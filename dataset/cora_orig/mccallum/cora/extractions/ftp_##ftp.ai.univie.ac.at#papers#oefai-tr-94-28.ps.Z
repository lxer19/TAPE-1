URL: ftp://ftp.ai.univie.ac.at/papers/oefai-tr-94-28.ps.Z
Refering-URL: http://www.ai.univie.ac.at/~juffi/thesis.html
Root-URL: 
Email: E-mail: juffi@ai.univie.ac.at  
Title: Efficient Pruning Methods for Relational Learning ausgefuhrt zum Zwecke der Erlangung des akademischen Grades eines
Author: eingereicht an der Technisch-Naturwissenschaftlichen von Johannes Furnkranz 
Address: Schottengasse 3 A-1010 Vienna, Austria  
Affiliation: Fakultat der Technischen Universitat Wien  Austrian Research Institute for Artificial Intelligence  
Note: Dissertation  OEFAI-TR-94-28  
Abstract-found: 0
Intro-found: 1
Reference: [Ali and Pazzani, 1993] <author> Kamal M. Ali and Michael J. Pazzani. HYDRA: </author> <title> A noisetolerant relational concept learning algorithm. </title> <booktitle> In Proceedings of the Thirteenth Joint International Conference on Artificial Intelligence, </booktitle> <pages> pages 10641071, </pages> <address> Chambery, France, </address> <year> 1993. </year>
Reference-contexts: During the writing of this thesis the implementation of the learning systems has been continuously improved. In fact, the current version is already able to handle multiple classes by incorporating an approach similar to that suggested in the relational learner HYDRA <ref> [Ali and Pazzani, 1993] </ref>: For each class a separate 8. CONCLUSION 93 concept description will be learned considering all examples for other classes as negative examples for the class to learn.
Reference: [Angluin and Laird, 1988] <author> D. Angluin and P. Laird. </author> <title> Learning from noisy exam-ples. </title> <journal> Machine Learning, </journal> <volume> 2(4) </volume> <pages> 343-370, </pages> <year> 1988. </year>
Reference-contexts: thesis we have used the domain of recognizing illegal chess positions in the king-rook-king (KRK) endgame which is described in detail in appendix A. 3.3.1 Setup of the Experiments The experiments in this section were performed with artificial noise added to the data following the Classification Noise Process described in <ref> [Angluin and Laird, 1988] </ref>. In this model a noise level of means that the sign of each example is reversed with a probability of . This means that % of the data have been wrong at training time.
Reference: [Bailey and Elkan, 1993] <author> Timothy L. Bailey and Charles Elkan. </author> <title> Estimating the accuracy of learned concepts. </title> <booktitle> In Proceedings of the 13th International Joint Conference on Artificial Intelligence (IJCAI-93), </booktitle> <pages> pages 895-900, </pages> <address> Chambery, France, </address> <year> 1993. </year>
Reference-contexts: In particular in domains where training instances are expensive or rare, this method is wasteful. One approach to avoid this problem could be to use cross-validation or bootstrap methods for evaluating the accuracy of the theories (see e.g. <ref> [Bailey and Elkan, 1993] </ref>). In particular for the efficient I-REP the additional computational costs caused by this method might still be bearable.
Reference: [Bain, 1991] <author> Michael Bain. </author> <title> Experiments in non-monotonic learning. </title> <booktitle> In Proceedings of the 8th International Workshop on Machine Learning, </booktitle> <pages> pages 380-384, </pages> <address> Evanston, Illinois, </address> <year> 1991. </year>
Reference: [Bergadano et al., 1993] <author> Francesco Bergadano, Daniele Gunetti, and Umberto Trinchero. </author> <title> The difficulties of learning logic programs with cut. </title> <journal> Journal of Artificial Intelligence Research, </journal> <volume> 1 </volume> <pages> 91-107, </pages> <year> 1993. </year>
Reference-contexts: However, contrary to recursion, learning cuts seems to be a very hard problem. The main reason for this is that a cut only has a procedural meaning and therefore cannot be easily induced from declarative data <ref> [Bergadano et al., 1993] </ref>.
Reference: [Bratko and King, 1994] <author> Ivan Bratko and Ross King. </author> <title> Applications of Inductive Logic Programming. </title> <journal> SIGART Bulletin, </journal> <volume> 5(1) </volume> <pages> 43-49, </pages> <year> 1994. </year>
Reference-contexts: For an overview of applications of empirical ILP systems consult <ref> [Bratko and King, 1994] </ref>. The learning task for most relational learning systems is shown in figure 2.1. We will exemplify it with a short example. In figure 2.2 the learning system has the task of learning the concept father.
Reference: [Bratko and Kononenko, 1986] <author> Ivan Bratko and Igor Kononenko. </author> <title> Learning diag-nostic rules from incomplete and noisy data. </title> <editor> In B. Phelps, editor, </editor> <booktitle> Interactions in AI and Statistical Methods, </booktitle> <pages> pages 142-153, </pages> <address> London, </address> <year> 1986. </year>
Reference-contexts: Research in propositional learning algorithms has already developed a variety of methods for noise handling. Noise-tolerant decision tree learning algorithms like CART [Breiman et al., 1984], C4.5 [Quinlan, 1993], ASSISTANT <ref> [Bratko and Kononenko, 1986] </ref>, CN2 [Clark and Boswell, 1991] are well-known and often applied to real-world problems. However, many of the solutions employed in these programs are tailored for propositional learning algorithms, so that the developement of noise-tolerant relational learning algorithms is currently a very active research field. 1.4. <p> We can distinguish two fundamentally different approaches [Cestnik et al., 1987]: Pre-Pruning means that during concept generation some training examples are deliberately ignored, so that the final concept description does not classify all training instances correctly. In decision tree learning these pre-pruning approaches include ID3 [Quinlan, 1986] or ASSISTANT <ref> [Bratko and Kononenko, 1986] </ref>. Post-Pruning means that first a complete and consistent concept description is generated from a proportion of the training data. The resulting concept is then analyzed with the remaining, unseen examples and, if necessary, is generalized to improve the accuracy on these examples.
Reference: [Breiman et al., 1984] <author> L. Breiman, J. Friedman, R. Olshen, and C. Stone. </author> <title> Classification and Regression Trees. </title> <publisher> Wadsworth & Brooks, </publisher> <address> Pacific Grove, CA, </address> <year> 1984. </year>
Reference-contexts: The most prominent representa 1.2. THE NEED FOR RELATIONS IN LEARNING 3 dangerous (Head,Body,Smiling,Holding,Jacket,Tie) :- red (Jacket). dangerous (Head,Body,Smiling,Holding,Jacket,Tie) :- Head = Body. tives of this family are C4.5 [Quinlan, 1993], Assistant [Cestnik et al., 1987] and CART <ref> [Breiman et al., 1984] </ref>. [Furnkranz, 1991] contains a summary of some basic methods for inducing decision trees from attribute-value data sets. 1.2 The Need for Relations in Learning In [Thrun et al., 1991] three problems are proposed in the robots domain. <p> Research in propositional learning algorithms has already developed a variety of methods for noise handling. Noise-tolerant decision tree learning algorithms like CART <ref> [Breiman et al., 1984] </ref>, C4.5 [Quinlan, 1993], ASSISTANT [Bratko and Kononenko, 1986], CN2 [Clark and Boswell, 1991] are well-known and often applied to real-world problems. <p> The resulting concept is then analyzed with the remaining, unseen examples and, if necessary, is generalized to improve the accuracy on these examples. In decision tree learning post-pruning approaches have e.g. been used in Reduced Er- ror Pruning [Quinlan, 1987], CART <ref> [Breiman et al., 1984] </ref> or ASSISTANT [Cestnik et al., 1987]. The main concern of the research reported in this thesis will be efficient pruning methods for rule learning algorithms. <p> Coincidentally, the learned concepts are of about equal complexity at this point. * The curve for the predictive accuracy is U-shaped, similar to some results on pruning decision trees to various degrees (see e.g. <ref> [Breiman et al., 1984] </ref>). * There is a transition from overfitting the noise to over-generalizing the rules. A low setting of Cutoff has a tendency to fit the noise, because most of the literals will have a correlation above the threshold. <p> The result is subsequently analyzed and (if necessary) simplified and generalized in order to increase its predictive accuracy on unseen data. Post-pruning approaches have been commonly used in the decision tree learning algorithms CART <ref> [Breiman et al., 1984] </ref>, ID3 [Quinlan, 1987] and ASSIS- TANT [Niblett and Bratko, 1986]. An overview and comparison of various approaches can be found in [Mingers, 1989a] and [Esposito et al., 1993a]. <p> For simplifying the resulting over-specific theory it is more common, however, to use a different set of examples that were not known in the initial learning phase (e.g. Error Complexity Pruning <ref> [Breiman et al., 1984] </ref>, Iterative Pruning [Gelfand et al., 1991] and Critical Value Pruning [Mingers, 1989a]). 4.1.1 The Algorithm The most common among these methods is Reduced Error Pruning (REP) [Quinlan, 1987]. <p> Research in decision tree learning has developed several methods for automating this selection <ref> [Breiman et al., 1984, Mingers, 1989a, Weiss and Indurkhya, 1994] </ref>. Most of these methods can be easily adapted for rule learning algorithms, once we have series of theories with different degrees of generality. <p> When the measured accuracy of one of the theories falls below the measured accuracy of the best theory so far minus the Standard Error for classification 3 , stop generating theories and return the last theory within the 1 SE margin. 3 This is based on an idea in CART <ref> [Breiman et al., 1984] </ref>, where the most general pruned decision tree within one SE of the best will be selected.
Reference: [Brunk and Pazzani, 1991] <author> Clifford A. Brunk and Michael J. Pazzani. </author> <title> An inves-tigation of noise-tolerant relational concept learning algorithms. </title> <booktitle> In Proceedings of the 8th International Workshop on Machine Learning, </booktitle> <pages> pages 389-393, </pages> <address> Evanston, Illinois, </address> <year> 1991. </year> <note> 94 BIBLIOGRAPHY 95 </note>
Reference-contexts: This simple algorithm has been adapted for a propositional rule learning framework by [Pagallo and Haussler, 1990] and subsequently been introduced to noise handling in Inductive Logic Programming by <ref> [Brunk and Pazzani, 1991] </ref>. At the beginning the training data are split into two subsets: a growing set (usually 2/3) and a pruning set (1/3). <p> It is very expensive to use, as at each step the algorithm has to evaluate one new theory for each literal of the old theory. delete-last-literal: This operator only tries to delete the last literal of each clause. <ref> [Brunk and Pazzani, 1991] </ref> argue that this more efficient operator is suitable for separate-and-conquer rule learning algorithms, because the order in which the literals of a clause are considered for pruning is inverse to the order in which they have been learned. delete-last-sequence: This operator, used e.g. in [Cohen, 1993], selects <p> It is very efficient and needs only few iterations. However, it should only be used in connection with one of the three other operators that are able to do the fine-tuning of the individual clauses. Reduced Error Pruning in its original form <ref> [Brunk and Pazzani, 1991] </ref> uses delete-last-literal and delete-clause for pruning the overly specific theories generated in phase 1. 4.1.2 Experiments [Brunk and Pazzani, 1991] show in a series of experiments in the KRK domain that REP improves upon pre-pruning with Foil's Encoding Length Stopping Criterion. <p> Reduced Error Pruning in its original form <ref> [Brunk and Pazzani, 1991] </ref> uses delete-last-literal and delete-clause for pruning the overly specific theories generated in phase 1. 4.1.2 Experiments [Brunk and Pazzani, 1991] show in a series of experiments in the KRK domain that REP improves upon pre-pruning with Foil's Encoding Length Stopping Criterion. We have performed similar experiments in the KRK domain which is described in detail in appendix A. <p> Of course, no stopping criterion was implemeted for the latter version in order to be able to overfit the data as described in <ref> [Brunk and Pazzani, 1991] </ref>. REP made use of all search 4.2. PROBLEMS WITH REDUCED ERROR PRUNING 41 optimization of section 2.3.3. The results are comparable to those reported in [Brunk and Pazzani, 1991]: REP performs better than Foil. <p> no stopping criterion was implemeted for the latter version in order to be able to overfit the data as described in <ref> [Brunk and Pazzani, 1991] </ref>. REP made use of all search 4.2. PROBLEMS WITH REDUCED ERROR PRUNING 41 optimization of section 2.3.3. The results are comparable to those reported in [Brunk and Pazzani, 1991]: REP performs better than Foil. <p> SUMMARY 49 4.4 Summary In this chapter we have reviewed several post-pruning approaches to noise-tolerant rule learning algorithm. Reduced Error Pruning (REP) <ref> [Brunk and Pazzani, 1991] </ref> is the best-known among these approaches and has been shown to achieve good results in terms of accuracy. However, this simple algorithm has several shortcomings as we have pointed out in section 4.2, most notably efficiency and incompatibility with the separate-and-conquer learning strategy. <p> For comparison, REP and Grow were implemented as described in [Cohen, 1993] with the exception that delete-last-literal was used as a clause pruning operator (as in <ref> [Brunk and Pazzani, 1991] </ref>) instead of Cohen's delete-last-sequence operator that deletes a final sequence of literals from a clause (see section 4.1.1). 1 I-REP uses delete-any-literal for pruning a clause. In order to have a comparison to the original version of REP we used information gain as a search heuristic. <p> Whenever the algorithm learns a clause that is worse than the empty 3 Preliminary experiments using delete-any-literal in the Grow algorithm indicate that its usage may not only result in an increase in run-time, but surprisingly also in a decrease in accuracy. <ref> [Brunk and Pazzani, 1991] </ref> also claim that in Foil and similar systems the more expensive delete-any-literal operator is not needed, because of the order in which the literals are added to the body of a clause.
Reference: [Buntine and Niblett, 1992] <author> Wray Buntine and Tim Niblett. </author> <title> A further compar-ison of splitting rules for decision-tree induction. </title> <journal> Machine Learning, </journal> <volume> 8 </volume> <pages> 75-85, </pages> <year> 1992. </year>
Reference-contexts: There are several search heuristics known from decision tree learning, most of them perform similarly (see e.g. <ref> [Mingers, 1989b, Buntine and Niblett, 1992] </ref>). [Lavrac et al., 1992b] and [Lavrac et al., 1992a] list a selection of several search heuristics for Foil- like empirical ILP system (see figure 2.4). 2.2.
Reference: [Cameron-Jones and Quinlan, 1993a] <author> R. M. Cameron-Jones and John Ross Quinlan. </author> <title> Avoiding pitfalls when learning recursive theories. </title> <editor> In R. Bajcsy, editor, </editor> <booktitle> Proceedings of the 13th International Joint Conference on Artificial Intelligence, </booktitle> <address> Chambery, France, </address> <year> 1993. </year>
Reference-contexts: However, one has to take care that not all variabilizations of recursive predicates are valid. Otherwise the program would very elegantly discover the "solution" ancestor (A,B) :- ancestor (A,B). There are many other pitfalls for a program that learns recursive definitions. <ref> [Cameron-Jones and Quinlan, 1993a] </ref> extensively discuss this problem and provide a fairly general solution. However, we feel that being able to learn recursive predicates is not a major issue in learning in real-world domains and have restricted our programs to non-recursive concept definitions. 2.3.
Reference: [Cameron-Jones and Quinlan, 1993b] <author> R.M. Cameron-Jones and J.R. Quinlan. </author> <title> First order learning, zeroth order data. </title> <booktitle> In Proceedings of the 6th Australian Joint Conference on AI. World Scientific, </booktitle> <year> 1993. </year>
Reference-contexts: A side effect of using propositional data is that we can compare propositional and relational learning algorithms and confirm that the quality of the concepts learned by the latter is not below the quality of the theories learned by the former (see <ref> [Cameron-Jones and Quinlan, 1993b] </ref> for more experiments along these lines). The appendix of [Holte, 1993] gives a summary of the results achieved by various algorithms on some of the most commonly used data sets of the UCI repository and a short description of these sets.
Reference: [Cameron-Jones, 1994] <author> R.M. Cameron-Jones. </author> <title> The complexity of Cohen's grow method. Unpublished draft for comments, </title> <month> May </month> <year> 1994. </year>
Reference-contexts: However, it should be intuitively clear that it will be less work to grow the theory of figure 3.6 from the empty theory (as Grow does) than to get there by successively pruning the theory of figure 4.2 (as REP does). 7 However, in <ref> [Cameron-Jones, 1994] </ref> it has recently been shown that this assumption is not quite correct and that the asymptotic time complexity of the Grow post-pruning method is also above the complexity of the initial rule growing phase. We will discuss this in a little more detail in section 6.3. <p> In order to get an idea on the asymptotic complexity of the various algorithms we have performed a log-log analysis as has been done in <ref> [Cameron-Jones, 1994] </ref>. <p> Thus it is significantly faster than the initial overfitting phase of both REP and Grow. In general the results we get are consistent with the analysis performed in <ref> [Cameron-Jones, 1994] </ref> for random data. In particular the evidence supports that REP has a complexity of (n 4 ) and that the initial rule growing phase is 6.3. EXPERIMENTS 73 O (n 2 log n) as shown in [Cohen, 1993] (see also section 4.1). <p> In particular the evidence supports that REP has a complexity of (n 4 ) and that the initial rule growing phase is 6.3. EXPERIMENTS 73 O (n 2 log n) as shown in [Cohen, 1993] (see also section 4.1). It also confirms the main result of <ref> [Cameron-Jones, 1994] </ref>, namely that the asymptotic complexity of Grow is not below the asymptotic complexity of the initial rule growing phase as has been claimed in [Cohen, 1993]. <p> This argument has been formalized in <ref> [Cameron-Jones, 1994] </ref>. In I-REP this is less likely to happen, because for each individual clause there is a high chance that if it fits noisy examples in the growing set it will not fit noisy examples in the pruning set. <p> In REP and Grow, however, a large number of these clauses are investigated, which makes it more probable that this will happen for one of them. This is also the main reason why Grow has a higher asymptotic time complexity than the initial overfitting phase <ref> [Cameron-Jones, 1994] </ref>. I-REP, on the other hand, will stop generating clauses whenever it has found a clause that has no support in the pruning set.
Reference: [Cestnik et al., 1987] <author> Bojan Cestnik, Igor Kononenko, and Ivan Bratko. </author> <title> ASSISTANT 86: A knowledge-elicitation tool for sophisticated users. </title> <editor> In Ivan Bratko and Nada Lavrac, editors, </editor> <booktitle> Progress in Machine Learning, </booktitle> <pages> pages 31-45, </pages> <address> Wilmslow, England, 1987. </address> <publisher> Sigma Press. </publisher>
Reference-contexts: The most prominent representa 1.2. THE NEED FOR RELATIONS IN LEARNING 3 dangerous (Head,Body,Smiling,Holding,Jacket,Tie) :- red (Jacket). dangerous (Head,Body,Smiling,Holding,Jacket,Tie) :- Head = Body. tives of this family are C4.5 [Quinlan, 1993], Assistant <ref> [Cestnik et al., 1987] </ref> and CART [Breiman et al., 1984]. [Furnkranz, 1991] contains a summary of some basic methods for inducing decision trees from attribute-value data sets. 1.2 The Need for Relations in Learning In [Thrun et al., 1991] three problems are proposed in the robots domain. <p> Prototypical for this approach is the LINUS system [Lavrac et al., 1991] that transforms the relational learning problem into an attribute-value representation that can be used by propositional learning algorithms like CN2 [Clark and Niblett, 1989] and ASSISTANT <ref> [Cestnik et al., 1987] </ref>. All three approaches impose different restrictions on the class of programs they can learn. LINUS e.g. is not able to learn recursive predicates, while Golem is limited to a restricted form of ground background knowledge. <p> We can distinguish two fundamentally different approaches <ref> [Cestnik et al., 1987] </ref>: Pre-Pruning means that during concept generation some training examples are deliberately ignored, so that the final concept description does not classify all training instances correctly. In decision tree learning these pre-pruning approaches include ID3 [Quinlan, 1986] or ASSISTANT [Bratko and Kononenko, 1986]. <p> The resulting concept is then analyzed with the remaining, unseen examples and, if necessary, is generalized to improve the accuracy on these examples. In decision tree learning post-pruning approaches have e.g. been used in Reduced Er- ror Pruning [Quinlan, 1987], CART [Breiman et al., 1984] or ASSISTANT <ref> [Cestnik et al., 1987] </ref>. The main concern of the research reported in this thesis will be efficient pruning methods for rule learning algorithms.
Reference: [Cestnik, 1990] <author> Bojan Cestnik. </author> <title> Estimating probabilities: A crucial task in Machine Learning. </title> <booktitle> In Proceedings of the European Conference on Artificial Intelligence (ECAI-90), </booktitle> <address> Stockholm, </address> <month> August </month> <year> 1990. </year>
Reference-contexts: p p+n ) and the a pri <p>- ori distribution ( P P +N ) of the positive and negative examples. 3 The improved probability estimates can be used in any of the other search heuristics. mFoil [Dzeroski and Bratko, 1992a] uses them directly for the simple probability search heuristic. <ref> [Cestnik, 1990] </ref> gives a closer analysis of these two heuristics. The information heuristic estimates the amount of information necessary to specify that an example covered by the clause is positive. This estimate can simply be calculated by taking the logarithm of the inverse of the probability P (c).
Reference: [Clark and Boswell, 1991] <author> Peter Clark and Robin Boswell. </author> <title> Rule induction with CN2: Some recent improvements. </title> <booktitle> In Proceedings of the 5th European Working Session of Learning, </booktitle> <pages> pages 151-163, </pages> <address> Porto, Portugal, </address> <year> 1991. </year>
Reference-contexts: Research in propositional learning algorithms has already developed a variety of methods for noise handling. Noise-tolerant decision tree learning algorithms like CART [Breiman et al., 1984], C4.5 [Quinlan, 1993], ASSISTANT [Bratko and Kononenko, 1986], CN2 <ref> [Clark and Boswell, 1991] </ref> are well-known and often applied to real-world problems. However, many of the solutions employed in these programs are tailored for propositional learning algorithms, so that the developement of noise-tolerant relational learning algorithms is currently a very active research field. 1.4. <p> It has its roots in the early days of Machine Learning in the covering algorithm of the famous AQ family [Michalski, 1980, Michalski et al., 1986]. CN2 <ref> [Clark and Niblett, 1989, Clark and Boswell, 1991] </ref> eliminated AQ's dependence on an initial seed example and employed the separate-and-conquer strategy for the first time. The term separate-and-conquer has been coined by [Pagallo and Haussler, 1990] in the context of learning decision lists. <p> that cover only a few examples by making sure that the number of bits that are needed to encode the current clause is less than the number of bits needed to encode the instances covered by it. 1 * Significance Testing was first used in the propositional CN2 induction algorithm <ref> [Clark and Niblett, 1989, Clark and Boswell, 1991] </ref> and later on in the relational learner mFoil [Dzeroski and Bratko, 1992a].
Reference: [Clark and Niblett, 1989] <author> Peter Clark and Tim Niblett. </author> <title> The CN2 induction al-gorithm. </title> <journal> Machine Learning, </journal> <volume> 3(4) </volume> <pages> 261-283, </pages> <year> 1989. </year>
Reference-contexts: One relational learning algorithm, LINUS, tries to automate this process (see page 10). Like the decision tree algorithms, other classic propositional learning algorithms (including CN2 <ref> [Clark and Niblett, 1989] </ref>, AQ [Michalski, 1980, Michalski et al., 1986], and others) are also limited to concept descriptions in propositional calculus. <p> Most of them learn from an attribute-value representation of the input data and their representational power thus is restricted to decision trees as in the ID3 family [Quinlan, 1983] or propositional Horn clauses as in AQ [Michalski et al., 1986] or CN2 <ref> [Clark and Niblett, 1989] </ref>. ILP algorithms, on the other hand, can not only test attributes for specific values, but also make use of relations (like equality) between the different attributes. Inductive Logic Programming has quickly developed to a very active research field. <p> Prototypical for this approach is the LINUS system [Lavrac et al., 1991] that transforms the relational learning problem into an attribute-value representation that can be used by propositional learning algorithms like CN2 <ref> [Clark and Niblett, 1989] </ref> and ASSISTANT [Cestnik et al., 1987]. All three approaches impose different restrictions on the class of programs they can learn. LINUS e.g. is not able to learn recursive predicates, while Golem is limited to a restricted form of ground background knowledge. <p> It has its roots in the early days of Machine Learning in the covering algorithm of the famous AQ family [Michalski, 1980, Michalski et al., 1986]. CN2 <ref> [Clark and Niblett, 1989, Clark and Boswell, 1991] </ref> eliminated AQ's dependence on an initial seed example and employed the separate-and-conquer strategy for the first time. The term separate-and-conquer has been coined by [Pagallo and Haussler, 1990] in the context of learning decision lists. <p> that cover only a few examples by making sure that the number of bits that are needed to encode the current clause is less than the number of bits needed to encode the instances covered by it. 1 * Significance Testing was first used in the propositional CN2 induction algorithm <ref> [Clark and Niblett, 1989, Clark and Boswell, 1991] </ref> and later on in the relational learner mFoil [Dzeroski and Bratko, 1992a].
Reference: [Cohen, 1993] <author> William W. Cohen. </author> <title> Efficient pruning methods for separate-andconquer rule learning systems. </title> <booktitle> In Proceedings of the 13th International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 988-994, </pages> <address> Chambery, France, </address> <year> 1993. </year>
Reference-contexts: each clause. [Brunk and Pazzani, 1991] argue that this more efficient operator is suitable for separate-and-conquer rule learning algorithms, because the order in which the literals of a clause are considered for pruning is inverse to the order in which they have been learned. delete-last-sequence: This operator, used e.g. in <ref> [Cohen, 1993] </ref>, selects the best of all theories that result from deleting a sequence of literals from the end of the clause. <p> Comparing these values to the values of the other algorithms shows that pruning is necessary in this domain. 4.2. PROBLEMS WITH REDUCED ERROR PRUNING 42 4.2.1 Efficiency In <ref> [Cohen, 1993] </ref> it was shown that the worst-case time complexity of REP is as bad as (n 4 ) on random data (n is the number of examples). The growing of the initial concept, on the other hand, is only (n 2 log n). <p> The growing of the initial concept, on the other hand, is only (n 2 log n). The derivation of these numbers as given in <ref> [Cohen, 1993] </ref> rests on the following assumptions: 1. Random data are incompressible. Therefore each example has to be explained by a separate rule. The resulting concept description before pruning will therefore contain O (n) rules altogether. 2. <p> According to 5. this simplification loop has to be performed at least n times. Therefore we get a total cost of (n 4 ). A more detailed proof can be found in <ref> [Cohen, 1993] </ref>. 2 While the number of relations is constant, the number of variabilizations for each literal might be increasing with the introduction of new variables. <p> Section 4.3 will further discuss this issue and present an alternative post-pruning algorithm that searches in a top-down fashion. 4.3 The Grow Algorithm In <ref> [Cohen, 1993] </ref> some of the problems of section 4.2 | in particular efficiency | have been recognized. Cohen has then proposed Grow, a post-pruning algorithm based on a technique used in [Pagallo and Haussler, 1990]. Like REP, the Grow algorithm first finds a theory that overfits the data. <p> The generalizations of the clauses of the intermediate theory are formed by repeatedly deleting a final sequence of conditions from the clause so that the error on the growing set goes up the least. For a detailed description of the Grow algorithm see <ref> [Cohen, 1993] </ref>. <p> This is repeated until all clauses in the final concept description (which is assumed to be of constant size by 4.) have been found. 7 Therefore the costs of this algorithm are O (n 2 log n). Again, consult <ref> [Cohen, 1993] </ref> for a detailed proof. <p> It does not remove the most useless clause or literal from the specific theory, but instead adds the most promising generalization of a rule to an initially empty theory. This results in a significant gain in efficiency, along with a slight gain in accuracy as the experiments in <ref> [Cohen, 1993] </ref> show. As we have already discussed, an explanation for this could be that top-down hill-climbing starts from the empty theory, which in many domains is much closer to the correct theory than the most specific one. <p> Training Accuracy Run-time Set Size REP Grow Overfitting REP Grow 100 91.77 9.05 91.60 10.71 8.63 2.44 1.66 500 97.62 0.95 98.17 0.72 456.56 1578.16 100.81 1000 98.01 1.38 98.30 0.77 2129.89 23125.34 806.89 Table 4.2: REP and Grow in the noisy KRK domain. As in <ref> [Cohen, 1993] </ref> the basic findings are that Grow's top-down search strategy prunes significantly faster than REP and is also able to gain a little accuracy, although these differences are not statistically significant. <p> However, this simple algorithm has several shortcomings as we have pointed out in section 4.2, most notably efficiency and incompatibility with the separate-and-conquer learning strategy. We have further presented a modified pruning algorithm by <ref> [Cohen, 1993] </ref> that prunes more efficiently and is also a little more accurate than REP. However the Grow algorithm still suffers from the fact that it has to generate an overly specific theory first. [Cohen, 1993] has tried to improve his Grow algorithm by adding two stopping heuristics to the initial <p> We have further presented a modified pruning algorithm by <ref> [Cohen, 1993] </ref> that prunes more efficiently and is also a little more accurate than REP. However the Grow algorithm still suffers from the fact that it has to generate an overly specific theory first. [Cohen, 1993] has tried to improve his Grow algorithm by adding two stopping heuristics to the initial stage of overfitting, and thus achieved a further speed-up of the algorithm. We will introduce an alternative way of combining pre-pruning and post-pruning methods in chapter 5 in order to avoid excessive overfitting. <p> A natural solution to this problem would be to start the pruning phase with a simpler theory. This idea has first been investigated in <ref> [Cohen, 1993] </ref>, where the efficient post-pruning algorithm Grow (see section 4.3) has been combined with some weak pre-pruning heuristics to speed up the learning process. <p> For comparison, REP and Grow were implemented as described in <ref> [Cohen, 1993] </ref> with the exception that delete-last-literal was used as a clause pruning operator (as in [Brunk and Pazzani, 1991]) instead of Cohen's delete-last-sequence operator that deletes a final sequence of literals from a clause (see section 4.1.1). 1 I-REP uses delete-any-literal for pruning a clause. <p> In particular the evidence supports that REP has a complexity of (n 4 ) and that the initial rule growing phase is 6.3. EXPERIMENTS 73 O (n 2 log n) as shown in <ref> [Cohen, 1993] </ref> (see also section 4.1). It also confirms the main result of [Cameron-Jones, 1994], namely that the asymptotic complexity of Grow is not below the asymptotic complexity of the initial rule growing phase as has been claimed in [Cohen, 1993]. <p> EXPERIMENTS 73 O (n 2 log n) as shown in <ref> [Cohen, 1993] </ref> (see also section 4.1). It also confirms the main result of [Cameron-Jones, 1994], namely that the asymptotic complexity of Grow is not below the asymptotic complexity of the initial rule growing phase as has been claimed in [Cohen, 1993]. However, in all experiments of this section, the absolute values for the run-time of Grow has been negligible compared to the run-time of the over-fitting phase.
Reference: [De Raedt and Bruynooghe, 1993] <author> Luc De Raedt and Maurice Bruynooghe. </author> <title> A theory of clausal discovery. </title> <editor> In R. Bajcsy, editor, </editor> <booktitle> Proceedings of the 13th International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 1058-1063, </pages> <address> Chambery, France, 1993. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Discovery is a very new branch of ILP which differs from most other approaches in that there is no particular goal concept specified in advance, but the program tries to find interesting regularities by itself. The most prominent systems are Claudien <ref> [De Raedt and Bruynooghe, 1993] </ref> and LaGrange [Dzeroski and Todorovski, 1993]. Of course, several systems would fit into more than one category.
Reference: [De Raedt and Lavrac, 1993] <author> Luc De Raedt and Nada Lavrac. </author> <title> The many faces of Inductive Logic Programming. </title> <editor> In J. Komorowski, editor, </editor> <booktitle> Proceedings of the 7th International Symposium on Methodologies for Intelligent Systems, Lecture Notes in Artificial Intelligence. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1993. </year> <note> BIBLIOGRAPHY 96 </note>
Reference-contexts: Other introductory texts include <ref> [De Raedt and Lavrac, 1993] </ref>, [Muggleton, 1993], and [Muggleton and De Raedt, 1994]. 2.1 Relational Learning The main concern of this thesis will be Relational Learning or Empirical Inductive Logic Programming. Learning systems of this category typically are designed to learn classification rules from real-world databases.
Reference: [De Raedt, 1992] <author> Luc De Raedt. </author> <title> Interactive Theory Revision: An Inductive Logic Programming Approach. </title> <publisher> Academic Press, </publisher> <year> 1992. </year>
Reference-contexts: RELATIONAL LEARNING 7 out to be correct. Typical revision systems are MIS [Shapiro, 1982], CIGOL [Muggleton, 1988], CLINT <ref> [De Raedt, 1992] </ref>, KRT (MOBAL) [Wrobel, 1994], Forte [Richards, 1992] and AUDREY [Wogulis, 1991]. Predicate Invention is an important research direction aiming at introducing new background knowledge in order to gain expressiveness or to make the resulting theory more understandable [Stahl, 1993].
Reference: [Dolsak and Muggleton, 1992] <author> Bojan Dolsak and Stephen Muggleton. </author> <title> The ap-plication of Inductive Logic Programming to finite-element mesh design. </title> <editor> In Stephen Muggleton, editor, </editor> <booktitle> Inductive Logic Programming, </booktitle> <pages> pages 453-472. </pages> <publisher> Academic Press Ltd., </publisher> <address> London, </address> <year> 1992. </year>
Reference-contexts: Relational Learning systems are designed for this purpose and have already been applied to various real-world problems, like finite-element mesh design <ref> [Dolsak and Muggleton, 1992, Dzeroski and Bratko, 1992a] </ref>, medical diagnosis [Lavrac et al., 1993, Petta, 1994], chess endgames [Morales, 1992, Muggleton et al., 1989, Quinlan, 1990, Dzeroski and Bratko, 1992a], natural language understanding [Zelle and Mooney, 1993], document recognition [Esposito et al., 1993b] etc. <p> THE MESH DOMAIN 80 7.2 The Mesh Domain We have also tested our algorithms on the finite element mesh design problem first studied and described in detail in <ref> [Dolsak and Muggleton, 1992] </ref>. The problem of mesh design is to break complex objects into a number of finite elements in order to be able to compute pressure and deformations when a force is applied to the object. <p> The basic problem during manual mesh design is the selection of the correct number of finite elements on the edges of the structure. Several authors have tried ILP methods on this problem <ref> [Dolsak and Muggleton, 1992, Dzeroski and Bratko, 1992a, Quinlan, 1994] </ref>.The available background knowledge consists of an attribute-based description of the edges and of topological relations between the edges.
Reference: [Dolsak et al., 1994] <author> Bojan Dolsak, Ivan Bratko, and Anton Jezernik. </author> <title> Finite ele-ment mesh design: An engineering domain for ILP application. </title> <booktitle> In Proceedings of the 4th International Workshop on Inductive Logic Programming, number 237 in GMD-Studien, </booktitle> <pages> pages 305-320, </pages> <address> Bad Honnef, Germany, </address> <year> 1994. </year>
Reference-contexts: Only examples for classes 1 and 2 are present in all five objects. For this reason recently five new objects have been 2 The given run-times are the total run-times (learning and pruning). 7.3. PROPOSITIONAL DATA SETS 83 included into the database. Preliminary results reported in <ref> [Dolsak et al., 1994] </ref> show significant improvements compared to previous results using only five objects. <p> We hope to significantly improve our results in this domain by working out these ideas and by using them on the new data set <ref> [Dolsak et al., 1994] </ref> which contains a total of 10 objects (and thus provides more redundancy). 7.3 Propositional Data Sets The purpose of the series of experiments reported in this section is that we want to compare our algorithms on a variety of natural data sets in order to get more
Reference: [Dzeroski and Bratko, 1992a] <author> Saso Dzeroski and Ivan Bratko. </author> <title> Handling noise in Inductive Logic Programming. </title> <booktitle> In Proceedings of the International Workshop on Inductive Logic Programming, </booktitle> <address> Tokyo, Japan, </address> <year> 1992. </year>
Reference-contexts: field can be found in [Sammut, 1993], a selection of some of the most important papers in [Muggleton, 1992]. [Lavrac and Dzeroski, 1993] is an introductory book on Inductive Logic Pro- gramming with a strong focus on relational learning systems, in particular on LINUS [Lavrac et al., 1991] and mFoil <ref> [Dzeroski and Bratko, 1992a] </ref>. Other introductory texts include [De Raedt and Lavrac, 1993], [Muggleton, 1993], and [Muggleton and De Raedt, 1994]. 2.1 Relational Learning The main concern of this thesis will be Relational Learning or Empirical Inductive Logic Programming. <p> Relational Learning systems are designed for this purpose and have already been applied to various real-world problems, like finite-element mesh design <ref> [Dolsak and Muggleton, 1992, Dzeroski and Bratko, 1992a] </ref>, medical diagnosis [Lavrac et al., 1993, Petta, 1994], chess endgames [Morales, 1992, Muggleton et al., 1989, Quinlan, 1990, Dzeroski and Bratko, 1992a], natural language understanding [Zelle and Mooney, 1993], document recognition [Esposito et al., 1993b] etc. <p> while the m-estimate tries to trade off between the a posteriori distribution ( p p+n ) and the a pri <p>- ori distribution ( P P +N ) of the positive and negative examples. 3 The improved probability estimates can be used in any of the other search heuristics. mFoil <ref> [Dzeroski and Bratko, 1992a] </ref> uses them directly for the simple probability search heuristic. [Cestnik, 1990] gives a closer analysis of these two heuristics. The information heuristic estimates the amount of information necessary to specify that an example covered by the clause is positive. <p> needed to encode the current clause is less than the number of bits needed to encode the instances covered by it. 1 * Significance Testing was first used in the propositional CN2 induction algorithm [Clark and Niblett, 1989, Clark and Boswell, 1991] and later on in the relational learner mFoil <ref> [Dzeroski and Bratko, 1992a] </ref>. <p> Statistical measures usually improve with the size of the training sets and so does the quality of the rules induced by Fossil. While both Foil and Fossil successively improve their predictive accuracy with increasing training set sizes, only Fossil converges towards a useful theory. 3.3.4 Comparison with mFoil mFoil <ref> [Dzeroski and Bratko, 1992a] </ref> is an algorithm based on Foil that has adapted several features from the CN2 learning algorithm, such as the use of the Laplace and m-estimate as a search heuristic (see figure 2.4) and the use of significance testing as a stopping criterion (see section 3.1). <p> However, one of the points to make here is that a good value of the m parameter is not only dependent on the amount of noise (as can be seen from the results given in <ref> [Dzeroski and Bratko, 1992a] </ref> and [Dzeroski and Bratko, 1992b]), but also on the size of the example set. The higher the noise level is, the higher 10 The current version achieves 98.44% on the same data sets with 1000 examples. 3.4. SUMMARY 36 one should choose the value of m. <p> The basic problem during manual mesh design is the selection of the correct number of finite elements on the edges of the structure. Several authors have tried ILP methods on this problem <ref> [Dolsak and Muggleton, 1992, Dzeroski and Bratko, 1992a, Quinlan, 1994] </ref>.The available background knowledge consists of an attribute-based description of the edges and of topological relations between the edges. <p> The learned theories were tested as in [Quinlan, 1994], which is a little different from the setup used in <ref> [Dzeroski and Bratko, 1992a] </ref>: Instead of actually predicting a value for the number of finite elements on an edge, we merely checked for all possible values whether this value could be derived from the learned rules or not. The basic difference is 7.2. <p> The basic difference is 7.2. THE MESH DOMAIN 81 that we tested on ground instances, whereas <ref> [Dzeroski and Bratko, 1992a] </ref> tested the target predicate with an unbound value for the number of finite elements for positive examples. The two procedures yield the same result when we assume that the rules are not overlapping, which, of course, cannot be guaranteed. <p> For algorithms like Golem [Muggleton and Feng, 1990] and Foil [Quinlan and Cameron-Jones, 1993] the topological relations have been made determinate, i.e. it has been enforced that each topological relation has at most one output value for each set of input values. <ref> [Dzeroski and Bratko, 1992a] </ref> report experiments that forced mFoil to use one of the topological relations at the beginning of the clause. This did not help much for the first four objects, but significantly improved the quality of the learned rules for object E.
Reference: [Dzeroski and Bratko, 1992b] <author> Saso Dzeroski and Ivan Bratko. </author> <title> Using the mestimate in Inductive Logic Programming. In Logical Approaches to Machine Learning, </title> <booktitle> Workshop Notes of the 10th European Conference on AI, </booktitle> <address> Vienna, Austria, </address> <year> 1992. </year>
Reference-contexts: Thus a noise level of in our experiments is roughly equivalent to a noise level of 2 in the results reported in <ref> [Lavrac and Dzeroski, 1992, Dzeroski and Bratko, 1992b] </ref>. Noise was added incrementally, i.e. instances which had a reversed sign at a noise level 1 also had a reversed sign at a noise level 2 &gt; 1 . <p> However, one of the points to make here is that a good value of the m parameter is not only dependent on the amount of noise (as can be seen from the results given in [Dzeroski and Bratko, 1992a] and <ref> [Dzeroski and Bratko, 1992b] </ref>), but also on the size of the example set. The higher the noise level is, the higher 10 The current version achieves 98.44% on the same data sets with 1000 examples. 3.4. SUMMARY 36 one should choose the value of m.
Reference: [Dzeroski and Lavrac, 1991] <author> Saso Dzeroski and Nada Lavrac. </author> <title> Learning relations from noisy examples: An empirical comparison of LINUS and FOIL. </title> <booktitle> In Proceedings of the 8th International Workshop on Machine Learning, </booktitle> <pages> pages 399402, </pages> <address> Evanston, Illinois, </address> <year> 1991. </year>
Reference: [Dzeroski and Todorovski, 1993] <author> Saso Dzeroski and Ljupco Todorovski. </author> <title> Discovering dynamics: From Inductive Logic Programming to machine discovery. </title> <booktitle> In Proceedings of the AAAI-93 Workshop on Knowledge Discovery in Databases, </booktitle> <pages> pages 125-137, </pages> <address> Washington, DC, 1993. </address> <publisher> AAAI Press. </publisher>
Reference-contexts: Discovery is a very new branch of ILP which differs from most other approaches in that there is no particular goal concept specified in advance, but the program tries to find interesting regularities by itself. The most prominent systems are Claudien [De Raedt and Bruynooghe, 1993] and LaGrange <ref> [Dzeroski and Todorovski, 1993] </ref>. Of course, several systems would fit into more than one category.
Reference: [Esposito et al., 1993a] <author> Floriana Esposito, Donato Malerba, and Giovanni Semeraro. </author> <title> Decision tree pruning as a search in the state space. </title> <booktitle> In Proceedings of the European Conference on Machine Learning, </booktitle> <pages> pages 165-184, </pages> <address> Vienna, Austria, 1993. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: Typically this results in a very complex theory that is hard to understand and is not very predictive on unseen examples. 8 Pruning is a standard way of dealing with noise in concept learning (see e.g. [Mingers, 1989a] or <ref> [Esposito et al., 1993a] </ref>). We can distinguish two fundamentally different approaches [Cestnik et al., 1987]: Pre-Pruning means that during concept generation some training examples are deliberately ignored, so that the final concept description does not classify all training instances correctly. <p> Post-pruning approaches have been commonly used in the decision tree learning algorithms CART [Breiman et al., 1984], ID3 [Quinlan, 1987] and ASSIS- TANT [Niblett and Bratko, 1986]. An overview and comparison of various approaches can be found in [Mingers, 1989a] and <ref> [Esposito et al., 1993a] </ref>. This chapter will first review how Reduced Error Pruning [Quinlan, 1987] can be adapted for a rule learning algorithm (section 4.1).
Reference: [Esposito et al., 1993b] <author> Floriana Esposito, Donato Malerba, Giovanni Semeraro, and Michael Pazzani. </author> <title> A Machine Learning approach to document understand-ing. </title> <booktitle> In Proceedings of the 2nd International Workshop on Multistrategy Learning, </booktitle> <pages> pages 276-292, </pages> <year> 1993. </year>
Reference-contexts: already been applied to various real-world problems, like finite-element mesh design [Dolsak and Muggleton, 1992, Dzeroski and Bratko, 1992a], medical diagnosis [Lavrac et al., 1993, Petta, 1994], chess endgames [Morales, 1992, Muggleton et al., 1989, Quinlan, 1990, Dzeroski and Bratko, 1992a], natural language understanding [Zelle and Mooney, 1993], document recognition <ref> [Esposito et al., 1993b] </ref> etc. Some of the systems even produced new knowledge that was of considerable interest for researchers in the application domain and has been published in journals of their subject area [Muggleton et al., 1992, Sternberg et al., 1992, King et al., 1992].
Reference: [Flach, 1992] <author> Peter A. Flach. </author> <title> Generality revisited. In Logical Approaches to Machine Learning, </title> <booktitle> Workshop Notes of the 10th European Conference on AI, </booktitle> <address> Vienna, Austria, </address> <year> 1992. </year> <note> BIBLIOGRAPHY 97 </note>
Reference-contexts: We consider the empty theory to be most general, because "Everything is false." is a very general statement. However, our "most specific" theory will cover more ground instances than the empty theory, and thus may be considered (extensionally) more general. See <ref> [Flach, 1992] </ref> for a discussion of related matters. 2 The restriction for admitting only theories with a cutoff above 0:15 was only made for reasons of efficiency.
Reference: [Flach, 1993] <author> Peter A. Flach. </author> <title> Predicate invention in inductive data engineer-ing. </title> <editor> In Pavel B. Brazdil, editor, </editor> <booktitle> Machine Learning: ECML-93, number 667 in Lecture Notes in Artificial Intelligence, </booktitle> <pages> pages 83-94, </pages> <address> Vienna, Austria, 1993. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: Predicate Invention is an important research direction aiming at introducing new background knowledge in order to gain expressiveness or to make the resulting theory more understandable [Stahl, 1993]. Com- mon methods to invent new predicates include detecting data dependencies <ref> [Flach, 1993] </ref> or clause completion heuristics [Kijsirikul et al., 1992]. Many systems try to invert deductive reasoning and are able to invent new predicates that way.
Reference: [Furnkranz and Widmer, 1994] <author> Johannes Furnkranz and Gerhard Widmer. </author> <title> Incremental Reduced Error Pruning. </title> <booktitle> In Proceedings of the 11th International Conference on Machine Learning, </booktitle> <pages> pages 70-77, </pages> <address> New Brunswick, NJ, </address> <year> 1994. </year>
Reference-contexts: Excerpts of this chapter have been previously published in <ref> [Furnkranz and Widmer, 1994] </ref>. 6.1 Incremental REP The new algorithm that we will present in this chapter was motivated by the observation that post-pruning is incompatible with the separate-and-conquer learning strategy as we have discussed in section 4.2.3. <p> Similar problems can be expected in a domains with a rather specific underlying theory. Confirmation for this hypothesis in the form of additional experimental evidence can be found in <ref> [Furnkranz and Widmer, 1994] </ref> and in chapter 7. Chapter 7 Experimental Evaluation After having presented an overview of new and old pruning methods for relational concept learning, we will now try to empirically evaluate and compare these methods in various test domains. <p> 88.74 21.43 86.73 26.32 87.42 28.12 89.92 28.89 88.99 29.82 87.74 3.12 88.21 23.89 89.12 29.82 92.20 3.12 88.03 22.43 90.14 29.82 92.20 2.08 91.54 12.81 91.64 Table 7.2: Accuracies in the mesh domain Some of the results reported here differ a little from the ones we have reported previously <ref> [Furnkranz, 1993b, Furnkranz, 1994d, Furnkranz and Widmer, 1994] </ref>, because the previous results are from different phases of our research which used no or different constraints on the search space. <p> However, the general picture remains the same: I-REP is clearly faster and a little more accurate than all of the other algorithms (with the exception of Fossil (0.3)). The advantage in terms of accuracy of I-REP is not as significant as in <ref> [Furnkranz and Widmer, 1994] </ref>. However, I-REP-2, the version of I-REP that prefers purity over accuracy (see section 6.3.1), is better than I-REP in this domain.
Reference: [Furnkranz, 1991] <author> Johannes Furnkranz. </author> <title> Induktives Lernen durch Generieren von Decision Trees. </title> <type> Master's thesis, </type> <institution> Vienna University of Technology, </institution> <year> 1991. </year> <note> In German. </note>
Reference-contexts: The most prominent representa 1.2. THE NEED FOR RELATIONS IN LEARNING 3 dangerous (Head,Body,Smiling,Holding,Jacket,Tie) :- red (Jacket). dangerous (Head,Body,Smiling,Holding,Jacket,Tie) :- Head = Body. tives of this family are C4.5 [Quinlan, 1993], Assistant [Cestnik et al., 1987] and CART [Breiman et al., 1984]. <ref> [Furnkranz, 1991] </ref> contains a summary of some basic methods for inducing decision trees from attribute-value data sets. 1.2 The Need for Relations in Learning In [Thrun et al., 1991] three problems are proposed in the robots domain.
Reference: [Furnkranz, 1993a] <author> Johannes Furnkranz. </author> <title> Avoiding noise fitting in a foil-like learning algorithm. </title> <booktitle> In Proceedings of the IJCAI-93 Workshop on Inductive Logic Programming, </booktitle> <pages> pages 14-23, </pages> <year> 1993. </year>
Reference-contexts: Parts of this chapter have been previously published in a somewhat different form in <ref> [Furnkranz, 1993a] </ref> and [Furnkranz, 1994b]. 3.1 Pre-Pruning in Relational Learning As we have discussed in section 2.3.4, noise in the data is a problem for the simple SeparateAndConquer rule learning algorithm of figure 2.3, because it tries to find explanations for every single example in the training set, including the erroneous
Reference: [Furnkranz, 1993b] <author> Johannes Furnkranz. Fossil: </author> <title> A robust relational learner. </title> <type> Technical Report OEFAI-TR-93-28, </type> <institution> Austrian Research Institute for Artificial Intelligence, </institution> <year> 1993. </year> <note> Extended version. </note>
Reference-contexts: 88.74 21.43 86.73 26.32 87.42 28.12 89.92 28.89 88.99 29.82 87.74 3.12 88.21 23.89 89.12 29.82 92.20 3.12 88.03 22.43 90.14 29.82 92.20 2.08 91.54 12.81 91.64 Table 7.2: Accuracies in the mesh domain Some of the results reported here differ a little from the ones we have reported previously <ref> [Furnkranz, 1993b, Furnkranz, 1994d, Furnkranz and Widmer, 1994] </ref>, because the previous results are from different phases of our research which used no or different constraints on the search space. <p> 9284.98 3712.14 7982.03 7541.57 3257.74 6355.69 REP 29669.36 19757.67 42305.26 38442.16 11144.54 28263.80 Grow 14437.17 6649.63 12225.26 11769.10 4320.45 9880.32 No Pruning (TDP) 2364.68 3833.84 6743.36 4521.52 1351.28 3762.94 TDP 3686.85 15622.16 18592.36 11104.58 1550.42 10111.27 I-REP-2 132.01 293.15 234.09 443.51 352.84 291.12 Table 7.3: Run-times in the mesh domain <ref> [Furnkranz, 1993b] </ref>) achieves a relatively good performance on unseen positive examples. Its overall accuracy, however, is very bad. The post-pruning algorithms are very inefficient 2 . Grow is more efficient and more accurate than REP. TDP clearly outperforms REP because it can start post-pruning with simpler and better theories.
Reference: [Furnkranz, 1994a] <author> Johannes Furnkranz. </author> <title> A comparison of pruning methods for relational concept learning. </title> <booktitle> In Proceedings of the AAAI-94 Workshop on Knowledge Discovery in Databases, </booktitle> <pages> pages 371-382, </pages> <year> 1994. </year>
Reference-contexts: We will mostly concentrate on comparing the approaches we have discussed in this thesis to each other, but will occasionally also include other learning systems into the tests to have a comparison to some well-known algorithms. Parts of this chapter have previously been presented in <ref> [Furnkranz, 1994a] </ref> and [Furnkranz, 1994c]. 7.1 Summary of the Experiments in the KRK Domain We have tested several algorithms in the domain of recognizing illegal chess positions in the KRK chess endgame [Muggleton et al., 1989].
Reference: [Furnkranz, 1994b] <author> Johannes Furnkranz. Fossil: </author> <title> A robust relational learner. </title> <booktitle> In Proceedings of the European Conference on Machine Learning, </booktitle> <pages> pages 122-137, </pages> <address> Catania, Italy, 1994. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: Parts of this chapter have been previously published in a somewhat different form in [Furnkranz, 1993a] and <ref> [Furnkranz, 1994b] </ref>. 3.1 Pre-Pruning in Relational Learning As we have discussed in section 2.3.4, noise in the data is a problem for the simple SeparateAndConquer rule learning algorithm of figure 2.3, because it tries to find explanations for every single example in the training set, including the erroneous examples.
Reference: [Furnkranz, 1994c] <author> Johannes Furnkranz. </author> <title> Pruning methods for rule learning al-gorithms. </title> <booktitle> In Proceedings of the 4th International Workshop on Inductive Logic Programming, number 237 in GMD-Studien, </booktitle> <pages> pages 321-336, </pages> <year> 1994. </year>
Reference-contexts: We will mostly concentrate on comparing the approaches we have discussed in this thesis to each other, but will occasionally also include other learning systems into the tests to have a comparison to some well-known algorithms. Parts of this chapter have previously been presented in [Furnkranz, 1994a] and <ref> [Furnkranz, 1994c] </ref>. 7.1 Summary of the Experiments in the KRK Domain We have tested several algorithms in the domain of recognizing illegal chess positions in the KRK chess endgame [Muggleton et al., 1989].
Reference: [Furnkranz, 1994d] <author> Johannes Furnkranz. </author> <title> Top-down pruning in relational learn-ing. </title> <booktitle> In Proceedings of the 11th European Conference on Artificial Intelligence, </booktitle> <pages> pages 453-457, </pages> <address> Amsterdam, The Netherlands, </address> <year> 1994. </year>
Reference-contexts: Again we report some experiments in the KRK domain (section 5.3) and subsequently summarize our findings (section 5.4). Parts of this chapter have been previously published in <ref> [Furnkranz, 1994d] </ref>. 50 5.1. GENERATING A SERIES OF CONCEPT DESCRIPTIONS 51 5.1 Generating a Series of Concept Descrip <p>- tions One advantage of the simple and efficient cutoff stopping criterion described in section 3.2.3 is its close relation to the search heuristic. <p> 88.74 21.43 86.73 26.32 87.42 28.12 89.92 28.89 88.99 29.82 87.74 3.12 88.21 23.89 89.12 29.82 92.20 3.12 88.03 22.43 90.14 29.82 92.20 2.08 91.54 12.81 91.64 Table 7.2: Accuracies in the mesh domain Some of the results reported here differ a little from the ones we have reported previously <ref> [Furnkranz, 1993b, Furnkranz, 1994d, Furnkranz and Widmer, 1994] </ref>, because the previous results are from different phases of our research which used no or different constraints on the search space. <p> Its overall accuracy, however, is very bad. The post-pruning algorithms are very inefficient 2 . Grow is more efficient and more accurate than REP. TDP clearly outperforms REP because it can start post-pruning with simpler and better theories. TDP's pruning time is not as low as in <ref> [Furnkranz, 1994d] </ref>, but still significantly lower than REP's. The time needed for finding the starting theory is also lower than the time needed for overfitting. It might be worthwhile to further speed up TDP by using Grow for the post-pruning phase.
Reference: [Gelfand et al., 1991] <author> S.B. Gelfand, C.S. Ravishankar, and E.J. Delp. </author> <title> An itera-tive growing and pruning algorithm for classification tree design. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 13(2) </volume> <pages> 163-174, </pages> <year> 1991. </year>
Reference-contexts: For simplifying the resulting over-specific theory it is more common, however, to use a different set of examples that were not known in the initial learning phase (e.g. Error Complexity Pruning [Breiman et al., 1984], Iterative Pruning <ref> [Gelfand et al., 1991] </ref> and Critical Value Pruning [Mingers, 1989a]). 4.1.1 The Algorithm The most common among these methods is Reduced Error Pruning (REP) [Quinlan, 1987].
Reference: [Holte et al., 1989] <author> R. Holte, L. Acker, and B. Porter. </author> <title> Concept learning and the problem of small disjuncts. </title> <booktitle> In Proceedings of the 11th International Joint Conference on Artificial Intelligence, </booktitle> <address> Detroit, MI, </address> <year> 1989. </year>
Reference-contexts: Explanations for noisy examples typically are very complicated and will decrease predictive accuracy when used to classify unseen examples. It has been suggested by <ref> [Holte et al., 1989] </ref> that a large proportion of the overall classification error of a theory can be attributed to clauses that cover only a small number of positive examples. This problem is known as the Small 20 3.1.
Reference: [Holte, 1993] <author> Robert C. Holte. </author> <title> Very simple classification rules perform well on most commonly used datasets. </title> <journal> Machine Learning, </journal> <volume> 11 </volume> <pages> 63-91, </pages> <year> 1993. </year> <note> BIBLIOGRAPHY 98 </note>
Reference-contexts: The appendix of <ref> [Holte, 1993] </ref> gives a summary of the results achieved by various algorithms on some of the most commonly used data sets of the UCI repository and a short description of these sets. We selected 9 of them for our 7.3. PROPOSITIONAL DATA SETS 84 experiments. <p> In the Lymphography data set we removed the 6 examples for the classes "normal find" and "fibrosis" in order to get a 2-class problem. All other data were used as described in <ref> [Holte, 1993] </ref>. For all data sets the task was to learn a definition for the minority class. In all datasets the background knowledge consisted of &lt; and = relations with one variable and one constant argument. <p> Run-times for all datasets were measured in CPU seconds for SUN SPARCstations ELC except for the Mushroom and KRKPa7 datasets which are quite big and thus had to be run on a considerably faster SPARCstation S10. All experiments followed the setup used in <ref> [Holte, 1993] </ref>, i.e. the algorithms were trained on 2=3 of the data and tested on the remaining 1=3. However, only 10 runs were performed for each algorithm on each data set. The results can be found in tables 7.4, 7.5, and 7.6. <p> The results of C4.5, a state-of-the-art decision tree learning system with extensive noise-handling capabilities [Quinlan, 1993], are taken from the experiments performed in <ref> [Holte, 1993] </ref> and are meant as an indicator of the performance of state-of-the-art decision tree learning algorithms on these data sets.
Reference: [Kijsirikul et al., 1992] <author> Boonserm Kijsirikul, Masayuki Numao, and Masamichi Shimura. </author> <title> Discrimination-based constructive induction of logic programs. </title> <booktitle> In Proceedings of the 10th National Conference on Artificial Intelligence, </booktitle> <pages> pages 44-49, </pages> <year> 1992. </year>
Reference-contexts: Predicate Invention is an important research direction aiming at introducing new background knowledge in order to gain expressiveness or to make the resulting theory more understandable [Stahl, 1993]. Com- mon methods to invent new predicates include detecting data dependencies [Flach, 1993] or clause completion heuristics <ref> [Kijsirikul et al., 1992] </ref>. Many systems try to invert deductive reasoning and are able to invent new predicates that way.
Reference: [King et al., 1992] <author> R. King, S. Muggleton, R. Lewis, and M. Sternberg. </author> <title> Drug design by Machine Learning: The use of Inductive Logic Programming to model the structure-activity relationships of trimethoprim analogues binding to dihydrofolate reductase. </title> <booktitle> Proceedings of the National Academy of Sciences, </booktitle> <volume> 89(23), </volume> <year> 1992. </year>
Reference: [Knoll et al., 1994] <author> Ulrich Knoll, Gholamreza Nakhaeizadeh, and Birgit Tausend. </author> <title> Cost-sensitive pruning of decision trees. </title> <booktitle> In Proceedings of the European Conference on Machine Learning (ECML-94), </booktitle> <pages> pages 383-386, </pages> <address> Catania, Italy, </address> <year> 1994. </year>
Reference-contexts: In some domains, however, this simple evaluation of the quality of a clause might be undesirable. [Kononenko and Bratko, 1991] discuss some alternatives to an accuracy-based evaluation of classifiers that could easily be adapted for pruning algorithms. Cost- sensitive pruning has recently been tried in <ref> [Knoll et al., 1994] </ref>. The only algorithm faster than I-REP is Fossil with a cutoff of 0.3. The reason for this is simply that Fossil couldn't discover any significant regularities in the data and thus consistently learned empty theories (all literals in the background knowledge had a correlation below 0.3). <p> Methods for including misclassification costs into pruning have already been incorporated into propositional learning systems <ref> [Knoll et al., 1994] </ref>. We also feel that Fossil's ability to generate logic theories of various degrees of generality should be further explored. One possible application might be not to select a single theory, but to use all of them simultaneously for classification.
Reference: [Kononenko and Bratko, 1991] <author> Igor Kononenko and Ivan Bratko. </author> <title> Informationbased evaluation criterion for classifier's performance. </title> <booktitle> Machine Learning, </booktitle> <address> 6:6780, </address> <year> 1991. </year>
Reference-contexts: The reason is that the post- pruning process usually removes a lot of rules that cover a few positive examples, but also an equal or greater number of negative examples. In some domains, however, this simple evaluation of the quality of a clause might be undesirable. <ref> [Kononenko and Bratko, 1991] </ref> discuss some alternatives to an accuracy-based evaluation of classifiers that could easily be adapted for pruning algorithms. Cost- sensitive pruning has recently been tried in [Knoll et al., 1994]. The only algorithm faster than I-REP is Fossil with a cutoff of 0.3. <p> This may cause the percentage of correctly classified positive examples to go down, while the overall accuracy increases. <ref> [Kononenko and Bratko, 1991] </ref> discusses why this can be problematic and give an alternative to an accuracy-based evaluation of classifiers that could easily be adapted for pruning algorithms. Methods for including misclassification costs into pruning have already been incorporated into propositional learning systems [Knoll et al., 1994].
Reference: [Lapointe et al., 1993] <author> Stephane Lapointe, Charles Ling, and Stan Matwin. </author> <title> Constructive Inductive Logic Programming. </title> <editor> In R. Bajcsy, editor, </editor> <booktitle> Proceedings of the 13th International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 10301036, </pages> <address> Chambery, France, 1993. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: To invent recursive predicates, typically all resolution steps involving the recursive predicate should be considered at once, a process that has been called inverting implication <ref> [Muggleton, in press, Lapointe et al., 1993] </ref>. Discovery is a very new branch of ILP which differs from most other approaches in that there is no particular goal concept specified in advance, but the program tries to find interesting regularities by itself.
Reference: [Lavrac and Dzeroski, 1992] <author> Nada Lavrac and Saso Dzeroski. </author> <title> Inductive learning of relations from noisy examples. </title> <editor> In Stephen Muggleton, editor, </editor> <booktitle> Inductive Logic Programming, </booktitle> <pages> pages 495-516. </pages> <publisher> Academic Press Ltd., </publisher> <address> London, </address> <year> 1992. </year>
Reference-contexts: Thus a noise level of in our experiments is roughly equivalent to a noise level of 2 in the results reported in <ref> [Lavrac and Dzeroski, 1992, Dzeroski and Bratko, 1992b] </ref>. Noise was added incrementally, i.e. instances which had a reversed sign at a noise level 1 also had a reversed sign at a noise level 2 &gt; 1 .
Reference: [Lavrac and Dzeroski, 1993] <author> Nada Lavrac and Saso Dzeroski. </author> <title> Inductive Logic Programming: Techniques and Applications. </title> <publisher> Ellis Horwood, </publisher> <year> 1993. </year>
Reference-contexts: Of course, several systems would fit into more than one category. An excellent overview of the history of the field can be found in [Sammut, 1993], a selection of some of the most important papers in [Muggleton, 1992]. <ref> [Lavrac and Dzeroski, 1993] </ref> is an introductory book on Inductive Logic Pro- gramming with a strong focus on relational learning systems, in particular on LINUS [Lavrac et al., 1991] and mFoil [Dzeroski and Bratko, 1992a].
Reference: [Lavrac et al., 1991] <author> Nada Lavrac, Saso Dzeroski, and Marko Grobelnik. </author> <title> Learning nonrecursive definitions of relations with LINUS. </title> <booktitle> In Proceedings of the European Working Session on Learning, Porto, </booktitle> <address> Portugal, </address> <year> 1991. </year>
Reference-contexts: The program typically receives a large collection of positive and negative examples from real-world databases as well as background knowledge in the form of relations. The prototypical example for this research is Foil [Quinlan, 1990] and its various successors, but there are several other approaches like LINUS <ref> [Lavrac et al., 1991] </ref> and Golem [Muggleton and Feng, 1990]. Theory Revision systems are not so much concerned with the induction of a useful theory, but with the maintenance of a complete and consistent theory. <p> overview of the history of the field can be found in [Sammut, 1993], a selection of some of the most important papers in [Muggleton, 1992]. [Lavrac and Dzeroski, 1993] is an introductory book on Inductive Logic Pro- gramming with a strong focus on relational learning systems, in particular on LINUS <ref> [Lavrac et al., 1991] </ref> and mFoil [Dzeroski and Bratko, 1992a]. Other introductory texts include [De Raedt and Lavrac, 1993], [Muggleton, 1993], and [Muggleton and De Raedt, 1994]. 2.1 Relational Learning The main concern of this thesis will be Relational Learning or Empirical Inductive Logic Programming. <p> A generic framework for bottom-up induction can be found in [Rouveirol et al., 1993]. Representation Change: The systems of this class approach the problem by reformulating it in a language that conventional Machine Learning systems can use. Prototypical for this approach is the LINUS system <ref> [Lavrac et al., 1991] </ref> that transforms the relational learning problem into an attribute-value representation that can be used by propositional learning algorithms like CN2 [Clark and Niblett, 1989] and ASSISTANT [Cestnik et al., 1987]. All three approaches impose different restrictions on the class of programs they can learn.
Reference: [Lavrac et al., 1992a] <author> Nada Lavrac, Bojan Cestnik, and Saso Dzeroski. </author> <title> Search heuristics in empirical Inductive Logic Programming. In Logical Approaches to Machine Learning, </title> <booktitle> Workshop Notes of the 10th European Conference on AI, </booktitle> <address> Vienna, Austria, </address> <year> 1992. </year>
Reference-contexts: There are several search heuristics known from decision tree learning, most of them perform similarly (see e.g. [Mingers, 1989b, Buntine and Niblett, 1992]). [Lavrac et al., 1992b] and <ref> [Lavrac et al., 1992a] </ref> list a selection of several search heuristics for Foil- like empirical ILP system (see figure 2.4). 2.2.
Reference: [Lavrac et al., 1992b] <author> Nada Lavrac, Bojan Cestnik, and Saso Dzeroski. </author> <title> Use of heuristics in empirical Inductive Logic Programming. </title> <editor> In S.H. Muggleton, ed-itor, </editor> <booktitle> Proceedings of the International Workshop on Inductive Logic Programming, </booktitle> <address> Tokyo, Japan, </address> <year> 1992. </year> <note> BIBLIOGRAPHY 99 </note>
Reference-contexts: There are several search heuristics known from decision tree learning, most of them perform similarly (see e.g. [Mingers, 1989b, Buntine and Niblett, 1992]). <ref> [Lavrac et al., 1992b] </ref> and [Lavrac et al., 1992a] list a selection of several search heuristics for Foil- like empirical ILP system (see figure 2.4). 2.2.
Reference: [Lavrac et al., 1993] <author> Nada Lavrac, Saso Dzeroski, Vladimir Pirnat, and Viljem Krizman. </author> <title> The utility of background knowledge in learning medical diagnostic rules. </title> <journal> Applied Artificial Intelligence, </journal> <volume> 7 </volume> <pages> 273-293, </pages> <year> 1993. </year>
Reference-contexts: Relational Learning systems are designed for this purpose and have already been applied to various real-world problems, like finite-element mesh design [Dolsak and Muggleton, 1992, Dzeroski and Bratko, 1992a], medical diagnosis <ref> [Lavrac et al., 1993, Petta, 1994] </ref>, chess endgames [Morales, 1992, Muggleton et al., 1989, Quinlan, 1990, Dzeroski and Bratko, 1992a], natural language understanding [Zelle and Mooney, 1993], document recognition [Esposito et al., 1993b] etc.
Reference: [Matheus et al., 1993] <author> Christopher J. Matheus, Philip K. Chan, and Gregory Piatetsky-Shapiro. </author> <title> Systems for knowledge discovery in databases. </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <volume> 5(6) </volume> <pages> 903-913, </pages> <month> December </month> <year> 1993. </year>
Reference-contexts: Learning systems of this category typically are designed to learn classification rules from real-world databases. Main characteristics of real-world databases are that they are large and unreliable. Algo- rithms designed to work on them must therefore be efficient and noise-tolerant <ref> [Matheus et al., 1993] </ref>. 2.1.
Reference: [Michalski et al., 1986] <author> R. S. Michalski, I. Mozetic, J. Hong, and N. Lavrac. </author> <title> The multi-purpose incremental learning system AQ15 and its testing application to three medical domains. </title> <booktitle> In Proceedings of the 5th National Conference on Artificial Intelligence, </booktitle> <pages> pages 1041-1045, </pages> <address> Philadelphia, PA, </address> <year> 1986. </year>
Reference-contexts: One relational learning algorithm, LINUS, tries to automate this process (see page 10). Like the decision tree algorithms, other classic propositional learning algorithms (including CN2 [Clark and Niblett, 1989], AQ <ref> [Michalski, 1980, Michalski et al., 1986] </ref>, and others) are also limited to concept descriptions in propositional calculus. <p> Most of them learn from an attribute-value representation of the input data and their representational power thus is restricted to decision trees as in the ID3 family [Quinlan, 1983] or propositional Horn clauses as in AQ <ref> [Michalski et al., 1986] </ref> or CN2 [Clark and Niblett, 1989]. ILP algorithms, on the other hand, can not only test attributes for specific values, but also make use of relations (like equality) between the different attributes. Inductive Logic Programming has quickly developed to a very active research field. <p> It has its roots in the early days of Machine Learning in the covering algorithm of the famous AQ family <ref> [Michalski, 1980, Michalski et al., 1986] </ref>. CN2 [Clark and Niblett, 1989, Clark and Boswell, 1991] eliminated AQ's dependence on an initial seed example and employed the separate-and-conquer strategy for the first time. The term separate-and-conquer has been coined by [Pagallo and Haussler, 1990] in the context of learning decision lists.
Reference: [Michalski, 1980] <author> Ryszard S. Michalski. </author> <title> Pattern recognition and rule-guided in-ference. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 2 </volume> <pages> 349-361, </pages> <year> 1980. </year>
Reference-contexts: One relational learning algorithm, LINUS, tries to automate this process (see page 10). Like the decision tree algorithms, other classic propositional learning algorithms (including CN2 [Clark and Niblett, 1989], AQ <ref> [Michalski, 1980, Michalski et al., 1986] </ref>, and others) are also limited to concept descriptions in propositional calculus. <p> It has its roots in the early days of Machine Learning in the covering algorithm of the famous AQ family <ref> [Michalski, 1980, Michalski et al., 1986] </ref>. CN2 [Clark and Niblett, 1989, Clark and Boswell, 1991] eliminated AQ's dependence on an initial seed example and employed the separate-and-conquer strategy for the first time. The term separate-and-conquer has been coined by [Pagallo and Haussler, 1990] in the context of learning decision lists.
Reference: [Mingers, 1989a] <author> John Mingers. </author> <title> An empirical comparison of pruning methods for decision tree induction. </title> <journal> Machine Learning, </journal> <volume> 4 </volume> <pages> 227-243, </pages> <year> 1989. </year>
Reference-contexts: Typically this results in a very complex theory that is hard to understand and is not very predictive on unseen examples. 8 Pruning is a standard way of dealing with noise in concept learning (see e.g. <ref> [Mingers, 1989a] </ref> or [Esposito et al., 1993a]). We can distinguish two fundamentally different approaches [Cestnik et al., 1987]: Pre-Pruning means that during concept generation some training examples are deliberately ignored, so that the final concept description does not classify all training instances correctly. <p> Post-pruning approaches have been commonly used in the decision tree learning algorithms CART [Breiman et al., 1984], ID3 [Quinlan, 1987] and ASSIS- TANT [Niblett and Bratko, 1986]. An overview and comparison of various approaches can be found in <ref> [Mingers, 1989a] </ref> and [Esposito et al., 1993a]. This chapter will first review how Reduced Error Pruning [Quinlan, 1987] can be adapted for a rule learning algorithm (section 4.1). <p> For simplifying the resulting over-specific theory it is more common, however, to use a different set of examples that were not known in the initial learning phase (e.g. Error Complexity Pruning [Breiman et al., 1984], Iterative Pruning [Gelfand et al., 1991] and Critical Value Pruning <ref> [Mingers, 1989a] </ref>). 4.1.1 The Algorithm The most common among these methods is Reduced Error Pruning (REP) [Quinlan, 1987]. <p> However, there is some evidence that algorithms using a separate pruning set perform better than those that have to estimate the amount of over- fitting exclusively from the training data <ref> [Mingers, 1989a] </ref>. 4.2.3 Separate-and-Conquer Strategy In decision tree learning usually a divide-and-conquer strategy is used. This means that the training set is split into disjoint sets according to the outcome of the test chosen for the top level decision. <p> Research in decision tree learning has developed several methods for automating this selection <ref> [Breiman et al., 1984, Mingers, 1989a, Weiss and Indurkhya, 1994] </ref>. Most of these methods can be easily adapted for rule learning algorithms, once we have series of theories with different degrees of generality.
Reference: [Mingers, 1989b] <author> John Mingers. </author> <title> An empirical comparison of selection measures for decision-tree induction. </title> <journal> Machine Learning, </journal> <volume> 3 </volume> <pages> 319-342, </pages> <year> 1989. </year>
Reference-contexts: There are several search heuristics known from decision tree learning, most of them perform similarly (see e.g. <ref> [Mingers, 1989b, Buntine and Niblett, 1992] </ref>). [Lavrac et al., 1992b] and [Lavrac et al., 1992a] list a selection of several search heuristics for Foil- like empirical ILP system (see figure 2.4). 2.2.
Reference: [Mittenecker, 1977] <editor> Erich Mittenecker. Planung und statistische Auswertung von Experimenten. Verlag Franz Deuticke, </editor> <address> Vienna, Austria, </address> <note> 8th edition, 1977. In German. </note>
Reference-contexts: Most differences in accuracies are not statistically significant. 3 Significant differences can be found in the KRKPa7 chess endgame domain, where TDP and 3 We have used a range test which can be used to quickly determine significant differences between medium values for small (N &lt; 20) sample sizes <ref> [Mittenecker, 1977] </ref>. For N = 10 the 7.3. PROPOSITIONAL DATA SETS 85 Breast Cancer Accuracy Stnd. Dev.
Reference: [Morales, 1992] <author> E. Morales. </author> <title> Learning chess patterns. </title> <editor> In Stephen Muggleton, editor, </editor> <booktitle> Inductive Logic Programming, </booktitle> <pages> pages 517-538. </pages> <publisher> Academic Press Ltd., </publisher> <address> London, </address> <year> 1992. </year>
Reference: [Muggleton and Buntine, 1988] <author> Stephen H. Muggleton and Wray L. Buntine. </author> <title> Machine invention of first-order predicates by inverting resolution. </title> <booktitle> In Proceedings of the 5th International Conference on Machine Learning, </booktitle> <pages> pages 339-352, </pages> <year> 1988. </year>
Reference-contexts: Com- mon methods to invent new predicates include detecting data dependencies [Flach, 1993] or clause completion heuristics [Kijsirikul et al., 1992]. Many systems try to invert deductive reasoning and are able to invent new predicates that way. Some invert one step of a resolution proof <ref> [Muggleton and Buntine, 1988, Wrobel, 1989, Rouveirol and Puget, 1990] </ref>, i.e. they are basically given a consequent and preconditions and try to guess a rule that can prove the consequent from the preconditions. <p> We will discuss this approach in more detail in section 2.2. Bottom-Up Induction: As opposed to top-down induction, the bottom-up approaches search for a complete and consistent theory by iterative generalization of clauses. The most common generalization operators are based on inverse resolution as in CIGOL <ref> [Muggleton and Buntine, 1988] </ref> or on relative least general generalization [Plotkin, 1971] as in Golem [Muggleton and Feng, 1990]. A generic framework for bottom-up induction can be found in [Rouveirol et al., 1993].
Reference: [Muggleton and De Raedt, 1994] <author> Stephen Muggleton and Luc De Raedt. </author> <title> Inductive Logic Programming: Theory and methods. </title> <journal> Journal of Logic Programming, </journal> <volume> 19,20:629-679, </volume> <year> 1994. </year>
Reference-contexts: Other introductory texts include [De Raedt and Lavrac, 1993], [Muggleton, 1993], and <ref> [Muggleton and De Raedt, 1994] </ref>. 2.1 Relational Learning The main concern of this thesis will be Relational Learning or Empirical Inductive Logic Programming. Learning systems of this category typically are designed to learn classification rules from real-world databases. Main characteristics of real-world databases are that they are large and unreliable.
Reference: [Muggleton and Feng, 1990] <author> Stephen H. Muggleton and Cao Feng. </author> <title> Efficient in-duction of logic programs. </title> <booktitle> In Proceedings of the 1st Conference on Algorithmic Learning Theory, </booktitle> <pages> pages 1-14, </pages> <address> Tokyo, Japan, </address> <year> 1990. </year> <note> BIBLIOGRAPHY 100 </note>
Reference-contexts: The prototypical example for this research is Foil [Quinlan, 1990] and its various successors, but there are several other approaches like LINUS [Lavrac et al., 1991] and Golem <ref> [Muggleton and Feng, 1990] </ref>. Theory Revision systems are not so much concerned with the induction of a useful theory, but with the maintenance of a complete and consistent theory. <p> The most common generalization operators are based on inverse resolution as in CIGOL [Muggleton and Buntine, 1988] or on relative least general generalization [Plotkin, 1971] as in Golem <ref> [Muggleton and Feng, 1990] </ref>. A generic framework for bottom-up induction can be found in [Rouveirol et al., 1993]. Representation Change: The systems of this class approach the problem by reformulating it in a language that conventional Machine Learning systems can use. <p> Another reason for the bad performance of ILP algorithms on this problem is that many of them (including our implementations) are not really able to make use of the provided topological relations, because of the problems discussed in section 2.3.1. For algorithms like Golem <ref> [Muggleton and Feng, 1990] </ref> and Foil [Quinlan and Cameron-Jones, 1993] the topological relations have been made determinate, i.e. it has been enforced that each topological relation has at most one output value for each set of input values. [Dzeroski and Bratko, 1992a] report experiments that forced mFoil to use one of
Reference: [Muggleton et al., 1989] <author> Stephen Muggleton, Michael Bain, Jean Hayes-Michie, and Donald Michie. </author> <title> An experimental comparison of human and machine learn-ing formalisms. </title> <booktitle> In Proceedings of the 6th International Workshop on Machine Learning, </booktitle> <pages> pages 113-118, </pages> <year> 1989. </year>
Reference-contexts: Parts of this chapter have previously been presented in [Furnkranz, 1994a] and [Furnkranz, 1994c]. 7.1 Summary of the Experiments in the KRK Domain We have tested several algorithms in the domain of recognizing illegal chess positions in the KRK chess endgame <ref> [Muggleton et al., 1989] </ref>. This domain has become a standard benchmark problem for relational learning systems, because it cannot be solved in a trivial way by propositional learning algorithms. A detailed description of this domain can be found in appendix A.
Reference: [Muggleton et al., 1992] <author> S. Muggleton, R. King, and M. Sternberg. </author> <title> Protein sec-ondary structure prediction using logic-based Machine Learning. </title> <journal> Protein Engineering, </journal> <volume> 5(7) </volume> <pages> 647-657, </pages> <year> 1992. </year>
Reference: [Muggleton, 1988] <author> Stephen H. Muggleton. </author> <title> A strategy for constructing new predi-cates in first order logic. </title> <booktitle> In Proceedings of the Third European Working Session on Learning, </booktitle> <pages> pages 123-130, </pages> <year> 1988. </year>
Reference-contexts: RELATIONAL LEARNING 7 out to be correct. Typical revision systems are MIS [Shapiro, 1982], CIGOL <ref> [Muggleton, 1988] </ref>, CLINT [De Raedt, 1992], KRT (MOBAL) [Wrobel, 1994], Forte [Richards, 1992] and AUDREY [Wogulis, 1991]. Predicate Invention is an important research direction aiming at introducing new background knowledge in order to gain expressiveness or to make the resulting theory more understandable [Stahl, 1993].
Reference: [Muggleton, 1992] <author> Stephen Muggleton, </author> <title> editor. Inductive Logic Programming. </title> <publisher> Academic Press Ltd., </publisher> <address> London, </address> <year> 1992. </year>
Reference-contexts: Of course, several systems would fit into more than one category. An excellent overview of the history of the field can be found in [Sammut, 1993], a selection of some of the most important papers in <ref> [Muggleton, 1992] </ref>. [Lavrac and Dzeroski, 1993] is an introductory book on Inductive Logic Pro- gramming with a strong focus on relational learning systems, in particular on LINUS [Lavrac et al., 1991] and mFoil [Dzeroski and Bratko, 1992a].
Reference: [Muggleton, 1993] <author> Stephen H. Muggleton. </author> <title> Inductive Logic Programming: Derivations, </title> <editor> successes and shortcomings. In Pavel B. Brazdil, editor, </editor> <booktitle> Machine Learning: ECML-93, number 667 in Lecture Notes in Artificial Intelligence, </booktitle> <pages> pages 21-37, </pages> <address> Vienna, Austria, 1993. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: Other introductory texts include [De Raedt and Lavrac, 1993], <ref> [Muggleton, 1993] </ref>, and [Muggleton and De Raedt, 1994]. 2.1 Relational Learning The main concern of this thesis will be Relational Learning or Empirical Inductive Logic Programming. Learning systems of this category typically are designed to learn classification rules from real-world databases.
Reference: [Muggleton, in press] <author> Stephen Muggleton. </author> <title> Inverting implication. </title> <journal> Artificial Intelligence, </journal> <note> in press. </note>
Reference-contexts: To invent recursive predicates, typically all resolution steps involving the recursive predicate should be considered at once, a process that has been called inverting implication <ref> [Muggleton, in press, Lapointe et al., 1993] </ref>. Discovery is a very new branch of ILP which differs from most other approaches in that there is no particular goal concept specified in advance, but the program tries to find interesting regularities by itself.
Reference: [Murphy and Pazzani, 1994] <author> Patrick M. Murphy and Michael J. Pazzani. </author> <title> Exploring the decision forest: An empirical investigation of Occam's Razor in decision tree induction. </title> <journal> Journal of Artificial Intelligence Research, </journal> <volume> 1 </volume> <pages> 257-275, </pages> <year> 1994. </year>
Reference-contexts: Using the terminology of [Schaffer, 1993, Wolpert, 1993], I-REP has a strong Overfitting Avoidance Bias, which can be detrimental in some domains (see <ref> [Murphy and Pazzani, 1994] </ref> for experiments along related lines). 6.2 An Example it has learned from are the same 250 examples that have been used to generate the overly specific theory from figure 4.2.
Reference: [Niblett and Bratko, 1986] <author> Tim Niblett and Ivan Bratko. </author> <title> Learning decision rules in noisy domains. </title> <booktitle> In Proceedings of Expert Systems 86. </booktitle> <publisher> Cambridge University Press, </publisher> <year> 1986. </year>
Reference-contexts: The result is subsequently analyzed and (if necessary) simplified and generalized in order to increase its predictive accuracy on unseen data. Post-pruning approaches have been commonly used in the decision tree learning algorithms CART [Breiman et al., 1984], ID3 [Quinlan, 1987] and ASSIS- TANT <ref> [Niblett and Bratko, 1986] </ref>. An overview and comparison of various approaches can be found in [Mingers, 1989a] and [Esposito et al., 1993a]. This chapter will first review how Reduced Error Pruning [Quinlan, 1987] can be adapted for a rule learning algorithm (section 4.1). <p> Generate an overly specific concept description 2. Generalize it to an appropriate level While phase 1. basically is identical for all algorithms, there are two principal methods for phase 2. Several algorithms (like Minimal Error Pruning <ref> [Niblett and Bratko, 1986] </ref> or Pessimistic Error Pruning [Quinlan, 1987]) analyze the performance of decision trees on the same data set from which they have 38 4.1.
Reference: [Oliver and Hand, 1994] <author> Jonathan J. Oliver and David Hand. </author> <title> Averaging over de-cision stumps. </title> <booktitle> In Proceedings of the European Conference on Machine Learning (ECML-94), </booktitle> <pages> pages 231-241, </pages> <address> Catania, Italy, </address> <year> 1994. </year>
Reference-contexts: One possible application might be not to select a single theory, but to use all of them simultaneously for classification. This approach | averaging | has already been tried on propositional learning systems and has yielded encouraging results (see e.g. <ref> [Oliver and Hand, 1994] </ref>). During the writing of this thesis the implementation of the learning systems has been continuously improved.
Reference: [Pagallo and Haussler, 1990] <author> Giulia Pagallo and David Haussler. </author> <title> Boolean feature discovery in empirical learning. </title> <journal> Machine Learning, </journal> <volume> 5 </volume> <pages> 71-99, </pages> <year> 1990. </year>
Reference-contexts: CN2 [Clark and Niblett, 1989, Clark and Boswell, 1991] eliminated AQ's dependence on an initial seed example and employed the separate-and-conquer strategy for the first time. The term separate-and-conquer has been coined by <ref> [Pagallo and Haussler, 1990] </ref> in the context of learning decision lists. Finally, it was first used in the Foil algorithm for efficiently inducing logic programs [Quinlan, 1990], which pioneered significant research in the field of relational learning. Although the work reported here will be mainly presented 2.2. <p> Error Complexity Pruning [Breiman et al., 1984], Iterative Pruning [Gelfand et al., 1991] and Critical Value Pruning [Mingers, 1989a]). 4.1.1 The Algorithm The most common among these methods is Reduced Error Pruning (REP) [Quinlan, 1987]. This simple algorithm has been adapted for a propositional rule learning framework by <ref> [Pagallo and Haussler, 1990] </ref> and subsequently been introduced to noise handling in Inductive Logic Programming by [Brunk and Pazzani, 1991]. At the beginning the training data are split into two subsets: a growing set (usually 2/3) and a pruning set (1/3). <p> Cohen has then proposed Grow, a post-pruning algorithm based on a technique used in <ref> [Pagallo and Haussler, 1990] </ref>. Like REP, the Grow algorithm first finds a theory that overfits the data.
Reference: [Petta, 1994] <author> Paolo Petta. </author> <title> The value of background knowledge for ILP: A case study in the interpretation of TI-201 myocardial SPECT polar maps. </title> <type> Technical Report OEFAI-TR-94-15, </type> <institution> Austrian Research Institute for Artificial Intelligence, </institution> <year> 1994. </year>
Reference-contexts: Relational Learning systems are designed for this purpose and have already been applied to various real-world problems, like finite-element mesh design [Dolsak and Muggleton, 1992, Dzeroski and Bratko, 1992a], medical diagnosis <ref> [Lavrac et al., 1993, Petta, 1994] </ref>, chess endgames [Morales, 1992, Muggleton et al., 1989, Quinlan, 1990, Dzeroski and Bratko, 1992a], natural language understanding [Zelle and Mooney, 1993], document recognition [Esposito et al., 1993b] etc.
Reference: [Plotkin, 1971] <author> G. D. Plotkin. </author> <title> Automatic methods of inductive inference. </title> <type> PhD thesis, </type> <institution> University of Edinburgh, </institution> <address> Scotland, </address> <year> 1971. </year> <note> BIBLIOGRAPHY 101 </note>
Reference-contexts: Bottom-Up Induction: As opposed to top-down induction, the bottom-up approaches search for a complete and consistent theory by iterative generalization of clauses. The most common generalization operators are based on inverse resolution as in CIGOL [Muggleton and Buntine, 1988] or on relative least general generalization <ref> [Plotkin, 1971] </ref> as in Golem [Muggleton and Feng, 1990]. A generic framework for bottom-up induction can be found in [Rouveirol et al., 1993]. Representation Change: The systems of this class approach the problem by reformulating it in a language that conventional Machine Learning systems can use.
Reference: [Quinlan and Cameron-Jones, 1993] <author> John Ross Quinlan and R. M. CameronJones. </author> <title> FOIL: A midterm report. </title> <booktitle> In Proceedings of the European Conference on Machine Learning, </booktitle> <pages> pages 3-20, </pages> <address> Vienna, Austria, </address> <year> 1993. </year>
Reference-contexts: In particular it is able to save backup points and restart the search at these whenever the greedy search leads to poor definitions. It also relearns entire clauses in some cases. A detailed description of these improvements can be found in <ref> [Quinlan and Cameron-Jones, 1993] </ref>. 3.3. <p> All reported results were averaged over 10 runs, except for the training set size 1000, where only 6 runs were performed, because of the complexity of this task for some algorithms. The tested algorithms were * the pre-pruning systems Foil 6.1 <ref> [Quinlan and Cameron-Jones, 1993] </ref> and Fossil with a cutoff of 0.3 (section 3.2), * the post-pruning systems REP (section 4.1) and Grow (section 4.3), * the combined system TDP (section 5.2), * and the integrated system I-REP (section 6.1). <p> For algorithms like Golem [Muggleton and Feng, 1990] and Foil <ref> [Quinlan and Cameron-Jones, 1993] </ref> the topological relations have been made determinate, i.e. it has been enforced that each topological relation has at most one output value for each set of input values. [Dzeroski and Bratko, 1992a] report experiments that forced mFoil to use one of the topological relations at the beginning
Reference: [Quinlan, 1983] <author> John Ross Quinlan. </author> <title> Learning efficient classification procedures and their application to chess end games. </title> <editor> In Ryszard S. Michalski, Jaime G. Carbonell, and Tom M. Mitchell, editors, </editor> <booktitle> Machine Learning. An Artificial Intelligence Approach, </booktitle> <pages> pages 463-482. </pages> <publisher> Tioga Publishing Co., </publisher> <year> 1983. </year>
Reference-contexts: The most prominent family of algorithms that attack these problems is based on the success of ID3 <ref> [Quinlan, 1983] </ref>. All algorithms of this family construct a concept description in the form of a decision tree (see figure 1.1). <p> Most of them learn from an attribute-value representation of the input data and their representational power thus is restricted to decision trees as in the ID3 family <ref> [Quinlan, 1983] </ref> or propositional Horn clauses as in AQ [Michalski et al., 1986] or CN2 [Clark and Niblett, 1989]. ILP algorithms, on the other hand, can not only test attributes for specific values, but also make use of relations (like equality) between the different attributes.
Reference: [Quinlan, 1986] <author> John Ross Quinlan. </author> <title> The effect of noise on concept learning. </title> <editor> In Ryszard S. Michalski, Jaime G. Carbonell, and Tom M. Mitchell, editors, </editor> <booktitle> Machine Learning: An Artificial Intelligence Approach, </booktitle> <volume> volume II, </volume> <pages> pages 149166. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1986. </year>
Reference-contexts: We can distinguish two fundamentally different approaches [Cestnik et al., 1987]: Pre-Pruning means that during concept generation some training examples are deliberately ignored, so that the final concept description does not classify all training instances correctly. In decision tree learning these pre-pruning approaches include ID3 <ref> [Quinlan, 1986] </ref> or ASSISTANT [Bratko and Kononenko, 1986]. Post-Pruning means that first a complete and consistent concept description is generated from a proportion of the training data. The resulting concept is then analyzed with the remaining, unseen examples and, if necessary, is generalized to improve the accuracy on these examples.
Reference: [Quinlan, 1987] <author> John Ross Quinlan. </author> <title> Simplifying decision trees. </title> <journal> International Journal of Man-Machine Studies, </journal> <volume> 27 </volume> <pages> 221-234, </pages> <year> 1987. </year>
Reference-contexts: The resulting concept is then analyzed with the remaining, unseen examples and, if necessary, is generalized to improve the accuracy on these examples. In decision tree learning post-pruning approaches have e.g. been used in Reduced Er- ror Pruning <ref> [Quinlan, 1987] </ref>, CART [Breiman et al., 1984] or ASSISTANT [Cestnik et al., 1987]. The main concern of the research reported in this thesis will be efficient pruning methods for rule learning algorithms. <p> The result is subsequently analyzed and (if necessary) simplified and generalized in order to increase its predictive accuracy on unseen data. Post-pruning approaches have been commonly used in the decision tree learning algorithms CART [Breiman et al., 1984], ID3 <ref> [Quinlan, 1987] </ref> and ASSIS- TANT [Niblett and Bratko, 1986]. An overview and comparison of various approaches can be found in [Mingers, 1989a] and [Esposito et al., 1993a]. This chapter will first review how Reduced Error Pruning [Quinlan, 1987] can be adapted for a rule learning algorithm (section 4.1). <p> commonly used in the decision tree learning algorithms CART [Breiman et al., 1984], ID3 <ref> [Quinlan, 1987] </ref> and ASSIS- TANT [Niblett and Bratko, 1986]. An overview and comparison of various approaches can be found in [Mingers, 1989a] and [Esposito et al., 1993a]. This chapter will first review how Reduced Error Pruning [Quinlan, 1987] can be adapted for a rule learning algorithm (section 4.1). We will then outline several problems with this simple method (section 4.2) and present an improved algorithm known from the literature (section 4.3) that solves some of them. <p> Generate an overly specific concept description 2. Generalize it to an appropriate level While phase 1. basically is identical for all algorithms, there are two principal methods for phase 2. Several algorithms (like Minimal Error Pruning [Niblett and Bratko, 1986] or Pessimistic Error Pruning <ref> [Quinlan, 1987] </ref>) analyze the performance of decision trees on the same data set from which they have 38 4.1. <p> Error Complexity Pruning [Breiman et al., 1984], Iterative Pruning [Gelfand et al., 1991] and Critical Value Pruning [Mingers, 1989a]). 4.1.1 The Algorithm The most common among these methods is Reduced Error Pruning (REP) <ref> [Quinlan, 1987] </ref>. This simple algorithm has been adapted for a propositional rule learning framework by [Pagallo and Haussler, 1990] and subsequently been introduced to noise handling in Inductive Logic Programming by [Brunk and Pazzani, 1991].
Reference: [Quinlan, 1990] <author> John Ross Quinlan. </author> <title> Learning logical definitions from relations. </title> <journal> Machine Learning, </journal> <volume> 5 </volume> <pages> 239-266, </pages> <year> 1990. </year>
Reference-contexts: Chapter 2 will give a short introduction into the new research area called Inductive Logic Programming (ILP) and will introduce a prototypical First Order Inductive Learner | Foil <ref> [Quinlan, 1990] </ref>. In the following two chapters 3 and 4 we will review well-known methods for noise handling in this relational learning system. <p> Relational learning algorithms learn classification rules for a concept. The program typically receives a large collection of positive and negative examples from real-world databases as well as background knowledge in the form of relations. The prototypical example for this research is Foil <ref> [Quinlan, 1990] </ref> and its various successors, but there are several other approaches like LINUS [Lavrac et al., 1991] and Golem [Muggleton and Feng, 1990]. Theory Revision systems are not so much concerned with the induction of a useful theory, but with the maintenance of a complete and consistent theory. <p> SEPARATE-AND-CONQUER RULE LEARNING ALGORITHMS 10 Top-Down Induction: This method is most common and will be our main concern in this research. It tries to find a complete and consistent theory by iterative specialization of the most general (empty) theory. The prototype system of this approach is Foil <ref> [Quinlan, 1990] </ref>. We will discuss this approach in more detail in section 2.2. Bottom-Up Induction: As opposed to top-down induction, the bottom-up approaches search for a complete and consistent theory by iterative generalization of clauses. <p> The term separate-and-conquer has been coined by [Pagallo and Haussler, 1990] in the context of learning decision lists. Finally, it was first used in the Foil algorithm for efficiently inducing logic programs <ref> [Quinlan, 1990] </ref>, which pioneered significant research in the field of relational learning. Although the work reported here will be mainly presented 2.2. <p> Otherwise the clause is rejected and no further clauses will be learned. Most Foil-like algorithms employ stopping criteria for noise handling. The most commonly used among them are * Encoding Length Restriction: This heuristic used in Foil itself 3.2. FOSSIL 22 <ref> [Quinlan, 1990] </ref> is based on the Minimum Description Length principle [Rissanen, 1978].
Reference: [Quinlan, 1991] <author> John Ross Quinlan. </author> <title> Determinate literals in Inductive Logic Programming. </title> <booktitle> In Proceedings of the 8th International Workshop on Machine Learning, </booktitle> <pages> pages 442-446, </pages> <year> 1991. </year>
Reference-contexts: Adding the literal child (A,C) to the body of the clause would therefore not exclude any negative examples and the heuristic value of adding the literal to the body of the clause would be very low for all of the greedy heuristics listed in figure 2.4. In <ref> [Quinlan, 1991] </ref> a solution is proposed that works for a powerful subclass of the problematic cases, the so-called determinate literals. Whenever no literals with a heuristic gain above a certain threshold can be found, Foil tries to improve the situation by adding determinate literals and thus introducing new variables. <p> Irrelevant literals could be removed later in a post-processing phase. Values between 0 and 1 result in a behavior similar to that described in <ref> [Quinlan, 1991] </ref>: until a literal with a correlation above a preset value is found, these problematic literals will be added to the clause body in the hope that the new variables they introduce will improve the situation.
Reference: [Quinlan, 1993] <author> John Ross Quinlan. C4.5: </author> <title> Programs for Machine Learning. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1993. </year>
Reference-contexts: This is repeated until one arrives at a leaf of the tree, in which case its classification label is returned. The most prominent representa 1.2. THE NEED FOR RELATIONS IN LEARNING 3 dangerous (Head,Body,Smiling,Holding,Jacket,Tie) :- red (Jacket). dangerous (Head,Body,Smiling,Holding,Jacket,Tie) :- Head = Body. tives of this family are C4.5 <ref> [Quinlan, 1993] </ref>, Assistant [Cestnik et al., 1987] and CART [Breiman et al., 1984]. [Furnkranz, 1991] contains a summary of some basic methods for inducing decision trees from attribute-value data sets. 1.2 The Need for Relations in Learning In [Thrun et al., 1991] three problems are proposed in the robots domain. <p> Research in propositional learning algorithms has already developed a variety of methods for noise handling. Noise-tolerant decision tree learning algorithms like CART [Breiman et al., 1984], C4.5 <ref> [Quinlan, 1993] </ref>, ASSISTANT [Bratko and Kononenko, 1986], CN2 [Clark and Boswell, 1991] are well-known and often applied to real-world problems. <p> Each line shows the average accuracy on the 10 sets, its standard deviation and range (difference between the maximum and the minimum accuracy encountered), and the run- time of the algorithm. The results of C4.5, a state-of-the-art decision tree learning system with extensive noise-handling capabilities <ref> [Quinlan, 1993] </ref>, are taken from the experiments performed in [Holte, 1993] and are meant as an indicator of the performance of state-of-the-art decision tree learning algorithms on these data sets. <p> Then the program orders the clauses of the resulting theories according to some heuristic in order to avoid conflicts caused by overlapping rules. A closer evaluation of the approach and a comparison to other approaches (e.g. the MDL based method used in C4.5 for generating rules from decision trees <ref> [Quinlan, 1993] </ref>) still has to be performed. Two other improvements that have been on the agenda since the first days of this project are to incorporate a simple beam search into Fossil and to elaborate the ideas for avoiding the problem with the introduction of new variables.
Reference: [Quinlan, 1994] <author> John Ross Quinlan. </author> <title> The minimum description length principle and categorical theories. </title> <booktitle> In Proceeding of the 11th International Conference on Machine Learning, </booktitle> <pages> pages 233-241, </pages> <address> New Brunswick, NJ, </address> <year> 1994. </year>
Reference-contexts: The basic problem during manual mesh design is the selection of the correct number of finite elements on the edges of the structure. Several authors have tried ILP methods on this problem <ref> [Dolsak and Muggleton, 1992, Dzeroski and Bratko, 1992a, Quinlan, 1994] </ref>.The available background knowledge consists of an attribute-based description of the edges and of topological relations between the edges. <p> Several authors have tried ILP methods on this problem [Dolsak and Muggleton, 1992, Dzeroski and Bratko, 1992a, Quinlan, 1994].The available background knowledge consists of an attribute-based description of the edges and of topological relations between the edges. The setup of our experiments was the same as in <ref> [Quinlan, 1994] </ref>, i.e. we learned rules from four of the five objects (A - E) in the data set and tested the learned concept on the fifth object. The learned theories were tested as in [Quinlan, 1994], which is a little different from the setup used in [Dzeroski and Bratko, 1992a]: <p> The setup of our experiments was the same as in <ref> [Quinlan, 1994] </ref>, i.e. we learned rules from four of the five objects (A - E) in the data set and tested the learned concept on the fifth object. The learned theories were tested as in [Quinlan, 1994], which is a little different from the setup used in [Dzeroski and Bratko, 1992a]: Instead of actually predicting a value for the number of finite elements on an edge, we merely checked for all possible values whether this value could be derived from the learned rules or not.
Reference: [Richards, 1992] <author> Bradley L. Richards. </author> <title> An Operator-Based Approach to FirstOrder Theory Revision. </title> <type> PhD thesis, </type> <institution> Department of Computer Sciences, University of Texas, Austin, TX, </institution> <year> 1992. </year>
Reference-contexts: RELATIONAL LEARNING 7 out to be correct. Typical revision systems are MIS [Shapiro, 1982], CIGOL [Muggleton, 1988], CLINT [De Raedt, 1992], KRT (MOBAL) [Wrobel, 1994], Forte <ref> [Richards, 1992] </ref> and AUDREY [Wogulis, 1991]. Predicate Invention is an important research direction aiming at introducing new background knowledge in order to gain expressiveness or to make the resulting theory more understandable [Stahl, 1993].
Reference: [Rissanen, 1978] <author> J. Rissanen. </author> <title> Modeling by shortest data description. </title> <journal> Automatica, </journal> <volume> 14 </volume> <pages> 465-471, </pages> <year> 1978. </year>
Reference-contexts: Most Foil-like algorithms employ stopping criteria for noise handling. The most commonly used among them are * Encoding Length Restriction: This heuristic used in Foil itself 3.2. FOSSIL 22 [Quinlan, 1990] is based on the Minimum Description Length principle <ref> [Rissanen, 1978] </ref>. <p> However, Grow does not attempt to solve the problems with bad splits (section 4.2.2) and with the separate-and-conquer strategy (section 4.2.3). [Srinivasan et al., 1992] use an algorithm similar to Grow to select a subset of clauses with an evaluation criterion based on the Minimum Description Length Principle <ref> [Rissanen, 1978] </ref> which does not require a separate test set for evaluating theories. <p> In particular for the efficient I-REP the additional computational costs caused by this method might still be bearable. The well-known Minimum Description Length (MDL) principle <ref> [Rissanen, 1978] </ref> that trades off the complexity of a theory against its classification performance may prove to be an efficient alternative that allows to assess the quality of a theory without evaluating it on a separate test set.
Reference: [Rouveirol and Puget, 1990] <author> Celine Rouveirol and Jean Fran~cois Puget. </author> <title> Beyond inversion of resolution. </title> <booktitle> In Proceedings of the 7th International Conference on Machine Learning, </booktitle> <pages> pages 122-130, </pages> <year> 1990. </year>
Reference-contexts: Com- mon methods to invent new predicates include detecting data dependencies [Flach, 1993] or clause completion heuristics [Kijsirikul et al., 1992]. Many systems try to invert deductive reasoning and are able to invent new predicates that way. Some invert one step of a resolution proof <ref> [Muggleton and Buntine, 1988, Wrobel, 1989, Rouveirol and Puget, 1990] </ref>, i.e. they are basically given a consequent and preconditions and try to guess a rule that can prove the consequent from the preconditions.
Reference: [Rouveirol et al., 1993] <author> Celine Rouveirol, Hilde Ade, and Luc de Raedt. </author> <title> Bottom up generalization in I.L.P. </title> <booktitle> In Proceedings of the IJCAI-93 Workshop on Inductive Logic Programming, </booktitle> <pages> pages 59-70, </pages> <year> 1993. </year> <note> BIBLIOGRAPHY 102 </note>
Reference-contexts: The most common generalization operators are based on inverse resolution as in CIGOL [Muggleton and Buntine, 1988] or on relative least general generalization [Plotkin, 1971] as in Golem [Muggleton and Feng, 1990]. A generic framework for bottom-up induction can be found in <ref> [Rouveirol et al., 1993] </ref>. Representation Change: The systems of this class approach the problem by reformulating it in a language that conventional Machine Learning systems can use.
Reference: [Sammut, 1993] <author> Claude Sammut. </author> <title> The origins of Inductive Logic Programming: A prehistoric tale. </title> <booktitle> In Proceedings of the 3rd International Workshop on Inductive Logic Programming, </booktitle> <pages> pages 177-216, </pages> <address> Bled, Slovenia, </address> <year> 1993. </year>
Reference-contexts: The most prominent systems are Claudien [De Raedt and Bruynooghe, 1993] and LaGrange [Dzeroski and Todorovski, 1993]. Of course, several systems would fit into more than one category. An excellent overview of the history of the field can be found in <ref> [Sammut, 1993] </ref>, a selection of some of the most important papers in [Muggleton, 1992]. [Lavrac and Dzeroski, 1993] is an introductory book on Inductive Logic Pro- gramming with a strong focus on relational learning systems, in particular on LINUS [Lavrac et al., 1991] and mFoil [Dzeroski and Bratko, 1992a].
Reference: [Schaffer, 1993] <author> Cullen Schaffer. </author> <title> Overfitting avoidance as bias. </title> <journal> Machine Learning, </journal> <volume> 10 </volume> <pages> 153-178, </pages> <year> 1993. </year>
Reference-contexts: In noisy domains, it can be expected that Fossil will over-generalize at high cutoff values, while it will overfit the noise in the data at low settings of this parameter. Thus Fossil's cutoff parameter may be viewed as a means for directly controlling the Overfitting Avoidance Bias <ref> [Schaffer, 1993, Wolpert, 1993] </ref>. Finding a good value for the cutoff is therefore an important problem. Section 3.3 will show some empirical evidence that setting the cutoff to 0:3 is a good heuristic, while chapter 5 will show ways for automatically adjusting the cutoff parameter. <p> If this accuracy is not estimated accurately, either because there are not enough remaining examples or because of a bad split, I-REP will be prone to over-generalization. Using the terminology of <ref> [Schaffer, 1993, Wolpert, 1993] </ref>, I-REP has a strong Overfitting Avoidance Bias, which can be detrimental in some domains (see [Murphy and Pazzani, 1994] for experiments along related lines). 6.2 An Example it has learned from are the same 250 examples that have been used to generate the overly specific theory from
Reference: [Shapiro, 1982] <author> Ehud Y. Shapiro. </author> <title> Algorithmic Program debugging. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, </address> <year> 1982. </year>
Reference-contexts: Theory revision systems constantly monitor the performance of their theory and attempt to generalize it when is unable to explain an observation and specialize it when one of its predictions does not turn 6 2.1. RELATIONAL LEARNING 7 out to be correct. Typical revision systems are MIS <ref> [Shapiro, 1982] </ref>, CIGOL [Muggleton, 1988], CLINT [De Raedt, 1992], KRT (MOBAL) [Wrobel, 1994], Forte [Richards, 1992] and AUDREY [Wogulis, 1991]. Predicate Invention is an important research direction aiming at introducing new background knowledge in order to gain expressiveness or to make the resulting theory more understandable [Stahl, 1993].
Reference: [Srinivasan et al., 1992] <author> A. Srinivasan, S. H. Muggleton, and M. E. Bain. </author> <title> Distinguishing noise from exceptions in non-monotonic learning. </title> <booktitle> In Proceedings of the International Workshop on Inductive Logic Programming, </booktitle> <address> Tokyo, Japan, </address> <year> 1992. </year>
Reference-contexts: However, Grow does not attempt to solve the problems with bad splits (section 4.2.2) and with the separate-and-conquer strategy (section 4.2.3). <ref> [Srinivasan et al., 1992] </ref> use an algorithm similar to Grow to select a subset of clauses with an evaluation criterion based on the Minimum Description Length Principle [Rissanen, 1978] which does not require a separate test set for evaluating theories.
Reference: [Stahl, 1993] <author> Irene Stahl. </author> <title> Predicate Invention in ILP | an overview. </title> <editor> In Pavel B. Brazdil, editor, </editor> <booktitle> Machine Learning: ECML-93, number 667 in Lecture Notes in Artificial Intelligence, </booktitle> <pages> pages 313-322, </pages> <address> Vienna, Austria, 1993. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: Predicate Invention is an important research direction aiming at introducing new background knowledge in order to gain expressiveness or to make the resulting theory more understandable <ref> [Stahl, 1993] </ref>. Com- mon methods to invent new predicates include detecting data dependencies [Flach, 1993] or clause completion heuristics [Kijsirikul et al., 1992]. Many systems try to invert deductive reasoning and are able to invent new predicates that way.
Reference: [Sternberg et al., 1992] <author> M. Sternberg, R. Lewis, R. King, and S. Muggleton. </author> <title> Modelling the structure and function of enzymes by machine learning. </title> <journal> Proceedings of the Royal Society of Chemistry: Faraday Discussions, </journal> <volume> 93 </volume> <pages> 269-280, </pages> <year> 1992. </year>
Reference: [Thrun et al., 1991] <author> S.B. Thrun, J. Bala, E. Bloedorn, I. Bratko, B. Cestnik, J. Cheng, K. De Jong, S. Dzeroski, S.E. Fahlman, D. Fisher, R. Hamann, K. Kaufman, S. Keller, I. Kononenko, J. Kreuziger, R.S. Michalski, T. Mitchell, P. Pachowitz, Y. Reich, H. Vafaie, W. Van de Welde, W. Wenzel, J. Wnek, and J. Zhang. </author> <title> The MONK's problems: A performance comparison of differ-ent learning algorithms. </title> <type> Technical Report CMU-CS-91-197, </type> <institution> Carnegie Mellon University, </institution> <month> December </month> <year> 1991. </year>
Reference-contexts: dangerous (Head,Body,Smiling,Holding,Jacket,Tie) :- Head = Body. tives of this family are C4.5 [Quinlan, 1993], Assistant [Cestnik et al., 1987] and CART [Breiman et al., 1984]. [Furnkranz, 1991] contains a summary of some basic methods for inducing decision trees from attribute-value data sets. 1.2 The Need for Relations in Learning In <ref> [Thrun et al., 1991] </ref> three problems are proposed in the robots domain. Each of them addresses a problem that is hard for decision tree learning algorithms. <p> The algorithms we will discuss in this thesis will be able to make use of relations in order to get simpler and more understandable concept descriptions. 1.3 Noise Tolerance Another important problem for decision tree algorithms is noise tolerance. Prob- lem 3 of <ref> [Thrun et al., 1991] </ref> illustrates this difficulty. Problem 3: Robots are dangerous when their jacket is green and they are holding a sword or when their jacket is not blue and the shape of their bodies is not octagon.
Reference: [Weiss and Indurkhya, 1994] <author> Sholom M. Weiss and Nitin Indurkhya. </author> <title> Small sam-ple decision tree pruning. </title> <booktitle> In Proceedings of the 11th Conference on Machine Learning, </booktitle> <pages> pages 335-342, </pages> <institution> Rutgers University, </institution> <address> New Brunswick, NJ, </address> <year> 1994. </year>
Reference-contexts: Research in decision tree learning has developed several methods for automating this selection <ref> [Breiman et al., 1984, Mingers, 1989a, Weiss and Indurkhya, 1994] </ref>. Most of these methods can be easily adapted for rule learning algorithms, once we have series of theories with different degrees of generality.
Reference: [Wogulis, 1991] <author> James Wogulis. </author> <title> Revising relational domain theories. </title> <booktitle> In Proceedings of the 8th International Workshop on Machine Learning, </booktitle> <pages> pages 462-466, </pages> <address> Evanston, Illinois, </address> <year> 1991. </year>
Reference-contexts: RELATIONAL LEARNING 7 out to be correct. Typical revision systems are MIS [Shapiro, 1982], CIGOL [Muggleton, 1988], CLINT [De Raedt, 1992], KRT (MOBAL) [Wrobel, 1994], Forte [Richards, 1992] and AUDREY <ref> [Wogulis, 1991] </ref>. Predicate Invention is an important research direction aiming at introducing new background knowledge in order to gain expressiveness or to make the resulting theory more understandable [Stahl, 1993].
Reference: [Wolpert, 1993] <author> David H. Wolpert. </author> <title> On overfitting avoidance as bias. </title> <type> Technical Report SFI TR 92-03-5001, </type> <institution> The Santa Fe Institute, </institution> <address> Santa Fe, NM, </address> <year> 1993. </year>
Reference-contexts: In noisy domains, it can be expected that Fossil will over-generalize at high cutoff values, while it will overfit the noise in the data at low settings of this parameter. Thus Fossil's cutoff parameter may be viewed as a means for directly controlling the Overfitting Avoidance Bias <ref> [Schaffer, 1993, Wolpert, 1993] </ref>. Finding a good value for the cutoff is therefore an important problem. Section 3.3 will show some empirical evidence that setting the cutoff to 0:3 is a good heuristic, while chapter 5 will show ways for automatically adjusting the cutoff parameter. <p> If this accuracy is not estimated accurately, either because there are not enough remaining examples or because of a bad split, I-REP will be prone to over-generalization. Using the terminology of <ref> [Schaffer, 1993, Wolpert, 1993] </ref>, I-REP has a strong Overfitting Avoidance Bias, which can be detrimental in some domains (see [Murphy and Pazzani, 1994] for experiments along related lines). 6.2 An Example it has learned from are the same 250 examples that have been used to generate the overly specific theory from
Reference: [Wrobel, 1989] <author> Stefan Wrobel. </author> <title> Demand-driven concept formation. </title> <editor> In K. Morik, editor, </editor> <booktitle> Knowledge Representation and Organization in Machine Learning, number 347 in Lecture Notes in Artificial Intelligence, </booktitle> <pages> pages 289-319. </pages> <address> SpringerVerlag, Berlin, </address> <year> 1989. </year> <note> BIBLIOGRAPHY 103 </note>
Reference-contexts: Com- mon methods to invent new predicates include detecting data dependencies [Flach, 1993] or clause completion heuristics [Kijsirikul et al., 1992]. Many systems try to invert deductive reasoning and are able to invent new predicates that way. Some invert one step of a resolution proof <ref> [Muggleton and Buntine, 1988, Wrobel, 1989, Rouveirol and Puget, 1990] </ref>, i.e. they are basically given a consequent and preconditions and try to guess a rule that can prove the consequent from the preconditions.
Reference: [Wrobel, 1994] <author> Stefan Wrobel. </author> <title> Concept formation during interactive theory re-vision. </title> <journal> Machine Learning, </journal> <volume> 14(2) </volume> <pages> 169-191, </pages> <year> 1994. </year>
Reference-contexts: RELATIONAL LEARNING 7 out to be correct. Typical revision systems are MIS [Shapiro, 1982], CIGOL [Muggleton, 1988], CLINT [De Raedt, 1992], KRT (MOBAL) <ref> [Wrobel, 1994] </ref>, Forte [Richards, 1992] and AUDREY [Wogulis, 1991]. Predicate Invention is an important research direction aiming at introducing new background knowledge in order to gain expressiveness or to make the resulting theory more understandable [Stahl, 1993].
Reference: [Zelle and Mooney, 1993] <author> John M. Zelle and Raymond J. Mooney. </author> <title> Learning se-mantic grammars with constructive inductive logic programming. </title> <booktitle> In Proceedings of the 11th National Conference on AI, </booktitle> <pages> pages 817-822, </pages> <address> Washington, DC, </address> <year> 1993. </year>
Reference-contexts: designed for this purpose and have already been applied to various real-world problems, like finite-element mesh design [Dolsak and Muggleton, 1992, Dzeroski and Bratko, 1992a], medical diagnosis [Lavrac et al., 1993, Petta, 1994], chess endgames [Morales, 1992, Muggleton et al., 1989, Quinlan, 1990, Dzeroski and Bratko, 1992a], natural language understanding <ref> [Zelle and Mooney, 1993] </ref>, document recognition [Esposito et al., 1993b] etc.
References-found: 100

