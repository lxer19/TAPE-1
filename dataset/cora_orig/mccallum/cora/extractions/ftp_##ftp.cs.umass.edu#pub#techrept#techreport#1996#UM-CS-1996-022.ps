URL: ftp://ftp.cs.umass.edu/pub/techrept/techreport/1996/UM-CS-1996-022.ps
Refering-URL: http://dis.cs.umass.edu/~mammen/scholar.html
Root-URL: 
Email: mammen@cs.umass.edu  hogg@parc.xerox.com  
Phone: 2  
Title: A New Look at the Easy-Hard-Easy Pattern of Combinatorial Search Difficulty  
Author: Dorothy L. Mammen and Tad Hogg 
Date: March 1996  
Address: Amherst, MA 01003, U.S.A.  3333 Coyote Hill Road Palo Alto, CA 94304, U.S.A.  
Affiliation: 1 Department of Computer Science University of Massachusetts  Xerox Palo Alto Research Center  University of Massachusetts  
Pubnum: Technical Report 96-22  
Abstract: The easy-hard-easy pattern in the difficulty of combinatorial search problems as constraints are added has been explained as due to a competition between the decrease in number of solutions and increased pruning. We test the generality of this explanation by examining one of its predictions: if the number of solutions is held fixed by the choice of problems, then increased pruning should lead to a monotonic decrease in search cost. Instead, we find the easy-hard-easy pattern in median search cost even when the number of solutions is held constant, for some search methods. This generalizes previous observations of this pattern and shows that the existing theory does not explain the full range of the peak in search cost. In these cases the pattern appears to be due to changes in the size of the minimal unsolvable subproblems, an aspect of the transition not previously reported. fl Much of this research was carried out while the first author was a summer intern at Xerox Palo Alto Research Center. This research was also partially supported by the National Science Foundation under Grant No. IRI-9321324 to Victor R. Lesser. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the National Science Foundation. 
Abstract-found: 1
Intro-found: 1
Reference: [ Asahiro et al., 1993 ] <author> Y. Asahiro, K. Iwama, and E. Miyano. </author> <title> Random generation of test instances with controlled attributes. </title> <booktitle> In Second DIMACS Challenge Workshop, </booktitle> <year> 1993. </year>
Reference-contexts: This tends to emphasize problems with many solutions and results in instances that are somewhat easier than uniform random selection. [ Cha and Iwama, 1995 ] have also used the approach of generating problems with specific attributes, for SAT problems, using the AIM generators developed by <ref> [ Asahiro et al., 1993 ] </ref> . We solved these problems using dynamic backtracking [ Ginsberg, 1993 ] in most cases. For comparison, we also did some searches with simple chronological backtrack instead.
Reference: [ Cha and Iwama, 1995 ] <author> B. Cha and K. Iwama. </author> <title> Performance test of local search algorithms using new types of random CNF formulas. </title> <booktitle> In Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 304-310, </pages> <address> Montreal, Quebec, Canada, </address> <year> 1995. </year>
Reference-contexts: This tends to emphasize problems with many solutions and results in instances that are somewhat easier than uniform random selection. <ref> [ Cha and Iwama, 1995 ] </ref> have also used the approach of generating problems with specific attributes, for SAT problems, using the AIM generators developed by [ Asahiro et al., 1993 ] . We solved these problems using dynamic backtracking [ Ginsberg, 1993 ] in most cases.
Reference: [ Cheeseman et al., 1991 ] <author> P. Cheeseman, B. Kanefsky, and W. Taylor. </author> <title> Where the really hard problems are. </title> <booktitle> In Proceedings of the Twelfth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 331-337, </pages> <address> Sydney, Australia, </address> <year> 1991. </year>
Reference-contexts: 1 Introduction Recently, many authors have shown that the solution cost for various kinds of combinatorial search problems follows a pattern of easy-hard-easy as a function of how tightly constrained the problems are. For example, this pattern appears for graph coloring as a function of the average graph connectivity <ref> [ Cheeseman et al., 1991, Hogg and Williams, 1994 ] </ref> , for propositional satisfiability (SAT) as a function of the ratio of number of clauses to number of variables [ Cheeseman et al., 1991, Mitchell et al., 1992, Crawford and Auton, 1993, Gent and Walsh, 1994b ] , and for constraint <p> All these effects become more pronounced as larger problems are considered, leading to sharper peaks and more abrupt transitions. This qualitative description explains many features of the observed behavior. This pruning explanation was also offered by <ref> [ Cheeseman et al., 1991 ] </ref> with respect to finding Hamiltonian circuits in highly constrained problems. This explanation can also be used to obtain a quantitative understanding of the behav 5 ior.
Reference: [ Crawford and Auton, 1993 ] <author> J. M. Crawford and L. D. Auton. </author> <title> Experimental results on the cross-over point in satisfiability problems. </title> <booktitle> In Proceedings of the Eleventh National Conference on Artificial Intelligence, </booktitle> <pages> pages 21-27, </pages> <address> Washington, DC, USA, </address> <year> 1993. </year>
Reference: [ Gent and Walsh, 1994a ] <author> Ian P. Gent and Toby Walsh. </author> <title> Easy problems are sometimes hard. </title> <journal> Artificial Intelligence, </journal> <volume> 70 </volume> <pages> 335-345, </pages> <year> 1994. </year>
Reference-contexts: Thus this could also explain observations of thrashing behavior for rare but extremely costly searches seen in the underconstrained region <ref> [ Gent and Walsh, 1994a, Hogg and Williams, 1994 ] </ref> .
Reference: [ Gent and Walsh, 1994b ] <author> I.P. Gent and T. Walsh. </author> <title> The SAT phase transition. In A.G. </title> <editor> Cohn, editor, </editor> <booktitle> Proceedings of the ECAI-94, </booktitle> <pages> pages 105-109. </pages> <publisher> John Wiley and Sons, </publisher> <year> 1994. </year>
Reference: [ Gent et al., 1995 ] <author> Ian P. Gent, Ewan MacIntyer, Patrick Prosser, and Toby Walsh. </author> <title> Scaling effects in the CSP phase transition. </title> <editor> In U. Montanari and F. Rossi, editors, </editor> <booktitle> Proc. of Principles and Practices of Constraint Programming PPCP95, </booktitle> <pages> pages 70-87. </pages> <publisher> Springer-Verlag, </publisher> <year> 1995. </year>
Reference-contexts: This accounts for the observed sharpening of the transition for larger problems. A further quantitative success of relating the search cost peak to transition phenomena is the evaluation of scaling behavior of the transition and search cost peak <ref> [ Kirkpatrick and Selman, 1994, Gent et al., 1995 ] </ref> . 4 Search Difficulty and Solvability In this section we take a closer look at the behavior of the search cost, specifically, by examining how the behavior depends on whether the problem has a solution and, if so, the number of
Reference: [ Ginsberg, 1993 ] <author> Matthew L. Ginsberg. </author> <title> Dynamic backtracking. </title> <journal> Journal of Artificial Intelligence Research, </journal> <volume> 1 </volume> <pages> 25-46, </pages> <year> 1993. </year>
Reference-contexts: We solved these problems using dynamic backtracking <ref> [ Ginsberg, 1993 ] </ref> in most cases. For comparison, we also did some searches with simple chronological backtrack instead. The search cost is measured as the number of nodes explored. 2.2 Graph Coloring We also experimented with the 3-coloring problem.
Reference: [ Hogg and Williams, 1994 ] <author> Tad Hogg and Colin P. Williams. </author> <title> The hardest constraint problems: A double phase transition. </title> <journal> Artificial Intelligence, </journal> <volume> 69 </volume> <pages> 359-377, </pages> <year> 1994. </year> <month> 17 </month>
Reference-contexts: 1 Introduction Recently, many authors have shown that the solution cost for various kinds of combinatorial search problems follows a pattern of easy-hard-easy as a function of how tightly constrained the problems are. For example, this pattern appears for graph coloring as a function of the average graph connectivity <ref> [ Cheeseman et al., 1991, Hogg and Williams, 1994 ] </ref> , for propositional satisfiability (SAT) as a function of the ratio of number of clauses to number of variables [ Cheeseman et al., 1991, Mitchell et al., 1992, Crawford and Auton, 1993, Gent and Walsh, 1994b ] , and for constraint <p> Thus this could also explain observations of thrashing behavior for rare but extremely costly searches seen in the underconstrained region <ref> [ Gent and Walsh, 1994a, Hogg and Williams, 1994 ] </ref> .
Reference: [ Hogg, 1996 ] <author> Tad Hogg. </author> <title> Refining the phase transitions in combinatorial search. </title> <journal> Artificial Intelligence, </journal> <note> 1996. to appear. </note>
Reference-contexts: This observation has motivated the introduction of additional parameters describing problem structure based on a more precise specification of the number of solutions <ref> [ Hogg, 1996 ] </ref> . In this paper we investigate the generality of this explanation by examining problems for which the number of solutions is restricted, including cases where the number is specified exactly to be either zero or one.
Reference: [ Johnson et al., 1991 ] <author> David S. Johnson, Cecilia R. Aragon, Lyle A. McGeoch, and Catherine Schevon. </author> <title> Optimization by simulated annealing: An experimental evaluation; part ii, graph coloring and number partitioning. </title> <journal> Operations Research, </journal> <volume> 39(3) </volume> <pages> 378-406, </pages> <year> 1991. </year>
Reference-contexts: For the 100-node graphs we studied, the number of binary nogoods is given by 150fl. In this case, we used a simple chronological backtrack search in combination with the Brelaz heuristic for variable and value ordering <ref> [ Johnson et al., 1991 ] </ref> . This heuristic assigns the most constrained nodes first (i.e., those with the most distinctly colored neighbors), breaking ties by choosing nodes with the most uncolored neighbors, and with any remaining ties broken randomly.
Reference: [ Kask and Dechter, 1995 ] <author> Kalev Kask and Rina Dechter. </author> <title> GSAT and local consistency. </title> <booktitle> In Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 616-622, </pages> <address> Montreal, Quebec, Canada, </address> <year> 1995. </year>
Reference: [ Kirkpatrick and Selman, 1994 ] <author> Scott Kirkpatrick and Bart Selman. </author> <title> Critical behavior in the satisfiability of random boolean expressions. </title> <journal> Science, </journal> <volume> 264 </volume> <pages> 1297-1301, </pages> <year> 1994. </year>
Reference-contexts: This accounts for the observed sharpening of the transition for larger problems. A further quantitative success of relating the search cost peak to transition phenomena is the evaluation of scaling behavior of the transition and search cost peak <ref> [ Kirkpatrick and Selman, 1994, Gent et al., 1995 ] </ref> . 4 Search Difficulty and Solvability In this section we take a closer look at the behavior of the search cost, specifically, by examining how the behavior depends on whether the problem has a solution and, if so, the number of
Reference: [ Mitchell et al., 1992 ] <author> D. Mitchell, B. Selman, and H. Levesque. </author> <title> Hard and easy distributions of SAT problems. </title> <booktitle> In Proceedings of the Tenth National Conference on Artificial Intelligence, </booktitle> <pages> pages 459-465, </pages> <address> San Jose, CA, USA, </address> <year> 1992. </year>
Reference-contexts: Error bars showing 95% confidence intervals are included. provide a useful examination of the properties of solvable problems. Furthermore, a study of satisfiability problems with backtracking search is consistent with a peak in cost for solvable problems <ref> [ Mitchell et al., 1992 ] </ref> , but there were insufficient highly constrained solvable problems to make a definite conclusion for the behavior with many constraints. 4.3 Problems With a Fixed Number of Solutions A more interesting case is the behavior of the problems with no solutions shown in Figures 2 <p> In contrast to our observations, a monotonic decrease in cost has been reported for unsolvable binary constraint problems [ Smith and Dyer, 1996 ] and for unsolvable 3SAT problems <ref> [ Mitchell et al., 1992 ] </ref> .
Reference: [ Prosser, 1996 ] <author> Patrick Prosser. </author> <title> An empirical study of phase transitions in binary constraint satisfaction problems. </title> <journal> Artificial Intelligence, </journal> <note> 1996. to appear. </note>
Reference-contexts: of number of clauses to number of variables [ Cheeseman et al., 1991, Mitchell et al., 1992, Crawford and Auton, 1993, Gent and Walsh, 1994b ] , and for constraint satisfaction problems (CSPs) as a function of the number of nogoods [ Williams and Hogg, 1994 ] and constraint tightness <ref> [ Smith, 1994, Prosser, 1996 ] </ref> . This regularity raises the possibility of determining, prior to search, the likely difficulty of problems. Unfortunately, this is not yet possible because of the high variance associated with the observations.
Reference: [ Smith and Dyer, 1996 ] <author> Barbara M. Smith and Martin E. Dyer. </author> <title> Locating the phase transition in binary constraint satisfaction problems. </title> <journal> Artificial Intelligence, </journal> <note> 1996. to appear. </note>
Reference-contexts: The fraction of solvable problems is also shown in Figure 1, scaled from 1.0 on the left to 0.0 on the right. This illustrates that the hard problems are concentrated in the so-called "mushy region" <ref> [ Smith and Dyer, 1996 ] </ref> where the probability of a solution is changing from 1.0 to 0.0. In particular, the peak in search cost is near the "crossover point," the point at which half the problems are solvable and half unsolvable. <p> This explanation can also be used to obtain a quantitative understanding of the behav 5 ior. For instance, the location of the transition region can be understood by an approxi-mate theory predicting that the cost peak occurs when the expected number of solutions equals one <ref> [ Smith and Dyer, 1996, Williams and Hogg, 1994 ] </ref> . In our example there are 3 10 possible assignments to the 10 variables in the problem. <p> By focusing more closely on these factors we can hope to gain a better understanding of the structure of hard problems, which may lead to more precise predictions of search cost. In contrast to our observations, a monotonic decrease in cost has been reported for unsolvable binary constraint problems <ref> [ Smith and Dyer, 1996 ] </ref> and for unsolvable 3SAT problems [ Mitchell et al., 1992 ] . <p> Error bars showing 95% confidence intervals are included. peak. That is, these critically constrained problems will typically be hard to search (because most of the constraints must be instantiated before any unproductive search paths can be identified) and, since they are concentrated at the transition <ref> [ Smith and Dyer, 1996 ] </ref> , give rise to the search peak. This explanation does not include any discussion of the changes in pruning capability as constraints are added.
Reference: [ Smith, 1994 ] <author> Barbara M. Smith. </author> <title> Phase transition and the mushy region in constraint satisfaction problems. In A.G. </title> <editor> Cohn, editor, </editor> <booktitle> Proceedings of the ECAI-94, </booktitle> <pages> pages 100-104. </pages> <publisher> John Wiley and Sons, </publisher> <year> 1994. </year>
Reference-contexts: of number of clauses to number of variables [ Cheeseman et al., 1991, Mitchell et al., 1992, Crawford and Auton, 1993, Gent and Walsh, 1994b ] , and for constraint satisfaction problems (CSPs) as a function of the number of nogoods [ Williams and Hogg, 1994 ] and constraint tightness <ref> [ Smith, 1994, Prosser, 1996 ] </ref> . This regularity raises the possibility of determining, prior to search, the likely difficulty of problems. Unfortunately, this is not yet possible because of the high variance associated with the observations.
Reference: [ Snedecor and Cochran, 1967 ] <author> George W. Snedecor and William G. Cochran. </author> <title> Statistical Methods. </title> <institution> Iowa State Univ. Press, Ames, Iowa, </institution> <note> 6th edition, </note> <year> 1967. </year>
Reference-contexts: In all of our results in this paper, we include 95% confidence intervals. The 95% confidence intervals for the estimate of the median obtained from our samples is given approximately <ref> [ Snedecor and Cochran, 1967, p. 124 ] </ref> by the percentiles 50 100= p of the data, where N is the number of samples. <p> The 95% confidence intervals for the estimate of fractions is given approximately <ref> [ Snedecor and Cochran, 1967, p. 210 ] </ref> by f 2 f (1 f )=N , where f is the estimated value of the fraction. In many cases in this paper, there are sufficient samples to make this interval smaller than the size of the plotted points.
Reference: [ Williams and Hogg, 1994 ] <author> C. P. Williams and T. Hogg. </author> <title> Exploiting the deep structure of constraint problems. </title> <journal> Artificial Intelligence, </journal> <volume> 70 </volume> <pages> 73-117, </pages> <year> 1994. </year>
Reference-contexts: propositional satisfiability (SAT) as a function of the ratio of number of clauses to number of variables [ Cheeseman et al., 1991, Mitchell et al., 1992, Crawford and Auton, 1993, Gent and Walsh, 1994b ] , and for constraint satisfaction problems (CSPs) as a function of the number of nogoods <ref> [ Williams and Hogg, 1994 ] </ref> and constraint tightness [ Smith, 1994, Prosser, 1996 ] . This regularity raises the possibility of determining, prior to search, the likely difficulty of problems. Unfortunately, this is not yet possible because of the high variance associated with the observations. <p> The existing explanation for the concentration of hard problems relies on a competition between changes in the number of solutions and the amount of pruning provided by the problem constraints <ref> [ Williams and Hogg, 1994 ] </ref> . With few constraints, there are many solutions so the search is usually easy. As constraints are added the number of solutions drops rapidly, making problems harder. But the new constraints also increase the pruning of unproductive search choices, tending to make search easier. <p> This explanation can also be used to obtain a quantitative understanding of the behav 5 ior. For instance, the location of the transition region can be understood by an approxi-mate theory predicting that the cost peak occurs when the expected number of solutions equals one <ref> [ Smith and Dyer, 1996, Williams and Hogg, 1994 ] </ref> . In our example there are 3 10 possible assignments to the 10 variables in the problem.
Reference: [ Yugami et al., 1994 ] <author> Nobuhiro Yugami, Yuiko Ohta, and Hirotaka Hara. </author> <title> Improving repair-based constraint satisfaction methods by value propagation. </title> <booktitle> In Proceedings of the Twelfth National Conference on Artificial Intelligence, </booktitle> <pages> pages 344-349, </pages> <address> Seattle, WA, USA, </address> <year> 1994. </year> <month> 18 </month>
References-found: 20

