URL: http://www.cs.columbia.edu/~shaw/papers/anlp97.ps.gz
Refering-URL: http://www.cs.columbia.edu/~shaw/papers/index.html
Root-URL: http://www.cs.columbia.edu
Email: kathy,pan,shaw@cs.columbia.edu  
Title: Language Generation for Multimedia Healthcare Briefings  
Author: Kathleen R. McKeown Shimei Pan and James Shaw Desmond A. Jordan Barry A. Allen flfl 
Address: New York, NY 10027, USA  New York, NY 10032  
Affiliation: Dept. of Computer Science Columbia University  Dept. of Anesthesiology and Medical Informatics Dept. flfl College of Physicians and Surgeons Columbia University  
Note: Published in Proc. of ANLP, Washington, D.C., pp. 277-282, 1997.  
Abstract: This paper identifies issues for language generation that arose in developing a multimedia interface to healthcare data that includes coordinated speech, text and graphics. In order to produce brief speech for time-pressured caregivers, the system both combines related information into a single sentence and uses abbreviated references in speech when an unambiguous textual reference is also used. Finally, due to the temporal nature of the speech, the language generation module needs to communicate information about the ordering and duration of references to other temporal media, such as graphics, in order to allow for coordi nation between media.
Abstract-found: 1
Intro-found: 1
Reference: <author> M. Dalal, S. Feiner, K. McKeown, D. Jordan, B. Allen, and Y. alSafadi. </author> <year> 1996a. </year> <title> Magic: An experimental system for generating multimedia briefings about post-bypass patient status. </title> <booktitle> In Proceedings of American Medical Informatics Association 1996 Fall. </booktitle>
Reference-contexts: MAGIC generates a multimedia briefing that integrates speech, text, and animated graphics to provide an update on patient status <ref> (Dalal et al., 1996a) </ref>. <p> Future planned evaluations will examine caregiver satisfaction with the spoken medium versus text. 3 Issues for Language Generation In the early stages of system development, a primary constraint on the language generation process was identified during an informal evaluation with ICU nurses and residents <ref> (Dalal et al., 1996a) </ref>.
Reference: <author> M. Dalal, S. Feiner, K. McKeown, S. Pan, M. Zhou, T. Hollerer, J. Shaw, Y. Feng, and J. Fromer. </author> <year> 1996b. </year> <title> Negotiation for automated generation of temporal multimedia presentations. </title> <booktitle> In Proceedings of ACM Multimedia '96. </booktitle>
Reference-contexts: Temporal coordination involves two problems: ensuring that ordering of spoken references to information is compatible with spatial ordering of the graphical actions and synchronizing the duration of spoken and graphical references <ref> (Dalal et al., 1996b) </ref>. In order to achieve this, language generation must provide a partial ordering of spoken references at a fairly early point in the generation process. <p> These are then sent to the media coordinator for negotiating with graphics an ordering that is compatible to both. Details on the implementation of this negotiation are presented in <ref> (Dalal et al., 1996b) </ref> and (Pan and McKeown, 1996). In order to synchronize duration of the spoken and graphical references, the lexical chooser invokes the speech synthesizer to calculate the duration of each lexical phrase that it generates.
Reference: <author> R. Dale. </author> <year> 1992. </year> <title> Generating Referring Expressions: Constructing Descriptions in a Domain of Objects and Processes. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference-contexts: In order to provide for more flexible synchronization, the speech sentence generator includes facilities for modifying pauses if conflicts with graphics durations arise (see (Pan and McKeown, 1996) for details). 4 Related Work There is considerable interest in producing fluent and concise sentences. EPICURE <ref> (Dale, 1992) </ref>, PlanDoc (Kukich et al., 1994; Shaw, 1995), and systems developed by Dalianis and Hovy (Dalia-nis and Hovy, 1993) all use various forms of conjunction and ellipsis to generate more concise sentences. In (Horacek, 1992) aggregation is performed at text-structure level.
Reference: <author> H. Dalianis and E. Hovy. </author> <year> 1993. </year> <title> Aggregation in natural language generation. </title> <booktitle> In Proceedings of the Fourth European Workshop on Natural Language Generation, </booktitle> <pages> pages 67-78, </pages> <address> Pisa, Italy. </address>
Reference: <author> J. Davis and J. Hirschberg. </author> <year> 1988. </year> <title> Assigning intonational features in synthesized spoken discourse. </title> <booktitle> In Proceedings of the 26th Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> pages 187-193, </pages> <address> Buffalo, New York. </address>
Reference-contexts: In (Prevost, 1995) and (Steedman, 1996), they explore a way to generate spoken lan guage with accurate contrastive stress based on information structure and carefully modeled domain knowledge. In <ref> (Davis and Hirschberg, 1988) </ref>, spoken directions are generated with richer intonation features.
Reference: <author> M. Elhadad. </author> <year> 1992. </year> <title> Using argumentation to control lexical choice: A functional unification-based approach. </title> <type> Ph.D. thesis, </type> <institution> Computer Science Department, Columbia University. </institution>
Reference: <author> H. Horacek. </author> <year> 1992. </year> <title> An integrated view of text planning. </title> <booktitle> In Aspects of Automated Natural Language Generation, </booktitle> <pages> pages 29-44. </pages> <publisher> Springer-Verlag. </publisher>
Reference-contexts: EPICURE (Dale, 1992), PlanDoc (Kukich et al., 1994; Shaw, 1995), and systems developed by Dalianis and Hovy (Dalia-nis and Hovy, 1993) all use various forms of conjunction and ellipsis to generate more concise sentences. In <ref> (Horacek, 1992) </ref> aggregation is performed at text-structure level. In addition to conjoining VP and NPs, FlowDoc (Passonneau et al., 1996) uses ontological generalization to combine descriptions of a set of objects into a more general description.
Reference: <author> K. Kukich, K. McKeown, and J. Shaw. </author> <year> 1994. </year> <title> Practical issues in automatic documentation generation. </title> <booktitle> In Proceedings of the 4th ACL Conference on Applied Natural Language Processing, </booktitle> <pages> pages 7-14, </pages> <address> Stuttgart. </address>
Reference: <author> S. Pan and K. McKeown. </author> <year> 1996. </year> <title> Spoken language generation in a multimedia system. </title> <booktitle> In Proceedings of ICSLP 96, </booktitle> <volume> volume 1, </volume> <pages> pages 374-377, </pages> <address> Philadelphia, PA. </address>
Reference-contexts: These are then sent to the media coordinator for negotiating with graphics an ordering that is compatible to both. Details on the implementation of this negotiation are presented in (Dalal et al., 1996b) and <ref> (Pan and McKeown, 1996) </ref>. In order to synchronize duration of the spoken and graphical references, the lexical chooser invokes the speech synthesizer to calculate the duration of each lexical phrase that it generates. <p> In order to provide for more flexible synchronization, the speech sentence generator includes facilities for modifying pauses if conflicts with graphics durations arise (see <ref> (Pan and McKeown, 1996) </ref> for details). 4 Related Work There is considerable interest in producing fluent and concise sentences.
Reference: <author> R. Passonneau, K. Kukich, V. Hatzivassiloglou, L. Lefkowitz, and H. Jing. </author> <year> 1996. </year> <title> Generating summaries of work flow diagrams. </title> <booktitle> In Proceedings of the International Conference on Natural Language Processing and Industrial Applications, </booktitle> <pages> pages 204-210, </pages> <address> New Brunswick, Canada, </address> <month> June. </month> <institution> Univeristy of Moncton. </institution>
Reference-contexts: In (Horacek, 1992) aggregation is performed at text-structure level. In addition to conjoining VP and NPs, FlowDoc <ref> (Passonneau et al., 1996) </ref> uses ontological generalization to combine descriptions of a set of objects into a more general description. Based on a corpus analysis in the basketball domain, (Robin, 1994) catalogued a set of revision operators such as adjoin and nominalization in his system STREAK.
Reference: <author> S. Prevost. </author> <year> 1995. </year> <title> A Semantics of Contrast and In-formaiton Structure for Specifying Intonation in Spoken Language Generation. </title> <type> Ph.D. thesis, </type> <institution> University of Pennsylvania. </institution>
Reference-contexts: Unlike STREAK, MAGIC does not use revision to combine information in a sentence. Generating spoken language from meanings or concepts (Meaning to Speech, MTS) is a new topic and only a few such systems were developed in recent years. In <ref> (Prevost, 1995) </ref> and (Steedman, 1996), they explore a way to generate spoken lan guage with accurate contrastive stress based on information structure and carefully modeled domain knowledge. In (Davis and Hirschberg, 1988), spoken directions are generated with richer intonation features.
Reference: <author> J. Robin. </author> <year> 1994. </year> <title> Revision-Based Generation of Natural Language Summaries Providing Historical Background. </title> <type> Ph.D. thesis, </type> <institution> Computer Science Department, Columbia University. </institution>
Reference-contexts: In (Horacek, 1992) aggregation is performed at text-structure level. In addition to conjoining VP and NPs, FlowDoc (Passonneau et al., 1996) uses ontological generalization to combine descriptions of a set of objects into a more general description. Based on a corpus analysis in the basketball domain, <ref> (Robin, 1994) </ref> catalogued a set of revision operators such as adjoin and nominalization in his system STREAK. Unlike STREAK, MAGIC does not use revision to combine information in a sentence.
Reference: <author> N. Roderer and P. Clayton. </author> <year> 1992. </year> <institution> Iaims at columbia presbyterian medical center: Accomplishments and challenges. In Bull. Am. Med. </institution> <address> Lib. </address> <publisher> Assoc., </publisher> <pages> pages 253-262. </pages>
Reference-contexts: To address this need, we are developing a multimedia briefing system, MAGIC (Multimedia Abstract Generation for Intensive Care), that takes as input online data collected during the surgical operation as well as information stored in the main databases at Columbia Presbyterian Medical Center <ref> (Roderer and Clayton, 1992) </ref>. MAGIC generates a multimedia briefing that integrates speech, text, and animated graphics to provide an update on patient status (Dalal et al., 1996a).
Reference: <author> J. Shaw. </author> <year> 1995. </year> <title> Conciseness through aggregation in text generation. </title> <booktitle> In Proceedings of the 33rd ACL (Student Session), </booktitle> <pages> pages 329-331. </pages>
Reference: <author> M. Steedman. </author> <year> 1996. </year> <title> Representing discourse in-formationn for spoken dialogue generation. </title> <booktitle> In Proceedings of ISSD 96, </booktitle> <pages> pages 89-92, </pages> <address> Philadel-phia, PA. </address>
Reference-contexts: Unlike STREAK, MAGIC does not use revision to combine information in a sentence. Generating spoken language from meanings or concepts (Meaning to Speech, MTS) is a new topic and only a few such systems were developed in recent years. In (Prevost, 1995) and <ref> (Steedman, 1996) </ref>, they explore a way to generate spoken lan guage with accurate contrastive stress based on information structure and carefully modeled domain knowledge. In (Davis and Hirschberg, 1988), spoken directions are generated with richer intonation features.
Reference: <author> M. Zhou and S. Feiner. </author> <year> 1997. </year> <title> Top-down hierarchical planning of coherent visual discourse. </title> <booktitle> In Proc. IUI '97 (1997 Int. Conf. on Intelligent User Interfaces), </booktitle> <address> Orlando, FL, </address> <month> January 6-9. </month>
Reference-contexts: The media allocator allocates content to media, and finally, the media specific generators realize content in their own specific media (see <ref> (Zhou and Feiner, 1997) </ref> for details on the graphics generator). A media coordinator is responsible for ensuring that spoken output and animated graphics are temporally coordinated. Within this context, the speech generator receives as input a partially ordered conceptual representation of information to be communicated.
References-found: 16

