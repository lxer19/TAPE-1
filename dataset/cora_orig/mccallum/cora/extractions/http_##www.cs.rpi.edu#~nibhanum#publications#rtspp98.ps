URL: http://www.cs.rpi.edu/~nibhanum/publications/rtspp98.ps
Refering-URL: http://www.cs.rpi.edu/~nibhanum/arsdir/vbsp_refs.html
Root-URL: http://www.cs.rpi.edu
Email: fnibhanum, szymanskg@cs.rpi.edu  
Title: Runtime Support for Virtual BSP Computer  
Author: Mohan V. Nibhanupudi and Boleslaw K. Szymanski 
Address: Troy, NY, USA 12180-3590  
Affiliation: Department of Computer Science Rensselaer Polytechnic Institute  
Abstract: Several computing environments including wide area networks and nondedicated networks of workstations are characterized by frequent unavailability of the participating machines. Parallel computations, with interdependencies among their component processes, can not make progress if some of the participating machines become unavailable during the computation. As a result, to deliver acceptable performance, the set of participating processors must be dynamically adjusted following the changes in computing environment. In this paper, we discuss the design of a run time system to support a Virtual BSP Computer that allows BSP programmers to treat a network of transient processors as a dedicated network. The Virtual BSP Computer enables parallel applications to remove computations from processors that become unavailable and thereby adapt to the changing computing environment. The run time system, which we refer to as adaptive replication system (ARS), uses replication of data and computations to keep current a mapping of a set of virtual processors to a subset of the available machines. ARS has been implemented and integrated with a message passing library for the Bulk-Synchronous Parallel (BSP) model. The extended library has been applied to two parallel applications with the aim of using idle machines in a network of workstations (NOW) for parallel computations. We present the performance results of ARS for these applications. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> Gilbert Cabillic and Isabelle Puaut. Stardust: </author> <title> an environment for parallel programming on networks of heterogeneous workstations. </title> <journal> J. Parallel and Distributed Computing, </journal> <volume> 40(1), </volume> <month> Jan </month> <year> 1997. </year>
Reference-contexts: CoCheck [12] tries to blend the resource manage-ment capabilities of systems like Condor [7] with parallel programming libraries such as PVM [13] and MPI [4]. It provides consistent checkpointing and process migration mechanism for MPI and PVM applications. Stardust <ref> [1] </ref> is a system for parallel computations on a network of heterogeneous workstations. It captures the state of the computation at the barrier synchronization points in the parallel program.
Reference: 2. <author> Clemens H. Cap and Volker Strumpen. </author> <title> Efficient Parallel Computing in Distributed Workstation Environments. </title> <booktitle> Parallel Computing, </booktitle> <pages> pages 1221-1234, </pages> <year> 1993. </year>
Reference-contexts: Synchronous parallel computations with the computation state distributed among the component processes cannot be modeled with master-worker parallelism. A limited form of adaptive parallelism can be achieved by dynamically balancing the load on the participating workstations. Parform <ref> [2] </ref> is a system for providing such capability to parallel applications. Leon et. al. [6] discuss implementation of a consistent checkpointing and roll back mechanism to transparently recover from individual processor failures. The consistent checkpoint is obtained by forcing a global synchronization before al lowing a checkpoint to proceed.
Reference: 3. <author> Nicholas Carriero, Eric Freeman, Gelernter, and David Kaminsky. </author> <title> Adaptive Parallelism and Piranha. </title> <journal> Computer, </journal> <volume> 28(1) </volume> <pages> 40-49, </pages> <month> January </month> <year> 1995. </year>
Reference-contexts: A recovery function using the function calls from the vendor library will be able to recreate the computation state in such a case. We have used the recovery function to successfully recompute the computation state in an application using such a random number generator. 3 Related Work Piranha <ref> [3] </ref> is a system for adaptive parallelism based on the tuple-space based coordination language Linda. Piranha implements master-worker parallelism and hence is applicable to only coarse grained parallel applications involving independent tasks. Synchronous parallel computations with the computation state distributed among the component processes cannot be modeled with master-worker parallelism.
Reference: 4. <author> Message Passing Interface Forum. </author> <title> MPI: A Message Passing Interface Standard. Technical report, Message Passing Interface Forum, </title> <month> May 5, </month> <year> 1994. </year>
Reference-contexts: The consistent checkpoint is obtained by forcing a global synchronization before al lowing a checkpoint to proceed. CoCheck [12] tries to blend the resource manage-ment capabilities of systems like Condor [7] with parallel programming libraries such as PVM [13] and MPI <ref> [4] </ref>. It provides consistent checkpointing and process migration mechanism for MPI and PVM applications. Stardust [1] is a system for parallel computations on a network of heterogeneous workstations. It captures the state of the computation at the barrier synchronization points in the parallel program. <p> It makes use of the checkpoint based migration scheme of Condor [7] for process migration. It should be noted that our protocol for adaptive replication scheme can be applied to other message passing libraries such as MPI <ref> [4] </ref>. 2 Replication level is the number of processes on which the computation state of a process is replicated.
Reference: 5. <author> L. Kleinrock and W.Korfhage. </author> <title> Collecting Unused Processing Capacity: An Analysis of Transient Distributed Systems. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 4(5), </volume> <month> May </month> <year> 1993. </year>
Reference-contexts: 1 Introduction Several computing environments are characterized by frequent unavailability of the participating machines. Machines that are available for use only part of the time are referred to as transient processors <ref> [5] </ref>. A transition of the host machine from an available to a non-available state is considered a transient failure. Such model of a network of transient processors applies to several computing paradigms, including wide area networks such as the Internet and local networks of nondedicated workstations (NOWs). <p> Use of ? This work was partially supported by NSF Grant CCR-9527151. The content does not necessarily reflect the position or policy of the U.S. Government. workstations in this manner allows additional sequential programs to accumulate work during idle times of the workstations <ref> [5] </ref>. However parallel programs, with interdependencies among their component processes, can not make progress if some of the participating workstations become unavailable during the computation. Parallel computations in such environments must adapt to the changing computing environment to deliver acceptable performance.
Reference: 6. <author> J. Leon, Allan L. Fischer, and Peter Steenkiste. </author> <title> Fail-safe PVM: A portable package for distributed programming with transparent recovery. </title> <type> Technical report, </type> <institution> School of Computer Science, Carnegie Mellon University, </institution> <address> Pittsburgh, PA 15213, </address> <month> Feb </month> <year> 1993. </year>
Reference-contexts: A limited form of adaptive parallelism can be achieved by dynamically balancing the load on the participating workstations. Parform [2] is a system for providing such capability to parallel applications. Leon et. al. <ref> [6] </ref> discuss implementation of a consistent checkpointing and roll back mechanism to transparently recover from individual processor failures. The consistent checkpoint is obtained by forcing a global synchronization before al lowing a checkpoint to proceed.
Reference: 7. <author> Michael J. Litzkow, Miron Livny, and Matt W. </author> <title> Mutka. Condor A Hunter of Idle Workstations. </title> <booktitle> In Proc. 8th Intl. Conf. Distributed Computing Systems, </booktitle> <address> San Jose, California, </address> <month> June 13-17, </month> <year> 1988. </year>
Reference-contexts: The consistent checkpoint is obtained by forcing a global synchronization before al lowing a checkpoint to proceed. CoCheck [12] tries to blend the resource manage-ment capabilities of systems like Condor <ref> [7] </ref> with parallel programming libraries such as PVM [13] and MPI [4]. It provides consistent checkpointing and process migration mechanism for MPI and PVM applications. Stardust [1] is a system for parallel computations on a network of heterogeneous workstations. <p> That is, a process can act as a backup for its immediate predecessor only. The prototype is implemented on Sun Sparcstations using the Solaris (SunOS 5.5) operating system. It makes use of the checkpoint based migration scheme of Condor <ref> [7] </ref> for process migration. It should be noted that our protocol for adaptive replication scheme can be applied to other message passing libraries such as MPI [4]. 2 Replication level is the number of processes on which the computation state of a process is replicated.
Reference: 8. <author> Richard Miller. </author> <title> A Library for Bulk-synchronous Parallel Programming. </title> <booktitle> In British Computer Society Workshop on General Purpose Parallel Computing, </booktitle> <month> Dec </month> <year> 1993. </year>
Reference-contexts: replicating computations of a failed process can easily be extended to work across heterogeneous architectures by providing automatic conversion of data representations. 4 Design of the Adaptive Replication System The Adaptive Replication System is designed within the framework of the BSP model [14] and developed using the Oxford BSP Library <ref> [8] </ref>. ARS consists of dynamic extensions to the Oxford BSP library and the adaptive replication scheme. The adaptive replication scheme is designed in two levels of abstraction: replication layer and user layer.
Reference: 9. <author> M. V. Nibhanupudi, C. D. Norton, and B. K. Szymanski. </author> <title> Plasma Simulation On Networks Of Workstations Using The Bulk-Synchronous Parallel Model. </title> <booktitle> In Proc. Intl. Conf. on Parallel and Distributed Processing Techniques and Applications (PDPTA'95), </booktitle> <address> Athens, Georgia, </address> <month> Nov </month> <year> 1995. </year>
Reference-contexts: It is simple, yet robust and was successfully used by us for implementing plasma simulation on a network of workstations <ref> [9] </ref>. We extended the Oxford BSP Library to provide dynamic process management and virtual synchronization as described in [10].
Reference: 10. <author> M. V. Nibhanupudi and B. K. Szymanski. </author> <title> Adaptive Parallelism In The Bulk-Synchronous Parallel model. </title> <booktitle> In Proceedings of the Second International Euro-Par Conference, </booktitle> <address> Lyon, France, </address> <month> Aug </month> <year> 1996. </year>
Reference-contexts: It is simple, yet robust and was successfully used by us for implementing plasma simulation on a network of workstations [9]. We extended the Oxford BSP Library to provide dynamic process management and virtual synchronization as described in <ref> [10] </ref>. The extensions include the following features: the component processes can be terminated at any time; new processes can be created to join the computation; and component processes can perform synchronization for one another. 4.2 Protocol for Replication and Recovery For the prototype under implementation we make the following assumptions. <p> It defines the maximum number of successive (transient) processor failures (according to the order of the processes in the logical ring topology, see section 4.2) that the adaptive replication system can tolerate. Refer to <ref> [10] </ref> for more details. bsp specific system state ( plasmaState ); bsp local system state ( localCharge ); bsp comp sstep ( bsp step ); CalcEField ( vpm, energy ); InitChargeDensity (); energy.ke ( 0.0 ); Advance ( elec pos, elec vel ); bsp comp sstep end ( bsp step );
Reference: 11. <author> J. K. Ousterhout. </author> <title> Scheduling techniques for concurrent systems. </title> <booktitle> In Proc. Third Intl. Conf. Distributed Computing Systems, </booktitle> <month> Oct </month> <year> 1982. </year>
Reference-contexts: In a heterogeneous network the computations on individual workstations often proceed at different speeds owing to differences in processor speed, characteristics of work load on the individual machines, etc. Due to the coarse grain nature of the applications, gang scheduling <ref> [11] </ref> is not required. To compensate for the differences in processing speed, a grace period can be used to allow a slow predecessor to complete its computations before concluding that the predecessor has failed. However, using a grace period also delays replicating for the predecessor when required.
Reference: 12. <author> G. Stellner. </author> <title> CoCheck: Checkpointing and process migration for MPI. </title> <booktitle> In Proceedings of the International Parallel Processing Symposium, </booktitle> <month> April </month> <year> 1996. </year>
Reference-contexts: Leon et. al. [6] discuss implementation of a consistent checkpointing and roll back mechanism to transparently recover from individual processor failures. The consistent checkpoint is obtained by forcing a global synchronization before al lowing a checkpoint to proceed. CoCheck <ref> [12] </ref> tries to blend the resource manage-ment capabilities of systems like Condor [7] with parallel programming libraries such as PVM [13] and MPI [4]. It provides consistent checkpointing and process migration mechanism for MPI and PVM applications.
Reference: 13. <author> V. S. Sunderam. </author> <title> PVM: A Framework for Parallel Distributed Computing. </title> <journal> Con-currency: Practice and Experience, </journal> <volume> 2(4) </volume> <pages> 315-339, </pages> <year> 1990. </year>
Reference-contexts: The consistent checkpoint is obtained by forcing a global synchronization before al lowing a checkpoint to proceed. CoCheck [12] tries to blend the resource manage-ment capabilities of systems like Condor [7] with parallel programming libraries such as PVM <ref> [13] </ref> and MPI [4]. It provides consistent checkpointing and process migration mechanism for MPI and PVM applications. Stardust [1] is a system for parallel computations on a network of heterogeneous workstations. It captures the state of the computation at the barrier synchronization points in the parallel program.
Reference: 14. <author> Leslie G. Valiant. </author> <title> A Bridging Model for Parallel Computation. </title> <journal> Communications of the ACM, </journal> <volume> 33(8) </volume> <pages> 103-111, </pages> <month> August </month> <year> 1990. </year> <title> This article was processed using the L A T E X macro package with LLNCS style </title>
Reference-contexts: However parallel programs, with interdependencies among their component processes, can not make progress if some of the participating workstations become unavailable during the computation. Parallel computations in such environments must adapt to the changing computing environment to deliver acceptable performance. Bulk-Synchronous Parallel (BSP) model <ref> [14] </ref> is a universal abstraction of a parallel computer. By providing an intermediate level of abstraction between hardware and software, BSP offers a model for general purpose, architecture independent parallel programming. <p> In section 6, we briefly discuss the performance of the adaptive replication system and present performance results for two applications. Finally, we summarize our work and conclude in section 7. 2 Adaptive Parallel Computations in Virtual BSP Computer 2.1 Model of Parallel Computation In the Bulk-Synchronous Parallel model <ref> [14] </ref> the parallel computation proceeds as a series of supersteps comprising of computation and communication operations. All the participating processors synchronize at the end of the superstep. <p> In addition, our approach to replicating computations of a failed process can easily be extended to work across heterogeneous architectures by providing automatic conversion of data representations. 4 Design of the Adaptive Replication System The Adaptive Replication System is designed within the framework of the BSP model <ref> [14] </ref> and developed using the Oxford BSP Library [8]. ARS consists of dynamic extensions to the Oxford BSP library and the adaptive replication scheme. The adaptive replication scheme is designed in two levels of abstraction: replication layer and user layer.
References-found: 14

