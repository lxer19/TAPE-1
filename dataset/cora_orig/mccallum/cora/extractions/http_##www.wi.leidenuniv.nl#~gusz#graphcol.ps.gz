URL: http://www.wi.leidenuniv.nl/~gusz/graphcol.ps.gz
Refering-URL: http://www.wi.leidenuniv.nl/~jvhemert/csp-ea/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: gusz@wi.leidenuniv.nl  jvdhauw@wi.leidenuniv.nl  
Title: Graph Coloring with Adaptive Genetic Algorithms  
Author: A.E. Eiben J.K. van der Hauw 
Address: P.O. Box 9512 2300 RA Leiden The Netherlands  P.O. Box 9512 2300 RA Leiden The Netherlands  
Affiliation: Leiden University Dept. of Computer Science  Leiden University Dept. of Computer Science  
Abstract: This technical report summarizes our results on solving graph coloring problems with Genetic Algorithms (GA). After testing many different options we conclude that the best one is a (1+1) order-based GA using an adaptation mechanism that periodically changes the fitness function, thus guiding the GA through the search space. Except from the decoder (fitness function) this GA is general, using no domain specific knowledge. We compare this GA to a powerful traditional graph coloring technique, DSatur, on a wide range of problems with different size, topology and edge density. The results show that the GA is superior to DSatur on the hardest problem instances and it scales up better with the problem size. The GA exhibits a linear time complexity for one measure and indicates a polynomial time complexity for another one. This report is also available at http://www.wi.leidenuniv.nl/TechRep/tr96-11.html 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Arabas, Z. Michalewicz, and J.J. Mulawka. </author> <title> GAVaPS a genetic algorithm with varying population size. </title> <booktitle> In First IEEE conference on Evolutionary Computation, </booktitle> <pages> pages 306-311, </pages> <year> 1994. </year>
Reference-contexts: The entropy belonging to one gene i is then: E i = j=1;n ij 6=0 N N and P L L Thus E is a normalized value in the interval <ref> [0; 1] </ref>. The minimum will be when all individuals are identical. The maximum will be when all gene values are uniformly distributed, as will be the expected case in the initial situation. <p> Adaptive operator probabilities are used in [11], [28], White and Oppacher adapt the crossover mechanism itself [43]. GAs with variable population size form a particular implementation of the basic idea by assigning lifetimes to individuals based on their fitness, <ref> [1] </ref>. Self-adaptive parameters are encoded in the chromosomes and undergo evolution themselves. As opposed to the previous two techniques, here there is not even an indirect user control of this parameter. A very well-known example is the mutation step size in ES [37] and in EP [20].
Reference: [2] <author> S. Arora, C. Lund, R. Motwani, M. Sudan, and M. Szegedy. </author> <title> Proof verification and hardness of approximation problems. </title> <booktitle> In Proceedings 33rd IEEE Symposium on the Foundations of Computer Science, </booktitle> <pages> pages 14-23, </pages> <address> Los Angeles, CA, </address> <year> 1992. </year> <note> IEEE Computer Sociecty. </note>
Reference-contexts: And if we assume P 6= N P for the optimization variants, there is an * &gt; 0 such that no polynomial time approximation algorithm for these problems can find a solution that is guaranteed to be within a ratio of jV j * of optimal <ref> [2] </ref>.
Reference: [3] <author> T. </author> <title> Back. The interaction of mutation rate, selection, and self-adaption within a genetic algorithm. </title> <editor> In R. Manner and B. Manderick, editors, </editor> <booktitle> Parellel Problem Solving from Nature - 2, </booktitle> <pages> pages 85-94. </pages> <publisher> North-Holland, </publisher> <year> 1992. </year>
Reference-contexts: As opposed to the previous two techniques, here there is not even an indirect user control of this parameter. A very well-known example is the mutation step size in ES [37] and in EP [20]. An adoptation of this technique for genetic algorithms is studied for instance by Back <ref> [3, 4] </ref> and Hinterding [26]. It is clear that varying parameters suit the general EA spirit better than static ones. Besides they have technical advantages. First of all, they lead to increased performance.
Reference: [4] <author> T. </author> <title> Back. Self-adaptation in genetic algorithms. </title> <editor> In F.J. Varela and P. Bourgine, editors, </editor> <booktitle> Proceedings of the first European Conference on Artificial Life, </booktitle> <pages> pages 263-271. </pages> <publisher> MIT Press, </publisher> <year> 1992. </year>
Reference-contexts: As opposed to the previous two techniques, here there is not even an indirect user control of this parameter. A very well-known example is the mutation step size in ES [37] and in EP [20]. An adoptation of this technique for genetic algorithms is studied for instance by Back <ref> [3, 4] </ref> and Hinterding [26]. It is clear that varying parameters suit the general EA spirit better than static ones. Besides they have technical advantages. First of all, they lead to increased performance.
Reference: [5] <author> T. Back and M. Schutz. </author> <title> Intelligent mutation rate control in canonical genetic algorithms. </title> <type> Technical report, </type> <institution> Center for Applied Systems Analysis, </institution> <address> Joseph-von-Fraunhofer-Str. 20, D-44227 Dortmund, </address> <year> 1996. </year>
Reference-contexts: This schedule typically assignes new values depending on time, most commonly the number of generations or fitness evaluations. An early example is the changing mutation rate of Fogarty [19], more recent applications are the `cooling schedules' of Hesser and Manner [25], Back and Schutz <ref> [5] </ref> or the non-uniform mutation of Michalewicz [33]. Adaptive parameters obtain new values by a feedback mechanism that monitors the evolution. The new values typically depend on the achieved progress. This progress measure is the input of a mechanism that resets the parameter.
Reference: [6] <author> A. Blum. </author> <title> An O(n 0:4 )-approximation algorithm for 3-coloring (and improved approximation algorithms for k-coloring). </title> <booktitle> In Proceedings of the 21st ACM Symposium on Theory of Computing, </booktitle> <pages> pages 535-542, </pages> <address> New York, 1989. </address> <publisher> ACM. </publisher>
Reference-contexts: Some existing algorithms are: an O (n 0:4 )-approximation algorithm by Blum <ref> [6] </ref>, the simple Greedy algorithm [31], DSatur from Brelaz [7], Iterated Greedy (IG) from Culberson and Luo [10], XRLF from Johnson et al. [27]. 2.2.1 The Greedy Algorithm A simple and well known algorithm for many problems is the greedy algorithm, which for graph coloring implies: For some ordering of the
Reference: [7] <author> D. Brelaz. </author> <title> New methods to color vertices of a graph. </title> <journal> Communications of the ACM, </journal> <volume> 22 </volume> <pages> 251-256, </pages> <year> 1979. </year>
Reference-contexts: We also select one traditional graph coloring technique to serve as the competitor we compare our GAs with. We choose DSatur, <ref> [7] </ref>, for its high performance. In Section 3 we discuss performance measures for comparison of different algorithms. We choose the probability of finding a solution (GAs and DSatur are stochastic algorithms) and the average number of search steps needed to find a solution, for our investigation. <p> Some existing algorithms are: an O (n 0:4 )-approximation algorithm by Blum [6], the simple Greedy algorithm [31], DSatur from Brelaz <ref> [7] </ref>, Iterated Greedy (IG) from Culberson and Luo [10], XRLF from Johnson et al. [27]. 2.2.1 The Greedy Algorithm A simple and well known algorithm for many problems is the greedy algorithm, which for graph coloring implies: For some ordering of the nodes of a graph, color the nodes in this <p> The reason to 3 The colors are ordered just to make selection possible. 7 mention it here is that the GA with order-based representation uses it as a decoder, see Section 4.2. 2.2.2 DSatur DSatur from Brelaz <ref> [7] </ref> uses a heuristic to dynamically change the ordering of the nodes and then applies the greedy method to color the nodes.
Reference: [8] <author> G.J. Chaitin. </author> <title> Register allocation and spilling via graph coloring. </title> <booktitle> In Proceedings of the ACM SIGPLAN 82 Symposium on Compiler Construction, </booktitle> <pages> pages 98-105. </pages> <publisher> ACM Press, </publisher> <year> 1982. </year>
Reference-contexts: Although no good polynomial algorithm exists for general graphs, there are many specific applications like register allocation <ref> [8] </ref>, time-tabling [42], scheduling and printed circuit testing [23] for 1 Thus, we only investigate graph instances that are 3-colorable. 4 which an algorithm can exist with a good expected performance for a specific class of graphs.
Reference: [9] <author> S.H. Clearwater and T. Hogg. </author> <title> Problem structure heuristics and scaling behavior for genetic algorithms. </title> <journal> Artificial Intelligence, </journal> <volume> 81 </volume> <pages> 327-347, </pages> <year> 1996. </year>
Reference-contexts: On Figure 1 the phase transition is clearly visible by the extreme drop in performance of DSatur. Clearwater and Hogg did a lot of research about the phase transition and developed some theory around it <ref> [9] </ref>. They use Walsh polynomials to model a CSP and to predict the cost function for simple backtrack search. This function can be used to predict where a peak in its cost will occur.
Reference: [10] <author> J.C. Culberson and F. Luo. </author> <title> Exploring the k-colorable landscape with iterated greedy. In Second DIMACS Challenge, </title> <journal> Discrete Mathematics and Theoretical Computer Science. AMS, </journal> <note> 1995. Available http://web.cs.ualberta.ca/~joe/. </note>
Reference-contexts: More information on these classes can be found in <ref> [10] </ref>. Creating test graphs happens by first pre-partitioning the vertices in three sets (3 colors) and then drawing edges randomly. <p> Some existing algorithms are: an O (n 0:4 )-approximation algorithm by Blum [6], the simple Greedy algorithm [31], DSatur from Brelaz [7], Iterated Greedy (IG) from Culberson and Luo <ref> [10] </ref>, XRLF from Johnson et al. [27]. 2.2.1 The Greedy Algorithm A simple and well known algorithm for many problems is the greedy algorithm, which for graph coloring implies: For some ordering of the nodes of a graph, color the nodes in this order with the smallest 3 color that is
Reference: [11] <author> L. Davis. </author> <title> Adapting operator probabilities in genetic algorithms. </title> <editor> In J. D. Schaffer, editor, </editor> <booktitle> Proceedings of the third International Conference on Genetic Algorithms, </booktitle> <pages> pages 61-69. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1989. </year> <month> 40 </month>
Reference-contexts: Adaptive parameters obtain new values by a feedback mechanism that monitors the evolution. The new values typically depend on the achieved progress. This progress measure is the input of a mechanism that resets the parameter. Adaptive operator probabilities are used in <ref> [11] </ref>, [28], White and Oppacher adapt the crossover mechanism itself [43]. GAs with variable population size form a particular implementation of the basic idea by assigning lifetimes to individuals based on their fitness, [1]. Self-adaptive parameters are encoded in the chromosomes and undergo evolution themselves.
Reference: [12] <author> A.E. Eiben, C.H.M. van Kemenade, and J.N. Kok. </author> <title> Orgy in the computer: Multi--parent reproduction in genetic algorithms,. </title> <editor> In F. Moran, A. Moreno, J.J. Merelo, and P. Chacon, editors, </editor> <booktitle> Proceedings of the 3rd European Conference on Artificial Life, number 929 in LNAI, </booktitle> <pages> pages 934-945. </pages> <publisher> Springer-Verlag, </publisher> <year> 1995. </year>
Reference-contexts: First we tried different operators: the traditional m-point, uniform and HUX crossovers, [17], and the multi-parent diagonal and scanning crossovers, [13], <ref> [12] </ref>. The results are given in Table 2.
Reference: [13] <author> A.E. Eiben, P.-E. Raue, and Zs. Ruttkay. </author> <title> Genetic algorithms with multi-parent recombination. </title> <editor> In Y. Davidor, editor, </editor> <booktitle> Parallel Problem Solving from Nature - 3, </booktitle> <volume> LNCS 866, </volume> <pages> pages 78-87. </pages> <publisher> Springer-Verlag, </publisher> <year> 1994. </year>
Reference-contexts: First we tried different operators: the traditional m-point, uniform and HUX crossovers, [17], and the multi-parent diagonal and scanning crossovers, <ref> [13] </ref>, [12]. The results are given in Table 2.
Reference: [14] <author> A.E. Eiben, P.-E. Raue, and Zs. Ruttkay. </author> <title> Repairing, adding constraints and learning as a means of improving GA performance on CSPs. </title> <editor> In M. Meyer, editor, </editor> <booktitle> Benelearn '94 Proceedings of the 4th Belgian-Dutch Conference on Machine Learning, </booktitle> <pages> pages 112-123, </pages> <year> 1994. </year>
Reference-contexts: This also reduces the chance for incorrect parameter settings. 26 4.5.2 GA with Stepwise Adaptation of Weights The adaptive approach we advocate here amounts to modifying the weigths of edges, respectively nodes, hence modifying the penalty function. This technique was introduced for constraint solving with GAs in <ref> [14] </ref> and [16]. The rationale behind it is that satisfying a constraint with a high penalty gives relatively high reward to the GA, hence the GA will be 'more interested' in satisfying such constraints. Thus, using appropriate weights can improve the performance. <p> run the GA with this f redefine f after termination END FOR ON-LINE SAW set initial weights (thus fitness function f) WHILE NOT termination DO FOR the next Tp fitness evaluations let the GA go with this f END FOR redefine f and recalculate fitness of individuals END DO In <ref> [14] </ref> and [16] the off-line version was applied, here we will use the on-line version modifying the weights, hence modifying the fitness function, during the evolution.
Reference: [15] <author> A.E. Eiben, P.-E. Raue, and Zs. Ruttkay. </author> <title> Solving constraint satisfaction problems using genetic algorithms. </title> <booktitle> In First IEEE conference on Evolutionary Computation, </booktitle> <pages> pages 542-547. </pages> <publisher> IEEE Service Center, </publisher> <year> 1994. </year>
Reference-contexts: However, increasing the population size while keeping T max constant can have positive effects on the performance <ref> [15] </ref>. We have examined the effect of changing for uniform, SCUN 5 , DIAG 35 and (2-parent) 34-point crossover, in each case with IP (SE), on two graphs: G eq;n=200;p=0:08;s=5 and G eq;n=1000;p=0:025;s=5 . The results are shown in Figure 8 and Figure 9. <p> Sexual Reproduction Recently, there are discussions on whether sexual reproduction has any advantage above asexual reproduction. In <ref> [15] </ref> several unary operators are compared for the Graph 3-Coloring problem with uniform crossover and a standard mutation for n = 50 with = 200. The best results came when using a unary operator (and no crossover). Thus, reasons enough to investigate the performance of a GA using mutation only.
Reference: [16] <author> A.E. Eiben and Zs. Ruttkay. </author> <title> Self-adaptivity for constraint satisfaction: Learning penalty functions. </title> <booktitle> In Third IEEE Conference on Evolutionary Computation, </booktitle> <pages> pages 258-261. </pages> <publisher> IEEE Service Center, </publisher> <year> 1996. </year>
Reference-contexts: This also reduces the chance for incorrect parameter settings. 26 4.5.2 GA with Stepwise Adaptation of Weights The adaptive approach we advocate here amounts to modifying the weigths of edges, respectively nodes, hence modifying the penalty function. This technique was introduced for constraint solving with GAs in [14] and <ref> [16] </ref>. The rationale behind it is that satisfying a constraint with a high penalty gives relatively high reward to the GA, hence the GA will be 'more interested' in satisfying such constraints. Thus, using appropriate weights can improve the performance. <p> GA with this f redefine f after termination END FOR ON-LINE SAW set initial weights (thus fitness function f) WHILE NOT termination DO FOR the next Tp fitness evaluations let the GA go with this f END FOR redefine f and recalculate fitness of individuals END DO In [14] and <ref> [16] </ref> the off-line version was applied, here we will use the on-line version modifying the weights, hence modifying the fitness function, during the evolution.
Reference: [17] <author> L.J. Eshelman. </author> <title> The CHC adaptive search algorithm: How to have safe search when engaging in nontraditional genetic recombination. </title> <booktitle> In Foundations of Genetic Algorithms - 1, </booktitle> <pages> pages 265-283, </pages> <year> 1991. </year>
Reference-contexts: It is obvious that when the minimum penalty of zero is reached, no constraints are violated and a solution is found. 4.1.1 Recombination Operators To optimize our GA we compared different settings. First we tried different operators: the traditional m-point, uniform and HUX crossovers, <ref> [17] </ref>, and the multi-parent diagonal and scanning crossovers, [13], [12]. The results are given in Table 2. <p> The optimal number of parents for diagonal crossover lies in the higher regions, in the sequel we will only use the 35 parents version. 12 13 14 4.1.2 Recombination with Incest Prevention In <ref> [17] </ref> Eshelman proposed restrictions on mating in order to prevent fast decrease of genetic diversity in the population. The idea is to forbid mating between similar individuals (that can be seen as 'relatives') and only recombine parents that are sufficiently different.
Reference: [18] <author> C. Fleurent and J.A. Ferland. </author> <title> Genetic and hybrid algorithms for graph coloring. </title> <editor> In I. H. Osman G. Laporte and P. L. Hammer, editors, </editor> <booktitle> Annals of Operations Research, Metaheuristics in Combinatorial Optimization, </booktitle> <institution> Universite de Montreal, Departement d'Informatique et de Recherche Operationalle, Canada, </institution> <year> 1994. </year> <note> Available via ftp://ftp.iro.umontreal.ca/pub/optim/fleurent/papers/coloring/coloring.ps.Z. </note>
Reference-contexts: In the sequel we will refer to this technique as IP (Incest Prevention). For the multi-parent operators Hamming distance is not applicable, therefore we will measure the diversity among the selected parents instead. As a measure of diversity we apply the entropy <ref> [18] </ref>. Let us assume that we use a k-ary alphabet, i.e., each gene i, (i = 1; : : : ; L) can take a value j 2 f1; : : : ; kg.
Reference: [19] <author> T.C. Fogarty. </author> <title> Varying the probability of mutation in the genetic algorithm. </title> <booktitle> In Proceedings of the third International Conference on Genetic Algorithms, </booktitle> <pages> pages 104-109, </pages> <year> 1989. </year>
Reference-contexts: Dynamic parameters obtain different values along the evolution prescribed by a user defined schedule. This schedule typically assignes new values depending on time, most commonly the number of generations or fitness evaluations. An early example is the changing mutation rate of Fogarty <ref> [19] </ref>, more recent applications are the `cooling schedules' of Hesser and Manner [25], Back and Schutz [5] or the non-uniform mutation of Michalewicz [33]. Adaptive parameters obtain new values by a feedback mechanism that monitors the evolution. The new values typically depend on the achieved progress.
Reference: [20] <editor> D.B. Fogel. </editor> <booktitle> Evolutionary Programming. </booktitle> <publisher> IEEE Press, </publisher> <year> 1995. </year>
Reference-contexts: 1 Introduction The main goal of this report is to present our results on solving graph coloring problems by Genetic Algorithms (GAs). We omit a general introduction of Evolutionary Computation, instead we refer to some literature, <ref> [20] </ref>, [29], [33], [37]. This report is organized as follows. In Section 2 we give a brief overview of graph coloring problems and traditional graph coloring techniques. <p> Self-adaptive parameters are encoded in the chromosomes and undergo evolution themselves. As opposed to the previous two techniques, here there is not even an indirect user control of this parameter. A very well-known example is the mutation step size in ES [37] and in EP <ref> [20] </ref>. An adoptation of this technique for genetic algorithms is studied for instance by Back [3, 4] and Hinterding [26]. It is clear that varying parameters suit the general EA spirit better than static ones. Besides they have technical advantages. First of all, they lead to increased performance.
Reference: [21] <author> B.R. Fox and M.B. McMahon. </author> <title> Genetic operators for sequencing problems. </title> <booktitle> In Foundations of Genetic Algorithms - 1, </booktitle> <pages> pages 284-300, </pages> <year> 1991. </year>
Reference-contexts: main conclusion of this section is that the best integer representation GA is the simplest one, using a (1 + 1) scheme and mutation as the only search operator. 18 4.2 Order-based Representation In order-based GAs the individuals are permutations and special operators are used to recombine and mutate permutations <ref> [21, 38] </ref>. Applying an order-based GA for graph coloring is based on the idea of defining chromosomes as permutations of nodes and defining a decoder that constructs a coloring from a permuatation. <p> Both types of problems need different kind of operators 4 Giving just a random color if no other colors are left has also been tried, but this gave worse results. 19 and several studies have been done to compare operators on both types of problems ([38], <ref> [21] </ref> and [32]).
Reference: [22] <author> M.R. Garey and D.S. Johnson. </author> <title> Computers and Intractability: A Guide to the Theory of NP-Completeness. W.H. </title> <publisher> Freedman and Co., </publisher> <year> 1979. </year>
Reference-contexts: There exist several variations of this problem, like finding the least number of colors that is needed to color the graph, or to find the largest subgraph in G that can be colored with the given number of colors. All of these problems are known to be NP-complete <ref> [22] </ref>, so it is unlikely that a polynomial-time algorithm exists that solves any of these problems.
Reference: [23] <author> M.R. Garey, D.S. Johnson, and H.C. </author> <title> So. An application of graph coloring to printed circuit testing. </title> <journal> IEEE Trans. on Circuits and Systems, </journal> <volume> CAS-23:591-599, </volume> <year> 1976. </year> <month> 41 </month>
Reference-contexts: Although no good polynomial algorithm exists for general graphs, there are many specific applications like register allocation [8], time-tabling [42], scheduling and printed circuit testing <ref> [23] </ref> for 1 Thus, we only investigate graph instances that are 3-colorable. 4 which an algorithm can exist with a good expected performance for a specific class of graphs. Graph Coloring can also be seen as a member of the class of Constraint Satisfaction Problems (CSPs).
Reference: [24] <author> G.R. Grimmet and C.J.H. McDiarmid. </author> <title> On colouring random graphs. </title> <booktitle> Mathematical Proceedings of the Cambridge Philosophical Society, </booktitle> <volume> 77 </volume> <pages> 313-324, </pages> <year> 1975. </year>
Reference-contexts: This ordering often is random, but some heuristics can be used to determine the ordering. Grimmet and McDiarmid <ref> [24] </ref> have shown that for almost all random graphs the greedy algorithm uses no more than about twice the optimal number of colors. Nevertheless, several studies showed that in practice and in theory, the greedy algorithm performs poorly [31, 40].
Reference: [25] <author> J. Hesser and R. </author> <title> Manner. Towards an optimal mutation probability in genetic algorithms. </title> <editor> In H.-P. Schwefel, editor, </editor> <booktitle> Parallel Problem Solving from Nature - 1, </booktitle> <volume> LNCS 496, </volume> <pages> pages 23-32. </pages> <publisher> Springer-Verlag, </publisher> <year> 1991. </year>
Reference-contexts: This schedule typically assignes new values depending on time, most commonly the number of generations or fitness evaluations. An early example is the changing mutation rate of Fogarty [19], more recent applications are the `cooling schedules' of Hesser and Manner <ref> [25] </ref>, Back and Schutz [5] or the non-uniform mutation of Michalewicz [33]. Adaptive parameters obtain new values by a feedback mechanism that monitors the evolution. The new values typically depend on the achieved progress. This progress measure is the input of a mechanism that resets the parameter.
Reference: [26] <author> R. Hinterding. </author> <title> Gaussian mutation and self-adaptation for numeric genetic algorithms. </title> <booktitle> In Second IEEE Conference on Evolutionary Computation, </booktitle> <pages> pages 384-389. </pages> <publisher> IEEE Service Center, </publisher> <year> 1995. </year>
Reference-contexts: A very well-known example is the mutation step size in ES [37] and in EP [20]. An adoptation of this technique for genetic algorithms is studied for instance by Back [3, 4] and Hinterding <ref> [26] </ref>. It is clear that varying parameters suit the general EA spirit better than static ones. Besides they have technical advantages. First of all, they lead to increased performance. Secondly, adaptive and self-adaptive parameters free the user from determining these parameters by having the EA doing it.
Reference: [27] <author> D.S. Johnson, C.R. Aragon, L.A. McGeoch, and C. Schevon. </author> <title> Optimization by simulated annealing: An experimental evaluation; part II, graph coloring and number partitioning. </title> <journal> Operations Research, </journal> <volume> 39(3) </volume> <pages> 378-406, </pages> <year> 1991. </year>
Reference-contexts: Some existing algorithms are: an O (n 0:4 )-approximation algorithm by Blum [6], the simple Greedy algorithm [31], DSatur from Brelaz [7], Iterated Greedy (IG) from Culberson and Luo [10], XRLF from Johnson et al. <ref> [27] </ref>. 2.2.1 The Greedy Algorithm A simple and well known algorithm for many problems is the greedy algorithm, which for graph coloring implies: For some ordering of the nodes of a graph, color the nodes in this order with the smallest 3 color that is possible without violating constraints.
Reference: [28] <author> B. A. Julstrom. </author> <title> What have you done for me lately? Adapting operator probabilities in a steady-state genetic algorithm. </title> <booktitle> In Proceedings of the sixth International Conference on Genetic Algorithms, </booktitle> <pages> pages 81-87, </pages> <year> 1995. </year>
Reference-contexts: Adaptive parameters obtain new values by a feedback mechanism that monitors the evolution. The new values typically depend on the achieved progress. This progress measure is the input of a mechanism that resets the parameter. Adaptive operator probabilities are used in [11], <ref> [28] </ref>, White and Oppacher adapt the crossover mechanism itself [43]. GAs with variable population size form a particular implementation of the basic idea by assigning lifetimes to individuals based on their fitness, [1]. Self-adaptive parameters are encoded in the chromosomes and undergo evolution themselves.
Reference: [29] <editor> J.R. Koza. </editor> <booktitle> Genetic Programming. </booktitle> <publisher> MIT Press, </publisher> <year> 1992. </year>
Reference-contexts: 1 Introduction The main goal of this report is to present our results on solving graph coloring problems by Genetic Algorithms (GAs). We omit a general introduction of Evolutionary Computation, instead we refer to some literature, [20], <ref> [29] </ref>, [33], [37]. This report is organized as follows. In Section 2 we give a brief overview of graph coloring problems and traditional graph coloring techniques. <p> runs of length t) = 1 P (no solutions in r runs of length t) = 1 (1 SR t ) r We can compute the number of runs r ff (with length T max = t) needed to find at least one solution with some given certainty ff, cf. <ref> [29] </ref>, pg. 193. as follows: (1 SR t ) r ff = 1 ff if and only if r ff = (1SR t ) log (1 ff) = log (1 SR t ) Now EFE ff := r ff t is the Expected number of Fitness Evaluations (search steps) needed to
Reference: [30] <author> L. Kronsjo. </author> <title> Algorithms: Their Complexity and Efficiency. </title> <publisher> Wiley and Sons, </publisher> <address> second edition, </address> <year> 1987. </year>
Reference-contexts: CPU time in seconds. This amounts to using time complexity for evaluating algorithms, <ref> [30] </ref>. Of course the CPU time depends on the specific implementation and on the hardware, thus even the same research group can get different results when running the experiments on another computer. Therefore, an implementation and hardware independent measure is preferable.
Reference: [31] <author> L. Kucera. </author> <title> The greedy coloring is a bad probabilistic algorithm. </title> <journal> Journal of Algorithms, </journal> <volume> 12 </volume> <pages> 674-684, </pages> <year> 1991. </year>
Reference-contexts: Some existing algorithms are: an O (n 0:4 )-approximation algorithm by Blum [6], the simple Greedy algorithm <ref> [31] </ref>, DSatur from Brelaz [7], Iterated Greedy (IG) from Culberson and Luo [10], XRLF from Johnson et al. [27]. 2.2.1 The Greedy Algorithm A simple and well known algorithm for many problems is the greedy algorithm, which for graph coloring implies: For some ordering of the nodes of a graph, color <p> Grimmet and McDiarmid [24] have shown that for almost all random graphs the greedy algorithm uses no more than about twice the optimal number of colors. Nevertheless, several studies showed that in practice and in theory, the greedy algorithm performs poorly <ref> [31, 40] </ref>. Our experiments with the greedy algorithm (not included in this report) confirmed that it performs very poorly, even quite far from the phase transition.
Reference: [32] <author> B. Manderick and P. Spiessens. </author> <title> How to select genetic operators for combinatorial optimization problems by analyzing their fitness landscape. </title> <editor> In J.C. Bioch and X.-H. Tan, editors, </editor> <booktitle> Proceedings of the 7th Dutch Conference on Artificial Intelligence, </booktitle> <pages> pages 127-136, </pages> <year> 1995. </year>
Reference-contexts: Both types of problems need different kind of operators 4 Giving just a random color if no other colors are left has also been tried, but this gave worse results. 19 and several studies have been done to compare operators on both types of problems ([38], [21] and <ref> [32] </ref>). <p> In [38] the most important order-based operators are described and compared and it shows that for scheduling-like problems order crossover #2 (OX2) by Syswerda [39] is the best operator. This can also be seen in the study of Manderick and Spiessens <ref> [32] </ref> that shows that a position-based operator is the best operator for a scheduling problem. Here OX, OX2, PMX, Cycle crossover and SWAP, RAR and Inversion mutation are compared.
Reference: [33] <author> Z. Michalewicz. </author> <title> Genetic Algorithms + Data structures = Evolution programs. </title> <publisher> Springer-Verlag, </publisher> <address> third edition, </address> <year> 1996. </year>
Reference-contexts: 1 Introduction The main goal of this report is to present our results on solving graph coloring problems by Genetic Algorithms (GAs). We omit a general introduction of Evolutionary Computation, instead we refer to some literature, [20], [29], <ref> [33] </ref>, [37]. This report is organized as follows. In Section 2 we give a brief overview of graph coloring problems and traditional graph coloring techniques. <p> An early example is the changing mutation rate of Fogarty [19], more recent applications are the `cooling schedules' of Hesser and Manner [25], Back and Schutz [5] or the non-uniform mutation of Michalewicz <ref> [33] </ref>. Adaptive parameters obtain new values by a feedback mechanism that monitors the evolution. The new values typically depend on the achieved progress. This progress measure is the input of a mechanism that resets the parameter.
Reference: [34] <author> Z. Michalewicz. </author> <type> personal communication. </type> <year> 1996. </year>
Reference-contexts: This accumulates knowledge on a research area that is thus becoming an emerging sub-technology within evolutionary computation. 4.5.1 Dynamic, adaptive and self-adaptive parameters Looking at related work on varying parameters in EAs one can distinguish common features several approaches share. This allows us to classify three different streams <ref> [34] </ref>. Dynamic parameters obtain different values along the evolution prescribed by a user defined schedule. This schedule typically assignes new values depending on time, most commonly the number of generations or fitness evaluations.
Reference: [35] <author> B. Nudel. </author> <title> Consistent-labeling problems and their algorithms: Expected complexities and theory based heuristics. </title> <journal> Journal of Artificial Intelligence, </journal> <volume> 21 </volume> <pages> 135-178, </pages> <year> 1983. </year>
Reference-contexts: One may be interested in one, some or all solutions, or only in the existence of a solution. It has been proved that every CSP can be equivalently transformed to a binary one, i.e. to a CSP where each individual constraint concerns exactly two variables, <ref> [35] </ref>. So the results that are found in this research might be applicable to other CSPs as well. 2.1.1 Problem Instances In the literature there are not many benchmark 3-colorable graphs and therefore new graphs are created with the graph generator 2 written by Joe Culberson.
Reference: [36] <author> B. Kenefsky P. Cheeseman and W. M. Taylor. </author> <title> Where the really hard problems are. </title> <booktitle> In Proceedings of the International Joint Conference on Artifical Intelligence, </booktitle> <pages> pages 331-337, </pages> <year> 1991. </year>
Reference-contexts: Turner [40] found that many k-colorable graphs are easy to color, so comparisons between algorithms based on these graphs are not very meaningful. For an interesting comparison one should look for harder problem instances that pose some challenges for candidate algorithms to overcome. Cheeseman et al. <ref> [36] </ref> found that NP-complete problems have an "order" parameter and that the hard problems occur at a critical value or phase transition of such a parameter. This phase transition will be at the point where the problem changes from under-constrained to over-constrained.
Reference: [37] <author> H.-P. Schwefel. </author> <title> Evolution and Optimum Seeking. </title> <booktitle> Sixth-Generation Computer Technology Series. </booktitle> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1995. </year> <month> 42 </month>
Reference-contexts: 1 Introduction The main goal of this report is to present our results on solving graph coloring problems by Genetic Algorithms (GAs). We omit a general introduction of Evolutionary Computation, instead we refer to some literature, [20], [29], [33], <ref> [37] </ref>. This report is organized as follows. In Section 2 we give a brief overview of graph coloring problems and traditional graph coloring techniques. <p> Self-adaptive parameters are encoded in the chromosomes and undergo evolution themselves. As opposed to the previous two techniques, here there is not even an indirect user control of this parameter. A very well-known example is the mutation step size in ES <ref> [37] </ref> and in EP [20]. An adoptation of this technique for genetic algorithms is studied for instance by Back [3, 4] and Hinterding [26]. It is clear that varying parameters suit the general EA spirit better than static ones. Besides they have technical advantages.
Reference: [38] <author> T. Starkweather, S. McDaniel, K. Mathias, D. Whitley, and C. Whiley. </author> <title> A comparison of genetic sequencing operators. </title> <editor> In R.K. Belew and L.B. Booker, editors, </editor> <booktitle> Proceedings of the fourth International Conference on Genetic Algorithms, </booktitle> <pages> pages 69-76. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1991. </year>
Reference-contexts: main conclusion of this section is that the best integer representation GA is the simplest one, using a (1 + 1) scheme and mutation as the only search operator. 18 4.2 Order-based Representation In order-based GAs the individuals are permutations and special operators are used to recombine and mutate permutations <ref> [21, 38] </ref>. Applying an order-based GA for graph coloring is based on the idea of defining chromosomes as permutations of nodes and defining a decoder that constructs a coloring from a permuatation. <p> In <ref> [38] </ref> the most important order-based operators are described and compared and it shows that for scheduling-like problems order crossover #2 (OX2) by Syswerda [39] is the best operator.
Reference: [39] <author> G. Syswerda. </author> <title> Schedule optimization using genetic algorithms. </title> <editor> In L. Davis, editor, </editor> <booktitle> Handbook of Genetic Algorithms, chapter 21, </booktitle> <pages> pages 332-349. </pages> <publisher> Van Nostrand Reinhold, </publisher> <address> New York, </address> <year> 1990. </year>
Reference-contexts: In [38] the most important order-based operators are described and compared and it shows that for scheduling-like problems order crossover #2 (OX2) by Syswerda <ref> [39] </ref> is the best operator. This can also be seen in the study of Manderick and Spiessens [32] that shows that a position-based operator is the best operator for a scheduling problem. Here OX, OX2, PMX, Cycle crossover and SWAP, RAR and Inversion mutation are compared.
Reference: [40] <author> Jonathan S. Turner. </author> <title> Almost all k-colorable graphs are easy to color. </title> <journal> Journal of Algorithms, </journal> <volume> 9 </volume> <pages> 63-82, </pages> <year> 1988. </year>
Reference-contexts: Turner <ref> [40] </ref> found that many k-colorable graphs are easy to color, so comparisons between algorithms based on these graphs are not very meaningful. For an interesting comparison one should look for harder problem instances that pose some challenges for candidate algorithms to overcome. <p> Grimmet and McDiarmid [24] have shown that for almost all random graphs the greedy algorithm uses no more than about twice the optimal number of colors. Nevertheless, several studies showed that in practice and in theory, the greedy algorithm performs poorly <ref> [31, 40] </ref>. Our experiments with the greedy algorithm (not included in this report) confirmed that it performs very poorly, even quite far from the phase transition. <p> Because of the random tie breaking, DSatur becomes a stochastic algorithm and just like for the GA, results of several runs need to be averaged to obtain useful statistics. For our investigation the implementation of Turner <ref> [40] </ref> has been implemented that uses heaps to dynamically keep the nodes ordered to saturation degree. A backtrack version of the algorithm is used which backtracks to the lastly evaluated node that still has available colors to try.
Reference: [41] <author> J.K. van der Hauw. </author> <title> Evaluating and Improving Steady State Evolutionary Algorithms on Constraint Satisfaction Problems. </title> <type> Mater's thesis, </type> <institution> Leiden University, </institution> <year> 1996. </year>
Reference-contexts: Sometimes the CPU time per search step will also be reported. Because the time per fitness evaluation in a GA may vary along the evolution (actually it will decrease with the number of evaluations by the special implementation of the fitness function, cf. <ref> [41] </ref>), the average time over all evaluations, abbreviated as ATE, is taken. Summarizing, we can note that neither real time, nor the number of search steps is fully satisfactory for comparing different algorithms. However, algorithms can be compared by their scale-up behavior. <p> The mutation rate is implemented in a special manner for this representation in such a way that the probability of performing X mutations (swapping X pairs of genes) in one individual equals the probability of performing X mutations in the integer representation using p m = 1=L, <ref> [41] </ref>. n = 200 n = 1000 Operators SR AES SR AES OX + No Mutation 0.24 60641 - OX + RAR 0.89 77021 0.04 274816 OX + SWAP 1.00 21195 0.16 220271 OX2 + No Mutation 0.88 17858 - OX2 + RAR 1.00 13265 0.88 65131 OX2 + SWAP 1.00
Reference: [42] <author> D. De Werra. </author> <title> An introduction to timetabling. </title> <journal> European Journal of Operations Research, </journal> <volume> 19 </volume> <pages> 151-162, </pages> <year> 1985. </year>
Reference-contexts: Although no good polynomial algorithm exists for general graphs, there are many specific applications like register allocation [8], time-tabling <ref> [42] </ref>, scheduling and printed circuit testing [23] for 1 Thus, we only investigate graph instances that are 3-colorable. 4 which an algorithm can exist with a good expected performance for a specific class of graphs.
Reference: [43] <author> T. White and F. Oppacher. </author> <title> Adaptive crossover using automata. </title> <editor> In Y. Davidor, H.-P. Schwefel, and R. Manner, editors, </editor> <booktitle> Parallel Problem Solving from Nature - 3, </booktitle> <volume> LNCS 866, </volume> <pages> pages 229-238. </pages> <publisher> Springer-Verlag, </publisher> <year> 1994. </year> <month> 43 </month>
Reference-contexts: The new values typically depend on the achieved progress. This progress measure is the input of a mechanism that resets the parameter. Adaptive operator probabilities are used in [11], [28], White and Oppacher adapt the crossover mechanism itself <ref> [43] </ref>. GAs with variable population size form a particular implementation of the basic idea by assigning lifetimes to individuals based on their fitness, [1]. Self-adaptive parameters are encoded in the chromosomes and undergo evolution themselves.
References-found: 43

