URL: http://www.ececs.uc.edu/~paw/lab/theses/rrajan.ps.gz
Refering-URL: http://www.ececs.uc.edu/~paw/lab/theses.html
Root-URL: 
Title: Dynamic Cancellation: A Heuristic for Selecting Cancellation Strategies in Time Warp Simulators  by  
Author: Raghunandan Rajan 
Degree: A thesis submitted to the  in partial fulfillment of the requirements for the degree of MASTER OF SCIENCE in the Department of Electrical and Computer Engineering of the College of Engineering  B.tech, Jawaharlal Nehru Technological University, Hyderabad, India, 1992 Thesis Advisor and Committee Chair: Dr. Philip A. Wilsey  
Date: February 19, 1996  
Affiliation: Division of Graduate Studies and Research of the University of Cincinnati  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Astrom, K. J., and Wittenmark, B. </author> <title> Adaptive Control. </title> <publisher> Addison Wesley, </publisher> <address> Reading, MA, </address> <year> 1989. </year>
Reference-contexts: The dynamic adjustment of simulation parameters requires careful design considerations. Many of these considerations are quite similar to the problems studied by traditional linear and adaptive control theorists <ref> [1] </ref>. These considerations include the need to implement an adjustment mechanism that converges to stable values and the need to understand how parameter adjustment affects (sampled) output values. However, dynamic adjustment of simulation parameters occurs by using general CPU cycles and thus intro 2 duces overhead into the simulation. <p> This results in a reduction, in the amount of work that has to be undone, leading to a shorter execution time. 5.2 Control Theory Control theory is concerned with modifying the behavior of dynamic systems so as to achieve the desired goals <ref> [1] </ref>. In general, a control system samples output values and adjusts input values in order to meet some performance criteria.
Reference: [2] <author> Ball, D., and Hoyt, S. </author> <title> The adaptive time-warp concurrency control algorithm. In Distributed Simulation (January 1990), </title> <booktitle> Society for Computer Simulation, </booktitle> <pages> pp. 174-177. </pages>
Reference-contexts: Furthermore, the optimal setting for the simulation parameters may not hold across an application domain or even throughout the entire simulation lifetime of a single application. Consequently, several investigations have proposed the dynamic adjustment of simulation parameters over the lifetime of the simulation <ref> [2, 24, 27, 33, 34, 35, 36, 41] </ref>. These investigations have shown that dynamic parameter adjustment can be used to successfully tune a Time Warp simulator for near optimal performance. The dynamic adjustment of simulation parameters requires careful design considerations. <p> One important tradeoff in a Time Warp simulation is which cancellation strategy to employ: aggressive cancellation [18] or lazy cancellation [13, 47]. Numerous studies of cancellation strategies have been performed and none has yet been unable to clearly demonstrate when one strategy consistently outperforms the other <ref> [2, 40] </ref>. The studies have only succeeded in showing that aggressive cancellation is more sensitive to optimal parameter adjustments in the lower level communication subsystem. Thus, most currently available Time Warp simulators support both strategies and provide user control of their setting [7, 19, 26]. <p> Several independent studies have shown that while applications slightly favor lazy cancellation, some executions perform significantly better under aggressive cancellation (even within the same application domain) <ref> [2, 32, 41] </ref>. Unfortunately, practical techniques to statically analyze an application for selecting cancellation strategies have yet to be developed. <p> The overhead of checking the dependency information attached to an event-message to determine whether to discard it or not makes this algorithm a very expensive optimization, although it does reduce the number of rollbacks. Adaptive Time Warp <ref> [2] </ref> introduces conservatism into the system by allowing a process which experiences a large number of rollbacks to block for a particular time duration BW. BW is varied depending on the time spent in blocked and faulted states (duration of wasted lookahead computation). <p> Several independent studies have shown that lazy cancellation performs better than aggressive cancellation [13, 47, 3, 23]. However, these 30 studies also show that, even within the same application domain, some executions perform better under aggressive cancellation <ref> [2, 41] </ref>. In studies involving the simulation of digital systems [39] described using the hardware description language VHDL [29, 37], we have observed (confirmed) that: 1. Neither cancellation strategy is clearly superior. 2. <p> These values are a time series of discrete values that have been used in several investigations to dynamically adjust simulation parameters <ref> [2, 24, 27, 33, 34, 35, 41] </ref>. These investigations have used data filtering techniques to smooth and to prevent spurious data points from causing wide variations in parameter adjustment. In this research, we have found that non-linear thresholding functions are best suited for selecting which cancellation strategy to use.
Reference: [3] <author> Berry, O., and Jefferson, D. </author> <title> Critical path analysis of distributed simulation. </title> <booktitle> In Distributed Simulation (1985), Society for Computer Simulation, </booktitle> <pages> pp. 57-60. </pages>
Reference-contexts: By delaying cancellation (of erroneous messages), lazy cancellation may allow the erroneous computation to spread, causing more rollbacks in other processes, thereby prolonging the execution time of the simulation. Berry <ref> [3] </ref> has documented an intriguing and beneficial characteristic of lazy cancellation. She has shown that, under some circumstances, Time Warp using lazy cancellation is capable of Supercritical Speedup i.e., | it can run faster than the critical path of the equivalent sequential simulation. <p> Once LP 4 re-executes the event-message at simulation time 40, the simulation finally completes. 29 Chapter 5 Dynamic Cancellation Time Warp has received considerable attention as a PDES mechanism because its optimistic nature is well suited for exploiting the parallelism that is typically available in large simulations <ref> [10, 3] </ref>. Although the Time Warp mechanism is capable of speeding up large simulations, its potential to do so has not been fully exploited due to excessive rollbacks (resulting in instability and wastage of the lookahead computation done by the LPs). <p> Therefore, the performance of a Time Warp simulator depends on the efficiency of the cancellation strategy employed to undo the effects of the erroneous computation. Several independent studies have shown that lazy cancellation performs better than aggressive cancellation <ref> [13, 47, 3, 23] </ref>. However, these 30 studies also show that, even within the same application domain, some executions perform better under aggressive cancellation [2, 41]. In studies involving the simulation of digital systems [39] described using the hardware description language VHDL [29, 37], we have observed (confirmed) that: 1.
Reference: [4] <author> Chandy, K. M., and Sherman, R. </author> <title> Space-time and simulation. </title> <booktitle> In Distributed Simulation (1989), Society for Computer Simulation, </booktitle> <pages> pp. 53-57. </pages>
Reference-contexts: Conservative approaches rely on some strategy to determine when it is safe to process an event, and block until they have a safe event to process [28]. 8 Optimistic approaches, on the other hand, do not avoid causality errors <ref> [11, 4] </ref>. <p> <ref> [11, 4] </ref>. Instead they assume that event-messages generally arrive in time-stamp order and so proceed forward, processing the events that are available in their event queue without blocking; whenever they discover a causality violation, they use various techniques to ensure that the simulation properly reflects the correct event execution order [11, 4]. The main drawback with conservative approaches is that they heavily rely on lookahead for their performance [22].
Reference: [5] <author> Charley, D., McBrayer, T., Hensgen, D., Wilsey, P. A., and Ankola, M. </author> <title> Distributed simulation on a reconfigurable network using non-uniform message passing. </title> <booktitle> In Proc. of the 5th ISMM International Conference on Parallel and Distributed Computing and Systems (October 1992), </booktitle> <editor> R. Melhem, </editor> <publisher> Ed., </publisher> <pages> pp. 247-250. </pages>
Reference: [6] <author> Chawla, P. </author> <title> Assignment Strategies for Parallel Discrete Event Simulation of Digital Systems. </title> <type> PhD thesis, </type> <institution> University of Cincinnati, Department of Electrical and Computer Engineering, </institution> <year> 1994. </year>
Reference: [7] <author> Das, S., Fujimoto, R., Panesar, K., Allison, D., and Hybinette, M. GTW: </author> <title> a time warp system for shared memory multiprocessors. </title> <booktitle> In Proceedings of the 1994 56 Winter Simulation Conference (December 1994), </booktitle> <editor> J. D. Tew, S. Manivannan, D. A. Sadowski, and A. F. Seila, </editor> <booktitle> Eds., </booktitle> <pages> pp. 1332-1339. </pages>
Reference-contexts: The studies have only succeeded in showing that aggressive cancellation is more sensitive to optimal parameter adjustments in the lower level communication subsystem. Thus, most currently available Time Warp simulators support both strategies and provide user control of their setting <ref> [7, 19, 26] </ref>. Furthermore, while Lin [21] has attempted to analytically characterize the effective performance spaces of each cancellation strategy, the approach requires complete knowledge of simulation behaviors and is not practically applicable. Thus, the determination of cancellation strategy would seem to be a suitable candidate for dynamic selection.
Reference: [8] <author> Ferscha, A. </author> <title> Probabilistic adaptive direct optimism control in time warp. </title> <booktitle> In Proc. of the 9th Workshop on Parallel and Distributed Simulation (PADS 95) (June 1995), </booktitle> <pages> pp. 120-129. </pages>
Reference-contexts: The major disadvantage of this technique is that the processor is not utilized when all the processes are penalized by the system, thereby wasting CPU cycles. Performance results from such techniques has discouraged further use of this technique. Similar approaches to stall LP event processing are reported in <ref> [8, 16] </ref>. Breathing Time Warp [45] is a combination of Breathing Time Buckets [44] and Time Warp. This technique works on the principle that events closer to GVT have a lower probability of being rolled back.
Reference: [9] <author> Fleischmann, J., and Wilsey, P. A. </author> <title> Comparative analysis of periodic state saving techniques in time warp simulators. </title> <booktitle> In Proc. of the 9th Workshop on Parallel and Distributed Simulation (PADS 95) (June 1995), </booktitle> <pages> pp. 50-58. </pages>
Reference-contexts: The amount of wasted lookahead computation can be reduced by minimizing the number of rollbacks in the system. A variety of algorithms have been proposed to alleviate the problem of excessive memory usage due to frequent state savings <ref> [9, 22, 33, 42] </ref>. All these algorithms use simulation time information, such as the number of rollbacks, to suggest an optimal checkpoint period. These studies show that overall Time Warp performance can be improved by dynamic parameter adjustment.
Reference: [10] <author> Fujimoto, R. </author> <title> Optimistic approaches to parallel discrete event simulation. </title> <booktitle> Transactions of the Society for Computer Simulation 7, </booktitle> <month> 2 (June </month> <year> 1990), </year> <pages> 153-191. </pages>
Reference-contexts: Once LP 4 re-executes the event-message at simulation time 40, the simulation finally completes. 29 Chapter 5 Dynamic Cancellation Time Warp has received considerable attention as a PDES mechanism because its optimistic nature is well suited for exploiting the parallelism that is typically available in large simulations <ref> [10, 3] </ref>. Although the Time Warp mechanism is capable of speeding up large simulations, its potential to do so has not been fully exploited due to excessive rollbacks (resulting in instability and wastage of the lookahead computation done by the LPs).
Reference: [11] <author> Fujimoto, R. </author> <title> Parallel discrete event simulation. </title> <journal> Communications of the ACM 33, </journal> <month> 10 (October </month> <year> 1990), </year> <pages> 30-53. </pages>
Reference-contexts: Introduction The Time Warp mechanism is one of the most important synchronization protocols for parallel simulation <ref> [11] </ref>. However in most applications, the successful use of Time Warp requires the careful selection of Time Warp optimization parameters (e.g., cancellation strategies, frequency of state saving, and so on). <p> Whenever the discussion applies to only one of these terms, an explicit distinction will be made. 7 time. There are two broad control organizations for parallel simulation: central event and distributed simulation <ref> [11, 28] </ref>. A central event parallel simulator has a single global event list and an event dispatch mechanism that centrally dispatches events to the parallel simulators for processing. Such simulators are not the topic of this thesis and will not be discussed further. <p> The simulation proceeds along the correct path as long as each of the LPs process their event-messages in non-decreasing time-stamp order <ref> [11, 28] </ref>. This is referred to as the Local Causality Constraint [20]. Adherence to this constraint is sufficient, although not always necessary, to ensure that the simulation will be correct (produce the same results as a sequential simulation). <p> This is because two events within the same LP may not be causally related and thus processable in any order (irrespective of their relative time-stamp values). Parallel simulators can be broadly classified into two categories based on their enforcement of causality constraints, namely conservative [28] and optimistic <ref> [11] </ref> parallel simulators. Conservative simulators strictly avoid the possibility of a causality error from ever occuring. In a conservative PDES strategy, an LP does not process an event until it can guarantee that no other events (s) containing a smaller time-stamp will later be received. <p> Conservative approaches rely on some strategy to determine when it is safe to process an event, and block until they have a safe event to process [28]. 8 Optimistic approaches, on the other hand, do not avoid causality errors <ref> [11, 4] </ref>. <p> <ref> [11, 4] </ref>. Instead they assume that event-messages generally arrive in time-stamp order and so proceed forward, processing the events that are available in their event queue without blocking; whenever they discover a causality violation, they use various techniques to ensure that the simulation properly reflects the correct event execution order [11, 4]. The main drawback with conservative approaches is that they heavily rely on lookahead for their performance [22]. <p> If there is no lookahead, the smallest time-stamped event in the simulation could affect every other pending event, resulting in a sequential execution. Thus, conservative approaches are poorly suited for applications with poor lookahead properties even if the application has considerable inherent parallelism <ref> [11] </ref>. Optimistic mechanisms allow executions to proceed without regard to causality violations and taking corrective action when violations are detected. Consequently, optimistic simulators exploit parallelism in situations where there is a possibility that causality errors might occur, but in fact do not. <p> The advantage of this mechanism over the approaches used in conventional Time Warp systems is two fold: (i) it reduces the overheads associated with message cancellation, and (ii) it quickly tracks down erroneous computation to minimize the damage that is caused. Although Direct Cancellation has reported good performance <ref> [11] </ref>, it is only applicable to shared memory systems. Madisetti proposes Wolf [25], in which a straggler message causes a process to send special control messages called wolf calls to the processes that are "infected" by the erroneous computation. <p> Rollbacks represent the only unproductive work done by the system. The characteristics of the application can cause it to favor either lazy or aggressive cancellation <ref> [13, 40, 11] </ref>. The performance of either cancellation strategy depends on how the events of an LP affect each other. If the dependency between the events of an LP is weak, then lazy cancellation tends to provide better performance.
Reference: [12] <author> Fujimoto, R. M. </author> <title> Time warp on a shared memory multiprocessor. </title> <booktitle> Transactions of Society for Computer Simulation (July 1989), </booktitle> <pages> 211-239. </pages>
Reference-contexts: An analysis of the performance of dynamic cancellation in comparison to either static (lazy or aggressive) cancellation strategy. 1.1 Motivation for the Research The Time Warp synchronization strategy for parallel discrete event simulation [18] offers several attractive properties over the conservative approaches [28] and has the potential to outperform them <ref> [12] </ref>. This potential arises due to Time Warp's relaxed enforcement of causality constraints. Unfortunately, instances of Time Warp simulators have yet to reliably produce improved performance figures. <p> Under certain conditions, LC is capable of beating the critical path of the simulation. Performance under LC deteriorates, if event dependencies of an LP are high (e.g., when an LP is modeling a counter). Direct Cancellation <ref> [12] </ref> is a mechanism that uses shared memory to streamline the cancellation of incorrect computations. Whenever an event E1 schedules another event E2, a pointer is left from E1 to E2. This pointer is used if it is later decided that E2 should be cancelled.
Reference: [13] <author> Gafni, A. </author> <title> Rollback mechanisms for optimistic distributed simulation systems. In Distributed Simulation (January 1988), </title> <booktitle> Society for Computer Simulation, </booktitle> <pages> pp. 61-67. </pages>
Reference-contexts: Thus, Time Warp control systems should be employed only as a last resort, when traditional static analysis fails. One important tradeoff in a Time Warp simulation is which cancellation strategy to employ: aggressive cancellation [18] or lazy cancellation <ref> [13, 47] </ref>. Numerous studies of cancellation strategies have been performed and none has yet been unable to clearly demonstrate when one strategy consistently outperforms the other [2, 40]. <p> These studies show that overall Time Warp performance can be improved by dynamic parameter adjustment. In conventional Time Warp, two strategies exist to undo the effects of the erroneous computation, namely aggressive [18] and lazy cancellation <ref> [13, 47] </ref>. Under aggressive cancellation the arrival of a straggler message causes the immediate generation of anti-messages for all output messages that were prematurely dispatched. <p> In this approach, anti-messages are sent out to the affected processes immediately upon the arrival of the straggler. AC tends to performs poorly if the dependency between events of an LP is low (e.g., when an LP is modeling a ROM store). In Lazy Cancellation (LC) <ref> [13, 47] </ref>, anti-messages are sent to the affected processes only if different messages are generated before and after a rollback. LC works under the assumption that incorrect input does not necessarily produce incorrect output. Under certain conditions, LC is capable of beating the critical path of the simulation. <p> By immediately generating anti-messages to cancel the potentially incorrect messages, aggressive cancellation prevents these incorrect messages from generating more incorrect messages, thereby preventing a cascade of anti-messages, and hence rollbacks. Experiments have shown that not all out-of-order event-message generate erroneous output <ref> [13, 40, 47] </ref>. Consequently, when a late message causes a process to rollback, but does not subsequently change the execution path of the process, the process will regenerate exactly the same messages that it did during the optimistic lookahead. <p> This verification can be performed by reprocessing the event messages and comparing the newly generated outputs with the already generated events. This is called Lazy Cancellation (LC) <ref> [13, 47] </ref>. Lazy Cancellation operates under the assumption that an out-of-order event-message does not generally generate erroneous output. A Time Warp system using lazy cancellation waits to see if the re-execution of the computation causes the same messages to be regenerated. <p> Rollbacks represent the only unproductive work done by the system. The characteristics of the application can cause it to favor either lazy or aggressive cancellation <ref> [13, 40, 11] </ref>. The performance of either cancellation strategy depends on how the events of an LP affect each other. If the dependency between the events of an LP is weak, then lazy cancellation tends to provide better performance. <p> Therefore, the performance of a Time Warp simulator depends on the efficiency of the cancellation strategy employed to undo the effects of the erroneous computation. Several independent studies have shown that lazy cancellation performs better than aggressive cancellation <ref> [13, 47, 3, 23] </ref>. However, these 30 studies also show that, even within the same application domain, some executions perform better under aggressive cancellation [2, 41]. In studies involving the simulation of digital systems [39] described using the hardware description language VHDL [29, 37], we have observed (confirmed) that: 1.
Reference: [14] <author> Glazer, D. W., and Tropper, C. </author> <title> On process migration and load balancing in time warp. </title> <journal> IEEE Transactions on Parallel and Distributed Systems 4, </journal> <month> 3 (March </month> <year> 1993), </year> <pages> 318-327. </pages>
Reference-contexts: Bad partitioning and varying communication latencies could cause this condition from frequently occuring. 14 A combination of Smallest Time-stamp First Scheduling (STFS) and Load Balancing to reduce the number of rollbacks has been presented by Glazer and Tropper <ref> [14] </ref>. Load balancing is accomplished by varying the time slices allocated to processes based on the parameter simulation advance rate of each process.
Reference: [15] <author> Gropp, W., Lusk, E., and Skjellum, A. </author> <title> Using MPI: Portable Parallel Programming with the Message-Passing Interface. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1994. </year> <month> 57 </month>
Reference: [16] <author> Hamnes, D. O., and Tripathi, A. </author> <title> Investigations in adaptive distributed simulation. </title> <booktitle> In Proc. of the 8th Workshop on Parallel and Distributed Simulation (PADS 94) (July 1994), Society for Computer Simulation, </booktitle> <pages> pp. 20-23. </pages>
Reference-contexts: The major disadvantage of this technique is that the processor is not utilized when all the processes are penalized by the system, thereby wasting CPU cycles. Performance results from such techniques has discouraged further use of this technique. Similar approaches to stall LP event processing are reported in <ref> [8, 16] </ref>. Breathing Time Warp [45] is a combination of Breathing Time Buckets [44] and Time Warp. This technique works on the principle that events closer to GVT have a lower probability of being rolled back.
Reference: [17] <institution> IEEE Standard VHDL Language Reference Manual. </institution> <address> New York, NY, </address> <year> 1993. </year>
Reference: [18] <author> Jefferson, D. </author> <title> Virtual time. </title> <journal> ACM Transactions on Programming Languages and Systems 7, </journal> <month> 3 (July </month> <year> 1985), </year> <pages> 405-425. </pages>
Reference-contexts: Thus, Time Warp control systems should be employed only as a last resort, when traditional static analysis fails. One important tradeoff in a Time Warp simulation is which cancellation strategy to employ: aggressive cancellation <ref> [18] </ref> or lazy cancellation [13, 47]. Numerous studies of cancellation strategies have been performed and none has yet been unable to clearly demonstrate when one strategy consistently outperforms the other [2, 40]. <p> lation strategy?); (ii) The design and implementation of control mechanisms for selecting a cancellation strategy; and (iii) An analysis of the performance of dynamic cancellation in comparison to either static (lazy or aggressive) cancellation strategy. 1.1 Motivation for the Research The Time Warp synchronization strategy for parallel discrete event simulation <ref> [18] </ref> offers several attractive properties over the conservative approaches [28] and has the potential to outperform them [12]. This potential arises due to Time Warp's relaxed enforcement of causality constraints. Unfortunately, instances of Time Warp simulators have yet to reliably produce improved performance figures. <p> These studies show that overall Time Warp performance can be improved by dynamic parameter adjustment. In conventional Time Warp, two strategies exist to undo the effects of the erroneous computation, namely aggressive <ref> [18] </ref> and lazy cancellation [13, 47]. Under aggressive cancellation the arrival of a straggler message causes the immediate generation of anti-messages for all output messages that were prematurely dispatched. <p> Where a conservative simulator blocks, an optimistic simulator proceeds and, when no causal relationship occurs, the optimistic simulator has higher throughput. 2.2 The Time Warp Protocol The Time Warp mechanism is an implementation of the Virtual Time paradigm proposed by Jefferson <ref> [18] </ref>. It is the most well known optimistic synchronization protocol for PDES. In a Time Warp simulation, the physical system under investigation is decomposed into a set of LPs that operate as asynchronously communicating discrete event simulators 9 [18] (Figure 2.1). <p> mechanism is an implementation of the Virtual Time paradigm proposed by Jefferson <ref> [18] </ref>. It is the most well known optimistic synchronization protocol for PDES. In a Time Warp simulation, the physical system under investigation is decomposed into a set of LPs that operate as asynchronously communicating discrete event simulators 9 [18] (Figure 2.1). The LPs operate asynchronously, processing event-messages in their time-stamp order and communicate exclusively by exchanging time-stamped event-messages. Each LP maintains its own simulation clock called the Local Virtual Time (LVT), which is the time-stamp of the event-message last processed by the LP. <p> Another disadvantage of this method is that the processes block before processing each and every event in the simulation. 16 Cancellation Studies Aggressive Cancellation (AC) is the cancellation mechanism originally proposed by Jefferson <ref> [18] </ref> to retract the incorrectly sent output messages from the distributed computation. In this approach, anti-messages are sent out to the affected processes immediately upon the arrival of the straggler. <p> Two cancellation strategies exist, that differ only in the time at which anti-messages are sent. These strategies are called: Aggressive Cancellation and Lazy Cancellation. 4.1 Aggressive Cancellation Aggressive Cancellation (AC) is the cancellation mechanism originally proposed by Jefferson <ref> [18] </ref> to retract erroneously sent output messages from the distributed computation.
Reference: [19] <author> Jefferson, D., Beckman, B., Wieland, F., Blume, L., Di Loreto, M., Hon-talas, P., Laroche, P., Sturdevant, K., Tupman, J., Warren, V., Wedel, J., Younger, H., and Bellenot, S. </author> <title> Distributed simulation and the time warp operating system. </title> <booktitle> In Proceedings of the 12 th SIGOPS | Symposium of Operating Systems Principles (1987), </booktitle> <pages> pp. 77-93. </pages>
Reference-contexts: The studies have only succeeded in showing that aggressive cancellation is more sensitive to optimal parameter adjustments in the lower level communication subsystem. Thus, most currently available Time Warp simulators support both strategies and provide user control of their setting <ref> [7, 19, 26] </ref>. Furthermore, while Lin [21] has attempted to analytically characterize the effective performance spaces of each cancellation strategy, the approach requires complete knowledge of simulation behaviors and is not practically applicable. Thus, the determination of cancellation strategy would seem to be a suitable candidate for dynamic selection.
Reference: [20] <author> Lamport, L. </author> <title> Time, clocks, and the ordering of events in a distributed system. </title> <journal> Communications of ACM (July 1978), </journal> <pages> 558-565. </pages>
Reference-contexts: The simulation proceeds along the correct path as long as each of the LPs process their event-messages in non-decreasing time-stamp order [11, 28]. This is referred to as the Local Causality Constraint <ref> [20] </ref>. Adherence to this constraint is sufficient, although not always necessary, to ensure that the simulation will be correct (produce the same results as a sequential simulation).
Reference: [21] <author> Lin, Y. </author> <title> Estimating the likelihood of success of lazy cancellation in time warp simulations. </title> <note> International Journal in Computer Simulation (1996). (to appear). </note>
Reference-contexts: The studies have only succeeded in showing that aggressive cancellation is more sensitive to optimal parameter adjustments in the lower level communication subsystem. Thus, most currently available Time Warp simulators support both strategies and provide user control of their setting [7, 19, 26]. Furthermore, while Lin <ref> [21] </ref> has attempted to analytically characterize the effective performance spaces of each cancellation strategy, the approach requires complete knowledge of simulation behaviors and is not practically applicable. Thus, the determination of cancellation strategy would seem to be a suitable candidate for dynamic selection. <p> Unfortunately, it is extremely difficult to make an a priori determination of the cancellation strategy most favorable to an application <ref> [24, 21] </ref>. In particular, Lin [21] demonstrates that even with a number of unrealistic assumptions, a static analysis to determine the optimal cancellation strategy is very complicated. <p> Unfortunately, it is extremely difficult to make an a priori determination of the cancellation strategy most favorable to an application [24, 21]. In particular, Lin <ref> [21] </ref> demonstrates that even with a number of unrealistic assumptions, a static analysis to determine the optimal cancellation strategy is very complicated.
Reference: [22] <author> Lin, Y.-B., and Lazowska, E. D. </author> <title> The optimal checkpoint interval in time warp parallel simulation. </title> <type> Tech. Rep. </type> <institution> 89-09-04, Department of Computer Science and Engineering, University of Washington, </institution> <address> Seattle, Washington, </address> <month> September </month> <year> 1989. </year>
Reference-contexts: The amount of wasted lookahead computation can be reduced by minimizing the number of rollbacks in the system. A variety of algorithms have been proposed to alleviate the problem of excessive memory usage due to frequent state savings <ref> [9, 22, 33, 42] </ref>. All these algorithms use simulation time information, such as the number of rollbacks, to suggest an optimal checkpoint period. These studies show that overall Time Warp performance can be improved by dynamic parameter adjustment. <p> The main drawback with conservative approaches is that they heavily rely on lookahead for their performance <ref> [22] </ref>.
Reference: [23] <author> Lin, Y.-B., and Lazowska, E. D. </author> <title> Processor scheduling for time warp parallel simulation. </title> <booktitle> In Advances in Parallel and Distributed Simulation (January 1991), Society for Computer Simulation, </booktitle> <pages> pp. 11-14. </pages>
Reference-contexts: A number of techniques have been proposed in the past to reduce the number of rollbacks in a Time Warp parallel simulation. A brief description of the various approaches follows. LP Scheduling In Smallest Time-stamp First Scheduling (STFS) <ref> [23] </ref>, processes are scheduled for execution in the order of the time-stamp of the next event to be processed (i.e., the process with the least time-stamp is scheduled for execution before others). This technique results in good performance in homogeneous environments with global knowledge of LP advancement. <p> Therefore, the performance of a Time Warp simulator depends on the efficiency of the cancellation strategy employed to undo the effects of the erroneous computation. Several independent studies have shown that lazy cancellation performs better than aggressive cancellation <ref> [13, 47, 3, 23] </ref>. However, these 30 studies also show that, even within the same application domain, some executions perform better under aggressive cancellation [2, 41]. In studies involving the simulation of digital systems [39] described using the hardware description language VHDL [29, 37], we have observed (confirmed) that: 1.
Reference: [24] <author> Lin, Y.-B., Preiss, B. R., Loucks, W. M., and Lazowska, E. D. </author> <title> Selecting the checkpoint interval in time warp simulation. </title> <booktitle> In Proc of the 7th Workshop on Parallel 58 and Distributed Simulation (PADS) (July 1993), Society for Computer Simulation, </booktitle> <pages> pp. 3-10. </pages>
Reference-contexts: Furthermore, the optimal setting for the simulation parameters may not hold across an application domain or even throughout the entire simulation lifetime of a single application. Consequently, several investigations have proposed the dynamic adjustment of simulation parameters over the lifetime of the simulation <ref> [2, 24, 27, 33, 34, 35, 36, 41] </ref>. These investigations have shown that dynamic parameter adjustment can be used to successfully tune a Time Warp simulator for near optimal performance. The dynamic adjustment of simulation parameters requires careful design considerations. <p> Unfortunately, it is extremely difficult to make an a priori determination of the cancellation strategy most favorable to an application <ref> [24, 21] </ref>. In particular, Lin [21] demonstrates that even with a number of unrealistic assumptions, a static analysis to determine the optimal cancellation strategy is very complicated. <p> These values are a time series of discrete values that have been used in several investigations to dynamically adjust simulation parameters <ref> [2, 24, 27, 33, 34, 35, 41] </ref>. These investigations have used data filtering techniques to smooth and to prevent spurious data points from causing wide variations in parameter adjustment. In this research, we have found that non-linear thresholding functions are best suited for selecting which cancellation strategy to use. <p> Initially the LPs use lazy cancellation. This control model mimics the approach used by Lin et al in their checkpointing studies <ref> [24] </ref>.
Reference: [25] <author> Madisetti, V., Walrand, J., and Messerschmitt, D. Wolf: </author> <title> A rollback algorithm for optimistic distributed simulation systems. </title> <booktitle> In Winter Simulation Conference (December 1988), Society for Computer Simulation, </booktitle> <pages> pp. 296-305. </pages>
Reference-contexts: Although Direct Cancellation has reported good performance [11], it is only applicable to shared memory systems. Madisetti proposes Wolf <ref> [25] </ref>, in which a straggler message causes a process to send special control messages called wolf calls to the processes that are "infected" by the erroneous computation. The objective is to accelerate delivery and processing of wolf calls to quickly stop the spread of erroneous computation.
Reference: [26] <author> Martin, D. E., McBrayer, T. J., and Wilsey, P. A. </author> <title> warped: A time warp simulation kernel for analysis and application development. </title> <booktitle> In 29th Hawaii International Conference on System Sciences (HICSS-29) (January 1996), </booktitle> <editor> H. El-Rewini and B. D. Shriver, Eds., </editor> <volume> vol. Volume I, </volume> <pages> pp. 383-386. </pages>
Reference-contexts: The studies have only succeeded in showing that aggressive cancellation is more sensitive to optimal parameter adjustments in the lower level communication subsystem. Thus, most currently available Time Warp simulators support both strategies and provide user control of their setting <ref> [7, 19, 26] </ref>. Furthermore, while Lin [21] has attempted to analytically characterize the effective performance spaces of each cancellation strategy, the approach requires complete knowledge of simulation behaviors and is not practically applicable. Thus, the determination of cancellation strategy would seem to be a suitable candidate for dynamic selection. <p> The results presented in this thesis have been obtained from two different Time Warp simulators | one of which is a purely VHDL digital system simulator, called VAST (Appendix B), while the other is a generic Time Warp simulator called warped (Appendix A) <ref> [26] </ref>. The warped project includes applications for queuing model simulation as well as VHDL simulation. The warped simulator (Appendix A) is currently under development, which is why the results of the benchmarks from the old simulator are also presented in this thesis.
Reference: [27] <author> Matsumoto, Y., and Taki, K. </author> <title> Adaptive time-ceiling for efficient parallel discrete event simulation. </title> <booktitle> In Object-Oriented Simulation Conference (OOS '93) (January 1993), </booktitle> <editor> T. Beaumariage and C. Roberts, Eds., </editor> <booktitle> Society for Computer Simulation, </booktitle> <pages> pp. 101-106. </pages>
Reference-contexts: Furthermore, the optimal setting for the simulation parameters may not hold across an application domain or even throughout the entire simulation lifetime of a single application. Consequently, several investigations have proposed the dynamic adjustment of simulation parameters over the lifetime of the simulation <ref> [2, 24, 27, 33, 34, 35, 36, 41] </ref>. These investigations have shown that dynamic parameter adjustment can be used to successfully tune a Time Warp simulator for near optimal performance. The dynamic adjustment of simulation parameters requires careful design considerations. <p> These values are a time series of discrete values that have been used in several investigations to dynamically adjust simulation parameters <ref> [2, 24, 27, 33, 34, 35, 41] </ref>. These investigations have used data filtering techniques to smooth and to prevent spurious data points from causing wide variations in parameter adjustment. In this research, we have found that non-linear thresholding functions are best suited for selecting which cancellation strategy to use.
Reference: [28] <author> Misra, J. </author> <title> Distributed discrete-event simulation. </title> <journal> Computing Surveys 18, </journal> <month> 1 (March </month> <year> 1986), </year> <pages> 39-65. </pages>
Reference-contexts: mechanisms for selecting a cancellation strategy; and (iii) An analysis of the performance of dynamic cancellation in comparison to either static (lazy or aggressive) cancellation strategy. 1.1 Motivation for the Research The Time Warp synchronization strategy for parallel discrete event simulation [18] offers several attractive properties over the conservative approaches <ref> [28] </ref> and has the potential to outperform them [12]. This potential arises due to Time Warp's relaxed enforcement of causality constraints. Unfortunately, instances of Time Warp simulators have yet to reliably produce improved performance figures. <p> Whenever the discussion applies to only one of these terms, an explicit distinction will be made. 7 time. There are two broad control organizations for parallel simulation: central event and distributed simulation <ref> [11, 28] </ref>. A central event parallel simulator has a single global event list and an event dispatch mechanism that centrally dispatches events to the parallel simulators for processing. Such simulators are not the topic of this thesis and will not be discussed further. <p> The simulation proceeds along the correct path as long as each of the LPs process their event-messages in non-decreasing time-stamp order <ref> [11, 28] </ref>. This is referred to as the Local Causality Constraint [20]. Adherence to this constraint is sufficient, although not always necessary, to ensure that the simulation will be correct (produce the same results as a sequential simulation). <p> This is because two events within the same LP may not be causally related and thus processable in any order (irrespective of their relative time-stamp values). Parallel simulators can be broadly classified into two categories based on their enforcement of causality constraints, namely conservative <ref> [28] </ref> and optimistic [11] parallel simulators. Conservative simulators strictly avoid the possibility of a causality error from ever occuring. In a conservative PDES strategy, an LP does not process an event until it can guarantee that no other events (s) containing a smaller time-stamp will later be received. <p> Such events that can be processed without any possibility of violating the local causality rule are called safe events. Conservative approaches rely on some strategy to determine when it is safe to process an event, and block until they have a safe event to process <ref> [28] </ref>. 8 Optimistic approaches, on the other hand, do not avoid causality errors [11, 4].
Reference: [29] <author> Navabi, Z. </author> <title> VHDL: Analysis and Modeling of Digital Systems. </title> <publisher> McGraw-Hill, </publisher> <address> New York, NY, </address> <year> 1993. </year>
Reference-contexts: However, these 30 studies also show that, even within the same application domain, some executions perform better under aggressive cancellation [2, 41]. In studies involving the simulation of digital systems [39] described using the hardware description language VHDL <ref> [29, 37] </ref>, we have observed (confirmed) that: 1. Neither cancellation strategy is clearly superior. 2. The optimal cancellation strategy is sensitive to the partitioning scheme employed for distributing the LPs on processors. 3. Different LPs within the same application operate best under different cancellation strategies. 4.
Reference: [30] <author> Palaniswamy, A. </author> <title> Dynamic Parameter Adjustment to Speed Time Warp Simulation. </title> <type> PhD thesis, </type> <institution> Dept of ECE, University of Cincinnati, Cincinnati, OH, </institution> <month> April </month> <year> 1994. </year>
Reference: [31] <author> Palaniswamy, A., Aji, S., and Wilsey, P. A. </author> <title> An efficient implementation of lazy reevaluation. </title> <booktitle> In Proc. of the 25th Annual Simulation Symposium (April 1992), Society for Computer Simulation, </booktitle> <pages> pp. 140-146. </pages>
Reference-contexts: The time in history from which the LVT and state values are restored is called the restoration time. All states with LVTs greater than the time-stamp of the straggler are discarded as the state information they contain could be erroneous (in this thesis, the possibility for lazy reevaluation <ref> [47, 31] </ref> is ignored). During the cancellation phase, the LP cancels the output events generated by processing events forward of the time-stamp of the straggler message. This is accomplished by sending anti-messages.
Reference: [32] <author> Palaniswamy, A., Aji, S., and Wilsey, P. A. </author> <title> Performance measures for several optimizations to a distributed digital system simulator. </title> <booktitle> In Proc. of the 26th Annual Simulation Symposium (April 1993), Society for Computer Simulation, </booktitle> <pages> pp. 21-29. 59 </pages>
Reference-contexts: Several independent studies have shown that while applications slightly favor lazy cancellation, some executions perform significantly better under aggressive cancellation (even within the same application domain) <ref> [2, 32, 41] </ref>. Unfortunately, practical techniques to statically analyze an application for selecting cancellation strategies have yet to be developed.
Reference: [33] <author> Palaniswamy, A., and Wilsey, P. A. </author> <title> Adaptive bounded time windows in an optimistically synchronized simulator. </title> <booktitle> In Third Great Lakes Symposium on VLSI (1993), </booktitle> <pages> pp. 114-118. </pages>
Reference-contexts: Furthermore, the optimal setting for the simulation parameters may not hold across an application domain or even throughout the entire simulation lifetime of a single application. Consequently, several investigations have proposed the dynamic adjustment of simulation parameters over the lifetime of the simulation <ref> [2, 24, 27, 33, 34, 35, 36, 41] </ref>. These investigations have shown that dynamic parameter adjustment can be used to successfully tune a Time Warp simulator for near optimal performance. The dynamic adjustment of simulation parameters requires careful design considerations. <p> The amount of wasted lookahead computation can be reduced by minimizing the number of rollbacks in the system. A variety of algorithms have been proposed to alleviate the problem of excessive memory usage due to frequent state savings <ref> [9, 22, 33, 42] </ref>. All these algorithms use simulation time information, such as the number of rollbacks, to suggest an optimal checkpoint period. These studies show that overall Time Warp performance can be improved by dynamic parameter adjustment. <p> These values are a time series of discrete values that have been used in several investigations to dynamically adjust simulation parameters <ref> [2, 24, 27, 33, 34, 35, 41] </ref>. These investigations have used data filtering techniques to smooth and to prevent spurious data points from causing wide variations in parameter adjustment. In this research, we have found that non-linear thresholding functions are best suited for selecting which cancellation strategy to use.
Reference: [34] <author> Palaniswamy, A., and Wilsey, P. A. </author> <title> Adaptive checkpoint intervals in an optimistically synchronized parallel digital system simulator. </title> <booktitle> In VLSI 93 (September 1993), </booktitle> <pages> pp. 353-362. </pages>
Reference-contexts: Furthermore, the optimal setting for the simulation parameters may not hold across an application domain or even throughout the entire simulation lifetime of a single application. Consequently, several investigations have proposed the dynamic adjustment of simulation parameters over the lifetime of the simulation <ref> [2, 24, 27, 33, 34, 35, 36, 41] </ref>. These investigations have shown that dynamic parameter adjustment can be used to successfully tune a Time Warp simulator for near optimal performance. The dynamic adjustment of simulation parameters requires careful design considerations. <p> These values are a time series of discrete values that have been used in several investigations to dynamically adjust simulation parameters <ref> [2, 24, 27, 33, 34, 35, 41] </ref>. These investigations have used data filtering techniques to smooth and to prevent spurious data points from causing wide variations in parameter adjustment. In this research, we have found that non-linear thresholding functions are best suited for selecting which cancellation strategy to use.
Reference: [35] <author> Palaniswamy, A., and Wilsey, P. A. </author> <title> Scheduling time warp processes using adaptive control techniques. </title> <booktitle> In Proceedings of the 1994 Winter Simulation Conference (December 1994), </booktitle> <editor> J. D. Tew, S. Manivannan, D. A. Sadowski, and A. F. Seila, </editor> <booktitle> Eds., </booktitle> <pages> pp. 731-738. </pages>
Reference-contexts: Furthermore, the optimal setting for the simulation parameters may not hold across an application domain or even throughout the entire simulation lifetime of a single application. Consequently, several investigations have proposed the dynamic adjustment of simulation parameters over the lifetime of the simulation <ref> [2, 24, 27, 33, 34, 35, 36, 41] </ref>. These investigations have shown that dynamic parameter adjustment can be used to successfully tune a Time Warp simulator for near optimal performance. The dynamic adjustment of simulation parameters requires careful design considerations. <p> The results, however, were not tested on a real multiprocessor but in a simulated multiprocessor environment, without taking into account factors such as operating system scheduling overheads, and loading of the system due to other processes (users). Likewise, Palaniswamy <ref> [35, 36] </ref> proposed a complex measure called useful work to establish estimates of LP productivity. He then uses the useful work value to establish a scheduling order between the LPs on a processor. Stalling Event Processing Penalty Based Throttling [41] schedules processes which receive the least number of anti-messages. <p> These values are a time series of discrete values that have been used in several investigations to dynamically adjust simulation parameters <ref> [2, 24, 27, 33, 34, 35, 41] </ref>. These investigations have used data filtering techniques to smooth and to prevent spurious data points from causing wide variations in parameter adjustment. In this research, we have found that non-linear thresholding functions are best suited for selecting which cancellation strategy to use.
Reference: [36] <author> Palaniswamy, A., and Wilsey, P. A. </author> <title> Parameterized time warp: An integrated adaptive solution to optimistic pdes. </title> <journal> Journal of Parallel and Distributed Computing (1996). (forthcoming). </journal>
Reference-contexts: Furthermore, the optimal setting for the simulation parameters may not hold across an application domain or even throughout the entire simulation lifetime of a single application. Consequently, several investigations have proposed the dynamic adjustment of simulation parameters over the lifetime of the simulation <ref> [2, 24, 27, 33, 34, 35, 36, 41] </ref>. These investigations have shown that dynamic parameter adjustment can be used to successfully tune a Time Warp simulator for near optimal performance. The dynamic adjustment of simulation parameters requires careful design considerations. <p> The results, however, were not tested on a real multiprocessor but in a simulated multiprocessor environment, without taking into account factors such as operating system scheduling overheads, and loading of the system due to other processes (users). Likewise, Palaniswamy <ref> [35, 36] </ref> proposed a complex measure called useful work to establish estimates of LP productivity. He then uses the useful work value to establish a scheduling order between the LPs on a processor. Stalling Event Processing Penalty Based Throttling [41] schedules processes which receive the least number of anti-messages.
Reference: [37] <author> Perry, D. L. </author> <title> VHDL. </title> <publisher> McGraw-Hill, </publisher> <address> New York, NY, </address> <year> 1991. </year>
Reference-contexts: However, these 30 studies also show that, even within the same application domain, some executions perform better under aggressive cancellation [2, 41]. In studies involving the simulation of digital systems [39] described using the hardware description language VHDL <ref> [29, 37] </ref>, we have observed (confirmed) that: 1. Neither cancellation strategy is clearly superior. 2. The optimal cancellation strategy is sensitive to the partitioning scheme employed for distributing the LPs on processors. 3. Different LPs within the same application operate best under different cancellation strategies. 4. <p> cancellation to enable switching back into lazy cancellation. 38 6.2 Benchmarks used in this investigation The performance of Dynamic Cancellation relative to lazy and aggressive cancellation was compared using models from two application domains namely queuing model simulations and the simulation of digital systems using the hardware description language VHDL <ref> [37] </ref>. The results presented in this thesis have been obtained from two different Time Warp simulators | one of which is a purely VHDL digital system simulator, called VAST (Appendix B), while the other is a generic Time Warp simulator called warped (Appendix A) [26].
Reference: [38] <author> Preiss, B. R., MacIntrye, I. D., and Loucks, W. M. </author> <title> On the trade-off between time and space in optimistic parallel discrete-event simulation. </title> <booktitle> In 6th Workshop on Parallel and Distributed Simulation (January 1992), Society for Computer Simulation, </booktitle> <pages> pp. 33-42. </pages>
Reference-contexts: This optimization is difficult to use because different simulation models (within the same application domain) may require different window sizes for optimal performance. Furthermore, an incorrectly sized bounding window can dramatically decrease performance. In the Filter algorithm proposed by Prakash and Subramanian <ref> [38] </ref>, each event-message carries a bounded amount of dependency information that describes the assumptions made in the generation of that message, and in addition, LPs keep track of straggler events that have occured in the system.
Reference: [39] <author> Rajan, R., and Wilsey, P. A. </author> <title> Dynamically switching between lazy and aggressive cancellation in a time warp parallel simulator. </title> <booktitle> In Proc. of the 28th Annual Simulation Symposium (April 1995), </booktitle> <publisher> IEEE Computer Society Press, </publisher> <pages> pp. 22-30. </pages>
Reference-contexts: Several independent studies have shown that lazy cancellation performs better than aggressive cancellation [13, 47, 3, 23]. However, these 30 studies also show that, even within the same application domain, some executions perform better under aggressive cancellation [2, 41]. In studies involving the simulation of digital systems <ref> [39] </ref> described using the hardware description language VHDL [29, 37], we have observed (confirmed) that: 1. Neither cancellation strategy is clearly superior. 2. The optimal cancellation strategy is sensitive to the partitioning scheme employed for distributing the LPs on processors. 3.
Reference: [40] <author> Reiher, P. L., Fujimoto, R. M., Bellenot, S., and Jefferson, D. </author> <title> Cancellation strategies in optimistic execution systems. </title> <booktitle> In Proceedings of the SCS Multiconference 60 on Distributed Simulation (January 1990), </booktitle> <volume> vol. 22, </volume> <booktitle> Society for Computer Simulation, </booktitle> <pages> pp. 112-121. </pages>
Reference-contexts: One important tradeoff in a Time Warp simulation is which cancellation strategy to employ: aggressive cancellation [18] or lazy cancellation [13, 47]. Numerous studies of cancellation strategies have been performed and none has yet been unable to clearly demonstrate when one strategy consistently outperforms the other <ref> [2, 40] </ref>. The studies have only succeeded in showing that aggressive cancellation is more sensitive to optimal parameter adjustments in the lower level communication subsystem. Thus, most currently available Time Warp simulators support both strategies and provide user control of their setting [7, 19, 26]. <p> on a processor in the past sends a message to an LP residing on a processor in the future, the object receiving that message may have already moved past the message's receive-time, in which case the work done by the object before the arrival of straggler may be in error <ref> [40] </ref>. These erroneous messages can have cascading effects. One out-of-order message can result in the generation of other out-of-order messages containing erroneous data, which in turn can generate many more, causing the error to spread across the system. <p> By immediately generating anti-messages to cancel the potentially incorrect messages, aggressive cancellation prevents these incorrect messages from generating more incorrect messages, thereby preventing a cascade of anti-messages, and hence rollbacks. Experiments have shown that not all out-of-order event-message generate erroneous output <ref> [13, 40, 47] </ref>. Consequently, when a late message causes a process to rollback, but does not subsequently change the execution path of the process, the process will regenerate exactly the same messages that it did during the optimistic lookahead. <p> Rollbacks represent the only unproductive work done by the system. The characteristics of the application can cause it to favor either lazy or aggressive cancellation <ref> [13, 40, 11] </ref>. The performance of either cancellation strategy depends on how the events of an LP affect each other. If the dependency between the events of an LP is weak, then lazy cancellation tends to provide better performance. <p> If the dependency between the events of an LP is weak, then lazy cancellation tends to provide better performance. On the other hand, aggressive cancellation would perform better if the event dependencies within an LP is strong. This section reviews two hypothetical applications developed by Reiher <ref> [40] </ref> that demonstrate how the choice of the cancellation strategy affects the performance of a Time Warp simulation. The first application is called BeLazy, and describes a scenario where lazy cancellation performs well, but aggressive cancellation performs poorly.
Reference: [41] <author> Reiher, P. L., Wieland, F., and Jefferson, D. R. </author> <title> Limitation of optimism in the time warp operating system. </title> <booktitle> In Winter Simulation Conference (December 1989), Society for Computer Simulation, </booktitle> <pages> pp. 765-770. </pages>
Reference-contexts: Furthermore, the optimal setting for the simulation parameters may not hold across an application domain or even throughout the entire simulation lifetime of a single application. Consequently, several investigations have proposed the dynamic adjustment of simulation parameters over the lifetime of the simulation <ref> [2, 24, 27, 33, 34, 35, 36, 41] </ref>. These investigations have shown that dynamic parameter adjustment can be used to successfully tune a Time Warp simulator for near optimal performance. The dynamic adjustment of simulation parameters requires careful design considerations. <p> Several independent studies have shown that while applications slightly favor lazy cancellation, some executions perform significantly better under aggressive cancellation (even within the same application domain) <ref> [2, 32, 41] </ref>. Unfortunately, practical techniques to statically analyze an application for selecting cancellation strategies have yet to be developed. <p> Likewise, Palaniswamy [35, 36] proposed a complex measure called useful work to establish estimates of LP productivity. He then uses the useful work value to establish a scheduling order between the LPs on a processor. Stalling Event Processing Penalty Based Throttling <ref> [41] </ref> schedules processes which receive the least number of anti-messages. Processes are penalized based on the anti-message count, and are basically skipped by the scheduler until the penalty reduces to zero. <p> Several independent studies have shown that lazy cancellation performs better than aggressive cancellation [13, 47, 3, 23]. However, these 30 studies also show that, even within the same application domain, some executions perform better under aggressive cancellation <ref> [2, 41] </ref>. In studies involving the simulation of digital systems [39] described using the hardware description language VHDL [29, 37], we have observed (confirmed) that: 1. Neither cancellation strategy is clearly superior. 2. <p> These values are a time series of discrete values that have been used in several investigations to dynamically adjust simulation parameters <ref> [2, 24, 27, 33, 34, 35, 41] </ref>. These investigations have used data filtering techniques to smooth and to prevent spurious data points from causing wide variations in parameter adjustment. In this research, we have found that non-linear thresholding functions are best suited for selecting which cancellation strategy to use.
Reference: [42] <author> R onngren, R., and Ayani, R. </author> <title> Adaptive checkpointing in time warp. </title> <booktitle> In Proc. of the 8th Workshop on Parallel and Distributed Simulation (PADS 94) (July 1994), Society for Computer Simulation, </booktitle> <pages> pp. 110-117. </pages>
Reference-contexts: The amount of wasted lookahead computation can be reduced by minimizing the number of rollbacks in the system. A variety of algorithms have been proposed to alleviate the problem of excessive memory usage due to frequent state savings <ref> [9, 22, 33, 42] </ref>. All these algorithms use simulation time information, such as the number of rollbacks, to suggest an optimal checkpoint period. These studies show that overall Time Warp performance can be improved by dynamic parameter adjustment.
Reference: [43] <author> Sokol, L. M., Briscoe, D. P., and Wieland, A. P. MTW: </author> <title> A strategy for scheduling discrete simulation events for concurrent execution. In Distributed Simulation (July 1988), </title> <booktitle> Society for Computer Simulation, </booktitle> <pages> pp. 34-42. </pages>
Reference-contexts: However, the mechanism provides no means to determine the values of N1 and N2, to dynamically alter their values to minimize execution time. The Moving Time Window (MTW) approach proposed by Sokol, Briscoe, and 15 Wienland <ref> [43] </ref> attempts to reduce the number of rollbacks in the system by preventing incorrect computations from propagating too far into the simulated time future.
Reference: [44] <author> Steinman, J. S. SPEEDES: </author> <title> A unified approach to parallel simulation. </title> <booktitle> In 6 th Workshop on Parallel and Distributed Simulation (January 1991), </booktitle> <editor> A. H. Rutan, Ed., </editor> <publisher> IEEE Computer Society Press, </publisher> <pages> pp. 75-84. </pages>
Reference-contexts: Performance results from such techniques has discouraged further use of this technique. Similar approaches to stall LP event processing are reported in [8, 16]. Breathing Time Warp [45] is a combination of Breathing Time Buckets <ref> [44] </ref> and Time Warp. This technique works on the principle that events closer to GVT have a lower probability of being rolled back. Thus N1 events closer to GVT are executed optimistically, and N2 events after that point are executed using breathing time buckets.
Reference: [45] <author> Steinman, J. S. </author> <title> Breathing time warp. </title> <booktitle> In 7 th Workshop on Parallel and Distributed Simulation (May 1993), </booktitle> <editor> A. H. Rutan, Ed., </editor> <publisher> IEEE Computer Society Press, </publisher> <pages> pp. 109-118. </pages>
Reference-contexts: Performance results from such techniques has discouraged further use of this technique. Similar approaches to stall LP event processing are reported in [8, 16]. Breathing Time Warp <ref> [45] </ref> is a combination of Breathing Time Buckets [44] and Time Warp. This technique works on the principle that events closer to GVT have a lower probability of being rolled back.
Reference: [46] <author> Vantage Analysis Systems. </author> <title> VHDL Intermediate Format: Access Routines, Reference Manual, </title> <month> July </month> <year> 1989. </year>
Reference: [47] <author> West, D. </author> <title> Optimizing time warp: Lazy rollback and lazy re-evaluation. </title> <type> Master's thesis, </type> <institution> University of Calgary, Calgary, Alberta, </institution> <year> 1988. </year> <month> 61 </month>
Reference-contexts: Thus, Time Warp control systems should be employed only as a last resort, when traditional static analysis fails. One important tradeoff in a Time Warp simulation is which cancellation strategy to employ: aggressive cancellation [18] or lazy cancellation <ref> [13, 47] </ref>. Numerous studies of cancellation strategies have been performed and none has yet been unable to clearly demonstrate when one strategy consistently outperforms the other [2, 40]. <p> These studies show that overall Time Warp performance can be improved by dynamic parameter adjustment. In conventional Time Warp, two strategies exist to undo the effects of the erroneous computation, namely aggressive [18] and lazy cancellation <ref> [13, 47] </ref>. Under aggressive cancellation the arrival of a straggler message causes the immediate generation of anti-messages for all output messages that were prematurely dispatched. <p> In this approach, anti-messages are sent out to the affected processes immediately upon the arrival of the straggler. AC tends to performs poorly if the dependency between events of an LP is low (e.g., when an LP is modeling a ROM store). In Lazy Cancellation (LC) <ref> [13, 47] </ref>, anti-messages are sent to the affected processes only if different messages are generated before and after a rollback. LC works under the assumption that incorrect input does not necessarily produce incorrect output. Under certain conditions, LC is capable of beating the critical path of the simulation. <p> Lastly, the scheme requires that one know the speed in real-time at which both the erroneous computations can spread, and the time required to transmit the control messages. Determining the bounds on these quantities may be difficult for certain systems. Lazy Rollback <ref> [47] </ref> provides a mechanism whereby certain rollbacks can be postponed or ignored. In this approach processes are considered as representing abstract data types with the state information as the data structure and input messages as operations on that data structure. <p> The time in history from which the LVT and state values are restored is called the restoration time. All states with LVTs greater than the time-stamp of the straggler are discarded as the state information they contain could be erroneous (in this thesis, the possibility for lazy reevaluation <ref> [47, 31] </ref> is ignored). During the cancellation phase, the LP cancels the output events generated by processing events forward of the time-stamp of the straggler message. This is accomplished by sending anti-messages. <p> By immediately generating anti-messages to cancel the potentially incorrect messages, aggressive cancellation prevents these incorrect messages from generating more incorrect messages, thereby preventing a cascade of anti-messages, and hence rollbacks. Experiments have shown that not all out-of-order event-message generate erroneous output <ref> [13, 40, 47] </ref>. Consequently, when a late message causes a process to rollback, but does not subsequently change the execution path of the process, the process will regenerate exactly the same messages that it did during the optimistic lookahead. <p> It will then receive the replacement positive message, and will likely have to rollback to deal with it as well, only to proceed along the identical execution path it was on before the superfluous anti-message arrived, and only after much reexecution <ref> [47] </ref>. 4.2 Lazy Cancellation In the situation discussed above, if instead of immediately dispatching the anti-message, the LP had waited for verification that the output message was incorrect, then then the unnecessary rollbacks could have been prevented. <p> This verification can be performed by reprocessing the event messages and comparing the newly generated outputs with the already generated events. This is called Lazy Cancellation (LC) <ref> [13, 47] </ref>. Lazy Cancellation operates under the assumption that an out-of-order event-message does not generally generate erroneous output. A Time Warp system using lazy cancellation waits to see if the re-execution of the computation causes the same messages to be regenerated. <p> Therefore, the performance of a Time Warp simulator depends on the efficiency of the cancellation strategy employed to undo the effects of the erroneous computation. Several independent studies have shown that lazy cancellation performs better than aggressive cancellation <ref> [13, 47, 3, 23] </ref>. However, these 30 studies also show that, even within the same application domain, some executions perform better under aggressive cancellation [2, 41]. In studies involving the simulation of digital systems [39] described using the hardware description language VHDL [29, 37], we have observed (confirmed) that: 1.
References-found: 47

