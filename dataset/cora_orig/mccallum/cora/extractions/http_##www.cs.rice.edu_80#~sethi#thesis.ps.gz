URL: http://www.cs.rice.edu:80/~sethi/thesis.ps.gz
Refering-URL: http://www.cs.rice.edu:80/~sethi/publications.html
Root-URL: 
Title: Communication Generation for Data-Parallel Languages  
Author: by Ajay Sethi Linda Torczon, Faculty Fellow 
Degree: A Thesis Submitted in Partial Fulfillment of the Requirements for the Degree Doctor of Philosophy Approved, Thesis Committee: Ken Kennedy, Noah Harding Professor  Peter Druschel, Assistant Professor  Richard Tapia, Noah Harding Professor  
Date: December, 1996  
Address: Houston, Texas  
Affiliation: RICE UNIVERSITY  Department of Computer Science Rice University  Department of Computer Science Rice University  Department of Computational and Applied Mathematics Rice University  Department of Computer Science Rice University  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> J. Adams, W. Brainerd, J. Martin, B. Smith, and J. Wagener. </author> <title> Fortran 90 Handbook. </title> <publisher> McGraw-Hill, </publisher> <address> New York, NY, </address> <year> 1992. </year>
Reference-contexts: It is expected that HPF will be a standard programming language for computationally intensive applications on many types of machines, such as traditional vector processors and newer massively parallel MIMD and SIMD multiprocessors." | The High Performance Fortran Handbook [69]. HPF is based on Fortran 90 <ref> [1] </ref>, which allows expressing data-parallel array expressions (that is, operations that act on whole arrays). In addition, Fortran 90 eliminates some of the deficiencies of Fortran 77. In particular, it allows the use of dynamically allocatable arrays as well as pointers. <p> As shown in Send z <ref> [1] </ref> at node 4 and Recv z [256] at node 9. If a Send is hoisted across multiple iterations, it requires prologue and epilogue communication loops that initiate appropriate number of Send and Recv primitives. <p> Assuming that the computation is partitioned using the owner-computes rule, the sequence of processors that processor 0 sends data to is PSend (0) = <ref> [0; 2; 2; 0; 1; 2; 0; 2] </ref>. (For any index j in the Global B on 151 processors. <p> Section 7.2 showed that Global B (7i+2) (0) = [2; 30; 51; 72; 79; 100; 121; 149] with the period 168 and PSend B (7i+2) (0), the sequence of processors that processor 0 sends data to, to be <ref> [0; 2; 2; 0; 1; 2; 0; 2] </ref>. Similarly, for B (7i + 5) we can compute Global B (7i+5) (0) = [5; 26; 54; 75; 96; 103; 124; 145] with the period 168, which results in PSend B (7i+5) (0) = [0; 0; 2; 0; 1; 2; 0; 2]. <p> Similarly, for B (7i + 5) we can compute Global B (7i+5) (0) = [5; 26; 54; 75; 96; 103; 124; 145] with the period 168, which results in PSend B (7i+5) (0) = <ref> [0; 0; 2; 0; 1; 2; 0; 2] </ref>.
Reference: [2] <author> A. V. Aho, R. Sethi, and J. Ullman. </author> <booktitle> Compilers: Principles, Techniques, and Tools. </booktitle> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <note> second edition, </note> <year> 1986. </year>
Reference-contexts: Section 4.9 compares our framework with previous work and Section 4.10 summarizes the framework. 4.1 Preliminaries This section describes the graph structure and the predicates used by our framework. 4.1.1 Interval-flow graph The communication placement framework (Section 4.2) is based on interval analysis <ref> [2] </ref>. Interval analysis incorporates program structure into data-flow equations to enable their non-iterative and efficient solution. However, unlike classical interval analysis, we do not construct a sequence of interval graphs by recursively collapsing intervals into single nodes. <p> Similarly, In order to compute the sets of data that processor 0 must send to other processors, we first determine the sequence of accesses to array B (in the global index space) that processor 0 owns, Global B (0) = <ref> [2; 30; 51; 72; 79; 100; 121; 149] </ref> with the period 168, and the corresponding iteration sequence Iter B (0) = [0; 4; 7; 10; 11; 14; 17; 21] with the period 24. <p> Assuming that the computation is partitioned using the owner-computes rule, the sequence of processors that processor 0 sends data to is PSend (0) = <ref> [0; 2; 2; 0; 1; 2; 0; 2] </ref>. (For any index j in the Global B on 151 processors. <p> do not expect the length of the expanded sequence to exceed the larger of the two block sizes.) After expansion, we get Iter A (0) = [0; 3; 5; 10; 12; 15; 17; 22] with the period 24, and the sequence of corresponding rhs accesses is Image rhs (0) = <ref> [2; 23; 37; 72; 86; 107; 121; 156] </ref> with the period 168. <p> In order be able to pack the messages corresponding to different rhs terms in a single pass over the array, we must find the union of PSend sequences corresponding to different rhs references. Section 7.2 showed that Global B (7i+2) (0) = <ref> [2; 30; 51; 72; 79; 100; 121; 149] </ref> with the period 168 and PSend B (7i+2) (0), the sequence of processors that processor 0 sends data to, to be [0; 2; 2; 0; 1; 2; 0; 2]. <p> Section 7.2 showed that Global B (7i+2) (0) = [2; 30; 51; 72; 79; 100; 121; 149] with the period 168 and PSend B (7i+2) (0), the sequence of processors that processor 0 sends data to, to be <ref> [0; 2; 2; 0; 1; 2; 0; 2] </ref>. Similarly, for B (7i + 5) we can compute Global B (7i+5) (0) = [5; 26; 54; 75; 96; 103; 124; 145] with the period 168, which results in PSend B (7i+5) (0) = [0; 0; 2; 0; 1; 2; 0; 2]. <p> Similarly, for B (7i + 5) we can compute Global B (7i+5) (0) = [5; 26; 54; 75; 96; 103; 124; 145] with the period 168, which results in PSend B (7i+5) (0) = <ref> [0; 0; 2; 0; 1; 2; 0; 2] </ref>. <p> By merging the two Global sequences we get Global B = <ref> [2; 5; 26; 30; : : : ; 124; 145; 149] </ref> with the period 168, and the unioned PSend B (0) = [0; 0; 0; 2; 2; 2; 0; 0; 1; 1; 2; 2; 0; 0; 2; 2]. 157 From this we can compute the sets of elements that a processor
Reference: [3] <author> S. Amarasinghe, J. Anderson, M. Lam, and C.-W. Tseng. </author> <title> An overview of the SUIF compiler for scalable parallel machines. </title> <booktitle> In Proceedings of the Seventh SIAM Conference on Parallel Processing for Scientific Computing, </booktitle> <address> San Francisco, CA, </address> <month> February </month> <year> 1995. </year>
Reference-contexts: Moreover, it illustrates that the communication optimizations depend not only on the dependence and data-flow information, but also on the resource constraints. It describes how communication optimizations are performed in the presence of not only arbitrary control flow but also resource constraints. 4. Current state-of-the-art HPF compilers <ref> [38, 3, 14] </ref> support techniques for simple regular distributions with a limited set of subscript patterns and provide either no or inefficient support for the general regular distribution (specifically, the cyclic (k) distribution; it is defined in Section 2.1.1). <p> Choose computation partitioning This phase is responsible for dividing work among processors. It determines the set of processors that execute every statement in the program. This phase can select different set of processors to execute different statements in a loop body. Unlike other HPF compilers <ref> [50, 38, 3, 14] </ref> that use either only owner computes rule or same computation partitioning for all the statements in a loop body, we evaluate the cost of various computation partitioning options and select the best option for each statement. <p> The sets of data that processor 0 must receive from other processors are computed similarly; we build the table of global indices for accesses made by processor 0, Global A (0) = [0; 15; 25; 50] with the period 60 and Iter A (0) = <ref> [0; 3; 5; 10] </ref> with the period 12. Since the iteration periods of Iter A and Iter B are differ processors. <p> of pk A =GCD (pk A ; s A ) and pk B =GCD (pk B ; s B ), but in practice we do not expect the length of the expanded sequence to exceed the larger of the two block sizes.) After expansion, we get Iter A (0) = <ref> [0; 3; 5; 10; 12; 15; 17; 22] </ref> with the period 24, and the sequence of corresponding rhs accesses is Image rhs (0) = [2; 23; 37; 72; 86; 107; 121; 156] with the period 168.
Reference: [4] <author> S. Amarasinghe and M. Lam. </author> <title> Communication optimization and code generation for distributed memory machines. </title> <booktitle> In Proceedings of the SIGPLAN '93 Conference on Programming Language Design and Implementation, </booktitle> <address> Albuquerque, NM, </address> <month> June </month> <year> 1993. </year>
Reference-contexts: This restricts the application of communication optimizations to communication primitives arising from individual loop nests only. For example, redundant communication elimination does not recognize redundant messages from different loop nests. SUIF compiler SUIF (Stanford University Intermediate Format) compiler is targetted towards efficient compilation of dense linear-algebra, data-parallel codes <ref> [7, 4] </ref>. Unlike HPF compilers, SUIF does not require users to provide data distributions for the shared arrays. <p> Unlike the Fortran D95 compiler, it assigns a loop iteration to a single processor; that is, it does not evaluate computation paritioning choices for individual statements and assigns same computation partitioning to all statements in a loop body <ref> [4] </ref>. SUIF compiler uses last write trees (LWTs) for computing precise array data-flow information efficiently for commonly occuring special cases [74, 4]. LWT analysis is performed on individual loop nests. <p> SUIF compiler uses last write trees (LWTs) for computing precise array data-flow information efficiently for commonly occuring special cases <ref> [74, 4] </ref>. LWT analysis is performed on individual loop nests. Due to the use of LWTs, the communication and computation code generation is limited to programs con 22 sisting of loop nests with affine array accesses and loop bounds. The technique cannot handle loops nested inside conditionals. <p> The problem of data-flow based communication placement has been addressed by several researchers. Amarasinghe and Lam use a last write tree to optimize communication placement and support VMP within a single loop nest <ref> [4] </ref>. Moreover, they don't allow loops within conditionals. Granston and Veidenbaum combine PRE and dependence analysis to eliminate redundant monolithic global-memory accesses across loop nests in the presence of conditionals [37]. <p> Therefore, the S table will have 12, 10, 8 , 6, 4 and 2 as the number of elements skipped for the first elements with offsets 4, 6, 8, 10, 12 and 14 respectively (that is, S <ref> [4] </ref> = 12, S [6] = 10, and so on). <p> 0 must send to other processors, we first determine the sequence of accesses to array B (in the global index space) that processor 0 owns, Global B (0) = [2; 30; 51; 72; 79; 100; 121; 149] with the period 168, and the corresponding iteration sequence Iter B (0) = <ref> [0; 4; 7; 10; 11; 14; 17; 21] </ref> with the period 24. After multiplying the iteration numbers by the stride s A , we get the global index sequence of corresponding left-hand-side (lhs) accesses, Image lhs (0) = [0; 20; 35; 50; 55; 70; 85; 105] with the period 120.
Reference: [5] <author> C. Ancourt, F. Coelho, F. Irigoin, and R. Keryell. </author> <title> A linear algebra framework for static HPF code distribution. </title> <booktitle> In Proceedings of the Fourth Workshop on Compilers for Parallel Computers, </booktitle> <address> Delft, The Netherlands, </address> <month> December </month> <year> 1993. </year>
Reference-contexts: A lot of research has been done to represent array sections efficiently <ref> [29, 8, 46, 7, 6, 5, 82] </ref>. Explicit representations can be classified as either precise or imprecise representations. The latter category of representations tend to sacrifice precision for efficiency. Imprecise representations use closed-form formulae or a restricted class of geometric patterns to approximate given array section with a convex region. <p> The sets of data that processor 0 must receive from other processors are computed similarly; we build the table of global indices for accesses made by processor 0, Global A (0) = [0; 15; 25; 50] with the period 60 and Iter A (0) = <ref> [0; 3; 5; 10] </ref> with the period 12. Since the iteration periods of Iter A and Iter B are differ processors. <p> of pk A =GCD (pk A ; s A ) and pk B =GCD (pk B ; s B ), but in practice we do not expect the length of the expanded sequence to exceed the larger of the two block sizes.) After expansion, we get Iter A (0) = <ref> [0; 3; 5; 10; 12; 15; 17; 22] </ref> with the period 24, and the sequence of corresponding rhs accesses is Image rhs (0) = [2; 23; 37; 72; 86; 107; 121; 156] with the period 168. <p> Similarly, for B (7i + 5) we can compute Global B (7i+5) (0) = <ref> [5; 26; 54; 75; 96; 103; 124; 145] </ref> with the period 168, which results in PSend B (7i+5) (0) = [0; 0; 2; 0; 1; 2; 0; 2]. <p> By merging the two Global sequences we get Global B = <ref> [2; 5; 26; 30; : : : ; 124; 145; 149] </ref> with the period 168, and the unioned PSend B (0) = [0; 0; 0; 2; 2; 2; 0; 0; 1; 1; 2; 2; 0; 0; 2; 2]. 157 From this we can compute the sets of elements that a processor <p> We have extensively cited and described two of the previous works in the chapter: the virtual-block scheme proposed by Gupta et al. [41] and the approach described by Chatterjee et al. [18]. Ancourt et al. use a linear algebra framework for compiling independent loops in HPF <ref> [5] </ref>. Although they can handle arbitrary affine array subscripts, the generated loop bounds and local array subscripts can be quite complex, and thus introduce a significant overhead. Furthermore, the assumption of independent parallelism allows them to enumerate loop iterations in any order, which is, in general, not always possible.
Reference: [6] <author> C. Ancourt and F. Irigoin. </author> <title> Scanning polyhedra with do loops. </title> <booktitle> In Proceedings of the Third ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, </booktitle> <address> Williamsburg, VA, </address> <month> April </month> <year> 1991. </year> <month> 166 </month>
Reference-contexts: Since LWTs are based on individual loop nests, SUIF compiler does not support global data-flow analysis. SUIF includes a package for manipulating linear inequalities. It uses Fourier Motzkin Elimination (FME) to generate loop nests corresponding to a system of linear inequalities <ref> [6] </ref>. For example, it uses FME to generate pack/send and receive/unpack loops. PARADIGM compiler The PARADIGM compiler, like the SUIF compiler, provides an automated means to parallelize programs written in a serial programming model [9]. <p> A lot of research has been done to represent array sections efficiently <ref> [29, 8, 46, 7, 6, 5, 82] </ref>. Explicit representations can be classified as either precise or imprecise representations. The latter category of representations tend to sacrifice precision for efficiency. Imprecise representations use closed-form formulae or a restricted class of geometric patterns to approximate given array section with a convex region. <p> PTDs are closed under intersection while union and difference can result in a list of sets. Fourier-Motzkin elimination A lot of researchers have proposed precise array section representations based on the Fourier-Motzkin elimination method <ref> [29, 6, 7, 57, 82] </ref>. These representations represent array sections with a set of linear inequalities. Operations on array sections, such as union, intersection, and difference are performed by manipu 36 lating the linear inequalities; thus, these operations can take exponential time in the worst case. <p> Therefore, the S table will have 12, 10, 8 , 6, 4 and 2 as the number of elements skipped for the first elements with offsets 4, 6, 8, 10, 12 and 14 respectively (that is, S [4] = 12, S <ref> [6] </ref> = 10, and so on).
Reference: [7] <author> J. Anderson and M. Lam. </author> <title> Global optimizations for parallelism and locality on scalable parallel machines. </title> <booktitle> In Proceedings of the SIGPLAN '93 Conference on Programming Language Design and Implementation, </booktitle> <address> Albuquerque, NM, </address> <month> June </month> <year> 1993. </year>
Reference-contexts: This restricts the application of communication optimizations to communication primitives arising from individual loop nests only. For example, redundant communication elimination does not recognize redundant messages from different loop nests. SUIF compiler SUIF (Stanford University Intermediate Format) compiler is targetted towards efficient compilation of dense linear-algebra, data-parallel codes <ref> [7, 4] </ref>. Unlike HPF compilers, SUIF does not require users to provide data distributions for the shared arrays. <p> Unlike HPF compilers, SUIF does not require users to provide data distributions for the shared arrays. It computes data distribution based on the computation being performed; restricting focus to regular, dense linear-algebra code allows the data distribution and computation partitioning problems to be formulated and solved using linear inequalities <ref> [7] </ref>. Unlike the Fortran D95 compiler, it assigns a loop iteration to a single processor; that is, it does not evaluate computation paritioning choices for individual statements and assigns same computation partitioning to all statements in a loop body [4]. <p> A lot of research has been done to represent array sections efficiently <ref> [29, 8, 46, 7, 6, 5, 82] </ref>. Explicit representations can be classified as either precise or imprecise representations. The latter category of representations tend to sacrifice precision for efficiency. Imprecise representations use closed-form formulae or a restricted class of geometric patterns to approximate given array section with a convex region. <p> PTDs are closed under intersection while union and difference can result in a list of sets. Fourier-Motzkin elimination A lot of researchers have proposed precise array section representations based on the Fourier-Motzkin elimination method <ref> [29, 6, 7, 57, 82] </ref>. These representations represent array sections with a set of linear inequalities. Operations on array sections, such as union, intersection, and difference are performed by manipu 36 lating the linear inequalities; thus, these operations can take exponential time in the worst case. <p> 0 must send to other processors, we first determine the sequence of accesses to array B (in the global index space) that processor 0 owns, Global B (0) = [2; 30; 51; 72; 79; 100; 121; 149] with the period 168, and the corresponding iteration sequence Iter B (0) = <ref> [0; 4; 7; 10; 11; 14; 17; 21] </ref> with the period 24. After multiplying the iteration numbers by the stride s A , we get the global index sequence of corresponding left-hand-side (lhs) accesses, Image lhs (0) = [0; 20; 35; 50; 55; 70; 85; 105] with the period 120.
Reference: [8] <author> V. Balasundaram. </author> <title> A mechanism for keeping useful internal information in parallel programming tools: The data access descriptor. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 9(2) </volume> <pages> 154-170, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: A lot of research has been done to represent array sections efficiently <ref> [29, 8, 46, 7, 6, 5, 82] </ref>. Explicit representations can be classified as either precise or imprecise representations. The latter category of representations tend to sacrifice precision for efficiency. Imprecise representations use closed-form formulae or a restricted class of geometric patterns to approximate given array section with a convex region. <p> Data access descriptors Data access descriptors (DADs) are more general than RSDs and can be used to represent a convex polyhedra that is bounded by hyperplanes that are either orthogonal to the axis or at 45 o angles with a pair of axes <ref> [8] </ref>. Thus, unlike RSDs, DADs can represent triangular array sections as well as diagonal and banded diagonal array sections. The intersection and union operations on DADs can take time proportional to the number of dimensions of the section. DADs are closed under intersection.
Reference: [9] <author> P. Banerjee, J. Chandy, M. Gupta, J.G.Holm, A. Lain, D.J. Palermo, S. Ra-maswamy, and E. Su. </author> <title> The PARADIGM compiler for distributed-memory message passing multicomputers. </title> <booktitle> In First International Workshop on Parallel Processing, </booktitle> <address> Banglore, India, </address> <month> December </month> <year> 1994. </year>
Reference-contexts: For example, it uses FME to generate pack/send and receive/unpack loops. PARADIGM compiler The PARADIGM compiler, like the SUIF compiler, provides an automated means to parallelize programs written in a serial programming model <ref> [9] </ref>. In addition to automatically performing data distribution for regular computations, it optionally parses HPF data distribution directives. It supports all the three regular distributions provided by HPF [82]. The PARADIGM compiler performs computation partitioning based only on the owner-computes rule.
Reference: [10] <author> D. Bell and J. </author> <title> Grimson. Distributed Database Systems. </title> <publisher> Addison-Wesley Publishing Company, </publisher> <address> Great Britain, </address> <year> 1992. </year>
Reference-contexts: This problem 101 102 103 is very similar to the ones encountered in scheduling and database management (file allocation) problems <ref> [32, 10] </ref> and can be similarly shown to be NP-complete: the knapsack problem [32] can be trivially reduced to the problem of optimally selecting the messages that should use the available buffer at any given node. <p> 0 must send to other processors, we first determine the sequence of accesses to array B (in the global index space) that processor 0 owns, Global B (0) = [2; 30; 51; 72; 79; 100; 121; 149] with the period 168, and the corresponding iteration sequence Iter B (0) = <ref> [0; 4; 7; 10; 11; 14; 17; 21] </ref> with the period 24. After multiplying the iteration numbers by the stride s A , we get the global index sequence of corresponding left-hand-side (lhs) accesses, Image lhs (0) = [0; 20; 35; 50; 55; 70; 85; 105] with the period 120. <p> The sets of data that processor 0 must receive from other processors are computed similarly; we build the table of global indices for accesses made by processor 0, Global A (0) = [0; 15; 25; 50] with the period 60 and Iter A (0) = <ref> [0; 3; 5; 10] </ref> with the period 12. Since the iteration periods of Iter A and Iter B are differ processors. <p> of pk A =GCD (pk A ; s A ) and pk B =GCD (pk B ; s B ), but in practice we do not expect the length of the expanded sequence to exceed the larger of the two block sizes.) After expansion, we get Iter A (0) = <ref> [0; 3; 5; 10; 12; 15; 17; 22] </ref> with the period 24, and the sequence of corresponding rhs accesses is Image rhs (0) = [2; 23; 37; 72; 86; 107; 121; 156] with the period 168.
Reference: [11] <author> S. Benkner, P. Brezany, and H. Zima. </author> <title> Processing array statements and procedure interfaces in the PREPARE High Performance Fortran compiler. </title> <booktitle> In Compiler Conference, </booktitle> <address> Edinburgh, </address> <month> April </month> <year> 1994. </year>
Reference-contexts: The compiler partitions computations based on owner-computes rule only. Though it does not support data-flow analysis for communication placement, the compiler splits loops into local and nonlocal parts and uses the local part to hide communication latency <ref> [11] </ref>. Fortran 90D compiler was originally targetted towards providing Fortran 90 support in addition to the data distribution directives (this was before HPF was developed) [19]. Over the last few years, the Fortran 90D compiler has 25 developed a compilation framework to provide an efficient, portable run-time library. <p> 0 must send to other processors, we first determine the sequence of accesses to array B (in the global index space) that processor 0 owns, Global B (0) = [2; 30; 51; 72; 79; 100; 121; 149] with the period 168, and the corresponding iteration sequence Iter B (0) = <ref> [0; 4; 7; 10; 11; 14; 17; 21] </ref> with the period 24. After multiplying the iteration numbers by the stride s A , we get the global index sequence of corresponding left-hand-side (lhs) accesses, Image lhs (0) = [0; 20; 35; 50; 55; 70; 85; 105] with the period 120.
Reference: [12] <author> R. Bordawekar, A. Choudhary, K. Kennedy, C. Koelbel, and M. Paleczny. </author> <title> A model and compilation strategy for out-of-core data parallel programs. </title> <booktitle> In Proceedings of the Fifth ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, </booktitle> <pages> pages 1-10, </pages> <address> Santa Barbara, CA, </address> <month> July </month> <year> 1995. </year>
Reference-contexts: Over the last few years, the Fortran 90D compiler has 25 developed a compilation framework to provide an efficient, portable run-time library. The compiler includes efficient libraries for redistribution as well as for supporting scalable I/O and out-of-core computations <ref> [13, 12] </ref>. The compilation effort at University of Maryland has been directed at towards providing providing efficient run-time support for irregular references [45, 42]. They have developed PARTI/CHAOS run-time library to support computation and communication generation efficiently [23]. <p> of pk A =GCD (pk A ; s A ) and pk B =GCD (pk B ; s B ), but in practice we do not expect the length of the expanded sequence to exceed the larger of the two block sizes.) After expansion, we get Iter A (0) = <ref> [0; 3; 5; 10; 12; 15; 17; 22] </ref> with the period 24, and the sequence of corresponding rhs accesses is Image rhs (0) = [2; 23; 37; 72; 86; 107; 121; 156] with the period 168.
Reference: [13] <author> Z. Bozkus, A. Choudhary, G. Fox, T. Haupt, S. Ranka, and M. Wu. </author> <title> Compiling Fortran 90D/HPF for distributed memory MIMD computers. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 21(1) </volume> <pages> 15-26, </pages> <month> April </month> <year> 1994. </year> <month> 167 </month>
Reference-contexts: Over the last few years, the Fortran 90D compiler has 25 developed a compilation framework to provide an efficient, portable run-time library. The compiler includes efficient libraries for redistribution as well as for supporting scalable I/O and out-of-core computations <ref> [13, 12] </ref>. The compilation effort at University of Maryland has been directed at towards providing providing efficient run-time support for irregular references [45, 42]. They have developed PARTI/CHAOS run-time library to support computation and communication generation efficiently [23].
Reference: [14] <author> Z. Bozkus, L. Meadows, S. Nakamoto, V. Schuster, and M. Young. </author> <title> Compiling high performance fortran. </title> <booktitle> In Proceedings of the Seventh SIAM Conference on Parallel Processing for Scientific Computing, </booktitle> <pages> pages 704-709, </pages> <address> San Francisco, CA, </address> <month> February </month> <year> 1995. </year>
Reference-contexts: Moreover, it illustrates that the communication optimizations depend not only on the dependence and data-flow information, but also on the resource constraints. It describes how communication optimizations are performed in the presence of not only arbitrary control flow but also resource constraints. 4. Current state-of-the-art HPF compilers <ref> [38, 3, 14] </ref> support techniques for simple regular distributions with a limited set of subscript patterns and provide either no or inefficient support for the general regular distribution (specifically, the cyclic (k) distribution; it is defined in Section 2.1.1). <p> Choose computation partitioning This phase is responsible for dividing work among processors. It determines the set of processors that execute every statement in the program. This phase can select different set of processors to execute different statements in a loop body. Unlike other HPF compilers <ref> [50, 38, 3, 14] </ref> that use either only owner computes rule or same computation partitioning for all the statements in a loop body, we evaluate the cost of various computation partitioning options and select the best option for each statement. <p> 0 must send to other processors, we first determine the sequence of accesses to array B (in the global index space) that processor 0 owns, Global B (0) = [2; 30; 51; 72; 79; 100; 121; 149] with the period 168, and the corresponding iteration sequence Iter B (0) = <ref> [0; 4; 7; 10; 11; 14; 17; 21] </ref> with the period 24. After multiplying the iteration numbers by the stride s A , we get the global index sequence of corresponding left-hand-side (lhs) accesses, Image lhs (0) = [0; 20; 35; 50; 55; 70; 85; 105] with the period 120.
Reference: [15] <author> D. Callahan and K. Kennedy. </author> <title> Analysis of interprocedural side effects in a parallel programming environment. </title> <booktitle> In Proceedings of the First International Conference on Supercomputing. </booktitle> <publisher> Springer-Verlag, </publisher> <address> Athens, Greece, </address> <month> June </month> <year> 1987. </year>
Reference-contexts: Intuitively, regular sections correspond to rectangular or right-triangular array sections and their higher dimension analogs <ref> [15, 46] </ref>. RSDs can also represent regular sections with constant stride. RSDs were originally developed for summarizing side effects across procedure boundaries and represent array sections using an imprecise representation. RSDs were used extensively in the Fortran D compiler [85]. <p> Therefore, we can construct a table such that each entry S [t] contains the number of array elements between the first element accessed by the outer loop iteration first, such that first mod pk = t, and the starting location for processor m. For example, the S <ref> [15] </ref> entry of the table for processor 2 is 10 because offset 15 corresponds to the first ele 140 ment, 111, accessed by the fourth iteration of the outer loop and the starting location for processor 2 is 121; therefore, the number of elements that need to be skipped is 121 <p> The sets of data that processor 0 must receive from other processors are computed similarly; we build the table of global indices for accesses made by processor 0, Global A (0) = <ref> [0; 15; 25; 50] </ref> with the period 60 and Iter A (0) = [0; 3; 5; 10] with the period 12. Since the iteration periods of Iter A and Iter B are differ processors. <p> of pk A =GCD (pk A ; s A ) and pk B =GCD (pk B ; s B ), but in practice we do not expect the length of the expanded sequence to exceed the larger of the two block sizes.) After expansion, we get Iter A (0) = <ref> [0; 3; 5; 10; 12; 15; 17; 22] </ref> with the period 24, and the sequence of corresponding rhs accesses is Image rhs (0) = [2; 23; 37; 72; 86; 107; 121; 156] with the period 168.
Reference: [16] <author> B. Chapman, P. Mehrotra, and H. Zima. </author> <title> Programming in Vienna Fortran. </title> <journal> Scientific Programming, </journal> <volume> 1(1) </volume> <pages> 31-50, </pages> <month> Fall </month> <year> 1992. </year>
Reference-contexts: The source language used by this project was Vienna Fortran <ref> [16, 17] </ref>; one of the predecessors of HPF. The Vienna Fortran group pioneered various compilation techniques [33, 35, 86]. The compiler introduced owner-computes rule and message vectorization. It also introduced the concept of overlap areas for regular, stencil-based computations.
Reference: [17] <author> B. Chapman, P. Mehrotra, and H. Zima. </author> <title> Vienna Fortran | A Fortran language extension for distributed memory multiprocessors. </title> <editor> In J. Saltz and P. Mehro-tra, editors, </editor> <title> Languages, Compilers, and Run-Time Environments for Distributed Memory Machines. </title> <publisher> North-Holland, </publisher> <address> Amsterdam, The Netherlands, </address> <year> 1992. </year>
Reference-contexts: The source language used by this project was Vienna Fortran <ref> [16, 17] </ref>; one of the predecessors of HPF. The Vienna Fortran group pioneered various compilation techniques [33, 35, 86]. The compiler introduced owner-computes rule and message vectorization. It also introduced the concept of overlap areas for regular, stencil-based computations. <p> 0 must send to other processors, we first determine the sequence of accesses to array B (in the global index space) that processor 0 owns, Global B (0) = [2; 30; 51; 72; 79; 100; 121; 149] with the period 168, and the corresponding iteration sequence Iter B (0) = <ref> [0; 4; 7; 10; 11; 14; 17; 21] </ref> with the period 24. After multiplying the iteration numbers by the stride s A , we get the global index sequence of corresponding left-hand-side (lhs) accesses, Image lhs (0) = [0; 20; 35; 50; 55; 70; 85; 105] with the period 120. <p> of pk A =GCD (pk A ; s A ) and pk B =GCD (pk B ; s B ), but in practice we do not expect the length of the expanded sequence to exceed the larger of the two block sizes.) After expansion, we get Iter A (0) = <ref> [0; 3; 5; 10; 12; 15; 17; 22] </ref> with the period 24, and the sequence of corresponding rhs accesses is Image rhs (0) = [2; 23; 37; 72; 86; 107; 121; 156] with the period 168.
Reference: [18] <author> S. Chatterjee, J. Gilbert, F. Long, R. Schreiber, and S. Teng. </author> <title> Generating local addresses and communication sets for data-parallel programs. </title> <booktitle> In Proceedings of the Fourth ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, </booktitle> <address> San Diego, CA, </address> <month> May </month> <year> 1993. </year>
Reference-contexts: In other words, in Figure 3.5, we have stacked the blocks assigned to a particular processor one under another. This view of the cyclic (k) distribution was first suggested by Chatterjee et al. <ref> [18] </ref>. 38 The squares mark the array elements accessed by a (5i) (i 0). Once we arrange the block-cyclically distributed array as shown in Figure 3.5, it can be seen that there exists a pattern in the array accesses. <p> The key observation, made by Chatterjee et al., is that the offset of an element determines the offset of the next element on the same processor <ref> [18] </ref>. Since the offsets range between 123 0 and k 1 (where k is the block size of the cyclic (k) distribution), by pigeon-hole principle, at least two of the first k + 1 local memory locations on any particular processor must have the same offset. <p> The algorithm stops when it finds a non-empty table entry; as mentioned before, for a given stride s, block size k, and number of processors p, it can be proved that the offset of an access completely specifies the offset the next access on the processor <ref> [18] </ref>. Therefore, if the algorithm comes across a non-empty table entry, it is guaranteed that the sequence of access gaps will repeat. <p> Chatterjee et al. have shown that for multidimensional regular array sections (corresponding to array references with independent subscripts), the memory access problem reduces to multiple applications of the algorithm used for the one-dimensional case <ref> [18] </ref>. <p> A 145 typical example of a loop with coupled subscripts is shown below. do i = l; u enddo In order to use table lookups for address generation of array references with coupled subscripts, we first show how the method presented by Chatterjee et al. <ref> [18] </ref> can be extended to find the starting location. Let l 1 = s 1 l + c 1 and l 2 = s 2 l + c 2 be the values of the two subscripts in the first loop iteration. <p> (m 1 ; m 2 ) corresponds to the smallest non-negative integer j which satisfies both of the following two inequalities k 1 m 1 (l 1 + s 1 j) mod p 1 k 1 &lt; k 1 (m 1 + 1); and As shown by Chatterjee et al. <ref> [18] </ref> for the one-dimensional case, finding such a j is equivalent to finding the minimum of the smallest non-negative solutions of the following set of simultaneous linear Diophantine equations fs 1 j p 1 k 1 q 1 = i 1 j k 1 m 1 l 1 i 1 k <p> The complete algorithm to determine the processor's starting location is shown in Figure 7.9. Using the same idea as described by Chatterjee et al. <ref> [18] </ref> for the one-dimensional case, the table of memory gaps can be obtained by first sorting the initial sequence of array accesses and then computing the distances between every two consecutive locations. <p> (k B ) distributions: do i = 0, u enddo Chatterjee et al. show that for each reference, the sequence of array elements accessed by any given processor can be computed using a table of local memory gaps whose size does not exceed the block size of the array's distribution <ref> [18] </ref>. <p> Chatterjee et al. show that only one pass over the locally owned elements of array B is needed to build all outgoing messages <ref> [18] </ref>. However, an ownership computation involving integer divisions is performed for each array access, in order to determine the destination processors for the accessed elements. <p> Processor m scans the elements of B it owns using the NextIndex function, which can be implemented using either the table of the local memory gaps between consecutive array accesses <ref> [18] </ref> or our demand-driven address generation method [61]. index B = start B ; count P = 0 while (index B &lt; end B ) do if (PSend [count P ] 6= m) then fl (buffer [PSend [count P ]])++ = B [index B ] endif count P = (count P <p> Neither Chatterjee et al. <ref> [18] </ref> nor Gupta et al. [41] deal with this issue. Stichnoth [80] indicates that combining communication steps would be profitable, but he does not describe the necessary analysis. In contrast, we show how our approach can support message coalescing optimization [48] to reduce the communication cost. <p> We have extensively cited and described two of the previous works in the chapter: the virtual-block scheme proposed by Gupta et al. [41] and the approach described by Chatterjee et al. <ref> [18] </ref>. Ancourt et al. use a linear algebra framework for compiling independent loops in HPF [5]. Although they can handle arbitrary affine array subscripts, the generated loop bounds and local array subscripts can be quite complex, and thus introduce a significant overhead.
Reference: [19] <author> A. Choudhary, G. Fox, S. Hiranandani, K. Kennedy, C. Koelbel, S. Ranka, and C.-W. Tseng. </author> <title> Unified compilation of Fortran 77D and 90D. </title> <journal> ACM Letters on Programming Languages and Systems, </journal> <volume> 2(1-4):95-114, </volume> <month> March-December </month> <year> 1993. </year>
Reference-contexts: Fortran 90D compiler was originally targetted towards providing Fortran 90 support in addition to the data distribution directives (this was before HPF was developed) <ref> [19] </ref>. Over the last few years, the Fortran 90D compiler has 25 developed a compilation framework to provide an efficient, portable run-time library. The compiler includes efficient libraries for redistribution as well as for supporting scalable I/O and out-of-core computations [13, 12].
Reference: [20] <author> T.H. Cormen, C.E. Leiserson, and R.L. Rivest. </author> <title> Introduction to Algorithms. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1990. </year>
Reference-contexts: The squares mark the array elements accessed by A (3i). 125 The equations can be solved independently (solutions exist for an individual equation if and only if is divisible by GCD (s; pk)). The general solution of a linear Diophantine equation can be found using extended Euclid algorithm <ref> [20] </ref>. The smallest solution for each of these k Diophantine equations gives an access in the first cycle. Since solving the above system of equations requires computing only a single GCD, the accesses in the first cycle can be computed in O (log min (s; pk) + k). <p> Two separate applications of the extended Euclid algorithm <ref> [20] </ref> determine d 1 ; ff 1 ; fi 1 and d 2 ; ff 2 ; fi 2 . <p> After multiplying the iteration numbers by the stride s A , we get the global index sequence of corresponding left-hand-side (lhs) accesses, Image lhs (0) = <ref> [0; 20; 35; 50; 55; 70; 85; 105] </ref> with the period 120.
Reference: [21] <institution> CONVEX Computer Corporation. Exemplar Architecture. CONVEX Press, Richardson, Texas, </institution> <note> first edition, 1993. 168 </note>
Reference-contexts: Another goal of the Fortran D95 compiler is to be compile HPF for a variety of architecture classes. Towards this end, we are currently targeting both the distributed-memory systems (using Message Passing Interface [26], MPI, library for message passing routines) and hardware DSM systems such as Convex Exemplar <ref> [21] </ref> as well as the software DSM systems such as TreadMarks [55]. outlines different phases of the Fortran D95 compiler in order to present the context 12 under which the communication generation techniques have been implemented. <p> 0 must send to other processors, we first determine the sequence of accesses to array B (in the global index space) that processor 0 owns, Global B (0) = [2; 30; 51; 72; 79; 100; 121; 149] with the period 168, and the corresponding iteration sequence Iter B (0) = <ref> [0; 4; 7; 10; 11; 14; 17; 21] </ref> with the period 24. After multiplying the iteration numbers by the stride s A , we get the global index sequence of corresponding left-hand-side (lhs) accesses, Image lhs (0) = [0; 20; 35; 50; 55; 70; 85; 105] with the period 120.
Reference: [22] <author> R. Das, M. Uysal, J. Saltz, and Y-S. Hwang. </author> <title> Communication optimizations for irregular scientific computations on distributed memory architectures. </title> <type> Technical Report CS-TR-3163, </type> <institution> Dept. of Computer Science, Univ. of Maryland, College Park, </institution> <month> October </month> <year> 1993. </year>
Reference-contexts: of pk A =GCD (pk A ; s A ) and pk B =GCD (pk B ; s B ), but in practice we do not expect the length of the expanded sequence to exceed the larger of the two block sizes.) After expansion, we get Iter A (0) = <ref> [0; 3; 5; 10; 12; 15; 17; 22] </ref> with the period 24, and the sequence of corresponding rhs accesses is Image rhs (0) = [2; 23; 37; 72; 86; 107; 121; 156] with the period 168. <p> efficient code at the receiving end and find the lengths of the DRecv sequences. 7.3 Code generation When generating communication for irregular problems, Das et al. allocate buffers for the non-local data immediately following the space for local array elements and translate the off-processor references to point to buffer addresses <ref> [22] </ref>. Using a similar idea, we allocate the space for the local and non-local rhs references contiguously, but we have a separate, appropriately sized buffer for each processor in PRecv [ PSend.
Reference: [23] <author> R. Das, M. Uysal, J. Saltz, and Y.-S. Hwang. </author> <title> Communication optimizations for irregular scientific computations on distributed memory architectures. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 22(3) </volume> <pages> 462-479, </pages> <month> September </month> <year> 1994. </year>
Reference-contexts: The compilation effort at University of Maryland has been directed at towards providing providing efficient run-time support for irregular references [45, 42]. They have developed PARTI/CHAOS run-time library to support computation and communication generation efficiently <ref> [23] </ref>. <p> do not expect the length of the expanded sequence to exceed the larger of the two block sizes.) After expansion, we get Iter A (0) = [0; 3; 5; 10; 12; 15; 17; 22] with the period 24, and the sequence of corresponding rhs accesses is Image rhs (0) = <ref> [2; 23; 37; 72; 86; 107; 121; 156] </ref> with the period 168.
Reference: [24] <author> D.M.Dhamdhere. </author> <title> A fast algorithm for code movemenet optimization. </title> <journal> ACM SIGPLAN Notices, </journal> <volume> 23(10) </volume> <pages> 172-180, </pages> <year> 1988. </year>
Reference-contexts: Clearly, this is an incorrect placement because if the right branch is taken, then the Recv x will not have a matching Send x. It is well known that the code motion process may be blocked by critical edges <ref> [24, 27, 79] </ref>.
Reference: [25] <author> J. Dongarra, R. van de Geijn, and D. Walker. </author> <title> A look at scalable dense linear algebra libraries. </title> <booktitle> In Proceedings of the 1992 Scalable High Performance Computing Conference, </booktitle> <pages> pages 372-379, </pages> <address> Williamsburg, VA, </address> <month> April </month> <year> 1992. </year>
Reference-contexts: Figure 2.2 shows an examples for each of the three distributions. Cyclic and cyclic (k) distributions are useful for writing efficient and load-balanced dense matrix algorithms <ref> [25] </ref>. 2.2 The Fortran D95 compiler The Fortran D95 compiler, being developed at Rice University, is a research and prototype compiler for HPF. A goal of the Fortran D95 compiler is to achieve performance comparable to or better than that extracted extracted by hand-compiled programs. <p> The sets of data that processor 0 must receive from other processors are computed similarly; we build the table of global indices for accesses made by processor 0, Global A (0) = <ref> [0; 15; 25; 50] </ref> with the period 60 and Iter A (0) = [0; 3; 5; 10] with the period 12. Since the iteration periods of Iter A and Iter B are differ processors.
Reference: [26] <author> J. Dongarra and D. Walker. </author> <title> MPI: The Message Passing Interface standard. </title> <journal> International Journal of Supercomputing Applications, </journal> <volume> 8(3) </volume> <pages> 151-180, </pages> <year> 1994. </year>
Reference-contexts: Next, we perform aggressive analysis and program transformations to optimize communication. Another goal of the Fortran D95 compiler is to be compile HPF for a variety of architecture classes. Towards this end, we are currently targeting both the distributed-memory systems (using Message Passing Interface <ref> [26] </ref>, MPI, library for message passing routines) and hardware DSM systems such as Convex Exemplar [21] as well as the software DSM systems such as TreadMarks [55]. outlines different phases of the Fortran D95 compiler in order to present the context 12 under which the communication generation techniques have been implemented. <p> Similarly, for B (7i + 5) we can compute Global B (7i+5) (0) = <ref> [5; 26; 54; 75; 96; 103; 124; 145] </ref> with the period 168, which results in PSend B (7i+5) (0) = [0; 0; 2; 0; 1; 2; 0; 2]. <p> By merging the two Global sequences we get Global B = <ref> [2; 5; 26; 30; : : : ; 124; 145; 149] </ref> with the period 168, and the unioned PSend B (0) = [0; 0; 0; 2; 2; 2; 0; 0; 1; 1; 2; 2; 0; 0; 2; 2]. 157 From this we can compute the sets of elements that a processor
Reference: [27] <author> K. Drechsler and M. Stadel. </author> <title> A solution to a problem with Morel and Renvoise's "global optimization by suppression of partial redundancies". </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 10(4) </volume> <pages> 635-640, </pages> <month> October </month> <year> 1988. </year>
Reference-contexts: Clearly, this is an incorrect placement because if the right branch is taken, then the Recv x will not have a matching Send x. It is well known that the code motion process may be blocked by critical edges <ref> [24, 27, 79] </ref>.
Reference: [28] <author> F.E.Allen. </author> <title> Control flow analysis. </title> <journal> ACM SIGPLAN Notices, </journal> <volume> 5(7) </volume> <pages> 1-19, </pages> <year> 1970. </year>
Reference-contexts: Tarjan intervals include only nodes that are part of a loop; that is, together with the header node h, the nodes in T (h) form a strongly connected region. As described by von Hanxleden [43], this 46 differs from the Allen-Cocke intervals <ref> [28, 53, 58] </ref> used in classical interval analysis. Allen-Cocke intervals include nodes whose predecessors are all in T (h); that is, they might include an acyclic structure dangling off the loop. Interval-flow graph differs from a control-flow graph in the way in which edges 2 E are classified.
Reference: [29] <author> P. Feautrier. </author> <title> Parametric integer programming. </title> <journal> Operationnelle/Operations Research, </journal> <volume> 22(3) </volume> <pages> 243-268, </pages> <month> September </month> <year> 1988. </year>
Reference-contexts: A lot of research has been done to represent array sections efficiently <ref> [29, 8, 46, 7, 6, 5, 82] </ref>. Explicit representations can be classified as either precise or imprecise representations. The latter category of representations tend to sacrifice precision for efficiency. Imprecise representations use closed-form formulae or a restricted class of geometric patterns to approximate given array section with a convex region. <p> A precise representation uses a set of inequalities to represent array sections. Clearly, this is the most powerful representation and can be used to represent any set. The problem of representing precise array data-flow information was first formulated by Feautrier <ref> [29, 30] </ref>. Feautrier proposed a parametric integer programming algorithm that can find such perfect information in the domain of loop nests where the loop bounds and array indices are affine functions of loop indices. However, operations 34 such as intersection and union have exponential time complexity in the worst case. <p> PTDs are closed under intersection while union and difference can result in a list of sets. Fourier-Motzkin elimination A lot of researchers have proposed precise array section representations based on the Fourier-Motzkin elimination method <ref> [29, 6, 7, 57, 82] </ref>. These representations represent array sections with a set of linear inequalities. Operations on array sections, such as union, intersection, and difference are performed by manipu 36 lating the linear inequalities; thus, these operations can take exponential time in the worst case.
Reference: [30] <author> P. Feautrier. </author> <title> Dataflow analysis of scalar and array references. </title> <journal> International Journal of Parallel Programming, </journal> <volume> 20(1) </volume> <pages> 23-52, </pages> <month> February </month> <year> 1991. </year> <month> 169 </month>
Reference-contexts: A precise representation uses a set of inequalities to represent array sections. Clearly, this is the most powerful representation and can be used to represent any set. The problem of representing precise array data-flow information was first formulated by Feautrier <ref> [29, 30] </ref>. Feautrier proposed a parametric integer programming algorithm that can find such perfect information in the domain of loop nests where the loop bounds and array indices are affine functions of loop indices. However, operations 34 such as intersection and union have exponential time complexity in the worst case. <p> Similarly, In order to compute the sets of data that processor 0 must send to other processors, we first determine the sequence of accesses to array B (in the global index space) that processor 0 owns, Global B (0) = <ref> [2; 30; 51; 72; 79; 100; 121; 149] </ref> with the period 168, and the corresponding iteration sequence Iter B (0) = [0; 4; 7; 10; 11; 14; 17; 21] with the period 24. <p> (x) = (x div k A ) mod p.) For example, processor 0 owns the elements B (30), B (51), B (100), and B (149) referenced by processor 2, and the set of data that processor 0 needs to send to processor 2 is DSend (0 ! 2) = B <ref> [30; 51; 100; 149] </ref> with the period 168, which corresponds to B [30; 51; 100; 149; 198; 219; : : :]. <p> 0 owns the elements B (30), B (51), B (100), and B (149) referenced by processor 2, and the set of data that processor 0 needs to send to processor 2 is DSend (0 ! 2) = B [30; 51; 100; 149] with the period 168, which corresponds to B <ref> [30; 51; 100; 149; 198; 219; : : :] </ref>. <p> In order be able to pack the messages corresponding to different rhs terms in a single pass over the array, we must find the union of PSend sequences corresponding to different rhs references. Section 7.2 showed that Global B (7i+2) (0) = <ref> [2; 30; 51; 72; 79; 100; 121; 149] </ref> with the period 168 and PSend B (7i+2) (0), the sequence of processors that processor 0 sends data to, to be [0; 2; 2; 0; 1; 2; 0; 2]. <p> By merging the two Global sequences we get Global B = <ref> [2; 5; 26; 30; : : : ; 124; 145; 149] </ref> with the period 168, and the unioned PSend B (0) = [0; 0; 0; 2; 2; 2; 0; 0; 1; 1; 2; 2; 0; 0; 2; 2]. 157 From this we can compute the sets of elements that a processor <p> the unioned PSend B (0) = [0; 0; 0; 2; 2; 2; 0; 0; 1; 1; 2; 2; 0; 0; 2; 2]. 157 From this we can compute the sets of elements that a processor needs to send for both rhs references, for example, DSend B (0 ! 2) = <ref> [30; 51; 54; 100; 103; 145; 149] </ref> with the period 168. Using the PSend B set, the messages can be packed in a single scan over the array B, as described in Section 7.3.
Reference: [31] <author> G. Fox, S. Hiranandani, K. Kennedy, C. Koelbel, U. Kremer, C.-W. Tseng, and M. Wu. </author> <title> Fortran D language specification. </title> <type> Technical Report TR90-141, </type> <institution> Dept. of Computer Science, Rice University, </institution> <month> December </month> <year> 1990. </year>
Reference-contexts: The PARADIGM compiler uses 23 Mathematica's fl symbolic manipulation capabilities to support computation par titioning, communication generation, and loop transformation [82]. Fortran D compiler Fortran D compiler was the first generation prototype compiler developed for Fortran D language <ref> [31] </ref> a HPF-like data-parallel language. The Fortran D compiler implemented several new compilation techniques [50, 49, 52]. However, since it was among the first data-parallel compilers developed, it had several restrictions, as well.
Reference: [32] <author> M. Garey and D. Johnson. </author> <title> Computers and Intractability, A Guide to the Theory of NP-Completeness. </title> <editor> W. H. </editor> <publisher> Freeman and Co., </publisher> <address> New York, NY, </address> <year> 1979. </year>
Reference-contexts: This problem 101 102 103 is very similar to the ones encountered in scheduling and database management (file allocation) problems <ref> [32, 10] </ref> and can be similarly shown to be NP-complete: the knapsack problem [32] can be trivially reduced to the problem of optimally selecting the messages that should use the available buffer at any given node. <p> This problem 101 102 103 is very similar to the ones encountered in scheduling and database management (file allocation) problems [32, 10] and can be similarly shown to be NP-complete: the knapsack problem <ref> [32] </ref> can be trivially reduced to the problem of optimally selecting the messages that should use the available buffer at any given node.
Reference: [33] <author> M. Gerndt. </author> <title> Array distribution in SUPERB. </title> <booktitle> In Proceedings of the 1989 ACM International Conference on Supercomputing, </booktitle> <address> Crete, Greece, </address> <month> June </month> <year> 1989. </year>
Reference-contexts: The source language used by this project was Vienna Fortran [16, 17]; one of the predecessors of HPF. The Vienna Fortran group pioneered various compilation techniques <ref> [33, 35, 86] </ref>. The compiler introduced owner-computes rule and message vectorization. It also introduced the concept of overlap areas for regular, stencil-based computations. However, like the Fortran D compiler, it was restricted in its scope. It supported only block and cyclc distributions.
Reference: [34] <author> M. Gerndt. </author> <title> Automatic Parallelization for Distributed-Memory Multiprocessing Systems. </title> <type> PhD thesis, </type> <institution> University of Bonn, </institution> <month> December </month> <year> 1989. </year>
Reference-contexts: Previous research was focused only on compilation strategies for handling block and cyclic distributions efficiently <ref> [34, 70, 68, 85] </ref>. This chapter demonstrates that the accesses made by cyclic (k) references exhibit a repetitive access pattern. It exploits the repetitive pattern to present efficient compilation techniques for cyclic (k) distributions. The rest of this chapter is organized as follows.
Reference: [35] <author> M. Gerndt. </author> <title> Updating distributed variables in local computations. </title> <journal> Concurrency: Practice and Experience, </journal> <volume> 2(3) </volume> <pages> 171-193, </pages> <month> September </month> <year> 1990. </year>
Reference-contexts: The source language used by this project was Vienna Fortran [16, 17]; one of the predecessors of HPF. The Vienna Fortran group pioneered various compilation techniques <ref> [33, 35, 86] </ref>. The compiler introduced owner-computes rule and message vectorization. It also introduced the concept of overlap areas for regular, stencil-based computations. However, like the Fortran D compiler, it was restricted in its scope. It supported only block and cyclc distributions. <p> After multiplying the iteration numbers by the stride s A , we get the global index sequence of corresponding left-hand-side (lhs) accesses, Image lhs (0) = <ref> [0; 20; 35; 50; 55; 70; 85; 105] </ref> with the period 120.
Reference: [36] <author> C. Gong, R. Gupta, and R. Melhem. </author> <title> Compilation techniques for optimizing communication on distributed-memory systems. </title> <booktitle> In Proceedings of the 1993 International Conference on Parallel Processing, </booktitle> <address> St. Charles, IL, </address> <month> August </month> <year> 1993. </year>
Reference-contexts: Gong, Gupta, and Melhem present a data-flow framework to separate sends and receives by placing sends at "the earliest point at which the communication can be performed" <ref> [36] </ref>. However, their technique does not eliminate partially redundant communication, handles only singly-nested loops and one-dimensional arrays, and does not provide balanced communication placement. 83 Gupta, Schonberg, and Srinivasan adapt PRE for communication placement and to develop a unified communication optimization framework [40].
Reference: [37] <author> E. Granston and A. Veidenbaum. </author> <title> Detecting redundant accesses to array data. </title> <booktitle> In Proceedings of Supercomputing '91, </booktitle> <address> Albuquerque, NM, </address> <month> November </month> <year> 1991. </year>
Reference-contexts: Moreover, they don't allow loops within conditionals. Granston and Veidenbaum combine PRE and dependence analysis to eliminate redundant monolithic global-memory accesses across loop nests in the presence of conditionals <ref> [37] </ref>. Gong, Gupta, and Melhem present a data-flow framework to separate sends and receives by placing sends at "the earliest point at which the communication can be performed" [36]. <p> do not expect the length of the expanded sequence to exceed the larger of the two block sizes.) After expansion, we get Iter A (0) = [0; 3; 5; 10; 12; 15; 17; 22] with the period 24, and the sequence of corresponding rhs accesses is Image rhs (0) = <ref> [2; 23; 37; 72; 86; 107; 121; 156] </ref> with the period 168. <p> By computing the owners of the elements of array B with these indices we can construct the table PRecv (0) = [0,2,1,0,1,1,0,1], as well as DRecv sets, for example, DRecv (0 1) = B <ref> [37; 86; 107; 156] </ref> with the period 168. Not all the tables shown here need to be actually allocated and assigned values. We need tables for storing the array access sequences corresponding to both the reference.
Reference: [38] <author> M. Gupta, S. Midkiff, E. Schonberg, V. Seshadri, D. Shields, K-Y. Wang, W-M. Ching, and T. Hgo. </author> <title> An HPF compiler for the ibm sp2. </title> <booktitle> In Proceedings of Supercomputing '95, </booktitle> <address> San Diego, CA, </address> <month> December </month> <year> 1995. </year>
Reference-contexts: Moreover, it illustrates that the communication optimizations depend not only on the dependence and data-flow information, but also on the resource constraints. It describes how communication optimizations are performed in the presence of not only arbitrary control flow but also resource constraints. 4. Current state-of-the-art HPF compilers <ref> [38, 3, 14] </ref> support techniques for simple regular distributions with a limited set of subscript patterns and provide either no or inefficient support for the general regular distribution (specifically, the cyclic (k) distribution; it is defined in Section 2.1.1). <p> Choose computation partitioning This phase is responsible for dividing work among processors. It determines the set of processors that execute every statement in the program. This phase can select different set of processors to execute different statements in a loop body. Unlike other HPF compilers <ref> [50, 38, 3, 14] </ref> that use either only owner computes rule or same computation partitioning for all the statements in a loop body, we evaluate the cost of various computation partitioning options and select the best option for each statement. <p> This section outlines some of the data-parallel compilers. IBM HPF compiler IBM provides perhaps the most advanced HPF compiler commercially available. The IBM compiler, called pHPF, is a native compiler for IBM SP2, a multiprocessor system based on distributed-memory architecture <ref> [38] </ref>. It performs various optimizations to improve uniprocessor performance as well. Like the Fortran D95 compiler, it supports scalarizer to convert Fortran 90 array expressions into Fortran 77 code. Unlike the Fortran D95 compiler, pHPF paritions computations based on owner-computes rule only.
Reference: [39] <author> M. Gupta and E. Schonberg. </author> <title> A framework for exploiting data availability to optimize communication. </title> <booktitle> In Proceedings of the Sixth Workshop on Languages and Compilers for Parallel Computing, </booktitle> <address> Portland, OR, </address> <month> August </month> <year> 1993. </year> <month> 170 </month>
Reference-contexts: But, the Fortran D95 compiler requires that non-owner processors send back the updated section to the owner processor. In other words, it does not allow a non-owner processor to hold updated values and make it send them to another non-owner processor when required <ref> [39] </ref>. In the Fortran D95 compiler, communication instances are represented using implicit representation during the computation partitioning and communication optimization phases. Only when more detailed information is required, for example in the code generation phase of the compiler, explicit form of communication representation is generated.
Reference: [40] <author> M. Gupta, E. Schonberg, and H. Srinivasan. </author> <title> A unified data-flow framework for optimizing communication. </title> <booktitle> In Proceedings of the Seventh Workshop on Languages and Compilers for Parallel Computing, </booktitle> <address> Ithaca, NY, </address> <month> August </month> <year> 1994. </year>
Reference-contexts: The important features of the communication placement framework presented 44 in this chapter are as follows: * First, the framework incorporates data-dependence information in the placement analysis to simplify the data-flow equations. This approach differs from previous global data-flow techniques <ref> [40, 44, 59] </ref>, which use dependence information only to evaluate whether different references have data-dependent (over lapping) communication sets. * Second, the framework shows that placement can be determined by a sequence of simple uni-directional analyses. <p> However, their technique does not eliminate partially redundant communication, handles only singly-nested loops and one-dimensional arrays, and does not provide balanced communication placement. 83 Gupta, Schonberg, and Srinivasan adapt PRE for communication placement and to develop a unified communication optimization framework <ref> [40] </ref>. Their framework does not perform any analysis to ensure balanced placement of Send and (blocking) Recv primitives. To ensure correctness, it initiates non-blocking receives immediately after the sends and uses a wait primitive before every non-local reference to block the statement from executing till the data are received. <p> Traditional dependence-based communication placement techniques performed VMP by placing Send immediately after the source of the dependence. But clearly, in the presence of conditionals, balance cannot be guaranteed with dependence-based placement. On the other hand, none of the previous data-flow based communication placement frameworks <ref> [40, 44] </ref> provided support for VMP. We exploit the knowledge about the graph structure and combine it with the equations for Send placement to support VMP.
Reference: [41] <author> S.K.S. Gupta, S.D. Kaushik, C.-H. Huang, and P. Sadayappan. </author> <title> On compiling array expressions for efficient execution on distributed-memory machines. </title> <type> Technical Report OSU-CISRC-4/94-TR19, </type> <institution> Department of Computer and Information Science, The Ohio State University, </institution> <month> April </month> <year> 1994. </year>
Reference-contexts: We also compared the execution times of the table-based address generation scheme (the SPMD code using M table is shown in Figure 7.5) and two techniques that had been described before: the run-time address resolution (also known as the guarded execution) and the virtual-block scheme proposed by Gupta et al. <ref> [41] </ref>. In the run-time resolution each processor executes the entire loop, and for each iteration every processor checks if it owns the array element that is being assigned to, in which case it computes the local memory address and performs the assignment. <p> If stride s is not greater than block size k, then all virtual processors own some of the array elements being accessed, i.e., all virtual processors are active <ref> [41] </ref>. <p> Neither Chatterjee et al. [18] nor Gupta et al. <ref> [41] </ref> deal with this issue. Stichnoth [80] indicates that combining communication steps would be profitable, but he does not describe the necessary analysis. In contrast, we show how our approach can support message coalescing optimization [48] to reduce the communication cost. <p> This allowed us to evaluate the overheads incurred by our techniques, as well as compare them with other existing methods, in particular the virtual processor approach by Gupta et al. <ref> [41] </ref>. Their solution is based on treating a block-cyclic distribution as either a block or cyclic distribution of data onto virtual processors, and mapping of the virtual processors to the physical processors in either a cyclic or block fashion. <p> We have extensively cited and described two of the previous works in the chapter: the virtual-block scheme proposed by Gupta et al. <ref> [41] </ref> and the approach described by Chatterjee et al. [18]. Ancourt et al. use a linear algebra framework for compiling independent loops in HPF [5].
Reference: [42] <author> R. v. Hanxleden. </author> <title> Handling irregular problems with Fortran D | A preliminary report. </title> <booktitle> In Proceedings of the Fourth Workshop on Compilers for Parallel Computers, </booktitle> <address> Delft, The Netherlands, </address> <month> December </month> <year> 1993. </year>
Reference-contexts: The compiler includes efficient libraries for redistribution as well as for supporting scalable I/O and out-of-core computations [13, 12]. The compilation effort at University of Maryland has been directed at towards providing providing efficient run-time support for irregular references <ref> [45, 42] </ref>. They have developed PARTI/CHAOS run-time library to support computation and communication generation efficiently [23].
Reference: [43] <author> R. v. Hanxleden. </author> <title> Compiler Support for Machine-Independent Parallelization of Irregular Problems. </title> <type> PhD thesis, </type> <institution> Dept. of Computer Science, Rice University, </institution> <month> December </month> <year> 1994. </year>
Reference-contexts: A Tarjan interval has a unique header node h, where h 62 T (h). Tarjan intervals include only nodes that are part of a loop; that is, together with the header node h, the nodes in T (h) form a strongly connected region. As described by von Hanxleden <ref> [43] </ref>, this 46 differs from the Allen-Cocke intervals [28, 53, 58] used in classical interval analysis. Allen-Cocke intervals include nodes whose predecessors are all in T (h); that is, they might include an acyclic structure dangling off the loop. <p> Previous research efforts did not take resource constraints into account and defined correctness under the assumption that sufficient resources were available <ref> [72, 43] </ref>. Chapter 5 presents the analysis required to ensure that the communication placement does not exceed the resource constraints. Assuming that the resource constraints are satisfied by the placement, correctness requires that the program executes matching number of Sends and Recvs. <p> As pointed out by von Hanxleden, correctness requires that "if a processor p reaches a reference requiring communication involving some other processor q, then q also has to reach the reference" <ref> [43] </ref>. Figure 4.8 presents an example program that can lead to incorrect communication placement. If the "do i" loop is partitioned such that processor 0 executes first 10 iterations and processor 1 executes last 10 iterations then the "if" conditional evaluates to false on processor 0. <p> It is worth stressing that the Fortran D compiler did not provide correctness. However, for a restricted class of programs, correctness of communication placement can be guaranteed by the communication placement framework itself. The Give-N-Take framework provided correct placement for the programs with following communication characteristics <ref> [43] </ref>: Definition 11 A program is a valid instance of communication placement problem if its na ive solution results in a correct problem; that is, the program annotated with Send/Recv pair immediately preceding each non-local reference is deadlock-free.
Reference: [44] <author> R. v. Hanxleden and K. Kennedy. </author> <title> Give-N-Take | A balanced code placement framework. </title> <booktitle> In Proceedings of the SIGPLAN '94 Conference on Programming Language Design and Implementation, </booktitle> <address> Orlando, FL, </address> <month> June </month> <year> 1994. </year>
Reference-contexts: Moreover, the absence of data-flow analysis precludes the possibility of redundant communication elimination in presence of conditionals and arbitrary control-flow. Though, over the last two years, a few data-flow based communication placement frameworks that address these issues have been developed, with the exception of the Fortran D compiler <ref> [44] </ref>, no compiler has implemented data-flow based communication placement analysis. This dissertation presents a global data-flow analysis technique that determines balanced non-atomic placement of communication prim itives and improves placement analysis in various other respects. 2. <p> Sends are initiated as early as possible and Recvs are executed as late as possible to expose the opportunities for overlapping communication with computation. Moreover, the framework ensures that every program execution path contains matching Send and Recv pairs; that is, it ensures that Sends and Recvs are balanced <ref> [44] </ref>. The important features of the communication placement framework presented 44 in this chapter are as follows: * First, the framework incorporates data-dependence information in the placement analysis to simplify the data-flow equations. <p> The important features of the communication placement framework presented 44 in this chapter are as follows: * First, the framework incorporates data-dependence information in the placement analysis to simplify the data-flow equations. This approach differs from previous global data-flow techniques <ref> [40, 44, 59] </ref>, which use dependence information only to evaluate whether different references have data-dependent (over lapping) communication sets. * Second, the framework shows that placement can be determined by a sequence of simple uni-directional analyses. <p> An interval is just a collection of nodes; it is defined formally below. While solving data-flow equations, we summarize appropriate information for an interval and record it in the interval header. Our interval-flow graph is similar to that used by the Give-N-Take framework <ref> [44] </ref>; it differs only in the way critical edges are eliminated (described below). The important properties of the interval-flow graph, G = (N; E), are as follows. We assume that G is reducible; that is, each loop has a unique header node. <p> Finally, for every non-empty interval T (h), there exists a unique g 2 T (h) such that (g; h) 2 E; that is, there is only one back edge out of T (h). This is achieved by adding a post-body node to T (h) <ref> [44] </ref>. The interval-flow graph shown in Figure 4.2 is used in this chapter to illustrate the communication placement framework. Though not shown in the figure, the graph is implicitly partitioned into intervals; each loop body in Figure 4.2 corresponds to an interval. <p> Let Succs (n) and Preds (n) correspond to the set of successor and predecessor nodes of n. Succs F (n) and Succs E (n) then correspond to the forward and entry edge successors of n. Additionally, the edges induce the following traversal orders over G <ref> [44] </ref>: given a forward edge (m; n), a Forward order visits m before n, and a Backward order visits m after n. <p> Traditionally, hoisting computation out of a loop with unknown bounds is considered unsafe because if the loop body is not executed, it introduces a new value on some execution path (s) of the program. However, since hoisting communication out of a loop can only cause over-communication <ref> [44] </ref>, we relax the safety criterion to hoist communication out of potentially zero-trip loops as follows. z The framework places send primitives only at the node start. 55 56 For header node h, not only the communication placed at the forward edge successor (s) of h can be hoisted across T <p> However, it has been noted by several researchers that for typical programs, the average out-degree of graph nodes and the maximal loop nesting depth can be assumed to be bounded by a small constant independent of the size of the program <ref> [76, 44] </ref>. Therefore, for well structured programs, elimination of critical edges should not increase the size of G significantly. <p> The Lazy Code Motion (LCM) technique [67] and the Give-N-Take framework <ref> [44] </ref> improved partial redundancy elimination optimization by excluding unnecessary code motion and by providing non-atomic placement regions, respectively. Our framework is based on both these frameworks. <p> This phases uses the same data-flow equations for send placement as the resource-independent send placement phase with the only difference being the initialization of appropriate data-flow variables. Note that if sufficient resources are available, our framework determines the same placement as that determined by constraint-independent frameworks <ref> [44] </ref>. Latest balanced receive placement: Finally, as described in Section 4.4, we use the (resource-based) send placement to determine the corresponding receive placement. Since non-local write is a dual problem, resource-based communication placement for non-local writes also requires the above four phases; but, in reverse order. <p> Since Sends are coalesced before determining the corresponding Recv placement, Sends can be coalesced without worrying about coalescing the matching Recvs. If placement for both Send and Recv primitives is determined in the same phase, as is done in the Give-N-Take framework <ref> [44] </ref>, ensuring the balancedness of coalesced messages becomes a nontrivial problem. Moreover, unlike the previous dependence-based placement techniques, communication placement using data-flow analysis allows implementation of message coalescing optimization across loop nests. <p> Traditional dependence-based communication placement techniques performed VMP by placing Send immediately after the source of the dependence. But clearly, in the presence of conditionals, balance cannot be guaranteed with dependence-based placement. On the other hand, none of the previous data-flow based communication placement frameworks <ref> [40, 44] </ref> provided support for VMP. We exploit the knowledge about the graph structure and combine it with the equations for Send placement to support VMP.
Reference: [45] <author> R. v. Hanxleden, K. Kennedy, C. Koelbel, R. Das, and J. Saltz. </author> <title> Compiler analysis for irregular problems in Fortran D. </title> <booktitle> In Proceedings of the Fifth Workshop on Languages and Compilers for Parallel Computing, </booktitle> <address> New Haven, CT, </address> <month> August </month> <year> 1992. </year>
Reference-contexts: The compiler includes efficient libraries for redistribution as well as for supporting scalable I/O and out-of-core computations [13, 12]. The compilation effort at University of Maryland has been directed at towards providing providing efficient run-time support for irregular references <ref> [45, 42] </ref>. They have developed PARTI/CHAOS run-time library to support computation and communication generation efficiently [23].
Reference: [46] <author> P. Havlak and K. Kennedy. </author> <title> An implementation of interprocedural bounded regular section analysis. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 2(3) </volume> <pages> 350-360, </pages> <month> July </month> <year> 1991. </year> <month> 171 </month>
Reference-contexts: A lot of research has been done to represent array sections efficiently <ref> [29, 8, 46, 7, 6, 5, 82] </ref>. Explicit representations can be classified as either precise or imprecise representations. The latter category of representations tend to sacrifice precision for efficiency. Imprecise representations use closed-form formulae or a restricted class of geometric patterns to approximate given array section with a convex region. <p> Intuitively, regular sections correspond to rectangular or right-triangular array sections and their higher dimension analogs <ref> [15, 46] </ref>. RSDs can also represent regular sections with constant stride. RSDs were originally developed for summarizing side effects across procedure boundaries and represent array sections using an imprecise representation. RSDs were used extensively in the Fortran D compiler [85].
Reference: [47] <author> S. Hiranandani, K. Kennedy, J. Mellor-Crummey, and A. Sethi. </author> <title> Compilation techniques for block-cyclic distributions. </title> <booktitle> In Proceedings of the 1994 ACM International Conference on Supercomputing, </booktitle> <address> Manchester, England, </address> <month> July </month> <year> 1994. </year>
Reference-contexts: Cyclic (k) distribution is useful in the programs that require both locality and load-balancing. For example, programs with triangular loops, such as Cholesky factorization [75] and Gaussian elimination <ref> [47] </ref>, can benefit from cyclic (k) distribution. Unlike block distribution, cyclic (k) distribution is amenable to load-balancing issues. Moreover, unlike cyclic distribution, cyclic (k) distribution can yield better locality. Thus, cyclic (k) distribution provides the benefits of both block and cyclic distributions. <p> However, this case is not expected to occur as frequently as case I. Therefore, we omit the details about the algorithm for case II; the algorithm has been described before <ref> [47] </ref>. This section presented a linear-time algorithm for generating local addresses for cyclic (k) distributions for the special case that occurs frequently. However, a linear-time algorithm for the general case will simplify handling of cyclic (k) distribution. <p> Note that the upper bound computation is simpler because the local upper bound need not be the actual last element accessed by the processor. The procedures for computing the local upper bound (GetU pperBound) and for global to local index conversion (Local) were presented in <ref> [47] </ref>. Experimental Results This section compares the performance of various address generation approaches for array references with MIV subscripts. Figure 7.7 shows two versions of the SPMD node code corresponding to our canonical loop nest example.
Reference: [48] <author> S. Hiranandani, K. Kennedy, and C.-W. Tseng. </author> <title> Compiler optimizations for Fortran D on MIMD distributed-memory machines. </title> <booktitle> In Proceedings of Supercomputing '91, </booktitle> <address> Albuquerque, NM, </address> <month> November </month> <year> 1991. </year>
Reference-contexts: Message pipelining optimization is an important optimization for programs with loop-carried dependences <ref> [48] </ref>. Chapter 6 describes how the data-dependence information is integrated with data-flow analysis to improve the precision and scope of these optimizations. The rest of this chapter is organized as follows. Section 4.1 introduces the graph structure and predicates used by our framework. <p> Thus, the initialization 54 causes communication to be placed inside the loop, as required. In other words, the initialization inhibits message vectorization optimization; hoisting communication to the outermost loop level is known as message vectorization in the data-parallel compiler literature <ref> [48] </ref>. In traditional code motion techniques, placement of computation at a node is considered safe if the computed value is used along all terminating paths from the node [76, 67]. <p> Thus, Erlebacher presents opportunity for VMP. However, it does not contain conditionals and dependence-based placement techniques can also successfully perform the VMP optimization. Since the benefits of the VMP for Erlebacher have been studied before <ref> [48] </ref>, we restrict our analysis to the performance gains due to latency hiding achieved by nonatomic placement of Sends and Recvs. We translated Erlebacher into SPMD node code with the communication placement that achieves latency hiding. <p> This differs from the placement of Send and Recv primitives described in Chapter 4 because communication primitives can be moved to earlier iterations. As mentioned before, in the distributed-memory compilation literature, the optimization that hoists communication to the outermost placement level is known as message vectorization <ref> [48] </ref>. The placement that combines message vec-torization with message pipelining is known as vector message pipelining (VMP) [48]. Traditional dependence-based communication placement techniques performed VMP by placing Send immediately after the source of the dependence. But clearly, in the presence of conditionals, balance cannot be guaranteed with dependence-based placement. <p> As mentioned before, in the distributed-memory compilation literature, the optimization that hoists communication to the outermost placement level is known as message vectorization <ref> [48] </ref>. The placement that combines message vec-torization with message pipelining is known as vector message pipelining (VMP) [48]. Traditional dependence-based communication placement techniques performed VMP by placing Send immediately after the source of the dependence. But clearly, in the presence of conditionals, balance cannot be guaranteed with dependence-based placement. <p> Neither Chatterjee et al. [18] nor Gupta et al. [41] deal with this issue. Stichnoth [80] indicates that combining communication steps would be profitable, but he does not describe the necessary analysis. In contrast, we show how our approach can support message coalescing optimization <ref> [48] </ref> to reduce the communication cost. In order be able to pack the messages corresponding to different rhs terms in a single pass over the array, we must find the union of PSend sequences corresponding to different rhs references.
Reference: [49] <author> S. Hiranandani, K. Kennedy, and C.-W. Tseng. </author> <title> Compiler support for machine-independent parallel programming in Fortran D. </title> <editor> In J. Saltz and P. Mehro-tra, editors, </editor> <title> Languages, Compilers, and Run-Time Environments for Distributed Memory Machines. </title> <publisher> North-Holland, </publisher> <address> Amsterdam, The Netherlands, </address> <year> 1992. </year>
Reference-contexts: Fortran D compiler Fortran D compiler was the first generation prototype compiler developed for Fortran D language [31] a HPF-like data-parallel language. The Fortran D compiler implemented several new compilation techniques <ref> [50, 49, 52] </ref>. However, since it was among the first data-parallel compilers developed, it had several restrictions, as well. The compiler supported optimizations such as message vectorization, message coalescing, message aggregation, coarse-grain pipelining, and vector message pipelining. It also provided some support for interprocedural reaching decomposition and overlap area analysis.
Reference: [50] <author> S. Hiranandani, K. Kennedy, and C.-W. Tseng. </author> <title> Compiling Fortran D for MIMD distributed-memory machines. </title> <journal> Communications of the ACM, </journal> <volume> 35(8) </volume> <pages> 66-80, </pages> <month> August </month> <year> 1992. </year>
Reference-contexts: Choose computation partitioning This phase is responsible for dividing work among processors. It determines the set of processors that execute every statement in the program. This phase can select different set of processors to execute different statements in a loop body. Unlike other HPF compilers <ref> [50, 38, 3, 14] </ref> that use either only owner computes rule or same computation partitioning for all the statements in a loop body, we evaluate the cost of various computation partitioning options and select the best option for each statement. <p> Fortran D compiler Fortran D compiler was the first generation prototype compiler developed for Fortran D language [31] a HPF-like data-parallel language. The Fortran D compiler implemented several new compilation techniques <ref> [50, 49, 52] </ref>. However, since it was among the first data-parallel compilers developed, it had several restrictions, as well. The compiler supported optimizations such as message vectorization, message coalescing, message aggregation, coarse-grain pipelining, and vector message pipelining. It also provided some support for interprocedural reaching decomposition and overlap area analysis. <p> After multiplying the iteration numbers by the stride s A , we get the global index sequence of corresponding left-hand-side (lhs) accesses, Image lhs (0) = <ref> [0; 20; 35; 50; 55; 70; 85; 105] </ref> with the period 120. <p> The sets of data that processor 0 must receive from other processors are computed similarly; we build the table of global indices for accesses made by processor 0, Global A (0) = <ref> [0; 15; 25; 50] </ref> with the period 60 and Iter A (0) = [0; 3; 5; 10] with the period 12. Since the iteration periods of Iter A and Iter B are differ processors.
Reference: [51] <author> S. Hiranandani, K. Kennedy, and C.-W. Tseng. </author> <title> Preliminary experiences with the Fortran D compiler. </title> <booktitle> In Proceedings of Supercomputing '93, </booktitle> <address> Portland, OR, </address> <month> November </month> <year> 1993. </year>
Reference-contexts: This heuristic is based on the experiences with compilation for distributed-memory machines: it has been observed that reducing frequency of communication often yields more significant benefits than the latency hiding optimization <ref> [51] </ref>. Message buffers for communication blocked at a node are deallocated. This frees up buffers and allows communication to be hoisted to the outermost placement locations. <p> Similarly, In order to compute the sets of data that processor 0 must send to other processors, we first determine the sequence of accesses to array B (in the global index space) that processor 0 owns, Global B (0) = <ref> [2; 30; 51; 72; 79; 100; 121; 149] </ref> with the period 168, and the corresponding iteration sequence Iter B (0) = [0; 4; 7; 10; 11; 14; 17; 21] with the period 24. <p> (x) = (x div k A ) mod p.) For example, processor 0 owns the elements B (30), B (51), B (100), and B (149) referenced by processor 2, and the set of data that processor 0 needs to send to processor 2 is DSend (0 ! 2) = B <ref> [30; 51; 100; 149] </ref> with the period 168, which corresponds to B [30; 51; 100; 149; 198; 219; : : :]. <p> 0 owns the elements B (30), B (51), B (100), and B (149) referenced by processor 2, and the set of data that processor 0 needs to send to processor 2 is DSend (0 ! 2) = B [30; 51; 100; 149] with the period 168, which corresponds to B <ref> [30; 51; 100; 149; 198; 219; : : :] </ref>. <p> In order be able to pack the messages corresponding to different rhs terms in a single pass over the array, we must find the union of PSend sequences corresponding to different rhs references. Section 7.2 showed that Global B (7i+2) (0) = <ref> [2; 30; 51; 72; 79; 100; 121; 149] </ref> with the period 168 and PSend B (7i+2) (0), the sequence of processors that processor 0 sends data to, to be [0; 2; 2; 0; 1; 2; 0; 2]. <p> the unioned PSend B (0) = [0; 0; 0; 2; 2; 2; 0; 0; 1; 1; 2; 2; 0; 0; 2; 2]. 157 From this we can compute the sets of elements that a processor needs to send for both rhs references, for example, DSend B (0 ! 2) = <ref> [30; 51; 54; 100; 103; 145; 149] </ref> with the period 168. Using the PSend B set, the messages can be packed in a single scan over the array B, as described in Section 7.3.
Reference: [52] <author> S. Hiranandani, K. Kennedy, and C.-W. Tseng. </author> <title> Evaluating compiler optimizations for Fortran D. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 21(1) </volume> <pages> 27-45, </pages> <month> April </month> <year> 1994. </year>
Reference-contexts: Fortran D compiler Fortran D compiler was the first generation prototype compiler developed for Fortran D language [31] a HPF-like data-parallel language. The Fortran D compiler implemented several new compilation techniques <ref> [50, 49, 52] </ref>. However, since it was among the first data-parallel compilers developed, it had several restrictions, as well. The compiler supported optimizations such as message vectorization, message coalescing, message aggregation, coarse-grain pipelining, and vector message pipelining. It also provided some support for interprocedural reaching decomposition and overlap area analysis.
Reference: [53] <author> J.Cocke. </author> <title> Global common subexpression elimination. </title> <journal> ACM SIGPLAN Notices, </journal> <volume> 5(7) </volume> <pages> 20-24, </pages> <year> 1970. </year>
Reference-contexts: Tarjan intervals include only nodes that are part of a loop; that is, together with the header node h, the nodes in T (h) form a strongly connected region. As described by von Hanxleden [43], this 46 differs from the Allen-Cocke intervals <ref> [28, 53, 58] </ref> used in classical interval analysis. Allen-Cocke intervals include nodes whose predecessors are all in T (h); that is, they might include an acyclic structure dangling off the loop. Interval-flow graph differs from a control-flow graph in the way in which edges 2 E are classified.
Reference: [54] <author> S. D. Kaushik. </author> <title> Private communication, </title> <month> April </month> <year> 1995. </year> <month> 172 </month>
Reference-contexts: Similarly, for B (7i + 5) we can compute Global B (7i+5) (0) = <ref> [5; 26; 54; 75; 96; 103; 124; 145] </ref> with the period 168, which results in PSend B (7i+5) (0) = [0; 0; 2; 0; 1; 2; 0; 2]. <p> the unioned PSend B (0) = [0; 0; 0; 2; 2; 2; 0; 0; 1; 1; 2; 2; 0; 0; 2; 2]. 157 From this we can compute the sets of elements that a processor needs to send for both rhs references, for example, DSend B (0 ! 2) = <ref> [30; 51; 54; 100; 103; 145; 149] </ref> with the period 168. Using the PSend B set, the messages can be packed in a single scan over the array B, as described in Section 7.3. <p> Table 7.4 gives the table generation, message packing, communication, and loop execution times for 160,000 iterations of the normalized loop described in Section 7.2 for our method and the virtual processor approach. (The code that implements the virtual processor scheme was provided by S.D. Kaushik <ref> [54] </ref>.) Once again, the experiments were performed on 32 processors of an Intel iPSC/860 hypercube, using the icc compiler with -O4 optimization level and dclock timer.
Reference: [55] <author> P. Keleher, A. Cox, S. Dwarkadas, and W. Zwaenepoel. TreadMarks: </author> <title> Distributed shared memory on standard workstations and operating systems. </title> <booktitle> In Proceedings of the 1994 Winter USENIX Conference, </booktitle> <month> January </month> <year> 1994. </year>
Reference-contexts: Towards this end, we are currently targeting both the distributed-memory systems (using Message Passing Interface [26], MPI, library for message passing routines) and hardware DSM systems such as Convex Exemplar [21] as well as the software DSM systems such as TreadMarks <ref> [55] </ref>. outlines different phases of the Fortran D95 compiler in order to present the context 12 under which the communication generation techniques have been implemented. The example program shown in Figure 2.1 is used to illustrate different phases of the compiler. <p> After multiplying the iteration numbers by the stride s A , we get the global index sequence of corresponding left-hand-side (lhs) accesses, Image lhs (0) = <ref> [0; 20; 35; 50; 55; 70; 85; 105] </ref> with the period 120.
Reference: [56] <author> W. Kelly, V. Maslov, W. Pugh, E. Rosser, T. Shpeisman, and D. Wonnacott. </author> <title> The omega library interface guide. </title> <type> Technical Report Version 0.95, </type> <institution> University of Maryland, </institution> <month> June </month> <year> 1995. </year>
Reference-contexts: Since the message sizes might be unknown at compile time, the compiler dynamically allocates storage for distributed data. Most of the loop partitioning as well as computation and generation of packing/unpacking code is based on the Omega Library developed at University of Maryland <ref> [56] </ref>. Omega library is used to develop a convenient notation for expressing and manipulating integer sets. <p> Thus, we directed our intellectual efforts towards developing efficient mode of expressing and computing communication sets and not on the development of the necessary underlying machinery for manipulating integer sets. We use the Omega library <ref> [56] </ref> for expressing integer sets and tuple relations. The representation is used for a wide range of applications including analysis for communication set computation as well as generating code for communication primitives (packing and unpacking code) and program transformations. <p> The Omega library represents relations and sets using Presburger formulas (possibly with limited uses of uninterpreted function symbols). Presburger formulas are formulas that can be constructed by combining affine constraints on integer variables with logical operations :, ^ and _, and the quantifiers 8 and 9 <ref> [56] </ref>. To compute the data section that needs to be communicated, we express the communication set as an integer set: the set of array indices that need to be communicated. Communication sets corresponding to scalars are represented as sets with zero set variables.
Reference: [57] <author> W. Kelly, W. Pugh, and E. Rosser. </author> <title> Code generation for multiple mappings. </title> <booktitle> In Frontiers '95: The 5th Symposium on the Frontiers of Massively Parallel Computation, </booktitle> <address> McLean, VA, </address> <month> February </month> <year> 1995. </year>
Reference-contexts: Over the last few years, they have developed techniques that are useful for compiler analysis also; the Fortran D95 compiler uses the Omega Library develoed at University at Maryland for representing communication and iteration sets as well as a basis for code generation <ref> [57] </ref>. 26 Chapter 3 Communication Analysis Communication analysis is the first step in the communication generation process. <p> However, operations 34 such as intersection and union have exponential time complexity in the worst case. But, it has been shown that most scientific programs have simple access patterns and the operations on the corresponding array sections often require only simple inequality manipulations <ref> [57] </ref>. The two new precise representations defined in the context of the Fortran D95 compiler are: 1. Periodic access sequence: for cyclic (k) distribution, data sets are concisely and efficiently represented using periodic sequences. 2. <p> PTDs are closed under intersection while union and difference can result in a list of sets. Fourier-Motzkin elimination A lot of researchers have proposed precise array section representations based on the Fourier-Motzkin elimination method <ref> [29, 6, 7, 57, 82] </ref>. These representations represent array sections with a set of linear inequalities. Operations on array sections, such as union, intersection, and difference are performed by manipu 36 lating the linear inequalities; thus, these operations can take exponential time in the worst case.
Reference: [58] <author> K. Kennedy. </author> <title> A global flow analysis algorithm. </title> <journal> International Journal of Computer Mathematics, </journal> <volume> 3 </volume> <pages> 5-15, </pages> <year> 1971. </year>
Reference-contexts: Tarjan intervals include only nodes that are part of a loop; that is, together with the header node h, the nodes in T (h) form a strongly connected region. As described by von Hanxleden [43], this 46 differs from the Allen-Cocke intervals <ref> [28, 53, 58] </ref> used in classical interval analysis. Allen-Cocke intervals include nodes whose predecessors are all in T (h); that is, they might include an acyclic structure dangling off the loop. Interval-flow graph differs from a control-flow graph in the way in which edges 2 E are classified.
Reference: [59] <author> K. Kennedy and N. Nedeljkovic. </author> <title> Combining dependence and data-flow analyses to optimize communication. </title> <booktitle> In Proceedings of the 9th International Parallel Processing Symposium, </booktitle> <address> Santa Barbara, CA, </address> <month> April </month> <year> 1995. </year>
Reference-contexts: The important features of the communication placement framework presented 44 in this chapter are as follows: * First, the framework incorporates data-dependence information in the placement analysis to simplify the data-flow equations. This approach differs from previous global data-flow techniques <ref> [40, 44, 59] </ref>, which use dependence information only to evaluate whether different references have data-dependent (over lapping) communication sets. * Second, the framework shows that placement can be determined by a sequence of simple uni-directional analyses.
Reference: [60] <author> K. Kennedy, N. Nedeljkovic, and A. Sethi. </author> <title> Communication generation for cyclic(k) distributions. </title> <booktitle> In Third Annual Workshop on Languages, Compilers, and Run-Time Systems for Scalable Computers (LCR'95), </booktitle> <address> Troy, N.Y., </address> <month> May </month> <year> 1995. </year>
Reference-contexts: Moreover, our techniques do not require tables for handling cyclic (k) distributions and support overlap areas for shift communication <ref> [62, 60] </ref>. The linear-time algorithm for the general case is not part of this dissertation.) Complexity First, as described in Section 7.1.1, the maximum length of the M table can be k. <p> It has been shown that for block and cyclic distributions, overlap areas provide improved performance by simplifying the non-local address calculation. Similar techniques can be developed to support shift communication pattern efficiently in presence of cyclic (k) distributions <ref> [60] </ref>. Finally, regarding code generation, various buffering schemes for non-local data and subscript translation need to be compared to evaluate relative merits of different schemes. 165
Reference: [61] <author> K. Kennedy, N. Nedeljkovic, and A. Sethi. </author> <title> Efficient address generation for block-cyclic distributions. </title> <booktitle> In Proceedings of the 1995 ACM International Conference on Supercomputing, </booktitle> <address> Barcelona, Spain, </address> <month> July </month> <year> 1995. </year>
Reference-contexts: 4.9 5.2 1083.2 s = 3 4.2 5.1 4.9 1088.3 s = 100 4.9 5.7 5.7 1083.5 k = 256 s = 25 4.4 6.7 5.2 1091.5 Table 7.2 Execution times in milliseconds for different versions of loops with the MIV subscript. locations on a demand-driven basis can be applied <ref> [61] </ref>. <p> S or G table) in the inner loop, and the other without any table space overhead, perform only slightly worse than the address generation based on using both the G and M tables, and therefore should be methods of choice if memory overhead needs to be reduced or completely eliminated <ref> [61] </ref>. 7.1.3 Coupled subscripts All address generation methods presented so far deal only with one-dimensional arrays. <p> Processor m scans the elements of B it owns using the NextIndex function, which can be implemented using either the table of the local memory gaps between consecutive array accesses [18] or our demand-driven address generation method <ref> [61] </ref>. index B = start B ; count P = 0 while (index B &lt; end B ) do if (PSend [count P ] 6= m) then fl (buffer [PSend [count P ]])++ = B [index B ] endif count P = (count P + 1) mod Length (PSend) index B
Reference: [62] <author> K. Kennedy, N. Nedeljkovic, and A. Sethi. </author> <title> A linear-time algorithm for computing the memory access sequence in data-parallel programs. </title> <booktitle> In Proceedings of the Fifth ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, </booktitle> <address> Santa Barbara, CA, </address> <month> July </month> <year> 1995. </year> <month> 173 </month>
Reference-contexts: Moreover, our techniques do not require tables for handling cyclic (k) distributions and support overlap areas for shift communication <ref> [62, 60] </ref>. The linear-time algorithm for the general case is not part of this dissertation.) Complexity First, as described in Section 7.1.1, the maximum length of the M table can be k. <p> Thus, our algorithm has fi (k) complexity. Next section presents results to show the efficiency of our linear-time algorithm. Experimental results This section compares the address generation method described in Section 7.1.1 with the linear-time algorithm for the general case <ref> [62] </ref>. The linear-time algorithm for the general case is based on the observation that the accesses form an integer lattice. Thus, all accesses made by an array with cyclic (k) distribution can be computed using the basis vectors of the lattice. <p> k 40 80 * * * s s = 7 * * Lattice * * s &lt; k 100 300 500 * * * * * k * * Lattice * * s &lt; k the special case algorithm presented in Figure 7.3 ("s &lt; k") and the lattice-based algorithm <ref> [62] </ref> ("Lattice"). 133 the general case algorithm. This is because the special case algorithm computes the starting location for a processor without solving the Diophantine equations. It can be observed from the graphs that the table construction times for both the algorithms are independent of the access stride. <p> Using the algorithms described in previous sections and in the related work <ref> [62] </ref>, we can construct the sequences of accessed array elements in both the local and the global index space (Local and Global, respectively), as well as their corresponding iteration numbers (Iter). 150 k 1 fi k 2 (s 1 ; s 2 ) Active procs M table Run time (1; 1) <p> In contrast, we do not need to unpack the received messages, but our approach requires table lookups in the loop. Since the overheads due to indirect addressing are small <ref> [62] </ref>, the loop execution in our scheme is faster than with the virtual processor method, except in the case when virtual-cyclic view was selected at both the sending and the receiving side. 7.6 Related work Several efforts to address some of the difficulties in compiling programs with cyclic (k) distribution have <p> The dissertation presented a linear-time algorithm for generating local access sequence for cyclic (k) distributions for the special cases that occur frequently. However, a linear-time algorithm for the general case will simplify handling of cyclic (k) distributions <ref> [62] </ref>. Moreover, in certain cases, the overhead of maintaining tables might not be acceptable, in which case techniques need to be developed to support cyclic (k) distribution without incurring the space overhead. In addition, the techniques presented in the dissertation use overflow regions irrespective of the communication pattern.
Reference: [63] <author> K. Kennedy and A. Sethi. </author> <title> A communication placement framework with unified dependence and data-flow analysis. </title> <booktitle> In Proceedings of the Third International Conference on High Performance Computing, </booktitle> <address> Trivandrum, </address> <month> December </month> <year> 1996. </year>
Reference-contexts: As discussed in Chapter 1, a performance-critical task of communication generation is to minimize communication overhead. The communication placement framework described in this chapter treats communication primitives as candidates for code motion and determines a judicious placement of communication primitives <ref> [63] </ref>. The framework has been implemented in the Fortran D95 compiler where it is used to determine the placement of communication primitives (Send and Recv) for distributed-memory systems. It reduces communication overhead by decreasing communication frequency. Frequency is reduced by hoisting communication to the outermost placement location.
Reference: [64] <author> K. Kennedy and A. Sethi. </author> <title> Resource-based communication placement analysis. </title> <booktitle> In Proceedings of the Ninth Workshop on Languages and Compilers for Parallel Computing, </booktitle> <address> San Jose, CA, </address> <month> August </month> <year> 1996. </year>
Reference-contexts: Moreover, and again, as explained in Chapter 6, independent Send and Recv phases allow us to support VMP. Finally, Chapter 5 describes how the compositional structure of our analysis allows us to incorporate machine-dependent resource constraints such as cache size and buffer size into the placement analysis <ref> [64] </ref>. The problem of data-flow based communication placement has been addressed by several researchers. Amarasinghe and Lam use a last write tree to optimize communication placement and support VMP within a single loop nest [4]. Moreover, they don't allow loops within conditionals.
Reference: [65] <author> A. Knies, M. O'Keefe, and T. MacDonald. </author> <title> High Performance Fortran: A practical analysis. </title> <journal> Scientific Programming, </journal> <volume> 3(3) </volume> <pages> 187-199, </pages> <month> Fall </month> <year> 1994. </year>
Reference-contexts: However, a linear-time algorithm for the general case will simplify handling of cyclic (k) distribution. As pointed out by Knies et al. address generation based on the local memory gap table makes a time versus space tradeoff <ref> [65] </ref>. Since a table is needed for every array reference with different stride or distribution, for large block sizes this can introduce a substantial memory overhead.
Reference: [66] <author> J. Knoop, O. Ruthing, and B. Steffen. </author> <title> Lazy code motion. </title> <booktitle> In Proceedings of the SIGPLAN '92 Conference on Programming Language Design and Implementation, </booktitle> <address> San Francisco, CA, </address> <month> June </month> <year> 1992. </year>
Reference-contexts: We assume that critical edges due to this and other constructs are eliminated before placement analysis is performed. It can be proved that after the elimination of critical edges, communication (in general, code) placement can be restricted only to node entries <ref> [66] </ref>. Finally, for every non-empty interval T (h), there exists a unique g 2 T (h) such that (g; h) 2 E; that is, there is only one back edge out of T (h). This is achieved by adding a post-body node to T (h) [44].
Reference: [67] <author> J. Knoop, O. Ruthing, and B. Steffen. </author> <title> Optimal code motion: </title> <journal> Theory and practice. ACM Transactions on Programming Languages and Systems, </journal> <volume> 16(4) </volume> <pages> 1117-1155, </pages> <month> July </month> <year> 1994. </year>
Reference-contexts: Note that a forward edge has both the source and sink of the edge in the same interval; forward edges do not cross interval boundaries. We assume that G does not have critical edges. A critical edge connects a node with multiple successors to a node with multiple predecessors <ref> [67] </ref>. Figure 4.1 illustrates how critical edges can lead to incorrect communication placement. Figure 4.1 (a) shows the earliest placement of Send x and the latest placement of Recv x. <p> In traditional code motion techniques, placement of computation at a node is considered safe if the computed value is used along all terminating paths from the node <ref> [76, 67] </ref>. <p> it either (a) contains an use of the communicated data (that is, Used (n; d) = &gt;), or (b) does not modify the data being sent (that is, Transp (n; d) = &gt;) and all its successors are safe (that is, " s2Succs F (n) SAFE (s; d) = &gt;) <ref> [67] </ref>. In terms of data-flow equation: SAFE (n; d) = SAFE (n; d) " [Used (n; d) [ (Transp (n; d) " " s2Succs F (n) SAFE (s; d))] (4:1) Succs F is as defined in Section 4.1.2. <p> The Lazy Code Motion (LCM) technique <ref> [67] </ref> and the Give-N-Take framework [44] improved partial redundancy elimination optimization by excluding unnecessary code motion and by providing non-atomic placement regions, respectively. Our framework is based on both these frameworks.
Reference: [68] <author> C. Koelbel. </author> <title> Compile-time generation of regular communications patterns. </title> <booktitle> In Proceedings of Supercomputing '91, </booktitle> <address> Albuquerque, NM, </address> <month> November </month> <year> 1991. </year>
Reference-contexts: Previous research was focused only on compilation strategies for handling block and cyclic distributions efficiently <ref> [34, 70, 68, 85] </ref>. This chapter demonstrates that the accesses made by cyclic (k) references exhibit a repetitive access pattern. It exploits the repetitive pattern to present efficient compilation techniques for cyclic (k) distributions. The rest of this chapter is organized as follows.
Reference: [69] <author> C. Koelbel, D. Loveman, R. Schreiber, G. Steele, Jr., and M. Zosel. </author> <title> The High Performance Fortran Handbook. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1994. </year>
Reference-contexts: It is expected that HPF will be a standard programming language for computationally intensive applications on many types of machines, such as traditional vector processors and newer massively parallel MIMD and SIMD multiprocessors." | The High Performance Fortran Handbook <ref> [69] </ref>. HPF is based on Fortran 90 [1], which allows expressing data-parallel array expressions (that is, operations that act on whole arrays). In addition, Fortran 90 eliminates some of the deficiencies of Fortran 77. In particular, it allows the use of dynamically allocatable arrays as well as pointers.
Reference: [70] <author> C. Koelbel and P. Mehrotra. </author> <title> Compiling global name-space programs for distributed execution. </title> <type> ICASE Report 90-70, </type> <institution> Institute for Computer Application in Science and Engineering, Hampton, VA, </institution> <month> October </month> <year> 1990. </year> <month> 174 </month>
Reference-contexts: Previous research was focused only on compilation strategies for handling block and cyclic distributions efficiently <ref> [34, 70, 68, 85] </ref>. This chapter demonstrates that the accesses made by cyclic (k) references exhibit a repetitive access pattern. It exploits the repetitive pattern to present efficient compilation techniques for cyclic (k) distributions. The rest of this chapter is organized as follows. <p> After multiplying the iteration numbers by the stride s A , we get the global index sequence of corresponding left-hand-side (lhs) accesses, Image lhs (0) = <ref> [0; 20; 35; 50; 55; 70; 85; 105] </ref> with the period 120.
Reference: [71] <author> U. Kremer and M. </author> <title> Rame. Compositional oil reservoir simulation in Fortran D: A feasibility study on Intel iPSC/860. </title> <journal> International Journal of Supercomputer Applications and High Performance Computing, </journal> <volume> 8(2), </volume> <month> Summer </month> <year> 1994. </year>
Reference-contexts: Disper is a 1500 line stencil computation from the UTCOMP reservoir simulator <ref> [71] </ref>. Unlike Erlebacher, Disper is highly data-parallel program. Figure 4.12 presents a fragment of code from Disper. As shown in the figure, it has a lot of conditionals nested inside loop nests. <p> Timings are in milliseconds. that every program execution path contains balanced communication placement. In order to derive any benefits, communication needs to be moved out of the conditionals possibly resulting in over-communication; but this allows communication to be hoisted out of loops <ref> [71] </ref>. In other words, Disper requires the safety criterion presented in Section 4.3 to be relaxed. However, since the safety has an independent data-flow equation, the equation can be changed easily.
Reference: [72] <author> J. Li and M. Chen. </author> <title> Automating the coordination of interprocessor communication. </title> <booktitle> In Advances in Languages and Compilers for Parallel Computing, </booktitle> <address> Irvine, CA, August 1990. </address> <publisher> The MIT Press. </publisher>
Reference-contexts: Previous research efforts did not take resource constraints into account and defined correctness under the assumption that sufficient resources were available <ref> [72, 43] </ref>. Chapter 5 presents the analysis required to ensure that the communication placement does not exceed the resource constraints. Assuming that the resource constraints are satisfied by the placement, correctness requires that the program executes matching number of Sends and Recvs. <p> Similarly, In order to compute the sets of data that processor 0 must send to other processors, we first determine the sequence of accesses to array B (in the global index space) that processor 0 owns, Global B (0) = <ref> [2; 30; 51; 72; 79; 100; 121; 149] </ref> with the period 168, and the corresponding iteration sequence Iter B (0) = [0; 4; 7; 10; 11; 14; 17; 21] with the period 24. <p> do not expect the length of the expanded sequence to exceed the larger of the two block sizes.) After expansion, we get Iter A (0) = [0; 3; 5; 10; 12; 15; 17; 22] with the period 24, and the sequence of corresponding rhs accesses is Image rhs (0) = <ref> [2; 23; 37; 72; 86; 107; 121; 156] </ref> with the period 168. <p> In order be able to pack the messages corresponding to different rhs terms in a single pass over the array, we must find the union of PSend sequences corresponding to different rhs references. Section 7.2 showed that Global B (7i+2) (0) = <ref> [2; 30; 51; 72; 79; 100; 121; 149] </ref> with the period 168 and PSend B (7i+2) (0), the sequence of processors that processor 0 sends data to, to be [0; 2; 2; 0; 1; 2; 0; 2].
Reference: [73] <author> B. Lu. </author> <title> Compiling reductions in the Fortran D95 compiler. M.S. </title> <type> Thesis (under preparation), </type> <month> October </month> <year> 1996. </year>
Reference-contexts: Thus, one-to-many is refined to be either broadcast (one-to-all) or multi-spread (one-to-many, but not all) patterns. Similarly, many-to-many patterns can also be refined. In addition, the Fortran D95 compiler performs extensive analysis to identify the reduction communication pattern, which is a special form of many-to-one communication pattern <ref> [73] </ref>. Since the communication pattern depends on both the number of sender and number of receiver processors, we must know not only the non-local reference but also the corresponding computation partitioning in order to compute the pattern for a communication descriptor.
Reference: [74] <author> D. Maydan, S. Amarasinghe, and M. Lam. </author> <title> Array data-flow analysis and its use in array privatization. </title> <booktitle> In Proceedings of the Twentieth Annual ACM Symposium on the Principles of Programming Languages, </booktitle> <address> Charleston, SC, </address> <month> January </month> <year> 1993. </year>
Reference-contexts: SUIF compiler uses last write trees (LWTs) for computing precise array data-flow information efficiently for commonly occuring special cases <ref> [74, 4] </ref>. LWT analysis is performed on individual loop nests. Due to the use of LWTs, the communication and computation code generation is limited to programs con 22 sisting of loop nests with affine array accesses and loop bounds. The technique cannot handle loops nested inside conditionals.
Reference: [75] <author> R. Mirchandaney, S. Hiranandani, and A. Sethi. </author> <title> Improving the performance of DSM systems via compiler involvement. </title> <booktitle> In Proceedings of Supercomputing '94, </booktitle> <address> Washington, DC, </address> <month> November </month> <year> 1994. </year>
Reference-contexts: Cyclic (k) distribution is useful in the programs that require both locality and load-balancing. For example, programs with triangular loops, such as Cholesky factorization <ref> [75] </ref> and Gaussian elimination [47], can benefit from cyclic (k) distribution. Unlike block distribution, cyclic (k) distribution is amenable to load-balancing issues. Moreover, unlike cyclic distribution, cyclic (k) distribution can yield better locality. Thus, cyclic (k) distribution provides the benefits of both block and cyclic distributions. <p> Similarly, for B (7i + 5) we can compute Global B (7i+5) (0) = <ref> [5; 26; 54; 75; 96; 103; 124; 145] </ref> with the period 168, which results in PSend B (7i+5) (0) = [0; 0; 2; 0; 1; 2; 0; 2].
Reference: [76] <author> E. Morel and C. </author> <title> Renvoise. Global optimization by suppression of partial redundancies. </title> <journal> Communications of the ACM, </journal> <volume> 22(2) </volume> <pages> 96-103, </pages> <month> February </month> <year> 1979. </year>
Reference-contexts: In traditional code motion techniques, placement of computation at a node is considered safe if the computed value is used along all terminating paths from the node <ref> [76, 67] </ref>. <p> However, it has been noted by several researchers that for typical programs, the average out-degree of graph nodes and the maximal loop nesting depth can be assumed to be bounded by a small constant independent of the size of the program <ref> [76, 44] </ref>. Therefore, for well structured programs, elimination of critical edges should not increase the size of G significantly. <p> endif endif : : : enddo enddo enddo enddo end the UTCOMP oil reservoir simulation program. 81 tion require communication placement that hides latency and, thus, demonstrate the usefulness of our framework. 4.9 Related work Code motion and placement to eliminate partially redundant computations was introduced by the PRE algorithm <ref> [76] </ref>. The Lazy Code Motion (LCM) technique [67] and the Give-N-Take framework [44] improved partial redundancy elimination optimization by excluding unnecessary code motion and by providing non-atomic placement regions, respectively. Our framework is based on both these frameworks.
Reference: [77] <author> T. Mowry, M. Lam, and A. Gupta. </author> <title> Design and evaluation of a compiler algorithm for prefetching. </title> <booktitle> In Proceedings of the Fifth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS-V), </booktitle> <pages> pages 62-73, </pages> <address> Boston, MA, </address> <month> October </month> <year> 1992. </year>
Reference-contexts: In case the loop bounds are unknown, the loop bounds can be assumed to be either very small (and all the messages fit in the buffer) or very large (such that no message fits in the buffer) <ref> [77] </ref>. 5.4.2 Resource analysis across loop nests As described before, besides increasing the size of non-local buffers, earlier placement of Sends also increases the range over which the non-local buffers need to be live and this further increase the total size of non-local buffers required.
Reference: [78] <author> W. Pugh. </author> <title> A practical algorithm for exact array dependence analysis. </title> <journal> Communications of the ACM, </journal> <volume> 35(8) </volume> <pages> 102-114, </pages> <month> August </month> <year> 1992. </year> <month> 175 </month>
Reference-contexts: Operations on array sections, such as union, intersection, and difference are performed by manipu 36 lating the linear inequalities; thus, these operations can take exponential time in the worst case. However, empirical evidence has shown that Fourier-Motzkin elimination is quite efficient for commonly encountered scientific codes <ref> [78] </ref>. 3.3.2 Periodic access sequences union of regular sections (in other words, it is a non-convex region), it can not be represented using either the RSD, DAD, or PTD representations.
Reference: [79] <author> B. Rosen, M. Wegman, and K. Zadeck. </author> <title> Global value numbers and redundant compuations. </title> <booktitle> In Proceedings of the Fifteenth Annual ACM Symposium on the Principles of Programming Languages, </booktitle> <address> San Diego, CA, </address> <month> January </month> <year> 1988. </year>
Reference-contexts: Clearly, this is an incorrect placement because if the right branch is taken, then the Recv x will not have a matching Send x. It is well known that the code motion process may be blocked by critical edges <ref> [24, 27, 79] </ref>. <p> Similarly, In order to compute the sets of data that processor 0 must send to other processors, we first determine the sequence of accesses to array B (in the global index space) that processor 0 owns, Global B (0) = <ref> [2; 30; 51; 72; 79; 100; 121; 149] </ref> with the period 168, and the corresponding iteration sequence Iter B (0) = [0; 4; 7; 10; 11; 14; 17; 21] with the period 24. <p> In order be able to pack the messages corresponding to different rhs terms in a single pass over the array, we must find the union of PSend sequences corresponding to different rhs references. Section 7.2 showed that Global B (7i+2) (0) = <ref> [2; 30; 51; 72; 79; 100; 121; 149] </ref> with the period 168 and PSend B (7i+2) (0), the sequence of processors that processor 0 sends data to, to be [0; 2; 2; 0; 1; 2; 0; 2].
Reference: [80] <author> J. Stichnoth. </author> <title> Efficient compilation of array statements for private memory mul-ticomputers. </title> <type> Technical Report CMU-CS-93-109, </type> <institution> School of Computer Science, Carnegie Mellon University, </institution> <month> February </month> <year> 1993. </year>
Reference-contexts: Neither Chatterjee et al. [18] nor Gupta et al. [41] deal with this issue. Stichnoth <ref> [80] </ref> indicates that combining communication steps would be profitable, but he does not describe the necessary analysis. In contrast, we show how our approach can support message coalescing optimization [48] to reduce the communication cost.
Reference: [81] <author> J. Stichnoth, D. O'Hallaron, and T. Gross. </author> <title> Generating communication for array statements: Design, implementation, and evaluation. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 21(1) </volume> <pages> 150-159, </pages> <month> April </month> <year> 1994. </year>
Reference-contexts: In the virtual-block scheme array 161 accesses are not reordered, but if the array section stride is larger than the block size, their method effectively reduces to the run-time address resolution. Stichnoth et al. use intersections of array slices for communication generation <ref> [81] </ref>. Their approach is similar to, and has the same drawback as, the virtual-cyclic scheme mentioned above. 7.7 Summary The chapter described efficient techniques for generating local addresses for array references with arbitrary affine subscripts.
Reference: [82] <author> E. Su, A. Lain, S. Ramaswamy, D. J. Palermo, E. W. Hodges IV, and P. Banerjee. </author> <title> Advanced compilation techniques in the PARADIGM compiler for distributed-memory multicomputers. </title> <booktitle> In Proceedings of the 1995 ACM International Conference on Supercomputing, </booktitle> <address> Barcelona, Spain, </address> <month> July </month> <year> 1995. </year>
Reference-contexts: In addition to automatically performing data distribution for regular computations, it optionally parses HPF data distribution directives. It supports all the three regular distributions provided by HPF <ref> [82] </ref>. The PARADIGM compiler performs computation partitioning based only on the owner-computes rule. It performs communication placement and optimizations based on dependence information. The PARADIGM compiler represents the data being communicated with linear inequalities. Unlike the SUIF compiler, it uses an "off-the-shelf" symbolic package for manipulating linear inequalities. <p> The PARADIGM compiler represents the data being communicated with linear inequalities. Unlike the SUIF compiler, it uses an "off-the-shelf" symbolic package for manipulating linear inequalities. The PARADIGM compiler uses 23 Mathematica's fl symbolic manipulation capabilities to support computation par titioning, communication generation, and loop transformation <ref> [82] </ref>. Fortran D compiler Fortran D compiler was the first generation prototype compiler developed for Fortran D language [31] a HPF-like data-parallel language. The Fortran D compiler implemented several new compilation techniques [50, 49, 52]. <p> A lot of research has been done to represent array sections efficiently <ref> [29, 8, 46, 7, 6, 5, 82] </ref>. Explicit representations can be classified as either precise or imprecise representations. The latter category of representations tend to sacrifice precision for efficiency. Imprecise representations use closed-form formulae or a restricted class of geometric patterns to approximate given array section with a convex region. <p> PTDs are closed under intersection while union and difference can result in a list of sets. Fourier-Motzkin elimination A lot of researchers have proposed precise array section representations based on the Fourier-Motzkin elimination method <ref> [29, 6, 7, 57, 82] </ref>. These representations represent array sections with a set of linear inequalities. Operations on array sections, such as union, intersection, and difference are performed by manipu 36 lating the linear inequalities; thus, these operations can take exponential time in the worst case. <p> An example of this 39 is the PARADIGM compiler which uses the in-built functionality of Mathematica to implement linear inequalities required for expressing array sections <ref> [82] </ref>. The Fortran D95 compiler utilizes an existing package for expressing the integer sets corresponding to computation and communication sets. Thus, we directed our intellectual efforts towards developing efficient mode of expressing and computing communication sets and not on the development of the necessary underlying machinery for manipulating integer sets.
Reference: [83] <author> E. Su, D. Palermo, and P. Banerjee. </author> <title> Processor tagged descriptors: A data structure for compiling for distributed-memory multicomputers. </title> <booktitle> In Proceedings of the International Conference on Parallel Architectures and Compilation Techniques (PACT), </booktitle> <address> Montreal, Canada, </address> <month> August </month> <year> 1994. </year>
Reference-contexts: The intersection and union operations on DADs can take time proportional to the number of dimensions of the section. DADs are closed under intersection. The union operation returns a conservative approximation of the unioned DAD sections. Processor tagged descriptors Processor tagged descriptors (PTDs) are used in the PARADIGM compiler <ref> [83] </ref> to incorporate processor information along with the array section information. PTDs are useful in expressing the distributed array sections; bounds of an array section for a processor can be parameterized with the processor number.
Reference: [84] <author> R. E. Tarjan. </author> <title> Testing flow graph reducibility. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 9 </volume> <pages> 355-365, </pages> <year> 1974. </year>
Reference-contexts: We assume that G is reducible; that is, each loop has a unique header node. In this chapter we assume that G corresponds to a structured program; however, the placement framework can be extended to handle jumps out of loops. We assume that G uses Tarjan intervals <ref> [84] </ref>, where a Tarjan interval T (h) is a set of control-flow nodes that correspond to a loop body in the program text. A Tarjan interval has a unique header node h, where h 62 T (h).
Reference: [85] <author> C.-W. Tseng. </author> <title> An Optimizing Fortran D Compiler for MIMD Distributed-Memory Machines. </title> <type> PhD thesis, </type> <institution> Dept. of Computer Science, Rice University, </institution> <month> January </month> <year> 1993. </year>
Reference-contexts: Since most parallel machines package memory with processors, accesses to remote memory are typically an order of magnitude slower than accesses to local memory. Thus, remote accesses add communication overhead to the total execution time and, as the number of processors increase, communication overhead can dominate the execution time <ref> [85] </ref>. Reducing communication overhead is a key goal of optimizing parallel programs. Multiprocessor/parallel systems support high-level parallel languages that allow programmers to use the familiar, machine-independent programming style to develop programs for multiprocessor systems. <p> RSDs can also represent regular sections with constant stride. RSDs were originally developed for summarizing side effects across procedure boundaries and represent array sections using an imprecise representation. RSDs were used extensively in the Fortran D compiler <ref> [85] </ref>. The union and intersection of RSDs can be computed in time proportional to 35 the number of section dimensions. RSDs are closed under intersection but not union. <p> Previous research was focused only on compilation strategies for handling block and cyclic distributions efficiently <ref> [34, 70, 68, 85] </ref>. This chapter demonstrates that the accesses made by cyclic (k) references exhibit a repetitive access pattern. It exploits the repetitive pattern to present efficient compilation techniques for cyclic (k) distributions. The rest of this chapter is organized as follows. <p> After multiplying the iteration numbers by the stride s A , we get the global index sequence of corresponding left-hand-side (lhs) accesses, Image lhs (0) = <ref> [0; 20; 35; 50; 55; 70; 85; 105] </ref> with the period 120.
Reference: [86] <author> H. Zima and B. Chapman. </author> <title> Compiling for distributed-memory systems. </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> 81(2) </volume> <pages> 264-287, </pages> <month> February </month> <year> 1993. </year>
Reference-contexts: The source language used by this project was Vienna Fortran [16, 17]; one of the predecessors of HPF. The Vienna Fortran group pioneered various compilation techniques <ref> [33, 35, 86] </ref>. The compiler introduced owner-computes rule and message vectorization. It also introduced the concept of overlap areas for regular, stencil-based computations. However, like the Fortran D compiler, it was restricted in its scope. It supported only block and cyclc distributions. <p> do not expect the length of the expanded sequence to exceed the larger of the two block sizes.) After expansion, we get Iter A (0) = [0; 3; 5; 10; 12; 15; 17; 22] with the period 24, and the sequence of corresponding rhs accesses is Image rhs (0) = <ref> [2; 23; 37; 72; 86; 107; 121; 156] </ref> with the period 168. <p> By computing the owners of the elements of array B with these indices we can construct the table PRecv (0) = [0,2,1,0,1,1,0,1], as well as DRecv sets, for example, DRecv (0 1) = B <ref> [37; 86; 107; 156] </ref> with the period 168. Not all the tables shown here need to be actually allocated and assigned values. We need tables for storing the array access sequences corresponding to both the reference.
References-found: 86

