URL: ftp://bugle.cs.uiuc.edu/pub/Pablo.Release.5/Documentation/PabloOverview.ps.gz
Refering-URL: http://vibes.cs.uiuc.edu/People/Staff/Aydt/publications.htm
Root-URL: http://www.cs.uiuc.edu
Title: An Overview of the Pablo Performance Analysis Environment  
Author: Daniel A. Reed Ruth A. Aydt Tara M. Madhyastha Roger J. Noe Keith A. Shields Bradley W. Schwartz 
Degree: Trustees. All Rights Reserved.  
Note: Copyright c 1992 The  Supported in part by the Defense Advanced Research Projects Agency under DARPA Contract Number DABT63-91-K-0004, by the National Science Foundation under grants NSF CCR87-06653 and NSF CDA87-22836, by the National Aeronautics and Space Administration under NASA Contract Number NAG-1-613, and by an equipment grant from the Digital Equipment Corporation External Research Program.  
Date: November 7, 1992  
Address: Urbana, Illinois 61801  
Affiliation: Department of Computer Science University of Illinois  University of Illinois Board of  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Arendt, J. W. </author> <title> Parallel Genome Sequence Comparison Using an iPSC/2 with a Concurrent File System. </title> <type> Master's thesis, </type> <institution> University of Illinois at Urbana-Champaign, Department of Computer Science, </institution> <month> Jan. </month> <year> 1991. </year>
Reference-contexts: Users could choose from the cross product of data analyses and data displays. Although this environment proved useful in studying the performance of both parallel applications [38, 18] and the Intel iPSC/2's parallel file system <ref> [1] </ref>, the dependence of performance data capture on modifications to a proprietary operating system precluded both wide distribution and porting to new architectures. The performance data file format was designed to support only distributed memory parallel systems, and the performance data analyses were intimately tied to the data source.
Reference: [2] <author> Aydt, R. A. SDDF: </author> <title> The Pablo Self-Describing Data Format. </title> <type> Tech. rep., </type> <institution> University of Illinois at Urbana-Champaign, Department of Computer Science, </institution> <month> Mar. </month> <year> 1992. </year>
Reference-contexts: Each stream attribute consists of a key and an attribute; both can be any string of characters. 10 See <ref> [2] </ref> for complete details. 13 Descriptor records describe record layouts, similar to a structure definition in the C program-ming language. Each descriptor record associates a record name with a description of the fields that will appear in all data records having that name.
Reference: [3] <author> Berry, M. et al. </author> <title> The Perfect Club Benchmarks: Performance Evaluation of Supercomputers. </title> <journal> The International Journal of Supercomputer Applications 3, </journal> <volume> 3 (1989), </volume> <pages> 5-40. </pages> <month> Fall. </month>
Reference-contexts: both data immersive presentation via head-mounted displays and integration with the Rice Fortran D compiler [15] Finally, x12 summarizes the current environment state and plans for future software development. 1 2 Pablo Design Philosophy The performance variability of parallel computer systems with even modest numbers of processors is well documented <ref> [3] </ref>. Larger numbers of processors exacerbate the already difficult problems of bottleneck identification and performance tuning. The primary reason for the increased difficulty is not the number of processors, but rather the greater complexity and frequency of component interactions as well as the number of potential optimization gradients.
Reference: [4] <author> Blattner, M. M., Sumikawa, D. A., and Greenberg, R. M. Earcons and Icons: </author> <title> Their Structure and Common Design Principles. </title> <booktitle> Human-Computer Interaction 4 (1989), </booktitle> <pages> 11-44. </pages>
Reference-contexts: The final example reveals not only the expected delay between message transmission and receipt but also the distribution of latencies. 16 We have also developed a set of "earcons," <ref> [4] </ref> or audio warnings, that presently include sampled voice warnings, enumerations, and alarms. As an example, we mapped aggregate processor utilization to a sonic alarm that sounded only when utilization fell below a specified threshold. We have found this particularly useful when processing large volumes of data.
Reference: [5] <author> Bly, S. </author> <title> Sound and Computer Information Presentation. </title> <type> PhD thesis, </type> <institution> University of California, Davis, </institution> <year> 1982. </year>
Reference-contexts: Experiments with sonic data presentation, often called sonification, have been underway since the early 1980's, when inexpensive technology made applied research in this area economical <ref> [5] </ref>. 15 However, the sonifications have often been limited to simple mappings between data values and primitive sound characteristics, such as volume, pitch, and wave shape.
Reference: [6] <author> Couch, A. L. </author> <title> Graphical Representations of Program Performance on Hypercube Message-Passing Multiprocessors. </title> <type> PhD thesis, </type> <institution> Tufts University, Department of Computer Science, </institution> <month> Apr. </month> <year> 1988. </year>
Reference-contexts: The Pablo data flow metaphor makes this integration possible. 6.1 Graphical Programming Models The graphical programming paradigm has been widely used in both academic and commercial settings to create coarse-grained data flow graphs. Couch's Seecube performance environment <ref> [6] </ref>, the aPE visualization system [9], originally developed at the Ohio State Supercomputer Center, and the University of New Mexico Khoros image processing system [40] are well-known research implementations of such systems. The AVS visualization system [37] and Silicon Graphics' Explorer system are successful examples in the commercial arena.
Reference: [7] <author> Deitel, H. M. </author> <title> An Introduction to Operating Systems. </title> <publisher> Addison-Wesley, </publisher> <year> 1984. </year>
Reference-contexts: Historically, computer systems have been studied experimentally by subjecting the test system to a known load and capturing static, aggregate performance measures such as throughput, response time, and utilization <ref> [7] </ref>. Similarly, the performance of application programs often has been assessed via code profiles that reveal the distribution of execution time across the code.
Reference: [8] <author> Dennis, J. B. </author> <title> First Version of a Data Flow Procedure Language. </title> <booktitle> In Lecture Notes in Computer Science, </booktitle> <volume> 19. </volume> <publisher> Springer-Verlag, </publisher> <year> 1974, </year> <pages> pp. 362-376. </pages>
Reference-contexts: unit's output to synthesize an instance of the previously specified output record and transmits the record to the output pipe. 6.3 Data Binding and Module Execution Rules In contrast to simple, static data flow graphs whose nodes have fixed size input data buffers, strongly typed inputs, and simple firing rules <ref> [8] </ref>, Pablo supports data buffering on module input and output pipes, polymorphic data analysis modules, complex mappings of data records to module inputs and outputs, and both synchronous and asynchronous module execution.
Reference: [9] <author> Dyer, D. S. </author> <title> A Dataflow Toolkit for Visualization. </title> <booktitle> IEEE Computer (July 1990), </booktitle> <pages> 60-69. </pages>
Reference-contexts: The Pablo data analysis environment supports the graphical interconnection of performance data transformation modules, in the style of aPE <ref> [9] </ref> or AVS [37], to form a directed, 14 acyclic data analysis graph. Performance data flows through the configured graph nodes and is transformed to yield the desired performance metrics. <p> The Pablo data flow metaphor makes this integration possible. 6.1 Graphical Programming Models The graphical programming paradigm has been widely used in both academic and commercial settings to create coarse-grained data flow graphs. Couch's Seecube performance environment [6], the aPE visualization system <ref> [9] </ref>, originally developed at the Ohio State Supercomputer Center, and the University of New Mexico Khoros image processing system [40] are well-known research implementations of such systems. The AVS visualization system [37] and Silicon Graphics' Explorer system are successful examples in the commercial arena.
Reference: [10] <author> FCCSET. </author> <title> Grand Challenges 1993: High Performance Computing and Communications, </title> <booktitle> the FY 1993 U.S. Research and Development Program. </booktitle> <institution> Federal Coordinating Council for Science, Engineering and Technology, Office of Science and Technology Policy, </institution> <year> 1992. </year>
Reference-contexts: an equal partner to theory and experiment, there is growing consensus that massively parallel systems are the only technically and economically viable approach to achieving the computing power needed to effectively study the "Grand Challenge" problems (e.g., ocean and climate modeling, computational fluid and combustion dynamics, or computational drug design) <ref> [10] </ref>. Several vendors have announced or begun delivery of massively parallel systems whose potential performance exceeds three hundred gigaflops, all having clear performance growth paths to multiple teraflops within three years. All these systems are constructed by coupling large numbers of standard, high-performance microprocessors via a high-speed communication network.
Reference: [11] <author> Francioni, J. M., Albright, L., and Jackson, J. A. </author> <title> The Sounds of Parallel Programs. </title> <booktitle> In Proceedings of the Sixth Distributed Memory Computing Conference (1991), </booktitle> <publisher> IEEE Computer Society. </publisher>
Reference-contexts: However, like visualization and graphics, sonification and music differ in important ways; sonification idioms are only beginning to emerge. As examples, Scaletti [35], Rabenhorst et al [31], and Francioni <ref> [11] </ref> have begun exploring the use of new idioms and abstractions for mapping data to sound. Francioni's work [11] is most relevant to our research goals, as it concerns the mapping of parallel computer system performance data to synthesized sound. <p> However, like visualization and graphics, sonification and music differ in important ways; sonification idioms are only beginning to emerge. As examples, Scaletti [35], Rabenhorst et al [31], and Francioni <ref> [11] </ref> have begun exploring the use of new idioms and abstractions for mapping data to sound. Francioni's work [11] is most relevant to our research goals, as it concerns the mapping of parallel computer system performance data to synthesized sound.
Reference: [12] <author> Fromm, H., Hercksen, U., Herzog, U., John, K., Klar, R., and Kleinoder, W. </author> <title> Experiences with Performance Measurement and Modeling of a Processor Array. </title> <booktitle> IEEE Tran-actions on Computers 32, </booktitle> <month> 1 (Jan. </month> <year> 1983). </year>
Reference-contexts: Thus, it is imperative that the Pablo trace capture library provide some safeguards for data volume and accuracy. There are two possible techniques that can reduce event tracing overheads to acceptable levels. The first is to develop hardware that supports capture and recording of software-generated events <ref> [24, 12, 13, 29, 28] </ref>.
Reference: [13] <author> Haban, D., and Wybranietz, D. </author> <title> A Hybrid Monitor for Behavior and Performance Analysis of Distributed Systems. </title> <journal> IEEE Transactions on Software Engineering 16, </journal> <month> 2 (Feb. </month> <year> 1990), </year> <pages> 197-211. </pages>
Reference-contexts: Thus, it is imperative that the Pablo trace capture library provide some safeguards for data volume and accuracy. There are two possible techniques that can reduce event tracing overheads to acceptable levels. The first is to develop hardware that supports capture and recording of software-generated events <ref> [24, 12, 13, 29, 28] </ref>.
Reference: [14] <author> Heath, M. T., and Etheridge, J. A. </author> <title> Visualizing the Performance of Parallel Programs. </title> <booktitle> IEEE Software (Sept. </booktitle> <year> 1991), </year> <pages> 29-39. 31 </pages>
Reference-contexts: We plan to add display update controls, allowing users to throttle the graph execution rate to perceptually manageable levels. In addition to the actual display update rate, Heath's experience with the ParaGraph performance visualization system <ref> [14] </ref> and our own experience [26] suggest that users also wish to view periodic performance "snapshots" (i.e., they wish to see state of the graphical displays only at discrete, often widely separated, points in the trace data).
Reference: [15] <author> Hiranandani, S., Kennedy, K., and Tseng, C.-W. </author> <title> Compiler Optimizations for Fortran D on MIMD Distributed-Memory Machines. </title> <booktitle> In Supercomputing '91 (Nov. </booktitle> <year> 1991), </year> <pages> pp. 86-100. </pages>
Reference-contexts: data reduction, display and sonification features, x9 describes our plans to study system software performance and resource management issues, followed in x10-x11 by a description of our current work to extend Pablo's functionality to include both data immersive presentation via head-mounted displays and integration with the Rice Fortran D compiler <ref> [15] </ref> Finally, x12 summarizes the current environment state and plans for future software development. 1 2 Pablo Design Philosophy The performance variability of parallel computer systems with even modest numbers of processors is well documented [3]. <p> Although this explicit parallelism makes correlation of dynamic performance data with program behavior straightforward, it does nothing to lessen the already difficult problem of programming parallel systems. In contrast, data parallel languages like Fortran 90 or its proposed extensions, Fortran D <ref> [15] </ref> and High Performance Fortran [16], not only provide many of the programming abstractions needed to elide the details of data placement and movement on distributed memory parallel systems, they also provide sufficient control to tailor data placement to match application behavior.
Reference: [16] <author> HPFF. </author> <title> DRAFT High-Performance Fortran Language Specfication. </title> <type> Tech. rep., </type> <institution> High Performance Fortran Forum, </institution> <month> Nov. </month> <year> 1992. </year>
Reference-contexts: Although this explicit parallelism makes correlation of dynamic performance data with program behavior straightforward, it does nothing to lessen the already difficult problem of programming parallel systems. In contrast, data parallel languages like Fortran 90 or its proposed extensions, Fortran D [15] and High Performance Fortran <ref> [16] </ref>, not only provide many of the programming abstractions needed to elide the details of data placement and movement on distributed memory parallel systems, they also provide sufficient control to tailor data placement to match application behavior.
Reference: [17] <institution> Intel Supercomputer Systems Division. Paragon XP/S Product Overview. Beaverton, Oregon, </institution> <month> Nov. </month> <year> 1991. </year>
Reference-contexts: All these systems are constructed by coupling large numbers of standard, high-performance microprocessors via a high-speed communication network. For example, the Paragon XP/S parallel system <ref> [17] </ref>, the commercial realization of the Intel/DARPA Touchstone project [19], is based on the high-performance i860/XP microprocessor and provides 200 megabyte/second, full-duplex communication links with software message passing latency measured in microseconds; the peak performance of the largest hardware configuration approaches 300 gigaflops. <p> As an example, the Intel Paragon XP/S system is designed to scale from 64 to over 500 processors, with planned expansion to 2048 processors <ref> [17] </ref>; the Thinking Machines CM-5 scales over a similar range [39]. Thus, portability is a necessary, but not sufficient, condition for a performance environment; scalability is also required. As the parallel system scales in size and performance, the performance environment must scale commensurately. <p> Our initial architectural targets are the Thinking Machines CM-5 [39] and the Intel Paragon XP/S systems <ref> [17] </ref>. As exemplars of common, massively parallel architectures, availability of software performance instrumentation for these machines will aid a large and growing user community. <p> Thus, one could use the Pablo performance analysis environment to explore the trace data drawn from a simulated computer architecture or to study the performance of operating system resource management policies on massively parallel systems. As an example of the latter, consider the recently announced Intel Paragon XP/S multicom-puter <ref> [17] </ref>. Each node will execute a Mach microkernel with an OSF/1 application interface on individual multicomputer nodes.
Reference: [18] <author> Jensen, D. W., and Reed, D. A. </author> <title> A Performance Analysis Exemplar: Parallel Ray Tracing. </title> <journal> Concurrency: Practice and Experience, </journal> <note> to appear (1992). </note>
Reference-contexts: Users could choose from the cross product of data analyses and data displays. Although this environment proved useful in studying the performance of both parallel applications <ref> [38, 18] </ref> and the Intel iPSC/2's parallel file system [1], the dependence of performance data capture on modifications to a proprietary operating system precluded both wide distribution and porting to new architectures.
Reference: [19] <author> Lillevik, S. L. </author> <title> Touchstone Program Overview. </title> <booktitle> In Proceedings of the Fifth Distributed Memory Computing Conference (1990), IEEE Computer Society, </booktitle> <pages> pp. 647-657. </pages>
Reference-contexts: All these systems are constructed by coupling large numbers of standard, high-performance microprocessors via a high-speed communication network. For example, the Paragon XP/S parallel system [17], the commercial realization of the Intel/DARPA Touchstone project <ref> [19] </ref>, is based on the high-performance i860/XP microprocessor and provides 200 megabyte/second, full-duplex communication links with software message passing latency measured in microseconds; the peak performance of the largest hardware configuration approaches 300 gigaflops.
Reference: [20] <author> Madhyastha, T. M. Porsonify: </author> <title> A Portable System for Data Sonification. </title> <type> Tech. rep., </type> <institution> University of Illinois at Urbana-Champaign, Department of Computer Science, </institution> <month> Mar. </month> <year> 1992. </year>
Reference-contexts: Furthermore, different instruments can interpret MIDI messages in different ways. This makes it almost impossible to play a composition written for one MIDI instrument on another. In light of these software and hardware constraints, we have identified the following criteria that we believe a portable sonification system should satisfy <ref> [20, 21, 22] </ref>: * Sound hardware should be manipulated by a network server, so that the interface to local and remote sound devices is the same. * The interface to a particular sound device cannot be too abstract | it must reflect hardware functions. <p> of a sonification should be both configurable and able to utilize all available capa bilities of a sound device. * It should be easy to create a wide range of sonifications that operate in real-time and that can be synchronized with visualizations. 7.1 Sonification Software Structure The Pablo sound toolkit <ref> [20] </ref> is an attempt to ensure portability across multiple sound devices by separating the sound hardware interface from the sonification (i.e., the algorithm that creates sound from the data on wishes to sonify). The design of the sound toolkit reflects the success of the X window system's client/server protocol.
Reference: [21] <author> Madhyastha, T. M. </author> <title> A Portable System for Data Sonification. </title> <type> Master's thesis, </type> <institution> University of Illinois at Urbana-Champaign, Department of Computer Science, </institution> <month> May </month> <year> 1992. </year>
Reference-contexts: Furthermore, different instruments can interpret MIDI messages in different ways. This makes it almost impossible to play a composition written for one MIDI instrument on another. In light of these software and hardware constraints, we have identified the following criteria that we believe a portable sonification system should satisfy <ref> [20, 21, 22] </ref>: * Sound hardware should be manipulated by a network server, so that the interface to local and remote sound devices is the same. * The interface to a particular sound device cannot be too abstract | it must reflect hardware functions.
Reference: [22] <author> Madhyastha, T. M., and Reed, D. A. </author> <title> A Framework for Sonification Design. In Data Sonification, </title> <editor> G. Kramer, Ed. </editor> <publisher> Addison-Wesley Publishing Company, </publisher> <year> 1993. </year>
Reference-contexts: Furthermore, different instruments can interpret MIDI messages in different ways. This makes it almost impossible to play a composition written for one MIDI instrument on another. In light of these software and hardware constraints, we have identified the following criteria that we believe a portable sonification system should satisfy <ref> [20, 21, 22] </ref>: * Sound hardware should be manipulated by a network server, so that the interface to local and remote sound devices is the same. * The interface to a particular sound device cannot be too abstract | it must reflect hardware functions.
Reference: [23] <author> Malony, A. D., and Reed, D. A. </author> <title> Visualizing Parallel Computer System Performance. In Instrumentation for Future Parallel Computing Systems, </title> <editor> M. Simmons, R. Koskela, and I. Bucher, Eds. </editor> <publisher> Addison-Wesley Publishing Company, </publisher> <year> 1989, </year> <pages> pp. 59-90. </pages>
Reference-contexts: If a tool's functionality is too limited, it will not be used. Conversely, if a tool is too general and does not support common cases in obvious ways, users will abandon it in frustration. Based on our experience designing, implementing and using two previous generations of performance analysis software <ref> [23, 26] </ref>, we believe there are three classes of potential performance 3 environment users: novice, intermediate, and expert. Novice users know relatively little about par-allel machine software or hardware, nor do they wish to learn more than the minimum necessary to optimize the performance of their application codes. <p> Moreover, they expect the added components to integrate seamlessly with extant elements. 2.4 Pablo Software Overview The design of the Pablo performance analysis environment draws on the lessons learned from the design, implementation and use of two previous generations of performance analysis software <ref> [23, 26] </ref>. Chief among these were the importance of portability, scalability, and extensibility. One of our earlier performance environments, developed for the Intel iPSC/2 hypercube, included instrumentation of Intel's NX/2 operating system [34, 32] to record operating system calls, context switches, message passing activity, and application-specified data.
Reference: [24] <author> Malony, A. D., and Reed, D. A. </author> <title> A Hardware-Based Performance Monitor for the Intel iPSC/2 Hypercube. </title> <booktitle> In 1990 ACM International Conference on Supercomputing (June 1990), Association for Computing Machinery. </booktitle>
Reference-contexts: We also modified the Free Software Foundation's gcc compiler to emit application program code with embedded calls to the operating system instrumentation library [25]. In collaboration with Intel, we also developed prototype hardware to unobtrusively capture the operating system and application software instrumentation data <ref> [24] </ref>. Using performance data, we created a graphical data analysis and display environment that supported a fixed set of data reductions and a variety of graphical displays [26]. Users could choose from the cross product of data analyses and data displays. <p> Thus, it is imperative that the Pablo trace capture library provide some safeguards for data volume and accuracy. There are two possible techniques that can reduce event tracing overheads to acceptable levels. The first is to develop hardware that supports capture and recording of software-generated events <ref> [24, 12, 13, 29, 28] </ref>.
Reference: [25] <author> Malony, A. D., Reed, D. A., Arendt, J. W., Aydt, R. A., Grabas, D., and Totty, B. K. </author> <title> An Integrated Performance Data Collection Analysis, and Visualization System. </title> <booktitle> In Proceedings of the Fourth Conference on Hypercube Concurrent Computers and Applications (Monterey, </booktitle> <address> CA, </address> <month> Mar. </month> <year> 1989), </year> <institution> Association for Computing Machinery. </institution>
Reference-contexts: We also modified the Free Software Foundation's gcc compiler to emit application program code with embedded calls to the operating system instrumentation library <ref> [25] </ref>. In collaboration with Intel, we also developed prototype hardware to unobtrusively capture the operating system and application software instrumentation data [24]. Using performance data, we created a graphical data analysis and display environment that supported a fixed set of data reductions and a variety of graphical displays [26]. <p> Unfortunately, little is known about effective resource management for massively parallel systems, particularly in the context of a general purpose operating system. As a result of our earlier work <ref> [25] </ref> and that by NIST [28], the Paragon XP/S system contains hardware and software support for the real-time capture and extraction of performance data.
Reference: [26] <author> Malony, A. D., Reed, D. A., and Rudolph, D. C. </author> <title> Integrating Performance Data Collection, Analysis, and Visualization. In Parallel Computer Systems: Performance Instrumentation and Visualization, </title> <editor> M. Simmons, R. Koskela, and I. Bucher, Eds. </editor> <publisher> Addison-Wesley Publishing Company, </publisher> <year> 1990. </year>
Reference-contexts: If a tool's functionality is too limited, it will not be used. Conversely, if a tool is too general and does not support common cases in obvious ways, users will abandon it in frustration. Based on our experience designing, implementing and using two previous generations of performance analysis software <ref> [23, 26] </ref>, we believe there are three classes of potential performance 3 environment users: novice, intermediate, and expert. Novice users know relatively little about par-allel machine software or hardware, nor do they wish to learn more than the minimum necessary to optimize the performance of their application codes. <p> Moreover, they expect the added components to integrate seamlessly with extant elements. 2.4 Pablo Software Overview The design of the Pablo performance analysis environment draws on the lessons learned from the design, implementation and use of two previous generations of performance analysis software <ref> [23, 26] </ref>. Chief among these were the importance of portability, scalability, and extensibility. One of our earlier performance environments, developed for the Intel iPSC/2 hypercube, included instrumentation of Intel's NX/2 operating system [34, 32] to record operating system calls, context switches, message passing activity, and application-specified data. <p> In collaboration with Intel, we also developed prototype hardware to unobtrusively capture the operating system and application software instrumentation data [24]. Using performance data, we created a graphical data analysis and display environment that supported a fixed set of data reductions and a variety of graphical displays <ref> [26] </ref>. Users could choose from the cross product of data analyses and data displays. <p> In contrast, a performance trace data file typically contains many event types and thousands of data records of each type. The event records 9 As an example, the trace format for our earlier instrumentation system <ref> [26] </ref>, could only be interpreted using software-embedded knowledge of the Intel iPSC/2 message passing hardware and operating system software. 12 are often quite small, only a few tens or hundreds of bytes, with a mixture of integers, floating point values, and character strings; scalars are more common than vectors or arrays. <p> The details of file input/output, storage allocation, and module execution scheduling are isolated in the environment infrastructure, making it straightforward to extend the environment by adding new data transformation modules. This design and its emphasis on the absence of software embedded data semantics reflects our earlier experience <ref> [26] </ref> that most performance data analyses are simple transformations that do not require knowledge of the data source (e.g., a particular parallel programming model) or its higher level meaning (e.g., this data value is a context switch). <p> We plan to add display update controls, allowing users to throttle the graph execution rate to perceptually manageable levels. In addition to the actual display update rate, Heath's experience with the ParaGraph performance visualization system [14] and our own experience <ref> [26] </ref> suggest that users also wish to view periodic performance "snapshots" (i.e., they wish to see state of the graphical displays only at discrete, often widely separated, points in the trace data).
Reference: [27] <author> MIDI Manufacturers Association. </author> <title> MIDI Musical Instrument Digital Interface, Specification 1.0. </title> <booktitle> International MIDI Association, </booktitle> <address> Los Angeles, CA, </address> <year> 1988. </year>
Reference-contexts: A better alternative is instruments that conform to the Musical Interface Digital Interface 15 The computer music community has been exploring the mapping of data to sounds for over thirty years. 22 (MIDI) <ref> [27] </ref>. Using a variety of built-in synthesis techniques, most MIDI instruments can play notes in many voices (timbres), ranging from traditional voices like a piano or trumpet to novel sound effects. MIDI commands are just a few bytes long, so it is easy to control output in real-time.
Reference: [28] <author> Mink, A., and Carpenter, R. </author> <title> A VLSI Chip Set for a Mmultiprocessor Performance Measurement System. In Parallel Computing Systems: Performance Instrumentation and Visualization, </title> <editor> M. Simmons, R. Koskela, and I. Bucher, Eds. </editor> <publisher> Addison-Wesley Publishing Company, </publisher> <year> 1990. </year>
Reference-contexts: Thus, it is imperative that the Pablo trace capture library provide some safeguards for data volume and accuracy. There are two possible techniques that can reduce event tracing overheads to acceptable levels. The first is to develop hardware that supports capture and recording of software-generated events <ref> [24, 12, 13, 29, 28] </ref>. <p> Unfortunately, little is known about effective resource management for massively parallel systems, particularly in the context of a general purpose operating system. As a result of our earlier work [25] and that by NIST <ref> [28] </ref>, the Paragon XP/S system contains hardware and software support for the real-time capture and extraction of performance data.
Reference: [29] <author> Mink, A., Draper, J., Roberts, J., and Carpenter, R. </author> <title> Hardware Assisted Multi--processord Performance Measurements. </title> <booktitle> In Proceedings of the 12th IFIP Working Group 7.3 International Symposium on Performance: Performance 87 (Brussels, </booktitle> <address> Belgium, </address> <month> Dec. </month> <year> 1987), </year> <pages> pp. 151-168. </pages>
Reference-contexts: Thus, it is imperative that the Pablo trace capture library provide some safeguards for data volume and accuracy. There are two possible techniques that can reduce event tracing overheads to acceptable levels. The first is to develop hardware that supports capture and recording of software-generated events <ref> [24, 12, 13, 29, 28] </ref>.
Reference: [30] <author> NCSA. </author> <note> NCSA HDF, Version 2.0. </note> <institution> University of Illinois at Urbana-Champaign, National Center for Supercomputing Applications, </institution> <month> Feb. </month> <year> 1989. </year>
Reference-contexts: Previously developed self-describing data formats such as the Hierarchical Data Format (HDF) <ref> [30] </ref> from NCSA and netCDF [33] from UCAR have been very successful. However, the scientific and graphical data sets supported by HDF and netCDF usually consist of a small number of large records, often containing arrays of floating point data.
Reference: [31] <author> Rabenhorst, D. A., Farrell, E. J., Jameson, D. H., Linton, T. D., and Mandel-man, J. A. </author> <title> Complementary Visualization and Sonification of Multi-Dimensional Data. </title> <booktitle> In Proceedings of the SPIE, Conference 1259, Extracting Meaning from Complex Data: Processing, Display, Interaction (1990). </booktitle>
Reference-contexts: However, like visualization and graphics, sonification and music differ in important ways; sonification idioms are only beginning to emerge. As examples, Scaletti [35], Rabenhorst et al <ref> [31] </ref>, and Francioni [11] have begun exploring the use of new idioms and abstractions for mapping data to sound. Francioni's work [11] is most relevant to our research goals, as it concerns the mapping of parallel computer system performance data to synthesized sound.
Reference: [32] <author> Reed, D. A., and Rudolph, D. C. </author> <title> Experiences with Hypercube Operating System Instrumentation. </title> <note> International Journal of High-Speed Computing (Dec. </note> <year> 1989), </year> <pages> 517-542. </pages>
Reference-contexts: Chief among these were the importance of portability, scalability, and extensibility. One of our earlier performance environments, developed for the Intel iPSC/2 hypercube, included instrumentation of Intel's NX/2 operating system <ref> [34, 32] </ref> to record operating system calls, context switches, message passing activity, and application-specified data. We also modified the Free Software Foundation's gcc compiler to emit application program code with embedded calls to the operating system instrumentation library [25]. <p> On a distributed memory parallel system with hundreds or thousands of processors, the size of an event trace file can quickly reach many gigabytes <ref> [32] </ref>. To gain insight from this data and to tune both system and application software, the data must be presented in ways that not only show trends but also allow detailed exploration of small scale behavior.
Reference: [33] <author> Rew, R. K. </author> <note> netCDF User's Guide, Version 1.0. </note> <institution> Unidata Program Center, University Corporation for Atmospheric Research, </institution> <month> Apr. </month> <year> 1989. </year>
Reference-contexts: Previously developed self-describing data formats such as the Hierarchical Data Format (HDF) [30] from NCSA and netCDF <ref> [33] </ref> from UCAR have been very successful. However, the scientific and graphical data sets supported by HDF and netCDF usually consist of a small number of large records, often containing arrays of floating point data.
Reference: [34] <author> Rudolph, D. C., and Reed, D. A. </author> <title> CRYSTAL: Operating System Instrumentation for the Intel iPSC/2. </title> <booktitle> In Proceedings of the Fourth Conference on Hypercube Concurrent Computers and Applications (Monterey, </booktitle> <address> CA, </address> <month> Mar. </month> <year> 1989). </year>
Reference-contexts: Chief among these were the importance of portability, scalability, and extensibility. One of our earlier performance environments, developed for the Intel iPSC/2 hypercube, included instrumentation of Intel's NX/2 operating system <ref> [34, 32] </ref> to record operating system calls, context switches, message passing activity, and application-specified data. We also modified the Free Software Foundation's gcc compiler to emit application program code with embedded calls to the operating system instrumentation library [25].
Reference: [35] <author> Scaletti, C., and Craig, A. B. </author> <title> Using Sound to Extract Meaning from Complex Data. </title> <booktitle> In Proceedings of the SPIE, Conference 1459, Extracting Meaning from Complex Data: Processing, Display, </booktitle> <address> Interaction II (San Jose, CA, </address> <year> 1991). </year>
Reference-contexts: However, like visualization and graphics, sonification and music differ in important ways; sonification idioms are only beginning to emerge. As examples, Scaletti <ref> [35] </ref>, Rabenhorst et al [31], and Francioni [11] have begun exploring the use of new idioms and abstractions for mapping data to sound. Francioni's work [11] is most relevant to our research goals, as it concerns the mapping of parallel computer system performance data to synthesized sound.
Reference: [36] <author> Shields, K. A. </author> <title> iPablo User's Guide. </title> <type> Tech. rep., </type> <institution> University of Illinois at Urbana-Champaign, Department of Computer Science, </institution> <month> Nov. </month> <year> 1992. </year>
Reference-contexts: The Pablo graphical instrumentation interface reduces the intellectual cost of source code instrumentation by allowing one to interactively specify the desired instrumentation <ref> [36] </ref>. These instrumentation directives can be global (e.g., trace calls to all procedures) or selective (e.g., count the calls to this procedure or trace only this specific procedure call). As noted in x3, the graphical instrumentation interface passes instrumentation specifications to a instrumentation parser that synthesizes instrumented application code. <p> the Motif menu bar, the list of instrumentable procedures contained in or called from the currently loaded source code file, the scrollable source code window that highlights the 7 Space restrictions preclude a complete description of all the instrumentation options supported by the iPablo instrumentation interface; for complete details see <ref> [36] </ref>. 10 instrumentable source code constructs, and the source code line instrumentation buttons at the bottom of the window.
Reference: [37] <author> Stardent Computer, Inc. </author> <title> Application Visualization System, User's Guide, </title> <year> 1989. </year>
Reference-contexts: As exemplars of common, massively parallel architectures, availability of software performance instrumentation for these machines will aid a large and growing user community. The performance analysis component of Pablo consists of a set of data transformation modules that can be graphically interconnected, in the style of aPE or AVS <ref> [37] </ref>, to form an acyclic, directed data analysis graph. Performance data flows through the graph nodes and is transformed to yield the desired performance metrics. <p> The Pablo data analysis environment supports the graphical interconnection of performance data transformation modules, in the style of aPE [9] or AVS <ref> [37] </ref>, to form a directed, 14 acyclic data analysis graph. Performance data flows through the configured graph nodes and is transformed to yield the desired performance metrics. <p> Couch's Seecube performance environment [6], the aPE visualization system [9], originally developed at the Ohio State Supercomputer Center, and the University of New Mexico Khoros image processing system [40] are well-known research implementations of such systems. The AVS visualization system <ref> [37] </ref> and Silicon Graphics' Explorer system are successful examples in the commercial arena. The wide acceptance of these systems suggests that users find the graphical construction of coarse-grained data flow graphs intuitive; the graphical interface provides the desired flexibility without introducing overwhelming complexity.
Reference: [38] <author> Stunkel, C. B., Fuchs, W. K., Rudolph, D. C., and Reed, D. A. </author> <note> Linear Optimization: </note>
Reference-contexts: Users could choose from the cross product of data analyses and data displays. Although this environment proved useful in studying the performance of both parallel applications <ref> [38, 18] </ref> and the Intel iPSC/2's parallel file system [1], the dependence of performance data capture on modifications to a proprietary operating system precluded both wide distribution and porting to new architectures.
References-found: 38

