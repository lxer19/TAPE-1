URL: http://www.cs.utexas.edu/users/rdb/papers/UTCSTR-98-13.ps.gz
Refering-URL: http://www.cs.utexas.edu/users/cilk/papers.html
Root-URL: 
Email: frdb,dionisisg@cs.utexas.edu  
Title: The Performance of Work Stealing in Multiprogrammed Environments  
Author: Robert D. Blumofe Dionisios Papadopoulos 
Date: May 28, 1998  
Address: Austin  
Affiliation: Department of Computer Sciences, The University of Texas at  
Abstract: We study the performance of user-level thread schedulers in multiprogrammed environments. Our goal is a user-level thread scheduler that delivers efficient performance under multiprogramming without any need for kernel-level resource management, such as coscheduling or process control. We show that a non-blocking implementation of the work-stealing algorithm achieves this goal. With this implementation, the execution time of a computation running with arbitrarily many processes on arbitrarily many processors can be modeled as a simple function of work and critical-path length. This model holds even when the processes run on a set of processors that arbitrarily grows and shrinks over time. We observe linear speedup whenever the number of processes is small relative to the average parallelism.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Juan Alemany and Edward W. Felton. </author> <title> Performance issues in non-blocking synchronization on shared-memory multiprocessors. </title> <booktitle> In Proceedings of the Eleventh Annual ACM Symposium on Principles of Distributed Computing (PODC), </booktitle> <pages> pages 125134, </pages> <address> Vancouver, British Columbia, Canada, </address> <month> August </month> <year> 1992. </year>
Reference-contexts: In comparison with our exclusively user-level implementation of work stealing, we expect that such kernel-level support admits a simpler implementation, with efficient performance under multiprogramming, through the use of preemption-safe locking <ref> [1, 13, 37] </ref>. Nevertheless, we have shown that such kernel support is not necessary to achieve our goals. Kernel-level support does have other benefits, however, notably the ability to make system calls non-blocking. <p> In addition, we shall not consider preemption-safe locking <ref> [1, 5, 13, 33, 37] </ref>, because it requires non-traditional kernel support. In particular, it requires either that the kernel does not preempt processes while they hold locks or that the kernel informs processes of impending preemptions. applications and for each of our three alternative work-stealing implementations.
Reference: [2] <author> James H. Anderson and Mark Moir. </author> <title> Universal constructions for multi-object operations. </title> <booktitle> In Proceedings of the 14th Annual ACM Symposium on Principles of Distributed Computing (PODC), </booktitle> <pages> pages 184193, </pages> <address> Ottawa, Canada, </address> <month> August </month> <year> 1995. </year>
Reference-contexts: The first provably efficient work-stealing algorithm [15] and implementation [14] is fairly recent, however. The idea of non-blocking and wait-free synchronization was developed by Herlihy [29]. There has been a long line of work attempting to make the idea more practical via universal constructions [11, 28], useful primitives <ref> [2, 3, 39] </ref>, and specific data objects [3, 36, 45]. In fact, our non-blocking implementation of work stealing uses the bounded-tags technique of [39]. Nevertheless, to this day, few applications or systems have been built with non-blocking synchronization.
Reference: [3] <author> James H. Anderson, Srikanth Ramamurthy, and Rohit Jain. </author> <title> Implementing wait-free objects on priority-based systems. </title> <booktitle> In Proceedings of the Sixteenth ACM Symposium on Principles of Distributed Computing (PODC), </booktitle> <address> Santa Barbara, California, </address> <month> August </month> <year> 1997. </year>
Reference-contexts: The first provably efficient work-stealing algorithm [15] and implementation [14] is fairly recent, however. The idea of non-blocking and wait-free synchronization was developed by Herlihy [29]. There has been a long line of work attempting to make the idea more practical via universal constructions [11, 28], useful primitives <ref> [2, 3, 39] </ref>, and specific data objects [3, 36, 45]. In fact, our non-blocking implementation of work stealing uses the bounded-tags technique of [39]. Nevertheless, to this day, few applications or systems have been built with non-blocking synchronization. <p> The idea of non-blocking and wait-free synchronization was developed by Herlihy [29]. There has been a long line of work attempting to make the idea more practical via universal constructions [11, 28], useful primitives [2, 3, 39], and specific data objects <ref> [3, 36, 45] </ref>. In fact, our non-blocking implementation of work stealing uses the bounded-tags technique of [39]. Nevertheless, to this day, few applications or systems have been built with non-blocking synchronization.
Reference: [4] <author> Thomas E. Anderson. </author> <title> The performance of spin lock alternatives for shared-memory multiprocessors. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 1(1):616, </volume> <month> January </month> <year> 1990. </year>
Reference-contexts: Our blocking-lock implementation uses the Solaris thread library. A lock is a mutex t, and the lock is operated upon with the mutex lock and mutex unlock calls. Many other and more sophisticated locking strategies are known <ref> [4, 24, 30] </ref>, but we do not consider them. One advantage of some of these strategies is that they perform well under high contention. In our case, each process has its own deque and contention arises only due to thieves, who steal at random.
Reference: [5] <author> Thomas E. Anderson, Brian N. Bershad, Edward D. Lazowska, and Henry M. Levy. </author> <title> Scheduler activations: Effective kernel support for the user-level management of parallelism. </title> <booktitle> In Proceedings of the Thirteenth ACM Symposium on Operating Systems Principles (SOSP), </booktitle> <pages> pages 95109, </pages> <address> Pacific Grove, California, </address> <month> October </month> <year> 1991. </year>
Reference-contexts: With no blocking, processes typically run for their full quantum, so the cost of cache warmup can be amortized over a long run. As another alternative to kernel-level resource management, first-class user-level threads [33] and sched-uler activations <ref> [5] </ref> are kernel-level mechanisms that support efficient multiprogramming with user-level threads, independent of any particular kernel-level resource-management policy. <p> In addition, we shall not consider preemption-safe locking <ref> [1, 5, 13, 33, 37] </ref>, because it requires non-traditional kernel support. In particular, it requires either that the kernel does not preempt processes while they hold locks or that the kernel informs processes of impending preemptions. applications and for each of our three alternative work-stealing implementations.
Reference: [6] <author> Thomas E. Anderson, Edward D. Lazowska, and Henry M. Levy. </author> <title> The performance implications of thread management alternatives for shared-memory multiprocessors. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 38(12):1631 1644, </volume> <month> December </month> <year> 1989. </year>
Reference-contexts: Focusing on the scheduler implementation, we shall make quantitative comparisons of (computational) speedup and only make qualitative comparisons of overhead. Our implementations are replete with instrumentation, and in order to keep the implementations simple, we have not employed many of the known mechanisms <ref> [6, 23, 38] </ref> for keeping the overhead low. For this reason, a quantitative comparison of the overhead for our three alternative implementations would be meaningless. We cannot, however, ignore overhead.
Reference: [7] <author> Thomas E. Anderson, Henry M. Levy, Brian N. Bershad, and Edward D. Lazowska. </author> <title> The interaction of archi tecture and operating system design. </title> <booktitle> In Proceedings of the Fourth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS), </booktitle> <pages> pages 108120, </pages> <address> Santa Clara, Califor-nia, </address> <month> April </month> <year> 1991. </year>
Reference-contexts: Similar numbers were counted for the other applications. In addition to the frequent context switches, blocking locks have a very high overhead. Locking and unlocking requires calls into the kernel that are expensive, and this overhead is only expected to get worse for the foreseeable future <ref> [7] </ref>. This overhead will be present in any implementation of locks that admit blocking in the kernel. A hybrid spin-then-block lock can reduce the number of context switches [18], but it still requires kernel support for blocking.
Reference: [8] <author> Ken Arnold and James Gosling. </author> <title> The Java Programming Language. </title> <publisher> Addison-Wesley, </publisher> <year> 1996. </year>
Reference-contexts: Such a scheduler could be employed by a parallelizing compiler, or the runtime system for a multithreaded language such as Cilk [14] or Java <ref> [8] </ref>. 1.1 The problem with static partitioning Before considering dynamic thread scheduling, we first review a well-known performance anomaly that occurs when parallel programs use a static partitioning of the work [31, pages 284285].
Reference: [9] <author> Nimar S. Arora, Robert D. Blumofe, and C. Greg Plaxton. </author> <title> Thread scheduling for multiprogrammed multipro cessors. </title> <booktitle> In Proceedings of the Tenth Annual ACM Symposium on Parallel Algorithms and Architectures (SPAA), </booktitle> <address> Puerto Vallarta, Mexico, </address> <month> June </month> <year> 1998. </year>
Reference-contexts: In fact, this performance model is based on an analytical bound that we have proven to hold in a model where the kernel-level scheduling is actually performed by an adversary <ref> [9] </ref>. Thus, our model is extraordinarily robust. We shall restrict attention to shared-memory multiprocessors, and all experiments are performed on a Sun Ultra Enterprise 5000 with 8 167-Mhz UltraSPARC processors running Solaris 2.5.1. <p> In this section, we review the work-stealing algorithm, and we state the proven performance bounds. In addition, we describe the non-blocking implementation of this algorithm <ref> [9] </ref>. <p> In the non-blocking work stealer, the deques are implemented with non-blocking synchronization. That is, instead of using mutual exclusion, we use powerful atomic instructions, notably the SPARC v9 casxa (64-bit compare-and-swap) instruction. A complete description of this implementation can be found in <ref> [9] </ref>. This implementation is non-blocking, as opposed to wait-free [29], meaning that it is possible for a process to starve in its attempt to perform a deque operation. Livelock, however, cannot occur because if one process starves, then others must be making progress. <p> Livelock, however, cannot occur because if one process starves, then others must be making progress. It turns out that wait-freedom is not needed to prove our analytical result <ref> [9] </ref> as stated in Section 5 the non-blocking property is sufficient. In addition to the non-blocking deque implementation, the non-blocking work stealer also makes judicious use of yields. Each process makes system calls to yield the processor between consecutive steal attempts. <p> The analytical result <ref> [9] </ref> states that for any number P of processes, the execution time T P is given by where T 1 is the work of the computation, T 1 is the critical-path length of the computation, and P A is the time-average number of processors that actually execute the computation.
Reference: [10] <author> Remzi H. Arpaci, Andrea C. Dusseau, Amin M. Vahdat, Lok T. Liu, Thomas E. Anderson, and David A. Patter son. </author> <title> The interaction of parallel and sequential workloads on a network of workstations. </title> <booktitle> In Proceedings of the 1995 ACM SIGMETRICS Conference on the Measurement and Modeling of Computer Systems, </booktitle> <pages> pages 267278, </pages> <address> Ottawa, Canada, </address> <month> May </month> <year> 1995. </year>
Reference-contexts: Similarly, users expect multiprocessor compute servers to support multiprogrammed work loads that include parallel applications. Unfortunately, unless parallel applications are coscheduled [40] or subject to process control [44], they display poor performance in such multiprogrammed environments <ref> [10, 17, 18, 19, 26] </ref>. As an alternative to coscheduling or process control, in this paper we investigate the use of dynamic, user-level, thread scheduling in order to achieve efficient performance under multiprogramming. <p> A number of studies have compared various process-scheduling strategies, and all have concluded that the traditional time-sharing, priority-based local scheduler found in most operating systems is inadequate <ref> [10, 17, 18, 19, 26] </ref>. In addition, all of these studies have concluded that some form of coscheduling or space partitioning with process control offers the best solution.
Reference: [11] <author> Greg Barnes. </author> <title> A method for implementing lock-free shared data structures. </title> <booktitle> In Proceedings of the Fifth Annual ACM Symposium on Parallel Algorithms and Architectures (SPAA), </booktitle> <pages> pages 261270, </pages> <address> Velen, Germany, </address> <month> June </month> <year> 1993. </year>
Reference-contexts: The first provably efficient work-stealing algorithm [15] and implementation [14] is fairly recent, however. The idea of non-blocking and wait-free synchronization was developed by Herlihy [29]. There has been a long line of work attempting to make the idea more practical via universal constructions <ref> [11, 28] </ref>, useful primitives [2, 3, 39], and specific data objects [3, 36, 45]. In fact, our non-blocking implementation of work stealing uses the bounded-tags technique of [39]. Nevertheless, to this day, few applications or systems have been built with non-blocking synchronization.
Reference: [12] <author> J. Barnes and P. Hut. </author> <title> A hierarchical O(N log N ) force-calculation algorithm. </title> <booktitle> Nature, </booktitle> <address> 324:446449, </address> <year> 1986. </year>
Reference-contexts: Each block is of size 16 fi 16. lu (n) Compute LU-decomposition without pivoting of a dense nfin matrix of doubles using a blocked data layout. Each block is of size 16 fi 16. barnes (n; s) Run Barnes-Hut n-body simulation <ref> [12] </ref> on n bodies for s time steps.
Reference: [13] <author> Brian N. Bershad. </author> <title> Practical considerations for non-blocking concurrent objects. </title> <booktitle> In Proceedings of the 13th International Conference on Distributed Computing Systems (ICDCS), </booktitle> <month> May </month> <year> 1993. </year>
Reference-contexts: In comparison with our exclusively user-level implementation of work stealing, we expect that such kernel-level support admits a simpler implementation, with efficient performance under multiprogramming, through the use of preemption-safe locking <ref> [1, 13, 37] </ref>. Nevertheless, we have shown that such kernel support is not necessary to achieve our goals. Kernel-level support does have other benefits, however, notably the ability to make system calls non-blocking. <p> In addition, we shall not consider preemption-safe locking <ref> [1, 5, 13, 33, 37] </ref>, because it requires non-traditional kernel support. In particular, it requires either that the kernel does not preempt processes while they hold locks or that the kernel informs processes of impending preemptions. applications and for each of our three alternative work-stealing implementations.
Reference: [14] <author> Robert D. Blumofe, Christopher F. Joerg, Bradley C. Kuszmaul, Charles E. Leiserson, Keith H. Randall, and Yuli Zhou. Cilk: </author> <title> An efficient multithreaded runtime system. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 37(1):5569, </volume> <month> August </month> <year> 1996. </year>
Reference-contexts: Such a scheduler could be employed by a parallelizing compiler, or the runtime system for a multithreaded language such as Cilk <ref> [14] </ref> or Java [8]. 1.1 The problem with static partitioning Before considering dynamic thread scheduling, we first review a well-known performance anomaly that occurs when parallel programs use a static partitioning of the work [31, pages 284285]. <p> The idea of work stealing goes back to 1981 [16] and has been used in many systems and applications since [20, 21, 27, 42, 46]. The first provably efficient work-stealing algorithm [15] and implementation <ref> [14] </ref> is fairly recent, however. The idea of non-blocking and wait-free synchronization was developed by Herlihy [29]. There has been a long line of work attempting to make the idea more practical via universal constructions [11, 28], useful primitives [2, 3, 39], and specific data objects [3, 36, 45]. <p> Nevertheless, to this day, few applications or systems have been built with non-blocking synchronization. Of notable exception is a study of non-blocking applications [37] and two non-blocking operating-system kernels [25, 34]. 3 Work stealing The work-stealing algorithm dynamically assigns threads to processes for execution in a provably efficient manner <ref> [14, 15] </ref>. In this section, we review the work-stealing algorithm, and we state the proven performance bounds. In addition, we describe the non-blocking implementation of this algorithm [9]. <p> Work-stealing versions for all of these applications are built on top of our Hood library, which is in turn built on top of the Solaris thread library. <ref> [14] </ref> states that this constant factor is quite small. <p> Hood supports the abstraction of user-level threads, and it schedules those threads onto processes using the non-blocking work stealer. Hood has been instrumented to measure work and critical-path length. The work is measured by adding up the elapsed time over each thread dispatch. Critical-path length is measured by timestamping <ref> [14] </ref>. Many other statistics are also collected and made available. To simplify the implementation, the current version of Hood supports run-to-completion threads only. Threads cannot use synchronization variables such as locks, condition variables, and semaphores. <p> First, the cost of these system calls does not show up as overhead T 1 =T s , because a 1-process execution never steals and consequently, never performs either of these system calls. Second, we know from prior analytical and empirical work <ref> [14, 15] </ref> that the number of steals per process grows at most linearly with the critical-path length T 1 and is independent of the amount of work T 1 . <p> For future parallel applications, we hope to make the use of our non-blocking work stealer more attractive. We plan to add synchronization variables to our Hood implementation, and we plan to build this scheduler into the runtime system for the Cilk multithreaded language <ref> [14] </ref>. In addition, we plan to port Hood to other platforms. The SPARC v9 casa and casxa instructions are easily replaced with the load-linked and store-conditional pair found in many other processor instruction sets.
Reference: [15] <author> Robert D. Blumofe and Charles E. Leiserson. </author> <title> Scheduling multithreaded computations by work stealing. </title> <booktitle> In Proceedings of the 35th Annual Symposium on Foundations of Computer Science (FOCS), </booktitle> <pages> pages 356368, </pages> <address> Santa Fe, New Mexico, </address> <month> November </month> <year> 1994. </year> <month> 18 </month>
Reference-contexts: As an alternative to coscheduling or process control, in this paper we investigate the use of dynamic, user-level, thread scheduling in order to achieve efficient performance under multiprogramming. We show that a non-blocking implementation of the well-known and provably efficient work-stealing scheduling algorithm <ref> [15] </ref> delivers efficient performance under multiprogramming. Moreover, we develop and evaluate a simple performance model based on work and critical-path length that characterizes accurately the performance of parallel applications that use this non-blocking work stealer. <p> The idea of work stealing goes back to 1981 [16] and has been used in many systems and applications since [20, 21, 27, 42, 46]. The first provably efficient work-stealing algorithm <ref> [15] </ref> and implementation [14] is fairly recent, however. The idea of non-blocking and wait-free synchronization was developed by Herlihy [29]. <p> Nevertheless, to this day, few applications or systems have been built with non-blocking synchronization. Of notable exception is a study of non-blocking applications [37] and two non-blocking operating-system kernels [25, 34]. 3 Work stealing The work-stealing algorithm dynamically assigns threads to processes for execution in a provably efficient manner <ref> [14, 15] </ref>. In this section, we review the work-stealing algorithm, and we state the proven performance bounds. In addition, we describe the non-blocking implementation of this algorithm [9]. <p> The ratio T 1 =T 1 is called the average parallelism. Given any multithreaded computation with work T 1 and critical-path length T 1 , we have the following results. The analytical result <ref> [15] </ref> states that for any number P of processes running on P A = P dedicated processors, the expected execution time T P is given by T P = O (T 1 =P + T 1 ) : (1) Note that because T 1 =P and T 1 are both lower <p> First, the cost of these system calls does not show up as overhead T 1 =T s , because a 1-process execution never steals and consequently, never performs either of these system calls. Second, we know from prior analytical and empirical work <ref> [14, 15] </ref> that the number of steals per process grows at most linearly with the critical-path length T 1 and is independent of the amount of work T 1 .
Reference: [16] <author> F. Warren Burton and M. Ronan Sleep. </author> <title> Executing functional programs on a virtual tree of processors. </title> <booktitle> In Proceedings of the 1981 Conference on Functional Programming Languages and Computer Architecture, </booktitle> <pages> pages 187194, </pages> <address> Portsmouth, New Hampshire, </address> <month> October </month> <year> 1981. </year>
Reference-contexts: Finally, we point out that our use of work stealing and non-blocking synchronization builds upon a long history in both areas, though they did not meet until now. The idea of work stealing goes back to 1981 <ref> [16] </ref> and has been used in many systems and applications since [20, 21, 27, 42, 46]. The first provably efficient work-stealing algorithm [15] and implementation [14] is fairly recent, however. The idea of non-blocking and wait-free synchronization was developed by Herlihy [29].
Reference: [17] <author> Mark Crovella, Prakash Das, Czarek Dubnicki, Thomas LeBlanc, and Evangelos Markatos. </author> <title> Multiprogramming on multiprocessors. </title> <booktitle> In Proceedings of the Third IEEE Symposium on Parallel and Distributed Processing, </booktitle> <month> December </month> <year> 1991. </year>
Reference-contexts: Similarly, users expect multiprocessor compute servers to support multiprogrammed work loads that include parallel applications. Unfortunately, unless parallel applications are coscheduled [40] or subject to process control [44], they display poor performance in such multiprogrammed environments <ref> [10, 17, 18, 19, 26] </ref>. As an alternative to coscheduling or process control, in this paper we investigate the use of dynamic, user-level, thread scheduling in order to achieve efficient performance under multiprogramming. <p> A number of studies have compared various process-scheduling strategies, and all have concluded that the traditional time-sharing, priority-based local scheduler found in most operating systems is inadequate <ref> [10, 17, 18, 19, 26] </ref>. In addition, all of these studies have concluded that some form of coscheduling or space partitioning with process control offers the best solution.
Reference: [18] <author> Andrea C. Dusseau, Remzi H. Arpaci, and David E. Culler. </author> <title> Effective distributed scheduling of parallel work loads. </title> <booktitle> In Proceedings of the ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems, </booktitle> <pages> pages 2536, </pages> <address> Philadelphia, Pennsylvania, </address> <month> May </month> <year> 1996. </year>
Reference-contexts: Similarly, users expect multiprocessor compute servers to support multiprogrammed work loads that include parallel applications. Unfortunately, unless parallel applications are coscheduled [40] or subject to process control [44], they display poor performance in such multiprogrammed environments <ref> [10, 17, 18, 19, 26] </ref>. As an alternative to coscheduling or process control, in this paper we investigate the use of dynamic, user-level, thread scheduling in order to achieve efficient performance under multiprogramming. <p> A number of studies have compared various process-scheduling strategies, and all have concluded that the traditional time-sharing, priority-based local scheduler found in most operating systems is inadequate <ref> [10, 17, 18, 19, 26] </ref>. In addition, all of these studies have concluded that some form of coscheduling or space partitioning with process control offers the best solution. <p> Interestingly, it has been shown recently that coscheduling can be achieved implicitly with little or no modification to existing kernel schedulers <ref> [18, 43] </ref>. The main advantage of coscheduling over our approach is that coscheduling may be able to achieve superlinear speedup due to caching effects. We discuss this issue in more detail in Section 7. <p> This overhead will be present in any implementation of locks that admit blocking in the kernel. A hybrid spin-then-block lock can reduce the number of context switches <ref> [18] </ref>, but it still requires kernel support for blocking. In contrast to the priocntl and yield system calls in the (non-naive) non-blocking implementation, the use of blocking locks violates the work-first design principle [22], and the overhead cannot be hidden.
Reference: [19] <author> Dror G. Feitelson and Larry Rudolph. </author> <title> Coscheduling based on runtime identification of activity working sets. </title> <journal> International Journal of Parallel Programming, </journal> <volume> 23(2):135160, </volume> <month> April </month> <year> 1995. </year>
Reference-contexts: Similarly, users expect multiprocessor compute servers to support multiprogrammed work loads that include parallel applications. Unfortunately, unless parallel applications are coscheduled [40] or subject to process control [44], they display poor performance in such multiprogrammed environments <ref> [10, 17, 18, 19, 26] </ref>. As an alternative to coscheduling or process control, in this paper we investigate the use of dynamic, user-level, thread scheduling in order to achieve efficient performance under multiprogramming. <p> A number of studies have compared various process-scheduling strategies, and all have concluded that the traditional time-sharing, priority-based local scheduler found in most operating systems is inadequate <ref> [10, 17, 18, 19, 26] </ref>. In addition, all of these studies have concluded that some form of coscheduling or space partitioning with process control offers the best solution.
Reference: [20] <author> Raphael Finkel and Udi Manber. </author> <title> DIBa distributed implementation of backtracking. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 9(2):235256, </volume> <month> April </month> <year> 1987. </year>
Reference-contexts: Finally, we point out that our use of work stealing and non-blocking synchronization builds upon a long history in both areas, though they did not meet until now. The idea of work stealing goes back to 1981 [16] and has been used in many systems and applications since <ref> [20, 21, 27, 42, 46] </ref>. The first provably efficient work-stealing algorithm [15] and implementation [14] is fairly recent, however. The idea of non-blocking and wait-free synchronization was developed by Herlihy [29].
Reference: [21] <author> Vincent W. Freeh, David K. Lowenthal, and Gregory R. Andrews. </author> <title> Distributed Filaments: Efficient fine-grain parallelism on a cluster of workstations. </title> <booktitle> In Proceedings of the First Symposium on Operating Systems Design and Implementation, pages 201213, </booktitle> <address> Monterey, California, </address> <month> November </month> <year> 1994. </year>
Reference-contexts: Finally, we point out that our use of work stealing and non-blocking synchronization builds upon a long history in both areas, though they did not meet until now. The idea of work stealing goes back to 1981 [16] and has been used in many systems and applications since <ref> [20, 21, 27, 42, 46] </ref>. The first provably efficient work-stealing algorithm [15] and implementation [14] is fairly recent, however. The idea of non-blocking and wait-free synchronization was developed by Herlihy [29].
Reference: [22] <author> Matteo Frigo, Charles E. Leiserson, and Keith H. Randall. </author> <booktitle> The implementation of the Cilk-5 multithreaded language. In Proceedings of the 1998 ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI), </booktitle> <address> Montreal, Canada, </address> <month> June </month> <year> 1998. </year>
Reference-contexts: Given the heavy cost of priocntl and yield system calls, it may come as a bit of a surprise that the non-blocking work stealer produces linear application speedup. An example of the work-first design principle <ref> [22] </ref>, the key to this performance is the fact that these system calls occur only when a process is stealing, and this has two important consequences. <p> A hybrid spin-then-block lock can reduce the number of context switches [18], but it still requires kernel support for blocking. In contrast to the priocntl and yield system calls in the (non-naive) non-blocking implementation, the use of blocking locks violates the work-first design principle <ref> [22] </ref>, and the overhead cannot be hidden. In a user-level thread scheduler, we do not want to go into the kernel every time we schedule a thread.
Reference: [23] <author> Seth Copen Goldstein, Klaus Erik Schauser, and David E. Culler. </author> <title> Lazy threads: Implementing a fast parallel call. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 37(1):520, </volume> <month> August </month> <year> 1996. </year>
Reference-contexts: Focusing on the scheduler implementation, we shall make quantitative comparisons of (computational) speedup and only make qualitative comparisons of overhead. Our implementations are replete with instrumentation, and in order to keep the implementations simple, we have not employed many of the known mechanisms <ref> [6, 23, 38] </ref> for keeping the overhead low. For this reason, a quantitative comparison of the overhead for our three alternative implementations would be meaningless. We cannot, however, ignore overhead.
Reference: [24] <author> Gary Graunke and Shreekant Thakkar. </author> <title> Synchronization algorithms for shared-memory multiprocessors. </title> <journal> IEEE Computer, </journal> <volume> 23(6):6069, </volume> <month> June </month> <year> 1990. </year>
Reference-contexts: Our blocking-lock implementation uses the Solaris thread library. A lock is a mutex t, and the lock is operated upon with the mutex lock and mutex unlock calls. Many other and more sophisticated locking strategies are known <ref> [4, 24, 30] </ref>, but we do not consider them. One advantage of some of these strategies is that they perform well under high contention. In our case, each process has its own deque and contention arises only due to thieves, who steal at random.
Reference: [25] <author> Michael Greenwald and David Cheriton. </author> <title> The synergy between non-blocking synchronization and operating system structure. </title> <booktitle> In Proceedings of the Second USENIX Symposium on Operating Systems Design and Implementation (OSDI), </booktitle> <pages> pages 123136, </pages> <address> Seattle, Washington, </address> <month> October </month> <year> 1996. </year>
Reference-contexts: In fact, our non-blocking implementation of work stealing uses the bounded-tags technique of [39]. Nevertheless, to this day, few applications or systems have been built with non-blocking synchronization. Of notable exception is a study of non-blocking applications [37] and two non-blocking operating-system kernels <ref> [25, 34] </ref>. 3 Work stealing The work-stealing algorithm dynamically assigns threads to processes for execution in a provably efficient manner [14, 15]. In this section, we review the work-stealing algorithm, and we state the proven performance bounds. In addition, we describe the non-blocking implementation of this algorithm [9].
Reference: [26] <author> Anoop Gupta, Andrew Tucker, and Shigeru Urushibara. </author> <title> The impact of operating system scheduling policies and synchronization methods on the performance of parallel applications. </title> <booktitle> In Proceedings of the 1991 ACM SIGMETRICS Conference on Measurement and Modeling of Computer Systems, </booktitle> <month> May </month> <year> 1991. </year>
Reference-contexts: Similarly, users expect multiprocessor compute servers to support multiprogrammed work loads that include parallel applications. Unfortunately, unless parallel applications are coscheduled [40] or subject to process control [44], they display poor performance in such multiprogrammed environments <ref> [10, 17, 18, 19, 26] </ref>. As an alternative to coscheduling or process control, in this paper we investigate the use of dynamic, user-level, thread scheduling in order to achieve efficient performance under multiprogramming. <p> In addition, we briefly discuss prior work on non-blocking synchronization and thread scheduling, upon which our implementation has been built. Much prior work on multiprogramming multiprocessors has focused on the management and scheduling of kernel-level resources, specifically processes <ref> [26, 32, 35, 40, 41, 44, 47] </ref>. A number of studies have compared various process-scheduling strategies, and all have concluded that the traditional time-sharing, priority-based local scheduler found in most operating systems is inadequate [10, 17, 18, 19, 26]. <p> A number of studies have compared various process-scheduling strategies, and all have concluded that the traditional time-sharing, priority-based local scheduler found in most operating systems is inadequate <ref> [10, 17, 18, 19, 26] </ref>. In addition, all of these studies have concluded that some form of coscheduling or space partitioning with process control offers the best solution. <p> This type of behavior will be seen in any implementation of spinning locks, no matter how clever it is in dealing with contention. This problem is well known <ref> [26] </ref> and traditionally is fixed by using blocking locks, and as we see in lock and then gets preempted by the kernel scheduler, then when other processes go to acquire that lock, they will be put to sleep by the kernel scheduler, thereby freeing up their processors so that the holding
Reference: [27] <author> Robert H. Halstead, Jr. </author> <title> Implementation of Multilisp: Lisp on a multiprocessor. </title> <booktitle> In Conference Record of the 1984 ACM Symposium on Lisp and Functional Programming, </booktitle> <pages> pages 917, </pages> <address> Austin, Texas, </address> <month> August </month> <year> 1984. </year>
Reference-contexts: Finally, we point out that our use of work stealing and non-blocking synchronization builds upon a long history in both areas, though they did not meet until now. The idea of work stealing goes back to 1981 [16] and has been used in many systems and applications since <ref> [20, 21, 27, 42, 46] </ref>. The first provably efficient work-stealing algorithm [15] and implementation [14] is fairly recent, however. The idea of non-blocking and wait-free synchronization was developed by Herlihy [29].
Reference: [28] <author> Maurice Herlihy. </author> <title> A methodology for implementing highly concurrent data structures. </title> <booktitle> In Proceedings of the Second ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming (PPoPP), </booktitle> <pages> pages 197 206, </pages> <address> Seattle, Washington, </address> <month> March </month> <year> 1990. </year>
Reference-contexts: The first provably efficient work-stealing algorithm [15] and implementation [14] is fairly recent, however. The idea of non-blocking and wait-free synchronization was developed by Herlihy [29]. There has been a long line of work attempting to make the idea more practical via universal constructions <ref> [11, 28] </ref>, useful primitives [2, 3, 39], and specific data objects [3, 36, 45]. In fact, our non-blocking implementation of work stealing uses the bounded-tags technique of [39]. Nevertheless, to this day, few applications or systems have been built with non-blocking synchronization.
Reference: [29] <author> Maurice Herlihy. </author> <title> Wait-free synchronization. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 11(1):124149, </volume> <month> January </month> <year> 1991. </year>
Reference-contexts: We show in this paper that this hope can be realized with a non-blocking implementation of the work-stealing thread-scheduling algorithm. This implementation employs non-blocking synchronization <ref> [29] </ref> for the concurrent data structures and judicious use of yields. The result is performance as shown in Figure 1 (b). <p> The first provably efficient work-stealing algorithm [15] and implementation [14] is fairly recent, however. The idea of non-blocking and wait-free synchronization was developed by Herlihy <ref> [29] </ref>. There has been a long line of work attempting to make the idea more practical via universal constructions [11, 28], useful primitives [2, 3, 39], and specific data objects [3, 36, 45]. In fact, our non-blocking implementation of work stealing uses the bounded-tags technique of [39]. <p> That is, instead of using mutual exclusion, we use powerful atomic instructions, notably the SPARC v9 casxa (64-bit compare-and-swap) instruction. A complete description of this implementation can be found in [9]. This implementation is non-blocking, as opposed to wait-free <ref> [29] </ref>, meaning that it is possible for a process to starve in its attempt to perform a deque operation. Livelock, however, cannot occur because if one process starves, then others must be making progress.
Reference: [30] <author> Alain Kagi, Doug Burger, and James R. Goodman. </author> <title> Efficient synchronization: Let them eat QOLB. </title> <booktitle> In Pro ceedings of the 24th Annual International Symposium on Computer Architecture (ISCA), </booktitle> <address> Denver, Colorado, </address> <month> June </month> <year> 1997. </year>
Reference-contexts: Our blocking-lock implementation uses the Solaris thread library. A lock is a mutex t, and the lock is operated upon with the mutex lock and mutex unlock calls. Many other and more sophisticated locking strategies are known <ref> [4, 24, 30] </ref>, but we do not consider them. One advantage of some of these strategies is that they perform well under high contention. In our case, each process has its own deque and contention arises only due to thieves, who steal at random.
Reference: [31] <author> Steve Kleiman, Devang Shah, and Bart Smaalders. </author> <title> Programming with Threads. </title> <publisher> SunSoft Press, Prentice Hall, </publisher> <year> 1996. </year>
Reference-contexts: employed by a parallelizing compiler, or the runtime system for a multithreaded language such as Cilk [14] or Java [8]. 1.1 The problem with static partitioning Before considering dynamic thread scheduling, we first review a well-known performance anomaly that occurs when parallel programs use a static partitioning of the work <ref> [31, pages 284285] </ref>. In the simplest case when such a program executes, it creates some number P of processes, where typically P is selected by a command-line argument, and each process performs a 1=P fraction of the total work. <p> The traditionally proposed solution to this problem is to use a number P of processes that is significantly greater than the number P M of machine processors, so that we are guaranteed to have P P A <ref> [31, page 285] </ref>. Indeed, using extra processes can improve the load imbalance, but as we see in Figure 1 (a), it does not solve the problem. As P grows, the overhead of creating and synchronizing the processes grows and the work per process T 1 =P shrinks.
Reference: [32] <author> Scott T. Leutenegger and Mary K. Vernon. </author> <title> The performance of multiprogrammed multiprocessor scheduling policies. </title> <booktitle> In Proceedings of the 1990 ACM SIGMETRICS Conference on Measurement and Modeling of Computer Systems, </booktitle> <address> Boulder, Colorado, </address> <month> May </month> <year> 1990. </year>
Reference-contexts: In addition, we briefly discuss prior work on non-blocking synchronization and thread scheduling, upon which our implementation has been built. Much prior work on multiprogramming multiprocessors has focused on the management and scheduling of kernel-level resources, specifically processes <ref> [26, 32, 35, 40, 41, 44, 47] </ref>. A number of studies have compared various process-scheduling strategies, and all have concluded that the traditional time-sharing, priority-based local scheduler found in most operating systems is inadequate [10, 17, 18, 19, 26]. <p> In general, with process control a parallel program creates and kills processes dynamically so that it continuously runs with a number of processes equal to the number of processors available to it. Process control can be used to implement resource-management policies, such as equipar-titioning <ref> [32, 35, 44] </ref>. As with our approach, process control requires a runtime-system layer that assigns user-level threads to processes dynamically, so that work can be reassigned when a process is created or killed.
Reference: [33] <author> Brian D. Marsh, Michael L. Scott, Thomas J. LeBlanc, and Evangelos P. Markatos. </author> <title> First-class user-level threads. </title> <booktitle> In Proceedings of the Thirteenth ACM Symposium on Operating Systems Principles (SOSP), </booktitle> <address> Pacific Grove, California, </address> <month> October </month> <year> 1991. </year> <month> 19 </month>
Reference-contexts: With no blocking, processes typically run for their full quantum, so the cost of cache warmup can be amortized over a long run. As another alternative to kernel-level resource management, first-class user-level threads <ref> [33] </ref> and sched-uler activations [5] are kernel-level mechanisms that support efficient multiprogramming with user-level threads, independent of any particular kernel-level resource-management policy. <p> In addition, we shall not consider preemption-safe locking <ref> [1, 5, 13, 33, 37] </ref>, because it requires non-traditional kernel support. In particular, it requires either that the kernel does not preempt processes while they hold locks or that the kernel informs processes of impending preemptions. applications and for each of our three alternative work-stealing implementations.
Reference: [34] <author> Henry Massalin and Calton Pu. </author> <title> A lock-free multiprocessor os kernel. </title> <type> Technical Report CUCS-005-91, </type> <institution> Columbia University, Department of Computer Science, </institution> <year> 1991. </year>
Reference-contexts: In fact, our non-blocking implementation of work stealing uses the bounded-tags technique of [39]. Nevertheless, to this day, few applications or systems have been built with non-blocking synchronization. Of notable exception is a study of non-blocking applications [37] and two non-blocking operating-system kernels <ref> [25, 34] </ref>. 3 Work stealing The work-stealing algorithm dynamically assigns threads to processes for execution in a provably efficient manner [14, 15]. In this section, we review the work-stealing algorithm, and we state the proven performance bounds. In addition, we describe the non-blocking implementation of this algorithm [9].
Reference: [35] <author> Cathy McCann, Raj Vaswani, and John Zahorjan. </author> <title> A dynamic processor allocation policy for multiprogrammed shared-memory multiprocessors. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 11(2):146178, </volume> <month> May </month> <year> 1993. </year>
Reference-contexts: In addition, we briefly discuss prior work on non-blocking synchronization and thread scheduling, upon which our implementation has been built. Much prior work on multiprogramming multiprocessors has focused on the management and scheduling of kernel-level resources, specifically processes <ref> [26, 32, 35, 40, 41, 44, 47] </ref>. A number of studies have compared various process-scheduling strategies, and all have concluded that the traditional time-sharing, priority-based local scheduler found in most operating systems is inadequate [10, 17, 18, 19, 26]. <p> In general, with process control a parallel program creates and kills processes dynamically so that it continuously runs with a number of processes equal to the number of processors available to it. Process control can be used to implement resource-management policies, such as equipar-titioning <ref> [32, 35, 44] </ref>. As with our approach, process control requires a runtime-system layer that assigns user-level threads to processes dynamically, so that work can be reassigned when a process is created or killed. <p> Our performance model shows that there is a performance penalty when operating in the regime where the number of processes is comparable to or larger than the average parallelism. With process control and a dynamic space-partitioning policy <ref> [35] </ref>, we can avoid operating in this regime. In general, our results indicate that local scheduling is adequate, provided that parallel applications are coded to use threads and that the threads library is implemented with our non-blocking work stealer.
Reference: [36] <author> Maged M. Michael and Michael L. Scott. </author> <title> Simple, fast, and practical non-blocking and blocking concurrent queue algorithms. </title> <booktitle> In Proceedings of the 15th Annual ACM Symposium on Priciples of Distributed Computing (PODC), </booktitle> <address> Philadelphia, Pennsylvania, </address> <month> May </month> <year> 1996. </year>
Reference-contexts: The idea of non-blocking and wait-free synchronization was developed by Herlihy [29]. There has been a long line of work attempting to make the idea more practical via universal constructions [11, 28], useful primitives [2, 3, 39], and specific data objects <ref> [3, 36, 45] </ref>. In fact, our non-blocking implementation of work stealing uses the bounded-tags technique of [39]. Nevertheless, to this day, few applications or systems have been built with non-blocking synchronization.
Reference: [37] <author> Maged M. Michael and Michael L. Scott. </author> <title> Relative performance of preemption-safe locking and non-blocking synchronization on multiprogrammed shared memory multiprocessors. </title> <booktitle> In Proceedings of the 11th International Parallel Processing Symposium (IPPS), </booktitle> <address> Geneva, Switzerland, </address> <month> April </month> <year> 1997. </year>
Reference-contexts: In comparison with our exclusively user-level implementation of work stealing, we expect that such kernel-level support admits a simpler implementation, with efficient performance under multiprogramming, through the use of preemption-safe locking <ref> [1, 13, 37] </ref>. Nevertheless, we have shown that such kernel support is not necessary to achieve our goals. Kernel-level support does have other benefits, however, notably the ability to make system calls non-blocking. <p> In fact, our non-blocking implementation of work stealing uses the bounded-tags technique of [39]. Nevertheless, to this day, few applications or systems have been built with non-blocking synchronization. Of notable exception is a study of non-blocking applications <ref> [37] </ref> and two non-blocking operating-system kernels [25, 34]. 3 Work stealing The work-stealing algorithm dynamically assigns threads to processes for execution in a provably efficient manner [14, 15]. In this section, we review the work-stealing algorithm, and we state the proven performance bounds. <p> In addition, we shall not consider preemption-safe locking <ref> [1, 5, 13, 33, 37] </ref>, because it requires non-traditional kernel support. In particular, it requires either that the kernel does not preempt processes while they hold locks or that the kernel informs processes of impending preemptions. applications and for each of our three alternative work-stealing implementations.
Reference: [38] <author> Eric Mohr, David A. Kranz, and Robert H. Halstead, Jr. </author> <title> Lazy task creation: A technique for increasing the granularity of parallel programs. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 2(3):264280, </volume> <month> July </month> <year> 1991. </year>
Reference-contexts: Focusing on the scheduler implementation, we shall make quantitative comparisons of (computational) speedup and only make qualitative comparisons of overhead. Our implementations are replete with instrumentation, and in order to keep the implementations simple, we have not employed many of the known mechanisms <ref> [6, 23, 38] </ref> for keeping the overhead low. For this reason, a quantitative comparison of the overhead for our three alternative implementations would be meaningless. We cannot, however, ignore overhead.
Reference: [39] <author> Mark Moir. </author> <title> Practical implementations of non-blocking synchronization primitives. </title> <booktitle> In Proceedings of the Six teenth ACM Symposium on Principles of Distributed Computing (PODC), </booktitle> <address> Santa Barbara, California, </address> <month> August </month> <year> 1997. </year>
Reference-contexts: The first provably efficient work-stealing algorithm [15] and implementation [14] is fairly recent, however. The idea of non-blocking and wait-free synchronization was developed by Herlihy [29]. There has been a long line of work attempting to make the idea more practical via universal constructions [11, 28], useful primitives <ref> [2, 3, 39] </ref>, and specific data objects [3, 36, 45]. In fact, our non-blocking implementation of work stealing uses the bounded-tags technique of [39]. Nevertheless, to this day, few applications or systems have been built with non-blocking synchronization. <p> There has been a long line of work attempting to make the idea more practical via universal constructions [11, 28], useful primitives [2, 3, 39], and specific data objects [3, 36, 45]. In fact, our non-blocking implementation of work stealing uses the bounded-tags technique of <ref> [39] </ref>. Nevertheless, to this day, few applications or systems have been built with non-blocking synchronization.
Reference: [40] <author> John K. Ousterhout. </author> <title> Scheduling techniques for concurrent systems. </title> <booktitle> In Proceedings of the 3rd International Conference on Distributed Computing Systems, </booktitle> <month> May </month> <year> 1982. </year>
Reference-contexts: Similarly, users expect multiprocessor compute servers to support multiprogrammed work loads that include parallel applications. Unfortunately, unless parallel applications are coscheduled <ref> [40] </ref> or subject to process control [44], they display poor performance in such multiprogrammed environments [10, 17, 18, 19, 26]. As an alternative to coscheduling or process control, in this paper we investigate the use of dynamic, user-level, thread scheduling in order to achieve efficient performance under multiprogramming. <p> In addition, we briefly discuss prior work on non-blocking synchronization and thread scheduling, upon which our implementation has been built. Much prior work on multiprogramming multiprocessors has focused on the management and scheduling of kernel-level resources, specifically processes <ref> [26, 32, 35, 40, 41, 44, 47] </ref>. A number of studies have compared various process-scheduling strategies, and all have concluded that the traditional time-sharing, priority-based local scheduler found in most operating systems is inadequate [10, 17, 18, 19, 26]. <p> In addition, all of these studies have concluded that some form of coscheduling or space partitioning with process control offers the best solution. Coscheduling <ref> [40] </ref>, which is a generalization of gang scheduling, attempts to run all of the processes of any given parallel program concurrently as a gang, thereby giving each program the illusion of running on a dedicated machine.
Reference: [41] <author> K. C. Sevcik. </author> <title> Application scheduling and processor allocation in multiprogrammed parallel processing systems. Performance Evaluation, </title> <address> 19(23):107140, </address> <month> March </month> <year> 1994. </year>
Reference-contexts: In addition, we briefly discuss prior work on non-blocking synchronization and thread scheduling, upon which our implementation has been built. Much prior work on multiprogramming multiprocessors has focused on the management and scheduling of kernel-level resources, specifically processes <ref> [26, 32, 35, 40, 41, 44, 47] </ref>. A number of studies have compared various process-scheduling strategies, and all have concluded that the traditional time-sharing, priority-based local scheduler found in most operating systems is inadequate [10, 17, 18, 19, 26].
Reference: [42] <author> Jaswinder Pal Singh, Anoop Gupta, and Marc Levoy. </author> <title> Parallel visualization algorithms: Performance and archi tectural implications. </title> <journal> IEEE Computer, </journal> <volume> 27(7):4555, </volume> <month> July </month> <year> 1994. </year>
Reference-contexts: Finally, we point out that our use of work stealing and non-blocking synchronization builds upon a long history in both areas, though they did not meet until now. The idea of work stealing goes back to 1981 [16] and has been used in many systems and applications since <ref> [20, 21, 27, 42, 46] </ref>. The first provably efficient work-stealing algorithm [15] and implementation [14] is fairly recent, however. The idea of non-blocking and wait-free synchronization was developed by Herlihy [29].
Reference: [43] <author> Patrick G. Sobalvarro and William E. Weihl. </author> <title> Demand-based coscheduling of parallel jobs on multiprogrammed multiprocessors. </title> <booktitle> In Proceedings of the IPPS '95 Workshop on Job Scheduling Strategies for Parallel Processing, </booktitle> <month> April </month> <year> 1995. </year>
Reference-contexts: Interestingly, it has been shown recently that coscheduling can be achieved implicitly with little or no modification to existing kernel schedulers <ref> [18, 43] </ref>. The main advantage of coscheduling over our approach is that coscheduling may be able to achieve superlinear speedup due to caching effects. We discuss this issue in more detail in Section 7.
Reference: [44] <author> Andrew Tucker and Anoop Gupta. </author> <title> Process control and scheduling issues for multiprogrammed shared-memory multiprocessors. </title> <booktitle> In Proceedings of the Twelfth ACM Symposium on Operating Systems Principles (SOSP), </booktitle> <pages> pages 159166, </pages> <address> Litchfield Park, Arizona, </address> <month> December </month> <year> 1989. </year>
Reference-contexts: Similarly, users expect multiprocessor compute servers to support multiprogrammed work loads that include parallel applications. Unfortunately, unless parallel applications are coscheduled [40] or subject to process control <ref> [44] </ref>, they display poor performance in such multiprogrammed environments [10, 17, 18, 19, 26]. As an alternative to coscheduling or process control, in this paper we investigate the use of dynamic, user-level, thread scheduling in order to achieve efficient performance under multiprogramming. <p> In addition, we briefly discuss prior work on non-blocking synchronization and thread scheduling, upon which our implementation has been built. Much prior work on multiprogramming multiprocessors has focused on the management and scheduling of kernel-level resources, specifically processes <ref> [26, 32, 35, 40, 41, 44, 47] </ref>. A number of studies have compared various process-scheduling strategies, and all have concluded that the traditional time-sharing, priority-based local scheduler found in most operating systems is inadequate [10, 17, 18, 19, 26]. <p> In the former case, we are leaving most of the processors idle. In the latter case, we may observe performance as in Figure 1 (a). As an alternative to the above scenario, the process control approach <ref> [44] </ref> would have the parallel program kill one of its processes. In general, with process control a parallel program creates and kills processes dynamically so that it continuously runs with a number of processes equal to the number of processors available to it. <p> In general, with process control a parallel program creates and kills processes dynamically so that it continuously runs with a number of processes equal to the number of processors available to it. Process control can be used to implement resource-management policies, such as equipar-titioning <ref> [32, 35, 44] </ref>. As with our approach, process control requires a runtime-system layer that assigns user-level threads to processes dynamically, so that work can be reassigned when a process is created or killed.
Reference: [45] <author> John D. Valois. </author> <title> Lock-free linked lists using compare-and-swap. </title> <booktitle> In Proceedings of the 14th Annual ACM Sym posium on Priciples of Distributed Computing (PODC), </booktitle> <address> Ottawa, Canada, </address> <month> August </month> <year> 1995. </year>
Reference-contexts: The idea of non-blocking and wait-free synchronization was developed by Herlihy [29]. There has been a long line of work attempting to make the idea more practical via universal constructions [11, 28], useful primitives [2, 3, 39], and specific data objects <ref> [3, 36, 45] </ref>. In fact, our non-blocking implementation of work stealing uses the bounded-tags technique of [39]. Nevertheless, to this day, few applications or systems have been built with non-blocking synchronization.
Reference: [46] <author> Mark T. Vandevoorde and Eric S. Roberts. WorkCrews: </author> <title> An abstraction for controlling parallelism. </title> <journal> International Journal of Parallel Programming, </journal> <volume> 17(4):347366, </volume> <month> August </month> <year> 1988. </year>
Reference-contexts: Finally, we point out that our use of work stealing and non-blocking synchronization builds upon a long history in both areas, though they did not meet until now. The idea of work stealing goes back to 1981 [16] and has been used in many systems and applications since <ref> [20, 21, 27, 42, 46] </ref>. The first provably efficient work-stealing algorithm [15] and implementation [14] is fairly recent, however. The idea of non-blocking and wait-free synchronization was developed by Herlihy [29].
Reference: [47] <author> Raj Vaswani and John Zahorjan. </author> <title> The implications of cache affinity on processor scheduling for multipro grammed, shared memory multiprocessors. </title> <booktitle> In Proceedings of the Thirteenth ACM Symposium on Operating Systems Principles (SOSP), </booktitle> <address> Pacific Grove, California, </address> <month> October </month> <year> 1991. </year>
Reference-contexts: In addition, we briefly discuss prior work on non-blocking synchronization and thread scheduling, upon which our implementation has been built. Much prior work on multiprogramming multiprocessors has focused on the management and scheduling of kernel-level resources, specifically processes <ref> [26, 32, 35, 40, 41, 44, 47] </ref>. A number of studies have compared various process-scheduling strategies, and all have concluded that the traditional time-sharing, priority-based local scheduler found in most operating systems is inadequate [10, 17, 18, 19, 26]. <p> Nevertheless, as we have already indicated, some applications probably do need some type of coscheduling, and our scheduler can benefit from dynamic space partitioning and process control. Moreover, we cannot conclude that local scheduling is entirely adequate, because our studies were performed with Solaris 2.5.1, which implements affinity scheduling <ref> [47] </ref>. We do, however, conjecture that affinity scheduling is of less value for applications that use our non-blocking work stealer than for other applications that use blocking synchronization.
Reference: [48] <author> Steven Cameron Woo, Moriyoshi Ohara, Evan Torrie, Jaswinder Pal Singh, and Anoop Gupta. </author> <title> The SPLASH-2 programs: Characterization and methodological considerations. </title> <booktitle> In Proceedings of the 22nd Annual International Symposium on Computer Architecture (ISCA), </booktitle> <pages> pages 2436, </pages> <address> Santa Margherita Ligure, Italy, </address> <month> June </month> <year> 1995. </year> <month> 20 </month>
Reference-contexts: Each block is of size 16 fi 16. barnes (n; s) Run Barnes-Hut n-body simulation [12] on n bodies for s time steps. This code is adapted from the SPLASH-2 <ref> [48] </ref> program, but for the work-stealing version, we parallelized the tree-building with a divide-and-conquer algorithm, so as to avoid the use of locks. heat (n; m; s) Simulate heat propagation on an n fi m grid for s iterations using Jacobi iteration on a 5-point stencil. <p> This application is very similar to the SPLASH-2 Ocean program <ref> [48] </ref>. msort (n) Merge sort n integers. Each recursive call is done in parallel, and in addition, the merging is done in parallel using a simple divide-and-conquer technique. ray () Raytrace scene to compute frame buffer of pixel colors. This application is adapted from the SPLASH-2 [48] program, and we use <p> the SPLASH-2 Ocean program <ref> [48] </ref>. msort (n) Merge sort n integers. Each recursive call is done in parallel, and in addition, the merging is done in parallel using a simple divide-and-conquer technique. ray () Raytrace scene to compute frame buffer of pixel colors. This application is adapted from the SPLASH-2 [48] program, and we use balls4.env as the scene to be rendered. Table 1: Applications used in our study. All applications are written in C++ and compiled with version 4.1 of the Sun CC compiler using flags -xarch=v8plus -O5 -dalign -noex.
References-found: 48

