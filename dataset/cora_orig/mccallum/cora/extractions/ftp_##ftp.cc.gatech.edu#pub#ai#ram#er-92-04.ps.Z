URL: ftp://ftp.cc.gatech.edu/pub/ai/ram/er-92-04.ps.Z
Refering-URL: http://www.cs.cmu.edu/afs/cs.cmu.edu/user/mcox/Public/Www/papers.html
Root-URL: 
Email: ashwin@cc.gatech.edu  cox@cc.gatech.edu  sn@chmsr.gatech.edu  
Title: An Architecture for Integrated Introspective Learning  
Author: Ashwin Ram Michael T. Cox S. Narayanan 
Address: Atlanta, Georgia 30332-0280  Atlanta, Georgia 30332-0280  Atlanta, Georgia 30332-0205  
Affiliation: College of Computing Georgia Institute of Technology  College of Computing Georgia Institute of Technology  School of Industrial Systems Engg. Georgia Institute of Technology  
Note: Machine Learning: Proceedings of the Ninth International Conference, Workshop on Computational Architectures, Aberdeen, Scotland, 1992.  
Abstract: This paper presents a computational model of integrated introspective learning, which is a deliberative learning process in which a rea-soner introspects about its own performance on a reasoning task, identifies what it needs to learn to improve its performance, formulates learning goals to acquire the required knowledge, and pursues its learning goals using multiple learning strategies. We discuss two case studies of integrated introspective learning in two different task domains. The first case study deals with learning diagnostic knowledge during a troubleshooting task, and is based on observations of human operators engaged in a real-world troubleshooting task at an electronics assembly plant. The second case study deals with learning multiple kinds of causal and explanatory knowledge during a story understanding task. The model is com-putationally justified as a uniform and extensible framework for deliberative learning using multiple learning strategies, and cogni-tively justified as a plausible model of human deliberative learning.
Abstract-found: 1
Intro-found: 1
Reference: [Birnbaum, 1986] <author> L. Birnbaum. </author> <title> Integrated Processing in Planning and Understanding. </title> <type> Ph.D. thesis, </type> <institution> Yale University, Department of Computer Science, </institution> <address> New Haven, CT, </address> <year> 1986. </year> <note> Research Report #489. </note>
Reference-contexts: Because knowledge goals are indexed in memory, it is quite likely that an understander will find information relevant to goals other than the ones that are currently "active." In other words, knowledge goals can be satisfied opportunistically during the course of understanding <ref> [Birnbaum, 1986; Dehn, 1989; Hammond, 1988; Ram, 1989; Ram, 1991] </ref>, leading to opportunistic learning of information previously identified as being useful to obtain (e.g., [Ram, 1992; Ram & Hunter, 1992]).
Reference: [Chi & VanLehn, 1991] <author> M.T.H. Chi & K. VanLehn. </author> <title> The Content of Physics Self-Explanations. </title> <journal> The Journal of the Learning Sciences, </journal> <volume> 1(1) </volume> <pages> 69-105, </pages> <year> 1991. </year>
Reference: [Cox & Ram, 1992] <author> M.T. Cox & A. Ram. </author> <title> Multistrat--egy Learning with Introspective Meta-Explanations. </title> <booktitle> In Machine Learning: Proceedings of the Ninth International Conference, </booktitle> <address> Aberdeen, Scotland, </address> <year> 1992. </year>
Reference-contexts: If a difficulty or failure is encountered, the system introspectively examines its own reasoning processes to determine where the problem lies, and use this introspective understanding to improve itself using the appropriate learning strategies <ref> [Cox & Ram, 1992; Ram & Cox, 1992] </ref>. 3 An architecture for integrated introspective learning The reasoner receives some input from the outside world, and focusses its attention on the part of the input which is relevant or interesting to it. <p> An Introspective Meta-XP, then, could be viewed as a "reasoning pattern," representing a trace of a typical reasoning process, the failures encountered during the reasoning process, and the learning necessary in that situation. Examples and further details may be found in <ref> [Cox & Ram, 1992; Ram & Cox, 1992] </ref>. 5 Two case studies To ensure generality of the theory, we have performed two case studies in developing reasoning systems in two very different task domains. <p> XP-Mis-Indexed-Structure directs the indexing algorithm to the old, incorrectly applied explanation. It recommends that the explanation be re-indexed so that it is not retrieved in similar situations in the future. Further details of the Meta-AQUA system can be found in <ref> [Cox & Ram, 1992; Ram & Cox, 1992] </ref>. 6 Conclusions The focus of our research is on the integration of different kinds of knowledge and reasoning processes into goal-driven, real-world systems that can learn through experience.
Reference: [Dehn, 1989] <author> N. Dehn. </author> <title> Computer Story Writing: The Role of Reconstructive and Dynamic Memory. </title> <type> Ph.D. thesis, </type> <institution> Yale University, Department of Computer Science, </institution> <address> New Haven, CT, </address> <year> 1989. </year> <note> Research Report #792. </note>
Reference-contexts: Because knowledge goals are indexed in memory, it is quite likely that an understander will find information relevant to goals other than the ones that are currently "active." In other words, knowledge goals can be satisfied opportunistically during the course of understanding <ref> [Birnbaum, 1986; Dehn, 1989; Hammond, 1988; Ram, 1989; Ram, 1991] </ref>, leading to opportunistic learning of information previously identified as being useful to obtain (e.g., [Ram, 1992; Ram & Hunter, 1992]).
Reference: [Hammond, 1988] <author> K.J. Hammond. </author> <title> Opportunistic Memory: </title> <editor> Storing and Recalling Suspended Goals. In J.L. Kolodner (ed.), </editor> <booktitle> Proceedings of a Workshop on Case-Based Reasoning, </booktitle> <pages> pp. 154-168, </pages> <address> Clearwater Beach, FL, </address> <year> 1988. </year>
Reference-contexts: Because knowledge goals are indexed in memory, it is quite likely that an understander will find information relevant to goals other than the ones that are currently "active." In other words, knowledge goals can be satisfied opportunistically during the course of understanding <ref> [Birnbaum, 1986; Dehn, 1989; Hammond, 1988; Ram, 1989; Ram, 1991] </ref>, leading to opportunistic learning of information previously identified as being useful to obtain (e.g., [Ram, 1992; Ram & Hunter, 1992]).
Reference: [Hammond, 1989] <author> K.J. Hammond. </author> <title> Case-Based Planning: Viewing Planning as a Memory Task. </title> <booktitle> Perspectives in Artificial Intelligence. </booktitle> <publisher> Academic Press, </publisher> <address> Boston, MA, </address> <year> 1989. </year>
Reference-contexts: Thus credit or blame assignment (e.g., <ref> [Hammond, 1989; Weintraub, 1991] </ref>), formulating knowledge goals, asking questions, focussing attention, and pursuing learning actions are essential components of our learning model. Experiential learning: Learning is an incremental process of theory formation in which the reasoner accumulates experience in some task domain. <p> This is essentially a case-based or experience-based approach, which relies on the assumption that it is worth learning about one's experiences since one is likely to have similar experiences in the future (see, e.g., <ref> [Hammond, 1989; Kolodner & Simpson, 1984; Ram, 1992; Schank, 1982] </ref>). Opportunistic learning: An important corollary of the active and experiential nature of learning is that learning is opportunistic.
Reference: [Hunter, 1990] <author> L.E. Hunter. </author> <title> Planning to Learn. </title> <booktitle> In Proceedings of the Twelvth Annual Conference of the Cognitive Science Society, </booktitle> <pages> pp. 26-34, </pages> <address> Boston, MA, </address> <year> 1990. </year>
Reference: [Kolodner & Simpson, 1984] <author> J. Kolodner & R. Simp-son. </author> <title> A Case for Case-Based Reasoning. </title> <booktitle> In Proceedings of the Sixth Annual Conference of the Cognitive Science Society, </booktitle> <address> Boulder, CO, </address> <year> 1984. </year>
Reference-contexts: This is essentially a case-based or experience-based approach, which relies on the assumption that it is worth learning about one's experiences since one is likely to have similar experiences in the future (see, e.g., <ref> [Hammond, 1989; Kolodner & Simpson, 1984; Ram, 1992; Schank, 1982] </ref>). Opportunistic learning: An important corollary of the active and experiential nature of learning is that learning is opportunistic.
Reference: [Michalski, 1992] <author> R.S. Michalski. </author> <title> Inferential Learning Theory as a Basis for Multistrategy Task-Adaptive Learning. In R.S. </title> <editor> Michalski & G. Tecuci (eds.), </editor> <title> Machine Learning IV: A Multistrategy Approach, </title> <publisher> Mor-gan Kaufman Publishers, </publisher> <address> San Mateo, CA, </address> <year> 1992, </year> <note> to appear. </note>
Reference: [Minsky, 1985] <author> M. Minsky. </author> <title> The Society of Mind. </title> <publisher> Si-mon and Schuster, </publisher> <address> New York, NY, </address> <year> 1985. </year>
Reference-contexts: Unlike successful processing where there may or may not be anything to learn, failure situations are guaranteed to provide a potential for learning, otherwise the failure would not have occurred <ref> [Minsky, 1985] </ref>. Note that an unexpected success also counts as a reasoning "failure" because the reasoner was unable to correctly predict the outcome of the task.
Reference: [Mitchell et al., 1986] <author> T.M. Mitchell, R. Keller, & S. Kedar-Cabelli. </author> <title> Explanation-Based Generalization: </title>
Reference-contexts: Let us discuss these properties at greater length. Active learning: Traditional approaches in machine learning have assumed that the knowledge to be learned has already been identified by an exter nal agent (e.g., the "target concept" in explanation--based generalization <ref> [Mitchell et al., 1986] </ref>). In some approaches, the learning process has no target or goal at all; the program has no sense of what it is trying to learn or why it is trying to learn it.
References-found: 11

