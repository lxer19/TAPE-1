URL: file://ftp.cs.utexas.edu/pub/qsim/papers/Pierce+Kuipers-AAAI94.ps.Z
Refering-URL: http://net.cs.utexas.edu/users/qr/robotics/papers.html
Root-URL: 
Email: dmpierce@cs.utexas.edu, kuipers@cs.utexas.edu  
Title: Learning to Explore and Build Maps  
Author: David Pierce and Benjamin Kuipers 
Address: Austin, TX 78712  
Affiliation: Department of Computer Sciences University of Texas at Austin  
Note: In Proceedings of the Twelfth National Conference on Artificial Intelligence (AAAI-94) Cambridge, MA: AAAI/MIT Press, 1994.  
Abstract: Using the methods demonstrated in this paper, a robot with an unknown sensorimotor system can learn sets of features and behaviors adequate to explore a continuous environment and abstract it to a finite-state automaton. The structure of this automaton can then be learned from experience, and constitutes a cognitive map of the environment. A generate-and-test method is used to define a hierarchy of features defined on the raw sense vector culminating in a set of continuously differentiable local state variables. Control laws based on these local state variables are defined for robustly following paths that implement repeatable state transitions. These state transitions are the basis for a finite-state automaton, a discrete abstraction of the robot's continuous world. A variety of existing methods can learn the structure of the automaton defined by the resulting states and transitions. A simple example of the performance of our implemented system is presented. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Angluin, D. </author> <year> 1987. </year> <title> Learning regular sets from queries and counterexamples. </title> <booktitle> Information and Computation 75 </booktitle> <pages> 87-106. </pages>
Reference: <author> Dean, T.; Basye, K.; and Kaelbling, L. </author> <year> 1993. </year> <title> Uncertainty in graph-based map learning. </title> <editor> In Connell, J. H., and Mahadevan, S., eds., </editor> <title> Robot Learning. </title> <address> Boston: </address> <publisher> Kluwer Academic Publishers. </publisher> <pages> 171-192. </pages>
Reference: <author> Dean, T.; Angluin, D.; Basye, K.; Engelson, S.; Kael-bling, L.; Kokkevis, E.; and Maron, O. </author> <year> 1992. </year> <title> Inferring finite automata with stochastic output functions and an application to map learning. </title> <booktitle> In Proceedings, Tenth National Conference on Artificial Intelligence, </booktitle> <pages> 208-214. </pages> <address> San Jose, CA: </address> <publisher> AAAI Press/MIT Press. </publisher>
Reference: <author> Drescher, G. L. </author> <year> 1991. </year> <title> Made-Up Minds: A Construc-tivist Approach to Artificial Intelligence. </title> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference: <author> Kortenkamp, D., and Weymouth, T. </author> <year> 1994. </year> <title> Topological mapping for mobile robots using a combination of sonar and vision sensing. </title> <booktitle> In Proceedings of the Twelfth National Conference on Artificial Intelligence (AAAI-94). </booktitle>
Reference: <author> Kuipers, B. J., and Byun, Y.-T. </author> <year> 1988. </year> <title> A robust, qualitative method for robot spatial learning. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence (AAAI-88), </booktitle> <pages> 774-779. </pages>
Reference: <author> Kuipers, B. J., and Byun, Y.-T. </author> <year> 1991. </year> <title> A robot exploration and mapping strategy based on a semantic hierarchy of spatial representations. </title> <journal> Journal of Robotics and Autonomous Systems 8 </journal> <pages> 47-63. </pages>
Reference: <author> Kuipers, B.; Froom, R.; Lee, W.-Y.; and Pierce, D. </author> <year> 1993. </year> <title> The semantic hierarchy in robot learning. </title> <editor> In Connell, J. H., and Mahadevan, S., eds., </editor> <title> Robot Learning. </title> <address> Boston: </address> <publisher> Kluwer Academic Publishers. </publisher> <pages> 141-170. </pages>
Reference: <author> Kuipers, B. J. </author> <year> 1978. </year> <title> Modeling spatial knowledge. </title> <booktitle> Cognitive Science 2 </booktitle> <pages> 129-153. </pages>
Reference: <author> Kuo, B. C. </author> <year> 1982. </year> <title> Automatic Control Systems. </title> <address> Engle-wood Cliffs, N.J.: </address> <publisher> Prentice-Hall, Inc., </publisher> <address> 4 edition. </address>
Reference-contexts: A simple proportional-integral (PI) control law is used with parameters = 1:0, ! = 0:05 <ref> (see Kuo 1982) </ref>. following behaviors. For each primitive action and feature, an open-loop behavior is defined (Figure 8) that is applicable in contexts where, according to the static action model, the action leaves the value of the feature invariant.
Reference: <author> Lin, L.-J., and Hanson, S. J. </author> <year> 1993. </year> <title> On-line learning for indoor navigation: Preliminary results with RatBot. In NIPS93 Robot Learning Workshop. </title>
Reference: <author> Mardia, K. V.; Kent, J. T.; and Bibby, J. M. </author> <year> 1979. </year> <title> Multivariate Analysis. </title> <address> New York: </address> <publisher> Academic Press. </publisher>
Reference: <author> Michie, D., and Chambers, R. A. </author> <year> 1968. </year> <title> BOXES: An experiment in adaptive control. </title> <editor> In Dale, E., and Michie, D., eds., </editor> <booktitle> Machine Intelligence 2. </booktitle> <publisher> Edinburgh: Oliver and Boyd. </publisher> <pages> 137-152. </pages>
Reference-contexts: The orientation of the robot with respect to the wall is the context that determines the action's effect on the feature. A brute-force way to define contexts is to break sensory space up into a large set of boxes <ref> (cf. Michie & Chambers 1968) </ref>. In the current example, a more elegant solution is possible. The learned blob features have associated context information, namely the positions of the features in the image from which they are produced (see Figure 4).
Reference: <author> Pierce, D. M. </author> <year> 1991. </year> <title> Learning a set of primitive actions with an uninterpreted sensorimotor apparatus. </title>
Reference-contexts: The action vector used to control the motor apparatus is a linear combination of the primitive actions, written u = i u i u i : This method has been successfully applied to both a ring of distance sensors and a small retina <ref> (Pierce 1991) </ref>. The static action model The purpose of the static action model is to tell how the primitive actions affect the features that serve as local state variables. Knowing how to take a feature to a target value is necessary for satisfying a constraint, i.e., moving to a path.
Reference: <editor> In Birnbaum, L. A., and Collins, G. C., eds., </editor> <booktitle> Machine Learning: Proceedings of the Eighth International Workshop (ML91), </booktitle> <pages> 338-342. </pages> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann Publishers, Inc. </publisher>
Reference: <author> Rivest, R. L., and Schapire, R. E. </author> <year> 1993. </year> <title> Inference of finite automata using homing sequences. </title> <booktitle> Information and Computation 103(2) </booktitle> <pages> 299-347. </pages>
References-found: 16

