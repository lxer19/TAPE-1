URL: http://www.cs.dartmouth.edu/~nicol/barrier/barrier.ps
Refering-URL: http://www.cs.dartmouth.edu/~nicol/barrier/barrier.html
Root-URL: http://www.cs.dartmouth.edu
Title: Noncommittal Barrier Synchronization  
Author: David M. Nicol 
Keyword: Synchronization, parallel simulation, optimistic computation, parallel prefix.  
Affiliation: Department of Computer Science College of William and Mary  
Abstract: Barrier synchronization is a fundamental operation in parallel computation. In many contexts, at the point a process enters a barrier it knows that it has already processed all work required of it prior to the synchronization. It then commits to the barrier, in the sense that the process blocks until every other process has also committed to the barrier. This paper treats the alternative case, when a process cannot enter a barrier with the assurance that it has already performed all necessary pre-synchronization computation. The problem arises when the number of pre-synchronization messages to be received by a process is unknown, for example, in any computation that is largely driven by an unpredictable exchange of messages. We describe a O(log 2 P ) time barrier algorithm for such problems, study its performance on a large-scale parallel system, and consider extensions to general associative reductions, as well as associative parallel prefix computations. fl A preliminary version of this paper appears in the Proceedings of the 1993 Workshop on Parallel and Distributed Simulation, under the title "Global Synchronization for Optimistic Parallel Discrete Event Simulations", portions of which are reprinted with permission. Copyright owned the journal "Parallel Computing"; this paper appears in vol. 21, pp. 529-549, 1995. y This research was supported in part by NASA grants NAG-1-1060, NAG-1-1132, and NAG-1-995, and NSF Grants ASC 8819373 and CCR-9201195. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S.G. Akl. </author> <title> The Design and Analysis of Parallel Algorithms. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1989. </year>
Reference-contexts: Define p, the system dimension, to be the smallest integer such that P 2 p . Our solution involves a balanced binary tree whose elements form an interval of process ids. The root node is T 0 = <ref> [0; 1; : : : ; P 1] </ref>. <p> The fact that this is possible is evident from our algorithm's basis in a tree structure; the computation of reductions and prefix operations on trees is already well-understood <ref> [1] </ref>; the point of this section is give enough details to show where our algorithm can be modified to support these operations. Let S be a set, and : S fi S ! S be an associative operator.
Reference: [2] <author> N.S. Arenstorf and H.F. Jordan. </author> <title> Comparing barrier algorithms. </title> <journal> Parallel Computing, </journal> <volume> 12(2) </volume> <pages> 157-170, </pages> <month> November </month> <year> 1989. </year>
Reference-contexts: The fundamental communication pattern we use is based on the butterfly barrier [3]. Students of synchronization should also read the comparative study of barriers on shared memory machines reported in <ref> [2] </ref>. The principle contribution of this paper is to identify and solve a general synchronization problem by bringing together ideas from optimistic parallel simulation, deterministic parallel synchronization, and distributed termination detection.
Reference: [3] <author> T.S. Axelrod. </author> <title> Effects of synchronization barriers on multiprocessor performance. </title> <journal> Parallel Computing, </journal> <volume> 3(2) </volume> <pages> 129-140, </pages> <month> May </month> <year> 1986. </year>
Reference-contexts: The problem arises in a surprising number of applications, including convergence checking, parallel discrete-event simulation, dynamic load-balancing, and checkpointing in parallel systems. We show how modification of a standard algorithm (the butterfly barrier <ref> [3] </ref>) permits the use of barrier synchronization when the total number of messages to be processed by a process prior to the barrier is unknown. There are two important elements to the algorithm. <p> While he finds his algorithm to be twice as fast as the serial one, no raw timing information is given. The fundamental communication pattern we use is based on the butterfly barrier <ref> [3] </ref>. Students of synchronization should also read the comparative study of barriers on shared memory machines reported in [2]. The principle contribution of this paper is to identify and solve a general synchronization problem by bringing together ideas from optimistic parallel simulation, deterministic parallel synchronization, and distributed termination detection.
Reference: [4] <author> S. Eick, A. Greenberg, B. Lubachevsky, and A. Weiss. </author> <title> Synchronous relaxation for parallel simulations with applications to circuit-switched networks. </title> <booktitle> In Proceedings of the 1991 Workshop on Parallel and Distributed Simulation, </booktitle> <pages> pages 151-162, </pages> <month> Jan. </month> <year> 1991. </year>
Reference-contexts: The resimulation may itself cause straggler messages to be sent to other processes, rolling them back. This window-based style of synchronization has cropped up in a number of synchronization protocols <ref> [10, 4, 12] </ref>. Another use for fast noncommittal barrier synchronization is in the computation of Global Virtual Time, or GVT. GVT is a time behind which the simulation will never be rolled back.
Reference: [5] <author> D. R. Jefferson. </author> <title> Virtual time. </title> <journal> ACM Trans. on Programming Languages and Systems, </journal> <volume> 7(3) </volume> <pages> 404-425, </pages> <month> July </month> <year> 1985. </year>
Reference-contexts: We developed a synchronization protocol that progresses by imposing a window [s; t) on simulation time, having processes execute optimistically (i.e., like Time Warp <ref> [5] </ref>) during that interval, but prohibits any process from evaluating an event with time-stamp greater than t until every process has reached time t. Following this a new window [t; t 0 ) is defined and the simulation advances past time t.
Reference: [6] <author> Sigurd L. Lillevik. </author> <title> The Touchstone 30 gigaflop DELTA prototype. </title> <booktitle> In Distributed Memory Computer Conference 91, </booktitle> <pages> pages 671-677. </pages> <address> IEEEPRESS, </address> <month> April </month> <year> 1991. </year>
Reference-contexts: All of these activities exact costs not suffered by an optimized conventional barrier. In this section we endevour to quantify these costs, by comparing the performance of our barrier with that of the conventional barrier gsync () provided on the Intel Touchstone Delta <ref> [6] </ref>. We first quantify the relative cost of our algorithm in the absence of rollbacks. Table 1 presents raw timings. These experiments simply call the barrier algorithms repeatedly. The numbers presented are averages taken over thousands of calls. Since there is no other message passing, our algorithm does not rollback.
Reference: [7] <author> F. Mattern. </author> <title> Algorithms for distributed termination detection. </title> <journal> Distributed Computing, </journal> <volume> 2 </volume> <pages> 161-175, </pages> <year> 1987. </year>
Reference-contexts: The problem we consider is essentially identical to termination detection, so it is worthwhile to consider the types of solutions proposed in that context, e.g., <ref> [7] </ref>. One key difference is that such algorithms generally view the system as being much more loosely coupled than parallel systems. Furthermore, the complexity of these algorithms is measured in terms of numbers of messages passed, rather than time to execute.
Reference: [8] <author> F. Mattern. </author> <title> Experience with a new distributed termination detection algorithm. In Distributed Algorithms. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1987. </year>
Reference-contexts: In a parallel system there is a huge performance difference between a computation that passes P messages serially, and one that passes P messages in parallel. Nevertheless, our algorithm has similarities to the "vector algorithm" proposed by Mattern <ref> [8] </ref>, in that both track the difference between messages sent and messages received. However, there are substantial differences between our approach and Mattern's. His algorithm relies on a circulating control vector with P components, that serially traverses processors; ours accumulates counts in a logarithmic fashion, and has no serial component.
Reference: [9] <author> Peter L. Reiher, Richard Fujimoto, Steven Bellenot, and David Jefferson. </author> <title> Cancellation strategies in optimistic execution systems. </title> <booktitle> In Distributed Simulation 1990, </booktitle> <pages> pages 112-121. </pages> <institution> Society for Computer Simulation, </institution> <year> 1990. </year> <month> 22 </month>
Reference-contexts: If there is absolutely no difference between the vectors about to be sent and those last sent, then there is no need to resend the synchronization message. This idea (called lazy cancellation <ref> [9] </ref>) has been developed in the parallel simulation world, and has proven to be effective.
Reference: [10] <author> L.M. Sokol, </author> <title> D.P. Briscoe, and A.P. Wieland. MTW:a strategy for scheduling discrete simulation events for concurrent execution. </title> <booktitle> In Distributed Simulation 1988, </booktitle> <pages> pages 34-42. </pages> <booktitle> SCS Simulation Series, </booktitle> <year> 1988. </year>
Reference-contexts: The resimulation may itself cause straggler messages to be sent to other processes, rolling them back. This window-based style of synchronization has cropped up in a number of synchronization protocols <ref> [10, 4, 12] </ref>. Another use for fast noncommittal barrier synchronization is in the computation of Global Virtual Time, or GVT. GVT is a time behind which the simulation will never be rolled back.
Reference: [11] <author> J. Song. </author> <title> A distributed-termination experiment on a mesh-connected array of processors. </title> <journal> Parallel Computing, </journal> <volume> 18(2) </volume> <pages> 779-791, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: However, there are substantial differences between our approach and Mattern's. His algorithm relies on a circulating control vector with P components, that serially traverses processors; ours accumulates counts in a logarithmic fashion, and has no serial component. One distributed termination solution by Song (found in <ref> [11] </ref>) deserves special notice, as it was proposed for parallel applications, and was tested on a 64-node Ncube multiprocessor. It is designed specifically for mesh-connected multiprocessors, and permits interprocessor communication only between processors that are directly connected by the mesh. <p> Of course there are some pitfalls to avoid concerning the safety of checkpointing in the presence of blocking receives, but these are tangential to the issue we address of determining when all message activity has ceased. 2.4 Convergence Checking As shown in <ref> [11] </ref>, noncommittal synchronization also arise in numerical contexts, when convergence determines termination. A process whose subdomain has converged enters the noncommittal barrier, but can 5 receive a message containing boundary interface values from a neighboring process whose subdomain has not. This unblocks it to continue the computation.
Reference: [12] <author> J.S. Steinman. Speedes: </author> <title> Synchronous parallel environment for emulation and discrete event simulation. </title> <booktitle> In Advances in Parallel and Distributed Simulation, </booktitle> <volume> volume 23, </volume> <pages> pages 95-103. </pages> <booktitle> SCS Simulation Series, </booktitle> <month> Jan. </month> <year> 1991. </year> <month> 23 </month>
Reference-contexts: The resimulation may itself cause straggler messages to be sent to other processes, rolling them back. This window-based style of synchronization has cropped up in a number of synchronization protocols <ref> [10, 4, 12] </ref>. Another use for fast noncommittal barrier synchronization is in the computation of Global Virtual Time, or GVT. GVT is a time behind which the simulation will never be rolled back.
References-found: 12

