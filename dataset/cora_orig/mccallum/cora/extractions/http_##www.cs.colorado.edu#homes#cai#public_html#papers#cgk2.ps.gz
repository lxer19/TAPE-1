URL: http://www.cs.colorado.edu/homes/cai/public_html/papers/cgk2.ps.gz
Refering-URL: http://www.cs.colorado.edu/homes/cai/public_html/mypapers.html
Root-URL: http://www.cs.colorado.edu
Title: A COMPARISON OF SOME DOMAIN DECOMPOSITION AND ILU PRECONDITIONED ITERATIVE METHODS FOR NONSYMMETRIC ELLIPTIC PROBLEMS  
Author: XIAO-CHUAN CAI WILLIAM D. GROPP DAVID E. KEYES 
Keyword: domain decomposition, preconditioning, iterative methods, nonsymmetric, indefinite, elliptic problems.  
Address: Lexington, KY 40506, USA  Argonne, IL 60439, USA  New Haven, CT 06520, USA  
Affiliation: Department of Mathematics, University of Kentucky  Mathematics and Computer Science Division Argonne National Laboratory  Department of Mechanical Engineering, Yale University  
Abstract: In recent years, competitive domain-decomposed preconditioned iterative techniques have been developed for nonsymmetric elliptic problems. In these techniques, a large problem is divided into many smaller problems whose requirements for coordination can be controlled to allow effective solution on parallel machines. A central question is how to choose these small problems and how to arrange the order of their solution. Different specifications of decomposition and solution order lead to a plethora of algorithms possessing complementary advantages and disadvantages. In this report we compare several methods, including the additive Schwarz algorithm, the classical multiplicative Schwarz algorithm, an accelerated multiplicative Schwarz algorithm, the tile algorithm, the CGK algorithm, the CSPD algorithm, and also the popular global ILU-family of preconditioners, on some nonsymmetric or indefinite elliptic model problems discretized by finite difference methods. The preconditioned problems are solved by the unrestarted GMRES method. A version of the accelerated multiplicative Schwarz method is a consistently good performer. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. E. Bank, J. F. Burgler, W. Fichtner and R. K. Smith, </author> <title> Some upwinding techniques for the finite element approximation of convection-diffusion equations Numer. </title> <journal> Math., </journal> <month> 58 </month> <year> (1990) </year> <month> 185-202. </month>
Reference-contexts: Two finite difference discretizations are employed alternately for the first-order terms in (2.1), namely, the central and upwinding discretizations. In practice, there are many other discretization techniques such as the artificial diffusion and streamline diffusion methods [24] and the methods in <ref> [1] </ref>. Multiple discretizations can usefully be combined in the same iterative process; see, e.g., [26]. Our methods require a coarse grid over containing n 0 interior nodes, or crosspoints, fc k ; k = 1; ; n 0 g; we call this the H -level grid. <p> Numerical Experiments In this section, we present some numerical results obtained by applying the aforementioned algorithms to ( u = 0 on @; 20 where different elliptic operators L will be specified and = <ref> [0; 1] </ref> fi [0; 1]. In all cases, the exact solution u = e xy sin (x) sin (y), and f can thus be set accordingly. The unit square is subdivided into two-level uniform meshes, with h and H representing the fine- and coarse-mesh sizes. <p> Numerical Experiments In this section, we present some numerical results obtained by applying the aforementioned algorithms to ( u = 0 on @; 20 where different elliptic operators L will be specified and = <ref> [0; 1] </ref> fi [0; 1]. In all cases, the exact solution u = e xy sin (x) sin (y), and f can thus be set accordingly. The unit square is subdivided into two-level uniform meshes, with h and H representing the fine- and coarse-mesh sizes.
Reference: [2] <author> P. E. Bjtrstad and M. D. Skogen, </author> <title> Domain decomposition algorithms of Schwarz type, designed for massively parallel computers, in Fifth International Symposium on Domain Decomposition Methods for Partial Differential Equations, </title> <editor> D. E. Keyes, T. F. Chan, G. A. Meurant, J. S. Scroggs and R. G. Voigt, eds., </editor> <publisher> SIAM, </publisher> <address> Philadelphia (1992). </address>
Reference-contexts: The ASM discussed in this subsection can be used recursively for the solving the subdomain problems. The result is the multilevel ASM, as developed in <ref> [2, 16, 39] </ref>. 2.5. Coarse grid plus SPD preconditioning (CSPD) The low-frequency modes of the error are the hardest to damp with nearly any iterative method. Therefore, a direct solver is usually employed on the 12 coarse grid, as in multigrid methods. <p> For example, a few cycles of multigrid or a few Gauss-Seidel iterations perform well for some test problems, as in <ref> [2] </ref> or [33]. The crosspoint matrix is usually obtained by discretizing the original differential equation. Using an approximate operator in this case usually results in large iteration counts for our nonsymmetric problems, for reasons that are not yet explained theoretically.
Reference: [3] <author> J. H. Bramble, Z. Leyk and J. E. Pasciak, </author> <title> Iterative schemes for nonsymmetric and indefinite elliptic boundary value problems, </title> <institution> Cornell University, </institution> <type> preprint, </type> <year> (1991). </year>
Reference-contexts: Whereas experimental papers for symmetric problems, such as [20] and [25], predominantly played the role of verifying theory, in this paper we hope to stimulate it. Algorithms based on preconditioned iterative solution of the normal equations are beyond the scope of this paper, though they continue to undergo development <ref> [3, 4, 28, 31] </ref>. The outline of this paper is as follows. In Section 2, we describe five domain decomposition methods, their convergence properties, and related implementation issues. Some issues related to parallelism and parallel complexity are discussed in Section 3. <p> Other methods making special use of the coarse-grid matrix can also be found in <ref> [3, 37] </ref>. For a symmetric, positive definite elliptic problem, many good precon-ditioners are available. Supplemented by an additional coarse-mesh pre-conditioner, they may become good, sometimes optimal, preconditioners for nonsymmetric problems, as shown in [38].
Reference: [4] <author> J. H. Bramble and J. E. Pasciak, </author> <title> Preconditioned iterative methods for nonselfadjoint or indefinite elliptic boundary value problems, in Unification of Finite Elements, </title> <editor> H. Kardestuncer, ed., </editor> <publisher> Elsevier Science Publishers B. B., North-Holland (1984) 167-184. </publisher>
Reference-contexts: Whereas experimental papers for symmetric problems, such as [20] and [25], predominantly played the role of verifying theory, in this paper we hope to stimulate it. Algorithms based on preconditioned iterative solution of the normal equations are beyond the scope of this paper, though they continue to undergo development <ref> [3, 4, 28, 31] </ref>. The outline of this paper is as follows. In Section 2, we describe five domain decomposition methods, their convergence properties, and related implementation issues. Some issues related to parallelism and parallel complexity are discussed in Section 3.
Reference: [5] <author> J. H. Bramble, J. E. Pasciak, and A. H. Schatz, </author> <title> The construction of preconditioners for elliptic problems by substructuring, I, </title> <journal> Math. Comp., </journal> <month> 47 </month> <year> (1986) </year> <month> 103-134. </month>
Reference-contexts: The three sequential solves shown are optionally followed by a relaxation step for the crosspoints on the fine-grid. 15 2.7. Substructuring algorithm (CGK) The CGK algorithm, developed in [9], was motivated by the tile algorithm of [22] and also the iterative substructuring algorithm of <ref> [5] </ref>. Its major differences relative to the tile algorithms are that it needs an extra set of interior solves and that the interface and interior solves are made independent of the coarse-grid problem. The first allows a proof of near-optimal convergence rate, and the second offers more flexible parallelization. <p> The independence of the coarse-grid problems from the others makes it possible to solve the coarse-grid problem on a collection of MIMD processors, while other processors perform interface and interior problems in parallel. The major difference between CGK and the BPS-I algorithm <ref> [5] </ref> for SPD systems is that the coarse-grid solve depends sequentially on the interface and interior solves in BPS-I. The price for the extra parallelism in CGK is that the convergence bound suffers an extra factor of (1 + ln (H=h)), as seen below. <p> Normally, parallelization can be accomplished only within each stage and not between the stages, which act as synchronization points. The counts of sequential stages for the six preconditioner algorithms introduced in the preceding section, as well as for the BPS (I) algorithm of <ref> [5] </ref>, are summarized in the Table 1. For convenience in providing a simplified parallel complexity analysis, focusing only on computer architecture-independent factors, we begin with the assumption that each subdomain is undivided in the mapping onto processors.
Reference: [6] <author> J. H. Bramble, J. E. Pasciak, J. Wang and J. Xu, </author> <title> Convergence estimates for product iterative methods with applications to domain decomposition and multigrid, </title> <journal> Math. Comp., </journal> <month> 57 </month> <year> (1991) </year> <month> 1-22. </month>
Reference-contexts: To obtain parallelism, one needs a good subdomain coloring strategy so that a set of independent subproblems can be introduced within each sequential step and the total number of sequential steps can be minimized. A detailed description of the algorithm and its theoretical aspects can be found in <ref> [6, 11, 27] </ref>. The coloring is realized as follows. Associated with the decomposition f j g, we define an undirected graph in which nodes represent the extended subregions and the edges intersections of the extended subregions.
Reference: [7] <author> X.- C. Cai, </author> <title> Some domain decomposition algorithms for nonselfadjoint elliptic and parabolic partial differential equations, </title> <type> Ph.D. thesis, </type> <institution> Courant Institute, </institution> <month> Sept. </month> <year> (1989). </year>
Reference-contexts: Additive Schwarz algorithm (ASM) An additive variant of the Schwarz alternating method was originally proposed in [13, 14, 30] for selfadjoint elliptic problems and extended to non-selfadjoint elliptic cases in <ref> [7, 10] </ref>. The idea is simply to give up the data dependency between the subproblems defined on subregions with different colors, as in going from Gauss-Seidel to Jacobi. <p> As proposed in [10], the following preconditioner is also optimal: ~ M 1 0 0 0 +(R N ) t ( ~ B h;N ) 1 R N : The ~ B h;i are those defined in the previous subsection. It has been shown <ref> [7, 10] </ref> that, in the piecewise linear finite element case, both preconditioners M 1 ASM are optimal under the same first two assumptions made for MSM in the sense that there exist two constants C ASM &gt; 0 and c ASM &gt; 0, which may be different for exact and inexact
Reference: [8] <author> X.- C. Cai, W. D. Gropp and D. E. Keyes, </author> <title> A comparison of some domain decomposition algorithms for nonsymmetric elliptic problems, in Fifth International Symposium on Domain Decomposition Methods for Partial Differential Equations, </title> <editor> D. E. Keyes, T. F. Chan, G. Meurant, J. S. Scroggs and R. G. Voigt, eds., </editor> <publisher> SIAM, </publisher> <address> Philadelphia (1992). </address>
Reference-contexts: Some issues related to parallelism and parallel complexity are discussed in Section 3. Section 4 contains numerical results for four different test problems, followed by some brief conclusions in Section 5. An early version of this work has appeared in an abridged proceedings form <ref> [8] </ref>. This paper completes and supersedes the earlier version. 3 2. Description of Algorithms In this section, we briefly describe all the algorithms under consideration. We give only the formulation used in our experiments but note here that each is representative of a class.
Reference: [9] <author> X.- C. Cai, W. D. Gropp and D. E. Keyes, </author> <title> Convergence rate estimate for a domain decomposition method, </title> <journal> Numer. Math., </journal> <month> 61 </month> <year> (1992) </year> <month> 153-169. </month>
Reference-contexts: The three sequential solves shown are optionally followed by a relaxation step for the crosspoints on the fine-grid. 15 2.7. Substructuring algorithm (CGK) The CGK algorithm, developed in <ref> [9] </ref>, was motivated by the tile algorithm of [22] and also the iterative substructuring algorithm of [5]. Its major differences relative to the tile algorithms are that it needs an extra set of interior solves and that the interface and interior solves are made independent of the coarse-grid problem. <p> This algorithm is analyzed in <ref> [9] </ref> for a piecewise linear finite element discretization in R 2 . The convergence rate degenerates logarithmically with the grid size.
Reference: [10] <author> X.- C. Cai and O. B. Widlund, </author> <title> Domain decomposition algorithms for indefinite elliptic problems, </title> <journal> SIAM J. Sci. Stat. Comp., </journal> <month> 13 </month> <year> (1992) </year> <month> 243-258. </month>
Reference-contexts: The block matrices with differing subscripts contain the h-scale coupling of the original discretization between points in the different sets. Following <ref> [10, 15] </ref>, we can obtain an overlapping decomposition of , denoted by f i ; i = 0; ; N g: For i 6= 0, we extend each i to a larger region 0 i which is cut off at the physical boundary of . <p> A somewhat disappointing experimental observation is that inexact solutions seem not to work well for the coarse grid solver. In fact, the existing theory for MSM [11], as well as the theory for ASM <ref> [10] </ref>, requires an exact solve on the coarse grid. In the piecewise linear finite element case, the convergence of MSR has been proved in [11], under certain assumptions. <p> Additive Schwarz algorithm (ASM) An additive variant of the Schwarz alternating method was originally proposed in [13, 14, 30] for selfadjoint elliptic problems and extended to non-selfadjoint elliptic cases in <ref> [7, 10] </ref>. The idea is simply to give up the data dependency between the subproblems defined on subregions with different colors, as in going from Gauss-Seidel to Jacobi. <p> Because of the lack of data dependency, the method is usually not to be recommended as a simple Richardson process, but as a preconditioner for some algebraic iterative methods of CG type. We denote by M ASM the preconditioning part of (2.9). Following <ref> [10] </ref> and using the notation of the previous subsection, we can define the inverse of the matrix M ASM , referred to as the additive Schwarz preconditioner, as M 1 0 0 0 +(R N ) t (B h;N ) 1 R N : The key ingredients for the success of <p> At each iteration, all subproblems are solved once. It is obvious that all subproblems are independent of each other and can therefore be solved in parallel. 11 To obtain an optimal convergence rate, one does not have to solve these subproblems exactly. As proposed in <ref> [10] </ref>, the following preconditioner is also optimal: ~ M 1 0 0 0 +(R N ) t ( ~ B h;N ) 1 R N : The ~ B h;i are those defined in the previous subsection. <p> As proposed in [10], the following preconditioner is also optimal: ~ M 1 0 0 0 +(R N ) t ( ~ B h;N ) 1 R N : The ~ B h;i are those defined in the previous subsection. It has been shown <ref> [7, 10] </ref> that, in the piecewise linear finite element case, both preconditioners M 1 ASM are optimal under the same first two assumptions made for MSM in the sense that there exist two constants C ASM &gt; 0 and c ASM &gt; 0, which may be different for exact and inexact
Reference: [11] <author> X.- C. Cai and O. B. Widlund, </author> <title> Multiplicative Schwarz algorithms for nonsymmetric and indefinite problems (1992) (SIAM J. </title> <journal> Numer Anal., </journal> <note> to appear). </note>
Reference-contexts: To obtain parallelism, one needs a good subdomain coloring strategy so that a set of independent subproblems can be introduced within each sequential step and the total number of sequential steps can be minimized. A detailed description of the algorithm and its theoretical aspects can be found in <ref> [6, 11, 27] </ref>. The coloring is realized as follows. Associated with the decomposition f j g, we define an undirected graph in which nodes represent the extended subregions and the edges intersections of the extended subregions. <p> A somewhat disappointing experimental observation is that inexact solutions seem not to work well for the coarse grid solver. In fact, the existing theory for MSM <ref> [11] </ref>, as well as the theory for ASM [10], requires an exact solve on the coarse grid. In the piecewise linear finite element case, the convergence of MSR has been proved in [11], under certain assumptions. <p> In fact, the existing theory for MSM <ref> [11] </ref>, as well as the theory for ASM [10], requires an exact solve on the coarse grid. In the piecewise linear finite element case, the convergence of MSR has been proved in [11], under certain assumptions. The rate of convergence is ku k s C MSR ! k h u h k A ; where C MSR &gt; 0 is a constant independent of h, H and J. The estimate holds in both two- and three-dimensional spaces.
Reference: [12] <author> T. F. Chan and D. E. Keyes, </author> <title> Interface preconditionings for domain-decomposed convection-diffusion operators, in Third International Symposium on Domain Decomposition Methods for Partial Differential Equations, </title> <editor> T. F. Chan, R. Glowinski, J. Periaux, and O. B. Widlund, eds., </editor> <publisher> SIAM, </publisher> <address> Philadelphia (1990). </address>
Reference-contexts: In our current implementation, every block in K EE has the form of the square root of the negative one-dimensional Laplacian along the interface, with size equal to the number of interior interface nodes. There are other possibilities for K EE (see, e.g., <ref> [12] </ref>) which better adapt the precondi-tioner to nonsymmetric and variable coefficient problems. <p> The nonoverlapping methods without interface correction do not behave well if the constant ffi is large with either discretization scheme. From comparing GK90 and GK91, we believe that this result is mostly caused by the 25 interface preconditioner. Experimentation with different flow directions in <ref> [12] </ref> showed that a skew orientation of the flow with respect to the interface was worse for the tangential preconditioner than either normal or tangential flow orientation. Meanwhile, the interface preconditioner employed in CGK makes no adaptation whatever to the presence or alignment of the convection terms.
Reference: [13] <author> M. Dryja, </author> <title> An additive Schwarz algorithm for two- and three- dimension finite element elliptic problems, in Domain Decomposition Methods for Partial Differential Equations II, </title> <editor> T. F. Chan, R. Glowinski, G. A. Meurant, J. Periaux, and O. B. Widlund, eds., </editor> <publisher> SIAM, </publisher> <address> Philadelphia (1989). </address> <month> 32 </month>
Reference-contexts: Additive Schwarz algorithm (ASM) An additive variant of the Schwarz alternating method was originally proposed in <ref> [13, 14, 30] </ref> for selfadjoint elliptic problems and extended to non-selfadjoint elliptic cases in [7, 10]. The idea is simply to give up the data dependency between the subproblems defined on subregions with different colors, as in going from Gauss-Seidel to Jacobi.
Reference: [14] <author> M. Dryja and O. B. Widlund, </author> <title> An additive variant of the alternating method for the case of many subregions, </title> <type> TR 339, </type> <institution> Dept. of Comp. Sci., Courant Institute (1987). </institution>
Reference-contexts: Additive Schwarz algorithm (ASM) An additive variant of the Schwarz alternating method was originally proposed in <ref> [13, 14, 30] </ref> for selfadjoint elliptic problems and extended to non-selfadjoint elliptic cases in [7, 10]. The idea is simply to give up the data dependency between the subproblems defined on subregions with different colors, as in going from Gauss-Seidel to Jacobi.
Reference: [15] <author> M. Dryja and O. B. Widlund, </author> <title> Towards a unified theory of domain decomposition algorithms for elliptic problems, in Third International Symposium on Domain Decomposition Methods for Partial Differential Equations, </title> <editor> T. F. Chan, R. Glowinski, J. Periaux, and O. B. Widlund, eds., </editor> <publisher> SIAM, </publisher> <address> Philadelphia (1990). </address>
Reference-contexts: The block matrices with differing subscripts contain the h-scale coupling of the original discretization between points in the different sets. Following <ref> [10, 15] </ref>, we can obtain an overlapping decomposition of , denoted by f i ; i = 0; ; N g: For i 6= 0, we extend each i to a larger region 0 i which is cut off at the physical boundary of .
Reference: [16] <author> M. Dryja and O. B. Widlund, </author> <title> Multilevel additive methods for elliptic finite element problems, in Parallel Algorithms for Partial Differential Equations, </title> <booktitle> Proceedings of the Sixth GAMM-Seminar, </booktitle> <address> Kiel, </address> <month> Jan. </month> <pages> 19-21, </pages> <editor> W. Hackbusch, ed., </editor> <address> Braunschweig, Ger-many (1991), </address> <publisher> Vieweg & Son. </publisher>
Reference-contexts: The ASM discussed in this subsection can be used recursively for the solving the subdomain problems. The result is the multilevel ASM, as developed in <ref> [2, 16, 39] </ref>. 2.5. Coarse grid plus SPD preconditioning (CSPD) The low-frequency modes of the error are the hardest to damp with nearly any iterative method. Therefore, a direct solver is usually employed on the 12 coarse grid, as in multigrid methods.
Reference: [17] <author> S. C. Eisenstat, H. C. Elman and M. H. Schultz, </author> <title> Variational iterative methods for nonsymmetric system of linear equations, </title> <journal> SIAM J. Numer. Anal., </journal> <month> 20 </month> <year> (1983) </year> <month> 345-357. </month>
Reference-contexts: It is the fine to-coarse grid restriction operator that is needed in any multigrid method. 2.2. GMRES for the preconditioned system The GMRES method, introduced in [32], is mathematically equivalent to the generalized conjugate residual (GCR) method <ref> [17] </ref> and can be used to solve the linear system of algebraic equations: P x = b; (2.4) where P is a nonsingular matrix, which may be nonsymmetric or indefinite, and b is a given vector in R n . <p> The m th iterate is thus x m = x 0 + z m . According to the theory of <ref> [17] </ref>, the rate of convergence of the GMRES method can be estimated by the ratio of the minimal eigenvalue of the symmetric part of the operator to the norm of the operator. <p> Those two quantities are defined by x6=0 [x; x] x6=0 jjjP xjjj jjjxjjj ; where [; ] is an inner product on R n that induces the norm jjjjjj. Following <ref> [17] </ref>, the rate of convergence can be characterized, not necessarily tightly, as follows: If c P &gt; 0, which means that the symmetric part of the operator P 6 is positive definite with respect to the inner product [; ], then the GMRES method converges and at the m th iteration,
Reference: [18] <author> H. C. Elman, </author> <title> A stability analysis of incomplete LU factorizations, </title> <journal> Math. Comp., </journal> <month> 47 </month> <year> (1986) </year> <month> 191-217. </month>
Reference-contexts: This is because ILU is sensitive to the signs and magnitudes of the coefficients of the nonsymmetric terms, as well as to the discretization parameter h. Some analysis was given in <ref> [18] </ref>. The central difference ILU results begin to deteriorate once the cell Peclet number, ffi h, exceeds 2 (which lies beyond the range of the upper part of Table 2). ILU results for a variable-coefficient test problem are included in Table 7 below. 4.3.
Reference: [19] <author> R. W. Freund and N. M. Nachtigal, </author> <title> QMR: A quasi-minimal residual method for non-Hermitian linear systems, </title> <journal> Numer. Math., </journal> <month> 60 </month> <year> (1991) </year> <month> 315-339. </month>
Reference-contexts: To fit the available memory, one is sometimes forced to use the k-step restarted GMRES method [32]. However, in this case neither an optimal convergence property nor even convergence is guaranteed. Methods generally less rapidly convergent per matrix-vector-multiply than GMRES have recently been devised <ref> [19, 34] </ref> in order to overcome this limitation. In our applications, we restrict ourselves to preconditioners sufficiently "strong" that the total number of GMRES iterations is relatively small, and therefore no restarting is required.
Reference: [20] <author> A. Greenbaum, C. Li and Z. Han, </author> <title> Parallelizing preconditioned conjugate gradient algorithms, </title> <journal> Comp. Phys. Comm., </journal> <month> 53 </month> <year> (1989) </year> <month> 295-309. </month>
Reference-contexts: In some cases the Galerkin results transfer immediately to finite difference discretizations, though this is less true for nonsymmetric problems than for symmetric. Whereas experimental papers for symmetric problems, such as <ref> [20] </ref> and [25], predominantly played the role of verifying theory, in this paper we hope to stimulate it. Algorithms based on preconditioned iterative solution of the normal equations are beyond the scope of this paper, though they continue to undergo development [3, 4, 28, 31].
Reference: [21] <author> W. D. Gropp and D. E. Keyes, </author> <title> Domain decomposition on parallel computers, Impact of Comp. </title> <institution> in Sci. and Eng., </institution> <month> 1 </month> <year> (1989) </year> <month> 421-439. </month>
Reference-contexts: For an extended discussion of the parallel communication complexity of domain decomposition algorithms for two-dimensional problems, see <ref> [21] </ref>. 4. Numerical Experiments In this section, we present some numerical results obtained by applying the aforementioned algorithms to ( u = 0 on @; 20 where different elliptic operators L will be specified and = [0; 1] fi [0; 1].
Reference: [22] <author> W. D. Gropp and D. E. Keyes, </author> <title> Domain decomposition with local mesh refinement, </title> <journal> SIAM J. Sci. Stat. Comp., </journal> <month> 13 </month> <year> (1992) </year> <month> 967-993. </month>
Reference-contexts: Tile algorithms (GK90/GK91) The tile algorithm, proposed in <ref> [22] </ref>, is designed especially for two-dimensional nonsymmetric problems and can be characterized as a nonoverlapping, multiplicative method. Numerical experiments indicate that the method converges at a rate that deteriorates logarithmically in the fine-mesh parameter, with the coarse-mesh size fixed. <p> W C is diagonal with all positive elements, all elements of W E are nonnegative, and their rows together sum to unity. A detailed description can be found in <ref> [22] </ref>. <p> Note that the second and third 14 steps are composed of completely independent subtasks on each interface and subdomain. It is observed in <ref> [22] </ref> that some additional saving can be achieved if M 1 GK is used as a right-preconditioner, because then a simple calculation shows that B h M 1 0 @ fl fl fl 1 A B I W E W C C where fl denotes a nonzero block. <p> The three sequential solves shown are optionally followed by a relaxation step for the crosspoints on the fine-grid. 15 2.7. Substructuring algorithm (CGK) The CGK algorithm, developed in [9], was motivated by the tile algorithm of <ref> [22] </ref> and also the iterative substructuring algorithm of [5]. Its major differences relative to the tile algorithms are that it needs an extra set of interior solves and that the interface and interior solves are made independent of the coarse-grid problem.
Reference: [23] <author> W. D. Gropp and D. E. Keyes, </author> <title> Parallel performance of domain-decomposed preconditioned Krylov methods for PDEs with adaptive refinement, </title> <journal> SIAM J. Sci. Stat. Comp., </journal> <month> 13 </month> <year> (1992) </year> <month> 128-145. </month>
Reference-contexts: Numerical experiments indicate that the method converges at a rate that deteriorates logarithmically in the fine-mesh parameter, with the coarse-mesh size fixed. This method has been tested for a large class of linear and nonlinear problems on various parallel machines <ref> [23] </ref>. Our tables include results labeled GK90 and GK91.
Reference: [24] <author> C. Johnson, U. Navert and J. Pitkaranta, </author> <title> Finite element methods for linear hyperbolic problems, </title> <journal> Comp. Meth. Appl. Mech. Eng., </journal> <month> 45 </month> <year> (1984) </year> <month> 285-312. </month>
Reference-contexts: Two finite difference discretizations are employed alternately for the first-order terms in (2.1), namely, the central and upwinding discretizations. In practice, there are many other discretization techniques such as the artificial diffusion and streamline diffusion methods <ref> [24] </ref> and the methods in [1]. Multiple discretizations can usefully be combined in the same iterative process; see, e.g., [26].
Reference: [25] <author> D. E. Keyes and W. D. Gropp, </author> <title> A comparison of domain decomposition techniques for elliptic partial differential equations and their parallel implementation, </title> <journal> SIAM J. Sci. Stat. Comput., </journal> <note> 8 (1987) s166-s202. </note>
Reference-contexts: In some cases the Galerkin results transfer immediately to finite difference discretizations, though this is less true for nonsymmetric problems than for symmetric. Whereas experimental papers for symmetric problems, such as [20] and <ref> [25] </ref>, predominantly played the role of verifying theory, in this paper we hope to stimulate it. Algorithms based on preconditioned iterative solution of the normal equations are beyond the scope of this paper, though they continue to undergo development [3, 4, 28, 31].
Reference: [26] <author> D. E. Keyes and W. D. Gropp, </author> <title> Domain-decomposable preconditioners for second-order upwind discretizations of multicomponent systems, </title> <editor> in R. Glowinski, Y. A. Kuznetsov, G. A. Meurant, J. Periaux, and O. B. Widlund, eds., </editor> <title> Fourth International Symposium on Domain Decomposition Methods for Partial Differential Equations, </title> <publisher> SIAM, </publisher> <address> Philadelphia (1991). </address>
Reference-contexts: In practice, there are many other discretization techniques such as the artificial diffusion and streamline diffusion methods [24] and the methods in [1]. Multiple discretizations can usefully be combined in the same iterative process; see, e.g., <ref> [26] </ref>. Our methods require a coarse grid over containing n 0 interior nodes, or crosspoints, fc k ; k = 1; ; n 0 g; we call this the H -level grid.
Reference: [27] <author> P. L. Lions, </author> <title> On the Schwarz alternating method. I, </title> <editor> in R. Glowinski, G. H. Golub, G. A. Meurant, and J. Periaux, eds., </editor> <title> First International Symposium on Domain Decomposition Methods for Partial Differential Equations, </title> <publisher> SIAM, </publisher> <address> Philadelphia (1988). </address>
Reference-contexts: To obtain parallelism, one needs a good subdomain coloring strategy so that a set of independent subproblems can be introduced within each sequential step and the total number of sequential steps can be minimized. A detailed description of the algorithm and its theoretical aspects can be found in <ref> [6, 11, 27] </ref>. The coloring is realized as follows. Associated with the decomposition f j g, we define an undirected graph in which nodes represent the extended subregions and the edges intersections of the extended subregions.
Reference: [28] <author> T. A. Manteuffel and S. V. Parter, </author> <title> Preconditioning and boundary conditions, </title> <journal> SIAM J. Numer. Anal., </journal> <month> 27 </month> <year> (1990) </year> <month> 656-694. </month>
Reference-contexts: Whereas experimental papers for symmetric problems, such as [20] and [25], predominantly played the role of verifying theory, in this paper we hope to stimulate it. Algorithms based on preconditioned iterative solution of the normal equations are beyond the scope of this paper, though they continue to undergo development <ref> [3, 4, 28, 31] </ref>. The outline of this paper is as follows. In Section 2, we describe five domain decomposition methods, their convergence properties, and related implementation issues. Some issues related to parallelism and parallel complexity are discussed in Section 3.
Reference: [29] <author> J. A. Meijerink and H. A. Van der Vorst, </author> <title> Guidelines for the usage of incomplete decompositions in the solving sets of linear equations as they occur in practical problems, </title> <journal> J. Comp. Phys., </journal> <month> 44 </month> <year> (1981) </year> <month> 134-155. </month>
Reference-contexts: Unfortunately, this is probably often the case for results reported in the literature for nonsymmetric elliptic problems; however, in many situations authors have no other practical recourse than to base convergence on (preconditioned) residual. Incomplete LU (ILU) decomposition <ref> [29] </ref> results are shown for zero, one, and two levels of fill [35]. Double precision is used throughout. Only machine-independent information, namely, the iteration count and true error as a function of iteration, is presented. Throughout this section, we use "ovlp" to denote the size of overlap.
Reference: [30] <author> S. V. Nepomnyaschikh, </author> <title> Domain decomposition and Schwarz methods in a subspace for the approximate solution of elliptic boundary value problems, </title> <type> Ph. D. Thesis, </type> <institution> Computing Center of the Siberian Branch of the USSR Academy of Sciences (1986). </institution>
Reference-contexts: Additive Schwarz algorithm (ASM) An additive variant of the Schwarz alternating method was originally proposed in <ref> [13, 14, 30] </ref> for selfadjoint elliptic problems and extended to non-selfadjoint elliptic cases in [7, 10]. The idea is simply to give up the data dependency between the subproblems defined on subregions with different colors, as in going from Gauss-Seidel to Jacobi.
Reference: [31] <author> S. V. Parter and S.-P. Wong, </author> <title> Preconditioning second order elliptic operators: condition numbers and the distribution of the singular values, </title> <journal> J. of Sci. Comp., </journal> <month> 6 </month> <year> (1991) </year> <month> 129-157. </month>
Reference-contexts: Whereas experimental papers for symmetric problems, such as [20] and [25], predominantly played the role of verifying theory, in this paper we hope to stimulate it. Algorithms based on preconditioned iterative solution of the normal equations are beyond the scope of this paper, though they continue to undergo development <ref> [3, 4, 28, 31] </ref>. The outline of this paper is as follows. In Section 2, we describe five domain decomposition methods, their convergence properties, and related implementation issues. Some issues related to parallelism and parallel complexity are discussed in Section 3.
Reference: [32] <author> Y. Saad and M. H. Schultz, </author> <title> GMRES: A generalized minimal residual algorithm for solving nonsymmetric linear systems, </title> <journal> SIAM J. Sci. Stat. Comp., </journal> <volume> 7 (1986) 865-869. </volume> <pages> 33 </pages>
Reference-contexts: the lack of a generally applicable dis-cretization technique for the general nonsymmetric elliptic operator, the lack of "good" algebraic iterative methods (such as CG for symmetric, positive definite problems), and the incompleteness of the mathematical theory for the performance of the algebraic iterative methods that do exist, such as GMRES <ref> [32] </ref>. By a "good" method, we mean a method that is provably convergent within memory requirements proportional to a small multiple of the number of degrees of freedom in the system, independent of the operator. <p> R 0 0 ( R 0 ), an n 0 fi n matrix, is somewhat special. It is the fine to-coarse grid restriction operator that is needed in any multigrid method. 2.2. GMRES for the preconditioned system The GMRES method, introduced in <ref> [32] </ref>, is mathematically equivalent to the generalized conjugate residual (GCR) method [17] and can be used to solve the linear system of algebraic equations: P x = b; (2.4) where P is a nonsingular matrix, which may be nonsymmetric or indefinite, and b is a given vector in R n . <p> The algorithm is parameter-free and quite robust. Its main disadvantage is its linear-in-m memory requirement. To fit the available memory, one is sometimes forced to use the k-step restarted GMRES method <ref> [32] </ref>. However, in this case neither an optimal convergence property nor even convergence is guaranteed. Methods generally less rapidly convergent per matrix-vector-multiply than GMRES have recently been devised [19, 34] in order to overcome this limitation. <p> Neither form of the tile algorithm requires an O (n) interpolation from the crosspoint to the subdomain interior degrees of freedom, or back again. The complexity of the GMRES method was analyzed in <ref> [32] </ref>. Since we consider only the five-point finite difference discretization, the action of the stiffness matrix on a given vector requires approximately 5n flops. In the sequential case, I steps of GMRES require I (I + 2)n + I (5n) multiplications.
Reference: [33] <author> B. F. Smith, </author> <title> A parallel implementation of an iterative substructuring algorithm for problems in three dimensions, in Fifth International Symposium on Domain Decomposition Methods for Partial Differential Equations, </title> <editor> D. E. Keyes, T. F. Chan, G. A. Meurant, J. S. Scroggs and R. G. Voigt, eds., </editor> <publisher> SIAM, </publisher> <address> Philadelphia (1992). </address>
Reference-contexts: For example, a few cycles of multigrid or a few Gauss-Seidel iterations perform well for some test problems, as in [2] or <ref> [33] </ref>. The crosspoint matrix is usually obtained by discretizing the original differential equation. Using an approximate operator in this case usually results in large iteration counts for our nonsymmetric problems, for reasons that are not yet explained theoretically.
Reference: [34] <author> H. A. Van der Vorst, </author> <title> Bi-CGSTAB: A more smoothly converging variant of CG-S for the solution of nonsymmetric linear systems, </title> <journal> SIAM J. Sci. Stat. Comp., </journal> <month> 13 </month> <year> (1992) </year> <month> 631-644. </month>
Reference-contexts: To fit the available memory, one is sometimes forced to use the k-step restarted GMRES method [32]. However, in this case neither an optimal convergence property nor even convergence is guaranteed. Methods generally less rapidly convergent per matrix-vector-multiply than GMRES have recently been devised <ref> [19, 34] </ref> in order to overcome this limitation. In our applications, we restrict ourselves to preconditioners sufficiently "strong" that the total number of GMRES iterations is relatively small, and therefore no restarting is required.
Reference: [35] <author> J. W. Watts, III, </author> <title> A conjugate gradient-truncated direct method for the iterative solution of the reservoir simulation equation, </title> <journal> Soc. of Petroleum Eng. J., </journal> <month> 21 </month> <year> (1981) </year> <month> 345-353. </month>
Reference-contexts: Incomplete LU (ILU) decomposition [29] results are shown for zero, one, and two levels of fill <ref> [35] </ref>. Double precision is used throughout. Only machine-independent information, namely, the iteration count and true error as a function of iteration, is presented. Throughout this section, we use "ovlp" to denote the size of overlap.
Reference: [36] <author> O. B. Widlund, </author> <title> Some Schwarz methods for symmetric and nonsymmetric elliptic problems, in Fifth International Symposium on Domain Decomposition Methods for Partial Differential Equations, </title> <editor> D. E. Keyes, T. F. Chan, G. A. Meurant, J. S. Scroggs and R. G. Voigt, eds., </editor> <publisher> SIAM, </publisher> <address> Philadelphia (1992). </address>
Reference-contexts: The ratio ovlp H is the same for each case along a diagonal, as tabulated in parentheses. This suggests that the iteration count depends only on the ratio ovlp H , but not on the actual mesh sizes h or H. This observation has recently been proved in <ref> [36] </ref>. The true error reduction curves corresponding to some entries of the H = 1=4, h = 128 column of Table 4 are given in Figure 3.
Reference: [37] <author> J. Xu, </author> <title> A new class of iterative methods for nonselfadjoint or indefinite problems, </title> <journal> SIAM J. Numer. Anal., </journal> <month> 29 </month> <year> (1992) </year> <month> 303-319. </month>
Reference-contexts: Other methods making special use of the coarse-grid matrix can also be found in <ref> [3, 37] </ref>. For a symmetric, positive definite elliptic problem, many good precon-ditioners are available. Supplemented by an additional coarse-mesh pre-conditioner, they may become good, sometimes optimal, preconditioners for nonsymmetric problems, as shown in [38].
Reference: [38] <author> J. Xu and X. - C. Cai, </author> <title> A preconditioned GMRES method for nonsymmetric or indefinite problems, </title> <journal> Math. Comp. </journal> <note> (1992) (to appear). </note>
Reference-contexts: Therefore, a direct solver is usually employed on the 12 coarse grid, as in multigrid methods. In the case of nonsymmetric problems, it is even more important to employ a direct coarse grid solver. Based on this observation, it is proved in <ref> [38] </ref> that a good preconditioner for B h can be constructed by combining a properly weighted coarse-grid matrix, obtained by discretizing the original nonsymmetric elliptic operator, and some local symmetric positive definite matrices, obtained by discretizing the symmetric positive definite part of the elliptic operator. <p> Other methods making special use of the coarse-grid matrix can also be found in [3, 37]. For a symmetric, positive definite elliptic problem, many good precon-ditioners are available. Supplemented by an additional coarse-mesh pre-conditioner, they may become good, sometimes optimal, preconditioners for nonsymmetric problems, as shown in <ref> [38] </ref>. More precisely, let ~ A h be a spectrally equivalent symmetric, positive definite preconditioner for A h , which is in turn the symmetric, positive definite part of B h . <p> In our numerical experiments, which use (2.15) in (2.14), the choice of ! = 1:0 is acceptable. The issue of finding the optimal ! in the general case is not fully understood, but seems not to be critical. The coarse-grid-plus-SPD-preconditioner (CSPD) method was analyzed in <ref> [38] </ref>. Suppose that the minimal and maximal eigenvalues of the precondi tioned symmetric, positive definite part ( ~ A h ) 1 A h are 0 and 1 . <p> Although the analysis given in <ref> [38] </ref> holds only in the A h inner product, and it is not known whether results similar to (2.16) and (2.17) hold in the Euclidean inner product, we again mention that all error and residual measurements behind Table 7 and Figure 7 are in L 2 . 2.6.
Reference: [39] <author> X. Zhang, </author> <title> Multilevel additive Schwarz methods, </title> <institution> CS-TR-2894 (UMIACS-TR-92-52), Dept. of Comp. Sci., University of Maryland (1992), </institution> <note> to appear in Numer. Math. 34 </note>
Reference-contexts: The ASM discussed in this subsection can be used recursively for the solving the subdomain problems. The result is the multilevel ASM, as developed in <ref> [2, 16, 39] </ref>. 2.5. Coarse grid plus SPD preconditioning (CSPD) The low-frequency modes of the error are the hardest to damp with nearly any iterative method. Therefore, a direct solver is usually employed on the 12 coarse grid, as in multigrid methods.
References-found: 39

