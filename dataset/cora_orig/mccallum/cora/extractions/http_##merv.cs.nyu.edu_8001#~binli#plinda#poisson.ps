URL: http://merv.cs.nyu.edu:8001/~binli/plinda/poisson.ps
Refering-URL: http://merv.cs.nyu.edu:8001/~binli/plinda/
Root-URL: http://www.cs.nyu.edu
Email: (jylee@math.ewha.ac.kr, jylee@cims.nyu.edu)  Karpjoo Jeong (jeong@mail.lns.cornell.edu, jeong@cs.nyu.edu)  
Title: A parallel Poisson solver using the fast multipole method on networks of workstations  
Author: June-Yub Lee 
Keyword: Keyword: Volume integral method, Fast direct Poissone solver, High order of accuracy, Adaptive quad-tree, Domain decomposition.  
Date: September 9, 1997  
Address: 120-750, KOREA,  Ithaca, NY14853  
Affiliation: Dept. of Math, Ewha Womans University, Seoul  Laboratory for Nuclear Studies, Cornell University,  
Abstract: We present a parallel Poisson solver on distributed computing environments. In the solver, the parallel implementation of the Fast Multipole Method (FMM) is designed to minimize amount of data communication and the number of data transfers and synchronizations. The experimental results show linear speedup, good load balancing, and reasonable performance under failure and demonstrate the viability of loosely coupled heterogeneous workstations for large scale scientific computations. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> T. F. Chan and D. C. Resasco, </author> <title> A domain-decomposed fast poisson solver on a rectangle, </title> <journal> SIAM J. Sci. Stat. Comput. </journal> <volume> 8(1) S14-26, </volume> <year> (1987). </year>
Reference-contexts: Solving the Poisson equation is generally computation-intensive and therefore, parallel processing becomes inevitable as a problem grows in size. In the last few decades, a great deal of effort has been directed at parallelizing numerical methods for the Poisson equation <ref> [1, 2, 3, 4] </ref>. In this paper, we present a parallel Poisson solver which can be used to solve large scale real world problems.
Reference: [2] <author> D. Lee, </author> <title> Fast parallel solution of the poisson equation on irregular domains, </title> <journal> Numer. </journal> <pages> Algorithms 8(2-4) 347-362, </pages> <year> (1994). </year>
Reference-contexts: Solving the Poisson equation is generally computation-intensive and therefore, parallel processing becomes inevitable as a problem grows in size. In the last few decades, a great deal of effort has been directed at parallelizing numerical methods for the Poisson equation <ref> [1, 2, 3, 4] </ref>. In this paper, we present a parallel Poisson solver which can be used to solve large scale real world problems.
Reference: [3] <author> U. Schumann and M. Strietzel, </author> <title> Parallel solution of tridiagonal systems for the poisson equation, </title> <journal> J. Sci. Comput. </journal> <volume> 10(2) 181-190, </volume> <year> (1995). </year> <note> 16 J.-Y. </note> <author> Lee and K. </author> <note> Jeong </note>
Reference-contexts: Solving the Poisson equation is generally computation-intensive and therefore, parallel processing becomes inevitable as a problem grows in size. In the last few decades, a great deal of effort has been directed at parallelizing numerical methods for the Poisson equation <ref> [1, 2, 3, 4] </ref>. In this paper, we present a parallel Poisson solver which can be used to solve large scale real world problems.
Reference: [4] <author> P. N. Swarztrauber and R. A. Sweet, </author> <title> Vector and parallel methods for the direct solution of poisson's equation, </title> <journal> J. Comput. Appl. Math. </journal> <pages> 27(1-2) 241-263, </pages> <year> (1989). </year>
Reference-contexts: Solving the Poisson equation is generally computation-intensive and therefore, parallel processing becomes inevitable as a problem grows in size. In the last few decades, a great deal of effort has been directed at parallelizing numerical methods for the Poisson equation <ref> [1, 2, 3, 4] </ref>. In this paper, we present a parallel Poisson solver which can be used to solve large scale real world problems.
Reference: [5] <author> L. Greengard and J.-Y. Lee, </author> <title> A direct adaptive poisson solver of arbitrary order accuracy, </title> <journal> J. Comput. Phys. </journal> <volume> 125 415-424, </volume> <year> (1996). </year>
Reference-contexts: Among currently available methods for solving the Poisson equation, we have chosen the direct, adaptive method <ref> [5] </ref> which solves the Poisson equation by directly evaluating the corresponding volume integral where the right-hand side f is defined on the leaf nodes of an adaptive quad-tree data structure. <p> Greengard and J.-Y. Lee <ref> [5] </ref>. At first glance, this integral approach seems to be less attractive in terms of computational cost and spatial parallelism since direct evaluation of an integral operator with global dependency is quite expensive ( O (N 2 ) work, where N is the number of points in the domain, vs. <p> In the FMM based sequential method <ref> [5] </ref>, there are three kinds of data dependency among l;k , l;k , and P M j : 1. The multipole expansion l;k of the node S l;k depends on the multipole expansions of the four children. l;k = d=0 2.
Reference: [6] <author> Canuto, M.Y. Hussaini, A. Quarteroni, and T.A. Zang, </author> <title> Spectral Methods in Fluid Dynamics, </title> <institution> Society for Industrial and Applied Mathematics, </institution> <address> Philadelphia, </address> <year> (1988). </year>
Reference-contexts: The method is based on a kind of domain decomposition or spectral element approach <ref> [6, 7] </ref>, in which local solutions are patched together using the Fast Multipole Method [8]. It allows a substantial amount of parallelism among intermediate steps, but also contains complicated data dependencies among them.
Reference: [7] <author> A. T. Patera, </author> <title> A spectral element method for fluid dynamics: laminar flow in a fluid expansion, </title> <journal> J. Comput. Phys. </journal> <volume> 54 468-488, </volume> <year> (1984). </year>
Reference-contexts: The method is based on a kind of domain decomposition or spectral element approach <ref> [6, 7] </ref>, in which local solutions are patched together using the Fast Multipole Method [8]. It allows a substantial amount of parallelism among intermediate steps, but also contains complicated data dependencies among them.
Reference: [8] <author> L. Greengard and V. Rokhlin, </author> <title> A fast algorithm for particle simulations, </title> <journal> J. Comput. Phys. </journal> <volume> 73 325-348, </volume> <year> (1987). </year>
Reference-contexts: The method is based on a kind of domain decomposition or spectral element approach [6, 7], in which local solutions are patched together using the Fast Multipole Method <ref> [8] </ref>. It allows a substantial amount of parallelism among intermediate steps, but also contains complicated data dependencies among them. <p> In this paper, we present a parallel algorithm for the Poisson equation and explain the implementation issues of a numerical algorithm on a distributed computing environment focusing on parallelization of the Fast Multipole Method <ref> [9, 8] </ref>. We address issues relevant to paralleliza-tion such as efficient data distribution, scheduling, and reliability which become more critical and challenging for distributed computing environments. The rest of this paper is organized as follows.
Reference: [9] <author> J. Carrier, L. Greegard, and V. Rokhlin, </author> <title> A fast adaptive multipole algorithm for particle simulation, </title> <note> SIAM J. </note> <institution> Sci. Stat. Comput. </institution> <month> 9(4) 669-686 </month> <year> (1987). </year>
Reference-contexts: In this paper, we present a parallel algorithm for the Poisson equation and explain the implementation issues of a numerical algorithm on a distributed computing environment focusing on parallelization of the Fast Multipole Method <ref> [9, 8] </ref>. We address issues relevant to paralleliza-tion such as efficient data distribution, scheduling, and reliability which become more critical and challenging for distributed computing environments. The rest of this paper is organized as follows.
Reference: [10] <author> F. W. Dorr, </author> <title> The direct solution of the discrete poisson equation on a rectangle, </title> <journal> SIAM Rev. </journal> <volume> 12 248-263, </volume> <year> (1970). </year>
Reference-contexts: There are quite a few approaches to this problem. The most standard of which are finite difference, finite element and spectral methods, but fast direct solvers <ref> [10] </ref>, relying on cyclic reduction or the fast Fourier transform (FFT), are limited to regular, tensor-product meshes.
Reference: [11] <author> C. Anderson, </author> <title> Domain decomposition techniques and the solution of poisson's equation in infinite domains, </title> <booktitle> In the Second International Symposium on Domain Decomposition methods pages 129-139, </booktitle> <year> (1987). </year>
Reference-contexts: For more complex discretizations, using finite difference or finite element methods, it is common to rely on iterative solution procedures, including multigrid and additive domain decomposition <ref> [11, 12] </ref>, which can easily be implemented on a parallel machine [13, 14]. Since the Laplacian is a (local) differential operator, a discretization point using such standard methods is coupled only to its nearest neighbors. This locality property has a two fold advantage in an iterative context.
Reference: [12] <author> A. Brandt, </author> <title> Multi-level adaptive solutions to boundary value problems, </title> <journal> Math. Comp. </journal> <volume> 31 330-390, </volume> <year> (1977). </year>
Reference-contexts: For more complex discretizations, using finite difference or finite element methods, it is common to rely on iterative solution procedures, including multigrid and additive domain decomposition <ref> [11, 12] </ref>, which can easily be implemented on a parallel machine [13, 14]. Since the Laplacian is a (local) differential operator, a discretization point using such standard methods is coupled only to its nearest neighbors. This locality property has a two fold advantage in an iterative context.
Reference: [13] <author> M. Griebel, </author> <title> Parallel domain-oriented multilevel methods, </title> <journal> SIAM J. Sci. Comput. </journal> <volume> 16(5) 1105-1125, </volume> <month> September </month> <year> (1995). </year>
Reference-contexts: For more complex discretizations, using finite difference or finite element methods, it is common to rely on iterative solution procedures, including multigrid and additive domain decomposition [11, 12], which can easily be implemented on a parallel machine <ref> [13, 14] </ref>. Since the Laplacian is a (local) differential operator, a discretization point using such standard methods is coupled only to its nearest neighbors. This locality property has a two fold advantage in an iterative context.
Reference: [14] <author> S. Kim, </author> <title> Parallel multidomain iterative algorithms for the helmbholtz wave equation, </title> <journal> Appl. Numer. Math. </journal> <volume> 17 411-429, </volume> <year> (1995). </year>
Reference-contexts: For more complex discretizations, using finite difference or finite element methods, it is common to rely on iterative solution procedures, including multigrid and additive domain decomposition [11, 12], which can easily be implemented on a parallel machine <ref> [13, 14] </ref>. Since the Laplacian is a (local) differential operator, a discretization point using such standard methods is coupled only to its nearest neighbors. This locality property has a two fold advantage in an iterative context.
Reference: [15] <author> N. Carriero and D. Gelernter, </author> <title> How to write parallel programs : a first course, </title> <publisher> MIT Press, </publisher> <address> Cambridge, </address> <year> (1992). </year>
Reference-contexts: Break even points are at K = 10 for single precision computation with p = 20 and K = 14 for double precision with p = 40. 3 Parallel Implementation Issues There are basically two approaches to parallel processing: shared memory and message passing <ref> [15] </ref>. <p> Since it is not easy to support fault tolerance through application code alone, we use a fault-tolerant computing system called "Persistent Linda" or PLinda [16, 17, 18] developed at New York University. PLinda is based on the shared memory Linda model <ref> [19, 15] </ref> and guarantees that shared memory called tuple space survives failure 1 . In the PLinda model, each process executes a series of steps (each step called an atomic action or transaction) that are guaranteed to run in the "all or nothing" manner.
Reference: [16] <author> K. Jeong, </author> <title> Fault-tolerant Parallel Processing Combining Linda, Checkpointing, and Transactions, </title> <type> PhD thesis, </type> <address> New York University, </address> <year> (1996). </year>
Reference-contexts: In this subsection, we explain how to extend the parallel algorithm in subsection 3.2. Since it is not easy to support fault tolerance through application code alone, we use a fault-tolerant computing system called "Persistent Linda" or PLinda <ref> [16, 17, 18] </ref> developed at New York University. PLinda is based on the shared memory Linda model [19, 15] and guarantees that shared memory called tuple space survives failure 1 .
Reference: [17] <author> K. Jeong and D. Shasha, Plinda 2.0: </author> <title> A transactional/checkpointing approach to fault tolerant linda, </title> <booktitle> In Proc. of the 13th International Symposium on Reliable Distributed Systems, </booktitle> <month> October </month> <year> (1994). </year>
Reference-contexts: In this subsection, we explain how to extend the parallel algorithm in subsection 3.2. Since it is not easy to support fault tolerance through application code alone, we use a fault-tolerant computing system called "Persistent Linda" or PLinda <ref> [16, 17, 18] </ref> developed at New York University. PLinda is based on the shared memory Linda model [19, 15] and guarantees that shared memory called tuple space survives failure 1 .
Reference: [18] <author> K. Jeong, D. Shasha, S. Talla, and P. Wyckoff, </author> <title> An approach to fault-tolerant parallel processing on intermittently idle, heterogeneous workstations, </title> <booktitle> In Proc. the 27th International Symposium on Fault Tolerant Computing, </booktitle> <month> June </month> <year> (1997). </year>
Reference-contexts: In this subsection, we explain how to extend the parallel algorithm in subsection 3.2. Since it is not easy to support fault tolerance through application code alone, we use a fault-tolerant computing system called "Persistent Linda" or PLinda <ref> [16, 17, 18] </ref> developed at New York University. PLinda is based on the shared memory Linda model [19, 15] and guarantees that shared memory called tuple space survives failure 1 .
Reference: [19] <author> N. Carriero, </author> <title> Implementing Tuple Space Machines, </title> <type> PhD thesis, </type> <institution> Yale University, Department of Computer Science, </institution> <year> (1987). </year>
Reference-contexts: Since it is not easy to support fault tolerance through application code alone, we use a fault-tolerant computing system called "Persistent Linda" or PLinda [16, 17, 18] developed at New York University. PLinda is based on the shared memory Linda model <ref> [19, 15] </ref> and guarantees that shared memory called tuple space survives failure 1 . In the PLinda model, each process executes a series of steps (each step called an atomic action or transaction) that are guaranteed to run in the "all or nothing" manner.
References-found: 19

