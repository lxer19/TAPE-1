URL: ftp://softlib.rice.edu/pub/CRPC-TRs/reports/CRPC-TR95554.ps.gz
Refering-URL: http://www.crpc.rice.edu/CRPC/softlib/TRs_online.html
Root-URL: 
Title: Parallel Mixed Integer Programming  
Author: Robert E. Bixby, William Cook, Alan Cox and Eva K. Lee 
Keyword: Parallelism; Mixed Integer Programming Abbreviated title: Parallel MIP code  
Address: New York, New York.  
Note: Supported in part by the Center for Research on Parallel Computation, Rice University, and by NSF Grants CCR-881504 and CCR-9407142 Research Institute for Discrete  Supported in part by postdoctoral fellowship from the Center for Research on Parallel Computation, and by NSF/NATO grant GER-9452935, NSF CAREER grant CCR-9501584  
Affiliation: Department of Computational and Applied Mathematics, Rice University, Houston, Texas.  Mathematics, University of Bonn, Bonn, Germany Department of Computer Sciences, Rice University, Houston, Texas Department of Industrial Engineering and Operations Research, Columbia University,  
Date: June 30, 1995  
Abstract: Numerical experiments for a parallel implementation of a branch-and-bound mixed 0/1 integer programming code are presented. Among its features, the code includes cutting-plane generation at the root node, and employs a new branching-variable selection rule within the search tree. The code runs on a loosely-coupled cluster of workstations using TreadMarks as the parallel software platform. Numerical tests were performed on all mixed 0/1 MIPLIB instances as well as two previously unsolved MIP instances, one arising from telecommunication networks and the other a multicommodity flow problem. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D. Applegate, R. E. Bixby, V. Chvatal and W. Cook, </author> <title> "The Traveling Salesman Problem," </title> <note> in preparation (1995). </note>
Reference-contexts: Two interesting features are that the code runs in parallel on a variety of architectures, including networks of workstations, and that it employs an apparently new branching rule called strong branching, which was developed as part of work on the traveling-salesman problem <ref> [1] </ref>. Other research that exploits parallelism in integer programming includes work on pure 0/1 problems [9], the traveling salesman problem [1], and general mixed integer programming [12]. <p> variety of architectures, including networks of workstations, and that it employs an apparently new branching rule called strong branching, which was developed as part of work on the traveling-salesman problem <ref> [1] </ref>. Other research that exploits parallelism in integer programming includes work on pure 0/1 problems [9], the traveling salesman problem [1], and general mixed integer programming [12]. In Canon and Hoffman [9], a complex branch-and-cut algorithm was run on a network of 9 DECstations, joined to form a "Local Area VAXcluster." Data, such as the global queue of active nodes, were shared through disk files. <p> The test set was a subset of those used in Crowder et al. [10]. In Applegate, Bixby, Chvatal and Cook <ref> [1] </ref>, the computations were very coarse-grained, with individual "tasks" often running for a large fraction of a day on the hardest instances. The parallelism, which employed a rather complex list of tasks, was implemented using the master-slave paradigm. Data were shared through message passing over TCP/IP sockets. <p> We note that CPLEX 3.0 implements a special routine for efficiently computing the L i and U i . A much more detailed study of strong branching is presented in <ref> [1] </ref>. 2.2.5 Reduced-cost Fixing and Heuristics Reduced-cost fixing refers to the fixing of variables to their upper or lower bounds by comparing their reduced-costs to the gap between a linear programming optimum and the current problem lower bound, the best known integral-feasible solution.
Reference: [2] <author> E. Balas, </author> <title> "Disjunctive Programming: Cutting Planes from logical conditions," in Nonlinear Programming 2 O. </title> <editor> L. Mangasarian et al., eds., </editor> <publisher> Academic Press, </publisher> <year> (1975b) </year> <month> 279-312. </month>
Reference-contexts: We have included only three kinds of cutting planes: disjunctive cuts, knapsack cuts, and a very restricted kind of clique cuts. These are discussed in the subsections that follow. 3 CPLEX is a registered trademark of CPLEX Optimization, Inc. 3 2.2.1 Disjunctive cuts Disjunctive cuts were introduced by Balas <ref> [2] </ref>, and their computational properties studied extensively in recent work by Balas, Ceria and Cornejols [3].
Reference: [3] <author> E. Balas, S. Ceria and G. Cornuejols, </author> <title> "A Lift-and-Project Cutting Plane Algorithm for Mixed 0/1 Programs," </title> <booktitle> MSRR 576 (1992), </booktitle> <institution> Carnegie Mellon University. </institution>
Reference-contexts: These are discussed in the subsections that follow. 3 CPLEX is a registered trademark of CPLEX Optimization, Inc. 3 2.2.1 Disjunctive cuts Disjunctive cuts were introduced by Balas [2], and their computational properties studied extensively in recent work by Balas, Ceria and Cornejols <ref> [3] </ref>.
Reference: [4] <author> E. Balas and E. Zemel, </author> <title> "facets of the knapsack polytope from minimal covers," </title> <note> SIAM Journal of Applied Mathematics 34 (1978) 119-148. </note>
Reference-contexts: If that results in a feasible solution with an objective value less than 1, we again obtain a violated cover. After identifying a violated cover, it is lifted (in both forward and reverse passes) <ref> [4, 20, 21] </ref>. We approximate the lifting coefficients by solving the linear programming relaxations of the corresponding lifting problems. 2.2.3 Clique Cuts We employ the following exact procedure to find lifted 2-covers.
Reference: [5] <author> R. E. Bixby, E.A. Boyd, S. S. Dadmehr and R. R. Indovina, </author> <title> "The MIPLIB Mixed Integer Programming Library," </title> <note> COAL Bulletin 22 (1993). </note>
Reference-contexts: 1 Introduction We report results for a rudimentary 0/1 mixed integer programming code, powerful enough to solve instances of real interest, including all the 0/1 problems in MIPLIB <ref> [5] </ref>, and at least two difficult, previously unsolved models.
Reference: [6] <author> R. E. Bixby and E. K. Lee, </author> <title> "Solving a Truck Dispatching Scheduling Problem Using Branch-and-Cut," </title> <institution> TR93-37 (1993), Department of Computational and Applied Mathematics, Rice University. </institution>
Reference-contexts: We use the term (primal) heuristic to refer broadly to heuristic procedures for constructing "good, approximately optimal" integral feasible solutions from available solutions that are in some sense "good," but fail to satisfy integrality. We incorporate an "adaptive" heuristic based on the heuristic used in <ref> [6] </ref>. At some node in the branch-and-bound tree, assume that an LP relaxation has been solved and that the optimal solution is fractional. The heuristic works as follows. If some problem lower bound is currently available, reduced-cost fixing is applied (as indicated above).
Reference: [7] <author> A. L. Brearley, G. Mitre and H. P. Williams, </author> <title> "Analysis of Mathematical programming problems prior to applying the simplex method," </title> <note> Mathematical Programming 5 (1975) 54-83. </note>
Reference-contexts: Finally we present computational results. 2 Basic Features of the Algorithm 2.1 Preprocessing Problem preprocessing has been shown to be a very effective way of improving integer programming formulations prior to and during branch-and-bound <ref> [7, 10, 15, 19] </ref>. Rather than writing our own preprocessor, we have simply employed the CPLEX 3.0 3 preprocessor, invoking it not only once, but repeatedly until no further reductions result.
Reference: [8] <author> J. B. Carter and J. K. Bennett and W. Zwaenepoel, </author> <title> "Implementation and Performance of Munin," </title> <booktitle> Proceedings of the 13th ACM Symposium on Operating Systems Principles, </booktitle> <year> (1991) </year> <month> 152-164. </month>
Reference-contexts: Data consistency is the guarantee that changes to shared memory variables get propagated to each processor before that processor tries to use the variable. Various techniques are used by TreadMarks to meet this challenge, including lazy release consistency [16] and a multiple-writer protocol <ref> [8] </ref>. Lazy release consistency is a novel algorithm that implements the release consistency memory model developed by Gharachorloo et al. [14]. From the programmer's standpoint, release consistency is identical to the traditional (hardware) multiprocessor shared-memory model, sequential consistency, if the data accesses by different processors are correctly synchronized.
Reference: [9] <author> T. L. Cannon and K. L. Hoffman, </author> <title> "Large-scaled 0/1 linear programming on distributed workstations," </title> <note> Annals of Operations Research 22 (1990) 181-217. </note>
Reference-contexts: Other research that exploits parallelism in integer programming includes work on pure 0/1 problems <ref> [9] </ref>, the traveling salesman problem [1], and general mixed integer programming [12]. In Canon and Hoffman [9], a complex branch-and-cut algorithm was run on a network of 9 DECstations, joined to form a "Local Area VAXcluster." Data, such as the global queue of active nodes, were shared through disk files. <p> Other research that exploits parallelism in integer programming includes work on pure 0/1 problems <ref> [9] </ref>, the traveling salesman problem [1], and general mixed integer programming [12]. In Canon and Hoffman [9], a complex branch-and-cut algorithm was run on a network of 9 DECstations, joined to form a "Local Area VAXcluster." Data, such as the global queue of active nodes, were shared through disk files. The test set was a subset of those used in Crowder et al. [10].
Reference: [10] <author> H. Crowder, E. L. Johnson and M. Padberg, </author> <title> "Solving large-scale zero-one linear programming problems," </title> <journal> Operations Research, </journal> <month> 31 </month> <year> (1983) </year> <month> 803-834. </month>
Reference-contexts: The test set was a subset of those used in Crowder et al. <ref> [10] </ref>. In Applegate, Bixby, Chvatal and Cook [1], the computations were very coarse-grained, with individual "tasks" often running for a large fraction of a day on the hardest instances. The parallelism, which employed a rather complex list of tasks, was implemented using the master-slave paradigm. <p> Finally we present computational results. 2 Basic Features of the Algorithm 2.1 Preprocessing Problem preprocessing has been shown to be a very effective way of improving integer programming formulations prior to and during branch-and-bound <ref> [7, 10, 15, 19] </ref>. Rather than writing our own preprocessor, we have simply employed the CPLEX 3.0 3 preprocessor, invoking it not only once, but repeatedly until no further reductions result. <p> The MIPLIB models for which we found it necessary to apply disjunctive cuts are set1* and modglob. 2.2.2 Knapsack cuts A commonly employed technique is to generate cutting planes by analyzing individual constraints. This approach was applied in <ref> [10] </ref>, for pure 0/1 problems, using the well-developed theory of knapsack polyhedra. One way of applying knapsack cuts to mixed 0/1 problems proceeds as follows. <p> In our procedure, violated covers are identified using a greedy approach on the nonzero fractional variables, in a fashion similar to that described in <ref> [10] </ref>. We approximate the optimal objective for the knapsack problem minf p X (1 x j )s j : j=1 by setting s j to 1 in nondecreasing order with respect to the ratios (1 x fl j )=a j , j = 1; : : : ; p.
Reference: [11] <author> D. Bienstock and O. Gunluk, </author> <title> "Computational Experience with a Difficult Mixed-Integer Multicommod-ity Flow Problem," </title> <note> Mathematical Programming 68 (1995) 213- 237. </note>
Reference-contexts: One was a multicommodity flow instance, supplied to us by Dan Bienstock, and the other was a telecommunication network problem. The former model included a significant number of non-trivial cutting planes (424 in total) added as a result of the research by Bienstock and Gunluk <ref> [11] </ref>. Let T n denote the time elapsed when n processors are used. In our tests, T n was always measured using "wall-clock" time, and was recorded starting from reading in the problem instance to the final shutdown of all processors after printing the solution.
Reference: [12] <author> J. Eckstein, </author> <title> "Parallel branch-and-bound algorithm for general integer programming on the CM-5," </title> <institution> TMC-257 (1993), Thinking Machines Corporation. </institution>
Reference-contexts: Other research that exploits parallelism in integer programming includes work on pure 0/1 problems [9], the traveling salesman problem [1], and general mixed integer programming <ref> [12] </ref>. In Canon and Hoffman [9], a complex branch-and-cut algorithm was run on a network of 9 DECstations, joined to form a "Local Area VAXcluster." Data, such as the global queue of active nodes, were shared through disk files. <p> The parallelism, which employed a rather complex list of tasks, was implemented using the master-slave paradigm. Data were shared through message passing over TCP/IP sockets. This code ran on heterogeneous networks of Unix workstations. Eckstein's code <ref> [12] </ref>, in contrast, was written for a specific, dedicated parallel computer, the Thinking Machines CM-5. His code also used message passing to share data.
Reference: [13] <author> J. J. Forrest and D. Goldfarb, </author> <title> "Steepest-Edge Simplex Algorithms for Linear Programming," </title> <note> Mathematical Programming 57 (1992) 341-374. </note>
Reference-contexts: the optimal basis for the LP relaxation, fix x i first to 0:0 and then to 1:0 and perform K iterations of the dual simplex method with steepest-edge pricing using as "normalizing" factors the L 2 norms of the rows of the basis inverse (option "dgradient 2" in CPLEX, see <ref> [13] </ref>). Let L i , U i , i 2 I, be the objective values that result from these simplex runs, where L i corresponds to fixing x i to 0:0 and U i to fixing it to 1.0.
Reference: [14] <author> K. Gharachorloo, D. Lenoski and J. Laudon, P. Gibbons, A. Gupta and J. Hennessy, </author> <title> "Memory Consistency and Event Ordering in Scalable Shared-Memory Multiprocessors," </title> <booktitle> Proceedings of the 17th Annual International Symposium on Computer Architecture, </booktitle> <address> SIGARCH90 (1990) 15-26. </address> <month> 20 </month>
Reference-contexts: Various techniques are used by TreadMarks to meet this challenge, including lazy release consistency [16] and a multiple-writer protocol [8]. Lazy release consistency is a novel algorithm that implements the release consistency memory model developed by Gharachorloo et al. <ref> [14] </ref>. From the programmer's standpoint, release consistency is identical to the traditional (hardware) multiprocessor shared-memory model, sequential consistency, if the data accesses by different processors are correctly synchronized. However, unlike sequential consistency, release consistency does not require data consistency at each write to shared memory.
Reference: [15] <author> K. L. Hoffman and M. Padberg, </author> <title> "Solving airline crew-scheduling problems by branch-and-cut," </title> <note> Man--agement Science 39 (1993) 657-682. </note>
Reference-contexts: Finally we present computational results. 2 Basic Features of the Algorithm 2.1 Preprocessing Problem preprocessing has been shown to be a very effective way of improving integer programming formulations prior to and during branch-and-bound <ref> [7, 10, 15, 19] </ref>. Rather than writing our own preprocessor, we have simply employed the CPLEX 3.0 3 preprocessor, invoking it not only once, but repeatedly until no further reductions result.
Reference: [16] <author> P. Keleher, A. Cox and W. Zwaenepoel, </author> <title> "Lazy Release Consistency for Software Distributed Shared Memory," </title> <booktitle> Proceedings of the 19th Annual International Symposium on Computer Architecture, </booktitle> <year> (1992) </year> <month> 13-21. </month>
Reference-contexts: Data consistency is the guarantee that changes to shared memory variables get propagated to each processor before that processor tries to use the variable. Various techniques are used by TreadMarks to meet this challenge, including lazy release consistency <ref> [16] </ref> and a multiple-writer protocol [8]. Lazy release consistency is a novel algorithm that implements the release consistency memory model developed by Gharachorloo et al. [14].
Reference: [17] <author> P. Keleher, A. Cox, S. Dwarkadas and W. Zwaenepoel, "TreadMarks: </author> <title> Distributed Memory on Standard Workstations and Operating Systems," </title> <booktitle> Proceedings of the 1994 Winter Usenix Conference, </booktitle> <year> (1994) </year> <month> 115-131 </month>
Reference-contexts: Portability and simplicity in our parallel implementation are achieved by using TreadMarks 1 . Tread-Marks <ref> [17] </ref> is a parallel programming system that allows distributed memory computing machines to be programmed as if they were shared memory machines.
Reference: [18] <author> K. Li and P. Hudak, </author> <title> "Memory Coherence in Shared Virtual Memory Systems," </title> <booktitle> ACM Transactions on Computer Systems 4 (1989) Vol 7, </booktitle> <pages> 229-239. </pages>
Reference-contexts: DSM enables processes running on different workstations to share data through a network-wide virtual memory, even though the hardware provided by the network lacks the capability for one workstation to access another workstation's physical memory <ref> [18] </ref>. For example, by a network.
Reference: [19] <author> L. A. Oley and R. J. Sjoquist, </author> <title> "Automatic reformulation of mixed and pure integers models to reduce solution time in APEX IV," </title> <note> SIGMAP Bulletin 32 (1983). </note>
Reference-contexts: Finally we present computational results. 2 Basic Features of the Algorithm 2.1 Preprocessing Problem preprocessing has been shown to be a very effective way of improving integer programming formulations prior to and during branch-and-bound <ref> [7, 10, 15, 19] </ref>. Rather than writing our own preprocessor, we have simply employed the CPLEX 3.0 3 preprocessor, invoking it not only once, but repeatedly until no further reductions result. <p> Rather than writing our own preprocessor, we have simply employed the CPLEX 3.0 3 preprocessor, invoking it not only once, but repeatedly until no further reductions result. In addition to applying standard linear programming (LP) reductions, also valid for integer programs, CPLEX applies "coefficient reduction" and "bound strengthening," see <ref> [19] </ref>. Statistics for the problems solved and the preprocessed versions are given in Table 1. We remark that, without preprocessing, our code could not solve the model mod011 from MIPLIB, and its performance was seriously affected in a number of other cases. 2.2 Cutting planes The basic algorithm is branch-and-bound.
Reference: [20] <author> L. A. Wolsey, </author> <title> "Faces for a linear inequality in 0-1 variables," </title> <note> Mathematical Programming 8 (1975) 165-178. </note>
Reference-contexts: If that results in a feasible solution with an objective value less than 1, we again obtain a violated cover. After identifying a violated cover, it is lifted (in both forward and reverse passes) <ref> [4, 20, 21] </ref>. We approximate the lifting coefficients by solving the linear programming relaxations of the corresponding lifting problems. 2.2.3 Clique Cuts We employ the following exact procedure to find lifted 2-covers.
Reference: [21] <author> E. Zemel, </author> <title> "Easily computable facets of the knapsack polytope," </title> <note> Mathematics of Operations Research 14 (1989) 760-764. </note>
Reference-contexts: If that results in a feasible solution with an objective value less than 1, we again obtain a violated cover. After identifying a violated cover, it is lifted (in both forward and reverse passes) <ref> [4, 20, 21] </ref>. We approximate the lifting coefficients by solving the linear programming relaxations of the corresponding lifting problems. 2.2.3 Clique Cuts We employ the following exact procedure to find lifted 2-covers.
References-found: 21

