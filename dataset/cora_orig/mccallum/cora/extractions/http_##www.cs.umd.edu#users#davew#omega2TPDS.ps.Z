URL: http://www.cs.umd.edu/users/davew/omega2TPDS.ps.Z
Refering-URL: http://www.cs.umd.edu/users/davew/pubs.html
Root-URL: 
Email: pugh@cs.umd.edu, (301)-405-2705 davew@cs.umd.edu, (301)-405-2726  
Title: Going beyond Integer Programming with the Omega Test to Eliminate False Data Dependences  
Author: William Pugh David Wonnacott 
Date: November 4, 1994  
Address: College Park, MD 20742 Univ. of Maryland, College Park, MD 20742  
Affiliation: Dept. of Computer Science Dept. of Computer Science Univ. of Maryland,  
Abstract: Array data dependence analysis methods currently in use generate false dependences that can prevent useful program transformations. These false dependences arise because the questions asked are conservative approximations to the questions we really should be asking. Unfortunately, the questions we really should be asking go beyond integer programming and require decision procedures for a subclass of Pres-burger formulas. In this paper, we describe how to extend the Omega test so that it can answer these queries and allow us to eliminate these false data dependences. We have implemented the techniques described here and believe they are suitable for use in production compilers. fl This work is supported by NSF grant CCR-9157384 and a Packard Fellowship.
Abstract-found: 1
Intro-found: 1
Reference: [BK89] <author> Vasanth Balasundaram and Ken Kennedy. </author> <title> A technique for summarizing data access and its use in parallelism enhancing transformations. </title> <booktitle> In ACM SIGPLAN'89 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 41-53, </pages> <year> 1989. </year>
Reference-contexts: Voevodin and Voevodin ([Voe92a], [Voe92b]) have also done work that is similar to Feautrier's. 4.8.2 Extending scalar data-flow methods Rosene [Ros90] extended standard scalar data flow analysis techniques by using Data Access Descriptors <ref> [BK89] </ref> to keep track of an approximation of the set of array elements that are defined, modified and/or 15 killed by each statement. Rosene only determines which levels carry a dependence, and doesn't calculate the dependence difference.
Reference: [Ble75] <author> W. W. Bledsoe. </author> <title> A new method for proving certain presburger formulas. In Advance Papers, </title> <booktitle> 4th Int. Joint Conference on Artif. Intell., </booktitle> <address> Tibilisi, Georgia, U.S.S.R, </address> <year> 1975. </year>
Reference-contexts: Once we have projected away y and z, we then compute the gist of the red equations with respect to the black equations. 8 3.4 Related Work Several authors have explored methods for using integer programming methods to decide subclasses of Presburger formulas <ref> [Ble75, Sho77, JM87] </ref>. The work of [Ble75, Sho77] cannot handle nested, alternating quantifiers. The work described in [JM87] can only handle constraints of the form v v 0 + c (for variables v and v 0 and constant c). <p> Once we have projected away y and z, we then compute the gist of the red equations with respect to the black equations. 8 3.4 Related Work Several authors have explored methods for using integer programming methods to decide subclasses of Presburger formulas [Ble75, Sho77, JM87]. The work of <ref> [Ble75, Sho77] </ref> cannot handle nested, alternating quantifiers. The work described in [JM87] can only handle constraints of the form v v 0 + c (for variables v and v 0 and constant c).
Reference: [Bra88] <author> Thomas Brandes. </author> <title> The importance of direct dependences for automatic parallelism. </title> <booktitle> In Proc of 1988 International Conference on Supercomputing, </booktitle> <pages> pages 407-417, </pages> <month> July </month> <year> 1988. </year>
Reference-contexts: needed per array access pair is under 1 ms on a SPARC IPX workstation ([PW92a, PW92b]) 4.8 Related Work In analyzing false array flow data dependences (caused by output dependences), there are two basic approaches: * Extend the pair-wise methods typically used for array data dependence to recognize array kills <ref> [Bra88, Rib90, Fea91, MAL92, MAL93] </ref>. * Extend scalar dataflow methods by recording which array sections are killed and/or defined [GS90, Ros90, Li92]. Both approaches have merits. <p> Both approaches have merits. Our work is an example of the first approach, and we believe it corrects several limitations and flaws in earlier work on that approach. 4.8.1 Extending pair-wise methods Brandes <ref> [Bra88] </ref> describes methods factoring out transitive dependences to determine "direct" dependences, and his work is similar to our computations for refinement, killing and covering. However, his methods do not apply if the dependence differences are coupled or the loop is non-rectangular. Ribas describes [Rib90] techniques to refine dependence distances.
Reference: [Coo72] <author> D. C. Cooper. </author> <title> Theorem proving in arithmetic with multiplication. </title> <editor> In B. Meltzer and D. Michie, editors, </editor> <booktitle> Machine Intelligence 7, </booktitle> <pages> pages 91-99. </pages> <publisher> American Elsevier, </publisher> <address> New York, </address> <year> 1972. </year>
Reference-contexts: Unfortunately, the questions we really should be asking go beyond integer programming and require decision procedures for a larger subclass of Presburger formulas <ref> [KK67, Coo72] </ref>. Presburger formulas are those that can be built by applying the first order logical connectives (:, ^, _, ), 8 and 9) to equality and inequality constraints on sums of integer variables and integer constants. <p> Presburger formulas are decidable, but the fastest known decision procedures that handle the full class take worst-case 2 2 2 O (n) time <ref> [Coo72, Opp78] </ref>. Our original work on the Omega test [Pug92] described efficient ways to answer the usual questions asked for dependence analysis. In this paper, we show how the Omega test can be extended so that it can be used to answer questions in a subclass of Presburger arithmetic.
Reference: [CP91] <author> D. Y. Cheng and D. M. Pase. </author> <title> An evaluation of automatic and interactive parallel programming tools. </title> <booktitle> In Supercomputing '91, </booktitle> <pages> pages 412-423, </pages> <month> November </month> <year> 1991. </year>
Reference-contexts: 1 Introduction Recent studies <ref> [HKK + 93, CP91] </ref> suggest that array data dependence testing analysis methods currently in use generate false dependences that can prevent useful program transformations. For the most part, these false dependences are not generated by the conservative nature of algorithms such as Banerjee's inequalities [SLY89, KPK90, May92].
Reference: [DE73] <author> G.B. Dantzig and B.C. Eaves. </author> <title> Fourier-Motzkin elimination and its dual. </title> <journal> Journal of Combinatorial Theory (A), </journal> <volume> 14 </volume> <pages> 288-297, </pages> <year> 1973. </year>
Reference-contexts: Only if both tests fail are we required to examine S 1 ; S 2 ; : : : ; S p . Also, when checking for integer solutions, we choose which variable to eliminate to avoid splintering when possible. 3.1 How the Omega test works Fourier-Motzkin variable elimination <ref> [DE73] </ref> eliminates a variable from a linear programming problem. Intuitively, Fourier-Motzkin variable elimination finds the n 1 dimensional shadow cast by an n dimensional object. Consider two constraints on z: a lower bound fi bz and an upper bound az ff (where a and b are positive integers).
Reference: [Fea91] <author> Paul Feautrier. </author> <title> Dataflow analysis of array and scalar references. </title> <journal> International Journal of Parallel Programming, </journal> <volume> 20(1), </volume> <month> February </month> <year> 1991. </year>
Reference-contexts: needed per array access pair is under 1 ms on a SPARC IPX workstation ([PW92a, PW92b]) 4.8 Related Work In analyzing false array flow data dependences (caused by output dependences), there are two basic approaches: * Extend the pair-wise methods typically used for array data dependence to recognize array kills <ref> [Bra88, Rib90, Fea91, MAL92, MAL93] </ref>. * Extend scalar dataflow methods by recording which array sections are killed and/or defined [GS90, Ros90, Li92]. Both approaches have merits. <p> While Ribas's definition is useful in the context of deriving VLSI designs, our definition is more appropriate for standard compiler optimizations. Paul Feautrier has described a more detailed form of analysis for array references <ref> [Fea91] </ref>. His methods are designed to produce exact information: for each read of an array element, he determines the precise statement and iteration which wrote the value. <p> His methods are much more expensive than ours (about 100fi more expensive) and work only for programs with a special static control structure (defined in <ref> [Fea91] </ref>). Maydan, Amarasinghe, and Lam ([MAL92, MAL93]) provide an efficient way of generating the information produced by Feautrier's technique under specific conditions. They also present evidence that and show that these specific conditions are frequently satisfied in real programs.
Reference: [GS90] <author> Thomas Gross and Peter Steenkiste. </author> <title> Structured dataflow analysis for arrays and its use in an optimizing compiler. </title> <journal> Software Practice and Experience, </journal> <volume> 20 </volume> <pages> 133-155, </pages> <month> February </month> <year> 1990. </year>
Reference-contexts: In analyzing false array flow data dependences (caused by output dependences), there are two basic approaches: * Extend the pair-wise methods typically used for array data dependence to recognize array kills [Bra88, Rib90, Fea91, MAL92, MAL93]. * Extend scalar dataflow methods by recording which array sections are killed and/or defined <ref> [GS90, Ros90, Li92] </ref>. Both approaches have merits. <p> Rosene's techniques have not been fully implemented. Thomas Gross and Peter Steenkiste describe <ref> [GS90] </ref> methods similar to that of Rosene. Gross and Steenkiste's work is not as thorough as that of Rosene's. However, they have implemented their approach, and obtained some experience with it. Zhiyuan Li [Li92] presents a technique for determining whether or not an array is privatizable.
Reference: [HKK + 93] <author> M. W. Hall, T. Karvey, K. Kennedy, N. McIntosh, K.S. McKinley, J. D. Oldham, M. Paleczny, and G. Roth. </author> <title> Experiences using the parascope editor: an interactive parallel programming tool. </title> <booktitle> In Principles and Practice of Parallel Programming, </booktitle> <month> April </month> <year> 1993. </year>
Reference-contexts: 1 Introduction Recent studies <ref> [HKK + 93, CP91] </ref> suggest that array data dependence testing analysis methods currently in use generate false dependences that can prevent useful program transformations. For the most part, these false dependences are not generated by the conservative nature of algorithms such as Banerjee's inequalities [SLY89, KPK90, May92].
Reference: [HP91] <author> M. Haghighat and C. Polychronopoulos. </author> <title> Symbolic dependence analysis for high-performance parallelizing compilers. </title> <booktitle> In Advances In Languages And Compilers for Parallel Processing, </booktitle> <month> August </month> <year> 1991. </year>
Reference-contexts: 8 (from program s141 of [LCD91]), which could not be handled by any compiler tested by [LCD91]. 5.1 Related Work Methods for incorporating assertions about invariant scalar variables into dependence analysis algorithms and producing queries to ask the user have been part of the compiler folklore for some time (see <ref> [HP91] </ref> for a recent discussion). However, previous work has not addressed how to ask concise questions given that some information is already known. Kathryn McKinley [McK90] describes how to handle index arrays in dependence analysis. Her work enumerates many typical cases and discusses how each can be handled.
Reference: [JM87] <author> Farnam Jahanian and Aloysius Ka-Lau Mok. </author> <title> A graph-theoretic approach for timing analysis and its implementation. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-36(8):961-975, </volume> <month> August </month> <year> 1987. </year>
Reference-contexts: Once we have projected away y and z, we then compute the gist of the red equations with respect to the black equations. 8 3.4 Related Work Several authors have explored methods for using integer programming methods to decide subclasses of Presburger formulas <ref> [Ble75, Sho77, JM87] </ref>. The work of [Ble75, Sho77] cannot handle nested, alternating quantifiers. The work described in [JM87] can only handle constraints of the form v v 0 + c (for variables v and v 0 and constant c). <p> The work of [Ble75, Sho77] cannot handle nested, alternating quantifiers. The work described in <ref> [JM87] </ref> can only handle constraints of the form v v 0 + c (for variables v and v 0 and constant c).
Reference: [KK67] <author> G. Kreisel and J. L. Krevine. </author> <title> Elements of Mathematical Logic. </title> <publisher> North-Holland Pub. Co., </publisher> <year> 1967. </year>
Reference-contexts: Unfortunately, the questions we really should be asking go beyond integer programming and require decision procedures for a larger subclass of Presburger formulas <ref> [KK67, Coo72] </ref>. Presburger formulas are those that can be built by applying the first order logical connectives (:, ^, _, ), 8 and 9) to equality and inequality constraints on sums of integer variables and integer constants.
Reference: [KP93] <author> Wayne Kelly and William Pugh. </author> <title> A framework for unifying reordering transformations. </title> <type> Technical Report CS-TR-3193, </type> <institution> Dept. of Computer Science, University of Maryland, College Park, </institution> <month> April </month> <year> 1993. </year>
Reference-contexts: We also describe experiences with an implementation of the methods described here that convince us that these techniques are suitable for use in production compilers. Many of the ideas described in this paper first appeared in [PW92a], and form the basis for additional work <ref> [PW93b, KP93] </ref>. A brief overview of this additional work is given in section 6. 2 Dependence Abstractions: Dependence Differences/Distances/Directions In this paper, we describe dependences with dependence differences. A dependence difference is defined by the difference in the loop index variables at the source and destination of the dependence. <p> To generate efficient code, we need to keep the loop bounds as simple as possible. By taking the gist of the constraints for a given level given the constraints that have been satisfied at outer levels, we can often generate simpler loop bounds. For more details, see <ref> [KP93] </ref>. 20 7 Availability An implementation of the Omega test is freely available for anonymous ftp from ftp.cs.umd.edu in the directory pub/omega.
Reference: [KPK90] <author> David Klappholz, Kleanthis Psarris, and Xiangyun Kong. </author> <title> On the perfect accuracy of an approximate subscript analysis test. </title> <booktitle> In Proc. of the 1990 International Conference on Supercomputing, </booktitle> <pages> pages 201-212, </pages> <month> November </month> <year> 1990. </year>
Reference-contexts: 1 Introduction Recent studies [HKK + 93, CP91] suggest that array data dependence testing analysis methods currently in use generate false dependences that can prevent useful program transformations. For the most part, these false dependences are not generated by the conservative nature of algorithms such as Banerjee's inequalities <ref> [SLY89, KPK90, May92] </ref>. These false dependences arise because the questions we ask of dependence analysis algorithms are conservative approximations to the questions we really should be asking (methods currently in use are unable to address the more complicated questions we should be asking).
Reference: [LCD91] <author> David Levine, David Callahan, and Jack Dongarra. </author> <title> A comparative study of automatic vectorizing compilers. </title> <type> Technical Report MCS-P218-0391, </type> <institution> Argonne National Laboratory, </institution> <month> April </month> <year> 1991. </year>
Reference-contexts: By adding additional algorithms that perform non-linear induction variable recognition and recognize summations and by knowning appropriate linear constraints on summations, these techniques allow us to handle Example 8 (from program s141 of <ref> [LCD91] </ref>), which could not be handled by any compiler tested by [LCD91]. 5.1 Related Work Methods for incorporating assertions about invariant scalar variables into dependence analysis algorithms and producing queries to ask the user have been part of the compiler folklore for some time (see [HP91] for a recent discussion). <p> By adding additional algorithms that perform non-linear induction variable recognition and recognize summations and by knowning appropriate linear constraints on summations, these techniques allow us to handle Example 8 (from program s141 of <ref> [LCD91] </ref>), which could not be handled by any compiler tested by [LCD91]. 5.1 Related Work Methods for incorporating assertions about invariant scalar variables into dependence analysis algorithms and producing queries to ask the user have been part of the compiler folklore for some time (see [HP91] for a recent discussion).
Reference: [Li92] <author> Zhiyuan Li. </author> <title> Array privatization for parallel execution of loops. </title> <booktitle> In Proc. of the 1992 International Conference on Supercomputing, </booktitle> <pages> pages 313-322, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: In analyzing false array flow data dependences (caused by output dependences), there are two basic approaches: * Extend the pair-wise methods typically used for array data dependence to recognize array kills [Bra88, Rib90, Fea91, MAL92, MAL93]. * Extend scalar dataflow methods by recording which array sections are killed and/or defined <ref> [GS90, Ros90, Li92] </ref>. Both approaches have merits. <p> Rosene's techniques have not been fully implemented. Thomas Gross and Peter Steenkiste describe [GS90] methods similar to that of Rosene. Gross and Steenkiste's work is not as thorough as that of Rosene's. However, they have implemented their approach, and obtained some experience with it. Zhiyuan Li <ref> [Li92] </ref> presents a technique for determining whether or not an array is privatizable. His technique, like Rosene's, is based on computing approximations of the sets of array elements defined and used in the body of a loop.
Reference: [MAL92] <author> Dror E. Maydan, Saman P. Amarasinghe, and Monica S. Lam. </author> <title> Data dependence and data-flow analysis of arrays. </title> <booktitle> In 5th Workshop on Languages and Compilers for Parallel Computing (Yale University tech. report YALEU/DCS/RR-915), </booktitle> <pages> pages 283-292, </pages> <month> August </month> <year> 1992. </year>
Reference-contexts: needed per array access pair is under 1 ms on a SPARC IPX workstation ([PW92a, PW92b]) 4.8 Related Work In analyzing false array flow data dependences (caused by output dependences), there are two basic approaches: * Extend the pair-wise methods typically used for array data dependence to recognize array kills <ref> [Bra88, Rib90, Fea91, MAL92, MAL93] </ref>. * Extend scalar dataflow methods by recording which array sections are killed and/or defined [GS90, Ros90, Li92]. Both approaches have merits.
Reference: [MAL93] <author> Dror E. Maydan, Saman P. Amarasinghe, and Monica S. Lam. </author> <title> Array data-flow analysis and its use in array privatization. </title> <booktitle> In ACM '93 Conf. on Principles of Programming Languages, </booktitle> <month> January </month> <year> 1993. </year>
Reference-contexts: needed per array access pair is under 1 ms on a SPARC IPX workstation ([PW92a, PW92b]) 4.8 Related Work In analyzing false array flow data dependences (caused by output dependences), there are two basic approaches: * Extend the pair-wise methods typically used for array data dependence to recognize array kills <ref> [Bra88, Rib90, Fea91, MAL92, MAL93] </ref>. * Extend scalar dataflow methods by recording which array sections are killed and/or defined [GS90, Ros90, Li92]. Both approaches have merits.
Reference: [May92] <author> Dror Eliezer Maydan. </author> <title> Accurate Analysis of Array References. </title> <type> PhD thesis, </type> <institution> Computer Systems Laboratory, Stanford U., </institution> <month> September </month> <year> 1992. </year>
Reference-contexts: 1 Introduction Recent studies [HKK + 93, CP91] suggest that array data dependence testing analysis methods currently in use generate false dependences that can prevent useful program transformations. For the most part, these false dependences are not generated by the conservative nature of algorithms such as Banerjee's inequalities <ref> [SLY89, KPK90, May92] </ref>. These false dependences arise because the questions we ask of dependence analysis algorithms are conservative approximations to the questions we really should be asking (methods currently in use are unable to address the more complicated questions we should be asking).
Reference: [McK90] <author> Kathryn S. McKinley. </author> <title> Dependence analysis of arrays subscripted by index arrays. </title> <institution> Technical Report RICE COMP TR91-162, Dept. of Computer Science, Rice University, </institution> <month> December </month> <year> 1990. </year>
Reference-contexts: However, previous work has not addressed how to ask concise questions given that some information is already known. Kathryn McKinley <ref> [McK90] </ref> describes how to handle index arrays in dependence analysis. Her work enumerates many typical cases and discusses how each can be handled. It is not a general purpose method and cannot handle cases such as array values in loop bounds or complicated subscripts of index arrays.
Reference: [Opp78] <author> D. Oppen. </author> <title> A 2 2 2 pn upper bound on the complexity of presburger arithmetic. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 16(3) </volume> <pages> 323-332, </pages> <month> July </month> <year> 1978. </year> <month> 22 </month>
Reference-contexts: Presburger formulas are decidable, but the fastest known decision procedures that handle the full class take worst-case 2 2 2 O (n) time <ref> [Coo72, Opp78] </ref>. Our original work on the Omega test [Pug92] described efficient ways to answer the usual questions asked for dependence analysis. In this paper, we show how the Omega test can be extended so that it can be used to answer questions in a subclass of Presburger arithmetic.
Reference: [Pug92] <author> William Pugh. </author> <title> The Omega test: a fast and practical integer programming algorithm for dependence analysis. </title> <journal> Communications of the ACM, </journal> <volume> 8 </volume> <pages> 102-114, </pages> <month> August </month> <year> 1992. </year>
Reference-contexts: Presburger formulas are decidable, but the fastest known decision procedures that handle the full class take worst-case 2 2 2 O (n) time [Coo72, Opp78]. Our original work on the Omega test <ref> [Pug92] </ref> described efficient ways to answer the usual questions asked for dependence analysis. In this paper, we show how the Omega test can be extended so that it can be used to answer questions in a subclass of Presburger arithmetic. <p> For normalized loops (which are used in all examples in this paper), this is equivalent to the traditional concept of dependence 3 distance. See [Pug93] for a more detailed discussion of these terms. The methods described in <ref> [Pug92] </ref> produce a summary of the possible dependence differences for a dependence, not taking into account the requirement that dependences point forward in time. This summary information is then filtered so as to only describe dependences that point forward in time. <p> We therefore apply our techniques to each dependence difference summary (our filtering and summarizing process ensures that we will always be able to describe each summary with a single conjuction of constraints). 3 Extending the Omega test The Omega test <ref> [Pug92] </ref> is an integer programming algorithm based on Fourier-Motzkin variable elimination. The basic operation supported by the Omega test is projection. Intuitively, the projection of a set of constraints is the shadow of a set of constraints. <p> The real shadow is a conservative approximation to the integer shadow of the set of constraints. In <ref> [Pug92] </ref>, we extended Fourier-Motzkin variable elimination to be an integer programming method. Even if afi bff, there may be no integer solution to z such that afi abz bff. However, if afi + (a 1)(b 1) bff, we know that an integer solution to z must exist. <p> Even if afi bff, there may be no integer solution to z such that afi abz bff. However, if afi + (a 1)(b 1) bff, we know that an integer solution to z must exist. This is the dark shadow of this pair of constraints (described in <ref> [Pug92] </ref>). The dark shadow is a pessimistic approximation to the integer shadow of the set of constraints. Note that if a = 1 or b = 1, the dark shadow and the real shadow are identical, and therefore also identical to the integer shadow. <p> There are cases when the real shadow contains integer points but the dark shadow does not. In this case, determining the existence of integer solutions to the original set of constraints requires the use of special case techniques, described in <ref> [Pug92] </ref>, that are almost never needed in practice. 3.2 Determining the validity of certain Presburger formulas Assume that p and q are propositions that can each be represented as a conjunction of linear equalities and inequalities. <p> We can determine the truthfulness of the following predicates: Is p a tautology? Trivial to check when p is a conjunction. Is p satisfiable? We can check this using techniques described in Section 3.1 and in <ref> [Pug92] </ref>. Is p ) q a tautology? This could not be efficiently answered using the techniques described in [Pug92], but can be efficiently answered in practice using techniques described in Section 3.3. <p> Is p satisfiable? We can check this using techniques described in Section 3.1 and in <ref> [Pug92] </ref>. Is p ) q a tautology? This could not be efficiently answered using the techniques described in [Pug92], but can be efficiently answered in practice using techniques described in Section 3.3. The projection transformation offered by the Omega test allows us to handle embeded existential qualifiers: :x (p) = (9x s:t: p). <p> In Example 4, there is a flow dependence carried by the inner loop iff 9L1; L2; L1 0 ; L2 0 s:t: x L1 = L1 0 n ^ 1 L2 &lt; L2 0 m ^ L1 = L1 0 x ^ L2 = y Using the techniques described in <ref> [Pug92] </ref> we can determine that this is equivalent to: x = 0 ^ 1 y &lt; m ^ 0 n. We could then allow the user to add assertions that would disprove the dependence. Assertions can easily be incorporated into the dependence tests.
Reference: [Pug93] <author> William Pugh. </author> <title> Definitions of dependence distance. </title> <journal> Letters on Programming Languages and Systems, </journal> <month> September </month> <year> 1993. </year>
Reference-contexts: A dependence difference is defined by the difference in the loop index variables at the source and destination of the dependence. For normalized loops (which are used in all examples in this paper), this is equivalent to the traditional concept of dependence 3 distance. See <ref> [Pug93] </ref> for a more detailed discussion of these terms. The methods described in [Pug92] produce a summary of the possible dependence differences for a dependence, not taking into account the requirement that dependences point forward in time.
Reference: [PW92a] <author> William Pugh and David Wonnacott. </author> <title> Eliminating false data dependences using the Omega test. </title> <booktitle> In SIG-PLAN Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 140-151, </pages> <address> San Francisco, California, </address> <month> June </month> <year> 1992. </year>
Reference-contexts: We also describe experiences with an implementation of the methods described here that convince us that these techniques are suitable for use in production compilers. Many of the ideas described in this paper first appeared in <ref> [PW92a] </ref>, and form the basis for additional work [PW93b, KP93]. A brief overview of this additional work is given in section 6. 2 Dependence Abstractions: Dependence Differences/Distances/Directions In this paper, we describe dependences with dependence differences. <p> Example 3 shows a loop with a flow dependence that can be refined (at the source) from (0+,1) to (0,1). Due to space limitations, we are unable to discuss the equations used to analyze refinement; they are given in <ref> [PW92a] </ref>. 4.5 Quick tests for when to check for the above We can often avoid performing the general tests described above by doing some quick tests based on the dependence difference/direction, as described in [PW92a]. 4.6 Testing Order We order our investigation of dependences by the number of loops containing both <p> limitations, we are unable to discuss the equations used to analyze refinement; they are given in <ref> [PW92a] </ref>. 4.5 Quick tests for when to check for the above We can often avoid performing the general tests described above by doing some quick tests based on the dependence difference/direction, as described in [PW92a]. 4.6 Testing Order We order our investigation of dependences by the number of loops containing both accesses, examining pairs with the greatest shared loop depth first. <p> It is possible to have M v = U v;r (using Ribas's terminology), without the dependence distance being constant (this is the case in Example 5 of <ref> [PW92a] </ref>). The error is that (6) in [Rib90] should include (y ffi i v;r (y)) 2 Int (A; b) and (7) in [Rib90] should include (x + ffi i v;r (x)) 2 Int (A; b). Ribas's Theorem holds only for iterations not near the beginning or end of any loop.
Reference: [PW92b] <author> William Pugh and David Wonnacott. </author> <title> Going beyond integer programming with the Omega test to eliminate false data dependences. </title> <type> Technical Report CS-TR-3191, </type> <institution> Dept. of Computer Science, University of Maryland, College Park, </institution> <month> December </month> <year> 1992. </year> <note> An earlier version of this paper appeared at the SIGPLAN PLDI'92 conference. </note>
Reference: [PW93a] <author> William Pugh and David Wonnacott. </author> <title> An evaluation of exact methods for analysis of value-based array data dependences. </title> <booktitle> In Sixth Annual Workshop on Programming Languages and Compilers for Parallel Computing, </booktitle> <address> Portland, OR, </address> <month> August </month> <year> 1993. </year>
Reference-contexts: We can combine these abilities, as well as any standard transformation of predicate calculus, to determine the validity of certain Presburger formulas. We have not attempted to formally capture the subclass of Presburger formulas we can answer efficiently. In <ref> [PW93a] </ref>, we give a procedure for simplifying arbitrary Presburger Formulas using the gist operation and other techniques (this procedure is, of course, not fast over the entire domain of Presburger arithmetic). <p> We can use the gist operation to reduce the number of constraints in the term that we negate, and thus perform the analysis reasonably efficiently. These techniques, and their use in detecting parallelism, are discussed in [PW93b]. In <ref> [PW93a] </ref>, we give a detailed comparison with other work in this area. 6.2 Code Generation We also make use of the gist operation when generating code for a loop that has been transformed using the framework described in ([KP93]).
Reference: [PW93b] <author> William Pugh and David Wonnacott. </author> <title> Static analysis of upper and lower bounds on dependences and parallelism. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <note> 1993. accepted for publication. </note>
Reference-contexts: We also describe experiences with an implementation of the methods described here that convince us that these techniques are suitable for use in production compilers. Many of the ideas described in this paper first appeared in [PW92a], and form the basis for additional work <ref> [PW93b, KP93] </ref>. A brief overview of this additional work is given in section 6. 2 Dependence Abstractions: Dependence Differences/Distances/Directions In this paper, we describe dependences with dependence differences. A dependence difference is defined by the difference in the loop index variables at the source and destination of the dependence. <p> We can use the gist operation to reduce the number of constraints in the term that we negate, and thus perform the analysis reasonably efficiently. These techniques, and their use in detecting parallelism, are discussed in <ref> [PW93b] </ref>. In [PW93a], we give a detailed comparison with other work in this area. 6.2 Code Generation We also make use of the gist operation when generating code for a loop that has been transformed using the framework described in ([KP93]).
Reference: [Rib90] <author> Hudson Ribas. </author> <title> Obtaining dependence vectors for nested-loop computations. </title> <booktitle> In Proc of 1990 International Conference on Parallel Processing, </booktitle> <address> pages II-212 II-219, </address> <month> August </month> <year> 1990. </year>
Reference-contexts: needed per array access pair is under 1 ms on a SPARC IPX workstation ([PW92a, PW92b]) 4.8 Related Work In analyzing false array flow data dependences (caused by output dependences), there are two basic approaches: * Extend the pair-wise methods typically used for array data dependence to recognize array kills <ref> [Bra88, Rib90, Fea91, MAL92, MAL93] </ref>. * Extend scalar dataflow methods by recording which array sections are killed and/or defined [GS90, Ros90, Li92]. Both approaches have merits. <p> However, his methods do not apply if the dependence differences are coupled or the loop is non-rectangular. Ribas describes <ref> [Rib90] </ref> techniques to refine dependence distances. <p> It is possible to have M v = U v;r (using Ribas's terminology), without the dependence distance being constant (this is the case in Example 5 of [PW92a]). The error is that (6) in <ref> [Rib90] </ref> should include (y ffi i v;r (y)) 2 Int (A; b) and (7) in [Rib90] should include (x + ffi i v;r (x)) 2 Int (A; b). Ribas's Theorem holds only for iterations not near the beginning or end of any loop. <p> It is possible to have M v = U v;r (using Ribas's terminology), without the dependence distance being constant (this is the case in Example 5 of [PW92a]). The error is that (6) in <ref> [Rib90] </ref> should include (y ffi i v;r (y)) 2 Int (A; b) and (7) in [Rib90] should include (x + ffi i v;r (x)) 2 Int (A; b). Ribas's Theorem holds only for iterations not near the beginning or end of any loop. Ribas uses a slightly different definition of "constant dependence distance" than we do.
Reference: [Ros90] <author> Carl Rosene. </author> <title> Incremental Dependence Analysis. </title> <type> PhD thesis, </type> <institution> Dept. of Computer Science, Rice University, </institution> <month> March </month> <year> 1990. </year>
Reference-contexts: In analyzing false array flow data dependences (caused by output dependences), there are two basic approaches: * Extend the pair-wise methods typically used for array data dependence to recognize array kills [Bra88, Rib90, Fea91, MAL92, MAL93]. * Extend scalar dataflow methods by recording which array sections are killed and/or defined <ref> [GS90, Ros90, Li92] </ref>. Both approaches have merits. <p> They also present evidence that and show that these specific conditions are frequently satisfied in real programs. Voevodin and Voevodin ([Voe92a], [Voe92b]) have also done work that is similar to Feautrier's. 4.8.2 Extending scalar data-flow methods Rosene <ref> [Ros90] </ref> extended standard scalar data flow analysis techniques by using Data Access Descriptors [BK89] to keep track of an approximation of the set of array elements that are defined, modified and/or 15 killed by each statement. Rosene only determines which levels carry a dependence, and doesn't calculate the dependence difference. <p> His use of Data Access Descriptors means that his techniques are approximate in situations in which our methods are exact. It should be possible to modify his tests to use integer programming constraints to define sets of array elements, but that would involve significant work beyond that described in <ref> [Ros90] </ref> (the Omega test could be used to represent array regions, but the Omega test cannot directly form the union of two sets of constraints). Rosene's techniques have not been fully implemented. Thomas Gross and Peter Steenkiste describe [GS90] methods similar to that of Rosene.
Reference: [Sho77] <author> Robert E. Shostak. </author> <title> On the sup-inf method for proving presburger formulas. </title> <journal> Journal of the ACM, </journal> <volume> 24(4) </volume> <pages> 529-543, </pages> <month> October </month> <year> 1977. </year>
Reference-contexts: Once we have projected away y and z, we then compute the gist of the red equations with respect to the black equations. 8 3.4 Related Work Several authors have explored methods for using integer programming methods to decide subclasses of Presburger formulas <ref> [Ble75, Sho77, JM87] </ref>. The work of [Ble75, Sho77] cannot handle nested, alternating quantifiers. The work described in [JM87] can only handle constraints of the form v v 0 + c (for variables v and v 0 and constant c). <p> Once we have projected away y and z, we then compute the gist of the red equations with respect to the black equations. 8 3.4 Related Work Several authors have explored methods for using integer programming methods to decide subclasses of Presburger formulas [Ble75, Sho77, JM87]. The work of <ref> [Ble75, Sho77] </ref> cannot handle nested, alternating quantifiers. The work described in [JM87] can only handle constraints of the form v v 0 + c (for variables v and v 0 and constant c).
Reference: [SLY89] <author> Z. Shen, Z. Li, and P. Yew. </author> <title> An emperical student of array subscripts and data dependences. </title> <booktitle> In Proc of 1989 International Conference on Parallel Processing, </booktitle> <month> August </month> <year> 1989. </year>
Reference-contexts: 1 Introduction Recent studies [HKK + 93, CP91] suggest that array data dependence testing analysis methods currently in use generate false dependences that can prevent useful program transformations. For the most part, these false dependences are not generated by the conservative nature of algorithms such as Banerjee's inequalities <ref> [SLY89, KPK90, May92] </ref>. These false dependences arise because the questions we ask of dependence analysis algorithms are conservative approximations to the questions we really should be asking (methods currently in use are unable to address the more complicated questions we should be asking).
Reference: [Voe92a] <author> Valentin V. Voevodin. </author> <booktitle> Mathematical Foundations of Parallel Computing. </booktitle> <publisher> World Scientific Publishers, </publisher> <year> 1992. </year> <booktitle> World Scientific Series in Computer Science, </booktitle> <volume> vol. </volume> <pages> 33. </pages>
Reference: [Voe92b] <author> Vladimir V. Voevodin. </author> <title> Theory and practice of parallelism detection in sequential programs. </title> <journal> Programming and Computer Software (Programmirovaniye), </journal> <volume> 18(3), </volume> <month> May </month> <year> 1992. </year>
Reference-contexts: Maydan, Amarasinghe, and Lam ([MAL92, MAL93]) provide an efficient way of generating the information produced by Feautrier's technique under specific conditions. They also present evidence that and show that these specific conditions are frequently satisfied in real programs. Voevodin and Voevodin ([Voe92a], <ref> [Voe92b] </ref>) have also done work that is similar to Feautrier's. 4.8.2 Extending scalar data-flow methods Rosene [Ros90] extended standard scalar data flow analysis techniques by using Data Access Descriptors [BK89] to keep track of an approximation of the set of array elements that are defined, modified and/or 15 killed by each
Reference: [Wol91] <author> Michael Wolfe. </author> <title> The tiny loop restructuring research tool. </title> <booktitle> In Proc of 1991 International Conference on Parallel Processing, </booktitle> <address> pages II-46 II-53, </address> <year> 1991. </year>
Reference-contexts: For more details, see [KP93]. 20 7 Availability An implementation of the Omega test is freely available for anonymous ftp from ftp.cs.umd.edu in the directory pub/omega. The directory contains a stand-alone implementation of the Omega test, papers describing the Omega test, and an implementation of Michael Wolfe's tiny tool <ref> [Wol91] </ref> augmented to use the Omega test as described in this paper. 8 Conclusions We have shown how the Omega test can be extended and utilized to answer a wide range of questions that previous analysis methods could not address.
Reference: [ZC91] <author> Hans Zima and Barbara Chapman. </author> <title> Supercompilers for Parallel and Vector Computers. </title> <publisher> ACM Press, </publisher> <year> 1991. </year> <month> 23 </month>
Reference-contexts: Our techniques also eliminate dead anti and output dependences, which has little semantic importance but can be useful in interactive environments (to reduce the amount of useless information displayed to the user). The following subsections give the formulae we use to eliminate dead dependences. Our notation (adapted from <ref> [ZC91] </ref>) is shown in Figure 1. These formulae need to enforce the constraint that one access precedes another (e.g. A (I) t C (I 00 )).
References-found: 35

