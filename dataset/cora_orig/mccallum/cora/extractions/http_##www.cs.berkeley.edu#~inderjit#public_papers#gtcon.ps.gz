URL: http://www.cs.berkeley.edu/~inderjit/public_papers/gtcon.ps.gz
Refering-URL: http://www.cs.berkeley.edu/~inderjit/
Root-URL: 
Title: Reliable Computation of the Condition Number of a Tridiagonal Matrix in O(n) Time  
Author: Inderjit S. Dhillon 
Keyword: Tridiagonal matrix, inverse, condition number, norm, overflow, underflow.  
Note: AMS subject classifications. 15A12, 15A60, 65F35.  
Date: August 20, 1997  
Address: San Jose, California  
Affiliation: IBM Almaden Research Center  
Abstract: We present one more algorithm to compute the condition number (for inversion) of a nfin tridiagonal matrix J in O(n) time. Previous O(n) algorithms for this task given by Higham in [17] are based on the tempting compact representation of the upper (lower) triangle of J 1 as the upper (lower) triangle of a rank-one matrix. However, they suffer from severe overflow and underflow problems, especially on diagonally dominant matrices. Our new algorithm avoids these problems and is as efficient as the earlier algorithms. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> E. Anderson, Z. Bai, C. Bischof, J. Demmel, J. Dongarra, J. Du Croz, A. Greenbaum, S. Hammarling, A. McKenney, S. Ostrouchov, and D. Sorensen. </author> <note> LAPACK Users' Guide (second edition). SIAM, Philadelphia, </note> <year> 1995. </year> <pages> 324 pages. </pages>
Reference-contexts: For the strongly diagonally dominant tridiagonal with a i = 1000, b i = c i = 1, all three algorithms outlined above fail when n is only 105. These over/underflow problems were recognized by Higham [17], [20, Section 14.5] and consequently the existing LAPACK version 2:0 <ref> [1] </ref> has software only to estimate the condition number of a general tridiagonal matrix using Hager's condition estimator [15, 19]. For positive definite tridiagonals, LAPACK does contain software to accurately compute the condition number. <p> The latter also appears to take O (n) time but our new algorithms are up to 3 times faster. These timing experiments were conducted on an IBM RS/6000 processor. 18 Matrix Type Description 1 Nonsymmetric random tridiagonal | each element is uniformly distributed in the interval <ref> [1; 1] </ref>. 2 Symmetric tridiagonal J = Q T DQ with Q random orthogonal and D diagonal with one element equal to 1 and all others equal to *. 3 Symmetric tridiagonal J = Q T DQ with Q random orthogonal and D diagonal with one element equal to * and
Reference: [2] <author> ANSI/IEEE, </author> <title> New York. IEEE Standard for Binary Floating Point Arithmetic, </title> <address> Std 754-1985 edition, </address> <year> 1985. </year>
Reference-contexts: If we choose x 1 = 1 then jy n j n and jx n j n1 . The overflow threshold in double precision IEEE arithmetic is 2 1023 10 308 <ref> [2] </ref>. When n = 540, n1 &gt; 10 308 and due to overflow all the above algorithms fail in double precision arithmetic. <p> It may no longer be true that J = L + D + U + or J = U D L but equality does hold for all entries except for those at or adjacent to any infinite pivot. The IEEE arithmetic standard <ref> [2] </ref> allows such computation to proceed without breakdown and thus, we do not have to worry about zero pivots. Expressions with 1 are not expensive to handle if done by the hardware, see [11] for a discussion. <p> Consider the matrix J = 1000 100 In its U DL decomposition, D (2) = 10 306 while D (1) is computed as D (1) = 1000 10 306 = 1000 10 310 : In IEEE double precision arithmetic, the above value overflows and D (1) is set to 1 <ref> [2] </ref>.
Reference: [3] <author> Edgar Asplund. </author> <title> Inverses of matrices fa ij g which satisfy a ij = 0 for j &gt; i + p. </title> <journal> Math. Scand., </journal> <volume> 7 </volume> <pages> 57-60, </pages> <year> 1959. </year>
Reference: [4] <author> S. O. Asplund. </author> <title> Finite boundary value problems solved by Green's matrix. </title> <journal> Math. Scand., </journal> <volume> 7 </volume> <pages> 49-56, </pages> <year> 1959. </year>
Reference-contexts: The information presented here does not necessarily reflect the position or the policy of the Government and no official endorsement should be inferred. 1 triangle of a rank-one matrix, which in turn is simply represented by the outer product of two vectors (see <ref> [4, 6, 17, 21] </ref> and Theorem 2.1 below). This property of the inverse may be exploited to compute kJ 1 k 1 and hence 1 (J), in O (n) time, see the beginning of Section 3 for details.
Reference: [5] <author> J. Barlow, </author> <year> 1996. </year> <title> private communication. </title>
Reference-contexts: For more on this problem, the interested reader is referred to [14, 23] and [12, Chapter 3]. As a way to find an optimal k, Jesse Barlow also independently discovered recurrences similar to (4.13), (4.14) and (4.15) <ref> [5] </ref>. 10 Numerical Results In this section, we present numerical results of our new algorithms and compare them with existing algo rithms. A variety of tridiagonal matrices listed in Table 2 forms our test-bed.
Reference: [6] <author> B. Bukhberger and G.A. Emel'yanenko. </author> <title> Methods of inverting tridiagonal matrices. </title> <journal> USSR Computat. Math. and Math. Phy., </journal> <volume> 13 </volume> <pages> 10-20, </pages> <year> 1973. </year>
Reference-contexts: The information presented here does not necessarily reflect the position or the policy of the Government and no official endorsement should be inferred. 1 triangle of a rank-one matrix, which in turn is simply represented by the outer product of two vectors (see <ref> [4, 6, 17, 21] </ref> and Theorem 2.1 below). This property of the inverse may be exploited to compute kJ 1 k 1 and hence 1 (J), in O (n) time, see the beginning of Section 3 for details.
Reference: [7] <author> L. S. DeJong. </author> <title> Towards a formal definition of numerical stability. </title> <journal> Numer. Math., </journal> <volume> 28 </volume> <pages> 211-220, </pages> <year> 1977. </year>
Reference-contexts: We have put small perturbations not only on the input but also on the output. This property is called mixed stability in <ref> [7] </ref> but note that our perturbations are relative ones. It is important to note that the backward perturbations for the LDU factorization differ from the ones for the U DL factorization. By (4.13), i is formed by a ratio of D + 's and D 's.
Reference: [8] <author> J. Demmel and A. McKenney. </author> <title> A test matrix generation suite. </title> <institution> Computer science dept. </institution> <type> technical report, </type> <institution> Courant Institute, </institution> <address> New York, NY, </address> <month> July </month> <year> 1989. </year> <note> (LAPACK Working Note #9). </note>
Reference-contexts: A variety of tridiagonal matrices listed in Table 2 forms our test-bed. The matrices of type 2-5 were obtained by Householder reduction of a random dense symmetric matrix that had the desired spectrum. See <ref> [8] </ref> for more on the generation of such matrices. The results given in Tables 3 and 4 support our claim that the algorithms in [17] are susceptible to severe overflow and underflow problems. However, they produce accurate answers when they don't suffer from such problems.
Reference: [9] <author> J. W. Demmel. </author> <title> The complexity of condition estimation. </title> <note> 1997. Submitted to J. of Complexity. </note>
Reference-contexts: The condition number of B, (B) = kBk kB 1 k; where k:k is a matrix norm, is one such measure. It has been conjectured that the cost of computing the condition number with guaranteed accuracy is nearly the same as solving the linear system itself <ref> [10, 9] </ref>. For a dense n fi n matrix B the cost of solving Bx = r is O (n 3 ), and the extra cost of computing the condition number accurately may be unacceptable.
Reference: [10] <author> James W. Demmel. </author> <title> Open problems in numerical linear algebra. </title> <type> IMA Preprint Series #961, </type> <institution> Institute for Mathematics and its Applications, University of Minnesota, Minneapolis, MN, USA, </institution> <month> April </month> <year> 1992. </year> <note> LAPACK Working Note 47. </note>
Reference-contexts: The condition number of B, (B) = kBk kB 1 k; where k:k is a matrix norm, is one such measure. It has been conjectured that the cost of computing the condition number with guaranteed accuracy is nearly the same as solving the linear system itself <ref> [10, 9] </ref>. For a dense n fi n matrix B the cost of solving Bx = r is O (n 3 ), and the extra cost of computing the condition number accurately may be unacceptable.
Reference: [11] <author> James W. Demmel and Xiaoye Li. </author> <title> Faster numerical algorithms via exception handling. </title> <journal> IEEE Trans. Comput., </journal> <volume> 43(8) </volume> <pages> 983-992, </pages> <year> 1994. </year>
Reference-contexts: The IEEE arithmetic standard [2] allows such computation to proceed without breakdown and thus, we do not have to worry about zero pivots. Expressions with 1 are not expensive to handle if done by the hardware, see <ref> [11] </ref> for a discussion. If i = 0, i.e. x i = 0 or y i = 0, then equation (4.3) or (4.13) cannot be used to compute i+1 even in exact arithmetic.
Reference: [12] <author> I. S. Dhillon. </author> <title> A New O(n 2 ) Algorithm for the Symmetric Tridiagonal Eigenvalue/Eigenvector Problem. </title> <type> PhD thesis, </type> <institution> University of California, Berkeley, California, </institution> <month> May </month> <year> 1997. </year> <note> Also available as Computer Science Division Technical Report No. UCB//CSD-97-971. </note>
Reference-contexts: See Meurant's survey article [22] for such formulae and more on the behavior of the inverse of a tridiagonal matrix. More recently, the diagonal of the inverse has been used to compute eigenvectors of a symmetric tridiagonal matrix <ref> [12, 23, 13, 14] </ref>. Section 9 briefly explains the connection to eigenvectors. 5 More Properties of the Inverse Consider the tridiagonal matrix J of even order with a i = 0 and b i = c i = 1 for all i. <p> For more on this problem, the interested reader is referred to [14, 23] and <ref> [12, Chapter 3] </ref>. As a way to find an optimal k, Jesse Barlow also independently discovered recurrences similar to (4.13), (4.14) and (4.15) [5]. 10 Numerical Results In this section, we present numerical results of our new algorithms and compare them with existing algo rithms.
Reference: [13] <author> I. S. Dhillon and B.N. Parlett. </author> <title> Orthogonal eigenvectors without Gram-Schmidt. </title> <note> 1997. in preparation. </note>
Reference-contexts: See Meurant's survey article [22] for such formulae and more on the behavior of the inverse of a tridiagonal matrix. More recently, the diagonal of the inverse has been used to compute eigenvectors of a symmetric tridiagonal matrix <ref> [12, 23, 13, 14] </ref>. Section 9 briefly explains the connection to eigenvectors. 5 More Properties of the Inverse Consider the tridiagonal matrix J of even order with a i = 0 and b i = c i = 1 for all i.
Reference: [14] <author> K. V. Fernando. </author> <title> On computing an eigenvector of a tridiagonal matrix part I: Basic results. </title> <journal> SIAM J. Matrix Anal. Appl., </journal> <volume> 18(4) </volume> <pages> 1013-1034, </pages> <month> October </month> <year> 1997. </year>
Reference-contexts: See Meurant's survey article [22] for such formulae and more on the behavior of the inverse of a tridiagonal matrix. More recently, the diagonal of the inverse has been used to compute eigenvectors of a symmetric tridiagonal matrix <ref> [12, 23, 13, 14] </ref>. Section 9 briefly explains the connection to eigenvectors. 5 More Properties of the Inverse Consider the tridiagonal matrix J of even order with a i = 0 and b i = c i = 1 for all i. <p> Often when the corresponding eigenvalue is sufficiently isolated, it suffices to choose k such that the (k; k) entry of (T ^ I) 1 has the largest absolute value among all diagonal elements of the inverse. For more on this problem, the interested reader is referred to <ref> [14, 23] </ref> and [12, Chapter 3]. As a way to find an optimal k, Jesse Barlow also independently discovered recurrences similar to (4.13), (4.14) and (4.15) [5]. 10 Numerical Results In this section, we present numerical results of our new algorithms and compare them with existing algo rithms.
Reference: [15] <author> W. W. Hager. </author> <title> Condition estimators. </title> <journal> SIAM J. Sci. Stat. Comput., </journal> <volume> 5 </volume> <pages> 311-316, </pages> <year> 1984. </year> <month> 21 </month>
Reference-contexts: For a dense n fi n matrix B the cost of solving Bx = r is O (n 3 ), and the extra cost of computing the condition number accurately may be unacceptable. In such cases, an estimate of the condition number may be obtained at a reduced cost <ref> [15, 18] </ref>. When the coefficient matrix J is tridiagonal, the linear system J x = r may be solved in O (n) time. The matrix J 1 is dense in general, and computation of (J ) by explicitly forming it would require O (n 2 ) time. <p> These over/underflow problems were recognized by Higham [17], [20, Section 14.5] and consequently the existing LAPACK version 2:0 [1] has software only to estimate the condition number of a general tridiagonal matrix using Hager's condition estimator <ref> [15, 19] </ref>. For positive definite tridiagonals, LAPACK does contain software to accurately compute the condition number.
Reference: [16] <author> N. J. Higham. </author> <title> Matrix condition numbers. M.Sc. </title> <type> thesis, </type> <institution> University of Manchester, </institution> <address> Manchester, England, </address> <year> 1983. </year>
Reference-contexts: Note that the structure of X is consistent with Theorem 2.1. 3 Unreliability of Earlier Algorithms In this section, we reproduce the three algorithms given in [17] and explain why they are unsatisfactory when implemented in finite precision. For more details on the algorithms see <ref> [16, 17] </ref>. <p> For more details on the operation counts for Higham's algorithms, the reader is referred to discussions of Algorithms 2, 3 and 5 in his M.Sc. thesis <ref> [16] </ref>. Recall that for our new algorithm we assumed that the factorizations in (4.6) and (4.7) exist. <p> Numerical results to show this are presented in the next section. In addition, this algorithm also works for tridiagonal matrices that are not unreduced, i.e., where some of the off-diagonal entries may be zero. None of the elaborate techniques used in <ref> [16, 17] </ref> are needed to handle this special case. As written, the algorithm requires IEEE arithmetic but it is easily modified to prevent overflow. In spite of the above precautions, Algorithm Nrminv Final1 can march dangerously close to the overflow and underflow thresholds.
Reference: [17] <author> N. J. Higham. </author> <title> Efficient algorithms for computing the condition number of a tridiagonal matrix. </title> <journal> SIAM J. Sci. Stat. Comput., </journal> <volume> 7 </volume> <pages> 150-165, </pages> <year> 1986. </year>
Reference-contexts: The information presented here does not necessarily reflect the position or the policy of the Government and no official endorsement should be inferred. 1 triangle of a rank-one matrix, which in turn is simply represented by the outer product of two vectors (see <ref> [4, 6, 17, 21] </ref> and Theorem 2.1 below). This property of the inverse may be exploited to compute kJ 1 k 1 and hence 1 (J), in O (n) time, see the beginning of Section 3 for details. <p> Note that the 1-norm of a matrix B = (fi ij ) is given by kBk 1 = max X jfi ij j; and that kBk 1 = kB T k 1 . In <ref> [17] </ref>, Higham gives three algorithms to compute kJ 1 k 1 in O (n) time for a general tridiagonal matrix J . However, all these algorithms suffer from severe overflow and underflow problems, especially on diagonally dominant matrices. <p> In this paper, we give a new algorithm that does not suffer from the above mentioned over/underflow problems. The new algorithm avoids such problems by computing sums of magnitudes of elements of the inverse itself. For positive definite J , Higham gives another algorithm in <ref> [17] </ref> that does not suffer from over/underflow problems and is shown to be backward stable. However this algorithm is entirely different from the algorithms for a general tridiagonal. Our new algorithm works for any tridiagonal and includes positive definite J as a special case. The paper is organized as follows. <p> The paper is organized as follows. In Section 2, we review the structure of the inverse of a tridiagonal matrix that enables computation of its norm in O (n) time. In Section 3, we present an outline of the algorithms given in <ref> [17] </ref> and show why they are unsuitable for general purpose use. We present the basic structure of our new algorithm in Section 4. This algorithm works under the assumption that all principal leading and trailing submatrices are nonsingular. <p> The key observation is that the nonsymmetric matrix J may be written as J = DT where D = diag (d i ) is as given above and T is symmetric. The result is then obtained by applying Theorem 2.2 to T 1 . See <ref> [17] </ref> for more details. tu When an off-diagonal entry is zero, it is easy to see that the "corresponding" block of the inverse is zero. <p> Note that the structure of X is consistent with Theorem 2.1. 3 Unreliability of Earlier Algorithms In this section, we reproduce the three algorithms given in <ref> [17] </ref> and explain why they are unsatisfactory when implemented in finite precision. For more details on the algorithms see [16, 17]. <p> Note that the structure of X is consistent with Theorem 2.1. 3 Unreliability of Earlier Algorithms In this section, we reproduce the three algorithms given in [17] and explain why they are unsatisfactory when implemented in finite precision. For more details on the algorithms see <ref> [16, 17] </ref>. <p> For the strongly diagonally dominant tridiagonal with a i = 1000, b i = c i = 1, all three algorithms outlined above fail when n is only 105. These over/underflow problems were recognized by Higham <ref> [17] </ref>, [20, Section 14.5] and consequently the existing LAPACK version 2:0 [1] has software only to estimate the condition number of a general tridiagonal matrix using Hager's condition estimator [15, 19]. For positive definite tridiagonals, LAPACK does contain software to accurately compute the condition number. <p> For positive definite tridiagonals, LAPACK does contain software to accurately compute the condition number. This is based on an alternate algorithm given by Higham in <ref> [17] </ref> that is special to the positive definite case. 4 The New Algorithm As we illustrated above, the vectors x, y, p and q that determine the inverse of a diagonally dominant matrix can be badly scaled. <p> This new algorithm, when implemented in finite precision, delivers correct answers on the examples of the previous section. It is also more efficient than the algorithms of <ref> [17] </ref>. In Table 1, we list the approximate operation counts in Algorithm Nrminv and compare them to Higham's algorithms. Note that neither U + nor L are used in Algorithm Nrminv and hence the corresponding division operations to compute them (see Figure 3) are not counted in Table 1. <p> However numerical experience, given in Section 10, indicates that the condition number is computed accurately despite element growth. It is an open problem to explain this phenomenon. We feel the situation is somewhat similar to Algorithms Higham 1 and Higham 2 that were outlined in Section 3. In <ref> [17] </ref>, Higham observes that when the latter algorithms do not over/underflow their answers are very accurate, but no error analysis has been able to explain this accuracy. <p> Underflow in computing i by (4.13) can cause similar problems. We now show how to overcome such overflow and underflow. Before doing so, we emphasize that the above over/underflow problems are not as severe as those in the algorithms of <ref> [17] </ref>. The discerning reader would have noticed that problems in the earlier algorithms are inevitable due to the explicit computation of the vectors x, y, p and q; see Section 3 for more details. There are two problems that we must address. <p> Numerical results to show this are presented in the next section. In addition, this algorithm also works for tridiagonal matrices that are not unreduced, i.e., where some of the off-diagonal entries may be zero. None of the elaborate techniques used in <ref> [16, 17] </ref> are needed to handle this special case. As written, the algorithm requires IEEE arithmetic but it is easily modified to prevent overflow. In spite of the above precautions, Algorithm Nrminv Final1 can march dangerously close to the overflow and underflow thresholds. <p> The matrices of type 2-5 were obtained by Householder reduction of a random dense symmetric matrix that had the desired spectrum. See [8] for more on the generation of such matrices. The results given in Tables 3 and 4 support our claim that the algorithms in <ref> [17] </ref> are susceptible to severe overflow and underflow problems. However, they produce accurate answers when they don't suffer from such problems. The new algorithms outlined in the previous section, Algorithm Nrminv Final1 and Algorithm Nrminv Final2, give accurate answers on all our test matrices. <p> The latter algorithms may be directly implemented to give reliable numerical software, and do not suffer from the inherent over/underflow prob lems of the earlier algorithms presented in <ref> [17] </ref>. Acknowledgements. I would like to thank Professors B.N.Parlett, J.W.Demmel and N.J.Higham for a careful reading of the manuscript and for many useful suggestions.
Reference: [18] <author> N. J. Higham. </author> <title> A survey of condition number estimation for triangular matrices. </title> <journal> SIAM Review, </journal> <volume> 29:575 596, </volume> <year> 1987. </year>
Reference-contexts: For a dense n fi n matrix B the cost of solving Bx = r is O (n 3 ), and the extra cost of computing the condition number accurately may be unacceptable. In such cases, an estimate of the condition number may be obtained at a reduced cost <ref> [15, 18] </ref>. When the coefficient matrix J is tridiagonal, the linear system J x = r may be solved in O (n) time. The matrix J 1 is dense in general, and computation of (J ) by explicitly forming it would require O (n 2 ) time.
Reference: [19] <author> N. J. Higham. </author> <title> FORTRAN codes for estimating the one-norm of a real or complex matrix, with appli cations to condition estimation. </title> <journal> ACM Trans. Math. Soft., </journal> <volume> 14(4) </volume> <pages> 381-396, </pages> <year> 1988. </year>
Reference-contexts: These over/underflow problems were recognized by Higham [17], [20, Section 14.5] and consequently the existing LAPACK version 2:0 [1] has software only to estimate the condition number of a general tridiagonal matrix using Hager's condition estimator <ref> [15, 19] </ref>. For positive definite tridiagonals, LAPACK does contain software to accurately compute the condition number. <p> Both the algorithms appear to be comparable in accuracy. In our numerical results, we have also included the current algorithm in LAPACK that estimates the condition number of a tridiagonal matrix <ref> [19] </ref>. This algorithm is guaranteed to give a lower bound on the condition number and extensive testing done in [19] indicates that its estimates are good approximations to the exact condition number in most cases. For all our test matrices, except one, the condition numbers are estimated accurately. <p> In our numerical results, we have also included the current algorithm in LAPACK that estimates the condition number of a tridiagonal matrix <ref> [19] </ref>. This algorithm is guaranteed to give a lower bound on the condition number and extensive testing done in [19] indicates that its estimates are good approximations to the exact condition number in most cases. For all our test matrices, except one, the condition numbers are estimated accurately. The only exception is the Toeplitz matrix with 0 on the diagonals and 1 on the off-diagonals, see Table 4. <p> For all our test matrices, except one, the condition numbers are estimated accurately. The only exception is the Toeplitz matrix with 0 on the diagonals and 1 on the off-diagonals, see Table 4. This example is similar to the one given in <ref> [19, p.386] </ref>, and LAPACK's condition estimator underestimates its condition number by a factor of n=2 for n = 200. In Table 5, we compare the times taken by our new algorithms with LAPACK's condition estimator.
Reference: [20] <author> N. J. Higham. </author> <title> Accuracy and stability of numerical algorithms. </title> <publisher> SIAM, </publisher> <year> 1996. </year>
Reference-contexts: However, all these algorithms suffer from severe overflow and underflow problems, especially on diagonally dominant matrices. The reason for these seemingly unavoidable problems is that the intermediate quantities computed by these algorithms can vary widely in scale <ref> [20] </ref>. In this paper, we give a new algorithm that does not suffer from the above mentioned over/underflow problems. The new algorithm avoids such problems by computing sums of magnitudes of elements of the inverse itself. <p> For the strongly diagonally dominant tridiagonal with a i = 1000, b i = c i = 1, all three algorithms outlined above fail when n is only 105. These over/underflow problems were recognized by Higham [17], <ref> [20, Section 14.5] </ref> and consequently the existing LAPACK version 2:0 [1] has software only to estimate the condition number of a general tridiagonal matrix using Hager's condition estimator [15, 19]. For positive definite tridiagonals, LAPACK does contain software to accurately compute the condition number.
Reference: [21] <author> I. Ikebe. </author> <title> On inverses of Hessenberg matrices. </title> <journal> Linear Algebra and its Applications, </journal> <volume> 24 </volume> <pages> 93-97, </pages> <year> 1979. </year>
Reference-contexts: The information presented here does not necessarily reflect the position or the policy of the Government and no official endorsement should be inferred. 1 triangle of a rank-one matrix, which in turn is simply represented by the outer product of two vectors (see <ref> [4, 6, 17, 21] </ref> and Theorem 2.1 below). This property of the inverse may be exploited to compute kJ 1 k 1 and hence 1 (J), in O (n) time, see the beginning of Section 3 for details. <p> Then two column vectors x and y exist such that the upper half of B 1 equals the upper half of xy T , i.e., (B 1 ) ik = x i y k for i k. Proof. See <ref> [21] </ref>. tu Let 2 6 6 6 a 1 c 1 0 b 2 a 3 : : : c n1 3 7 7 7 : (2.1) The tridiagonal matrix given above is said to be unreduced or irreducible if b i 6= 0 and c i 6= 0 for all
Reference: [22] <author> G. Meurant. </author> <title> A review on the inverse of symmetric tridiagonal and block tridiagonal matrices. </title> <journal> SIAM J. Mat. Anal. Appl., </journal> <volume> 13(3) </volume> <pages> 707-728, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: See Meurant's survey article <ref> [22] </ref> for such formulae and more on the behavior of the inverse of a tridiagonal matrix. More recently, the diagonal of the inverse has been used to compute eigenvectors of a symmetric tridiagonal matrix [12, 23, 13, 14].
Reference: [23] <author> B.N. Parlett and I.S. Dhillon. </author> <title> Fernando's solution to Wilkinson's problem: An application of double factorization. </title> <journal> Lin. Alg. Appl., </journal> <volume> 267 </volume> <pages> 247-279, </pages> <year> 1997. </year>
Reference-contexts: See Meurant's survey article [22] for such formulae and more on the behavior of the inverse of a tridiagonal matrix. More recently, the diagonal of the inverse has been used to compute eigenvectors of a symmetric tridiagonal matrix <ref> [12, 23, 13, 14] </ref>. Section 9 briefly explains the connection to eigenvectors. 5 More Properties of the Inverse Consider the tridiagonal matrix J of even order with a i = 0 and b i = c i = 1 for all i. <p> Other formulae that are computationally better than (5.21) may be found in Corollary 4 of <ref> [23] </ref>. Theorem 5.6 Let J be a nonsingular tridiagonal matrix of order n that permits the factorizations in (4.6) and (4.7). Then i (J 1 ) ii may be computed as 1 = D + (i) + D (i) J ii : (5.21) Proof. <p> Then i (J 1 ) ii may be computed as 1 = D + (i) + D (i) J ii : (5.21) Proof. See Theorem 2 and Corollary 3 of <ref> [23] </ref>. tu 9 6 Eliminating the assumptions In this section, we extend the algorithm outlined in Section 4 to handle breakdown of triangular factorization. The theory developed in the previous section leads to these extensions. <p> Often when the corresponding eigenvalue is sufficiently isolated, it suffices to choose k such that the (k; k) entry of (T ^ I) 1 has the largest absolute value among all diagonal elements of the inverse. For more on this problem, the interested reader is referred to <ref> [14, 23] </ref> and [12, Chapter 3]. As a way to find an optimal k, Jesse Barlow also independently discovered recurrences similar to (4.13), (4.14) and (4.15) [5]. 10 Numerical Results In this section, we present numerical results of our new algorithms and compare them with existing algo rithms.
Reference: [24] <author> G. W. Stewart. </author> <title> Introduction to Matrix Computations. </title> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1973. </year>
Reference-contexts: In our upcoming treatment we will extensively use the famous Cauchy-Binet formula B adj (B) = det (B) I (4.8) where adj (B) is the classical adjugate of B and is the transpose of the matrix of cofactors <ref> [24, p.402] </ref>, to get expressions for elements of B 1 . Since J is tridiagonal, (4.8) implies that i = x i y i = det (J) where J r:s denotes the principal submatrix of J in rows and columns r through s.
Reference: [25] <author> J. H. Wilkinson. </author> <title> The calculation of the eigenvectors of codiagonal matrices. </title> <journal> Computer J., </journal> <volume> 1 </volume> <pages> 90-96, </pages> <year> 1958. </year>
Reference-contexts: However, an arbitrary choice of k does not always work, as observed by Wilkinson in <ref> [25, 26] </ref>. Note that the pair ( ^ ; z k ) has the residual norm k (T ^ I)z k k = k (T ^ I) 1 e k k where we assume that ^ is not an exact eigenvalue of T .
Reference: [26] <author> J. H. Wilkinson. </author> <title> The Algebraic Eigenvalue Problem. </title> <publisher> Oxford University Press, Oxford, </publisher> <year> 1965. </year> <month> 22 </month>
Reference-contexts: However, an arbitrary choice of k does not always work, as observed by Wilkinson in <ref> [25, 26] </ref>. Note that the pair ( ^ ; z k ) has the residual norm k (T ^ I)z k k = k (T ^ I) 1 e k k where we assume that ^ is not an exact eigenvalue of T .
References-found: 26

