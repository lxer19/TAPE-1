URL: ftp://ife.ethz.ch/pub/music/paper/gordon.ps
Refering-URL: http://www.ife.ee.ethz.ch/music/music.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Entry for the 1992 Gordon Bell Prizes The MUSIC System (Multi Signalprocessor System with Intelligent Communication)  
Author: by Anton Gunzinger Urs Muller Walter Scott Bernhard Baumle Peter Kohler Florian Muller-Plathe Wilfred F. van Gunsteren and Walter Guggenbuhl 
Keyword: Category Price/Performance: Neural Nets Performance Price/Performance Peak performance 1800 MFlops 111 $/MFlops Back-propagation 870 MFlops 230 $/MFlops Mandelbrot 590 MFlops 339 $/MFlops Category Performance: Molecular Dynamics  
Abstract: This entry is for the 1992 Gordon Bell Prizes in the two categories: Price/Performance and Performance. The MUSIC system has a parallel distributed memory architecture based on digital signal processors (DSP). A system with 30 processor elements (PE) is operational. It has a peak performance of 1.8 GFlops, an electrical power consumption of 350 W (including forced air cooling) and fits into a 19 inch rack. The hardware price of this system is 40 000 US $ which means a selling price of approximately 200 000 US $. Beside the well-known Mandelbrot algorithm two real applications are at the moment implemented on the system and run error-free: the back-propagation algorithm for neural net simulations and MD Atom for simulations in the field Molecular Dynamics. A 60 PE, 3.6 GFlops system is under construction The peak performance as well as the sustained performances for the Mandelbrot and the back-propagation algorithms are given in the following table. For the price/performance ratio a selling price of 200 000 US $ is considered (see section 1). The performance in molecular dynamics (see section 3) is bench-marked for a 125 atom model with 1000 iteration steps and a 1000 atom model with 100 iteration steps. To the best of our knowledge, the MUSIC implementation is currently the fastest in the world. (The NEC SX-3 is a state of the art super computer and holds the former speed record) 125/1000 1000/100 MUSIC-10 1.3 seconds 3.8 seconds NEC SX-3 1.4 seconds 4.4 seconds and should become operational in summer 1992.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. R. Shively and L. J. Wu. </author> <title> Application and Packaging of the AT&T DSP3 Parallel Signal Processor. </title> <editor> In V. Cappellini and A. G. Constantinides, editors, </editor> <booktitle> Digital Signal Processing-91. </booktitle> <publisher> Elsevier, </publisher> <year> 1991. </year>
Reference-contexts: The managers of the different boards are connected by their transputer links and form a standard transputer network. References to related systems can be found in <ref> [1, 2, 3, 4] </ref>; further reading about MUSIC is found in [5, 6]. 2 2 Neural Net Simulation One major difficulty in the research of learning behaviour and learning algorithms of neural nets is the large computing time needed for simulations on digital computers.
Reference: [2] <author> N. Morgan, J. Beck, P. Kohn, J. Bilmes, E. Allman, and J. Beer. </author> <title> The rap: A Ring Array Processor for Layered Network Calculations. In International Conference On Application Specific Array Processors. </title> <publisher> IEEE Computer Society Press, </publisher> <year> 1990. </year>
Reference-contexts: The managers of the different boards are connected by their transputer links and form a standard transputer network. References to related systems can be found in <ref> [1, 2, 3, 4] </ref>; further reading about MUSIC is found in [5, 6]. 2 2 Neural Net Simulation One major difficulty in the research of learning behaviour and learning algorithms of neural nets is the large computing time needed for simulations on digital computers.
Reference: [3] <author> Michael Witbrock and Marco Zagha. </author> <title> An Implementation of Backpropagation Learning on GF11, a Large SIMD Parallel Computer. </title> <journal> Parallel Computing, </journal> (14):329-346, 1990. 
Reference-contexts: The managers of the different boards are connected by their transputer links and form a standard transputer network. References to related systems can be found in <ref> [1, 2, 3, 4] </ref>; further reading about MUSIC is found in [5, 6]. 2 2 Neural Net Simulation One major difficulty in the research of learning behaviour and learning algorithms of neural nets is the large computing time needed for simulations on digital computers. <p> That means that it allows almost any modification on the neural network structure and learning algorithm. Other implementations are much more restricted in this point. The IBM GF11 implementation (900 MCUPS) for instance <ref> [3] </ref> parallelizes over the training set. This method only allows batch-learning (no immediate weight update) which has the effect that the learning convergence is in many cases much slower. 3 3 Molecular Dynamics The program MDAtom is used for time discrete simulations of the dynamics of atomic fluids.
Reference: [4] <author> D. A. Pomerleau, G. Gusciora, D. Touretzky and H. Kung. </author> <title> Neural Network Simulation at Warp Speed: how we got 17 million connections per second. </title> <booktitle> In IEEE Int. Conf. on Neural Networks, </booktitle> <pages> pages 143-150, </pages> <address> San Diego CA, </address> <year> 1988. </year>
Reference-contexts: The managers of the different boards are connected by their transputer links and form a standard transputer network. References to related systems can be found in <ref> [1, 2, 3, 4] </ref>; further reading about MUSIC is found in [5, 6]. 2 2 Neural Net Simulation One major difficulty in the research of learning behaviour and learning algorithms of neural nets is the large computing time needed for simulations on digital computers.
Reference: [5] <author> Anton Gunzinger, Urs Muller, and Hansruedi Vonder Muhll. </author> <title> Architecture and Realization of a Multi Signalprocessor System. </title> <editor> In Amnon Aliphas, editor, </editor> <address> Berlin '91, </address> <pages> pages 242-249. </pages> <publisher> DSP Associates, </publisher> <year> 1991. </year>
Reference-contexts: The managers of the different boards are connected by their transputer links and form a standard transputer network. References to related systems can be found in [1, 2, 3, 4]; further reading about MUSIC is found in <ref> [5, 6] </ref>. 2 2 Neural Net Simulation One major difficulty in the research of learning behaviour and learning algorithms of neural nets is the large computing time needed for simulations on digital computers. This problem can be overcome by using parallel architectures like the implementation on MUSIC.
Reference: [6] <author> Anton Gunzinger and Urs Muller. </author> <title> Konzept und Bau einer Lernmaschine fur Neuronale Netze. </title> <journal> Bulletin SEV/VSE, </journal> <volume> 82(13) </volume> <pages> 27-32, </pages> <month> Juli </month> <year> 1991. </year>
Reference-contexts: The managers of the different boards are connected by their transputer links and form a standard transputer network. References to related systems can be found in [1, 2, 3, 4]; further reading about MUSIC is found in <ref> [5, 6] </ref>. 2 2 Neural Net Simulation One major difficulty in the research of learning behaviour and learning algorithms of neural nets is the large computing time needed for simulations on digital computers. This problem can be overcome by using parallel architectures like the implementation on MUSIC.
Reference: [7] <author> D. E. Rumelhart, G. E. Hinton, and R. J. Williams. </author> <title> Learning Internal Representation by Error Propagation. </title> <booktitle> In Parallel Distributet Processing: Explorations in the Microstructure of Cognition, </booktitle> <volume> volume 1, </volume> <pages> pages 318-362. </pages> <publisher> Bradford Books, </publisher> <address> Cambridge MA, </address> <year> 1986. </year>
Reference-contexts: It is implemented on many computers, which allows a comparison of MUSIC with other systems. To train the neural net, examples are needed which consist of selected input vectors and the desired corresponding output (target) vectors of the net. The most time consuming part of the algorithm <ref> [7] </ref> is given by (1) for the forward and (2,3) for the backward path (learning): o j = f ( i w new ji + ffi j o i with (2) ffi j = f 0 (a j ) k Each of the processor elements of the MUSIC system computes a
Reference: [8] <author> Wei-Ming Lin, Viktor K. Prasanna, and K. Wojtek Przytula. </author> <title> Algorithmic Mapping of Neural Network Models onto Parallel SIMD Machines. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 40(12) </volume> <pages> 1390-1401, </pages> <month> December </month> <year> 1991. </year>
Reference-contexts: To avoid the communication of the updated weights, which would lead to communication saturation very easily, two different weight subsets for the forward and the backward propagation are stored and updated on every processor element <ref> [8] </ref>. A single connection update demands a multiplication plus an addition in the forward (1) as well as in the backward path (3). The actual weight update (2) needs an additional multiplication and addition. The kernel part of the algorithm thus costs six floating point operations.
Reference: [9] <author> W. F. van Gunsteren and H. J. C. Berendsen. </author> <title> Molecular Dynamics Computer Simulations: Methodology, </title> <booktitle> Applications and Perspectives in Chemistry.Angewandte Chemie Int. </booktitle> <editor> Ed. Engl. </editor> <volume> 29(1990), </volume> <pages> pages 992-1023. </pages>
Reference: [10] <author> M. P. Allen and D. J. Tildesley. </author> <title> Computer Simulations of Liquids, </title> <publisher> Oxford University Press 1987 </publisher>
Reference: [11] <author> W. F. van Gunsteren, H. J. C. Berendsen, F. Colonna, D. Perahia, J.P. Hollenberg and D. </author> <title> Lellouch On Searching Neighbours in Computer Simulations of Macromolecular Systems J. </title> <journal> Comp. Chem. </journal> <volume> Vol. 5 No. </volume> <month> 3 272 -279 </month> <year> (1984) </year>
Reference-contexts: The MUSIC implementation is written in assembly language, as no compiler was available at the time of writing. The implementations on the NEC SX-3, the CRAY YMP, and the Sun-4 (IPX) were done by ourselves. We have considerable experience in implementing MD code on super computers <ref> [11] </ref> [12]. These implementations were written in FORTRAN and have been optimised for the respective hardware. As far as we know, these are the fastest implementations of MD Atom on super computers. The measured results of this comparison are given in the following table.
Reference: [12] <institution> Florian Muller-Plathe Parallelising a Molecular Dynamics Algorithm on a MultiProcessor Workstation Computer Physics Communications 61 285-293 (1990) 5 </institution>
Reference-contexts: The MUSIC implementation is written in assembly language, as no compiler was available at the time of writing. The implementations on the NEC SX-3, the CRAY YMP, and the Sun-4 (IPX) were done by ourselves. We have considerable experience in implementing MD code on super computers [11] <ref> [12] </ref>. These implementations were written in FORTRAN and have been optimised for the respective hardware. As far as we know, these are the fastest implementations of MD Atom on super computers. The measured results of this comparison are given in the following table.
References-found: 12

