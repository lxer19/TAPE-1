URL: http://www.umiacs.umd.edu/research/yaser/icpr94.ps.Z
Refering-URL: http://www.umiacs.umd.edu/users/lsd/pubs.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Recognizing Facial Expressions by Spatio-Temporal Analysis  
Author: Yaser Yacoob Larry Davis 
Address: College Park, MD 20742  
Affiliation: Computer Vision Laboratory University of Maryland  
Abstract: An approach for analysis and representation of facial dynamics for recognition of facial expressions from image sequences is proposed. The algorithms we develop utilize optical flow computation to identify the direction of rigid and non-rigid motions that are caused by human facial expressions. A mid-level symbolic representation that is motivated by linguistic and psychological considerations is developed. Recognizing six facial expressions, as well as eye blinking, are demonstrated on a collection of image sequences. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. Abdel-Mottaleb, R. Chellappa, and A. Rosen-feld, </author> <title> "Binocular motion stereo using MAP estimation", </title> <journal> IEEE CVPR, </journal> <pages> 321-327, </pages> <year> 1993. </year>
Reference-contexts: Lip actions have higher interpretation precedence than mouth corners actions and whole mouth actions have the highest interpretation precedence. 3.2 Computing basic actions The approach we use for optical flow computation is correlation-based and was recently proposed by Abdel Mottaleb et al. <ref> [1] </ref>. The flow magnitudes are first thresholded to reduce the effect of small motions probably due to noise. The motion vectors are then re-quantized into eight principle directions. The optical flow vectors are filtered using both spatial and temporal procedures that improve their coherence and continuity, respectively.
Reference: [2] <author> J.N. Bassili, </author> <title> "Emotion recognition: The role of facial movement and the relative importance of upper and lower areas of the face," </title> <journal> Journal of Personality and Social Psychology, </journal> <volume> Vol. 37, </volume> <pages> 2049-2059, </pages> <year> 1979. </year>
Reference-contexts: The set of all detected facial actions is used in the following section for recognizing facial expressions. 4 Recognizing facial expressions We have designed a rule based system that combines some of the expression descriptions from [3] and <ref> [2] </ref>. We divide every facial expression into three temporal parts: the beginning, epic and ending. Figure 3 shows the temporal parts of a `smile' model.
Reference: [3] <author> P. Ekman and W. Friesen, </author> <title> Unmasking the Face, </title> <publisher> Prentice-Hall, Inc., </publisher> <year> 1975. </year>
Reference-contexts: The set of all detected facial actions is used in the following section for recognizing facial expressions. 4 Recognizing facial expressions We have designed a rule based system that combines some of the expression descriptions from <ref> [3] </ref> and [2]. We divide every facial expression into three temporal parts: the beginning, epic and ending. Figure 3 shows the temporal parts of a `smile' model.
Reference: [4] <author> Y. Yacoob, and L.S. Davis, </author> <title> Computing Spatio-Temporal Representations of Human Faces, </title> <type> Technical Report CAR-TR-706, </type> <institution> Center for Automation Research, Univ. of Maryland, College Park, </institution> <year> 1994. </year>
Reference-contexts: The two types of vertical partitions are designed to capture several mouth motions. Single vertical partitions capture mouth horizontal expansions and contractions when the mouth is not completely horizontal. The two vertical partitions are designed to capture the motion of the corners of the mouth. Confidence measurements (see <ref> [4] </ref>) are used to construct the mid-level representation of a region motion. The highest ranking partition in each type is used as a pointer into the dictionary of motions (see Table 1), to determine the action that may have occurred at the feature.
Reference: [5] <editor> Y. Yacoob, and L.S. Davis, </editor> <booktitle> "Computing Spatio-Temporal Representations of Human Faces" IEEE CVPR, </booktitle> <pages> 70-75, </pages> <year> 1994. </year>
References-found: 5

