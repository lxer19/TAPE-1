URL: http://www.cs.gatech.edu/people/home/kjain/sn.ps
Refering-URL: http://www.cs.gatech.edu/people/home/kjain/
Root-URL: 
Email: Email: kjain@cc.gatech.edu  
Title: A Factor 2 Approximation Algorithm for the Generalized Steiner Network Problem  
Author: Kamal Jain 
Affiliation: College of Computing Georgia Institute of Technology.  
Abstract: We present a factor 2 approximation algorithm for finding a minimum-cost subgraph having at least a specified number of edges in each cut. This class of problems includes, among others, the generalized Steiner network problem, which is also known as the survivable network design problem. Our algorithm first solves the linear relaxation of this problem, and then iteratively rounds off the solution. The key idea in rounding off is that in a basic solution of the LP relaxation, at least one edge gets included at least to the extent of half. We include this edge into our integral solution and solve the residual problem. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> N. Garg, V. V. Vazirani, and M. Yannakakis. </author> <title> Approximation algorithms for multiway cuts in node-weighted and directed graphs. </title> <booktitle> Proc. 21th International Colloquium on Automata, Languages and Programming, </booktitle> <year> 1994. </year>
Reference-contexts: Hence our algorithm puts the generalized case at par with this special case. Our algorithm falls into the class of rounding algorithms. Rounding algorithms use an optimal fractional solution to obtain a good integral solution. Some problems, like vertex cover [6] and node multiway cut <ref> [1] </ref>, have the remarkable property that they admit an optimal fractional solution which is half-integral. When this property holds, rounding up gives an approximation factor of 2. <p> This implies that we can find an optimal solution to LP (3). We also need to show that, once we have an optimal solution, how can we find an optimal basic solution. Suppose we have a separation oracle for LP (2). Let x res be some vector in <ref> [0; 1] </ref> E (G res ) for which we either want to determine whether x res is a feasible point for LP (3) or, if not, then we want to produce a constraint of LP (3) which is not satisfied. Let us extend the vector x res from [0; 1] E <p> vector in <ref> [0; 1] </ref> E (G res ) for which we either want to determine whether x res is a feasible point for LP (3) or, if not, then we want to produce a constraint of LP (3) which is not satisfied. Let us extend the vector x res from [0; 1] E (G res ) to [0; 1] E (G) , by assigning 1 to the fields corre <br>- sponding to the edges in E 1 2 +. Let us call the extended vector, x. <p> Let us extend the vector x res from <ref> [0; 1] </ref> E (G res ) to [0; 1] E (G) , by assigning 1 to the fields corre <br>- sponding to the edges in E 1 2 +. Let us call the extended vector, x.
Reference: [2] <author> M. X. Goemans, A. Goldberg, S. Plotkin, D. Shmoys, E. Tardos, and D. P. Williamson. </author> <title> Approximation algorithms for network design problems. </title> <booktitle> SODA, </booktitle> <pages> 223-232, </pages> <year> 1994. </year>
Reference-contexts: The authors of [9] give a 2k-approximation algorithm, where k is the maximum requirement of a set. The approximation factor was later improved to 2H k in <ref> [2] </ref>, where H k = 1 + 1 2 + 1 k . The algorithm in [2] also works for weakly supermodular functions. No better approximation factor was known even for the generalized Steiner network problem, which was the main motivation for studying this class of problems. <p> The authors of [9] give a 2k-approximation algorithm, where k is the maximum requirement of a set. The approximation factor was later improved to 2H k in <ref> [2] </ref>, where H k = 1 + 1 2 + 1 k . The algorithm in [2] also works for weakly supermodular functions. No better approximation factor was known even for the generalized Steiner network problem, which was the main motivation for studying this class of problems. <p> We leave open the developing of purely combinatorial constant factor algorithm for the problem. 2 Preliminaries In this section, we briefly establish a few facts about weakly supermodular functions, submodular functions and proper functions. These facts can also be found in <ref> [2] </ref>. Definition 2.1 A function f : 2 V ! Z + is proper if f (V ) = 0 and the following two conditions hold 1. For every subset S of V , f (S) = f (V S). 2.
Reference: [3] <author> M. X. Goemans and D. P. Williamson. </author> <title> A general approximation technique for constrained forest problem. </title> <journal> SIAM Journal on Computing, </journal> <volume> 24 </volume> <pages> 296-317, </pages> <month> April </month> <year> 1995. </year>
Reference: [4] <author> R. Gomory and T. Hu. </author> <title> Multi-terminal network flows. </title> <journal> SIAM Journal of Applied Mathematics, </journal> <volume> 9 </volume> <pages> 551-570, </pages> <year> 1961. </year>
Reference: [5] <author> L. G. Khachiyan, </author> <title> A polynomial algorithm for linear programming (in Russian), </title> <journal> Doklady Akademiia Nauk USSR 244 </journal> <note> 1093-1096 (1979). A translation appears in Soviet Mathematics Doklady </note> 20:191-194, (1979). 
Reference-contexts: not dependent upon the equalities in E, such that (L (t fl )) = f . (c) x L (t fl ) S S " fx : (x) = f g (Note that dim (S) decreases by one.) A computation similar to that in the analysis of the ellipsoid algorithm <ref> [5] </ref> shows that we have to run the binary search in step (2:b) until we get two points t low &lt; t up such that L (t low ) is feasible, 14 L (t up ) is infeasible, and t up t low &lt; 1 m!2 T P oly (m) .
Reference: [6] <author> G. L. Nemhauser and L. E. Trotter, Jr.. </author> <title> Vertex packing: structural properties and algorithms. </title> <journal> Mathematical Programming, </journal> <volume> 8 </volume> <pages> 232-248, </pages> <year> 1975. </year>
Reference-contexts: Hence our algorithm puts the generalized case at par with this special case. Our algorithm falls into the class of rounding algorithms. Rounding algorithms use an optimal fractional solution to obtain a good integral solution. Some problems, like vertex cover <ref> [6] </ref> and node multiway cut [1], have the remarkable property that they admit an optimal fractional solution which is half-integral. When this property holds, rounding up gives an approximation factor of 2.
Reference: [7] <author> E. Tardos. </author> <title> A strongly polynomial algorithm to solve combinatorial linear programs. </title> <journal> Operations Research, </journal> <volume> 34 </volume> <pages> 250-256, </pages> <year> 1986. </year> <month> 17 </month>
Reference-contexts: taken by Vaidya's algorithm [8], the time taken by the implementation is O (m 2 (T + log m))P (m) + O (m 3 n (T + log m))M (m; n). 9 Implementing the Algorithm in Strongly Polynomial Time Tardos gave a strongly polynomial algorithm to solve combinatorial LPs in <ref> [7] </ref>. In that algorithm she requires an explicit declaration of all the constraints. If we can write LP (3) compactly with polynomial number of constraints then we can use Tardos' algorithm [7]. Note that LP (3) is a restriction of LP (2). <p> 9 Implementing the Algorithm in Strongly Polynomial Time Tardos gave a strongly polynomial algorithm to solve combinatorial LPs in <ref> [7] </ref>. In that algorithm she requires an explicit declaration of all the constraints. If we can write LP (3) compactly with polynomial number of constraints then we can use Tardos' algorithm [7]. Note that LP (3) is a restriction of LP (2). It is obtained by taking a partial solution and then fixing the values of some of the edges in that partial solution. So, if we represent LP (2) compactly then we can do the same with LP (3). <p> v2V ij X f uw X f wv 8 (uv) 2 E : x (uv) f uv By the maxflow-mincut theorem, the feasible region of LP (6) is same as the projection of the feasible region of LP (7) on the variables x e . 16 By Tardos' result in <ref> [7] </ref>, we can find an optimal solution to LP (7). But this solution may not be a basic solution to LP (6).
Reference: [8] <author> P. M. Vaidya. </author> <title> A new algorithm for minimizing convex functions over convex sets. </title> <journal> Mathematical Programming, </journal> <volume> 73 </volume> <pages> 291-341, </pages> <year> 1996. </year>
Reference-contexts: Hence we obtain a separation oracle that runs in O (n)M (m; n) + O (n 3 ) = O (n)M (m; n) time. By plugging this in the running time of Vaidya's algorithm <ref> [8] </ref>, it follows that an optimal solution to the linear relaxation of IP (5) can be found in O (m 2 n (T +log m))M (m; n)+O (m 2 (T +log m))P (m) time, where P (m) is the time to multiply two m fi m matrices. <p> Hence the total time taken by rounding is O (m 2 )P (m) + O (m 3 n (T + log m))M (m; n) time. By taking into account the time taken by Vaidya's algorithm <ref> [8] </ref>, the time taken by the implementation is O (m 2 (T + log m))P (m) + O (m 3 n (T + log m))M (m; n). 9 Implementing the Algorithm in Strongly Polynomial Time Tardos gave a strongly polynomial algorithm to solve combinatorial LPs in [7].
Reference: [9] <author> D. P. Williamson, M. X. Goemans, M. Mihail, and V. V. Vazirani. </author> <title> A primal-dual approximation algorithm for generalized Steiner network problems. </title> <journal> Combinatorica, </journal> <volume> 15 </volume> <pages> 435-454, </pages> <month> December </month> <year> 1995. </year>
Reference-contexts: For every A; B V , at least one of the following holds * f (A) + f (B) f (A B) + f (B A) The problem was first considered in <ref> [9] </ref> with the stronger assumption that f is proper (see Definition 2.1). The authors of [9] give a 2k-approximation algorithm, where k is the maximum requirement of a set. <p> For every A; B V , at least one of the following holds * f (A) + f (B) f (A B) + f (B A) The problem was first considered in <ref> [9] </ref> with the stronger assumption that f is proper (see Definition 2.1). The authors of [9] give a 2k-approximation algorithm, where k is the maximum requirement of a set. The approximation factor was later improved to 2H k in [2], where H k = 1 + 1 2 + 1 k . The algorithm in [2] also works for weakly supermodular functions.
References-found: 9

