URL: http://www.cs.wisc.edu/~ramasamy/paper/cache.ps
Refering-URL: http://www.cs.wisc.edu/~ramasamy/ramasamy.html
Root-URL: 
Email: samitg@cs.wisc.edu  
Title: Caching Multidimensional Queries Using Chunks  
Author: Prasad M. Deshpande Karthikeyan Ramasamy Amit Shukla Jeffrey F. Naughton fpmd, karthik, naughton, 
Date: 213  
Note: Paper Number  
Address: Wisconsin, Madison, WI 53706  
Affiliation: Computer Sciences Department University of  
Abstract: Caching has been proposed (and implemented) by OLAP systems in order to reduce response times for multidimensional queries. Previous work on such caching has considered table level caching and query level caching. Table level caching is suitable for static schemes. On the other hand, Query level caching can be used in dynamic schemes, but is too coarse for large query results. Query level caching has the further drawback for small query results in that it is only effective when a new query is subsumed by a cached previous query. In this paper, we propose caching small regions of the multidimensional space called chunks. Chunk-based caching allows fine granularity caching, and also allows queries to partially reuse the results of previous queries with which they overlap. To facilitate the computation of chunks required by a query but not found in the cache, we propose a new organization for relational tables, which we call a chunked file. Our experiments show that for workloads that exhibit query locality, chunked caching combined with the chunked file organization performs better than query level caching. An unexpected benefit of the chunked file organization is that, due to its multidimensional clustering properties, it can significantly improve the performance of queries that miss the cache entirely as compared to traditional file organizations.
Abstract-found: 1
Intro-found: 1
Reference: [AAD+96] <author> S. Agarwal, R. Agrawal, P.M. Deshpande, A. Gupta, J.F. Naughton, R. Ramakrishnan, S. Sarawagi. </author> <title> On the Computation of Multidimensional Aggregates, </title> <booktitle> Proc. of the 22nd Int. VLDB Conf., </booktitle> <volume> 506521, </volume> <year> 1996. </year>
Reference: [ARBOR] <institution> Arbor Software Corporation. </institution> <note> The Essbase Product Family, http://www.arborsoft.com/essbase/datasht/esb fmly1.html </note>
Reference: [BPT97] <author> E. Baralis, S. Paraboschi, E. Teniente. </author> <title> Materialized View Selection in a Multidimensional Database, </title> <booktitle> Proc. of the 23rd Int. VLDB Conf., </booktitle> <year> 1997. </year>
Reference: [DFJST] <author> S. Dar, M. J. Franklin, B. T. Jonsson, D. Srivastava, M. </author> <title> Tan Semantic Data Caching and Replacement Proc. </title> <booktitle> of the 22nd Int. VLDB Conf., </booktitle> <year> 1996. </year>
Reference-contexts: We have a semantic approach to caching. Semantic query caching for client-server systems has been studied in <ref> [DFJST] </ref>. The semantic approach is very suitable to the OLAP domain where the data is multi-dimensional and the notion of semantic data regions is very natural. One of the drawbacks of semantic caching is that, the cache has to maintain information about the cached semantic regions.
Reference: [DKLP+94] <author> D. DeWitt, N. Kabra, J. Luo, J. M. Patel, J. Yu. </author> <title> Client-Server Paradise. </title> <booktitle> Proc. of the 1994 VLDB Conf., </booktitle> <year> 1994. </year>
Reference-contexts: The middle tier has to separate the result tuples into different chunks in order to cache them. We did a full implementation of the chunked file in the PARADISE <ref> [DKLP+94] </ref> database system. Chunked file is implemented by using a BTree as a chunk index on a fact file. Fact file is a relational file which is optimized 17 for storing and accessing the records in a fact table [RJZN97]. It exploits the fixed length property of fact table records.
Reference: [Fell57] <author> William Feller, </author> <title> An Introduction to Probability Theory and Its Applications, Vol. I, </title> <publisher> John Wiley & Sons, </publisher> <pages> pp 241; 1957. </pages>
Reference-contexts: Suppose query is a selection on A, i.e. A = x. The expected number of tuples satisfying this condition is n = N D . Thus number of bits set in the bitmap is n. We use the following result from probability theory <ref> [Fell57] </ref> : If r elements are chosen uniformly randomly from a set of k elements, the expected number of distinct elements obtained in the sample is f (r; k) = k k (1 1=k) r . f (r; k) has the following properties: f (r; k) r; k f (r; k)
Reference: [GBLP96] <author> J. Gray, A. Bosworth, A. Layman, H. Pirahesh. </author> <title> Data Cube: A Relational Aggregation Operator Generalizing Group-By, </title> <booktitle> Cross-Tab, and Sub-Totals, Proc. of the 12th Int. Conf. on Data Engg., </booktitle> <pages> pp 152-159, </pages> <year> 1996. </year>
Reference: [GHRU97] <author> H. Gupta, V. Harinarayan, A. Rajaraman, J.D. Ullman. </author> <title> Index Selection for OLAP. </title> <booktitle> Proc. of the 13th ICDE, </booktitle> <address> 208219, </address> <year> 1997. </year>
Reference-contexts: Nature of caching Under this category, the caching schemes can be classified as static or dynamic. In static caching, a set of group-bys is chosen and the corresponding tables are materialized. Thus it reduces to the problem of selecting what aggregates to precompute [HRU96] <ref> [GHRU97] </ref> [SDN] using a given amount of space. The choice of these tables are made a priori and is independent of the actual query stream. On the contrary, dynamic caching schemes adapt depending on the type of query stream.
Reference: [Gupt97] <author> H. Gupta. </author> <title> Selection of Views to Materialize in a Data Warehouse. </title> <booktitle> Proc. of the Sixth ICDT, </booktitle> <volume> 98112, </volume> <year> 1997. </year>
Reference: [HRU96] <author> V. Harinarayanan, A. Rajaraman, J.D. Ullman. </author> <title> Implementing Data Cubes Efficiently, </title> <booktitle> Proc. ACM SIG-MOD Int. Conf. on Management of Data, </booktitle> <address> 205227, </address> <year> 1996. </year> <month> 25 </month>
Reference-contexts: Nature of caching Under this category, the caching schemes can be classified as static or dynamic. In static caching, a set of group-bys is chosen and the corresponding tables are materialized. Thus it reduces to the problem of selecting what aggregates to precompute <ref> [HRU96] </ref> [GHRU97] [SDN] using a given amount of space. The choice of these tables are made a priori and is independent of the actual query stream. On the contrary, dynamic caching schemes adapt depending on the type of query stream. <p> Schemes which make use of a profit metric consisting of the size and execution cost of a query are considered in [SSV]. We use a similar replacement scheme which considers the benefit of a chunk. The notion of benefit of a group-by was introduced in <ref> [HRU96] </ref>. Since we do not do any aggregation in the middle tier, a group-by benefits itself but not any other group-by. The benefit of a chunk is measured by the fraction of the base table that it represents.
Reference: [RK96] <author> R. Kimball. </author> <title> The Data Warehouse Toolkit, </title> <publisher> John Wiley & Sons, </publisher> <year> 1996. </year>
Reference: [KT95] <author> Kenan Technologies. </author> <title> An Introduction to Multidimensional Database Technology, </title> <note> A white paper available from http://www.kenan.com/ </note>
Reference: [MSI95] <author> MicroStrategy Inc. </author> <title> The Case for Relational OLAP, </title> <note> A white paper available from http://www.strategy.com/ </note>
Reference: [OQ97] <author> P. O'Neil, D. Quass, </author> <title> Improved Query Performance with Variant Indexes. </title> <booktitle> Proc. ACM SIGMOD Int. Conf. on Management of Data, </booktitle> <volume> 3849, </volume> <year> 1997. </year>
Reference: [OG95] <author> P. O'Neil, G. Graefe, </author> <title> Multi-Table Joins Through Bitmapped Join Indices. </title> <booktitle> SIGMOD Record, </booktitle> <volume> 811, </volume> <month> Septem-ber </month> <year> 1995. </year>
Reference: [RJZN97] <author> K. Ramasamy, Q. Jin, Y. Zhao and J. F. Naughton. </author> <title> Bit-Map Indices: Implementation Issues and Performance Results. </title> <note> Working Paper. </note>
Reference-contexts: Chunked file is implemented by using a BTree as a chunk index on a fact file. Fact file is a relational file which is optimized 17 for storing and accessing the records in a fact table <ref> [RJZN97] </ref>. It exploits the fixed length property of fact table records. It eliminates the slot overhead in the pages and provides a fast path for skipped sequential access. To get a chunk based organization, the tuples in the fact file are clustered on a chunk basis.
Reference: [SS94] <author> S. Sarawagi and M. Stonebraker. </author> <title> Efficient Organization of Large Multidimensional Arrays. </title> <booktitle> Proc. of the 11th Int. Conf. on Data Engg., </booktitle> <year> 1994. </year>
Reference-contexts: Instead of storing a large array in simple row major or column major order, they are broken down into chunks 6 and stored in a chunked format <ref> [SS94] </ref> [ZDN97]. The distinct values for each dimension are divided into ranges and the chunks are created based on this division. Figure 1 shows how the multidimensional space can be broken up into chunks. Our observation is that chunks could be very suitable as a unit of caching. <p> This suggests that the chunk range at any level in the hierarchy should be a proportional to the number of distinct values of the dimension at that level. This agrees with a similar observation made in <ref> [SS94] </ref>, in the context of multi-dimensional arrays. Section 6 describes some experiments to determine the optimal chunk range. 5.2 Query Processing 5.2.1 Query Analysis When a new query is issued, it is necessary to check if it can be answered from the cache.
Reference: [SDNR96] <author> A. Shukla, P.M. Deshpande, J.F. Naughton, K. Ramasamy, </author> <title> Storage Estimation for Multidimensional Aggregates in the Presence of Hierarchies, </title> <booktitle> Proc. of the 22nd Int. VLDB Conf., </booktitle> <volume> 522531, </volume> <year> 1996. </year>
Reference: [SDN] <author> A. Shukla, P.M. Deshpande, J.F. Naughton, </author> , <note> Submitted for SIGMOD 1998. </note>
Reference-contexts: Nature of caching Under this category, the caching schemes can be classified as static or dynamic. In static caching, a set of group-bys is chosen and the corresponding tables are materialized. Thus it reduces to the problem of selecting what aggregates to precompute [HRU96] [GHRU97] <ref> [SDN] </ref> using a given amount of space. The choice of these tables are made a priori and is independent of the actual query stream. On the contrary, dynamic caching schemes adapt depending on the type of query stream.
Reference: [SSV] <author> P. Scheuermann, J. Shim and R. </author> <title> Vingralek WATCHMAN : A Data Warehouse Intelligent Cache Manager Proc. </title> <booktitle> of the 22nd Int. VLDB Conf., </booktitle> <year> 1996. </year>
Reference-contexts: Some of them have significant applicability to the domain of data warehousing and OLAP. Cache replacement and admission schemes specific to warehousing have been studied in <ref> [SSV] </ref>. In their work, a profit metric is defined for each query and on the basis of it a decision is taken whether the query has to be cached or can be replaced. <p> This cost has to be incorporated into the cache policies. Schemes which make use of a profit metric consisting of the size and execution cost of a query are considered in <ref> [SSV] </ref>. We use a similar replacement scheme which considers the benefit of a chunk. The notion of benefit of a group-by was introduced in [HRU96]. Since we do not do any aggregation in the middle tier, a group-by benefits itself but not any other group-by. <p> The query streams consisted of 1500 queries. 6.1.3 Performance Metrics We used two metrics in order to evaluate the effectiveness of the caching schemes : 1. The average execution time of the last 100 queries in the query stream. 2. Cost Saving Ratio This metric was defined in <ref> [SSV] </ref>. It is a measure of the percentage of the total cost of the queries saved due to hits in the cache.
Reference: [SDJL96] <author> D. Srivastava, S. Dar, H. V. Jagadish and A. Y. Levy. </author> <title> Answering Queries with Aggregation Using Views Proc. </title> <booktitle> of the 22nd Int. VLDB Conf., </booktitle> <year> 1996. </year>
Reference-contexts: The idea of using a profit metric is relevant in OLAP since, highly aggregated results are expensive to compute and should be given preference while caching as well as replacing. The problem of answering queries with aggregation using views has been studied extensively in <ref> [SDJL96] </ref>. They describe the conditions under which a new query can be answered using cached aggregate views. A query need not be answered from a single view, but it could be decomposed into multiple queries each of which is answered from a different view.
Reference: [TPCD95] <editor> TPC benchmark D, </editor> <title> proposed revision 1.0. </title> <address> San Jose, </address> <month> April </month> <year> 1995. </year>
Reference: [Ull96] <author> J.D. Ullman, </author> <title> Efficient Implementation of Data Cubes Via Materialized Views A survey of the field for the 1996 KDD conference. </title>
Reference: [ZDN97] <author> Y. Zhao, P.M. Deshpande, J.F. Naughton. </author> <title> An ArrayBased Algorithm for Simultaneous Multidimensional Aggregates, </title> <booktitle> Proc. ACM SIGMOD Int. Conf. on Management of Data, </booktitle> <volume> 159170, </volume> <year> 1997. </year> <month> 26 </month>
Reference-contexts: Instead of storing a large array in simple row major or column major order, they are broken down into chunks 6 and stored in a chunked format [SS94] <ref> [ZDN97] </ref>. The distinct values for each dimension are divided into ranges and the chunks are created based on this division. Figure 1 shows how the multidimensional space can be broken up into chunks. Our observation is that chunks could be very suitable as a unit of caching.
References-found: 24

