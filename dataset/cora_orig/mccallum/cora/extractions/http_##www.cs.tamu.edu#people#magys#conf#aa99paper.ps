URL: http://www.cs.tamu.edu/people/magys/conf/aa99paper.ps
Refering-URL: http://www.cs.tamu.edu/people/magys/conf/publication.html
Root-URL: http://www.cs.tamu.edu
Email: magys@cs.tamu.edu ioerger@cs.tamu.edu yen@cs.tamu.edu  
Title: PETEEI: A PET with Evolving Emotional Intelligence  
Author: Magy Seif El-Nasr Thomas R. Ioerger John Yen 
Address: College Station, TX 77844-3112 College Station, TX 77844-3112 College Station, TX 77844-3112  
Affiliation: Texas A&M University Texas A&M University Texas A&M University Computer Science Department Computer Science Department Computer Science Department  
Abstract: The emergence of what is now called emotional intelligence has revealed yet another aspect of human intelligence. Emotions have been shown to have a major impact on many of our everyday functions, including decision-making, planning, communication, and behavior. AI researchers have recently acknowledged this major role that emotions play, and thus have began to incorporate models for simulating emotions into agents. However, the emotional process is not a simple process; it is often linked with many other processes, one of which is learning. It has long been emphasized in psychology that memory and experience help shape the dynamic nature of the emotional process. In this paper, we introduce PETEEI (a PET with Evolving Emotional Intelligence). PETEEI is based on a fuzzy logic model for simulating emotions in agents, with a particular emphasis on incorporating various learning mechanisms so that an agent can adapt its emotions according to its own experience. Additionally, PETEEI is designed to recognize and cope with the various moods and emotional responses of its owner. A user evaluation experiment indicated that simulating the dynamic emotional process through learning provides a significantly more believable agent. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Aron, A. and Aron N. </author> <title> Self-expansion motivation and including other in the self. </title> <editor> In S. Duck (ed.), </editor> <title> Handbook of personal relationships: Theory, </title> <booktitle> research, and interventions (2 nd ed., </booktitle> <pages> pp. 251-270). </pages> <address> Chichester, England:Wiley, </address> <year> 1997. </year>
Reference-contexts: Furthermore, the agents behavior is not solely determined by its emotional state, but it also depends on some predefined social norms that defines and limits the expressiveness of its behavior <ref> [1, 27] </ref>. For example, if the user is in a very bad mood and the user is considered a good friend, the agent will not tend to be very aggressive in its behavior. <p> Therefore, modeling emotions and personality may provide a good starting point for team training applications. Through many studies in social psychology, emotions, shared knowledge and self-presentation have been acknowledged to be the main facilitators of human-human communication <ref> [31, 27, 1] </ref>. These studies have inspired many researchers to look for alternative ways to solve the human-computer interaction problem using human-human interaction as a model. <p> We believe personality is an important component to be added to our model in the near future. Human intelligence includes many other phenomenon that have challenged and intrigued psychologists for decades. These concepts include self-perception, self-awareness, self-expansion, self-presentation, and self-esteem <ref> [16, 1, 10] </ref>. They have been recognized by psychologists to have a major impact on the subjects stability, emotional and social responses [10, 1]. In conclusion, learning helps in capturing the dynamic nature of the emotional process. <p> Human intelligence includes many other phenomenon that have challenged and intrigued psychologists for decades. These concepts include self-perception, self-awareness, self-expansion, self-presentation, and self-esteem [16, 1, 10]. They have been recognized by psychologists to have a major impact on the subjects stability, emotional and social responses <ref> [10, 1] </ref>. In conclusion, learning helps in capturing the dynamic nature of the emotional process. Our model is just another building block in our attempt to understand real human intelligence, and to make use of its simulation in various applications. 7.
Reference: [2] <author> Bates, J. </author> <title> The role of emotion in believable agents. </title> <journal> Communications of ACM, </journal> <volume> 37:7, </volume> <pages> 122-125, </pages> <year> 1992. </year>
Reference-contexts: Recognizing the importance of the emotional process in the simulation of lifelike characters [6], a number of computational models of emotions have been proposed within the agents community [33, 23]. An important effort in this area is the OZ project <ref> [2, 25] </ref> at CMU. The OZ project simulates believable emotional and social agents; each agent initially has preset attitudes towards certain objects in the environment. Furthermore, each agent has some initial goals and a set of strategies that it can follow to achieve each goal.
Reference: [3] <author> Bower, G. H. and Cohen, P. R. </author> <title> Emotional influences in memory and thinking: Data and theory. </title> <editor> In M. Clack and S. Fiske (ed.), </editor> <booktitle> Affect and Cognition (pp. </booktitle> <pages> 291-331). </pages> <address> London, </address> <publisher> England:Lawrence Erlbaum Association Publishers, </publisher> <year> 1982. </year>
Reference-contexts: Instead of calculating the Q-value of a state by maximizing the reward, the mood is used as an averaging factor for the new states. As noted in <ref> [3] </ref>, when the agent is in a positive mood it will tend to expect positive events to occur, and otherwise it will expect negative events to occur. Thus, we refined the expectation mechanism to capture this phenomenon.
Reference: [4] <author> Damasio, A. </author> <title> Descartes error: Emotion, reason, and the human brain. </title> <publisher> New York: </publisher> <editor> G. P. Putnam, </editor> <year> 1994. </year>
Reference-contexts: The importance of emotions in the theory of human intelligence has recently been strengthened through neurological evidence presented by Damasio <ref> [4] </ref>. As a result, many researchers within the agents and AI field have began to develop computational models of emotions. Simulating emotional intelligence in certain types of computer programs is important. <p> The formula described above gives the maximum expected reward given that the agent is at a particular state. Emotions and moods have a great impact on human decisions and event evaluation <ref> [4, 10] </ref>. The mood is thus used in the model to guide the expectation values of the next state, s , given that the agent is in a state s.
Reference: [5] <author> Domjan, M. </author> <booktitle> The principles of learning and behavior (4 ed.). </booktitle> <address> Boston: </address> <publisher> Brooks/Cole Publishing Co. </publisher> <year> 1998. </year>
Reference-contexts: This is especially true in the taste aversion paradigms of Pavlovian conditioning, where a rat would associate sweet with poison after some trials where the rats were injected with poison subsequent to eating sweets <ref> [5] </ref>. Each of these associations will have an accumulator, which is incremented by the repetition and intensity of the object-emotion occurrence. This type of learning will provide the agent with another type of expectation triggered by the object rather than the event.
Reference: [6] <author> Elliot C. and Brzezinki J. </author> <title> Autonomous agents as synthetic character. AI Magazine, </title> <publisher> AAAI press, </publisher> <pages> 13-30, </pages> <year> 1998. </year>
Reference-contexts: Simulating emotional intelligence in certain types of computer programs is important. Computational models of emotions are very useful to many applications, including personal assistance applications, training simulations, intelligent interfaces, and entertainment applications. Recognizing the importance of the emotional process in the simulation of lifelike characters <ref> [6] </ref>, a number of computational models of emotions have been proposed within the agents community [33, 23]. An important effort in this area is the OZ project [2, 25] at CMU. <p> Moreover, these training systems can use humanlike agents (i.e., synthetic characters) to replace some of the team members. Clark Elliot summarized current efforts in humanlike agent simulations, some of which simulated characters with different personalities and different emotions <ref> [6] </ref>. Therefore, modeling emotions and personality may provide a good starting point for team training applications. Through many studies in social psychology, emotions, shared knowledge and self-presentation have been acknowledged to be the main facilitators of human-human communication [31, 27, 1].
Reference: [7] <author> Eibl-Eibesfeldt, I. </author> <booktitle> Human ethology. </booktitle> <address> New York: </address> <publisher> Aldine de Gruyter, </publisher> <year> 1989. </year>
Reference: [8] <author> Fiske, A. P. </author> <title> The four elementary forms of sociality: Framework for a unified theory of social relations. </title> <journal> Psychology Review, </journal> <volume> 99, </volume> <pages> 689-723, </pages> <year> 1992. </year>
Reference-contexts: This technique is widely used in relationships, whenever a partner feels guilty, he/she goes under a submissive role; he/she will go out of his/her way to do something for the other partner to make up for what he/she did wrong <ref> [8] </ref>. 2.1.4 Pavlovian Conditioning Associating an object directly with an emotion forms yet another type of learning.
Reference: [9] <author> Gardner H. </author> <title> Frames of Mind. </title> <address> New York: </address> <publisher> Basic Books, </publisher> <year> 1973. </year>
Reference-contexts: 1. INTRODUCTION Artificial Intelligence (AI) and psychology researchers have long been concerned with defining intelligence and finding a way to simulate it. Many theories of intelligence have been formulated, however, very few included emotions. In Howard Gardners book, Frames of the Mind, he describes the concept of Multiple Intelligence <ref> [9] </ref>. He divided intelligence into six types: linguistic, musical, logical-mathematical, spatial, bodily kinesthetic and personal intelligence. Accordingly, a persons intelligence can vary along these dimensions.
Reference: [10] <author> Goleman D. </author> <title> Emotional Intelligence. </title> <address> New York: </address> <publisher> Bantam Books, </publisher> <year> 1995. </year>
Reference-contexts: Accordingly, a persons intelligence can vary along these dimensions. Gardners theory is important because, by including personal intelligence, it incorporated the social and emotional capabilities that people possess, which then led to the rise of what is called the emotional intelligence theory <ref> [10] </ref>. The importance of emotions in the theory of human intelligence has recently been strengthened through neurological evidence presented by Damasio [4]. As a result, many researchers within the agents and AI field have began to develop computational models of emotions. <p> The formula described above gives the maximum expected reward given that the agent is at a particular state. Emotions and moods have a great impact on human decisions and event evaluation <ref> [4, 10] </ref>. The mood is thus used in the model to guide the expectation values of the next state, s , given that the agent is in a state s. <p> Nevertheless, the model still falls short in several aspects. Psychologists recognized personality to be a factor that influences and is being influenced by the learning and the emotional processes <ref> [10] </ref>. Furthermore, personality has been recognized by many artists to be one of the most important factors in character animation [32]. Some researchers have added personality to their emotional agent models [13]. However, personality is a very challenging concept to simulate, since there are many traits and individual variations [26]. <p> We believe personality is an important component to be added to our model in the near future. Human intelligence includes many other phenomenon that have challenged and intrigued psychologists for decades. These concepts include self-perception, self-awareness, self-expansion, self-presentation, and self-esteem <ref> [16, 1, 10] </ref>. They have been recognized by psychologists to have a major impact on the subjects stability, emotional and social responses [10, 1]. In conclusion, learning helps in capturing the dynamic nature of the emotional process. <p> Human intelligence includes many other phenomenon that have challenged and intrigued psychologists for decades. These concepts include self-perception, self-awareness, self-expansion, self-presentation, and self-esteem [16, 1, 10]. They have been recognized by psychologists to have a major impact on the subjects stability, emotional and social responses <ref> [10, 1] </ref>. In conclusion, learning helps in capturing the dynamic nature of the emotional process. Our model is just another building block in our attempt to understand real human intelligence, and to make use of its simulation in various applications. 7.
Reference: [11] <author> Kaelbling, L. P., Littman, M. L., and A. W. Moore. </author> <title> Reinforcement Learning: A Survey. </title> <journal> Journal of Artificial Intelligence Research, </journal> <volume> 4, </volume> <pages> 237-285, </pages> <year> 1996. </year>
Reference-contexts: The agent can potentially learn this link or sequence of links by using a reinforcement learning algorithm <ref> [11, 19] </ref>; we will briefly outline one reinforcement algorithm, namely the Q-learning algorithm. The reader is referred back to [11, 19] for more details. It is often the case that an agent does not know the consequences of a given action until a complete sequence of actions ends. <p> The agent can potentially learn this link or sequence of links by using a reinforcement learning algorithm <ref> [11, 19] </ref>; we will briefly outline one reinforcement algorithm, namely the Q-learning algorithm. The reader is referred back to [11, 19] for more details. It is often the case that an agent does not know the consequences of a given action until a complete sequence of actions ends.
Reference: [12] <author> Kim, J. and Moon, J. Y. </author> <title> Designing towards emotional usability in customer interfaces - trustworthiness of cyber-banking system interfaces. Interacting with computer: </title> <journal> The interdisciplinary journal of human computer interaction, </journal> <volume> 10, </volume> <year> 1998. </year>
Reference-contexts: Some others tried to make the interface more appealing to the user and to invoke emotional responses from the user in the process <ref> [12] </ref>. Research is still open for new ideas on how to use emotions and learning to enhance the interface, and break the barrier between human and computer. A model of emotions can also be used to simulate emotions in character animation.
Reference: [13] <author> Loyall, A. B. and Bates, J. </author> <title> Personality-based believable agents that use language. </title> <booktitle> Proc. of the first autonomous agents conference, </booktitle> <year> 1997. </year>
Reference-contexts: Furthermore, personality has been recognized by many artists to be one of the most important factors in character animation [32]. Some researchers have added personality to their emotional agent models <ref> [13] </ref>. However, personality is a very challenging concept to simulate, since there are many traits and individual variations [26]. We believe personality is an important component to be added to our model in the near future. Human intelligence includes many other phenomenon that have challenged and intrigued psychologists for decades.
Reference: [14] <author> Maes, P. </author> <title> Agents that reduce work and information overload. </title> <journal> Communications of ACM, </journal> <volume> 1:7, </volume> <pages> 37-45, </pages> <year> 1997. </year>
Reference-contexts: Some researchers tried to solve this problem by developing personalized interface agents - agents that learn about the user and try to assist him/her in any way possible <ref> [14] </ref>. Some others tried to make the interface more appealing to the user and to invoke emotional responses from the user in the process [12].
Reference: [15] <author> Mark, M. A. </author> <title> The VCR tutor: Design and evaluation of an intelligent tutoring system. </title> <type> Masters thesis, </type> <institution> University of Saskatchewan, Saskatoon, Saskatchewan, </institution> <year> 1991. </year>
Reference-contexts: Such a model could potentially improve many training applications, especially when team training is an issue. Training applications have traditionally been concerned with simple tasks, such as maintenance, which normally involve a sequence of simple lessons that are given to a trainee <ref> [15] </ref>. Clearly, group training is quite different since it relies on many other factors, such as group coherence, group interactions, moral, and dominance within the group [20]. It has been noted that most of these different concepts heavily depend on emotions and experience [20].
Reference: [16] <author> McKay, M. and Fanning P. Self Esteem. St. Martins Paperbacks, USA, </author> <year> 1978. </year>
Reference-contexts: We believe personality is an important component to be added to our model in the near future. Human intelligence includes many other phenomenon that have challenged and intrigued psychologists for decades. These concepts include self-perception, self-awareness, self-expansion, self-presentation, and self-esteem <ref> [16, 1, 10] </ref>. They have been recognized by psychologists to have a major impact on the subjects stability, emotional and social responses [10, 1]. In conclusion, learning helps in capturing the dynamic nature of the emotional process.
Reference: [17] <author> Miller, G. A. </author> <title> The magical number seven, plus or minus two: Some limits on our capacity for processing information. </title> <journal> Psychological Review, </journal> <volume> 63, </volume> <pages> 81-97, </pages> <year> 1956. </year>
Reference: [18] <author> Minsky, M. </author> <booktitle> The society of the mind. </booktitle> <address> New York: </address> <publisher> Simon and Schuster, </publisher> <year> 1986. </year>
Reference: [19] <author> Mitchell, T. M. </author> <title> Machine Learning. </title> <address> New York: </address> <publisher> McGraw-Hill Co., </publisher> <year> 1996. </year>
Reference-contexts: The agent can potentially learn this link or sequence of links by using a reinforcement learning algorithm <ref> [11, 19] </ref>; we will briefly outline one reinforcement algorithm, namely the Q-learning algorithm. The reader is referred back to [11, 19] for more details. It is often the case that an agent does not know the consequences of a given action until a complete sequence of actions ends. <p> The agent can potentially learn this link or sequence of links by using a reinforcement learning algorithm <ref> [11, 19] </ref>; we will briefly outline one reinforcement algorithm, namely the Q-learning algorithm. The reader is referred back to [11, 19] for more details. It is often the case that an agent does not know the consequences of a given action until a complete sequence of actions ends. <p> The table can be initially filled with random values. The agent will begin from a state s. It will take an action, a, which takes it to a new state '.s The agent may obtain a reward, r, for its action <ref> [19] </ref>. If it receives a reward, it updates the table above using the following formula: Q (s,a) r Q (s ,a ) + g max [19] where r is the immediate reward, g is a discount factor, 's is the new state, and 'a is an action from the new state <p> It will take an action, a, which takes it to a new state '.s The agent may obtain a reward, r, for its action <ref> [19] </ref>. If it receives a reward, it updates the table above using the following formula: Q (s,a) r Q (s ,a ) + g max [19] where r is the immediate reward, g is a discount factor, 's is the new state, and 'a is an action from the new state '.s Thus, the Q-value of the previous state-action pair depends on the Q-value of the new state-action pair. <p> We use another learning model, which will be detailed in the next section, to determine the probability of users actions. We used a new formula, which was stated in <ref> [19] </ref> to calculate the Q-value for a non-markov model. The formula is as follows: ),(max),|()],([),( asQassPasrEasQ a s where ),|( assP is the probability of reaching a new state s if action a is taken in state s. )],([ asrE is the expected amount of reward [19]. <p> which was stated in <ref> [19] </ref> to calculate the Q-value for a non-markov model. The formula is as follows: ),(max),|()],([),( asQassPasrEasQ a s where ),|( assP is the probability of reaching a new state s if action a is taken in state s. )],([ asrE is the expected amount of reward [19]. At any given time, the agent will be faced with different actions to take with the possibility of different outcomes and different rewards. The formula described above gives the maximum expected reward given that the agent is at a particular state.
Reference: [20] <author> Nye, J. L. and Brower, A. M. </author> <title> Whats social about social cognition? London: </title> <publisher> Sage Publications, </publisher> <year> 1996. </year>
Reference-contexts: Clearly, group training is quite different since it relies on many other factors, such as group coherence, group interactions, moral, and dominance within the group <ref> [20] </ref>. It has been noted that most of these different concepts heavily depend on emotions and experience [20]. Moreover, these training systems can use humanlike agents (i.e., synthetic characters) to replace some of the team members. <p> Clearly, group training is quite different since it relies on many other factors, such as group coherence, group interactions, moral, and dominance within the group <ref> [20] </ref>. It has been noted that most of these different concepts heavily depend on emotions and experience [20]. Moreover, these training systems can use humanlike agents (i.e., synthetic characters) to replace some of the team members. Clark Elliot summarized current efforts in humanlike agent simulations, some of which simulated characters with different personalities and different emotions [6].
Reference: [21] <author> Ortony, A., Clore, G., and Collins, A. </author> <title> The cognitive structure of emotions. </title> <publisher> Cambridge: Cambridge University Press, </publisher> <year> 1988. </year>
Reference-contexts: The agent perceives an event in the environment. This event is then evaluated according to the agents goals, standards and attitudes. After an event is evaluated, special rules are used to produce an emotion with a specific intensity. These rules are based on Ortony et al.s event-appraisal model <ref> [21] </ref>. The emotions triggered are then mapped, according to their intensity, to a specific behavior. This behavior is expressed in the form of text or animation [25]. Even though OZs model of emotions has many interesting features, it has some limitations too. <p> The example discussed above was described in a very simplistic way. As a matter of fact, many factors are influencing your emotional states. When an event occurs or when you think an event is about to occur, a desirability measure is calculated relative to a specific event <ref> [21] </ref>. This desirability measure will typically depend on the events impact on a set of goals. It is often the case that a given event does not have any impact on any specific goal directly, but some sequence of events may eventually have an impact on some goals. <p> Emotion is generated according to the expectation of certain events occurrence and the desirability of those events. We used some rules to simulate the emotion generation process. These rules were taken from <ref> [21] </ref>. For example, joy was described as the occurrence of a desirable event, and hope was described as the occurrence of an unconfirmed desirable event. Therefore, as it can be seen, the emotion of hope will use the expectation and desirability measure.
Reference: [22] <author> Pfeifer, R. </author> <booktitle> Artificial Intelligence Models of Emotions. Cognitive perspective on emotion and motivation, </booktitle> <pages> 287-320, </pages> <year> 1988. </year>
Reference: [23] <author> Picard, R. W. </author> <title> Affective Computing. </title> <publisher> Cambridge: MIT press, </publisher> <year> 1997. </year>
Reference-contexts: Computational models of emotions are very useful to many applications, including personal assistance applications, training simulations, intelligent interfaces, and entertainment applications. Recognizing the importance of the emotional process in the simulation of lifelike characters [6], a number of computational models of emotions have been proposed within the agents community <ref> [33, 23] </ref>. An important effort in this area is the OZ project [2, 25] at CMU. The OZ project simulates believable emotional and social agents; each agent initially has preset attitudes towards certain objects in the environment.
Reference: [24] <author> Reilly, W. S. and Bates, J. </author> <title> Building emotional agents. </title> <institution> Pittsburgh, PA: Carnegie Mellon University, </institution> <type> Technical Report CMU-CS-92-143, </type> <year> 1992. </year>
Reference-contexts: Thus, in order to measure the desirability of a specific event, we will need to identify the link between an event or a sequence of events and the corresponding goals, which has been noted to be a very complex task <ref> [24] </ref>. The agent can potentially learn this link or sequence of links by using a reinforcement learning algorithm [11, 19]; we will briefly outline one reinforcement algorithm, namely the Q-learning algorithm. The reader is referred back to [11, 19] for more details.
Reference: [25] <author> Reilly, W. S. </author> <title> Believable social and emotional agents. </title> <institution> School of Computer Science, Pittsburgh, PA: Carnegie Mellon University, </institution> <type> Ph.D. thesis, </type> <year> 1996. </year>
Reference-contexts: Recognizing the importance of the emotional process in the simulation of lifelike characters [6], a number of computational models of emotions have been proposed within the agents community [33, 23]. An important effort in this area is the OZ project <ref> [2, 25] </ref> at CMU. The OZ project simulates believable emotional and social agents; each agent initially has preset attitudes towards certain objects in the environment. Furthermore, each agent has some initial goals and a set of strategies that it can follow to achieve each goal. <p> These rules are based on Ortony et al.s event-appraisal model [21]. The emotions triggered are then mapped, according to their intensity, to a specific behavior. This behavior is expressed in the form of text or animation <ref> [25] </ref>. Even though OZs model of emotions has many interesting features, it has some limitations too. An emotion is triggered only when an event affects the agents standards, attitudes or the success of its goals.
Reference: [26] <author> Riso, D. R. and Hudson, R. </author> <title> Personality Types. </title> <institution> USA: Houghton Mifflin, </institution> <year> 1996. </year>
Reference-contexts: Furthermore, personality has been recognized by many artists to be one of the most important factors in character animation [32]. Some researchers have added personality to their emotional agent models [13]. However, personality is a very challenging concept to simulate, since there are many traits and individual variations <ref> [26] </ref>. We believe personality is an important component to be added to our model in the near future. Human intelligence includes many other phenomenon that have challenged and intrigued psychologists for decades. These concepts include self-perception, self-awareness, self-expansion, self-presentation, and self-esteem [16, 1, 10].
Reference: [27] <author> Rusbult, C. E. and Arriaga, X. B. </author> <title> Interdependence theory. </title> <editor> S. Duck (ed.), </editor> <booktitle> Handbook of personal relationshps: Theory, research, and interventions (2 nd ed., </booktitle> <pages> pp. 221-250). </pages> <address> Chichester, England:Wiley, </address> <year> 1997. </year>
Reference-contexts: Furthermore, the agents behavior is not solely determined by its emotional state, but it also depends on some predefined social norms that defines and limits the expressiveness of its behavior <ref> [1, 27] </ref>. For example, if the user is in a very bad mood and the user is considered a good friend, the agent will not tend to be very aggressive in its behavior. <p> Therefore, modeling emotions and personality may provide a good starting point for team training applications. Through many studies in social psychology, emotions, shared knowledge and self-presentation have been acknowledged to be the main facilitators of human-human communication <ref> [31, 27, 1] </ref>. These studies have inspired many researchers to look for alternative ways to solve the human-computer interaction problem using human-human interaction as a model.
Reference: [28] <author> Seif El-Nasr, M. </author> <title> Modeling emotion dynamics in intelligent agents. </title> <institution> Department of Computer Science, College Station, TX: Texas A&M University, </institution> <type> Masters thesis, </type> <year> 1998. </year>
Reference-contexts: The learning model (model 3) further improved this measure by 2.6 to get an average of 8.1 units. For a complete review of the protocol and questions asked, the reader is referred to <ref> [28] </ref>. The results discussed above confirmed our earlier hypothesis that simulating the dynamic emotional process provides a significantly more believable agent. 5. DISCUSSION A computational model of emotions, such as the one presented here, can be of great benefit to certain types of computer programs.
Reference: [29] <author> Simon, H. </author> <title> Motivational and emotional control of cognition. </title> <journal> Psychological review, </journal> <volume> 74, </volume> <pages> 29-39, </pages> <year> 1967. </year>
Reference: [30] <editor> Simon, H. </editor> <booktitle> The science of the artificial. </booktitle> <address> Cambridge, </address> <publisher> MA:MIT Press, </publisher> <year> 1996. </year>
Reference: [31] <author> Suchman, L. </author> <title> Plans and situated actions. </title> <publisher> Cambridge University Press, </publisher> <year> 1981. </year>
Reference-contexts: Therefore, modeling emotions and personality may provide a good starting point for team training applications. Through many studies in social psychology, emotions, shared knowledge and self-presentation have been acknowledged to be the main facilitators of human-human communication <ref> [31, 27, 1] </ref>. These studies have inspired many researchers to look for alternative ways to solve the human-computer interaction problem using human-human interaction as a model.
Reference: [32] <author> Thomas, F. and Johnston, O. </author> <title> The illusion of life. </title> <address> New York: </address> <publisher> Abbeville Press, </publisher> <year> 1981. </year>
Reference-contexts: Nevertheless, the model still falls short in several aspects. Psychologists recognized personality to be a factor that influences and is being influenced by the learning and the emotional processes [10]. Furthermore, personality has been recognized by many artists to be one of the most important factors in character animation <ref> [32] </ref>. Some researchers have added personality to their emotional agent models [13]. However, personality is a very challenging concept to simulate, since there are many traits and individual variations [26]. We believe personality is an important component to be added to our model in the near future.
Reference: [33] <author> Velasquez, J. </author> <title> Modeling emotions and other motivations in synthetic agents. </title> <booktitle> Proc. of the AAAI conference, </booktitle> <pages> 10-15, </pages> <year> 1997. </year>
Reference-contexts: Computational models of emotions are very useful to many applications, including personal assistance applications, training simulations, intelligent interfaces, and entertainment applications. Recognizing the importance of the emotional process in the simulation of lifelike characters [6], a number of computational models of emotions have been proposed within the agents community <ref> [33, 23] </ref>. An important effort in this area is the OZ project [2, 25] at CMU. The OZ project simulates believable emotional and social agents; each agent initially has preset attitudes towards certain objects in the environment.
References-found: 33

