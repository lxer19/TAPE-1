URL: ftp://rtcl.eecs.umich.edu/outgoing/iast/ics.ps.Z
Refering-URL: http://www.eecs.umich.edu/RTCL/routing/
Root-URL: http://www.cs.umich.edu
Email: Email: fiast,kgshing@eecs.umich.edu  
Title: Mapping Concurrently-Communicating Subcubes in a Hypercube Multicomputer  
Author: Bing-rung Tsai and Kang G. Shin 
Address: Ann Arbor, MI 48109-2122  
Affiliation: Real-Time Computing Laboratory Department of Electrical Engineering and Computer Science The University of Michigan  
Abstract: This paper considers the problem of mapping concurrently-communicating subcubes within a hypercube multicomputer so as to minimize inter-subcube communication traffic. Our objective is to minimize the total communication bandwidth required. Some important mathematical properties of subcube mappings are derived. Methods are proposed to modify existing optimization algorithms for finding optimal mappings. A subset of all possible mappings, called parallel mappings, are found to possess some desirable properties. For some special case, optimal parallel mappings are also proved to be optimal among all mappings. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. S. Chen and K. G. Shin, </author> <title> "Processor allocation in an n-cube multiprocessor using gray codes", </title> <journal> IEEE Trans. on Computers, </journal> <volume> vol. C-36, </volume> <pages> pp. 1396-1407, </pages> <month> Dec. </month> <year> 1987. </year>
Reference-contexts: 1 Introduction Subcube allocation | the problem of finding a sub-cube in a large target hypercube | has been studied extensively <ref> [1, 2] </ref> under the assumption that incoming subcube requests are independent. The commonly-used objective of subcube allocation is to minimize hypercube fragmentation.
Reference: [2] <author> D. D. Sharma and D. K. Pradhan, </author> <title> "A novel approach for subcubes allocation in hypercube multiprocessors", </title> <booktitle> in Proc. of the Fourth IEEE Intl. Symposium on Parallel and Distributed Processing, </booktitle> <pages> pp. 336-345, </pages> <year> 1992. </year>
Reference-contexts: 1 Introduction Subcube allocation | the problem of finding a sub-cube in a large target hypercube | has been studied extensively <ref> [1, 2] </ref> under the assumption that incoming subcube requests are independent. The commonly-used objective of subcube allocation is to minimize hypercube fragmentation.
Reference: [3] <author> D. L. Kiskis and K. G. Shin, </author> <title> "Embedding triple-modular redundancy into a hypercube architecture", </title> <booktitle> in Proc. of the Third Conf. on Hypercube Concurrent Computers and Applications, </booktitle> <pages> pp. 337-345, </pages> <month> Jan. </month> <year> 1988. </year>
Reference-contexts: There can still be inter-group (or inter-subcube) communications, which may become a major performance bottleneck if these communicating modules/subcubes are not carefully placed within the hypercube. For example, the embedding of TMR modules into the hypercube, as discussed in <ref> [3] </ref>, requires each TMR to be embedded into a 2-dimensional subcube, Q 2 . So, a task composed of communicat The work reported in this paper was supported in part by the Office of Naval Research under grants N00014-92-J-1080 and N00014-91-J-1115.
Reference: [4] <author> B.-R. Tsai and K. G. Shin, </author> <title> "Communication-oriented assignment of task modules in hypercube multicomputers", </title> <booktitle> in Proc. 12-th Int'l Conf. on Distributed Comput. Syst., </booktitle> <pages> pp. 38-45, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: For example, H (00fl; fl11) = 1, and H (00fl; 11fl) = 2. We will assume that the sizes of communicating sub-cubes are known a priori, and communication events among these subcubes occur within a small time window <ref> [4, 5] </ref>, i.e., messages are exchanged almost concurrently, as in the FFT computation. A weighted task graph G will be used to represent the communication behavior among the subcubes within the time window. <p> Therefore, we define the bandwidth of such an instance of subcube communication to be w ij T ( i ; j ). In <ref> [4, 5] </ref> we have shown that for concurrently-communicating modules, the total bandwidth of a mapping is a good indicator of run-time performance. A mapping with a smaller total bandwidth almost always has better run-time performance, regardless of the underlying switching methods. <p> Note that if all subcubes are parallel, we can ignore the "don't cares", in subcube addresses when calculating their Hamming distances. The optimization problem for (G; d; n) is then reduced to finding optimal mappings for (G; 0; n d). This is just the optimization problem we treated in <ref> [4] </ref>. Parallel mappings also have the advantage that, even with the simplest (fixed-order) e-cube routing algorithm, all inter-subcube messages are routed through links that are never used for intra-subcube messages. <p> Therefore the optimization algorithm for (G; 0; n) can find an optimal mapping for (G; d; n) by constructing G d X and apply the algorithm to (G d X ; 0; n). Since the optimization problem is NP-hard <ref> [4] </ref>, the computation cost is much higher than the case of finding an optimal parallel mapping, where only the problem (G; 0; n d) needs to be considered. In what follows, we will show that for some special cases of G, an optimal parallel mapping is indeed optimal.
Reference: [5] <author> B.-R. Tsai and K. G. Shin, </author> <title> "Mapping concurrent communicating modules to mesh multicomputers equipped with virtual channels", </title> <note> submitted to publication, </note> <year> 1994. </year>
Reference-contexts: For example, H (00fl; fl11) = 1, and H (00fl; 11fl) = 2. We will assume that the sizes of communicating sub-cubes are known a priori, and communication events among these subcubes occur within a small time window <ref> [4, 5] </ref>, i.e., messages are exchanged almost concurrently, as in the FFT computation. A weighted task graph G will be used to represent the communication behavior among the subcubes within the time window. <p> Therefore, we define the bandwidth of such an instance of subcube communication to be w ij T ( i ; j ). In <ref> [4, 5] </ref> we have shown that for concurrently-communicating modules, the total bandwidth of a mapping is a good indicator of run-time performance. A mapping with a smaller total bandwidth almost always has better run-time performance, regardless of the underlying switching methods.
Reference: [6] <author> S. Padmanabhan and C. Baru, </author> <title> "Routing between subcubes in a hypercube", </title> <booktitle> in Proc. of the 6th Distributed Memory Computing Conference, </booktitle> <pages> pp. 295-298, </pages> <month> Apr. </month> <year> 1991. </year>
Reference-contexts: We will first discuss a simple case where all sub-cubes are of the same dimension, using the subcube communication model defined for uniform-size sub-cubes as in <ref> [6, 7] </ref>. <p> Since we are now dealing only with uniform-sized sub-cubes of dimension d (the general case of non-uniform sized subcubes are discussed in [8]), the number of messages sent is 2 d in each instance of communication. These messages are routed by the algorithm Eq-subcube-route proposed in <ref> [6] </ref>, where a 1-to-1 mapping function is found between source and destination nodes, and a message between each source-destination pair is routed through a shortest path. Also, all messages in an instance of subcube communication are routed through edge-disjoint paths. <p> The communication model we used was based on the one proposed in <ref> [6, 7] </ref> for routing messages between subcubes of the same size. Our objective was to minimize the total inter-subcube communication bandwidth. Several important mathematical properties of this type of mappings were derived. Methods were proposed to modify existing algorithms to find an optimal mapping.
Reference: [7] <author> M. S. Chen and K. G. Shin, </author> <title> "Subcube allocation and task migration in hypercube multiprocessor", </title> <journal> IEEE Trans. on Computers, </journal> <volume> vol. C-39, </volume> <pages> pp. 1146-1155, </pages> <month> Sep. </month> <year> 1990. </year>
Reference-contexts: We will first discuss a simple case where all sub-cubes are of the same dimension, using the subcube communication model defined for uniform-size sub-cubes as in <ref> [6, 7] </ref>. <p> Also, all messages in an instance of subcube communication are routed through edge-disjoint paths. From <ref> [7] </ref>, we get the sum of lengths of these paths as T ( i ; j ) = M ( i ; j )2 d , where M ( i ; j ) is defined as M ( i ; j ) = i=1 m (a i ; b i ), <p> As in <ref> [7] </ref>, we define the frontier subcube of ff towards fi, denoted by ff!fi = c n c n1 :::c 0 such that c i = b i if a i = fl ^ b i 2 f0; 1g, and c i = a i otherwise. <p> The communication model we used was based on the one proposed in <ref> [6, 7] </ref> for routing messages between subcubes of the same size. Our objective was to minimize the total inter-subcube communication bandwidth. Several important mathematical properties of this type of mappings were derived. Methods were proposed to modify existing algorithms to find an optimal mapping.
Reference: [8] <author> B.-R. Tsai, </author> <title> Mapping and Scheduling of Concurrent Communication Traffic in Multicomputer Networks, </title> <type> PhD thesis, </type> <institution> The University of Michi-gan, </institution> <year> 1994. </year>
Reference-contexts: We define an instance of subcube communication as each node in i sends a message of length w ij to another node in j . Since we are now dealing only with uniform-sized sub-cubes of dimension d (the general case of non-uniform sized subcubes are discussed in <ref> [8] </ref>), the number of messages sent is 2 d in each instance of communication. These messages are routed by the algorithm Eq-subcube-route proposed in [6], where a 1-to-1 mapping function is found between source and destination nodes, and a message between each source-destination pair is routed through a shortest path. <p> We also confirm that optimization of mappings with respect to improves several other performance parameters as well. We will again focus on the discussion of the case of uniform-size communicating subcubes, since we have shown <ref> [8] </ref> that mapping variable-size subcubes can always be reduced to a uniform-size subcube mapping problem. The simulated annealing method [9] is shown to be an effective algorithm for finding near-optimal solutions to NP-hard task-mapping problems [10, 11].
Reference: [9] <author> P. J. M. Laarhoven and E. H. L. Aarts, </author> <title> Simulated Annealing: Theory and Applications, </title> <address> D. </address> <publisher> Reidel Publishing Company, </publisher> <year> 1987. </year>
Reference-contexts: We will again focus on the discussion of the case of uniform-size communicating subcubes, since we have shown [8] that mapping variable-size subcubes can always be reduced to a uniform-size subcube mapping problem. The simulated annealing method <ref> [9] </ref> is shown to be an effective algorithm for finding near-optimal solutions to NP-hard task-mapping problems [10, 11]. In [11], we investigated a simulated annealing method optimization process for finding good sub-optimal mappings for the problem (G; 0; n).
Reference: [10] <author> F. Ercal, J. Ramanujam, and P. Sadayappan, </author> <title> "Task allocation onto a hypercube by recursive min-cut bipartitioning", </title> <booktitle> in Proc. of the Third Conf. on Hypercube Concurrent Computers and Applications, </booktitle> <pages> pp. 210-221, </pages> <month> Jan. </month> <year> 1988. </year>
Reference-contexts: The simulated annealing method [9] is shown to be an effective algorithm for finding near-optimal solutions to NP-hard task-mapping problems <ref> [10, 11] </ref>. In [11], we investigated a simulated annealing method optimization process for finding good sub-optimal mappings for the problem (G; 0; n). The implementation of the simulated annealing method here is based on parameters selected with a similar criterion as in [10]. <p> In [11], we investigated a simulated annealing method optimization process for finding good sub-optimal mappings for the problem (G; 0; n). The implementation of the simulated annealing method here is based on parameters selected with a similar criterion as in <ref> [10] </ref>. We set the initial temperature T 0 = 30, the new temperature T new = 0:95T , where T is the temperature in the last iteration.
Reference: [11] <author> B.-R. Tsai and K. G. Shin, </author> <title> "Communication-oriented assignment of task modules in faulty hypercube multicomputers", </title> <journal> IEEE Trans. on Computers, </journal> <volume> vol. C-36, </volume> <pages> pp. 1396-1407, </pages> <month> May </month> <year> 1994. </year>
Reference-contexts: The simulated annealing method [9] is shown to be an effective algorithm for finding near-optimal solutions to NP-hard task-mapping problems <ref> [10, 11] </ref>. In [11], we investigated a simulated annealing method optimization process for finding good sub-optimal mappings for the problem (G; 0; n). The implementation of the simulated annealing method here is based on parameters selected with a similar criterion as in [10]. <p> The simulated annealing method [9] is shown to be an effective algorithm for finding near-optimal solutions to NP-hard task-mapping problems [10, 11]. In <ref> [11] </ref>, we investigated a simulated annealing method optimization process for finding good sub-optimal mappings for the problem (G; 0; n). The implementation of the simulated annealing method here is based on parameters selected with a similar criterion as in [10].
Reference: [12] <author> A. V. Aho, J. E. Hopcroft, and J. D. Ull-man, </author> <title> Data Structures and Algorithms, </title> <publisher> Addison-Wesley, </publisher> <year> 1983. </year> <title> X </title> . 
Reference-contexts: The freezing point is set so that a move increasing the objective function by a unit value has an acceptable probability of 2 31 . The perturb function is given by performing random 2-opt exchanges <ref> [12] </ref> on the original mapping. Since each instance of 2-opt exchange takes approximately the same amount of computing time, the expected computing time of an optimization process can be normalized and expressed as the average number of exchanges performed.
References-found: 12

