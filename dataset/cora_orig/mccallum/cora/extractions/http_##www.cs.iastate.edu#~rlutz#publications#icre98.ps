URL: http://www.cs.iastate.edu/~rlutz/publications/icre98.ps
Refering-URL: http://www.cs.iastate.edu/~rlutz/homepage.html
Root-URL: http://www.cs.iastate.edu
Email: rlutz@cs.iastate.edu  mmoseman@cs.iastate.edu  srtockey, destatez@collins.rockwell.com  
Title: Safety Analysis of Requirements for a Product Family  
Author: Robyn R. Lutz Guy G. Helmer Michelle M. Moseman David E. Statezni Stephen R. Tockey 
Address: ghelmer,  Communication  
Affiliation: Iowa State University and Jet Propulsion Laboratory  Iowa State University  Rockwell Avionics and  
Abstract: A safety analysis was performed on the software requirements for a family of flight instrumentation displays of commercial aircraft. First, an existing Safety Checklist was extended to apply to four-variable models and used to analyze the requirements models for representative members of the product family. The results were evaluated against an initial specification of the product family's required commonalities and variabilities. The Safety Checklist was found to be effective at analyzing the completeness of the product family requirements and at identifying additional variabilities and commonalities. Secondly, a forward and backward search for hazards was performed on representative members of the product family. Additional safety requirements for enhanced fault tolerance were derived from these searches. The safety analysis techniques used here appear to have applicability for enhancing the completeness and robustness of a product family's safety-related software requirements. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Cha, S. S., N. G. Leveson, and T. J. </author> <month> Shimeall </month> <year> (1991), </year> <title> "Safety Verification of Ada Programs Using Fault Tree Analysis," </title> <journal> In IEEE Software, </journal> <volume> 8, 4, </volume> <pages> 48-59. </pages> <note> [2] de Lemos, </note> <author> R., A. Saeed, and T. </author> <title> Anderson (1995), "Analyzing Safety Requirements for Process-Control Systems," </title> <journal> IEEE Software 12, </journal> <volume> 3, </volume> <pages> 42-53. </pages>
Reference-contexts: Previous work indicates that Software Failure Modes and Effects Analysis (forward search for hazards) [15, 19, 23], in conjunction with Software Fault Tree Analysis (backward search for feasible combinations of enabling circumstances), <ref> [1, 2, 10] </ref> is effective at identifying unsafe situations that can sometimes be alleviated by derived software safety requirements [12].
Reference: [3] <author> Faulk, S., J. Brackett, P. Ward, and J. Kirby, Jr. </author> <year> (1992), </year> <title> "The CoRE Method for Real-Time Requirements," </title> <booktitle> In IEEE Software, </booktitle> <month> September </month> <year> 1992, </year> <pages> 22-33. </pages>
Reference-contexts: The requirements specification documents of three legacy members of the product family that was being developed also were an input to the safety analysis. At the beginning of our work, the project anticipated specifying the product family requirements in either CoRE <ref> [3] </ref> or in SCR* [6], which drove our interest in tailoring our safety analysis techniques to the four-variable model, upon which both CoRE and SCR* are based (see also [16]).
Reference: [4] <author> Fencott, C. and B. </author> <month> Hebbron </month> <year> (1995), </year> <title> "The Application of HAZOP Studies to Integrated Requirements Models for Control Systems," </title> <journal> ISA Transactions 34, </journal> <pages> 297-308. </pages>
Reference-contexts: The checklist was further extended to handle human-computer interactions in Leveson [10]. Forward and backward searches for hazards and their contributing causes are widely used to evaluate the safety aspects of both hardware and software <ref> [4, 5, 13, 14, 18] </ref>.
Reference: [5] <author> Heimdahl, M. P. E. and N. G. </author> <title> Leveson (1996), "Completeness and Consistency in Hierarchical State-Based Requirements," </title> <journal> IEEE Transactions on Software Engineering 22, </journal> <volume> 6, </volume> <pages> 363-377. </pages>
Reference-contexts: The checklist was further extended to handle human-computer interactions in Leveson [10]. Forward and backward searches for hazards and their contributing causes are widely used to evaluate the safety aspects of both hardware and software <ref> [4, 5, 13, 14, 18] </ref>.
Reference: [6] <author> Heitmeyer, C., A. Bull, C. Gasarch, and B. </author> <month> Labaw </month> <year> (1995), </year> <title> "SCR: A Toolset for Specifying and Analyzing Requirements," </title> <booktitle> In Proceedings of the 10th Annual Conference on Computer Assurance, IEEE, </booktitle> <address> Gaithersburg, MD, </address> <pages> pp. 109-122. </pages>
Reference-contexts: The requirements specification documents of three legacy members of the product family that was being developed also were an input to the safety analysis. At the beginning of our work, the project anticipated specifying the product family requirements in either CoRE [3] or in SCR* <ref> [6] </ref>, which drove our interest in tailoring our safety analysis techniques to the four-variable model, upon which both CoRE and SCR* are based (see also [16]). The requirements for the initial prototype were later developed using SCR*, allowing a clean fit with the four-variable version of the Safety Checklist.
Reference: [7] <author> Helmer, Guy G. </author> <year> (1997), </year> <title> "Safety Checklist for Four-Variable Requirements Methods," </title> <institution> TR98-01, Iowa State University Department of Computer Science. </institution>
Reference-contexts: familiar to both software and hardware engineers, are widely used and well documented, and can be taught. 2 Safety Analyis Techniques 2.1 Safety Checklist The checklists in [8, 10, 11] were combined into a single checklist that partitioned the criteria into those appropriate for the components of the four-variable model <ref> [7] </ref>. The four-variable model documents a system by describing its function in terms of the operations on the input variables, monitored variables, controlled variables, and output variables [17].
Reference: [8] <author> Jaffe, M. S., N. G. Leveson, M. P.E. Heimdahl, and B. E. </author> <month> Melhart </month> <year> (1991), </year> <title> "Software Requirements Analysis for Real-Time Process-Control Systems," </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 17, 3, </volume> <pages> 241-257. </pages>
Reference-contexts: In the work described here, a safety analysis was performed on the software requirements for a family of flight instrumentation displays of commercial aircraft. An overview of the safety analysis process is shown in Fig. 1. First, a set of completeness criteria for analyzing requirements, derived from <ref> [8, 10, 11] </ref>, was tailored for a four-variable model [17] and models were created of parts of three representive members of the product family. <p> The completeness criteria, originally developed by Jaffe, Leveson, Heimdahl, and Melhart as a set of predicates that must hold on a finite-state model of the requirements <ref> [8] </ref>, were translated by Lutz into an English-language checklist and used to target root causes of safety-related software errors found during spacecraft integration and system testing. <p> The safety analysis techniques chosen|Safety Checklist, SFMEA, and SFTA| support this goal in that checklists, FMEAs, and FTAs are techniques familiar to both software and hardware engineers, are widely used and well documented, and can be taught. 2 Safety Analyis Techniques 2.1 Safety Checklist The checklists in <ref> [8, 10, 11] </ref> were combined into a single checklist that partitioned the criteria into those appropriate for the components of the four-variable model [7].
Reference: [9] <author> Lamport, L. and N. </author> <title> Lynch (1990), "Distributed Computing Models and Methods," </title> <booktitle> In Handbook of Theoretical Computer Science, </booktitle> <volume> vol. </volume> <editor> B, </editor> <title> Formal Models and Semantics, </title> <editor> J. van Leeuwen, Ed. Cam-bridge/Amsterdam: </editor> <publisher> MIT Press/Elsevier, </publisher> <pages> pp. 1157-1199. </pages>
Reference-contexts: In a message-passing model of a distributed system, two kinds of failures are generally represented: communication failures and process failures <ref> [9] </ref>. In accordance with this model, two kinds of failures are analyzed in a SFMEA for each software component: communication failures (needed to analyze data dependencies and interface errors) and process failures (needed to analyze the effects of software failing to function correctly).
Reference: [10] <author> Leveson, N. G. </author> <year> (1995), </year> <title> Safeware: System Safety and Computers, </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA. </address>
Reference-contexts: In the work described here, a safety analysis was performed on the software requirements for a family of flight instrumentation displays of commercial aircraft. An overview of the safety analysis process is shown in Fig. 1. First, a set of completeness criteria for analyzing requirements, derived from <ref> [8, 10, 11] </ref>, was tailored for a four-variable model [17] and models were created of parts of three representive members of the product family. <p> The issues found involved the experimental prototypes of a future system currently in the requirements stage of development. Our focus was on validating the emerging product family requirements from a safety perspective. Following Leveson <ref> [10] </ref>, software safety is defined to be freedom from undesired and unplanned events that result in a specified level of loss. Software safety analy 2 sis techniques focus on how software can contribute to conditions that result in loss or failure. <p> In one study this Safety Checklist was found to address the causes of software safety errors discovered during integration and system testing in 77% of the cases [11]. The checklist was further extended to handle human-computer interactions in Leveson <ref> [10] </ref>. Forward and backward searches for hazards and their contributing causes are widely used to evaluate the safety aspects of both hardware and software [4, 5, 13, 14, 18]. <p> Previous work indicates that Software Failure Modes and Effects Analysis (forward search for hazards) [15, 19, 23], in conjunction with Software Fault Tree Analysis (backward search for feasible combinations of enabling circumstances), <ref> [1, 2, 10] </ref> is effective at identifying unsafe situations that can sometimes be alleviated by derived software safety requirements [12]. <p> The safety analysis techniques chosen|Safety Checklist, SFMEA, and SFTA| support this goal in that checklists, FMEAs, and FTAs are techniques familiar to both software and hardware engineers, are widely used and well documented, and can be taught. 2 Safety Analyis Techniques 2.1 Safety Checklist The checklists in <ref> [8, 10, 11] </ref> were combined into a single checklist that partitioned the criteria into those appropriate for the components of the four-variable model [7]. <p> These were: "Autopilot engaged when display shows not en gaged," "Fault flag displayed erroneously," and "Cue (aircraft icon) displayed when should be removed." These three failure modes then served as initial root nodes for the backward search. The backward search used the Software Fault Tree Analysis (SFTA) technique <ref> [10] </ref> to work backward in time considering the possible combinations of events that could have led to the failure indicated by the root node.
Reference: [11] <author> Lutz, R. R. </author> <year> (1996), </year> <title> "Targeting Safety-Related Errors During Software Requirements Analysis," </title> <journal> In Journal of Systems and Software, </journal> <volume> 34, </volume> <pages> 223-230. </pages>
Reference-contexts: In the work described here, a safety analysis was performed on the software requirements for a family of flight instrumentation displays of commercial aircraft. An overview of the safety analysis process is shown in Fig. 1. First, a set of completeness criteria for analyzing requirements, derived from <ref> [8, 10, 11] </ref>, was tailored for a four-variable model [17] and models were created of parts of three representive members of the product family. <p> In one study this Safety Checklist was found to address the causes of software safety errors discovered during integration and system testing in 77% of the cases <ref> [11] </ref>. The checklist was further extended to handle human-computer interactions in Leveson [10]. Forward and backward searches for hazards and their contributing causes are widely used to evaluate the safety aspects of both hardware and software [4, 5, 13, 14, 18]. <p> The safety analysis techniques chosen|Safety Checklist, SFMEA, and SFTA| support this goal in that checklists, FMEAs, and FTAs are techniques familiar to both software and hardware engineers, are widely used and well documented, and can be taught. 2 Safety Analyis Techniques 2.1 Safety Checklist The checklists in <ref> [8, 10, 11] </ref> were combined into a single checklist that partitioned the criteria into those appropriate for the components of the four-variable model [7].
Reference: [12] <author> Lutz, R. and R. </author> <month> Woodhouse </month> <year> (1997), </year> <title> "Requirements Analysis Using Forward and Backward Search," </title> <journal> Annals of Software Engineering, Special Volume on Requirements Engineering, </journal> <volume> 3, </volume> <pages> pp. 459-475. </pages>
Reference-contexts: work indicates that Software Failure Modes and Effects Analysis (forward search for hazards) [15, 19, 23], in conjunction with Software Fault Tree Analysis (backward search for feasible combinations of enabling circumstances), [1, 2, 10] is effective at identifying unsafe situations that can sometimes be alleviated by derived software safety requirements <ref> [12] </ref>. One goal of our work was to enable the transfer of these safety analysis techniques to the reuse project as it scaled up the dimensions of the product family it was supporting. <p> To assist in the analysis of any possible failures of the software, two types of tables, Data Tables and Event Tables, are constructed. (A more detailed description of forward and backward searches appears in <ref> [12] </ref>). The SFMEA was organized so as to facilitate consideration of the product family requirements. The effect of each category of anomalous data or behavior (e.g., "Timing of Data Wrong," "Abnormal Termination of Process") was considered separately for each of the three representative members of the product family.
Reference: [13] <author> Maier, T. </author> <year> (1995), </year> <title> "FMEA and FTA To Support Safe Design of Embedded Software in Safety-Critical Systems," </title> <booktitle> In CSR 12th Annual Workshop on Safety and Reliability of Software Based Systems, </booktitle> <address> Bruges, Bel-gium. </address>
Reference-contexts: The checklist was further extended to handle human-computer interactions in Leveson [10]. Forward and backward searches for hazards and their contributing causes are widely used to evaluate the safety aspects of both hardware and software <ref> [4, 5, 13, 14, 18] </ref>.
Reference: [14] <author> McDermid, J. A. and D. J. </author> <month> Pumfrey </month> <year> (1994), </year> <title> "A Development of Hazard Analysis To Aid Software Design," </title> <booktitle> In Proceedings of the 9th Annual Conference on Computer Assurance, IEEE, </booktitle> <address> Gaithersburg, MD, </address> <pages> pp. 17-25. </pages>
Reference-contexts: The checklist was further extended to handle human-computer interactions in Leveson [10]. Forward and backward searches for hazards and their contributing causes are widely used to evaluate the safety aspects of both hardware and software <ref> [4, 5, 13, 14, 18] </ref>.
Reference: [15] <author> Military Standard, </author> <title> Procedures for Performing a Failure Mode, Effects and Criticality Analysis (1980), </title> <publisher> MIL-STD-1629A. </publisher>
Reference-contexts: Forward and backward searches for hazards and their contributing causes are widely used to evaluate the safety aspects of both hardware and software [4, 5, 13, 14, 18]. Previous work indicates that Software Failure Modes and Effects Analysis (forward search for hazards) <ref> [15, 19, 23] </ref>, in conjunction with Software Fault Tree Analysis (backward search for feasible combinations of enabling circumstances), [1, 2, 10] is effective at identifying unsafe situations that can sometimes be alleviated by derived software safety requirements [12].
Reference: [16] <author> Miller, S. P. </author> <year> (1998), </year> <title> "Specifying the Mode Logic of a Flight Guidance System in CoRE and SCR," </title> <booktitle> 2nd Workshop on Formal Methods in Software Practice, </booktitle> <address> Clearwater Beach, FL, </address> <publisher> forthcoming. </publisher>
Reference-contexts: At the beginning of our work, the project anticipated specifying the product family requirements in either CoRE [3] or in SCR* [6], which drove our interest in tailoring our safety analysis techniques to the four-variable model, upon which both CoRE and SCR* are based (see also <ref> [16] </ref>). The requirements for the initial prototype were later developed using SCR*, allowing a clean fit with the four-variable version of the Safety Checklist. From a safety perspective, our primary concern was the completeness of the commonalities and variabilities that the reuse process identified and the requirements for robustness.
Reference: [17] <author> Parnas, D. L. and J. </author> <title> Madey (1995), "Functional Documents for Computer Systems," </title> <journal> In Journal of Systems and Software, </journal> <volume> 25, 1, </volume> <pages> 41-61. </pages>
Reference-contexts: An overview of the safety analysis process is shown in Fig. 1. First, a set of completeness criteria for analyzing requirements, derived from [8, 10, 11], was tailored for a four-variable model <ref> [17] </ref> and models were created of parts of three representive members of the product family. The relevant completeness criteria, formatted as a Safety Checklist (a set of questions to guide analysis), were then used to analyze the requirements models for these three representative members of the product family. <p> The four-variable model documents a system by describing its function in terms of the operations on the input variables, monitored variables, controlled variables, and output variables <ref> [17] </ref>.
Reference: [18] <author> Reese, J. D., </author> <title> "Software Deviation Analysis," </title> <type> Ph.D. thesis, </type> <institution> University of California, Irvine, California, </institution> <year> 1995. </year>
Reference-contexts: The checklist was further extended to handle human-computer interactions in Leveson [10]. Forward and backward searches for hazards and their contributing causes are widely used to evaluate the safety aspects of both hardware and software <ref> [4, 5, 13, 14, 18] </ref>.
Reference: [19] <author> Reifer, D. J. </author> <year> (1979), </year> <title> "Software Failure Modes and Effects Analysis,"IEEE Transactions on Reliability, </title> <journal> R-28, </journal> <volume> 3, </volume> <pages> 247-249. </pages>
Reference-contexts: Forward and backward searches for hazards and their contributing causes are widely used to evaluate the safety aspects of both hardware and software [4, 5, 13, 14, 18]. Previous work indicates that Software Failure Modes and Effects Analysis (forward search for hazards) <ref> [15, 19, 23] </ref>, in conjunction with Software Fault Tree Analysis (backward search for feasible combinations of enabling circumstances), [1, 2, 10] is effective at identifying unsafe situations that can sometimes be alleviated by derived software safety requirements [12].
Reference: [20] <author> RTCA/DO-178B (1992), </author> <title> Software Considerations in Airborne Systems and Equipment Certification, </title> <publisher> RTCA, Inc., </publisher> <address> 1140 Connecticut Avenue, NW, Suite 1020, Washington, DC, </address> <pages> 20036-4001. </pages>
Reference-contexts: For example, the entire set of display outputs produced by the software analyzed here would need to be certified to DO-178B Level A (the highest level of criticality) since the software's anomalous behavior could cause or contribute to a catastrophic failure condition for the aircraft <ref> [20] </ref>. 1.2 Related Work The safety analysis techniques used here are well defined in the literature.
Reference: [21] <institution> Software Productivity Consortium (Nov., </institution> <year> 1993), </year> <title> Reuse-Driven Software Processes Guidebook, </title> <publisher> SPC-92019-CMC, v. 02.00.03. </publisher>
Reference-contexts: For the software portion of this project, the Software Productivity Consortium's (SPC) description of the process of producing reusable software <ref> [21] </ref> was used as a baseline. Our work formed part of their "Domain Verification Activity," which SPC defines as, "Verify the correctness, consistency, and completeness of DE (Domain Engineering) work products" (Fig. 2). The product family that we worked with was a flight instrumentation display.
Reference: [22] <author> Weiss, D. M. </author> <year> (1997), </year> <title> "Defining Families: The Commonality Analysis," </title> <note> submitted for publication. </note>
Reference-contexts: 1 Introduction With increased reuse of software components comes a growing awareness of the difficulty of specifying the requirements for a family of software products in such a way that the possible variations among the family members are adequately represented <ref> [22] </ref>. From a safety perspective, ensuring completeness in the software requirements is an essential part of the reuse process. The safety analysis helps verify that all implicit required commonalities and all permitted variations among the family members are accurately and com fl c fl1998 IEEE.
Reference: [23] <author> Wunram, J. </author> <year> (1990), </year> <title> "A Strategy for Identification and Development of Safety Critical Software Embedded in Complex Space Systems," </title> <address> IAA 90-557, </address> <pages> 35-51. 8 </pages>
Reference-contexts: Forward and backward searches for hazards and their contributing causes are widely used to evaluate the safety aspects of both hardware and software [4, 5, 13, 14, 18]. Previous work indicates that Software Failure Modes and Effects Analysis (forward search for hazards) <ref> [15, 19, 23] </ref>, in conjunction with Software Fault Tree Analysis (backward search for feasible combinations of enabling circumstances), [1, 2, 10] is effective at identifying unsafe situations that can sometimes be alleviated by derived software safety requirements [12].
References-found: 22

