URL: ftp://ftp.cs.utexas.edu/pub/mooney/papers/emnlp-96.ps.Z
Refering-URL: http://www.cs.utexas.edu/users/ml/abstracts.html
Root-URL: 
Email: mooney@cs.utexas.edu  
Title: Comparative Experiments on Disambiguating Word Senses: An Illustration of the Role of Bias in Machine Learning  
Author: Raymond J. Mooney 
Address: Austin, TX 78712-1188  
Affiliation: Department of Computer Sciences University of Texas  
Date: 1996  
Note: Appears in Conference on Empirical Methods in Natural Language Processing,  
Abstract: This paper describes an experimental comparison of seven different learning algorithms on the problem of learning to disambiguate the meaning of a word from context. The algorithms tested include statistical, neural-network, decision-tree, rule-based, and case-based classification techniques. The specific problem tested involves disambiguating six senses of the word "line" using the words in the current and proceeding sentence as context. The statistical and neural-network methods perform the best on this particular problem and we discuss a potential reason for this observed difference. We also discuss the role of bias in machine learning and its importance in explaining performance differences observed on specific problems. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Aha, D. W. </author> <year> (1992). </year> <title> Generalizing from case studies: A case study. </title> <booktitle> In Proceedings of the Ninth International Conference on Machine Learning, </booktitle> <pages> pp. </pages> <address> 1-10 Aberdeen, Scotland. </address>
Reference-contexts: A simple approach is to automate the selection of a method using internal cross-validation (Schaffer, 1993). Another approach is to use meta-learning to learn a set of rules (or other classifier) that predicts when a learning algorithm will perform best on a domain given features describing the problem <ref> (Aha, 1992) </ref>. A recent special issue of the Machine Learning journal on "Bias Evaluation and Selection" introduced by Gordon and desJardins (1995) presents current research in this general area.
Reference: <author> Aha, D. W., Kibler, D., & Albert, M. K. </author> <year> (1991). </year> <title> Instance-based learning algorithms. </title> <journal> Machine Learning, </journal> <volume> 6 (1), </volume> <pages> 37-66. </pages>
Reference-contexts: Nearest neighbor bases its classifications on all features; however, it weights them all equally. Therefore, differential weighting is apparently necessary for high-performance on this problem. Alternative instance-based methods that weight features based on their predictive ability have also been developed <ref> (Aha et al., 1991) </ref>. Therefore, our results indicate that lexical disambiguation is perhaps best performed using methods that combine weighted evidence from all of the features rather tures actually present in the examples.
Reference: <author> Anoe, C., & Bennett, S. W. </author> <year> (1995). </year> <title> Evaluating automated and manual acquisition of anaphora resolution strategies. </title> <booktitle> In Proceedings of the 33rd Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> pp. </pages> <address> 122-129 Cambridge, MA. </address>
Reference-contexts: Similar comparisons of a range of algorithms should also be performed on other natural language problems such as part-of-speech tagging (Church, 1988), prepositional phrase attachment (Hindle & Rooth, 1993), anaphora resolution <ref> (Anoe & Bennett, 1995) </ref>, etc.. Since the requirements of individual tasks vary, different algorithms may be suitable for different sub-problems in natural language processing. Conclusions This paper has presented fairly comprehensive experiments comparing seven quite different empirical methods on learning to disambiguate words in context.
Reference: <author> Atlas, L., Cole, R., Conner, J., El-Sharkawi, M., Marks, R., Muthusamy, Y., & Bernard, E. </author> <year> (1990). </year> <title> Performance comparisons between backpropagation networks and classification trees on three real-world applications. </title> <editor> In Touretzky, D. S. (Ed.), </editor> <booktitle> Advances in Neural Information Processing Systems 2. </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA. </address>
Reference: <author> Baffes, P., & Mooney, R. </author> <year> (1993). </year> <title> Symbolic revision of theories with M-of-N rules. </title> <booktitle> In Proceedings of the Thirteenth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 1135-1140 Chambery, France. </address>
Reference: <author> Blumer, A., Ehrenfeucht, A., Haussler, D., & War-muth, M. </author> <year> (1987). </year> <title> Occam's razor. </title> <journal> Information Processing Letters, </journal> <volume> 24, </volume> <pages> 377-380. </pages>
Reference-contexts: Most learning algorithms have some sort of "Occam's razor" bias in which hypotheses that can be represented with fewer bits in some particular representation language are preferred <ref> (Blumer, Ehrenfeucht, Haussler, & Warmuth, 1987) </ref>. However, the compactness with which different representation languages (e.g. decision trees, DNF, linear threshold networks) can represent particular functions can vary dramatically (e.g. see Pagallo and Haussler (1990)). Therefore, different biases can perform better or worse on specific problems.
Reference: <author> Brill, E. </author> <year> (1993). </year> <title> Automatic grammar induction and parsing free text: A transformation-based approach. </title> <booktitle> In Proceedings of the 31st Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> pp. </pages> <address> 259-265 Colum-bus, Ohio. </address>
Reference-contexts: An important question is whether some methods perform significantly better than others on particular types of problems. Unfortunately, there have been very few direct comparisons of alternative methods on identical test data. A somewhat indirect comparison of applying stochastic context-free grammars (Periera & Shabes, 1992), a transformation-based method <ref> (Brill, 1993) </ref>, and inductive logic programming (Zelle & Mooney, 1994) to parsing the ATIS (Airline Travel Information Service) corpus from the Penn Treebank (Marcus, Santorini, & Marcinkiewicz, 1993) indicates fairly similar performance for these three very different methods.
Reference: <author> Brown, P., Della-Pietra, S., Della-Pietra, V., & Mercer, R. </author> <year> (1991). </year> <title> Word sense disambiguation using statistical methods. </title> <booktitle> In Proceedings of the 29th Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> pp. 264-270. </pages>
Reference: <author> Charniak, E. </author> <year> (1993). </year> <title> Statistical Language Learning. </title> <publisher> MIT Press. </publisher>
Reference: <author> Church, K. </author> <year> (1988). </year> <title> A stochastic parts program and noun phrase parser for unrestricted text. </title> <booktitle> In Proceedings of the Second Conference on Applied Natural Language Processing. Association for Computational Linguistics. </booktitle>
Reference-contexts: In particular, it would be interesting to see if the accuracy ranking of the seven algorithms is affected by a change in the representation. Similar comparisons of a range of algorithms should also be performed on other natural language problems such as part-of-speech tagging <ref> (Church, 1988) </ref>, prepositional phrase attachment (Hindle & Rooth, 1993), anaphora resolution (Anoe & Bennett, 1995), etc.. Since the requirements of individual tasks vary, different algorithms may be suitable for different sub-problems in natural language processing.
Reference: <author> Clark, P., & Niblett, T. </author> <year> (1989). </year> <title> The CN2 induction algorithm. </title> <journal> Machine Learning, </journal> <volume> 3, </volume> <pages> 261-284. </pages>
Reference: <author> Cover, T. M., & Hart, P. E. </author> <year> (1967). </year> <title> Nearest neighbor pattern classification. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> 13, </volume> <pages> 21-27. </pages>
Reference-contexts: We compare a naive Bayesian classifier (Duda & Hart, 1973), a perceptron (Rosenblatt, 1962), a decision-tree learner (Quinlan, 1993), a k nearest-neighbor classifier <ref> (Cover & Hart, 1967) </ref>, logic-based DNF (disjunctive normal form) and CNF (conjunctive normal form) learners (Mooney, 1995) and a decision-list learner (Rivest, 1987).
Reference: <author> Dietterich, T. G., Hild, H., & Bakiri, G. </author> <year> (1990). </year> <title> A comparative study of ID3 and backpropagation for English text-to-speech mapping. </title> <booktitle> In Proceedings of the Seventh International Conference on Machine Learning, </booktitle> <pages> pp. </pages> <address> 24-31 Austin, TX. </address>
Reference: <author> Duda, R. O., & Hart, P. E. </author> <year> (1973). </year> <title> Pattern Classification and Scene Analysis. </title> <publisher> Wiley, </publisher> <address> New York. </address>
Reference-contexts: In this paper, we present direct comparisons of a fairly wide range of general learning algorithms on the problem of discriminating six senses of the word "line" from context, using data assembled by Leacock et al. (1993b). We compare a naive Bayesian classifier <ref> (Duda & Hart, 1973) </ref>, a perceptron (Rosenblatt, 1962), a decision-tree learner (Quinlan, 1993), a k nearest-neighbor classifier (Cover & Hart, 1967), logic-based DNF (disjunctive normal form) and CNF (conjunctive normal form) learners (Mooney, 1995) and a decision-list learner (Rivest, 1987).
Reference: <author> Fisher, D. H., & McKusick, K. B. </author> <year> (1989). </year> <title> An empirical comparison of ID3 and backpropagation. </title> <booktitle> In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 788-793 Detroit, MI. </address>
Reference: <author> Friedman, J., Bentley, J., & Finkel, R. </author> <year> (1977). </year> <title> An algorithm for finding best matches in logarithmic expected time. </title> <journal> ACM Transactions on Mathematical Software, </journal> <volume> 3 (3), </volume> <pages> 209-226. </pages>
Reference-contexts: Naive Bayes is the slowest; both it and perceptron have the constant overhead of computing a weighted function over all of the almost 3,000 features. Nearest neighbor grows linearly with the number of training instances as expected; more sophisticated indexing methods can reduce this to logarithmic expected time <ref> (Friedman, Bentley, & Finkel, 1977) </ref>. 5 4 C4.5 suffers a small constant overhead due to the C code having to read the test data in from a separate file. 5 It should be noted that the implementation of nearest neighbor was optimized to handle sparse binary vectors by only including and
Reference: <author> Gale, W., Church, K., & Yarowsky, D. </author> <year> (1992a). </year> <title> A method for disambiguating word senses in a large corpus. </title> <journal> Computers and the Humanities, </journal> <volume> 26, </volume> <pages> 415-439. </pages>
Reference-contexts: Previous studies have first sampled the data so that all senses were equally represented. Leacock et al. (1993b), Leacock, Towell, and Voorhees (1993a) and Voorhees, Leacock, and Towell (1995) present results on a Bayesian method <ref> (Gale, Church, & Yarowsky, 1992a) </ref>, a content vector method from information retrieval (Salton, Wong, & Yang, 1975), and a neural network trained using backpropagation (Rumelhart, Hinton, & Williams, 1986).
Reference: <author> Gale, W., Church, K. W., & Yarowsky, D. </author> <year> (1992b). </year> <title> Estimating upper and lower bounds on the performance of word-sense disambiguation programs. </title> <booktitle> In Proceedings of the 30th Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> pp. </pages> <address> 249-256 Newark, Delaware. </address>
Reference: <editor> Gordon, D. F., & desJardins, M. </editor> <year> (1995). </year> <title> Evaluation and selection of biases in machine learning. </title> <journal> Machine Learning, </journal> <volume> 20 (1/2), </volume> <pages> 5-22. </pages>
Reference-contexts: If all problems are not equally likely, the expected generalization performance over a distribution of real-world problems can of course be positive <ref> (Rao, Gordon, & Spears, 1995) </ref>. In machine learning, bias refers to "any basis for choosing one generalization over another, other than strict consistency with the instances" (Mitchell, 1980).
Reference: <author> Hindle, D., & Rooth, M. </author> <year> (1993). </year> <title> Structural ambiguity and lexical relations. </title> <journal> Computational Linguistics, </journal> <volume> 19 (1), </volume> <pages> 103-120. </pages>
Reference-contexts: In particular, it would be interesting to see if the accuracy ranking of the seven algorithms is affected by a change in the representation. Similar comparisons of a range of algorithms should also be performed on other natural language problems such as part-of-speech tagging (Church, 1988), prepositional phrase attachment <ref> (Hindle & Rooth, 1993) </ref>, anaphora resolution (Anoe & Bennett, 1995), etc.. Since the requirements of individual tasks vary, different algorithms may be suitable for different sub-problems in natural language processing.
Reference: <author> Holte, R. C. </author> <year> (1993). </year> <title> Very simple classification rules perform well on most commonly used datasets. </title> <journal> Machine Learning, </journal> <volume> 11 (1), </volume> <pages> 63-90. </pages>
Reference: <author> Hume, D. </author> <title> (1748). An Inquiry Concerning Human Understanding Reprinted 1955. </title> <publisher> Liberal Arts Press, </publisher> <address> New York. </address>
Reference: <author> Kulikowski, C. A., & Weiss, S. M. </author> <year> (1991). </year> <title> Computer Systems That Learn - Classification and Prediction Methods from Statistics, Neural Nets, Machine Learning, and Expert Systems. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA. </address>
Reference: <author> Langley, P. </author> <year> (1996). </year> <title> Elements of Machine Learning. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Francisco, CA. </address>
Reference: <author> Leacock, C., Towell, G., & Voorhees, E. </author> <year> (1993a). </year> <title> Corpus-based statistical sense resolution. </title> <booktitle> In Proceedings of the ARPA Workshop on Human Language Technology. </booktitle>
Reference: <author> Leacock, C., Towell, G., & Voorhees, E. </author> <year> (1993b). </year> <title> Towards building contextual representations of word senses using statistical models. </title> <booktitle> In Proceedings of the SIGLEX Workshop: Acquisition of Lexical Knowledge from Text, </booktitle> <pages> pp. 10-20. </pages> <institution> Association for Computational Linguistics. </institution>
Reference: <author> Lehman, J. F. </author> <year> (1994). </year> <title> Toward the essential nature of satistical knowledge in sense resolution. </title> <booktitle> In Proceedings of the Twelfth National Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 734-741 Seattle, WA. </address>
Reference: <author> Ling, C. X. </author> <year> (1994). </year> <title> Learning the past tense of English verbs: The symbolic pattern asso-ciator vs. connectionist models. </title> <journal> Journal of Artificial Intelligence Research, </journal> <volume> 1, </volume> <pages> 209-229. </pages>
Reference: <author> Ling, C. X., & Marinov, M. </author> <year> (1993). </year> <title> Answering the connectionist challenge: A symbolic model of learning the past tense of English verbs. </title> <journal> Cognition, </journal> <volume> 49 (3), </volume> <pages> 235-290. </pages>
Reference: <author> Marcus, M., Santorini, B., & Marcinkiewicz, M. </author> <year> (1993). </year> <title> Building a large annotated corpus of English: The Penn treebank. </title> <journal> Computational Linguistics, </journal> <volume> 19 (2), </volume> <pages> 313-330. </pages>
Reference-contexts: A somewhat indirect comparison of applying stochastic context-free grammars (Periera & Shabes, 1992), a transformation-based method (Brill, 1993), and inductive logic programming (Zelle & Mooney, 1994) to parsing the ATIS (Airline Travel Information Service) corpus from the Penn Treebank <ref> (Marcus, Santorini, & Marcinkiewicz, 1993) </ref> indicates fairly similar performance for these three very different methods. Also, comparisons of Bayesian, information retrieval, neural-network, and case-based methods on word-sense disambiguation have also demonstrated similar performance (Leacock, Towell, & Voorhees, 1993b; Lehman, 1994).
Reference: <author> Merz, C., Murphy, P. M., & Aha, D. W. </author> <year> (1996). </year> <note> Repository of machine learning databases http://www.ics.uci.edu/~mlearn/mlrepository.html. Department of Information and Computer Science, </note> <institution> University of California, </institution> <address> Irvine, CA. </address>
Reference-contexts: Background on Machine Learning and Bias Research in machine learning over the last ten years has been particularly concerned with experimental comparisons and the relative performance of different classification methods (Shavlik & Di etterich, 1990; Kulikowski & Weiss, 1991; Langley, 1996). In particular, the UCI Machine Learning Data Repository <ref> (Merz, Murphy, & Aha, 1996) </ref> was assembled to facilitate empirical comparisons.
Reference: <author> Michalski, R. S. </author> <year> (1983). </year> <title> A theory and methodology of inductive learning. </title> <editor> In Michalski, R. S., Carbonell, J. G., & Mitchell, T. M. (Eds.), </editor> <booktitle> Machine Learning: An Artificial Intelligence Approach, </booktitle> <pages> pp. 83-134. </pages> <publisher> Tioga. </publisher>
Reference: <author> Miller, G. </author> <year> (1991). </year> <title> WordNet: An on-line lexical database. </title> <journal> International Journal of Lexicography, </journal> <volume> 3 (4). </volume>
Reference-contexts: The corpus was assembled from the 1987-89 Wall Street Journal and a 25 million word corpus from the American Printing House for the Blind. Sentences containing "line" were extracted and assigned a single sense from WordNet <ref> (Miller, 1991) </ref>. There are a total of 4,149 examples in the full corpus unequally distributed across the six senses. Due to the use of the Wall Street Journal, the "product" sense is more than 5 times as common as any of the others.
Reference: <author> Mitchell, T. </author> <year> (1980). </year> <title> The need for biases in learning generalizations. </title> <type> Tech. rep. </type> <institution> CBM-TR-117, Rutgers University. </institution> <note> Reprinted in Readings in Machine Learning, </note> <editor> J. W. </editor> <booktitle> Shavlik and T. </booktitle>
Reference-contexts: If all problems are not equally likely, the expected generalization performance over a distribution of real-world problems can of course be positive (Rao, Gordon, & Spears, 1995). In machine learning, bias refers to "any basis for choosing one generalization over another, other than strict consistency with the instances" <ref> (Mitchell, 1980) </ref>. Decision-tree methods have a bias for simple decision trees, rule induction methods have a bias for simple DNF expressions, neural-network methods have a bias for linear threshold functions, 1 and naive Bayes has a bias for functions which respect conditional independence of features.
Reference: <editor> G. Dietterich (eds.), </editor> <publisher> Morgan Kaufman, </publisher> <address> San Mateo, CA, </address> <year> 1990. </year>
Reference: <author> Mooney, R. J. </author> <year> (1995). </year> <title> Encouraging experimental results on learning CNF. </title> <journal> Machine Learning, </journal> <volume> 19 (1), </volume> <pages> 79-92. </pages>
Reference-contexts: Subsequent experiments on this problem have demonstrated that an inductive logic programming method produces even better results than decision trees <ref> (Mooney & Califf, 1995) </ref>. In this paper, we present direct comparisons of a fairly wide range of general learning algorithms on the problem of discriminating six senses of the word "line" from context, using data assembled by Leacock et al. (1993b). <p> We compare a naive Bayesian classifier (Duda & Hart, 1973), a perceptron (Rosenblatt, 1962), a decision-tree learner (Quinlan, 1993), a k nearest-neighbor classifier (Cover & Hart, 1967), logic-based DNF (disjunctive normal form) and CNF (conjunctive normal form) learners <ref> (Mooney, 1995) </ref> and a decision-list learner (Rivest, 1987). Tests on all methods used identical training and test sets, and ten separate random trials were run in order to measure average performance and allow statistical testing of the significance of any observed differences. <p> Most rule-based methods, e.g. Michalski (1983), induce a disjunctive set of conjunctive rules and therefore represent concepts in DNF. Some recent results have indicated that representing concepts in CNF (a conjunction of disjunctions) frequently performs somewhat better <ref> (Mooney, 1995) </ref>. Some concepts are more compactly represented in CNF compared to DNF and vice versa. Therefore, both representations are included. <p> Empirically, the time complexity for most methods are growing somewhat worse than linearly in the number of training examples. The worst in this regard are PFoil-DNF and PFoil-CNF which have a worst-case complexity of O (n 2 ) <ref> (Mooney, 1995) </ref>. However, all of the methods are able to process fairly large sets of data in reasonable time. With respect to testing time, the symbolic methods perform the best since they only need to test a small number of features before making a decision.
Reference: <author> Mooney, R. J., & Califf, M. E. </author> <year> (1995). </year> <title> Induction of first-order decision lists: Results on learning the past tense of English verbs. </title> <journal> Journal of Artificial Intelligence Research, </journal> <volume> 3, </volume> <pages> 1-24. </pages>
Reference-contexts: Subsequent experiments on this problem have demonstrated that an inductive logic programming method produces even better results than decision trees <ref> (Mooney & Califf, 1995) </ref>. In this paper, we present direct comparisons of a fairly wide range of general learning algorithms on the problem of discriminating six senses of the word "line" from context, using data assembled by Leacock et al. (1993b). <p> We compare a naive Bayesian classifier (Duda & Hart, 1973), a perceptron (Rosenblatt, 1962), a decision-tree learner (Quinlan, 1993), a k nearest-neighbor classifier (Cover & Hart, 1967), logic-based DNF (disjunctive normal form) and CNF (conjunctive normal form) learners <ref> (Mooney, 1995) </ref> and a decision-list learner (Rivest, 1987). Tests on all methods used identical training and test sets, and ten separate random trials were run in order to measure average performance and allow statistical testing of the significance of any observed differences. <p> Most rule-based methods, e.g. Michalski (1983), induce a disjunctive set of conjunctive rules and therefore represent concepts in DNF. Some recent results have indicated that representing concepts in CNF (a conjunction of disjunctions) frequently performs somewhat better <ref> (Mooney, 1995) </ref>. Some concepts are more compactly represented in CNF compared to DNF and vice versa. Therefore, both representations are included. <p> Empirically, the time complexity for most methods are growing somewhat worse than linearly in the number of training examples. The worst in this regard are PFoil-DNF and PFoil-CNF which have a worst-case complexity of O (n 2 ) <ref> (Mooney, 1995) </ref>. However, all of the methods are able to process fairly large sets of data in reasonable time. With respect to testing time, the symbolic methods perform the best since they only need to test a small number of features before making a decision.
Reference: <author> Mooney, R. J., Shavlik, J. W., Towell, G., & Gove, A. </author> <year> (1989). </year> <title> An experimental comparison of symbolic and connectionist learning algorithms. </title> <booktitle> In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 775-780 Detroit, MI. </address> <note> Reprinted in Readings in Machine Learning, </note> <editor> J. W. Shavlik and T. G. Dietterich (eds.), </editor> <publisher> Morgan Kaufman, </publisher> <address> San Mateo, CA, </address> <year> 1990. </year>
Reference: <author> Murphy, P. M., & Pazzani, M. J. </author> <year> (1991). </year> <title> ID2-of-3: Constructive induction of M-of-N concepts for discriminators in decision trees. </title> <booktitle> In Proceedings of the Eighth International Workshop on Machine Learning, </booktitle> <pages> pp. </pages> <address> 183-187 Evanston, IL. </address>
Reference: <author> Pagallo, G., & Haussler, D. </author> <year> (1990). </year> <title> Boolean feature discovery in empirical learning. </title> <journal> Machine Learning, </journal> <volume> 5, </volume> <pages> 71-100. </pages>
Reference: <author> Periera, F., & Shabes, Y. </author> <year> (1992). </year> <title> Inside-outside reestimation from partially bracketed corpora. </title> <booktitle> In Proceedings of the 30th Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> pp. </pages> <address> 128-135 Newark, Delaware. </address>
Reference-contexts: An important question is whether some methods perform significantly better than others on particular types of problems. Unfortunately, there have been very few direct comparisons of alternative methods on identical test data. A somewhat indirect comparison of applying stochastic context-free grammars <ref> (Periera & Shabes, 1992) </ref>, a transformation-based method (Brill, 1993), and inductive logic programming (Zelle & Mooney, 1994) to parsing the ATIS (Airline Travel Information Service) corpus from the Penn Treebank (Marcus, Santorini, & Marcinkiewicz, 1993) indicates fairly similar performance for these three very different methods.
Reference: <author> Quinlan, J. R. </author> <year> (1993). </year> <title> C4.5: Programs for Machine Learning. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Ma-teo,CA. </address>
Reference-contexts: We compare a naive Bayesian classifier (Duda & Hart, 1973), a perceptron (Rosenblatt, 1962), a decision-tree learner <ref> (Quinlan, 1993) </ref>, a k nearest-neighbor classifier (Cover & Hart, 1967), logic-based DNF (disjunctive normal form) and CNF (conjunctive normal form) learners (Mooney, 1995) and a decision-list learner (Rivest, 1987). <p> In the current experiments, there was never a problem with convergence during training. As a representative of decision-tree methods, we chose C4.5 <ref> (Quinlan, 1993) </ref>, a system that is easily available and included in most recent experimental comparisons in machine learning. All parameters were left at their default values.
Reference: <author> Quinlan, J. </author> <year> (1990). </year> <title> Learning logical definitions from relations. </title> <journal> Machine Learning, </journal> <volume> 5 (3), </volume> <pages> 239-266. </pages>
Reference-contexts: All of the logic-based methods are variations of the Foil algorithm for induction of first-order function-free Horn clauses <ref> (Quinlan, 1990) </ref>, appropriately simplified for the propositional case. They are called PFoil-DNF, PFoil-CNF, and PFoil-DList. The algorithms are greedy covering (separate-and-conquer) methods that use an information-theoretic heuristic to guide a top-down search for a simple definition consistent with the training data.
Reference: <author> Rao, R. B., Gordon, D., & Spears, W. </author> <year> (1995). </year> <title> For every generalization action is there really an equal an opposite reaction? Analysis of the conservation law for generalization performance. </title> <booktitle> In Proceedings of the Twelfth International Conference on Machine Learning, </booktitle> <pages> pp. </pages> <address> 471-479 San Francisco, CA. </address> <publisher> Morgan Kaufman. </publisher>
Reference-contexts: If all problems are not equally likely, the expected generalization performance over a distribution of real-world problems can of course be positive <ref> (Rao, Gordon, & Spears, 1995) </ref>. In machine learning, bias refers to "any basis for choosing one generalization over another, other than strict consistency with the instances" (Mitchell, 1980).
Reference: <editor> Reilly, R. G., & Sharkey, N. E. (Eds.). </editor> <year> (1992). </year> <title> Connectionist Approaches to Natural Language Processing. </title> <publisher> Lawrence Erlbaum and Associates, </publisher> <address> Hilldale, NJ. </address>
Reference: <author> Rivest, R. L. </author> . <year> (1987). </year> <title> Learning decision lists. </title> <journal> Machine Learning, </journal> <volume> 2 (3), </volume> <pages> 229-246. </pages>
Reference-contexts: We compare a naive Bayesian classifier (Duda & Hart, 1973), a perceptron (Rosenblatt, 1962), a decision-tree learner (Quinlan, 1993), a k nearest-neighbor classifier (Cover & Hart, 1967), logic-based DNF (disjunctive normal form) and CNF (conjunctive normal form) learners (Mooney, 1995) and a decision-list learner <ref> (Rivest, 1987) </ref>. Tests on all methods used identical training and test sets, and ten separate random trials were run in order to measure average performance and allow statistical testing of the significance of any observed differences. <p> Some recent results have indicated that representing concepts in CNF (a conjunction of disjunctions) frequently performs somewhat better (Mooney, 1995). Some concepts are more compactly represented in CNF compared to DNF and vice versa. Therefore, both representations are included. Finally, decision lists <ref> (Rivest, 1987) </ref> are ordered lists of conjunctive rules, where rules are tested in order and the first one that matches an instance is used to classify it.
Reference: <author> Rosenblatt, F. </author> <year> (1962). </year> <title> Principles of Neurodynam-ics. </title> <publisher> Spartan, </publisher> <address> New York. </address>
Reference-contexts: In this paper, we present direct comparisons of a fairly wide range of general learning algorithms on the problem of discriminating six senses of the word "line" from context, using data assembled by Leacock et al. (1993b). We compare a naive Bayesian classifier (Duda & Hart, 1973), a perceptron <ref> (Rosenblatt, 1962) </ref>, a decision-tree learner (Quinlan, 1993), a k nearest-neighbor classifier (Cover & Hart, 1967), logic-based DNF (disjunctive normal form) and CNF (conjunctive normal form) learners (Mooney, 1995) and a decision-list learner (Rivest, 1987). <p> Since the previous results of Leacock et al. (1993b) indicated that neural networks did not benefit from hidden units on the "line" disambiguation data, we employed a simple perceptron <ref> (Rosenblatt, 1962) </ref> as a representative connectionist method. The implementation learns a separate perceptron for recognizing each sense and assigns a test case to the sense indicated by the perceptron whose output most exceeds its threshold. In the current experiments, there was never a problem with convergence during training.
Reference: <author> Rumelhart, D. E., Hinton, G. E., & Williams, J. R. </author> <year> (1986). </year> <title> Learning internal representations by error propagation. </title> <editor> In Rumelhart, D. E., & McClelland, J. L. (Eds.), </editor> <booktitle> Parallel Distributed Processing, </booktitle> <volume> Vol. I, </volume> <pages> pp. 318-362. </pages> <publisher> MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference-contexts: Leacock et al. (1993b), Leacock, Towell, and Voorhees (1993a) and Voorhees, Leacock, and Towell (1995) present results on a Bayesian method (Gale, Church, & Yarowsky, 1992a), a content vector method from information retrieval (Salton, Wong, & Yang, 1975), and a neural network trained using backpropagation <ref> (Rumelhart, Hinton, & Williams, 1986) </ref>. The neural network architecture that performed at least as well as any other contained no hidden units, so was effectively equivalent to a perceptron.
Reference: <author> Salton, G., Wong, A., & Yang, C. S. </author> <year> (1975). </year> <title> A vector space model for automatic indexing. </title> <journal> Communications of the Association for Computing Machinery, </journal> <volume> 18 (11), </volume> <pages> 613-620. </pages>
Reference-contexts: Previous studies have first sampled the data so that all senses were equally represented. Leacock et al. (1993b), Leacock, Towell, and Voorhees (1993a) and Voorhees, Leacock, and Towell (1995) present results on a Bayesian method (Gale, Church, & Yarowsky, 1992a), a content vector method from information retrieval <ref> (Salton, Wong, & Yang, 1975) </ref>, and a neural network trained using backpropagation (Rumelhart, Hinton, & Williams, 1986). The neural network architecture that performed at least as well as any other contained no hidden units, so was effectively equivalent to a perceptron.
Reference: <author> Schaffer, C. </author> <year> (1993). </year> <title> Selecting a classification method by cross-validation. </title> <journal> Machine Learning, </journal> <volume> 13 (1), </volume> <pages> 135-143. </pages>
Reference-contexts: A simple approach is to automate the selection of a method using internal cross-validation <ref> (Schaffer, 1993) </ref>. Another approach is to use meta-learning to learn a set of rules (or other classifier) that predicts when a learning algorithm will perform best on a domain given features describing the problem (Aha, 1992).
Reference: <author> Schaffer, C. </author> <year> (1994). </year> <title> A conservation law for generalization performance. </title> <booktitle> In Proceedings of the Eleventh International Conference on Machine Learning, </booktitle> <pages> pp. </pages> <address> 259-265 San Francisco, CA. </address> <publisher> Morgan Kaufman. </publisher>
Reference-contexts: It can be proven that when averaged over a uniform distribution of all possible classification problems, the generalization performance (predictive accuracy on unseen examples) of any inductive algorithm is zero. This has been called the "Conservation Law for Generalization Performance" <ref> (Schaffer, 1994) </ref> or a "no free lunch" theorem (Wolpert, 1992). However, averaging over a uniform distribution of all possible functions is effectively equivalent to assuming a "random universe" in which the past is not predictive of the future.
Reference: <author> Shavlik, J. W., & Dietterich, T. G. </author> <title> (Eds.). </title> <booktitle> (1990). Readings in Machine Learning. </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo,CA. </address>
Reference: <author> Shavlik, J. W., Mooney, R. J., & Towell, G. G. </author> <year> (1991). </year> <title> Symbolic and neural learning algorithms: An experimental comparison. </title> <journal> Machine Learning, </journal> <volume> 6, </volume> <pages> 111-143. </pages> <note> Reprinted in Readings in Knowledge Acquisition and Learning, </note> <editor> B. G. Buchanan and D. C. Wilkins (eds.), </editor> <publisher> Morgan Kaufman, </publisher> <address> San Mateo, CA, </address> <year> 1993. </year>
Reference-contexts: The logic-based induction methods are slowest, C4.5 and perceptron intermediate, and naive Bayes the fastest. Since it just stores examples, training time for Nearest Neighbor is always zero. In general, connectionist methods are much slower to train than alternative techniques <ref> (Shavlik et al., 1991) </ref>; however, in this case a simple perceptron converges quite rapidly.
Reference: <author> Towell, G. G., Shavlik, J. W., & Noordewier, M. O. </author> <year> (1990). </year> <title> Refinement of approximate domain theories by knowledge-based artificial neural networks. </title> <booktitle> In Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 861-866 Boston, MA. </address>
Reference: <author> Voorhees, E., Leacock, C., & Towell, G. </author> <year> (1995). </year> <title> Learning context to disambiguate word senses. </title> <editor> In Petsche, T., Hanson, S., & Shav-lik, J. (Eds.), </editor> <booktitle> Computational Learning Theory and Natural Learning Systems, </booktitle> <volume> Vol. 3, </volume> <pages> pp. 279-305. </pages> <publisher> MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference: <author> Weiss, S. M., & Kapouleas, I. </author> <year> (1989). </year> <title> An empirical comparison of pattern recognition, neural nets, and machine learning classification methods. </title> <booktitle> In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 781-787 Detroit, MI. </address>
Reference: <editor> Wermter, S., Riloff, E., & Scheler, G. (Eds.). </editor> <year> (1996). </year> <title> Symbolic, Connectionist, and Statistical Approaches to Learning for Natural Language Processing. </title> <publisher> Springer Verlag, Berlin. in press. </publisher>
Reference: <author> Wolpert, D. H. </author> <year> (1992). </year> <title> On the connection between in-sample testing and generalization error. </title> <journal> Complex Systems, </journal> <volume> 6, </volume> <pages> 47-94. </pages>
Reference-contexts: It can be proven that when averaged over a uniform distribution of all possible classification problems, the generalization performance (predictive accuracy on unseen examples) of any inductive algorithm is zero. This has been called the "Conservation Law for Generalization Performance" (Schaffer, 1994) or a "no free lunch" theorem <ref> (Wolpert, 1992) </ref>. However, averaging over a uniform distribution of all possible functions is effectively equivalent to assuming a "random universe" in which the past is not predictive of the future.
Reference: <author> Yarowsky, D. </author> <year> (1994). </year> <title> Decision lists for lexical ambiguity resolution: Application to accent restoration in Spanish and French. </title> <booktitle> In Proceedings of the 32nd Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> pp. </pages> <address> 88-95 Las Cruces, NM. </address>
Reference-contexts: A number of effective concept-learning systems have employed decision lists (Clark & Niblett, 1989; Quinlan, 1993; Mooney & Califf, 1995) and they have already been successfully applied to lexical disambiguation <ref> (Yarowsky, 1994) </ref>. All of the logic-based methods are variations of the Foil algorithm for induction of first-order function-free Horn clauses (Quinlan, 1990), appropriately simplified for the propositional case. They are called PFoil-DNF, PFoil-CNF, and PFoil-DList.
Reference: <author> Zelle, J. M., & Mooney, R. J. </author> <year> (1994). </year> <title> Inducing deterministic Prolog parsers from treebanks: A machine learning approach. </title> <booktitle> In Proceedings of the Twelfth National Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 748-753 Seattle, WA. </address>
Reference-contexts: Unfortunately, there have been very few direct comparisons of alternative methods on identical test data. A somewhat indirect comparison of applying stochastic context-free grammars (Periera & Shabes, 1992), a transformation-based method (Brill, 1993), and inductive logic programming <ref> (Zelle & Mooney, 1994) </ref> to parsing the ATIS (Airline Travel Information Service) corpus from the Penn Treebank (Marcus, Santorini, & Marcinkiewicz, 1993) indicates fairly similar performance for these three very different methods.
References-found: 60

