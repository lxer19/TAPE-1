URL: http://www.ri.cmu.edu/afs/cs.cmu.edu/Web/Groups/VirtualizedR/papers/RepVis/RepVis.ps.gz
Refering-URL: http://www.ri.cmu.edu/afs/cs.cmu.edu/Web/Groups/VirtualizedR/papers.html
Root-URL: 
Date: June 24, 1995.  
Note: Presented at IEEE Workshop on the Representation of Visual Scenes, Boston,  
Abstract: The visual medium evolved from early paintings to the realistic paintings of the classical era to photographs. The medium of moving imagery started with motion pictures. Television and video recording advanced it to show action live or capture and playback later. In all of the above media, the view of the scene is determined at the transcription time, independent of the viewer. We have been developing a new visual medium called vir-tualized reality. It delays the selection of the viewing angle till view time, using techniques from computer vision and computer graphics. The visual event is captured using many cameras that cover the action from all sides. The 3D structure of the event, aligned with the pixels of the image, is computed for a few selected directions using a stereo technique. Triangulation and texture mapping enable the placement of a soft-camera to reconstruct the event from any new viewpoint. With a stereo-viewing system, virtual-ized reality allows a viewer to move freely in the scene, independent of the transcription angles used to record the scene. Virtualized reality has significant advantages over virtual reality. The virtual reality world is typically constructed using simplistic, artificially-created CAD models. Virtualized reality starts with the real world scene and virtualizes it. It is a fully 3D medium as it knows the 3D structure of every point in the image. The applications of virtualized reality are many. Training can become safer and more effective by enabling the trainee to move about freely in a virtualized environment. A whole new entertainment programming can open by allowing the viewer to watch a basketball game while standing on the court or while running with a particular player. In this paper, we describe the hardware and software setup in our studio to make virtualized reality movies. Examples are provided to demonstrate the effectiveness of the system. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. J. Frankel and J. A. Webb. </author> <title> Design, Implementation and Performance of a Multi-Camera Interactive Video Display System. Computer Architectures for Machine Perception. </title> <note> To appear. Como, </note> <institution> Italy, </institution> <year> 1995. </year>
Reference: [2] <author> H. Fuchs, G. Bishop, K. Arthur, L. McMillan, R. Bajcsy, S.W. Lee, H. Farid, and T. Kanade. </author> <title> Virtual Space Teleconferencing using a Sea of Cameras, </title> <booktitle> In Proceedings of the First International Symposium on Medical Robotics and Computer Assisted Surgery, </booktitle> <address> pp.161-167, </address> <year> 1994 </year>
Reference-contexts: Fuchs and Neuman [3] presented a proposal to achieve telepresence for medical applications. Some initial experiments were conducted at CMU using the video-rate stereo machine [7][9], by the team of UNC, UPenn and CMU <ref> [2] </ref>, and at Tsukuba by Ohta and Satoh [10]. Laveau and Faugeras [8] attempt view transfer with uncalibrated cameras using epipolar constraints alone. This paper introduces the concept of virtualized reality.
Reference: [3] <author> H. Fuchs and U. Neuman. </author> <title> A Vision Telepresence for Medical Consultation and other Applications. </title> <booktitle> In Sixth International Symposium of Robotics Research, </booktitle> <pages> pages 555571, </pages> <year> 1993. </year>
Reference-contexts: Kanade [6] proposed the use of multi-camera stereo using supercomputers for creating 3D models to enrich the virtual world. Rioux, Go-din and Blais [16] outlined a procedure to communicate complete 3D information about an object using depth and reflectance. Fuchs and Neuman <ref> [3] </ref> presented a proposal to achieve telepresence for medical applications. Some initial experiments were conducted at CMU using the video-rate stereo machine [7][9], by the team of UNC, UPenn and CMU [2], and at Tsukuba by Ohta and Satoh [10].
Reference: [4] <author> M. Garland and P. Heckbert. </author> <title> Terrain Simplification. </title> <booktitle> In Prep aration. </booktitle>
Reference-contexts: Though this is a large number of triangles, the regularity makes it possible to render them efficiently on graphics workstations. We reduce the number of triangles in our scene definition by adapting an algorithm developed by Garland and Heckbert that simplifies a general dense elevation/depth map into planar patches <ref> [4] </ref>. The algorithm computes a triangulation using the smallest number of vertices given a measure for the maximum deviation from the original depth map. The procedure starts with two triangles defined by the outer four vertices.
Reference: [5] <author> H. Hoppe, T. DeRose, T. Duchamp, M. Halstead, H. Jin, J. McDonald, J. Schweitzer, and W. Stuetzle, </author> <title> Piecewise Smooth Surface Reconstruction, </title> <journal> Computer Graphics SIGGRAPH94, </journal> <pages> 295-302, </pages> <year> 1994. </year>
Reference: [6] <author> T. Kanade. </author> <title> User Viewpoint: Putting the Reality into Virtual Reality. MasPar News, </title> <type> 2(2), </type> <month> Nov. </month> <year> 1991. </year>
Reference-contexts: Stereo or image-matching methods, which are the key components in virtualized reality, are well-studied. Precise reconstruction of the whole scene using a large number of cameras is, however, relatively new. Kanade <ref> [6] </ref> proposed the use of multi-camera stereo using supercomputers for creating 3D models to enrich the virtual world. Rioux, Go-din and Blais [16] outlined a procedure to communicate complete 3D information about an object using depth and reflectance.
Reference: [7] <author> T. Kanade. </author> <title> Very Fast 3-D Sensing Hardware. </title> <booktitle> In Sixth International Symposium of Robotics Research, </booktitle> <pages> pages 185198, </pages> <year> 1993. </year>
Reference: [8] <author> S. Laveau and O. Faugeras. </author> <title> 3-D Scene Representation as a Collection of Images and Fundamental Matrices, </title> <type> INRIA Tech Report 2205, </type> <year> 1994. </year>
Reference-contexts: Fuchs and Neuman [3] presented a proposal to achieve telepresence for medical applications. Some initial experiments were conducted at CMU using the video-rate stereo machine [7][9], by the team of UNC, UPenn and CMU [2], and at Tsukuba by Ohta and Satoh [10]. Laveau and Faugeras <ref> [8] </ref> attempt view transfer with uncalibrated cameras using epipolar constraints alone. This paper introduces the concept of virtualized reality. We present the three stages of creating a virtualized real scene scene transcription, structure extraction and view generation in the next three sections.

References-found: 8

