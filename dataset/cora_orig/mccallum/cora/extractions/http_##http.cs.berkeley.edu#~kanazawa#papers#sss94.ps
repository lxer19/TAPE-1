URL: http://http.cs.berkeley.edu/~kanazawa/papers/sss94.ps
Refering-URL: http://http.cs.berkeley.edu/~kanazawa/papers/sss94.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: fpoole,kanazawag@cs.ubc.ca  
Title: A Decision-Theoretic Abductive Basis for Planning  
Author: David Poole and Keiji Kanazawa 
Address: 2366 Main Mall Vancouver, B.C., Canada V6T 1Z4  
Affiliation: Department of Computer Science University of British Columbia  
Abstract: This paper presents a coherent synthesis of logic and decision theory and shows how it can be used. We allow an axiomatization of the world in definite clauses from a set of assumables. These assumables are partitioned into the set of controllable assumables and uncontrollable assumables. The uncontrollable assumables have probabilities associated with them. The logic allows multiple concurrent actions and lets us predict the effects for both the uncontrolled and controlled cases. We show an example of its use and argue that abduction, particularly probabilistic abduction, lays an important groundwork for decision theoretic and probabilistic planning. The main empirical claim is that uncertainty and choices can be represented as independent exogenous events using logic to give the consequences of the events, resulting in a powerful and yet simple representation.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Krzysztof R. Apt and Martin Bezem. </author> <title> Acyclic programs. New Generation Computing, </title> <address> 9(3-4):335-363, </address> <year> 1991. </year>
Reference-contexts: The probabilities of elements of controllable sets are optional, and if they are present, it means that the agent does not have to control the variable. The probabilities are for the case where the agent does not set the values of the variable. F is an acyclic <ref> [1] </ref> set of definite Horn clauses, such that no member of a random variable is at the head of any clause. Note that when C is empty, then this exactly corresponds to a probabilistic Horn abduction theory. The semantics is defined in terms of possible worlds. <p> The measure of w is the product 2 of the probabilities associated with the elements of the base of w. 1 As F [base (w) is acyclic there is a unique stable model and it can be computed using SLD resolution with negation as failure <ref> [1] </ref>. 2 When R is infinite, we need a more sophisticated measure as in [25]. That will only complicate this paper, however.
Reference: [2] <author> Fahiem Bacchus, Josh Tenenberg, and Jo-hannes A. Koomen. </author> <title> A non-reified temporal logic. </title> <journal> Artificial Intelligence, </journal> <volume> 52(1) </volume> <pages> 87-108, </pages> <year> 1991. </year>
Reference-contexts: In this section we present a temporal representation that can allow for multiple concurrent actions where actions can be seen as controllable propositions. We adopt a nonreified temporal logic <ref> [2] </ref> 3 , with a dis 3 We do not explicitly adopt a 2-sorted logic, as the only crete temporal structure. What is important is the use of propositions parameterized by temporal terms rather than, for example, the discreteness of time.
Reference: [3] <author> Thomas Dean, Leslie Pack Kaelbling, Jak Kir-man, and Ann Nicholson. </author> <title> Planning with deadlines in stochastic domains. </title> <booktitle> In Proceedings of the Eleventh National Conference on Artificial Intel--ligence, </booktitle> <pages> pages 574-579. </pages> <publisher> AAAI, </publisher> <year> 1993. </year>
Reference-contexts: In the real world, typical assumptions of complete knowledge and deterministic change, including deterministic effects of actions, are inappropriate and inadequate. To this end, researchers have proposed a variety of methods for handling uncertainty, such as probability and decision theory, in the decision-making process <ref> [18, 28, 4, 13, 6, 17, 3] </ref>. At the same time, in addressing issues of diagnosis, or explanation in general, researchers also find that uncertainty must be addressed.
Reference: [4] <author> Thomas Dean and Keiji Kanazawa. </author> <title> Persistence and probabilistic projection. </title> <journal> IEEE Transactions on Systems, Man and Cybernetics, </journal> <volume> 19(3) </volume> <pages> 574-585, </pages> <month> May/June </month> <year> 1989. </year>
Reference-contexts: In the real world, typical assumptions of complete knowledge and deterministic change, including deterministic effects of actions, are inappropriate and inadequate. To this end, researchers have proposed a variety of methods for handling uncertainty, such as probability and decision theory, in the decision-making process <ref> [18, 28, 4, 13, 6, 17, 3] </ref>. At the same time, in addressing issues of diagnosis, or explanation in general, researchers also find that uncertainty must be addressed.
Reference: [5] <author> Marc Denecker, Lode Missiaen, and Maurice Bruynooghe. </author> <title> Temporal reasoning with abductive event calculus. </title> <booktitle> In Proceedings of the TenthEuro-pean Conference on Artificial Intelligence, </booktitle> <pages> pages 384-388, </pages> <address> Vienna, Austria, </address> <year> 1992. </year> <pages> ECAI. </pages>
Reference-contexts: This again is easy to add: we add random noise in the definitions of these relations. The optimal plan here will be the optimal purely reactive agent with only these two sensors. 8 Related Work <ref> [7, 5] </ref> provide abductive characterizations of temporal projection and planning in the event calculus [16]. Our work contrasts with that work foremost by our interest in the representation of uncertainty and preference for use as a decision-theoretic abductive basis for planning.
Reference: [6] <author> Mark Drummond and John Bresina. </author> <title> Anytime synthetic projection: Maximizing the probability of goal satisfaction. </title> <booktitle> In Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <pages> pages 138-144, </pages> <address> Boston, Masssachusetts, 1990. </address> <publisher> AAAI. </publisher>
Reference-contexts: In the real world, typical assumptions of complete knowledge and deterministic change, including deterministic effects of actions, are inappropriate and inadequate. To this end, researchers have proposed a variety of methods for handling uncertainty, such as probability and decision theory, in the decision-making process <ref> [18, 28, 4, 13, 6, 17, 3] </ref>. At the same time, in addressing issues of diagnosis, or explanation in general, researchers also find that uncertainty must be addressed.
Reference: [7] <author> Kave Eshghi. </author> <title> Abductive planning with event calculus. </title> <booktitle> In Proceedings of the Fifth International Conference on Logic Programming, </booktitle> <pages> pages 562-, </pages> <year> 1988. </year>
Reference-contexts: (the "facts") and a set of assumables, an explanation of a goal is a subset of the assumables that is consistent with the facts and which together with the facts logically implies the goal. 2.1 Planning as Abduction First, we review ideas behind the use of abduction in planning (e.g., <ref> [7] </ref>). The general idea of planning as abduction is as follows. We assume that we have a logical theory and a set of controllable propositions (i.e., a set of propositions which the agent can set true). <p> This again is easy to add: we add random noise in the definitions of these relations. The optimal plan here will be the optimal purely reactive agent with only these two sensors. 8 Related Work <ref> [7, 5] </ref> provide abductive characterizations of temporal projection and planning in the event calculus [16]. Our work contrasts with that work foremost by our interest in the representation of uncertainty and preference for use as a decision-theoretic abductive basis for planning.
Reference: [8] <author> Richard E. Fikes and Nils J. Nilsson. </author> <title> Strips: A new approach to the application of theorem proving to problem solving. </title> <journal> Artificial Intelligence, </journal> <volume> 2 </volume> <pages> 189-208, </pages> <year> 1971. </year>
Reference-contexts: In our framework, we represent an action and its possible effects in terms of hypotheses about what actually happens. A probability distribution over the hypotheses encodes our uncertainty about the actual effects of an action. Our action ontology is more general than that of STRIPS planners <ref> [8] </ref>. There are no action preconditions per se in the pesky blocks world. Any action may be attempted at any time, but if the necessary conditions for their intended effects do not hold, then the effects may be completely different.
Reference: [9] <author> D. Fudenberg and J. Tirole. </author> <title> Game Theory. </title> <publisher> MIT Press, </publisher> <address> Cambridge Massachusetts, </address> <year> 1992. </year>
Reference-contexts: There is an isomorphism [25] between the propositional version of probabilistic Horn abduction and Bayesian networks [21]. We can represent arbitrary dependence by inventing hypotheses. 2.3 Game/Decision Theory Decision theory and its multi-agent counterpart, game theory <ref> [27, 9] </ref>, are normative theories of reasoning under uncertainty. The framework below should be seen as representation based on the normalized [27] (or strategic [9]) form of a game, with possible world corresponding to a complete play of a game. <p> We can represent arbitrary dependence by inventing hypotheses. 2.3 Game/Decision Theory Decision theory and its multi-agent counterpart, game theory [27, 9], are normative theories of reasoning under uncertainty. The framework below should be seen as representation based on the normalized [27] (or strategic <ref> [9] </ref>) form of a game, with possible world corresponding to a complete play of a game. What we have added here is that a logic program can be used to give the consequences of the play. <p> what is effectively the extensive form of a game, where the output is in terms of if-then-else rules, we will adopt the form of the strategic form, where a plan (strategy) is an adoption of a function from observables (sensor values and/or partial memory of state) to actions (actuator values) <ref> [9] </ref>. It turns out that strategic games are more powerful: the strategic form can easily handle the case where there is not total recall (the agent doesn't necessarily remember everything it has chosen), as is the case for most (real and artificial) agents.
Reference: [10] <author> M. Gelfond and V Lifschitz. </author> <title> The stable model semantics for logic programming. </title> <editor> In R. Kowalski and K. Bowen, editors, </editor> <booktitle> Proceedings of the Fifth Logic Programming Symposium, </booktitle> <pages> pages 1070-1080, </pages> <address> Cambridge, Mass., </address> <year> 1988. </year>
Reference-contexts: Two worlds are the same if they have the same base. Atom a is true in world w if it can be derived (using SLDNF) from F [ base (w), and is false otherwise (in other words w is the stable model <ref> [10] </ref> 1 of F [ base (w); a stable model semantics enables the use of negation as failure in the theory).
Reference: [11] <author> Robert Goldman. </author> <title> A Probabilistic Approach to Language Understanding. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, Brown University, </institution> <year> 1990. </year> <note> Available as Technical Report CS-TR-90-34. </note>
Reference-contexts: In determining the cause of an effect, for instance the disease causing some symptom in medical diagnosis, it is rarely possible to determine with certainty the disease from among a number of possible candidates. Researchers have proposed various methods of abduction with probability to address diagnosis with uncertainty (e.g., <ref> [11] </ref>). Our aim is to develop a coherent framework that incorporates both planning and diagnosis. Our framework for temporal projection is implemented, and has been pretty well tested for the axiomatization of Section 4.
Reference: [12] <author> Peter Haddawy. </author> <title> Representing Plans Under Uncertainty: A Logic of Time, Chance, and Action. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, University of Illinois Urbana-Champaign, </institution> <year> 1991. </year>
Reference-contexts: Our work contrasts with that work foremost by our interest in the representation of uncertainty and preference for use as a decision-theoretic abductive basis for planning. Haddawy <ref> [12] </ref> presents a logic for the representation of actions and utilities that is considerably richer than ours.
Reference: [13] <author> Steven John Hanks. </author> <title> Projecting Plans for Uncertain Worlds. </title> <type> PhD thesis, </type> <institution> Yale University Department of Computer Science, </institution> <month> January </month> <year> 1990. </year>
Reference-contexts: In the real world, typical assumptions of complete knowledge and deterministic change, including deterministic effects of actions, are inappropriate and inadequate. To this end, researchers have proposed a variety of methods for handling uncertainty, such as probability and decision theory, in the decision-making process <ref> [18, 28, 4, 13, 6, 17, 3] </ref>. At the same time, in addressing issues of diagnosis, or explanation in general, researchers also find that uncertainty must be addressed.
Reference: [14] <author> Ron A. Howard and James E. Matheson. </author> <title> Influence diagrams. </title> <editor> In Ron A. Howard and James E. Matheson, editors, </editor> <title> The Principles and Applications of Decision Analysis. Strategic Decisions Group, </title> <address> Menlo Park, CA 94025, </address> <year> 1984. </year>
Reference-contexts: This will be done first in the context of influence diagrams <ref> [14] </ref>, and then we will show how we can go beyond influence diagrams.
Reference: [15] <author> Robert Kowalski. </author> <title> A Logic for Problem Solving. </title> <publisher> North-Holland, </publisher> <address> New York, </address> <year> 1979. </year>
Reference-contexts: Note that the form of the random variables gives us a form of integrity constraints <ref> [15] </ref>. For example, in (1), the success of a puton action prevents the occurrence of dropping or toppling. The possible outcomes cannot all take place at the same time.
Reference: [16] <author> Robert Kowalski and Marek J. Sergot. </author> <title> A logic-based calculus of events. </title> <journal> New Generation Computing, </journal> <volume> 4(1) </volume> <pages> 67-95, </pages> <year> 1986. </year>
Reference-contexts: This again is easy to add: we add random noise in the definitions of these relations. The optimal plan here will be the optimal purely reactive agent with only these two sensors. 8 Related Work [7, 5] provide abductive characterizations of temporal projection and planning in the event calculus <ref> [16] </ref>. Our work contrasts with that work foremost by our interest in the representation of uncertainty and preference for use as a decision-theoretic abductive basis for planning. Haddawy [12] presents a logic for the representation of actions and utilities that is considerably richer than ours.
Reference: [17] <author> Nicholas Kushmerick, Steve Hanks, and Daniel Weld. </author> <title> An algorithm for probabilistic planning. </title> <type> Technical Report 93, </type> <institution> University of Washington Department of Computer Science, </institution> <address> Seattle, Wash-ington, </address> <year> 1993. </year>
Reference-contexts: In the real world, typical assumptions of complete knowledge and deterministic change, including deterministic effects of actions, are inappropriate and inadequate. To this end, researchers have proposed a variety of methods for handling uncertainty, such as probability and decision theory, in the decision-making process <ref> [18, 28, 4, 13, 6, 17, 3] </ref>. At the same time, in addressing issues of diagnosis, or explanation in general, researchers also find that uncertainty must be addressed.
Reference: [18] <author> Curtis P. Langlotz, Lawrence M. Fagan, Sam-son W. Tu, and et al. </author> <title> A therapy planning architecture that combines decision theory and artificial intelligence techniques. </title> <journal> Computers and Biomedical Research, </journal> <year> 1987. </year>
Reference-contexts: In the real world, typical assumptions of complete knowledge and deterministic change, including deterministic effects of actions, are inappropriate and inadequate. To this end, researchers have proposed a variety of methods for handling uncertainty, such as probability and decision theory, in the decision-making process <ref> [18, 28, 4, 13, 6, 17, 3] </ref>. At the same time, in addressing issues of diagnosis, or explanation in general, researchers also find that uncertainty must be addressed.
Reference: [19] <author> Fangzhen Lin and Yoav Shoham. </author> <title> Concurrent actions in the situation calculus. </title> <booktitle> In Proceedings of the Tenth National Conference on Artificial Intelligence, </booktitle> <pages> pages 590-595, </pages> <address> San Jose, California, 1992. </address> <publisher> AAAI. </publisher>
Reference-contexts: In a similar fashion, we can also find out the utility of a given plan. 5 Concurrent Actions and Exogenous Events In our framework, we can represent concurrent actions and exogenous events in a straightforward fashion (cf. <ref> [19, 20, 22, 26] </ref>). In fact, one way to look at the effect axioms in the previous section is that an effect results from the execution of concurrent actions by an agent (through the controllables) and by nature (through the random variables).
Reference: [20] <author> Leora Morgenstern and Lynn Andrea Stein. </author> <title> Why things go wrong: A formal theory of causal reasoning. </title> <booktitle> In Proceedings of the Seventh National Conference on Artificial Intelligence, </booktitle> <pages> pages 518-523, </pages> <address> Minneapolis, Minnesota, 1988. </address> <publisher> AAAI. </publisher>
Reference-contexts: In a similar fashion, we can also find out the utility of a given plan. 5 Concurrent Actions and Exogenous Events In our framework, we can represent concurrent actions and exogenous events in a straightforward fashion (cf. <ref> [19, 20, 22, 26] </ref>). In fact, one way to look at the effect axioms in the previous section is that an effect results from the execution of concurrent actions by an agent (through the controllables) and by nature (through the random variables).
Reference: [21] <author> Judea Pearl. </author> <title> Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. </title> <publisher> Mor-gan Kaufmann, </publisher> <address> Los Altos, </address> <year> 1988. </year>
Reference-contexts: The logic is definite Horn clauses with no assumables at the heads of clauses (this means that the logic cannot impose any dependencies on the assumables). There is an isomorphism [25] between the propositional version of probabilistic Horn abduction and Bayesian networks <ref> [21] </ref>. We can represent arbitrary dependence by inventing hypotheses. 2.3 Game/Decision Theory Decision theory and its multi-agent counterpart, game theory [27, 9], are normative theories of reasoning under uncertainty.
Reference: [22] <author> Edwin P. D. Pednault. </author> <title> Formulating multiagent, dynamic-world problems in the classical planning framework. </title> <editor> In Michael P. Georgeff and Amy P. Lansky, editors, </editor> <booktitle> Reasoning about Actions and Plans: proceedings of the 1986 Workshop, </booktitle> <pages> pages 47-82. </pages> <publisher> Morgan Kaufmann, </publisher> <address> Timberline, Oregon, </address> <year> 1987. </year>
Reference-contexts: In a similar fashion, we can also find out the utility of a given plan. 5 Concurrent Actions and Exogenous Events In our framework, we can represent concurrent actions and exogenous events in a straightforward fashion (cf. <ref> [19, 20, 22, 26] </ref>). In fact, one way to look at the effect axioms in the previous section is that an effect results from the execution of concurrent actions by an agent (through the controllables) and by nature (through the random variables).
Reference: [23] <author> David Poole. </author> <title> The independent assumption framework: A game-theory logic and its application to the design of rational agents. </title> <publisher> Forthcoming. </publisher>
Reference-contexts: Below we have only given the one player with nature version of the strategic form, but it can be extended in a reasonably straight forward way to to the multi-agent game theory case. See <ref> [23] </ref> for details. 3 Decision Theoretic Abductive Planning The framework we are proposing [23] is one where there are three sets of formulae, namely a set of controllable propositions which the agent can set, a set of uncontrollable propositions with probabilities over them, and a set of facts (definite Horn clauses) <p> Below we have only given the one player with nature version of the strategic form, but it can be extended in a reasonably straight forward way to to the multi-agent game theory case. See <ref> [23] </ref> for details. 3 Decision Theoretic Abductive Planning The framework we are proposing [23] is one where there are three sets of formulae, namely a set of controllable propositions which the agent can set, a set of uncontrollable propositions with probabilities over them, and a set of facts (definite Horn clauses) which tell us the consequences of these propositions. <p> is also very important when we want to have conditional plans that are adopted by agents without knowing what other agents are doing (here we can see nature as adopting a conditional plan to make the block succeed if it is being put on something | see Section 6 and <ref> [23] </ref>). While this is true in the semantics, the abductive view lets us consistently ignore whether puton success (a; 1) is true unless we actually attempt to put a on some block. Thus when reasoning we do not have to consider these incompatible alternatives. <p> We represent these conditions through 4 As we are using negation as failure we can axiomatize clear as clear (X; S) ~ on (Z; X; S) ^ X 6= table: clear (table; S) true: where `~' means negation as failure <ref> [23] </ref>. the proposition puton preconds (X; Z; S) that is true whenever the necessary (but not sufficient) conditions for a successful puton (X; Z; S) hold true.
Reference: [24] <author> David Poole. </author> <title> A methodology for using a default and abductive reasoning system. </title> <journal> International Journal of Intelligent Systems, </journal> <volume> 5(5) </volume> <pages> 521-548, </pages> <month> De-cember </month> <year> 1990. </year>
Reference-contexts: There may be a cost or utility associated with a plan reflecting how good it is, but that under this approach all plans are guaranteed to achieve the goal (the goal logically follows from the achievable propositions being true). 2.2 Recognition as Abduction A more traditional view of abduction <ref> [24] </ref> is where the assumables are assumptions about what may be true, and the goal is an observation. If the facts are causal rules, then an explanation is a logical theory about what could have caused the observation. <p> This corresponds to abducing to the causes: the set of minimal explanations of the observation is a succinct description of the set of possible worlds consistent with the observation (the consistent possible worlds are exactly those that extend the minimal explanations of the goal) <ref> [24] </ref>. Finally, we must be careful to note that adopting an abductive framework for planning is principally a representational commitment. It does not in itself solve many of the classical planning issues such as search.
Reference: [25] <author> David Poole. </author> <title> Probabilistic Horn abduction and Bayesian networks. </title> <journal> Artificial Intelligence, </journal> <volume> 64(1) </volume> <pages> 81-129, </pages> <year> 1993. </year>
Reference-contexts: If the facts are causal rules, then an explanation is a logical theory about what could have caused the observation. One interesting instance of this is probabilistic Horn abduction <ref> [25] </ref>, where there are probabilities over the assumables. Assumables are grouped into disjoint sets corresponding to random variables. <p> The logic is definite Horn clauses with no assumables at the heads of clauses (this means that the logic cannot impose any dependencies on the assumables). There is an isomorphism <ref> [25] </ref> between the propositional version of probabilistic Horn abduction and Bayesian networks [21]. We can represent arbitrary dependence by inventing hypotheses. 2.3 Game/Decision Theory Decision theory and its multi-agent counterpart, game theory [27, 9], are normative theories of reasoning under uncertainty. <p> the probabilities associated with the elements of the base of w. 1 As F [base (w) is acyclic there is a unique stable model and it can be computed using SLD resolution with negation as failure [1]. 2 When R is infinite, we need a more sophisticated measure as in <ref> [25] </ref>. That will only complicate this paper, however. <p> The probability of an explanation can be obtained by multiplying the probabilities of the elements of the explanation. The rules in our example below are designed so that the rules are disjoint so that the probabilities of the explanations can be added. See <ref> [25] </ref> for details. We assume that some of the propositions that are concluded by R are of the form utility (U ) meaning that U is a number representing the utility. <p> Our current implementation is a modified version of the probabilistic Horn abduction interpreter <ref> [25] </ref> with the addition of controllable actions and negation as failure. This interpreter uses logic programming technology to build up proofs of states of the world on the basis of assumptions. Given our theory, we can, for example, find out the likelihood of success of doing puton (b; a; 0). <p> We here show how to represent influence diagrams; we extend the representation of Bayesian networks in probabilistic Horn abduction <ref> [25] </ref> to show to represent decision nodes. Value nodes are just represented as definite Horn clauses that imply a particular utility.
Reference: [26] <author> Murray Shanahan. </author> <title> Prediction is deduction but explanation is abduction. </title> <booktitle> In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 1140-1145, </pages> <address> Detroit, Michigan, </address> <year> 1989. </year> <pages> IJCAI. </pages>
Reference-contexts: In a similar fashion, we can also find out the utility of a given plan. 5 Concurrent Actions and Exogenous Events In our framework, we can represent concurrent actions and exogenous events in a straightforward fashion (cf. <ref> [19, 20, 22, 26] </ref>). In fact, one way to look at the effect axioms in the previous section is that an effect results from the execution of concurrent actions by an agent (through the controllables) and by nature (through the random variables).
Reference: [27] <author> J. Von Neumann and O. Morgenstern. </author> <title> Theory of Games and Economic Bahavior. </title> <publisher> Princeton University Press, </publisher> <address> Princeton, third edition, </address> <year> 1953. </year>
Reference-contexts: There is an isomorphism [25] between the propositional version of probabilistic Horn abduction and Bayesian networks [21]. We can represent arbitrary dependence by inventing hypotheses. 2.3 Game/Decision Theory Decision theory and its multi-agent counterpart, game theory <ref> [27, 9] </ref>, are normative theories of reasoning under uncertainty. The framework below should be seen as representation based on the normalized [27] (or strategic [9]) form of a game, with possible world corresponding to a complete play of a game. <p> We can represent arbitrary dependence by inventing hypotheses. 2.3 Game/Decision Theory Decision theory and its multi-agent counterpart, game theory [27, 9], are normative theories of reasoning under uncertainty. The framework below should be seen as representation based on the normalized <ref> [27] </ref> (or strategic [9]) form of a game, with possible world corresponding to a complete play of a game. What we have added here is that a logic program can be used to give the consequences of the play.
Reference: [28] <author> Michael P. Wellman. </author> <title> Formulation of Tradeoffs in Planning Under Uncertainty. </title> <publisher> Pitman, </publisher> <address> London, </address> <year> 1990. </year>
Reference-contexts: In the real world, typical assumptions of complete knowledge and deterministic change, including deterministic effects of actions, are inappropriate and inadequate. To this end, researchers have proposed a variety of methods for handling uncertainty, such as probability and decision theory, in the decision-making process <ref> [18, 28, 4, 13, 6, 17, 3] </ref>. At the same time, in addressing issues of diagnosis, or explanation in general, researchers also find that uncertainty must be addressed.
References-found: 28

