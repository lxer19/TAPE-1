URL: ftp://www.cs.rutgers.edu/pub/technical-reports/lcsr-tr-256.ps.Z
Refering-URL: http://www.cs.rutgers.edu/pub/technical-reports/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: TWO APPROACHES TO THE HIERARCHICAL SOLUTION OF CONSTRAINT SATISFACTION PROBLEMS  Written under the direction of  
Author: BY SUNIL KUMAR MOHAN Prof. Thomas Ellman 
Degree: A dissertation submitted to the Graduate School|New Brunswick  in partial fulfillment of the requirements for the degree of Doctor of Philosophy  and approved by  
Date: January, 1996  
Note: Graduate Program in Computer Science  
Address: New Jersey  Brunswick, New Jersey  
Affiliation: Rutgers, The State University of  New  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Jerome Bracken and Garth P. McCormick. </author> <title> Selected Applications of Nonlinear Programming. </title> <publisher> John Wiley and Sons, </publisher> <year> 1968. </year>
Reference-contexts: The design goal is to minimize the total weight of the three panels for a specified weight handling capacity. The problem modeled here is an adaptation from a description published in <ref> [1] </ref>. The original continuous non-linear optimization problem is posed here as a discrete constraint satisfaction problem (e.g. for a situation where manufacturing can only produce a discrete set of measurements), with the objective function translated into a constraint restricting the weight of the bulkhead to be below a specified value.
Reference: [2] <author> Wesley Braudaway. </author> <title> Automated synthesis of constrained generators. In Automating Software Design. </title> <publisher> AAAI Press, </publisher> <year> 1991. </year>
Reference-contexts: There has been other work on automated programming in the field of CSPs, e.g. <ref> [2] </ref> describing techniques for problem reformulation, [69] describing a solution-repair approach, and [42] describing the automated formulation of search heuristics. 196 7.4 Future Directions This thesis opens up several interesting areas for further research.
Reference: [3] <author> C. A. Brown and P. W. </author> <title> Purdom Junior. How to search efficiently. </title> <booktitle> In Proceedings of the 7th International Joint Conference on AI, </booktitle> <pages> pages 588-594, </pages> <year> 1981. </year>
Reference: [4] <author> Maurice Bruynooghe. </author> <title> Solving combinatorial search problems by intelligent backtracking. </title> <journal> Information Processing Letters, </journal> <volume> 12(1), </volume> <month> February </month> <year> 1981. </year>
Reference: [5] <author> Yves Caseau. </author> <title> Abstract interpretation of constraints over an order-sorted domain. </title> <booktitle> In Proceedings of the ILPS, </booktitle> <address> San Diego, </address> <year> 1991. </year>
Reference: [6] <author> Yves Caseau and Jean-Francois Puget. </author> <title> Constraints on order-sorted domains. </title> <booktitle> In Proceedings of the European Conference on AI, </booktitle> <year> 1994. </year>
Reference: [7] <author> Peter Cheeseman, Bob Kanefsky, and William M. Taylor. </author> <title> Where the really hard problems are. </title> <booktitle> In Proceedings of the International Joint Conference on AI, </booktitle> <pages> pages 331-337, </pages> <address> Sydney, Australia, </address> <year> 1991. </year>
Reference: [8] <author> Rina Dechter. </author> <title> Enhancement schemes for constraint processing: Backjumping, learning, and cutset decomposition. </title> <journal> Artificial Intelligence, </journal> <volume> 41 </volume> <pages> 273-312, </pages> <year> 1990. </year>
Reference: [9] <author> Rina Dechter and Judea Pearl. </author> <title> The cycle-cutset method for improving search performance in ai applications. </title> <booktitle> In Proceedings of the Third IEEE conference on AI applications, </booktitle> <pages> pages 224-230, </pages> <address> Orlando, </address> <year> 1987. </year>
Reference: [10] <author> Rina Dechter and Judea Pearl. </author> <title> Network-based heuristics for constraint-satisfaction problems. </title> <journal> Artificial Intelligence, </journal> <volume> 34 </volume> <pages> 1-38, </pages> <year> 1988. </year>
Reference-contexts: There are two such criteria important to this thesis: 1. Constraint Arity. Problems where each constraint restricts only up to two variables are called Binary CSPs. Several problem solution techniques and heuristics take advantage of this property (e.g. <ref> [18, 10, 47] </ref>). The problem solution methods proposed in this thesis are more general and so we shall consider problems not 3 restricted on the arity of their constraints. These problems are popularly referred to as `n-ary CSPs'. 2. Number of Solutions. <p> Correspondingly, the problem of constraint satisfaction is also referred to as the Consistent Labeling Problem ([30, 56]). Several types of Constraint Satisfaction Problems can be identified. The most commonly studied class is that of finding one solution to the CSP ([49, 18] and a summary in <ref> [10] </ref>). We will also be devoting considerable attention in this thesis to the problem of finding all solutions ([31]). Nadel ([56]) also identifies the problems of counting the number of solutions, and of determining solvability. <p> A complete search tree lists all the possible bindings. Clever search algorithms try to reduce the number of nodes actually explored by avoiding as early as possible paths that do not lead to a solution. Different techniques are used to detect dead-end branches, e.g. <ref> [31, 62, 10] </ref>. 2.2.3 The cost of search Both space (memory) and time requirements of a search algorithm are useful measures of its efficiency. The memory used by most popular search algorithms is bound by a polynomial function on the number of variables and sizes of their domains [31]. <p> Freuder generalizes the notion of consistency to k-ary consistency, in which consistency is performed on sets of k variables. Arc-consistency is then a 2-ary consistency. Dechter and Pearl further develop this into directional consistency <ref> [10] </ref>. Freuder ([18]) demonstrates that a tree-shaped constraint graph, after performing 40 arc-consistency, does not require any backtracks to find the first solution. <p> This is usually more efficient for finding all solutions, because after arc consistency filters the variables' domains, their cross-product might still contain values that 188 violate conjunctions of constraints. Where arc consistency is particularly suitable for problems requiring one solution <ref> [18, 19, 10] </ref> IS-decomposition might be viewed as an efficient adaptation of arc consistency for problems requiring all solutions. 7.3.4 Trees of variable clusters In [18] Freuder showed that after performing arc consistency, finding the first solution for a problem with a tree-shaped constraint network does not require any backtracking. <p> If the constraint is global, this approach completely fails to produce useful decompositions. Tree clustering also fails to produce any decompositions for constraint networks that are complete graphs. The Adaptive Consistency algorithm described in <ref> [10] </ref> is shown to induce the same clusters produced by the triangulation scheme of [11]. Both algorithms take an `m-ordering' of variables as argument.
Reference: [11] <author> Rina Dechter and Judea Pearl. </author> <title> Tree clustering for constraint networks. </title> <journal> Artificial Intelligence, </journal> <volume> 35, </volume> <year> 1989. </year>
Reference-contexts: binary CSPs can be applied to 39 X 1 X 2 w @ @ @ @ (a) T 13 T 14 w w X 1 X 3 X 4 X 4 @ @ X 4 Constraint Graph. higher arity CSPs by transforming the CSP into an equivalent dual constraint graph <ref> [11] </ref>). In the dual graph, each constraint is represented by a node (called a c-variable), and there is a simple arc between nodes that share variables in their argument sets. The dual graph for example 1 is shown in figure 2.6-b. <p> For non-binary CSPs, the primal constraint graph is used for this step. Consistency techniques performed on the clustered graph, by treating each cluster as a single variable, will render the network backtrack-free. Two examples of such clustering techniques are described in <ref> [11] </ref> and [28]. For these techniques to work, there should be at least one variable cluster that completely subsumes the largest arity constraint in the problem. <p> They therefore need to be variable-independent of each other. This is why the decomposition is called an Independent Set decomposition, borrowing the graph-theoretic notion of an independent set of vertices. In the dual graph representation of a CSP (chapter 2, and <ref> [11] </ref>), constraints are represented by vertices, and extracting an independent set of constraints corresponds directly to selecting an independent set of these vertices. 3.4.2 Selecting a suitable independent constraint set We noted above that the more constraints that can be extracted, the greater the potential for improving search performance by the <p> This has led to decomposition techniques that divide a CSP into subproblems (variable clusters) connected by a tree-shaped residual subproblem <ref> [11, 28] </ref>. The decomposition is solved by first solving the subproblems, saving their solutions, and then performing directional arc-consistency on the tree-shaped residual, treating each cluster-subproblem as a single variable. The first solution for the problem can now be found without any further backtracking. <p> If the constraint is global, this approach completely fails to produce useful decompositions. Tree clustering also fails to produce any decompositions for constraint networks that are complete graphs. The Adaptive Consistency algorithm described in [10] is shown to induce the same clusters produced by the triangulation scheme of <ref> [11] </ref>. Both algorithms take an `m-ordering' of variables as argument. Given the same variable ordering, Adaptive Consistency coordinates the solution of the subproblems produced by Tree Clustering by enforcing local consistency between them while it is being executed.
Reference: [12] <author> M. Dincbas, H. Simonis, and P. van Hentenryck. </author> <title> Solving the car sequencing problem in clp. </title> <booktitle> In Proceedings of the ECAI, </booktitle> <pages> pages 290-295, </pages> <year> 1988. </year>
Reference-contexts: A solution requires the assignment of a value to each variable, selected from the corresponding domain, such that the set of constraints is satisfied. Constraint satisfaction problems have found application in design (e.g. [52, 39]), planning and scheduling (e.g. <ref> [12, 36] </ref>). Job-shop scheduling, graph coloring and satisfiability ([24]) are some examples of CSP applications that have also been of considerable theoretical interest through the years. In job-shop scheduling, for example, the variables are operation start times, and the constraints represent restrictions on resource capacities and operation precedences.
Reference: [13] <author> Charles M. Eastman. </author> <title> Automated space planning. </title> <journal> Artificial Intelligence, </journal> <volume> 4 </volume> <pages> 41-64, </pages> <year> 1973. </year>
Reference-contexts: The problem selected here is a simple version which nonetheless is non-trivial, and serves to demonstrate the power of the decomposition techniques proposed in this thesis. Similar problems have been studied for example in <ref> [13, 17, 16] </ref>. This floorplanning problem is an expansion of the problem described in the first chapter. There is a rectangular house of specified length and width, which must be filled with four rooms, each of a specified minimum area.
Reference: [14] <author> Thomas Ellman. </author> <title> Abstraction via approximate symmetry. </title> <booktitle> In Proceedings of the International Joint Conference on AI, </booktitle> <pages> pages 916-921, </pages> <year> 1993. </year> <month> 220 </month>
Reference-contexts: The general idea of applying abstraction levels or spaces to constraint satisfaction problems described here, and previously developed in [45, 48, 46, 68], has been generalized by Ellman and described in <ref> [14, 15] </ref>. In Ellman's terms, the procedure HiT 144 constructs a hierarchical CSP by defining a "necessary approximate symmetry" on the original problem's search space. <p> Two of the hierarchical solution strategies described here, HSS-2 and HSS-4, are also new. Ellman describes a more general formulation of the use of abstraction levels in solving constraint satisfaction problems in <ref> [14, 15] </ref>. In Ellman's terms, the procedure HiT constructs a hierarchical CSP by defining a "necessary approximate symmetry" on the original problem's search space.
Reference: [15] <author> Thomas Ellman. </author> <title> Synthesis of abstraction hierarchies for constraint satisfaction by clustering approximately equivalent objects. </title> <booktitle> In Proceedings of the International Machine Learning Workshop, </booktitle> <year> 1993. </year>
Reference-contexts: The general idea of applying abstraction levels or spaces to constraint satisfaction problems described here, and previously developed in [45, 48, 46, 68], has been generalized by Ellman and described in <ref> [14, 15] </ref>. In Ellman's terms, the procedure HiT 144 constructs a hierarchical CSP by defining a "necessary approximate symmetry" on the original problem's search space. <p> Two of the hierarchical solution strategies described here, HSS-2 and HSS-4, are also new. Ellman describes a more general formulation of the use of abstraction levels in solving constraint satisfaction problems in <ref> [14, 15] </ref>. In Ellman's terms, the procedure HiT constructs a hierarchical CSP by defining a "necessary approximate symmetry" on the original problem's search space.
Reference: [16] <author> U. Flemming, C. A. Baykan, R. F. Coyne, and M. S. Fox. </author> <title> Hierarchical generate-and-test vs constraint-directed search. </title> <editor> In J. S. Gero, editor, </editor> <booktitle> AI in Design, </booktitle> <pages> pages 817-838. </pages> <publisher> Kluwer Academic Publishers, </publisher> <year> 1992. </year>
Reference-contexts: The problem selected here is a simple version which nonetheless is non-trivial, and serves to demonstrate the power of the decomposition techniques proposed in this thesis. Similar problems have been studied for example in <ref> [13, 17, 16] </ref>. This floorplanning problem is an expansion of the problem described in the first chapter. There is a rectangular house of specified length and width, which must be filled with four rooms, each of a specified minimum area.
Reference: [17] <author> Ulrich Flemming, Robert F. Coyne, Timothy Glavin, Hung Hsi, and Michael D. Rychener. </author> <title> A generative expert system for the design of building layouts (final report). </title> <type> Technical Report EDRC 48-15-89, </type> <institution> Engineering Design Research Centre, </institution> <address> CMU, Pittsburgh, PA, </address> <year> 1989. </year>
Reference-contexts: The problem selected here is a simple version which nonetheless is non-trivial, and serves to demonstrate the power of the decomposition techniques proposed in this thesis. Similar problems have been studied for example in <ref> [13, 17, 16] </ref>. This floorplanning problem is an expansion of the problem described in the first chapter. There is a rectangular house of specified length and width, which must be filled with four rooms, each of a specified minimum area.
Reference: [18] <author> Eugene C. Freuder. </author> <title> A sufficient condition for backtrack-free search. </title> <journal> JACM, </journal> <volume> 29(1) </volume> <pages> 24-32, </pages> <year> 1982. </year>
Reference-contexts: There are two such criteria important to this thesis: 1. Constraint Arity. Problems where each constraint restricts only up to two variables are called Binary CSPs. Several problem solution techniques and heuristics take advantage of this property (e.g. <ref> [18, 10, 47] </ref>). The problem solution methods proposed in this thesis are more general and so we shall consider problems not 3 restricted on the arity of their constraints. These problems are popularly referred to as `n-ary CSPs'. 2. Number of Solutions. <p> This is usually more efficient for finding all solutions, because after arc consistency filters the variables' domains, their cross-product might still contain values that 188 violate conjunctions of constraints. Where arc consistency is particularly suitable for problems requiring one solution <ref> [18, 19, 10] </ref> IS-decomposition might be viewed as an efficient adaptation of arc consistency for problems requiring all solutions. 7.3.4 Trees of variable clusters In [18] Freuder showed that after performing arc consistency, finding the first solution for a problem with a tree-shaped constraint network does not require any backtracking. <p> Where arc consistency is particularly suitable for problems requiring one solution [18, 19, 10] IS-decomposition might be viewed as an efficient adaptation of arc consistency for problems requiring all solutions. 7.3.4 Trees of variable clusters In <ref> [18] </ref> Freuder showed that after performing arc consistency, finding the first solution for a problem with a tree-shaped constraint network does not require any backtracking. This has led to decomposition techniques that divide a CSP into subproblems (variable clusters) connected by a tree-shaped residual subproblem [11, 28].
Reference: [19] <author> Eugene C. Freuder. </author> <title> A sufficient condition for backtrack-bounded search. </title> <journal> JACM, </journal> <volume> 34(4) </volume> <pages> 755-761, </pages> <year> 1985. </year>
Reference-contexts: This is usually more efficient for finding all solutions, because after arc consistency filters the variables' domains, their cross-product might still contain values that 188 violate conjunctions of constraints. Where arc consistency is particularly suitable for problems requiring one solution <ref> [18, 19, 10] </ref> IS-decomposition might be viewed as an efficient adaptation of arc consistency for problems requiring all solutions. 7.3.4 Trees of variable clusters In [18] Freuder showed that after performing arc consistency, finding the first solution for a problem with a tree-shaped constraint network does not require any backtracking.
Reference: [20] <author> Eugene C. Freuder. </author> <title> Partial constraint satisfaction. </title> <booktitle> In Proceedings of the 11th International Joint Conference on AI, </booktitle> <pages> pages 278-283, </pages> <year> 1989. </year>
Reference: [21] <author> Eugene C. Freuder and Paul D. Hubbe. </author> <title> Using inferred disjunctive constraints to decompose constraint satisfaction problems. </title> <booktitle> In Proceedings of the 13th International Joint Conference on AI, </booktitle> <pages> pages 254-260, </pages> <address> Chambery, France, </address> <year> 1993. </year>
Reference: [22] <author> Eugene C. Freuder and Michael J. Quinn. </author> <title> Taking advantage of stable sets of variables in constraint satisfaction problems. </title> <booktitle> In Proceedings of the International Joint Conference on AI, </booktitle> <year> 1985. </year>
Reference: [23] <author> Eugene C. Freuder and Richard J. Wallace. </author> <title> Partial constraint satisfaction. </title> <journal> Artificial Intelligence (special volume: Constraint-Based Reasoning), </journal> <volume> 58(1-3):21-70, </volume> <year> 1992. </year>
Reference: [24] <author> Michael R. Garey and David S. Johnson. </author> <title> Computers and Intractability: A Guide to the Theory of NP-Completeness. </title> <editor> W. H. </editor> <publisher> Freeman and Company, </publisher> <year> 1979. </year>
Reference: [25] <author> J. Gaschnig. </author> <title> A general backtracking algorithm that eliminates most redundant tests. </title> <booktitle> In Proceedings of the International Joint Conference on AI, </booktitle> <publisher> MIT, </publisher> <address> Cam-bridge, MA, </address> <month> August </month> <year> 1977. </year>
Reference: [26] <author> Matthew L. Ginsberg. </author> <title> Dynamic backtracking. </title> <journal> Journal of AI Research, </journal> <volume> 1 </volume> <pages> 25-46, </pages> <year> 1993. </year>
Reference-contexts: We will only look at some of the main points in Dynamic Backtracking here, and for a detailed description defer to <ref> [26] </ref>. Dynamic Backtracking contains two key ideas. Whenever a constraint fails, or a variable runs out of new values to generate, a culprit is chosen as the backtracking target. When control jumps back to the culprit variable, the values bound to other variables are not retracted. <p> This was suggested by Freuder 1 as an efficient scheme for storing constraints available to the problem as a list of satisfying tuples. This could reduce or even eliminate the cost of testing such constraints. * Improving the explanation mechanism of Dynamic Backtracking. As described in <ref> [26] </ref>, Dynamic Backtracking only keeps track of "no-goods" | value combinations that violate some constraint. This allows the algorithms to avoid generating and testing these value combinations again.
Reference: [27] <author> Solomon W. Golumb and Leonard D. Baumert. </author> <title> Backtrack programming. </title> <journal> JACM, </journal> <volume> 12(4) </volume> <pages> 516-524, </pages> <year> 1965. </year>
Reference-contexts: the constraints T ij represent the following relations: T 13 = T 14 = T 24 = T 35 = T 45 = fa; b; cg fi fa; b; cg 2.2 Backtrack Search 2.2.1 The Backtrack algorithm The most well known algorithm for solving a Constraint Satisfaction Problem is Backtrack <ref> [27, 55] </ref>. Given an ordering of variables and constraints for a problem, at each step it either picks a new value binding for the current variable, or evaluates the current constraint on the already bound (or instantiated) variables.
Reference: [28] <author> Marc Gyssens, Peter G. Jeavons, and David A. Cohen. </author> <title> Decomposing constraint satisfaction problems using database techniques. </title> <journal> Artificial Intelligence, </journal> ?, <year> 1994. </year>
Reference-contexts: For non-binary CSPs, the primal constraint graph is used for this step. Consistency techniques performed on the clustered graph, by treating each cluster as a single variable, will render the network backtrack-free. Two examples of such clustering techniques are described in [11] and <ref> [28] </ref>. For these techniques to work, there should be at least one variable cluster that completely subsumes the largest arity constraint in the problem. <p> This has led to decomposition techniques that divide a CSP into subproblems (variable clusters) connected by a tree-shaped residual subproblem <ref> [11, 28] </ref>. The decomposition is solved by first solving the subproblems, saving their solutions, and then performing directional arc-consistency on the tree-shaped residual, treating each cluster-subproblem as a single variable. The first solution for the problem can now be found without any further backtracking.
Reference: [29] <author> P. V. Hall. </author> <title> Optimization of a single relational expression in a relational data base system. </title> <journal> IBM Journal of Research and Development, </journal> <volume> (20) 3, </volume> <year> 1976. </year> <month> 221 </month>
Reference-contexts: Such constraints can be reformulated by substituting in appropriate abstract variables, thus changing the scope of the constraint, and also avoiding recomputation of that subexpression. Taking advantage of common subexpressions is a well known technique for optimizing relational database queries. It has been applied within a single query (e.g. <ref> [29] </ref>) and across groups of multiple queries (e.g. [34, 61]). The motivation there is to reduce 193 repeated access to data stored on slow media.
Reference: [30] <author> R. M. Haralick, L.S. Davis, A. Rosenfeld, and D. L. Milgram. </author> <title> Reduction operations for constraint satisfaction. </title> <journal> Information Science, </journal> <volume> 14 </volume> <pages> 199-219, </pages> <year> 1978. </year>
Reference: [31] <author> R. M. Haralick and G. L. Elliott. </author> <title> Increasing tree search efficiency for constraint satisfaction problems. </title> <journal> Artificial Intelligence, </journal> <volume> 14 </volume> <pages> 263-313, </pages> <year> 1980. </year>
Reference-contexts: Changing line (5) to EXIT will transform it to stop after finding the first solution. Backtrack is the most common and simplest algorithm for solving CSPs. It requires the least amount of memory, compared to the usually faster algorithms Backmark and Forward-Check <ref> [31] </ref>. Furthermore, it does not require the domains of its variables to be explicitly listed. <p> A complete search tree lists all the possible bindings. Clever search algorithms try to reduce the number of nodes actually explored by avoiding as early as possible paths that do not lead to a solution. Different techniques are used to detect dead-end branches, e.g. <ref> [31, 62, 10] </ref>. 2.2.3 The cost of search Both space (memory) and time requirements of a search algorithm are useful measures of its efficiency. The memory used by most popular search algorithms is bound by a polynomial function on the number of variables and sizes of their domains [31]. <p> The memory used by most popular search algorithms is bound by a polynomial function on the number of variables and sizes of their domains <ref> [31] </ref>. Since Constraint Satisfaction Problems are NP-hard, time is usually the more important cost parameter. When evaluating and comparing different algorithms, the time cost is usually estimated by counting the number of events in a search algorithm. <p> A form of look-ahead search called Forward-Check, described below, avoids this kind of inefficiency. The Forward-Check algorithm shown in figure 2.4 is adapted from <ref> [31] </ref>. The basic principle of Forward-Check is best described by focusing on the ordering of variables 31 in a control sequence. At each variable in the sequence, a set of future variables is defined, whose values are restricted in conjunction with the current variable through one or more constraints. <p> At the cost of this additional memory requirement, the look-ahead action of Forward-Check often yields a significant speed improvement over Backtrack and most other algorithms (e.g. <ref> [31] </ref>). However sometimes the memory requirement can be too high, and Backtrack the only feasible algorithm. For this reason, and the simplicity of the algorithm, Backtrack is still widely used, with a lot of techniques devised to improve its performance. <p> The Backtrack algorithm was included in the experiments because it is the simplest and most well known search algorithm, and also has the lowest memory requirement. Forward-Check was selected because it is the fastest known algorithm in widespread use (e.g. <ref> [31] </ref>). Three additional search algorithms | Dynamic Forward-Check using the "fail-first" heuristic ([31]), Backmarking (ibid.) and Backjumping ([8]) | were also considered, but 94 eliminated by early experiments for not performing as well as simple Forward-Check. <p> Finally, early experiments verified the conclusion in <ref> [31] </ref> that Backmarking generally did not perform as well as Forward-Check. 4.2.4 Control Sequences The simple control sequence used for basic search was generated using a combination of the following heuristics: * Minimize the total depth and bandwidth of constraints in the sequence ([47, 71]). * Order adjacent constraints on increasing
Reference: [32] <author> Paul D. Hubbe. </author> <title> Cross product representation of the constraint satisfaction problem search space. </title> <type> Technical Report 92-17, </type> <institution> Dept of Computer Science, University of New Hampshire, </institution> <month> September </month> <year> 1992. </year> <type> Master's Thesis. </type>
Reference-contexts: The cross-product representation (CPR) and its use in modified versions of the Backtrack (BT-CPR) and Forward-Check (FC-CPR) algorithms is described in <ref> [33, 32] </ref>. 190 The BT-CPR algorithm, for example, maintains a set of cross-products, representing the valid partial solutions found so far, that are repeatedly extended, trimmed and merged until all the variables are covered and all non-solutions eliminated. <p> Some of these heuristic techniques are described in [47], and were used in this thesis to construct the simple control sequence for each test problem. * Comparing Bottom-Up with CPR generalized for n-ary CSPs. The cross-product representation (CPR) based algorithms <ref> [33, 32] </ref> also attack the redundant testing of constraints, using what are effectively incrementally extended domain decompositions of the CSP (see previous section for a brief description).
Reference: [33] <author> Paul D. Hubbe and Eugene C. Freuder. </author> <title> An efficient cross-product representation of the constraint satisfaction problem search space. </title> <booktitle> In Proceedings of the National Conference on AI, </booktitle> <pages> pages 421-428, </pages> <year> 1992. </year>
Reference-contexts: The cross-product representation (CPR) and its use in modified versions of the Backtrack (BT-CPR) and Forward-Check (FC-CPR) algorithms is described in <ref> [33, 32] </ref>. 190 The BT-CPR algorithm, for example, maintains a set of cross-products, representing the valid partial solutions found so far, that are repeatedly extended, trimmed and merged until all the variables are covered and all non-solutions eliminated. <p> Some of these heuristic techniques are described in [47], and were used in this thesis to construct the simple control sequence for each test problem. * Comparing Bottom-Up with CPR generalized for n-ary CSPs. The cross-product representation (CPR) based algorithms <ref> [33, 32] </ref> also attack the redundant testing of constraints, using what are effectively incrementally extended domain decompositions of the CSP (see previous section for a brief description).
Reference: [34] <author> M. Jarke. </author> <title> Common subexpression isolation in multiple query optimization. </title> <editor> In D. Reiner W. Kim and D. Batory, editors, </editor> <title> Query Processing in Database Systems. </title> <publisher> Springer-Verlag, </publisher> <year> 1984. </year>
Reference-contexts: Taking advantage of common subexpressions is a well known technique for optimizing relational database queries. It has been applied within a single query (e.g. [29]) and across groups of multiple queries (e.g. <ref> [34, 61] </ref>). The motivation there is to reduce 193 repeated access to data stored on slow media.
Reference: [35] <author> Philippe Jegou. Cyclic-clustering: </author> <title> a compromise between tree-clustering and the cycle-cutset method for improving search efficiency. </title> <booktitle> In Proceedings of the European Conference on AI, </booktitle> <pages> pages 369-371, </pages> <address> Stockholm, </address> <year> 1990. </year>
Reference: [36] <author> M. D. Johnston. Spike: </author> <title> Ai scheduling for nasa's hubble space telescope. </title> <booktitle> In Proceedings of the Sixth Conference on AI Applications. IEEE, </booktitle> <year> 1990. </year>
Reference-contexts: A solution requires the assignment of a value to each variable, selected from the corresponding domain, such that the set of constraints is satisfied. Constraint satisfaction problems have found application in design (e.g. [52, 39]), planning and scheduling (e.g. <ref> [12, 36] </ref>). Job-shop scheduling, graph coloring and satisfiability ([24]) are some examples of CSP applications that have also been of considerable theoretical interest through the years. In job-shop scheduling, for example, the variables are operation start times, and the constraints represent restrictions on resource capacities and operation precedences.
Reference: [37] <author> Craig A. Knoblock, J. Tennenberg, and Q. Yang. </author> <title> Characterizing abstraction hierarchies for planning. </title> <booktitle> In Proceedings of the Ninth NCAI, </booktitle> <address> Anaheim, CA, </address> <year> 1991. </year>
Reference-contexts: This is the same as the "upward solution property" of a hierarchical system as defined by Knoblock for planning domains in <ref> [37] </ref>. The hierarchical solution approaches discussed here are demonstrated again on more complex examples of CSPs in the next chapter. 145 Chapter 6 Some Application Case Studies This chapter presents three case studies of the application of the hierarchical solution techniques discussed in previous chapters to three simple application domains. <p> This is the same as the "upward solution property" of a hierarchical system as defined by Knoblock for planning domains in <ref> [37] </ref>. 7.3.10 Hierarchical solution in CSPs Several application domains exhibit a component based hierarchical structure. This structure manifests itself in a CSP model in several different ways. In the floorplanning domain of Chapter 6, the components are rooms, and each room is represented by four variables in the CSP.
Reference: [38] <author> Donald E. Knuth. </author> <title> Estimating the efficiency of backtrack programs. </title> <journal> Mathematics of Computation, </journal> <volume> 29(129) </volume> <pages> 121-136, </pages> <month> January </month> <year> 1975. </year>
Reference: [39] <author> S. C-Y. Lu and G. Wilhelm. </author> <title> Applying constraint-based reasoning to geometric tolerancing. </title> <editor> In J. S. Gero, editor, </editor> <booktitle> Applications of AI in Engineering V, </booktitle> <pages> pages 37-54. </pages> <publisher> Computational Mechanics Publications with Springer-Verlag, </publisher> <year> 1990. </year>
Reference-contexts: A solution requires the assignment of a value to each variable, selected from the corresponding domain, such that the set of constraints is satisfied. Constraint satisfaction problems have found application in design (e.g. <ref> [52, 39] </ref>), planning and scheduling (e.g. [12, 36]). Job-shop scheduling, graph coloring and satisfiability ([24]) are some examples of CSP applications that have also been of considerable theoretical interest through the years.
Reference: [40] <author> Alan K. Mackworth. </author> <title> Consistency in networks of relations. </title> <journal> Artificial Intelligence, </journal> <volume> 8 </volume> <pages> 99-118, </pages> <year> 1977. </year>
Reference: [41] <author> Alan K. Mackworth, J. A. Mulder, and W. S. Havens. </author> <title> Hierarchical arc consistency: Exploiting structured domains in constraint satisfaction. </title> <journal> Computational Intelligence, </journal> <volume> 1(3) </volume> <pages> 118-126, </pages> <year> 1985. </year>
Reference-contexts: The paper also describes a least-commitment approach that takes advantage of a taxonomic organization of components. This is very similar to the least-commitment search used in MOLGEN ([66, 65]). A third approach to exploiting hierarchical structure in a problem domain is described in <ref> [41] </ref>. The Hierarchical Arc Consistency (HAC) algorithm takes advantage of a taxonomic organization of the domain of each variable induced by inherent structure in the application.
Reference: [42] <author> Steven Minton. </author> <title> Integrating heuristics for constraint satisfaction problems: A case study. </title> <booktitle> In Proceedings of the National Conference on AI (AAAI-93), </booktitle> <year> 1993. </year>
Reference-contexts: There has been other work on automated programming in the field of CSPs, e.g. [2] describing techniques for problem reformulation, [69] describing a solution-repair approach, and <ref> [42] </ref> describing the automated formulation of search heuristics. 196 7.4 Future Directions This thesis opens up several interesting areas for further research.
Reference: [43] <author> David Mitchell, Bart Selman, and Hector Levesque. </author> <title> Hard and easy distributions of sat problems. </title> <booktitle> In Proceedings of the National Conference on AI (AAAI-92), </booktitle> <pages> pages 459-465, </pages> <year> 1992. </year>
Reference: [44] <author> Sanjay Mittal and F. Frayman. </author> <title> Making partial choices in constraint reasoning problems. </title> <booktitle> In Proceedings of the National Conference on AI (AAAI-87), </booktitle> <pages> pages 631-636, </pages> <address> Seattle, WA, </address> <month> August </month> <year> 1987. </year> <month> 222 </month>
Reference-contexts: HiT's global constraint decomposition was able to take advantage of this syntactic structure of the global constraint in constructing a useful abstraction for the problem. An alternative approach to the modelling and use of component structures in a CSP is described in <ref> [44] </ref>. This paper advocates the explication of the hidden structure of compound objects into tuples of variables, each representing a primitive component. The variable domains are also expressed in sets of corresponding value-tuples representing predefined component configurations.
Reference: [45] <author> Sunil Mohan. </author> <title> Constructing hierarchical solvers for constraint satisfaction problems. </title> <note> AI/Design Working Paper 137, </note> <institution> Department of Computer Science, Rutgers University, </institution> <address> New Brunswick, NJ, </address> <month> May </month> <year> 1989. </year> <type> Thesis Proposal. </type>
Reference-contexts: In the resulting hierarchical system the decomposed global constraint is replaced with a set of smaller arity constraints, which search procedures can use for early pruning. This procedure of transforming a CSP into a hierarchical CSP system is an outcome of previous research on search space abstraction, described in <ref> [45, 48, 46, 68] </ref>. For completeness, this chapter begins by reviewing search space abstraction. Then follows a description of the procedure for constructing a hierarchical CSP system by decomposing a global constraint. <p> Finally, we looked at four hierarchical search strategies for solving the resulting hierarchical system, their relative benefits and disadvantages, and how to select a suitable abstraction function. The general idea of applying abstraction levels or spaces to constraint satisfaction problems described here, and previously developed in <ref> [45, 48, 46, 68] </ref>, has been generalized by Ellman and described in [14, 15]. In Ellman's terms, the procedure HiT 144 constructs a hierarchical CSP by defining a "necessary approximate symmetry" on the original problem's search space. <p> Sacerdoti ([60]) further developed the idea into a hierarchy of abstraction 194 spaces in the system ABSTRIPS. The abstraction levels produced by HiT are very similar to these earlier forms. The general idea of using abstraction levels in constraint satisfaction problems was previously developed in <ref> [45, 48, 46, 68] </ref>. The research in this thesis builds upon this work, and makes the motivation of seeking search-pruning benefit from global constraints more explicit. Two of the hierarchical solution strategies described here, HSS-2 and HSS-4, are also new.
Reference: [46] <author> Sunil Mohan. </author> <title> Constructing hierarchical solvers for functional constraint satisfaction problems. </title> <booktitle> In Working Notes, AAAI Spring Symposium on Constraint-Based Reasoning, </booktitle> <pages> pages 147-153, </pages> <address> Stanford University, Palo Alto, CA, </address> <month> March </month> <year> 1991. </year>
Reference-contexts: In the resulting hierarchical system the decomposed global constraint is replaced with a set of smaller arity constraints, which search procedures can use for early pruning. This procedure of transforming a CSP into a hierarchical CSP system is an outcome of previous research on search space abstraction, described in <ref> [45, 48, 46, 68] </ref>. For completeness, this chapter begins by reviewing search space abstraction. Then follows a description of the procedure for constructing a hierarchical CSP system by decomposing a global constraint. <p> Finally, we looked at four hierarchical search strategies for solving the resulting hierarchical system, their relative benefits and disadvantages, and how to select a suitable abstraction function. The general idea of applying abstraction levels or spaces to constraint satisfaction problems described here, and previously developed in <ref> [45, 48, 46, 68] </ref>, has been generalized by Ellman and described in [14, 15]. In Ellman's terms, the procedure HiT 144 constructs a hierarchical CSP by defining a "necessary approximate symmetry" on the original problem's search space. <p> Sacerdoti ([60]) further developed the idea into a hierarchy of abstraction 194 spaces in the system ABSTRIPS. The abstraction levels produced by HiT are very similar to these earlier forms. The general idea of using abstraction levels in constraint satisfaction problems was previously developed in <ref> [45, 48, 46, 68] </ref>. The research in this thesis builds upon this work, and makes the motivation of seeking search-pruning benefit from global constraints more explicit. Two of the hierarchical solution strategies described here, HSS-2 and HSS-4, are also new.
Reference: [47] <author> Sunil Mohan. </author> <title> The trouble with n-ary. </title> <booktitle> In Proceedings of the Workshop on AI Approaches to Modelling and Scheduling Manufacturing Processes, at the 1994 IEEE Conference on Tools with AI. IEEE, </booktitle> <month> November </month> <year> 1994. </year>
Reference-contexts: There are two such criteria important to this thesis: 1. Constraint Arity. Problems where each constraint restricts only up to two variables are called Binary CSPs. Several problem solution techniques and heuristics take advantage of this property (e.g. <ref> [18, 10, 47] </ref>). The problem solution methods proposed in this thesis are more general and so we shall consider problems not 3 restricted on the arity of their constraints. These problems are popularly referred to as `n-ary CSPs'. 2. Number of Solutions. <p> The look-ahead nature of Forward-Check reduces the scope of constraints by eliminating the forward variable from the scope (see Chapter 2). Binary constraints get their scope trivially reduced to a single variable. This is why some dynamic ordering heuristics work particularly well for Binary CSPs in Forward-Check <ref> [47] </ref>. However, higher arity constraints, and constraint interactions, can still have extended scopes, and contain other constraints with the potential for redundant constraint checks. One of the aims of Dynamic Backtracking is to reduce the scope of a failing constraint to only its argument variables ([26, 64]). <p> In problems with global constraints, every control sequence will have the same value for these properties. Some alternative heuristics are suggested in <ref> [47] </ref> and used in this thesis. 7.3.3 Network consistency techniques Network consistency techniques preprocess a constraint network and remove values from variables' domains that are found to lead to a conflict in a small subset of the problem. <p> Since redundant tests are caused by artificial serial dependencies, even simple control sequences that minimize artificial variable dependence (as an example heuristic) should offer improved performance. Some of these heuristic techniques are described in <ref> [47] </ref>, and were used in this thesis to construct the simple control sequence for each test problem. * Comparing Bottom-Up with CPR generalized for n-ary CSPs.
Reference: [48] <author> Sunil Mohan and Chris Tong. </author> <title> Automatic construction of a hierarchical generate-and-test algorithm. </title> <booktitle> In Proceedings of the International Machine Learning Workshop, </booktitle> <address> Ithaca, NY, </address> <year> 1989. </year>
Reference-contexts: In the resulting hierarchical system the decomposed global constraint is replaced with a set of smaller arity constraints, which search procedures can use for early pruning. This procedure of transforming a CSP into a hierarchical CSP system is an outcome of previous research on search space abstraction, described in <ref> [45, 48, 46, 68] </ref>. For completeness, this chapter begins by reviewing search space abstraction. Then follows a description of the procedure for constructing a hierarchical CSP system by decomposing a global constraint. <p> Finally, we looked at four hierarchical search strategies for solving the resulting hierarchical system, their relative benefits and disadvantages, and how to select a suitable abstraction function. The general idea of applying abstraction levels or spaces to constraint satisfaction problems described here, and previously developed in <ref> [45, 48, 46, 68] </ref>, has been generalized by Ellman and described in [14, 15]. In Ellman's terms, the procedure HiT 144 constructs a hierarchical CSP by defining a "necessary approximate symmetry" on the original problem's search space. <p> Sacerdoti ([60]) further developed the idea into a hierarchy of abstraction 194 spaces in the system ABSTRIPS. The abstraction levels produced by HiT are very similar to these earlier forms. The general idea of using abstraction levels in constraint satisfaction problems was previously developed in <ref> [45, 48, 46, 68] </ref>. The research in this thesis builds upon this work, and makes the motivation of seeking search-pruning benefit from global constraints more explicit. Two of the hierarchical solution strategies described here, HSS-2 and HSS-4, are also new.
Reference: [49] <author> Ugo Montanari. </author> <title> Networks of constraints: Fundamental properties and applications to picture processing. </title> <journal> Information Sciences, </journal> <volume> 7 </volume> <pages> 95-132, </pages> <year> 1974. </year>
Reference: [50] <author> Ugo Montanari and Francesca Rossi. </author> <title> Constraint relaxation may be perfect. </title> <journal> Artificial Intelligence, </journal> <volume> 48 </volume> <pages> 143-170, </pages> <year> 1991. </year>
Reference: [51] <author> Nicola Muscettola, Barney Pell, Othar Hansson, and Sunil Mohan. </author> <title> Automating mission scheduling for space-based observatories. In Robotic Telescopes, </title> <booktitle> volume 79 of ASP Conference Series, </booktitle> <pages> pages 148-166. </pages> <booktitle> Astronomical Society of the Pacific, </booktitle> <address> San Francisco, California, </address> <year> 1995. </year>
Reference: [52] <author> B. A. Nadel and J. Lin. </author> <title> Automobile transmission design as a constraint satisfaction problem: a collaborative research project with ford motor co. </title> <booktitle> In Proceedings of the AAAI-90 Workshop on Constraint Directed Reasoning, </booktitle> <month> August </month> <year> 1990. </year>
Reference-contexts: A solution requires the assignment of a value to each variable, selected from the corresponding domain, such that the set of constraints is satisfied. Constraint satisfaction problems have found application in design (e.g. <ref> [52, 39] </ref>), planning and scheduling (e.g. [12, 36]). Job-shop scheduling, graph coloring and satisfiability ([24]) are some examples of CSP applications that have also been of considerable theoretical interest through the years.
Reference: [53] <author> George L. Nemhauser and Laurence A. Wolsey. </author> <title> Integer and Combinatorial Optimization. </title> <publisher> John Wiley and Sons, </publisher> <year> 1988. </year>
Reference: [54] <author> J. C. Shaw Newell, Alan and H. A. Simon. </author> <title> Report on a general problem-solving program. </title> <booktitle> In Information Processing - UNESCO Proceedings, </booktitle> <pages> pages 256-264. </pages> <address> UN-ESCO, </address> <month> June </month> <year> 1959. </year>
Reference-contexts: In this section we will formalize the notion of search space abstraction and abstraction levels as applied to constraint satisfaction problems. 5.1.1 Defining an abstraction level The notion of Abstraction Levels was first introduced in the AI community in GPS <ref> [54] </ref> and ABSTRIPS [60]. An abstraction level is a complete and self-contained simpler version of the original problem, with an abstracted search space, and abstracted constraints. Each abstract solution refines into a set of candidates, called its refinement, in the Lower or Base Level search space.
Reference: [55] <author> Nils J. Nilsson. </author> <booktitle> Principles of AI. </booktitle> <publisher> Morgan Kaufmann, </publisher> <year> 1980. </year>
Reference-contexts: the constraints T ij represent the following relations: T 13 = T 14 = T 24 = T 35 = T 45 = fa; b; cg fi fa; b; cg 2.2 Backtrack Search 2.2.1 The Backtrack algorithm The most well known algorithm for solving a Constraint Satisfaction Problem is Backtrack <ref> [27, 55] </ref>. Given an ordering of variables and constraints for a problem, at each step it either picks a new value binding for the current variable, or evaluates the current constraint on the already bound (or instantiated) variables.
Reference: [56] <author> B. A. Nudel. </author> <title> Consistent-labeling problems and their algorithms: expected-complexities and theory-based heuristics. </title> <journal> Artificial Intelligence (special issue on Search and Heuristics), </journal> <volume> 21(3 and </volume> 4):135-178, March 1983. Also in book: Search and Heuristics, North Holland, Amsterdam, 1983. 
Reference: [57] <author> Mark Perlin. </author> <title> Arc consistency for factorable relations. </title> <journal> Artificial Intelligence, </journal> <volume> 53 </volume> <pages> 329-342, </pages> <year> 1992. </year>
Reference-contexts: There are situations where the solution cache tree structure can be made more space efficient. For example, a fuller cache tree is more efficiently representable by storing values that do not occur. Relation factoring (e.g. <ref> [57] </ref>) can also be used to compress the solution cache. * Upgrading the Forward-Check implementation of bottom-up solution. The current implementation treats divisions between subproblems as hard boundaries.
Reference: [58] <author> P. W. Jr. Purdom and C. A. Brown. </author> <title> An analysis of backtracking with search rearrangement. </title> <journal> SIAM Journal of Computing, </journal> <volume> 12(4) </volume> <pages> 717-733, </pages> <year> 1983. </year> <month> 223 </month>
Reference: [59] <author> F. Rossi and U. Montanari. </author> <title> Exact solution in linear time of networks of constraints using perfect relaxation. </title> <booktitle> In Proceedings of the 1st International Conference on Principles of Knowledge Representation and Reasoning, </booktitle> <pages> pages 394-399. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1989. </year>
Reference: [60] <author> Earl D. Sacerdoti. </author> <title> Planning in a hierarchy of abstraction spaces. </title> <journal> Artificial Intelligence, </journal> <volume> 5(2) </volume> <pages> 115-135, </pages> <year> 1974. </year>
Reference-contexts: In this section we will formalize the notion of search space abstraction and abstraction levels as applied to constraint satisfaction problems. 5.1.1 Defining an abstraction level The notion of Abstraction Levels was first introduced in the AI community in GPS [54] and ABSTRIPS <ref> [60] </ref>. An abstraction level is a complete and self-contained simpler version of the original problem, with an abstracted search space, and abstracted constraints. Each abstract solution refines into a set of candidates, called its refinement, in the Lower or Base Level search space.
Reference: [61] <author> Timos K. Sellis. </author> <title> Global query optimization. </title> <booktitle> In ACM-SIGMOD, </booktitle> <pages> pages 191-205, </pages> <year> 1986. </year>
Reference-contexts: Taking advantage of common subexpressions is a well known technique for optimizing relational database queries. It has been applied within a single query (e.g. [29]) and across groups of multiple queries (e.g. <ref> [34, 61] </ref>). The motivation there is to reduce 193 repeated access to data stored on slow media.
Reference: [62] <author> Murray Shanahan and Richard Southwick. </author> <title> Search, Inference and Dependencies in AI. </title> <publisher> Ellis Horwood Ltd., </publisher> <address> Chichester, England, </address> <year> 1989. </year>
Reference-contexts: A complete search tree lists all the possible bindings. Clever search algorithms try to reduce the number of nodes actually explored by avoiding as early as possible paths that do not lead to a solution. Different techniques are used to detect dead-end branches, e.g. <ref> [31, 62, 10] </ref>. 2.2.3 The cost of search Both space (memory) and time requirements of a search algorithm are useful measures of its efficiency. The memory used by most popular search algorithms is bound by a polynomial function on the number of variables and sizes of their domains [31]. <p> This is a source of inefficiency in the search procedure, and the first part of the thesis (chapter 3) focuses on some techniques to reduce redundant constraint checks. Redundancies are a well known source of inefficiency in the solution of CSPs. For example, <ref> [62] </ref> identify the "redundant discovery of incompatibilities and the redundant elimination of possibilities" as "two major sources of inefficiency in chronological backtracking". The definition of a redundant constraint check used in this thesis is more general, and includes constraint checks that succeed, in addition to those that fail. <p> This was yet further generalized into the Dynamic Backtracking algorithm ([26]). See also <ref> [62] </ref> for a good description of the historical development of the ideas of selective backtracking and conflict recording, and their application to solving CSPs and theorem proving. We will only look at some of the main points in Dynamic Backtracking here, and for a detailed description defer to [26].
Reference: [63] <author> David E. Smith. </author> <title> Controlling Inference. </title> <type> PhD thesis, </type> <institution> Dept of Computer Science, Stanford University, </institution> <year> 1985. </year>
Reference-contexts: functions: Args (C) = The set or tuple of variables occuring as arguments to constraints in the control sequence C Vars (C) = The set or tuple of variables generated or bound in control sequence C The cost model developed below is an extension of the cost model described in <ref> [63] </ref>, modified to account for CSPs where the cost of a constraint depends upon the size of its search space, and not on the number of its solutions. 2.6.1 Number of solutions of a CSP Let us define Numsol (C b ; Y a = y) to represent the number of <p> For a constraint T , AvgCost (T ; C) = Cost (T ) = k T The main difference between this cost model and that developed by Smith <ref> [63] </ref> is that here the cost of solving a constraint includes the cost of generating its search space, whereas in Smith's model the cost of solving a conjunct is proportional to the number of its solutions.
Reference: [64] <author> R. M. Stallman and Gerald J. Sussman. </author> <title> Forward reasoning and dependency-directed backtracking in a system for computer-aided circuit analysis. </title> <journal> Artificial Intelligence, </journal> <volume> 9(2) </volume> <pages> 135-196, </pages> <year> 1977. </year>
Reference: [65] <author> Mark J. Stefik. </author> <title> Planning and meta-planning (MOLGEN: Part 2). </title> <journal> Artificial Intelligence, </journal> <volume> 16 </volume> <pages> 141-169, </pages> <year> 1981. </year>
Reference: [66] <author> Mark J. Stefik. </author> <title> Planning with constraints (MOLGEN: Part 1). </title> <journal> Artificial Intelligence, </journal> <volume> 16 </volume> <pages> 111-140, </pages> <year> 1981. </year>
Reference: [67] <author> C. Tong. KBSDE: </author> <title> an environment for developing knowledge-based design tools. </title> <editor> In T. Dietterich, editor, </editor> <booktitle> Proceedings of the Workshop on Knowledge Compilation, </booktitle> <pages> pages 127-138, </pages> <institution> Oregon State University, </institution> <month> September </month> <year> 1986. </year>
Reference: [68] <author> Christopher Tong, Wesley Braudaway, Sunil Mohan, and Kerstin Voigt. </author> <title> Reformulating constraints for compilability and efficiency. </title> <booktitle> In Proceedings of the Workshop on Change of Representation and Problem Reformulation, </booktitle> <address> April 1992. Pacific Grove, CA. </address>
Reference-contexts: In the resulting hierarchical system the decomposed global constraint is replaced with a set of smaller arity constraints, which search procedures can use for early pruning. This procedure of transforming a CSP into a hierarchical CSP system is an outcome of previous research on search space abstraction, described in <ref> [45, 48, 46, 68] </ref>. For completeness, this chapter begins by reviewing search space abstraction. Then follows a description of the procedure for constructing a hierarchical CSP system by decomposing a global constraint. <p> Finally, we looked at four hierarchical search strategies for solving the resulting hierarchical system, their relative benefits and disadvantages, and how to select a suitable abstraction function. The general idea of applying abstraction levels or spaces to constraint satisfaction problems described here, and previously developed in <ref> [45, 48, 46, 68] </ref>, has been generalized by Ellman and described in [14, 15]. In Ellman's terms, the procedure HiT 144 constructs a hierarchical CSP by defining a "necessary approximate symmetry" on the original problem's search space. <p> Sacerdoti ([60]) further developed the idea into a hierarchy of abstraction 194 spaces in the system ABSTRIPS. The abstraction levels produced by HiT are very similar to these earlier forms. The general idea of using abstraction levels in constraint satisfaction problems was previously developed in <ref> [45, 48, 46, 68] </ref>. The research in this thesis builds upon this work, and makes the motivation of seeking search-pruning benefit from global constraints more explicit. Two of the hierarchical solution strategies described here, HSS-2 and HSS-4, are also new.
Reference: [69] <author> Kerstin Voigt and Chris Tong. </author> <title> Automating the construction of patchers that satisfy global constraints. </title> <booktitle> In Proceedings of the International Joint Conference on AI, </booktitle> <year> 1989. </year>
Reference-contexts: There has been other work on automated programming in the field of CSPs, e.g. [2] describing techniques for problem reformulation, <ref> [69] </ref> describing a solution-repair approach, and [42] describing the automated formulation of search heuristics. 196 7.4 Future Directions This thesis opens up several interesting areas for further research.
Reference: [70] <author> H. P. Williams. </author> <title> Model Building in Mathematical Programming. </title> <publisher> John Wiley and Sons, </publisher> <address> second edition, </address> <year> 1985. </year>
Reference-contexts: In our problem model, we will assign one variable to each department. The value 1 This problem is adapted from problem 12.10 in <ref> [70] </ref>. An expanded version of the original problem is described here. 164 of each variable in a solution will be the new location of that department in one relocation scheme. The corporation (c 0 in our model), owns two companies (c 1 and c 2 ).
Reference: [71] <author> Ramin Zabih. </author> <title> Some applications of graph bandwidth to constraint satisfaction problems. </title> <booktitle> In Proceedings of the National Conference on AI (AAAI-90), </booktitle> <pages> pages 46-51, </pages> <year> 1990. </year> <month> 224 </month>
Reference-contexts: This results in earlier invocation of each refinement constraint, with smaller backtrack potential. (See, for example, the discussion on the connection between constraint bandwidth and backtrack overhead in <ref> [71] </ref>). Usually, a small abstract search space and many refinement constraints are conflicting requirements, and a balance is needed. In the procedure HiT for constructing a hierarchical CSP described in the previous section, the abstract search space was defined from knowledge about the ranges of the component abstraction functions.
References-found: 71

