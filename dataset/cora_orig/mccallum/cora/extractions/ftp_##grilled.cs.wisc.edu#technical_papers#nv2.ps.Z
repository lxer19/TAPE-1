URL: ftp://grilled.cs.wisc.edu/technical_papers/nv2.ps.Z
Refering-URL: http://www.cs.wisc.edu/~paradyn/papers.html
Root-URL: 
Title: Mapping Performance Data for High-Level and Data Views of Parallel Program Performance 1  
Date: November 27, 1995  
Note: Page 1  
Abstract: Programs written in high-level parallel languages need profiling tools that provide performance data in terms of the semantics of the high-level language. But high-level performance data can be incomplete when the cause of a performance problem cannot be explained in terms of the semantics of the language. We also need the ability to view the performance of the underlying mechanisms used by the language and correlate the underlying activity to the language source code. The key techniques for providing these performance views is the ability to map low-level performance data up to the language abstractions. We identify the various kinds of mapping information that needs to be gathered to support multiple views of performance data and describe how we can mine mapping information from the compiler and run-time environment. We also describe how we use this information to produce performance data at the higher levels, and how we present this data in terms of both the code and parallel data structures. We have developed an implementation of these mapping techniques for the data parallel CM Fortran language running on the TMC CM-5. We have augmented the Paradyn Parallel Performance Tools with these mapping and high-level language facilities and used them to study several real data parallel Fortran (CM Fortran) applications. Our mapping and high-level language techniques allowed us to quickly understand these applications and modify them to obtain significant performance improvements.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Vikram S. Adve, Jhu-Chun Wang, John Mellor-Crummey, Daniel A. Reed, Mark Anderson, and Ken Kennedy. </author> <title> An integrated compilation and performance analysis environment for data parallel programming. </title> <type> Technical Report 94513-S, </type> <institution> CR-PC, </institution> <year> 1994. </year>
Reference: [2] <author> Francois Bodin, P. Beckman, Dennis Gannon, J. Gotwals, S. Narayana, S. Srinivas, and B. Winnicka. Sage++: </author> <title> An object oriented toolkit and class library for building fortran and C++ restructuring tools. </title> <booktitle> In OONSKI 1994, </booktitle> <year> 1994. </year>
Reference-contexts: In the research world, examples include the Pablo system from the Universities of Illinois [24,1] that can trace Fortran D programs and present this information in terms of the source program, and TAU from University of Oregon [20] that can do similar operations for pC++ programs <ref> [2] </ref>. While presenting performance data at the source code level of a high-level parallel language is crucial, it is not always sufficient. The language abstractions can insulate a programmer from the need to specify the low-level details, but they can also hide the cause of a performance problem.
Reference: [3] <author> Leonardo Dagum. </author> <title> Three-dimensional direct particle simulation on the connection machine. </title> <type> Technical Report RNR-91-022, </type> <institution> NASA Ames Research Center, </institution> <year> 1991. </year>
Reference: [4] <author> Leonardo Dagum and S.H. Konrad Zhuh. </author> <title> Three-dimensional particle simulation of high altitude rocket plumes. </title> <type> Technical Report RNR-92-026, </type> <institution> NASA Ames Research Center, </institution> <year> 1992. </year>
Reference: [5] <author> William DePauw, Richard Helm, Doug Kimelman, and John Vlissades. </author> <title> Visualizing the behavior of object-oriented systems. </title> <booktitle> In Object-Oriented Programming Systems, Languages, and Applications Conference, </booktitle> <pages> pages 326337, </pages> <month> May </month> <year> 1993. </year> <note> Page 21 November 27, </note> <year> 1995 </year>
Reference: [6] <author> A. J. Goldberg and John Hennessy. </author> <title> Performance debugging shared memory multiprocessor programs with mtool. </title> <booktitle> In Supercomputing 1991, </booktitle> <pages> pages 481490, </pages> <month> November </month> <year> 1991. </year>
Reference: [7] <author> S. L. Graham, P. B. Kessler, and M. K. McKusick. </author> <title> Gprof: A call graph execution profiler. </title> <booktitle> In ACM SIGPLAN Symposium on Compiler Construction, </booktitle> <month> June </month> <year> 1982. </year>
Reference-contexts: If you try to split the cost between the merged source statements, you must be able to assign a proportion to each statement; this is not always possible. Simply making an even split (such as is done with recursive procedure call chains in gprof <ref> [7] </ref>) can produce misleading results. 3.2 Mining Mapping Data Mining noun, verb, and mapping data from a parallel programming system is sometimes difficult because the programming systems either do not provide information or the information is provided in non-standard ways.
Reference: [8] <author> Anoop Gupta, Margaret Martonosi, and Tom Anderson. Memspy: </author> <title> Analyzing memory system bottlenecks in programs. Performance Evaluation Review, </title> <address> 20(1):112, </address> <month> June </month> <year> 1992. </year>
Reference-contexts: Our facility for mapping low-level performance data makes it relatively easy to provide both control and data views. Data views of performance are not new; they have been used to study memory system behavior. For example, Cprof [17] and MemSpy <ref> [8] </ref> can relate cache hits and misses to data structures in sequential C and Fortran programs. Several algorithm animation and visualization tools have been developed as part of sequential object-oriented programming systems [9,16,5].
Reference: [9] <author> V. Haarslev and R. Moller. </author> <title> A framework for visualizing object-oriented systems. </title> <booktitle> In Object-Oriented Programming Systems, Languages, and Applications Conference, </booktitle> <pages> pages 237244, </pages> <month> May </month> <year> 1990. </year>
Reference: [10] <author> Michael T. Heath and Jennifer A. Etheridge. </author> <title> Visualizing the performance of parallel programs. </title> <journal> IEEE Software, </journal> <volume> 8(5):2939, </volume> <month> September </month> <year> 1991. </year>
Reference: [11] <author> High Performance Fortran Forum. </author> <title> High Performance Fortran Language Specification - Version 1.0, </title> <month> January </month> <year> 1993. </year>
Reference-contexts: Mappings are discussed in detail in Section 3. We will describe the NV model using examples from the data-parallel language CM Fortran [28]. CM Fortran (and its implementation on CM-5 computers) is representative of many high-level parallel programming languages, including HPF <ref> [11] </ref>. The NV model, however, is applicable to many other parallel programming models. We will use the example CM Fortran program in Figure 1 to describe some of the nouns and verbs of the CM Fortran language.
Reference: [12] <author> Jeffrey K. Hollingsworth and Barton P. Miller. </author> <title> Dynamic control of performance monitoring on large scale parallel systems. </title> <booktitle> In 7th ACM International Conference on Supercomputing, </booktitle> <pages> pages 185194, </pages> <month> July </month> <year> 1993. </year>
Reference: [13] <author> Jeffrey K. Hollingsworth, Barton P. Miller, and Jon Cargille. </author> <title> Dynamic program instrumentation for scalable performance tools. </title> <booktitle> In Scalable High Performance Computing Conference, </booktitle> <month> May </month> <year> 1994. </year>
Reference: [14] <author> R. Bruce Irvin and Barton P. Miller. </author> <title> A performance tool for high-level parallel programming languages. </title> <editor> In Karsten M. Decker and Rene M. Rehmann, editors, </editor> <booktitle> Programming Environments for Massively Parallel Distributed Systems, </booktitle> <pages> pages 299314. </pages> <publisher> Birkhauser Verlag, </publisher> <year> 1994. </year>
Reference-contexts: We conclude in Section 5. 2 THE NV MODEL OF HIGH-LEVEL PERFORMANCE DATA We have developed a framework within which we can discuss performance characteristics of programs written in many different programming models. This framework is called the Noun-Verb (NV) model <ref> [14] </ref>. In NV, a noun is any program element for which performance measurements can be made, and a verb is any potential action that might be taken by a noun or performed on a noun.
Reference: [15] <author> R. Bruce Irvin. </author> <title> Performance tool for high-level parallel programming languages. </title> <type> Ph.D. Dissertation, </type> <institution> University of Wiscon-sin-Madison, </institution> <month> November </month> <year> 1995. </year>
Reference-contexts: The code was written by a group of computational scientists at the Numerical Aerodynamic Simulation Laboratory of NASA Ames Research Center. We briey summarize our experience with PSICM; a full description of this study can be found elsewhere <ref> [15] </ref>. Our analysis of PSICM showed that combinations of code and data views of performance could be very useful for the performance analysis of data-parallel programs. In particular, we identified a single statement that caused large amounts of implicit Node-level activity and explained the cause of the activity.
Reference: [16] <author> M. F. Kleyn and P. C. Gingrich. </author> <title> Graphtrace - understanding object-oriented systems using concurrently animated views. </title> <booktitle> In Object-Oriented Programming Systems, Languages, and Applications Conference, </booktitle> <pages> pages 191205, </pages> <month> May </month> <year> 1988. </year>
Reference: [17] <author> Alvin R. Lebeck and David A. Wood. </author> <title> Cache profiling and the spec benchmarks: A case study. </title> <journal> IEEE Computer, </journal> <volume> 27(10):15 26, </volume> <month> October </month> <year> 1994. </year>
Reference-contexts: Our facility for mapping low-level performance data makes it relatively easy to provide both control and data views. Data views of performance are not new; they have been used to study memory system behavior. For example, Cprof <ref> [17] </ref> and MemSpy [8] can relate cache hits and misses to data structures in sequential C and Fortran programs. Several algorithm animation and visualization tools have been developed as part of sequential object-oriented programming systems [9,16,5]. <p> First aggregate costs of F1, F2, ..., then treat as a one-to-many mapping to L1, L2, ... Page 7 November 27, 1995 returned by function foo () when called by function bar ( ). This is similar to the scheme used in the Cprof memory profiler <ref> [17] </ref>. This technique can also be applied to case 1. 4. We could name the object by the memory location at which it was allocated. For example, noun:0x5000 might represent the data object allocated at memory location 0x5000. If memory space is re-used, there is a chance of ambiguity.
Reference: [18] <institution> MasPar Computer Corporation, 749 North Mary Avenue, Sunnyvale, CA. </institution> <note> MPPE Reference Manual, </note> <year> 1991. </year>
Reference-contexts: There are several existing tools that do source-level profiling. Some commercial examples of these tools include the MPP Apprentice [29] for the Cray T3D, Prism [27] for the TMC CM-5 and MPPE <ref> [18] </ref> from Maspar. In the research world, examples include the Pablo system from the Universities of Illinois [24,1] that can trace Fortran D programs and present this information in terms of the source program, and TAU from University of Oregon [20] that can do similar operations for pC++ programs [2].
Reference: [19] <author> Barton P. Miller, Mark D. Callaghan, Jonathan M. Cargille, Jeffrey K. Hollingsworth, R. Bruce Irvin, Karen L. Karavanic, Krishna Kunchithapadam, and Tia Newhall. </author> <title> The Paradyn parallel performance measurement tools. </title> <journal> IEEE Computer, </journal> <volume> 28(11), </volume> <month> November </month> <year> 1995. </year>
Reference: [20] <author> Bernd Mohr, Darryl Brown, and Allen Malony. </author> <title> Tau: A portable parallel program analysis environment for pC++. </title> <booktitle> In International Conference on Parallel Systems, </booktitle> <pages> pages 2940. </pages> <publisher> Springer Verlag, </publisher> <month> September </month> <year> 1994. </year>
Reference-contexts: In the research world, examples include the Pablo system from the Universities of Illinois [24,1] that can trace Fortran D programs and present this information in terms of the source program, and TAU from University of Oregon <ref> [20] </ref> that can do similar operations for pC++ programs [2]. While presenting performance data at the source code level of a high-level parallel language is crucial, it is not always sufficient.
Reference: [21] <author> D. W. Peaceman and H. H. Rachford. </author> <title> The numerical solution of parabolic and elliptic differential equations. </title> <journal> Journal of the Society of Industrial Applied Mathematics, </journal> <volume> 3(1):2833, </volume> <year> 1955. </year>
Reference: [22] <author> Donald W. Peaceman. </author> <title> Fundamentals of Numerical Reservoir Simulation. </title> <publisher> Elsevier Scientific Publishing Company, </publisher> <year> 1977. </year>
Reference: [23] <institution> Pure Software Incorporated, </institution> <address> Menlo Park, CA. </address> <note> Quantify Users Guide, </note> <year> 1993. </year>
Reference: [24] <author> Daniel A. Reed, Robert D. Olson, Ruth A. Aydt, Tara M. Madhyastha, Thomas Birkett, David W. Jensen, Bobby A. Nazief, and Brian K. Totty. </author> <title> Scalable performance analysis: The Pablo performance analysis environment. </title> <editor> In A. Skjellum, editor, </editor> <booktitle> Scalable Parallel Libraries Conference. IEEE Computer Society, </booktitle> <year> 1993. </year>
Reference: [25] <author> Robert T. Schumacher. </author> <title> Self-sustaining oscillations of the bowed string. </title> <address> Acustica, 43:109, </address> <year> 1979. </year>
Reference: [26] <author> Robert T. Schumacher. </author> <title> Analysis of aperiodicities in nearly periodic waveforms. </title> <journal> Journal of Acoustic Society of America, </journal> <volume> 91:438, </volume> <year> 1992. </year>
Reference: [27] <author> Steve Sistare, Don Allen, Rich Bowker, Karen Jourdenais, Josh Simons, and Rich Title. </author> <title> Data visualization and performance analysis in the Prism programming environment. </title> <booktitle> In Programming Environments for Parallel Computing, </booktitle> <pages> pages 3752. </pages> <publisher> North-Holland, </publisher> <year> 1992. </year>
Reference-contexts: There are several existing tools that do source-level profiling. Some commercial examples of these tools include the MPP Apprentice [29] for the Cray T3D, Prism <ref> [27] </ref> for the TMC CM-5 and MPPE [18] from Maspar.
Reference: [28] <institution> Thinking Machines Corporation, </institution> <address> Cambridge MA. </address> <note> CM Fortran Reference Manual, </note> <month> January </month> <year> 1991. </year>
Reference-contexts: With mappings, performance information collected at arbitrary levels of abstraction can be related to language level nouns and verbs. Mappings are discussed in detail in Section 3. We will describe the NV model using examples from the data-parallel language CM Fortran <ref> [28] </ref>. CM Fortran (and its implementation on CM-5 computers) is representative of many high-level parallel programming languages, including HPF [11]. The NV model, however, is applicable to many other parallel programming models.
Reference: [29] <author> Winifred Williams, Timothy Hoel, and Douglas Pase. </author> <title> The MPP Apprentice performance tool: Delivering the performance of the Cray T3D. </title> <editor> In Karsten M. Decker and Rene M. Rehmann, editors, </editor> <title> Programming Environments for Massively Parallel Distributed Systems. </title> <publisher> Birkhauser Verlag, </publisher> <year> 1994. </year>
Reference-contexts: If we present performance data in terms of low-level node computing and message passing, for example, it would be difficult for the programmer to relate this information to their program. There are several existing tools that do source-level profiling. Some commercial examples of these tools include the MPP Apprentice <ref> [29] </ref> for the Cray T3D, Prism [27] for the TMC CM-5 and MPPE [18] from Maspar.
References-found: 29

