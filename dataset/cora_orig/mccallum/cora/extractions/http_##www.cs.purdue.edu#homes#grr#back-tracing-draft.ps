URL: http://www.cs.purdue.edu/homes/grr/back-tracing-draft.ps
Refering-URL: http://www.cs.purdue.edu/people/grr/
Root-URL: http://www.cs.purdue.edu
Title: Cyclic Distributed Garbage Collection Without Global Synchronization  Comittee Members:  
Author: Vincent Russo (Advisor) Douglas Comer, Tony Hosking, Michal Young, Vernon Rego 
Address: West Lafayette, IN 47907  
Affiliation: Computer Science Department Purdue University  
Note: Ph.D. Candidate: Gustavo Rodriguez-Rivera,  
Abstract: Preliminary Examination Report April 28, 1995 Abstract In this report we show an algorithm for cyclic distributed garbage collection that does not require global coordination and is tolerant to message, network, and process failures. Most of the cyclic distributed garbage collectors use mark-and-sweep to find the transitive closure of objects that are reached from the global roots. The main disadvantage of mark-and-sweep is that it requires global coordination to know when the mark-phase has ended. Our algorithm takes a more radical approach and uses back-tracing instead of mark-and-sweep to eliminate the need for global synchronization. Starting from an object that is suspected to be garbage, the algorithm recursively traces back the references that point to the suspect to find the transitive closure of objects that reach the suspect. If this closure does not contain any root, then the objects in the closure are collected. Local garbage collectors have to be modified to provide back-references for local proxies (representation of remote objects) and local principals (exported objects). One interesting feature of the algorithm is that all the state necessary for garbage collecting one closure is stored in a single message. This allows the algorithm not to require global synchronization and to make it scalable for usage in very large distributed systems. The cost of the algorithm is minimum. It only adds small overhead in the local garbage collector to compute the back-references plus some extra space in the process to store them. We show how this algorithm is implemented and a proof of its correctness. 
Abstract-found: 1
Intro-found: 1
Reference: [BDS91] <author> Hans-J. Boehm, Alan J. Demers, and Scott Shenker. </author> <title> Mostly parallel garbage collection. </title> <booktitle> In Proceedings of the 1991 SIGPLAN Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 157-164, </pages> <address> Toronto, Ontario, </address> <month> June </month> <year> 1991. </year> <note> ACM Press. Published as SIGPLAN Notices 26(6), </note> <month> June </month> <year> 1992. </year>
Reference-contexts: Any other incremental garbage collection technique can be adapted to also find the local-back-references without long pauses. In the Renaissance local garbage collector we have used an incremental garbage collector based on the one described in <ref> [BDS91] </ref>. New proxies and principals are created with z.roots equal to [R] . Also new principals are created with the flag o.dirty set to true, and o.sequence equal to 0 .
Reference: [BEN + 93] <author> Andrew Birrell, David Evers, Greg Nelson, Susan Owicki, and Edward Wobber. </author> <title> Distributed Garbage Collection for Network Objects. </title> <type> Technical Report 116, </type> <institution> Digital Equipment Corporation Systems Research Center, </institution> <year> 1993. </year>
Reference-contexts: Other algorithms are efficient passing references around without telling the owner, but are not fault-tolerant. Other algorithms are scalable and deal with process crashing and lost and duplicated messages, but are not cyclic. The algorithm we propose here is an extension of reference listing algorithms such as <ref> [BEN + 93] </ref>, and [SDP92]. These algorithms are already scalable and tolerant to lost and duplicated messages, but can not collect cyclic data. The algorithm we describe uses reference listing plus additional mechanisms that allow the collection of garbage cycles without the need of global synchronization. <p> In order to insure this invariant even in the presence of lost and duplicated messages we use an approach similar to the one described in <ref> [BEN + 93] </ref>. Assume that process p wants to send an object-id oid for object o to process q, and r is the process that owns o. Also assume that p, q, and r are different processes. <p> Periodically each process p checks if the process q still exists (using a special server described later). If the processes has died, then it removes that entry from p.recentfqg. A more detailed description of these operations and a proof of their correctness are described in <ref> [BEN + 93] </ref>. 2.3 Local Garbage Collection and Local Back References The local garbage collector has to be modified to find the local-back-references of local principals and local proxies. Local-back-references are kept for every proxy and principal z in the variable z.roots. <p> Notice that if a process crashes helding a reference to an object, the object is never deleted. Also this algorithm is not tolerant to message lost and duplication. Reference listing is a variation of reference counting that is tolerant to failures [SDP92], <ref> [BEN + 93] </ref>, and [MS91]. In reference listing, principals keep a list of the processes that have references to them. This is similar to what our algorithm does. When a reference is transmitted, the owner of the principal has to be notified to update the list for that principal.
Reference: [Bev87] <author> David I. Bevan. </author> <title> Distributed Garbage Collection Using Reference Counting. </title> <editor> In de Bakker et al. </editor> <booktitle> [dBNT87], </booktitle> <pages> pages 176/117-187. </pages>
Reference-contexts: Some of these algorithms pass references in a single message. However, they are unable to collect objects after a process that was helding references to them has crashed. Weighted reference counting is one of these algorithms <ref> [Bev87] </ref>, [WW87]. In weighted reference counting each reference has an associated integer weight. When a process passes a copy of the reference, part of this weight goes with the copy.
Reference: [Bis77] <author> Peter B. Bishop. </author> <title> Computer Systems with a Very Large Address Space and Garbage Collection. </title> <type> PhD thesis, </type> <institution> Massachusetts Institute of Technology Laboratory for Computer Science, </institution> <month> May </month> <year> 1977. </year> <note> Technical report MIT/LCS/TR-178. </note>
Reference-contexts: Even though the algorithm addresses the issue of global coordination, it only solves the problem partially. Services that have a large number of clients should include all the clients in their garbage collections. Some other techniques are a hybrid of reference counting and tracing techniques. For example <ref> [Bis77] </ref> suggests the idea of using reference counting plus object migration to collect cycles of garbage. When a group of objects is suspected to form a garbage cycle, they are moved to a single process where the local garbage collector can collect them.
Reference: [dBNT87] <editor> Jacobus W. de Bakker, L. Nijman, and Philip C. Treleaven, editors. </editor> <booktitle> Parallel Architectures and Languages Europe, number 258, 259 in Lecture Notes in Computer Science, </booktitle> <address> Eindhoven, The Netherlands, June 1987. </address> <publisher> Springer-Verlag. </publisher>
Reference: [Hug85] <author> John Hughes. </author> <title> A distributed garbage collection algorithm. </title> <editor> In Jean-Pierre Jouannaud, editor, </editor> <booktitle> ACM Conference on Functional Programming Languages and Computer Architecture, number 201 in Lecture Notes in Computer Science, </booktitle> <pages> pages 256-272, </pages> <address> Nancy, France, </address> <month> September </month> <year> 1985. </year> <note> Springer-Verlag. </note>
Reference-contexts: In this way reference operations are tolerant to message lost and duplication. Reference listing scales up very well, however it is not capable of collecting garbage cycles. Tracing with time stamps <ref> [Hug85] </ref> is an elegant extension to the mark-and-sweep garbage collector for a distributed environment. The basic idea is that each local garbage collection propagates a GC-time-stamp from the local roots to the objects they reach. These time stamps are also propagated from proxies to principals.
Reference: [JL92] <author> Richard E. Jones and Rafael D. Lins. </author> <title> Cyclic weighted reference counting without delay. </title> <type> Technical Report 28-92, </type> <institution> University of Kent, Canterbury, </institution> <address> United Kingdom, </address> <month> December </month> <year> 1992. </year>
Reference-contexts: A major drawback of the algorithm is that not all distributed systems allow object migration. Another hybrid technique traces locally subgraphs rooted by potential garbage objects <ref> [JL92] </ref>. Objects in the subgraph that are reachable from an external root are kept. Objects that are only reachable from within the subgraph are deleted. The drawback of this algorithm is the overhead introduced by tracing the subgraph every time a reference is deleted. In a following paper [JL92], they reduce <p> garbage objects <ref> [JL92] </ref>. Objects in the subgraph that are reachable from an external root are kept. Objects that are only reachable from within the subgraph are deleted. The drawback of this algorithm is the overhead introduced by tracing the subgraph every time a reference is deleted. In a following paper [JL92], they reduce the tracing overhead by delaying the tracing of several graphs and grouping them into one. However, still some kind of global synchronization is needed to allow multiple auxiliary tracings to run at the same time. Our algorithm has some similarities to this one.
Reference: [LL89] <author> Barbara Liskov and Rivka Ladin. </author> <title> Highly-available distributed services and fault- tolerant distributed garbage collection. </title> <booktitle> In Fifth ACM Symposium on the Principles of Distributed Computing, </booktitle> <pages> pages 29-39, </pages> <year> 1989. </year>
Reference-contexts: The main problem of this algorithm is that it requires global coordination to compute this lower-bound. Also the garbage of the whole system may be held because a lazy process does not run garbage collection. A logically centralized but physically distributed reference service is used in <ref> [LL89] </ref> to centralize all the reach-ability information of the system. Each local garbage collector sends the reachability information they gather to this service. Using all the reachability information, the service builds the reachability graph of the system and determines which objects are garbage.
Reference: [LL92] <author> Rivka Ladin and Barbara Liskov. </author> <title> Garbage collection of a distributed heap. </title> <booktitle> In Principles of Distributed Computing, </booktitle> <pages> pages 708-715, </pages> <year> 1992. </year>
Reference-contexts: Each local garbage collector sends the reachability information they gather to this service. Using all the reachability information, the service builds the reachability graph of the system and determines which objects are garbage. Later in another paper by the same authors <ref> [LL92] </ref>, they reduced the amount of information that the centralized server needs to hold by implementing Hughes' algorithm. The centralized server propagates time-stamps internally and it determines the global lower-bound. Because of the need of a centralized service, this algorithm does not scale up well.
Reference: [LQP92] <author> Bernard Lang, Christian Queinnec, and Jose Piquer. </author> <title> Garbage collecting the world. </title> <booktitle> In ACM Symposium on Principles of Programming, </booktitle> <pages> pages 39-50, </pages> <address> Albuquerque, New Mexico, </address> <month> January </month> <year> 1992. </year>
Reference-contexts: The centralized server propagates time-stamps internally and it determines the global lower-bound. Because of the need of a centralized service, this algorithm does not scale up well. Garbage collection between groups is suggested in <ref> [LQP92] </ref> to solve the problem of global synchronization. Complete garbage collection is performed inside each group, and inter-group references are treated conservatively. First the algorithm performs group negotiation to build up a group. Then it performs a marking phase that requires coordination between the processes in the group.
Reference: [MR93] <author> Patrick A. Muckelbauer and Vincent F. Russo. </author> <title> The Renaissance Distributed Object System. </title> <type> Technical Report TR.93-022, </type> <institution> Department of Computer Science, Purdue University, </institution> <year> 1993. </year>
Reference-contexts: The algorithm we describe uses reference listing plus additional mechanisms that allow the collection of garbage cycles without the need of global synchronization. It was implemented as part of the Renaissance distributed system <ref> [MR93] </ref>. However, it can be used as an extension for systems that already use reference listing to collect garbage cycles. The paper is organized in the following way: First, we explain the terminology used in this paper and the basic ideas behind the algorithm.
Reference: [MS91] <author> Luigi Mancini and S. K. Shrinivastava. </author> <title> Fault-tolerant reference counting for garbage colection in distributed systems. </title> <journal> Computer Journal, </journal> <volume> 34(6) </volume> <pages> 503-513, </pages> <month> December </month> <year> 1991. </year>
Reference-contexts: Notice that if a process crashes helding a reference to an object, the object is never deleted. Also this algorithm is not tolerant to message lost and duplication. Reference listing is a variation of reference counting that is tolerant to failures [SDP92], [BEN + 93], and <ref> [MS91] </ref>. In reference listing, principals keep a list of the processes that have references to them. This is similar to what our algorithm does. When a reference is transmitted, the owner of the principal has to be notified to update the list for that principal.
Reference: [Ros94] <author> Guido Van Rossum. </author> <title> Python Reference Manual. </title> <type> Technical report, </type> <institution> CWI, </institution> <address> Amsterdam, </address> <month> October </month> <year> 1994. </year> <note> Available from http://www.cwi.nl/ guido/Python.html. </note>
Reference-contexts: Finally, we explain how the distributed algorithm finds inter-process garbage. Even though the implementation of the algorithm in the Renaissance system was done in C++, the language used in this paper to illustrate the algorithm is Python <ref> [Ros94] </ref>. 2.1 Process Data Structures The algorithm needs the following data structures. For each process p there is the set p.principals of all local objects that are currently exported by p. Also for each process p there is the set p.proxies of all proxies that exist in this process.
Reference: [SDP92] <author> Marc Shapiro, Peter Dickman, and David Plainfosse. </author> <title> Robust, distributed references and acyclic garbage collection. </title> <booktitle> In Symposium on Principles of Distributed Computing, </booktitle> <pages> pages 135-146, </pages> <address> Vancouver (Canada), </address> <month> August </month> <year> 1992. </year> <note> ACM. </note>
Reference-contexts: Other algorithms are scalable and deal with process crashing and lost and duplicated messages, but are not cyclic. The algorithm we propose here is an extension of reference listing algorithms such as [BEN + 93], and <ref> [SDP92] </ref>. These algorithms are already scalable and tolerant to lost and duplicated messages, but can not collect cyclic data. The algorithm we describe uses reference listing plus additional mechanisms that allow the collection of garbage cycles without the need of global synchronization. <p> Notice that if a process crashes helding a reference to an object, the object is never deleted. Also this algorithm is not tolerant to message lost and duplication. Reference listing is a variation of reference counting that is tolerant to failures <ref> [SDP92] </ref>, [BEN + 93], and [MS91]. In reference listing, principals keep a list of the processes that have references to them. This is similar to what our algorithm does. When a reference is transmitted, the owner of the principal has to be notified to update the list for that principal.
Reference: [Wil92] <author> Paul R. Wilson. </author> <title> Uniprocessor garbage collection techniques. </title> <editor> In Yves Bekkers and Jacques Cohen, editors, </editor> <booktitle> International Workshop on Memory Management, number 637 in Lecture Notes in Computer Science, </booktitle> <pages> pages 1-42, </pages> <address> St. Malo, France, </address> <month> September </month> <year> 1992. </year> <note> Springer-Verlag. </note>
Reference-contexts: For a thorough survey of local garbage collection techniques, we invite the reader to refer to <ref> [Wil92] </ref>. As we have explained before, there are a lot of algorithms for distributed garbage collection that have very different characteristics. We categorize them in three basic techniques: Reference Counting, Tracing, and Hybrid.
Reference: [WW87] <author> P. Watson and I. Watson. </author> <title> An Efficient Garbage Collection Scheme for Parallel Computer Architecture. </title> <editor> In de Bakker et al. </editor> <booktitle> [dBNT87], </booktitle> <pages> pages 432 - 443. </pages>
Reference-contexts: Some of these algorithms pass references in a single message. However, they are unable to collect objects after a process that was helding references to them has crashed. Weighted reference counting is one of these algorithms [Bev87], <ref> [WW87] </ref>. In weighted reference counting each reference has an associated integer weight. When a process passes a copy of the reference, part of this weight goes with the copy. When a reference is deleted, the owner of the object is informed and it subtracts this value from the original weight.
References-found: 16

