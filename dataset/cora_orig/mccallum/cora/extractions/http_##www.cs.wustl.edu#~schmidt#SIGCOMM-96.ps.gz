URL: http://www.cs.wustl.edu/~schmidt/SIGCOMM-96.ps.gz
Refering-URL: http://www.cs.wustl.edu/~schmidt/corba-research-overview.html
Root-URL: 
Email: gokhale@cs.wustl.edu and schmidt@cs.wustl.edu  
Title: Measuring the Performance of Communication Middleware on High-Speed Networks  
Author: Aniruddha Gokhale and Douglas C. Schmidt 
Keyword: Communication middleware, distributed object computing, CORBA, high-speed networks.  
Address: St. Louis, MO 63130, USA  
Affiliation: Department of Computer Science, Washington University  
Abstract: An earlier version of this paper appeared in the Proceedings of the SIGCOMM Conference, 1996, Stanford University, August, 1996. Abstract Conventional implementations of communication middle-ware (such as CORBA and traditional RPC toolkits) incur considerable overhead when used for performance-sensitive applications over high-speed networks. As gigabit networks become pervasive, inefficient middleware will force programmers to use lower-level mechanisms to achieve the necessary transfer rates. This is a serious problem for mission/life-critical applications (such as satellite surveillance and medical imaging). This paper compares the performance of several widely used communication middleware mechanisms on a high-speed ATM network. The middleware ranged from lower-level mechanisms (such as socket-based C interfaces and C++ wrappers for sockets) to higher-level mechanisms (such as RPC, hand-optimized RPC and two implementations of CORBA - Orbix 2.0.1 and ORBeline 2.0). These measurements reveal that the lower-level C and C++ implementations outperform the CORBA implementations significantly (the best CORBA throughput for remote transfer was roughly 75 to 80 percent of the best C/C++ throughput for sending scalar data types and only around 33 percent for sending structs containing binary fields), and the hand-optimized RPC code performs slightly better than the CORBA implementations. Our goal in precisely pinpointing the sources of overhead for communication middleware is to develop scalable and flexible CORBA implementations that can deliver gigabit data rates to applications. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. Abbott and L. Peterson. </author> <title> Increasing Network Throughput by Integrating Protocol Layers. </title> <journal> ACM Transactions on Networking, </journal> <volume> 1(5), </volume> <month> October </month> <year> 1993. </year>
Reference-contexts: A remedy for this problem is to use Application Level Framing (ALF) [5, 4, 8] and Integrated Layer Processing (ILP) <ref> [5, 1, 20] </ref>. ALF ensures that lower layer protocols deal with data in units specified by the application.
Reference: [2] <author> Kenneth Birman and Robbert van Renesse. </author> <title> RPC Considered Inadequate. </title> <booktitle> In Reliable Distributed Computing with the Isis Toolkit, </booktitle> <pages> pages 68-78. </pages> <publisher> IEEE Computer Society Press, Los Alamitos, </publisher> <year> 1994. </year>
Reference-contexts: In general, existing implementations of CORBA have not been optimized since performance has not been a problem on low-speed networks. It is beyond the scope of this paper to discuss limitations with CORBA features (see <ref> [2] </ref> for a synopsis). 3 Experimental Results of CORBA over ATM This section describes our CORBA/ATM testbed and presents the results of our performance experiments. 3.1 CORBA/ATM Testbed Environment 3.1.1 Hardware and Software Platforms The experiments in this section were collected using a Bay Networks LattisCell 10114 ATM switch connected to
Reference: [3] <author> G.J Blaine, M.E. Boyd, and S.M. Crider. </author> <title> Project Spectrum: Scalable Bandwidth for the BJC Health System. </title> <journal> HIMSS, Health Care Communications, </journal> <pages> pages 71-81, </pages> <year> 1994. </year>
Reference-contexts: The use of low-level mechanisms increases development effort and reduces system reliability, flexibility, and reuse. This is a serious problem for mission/life-critical applications (such as satellite surveillance and medical imaging <ref> [3, 7] </ref>). Therefore, it is imperative that performance of high-level, but inefficient, communication middleware be improved to match that of low-level, but efficient, tools. <p> The use of typed data is representative of applications like electronic medical imaging <ref> [7, 3] </ref> and high-speed distributed databases (such as global change repositories [17]). In addition, measuring typed data transfer reveals the overhead of presentation layer conversions and data copying for the various communication middleware mechanisms we measured.
Reference: [4] <author> Isabelle Chrisment. </author> <title> Impact of ALF on Communication Subsystems Design and Performance. </title> <booktitle> In First International Workshop on High Performance Protocol Architectures, HIP-PARCH '94, </booktitle> <institution> Sophia Antipolis, France, </institution> <month> December </month> <year> 1994. </year> <institution> IN-RIA France. </institution>
Reference-contexts: A remedy for this problem is to use Application Level Framing (ALF) <ref> [5, 4, 8] </ref> and Integrated Layer Processing (ILP) [5, 1, 20]. ALF ensures that lower layer protocols deal with data in units specified by the application.
Reference: [5] <author> David D. Clark and David L. Tennenhouse. </author> <title> Architectural Considerations for a New Generation of Protocols. </title> <booktitle> In Proceedings of the Symposium on Communications Architectures and Protocols (SIGCOMM), </booktitle> <pages> pages 200-208, </pages> <address> Philadelphia, PA, </address> <month> September </month> <year> 1990. </year> <note> ACM. </note>
Reference-contexts: As discussed in Section 3.2.2, this overhead arises from the amount of time the CORBA implementations spend performing presentation layer conversions and data copying. 4.2 Presentation Layer and Data Copying The presentation layer is a major bottleneck in high-performance communication subsystems <ref> [5] </ref>. This layer transforms typed data objects from higher-level representations to lower-level representations (marshalling) and vice versa (demarshalling). In both RPC toolkits and CORBA, this transformation process is performed by client-side stubs and server-side skeletons that are generated by interface definition language (IDL) compilers. <p> A remedy for this problem is to use Application Level Framing (ALF) <ref> [5, 4, 8] </ref> and Integrated Layer Processing (ILP) [5, 1, 20]. ALF ensures that lower layer protocols deal with data in units specified by the application. <p> A remedy for this problem is to use Application Level Framing (ALF) [5, 4, 8] and Integrated Layer Processing (ILP) <ref> [5, 1, 20] </ref>. ALF ensures that lower layer protocols deal with data in units specified by the application.
Reference: [6] <author> Sudheer Dharnikota, Kurt Maly, and C. M. Overstreet. </author> <title> Performance Evaluation of TCP(UDP)/IP over ATM networks. </title> <institution> Department of Computer Science, </institution> <type> Technical Report CSTR 94 23, </type> <institution> Old Dominion University, </institution> <month> September </month> <year> 1994. </year>
Reference-contexts: However, the CORBA and RPC implementations do not omit the overhead of the no-op function calls, which has a non-trivial overhead 3 (shown in Section 3.2.2). 3.1.3 TTCP Parameter Settings Existing studies <ref> [7, 11, 6, 23, 18] </ref> of transport protocol performance over ATM demonstrate the impact of parameters such as socket queue sizes and data buffer on performance. <p> particular, less attention has been paid to integrating the 11 Version Iterations 1 100 500 1,000 Orbix 9.25 28.52 12.11 10.45 Table 10: Percentage Improvement in Client-Side Latency for Sending 100 Requests per Iteration using Oneway Methods following topics related to communication middleware: 4.1 Transport Protocol Performance over ATM Networks <ref> [7, 11, 6] </ref> present results on performance of TCP/IP (and UDP/IP [6]) on ATM networks by varying a number of parameters (such as TCP window size, socket queue size, and user data size). <p> Iterations 1 100 500 1,000 Orbix 9.25 28.52 12.11 10.45 Table 10: Percentage Improvement in Client-Side Latency for Sending 100 Requests per Iteration using Oneway Methods following topics related to communication middleware: 4.1 Transport Protocol Performance over ATM Networks [7, 11, 6] present results on performance of TCP/IP (and UDP/IP <ref> [6] </ref>) on ATM networks by varying a number of parameters (such as TCP window size, socket queue size, and user data size). <p> This work indicates that in addition to the host architecture and host network interface, parameters configurable in software (like TCP window size, socket queue size and user data size) significantly affect TCP throughput. <ref> [6] </ref> also shows that UDP performs better than TCP over ATM networks, which is attributed to redundant TCP processing overhead on highly-reliable ATM links.
Reference: [7] <author> Minh DoVan, Louis Humphrey, Geri Cox, and Carl Ravin. </author> <title> Initial Experience with Asynchronous Transfer Mode for Use in a Medical Imaging Network. </title> <journal> Journal of Digital Imaging, </journal> <volume> 8(1) </volume> <pages> 43-48, </pages> <month> February </month> <year> 1995. </year>
Reference-contexts: The use of low-level mechanisms increases development effort and reduces system reliability, flexibility, and reuse. This is a serious problem for mission/life-critical applications (such as satellite surveillance and medical imaging <ref> [3, 7] </ref>). Therefore, it is imperative that performance of high-level, but inefficient, communication middleware be improved to match that of low-level, but efficient, tools. <p> The use of typed data is representative of applications like electronic medical imaging <ref> [7, 3] </ref> and high-speed distributed databases (such as global change repositories [17]). In addition, measuring typed data transfer reveals the overhead of presentation layer conversions and data copying for the various communication middleware mechanisms we measured. <p> However, the CORBA and RPC implementations do not omit the overhead of the no-op function calls, which has a non-trivial overhead 3 (shown in Section 3.2.2). 3.1.3 TTCP Parameter Settings Existing studies <ref> [7, 11, 6, 23, 18] </ref> of transport protocol performance over ATM demonstrate the impact of parameters such as socket queue sizes and data buffer on performance. <p> particular, less attention has been paid to integrating the 11 Version Iterations 1 100 500 1,000 Orbix 9.25 28.52 12.11 10.45 Table 10: Percentage Improvement in Client-Side Latency for Sending 100 Requests per Iteration using Oneway Methods following topics related to communication middleware: 4.1 Transport Protocol Performance over ATM Networks <ref> [7, 11, 6] </ref> present results on performance of TCP/IP (and UDP/IP [6]) on ATM networks by varying a number of parameters (such as TCP window size, socket queue size, and user data size).
Reference: [8] <author> Atanu Ghosh, Jon Crowcroft, Michael Fry, and Mark Hand-ley. </author> <title> Integrated Layer Video Decoding and Application Layer Framed Secure Login: General Lessons from Two or Three Very Different Applications. </title> <booktitle> In First International Workshop on High Performance Protocol Architectures, HIPPARCH '94, </booktitle> <institution> Sophia Antipolis, France, </institution> <month> December </month> <year> 1994. </year> <institution> INRIA France. </institution>
Reference-contexts: A remedy for this problem is to use Application Level Framing (ALF) <ref> [5, 4, 8] </ref> and Integrated Layer Processing (ILP) [5, 1, 20]. ALF ensures that lower layer protocols deal with data in units specified by the application.
Reference: [9] <author> Aniruddha Gokhale, Tim Harrison, Douglas C. Schmidt, and Guru Parulkar. </author> <title> Operating System Support for High Performance, Real-time CORBA. </title> <booktitle> In Proceedings of the 5 th International Workshop on Object-Orientation in Operating Systems, </booktitle> <month> October </month> <year> 1996. </year>
Reference-contexts: Our goal in precisely pinpointing the sources of 1 Computing Model overhead for communication middleware is to develop scalable and flexible CORBA implementations that can deliver gigabit data rates to applications <ref> [9] </ref>.
Reference: [10] <author> Phillip Hoschka and Christian Huitema. </author> <title> Automatic Generation of Optimized Code for Marshalling Routines. </title> <booktitle> In IFIP Conference of Upper Layer Protocols, Architectures and Applications ULPAA'94, Barcelona, Spain, 1994. IFIP. </booktitle> <pages> 13 </pages>
Reference-contexts: The USC stub compiler supports the automatic generation of device and protocol header marshalling code. The USC tool generates optimized C code that automatically aligns data structures and performs network/host byte order conversions. * Generating code based on Control Flow Analysis of interface specification: <ref> [10] </ref> describes a technique of exploiting application-specific knowledge contained in the type specifications of an application to generate optimized marshalling code. This work tries to achieve an optimal tradeoff between interpreted code (which is slow but compact in size) and compiled code (which is fast but larger in size).
Reference: [11] <author> K. Modeklev, E. Klovning, and O. Kure. </author> <title> TCP/IP Behavior in a High-Speed Local ATM Network Environment. </title> <booktitle> In Proceed ings of the 19 th Conference on Local Computer Networks, </booktitle> <pages> pages 176-185, </pages> <address> Minneapolis, MN, </address> <month> October </month> <year> 1994. </year> <note> IEEE. </note>
Reference-contexts: However, the CORBA and RPC implementations do not omit the overhead of the no-op function calls, which has a non-trivial overhead 3 (shown in Section 3.2.2). 3.1.3 TTCP Parameter Settings Existing studies <ref> [7, 11, 6, 23, 18] </ref> of transport protocol performance over ATM demonstrate the impact of parameters such as socket queue sizes and data buffer on performance. <p> These parameters influence the size of the TCP segment window, which has been shown to significantly impact CORBA-level and TCP-level performance on high-speed networks <ref> [11, 23] </ref>. <p> particular, less attention has been paid to integrating the 11 Version Iterations 1 100 500 1,000 Orbix 9.25 28.52 12.11 10.45 Table 10: Percentage Improvement in Client-Side Latency for Sending 100 Requests per Iteration using Oneway Methods following topics related to communication middleware: 4.1 Transport Protocol Performance over ATM Networks <ref> [7, 11, 6] </ref> present results on performance of TCP/IP (and UDP/IP [6]) on ATM networks by varying a number of parameters (such as TCP window size, socket queue size, and user data size).
Reference: [12] <institution> Object Management Group. </institution> <month> CORBAServices: </month> <title> Common Object Services Specification, </title> <note> Revised Edition, 95-3-31 edition, </note> <month> March </month> <year> 1995. </year>
Reference-contexts: Object adapters can be specialized to provide support for certain object implementation styles (such as OODB object adapters for persistence and library object adapters for non-remote objects). * Higher-level Object Services (not shown): These services include the CORBA Object Services <ref> [12] </ref> such as the Name service, Event service, Object Lifecycle service, and the Trader service. There is currently no explicit support for real-time guarantees in the CORBA 2.0 specification, although there is a domain-specific Task Force in the OMG that is focusing on specifying real-time CORBA.
Reference: [13] <author> Object Management Group. </author> <title> The Common Object Request Broker: Architecture and Specification, </title> <address> 2.0 edition, </address> <month> July </month> <year> 1995. </year>
Reference-contexts: Substantial time and effort has traditionally been required to develop this type of software; yet all too frequently communication software fails to achieve its performance and functionality requirements. Communication middleware based on the Common Object Request Broker Architecture (CORBA) <ref> [13] </ref> is a promising approach for improving the flexibility, reliability, and portability of communication software. CORBA is designed to enhance distributed applications by automating common networking tasks such as object registration, location, and activation; request demultiplexing; framing and error-handling; parameter marshalling and demarshalling; and operation dispatching. <p> is organized as follows: Section 2 outlines the CORBA communication middleware architecture; Section 3 demonstrates the key sources of overhead in conventional CORBA implementations over ATM; Section 4 describes related work; and Section 5 presents concluding remarks. 2 Overview of CORBA CORBA is an open standard for distributed object computing <ref> [13] </ref>. The CORBA standard defines a set of components that allow client applications to invoke operations (op) with arguments (args) on object implementations. Flexibility is enhanced by using CORBA since the object implementations can be configured to run locally and/or remotely without affecting their implementation or use. <p> In both RPC toolkits and CORBA, this transformation process is performed by client-side stubs and server-side skeletons that are generated by interface definition language (IDL) compilers. IDL compilers translate interfaces written in an IDL (such as Sun RPC XDR [24], DCE NDR, or CORBA CDR <ref> [13] </ref>) to other forms such as a network wire format. A significant amount of research has been devoted to developing efficient stub generators.
Reference: [14] <author> Sean W. O'Malley, Todd A. Proebsting, and Allen B. Montz. </author> <title> USC: A Universal Stub Compiler. </title> <booktitle> In Proceedings of the Symposium on Communications Architecturesand Protocols (SIG-COMM), </booktitle> <address> London, UK, </address> <month> August </month> <year> 1994. </year>
Reference-contexts: A significant amount of research has been devoted to developing efficient stub generators. We cite a few of these and classify them as below. * Annotating high level programming languages: The Universal Stub Compiler (USC) <ref> [14] </ref> annotates the C programming language with layouts of various data types. The USC stub compiler supports the automatic generation of device and protocol header marshalling code.
Reference: [15] <author> Graham Parrington. </author> <title> A Stub Generation System for C++. </title> <journal> Computing Systems, </journal> <volume> 8(2) </volume> <pages> 135-170, </pages> <month> Spring </month> <year> 1995. </year>
Reference-contexts: The runtime usage of a given data type or method can be used to dynamically link in either the compiled or the interpreted version. Dynamic linking has been shown to be useful for mid-stream adaptation of protocol implementations [20]. * Using high level programming languages for distributed applications: <ref> [15] </ref> describes a stub compiler for the C++ language. This stub compiler does not need an auxiliary interface definition language. Instead, it uses the operator overloading feature of C++ to enable parameter marshalling. This approach enables distributed applications to be constructed in a straightforward manner.
Reference: [16] <author> Guru Parulkar, Douglas C. Schmidt, and Jonathan S. Turner. </author> <title> a I t P m: a Strategy for Integrating IP with ATM. </title> <booktitle> In Proceedings of the Symposium on Communications Architectures and Protocols (SIGCOMM). ACM, </booktitle> <month> September </month> <year> 1995. </year>
Reference-contexts: The user-level memory-to-memory bandwidth of our SPARCstation 20 model 712s was measured at 1.4 Gbps, which is roughly comparable to an OC24 gigabit ATM network <ref> [16] </ref>. 3.1.2 Traffic Generators Earlier studies [23, 18] tested the performance of flooding models that transferred untyped bytestream data between hosts using several implementations of CORBA and other lower-level mechanisms like sockets. Untyped bytestream traffic is representative of applications like bulk file transfer and videoconferencing.
Reference: [17] <author> Joseph C. Pasquale, Eric W. Anderson, Kevin R. Fall, and Jonathan S. Kay. </author> <title> High-performance I/O and Networking Software in Sequoia 2000. </title> <journal> Digital Technical Journal, </journal> <volume> 7(3), </volume> <year> 1995. </year>
Reference-contexts: The use of typed data is representative of applications like electronic medical imaging [7, 3] and high-speed distributed databases (such as global change repositories <ref> [17] </ref>). In addition, measuring typed data transfer reveals the overhead of presentation layer conversions and data copying for the various communication middleware mechanisms we measured. Traffic for the experiments was generated and consumed by an extended version of the widely available TTCP protocol benchmarking tool.
Reference: [18] <author> Irfan Pyarali, Timothy H. Harrison, and Douglas C. Schmidt. </author> <title> Design and Performance of an Object-Oriented Framework for High-Performance Electronic Medical Imaging. </title> <booktitle> In Proceedings of the 2 nd Conference on Object-Oriented Technologies and Systems, </booktitle> <address> Toronto, Canada, June 1996. </address> <publisher> USENIX. </publisher>
Reference-contexts: Experience over the past several years [19] indicates CORBA is well-suited for request/response applications over lower-speed networks (such as Ethernet and Token Ring). However, earlier studies <ref> [18, 23] </ref>, and our results shown in Section 3, demonstrate that conventional implementations of CORBA incur considerable overhead when used for performance-sensitive applications over high-speed networks. <p> The user-level memory-to-memory bandwidth of our SPARCstation 20 model 712s was measured at 1.4 Gbps, which is roughly comparable to an OC24 gigabit ATM network [16]. 3.1.2 Traffic Generators Earlier studies <ref> [23, 18] </ref> tested the performance of flooding models that transferred untyped bytestream data between hosts using several implementations of CORBA and other lower-level mechanisms like sockets. Untyped bytestream traffic is representative of applications like bulk file transfer and videoconferencing. <p> However, the CORBA and RPC implementations do not omit the overhead of the no-op function calls, which has a non-trivial overhead 3 (shown in Section 3.2.2). 3.1.3 TTCP Parameter Settings Existing studies <ref> [7, 11, 6, 23, 18] </ref> of transport protocol performance over ATM demonstrate the impact of parameters such as socket queue sizes and data buffer on performance.
Reference: [19] <author> Sanjay Radia, Graham Hamilton, Peter Kessler, and Michael Powell. </author> <title> The Spring Object Model. </title> <booktitle> In Proceedings of the Conference on Object-Oriented Technologies, </booktitle> <address> Monterey, CA, June 1995. </address> <publisher> USENIX. </publisher>
Reference-contexts: CORBA is designed to enhance distributed applications by automating common networking tasks such as object registration, location, and activation; request demultiplexing; framing and error-handling; parameter marshalling and demarshalling; and operation dispatching. Experience over the past several years <ref> [19] </ref> indicates CORBA is well-suited for request/response applications over lower-speed networks (such as Ethernet and Token Ring). However, earlier studies [18, 23], and our results shown in Section 3, demonstrate that conventional implementations of CORBA incur considerable overhead when used for performance-sensitive applications over high-speed networks.
Reference: [20] <author> Antony Richards, Ranil De Silva, Anne Fladenmuller, Aruna Seneviratne, and Michael Fry. </author> <title> The Application of ILP/ALF to Configurable Protocols. </title> <booktitle> In First International Workshop on High Performance Protocol Architectures, HIPPARCH '94, </booktitle> <institution> Sophia Antipolis, France, </institution> <month> December </month> <year> 1994. </year> <institution> INRIA France. </institution>
Reference-contexts: The runtime usage of a given data type or method can be used to dynamically link in either the compiled or the interpreted version. Dynamic linking has been shown to be useful for mid-stream adaptation of protocol implementations <ref> [20] </ref>. * Using high level programming languages for distributed applications: [15] describes a stub compiler for the C++ language. This stub compiler does not need an auxiliary interface definition language. Instead, it uses the operator overloading feature of C++ to enable parameter marshalling. <p> A remedy for this problem is to use Application Level Framing (ALF) [5, 4, 8] and Integrated Layer Processing (ILP) <ref> [5, 1, 20] </ref>. ALF ensures that lower layer protocols deal with data in units specified by the application.
Reference: [21] <author> Dennis Ritchie. </author> <title> A Stream Input-Output System. </title> <journal> AT&T Bell Labs Technical Journal, </journal> <volume> 63(8) </volume> <pages> 311-324, </pages> <month> October </month> <year> 1984. </year>
Reference-contexts: The LattisCell 10114 is a 16 Port, OC3 155 Mbs/port switch. Each SPARCstation 20 contains two 70 MHz Super SPARC CPUs with a 1 Megabyte cache per-CPU. The SunOS 5.4 TCP/IP protocol stack is implemented using the STREAMS communication framework <ref> [21] </ref>. Each SPARC-station has 128 Mbytes of RAM and an ENI-155s-MF ATM adaptor card, which supports 155 Megabits per-sec (Mbps) SONET multimode fiber. The Maximum Transmission Unit (MTU) on the ENI ATM adaptor is 9,180 bytes. Each ENI card has 512 Kbytes of on-board memory.
Reference: [22] <author> Douglas C. Schmidt. </author> <title> ACE: an Object-Oriented Framework for Developing Distributed Applications. </title> <booktitle> In Proceedings of the 6 th USENIX C++ Technical Conference, </booktitle> <address> Cambridge, Mas-sachusetts, </address> <month> April </month> <year> 1994. </year> <institution> USENIX Association. </institution>
Reference-contexts: The experiments conducted for this paper extend our earlier studies [23] by measuring the performance of sockets, ACE C++ wrappers for sockets <ref> [22] </ref>, standard- and hand-optimized version of Sun's Transport Independent RPC (TI-RPC) [25], and two widely used implementations of CORBA (Orbix 2.0 and ORBeline 2.0) to transfer both bytestream and typed data between remote hosts over a high-speed ATM network. <p> We plan to enhance previously described ideas and propose newer schemes for efficient object-to-object communication. The source code for the various tests performed in this paper is available through the ACE <ref> [22] </ref> software distribution at http://www.cs.wustl.edu/~schmidt. Acknowledgments We would like to thank the anonymous reviewers and also Bill Janssen, Karl McCabe and Alan Ewald for their suggestions in improving the paper.
Reference: [23] <author> Douglas C. Schmidt, Timothy H. Harrison, and Ehab Al-Shaer. </author> <title> Object-Oriented Components for High-speed Network Programming. </title> <booktitle> In Proceedings of the 1 st Conference on Object-Oriented Technologies and Systems, </booktitle> <address> Monterey, CA, June 1995. </address> <publisher> USENIX. </publisher>
Reference-contexts: Experience over the past several years [19] indicates CORBA is well-suited for request/response applications over lower-speed networks (such as Ethernet and Token Ring). However, earlier studies <ref> [18, 23] </ref>, and our results shown in Section 3, demonstrate that conventional implementations of CORBA incur considerable overhead when used for performance-sensitive applications over high-speed networks. <p> The user-level memory-to-memory bandwidth of our SPARCstation 20 model 712s was measured at 1.4 Gbps, which is roughly comparable to an OC24 gigabit ATM network [16]. 3.1.2 Traffic Generators Earlier studies <ref> [23, 18] </ref> tested the performance of flooding models that transferred untyped bytestream data between hosts using several implementations of CORBA and other lower-level mechanisms like sockets. Untyped bytestream traffic is representative of applications like bulk file transfer and videoconferencing. <p> Note, however, that bytestream traffic does not adequately test the overhead of presentation layer conversions since untyped data need not be marshalled or demarshalled. Ironically, the implementations of CORBA used in our tests perform marshalling and demarshalling even for untyped octet data <ref> [23] </ref>, which is further evidence that CORBA implementations have not been optimized for high-speed networks. The experiments conducted for this paper extend our earlier studies [23] by measuring the performance of sockets, ACE C++ wrappers for sockets [22], standard- and hand-optimized version of Sun's Transport Independent RPC (TI-RPC) [25], and two <p> Ironically, the implementations of CORBA used in our tests perform marshalling and demarshalling even for untyped octet data <ref> [23] </ref>, which is further evidence that CORBA implementations have not been optimized for high-speed networks. The experiments conducted for this paper extend our earlier studies [23] by measuring the performance of sockets, ACE C++ wrappers for sockets [22], standard- and hand-optimized version of Sun's Transport Independent RPC (TI-RPC) [25], and two widely used implementations of CORBA (Orbix 2.0 and ORBeline 2.0) to transfer both bytestream and typed data between remote hosts over a high-speed ATM network. <p> However, the CORBA and RPC implementations do not omit the overhead of the no-op function calls, which has a non-trivial overhead 3 (shown in Section 3.2.2). 3.1.3 TTCP Parameter Settings Existing studies <ref> [7, 11, 6, 23, 18] </ref> of transport protocol performance over ATM demonstrate the impact of parameters such as socket queue sizes and data buffer on performance. <p> These parameters influence the size of the TCP segment window, which has been shown to significantly impact CORBA-level and TCP-level performance on high-speed networks <ref> [11, 23] </ref>. <p> A comparison of our current results for typed data with other work using untyped data in a similar CORBA/ATM testbed <ref> [23] </ref> reveal that the low-level C socket version and the C++ socket wrapper versions of TTCP are roughly equivalent for a given socket queue size. Likewise, the performance of Orbix for sequences of scalar data types is almost the same as that reported for untyped data sequences.
Reference: [24] <author> Sun Microsystems. XDR: </author> <title> External Data Representation Standard. Network Information Center RFC 1014, </title> <month> June </month> <year> 1987. </year>
Reference-contexts: In both RPC toolkits and CORBA, this transformation process is performed by client-side stubs and server-side skeletons that are generated by interface definition language (IDL) compilers. IDL compilers translate interfaces written in an IDL (such as Sun RPC XDR <ref> [24] </ref>, DCE NDR, or CORBA CDR [13]) to other forms such as a network wire format. A significant amount of research has been devoted to developing efficient stub generators.
Reference: [25] <author> Sun Microsystems. </author> <title> Open Network Computing: Transport Independent RPC, </title> <month> June </month> <year> 1995. </year>
Reference-contexts: The experiments conducted for this paper extend our earlier studies [23] by measuring the performance of sockets, ACE C++ wrappers for sockets [22], standard- and hand-optimized version of Sun's Transport Independent RPC (TI-RPC) <ref> [25] </ref>, and two widely used implementations of CORBA (Orbix 2.0 and ORBeline 2.0) to transfer both bytestream and typed data between remote hosts over a high-speed ATM network.
References-found: 25

