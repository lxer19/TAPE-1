URL: http://www.cs.rutgers.edu/~krasheed/sm.ps
Refering-URL: http://athos.rutgers.edu/~shehata/papers.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: krasheed,hirsh@cs.rutgers.edu  
Phone: 445-2001, FAX -5691  
Title: Learning to be Selective in Genetic-Algorithm-Based Design Optimization  
Author: Khaled Rasheed Haym Hirsh 
Address: New Jersey New Brunswick, NJ 08903, USA Phone:(732)  
Affiliation: Department of Computer Science Rutgers, The State University of  
Abstract-found: 0
Intro-found: 1
Reference: [ Gelsey et al. 1996 ] <author> Andrew Gelsey, M. Schwabacher, and Don Smith. </author> <title> Using modeling knowledge to guide design space search. </title> <booktitle> In Fourth International Conference on Artificial Intelligence in Design '96, </booktitle> <year> 1996. </year>
Reference-contexts: Learning to be Selective in GA-based Design Optimization 6 3.1 Application domain 1: Supersonic transport aircraft design domain 3.1.1 Domain description Our first domain concerns the conceptual design of supersonic transport aircraft. We summarize it briefly here; it is described in more detail elsewhere <ref> [ Gelsey et al. 1996 ] </ref> . Figure 1 shows a diagram of a typical airplane automatically designed by our software system.
Reference: [ Glover 1989 ] <author> F. Glover. </author> <title> Tabu Search-Part I. </title> <journal> ORSA Journal on Computing, </journal> <volume> 1(3) </volume> <pages> 190-206, </pages> <year> 1989. </year>
Reference-contexts: Several research efforts outside the GA field also focused on the idea of using search history to guide future exploration. The examples include: * Tabu search <ref> [ Glover 1989, Glover 1990 ] </ref> is a search method similar to simulated annealing in the sense that it is a path following method that may allow movements to an inferior state in an effort to avoid being trapped in local optima.
Reference: [ Glover 1990 ] <author> F. Glover. </author> <title> Tabu Search-Part II. </title> <journal> ORSA Journal on Computing, </journal> <volume> 2(1) </volume> <pages> 4-32, </pages> <year> 1990. </year> <note> Learning to be Selective in GA-based Design Optimization 31 </note>
Reference-contexts: Several research efforts outside the GA field also focused on the idea of using search history to guide future exploration. The examples include: * Tabu search <ref> [ Glover 1989, Glover 1990 ] </ref> is a search method similar to simulated annealing in the sense that it is a path following method that may allow movements to an inferior state in an effort to avoid being trapped in local optima.
Reference: [ Goldberg 1989 ] <author> David E. Goldberg. </author> <title> Genetic Algorithms in Search, Optimization, and Machine Learning. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Mass., </address> <year> 1989. </year>
Reference-contexts: 1 Introduction Genetic Algorithms (GAs) <ref> [ Goldberg 1989 ] </ref> are search algorithms that simulate the process of natural selection. <p> The blank regions of the curve are unevaluable points. The figure illustrates the "slab-shaped" evaluable region in this three dimensional subspace. The figure shows how difficult it is for traditional GAs to do optimizations in this domain | for example, the classical point-crossover operation <ref> [ Goldberg 1989 ] </ref> may well use two evaluable parents and produce unevaluable children. In summary, the problem has 12 parameters and 37 inequality constraints. 0.6% of the search space is evaluable. No statistics exist regarding the fraction of the search space that is feasible because it is extremely small. <p> At a higher level, it is not clear that the K-nearest neighbor approach is the best approach for screening. We plan on investigating the use of a classifier system <ref> [ Goldberg 1989 ] </ref> which screens potential points by classifying them as promising or unpromising. We also plan to explore the use of more sophisticated machine-learning techniques to extrapolate from past evaluations as part of the screening module.
Reference: [ Haas et al. 1992 ] <author> M. Haas, R. Elmquist, and D. Sobel. </author> <title> NAWC Inlet Design and Analysis (NIDA) Code, </title> <note> Final Report. UTRC Report R92-970037-1, </note> <year> 1992. </year>
Reference-contexts: The missile inlet is axisymmetric and the coordinates are given in terms of axial (x) and radial (r) positions. The simulator used in this domain is a program called "NIDA" which was developed at United Technology Research Center (UTRC) as an inlet analysis/design tool <ref> [ Haas et al. 1992 ] </ref> .
Reference: [ Laird et al. 1986 ] <author> J. E. Laird, P. S. Rosenbloom, and A. Newell. </author> <title> Chunking in Soar: The anatomy of a general learning mechanism. </title> <journal> Machine Learning, </journal> <volume> 1(11), </volume> <year> 1986. </year>
Reference-contexts: Soar <ref> [ Laird et al. 1986 ] </ref> is a general problem-solving architecture that uses EBL to form rules that summarize the problem-solving conducted in a problem space so that the same results can be reproduced in a single step in similar situations, both within a single problem-solving task, as well as on
Reference: [ Louis 1997 ] <author> Sushil J. Louis. </author> <title> Working from blueprints: Evolutionary learning for design. </title> <journal> Artificial Intelligence in Engineering, </journal> <volume> 11(3) </volume> <pages> 335-341, </pages> <year> 1997. </year>
Reference-contexts: Also in the field of GA design optimization <ref> [ Louis 1997 ] </ref> presented a method for using information about an entire GA optimization to guide other GA optimizations in similar domains. Several research efforts outside the GA field also focused on the idea of using search history to guide future exploration.
Reference: [ Michalewicz 1996 ] <author> Zbigniew Michalewicz. </author> <title> Genetic Algorithms + Data Structures = Evolution Programs. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1996. </year>
Reference-contexts: GAs have many advantages over other search techniques in complex domains. They tend to avoid being trapped in local sub-optima and can handle different types of optimization variables (discrete, continuous and mixed). A large amount of literature exists about the application of GAs to optimization problems <ref> [ Michalewicz 1996 ] </ref> . This paper investigates some aspects of GA optimization in realistic continuous-variable engineering design domains. In such domains a design is represented by a number of continuous design parameters, so that potential solutions are vectors (points) in a multidimensional vector space.
Reference: [ Minton 1988 ] <author> S. Minton. </author> <title> Learning search control knowledge: An explanation-based approach. </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, MA, </address> <year> 1988. </year>
Reference-contexts: PRODIGY <ref> [ Minton 1988 ] </ref> is a domain independent planning system that uses EBL to form search-control rules that help the PRODIGY planner make correct control decisions in situations that are similar to past decisions, both within a single overall task as well as across tasks. 6 Final Remarks This paper has
Reference: [ Mitchell 1997 ] <author> Tom Mitchell. </author> <title> Machine Learning. </title> <publisher> McGraw-Hill, </publisher> <year> 1997. </year>
Reference-contexts: going back to these states so as not to keep cycling. * Dependency-directed backtracking [ Rich and Knight 1991 ] is a search method similar to depth-first search which uses search history to decide which state to backtrack to in case a search path proved fruitless. * Explanation-based learning (EBL) <ref> [ Mitchell 1997 ] </ref> takes the outcome of a training process (such as a rule, a proof or a decision tree) and transforms it to a more compact (and often more general) form. [ Prieditis and Mostow 1987 ] proposed an adaptive Prolog interpreter called PROLEARN which reduces the time of
Reference: [ Powell and Skolnick 1993 ] <author> D. Powell and M. Skolnick. </author> <title> Using genetic algorithms in engineering design optimization with non-linear constraints. </title> <booktitle> In Proceedings of the Fifth International Conference on Genetic Algorithms, </booktitle> <pages> pages 424-431. </pages> <publisher> Morgan Kaufmann, </publisher> <month> July </month> <year> 1993. </year>
Reference-contexts: Constraints best No. No. inequ. equ. f 1 13 5 4 0 26.78 3 3 5 6 0 -3.06 5 6 6 0 4 8.92 7 21 13 13 0 97.5 after Sandgren's work <ref> [ Powell and Skolnick 1993 ] </ref> . Those problems have now become used in engineering design optimization domains as benchmarks. One of the most recent experiments involving these domains was reported in [ Powell and Skolnick 1993 ] , in which a GA package called OOGA and a numerical optimization package <p> 6 0 -3.06 5 6 6 0 4 8.92 7 21 13 13 0 97.5 after Sandgren's work <ref> [ Powell and Skolnick 1993 ] </ref> . Those problems have now become used in engineering design optimization domains as benchmarks. One of the most recent experiments involving these domains was reported in [ Powell and Skolnick 1993 ] , in which a GA package called OOGA and a numerical optimization package called NumOpt were compared to each other in 10 of Sandgren's domains. The 10 domains were a representative sample of the original 30.
Reference: [ Prieditis and Mostow 1987 ] <author> A. E. Prieditis and J. Mostow. Prolearn: </author> <title> Towards a prolog interpreter that learns. </title> <booktitle> In Proceedings of the Sixth National Conference on Artificial Intelligence, </booktitle> <address> Seattle, WA, 1987. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: decide which state to backtrack to in case a search path proved fruitless. * Explanation-based learning (EBL) [ Mitchell 1997 ] takes the outcome of a training process (such as a rule, a proof or a decision tree) and transforms it to a more compact (and often more general) form. <ref> [ Prieditis and Mostow 1987 ] </ref> proposed an adaptive Prolog interpreter called PROLEARN which reduces the time of executing Prolog queries by using EBL to form generalizations of past proofs that are cached away and used in future problem-solving episodes.
Reference: [ Rasheed et al. 1997 ] <author> Khaled Rasheed, Haym Hirsh, and Andrew Gelsey. </author> <title> A genetic algorithm for continuous design space search. </title> <journal> Artificial Intelligence in Engineering, </journal> <volume> 11(3) </volume> <pages> 295-305, </pages> <address> 1997. </address> <publisher> Elsevier Science Ltd. </publisher>
Reference-contexts: We conducted our investigations in the context of GADO <ref> [ Rasheed 1998, Rasheed et al. 1997 ] </ref> , a highly adaptive GA that was designed with the goal of being suitable for use in engineering design. It uses new operators and search control strategies that target the domains that typically arise in such applications.
Reference: [ Rasheed 1998 ] <author> Khaled Rasheed. GADO: </author> <title> A genetic algorithm for continuous design optimization. </title> <type> Technical Report DCS-TR-352, </type> <institution> Department of Computer Science, Rutgers University, </institution> <address> New Brunswick, NJ, </address> <month> January </month> <year> 1998. </year> <type> Ph.D. Thesis, </type> <note> http://www.cs.rutgers.edu/~krasheed/thesis.ps. Learning to be Selective in GA-based Design Optimization 32 </note>
Reference-contexts: We conducted our investigations in the context of GADO <ref> [ Rasheed 1998, Rasheed et al. 1997 ] </ref> , a highly adaptive GA that was designed with the goal of being suitable for use in engineering design. It uses new operators and search control strategies that target the domains that typically arise in such applications. <p> No statistics exist regarding the fraction of the search space that is feasible because it is extremely small. A detailed description of the experiments showing the superiority of GADO to other optimizers in this domain can be found in <ref> [ Rasheed 1998 ] </ref> . Here our focus is on studying the effect of the screening module on performance. 3.1.2 Experiments and results the average of 15 runs of GADO both with and without the screening module. <p> The sixth column shows the best known optima of the problems. A detailed description of these domains is given in [ Sandgren 1977 ] . A detailed description of the experiments showing the superiority of GADO to other optimizers in these domains can be found in <ref> [ Rasheed 1998 ] </ref> . In this paper we only focus on studying the effect of the screening module on performance. 3 We were unable to do any comparison in 2 of the 10 domains because they had unbounded variables.
Reference: [ Ravise and Sebag 1996 ] <author> Caroline Ravise and Michele Sebag. </author> <title> An advanced evolution should not repeat its past errors. </title> <booktitle> In Thirteenth International Conference on Machine Learning, </booktitle> <year> 1996. </year>
Reference-contexts: The best final performance was achieved with the default value of 2, the default value set prior to the start of all experiments. 5 Related work The idea of using the GA optimization history to guide further explorations was studied in <ref> [ Ravise and Sebag 1996 ] </ref> where inductive learning was used to learn rules describing bad points in a multi-dimension boolean space. The use of rules was appropriate in that research because the evaluation functions were not expensive enough to warrant the use of case-based learning.
Reference: [ Rich and Knight 1991 ] <author> Elaine Rich and Kevin Knight. </author> <booktitle> Artificial Intelligence. </booktitle> <publisher> McGraw-Hill, </publisher> <year> 1991. </year>
Reference-contexts: The search avoids going back to these states so as not to keep cycling. * Dependency-directed backtracking <ref> [ Rich and Knight 1991 ] </ref> is a search method similar to depth-first search which uses search history to decide which state to backtrack to in case a search path proved fruitless. * Explanation-based learning (EBL) [ Mitchell 1997 ] takes the outcome of a training process (such as a rule,
Reference: [ Sandgren 1977 ] <author> E. Sandgren. </author> <title> The utility of nonlinear programming algorithms. </title> <type> Technical report, </type> <institution> Purdue University, </institution> <year> 1977. </year> <type> Ph.D. Thesis. </type>
Reference-contexts: We then compared the two systems in several domains: two new domains from real tasks in aerodynamic design, plus others from an existing set of engineering design benchmarks <ref> [ Sandgren 1977 ] </ref> . Learning to be Selective in GA-based Design Optimization 6 3.1 Application domain 1: Supersonic transport aircraft design domain 3.1.1 Domain description Our first domain concerns the conceptual design of supersonic transport aircraft. <p> In 1977, Eric Sandgren published his Ph.D. thesis by the title "The utility of nonlinear programming algorithms" <ref> [ Sandgren 1977 ] </ref> . He applied 35 nonlinear optimization algorithms to 30 engineering design optimization problems and compared their performance. 2 Sandgren's general conclusion was that no single optimization technique among the ones he tested performed reasonably well in all the test cases. <p> The fourth and fifth columns show the number of inequality and equality constraints respectively. The sixth column shows the best known optima of the problems. A detailed description of these domains is given in <ref> [ Sandgren 1977 ] </ref> . A detailed description of the experiments showing the superiority of GADO to other optimizers in these domains can be found in [ Rasheed 1998 ] .
Reference: [ Wright 1990 ] <author> Alden Wright. </author> <title> Genetic algorithms for real parameter optimization. </title> <booktitle> In The First workshop on the Foundations of Genetic Algorithms and Classifier Systems, </booktitle> <pages> pages 205-218, </pages> <institution> Indiana University, Bloomington, </institution> <address> July 1990. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: For example, when evaluable points form thin slab-like regions that are not parallel to any of the principal axis some crossover operators such as point crossover may not yield satisfactory results <ref> [ Wright 1990 ] </ref> . This paper presents a modification of GAs specifically intended to improve its performance in realistic continuous-variable engineering design domains of this sort. The idea is to accumulate a large enough sample of the points evaluated during the course of the GA optimization.
Reference: [ Zha et al. 1996 ] <author> G.-C. Zha, Don Smith, Mark Schwabacher, Khaled Rasheed, Andrew Gelsey, and Doyle Knight. </author> <title> High performance supersonic missile inlet design using automated optimization. </title> <booktitle> In AIAA Symposium on Multidisciplinary Analysis and Optimization '96, </booktitle> <year> 1996. </year>
Reference-contexts: The figure is qualitatively the same as Figure 3. 3.2 Application domain 2: Supersonic cruise missile inlet domain 3.2.1 Domain description Our second domain concerns the design of inlets for supersonic and hypersonic missiles. We summarize it briefly here; it is described in more detail in <ref> [ Zha et al. 1996 ] </ref> . The missile inlet designed is an axisymmetric mixed compression inlet that cruises at Mach 4 at 60000 feet altitude.
References-found: 19

