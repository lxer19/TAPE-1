URL: http://www.cs.rice.edu/~aron/papers/rice-TR98-318.ps
Refering-URL: http://www.cs.rice.edu:80/~aron/research.html
Root-URL: 
Title: TCP: Improving Startup Dynamics by Adaptive Timers and Congestion Control  
Author: Mohit Aron Peter Druschel 
Affiliation: Department of Computer Science Rice University  
Pubnum: TR98-318  
Abstract: This paper studies the startup dynamics of TCP on both high as well as low bandwidth-delay network paths and proposes a set of enhancements that improve both the latency as well as throughput of relatively short TCP transfers. Numerous studies have shown that the timer and congestion control mechanisms in TCP can have a limiting effect on performance in the startup phase. Based on the results of our study, we propose mechanisms for adapting TCP in order to yield increased performance. First, we propose a framework for the management of timing in TCP. Second, we show how TCP can utilize the proposed timer framework to reduce the overly conservative delay associated with a retransmission timeout. Third, we propose the use of packet pacing in the initial slow-start to improve the performance of relatively short transfers that characterize the web traffic. Finally, we quantify the importance of estimating the initial slow-start threshold in TCP, specially on high bandwidth-delay paths. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. Allman, C. Hayes, H. Kruse, and S. Ostermann. </author> <title> TCP Performance over Satellite Links. </title> <booktitle> In Proceedings of 5th International Conference on Telecommunication Systems, </booktitle> <month> Mar. </month> <year> 1997. </year>
Reference-contexts: The slow-start congestion control mechanism [16] has been found to be slow in filling the network pipe <ref> [21, 12, 1] </ref> and affects the performance of short transfers that typically finish during the initial slow-start. Throughout this paper, the term pipe size is intended to be synonymous with the product of the available bandwidth 2 and the round-trip time observed when there is no queuing at the routers. <p> This topology is similar to the one used in <ref> [1] </ref> to emulate satellite networks and provides a high bandwidth delay path of size 116KB. The links used in this topology, however, do not simulate any bit errors. <p> Many of these limitations have also been observed elsewhere in the literature <ref> [21, 12, 1, 6, 14] </ref>. As we will show, the impact of these problems is particularly significant in networks with large bandwidth-delay products, including high-bandwidth, long-haul networks and satellite networks. <p> During this time, TCP was underutiliz-ing the available capacity in the network. Once the pipe is full, further increase in the congestion window fills up the router buffers until congestion occurs due to buffer overflows. Other researchers <ref> [1] </ref> have also observed that the linear rate of growth of the congestion window can cause decreased performance in satellite networks that typically involve high bandwidth-delay paths. We do not address this problem in this paper, but in Appendix B we suggest some possible approaches that can be used. <p> The propagation delay for the topology in Figure 2 was set to 290ms. As mentioned in Section 2, this topology is similar to the one used in <ref> [1] </ref> for emulating satellite networks. 5.2.1 Satellite Network and D1 in figure 2. The y-axis shows the effective throughput, while the x-axis depicts the simulation time for which the simulation was allowed to run. <p> Brakmo et al [6] have also used the fine-grained system clock to detect lost packets early (while processing a received duplicate ACK) in TCP Vegas. Their method does not however affect the coarse-grained retransmission timeout in TCP. Allman et al <ref> [1] </ref> have shown the limiting effect of slow-start and congestion avoidance schemes in TCP in utilizing the bandwidth over satellite networks. Our proposed scheme for pacing packets in slow-start addresses their former observation. Visweswaraiah et al [25] suggest using rate-based pacing to improve the restart of idle connections.
Reference: [2] <author> M. F. Arlitt and C. L. Williamson. </author> <title> Web Server Workload Characterization: The Search for Invariants. </title> <booktitle> In Proceedings of the ACM SIGMETRICS '96 Conference, </booktitle> <address> Philadelphia, PA, </address> <month> Apr. </month> <year> 1996. </year>
Reference-contexts: Only very large TCP transfers (of sizes greater than 45MB) attained an effective throughput of 70% and shall be able to effectively utilize the high-bandwidth network. Today, the vast majority of TCP traffic over the Internet consists of HTTP transfers that have a mean size of less than 100KB <ref> [2] </ref>. Most of the TCP transfers on the Internet that use the ftp protocol are also less than 10MB.
Reference: [3] <author> H. Balakrishnan, S. Seshan, M. Stemm, and R. H. Katz. </author> <title> Analyzing Stability in Wide-Area Network Performance. </title> <booktitle> In Proceedings of the ACM SIGMETRICS '97 Conference, </booktitle> <year> 1997. </year>
Reference-contexts: Paxson [22] shows that in the absence of the SACK TCP option [20], a significant number of lost packets in the Internet are recovered using the coarse-grained retransmission timeout. The same was confirmed by Balakrishnan et al <ref> [3] </ref>. Our proposed timer framework reduces the unnecessary long delays associated with a retransmission timeout when a coarse-grained clock is used for scheduling events. Brakmo et al [6] have also used the fine-grained system clock to detect lost packets early (while processing a received duplicate ACK) in TCP Vegas.
Reference: [4] <author> D. Borman, R. Braden, and V. Jacobson. </author> <title> RFC 1323: TCP extensions for high performance, </title> <month> May </month> <year> 1992. </year>
Reference-contexts: 1 Introduction As new network technologies emerge and transform the Internet, the TCP (Transmission Control Protocol) is being evolved to cope with new operating conditions and performance demands. For instance, extensions like large windows <ref> [4] </ref>, selective ac-knowledgements [20], PAWS (protection agains wrapped sequence numbers) [4] and the timestamp option [4] are being incorporated in TCP to maintain correct operation and high performance on the evolving Internet. <p> 1 Introduction As new network technologies emerge and transform the Internet, the TCP (Transmission Control Protocol) is being evolved to cope with new operating conditions and performance demands. For instance, extensions like large windows <ref> [4] </ref>, selective ac-knowledgements [20], PAWS (protection agains wrapped sequence numbers) [4] and the timestamp option [4] are being incorporated in TCP to maintain correct operation and high performance on the evolving Internet. <p> 1 Introduction As new network technologies emerge and transform the Internet, the TCP (Transmission Control Protocol) is being evolved to cope with new operating conditions and performance demands. For instance, extensions like large windows <ref> [4] </ref>, selective ac-knowledgements [20], PAWS (protection agains wrapped sequence numbers) [4] and the timestamp option [4] are being incorporated in TCP to maintain correct operation and high performance on the evolving Internet. <p> The version of TCP Lite used in our simulations corresponds to Lite.4 proposed in [5]. This version fixes many bugs in the original 4.4BSD-Lite [26] distribution. TCP Lite is an extension of TCP Reno and provides support for long fat pipes (high bandwidth-delay paths) amongst other improvements <ref> [4] </ref>. <p> This effectively results in a fine-grained measurement of RTT and avoids an overly conservative estimation of RTO without affecting the clock granularity for actually scheduling timeouts. The 4.4BSD implementations of TCP also use the timestamp option <ref> [4] </ref> in the packet header to measure the round-trip time of a segment in addition to maintaining internal variables for timing a segment 7 . This timestamp is reflected back in acknowledgements sent by the receiver. <p> This timestamp is reflected back in acknowledgements sent by the receiver. It is to be noted that clock granularities finer than 1ms should not be used in the timestamp option in TCP <ref> [4] </ref> (the BSD implementations use a 500ms clock granularity). This value is the minimum suggested in RFC1323 [4] and is necessary for the detection of timestamps that are older than 24 days by the PAWS (protection against wrapped sequence numbers) mechanism in TCP 8 . <p> This timestamp is reflected back in acknowledgements sent by the receiver. It is to be noted that clock granularities finer than 1ms should not be used in the timestamp option in TCP <ref> [4] </ref> (the BSD implementations use a 500ms clock granularity). This value is the minimum suggested in RFC1323 [4] and is necessary for the detection of timestamps that are older than 24 days by the PAWS (protection against wrapped sequence numbers) mechanism in TCP 8 . However, this does not imply that a finer granularity clock available in the OS cannot be used to its full advantage. <p> If they are within a millisecond, the internal estimation can be used; if not, the RTT measurement using the timestamp should be used in the timeout estimation equations (after scaling it to nanosecond granularity). 7 This avoids underestimations of RTT when an ACK is misinterpreted as acknowledging a retransmitted segment <ref> [4] </ref> 8 As long as the timestamp doesn't have a finer granularity than 1ms, the PAWS test remains unaffected. 12 TCP sender in the simulation run presented in Section 3. RT T c gives the RTT measurement made by a 500ms clock.
Reference: [5] <author> L. Brakmo and L. Peterson. </author> <title> Performance Problems in 4.4BSD TCP. </title> <journal> ACM Computer Communication Review, </journal> <volume> 25(5) </volume> <pages> 69-86, </pages> <month> Oct. </month> <year> 1995. </year>
Reference-contexts: The coarse-grained clock 1 used for measuring round-trip time 1 4.4BSD TCP uses a 500ms clock for measuring RTT and scheduling timeouts 1 2 (RTT) and scheduling retransmission timeouts (RTO) in the BSD based implementations of TCP has been shown to affect both latency as well as throughput <ref> [6, 5, 14, 19] </ref>. The slow-start congestion control mechanism [16] has been found to be slow in filling the network pipe [21, 12, 1] and affects the performance of short transfers that typically finish during the initial slow-start. <p> FCFS). Host and router computation is assumed to have zero overhead. The simulator clock has a granularity of 1s. The version of TCP Lite used in our simulations corresponds to Lite.4 proposed in <ref> [5] </ref>. This version fixes many bugs in the original 4.4BSD-Lite [26] distribution. TCP Lite is an extension of TCP Reno and provides support for long fat pipes (high bandwidth-delay paths) amongst other improvements [4]. <p> This results in a low bandwidth-delay path of pipe size 200KB between R1 and R2. The setup is similar to other studies of TCP dynamics on low speed WANs <ref> [6, 5] </ref> and resembles an internet where 10Mbps Ethernet LANs are connected by a T1 link. 4 The simulations on a satellite network involve setting the round-trip propagation delay in Figure 2 to 580ms, while the router buffer sizes were set to 70 packets. <p> The framework allows TCP to perform more accurate RTT measurements and to schedule 4 Delayed ACKs in TCP cause the window increase to be less than exponential <ref> [5] </ref>. 5 Delayed ACKs cause the window increase to be less than 1 segment every RTT 8 finer-grained timeouts that are much closer to the RTT of the network by exploiting improved timing facilities available in modern computer systems. <p> For small RTTs, the contribution of (sa &gt;> 3) would be much smaller than the contribution due to sd, thus resulting in large estimates of RTO as compared to the average RTT (given by (sa &gt;> 3)). 2. Brakmo and Peterson <ref> [5] </ref> have shown that due to limited precision of the C implementation, the mean deviation estimator does not decay even when repeated RTT measurements with the same value are made. This problem is significant only when sd is large compared to (sa &gt;> 3) i.e. when the clock is coarse-grained. <p> This problem is significant only when sd is large compared to (sa &gt;> 3) i.e. when the clock is coarse-grained. The work in <ref> [5] </ref> shows that for round-trip times of about 100ms, the estimated RTO can be as large as 5 ticks and almost never goes below 3 ticks. RTO values of 5 ticks and 3 ticks can cause an actual timeout delay of 2-2.5s and 1-1.5s, respectively 6 . Brakmo and Peterson [5] <p> <ref> [5] </ref> shows that for round-trip times of about 100ms, the estimated RTO can be as large as 5 ticks and almost never goes below 3 ticks. RTO values of 5 ticks and 3 ticks can cause an actual timeout delay of 2-2.5s and 1-1.5s, respectively 6 . Brakmo and Peterson [5] also propose a fix for the second problem described above by using larger scaling factors. <p> RT T f gives the RTT measurement made by a 1ms clock. RT O O gives the RTO estimate as computed by TCP Lite. RT O B gives the RTO estimate after applying the fixes suggested by Brakmo and Peterson <ref> [5] </ref> to the timeout estimation algorithms in TCP Lite. RT O Nf gives the RTO estimate as computed using RTT measurements by the 1ms clock 9 . RT O Nc gives the RTO estimate as computed by equation 2 by using f rtt = 1000Hz and f ev = 2Hz. <p> We have also performed similar simulations with the technique suggested by Brakmo and Peterson in <ref> [5] </ref>. <p> Our results show that the senders using our proposed timer scheme were able to transfer about 1.5MB more data during this period as compared to the original scheme. Similar simulations with the technique in <ref> [5] </ref> resulted in an average delay of about 950ms. Our results also indicate that less than 20MB of data were transmitted in the 5s following the startup of sender S8.
Reference: [6] <author> L. Brakmo and L. Peterson. </author> <title> TCP Vegas: End to End Congestion Avoidance on a Global Internet. </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> 13(8) </volume> <pages> 1465-1480, </pages> <month> Oct. </month> <year> 1995. </year>
Reference-contexts: The coarse-grained clock 1 used for measuring round-trip time 1 4.4BSD TCP uses a 500ms clock for measuring RTT and scheduling timeouts 1 2 (RTT) and scheduling retransmission timeouts (RTO) in the BSD based implementations of TCP has been shown to affect both latency as well as throughput <ref> [6, 5, 14, 19] </ref>. The slow-start congestion control mechanism [16] has been found to be slow in filling the network pipe [21, 12, 1] and affects the performance of short transfers that typically finish during the initial slow-start. <p> This results in a low bandwidth-delay path of pipe size 200KB between R1 and R2. The setup is similar to other studies of TCP dynamics on low speed WANs <ref> [6, 5] </ref> and resembles an internet where 10Mbps Ethernet LANs are connected by a T1 link. 4 The simulations on a satellite network involve setting the round-trip propagation delay in Figure 2 to 580ms, while the router buffer sizes were set to 70 packets. <p> Many of these limitations have also been observed elsewhere in the literature <ref> [21, 12, 1, 6, 14] </ref>. As we will show, the impact of these problems is particularly significant in networks with large bandwidth-delay products, including high-bandwidth, long-haul networks and satellite networks. <p> Typically, the OS service for measuring time can provide a finer granularity than the service for event scheduling. This is because most modern architectures provide a fine-grained timer/counter with micro to nano-second granularity in hardware, whose current value can be read with little overhead <ref> [6] </ref>. Providing an event timer, on the other hand, involves a thread dispatch that is currently only efficiently supported at a millisecond granularity as a finer granularity could cause significant interrupt overhead. <p> In order to improve the efficiency of slow-start, once could consider the following naive approach: 1. Measure the bandwidth-delay product and set the slow-start threshold (ssthresh) to this value. Techniques to measure the bandwidth-delay product have been shown in <ref> [14, 6, 18, 22] </ref> and Hoe [13] has already proposed setting the initial ssthresh value to the estimated bandwidth-delay product. 2. Set the congestion window to the value of ssthresh. This would immediately send out a bandwidth-delay product's worth of data, thus filling up the network pipe immediately. <p> The same was confirmed by Balakrishnan et al [3]. Our proposed timer framework reduces the unnecessary long delays associated with a retransmission timeout when a coarse-grained clock is used for scheduling events. Brakmo et al <ref> [6] </ref> have also used the fine-grained system clock to detect lost packets early (while processing a received duplicate ACK) in TCP Vegas. Their method does not however affect the coarse-grained retransmission timeout in TCP.
Reference: [7] <author> L. S. Brakmo and L. L. Peterson. </author> <title> Experiences with Network Simulation. </title> <booktitle> In Proceedings of the ACM SIGMETRICS '96 Conference, </booktitle> <year> 1996. </year>
Reference-contexts: Related work is discussed in Section 6 and in Section 7 we summarize our conclusions. 2 Simulation Environment This section describes the simulation environment used in our study. All simulations were done using the x-sim network simulator <ref> [7] </ref>, which is based on the x-kernel [15]. x-sim is an execution-driven network simulator, where the actions of network protocols are simulated by executing its actual protocol implementation code, rather than an abstract behavioral model of the protocol. x-sim supports multiple hosts, each running a full protocol stack, and several abstract <p> All senders transfer 100MB of data to the corresponding destinations and the simulation time was limited so as to terminate the transfers before they finish (as suggested in <ref> [7] </ref>). We define effective throughput as the ratio of the total amount of useful data that was transferred, to the maximum amount of useful data that could have been transferred over the bottleneck link for the time of the simulation.
Reference: [8] <author> R. Brown. </author> <title> Calendar queues: A fast O(1) priority queue implementation for the simulation event set problem. </title> <journal> Communications of the ACM, </journal> <volume> 31(10) </volume> <pages> 1220-1227, </pages> <month> Oct. </month> <year> 1988. </year> <month> 21 </month>
Reference-contexts: A designated function in the TCP module is invoked as a result of the software interrupt. This function is used by the TCP module to implement its various event timer facilities using appropriate data structure, such as timing 9 wheel [24] and calendar queues <ref> [8] </ref>. Again, the TCP module can query the granularity of this event service, and this granuarity determines the granularity of TCP's timers. Typically, the OS service for measuring time can provide a finer granularity than the service for event scheduling.
Reference: [9] <author> K. Fall and S. Floyd. </author> <title> Simulation-based Comparisons of Tahoe, Reno, and SACK TCP. </title> <journal> Computer Communication Review, </journal> <volume> 26(3), </volume> <month> July </month> <year> 1996. </year>
Reference-contexts: Our method of estimating ssthresh is similar to the one described in [14] except that it repeatedly estimates ssthresh until a value that differs from the minimum by less than 10% is obtained. Fall and Floyd <ref> [9] </ref> investigate the effect of multiple packet losses on the congestion control algorithms of TCP Reno. They point out that the absence of selective acknowledgments imposes limits on TCP's performance. Their work also shows that TCP with 19 selective acknowledgments (SACK-TCP) can effectively recover from multiple packet losses.
Reference: [10] <author> S. Floyd. </author> <title> TCP and Successive Fast Retransmits. </title> <type> Technical report, </type> <institution> Lawrence Berke-ley Laboratory, </institution> <month> May </month> <year> 1995. </year> <month> ftp://ftp.ee.lbl.gov/papers/fastretrans.ps. </month>
Reference-contexts: We also observe that pacing with a 10ms clock offers lesser improvement in this topology than for the one used for satellite network because of the relatively short round-trip time (60ms compared to 580ms in satellite topology). 6 Related Work Floyd <ref> [10] </ref> discusses the problem of invoking fast retransmit mechanism multiple times for the same window of data. Hoe [14] proposes two methods to improve TCP's congestion control algorithms.
Reference: [11] <author> S. Floyd, M. Allman, and C. Partridge. </author> <title> Increasing TCP's Initial Window. </title> <type> IETF Internet Draft, </type> <month> July </month> <year> 1997. </year> <note> Available by anonymous ftp from ds.internic.net/internet-drafts/draft-floyd-incr-init-win-00.txt. </note>
Reference-contexts: Setting the initial congestion window to the above value has been proposed by Floyd et al <ref> [11] </ref> and is currently in the process of standardization by IETF.
Reference: [12] <author> J. Heidemann, K. Obraczka, and J. </author> <title> Touch. Modeling the performance of HTTP over several transport protocols. To appear, </title> <journal> IEEE/ACM Transactions on Networking 5(5), </journal> <month> Oct. </month> <year> 1997. </year>
Reference-contexts: The slow-start congestion control mechanism [16] has been found to be slow in filling the network pipe <ref> [21, 12, 1] </ref> and affects the performance of short transfers that typically finish during the initial slow-start. Throughout this paper, the term pipe size is intended to be synonymous with the product of the available bandwidth 2 and the round-trip time observed when there is no queuing at the routers. <p> Many of these limitations have also been observed elsewhere in the literature <ref> [21, 12, 1, 6, 14] </ref>. As we will show, the impact of these problems is particularly significant in networks with large bandwidth-delay products, including high-bandwidth, long-haul networks and satellite networks.
Reference: [13] <author> J. C. Hoe. </author> <title> Start-up Dynamics of TCP's Congestion Control and Avoidance Schemes. </title> <type> Master's thesis, </type> <institution> MIT, </institution> <year> 1995. </year>
Reference-contexts: In order to improve the efficiency of slow-start, once could consider the following naive approach: 1. Measure the bandwidth-delay product and set the slow-start threshold (ssthresh) to this value. Techniques to measure the bandwidth-delay product have been shown in [14, 6, 18, 22] and Hoe <ref> [13] </ref> has already proposed setting the initial ssthresh value to the estimated bandwidth-delay product. 2. Set the congestion window to the value of ssthresh. This would immediately send out a bandwidth-delay product's worth of data, thus filling up the network pipe immediately. There are several problems with the above approach. <p> Paxson [22] suggests a more robust bottleneck estimation technique called PBM that forms estimates using a range of packet bunch sizes. The second method in <ref> [13] </ref> recovers multiple packet losses in the same window without decreasing the window multiple times. Our method of estimating ssthresh is similar to the one described in [14] except that it repeatedly estimates ssthresh until a value that differs from the minimum by less than 10% is obtained.
Reference: [14] <author> J. C. Hoe. </author> <title> Improving the Start-up Behaviour of a Congestion Control Scheme for TCP. </title> <booktitle> In Proceedings of the ACM SIGCOMM '96 Symposium, </booktitle> <year> 1996. </year>
Reference-contexts: The coarse-grained clock 1 used for measuring round-trip time 1 4.4BSD TCP uses a 500ms clock for measuring RTT and scheduling timeouts 1 2 (RTT) and scheduling retransmission timeouts (RTO) in the BSD based implementations of TCP has been shown to affect both latency as well as throughput <ref> [6, 5, 14, 19] </ref>. The slow-start congestion control mechanism [16] has been found to be slow in filling the network pipe [21, 12, 1] and affects the performance of short transfers that typically finish during the initial slow-start. <p> Thirdly, we show how the performance of the slow-start mechanism in TCP can be improved by using the event scheduling service to pace packets. Finally, we quantify the impact of estimating the slow-start threshold (ssthresh) <ref> [14] </ref> on the startup TCP performance in high bandwidth-delay networks. The remainder of this paper is organized as follows. The simulation environment used to obtain the results presnted in this paper is described in Section 2. <p> Many of these limitations have also been observed elsewhere in the literature <ref> [21, 12, 1, 6, 14] </ref>. As we will show, the impact of these problems is particularly significant in networks with large bandwidth-delay products, including high-bandwidth, long-haul networks and satellite networks. <p> In order to improve the efficiency of slow-start, once could consider the following naive approach: 1. Measure the bandwidth-delay product and set the slow-start threshold (ssthresh) to this value. Techniques to measure the bandwidth-delay product have been shown in <ref> [14, 6, 18, 22] </ref> and Hoe [13] has already proposed setting the initial ssthresh value to the estimated bandwidth-delay product. 2. Set the congestion window to the value of ssthresh. This would immediately send out a bandwidth-delay product's worth of data, thus filling up the network pipe immediately. <p> Hoe <ref> [14] </ref> proposes two methods to improve TCP's congestion control algorithms. First, it attempts to set the slow-start threshold (ssthresh) to an appropriate value by measuring the bandwidth-delay product using a variant of the packet-pair technique [18]. <p> The second method in [13] recovers multiple packet losses in the same window without decreasing the window multiple times. Our method of estimating ssthresh is similar to the one described in <ref> [14] </ref> except that it repeatedly estimates ssthresh until a value that differs from the minimum by less than 10% is obtained. Fall and Floyd [9] investigate the effect of multiple packet losses on the congestion control algorithms of TCP Reno.
Reference: [15] <author> N. C. Hutchinson and L. L. Peterson. </author> <title> The x-kernel: An Architecture for Implementing Network Protocols. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 17(1) </volume> <pages> 64-76, </pages> <month> January </month> <year> 1991. </year>
Reference-contexts: Related work is discussed in Section 6 and in Section 7 we summarize our conclusions. 2 Simulation Environment This section describes the simulation environment used in our study. All simulations were done using the x-sim network simulator [7], which is based on the x-kernel <ref> [15] </ref>. x-sim is an execution-driven network simulator, where the actions of network protocols are simulated by executing its actual protocol implementation code, rather than an abstract behavioral model of the protocol. x-sim supports multiple hosts, each running a full protocol stack, and several abstract link behaviours (point-to-point and ethernet links).
Reference: [16] <author> V. Jacobson. </author> <title> Congestion Avoidance and Control. </title> <booktitle> In Proceedings of the ACM SIGCOMM '88 Symposium, </booktitle> <pages> pages 314-32, </pages> <month> Aug. </month> <year> 1988. </year>
Reference-contexts: The slow-start congestion control mechanism <ref> [16] </ref> has been found to be slow in filling the network pipe [21, 12, 1] and affects the performance of short transfers that typically finish during the initial slow-start. <p> TCP Lite is an extension of TCP Reno and provides support for long fat pipes (high bandwidth-delay paths) amongst other improvements [4]. The timeout estimation and congestion control algorithms used in TCP Lite are essentially the same as those in TCP Reno <ref> [16, 17, 23] </ref>. topology in Figure 1 was used to simulate a high speed WAN (wide area network) while the one in Figure 2 was used to simulate both a low speed WAN as well as a satellite network. <p> In this section, we show how to achieve shorter retransmission timeouts and the associated throughput loss taking advantage of the timer framework proposed in the previous section. The RTO value calculation in the BSD implementations of TCP are described in <ref> [16] </ref>.
Reference: [17] <author> V. Jacobson. </author> <title> Berkeley TCP evolution from 4.3-tahoe to 4.3-reno. </title> <booktitle> In Proceedings of the Eighteenth Internet Engineering Task Force, </booktitle> <month> Aug. </month> <year> 1990. </year>
Reference-contexts: TCP Lite is an extension of TCP Reno and provides support for long fat pipes (high bandwidth-delay paths) amongst other improvements [4]. The timeout estimation and congestion control algorithms used in TCP Lite are essentially the same as those in TCP Reno <ref> [16, 17, 23] </ref>. topology in Figure 1 was used to simulate a high speed WAN (wide area network) while the one in Figure 2 was used to simulate both a low speed WAN as well as a satellite network.
Reference: [18] <author> S. Keshav. </author> <title> A Control-Theoretic Approach to Flow Control. </title> <booktitle> In Proceedings of the ACM SIGCOMM '91 Symposium, </booktitle> <pages> pages 3-15, </pages> <month> Sept. </month> <year> 1991. </year>
Reference-contexts: In order to improve the efficiency of slow-start, once could consider the following naive approach: 1. Measure the bandwidth-delay product and set the slow-start threshold (ssthresh) to this value. Techniques to measure the bandwidth-delay product have been shown in <ref> [14, 6, 18, 22] </ref> and Hoe [13] has already proposed setting the initial ssthresh value to the estimated bandwidth-delay product. 2. Set the congestion window to the value of ssthresh. This would immediately send out a bandwidth-delay product's worth of data, thus filling up the network pipe immediately. <p> This would immediately send out a bandwidth-delay product's worth of data, thus filling up the network pipe immediately. There are several problems with the above approach. The techniques used to measure the bandwidth-delay product can overestimate its value. These techniques usually implement a variant of the packet-pair algorithm <ref> [18] </ref> to estimate the bandwidth 9 BSD implementations set the initial values of sa and sd so as to give a value of rto that is three times as large as the measured RTT. <p> Hoe [14] proposes two methods to improve TCP's congestion control algorithms. First, it attempts to set the slow-start threshold (ssthresh) to an appropriate value by measuring the bandwidth-delay product using a variant of the packet-pair technique <ref> [18] </ref>. Paxson [22] suggests a more robust bottleneck estimation technique called PBM that forms estimates using a range of packet bunch sizes. The second method in [13] recovers multiple packet losses in the same window without decreasing the window multiple times.
Reference: [19] <author> D. Lin and H. T. Kung. </author> <title> TCP Fast Recovery Strategies: Analysis and Improvements. </title> <booktitle> In Proceedings of IEEE INFOCOM '98, </booktitle> <month> Mar. </month> <year> 1998. </year>
Reference-contexts: The coarse-grained clock 1 used for measuring round-trip time 1 4.4BSD TCP uses a 500ms clock for measuring RTT and scheduling timeouts 1 2 (RTT) and scheduling retransmission timeouts (RTO) in the BSD based implementations of TCP has been shown to affect both latency as well as throughput <ref> [6, 5, 14, 19] </ref>. The slow-start congestion control mechanism [16] has been found to be slow in filling the network pipe [21, 12, 1] and affects the performance of short transfers that typically finish during the initial slow-start.
Reference: [20] <author> M. Mathis, J. Mahdavi, S. Floyd, and A. Romanow. </author> <title> RFC 2018: TCP selective acknowledgment options, </title> <address> Oct. </address> <year> 1996. </year>
Reference-contexts: 1 Introduction As new network technologies emerge and transform the Internet, the TCP (Transmission Control Protocol) is being evolved to cope with new operating conditions and performance demands. For instance, extensions like large windows [4], selective ac-knowledgements <ref> [20] </ref>, PAWS (protection agains wrapped sequence numbers) [4] and the timestamp option [4] are being incorporated in TCP to maintain correct operation and high performance on the evolving Internet. <p> They point out that the absence of selective acknowledgments imposes limits on TCP's performance. Their work also shows that TCP with 19 selective acknowledgments (SACK-TCP) can effectively recover from multiple packet losses. Paxson [22] shows that in the absence of the SACK TCP option <ref> [20] </ref>, a significant number of lost packets in the Internet are recovered using the coarse-grained retransmission timeout. The same was confirmed by Balakrishnan et al [3]. Our proposed timer framework reduces the unnecessary long delays associated with a retransmission timeout when a coarse-grained clock is used for scheduling events.
Reference: [21] <author> J. C. </author> <title> Mogul. </title> <booktitle> The Case for Persistent-Connection HTTP. In Proceedings of the ACM SIGCOMM '95 Symposium, </booktitle> <year> 1995. </year>
Reference-contexts: The slow-start congestion control mechanism [16] has been found to be slow in filling the network pipe <ref> [21, 12, 1] </ref> and affects the performance of short transfers that typically finish during the initial slow-start. Throughout this paper, the term pipe size is intended to be synonymous with the product of the available bandwidth 2 and the round-trip time observed when there is no queuing at the routers. <p> Many of these limitations have also been observed elsewhere in the literature <ref> [21, 12, 1, 6, 14] </ref>. As we will show, the impact of these problems is particularly significant in networks with large bandwidth-delay products, including high-bandwidth, long-haul networks and satellite networks.
Reference: [22] <author> V. Paxson. </author> <title> End-to-End Internet Packet Dynamics. </title> <booktitle> In Proceedings of the ACM SIGCOMM '97 Symposium, </booktitle> <year> 1997. </year>
Reference-contexts: The routers are modelled as network nodes that supports a particular queuing 2 Available bandwidth indicates how fast a connection should transmit data to preserve network stability while bottleneck bandwidth gives an upper bound on how fast a connection can possibly transmit data <ref> [22] </ref>. 3 discipline (e.g. FCFS). Host and router computation is assumed to have zero overhead. The simulator clock has a granularity of 1s. The version of TCP Lite used in our simulations corresponds to Lite.4 proposed in [5]. This version fixes many bugs in the original 4.4BSD-Lite [26] distribution. <p> In order to improve the efficiency of slow-start, once could consider the following naive approach: 1. Measure the bandwidth-delay product and set the slow-start threshold (ssthresh) to this value. Techniques to measure the bandwidth-delay product have been shown in <ref> [14, 6, 18, 22] </ref> and Hoe [13] has already proposed setting the initial ssthresh value to the estimated bandwidth-delay product. 2. Set the congestion window to the value of ssthresh. This would immediately send out a bandwidth-delay product's worth of data, thus filling up the network pipe immediately. <p> Hoe [14] proposes two methods to improve TCP's congestion control algorithms. First, it attempts to set the slow-start threshold (ssthresh) to an appropriate value by measuring the bandwidth-delay product using a variant of the packet-pair technique [18]. Paxson <ref> [22] </ref> suggests a more robust bottleneck estimation technique called PBM that forms estimates using a range of packet bunch sizes. The second method in [13] recovers multiple packet losses in the same window without decreasing the window multiple times. <p> They point out that the absence of selective acknowledgments imposes limits on TCP's performance. Their work also shows that TCP with 19 selective acknowledgments (SACK-TCP) can effectively recover from multiple packet losses. Paxson <ref> [22] </ref> shows that in the absence of the SACK TCP option [20], a significant number of lost packets in the Internet are recovered using the coarse-grained retransmission timeout. The same was confirmed by Balakrishnan et al [3].
Reference: [23] <author> W. Stevens. </author> <title> TCP/IP Illustrated Volume 1 : The Protocols. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1994. </year>
Reference-contexts: TCP Lite is an extension of TCP Reno and provides support for long fat pipes (high bandwidth-delay paths) amongst other improvements [4]. The timeout estimation and congestion control algorithms used in TCP Lite are essentially the same as those in TCP Reno <ref> [16, 17, 23] </ref>. topology in Figure 1 was used to simulate a high speed WAN (wide area network) while the one in Figure 2 was used to simulate both a low speed WAN as well as a satellite network. <p> This state continues until t=26.5s, when the congestion window has again grown too large, resulting in the loss of a single segment. This loss is detected by TCP's fast retransmit mechanism <ref> [23] </ref>, the lost segment is retransmitted, the congestion window is halved, and TCP continues in the congestion avoidance state.
Reference: [24] <author> G. Varghese and A. Lauck. </author> <title> Hashed and hierarchical timing wheels: Data structures for the efficient implementation of a timer facility. </title> <booktitle> In Proceedings of the Eleventh ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 171-180, </pages> <month> Nov. </month> <year> 1987. </year> <month> 22 </month>
Reference-contexts: A designated function in the TCP module is invoked as a result of the software interrupt. This function is used by the TCP module to implement its various event timer facilities using appropriate data structure, such as timing 9 wheel <ref> [24] </ref> and calendar queues [8]. Again, the TCP module can query the granularity of this event service, and this granuarity determines the granularity of TCP's timers. Typically, the OS service for measuring time can provide a finer granularity than the service for event scheduling.
Reference: [25] <author> V. Visweswaraiah and J. Heidemann. </author> <title> Improving restart of idle TCP connections. </title> <type> Technical Report 97-661, </type> <institution> University of Southern California, </institution> <month> November </month> <year> 1997. </year>
Reference-contexts: Allman et al [1] have shown the limiting effect of slow-start and congestion avoidance schemes in TCP in utilizing the bandwidth over satellite networks. Our proposed scheme for pacing packets in slow-start addresses their former observation. Visweswaraiah et al <ref> [25] </ref> suggest using rate-based pacing to improve the restart of idle connections.
Reference: [26] <author> G. Wright and W. Stevens. </author> <title> TCP/IP Illustrated Volume 2 : The Implementation. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1995. </year>
Reference-contexts: FCFS). Host and router computation is assumed to have zero overhead. The simulator clock has a granularity of 1s. The version of TCP Lite used in our simulations corresponds to Lite.4 proposed in [5]. This version fixes many bugs in the original 4.4BSD-Lite <ref> [26] </ref> distribution. TCP Lite is an extension of TCP Reno and provides support for long fat pipes (high bandwidth-delay paths) amongst other improvements [4].
Reference: [27] <author> L. Zhang, S. Shenker, and D. D. Clark. </author> <title> Observations on the Dynamics of a Congestion Control Algorithm: The Effects of Two-Way Traffic. </title> <booktitle> In Proceedings of the ACM SIGCOMM '91 Symposium, </booktitle> <pages> pages 133-148, </pages> <year> 1991. </year>
Reference-contexts: The packet-pair algorithm estimates bandwidth by measuring the difference in the times of reception of the ACKs of two closely sent data segments. Certain network phenomena like ack clustering <ref> [27] </ref> and the absence of fair queuing in the network routers can give an inflated estimate of the bandwidth, if computed using the packet-pair algorithm. Furthermore, the measured RTT usually includes queuing delays that can also result in an elevated estimate of the bandwidth-delay product.
References-found: 27

