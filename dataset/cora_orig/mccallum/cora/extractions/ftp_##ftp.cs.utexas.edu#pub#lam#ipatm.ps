URL: ftp://ftp.cs.utexas.edu/pub/lam/ipatm.ps
Refering-URL: http://www.cs.utexas.edu/users/lam/NRL/ipatm.html
Root-URL: http://www.cs.utexas.edu
Title: Providing Application-Level QoS  
Author: Simon S. Lam 
Date: October 14, 1996  
Address: Austin, Texas 78712-1188  
Affiliation: Department of Computer Sciences The University of Texas at Austin  
Pubnum: TR-96-26  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Ernst W. Biersack. </author> <title> Performance evaluation of forward error correction in ATM networks. </title> <booktitle> In Proceedings of ACM SIGCOMM '92, </booktitle> <pages> pages 248-257, </pages> <month> August </month> <year> 1992. </year>
Reference-contexts: Furthermore, if only some connections use FEC, the improved performance of these connections is at the expense of connections that do not use FEC. These issues were investigated, and it was observed that the use of FEC would provide a net performance gain only for networks with heterogeneous traffic <ref> [1] </ref>. The use of FEC requires additional support at the two end points of a connection (e.g., in the end systems).
Reference: [2] <author> P. Boyer. </author> <title> A reservation principle with applications to the ATM traffic control. </title> <journal> Comp. Networks and ISDN Sys., </journal> <volume> 24 </volume> <pages> 321-334, </pages> <year> 1992. </year>
Reference-contexts: objective would be to avoid discarding more than one cell from a message so that the message loss probability is further improved [11]. 3.3 ATM block transfer The ATM block transfer (ABT) capability being standardized by ITU-T [7, 3] has been known for some time as a fast reservation protocol <ref> [2] </ref>. The concept of a block was introduced to represent some high-level protocol data unit (s). Conceptually, a traffic source generates 2 a sequence of blocks, each of which is a sequence of cells bracketed by two RM cells.
Reference: [3] <author> Thomas M. Chen, Steve S. Liu, and Vijay K. Samalam. </author> <title> The available bit rate service for data in ATM networks. </title> <journal> IEEE Communications Magazine, </journal> <pages> pages 56-71, </pages> <month> May </month> <year> 1996. </year>
Reference-contexts: to selectively discard cells; if each message has only one parity cell, the objective would be to avoid discarding more than one cell from a message so that the message loss probability is further improved [11]. 3.3 ATM block transfer The ATM block transfer (ABT) capability being standardized by ITU-T <ref> [7, 3] </ref> has been known for some time as a fast reservation protocol [2]. The concept of a block was introduced to represent some high-level protocol data unit (s).
Reference: [4] <author> I. Cidon, R. Guerin, and A. Khamisy. </author> <title> An investigation of application level performance in ATM networks. </title> <booktitle> In Proceedings of IEEE INFOCOM '95, </booktitle> <address> Boston, MA, </address> <month> April </month> <year> 1995. </year>
Reference-contexts: In some of the references cited, an ADU is also called a message or a packet. The sequence of cells carrying the ADU is also called a block or a burst. 2 Analyzing application-level performance The approach of Cidon et al. is to employ analytic modeling <ref> [4] </ref> and simulations [5] to determine the performance of messages (ADUs) delivered by an ATM network that provides cell-level guarantees (cell loss probability, cell delay, and cell delay jitter). It was observed that the message loss probability of a connection differs greatly from the cell loss probability guaranteed.
Reference: [5] <author> I. Cidon, R. Guerin, A. Khamisy, and K. N. Sivarajan. </author> <title> Cell versus message level performances in ATM networks. </title> <journal> Telecommunication Systems, </journal> <volume> 5 </volume> <pages> 223-239, </pages> <year> 1996. </year>
Reference-contexts: In some of the references cited, an ADU is also called a message or a packet. The sequence of cells carrying the ADU is also called a block or a burst. 2 Analyzing application-level performance The approach of Cidon et al. is to employ analytic modeling [4] and simulations <ref> [5] </ref> to determine the performance of messages (ADUs) delivered by an ATM network that provides cell-level guarantees (cell loss probability, cell delay, and cell delay jitter). It was observed that the message loss probability of a connection differs greatly from the cell loss probability guaranteed.
Reference: [6] <author> R. Gopalakrishnan and Guru Parulkar. </author> <title> Efficient user space protocol implementations with QoS guarantees using real-time upcalls. </title> <type> Technical Report WUCS-96-11, </type> <institution> Washington University in St. Louis, </institution> <year> 1996. </year>
Reference-contexts: To provide application-level performance 1 Loss due to buffer overflow is possible. 3 guarantees between these end points, additional support in the workstation operating sys-tems is needed, particularly, CPU scheduling that provides QoS guarantees, as well as techniques for moving data efficiently between user address space and network interface <ref> [6, 14, 15] </ref>.
Reference: [7] <author> ITU-T Rec. I.371. </author> <title> Traffic Control and Congestion Control in B-ISDN. </title> <address> Perth, U.K., </address> <month> Nov. </month> <pages> 6-14, </pages> <year> 1995. </year>
Reference-contexts: to selectively discard cells; if each message has only one parity cell, the objective would be to avoid discarding more than one cell from a message so that the message loss probability is further improved [11]. 3.3 ATM block transfer The ATM block transfer (ABT) capability being standardized by ITU-T <ref> [7, 3] </ref> has been known for some time as a fast reservation protocol [2]. The concept of a block was introduced to represent some high-level protocol data unit (s).
Reference: [8] <author> Simon S. Lam and Geoffrey G. Xie. </author> <title> Burst scheduling networks. </title> <type> Technical Report TR-94-20, </type> <institution> University of Texas at Austin, </institution> <month> July </month> <year> 1994. </year> <note> Revised, August 1996. An abbreviated version in Proceedings of IEEE INFOCOM '95, </note> <month> April </month> <year> 1995. </year>
Reference-contexts: Note that such a generalization is backward-compatible since a block is a sequence of cells, which subsumes a single cell as a special case. 4.1 Burst scheduling networks The class of burst scheduling networks presented in <ref> [8, 9] </ref> supports a real-time VBR service for blocks. Each flow is modeled as a sequence of bursts, each of which is a sequence of packets (cells) that carry an application data unit (same as block in ABT).
Reference: [9] <author> Simon S. Lam and Geoffrey G. Xie. </author> <title> Group priority scheduling. </title> <type> Technical Report TR-95-28, </type> <institution> University of Texas at Austin, </institution> <month> July </month> <year> 1995. </year> <note> Revised, September 1996. An abbreviated version in Proceedings of IEEE INFOCOM '96, </note> <month> March </month> <year> 1996. </year>
Reference-contexts: Note that such a generalization is backward-compatible since a block is a sequence of cells, which subsumes a single cell as a special case. 4.1 Burst scheduling networks The class of burst scheduling networks presented in <ref> [8, 9] </ref> supports a real-time VBR service for blocks. Each flow is modeled as a sequence of bursts, each of which is a sequence of packets (cells) that carry an application data unit (same as block in ABT).
Reference: [10] <author> A. Romanow and S. Floyd. </author> <title> Dynamics of TCP traffic over ATM networks. </title> <booktitle> In Proceedings of ACM SIGCOMM '94, </booktitle> <address> London, England, </address> <month> August </month> <year> 1994. </year>
Reference-contexts: Therefore, when a channel is congested (i.e., buffer utilization exceeding a threshold) and cell discard is needed, entire packets should be discarded rather than individual cells. There are several variants of this idea: early packet discard (EPD) <ref> [10] </ref>, and EPD with hysteresis and fair EPD with hysteresis [12]. Clearly, using any one of these methods would improve the packet loss probability of an ATM network for the same cell loss guarantee. Implementing these methods would require that switches keep additional per-connection state information. <p> Implementing these methods would require that switches keep additional per-connection state information. Switches also need to recognize the last cell of each packet. For an AAL5 packet, in particular, it is suggested that switches determine the end of an AAL5 packet by examining the AAL5 headers of cells <ref> [10] </ref>. 3.2 Forward error correction The use of forward error correction (FEC) has been proposed to improve not only the application-level loss probability but end-to-end delay as well [11]. Consider a message (ADU) that is segmented and carried in n cells from a source to a destination.
Reference: [11] <author> Nachum Shacham and Paul McKenney. </author> <title> Packet recovery in high-speed networks using coding and buffer management. </title> <booktitle> In Proceedings of IEEE INFOCOM '90, </booktitle> <pages> pages 124-131, </pages> <year> 1990. </year>
Reference-contexts: packet, in particular, it is suggested that switches determine the end of an AAL5 packet by examining the AAL5 headers of cells [10]. 3.2 Forward error correction The use of forward error correction (FEC) has been proposed to improve not only the application-level loss probability but end-to-end delay as well <ref> [11] </ref>. Consider a message (ADU) that is segmented and carried in n cells from a source to a destination. Suppose the source also sends a redundant "parity cell." The destination can reconstruct the original message as soon as n out of the n + 1 cells have arrived. <p> Also, support can be added in switches to selectively discard cells; if each message has only one parity cell, the objective would be to avoid discarding more than one cell from a message so that the message loss probability is further improved <ref> [11] </ref>. 3.3 ATM block transfer The ATM block transfer (ABT) capability being standardized by ITU-T [7, 3] has been known for some time as a fast reservation protocol [2]. The concept of a block was introduced to represent some high-level protocol data unit (s).
Reference: [12] <author> J.S. Turner. </author> <title> Maintaining high throughput during overload in ATM switches. </title> <booktitle> Proceedings of IEEE INFOCOM '96. </booktitle> <pages> pages 287-295, </pages> <year> 1996. </year>
Reference-contexts: Therefore, when a channel is congested (i.e., buffer utilization exceeding a threshold) and cell discard is needed, entire packets should be discarded rather than individual cells. There are several variants of this idea: early packet discard (EPD) [10], and EPD with hysteresis and fair EPD with hysteresis <ref> [12] </ref>. Clearly, using any one of these methods would improve the packet loss probability of an ATM network for the same cell loss guarantee. Implementing these methods would require that switches keep additional per-connection state information. Switches also need to recognize the last cell of each packet.
Reference: [13] <author> Geoffrey G. Xie and Simon S. Lam. </author> <title> Real-time block transfer under a link sharing hierarchy. </title> <type> Technical Report TR-96-19, </type> <institution> University of Texas at Austin, </institution> <month> June </month> <year> 1996. </year> <note> Available from http://www.cs.utexas.edu/users/lam/NRL/ . To appear in Proceedings IEEE INFOCOM '97. </note>
Reference-contexts: The packet scheduler is highly efficient and allocates bandwidth to a flow on a per-burst basis (like ABT). Tight bounds on the end-to-end delays of bursts are proved. Two burst-based admission control policies are described in <ref> [13] </ref> to provide the following classes of service: * Real-time VBR service with no loss. Each flow in this class is allocated its peak bandwidth at connection setup. <p> For applications that can tolerate a small block loss rate, their flows are admitted at connection setup time on the basis of their peak and sustained rates with overbooking allowed at each switch. The block loss rate of these flows can be calculated and negotiated at connection setup <ref> [13] </ref>. 4.2 End system support The end points of a connection are typically application programs running in the user address spaces of workstation operating systems.
Reference: [14] <author> David K. Y. Yau and Simon S. Lam. </author> <title> Operating system techniques for distributed multimedia. </title> <type> Technical Report TR-95-36, </type> <institution> University of Texas at Austin, </institution> <month> July </month> <year> 1995. </year> <note> Revised, January 1996. An abbreviated version in Proceedings MMCN '96, </note> <month> January </month> <year> 1996. </year>
Reference-contexts: To provide application-level performance 1 Loss due to buffer overflow is possible. 3 guarantees between these end points, additional support in the workstation operating sys-tems is needed, particularly, CPU scheduling that provides QoS guarantees, as well as techniques for moving data efficiently between user address space and network interface <ref> [6, 14, 15] </ref>.
Reference: [15] <author> David K. Y. Yau and Simon S. Lam. </author> <title> Adaptive rate-controlled scheduling for multimedia applications. </title> <type> Technical Report TR-96-17, </type> <institution> University of Texas at Austin, </institution> <month> April </month> <year> 1996. </year> <note> Revised, September 1996. An abbreviated version in Proceedings ACM Multimedia '96, </note> <month> November </month> <year> 1996. </year> <month> 4 </month>
Reference-contexts: To provide application-level performance 1 Loss due to buffer overflow is possible. 3 guarantees between these end points, additional support in the workstation operating sys-tems is needed, particularly, CPU scheduling that provides QoS guarantees, as well as techniques for moving data efficiently between user address space and network interface <ref> [6, 14, 15] </ref>.
References-found: 15

