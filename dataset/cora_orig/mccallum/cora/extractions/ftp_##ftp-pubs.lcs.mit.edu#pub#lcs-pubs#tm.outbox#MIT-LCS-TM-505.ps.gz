URL: ftp://ftp-pubs.lcs.mit.edu/pub/lcs-pubs/tm.outbox/MIT-LCS-TM-505.ps.gz
Refering-URL: ftp://ftp-pubs.lcs.mit.edu/pub/lcs-pubs/listings/catatm.html
Root-URL: 
Title: Coordinated Resource Management in a Replicated Object Server  
Author: Sanjay Ghemawat Robert Gruber James O'Toole Liuba Shrira 
Abstract: We propose several new techniques for resource management in a replicated object server. By coordinating cache and disk usage among the replicas, these techniques increase throughput and reduce fetch latency. Cache splitting speeds up fetches by avoiding redundant cache entries, effectively increasing the cache size. Coordinated writing coordinates disk writes to ensure that one replica is always available to service fetches. We investigate the performance of a replicated server using these techniques, and we present simulation results showing that these techniques provide substantial performance improvements across a variety of workloads. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Atul Adya. </author> <title> A distributed commit protocol for optimistic concurrency control. </title> <type> Master's thesis, </type> <institution> Mas-sachusetts Institute of Technology, </institution> <month> February </month> <year> 1994. </year>
Reference-contexts: We assume the need to abort is detected at the server using a validation phase that does not require any disk accesses; see <ref> [1] </ref> for the details. operation. The server is implemented using a primary-backup-witness scheme. The witness is not depicted; it is not used in the normal case, and our techniques do not apply to the failover case where the witness has taken over the task of the backup.
Reference: [2] <author> D. Agrawal and A. El Abbadi. </author> <title> Resilient logical structures for efficient management of replicated data. </title> <type> Technical Report TRCS 92-04, </type> <institution> Department of Computer Science, University of California, Santa Barbara, </institution> <address> CA 93106, </address> <year> 1992. </year>
Reference-contexts: As expected, in uniform access patterns where disk reads are more important, the advantage of cache splitting is more significant. 7 Related work There is a substantial body of work in the literature concerning the operation of replicated servers. Recently, replicated server design and performance have attracted much attention <ref> [9, 7, 3, 10, 2] </ref>. Previous efforts to evaluate the utilization of the combined resources of both replicas has focused primarily on improving the load balance between the primary and the backup replica.
Reference: [3] <author> A. Bhide, E. Elnozahy, and S. Morgan. </author> <title> A Highly Available Network File Server. </title> <booktitle> In Winter 1991 USENIX Conference. USENIX Association, </booktitle> <month> January </month> <year> 1991. </year>
Reference-contexts: As expected, in uniform access patterns where disk reads are more important, the advantage of cache splitting is more significant. 7 Related work There is a substantial body of work in the literature concerning the operation of replicated servers. Recently, replicated server design and performance have attracted much attention <ref> [9, 7, 3, 10, 2] </ref>. Previous efforts to evaluate the utilization of the combined resources of both replicas has focused primarily on improving the load balance between the primary and the backup replica.
Reference: [4] <author> S. Carson and S. Setia. </author> <title> Analysis of the periodic update write policy for disk cache. </title> <journal> IEEE Transactions on Sowtware Engineering, </journal> <volume> 18(1) </volume> <pages> 213-226, </pages> <month> January </month> <year> 1992. </year>
Reference-contexts: Disk arms can be scheduled more efficiently if write requests are accumulated and applied together, a technique known as batching. Studies show that batching can provide significantly higher bandwidth than random access [12]. Nevertheless, batching can substantially delay client fetches, which might block behind batched writes <ref> [4] </ref>. Such varying delays can substantially reduce the effectiveness of client prefetching. Write coordination avoids this problem by ensuring that one replica is always available to service fetches, allowing the server to enjoy the benefits of batching without imposing a penalty on fetches.
Reference: [5] <author> M. Franklin, M. Carey, , and M. Livny. </author> <title> Global memory management in client-server dbms architectures. </title> <booktitle> In Proceedings of 18th VLDB Conf., </booktitle> <year> 1992. </year>
Reference-contexts: We are not aware of other work in the replicated servers area that considers the aggressive coordinated resource management that we propose. Franklin, Carey, and Livny <ref> [5] </ref> describe a global cache management technique in a database system.
Reference: [6] <author> H. Garcia-Molina and C.A. Polyzois. </author> <title> Processing of read-only queries at a remote backup. </title> <type> Technical Report CS-TR-354-91, </type> <institution> Department of Computer Science, Princeton University, </institution> <month> December </month> <year> 1991. </year>
Reference-contexts: Each replica therefore processes some of the fetches and performs some of the reads required. Fetch balancing is similar to the scheme described in <ref> [6] </ref> that sends read-only queries to the backup in a replicated relational database. 3 New Techniques In this section we describe our techniques for coordinating the use of cache memory and disk arms at the server replicas. <p> Previous efforts to evaluate the utilization of the combined resources of both replicas has focused primarily on improving the load balance between the primary and the backup replica. One approach to load balancing in a replicated database design is to execute read-only queries at the backup <ref> [6] </ref>. This technique improves server throughput by increasing processor and disk arm utilization at the backup. A different approach to load balancing was implemented in the Harp file system [9].
Reference: [7] <author> H. Garcia-Molina and C.A. Polyzois. </author> <title> Evaluation of remote backup algorithms for transaction processing systems. </title> <booktitle> In ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 246-255, </pages> <address> San Diego, CA, </address> <month> June </month> <year> 1992. </year>
Reference-contexts: As expected, in uniform access patterns where disk reads are more important, the advantage of cache splitting is more significant. 7 Related work There is a substantial body of work in the literature concerning the operation of replicated servers. Recently, replicated server design and performance have attracted much attention <ref> [9, 7, 3, 10, 2] </ref>. Previous efforts to evaluate the utilization of the combined resources of both replicas has focused primarily on improving the load balance between the primary and the backup replica.
Reference: [8] <author> B. Liskov, M. Day, and L. Shrira. </author> <title> Distributed object management in Thor. </title> <editor> In M. Tamer Ozsu, Umesh Dayal, and Patrick Valduriez, editors, </editor> <booktitle> Distributed Object Management. </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, California, </address> <year> 1993. </year>
Reference-contexts: Although we believe that these techniques are applicable to a variety of replicated server architectures, we explore them here in the context of a primary-copy server in the Thor persistent object system <ref> [8] </ref>. Thor clients fetch objects from the server into a local cache, compute locally, and then send any modifications to be committed at the server. As such systems scale, they tend to become I/O bound, so techniques for enhancing I/O latency and throughput are of substantial interest. <p> The baseline is derived from our work on Thor <ref> [8] </ref>, a client-server object-oriented database system with replicated object servers. Three important features of Thor that we use in our baseline are optimistic concurrency control, object-based architecture, and primary copy replication.
Reference: [9] <author> B. Liskov, S. Ghemawat, R. Gruber, P. Johnson, L. Shrira, and M. Williams. </author> <title> Replication in the Harp file system. </title> <booktitle> In Proceedings of the 13th ACM Symposium on Operating Systems Principles, </booktitle> <year> 1991. </year>
Reference-contexts: A transaction is considered committed once its commit entry is present in both logs each machine running a replica has an uninterruptible power supply to prevent the simultaneous loss of both logs. This approach to fast primary copy commit was invented for the Harp replicated file system <ref> [9] </ref>. Installing The system uses an object-based rather than a page-based architecture. Objects managed by the server are grouped into segments, and each replica has a segment cache; segments are the unit of disk transfer and caching at the server replicas. <p> As expected, in uniform access patterns where disk reads are more important, the advantage of cache splitting is more significant. 7 Related work There is a substantial body of work in the literature concerning the operation of replicated servers. Recently, replicated server design and performance have attracted much attention <ref> [9, 7, 3, 10, 2] </ref>. Previous efforts to evaluate the utilization of the combined resources of both replicas has focused primarily on improving the load balance between the primary and the backup replica. <p> One approach to load balancing in a replicated database design is to execute read-only queries at the backup [6]. This technique improves server throughput by increasing processor and disk arm utilization at the backup. A different approach to load balancing was implemented in the Harp file system <ref> [9] </ref>. In Harp, data is statically partitioned between file systems and each active site serves as the primary replica for one file system and as the backup replica for another.
Reference: [10] <author> C. Mohan, K. Treiber, and R. Obermack. </author> <title> Algorithms for the management of remote backup databases for disaster recovery. </title> <institution> IBM Reasearch Report RJ 7885R, IBM Almaden Research Center, </institution> <address> San Jose, CA, </address> <month> June </month> <year> 1990. </year>
Reference-contexts: As expected, in uniform access patterns where disk reads are more important, the advantage of cache splitting is more significant. 7 Related work There is a substantial body of work in the literature concerning the operation of replicated servers. Recently, replicated server design and performance have attracted much attention <ref> [9, 7, 3, 10, 2] </ref>. Previous efforts to evaluate the utilization of the combined resources of both replicas has focused primarily on improving the load balance between the primary and the backup replica.
Reference: [11] <author> C. Polyzois, A. Bhide, and D. Dias. </author> <title> Disk mirroring with alternating deferred updates. </title> <booktitle> In Proceedings of 19th VLDB Conf., </booktitle> <year> 1993. </year>
Reference-contexts: We are not aware of other work in the replicated servers area that considers the aggressive coordinated resource management that we propose. Franklin, Carey, and Livny [5] describe a global cache management technique in a database system. The pioneering work of Polyzois, Bhide, and Dias <ref> [11] </ref> studies the performance of write coordination in a mirrored disk system. 8 Conclusion In this paper, after presenting a baseline replicated object server design, we proposed several new coordination techniques that enable the server to utilize cache memory and disk bandwidth more efficiently.
Reference: [12] <author> M. Seltzer, P. Chen, and J. Ousterhout. </author> <title> Disk scheduling revisited. </title> <booktitle> In Proceedings of Winter USENIX, </booktitle> <year> 1990. </year>
Reference-contexts: Disk arms can be scheduled more efficiently if write requests are accumulated and applied together, a technique known as batching. Studies show that batching can provide significantly higher bandwidth than random access <ref> [12] </ref>. Nevertheless, batching can substantially delay client fetches, which might block behind batched writes [4]. Such varying delays can substantially reduce the effectiveness of client prefetching. <p> This simplistic disk model is intended to capture the essential aspect of disk drive performance that is relevant here: when a large number of operations are outstanding, the disk driver or scheduler can order the operations to obtain approximately one-half the raw disk transfer bandwidth available <ref> [12] </ref>. 5 Experiment Setup We designed and ran a series of experiments to evaluate the coordination techniques presented in Section 3. We compared the performance of several experimental configurations on a variety of workloads.
References-found: 12

