URL: http://www.cs.ualberta.ca/~greiner/PAPERS/ijcai-repn.ps
Refering-URL: http://www.cs.ualberta.ca/~greiner/PAPERS/
Root-URL: 
Email: greiner@cs.toronto.edu  elkan@cs.ucsd.edu  
Title: Measuring and Improving the Effectiveness of Representations  
Author: Russell Greiner Charles Elkan 
Address: Toronto, Ontario M5S 1A4  La Jolla, California 92093-0114  
Affiliation: Department of Computer Science University of Toronto  Department of Computer Science University of California, San Diego  
Abstract: This report discusses what it means to claim that a representation is an effective encoding of knowledge. We first present dimensions of merit for evaluating representations, based on the view that usefulness is a behavioral property, and is necessarily relative to a specified task. We then provide methods (based on results from mathematical statistics) for reliably measuring effectiveness empirically, and hence for comparing different representations. We also discuss weak but guaranteed methods of improving inadequate representations. Our results are an application of the ideas of formal learning theory to concrete knowledge represen tation formalisms.
Abstract-found: 1
Intro-found: 1
Reference: [ Bollobas, 1985 ] <author> B. Bollobas. </author> <title> Random Graphs. </title> <publisher> Acad. Press, </publisher> <year> 1985. </year>
Reference-contexts: Chernoff bounds tell us the probable rate of convergence: the probability that "S n is more than + fi" goes to 0 exponentially fast as n increases; and, for a fixed n, exponentially as fi increases. Formally, <ref> [ Bollobas, 1985, p. 12 ] </ref> P r [ S n &gt; + fi ] e fi 2 Recall now that a representation's utility is defined as the mean of its scores over its distribution of possible queries.
Reference: [ Borgida and Etherington, 1989 ] <author> A. Borgida and D. Ether-ington. </author> <title> Hierarchical knowledge bases and efficient disjunctive reasoning. </title> <booktitle> In KR-89, </booktitle> <year> 1989. </year>
Reference: [ Brewka, 1989 ] <author> G. Brewka. </author> <title> Preferred subtheories: An extended logical framework for default reasoning. </title> <booktitle> In IJCAI-89, </booktitle> <year> 1989. </year>
Reference-contexts: 1 : F (x) P (x): :F (x) , one could conclude either F (T), based on the first fact and first default, d 1 ; or :F (T), based on the second fact and second default, d 2 . 8 One way around this problem involves prioritizing the defaults <ref> [ Przymusinski, 1987; Brewka, 1989 ] </ref> . Here, for example, we could specify d 2 d 1 , meaning we should use the d 2 default if it applies, and only if it does not should we consider d 1 .
Reference: [ Chernoff, 1952 ] <author> H. Chernoff. </author> <title> A measure of asymptotic efficiency for tests of a hypothesis based on the sums of observations. </title> <journal> Annals of Mathematical Statistics, </journal> <volume> 23, </volume> <year> 1952. </year>
Reference: [ Cohen, 1990 ] <author> W. Cohen. </author> <title> Using distribution-free learning theory to analyze chunking. </title> <booktitle> In CSCSI-90, </booktitle> <year> 1990. </year>
Reference-contexts: a complete binary tree, where each node corresponds to a literal, and one descending arc indicates that this literal should be positive, and other, that is should be negative. [2] Several previous systems have implicitly dealt with this theme, of gaining efficiency at the expense of accuracy or categoricity; see <ref> [ Cohen, 1990 ] </ref> , [ Subramanian and Genesereth, 1987 ] , [ Levesque, 1986; Selman and Kautz, 1988; Etherington et al., 1989; Borgida and Etherington, 1989 ] , [ Selman and Kautz, 1991 ] . None, however, have explicitly quantified the tradeoffs.
Reference: [ DeJong and Mooney, 1986 ] <author> G. DeJong and R. Mooney. </author> <title> Explanation-based learning: An alternative view. </title> <journal> Machine Learning, </journal> <volume> 1(2), </volume> <year> 1986. </year>
Reference: [ DeJong, 1988 ] <author> G. DeJong. </author> <booktitle> AAAI workshop on Explanation-Based Learning. Sponsored by AAAI, </booktitle> <year> 1988. </year>
Reference: [ Dietterich, 1986 ] <author> T. Dietterich. </author> <title> Learning at the knowledge level. </title> <journal> Machine Learning, </journal> <volume> 1(3), </volume> <year> 1986. </year>
Reference-contexts: Increasing efficiency by decreasing accuracy: The previous subsection deals with speedup learning (performing only "symbol-level" modifications <ref> [ Dietterich, 1986 ] </ref> ), whose objective is new performance systems that are as accurate and as categorical as the original system, but (we hope) faster. This subsection removes this constraint, and considers techniques that are allowed to produce systems that are less accurate or less categorical.
Reference: [ Etherington et al., 1989 ] <author> D. Etherington, A. Borgida, R. Brachman, and H. Kautz. </author> <title> Vivid knowledge and tractable reasoning: Preliminary report. </title> <booktitle> In IJCAI-89, </booktitle> <year> 1989. </year>
Reference: [ Goldberg, 1979 ] <author> A. Goldberg. </author> <title> An average case complexity analysis of the satisfiability problem. </title> <booktitle> In Proceedings of the 4th Workshop on Automated Deduction, </booktitle> <year> 1979. </year>
Reference-contexts: of the lemmas and theorems presented in this short paper. will encounter; it therefore is more likely to provide a good indication of R's true utility than we would get by testing R on worst case queries, a set of concocted queries, a sample drawn randomly from a uniform distribution <ref> [ Goldberg, 1979 ] </ref> , or any particular collection of "benchmark challenge problems" [ Keller, 1987 ] .
Reference: [ Greiner and Cohen, 1991a ] <author> R. Greiner and W. Cohen. </author> <title> EBL systems that (almost) always improve performance. </title> <type> Technical report, </type> <institution> Univ. of Toronto, </institution> <year> 1991. </year>
Reference-contexts: We can, however, use a set of samples to estimate it, and use this information to determine whether R 2 would be better than R 1 , with high confidence. In fact, we can obtain reasonable estimates of this distribution by running R 1 alone; see <ref> [ Greiner and Cohen, 1991a ] </ref> . That paper also shows how to extend this learning system to handle more elaborate classes of inference graphs (with many different paths from query to retrieval, involving conjunctions, etc.), and other types of modifications (besides simply rearranging the strategy). <p> Some arcs are "probabilistic", meaning that whether a representation can traverse such an arc can depend on the contents of the fact set, or the particular query posed, etc. A representation returns Yes if it reachs any leaf node. (More details appear in <ref> [ Greiner and Cohen, 1991a ] </ref> .) The R 1 representation answers G () queries by exploring the entire G M graph.
Reference: [ Greiner and Cohen, 1991b ] <author> R. Greiner and W. Cohen. </author> <title> Producing more accurate theories. </title> <type> Technical report, </type> <institution> Univ. of Toronto, </institution> <year> 1991. </year>
Reference-contexts: Similarly, if we knew that there were many relevant individuals, but very few were pacifists, then we would know that d 4 d 3 is appropriate. In general, however, we do not know the distribution. <ref> [ Greiner and Cohen, 1991b ] </ref> presents a PAO-like algorithm that uses a set of samples to approximate the distribution, to obtain an estimate that is sufficiently close to guarantee that the total ordering based on it will be close to the global optimal, with high probability.
Reference: [ Greiner and Elkan, 1991 ] <author> R. Greiner and C. Elkan. </author> <title> Effective representations. </title> <type> Technical report, </type> <institution> Univ. of Toronto, </institution> <year> 1991. </year>
Reference-contexts: This condition could be relaxed. In addition, the answers to questions could also provide extra information, such as a witness for an existential query, or information about the derivation path used to solve a problem. See <ref> [ Greiner and Elkan, 1991 ] </ref> . 4 We could use the t function to deal with resource requirements in general, including space usage, power consumption, etc., as well as time. 5 If the logic used by the representation has a model-theoretic semantics, the notional oracle that defines the correct answers <p> This means we can approximate the representation's true utility, with provably high probability to arbitrarily high accuracy, by watching its behavior over enough samples. Notice the estimate ^ M N 1 (R), like the real M (R), depends on the distribution of queries that R 7 <ref> [ Greiner and Elkan, 1991 ] </ref> provides the proofs for all of the lemmas and theorems presented in this short paper. will encounter; it therefore is more likely to provide a good indication of R's true utility than we would get by testing R on worst case queries, a set of <p> Due to space limitations, this short paper can only summarize a few individual algorithms associated with various type of utility measures. The extended paper, <ref> [ Greiner and Elkan, 1991 ] </ref> , presents these algorithms (and others) in detail, and proves their correctness. Improving efficiency (preserving accuracy): Suppose that a representation is producing the correct answers, but too slowly.
Reference: [ Greiner and Orponen, 1991 ] <author> R. Greiner and P. Orponen. </author> <title> Probably approximately optimal derivation strategies. In KR-91. </title> <publisher> Morgan Kaufmann, </publisher> <year> 1991. </year>
Reference-contexts: The PAO system <ref> [ Greiner and Orponen, 1991 ] </ref> is another variant of this idea: it uses a set of training examples to identify a strategy that is, with high probability, arbitrarily close to the globally optimal strategy.
Reference: [ Greiner, 1991 ] <author> R. Greiner. </author> <title> Finding the optimal derivation strategy in a redundant knowledge base. </title> <journal> Artificial Intelligence, </journal> <year> 1991. </year>
Reference-contexts: of following the hR c ; D c i path), and the frequencies of the various possible queries (e.g., that 80% of the queries would be buyCar (c1), 5% would be buyCar (c2), and 15% would be buyCar (c) for some c such that buyCar (c) is not provable; see <ref> [ Greiner, 1991 ] </ref> ). In general, we do not know this distribution information. We can, however, use a set of samples to estimate it, and use this information to determine whether R 2 would be better than R 1 , with high confidence.
Reference: [ Haussler, 1988 ] <author> D. Haussler. </author> <title> Quantifying inductive bias: AI learning algorithms and Valiant's learning framework. </title> <journal> Artificial Intelligence, </journal> <year> 1988. </year>
Reference-contexts: One obvious one is to remove the defaults (here usually called "hypotheses", etc.) that are inconsistent with the data. Essentially all inductive inference systems fit into the framework; see 9 N = "Nixon"; Q = "Quaker"; R = "Republican"; P = "Pacifist". [ Russell and Grosof, 1987 ] , <ref> [ Haussler, 1988 ] </ref> . 5 Conclusion The principal claim of many papers on knowledge representation is that one proposed representation is appropriate, or that one is better than another: e.g., that this axiomatization of liquids is good, or that this EBL process does produce improved problem-solvers, and so on.
Reference: [ Keller, 1987 ] <author> R. Keller. </author> <title> Defining operationality for explanation-based learning. </title> <booktitle> In AAAI-87, </booktitle> <year> 1987. </year>
Reference-contexts: therefore is more likely to provide a good indication of R's true utility than we would get by testing R on worst case queries, a set of concocted queries, a sample drawn randomly from a uniform distribution [ Goldberg, 1979 ] , or any particular collection of "benchmark challenge problems" <ref> [ Keller, 1987 ] </ref> . Comparing representations: If we had an analytic technique for evaluating the utility of representations with respect to a distribution of queries, and knew this distribution of queries, we could directly determine which of two representations was better.
Reference: [ Law and Kelton, 1982 ] <author> A. Law and W. </author> <title> Kelton. Simulation Modeling and Analysis. </title> <publisher> McGraw-Hill Book Co., </publisher> <year> 1982. </year>
Reference-contexts: In general we have neither analytic technique nor distribution, but we can fall back on an empirical technique | of "running" both contenders; i.e., finding the "paired-t confidence" <ref> [ Law and Kelton, 1982 ] </ref> . Lemma 2 Let ffi &gt; 0 be a given constant, and M () 2 U be a utility measure.
Reference: [ Levesque and Brachman, 1985 ] <author> H. Levesque and R. Brach-man. </author> <title> A fundamental tradeoff in knowledge representation and reasoning. </title> <booktitle> In Readings in Knowledge Representation. </booktitle> <publisher> Morgan Kaufmann Publishers, Inc., </publisher> <year> 1985. </year>
Reference: [ Levesque, 1986 ] <author> H. Levesque. </author> <title> Making believers out of computers. </title> <journal> Artificial Intelligence, </journal> <volume> 30(1), </volume> <year> 1986. </year>
Reference: [ Mitchell et al., 1986 ] <author> T. Mitchell, R. Keller, and S. Kedar-Cabelli. </author> <title> Example-based generalization: A unifying view. </title> <journal> Machine Learning, </journal> <volume> 1(1), </volume> <year> 1986. </year>
Reference: [ Nagel and Newman, 1958 ] <author> E. Nagel and J. Newman. </author> <title> Godel's Proof. </title> <publisher> New York University Press, </publisher> <year> 1958. </year>
Reference: [ Przymusinski, 1987 ] <author> T. Przymusinski. </author> <title> On the declarative semantics of stratified deductive databases and logic programs. In Foundations of Deductive Databases and Logic Programming. </title> <publisher> Morgan Kaufmann Pub., Inc., </publisher> <year> 1987. </year>
Reference-contexts: 1 : F (x) P (x): :F (x) , one could conclude either F (T), based on the first fact and first default, d 1 ; or :F (T), based on the second fact and second default, d 2 . 8 One way around this problem involves prioritizing the defaults <ref> [ Przymusinski, 1987; Brewka, 1989 ] </ref> . Here, for example, we could specify d 2 d 1 , meaning we should use the d 2 default if it applies, and only if it does not should we consider d 1 .
Reference: [ Reiter, 1987 ] <author> R. Reiter. </author> <title> Nonmonotonic reasoning. </title> <booktitle> In Annual Review of Computing Sciences, </booktitle> <volume> volume 2. </volume> <publisher> Annual Reviews Incorporated, </publisher> <year> 1987. </year>
Reference-contexts: This paper gives operational criteria for evaluating the goodness of a "representation". 1 Many areas of AI research can use these results. For example, many papers on nonmono-tonic logic <ref> [ Reiter, 1987 ] </ref> implicitly or explicitly make the claim that one formalism leads to better representations fl Supported by an Operating Grant from Canada's Natural Science and Engineering Research Council. <p> None, however, have explicitly quantified the tradeoffs. Improving accuracy (ignoring efficiency): One standard issue with default logic is the "multiple extension problem" <ref> [ Reiter, 1987 ] </ref> : For example, knowing the facts F 1 = fB (T); P (T)g and the defaults D 1 = d 1 : F (x) P (x): :F (x) , one could conclude either F (T), based on the first fact and first default, d 1 ; or
Reference: [ Russell and Grosof, 1987 ] <author> S. Russell and B. Grosof. </author> <title> A declarative approach to bias in concept learning. </title> <booktitle> In AAAI-87, </booktitle> <year> 1987. </year>
Reference-contexts: One obvious one is to remove the defaults (here usually called "hypotheses", etc.) that are inconsistent with the data. Essentially all inductive inference systems fit into the framework; see 9 N = "Nixon"; Q = "Quaker"; R = "Republican"; P = "Pacifist". <ref> [ Russell and Grosof, 1987 ] </ref> , [ Haussler, 1988 ] . 5 Conclusion The principal claim of many papers on knowledge representation is that one proposed representation is appropriate, or that one is better than another: e.g., that this axiomatization of liquids is good, or that this EBL process does
Reference: [ Segre, 1988 ] <editor> A. Segre. </editor> <booktitle> Operationality and real-world plans. In AAAI Workshop on Explanation-Based Learning, </booktitle> <year> 1988. </year>
Reference-contexts: The three dimensions of merit listed above are not exhaustive: i.e., they do not span the space of external criteria of merit for representations. In particular, <ref> [ Segre, 1988 ] </ref> identifies a number of further dimensions of merit that are important if the world being modeled by the representation is uncertain. Our dimensions are still quite general; we show below that linear combinations cover many standard situations.
Reference: [ Selman and Kautz, 1988 ] <author> B. Selman and H. Kautz. </author> <title> The complexity of model-preference default theories. </title> <booktitle> In CSCSI-88, </booktitle> <year> 1988. </year>
Reference: [ Selman and Kautz, 1991 ] <author> B. Selman and H. Kautz. </author> <title> Knowledge compilation using horn approximations. </title> <booktitle> In AAAI-91, </booktitle> <year> 1991. </year>
Reference-contexts: [2] Several previous systems have implicitly dealt with this theme, of gaining efficiency at the expense of accuracy or categoricity; see [ Cohen, 1990 ] , [ Subramanian and Genesereth, 1987 ] , [ Levesque, 1986; Selman and Kautz, 1988; Etherington et al., 1989; Borgida and Etherington, 1989 ] , <ref> [ Selman and Kautz, 1991 ] </ref> . None, however, have explicitly quantified the tradeoffs.
Reference: [ Simon, 1981 ] <editor> H. Simon. </editor> <booktitle> The Sciences of the Artificial. </booktitle> <publisher> M.I.T. Press, </publisher> <year> 1981. </year>
Reference: [ Subramanian and Genesereth, 1987 ] <author> D. Subramanian and M. Genesereth. </author> <title> The relevance of irrelevance. </title> <booktitle> In IJCAI-87, </booktitle> <year> 1987. </year>
Reference-contexts: each node corresponds to a literal, and one descending arc indicates that this literal should be positive, and other, that is should be negative. [2] Several previous systems have implicitly dealt with this theme, of gaining efficiency at the expense of accuracy or categoricity; see [ Cohen, 1990 ] , <ref> [ Subramanian and Genesereth, 1987 ] </ref> , [ Levesque, 1986; Selman and Kautz, 1988; Etherington et al., 1989; Borgida and Etherington, 1989 ] , [ Selman and Kautz, 1991 ] . None, however, have explicitly quantified the tradeoffs.
References-found: 30

