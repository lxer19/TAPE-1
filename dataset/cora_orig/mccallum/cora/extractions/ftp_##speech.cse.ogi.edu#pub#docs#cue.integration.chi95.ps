URL: ftp://speech.cse.ogi.edu/pub/docs/cue.integration.chi95.ps
Refering-URL: http://www.cse.ogi.edu/CSLU/publications/publications.html
Root-URL: http://www.cse.ogi.edu
Email: wardk@cse.ogi.edu,  
Title: CHI 95 Integrating Multiple Cues for Spoken Language Understanding  
Author: Karen Ward and David G. Novick 
Keyword: Spoken language interfaces  
Note: (503) 690-1121  
Address: 20000 NW Walker Road, Beaverton, Oregon 97006 USA  
Affiliation: Oregon Graduate Institute of Science Technology  
Abstract: As spoken language interfaces for real-world systems become a practical possibility, it has become apparent that such interfaces will need to draw on a variety of cues from diverse sources to achieve a robustness and naturalness approaching that of human performance [1]. However, our knowledge of how these cues behave in the aggregate is still tantalizingly sketchy. We lack a strong theoretical basis for predicting which cues will prove useful in practice and for specifying how these cues should be combined to signal or cancel out potential interpretations of the communicative signal. In the research program summarized here, we propose to develop and test an initial theory of cue integration for spoken language interfaces. By establishing a principled basis for integrating knowledge sources for such interfaces, we believe that we can develop systems that perform better from a computer-human interaction standpoint. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Cole, R. A., Hirschman, L. </author> <title> et al (1992). </title> <booktitle> Workshop on Spoken Language Understanding, </booktitle> <institution> Oregon Graduate Institute Technical Report No. CS/E 92-014. </institution>
Reference: [2] <author> Goodine, D., Hirschman, L., Polifroni, J., Senef f, S., & Zue, V. </author> <year> (1992). </year> <title> Evaluating Interactive Spoken Language Systems, </title> <booktitle> Proceedings of the 1992 International Conference on Spoken Language pr ocessing (ICSLP 92), </booktitle> <pages> pp. 197-200. </pages>
Reference-contexts: Our research program, therefore, calls for understanding how various cues contribute to system performance in the context of spoken language interfaces to task-oriented mixed-initiative systems. We furthermore join others (e.g., <ref> [2] </ref>) in asserting that such systems are best evaluated as interfaces and judged in terms of their success in supporting users in accomplishing tasks. <p> We plan to use a within-subject design with each subject using both versions of the system to complete several tasks. Metrics will be slightly modified from those proposed by Goodine et al <ref> [2] </ref>: Task completion, Task completion time, Correctness of solution, Number of turns, User satisfaction (from debriefing questionnaire). A second experiment will probe details of the cue interrelationships. Subjects will complete several scheduling tasks using versions of the system in which one or more of the cues are ignored.
Reference: [3] <author> Howells, T., Friedman, D., & Fanty , M. </author> <year> (1992). </year> <title> Broca, An Integrated Parser for Spoken Language, </title> <booktitle> Proceedings of the 1992 International Confer ence on Spoken Language processing (ICSLP 92) , pp. </booktitle> <pages> 325-328. </pages>
Reference-contexts: INTRODUCTION Historically, spoken language understanding research developed from the speech recognition (SR) tradition with its emphasis on identifying words and phrases. Current systems have largely evolved through a series of heuristics-driven enhancements to existing speech recognizers (e.g., <ref> [3] </ref>, [4], [9]). This evolution has led to what we term the SR bias, an emphasis on getting the words right as the measurable goal of a spoken language component; system enhancements are viewed as improving the performance of the recognizer.
Reference: [4] <author> Issar, S. & Ward, W. </author> <year> (1993). </year> <title> CMUs Robust Spoken Language Understanding System, </title> <booktitle> Eurospeech 93, </booktitle> <pages> pp. 2147-2150. </pages>
Reference-contexts: INTRODUCTION Historically, spoken language understanding research developed from the speech recognition (SR) tradition with its emphasis on identifying words and phrases. Current systems have largely evolved through a series of heuristics-driven enhancements to existing speech recognizers (e.g., [3], <ref> [4] </ref>, [9]). This evolution has led to what we term the SR bias, an emphasis on getting the words right as the measurable goal of a spoken language component; system enhancements are viewed as improving the performance of the recognizer.
Reference: [5] <author> Nakajima, S. & Allen, J. </author> <year> (1993). </year> <title> A Study on Prosody and Discourse Structure in Cooperative Dialogues, </title> <type> Rochester Tech Report No TRAINS-TN93-2, </type> <month> Sept. </month> <year> 1993. </year>
Reference-contexts: Pitch changes offer additional cues about the speaker s intentions. Pierrehumbert and Hirschberg [7] proposed that phrasal tunes signal relationships between the propositional content and the mutual beliefs of the participants. More specifically, Nakajima and Allen <ref> [5] </ref> examined the relationship between fundamental frequency (F0) and discourse structure in spontaneous task-oriented dialogue and found that F0 values tend to signal topic shift and topic continuation across pause boundaries.
Reference: [6] <author> Novick, D. G. & Sutton, S. </author> <year> (1994). </year> <title> An Empirical Model of Acknowledgment for Spoken-Language Systems, </title> <booktitle> in Proceedings of the 32nd Annual meeting of the Association for Computational Linguistics , pp 96-101. </booktitle>
Reference: [7] <author> Pierrehumbert, J. & Hirschberg, J. </author> <year> (1990). </year> <title> The Meaning of Intonational Contours in the Interpretation of Discourse, in Intentions in Communication, </title> <editor> P. Cohen, J. Morgan, & M. Pollack (Eds.), </editor> <volume> Chapter 14, </volume> <pages> pp 271-311, </pages> <address> Cambridge, </address> <publisher> MS:MIT Press. </publisher>
Reference-contexts: Pause length is a strong marker for syntactic structure in professionally read speech ([8], [10]). We lack computational models for understanding pause cues in spontaneous speech, however; existing systems simply ignore pause. Pitch changes offer additional cues about the speaker s intentions. Pierrehumbert and Hirschberg <ref> [7] </ref> proposed that phrasal tunes signal relationships between the propositional content and the mutual beliefs of the participants. <p> More specifically, Nakajima and Allen [5] examined the relationship between fundamental frequency (F0) and discourse structure in spontaneous task-oriented dialogue and found that F0 values tend to signal topic shift and topic continuation across pause boundaries. Pitch accents mark salient material <ref> [7] </ref>, which may be useful not only in interpreting the intention behind the utterance but also in locating critical content words for recognition purposes.
Reference: [8] <author> Price, P., Ostendorf, M., Shattuck-Hufnagel, S., & Fong, C. </author> <year> (1991). </year> <title> The Use of Prosody in Syntactic Disambiguation, </title> <booktitle> in Proceedings of the Fourth DARPA Workshop on Speech and Natural Language , ed. Patti Price. </booktitle>
Reference: [9] <author> Seneff, S. </author> <year> (1992). </year> <title> TINA: A Natural Language System for Spoken Language Applications, </title> <journal> Computational Linguistics, </journal> <volume> Vol 18, No. 1, </volume> <pages> pp 61-86. </pages>
Reference-contexts: INTRODUCTION Historically, spoken language understanding research developed from the speech recognition (SR) tradition with its emphasis on identifying words and phrases. Current systems have largely evolved through a series of heuristics-driven enhancements to existing speech recognizers (e.g., [3], [4], <ref> [9] </ref>). This evolution has led to what we term the SR bias, an emphasis on getting the words right as the measurable goal of a spoken language component; system enhancements are viewed as improving the performance of the recognizer.
Reference: [10] <author> Wang, M. Q. & Hirschberg, J., </author> <title> Automatic Classification of Intonational Phrase Boundaries, </title> <booktitle> Computer Speech and Language, </booktitle> <volume> Vol. 6, </volume> <pages> pp. 175-196. </pages>
Reference-contexts: Current systems rely primarily on lexicalization to signal speaker intention, with the context of the preceding utterance providing additional constraints (e.g., [13]). Pause length is a strong marker for syntactic structure in professionally read speech ([8], <ref> [10] </ref>). We lack computational models for understanding pause cues in spontaneous speech, however; existing systems simply ignore pause. Pitch changes offer additional cues about the speaker s intentions. Pierrehumbert and Hirschberg [7] proposed that phrasal tunes signal relationships between the propositional content and the mutual beliefs of the participants.
Reference: [11] <author> Ward, K. & Novick, D. G. </author> <year> (1994). </year> <title> On the Need for a Theory of Integration of Knowledge Sources for Spoken Language Understanding. </title> <booktitle> Proceedings of the AAAI-94 Workshop on the Integration of Natural Language and Speech Processing, </booktitle> <month> July </month> <year> 1994, </year> <pages> pp. 23-30. </pages>
Reference-contexts: Recently we have seen an increase in research probing specific relationships between some of the knowledge sources used in spoken communication; a brief review may be found in <ref> [11] </ref>. In summary, however, we note that although several studies have shown relationships between pairs of various potential cues, none have attempted to study more complex interactions or to test the practical application of their findings in a working system.
Reference: [12] <author> Ward, K. & Novick, D. G. </author> <year> (1995). </year> <title> Prosodic Cues to Word Usage. </title> <note> to appear in ICASSP-95. </note>
Reference-contexts: The usefulness of this finding lies in considering local pitch change as one of several redundant cues. For example, the direction of pitch change could serve as a confirming cue when analyzing ambiguous or erroneous recog-nizer output. Details of this study may be found in <ref> [12] </ref>. We are now expanding the prosodic study to encompass other acknowledgment acts and to account for the contribution of the four cues identif ied above in recognizing acknowledgments in mixed-initiative task-oriented dialogue.
Reference: [13] <author> Young, S. & Ward, W. </author> <year> (1993). </year> <title> Semantic and Pragmatically Based Re-Recognition of Spontaneous Speech, </title> <booktitle> Eurospeech 93, </booktitle> <pages> pp. 2243-2246. </pages>
Reference-contexts: In this research program we are studying the interrelationships of four cues: Pause length, Simplified intonational contour (pitch change), Context of the preceding speech act, Lexicalization (word choice). Current systems rely primarily on lexicalization to signal speaker intention, with the context of the preceding utterance providing additional constraints (e.g., <ref> [13] </ref>). Pause length is a strong marker for syntactic structure in professionally read speech ([8], [10]). We lack computational models for understanding pause cues in spontaneous speech, however; existing systems simply ignore pause. Pitch changes offer additional cues about the speaker s intentions.
References-found: 13

