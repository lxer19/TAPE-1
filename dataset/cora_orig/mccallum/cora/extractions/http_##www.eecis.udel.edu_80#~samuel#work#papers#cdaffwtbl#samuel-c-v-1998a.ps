URL: http://www.eecis.udel.edu:80/~samuel/work/papers/cdaffwtbl/samuel-c-v-1998a.ps
Refering-URL: http://www.eecis.udel.edu:80/~samuel/work/papers/cdaffwtbl/index.html
Root-URL: http://www.cis.udel.edu
Email: fsamuel,carberry,vijayg@cis.udel.edu  
Title: COMPUTING DIALOGUE ACTS FROM FEATURES WITH TRANSFORMATION-BASED LEARNING  
Author: Ken Samuel, Sandra Carberry, and K. Vijay-Shanker 
Web: http://www.eecis.udel.edu/~fsamuel,carberry,vijayg/  
Address: 19716 USA  
Affiliation: Department of Computer and Information Sciences University of Delaware Newark, Delaware  
Abstract: To interpret natural language at the discourse level, it is very useful to accurately recognize dialogue acts, such as SUGGEST, in identifying speaker intentions. Our research explores the utility of a machine learning method called Transformation-Based Learning (TBL) in computing dialogue acts, because TBL has a number of advantages over alternative approaches for this application. We have identified some extensions to TBL that are necessary in order to address the limitations of the original algorithm and the particular demands of discourse processing. We use a Monte Carlo strategy to increase the applicability of the TBL method, and we select features of utterances that can be used as input to improve the performance of TBL. Our system is currently being tested on the VerbMobil corpora of spoken dialogues, producing promising preliminary results. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Alexandersson, J.; Maier, E.; and Reithinger, N. </author> <year> 1995. </year> <title> A robust and efficient three-layered dialogue component for a speech-to-speech translation system. </title> <booktitle> In Proceedings of the European Association for Computational Linguistics. </booktitle>
Reference: <author> Andernach, T. </author> <year> 1996. </year> <title> A machine learning approach to the classification of dialogue utterances. </title> <booktitle> In Proceedings of NeMLaP-2. </booktitle>
Reference: <author> Brill, E. </author> <year> 1995a. </year> <title> Transformation-based error-driven learning and natural language processing: A case study in part-of-speech tagging. </title> <booktitle> Computational Linguistics 21(4) </booktitle> <pages> 543-566. </pages>
Reference-contexts: Transformation-Based Learning Brill introduced the TBL method and showed that it is very effective on the part-of-speech tagging problem 2 ; it achieved accuracy rates as high as 97.2%, which is as good as or better than any other results reported for this task <ref> (Brill 1995a) </ref>. Computing part-of-speech tags and computing dialogue acts are similar processes, in that a part-of-speech tag is dependent on the surrounding words, while a dialogue act is dependent on the surrounding utterances. <p> can fix the tag of a given utterance, most of which are completely unrelated to the task at hand. 7 5 Typically, the stopping criterion is to terminate training when no rule can be found that improves the tagging accuracy on the training corpus by more than some predetermined threshold <ref> (Brill 1995a) </ref>. 6 The score measures the amount of improvement in the tagging accuracy of the training corpus that would result from including a given rule in the final model (Brill 1995a). 7 For example, the following rule would correctly tag utterance B 2 in Figure 1: IF the third letter <p> no rule can be found that improves the tagging accuracy on the training corpus by more than some predetermined threshold <ref> (Brill 1995a) </ref>. 6 The score measures the amount of improvement in the tagging accuracy of the training corpus that would result from including a given rule in the final model (Brill 1995a). 7 For example, the following rule would correctly tag utterance B 2 in Figure 1: IF the third letter in the second word of the utterance is "s", THEN change the utterance's tag to SUGGEST.
Reference: <author> Brill, E. </author> <year> 1995b. </year> <title> Unsupervised learning of disambiguation rules for part of speech tagging. </title> <booktitle> In Proceedings of the Very Large Corpora Workshop. </booktitle>
Reference-contexts: Brill developed an unsupervised version of TBL for part-of-speech tagging, but this algorithm requires examples that can be tagged unambiguously, such as "the", which is always a determiner <ref> (Brill 1995b) </ref>. Unfortunately, in discourse, we have few unambiguous examples. But we intend to examine the potential of the following weakly-supervised version of TBL. The system is first trained on a small set of tagged data to produce a few models.
Reference: <author> Chen, K.-h. </author> <year> 1995. </year> <title> Topic identification in discourse. </title> <booktitle> In Proceedings of the Seventh Meeting of the European Association for Computational Linguistics, </booktitle> <pages> 267-271. </pages>
Reference: <author> Dagan, I., and Engelson, S. P. </author> <year> 1995. </year> <title> Committee-based sampling for training probabilistic classifiers. </title> <booktitle> In Proceedings of the International Conference on Machine Learning, </booktitle> <pages> 150-157. </pages>
Reference: <author> Hinkelman, E. A. </author> <year> 1990. </year> <title> Linguistic and Pragmatic Constraints on Utterance Interpretation. </title> <type> Ph.D. Dissertation, </type> <institution> University of Rochester, Rochester, New York. </institution> <type> Tech Report: UR CS TR #238. </type>
Reference: <author> Hirschberg, J., and Litman, D. </author> <year> 1993. </year> <title> Empirical studies on the disambiguation of cue phrases. </title> <booktitle> Computational Linguistics 19(3) </booktitle> <pages> 501-530. </pages>
Reference-contexts: These researchers have each used traditional methods to produce a list of cue phrases; a survey of these lists is presented in Hirschberg and Litman <ref> (Hirschberg & Litman 1993) </ref>. It may be possible to use the power of machine learning to generate an effective list of cue phrases automatically.
Reference: <author> Lambert, L. </author> <year> 1993. </year> <title> Recognizing Complex Discourse Acts: A Tripartite Plan-Based Model of Dialogue. </title> <type> Ph.D. Dissertation, </type> <institution> The University of Delaware, Newark, Delaware. </institution> <type> Tech Report: </type> <pages> 93-19. </pages>
Reference: <author> Mast, M.; Niemann, H.; Noeth, E.; and Schukat-Talamazzini, E. G. </author> <year> 1995. </year> <title> Automatic classification of dialog acts with semantic classification trees and polygrams. </title> <booktitle> In Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence, </booktitle> <pages> 71-78. </pages> <booktitle> New Approaches to Learning for Natural Language Processing Workshop. </booktitle>
Reference: <author> Nagata, M., and Morimoto, T. </author> <year> 1994a. </year> <title> First steps toward statistical modeling of dialogue to predict the speech act type of the next utterance. </title> <booktitle> Speech Communication 15 </booktitle> <pages> 193-203. </pages>
Reference: <author> Nagata, M., and Morimoto, T. </author> <year> 1994b. </year> <title> An information-theoretic model of discourse for next utterance type prediction. </title> <journal> Transactions of Information Processing Society of Japan 35(6) </journal> <pages> 1050-1061. </pages>
Reference: <author> Ramshaw, L. A., and Marcus, M. P. </author> <year> 1994. </year> <title> Exploring the statistical derivation of transformation rule sequences for part-of-speech tagging. </title> <booktitle> In Proceedings of the 32nd Annual Meeting of the ACL, </booktitle> <pages> 86-95. </pages> <booktitle> Balancing Act Workshop. </booktitle>
Reference-contexts: Ramshaw and Marcus <ref> (Ramshaw & Marcus 1994) </ref> compared TBL with DTs and reported two advantages of TBL: Leveraged Learning: In the middle of a training session, TBL can use the tags that have already been computed to help in computing other tags, while DTs cannot make use of this type of information. <p> Discarding Irrelevant Input: If an HMM is given access to information that happens to be irrelevant to the task at hand, 9 its performance suffers. This is because the irrelevant information interferes with the important features of the input in a fully-connected network. But, as Ramshaw and Mar-cus <ref> (Ramshaw & Marcus 1994) </ref> showed experimentally, TBL's success is largely unaffected by irrelevant features in the input. This is because rules that consider relevant features generally improve the tags in the training corpus, while the effect of rules without any relevant features is completely random.
Reference: <author> Reithinger, N., and Klesen, M. </author> <year> 1997. </year> <title> Dialogue act classification using language models. </title> <booktitle> In Proceedings of EuroSpeech-97, </booktitle> <pages> 2235-2238. </pages>
Reference-contexts: Further information about this work is presented in another paper (Samuel 1998). Early Results & Planned Improvements We have implemented the TBL algorithm outlined above, and we are currently testing it on the Verb-Mobil corpora of face-to-face dialogues <ref> (Reithinger & Klesen 1997) </ref>, which consist of dialogues with utterances that have been hand-tagged with one of 42 dialogue acts.
Reference: <author> Reithinger, N., and Maier, E. </author> <year> 1995. </year> <title> Utilizing statistical dialogue act processing in verbmobil. </title> <booktitle> In Proceedings of the 33rd Annual Meeting of the ACL, </booktitle> <pages> 116-121. </pages>
Reference: <author> Reithinger, N.; Engel, R.; Kipp, M.; and Klesen, M. </author> <year> 1996. </year> <title> Predicting dialogue acts for a speech-to-speech translation system. </title> <type> Technical Report Verbmobil-Report 151, </type> <institution> DFKI GmbH Saarbruecken. </institution>
Reference: <author> Samuel, K. B. </author> <year> 1996. </year> <title> Using statistical learning algorithms to compute discourse information. </title> <type> Technical Report #97-11, </type> <institution> The University of Delaware. </institution>
Reference-contexts: Given sufficient 9 For example, the third letter of the second word of each utterance is unlikely to be relevant to the task of computing dialogue acts. 10 Several researchers have proposed different features, as we discussed in previous work <ref> (Samuel 1996) </ref>. But these sets of features are likely to have errors and omissions. <p> Then, given new data, each model independently tags the input, and the responses are compared. For a given tag, the confidence measure is a function of the agreement among the different mod els on that tag. <ref> (Samuel 1996) </ref> Weakly-Supervised Learning: When there is not enough tagged training data available, we would like the system to be capable of training with untagged data.
Reference: <author> Samuel, K. </author> <year> 1998. </year> <title> Lazy transformation-based learning. </title> <booktitle> In Proceedings of FLAIRS. </booktitle>
Reference-contexts: Thus, the Monte Carlo extension enhances TBL, so that it works efficiently and effectively with thousands of templates, thereby increasing the applicability of the TBL method. Further information about this work is presented in another paper <ref> (Samuel 1998) </ref>. Early Results & Planned Improvements We have implemented the TBL algorithm outlined above, and we are currently testing it on the Verb-Mobil corpora of face-to-face dialogues (Reithinger & Klesen 1997), which consist of dialogues with utterances that have been hand-tagged with one of 42 dialogue acts.
References-found: 18

