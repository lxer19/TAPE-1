URL: http://www.medg.lcs.mit.edu/mpf/ftp/term-paper.ps
Refering-URL: http://www.medg.lcs.mit.edu/mpf/RAS-abstract.html
Root-URL: 
Email: Email: mpf@medg.lcs.mit.edu  
Title: Rational partial state-graph search  
Author: Michael P. Frank 
Affiliation: MIT Lab for Computer Science  
Date: May 19, 1993 1  
Note: Rational partial state-graph search  
Abstract: The AI technique of searching through trees or graphs of neighboring states in a state-space has been used for many years in game-playing and problem-solving domains. For many of these domains, the state-spaces are too large to search completely; there is only time for a partial state-space search. Any partial search technique must address two issues: what part of the space do we search, and how do we obtain useful information from a partially-searched space? Recently, a number of research groups have developed rational techniques, by which I mean ones based on decision theoretic principles, that answer one or both of these questions. These researchers have argued convincingly that their rational approaches improve on the non-decision-theoretic techniques previously used for partial state-space search. In this paper, I will survey work in this area by researchers such Hansson & Mayer, Russell & Wefald, and Baum & Smith, with an emphasis on the latter, since it subsumes much of the earlier work. I will conclude with some speculations on how to apply the principles learned from rational state-space search to do abstract reasoning that transcends the state-space paradigm. 
Abstract-found: 1
Intro-found: 1
Reference: [these need a little work still] 
Reference: [1] <author> Eric B. Baum and Warren D. Smith, </author> <title> Best Play for Imperfect Players and Game Tree Search, </title> <type> unpublished draft report. </type>
Reference: [2] <author> Russell & Wefald, </author> <booktitle> Principles of Metareasoning </booktitle>
Reference-contexts: BPS is a well-justified way to use heuristic node values, but it says nothing about how to grow a good tree. 3.0.1 Russell & Wefalds MGSS* Finally, a method for rational game-tree growth was described by Stuart Russell and Eric Wefald and implemented in their program MGSS* <ref> [2] </ref>. Russell and Wefald had a number of new fundamental insights. One was to characterize the problem of tree growth in terms of a meta-level search of possible sequences of computational actions, just as base-level game playing characterizes the problem in terms of a search of sequences of game actions.
Reference: [3] <author> Judea Pearl, </author> <title> Heuristics </title>
Reference-contexts: Thus A* might be a poor algorithm if time is important. There have been various tweaks to these sorts of algorithms to improve their performance, such as alpha-beta search with iterative deepening. There are also many similar alternative algorithms, such as Pearls SCOUT <ref> [3] </ref>. However, in game playing, there was, for a long time nothing that did any sort of selective search control. Then ad-hoc methods for selective game-search, such as singular extensions, were developed. <p> The dominant method for handling uncertainty about the true value of nodes has been in terms of probability. Berliner proposed the B* algorithm [7], which worked with bounds on the probability of winning, rather than definite values. Pearl described in <ref> [3] </ref> how to use entire probability distributions over the space of game outcomes, under the assumption that distributions at Rational partial state-graph search May 19, 1993 8 different leaves are independent.
Reference: [4] <institution> Rons thesis </institution>
Reference-contexts: Games are assumed to have only two players. Moves are made in a definite sequence, rather than simultaneously. There is always a definite player whose turn it is to move. Work by Ronald Bodkin has shown how to loosen these assumptions and generalize some of the traditional game-playing algorithms <ref> [4] </ref>. Can this be done for Baum and Smiths approach as well? It seems likely that work can be done along these lines; generalizing scalar outcome-values to payoff vectors, generalizing move lists to multi-player move matrices, etc.
Reference: [5] <institution> McAllesters conspiracy numbers paper </institution>
Reference-contexts: There are also many similar alternative algorithms, such as Pearls SCOUT [3]. However, in game playing, there was, for a long time nothing that did any sort of selective search control. Then ad-hoc methods for selective game-search, such as singular extensions, were developed. David McAllester <ref> [5] </ref> proposed a more unified, general, well-justified alternative to these methods, called conspiracy search, which roughly measured which parts of the search tree, if explored more deeply, would be most likely to have an important effect on our current situation.
Reference: [6] <institution> A Hansson & Mayer paper on games </institution>
Reference-contexts: However, like minimax, these distributions were over what the node value would be if we assumed perfect play by other players. Other Hansson and Andrew Mayer <ref> [6] </ref> described a system called BPS (Bayesian problem solver) in which an ordinary evaluation function on nodes could be considered as evidence, in the Bayesian sense, of the nodes true value; the probability distributions over nodes values can then propagated through a tree like in a Bayesian belief network.
Reference: [7] <institution> Berliner reference from Pearl </institution>
Reference-contexts: Meanwhile, other researchers were looking at ways to define tree evaluation in ways that didnt make minimaxs assumption of correct heuristic leaf values. The dominant method for handling uncertainty about the true value of nodes has been in terms of probability. Berliner proposed the B* algorithm <ref> [7] </ref>, which worked with bounds on the probability of winning, rather than definite values. Pearl described in [3] how to use entire probability distributions over the space of game outcomes, under the assumption that distributions at Rational partial state-graph search May 19, 1993 8 different leaves are independent.
Reference: [8] <author> Barney Pell, </author> <type> Ph.D. thesis </type>
Reference-contexts: So, if we abandon comparison against programs in well-established narrow domains as a good basis for evaluating AI techniques, how can we evaluate our methods? One solution, proposed by Barney Pell in <ref> [8] </ref>, is to try to establish a new, broader competitive problem domain; one for which even a program that was very domain-specific would still need lots of general reasoning mechanisms. Another idea, which is easier because it can be implemented on the individual level, is as follows: 1.
Reference: [9] <author> Warren D. Smith, </author> <title> Approximation of staircases by staircases </title>
Reference-contexts: Recall that they assume the exact amount of deeper search not to be very important. They compress the set of data-points in each bin into a simpler representation of the distribution of points; the exact method for this is described in a separate paper <ref> [9] </ref>. 4.1.5 Backing up distributions Baum and Smiths method for quickly backing up distributions depends heavily on the particular staircase (the S in DFISA) representation that they use.

References-found: 10

