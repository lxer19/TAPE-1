URL: http://cobar.cs.umass.edu/pubfiles/cvpr94.ps.gz
Refering-URL: http://cobar.cs.umass.edu/pubfiles/
Root-URL: 
Email: manmatha@cs.umass.edu  
Title: A Framework for Recovering Affine Transforms Using Points, Lines or Image Brightnesses find scale changes
Author: R. Manmatha 
Note: Experiments demonstrate that this technique can  
Address: Amherst, Amherst, MA-01002  
Affiliation: Computer Science Department University of Massachusetts at  
Abstract: Image deformations due to relative motion between an observer and an object may be used to infer 3-D structure. Up to first order these deformations can be written in terms of an affine transform. Here, a new framework for measuring affine transforms which correctly handles the problem of corresponding deformed patches is presented. In this framework, points, lines or image brightnesses may be used to derive the affine transform between image patches. No correspondence is required. The patches are filtered using gaussians and derivatives of gaussians and the filters deformed according to the affine transform. The problem of finding the affine transform is therefore reduced to that of finding the appropriate deformed filter to use. The method is local and can handle large affine deformations. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J.R. Bergen, P. Anandan, K. J. Hanna, and R. Hingo rani. </author> <title> Hierarchical model-based motion estimation. </title> <booktitle> In Proc. 2nd European Conference on Computer Vision, </booktitle> <pages> pages 237-252, </pages> <year> 1992. </year>
Reference-contexts: By linearizing the image intensities or the fil ter outputs with respect to the image coordinates. Linearization limits these algorithms to cases when the affine transforms are small. This linearization does not account for the deformation due to the affine transform. <ref> [1, 2, 10, 11] </ref> (Note that [10] essentially re-discovered the method due to [1]). 2. Matching image intensities by searching through the space of all affine parameters. This approach adopts a brute force search strategy which is potentially slow [4]. 3. <p> Linearization limits these algorithms to cases when the affine transforms are small. This linearization does not account for the deformation due to the affine transform. [1, 2, 10, 11] (Note that [10] essentially re-discovered the method due to <ref> [1] </ref>). 2. Matching image intensities by searching through the space of all affine parameters. This approach adopts a brute force search strategy which is potentially slow [4]. 3. Line based methods which match the closed boundaries of corresponding regions [3, 9]. <p> The equation clearly shows that to recover affine transforms by filtering, one must deform the filter appropriately; a point ignored in previous work <ref> [1, 2, 11, 4] </ref>. The equation is local because the gaussians rapidly decay. The integral may be interpreted as the result of convolving the function with a gaussian at the origin. It may also be interpreted as the result of a filtering operation with a gaussian. <p> A number of methods incorporate the idea of filtering at many points <ref> [1, 2, 10] </ref>. However, none of these compensate for the deformation terms (in essence the difference between the traditional linearization methods and the technique presented here are the additional second derivative terms). Translation may be incorporated as before.
Reference: [2] <author> M. Campani and A. Verri. </author> <title> Motion analysis from opti cal flow. </title> <booktitle> Computer Vision Graphics and Image Pro-cessing:Image Understanding, </booktitle> <volume> 56(12) </volume> <pages> 90-107, </pages> <year> 1992. </year>
Reference-contexts: By linearizing the image intensities or the fil ter outputs with respect to the image coordinates. Linearization limits these algorithms to cases when the affine transforms are small. This linearization does not account for the deformation due to the affine transform. <ref> [1, 2, 10, 11] </ref> (Note that [10] essentially re-discovered the method due to [1]). 2. Matching image intensities by searching through the space of all affine parameters. This approach adopts a brute force search strategy which is potentially slow [4]. 3. <p> The equation clearly shows that to recover affine transforms by filtering, one must deform the filter appropriately; a point ignored in previous work <ref> [1, 2, 11, 4] </ref>. The equation is local because the gaussians rapidly decay. The integral may be interpreted as the result of convolving the function with a gaussian at the origin. It may also be interpreted as the result of a filtering operation with a gaussian. <p> A number of methods incorporate the idea of filtering at many points <ref> [1, 2, 10] </ref>. However, none of these compensate for the deformation terms (in essence the difference between the traditional linearization methods and the technique presented here are the additional second derivative terms). Translation may be incorporated as before.
Reference: [3] <author> R. Cipolla and A. Blake. </author> <title> Surface orientation and time to contact from image divergence and deformation. </title> <booktitle> In Proc. 2nd European Conference on Computer Vision, </booktitle> <pages> pages 187-202, </pages> <year> 1992. </year>
Reference-contexts: Matching image intensities by searching through the space of all affine parameters. This approach adopts a brute force search strategy which is potentially slow [4]. 3. Line based methods which match the closed boundaries of corresponding regions <ref> [3, 9] </ref>. Of these approaches, only the third deals with the problem of corresponding deformed patches. However, it is limited to homogenous regions with closed boundaries. Patches deformed under similarity transforms may also be matched using the Mellin-Fourier Transform ([5]).
Reference: [4] <author> D. G. Jones and J. Malik. </author> <title> A computational frame work for determining stereo correspondence from a set of linear spatial filters. </title> <booktitle> In Proc. 2nd European Conference on Computer Vision, </booktitle> <pages> pages 395-410, </pages> <year> 1992. </year>
Reference-contexts: Matching image intensities by searching through the space of all affine parameters. This approach adopts a brute force search strategy which is potentially slow <ref> [4] </ref>. 3. Line based methods which match the closed boundaries of corresponding regions [3, 9]. Of these approaches, only the third deals with the problem of corresponding deformed patches. However, it is limited to homogenous regions with closed boundaries. <p> The equation clearly shows that to recover affine transforms by filtering, one must deform the filter appropriately; a point ignored in previous work <ref> [1, 2, 11, 4] </ref>. The equation is local because the gaussians rapidly decay. The integral may be interpreted as the result of convolving the function with a gaussian at the origin. It may also be interpreted as the result of a filtering operation with a gaussian.
Reference: [5] <author> J. Rubinstein J.Segman and Y.Y. Zeevi. </author> <title> The canoni cal coordinates method for pattern deformation: Theoretical and computational considerations. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 14(12) </volume> <pages> 1171-1183, </pages> <year> 1992. </year>
Reference: [6] <author> R. Manmatha. </author> <title> Image matching under affine defor mations. In Invited Paper, </title> <booktitle> Proc. of the 27nd Asilo-mar IEEE Conf. on Signals, Systems and Computers,, </booktitle> <year> 1993. </year>
Reference-contexts: Large scales are handled as before. t 0 is obtained either by a local search or from a coarser level in a pyramid scheme, while ffit is estimated from the equation (see <ref> [6] </ref> for details). Note that since the gaussians are rotation invariant, the translation can be recovered for arbitrary rotations about an axis perpendicular to the image. <p> Fig (1) shows a dollar bill scaled by 1.4. The algorithm correctly recovers the scale as 1.41. Other experiments with scaled and rotated versions of the dollar bill consistently show good recovery of scale within a few percent. For other experimental results see <ref> [8, 6, 7] </ref>. 4 Solving for the General Affine There are two factors which need to be taken into account in the general case. First note that in the similarity case all the filtering was done at one point (the origin).
Reference: [7] <author> R. Manmatha. </author> <title> Measuring the affine transform using gaussian filters. </title> <booktitle> In To appear in Proc. of the Third European Conf. on Computer Vision, </booktitle> <year> 1994. </year>
Reference-contexts: Fig (1) shows a dollar bill scaled by 1.4. The algorithm correctly recovers the scale as 1.41. Other experiments with scaled and rotated versions of the dollar bill consistently show good recovery of scale within a few percent. For other experimental results see <ref> [8, 6, 7] </ref>. 4 Solving for the General Affine There are two factors which need to be taken into account in the general case. First note that in the similarity case all the filtering was done at one point (the origin).
Reference: [8] <author> R. Manmatha and J. Oliensis. </author> <title> Measuring the affine transform i: Scale and rotation. </title> <note> Technical Report Technical Report CMPSCI TR 92-74,University of Massachusetts at Amherst,MA,1992. Also in Proc. of the Darpa Image Understanding Workshop 1993. </note>
Reference-contexts: Deformations can be used to infer local surface geometry and depth from motion. Since a repeating texture pattern can be thought of as a pattern in motion, shape from texture can also be derived from deformations <ref> [8] </ref>. <p> For points and lines, explicit correspondence need not be established. Further, the method works for both closed and open con tours and even for collections of line segments. 1.1 Previous Work Affine transforms between image patches have been recovered in three different ways (for more details see <ref> [8] </ref>): 1. By linearizing the image intensities or the fil ter outputs with respect to the image coordinates. Linearization limits these algorithms to cases when the affine transforms are small. <p> Then it may be shown that the output of F 1 filtered with a gaussian is equal to the output of F 2 filtered with a gaussian deformed by the affine transform (see <ref> [8] </ref> for details) i.e. Z Z (4) where the integrals are taken from 1 to 1. <p> Similar equations may be written using derivative of gaussian filters (for details see <ref> [8] </ref>). 3 Solution for the Case of Similarity Transforms To solve equation (6) requires finding a gaussian of the appropriate scale s given . A brute force search through the space of scale changes is not desirable. <p> No other scheme is able to do this. 3.3 Experimental Results Experiments on synthetic images show that the affine transform can be recovered to within a few percent (see <ref> [8] </ref>). Figure (2) illustrates the power of this algorithm. A random dot image is scaled by a factor of 1.1 and rotated around an axis perpendicular to the image by 30 deg. On the left is the flow produced by an SSD based pyramid scheme. <p> Fig (1) shows a dollar bill scaled by 1.4. The algorithm correctly recovers the scale as 1.41. Other experiments with scaled and rotated versions of the dollar bill consistently show good recovery of scale within a few percent. For other experimental results see <ref> [8, 6, 7] </ref>. 4 Solving for the General Affine There are two factors which need to be taken into account in the general case. First note that in the similarity case all the filtering was done at one point (the origin).
Reference: [9] <author> H. S. Sawhney and A. R. Hanson. </author> <title> Identification and 3D description of `shallow' environmental structure in a sequence of images. </title> <booktitle> In Proc. Computer Vision and Pattern Recognition Conference, </booktitle> <pages> pages 179-186, </pages> <year> 1991. </year>
Reference-contexts: Matching image intensities by searching through the space of all affine parameters. This approach adopts a brute force search strategy which is potentially slow [4]. 3. Line based methods which match the closed boundaries of corresponding regions <ref> [3, 9] </ref>. Of these approaches, only the third deals with the problem of corresponding deformed patches. However, it is limited to homogenous regions with closed boundaries. Patches deformed under similarity transforms may also be matched using the Mellin-Fourier Transform ([5]).
Reference: [10] <author> J. Shi and C. Tomasi. </author> <title> Good features to track. </title> <type> Tech nical Report Technical Report TR 93-1399,Cornell University,Ithaca, </type> <address> NY, </address> <year> 1993. </year> <note> Also to appear in Proc. Computer Vision and Pattern Recognition Conference 1994. </note>
Reference-contexts: By linearizing the image intensities or the fil ter outputs with respect to the image coordinates. Linearization limits these algorithms to cases when the affine transforms are small. This linearization does not account for the deformation due to the affine transform. <ref> [1, 2, 10, 11] </ref> (Note that [10] essentially re-discovered the method due to [1]). 2. Matching image intensities by searching through the space of all affine parameters. This approach adopts a brute force search strategy which is potentially slow [4]. 3. <p> By linearizing the image intensities or the fil ter outputs with respect to the image coordinates. Linearization limits these algorithms to cases when the affine transforms are small. This linearization does not account for the deformation due to the affine transform. [1, 2, 10, 11] (Note that <ref> [10] </ref> essentially re-discovered the method due to [1]). 2. Matching image intensities by searching through the space of all affine parameters. This approach adopts a brute force search strategy which is potentially slow [4]. 3. Line based methods which match the closed boundaries of corresponding regions [3, 9]. <p> A number of methods incorporate the idea of filtering at many points <ref> [1, 2, 10] </ref>. However, none of these compensate for the deformation terms (in essence the difference between the traditional linearization methods and the technique presented here are the additional second derivative terms). Translation may be incorporated as before. <p> Convergence is somewhat slower with (n,k) = (5,2). 0:2 2:0 After the first iteration, the recovered affine transform was 2:08 0:24 . This shows that convergence is very rapid. The following affine transform was also tried. 0:3420 0:5638 . This converged in 5 iterations (compare <ref> [10] </ref> where they took 19 iterations to solve it). The experiments were repeated using large amounts of noise (roughly 15% of the magnitude of the sine wave) and performance was still good.
Reference: [11] <author> P. Werkhoven and J. J. Koenderinck. </author> <title> Extraction of motion parallax structure in the visual system 1. </title> <journal> Biological Cybernetics, </journal> <year> 1990. </year>
Reference-contexts: This allows the linearization point to be moved so that arbitrary affine transforms can be solved unlike traditional methods restricted to small affines. The method is local, applicable to arbitrary dimensions and can measure affine transforms in situations where other algorithms fail. For example, Werkhoven and Koenderink's algorithm <ref> [11] </ref> when run on the images in Figure (1) returns a scale factor of 1.16 while our algorithm does the matching correctly and therefore returns a scale factor of 1.41. It is also shown that points and lines can be treated as part of the same framework. <p> By linearizing the image intensities or the fil ter outputs with respect to the image coordinates. Linearization limits these algorithms to cases when the affine transforms are small. This linearization does not account for the deformation due to the affine transform. <ref> [1, 2, 10, 11] </ref> (Note that [10] essentially re-discovered the method due to [1]). 2. Matching image intensities by searching through the space of all affine parameters. This approach adopts a brute force search strategy which is potentially slow [4]. 3. <p> The equation clearly shows that to recover affine transforms by filtering, one must deform the filter appropriately; a point ignored in previous work <ref> [1, 2, 11, 4] </ref>. The equation is local because the gaussians rapidly decay. The integral may be interpreted as the result of convolving the function with a gaussian at the origin. It may also be interpreted as the result of a filtering operation with a gaussian.
References-found: 11

