URL: http://www.cs.ucsd.edu/~calder/papers/MICRO-97-VP.ps.Z
Refering-URL: http://www.cs.ucsd.edu/~calder/papers.html
Root-URL: http://www.cs.ucsd.edu
Email: fcalder,pfellerg@cs.ucsd.edu eustace@pa.dec.com  
Title: Value Profiling  
Phone: Telephone:  
Author: Brad Calder Peter Feller Alan Eustace 
Address: 445 Hoes Lane P.O. Box 1331 Piscataway, NJ 08855-1331, USA.  
Affiliation: Service Center  Department of Computer Science and Engineering Digital Equipment Corporation University of California, San Diego Western Research Lab  
Note: Copyright 1997 IEEE. Published in the Proceedings of Micro-30, December 1-3, 1997 in Research Triangle Park, North Carolina. Personal use of this material is permitted. However, permission to reprint/republish this material for advertising or promotional purposes or for creating new collective works for resale or redistribution to servers or lists, or to reuse any copyrighted component of this work in other works, must be obtained from the IEEE. Contact: Manager, Copyrights and Permissions IEEE  Intl. 908-562-3966.  
Abstract: In this paper we examine the invariance found from profiling instruction values, and show that many instructions have semi-invariant values even across different inputs. We also investigate the ability to estimate the invari-ance for all instructions in a program from only profiling load instructions. In addition, we propose a new type of profiling called Convergent Profiling. Estimating the in-variance from loads and convergent profiling are used to reduce the profiling time needed to generate an accurate value profile. The value profile can then be used to automatically guide code generation for dynamic compilation, adaptive execution, code specialization, partial evaluation and other compiler optimizations. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Auslander, M. Philipose, C. Chambers, S.J. Eggers, and B.N. Bershad. </author> <title> Fast, effective dynamic compilation. </title> <booktitle> In Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation. ACM, </booktitle> <month> May </month> <year> 1996. </year>
Reference-contexts: For these techniques to be effective the compiler must determine which sections of code to concentrate on for the adaptive execution. Existing techniques for dynamic compilation and adaptive execution require the user to identify run-time invariants using user guided annotations <ref> [1, 3, 4, 7, 8] </ref>. One of the goals of value profiling is to provide an automated approach for identifying semi-invariant variables and to use this to guide dynamic compilation and adaptive execution. <p> Consel and Noel [3] use partial evaluation techniques to automatically generate templates for run-time code generation, although their approach still requires the user to annotate arguments of the top-level procedures, global variables and a few data structures as run-time constants. Auslander et.al. <ref> [1] </ref> proposed a dynamic compilation system that uses a unique form of binding time analysis to generate templates for code sequences that have been identified as semi-invariant. Their approach currently uses user defined annotations to indicate which variables are semi-invariant.
Reference: [2] <author> T. Autrey and M. Wolfe. </author> <title> Initial results for glacial variable analysis. </title> <booktitle> In 9th International Workshop on Languages and Compilers for Parallel Computing, </booktitle> <month> August </month> <year> 1996. </year>
Reference-contexts: Their approach requires programmers to provide hints to the staging analysis to determine what arguments have semi-invariant behavior. In addition, Autrey and Wolfe have started to investigate a form of staging analysis for automatic identification of semi-invariant variables <ref> [2] </ref>. Consel and Noel [3] use partial evaluation techniques to automatically generate templates for run-time code generation, although their approach still requires the user to annotate arguments of the top-level procedures, global variables and a few data structures as run-time constants.
Reference: [3] <author> C. Consel and F. Noel. </author> <title> A general approach for run-time specialization and its application to C. </title> <booktitle> In Thirteenth ACM Symposium on Principles of Programming Languages. ACM, </booktitle> <month> January </month> <year> 1996. </year>
Reference-contexts: For these techniques to be effective the compiler must determine which sections of code to concentrate on for the adaptive execution. Existing techniques for dynamic compilation and adaptive execution require the user to identify run-time invariants using user guided annotations <ref> [1, 3, 4, 7, 8] </ref>. One of the goals of value profiling is to provide an automated approach for identifying semi-invariant variables and to use this to guide dynamic compilation and adaptive execution. <p> Their approach requires programmers to provide hints to the staging analysis to determine what arguments have semi-invariant behavior. In addition, Autrey and Wolfe have started to investigate a form of staging analysis for automatic identification of semi-invariant variables [2]. Consel and Noel <ref> [3] </ref> use partial evaluation techniques to automatically generate templates for run-time code generation, although their approach still requires the user to annotate arguments of the top-level procedures, global variables and a few data structures as run-time constants.
Reference: [4] <author> D.R. Engler, W.C. Hsieh, and M.F. Kaashoek. </author> <title> `C: A language for high-level efficient, and machine-independent dynamic code generation. </title> <booktitle> In Thirteenth ACM Symposium on Principles of Programming Languages. ACM, </booktitle> <month> January </month> <year> 1996. </year>
Reference-contexts: For these techniques to be effective the compiler must determine which sections of code to concentrate on for the adaptive execution. Existing techniques for dynamic compilation and adaptive execution require the user to identify run-time invariants using user guided annotations <ref> [1, 3, 4, 7, 8] </ref>. One of the goals of value profiling is to provide an automated approach for identifying semi-invariant variables and to use this to guide dynamic compilation and adaptive execution.
Reference: [5] <author> F. Gabbay and A. Mendelson. </author> <title> Speculative execution based on value prediction. </title> <type> EE Department TR 1080, </type> <institution> Technion - Israel Institue of Technology, </institution> <month> November </month> <year> 1996. </year>
Reference-contexts: Value prediction is used to predict the next result value (write of a register) for an instruction. This has been shown to provide predictable results by using previously cached values to predict the next value of the variable using a hardware buffer <ref> [5, 9, 10] </ref>. This approach was shown to work well for a hardware value predictor, since values produced by an instruction have a high degree of temporal locality. Our research into the semi-invariance of variables is different from these previous hardware predication studies. <p> These results show that value profiling can be very effective for reducing the execution time of long latency instructions. The recent publications on Value Prediction in hardware provided further motivation for our research into value profiling <ref> [5, 9, 10] </ref>.
Reference: [6] <author> D.M. Gallagher, W.Y. Chen, S.A. Mahlke, J.C. Gyllenhaal, and W.W. Hwu. </author> <title> Dynamic memory disambiguation using the memory conflict buffer. </title> <booktitle> In Six International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <year> 1994. </year>
Reference-contexts: Instructions shown to have a high invariance with the value profiler could even be given a sticky replacement policy. The Memory Disambiguation Buffer <ref> [6] </ref> (MDB) is an architecture that allows a load and its dependent instructions to be hoisted out of a loop, by checking if store addresses inside the loop conflict with the load.
Reference: [7] <author> T.B. Knoblock and E. Ruf. </author> <title> Data specialization. </title> <booktitle> In Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation. ACM, </booktitle> <month> January </month> <year> 1996. </year>
Reference-contexts: For these techniques to be effective the compiler must determine which sections of code to concentrate on for the adaptive execution. Existing techniques for dynamic compilation and adaptive execution require the user to identify run-time invariants using user guided annotations <ref> [1, 3, 4, 7, 8] </ref>. One of the goals of value profiling is to provide an automated approach for identifying semi-invariant variables and to use this to guide dynamic compilation and adaptive execution. <p> One of the goals of value profiling is to provide an automated approach for identifying semi-invariant variables and to use this to guide dynamic compilation and adaptive execution. Staging analysis has been proposed by Lee and Leone [8] and Knoblock and Ruf <ref> [7] </ref> as an effective means for determining which computations can be performed early by the compiler and which optimizations should be performed late or postponed by the compiler for dynamic code generation. Their approach requires programmers to provide hints to the staging analysis to determine what arguments have semi-invariant behavior.
Reference: [8] <author> P. Lee and M. Leone. </author> <title> Optimizing ml with run-time code generation. </title> <booktitle> In Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation. ACM, </booktitle> <month> May </month> <year> 1996. </year>
Reference-contexts: For these techniques to be effective the compiler must determine which sections of code to concentrate on for the adaptive execution. Existing techniques for dynamic compilation and adaptive execution require the user to identify run-time invariants using user guided annotations <ref> [1, 3, 4, 7, 8] </ref>. One of the goals of value profiling is to provide an automated approach for identifying semi-invariant variables and to use this to guide dynamic compilation and adaptive execution. <p> One of the goals of value profiling is to provide an automated approach for identifying semi-invariant variables and to use this to guide dynamic compilation and adaptive execution. Staging analysis has been proposed by Lee and Leone <ref> [8] </ref> and Knoblock and Ruf [7] as an effective means for determining which computations can be performed early by the compiler and which optimizations should be performed late or postponed by the compiler for dynamic code generation.
Reference: [9] <author> M.H. Lipasti and J.P. Shen. </author> <title> Exceeding the dataflow limit via value prediction. </title> <booktitle> In 29th International Symposium on Microarchitecture, </booktitle> <month> December </month> <year> 1996. </year>
Reference-contexts: Value prediction is used to predict the next result value (write of a register) for an instruction. This has been shown to provide predictable results by using previously cached values to predict the next value of the variable using a hardware buffer <ref> [5, 9, 10] </ref>. This approach was shown to work well for a hardware value predictor, since values produced by an instruction have a high degree of temporal locality. Our research into the semi-invariance of variables is different from these previous hardware predication studies. <p> These results show that value profiling can be very effective for reducing the execution time of long latency instructions. The recent publications on Value Prediction in hardware provided further motivation for our research into value profiling <ref> [5, 9, 10] </ref>. <p> These results show that value profiling can be very effective for reducing the execution time of long latency instructions. The recent publications on Value Prediction in hardware provided further motivation for our research into value profiling [5, 9, 10]. The recent paper by Lipasti et al. <ref> [9] </ref> showed that on average 49% of the instructions wrote the same value as they did the last time, and 61% of the executed instructions produced the same value as one of the last 4 values produced by that instruction using a 16K value prediction table. <p> can be used to determine if these potential variables or instructions have the same value across multiple inputs, in order to guide code specialization. 2.1.2 Hardware-based Optimizations In predicting the most recent value (s) seen, an instruction's future value has been shown to have good predictability using tag-less hardware buffers <ref> [9, 10] </ref>. Our results show that value profiling can be used to classify the invariance of instructions, so a form of value profiling could potentially be used to improve hardware value prediction. <p> Determining the invariance of an instruction's resulting value can be calculated in many different ways. The value prediction results presented by Lipasti et al. <ref> [9, 10] </ref> used a tag-less table to store a cache of the most recently used values to predict the next result value for an instruction.
Reference: [10] <author> M.H. Lipasti, C.B. Wilkerson, and J.P. Shen. </author> <title> Value locality and load value prediction. </title> <booktitle> In Seventh International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <month> October </month> <year> 1996. </year>
Reference-contexts: Value prediction is used to predict the next result value (write of a register) for an instruction. This has been shown to provide predictable results by using previously cached values to predict the next value of the variable using a hardware buffer <ref> [5, 9, 10] </ref>. This approach was shown to work well for a hardware value predictor, since values produced by an instruction have a high degree of temporal locality. Our research into the semi-invariance of variables is different from these previous hardware predication studies. <p> These results show that value profiling can be very effective for reducing the execution time of long latency instructions. The recent publications on Value Prediction in hardware provided further motivation for our research into value profiling <ref> [5, 9, 10] </ref>. <p> can be used to determine if these potential variables or instructions have the same value across multiple inputs, in order to guide code specialization. 2.1.2 Hardware-based Optimizations In predicting the most recent value (s) seen, an instruction's future value has been shown to have good predictability using tag-less hardware buffers <ref> [9, 10] </ref>. Our results show that value profiling can be used to classify the invariance of instructions, so a form of value profiling could potentially be used to improve hardware value prediction. <p> Determining the invariance of an instruction's resulting value can be calculated in many different ways. The value prediction results presented by Lipasti et al. <ref> [9, 10] </ref> used a tag-less table to store a cache of the most recently used values to predict the next result value for an instruction.
Reference: [11] <author> A. Srivastava and A. Eustace. </author> <title> ATOM: A system for building customized program analysis tools. </title> <booktitle> In Proceedings of the Conference on Programming Language Design and Implementation, pages 196205. ACM, </booktitle> <year> 1994. </year>
Reference-contexts: We compiled the SPEC benchmark suite under OSF/1 V4.0 operating system using full compiler optimization (-O4 -ifo). Table 1 shows the two data sets we used in gathering results for each program, and the number of instructions executed in millions. We used ATOM <ref> [11] </ref> to instrument the programs and gather the value profiles. The ATOM instrumentation tool has an interface that allows the elements of the program executable, such as instructions, basic blocks, and procedures, to be queried and manipulated.
References-found: 11

