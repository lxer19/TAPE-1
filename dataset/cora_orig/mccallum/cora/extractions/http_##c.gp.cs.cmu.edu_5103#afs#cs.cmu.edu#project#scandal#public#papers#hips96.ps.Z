URL: http://c.gp.cs.cmu.edu:5103/afs/cs.cmu.edu/project/scandal/public/papers/hips96.ps.Z
Refering-URL: http://c.gp.cs.cmu.edu:5103/afs/cs.cmu.edu/user/jch/mosaic/publications.html
Root-URL: http://www.cs.cmu.edu
Email: jch@cs.cmu.edu  
Title: First International Workshop on High-Level Programming Models and Supportive Environments, April 1996. An Efficient Implementation
Author: Jonathan C. Hardwick 
Address: Pittsburgh, PA 15213, USA  
Affiliation: School of Computer Science Carnegie Mellon University  
Abstract: This paper presents work in progress on a new method of implementing irregular divide-and-conquer algorithms in a nested data-parallel language model on distributed-memory multiprocessors. The main features discussed are the recursive subdivision of asynchronous processor groups to match the change from data-parallel to control-parallel behavior over the lifetime of an algorithm, switching from parallel code to serial code when the group size is one (with the opportunity to use a more efficient serial algorithm) , and a simple manager-based run-time load-balancing system. Sample algorithms translated from the high-level nested data-parallel language NESL into C and MPI using this method are significantly faster than the current NESL system, and show the potential for further speedup. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. V. Aho, J. E. Hopcroft, and J. D. Ullman. </author> <title> The Design and Analysis of Computer Algorithms. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1974. </year>
Reference-contexts: Using nested data parallelism for divide-and conquer algorithms Divide-and-conquer algorithms provide a good illustration of the strengths of the nested data-parallel model. Figure 1 shows pseudocode for the quicksort algorithm (taken from <ref> [1] </ref>), which will be used as an example for the rest of this section. Quicksort was chosen because it is a well-known and very simple divide-and-conquer algorithm that also illustrates the problems of irregular data distribution. <p> element a randomly from S; let S 1 , S 2 and S 3 be the sequences of elements in S less than, equal to, and greater than a, respectively; return (QUICKSORT (S 1 ) followed by S 2 followed by QUICKSORT (S 3 )) end and-conquer algorithm (taken from <ref> [1] </ref>). implementing the parallel recursion as a single parallel function call across a nested sequence containing the two subsequences S 1 and S 2 . in terms of the stylized parallelism profile (parallelism versus time) of a divide-and-conquer algorithm expressed in the three different language models. <p> Quicksort (S) = if (#S &lt;= 1) then S else let a = S [rand (#S)]; S1 = -e in S | e &lt; a-; S3 = -e in S | e &gt; a-; R = -Quicksort (v) : v in [S1, S3]- in R [0] ++ S2 ++ R <ref> [1] </ref>; The current NESL system consists of three layers. The first is a compiler that translates the NESL program into VCODE, an intermediate vector language [5]. The data structures that are represented as nested sequences in NESL are flattened into segmented vectors in VCODE.
Reference: [2] <author> F. Aurenhammer. </author> <title> Voronoi diagrams: a survey of a fundamental geometric data structure. </title> <journal> ACM Computing Surveys, </journal> <volume> 23 </volume> <pages> 345-405, </pages> <year> 1991. </year>
Reference-contexts: The rest of this paper is arranged as follows. Section 2 uses a simple irregular divide-and-conquer algorithm to il Algorithm Reference Barnes-Hut n-body [9] Delaunay triangulation <ref> [2] </ref> Geometric graph separators [26] Two-dimensional convex hull [7] Table 1. Examples of irregular divide-and conquer algorithms. lustrate the theoretical performance advantages of the nested data-parallel model, and the practical difficulties of writing an efficient implementation.
Reference: [3] <author> S. T. Barnard. PMRSB: </author> <title> Parallel multilevel recursive spectral bisection. </title> <booktitle> In Proceedingsof Supercomputing'95, </booktitle> <month> Nov. </month> <year> 1995. </year>
Reference-contexts: Again, the trends are similar, with load-balancing improving performance by 0.83-1.04 times, and fused loops by 1.07-1.14 times. 7. Related work One of the main ideas behind this work was independently arrived at by Barnard <ref> [3] </ref>, who has implemented a parallel multi-level recursive spectral bisection algorithm on the Cray T3D using recursive asynchronous task teams, which are analogous to the processor groups described earlier. However, the work described here goes further in three areas.
Reference: [4] <author> G. E. Blelloch. </author> <title> Vector Models for Data-Parallel Computing. </title> <publisher> MIT Press, </publisher> <year> 1990. </year>
Reference-contexts: 1. Introduction Nested data-parallel languages are a recent solution to the problem of easily and efficiently expressing parallel algorithms that operate on irregular data structures <ref> [4] </ref>. These irregular data structures, such as unstructured sparse matrices, graphs, and trees, are becoming increasingly prevalent in computationally intensive problems [16]. Existing parallel languages are generally either data-parallel or control-parallel in nature. <p> The nested data-parallel model is an extension of the standard (or flat) data-parallel model, adding the ability to nest flat data-parallel structures and to apply arbitrary parallel function calls in parallel across such structures <ref> [4] </ref>. It combines the data-parallel model's parallelizability and ease of programming with the control-parallel model's run-time efficiency for irregular algorithms [10].
Reference: [5] <author> G. E. Blelloch and S. Chatterjee. </author> <title> VCODE: A data-parallel intermediate language. </title> <booktitle> In Proceedings of Symposium on The Frontiers of Massively Parallel Computation, </booktitle> <pages> pages 471-480, </pages> <month> Oct. </month> <year> 1990. </year>
Reference-contexts: The first is a compiler that translates the NESL program into VCODE, an intermediate vector language <ref> [5] </ref>. The data structures that are represented as nested sequences in NESL are flattened into segmented vectors in VCODE. The second layer is a portable VCODE interpreter.
Reference: [6] <author> G. E. Blelloch, S. Chatterjee, J. C. Hardwick, M. Reid-Miller, J. Sipelstein, and M. Zagha. CVL: </author> <title> A C vector library. </title> <type> Technical Report CMU-CS-93-114, </type> <institution> School of Computer Science, Carnegie Mellon University, </institution> <month> Feb. </month> <year> 1993. </year>
Reference-contexts: CVL provides an abstract segmented vector machine model that is independent of the underlying architecture, and a variety of data-parallel functions that operate on the vectors <ref> [6] </ref>. This three-layer model is a good match for the vector and SIMD machines originally targeted by NESL.
Reference: [7] <author> G. E. Blelloch, J. C. Hardwick, J. Sipelstein, and M. Za-gha. </author> <note> NESL user's manual (for NESL version 3.1). Technical Report CMU-CS-95-169, </note> <institution> School of Computer Science, Carnegie Mellon University, </institution> <month> July </month> <year> 1995. </year>
Reference-contexts: On two sample algorithms (quicksort and a two-dimensional convex hull algorithm) the code produced is significantly faster than the equivalent algorithm expressed in the current NESL system (a high-level sequence-based nested data-parallel language <ref> [7] </ref>), and shows the potential for further speedup. The rest of this paper is arranged as follows. Section 2 uses a simple irregular divide-and-conquer algorithm to il Algorithm Reference Barnes-Hut n-body [9] Delaunay triangulation [2] Geometric graph separators [26] Two-dimensional convex hull [7] Table 1. <p> NESL system (a high-level sequence-based nested data-parallel language <ref> [7] </ref>), and shows the potential for further speedup. The rest of this paper is arranged as follows. Section 2 uses a simple irregular divide-and-conquer algorithm to il Algorithm Reference Barnes-Hut n-body [9] Delaunay triangulation [2] Geometric graph separators [26] Two-dimensional convex hull [7] Table 1. Examples of irregular divide-and conquer algorithms. lustrate the theoretical performance advantages of the nested data-parallel model, and the practical difficulties of writing an efficient implementation. <p> The NESL code for the recursive step of quickhull is shown in Figure 5. The function hsplit returns all (x; y) coordinates in the sequence points that are to one side of the line formed by the points p1 and p2. For further details, see <ref> [7] </ref>. All experiments were performed on an Intel Paragon running OSF R1.2, using icc -O3 and MPICH 1.0.11. The NESL system used an MPI-based version of CVL [17]. For quicksort, sequences of pseudo-random 64-bit floating-point numbers were used as input.
Reference: [8] <author> G. E. Blelloch, J. C. Hardwick, J. Sipelstein, M. Zagha, and S. Chatterjee. </author> <title> Implementation of a portable nested data-parallel language. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 21(1) </volume> <pages> 4-14, </pages> <month> Apr. </month> <year> 1994. </year>
Reference-contexts: It combines the data-parallel model's parallelizability and ease of programming with the control-parallel model's run-time efficiency for irregular algorithms [10]. Although the performance of a nested data-parallel language has been demonstrated to be competitive with that of other high-level parallel languages for irregular algorithms on vector and SIMD machines <ref> [8] </ref>, performance is relatively poor on the current generation of distributed-memory multiprocessors. These efficiency problems are due mainly to the reliance of current nested data-parallel language implementations on a library of low-level vector functions, which results in unnecessary interprocessor communication and a loss of data locality. <p> The second layer is a portable VCODE interpreter. Note that since the interpretive overhead of each VCODE instruction is amortized over the length of the vectors on which it operates, interpretation does not impose a significant performance penalty for large problem sizes <ref> [8] </ref>. The final layer is CVL, a run-time library that is the only part of the system that needs to be rewritten for a new machine.
Reference: [9] <author> G. E. Blelloch and G. Narlikar. </author> <title> A comparison of two n-body algorithms. </title> <booktitle> In Proceedings of DIMACS International Algorithm Implementation Challenge, </booktitle> <month> Oct. </month> <year> 1994. </year>
Reference-contexts: The rest of this paper is arranged as follows. Section 2 uses a simple irregular divide-and-conquer algorithm to il Algorithm Reference Barnes-Hut n-body <ref> [9] </ref> Delaunay triangulation [2] Geometric graph separators [26] Two-dimensional convex hull [7] Table 1. Examples of irregular divide-and conquer algorithms. lustrate the theoretical performance advantages of the nested data-parallel model, and the practical difficulties of writing an efficient implementation.
Reference: [10] <author> G. E. Blelloch and G. W. Sabot. </author> <title> Compiling collection-oriented languages onto massively parallel computers. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 8(2) </volume> <pages> 119-134, </pages> <month> Feb. </month> <year> 1990. </year>
Reference-contexts: It combines the data-parallel model's parallelizability and ease of programming with the control-parallel model's run-time efficiency for irregular algorithms <ref> [10] </ref>. Although the performance of a nested data-parallel language has been demonstrated to be competitive with that of other high-level parallel languages for irregular algorithms on vector and SIMD machines [8], performance is relatively poor on the current generation of distributed-memory multiprocessors.
Reference: [11] <author> E. D. Brooks III, B. C. Gorda, and K. H. Warren. </author> <title> The parallel C preprocessor. </title> <journal> Scientific Programming, </journal> <volume> 1(1) </volume> <pages> 79-89, </pages> <year> 1992. </year>
Reference-contexts: Finally, it is built on top on C and MPI and hence is widely portable, rather than being tied to the shared-memory architecture of a particular machine. The PCP system also supports a variant of asynchronous task teams, although under explicit programmer control <ref> [11] </ref>. PCP is a data-parallel extension of C that is designed to exploit nested parallelism. The programmer can defer choice of team sizes until run time, allowing for some approximate load balancing. Again, there is no dynamic load balancing, and no use of serial code.
Reference: [12] <author> S. Chakrabarti, J. Demmel, and K. Yelick. </author> <title> Modeling the benefits of mixed data and task parallelism. </title> <booktitle> In Proceedings of ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <month> July </month> <year> 1995. </year>
Reference-contexts: Additionally, Chakrabarti and others have analyzed the theoretical benefits of mixed data and control parallelism <ref> [12] </ref>. They conclude that best results are obtained when communication is slow or when there is a large number of processors, and that a single switch between data and control parallelism can achieve most of the benefits of a more general model.
Reference: [13] <author> M. M. T. Chakravarty, F. W. Schroer, and M. Simons. </author> <title> V nested parallelism in C. </title> <booktitle> In Proceedingsof Workshopon Massively Parallel Programming Models, </booktitle> <month> Oct. </month> <year> 1995. </year>
Reference-contexts: There are now several other nested data-parallel languages besides NESL. Proteus is a high-level architecture-independent programming language designed for rapid application prototyping [21]. V extends nested data parallelism to the imperative programming model of C <ref> [13] </ref>, and the language developed by Sheffler and Chatterjee adds nested constructs to C++ [25], using a flattening technique to transform nested data-parallel code into ordinary C++.
Reference: [14] <author> S. Chatterjee. </author> <title> Compiling Data-Parallel Programs for Efficient Execution on Shared-Memory Multiprocessors. </title> <type> PhD thesis, </type> <institution> School of Computer Science, Carnegie Mellon University, </institution> <month> Oct. </month> <year> 1991. </year>
Reference-contexts: Again, there is no dynamic load balancing, and no use of serial code. Previous work on improving the performance of NESL has involved the compilation of VCODE into multi-threaded C for a shared-memory multiprocessor <ref> [14] </ref>. The compiler used extensive symbolic loop analysis and program graph clustering to improve locality and reduce synchronization, but retained a flat, implicitly load-balanced model. There are now several other nested data-parallel languages besides NESL. Proteus is a high-level architecture-independent programming language designed for rapid application prototyping [21].
Reference: [15] <author> D. Engelhardt and A. Wendelborn. </author> <title> A partitioning-independent paradigm for nested data parallelism. </title> <booktitle> In Proceedings of International Conference on Parallel Architectures and Compiler Technology, </booktitle> <month> June </month> <year> 1995. </year>
Reference-contexts: However, all three of these languages use CVL as a base implementation layer, and are therefore limited by its performance problems on current distributed-memory multiprocessors. Adl, a functional language similar to NESL, uses a multi-threaded implementation instead of CVL, but has so far only been implemented on the CM-5 <ref> [15] </ref>. Compiling serial and parallel versions of the same code is also done by the Illinois Concert System compiler for two fine-grained object-oriented languages (IC++ and Concurrent Aggregates), using a multi-level execution model [24].
Reference: [16] <author> G. C. Fox. </author> <title> The architecture of problems and portable parallel software systems. </title> <type> Technical Report SCCS-134, </type> <institution> Syra-cuse Center for Computational Science, Syracuse University, </institution> <year> 1991. </year>
Reference-contexts: 1. Introduction Nested data-parallel languages are a recent solution to the problem of easily and efficiently expressing parallel algorithms that operate on irregular data structures [4]. These irregular data structures, such as unstructured sparse matrices, graphs, and trees, are becoming increasingly prevalent in computationally intensive problems <ref> [16] </ref>. Existing parallel languages are generally either data-parallel or control-parallel in nature. The data-parallel (or collection-oriented [27]) model has a single thread of control, and is easy to understand and use.
Reference: [17] <author> J. C. Hardwick. </author> <title> Porting a vector library: a comparison of MPI, Paris, CMMD and PVM. </title> <booktitle> In Proceedings of Scalable Parallel Libraries Conference, </booktitle> <pages> pages 68-77, </pages> <address> Starkville, Mis-sissippi, </address> <month> Oct. </month> <year> 1994. </year>
Reference-contexts: However, it is difficult to write an efficient implementation of CVL (and hence NESL) for the current generation of distributed-memory multiprocessors <ref> [17] </ref>. There are at least three reasons for this. First, to enforce the guarantees of complexity that apply to each NESL primitive, CVL must perform a load-balancing step whenever a vector changes length. <p> For further details, see [7]. All experiments were performed on an Intel Paragon running OSF R1.2, using icc -O3 and MPICH 1.0.11. The NESL system used an MPI-based version of CVL <ref> [17] </ref>. For quicksort, sequences of pseudo-random 64-bit floating-point numbers were used as input. For quickhull, uniform distributions of points inside the unit square were projected onto (x; x 2 +y 2 ), resulting in convex hulls of approximately p n points for an input sequence of size n.
Reference: [18] <author> J. C. Hardwick. </author> <title> A portable toolbox for nested data-parallel algorithms on distributed-memory multiprocessors. </title> <type> PhD proposal, </type> <institution> School of Computer Science, Carnegie Mellon University, </institution> <month> Apr. </month> <year> 1995. </year>
Reference-contexts: The system could be extended to operate in the parallel phase of the algorithm, dealing with multi-processor groups as well as single processors <ref> [18] </ref>. Finally, the use of threads or active messages would allow the load-balancing system to be distributed across the machine, rather than tying up one processor. 10. Acknowledgements I would like to thank my adviser, Guy Blelloch, for his guidance and suggestions.
Reference: [19] <author> C. N. M. Karavassili. </author> <title> Description of the adaptive resource management problem, cost functions and performance objectives. </title> <type> Technical Report P8144, </type> <institution> ESPRIT III, </institution> <month> Dec. </month> <year> 1994. </year>
Reference-contexts: However, neither model is designed to deal with the data-dependent computations typical of irregular algorithms. Load-balancing is one of the most heavily-studied areas of parallel computation. The interested reader is referred to a survey such as <ref> [19] </ref>. 8. Summary and conclusions The promise of nested data-parallel languages has been hampered by the inefficiency of their current implementation on distributed-memory multiprocessors.
Reference: [20] <author> Message Passing Interface Forum. </author> <title> MPI: A message-passing interface standard. </title> <journal> International Journal of Supercomputing Applications and High Performance Computing, </journal> <volume> 8(3/4), </volume> <year> 1994. </year>
Reference-contexts: That is, data-parallel behavior at the beginning of the algorithm, control-parallel behavior at the end of the algorithm, and combined data-parallel and control-parallel behavior in between the two extremes. Given a divide-and-conquer algorithm, we can implement this idea using a message-passing system such as MPI <ref> [20] </ref>. At the beginning of the algorithm, its data structures are spread in a block-cyclic fashion across the machine. The processors are in a single group, executing flat data-parallel operations.
Reference: [21] <author> P. H. Mills, L. S. Nyland, J. F. Prins, J. H. Reif, and R. A. Wagner. </author> <title> Prototyping parallel and distributed programs in Proteus. </title> <booktitle> In Proceedings of Symposium on Parallel and Distributed Processing, </booktitle> <month> Dec. </month> <year> 1991. </year>
Reference-contexts: The compiler used extensive symbolic loop analysis and program graph clustering to improve locality and reduce synchronization, but retained a flat, implicitly load-balanced model. There are now several other nested data-parallel languages besides NESL. Proteus is a high-level architecture-independent programming language designed for rapid application prototyping <ref> [21] </ref>. V extends nested data parallelism to the imperative programming model of C [13], and the language developed by Sheffler and Chatterjee adds nested constructs to C++ [25], using a flattening technique to transform nested data-parallel code into ordinary C++.
Reference: [22] <author> J. Misra. Powerlist: </author> <title> a structure for parallel recursion. In A Classical Mind: Essays in Honor of C.A.R. Hoare. </title> <publisher> Prentice-Hall, </publisher> <month> Jan. </month> <year> 1994. </year>
Reference-contexts: Divacon is a formal model for such algorithms and was implemented on the CM-2 [23]. More recently, the powerlist has been proposed as the basic data structure of a similar model, exposing the parallelism and recursion in an algorithm <ref> [22] </ref>. However, neither model is designed to deal with the data-dependent computations typical of irregular algorithms. Load-balancing is one of the most heavily-studied areas of parallel computation. The interested reader is referred to a survey such as [19]. 8.
Reference: [23] <author> Z. G. Mou and P. Hudak. </author> <title> An algebraic model of divide-and-conquer and its parallelism. </title> <journal> Journal of Supercomputing, </journal> <volume> 2(3) </volume> <pages> 257-278, </pages> <month> Nov. </month> <year> 1988. </year>
Reference-contexts: Most work on parallel divide-and-conquer algorithms has concentrated on regular algorithms, such as Fast Fourier Transforms, sorting networks, and prefix sums. Divacon is a formal model for such algorithms and was implemented on the CM-2 <ref> [23] </ref>. More recently, the powerlist has been proposed as the basic data structure of a similar model, exposing the parallelism and recursion in an algorithm [22]. However, neither model is designed to deal with the data-dependent computations typical of irregular algorithms.
Reference: [24] <author> J. Pleyvak, V. Karamcheti, X. Zhang, and A. A. Chien. </author> <title> A hybrid execution model for fine-grained languages on distributed memory multicomputers. </title> <booktitle> In Proceedings of Supercomputing '95, </booktitle> <month> Dec. </month> <year> 1995. </year>
Reference-contexts: Compiling serial and parallel versions of the same code is also done by the Illinois Concert System compiler for two fine-grained object-oriented languages (IC++ and Concurrent Aggregates), using a multi-level execution model <ref> [24] </ref>. Although the compiler is aimed at a thread-based language model rather than a nested data-parallel model, it tackles many of the same problems, namely run-time adaptation to changing data layouts, use of sequential code to improve efficiency, and minimizing the overhead of parallel code.
Reference: [25] <author> T. J. Sheffler and S. Chatterjee. </author> <title> An object-oriented approach to nested data parallelism. </title> <booktitle> In Proceedings of Symposium on The Frontiers of Massively Parallel Computation, </booktitle> <month> Feb. </month> <year> 1995. </year>
Reference-contexts: There are now several other nested data-parallel languages besides NESL. Proteus is a high-level architecture-independent programming language designed for rapid application prototyping [21]. V extends nested data parallelism to the imperative programming model of C [13], and the language developed by Sheffler and Chatterjee adds nested constructs to C++ <ref> [25] </ref>, using a flattening technique to transform nested data-parallel code into ordinary C++. However, all three of these languages use CVL as a base implementation layer, and are therefore limited by its performance problems on current distributed-memory multiprocessors.
Reference: [26] <author> H. D. Simon and S.-H. Teng. </author> <title> How good is recursive bisection? Technical Report RNR-93-012, </title> <institution> NASA Ames Research Center, </institution> <year> 1993. </year>
Reference-contexts: The rest of this paper is arranged as follows. Section 2 uses a simple irregular divide-and-conquer algorithm to il Algorithm Reference Barnes-Hut n-body [9] Delaunay triangulation [2] Geometric graph separators <ref> [26] </ref> Two-dimensional convex hull [7] Table 1. Examples of irregular divide-and conquer algorithms. lustrate the theoretical performance advantages of the nested data-parallel model, and the practical difficulties of writing an efficient implementation.

References-found: 26

