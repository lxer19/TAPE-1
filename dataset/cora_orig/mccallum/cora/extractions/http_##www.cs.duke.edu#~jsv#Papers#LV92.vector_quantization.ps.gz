URL: http://www.cs.duke.edu/~jsv/Papers/LV92.vector_quantization.ps.gz
Refering-URL: http://www.cs.duke.edu/~jsv/Papers/catalog/node33.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Nearly Optimal Vector Quantization via Linear Programming (extended abstract)  
Author: Jyh-Han Lin and Jeffrey Scott Vitter 
Address: Providence, R. I. 02912-1910  
Affiliation: Department of Computer Science Brown University  
Abstract: We present new vector quantization algorithms based on the theory developed in [LiV]. The new approach is to formulate a vector quantization problem as a 0-1 integer linear program. We first solve its relaxed linear program by linear programming techniques. Then we transform the linear program solution into a provably good solution for the vector quantization problem. These methods lead to the first known polynomial-time full-search vector quantization codebook design algorithm and tree pruning algorithm with provable worst-case performance guarantees. We also introduce the notion of pseudorandom pruned tree-structured vector quantizers. Initial experimental results on image compression are very encouraging.
Abstract-found: 1
Intro-found: 1
Reference: [BFO] <author> L. Breiman, J. H. Friedman, R. A. Olshen, and C. J. Stone, </author> <title> Classification Trees and Regression Trees, </title> <publisher> Wadsworth, </publisher> <address> Belmont, CA, </address> <year> 1984. </year>
Reference-contexts: For tree-structured codebook, Chou, Lookabaugh, and Gray [CLG] propose a tree pruning heuristic based on the BFOS algorithm <ref> [BFO] </ref> in which a given initial tree is pruned back according to certain optimization criterion. Their heuristic traces the lower convex hull of the distortion-rate function and the final pruned subtrees are optimal for their rates. <p> Tree-structured vector quantizers also have a distinguished "successive approximation" and "graceful degradation" character. In this section we present an approximate tree pruning algorithm. Besides pruned tree-structured vector quantization (PTSVQ), the tree pruning problem has many other applications such as regression trees, decision trees, and computer graphics <ref> [BFO, CLG] </ref>. Our notations in this section follow that of [CLG]. A tree T is a finite set of nodes, t 0 ; t 1 ; . . . ; t n , with a unique root node t 0 . <p> Therefore, we have to use heuristics in practice <ref> [BFO, CLG] </ref>. 3.1 Approximate Tree Pruning The following is an outline of the approximate tree pruning algorithm: 1. Solve the linear program relaxation of the tree pruning problem by linear pro gramming techniques; denote the fractional solution by b x. 2.
Reference: [CLG] <author> P. A. Chou, T. Lookabaugh, and R. M. Gray, </author> <title> "Optimal Pruning with Applications to Tree-Structured Source Coding and Modeling," </title> <journal> IEEE Transactions on Information Theory (1989), </journal> <pages> 299-315. </pages>
Reference-contexts: The most popular algorithm for full-search codebook design is the generalized Lloyd algorithm [GKL, LBG], an iterative clustering descent algorithm that produces a locally optimal codebook with respect to a training sequence. For tree-structured codebook, Chou, Lookabaugh, and Gray <ref> [CLG] </ref> propose a tree pruning heuristic based on the BFOS algorithm [BFO] in which a given initial tree is pruned back according to certain optimization criterion. Their heuristic traces the lower convex hull of the distortion-rate function and the final pruned subtrees are optimal for their rates. <p> Tree-structured vector quantizers also have a distinguished "successive approximation" and "graceful degradation" character. In this section we present an approximate tree pruning algorithm. Besides pruned tree-structured vector quantization (PTSVQ), the tree pruning problem has many other applications such as regression trees, decision trees, and computer graphics <ref> [BFO, CLG] </ref>. Our notations in this section follow that of [CLG]. A tree T is a finite set of nodes, t 0 ; t 1 ; . . . ; t n , with a unique root node t 0 . <p> In this section we present an approximate tree pruning algorithm. Besides pruned tree-structured vector quantization (PTSVQ), the tree pruning problem has many other applications such as regression trees, decision trees, and computer graphics [BFO, CLG]. Our notations in this section follow that of <ref> [CLG] </ref>. A tree T is a finite set of nodes, t 0 ; t 1 ; . . . ; t n , with a unique root node t 0 . The set of leaves of a tree T is denoted by e T . <p> Therefore, we have to use heuristics in practice <ref> [BFO, CLG] </ref>. 3.1 Approximate Tree Pruning The following is an outline of the approximate tree pruning algorithm: 1. Solve the linear program relaxation of the tree pruning problem by linear pro gramming techniques; denote the fractional solution by b x. 2.
Reference: [Chv] <author> V. Chvatal, </author> <title> "A Greedy Heuristic for the Set-Covering Problem," </title> <booktitle> Mathematics 9 of Operations Research 4 (1979), </booktitle> <pages> 233-235. </pages>
Reference-contexts: One of the most important strategies for obtaining provably good approximation algorithms to an integer program is to drop the integrality constraints, solve the resulting linear programming problem, 2 and then round the solution to an integral solution. Much work along this line has been done, for example <ref> [Chv, Lov, Rag, RaT] </ref>. In [LiV], we build on previous work and propose new transformation methods for obtaining provably good solutions from linear program relaxation of a type of 0-1 optimization problems. These methods can be applied to codebook design problems. <p> A vector t i is in S j if and only if d 2 X (t i ; t j ) (1+*) c D i . 3. Apply the greedy set covering algorithm <ref> [Chv, Joh, Lov] </ref>: Choose the set which covers the most uncovered vectors. Repeat this process until all vectors are covered. Let U be the set of indices of sets chosen by the greedy heuristic.
Reference: [Dan] <author> G. Dantzig, </author> <title> "Programming of Interdependent Activities, II, Mathematical Models," in Activity Analysis of Production and Allocation, </title> <publisher> John Wiley & Sons, Inc, </publisher> <address> New York, </address> <year> 1951, </year> <pages> 19-32. </pages>
Reference-contexts: In practice, the simplex method <ref> [Dan] </ref> has been proven to be very efficient, although its worst case performance is not polynomial. 2 2 Full-Search Vector Quantization In this section, we present an approximation algorithm for the (discrete) full-search (vector quantization) codebook design problem.
Reference: [GNR] <author> R. S. Garfinkel, A. W. Neebe, and M. R. Rao, </author> <title> "An Algorithm for the M - Median Plant Location Problem," </title> <booktitle> Transportation Science 8 (1974), </booktitle> <pages> 217-236. </pages>
Reference-contexts: The number of variables in the linear program is O (n 2 ) and the number of constraints is also O (n 2 ). A straightforward 7 implementation of the simplex method for linear programming requires O (n 4 ) space. By the decomposition technique in <ref> [GNR] </ref>, the space requirement can be reduced to O (n 2 ). Unfortunately, for image compression, the number of training vectors can be in the order of 10 6 . Therefore, it may require gigabytes of memory to solve the linear program.
Reference: [Ger] <author> A. Gersho, </author> <title> "On the Structure of Vector Quantizers," </title> <journal> IEEE Transactions on Information Theory 28 (March 1982), </journal> <pages> 157-166. </pages>
Reference-contexts: 1 Introduction A full-search vector quantizer partitions a signal space into regions each of which is represented by a representative vector <ref> [Ger, GeG, Gra] </ref>. In full-search vector quantization, the distortion between an input vector and each representative vector (codeword) in an unstructured codebook is computed. The input vector is then represented by the index of the codeword with minimum distortion.
Reference: [GeG] <author> A. Gersho and R. M. Gray, </author> <title> Vector Quantization and Signal Compression, </title> <publisher> Kluwer Academic Press, </publisher> <address> Massachusetts, </address> <year> 1991. </year>
Reference-contexts: 1 Introduction A full-search vector quantizer partitions a signal space into regions each of which is represented by a representative vector <ref> [Ger, GeG, Gra] </ref>. In full-search vector quantization, the distortion between an input vector and each representative vector (codeword) in an unstructured codebook is computed. The input vector is then represented by the index of the codeword with minimum distortion.
Reference: [Gra] <author> R. M. Gray, </author> <title> "Vector Quantization," </title> <journal> IEEE ASSP Magazine (April 1984), </journal> <pages> 4-29. </pages>
Reference-contexts: 1 Introduction A full-search vector quantizer partitions a signal space into regions each of which is represented by a representative vector <ref> [Ger, GeG, Gra] </ref>. In full-search vector quantization, the distortion between an input vector and each representative vector (codeword) in an unstructured codebook is computed. The input vector is then represented by the index of the codeword with minimum distortion.
Reference: [GKL] <author> R. M. Gray, J. C. Kieffer, and Y. Linde, </author> <title> "Locally Optimal Block Quantizer Design," </title> <booktitle> Information and Control 45 (1980), </booktitle> <pages> 178-198. </pages>
Reference-contexts: The methods for code-book design usually involve the use of a training sequence. The training sequence is a collection of sample signal from the source to be coded. The most popular algorithm for full-search codebook design is the generalized Lloyd algorithm <ref> [GKL, LBG] </ref>, an iterative clustering descent algorithm that produces a locally optimal codebook with respect to a training sequence.
Reference: [Joh] <author> D. S. Johnson, </author> <title> "Approximation Algorithms for Combinatorial Problems," </title> <journal> Journal of Computer and System Sciences 9 (1974), </journal> <pages> 256-278. </pages>
Reference-contexts: A vector t i is in S j if and only if d 2 X (t i ; t j ) (1+*) c D i . 3. Apply the greedy set covering algorithm <ref> [Chv, Joh, Lov] </ref>: Choose the set which covers the most uncovered vectors. Repeat this process until all vectors are covered. Let U be the set of indices of sets chosen by the greedy heuristic.
Reference: [Kar] <author> N. Karmarkar, </author> <title> "A New Polynomial-Time Algorithm for Linear Programming," </title> <booktitle> Combinatorica 4 (1984), </booktitle> <pages> 373-395. </pages>
Reference-contexts: Our approximate tree pruning algorithm works for general trees and applies to other cost constraints, such as the average path length and the leaf entropy. 2 The linear programming problem can be solved in polynomial time by the ellipsoid algorithm [Kha] or by the interior point method <ref> [Kar] </ref>. In practice, the simplex method [Dan] has been proven to be very efficient, although its worst case performance is not polynomial. 2 2 Full-Search Vector Quantization In this section, we present an approximation algorithm for the (discrete) full-search (vector quantization) codebook design problem.
Reference: [Kha] <author> L. G. Khachiyan, </author> <title> "A Polynomial Algorithm in Linear Programming," </title> <journal> Soviet Math. </journal> <volume> Doklady 20 (1979), </volume> <pages> 191-194. </pages>
Reference-contexts: Our approximate tree pruning algorithm works for general trees and applies to other cost constraints, such as the average path length and the leaf entropy. 2 The linear programming problem can be solved in polynomial time by the ellipsoid algorithm <ref> [Kha] </ref> or by the interior point method [Kar].
Reference: [LSC] <author> J. Lin, J. A. Storer, and M. Cohn, </author> <title> "On the Complexity of Optimal Tree Pruning for Source Coding," </title> <booktitle> in Proceedings of the Data Compression Conference, </booktitle> <editor> J. A. Storer and J. H. Reif, eds., </editor> <address> Snowbird, Utah, </address> <month> April </month> <year> 1991, </year> <pages> 63-72. </pages>
Reference-contexts: However, if there is no point (pruned subtree) on the lower convex hull at a desired rate, it requires time-sharing between two neighboring points (pruned subtrees). Lin, Storer, and Cohn <ref> [LSC] </ref> show that the tree pruning problem is N P-hard in general. 1 In this paper, we propose a new approach for codebook design based on linear programming. <p> program for the optimal tree pruning problem is to minimize the cost X x t D (t) (12) subject to X t2path ( e t) x t = 1; e t 2 e T ; (13) t2T x t 2 f0; 1g; t 2 T: (15) Lin, Storer, and Cohn <ref> [LSC] </ref> show that, in general, the tree pruning problem is N P-hard. Therefore, we have to use heuristics in practice [BFO, CLG]. 3.1 Approximate Tree Pruning The following is an outline of the approximate tree pruning algorithm: 1.
Reference: [LiV] <author> J.-H. Lin and J. S. Vitter, </author> <title> "*-Approximations with Minimum Packing Constraint Violation," </title> <note> submitted for publication. </note>
Reference-contexts: Much work along this line has been done, for example [Chv, Lov, Rag, RaT]. In <ref> [LiV] </ref>, we build on previous work and propose new transformation methods for obtaining provably good solutions from linear program relaxation of a type of 0-1 optimization problems. These methods can be applied to codebook design problems. In Section 2, we present a greedy full-search codebook formation algorithm. <p> Let U be the set of indices of sets chosen by the greedy heuristic. Output U = ft j g j2U as the codebook. 3 3 The codebook can be further improved by the generalized Lloyd algorithm. 3 By the results in <ref> [LiV] </ref>, we have the following application: Corollary 1 Given any * &gt; 0, the greedy codebook formation algorithm outputs a codebook U of size at most (1 + 1=*)s (ln n + 1) such that 1 n i=1 min t j 2U d 2 (1 + *) c D (1 + <p> Given * &gt; 0, in a top-down and breadth-first fashion, we prune the tree at any node t where P t 0 2path (t) b x t 0 1=(1 + *). The results in <ref> [LiV] </ref> imply the following: Corollary 2 Given any * &gt; 0, the approximate tree pruning algorithm outputs a pruned subtree S satisfying C (S) (1 + 1=*)C and D (S) (1 + *) c D (1 + *)D, where c D is the distortion of the optimal fractional solution for the <p> A probability tree functional u fl is monotonic nondecreasing if and only if for any subtree S of T , we have u (S) 0. Similarly, u fl is monotonic nonincreasing if and only if u (S) 0 for any subtree S of T . The results in <ref> [LiV] </ref> imply the following monotonic properties of probability tree functionals: Corollary 3 If a linear tree functional u is monotonic nondecreasing (nonincreasing), then the probability tree functional u fl is also monotonic nondecreasing (nonincreasing).
Reference: [LBG] <author> Y. Linde, A. Buzo, and R. M. Gray, </author> <title> "An Algorithm for Vector Quantizer Design," </title> <journal> IEEE Transactions on Communications COM-28 (January 1980), </journal> <pages> 84-95. </pages>
Reference-contexts: The methods for code-book design usually involve the use of a training sequence. The training sequence is a collection of sample signal from the source to be coded. The most popular algorithm for full-search codebook design is the generalized Lloyd algorithm <ref> [GKL, LBG] </ref>, an iterative clustering descent algorithm that produces a locally optimal codebook with respect to a training sequence.
Reference: [Lov] <author> L. Lovasz, </author> <title> "On the Ratio of Optimal Integral and Fractional Covers," </title> <booktitle> Discrete Mathematics 13 (1975), </booktitle> <pages> 383-390. </pages>
Reference-contexts: One of the most important strategies for obtaining provably good approximation algorithms to an integer program is to drop the integrality constraints, solve the resulting linear programming problem, 2 and then round the solution to an integral solution. Much work along this line has been done, for example <ref> [Chv, Lov, Rag, RaT] </ref>. In [LiV], we build on previous work and propose new transformation methods for obtaining provably good solutions from linear program relaxation of a type of 0-1 optimization problems. These methods can be applied to codebook design problems. <p> A vector t i is in S j if and only if d 2 X (t i ; t j ) (1+*) c D i . 3. Apply the greedy set covering algorithm <ref> [Chv, Joh, Lov] </ref>: Choose the set which covers the most uncovered vectors. Repeat this process until all vectors are covered. Let U be the set of indices of sets chosen by the greedy heuristic.
Reference: [Pap] <author> C. H. Papadimitriou, </author> <title> "Worst-case and Probabilistic Analysis of a Geometric Location Problem," </title> <journal> SIAM Journal on Computing 10 (1981), </journal> <pages> 542-557. </pages>
Reference-contexts: Clearly, the optimal fractional solution (linear program solution) is a lower bound on the solutions of the full-search codebook design problem. The N P-hardness result in <ref> [Pap] </ref> can be easily modified to show that the full search codebook design problem is N P-hard. 2.1 A Greedy Codebook Formation Algorithm The following is the greedy codebook formation algorithm: 1.
Reference: [Rag] <author> P. Raghavan, </author> <title> "Probabilistic Construction of Deterministic Algorithms: Approximating Packing Integer Programs," </title> <journal> Journal of Computer and System Science 37 (1988), </journal> <pages> 130-143. </pages>
Reference-contexts: One of the most important strategies for obtaining provably good approximation algorithms to an integer program is to drop the integrality constraints, solve the resulting linear programming problem, 2 and then round the solution to an integral solution. Much work along this line has been done, for example <ref> [Chv, Lov, Rag, RaT] </ref>. In [LiV], we build on previous work and propose new transformation methods for obtaining provably good solutions from linear program relaxation of a type of 0-1 optimization problems. These methods can be applied to codebook design problems.
Reference: [RaT] <author> P. Raghavan and C. D. Thompson, </author> <title> "Randomized Rounding: A Technique for Provably Good Algorithms and Algorithmic Proofs," </title> <booktitle> Combinatorics 7 (1987), </booktitle> <pages> 365-374. </pages>
Reference-contexts: One of the most important strategies for obtaining provably good approximation algorithms to an integer program is to drop the integrality constraints, solve the resulting linear programming problem, 2 and then round the solution to an integral solution. Much work along this line has been done, for example <ref> [Chv, Lov, Rag, RaT] </ref>. In [LiV], we build on previous work and propose new transformation methods for obtaining provably good solutions from linear program relaxation of a type of 0-1 optimization problems. These methods can be applied to codebook design problems.
Reference: [Ris] <author> E. A. Riskin, </author> <title> Variable Rate Vector Quantization of Images, </title> <publisher> Ph. </publisher> <address> D. </address> <institution> Dissertation, Stanford University, </institution> <year> 1990. </year> <month> 10 </month>
Reference-contexts: The results indicate that the performances of PTSVQs and pseudo-random PTSVQs are very similar. Compared with similar experiments by Riskin in <ref> [Ris] </ref>, our approximate tree pruning algorithm performs at least as well as the generalized BFOS algorithm, although we use a different initial tree. We also note that the PSNRs can be further improved by predictive coding techniques as indicated in [Ris]. 5 Conclusions In this paper, we propose a new approach <p> Compared with similar experiments by Riskin in <ref> [Ris] </ref>, our approximate tree pruning algorithm performs at least as well as the generalized BFOS algorithm, although we use a different initial tree. We also note that the PSNRs can be further improved by predictive coding techniques as indicated in [Ris]. 5 Conclusions In this paper, we propose a new approach for vector quantization codebook design problems. Our method is to formulate a codebook design problem as a 0-1 integer linear program.
References-found: 20

