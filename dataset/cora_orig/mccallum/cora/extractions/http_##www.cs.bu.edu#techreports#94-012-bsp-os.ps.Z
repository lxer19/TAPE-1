URL: http://www.cs.bu.edu/techreports/94-012-bsp-os.ps.Z
Refering-URL: http://cs-www.bu.edu/techreports/Home.html
Root-URL: 
Email: heddaya@cs.bu.edu  amr@das.harvard.edu  
Title: OS Support for Portable Bulk Synchronous Parallel Programs (Position Paper)  
Author: Abdelsalam Heddaya Amr F. Fahmy 
Date: December 5, 1994  
Address: Boston University  
Affiliation: Computer Science Dept.  Aiken Computation Lab Harvard University  
Pubnum: BU-CS-94-012  
Abstract: For parallel programs to become portable, they must be executable with uniform efficiency on a variety of hardware platforms, which is not the case at present. In 1990, Valiant proposed Bulk-Synchronous Parallelism (BSP) as a model on which portable parallel programs can be built [Val90a]. We argue that shared-memory BSP is efficiently implementable on a wide variety of parallel hardware, and that BSP forms a useful basis for providing an even higher level programming interface based on Sequential Consistency (SC). A list of OS memory and thread management features needed to support BSP and SC parallel programs are given, under the assumption that the parallel computer is space-shared among multiple parallel task, rather than time-shared. Known techniques to realize efficiently the most important of these features are sketched. fl This document is available electronically as URL "ftp://cs-ftp.bu.edu/techreports/94-012-bsp-os.ps.Z". y Contact author. Address: 111 Cummington St., Boston, MA 02215. Phone: 617 353-8922. Fax: 617 353-6457. Research supported in part by NSF grants IRI-9041581 and CDA-8920936. z Research supported in part by ARPA contract no. F19628-92-C-0113 and by NSF grant CDA-9308833. 
Abstract-found: 1
Intro-found: 1
Reference: [BHMW94] <author> D.C. Burger, R.S. Hyder, B.P. Miller, and D.A. Wood. </author> <title> Paging tradeoffs in distributed-shared-memory multiprocessors. </title> <booktitle> In Proc. Supercomputing '94, </booktitle> <month> Nov. </month> <year> 1994. </year>
Reference-contexts: Virtual memory (VM) can offer additional programming convenience, for both the SC and BSP models, by allowing the address spaces A 1 and A 2 to be larger than the available physical memory. However, not all classes of applications can afford the cost of virtual memory. In <ref> [BHMW94] </ref>, Burger et al. show that many parallel programs have working sets so large as to render VM performance overhead unacceptable. 4 Implementation Techniques 4.1 Memory Management Mapping program data structures onto the BSP address space, A 2 , is relatively straightforward: either let the programmer do it manually, or automate
Reference: [CDG + 93] <author> D.E. Culler, A. Dusseau, S.C. Goldstein, A. Krishnamurthy, S. Lumetta, T. von Eicken, and K. Yelick. </author> <title> Introduction to Split-C: Version 1.0. </title> <type> Technical report, </type> <institution> Univ. of Cali-fornia, Berkeley, EECS, Computer Science Division, </institution> <month> April </month> <year> 1993. </year>
Reference-contexts: The Split-C programming language represents an instance of the latter approach <ref> [CDG + 93] </ref>. An array X in Split-C can be automatically mapped by the compiler in blocked or cyclic fashion, corresponding to X [i] being allocated in memory module bi=pc, or in module (i mod p), respectively. There's also a generalized blocked cyclic mapping for multidimensional arrays.
Reference: [CFSV95] <author> T.E. Cheatham, A. Fahmy, D.C. Stefanescu, and L.G. Valiant. </author> <title> Bulk synchronous parallel computing: A paradigm for transportable software. </title> <booktitle> In Proc. 28th Hawaii International Conference on System Sciences, </booktitle> <address> Maui, Hawaii, </address> <month> Jan. </month> <year> 1995. </year>
Reference-contexts: An optimally portable BSP algorithm for matrix multiplication is described in <ref> [CFSV95] </ref>. A BSP programming language and run-time library is presented in [McC94a]. SC.
Reference: [CKA91] <author> David Chaiken, John Kubiatowics, and Anant Agarwal. </author> <title> LimitLESS directories: a scalable cache coherence scheme. </title> <booktitle> In Proc. 4th ACM Intl. Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <address> Santa Clara, California, </address> <pages> pages 224-234, </pages> <month> Apr. </month> <year> 1991. </year> <note> Describes the Alewife machine. </note>
Reference-contexts: Many parallel computer designers believe that, for large classes of SC programs that possess high locality in inter-processor communication, it is possible to achieve most of the convenience of PRAM programming, and most of the efficiency of hardware-specialized programs <ref> [LLG + 92, CKA91] </ref>. In this position paper, we briefly describe the BSP and SC models, work out the OS features they require, and survey the known implementation techniques needed to deliver both a BSP and an SC programming interface.
Reference: [CKP + 93] <author> D. Culler, R. Karp, D. Patterson, A. Sahay, K.E. Schauser, E. Santos, R. Subramonian, and T. von Eicken. </author> <title> LogP: Towards a realistic model of parallel computation. </title> <booktitle> In Proc. 8 4th ACM SIGPLAN Symp. on Principles and Practice of Parallel Programming, </booktitle> <address> San Diego, </address> <month> May </month> <year> 1993. </year> <note> Superseded by a later tech report. </note>
Reference-contexts: Several years ago, two new models have been proposed that strike a fresh balance between the 1 In comparison to a special purpose computer embodying the same program. 1 two extremes, Bulk-Synchronous Parallelism (BSP) [Val90a], and LogP <ref> [CKP + 93] </ref>. Furthermore, at least one of these models (BSP) promises to form an excellent framework in which to implement the sequentially consistent (SC) shared memory model [Lam79] and its variants (e.g., [GLL + 90]).
Reference: [GLL + 90] <author> Kourosh Gharachorloo, D. Lenoski, J. Laudon, P. Gibbons, Anoop Gupta, and John Hennessy. </author> <title> Memory consistency and event ordering in scalable shared-memory multiprocessors. </title> <booktitle> In Proc. 17th Annual International Symposium on Computer Architecture, </booktitle> <month> May </month> <year> 1990. </year>
Reference-contexts: Furthermore, at least one of these models (BSP) promises to form an excellent framework in which to implement the sequentially consistent (SC) shared memory model [Lam79] and its variants (e.g., <ref> [GLL + 90] </ref>). SC models share with PRAM the assumption that remote and local memory are equidistant, but do not ignore the cost of synchronization.
Reference: [Lam79] <author> Leslie Lamport. </author> <title> How to make a multiprocessor computer that correctly executes mul-tiprocess programs. </title> <journal> IEEE Trans. on Computers, </journal> <volume> C-28(9):690-691, </volume> <month> Sep. </month> <year> 1979. </year>
Reference-contexts: Furthermore, at least one of these models (BSP) promises to form an excellent framework in which to implement the sequentially consistent (SC) shared memory model <ref> [Lam79] </ref> and its variants (e.g., [GLL + 90]). SC models share with PRAM the assumption that remote and local memory are equidistant, but do not ignore the cost of synchronization. <p> An optimally portable BSP algorithm for matrix multiplication is described in [CFSV95]. A BSP programming language and run-time library is presented in [McC94a]. SC. Sequentially consistent shared memory <ref> [Lam79] </ref> consists of a uniform cost one-dimensional address space A 1 , such that memory operations performed by different threads form a global partial 4 order that is consistent with the ordering observed by each thread individually. 3 Intuitively, the partial ordering requirement rules out the possibility of circular data dependencies
Reference: [Lei92] <author> F. Thomas Leighton. </author> <title> Introduction to Parallel Algorithms and Architectures: Arrays, Trees, Hypercubes. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, California, </address> <year> 1992. </year> <note> Vol II draft available as MIT/LCS/RSS10. </note>
Reference-contexts: In reaction, many theoreticians, as well as programmers, decided that parallel algorithms should be designed, analyzed and programmed for models that explicitly account for the detailed characteristics of the communication and synchronization hardware <ref> [Lei92] </ref>. As a result, a wide range of architectures exist today for parallel computing. Each can be programmed in its own language using its own library for its own specialized hardware. Such programs are usually hard to write in the first place and tend to be non-portable to other platforms.
Reference: [LEK91] <author> Richard P. LaRowe, Carla Schlatter Ellis, and Laurence S. Kaplan. </author> <title> The robustness of NUMA memory management. </title> <booktitle> In Proc. 13th ACM Symp. on Operating System Principles, Asilomar, California, </booktitle> <pages> pages 137-151, </pages> <month> Oct. </month> <year> 1991. </year>
Reference-contexts: There are two known approaches to handle this problem. The first approach moves, copies or caches the hot-spot item, depending on the particular mix of concurrent operations issued <ref> [LEK91] </ref>. Another approach combines the concurrent operations in a tree-like structure, rooted at the hot-spot memory module.
Reference: [LH89] <author> Kai Li and Paul Hudak. </author> <title> Memory coherence in shared virtual memory systems. </title> <journal> ACM Trans. on Computer Systems, </journal> <volume> 7(4) </volume> <pages> 321-359, </pages> <month> Nov. </month> <year> 1989. </year>
Reference: [LLG + 92] <author> Daniel Lenoski, James Laudon, Kourosh Gharachorloo, Wolf-Dietrich Weber, Anoop Gupta, John Hennessy, Mark Horowitz, and Monica S. Lam. </author> <title> The Stanford Dash multiprocessor. </title> <journal> IEEE Computer, </journal> <volume> 25(3) </volume> <pages> 63-79, </pages> <month> Mar. </month> <year> 1992. </year>
Reference-contexts: Many parallel computer designers believe that, for large classes of SC programs that possess high locality in inter-processor communication, it is possible to achieve most of the convenience of PRAM programming, and most of the efficiency of hardware-specialized programs <ref> [LLG + 92, CKA91] </ref>. In this position paper, we briefly describe the BSP and SC models, work out the OS features they require, and survey the known implementation techniques needed to deliver both a BSP and an SC programming interface.
Reference: [McC94a] <editor> W.F. McColl. </editor> <booktitle> BSP programming. In DIMACS series of Discrete Mathematics and Theoretical Computer Science, </booktitle> <year> 1994. </year> <note> To appear. </note>
Reference-contexts: An optimally portable BSP algorithm for matrix multiplication is described in [CFSV95]. A BSP programming language and run-time library is presented in <ref> [McC94a] </ref>. SC.
Reference: [McC94b] <author> W.F. McColl. </author> <title> Measurements of l, g for various parallel computing platforms. </title> <type> Private communication., </type> <month> Nov. </month> <year> 1994. </year>
Reference-contexts: Hence, processor utilization|roughly equivalent to parallel efficiency|will be at least 1 2 even in the extreme case where every step in every thread requires remote communication. Recent measurements by McColl indicate that L=g ranges from tens to hundreds of threads per processor <ref> [McC94b] </ref>. 2. Map the program's address space|be it BSP's A 2 or SC's A 1 |onto the machine's distributed memory so as to avoid the creation of hot-spot modules. 3. Place threads on nodes so as to enhance locality of reference, thus minimizing communication and synchronization across the network. 4.
Reference: [Val90a] <author> L.G. Valiant. </author> <title> A bridging model for parallel computation. </title> <journal> Comm. ACM, </journal> <volume> 33(8) </volume> <pages> 103-111, </pages> <month> Aug. </month> <year> 1990. </year>
Reference-contexts: Several years ago, two new models have been proposed that strike a fresh balance between the 1 In comparison to a special purpose computer embodying the same program. 1 two extremes, Bulk-Synchronous Parallelism (BSP) <ref> [Val90a] </ref>, and LogP [CKP + 93]. Furthermore, at least one of these models (BSP) promises to form an excellent framework in which to implement the sequentially consistent (SC) shared memory model [Lam79] and its variants (e.g., [GLL + 90]). <p> A 1 = [1::C] One-dimensional address space C &gt; m d requires virtual memory. parameter g, defined as the ratio between the processing rate and the network delivery rate, i.e., the interval between successive words delivered by the network, expressed in processor cycles <ref> [Val90a] </ref>. In other words, g is the inverse of the per-node share of the network bandwidth, given in terms of cycles/word. The synchronization cost of the machine is embodied in the parameter L, given by the number of cycles required to achieve barrier synchronization across all p processors.
Reference: [Val90b] <author> L.G. Valiant. </author> <title> General purpose parallel architectures. </title> <publisher> Elsevier & MIT Press, </publisher> <address> Amster-dam, New York and Cambridge (Mass.), </address> <year> 1990. </year>
Reference-contexts: be attributed to the existence of high level programming languages based on the von Neumann machine model [vN45] which is both simple and predictably uniformly efficient, in the sense that a program compiled for this model can be automatically optimized to run efficiently 1 on a variety of hardware platforms <ref> [Val90b] </ref>. The von Neumann model, formalized for the purpose of algorithm analysis as the Random Access Machine (RAM), is simple and "high level" because it ignores the differences in the costs of individual computational steps, as well as the variation in the cost of communication between processor and memory. <p> The average effect of such false sharing can be minimized, by allocating memory using a randomly chosen hash function, which minimizes the likelihood that concurrently referenced A 1 locations will fall in the same module <ref> [Val90b] </ref>.
Reference: [Val92] <author> L.G. Valiant. </author> <title> A combining mechanism for parallel computers. </title> <type> Technical Report TR-24-92, </type> <institution> Harvard University, Center for Research in Computing Technology, </institution> <month> Nov. </month> <year> 1992. </year>
Reference-contexts: The first approach moves, copies or caches the hot-spot item, depending on the particular mix of concurrent operations issued [LEK91]. Another approach combines the concurrent operations in a tree-like structure, rooted at the hot-spot memory module. Combining can be done in hardware, as in the CM-5, or in software <ref> [Val92] </ref>. 4.2 Thread Management There are three major methods to share a machine among multiple parallel tasks: batch, timesharing and space-sharing The first of these is the most efficient, yet the least flexible, rendering interactive parallel computing infeasible.
Reference: [vN45] <author> J. von Neumann. </author> <title> First draft of a report on the EDVAC. </title> <type> Technical report, </type> <institution> University of Pennsylvania, </institution> <year> 1945. </year> <month> 9 </month>
Reference-contexts: 1 Introduction General purpose sequential computing has enjoyed great success. This can be attributed to the existence of high level programming languages based on the von Neumann machine model <ref> [vN45] </ref> which is both simple and predictably uniformly efficient, in the sense that a program compiled for this model can be automatically optimized to run efficiently 1 on a variety of hardware platforms [Val90b].
References-found: 17

