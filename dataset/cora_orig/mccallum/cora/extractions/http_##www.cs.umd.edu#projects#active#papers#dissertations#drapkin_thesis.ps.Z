URL: http://www.cs.umd.edu/projects/active/papers/dissertations/drapkin_thesis.ps.Z
Refering-URL: http://www.cs.umd.edu/projects/active/papers/papers.html
Root-URL: 
Abstract-found: 0
Intro-found: 1
Reference: [All84] <author> J. Allen. </author> <title> Towards a general theory of action and time. </title> <journal> Artificial Intelligence, </journal> <volume> 23:123--154, </volume> <year> 1984. </year>
Reference-contexts: It is thus important for the reasoning agent to be able to recognize this passage of time. The issue of representing time within a logic has been studied intensively, e.g., by Allen <ref> [All84] </ref>, McDermott [McD82], and McKenzie and Snodgrass [MS87]. However, such representations of time are not related in any obvious way to the process of actually producing theorems in that same logic. We might call this type of time study static, for it does not require non-monotonicity. <p> A great deal of research has been devoted to this field. Perhaps the two most influential temporal formalisms are those of Allen (<ref> [All84] </ref>) and McDermott ([McD82]). In [All84], Allen develops a logic which permits reasoning about time. Time intervals are the principal objects in the domain. Three basic entities are associated with time: properties, events, and processes. <p> Finally, OCCU RRIN G (p; i) denotes the fact that process p occurred over interval i. A process is said to occur over an interval i iff it occurs over some subinterval of i. Having set up a way to handle temporal information, <ref> [All84] </ref> then proceeds to handle actions, causation, intentions, and plans. [McD82] constructs his theory using fact types and event types. Unlike Allen, McDermott uses time points as primitive. T (t; p) denotes the fact that fact type p holds at time t.
Reference: [Ari84] <institution> Arity Corporation, Concord, Massachusetts. </institution> <address> Arity/Prolog: </address> <booktitle> The Programming Environment, </booktitle> <year> 1984. </year>
Reference: [BP83] <author> J. Barwise and J. Perry. </author> <title> Situations and Attitudes. </title> <publisher> MIT Press, </publisher> <year> 1983. </year>
Reference: [Che80] <author> B. Chellas. </author> <title> Modal Logic. </title> <publisher> Cambridge University Press, </publisher> <year> 1980. </year>
Reference-contexts: that the agent is not aware of q. 1 It is interesting to note that L i acts like the classical belief operator, so that, for instance, if one assumes that the agents are aware of all formulas, the logic reduces to the classical logic of belief, weak S5 (see <ref> [Che80] </ref>). [FH88] also present a logic of local reasoning which allows agents to hold inconsistent beliefs. It is based on the fact that humans don't focus on all issues simultaneously. Thus one can view a reasoning agent as a society of minds, each with its own set of beliefs.
Reference: [CM84] <author> W. F. Clocksin and C. S. Mellish. </author> <title> Programming in Prolog. </title> <publisher> Springer-Verlag, </publisher> <address> second edition, </address> <year> 1984. </year>
Reference: [CPr84] <institution> SRI International, Menlo Park, California. </institution> <note> C-Prolog User's Manual, </note> <month> February </month> <year> 1984. </year>
Reference: [deK86a] <author> J. deKleer. </author> <title> An assumption-based TMS. </title> <journal> Artificial Intelligence, </journal> <volume> 28:127--162, </volume> <year> 1986. </year>
Reference-contexts: These new (invalid) conclusions may then be the basis for further deductions. It is this proliferation of invalid conclusions that needs to be curtailed. Currently the contradictory beliefs themselves are the only beliefs which are retracted. A mechanism similar to that of [Doy82] and <ref> [deK86a] </ref>, put into a real-time framework, may be appropriate for handling both the consequents and the antecedents of the contradictory beliefs.
Reference: [deK86b] <author> J. deKleer. </author> <title> Extending the ATMS. </title> <journal> Artificial Intelligence, </journal> <volume> 28:163--196, </volume> <year> 1986. </year>
Reference: [deK86c] <author> J. deKleer. </author> <title> Problem solving with the ATMS. </title> <journal> Artificial Intelligence, </journal> <volume> 28:197--224, </volume> <year> 1986. </year>
Reference: [DMP85] <author> J. Drapkin, M. Miller, and D. Perlis. </author> <title> Real-time default reasoning, relevance, and memory models. </title> <type> Technical Report TR-85-35, </type> <institution> Systems Research Center, University of Maryland, College Park, Maryland, </institution> <year> 1985. </year>
Reference: [DMP86a] <author> J. Drapkin, M. Miller, and D. Perlis. </author> <title> A memory model for real-time commonsense reasoning. </title> <type> Technical Report TR-86-21, </type> <institution> Systems Research Center, University of Maryland, College Park, Maryland, </institution> <year> 1986. </year>
Reference-contexts: We can think of retraction in terms of lack of inheritance. Introducing a notion of relevance along the lines pursued in <ref> [DMP86a] </ref>, where a computational model of memory was proposed, would help in this regard. We envision a given step as being a sort of short-term memory (STM) as in [DMP86a], where only a very small number of beliefs are held at any given time. <p> Introducing a notion of relevance along the lines pursued in <ref> [DMP86a] </ref>, where a computational model of memory was proposed, would help in this regard. We envision a given step as being a sort of short-term memory (STM) as in [DMP86a], where only a very small number of beliefs are held at any given time. This would be the working set of beliefs. This requires the use of a notion of relevance: those beliefs relevant to the current task at hand would be retained; all others would not.
Reference: [DMP86b] <author> J. Drapkin, M. Miller, and D. Perlis. </author> <title> On default handling: Consistency before and after. </title> <type> Technical Report TR-86-20, </type> <institution> Systems Research Center, University of Maryland, College Park, Maryland, </institution> <year> 1986. </year>
Reference: [Doy82] <author> J. Doyle. </author> <title> Some theories of reasoned assumptions: An essay in rational psychology. </title> <type> Technical report, </type> <institution> Department of Computer Science, Carnegie Mellon University, </institution> <year> 1982. </year>
Reference-contexts: These new (invalid) conclusions may then be the basis for further deductions. It is this proliferation of invalid conclusions that needs to be curtailed. Currently the contradictory beliefs themselves are the only beliefs which are retracted. A mechanism similar to that of <ref> [Doy82] </ref> and [deK86a], put into a real-time framework, may be appropriate for handling both the consequents and the antecedents of the contradictory beliefs.
Reference: [DP86a] <author> J. Drapkin and D. Perlis. </author> <title> A preliminary excursion into step-logics. </title> <booktitle> In Proceedings SIGART International Symposium on Methodologies for Intelligent Systems, pages 262--269. ACM, 1986. </booktitle> <address> Knoxville, Tennessee. </address>
Reference-contexts: Two commonsense reasoning problems, the Brother problem and the Three-wise-men problem, are modelled using step-logic. 1.3 Outline of Thesis In this section I briefly sketch the research which this dissertation encompasses. Some of the work reported on includes work done jointly with my advisor; see <ref> [DP86b, DP86a, EDP88] </ref>. Chapter 2 provides an overview of step-logic. I describe how it is different from traditional logic, and why it is that this new logic is needed. Reasoning agents that are logically omniscient are described and contrasted with those that have limited reasoning capabilities.
Reference: [DP86b] <author> J. Drapkin and D. Perlis. Step-logics: </author> <title> An alternative approach to limited reasoning. </title> <booktitle> In Proceedings of the European Conf. on Artificial Intelligence, pages 160--163, 1986. </booktitle> <address> Brighton, England. </address>
Reference-contexts: Two commonsense reasoning problems, the Brother problem and the Three-wise-men problem, are modelled using step-logic. 1.3 Outline of Thesis In this section I briefly sketch the research which this dissertation encompasses. Some of the work reported on includes work done jointly with my advisor; see <ref> [DP86b, DP86a, EDP88] </ref>. Chapter 2 provides an overview of step-logic. I describe how it is different from traditional logic, and why it is that this new logic is needed. Reasoning agents that are logically omniscient are described and contrasted with those that have limited reasoning capabilities. <p> See [Get63] for a discussion of belief vs. knowledge. 11 In <ref> [DP86b] </ref> we proposed eight step-logic pairs, arranged in increasing sophistication with respect to the three mechanisms above (self-knowledge (S), time (T), and retraction (R)).
Reference: [EDP88] <author> J. Elgot-Drapkin and D. Perlis. </author> <title> Reasoning situated in time I: Basic concepts. </title> <type> Technical Report CS-TR-2016, </type> <institution> Department of Computer Science, University of Maryland, College Park, Maryland, </institution> <month> April </month> <year> 1988. </year>
Reference-contexts: Two commonsense reasoning problems, the Brother problem and the Three-wise-men problem, are modelled using step-logic. 1.3 Outline of Thesis In this section I briefly sketch the research which this dissertation encompasses. Some of the work reported on includes work done jointly with my advisor; see <ref> [DP86b, DP86a, EDP88] </ref>. Chapter 2 provides an overview of step-logic. I describe how it is different from traditional logic, and why it is that this new logic is needed. Reasoning agents that are logically omniscient are described and contrasted with those that have limited reasoning capabilities. <p> Chapters 6 and 7 define particular SL 7 -theories which are suitable for the Brother problem and the Three-wise-men problem, respectively. 22 6 The Brother Problem In this chapter I report on work done in <ref> [EDP88] </ref> in which we presented a real-time solution to the Brother problem (see [Moo83]). An implementation for this problem can be found in Appendix D. 6.1 Statement of the Problem We reiterate the problem which was described above in Section 2.3.
Reference: [FH88] <author> R. Fagin and Y. Halpern, J. </author> <title> Belief, awareness, and limited reasoning. </title> <journal> Artificial Intelligence, </journal> <volume> 34(1):39--76, </volume> <year> 1988. </year>
Reference-contexts: Fagin and Halpern (<ref> [FH88] </ref>) extend Levesque's notion of implicit and explicit beliefs to allow for multiple agents and beliefs of beliefs. [FH88] propose a logic of awareness (again with explicit and implicit beliefs) which is based on the idea that one cannot have beliefs about something of which one has no knowledge. <p> The explicit beliefs, on the other hand, are generated by awareness of primitive propositions. As in [Lev84], the explicit beliefs do not necessarily include all valid formulas but, unlike [Lev84], are closed under implication. <ref> [FH88] </ref> extend their logic of awareness to include awareness of arbitrary formulas (not just primitive propositions). In addition to the operators for implicit and explicit belief (L i and B i , respectively), an operator for awareness, A i , is introduced. <p> the agent is not aware of q. 1 It is interesting to note that L i acts like the classical belief operator, so that, for instance, if one assumes that the agents are aware of all formulas, the logic reduces to the classical logic of belief, weak S5 (see [Che80]). <ref> [FH88] </ref> also present a logic of local reasoning which allows agents to hold inconsistent beliefs. It is based on the fact that humans don't focus on all issues simultaneously. Thus one can view a reasoning agent as a society of minds, each with its own set of beliefs. <p> It is based on the fact that humans don't focus on all issues simultaneously. Thus one can view a reasoning agent as a society of minds, each with its own set of beliefs. Unlike the previous logics that <ref> [FH88] </ref> propose, in this logic there is not necessarily only one set of states that an agent thinks possible, but rather many sets, each one corresponding to a different set of beliefs. <p> We can say then that the agent is ``aware of'' only certain axioms at any given step. This has some similarity to Fagin and Halpern's notion of awareness (see <ref> [FH88] </ref> and Section 2.1.1). In order to distinguish the agent's wffs from our own (i.e., wffs of SL 0 from wffs of SL 0 ), we write not (ff) for the agent's negation of ff, and implies (ff; fi) for the agent's representation of (ff ! fi).
Reference: [Get63] <author> E. Gettier. </author> <title> Is justified true belief knowledge? Analysis, </title> <address> 23:121--123, </address> <year> 1963. </year>
Reference-contexts: See <ref> [Get63] </ref> for a discussion of belief vs. knowledge. 11 In [DP86b] we proposed eight step-logic pairs, arranged in increasing sophistication with respect to the three mechanisms above (self-knowledge (S), time (T), and retraction (R)). <p> This rule is intended to have the following effect. 1 known, believed, or concluded. The distinctions between these (see <ref> [Get63, Per86, Per88b] </ref>) will not be addressed here. 19 :K (i; ff) is to be deduced at step i + 1 if ff is not an i-theorem, but does appear as a closed sub-formula at step i. 2 We regard the closed sub-formulas at step i as approximating the wffs that
Reference: [Gra78] <author> J. Grant. </author> <title> Classifications for inconsistent theories. </title> <journal> Notre Dame Journal of Formal Logic, </journal> <volume> 19(3), </volume> <year> 1978. </year>
Reference: [Haa85] <author> A. Haas. </author> <title> Possible events, actual events, and robots. </title> <booktitle> Computational Intelligence, </booktitle> <address> 1(2):59--70, </address> <year> 1985. </year>
Reference-contexts: But time spent in such derivations is concurrent with changes in the world. Thus, for example, it is not appropriate to spend hours figuring out a plan to save Nell from an onrushing train; she will no longer need saving by then (see [McD82] and <ref> [Haa85] </ref>). Even if the only changes are within the agent, this is still important, for it may be useful to know whether a problem is nearing solution, or if one has only begun initial explorations, and so on. <p> A train is quickly approaching, and Dudley must determine how to save her. [McD82] discusses this problem in terms of prevention of an act---one must prevent Nell from being destroyed by the train. <ref> [Haa85] </ref> expands upon this work; he distinguishes between possible and actual situations. What we find pertinent is the fact that Dudley has a limited amount of time in which he must find a solution.
Reference: [Haa86] <author> A. Haas. </author> <title> A syntactic theory of belief and action. </title> <journal> Artificial Intelligence, </journal> <volume> 28:245--292, </volume> <year> 1986. </year> <month> 87 </month>
Reference-contexts: Many others have contributed formalisms for reasoning about time and action including <ref> [Haa86, HS86, MB83, MS87, Moo85, Lif87, Sho88] </ref>. In contrast to these theories, the focus of this thesis is not primarily to be able to reason about time, but rather to be able to reason in time.
Reference: [Hen73] <author> G. Hendrix. </author> <title> Modeling simultaneous actions and continuous processes. </title> <journal> Artificial Intelligence, </journal> <volume> 4:145--180, </volume> <year> 1973. </year>
Reference: [HM86] <author> S. Hanks and D. McDermott. </author> <title> Default reasoning, nonmonotonic logics, and the frame problem. </title> <booktitle> In Proceedings of the Fifth National Conference on Artificial Intelligence. AAAI, 1986. </booktitle> <address> Philadelphia, PA. </address>
Reference: [HS86] <author> J. Halpern and Y. Shoham. </author> <title> A propositional modal logic of time intervals. </title> <booktitle> In Proceedings of the Symposium on Logic in Computer Science. IEEE, 1986. </booktitle> <address> Boston, MA. </address>
Reference-contexts: Many others have contributed formalisms for reasoning about time and action including <ref> [Haa86, HS86, MB83, MS87, Moo85, Lif87, Sho88] </ref>. In contrast to these theories, the focus of this thesis is not primarily to be able to reason about time, but rather to be able to reason in time.
Reference: [KL87] <author> S. Kraus and D. Lehmann. </author> <title> Knowledge, belief and time. </title> <type> Technical Report 87-4, </type> <institution> Department of Computer Science, Hebrew University, </institution> <address> Jerusalem 91904, Israel, </address> <month> April </month> <year> 1987. </year>
Reference-contexts: Our model of reasoning is particularly well-suited to this type of deduction. See Chapter 7 for a development of and solution to this problem. Others have studied this problem as well (e.g. see [Kon84] and <ref> [KL87] </ref>), but from a final-tray perspective. 2.3.2 The Brother problem [Moo83] presents the following problem. Consider my reason for believing that I do not have an older brother. <p> This idea, although quite promising, has not been investigated in any detail by the author. Many formulations of the Three-wise-men problem have involved the use of common knowledge or common belief (see [Kon84] and <ref> [KL87] </ref> in particular). For instance, a possible axiom might be C (W 1 _ W 2 _ W 3 ): it is common knowledge that at least one card is white. I found adding the common knowledge concept introduced unnecessary complications. <p> I found adding the common knowledge concept introduced unnecessary complications. This was to a large degree due to the fact that I have modelled the reasoning from wise man #1's point of view, rather than using a meta-language that describes the reasoning of all three (as <ref> [Kon84, KL87] </ref> have both done). I feel that this is more in the spirit of step-logics, where the idea is to allow the reasoner itself enough power (with no outside ``oracle'' intervention) to solve the problem.
Reference: [Kon83] <author> K. Konolige. </author> <title> A deductive model of belief. </title> <booktitle> In Proceedings of the 8th Int'l Joint Conf. on Artificial Intelligence, pages 377--381, 1983. </booktitle> <address> Karlsruhe, West Germany. </address>
Reference: [Kon84] <author> K. Konolige. </author> <title> Belief and incompleteness. </title> <type> Technical Report 319, </type> <institution> SRI International, </institution> <year> 1984. </year>
Reference-contexts: Hence traditional logics cannot be used as satisfactory models of these agents. This has brought about tremendous strides in the area of limited reasoning. We describe here several such approaches. <ref> [Kon84] </ref> includes work based on the fact that people are not always aware of all the relevant rules. A small child, for instance, may be trying to solve the equation ``x + 2 = 5''. <p> His capabilities may be limited by the fact that he does not know all the possible rules. Konolige used this idea of relevance incompleteness to get an interesting solution to the Three-wise-men problem. In Chapter 7 we present our own solution to this problem. <ref> [Kon84] </ref> also discusses two other types of limited reasoning. The first is resource-limited incompleteness, in which an agent may have the inferential capability to derive some consequence of his beliefs, yet does not have the computational resources to do so. <p> This is a difficulty that arises, for instance, in a chess-playing program. The final type of limited reasoning that <ref> [Kon84] </ref> mentions is that of fundamental logical incompleteness. It may be, for example, that an agent simply does not reason about beliefs of other agents at all. This would make a solution to the Three-wise-men problem impossible. <p> Our model of reasoning is particularly well-suited to this type of deduction. See Chapter 7 for a development of and solution to this problem. Others have studied this problem as well (e.g. see <ref> [Kon84] </ref> and [KL87]), but from a final-tray perspective. 2.3.2 The Brother problem [Moo83] presents the following problem. Consider my reason for believing that I do not have an older brother. <p> This idea, although quite promising, has not been investigated in any detail by the author. Many formulations of the Three-wise-men problem have involved the use of common knowledge or common belief (see <ref> [Kon84] </ref> and [KL87] in particular). For instance, a possible axiom might be C (W 1 _ W 2 _ W 3 ): it is common knowledge that at least one card is white. I found adding the common knowledge concept introduced unnecessary complications. <p> I found adding the common knowledge concept introduced unnecessary complications. This was to a large degree due to the fact that I have modelled the reasoning from wise man #1's point of view, rather than using a meta-language that describes the reasoning of all three (as <ref> [Kon84, KL87] </ref> have both done). I feel that this is more in the spirit of step-logics, where the idea is to allow the reasoner itself enough power (with no outside ``oracle'' intervention) to solve the problem.
Reference: [Kon85a] <author> K. Konolige. </author> <title> A computational theory of belief introspection. </title> <booktitle> In Proceedings of the 9th Int'l Joint Conf. on Artificial Intelligence, pages 503--508, 1985. </booktitle> <address> Los Angeles, CA. </address>
Reference: [Kon85b] <author> K. Konolige. </author> <title> Experimental robot psychology. </title> <type> Technical Report 363, </type> <institution> SRI International, </institution> <year> 1985. </year>
Reference: [Kow79] <author> R. Kowalski. </author> <title> Logic for Problem Solving. </title> <publisher> North Holland, </publisher> <year> 1979. </year>
Reference: [Lak86] <author> G. Lakemeyer. </author> <title> Steps towards a first-order logic of explicit and implicit belief. </title> <editor> In J. Halpern, editor, </editor> <booktitle> Proceedings of the 1986 Conference on Theoretical Aspects of Reasoning about Knowledge, pages 325--340. </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> 1986. Monterey, CA. </address>
Reference: [Lev84] <author> H. Levesque. </author> <title> A logic of implicit and explicit belief. </title> <booktitle> In Proceedings of the 3rd National Conf. on Artificial Intelligence, pages 198--202, 1984. </booktitle> <address> Austin, TX. </address>
Reference-contexts: As in <ref> [Lev84] </ref>'s logic, an agent's implicit beliefs include all valid formulas and all the logical consequences of his implicit beliefs. The explicit beliefs, on the other hand, are generated by awareness of primitive propositions. As in [Lev84], the explicit beliefs do not necessarily include all valid formulas but, unlike [Lev84], are closed under implication. [FH88] extend their logic of awareness to include awareness of arbitrary formulas (not just primitive propositions). <p> As in <ref> [Lev84] </ref>'s logic, an agent's implicit beliefs include all valid formulas and all the logical consequences of his implicit beliefs. The explicit beliefs, on the other hand, are generated by awareness of primitive propositions. As in [Lev84], the explicit beliefs do not necessarily include all valid formulas but, unlike [Lev84], are closed under implication. [FH88] extend their logic of awareness to include awareness of arbitrary formulas (not just primitive propositions). In addition to the operators for implicit and explicit belief (L i and B i , respectively), an operator for awareness, A i , is introduced.
Reference: [Lif87] <author> V. Lifschitz. </author> <title> Formal theories of action (preliminary report). </title> <booktitle> In Proceedings of the 10th Int'l Joint Conf. on Artificial Intelligence, pages 966--972. </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> 1987. Milan, Italy. </address>
Reference-contexts: Many others have contributed formalisms for reasoning about time and action including <ref> [Haa86, HS86, MB83, MS87, Moo85, Lif87, Sho88] </ref>. In contrast to these theories, the focus of this thesis is not primarily to be able to reason about time, but rather to be able to reason in time.
Reference: [Mat49] <author> B. Mates. </author> <title> Diodorean implication. </title> <journal> Philosophical Review, </journal> <volume> 58:234--242, </volume> <year> 1949. </year>
Reference: [MB83] <author> J. Malik and T. Binford. </author> <title> Reasoning in time and space. </title> <booktitle> In Proceedings of the 8th Int'l Joint Conf. on Artificial Intelligence, pages 343--345, 1983. </booktitle> <address> Karlsruhe, West Germany. </address>
Reference-contexts: Many others have contributed formalisms for reasoning about time and action including <ref> [Haa86, HS86, MB83, MS87, Moo85, Lif87, Sho88] </ref>. In contrast to these theories, the focus of this thesis is not primarily to be able to reason about time, but rather to be able to reason in time.
Reference: [McC78] <author> J. McCarthy. </author> <title> Formalization of two puzzles involving knowledge. Unpublished note, </title> <institution> Stanford University, </institution> <year> 1978. </year>
Reference-contexts: detailed solutions, including implementations, are provided for the first two: Chapter 6 contains the solution to the Brother problem and Chapter 7 contains the solution to the Three-wise-men problem. 2.3.1 The Three-wise-men problem We present a variation of this classic problem which was first introduced to the AI literature by <ref> [McC78] </ref>. A king wishes to know whether his three advisors are as wise as they claim to be. Three chairs are lined up, all facing the same direction, with one behind the other. The wise men are instructed to sit down.
Reference: [McC80] <author> J. McCarthy. </author> <title> Circumscription-a form of non-monotonic reasoning. </title> <journal> Artificial Intelligence, </journal> <volume> 13(1,2):27--39, </volume> <year> 1980. </year>
Reference-contexts: Because of this, traditional monotonic logics are unsuitable for formalizing these agents; we are again forced into a non-monotonic setting. Although several formalisms for non-monotonic reasoning have already been proposed (see <ref> [MD80, Rei80, McC80] </ref>), they do not address the issue of real-time commonsense reasoning. 1.2 Accomplishments The primary contributions of this work are the following: * A precise characterization of step-logic, a formalism designed to take into account the fact that reasoning occurs over time, is given.
Reference: [McC86] <author> J. McCarthy. </author> <title> Applications of circumscription to formalizing common-sense knowledge. </title> <journal> Artificial Intelligence, </journal> <volume> 28(1):89--116, </volume> <year> 1986. </year>
Reference: [McD82] <author> D. McDermott. </author> <title> A temporal logic for reasoning about processes and plans. </title> <booktitle> Cognitive Science, </booktitle> <address> 6:101--155, </address> <year> 1982. </year>
Reference-contexts: It is thus important for the reasoning agent to be able to recognize this passage of time. The issue of representing time within a logic has been studied intensively, e.g., by Allen [All84], McDermott <ref> [McD82] </ref>, and McKenzie and Snodgrass [MS87]. However, such representations of time are not related in any obvious way to the process of actually producing theorems in that same logic. We might call this type of time study static, for it does not require non-monotonicity. <p> But time spent in such derivations is concurrent with changes in the world. Thus, for example, it is not appropriate to spend hours figuring out a plan to save Nell from an onrushing train; she will no longer need saving by then (see <ref> [McD82] </ref> and [Haa85]). Even if the only changes are within the agent, this is still important, for it may be useful to know whether a problem is nearing solution, or if one has only begun initial explorations, and so on. <p> A process is said to occur over an interval i iff it occurs over some subinterval of i. Having set up a way to handle temporal information, [All84] then proceeds to handle actions, causation, intentions, and plans. <ref> [McD82] </ref> constructs his theory using fact types and event types. Unlike Allen, McDermott uses time points as primitive. T (t; p) denotes the fact that fact type p holds at time t. <p> Unlike Allen, McDermott uses time points as primitive. T (t; p) denotes the fact that fact type p holds at time t. OCC (t 1 ; t 2 ; e) denotes the fact that event type e occurred over the interval &lt; t 1 ; t 2 &gt;. <ref> [McD82] </ref> then uses these primitives to reason about temporal information and events. Many others have contributed formalisms for reasoning about time and action including [Haa86, HS86, MB83, MS87, Moo85, Lif87, Sho88]. <p> This problem is tackled in detail in Chapter 6, where both a formal solution and an implementation of that solution are given. 2.3.3 Little Nell Consider Little Nell who has been tied to the railroad tracks. A train is quickly approaching, and Dudley must determine how to save her. <ref> [McD82] </ref> discusses this problem in terms of prevention of an act---one must prevent Nell from being destroyed by the train. [Haa85] expands upon this work; he distinguishes between possible and actual situations.
Reference: [MD80] <author> D. McDermott and J. Doyle. </author> <title> Non-monotonic logic I. </title> <journal> Artificial Intelligence, </journal> <volume> 13(1,2):41--72, </volume> <year> 1980. </year>
Reference-contexts: Because of this, traditional monotonic logics are unsuitable for formalizing these agents; we are again forced into a non-monotonic setting. Although several formalisms for non-monotonic reasoning have already been proposed (see <ref> [MD80, Rei80, McC80] </ref>), they do not address the issue of real-time commonsense reasoning. 1.2 Accomplishments The primary contributions of this work are the following: * A precise characterization of step-logic, a formalism designed to take into account the fact that reasoning occurs over time, is given.
Reference: [Men87] <author> E. Mendelson. </author> <title> Introduction to Mathematical Logic. </title> <publisher> Wadsworth, </publisher> <address> Belmont, CA, </address> <note> 3rd edition, </note> <year> 1987. </year>
Reference-contexts: (ff) ! [(9fi)(9fl)(ff = implies (fi; implies (fl; fi)))_ (9fi)(9fl)(ff = implies (implies (not (fl); not (fi)); implies (implies (not (fl); fi); fl)))_ (9fi)(9fl)(9ffi)(ff = implies (implies (fi; implies (fl; ffi)); implies (implies (fi; fl); implies (fi; ffi))))]] *AX says that axioms are the usual three tautology types, as in <ref> [Men87] </ref>.* THM: (8ff)(8i)(K (i; ff) ! [F eed (ff; i) _ M p (ff; i)]) *THM defines what it means for ff to be proven by the agent at time-step i: either ff has been ``fed in'' (F eed (ff; i)), or ff has been derived through modus ponens from previous <p> SL 0 is a first order theory with equality, with the rules of modus ponens and generalization. Frequent use is made of the Deduction Theorem. We follow the treatment of <ref> [Men87] </ref>. A.2 Axioms of SL 0 The axioms are those listed in Section 4.2.1. A.3 Analytic Completeness A.3.1 Preliminary Lemmas Before presenting the proof of analytic completeness, we first give the following lemmas and their proofs.
Reference: [Mil56] <author> G. Miller. </author> <title> The magical number seven plus or minus two. </title> <journal> The Psychological Review, </journal> <volume> 63:81--97, </volume> <year> 1956. </year>
Reference: [Moo83] <author> R. Moore. </author> <title> Semantical considerations on nonmonotonic logic. </title> <booktitle> In Proceedings of the 8th Int'l Joint Conf. on Artificial Intelligence, 1983. </booktitle> <address> Karlsruhe, West Germany. </address>
Reference-contexts: Our model of reasoning is particularly well-suited to this type of deduction. See Chapter 7 for a development of and solution to this problem. Others have studied this problem as well (e.g. see [Kon84] and [KL87]), but from a final-tray perspective. 2.3.2 The Brother problem <ref> [Moo83] </ref> presents the following problem. Consider my reason for believing that I do not have an older brother. It is surely not that one of my parents once casually remarked, ``you know, you don't have any older brothers,'' nor have I pieced it together by carefully sifting other evidence. <p> Chapters 6 and 7 define particular SL 7 -theories which are suitable for the Brother problem and the Three-wise-men problem, respectively. 22 6 The Brother Problem In this chapter I report on work done in [EDP88] in which we presented a real-time solution to the Brother problem (see <ref> [Moo83] </ref>). An implementation for this problem can be found in Appendix D. 6.1 Statement of the Problem We reiterate the problem which was described above in Section 2.3. Moore explains: Consider my reason for believing that I do not have an older brother.
Reference: [Moo85] <author> R. Moore. </author> <title> Formal Theories of the Commonsense World, chapter A Formal Theory of Knowledge and Action, </title> <publisher> pages 319--358. Ablex Publishing Company, </publisher> <year> 1985. </year> <month> 88 </month>
Reference-contexts: Many others have contributed formalisms for reasoning about time and action including <ref> [Haa86, HS86, MB83, MS87, Moo85, Lif87, Sho88] </ref>. In contrast to these theories, the focus of this thesis is not primarily to be able to reason about time, but rather to be able to reason in time.
Reference: [MP85] <author> J. Minker and D. Perlis. </author> <title> Computing protected circumscription. </title> <journal> Journal of Logic Programming, </journal> <volume> 4:235--249, </volume> <year> 1985. </year>
Reference: [MS87] <author> E. McKenzie and R. Snodgrass. </author> <title> Extending the relational algebra to support transaction time. </title> <booktitle> In Proceedings of the SIGMOD Conference, pages 454--466. ACM, 1987. </booktitle> <address> San Francisco, California. </address>
Reference-contexts: It is thus important for the reasoning agent to be able to recognize this passage of time. The issue of representing time within a logic has been studied intensively, e.g., by Allen [All84], McDermott [McD82], and McKenzie and Snodgrass <ref> [MS87] </ref>. However, such representations of time are not related in any obvious way to the process of actually producing theorems in that same logic. We might call this type of time study static, for it does not require non-monotonicity. <p> Many others have contributed formalisms for reasoning about time and action including <ref> [Haa86, HS86, MB83, MS87, Moo85, Lif87, Sho88] </ref>. In contrast to these theories, the focus of this thesis is not primarily to be able to reason about time, but rather to be able to reason in time.
Reference: [Nil83] <author> N. Nilsson. </author> <booktitle> Artificial intelligence prepares for 2001. AI Magazine, </booktitle> <address> 4(4):7--14, </address> <year> 1983. </year>
Reference-contexts: This limitation must be recognized by the reasoner himself; that is, the agent should be able to reason about its ongoing reasoning efforts themselves. Its reasoning must be ``situated'' in a temporal environment (see [Suc86]). The paradigm for such an agent would seem to be that suggested by <ref> [Nil83] </ref>, namely, a computer individual with a lifetime of its own. What is of interest for such an agent is not its ``ultimate'' set of conclusions, but rather its changing set of conclusions over time. In fact there will be, in general, no ultimate or limiting set of conclusions. <p> This would then come that much closer to formalizing the ``computer individual'' postulated by Nilsson (see <ref> [Nil83] </ref>), where the system would have a constantly changing model of the world, learning and benefiting from its experiences. 43 A Proofs of Theorems about SL 0 This appendix contains the proofs of the results found in Section 4.2.2.
Reference: [Per81] <author> D. Perlis. </author> <title> Language, Computation, and Reality. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, University of Rochester, Rochester, </institution> <address> New York, </address> <year> 1981. </year>
Reference: [Per84] <author> D. Perlis. </author> <title> Non-monotonicity and real-time reasoning. </title> <booktitle> In Proceedings of the Workshop on Non-monotonic Reasoning. AAAI, </booktitle> <address> October 1984. New Paltz, New York. </address>
Reference: [Per85] <author> D. Perlis. </author> <title> Languages with self reference I: </title> <booktitle> Foundations. Artificial Intelligence, </booktitle> <address> 25:301--322, </address> <year> 1985. </year>
Reference: [Per86] <author> D. Perlis. </author> <title> On the consistency of commonsense reasoning. </title> <journal> Computational Intelligence, </journal> <volume> 2:180-- 190, </volume> <year> 1986. </year>
Reference-contexts: This rule is intended to have the following effect. 1 known, believed, or concluded. The distinctions between these (see <ref> [Get63, Per86, Per88b] </ref>) will not be addressed here. 19 :K (i; ff) is to be deduced at step i + 1 if ff is not an i-theorem, but does appear as a closed sub-formula at step i. 2 We regard the closed sub-formulas at step i as approximating the wffs that
Reference: [Per87] <author> D. Perlis. </author> <title> Circumscribing with sets. </title> <journal> Artificial Intelligence, </journal> <volume> 31:201--211, </volume> <year> 1987. </year>
Reference: [Per88a] <author> D. Perlis. </author> <note> Autocircumscription. To appear, Artificial Intelligence, </note> <year> 1988. </year>
Reference-contexts: It is the former part, however, that is more difficult. The reasoner must be able to determine that he doesn't know a particular piece of information. Step-logic, with its finitary introspective capabilities, allows this determination to be made in real-time within the formalism itself. ([Moo83] and <ref> [Per88a] </ref> have developed formalisms for such reasoning, although both work within a final-tray setting.) The reasoner is able to introspect and determine that he does not have the knowledge of an older brother.
Reference: [Per88b] <author> D. Perlis. </author> <title> Languages with self reference II: Knowledge, belief, and modality. </title> <journal> Artificial Intelligence, </journal> <volume> 34:179--212, </volume> <year> 1988. </year>
Reference-contexts: This rule is intended to have the following effect. 1 known, believed, or concluded. The distinctions between these (see <ref> [Get63, Per86, Per88b] </ref>) will not be addressed here. 19 :K (i; ff) is to be deduced at step i + 1 if ff is not an i-theorem, but does appear as a closed sub-formula at step i. 2 We regard the closed sub-formulas at step i as approximating the wffs that
Reference: [PM86] <author> D. Perlis and J. Minker. </author> <title> Completeness results for circumscription. </title> <journal> Artificial Intelligence, </journal> <volume> 28(1):29--42, </volume> <year> 1986. </year>
Reference: [Pol87] <author> J. Pollock. </author> <title> Defeasible reasoning. </title> <booktitle> Cognitive Science, </booktitle> <address> 11:481--518, </address> <year> 1987. </year>
Reference: [PR84] <author> G. Priest and R. Routley. </author> <title> Introduction: Paraconsistent logics. </title> <journal> Studia logica, </journal> <volume> 43:3--16, </volume> <year> 1984. </year>
Reference: [Pri67] <author> A.N. </author> <title> Prior. Past, Present and Future. </title> <publisher> Clarendon Press, Oxford, </publisher> <year> 1967. </year>
Reference: [Rei78] <author> R. Reiter. </author> <title> On closed world databases. </title> <editor> In H. Gallaire and J. Minker, editors, </editor> <booktitle> Logic and Databases, pages 55--76. </booktitle> <publisher> Plenum, </publisher> <year> 1978. </year>
Reference: [Rei80] <author> R. Reiter. </author> <title> A logic for default reasoning. </title> <journal> Artificial Intelligence, </journal> <volume> 13(1,2):81--132, </volume> <year> 1980. </year>
Reference-contexts: Because of this, traditional monotonic logics are unsuitable for formalizing these agents; we are again forced into a non-monotonic setting. Although several formalisms for non-monotonic reasoning have already been proposed (see <ref> [MD80, Rei80, McC80] </ref>), they do not address the issue of real-time commonsense reasoning. 1.2 Accomplishments The primary contributions of this work are the following: * A precise characterization of step-logic, a formalism designed to take into account the fact that reasoning occurs over time, is given.
Reference: [Sho88] <author> Y. Shoham. </author> <title> Reasoning About Change. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1988. </year>
Reference-contexts: Many others have contributed formalisms for reasoning about time and action including <ref> [Haa86, HS86, MB83, MS87, Moo85, Lif87, Sho88] </ref>. In contrast to these theories, the focus of this thesis is not primarily to be able to reason about time, but rather to be able to reason in time.
Reference: [Suc86] <author> L. Suchman. </author> <title> Plans and situated actions: the problem of human-machine communication. </title> <type> Technical report, </type> <note> Xerox PARC, </note> <year> 1986. </year>
Reference-contexts: This limitation must be recognized by the reasoner himself; that is, the agent should be able to reason about its ongoing reasoning efforts themselves. Its reasoning must be ``situated'' in a temporal environment (see <ref> [Suc86] </ref>). The paradigm for such an agent would seem to be that suggested by [Nil83], namely, a computer individual with a lifetime of its own. What is of interest for such an agent is not its ``ultimate'' set of conclusions, but rather its changing set of conclusions over time.
Reference: [Var86] <author> M. Vardi. </author> <title> On epistemic logic and logical omniscience. </title> <editor> In J. Halpern, editor, </editor> <booktitle> Proceedings of the 1986 Conference on Theoretical Aspects of Reasoning about Knowledge, pages 293--305. </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> 1986. Monterey, CA. </address>
Reference: [Won86] <author> W. G. Wong. </author> <title> Prolog: A language for artificial intelligence. </title> <journal> PC Magazine, </journal> <volume> 5(17):247--263, </volume> <month> October </month> <year> 1986. </year> <month> 89 </month>
References-found: 64

