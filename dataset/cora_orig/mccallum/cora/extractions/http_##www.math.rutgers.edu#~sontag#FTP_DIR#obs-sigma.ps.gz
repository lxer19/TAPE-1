URL: http://www.math.rutgers.edu/~sontag/FTP_DIR/obs-sigma.ps.gz
Refering-URL: http://www.math.rutgers.edu/~sontag/papers.html
Root-URL: 
Email: E-mail: albertin@pdmat1.unipd.it,sontag@hilbert.rutgers.edu  
Title: OBSERVABILITY IN RECURRENT NEURAL NETWORKS  
Author: Francesca Albertini Eduardo D. Sontag 
Keyword: Recurrent neural networks, observability.  
Date: December 1992, rev May 1993  
Address: New Brunswick, NJ 08903  Via Belzoni 7, 35100 Padova, Italy.  
Affiliation: SYCON Rutgers Center for Systems and Control Department of Mathematics, Rutgers University,  INDAM (Istituto Nazionale di Alta Matematica Francesco Severi, Italy)  Also: Universita' di Padova, Dipartimento di Matematica,  
Note: STATE  This research was supported in part by US Air Force Grant AFOSR-91-0346, and also by an  fellowship. Rutgers Center for Systems and Control  
Abstract: Report SYCON-92-07rev ABSTRACT We obtain a characterization of observability for a class of nonlinear systems which appear in neural networks research. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <editor> Albertini, F., and E.D. Sontag, </editor> <title> "For neural networks, function determines form," Neural Networks, to appear. Summary in: "For neural networks, function determines form," </title> <booktitle> Proc. IEEE Conf. Decision and Control, </booktitle> <address> Tucson, Dec. 1992, </address> <publisher> IEEE Publications, </publisher> <year> 1992, </year> <pages> pp. 26-31. </pages>
Reference-contexts: In the recent work <ref> [1] </ref>, we explored realization questions, and in particular the fact that all the entries of the matrices A, B, and C can be recovered (up to a small number of symmetries) from the zero-initial state input/output behavior, assuming suitable minimality assumptions, and as long as is nonlinear enough. <p> the parameters up to basis changes, and it is reminiscent of old work of Rugh and coworkers, as well as Boyd and Chua |see for instance [5] and [3]| on uniqueness of interconnections containing nonlinearities. (The paper [2] explains the relation between those more classical facts and the result in <ref> [1] </ref>). In this paper, we look at questions of observability, that is, state distinguishability for a known system, as opposed to determination of the systems parameters with a known initial state.
Reference: [2] <author> Albertini, F., E.D. Sontag, and V. Maillot, </author> <title> "Uniqueness of weights for neural networks," in Artificial Neural Networks with Applications in Speech and Vision (R. Mammone, </title> <editor> ed.), </editor> <publisher> Chapman and Hall, </publisher> <address> London, </address> <year> 1993, </year> <note> to appear. </note>
Reference-contexts: This is somewhat surprising, since for the linear case one can only recover the parameters up to basis changes, and it is reminiscent of old work of Rugh and coworkers, as well as Boyd and Chua |see for instance [5] and [3]| on uniqueness of interconnections containing nonlinearities. (The paper <ref> [2] </ref> explains the relation between those more classical facts and the result in [1]). In this paper, we look at questions of observability, that is, state distinguishability for a known system, as opposed to determination of the systems parameters with a known initial state. <p> i ) 6= (b j ; fi j ) 8i 6= j ; the functions 1 ; (b 1 u + fi 1 ) ; : : : ; (b l u + fi l ) are linearly independent; that is: c 0 + i=1 The following result is from <ref> [2] </ref>, and it provides sufficient conditions for a given function to satisfy property IP; these conditions are weak enough to allow inclusion of most examples of interest in neural networks. <p> Another example which appears often in the context of neural nets is that of arctan (x). Here, integrating 1 1+z 2 , one can find a branch defined on the complement of fRe z = 0; jIm zj 1g, so one may pick z 0 = i. See <ref> [2] </ref> for much more on property IP and related matters. We will provide results under a restriction on the class of systems (1). We state this condition next. For any matrix M , M i denotes the i-th row of M . Fix a pair of positive integers m; n.
Reference: [3] <author> Boyd, S., and L.O. Chua, </author> <title> "Uniqueness of circuits and systems containing one nonlinearity," </title> <journal> IEEE Trans. Automatic Control AC-30(1985): </journal> <pages> 674-681. </pages>
Reference-contexts: This is somewhat surprising, since for the linear case one can only recover the parameters up to basis changes, and it is reminiscent of old work of Rugh and coworkers, as well as Boyd and Chua |see for instance [5] and <ref> [3] </ref>| on uniqueness of interconnections containing nonlinearities. (The paper [2] explains the relation between those more classical facts and the result in [1]).
Reference: [4] <author> Hertz, J., A. Krogh, and R.G. Palmer, </author> <title> Introduction to the Theory of Neural Computation, </title> <publisher> Addison-Wesley, </publisher> <address> Redwood City, </address> <year> 1991. </year>
Reference-contexts: 1 Introduction Systems consisting of a large number of interconnected "neurons" evolving according to difference (in discrete-time) or differential (in continuous-time) equations have attracted considerable attention lately; see for instance the material on "recurrent nets" in the textbook <ref> [4] </ref>.
Reference: [5] <author> Smith, W.W., and W.J. Rugh, </author> <title> "On the Structure of a Class of Nonlinear Systems," </title> <journal> IEEE Trans. Automatic Control AC-19(1974): </journal> <pages> 701-706. </pages>
Reference-contexts: This is somewhat surprising, since for the linear case one can only recover the parameters up to basis changes, and it is reminiscent of old work of Rugh and coworkers, as well as Boyd and Chua |see for instance <ref> [5] </ref> and [3]| on uniqueness of interconnections containing nonlinearities. (The paper [2] explains the relation between those more classical facts and the result in [1]).
Reference: [6] <author> Sontag, E.D., </author> <title> "Realization theory of discrete-time nonlinear systems: Part I- The bounded case," </title> <journal> IEEE Trans.Circuits and Syst., </journal> <volume> CAS-26(1979): </volume> <pages> 342-356. </pages>
Reference-contexts: So in particular: Corollary 2.2 If 2 S and det A 6= 0, then is observable if and only if O c (A; C) = 0. Remark 2.3 It is perhaps remarkable that this latter condition is formally the same as the observability condition (see e.g. <ref> [6] </ref>) that results for bilinear systems with transition matrices A; 1 ; : : : ; n and output matrix C. (We thank Leonid Gurvits for pointing this out to us.) As any coordinate subspace has the form V = P j i j (IR n ), for some finite set
Reference: [7] <author> Sontag, E.D., </author> <title> Mathematical Control Theory: Deterministic Finite Dimensional Systems, </title> <publisher> Springer, </publisher> <address> New York, </address> <year> 1990. </year> <month> 11 </month>
Reference-contexts: This definition can be formalized in the obvious way both for discrete and continuous-time systems; see e.g. <ref> [7] </ref> for details, as well as for references to equivalences between this definition and "single experiment" definitions. <p> Recall that the pair of matrices (A; C) is said to be observable -in the sense of classical linear systems theory; see e.g. <ref> [7] </ref>, Section 5.2- if the largest A-invariant subspace included in ker C, denoted O (A; C), is zero.
References-found: 7

