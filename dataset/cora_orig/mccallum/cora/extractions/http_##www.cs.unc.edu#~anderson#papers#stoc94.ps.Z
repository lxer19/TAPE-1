URL: http://www.cs.unc.edu/~anderson/papers/stoc94.ps.Z
Refering-URL: http://www.cs.unc.edu/~anderson/papers.html
Root-URL: http://www.cs.unc.edu
Title: Time Bounds for Mutual Exclusion and Related Problems (Extended Abstract)  for asynchronous shared memory concurrent programs.  
Author: Jae-Heon Yang James H. Anderson 
Note: Work supported, in part, by NSF Contracts CCR-9109497 and CCR-9216421 and by the NASA Center for Excellence in Space Data and Information Sciences (CESDIS).  
Address: College Park, Maryland 20742-3255  Chapel Hill, North Carolina 27599-3175  
Affiliation: Department of Computer Science The University of Maryland  Department of Computer Science The University of North Carolina  
Abstract: We establish trade-offs between time complexity and write- and access-contention for solutions to the mutual exclusion problem. The write-contention (access-contention) of a concurrent program is the number of processes that may be simultaneously enabled to write (access) the same shared variable. Our notion of time complexity distinguishes between local and remote references to shared memory. We show that, for any N -process mutual exclusion algorithm with write-contention w, there exists an execution involving only one process in which that process executes (log w N ) remote memory references for entry into its critical section. We further show that among these remote references, ( log w N ) distinct remote variables are accessed. For algorithms with access-contention c, we show that the latter bound can be improved to (log c N ). The last two of these results imply that a trade-off between contention and time complexity exists even if coherent caching techniques are employed. Because the execution that establishes these bounds involves only one process, our results show that "fast mutual exclusion" requires arbitrarily high write-contention. We show that these bounds hold when using any of a variety of synchronization primitives, including read, write, test-and-set, load-and-store, compare-and-swap, and fetch-and-add, and that they can be generalized to apply when using even stronger primitives. Our results can be extended to apply to a class of decision problems that includes the leader-election problem. The time bounds that we establish are the first of their kind p
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. Alur and G. Taubenfeld, </author> <title> "Results about Fast Mutual Exclusion", </title> <booktitle> Proceedings of the Thirteenth IEEE Real-Time Systems Symposium, </booktitle> <month> December, </month> <year> 1992, </year> <pages> pp. 12-21. </pages>
Reference-contexts: Observe that jZ1j + jZ2j = jZj. The computation G that we seek is defined as follows. G H Z ffi L (1) ffi L (2) ffi ffi L (jZj) ffi h <ref> [R 1 ; W 1 ; 1] </ref>; To complete the proof, we must show that G is in C and that G satisfies (C1) through (C4). For brevity, we only provide a sketch of these arguments, deferring detailed proofs to the full paper. <p> It is interesting to note that there exist read/write mutual exclusion algorithms with write-contention N that have O (1) time complexity in the absence of competition <ref> [1, 9, 14] </ref>. Thus, establishing the above-mentioned lower bound for read/write algorithms will require proof techniques that differ from those given in this paper. We do not know whether the bound given in Theorem 4 is tight.
Reference: [2] <author> J. Anderson, </author> <title> "A Fine-Grained Solution to the Mutual Exclusion Problem", </title> <journal> Acta Informatica, </journal> <volume> Vol. 30, No. 3, </volume> <year> 1993, </year> <pages> pp. 249-265. </pages>
Reference-contexts: Thus, we have the following corollary. Corollary 1: For any system S satisfying the conditions of Theorem 1, there exist (N ) processes i in P for which the conclusion of the theorem holds. 2 Similar corollaries apply to the theorems in the following subsections. In <ref> [2] </ref>, a mutual exclusion algorithm requiring O (N ) remote memory references per critical section acquisition is given that employs only single-reader, single-writer variables. Thus, if k is taken to be a positive constant, then the bound of Theorem 1 is asymptotically tight.
Reference: [3] <author> T. Anderson, </author> <title> "The Performance of Spin Lock Alternatives for Shared-Memory Multiprocessors", </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> Vol. 1, No. 1, </volume> <month> January, </month> <year> 1990, </year> <pages> pp. 6-16. </pages>
Reference-contexts: First, it is conceptually simple. In fact, this measure is a natural descendent of the standard time complexity measure used in sequential programming. Second, this measure has a tangible connection with real performance, as demonstrated by a number of recently published performance studies <ref> [3, 11, 14] </ref>. All other proposed time complexity measures for concurrent programs that we know of fail to satisfy at least one of these criteria. 1 We present several lower-bound results for mutual exclusion that are based on the time complexity measure of Yang and Anderson. <p> Limiting access-contention is an important consideration when designing algorithms for problems, such as mutual exclusion and shared counting, that must cope well with high competition among processes <ref> [3, 7, 8, 13] </ref>. Performance problems associated with high access-contention can be partially alleviated by employing coherent caching techniques to reduce concurrent reads of the same memory location. However, even when such techniques are employed, limiting write-contention is still an important concern.
Reference: [4] <author> E. Dijkstra, </author> <title> "Solution of a Problem in Concurrent Programming Control", </title> <journal> Communications of the ACM , Vol. </journal> <volume> 8, No. 9, </volume> <year> 1965, </year> <pages> pp. 569. </pages>
Reference-contexts: 1 Introduction The mutual exclusion problem is a fundamental paradigm for coordinating accesses to shared data on asynchronous shared memory multiprocessing systems <ref> [4] </ref>. In this problem, accesses to shared data are abstracted as "critical sections" of code, and it is required that at most one process executes its critical section at any time.
Reference: [5] <author> C. Dwork, M. Herlihy, and O. Waarts, </author> <title> "Contention in Shared Memory Algorithms", </title> <booktitle> Proceedings of the 25th ACM Symposium on Theory of Computing, </booktitle> <month> May, </month> <year> 1993, </year> <pages> pp. 174-183. </pages>
Reference-contexts: Our results apply not only to mutual exclusion but also to a class of decision problems that includes the leader-election problem. Related work includes previous research by Dwork et al. given in <ref> [5] </ref>, where it is shown that solving mutual exclusion with access-contention c requires ((log 2 N )=c) memory references. Our work extends that of Dwork et al. in several directions. First, the implications concerning fast mutual exclusion and cache coherence noted above do not follow from their work.
Reference: [6] <author> M. Herlihy, </author> <title> "Wait-Free Synchronization", </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> Vol. 13, No. 1, </volume> <year> 1991, </year> <pages> pp. 124-149. </pages>
Reference-contexts: Because any algorithm that solves the leader election or mutual exclusion problems also solves the minimal mutual exclusion problem (this will be shown formally in the full paper), these trade-offs apply to these problems as well. For wait-free algorithms, Herlihy has characterized synchronization primitives by consensus number <ref> [6] </ref>. Such a characterization is not applicable when waiting is introduced. One way of determining the power of synchronization primitives in this case is to compare the time complexity of mutual exclusion using such primi-tives.
Reference: [7] <author> M. Herlihy, B-H. Lim, and N. Shavit, </author> <title> "Low Contention Load Balancing on Large-Scale Multiprocessors", </title> <booktitle> Proceedings of the 3rd ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <month> July, </month> <year> 1992, </year> <pages> pp. 219-227. </pages>
Reference-contexts: Limiting access-contention is an important consideration when designing algorithms for problems, such as mutual exclusion and shared counting, that must cope well with high competition among processes <ref> [3, 7, 8, 13] </ref>. Performance problems associated with high access-contention can be partially alleviated by employing coherent caching techniques to reduce concurrent reads of the same memory location. However, even when such techniques are employed, limiting write-contention is still an important concern.
Reference: [8] <author> M. Herlihy, N. Shavit, and O. Waarts, </author> <title> "Low Contention Linearizable Counting", </title> <booktitle> Proceedings of the 32nd IEEE Symposium on Foundations of Computer Science, </booktitle> <month> October, </month> <year> 1991, </year> <pages> pp. 526-535. </pages>
Reference-contexts: Limiting access-contention is an important consideration when designing algorithms for problems, such as mutual exclusion and shared counting, that must cope well with high competition among processes <ref> [3, 7, 8, 13] </ref>. Performance problems associated with high access-contention can be partially alleviated by employing coherent caching techniques to reduce concurrent reads of the same memory location. However, even when such techniques are employed, limiting write-contention is still an important concern.
Reference: [9] <author> L. Lamport, </author> <title> "A Fast Mutual Exclusion Algorithm", </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> Vol. 5, No. 1, </volume> <month> February, </month> <year> 1987, </year> <pages> pp. 1-11. </pages>
Reference-contexts: Also, because the execution that establishes these bounds involves only one process, it follows that so-called fast mutual exclusion algorithms | i.e., algorithms that require a process to execute only a constant number of remote memory references in the absence of competition <ref> [9] </ref> | require arbitrarily high write-contention in the worst case. These bounds hold assuming that each atomic operation accesses at most one remote variable. A variety of well-known synchronization primitives satisfy this assumption, including read, write, test-and-set, load-and-store, compare-and-swap, and fetch-and-add. <p> It is interesting to note that there exist read/write mutual exclusion algorithms with write-contention N that have O (1) time complexity in the absence of competition <ref> [1, 9, 14] </ref>. Thus, establishing the above-mentioned lower bound for read/write algorithms will require proof techniques that differ from those given in this paper. We do not know whether the bound given in Theorem 4 is tight.
Reference: [10] <author> N. Lynch and N. Shavit, </author> <title> "Timing-Based Mutual Exclusion", </title> <booktitle> Proceedings of the Thirteenth IEEE Real-Time Systems Symposium, </booktitle> <month> December, </month> <year> 1992, </year> <pages> pp. 2-11. </pages>
Reference-contexts: Past work on the complexity of mutual exclusion has almost exclusively focused on space requirements; the limited work on time bounds that has been done has focused on partially synchronous models <ref> [10] </ref>. The lack of prior work on time bounds for mutual exclusion within asynchronous models is probably due to difficulties associated with measuring the time spent within busy-waiting constructs.
Reference: [11] <author> J. Mellor-Crummey and M. Scott, </author> <title> "Algorithms for Scalable Synchronization on Shared-Memory Multiprocessors", </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> Vol. 9, No. 1, </volume> <month> February, </month> <year> 1991, </year> <pages> pp. 21-65. </pages>
Reference-contexts: First, it is conceptually simple. In fact, this measure is a natural descendent of the standard time complexity measure used in sequential programming. Second, this measure has a tangible connection with real performance, as demonstrated by a number of recently published performance studies <ref> [3, 11, 14] </ref>. All other proposed time complexity measures for concurrent programs that we know of fail to satisfy at least one of these criteria. 1 We present several lower-bound results for mutual exclusion that are based on the time complexity measure of Yang and Anderson. <p> In particular, an algorithm by Mellor-Crummey and Scott given in <ref> [11] </ref> solves the mutual exclusion problem for w processes, in O (1) time, with access-contention (and hence write-contention) w. By applying this solution within a balanced w-ary tree with N leaves, it is possible to obtain an N -process O (log w N ) mutual exclusion algorithm with access-contention w.
Reference: [12] <author> M. Merritt and G. Taubenfeld, </author> <title> "Knowledge in Shared Memory Systems", </title> <booktitle> Proceedings of the Tenth ACM Symposium on Principles of Distributed Computing, </booktitle> <month> August, </month> <year> 1991, </year> <pages> pp. 189-200. </pages>
Reference-contexts: In Section 2, we present our model of shared memory systems. The above-mentioned time bounds are then established in Section 3. Concluding remarks appear in Section 4. 2 Shared Memory Systems Our model of a shared memory system is similar to that given by Merritt and Taubenfeld in <ref> [12] </ref>. A system S = (C; P; V ) consists of a set of computations C, a set of processes P = f1; 2; ; N g, and a set of variables V . A computation is a finite sequence of events.
Reference: [13] <author> G. Pfister and A. Norton, </author> <title> "Hot Spot Contention and Combining in Multistage Interconnection Networks", </title> <journal> IEEE Transactions on Computers, </journal> <volume> Vol. C-34, No. 11, </volume> <month> November, </month> <year> 1985, </year> <pages> pp. 943-948. </pages>
Reference-contexts: Limiting access-contention is an important consideration when designing algorithms for problems, such as mutual exclusion and shared counting, that must cope well with high competition among processes <ref> [3, 7, 8, 13] </ref>. Performance problems associated with high access-contention can be partially alleviated by employing coherent caching techniques to reduce concurrent reads of the same memory location. However, even when such techniques are employed, limiting write-contention is still an important concern.
Reference: [14] <author> J. Yang and J. Anderson, </author> <title> "Fast, Scalable Synchronization with Minimal Hardware Support", </title> <booktitle> Proceedings of the Twelfth ACM Symposium on Principles of Distributed Computing , August, </booktitle> <year> 1993, </year> <pages> pp. 171-182. </pages>
Reference-contexts: In other words, the standard sequential programming metric yields no useful information concerning the performance of such algorithms under contention. In a recent paper, Yang and Anderson proposed a time measure for concurrent programs that distinguishes between local and remote accesses of shared memory <ref> [14] </ref>. A shared variable access is local if does not require a traversal of the global interconnect between processors and shared memory, and is remote otherwise. Although the notion of a locally accessible shared variable may seem counterintuitive, there are two architectural paradigms that support it. <p> First, it is conceptually simple. In fact, this measure is a natural descendent of the standard time complexity measure used in sequential programming. Second, this measure has a tangible connection with real performance, as demonstrated by a number of recently published performance studies <ref> [3, 11, 14] </ref>. All other proposed time complexity measures for concurrent programs that we know of fail to satisfy at least one of these criteria. 1 We present several lower-bound results for mutual exclusion that are based on the time complexity measure of Yang and Anderson. <p> Note that Mellor-Crummey and Scott's algorithm uses load-and-store and compare-and-swap. Even with weaker atomic operations, logarithmic behavior can be achieved. In particular, an N -process O (log 2 N ) mutual exclusion algorithm based on read/write atom-icity has been given by Yang and Anderson in <ref> [14] </ref>. <p> For instance, it is possible to solve the mutual exclusion problem with O (1) time complexity using load-and-store or fetch-and-add, while the best-known upper bound for read/write algorithms is O (log 2 N ) <ref> [14] </ref>. If a lower-bound result could be proved showing that this gap is fundamental, then this would establish that reads and writes are weaker than read-modify-writes from a performance standpoint. <p> It is interesting to note that there exist read/write mutual exclusion algorithms with write-contention N that have O (1) time complexity in the absence of competition <ref> [1, 9, 14] </ref>. Thus, establishing the above-mentioned lower bound for read/write algorithms will require proof techniques that differ from those given in this paper. We do not know whether the bound given in Theorem 4 is tight. <p> We do not know whether the bound given in Theorem 4 is tight. We conjecture that this bound can be improved to (log w N ), which has a matching algorithm <ref> [14] </ref>. One may be interested in determining the effect of contention on space requirements. It is quite easy to show that solving the minimal mutual exclusion problem with write-contention w requires at least N=w variables. In particular, it can be shown that every process writes a variable before eating.
References-found: 14

