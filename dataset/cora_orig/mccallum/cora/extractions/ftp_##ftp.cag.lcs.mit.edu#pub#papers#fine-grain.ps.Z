URL: ftp://ftp.cag.lcs.mit.edu/pub/papers/fine-grain.ps.Z
Refering-URL: http://www.cag.lcs.mit.edu/alewife/papers/fine-grain.html
Root-URL: 
Title: Experience with Fine-Grain Synchronization in MIMD Machines for Preconditioned Conjugate Gradient  
Author: Donald Yeung and Anant Agarwal 
Address: Cambridge, MA 02139  
Affiliation: Laboratory for Computer Science Massachusetts Institute of Technology  
Date: May 1993.  
Note: Appears in Proceedings of the 4th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming,  
Abstract: This paper discusses our experience with fine-grain synchronization for a variant of the preconditioned conjugate gradient method. This algorithm represents a large class of algorithms that have been widely used but traditionally difficult to implement efficiently on vector and parallel machines. Through a series of experiments conducted using a simulator of a distributed shared-memory multiprocessor, this paper addresses two major questions related to fine-grain synchronization in the context of this application. First, what is the overall impact of fine-grain synchronization on performance? Second, what are the individual contributions of the following three mechanisms typically provided to support fine-grain synchronization: language-level support, full-empty bits for compact storage and communication of synchronization state, and efficient processor operations on the state bits? Our experiments indicate that fine-grain synchronization improves overall performance by a factor of 3.7 on 16 processors using the largest problem size we could simulate; we project that a significant performance advantage will be sustained for larger problem sizes. We also show that the bulk of the performance advantage for this application can be attributed to exposing increased parallelism through language-level expression of fine-grain synchronization. A smaller fraction relies on a compact implementation of synchronization state, while an even smaller fraction results from efficient full-empty bit operations. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Anant Agarwal, David Chaiken, Kirk Johnson, David Kranz, John Kubiatowicz, Kiyoshi Kurihara, Beng-Hong Lim, Gino Maa, and Dan Nussbaum. </author> <title> The MIT Alewife Machine: A Large-Scale Distributed-Memory Multiprocessor. </title> <type> MIT/LCS/TM 454, </type> <institution> MIT Laboratory for Computer Science, </institution> <month> June </month> <year> 1991. </year>
Reference-contexts: We analyze the benefits both with a fixed problem size and when problem size is scaled with machine size. Our study uses a simulator of Alewife, a distributed memory multiprocessor that provides hardware support for the shared-memory abstraction <ref> [1] </ref>. Our first result is that applications for which synchronization is challenging do exist. Furthermore, implementations on MIMD machines can achieve good performance by employing fine-grain synchronization. Second, through a sequence of experiments, we try to understand exactly where the muscle of fine-grain synchronization lies.
Reference: [2] <author> Gail Alverson, Robert Alverson, and David Callahan. </author> <title> Exploiting Heterogeneous Parallelism on a Multithreaded Multiprocessor. </title> <booktitle> Workshop on Multithreaded Computers, Proceedings of Supercomputing '91, ACM Sigraph & IEEE, </booktitle> <month> November </month> <year> 1991. </year>
Reference: [3] <author> Arvind, and Rishiyur S. Nikhil. I-Structures: </author> <title> Data Structures for Parallel Computing. </title> <journal> ACM Transactions on Programming Languages and Systems, pp. </journal> <volume> 598-632, Vol. 11, No. 4, </volume> <month> October </month> <year> 1989. </year>
Reference-contexts: The first component of support provides the programmer with a means to express synchronization at a fine granularity resulting in increased parallelism. Another attractive consequence is simpler, more elegant code <ref> [3] </ref>. The second component of support addresses the fact that an application using fine-grain synchronization will need a large synchronization name space. Providing special synchronization state can lead to an efficient implementation from the standpoint of the memory system. We refer to this benefit as memory efficiency.
Reference: [4] <author> Jack J. Dongarra, Iain S. Duff, Danny C. Sorensen, and Henk A. van der Vorst. </author> <title> Solving Linear Systems on Vector and Shared Memory Computers. </title> <publisher> SIAM, </publisher> <address> Philadelphia. </address> <year> 1991. </year>
Reference-contexts: Since the operations in the basic CG method consist of vector updates, inner products, and sparse matrix-vector multiplies, efficient parallel versions of the algorithm have been demonstrated on many vector machines and MIMD multiprocessors <ref> [4, 6] </ref>. Preconditioned CG methods, however, have not enjoyed the same success. In many of the most popular preconditioning techniques, the precon-ditioner steps involve recurrence relations which do not vectorize or parallelize easily. <p> The difficulty in performing computations involving recurrence 3 relations is well known. Table 2 shows performance numbers on some vector computers as presented in <ref> [4] </ref>. The first column of numbers shows the absolute peak floating point performance of the machine. The remaining columns give the maximum performance in MFlops on each of the four vector operations that appear in MICCG3D. Notice how performance degrades for recurrence relations as compared to the other vector operations.
Reference: [5] <author> Gene H. Golub and Charles F. van Loan. </author> <title> Matrix Computations. </title> <publisher> Johns Hopkins University Press, </publisher> <address> Baltimore, Maryland. </address> <year> 1983. </year>
Reference-contexts: The idea is to choose a preconditioner such that K 1 A is close to the identity matrix I <ref> [5] </ref>. Since the operations in the basic CG method consist of vector updates, inner products, and sparse matrix-vector multiplies, efficient parallel versions of the algorithm have been demonstrated on many vector machines and MIMD multiprocessors [4, 6]. Preconditioned CG methods, however, have not enjoyed the same success.
Reference: [6] <author> Louis A. Hageman and David M. Young. </author> <title> Applied Iterative Methods. </title> <publisher> Academic Press, </publisher> <address> New York. </address> <year> 1981. </year>
Reference-contexts: Since the operations in the basic CG method consist of vector updates, inner products, and sparse matrix-vector multiplies, efficient parallel versions of the algorithm have been demonstrated on many vector machines and MIMD multiprocessors <ref> [4, 6] </ref>. Preconditioned CG methods, however, have not enjoyed the same success. In many of the most popular preconditioning techniques, the precon-ditioner steps involve recurrence relations which do not vectorize or parallelize easily.
Reference: [7] <author> David Kranz, Beng-Hong Lim, and Anant Agarwal. </author> <title> Low-Cost Support for Fine-Grain Synchronization in Multiprocessors. Multithreading: </title>
Reference-contexts: Alewife supports the fine-grain synchronization capabilities described in Section 2. At the language level, L-structure and J-structure constructs allow the expression of synchronization at data-level granularity. L-structures enforce mutual exclusion and J-structures provide producer-consumer synchronization (a detailed discussion on language-level support for fine-grain synchronization in Alewife appears in <ref> [7] </ref>). Memory efficiency and cycle efficiency as discussed in Section 2 are facilitated by full-empty bits in the memory hardware and fast operations on full-empty bits in the processor hardware, respectively. Alewife facilitates memory efficiency by allocating a full-empty bit for every word in memory.
References-found: 7

