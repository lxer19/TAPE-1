URL: http://www.cs.rochester.edu/u/sandhya/papers/hpca97.ps.gz
Refering-URL: http://www.cs.rochester.edu/u/sandhya/papers/
Root-URL: 
Email: willyg@cs.rice.edu  sandhya@cs.rochester.edu  
Title: Software DSM Protocols that Adapt between Single Writer and Multiple Writer  
Author: Cristiana Amza Alan L. Cox Sandhya Dwarkadas and Willy Zwaenepoel 
Note: This work is supported in part by the National Science Foundation under Grants CCR-9410457, BIR-9408503, CCR-9457770, CCR-9502500, CCR-9521735, CDA-9502791, and MIP-9521386, by the Texas TATP program under Grant 003604-017, and by grants from IBM Corporation and from Tech-Sym, Inc.  
Address: famza, alc,  Rochester  
Affiliation: Department of Computer Science Rice University  Department of Computer Science University of  
Abstract: We present two software DSM protocols that dynamically adapt between a single writer (SW) and a multiple writer (MW) protocol based on the application's sharing patterns. The first protocol (WFS) adapts based on write-write false sharing; the second (WFS+WG) based on a combination of write-write false sharing and write-granularity. The adaptation is automatic. No user or compiler information is needed. The choice between SW and MW is made on a per-page basis. We measured the performance of our adaptive protocols on an 8-node SPARC cluster connected by a 155 Mbps ATM network. We used 8 applications, covering a broad spectrum in terms of write-write false sharing and write granularity. We compare our adaptive protocols against the TreadMarks MW-only approach and the CVM SW-only approach. Adaptation to write-write false sharing proves to be the critical performance factor, while adaptation to write-granularity plays only a secondary role in our environment and for the applications considered. Each of the two adaptive protocols matches or exceeds the performance of the best of MW and SW in seven out of the eight applications. For these applications, speedup improvements over SW range from 1.0 to 2.7. The largest improvements over SW occur for applications with high write-write false sharing. Compared to MW, speedups improve by a factor of 1.0 to 1.6, with the largest improvements occurring for applications with little or no write-write false sharing. Both WFS and WFS+WG speedups fall below the best of MW and SW for one application, but only by a factor of 1.09 and 1.06. In addition, memory usage is reduced considerably compared to MW, in some cases making the memory overhead all but negligible. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S.V. Adve, A.L. Cox, S. Dwarkadas, R. Raja-mony, and W. Zwaenepoel. </author> <title> A comparison of entry consistency and lazy release consistency implementations. </title> <booktitle> In Proceedings of the Second High Performance Computer Architecture Symposium, </booktitle> <pages> pages 26-37, </pages> <month> February </month> <year> 1996. </year>
Reference-contexts: Various techniques have been proposed to replace diffing by cheaper alternatives [15, 21] or to o*oad diffing to a communication coprocessor [22]. This work is orthogonal to ours, in that we could incorporate these techniques into our adaptive protocols. Using per-word timestamps <ref> [1, 15, 21] </ref> addresses the problem of diff accumulation directly. The problem is alleviated in our system because we switch to using whole pages whenever the diffs are large. The work of Cox and Fowler, and Stenstrom and Brorsson [7, 20] adapts to migratory sharing patterns in hardware cache-coherence protocols.
Reference: [2] <author> S.V. Adve and M.D. Hill. </author> <title> A unified formalization of four shared-memory models. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 4(6) </volume> <pages> 613-624, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: The Lazy Release Consistency (LRC) algorithm [14] delays the propagation of modifications to a processor until that processor executes an acquire. To do so, LRC uses the happened-before-1 partial order <ref> [2] </ref>. The happened-before-1 partial order is the union of the total processor order of the memory accesses on each individual processor and the partial order of release-acquire pairs. Vector timestamps are used to represent the partial order [14].
Reference: [3] <author> C. Amza, A.L. Cox, S. Dwarkadas, P. Keleher, H. Lu, R. Rajamony, and W. Zwaenepoel. </author> <title> Tread-Marks: Shared memory computing on networks of workstations. </title> <journal> IEEE Computer, </journal> <volume> 29(2) </volume> <pages> 18-28, </pages> <month> February </month> <year> 1996. </year>
Reference-contexts: Furthermore, there is a significant memory overhead for recording the modifications. The memory costs can be bounded by garbage collection, but frequent garbage collection results in added execution time. CVM [13] uses a SW protocol, while TreadMarks <ref> [3] </ref> uses a MW protocol (see the work of Keleher [13] for a study of the tradeoffs). Other systems (such as Munin [6]) allow multiple protocols to be used, but require user annotation to choose between them. In this paper we take an alternative approach. <p> The second adaptive protocol (WFS+WG), in addition, takes into account write granularity, and uses diffs for pages with small write granularity, even if they do not exhibit write-write false sharing. The adaptive protocols were implemented in Tread-Marks <ref> [3] </ref>. 8 applications are used to demonstrate the performance: SOR and TSP are small kernels; Barnes-Hut and Water are from the Splash benchmarks suite [19]; IS and 3D-FFT are from the NAS benchmark suite [4]; Shallow is a small weather modeling code from NCAR [18]; and ILINK is a production computational <p> A faulting processor uses this information and the vector times-tamp of its own copy of the page to determine which modifications to the page it needs to request from other processors to make its copy up-to-date. In TreadMarks <ref> [3] </ref>, detection of modifications is done by twinning and diffing. A page is initially write-protected, so that at the first write a protection violation occurs.
Reference: [4] <author> D. Bailey, J. Barton, T. Lasinski, and H. Simon. </author> <title> The NAS parallel benchmarks. </title> <type> Technical Report TR RNR-91-002, </type> <institution> NASA Ames, </institution> <month> August </month> <year> 1991. </year>
Reference-contexts: The adaptive protocols were implemented in Tread-Marks [3]. 8 applications are used to demonstrate the performance: SOR and TSP are small kernels; Barnes-Hut and Water are from the Splash benchmarks suite [19]; IS and 3D-FFT are from the NAS benchmark suite <ref> [4] </ref>; Shallow is a small weather modeling code from NCAR [18]; and ILINK is a production computational genetics code [11]. These applications cover a wide spectrum in terms of write-write false sharing and write-granularity. We present performance results on a 155Mbps ATM network connecting 8 SPARC-20 model 61 workstations. <p> This led us to a conservative threshold value of 3Kb to switch from diffs to whole pages. 5 Applications We use 8 applications in this study: Red-black SOR, Water, TSP, and Barnes-Hut from the Splash benchmark suite [19], IS and 3D-FFT from the NAS benchmark suite <ref> [4] </ref> Shallow from NCAR [18] and ILINK, a large computational genetics code [11]. The applications and input sets used vary considerably in terms of their amount of write-write false sharing and their write granularity. Tables 1 and 2 summarize the relevant characteristics of the applications.
Reference: [5] <author> B.N. Bershad, M.J. Zekauskas, </author> <title> and W.A. </title> <booktitle> Saw-don. The Midway distributed shared memory system. In Proceedings of the '93 CompCon Conference, </booktitle> <pages> pages 528-537, </pages> <month> February </month> <year> 1993. </year>
Reference-contexts: The innovation in our work is that it chooses automatically between SW and MW protocols. In Munin, the choice of protocol was based on somewhat burdensome user annotations. False sharing has also been addressed by static analysis [12], and by using objects as a smaller consistency unit <ref> [5] </ref>. Freeh et al. [9] implement an adaptive algorithm that detects falsely shared pages and migrates the shared data such that false sharing is eliminated.
Reference: [6] <author> J.B. Carter, J.K. Bennett, and W. Zwaenepoel. </author> <title> Techniques for reducing consistency-related information in distributed shared memory systems. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 13(3) </volume> <pages> 205-243, </pages> <month> August </month> <year> 1995. </year>
Reference-contexts: 1 Introduction This paper focuses on protocols for implementing lazy release-consistent (LRC) [14] software distributed shared memory (DSM) [16] on commodity hardware. Both single writer (SW) [13] and multiple writer (MW) <ref> [6] </ref> protocols have been used to implement LRC. SW protocols allow only a single writable copy of a page at any given time. Furthermore, they always transfer a whole page to satisfy an access miss. With MW protocols several writable copies of a page may co-exist. <p> Furthermore, they always transfer a whole page to satisfy an access miss. With MW protocols several writable copies of a page may co-exist. Instead of transferring whole pages, MW protocols transfer diffs, records of the modifications made to a page <ref> [6] </ref>. SW protocols suffer from the ping-pong effect in the case of write-write false sharing (concurrent writes from different processors to non-overlapping parts of the page). <p> The memory costs can be bounded by garbage collection, but frequent garbage collection results in added execution time. CVM [13] uses a SW protocol, while TreadMarks [3] uses a MW protocol (see the work of Keleher [13] for a study of the tradeoffs). Other systems (such as Munin <ref> [6] </ref>) allow multiple protocols to be used, but require user annotation to choose between them. In this paper we take an alternative approach. We observe that for some applications a MW protocol is preferred while for others a SW protocol is more desirable. <p> Our work could be extended to dynamically detect migratory data access and optimize the protocol accordingly. Munin <ref> [6] </ref> used multiple protocols to handle data with different access characteristics. The innovation in our work is that it chooses automatically between SW and MW protocols. In Munin, the choice of protocol was based on somewhat burdensome user annotations.
Reference: [7] <author> A.L. Cox and R.J. Fowler. </author> <title> Adaptive cache coherency for detecting migratory shared data. </title> <booktitle> In Proceedings of the 20th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 98-108, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: Using per-word timestamps [1, 15, 21] addresses the problem of diff accumulation directly. The problem is alleviated in our system because we switch to using whole pages whenever the diffs are large. The work of Cox and Fowler, and Stenstrom and Brorsson <ref> [7, 20] </ref> adapts to migratory sharing patterns in hardware cache-coherence protocols. Migratory cache blocks are detected dynamically (how??).
Reference: [8] <author> B. Fleisch and G. Popek. </author> <title> Mirage: A coherent distributed shared memory design. </title> <booktitle> In Proceedings of the 12th ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 211-223, </pages> <month> December </month> <year> 1989. </year>
Reference-contexts: However, on write faults, the last version of the page needs to migrate to the new owner, thus the exact location of the last owner needs to be determined. In our implementation of SW, as in the CVM protocol and Mirage <ref> [8] </ref>, we address the ping-pong problem by guaranteeing a processor ownership for a newly obtained page for a minimum quantum of time before it can be taken away by another processor. We use a fixed 1 millisecond quantum.
Reference: [9] <author> V.W. Freeh and G.R. Andrews. </author> <title> Dynamically controlling false sharing in distributed shared memory. </title> <booktitle> In Proceedings of the Fifth Symposium on High-Performance Distributed Computing, </booktitle> <year> 1996. </year>
Reference-contexts: In Munin, the choice of protocol was based on somewhat burdensome user annotations. False sharing has also been addressed by static analysis [12], and by using objects as a smaller consistency unit [5]. Freeh et al. <ref> [9] </ref> implement an adaptive algorithm that detects falsely shared pages and migrates the shared data such that false sharing is eliminated.
Reference: [10] <author> K. Gharachorloo, D. Lenoski, J. Laudon, P. Gibbons, A. Gupta, and J. Hennessy. </author> <title> Memory consistency and event ordering in scalable shared-memory multiprocessors. </title> <booktitle> In Proceedings of the 17th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 15-26, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: Section 7 discusses related work. Section 8 presents our conclusions. 2 Background In the following we introduce lazy release consistency, the TreadMarks MW protocol and our implementation of the CVM single-writer protocol. 2.1 Lazy Release Consistency Release consistency (RC) is a relaxed memory consistency model <ref> [10] </ref>. In RC, ordinary shared memory accesses are distinguished from synchronization accesses, with the latter category subdivided into acquire and release accesses. Acquire and release accesses correspond roughly to the conventional synchronization operations on a lock, but other synchronization mechanisms can be built on this model as well.
Reference: [11] <author> S.K. Gupta, A.A. Schaffer, A.L. Cox, S. Dwarkadas, and W. Zwaenepoel. </author> <title> Integrating parallelization strategies for linkage analysis. </title> <journal> Computers and Biomedical Research, </journal> <volume> 28 </volume> <pages> 116-139, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: are used to demonstrate the performance: SOR and TSP are small kernels; Barnes-Hut and Water are from the Splash benchmarks suite [19]; IS and 3D-FFT are from the NAS benchmark suite [4]; Shallow is a small weather modeling code from NCAR [18]; and ILINK is a production computational genetics code <ref> [11] </ref>. These applications cover a wide spectrum in terms of write-write false sharing and write-granularity. We present performance results on a 155Mbps ATM network connecting 8 SPARC-20 model 61 workstations. <p> of 3Kb to switch from diffs to whole pages. 5 Applications We use 8 applications in this study: Red-black SOR, Water, TSP, and Barnes-Hut from the Splash benchmark suite [19], IS and 3D-FFT from the NAS benchmark suite [4] Shallow from NCAR [18] and ILINK, a large computational genetics code <ref> [11] </ref>. The applications and input sets used vary considerably in terms of their amount of write-write false sharing and their write granularity. Tables 1 and 2 summarize the relevant characteristics of the applications.
Reference: [12] <author> T.E. Jeremiassen and S. Eggers. </author> <title> Reducing false sharing on shared memory multiprocessors through compile time data transformations. </title> <booktitle> In Proceedings of the 5th ACM Symposium on the Principles and Practice of Parallel Programming, </booktitle> <month> July </month> <year> 1995. </year>
Reference-contexts: Munin [6] used multiple protocols to handle data with different access characteristics. The innovation in our work is that it chooses automatically between SW and MW protocols. In Munin, the choice of protocol was based on somewhat burdensome user annotations. False sharing has also been addressed by static analysis <ref> [12] </ref>, and by using objects as a smaller consistency unit [5]. Freeh et al. [9] implement an adaptive algorithm that detects falsely shared pages and migrates the shared data such that false sharing is eliminated.
Reference: [13] <author> P. Keleher. </author> <title> The relative importance of concurrent writers and weak consistency models. </title> <booktitle> In Proceedings of the 16th International Conference on Distributed Computing Systems, </booktitle> <pages> pages 91-98, </pages> <month> May </month> <year> 1996. </year>
Reference-contexts: 1 Introduction This paper focuses on protocols for implementing lazy release-consistent (LRC) [14] software distributed shared memory (DSM) [16] on commodity hardware. Both single writer (SW) <ref> [13] </ref> and multiple writer (MW) [6] protocols have been used to implement LRC. SW protocols allow only a single writable copy of a page at any given time. Furthermore, they always transfer a whole page to satisfy an access miss. <p> Furthermore, there is a significant memory overhead for recording the modifications. The memory costs can be bounded by garbage collection, but frequent garbage collection results in added execution time. CVM <ref> [13] </ref> uses a SW protocol, while TreadMarks [3] uses a MW protocol (see the work of Keleher [13] for a study of the tradeoffs). Other systems (such as Munin [6]) allow multiple protocols to be used, but require user annotation to choose between them. <p> Furthermore, there is a significant memory overhead for recording the modifications. The memory costs can be bounded by garbage collection, but frequent garbage collection results in added execution time. CVM <ref> [13] </ref> uses a SW protocol, while TreadMarks [3] uses a MW protocol (see the work of Keleher [13] for a study of the tradeoffs). Other systems (such as Munin [6]) allow multiple protocols to be used, but require user annotation to choose between them. In this paper we take an alternative approach. <p> The biggest differences in favor of MW occur for Barnes and ILINK where MW has a speedup of 3.7 and 5.1, respectively, compared to 1.4 and 2.8 for SW. These results are similar to those of Keleher <ref> [13] </ref>, allowing for some differences in platform and applications. Comparing the adaptive to the non-adaptive protocols, we see from Figure 3 that, for all but 3D-FFT and TSP, both adaptive protocols match or exceed the speedup of the best of the non-adaptive protocols. <p> The ownership request messages in the adaptive protocols may cause some increase in the total number of messages, although the ownership requests can sometimes be piggybacked on page transfers. 7 Related Work The SW protocol we use is based on the work of Keleher <ref> [13] </ref>. His work demonstrates that the performance benefits resulting from using LRC rather than sequential consistency (SC) are considerably larger than those resulting from allowing MWs.
Reference: [14] <author> P. Keleher, A. L. Cox, and W. Zwaenepoel. </author> <title> Lazy release consistency for software distributed shared memory. </title> <booktitle> In Proceedings of the 19th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 13-21, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: 1 Introduction This paper focuses on protocols for implementing lazy release-consistent (LRC) <ref> [14] </ref> software distributed shared memory (DSM) [16] on commodity hardware. Both single writer (SW) [13] and multiple writer (MW) [6] protocols have been used to implement LRC. SW protocols allow only a single writable copy of a page at any given time. <p> Essentially, RC allows the effects of ordinary shared memory accesses to be delayed until a subsequent release by the same processor is performed. The Lazy Release Consistency (LRC) algorithm <ref> [14] </ref> delays the propagation of modifications to a processor until that processor executes an acquire. To do so, LRC uses the happened-before-1 partial order [2]. <p> To do so, LRC uses the happened-before-1 partial order [2]. The happened-before-1 partial order is the union of the total processor order of the memory accesses on each individual processor and the partial order of release-acquire pairs. Vector timestamps are used to represent the partial order <ref> [14] </ref>. When a processor executes an acquire, it sends its current vector timestamp in the acquire message. The last releaser then piggybacks on its response a set of write notices, one per page. These write notices describe the shared data modifications that precede the acquire according to the partial order.
Reference: [15] <author> P.T. Koch, R.J. Fowler, and E. </author> <month> Jul. </month> <title> Write ranges: A technique for improving capture and propagation of writes in software DSMs. </title> <note> Submitted for publication. </note>
Reference-contexts: We show that under LRC the benefits of MW and SW protocols can be combined into one adaptive algorithm that uses the appropriate protocol on a per-page basis. Various techniques have been proposed to replace diffing by cheaper alternatives <ref> [15, 21] </ref> or to o*oad diffing to a communication coprocessor [22]. This work is orthogonal to ours, in that we could incorporate these techniques into our adaptive protocols. Using per-word timestamps [1, 15, 21] addresses the problem of diff accumulation directly. <p> Various techniques have been proposed to replace diffing by cheaper alternatives [15, 21] or to o*oad diffing to a communication coprocessor [22]. This work is orthogonal to ours, in that we could incorporate these techniques into our adaptive protocols. Using per-word timestamps <ref> [1, 15, 21] </ref> addresses the problem of diff accumulation directly. The problem is alleviated in our system because we switch to using whole pages whenever the diffs are large. The work of Cox and Fowler, and Stenstrom and Brorsson [7, 20] adapts to migratory sharing patterns in hardware cache-coherence protocols.
Reference: [16] <author> K. Li and P. Hudak. </author> <title> Memory coherence in shared virtual memory systems. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 7(4) </volume> <pages> 321-359, </pages> <month> November </month> <year> 1989. </year>
Reference-contexts: 1 Introduction This paper focuses on protocols for implementing lazy release-consistent (LRC) [14] software distributed shared memory (DSM) <ref> [16] </ref> on commodity hardware. Both single writer (SW) [13] and multiple writer (MW) [6] protocols have been used to implement LRC. SW protocols allow only a single writable copy of a page at any given time. Furthermore, they always transfer a whole page to satisfy an access miss.
Reference: [17] <author> H. Lu, S. Dwarkadas, A.L. Cox, and W. Zwaenepoel. </author> <title> Message passing versus distributed shared memory on networks of workstations. </title> <booktitle> In Proceedings SuperComputing '95, </booktitle> <month> De-cember </month> <year> 1995. </year>
Reference-contexts: Adapting to write granularity also alleviates the diff accumulation <ref> [17] </ref> that occurs in MW. The diff accumulation problem occurs in connection with migratory data where a sequence of synchronizing processors write the same data one after another. <p> WFS keeps all these pages in SW mode during the entire execution. WFS+WG switches to SW mode for all pages after the first iteration. Although the adaptive protocols send more messages than MW due to ownership requests, diffing overhead and diff accumulation <ref> [17] </ref> in MW result in better execution times for the adaptive protocols. The small improvement of WFS over SW is due to the extra messages in SW for forwarding ownership requests. 3D-FFT solves a differential equation using 3D forward and inverse FFT's.
Reference: [18] <author> R. Sadourny. </author> <title> The dynamics of finite-difference models of the shallow-water equations. </title> <journal> Journal of Atmospheric Sciences, </journal> <volume> 32(4), </volume> <month> April </month> <year> 1975. </year>
Reference-contexts: adaptive protocols were implemented in Tread-Marks [3]. 8 applications are used to demonstrate the performance: SOR and TSP are small kernels; Barnes-Hut and Water are from the Splash benchmarks suite [19]; IS and 3D-FFT are from the NAS benchmark suite [4]; Shallow is a small weather modeling code from NCAR <ref> [18] </ref>; and ILINK is a production computational genetics code [11]. These applications cover a wide spectrum in terms of write-write false sharing and write-granularity. We present performance results on a 155Mbps ATM network connecting 8 SPARC-20 model 61 workstations. <p> This led us to a conservative threshold value of 3Kb to switch from diffs to whole pages. 5 Applications We use 8 applications in this study: Red-black SOR, Water, TSP, and Barnes-Hut from the Splash benchmark suite [19], IS and 3D-FFT from the NAS benchmark suite [4] Shallow from NCAR <ref> [18] </ref> and ILINK, a large computational genetics code [11]. The applications and input sets used vary considerably in terms of their amount of write-write false sharing and their write granularity. Tables 1 and 2 summarize the relevant characteristics of the applications.
Reference: [19] <author> J.P. Singh, W.-D. Weber, and A. Gupta. </author> <title> SPLASH: Stanford parallel applications for shared-memory. </title> <type> Technical Report CSL-TR-91-469, </type> <institution> Stanford University, </institution> <month> April </month> <year> 1991. </year>
Reference-contexts: The adaptive protocols were implemented in Tread-Marks [3]. 8 applications are used to demonstrate the performance: SOR and TSP are small kernels; Barnes-Hut and Water are from the Splash benchmarks suite <ref> [19] </ref>; IS and 3D-FFT are from the NAS benchmark suite [4]; Shallow is a small weather modeling code from NCAR [18]; and ILINK is a production computational genetics code [11]. These applications cover a wide spectrum in terms of write-write false sharing and write-granularity. <p> This led us to a conservative threshold value of 3Kb to switch from diffs to whole pages. 5 Applications We use 8 applications in this study: Red-black SOR, Water, TSP, and Barnes-Hut from the Splash benchmark suite <ref> [19] </ref>, IS and 3D-FFT from the NAS benchmark suite [4] Shallow from NCAR [18] and ILINK, a large computational genetics code [11]. The applications and input sets used vary considerably in terms of their amount of write-write false sharing and their write granularity.
Reference: [20] <author> P. Stenstrom, M. Brorsson, and L. Sandberg. </author> <title> An adaptive cache coherence protocol optimized for migratory sharing. </title> <booktitle> In Proceedings of the 20th Annual International Symposium on Computer Architecture, </booktitle> <month> May </month> <year> 1993. </year>
Reference-contexts: Using per-word timestamps [1, 15, 21] addresses the problem of diff accumulation directly. The problem is alleviated in our system because we switch to using whole pages whenever the diffs are large. The work of Cox and Fowler, and Stenstrom and Brorsson <ref> [7, 20] </ref> adapts to migratory sharing patterns in hardware cache-coherence protocols. Migratory cache blocks are detected dynamically (how??).
Reference: [21] <author> M.J. Zekauskas, </author> <title> W.A. Sawdon, and B.N. Ber-shad. Software write detection for distributed shared memory. </title> <booktitle> In Proceedings of the First USENIX Symposium on Operating System Design and Implementation, </booktitle> <pages> pages 87-100, </pages> <month> Novem-ber </month> <year> 1994. </year>
Reference-contexts: We show that under LRC the benefits of MW and SW protocols can be combined into one adaptive algorithm that uses the appropriate protocol on a per-page basis. Various techniques have been proposed to replace diffing by cheaper alternatives <ref> [15, 21] </ref> or to o*oad diffing to a communication coprocessor [22]. This work is orthogonal to ours, in that we could incorporate these techniques into our adaptive protocols. Using per-word timestamps [1, 15, 21] addresses the problem of diff accumulation directly. <p> Various techniques have been proposed to replace diffing by cheaper alternatives [15, 21] or to o*oad diffing to a communication coprocessor [22]. This work is orthogonal to ours, in that we could incorporate these techniques into our adaptive protocols. Using per-word timestamps <ref> [1, 15, 21] </ref> addresses the problem of diff accumulation directly. The problem is alleviated in our system because we switch to using whole pages whenever the diffs are large. The work of Cox and Fowler, and Stenstrom and Brorsson [7, 20] adapts to migratory sharing patterns in hardware cache-coherence protocols.
Reference: [22] <author> Y. Zhou, L. Iftode, and K. Li. </author> <title> Performance evaluation of two home-based lazy release consistency protocols for shared virtual memory systems. </title> <booktitle> In Proceedings of the Second USENIX Symposium on Operating System Design and Implementation, </booktitle> <pages> pages 75-88, </pages> <month> nov </month> <year> 1996. </year>
Reference-contexts: We show that under LRC the benefits of MW and SW protocols can be combined into one adaptive algorithm that uses the appropriate protocol on a per-page basis. Various techniques have been proposed to replace diffing by cheaper alternatives [15, 21] or to o*oad diffing to a communication coprocessor <ref> [22] </ref>. This work is orthogonal to ours, in that we could incorporate these techniques into our adaptive protocols. Using per-word timestamps [1, 15, 21] addresses the problem of diff accumulation directly. The problem is alleviated in our system because we switch to using whole pages whenever the diffs are large.
References-found: 22

