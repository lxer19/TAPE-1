URL: http://www.cis.ohio-state.edu/~harrold/webpapers/icse92.ps
Refering-URL: http://www.cis.ohio-state.edu/~harrold/allpapers.html
Root-URL: 
Title: Incremental Testing of Object-Oriented Class Structures  
Author: Mary Jean Harrold, John D. McGregor and Kevin J. Fitzpatrick 
Address: Clemson, SC 29634-1906  
Affiliation: Department of Computer Science Clemson University  
Abstract: Although there is much interest in creating libraries of well-designed, thoroughly-tested classes that can be confidently reused for many applications, few class testing techniques have been developed. In this paper, we present a class testing technique that exploits the hierarchical nature of the inheritance relation to test related groups of classes by reusing the testing information for a parent class to guide the testing of a subclass. We initially test base classes having no parents by designing a test suite that tests each member function individually and also tests the interactions among member functions. To design a test suite for a subclass, our algorithm incrementally updates the history of its parent to reect both the modified, inherited attributes and the subclass's newly defined attributes. Only those new attributes or affected, inherited attributes are tested and the parent class' test suites are reused, if possible, for the testing. Inherited attributes are retested in their new context in a subclass by testing their interactions with the subclass's newly defined attributes. We have incorporated a data ow tester into Free Soft and are using it for our experimentation. ware Foundation, Inc's C++ compiler
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> B. Beizer, </author> <title> in Software Testing Techniques, </title> <publisher> Van Nos-trand Reinhold Company, Inc., </publisher> <address> New York, </address> <year> 1990. </year>
Reference-contexts: For integration testing, the interface between the units is the focus of the testing. Interface problems include errors in input/output format, incorrect sequencing of subroutine calls, and misunderstood entry or exit parameter values <ref> [1] </ref>. Although many of the integration testing techniques are specification-based, some interprocedural program-based testing techniques have recently been developed [8, 13].
Reference: 2. <author> T. J. Cheatham and L. Mellinger, </author> <title> ``Testing object-oriented software systems,'' </title> <booktitle> Proceedings of the 1990 Computer Science Conference, </booktitle> <pages> pp. 161-165, </pages> <year> 1990. </year>
Reference-contexts: Part of his test design phase is an analysis of the effects of inheritance on the subclass. He suggests that only minimal testing may be required for inherited member functions whose functionality has not changed. Cheatham and Mellinger <ref> [2] </ref> also discuss the problem of subclass testing and present a more extensive analysis of the retesting required for a subclass.
Reference: 3. <author> S. P. Fielder, </author> ` <title> `Object-oriented unit testing,'' </title> <journal> Hewlett-Packard Journal, </journal> <pages> pp. 69-74, </pages> <month> April </month> <year> 1989. </year>
Reference-contexts: However, Perry and Kaiser [16] have shown that many inherited attributes in subclasses of well designed and thoroughly tested classes must be retested in the context of the subclasses. Thus, any subclass testing technique must ensure that this interaction of new attributes and inherited attributes is thoroughly tested. Fielder <ref> [3] </ref> presented a technique to test subclasses whose parent classes have been thoroughly tested. Part of his test design phase is an analysis of the effects of inheritance on the subclass. He suggests that only minimal testing may be required for inherited member functions whose functionality has not changed.
Reference: 4. <author> P. Frankl, </author> <title> ``A framework for testing object-oriented programs,'' </title> <type> Technical Report, </type> <institution> Department of Electrical Engineering and Computer Science, Polytechnic University, </institution> <address> New York, </address> <year> 1989. </year>
Reference-contexts: Thus, we individually test each member function in a class using a test suite that contains both specification-based and program-based test cases. The specification-based test cases can be constructed using existing approaches such as the one proposed by Frankl <ref> [4] </ref>. During this phase of testing, we follow the standard unit testing practice of handling calls to other member functions (procedures) by providing stubs representing called member functions and drivers representing calling member functions.
Reference: 5. <author> P. Frankl and S. Weiss, </author> <title> ``Is data ow testing more effective than branch testing? An emperical study,'' </title> <booktitle> Proceedings of Quality Week 1991, </booktitle> <month> May </month> <year> 1991. </year>
Reference-contexts: Test cases are generated that satisfy the testing requirements when used in a program's execution. One criterion, `all-uses'[6], requires that each definition of a variable be tested on some path to each of its uses. The `all-uses' criterion has been shown to be effective in uncovering errors <ref> [5] </ref> and feasible since relatively few test cases typically are required for its satisfaction [20]. Data ow testing is also used to validate the interfaces between procedures [7, 8].
Reference: 6. <author> P. G. Frankl and E. J. Weyuker, </author> <title> ``An applicable family of data ow testing criteria,'' </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> vol. SE-14, no. 10, </volume> <pages> pp. 1483-1498, </pages> <month> October </month> <year> 1988. </year>
Reference-contexts: of each type class of code new recursive redefined virtual virtual virtual new recursive redefined Interactor 908 79 0 0 14 0 0 Scene 195 21 59 0 8 14 1 MonoScene 98 1 73 0 4 16 4 Dialog 84 3 74 0 1 24 0 ____________________________________________________________________________________________________ ow testing <ref> [6, 11, 15] </ref> to demonstrate the feasibility of our technique.
Reference: 7. <author> M. J. Harrold and M. L. Soffa, </author> <title> ``Interprocedural data ow testing,'' </title> <booktitle> Proceedings of the Third Testing, Analysis, and Verification Symposium (TAV3 - SIGSOFT89), </booktitle> <pages> pp. </pages> <address> 158-167 , Key West, FL , December 1989. </address>
Reference-contexts: The `all-uses' criterion has been shown to be effective in uncovering errors [5] and feasible since relatively few test cases typically are required for its satisfaction [20]. Data ow testing is also used to validate the interfaces between procedures <ref> [7, 8] </ref>. When validating the interface, the focus of the testing is the definitions and uses of variables that extend across procedure boundaries and includes global variables and reference parameters.
Reference: 8. <author> M. J. Harrold and M. L. Soffa, </author> <title> ``Selecting Data for Integration Testing,'' </title> <journal> IEEE Software, special issue on testing and debugging, </journal> <pages> pp. 58-65, </pages> <month> March </month> <year> 1991. </year>
Reference-contexts: Interface problems include errors in input/output format, incorrect sequencing of subroutine calls, and misunderstood entry or exit parameter values [1]. Although many of the integration testing techniques are specification-based, some interprocedural program-based testing techniques have recently been developed <ref> [8, 13] </ref>. A test set is adequate for a selected criterion if it covers the program according to that criterion [19] and a program is deemed to be adequately tested if it has been tested with an adequate test set. <p> The `all-uses' criterion has been shown to be effective in uncovering errors [5] and feasible since relatively few test cases typically are required for its satisfaction [20]. Data ow testing is also used to validate the interfaces between procedures <ref> [7, 8] </ref>. When validating the interface, the focus of the testing is the definitions and uses of variables that extend across procedure boundaries and includes global variables and reference parameters.
Reference: 9. <author> W. E. Howden, </author> <title> in Software Engineering and Technology: Functional Program Testing and Analysis, </title> <publisher> McGraw-Hill, </publisher> <address> New York, </address> <year> 1987. </year>
Reference-contexts: Thus, systematic testing techniques generate a representative set of test cases to provide coverage of the program according to some selected criteria. There are two general forms of test case coverage: specification-based and program-based <ref> [9] </ref>. In specification-based or `black-box' testing, test cases are generated to show that a program satisfies its functional and performance specifications. Specification-based test cases are usually developed manually by considering a program's requirements.
Reference: 10. <author> M. Killian, </author> <title> ``Trellis: Turning designs into programs,'' </title> <journal> CACM, </journal> <volume> vol. 33, no. 9, </volume> <pages> pp. 65-67, </pages> <month> Septem-ber </month> <year> 1990. </year>
Reference-contexts: Our testing technique assumes a language model that is a generalization of the C++[17] model but is sufficiently exible to support other languages such as Trellis <ref> [10] </ref> with similar features.
Reference: 11. <author> B. Korel and J. Laski, </author> <title> ``A tool for data ow oriented program testing,'' </title> <booktitle> ACM Softfair Proceedings, </booktitle> <pages> pp. 35-37, </pages> <month> December </month> <year> 1985. </year>
Reference-contexts: of each type class of code new recursive redefined virtual virtual virtual new recursive redefined Interactor 908 79 0 0 14 0 0 Scene 195 21 59 0 8 14 1 MonoScene 98 1 73 0 4 16 4 Dialog 84 3 74 0 1 24 0 ____________________________________________________________________________________________________ ow testing <ref> [6, 11, 15] </ref> to demonstrate the feasibility of our technique.
Reference: 12. <author> T. Korson and J. D. McGregor, </author> <title> ``Understanding object-oriented: A unifying paradigm,'' </title> <journal> Communications of the ACM, </journal> <volume> vol. 33, no. 9, </volume> <pages> pp. 40-60, </pages> <month> September </month> <year> 1990. </year>
Reference-contexts: Cheatham and Mellinger [2] also discuss the problem of subclass testing and present a more extensive analysis of the retesting required for a subclass. However, both of these subclass testing techniques require that the __________________ More detailed discussion of object-oriented programming is given by Korson and McGregor <ref> [12] </ref>. analysis be performed by hand, which prohibits automating the design phase of the testing. Additionally, neither technique attempts to reuse the parent class's test suite to test the subclass.
Reference: 13. <author> U. Linnenkugel and M. Mullerburg, </author> <title> ``Test data selection criteria for integration testing,'' </title> <booktitle> Proceedings of the 1990 Conference on Systems Integration, </booktitle> <pages> pp. 45-58, </pages> <month> April </month> <year> 1990. </year>
Reference-contexts: Interface problems include errors in input/output format, incorrect sequencing of subroutine calls, and misunderstood entry or exit parameter values [1]. Although many of the integration testing techniques are specification-based, some interprocedural program-based testing techniques have recently been developed <ref> [8, 13] </ref>. A test set is adequate for a selected criterion if it covers the program according to that criterion [19] and a program is deemed to be adequately tested if it has been tested with an adequate test set.
Reference: 14. <author> M. A. Linton and P. R. Calder, </author> <booktitle> ``The design and implementation of InterViews,'' Proceedings of USNIX C++ Workship, </booktitle> <pages> pp. 256-267, </pages> <year> 1987. </year>
Reference-contexts: Experimentation We are using a variety of existing C++ class hierarchies for our experiments to determine the savings in testing gained using our technique. We are considering the class hierarchies in InterViews 2.6 <ref> [14] </ref>, which is a library of graphics interface classes. One representative class hierarchy in InterViews is base class Interactor, and its subclasses, Scene, MonoScene and Dialog, where Scene is a subclass of Interactor, MonoScene is a subclass of Scene, and Dialog is a subclass of MonoScene.
Reference: 15. <author> S. C. Ntafos, </author> <title> ``An evaluation of required element testing strategies,'' </title> <booktitle> Proceedings of 7th International Conference on Software Engineering, </booktitle> <pages> pp. 250-256, </pages> <month> March </month> <year> 1984. </year>
Reference-contexts: of each type class of code new recursive redefined virtual virtual virtual new recursive redefined Interactor 908 79 0 0 14 0 0 Scene 195 21 59 0 8 14 1 MonoScene 98 1 73 0 4 16 4 Dialog 84 3 74 0 1 24 0 ____________________________________________________________________________________________________ ow testing <ref> [6, 11, 15] </ref> to demonstrate the feasibility of our technique.
Reference: 16. <author> D. E. Perry and G. E. Kaiser, </author> <title> ``Adequate testing and object-oriented programming,'' </title> <journal> Journal of Object Oriented Programming, </journal> <volume> vol. 2, </volume> <pages> pp. 13-19, </pages> <month> Jan--uary/February </month> <year> 1990. </year>
Reference-contexts: Additionally, completely retesting each class does not exploit opportunities to reuse and share the design, construction and execution of test suites. Another approach to class testing is to utilize the hierarchical nature of classes related by inheritance to reduce the overhead of retesting each subclass. However, Perry and Kaiser <ref> [16] </ref> have shown that many inherited attributes in subclasses of well designed and thoroughly tested classes must be retested in the context of the subclasses. Thus, any subclass testing technique must ensure that this interaction of new attributes and inherited attributes is thoroughly tested. <p> Our incremental testing technique addresses the test data adequacy concerns expressed by Perry and Kaiser <ref> [16] </ref>. The antidecomposition axiom cautions that adequate testing of a class does not imply that individual member functions have been adequately tested for use in all contexts. Our technique tests each member function independent of its place in the class.
Reference: 17. <author> B. Stroustrup, </author> <title> in The C++ Programming Language, </title> <publisher> Addison-Wesley Publishing Company, </publisher> <address> Massachusetts, </address> <year> 1986. </year>
Reference-contexts: Conclusion We have presented an incremental technique to validate classes that exploits the hierarchical structure of groups of classes related by inheritance. Our language model is a generalization of the C++ <ref> [17] </ref> language. Base classes are initially tested using both specification-based and program-based test cases, and a history of the testing information is saved. A subclass is then tested by incrementally updating the history of the parent class to reect the differences from the parent.
Reference: 18. <author> P. Wegner and S. B. Zdonik, </author> <title> ``Inheritance as an incremental modification mechanism or what like is and isn't like,'' </title> <booktitle> Proceedings of ECOOP'88, </booktitle> <pages> pp. 55-77, </pages> <publisher> Springer-Verlag, </publisher> <year> 1988. </year>
Reference-contexts: The class designer controls the specification of the modifier while the inheritance controls the combination of the modifier and the parent class to get the subclass. Figure 1 illustrates inheritance as an incremental modification technique <ref> [18] </ref> that transforms a parent class P with modifier M into a resulting class R. The composition operator symbolically unites M and P to get R, where R = P M. <p> R result class P parent class modifier The subclass designer specifies the modifier, which may contain various types of attributes that alter the parent class. These include the redefined, virtual and recursive attributes presented by Wegner <ref> [18] </ref> along with an additional type of attribute, the new attribute. We further classify Wegner 's v irtual attribute as virtual-new, virtual-recursive and virtual-redefined. In the following discussion, we reference Figure 1 and define these six types of attributes.
Reference: 19. <author> E. J. Weyuker, </author> <title> ``Axiomatizing software test data adequacy,'' </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> vol. SE-12, no. 12, </volume> <pages> pp. 1128-1138, </pages> <month> December </month> <year> 1986. </year>
Reference-contexts: Although many of the integration testing techniques are specification-based, some interprocedural program-based testing techniques have recently been developed [8, 13]. A test set is adequate for a selected criterion if it covers the program according to that criterion <ref> [19] </ref> and a program is deemed to be adequately tested if it has been tested with an adequate test set. Weyuker [19] developed a set of axioms for test data adequacy that expose insufficiencies in program-based adequacy criteria. Several of these axioms are specifically related to unit and integration testing. <p> A test set is adequate for a selected criterion if it covers the program according to that criterion <ref> [19] </ref> and a program is deemed to be adequately tested if it has been tested with an adequate test set. Weyuker [19] developed a set of axioms for test data adequacy that expose insufficiencies in program-based adequacy criteria. Several of these axioms are specifically related to unit and integration testing. The antiextensionality axiom reminds us that two programs that compute the same function may have entirely different implementations.
Reference: 20. <author> E. J. Weyuker, </author> <title> ``The cost of data ow testing: An empirical study,'' </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> vol. SE-16, no. 2, </volume> <pages> pp. 121-128, </pages> <month> Febru-ary </month> <year> 1990. </year>
Reference-contexts: One criterion, `all-uses'[6], requires that each definition of a variable be tested on some path to each of its uses. The `all-uses' criterion has been shown to be effective in uncovering errors [5] and feasible since relatively few test cases typically are required for its satisfaction <ref> [20] </ref>. Data ow testing is also used to validate the interfaces between procedures [7, 8]. When validating the interface, the focus of the testing is the definitions and uses of variables that extend across procedure boundaries and includes global variables and reference parameters.
References-found: 20

