URL: http://ftp.eecs.umich.edu/people/neuhoff/percep_prune_ICIP97.ps
Refering-URL: http://ftp.eecs.umich.edu/people/neuhoff/
Root-URL: http://www.eecs.umich.edu
Title: Image Coding by Matching Pursuit and Perceptual Pruning  
Author: Michael J. Horowitz and David L. Neuhoff 
Keyword: Overview Cortex Transform  
Note: Model for the Response of the Striate Cortex R(,) b(,) S(,) N(,) (1)  
Address: Ann Arbor, MI 48109  
Affiliation: University of Michigan,  
Abstract: We introduce an image coding algorithm based on the cortex transform, matching pursuit and perceptual pruning that selects and codes only the most perceptually relevant image components, as determined by a new image indistinguishability criterion that derives from a maximum likelihood paradigm. We demonstrate that this method selects image components that produce images with higher subjective quality than matching pursuit with the same number of components. We also show that our perceptual quantization rule makes a substantial gain over uniform scalar quantization. Finally, we present image coding results of high quality at low encoding rates. This paper describes a perceptual image coder that uses a technique similar to matching pursuit (MP) [1] to select and code only the most perceptually relevant image components, as determined by a newly developed image indistinguishability criterion. The coder operates on an image with the information preserving cortex transform [2,3] that is designed to produce transform coefficients that model the responses of simple cell neurons in the striate cortex. We think of the simple cells as sensors and the transform coefficients as sensor values. We hypothesize that each sensor has internal noise that limits sensitivity and, consequently, two images having similar sensor output values are perceived as identical. The indistinguishability criterion is based on a Gaussian assumption for the noise and a maximum likelihood paradigm. The coding algorithm operates in two stages. In stage 1, the algorithm selects sensors in a manner similar to MP. A large number of sensors are selected to ensure that the reproduction contains all perceptually relevant information. In stage 2 it prunes (i.e. eliminates) a set of sensors in such a way that the indistinguishability criterion is still satisfied. The remaining sensor values are quantized with a perceptually based quantization rule, and encoded along with their types and locations. We find that the method produces good quality images at low rates. In comparison to conventional MP, In response to an n-pixel black-white image f = [f(x,y)], the cortex transform produces the vector-valued image a = [a(x,y)] = T(f), where a(x,y) = (a 1 (x,y), , a 66 (x,y)) and where a i (x,y) = f(x,y) * f i (x,y) is the response of a linear filter with impulse response f i (x,y). Described in the frequency domain: one filter is lowpass with radial cutoff frequency w L = .053 p, another is high-pass with radial cutoff frequency 16w L , and the remaining are bandpass with frequency responses that partition the spectrum between radial frequencies w L and 16w L into 32 segments each with a one octave radial frequency bandwidth and each occupying one eighth of the angular spectrum. Corresponding to each bandpass segment of the spectral partition, there are two filters with complementary phasing, for a total of 64 bandpass filters. The low-pass filter is considered to have scale 0, the bandpass filters have scales 1 to 4 and the highpass filter has scale 5. The filters are not "ideal"; rather their frequency responses are tapered by Gaussian rolloffs. Each filter is normalized so its impulse response has unit energy. The details, which are omitted for lack of space, are similar to those in [2]. In effect, each of the bandpass filters models a class of simple cells of the striate cortex whose receptive field is a short line segment with one of eight orientations, one of four widths (scales) and one of two phases. We hypothesize that when visual attention is directed to pixel (x,y) of the image, the response of the striate cortex is modeled by the 326-dimensional random vector The vector b(x,y) is a subset of the sensor values produced by the cortex transform. It includes the output of all 66 types of filters at location (x,y), plus outputs from the filters of scale s = 0, 1, ..., 4 located at the 4 corners of a square centered at (x,y) with sides of length 2 5-s . The vector of noises N (x,y) has independent Gaussian com both the perceptually based sensor selection and the quantization rules offer significant improvements.
Abstract-found: 1
Intro-found: 0
Reference: [1] <author> S. Mallat, Z. Zhang, </author> <title> "Matching pursuits with time-frequency dictionaries," </title> <journal> IEEE Trans. on Signal Processing, </journal> <volume> Vol. 41, </volume> <pages> pp. 3397-3415, </pages> <month> Dec. </month> <year> 1993. </year>
Reference: [2] <author> A. B. Watson, </author> <title> "The cortex transform: rapid computation of simulated neural images," C o m p . V i s i o n , Graphics and Image Proc., </title> <journal> Vol. </journal> <volume> 39, </volume> <pages> pp. 311-327, </pages> <year> 1987. </year>
Reference: [3] <author> A. B. Watson, </author> " <title> Efficiency of an image code based on human vision," </title> <journal> JISA A, </journal> <volume> Vol. 4, </volume> <pages> pp. 2401-2417, </pages> <year> 1987. </year>
Reference: [4] <author> H. </author> <title> Van Trees, Detection, Estimation, and Modulation Theory, Part I, </title> <address> New York: </address> <publisher> Wiley, </publisher> <year> 1969. </year>
Reference: [5] <author> D.L. Neuhoff, </author> <title> Personal Correspondence, </title> <journal> Feb. </journal> <volume> 7, </volume> <year> 1995. </year>
References-found: 5

