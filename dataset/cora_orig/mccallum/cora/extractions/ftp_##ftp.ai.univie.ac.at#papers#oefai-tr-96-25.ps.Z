URL: ftp://ftp.ai.univie.ac.at/papers/oefai-tr-96-25.ps.Z
Refering-URL: http://www.ai.univie.ac.at/cgi-bin/tr-online/?number+96-25
Root-URL: 
Title: Separate-and-Conquer Rule Learning  
Abstract: Johannes Furnkranz juffi@ai.univie.ac.at Austrian Research Institute for Artificial Intelligence Schottengasse 3, A-1010 Wien, Austria Technical Report OEFAI-TR-96-25 Abstract This paper is a survey of inductive rule learning algorithms that use a separate-and-conquer strategy. This strategy can be traced back to the AQ learning system and still enjoys popularity as can be seen from its frequent use in inductive logic programming systems. We will put this wide variety of algorithms into a single framework and analyze them along three different dimensions, namely their search, language and overfitting avoidance biases.
Abstract-found: 1
Intro-found: 1
Reference: <author> Ade, H., De Raedt, L., & Bruynooghe, M. </author> <year> (1995). </year> <title> Declarative bias for specific-to-general ILP systems. Machine Learning, 20 (1-2). Special Issue on Bias Evaluation and Selection. </title>
Reference-contexts: FOSSIL (Furnkranz, 1994b), REP (Brunk & Pazzani, 1991), TDP (Furnkranz, 1994c), I-REP (Furnkranz & Widmer, 1994), I 2 -REP (Furnkranz, 1995), ML-SMART (Bergadano & Giordana, 1988), GA-SMART (Giordana & Sale, 1992), SMART+ (Botta & Giordana, 1993), FOCL (Pazzani & Kibler, 1992), GRENDEL (Cohen, 1994), GOLEM (Muggleton & Feng, 1990), NINA <ref> (Ade et al., 1995) </ref>, PROGOL (Muggleton, 1995) functional relations: FILP (Bergadano & Gunetti, 1993), FFOIL (Quinlan, 1996) regression rules: IBL-SMART (Widmer, 1993) RULE (Weiss & Indurkhya, 1993, 1995), FORS (Karalic, 1995) 3 F urnkranz Given: * a target concept, * positive and negative examples * described with several features and * <p> Although CLINT is not a separate-and-conquer learning algorithm, this technique could be easily adapted for members of this family. In fact this idea has already been used in the NINA separate-and-conquer framework for analyzing bottom-up inductive logic programming algorithms <ref> (Ade et al., 1995) </ref>. Furthermore, techniques for explicitly modeling the language bias (see section 3.1.5) could be easily used for defining a series of hypothesis languages with increasing expressiveness like the ones used in CLINT. <p> A representation change called flattening that removes all function symbols from the examples and the background knowledge allows to implement generalization with a single operator that drops literals from rules (truncation) (Rouveirol, 1994). NINA <ref> (Ade et al., 1995) </ref> is a bottom-up first-order separate-and-conquer algorithm that unifies several bottom-up ILP algorithms such as GOLEM (Muggleton & Feng, 1990), ITOU (Rouveirol, 1992), and CLINT (De Raedt, 1992).
Reference: <author> Ali, K. M., & Pazzani, M. J. </author> <year> (1993). </year> <title> HYDRA: A noise-tolerant relational concept learning algorithm. </title> <editor> In Bajcsy, R. (Ed.), </editor> <booktitle> Proceedings of the 13th Joint International Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 1064-1071 Chambery, France. </address>
Reference-contexts: Clark & Boswell, 1991), CN2-MCI (Kramer, 1994) GREEDY3 (Pagallo & Haussler, 1990), PREPEND (Webb & Brkic, 1993; Webb, 1994), FOIDL (Mooney & Califf, 1995) logic programs: INDUCE (Michalski, 1980), FOIL (Quinlan, 1990; Quinlan & Cameron-Jones, 1995a), mFOIL (Dzeroski & Bratko, 1992), SFOIL (Pompe et al., 1993), MILP (Kovacic, 1994b) HYDRA <ref> (Ali & Pazzani, 1993) </ref>, CHAMP (Kijsirikul et al., 1991, 1992), FOSSIL (Furnkranz, 1994b), REP (Brunk & Pazzani, 1991), TDP (Furnkranz, 1994c), I-REP (Furnkranz & Widmer, 1994), I 2 -REP (Furnkranz, 1995), ML-SMART (Bergadano & Giordana, 1988), GA-SMART (Giordana & Sale, 1992), SMART+ (Botta & Giordana, 1993), FOCL (Pazzani & Kibler, 1992), <p> Then the program assigns a weight to each rule according to some heuristic and the class predicted by the rule with the highest weight will be returned. This method is used in HYDRA <ref> (Ali & Pazzani, 1993) </ref> where the ls-content of a rule (see section 4.3) is used as a weighting heuristic. In AQ-15 (Michalski et al., 1986) each rule is weighted by the percentage of positive examples in the set of examples covered by it. <p> As the denominators P + 2 and N + 2 remain constant inside the FindBestRule procedure, they can be omitted without changing the behavior of the program. In its more general form it is used in HYDRA <ref> (Ali & Pazzani, 1993) </ref> for assessing the quality of rules in multi-class problems. <p> In the case of specialization operators, where p 0 p and n 0 n, it measures the increase in uncovered negative examples minus the decrease in covered positive examples, for generalization operators vice versa. ls-Gain: LSG (r) = C (r)LS (r) C (r 0 )LS (r 0 ) HYDRA <ref> (Ali & Pazzani, 1993) </ref> uses the gain in ls-content times coverage between a rule and its refinement as a search heuristic. 4.3.4 Weighted Heuristics Many heuristics use weighting functions for combining several basic heuristics or for adjusting the behavior of a single heuristic in a certain direction (as for example in
Reference: <author> Bain, M. </author> <year> (1991). </year> <title> Experiments in non-monotonic learning. </title> <booktitle> In Proceedings of the 8th International Workshop on Machine Learning, </booktitle> <pages> pp. </pages> <address> 380-384 Evanston, Illinois. </address>
Reference-contexts: A definition for the invented predicate is then induced from these examples by recursively calling CHAMP with the invented predicate as the target predicate. A very similar approach | called closed-world specialization | is taken in <ref> (Bain, 1991) </ref> and (Srinivasan, Muggleton, & Bain, 1992). Here over-general clauses learned by the bottom-up first-order separate-and-conquer learner GOLEM (Muggleton & Feng, 1990) are specialized by adding a negated new predicate.
Reference: <author> Bergadano, F., & Giordana, A. </author> <year> (1988). </year> <title> A knowledge intensive approach to concept induction. </title> <booktitle> In Proceedings of the 5th International Conference on Machine Learning, </booktitle> <pages> pp. </pages> <address> 305-317 Ann Arbor, Michigan. </address>
Reference-contexts: Quinlan & Cameron-Jones, 1995a), mFOIL (Dzeroski & Bratko, 1992), SFOIL (Pompe et al., 1993), MILP (Kovacic, 1994b) HYDRA (Ali & Pazzani, 1993), CHAMP (Kijsirikul et al., 1991, 1992), FOSSIL (Furnkranz, 1994b), REP (Brunk & Pazzani, 1991), TDP (Furnkranz, 1994c), I-REP (Furnkranz & Widmer, 1994), I 2 -REP (Furnkranz, 1995), ML-SMART <ref> (Bergadano & Giordana, 1988) </ref>, GA-SMART (Giordana & Sale, 1992), SMART+ (Botta & Giordana, 1993), FOCL (Pazzani & Kibler, 1992), GRENDEL (Cohen, 1994), GOLEM (Muggleton & Feng, 1990), NINA (Ade et al., 1995), PROGOL (Muggleton, 1995) functional relations: FILP (Bergadano & Gunetti, 1993), FFOIL (Quinlan, 1996) regression rules: IBL-SMART (Widmer, 1993) RULE <p> A new variable has depth i + 1, where i is the maximum depth of all old variables of the literal where the new variable is introduced. 12 Separate-and-Conquer Rule Learning more than one literal at a time can also be found in ML-SMART <ref> (Bergadano & Giordana, 1988) </ref> and FOCL (Pazzani & Kibler, 1992). These systems allow to replace conditions of a rule with the body of their definitions in the background knowledge. In a later version of ML-SMART (Bergadano, Giordana, & Ponsero, 1989) one could also specify so-called predicate sets. <p> FilterRules will not remove any rules. Thus best-first search does not restrict the number of candidate rules and may be viewed 17 F urnkranz as a beam search with an infinite beam size b = 1. ML-SMART <ref> (Bergadano, Giordana, & Saitta, 1988) </ref> implements such a strategy with several coverage-based pruning heuristics that discard unpromising rules. In (Botta, Giordana, & Saitta, 1992) this approach has been shown to compare favorably to hill-climbing in an artificial domain.
Reference: <author> Bergadano, F., Giordana, A., & Ponsero, S. </author> <year> (1989). </year> <title> Deduction in top-down inductive learning. </title> <booktitle> In Proceedings of the 6th International Workshop on Machine Learning, </booktitle> <pages> pp. 23-25. </pages>
Reference-contexts: These systems allow to replace conditions of a rule with the body of their definitions in the background knowledge. In a later version of ML-SMART <ref> (Bergadano, Giordana, & Ponsero, 1989) </ref> one could also specify so-called predicate sets. A predicate set is a set of literals that are known to be relevant for the definition of a certain predicate.
Reference: <author> Bergadano, F., Giordana, A., & Saitta, L. </author> <year> (1988). </year> <title> Automated concept acquisition in noisy environments. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 10, </volume> <pages> 555-578. </pages>
Reference-contexts: Quinlan & Cameron-Jones, 1995a), mFOIL (Dzeroski & Bratko, 1992), SFOIL (Pompe et al., 1993), MILP (Kovacic, 1994b) HYDRA (Ali & Pazzani, 1993), CHAMP (Kijsirikul et al., 1991, 1992), FOSSIL (Furnkranz, 1994b), REP (Brunk & Pazzani, 1991), TDP (Furnkranz, 1994c), I-REP (Furnkranz & Widmer, 1994), I 2 -REP (Furnkranz, 1995), ML-SMART <ref> (Bergadano & Giordana, 1988) </ref>, GA-SMART (Giordana & Sale, 1992), SMART+ (Botta & Giordana, 1993), FOCL (Pazzani & Kibler, 1992), GRENDEL (Cohen, 1994), GOLEM (Muggleton & Feng, 1990), NINA (Ade et al., 1995), PROGOL (Muggleton, 1995) functional relations: FILP (Bergadano & Gunetti, 1993), FFOIL (Quinlan, 1996) regression rules: IBL-SMART (Widmer, 1993) RULE <p> A new variable has depth i + 1, where i is the maximum depth of all old variables of the literal where the new variable is introduced. 12 Separate-and-Conquer Rule Learning more than one literal at a time can also be found in ML-SMART <ref> (Bergadano & Giordana, 1988) </ref> and FOCL (Pazzani & Kibler, 1992). These systems allow to replace conditions of a rule with the body of their definitions in the background knowledge. In a later version of ML-SMART (Bergadano, Giordana, & Ponsero, 1989) one could also specify so-called predicate sets. <p> FilterRules will not remove any rules. Thus best-first search does not restrict the number of candidate rules and may be viewed 17 F urnkranz as a beam search with an infinite beam size b = 1. ML-SMART <ref> (Bergadano, Giordana, & Saitta, 1988) </ref> implements such a strategy with several coverage-based pruning heuristics that discard unpromising rules. In (Botta, Giordana, & Saitta, 1992) this approach has been shown to compare favorably to hill-climbing in an artificial domain.
Reference: <author> Bergadano, F., & Gunetti, D. </author> <year> (1993). </year> <title> An interactive system to learn functional logic programs. </title> <editor> In Bajcsy, R. (Ed.), </editor> <booktitle> Proceedings of the 13th International Joint Conference on Artificial Intelligence, </booktitle> <pages> pp. 1044-1049. </pages> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: 1994c), I-REP (Furnkranz & Widmer, 1994), I 2 -REP (Furnkranz, 1995), ML-SMART (Bergadano & Giordana, 1988), GA-SMART (Giordana & Sale, 1992), SMART+ (Botta & Giordana, 1993), FOCL (Pazzani & Kibler, 1992), GRENDEL (Cohen, 1994), GOLEM (Muggleton & Feng, 1990), NINA (Ade et al., 1995), PROGOL (Muggleton, 1995) functional relations: FILP <ref> (Bergadano & Gunetti, 1993) </ref>, FFOIL (Quinlan, 1996) regression rules: IBL-SMART (Widmer, 1993) RULE (Weiss & Indurkhya, 1993, 1995), FORS (Karalic, 1995) 3 F urnkranz Given: * a target concept, * positive and negative examples * described with several features and * optional background knowledge Find: * a simple set of rules <p> This is also confirmed by early results from statistical learning theory (Vapnik & Chervonenkis, 1971, 1981), where it has been observed that larger hypothesis spaces can lead to poorer generalization behavior (see also <ref> (Saitta & Bergadano, 1993) </ref>). 18 Separate-and-Conquer Rule Learning 4.1.4 Stochastic Search Another approach to escape the danger of getting stuck in local optima is to use a stochastic search, which be implemented into the framework of figure 4 by allowing randomness in the RefineRule procedure.
Reference: <author> Bergadano, F., & Gunetti, D. </author> <year> (1995). </year> <title> Inductive Logic Programming | From Machine Learning to Software Engineering. Logic Programming Series. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference-contexts: Predicate sets have later been generalized to clause sets <ref> (Bergadano & Gunetti, 1995) </ref>. These are enhanced PROLOG programs, where sets of variables, literals and clauses can appear in the definition. The task of the learner is to find the best rules defined by appropriate subsets of these clause sets.
Reference: <author> Bergadano, F., Matwin, S., Michalski, R. S., & Zhang, J. </author> <year> (1992). </year> <title> Learning two-tiered descriptions of flexible concepts: The POSEIDON system. </title> <journal> Machine Learning, </journal> <volume> 8, </volume> <pages> 5-43. </pages>
Reference-contexts: we feel that a separate treatment of these two issues is justified. 2 Separate-and-Conquer Rule Learning propositional rule sets (DNF): AQ (Michalski, 1969), AQ15 (Michalski et al., 1986), AQ17 (Bloedorn & Michalski, 1991; Wnek & Michalski, 1994; Bloedorn et al., 1993) PRISM (Cendrowska, 1987), SWAP-1 (Weiss & Indurkhya, 1991), POSEIDON <ref> (Bergadano et al., 1992) </ref>, PFOIL (Mooney, 1995), JoJo (Fensel & Wiese, 1993; Wiese, 1996) ATRIS (Kononenko & Kovacic, 1992; Mladenic, 1993) CiPF (Pfahringer, 1994a, 1994b) DLG (Webb, 1992; Webb & Agar, 1992), CLASS (Webb, 1993), SIA (Venturini, 1993) GROW (Cohen, 1993), RIPPER (Cohen, 1995), BEXA (Theron & Cloete, 1996) CNF: PFOIL-CNF <p> In its original formulation (Quinlan, 1990) IC (r) and IC (r 0 ) are computed by counting proofs, while C (r) is computed by counting instances. Coverage Gain: CG (r) = P n n 0 This heuristic is used for pruning in the POSEIDON algorithm <ref> (Bergadano et al., 1992) </ref>. <p> If this is not the case, the condition or rule will be removed. This framework has later been generalized in the POSEIDON system <ref> (Bergadano et al., 1992) </ref>. POSEIDON can simplify a complete and consistent concept description, which has been induced by AQ15 (Michalski et al., 1986), by removing conditions and rules and by 9. <p> Other algorithms employ additional simplification operators like deleting each condition of a rule (Furnkranz & Widmer, 1994), deleting a final sequence of conditions (Cohen, 1993), finding the best replacement for a condition (Weiss & Indurkhya, 1991), and extending and contracting internal disjunctions and intervals <ref> (Bergadano et al., 1992) </ref>. If the accuracy of the best simplification is not below the accuracy of the unpruned theory, REP will continue to prune the new theory. This is repeated until the accuracy of the best pruned theory is below that of its predecessor.
Reference: <author> Bloedorn, E., & Michalski, R. S. </author> <year> (1991). </year> <title> Constructive induction from data in AQ17-DCI: Further experiments. </title> <type> Tech. rep. </type> <institution> MLI 91-12, Artificial Intelligence Center, George Mason University, Fairfax, VA. </institution> <note> 37 F urnkranz Bloedorn, </note> <author> E., Michalski, R. S., & Wnek, J. </author> <year> (1993). </year> <title> Multistrategy constructive induction: </title> <booktitle> AQ17-MCI. In Proceedings of the 2nd International Workshop on Multistrategy Learning, </booktitle> <pages> pp. 188-203. </pages>
Reference-contexts: The simplest approach to constructive induction with separate-and-conquer learning algorithms is to apply a predefined set of arithmetic and logical operators to certain attributes and compute new attributes from them. For example AQ17-DCI <ref> (Bloedorn & Michalski, 1991) </ref> | and to some extend AQ15 (Michalski et al., 1986) | can compute equality and inequality relations, use addition and multiplication operators, and can determine optima, 14 Separate-and-Conquer Rule Learning averages and frequencies in sets of features, reminiscent of some ideas previously used in the BACON discovery
Reference: <author> Bostrom, H. </author> <year> (1995). </year> <title> Covering vs. divide-and-conquer for top-down induction of logic programs. </title> <booktitle> In Proceedings of the 14th International Joint Conference on Artificial Intelligence (IJCAI-95), </booktitle> <pages> pp. 1194-1200. </pages>
Reference-contexts: The most commonly used alternative is decision tree learning via the divide-and-conquer strategy (Quinlan, 1986). Much of the popularity of decision tree learning stems from its efficiency in learning and classification <ref> (Bostrom, 1995) </ref>. Moreover, decision trees can easily be turned into a rule set by generating one rule for each path from the root a leaf. However, there are several aspects which make rule learning via the separate-and-conquer strategy attractive: * Decision trees are often quite complex and hard to understand. <p> Additional evidence for this comes from Rivest (1987) who shows that decision lists (ordered rule sets) with at most k conditions per rule are strictly more expressive than decision trees of depth k. A similar result has been proven in <ref> (Bostrom, 1995) </ref>. * The restriction of decision tree learning algorithms to non-overlapping rules imposes strong constraints on learnable rules.
Reference: <author> Botta, M., Giordana, A., & Saitta, L. </author> <year> (1992). </year> <title> Comparison of search strategies in learning relations. </title> <editor> In Neumann, B. (Ed.), </editor> <booktitle> Proceedings of the 10th European Conference on Artificial Intelligence (ECAI-92), </booktitle> <pages> pp. </pages> <address> 451-455 Vienna, Austria. </address> <publisher> John Wiley & Sons. </publisher>
Reference-contexts: ML-SMART (Bergadano, Giordana, & Saitta, 1988) implements such a strategy with several coverage-based pruning heuristics that discard unpromising rules. In <ref> (Botta, Giordana, & Saitta, 1992) </ref> this approach has been shown to compare favorably to hill-climbing in an artificial domain. When no pruning heuristics are used (i.e., StoppingCriterion always returns false) the search space will be completely exhausted and it is guaranteed that an optimal solution will be found.
Reference: <author> Botta, M., & Giordana, A. </author> <year> (1993). </year> <title> SMART+: A multi-strategy learning tool. </title> <editor> In Bajcsy, R. (Ed.), </editor> <booktitle> Proceedings of the 13th Joint International Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 937-944 Chambery, France. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: (Pompe et al., 1993), MILP (Kovacic, 1994b) HYDRA (Ali & Pazzani, 1993), CHAMP (Kijsirikul et al., 1991, 1992), FOSSIL (Furnkranz, 1994b), REP (Brunk & Pazzani, 1991), TDP (Furnkranz, 1994c), I-REP (Furnkranz & Widmer, 1994), I 2 -REP (Furnkranz, 1995), ML-SMART (Bergadano & Giordana, 1988), GA-SMART (Giordana & Sale, 1992), SMART+ <ref> (Botta & Giordana, 1993) </ref>, FOCL (Pazzani & Kibler, 1992), GRENDEL (Cohen, 1994), GOLEM (Muggleton & Feng, 1990), NINA (Ade et al., 1995), PROGOL (Muggleton, 1995) functional relations: FILP (Bergadano & Gunetti, 1993), FFOIL (Quinlan, 1996) regression rules: IBL-SMART (Widmer, 1993) RULE (Weiss & Indurkhya, 1993, 1995), FORS (Karalic, 1995) 3 F <p> DLG (Webb, 1992) employs it as a search heuristic, but it is more often used as a weighting function (as e.g. in FOIL (Quinlan, 1990)). 24 Separate-and-Conquer Rule Learning Abductivity: ABD (r) = 1 l S This measure has been used in various versions of the SMART family of algorithms <ref> (Botta & Giordana, 1993) </ref>. It aims at measuring how well r is explained by the available background knowledge. <p> ABD (r) is the percentage of conditions that appear in r S , but not in r G . If no background knowledge is available l G = l S = l and thus ABD (r) = 0. For details we refer to <ref> (Botta & Giordana, 1993) </ref>. In some versions l G is approximated by l. l S can be approximated with the length of the language template used in GA-SMART (see section 3.1.5). <p> Separate-and-Conquer Rule Learning SMART+: SM ART (r) = aW IG (r) + b P P (r) + cABD (r) This and similar measures have been used in various versions of the ML-SMART and GA-SMART algorithms (Botta et al., 1992; Giordana & Sale, 1992) and their successor, the SMART+ learning tool <ref> (Botta & Giordana, 1993) </ref>. It computes the weighted average of three terms, the weighted information gain used in FOIL, a weighted consistency measure based on purity, and the abductivity measure.
Reference: <author> Breiman, L., Friedman, J., Olshen, R., & Stone, C. </author> <year> (1984). </year> <title> Classification and Regression Trees. </title> <publisher> Wadsworth & Brooks, </publisher> <address> Pacific Grove, CA. </address>
Reference-contexts: Figure 6 (a) illustrates how post-pruning works in decision tree learning. The right half of the overfitting tree covers the sets C and D of the training instances. When the 10. This method is inspired by the approach taken in CART <ref> (Breiman, Friedman, Olshen, & Stone, 1984) </ref> where the most general decision tree within this standard error margin is selected as a final theory. 31 F urnkranz pruning algorithm decides to prune these two leaves, their ancestor node becomes a leaf that now covers the examples C [ D.
Reference: <author> Brunk, C. A., & Pazzani, M. J. </author> <year> (1991). </year> <title> An investigation of noise-tolerant relational concept learning algorithms. </title> <booktitle> In Proceedings of the 8th International Workshop on Machine Learning, </booktitle> <pages> pp. </pages> <address> 389-393 Evanston, Illinois. </address>
Reference-contexts: & Brkic, 1993; Webb, 1994), FOIDL (Mooney & Califf, 1995) logic programs: INDUCE (Michalski, 1980), FOIL (Quinlan, 1990; Quinlan & Cameron-Jones, 1995a), mFOIL (Dzeroski & Bratko, 1992), SFOIL (Pompe et al., 1993), MILP (Kovacic, 1994b) HYDRA (Ali & Pazzani, 1993), CHAMP (Kijsirikul et al., 1991, 1992), FOSSIL (Furnkranz, 1994b), REP <ref> (Brunk & Pazzani, 1991) </ref>, TDP (Furnkranz, 1994c), I-REP (Furnkranz & Widmer, 1994), I 2 -REP (Furnkranz, 1995), ML-SMART (Bergadano & Giordana, 1988), GA-SMART (Giordana & Sale, 1992), SMART+ (Botta & Giordana, 1993), FOCL (Pazzani & Kibler, 1992), GRENDEL (Cohen, 1994), GOLEM (Muggleton & Feng, 1990), NINA (Ade et al., 1995), PROGOL <p> Simplifications that are usually tried are deleting an entire rule, or deleting the last condition of a rule as in reduced error pruning (REP) <ref> (Brunk & Paz-zani, 1991) </ref>.
Reference: <author> Buntine, W., & Niblett, T. </author> <year> (1992). </year> <title> A further comparison of splitting rules for decision-tree induction. </title> <journal> Machine Learning, </journal> <volume> 8, </volume> <pages> 75-85. </pages>
Reference: <author> Cameron-Jones, R. M., & Quinlan, J. R. </author> <year> (1993). </year> <title> Avoiding pitfalls when learning recursive theories. </title> <editor> In Bajcsy, R. (Ed.), </editor> <booktitle> Proceedings of the 13th International Joint Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 1050-1057 Chambery, France. </address>
Reference: <author> Cendrowska, J. </author> <year> (1987). </year> <title> PRISM: An algorithm for inducing modular rules. </title> <journal> International Journal of Man-Machine Studies, </journal> <volume> 27, </volume> <pages> 349-370. </pages>
Reference-contexts: Thus we feel that a separate treatment of these two issues is justified. 2 Separate-and-Conquer Rule Learning propositional rule sets (DNF): AQ (Michalski, 1969), AQ15 (Michalski et al., 1986), AQ17 (Bloedorn & Michalski, 1991; Wnek & Michalski, 1994; Bloedorn et al., 1993) PRISM <ref> (Cendrowska, 1987) </ref>, SWAP-1 (Weiss & Indurkhya, 1991), POSEIDON (Bergadano et al., 1992), PFOIL (Mooney, 1995), JoJo (Fensel & Wiese, 1993; Wiese, 1996) ATRIS (Kononenko & Kovacic, 1992; Mladenic, 1993) CiPF (Pfahringer, 1994a, 1994b) DLG (Webb, 1992; Webb & Agar, 1992), CLASS (Webb, 1993), SIA (Venturini, 1993) GROW (Cohen, 1993), RIPPER (Cohen, <p> Separate-and-conquer learners do not make such a restriction and are thus less susceptible to this problem. An extreme example for this problem can be found in <ref> (Cendrowska, 1987) </ref>, where it is shown that the minimal decision tree for the concept x defined as x :- a = 3, b = 3. has 10 interior nodes and 21 leafs assuming that the attributes a : : : d each have three values. 4 Separate-and-Conquer Rule Learning procedure SimpleSeparateAndConquer <p> In particular the last issue has contributed to a recent revival of separate-and-conquer learning strategies, which has been a source of motivation for this systematic overview. 2.2 The Algorithm in a more or less equivalent form in the PRISM learning system <ref> (Cendrowska, 1987) </ref>. It starts with an empty theory and successively adds rules to it until all positive examples are covered. The learning of single rules starts with a rule whose body is always true. <p> Information content: IC (r) = log p + n Sometimes the logarithm of the rule's purity is used, which measures the amount of information contained in the classification of the covered examples. This estimate is essentially used in PRISM <ref> (Cendrowska, 1987) </ref>. It is basically equivalent to the purity estimate in the sense that a set of rules ordered by ascending information content will exhibit the same order as when ordered by descending purity. Thus its disadvantages apply here as well. <p> Michalski (1983) suggests the use of not covered negative examples and covered positive examples as the basic heuristics for a lef. In their special case where t i = 1 lef s are often used for breaking ties. PRISM <ref> (Cendrowska, 1987) </ref> for example evaluates rules with a variant of the information content heuristic and breaks ties using positive coverage. 4.3.6 Determinate Literals Several inductive logic programming algorithms, like GOLEM (Muggleton & Feng, 1990), restrict the conditions that may be used in the body of a rule to determinate literals, i.e.
Reference: <author> Clark, P., & Boswell, R. </author> <year> (1991). </year> <title> Rule induction with CN2: Some recent improvements. </title> <booktitle> In Proceedings of the 5th European Working Session of Learning, </booktitle> <pages> pp. 151-163 Porto, </pages> <address> Portugal. </address>
Reference-contexts: Originating from the ID3 decision tree learning system (Quinlan, 1983), this measure has been used in early versions of the CN2 learning algorithm (Clark & Niblett, 1989). However, it suffers from similar deficiencies as purity and information content and has later been replaced by the Laplace estimate <ref> (Clark & Boswell, 1991) </ref>. Cross Entropy: CE (r) = p + n p P p + n n N The cross entropy is an information theoretic measure for the distance between the a priori distribution of examples and the a posteriori distribution of the examples that are covered by r. <p> If a rule covers no examples, its Laplace will be 1 2 (random guessing). On the other hand, if the rule's coverage goes to infinity, LAP (r) converges towards P (r). 7 Because of its simplicity this heuristic is quite popular and is used in CN2 <ref> (Clark & Boswell, 1991) </ref>, mFOIL (Dzeroski & Bratko, 1992), CLASS (Webb, 1993), BEXA (Theron & Cloete, 1996) and several others. m-estimate: M (r) = P +N The m-estimate generalizes the Laplace so that rules with 0-coverage will be evaluated with the a priori probability of the positive examples in the training <p> Both, the Laplace and the m-estimate can also be used for estimating probabilities in more complicated formulas. The m-estimate is primarily used in CN2 <ref> (Clark & Boswell, 1991) </ref> and mFOIL (Dzeroski & Bratko, 1992). 7.
Reference: <author> Clark, P., & Niblett, T. </author> <year> (1989). </year> <title> The CN2 induction algorithm. </title> <journal> Machine Learning, </journal> <volume> 3 (4), </volume> <pages> 261-283. </pages>
Reference-contexts: Theories that impose a fixed evaluation order on their rules are commonly referred to as decision lists (Rivest, 1987). They can be viewed as a PROLOG program where each rule ends with a cut (!) (Mooney & Califf, 1995). CN2 <ref> (Clark & Niblett, 1989) </ref> is able to handle multi-class problems using an evaluation function that gives preference to class distributions where examples of one class dominate (see section 4.3). Each learned rule will predict the class that is dominant among the examples it covers. <p> Beam search effectively maintains hill-climbing's efficiency (reduced by a constant factor), but can yield better results because it explores a larger portion of the hypothesis space. Thus many separate-and-conquer algorithms use beam search in their FindBestRule procedures. Among them are AQ (Michalski et al., 1986), CN2 <ref> (Clark & Niblett, 1989) </ref>, mFOIL (Dzeroski & Bratko, 1992), and BEXA (Theron & Cloete, 1996). <p> Originating from the ID3 decision tree learning system (Quinlan, 1983), this measure has been used in early versions of the CN2 learning algorithm <ref> (Clark & Niblett, 1989) </ref>. However, it suffers from similar deficiencies as purity and information content and has later been replaced by the Laplace estimate (Clark & Boswell, 1991). <p> It has been used in the J-measure (Goodman & Smyth, 1988) and in the significance tests for rules used in CN2 <ref> (Clark & Niblett, 1989) </ref>. Both will be discussed below. Laplace estimate: LAP (r) = p + n + 2 The Laplace estimate penalizes rules with low coverage. If a rule covers no examples, its Laplace will be 1 2 (random guessing). <p> The sum of these terms for all l literals of the clause has to be reduced by log 2 (l !) since the ordering of literals within a clause is in general irrelevant. * Significance Testing was first used as rule stopping criterion in the propositional CN2 induction algorithm <ref> (Clark & Niblett, 1989) </ref> and later on in the relational learner mFOIL (Dzeroski & Bratko, 1992). It tests for significant differences between the distribution of positive and negative examples covered by a rule and the overall distribution of positive and negative examples.
Reference: <author> Cohen, W. W. </author> <year> (1993). </year> <title> Efficient pruning methods for separate-and-conquer rule learning systems. </title> <booktitle> In Proceedings of the 13th International Joint Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 988-994 Chambery, France. </address>
Reference-contexts: al., 1993) PRISM (Cendrowska, 1987), SWAP-1 (Weiss & Indurkhya, 1991), POSEIDON (Bergadano et al., 1992), PFOIL (Mooney, 1995), JoJo (Fensel & Wiese, 1993; Wiese, 1996) ATRIS (Kononenko & Kovacic, 1992; Mladenic, 1993) CiPF (Pfahringer, 1994a, 1994b) DLG (Webb, 1992; Webb & Agar, 1992), CLASS (Webb, 1993), SIA (Venturini, 1993) GROW <ref> (Cohen, 1993) </ref>, RIPPER (Cohen, 1995), BEXA (Theron & Cloete, 1996) CNF: PFOIL-CNF (Mooney, 1995), ICL (De Raedt & Van Laer, 1995) decision lists: (Rivest, 1987), CN2 (Clark & Niblett, 1989; Clark & Boswell, 1991), CN2-MCI (Kramer, 1994) GREEDY3 (Pagallo & Haussler, 1990), PREPEND (Webb & Brkic, 1993; Webb, 1994), FOIDL (Mooney <p> Other algorithms employ additional simplification operators like deleting each condition of a rule (Furnkranz & Widmer, 1994), deleting a final sequence of conditions <ref> (Cohen, 1993) </ref>, finding the best replacement for a condition (Weiss & Indurkhya, 1991), and extending and contracting internal disjunctions and intervals (Bergadano et al., 1992). If the accuracy of the best simplification is not below the accuracy of the unpruned theory, REP will continue to prune the new theory. <p> The reason is that GROW like REP, has to learn an overfitting intermediate theory. An obvious improvement would therefore be to limit the amount of overfitting by using pre-pruning heuristics inside the SeparateAndConquer program that is called in the algorithm of figure 5. <ref> (Cohen, 1993) </ref> improves the GROW algorithm in such a way by using two weak MDL-based stopping criteria.
Reference: <author> Cohen, W. W. </author> <year> (1994). </year> <title> Grammatically biased learning: Learning logic programs using an explicit antecedent description language. </title> <journal> Artificial Intelligence, </journal> <volume> 68 (2), </volume> <pages> 303-366. </pages>
Reference-contexts: Pazzani, 1993), CHAMP (Kijsirikul et al., 1991, 1992), FOSSIL (Furnkranz, 1994b), REP (Brunk & Pazzani, 1991), TDP (Furnkranz, 1994c), I-REP (Furnkranz & Widmer, 1994), I 2 -REP (Furnkranz, 1995), ML-SMART (Bergadano & Giordana, 1988), GA-SMART (Giordana & Sale, 1992), SMART+ (Botta & Giordana, 1993), FOCL (Pazzani & Kibler, 1992), GRENDEL <ref> (Cohen, 1994) </ref>, GOLEM (Muggleton & Feng, 1990), NINA (Ade et al., 1995), PROGOL (Muggleton, 1995) functional relations: FILP (Bergadano & Gunetti, 1993), FFOIL (Quinlan, 1996) regression rules: IBL-SMART (Widmer, 1993) RULE (Weiss & Indurkhya, 1993, 1995), FORS (Karalic, 1995) 3 F urnkranz Given: * a target concept, * positive and negative <p> The most flexible and most expressive framework for explicitly modeling hypothesis spaces are antecedent description grammars <ref> (Cohen, 1994) </ref> as used in the top-down separate-and-conquer learning algorithm GRENDEL. An antecedent description grammar is a context-free grammar whose symbols are logical literals. Its terminal symbols are literals from the background knowledge.
Reference: <author> Cohen, W. W. </author> <year> (1995). </year> <title> Fast effective rule induction. </title> <editor> In Prieditis, A., & Russell, S. (Eds.), </editor> <booktitle> Proceedings of the 12th International Conference on Machine Learning. 38 Separate-and-Conquer Rule Learning De Raedt, </booktitle> <editor> L. </editor> <year> (1992). </year> <title> Interactive Theory Revision: An Inductive Logic Programming Approach. </title> <publisher> Academic Press. </publisher>
Reference-contexts: (Cendrowska, 1987), SWAP-1 (Weiss & Indurkhya, 1991), POSEIDON (Bergadano et al., 1992), PFOIL (Mooney, 1995), JoJo (Fensel & Wiese, 1993; Wiese, 1996) ATRIS (Kononenko & Kovacic, 1992; Mladenic, 1993) CiPF (Pfahringer, 1994a, 1994b) DLG (Webb, 1992; Webb & Agar, 1992), CLASS (Webb, 1993), SIA (Venturini, 1993) GROW (Cohen, 1993), RIPPER <ref> (Cohen, 1995) </ref>, BEXA (Theron & Cloete, 1996) CNF: PFOIL-CNF (Mooney, 1995), ICL (De Raedt & Van Laer, 1995) decision lists: (Rivest, 1987), CN2 (Clark & Niblett, 1989; Clark & Boswell, 1991), CN2-MCI (Kramer, 1994) GREEDY3 (Pagallo & Haussler, 1990), PREPEND (Webb & Brkic, 1993; Webb, 1994), FOIDL (Mooney & Califf, 1995) <p> Post-pruning methods are used as pre-pruning heuristics. I-REP has been shown to outperform various other pruning algorithms in a variety of noisy domains, in particular in terms of efficiency (Furnkranz & Widmer, 1994; Furnkranz, 1996). However, it has several weaknesses, which have been addressed in subsequent work <ref> (Cohen, 1995) </ref>. First Cohen (1995) has shown that accuracy estimates for low-coverage rules will have a high variance and therefore I-REP is likely to stop prematurely and to overgeneralize in domains that are susceptible to the small disjuncts problem (Holte, Acker, & Porter, 1989).
Reference: <author> De Raedt, L. (Ed.). </author> <year> (1995). </year> <booktitle> Advances in Inductive Logic Programming, Vol. 32 of Frontiers in Artificial Intelligence and Applications. </booktitle> <publisher> IOS Press. </publisher>
Reference-contexts: PFOIL (Mooney, 1995), JoJo (Fensel & Wiese, 1993; Wiese, 1996) ATRIS (Kononenko & Kovacic, 1992; Mladenic, 1993) CiPF (Pfahringer, 1994a, 1994b) DLG (Webb, 1992; Webb & Agar, 1992), CLASS (Webb, 1993), SIA (Venturini, 1993) GROW (Cohen, 1993), RIPPER (Cohen, 1995), BEXA (Theron & Cloete, 1996) CNF: PFOIL-CNF (Mooney, 1995), ICL <ref> (De Raedt & Van Laer, 1995) </ref> decision lists: (Rivest, 1987), CN2 (Clark & Niblett, 1989; Clark & Boswell, 1991), CN2-MCI (Kramer, 1994) GREEDY3 (Pagallo & Haussler, 1990), PREPEND (Webb & Brkic, 1993; Webb, 1994), FOIDL (Mooney & Califf, 1995) logic programs: INDUCE (Michalski, 1980), FOIL (Quinlan, 1990; Quinlan & Cameron-Jones, 1995a), <p> FOSSIL (Furnkranz, 1994b), REP (Brunk & Pazzani, 1991), TDP (Furnkranz, 1994c), I-REP (Furnkranz & Widmer, 1994), I 2 -REP (Furnkranz, 1995), ML-SMART (Bergadano & Giordana, 1988), GA-SMART (Giordana & Sale, 1992), SMART+ (Botta & Giordana, 1993), FOCL (Pazzani & Kibler, 1992), GRENDEL (Cohen, 1994), GOLEM (Muggleton & Feng, 1990), NINA <ref> (Ade et al., 1995) </ref>, PROGOL (Muggleton, 1995) functional relations: FILP (Bergadano & Gunetti, 1993), FFOIL (Quinlan, 1996) regression rules: IBL-SMART (Widmer, 1993) RULE (Weiss & Indurkhya, 1993, 1995), FORS (Karalic, 1995) 3 F urnkranz Given: * a target concept, * positive and negative examples * described with several features and * <p> Although CLINT is not a separate-and-conquer learning algorithm, this technique could be easily adapted for members of this family. In fact this idea has already been used in the NINA separate-and-conquer framework for analyzing bottom-up inductive logic programming algorithms <ref> (Ade et al., 1995) </ref>. Furthermore, techniques for explicitly modeling the language bias (see section 3.1.5) could be easily used for defining a series of hypothesis languages with increasing expressiveness like the ones used in CLINT. <p> A representation change called flattening that removes all function symbols from the examples and the background knowledge allows to implement generalization with a single operator that drops literals from rules (truncation) (Rouveirol, 1994). NINA <ref> (Ade et al., 1995) </ref> is a bottom-up first-order separate-and-conquer algorithm that unifies several bottom-up ILP algorithms such as GOLEM (Muggleton & Feng, 1990), ITOU (Rouveirol, 1992), and CLINT (De Raedt, 1992). <p> All algorithms and heuristics discussed in this paper can be applied to this task as well with only slight modifications (e.g., to swap the role of p and n in the heuristics). ICL <ref> (De Raedt & Van Laer, 1995) </ref> is a similar approach that learns in a first-order logic framework. The basic entity that it covers are not single examples, but (partial) ground models of the target theory.
Reference: <author> De Raedt, L., & Bruynooghe, M. </author> <year> (1990). </year> <title> Indirect relevance and bias in inductive concept learning. </title> <journal> Knowledge Acquisition, </journal> <volume> 2, </volume> <pages> 365-390. </pages>
Reference: <author> De Raedt, L., & Van Laer, W. </author> <year> (1995). </year> <title> Inductive constraint logic. </title> <booktitle> In Proceedings of the 5th Workshop on Algorithmic Learning Theory (ALT-95). </booktitle> <publisher> Springer-Verlag. </publisher>
Reference-contexts: PFOIL (Mooney, 1995), JoJo (Fensel & Wiese, 1993; Wiese, 1996) ATRIS (Kononenko & Kovacic, 1992; Mladenic, 1993) CiPF (Pfahringer, 1994a, 1994b) DLG (Webb, 1992; Webb & Agar, 1992), CLASS (Webb, 1993), SIA (Venturini, 1993) GROW (Cohen, 1993), RIPPER (Cohen, 1995), BEXA (Theron & Cloete, 1996) CNF: PFOIL-CNF (Mooney, 1995), ICL <ref> (De Raedt & Van Laer, 1995) </ref> decision lists: (Rivest, 1987), CN2 (Clark & Niblett, 1989; Clark & Boswell, 1991), CN2-MCI (Kramer, 1994) GREEDY3 (Pagallo & Haussler, 1990), PREPEND (Webb & Brkic, 1993; Webb, 1994), FOIDL (Mooney & Califf, 1995) logic programs: INDUCE (Michalski, 1980), FOIL (Quinlan, 1990; Quinlan & Cameron-Jones, 1995a), <p> FOSSIL (Furnkranz, 1994b), REP (Brunk & Pazzani, 1991), TDP (Furnkranz, 1994c), I-REP (Furnkranz & Widmer, 1994), I 2 -REP (Furnkranz, 1995), ML-SMART (Bergadano & Giordana, 1988), GA-SMART (Giordana & Sale, 1992), SMART+ (Botta & Giordana, 1993), FOCL (Pazzani & Kibler, 1992), GRENDEL (Cohen, 1994), GOLEM (Muggleton & Feng, 1990), NINA <ref> (Ade et al., 1995) </ref>, PROGOL (Muggleton, 1995) functional relations: FILP (Bergadano & Gunetti, 1993), FFOIL (Quinlan, 1996) regression rules: IBL-SMART (Widmer, 1993) RULE (Weiss & Indurkhya, 1993, 1995), FORS (Karalic, 1995) 3 F urnkranz Given: * a target concept, * positive and negative examples * described with several features and * <p> Although CLINT is not a separate-and-conquer learning algorithm, this technique could be easily adapted for members of this family. In fact this idea has already been used in the NINA separate-and-conquer framework for analyzing bottom-up inductive logic programming algorithms <ref> (Ade et al., 1995) </ref>. Furthermore, techniques for explicitly modeling the language bias (see section 3.1.5) could be easily used for defining a series of hypothesis languages with increasing expressiveness like the ones used in CLINT. <p> A representation change called flattening that removes all function symbols from the examples and the background knowledge allows to implement generalization with a single operator that drops literals from rules (truncation) (Rouveirol, 1994). NINA <ref> (Ade et al., 1995) </ref> is a bottom-up first-order separate-and-conquer algorithm that unifies several bottom-up ILP algorithms such as GOLEM (Muggleton & Feng, 1990), ITOU (Rouveirol, 1992), and CLINT (De Raedt, 1992). <p> All algorithms and heuristics discussed in this paper can be applied to this task as well with only slight modifications (e.g., to swap the role of p and n in the heuristics). ICL <ref> (De Raedt & Van Laer, 1995) </ref> is a similar approach that learns in a first-order logic framework. The basic entity that it covers are not single examples, but (partial) ground models of the target theory.
Reference: <author> Dehaspe, L., & De Raedt, L. </author> <year> (1996). </year> <title> DLAB: A declarative language bias formalism. </title> <booktitle> In Proceedings of the International Symposium on Methodologies for Intelligent Systems (ISMIS-96), </booktitle> <pages> pp. 613-622. </pages>
Reference-contexts: This framework combines the advantages of rule models and clause sets by recognizing that predicate variables implicitly define predicate sets. It has later been generalized into the DLAB declarative language bias formalism <ref> (Dehaspe & De Raedt, 1996) </ref>, which can also specify the number of items that have to be chosen from an explicitly or implicitly defined predicate set.
Reference: <author> Domingos, P. </author> <year> (1996a). </year> <title> Linear-time rule induction. </title> <booktitle> In Proceedings of the 2nd International Conference on Knowledge Discovery and Data Mining (KDD-96), </booktitle> <pages> pp. 96-101. </pages> <publisher> AAAI Press. </publisher>
Reference-contexts: A similar approach has also been taken in the inductive logic programming algorithm CHILLIN (Zelle, Mooney, & Konvisser, 1994), where rules are generalized by forming their least general generalization (Plotkin, 1970) and, if necessary, successively specialized using top-down hill-climbing as in FOIL. CWS <ref> (Domingos, 1996a) </ref> interleaves the induction of different rules by starting to induce the next rule in the same cycle as the second condition of the current rule is learned. ITRULE (Goodman & Smyth, 1988) performs an efficient exhaustive search for a fixed number of rule with a fixed maximum length.
Reference: <author> Domingos, P. </author> <year> (1996b). </year> <title> Unifying instance-based and rule-based induction. </title> <journal> Machine Learning, </journal> <volume> 24, </volume> <pages> 141-168. </pages>
Reference-contexts: There are also a variety of other rule learning approaches that do not use separate-and-conquer frameworks. In particular several algorithms that use a bottom-up learning strategy start with a set of rules, each representing one example, and successively generalize the entire rule set. RISE <ref> (Domingos, 1996b) </ref> is a particularly successful system that uses such an approach, where single rules are minimally generalized so that they cover the example that is most similar to them. Domingos (1996b) has named his method "conquering without separating".
Reference: <author> Dzeroski, S., & Bratko, I. </author> <year> (1992). </year> <title> Handling noise in Inductive Logic Programming. </title> <booktitle> In Proceedings of the International Workshop on Inductive Logic Programming Tokyo, </booktitle> <address> Japan. </address>
Reference-contexts: & Van Laer, 1995) decision lists: (Rivest, 1987), CN2 (Clark & Niblett, 1989; Clark & Boswell, 1991), CN2-MCI (Kramer, 1994) GREEDY3 (Pagallo & Haussler, 1990), PREPEND (Webb & Brkic, 1993; Webb, 1994), FOIDL (Mooney & Califf, 1995) logic programs: INDUCE (Michalski, 1980), FOIL (Quinlan, 1990; Quinlan & Cameron-Jones, 1995a), mFOIL <ref> (Dzeroski & Bratko, 1992) </ref>, SFOIL (Pompe et al., 1993), MILP (Kovacic, 1994b) HYDRA (Ali & Pazzani, 1993), CHAMP (Kijsirikul et al., 1991, 1992), FOSSIL (Furnkranz, 1994b), REP (Brunk & Pazzani, 1991), TDP (Furnkranz, 1994c), I-REP (Furnkranz & Widmer, 1994), I 2 -REP (Furnkranz, 1995), ML-SMART (Bergadano & Giordana, 1988), GA-SMART (Giordana <p> The literal is symmetric in the variables X and Y. A more detailed description of this syntax can be found in the appendix of (Furnkranz, 1994a). Similar declarations can be made in mFOIL <ref> (Dzeroski & Bratko, 1992) </ref>, recent versions of FOIL (Quinlan & Cameron-Jones, 1995a), PROGOL (Muggleton, 1995), and others. Restrictions of this type can significantly reduce the hypothesis space. Similar effects can also be achieved by restricting the domains of the selectors. <p> Thus many separate-and-conquer algorithms use beam search in their FindBestRule procedures. Among them are AQ (Michalski et al., 1986), CN2 (Clark & Niblett, 1989), mFOIL <ref> (Dzeroski & Bratko, 1992) </ref>, and BEXA (Theron & Cloete, 1996). <p> On the other hand, if the rule's coverage goes to infinity, LAP (r) converges towards P (r). 7 Because of its simplicity this heuristic is quite popular and is used in CN2 (Clark & Boswell, 1991), mFOIL <ref> (Dzeroski & Bratko, 1992) </ref>, CLASS (Webb, 1993), BEXA (Theron & Cloete, 1996) and several others. m-estimate: M (r) = P +N The m-estimate generalizes the Laplace so that rules with 0-coverage will be evaluated with the a priori probability of the positive examples in the training set instead of 1 2 <p> Both, the Laplace and the m-estimate can also be used for estimating probabilities in more complicated formulas. The m-estimate is primarily used in CN2 (Clark & Boswell, 1991) and mFOIL <ref> (Dzeroski & Bratko, 1992) </ref>. 7. <p> clause has to be reduced by log 2 (l !) since the ordering of literals within a clause is in general irrelevant. * Significance Testing was first used as rule stopping criterion in the propositional CN2 induction algorithm (Clark & Niblett, 1989) and later on in the relational learner mFOIL <ref> (Dzeroski & Bratko, 1992) </ref>. It tests for significant differences between the distribution of positive and negative examples covered by a rule and the overall distribution of positive and negative examples.
Reference: <author> Dzeroski, S., Schulze-Kremer, S., Heidtke, K. R., Siems, K., & Wettschereck, D. </author> <year> (1996). </year> <title> Applying ILP to diterpene structure elucidation from 13 C NMR spectra. </title> <booktitle> In Proceedings of the MLnet Familiarization Workshop on Data Mining with Inductive Logic Programming (ILP for KDD), </booktitle> <pages> pp. 12-24. </pages>
Reference-contexts: With this admissible search heuristic PROGOL performs an exhaustive search through the hypothesis space. However, for longer rules (&gt; 4 conditions) this exhaustive search is too inefficient for practical problems <ref> (Dzeroski et al., 1996) </ref>. A similar heuristic is used in FOIL's hill-climbing algorithm for safely pruning certain branches of the search space (Quinlan, 1990). It might be worth-while to try a best-first search with this heuristic.
Reference: <author> Fensel, D., & Wiese, M. </author> <year> (1993). </year> <title> Refinement of rule sets with JoJo. </title> <editor> In Brazdil, P. (Ed.), </editor> <booktitle> Proceedings of the 6th European Conference on Machine Learning (ECML-93), No. 667 in Lecture Notes in Artificial Intelligence, </booktitle> <pages> pp. 378-383. </pages> <publisher> Springer-Verlag. </publisher>
Reference-contexts: Similarly, IBL-SMART (Widmer, 1993) can perform a generalization step by dropping a condition whenever its top-down search leads to a rule that covers too few positive examples (according some predefined threshold). However, both algorithms preserve an overall top-down tendency in its search. The JoJo algorithm <ref> (Fensel & Wiese, 1993) </ref> on the other hand starts the search at an arbitrary point in the hypothesis space (e.g., a randomly generated rule) and improves it by applying generalization and specialization operators, i.e., by adding or dropping conditions.
Reference: <author> Fensel, D., & Wiese, M. </author> <year> (1994). </year> <title> From JoJo to Frog: Extending a bi-directional strategy to a more flexible three-directional search. </title> <editor> In Globig, C., & Althoff, K.-D. (Eds.), </editor> <booktitle> Beitrage zum 7. Fachgruppentreffen Maschinelles Lernen, No. LSA-95-01 in Forschungsbericht, </booktitle> <pages> pp. </pages> <institution> 37-44 University of Kaiserslautern. Zentrum fur Lernende Systeme und Anwen-dungen. </institution>
Reference-contexts: Recent additions allow the system to directly replace conditions in rules <ref> (Fensel & Wiese, 1994) </ref> and to use general first-order literals (Wiese, 1996).
Reference: <author> Furnkranz, J. </author> <year> (1994a). </year> <title> Efficient Pruning Methods for Relational Learning. </title> <type> Ph.D. thesis, </type> <institution> Vienna University of Technology. </institution>
Reference-contexts: Many predicates are also symmetric in some of their input arguments, i.e. they will produce the same result no matter in which order these arguments are given. These symmetries can also be exploited by various programs. 11 F urnkranz The programs used in <ref> (Furnkranz, 1994a, 1996) </ref> for example can specify background knowledge with statements like known literal (adjacent (X,Y),[X-file,Y-file],[+,+],[X-Y]). This declaration specifies that the literal adjacent/2 can be used as a rule condition with two input variables (+) of the type file. The literal is symmetric in the variables X and Y. <p> This declaration specifies that the literal adjacent/2 can be used as a rule condition with two input variables (+) of the type file. The literal is symmetric in the variables X and Y. A more detailed description of this syntax can be found in the appendix of <ref> (Furnkranz, 1994a) </ref>. Similar declarations can be made in mFOIL (Dzeroski & Bratko, 1992), recent versions of FOIL (Quinlan & Cameron-Jones, 1995a), PROGOL (Muggleton, 1995), and others. Restrictions of this type can significantly reduce the hypothesis space. Similar effects can also be achieved by restricting the domains of the selectors.
Reference: <author> Furnkranz, J. </author> <year> (1994b). </year> <title> Fossil: A robust relational learner. </title> <editor> In Bergadano, F., & De Raedt, L. (Eds.), </editor> <booktitle> Proceedings of the 7th European Conference on Machine Learning (ECML-94), Vol. 784 of Lecture Notes in Artificial Intelligence, </booktitle> <pages> pp. 122-137 Catania, </pages> <address> Italy. </address> <publisher> Springer-Verlag. </publisher> <address> 39 F urnkranz Furnkranz, J. </address> <year> (1994c). </year> <title> Top-down pruning in relational learning. </title> <editor> In Cohn, A. (Ed.), </editor> <booktitle> Proceedings of the 11th European Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 453-457 Am-sterdam, The Netherlands. </address> <publisher> John Wiley & Sons. </publisher>
Reference-contexts: 1990), PREPEND (Webb & Brkic, 1993; Webb, 1994), FOIDL (Mooney & Califf, 1995) logic programs: INDUCE (Michalski, 1980), FOIL (Quinlan, 1990; Quinlan & Cameron-Jones, 1995a), mFOIL (Dzeroski & Bratko, 1992), SFOIL (Pompe et al., 1993), MILP (Kovacic, 1994b) HYDRA (Ali & Pazzani, 1993), CHAMP (Kijsirikul et al., 1991, 1992), FOSSIL <ref> (Furnkranz, 1994b) </ref>, REP (Brunk & Pazzani, 1991), TDP (Furnkranz, 1994c), I-REP (Furnkranz & Widmer, 1994), I 2 -REP (Furnkranz, 1995), ML-SMART (Bergadano & Giordana, 1988), GA-SMART (Giordana & Sale, 1992), SMART+ (Botta & Giordana, 1993), FOCL (Pazzani & Kibler, 1992), GRENDEL (Cohen, 1994), GOLEM (Muggleton & Feng, 1990), NINA (Ade et <p> Correlation: CORR (r) = p+tnfnn p 0 +n 0 ( p 0 n 0 p+n (tn+fn) (1 ( p 0 n 0 p+n (tn+fn) tn = n 0 n; fn = p 0 p This correlation estimate has been suggested for the top-down hill-climbing algorithm FOSSIL <ref> (Furnkranz, 1994b) </ref>. <p> Negative values indicate a negative correlation, which suggests to add the negation of the condition c to r 0 . For a derivation of this formula, its efficient computation, and a discussion of its advantages we have to refer the reader to <ref> (Furnkranz, 1994b) </ref>. 4.3.2 Complexity Estimates There are a variety of heuristics for measuring the complexity of candidate rules. Among them are: Rule Length: L (r) = l This simple measure estimates the complexity of a rule with the number of its conditions. <p> If the difference is insignificant, the rule is discarded. * The Cutoff Stopping Criterion compares the heuristic evaluation of a literal to a user-set threshold and only admits literals that have an evaluation above this cutoff. 9 It has been used in the relational separate-and-conquer learning system FOSSIL <ref> (Furnkranz, 1994b) </ref>. Under the assumption that the search heuristic returns values between 0 and 1, FOSSIL will fit all of the data at cutoff = 0 (no pre-pruning). On the other hand, cutoff = 1 means that FOSSIL will learn an empty theory (maximum pre-pruning). <p> Values between 0 and 1 trade off the two extremes. For the correlation heuristic, a value of 0:3 has been shown to yield good results at different training set sizes and at differing levels of noise <ref> (Furnkranz, 1994b) </ref> as well as across a variety of test domains (Furnkranz, 1996). 5.2 Post-pruning While pre-pruning techniques try to account for the noise in the data while constructing the final theory, post-pruning methods attempt to improve the learned theory in a post-processing phase (subroutine PostProcess of figure 4). <p> However, there is always the danger that a predefined stopping criterion will oversimplify the theory. To avoid this Furnkranz (1994c) has developed an algorithm called Top-Down Pruning (TDP). This algorithm generates all theories that can be learned with different settings of the cutoff parameter of FOSSIL's cutoff stopping criterion <ref> (Furnkranz, 1994b) </ref>. This series of theories is generated in a top-down fashion.
Reference: <author> Furnkranz, J. </author> <year> (1995). </year> <title> A tight integration of pruning and learning (extended abstract). </title>
Reference-contexts: FOIL (Quinlan, 1990; Quinlan & Cameron-Jones, 1995a), mFOIL (Dzeroski & Bratko, 1992), SFOIL (Pompe et al., 1993), MILP (Kovacic, 1994b) HYDRA (Ali & Pazzani, 1993), CHAMP (Kijsirikul et al., 1991, 1992), FOSSIL (Furnkranz, 1994b), REP (Brunk & Pazzani, 1991), TDP (Furnkranz, 1994c), I-REP (Furnkranz & Widmer, 1994), I 2 -REP <ref> (Furnkranz, 1995) </ref>, ML-SMART (Bergadano & Giordana, 1988), GA-SMART (Giordana & Sale, 1992), SMART+ (Botta & Giordana, 1993), FOCL (Pazzani & Kibler, 1992), GRENDEL (Cohen, 1994), GOLEM (Muggleton & Feng, 1990), NINA (Ade et al., 1995), PROGOL (Muggleton, 1995) functional relations: FILP (Bergadano & Gunetti, 1993), FFOIL (Quinlan, 1996) regression rules: IBL-SMART
Reference: <editor> In Lavrac, N., & Wrobel, S. (Eds.), </editor> <booktitle> Proceedings of the 8th European Conference on Machine Learning (ECML-95), Vol. 912 of Lecture Notes in Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 291-294 Heraclion, Greece. </address> <publisher> Springer-Verlag. </publisher>
Reference: <author> Furnkranz, J. </author> <year> (1996). </year> <title> Pruning algorithms for rule learning. </title> <type> Tech. rep. </type> <institution> OEFAI-TR-96-07, Austrian Research Institute for Artificial Intelligence. </institution> <note> Submitted to Machine Learning. </note>
Reference-contexts: Values between 0 and 1 trade off the two extremes. For the correlation heuristic, a value of 0:3 has been shown to yield good results at different training set sizes and at differing levels of noise (Furnkranz, 1994b) as well as across a variety of test domains <ref> (Furnkranz, 1996) </ref>. 5.2 Post-pruning While pre-pruning techniques try to account for the noise in the data while constructing the final theory, post-pruning methods attempt to improve the learned theory in a post-processing phase (subroutine PostProcess of figure 4).
Reference: <author> Furnkranz, J., & Widmer, G. </author> <year> (1994). </year> <title> Incremental Reduced Error Pruning. </title> <editor> In Cohen, W., & Hirsh, H. (Eds.), </editor> <booktitle> Proceedings of the 11th International Conference on Machine Learning, </booktitle> <pages> pp. </pages> <address> 70-77 New Brunswick, NJ. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Califf, 1995) logic programs: INDUCE (Michalski, 1980), FOIL (Quinlan, 1990; Quinlan & Cameron-Jones, 1995a), mFOIL (Dzeroski & Bratko, 1992), SFOIL (Pompe et al., 1993), MILP (Kovacic, 1994b) HYDRA (Ali & Pazzani, 1993), CHAMP (Kijsirikul et al., 1991, 1992), FOSSIL (Furnkranz, 1994b), REP (Brunk & Pazzani, 1991), TDP (Furnkranz, 1994c), I-REP <ref> (Furnkranz & Widmer, 1994) </ref>, I 2 -REP (Furnkranz, 1995), ML-SMART (Bergadano & Giordana, 1988), GA-SMART (Giordana & Sale, 1992), SMART+ (Botta & Giordana, 1993), FOCL (Pazzani & Kibler, 1992), GRENDEL (Cohen, 1994), GOLEM (Muggleton & Feng, 1990), NINA (Ade et al., 1995), PROGOL (Muggleton, 1995) functional relations: FILP (Bergadano & Gunetti, <p> As P and N are constant for all candidate rules, maximizing accuracy amounts to maximizing p n. In this form it is part of the admissible search heuristic used in PROGOL (Muggleton, 1995). It is also used in I-REP <ref> (Furnkranz & Widmer, 1994) </ref>, which will be discussed in section 5.4, where we will also mention some deficiencies of this measure. <p> Simplifications that are usually tried are deleting an entire rule, or deleting the last condition of a rule as in reduced error pruning (REP) (Brunk & Paz-zani, 1991). Other algorithms employ additional simplification operators like deleting each condition of a rule <ref> (Furnkranz & Widmer, 1994) </ref>, deleting a final sequence of conditions (Cohen, 1993), finding the best replacement for a condition (Weiss & Indurkhya, 1991), and extending and contracting internal disjunctions and intervals (Bergadano et al., 1992). <p> TDP's implementation made use of several optimizations, so that finding this theory is often cheaper than completely fitting the noise. 5.4 Integrating Pre- and Post-pruning There is another fundamental problem with post-pruning in separate-and-conquer algorithms, which was first pointed out in <ref> (Furnkranz & Widmer, 1994) </ref>. Although the separate-and-conquer approach shares many similarities with the divide-and-conquer strategy, there is one important difference: Pruning of branches in a decision tree will never affect the neighboring branches, whereas pruning of conditions of a rule will affect all subsequent rules. <p> Incremental reduced error pruning (I-REP) <ref> (Furnkranz & Widmer, 1994) </ref> addresses this problem by pruning each individual rule right after it has been learned. This ensures that the algorithm can remove the training examples that are covered by the pruned rule before subsequent rules are learned.
Reference: <author> Georgeff, M. P., & Wallace, C. S. </author> <year> (1984). </year> <title> A general criterion for inductive inference. </title> <editor> In O'Shea, T. (Ed.), </editor> <booktitle> Proceedings of the Sixth European Conference on Artificial Intelligence (ECAI-84), </booktitle> <pages> pp. </pages> <address> 473-482 Amsterdam. </address> <publisher> Elsevier. </publisher>
Reference-contexts: Minimum Description Length: M DL (H) = I (H) + I (EjH) The minimum description length principle (Wallace & Boulton, 1968; Rissanen, 1978) has recently gained popularity in inductive learning as a heuristic that aims at finding a trade-off between the complexity and the accuracy of a hypothesis <ref> (Georgeff & Wallace, 1984) </ref>. It is defined as the amount of information needed to transmit a hypothesis H and the amount of information needed to transmit a set of examples E with the help of this hypothesis.
Reference: <author> Giordana, A., & Sale, C. </author> <year> (1992). </year> <title> Learning structured concepts using genetic algorithms. </title> <editor> In Sleeman, D., & Edwards, P. (Eds.), </editor> <booktitle> Proceedings of the 9th International Workshop on Machine Learning (ML-92), </booktitle> <pages> pp. </pages> <address> 169-178 Edinburgh. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: (Dzeroski & Bratko, 1992), SFOIL (Pompe et al., 1993), MILP (Kovacic, 1994b) HYDRA (Ali & Pazzani, 1993), CHAMP (Kijsirikul et al., 1991, 1992), FOSSIL (Furnkranz, 1994b), REP (Brunk & Pazzani, 1991), TDP (Furnkranz, 1994c), I-REP (Furnkranz & Widmer, 1994), I 2 -REP (Furnkranz, 1995), ML-SMART (Bergadano & Giordana, 1988), GA-SMART <ref> (Giordana & Sale, 1992) </ref>, SMART+ (Botta & Giordana, 1993), FOCL (Pazzani & Kibler, 1992), GRENDEL (Cohen, 1994), GOLEM (Muggleton & Feng, 1990), NINA (Ade et al., 1995), PROGOL (Muggleton, 1995) functional relations: FILP (Bergadano & Gunetti, 1993), FFOIL (Quinlan, 1996) regression rules: IBL-SMART (Widmer, 1993) RULE (Weiss & Indurkhya, 1993, 1995), <p> ML-SMART (Bergadano, Giordana, & Saitta, 1988) implements such a strategy with several coverage-based pruning heuristics that discard unpromising rules. In <ref> (Botta, Giordana, & Saitta, 1992) </ref> this approach has been shown to compare favorably to hill-climbing in an artificial domain. When no pruning heuristics are used (i.e., StoppingCriterion always returns false) the search space will be completely exhausted and it is guaranteed that an optimal solution will be found. <p> The best s rules are selected to form the next generation. This process is repeated until the best rule remains stable for a certain number of generations. A similar approach was used in GA-SMART for learning first-order rules in a top-down fashion <ref> (Giordana & Sale, 1992) </ref>. 4.2 Search Strategy An important decision that has to be made is in which direction the hypothesis space will be searched.
Reference: <author> Goldberg, D. E. </author> <year> (1989). </year> <title> Genetic Algorithms in Search, Optimization and Machine Learning. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA. </address>
Reference-contexts: A similar approach is implemented in the SFOIL algorithm (Pompe et al., 1993). Another family of stochastic separate-and-conquer rule learning algorithms choose a genetic algorithm <ref> (Goldberg, 1989) </ref> for finding good rules. One such system, SIA (Venturini, 1993), selects a random starting example and searches for a suitable generalization in a bottom-up fashion. It maintains a set of s candidate rules | a generation | which is initialized with random generalizations of the selected examples.
Reference: <author> Goodman, R. M., & Smyth, P. </author> <year> (1988). </year> <title> Information-theoretic rule induction. </title> <editor> In Kodratoff, Y. (Ed.), </editor> <booktitle> Proceedings of the 8th European Conference on Artificial Intelligence (ECAI-88), </booktitle> <pages> pp. </pages> <address> 357-362 London. </address> <publisher> Pitman. </publisher>
Reference-contexts: It has been used in the J-measure <ref> (Goodman & Smyth, 1988) </ref> and in the significance tests for rules used in CN2 (Clark & Niblett, 1989). Both will be discussed below. Laplace estimate: LAP (r) = p + n + 2 The Laplace estimate penalizes rules with low coverage. <p> The general form of weighted heuristics is the following: W H (r) = i=1 Some of the best-known weighted heuristics are: J-measure: J (r) = C (r)CE (r) The J-measure has first been described in <ref> (Goodman & Smyth, 1988) </ref> and later used in the stochastic search experiments of (Kononenko & Kovacic, 1992). <p> CWS (Domingos, 1996a) interleaves the induction of different rules by starting to induce the next rule in the same cycle as the second condition of the current rule is learned. ITRULE <ref> (Goodman & Smyth, 1988) </ref> performs an efficient exhaustive search for a fixed number of rule with a fixed maximum length.
Reference: <author> Hart, P. E., Nilsson, N. J., & Raphael, B. </author> <year> (1968). </year> <title> A formal basis for the heuristic determination of minimum cost paths. </title> <journal> IEEE Transactions on Systems Science and Cybernetics, </journal> <volume> 4 (2), </volume> <pages> 100-107. </pages>
Reference-contexts: When no pruning heuristics are used (i.e., StoppingCriterion always returns false) the search space will be completely exhausted and it is guaranteed that an optimal solution will be found. Nevertheless, the A* algorithm <ref> (Hart, Nilsson, & Raphael, 1968) </ref> allows to prune large portions of the search space without losing an optimal solution. This optimality can be guaranteed if the search heuristic is admissible.
Reference: <author> Helft, N. </author> <year> (1989). </year> <title> Induction as nonmonotonic inference. </title> <booktitle> In Proceedings of the 1st International Conference on Principles of Knowledge Representation and Reasoning, </booktitle> <pages> pp. 149-156. </pages>
Reference-contexts: FOIL allows the specification of a maximum variable number and a maximum variable depth 4 . It also makes sense to allow only linked literals, i.e. to literals that share variables with the head of the clause or with another linked literal <ref> (Helft, 1989) </ref>. Severe restrictions have to be used when learning recursive programs in order to avoid infinite recursions.
Reference: <author> Holte, R., Acker, L., & Porter, B. </author> <year> (1989). </year> <title> Concept learning and the problem of small disjuncts. </title> <booktitle> In Proceedings of the 11th International Joint Conference on Artificial Intelligence Detroit, </booktitle> <address> MI. </address>
Reference-contexts: First Cohen (1995) has shown that accuracy estimates for low-coverage rules will have a high variance and therefore I-REP is likely to stop prematurely and to overgeneralize in domains that are susceptible to the small disjuncts problem <ref> (Holte, Acker, & Porter, 1989) </ref>. Second, the accuracy-based pruning criterion used in I-REP basically optimizes the difference between the positive and negative examples covered by a rule. Cohen (1995) points out that this measure can lead to undesirable choices.
Reference: <author> Karalic, A. </author> <year> (1995). </year> <title> First Order Regression. </title> <type> Ph.D. thesis, </type> <institution> University of Ljubljana, Faculty of Electrical Engineering and Computer Science, Slovenia. </institution>
Reference-contexts: Sale, 1992), SMART+ (Botta & Giordana, 1993), FOCL (Pazzani & Kibler, 1992), GRENDEL (Cohen, 1994), GOLEM (Muggleton & Feng, 1990), NINA (Ade et al., 1995), PROGOL (Muggleton, 1995) functional relations: FILP (Bergadano & Gunetti, 1993), FFOIL (Quinlan, 1996) regression rules: IBL-SMART (Widmer, 1993) RULE (Weiss & Indurkhya, 1993, 1995), FORS <ref> (Karalic, 1995) </ref> 3 F urnkranz Given: * a target concept, * positive and negative examples * described with several features and * optional background knowledge Find: * a simple set of rules that discriminates between (unseen) positive and negative examples of the target concept There are various approaches for tackling this <p> A numeric prediction for a new example is then derived by finding a rule that covers the example and using the numeric class variables of all other examples covered by that rule for deriving a prediction. RULE (Weiss & Indurkhya, 1995) and FORS <ref> (Karalic, 1995) </ref> are able to directly use real-valued 34 Separate-and-Conquer Rule Learning class variables. They employ a top-down hill-climbing algorithm for finding a rule body that minimizes an error function (like the mean squared error) on the prediction of the covered examples.
Reference: <author> Kietz, J.-U., & Wrobel, S. </author> <year> (1992). </year> <title> Controlling the complexity of learning in logic through syntactic and task-oriented models. </title> <editor> In Muggleton, S. H. (Ed.), </editor> <booktitle> Inductive Logic Programming, chap. </booktitle> <volume> 16, </volume> <pages> pp. 335-359. </pages> <publisher> Academic Press Ltd., </publisher> <address> London. </address> <note> 40 Separate-and-Conquer Rule Learning Kijsirikul, </note> <author> B., Numao, M., & Shimura, M. </author> <year> (1991). </year> <title> Efficient learning of logic programs with non-determinate, non-discriminating literals. </title> <booktitle> In Proceedings of the 8th International Workshop on Machine Learning, </booktitle> <pages> pp. </pages> <address> 417-421 Evanston, Illinois. </address>
Reference-contexts: The task of the learner is to find the best rules defined by appropriate subsets of these clause sets. Similarly, the RDT rule learning system has expanded the relational cliches idea to modeling the entire hypothesis space instead of only certain conjunctions <ref> (Kietz & Wrobel, 1992) </ref>. Hierarchically organized predicate variables can be used for writing down rule models that can be instantiated by replacing all predicate variables in a rule models with a suitable predicate.
Reference: <author> Kijsirikul, B., Numao, M., & Shimura, M. </author> <year> (1992). </year> <title> Discrimination-based constructive induction of logic programs. </title> <booktitle> In Proceedings of the 10th National Conference on Artificial Intelligence, </booktitle> <pages> pp. 44-49. </pages>
Reference-contexts: A few other approaches that directly invoke constructive induction operators during the learning process have been developed in inductive logic programming. In this context constructive induction is often called predicate invention, as it is not concerned with the construction of new features, but of new predicates. CHAMP <ref> (Kijsirikul et al., 1992) </ref> reverts to inventing a new predicate whenever the top-down first-order separate-and-conquer learner CHAM (Kijsirikul et al., 1991) cannot complete the current clause by appending a literal from the background knowledge without excluding all positive examples or without exceeding a certain clause length. 6 In that case CHAMP
Reference: <author> Kirkpatrick, S., Gelatt, C., & Vecchi, M. </author> <year> (1983). </year> <title> Optimization by simulated annealing. </title> <journal> Science, </journal> <volume> 220, </volume> <pages> 671-680. </pages>
Reference-contexts: The probability with which suboptimal rules are selected may also decrease over time so that the algorithm will eventually stabilize (simulated annealing <ref> (Kirkpatrick, Gelatt, & Vecchi, 1983) </ref>). Kononenko and Kovacic (1992) and Mladenic (1993) present and compare a variety of such algorithms, ranging from an entirely random search to an approach based on Markovian neural networks (Kovacic, 1991). The latter algorithm has later been generalized into a first-order framework (Kovacic, 1994b).
Reference: <author> Kohavi, R. </author> <year> (1995). </year> <title> Wrappers for Performance Enhancement and Oblivious Decision Graphs. </title> <type> Ph.D. thesis, </type> <institution> Stanford University, Dept. of Computer Science. </institution>
Reference: <author> Kohavi, R., & John, G. H. </author> <year> (1995). </year> <title> Automatic parameter selection by minimizing estimated error. </title> <editor> In Prieditis, A., & Russell, S. (Eds.), </editor> <booktitle> Proceedings of the 12th International Conference on Machine Learning (ICML-95). </booktitle> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Kononenko, I., & Kovacic, M. </author> <year> (1992). </year> <title> Learning as optimization: Stochastic generation of multiple knowledge. </title> <editor> In Sleeman, D., & Edwards, P. (Eds.), </editor> <booktitle> Proceedings of the 9th International Workshop on Machine Learning (ML-92), </booktitle> <pages> pp. 257-262. </pages> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: The ATRIS rule learning shell (Mladenic, 1993) allows to perform a similar bidirectional search, but replaces JoJo's hill-climbing search with less myopic stochastic search procedures as in <ref> (Kononenko & Kovacic, 1992) </ref> or a generalized hill-climbing that allows to perform a fixed number of refinement operations at a time. 4.3 Search Heuristics The most influential bias is the search heuristic, which estimates the quality of rules found in the search space and ideally guides the search algorithms into the <p> The general form of weighted heuristics is the following: W H (r) = i=1 Some of the best-known weighted heuristics are: J-measure: J (r) = C (r)CE (r) The J-measure has first been described in (Goodman & Smyth, 1988) and later used in the stochastic search experiments of <ref> (Kononenko & Kovacic, 1992) </ref>.
Reference: <author> Kovacic, M. </author> <year> (1991). </year> <title> Markovian neural networks. </title> <journal> Biological Cybernetics, </journal> <volume> 64, </volume> <pages> 337-342. </pages>
Reference-contexts: Kononenko and Kovacic (1992) and Mladenic (1993) present and compare a variety of such algorithms, ranging from an entirely random search to an approach based on Markovian neural networks <ref> (Kovacic, 1991) </ref>. The latter algorithm has later been generalized into a first-order framework (Kovacic, 1994b). The resulting system, MILP performs a stochastic hill-climbing search with simulated annealing.
Reference: <author> Kovacic, M. </author> <year> (1994a). </year> <title> MDL-heuristics in ILP revised. </title> <booktitle> In Proceedings of the ML-COLT-94 Workshop on Applications of Descriptional Complexity to Inductive, Statistical, and Visual Inference. </booktitle>
Reference-contexts: The goal is to minimize this measure. Unfortunately, both terms are not computable and have to be approximated. For various computable approximations for rule learning we refer to <ref> (Kovacic, 1994a, 1994b) </ref> and (Pfahringer, 1995a, 1995b). FOIL (Quinlan, 1990) uses a variant of the MDL principle as a stopping criterion (see section 5.1).
Reference: <author> Kovacic, M. </author> <year> (1994b). </year> <title> Stochastic Inductive Logic Programming. </title> <type> Ph.D. thesis, </type> <institution> Department of Computer and Information Science, University of Ljubljana. </institution>
Reference-contexts: & Niblett, 1989; Clark & Boswell, 1991), CN2-MCI (Kramer, 1994) GREEDY3 (Pagallo & Haussler, 1990), PREPEND (Webb & Brkic, 1993; Webb, 1994), FOIDL (Mooney & Califf, 1995) logic programs: INDUCE (Michalski, 1980), FOIL (Quinlan, 1990; Quinlan & Cameron-Jones, 1995a), mFOIL (Dzeroski & Bratko, 1992), SFOIL (Pompe et al., 1993), MILP <ref> (Kovacic, 1994b) </ref> HYDRA (Ali & Pazzani, 1993), CHAMP (Kijsirikul et al., 1991, 1992), FOSSIL (Furnkranz, 1994b), REP (Brunk & Pazzani, 1991), TDP (Furnkranz, 1994c), I-REP (Furnkranz & Widmer, 1994), I 2 -REP (Furnkranz, 1995), ML-SMART (Bergadano & Giordana, 1988), GA-SMART (Giordana & Sale, 1992), SMART+ (Botta & Giordana, 1993), FOCL (Pazzani <p> Kononenko and Kovacic (1992) and Mladenic (1993) present and compare a variety of such algorithms, ranging from an entirely random search to an approach based on Markovian neural networks (Kovacic, 1991). The latter algorithm has later been generalized into a first-order framework <ref> (Kovacic, 1994b) </ref>. The resulting system, MILP performs a stochastic hill-climbing search with simulated annealing. Whenever it reaches a local optimum, it backtracks to a previous rule, whose successors have not yet been examined, in order to get a new starting point.
Reference: <author> Kramer, S. </author> <year> (1994). </year> <title> CN2-MCI: A two-step method for constructive induction. </title> <booktitle> In Proceedings of the ML-COLT-94 Workshop on Constructive Induction and Change of Representation. </booktitle>
Reference-contexts: 1994b) DLG (Webb, 1992; Webb & Agar, 1992), CLASS (Webb, 1993), SIA (Venturini, 1993) GROW (Cohen, 1993), RIPPER (Cohen, 1995), BEXA (Theron & Cloete, 1996) CNF: PFOIL-CNF (Mooney, 1995), ICL (De Raedt & Van Laer, 1995) decision lists: (Rivest, 1987), CN2 (Clark & Niblett, 1989; Clark & Boswell, 1991), CN2-MCI <ref> (Kramer, 1994) </ref> GREEDY3 (Pagallo & Haussler, 1990), PREPEND (Webb & Brkic, 1993; Webb, 1994), FOIDL (Mooney & Califf, 1995) logic programs: INDUCE (Michalski, 1980), FOIL (Quinlan, 1990; Quinlan & Cameron-Jones, 1995a), mFOIL (Dzeroski & Bratko, 1992), SFOIL (Pompe et al., 1993), MILP (Kovacic, 1994b) HYDRA (Ali & Pazzani, 1993), CHAMP (Kijsirikul <p> Similar ideas are implemented in CiPF (Pfahringer, 1994a, 1994b) which uses a propositional top-down separate-and-conquer algorithm as the basic induction module and in CN2-MCI <ref> (Kramer, 1994) </ref> which introduces a new powerful constructive induction operator for CN2-like algorithms. This operator constructs a new attribute from the cross-product of attributes that often occur together in different rules.
Reference: <author> Kramer, S. </author> <year> (1996). </year> <title> Structural regression trees. </title> <booktitle> In Proceedings of the 13th National Conference on Artificial Intelligence (AAAI-96), </booktitle> <pages> pp. 812-819. </pages> <publisher> AAAI Press. </publisher>
Reference: <author> Langley, P., Simon, H. A., & Bradshaw, G. L. </author> <year> (1987). </year> <title> Heuristics for empirical discovery. </title>
Reference-contexts: Michalski, 1991) | and to some extend AQ15 (Michalski et al., 1986) | can compute equality and inequality relations, use addition and multiplication operators, and can determine optima, 14 Separate-and-Conquer Rule Learning averages and frequencies in sets of features, reminiscent of some ideas previously used in the BACON discovery system <ref> (Langley, Simon, & Bradshaw, 1987) </ref>. The generated attributes are then evaluated with an attribute quality function which basically computes the number of attribute values that only occur in instances of single target classes.
Reference: <editor> In Bolc, L. (Ed.), </editor> <booktitle> Computational Models of Learning. </booktitle> <publisher> Springer-Verlag. </publisher> <editor> Reprinted in J.W. Shavlik and T.G. Dietterich (eds.), </editor> <booktitle> Readings in Machine Learning, </booktitle> <publisher> Morgan Kaufmann, </publisher> <year> 1991. </year>
Reference-contexts: Thus we feel that a separate treatment of these two issues is justified. 2 Separate-and-Conquer Rule Learning propositional rule sets (DNF): AQ (Michalski, 1969), AQ15 (Michalski et al., 1986), AQ17 (Bloedorn & Michalski, 1991; Wnek & Michalski, 1994; Bloedorn et al., 1993) PRISM (Cendrowska, 1987), SWAP-1 <ref> (Weiss & Indurkhya, 1991) </ref>, POSEIDON (Bergadano et al., 1992), PFOIL (Mooney, 1995), JoJo (Fensel & Wiese, 1993; Wiese, 1996) ATRIS (Kononenko & Kovacic, 1992; Mladenic, 1993) CiPF (Pfahringer, 1994a, 1994b) DLG (Webb, 1992; Webb & Agar, 1992), CLASS (Webb, 1993), SIA (Venturini, 1993) GROW (Cohen, 1993), RIPPER (Cohen, 1995), BEXA (Theron <p> A similar idea has been explored further in <ref> (Silverstein & Pazzani, 1991) </ref>. Relational cliches are conjunctions of the type explained above with the difference that the predicate does not have to be exactly specified. Instead the user can provide a place-holder that stands for a certain class of predicates. <p> A definition for the invented predicate is then induced from these examples by recursively calling CHAMP with the invented predicate as the target predicate. A very similar approach | called closed-world specialization | is taken in <ref> (Bain, 1991) </ref> and (Srinivasan, Muggleton, & Bain, 1992). Here over-general clauses learned by the bottom-up first-order separate-and-conquer learner GOLEM (Muggleton & Feng, 1990) are specialized by adding a negated new predicate. <p> This measure will attain its optimal value when no negative examples are covered. However, it does not aim at covering many positive examples. It is used in the GREEDY3 (Pagallo & Haussler, 1990) and SWAP-1 <ref> (Weiss & Indurkhya, 1991) </ref> algorithms. Information content: IC (r) = log p + n Sometimes the logarithm of the rule's purity is used, which measures the amount of information contained in the classification of the covered examples. This estimate is essentially used in PRISM (Cendrowska, 1987). <p> In this case the counting-instances and counting-proofs methods discussed at the beginning of this section produce identical results. In FOIL such determinate literals are added to the body of the rule when no other condition is given a high evaluation by the search heuristic <ref> (Quinlan, 1991) </ref>. This is necessary, because determinate literals usually have a low heuristic evaluation, because they will typically have a valid ground instantiation for all positive and negative training examples. <p> Other algorithms employ additional simplification operators like deleting each condition of a rule (Furnkranz & Widmer, 1994), deleting a final sequence of conditions (Cohen, 1993), finding the best replacement for a condition <ref> (Weiss & Indurkhya, 1991) </ref>, and extending and contracting internal disjunctions and intervals (Bergadano et al., 1992). If the accuracy of the best simplification is not below the accuracy of the unpruned theory, REP will continue to prune the new theory.
Reference: <author> Lavrac, N., Dzeroski, S., & Grobelnik, M. </author> <year> (1991). </year> <title> Learning nonrecursive definitions of relations with LINUS. </title> <booktitle> In Proceedings of the 5th European Working Session on Learning (EWSL-91), </booktitle> <pages> pp. 265-281 Porto, </pages> <address> Portugal. </address> <publisher> Springer-Verlag. </publisher>
Reference: <author> Lloyd, J. W. </author> <year> (1987). </year> <title> Foundations of Logic Programming (2nd, extended edition). </title> <publisher> Springer-Verlag, </publisher> <address> Berlin. 41 F urnkranz Matheus, C. J. </address> <year> (1989). </year> <title> A constructive induction framework. </title> <booktitle> In Proceedings of the 6th International Workshop on Machine Learning, </booktitle> <pages> pp. 474-475. </pages>
Reference-contexts: Rules are often called (definite) clauses in logic programming terminology. In the remainder of this paper we will use these terms interchangeably. In general we will follow the logic programming terminology defined in <ref> (Lloyd, 1987) </ref>. 9 F urnkranz 3.1 Static Language Bias There is a wide variety of condition types that can be made available for a classification learning algorithm.
Reference: <author> Michalski, R. S., Mozetic, I., Hong, J., & Lavrac, N. </author> <year> (1986). </year> <title> The multi-purpose incremental learning system AQ15 and its testing application to three medical domains. </title> <booktitle> In Proceedings of the 5th National Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 1041-1045 Philadelphia, PA. </address>
Reference-contexts: However, in particular in the context of separate-and-conquer rule learning, there are often two separate criteria for growing and simplifying hypotheses. Thus we feel that a separate treatment of these two issues is justified. 2 Separate-and-Conquer Rule Learning propositional rule sets (DNF): AQ (Michalski, 1969), AQ15 <ref> (Michalski et al., 1986) </ref>, AQ17 (Bloedorn & Michalski, 1991; Wnek & Michalski, 1994; Bloedorn et al., 1993) PRISM (Cendrowska, 1987), SWAP-1 (Weiss & Indurkhya, 1991), POSEIDON (Bergadano et al., 1992), PFOIL (Mooney, 1995), JoJo (Fensel & Wiese, 1993; Wiese, 1996) ATRIS (Kononenko & Kovacic, 1992; Mladenic, 1993) CiPF (Pfahringer, 1994a, 1994b) <p> This method is used in HYDRA (Ali & Pazzani, 1993) where the ls-content of a rule (see section 4.3) is used as a weighting heuristic. In AQ-15 <ref> (Michalski et al., 1986) </ref> each rule is weighted by the percentage of positive examples in the set of examples covered by it. The weights of rules of the same class are combined to a weight for the entire class and the class with the highest weight will be returned. <p> The simplest approach to constructive induction with separate-and-conquer learning algorithms is to apply a predefined set of arithmetic and logical operators to certain attributes and compute new attributes from them. For example AQ17-DCI (Bloedorn & Michalski, 1991) | and to some extend AQ15 <ref> (Michalski et al., 1986) </ref> | can compute equality and inequality relations, use addition and multiplication operators, and can determine optima, 14 Separate-and-Conquer Rule Learning averages and frequencies in sets of features, reminiscent of some ideas previously used in the BACON discovery system (Langley, Simon, & Bradshaw, 1987). <p> The prototypical system for this approach is the AQ17-HCI algorithm (Wnek & Michalski, 1994), which incorporates several constructive induction operators based on ideas used earlier in the INDUCE system (Michalski, 1980). AQ17-HCI scans the rules generated by the AQ15 induction algorithm <ref> (Michalski et al., 1986) </ref> for patterns of co-occurring values of a single attributes, co-occurring conjunctions, or even subsets of the induced rule set that have a high pattern strength. <p> Setting b = 1 will yield hill-climbing again. Beam search effectively maintains hill-climbing's efficiency (reduced by a constant factor), but can yield better results because it explores a larger portion of the hypothesis space. Thus many separate-and-conquer algorithms use beam search in their FindBestRule procedures. Among them are AQ <ref> (Michalski et al., 1986) </ref>, CN2 (Clark & Niblett, 1989), mFOIL (Dzeroski & Bratko, 1992), and BEXA (Theron & Cloete, 1996). <p> A commonly used post-processing technique aims at removing redundant conditions from the body of a rule and removing unnecessary rules from the concept. The latter technique has already been used in various versions of the AQ algorithm <ref> (Michalski et al., 1986) </ref>. The basic idea is to test whether the removal of a single condition or even of an entire rule would lead to a decrease in the quality of the concept description, usually measured in terms of classification accuracy on the training set. <p> If this is not the case, the condition or rule will be removed. This framework has later been generalized in the POSEIDON system (Bergadano et al., 1992). POSEIDON can simplify a complete and consistent concept description, which has been induced by AQ15 <ref> (Michalski et al., 1986) </ref>, by removing conditions and rules and by 9.
Reference: <author> Michalski, R. S. </author> <year> (1969). </year> <title> On the quasi-minimal solution of the covering problem. </title> <booktitle> In Proceedings of the 5th International Symposium on Information Processing (FCIP-69), Vol. A3 (Switching Circuits), </booktitle> <pages> pp. </pages> <address> 125-128 Bled, Yugoslavia. </address>
Reference-contexts: The Separate-and-Conquer Strategy The separate-and-conquer strategy has its origins in the AQ family of algorithms <ref> (Michalski, 1969) </ref> under the name covering strategy. <p> However, in particular in the context of separate-and-conquer rule learning, there are often two separate criteria for growing and simplifying hypotheses. Thus we feel that a separate treatment of these two issues is justified. 2 Separate-and-Conquer Rule Learning propositional rule sets (DNF): AQ <ref> (Michalski, 1969) </ref>, AQ15 (Michalski et al., 1986), AQ17 (Bloedorn & Michalski, 1991; Wnek & Michalski, 1994; Bloedorn et al., 1993) PRISM (Cendrowska, 1987), SWAP-1 (Weiss & Indurkhya, 1991), POSEIDON (Bergadano et al., 1992), PFOIL (Mooney, 1995), JoJo (Fensel & Wiese, 1993; Wiese, 1996) ATRIS (Kononenko & Kovacic, 1992; Mladenic, 1993) CiPF
Reference: <author> Michalski, R. S. </author> <year> (1973). </year> <title> AQVAL/1 | computer implementation of a variable-valued logic system VL 1 and examples of its application to pattern recognition. </title> <booktitle> In Proceedings of the 1st International Joint Conference on Pattern Recognition, </booktitle> <pages> pp. 3-17. </pages>
Reference: <author> Michalski, R. S. </author> <year> (1980). </year> <title> Pattern recognition and rule-guided inference. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 2, </volume> <pages> 349-361. </pages>
Reference-contexts: & Cloete, 1996) CNF: PFOIL-CNF (Mooney, 1995), ICL (De Raedt & Van Laer, 1995) decision lists: (Rivest, 1987), CN2 (Clark & Niblett, 1989; Clark & Boswell, 1991), CN2-MCI (Kramer, 1994) GREEDY3 (Pagallo & Haussler, 1990), PREPEND (Webb & Brkic, 1993; Webb, 1994), FOIDL (Mooney & Califf, 1995) logic programs: INDUCE <ref> (Michalski, 1980) </ref>, FOIL (Quinlan, 1990; Quinlan & Cameron-Jones, 1995a), mFOIL (Dzeroski & Bratko, 1992), SFOIL (Pompe et al., 1993), MILP (Kovacic, 1994b) HYDRA (Ali & Pazzani, 1993), CHAMP (Kijsirikul et al., 1991, 1992), FOSSIL (Furnkranz, 1994b), REP (Brunk & Pazzani, 1991), TDP (Furnkranz, 1994c), I-REP (Furnkranz & Widmer, 1994), I 2 <p> Moreover, they can also make use of tree-structured attributes. A description of these extensions can be found in <ref> (Michalski, 1980) </ref>. 3.1.2 Literals Research in inductive logic programming (ILP), in particular on FOIL and related systems (Quinlan & Cameron-Jones, 1995a), has produced algorithms for solving classification problems in first-order logic. <p> The prototypical system for this approach is the AQ17-HCI algorithm (Wnek & Michalski, 1994), which incorporates several constructive induction operators based on ideas used earlier in the INDUCE system <ref> (Michalski, 1980) </ref>. AQ17-HCI scans the rules generated by the AQ15 induction algorithm (Michalski et al., 1986) for patterns of co-occurring values of a single attributes, co-occurring conjunctions, or even subsets of the induced rule set that have a high pattern strength.
Reference: <author> Michalski, R. S. </author> <year> (1983). </year> <title> A theory and methodology of inductive learning. </title> <journal> Artificial Intelligence, </journal> <volume> 20 (2), </volume> <pages> 111-162. </pages>
Reference-contexts: Lexicographic evaluation functionals (lef s) <ref> (Michalski, 1983) </ref> are a general mechanism for using a hierarchy of evaluation functions. A lef is an ordered set of pairs (H i (r); t i ), where the H i are heuristic functions and the t i 2 [0 : : : 1] are tolerance thresholds.
Reference: <author> Mingers, J. </author> <year> (1989). </year> <title> An empirical comparison of selection measures for decision-tree induction. </title> <journal> Machine Learning, </journal> <volume> 3, </volume> <pages> 319-342. </pages>
Reference: <author> Mitchell, T. M. </author> <year> (1980). </year> <title> The need for biases in learning generalizations. </title> <type> Tech. rep., </type> <institution> Computer Science Department, Rutgers University, </institution> <address> New Brunswick, MA. </address> <note> Reprinted in J.W. </note> <editor> Shavlik and T.G. Dietterich (eds.), </editor> <booktitle> Readings in Machine Learning, </booktitle> <publisher> Morgan Kaufmann, </publisher> <year> 1991. </year>
Reference-contexts: Language Bias Before the user invokes a certain learning algorithms he already has to make a choice of a suitable representation language for the hypotheses to learn. This choice naturally has a considerable influence on the result of the learning procedure <ref> (Mitchell, 1980) </ref>.
Reference: <author> Mitchell, T. M. </author> <year> (1982). </year> <title> Generalization as search. </title> <journal> Artificial Intelligence, </journal> <volume> 18 (2), </volume> <pages> 203-226. </pages>
Reference-contexts: Rules can be organized into a generality lattice, the so-called version space <ref> (Mitchell, 1982) </ref>, where rule A is considered to be more general than rule B iff A covers all instances that are covered by B. B is then said to be more specific than A.
Reference: <author> Mladenic, D. </author> <year> (1993). </year> <title> Combinatorial optimization in inductive concept learning. </title> <booktitle> In Proceedings of the 10th International Conference on Machine Learning (ML-93), </booktitle> <pages> pp. 205-211. </pages> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: A simple technique for decreasing search myopia in hill-climbing is to look further ahead. This can be done by choosing the best rule resulting from performing n refinement steps at once instead of only 1. This approach has been implemented in the ATRIS rule learning shell <ref> (Mladenic, 1993) </ref>. Its major deficiency is its inefficiency, as the search space for each refinement step grows exponentially with n. 4.1.2 Beam Search Many algorithms try to alleviate the myopic behavior of hill-climbing by using beam search. <p> Recent additions allow the system to directly replace conditions in rules (Fensel & Wiese, 1994) and to use general first-order literals (Wiese, 1996). The ATRIS rule learning shell <ref> (Mladenic, 1993) </ref> allows to perform a similar bidirectional search, but replaces JoJo's hill-climbing search with less myopic stochastic search procedures as in (Kononenko & Kovacic, 1992) or a generalized hill-climbing that allows to perform a fixed number of refinement operations at a time. 4.3 Search Heuristics The most influential bias is
Reference: <author> Mooney, R. J. </author> <year> (1995). </year> <title> Encouraging experimental results on learning CNF. </title> <journal> Machine Learning, </journal> <volume> 19, </volume> <pages> 79-92. </pages>
Reference-contexts: treatment of these two issues is justified. 2 Separate-and-Conquer Rule Learning propositional rule sets (DNF): AQ (Michalski, 1969), AQ15 (Michalski et al., 1986), AQ17 (Bloedorn & Michalski, 1991; Wnek & Michalski, 1994; Bloedorn et al., 1993) PRISM (Cendrowska, 1987), SWAP-1 (Weiss & Indurkhya, 1991), POSEIDON (Bergadano et al., 1992), PFOIL <ref> (Mooney, 1995) </ref>, JoJo (Fensel & Wiese, 1993; Wiese, 1996) ATRIS (Kononenko & Kovacic, 1992; Mladenic, 1993) CiPF (Pfahringer, 1994a, 1994b) DLG (Webb, 1992; Webb & Agar, 1992), CLASS (Webb, 1993), SIA (Venturini, 1993) GROW (Cohen, 1993), RIPPER (Cohen, 1995), BEXA (Theron & Cloete, 1996) CNF: PFOIL-CNF (Mooney, 1995), ICL (De Raedt <p> et al., 1992), PFOIL <ref> (Mooney, 1995) </ref>, JoJo (Fensel & Wiese, 1993; Wiese, 1996) ATRIS (Kononenko & Kovacic, 1992; Mladenic, 1993) CiPF (Pfahringer, 1994a, 1994b) DLG (Webb, 1992; Webb & Agar, 1992), CLASS (Webb, 1993), SIA (Venturini, 1993) GROW (Cohen, 1993), RIPPER (Cohen, 1995), BEXA (Theron & Cloete, 1996) CNF: PFOIL-CNF (Mooney, 1995), ICL (De Raedt & Van Laer, 1995) decision lists: (Rivest, 1987), CN2 (Clark & Niblett, 1989; Clark & Boswell, 1991), CN2-MCI (Kramer, 1994) GREEDY3 (Pagallo & Haussler, 1990), PREPEND (Webb & Brkic, 1993; Webb, 1994), FOIDL (Mooney & Califf, 1995) logic programs: INDUCE (Michalski, 1980), FOIL (Quinlan, 1990; Quinlan <p> (Cohen, 1993), RIPPER (Cohen, 1995), BEXA (Theron & Cloete, 1996) CNF: PFOIL-CNF (Mooney, 1995), ICL (De Raedt & Van Laer, 1995) decision lists: (Rivest, 1987), CN2 (Clark & Niblett, 1989; Clark & Boswell, 1991), CN2-MCI (Kramer, 1994) GREEDY3 (Pagallo & Haussler, 1990), PREPEND (Webb & Brkic, 1993; Webb, 1994), FOIDL <ref> (Mooney & Califf, 1995) </ref> logic programs: INDUCE (Michalski, 1980), FOIL (Quinlan, 1990; Quinlan & Cameron-Jones, 1995a), mFOIL (Dzeroski & Bratko, 1992), SFOIL (Pompe et al., 1993), MILP (Kovacic, 1994b) HYDRA (Ali & Pazzani, 1993), CHAMP (Kijsirikul et al., 1991, 1992), FOSSIL (Furnkranz, 1994b), REP (Brunk & Pazzani, 1991), TDP (Furnkranz, 1994c), <p> Theories that impose a fixed evaluation order on their rules are commonly referred to as decision lists (Rivest, 1987). They can be viewed as a PROLOG program where each rule ends with a cut (!) <ref> (Mooney & Califf, 1995) </ref>. CN2 (Clark & Niblett, 1989) is able to handle multi-class problems using an evaluation function that gives preference to class distributions where examples of one class dominate (see section 4.3). Each learned rule will predict the class that is dominant among the examples it covers. <p> Placing this simple general rule near the end of the rule list allows to handle these exceptions with rules that 8 Separate-and-Conquer Rule Learning are placed before the general rule and keep the general rule simple. This hypothesis has been empirically confirmed in (Webb, 1994) and <ref> (Mooney & Califf, 1995) </ref>. Another method for inducing multi-class concepts is to learn a separate concept description for each class taking all examples of other classes as negative examples for the class to learn.
Reference: <author> Mooney, R. J., & Califf, M. E. </author> <year> (1995). </year> <title> Induction of first-order decision lists: Results on learning the past tense of english verbs. </title> <journal> Journal of Artificial Intelligence Research, </journal> <volume> 3, </volume> <pages> 1-24. </pages>
Reference-contexts: treatment of these two issues is justified. 2 Separate-and-Conquer Rule Learning propositional rule sets (DNF): AQ (Michalski, 1969), AQ15 (Michalski et al., 1986), AQ17 (Bloedorn & Michalski, 1991; Wnek & Michalski, 1994; Bloedorn et al., 1993) PRISM (Cendrowska, 1987), SWAP-1 (Weiss & Indurkhya, 1991), POSEIDON (Bergadano et al., 1992), PFOIL <ref> (Mooney, 1995) </ref>, JoJo (Fensel & Wiese, 1993; Wiese, 1996) ATRIS (Kononenko & Kovacic, 1992; Mladenic, 1993) CiPF (Pfahringer, 1994a, 1994b) DLG (Webb, 1992; Webb & Agar, 1992), CLASS (Webb, 1993), SIA (Venturini, 1993) GROW (Cohen, 1993), RIPPER (Cohen, 1995), BEXA (Theron & Cloete, 1996) CNF: PFOIL-CNF (Mooney, 1995), ICL (De Raedt <p> et al., 1992), PFOIL <ref> (Mooney, 1995) </ref>, JoJo (Fensel & Wiese, 1993; Wiese, 1996) ATRIS (Kononenko & Kovacic, 1992; Mladenic, 1993) CiPF (Pfahringer, 1994a, 1994b) DLG (Webb, 1992; Webb & Agar, 1992), CLASS (Webb, 1993), SIA (Venturini, 1993) GROW (Cohen, 1993), RIPPER (Cohen, 1995), BEXA (Theron & Cloete, 1996) CNF: PFOIL-CNF (Mooney, 1995), ICL (De Raedt & Van Laer, 1995) decision lists: (Rivest, 1987), CN2 (Clark & Niblett, 1989; Clark & Boswell, 1991), CN2-MCI (Kramer, 1994) GREEDY3 (Pagallo & Haussler, 1990), PREPEND (Webb & Brkic, 1993; Webb, 1994), FOIDL (Mooney & Califf, 1995) logic programs: INDUCE (Michalski, 1980), FOIL (Quinlan, 1990; Quinlan <p> (Cohen, 1993), RIPPER (Cohen, 1995), BEXA (Theron & Cloete, 1996) CNF: PFOIL-CNF (Mooney, 1995), ICL (De Raedt & Van Laer, 1995) decision lists: (Rivest, 1987), CN2 (Clark & Niblett, 1989; Clark & Boswell, 1991), CN2-MCI (Kramer, 1994) GREEDY3 (Pagallo & Haussler, 1990), PREPEND (Webb & Brkic, 1993; Webb, 1994), FOIDL <ref> (Mooney & Califf, 1995) </ref> logic programs: INDUCE (Michalski, 1980), FOIL (Quinlan, 1990; Quinlan & Cameron-Jones, 1995a), mFOIL (Dzeroski & Bratko, 1992), SFOIL (Pompe et al., 1993), MILP (Kovacic, 1994b) HYDRA (Ali & Pazzani, 1993), CHAMP (Kijsirikul et al., 1991, 1992), FOSSIL (Furnkranz, 1994b), REP (Brunk & Pazzani, 1991), TDP (Furnkranz, 1994c), <p> Theories that impose a fixed evaluation order on their rules are commonly referred to as decision lists (Rivest, 1987). They can be viewed as a PROLOG program where each rule ends with a cut (!) <ref> (Mooney & Califf, 1995) </ref>. CN2 (Clark & Niblett, 1989) is able to handle multi-class problems using an evaluation function that gives preference to class distributions where examples of one class dominate (see section 4.3). Each learned rule will predict the class that is dominant among the examples it covers. <p> Placing this simple general rule near the end of the rule list allows to handle these exceptions with rules that 8 Separate-and-Conquer Rule Learning are placed before the general rule and keep the general rule simple. This hypothesis has been empirically confirmed in (Webb, 1994) and <ref> (Mooney & Califf, 1995) </ref>. Another method for inducing multi-class concepts is to learn a separate concept description for each class taking all examples of other classes as negative examples for the class to learn.
Reference: <author> Muggleton, S., Bain, M., Hayes-Michie, J., & Michie, D. </author> <year> (1989). </year> <title> An experimental comparison of human and machine learning formalisms. </title> <booktitle> In Proceedings of the 6th International Workshop on Machine Learning, </booktitle> <pages> pp. 113-118. </pages>
Reference-contexts: These (or their negations) can then be used as additional conditions in the final rules. A typical example is the king-rook-king (KRK) chess endgame learning task <ref> (Muggleton et al., 1989) </ref> that has developed into a standard benchmark problem for ILP algorithms. The goal concept is to recognize illegal white-to-move positions in this endgame. These can be positions where two or more pieces are on the same square or positions where the black king is in check. <p> The target predicate is illegal (WKF,WKR,WRF,WRR,BKF,BKR) where the six arguments specify the file and the row coordinates of the squares of the three pieces. Using only selectors no 10 Separate-and-Conquer Rule Learning meaningful concept representation can be learned from this task <ref> (Muggleton et al., 1989) </ref>. However, if additional background relations like adjacent/2, &lt;/2, or =/2 can be used as possible conditions, the final rules are able to check whether two pieces are on the same file or rank, on adjacent squares etc.
Reference: <author> Muggleton, S. H. (Ed.). </author> <year> (1992). </year> <title> Inductive Logic Programming. </title> <publisher> Academic Press Ltd., </publisher> <month> Lon-don. </month> <title> 42 Separate-and-Conquer Rule Learning Muggleton, </title> <editor> S. H. </editor> <year> (1995). </year> <title> Inverse entailment and Progol. </title> <journal> New Generation Computing, </journal> <volume> 13 (3,4), </volume> <pages> 245-286. </pages> <note> Special Issue on Inductive Logic Programming. </note>
Reference-contexts: A definition for the invented predicate is then induced from these examples by recursively calling CHAMP with the invented predicate as the target predicate. A very similar approach | called closed-world specialization | is taken in (Bain, 1991) and <ref> (Srinivasan, Muggleton, & Bain, 1992) </ref>. Here over-general clauses learned by the bottom-up first-order separate-and-conquer learner GOLEM (Muggleton & Feng, 1990) are specialized by adding a negated new predicate.
Reference: <author> Muggleton, S. H., & Feng, C. </author> <year> (1990). </year> <title> Efficient induction of logic programs. </title> <booktitle> In Proceedings of the 1st Conference on Algorithmic Learning Theory, </booktitle> <pages> pp. </pages> <address> 1-14 Tokyo, Japan. </address>
Reference-contexts: (Kijsirikul et al., 1991, 1992), FOSSIL (Furnkranz, 1994b), REP (Brunk & Pazzani, 1991), TDP (Furnkranz, 1994c), I-REP (Furnkranz & Widmer, 1994), I 2 -REP (Furnkranz, 1995), ML-SMART (Bergadano & Giordana, 1988), GA-SMART (Giordana & Sale, 1992), SMART+ (Botta & Giordana, 1993), FOCL (Pazzani & Kibler, 1992), GRENDEL (Cohen, 1994), GOLEM <ref> (Muggleton & Feng, 1990) </ref>, NINA (Ade et al., 1995), PROGOL (Muggleton, 1995) functional relations: FILP (Bergadano & Gunetti, 1993), FFOIL (Quinlan, 1996) regression rules: IBL-SMART (Widmer, 1993) RULE (Weiss & Indurkhya, 1993, 1995), FORS (Karalic, 1995) 3 F urnkranz Given: * a target concept, * positive and negative examples * described <p> A very similar approach | called closed-world specialization | is taken in (Bain, 1991) and (Srinivasan, Muggleton, & Bain, 1992). Here over-general clauses learned by the bottom-up first-order separate-and-conquer learner GOLEM <ref> (Muggleton & Feng, 1990) </ref> are specialized by adding a negated new predicate. The intuition behind this approach is that the original rule will already cover more positive than negative examples and the new predicate will only be used for denoting the few exceptions to the rule. <p> NINA (Ade et al., 1995) is a bottom-up first-order separate-and-conquer algorithm that unifies several bottom-up ILP algorithms such as GOLEM <ref> (Muggleton & Feng, 1990) </ref>, ITOU (Rouveirol, 1992), and CLINT (De Raedt, 1992). <p> In their special case where t i = 1 lef s are often used for breaking ties. PRISM (Cendrowska, 1987) for example evaluates rules with a variant of the information content heuristic and breaks ties using positive coverage. 4.3.6 Determinate Literals Several inductive logic programming algorithms, like GOLEM <ref> (Muggleton & Feng, 1990) </ref>, restrict the conditions that may be used in the body of a rule to determinate literals, i.e. to literals that have at most one valid ground substitution for each combination of input variables.
Reference: <author> Pagallo, G., & Haussler, D. </author> <year> (1990). </year> <title> Boolean feature discovery in empirical learning. </title> <journal> Machine Learning, </journal> <volume> 5, </volume> <pages> 71-99. </pages>
Reference-contexts: 1992; Webb & Agar, 1992), CLASS (Webb, 1993), SIA (Venturini, 1993) GROW (Cohen, 1993), RIPPER (Cohen, 1995), BEXA (Theron & Cloete, 1996) CNF: PFOIL-CNF (Mooney, 1995), ICL (De Raedt & Van Laer, 1995) decision lists: (Rivest, 1987), CN2 (Clark & Niblett, 1989; Clark & Boswell, 1991), CN2-MCI (Kramer, 1994) GREEDY3 <ref> (Pagallo & Haussler, 1990) </ref>, PREPEND (Webb & Brkic, 1993; Webb, 1994), FOIDL (Mooney & Califf, 1995) logic programs: INDUCE (Michalski, 1980), FOIL (Quinlan, 1990; Quinlan & Cameron-Jones, 1995a), mFOIL (Dzeroski & Bratko, 1992), SFOIL (Pompe et al., 1993), MILP (Kovacic, 1994b) HYDRA (Ali & Pazzani, 1993), CHAMP (Kijsirikul et al., 1991, <p> A similar result has been proven in (Bostrom, 1995). * The restriction of decision tree learning algorithms to non-overlapping rules imposes strong constraints on learnable rules. One problem resulting from this constraint is the replicated subtree problem <ref> (Pagallo & Haussler, 1990) </ref>: It often happens that identical subtrees have to be learned at various places in a decision tree, because of the fragmentation of the example space imposed by the restriction to non-overlapping rules. <p> This measure will attain its optimal value when no negative examples are covered. However, it does not aim at covering many positive examples. It is used in the GREEDY3 <ref> (Pagallo & Haussler, 1990) </ref> and SWAP-1 (Weiss & Indurkhya, 1991) algorithms. Information content: IC (r) = log p + n Sometimes the logarithm of the rule's purity is used, which measures the amount of information contained in the classification of the covered examples. <p> This method can be easily adopted for avoiding overfitting of noisy data. A frequently used approach is to maximize the predictive accuracy measured on a separate set of data that has not been available to the learner during theory construction. This method has been suggested in in <ref> (Pagallo & Haussler, 1990) </ref> based on similar algorithms for pruning decision trees (Quinlan, 1987b). Before learning a complete and consistent concept description the training set is split into two subsets: a growing set (usually 2/3) and a pruning set (1/3). <p> However, post-pruning has also several disadvantages, most notably efficiency. Cohen (1993) has shown that REP has a time complexity of (n 4 ) on purely random data. Therefore he proposed GROW a new pruning algorithm based on a technique used in the GROVE learning system <ref> (Pagallo & Haussler, 1990) </ref>. Like REP, GROW first finds a theory that overfits the data.
Reference: <author> Pazzani, M., & Kibler, D. </author> <year> (1992). </year> <title> The utility of knowledge in inductive learning. </title> <journal> Machine Learning, </journal> <volume> 9, </volume> <pages> 57-94. </pages>
Reference-contexts: (Kovacic, 1994b) HYDRA (Ali & Pazzani, 1993), CHAMP (Kijsirikul et al., 1991, 1992), FOSSIL (Furnkranz, 1994b), REP (Brunk & Pazzani, 1991), TDP (Furnkranz, 1994c), I-REP (Furnkranz & Widmer, 1994), I 2 -REP (Furnkranz, 1995), ML-SMART (Bergadano & Giordana, 1988), GA-SMART (Giordana & Sale, 1992), SMART+ (Botta & Giordana, 1993), FOCL <ref> (Pazzani & Kibler, 1992) </ref>, GRENDEL (Cohen, 1994), GOLEM (Muggleton & Feng, 1990), NINA (Ade et al., 1995), PROGOL (Muggleton, 1995) functional relations: FILP (Bergadano & Gunetti, 1993), FFOIL (Quinlan, 1996) regression rules: IBL-SMART (Widmer, 1993) RULE (Weiss & Indurkhya, 1993, 1995), FORS (Karalic, 1995) 3 F urnkranz Given: * a target <p> A new variable has depth i + 1, where i is the maximum depth of all old variables of the literal where the new variable is introduced. 12 Separate-and-Conquer Rule Learning more than one literal at a time can also be found in ML-SMART (Bergadano & Giordana, 1988) and FOCL <ref> (Pazzani & Kibler, 1992) </ref>. These systems allow to replace conditions of a rule with the body of their definitions in the background knowledge. In a later version of ML-SMART (Bergadano, Giordana, & Ponsero, 1989) one could also specify so-called predicate sets.
Reference: <author> Pfahringer, B. </author> <year> (1994a). </year> <title> Controlling constructive induction in CiPF: an MDL approach. </title> <editor> In Brazdil, P. B. (Ed.), </editor> <booktitle> Proceedings of the 7th European Conference on Machine Learning (ECML-94), Lecture Notes in Artificial Intelligence, </booktitle> <pages> pp. 242-256 Catania, </pages> <address> Sicily. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: 1969), AQ15 (Michalski et al., 1986), AQ17 (Bloedorn & Michalski, 1991; Wnek & Michalski, 1994; Bloedorn et al., 1993) PRISM (Cendrowska, 1987), SWAP-1 (Weiss & Indurkhya, 1991), POSEIDON (Bergadano et al., 1992), PFOIL (Mooney, 1995), JoJo (Fensel & Wiese, 1993; Wiese, 1996) ATRIS (Kononenko & Kovacic, 1992; Mladenic, 1993) CiPF <ref> (Pfahringer, 1994a, 1994b) </ref> DLG (Webb, 1992; Webb & Agar, 1992), CLASS (Webb, 1993), SIA (Venturini, 1993) GROW (Cohen, 1993), RIPPER (Cohen, 1995), BEXA (Theron & Cloete, 1996) CNF: PFOIL-CNF (Mooney, 1995), ICL (De Raedt & Van Laer, 1995) decision lists: (Rivest, 1987), CN2 (Clark & Niblett, 1989; Clark & Boswell, 1991), <p> AQ17-MCI (Bloedorn et al., 1993) integrates the approaches taken by AQ17-DCI and AQ17-HCI into a single system that is able to learn meta-rules that specify which types of constructive operators are suitable for which type of tasks. Similar ideas are implemented in CiPF <ref> (Pfahringer, 1994a, 1994b) </ref> which uses a propositional top-down separate-and-conquer algorithm as the basic induction module and in CN2-MCI (Kramer, 1994) which introduces a new powerful constructive induction operator for CN2-like algorithms. This operator constructs a new attribute from the cross-product of attributes that often occur together in different rules.
Reference: <author> Pfahringer, B. </author> <year> (1994b). </year> <title> Robust constructive induction. </title> <editor> In Nebel, B., & Dreschler-Fischer, F. (Eds.), </editor> <booktitle> Proceedings of the 18th German Annual Conference on Artificial Intelligence (KI-94), Lecture Notes in Artificial Intelligence, </booktitle> <pages> pp. 118-129. </pages> <publisher> Springer-Verlag. </publisher>
Reference: <author> Pfahringer, B. </author> <year> (1995a). </year> <title> A new MDL measure for robust rule induction (extended abstract). </title>
Reference-contexts: The goal is to minimize this measure. Unfortunately, both terms are not computable and have to be approximated. For various computable approximations for rule learning we refer to (Kovacic, 1994a, 1994b) and <ref> (Pfahringer, 1995a, 1995b) </ref>. FOIL (Quinlan, 1990) uses a variant of the MDL principle as a stopping criterion (see section 5.1).
Reference: <editor> In Lavrac, N., & Wrobel, S. (Eds.), </editor> <booktitle> Proceedings of the 8th European Conference on Machine Learning (ECML-95), No. 912 in Lecture Notes in Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 331-334 Heraclion, Greece. </address> <publisher> Springer-Verlag. </publisher>
Reference: <author> Pfahringer, B. </author> <year> (1995b). </year> <title> Practical Uses of the Minimum Description Length Principle in Inductive Learning. </title> <type> Ph.D. thesis, </type> <institution> Technische Universitat Wien. </institution>
Reference: <author> Plotkin, G. D. </author> <year> (1970). </year> <title> A note on inductive generalisation. </title> <editor> In Meltzer, B., & Michie, D. (Eds.), </editor> <booktitle> Machine Intelligence 5, </booktitle> <pages> pp. 153-163. </pages> <publisher> Elsevier North-Holland, </publisher> <address> New York. </address>
Reference-contexts: Domingos (1996b) has named his method "conquering without separating". A similar approach has also been taken in the inductive logic programming algorithm CHILLIN (Zelle, Mooney, & Konvisser, 1994), where rules are generalized by forming their least general generalization <ref> (Plotkin, 1970) </ref> and, if necessary, successively specialized using top-down hill-climbing as in FOIL. CWS (Domingos, 1996a) interleaves the induction of different rules by starting to induce the next rule in the same cycle as the second condition of the current rule is learned.
Reference: <author> Plotkin, G. D. </author> <year> (1971). </year> <title> A further note on inductive generalisation. </title> <editor> In Meltzer, B., & Michie, D. (Eds.), </editor> <booktitle> Machine Intelligence 6, </booktitle> <pages> pp. 101-124. </pages> <publisher> Elsevier North-Holland, </publisher> <address> New York. </address>
Reference-contexts: This starting rule is then generalized to increase the number of covered examples. GOLEM, for example, forms a starting clause by computing the relative least general generalization <ref> (Plotkin, 1971) </ref> of a set of randomly chosen pairs of positive examples. This starting clause is successively generalized by greedily selecting additional positive examples that will be used for building the rlgg. <p> As the most specific clauses can be exponentially large, even infinite in the case of general first-order horn-clause logic <ref> (Plotkin, 1971) </ref>, the hypothesis space has to be restricted to a subset of first-order logic using syntactic (section 3.1.3) or semantic (section 4.3.6) restrictions. There are only a few propositional bottom-up separate-and-conquer learning algorithms.
Reference: <author> Pompe, U., Kovacic, M., & Kononenko, I. </author> <year> (1993). </year> <title> SFOIL: Stochastic approach to inductive logic programming. </title> <booktitle> In Proceedings of the 2nd Slovenian Conference on Electrical Engineering and Computer Science (ERK-93), </booktitle> <volume> Vol. B, </volume> <pages> pp. </pages> <address> 189-192 Portoroz, Slovenia. </address>
Reference-contexts: lists: (Rivest, 1987), CN2 (Clark & Niblett, 1989; Clark & Boswell, 1991), CN2-MCI (Kramer, 1994) GREEDY3 (Pagallo & Haussler, 1990), PREPEND (Webb & Brkic, 1993; Webb, 1994), FOIDL (Mooney & Califf, 1995) logic programs: INDUCE (Michalski, 1980), FOIL (Quinlan, 1990; Quinlan & Cameron-Jones, 1995a), mFOIL (Dzeroski & Bratko, 1992), SFOIL <ref> (Pompe et al., 1993) </ref>, MILP (Kovacic, 1994b) HYDRA (Ali & Pazzani, 1993), CHAMP (Kijsirikul et al., 1991, 1992), FOSSIL (Furnkranz, 1994b), REP (Brunk & Pazzani, 1991), TDP (Furnkranz, 1994c), I-REP (Furnkranz & Widmer, 1994), I 2 -REP (Furnkranz, 1995), ML-SMART (Bergadano & Giordana, 1988), GA-SMART (Giordana & Sale, 1992), SMART+ (Botta <p> The resulting system, MILP performs a stochastic hill-climbing search with simulated annealing. Whenever it reaches a local optimum, it backtracks to a previous rule, whose successors have not yet been examined, in order to get a new starting point. A similar approach is implemented in the SFOIL algorithm <ref> (Pompe et al., 1993) </ref>. Another family of stochastic separate-and-conquer rule learning algorithms choose a genetic algorithm (Goldberg, 1989) for finding good rules. One such system, SIA (Venturini, 1993), selects a random starting example and searches for a suitable generalization in a bottom-up fashion. <p> The most commonly used stopping criteria are * Minimum Purity Criterion: This simple criterion requires that a certain percentage of the examples covered by the learned rules is positive. It is for example used in the SFOIL algorithm <ref> (Pompe et al., 1993) </ref> as a termination criterion for the stochastic search.
Reference: <author> Quinlan, J. R. </author> <year> (1983). </year> <title> Learning efficient classification procedures and their application to chess end games. </title> <editor> In Michalski, R. S., Carbonell, J. G., & Mitchell, T. M. (Eds.), </editor> <booktitle> Machine Learning. An Artificial Intelligence Approach, </booktitle> <pages> pp. 463-482. </pages> <publisher> Tioga Publishing Co. </publisher>
Reference-contexts: Originating from the ID3 decision tree learning system <ref> (Quinlan, 1983) </ref>, this measure has been used in early versions of the CN2 learning algorithm (Clark & Niblett, 1989). However, it suffers from similar deficiencies as purity and information content and has later been replaced by the Laplace estimate (Clark & Boswell, 1991).
Reference: <author> Quinlan, J. R. </author> <year> (1986). </year> <title> Induction of decision trees. </title> <journal> Machine Learning, </journal> <volume> 1, </volume> <pages> 81-106. </pages>
Reference-contexts: The most commonly used alternative is decision tree learning via the divide-and-conquer strategy <ref> (Quinlan, 1986) </ref>. Much of the popularity of decision tree learning stems from its efficiency in learning and classification (Bostrom, 1995). Moreover, decision trees can easily be turned into a rule set by generating one rule for each path from the root a leaf.
Reference: <author> Quinlan, J. R. </author> <year> (1987a). </year> <title> Generating production rules from decision trees. </title> <booktitle> In Proceedings of the 10th International Joint Conference on Artificial Intelligence (IJCAI-87), </booktitle> <pages> pp. 304-307. </pages> <publisher> Morgan Kaufmann. 43 F urnkranz Quinlan, </publisher> <editor> J. R. </editor> <year> (1987b). </year> <title> Simplifying decision trees. </title> <journal> International Journal of Man-Machine Studies, </journal> <volume> 27, </volume> <pages> 221-234. </pages>
Reference-contexts: Quinlan (1993) has noted that even pruned decision trees may be too cumbersome, complex, and inscrutable to provide insight into the domain at hand and has consequently devised procedures for simplifying decision trees into pruned production rule sets <ref> (Quinlan, 1987a, 1993) </ref>. Additional evidence for this comes from Rivest (1987) who shows that decision lists (ordered rule sets) with at most k conditions per rule are strictly more expressive than decision trees of depth k. <p> Recently, the BEXA algorithm (Theron & Cloete, 1996) has used significance testing as a pre-pruning criterion and performs an additional post-pruning phase where conditions and rules are pruned in the way described in <ref> (Quinlan, 1987a) </ref>. However, there is always the danger that a predefined stopping criterion will oversimplify the theory. To avoid this Furnkranz (1994c) has developed an algorithm called Top-Down Pruning (TDP). <p> Last but not least, the C4.5 decision tree induction algorithm has an option that allows to generate compact decision lists from decision trees by turning a decision tree into a set of non-overlapping rules, pruning these rules, and ordering the resulting overlapping rules into a decision list <ref> (Quinlan, 1987a, 1993) </ref>. 7. Conclusion In this paper we have given a survey of the best-known members of the family of separate-and-conquer or covering learning algorithms, which have been in use for almost 30 years now.
Reference: <author> Quinlan, J. R. </author> <year> (1990). </year> <title> Learning logical definitions from relations. </title> <journal> Machine Learning, </journal> <volume> 5, </volume> <pages> 239-266. </pages>
Reference-contexts: Finally, the ordering of the rules is also important when learning recursive concepts, where it has to be ensured that the base case of the recursion comes before the recursive rule as e.g. in FOIL <ref> (Quinlan, 1990) </ref>. In the remainder of this paper we will neglect the aspect of rule ordering and simply assume that rules are used in the same order in which they are learned. 3. <p> The original version of FOIL <ref> (Quinlan, 1990) </ref> for example allowed all possible combinations of variables in the arguments of the used literals. Thus the search space grew exponentially with the number of attributes in the data set, which severely handicapped the program in terms of both efficiency and accuracy. <p> However, for longer rules (&gt; 4 conditions) this exhaustive search is too inefficient for practical problems (Dzeroski et al., 1996). A similar heuristic is used in FOIL's hill-climbing algorithm for safely pruning certain branches of the search space <ref> (Quinlan, 1990) </ref>. It might be worth-while to try a best-first search with this heuristic. However, there is considerable evidence that exhausting a search space can lead to worse results because the chances that rules are encountered that fit the training data by chance are increased. <p> All common heuristics are based on determining several basic properties of a candidate rule, like the number of positive and negative examples that it covers. Minor variations in counting are possible, as for example in FOIL <ref> (Quinlan, 1990) </ref> which does not rely on counting instances but instead counts the number of different instantiations of the rule body that allow to infer a given example (counting proofs). <p> DLG (Webb, 1992) employs it as a search heuristic, but it is more often used as a weighting function (as e.g. in FOIL <ref> (Quinlan, 1990) </ref>). 24 Separate-and-Conquer Rule Learning Abductivity: ABD (r) = 1 l S This measure has been used in various versions of the SMART family of algorithms (Botta & Giordana, 1993). It aims at measuring how well r is explained by the available background knowledge. <p> The goal is to minimize this measure. Unfortunately, both terms are not computable and have to be approximated. For various computable approximations for rule learning we refer to (Kovacic, 1994a, 1994b) and (Pfahringer, 1995a, 1995b). FOIL <ref> (Quinlan, 1990) </ref> uses a variant of the MDL principle as a stopping criterion (see section 5.1). <p> form is the following: G (r) = W (r)(H (r) H (r 0 )) Some examples for gain heuristics are: Weighted Information Gain: W IG (r) = C (r)(IC (r) IC (r 0 )) The classical example for a gain heuristic is the weighted information gain heuristic used in FOIL <ref> (Quinlan, 1990) </ref>. Here the basic heuristic is information content and the difference is weighted with the number of covered positive examples. The sign has to be reversed as IC (r) is a heuristic that has to minimized so that IC (r) IC (r 0 ) &lt; 0 will usually hold. <p> The sign has to be reversed as IC (r) is a heuristic that has to minimized so that IC (r) IC (r 0 ) &lt; 0 will usually hold. In its original formulation <ref> (Quinlan, 1990) </ref> IC (r) and IC (r 0 ) are computed by counting proofs, while C (r) is computed by counting instances. Coverage Gain: CG (r) = P n n 0 This heuristic is used for pruning in the POSEIDON algorithm (Bergadano et al., 1992). <p> It is for example used in the SFOIL algorithm (Pompe et al., 1993) as a termination criterion for the stochastic search. In FOIL <ref> (Quinlan, 1990) </ref> this criterion is used as a RuleStoppingCriterion: When the best rule is below a certain purity threshold (usually 80%) it is rejected and the learned theory is considered to be complete. * Encoding Length Restriction: This heuristic used in the ILP algorithm FOIL (Quinlan, 1990) is based on the <p> In FOIL <ref> (Quinlan, 1990) </ref> this criterion is used as a RuleStoppingCriterion: When the best rule is below a certain purity threshold (usually 80%) it is rejected and the learned theory is considered to be complete. * Encoding Length Restriction: This heuristic used in the ILP algorithm FOIL (Quinlan, 1990) is based on the Minimum Description Length principle (Rissanen, 1978).
Reference: <author> Quinlan, J. R. </author> <year> (1991). </year> <title> Determinate literals in inductive logic programming. </title> <booktitle> In Proceedings of the 8th International Workshop on Machine Learning, </booktitle> <pages> pp. 442-446. </pages>
Reference-contexts: In this case the counting-instances and counting-proofs methods discussed at the beginning of this section produce identical results. In FOIL such determinate literals are added to the body of the rule when no other condition is given a high evaluation by the search heuristic <ref> (Quinlan, 1991) </ref>. This is necessary, because determinate literals usually have a low heuristic evaluation, because they will typically have a valid ground instantiation for all positive and negative training examples.
Reference: <author> Quinlan, J. R. </author> <year> (1993). </year> <title> C4.5: Programs for Machine Learning. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA. </address>
Reference-contexts: Severe restrictions have to be used when learning recursive programs in order to avoid infinite recursions. This problem has been discussed at length in <ref> (Cameron-Jones & Quinlan, 1993) </ref>. 3.1.4 Relational Clich es In some cases it may proof useful for top-down algorithms to not only add one condition at a time, but to add a conjunction of conditions at once. The classical example is to avoid myopic behavior in hill-climbing algorithms. <p> In addition he shows that an alternative rule stopping criterion based on theory description length and an additional post-pruning phase can further improve I-REP. The resulting algorithm, RIPPER, has been shown to be competitive with C4.5rules <ref> (Quinlan, 1993) </ref> without losing I-REP's efficiency. 6. Related Work In the literature one can also find a variety of separate-and-conquer learning algorithms that tackle slightly different tasks than the inductive concept learning problem as defined in figure 2.
Reference: <author> Quinlan, J. R. </author> <year> (1996). </year> <title> Learning first-order definitions of functions. </title> <journal> Journal of Artificial Intelligence Research. </journal> <note> To appear. </note>
Reference-contexts: 1994), I 2 -REP (Furnkranz, 1995), ML-SMART (Bergadano & Giordana, 1988), GA-SMART (Giordana & Sale, 1992), SMART+ (Botta & Giordana, 1993), FOCL (Pazzani & Kibler, 1992), GRENDEL (Cohen, 1994), GOLEM (Muggleton & Feng, 1990), NINA (Ade et al., 1995), PROGOL (Muggleton, 1995) functional relations: FILP (Bergadano & Gunetti, 1993), FFOIL <ref> (Quinlan, 1996) </ref> regression rules: IBL-SMART (Widmer, 1993) RULE (Weiss & Indurkhya, 1993, 1995), FORS (Karalic, 1995) 3 F urnkranz Given: * a target concept, * positive and negative examples * described with several features and * optional background knowledge Find: * a simple set of rules that discriminates between (unseen) positive <p> This increases the comprehensibility of the learned concepts. Similar problems have to be tackled in first-order function learning <ref> (Quinlan, 1996) </ref>, where the learned rules do not check the validity of a given ground instance but derive ground values for its unbound variables. Different rules might derive different values and thus some ordering of the rules is needed to handle these clashes.
Reference: <author> Quinlan, J. R., & Cameron-Jones, R. M. </author> <year> (1995a). </year> <title> Induction of logic programs: FOIL and related systems. </title> <journal> New Generation Computing, </journal> <volume> 13 (3,4), </volume> <pages> 287-312. </pages> <note> Special Issue on Inductive Logic Programming. </note>
Reference-contexts: Moreover, they can also make use of tree-structured attributes. A description of these extensions can be found in (Michalski, 1980). 3.1.2 Literals Research in inductive logic programming (ILP), in particular on FOIL and related systems <ref> (Quinlan & Cameron-Jones, 1995a) </ref>, has produced algorithms for solving classification problems in first-order logic. In these cases the target concept is usually represented as a PROLOG relation in the form concept name (A1,A2,: : :,An) where concept name is an n-ary PROLOG predicate denoting the concept to learn. <p> The literal is symmetric in the variables X and Y. A more detailed description of this syntax can be found in the appendix of (Furnkranz, 1994a). Similar declarations can be made in mFOIL (Dzeroski & Bratko, 1992), recent versions of FOIL <ref> (Quinlan & Cameron-Jones, 1995a) </ref>, PROGOL (Muggleton, 1995), and others. Restrictions of this type can significantly reduce the hypothesis space. Similar effects can also be achieved by restricting the domains of the selectors. <p> For example it may be useful to specify that selectors for list-valued attributes will only be used with the empty list, but not with arbitrary lists <ref> (Quinlan & Cameron-Jones, 1995a) </ref>. Many rule learning systems also place upper bounds on the complexity of the learned rules in order to restrict the search space. PROGOL, e.g., has a parameter that can be used to specify a maximum rule length. <p> A typical example for this myopia are first-order literals that introduce new variables and have no discriminatory power as discussed in sections 3.1.2 and 4.3.6. Nevertheless, most first-order top-down separate-and-conquer algorithms like FOIL and its many relatives <ref> (Quinlan & Cameron-Jones, 1995a) </ref> use hill-climbing because of its efficiency. A simple technique for decreasing search myopia in hill-climbing is to look further ahead. This can be done by choosing the best rule resulting from performing n refinement steps at once instead of only 1.
Reference: <author> Quinlan, J. R., & Cameron-Jones, R. M. </author> <year> (1995b). </year> <title> Oversearching and layered search in empirical learning. </title> <editor> In Mellish, C. (Ed.), </editor> <booktitle> Proceedings of the 14th International Joint Conference on Artificial Intelligence, </booktitle> <pages> pp. 1019-1024. </pages> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Rissanen, J. </author> <year> (1978). </year> <title> Modeling by shortest data description. </title> <journal> Automatica, </journal> <volume> 14, </volume> <pages> 465-471. </pages>
Reference-contexts: In later work, Quinlan (1993) replaced this algorithm by a scheme that groups the rules according to the classes they predict and orders these groups using a heuristic based on the minimum description length principle <ref> (Rissanen, 1978) </ref>. This increases the comprehensibility of the learned concepts. Similar problems have to be tackled in first-order function learning (Quinlan, 1996), where the learned rules do not check the validity of a given ground instance but derive ground values for its unbound variables. <p> used as a RuleStoppingCriterion: When the best rule is below a certain purity threshold (usually 80%) it is rejected and the learned theory is considered to be complete. * Encoding Length Restriction: This heuristic used in the ILP algorithm FOIL (Quinlan, 1990) is based on the Minimum Description Length principle <ref> (Rissanen, 1978) </ref>. It tries to avoid learning complicated rules that cover only a few examples by making sure that the number of bits that are needed to encode a clause is less than the number 28 Separate-and-Conquer Rule Learning of bits needed to encode the instances covered by it.
Reference: <author> Rivest, R. L. </author> <year> (1987). </year> <title> Learning decision lists. </title> <journal> Machine Learning, </journal> <volume> 2, </volume> <pages> 229-246. </pages>
Reference-contexts: Wiese, 1996) ATRIS (Kononenko & Kovacic, 1992; Mladenic, 1993) CiPF (Pfahringer, 1994a, 1994b) DLG (Webb, 1992; Webb & Agar, 1992), CLASS (Webb, 1993), SIA (Venturini, 1993) GROW (Cohen, 1993), RIPPER (Cohen, 1995), BEXA (Theron & Cloete, 1996) CNF: PFOIL-CNF (Mooney, 1995), ICL (De Raedt & Van Laer, 1995) decision lists: <ref> (Rivest, 1987) </ref>, CN2 (Clark & Niblett, 1989; Clark & Boswell, 1991), CN2-MCI (Kramer, 1994) GREEDY3 (Pagallo & Haussler, 1990), PREPEND (Webb & Brkic, 1993; Webb, 1994), FOIDL (Mooney & Califf, 1995) logic programs: INDUCE (Michalski, 1980), FOIL (Quinlan, 1990; Quinlan & Cameron-Jones, 1995a), mFOIL (Dzeroski & Bratko, 1992), SFOIL (Pompe et <p> The latter has the advantage that the evaluation of its rules does not change with their position in the list. Theories that impose a fixed evaluation order on their rules are commonly referred to as decision lists <ref> (Rivest, 1987) </ref>. They can be viewed as a PROLOG program where each rule ends with a cut (!) (Mooney & Califf, 1995).
Reference: <author> Rouveirol, C. </author> <year> (1992). </year> <title> Extensions of inversion of resolution applied to theory completion. </title>
Reference-contexts: GOLEM, for example, forms a starting clause by computing the relative least general generalization (Plotkin, 1971) of a set of randomly chosen pairs of positive examples. This starting clause is successively generalized by greedily selecting additional positive examples that will be used for building the rlgg. ITOU <ref> (Rouveirol, 1992) </ref> constructs a starting clause by adding all conditions than can be proved from the background knowledge (saturation). <p> NINA (Ade et al., 1995) is a bottom-up first-order separate-and-conquer algorithm that unifies several bottom-up ILP algorithms such as GOLEM (Muggleton & Feng, 1990), ITOU <ref> (Rouveirol, 1992) </ref>, and CLINT (De Raedt, 1992). As the most specific clauses can be exponentially large, even infinite in the case of general first-order horn-clause logic (Plotkin, 1971), the hypothesis space has to be restricted to a subset of first-order logic using syntactic (section 3.1.3) or semantic (section 4.3.6) restrictions.
Reference: <editor> In Muggleton, S. H. (Ed.), </editor> <booktitle> Inductive Logic Programming, </booktitle> <pages> pp. 63-92. </pages> <publisher> Academic Press Ltd., London. </publisher>
Reference: <author> Rouveirol, C. </author> <year> (1994). </year> <title> Flattening and saturation: Two representation changes for generalization. </title> <journal> Machine Learning, </journal> <volume> 14, </volume> <pages> 219-232. </pages> <note> Special issue on Evaluating and Changing Representation. </note>
Reference-contexts: A representation change called flattening that removes all function symbols from the examples and the background knowledge allows to implement generalization with a single operator that drops literals from rules (truncation) <ref> (Rouveirol, 1994) </ref>. NINA (Ade et al., 1995) is a bottom-up first-order separate-and-conquer algorithm that unifies several bottom-up ILP algorithms such as GOLEM (Muggleton & Feng, 1990), ITOU (Rouveirol, 1992), and CLINT (De Raedt, 1992).
Reference: <author> Saitta, L., & Bergadano, F. </author> <year> (1993). </year> <title> Pattern recognition and valiant's learning framework. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 15 (2), </volume> <pages> 145-154. </pages>
Reference-contexts: This is also confirmed by early results from statistical learning theory (Vapnik & Chervonenkis, 1971, 1981), where it has been observed that larger hypothesis spaces can lead to poorer generalization behavior (see also <ref> (Saitta & Bergadano, 1993) </ref>). 18 Separate-and-Conquer Rule Learning 4.1.4 Stochastic Search Another approach to escape the danger of getting stuck in local optima is to use a stochastic search, which be implemented into the framework of figure 4 by allowing randomness in the RefineRule procedure.
Reference: <author> Schaffer, C. </author> <year> (1993). </year> <title> Overfitting avoidance as bias. </title> <journal> Machine Learning, </journal> <volume> 10, </volume> <pages> 153-178. </pages>
Reference: <author> Segal, R., & Etzioni, O. </author> <year> (1994). </year> <title> Learning decision lists using homogeneous rules. </title> <booktitle> In Proceedings of the 12th National Conference on Artificial Intelligence (AAAI-94), </booktitle> <pages> pp. </pages> <address> 619-625 Cambridge, MA. </address> <publisher> AAAI Press. </publisher>
Reference: <author> Shapiro, E. Y. </author> <year> (1981). </year> <title> An algorithm that infers theories from facts. </title> <booktitle> In Proceedings of the 7th International Joint Conference on Artificial Intelligence, </booktitle> <pages> pp. 446-451. </pages>
Reference-contexts: Arguments where only bound variables can appear are called input variables, whereas arguments where new variables can be used as well are called output variables. Type and mode declarations have already been used in early ILP systems such as MIS <ref> (Shapiro, 1981) </ref>. Many predicates are also symmetric in some of their input arguments, i.e. they will produce the same result no matter in which order these arguments are given.
Reference: <author> Silverstein, G., & Pazzani, M. J. </author> <year> (1991). </year> <title> Relational cliches: Constraining constructive induction during relational learning. </title> <booktitle> In Proceedings of the 8th International Workshop on Machine Learning, </booktitle> <pages> pp. </pages> <address> 203-207 Evanston, Illinois. </address> <note> 44 Separate-and-Conquer Rule Learning Silverstein, </note> <author> G., & Pazzani, M. J. </author> <year> (1993). </year> <title> Learning relational cliches. </title> <booktitle> In Proceedings of the IJCAI-93 Workshop on Inductive Logic Programming, </booktitle> <pages> pp. 71-82. </pages>
Reference-contexts: A similar idea has been explored further in <ref> (Silverstein & Pazzani, 1991) </ref>. Relational cliches are conjunctions of the type explained above with the difference that the predicate does not have to be exactly specified. Instead the user can provide a place-holder that stands for a certain class of predicates.
Reference: <author> Srinivasan, A., Muggleton, S. H., & Bain, M. E. </author> <year> (1992). </year> <title> Distinguishing noise from exceptions in non-monotonic learning. </title> <booktitle> In Proceedings of the International Workshop on Inductive Logic Programming Tokyo, </booktitle> <address> Japan. </address>
Reference-contexts: A definition for the invented predicate is then induced from these examples by recursively calling CHAMP with the invented predicate as the target predicate. A very similar approach | called closed-world specialization | is taken in (Bain, 1991) and <ref> (Srinivasan, Muggleton, & Bain, 1992) </ref>. Here over-general clauses learned by the bottom-up first-order separate-and-conquer learner GOLEM (Muggleton & Feng, 1990) are specialized by adding a negated new predicate.
Reference: <author> Theron, H., & Cloete, I. </author> <year> (1996). </year> <title> BEXA: A covering algorithm for learning propositional concept descriptions. </title> <journal> Machine Learning, </journal> <volume> 24, </volume> <pages> 5-40. </pages>
Reference-contexts: (Weiss & Indurkhya, 1991), POSEIDON (Bergadano et al., 1992), PFOIL (Mooney, 1995), JoJo (Fensel & Wiese, 1993; Wiese, 1996) ATRIS (Kononenko & Kovacic, 1992; Mladenic, 1993) CiPF (Pfahringer, 1994a, 1994b) DLG (Webb, 1992; Webb & Agar, 1992), CLASS (Webb, 1993), SIA (Venturini, 1993) GROW (Cohen, 1993), RIPPER (Cohen, 1995), BEXA <ref> (Theron & Cloete, 1996) </ref> CNF: PFOIL-CNF (Mooney, 1995), ICL (De Raedt & Van Laer, 1995) decision lists: (Rivest, 1987), CN2 (Clark & Niblett, 1989; Clark & Boswell, 1991), CN2-MCI (Kramer, 1994) GREEDY3 (Pagallo & Haussler, 1990), PREPEND (Webb & Brkic, 1993; Webb, 1994), FOIDL (Mooney & Califf, 1995) logic programs: INDUCE <p> Thus many separate-and-conquer algorithms use beam search in their FindBestRule procedures. Among them are AQ (Michalski et al., 1986), CN2 (Clark & Niblett, 1989), mFOIL (Dzeroski & Bratko, 1992), and BEXA <ref> (Theron & Cloete, 1996) </ref>. <p> On the other hand, if the rule's coverage goes to infinity, LAP (r) converges towards P (r). 7 Because of its simplicity this heuristic is quite popular and is used in CN2 (Clark & Boswell, 1991), mFOIL (Dzeroski & Bratko, 1992), CLASS (Webb, 1993), BEXA <ref> (Theron & Cloete, 1996) </ref> and several others. m-estimate: M (r) = P +N The m-estimate generalizes the Laplace so that rules with 0-coverage will be evaluated with the a priori probability of the positive examples in the training set instead of 1 2 . <p> For this test it exploits the fact that the likelihood ratio statistic that can be derived from the J-measure as LRS (r) = 2 (P +N )J (r) is approximately distributed 2 with 1 degree of freedom. Insignificant rules can thus be rejected. In BEXA <ref> (Theron & Cloete, 1996) </ref> this test is also used for comparing the distribution of instances covered by a rule to that of its direct predecessor. <p> These are not intended to entirely prevent overfitting like the pre-pruning approaches of section 5.1, but to reduce the amount of overfitting, so that the post-pruning phase can start with a better theory and has to do less work. Recently, the BEXA algorithm <ref> (Theron & Cloete, 1996) </ref> has used significance testing as a pre-pruning criterion and performs an additional post-pruning phase where conditions and rules are pruned in the way described in (Quinlan, 1987a). However, there is always the danger that a predefined stopping criterion will oversimplify the theory.
Reference: <author> Utgoff, P. E. </author> <year> (1986). </year> <title> Shift of bias for inductive concept learning. </title> <editor> In Michalski, R., Carbonell, J., & Mitchell, T. (Eds.), </editor> <booktitle> Machine Learning: An Artificial Intelligence Approach, </booktitle> <volume> Vol. II, </volume> <pages> pp. 107-148. </pages> <publisher> Morgan Kaufmann, </publisher> <address> Los Altos, CA. </address>
Reference-contexts: Once a language bias is defined it cannot be changed without user intervention. In this section we will discuss approaches that can dynamically adjust their language bias to the problem at hand via a so-called bias shift <ref> (Utgoff, 1986) </ref>: If the hypothesis space does not include an acceptable concept description, these techniques allow the learner to shift to a weaker bias, i.e. allow to express concepts in a more expressive representation language. 3.2.1 Language Hierarchies A simple approach for implementing a procedure for dynamically shifting the language bias <p> Kohavi and John (1995) describe an approach how such parameters could be automatically adjusted. 3.2.2 Constructive Induction In its original use <ref> (Utgoff, 1986) </ref> the term bias shift referred to the process of automatically extending the representation language by constructing new features, a process that is commonly known as constructive induction (Matheus, 1989).
Reference: <author> Van Horn, K. S., & Martinez, T. R. </author> <year> (1993). </year> <title> The BBG rule induction algorithm. </title> <booktitle> In Proceedings of the 6th Australian Joint Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 348-355 Melbourne, Australia. </address>
Reference-contexts: ITRULE (Goodman & Smyth, 1988) performs an efficient exhaustive search for a fixed number of rule with a fixed maximum length. BBG <ref> (Van Horn & Martinez, 1993) </ref> learns a decision list by inserting a learned rule at appropriate places and evaluating the quality of the resulting decision list on the entire training set.
Reference: <author> Vapnik, V. N., & Chervonenkis, Y. A. </author> <year> (1971). </year> <title> On the uniform convergence of relative frequencies to their probabilities. </title> <journal> Theory of Probability and Its Applications, </journal> <volume> 16, </volume> <pages> 264-280. </pages>
Reference-contexts: They have empirically verified in a variety of domains that too large a beam width may lead to worse results. This is also confirmed by early results from statistical learning theory <ref> (Vapnik & Chervonenkis, 1971, 1981) </ref>, where it has been observed that larger hypothesis spaces can lead to poorer generalization behavior (see also (Saitta & Bergadano, 1993)). 18 Separate-and-Conquer Rule Learning 4.1.4 Stochastic Search Another approach to escape the danger of getting stuck in local optima is to use a stochastic search,
Reference: <author> Vapnik, V. N., & Chervonenkis, Y. A. </author> <year> (1981). </year> <title> Necessary and sufficient conditions for the uniform convergence of means to their expectations. </title> <journal> Theory of Probability and Its Applications, </journal> <volume> 26, </volume> <pages> 532-553. </pages>
Reference: <author> Venturini, G. </author> <year> (1993). </year> <title> SIA: A supervised inductive algorithm with genetic search for learning attributes based concepts. </title> <editor> In Brazdil, P. (Ed.), </editor> <booktitle> Proceedings of the 6th European Conference on Machine Learning (ECML-93), Vol. 667 of Lecture Notes in Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 280-296 Vienna, Austria. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: 1994; Bloedorn et al., 1993) PRISM (Cendrowska, 1987), SWAP-1 (Weiss & Indurkhya, 1991), POSEIDON (Bergadano et al., 1992), PFOIL (Mooney, 1995), JoJo (Fensel & Wiese, 1993; Wiese, 1996) ATRIS (Kononenko & Kovacic, 1992; Mladenic, 1993) CiPF (Pfahringer, 1994a, 1994b) DLG (Webb, 1992; Webb & Agar, 1992), CLASS (Webb, 1993), SIA <ref> (Venturini, 1993) </ref> GROW (Cohen, 1993), RIPPER (Cohen, 1995), BEXA (Theron & Cloete, 1996) CNF: PFOIL-CNF (Mooney, 1995), ICL (De Raedt & Van Laer, 1995) decision lists: (Rivest, 1987), CN2 (Clark & Niblett, 1989; Clark & Boswell, 1991), CN2-MCI (Kramer, 1994) GREEDY3 (Pagallo & Haussler, 1990), PREPEND (Webb & Brkic, 1993; Webb, <p> A similar approach is implemented in the SFOIL algorithm (Pompe et al., 1993). Another family of stochastic separate-and-conquer rule learning algorithms choose a genetic algorithm (Goldberg, 1989) for finding good rules. One such system, SIA <ref> (Venturini, 1993) </ref>, selects a random starting example and searches for a suitable generalization in a bottom-up fashion. It maintains a set of s candidate rules | a generation | which is initialized with random generalizations of the selected examples. <p> There are only a few propositional bottom-up separate-and-conquer learning algorithms. One such example is SIA <ref> (Venturini, 1993) </ref> which uses a genetic algorithm for searching the space of generalizations of a randomly selected example. However, the stochastic search 20 Separate-and-Conquer Rule Learning does not progress in a strictly bottom-up fashion.
Reference: <author> Wallace, C. S., & Boulton, D. M. </author> <year> (1968). </year> <title> An information measure for classification. </title> <journal> Computer Journal, </journal> <pages> pp. 185-194. </pages>
Reference: <author> Watanabe, L., & Rendell, L. </author> <year> (1991). </year> <title> Learning structural decision trees from examples. </title> <booktitle> In Proceedings of the 12th International Joint Conference on Artificial Intelligence (IJCAI-91), </booktitle> <pages> pp. 770-776. </pages>
Reference: <author> Webb, G. I. </author> <year> (1992). </year> <title> Learning disjunctive class descriptions by least generalisation. </title> <type> Tech. rep. TR C92/9, </type> <institution> Deakin University, School of Computing & Mathematics, </institution> <address> Geelong, Australia. </address>
Reference-contexts: One such example is SIA (Venturini, 1993) which uses a genetic algorithm for searching the space of generalizations of a randomly selected example. However, the stochastic search 20 Separate-and-Conquer Rule Learning does not progress in a strictly bottom-up fashion. Another propositional rule learning system, DLG <ref> (Webb, 1992) </ref>, successively generalizes a starting example by constructing a propositional least general generalization of the current rule and the next positive example. <p> Positive Coverage: C (r) = p This measurement for the complexity of a rule is based on the assumption that shorter rules are more general and thus cover a higher number of positive examples. DLG <ref> (Webb, 1992) </ref> employs it as a search heuristic, but it is more often used as a weighting function (as e.g. in FOIL (Quinlan, 1990)). 24 Separate-and-Conquer Rule Learning Abductivity: ABD (r) = 1 l S This measure has been used in various versions of the SMART family of algorithms (Botta &
Reference: <author> Webb, G. I. </author> <year> (1993). </year> <title> Systematic search for categorical attribute-value data-driven machine learning. </title> <editor> In Rowles, C., Liu, H., & Foo, N. (Eds.), </editor> <booktitle> Proceedings of the 6th Australian Joint Conference of Artificial Intelligence (AI'93), </booktitle> <pages> pp. </pages> <address> 342-347 Melbourne. </address> <publisher> World Scientific. </publisher>
Reference-contexts: Wnek & Michalski, 1994; Bloedorn et al., 1993) PRISM (Cendrowska, 1987), SWAP-1 (Weiss & Indurkhya, 1991), POSEIDON (Bergadano et al., 1992), PFOIL (Mooney, 1995), JoJo (Fensel & Wiese, 1993; Wiese, 1996) ATRIS (Kononenko & Kovacic, 1992; Mladenic, 1993) CiPF (Pfahringer, 1994a, 1994b) DLG (Webb, 1992; Webb & Agar, 1992), CLASS <ref> (Webb, 1993) </ref>, SIA (Venturini, 1993) GROW (Cohen, 1993), RIPPER (Cohen, 1995), BEXA (Theron & Cloete, 1996) CNF: PFOIL-CNF (Mooney, 1995), ICL (De Raedt & Van Laer, 1995) decision lists: (Rivest, 1987), CN2 (Clark & Niblett, 1989; Clark & Boswell, 1991), CN2-MCI (Kramer, 1994) GREEDY3 (Pagallo & Haussler, 1990), PREPEND (Webb & <p> To handle clashes (when multiple rules fire) CN2 orders rules in the order they have been learned. This seems to be a natural strategy, because most search heuristics tend to learn more general rules first. However, it has been pointed out in <ref> (Webb & Brkic, 1993) </ref> that prepending a new rule to the previously learned rules can produce simpler concepts. <p> It might be worth-while to try a best-first search with this heuristic. However, there is considerable evidence that exhausting a search space can lead to worse results because the chances that rules are encountered that fit the training data by chance are increased. For example, <ref> (Webb, 1993) </ref> has used the efficient best-first search algorithm OPUS (Webb, 1995) for inducing decision lists in a covering framework and has surprisingly found out that the generalizations discovered by beam search with CN2 are often superior to those found by an exhaustive best-first-search. <p> On the other hand, if the rule's coverage goes to infinity, LAP (r) converges towards P (r). 7 Because of its simplicity this heuristic is quite popular and is used in CN2 (Clark & Boswell, 1991), mFOIL (Dzeroski & Bratko, 1992), CLASS <ref> (Webb, 1993) </ref>, BEXA (Theron & Cloete, 1996) and several others. m-estimate: M (r) = P +N The m-estimate generalizes the Laplace so that rules with 0-coverage will be evaluated with the a priori probability of the positive examples in the training set instead of 1 2 . <p> Such a bias towards simpler theories has been termed overfitting avoidance bias (Schaffer, 1993; Wolpert, 1993). Several algorithms, such as CLASS <ref> (Webb, 1993) </ref>, rely on the noise handling capabilities of search heuristics like the Laplace-estimate, which can prefer rules that cover only a few negative examples over clauses that cover no negative examples if the former cover more positive examples.
Reference: <author> Webb, G. I. </author> <year> (1994). </year> <title> Recent progress in learning decision lists by prepending inferred rules. </title> <booktitle> In Proceedings of the 2nd Singapore International Conference on Intelligent Systems, </booktitle> <pages> pp. </pages> <note> B280-B285. </note> <author> F urnkranz Webb, G. I. </author> <year> (1995). </year> <title> OPUS: An efficient admissible algorithm for unordered search. </title> <journal> Journal of Artificial Intelligence Research, </journal> <volume> 5, </volume> <pages> 431-465. </pages>
Reference-contexts: Placing this simple general rule near the end of the rule list allows to handle these exceptions with rules that 8 Separate-and-Conquer Rule Learning are placed before the general rule and keep the general rule simple. This hypothesis has been empirically confirmed in <ref> (Webb, 1994) </ref> and (Mooney & Califf, 1995). Another method for inducing multi-class concepts is to learn a separate concept description for each class taking all examples of other classes as negative examples for the class to learn.
Reference: <author> Webb, G. I., & Agar, J. W. M. </author> <year> (1992). </year> <title> Inducing diagnostic rules for glomerular disease with the DLG machine learning algorithm. </title> <journal> Artificial Intelligence in Medicine, </journal> <volume> 4, </volume> <pages> 419-430. </pages>
Reference-contexts: One such example is SIA (Venturini, 1993) which uses a genetic algorithm for searching the space of generalizations of a randomly selected example. However, the stochastic search 20 Separate-and-Conquer Rule Learning does not progress in a strictly bottom-up fashion. Another propositional rule learning system, DLG <ref> (Webb, 1992) </ref>, successively generalizes a starting example by constructing a propositional least general generalization of the current rule and the next positive example. <p> Positive Coverage: C (r) = p This measurement for the complexity of a rule is based on the assumption that shorter rules are more general and thus cover a higher number of positive examples. DLG <ref> (Webb, 1992) </ref> employs it as a search heuristic, but it is more often used as a weighting function (as e.g. in FOIL (Quinlan, 1990)). 24 Separate-and-Conquer Rule Learning Abductivity: ABD (r) = 1 l S This measure has been used in various versions of the SMART family of algorithms (Botta &
Reference: <author> Webb, G. I., & Brkic, N. </author> <year> (1993). </year> <title> Learning decision lists by prepending inferred rules. </title> <booktitle> In Proceedings of the AI'93 Workshop on Machine Learning and Hybrid Systems Melbourne, </booktitle> <address> Australia. </address>
Reference-contexts: Wnek & Michalski, 1994; Bloedorn et al., 1993) PRISM (Cendrowska, 1987), SWAP-1 (Weiss & Indurkhya, 1991), POSEIDON (Bergadano et al., 1992), PFOIL (Mooney, 1995), JoJo (Fensel & Wiese, 1993; Wiese, 1996) ATRIS (Kononenko & Kovacic, 1992; Mladenic, 1993) CiPF (Pfahringer, 1994a, 1994b) DLG (Webb, 1992; Webb & Agar, 1992), CLASS <ref> (Webb, 1993) </ref>, SIA (Venturini, 1993) GROW (Cohen, 1993), RIPPER (Cohen, 1995), BEXA (Theron & Cloete, 1996) CNF: PFOIL-CNF (Mooney, 1995), ICL (De Raedt & Van Laer, 1995) decision lists: (Rivest, 1987), CN2 (Clark & Niblett, 1989; Clark & Boswell, 1991), CN2-MCI (Kramer, 1994) GREEDY3 (Pagallo & Haussler, 1990), PREPEND (Webb & <p> To handle clashes (when multiple rules fire) CN2 orders rules in the order they have been learned. This seems to be a natural strategy, because most search heuristics tend to learn more general rules first. However, it has been pointed out in <ref> (Webb & Brkic, 1993) </ref> that prepending a new rule to the previously learned rules can produce simpler concepts. <p> It might be worth-while to try a best-first search with this heuristic. However, there is considerable evidence that exhausting a search space can lead to worse results because the chances that rules are encountered that fit the training data by chance are increased. For example, <ref> (Webb, 1993) </ref> has used the efficient best-first search algorithm OPUS (Webb, 1995) for inducing decision lists in a covering framework and has surprisingly found out that the generalizations discovered by beam search with CN2 are often superior to those found by an exhaustive best-first-search. <p> On the other hand, if the rule's coverage goes to infinity, LAP (r) converges towards P (r). 7 Because of its simplicity this heuristic is quite popular and is used in CN2 (Clark & Boswell, 1991), mFOIL (Dzeroski & Bratko, 1992), CLASS <ref> (Webb, 1993) </ref>, BEXA (Theron & Cloete, 1996) and several others. m-estimate: M (r) = P +N The m-estimate generalizes the Laplace so that rules with 0-coverage will be evaluated with the a priori probability of the positive examples in the training set instead of 1 2 . <p> Such a bias towards simpler theories has been termed overfitting avoidance bias (Schaffer, 1993; Wolpert, 1993). Several algorithms, such as CLASS <ref> (Webb, 1993) </ref>, rely on the noise handling capabilities of search heuristics like the Laplace-estimate, which can prefer rules that cover only a few negative examples over clauses that cover no negative examples if the former cover more positive examples.
Reference: <author> Weiss, S. M., & Indurkhya, N. </author> <year> (1991). </year> <title> Reduced complexity rule induction. </title> <booktitle> In Proceedings of the 12th International Joint Conference on Artificial Intelligence (IJCAI-91), </booktitle> <pages> pp. 678-684. </pages>
Reference-contexts: Thus we feel that a separate treatment of these two issues is justified. 2 Separate-and-Conquer Rule Learning propositional rule sets (DNF): AQ (Michalski, 1969), AQ15 (Michalski et al., 1986), AQ17 (Bloedorn & Michalski, 1991; Wnek & Michalski, 1994; Bloedorn et al., 1993) PRISM (Cendrowska, 1987), SWAP-1 <ref> (Weiss & Indurkhya, 1991) </ref>, POSEIDON (Bergadano et al., 1992), PFOIL (Mooney, 1995), JoJo (Fensel & Wiese, 1993; Wiese, 1996) ATRIS (Kononenko & Kovacic, 1992; Mladenic, 1993) CiPF (Pfahringer, 1994a, 1994b) DLG (Webb, 1992; Webb & Agar, 1992), CLASS (Webb, 1993), SIA (Venturini, 1993) GROW (Cohen, 1993), RIPPER (Cohen, 1995), BEXA (Theron <p> This measure will attain its optimal value when no negative examples are covered. However, it does not aim at covering many positive examples. It is used in the GREEDY3 (Pagallo & Haussler, 1990) and SWAP-1 <ref> (Weiss & Indurkhya, 1991) </ref> algorithms. Information content: IC (r) = log p + n Sometimes the logarithm of the rule's purity is used, which measures the amount of information contained in the classification of the covered examples. This estimate is essentially used in PRISM (Cendrowska, 1987). <p> Other algorithms employ additional simplification operators like deleting each condition of a rule (Furnkranz & Widmer, 1994), deleting a final sequence of conditions (Cohen, 1993), finding the best replacement for a condition <ref> (Weiss & Indurkhya, 1991) </ref>, and extending and contracting internal disjunctions and intervals (Bergadano et al., 1992). If the accuracy of the best simplification is not below the accuracy of the unpruned theory, REP will continue to prune the new theory.
Reference: <author> Weiss, S. M., & Indurkhya, N. </author> <year> (1993). </year> <title> Rule-based regression. </title> <editor> In Bajcsy, R. (Ed.), </editor> <booktitle> Proceedings of the 13th International Joint Conference on Artificial Intelligence (IJCAI-93), </booktitle> <pages> pp. 1072-1078. </pages>
Reference-contexts: & Giordana, 1988), GA-SMART (Giordana & Sale, 1992), SMART+ (Botta & Giordana, 1993), FOCL (Pazzani & Kibler, 1992), GRENDEL (Cohen, 1994), GOLEM (Muggleton & Feng, 1990), NINA (Ade et al., 1995), PROGOL (Muggleton, 1995) functional relations: FILP (Bergadano & Gunetti, 1993), FFOIL (Quinlan, 1996) regression rules: IBL-SMART (Widmer, 1993) RULE <ref> (Weiss & Indurkhya, 1993, 1995) </ref>, FORS (Karalic, 1995) 3 F urnkranz Given: * a target concept, * positive and negative examples * described with several features and * optional background knowledge Find: * a simple set of rules that discriminates between (unseen) positive and negative examples of the target concept There
Reference: <author> Weiss, S. M., & Indurkhya, N. </author> <year> (1995). </year> <title> Rule-based machine learning methods for functional prediction. </title> <journal> Journal of Artificial Intelligence Research, </journal> <volume> 3, </volume> <pages> 383-403. </pages>
Reference-contexts: A numeric prediction for a new example is then derived by finding a rule that covers the example and using the numeric class variables of all other examples covered by that rule for deriving a prediction. RULE <ref> (Weiss & Indurkhya, 1995) </ref> and FORS (Karalic, 1995) are able to directly use real-valued 34 Separate-and-Conquer Rule Learning class variables. They employ a top-down hill-climbing algorithm for finding a rule body that minimizes an error function (like the mean squared error) on the prediction of the covered examples.
Reference: <author> Widmer, G. </author> <year> (1993). </year> <title> Combining knowledge-based and instance-based learning to exploit qualitative knowledge. </title> <journal> Informatica, </journal> <volume> 17, </volume> <pages> 371-385. </pages> <note> Special Issue on Multistrategy Learning. </note>
Reference-contexts: 1995), ML-SMART (Bergadano & Giordana, 1988), GA-SMART (Giordana & Sale, 1992), SMART+ (Botta & Giordana, 1993), FOCL (Pazzani & Kibler, 1992), GRENDEL (Cohen, 1994), GOLEM (Muggleton & Feng, 1990), NINA (Ade et al., 1995), PROGOL (Muggleton, 1995) functional relations: FILP (Bergadano & Gunetti, 1993), FFOIL (Quinlan, 1996) regression rules: IBL-SMART <ref> (Widmer, 1993) </ref> RULE (Weiss & Indurkhya, 1993, 1995), FORS (Karalic, 1995) 3 F urnkranz Given: * a target concept, * positive and negative examples * described with several features and * optional background knowledge Find: * a simple set of rules that discriminates between (unseen) positive and negative examples of the <p> For example, the basic induction algorithm of the SWAP-1 rule learning procedure checks whether dropping or replacing a previously learned condition can improve the rule's purity before it tries to improve it by adding a new condition. Similarly, IBL-SMART <ref> (Widmer, 1993) </ref> can perform a generalization step by dropping a condition whenever its top-down search leads to a rule that covers too few positive examples (according some predefined threshold). However, both algorithms preserve an overall top-down tendency in its search. <p> The key issue here is the definition of an appropriate evaluation criterion. This is a non-trivial issue, because the real-valued prediction of a regression rule will in general never be identical to the true value. In IBL-SMART <ref> (Widmer, 1993) </ref>, another algorithm from the ML-SMART family, this problem is solved by using a discretized class variable for learning.
Reference: <author> Wiese, M. </author> <year> (1996). </year> <title> A bidirectional ILP algorithm. </title> <booktitle> In Proceedings of the MLnet Familiarization Workshop on Data Mining with Inductive Logic Programming (ILP for KDD), </booktitle> <pages> pp. 61-72. </pages>
Reference-contexts: Recent additions allow the system to directly replace conditions in rules (Fensel & Wiese, 1994) and to use general first-order literals <ref> (Wiese, 1996) </ref>.
Reference: <author> Wnek, J., & Michalski, R. S. </author> <year> (1994). </year> <title> Hypothesis-driven constructive induction in AQ17-HCI: A method and experiments. </title> <journal> Machine Learning, </journal> <volume> 14 (2), </volume> <pages> 139-168. </pages> <note> Special Issue on Evaluating and Changing Representation. </note>
Reference-contexts: Based on these observations the wrapper changes the input representation or certain parameters of the learning algorithm to improve the result. The prototypical system for this approach is the AQ17-HCI algorithm <ref> (Wnek & Michalski, 1994) </ref>, which incorporates several constructive induction operators based on ideas used earlier in the INDUCE system (Michalski, 1980).
Reference: <author> Wolpert, D. H. </author> <year> (1993). </year> <title> On overfitting avoidance as bias. </title> <type> Tech. rep. SFI TR 92-03-5001, </type> <institution> The Santa Fe Institute, </institution> <address> Santa Fe, NM. </address>
Reference: <author> Zelle, J. M., Mooney, R. J., & Konvisser, J. B. </author> <year> (1994). </year> <title> Combining top-down and bottom-up techniques in inductive logic programming. </title> <editor> In Cohen, W., & Hirsh, H. (Eds.), </editor> <booktitle> Proceedings of the 11th International Conference on Machine Learning, </booktitle> <pages> pp. </pages> <address> 343-351 New Brunswick, NJ. </address> <publisher> Morgan Kaufmann. </publisher> <pages> 46 </pages>
Reference-contexts: Domingos (1996b) has named his method "conquering without separating". A similar approach has also been taken in the inductive logic programming algorithm CHILLIN <ref> (Zelle, Mooney, & Konvisser, 1994) </ref>, where rules are generalized by forming their least general generalization (Plotkin, 1970) and, if necessary, successively specialized using top-down hill-climbing as in FOIL.
References-found: 127

