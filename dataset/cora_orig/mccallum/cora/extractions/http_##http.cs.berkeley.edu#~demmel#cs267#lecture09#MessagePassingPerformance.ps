URL: http://http.cs.berkeley.edu/~demmel/cs267/lecture09/MessagePassingPerformance.ps
Refering-URL: http://http.cs.berkeley.edu/~demmel/cs267/lecture09/lecture09.html
Root-URL: http://www.cs.berkeley.edu
Title: Message-Passing Performance of Various Computers  
Author: Jack J. Dongarra Tom Dunigan 
Abstract: This report compares the performance of different computer systems for basic message passing. Latency and bandwidth are measured on Convex, Cray, IBM, Intel, KSR, Meiko, nCUBE, NEC, SGI, and TMC multiprocessors. Communication performance is contrasted with the computational power of each system. The comparison includes both shared and distributed memory computers as well as networked workstation clus ters.
Abstract-found: 1
Intro-found: 1
Reference: [1] <editor> HPCwire No. </editor> <volume> 4912 12/2/94, </volume> <year> 1994. </year> <title> Email exchange. </title>
Reference-contexts: Most high-end workstations can transmit 6 network data at or near media data rates (e.g., 12 MB/second for FDDI). Data rates of 73 MB/second for UDP have been reported between Crays on HiPPI (and even over a wide-area using seven OC3's) <ref> [1] </ref>. Latency and bandwidth will depend as much on the efficiency of the TCP/IP implementation as on the network interface hardware and media. As with multiprocessors, the number of times the message is touched is a critical parameter as is context-switch time.
Reference: [2] <author> J. Dongarra. </author> <title> Performance of various computers using standard linear equations software in a Fortran environment. </title> <type> Technical Report CS-89-85, </type> <institution> University of Tennessee, </institution> <year> 1995. </year>
Reference-contexts: At one time, a programmer had to go out of his way to code a matrix routine that would not run at nearly top efficiency on any system with an optimizing compiler. Owing to the proliferation of exotic computer architectures, this situation is no longer true. The LINPACK Benchmark <ref> [2] </ref> illustrates this point quite well. In practice, as Table 2 shows, there may be a significant difference between peak theoretical and actual performance 3.2 The LINPACK Benchmark The LINPACK benchmark features solving a system of linear equation, Ax = b.
Reference: [3] <author> T. H. Dunigan. </author> <title> Early experiences and performance of the intel paragon. </title> <type> Technical report, </type> <institution> Oak Ridge National Laboratory, </institution> <year> 1993. </year> <month> ORNL/TM-12194. </month>
Reference-contexts: On most current message-passing multiprocessors the per-hop delay is negligible due to "worm-hole" routing techniques and the small diameter of the communication network <ref> [3] </ref>. The results reported in this report reflect nearest-neighbor communication. A linear least-squares fit can be used to calculate ff and fi from experimental data of message-passing times versus message length. The start-up time, ff, may be slightly different than the zero-length time, and 1=fi should be asymptotic bandwidth.
Reference: [4] <author> Message Passing Interface Forum. </author> <title> MPI: A Message-Passing Interface Standard . International Journal of Supercomputer Applications and High Perf ormance Computing, </title> <type> 8(3/4), </type> <year> 1994. </year> <note> Special issue on MPI. Also available electronically, the url is ftp://www.netlib.org/mpi/mpi-report.ps. </note>
Reference-contexts: Communications and Parallel Processing Systems This report compares the results of a set of benchmarks for measuring communication time on a number of NUMA computers ranging from a collection of workstations using PVM [5] to machines like the IBM SP-2 and the Cray T3D using their native communication library, MPI <ref> [4] </ref>, or PVM. We are interested in the communication performance for a number of reasons. First, our main interest is to obtain fundamental parameters on a given hardware platform to help in building models of execution. <p> In running the tests, the user is allowed to change the message passing calls to the appropriate call on the specific system the program is to be run on. We have provided both PVM and MPI <ref> [4] </ref> implementations in netlib. 13 4.2 Obtaining the Software The software used to generate the data for this report can be obtained by sending electronic mail to netlib@www.netlib.org . To receive the single-precision software for this benchmark, in the mail message to netlib@www.netlib.org type send comm.shar from benchmark .
Reference: [5] <author> A. Geist, A. Beguelin, J. Dongarra, W. Jiang, R. Manchek, and V. Sunderam. </author> <title> PVM: </title>
Reference-contexts: software, amount of memory, and by the speed of the processors and of the interconnecting network. 1.2 Communications and Parallel Processing Systems This report compares the results of a set of benchmarks for measuring communication time on a number of NUMA computers ranging from a collection of workstations using PVM <ref> [5] </ref> to machines like the IBM SP-2 and the Cray T3D using their native communication library, MPI [4], or PVM. We are interested in the communication performance for a number of reasons.
References-found: 5

