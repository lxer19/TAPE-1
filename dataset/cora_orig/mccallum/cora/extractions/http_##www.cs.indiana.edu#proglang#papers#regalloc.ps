URL: http://www.cs.indiana.edu/proglang/papers/regalloc.ps
Refering-URL: http://www.cs.indiana.edu/proglang/proglang.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: fburger,owaddell,dybg@cs.indiana.edu  
Title: Register Allocation Using Lazy Saves, Eager Restores, and Greedy Shu*ing  
Author: Robert G. Burger Oscar Waddell R. Kent Dybvig 
Address: Lindley Hall 215 Bloomington, Indiana 47405  
Affiliation: Indiana University Computer Science Department  
Abstract: This paper presents a fast and effective linear intraprocedu-ral register allocation strategy that optimizes register usage across procedure calls. It capitalizes on our observation that while procedures that do not contain calls (syntactic leaf routines) account for under one third of all procedure activations, procedures that actually make no calls (effective leaf routines) account for over two thirds of all procedure activations. Well-suited for both caller- and callee-save registers, our strategy employs a "lazy" save mechanism that avoids saves for all effective leaf routines, an "eager" restore mechanism that reduces the effect of memory latency, and a "greedy" register shu*ing algorithm that does a remarkably good job of minimizing the need for temporaries in setting up procedure calls. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Andrew W. Appel and Zhong Shao. </author> <title> Callee-save registers in continuation-passing style. </title> <journal> Lisp and Symbolic Computation, </journal> <volume> 5(3) </volume> <pages> 191-221, </pages> <year> 1992. </year>
Reference-contexts: Although [12] describes a register shu*ing algorithm similar to ours, details regarding the selection of the node used to break cycles are not given. Shao and Appel <ref> [13, 1] </ref> have developed a closure conversion algorithm that exploits control and data flow information to obtain extensive closure sharing. This sharing enhances the benefit they obtain from allocating closures in registers.
Reference: [2] <author> Anders Bondorf. </author> <note> Similix Manual, System Version 5.0. </note> <institution> DIKU, University of Copenhagen, Denmark, </institution> <year> 1993. </year>
Reference-contexts: In Section 2.4 we explain how our strategy applies to callee-save registers. Benchmark Lines Description Compiler 30,000 Chez Scheme recompiling itself DDD 15,000 hardware derivation system [3] deriving Scheme machine [4] Similix 7,000 self-application of the Similix <ref> [2] </ref> partial evaluator SoftScheme 10,000 Wright's soft typer [15] checking a 2,500 line program Table 1. E ! x ! true ! false ! call ! (seq E 1 E 2 ) We assume that assignment conversion has already been done, so there are no assignment expressions.
Reference: [3] <author> Bhaskar Bose. </author> <title> DDD|A transformation system for Digital Design Derivation. </title> <type> Technical Report 331, </type> <institution> Indiana University, Computer Science Department, </institution> <month> May </month> <year> 1991. </year>
Reference-contexts: In Section 2.4 we explain how our strategy applies to callee-save registers. Benchmark Lines Description Compiler 30,000 Chez Scheme recompiling itself DDD 15,000 hardware derivation system <ref> [3] </ref> deriving Scheme machine [4] Similix 7,000 self-application of the Similix [2] partial evaluator SoftScheme 10,000 Wright's soft typer [15] checking a 2,500 line program Table 1.
Reference: [4] <author> Robert G. Burger. </author> <title> The Scheme Machine. </title> <type> Technical Report 413, </type> <institution> Indiana University, Computer Science Department, </institution> <month> August </month> <year> 1994. </year>
Reference-contexts: In Section 2.4 we explain how our strategy applies to callee-save registers. Benchmark Lines Description Compiler 30,000 Chez Scheme recompiling itself DDD 15,000 hardware derivation system [3] deriving Scheme machine <ref> [4] </ref> Similix 7,000 self-application of the Similix [2] partial evaluator SoftScheme 10,000 Wright's soft typer [15] checking a 2,500 line program Table 1.
Reference: [5] <author> G. J. Chaitin, M. A. Auslander, A. K. Cocke, M. E. Hopkins, and P. W. Markstein. </author> <title> Register allocation via coloring. </title> <journal> Computer Languages, </journal> <volume> 6 </volume> <pages> 47-57, </pages> <year> 1981. </year>
Reference-contexts: 1 Introduction Register allocation, the complex problem of deciding which values will be held in which registers over what portions of the program, encompasses several interrelated sub-problems. Perhaps the most well-known of these is to decide which variables to assign to registers so that there is no conflict <ref> [5] </ref>. Another involves splitting live ranges of variables in order to reduce conflicts. These problems have been addressed for both intraprocedural and interprocedural register allocation. Optimizing register usage across procedure calls is also an important problem, but up to now it has been addressed primarily in terms of interprocedural analysis. <p> Performance increases monotonically from zero through six registers, although the difference between five and six registers is minimal. Our greedy shu*ing algorithm becomes important as the number of argument registers increases. Before we installed this algorithm, the performance actually decreased after two argument registers. 5 Related Work Graph coloring <ref> [5] </ref> has become the basis for most modern register allocation strategies. Several improvements to graph coloring have been made to reduce expense, to determine which variables should receive highest priority for available registers, and to handle interprocedural register allocation.
Reference: [6] <author> F. Chow. </author> <title> Minimizing register usage penalty at procedure calls. </title> <booktitle> In Proceedings of the SIGPLAN '88 Conference on Programming Language Design and Implementation, </booktitle> <month> June </month> <year> 1988. </year>
Reference-contexts: Consequently, if ret 2 S t [E] " S f [E], 2 then E will inevitably make a call, but if ret 62 S t [E] " S f [E], then E contains a path without any calls. Chow <ref> [6] </ref> describes a related technique called "shrink wrapping" to move the saves and restores of callee-save registers to regions where the registers are active. His technique, however, is applied after variables have been assigned to callee-save registers. <p> In order to improve procedure call behavior, incoming and outgoing parameters are "pre-colored" with argument registers. The priority-coloring algorithm is able to make effective use of caller-save registers for syntactic leaf procedures, preferring callee-save registers for the rest. Chow <ref> [6] </ref> extends the priority-based coloring algorithm to an interprocedural register allocator designed to minimize register use penalties at procedure calls. He provides a mechanism for propagating saves and restores of callee-save registers to the upper regions of the call graph. <p> Our baseline for comparison is efficient code generated by an optimizing compiler that already makes extensive use of global registers and local register allocation. This is within range of improvements reported for interprocedural register allocation <ref> [14, 6] </ref>. Although the compiler now spends around 7% of its time on register allocation, the compiler actually runs faster since it is self-compiled and benefits from its own register allocation strategy.
Reference: [7] <author> Fred C. Chow and John L. Hennessy. </author> <title> The priority-based coloring approach to register allocation. </title> <journal> Transactions on Programming Languages and Systems, </journal> <volume> 12(4) </volume> <pages> 501-536, </pages> <month> October </month> <year> 1990. </year>
Reference-contexts: Steenkiste and Hennessy found that an average of 36% of calls at run time are to (syntactic) leaf routines; this is similar to our findings of an average slightly below one third. They did not identify or measure the frequency of calls to effective leaf routines. Chow and Hennessy <ref> [7] </ref> present an intraprocedural algorithm that addresses certain shortcomings of straightforward graph coloring. In their approach, coloring of the register interference graph is ordered by an estimate of total run-time savings from allocating a live range to a register, normalized by the size of the region occupied.
Reference: [8] <editor> William Clinger and Jonathan Rees (editors). </editor> <title> Revised 4 report on the algorithmic language Scheme. LISP Pointers, </title> <address> IV(3):1-55, </address> <month> July-September </month> <year> 1991. </year>
Reference-contexts: Section 5 describes related work. Section 6 summarizes our results and discusses possibilities for future work. 2 Save and Restore Placement For purposes of discussion we describe our strategy for save and restore placement in terms of caller-save registers and the simplified language of expressions based on Scheme <ref> [8] </ref> below. In Section 2.4 we explain how our strategy applies to callee-save registers.
Reference: [9] <author> William D. Clinger and Lars Thomas Hansen. </author> <title> Lambda, the ultimate label, or a simple optimizing compiler for Scheme. </title> <booktitle> In Proceedings of the 1994 ACM Conference on LISP and Functional Programming, </booktitle> <pages> pages 128-139, </pages> <year> 1994. </year>
Reference-contexts: We pick as the last complex argument one on which none of the simple arguments depend (if such a complex argument exists), since it can be evaluated directly into its argument register. Ordering the simple arguments is a problem of optimizing parallel assignments, as noted in <ref> [9, 12] </ref>. We build the dependency graph and essentially perform a topological sort. If we detect a cycle, we find the argument causing the largest number of dependencies and remove it, placing it into a temporary location, in hopes of breaking the cycle. <p> Chow also claims that interprocedural register allocation requires a large number of registers in order to have a noticeable impact; the 20 available to his algorithm were inadequate for large benchmarks. Clinger and Hansen <ref> [9] </ref> describe an optimizing compiler for Scheme which achieves respectable performance through a combination of aggressive lambda-lifting and parallel assignment optimization. Lambda lifting transforms the free variables of a procedure into extra arguments, decreasing closure creation cost and increasing the number of arguments subject to register allocation. <p> Preliminary experiments suggest that this results in a small (2-3%) but consistent improvement. Other researchers have investigated the use of lambda lifting to increase the number of arguments available for placement in registers <ref> [13, 9] </ref>. While lambda lifting can easily result in net performance decreases, it is worth investigating whether lambda lifting with an appropriate set of heuristics such as those described in [13] can indeed increase the effectiveness of our register allocator without significantly increasing compile time.
Reference: [10] <author> Richard P. Gabriel. </author> <title> Performance and Evaluation of LISP Systems. </title> <publisher> MIT Press series in computer systems. MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1985. </year>
Reference-contexts: In order to minimize redundant saves, therefore, our strategy saves registers as soon as a call is inevitable. Table 2 gives the results of our measurements for a set of benchmarks described in Table 1 and for a Scheme version of the Gabriel benchmark suite <ref> [10] </ref>. Effective leaf routines are classified as syntactic and non-syntactic leaf nodes. Non-syntactic internal nodes are activations of procedures that have paths without calls but make calls at run time, and syntactic internal nodes are those that have no paths without calls.
Reference: [11] <author> Robert Hieb, R. Kent Dybvig, and Carl Bruggeman. </author> <title> Representing control in the presence of first-class continuations. </title> <booktitle> In Proceedings of the SIGPLAN '90 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 66-77, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: Our Scheme code actually outperforms optimized C code for this benchmark despite the additional overhead of our stack overflow checks <ref> [11] </ref> and poorer low-level instruction scheduling. Part of the performance advantage for the Scheme version is due to our compiler's use of caller-save registers, which turns out to be slightly better for this benchmark.
Reference: [12] <author> David Kranz. </author> <title> Orbit: an optimizing compiler for Scheme. </title> <type> Technical Report 632, </type> <institution> Yale University, Computer Science Department, </institution> <year> 1988. </year>
Reference-contexts: We pick as the last complex argument one on which none of the simple arguments depend (if such a complex argument exists), since it can be evaluated directly into its argument register. Ordering the simple arguments is a problem of optimizing parallel assignments, as noted in <ref> [9, 12] </ref>. We build the dependency graph and essentially perform a topological sort. If we detect a cycle, we find the argument causing the largest number of dependencies and remove it, placing it into a temporary location, in hopes of breaking the cycle. <p> Their shu*ing algorithm is similar to ours in that it attempts to find an ordering that will not require the introduction of temporaries but differs in that any cycle causes a complete spill of all arguments into temporary stack locations. Although <ref> [12] </ref> describes a register shu*ing algorithm similar to ours, details regarding the selection of the node used to break cycles are not given. Shao and Appel [13, 1] have developed a closure conversion algorithm that exploits control and data flow information to obtain extensive closure sharing.
Reference: [13] <author> Zhong Shao and Andrew W. Appel. </author> <title> Space-efficient closure representations. </title> <booktitle> In Proceedings of the 1994 ACM Conference on LISP and Functional Programming, </booktitle> <pages> pages 150-161, </pages> <year> 1994. </year>
Reference-contexts: Although [12] describes a register shu*ing algorithm similar to ours, details regarding the selection of the node used to break cycles are not given. Shao and Appel <ref> [13, 1] </ref> have developed a closure conversion algorithm that exploits control and data flow information to obtain extensive closure sharing. This sharing enhances the benefit they obtain from allocating closures in registers. <p> Preliminary experiments suggest that this results in a small (2-3%) but consistent improvement. Other researchers have investigated the use of lambda lifting to increase the number of arguments available for placement in registers <ref> [13, 9] </ref>. While lambda lifting can easily result in net performance decreases, it is worth investigating whether lambda lifting with an appropriate set of heuristics such as those described in [13] can indeed increase the effectiveness of our register allocator without significantly increasing compile time. <p> While lambda lifting can easily result in net performance decreases, it is worth investigating whether lambda lifting with an appropriate set of heuristics such as those described in <ref> [13] </ref> can indeed increase the effectiveness of our register allocator without significantly increasing compile time. Acknowledgement: The authors would like to thank Mike Ashley for his helpful comments on an earlier version of this paper.
Reference: [14] <author> P. A. Steenkiste and J. L. Hennessy. </author> <title> A simple interpro-cedural register allocation algorithm and its effectiveness for Lisp. </title> <journal> Transactions on Programming Languages and Systems, </journal> <volume> 11(1) </volume> <pages> 1-32, </pages> <month> January </month> <year> 1989. </year>
Reference-contexts: Several improvements to graph coloring have been made to reduce expense, to determine which variables should receive highest priority for available registers, and to handle interprocedural register allocation. Steenkiste and Hennessy <ref> [14] </ref> implemented a combined intraprocedural and interprocedural register allocator for Lisp that assigns registers based on a bottom-up coloring of a simplified interprocedural control flow graph. They handle cycles in the call graph and links to anonymous procedures by introducing additional saves and restores at procedure call boundaries. <p> Our baseline for comparison is efficient code generated by an optimizing compiler that already makes extensive use of global registers and local register allocation. This is within range of improvements reported for interprocedural register allocation <ref> [14, 6] </ref>. Although the compiler now spends around 7% of its time on register allocation, the compiler actually runs faster since it is self-compiled and benefits from its own register allocation strategy.
Reference: [15] <author> Andrew K. Wright and Robert Cartwright. </author> <title> A practical soft type system for Scheme. </title> <booktitle> In Proceedings of the 1994 ACM Conference on LISP and Functional Programming, </booktitle> <pages> pages 250-262, </pages> <year> 1994. </year> <month> 9 </month>
Reference-contexts: In Section 2.4 we explain how our strategy applies to callee-save registers. Benchmark Lines Description Compiler 30,000 Chez Scheme recompiling itself DDD 15,000 hardware derivation system [3] deriving Scheme machine [4] Similix 7,000 self-application of the Similix [2] partial evaluator SoftScheme 10,000 Wright's soft typer <ref> [15] </ref> checking a 2,500 line program Table 1. E ! x ! true ! false ! call ! (seq E 1 E 2 ) We assume that assignment conversion has already been done, so there are no assignment expressions. All constants are reduced to either true or false.
References-found: 15

