URL: http://polaris.cs.uiuc.edu/reports/1390.ps.gz
Refering-URL: http://polaris.cs.uiuc.edu/polaris/rep2.html
Root-URL: http://www.cs.uiuc.edu
Email: email: rwerger@csrd.uiuc.edu  
Phone: telephone: (217) 244-0070  fax: (217) 244-1351  
Title: The LRPD Test: Speculative Run-Time Parallelization of Loops with Privatization and Reduction Parallelization  
Author: Lawrence Rauchwerger and David Padua 
Note: Corresponding Author: Lawrence Rauchwerger  Research supported in part by Intel and NASA Graduate Fellowships, and Army contract #DABT63-92-C-0033. This work is not necessarily representative of the positions or policies of the Army or the Government.  
Address: 1308 W. Main St., Urbana, IL 61801  
Affiliation: Center for Supercomputing Research and Development University of Illinois at Urbana-Champaign  
Abstract: Current parallelizing compilers cannot identify a significant fraction of parallelizable loops because they have complex or statically insufficiently defined access patterns. As parallelizable loops arise frequently in practice, we advocate a novel framework for their identification: speculatively execute the loop as a doall, and apply a fully parallel data dependence test to determine if it had any cross-iteration dependences; if the test fails, then the loop is re-executed serially. Since, from our experience, a significant amount of the available parallelism in Fortran programs can be exploited by loops transformed through privatization and reduction parallelization, our methods can speculatively apply these transformations and then check their validity at run-time. Another important contribution of this paper is a novel method for reduction recognition which goes beyond syntactic pattern matching: it detects at run-time if the values stored in an array participate in a reduction operation, even if they are transferred through private variables and/or are affected by statically unpredictable control flow. We present experimental results on loops from the PERFECT Benchmarks which substantiate our claim that these techniques can yield significant speedups which are often superior to those obtainable by inspector/executor methods. The methods presented in this paper differ from and extend our previous work on several important points. First, instead of distributing the loop into inspector and executor loops (the approach taken in all previous work on run-time parallelization) we advocate the use of run-time tests to validate the execution of a loop that is speculatively executed in parallel. Second, in addition to array privatization, the new techniques are capable of testing the validity of the powerful reduction parallelization transformation at run-time. Finally, the new algorithms consider only data dependences caused by actual cross-iteration data-flow (a flow of values) and thus potentially qualify more loops as parallel than possible with our previous run-time data dependence test. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. Abraham. </author> <title> Private communication, </title> <year> 1994. </year>
Reference-contexts: In fact, using private shadow structures enables some additional optimization of the LPD test as follows. Since the shadow structures are private to each processor, 3 any returns the OR of its vector operand's elements, i.e., any (v [1 : n]) = (v <ref> [1] </ref> _ v [2] _ : : : _ v [n]). 6 the iteration number can be used as the mark. <p> In the marking phase of the test, i.e., during the speculative parallel execution of the loop, any array element defined or used outside the reduction statement is invalidated as a reduction variable, i.e., its 4 This fact was noted by Santosh Abraham <ref> [1] </ref>. 7 do i=1,n S2: .... = A (L (i)) enddo (a) doall i=1,n markwrite (K (i)) markredux (K (i)) S1: A (K (i)) = .... markread (L (i)) markredux (L (i)) S2: .... = A (L (i)) markwrite (R (i)) S3: A (R (i)) = A (R (i)) + exp
Reference: [2] <author> J. R. Allen, K. Kennedy, C. Porterfield, and J. Warren. </author> <title> Conversion of control dependence to data dependence. </title> <booktitle> In Proceedings of the 10th ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 177-189, </pages> <month> January </month> <year> 1983. </year>
Reference-contexts: In fact, using private shadow structures enables some additional optimization of the LPD test as follows. Since the shadow structures are private to each processor, 3 any returns the OR of its vector operand's elements, i.e., any (v [1 : n]) = (v [1] _ v <ref> [2] </ref> _ : : : _ v [n]). 6 the iteration number can be used as the mark. <p> The general strategy of our methods is a fairly straightforward demand driven forward substitution of all the variables on the RHS, a process by which all control flow dependences are substituted by data dependences as described in <ref> [2, 32] </ref>. Once this expression of the RHS is obtained it can be analyzed and validated by the methods described in the previous section.
Reference: [3] <institution> Alliant Computer Systems Corporation, 42 Nagog Park, Acton, Massachusetts 01720. FX/Series Architecture Manual, </institution> <year> 1986. </year> <title> Part Number: </title> <publisher> 300-00001-B. </publisher>
Reference-contexts: Similarly, using hash tables the analysis phase and any needed last value assignments and/or processor-wise reduction operations can be performed in time O (na=p + log p). 5 Experimental Results In this section we present experimental results obtained on two modestly parallel machines with 8 (Alliant FX/80 <ref> [3] </ref>) and 14 processors (Alliant FX/2800 [4]) using a Fortran implementation of our methods. However, we remark that our results scale with the number of processors and the data size and thus they should be extrapolated for massively parallel processors (MPPs), the actual target of our run-time methods.
Reference: [4] <institution> Alliant Computers Systems Corporation. Alliant FX/2800 Series System Description, </institution> <year> 1991. </year>
Reference-contexts: tables the analysis phase and any needed last value assignments and/or processor-wise reduction operations can be performed in time O (na=p + log p). 5 Experimental Results In this section we present experimental results obtained on two modestly parallel machines with 8 (Alliant FX/80 [3]) and 14 processors (Alliant FX/2800 <ref> [4] </ref>) using a Fortran implementation of our methods. However, we remark that our results scale with the number of processors and the data size and thus they should be extrapolated for massively parallel processors (MPPs), the actual target of our run-time methods.
Reference: [5] <author> R. Ballance, A. Maccabe, and K. Ottenstein. </author> <title> The Program Dependence Web: a Representation Supporting Control Data- and Demand-Driven Interpretation of Imperative Languages. </title> <booktitle> In Proceedings of the SIGPLAN'90 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 257-271, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: What is known, however, is the set of all possible RHS forms, which can be computed by following all potential paths in the control flow graph. A direct approach uses a gated static single assignment (GSSA) <ref> [5, 33] </ref> representation of the program. In such a representation, scalar variables are assigned only once.
Reference: [6] <author> U. Banerjee. </author> <title> Dependence Analysis for Supercomputing. </title> <publisher> Kluwer. </publisher> <address> Boston, MA., </address> <year> 1988. </year>
Reference-contexts: In order to determine whether or not the execution order of the data accesses affects the semantics of the loop, the data dependence relations between the statements in the loop body must be analyzed <ref> [6, 17, 24, 34, 37] </ref>. There are three possible types of dependences between two statements that access the same memory location: flow (read after write), anti (write after read), and output (write after write). Flow dependences express a fundamental relationship about the data flow in the program.
Reference: [7] <author> M. Berry, D. Chen, P. Koss, D. Kuck, S. Lo, Y. Pang, R. Roloff, A. Sameh, E. Clementi, S. Chin, D. Schneider, G. Fox, P. Messina, D. Walker, C. Hsiung, J. Schwarzmeier, K. Lue, S. Orzag, F. Seidl, O. Johnson, G. Swanson, R. Goodrum, and J. Martin. </author> <title> The PERFECT club benchmarks: Effective performance evaluation of supercomputers. </title> <type> Technical Report CSRD-827, </type> <institution> Center for Supercomputing Research and Development, University of Illinois, Urbana, IL, </institution> <month> May </month> <year> 1989. </year>
Reference-contexts: However, we remark that our results scale with the number of processors and the data size and thus they should be extrapolated for massively parallel processors (MPPs), the actual target of our run-time methods. We considered seven do loops from the PERFECT Benchmarks <ref> [7] </ref> that could not be parallelized by any compiler available to us. Our results are summarized in Table 1.
Reference: [8] <author> H. Berryman and J. Saltz. </author> <title> A manual for PARTI runtime primitives. </title> <type> Interim Report 90-13, </type> <institution> ICASE, </institution> <year> 1990. </year> <month> 16 </month>
Reference-contexts: developing methods for constructing execution schedules for partially parallel loops, i.e., loops whose parallelization requires synchronization to ensure that the iterations are executed in the correct order. 1 These methods are centered around the extraction of an inspector loop that analyzes the data access pattern off-line, i.e., without side effects <ref> [8, 19, 22, 26, 27, 28, 29, 35, 36] </ref>. The inspection phase of these schemes usually yields a partitioning of the set of iterations into subsets that can be executed in parallel. These subsets, sometimes called wavefronts, are scheduled sequentially by placing synchronization barriers between them.
Reference: [9] <author> W. Blume and R. Eigenmann. </author> <title> Performance Analysis of Parallelizing Compilers on the Perfect Benchmarks T M Programs. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 3(6) </volume> <pages> 643-656, </pages> <month> November </month> <year> 1992. </year>
Reference-contexts: Thus, in order to realize the full potential of parallel computing it has become clear that static (compile-time) analysis must be complemented by new methods capable of automatically extracting parallelism at run-time <ref> [9, 11, 13] </ref>. Run-time techniques can succeed where static compilation fails because they have access to the input data. For example, input dependent or dynamic data distribution, memory accesses guarded by run-time dependent conditions, and subscript expressions can all be analyzed unambiguously at run-time.
Reference: [10] <author> M. Burke, R. Cytron, J. Ferrante, and W. Hsieh. </author> <title> Automatic generation of nested, fork-join parallelism. </title> <journal> Journal of Supercomputing, </journal> <pages> pages 71-88, </pages> <year> 1989. </year>
Reference-contexts: Privatization creates, for each processor cooperating on the execution of the loop, private copies of the program variables that give rise to anti or output dependences (see, e.g., <ref> [10, 20, 21, 31, 32] </ref>).
Reference: [11] <author> W. J. Camp, S. J. Plimpton, B. A. Hendrickson, and R. W. Leland. </author> <title> Massively parallel methods for engineering and science problems. </title> <journal> Comm. ACM, </journal> <volume> 37(4) </volume> <pages> 31-41, </pages> <month> April </month> <year> 1994. </year>
Reference-contexts: Typical examples are complex simulations such as SPICE for circuit simulation, DYNA-3D and PRONTO-3D for structural mechanics modeling, GAUSSIAN and DMOL for quantum mechanical simulation of molecules, CHARMM and DISCOVER for molecular dynamics simulation of organic systems, and FIDAP for modeling complex fluid flows <ref> [11] </ref>. Thus, in order to realize the full potential of parallel computing it has become clear that static (compile-time) analysis must be complemented by new methods capable of automatically extracting parallelism at run-time [9, 11, 13]. <p> Thus, in order to realize the full potential of parallel computing it has become clear that static (compile-time) analysis must be complemented by new methods capable of automatically extracting parallelism at run-time <ref> [9, 11, 13] </ref>. Run-time techniques can succeed where static compilation fails because they have access to the input data. For example, input dependent or dynamic data distribution, memory accesses guarded by run-time dependent conditions, and subscript expressions can all be analyzed unambiguously at run-time.
Reference: [12] <author> A. Dinning and E. Schonberg. </author> <title> An empirical comparison of monitoring algorithms for access anomaly detection. </title> <booktitle> In Proc. </booktitle> <pages> ACM ???, pages 1-10, </pages> <year> 1990. </year>
Reference-contexts: Run-time analysis techniques have also been used to detect access anomalies or race conditions in parallel programs (see, e.g., <ref> [12, 23, 30] </ref>).
Reference: [13] <author> R. Eigenmann, J. Hoeflinger, Z. Li, and D. Padua. </author> <title> Experience in the Automatic Parallelization of Four Perfect-Benchmark Programs. </title> <booktitle> Lecture Notes in Computer Science 589. Proceedings of the Fourth Workshop on Languages and Compilers for Parallel Computing, </booktitle> <address> Santa Clara, CA, </address> <pages> pages 65-83, </pages> <month> August </month> <year> 1991. </year>
Reference-contexts: Thus, in order to realize the full potential of parallel computing it has become clear that static (compile-time) analysis must be complemented by new methods capable of automatically extracting parallelism at run-time <ref> [9, 11, 13] </ref>. Run-time techniques can succeed where static compilation fails because they have access to the input data. For example, input dependent or dynamic data distribution, memory accesses guarded by run-time dependent conditions, and subscript expressions can all be analyzed unambiguously at run-time. <p> One typical method is to transform the do loop into a doall and enclose the access to the reduction variable in an unordered critical section <ref> [13, 37] </ref>. Drawbacks of this method are that it is not scalable and requires synchronizations which can be very expensive in large multiprocessor systems.
Reference: [14] <author> V. Krothapalli and P. Sadayappan. </author> <title> An approach to synchronization of parallel computing. </title> <booktitle> In Proceedings of the 1988 International Conference on Supercomputing, </booktitle> <pages> pages 573-581, </pages> <month> June </month> <year> 1988. </year>
Reference-contexts: Compilers often transform programs to optimize performance. The two most effective transformations for increasing the amount of parallelism in a loop (i.e., removing certain types of data dependences) are array privatization and reduction parallelization. Krothapalli and Sadayappan <ref> [14] </ref> proposed an inspector method for run-time privatization which relies heavily on synchronizaton, inserts an additional level of indirection into all memory accesses, and calls for dynamic shared memory allocation.
Reference: [15] <author> C. Kruskal. </author> <title> Efficient parallel algorithms for graph problems. </title> <month> August </month> <year> 1985. </year>
Reference-contexts: A scalable method can be obtained by noting that a reduction operation is an associative and commutative recurrence and can thus be parallelized using a recursive doubling algorithm <ref> [15, 16, 18] </ref>.
Reference: [16] <author> C. Kruskal. </author> <title> Efficient parallel algorithms for graph problems. </title> <address> pages 869-876, </address> <month> August </month> <year> 1986. </year>
Reference-contexts: A scalable method can be obtained by noting that a reduction operation is an associative and commutative recurrence and can thus be parallelized using a recursive doubling algorithm <ref> [15, 16, 18] </ref>.
Reference: [17] <author> D. J. Kuck, R. H. Kuhn, D. A. Padua, B. Leasure, and M. Wolfe. </author> <title> Dependence graphs and compiler optimizations. </title> <booktitle> In Proceedings of the 8th ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 207-218, </pages> <month> January </month> <year> 1981. </year>
Reference-contexts: In order to determine whether or not the execution order of the data accesses affects the semantics of the loop, the data dependence relations between the statements in the loop body must be analyzed <ref> [6, 17, 24, 34, 37] </ref>. There are three possible types of dependences between two statements that access the same memory location: flow (read after write), anti (write after read), and output (write after write). Flow dependences express a fundamental relationship about the data flow in the program.
Reference: [18] <author> F. Thomson Leighton. </author> <title> Introduction to Parallel Algorithms and Architectures: Arrays, Trees, Hypercubes. </title> <publisher> Morgan Kaufmann, </publisher> <year> 1992. </year>
Reference-contexts: A scalable method can be obtained by noting that a reduction operation is an associative and commutative recurrence and can thus be parallelized using a recursive doubling algorithm <ref> [15, 16, 18] </ref>. <p> The counting in Step 2 (a) can be done in parallel by giving each processor s=p values to add within its private memory, 13 and then summing the p resulting values in global storage, which takes O (s=p + log p) time <ref> [18] </ref>. The comparisons in Step 2 (b) (2 (d)) of A w with A r (with A np and A nx ) take O (s=p + log p) time.
Reference: [19] <author> S. Leung and J. Zahorjan. </author> <title> Improving the performance of runtime parallelization. </title> <booktitle> In 4th PPOPP, </booktitle> <pages> pages 83-91, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: Although more powerful analysis techniques could remove this last limitation when the index arrays are computed using only statically-known values, nothing can be done at compile-time when the index arrays are a function of the input data <ref> [19, 29, 36] </ref>. <p> developing methods for constructing execution schedules for partially parallel loops, i.e., loops whose parallelization requires synchronization to ensure that the iterations are executed in the correct order. 1 These methods are centered around the extraction of an inspector loop that analyzes the data access pattern off-line, i.e., without side effects <ref> [8, 19, 22, 26, 27, 28, 29, 35, 36] </ref>. The inspection phase of these schemes usually yields a partitioning of the set of iterations into subsets that can be executed in parallel. These subsets, sometimes called wavefronts, are scheduled sequentially by placing synchronization barriers between them.
Reference: [20] <author> Zhiyuan Li. </author> <title> Array privatization for parallel execution of loops. </title> <booktitle> In Proceedings of the 19th International Symposium on Computer Architecture, </booktitle> <pages> pages 313-322, </pages> <year> 1992. </year>
Reference-contexts: Privatization creates, for each processor cooperating on the execution of the loop, private copies of the program variables that give rise to anti or output dependences (see, e.g., <ref> [10, 20, 21, 31, 32] </ref>).
Reference: [21] <author> D. E. Maydan, S. P. Amarasinghe, and M. S. Lam. </author> <title> Data dependence and data-flow analysis of arrays. </title> <booktitle> In Proceedings 5th Workshop on Programming Languages and Compilers for Parallel Computing, </booktitle> <month> August </month> <year> 1992. </year>
Reference-contexts: Privatization creates, for each processor cooperating on the execution of the loop, private copies of the program variables that give rise to anti or output dependences (see, e.g., <ref> [10, 20, 21, 31, 32] </ref>).
Reference: [22] <author> S. Midkiff and D. Padua. </author> <title> Compiler algorithms for synchronization. </title> <journal> IEEE Trans. Comput., </journal> <volume> C-36(12):1485-1495, </volume> <year> 1987. </year>
Reference-contexts: developing methods for constructing execution schedules for partially parallel loops, i.e., loops whose parallelization requires synchronization to ensure that the iterations are executed in the correct order. 1 These methods are centered around the extraction of an inspector loop that analyzes the data access pattern off-line, i.e., without side effects <ref> [8, 19, 22, 26, 27, 28, 29, 35, 36] </ref>. The inspection phase of these schemes usually yields a partitioning of the set of iterations into subsets that can be executed in parallel. These subsets, sometimes called wavefronts, are scheduled sequentially by placing synchronization barriers between them.
Reference: [23] <author> I. Nudler and L. Rudolph. </author> <title> Tools for the efficient developement of efficient parallel programs. </title> <booktitle> In Proc. 1st Israeli Conference on Computer System Engineering, </booktitle> <year> 1988. </year>
Reference-contexts: Run-time analysis techniques have also been used to detect access anomalies or race conditions in parallel programs (see, e.g., <ref> [12, 23, 30] </ref>).
Reference: [24] <author> D. A. Padua and M. J. Wolfe. </author> <title> Advanced compiler optimizations for supercomputers. </title> <journal> Communications of the ACM, </journal> <volume> 29 </volume> <pages> 1184-1201, </pages> <month> December </month> <year> 1986. </year>
Reference-contexts: Restructuring, or parallelizing, compilers address these problems by detecting and exploiting parallelism in sequential programs written in conventional languages. Although compiler techniques for the automatic detection of parallelism have been studied extensively over the last two decades (see, e.g., <ref> [24, 34] </ref>), current parallelizing compilers cannot extract a significant fraction of the available parallelism in a loop if it has a complex and/or statically insufficiently defined access pattern. <p> In order to determine whether or not the execution order of the data accesses affects the semantics of the loop, the data dependence relations between the statements in the loop body must be analyzed <ref> [6, 17, 24, 34, 37] </ref>. There are three possible types of dependences between two statements that access the same memory location: flow (read after write), anti (write after read), and output (write after write). Flow dependences express a fundamental relationship about the data flow in the program.
Reference: [25] <author> L. Rauchwerger and D. Padua. </author> <title> The privatizing doall test: A run-time technique for doall loop identification and array privatization. </title> <booktitle> In Proceedings of the 1994 International Conference on Supercomputing, </booktitle> <pages> pages 33-43, </pages> <month> July </month> <year> 1994. </year>
Reference-contexts: The ideal speedup of loop 40 is not very large since the loop is small, imbalanced between iterations, and traverses a linked list. The linked list traversal was parallelized using techniques we developed for automatically parallelizing while loops <ref> [25] </ref>. Thus, although the obtained speedup is modest, it represents a significant fraction of the ideal speedup (see Fig. 14). Therefore, since loop 40 is one of the smallest loops in the LOAD subroutine, we expect to obtain better speedups on the larger loops (since they have larger ideal speedups).
Reference: [26] <author> J. Saltz and R. Mirchandaney. </author> <title> The preprocessed doacross loop. In Dr. </title> <editor> H.D. Schwetman, editor, </editor> <booktitle> Proceedings of the 1991 International Conference on Parallel Processing, </booktitle> <pages> pages 174-178. </pages> <publisher> CRC Press, Inc., </publisher> <year> 1991. </year> <title> Vol. </title> <booktitle> II Software. </booktitle>
Reference-contexts: developing methods for constructing execution schedules for partially parallel loops, i.e., loops whose parallelization requires synchronization to ensure that the iterations are executed in the correct order. 1 These methods are centered around the extraction of an inspector loop that analyzes the data access pattern off-line, i.e., without side effects <ref> [8, 19, 22, 26, 27, 28, 29, 35, 36] </ref>. The inspection phase of these schemes usually yields a partitioning of the set of iterations into subsets that can be executed in parallel. These subsets, sometimes called wavefronts, are scheduled sequentially by placing synchronization barriers between them. <p> from previous methods in two major points. * Instead of finding a valid parallel execution schedule for the loop, we focus on the problem of simply deciding if the loop is fully parallel, that is, determining whether or not the loop has cross-iteration dependences. (This approach was also taken in <ref> [26] </ref>.) 1 The only exception of which we are aware is our inspector method for doall parallelization [26]. Run-time analysis techniques have also been used to detect access anomalies or race conditions in parallel programs (see, e.g., [12, 23, 30]). <p> the loop, we focus on the problem of simply deciding if the loop is fully parallel, that is, determining whether or not the loop has cross-iteration dependences. (This approach was also taken in <ref> [26] </ref>.) 1 The only exception of which we are aware is our inspector method for doall parallelization [26]. Run-time analysis techniques have also been used to detect access anomalies or race conditions in parallel programs (see, e.g., [12, 23, 30]). <p> Krothapalli and Sadayappan [14] proposed an inspector method for run-time privatization which relies heavily on synchronizaton, inserts an additional level of indirection into all memory accesses, and calls for dynamic shared memory allocation. In our previous work <ref> [26] </ref> we gave an inspector method without these drawbacks for determining whether a do loop can be executed as a doall, perhaps by privatizing some shared variables. No previous run-time methods have been proposed for parallelizing reduction operations. The methods presented in this paper differ from our previous work [26] in <p> work <ref> [26] </ref> we gave an inspector method without these drawbacks for determining whether a do loop can be executed as a doall, perhaps by privatizing some shared variables. No previous run-time methods have been proposed for parallelizing reduction operations. The methods presented in this paper differ from our previous work [26] in several important ways. First, we advocate the use of run-time tests to validate the execution of a loop that is speculatively executed in parallel. <p> Finally, the new algorithms consider only data dependences caused by actual cross-iteration data-flow (a flow of values). Thus, they may potentially qualify more loops as parallel than the method in <ref> [26] </ref> which conservatively considered the dependences due to every memory reference even if no cross-iteration data-flow occurred at run-time. This situation could arise for example when a loop reads a shared variable, but then only uses it conditionally. <p> Since predicates seldom can be evaluated statically, the compiler must be conservative and conclude that the read access causes a dependence in every iteration of the loop. The test given here improves upon the Privatizing doall test described in <ref> [26] </ref> by checking only the dynamic data dependences caused by the actual cross-iteration flow of values stored in the shared arrays. This is accomplished using a technique we call dynamic dead reference elimination which is explained in detail following the description of the test. <p> As can be observed from the example in Fig. 2, this method allows the LPD test to qualify more loops for parallel execution then would be otherwise possible by just inspecting the memory references as in the original PD test <ref> [26] </ref>. In particular, after marking and counting we obtain the results depicted in the tables. The loop fails the PD test since A w (:) ^ A r (:) is not zero everywhere (Step 2 (b)).
Reference: [27] <author> J. Saltz, R. Mirchandaney, and K. Crowley. </author> <title> The doconsider loop. </title> <booktitle> In Proceedings of the 1989 International Conference on Supercomputing, </booktitle> <pages> pages 29-40, </pages> <month> June </month> <year> 1989. </year>
Reference-contexts: developing methods for constructing execution schedules for partially parallel loops, i.e., loops whose parallelization requires synchronization to ensure that the iterations are executed in the correct order. 1 These methods are centered around the extraction of an inspector loop that analyzes the data access pattern off-line, i.e., without side effects <ref> [8, 19, 22, 26, 27, 28, 29, 35, 36] </ref>. The inspection phase of these schemes usually yields a partitioning of the set of iterations into subsets that can be executed in parallel. These subsets, sometimes called wavefronts, are scheduled sequentially by placing synchronization barriers between them.
Reference: [28] <author> J. Saltz, R. Mirchandaney, and K. Crowley. </author> <title> Run-time parallelization and scheduling of loops. </title> <journal> IEEE Trans. Comput., </journal> <volume> 40(5), </volume> <month> May </month> <year> 1991. </year>
Reference-contexts: developing methods for constructing execution schedules for partially parallel loops, i.e., loops whose parallelization requires synchronization to ensure that the iterations are executed in the correct order. 1 These methods are centered around the extraction of an inspector loop that analyzes the data access pattern off-line, i.e., without side effects <ref> [8, 19, 22, 26, 27, 28, 29, 35, 36] </ref>. The inspection phase of these schemes usually yields a partitioning of the set of iterations into subsets that can be executed in parallel. These subsets, sometimes called wavefronts, are scheduled sequentially by placing synchronization barriers between them.
Reference: [29] <author> E. Schonberg. </author> <title> On-the-fly detection of access anomalies. </title> <booktitle> In Proceedings of the SIGPLAN 1989 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 285-297, </pages> <address> Portland, Oregon, </address> <year> 1989. </year>
Reference-contexts: Although more powerful analysis techniques could remove this last limitation when the index arrays are computed using only statically-known values, nothing can be done at compile-time when the index arrays are a function of the input data <ref> [19, 29, 36] </ref>. <p> developing methods for constructing execution schedules for partially parallel loops, i.e., loops whose parallelization requires synchronization to ensure that the iterations are executed in the correct order. 1 These methods are centered around the extraction of an inspector loop that analyzes the data access pattern off-line, i.e., without side effects <ref> [8, 19, 22, 26, 27, 28, 29, 35, 36] </ref>. The inspection phase of these schemes usually yields a partitioning of the set of iterations into subsets that can be executed in parallel. These subsets, sometimes called wavefronts, are scheduled sequentially by placing synchronization barriers between them.
Reference: [30] <author> P. Tu and D. Padua. </author> <title> Array privatization for shared and distributed memory machines. </title> <booktitle> In Proceedings 2nd Workshop on Languages, Compilers, and Run-Time Environments for Distributed Memory Machines, </booktitle> <month> September </month> <year> 1992. </year>
Reference-contexts: Run-time analysis techniques have also been used to detect access anomalies or race conditions in parallel programs (see, e.g., <ref> [12, 23, 30] </ref>).
Reference: [31] <author> P. Tu and D. Padua. </author> <title> Automatic array privatization. </title> <booktitle> In Proceedings 6th Annual Workshop on Languages and Compilers for Parallel Computing, </booktitle> <address> Portland, OR, </address> <month> August </month> <year> 1993. </year>
Reference-contexts: Privatization creates, for each processor cooperating on the execution of the loop, private copies of the program variables that give rise to anti or output dependences (see, e.g., <ref> [10, 20, 21, 31, 32] </ref>).
Reference: [32] <author> Peng Tu and David Padua. </author> <title> GSA based demand-driven symbolic analysis. </title> <type> Technical Report 1339, </type> <institution> University of Illinois at Urbana-Champaign, Cntr for Supercomputing Res & Dev, </institution> <month> February </month> <year> 1994. </year>
Reference-contexts: Privatization creates, for each processor cooperating on the execution of the loop, private copies of the program variables that give rise to anti or output dependences (see, e.g., <ref> [10, 20, 21, 31, 32] </ref>). <p> The general strategy of our methods is a fairly straightforward demand driven forward substitution of all the variables on the RHS, a process by which all control flow dependences are substituted by data dependences as described in <ref> [2, 32] </ref>. Once this expression of the RHS is obtained it can be analyzed and validated by the methods described in the previous section.
Reference: [33] <author> M. Wolfe. </author> <title> Optimizing Compilers for Supercomputers. </title> <publisher> The MIT Press, </publisher> <address> Boston, MA, </address> <year> 1989. </year>
Reference-contexts: What is known, however, is the set of all possible RHS forms, which can be computed by following all potential paths in the control flow graph. A direct approach uses a gated static single assignment (GSSA) <ref> [5, 33] </ref> representation of the program. In such a representation, scalar variables are assigned only once.
Reference: [34] <author> J. Wu, J. Saltz, S. Hiranandani, and H. Berryman. </author> <title> Runtime compilation methods for multicomputers. In Dr. </title> <editor> H.D. Schwetman, editor, </editor> <booktitle> Proceedings of the 1991 International Conference on Parallel Processing, </booktitle> <pages> pages 26-30. </pages> <publisher> CRC Press, Inc., </publisher> <year> 1991. </year> <title> Vol. </title> <booktitle> II Software. </booktitle>
Reference-contexts: Restructuring, or parallelizing, compilers address these problems by detecting and exploiting parallelism in sequential programs written in conventional languages. Although compiler techniques for the automatic detection of parallelism have been studied extensively over the last two decades (see, e.g., <ref> [24, 34] </ref>), current parallelizing compilers cannot extract a significant fraction of the available parallelism in a loop if it has a complex and/or statically insufficiently defined access pattern. <p> In order to determine whether or not the execution order of the data accesses affects the semantics of the loop, the data dependence relations between the statements in the loop body must be analyzed <ref> [6, 17, 24, 34, 37] </ref>. There are three possible types of dependences between two statements that access the same memory location: flow (read after write), anti (write after read), and output (write after write). Flow dependences express a fundamental relationship about the data flow in the program.
Reference: [35] <author> C. Zhu and P. C. Yew. </author> <title> A scheme to enforce data dependence on large multiprocessor systems. </title> <journal> IEEE Trans. Softw. Eng., </journal> <volume> 13(6) </volume> <pages> 726-739, </pages> <month> June </month> <year> 1987. </year>
Reference-contexts: developing methods for constructing execution schedules for partially parallel loops, i.e., loops whose parallelization requires synchronization to ensure that the iterations are executed in the correct order. 1 These methods are centered around the extraction of an inspector loop that analyzes the data access pattern off-line, i.e., without side effects <ref> [8, 19, 22, 26, 27, 28, 29, 35, 36] </ref>. The inspection phase of these schemes usually yields a partitioning of the set of iterations into subsets that can be executed in parallel. These subsets, sometimes called wavefronts, are scheduled sequentially by placing synchronization barriers between them.
Reference: [36] <author> H. Zima. </author> <title> Supercompilers for Parallel and Vector Computers. </title> <publisher> ACM Press, </publisher> <address> New York, New York, </address> <year> 1991. </year> <pages> 17 18 19 20 </pages>
Reference-contexts: Although more powerful analysis techniques could remove this last limitation when the index arrays are computed using only statically-known values, nothing can be done at compile-time when the index arrays are a function of the input data <ref> [19, 29, 36] </ref>. <p> developing methods for constructing execution schedules for partially parallel loops, i.e., loops whose parallelization requires synchronization to ensure that the iterations are executed in the correct order. 1 These methods are centered around the extraction of an inspector loop that analyzes the data access pattern off-line, i.e., without side effects <ref> [8, 19, 22, 26, 27, 28, 29, 35, 36] </ref>. The inspection phase of these schemes usually yields a partitioning of the set of iterations into subsets that can be executed in parallel. These subsets, sometimes called wavefronts, are scheduled sequentially by placing synchronization barriers between them.
References-found: 36

