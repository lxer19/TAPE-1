URL: ftp://ftp.cs.columbia.edu/pub/cs4999/hearstAcl94.ps
Refering-URL: http://www.cs.columbia.edu/~becky/cs-readings.html
Root-URL: http://www.cs.columbia.edu
Email: marti@cs.berkeley.edu  
Title: MULTI-PARAGRAPH SEGMENTATION OF EXPOSITORY TEXT  
Author: Marti A. Hearst and 
Address: 571 Evans Hall  Berkeley, CA 94720  
Affiliation: Computer Science Division,  University of California, Berkeley  Xerox Palo Alto Research Center  
Date: 23 Jun 1994  
Note: cmp-lg/9406037  To Appear in ACL '94, Las Cruces, NM  
Abstract: This paper describes TextTiling, an algorithm for partitioning expository texts into coherent multi-paragraph discourse units which reflect the subtopic structure of the texts. The algorithm uses domain-independent lexical frequency and distribution information to recognize the interactions of multiple simultaneous themes. Two fully-implemented versions of the algorithm are described and shown to produce segmentation that corresponds well to human judgments of the major subtopic boundaries of thirteen lengthy texts. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Brown, Gillian, & George Yule. </author> <year> 1983. </year> <title> Discourse Analysis. </title> <booktitle> Cambridge Textbooks in Linguistics Series. </booktitle> <publisher> Cam-bridge University Press. </publisher>
Reference-contexts: From a computational viewpoint, deducing textual topic structure from lexical connectivity alone is appealing, both because it is easy to compute, and also because discourse cues are sometimes misleading with respect to the topic structure <ref> (Brown & Yule 1983) </ref>(x3). 1 Additionally, (Passonneau & Litman 1993) concede the difficulty of eliciting hierarchical intentional structure with any degree of consistency from their human judges.
Reference: <author> Chafe, Wallace L. </author> <year> 1979. </year> <title> The flow of thought and the flow of language. In Syntax and Semantics: Discourse and Syntax , ed. </title> <booktitle> by Talmy Givon, </booktitle> <volume> volume 12, </volume> <pages> 159-182. </pages> <publisher> Academic Press. </publisher>
Reference-contexts: This assumption, as will be seen, is not always valid, but is nevertheless quite useful. This theoretical stance bears a close resemblance to Chafe's notion of The Flow Model of discourse <ref> (Chafe 1979) </ref>, in description of which he writes (pp 179-180): Our data : : : suggest that as a speaker moves from focus to focus (or from thought to thought) there are certain points at which there may be a more or less radical change in space, time, character configuration, event
Reference: <author> Cochran, W. G. </author> <year> 1950. </year> <title> The comparison of percentages in matched samples. </title> <journal> Biometrika 37.256-266. </journal>
Reference-contexts: As Figure 3 shows, agreement among judges is imperfect, but trends can be discerned. In Passonneau & Litman's (1993) data, if 4 or more out of 7 judges mark a boundary, the segmentation is found to be significant using a variation of the Q-test <ref> (Cochran 1950) </ref>. My data showed similar results. However, it isn't clear how useful this significance information is, since a simple majority does not provide overwhelming proof about the objective reality of the subtopic break.
Reference: <author> Dagan, Ido, Shaul Marcus, & Shaul Markovitch. </author> <year> 1993. </year> <title> Contextual word similarity and estimation from sparse data. </title> <booktitle> In Proceedings of the 31th Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> 164-171. </pages>
Reference: <author> Gale, William A., Kenneth W. Church, & David Yarowsky. </author> <year> 1992a. </year> <title> Estimating upper and lower bounds on the performance of word-sense disambiguation programs. </title> <booktitle> In Proceedings of the 30th Meeting of the Association for Computational Linguistics, </booktitle> <pages> 249-256. </pages> ||, ||, & ||. <year> 1992b. </year> <title> A method for disambiguating word senses in a large corpus. </title> <booktitle> Computers and the Humanities 5-6.415-439. </booktitle>
Reference: <author> Grosz, Barbara J., & Candace L. Sidner. </author> <year> 1986. </year> <title> Attention, intention, and the structure of discourse. </title> <note> Computational Linguistics 12.172-204. </note>
Reference-contexts: This is followed by a description of two algorithms for subtopic structuring that make use only of lexical cohesion relations, the evaluation of these algorithms, and a summary and discussion 1 of future work. THE DISCOURSE MODEL Many discourse models assume a hierarchical segmentation model, e.g., attentional/intentional structure <ref> (Grosz & Sidner 1986) </ref> and Rhetorical Structure Theory (Mann & Thompson 1987). <p> The chains are used to structure texts according to the attentional/intentional theory of discourse structure <ref> (Grosz & Sidner 1986) </ref>, and the extent of the chains correspond to the extent of a segment. The algorithm also incorporates the notion of "chain returns" repetition of terms after a long hiatus to close off an intention that spans over a digression.
Reference: <author> Halliday, M. A. K., & R. Hasan. </author> <year> 1976. </year> <title> Cohesion in English. </title> <publisher> London: Longman. </publisher>
Reference-contexts: This is not so much a change in setting or character as a change in subject matter. Therefore, to recognize where the subtopic changes occur, I make use of lexical cohesion relations <ref> (Halliday & Hasan 1976) </ref> in a manner similar to that suggested by Skorochod'ko. Morris and Hirst's pioneering work on computing discourse structure from lexical relations (Morris & Hirst 1991), (Morris 1988) is a precursor to the work reported on here.
Reference: <author> Hearst, Marti A. </author> <year> 1993. </year> <title> TextTiling: A quantitative approach to discourse segmentation. </title> <type> Technical Report Sequoia 93/24, </type> <institution> Computer Science Department, University of California, Berkeley. </institution> ||, <year> 1994. </year> <title> Context and Structure in Automated Full-Text Information Access. </title> <institution> University of California at Berke-ley dissertation. (Computer Science Division Technical Report). </institution>
Reference-contexts: The algorithms are fully implemented: term repetition alone, without use of thesaural relations, knowledge bases, or inference mechanisms, works well for many of the experimental texts. The structure it obtains is coarse-grained but generally reflects human judgment data. Earlier work <ref> (Hearst 1993) </ref> incorporated thesaural information into the algorithms; surprisingly the latest experiments find that this information degrades the performance. This could very well be due to problems with the algorithm used.

Reference: <author> Kozima, Hideki. </author> <year> 1993. </year> <title> Text segmentation based on similarity between words. </title> <booktitle> In Proceedings of the 31th Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> 286-288, </pages> <address> Columbus, OH. </address>
Reference: <author> Longacre, R. E. </author> <year> 1979. </year> <title> The paragraph as a grammatical unit. In Syntax and Semantics: Discourse and Syntax , ed. </title> <booktitle> by Talmy Givon, </booktitle> <volume> volume 12, </volume> <pages> 115-134. </pages> <publisher> Academic Press. </publisher>
Reference: <author> Mann, William C., & Sandra A. Thompson. </author> <year> 1987. </year> <title> Rhetorical structure theory: A theory of text organization. </title> <type> Technical Report ISI/RS 87-190, ISI. </type>
Reference-contexts: THE DISCOURSE MODEL Many discourse models assume a hierarchical segmentation model, e.g., attentional/intentional structure (Grosz & Sidner 1986) and Rhetorical Structure Theory <ref> (Mann & Thompson 1987) </ref>.
Reference: <author> Miller, George A., Richard Beckwith, Christiane Fellbaum, Derek Gross, & Katherine J. Miller. </author> <year> 1990. </year> <title> Introduction to WordNet: An on-line lexical database. </title> <journal> Journal of Lexicography 3.235-244. </journal>
Reference-contexts: This could very well be due to problems with the algorithm used. A simple algorithm that just posits relations among terms that are a small distance apart according to WordNet <ref> (Miller et al. 1990) </ref> or Ro-get's 1911 thesaurus (from Project Gutenberg), modeled after Morris and Hirst's heuristics, might work better. Therefore I do not feel the issue is closed, and instead consider successful grouping of related words as future work.
Reference: <author> Morris, Jane. </author> <year> 1988. </year> <title> Lexical cohesion, the thesaurus, and the structure of text. </title> <type> Technical Report CSRI-219, </type> <institution> Computer Systems Research Institute, University of Toronto. ||, & Graeme Hirst. </institution> <year> 1991. </year> <title> Lexical cohesion computed by thesaural relations as an indicator of the structure of text. </title> <note> Computational Linguistics 17.21-48. </note>
Reference-contexts: Therefore, to recognize where the subtopic changes occur, I make use of lexical cohesion relations (Halliday & Hasan 1976) in a manner similar to that suggested by Skorochod'ko. Morris and Hirst's pioneering work on computing discourse structure from lexical relations (Morris & Hirst 1991), <ref> (Morris 1988) </ref> is a precursor to the work reported on here.
Reference: <author> Passonneau, Rebecca J., & Diane J. Litman. </author> <year> 1993. </year> <title> Intention-based segmentation: Human reliability and correlation with linguistic cues. </title> <booktitle> In Proceedings of the 31st Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> 148-155. </pages>
Reference-contexts: From a computational viewpoint, deducing textual topic structure from lexical connectivity alone is appealing, both because it is easy to compute, and also because discourse cues are sometimes misleading with respect to the topic structure (Brown & Yule 1983)(x3). 1 Additionally, <ref> (Passonneau & Litman 1993) </ref> concede the difficulty of eliciting hierarchical intentional structure with any degree of consistency from their human judges.
Reference: <author> Resnik, Philip, </author> <year> 1993. </year> <title> Selection and Information: A Class-Based Approach to Lexical Relationships. </title> <institution> University of Pennsylvania dissertation. (Institute for Research in Cognitive Science report IRCS-93-42). </institution>
Reference: <author> Salton, Gerard. </author> <year> 1988. </year> <title> Automatic text processing : the transformation, analysis, </title> <booktitle> and retrieval of information by computer. </booktitle> <address> Reading, MA: </address> <publisher> Addison-Wesley. </publisher> ||, <editor> James Allan, & Chris Buckley. </editor> <year> 1993. </year> <title> Approaches to passage retrieval in full text information systems. </title> <booktitle> In Proceedings of the 16th Annual International ACM/SIGIR Conference, </booktitle> <pages> 49-58, </pages> <address> Pittsburgh, PA. </address>
Reference-contexts: These scores appear in Table 1 (results at 33% are also shown for comparison purposes). The algorithms are evaluated according to how many true boundaries they select out of the total selected (precision) and how many true boundaries are found out of the total possible (recall) <ref> (Salton 1988) </ref>. The recall measure implicitly signals the number of missed boundaries (false negatives, or deletion errors); the number of false positives, or insertion errors, is indicated explicitly.
Reference: <author> Sch utze, Hinrich. </author> <year> 1993. </year> <title> Word space. </title> <booktitle> In Advances in Neural Information Processing Systems 5 , ed. </booktitle> <editor> by Stephen J. Hanson, Jack D. Cowan, & C. Lee Giles. </editor> <address> San Mateo CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Skorochod'ko, E.F. </author> <year> 1972. </year> <title> Adaptive method of automatic abstracting and indexing. </title> <booktitle> In Information Processing 71: Proceedings of the IFIP Congress 71 , ed. by C.V. Freiman, </booktitle> <pages> 1179-1182. </pages> <publisher> North-Holland Publishing Company. </publisher>
Reference: <author> Stark, Heather. </author> <year> 1988. </year> <title> What do paragraph markers do? Discourse Processes 11.275-304. </title>
Reference-contexts: contents of the previous three paragraphs; much of the terminol 6 Paragraphs of three or fewer sentences were combined with their neighbor if that neighbor was deemed to follow at "true" boundary, as in paragraphs 2 and 3 of the Stargazers text. 7 This might be explained in part by <ref> (Stark 1988) </ref> who shows that readers disagree measurably about where to place paragraph boundaries when presented with texts with those boundaries removed. ogy that occurred in all of them reappears in this one location (in the spirit of a Grosz & Sidner (1986) "pop" operation).
Reference: <author> Tannen, Deborah. </author> <year> 1989. </year> <title> Talking Voices: Repetition, dialogue, and imagery in conversational discourse. Studies in Interactional Sociolinguistics 6. </title> <publisher> Cambridge University Press. </publisher>
Reference: <author> Walker, Marilyn. </author> <year> 1991. </year> <title> Redundancy in collaborative dialogue. </title> <booktitle> In AAAI Fall Symposium on Discourse Structure in Natural Language Understanding and Generation, </booktitle> <editor> ed. </editor> <title> by Julia Hirschberg, </title> <type> Diane Litman, Kathy McCoy, </type> & <institution> Candy Sidner, </institution> <address> Pacific Grove, CA. </address>
Reference: <author> Yarowsky, David. </author> <year> 1992. </year> <title> Word sense disambiguation using statistical models of Roget's categories trained on large corpora. </title> <booktitle> In Proceedings of the Fourteenth International Conference on Computational Linguistics, </booktitle> <pages> 454-460, </pages> <address> Nantes, France. </address> <month> 8 </month>
References-found: 22

