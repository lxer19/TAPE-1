URL: http://www.cs.umass.edu/~papka/sigir98.ps.gz
Refering-URL: http://www.cs.umass.edu/~papka/
Root-URL: 
Title: On-line New Event Detection and Tracking event detection and event tracking are part of the
Author: James Allan, Ron Papka, and Victor Lavrenko 
Note: New  initiative.  
Address: Amherst, MA 01003  
Affiliation: Center for Intelligent Information Retrieval Computer Science Department University of Massachusetts  
Abstract: We define and describe the related problems of new event detection and event tracking within a stream of broadcast news stories. We focus on a strict on-line setting|i.e., the system must make decisions about one story before looking at any subsequent stories. Our approach to detection uses a single pass clustering algorithm and a novel thresholding model that incorporates the properties of events as a major component. Our approach to tracking is similar to typical information filtering methods. We discuss the value of "surprising" features that have unusual occurrence characteristics, and briefly explore on-line adaptive filtering to handle evolving events in the news. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Allan. </author> <title> Incremental relevance feedback for information filtering. </title> <booktitle> In Proceedings of SIGIR '96, </booktitle> <pages> pages 270-278, </pages> <year> 1996. </year>
Reference: [2] <author> J. Allan, L. Ballesteros, J. Callan, W. Croft, and Z. Lu. </author> <title> Recent experiments with inquery. </title> <booktitle> In The Fourth Text REtrieval Conference (TREC-4), </booktitle> <pages> pages 49-63, </pages> <year> 1995. </year>
Reference-contexts: story triggers an existing query, the story is assumed to discuss the event represented in the query, otherwise it contains a new event. 4.1 Detection Experiments The new event detection algorithm was implemented by combining the ranked-retrieval mechanisms of Inquery, a feature extraction and selection process based on relevance feedback <ref> [2] </ref>, and InRoute's routing architecture [5].
Reference: [3] <author> J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang. </author> <title> Topic detection and tracking pilot study: Final report. In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, 1998. </title> <publisher> Forthcoming. </publisher>
Reference-contexts: As the research is broadened to the larger TDT scope, the unresolved questions become more troublesome. Detailed results of that study are reported elsewhere <ref> [3] </ref>; this paper presents advances in our understanding of the problem after the end of the pilot study. We wish to make it clear that the corpus and evaluation methodology that were devised in the TDT study were a joint effort by four groups. <p> Overlaps and brief mentions were removed from the corpus before processing, leaving 1124 relevant stories for evaluation. The TDT corpus and relevance judgments are described in more detail in the pilot study's final report <ref> [3] </ref> and are available from the Linguistic Data Consortium. <p> Smaller thresholds (e.g., 0.6) cause performance to get consistently worse because they are adding stories that are less and less likely to be relevant. 4 Preliminary studies in the Retrospective Detection task of the TDT pilot study <ref> [3] </ref> support this intuition. One of the nice features of adaptive tracking is that when it works well, it allows the system to operate effectively with fewer sample stories.
Reference: [4] <author> C. Buckley and G. Salton. </author> <title> Optimization of relevance feedback weights. </title> <booktitle> In Proceedings of SIGIR '95, </booktitle> <pages> pages 351-357, </pages> <year> 1995. </year>
Reference-contexts: Some efforts have been made to classify news stories or other documents into broad subject areas automatically using nearest neighbor matching [16], pattern matching [9], or other algorithms based on supervised training <ref> [4, 13, 17] </ref>. For the most part, those techniques are intended to match stories or documents against a set of category labels that are known a priori, a method that is helpful for event tracking but inappropriate for detection.
Reference: [5] <author> J. Callan. </author> <title> Document filtering with inference networks. </title> <booktitle> In Proceedings of SIGIR '96, </booktitle> <pages> pages 262-269, </pages> <year> 1996. </year>
Reference-contexts: the story is assumed to discuss the event represented in the query, otherwise it contains a new event. 4.1 Detection Experiments The new event detection algorithm was implemented by combining the ranked-retrieval mechanisms of Inquery, a feature extraction and selection process based on relevance feedback [2], and InRoute's routing architecture <ref> [5] </ref>.
Reference: [6] <author> C. Carrick and C. Watters. </author> <title> Automatic association of news items. </title> <booktitle> Information Processing & Management, </booktitle> <volume> 33(5) </volume> <pages> 615-632, </pages> <year> 1997. </year>
Reference-contexts: We believe a better approach to new event detection is to use general word co-occurrence retrieval in a process that specifically models event-level features in addition to event-class-level features. Some recent work that associates news photographs with stories about the picture <ref> [6] </ref> is very similar in spirit to Event Tracking. Their stated interest is in linking stories that discuss the same event, though they work solely on the problem of linking photographs and stories. As we will do in our work, they represented stories and photo captions by sets of features.
Reference: [7] <author> P. Cohen. </author> <title> Empirical Methods for Artificial Intelligence. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1995. </year>
Reference-contexts: Once the threshold parameters are obtained, we infer their expected performance using a simple bootstrap process <ref> [7] </ref>. The process randomly selects 25 instances (with replacement) from the data to form a bootstrap sample. Performance is calculated on the sample.
Reference: [8] <author> G. DeJong. </author> <title> Prediction and substantiation: A new approach to natural language processing. </title> <journal> Cognitive Science, </journal> <volume> 3 </volume> <pages> 251-273, </pages> <year> 1979. </year>
Reference: [9] <author> P. Hayes, L. Knecht, and M. Cellio. </author> <title> A News Story Categorization System, </title> <address> pages 518-526. </address> <publisher> Morgan Kaufmann Publishing, </publisher> <address> San Francisco, </address> <year> 1997. </year> <booktitle> Originally appeared in Proceedings of the 2nd Conference on Applied Natural Language Processing, </booktitle> <year> 1988. </year>
Reference-contexts: Some efforts have been made to classify news stories or other documents into broad subject areas automatically using nearest neighbor matching [16], pattern matching <ref> [9] </ref>, or other algorithms based on supervised training [4, 13, 17]. For the most part, those techniques are intended to match stories or documents against a set of category labels that are known a priori, a method that is helpful for event tracking but inappropriate for detection.
Reference: [10] <author> K. S. Jones and P. Willett, </author> <title> editors. </title> <booktitle> Readings in Information Retrieval. </booktitle> <publisher> Morgan Kaufmann Publishing, </publisher> <address> San Francisco, </address> <year> 1997. </year> <pages> Chapter 4, pages 167-256. </pages>
Reference: [11] <author> R. Kohavi. </author> <title> A study of cross-validation and bootstrap for accuracy estimation and model selection. </title> <booktitle> In Proceedings of International Joint Conference on Artificial Intelligence, </booktitle> <year> 1995. </year>
Reference-contexts: Separate training and testing phases were not performed due to the unavailability of more judged events. In order to avoid over-fitting our threshold parameters p and tp, we selected parameters based on k-fold cross-validation <ref> [11] </ref>. The general algorithm is to randomly partition the data into k sets, and to leave one set out while finding parameters that best fit the remaining k 1 sets. The process repeats for k iterations. The parameters that give rise to the smallest overall performance error are used.
Reference: [12] <author> W. Lam, S. Mukhopadhyay, J. Mostafa, and M. Palakal. </author> <title> Detection of shifts in user interests for personalized information filtering. </title> <booktitle> In Proceedings of SIGIR '96, </booktitle> <pages> pages 317-325, </pages> <year> 1996. </year>
Reference: [13] <author> D. Lewis, R. Schapire, J. Callan, and R. Papka. </author> <title> Training algorithms for linear text classifiers. </title> <booktitle> In Proceedings of SIGIR '96, </booktitle> <pages> pages 298-306, </pages> <year> 1996. </year>
Reference-contexts: Some efforts have been made to classify news stories or other documents into broad subject areas automatically using nearest neighbor matching [16], pattern matching [9], or other algorithms based on supervised training <ref> [4, 13, 17] </ref>. For the most part, those techniques are intended to match stories or documents against a set of category labels that are known a priori, a method that is helpful for event tracking but inappropriate for detection.
Reference: [14] <author> D. D. Lewis. </author> <title> The TREC-5 filtering track. </title> <editor> In E. M. Voorhees and D. K. Harman, editors, </editor> <booktitle> The Fifth Text REtrieval Conference (TREC-5), </booktitle> <pages> pages 75-96, </pages> <month> Nov. </month> <year> 1997. </year> <note> NIST Special Publication 500-238. </note>
Reference: [15] <author> A. Martin, T. K. G. Doddington, M. Ordowski, and M. Przybocki. </author> <title> The DET curve in assessment of detection task performance. </title> <booktitle> In Proceedings of Eu-roSpeech'97, </booktitle> <volume> volume 4, </volume> <pages> pages 1895-1898, </pages> <year> 1997. </year>
Reference-contexts: An ideal system might output a score that corresponds to the probability that the story discusses the event; ideal systems do not yet exist. In this work, we skirt the threshold issue by using a Detection Error Tradeoff curve <ref> [15] </ref> to show how false alarm and miss rates vary with respect to each other at various threshold values. Figure 4 presents examples of DET plots showing curves for several different runs.
Reference: [16] <author> B. Masland, G. Linoff, and D. Waltz. </author> <title> Classifying news stories using memory based reasoning. </title> <booktitle> In Proceedings of SIGIR '92, </booktitle> <pages> pages 59-65, </pages> <year> 1992. </year>
Reference-contexts: Some efforts have been made to classify news stories or other documents into broad subject areas automatically using nearest neighbor matching <ref> [16] </ref>, pattern matching [9], or other algorithms based on supervised training [4, 13, 17]. For the most part, those techniques are intended to match stories or documents against a set of category labels that are known a priori, a method that is helpful for event tracking but inappropriate for detection.
Reference: [17] <author> R. Papka, J. Callan, and A. Barto. </author> <title> Text-based information retrieval using exponentiated gradient descent. </title> <booktitle> In Proceedings of the 10th Annual Conference of Advances in Neural Information Processing Systems, </booktitle> <pages> pages 3-9, </pages> <year> 1996. </year>
Reference-contexts: Some efforts have been made to classify news stories or other documents into broad subject areas automatically using nearest neighbor matching [16], pattern matching [9], or other algorithms based on supervised training <ref> [4, 13, 17] </ref>. For the most part, those techniques are intended to match stories or documents against a set of category labels that are known a priori, a method that is helpful for event tracking but inappropriate for detection.
Reference: [18] <author> G. Salton. </author> <title> Automatic Text Processing. </title> <publisher> Addison-Wesley Publishing Co, </publisher> <address> Massachusetts, </address> <year> 1989. </year>
Reference-contexts: The consolidation threshold was used to build lists of stories that were assumed to be related to each query. We tested various methods of combining stories that exceeded this threshold into one query. One of the methods for agglomerating queries used average link clustering <ref> [23, 18] </ref>. We found that agglomerating using low values for p had worse performance than agglomerating at higher values, but in general, agglomeration with good parameters had no effect on detection performance.
Reference: [19] <author> A. Singhal, M. Mitra, and C. Buckley. </author> <title> Learning routing queries in a query zone. </title> <booktitle> In Proceedings of SIGIR '97, </booktitle> <pages> pages 25-32, </pages> <year> 1997. </year>
Reference: [20] <author> J. Tague-Sutcliffe. </author> <title> Measuring the informativeness of a retrieval process. </title> <booktitle> In Proceedings of SIGIR '92, </booktitle> <pages> pages 23-36, </pages> <year> 1992. </year>
Reference: [21] <editor> C. van Rijsbergen. </editor> <booktitle> Information Retrieval, </booktitle> <address> 2ed. But-terworths, Massachusetts, </address> <year> 1979. </year>
Reference-contexts: Our approach to the problem is a modification of the well-known single pass clustering algorithm <ref> [21] </ref>. Our algorithm processes each new story on the stream sequentially, as follows: 1. Use feature extraction and selection techniques to build a query representation for the story's content. 2. Determine the query's initial threshold by evaluat ing the new story with the query. 3.
Reference: [22] <author> E. M. Voorhees and D. Harman. </author> <title> Overview of the sixth text retrieval conference. </title> <editor> In E. M. Voorhees and D. K. Harman, editors, </editor> <booktitle> The Sixth Text REtrieval Conference (TREC-6), </booktitle> <year> 1998. </year> <note> NIST Special Publication, forthcoming. </note>
Reference: [23] <author> P. Willett. </author> <title> Recent trends in hierarchic document clustering: A critical review. </title> <booktitle> Information Processing & Management, </booktitle> <volume> 24(5) </volume> <pages> 577-597, </pages> <year> 1988. </year>
Reference-contexts: The consolidation threshold was used to build lists of stories that were assumed to be related to each query. We tested various methods of combining stories that exceeded this threshold into one query. One of the methods for agglomerating queries used average link clustering <ref> [23, 18] </ref>. We found that agglomerating using low values for p had worse performance than agglomerating at higher values, but in general, agglomeration with good parameters had no effect on detection performance.
Reference: [24] <author> Y. Yang, T. Pierce, and J. Carbonell. </author> <title> A study on retrospective and on-line event detection. </title> <booktitle> In Proceedings of SIGIR '98, </booktitle> <year> 1998. </year>
References-found: 24

