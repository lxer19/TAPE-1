URL: http://www.isi.edu/sims/papers/97-jdmkd.ps
Refering-URL: http://www.isi.edu/sims/chunnan/index.html
Root-URL: 
Email: chunnan@asu.edu knoblock@isi.edu  
Phone: Ph: (602)965-1757, Fax: (602)965-2751  
Title: Discovering Robust Knowledge from Databases that Change  
Author: Chun-Nan Hsu Craig A. Knoblock 
Date: March 3, 1997  
Address: PO Box 875406 4676 Admiralty Way Tempe, AZ 85287 Marina del Rey, CA 90292  
Affiliation: Department of Computer Science Information Sciences Institute and Engineering Department of Computer Science Arizona State University University of Southern California  
Abstract: Many applications of knowledge discovery and data mining such as rule discovery for semantic query optimization, database integration and decision support, require the knowledge to be consistent with data. However, databases usually change over time and make machine-discovered knowledge inconsistent. Useful knowledge should be robust against database changes so that it is unlikely to become inconsistent after database changes. This paper defines this notion of robustness in the context of relational databases that contain multiple relations and describes how robustness of first-order Horn-clause rules can be estimated and applied in knowledge discovery. Our experiments show that the estimation approach can accurately predict the robustness of a rule.
Abstract-found: 1
Intro-found: 1
Reference: [ Agrawal et al., 1993 ] <author> Rakesh Agrawal, Tomasz Imielinski, and Arun Swami. </author> <title> Database mining: A performance perspective. </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <volume> 5(6) </volume> <pages> 914-925, </pages> <month> December </month> <year> 1993. </year>
Reference-contexts: Robustness of discovered knowledge can be defined as the probability that the knowledge is consistent with a database state. This probability is different from the confidence factors such as the "support" count for an association rule <ref> [ Agrawal et al., 1993 ] </ref> in that the support count expresses the probability that a data instance satisfies a rule, while robustness expresses the probability that an entire database state is consistent with a rule. <p> An example of the confidence factors is the "support" counts for association rules <ref> [ Agrawal et al., 1993 ] </ref> .
Reference: [ Ambite and Knoblock, 1995 ] <author> Jose-Luis Ambite and Craig A. Knoblock. </author> <title> Reconciling distributed information sources. </title> <booktitle> In Working Notes of the AAAI Spring Symposium on Information Gathering in Distributed Heterogeneous Environments, </booktitle> <address> Palo Alto, CA, </address> <year> 1995. </year>
Reference-contexts: Examples include rule discovery for semantic query optimization [ Hsu, 1996, Hsu and Knoblock, 1994, Hsu and Knoblock, 1996b, Siegel, 1988, Siegel et al., 1991, Shekhar et al., 1993 ] , learning an integrated ontology of heterogeneous databases <ref> [ Dao and Perry, 1995, Ambite and Knoblock, 1995 ] </ref> , functional dependency discovery [ Bell, 1995, Mannila and Raiha, 1994 ] , knowledge discovery for decision support, etc. However, most approaches to these problems assume static databases, while in practice, databases are dynamic, that is, they change frequently. <p> Since the rules are increasingly robust, eventually the need of rule repair can be eliminated. Another application of the robustness estimation is integrating heterogeneous databases <ref> [ Dao and Perry, 1995, Ambite and Knoblock, 1995 ] </ref> . This problem requires the system to extract a compressed description (e.g. integrated view definitions, or a temporary concept description) of data and the consistency of the description and data is important.
Reference: [ Arens et al., 1993 ] <author> Yigal Arens, Chin Y. Chee, Chun-Nan Hsu, and Craig A. Knoblock. </author> <title> Retrieving and integrating data from multiple information sources. </title> <journal> International Journal on Intelligent and Cooperative Information Systems, </journal> <volume> 2(2) </volume> <pages> 127-159, </pages> <year> 1993. </year>
Reference: [ Arens et al., 1996 ] <author> Yigal Arens, Craig A. Knoblock, and Wei-Min Shen. </author> <title> Query reformulation for dynamic information integration. </title> <journal> Journal of Intelligent Information Systems, Special Issue on Intelligent Information Integration, </journal> <year> 1996. </year>
Reference: [ Bacchus et al., 1992 ] <author> Fahiem Bacchus, Adam Grove, Joseph Y. Halpern, and Daphne Koller. </author> <title> From statistics to beliefs. </title> <booktitle> In Proceedings of the Tenth National Conference on Artificial Intelligence(AAAI-92), </booktitle> <pages> pages 602-608, </pages> <address> San Jose, CA, </address> <year> 1992. </year>
Reference-contexts: The formalism proposed by [ Bacchus, 1988 ] , [ Halpern, 1990 ] , and [ Bacchus et al., 1992, Bacchus et al., 1993, Bacchus et al., 1994 ] for uncertain reasoning, in spite of the different motivation, is quite similar to robustness. <ref> [ Bacchus et al., 1992 ] </ref> defines the degree of belief in a given logic sentence ' as the probability of the set of worlds where ' is true. They further define this probability as the ratio between the number of all possible worlds and worlds where ' is true. <p> They further define this probability as the ratio between the number of all possible worlds and worlds where ' is true. This is the same as Definition 1, if we consider a database as a model of "worlds." <ref> [ Bacchus et al., 1992 ] </ref> also surveys early philosophical work on probability that discuss related uncertainty measures.
Reference: [ Bacchus et al., 1993 ] <author> Fahiem Bacchus, Adam Grove, Joseph Y. Halpern, and Daphne Koller. </author> <title> Statistical foundations for default reasoning. </title> <booktitle> In Proceedings of the 13th International Joint Conference on Artificial Intelligence(IJCAI-93), </booktitle> <pages> pages 563-569, </pages> <address> Chambery, France, </address> <year> 1993. </year>
Reference: [ Bacchus et al., 1994 ] <author> Fahiem Bacchus, Adam Grove, Joseph Y. Halpern, and Daphne Koller. </author> <title> Forming beliefs about a changing world. </title> <booktitle> In Proceedings of the Twelfth National Conference on Artificial Intelligence(AAAI-94), </booktitle> <pages> pages 222-229, </pages> <address> Seattle, WA, </address> <year> 1994. </year>
Reference: [ Bacchus, 1988 ] <author> Fahiem Bacchus. </author> <title> Representing and Reasoning with Probabilistic Knowledge. </title> <type> PhD thesis, </type> <institution> University of Alberta, Edmonton, Alta., Canada, </institution> <year> 1988. </year> <note> Also available from MIT Press, </note> <year> 1990. </year>
Reference-contexts: Our emphasis on transactions in our definition of robustness is analogous in spirit to the notion of accessibility in the possible worlds semantics of modal logic [ Ramsay, 1988 ] . The formalism proposed by <ref> [ Bacchus, 1988 ] </ref> , [ Halpern, 1990 ] , and [ Bacchus et al., 1992, Bacchus et al., 1993, Bacchus et al., 1994 ] for uncertain reasoning, in spite of the different motivation, is quite similar to robustness. [ Bacchus et al., 1992 ] defines the degree of belief in
Reference: [ Bell, 1995 ] <author> Siegfried Bell. </author> <title> Discovery and maintenance of functional dependencies by independencies. </title> <booktitle> In Proceedings of the First International Conference on Knowledge Discovery and Data Mining(KDD-95), </booktitle> <address> Menlo Park, CA, 1995. </address> <publisher> AAAI Press. </publisher>
Reference-contexts: rule discovery for semantic query optimization [ Hsu, 1996, Hsu and Knoblock, 1994, Hsu and Knoblock, 1996b, Siegel, 1988, Siegel et al., 1991, Shekhar et al., 1993 ] , learning an integrated ontology of heterogeneous databases [ Dao and Perry, 1995, Ambite and Knoblock, 1995 ] , functional dependency discovery <ref> [ Bell, 1995, Mannila and Raiha, 1994 ] </ref> , knowledge discovery for decision support, etc. However, most approaches to these problems assume static databases, while in practice, databases are dynamic, that is, they change frequently.
Reference: [ Cestnik and Bratko, 1991 ] <author> Bojan Cestnik and Ivan Bratko. </author> <title> On estimating probabilities in tree pruning. </title> <booktitle> In Machine Learning - EWSL-91, European Working Session on Learning, </booktitle> <pages> pages 138-150. </pages> <publisher> Springer-Verlag, </publisher> <address> Berlin, Germany, </address> <year> 1991. </year>
Reference-contexts: T3: One of the existing tuples of geoloc with its ?latitude &lt; 35.89 and its ?country 6= ``Malta'' is updated such that its ?country = ``Malta''. Table 3: Transactions that invalidate R2.1 The Laplace law is a special case of a modified estimate called m-Probability <ref> [ Cestnik and Bratko, 1991 ] </ref> . A prior probability of outcomes can be brought to bear in this more general estimate. m-Probability Let r, n, and C be as in the description of the Laplace law.
Reference: [ Clark and Niblett, 1989 ] <author> Peter Clark and Tim Niblett. </author> <title> The CN2 induction algorithm. </title> <journal> Machine Learning, </journal> <volume> 3(4) </volume> <pages> 261-283, </pages> <year> 1989. </year> <month> 31 </month>
Reference-contexts: This is not enough for dynamic closed-world databases where updates and deletions may affect the validity of a rule, as we discussed earlier. Other uncertainty measures applied widely in rule induction and KDD applications are significance and rough set theory. Significance <ref> [ Clark and Niblett, 1989 ] </ref> is used to measure 23 Consistent Inconsistent (:I) (I) Total P c &gt; 0:75 40 7 47 P c 0:75 219 89 308 precision = (L) 28.89% Total 259 96 355 recall = 92.70% Table 15: The joint distribution of the actual and estimated robustness
Reference: [ Cohen, 1993 ] <author> William W. Cohen. </author> <title> Efficient pruning methods for separate-and-conquer rule learning systems. </title> <booktitle> In Proceedings of the 13th International Joint Conference on Artificial Intelligence(IJCAI-93), </booktitle> <address> Chambery, France, </address> <year> 1993. </year>
Reference-contexts: This is because the search space of rule construction is already huge and evaluating robustness is not trivial. Previous work in classification rule induction <ref> [ Cohen, 1993, Cohen, 1995, Furnkranz and Widmer, 1994 ] </ref> also shows that dividing a learning process into a two-stage rule construction and rule pruning can yield better results in terms of classification accuracy 16 as well as the efficiency of learning.
Reference: [ Cohen, 1995 ] <author> William W. Cohen. </author> <title> Fast effective rule induction. </title> <booktitle> In Machine Learning, Proceedings of the 12th International Conference(ML-95), </booktitle> <address> San Mateo, CA, 1995. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: This is because the search space of rule construction is already huge and evaluating robustness is not trivial. Previous work in classification rule induction <ref> [ Cohen, 1993, Cohen, 1995, Furnkranz and Widmer, 1994 ] </ref> also shows that dividing a learning process into a two-stage rule construction and rule pruning can yield better results in terms of classification accuracy 16 as well as the efficiency of learning.
Reference: [ Cussens, 1993 ] <author> James Cussens. </author> <title> Bayes and pesudo-Bayes estimates of conditional probabilities and their reliability. </title> <booktitle> In Machine Learning: ECML-93, </booktitle> <pages> pages 136-152, </pages> <address> Berlin, Germany, 1993. </address> <publisher> Springer-Verlag. </publisher>
Reference: [ Dao and Perry, 1995 ] <author> Son Dao and Brad Perry. </author> <title> Applying a data miner to heterogeneous schema integration. </title> <booktitle> In Proceedings of the First International Conference on Knowledge Discovery and Data Mining(KDD-95), </booktitle> <address> Menlo Park, CA, 1995. </address> <publisher> AAAI Press. </publisher>
Reference-contexts: Examples include rule discovery for semantic query optimization [ Hsu, 1996, Hsu and Knoblock, 1994, Hsu and Knoblock, 1996b, Siegel, 1988, Siegel et al., 1991, Shekhar et al., 1993 ] , learning an integrated ontology of heterogeneous databases <ref> [ Dao and Perry, 1995, Ambite and Knoblock, 1995 ] </ref> , functional dependency discovery [ Bell, 1995, Mannila and Raiha, 1994 ] , knowledge discovery for decision support, etc. However, most approaches to these problems assume static databases, while in practice, databases are dynamic, that is, they change frequently. <p> Since the rules are increasingly robust, eventually the need of rule repair can be eliminated. Another application of the robustness estimation is integrating heterogeneous databases <ref> [ Dao and Perry, 1995, Ambite and Knoblock, 1995 ] </ref> . This problem requires the system to extract a compressed description (e.g. integrated view definitions, or a temporary concept description) of data and the consistency of the description and data is important.
Reference: [ Dzeroski, 1996 ] <author> Saso Dzeroski. </author> <title> Inductive logic programming and knowledge discovery in databases. </title> <editor> In Usama M. Fayyad, Gregory Piatetsky-Shapiro, Padhraic Smyth, and Ramasamy Uthurusamy, editors, </editor> <booktitle> Advances in Knowledge Discovery and Data Mining, chapter 5. </booktitle> <publisher> AAAI Press/MIT Press, </publisher> <year> 1996. </year>
Reference-contexts: Our definition of robustness provides a new measure of uncertainty for Horn-clause rules discovered from those databases. This measure can be applied in inductive logic programming (ILP), an important data mining technique <ref> [ Dzeroski, 1996 ] </ref> . 2. This paper presents an efficient approach to the estimation and use of the new measure. The complexity of the estimation is proportional to the length of a rule, and therefore is scalable to large databases.
Reference: [ Furnkranz and Widmer, 1994 ] <author> Johannes Furnkranz and Gerhard Widmer. </author> <title> Incremental reduced error prunning. </title> <booktitle> In Machine Learning, Proceedings of the 11th International Conference(ML-94), </booktitle> <address> San Mateo, CA, 1994. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: This is because the search space of rule construction is already huge and evaluating robustness is not trivial. Previous work in classification rule induction <ref> [ Cohen, 1993, Cohen, 1995, Furnkranz and Widmer, 1994 ] </ref> also shows that dividing a learning process into a two-stage rule construction and rule pruning can yield better results in terms of classification accuracy 16 as well as the efficiency of learning.
Reference: [ Ginsberg, 1987 ] <author> Matthew L. Ginsberg. </author> <title> Readings in Nonmonotonic Reasoning. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1987. </year>
Reference-contexts: Reasoning about the consistency of beliefs and knowledge after changes to closed-world relational data is an important research subject in nonmonotonic and uncertain reasoning <ref> [ Ginsberg, 1987, Shafer and Pearl, 1990 ] </ref> . Our emphasis on transactions in our definition of robustness is analogous in spirit to the notion of accessibility in the possible worlds semantics of modal logic [ Ramsay, 1988 ] .
Reference: [ Halpern, 1990 ] <author> Joseph Y. Halpern. </author> <title> An analysis of first-order logics of probability. </title> <journal> Artificial Intelligence, </journal> <volume> 46(3), </volume> <month> December </month> <year> 1990. </year>
Reference-contexts: Our emphasis on transactions in our definition of robustness is analogous in spirit to the notion of accessibility in the possible worlds semantics of modal logic [ Ramsay, 1988 ] . The formalism proposed by [ Bacchus, 1988 ] , <ref> [ Halpern, 1990 ] </ref> , and [ Bacchus et al., 1992, Bacchus et al., 1993, Bacchus et al., 1994 ] for uncertain reasoning, in spite of the different motivation, is quite similar to robustness. [ Bacchus et al., 1992 ] defines the degree of belief in a given logic sentence '
Reference: [ Helmbold and Long, 1994 ] <author> David P. Helmbold and Philip M. </author> <title> Long. Tracking drifting concepts by minimizing disagreement. </title> <journal> Machine Learning, </journal> <volume> 14 </volume> <pages> 27-45, </pages> <year> 1994. </year>
Reference-contexts: Both views do not capture all aspects of uncertainty but since database transactions are indeed deterministic, our assumption is more appropriate for database applications. Learning drifting concepts <ref> [ Widmer and Kubat, 1993, Helmbold and Long, 1994 ] </ref> is also related to robustness.
Reference: [ Howson and Urbach, 1988 ] <author> Colin Howson and Peter Urbach. </author> <title> Scientific Reasoning: The Bayesian Approach. </title> <publisher> Open Court, </publisher> <year> 1988. </year>
Reference-contexts: The probability that the outcome of the next experiment will be C can be estimated as r + 1 . A detailed description and a proof of the Laplace law can be found in <ref> [ Howson and Urbach, 1988 ] </ref> . The Laplace law applies to any repeatable experiment (e.g., tossing a coin). 7 R2.1: ?latitude 35.89 ( geoloc ( , ,?country,?latitude, ) ^ ?country = ``Malta''.
Reference: [ Hsu and Knoblock, 1993 ] <author> Chun-Nan Hsu and Craig A. Knoblock. </author> <title> Reformulating query plans for multidatabase systems. </title> <booktitle> In Proceedings of the Second International Conference on Information and Knowledge Management(CIKM-93), </booktitle> <address> Washington, D.C., </address> <year> 1993. </year>
Reference: [ Hsu and Knoblock, 1994 ] <author> Chun-Nan Hsu and Craig A. Knoblock. </author> <title> Rule induction for semantic query optimization. </title> <booktitle> In Machine Learning, Proceedings of the 11th International Conference(ML-94), </booktitle> <address> San Mateo, CA, 1994. </address> <publisher> Morgan Kaufmann. </publisher> <pages> 32 </pages>
Reference-contexts: Robustness estimation can be used to guide the discovery and repair so that the resulting rules are robust and require a minimal maintenance cost. Previously, we have applied the robustness estimation approach to rule discovery for semantic query optimization <ref> [ Hsu and Knoblock, 1994, Hsu and Knoblock, 1996b ] </ref> .
Reference: [ Hsu and Knoblock, 1996a ] <author> Chun-Nan Hsu and Craig A. Knoblock. </author> <title> Discovering robust knowledge from dynamic closed-world data. </title> <booktitle> In Proceedings of the Thirteenth National Conference on Artificial Intelligence (AAAI-96), </booktitle> <address> Portland, Oregon, 1996. </address> <publisher> AAAI Press. </publisher>
Reference-contexts: To deal with this problem, we apply the robustness estimation approach to guide the data mining and evaluation of semantic rules. In the data mining stage, the discovery system uses a rule pruning approach <ref> [ Hsu and Knoblock, 1996a ] </ref> to prune antecedents of a discovered rule to increase its robustness. This approach estimates the robustness of a partially pruned rule and searches for the pruning that yields high robust rules.
Reference: [ Hsu and Knoblock, 1996b ] <author> Chun-Nan Hsu and Craig A. Knoblock. </author> <title> Using inductive learning to generate rules for semantic query optimization. </title> <editor> In Usama M. Fayyad, Gregory Piatetsky-Shapiro, Padhraic Smyth, and Ramasamy Uthurusamy, editors, </editor> <booktitle> Advances in Knowledge Discovery and Data Mining, chapter 17. </booktitle> <publisher> AAAI Press/MIT Press, </publisher> <year> 1996. </year>
Reference-contexts: Robustness estimation can be used to guide the discovery and repair so that the resulting rules are robust and require a minimal maintenance cost. Previously, we have applied the robustness estimation approach to rule discovery for semantic query optimization <ref> [ Hsu and Knoblock, 1994, Hsu and Knoblock, 1996b ] </ref> .
Reference: [ Hsu, 1996 ] <author> Chun-Nan Hsu. </author> <title> Learning Effective and Robust Knowledge for Semantic Query Optimization. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, University of Southern California, </institution> <year> 1996. </year>
Reference-contexts: From the rule given above, we can reformulate the query so that there is no need to check the railroad access of seaports, which may reduce execution time. We have developed a rule discovery system called basil <ref> [ Hsu, 1996 ] </ref> to provide semantic rules for the SQO optimizer in the sims information mediator [ Arens et al., 1993, Knoblock et al., 1994, Arens et al., 1996 ] , which integrates heterogeneous information sources. The optimizer achieves significant savings using discovered rules. <p> In the evaluation stage of the discovery, the system eliminates rules when their estimated robustness values are below 4 a given threshold. Our experimental results show that the resulting rules are effective in query optimization and robust against database changes <ref> [ Hsu, 1996 ] </ref> . We can also apply the robustness estimation approach to rule maintenance in a manner similar to our rule pruning approach. <p> Generally speaking, a rule is more applicable if it is shorter. In other words, if the number of antecedent literals of a rule is smaller, then it is more widely applicable because it is less specific. Many knowledge discovery systems including the rule discovery system for SQO <ref> [ Hsu, 1996 ] </ref> and ILP systems [ Dzeroski, 1996, Lavrac and Dzeroski, 1994, Raedt and Bruynooghe, 1993 ] can generate Horn-clause rules from data represented in relations similar to those in relational databases. However, the discovered rules are usually too specific and not robust against database changes. <p> estimate and sort on the robustness of rules in R 0 ; 8 retain top B rules in R 0 and remove the rest; 1 Our previous experiments showed that long rules are less applicable and that there is approximately an inverse proportional relation between the applicability and estimated robustness <ref> [ Hsu, 1996 ] </ref> . 17 9 merge sorted R 0 into R in sorted order of the robustness; 10 RETURN O; Let B denote the input beam size, our algorithm expands the search by pruning one literal from the input rule in each search step (starting from line 3), preserves <p> This example shows the utility of the rule pruning with the robustness estimation. 5 Experimental Results This section describes the empirical evaluation on the robustness estimation approach applied to large-scaled real-world databases. For this purpose, we used the rule discovery system basil <ref> [ Hsu, 1996 ] </ref> to derive rules from two large oracle relational databases. These databases are originally part of a real-world transportation logistic planning application. Table 12 summarizes the contents and the sizes of these databases.
Reference: [ King, 1981 ] <author> Jonathan J. King. </author> <title> Query Optimization by Semantic Reasoning. </title> <type> PhD thesis, </type> <institution> Stanford University, Department of Computer Science, </institution> <year> 1981. </year>
Reference: [ Knoblock et al., 1994 ] <author> Craig A. Knoblock, Yigal Arens, and Chun-Nan Hsu. </author> <title> Cooperating agents for information retrieval. </title> <booktitle> In Proceedings of the Second International Conference on Intelligent and Cooperative Information Systems, </booktitle> <address> Toronto, Ontario, Canada, </address> <year> 1994. </year>
Reference: [ Lavrac and Dzeroski, 1994 ] <author> Nada Lavrac and Saso Dzeroski. </author> <title> Inductive Logic Programming: Techniques and Applications. </title> <publisher> Ellis Horwood, </publisher> <year> 1994. </year>
Reference-contexts: The prior probability used here is that k outcomes are equally probable. The m-probability estimate has produced convincing results in noisy data handling and decision trees pruning when applied in many machine learning systems <ref> [ Cest-nik and Bratko, 1991, Lavrac and Dzeroski, 1994 ] </ref> . The advantage of the Laplace estimate is that it takes both known relative frequency and prior probability into account.
Reference: [ Lloyd, 1987 ] <author> John W. Lloyd. </author> <title> Foundations of Logic Programming. </title> <publisher> Springer-Verlag, </publisher> <address> Berlin, Ger-many, </address> <year> 1987. </year>
Reference-contexts: Table 1 shows the schema of an example database with five relations and their attributes. Table 1 also shows some Horn-clause rules that express the regularity of data. We adopt standard Prolog terminology and semantics as defined in <ref> [ Lloyd, 1987 ] </ref> in our discussion of rules. In addition, we refer to literals defined on database relations as database literals (e.g., seaport ( ,?glc cd,?storage, , , )) and literals on built-in relations as built-in literals (e.g., ?latitude 35.89). We distinguish between two classes of rules.
Reference: [ Mannila and Raiha, 1994 ] <author> Heikki Mannila and Kari-Jouko Raiha. </author> <title> Algorithms for inferring functional dependencies from relations. </title> <journal> Data and Knowledge Engineering, </journal> <volume> 12 </volume> <pages> 83-99, </pages> <year> 1994. </year>
Reference-contexts: rule discovery for semantic query optimization [ Hsu, 1996, Hsu and Knoblock, 1994, Hsu and Knoblock, 1996b, Siegel, 1988, Siegel et al., 1991, Shekhar et al., 1993 ] , learning an integrated ontology of heterogeneous databases [ Dao and Perry, 1995, Ambite and Knoblock, 1995 ] , functional dependency discovery <ref> [ Bell, 1995, Mannila and Raiha, 1994 ] </ref> , knowledge discovery for decision support, etc. However, most approaches to these problems assume static databases, while in practice, databases are dynamic, that is, they change frequently.
Reference: [ Minton, 1988 ] <author> Steven Minton. </author> <title> Learning Effective Search Control Knowledge: An Explanation-Based Approach. </title> <type> PhD thesis, </type> <institution> Carnegie Mellon University, School of Computer Science, </institution> <year> 1988. </year>
Reference-contexts: Another example of rule pruning is the speedup learning system prodigy-ebl <ref> [ Minton, 1988 ] </ref> , which learns search-control rules for problem solving. To increase the applicability of its learned rules, prodigy-ebl contains a compressor to prune rules after they are constructed.
Reference: [ Pawlak, 1991 ] <author> Zdzislaw Pawlak. </author> <title> Rough Sets: Theoretical aspects of Reasoning about Data. </title> <publisher> Kluwer, </publisher> <address> Boston, MA, </address> <year> 1991. </year>
Reference-contexts: Rough set theory <ref> [ Pawlak, 1991, Ziarko, 1995 ] </ref> is useful for measuring whether a given set of attributes is sufficient to represent a target concept.
Reference: [ Piatetsky-Shapiro, 1984 ] <author> Gregory Piatetsky-Shapiro. </author> <title> A Self-Organizing Database System A Different Approach To Query Optimization. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, </institution> <address> New York University, </address> <year> 1984. </year>
Reference-contexts: The number of tuples that satisfy a literal can be retrieved from the database. If this is too expensive for large databases, we can use the estimation approaches used for conventional query optimization <ref> [ Piatetsky-Shapiro, 1984, Ullman, 1988 ] </ref> to estimate this number. 10 * The value of latitude is updated, given that the tuple that is updated is a tuple of geoloc with its ?country ="Malta": Pr (x 4 jx 2 ^ x 1 ) = t u;geoloc;latitude + 1 t u;geoloc +
Reference: [ Piatetsky-Shapiro, 1991 ] <author> Gregory Piatetsky-Shapiro. </author> <title> Discovery, analysis, and presentation of strong rules. </title> <editor> In G. Piatetsky-Shapiro and William J. Frawley, editors, </editor> <booktitle> Knowledge Discovery in Databases, </booktitle> <pages> pages 229-248. </pages> <publisher> MIT Press, </publisher> <year> 1991. </year> <month> 33 </month>
Reference-contexts: of the actual and estimated robustness robustness values can provide sufficient information for rule discovery and maintenance to deal with database changes. 6 Related Uncertainty Measures Most rule discovery systems assign an uncertainty confidence factor to a discovered rule and such a rule is referred to as a strong rule <ref> [ Piatetsky-Shapiro, 1991 ] </ref> . An example of the confidence factors is the "support" counts for association rules [ Agrawal et al., 1993 ] .
Reference: [ Raedt and Bruynooghe, 1993 ] <author> Luc De Raedt and Maurice Bruynooghe. </author> <title> A theory of clausal discov-ery. </title> <booktitle> In Proceedings of the 13th International Joint Conference on Artificial Intelligence(IJCAI-93), </booktitle> <address> Chambery, France, </address> <year> 1993. </year>
Reference: [ Ramsay, 1988 ] <author> Allan Ramsay. </author> <booktitle> Formal Methods in Artificial Intelligence. </booktitle> <publisher> Cambridge University Press, </publisher> <address> Cambridge, U.K., </address> <year> 1988. </year>
Reference-contexts: The robustness of r in accessible states from the current state d is defined as Robust (rjd) = Pr (:tjd) = 1 Pr (tjd). This definition of robustness is analogous in spirit to the notion of accessibility and the possible worlds semantics in modal logic <ref> [ Ramsay, 1988 ] </ref> . Definition 2 retains our intuitive notion of robustness, but allows us to estimate robustness without counting the intractably large number of possible database states. <p> Our emphasis on transactions in our definition of robustness is analogous in spirit to the notion of accessibility in the possible worlds semantics of modal logic <ref> [ Ramsay, 1988 ] </ref> .
Reference: [ Shafer and Pearl, 1990 ] <author> Glenn Shafer and Judea Pearl. </author> <title> Readings in Uncertain Reasoning. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1990. </year>
Reference-contexts: Reasoning about the consistency of beliefs and knowledge after changes to closed-world relational data is an important research subject in nonmonotonic and uncertain reasoning <ref> [ Ginsberg, 1987, Shafer and Pearl, 1990 ] </ref> . Our emphasis on transactions in our definition of robustness is analogous in spirit to the notion of accessibility in the possible worlds semantics of modal logic [ Ramsay, 1988 ] .
Reference: [ Shekhar et al., 1993 ] <author> Shashi Shekhar, Babak Hamidzadeh, Ashim Kohli, and Mark Coyle. </author> <title> Learning transformation rules for semantic query optimization: A data-driven approach. </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <volume> 5(6) </volume> <pages> 950-964, </pages> <year> 1993. </year>
Reference: [ Siegel et al., 1991 ] <author> Michael D. Siegel, Edward Sciore, and Sharon Salveter. </author> <title> Rule discovery for query optimization. </title> <editor> In Gregory Piatetsky-Shapiro and William J. Frawley, editors, </editor> <booktitle> Knowledge Discovery in Databases, </booktitle> <pages> pages 411-427. </pages> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1991. </year>
Reference: [ Siegel, 1988 ] <author> Michael D. Siegel. </author> <title> Automatic rule derivation for semantic query optimization. </title> <editor> In Larry Kerschberg, editor, </editor> <booktitle> Proceedings of the Second International Conference on Expert Database Systems, </booktitle> <pages> pages 371-385. </pages> <institution> George Mason Foundation, Fairfax, VA, </institution> <year> 1988. </year>
Reference: [ Sun and Yu, 1994 ] <author> Wei Sun and Clement T. Yu. </author> <title> Semantic query optimization for tree and chain queries. </title> <journal> IEEE Trans. Knowledge and Data Engineering, </journal> <volume> 6(1) </volume> <pages> 136-151, </pages> <year> 1994. </year>
Reference: [ Ullman, 1988 ] <author> Jeffrey D. Ullman. </author> <title> Principles of Database and Knowledge-base Systems, volume I,II. </title> <publisher> Computer Science Press, </publisher> <address> Palo Alto, CA, </address> <year> 1988. </year>
Reference-contexts: The number of tuples that satisfy a literal can be retrieved from the database. If this is too expensive for large databases, we can use the estimation approaches used for conventional query optimization <ref> [ Piatetsky-Shapiro, 1984, Ullman, 1988 ] </ref> to estimate this number. 10 * The value of latitude is updated, given that the tuple that is updated is a tuple of geoloc with its ?country ="Malta": Pr (x 4 jx 2 ^ x 1 ) = t u;geoloc;latitude + 1 t u;geoloc +
Reference: [ Widmer and Kubat, 1993 ] <author> Gerhard Widmer and Miroslav Kubat. </author> <title> Effective learning in dynamic environments by explicit context tracking. </title> <booktitle> In Machine Learning: </booktitle> <address> ECML-93, Berlin, Germany, 1993. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: Both views do not capture all aspects of uncertainty but since database transactions are indeed deterministic, our assumption is more appropriate for database applications. Learning drifting concepts <ref> [ Widmer and Kubat, 1993, Helmbold and Long, 1994 ] </ref> is also related to robustness.
Reference: [ Ziarko, 1995 ] <author> Wojciech Ziarko. </author> <title> The special issue on rough sets and knowledge discovery. </title> <journal> Computational Intelligence, </journal> <volume> 11(2), </volume> <year> 1995. </year> <month> 34 </month>
Reference-contexts: Rough set theory <ref> [ Pawlak, 1991, Ziarko, 1995 ] </ref> is useful for measuring whether a given set of attributes is sufficient to represent a target concept.
References-found: 45

