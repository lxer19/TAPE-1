URL: http://www.cs.gatech.edu/gvu/people/student/Brad.Topol/replica.ps.Z
Refering-URL: http://www.cs.gatech.edu/gvu/people/student/Brad.Topol.html
Root-URL: 
Title: Robust State Sharing for Wide Area Distributed Applications  
Author: Brad Topol Mustaque Ahamad John T. Stasko 
Address: Atlanta, Georgia  
Affiliation: College of Computing, Georgia Institute of Technology,  
Note: Authors' address:  
Date: September 1997  30332-0280.  
Pubnum: GIT-CC-97-25  
Abstract: In this article, we present the Mocha wide area computing infrastructure we are currently developing. Mocha provides support for robust shared objects on heterogeneous platforms, and utilizes advanced distributed shared memory techniques for maintaining consistency of shared objects that are replicated at multiple nodes to improve performance. In addition, our system handles failures that we feel will be common in wide area environments. For example, to ensure that the state of an object is not lost due to a node failure, updated state of the object can be disseminated to several other nodes. The overhead of such state dissemination can be controlled based on the level of availability needed for shared objects. We have used an approach that makes use of multiple communication protocols to improve the efficiency of shared object state transfers in Mocha. We also provide an empirical evaluation of our prototype implementation for both local and wide area networks and present a sample home service application written with the system. fl This work was supported in part by NSF grant CCR-9619371 and the Broadband Telecommunications Center at Georgia Tech.
Abstract-found: 1
Intro-found: 1
Reference: [B + 91] <author> Kenneth Birman et al. </author> <title> Lightweight causal and atomic group multicast. </title> <journal> ACM TOCS, </journal> <volume> 9(3) </volume> <pages> 272-314, </pages> <year> 1991. </year>
Reference-contexts: Furthermore, we provide replicated copies for failure handling which in a message passing 22 model would require group communication and virtual synchrony support <ref> [B + 91] </ref> and is not currently addressed by the above message passing systems. Another non-shared object approach utilized by metacomputing systems to allow task cooperation is the use of remote procedure call (RPC) or its object-based equivalent, remote method invocation (RMI).
Reference: [BBB96] <author> J. Eric Baldeschwieler, Robert D. Blumofe, and Eric A. Brewer. </author> <title> ATLAS: An infrastructure for global computing. </title> <booktitle> In Proceedings of the Seventh 24 ACM SIGOPS European Workshop, </booktitle> <pages> pages 165-172, </pages> <address> Connemara, Ireland, </address> <month> September </month> <year> 1996. </year>
Reference-contexts: Another non-shared object approach utilized by metacomputing systems to allow task cooperation is the use of remote procedure call (RPC) or its object-based equivalent, remote method invocation (RMI). Atlas <ref> [BBB96] </ref>, WebWork [F + 95], NetSolve [CD96], and Legion [GW96] all rely on forms of RPC/RMI for task interaction. In some cases, a RPC/RMI model's performance suffers from the clients need to repeatedly contact a server to perform distributed computation.
Reference: [BHST96] <author> Tim Brecht, Sandhu Harjinder, Meijuan Shan, and Jimmy Talbott. ParaWeb: </author> <title> Towards world-wide supercomputing. </title> <booktitle> In Proceedings of the Seventh ACM SIGOPS European Workshop, </booktitle> <pages> pages 181-188, </pages> <address> Connemara, Ireland, </address> <month> September </month> <year> 1996. </year>
Reference-contexts: We are also not aware of an implementation of TIE. The ParaWeb system <ref> [BHST96] </ref> modifies the Java interpreter to provide a global shared address space using distributed shared memory techniques pioneered by systems such as Munin and Treadmarks. In the ParaWeb implementation, the Java interpreters have been modified to permit them to cooperate and maintain the illusion of global shared memory.
Reference: [BK93] <author> H. E. Bal and M. F. Kaashoek. </author> <title> Object distribution in orca using compile-time and run-time techniques. </title> <booktitle> In OOPSLA, </booktitle> <year> 1993. </year>
Reference-contexts: The shared memory and shared object models are attractive for state sharing because they are simpler to program than standard message passing. They have been explored in <ref> [KCZ92, BZ91, GLL + 90, BK93] </ref>.
Reference: [BZ91] <author> Brian N. Bershad and Matthew J. Zekauskas. Midway: </author> <title> Shared memory parallel programming with entry consistency for distributed memory multiprocessors. </title> <type> Technical Report CMU-CS-91-170, </type> <institution> Carnegie Mellon University, </institution> <month> September </month> <year> 1991. </year>
Reference-contexts: The shared memory and shared object models are attractive for state sharing because they are simpler to program than standard message passing. They have been explored in <ref> [KCZ92, BZ91, GLL + 90, BK93] </ref>. <p> between threads across Mocha servers running at different nodes and (ii) support the sharing of complex objects. 2.1.1 Maintaining Shared State Consistency Mocha's model for maintaining shared state is motivated by weakly ordered shared memory models such as Release Consistency [GLL + 90], Lazy Release Consistency [KCZ92], and Entry Consistency <ref> [BZ91] </ref>. These models have been shown to provide highly efficient state sharing implementations. In these memory models, shared memory is guarded by synchronization constructs (i.e., lock acquire and release) and is only made consistent with the most recent updates when certain synchronization points in the code are reached. <p> This association is exploited to efficiently maintain consistency guarantees between Replicas. This approach allows Mocha's runtime to exploit the synchronization present in an application to improve the performance of consistency maintenance, a technique well established by advanced DSM systems <ref> [BZ91, KCZ92] </ref>. Figure 3 shows a typical section of code in which Replicas are associated with a ReplicaLock to enable them to serve as a form of consistent distributed shared memory. <p> As described in the previous section, the Mocha shared object model consists of replicas which must be associated with a ReplicaLock object thereby supporting a variant of entry consistency <ref> [BZ91] </ref>. When an application thread desires exclusive access to shared replicas, it calls the ReplicaLock's lock () method. The pseudo-code for this method is provided in Figure 5.
Reference: [C + 96] <author> K. Mani Chandy et al. </author> <title> A world-wide distributed system using Java and the internet. </title> <booktitle> In Fifth IEEE International Symposium on High-Performance Distributed Computing (HPDC-5), </booktitle> <address> Syracuse, NY, </address> <month> August </month> <year> 1996. </year>
Reference-contexts: We describe systems from each of these categories. Wide area computing is closely related to metacomputing. A number of meta-computing systems are currently being implemented. Some systems rely on message passing instead of shared objects to allow tasks to cooperate. Examples of these systems include Chandy's worldwide distributed system <ref> [C + 96] </ref> and IceT [GS97]. For the Mocha system, we chose to utilize shared objects instead of message passing because they provide a model that is simpler to program than standard message passing.
Reference: [CD96] <author> Henri Casanova and Jack Dongarra. NetSolve: </author> <title> A network server for solving computational science problems. </title> <booktitle> In Proceedings of Supercomputing '96, </booktitle> <address> Pittsburgh, PA, </address> <month> November </month> <year> 1996. </year> <note> To appear. </note>
Reference-contexts: Another non-shared object approach utilized by metacomputing systems to allow task cooperation is the use of remote procedure call (RPC) or its object-based equivalent, remote method invocation (RMI). Atlas [BBB96], WebWork [F + 95], NetSolve <ref> [CD96] </ref>, and Legion [GW96] all rely on forms of RPC/RMI for task interaction. In some cases, a RPC/RMI model's performance suffers from the clients need to repeatedly contact a server to perform distributed computation.
Reference: [CMRB96] <author> Michael Condict, Dejan Milojicic, Franklin Reynolds, and Don Bolinger. </author> <title> Towards a world-wide civilization of objects. </title> <booktitle> In Proceedings of the Seventh ACM SIGOPS European Workshop, </booktitle> <pages> pages 25-32, </pages> <address> Connemara, Ireland, </address> <month> September </month> <year> 1996. </year>
Reference-contexts: For a more thorough comparison of RPC/RMI and shared memory please refer to [YC97]. Several metacomputing systems are currently providing shared memory. The TIE design <ref> [CMRB96] </ref> supports shared objects via object caching and entry consistency. The developers of TIE believe that in the future, available network bandwidth will be limited (due to growing popularity of the internet) and aggressive caching must be performed to avoid server bottlenecks.
Reference: [CT96] <author> P. Ciancarini and R. Tolksdorf. </author> <title> Using the web to coordinate distributed applications. </title> <booktitle> In Proceedings of the Seventh ACM SIGOPS European Workshop, </booktitle> <address> Connemara, Ireland, </address> <month> September </month> <year> 1996. </year>
Reference-contexts: In contrast, the Mocha system attempts to exploit locality by sending shared state changes directly to the next thread that needs access to the data. Mocha also allows the number of updated replicas to be configured whereas JSDA updates all copies. 23 PageSpace <ref> [CT96] </ref> relies on a Linda-like coordination technology. Essentially, PageSpace supports a global tuple space which nodes may insert or remove tuples without any regard for where the tuples are stored. Mocha's consistency actions are driven by synchronization operations.
Reference: [F + 95] <author> Geoffrey Fox et al. WebWork: </author> <title> Integrated programming environment tools for national and grand challenges. </title> <type> Technical Report NPAC SCCS-715, </type> <institution> Syracuse Univesity, Syracuse, </institution> <address> NY, </address> <month> June </month> <year> 1995. </year>
Reference-contexts: Another non-shared object approach utilized by metacomputing systems to allow task cooperation is the use of remote procedure call (RPC) or its object-based equivalent, remote method invocation (RMI). Atlas [BBB96], WebWork <ref> [F + 95] </ref>, NetSolve [CD96], and Legion [GW96] all rely on forms of RPC/RMI for task interaction. In some cases, a RPC/RMI model's performance suffers from the clients need to repeatedly contact a server to perform distributed computation.
Reference: [FGKT96] <author> Ian Foster, Jonathan Geisler, Carl Kesselman, and Steve Tuecke. </author> <title> Mul-timethod communication for high-Performance metacomputing applications. </title> <booktitle> In Proceedings of Supercomputing '96, </booktitle> <address> Pittsburgh, PA, </address> <month> November </month> <year> 1996. </year> <note> To appear. </note>
Reference-contexts: With wide area distributed computing environments, geographically distributed resources such as workstations, personal computers, supercomputers, graphic rendering engines, and scientific instruments will be available for use in a seamless fashion by parallel applications <ref> [GW96, FGKT96] </ref>. Many envision that it will be possible to transport application code to remote sites in the wide area virtual computer where it may be executed in the presence of needed resources.
Reference: [GLL + 90] <author> Kourosh Gharachorloo, Daniel Lenoski, James Laudon, Phillip Gibbons, Anoop Gupta, and John Hennessy. </author> <title> Memory consistency and event ordering in scalable shared-memory multiprocessors. </title> <booktitle> In Proceedings of the Seventeenth International Symposium on Computer Architecture, </booktitle> <pages> pages 15-26, </pages> <month> May </month> <year> 1990. </year> <month> 25 </month>
Reference-contexts: The shared memory and shared object models are attractive for state sharing because they are simpler to program than standard message passing. They have been explored in <ref> [KCZ92, BZ91, GLL + 90, BK93] </ref>. <p> an efficient scheme for the consistency maintenance of shared state between threads across Mocha servers running at different nodes and (ii) support the sharing of complex objects. 2.1.1 Maintaining Shared State Consistency Mocha's model for maintaining shared state is motivated by weakly ordered shared memory models such as Release Consistency <ref> [GLL + 90] </ref>, Lazy Release Consistency [KCZ92], and Entry Consistency [BZ91]. These models have been shown to provide highly efficient state sharing implementations.
Reference: [GS97] <author> Paul Gray and Vaidy Sunderam. IceT: </author> <title> Distributed computing and Java. </title> <booktitle> In Proceedings of ACM 1997 Workshop on Java for Science and Engineering, </booktitle> <address> Las Vegas, Nevada, </address> <month> June </month> <year> 1997. </year>
Reference-contexts: Wide area computing is closely related to metacomputing. A number of meta-computing systems are currently being implemented. Some systems rely on message passing instead of shared objects to allow tasks to cooperate. Examples of these systems include Chandy's worldwide distributed system [C + 96] and IceT <ref> [GS97] </ref>. For the Mocha system, we chose to utilize shared objects instead of message passing because they provide a model that is simpler to program than standard message passing.
Reference: [GW96] <author> Andrew S Grimshaw and William A. Wulf. </author> <title> Legion flexible support for wide-area computing. </title> <booktitle> In Proceedings of the Seventh ACM SIGOPS Eu-ropean Workshop, </booktitle> <pages> pages 205-212, </pages> <address> Connemara, Ireland, </address> <month> September </month> <year> 1996. </year>
Reference-contexts: With wide area distributed computing environments, geographically distributed resources such as workstations, personal computers, supercomputers, graphic rendering engines, and scientific instruments will be available for use in a seamless fashion by parallel applications <ref> [GW96, FGKT96] </ref>. Many envision that it will be possible to transport application code to remote sites in the wide area virtual computer where it may be executed in the presence of needed resources. <p> Another non-shared object approach utilized by metacomputing systems to allow task cooperation is the use of remote procedure call (RPC) or its object-based equivalent, remote method invocation (RMI). Atlas [BBB96], WebWork [F + 95], NetSolve [CD96], and Legion <ref> [GW96] </ref> all rely on forms of RPC/RMI for task interaction. In some cases, a RPC/RMI model's performance suffers from the clients need to repeatedly contact a server to perform distributed computation.
Reference: [J + 95] <author> Anthony D. Joseph et al. </author> <title> Rover: A toolkit for mobile information access. </title> <booktitle> In Proc. Fifteenth ACM Symposium on Operating Systems, </booktitle> <pages> pages 156-171, </pages> <address> Copper Mountain Resort, CO, </address> <month> dec </month> <year> 1995. </year> <note> [Jsd97] http://www.javasoft.com/people/richb/jsda/, 1997. </note>
Reference-contexts: Mocha's consistency actions are driven by synchronization operations. In certain systems and applications, synchronization for all operations may not be desirable. For example, systems such as Bayou [TDP + 94], Coda [KS92], and Rover <ref> [J + 95] </ref> which address mobility avoid synchronization and instead rely upon conflict detection and resolution to maintain consistency. Our future work will explore non-synchronization based consistency models that are suitable for supporting shared objects.
Reference: [KCZ92] <author> Pete Keleher, Alan L. Cox, and Willy Zwaenepoel. </author> <title> Lazy release consistency for software distributed shared memory. </title> <booktitle> In Proceedings of the 19th International Symposium of Computer Architecture, </booktitle> <year> 1992. </year>
Reference-contexts: The shared memory and shared object models are attractive for state sharing because they are simpler to program than standard message passing. They have been explored in <ref> [KCZ92, BZ91, GLL + 90, BK93] </ref>. <p> maintenance of shared state between threads across Mocha servers running at different nodes and (ii) support the sharing of complex objects. 2.1.1 Maintaining Shared State Consistency Mocha's model for maintaining shared state is motivated by weakly ordered shared memory models such as Release Consistency [GLL + 90], Lazy Release Consistency <ref> [KCZ92] </ref>, and Entry Consistency [BZ91]. These models have been shown to provide highly efficient state sharing implementations. <p> This association is exploited to efficiently maintain consistency guarantees between Replicas. This approach allows Mocha's runtime to exploit the synchronization present in an application to improve the performance of consistency maintenance, a technique well established by advanced DSM systems <ref> [BZ91, KCZ92] </ref>. Figure 3 shows a typical section of code in which Replicas are associated with a ReplicaLock to enable them to serve as a form of consistent distributed shared memory.
Reference: [KS92] <author> J. J. Kistler and M. Satyanarayanan. </author> <title> Disconnected operation in the coda file system. </title> <journal> ACM Transactions on Computing Systems, </journal> <volume> 10 </volume> <pages> 3-25, </pages> <year> 1992. </year>
Reference-contexts: Mocha's consistency actions are driven by synchronization operations. In certain systems and applications, synchronization for all operations may not be desirable. For example, systems such as Bayou [TDP + 94], Coda <ref> [KS92] </ref>, and Rover [J + 95] which address mobility avoid synchronization and instead rely upon conflict detection and resolution to maintain consistency. Our future work will explore non-synchronization based consistency models that are suitable for supporting shared objects.
Reference: [R + 96] <author> R. Riggs et al. </author> <title> Pickling state in Java. </title> <booktitle> In Proceedings of the 2nd Conference on Object-Oriented Technologies and Systems (COOTS), </booktitle> <pages> pages 241-250, </pages> <address> Toronto, Ontario, </address> <month> June </month> <year> 1996. </year>
Reference-contexts: Replicas may contain both homogeneous arrays of primitive data types as well as bona fide Java objects which are serializable <ref> [R + 96] </ref>.
Reference: [SG90] <author> John Stamos and David K. Gifford. </author> <title> Remote evaluation. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 12(4) </volume> <pages> 537-565, </pages> <month> October </month> <year> 1990. </year>
Reference-contexts: These include security, the ability to ship and dynamically link in application code (i.e., remote evaluation support <ref> [SG90] </ref>), and basic debugging and event logging facilities that provide insight into execution of code at remote locations.
Reference: [Sun90] <author> V.S. Sunderam. </author> <title> PVM: A framework for parallel distributed computing. </title> <journal> Concurrency: Practice & Experience, </journal> <volume> 2(4) </volume> <pages> 315-339, </pages> <month> December </month> <year> 1990. </year>
Reference-contexts: Mocha's basic constructs for distributed computing are fashioned after constructs for popular local area distributed computing environments such as PVM <ref> [Sun90] </ref>. However, the primitives have been modified to take advantage of Java's object oriented capabilities. In the Mocha environment, the application is composed of threads which execute in the address spaces of Mocha Servers. These threads may be initiated (i.e., spawned) using a method from the provided Mocha class.
Reference: [TDP + 94] <author> D. Terry, A. Demers, K. Petersen, M. Spreitzer, M. Theimer, and B. Welch. </author> <title> Session guarantees for weakly consistent replicated data. </title> <booktitle> In Proceedings of 1994 Symposium on Parallel and Distributed Information Systems, </booktitle> <month> September </month> <year> 1994. </year>
Reference-contexts: Mocha's consistency actions are driven by synchronization operations. In certain systems and applications, synchronization for all operations may not be desirable. For example, systems such as Bayou <ref> [TDP + 94] </ref>, Coda [KS92], and Rover [J + 95] which address mobility avoid synchronization and instead rely upon conflict detection and resolution to maintain consistency. Our future work will explore non-synchronization based consistency models that are suitable for supporting shared objects.
Reference: [YC97] <author> Weimin Yu and Alan Cox. Java/DSM: </author> <title> A platform for heterogeneous computing. </title> <booktitle> In Proceedings of ACM 1997 Workshop on Java for Science and Engineering, </booktitle> <address> Las Vegas, Nevada, </address> <month> June </month> <year> 1997. </year> <month> 26 </month>
Reference-contexts: This of course depends on the type of remote computing activities being performed as well as the type of caching strategies employed by the RPC/RMI system. For a more thorough comparison of RPC/RMI and shared memory please refer to <ref> [YC97] </ref>. Several metacomputing systems are currently providing shared memory. The TIE design [CMRB96] supports shared objects via object caching and entry consistency. <p> ParaWeb utilizes Java's built-in synchronization facilities to monitor when remote memory must be updated to maintain the illusion of consistent global memory. In a similar approach, Yu and Cox <ref> [YC97] </ref> are currently implementing a parallel Java Virtual Machine layered on top of the TreadMarks page-based distributed shared memory system. Currently, they are addressing problems such as data type conversion between machines of different architectures as well as garbage collection.
References-found: 22

