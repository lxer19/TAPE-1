URL: ftp://ftp.orie.cornell.edu/pub/techreps/TR999.ps.Z
Refering-URL: http://www.orie.cornell.edu/~shmoys/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Fast Approximation Algorithms for Fractional Packing and Covering Problems  
Author: Serge A. Plotkin David B. Shmoys Eva Tardos 
Note: Research supported by NSF Research Initiation Award CCR-900-8226, by U.S. Army Research Office Grant DAAL-03-91-G-0102, by ONR Contract N00014-88-K-0166, and by a grant from Mitsubishi Corporation. Research partially supported by an NSF PYI award CCR-89-96272 with matching support from UPS, and Sun Microsystems, and by the National Science Foundation, the Air Force Office of Scientific Research, and the Office of Naval Research, through NSF grant DMS-8920550. Research supported in part by a Packard Fellowship, an NSF PYI award, a Sloan Fellowship, and by the National Science Foundation, the Air Force Office of Scientific Research, and the Office of Naval Research, through NSF grant DMS-8920550.  
Date: February 24, 1995  
Affiliation: Stanford University Cornell University Cornell University  
Abstract: This paper presents fast algorithms that find approximate solutions for a general class of problems, which we call fractional packing and covering problems. The only previously known algorithms for solving these problems are based on general linear programming techniques. The techniques developed in this paper greatly outperform the general methods in many applications, and are extensions of a method previously applied to find approximate solutions to multicommodity flow problems. Our algorithm is a Lagrangean relaxation technique; an important aspect of our results is that we obtain a theoretical analysis of the running time of a Lagrangean relaxation-based algorithm. We give several applications of our algorithms. The new approach yields several orders of magnitude of improvement over the best previously known running times for algorithms for the scheduling of unrelated parallel machines in both the preemptive and the non-preemptive models, for the job shop problem, for the Held & Karp bound for the traveling salesman problem, for the cutting-stock problem, for the network embedding problem, and for the minimum-cost multicommodity flow problem. fl Technical Report ORIE-999 of the School of Operations Research and Industrial Engineering, Cornell University 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. E. Dyer. </author> <title> An O(n) algorithm for the multiple-choice knapsack linear program. </title> <journal> Mathematical Programming, </journal> <volume> 29 </volume> <pages> 57-63, </pages> <year> 1984. </year> <month> 50 </month>
Reference-contexts: To optimize over P j , note that this is the dual of a 2-variable linear program with M constraints, and, in fact, it is a fractional multiple-choice knapsack problem with M variables. Dyer <ref> [1] </ref> has shown that this problem can be solved in O (M ) time. For the deterministic version, when P = P 1 fi fi P N , we have N .
Reference: [2] <author> K. Eisemann. </author> <title> The trim problem. </title> <journal> Management Science, </journal> <volume> 3 </volume> <pages> 279-284, </pages> <year> 1957. </year>
Reference-contexts: Although we want an integer solution, the linear relaxation of this formulation has been extremely useful in practical applications; furthermore, there are applications in which patterns may be used fractionally <ref> [2] </ref>. Also, finding an approximate solution to this linear relaxation is the key ingredient of Karmarkar & Karp's [13] fully polynomial approximation scheme for the bin-packing problem.
Reference: [3] <author> M. L. Fredman and R. E. Tarjan. </author> <title> Fibonacci heaps and their uses in improved network optimization algorithms. </title> <journal> J. Assoc. Comput. Mach., </journal> <volume> 34 </volume> <pages> 596-615, </pages> <year> 1987. </year>
Reference: [4] <author> H. N. Gabow. </author> <title> Using Euler partitions to edge-color bipartite multi-graphs. </title> <journal> Int. J. Comput. Inform. Sci., </journal> <volume> 5 </volume> <pages> 345-355, </pages> <year> 1976. </year>
Reference-contexts: Round these rescaled times by forming the multigraph G, where each ij 2 E occurs with multiplicity dp ij e. Thus, the maximum degree of this graph is at most Q + N . Using an algorithm of Gabow <ref> [4] </ref>, we can color this graph in O (M log ) time with 2 dlog 2 e colors. By choosing Q = 2 l N , where l = dlog 2 (N + N * 1 )e, it follows that 2 l = O (N=*).
Reference: [5] <author> P. C. Gilmore and R. E. Gomory. </author> <title> A linear programming approach to the cutting-stock problem. </title> <journal> Operations Research, </journal> <volume> 9 </volume> <pages> 839-859, </pages> <year> 1961. </year>
Reference-contexts: Gilmore & Gomory proposed a natural integer programming formulation of this problem and studied methods to solve it as well as its linear relaxation <ref> [5, 6] </ref>. This linear relaxation is also the key ingredient of the fully polynomial approximation scheme for the bin-packing problem that is due to Karmarkar & Karp [13]. We also consider problems with simultaneous packing and covering constraints. In this paper we focus on obtaining approximate solutions for these problems.
Reference: [6] <author> P. C. Gilmore and R. E. Gomory. </author> <title> A linear programming approach to the cutting-stock problem Part II. </title> <journal> Operations Research, </journal> <volume> 11 </volume> <pages> 863-888, </pages> <year> 1963. </year>
Reference-contexts: Gilmore & Gomory proposed a natural integer programming formulation of this problem and studied methods to solve it as well as its linear relaxation <ref> [5, 6] </ref>. This linear relaxation is also the key ingredient of the fully polynomial approximation scheme for the bin-packing problem that is due to Karmarkar & Karp [13]. We also consider problems with simultaneous packing and covering constraints. In this paper we focus on obtaining approximate solutions for these problems.
Reference: [7] <author> A. V. Goldberg. </author> <title> A natural randomization strategy for multicommodity flow and related algorithms. </title> <type> Unpublished manuscript, </type> <year> 1991. </year>
Reference-contexts: In order to check if P2 is satisfied by the current solution, it would be necessary to compute C P (y). This is no longer done each iteration; instead, this condition is checked with probability 1=k. This particular method of randomizing is an extension of an idea that Goldberg <ref> [7] </ref> has used for the multicommodity flow problem, and was also independently discovered by Grigoriadis & Khachiyan [10]. The key to the randomized version of our algorithm is the following lemma. The proof of this lemma is analogous to the proof of Lemma 2.3.
Reference: [8] <author> A. V. Goldberg, S. A. Plotkin, and E. Tardos. </author> <title> Combinatorial algorithms for the generalized flow problem. </title> <journal> Mathematics of Operations Research, </journal> <volume> 16 </volume> <pages> 351-381, </pages> <year> 1990. </year>
Reference-contexts: The fastest previously known algorithm for solving this problem is the Fat-Path generalized flow algorithm of Goldberg, Plotkin, and Tardos <ref> [8] </ref>. In order to convert the packing problem 37 defined by (15-18) into a generalized flow problem, we construct a bipartite graph with nodes representing jobs and machines and introduce an edge from machine node i to job node j with gain 1=p ij if p ij T . <p> On the other hand, if the maximum excess that can be generated at the source is below N , the original packing problem is infeasible, i.e., the current value of T is too small. The running time of the Fat-Path algorithm given in <ref> [8] </ref> is O (m 2 n 2 log n log 2 B), where n; m, and B are the number of nodes, edges, and the maximum integer used to represent gains or capacities, respectively.
Reference: [9] <author> A. V. Goldberg, S. A. Plotkin, D. B. Shmoys, and E. Tardos. </author> <title> Interior point methods for fast parallel algorithms for bipartite matching and related problems. </title> <journal> SIAM J. on Computing, </journal> <note> to appear. </note>
Reference-contexts: In some applications, such as the bipartite matching problem, it is possible to find a starting solution with L = log (n* 1 ), which is, roughly speaking, the number of bits of accuracy required <ref> [9] </ref>. Unfortunately, we do not know of comparable results for any of our applications. For two of our applications, the bin-packing problem and the Held-Karp bound, such results would yield algorithms with running times that clearly improve on the algorithms based on the approach presented here.
Reference: [10] <author> M. D. Grigoriadis and L. G. Khachiyan. </author> <title> Fast approximation schemes for convex programs with many blocks and coupling constraints. </title> <type> Technical Report DCS-TR-273, </type> <institution> Rutgers University, </institution> <address> New Brunswick, NJ, </address> <year> 1991. </year>
Reference-contexts: Recently, extensions of this method to other applications were found independently by Grigoriadis & Khachiyan <ref> [10] </ref>. An important theoretical aspect of our results is their connection to Lagrangean relaxation. The main idea of our algorithm is as follows. <p> Recently, extensions of this method were found independently also by Grigoriadis & Khachiyan <ref> [10] </ref>. The algorithm of Grigoriadis & Khachiyan is better in that the number of iteration is a factor of log (m* 1 )= log m less than claimed by Theorem 2.5. Randomized Version. In some cases, the bound in Theorem 2.5 can be improved using randomization. <p> This is no longer done each iteration; instead, this condition is checked with probability 1=k. This particular method of randomizing is an extension of an idea that Goldberg [7] has used for the multicommodity flow problem, and was also independently discovered by Grigoriadis & Khachiyan <ref> [10] </ref>. The key to the randomized version of our algorithm is the following lemma. The proof of this lemma is analogous to the proof of Lemma 2.3.
Reference: [11] <author> M. Held and R. M. Karp. </author> <title> The traveling-salesman problem and minimum cost spanning trees. </title> <journal> Operations Research, </journal> <volume> 18 </volume> <pages> 1138-1162, </pages> <year> 1970. </year>
Reference-contexts: In Section 5, we shall discuss the following further applications: the Held & Karp lower bound for the traveling salesman problem <ref> [11] </ref> (packing 1-trees subject to degree-2 and cost constraints); scheduling unrelated parallel machines in both the preemptive and non-preemptive models, as well as scheduling job shops (packing jobs subject to machine load constraints); embedding graphs with small dilation and congestion (packing short paths subject to capacity constraints); and the minimum-cost multicommodity <p> Lagrangean relaxation has been recognized as an important tool for combinatorial optimization problems since the work of Held & Karp on the traveling salesman problem <ref> [11] </ref>; in our discussion of this application (in Section 5) we examine the relationship between our algorithm and the traditional approach. <p> The Held-Karp bound for the TSP with triangle inequality. One of the most useful ways to obtain a lower bound on the length of the optimum tour for the traveling salesman problem was proposed by Held & Karp <ref> [11] </ref>, and is based on the idea of Lagrangean relaxation. <p> Unfortunately, this implies that the algorithm might run for O (N 3 log N ) iterations, where each iteration takes O (N 2 ) time. Next we consider an alternative packing formulation of the Held-Karp bound that yields a much better running time. The Help & Karp <ref> [11] </ref> showed that the bound can also be obtained by optimization over the subtour elimination polytope.
Reference: [12] <author> S. Kapoor and P. M. Vaidya. </author> <title> Fast algorithms for convex quadratic programming and multicommodity flows. </title> <booktitle> In Proceedings of the 18nd Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 147-159, </pages> <year> 1986. </year>
Reference-contexts: Alternatively, one can apply the other linear programming algorithm of Vaidya [28] for problems where the polytope P can be described with few variables. Furthermore, if the problem has an appropriate network structure then the ideas of Kapoor and Vaidya <ref> [12] </ref> can be used to speed up the matrix inversions involved. The algorithm in [27] obtains an optimal dual solution to a fractional packing or covering problem, but no primal solution.
Reference: [13] <author> N. Karmarkar and R. M. Karp. </author> <title> An efficient approximation scheme for the one-dimensional bin-packing problem. </title> <booktitle> In Proceedings of the 23rd Annual IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pages 206-213, </pages> <year> 1982. </year>
Reference-contexts: This linear relaxation is also the key ingredient of the fully polynomial approximation scheme for the bin-packing problem that is due to Karmarkar & Karp <ref> [13] </ref>. We also consider problems with simultaneous packing and covering constraints. In this paper we focus on obtaining approximate solutions for these problems. For an error parameter * &gt; 0, a point x 2 P is an *-approximate solution for the packing problem if Ax (1 + *)b. <p> Although we want an integer solution, the linear relaxation of this formulation has been extremely useful in practical applications; furthermore, there are applications in which patterns may be used fractionally [2]. Also, finding an approximate solution to this linear relaxation is the key ingredient of Karmarkar & Karp's <ref> [13] </ref> fully polynomial approximation scheme for the bin-packing problem. Given a possible number of raws r, we try to find x 2 P = fx j : P N 0; j = 1; : : : ; N g that satisfies (27). <p> The integer version of the cutting-stock problem is equivalent to the bin-packing problem, which is usually stated in terms of pieces of specified sizes that are to be packed into the minimum number of bins. Karmarkar & Karp <ref> [13] </ref> gave a fully polynomial approximation scheme for the bin-packing problem which uses an algorithm (based on the ellipsoid method) 47 for the fractional cutting-stock problem. Our algorithm can be used to replace the ellipsoid method in this application to yield the fastest known deterministic algorithm for this problem. <p> The Karmarkar & Karp algorithm first deletes any piece of size at most *=2. Let I 0 denote the resulting instance. These small pieces can be added back to a packing of the remaining pieces, arbitrarily filling up the bins without effecting the performance guarantee (by Lemma 3 in <ref> [13] </ref>). Next the algorithm uses grouping of pieces to have a small number of distinct piece sizes. Karmarkar & Karp use linear grouping for one version of the algorithm, but they use geometric grouping for a more sophisticated version. <p> This grouping yields a rounded instance J which satisfies opt (J ) opt (I) opt (J ) + k log 2* 1 (by Lemma 5 in <ref> [13] </ref>). The Karmarkar & Karp algorithm approximately solves the fractional cutting-stock problem corresponding to instance J to obtain a vertex x, which is converted to the integer solution dxe. <p> It is not hard to show that M , the number of different piece sizes in the rounded instance is at most (2=k)size (I) + dlog 2* 1 e (by Lemma 5 in <ref> [13] </ref>). The choice of k implies that M = O (* 1 log * 1 ).
Reference: [14] <author> D. R. Karger and C. Stein. </author> <title> An ~ O(n 2 ) algorithm for minimum cut. </title> <type> Unpublished manuscript, </type> <year> 1992. </year>
Reference-contexts: Deterministically, the minimum cut can be obtained in O (N 3 ) time. We use the recent randomized minimum cut algorithm of Karger and Stein <ref> [14] </ref>. Lemma 5.7 [14] The subroutine required by the packing algorithm in Theorem 2.5 for this problem can be implemented by a randomized algorithm that runs in O (N 2 log 5 N ) time with high probability. <p> Deterministically, the minimum cut can be obtained in O (N 3 ) time. We use the recent randomized minimum cut algorithm of Karger and Stein <ref> [14] </ref>. Lemma 5.7 [14] The subroutine required by the packing algorithm in Theorem 2.5 for this problem can be implemented by a randomized algorithm that runs in O (N 2 log 5 N ) time with high probability.
Reference: [15] <author> R. M. Karp. </author> <title> Probabilistic recurrence relations. </title> <booktitle> In Proceedings of the 23rd Annual ACM Symposium on the Theory of Computing, </booktitle> <pages> pages 190-197, </pages> <year> 1991. </year>
Reference-contexts: We use a result due to Karp <ref> [15] </ref> to analyze the number of iterations used by the randomized version of Improve-Packing. Let ffi denote the ratio of upper and lower bounds on the potential function during a single execution of Improve-Packing. <p> To analyze the number of iterations, we once again apply the result of Karp <ref> [15] </ref>. This implies that the randomized version of Improve-Cover is expected to terminate in O (( P k* 1 0 ) iterations, and is a factor of * 1 faster if the initial solution is 6*-optimal for * 1=12.
Reference: [16] <author> P. Klein, S. A. Plotkin, C. Stein, and E. Tardos. </author> <title> Faster approximation algorithms for the unit capacity concurrent flow problem with applications to routing and finding sparse cuts. </title> <type> Technical Report 961, </type> <institution> School of Operations Research and Industrial Engineering, Cornell University, </institution> <year> 1991. </year> <note> A preliminary version of this paper appeared in Proceedings of the 22nd Annual ACM Symposium on Theory of Computing, pages 310-321, 1990. 51 </note>
Reference-contexts: Our approach extends a method previously applied to find approximate solutions to multi-commodity flow problems, first by Shahrokhi & Matula [25], and later by Klein, Plotkin, Stein & Tardos <ref> [16] </ref> and Leighton, Makedon, Plotkin, Stein, Tardos & Tragoudas [19]. Recently, extensions of this method to other applications were found independently by Grigoriadis & Khachiyan [10]. An important theoretical aspect of our results is their connection to Lagrangean relaxation. The main idea of our algorithm is as follows. <p> Lagrangean relaxation has been recognized as an important tool for combinatorial optimization problems since the work of Held & Karp on the traveling salesman problem [11]; in our discussion of this application (in Section 5) we examine the relationship between our algorithm and the traditional approach. As in <ref> [16] </ref>, our algorithms can also be modified to generate integral approximate solutions and thus yield theorems relating the linear and fractional optima along the lines of Raghavan & Thompson [24] and give alternative deterministic algorithms to obtain the results of Raghavan [23]. <p> As we have mentioned in the Introduction Theorem 2.5 is an extension of a method previously applied to find approximate solutions to multicommodity flow problems, first by Shahrokhi & Matula [25], and later by Klein, Plotkin, Stein & Tardos <ref> [16] </ref> and Leighton, Makedon, Plotkin, 9 Stein, Tardos & Tragoudas [19]. Recently, extensions of this method were found independently also by Grigoriadis & Khachiyan [10]. <p> Randomized Version. In some cases, the bound in Theorem 2.5 can be improved using randomization. This approach was introduced by Klein, Plotkin, Stein, & Tardos <ref> [16] </ref> in the context of multicommodity flow; we shall present other applications in Section 5. <p> Integer Packing. In some cases, a modified version of the packing algorithm can also be used to find near-optimal solutions to the related integer packing problem. This approach is a generalization of the approach used in <ref> [16] </ref> to obtain integer solutions to the uniform multicommodity flow problem. In Section 5, we will apply this algorithm to the job-shop scheduling problem and the network embedding problem. <p> This algorithm finds an integer point in P , but it might only satisfy a greatly relaxed version of the packing constraints. The following theorem gives a bound on the quality of the solution delivered by this algorithm. The theorem is an extension of a result in <ref> [16] </ref> for the multicommodity flow problem with uniform capacities. The existence of an integer solution 15 under similar assumptions has been proven by Raghavan [23]. However, Raghavan constructs the integer solution using linear programming. Theorem 2.11 Let 0 = max ( fl ; ( =d) log m).
Reference: [17] <author> E. L. Lawler. </author> <title> Fast approximation algorithms for knapsack problems. </title> <journal> Mathematics of Operations Research, </journal> <volume> 4 </volume> <pages> 339-356, </pages> <year> 1979. </year>
Reference-contexts: Although this is N P -hard, recall that by Theorem 3.10 an *=2-approximation algorithm would suffice for our purposes. Lawler <ref> [17] </ref> gave efficient approximation algorithms for the M -piece ordinary knapsack problem that run in O (M * 2 ) and O (M log * 1 + * 4 ) time. <p> Lawler has shown that these solutions can all be augmented to include a greedily selected extension of small pieces in (M log * 1 ) time, using median finding (see section 6 in <ref> [17] </ref>). This algorithm can also be used for problems with multiple items. The resulting implementation of the subroutine runs in O (M log * 1 + * 4 ) time. <p> The resulting implementation of the subroutine runs in O (M log * 1 + * 4 ) time. In order to obtain the O (M * 2 ) bound, we have to further modify Lawler's algorithm, using another technique that was introduced in <ref> [17] </ref> in a somewhat different context. We can assume without loss of generality that the multiplicity of each of the large pieces is at most O (* 1 ).
Reference: [18] <author> E. L. Lawler and J. Labetoulle. </author> <title> On preemptive scheduling on unrelated parallel processors by linear programming. </title> <journal> J. Assoc. Comput. Mach., </journal> <volume> 25 </volume> <pages> 612-619, </pages> <year> 1978. </year>
Reference-contexts: In a related model, we consider schedules with preemptions: a job may be started on one machine, interrupted, and then continued later on another. Lawler & Labetoulle <ref> [18] </ref> showed that an optimal preemptive schedule for this problem, RjpmtnjC max , can be found by minimizing T subject to N X p ij x ij T; i = 1; : : : ; M; (19) i=1 M X x ij = 1; j = 1; : : : ; <p> If we use relatively few distinct matchings, then we introduce few preemptions, and it can be shown that O (N ) matchings suffice <ref> [18] </ref>. In order to apply our relaxed decision procedure, we shall do a bisection search for the minimum value of T for which we find an *-approximate solution. <p> If we are interested in computing a schedule that completes in exactly time T , then it takes O (jEj (jEj + M )) time to compute such a schedule <ref> [18] </ref>. However, since x is itself only approximately optimal, there is little point to computing the best schedule corresponding to x: we can more efficiently compute a somewhat longer schedule.
Reference: [19] <author> T. Leighton, F. Makedon, S. Plotkin, C. Stein, E. Tardos, and S. Tragoudas. </author> <title> Fast approximation algorithms for multicommodity flow problems. </title> <booktitle> In Proceedings of the 23rd Annual ACM Symposium on the Theory of Computing, </booktitle> <pages> pages 101-111, </pages> <year> 1991. </year>
Reference-contexts: Our approach extends a method previously applied to find approximate solutions to multi-commodity flow problems, first by Shahrokhi & Matula [25], and later by Klein, Plotkin, Stein & Tardos [16] and Leighton, Makedon, Plotkin, Stein, Tardos & Tragoudas <ref> [19] </ref>. Recently, extensions of this method to other applications were found independently by Grigoriadis & Khachiyan [10]. An important theoretical aspect of our results is their connection to Lagrangean relaxation. The main idea of our algorithm is as follows. <p> For simplicity of presentation, throughout the paper we shall use a model of computation that allows the use of exact arithmetic on real numbers and provides exponentiation as a single step. In <ref> [19] </ref>, it has been shown that the special case of the algorithm for the multicommodity flow problem can be implemented in the RAM model without increasing the running time. <p> As we have mentioned in the Introduction Theorem 2.5 is an extension of a method previously applied to find approximate solutions to multicommodity flow problems, first by Shahrokhi & Matula [25], and later by Klein, Plotkin, Stein & Tardos [16] and Leighton, Makedon, Plotkin, 9 Stein, Tardos & Tragoudas <ref> [19] </ref>. Recently, extensions of this method were found independently also by Grigoriadis & Khachiyan [10]. The algorithm of Grigoriadis & Khachiyan is better in that the number of iteration is a factor of log (m* 1 )= log m less than claimed by Theorem 2.5. Randomized Version. <p> Randomization speeds up the algorithm by roughly a factor of k if = P ` ` and either ` = ^ for each `, or the k subroutines have the same time bound. This assumption is satisfied, for example, in the multicommodity flow problem considered in <ref> [19] </ref>. <p> Another use of this approximation is to convert our results to the RAM model of computation. In this paper we have focused on a model that allows exact arithmetic and assumes that exponentiation can be performed in a single step. As was done in <ref> [19] </ref> for the multicommodity flow problem, we can use approximate exponentiation to compute an approximate dual solution ~y in O (m log (m* 1 )) time per iteration. <p> It is easy to limit the length of the numbers by a polynomial in the input length, similar to the length of the numbers used in exact linear programming algorithms. However, it might be possible to find an *-approximate solution using decreased precision, as was done in <ref> [19] </ref> for the multicommodity flow problem. We leave this as an open problem. In the application to the minimum-cost multicommodity flow problem, even approximate optimization over P will be too time consuming, and we will use a further relaxed subroutine. <p> The idea is to define the same packing problem using a different polytope that has a smaller width. This technique can be applied for multicommodity flow problems (to obtain the formulation used in <ref> [19] </ref>) and for the preemptive machine scheduling problem, which will be discussed in the next section. Consider a packing problem defined by the convex set P = P 1 fi fiP k , and the inequalities P ` A ` x ` b.
Reference: [20] <author> T. Leighton and S. Rao. </author> <title> An approximate max-flow min-cut theorem for uniform multi-commodity flow problems with applications to approximation algorithms. </title> <booktitle> In Proceedings of the 29th Annual Symposium on Foundations of Computer Science, </booktitle> <pages> pages 422-431, </pages> <year> 1988. </year>
Reference-contexts: The dilation of the embedding is the maximum number of edges on one of the paths used, and the congestion is the maximum number of paths that contain the same edge in G. Leighton and Rao <ref> [20] </ref> gave an algorithm to embed H in G with dilation and congestion both O ( log N ff ). <p> Leighton and Rao <ref> [20] </ref> show that when ` = fi ( log N ff ), then there exists an embedding with dilation and congestion at most `.
Reference: [21] <author> J. K. Lenstra, D. B. Shmoys, and E. Tardos. </author> <title> Approximation algorithms for scheduling unrelated parallel machines. </title> <journal> Mathematical Programming, A, </journal> <volume> 24 </volume> <pages> 259-272, </pages> <year> 1990. </year>
Reference-contexts: This problem, often denoted RjjC max , is N P -complete, and in fact, Lenstra, Shmoys, & Tardos showed that there does not exist an *-approximation algorithm with * &lt; 1=2 unless P = N P . Lenstra, Shmoys, & Tardos <ref> [21] </ref> also gave a 1-approximation algorithm for it, based on a 1-relaxed decision procedure.
Reference: [22] <author> S. Plotkin, D. B. Shmoys and E. Tardos. </author> <title> Fast approximation algorithms for fractional packing and covering problems. </title> <type> Technical Report 999, </type> <institution> School of Operations Research and Industrial Engineering, Cornell University, </institution> <address> Ithaca, NY, </address> <year> 1991. </year>
Reference-contexts: Remark In an earlier version of this paper <ref> [22] </ref> we developed an algorithm analogous to Improve-Packing for the General problem, instead of the above reduction. We would like to thank an anonymous referee for pointing out this reduction.
Reference: [23] <author> P. Raghavan. </author> <title> Probabilistic construction of deterministic algorithms: approximating packing integer programs. </title> <journal> J. Comput. System Sciences, </journal> <volume> 37 </volume> <pages> 130-143, </pages> <year> 1988. </year>
Reference-contexts: As in [16], our algorithms can also be modified to generate integral approximate solutions and thus yield theorems relating the linear and fractional optima along the lines of Raghavan & Thompson [24] and give alternative deterministic algorithms to obtain the results of Raghavan <ref> [23] </ref>. The modified algorithm is, in some cases, more efficient than the original algorithm, due 4 to the fact that it terminates as soon as it can no longer improve the current solution while maintaining integrality. <p> The following theorem gives a bound on the quality of the solution delivered by this algorithm. The theorem is an extension of a result in [16] for the multicommodity flow problem with uniform capacities. The existence of an integer solution 15 under similar assumptions has been proven by Raghavan <ref> [23] </ref>. However, Raghavan constructs the integer solution using linear programming. Theorem 2.11 Let 0 = max ( fl ; ( =d) log m). There exists an integral solution to P with x ` 2 P ` and fl +O ( p 0 ( =d) log (mkd)). <p> Shmoys, Stein, & Wein [26] give a randomized O (log 2 (M + ))-approximation algorithm for this problem and a deterministic variant that uses the randomized rounding technique of Raghavan & Thompson [24] and its deterministic analogue due to Raghavan <ref> [23] </ref>. The overwhelming computational bottleneck of the deterministic algorithm is the solution of a certain fractional packing problem. <p> This algorithm can be made deterministic by formulating the problem of choosing initial delays so that each machine is always assigned O (log (M + )) jobs as an integer packing problem, and then applying the techniques of Raghavan & Thompson [24] and Raghavan <ref> [23] </ref> to approximately solve this packing problem. The computational bottleneck of this procedure is solving the fractional relaxation of the integer packing problem. <p> The fastest previously known algorithm is obtained by using the linear programming algorithm of Vaidya [28], which solves the fractional packing problem in O ( ~ N 10:5 7 log (M + )) time. Then one can apply the techniques of Raghavan and Thompson [24] and Raghavan <ref> [23] </ref> to round to an integer solution. Our algorithm marks a very large improvement over this running time. Network embeddings. Let G = (V; E G ) and H = (V; E H ) denote two constant-degree graphs on the same set of N nodes.
Reference: [24] <author> P. Raghavan and C. D. Thompson. </author> <title> Randomized rounding: a technique for provably good algorithms and algorithmic proofs. </title> <journal> Combinatorica, </journal> <volume> 7 </volume> <pages> 365-374, </pages> <year> 1987. </year>
Reference-contexts: As in [16], our algorithms can also be modified to generate integral approximate solutions and thus yield theorems relating the linear and fractional optima along the lines of Raghavan & Thompson <ref> [24] </ref> and give alternative deterministic algorithms to obtain the results of Raghavan [23]. The modified algorithm is, in some cases, more efficient than the original algorithm, due 4 to the fact that it terminates as soon as it can no longer improve the current solution while maintaining integrality. <p> Shmoys, Stein, & Wein [26] give a randomized O (log 2 (M + ))-approximation algorithm for this problem and a deterministic variant that uses the randomized rounding technique of Raghavan & Thompson <ref> [24] </ref> and its deterministic analogue due to Raghavan [23]. The overwhelming computational bottleneck of the deterministic algorithm is the solution of a certain fractional packing problem. <p> This algorithm can be made deterministic by formulating the problem of choosing initial delays so that each machine is always assigned O (log (M + )) jobs as an integer packing problem, and then applying the techniques of Raghavan & Thompson <ref> [24] </ref> and Raghavan [23] to approximately solve this packing problem. The computational bottleneck of this procedure is solving the fractional relaxation of the integer packing problem. <p> The fastest previously known algorithm is obtained by using the linear programming algorithm of Vaidya [28], which solves the fractional packing problem in O ( ~ N 10:5 7 log (M + )) time. Then one can apply the techniques of Raghavan and Thompson <ref> [24] </ref> and Raghavan [23] to round to an integer solution. Our algorithm marks a very large improvement over this running time. Network embeddings. Let G = (V; E G ) and H = (V; E H ) denote two constant-degree graphs on the same set of N nodes.
Reference: [25] <author> F. Shahrokhi and D. W. Matula. </author> <title> The maximum concurrent flow problem. </title> <journal> J. Assoc. Comput. Mach., </journal> <volume> 37 </volume> <pages> 318-334, </pages> <year> 1990. </year>
Reference-contexts: O fl (N 3 1 ff ) fl (N 3 ) that f (n) log c n (g (n)); we define O fl analogously. Our approach extends a method previously applied to find approximate solutions to multi-commodity flow problems, first by Shahrokhi & Matula <ref> [25] </ref>, and later by Klein, Plotkin, Stein & Tardos [16] and Leighton, Makedon, Plotkin, Stein, Tardos & Tragoudas [19]. Recently, extensions of this method to other applications were found independently by Grigoriadis & Khachiyan [10]. An important theoretical aspect of our results is their connection to Lagrangean relaxation. <p> As we have mentioned in the Introduction Theorem 2.5 is an extension of a method previously applied to find approximate solutions to multicommodity flow problems, first by Shahrokhi & Matula <ref> [25] </ref>, and later by Klein, Plotkin, Stein & Tardos [16] and Leighton, Makedon, Plotkin, 9 Stein, Tardos & Tragoudas [19]. Recently, extensions of this method were found independently also by Grigoriadis & Khachiyan [10].
Reference: [26] <author> D. B. Shmoys, C. Stein and J. Wein. </author> <title> Improved approximation algorithms for shop scheduling problems. </title> <booktitle> In Proceedings of the Second Annual ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <pages> pages 148-157, </pages> <year> 1991. </year>
Reference-contexts: Shmoys, Stein, & Wein <ref> [26] </ref> give a randomized O (log 2 (M + ))-approximation algorithm for this problem and a deterministic variant that uses the randomized rounding technique of Raghavan & Thompson [24] and its deterministic analogue due to Raghavan [23].
Reference: [27] <author> P. M. Vaidya. </author> <title> A new algorithm for minimizing convex functions over convex sets. </title> <booktitle> In Proceedings of the 30th Annual IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pages 338-343, </pages> <year> 1989. </year>
Reference-contexts: The problem can be solved more efficiently by the algorithm of Vaidya <ref> [27] </ref>; it obtains the optimal value in O (mL) calls to an optimization subroutine for P plus O (mM (m)L) additional time; L and M (m) denote the binary size of the problem and the time needed to invert m by m matrices, respectively. <p> Furthermore, if the problem has an appropriate network structure then the ideas of Kapoor and Vaidya [12] can be used to speed up the matrix inversions involved. The algorithm in <ref> [27] </ref> obtains an optimal dual solution to a fractional packing or covering problem, but no primal solution. <p> In many cases, is not sufficiently small (even exponential), so in Section 4 we give techniques that often reduce . the speedup over his algorithms <ref> [27, 28] </ref> when we assume that * &gt; 0 is any constant, and ignore polylogarithmic factors. <p> Although we will focus on *-approximation algorithms for fixed *, this is only to simplify the discussion of running times. In each of the applications except for the bin-packing problem, we obtain a significant speedup over previously known algorithms. When we cite bounds based on Vaidya's algorithm <ref> [27] </ref> for the dual problem, then we also include the time required for finding an optimal primal solution when appropriate. Scheduling unrelated parallel machines: with and without preemption. Suppose that there are N jobs and M machines, and each job must be scheduled on exactly one of the machines. <p> This running time marks a major improvement over the best previously known time that is obtained by using Vaidya's algorithm <ref> [27] </ref>. <p> Theorem 5.8 For any fixed r &gt; 1, there is a randomized r-approximation algorithm for computing the Held-Karp bound that runs in O (N 4 log 6 N ) time. In contrast, Vaidya's algorithm <ref> [27] </ref> takes O (N 2 M (N ) log N ) time. The cutting-stock problem. <p> The best previously known algorithm is obtained by using Vaidya's algorithm <ref> [27] </ref> to approximately solve the linear programming dual of the problem, and then use the techniques of Karmarkar & Karp and the algorithm of Vaidya [28] to obtain a primal solution. <p> Our cutting stock algorithm was a significant improvement over the best previously know algorithm when M is large relative to * 1 . However, in this application M = O (* 1 log * 1 ). Using the algorithms of Vaidya <ref> [28, 27] </ref> to solve the fractional cutting stock problems, as mentioned after Theorem 5.11, and plugging in M = O (* 1 log * 1 ) gives a deterministic algorithm that runs in O fl (N log * 1 + * 4 M (M )) time, and a randomized version that
Reference: [28] <author> P. M. Vaidya. </author> <title> Speeding up linear programming using fast matrix multiplication. </title> <booktitle> In Proceedings of the 30th Annual IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pages 332-337, </pages> <year> 1989. </year>
Reference-contexts: Alternatively, one can apply the other linear programming algorithm of Vaidya <ref> [28] </ref> for problems where the polytope P can be described with few variables. Furthermore, if the problem has an appropriate network structure then the ideas of Kapoor and Vaidya [12] can be used to speed up the matrix inversions involved. <p> We can use Vaidya's algorithm <ref> [28] </ref> to solve this linear program. The parameter L in the bound of either linear programming algorithm of Vaidya depends on the quality of the starting solution; for example, in [28], it depends on how close the point is to the central path. <p> We can use Vaidya's algorithm <ref> [28] </ref> to solve this linear program. The parameter L in the bound of either linear programming algorithm of Vaidya depends on the quality of the starting solution; for example, in [28], it depends on how close the point is to the central path. In some applications, such as the bipartite matching problem, it is possible to find a starting solution with L = log (n* 1 ), which is, roughly speaking, the number of bits of accuracy required [9]. <p> In many cases, is not sufficiently small (even exponential), so in Section 4 we give techniques that often reduce . the speedup over his algorithms <ref> [27, 28] </ref> when we assume that * &gt; 0 is any constant, and ignore polylogarithmic factors. <p> The previous best algorithm is obtained by using the linear programming algorithm of Vaidya <ref> [28] </ref>. Our running time marks an fl (M 2:5 N 1:5 ) improvement over this algorithm for the deterministic algorithm, and an fl ((M N ) 2:5 ) improvement for the randomized algorithm. Job shop scheduling. <p> The fastest previously known algorithm is obtained by using the linear programming algorithm of Vaidya <ref> [28] </ref>, which solves the fractional packing problem in O ( ~ N 10:5 7 log (M + )) time. Then one can apply the techniques of Raghavan and Thompson [24] and Raghavan [23] to round to an integer solution. Our algorithm marks a very large improvement over this running time. <p> The best previously known algorithm is obtained by using Vaidya's algorithm [27] to approximately solve the linear programming dual of the problem, and then use the techniques of Karmarkar & Karp and the algorithm of Vaidya <ref> [28] </ref> to obtain a primal solution. The resulting deterministic algorithm runs in O fl (M 4 M (M ) + M 3 * 2 ) time. A randomized version runs in O fl (M 3 M (M ) + M 3 * 2 ) time. <p> Our cutting stock algorithm was a significant improvement over the best previously know algorithm when M is large relative to * 1 . However, in this application M = O (* 1 log * 1 ). Using the algorithms of Vaidya <ref> [28, 27] </ref> to solve the fractional cutting stock problems, as mentioned after Theorem 5.11, and plugging in M = O (* 1 log * 1 ) gives a deterministic algorithm that runs in O fl (N log * 1 + * 4 M (M )) time, and a randomized version that <p> The best previously known algorithm is due to Vaidya <ref> [28] </ref>. For the randomized version, our algorithm is an fl (M :5 N K 2:5 ) factor faster than Vaidya's. Acknowledgments We are grateful to Andrew Goldberg and Cliff Stein for many helpful discussions.
Reference: [29] <author> S. L. van de Velde. </author> <title> Machine scheduling and Lagrangian relaxation. </title> <type> Doctoral thesis, </type> <institution> Centre for Mathematics and Computer Science, </institution> <address> Amsterdam, </address> <year> 1991. </year> <month> 52 </month>
Reference-contexts: For a given P j , this is done by computing the minimum modified processing time y i p ij , where the minimization is restricted to those machines for which p ij T . This approach is quite similar to the ascent method that Van de Velde <ref> [29] </ref> used to solve this linear program; he also used a Lagrangean method that, in each iteration, constructs a schedule by assigning 35 each job to its fastest machine with respect to the modified processing times, but uses a much simpler rule to update the dual variables y.
References-found: 29

