URL: http://www.cs.berkeley.edu/~debevec/Research/HDR/debevec-siggraph97.ps.gz
Refering-URL: http://www.cs.berkeley.edu/~debevec/Research/HDR/
Root-URL: 
Title: Recovering High Dynamic Range Radiance Maps from Photographs  
Author: Paul E. Debevec Jitendra Malik 
Keyword: CR Descriptors: I.2.10 [Artificial Intelligence]: Vision and Scene Understanding Intensity, color, photometry and thresholding; I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism Color, shading, shadowing, and texture; I.4.1 [Image Processing]: Digitization Scanning; I.4.8 [Image Processing]: Scene Analysis Photometry, Sensor Fusion.  
Address: Berkeley 1  
Affiliation: University of California at  
Date: August 1997  
Note: From the SIGGRAPH'97 Conference Proceedings,  
Abstract: We present a method of recovering high dynamic range radiance maps from photographs taken with conventional imaging equipment. In our method, multiple photographs of the scene are taken with different amounts of exposure. Our algorithm uses these differently exposed photographs to recover the response function of the imaging process, up to factor of scale, using the assumption of reciprocity. With the known response function, the algorithm can fuse the multiple photographs into a single, high dynamic range radiance map whose pixel values are proportional to the true radiance values in the scene. We demonstrate our method on images acquired with both photochemical and digital imaging processes. We discuss how this work is applicable in many areas of computer graphics involving digitized photographs, including image-based modeling, image compositing, and image processing. Lastly, we demonstrate a few applications of having high dynamic range radiance maps, such as synthesizing realistic motion blur and simulating the response of the human visual system. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> ADAMS, A. </author> <title> Basic Photo, 1st ed. </title> <publisher> Morgan & Morgan, </publisher> <address> Hastings-on-Hudson, New York, </address> <year> 1970. </year>
Reference-contexts: For the newer technology of solid-state imaging with charge coupled devices, [19] is an excellent reference. The technical and artistic problem of representing the dynamic range of a natural scene on the limited range of film has concerned photographers from the early days - <ref> [1] </ref> presents one of the best known systems to choose shutter speeds, lens apertures, and developing conditions to best coerce the dynamic range of a scene to fit into what is possible on a print.
Reference: [2] <author> CHEN, E. </author> <title> QuickTime VR an image-based approach to virtual environment navigation. </title> <note> In SIGGRAPH '95 (1995). </note>
Reference-contexts: a set of differently exposed images. the entire dynamic range captured by the original photographs. 1.1 Applications Our technique of deriving imaging response functions and recovering high dynamic range radiance maps has many possible applications in computer graphics: Image-based modeling and rendering Image-based modeling and rendering systems to date (e.g. <ref> [11, 15, 2, 3, 12, 6, 17] </ref>) make the assumption that all the images are taken with the same exposure settings and film response functions.
Reference: [3] <author> DEBEVEC, P. E., TAYLOR, C. J., AND MALIK, J. </author> <title> Modeling and rendering architecture from photographs: A hybrid geometry- and image-based approach. </title> <booktitle> In SIGGRAPH '96 (August 1996), </booktitle> <pages> pp. 11-20. </pages>
Reference-contexts: a set of differently exposed images. the entire dynamic range captured by the original photographs. 1.1 Applications Our technique of deriving imaging response functions and recovering high dynamic range radiance maps has many possible applications in computer graphics: Image-based modeling and rendering Image-based modeling and rendering systems to date (e.g. <ref> [11, 15, 2, 3, 12, 6, 17] </ref>) make the assumption that all the images are taken with the same exposure settings and film response functions.
Reference: [4] <author> FAUGERAS, O. </author> <title> Three-Dimensional Computer Vision. </title> <publisher> MIT Press, </publisher> <year> 1993. </year>
Reference-contexts: An unfortunate aspect of the PhotoCD process is that it does not scan precisely the same area of each negative relative to the extents of the image. 11 To counteract this effect, we geometrically registered the images to each other using a using normalized correlation (see <ref> [4] </ref>) to determine, with sub-pixel accuracy, corresponding pixels between pairs of images. Fig. 7 (a-c) shows the response functions for the red, green, and blue channels of the church sequence recovered from 28 pixel locations.
Reference: [5] <author> FERWERDA, J. A., PATTANAIK, S. N., SHIRLEY, P., AND GREENBERG, D. P. </author> <title> A model of visual adaptation for realistic image synthesis. </title> <booktitle> In SIGGRAPH '96 (1996), </booktitle> <pages> pp. 249-258. </pages>
Reference-contexts: In particular, the method should be useful for developing reflectance and illumination models, and comparing global illumination solutions against ground truth data. Rendering high dynamic range scenes on conventional display devices is the subject of considerable previous work, including <ref> [20, 16, 5, 23] </ref>.
Reference: [6] <author> GORTLER, S. J., GRZESZCZUK, R., SZELISKI, R., AND CO-HEN, M. F. </author> <booktitle> The Lumigraph. In SIGGRAPH '96 (1996), </booktitle> <pages> pp. 43-54. </pages>
Reference-contexts: a set of differently exposed images. the entire dynamic range captured by the original photographs. 1.1 Applications Our technique of deriving imaging response functions and recovering high dynamic range radiance maps has many possible applications in computer graphics: Image-based modeling and rendering Image-based modeling and rendering systems to date (e.g. <ref> [11, 15, 2, 3, 12, 6, 17] </ref>) make the assumption that all the images are taken with the same exposure settings and film response functions.
Reference: [7] <author> HORN, B. K. P. </author> <title> Robot Vision. </title> <publisher> MIT Press, </publisher> <address> Cambridge, Mass., </address> <year> 1986, </year> <journal> ch. </journal> <volume> 10, </volume> <pages> pp. 206-208. </pages>
Reference-contexts: A discussion of the modes of reciprocity failure may be found in [18], ch. 4. 3 L is proportional E for any particular pixel, but it is possible for the proportionality factor to be different at different places on the sensor. One formula for this variance, given in <ref> [7] </ref>, is E = L 4 d 2 cos 4 ff, where ff measures the pixel's angle from the lens' optical axis. However, most modern camera lenses are designed to compensate for this effect, and provide a nearly constant mapping between radiance and irradiance at f/8 and smaller apertures.
Reference: [8] <author> JAMES, T., Ed. </author> <title> The Theory of the Photographic Process. </title> <publisher> Macmillan, </publisher> <address> New York, </address> <year> 1977. </year>
Reference-contexts: this paper will allow such methods to be tested on real radiance maps in addition to synthetically computed radiance solutions. 1.2 Background The photochemical processes involved in silver halide photography have been the subject of continued innovation and research ever since the invention of the daguerretype in 1839. [18] and <ref> [8] </ref> provide a comprehensive treatment of the theory and mechanisms involved. For the newer technology of solid-state imaging with charge coupled devices, [19] is an excellent reference.
Reference: [9] <author> KAUFMAN, J. E., Ed. </author> <title> IES Lighting Handbook; the standard lighting guide, </title> <booktitle> 7th ed. Illuminating Engineering Society, </booktitle> <address> New York, </address> <year> 1987, </year> <note> p. 24. </note>
Reference-contexts: With these numbers, formulas that give an approximate prediction of film response can be found in <ref> [9] </ref>. Such an approximation can be adequate for simulating visual artifacts such as glare, and predicting areas of scotopic retinal response.
Reference: [10] <author> KOLB, C., MITCHELL, D., AND HANRAHAN, P. </author> <title> A realistic camera model for computer graphics. </title> <note> In SIGGRAPH '95 (1995). </note>
Reference-contexts: However, most modern camera lenses are designed to compensate for this effect, and provide a nearly constant mapping between radiance and irradiance at f/8 and smaller apertures. See also <ref> [10] </ref>. quantities we will be dealing with are weighted by the spectral response at the sensor site. For color photography, the color channels may be treated separately.
Reference: [11] <author> LAVEAU, S., AND FAUGERAS, O. </author> <title> 3-D scene representation as a collection of images. </title> <booktitle> In Proceedings of 12th International Conference on Pattern Recognition (1994), </booktitle> <volume> vol. 1, </volume> <pages> pp. 689-691. </pages>
Reference-contexts: a set of differently exposed images. the entire dynamic range captured by the original photographs. 1.1 Applications Our technique of deriving imaging response functions and recovering high dynamic range radiance maps has many possible applications in computer graphics: Image-based modeling and rendering Image-based modeling and rendering systems to date (e.g. <ref> [11, 15, 2, 3, 12, 6, 17] </ref>) make the assumption that all the images are taken with the same exposure settings and film response functions.
Reference: [12] <author> LEVOY, M., AND HANRAHAN, P. </author> <title> Light field rendering. </title> <booktitle> In SIGGRAPH '96 (1996), </booktitle> <pages> pp. 31-42. </pages>
Reference-contexts: a set of differently exposed images. the entire dynamic range captured by the original photographs. 1.1 Applications Our technique of deriving imaging response functions and recovering high dynamic range radiance maps has many possible applications in computer graphics: Image-based modeling and rendering Image-based modeling and rendering systems to date (e.g. <ref> [11, 15, 2, 3, 12, 6, 17] </ref>) make the assumption that all the images are taken with the same exposure settings and film response functions.
Reference: [13] <author> MADDEN, B. C. </author> <title> Extended intensity range imaging. </title> <type> Tech. rep., </type> <institution> GRASP Laboratory, University of Pennsylvania, </institution> <year> 1993. </year>
Reference-contexts: In scientific applications of photography, such as in astronomy, the nonlinear film response has been addressed by suitable calibration procedures. It is our objective instead to develop a simple self-calibrating procedure not requiring calibration charts or photometric measuring devices. In previous work, <ref> [13] </ref> used multiple flux integration times of a CCD array to acquire extended dynamic range images.
Reference: [14] <author> MANN, S., AND PICARD, R. W. </author> <title> Being 'undigital' with digital cameras: Extending dynamic range by combining differently exposed pictures. </title> <booktitle> In Proceedings of IS&T 46th annual conference (May 1995), </booktitle> <pages> pp. 422-428. </pages>
Reference-contexts: In previous work, [13] used multiple flux integration times of a CCD array to acquire extended dynamic range images. Since direct CCD outputs were available, the work did not need to deal with the 2 From the SIGGRAPH'97 Conference Proceedings, August 1997 problem of nonlinear pixel value response. <ref> [14] </ref> addressed the problem of nonlinear response but provide a rather limited method of recovering the response curve.
Reference: [15] <author> MCMILLAN, L., AND BISHOP, G. </author> <title> Plenoptic Modeling: An image-based rendering system. </title> <note> In SIGGRAPH '95 (1995). </note>
Reference-contexts: a set of differently exposed images. the entire dynamic range captured by the original photographs. 1.1 Applications Our technique of deriving imaging response functions and recovering high dynamic range radiance maps has many possible applications in computer graphics: Image-based modeling and rendering Image-based modeling and rendering systems to date (e.g. <ref> [11, 15, 2, 3, 12, 6, 17] </ref>) make the assumption that all the images are taken with the same exposure settings and film response functions.
Reference: [16] <author> SCHLICK, C. </author> <title> Quantization techniques for visualization of high dynamic range pictures. </title> <booktitle> In Fifth Eurographics Workshop on Rendering (Darmstadt, </booktitle> <address> Germany) (June 1994), </address> <pages> pp. 7-18. </pages>
Reference-contexts: In particular, the method should be useful for developing reflectance and illumination models, and comparing global illumination solutions against ground truth data. Rendering high dynamic range scenes on conventional display devices is the subject of considerable previous work, including <ref> [20, 16, 5, 23] </ref>.
Reference: [17] <author> SZELISKI, R. </author> <title> Image mosaicing for tele-reality applications. </title> <booktitle> In IEEE Computer Graphics and Applications (1996). </booktitle>
Reference-contexts: a set of differently exposed images. the entire dynamic range captured by the original photographs. 1.1 Applications Our technique of deriving imaging response functions and recovering high dynamic range radiance maps has many possible applications in computer graphics: Image-based modeling and rendering Image-based modeling and rendering systems to date (e.g. <ref> [11, 15, 2, 3, 12, 6, 17] </ref>) make the assumption that all the images are taken with the same exposure settings and film response functions.
Reference: [18] <author> TANI, T. </author> <title> Photographic sensitivity : theory and mechanisms. </title> <publisher> Oxford University Press, </publisher> <address> New York, </address> <year> 1995. </year>
Reference-contexts: presented in this paper will allow such methods to be tested on real radiance maps in addition to synthetically computed radiance solutions. 1.2 Background The photochemical processes involved in silver halide photography have been the subject of continued innovation and research ever since the invention of the daguerretype in 1839. <ref> [18] </ref> and [8] provide a comprehensive treatment of the theory and mechanisms involved. For the newer technology of solid-state imaging with charge coupled devices, [19] is an excellent reference. <p> A discussion of the modes of reciprocity failure may be found in <ref> [18] </ref>, ch. 4. 3 L is proportional E for any particular pixel, but it is possible for the proportionality factor to be different at different places on the sensor.
Reference: [19] <author> THEUWISSEN, A. J. P. </author> <title> Solid-state imaging with charge-coupled devices. </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Dordrecht; Boston, </address> <year> 1995. </year>
Reference-contexts: For the newer technology of solid-state imaging with charge coupled devices, <ref> [19] </ref> is an excellent reference.
Reference: [20] <author> TUMBLIN, J., AND RUSHMEIER, H. </author> <title> Tone reproduction for realistic images. </title> <journal> IEEE Computer Graphics and Applications 13, </journal> <volume> 6 (1993), </volume> <pages> 42-48. </pages>
Reference-contexts: In particular, the method should be useful for developing reflectance and illumination models, and comparing global illumination solutions against ground truth data. Rendering high dynamic range scenes on conventional display devices is the subject of considerable previous work, including <ref> [20, 16, 5, 23] </ref>.
Reference: [21] <author> WARD, G. J. </author> <title> Measuring and modeling anisotropic reflection. </title> <booktitle> In SIGGRAPH '92 (July 1992), </booktitle> <pages> pp. 265-272. </pages>
Reference-contexts: The area of image-based modeling and rendering is working toward recovering more advanced reflection models (up to complete BRDF's) of the surfaces in the scene (e.g. <ref> [21] </ref>). These methods, which involve observing surface radiance in various directions under various lighting conditions, require absolute radiance values rather than the nonlinearly mapped pixel values found in conventional images.
Reference: [22] <author> WARD, G. J. </author> <title> The radiance lighting simulation and rendering system. </title> <booktitle> In SIGGRAPH '94 (July 1994), </booktitle> <pages> pp. 459-472. </pages>
Reference-contexts: For efficiency, the map can be converted to the image format used in the RADIANCE <ref> [22] </ref> simulation and rendering system, which uses just eight bits for each of the mantissa and exponent. This format is particularly compact for color radiance maps, since it stores just one exponent value for all three color values at each pixel.
Reference: [23] <author> WARD, G. J., RUSHMEIER, H., AND PIATKO, C. </author> <title> A visibility matching tone reproduction operator for high dynamic range scenes. </title> <type> Tech. Rep. </type> <institution> LBNL-39882, Lawrence Berkeley National Laboratory, </institution> <month> March </month> <year> 1997. </year>
Reference-contexts: In particular, the method should be useful for developing reflectance and illumination models, and comparing global illumination solutions against ground truth data. Rendering high dynamic range scenes on conventional display devices is the subject of considerable previous work, including <ref> [20, 16, 5, 23] </ref>. <p> Images (e) and (f) were generated by a method described in <ref> [23] </ref>. Images (d-f) courtesy of Gregory Ward Larson. 8 From the SIGGRAPH'97 Conference Proceedings, August 1997 adjust the brightness and contrast of the images 10 to guarantee that each image would be digitized using the same response function. <p> Fig. 8 (d) is a false-color image showing radiance values for a grayscale version of the radiance map; the highest listed radiance value is nearly 250,000 times that of the lowest. Figs. 8 (e,f) show two renderings of the radiance map using a new tone reproduction algorithm <ref> [23] </ref>. Although the rightmost stained glass window has radiance values over a thousand times higher than the darker areas in the rafters, these renderings exhibit detail in both areas. moving the camera during the exposure.
References-found: 23

