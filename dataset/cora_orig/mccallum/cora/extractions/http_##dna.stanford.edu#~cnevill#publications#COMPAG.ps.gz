URL: http://dna.stanford.edu/~cnevill/publications/COMPAG.ps.gz
Refering-URL: http://dna.stanford.edu/~cnevill/resume.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: email bmcqueen@waikato.ac.nz  email srg1@waikato.ac.nz, cgn@waikato.ac.nz, ihw@waikato.ac.nz  
Title: Applying Machine Learning to Agricultural Data  
Author: ROBERT J. McQUEEN STEPHEN R. GARNER CRAIG G. NEVILL-MANNING IAN H. WITTEN 
Address: Hamilton, New Zealand  Hamilton, New Zealand  
Affiliation: Management Systems, University of Waikato,  Computer Science, University of Waikato,  
Abstract: Many techniques have been developed for learning rules and relationships automatically from diverse data sets, to simplify the often tedious and error-prone process of acquiring knowledge from empirical data. While these techniques are plausible, theoretically well-founded, and perform well on more or less artificial test data sets, they depend on their ability to make sense of real-world data. This paper describes a project that is applying a range of machine learning strategies to problems in agriculture and horticulture. We briefly survey some of the techniques emerging from machine learning research, describe a software workbench for experimenting with a variety of techniques on real-world data sets, and describe a case study of dairy herd management in which culling rules were inferred from a mediumsized database of herd information. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Angluin, D. and Smith, C.H., </author> <year> 1983. </year> <title> Inductive inference: theory and methods. </title> <journal> Computing Surveys, </journal> <volume> 15: </volume> <pages> 237269. </pages>
Reference-contexts: There are numerous other words that could be used to mean much the same thing; indeed others have defined terms such as generalization (Schank et al., 1986), inductive learning (Michalski, 1983), and inductive modelling <ref> (Angluin & Smith, 1983) </ref> in almost identical ways. Moreover, what is learnedour structural descriptionis sometimes called a generalization, a description, a concept, a model, an hypothesis. For present purposes we regard these as equivalent, and simply use the term concept to denote the structural description that the machine acquires.
Reference: <author> Bareiss, A.R. Porter, B.W. and Weir, C.C. </author> <year> 1988, </year> <title> PROTOS: an exemplar-based learning apprentice. </title> <journal> Int. J. Man Machine Studies. </journal> <volume> 29(5), </volume> <pages> 549-561 Breiman, </pages> <editor> L., and Friedman, J.H., Olshen, R., and Stone C., </editor> <year> 1984. </year> <title> Classification and regression trees. </title> <booktitle> Wadsworth International Group; Belmont, </booktitle> <address> California. </address>
Reference-contexts: In some respects, the requirement for a teacher can substitute for the lack of an adequate domain theory, for the teacher can be consulted to explain the situation whenever a new example fails to fit the systems expectations <ref> (Bareiss et al., 1988) </ref>. The key problem here is to implement a dialog between system and teacher that allows information to be articulated by either party at the appropriate level, and understood by the other.
Reference: <author> Cameron-Jones, R.M., and Quinlan, J.R., </author> <year> 1993. </year> <title> Avoiding Pitfalls When Learning Recursive Theories Proc. </title> <booktitle> IJCAI 93, </booktitle> <publisher> Morgan Kaufmann: </publisher> <address> 1050-1055 Cendrowska, J., </address> <year> 1987. </year> <title> PRISM: an algorithm for inducing modular rules. </title> <journal> Int J Man-Machine Studies, </journal> <volume> 27: </volume> <pages> 349370. </pages>
Reference: <author> Cheeseman, P., Kelly, J., Self, M., Stutz, J., Taylor, W., and Freeman, D., </author> <year> 1988. </year> <title> AUTOCLASS: A Bayesian classification system. </title> <editor> In: Laird, J. (Editor), </editor> <booktitle> Proc. of the Fifth International Conference on Machine Learning. </booktitle> <address> Ann Arbor, MI: </address> <publisher> Morgan Kaufmann: </publisher> <pages> 54 20 DeJong, </pages> <editor> G. and Mooney, R. </editor> <year> 1986. </year> <title> Explanation-based learning: an alternative view. </title> <booktitle> Machine Learning 1(2): </booktitle> <pages> 145-176 Fisher, </pages> <address> D., </address> <year> 1987. </year> <title> Knowledge Acquisition Via Incremental Conceptual Clustering. </title> <journal> Machine Learning, </journal> <volume> 2: </volume> <pages> 139172. </pages>
Reference-contexts: In contrast, unsupervised learning is where a set of examples is supplied but there is no indication of the classes that they belong to <ref> (Cheeseman et al, 1988, Fisher, 1987) </ref>. In this situation, the learning scheme is expected to analyze the similarities and differences between the examples and come up with a clustering that, in effect, assigns classes to them. <p> These methods both induce decision trees using essentially the same technique. Machine learning researchers also incorporate statistics into learning schemes directly, as in the case of the Bayesian classification system AUTOCLASS <ref> (Cheeseman et al, 1988) </ref>. AQ11: AN EARLY EXAMPLE OF AN AGRICULTURAL APPLICATION An often quoted example of the application of machine learning in agriculture is the use of the AQ11 program to identify rules for diagnosis of soybean diseases. <p> As mentioned earlier, AUTOCLASS discovers classes in a database using a Bayesian statistical technique, which has several advantages over other methods <ref> (Cheeseman et al., 1988) </ref>. The number of classes is determined automatically; examples are assigned with a probability to each class rather than absolutely to a single class; and the example data can be real or discrete.
Reference: <author> Gaines, B.R., </author> <year> 1991. </year> <title> The tradeoff between knowledge and data in knowledge acquisition. </title> <editor> In PiatetskyShapiro and Frawley, </editor> <year> 1991: </year> <month> 491505. </month>
Reference-contexts: Methods of machine learning need to be robust enough to cope with imperfect data and to discover laws in it that may not always hold but are useful for the problem at hand. The seven levels of quality shown in Table 1 can be distinguished in a data set <ref> (Gaines, 1991) </ref>. The aim of a learning system is to discover a set of decision rules that is complete, in that it describes all of the data; correct, predicting the data accurately; and minimal, i.e. with no redundancy (level 1), given information at one of the other levels. <p> PRISM uses a top-down approach, like that of C4.5, for rule rather than decision tree induction (Cendrowska, 1987); and INDUCT is an improved version that is probabilistically based and copes with situations that demand nondeterministic rules <ref> (Gaines, 1991) </ref>. FOIL, for first-order inductive learner (Quinlan, 1990), induces logical definitions, expressed as Horn clauses, from data presented in the form of relations. It begins with a set of relations, each defined as a set of related values.
Reference: <author> Gennari, J.H., </author> <year> 1989. </year> <title> A survey of clustering methods., </title> <type> Technical Report 89-38, </type> <institution> Irvine: University of California, Dept. of Information and Computer Science. </institution>
Reference: <author> Haussler, D., </author> <year> 1987. </year> <title> Learning conjunctive concepts in structural domains. </title> <booktitle> Proc. AAAI: </booktitle> <volume> 466 470. </volume>
Reference: <author> Kaufman, K.A., and Michalski, R.S., </author> <year> 1993. </year> <title> EMERALD 2: An Integrated System of Machine Learning and Discovery Programs to Support Education and Experimental Research. </title> <type> Technical Report MLI 93-10, </type> <institution> George Mason University. </institution>
Reference-contexts: Other systems such as the MLC++ project at Stanford University (Kohavi et al,1994), and the European Machine Learning Toolbox project (Kodratoff et al, 1992) are intended for use by machine learning researchers and programmers developing and evaluating machine learning schemes, while the Emerald system <ref> (Kaufman et al, 1993) </ref> is designed as an educational tool. The WEKA workbench is flexible enough to be used as in a machine learning research role, and has also been used successfully in undergraduate courses teaching machine learning.
Reference: <author> Kodratoff, Y., Sleeman, D., Uszynski, M., Causse, K., and Craw, S., </author> <year> 1992. </year> <title> Building a Machine Learning Toolbox. </title> <editor> In: Steels, L. and Lepape, B. (Editors), </editor> <title> Enhancing the Knowledge Engineering Process, </title> <publisher> Elsevier Science Publishers B.V.: </publisher> <pages> 81-108. </pages>
Reference-contexts: Other systems such as the MLC++ project at Stanford University (Kohavi et al,1994), and the European Machine Learning Toolbox project <ref> (Kodratoff et al, 1992) </ref> are intended for use by machine learning researchers and programmers developing and evaluating machine learning schemes, while the Emerald system (Kaufman et al, 1993) is designed as an educational tool.
Reference: <author> Kohavi, R., George, J., Long, R., Manley, D., and Pfleger, K., </author> <year> 1994. </year> <title> MLC++: A Machine Learning Library in C++. </title> <type> Technical Report, </type> <institution> Computer Science Department, Stanford University. </institution>
Reference-contexts: Other systems such as the MLC++ project at Stanford University <ref> (Kohavi et al,1994) </ref>, and the European Machine Learning Toolbox project (Kodratoff et al, 1992) are intended for use by machine learning researchers and programmers developing and evaluating machine learning schemes, while the Emerald system (Kaufman et al, 1993) is designed as an educational tool.
Reference: <author> Lebowitz, M. </author> <year> 1986. </year> <title> Concept learning in a rich input domain: </title> <booktitle> Generalization-Based Memory. </booktitle>
Reference: <editor> In: R.S. Michalski, J.G. Carbonell and T.M. Mitchell (Editors), </editor> <booktitle> Machine Learning: An Artificial Intelligence Approach, Volume II, </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> Los Altos, CA. </address> <pages> 193-214. </pages>
Reference: <author> MacDonald, B.A. and Witten, I.H. </author> <year> 1989, </year> <title> A framework for knowledge acquisition through techniques of concept learning. </title> <journal> IEEE Trans Systems, Man and Cybernetics 19(3), </journal> <month> 499-512. </month> <title> 21 Michalski, R.S. Pattern recognition as rule-guided inductive inference. 1980, </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence 2(4), </journal> <pages> 349-361. </pages>
Reference: <author> Michalski, R.S. and Chilausky, R.L., </author> <year> 1980. </year> <title> Learning by being told and learning from examples: an experimental comparison of the two methods of knowledge acquisition in the context of developing an expert system for soybean disease diagnosis. International J Policy Analysis and Information Systems, </title> <type> 4: 125161 Michalski, R.S., </type> <year> 1983. </year> <title> A theory and methodology of inductive learning. </title> <journal> Artificial Intelligence, </journal> <volume> 20: </volume> <pages> 111161. </pages>
Reference-contexts: In this early application the similarity-based learning program AQ11 was used to analyze data from over 600 questionnaires describing diseased plants <ref> (Michalski & Chilausky, 1980) </ref>. Each plant was assigned to one of 17 disease categories by an expert collaberator, who used a variety of measurements describing the condition of the plant. <p> Surprisingly, the computer-generated rules outperformed the expert-derived rules on the remaining test instancesthey gave the correct disease top ranking just over 97% of the time, compared to just under 72% for the expert-derived rules <ref> (Michalski & Chilausky, 1980) </ref>. Furthermore, according to Quinlan (in foreword, PiatetskyShapiro & Frawley, 1991), not only did A Q 11 find rules that outperformed those of the expert collaborator, but the same expert was so impressed that he adopted the discovered rules in place of his own.
Reference: <author> Michalski, R.S., Davis, J.H., Bisht, V.S. and Sinclair, J.B., </author> <year> 1982. </year> <title> PLANT/ds: an expert consulting system for the diagnosis of soybean diseases. </title> <booktitle> Proc. European Conference on Artificial Intelligence, </booktitle> <address> Orsay, France, </address> <month> July: 133138. </month>
Reference: <author> Mitchell, T.M., Keller, R.M. and Kedar-Cabelli, S.T., </author> <year> 1986. </year> <title> Explanation-based generalization: a unifying view. </title> <note> Machine Learning 1(1) 47-80 Monk, </note> <author> T.J., Mitchell, S., Smith, L.A. and Holmes, G., </author> <year> 1994. </year> <title> Geometric comparison of classifications and rule sets, </title> <booktitle> Proc. AAAI workshop on knowledge discovery in databases, </booktitle> <address> Seattle, Washington, </address> <month> July: </month> <pages> 395-406. </pages>
Reference-contexts: However, it may still be possible to learn new and more efficient ways of employing that theory to interpret examples; this is often called explanation-based learning because it focuses on the explanations that the theory is capable of generating for each example <ref> (Mitchell, et al. 1986, DeJon et al., 1986) </ref>.
Reference: <author> Mooney, R.J., </author> <year> 1992. </year> <title> Encouraging Experimental Results on Learning CNF. </title> <type> Technical Report, </type> <institution> University of Texas. </institution>
Reference-contexts: CNF and DNF are simple algorithms for creating rules that take the form of conjunctions (the terms in a rule are ANDed together) and disjunctions (terms ORed together) respectively. Interesting and surprising results have been reported on differences between these two seemingly very similar concept representations <ref> (Mooney, 1992) </ref>. PRISM uses a top-down approach, like that of C4.5, for rule rather than decision tree induction (Cendrowska, 1987); and INDUCT is an improved version that is probabilistically based and copes with situations that demand nondeterministic rules (Gaines, 1991).
Reference: <author> Murthy, S.K., Kasif, S., Salzberg, S., and Beigel, R., </author> <year> 1993. </year> <title> OC1: Randomized Induction of Decision Trees. </title> <booktitle> Proc. of the Eleventh National Conference on Artificial Intelligence. </booktitle>
Reference-contexts: C4.5 is a well-developed piece of software that derives from the earlier ID3 scheme (Quinlan, 1986), which itself evolved through several versions. OC1, another scheme in the workbench, also induces decision trees top-down, but each node classifies examples by testing linear combinations of features instead of a single feature <ref> (Murthy et al., 1993) </ref>. Although restricted to numeric data, this method consistently finds much smaller trees than 12 comparable methods that use univariate trees. CNF, DNF, PRISM, and INDUCT all represent the concepts they induce in the form of rules rather than decision trees.
Reference: <institution> Washington, D.C.: </institution> <note> 322327 Ousterhout, </note> <author> J. K., </author> <year> 1994. </year> <title> TCL and TK toolkit, </title> <publisher> Addison-Wesley. </publisher>
Reference: <author> Pazzani, M. and Kibler, D. </author> <year> 1992, </year> <title> The utility of knowledge in inductive learning. Machine Learning 9(1), </title> <editor> 57-94 PiatetskyShapiro, G. and Frawley, W.J. (Editors), </editor> <year> 1991: </year> <title> Knowledge discovery in databases. </title> <publisher> AAAI Press, </publisher> <address> Menlo Park, CA. </address> <note> 525 pp. 22 Quinlan, </note> <author> J.R., </author> <year> 1986. </year> <title> Induction of decision trees. </title> <journal> Machine Learning, </journal> <volume> 1: </volume> <pages> 81106. </pages>
Reference-contexts: Single versus multi-paradigm. A final distinction can be made between single-paradigm learners and multi-paradigm ones. Because of the various strengths and weaknesses of current machine learning schemes, there is currently a great deal of interest in combining learning mechanisms that adopt several approaches <ref> (e.g. Pazzani et al., 1992) </ref>. For example, similarity-based learning may be used to correct or complete a partial domain theory, or a judicious combination of bottom-up and top-down learning may outperform either on its own.
Reference: <author> Quinlan, J.R., </author> <year> 1990. </year> <title> Learning Logical Definitions from Relations. </title> <journal> Machine Learning, </journal> <volume> 5: </volume> <pages> 239-266. </pages>
Reference-contexts: PRISM uses a top-down approach, like that of C4.5, for rule rather than decision tree induction (Cendrowska, 1987); and INDUCT is an improved version that is probabilistically based and copes with situations that demand nondeterministic rules (Gaines, 1991). FOIL, for first-order inductive learner <ref> (Quinlan, 1990) </ref>, induces logical definitions, expressed as Horn clauses, from data presented in the form of relations. It begins with a set of relations, each defined as a set of related values. <p> They provided data from ten herds, over six years, representing 19000 records, each containing 705 attributes. These attributes are summarized in Table 3. INITIAL DATA STRUCTURING The machine learning tools used for the analysis were primarily C4.5 (Quinlan, 1992) and FOIL <ref> (Quinlan, 1990) </ref>. The initial raw data set as received from the Livestock Improvement Corporation was run through C4.5 on the workbench. Classification was done on the fate code attribute, which can take the values sold, dead, lost and unknown. The resulting tree, shown in Figure 4, proved disappointing.
Reference: <author> Quinlan, J.R., </author> <year> 1991. </year> <title> Determinate Literals in Inductive Logic Programming. </title> <booktitle> Proc. 12th International Joint Conference on Artificial Intelligence: </booktitle> <pages> 746-750, </pages> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Quinlan, J.R., </author> <year> 1992. </year> <title> C4.5: Programs for Machine Learning. </title> <publisher> Morgan Kaufmann. </publisher> <pages> 302 pp. </pages>
Reference-contexts: The other schemes in the workbench are for supervised learning. C4.5 performs top-down induction of decision trees from a set of examples which have each been given a classification <ref> (Quinlan, 1992) </ref>. Typically, a training set will be specified by the user. The root of the tree specifies an attribute to be selected and tested first, and the subordinate nodes dictate tests on further attributes. The leaves are marked to show the classification of the object they represent. <p> They provided data from ten herds, over six years, representing 19000 records, each containing 705 attributes. These attributes are summarized in Table 3. INITIAL DATA STRUCTURING The machine learning tools used for the analysis were primarily C4.5 <ref> (Quinlan, 1992) </ref> and FOIL (Quinlan, 1990). The initial raw data set as received from the Livestock Improvement Corporation was run through C4.5 on the workbench. Classification was done on the fate code attribute, which can take the values sold, dead, lost and unknown.
Reference: <author> Quinlan, J.R., and Cameron-Jones, R.M., </author> <year> 1993. </year> <title> FOIL: a midterm report. </title> <booktitle> Proc. European Conference on Machine Learning, </booktitle> <publisher> Springer Verlag: </publisher> <pages> 3-20 Schank, </pages> <editor> R.C., Collins, G.C. and Hunter, L.E., </editor> <year> 1986. </year> <title> Transcending inductive category formation in learning. </title> <journal> Behavioral and Brain Sciences, </journal> <volume> 9: </volume> <pages> 639651. </pages>
Reference: <author> Winston, P.H. </author> <year> 1972. </year> <title> Learning structural descriptions from examples. </title> <editor> in P.H. Winston, Ed., </editor> <booktitle> The Psychology of Computer Vision, </booktitle> <publisher> McGraw-Hill, </publisher> <address> New York, </address> <pages> 689-702. </pages>

References-found: 25

