URL: http://www.combinatorics.org/Volume_5/PostScriptfiles/v5i1r20.ps
Refering-URL: http://www.combinatorics.org/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: email: Conrado.Martinez@lsi.upc.es  email: e9125354@fbma.tuwien.ac.at  email: Helmut.Prodinger@tuwien.ac.at  
Title: ON THE NUMBER OF DESCENDANTS AND ASCENDANTS IN RANDOM SEARCH TREES  
Author: Conrado Mart nez Alois Panholzer Helmut Prodinger 
Note: AMS Subject Classification. 05A15 (primary) 05C05, 68P10 (secondary)  
Date: Submitted: January 7, 1997; Accepted: March 26, 1998.  
Web: www: http://www-lsi.upc.es/~conrado/home.html  www: http://info.tuwien.ac.at/theoinf/proding.htm  
Address: Pau Gargallo 5, E-08028 Barcelona, Spain.  Wiedner Hauptstrasse 8-10, A-1040 Vienna, Austria.  Wiedner Hauptstrasse 8-10, A-1040 Vienna, Austria.  
Affiliation: Departament de Llenguatges i Sistemes Informatics, Polytechnical University of Catalonia,  Institut fur Algebra und Diskrete Mathematik, Technical University of Vienna,  Institut fur Algebra und Diskrete Mathematik, Technical University of Vienna,  
Abstract: The number of descendants of a node in a binary search tree (BST) is the size of the subtree having this node as a root; the number of ascendants is the number of nodes on the path connecting this node with the root. Using a purely combinatorial approach (generating functions and differential equations) we are able to extend previous results. For the number of descendants we get explicit formula for all moments; for the number of ascendants, which is harder, we get the variance. A natural extension of binary search trees occurs when performing local reorganisations. Poblete and Munro have already analyzed some aspects of these locally balanced binary search trees (LBSTs). Here, we relate these structures with the performance of median-of-three Quicksort. We get as new results the variances for ascendants and descendants in this setting. If the rank of the node itself is picked at random ("grand averages"), the corresponding parameters only depend on the size n. In this instance, we get all the moments for the descendants (BST and LBST), as well as the probabilities. For ascendants (LBST), we get the variance and (in principle) the higher moments, as well as the (normal) limiting distribution. The emphasis is on explicit formula, and these are sometimes quite involved. Thus, in some instances, we have decided to state abridged versions in the paper and collect the long forms into an appendix that can be downloaded from the URLs http://info.tuwien.ac.at/theoinf/abstract/abs 120.htm and http://www.lsi.upc.es/~conrado/research/. fl This research was partly done while the third author was visiting the CRM (Centre de Recerca Matematica, Institut d'Estudis Catalans). The first author was supported by the ESPRIT Long Term Research Project ALCOM IT (contract no. 20244). The second author was supported by the FWF Project 12599-MAT. All 3 authors are supported by the Project 16/98 of Acciones Integradas 1998/99. The appendix of this paper with all the outsize expressions is downloadable from the URLs http://info.tuwien.ac.at/theoinf/abstract/abs 120.htm and http://www.lsi.upc.es/~conrado/research/. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> G.M. </author> <title> Adel'son-Vel'skii and E.M. Landis. An algorithm for the organization of information. </title> <journal> Dokladi Akademia Nauk SSSR, </journal> <volume> 146(2) </volume> <pages> 263-266, </pages> <year> 1962. </year> <journal> English translation in Soviet Math. </journal> <volume> Doklay 3 ,1962, </volume> <pages> 1259-1263. </pages>
Reference-contexts: We assume that the reader is already familiar with binary search trees and the basic algorithms to manipulate them [20, 31, 9]. Height and weight-balanced versions of the binary search trees, like AVL and red-black trees <ref> [1, 11] </ref>, have been proposed and find many useful applications, since all of them guarantee good worst-case performance of both searches and updates. Locally balanced search trees (LBSTs) were introduced by Bell [4] and Walker and Wood [34], and thoroughly analyzed by Poblete and Munro in [27]. <p> Locally balanced binary search trees One approach to avoid drastically unbalanced binary search trees is the introduction of strict balance constraints like in AVLs or red-black trees <ref> [1, 11] </ref>. Such schemes guarantee logarithmic performance of searches and updates in the worst-case, but they have additional space requirements and are more difficult to implement than standard BSTs.
Reference: [2] <author> C.R. Aragon and R.G. Seidel. </author> <title> Randomized search trees. </title> <booktitle> In Proc. of the 30th Annual IEEE Symposium on Foundations of Computer Science (FOCS), </booktitle> <pages> pages 540-545, </pages> <year> 1989. </year>
Reference-contexts: 1. Introduction Binary search trees are among the most important and commonly used data structures, their applications spanning a wide range of the areas of Computer Science. Standard binary search trees (BSTs, for short) are still the subject of active research, see for instance the recent articles <ref> [2, 28] </ref>.
Reference: [3] <author> S.R. Arora and W.T. Dent. </author> <title> Randomized binary search technique. </title> <journal> Comm. ACM, </journal> <volume> 12(2) </volume> <pages> 77-80, </pages> <year> 1969. </year>
Reference-contexts: THE ELECTRONIC JOURNAL OF COMBINATORICS 5 (1998), #R20 5 BST LBST Of a given node Of a random node Of a given node Of a random node Average <ref> [3] </ref>, Probability, Average [17], Average, Ascendants variance fl moments, limit variance fl variance [27] fl , distribution [23, 5, 22, 18] higher order moments, PGF, limit distribution fl Descendants Probability, Probability, PGF, average, Probability, moments [21] fl moments [21] fl variance fl moments fl Table 1. <p> This differential equation has the following solution A (z; u; v) = (1 z) v (1 uz) v 0 Starting with this generating function, it is easy to get the following theorems. At first we obtain an old result from <ref> [3] </ref>: Theorem 4.1. The expected number of ascendants a n;j = E [A n;j ] of the j th node in a random binary search tree of size n is a n;j = H j + H n+1j 1: Proof.
Reference: [4] <author> C.J. Bell. </author> <title> An Investigation into the Principles of the Classification and Analysis of Data on an Automatic Digital Computer. </title> <type> PhD thesis, </type> <institution> Leeds University, </institution> <year> 1965. </year>
Reference-contexts: Height and weight-balanced versions of the binary search trees, like AVL and red-black trees [1, 11], have been proposed and find many useful applications, since all of them guarantee good worst-case performance of both searches and updates. Locally balanced search trees (LBSTs) were introduced by Bell <ref> [4] </ref> and Walker and Wood [34], and thoroughly analyzed by Poblete and Munro in [27]. LBSTs have been proposed as an alternative to more complex balancing schemes for search trees. <p> Such schemes guarantee logarithmic performance of searches and updates in the worst-case, but they have additional space requirements and are more difficult to implement than standard BSTs. As an alternative, several authors <ref> [4, 34, 27] </ref> have suggested the use of a simple heuristic that makes the construction of poorly balanced trees much less likely than with the use of the standard algorithms. Furthermore, the heuristic was shown to yield significant savings in the expected search time.
Reference: [5] <author> G.G. Brown and B.O. Shubert. </author> <title> On random binary trees. </title> <journal> Mathematics of Operations Research, </journal> <volume> 9(1) </volume> <pages> 43-65, </pages> <year> 1984. </year>
Reference-contexts: THE ELECTRONIC JOURNAL OF COMBINATORICS 5 (1998), #R20 5 BST LBST Of a given node Of a random node Of a given node Of a random node Average [3], Probability, Average [17], Average, Ascendants variance fl moments, limit variance fl variance [27] fl , distribution <ref> [23, 5, 22, 18] </ref> higher order moments, PGF, limit distribution fl Descendants Probability, Probability, PGF, average, Probability, moments [21] fl moments [21] fl variance fl moments fl Table 1. Summary of previous works and the results of this paper. The structure of the paper is as follows.
Reference: [6] <author> Ph. Flajolet and A.M. Odlyzko. </author> <title> Singularity analysis of generating functions. </title> <journal> SIAM Journal on Discrete Mathematics, </journal> <volume> 3(2) </volume> <pages> 216-240, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: them in this paper, the reader should be aware of the existing powerful techniques to extract asymptotic information about the coefficients of a generating function if we know its behaviour near its singularities or in some case, even if we only know the functional equation satisfied by the generating function <ref> [33, 6] </ref>. <p> Using the expansion <ref> [6] </ref> [z n ](1 z) ff = (ff) 1 + 2n 1 we get uniformly in the circle jv 1j &lt; 1 4 v 2 ( + 4v + 3)(1 z) (1)=2 + O (n) v 2 ( + 4v + 3) 2 ) 3 1 n : Applying the following
Reference: [7] <author> Ph. Flajolet and R. Sedgewick. </author> <title> The Average Case Analysis of Algorithms: Multivariate Asymptotics and Limit Distributions. </title> <institution> Rapport de recherche de l'INRIA #3162, </institution> <year> 1997. </year> <note> THE ELECTRONIC JOURNAL OF COMBINATORICS 5 (1998), #R20 26 </note>
Reference-contexts: ff = (ff) 1 + 2n 1 we get uniformly in the circle jv 1j &lt; 1 4 v 2 ( + 4v + 3)(1 z) (1)=2 + O (n) v 2 ( + 4v + 3) 2 ) 3 1 n : Applying the following quasi-power theorem of Hwang <ref> [15, 7] </ref> leads immediately to the above given result. Theorem 7.3. (Quasi-power theorem [H.-K.
Reference: [8] <author> Ph. Flajolet and M. Soria. </author> <title> General combinatorial schemas: Gaussian limit distributions and exponential tails. </title> <journal> Discrete Mathematics, </journal> <volume> 114, </volume> <year> 1993. </year>
Reference-contexts: The solution of the differential equation above is the explicit form given in the theorem. Extracting coefficients in exact form from there is quite difficult. However, as Philippe Flajolet kindly pointed to us, asymptotic information and most notably, the limiting probability distribution can be established <ref> [8, 15] </ref>. In this case, it follows that A n converges in distribution (converges in law) to a Gaussian distribution, i.e.
Reference: [9] <author> G.H. Gonnet and R. Baeza-Yates. </author> <title> Handbook of Algorithms and Data Structures In Pascal and C. </title> <publisher> Addison-Wesley, </publisher> <address> 2nd edition, </address> <year> 1991. </year>
Reference-contexts: We assume that the reader is already familiar with binary search trees and the basic algorithms to manipulate them <ref> [20, 31, 9] </ref>. Height and weight-balanced versions of the binary search trees, like AVL and red-black trees [1, 11], have been proposed and find many useful applications, since all of them guarantee good worst-case performance of both searches and updates.
Reference: [10] <author> R.L. Graham, D.E. Knuth, and O. Patashnik. </author> <title> Concrete Mathematics. </title> <publisher> Addison-Wesley, </publisher> <year> 1989. </year>
Reference-contexts: n;j = m j the root is the k th element i h the root is the k th element i 1 [[m = n]] + n k=1 1 n X P [D k1;j = m] ; (5) where [[P ]] is 1 if P is true and 0 otherwise <ref> [10] </ref>. This recursion translates nicely into a functional equation over the generating function for the family of random variables fD n;j g. Solving the functional equation and extracting coefficients of the generating function, we get the following theorem, which was already found by Lent [21] using probabilistic techniques. Theorem 3.1.
Reference: [11] <author> L.J. Guibas and R. Sedgewick. </author> <title> A dichromatic framework for balanced trees. </title> <booktitle> In Proc. of the 19th Annual IEEE Symposium on Foundations of Computer Science (FOCS), </booktitle> <pages> pages 8-21, </pages> <year> 1978. </year>
Reference-contexts: We assume that the reader is already familiar with binary search trees and the basic algorithms to manipulate them [20, 31, 9]. Height and weight-balanced versions of the binary search trees, like AVL and red-black trees <ref> [1, 11] </ref>, have been proposed and find many useful applications, since all of them guarantee good worst-case performance of both searches and updates. Locally balanced search trees (LBSTs) were introduced by Bell [4] and Walker and Wood [34], and thoroughly analyzed by Poblete and Munro in [27]. <p> Locally balanced binary search trees One approach to avoid drastically unbalanced binary search trees is the introduction of strict balance constraints like in AVLs or red-black trees <ref> [1, 11] </ref>. Such schemes guarantee logarithmic performance of searches and updates in the worst-case, but they have additional space requirements and are more difficult to implement than standard BSTs.
Reference: [12] <author> C.A.R. Hoare. </author> <title> Find (Algorithm 65). </title> <journal> Comm. ACM, </journal> <volume> 4 </volume> <pages> 321-322, </pages> <year> 1961. </year>
Reference-contexts: Deepening our knowledge about binary search trees is interesting in its own; moreover, most of this knowledge can be translated and applied to other data structures such as heap ordered trees, k-d-trees [33], and to important algorithms like quicksort and Hoare's Find algorithm for selection (also known as quickselect) <ref> [12, 13, 30, 31] </ref>. We assume that the reader is already familiar with binary search trees and the basic algorithms to manipulate them [20, 31, 9]. <p> P n;j = internal path length, Then, S n;j = P n;j + 1 = A n;j ; E [U n ] = n + 1 E [I n ] = n ( E [A n ] 1) ; There is also a close relationship between the performance of quickselect <ref> [12, 19, 17] </ref> and the number of ascendants. Proposition 1.3. Let F n;j be the number of recursive calls made by quickselect to select the j th element out of n elements.
Reference: [13] <author> C.A.R. Hoare. </author> <title> Quicksort. </title> <journal> Comput. J., </journal> <volume> 5 </volume> <pages> 10-15, </pages> <year> 1962. </year>
Reference-contexts: Deepening our knowledge about binary search trees is interesting in its own; moreover, most of this knowledge can be translated and applied to other data structures such as heap ordered trees, k-d-trees [33], and to important algorithms like quicksort and Hoare's Find algorithm for selection (also known as quickselect) <ref> [12, 13, 30, 31] </ref>. We assume that the reader is already familiar with binary search trees and the basic algorithms to manipulate them [20, 31, 9].
Reference: [14] <author> M. Hoshi and Ph. Flajolet. </author> <title> Page usage in a quadtree index. </title> <journal> BIT, </journal> <volume> 32(3) </volume> <pages> 384-402, </pages> <year> 1992. </year>
Reference-contexts: The study of the number of descendants has applications in the context of paged trees (see for instance <ref> [20, 14] </ref>).
Reference: [15] <author> H.-K. Hwang. </author> <title> Theoremes limites pour les structures combinatoires et les fonctions arithmetiques. </title> <type> PhD thesis, </type> <institution> Ecole Polytechnique, </institution> <year> 1994. </year>
Reference-contexts: The solution of the differential equation above is the explicit form given in the theorem. Extracting coefficients in exact form from there is quite difficult. However, as Philippe Flajolet kindly pointed to us, asymptotic information and most notably, the limiting probability distribution can be established <ref> [8, 15] </ref>. In this case, it follows that A n converges in distribution (converges in law) to a Gaussian distribution, i.e. <p> ff = (ff) 1 + 2n 1 we get uniformly in the circle jv 1j &lt; 1 4 v 2 ( + 4v + 3)(1 z) (1)=2 + O (n) v 2 ( + 4v + 3) 2 ) 3 1 n : Applying the following quasi-power theorem of Hwang <ref> [15, 7] </ref> leads immediately to the above given result. Theorem 7.3. (Quasi-power theorem [H.-K.
Reference: [16] <author> E. Kamke. </author> <title> Differentialgleichungen: Losungsmethoden und Losungen. </title> <publisher> Teubner, Stuttgart, </publisher> <year> 1977. </year>
Reference-contexts: The former can be solved, in principle, by quadrature through the variation of constant |actually, functions in u and v| method. For the second order differential equations, the theory of hypergeometric differential equations comes into play <ref> [16] </ref>. Nowadays, most of the necessary mathematical knowledge is embodied into modern computer algebra systems. In our case, Maple needed little or no assistance to solve the differential equations that we had.
Reference: [17] <author> P. Kirschenhofer, C. Martnez, and H. Prodinger. </author> <title> Analysis of Hoare's Find Algorithm with Median-of-three partition. Random Structures & Algorithms, </title> <booktitle> 10 </booktitle> <pages> 143-156, </pages> <year> 1997. </year>
Reference-contexts: A similar idea, namely, selecting a sample of 3 elements and taking the median of the sample as the pivot element for partitioning in algorithms like quicksort and quickselect has been shown to yield significant improvements in theory and practice <ref> [30, 17] </ref>. Random search trees, either random BSTs or random LBSTs, are search trees built by performing n random insertions into an initially empty tree [20, 24]. <p> P n;j = internal path length, Then, S n;j = P n;j + 1 = A n;j ; E [U n ] = n + 1 E [I n ] = n ( E [A n ] 1) ; There is also a close relationship between the performance of quickselect <ref> [12, 19, 17] </ref> and the number of ascendants. Proposition 1.3. Let F n;j be the number of recursive calls made by quickselect to select the j th element out of n elements. <p> THE ELECTRONIC JOURNAL OF COMBINATORICS 5 (1998), #R20 5 BST LBST Of a given node Of a random node Of a given node Of a random node Average [3], Probability, Average <ref> [17] </ref>, Average, Ascendants variance fl moments, limit variance fl variance [27] fl , distribution [23, 5, 22, 18] higher order moments, PGF, limit distribution fl Descendants Probability, Probability, PGF, average, Probability, moments [21] fl moments [21] fl variance fl moments fl Table 1. <p> The only difference between the expected number of passes in quickselect, as given in the work by Kirschenhofer et al. <ref> [17] </ref>, and the number of ascendants in LBSTs relies on the initial conditions.
Reference: [18] <author> P. Kirschenhofer and H. Prodinger. </author> <title> Comparisons in Hoare's Find algorithm. Combinatorics, </title> <journal> Probability and Computing, </journal> <volume> 7 </volume> <pages> 111-120, </pages> <year> 1998. </year>
Reference-contexts: THE ELECTRONIC JOURNAL OF COMBINATORICS 5 (1998), #R20 5 BST LBST Of a given node Of a random node Of a given node Of a random node Average [3], Probability, Average [17], Average, Ascendants variance fl moments, limit variance fl variance [27] fl , distribution <ref> [23, 5, 22, 18] </ref> higher order moments, PGF, limit distribution fl Descendants Probability, Probability, PGF, average, Probability, moments [21] fl moments [21] fl variance fl moments fl Table 1. Summary of previous works and the results of this paper. The structure of the paper is as follows.
Reference: [19] <author> D.E. Knuth. </author> <title> Mathematical analysis of algorithms. </title> <booktitle> In Proc. of the 1971 IFIP Congress, </booktitle> <pages> pages 19-27, </pages> <address> Amsterdam, 1972. </address> <publisher> North-Holland. </publisher>
Reference-contexts: P n;j = internal path length, Then, S n;j = P n;j + 1 = A n;j ; E [U n ] = n + 1 E [I n ] = n ( E [A n ] 1) ; There is also a close relationship between the performance of quickselect <ref> [12, 19, 17] </ref> and the number of ascendants. Proposition 1.3. Let F n;j be the number of recursive calls made by quickselect to select the j th element out of n elements.
Reference: [20] <author> D.E. Knuth. </author> <title> The Art of Computer Programming: Sorting and Searching, volume 3. </title> <publisher> Addison-Wesley, </publisher> <year> 1973. </year>
Reference-contexts: We assume that the reader is already familiar with binary search trees and the basic algorithms to manipulate them <ref> [20, 31, 9] </ref>. Height and weight-balanced versions of the binary search trees, like AVL and red-black trees [1, 11], have been proposed and find many useful applications, since all of them guarantee good worst-case performance of both searches and updates. <p> Random search trees, either random BSTs or random LBSTs, are search trees built by performing n random insertions into an initially empty tree <ref> [20, 24] </ref>. <p> The study of the number of descendants has applications in the context of paged trees (see for instance <ref> [20, 14] </ref>). <p> Excellent sources of information about generating functions and their applications to combinatorics and the analysis of algorithms are <ref> [35, 33, 32, 20] </ref>. We make extensive use in this paper of probability generating functions (PGFs) as well as multivariate generating functions whose coefficients are PGFs themselves. We define them in turn. <p> Last, but not least, we can obtain the following corollaries, from Propositions 1.4 and 1.5 and the theorems in this section. These results can already be found in <ref> [20] </ref>, although there is a slight difference in E h (b) i , because n + 1 comparisons per partition are counted there, while we count n 1 comparison per partition. Corollary 3.2.
Reference: [21] <author> J. Lent. </author> <title> Probabilistic analysis of some searching and sorting algorithms. </title> <type> PhD thesis, </type> <institution> George Washington University, </institution> <year> 1996. </year>
Reference-contexts: given node Of a random node Of a given node Of a random node Average [3], Probability, Average [17], Average, Ascendants variance fl moments, limit variance fl variance [27] fl , distribution [23, 5, 22, 18] higher order moments, PGF, limit distribution fl Descendants Probability, Probability, PGF, average, Probability, moments <ref> [21] </ref> fl moments [21] fl variance fl moments fl Table 1. Summary of previous works and the results of this paper. The structure of the paper is as follows. We start with an overview of some basic facts about generating functions and, in particular, about probability generating functions (Section 2). <p> a random node Of a given node Of a random node Average [3], Probability, Average [17], Average, Ascendants variance fl moments, limit variance fl variance [27] fl , distribution [23, 5, 22, 18] higher order moments, PGF, limit distribution fl Descendants Probability, Probability, PGF, average, Probability, moments <ref> [21] </ref> fl moments [21] fl variance fl moments fl Table 1. Summary of previous works and the results of this paper. The structure of the paper is as follows. We start with an overview of some basic facts about generating functions and, in particular, about probability generating functions (Section 2). <p> In Section 3 we develop the main steps of our approach, taking the analysis of the number of descendants in random BSTs as a first introductory example. We provide here alternative derivations to the results of Lent <ref> [21] </ref>, finding the probability that the j th node in a random BST of size n has m descendants (Theorem 3.1). We also find exact and asymptotic values for all ordinary moments, including the expected value and variance (Theorem 3.2). <p> This recursion translates nicely into a functional equation over the generating function for the family of random variables fD n;j g. Solving the functional equation and extracting coefficients of the generating function, we get the following theorem, which was already found by Lent <ref> [21] </ref> using probabilistic techniques. Theorem 3.1. <p> A few comments concerning the last theorem are in order now. Observe that for s 3 1 n X d n;j = s 1 s + 1 + n : Asymptotically, this quantity is ~ s 1 one of the observations in the work of Lent <ref> [21] </ref>. The coincidence in asymptotic behavior with d (s) is remarkable; recall that in general E [D s 2 n 1jn s 5 ; except when s = 1 and the same observation holds for the shifted factorial moments we were dealing with.
Reference: [22] <author> G. Louchard. </author> <title> Exact and asymptotic distributions in digital and binary search trees. </title> <journal> Theoretical Informatics and Applications, </journal> <volume> 21(4) </volume> <pages> 479-496, </pages> <year> 1987. </year>
Reference-contexts: THE ELECTRONIC JOURNAL OF COMBINATORICS 5 (1998), #R20 5 BST LBST Of a given node Of a random node Of a given node Of a random node Average [3], Probability, Average [17], Average, Ascendants variance fl moments, limit variance fl variance [27] fl , distribution <ref> [23, 5, 22, 18] </ref> higher order moments, PGF, limit distribution fl Descendants Probability, Probability, PGF, average, Probability, moments [21] fl moments [21] fl variance fl moments fl Table 1. Summary of previous works and the results of this paper. The structure of the paper is as follows.
Reference: [23] <author> W.C. Lynch. </author> <title> More combinatorial properties of certain trees. </title> <journal> Comput. J., </journal> <volume> 7 </volume> <pages> 299-302, </pages> <year> 1965. </year>
Reference-contexts: THE ELECTRONIC JOURNAL OF COMBINATORICS 5 (1998), #R20 5 BST LBST Of a given node Of a random node Of a given node Of a random node Average [3], Probability, Average [17], Average, Ascendants variance fl moments, limit variance fl variance [27] fl , distribution <ref> [23, 5, 22, 18] </ref> higher order moments, PGF, limit distribution fl Descendants Probability, Probability, PGF, average, Probability, moments [21] fl moments [21] fl variance fl moments fl Table 1. Summary of previous works and the results of this paper. The structure of the paper is as follows.
Reference: [24] <author> H.M. Mahmoud. </author> <title> Evolution of Random Search Trees. </title> <publisher> Wiley Interscience, </publisher> <year> 1992. </year>
Reference-contexts: Random search trees, either random BSTs or random LBSTs, are search trees built by performing n random insertions into an initially empty tree <ref> [20, 24] </ref>.
Reference: [25] <author> A. Panholzer. </author> <title> Untersuchungen zur durchschnittlichen Gestalt gewisser Baumfamilien. Mit besonderer Beruck-sichtigung von Anwendungen in der Informatik. </title> <type> PhD thesis, </type> <institution> Technische Universitat Wien, </institution> <year> 1997. </year>
Reference: [26] <author> P.V. Poblete. </author> <title> The analysis of heuristics for search trees. </title> <journal> Acta Informatica, </journal> <volume> 30 </volume> <pages> 233-248, </pages> <year> 1993. </year>
Reference-contexts: LBSTs). The number of descendants and the number of ascendants in random BSTs have been investigated in several previous works ([3, 5, 23, 22, 21]). The number of ascendants of a random node in a random LBST has been studied in <ref> [27, 26] </ref>. We define the number of descendants D n;j as the size of the subtree rooted at the j th node, so we count the j th node as a descendant of itself. <p> We will call the binary search trees constructed in this way locally balanced binary search trees (LBST, for short). Poblete and Munro [27] and Poblete <ref> [26] </ref> carry on the analysis of this heuristic and some generalizations by means of bottom-up or fringe techniques: they basically study the number of nodes that are at level k and which are the root of a subtree of size 1 or 2.
Reference: [27] <author> P.V. Poblete and J.I. Munro. </author> <title> The analysis of a fringe heuristic for binary search trees. </title> <journal> J. Algorithms, </journal> <volume> 6 </volume> <pages> 336-350, </pages> <year> 1985. </year>
Reference-contexts: Locally balanced search trees (LBSTs) were introduced by Bell [4] and Walker and Wood [34], and thoroughly analyzed by Poblete and Munro in <ref> [27] </ref>. LBSTs have been proposed as an alternative to more complex balancing schemes for search trees. In these search trees, only local rebalancing is made; after each insertion, local rebalancing is applied to ensure that all subtrees of size 3 in the tree are complete 1 . <p> LBSTs). The number of descendants and the number of ascendants in random BSTs have been investigated in several previous works ([3, 5, 23, 22, 21]). The number of ascendants of a random node in a random LBST has been studied in <ref> [27, 26] </ref>. We define the number of descendants D n;j as the size of the subtree rooted at the j th node, so we count the j th node as a descendant of itself. <p> THE ELECTRONIC JOURNAL OF COMBINATORICS 5 (1998), #R20 5 BST LBST Of a given node Of a random node Of a given node Of a random node Average [3], Probability, Average [17], Average, Ascendants variance fl moments, limit variance fl variance <ref> [27] </ref> fl , distribution [23, 5, 22, 18] higher order moments, PGF, limit distribution fl Descendants Probability, Probability, PGF, average, Probability, moments [21] fl moments [21] fl variance fl moments fl Table 1. Summary of previous works and the results of this paper. <p> We are also able to compute the PGF of A n , the number of ascendants of a random node (Theorem 7.2), as well as all its moments (Theorems 7.4 and 7.5), thus extending the results of Poblete and Munro <ref> [27] </ref>. The results of previous works and the new results in this paper are summarized in Table 1. Entries corresponding to new results in this paper and to alternative derivations of previous results are marked by ` fl '. 2. <p> Such schemes guarantee logarithmic performance of searches and updates in the worst-case, but they have additional space requirements and are more difficult to implement than standard BSTs. As an alternative, several authors <ref> [4, 34, 27] </ref> have suggested the use of a simple heuristic that makes the construction of poorly balanced trees much less likely than with the use of the standard algorithms. Furthermore, the heuristic was shown to yield significant savings in the expected search time. <p> We will call the binary search trees constructed in this way locally balanced binary search trees (LBST, for short). Poblete and Munro <ref> [27] </ref> and Poblete [26] carry on the analysis of this heuristic and some generalizations by means of bottom-up or fringe techniques: they basically study the number of nodes that are at level k and which are the root of a subtree of size 1 or 2. <p> Solving this differential equation and extracting the coefficients leads to the second factorial moments, which are given in the appendix. In <ref> [27] </ref> the authors considered the expectation and variance of A n in random LBSTs. To be more precise, they stated the problem in terms of unsuccessful search costs. Here, we are able to reproduce their results and extend them to higher order moments.
Reference: [28] <author> S. Roura and C. Martnez. </author> <title> Randomization of search trees by subtree size. </title> <editor> In J. Daz and M. Serna, editors, </editor> <booktitle> Proc. of the 4th European Symposium on Algorithms (ESA), volume 1136 of LNCS, </booktitle> <pages> pages 91-106. </pages> <publisher> Springer, </publisher> <year> 1996. </year>
Reference-contexts: 1. Introduction Binary search trees are among the most important and commonly used data structures, their applications spanning a wide range of the areas of Computer Science. Standard binary search trees (BSTs, for short) are still the subject of active research, see for instance the recent articles <ref> [2, 28] </ref>.
Reference: [29] <author> B. Salvy and P. Zimmermann. </author> <title> Gfun: a Maple package for the manipulation of generating and holonomic functions in one variable. </title> <journal> ACM Transactions on Mathematical Software, </journal> <volume> 20(2) </volume> <pages> 163-177, </pages> <year> 1994. </year>
Reference-contexts: The last step, that of extracting coefficients in exact form, was, at large, the least systematic and mechanical one. A great deal of combinatorial identities, inspired guessing and patience was needed. Standard Maple tools like the function interp or the Gfun package <ref> [29] </ref> proved also to be useful. However, once the solution is obtained, it is just a matter of minutes to check its correctness. It is quite difficult to provide a detailed and ordered description of the methods that we used to extract coefficients from generating functions.
Reference: [30] <author> R. Sedgewick. </author> <title> Quicksort. </title> <publisher> Garland, </publisher> <address> New York, </address> <year> 1978. </year>
Reference-contexts: Deepening our knowledge about binary search trees is interesting in its own; moreover, most of this knowledge can be translated and applied to other data structures such as heap ordered trees, k-d-trees [33], and to important algorithms like quicksort and Hoare's Find algorithm for selection (also known as quickselect) <ref> [12, 13, 30, 31] </ref>. We assume that the reader is already familiar with binary search trees and the basic algorithms to manipulate them [20, 31, 9]. <p> A similar idea, namely, selecting a sample of 3 elements and taking the median of the sample as the pivot element for partitioning in algorithms like quicksort and quickselect has been shown to yield significant improvements in theory and practice <ref> [30, 17] </ref>. Random search trees, either random BSTs or random LBSTs, are search trees built by performing n random insertions into an initially empty tree [20, 24].
Reference: [31] <author> R. Sedgewick. </author> <title> Algorithms in C. </title> <publisher> Addison-Wesley, 3rd edition, </publisher> <year> 1997. </year>
Reference-contexts: Deepening our knowledge about binary search trees is interesting in its own; moreover, most of this knowledge can be translated and applied to other data structures such as heap ordered trees, k-d-trees [33], and to important algorithms like quicksort and Hoare's Find algorithm for selection (also known as quickselect) <ref> [12, 13, 30, 31] </ref>. We assume that the reader is already familiar with binary search trees and the basic algorithms to manipulate them [20, 31, 9]. <p> We assume that the reader is already familiar with binary search trees and the basic algorithms to manipulate them <ref> [20, 31, 9] </ref>. Height and weight-balanced versions of the binary search trees, like AVL and red-black trees [1, 11], have been proposed and find many useful applications, since all of them guarantee good worst-case performance of both searches and updates.
Reference: [32] <author> R. Sedgewick and Ph. Flajolet. </author> <title> An Introduction to the Analysis of Algorithms. </title> <publisher> Addison-Wesley, </publisher> <year> 1996. </year>
Reference-contexts: Excellent sources of information about generating functions and their applications to combinatorics and the analysis of algorithms are <ref> [35, 33, 32, 20] </ref>. We make extensive use in this paper of probability generating functions (PGFs) as well as multivariate generating functions whose coefficients are PGFs themselves. We define them in turn.
Reference: [33] <author> J.S. Vitter and Ph. Flajolet. </author> <title> Average-case analysis of algorithms and data structures. </title> <editor> In J. van Leeuwen, editor, </editor> <booktitle> Handbook of Theoretical Computer Science, chapter 9. </booktitle> <publisher> North-Holland, </publisher> <year> 1990. </year>
Reference-contexts: Deepening our knowledge about binary search trees is interesting in its own; moreover, most of this knowledge can be translated and applied to other data structures such as heap ordered trees, k-d-trees <ref> [33] </ref>, and to important algorithms like quicksort and Hoare's Find algorithm for selection (also known as quickselect) [12, 13, 30, 31]. We assume that the reader is already familiar with binary search trees and the basic algorithms to manipulate them [20, 31, 9]. <p> Excellent sources of information about generating functions and their applications to combinatorics and the analysis of algorithms are <ref> [35, 33, 32, 20] </ref>. We make extensive use in this paper of probability generating functions (PGFs) as well as multivariate generating functions whose coefficients are PGFs themselves. We define them in turn. <p> them in this paper, the reader should be aware of the existing powerful techniques to extract asymptotic information about the coefficients of a generating function if we know its behaviour near its singularities or in some case, even if we only know the functional equation satisfied by the generating function <ref> [33, 6] </ref>.
Reference: [34] <author> A. Walker and D. Wood. </author> <title> Locally balanced binary trees. </title> <journal> Comput. J., </journal> <volume> 19(4) </volume> <pages> 322-325, </pages> <year> 1976. </year>
Reference-contexts: Locally balanced search trees (LBSTs) were introduced by Bell [4] and Walker and Wood <ref> [34] </ref>, and thoroughly analyzed by Poblete and Munro in [27]. LBSTs have been proposed as an alternative to more complex balancing schemes for search trees. <p> Such schemes guarantee logarithmic performance of searches and updates in the worst-case, but they have additional space requirements and are more difficult to implement than standard BSTs. As an alternative, several authors <ref> [4, 34, 27] </ref> have suggested the use of a simple heuristic that makes the construction of poorly balanced trees much less likely than with the use of the standard algorithms. Furthermore, the heuristic was shown to yield significant savings in the expected search time.
Reference: [35] <editor> H. Wilf. Generatingfunctionology. </editor> <publisher> Academic Press, </publisher> <year> 1990. </year>
Reference-contexts: Excellent sources of information about generating functions and their applications to combinatorics and the analysis of algorithms are <ref> [35, 33, 32, 20] </ref>. We make extensive use in this paper of probability generating functions (PGFs) as well as multivariate generating functions whose coefficients are PGFs themselves. We define them in turn.
References-found: 35

