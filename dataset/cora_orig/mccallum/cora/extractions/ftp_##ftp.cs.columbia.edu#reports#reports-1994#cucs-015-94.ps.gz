URL: ftp://ftp.cs.columbia.edu/reports/reports-1994/cucs-015-94.ps.gz
Refering-URL: http://www.cs.columbia.edu/~library/1994.html
Root-URL: http://www.cs.columbia.edu
Email: pascale@cs.columbia.edu dekai@cs.ust.hk  
Title: Statistical Augmentation of a Chinese Machine-Readable Dictionary  
Author: Pascale Fung Dekai Wu 
Address: New York, NY 10027  USA Clear Water Bay, Hong Kong  
Affiliation: Columbia University HKUST Computer Science Department Department of Computer Science  University of Science Technology  
Abstract: We describe a method of using statistically-collected Chinese character groups from a corpus to augment a Chinese dictionary. The method is particularly useful for extracting domain-specific and regional words not readily available in machine-readable dictionaries. Output was evaluated both using human evaluators and against a previously available dictionary. We also evaluated performance improvement in automatic Chinese tokenization. Results show that our method outputs legitimate words, acronymic constructions, idioms, names and titles, as well as technical compounds, many of which were lacking from the original dictionary. 
Abstract-found: 1
Intro-found: 1
Reference: <author> BDC. </author> <year> 1992. </year> <title> The BDC Chinese-English electronic dictionary (version 2.0). Behavior Design Corporation. </title>
Reference-contexts: This gives the recall and precision of our output with respect to the training corpus. Unfortunately, the training corpus is untokenized and too large to tokenize by hand. We therefore estimated the words in the training corpus by passing it through an automatic tokenizer based on the BDC dictionary <ref> (BDC 1992) </ref>. <p> We would also like to thank our evaluators, Philip Chan, Eva Fong, Duanyang Guo, Zhe Li, Cindy Ng, Derek Ngok, Xuanyin Xia, and Michelle Zhou. The machine-readable dictionary <ref> (BDC 1992) </ref> was provided by Behavior Design Corporation.
Reference: <author> Chang, Chao-Huang & Cheng-Der Chen. </author> <year> 1993. </year> <title> HMM-based part-of-speech tagging for Chinese corpora. </title> <booktitle> In Proceedings of the Workshop on Very Large Corpora, </booktitle> <pages> 40-47, </pages> <address> Columbus, Ohio. </address>
Reference: <author> Chen, Yong-zhen & Spring Chen. </author> <year> 1983. </year> <title> Chinese idioms and their English equivalents. </title>
Reference-contexts: In Chinese especially, there are many four character words which form a special idiomatic class known as y (cheng yu). There are dictionaries of cheng yu with all or nearly all entries being four character idioms <ref> (e.g., Chen & Chen 1983) </ref>. In the training corpus we used, we discovered new cheng yu that were invented to describe a new concept.
Reference: <author> Hong Kong: </author> <type> Shang Wu Yin Shu Ju. </type>
Reference: <author> Chiang, Tung-Hui, Jing-Shin Chang, Ming-Yu Lin, & Keh-Yih Su. </author> <year> 1992. </year> <title> Statistical models for word segmentation and unknown resolution. </title> <booktitle> In Proceedings of ROCLING-92, </booktitle> <pages> 121-146. </pages> <address> FDMC. </address> <year> 1986. </year> <title> Xiandai hanyu pinlu cidian (Frequency dictionary of modern Chinese). </title> <publisher> Beijing Language Institute Press. </publisher>
Reference: <author> Lin, Ming-Yu, Tung-Hui Chiang, & Keh-Yih Su. </author> <year> 1993. </year> <title> A preliminary study on unknown word problem in Chinese word segmentation. </title> <booktitle> In Proceedings of ROCLING-93, </booktitle> <pages> 119-141. </pages>
Reference: <author> Lin, Yi-Chung, Tung-Hui Chiang, & Keh-Yih Su. </author> <year> 1992. </year> <title> Discrimination oriented probabilistic tagging. </title> <booktitle> In Proceedings of ROCLING-92, </booktitle> <pages> 85-96. </pages>
Reference: <author> Liu, Y. </author> <year> 1987. </year> <title> New advances in computers and natural language processing in China. </title> <journal> Information Science, </journal> <volume> 8 </volume> <pages> 64-70. </pages> <note> In Chinese. </note>
Reference-contexts: Function words are often unigrams, and n-grams with n &gt; 4 usually are specific idioms. According to the Frequency Dictionary of Modern Chinese (FDMC 1986), among the top 9000 most frequent words, 26.7% are unigrams, 69.8% are bigrams, 2.7% are trigrams, 0.007% 4-grams, and 0.0002% 5-grams. Another study <ref> (Liu 1987) </ref> showed that in general, 75% of Chinese words are bigrams, 14% trigrams, 6% n-grams with n &gt; 3. Inadequate dictionaries have become the major bottleneck to Chinese natural language processing.
Reference: <author> Smadja, Frank. </author> <year> 1993. </year> <title> Retrieving collocations from text: </title> <journal> Xtract. Computational Linguistics, </journal> <volume> 19(1) </volume> <pages> 143-177. </pages>
Reference-contexts: ) which can mean "stand" or "establish" by itself. 2: From the unigram list, we found all the bigrams associated with each unigram and obtained a list of all bigrams found. 3: We kept only bigrams which occur significantly more than chance expectation, and which appear in a rigid way <ref> (Smadja 1993) </ref>. This yields a list of possible bigrams and most frequent relative distance between the two characters.
Reference: <author> Sproat, Richard, Chilin Shih, William Gale, & N. Chang. </author> <year> 1994. </year> <title> A stochastic word segmentation algorithm for a Mandarin text-to-speech system. </title> <booktitle> In Proceedings of the 32nd Annual Conference of the Association for Computational Linguistics, </booktitle> <address> Las Cruces, New Mexico. </address> <note> To appear. </note>
Reference-contexts: Such invented terms are highly domain dependent, as are the usage frequencies of established cheng yu. 3.9 Names Tokenizing Chinese names is a difficult task <ref> (Sproat et al. 1994) </ref> because Chinese names start with a unigram or bigram family name, and are followed by a given name freely composed of one or two characters.
Reference: <author> Wu, Dekai. </author> <year> 1994. </year> <title> Aligning a parallel English-Chinese corpus statistically with lexical criteria. </title> <booktitle> In Proceedings of the 32nd Annual Conference of the Association for Computational Linguistics, </booktitle> <address> Las Cruces, New Mexico. </address> <note> To appear. </note>
Reference-contexts: We are using text from (the Chinese part of) the HKUST English-Chinese Parallel Bilingual Corpus <ref> (Wu 1994) </ref>, specifically, transcriptions of the parliamentary proceedings of the Legislative Council. The transcribed Chinese is formalized literary Cantonese that is closer to Mandarin than conversational Cantonese. However, more vocabulary is preserved from classical literary Chinese than in Mandarin, which affects the ratio of bigrams to other words.
Reference: <author> Wu, Dekai & Pascale Fung, </author> <year> 1994. </year> <title> Improving Chinese tokenization with linguistic filters on statistical lexical acquisition. </title> <note> Submitted. </note>
Reference-contexts: We are using text from (the Chinese part of) the HKUST English-Chinese Parallel Bilingual Corpus <ref> (Wu 1994) </ref>, specifically, transcriptions of the parliamentary proceedings of the Legislative Council. The transcribed Chinese is formalized literary Cantonese that is closer to Mandarin than conversational Cantonese. However, more vocabulary is preserved from classical literary Chinese than in Mandarin, which affects the ratio of bigrams to other words.
Reference: <author> Wu, Zimin & Gwyneth Tseng. </author> <year> 1993. </year> <title> Chinese text segmentation for text retrieval: Achievements and problems. </title> <journal> Journal of The American Society for Information Science, </journal> <volume> 44(9) </volume> <pages> 532-542. </pages>
References-found: 13

