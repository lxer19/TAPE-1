URL: http://www.cs.wisc.edu/~solodov/mvs98cpvd.ps.Z
Refering-URL: http://www.cs.wisc.edu/~solodov/solodov.html
Root-URL: http://www.cs.wisc.edu
Title: ON THE CONVERGENCE OF CONSTRAINED PARALLEL VARIABLE DISTRIBUTION ALGORITHMS  
Author: MICHAEL V. SOLODOV 
Keyword: Key words. parallel optimization, nonlinear programming, linear convergence  
Date: 187-196, February 1998 009  
Note: SIAM J. OPTIM. c 1998 Society for Industrial and Applied Mathematics Vol. 8, No. 1, pp.  AMS subject classifications. 90C30, 49D27 PII. S1052623495293949  
Abstract: We consider the parallel variable distribution (PVD) approach proposed by Ferris and Mangasarian [SIAM J. Optim., 4 (1994), pp. 815-832] for solving optimization problems. The problem variables are distributed among p processors with each processor having the primary responsibility for updating its block of variables while allowing the remaining "secondary" variables to change in a restricted fashion along some easily computable directions. For constrained nonlinear programs, convergence in [M. C. Ferris and O. L. Mangasarian, SIAM J. Optim., 4 (1994), pp. 815-832] was established in the special case of convex block-separable constraints. For general (inseparable) constraints, it was suggested that a dual differentiable exact penalty function reformulation of the problem be used. We propose to apply the PVD approach to problems with general convex constraints directly and show that the algorithm converges, provided certain conditions are imposed on the change of secondary variables. These conditions are both natural and practically implementable. We also show that the original requirement of exact global solution of the parallel subproblems can be replaced by a less stringent sufficient descent condition. The first rate of convergence result for the class of constrained PVD algorithms is also given. 1. Introduction. We consider the general nonlinear programming problem 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D. P. Bertsekas, </author> <title> Constrained Optimization and Lagrange Multiplier Methods, </title> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1982. </year>
Reference-contexts: This can be done in several ways, but, unfortunately, each has some disadvantages. The exterior penalty approach [5] requires the unboundedness of the penalty parameter, while the augmented Lagrangian methods <ref> [24, 1] </ref> change the minimization problem into a saddle-point problem which is, in general, more difficult. In [4] it was suggested to use a certain dual differentiable exact penalty function formulation [8] for which the penalty parameter remains finite. This is a reasonable approach, but it also has some drawbacks.
Reference: [2] <author> D. P. Bertsekas and J. N. Tsitsiklis, </author> <title> Parallel and Distributed Computation, </title> <publisher> Prentice-Hall, Inc., </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1989. </year>
Reference-contexts: The distinctive novel feature of this algorithm is the presence of the "forget-me-not" term x i l + D i l l in the parallel subproblems (1.2) which allows for a change in "secondary" variables. This makes PVD fundamentally different from the block Jacobi <ref> [2] </ref>, coordinate descent [26], and parallel gradient distribution algorithms [16]. The forget-me-not approach improves robustness and accelerates convergence of the algorithm and is the key to its success. <p> In fact, the presence of forget-me-not terms is what separates PVD from other related parallel techniques <ref> [2] </ref>. It is therefore natural to choose the directions in a special way and study their effect on the properties of the algorithm. In [25], by imposing natural restrictions on these directions, we were able to strengthen convergence results for unconstrained PVD.
Reference: [3] <author> R. W. Cottle, F. Giannessi, and J.-L. Lions, </author> <title> Variational Inequalities and Complementarity Problems: Theory and Applications, </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1980. </year>
Reference-contexts: Condition (2.5) states that f () does not grow faster than quadratically near its set of minimizers. In conclusion, we note that the implicit Lagrangian reformulation [18] of the nonlinear complementarity problem (NCP) satisfies (2.4)-(2.5) under certain assump tions. Consider the following NCP <ref> [3, 21] </ref> of finding an x 2 &lt; n such that F (x) 0; x 0; hx; F (x)i = 0; where F : &lt; n ! &lt; n .
Reference: [4] <author> M. C. Ferris and O. L. Mangasarian, </author> <title> Parallel variable distribution, </title> <journal> SIAM J. Optim., </journal> <volume> 4 (1994), </volume> <pages> pp. 815-832. </pages>
Reference-contexts: 1. Introduction. We consider the general nonlinear programming problem min f (x);(1.1) where C is a nonempty closed convex set in &lt; n and f : &lt; n ! &lt; is a continuously differentiable function. We first describe the PVD algorithm proposed in <ref> [4] </ref> and, in the unconstrained case, further studied and extended in [25, 7]. <p> In principle, any point with the objective function value at least as good as the smallest computed by all the processors is acceptable. We refer the reader to <ref> [4] </ref> for a study of computational efficiency of the PVD approach and other practical issues. In [4] it was shown that in the special case when the feasible set C has block separable structure (i.e., C is a Cartesian product of closed convex sets), every accumulation point of the PVD iterates <p> In principle, any point with the objective function value at least as good as the smallest computed by all the processors is acceptable. We refer the reader to <ref> [4] </ref> for a study of computational efficiency of the PVD approach and other practical issues. In [4] it was shown that in the special case when the feasible set C has block separable structure (i.e., C is a Cartesian product of closed convex sets), every accumulation point of the PVD iterates satisfies the minimum principle necessary opti mality condition [15]. <p> It was therefore argued that having a stationary point that results from minimizing the objective function with respect to individual blocks of variables and subject to the problem constraints does not result in a useful point unless the constraints are separable <ref> [4] </ref>. <p> Moreover, we prove convergence for the case of Holder continuous gradient of the objective function (Lipschitz continuity was assumed in <ref> [4] </ref> and [25]). We are further able to give the first rate of convergence result for the constrained PVD methods (Theorem 2.2). <p> Fortunately, those conditions are natural and easily implementable in practice. The importance of change in the secondary variables was mentioned and experimentally established in <ref> [4] </ref>. However, convergence analysis in [4] fails to take advantage of forget-me-not terms. This inevitably weakens the properties of PVD algorithms, especially in the constrained case. <p> Fortunately, those conditions are natural and easily implementable in practice. The importance of change in the secondary variables was mentioned and experimentally established in <ref> [4] </ref>. However, convergence analysis in [4] fails to take advantage of forget-me-not terms. This inevitably weakens the properties of PVD algorithms, especially in the constrained case. In fact, it was suggested that the only sensible way to distribute variables for problems with inseparable constraints is to convert them to unconstrained problems. <p> This can be done in several ways, but, unfortunately, each has some disadvantages. The exterior penalty approach [5] requires the unboundedness of the penalty parameter, while the augmented Lagrangian methods [24, 1] change the minimization problem into a saddle-point problem which is, in general, more difficult. In <ref> [4] </ref> it was suggested to use a certain dual differentiable exact penalty function formulation [8] for which the penalty parameter remains finite. This is a reasonable approach, but it also has some drawbacks. <p> This CONSTRAINED PARALLEL VARIABLE DISTRIBUTION 191 was also the case for the analysis of unconstrained PVD algorithms [25]. Another im provement consists of extending the analysis to functions in the class C 1;ff L (&lt; n ) where ff 2 (0; 1] (in <ref> [4, 25] </ref> the case of ff = 1 is considered). We are now ready to prove our main results. Theorem 2.1. Let f () 2 C 1;ff L (&lt; n ). <p> This provides a flexible framework for effective load balancing. Finally, we note that (2.3) can be easily satisfied in practice if we take (x i l ; 0) as starting points when minimizing i l (; ); l = 1; : : : ; p, in subproblems (1.2). In <ref> [4] </ref>, the following optimality function was used to monitor the progress of the algorithm in the case of block-separable constraints: '(x) := minfhrf (x); hi j x + h 2 C; khk 1g: Then convergence results similar to our Theorem 2.1 follow from the relation f (x i ) f (x
Reference: [5] <author> A. V. Fiacco and G. P. McCormick, </author> <title> Nonlinear Programming: Sequential Unconstrained Minimization Techniques, </title> <publisher> John Wiley & Sons, </publisher> <address> New York, </address> <year> 1968. </year>
Reference-contexts: In fact, it was suggested that the only sensible way to distribute variables for problems with inseparable constraints is to convert them to unconstrained problems. This can be done in several ways, but, unfortunately, each has some disadvantages. The exterior penalty approach <ref> [5] </ref> requires the unboundedness of the penalty parameter, while the augmented Lagrangian methods [24, 1] change the minimization problem into a saddle-point problem which is, in general, more difficult.
Reference: [6] <author> R. Fletcher, </author> <title> Practical Methods of Optimization, </title> <publisher> John Wiley & Sons, </publisher> <address> Chichester, UK, </address> <year> 1981. </year>
Reference-contexts: One of the referees for this paper made an interesting suggestion of computing the secondary directions by projecting onto the linearization of a nonlinear constraint set, much in the spirit of the iterative quadratic programming approach <ref> [6] </ref>. At this time, this is an open question as we do not have a proof verifying that this approach will work. However, it certainly deserves further investigation.
Reference: [7] <author> M. Fukushima, </author> <title> Parallel variable transformation in unconstrained optimization, </title> <note> SIAM J. Op-tim., 8 (1998), to appear. </note>
Reference-contexts: We first describe the PVD algorithm proposed in [4] and, in the unconstrained case, further studied and extended in <ref> [25, 7] </ref>. Let the problem variables x 2 &lt; n be partitioned into p blocks x 1 ; : : : ; x p such that x l 2 &lt; n l , P p These blocks of variables are then distributed among p parallel processors.
Reference: [8] <author> S.-P. Han and O. L. Mangasarian, </author> <title> A dual differentiable exact penalty function, </title> <journal> Math. Programming, </journal> <volume> 25 (1983), </volume> <pages> pp. 293-301. </pages>
Reference-contexts: The exterior penalty approach [5] requires the unboundedness of the penalty parameter, while the augmented Lagrangian methods [24, 1] change the minimization problem into a saddle-point problem which is, in general, more difficult. In [4] it was suggested to use a certain dual differentiable exact penalty function formulation <ref> [8] </ref> for which the penalty parameter remains finite. This is a reasonable approach, but it also has some drawbacks. In particular, by using this dual penalty function formulation we increase the dimensionality of the problem and may lose any special structure if it was present in the problem.
Reference: [9] <author> Y. Y. Lin and J.-S. Pang, </author> <title> Iterative methods for large convex quadratic programs: A survey, </title> <journal> SIAM J. Control Optim., </journal> <volume> 25 (1987), </volume> <pages> pp. 383-411. </pages>
Reference-contexts: When C is a polyhedral set (i.e., the constraints are linear), computing these directions requires solving a single quadratic programming problem at every synchronization step of Algorithm 1.1. For this, a wealth of fast and reliable algorithms is available <ref> [9] </ref>. In the case of nonlinear convex constraints, the task of computing the projected gradient directions is considerably more difficult.
Reference: [10] <author> X.-D. Luo and P. Tseng, </author> <title> On global projection-type error bound for the linear complementarity problem, </title> <note> Linear Algebra Appl., to appear. </note>
Reference-contexts: Moreover, in certain situations, this condition holds globally (with c 3 = 1) <ref> [10, 11, 17, 20] </ref>. Condition (2.5) states that f () does not grow faster than quadratically near its set of minimizers. In conclusion, we note that the implicit Lagrangian reformulation [18] of the nonlinear complementarity problem (NCP) satisfies (2.4)-(2.5) under certain assump tions.
Reference: [11] <author> Z.-Q. Luo, O. L. Mangasarian, J. Ren, and M. V. Solodov, </author> <title> New error bounds for the linear complementarity problem, </title> <journal> Math. Oper. Res., </journal> <volume> 19 (1994), </volume> <pages> pp. 880-892. </pages>
Reference-contexts: Moreover, in certain situations, this condition holds globally (with c 3 = 1) <ref> [10, 11, 17, 20] </ref>. Condition (2.5) states that f () does not grow faster than quadratically near its set of minimizers. In conclusion, we note that the implicit Lagrangian reformulation [18] of the nonlinear complementarity problem (NCP) satisfies (2.4)-(2.5) under certain assump tions. <p> First note that rM (; ff) is Lipschitz continuous on any bounded set if F () and rF () are Lipschitz continuous and it is Lipschitz continuous everywhere if F () is affine. In <ref> [11] </ref> it was established that for all x 2 &lt; n (and any F ()) 2 (ff 1)kx [x F (x)] + k 2 M (x; ff) 2ff (ff 1)kx [x F (x)] + k 2 :(2.6) Let S := fx 2 &lt; n j x [x F (x)] + =
Reference: [12] <author> Z.-Q. Luo and P. Tseng, </author> <title> Error bound and convergence analysis of matrix splitting algorithms for the affine variational inequality problem, </title> <journal> SIAM J. Optim., </journal> <volume> 2 (1992), </volume> <pages> pp. 43-54. </pages>
Reference-contexts: Condition (2.4) is sometimes referred to as a projection-type error bound [13, 14]. This error bound is known to hold when f () is quadratic and C is polyhedral <ref> [12, 23] </ref> or when f () is strongly convex [20] or when f () is a certain convex (not necessarily strictly convex) function and C is polyhedral [13] (see [14, Theorem 2.1] for a summary). <p> It is further known that, when F () is affine <ref> [12, 23] </ref> or F () has certain strong monotonicity structure [27, Theorem 2], then the following error bound holds: d (x; S) kx [x F (x)] + k 8x with kx [x F (x)] + k *; where and * are positive constants (independent of x).
Reference: [13] <author> Z.-Q. Luo and P. Tseng, </author> <title> On the linear convergence of descent methods for convex essentially smooth minimization, </title> <journal> SIAM J. Control Optim., </journal> <volume> 30 (1992), </volume> <pages> pp. 408-425. </pages>
Reference-contexts: The use of a different optimality function '(x) := kr (x)k 2 allows us furthermore to give a rate of convergence result under the conditions similar to those in <ref> [13] </ref>. Theorem 2.2. Let f () 2 C 1;1 L (&lt; n ) and fx i g be any sequence generated by Algorithm 1.1. Let accumulation points of the sequence fx i g exist and belong to the set S := arg min x2C f (x) 6= ;. <p> The difficulty with the parallel algorithm is that we cannot explicitly relate fr (x i )g to fx i+1 x i g. Condition (2.4) is sometimes referred to as a projection-type error bound <ref> [13, 14] </ref>. <p> This error bound is known to hold when f () is quadratic and C is polyhedral [12, 23] or when f () is strongly convex [20] or when f () is a certain convex (not necessarily strictly convex) function and C is polyhedral <ref> [13] </ref> (see [14, Theorem 2.1] for a summary). Moreover, in certain situations, this condition holds globally (with c 3 = 1) [10, 11, 17, 20]. Condition (2.5) states that f () does not grow faster than quadratically near its set of minimizers.
Reference: [14] <author> Z.-Q. Luo and P. Tseng, </author> <title> Error bounds and convergence analysis of feasible descent methods: A general approach, </title> <journal> Ann. Oper. Res., </journal> <volume> 46 (1993), </volume> <pages> pp. 157-178. </pages>
Reference-contexts: The difficulty with the parallel algorithm is that we cannot explicitly relate fr (x i )g to fx i+1 x i g. Condition (2.4) is sometimes referred to as a projection-type error bound <ref> [13, 14] </ref>. <p> This error bound is known to hold when f () is quadratic and C is polyhedral [12, 23] or when f () is strongly convex [20] or when f () is a certain convex (not necessarily strictly convex) function and C is polyhedral [13] (see <ref> [14, Theorem 2.1] </ref> for a summary). Moreover, in certain situations, this condition holds globally (with c 3 = 1) [10, 11, 17, 20]. Condition (2.5) states that f () does not grow faster than quadratically near its set of minimizers.
Reference: [15] <author> O. L. Mangasarian, </author> <title> Nonlinear Programming, </title> <publisher> McGraw-Hill, </publisher> <address> New York, </address> <year> 1969. </year>
Reference-contexts: In [4] it was shown that in the special case when the feasible set C has block separable structure (i.e., C is a Cartesian product of closed convex sets), every accumulation point of the PVD iterates satisfies the minimum principle necessary opti mality condition <ref> [15] </ref>. It was further stated that in the case of inseparable constraints, the PVD approach may fail. <p> It is well known that some x 2 &lt; n satisfies the minimum principle necessary optimality condition <ref> [15] </ref> for problem (1.1) x 2 C; hrf (x); y xi 0 8 y 2 C if and only if r (x) = 0. We shall call such x a stationary point of (1.1).
Reference: [16] <author> O. L. Mangasarian, </author> <title> Parallel gradient distribution in unconstrained optimization, </title> <journal> SIAM J. Control Optim., </journal> <volume> 33 (1995), </volume> <pages> pp. 1916-1925. </pages>
Reference-contexts: This makes PVD fundamentally different from the block Jacobi [2], coordinate descent [26], and parallel gradient distribution algorithms <ref> [16] </ref>. The forget-me-not approach improves robustness and accelerates convergence of the algorithm and is the key to its success.
Reference: [17] <author> O. L. Mangasarian and J. Ren, </author> <title> New improved error bounds for the linear complementarity problem, </title> <journal> Math. Programming, </journal> <volume> 66 (1994), </volume> <pages> pp. 241-255. </pages>
Reference-contexts: Moreover, in certain situations, this condition holds globally (with c 3 = 1) <ref> [10, 11, 17, 20] </ref>. Condition (2.5) states that f () does not grow faster than quadratically near its set of minimizers. In conclusion, we note that the implicit Lagrangian reformulation [18] of the nonlinear complementarity problem (NCP) satisfies (2.4)-(2.5) under certain assump tions.
Reference: [18] <author> O. L. Mangasarian and M. V. Solodov, </author> <title> Nonlinear complementarity as unconstrained and constrained minimization, </title> <journal> Math. Programming, </journal> <volume> 62 (1993), </volume> <pages> pp. 277-297. </pages>
Reference-contexts: Moreover, in certain situations, this condition holds globally (with c 3 = 1) [10, 11, 17, 20]. Condition (2.5) states that f () does not grow faster than quadratically near its set of minimizers. In conclusion, we note that the implicit Lagrangian reformulation <ref> [18] </ref> of the nonlinear complementarity problem (NCP) satisfies (2.4)-(2.5) under certain assump tions. Consider the following NCP [3, 21] of finding an x 2 &lt; n such that F (x) 0; x 0; hx; F (x)i = 0; where F : &lt; n ! &lt; n . In [18] it was <p> Lagrangian reformulation <ref> [18] </ref> of the nonlinear complementarity problem (NCP) satisfies (2.4)-(2.5) under certain assump tions. Consider the following NCP [3, 21] of finding an x 2 &lt; n such that F (x) 0; x 0; hx; F (x)i = 0; where F : &lt; n ! &lt; n . In [18] it was established that the NCP can be solved via minimization of the following implicit Lagrangian function: M (x; ff) := 2ffhx; F (x)i + k [x ffF (x)] + k 2 kxk 2 + k [F (x) ffx] + k 2 kF (x)k 2 ; where ff &gt; 1
Reference: [19] <author> J. M. Ortega and W. C. Rheinboldt, </author> <title> Iterative Solution of Nonlinear Equations in Several Variables, </title> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1970. </year>
Reference-contexts: By R-linear convergence and Q-linear convergence, we mean linear convergence in the root sense and in the quotient sense, respectively, as defined in <ref> [19] </ref>. 2. Convergence of constrained PVD algorithms. In this section we show that, in the general convex-constrained case, for the PVD approach to be effective it is crucial to impose certain conditions on the change of secondary variables. Fortunately, those conditions are natural and easily implementable in practice.
Reference: [20] <author> J.-S. Pang, </author> <title> A posteriori error bounds for the linearly-constrained variational inequality problem, </title> <journal> Math. Oper. Res., </journal> <volume> 12 (1987), </volume> <pages> pp. 474-484. </pages>
Reference-contexts: Condition (2.4) is sometimes referred to as a projection-type error bound [13, 14]. This error bound is known to hold when f () is quadratic and C is polyhedral [12, 23] or when f () is strongly convex <ref> [20] </ref> or when f () is a certain convex (not necessarily strictly convex) function and C is polyhedral [13] (see [14, Theorem 2.1] for a summary). Moreover, in certain situations, this condition holds globally (with c 3 = 1) [10, 11, 17, 20]. <p> Moreover, in certain situations, this condition holds globally (with c 3 = 1) <ref> [10, 11, 17, 20] </ref>. Condition (2.5) states that f () does not grow faster than quadratically near its set of minimizers. In conclusion, we note that the implicit Lagrangian reformulation [18] of the nonlinear complementarity problem (NCP) satisfies (2.4)-(2.5) under certain assump tions.
Reference: [21] <author> J.-S. Pang, </author> <title> Complementarity problems, in Handbook of Global Optimization, </title> <editor> R. Horst and P. Pardalos, eds., </editor> <publisher> Kluwer Academic Publishers, Norwell, </publisher> <address> MA, </address> <year> 1995, </year> <pages> pp. 271-338. </pages>
Reference-contexts: Condition (2.5) states that f () does not grow faster than quadratically near its set of minimizers. In conclusion, we note that the implicit Lagrangian reformulation [18] of the nonlinear complementarity problem (NCP) satisfies (2.4)-(2.5) under certain assump tions. Consider the following NCP <ref> [3, 21] </ref> of finding an x 2 &lt; n such that F (x) 0; x 0; hx; F (x)i = 0; where F : &lt; n ! &lt; n .
Reference: [22] <author> B. T. Polyak, </author> <title> Introduction to Optimization, Optimization Software, </title> <publisher> Inc., Publications Division, </publisher> <address> New York, </address> <year> 1987. </year>
Reference-contexts: Hence f (x i ) f (y i l + D i l ) i hrf (x i ); r (x i )i i kr (x i )k 1+ff :(2.1) 192 MICHAEL V. SOLODOV By properties of the projection operator <ref> [22, p. 121] </ref>, for any x 2 &lt; n and any y 2 C it holds that hx P C [x]; y P C [x]i 0: Taking x = x i rf (x i ) and y = x i 2 C, we have 0 hx i rf (x i ) <p> In that case, from (2.6), M (x; ff) min M (x; ff) = M (x; ff) -d (x; S) 2 ; - := 2 (ff 1)= 2 &gt; 0:(2.7) By a well-known lemma <ref> [22, p. 6] </ref>, we have that M (x; ff) M (P S [x]; ff) hrM (x; ff); x P S [x]i + 2 Hence, from (2.7), hrM (x; ff); x P S [x]i M (x; ff) 2 (- L=2)M (x; ff): Therefore, if - &gt; L=2, krM (x; ff)kd (x; S)
Reference: [23] <author> S. M. Robinson, </author> <title> Some continuity properties of polyhedral multifunctions, Math. Programming Study, </title> <booktitle> 14 (1981), </booktitle> <pages> pp. 206-214. </pages>
Reference-contexts: Condition (2.4) is sometimes referred to as a projection-type error bound [13, 14]. This error bound is known to hold when f () is quadratic and C is polyhedral <ref> [12, 23] </ref> or when f () is strongly convex [20] or when f () is a certain convex (not necessarily strictly convex) function and C is polyhedral [13] (see [14, Theorem 2.1] for a summary). <p> It is further known that, when F () is affine <ref> [12, 23] </ref> or F () has certain strong monotonicity structure [27, Theorem 2], then the following error bound holds: d (x; S) kx [x F (x)] + k 8x with kx [x F (x)] + k *; where and * are positive constants (independent of x).
Reference: [24] <author> R. T. Rockafellar, </author> <title> Augmented Lagrange multiplier functions and duality in nonconvex programming, </title> <journal> SIAM J. Control, </journal> <volume> 12 (1974), </volume> <pages> pp. 268-285. </pages>
Reference-contexts: This can be done in several ways, but, unfortunately, each has some disadvantages. The exterior penalty approach [5] requires the unboundedness of the penalty parameter, while the augmented Lagrangian methods <ref> [24, 1] </ref> change the minimization problem into a saddle-point problem which is, in general, more difficult. In [4] it was suggested to use a certain dual differentiable exact penalty function formulation [8] for which the penalty parameter remains finite. This is a reasonable approach, but it also has some drawbacks.
Reference: [25] <author> M. V. Solodov, </author> <title> New inexact parallel variable distribution algorithms, </title> <journal> Comput. Optim. Appl., </journal> <volume> 7 (1997), </volume> <pages> pp. 165-182. </pages>
Reference-contexts: We first describe the PVD algorithm proposed in [4] and, in the unconstrained case, further studied and extended in <ref> [25, 7] </ref>. Let the problem variables x 2 &lt; n be partitioned into p blocks x 1 ; : : : ; x p such that x l 2 &lt; n l , P p These blocks of variables are then distributed among p parallel processors. <p> In fact, the presence of forget-me-not terms is what separates PVD from other related parallel techniques [2]. It is therefore natural to choose the directions in a special way and study their effect on the properties of the algorithm. In <ref> [25] </ref>, by imposing natural restrictions on these directions, we were able to strengthen convergence results for unconstrained PVD. A reasonable choice of directions also allowed us to propose useful generalizations, such as algorithms with inexact subproblem solution and a certain degree of asynchronization [25]. <p> In <ref> [25] </ref>, by imposing natural restrictions on these directions, we were able to strengthen convergence results for unconstrained PVD. A reasonable choice of directions also allowed us to propose useful generalizations, such as algorithms with inexact subproblem solution and a certain degree of asynchronization [25]. We now define the following projected gradient residual function r (x) := x P C [x rf (x)];(1.4) where P C [] stands for the orthogonal projection map onto the closed convex set C; i.e., P C [y] := arg min x2C kx yk. <p> Moreover, we prove convergence for the case of Holder continuous gradient of the objective function (Lipschitz continuity was assumed in [4] and <ref> [25] </ref>). We are further able to give the first rate of convergence result for the constrained PVD methods (Theorem 2.2). Finally, in section 2 we also show that the exact global solution requirement for parallel subproblems (1.2) can be replaced by a less stringent condition of sufficient descent (see (2.3)). <p> Furthermore, considering specific directions and making explicit use of their properties in our analysis, we are able to obtain stronger convergence results, including rate of convergence results. This CONSTRAINED PARALLEL VARIABLE DISTRIBUTION 191 was also the case for the analysis of unconstrained PVD algorithms <ref> [25] </ref>. Another im provement consists of extending the analysis to functions in the class C 1;ff L (&lt; n ) where ff 2 (0; 1] (in [4, 25] the case of ff = 1 is considered). We are now ready to prove our main results. Theorem 2.1. <p> This CONSTRAINED PARALLEL VARIABLE DISTRIBUTION 191 was also the case for the analysis of unconstrained PVD algorithms [25]. Another im provement consists of extending the analysis to functions in the class C 1;ff L (&lt; n ) where ff 2 (0; 1] (in <ref> [4, 25] </ref> the case of ff = 1 is considered). We are now ready to prove our main results. Theorem 2.1. Let f () 2 C 1;ff L (&lt; n ).
Reference: [26] <author> P. Tseng, </author> <title> Dual coordinate ascent methods for non-strictly convex minimization, </title> <journal> Math. Programming, </journal> <volume> 59 (1993), </volume> <pages> pp. 231-248. </pages>
Reference-contexts: The distinctive novel feature of this algorithm is the presence of the "forget-me-not" term x i l + D i l l in the parallel subproblems (1.2) which allows for a change in "secondary" variables. This makes PVD fundamentally different from the block Jacobi [2], coordinate descent <ref> [26] </ref>, and parallel gradient distribution algorithms [16]. The forget-me-not approach improves robustness and accelerates convergence of the algorithm and is the key to its success.
Reference: [27] <author> P. Tseng, </author> <title> On linear convergence of iterative methods for the variational inequality problem, </title> <journal> J. Comput. Appl. Math., </journal> <volume> 60 (1995), </volume> <pages> pp. 237-252. </pages>
Reference-contexts: It is further known that, when F () is affine [12, 23] or F () has certain strong monotonicity structure <ref> [27, Theorem 2] </ref>, then the following error bound holds: d (x; S) kx [x F (x)] + k 8x with kx [x F (x)] + k *; where and * are positive constants (independent of x).
References-found: 27

