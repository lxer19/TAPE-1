URL: ftp://robotics.stanford.edu/pub/gjohn/papers/cvc45.ps
Refering-URL: http://www.robotics.stanford.edu/~gjohn/pubs.html
Root-URL: http://www.robotics.stanford.edu
Email: gjohn@cs.Stanford.EDU  
Title: Cross-Validated C4.5: Using Error Estimation for Automatic Parameter Selection  
Author: George H. John 
Date: Oct 5, 1994  
Address: Stanford, CA 94305  
Affiliation: Computer Science Department Stanford University  
Abstract: Machine learning algorithms for supervised learning are in wide use. An important issue in the use of these algorithms is how to set the parameters of the algorithm. While the default parameter values may be appropriate for a wide variety of tasks, they are not necessarily optimal for a given task. In this paper, we investigate the use of cross-validation to select parameters for the C4.5 decision tree learning algorithm. Experimental results on five datasets show that when cross-validation is applied to selecting an important parameter for C4.5, the accuracy of the induced trees on independent test sets is generally higher than the accuracy when using the default parameter value. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Bailey, T. L. & Elkan, C. </author> <year> (1993), </year> <title> Estimating the accuracy of learned concepts, </title> <editor> in R. Bajcsy, ed., </editor> <booktitle> "Proceedings of the Thirteenth International Joint Conference on Artificial Intelligence", </booktitle> <publisher> Morgan Kaufmann, </publisher> <pages> pp. 895-900. </pages>
Reference: <author> Breiman, L., Friedman, J., Olshen, R. & Stone, C. </author> <year> (1984), </year> <title> Classification and Regression Trees, </title> <publisher> Chapman & Hall, </publisher> <address> New York. </address>
Reference-contexts: A common choice for the representation of b f is a decision tree (Hunt, Marin & Stone 1966, Morgan & Messenger 1973, Breiman, Friedman, Olshen & Stone 1984). The process of building a decision tree is a recursive partitioning of a training set. CART <ref> (Breiman et al. 1984) </ref>, C4.5 (Quinlan 1993) and other decision tree algorithms use a stopping parameter, which sets some lower bound on the number of elements that must be in a set in order for that set to be partitioned further.
Reference: <author> Efron, B. & Tibshirani, R. </author> <year> (1986), </year> <title> "Bootstrap methods for standard errors, confidence intervals, and other measures of statistical accuracy", </title> <booktitle> Statistical Science 1(1), </booktitle> <pages> 54-77. </pages>
Reference-contexts: We hope that our results will inspire machine learning researchers to look more closely at cross-validation and related statistical error estimation techniques such as the bootstrap <ref> (Efron & Tibshirani 1986) </ref> as tools for parameter selection. Acknowledgments This material is based upon work supported under a National Science Foundation Graduate Research Fellowship. We would like to thank J. R. Quinlan for publishing the source code to C4.5, which allowed us to implement our ideas quite easily.
Reference: <author> Hubel, P. J. </author> <year> (1977), </year> <title> Robust Statistical Procedures, </title> <institution> Society for Industrial and Applied Mathematics, </institution> <address> Pitts-burgh, PA. </address>
Reference-contexts: We use a 20% trimmed mean, removing the top and bottom 20% of the values and then taking the mean of the rest. A trimmed mean is a more robust estimator <ref> (Hubel 1977) </ref> of the mean of a set of data if the data is suspected to contain outliers.
Reference: <author> Hunt, E. B., Marin, J. & Stone, P. J. </author> <year> (1966), </year> <title> Experiments in Induction, </title> <publisher> Academic Press, </publisher> <address> New York. </address> <publisher> 3 Morgan, </publisher> <editor> J. N. & Messenger, R. C. </editor> <year> (1973), </year> <title> THAID: a sequential analysis program for the analysis of nominal scale dependent variables, </title> <institution> University of Michigan. </institution>
Reference: <author> Murphy, P. M. & Aha, D. W. </author> <year> (1994), </year> <note> "UCI repository of machine learning databases", Available by anonymous ftp to ics.uci.edu in the pub/machine-learning-databases directory. </note>
Reference-contexts: The best estimated value of m is multiplied by 20/19 as a final correction for training set size. 3 Experiments We show results for four datasets taken from the UC Irvine repository <ref> (Murphy & Aha 1994) </ref> and one artificial dataset of our own construction. The Irvine datasets are the Wisconsin breast cancer database, the Pima Indians diabetes database, the credit database, and the artificial monks2 data.
Reference: <author> Quinlan, J. R. </author> <year> (1993), </year> <title> C4.5: Programs for Machine Learning, </title> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: 1 Introduction Technical Note STAN-CS-TN-94-12 Cross-validation (Weiss & Kulikowski 1991, Bailey & Elkan 1993) is a powerful tool for error estimation which has unfortunately been under-utilized in the machine learning community. We investigate its use in the C4.5 decision tree algorithm <ref> (Quinlan 1993) </ref> as the evaluation component of an exhaustive search over a space of parameter values. In supervised classification learning, one is given a training set of labeled instances. <p> A common choice for the representation of b f is a decision tree (Hunt, Marin & Stone 1966, Morgan & Messenger 1973, Breiman, Friedman, Olshen & Stone 1984). The process of building a decision tree is a recursive partitioning of a training set. CART (Breiman et al. 1984), C4.5 <ref> (Quinlan 1993) </ref> and other decision tree algorithms use a stopping parameter, which sets some lower bound on the number of elements that must be in a set in order for that set to be partitioned further. In C4.5 this is called the MINOBJS or m parameter.
Reference: <author> Weiss, S. M. & Kulikowski, C. A. </author> <year> (1991), </year> <title> Computer Systems that Learn, </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA. </address>
Reference-contexts: 1 Introduction Technical Note STAN-CS-TN-94-12 Cross-validation <ref> (Weiss & Kulikowski 1991, Bailey & Elkan 1993) </ref> is a powerful tool for error estimation which has unfortunately been under-utilized in the machine learning community.
References-found: 8

