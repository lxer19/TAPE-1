URL: http://www.cse.psu.edu/~zha/papers/inner.ps
Refering-URL: http://www.cse.psu.edu/~zha/papers.html
Root-URL: http://www.cse.psu.edu
Title: LARGE SPARSE SYMMETRIC EIGENVALUE PROBLEMS WITH HOMOGENEOUS LINEAR CONSTRAINTS: THE LANCZOS PROCESS WITH INNER-OUTER ITERATIONS  
Author: GENE H. GOLUB ZHENYUE ZHANG AND HONGYUAN ZHA 
Abstract: We study inner-outer iteration approach for large eigenproblems using symmetric eigenproblem with homogeneous linear constraints as a concrete example. The goal is to compute the extreme eigenvalues to certain accuracy with minimum total number of inner iteration steps. We develop two methods: variable-accuracy inner-outer Lanczos process and successive inner-outer Lanczos process, and we provide analysis to explain the behavior of these two methods. We also present various numerical examples to demonstrate the efficiency and accuracy of these methods. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Bjorck. </author> <title> Numerical Methods for Least Squares Problems. </title> <publisher> SIAM, </publisher> <address> Philadelphia, </address> <year> 1996. </year>
Reference-contexts: This motivates us to introduce the tolerance sequence o k (ff) = *=ju (k)j ff (4.6) with ff 2 <ref> [1; 2] </ref>. From the above discussion ff = 2 seems to be the best choice, and therefore will be used in the example below. Example 3.
Reference: [2] <author> J.H. Bramble, A.V. Knyazev, and J.E. Pasciak. </author> <title> A subspace preconditioning algorithm for eigenvector/eigenvalue computation. Advances in Comp. </title> <journal> Math., </journal> <volume> 6 </volume> <pages> 159-189, </pages> <year> 1996 </year>
Reference-contexts: The concept and technique of inner-outer iteration have been discussed in the literature mainly for the case of solving linear systems [7, 4, 6, 9]. Its application to the eigenvalue problems only recently has drawn considerable interests <ref> [2, 12, 13] </ref>. There are also discussions about inexact Newton's method for solving nonlinear equations. A very important observation is that different iterative processes for eigenproblems exhibit very different behavior with respect to the distribution of the accuracy of the inner iterations. <p> This motivates us to introduce the tolerance sequence o k (ff) = *=ju (k)j ff (4.6) with ff 2 <ref> [1; 2] </ref>. From the above discussion ff = 2 seems to be the best choice, and therefore will be used in the example below. Example 3.
Reference: [3] <author> D. Calvetti, L. Reichel and D. Sorensen. </author> <title> An implicitly restarted Lanczos method for large symmetric eigenvalue problems. </title> <journal> ETNA, </journal> <volume> 2 </volume> <pages> 1-21, </pages> <year> 1994. </year>
Reference-contexts: Also the sensitivity issue alluded to in Example 6 seems to be related to the choice of the initial vector x (k) . We are exploring using the recently proposed thick-restart strategy <ref> [3, 27, 30] </ref>. Those are the areas that certainly deserve further investigation. Acknowledgement. We thank the anonymous referees for many insightful suggestions and comments which greatly improve the presentation of the paper.
Reference: [4] <author> H. Elman and G. H. Golub. </author> <title> Inexact and preconditioned Uzawa algorithms for saddle point problems. </title> <journal> SIAM Journal of Numerical Analysis, </journal> <volume> 31 </volume> <pages> 1645-1661, </pages> <year> 1994. </year>
Reference-contexts: Investigating the effects of the accuracy of these inner iterations on the overall accuracy of the computed eigenpairs is the major theme of this paper. The concept and technique of inner-outer iteration have been discussed in the literature mainly for the case of solving linear systems <ref> [7, 4, 6, 9] </ref>. Its application to the eigenvalue problems only recently has drawn considerable interests [2, 12, 13]. There are also discussions about inexact Newton's method for solving nonlinear equations.
Reference: [5] <author> T. Ericsson and A. Ruhe. </author> <title> The spectral transformation Lanczos method for the numerical solution of large sparse generalized symmetric eigenvalue problems. </title> <journal> Mathematics of Computation, </journal> <volume> 35 </volume> <pages> 1251-1268, </pages> <year> 1980. </year>
Reference-contexts: Examples include 1) the spectral shift-and-invert method for subspace iteration and Lanczos process where one needs to compute (A oeI) 1 u for a given u at each iteration step <ref> [5, 23] </ref>; 2) the Jacobi-Davidson algorithm [26]; 3) the Lanczos bidiagonalization process for the generalized SVD of the matrix pair fA; Bg, where at each iteration step a linear least squares problem with [A T ; B T ] T as the coefficient matrix needs to be solved [31]. <p> One possible approach suggested in the literature is to use direct method for computing the required product, for example, in the shift-and-invert case, one computes the LU (LDL T ) decomposition of A oeI, and then forms the vector (A oeI) 1 u by solving triangular linear systems <ref> [5, 23] </ref>. When the dimension of the problem becomes large, speed and storage constraints force one to resort to iterative methods for the computation of the product. This results in an inner-outer iteration process where at each outer iteration step the matrix-vector multiplication is accomplished by an inner iteration.
Reference: [6] <author> E. Giladi, G. H. Golub and J. H. Keller. </author> <title> Inner and outer iterations for the Chebyshev algorithm. </title> <type> Manuscript SCCM-95-12, </type> <institution> Stanford University, </institution> <year> 1995. </year>
Reference-contexts: Investigating the effects of the accuracy of these inner iterations on the overall accuracy of the computed eigenpairs is the major theme of this paper. The concept and technique of inner-outer iteration have been discussed in the literature mainly for the case of solving linear systems <ref> [7, 4, 6, 9] </ref>. Its application to the eigenvalue problems only recently has drawn considerable interests [2, 12, 13]. There are also discussions about inexact Newton's method for solving nonlinear equations.
Reference: [7] <author> G. H. Golub and M. Overton. </author> <title> The convergence of inexact Chebyshev and Richardson iterative methods for solving linear systems. </title> <journal> Numerische Mathematik, </journal> <volume> 53 </volume> <pages> 571-593, </pages> <year> 1988. </year>
Reference-contexts: Investigating the effects of the accuracy of these inner iterations on the overall accuracy of the computed eigenpairs is the major theme of this paper. The concept and technique of inner-outer iteration have been discussed in the literature mainly for the case of solving linear systems <ref> [7, 4, 6, 9] </ref>. Its application to the eigenvalue problems only recently has drawn considerable interests [2, 12, 13]. There are also discussions about inexact Newton's method for solving nonlinear equations.
Reference: [8] <author> G. H. Golub and C. F. Van Loan. </author> <title> Matrix Computations. </title> <publisher> Johns Hopkins University Press, </publisher> <address> Baltimore, Maryland, third edition. </address>
Reference-contexts: A' denotes the transpose of A. We also use several MATLAB functions such as rand, qr, diag for constructing testing matrices. 2. Lanczos Process with Inner-Outer Iterations. The simple symmetric Lanczos process in infinite precision applied to matrix B is summarized in the following <ref> [8, Section 9] </ref>: Symmetric Eigenvalue Problems with Linear Homogeneous Constraints 3 Algorithm Simple Lanczos 1. Initialization. Choose v 1 and set fi 1 = kv 1 k 2 and q 0 = 0. 2.
Reference: [9] <author> G. H. Golub and Q. Ye. </author> <title> The inexact conjugate gradient method. </title> <note> In preparation. </note>
Reference-contexts: Investigating the effects of the accuracy of these inner iterations on the overall accuracy of the computed eigenpairs is the major theme of this paper. The concept and technique of inner-outer iteration have been discussed in the literature mainly for the case of solving linear systems <ref> [7, 4, 6, 9] </ref>. Its application to the eigenvalue problems only recently has drawn considerable interests [2, 12, 13]. There are also discussions about inexact Newton's method for solving nonlinear equations.
Reference: [10] <author> A. Greenbaum. </author> <title> Behavior of slightly perturbed Lanczos conjugate gradient recurrences. </title> <journal> Linear Algebra and Its Applications, </journal> <volume> 113 </volume> <pages> 7-63, </pages> <year> 1989. </year>
Reference-contexts: Empirical evidence shows that the final accuracy is essentially the same as the constant accuracy used in the inner iterations. To see why this is so, let us recall a result of Greenbaum <ref> [10] </ref> which states that the tridiagonal matrix T j generated at the end of the j-th finite precision Lanczos process satisfying AQ j = Q j T j + fi j q j+1 e T with kF j k 2 = O ( p jkAk 2 ) is the same as
Reference: [11] <author> W. Kahan, B. N. Parlett and E. Jiang. </author> <title> Residual bounds on approximate eigensystems of nonnormal matrices. </title> <journal> SIAM J. Numer. Anal., </journal> <volume> 19 </volume> <pages> 470-484, </pages> <year> 1982. </year>
Reference-contexts: Remark. We notice as mentioned in the proof above that Eu = ~ Au u; E ~u = (A~u ~ ~u): The results of the above theorem can also be cast in terms of these residuals <ref> [11] </ref>. However, as we will see later we are more interested in controlling the norm of the perturbation matrix E and thus the results are presented in terms of E and (approximate) eigenvectors. Now we return to Example 1.
Reference: [12] <author> Y. Lai, K. Lin, and W. Lin. </author> <title> An inexact inverse iteration for large sparse eigenvalue problems. </title> <journal> Num. Lin. Alg. Appl., </journal> <volume> 4 </volume> <pages> 425-437, </pages> <year> 1997 </year>
Reference-contexts: The concept and technique of inner-outer iteration have been discussed in the literature mainly for the case of solving linear systems [7, 4, 6, 9]. Its application to the eigenvalue problems only recently has drawn considerable interests <ref> [2, 12, 13] </ref>. There are also discussions about inexact Newton's method for solving nonlinear equations. A very important observation is that different iterative processes for eigenproblems exhibit very different behavior with respect to the distribution of the accuracy of the inner iterations. <p> On the other hand, for the power method, for example, the situation is just the opposite: one can start with very inaccurate inner iterations and gradually increases the accuracy and still be able to obtain high accuracy for the computed eigenpairs <ref> [12] </ref>. In this paper, we concentrate on the Lanczos process for the symmetric eigenproblems and apply it to a concrete problem below. We should emphasize that the reason for choosing this particular problem is because we need to provide a concrete environment to discuss various issues associated with inner-outer iteration.
Reference: [13] <author> R. B. Lehoucq and K. Meerbergen. </author> <title> Using generalized Cayley transformations within an inexact rational Krylov sequence method. </title> <note> SIAM J. Matrix Anal. Applic., 1999 (to appear) </note>
Reference-contexts: The concept and technique of inner-outer iteration have been discussed in the literature mainly for the case of solving linear systems [7, 4, 6, 9]. Its application to the eigenvalue problems only recently has drawn considerable interests <ref> [2, 12, 13] </ref>. There are also discussions about inexact Newton's method for solving nonlinear equations. A very important observation is that different iterative processes for eigenproblems exhibit very different behavior with respect to the distribution of the accuracy of the inner iterations.
Reference: [14] <author> S. M. Lu and J.L. Barlow. </author> <title> Multifrontal computation with the orthogonal factors of sparse matrices. </title> <journal> SIAM J. Matrix Anal. Applic., </journal> <volume> 17 </volume> <pages> 658-679, </pages> <year> 1996. </year>
Reference-contexts: Therefore in both these cases, the constrained eigenproblem is readily solved by using, for example, the sparse QR algorithms in <ref> [14, 15] </ref>. In this paper, we will discuss the case where the projection P u has to be computed iteratively. In Section 2, a framework based on inner-outer Lanczos process is presented for solving (1.1).
Reference: [15] <author> P. Matstoms. </author> <title> Sparse QR factorization with apllications to linear least squares problems. </title> <type> Ph.D. </type> <institution> Dessertation, Department of Mathematics, Linkoping University, Sweden, </institution> <year> 1994. </year>
Reference-contexts: Therefore in both these cases, the constrained eigenproblem is readily solved by using, for example, the sparse QR algorithms in <ref> [14, 15] </ref>. In this paper, we will discuss the case where the projection P u has to be computed iteratively. In Section 2, a framework based on inner-outer Lanczos process is presented for solving (1.1).
Reference: [16] <author> C. C. Paige. </author> <title> Error analysis of the Lanczos algorithm for tridiagonalizing a symmetric matrix. </title> <journal> Journal of Institute of Mathematics and Applications. </journal> <volume> 18 </volume> <pages> 341-349, </pages> <year> 1976. </year>
Reference: [17] <author> C. C. Paige. </author> <title> Accuracy and effectiveness of the Lanczos algorithm for the symmetric eigenprob-lem. </title> <journal> Linear Algebra and Its Applications, </journal> <volume> 34 </volume> <pages> 235-258, </pages> <year> 1980. </year>
Reference: [18] <author> C. C. Paige and M. A. Saunders. </author> <title> LSQR: an algorithm for sparse linear equations and sparse least squares. </title> <journal> ACM Transaction on Mathematical Software, </journal> <volume> 8 </volume> <pages> 43-71, </pages> <year> 1982. </year>
Reference: [19] <author> B. N. Parlett. </author> <title> The Symmetric Eigenvalue Problem. </title> <publisher> SIAM, </publisher> <address> Philadelphia, </address> <year> 1998. </year>
Reference-contexts: Below we list the components of the eigenvectors u 1 and u 2 . 8.9160e-01 8.9665e-01 3.0807e-03 3.1341e-03 7.5469e-07 7.9987e-07 Remark. Several other examples of similar matrices are presented in [22]. In general, extreme eigenvectors of tridiagonal matrices resulted from the Lanczos process will have decreasing components <ref> [19] </ref>. The small magnitude of the last components of the eigenvectors is the key for the convergence property of Lanczos process.
Reference: [20] <author> B. N. Parlett. </author> <title> The rewards for maintaining semi-orthogonality among Lanczos vectors. </title> <journal> Journal of Numerical Linear Algebra and Its Applications, </journal> <volume> 1 </volume> <pages> 243-267, </pages> <year> 1992. </year>
Reference: [21] <author> B. N. Parlett and D. S. Scott. </author> <title> The Lanczos algorithm with selective reorthogonalization. </title> <journal> Mathematics of Computation, </journal> <volume> 33 </volume> <pages> 217-238, </pages> <year> 1979. </year>
Reference: [22] <author> B. N. Parlett. </author> <title> Invariant subspaces for tightly clustered eigenvalues of tridiagonals. </title> <journal> BIT, </journal> <volume> 36 </volume> <pages> 542-562, </pages> <year> 1996. </year>
Reference-contexts: Below we list the components of the eigenvectors u 1 and u 2 . 8.9160e-01 8.9665e-01 3.0807e-03 3.1341e-03 7.5469e-07 7.9987e-07 Remark. Several other examples of similar matrices are presented in <ref> [22] </ref>. In general, extreme eigenvectors of tridiagonal matrices resulted from the Lanczos process will have decreasing components [19]. The small magnitude of the last components of the eigenvectors is the key for the convergence property of Lanczos process.
Reference: [23] <author> Y. Saad. </author> <title> Numerical Methods for Large Eigenvalue Problems. </title> <publisher> University of Manchester Press, </publisher> <address> New York, </address> <year> 1992. </year>
Reference-contexts: Examples include 1) the spectral shift-and-invert method for subspace iteration and Lanczos process where one needs to compute (A oeI) 1 u for a given u at each iteration step <ref> [5, 23] </ref>; 2) the Jacobi-Davidson algorithm [26]; 3) the Lanczos bidiagonalization process for the generalized SVD of the matrix pair fA; Bg, where at each iteration step a linear least squares problem with [A T ; B T ] T as the coefficient matrix needs to be solved [31]. <p> One possible approach suggested in the literature is to use direct method for computing the required product, for example, in the shift-and-invert case, one computes the LU (LDL T ) decomposition of A oeI, and then forms the vector (A oeI) 1 u by solving triangular linear systems <ref> [5, 23] </ref>. When the dimension of the problem becomes large, speed and storage constraints force one to resort to iterative methods for the computation of the product. This results in an inner-outer iteration process where at each outer iteration step the matrix-vector multiplication is accomplished by an inner iteration.
Reference: [24] <author> M. A. Saunders. </author> <title> Solutions of sparse rectangular systems using LSQR and Craig. </title> <journal> BIT, </journal> <volume> 35 </volume> <pages> 588-604, </pages> <year> 1995. </year> <note> 16 GENE GOLUB, ZHENYUE ZHANG and HONGYUAN ZHA </note>
Reference: [25] <author> H. D. Simon. </author> <title> Analysis of the symmetric Lanczos algorithm with reorthogonalization methods. </title> <journal> Linear Algebra and Its Applications, </journal> <volume> 61 </volume> <pages> 103-131, </pages> <year> 1984. </year>
Reference: [26] <author> G. L. G. Sleijpen and H. A. van der Vorst. </author> <title> A Jacobi-Davidson iteration method for linear eigenvalue problems. </title> <journal> SIAM J. Matrix Anal. Applic., </journal> <volume> 17(2) </volume> <pages> 401-425, </pages> <year> 1996 </year>
Reference-contexts: Examples include 1) the spectral shift-and-invert method for subspace iteration and Lanczos process where one needs to compute (A oeI) 1 u for a given u at each iteration step [5, 23]; 2) the Jacobi-Davidson algorithm <ref> [26] </ref>; 3) the Lanczos bidiagonalization process for the generalized SVD of the matrix pair fA; Bg, where at each iteration step a linear least squares problem with [A T ; B T ] T as the coefficient matrix needs to be solved [31].
Reference: [27] <author> A. Stathopoulos, Y. Saad, and K. Wu. </author> <title> Dynamic thick restarting of the Davidson and the implicitly restarted Arnoldi methods. </title> <journal> SIAM J. Matrix Anal. Applic., </journal> <volume> 19(1) </volume> <pages> 229-245, </pages> <year> 1998 </year>
Reference-contexts: Also the sensitivity issue alluded to in Example 6 seems to be related to the choice of the initial vector x (k) . We are exploring using the recently proposed thick-restart strategy <ref> [3, 27, 30] </ref>. Those are the areas that certainly deserve further investigation. Acknowledgement. We thank the anonymous referees for many insightful suggestions and comments which greatly improve the presentation of the paper.
Reference: [28] <author> G.W. Stewart and J. Sun. </author> <title> Matrix Perturbation Theory, </title> <publisher> Academic Press, </publisher> <address> Boston, </address> <year> 1990. </year>
Reference-contexts: So the position where perturbation occurs in a matrix affects the pertur bation in the eigenvalues and eigenvectors. Now we are ready to present our main perturbation results. 1 1 Similar but less sharp result for the eigenvalues is also presented in <ref> [28] </ref>. Symmetric Eigenvalue Problems with Linear Homogeneous Constraints 5 Theorem 3.1. Let U and ~ U be the eigenspaces corresponding to the smallest eigenvalues of A and ~ of ~ A, respectively. Then 1.
Reference: [29] <author> J. H. Wilkinson. </author> <title> The Algebraic Eigenvalue Problem. </title> <publisher> Claredon Press, Oxford, </publisher> <address> England, </address> <year> 1965. </year>
Reference: [30] <author> K. Wu and H. Simon. </author> <title> Thick-restart Lanczos method for symmetric eigenvalue problems. </title> <type> Report Number 41412. </type> <institution> Lawrence Berkeley National Laboratory, </institution> <year> 1998. </year>
Reference-contexts: Also the sensitivity issue alluded to in Example 6 seems to be related to the choice of the initial vector x (k) . We are exploring using the recently proposed thick-restart strategy <ref> [3, 27, 30] </ref>. Those are the areas that certainly deserve further investigation. Acknowledgement. We thank the anonymous referees for many insightful suggestions and comments which greatly improve the presentation of the paper.
Reference: [31] <author> H. Zha. </author> <title> Computing the generalized singular values/vectors of large sparse or structured matrix pairs. </title> <journal> Numerische Mathematik, </journal> <volume> 72 </volume> <pages> 391-417, </pages> <year> 1996. </year>
Reference-contexts: iteration step [5, 23]; 2) the Jacobi-Davidson algorithm [26]; 3) the Lanczos bidiagonalization process for the generalized SVD of the matrix pair fA; Bg, where at each iteration step a linear least squares problem with [A T ; B T ] T as the coefficient matrix needs to be solved <ref> [31] </ref>.
References-found: 31

