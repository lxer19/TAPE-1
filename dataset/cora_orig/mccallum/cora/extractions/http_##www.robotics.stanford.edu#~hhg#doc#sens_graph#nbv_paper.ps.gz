URL: http://www.robotics.stanford.edu/~hhg/doc/sens_graph/nbv_paper.ps.gz
Refering-URL: http://www.robotics.stanford.edu/~hhg/doc/sens_graph/
Root-URL: http://www.robotics.stanford.edu
Email: hhg@flamingo.stanford.edu  
Title: The Next-Best View Problem in a Mobile Range-Data Acquisition System  
Author: Hector H. Gonzalez-Ba~nos 
Affiliation: Computer Science Department Stanford University  
Abstract: This report presents next-best view (NBV) issues in a mobile range-data acquistion system (MRAS). Given the nature of a mobile systems, some of the traditional assumptions made for fixed sensor systems are not entirely justifiable in robotics. Some extra considerations have to be addressed, such as geometric constraints over the robot motions, the cost of planning motions, the cost of translating among subsequent viewpoints, the cost of sensing, and measurement ambiguity. Some traditional issues are even more critical in a mobile system, such as the alignment of multiple-views. Some of these problems have already been addressed in the NBV literature at least to some extense, while others remain open. This reports presents a small survey of papers that may prove relevant in solving the NBV and scene-exploration problem in a MRAS.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J.E. Banta, Y. Zhien, X.Z. Wang, G. Zhang, M.T. Smith, and M.A. Abidi. </author> <title> A "next-best view algorithm" for three-dimensional scene reconstruction using range images. </title> <booktitle> volume 2588, </booktitle> <pages> pages 418-29, </pages> <year> 1995. </year>
Reference-contexts: The objective of the paper is to answer the question of whether a particular surface may be explored in a finite number of steps using ordinary sensors. A more pragmatical approach is given in <ref> [1] </ref>. The authors propose a sensing module capable of determining the next view very quickly. The drawback is that there is no guarantee that the computed next view is the best, or even the near best. <p> The work in [8] presents the paradigm of solving the ray and camera occlusions separately, although the order presented in that paper may not be suitable for a MRAS. The papers <ref> [3, 1, 6] </ref> try to provide very practical approaches for 3-D exploration, although [1] provides a very loosely fundamented one. On the opposite side we 4 have the work in [7], where most efforts are aimed in proving the correctness of an algorithm. <p> The work in [8] presents the paradigm of solving the ray and camera occlusions separately, although the order presented in that paper may not be suitable for a MRAS. The papers [3, 1, 6] try to provide very practical approaches for 3-D exploration, although <ref> [1] </ref> provides a very loosely fundamented one. On the opposite side we 4 have the work in [7], where most efforts are aimed in proving the correctness of an algorithm.
Reference: [2] <author> Z. Chen and C.M. Huang. </author> <title> Terrain exploration of a sensor-based robot moving among unknown obstacles of polygonal shape. </title> <journal> In Robotica, </journal> <volume> volume 12, </volume> <pages> pages 33-44, </pages> <year> 1994. </year>
Reference-contexts: A group of papers assume that the problem is outright 2-D. The papers <ref> [2, 5] </ref> approach the problem from a computational geometry perspective. They attack the problem of on-line search of polygons. <p> In [5] a type of polygon is introduced for which a (1 + p 5)=2-competitive search is possible (the worst-case cost or distance is at most (1 + p 5)=2 times worse than the optimal strategy given complete knowledge of the geometry). In <ref> [2] </ref> general polygons are considered, and an algorithm for the incremental exploration of the workspace is provided. In this paper the exploration is, of course, not as efficient as the one described in [5], as the algorithm is not restricted to polygons of a particular class. <p> And finally we have those papers that attempt to solve the 3-D exploration by assuming that a 2-D solution is a good approximation for the case of mobile range-finders restricted to a plane. The papers <ref> [2, 5] </ref> provide explicit results in the intrinsic computational geometry problem behind scene exploration issues. And [4] introduces a method to solve, both the motion planning problem and the reconstruction of a 2-D layout, within the same framework, relying exclusively in sensor readings.
Reference: [3] <author> C.I. Connolly. </author> <title> The determination of the next best view. </title> <booktitle> In IEEE Int. Conf. Robot. & Autom., </booktitle> <pages> pages 432-435, </pages> <year> 1985. </year>
Reference-contexts: In the experimental results section, the paper includes a plot of how the ratio of ideal (occupied) volume versus recovered (occupied or unexplored) volume increases monotonically over the number of views assimilated into the world model. Better practical approaches are described in <ref> [3, 8, 9] </ref>. The first real approach to solve the NBV is described in [3], where the planetarium algorithm is introduced. The basic idea is to solve for sensor placement from a local map of the scene described by an octree. <p> Better practical approaches are described in [3, 8, 9]. The first real approach to solve the NBV is described in <ref> [3] </ref>, where the planetarium algorithm is introduced. The basic idea is to solve for sensor placement from a local map of the scene described by an octree. The planetarium algorithm 3 gives the best viewpoint among a set of camera positions distributed uniformly on a sphere around the scene. <p> The work in [8] presents the paradigm of solving the ray and camera occlusions separately, although the order presented in that paper may not be suitable for a MRAS. The papers <ref> [3, 1, 6] </ref> try to provide very practical approaches for 3-D exploration, although [1] provides a very loosely fundamented one. On the opposite side we 4 have the work in [7], where most efforts are aimed in proving the correctness of an algorithm.
Reference: [4] <author> K. Kakusho, T. Kitahashi, K. Kondo, and J.C. Latombe. </author> <title> Continuous purposive sensing and motion for 2d map building. </title> <booktitle> In Proc. IEEE Int. Conf. on Syst., Man, & Cybern., </booktitle> <volume> volume 2, </volume> <pages> pages 1472-77, </pages> <year> 1995. </year>
Reference-contexts: They are important, however, in that they provide an idea of the basic geometric problem, and establish bounds of how effectively we can solve it. In <ref> [4] </ref> an algorithm for purposive sensing and motion fo 2-D map building is presented. The authors consider real sensors (sonars), and collision-avoidance issues. <p> The papers [2, 5] provide explicit results in the intrinsic computational geometry problem behind scene exploration issues. And <ref> [4] </ref> introduces a method to solve, both the motion planning problem and the reconstruction of a 2-D layout, within the same framework, relying exclusively in sensor readings. As we may see, some of aspects of the NBV for a MRAS have been addressed, although not in a unified fashion.
Reference: [5] <author> J.M. Kleinberg. </author> <title> On-line search in a simple polygon. </title> <booktitle> In Proc. 5th ACM-SIAM Symp. on Discrete Algorithms., </booktitle> <pages> pages 8-15, </pages> <year> 1994. </year>
Reference-contexts: A group of papers assume that the problem is outright 2-D. The papers <ref> [2, 5] </ref> approach the problem from a computational geometry perspective. They attack the problem of on-line search of polygons. <p> A group of papers assume that the problem is outright 2-D. The papers [2, 5] approach the problem from a computational geometry perspective. They attack the problem of on-line search of polygons. In <ref> [5] </ref> a type of polygon is introduced for which a (1 + p 5)=2-competitive search is possible (the worst-case cost or distance is at most (1 + p 5)=2 times worse than the optimal strategy given complete knowledge of the geometry). <p> In [2] general polygons are considered, and an algorithm for the incremental exploration of the workspace is provided. In this paper the exploration is, of course, not as efficient as the one described in <ref> [5] </ref>, as the algorithm is not restricted to polygons of a particular class. In both papers the results are very clean, precise, and provable, but they do not consider physical limitations of any type, and assume perfect sensing. <p> And finally we have those papers that attempt to solve the 3-D exploration by assuming that a 2-D solution is a good approximation for the case of mobile range-finders restricted to a plane. The papers <ref> [2, 5] </ref> provide explicit results in the intrinsic computational geometry problem behind scene exploration issues. And [4] introduces a method to solve, both the motion planning problem and the reconstruction of a 2-D layout, within the same framework, relying exclusively in sensor readings.
Reference: [6] <author> E. Kruse, R. Gutsche, </author> <title> and F.M. Wahl. Efficient, iterative, sensor based 3-d map building using rating functions in configuration space. </title> <booktitle> In IEEE Int. Conf. Robot. & Autom., </booktitle> <pages> pages 1067-72, </pages> <year> 1996. </year>
Reference-contexts: However, the central idea of using model primitives to reduce uncertainity may prove a good starting point for NBV approaches that seek to maximize the information content (entropy minimization). As for the question of the objective function definition (what we mean by "best"), <ref> [6] </ref> proposes a performance criterion that will very likely prove to be well-suited for a MRAS. The paper proposes a "planning-sensing-updating" cycle, where special attention is paid on planning. <p> Papers [11, 10] pose different views with respect to the requisite of using models in NBV computation. In [10], the constraint of mantaining a specified degree of certainity is considered. The work described in <ref> [6] </ref> gives attention to the characteristics of the objective function (what is intended as "best"), and includes the cost of motion planning in the rating functions. In [9], the coupling between the NBV problem and that of multiple-views aligment is taking into account in the problem restrictions. <p> The work in [8] presents the paradigm of solving the ray and camera occlusions separately, although the order presented in that paper may not be suitable for a MRAS. The papers <ref> [3, 1, 6] </ref> try to provide very practical approaches for 3-D exploration, although [1] provides a very loosely fundamented one. On the opposite side we 4 have the work in [7], where most efforts are aimed in proving the correctness of an algorithm.
Reference: [7] <author> K.N. Kutulakos, C.R. Dyer, and V.J. Lumelsky. </author> <title> Provable strategies for vsion-guided exploration in three dimensions. </title> <booktitle> In IEEE Int. Conf. Robot. & Autom., </booktitle> <volume> volume 2, </volume> <pages> pages 1365-72, </pages> <year> 1994. </year>
Reference-contexts: Although the authors propose a specific form for the rating function, their methodology holds as long as certain (acceptable) conditions are met. A good mathematical formalization of vision-guided exploration is given in <ref> [7] </ref>. This paper provide an approach for exploring unknown, arbitrary surfaces in 3-D space. The main contributions are two provably-correct exploration strategies. One strategy uses a range sensor, and is complete for smooth and connected surfaces of finite area. <p> The papers [3, 1, 6] try to provide very practical approaches for 3-D exploration, although [1] provides a very loosely fundamented one. On the opposite side we 4 have the work in <ref> [7] </ref>, where most efforts are aimed in proving the correctness of an algorithm. And finally we have those papers that attempt to solve the 3-D exploration by assuming that a 2-D solution is a good approximation for the case of mobile range-finders restricted to a plane.
Reference: [8] <author> J. Maver and R. </author> <title> Bajcsy. Occlusions as a guide for planning the next view. </title> <journal> IEEE Trans. Pattern Anal. and Machine Intell., </journal> <volume> 15(5) </volume> <pages> 417-433, </pages> <year> 1993. </year>
Reference-contexts: In the experimental results section, the paper includes a plot of how the ratio of ideal (occupied) volume versus recovered (occupied or unexplored) volume increases monotonically over the number of views assimilated into the world model. Better practical approaches are described in <ref> [3, 8, 9] </ref>. The first real approach to solve the NBV is described in [3], where the planetarium algorithm is introduced. The basic idea is to solve for sensor placement from a local map of the scene described by an octree. <p> This algorithm is a lot faster than the planetarium one, but does not handle occlusions as well. The work described in <ref> [8] </ref> addresses the fact that occlusions in a real laser range-finder are of two types: those originated when the laser light does not reach the surface, and those caused because the reflected laser light does not reach the camera. <p> In a robot equipped with a vertical laser range-finder mounted on a turret, rotations of the sensor system solve for ray occlusions, not camera ones translations of the robot solve for camera occlusions. Applying directly the method proposed in <ref> [8] </ref> will yield innefficient strategies, as translations (which require planning) will be effected prior to turret rotations (which are faster and more precise to execute). The final paper [9] described in this report is the work of R. Pito. <p> In [9], the coupling between the NBV problem and that of multiple-views aligment is taking into account in the problem restrictions. The work in <ref> [8] </ref> presents the paradigm of solving the ray and camera occlusions separately, although the order presented in that paper may not be suitable for a MRAS. The papers [3, 1, 6] try to provide very practical approaches for 3-D exploration, although [1] provides a very loosely fundamented one.
Reference: [9] <author> R. Pito. </author> <title> A sensor based solution to the next best view problem. </title> <booktitle> In Proc. IEEE 13th Int. Conf. on Pattern Recognition, </booktitle> <volume> volume 1, </volume> <pages> pages 941-5, </pages> <year> 1996. </year>
Reference-contexts: In the experimental results section, the paper includes a plot of how the ratio of ideal (occupied) volume versus recovered (occupied or unexplored) volume increases monotonically over the number of views assimilated into the world model. Better practical approaches are described in <ref> [3, 8, 9] </ref>. The first real approach to solve the NBV is described in [3], where the planetarium algorithm is introduced. The basic idea is to solve for sensor placement from a local map of the scene described by an octree. <p> Applying directly the method proposed in [8] will yield innefficient strategies, as translations (which require planning) will be effected prior to turret rotations (which are faster and more precise to execute). The final paper <ref> [9] </ref> described in this report is the work of R. Pito. His work provides a system to automatically acquire surface models by repeatedly solving the NBV problem. The objective functions addressed in this work deals with the information content exclusively, and no motion-related cost is considered. <p> This paper presents one of the best algorithms so far, but it remains unclear how easy it is to compute the positional space of a particular problem. In <ref> [9] </ref>, the experimental setup consists on a range-finder orbiting along a 90 degree arc around a turntable. Scans are made by moving the scanner, and different views are obtained by rotating the turntable. <p> In [10], the constraint of mantaining a specified degree of certainity is considered. The work described in [6] gives attention to the characteristics of the objective function (what is intended as "best"), and includes the cost of motion planning in the rating functions. In <ref> [9] </ref>, the coupling between the NBV problem and that of multiple-views aligment is taking into account in the problem restrictions. The work in [8] presents the paradigm of solving the ray and camera occlusions separately, although the order presented in that paper may not be suitable for a MRAS.
Reference: [10] <author> P. Whaite and F.P. Ferrie. </author> <title> From uncertainty to visual exploration. </title> <booktitle> In Proc. 3rd Int. Conf. on Computer Vision, </booktitle> <pages> pages 690-7, </pages> <year> 1990. </year>
Reference-contexts: According to this paper, model-free methods compare favorably to model-based ones in purely search tasks, and their simplicity compensates many of the efficiency advantages a model-based method may possess. In <ref> [10] </ref>, an opposite paradigm is stated. Given a set of primitives for modeling (superquadrics in this case), it is plausible to compute the degree of uncertainity of a model fragment. Future viewpoints are selected in order to reduce the ambiguity of the current information state. <p> Papers <ref> [11, 10] </ref> pose different views with respect to the requisite of using models in NBV computation. In [10], the constraint of mantaining a specified degree of certainity is considered. <p> Papers [11, 10] pose different views with respect to the requisite of using models in NBV computation. In <ref> [10] </ref>, the constraint of mantaining a specified degree of certainity is considered. The work described in [6] gives attention to the characteristics of the objective function (what is intended as "best"), and includes the cost of motion planning in the rating functions.
Reference: [11] <author> L. Wixson. </author> <title> Viewpoint selection for visual search. </title> <booktitle> In Proc. IEEE Conf. on Comp. Vision and Patt. Recog., </booktitle> <pages> pages 800-805, </pages> <year> 1994. </year> <month> 5 </month>
Reference-contexts: The real question, however, is if a search task, as a task requisite, requires model construction. There is a class of problems in which we are really interested only in searching the environment, not in the model itself (for target localization, hide and seek problems, fault detections, etc.). In <ref> [11] </ref>, the author questions the requirement of models in purely search problems, and proposes a compromise between fixed-increment strategies (where the sensor rotates in fixed increments around the search area) and model-based ones. <p> Papers <ref> [11, 10] </ref> pose different views with respect to the requisite of using models in NBV computation. In [10], the constraint of mantaining a specified degree of certainity is considered.
References-found: 11

