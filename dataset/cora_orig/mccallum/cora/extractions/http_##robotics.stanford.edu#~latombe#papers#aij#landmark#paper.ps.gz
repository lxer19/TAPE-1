URL: http://robotics.stanford.edu/~latombe/papers/aij/landmark/paper.ps.gz
Refering-URL: http://robotics.stanford.edu/~latombe/pub.html
Root-URL: http://www.robotics.stanford.edu
Email: lazanas@flamingo.stanford.edu  latombe@cs.stanford.edu  
Title: Motion Planning with Uncertainty: A Landmark Approach for their experimental work with the planner using
Author: Anthony Lazanas Jean-Claude Latombe Craig Becker, Philippe Moutarlier, Joaquin Salas, Benjamin Schalet, Ken Tokusei, and David Zhu Craig Becker and Ken Tokusei. 
Note: Acknowledgments: This research was funded by darpa/onr contract n00014-92-j-1809. The authors thank  
Address: Stanford, CA 94305, USA  
Affiliation: Robotics Laboratory, Department of Computer Science Stanford University,  
Abstract: In robotics uncertainty exists at both planning and execution time. Effective planning must make sure that enough information becomes available to the sensors during execution, to allow the robot to correctly identify the states it traverses. It requires selecting a set of states, associating a motion command with every state, and synthesizing functions to recognize state achievement. These three tasks are often interdependent, causing existing planners to be either unsound, incomplete, and/or computationally impractical. In this paper we partially break this interdependence by assuming the existence of landmark regions in the workspace. We define such regions as "islands of perfection" where position sensing and motion control are accurate. Using this notion, we propose a sound and complete planner of polynomial complexity. Creating landmarks may require some prior engineering of the robot and/or its environment. Though we believe that such engineering is unavoidable in order to build reliable practical robot systems, its cost must be reduced as much as possible. With this goal in mind, we also investigate how some of our original assumptions can be eliminated. In particular, we show that sensing and control do not have to be perfect in landmark regions. We also study the dependency of a plan on control uncertainty and we show that the structure of a reliable plan only changes at critical values of this uncertainty. Hence, any uncertainty reduction between two consecutive such values is useless. The proposed planner has been implemented. Experimentation has been successfully conducted both in simulation and using a nomad-200 mobile robot.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Ayache, N., </author> <title> Artificial Vision for Mobile Robots: Stereo Vision and Multisensory Perception, </title> <publisher> The MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1991. </year>
Reference-contexts: Over the past decade, there has also been a substantial amount of work at reducing uncertainty (mainly position uncertainty) while a robot is moving. For example, for mobile robots, many techniques have been proposed to combine the estimates provided by both dead-reckoning and environmental sensing (e.g., see <ref> [1, 9, 29, 40] </ref>). These techniques address the problem of tracking a selected motion plan as well as possible, not the problem of generating this plan.
Reference: [2] <author> Brafman, R.I., Latombe, J.C., and Shoham, Y., </author> <title> Towards Knowledge-Level Analysis of Motion Planning, </title> <booktitle> Proc. of the 11th Nat. Conf. on Artificial Intelligence, AAAI, </booktitle> <address> Washington, DC, 670-675, </address> <month> July </month> <year> 1993. </year>
Reference-contexts: To generate reliable plans, the planner must choose courses of actions whose execution is guaranteed to make enough knowledge available to allow the robot to correctly identify the states it traverses, despite execution-time errors in control and sensing <ref> [2] </ref>. The overall task of the planner is to select an adequate set of states, associate appropriate motion commands with these states, and synthesize state-recognition functions. All three subtasks are interdependent. One often expects too much from a system reasoning in the presence of uncertainty.
Reference: [3] <author> Briggs, A.J., </author> <title> An Efficient Algorithm for One-Step Planar Compliant Motion Planning with Uncertainty, </title> <booktitle> Proc. of the 5th Annual Symp. on Comp. Geom., Saarbrucken, </booktitle> <address> Germany, </address> <year> 1989. </year>
Reference-contexts: These backprojections are computed at critical directions of motion where the topology of the backprojection's boundary changes. Donald proposed an O (n 4 log n) algorithm, with n being the number of obstacle edges, to compute nondirectional backprojections and embedded this algorithm into a polynomial one-step planner. Briggs <ref> [3] </ref> reduced the time complexity of computing a nondirectional backprojection to O (n 2 log n). Fox and Hutchinson [19] extended the algorithm to exploit visual constraints and allow visual compliant motions. However, even when nondirectional backprojections are used, one last difficulty to construct a multi-step planner is backchaining.
Reference: [4] <author> Brooks, R.A., </author> <title> Symbolic Error Analysis and Robot Planning, </title> <journal> Int. J. of Robotics Research, </journal> <volume> 1(4) </volume> <pages> 29-68, </pages> <year> 1982. </year>
Reference-contexts: Two main application domains have been considered: part mating for mechanical assembly and mobile robot navigation. Various approaches have been proposed, which are applicable to one domain, or the other, or both. They include skeleton refinement <ref> [31, 39, 4, 36] </ref>, inductive learning from experiments [15], iterative removal of contacts [25, 10, 22], and preimage backchaining [32, 34, 16].
Reference: [5] <author> Buckley, S.J., </author> <title> Planning and Teaching Compliant Motion Strategies, </title> <type> Ph.D. Dissertation, </type> <institution> Dept. of Electrical Engineering and Computer Science, MIT, </institution> <address> Cam-bridge, MA, </address> <year> 1986. </year>
Reference-contexts: Similar notions have been previously introduced in the literature with different names, e.g., landmarks [30], atomic regions <ref> [5] </ref>, signature neighborhoods [33], perceptual equivalent classes [13], sensory uncertainty field [38], and visual constraints [21, 19]. Our landmarks are mainly aimed at simplifying the selection of the set of states that the robot may traverse and the synthesis of the state-recognition functions. <p> This set is called the forward projection of the motion command <ref> [5, 7, 12] </ref>. A slight variation of the algorithm computing backprojections can be used to compute forward projections.) Fig. 10 shows an example with a single goal-extension disk in white, an intermediate-goal disk in grey, and an unexpected obstacle in black.
Reference: [6] <author> Canny, J.F. and Reif, J.H., </author> <title> New Lower-Bound Techniques for Robot Motion Planning Problems, </title> <booktitle> Proc. of the 28th SYMP. on the FOCS, </booktitle> <address> Los Angeles, CA, 49-60, </address> <year> 1987. </year>
Reference-contexts: In fact, it has been shown that these motion planners attack problems which are inherently intractable <ref> [6] </ref>. In our planner, like in previous planners, soundness and completeness are proven under the assumption that all errors are restricted to lie within bounded uncertainty intervals. <p> Such a decision takes double exponential time in r. Moreover, the smallest r for which a plan may exist grows with the complexity of the environment. Actually, various forms of the above motion planning problem have been proven intrinsically hard <ref> [6, 35, 7] </ref>.
Reference: [7] <author> Canny, J.F., </author> <title> On Computability of Fine Motion Plans, </title> <booktitle> Proc. of the IEEE Int. Conf. on Robotics and Automation, </booktitle> <address> Scottsdale, AZ, 177-182, </address> <year> 1989. </year>
Reference-contexts: Furthermore, most known sound and complete planning algorithms take exponential time in some measure of the size of the input problem (typically, the complexity of the robot's environment) <ref> [7, 12] </ref>, which makes them virtually inapplicable. In fact, it has been shown that these motion planners attack problems which are inherently intractable [6]. In our planner, like in previous planners, soundness and completeness are proven under the assumption that all errors are restricted to lie within bounded uncertainty intervals. <p> This region, which is precisely the preimage of the goal for that command, also depends on the termination condition. This recursive dependence was noted in [32]. Despite this difficulty, Canny <ref> [7] </ref> described a complete planner with very few restrictive assumptions in it. This planner generates an r-step plan by reducing the input problem to deciding the satisfiability of a semi-algebraic formula with 2r alternating existential and universal quantifiers. Such a decision takes double exponential time in r. <p> Such a decision takes double exponential time in r. Moreover, the smallest r for which a plan may exist grows with the complexity of the environment. Actually, various forms of the above motion planning problem have been proven intrinsically hard <ref> [6, 35, 7] </ref>. <p> This set is called the forward projection of the motion command <ref> [5, 7, 12] </ref>. A slight variation of the algorithm computing backprojections can be used to compute forward projections.) Fig. 10 shows an example with a single goal-extension disk in white, an intermediate-goal disk in grey, and an unexpected obstacle in black.
Reference: [8] <author> Chapman, D. and Agre, P.E., </author> <title> Abstract Reasoning as Emergent from Concrete Activity, Reasoning about Actions and Plans, edited by Georgeff, M.P. </title> <editor> and Lansky, A.L, </editor> <publisher> Morgan Kaufmann Publishers, </publisher> <address> Los Altos, CA, 411-424, </address> <year> 1986. </year>
Reference-contexts: Each rule is attached to some region of the robot configuration space and specifies the motion command to be executed if this region is attained. Such a plan is reminiscent of a reaction plan as proposed in <ref> [8, 14, 37] </ref>. Creating landmarks requires some prior engineering of the robot and/or its environment. <p> However, it may be preferable to use more sophisticated probabilistic distributions at execution time to better use all sources of information then available. Reaction plans have been previously proposed as a way to deal with uncertainty at planning time <ref> [37, 8, 14] </ref>. Such plans consist of goal-oriented rules triggered by the data available at execution time. In particular, Schoppers [37] developed the notion of a universal plan whose rules cover all possible situations that may occur at execution time. The plans generated by our planner are very similar.
Reference: [9] <author> Crowley, J.L., </author> <title> World Modeling and Position Estimation for a Mobile Robot Using Ultrasonic Ranging, </title> <booktitle> Proc. of the IEEE Int. Conf. on Robotics and Automation, </booktitle> <address> Scottsdale, AZ, 674-680, </address> <year> 1989. </year>
Reference-contexts: Over the past decade, there has also been a substantial amount of work at reducing uncertainty (mainly position uncertainty) while a robot is moving. For example, for mobile robots, many techniques have been proposed to combine the estimates provided by both dead-reckoning and environmental sensing (e.g., see <ref> [1, 9, 29, 40] </ref>). These techniques address the problem of tracking a selected motion plan as well as possible, not the problem of generating this plan.
Reference: [10] <author> Dakin, G.A. and Popplestone, </author> <title> R.J., Augmenting a Nominal Assembly Motion Plan with a Compliant Behavior. </title> <booktitle> Proc. of the 9th Nat. Conf. on Artificial Intelligence, </booktitle> <address> Anaheim, CA, 653-658, </address> <month> July </month> <year> 1991. </year>
Reference-contexts: Two main application domains have been considered: part mating for mechanical assembly and mobile robot navigation. Various approaches have been proposed, which are applicable to one domain, or the other, or both. They include skeleton refinement [31, 39, 4, 36], inductive learning from experiments [15], iterative removal of contacts <ref> [25, 10, 22] </ref>, and preimage backchaining [32, 34, 16]. Skeleton refinement, inductive learning, and iterative removal of contacts essentially operate in two phases: a motion plan is first generated assuming no uncertainty and then transformed to deal with uncertainty.
Reference: [11] <author> Donald, B.R., </author> <title> A Geometric Approach to Error Detection and Recovery for Robot Motion Planning with Uncertainty, </title> <journal> Artificial Intelligence J., </journal> <volume> 52(1-3):223-271, </volume> <year> 1988. </year>
Reference-contexts: For example, one may introduce time and consider uncertainty in the robot velocity, allowing the construction of more sophisticated termination conditions [34, 16]. The workspace model (e.g., the location and the shape of the obstacles) may also be subject to errors, yielding 5 a third type of uncertainty <ref> [11] </ref>. For the sake of simplicity we will not discuss these variants here (see [23]). <p> However, a given planning problem may admit no such plans, while it could have admitted one if uncertainty had been set slightly smaller. Furthermore, when correct plans exist, they may be overly complex. To deal with this drawback, Donald <ref> [11] </ref> proposed the notion of an Error Detection and Recovery Strategy, defined as an r-step plan (r &gt; 1) that attains the goal whenever it is recognizably reachable and signals failure whenever chances that it serendipitously achieve the goal vanish. <p> Indeed, a non-correct motion may miss all the disks in its termination set and continue for ever. Introducing some awareness of time is one way to address this drawback. Another approach, inspired by Donald's EDR strategies <ref> [11] </ref>, is to make sure that every non-correct imperfect-control motion command inserted in the plan will either succeed or fail recognizably.
Reference: [12] <author> Donald, B.R., </author> <title> The Complexity of Planar Compliant Motion Planning Under Uncertainty, </title> <journal> Algorithmica, </journal> <volume> 5 </volume> <pages> 353-382, </pages> <year> 1990. </year>
Reference-contexts: Furthermore, most known sound and complete planning algorithms take exponential time in some measure of the size of the input problem (typically, the complexity of the robot's environment) <ref> [7, 12] </ref>, which makes them virtually inapplicable. In fact, it has been shown that these motion planners attack problems which are inherently intractable [6]. In our planner, like in previous planners, soundness and completeness are proven under the assumption that all errors are restricted to lie within bounded uncertainty intervals. <p> The continuous set of backprojections of a region R for all possible directions of motion is called the nondirectional backprojection of R. In the plane (i.e., for a point robot moving in the plane), Donald <ref> [12] </ref> showed that, as far as planning is concerned, this set is sufficiently described by a polynomial number 6 of (directional) backprojections. These backprojections are computed at critical directions of motion where the topology of the backprojection's boundary changes. <p> This set is called the forward projection of the motion command <ref> [5, 7, 12] </ref>. A slight variation of the algorithm computing backprojections can be used to compute forward projections.) Fig. 10 shows an example with a single goal-extension disk in white, an intermediate-goal disk in grey, and an unexpected obstacle in black.
Reference: [13] <author> Donald, B.R. and Jennings, J., </author> <title> Constructive Recognizability for Task-Directed Robot Programming, </title> <journal> J. of Robotics and Autonomous Systems, </journal> <volume> 9 </volume> <pages> 41-74, </pages> <year> 1992. </year> <month> 35 </month>
Reference-contexts: Similar notions have been previously introduced in the literature with different names, e.g., landmarks [30], atomic regions [5], signature neighborhoods [33], perceptual equivalent classes <ref> [13] </ref>, sensory uncertainty field [38], and visual constraints [21, 19]. Our landmarks are mainly aimed at simplifying the selection of the set of states that the robot may traverse and the synthesis of the state-recognition functions. Instead, research like the one described in [13] is aimed at automating state selection and <p> [5], signature neighborhoods [33], perceptual equivalent classes <ref> [13] </ref>, sensory uncertainty field [38], and visual constraints [21, 19]. Our landmarks are mainly aimed at simplifying the selection of the set of states that the robot may traverse and the synthesis of the state-recognition functions. Instead, research like the one described in [13] is aimed at automating state selection and state recognition. Although it has great potential in reducing the engineering cost and the limitations associated with our landmarks, it is not clear as yet whether it can yield time-efficient planners.
Reference: [14] <author> Drummond, M., </author> <title> Situated Control Rules, </title> <booktitle> Proc. of the First Int. Conf. on Prin--ciples of Knowledge Representation and Reasoning, </booktitle> <publisher> Morgan Kaufmann Publishers, </publisher> <address> Los Altos, CA, 103-113, </address> <year> 1989. </year>
Reference-contexts: Each rule is attached to some region of the robot configuration space and specifies the motion command to be executed if this region is attained. Such a plan is reminiscent of a reaction plan as proposed in <ref> [8, 14, 37] </ref>. Creating landmarks requires some prior engineering of the robot and/or its environment. <p> However, it may be preferable to use more sophisticated probabilistic distributions at execution time to better use all sources of information then available. Reaction plans have been previously proposed as a way to deal with uncertainty at planning time <ref> [37, 8, 14] </ref>. Such plans consist of goal-oriented rules triggered by the data available at execution time. In particular, Schoppers [37] developed the notion of a universal plan whose rules cover all possible situations that may occur at execution time. The plans generated by our planner are very similar.
Reference: [15] <author> Dufay, B. and Latombe, </author> <title> J.C., An Approach to Automatic Robot Programming Based on Inductive Learning, </title> <journal> Int. J. of Robotics Research, </journal> <volume> 3(4) </volume> <pages> 3-20, </pages> <year> 1984. </year>
Reference-contexts: Two main application domains have been considered: part mating for mechanical assembly and mobile robot navigation. Various approaches have been proposed, which are applicable to one domain, or the other, or both. They include skeleton refinement [31, 39, 4, 36], inductive learning from experiments <ref> [15] </ref>, iterative removal of contacts [25, 10, 22], and preimage backchaining [32, 34, 16]. Skeleton refinement, inductive learning, and iterative removal of contacts essentially operate in two phases: a motion plan is first generated assuming no uncertainty and then transformed to deal with uncertainty.
Reference: [16] <author> Erdmann, M., </author> <title> On Motion Planning with Uncertainty, </title> <type> Tech. Rep. 810, </type> <institution> AI Lab., MIT, </institution> <address> Cambridge, MA, </address> <year> 1984. </year>
Reference-contexts: Various approaches have been proposed, which are applicable to one domain, or the other, or both. They include skeleton refinement [31, 39, 4, 36], inductive learning from experiments [15], iterative removal of contacts [25, 10, 22], and preimage backchaining <ref> [32, 34, 16] </ref>. Skeleton refinement, inductive learning, and iterative removal of contacts essentially operate in two phases: a motion plan is first generated assuming no uncertainty and then transformed to deal with uncertainty. Instead, preimage backchaining takes uncertainty into account throughout the whole planning process. <p> A complete planner is one which returns a correct plan whenever one exists, and failure otherwise. The above problem formulation admits many variants. For example, one may introduce time and consider uncertainty in the robot velocity, allowing the construction of more sophisticated termination conditions <ref> [34, 16] </ref>. The workspace model (e.g., the location and the shape of the obstacles) may also be subject to errors, yielding 5 a third type of uncertainty [11]. For the sake of simplicity we will not discuss these variants here (see [23]). <p> Such a decision takes double exponential time in r. Moreover, the smallest r for which a plan may exist grows with the complexity of the environment. Actually, various forms of the above motion planning problem have been proven intrinsically hard [6, 35, 7]. At the expense of completeness, Erdmann <ref> [16] </ref> suggested that goal reachability and recognizability be treated separately by identifying a subset of the goal, called a kernel, such that when this subset is attained, goal achievement can be recognized (by TC) independently of the way it has been achieved.
Reference: [17] <author> Erdmann, M., </author> <title> Randomization in Robot Tasks, </title> <journal> Int. J. of Robotics Research, </journal> <volume> 11(5) </volume> <pages> 399-436, </pages> <year> 1992. </year>
Reference-contexts: To deal with this drawback, Donald [11] proposed the notion of an Error Detection and Recovery Strategy, defined as an r-step plan (r &gt; 1) that attains the goal whenever it is recognizably reachable and signals failure whenever chances that it serendipitously achieve the goal vanish. Erdmann <ref> [17] </ref> introduced randomized plans whose execution converges toward the goal with probability one. In this paper we propose a different approach which consists of allowing the directional uncertainty to vary over some interval. We propose computational tools to build planners that can select values of according to various optimization criteria.
Reference: [18] <author> Erdmann, M., </author> <title> Towards Task-Level Planning: Action-Based Sensor Design, </title> <type> Tech. Rep. </type> <institution> CMU-CS-92-116, Dept. of Computer Science, Carnegie Mellon Univ., </institution> <address> Pittsburgh, PA, </address> <month> February </month> <year> 1992. </year>
Reference-contexts: Thus, although the planner assumed perfect sensing in landmark regions, we can now create these areas by engineering the workspace in such a way that the sensors just provide the information that is needed by the plan (see <ref> [18] </ref> for a similar idea). Going further, the definition of a landmark region can even be modified without having to significantly change the planning techniques developed above.
Reference: [19] <author> Fox, A. and Hutchinson, S., </author> <title> Exploiting Visual Constraints in the Synthesis of Uncertainty-Tolerant Motion Plans, </title> <type> Tech. Rep. </type> <institution> UIUC-BI-AI-RCV-92-05, The University of Illinois at Urbana-Champaign, </institution> <month> October </month> <year> 1992. </year>
Reference-contexts: Briggs [3] reduced the time complexity of computing a nondirectional backprojection to O (n 2 log n). Fox and Hutchinson <ref> [19] </ref> extended the algorithm to exploit visual constraints and allow visual compliant motions. However, even when nondirectional backprojections are used, one last difficulty to construct a multi-step planner is backchaining. <p> Similar notions have been previously introduced in the literature with different names, e.g., landmarks [30], atomic regions [5], signature neighborhoods [33], perceptual equivalent classes [13], sensory uncertainty field [38], and visual constraints <ref> [21, 19] </ref>. Our landmarks are mainly aimed at simplifying the selection of the set of states that the robot may traverse and the synthesis of the state-recognition functions. Instead, research like the one described in [13] is aimed at automating state selection and state recognition.
Reference: [20] <author> Friedman, J., </author> <title> Computational Aspects of Compliant Motion Planning, </title> <type> Ph.D. Dissertation, Report No. </type> <institution> STAN-CS-91-1368, Dept. of Computer Science, Stanford University, Stanford, </institution> <address> CA, </address> <year> 1991. </year>
Reference-contexts: We show that backchaining is then reduced to iteratively computing a relatively small set of (directional) backprojections for a growing set of landmark regions. This result directly yields a complete planning algorithm that takes polynomial time in the complexity of the landmark and obstacle regions. Previously, Friedman <ref> [20] </ref> had proposed another polynomial multi-step planner for a compliant point robot in a polygonal workspace by assuming that sensing exactly detects when the robot traverses line segments joining vertices of the workspace.
Reference: [21] <author> Hutchinson, S., </author> <title> Exploiting Visual Constraints in Robot Motion Planning, </title> <booktitle> Proc. of the IEEE Int. Conf. of Robotics and Automation, </booktitle> <address> Sacramento, CA, 1722-1727, </address> <year> 1991. </year>
Reference-contexts: Similar notions have been previously introduced in the literature with different names, e.g., landmarks [30], atomic regions [5], signature neighborhoods [33], perceptual equivalent classes [13], sensory uncertainty field [38], and visual constraints <ref> [21, 19] </ref>. Our landmarks are mainly aimed at simplifying the selection of the set of states that the robot may traverse and the synthesis of the state-recognition functions. Instead, research like the one described in [13] is aimed at automating state selection and state recognition.
Reference: [22] <author> Gottschlich, </author> <title> S.N. and Kak, A.C., Dealing with Uncertainty in CAD-Based Assembly Motion Planning, </title> <booktitle> Proc. of the 9th Nat. Conf. on Artificial Intelligence, </booktitle> <address> Anaheim, CA, 646-652, </address> <month> July </month> <year> 1991. </year>
Reference-contexts: Two main application domains have been considered: part mating for mechanical assembly and mobile robot navigation. Various approaches have been proposed, which are applicable to one domain, or the other, or both. They include skeleton refinement [31, 39, 4, 36], inductive learning from experiments [15], iterative removal of contacts <ref> [25, 10, 22] </ref>, and preimage backchaining [32, 34, 16]. Skeleton refinement, inductive learning, and iterative removal of contacts essentially operate in two phases: a motion plan is first generated assuming no uncertainty and then transformed to deal with uncertainty.
Reference: [23] <author> Latombe, </author> <title> J.C., Robot Motion Planning, </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, MA, </address> <year> 1991. </year>
Reference-contexts: This is the case, for example, in mechanical part-mating tasks, where both errors and tolerances are usually small, and mobile robot navigation tasks, where both errors and tolerances may be large. For such tasks, classical path planning methods <ref> [23] </ref>, which use simple geometric models while assuming null uncertainty, are clearly insufficient. At best, they produce paths that require frequent replanning to deal with discrepancies detected by sensors during execution. <p> The workspace model (e.g., the location and the shape of the obstacles) may also be subject to errors, yielding 5 a third type of uncertainty [11]. For the sake of simplicity we will not discuss these variants here (see <ref> [23] </ref>).
Reference: [24] <author> Latombe, J.C., Lazanas, A., and Shekhar, S., </author> <title> Robot Motion Planning with Uncertainty in Control and Sensing, </title> <journal> Artificial Intelligence J. </journal> <volume> 52(1) </volume> <pages> 1-47, </pages> <year> 1991. </year>
Reference-contexts: He proposed an O (n log n) algorithm to compute backprojections in the plane when the obstacles are polygons bounded by n edges. An implemented planner based on this approach is described in <ref> [24] </ref>. Once the kernel of a goal has been identified, a remaining issue is the selection of the commanded direction of motion to attain this kernel, since the backprojection of the kernel depends on this direction. The planner described in [24] only considers a finite number of regularly spaced directions; hence, <p> An implemented planner based on this approach is described in <ref> [24] </ref>. Once the kernel of a goal has been identified, a remaining issue is the selection of the commanded direction of motion to attain this kernel, since the backprojection of the kernel depends on this direction. The planner described in [24] only considers a finite number of regularly spaced directions; hence, it is incomplete, and usually not very efficient. The continuous set of backprojections of a region R for all possible directions of motion is called the nondirectional backprojection of R.
Reference: [25] <author> Laugier, C. and Theveneau, P., </author> <title> Planning Sensor-Based Motions for Part-Mating Using Geometric Reasoning Techniques, </title> <booktitle> Proc. of European Conf. on Artificial Intelligence, </booktitle> <address> Brighton, UK, </address> <year> 1986. </year>
Reference-contexts: Two main application domains have been considered: part mating for mechanical assembly and mobile robot navigation. Various approaches have been proposed, which are applicable to one domain, or the other, or both. They include skeleton refinement [31, 39, 4, 36], inductive learning from experiments [15], iterative removal of contacts <ref> [25, 10, 22] </ref>, and preimage backchaining [32, 34, 16]. Skeleton refinement, inductive learning, and iterative removal of contacts essentially operate in two phases: a motion plan is first generated assuming no uncertainty and then transformed to deal with uncertainty.
Reference: [26] <author> Lazanas, A. and Latombe, </author> <title> J.C., Landmark-Based Robot Navigation, </title> <booktitle> Proc. of the 10th Nat. Conf. on Artificial Intelligence, </booktitle> <address> San Jose, 697-702, </address> <month> July </month> <year> 1992. </year>
Reference-contexts: The difficulty comes from the fact that backchaining introduces a twofold variation: when the commanded direction of motion varies, both the backprojection of the current kernel and the kernel of this backprojection (which will be used at the next backchaining iteration) vary. In this paper (as in <ref> [26, 27] </ref>) we deal with this difficulty by introducing landmarks. <p> By definition of the goal extension, the robot cannot move into it using the perfect-control mode. Given a goal G, we first compute its extension E (G). If the initial region I lies 2 In previous papers <ref> [26, 27] </ref>, we called this set the kernel of the goal.
Reference: [27] <author> Lazanas, A. and Latombe, </author> <title> J.C., Landmark-Based Robot Navigation, </title> <type> Tech. Rep. </type> <institution> STAN-CS-92-1428, Dept. of Computer Science, Stanford Univ., Stanford, CA, </institution> <note> 1992 (to appear in Algorithmica). 36 </note>
Reference-contexts: Section 12 discusses other extensions of the planner. This paper builds upon and extends previous work presented in <ref> [27] </ref>. There is some limited overlap between the two publications, so that the current paper is self-contained. 4 2 Background Motion planning with uncertainty has been a research topic in robotics for almost two decades. <p> The difficulty comes from the fact that backchaining introduces a twofold variation: when the commanded direction of motion varies, both the backprojection of the current kernel and the kernel of this backprojection (which will be used at the next backchaining iteration) vary. In this paper (as in <ref> [26, 27] </ref>) we deal with this difficulty by introducing landmarks. <p> By definition of the goal extension, the robot cannot move into it using the perfect-control mode. Given a goal G, we first compute its extension E (G). If the initial region I lies 2 In previous papers <ref> [26, 27] </ref>, we called this set the kernel of the goal. <p> The latter are supported by rays erected from landmark and obstacle disks. These rays are tangent to the disks and parallel to the directions d . Two intersecting rays form a spike. The backprojection of Fig. 3 has two spikes. (See <ref> [27] </ref> for a more detailed description of a backprojection.) The boundary of the backprojection consists of O (`) arcs and edges. A one-step plan may not exist, or may not be desirable, if its cost is too high. Then the planner can attempt to create a multi-step plan iteratively. <p> Let s 2 O (`) be the number of landmark regions; the number of iterations performed by the planner is bounded by s. The computation of every backprojection can be done in time O (` log `) using a traditional sweep-line algorithm given in <ref> [27] </ref>. Determining which initial-position disks are contained in the backprojection and which intermediate-goal disks are intersected by it is done while the backprojection is being computed, within the same asymptotic time complexity. <p> For the sake of simplicity, we will not describe this simple extension here. 17 6 Planning with Constant Directional Uncertainty Let us first consider the case where the directional uncertainty is fixed to some given value f . We previously considered this case in <ref> [27] </ref>. In the d-plane the line = f intersects the critical curves at O (` 3 ) points (critical commanded directions of motion), which partition the set S 1 of values of d into O (` 3 ) cells of dimensions 1 and 0 (open intervals and points). <p> However, it may be preferable to keep several exit points among which the robot can choose at execution time in order to minimize the length of the paths performed in the perfect-control mode in the landmark regions <ref> [27] </ref>. Several executions of the same plan may lead the robot to perform different sequences of commands, since control errors (in the interval [0; f ]) may yield the same command to terminate in one landmark region or another (in the termination set of the command). <p> One can easily imagine variants based on other search strategies. However, not all strategies yield optimal plans. The time complexity of the planner, O (s` 4 log `), is one order of magnitude greater than the complexity of a similar planner described in <ref> [27] </ref>. The difference comes from the fact that the above planner recomputes a backprojection from scratch in every cell of the decomposition of S 1 . Instead, the planner of [27] computes a first backprojection and incrementally modifies this backprojection as it scans the cells in S 1 . <p> O (s` 4 log `), is one order of magnitude greater than the complexity of a similar planner described in <ref> [27] </ref>. The difference comes from the fact that the above planner recomputes a backprojection from scratch in every cell of the decomposition of S 1 . Instead, the planner of [27] computes a first backprojection and incrementally modifies this backprojection as it scans the cells in S 1 . However, this requires tracking all the changes in the backprojection topology, yielding 33 different types of events that include the 11 types listed in Section 5. <p> There are significant practical advantages in having less events to consider. In 19 particular, the above algorithm is simpler to implement than the one of <ref> [27] </ref>. Because it recomputes backprojections from scratch in every cell, it is also less sensitive to floating-point computation errors. 7 One-Step Planning with Controlled Uncertainty Now let the directional uncertainty be controllable by the robot within the given interval [ min ; max ]. <p> For example, the restriction of landmark and obstacle regions to being unions of disks could easily be removed to allow these areas to be described as generalized polygons 5 Actually, this time was obtained with the planner described in <ref> [27] </ref> and mentioned in Section 6. 23 (regions bounded by simple closed curves made of straight and circular edges). This extension only requires a straightforward adaptation in the construction of the critical curves.
Reference: [28] <author> Lazanas, A., </author> <title> Motion Planning with Uncertainty: A Landmark Approach, </title> <type> Ph.D. Dissertation, Tech. Rep., </type> <institution> Dept. of Computer Science, Stanford Univ., Stanford, CA, </institution> <note> 1994 (in preparation). </note>
Reference-contexts: The equation of the curve of an L-Spike event is significantly more complicated. However, we can show that it is of the form: = f spike (d); where f spike has a single maximum and at most one intersection with any line of slope 1 (see <ref> [28] </ref> for a proof of these claims). We call f spike a spike curve. <p> Fig. 2 shows a motion command generated by the above algorithm. 4 O-events serve only to indicate the limits of existence of a spike. For more details see <ref> [28] </ref>. 20 8 Multi-Step Planning with Controlled Uncertainty To generate a multi-step plan, we can use the following greedy algorithm: At every iteration, sweep a line parallel to the d-axis in order to find the highest value of such that there exists a backprojection of the current goal extension which either <p> event curves among themselves, since these intersection points cannot give rise to the highest value of we are looking for. (Remember we only seek the first intermediate-goal disk to be intersected.) Furthermore, the algorithm must consider intersection points among event curves at most once over all iterations (see proof in <ref> [28] </ref>). Hence, the total complexity of the planner is O (s` 5 log `). The output plan has s steps at most. Fig. 6 illustrates the operation of this algorithm with an example. The workspace contains 7 landmark disks A through G, and 4 obstacles.
Reference: [29] <author> Leonard, J.J. and Durrant-Whyte, H.F., </author> <title> Mobile Robot Localization by Tracking Geometric Beacons, </title> <journal> IEEE Tr. on Robotics and Automation, </journal> <volume> 7(3), </volume> <pages> 376-382, </pages> <year> 1991. </year>
Reference-contexts: Over the past decade, there has also been a substantial amount of work at reducing uncertainty (mainly position uncertainty) while a robot is moving. For example, for mobile robots, many techniques have been proposed to combine the estimates provided by both dead-reckoning and environmental sensing (e.g., see <ref> [1, 9, 29, 40] </ref>). These techniques address the problem of tracking a selected motion plan as well as possible, not the problem of generating this plan.
Reference: [30] <author> Levitt, T.S., Lawton, D.T., Chelberg, D.M. and Nelson, </author> <title> P.C., Qualitative Navigation, </title> <booktitle> Proc. of DARPA Image Understanding Workshop, </booktitle> <address> Los Angeles, CA, 447-465, </address> <year> 1987. </year>
Reference-contexts: Our notion of a landmark corresponds approximately to a recognizable feature of the workspace that induces a field of influence (the landmark region); if the robot is in this field, it senses the landmark. Similar notions have been previously introduced in the literature with different names, e.g., landmarks <ref> [30] </ref>, atomic regions [5], signature neighborhoods [33], perceptual equivalent classes [13], sensory uncertainty field [38], and visual constraints [21, 19]. Our landmarks are mainly aimed at simplifying the selection of the set of states that the robot may traverse and the synthesis of the state-recognition functions.
Reference: [31] <author> Lozano-Perez, </author> <title> T.,The Design of a Mechanical Assembly System, </title> <type> Tech. Rep. </type> <institution> AI-TR 397, Artificial Intelligence Laboratory, MIT, </institution> <year> 1976. </year>
Reference-contexts: Two main application domains have been considered: part mating for mechanical assembly and mobile robot navigation. Various approaches have been proposed, which are applicable to one domain, or the other, or both. They include skeleton refinement <ref> [31, 39, 4, 36] </ref>, inductive learning from experiments [15], iterative removal of contacts [25, 10, 22], and preimage backchaining [32, 34, 16].
Reference: [32] <author> Lozano-Perez, T., Mason, </author> <title> M.T. and Taylor, R.H., Automatic Synthesis of Fine-Motion Strategies for Robots, </title> <journal> Int. J. of Robotics Research, </journal> <volume> 3(1) </volume> <pages> 3-24, </pages> <year> 1984. </year>
Reference-contexts: Various approaches have been proposed, which are applicable to one domain, or the other, or both. They include skeleton refinement [31, 39, 4, 36], inductive learning from experiments [15], iterative removal of contacts [25, 10, 22], and preimage backchaining <ref> [32, 34, 16] </ref>. Skeleton refinement, inductive learning, and iterative removal of contacts essentially operate in two phases: a motion plan is first generated assuming no uncertainty and then transformed to deal with uncertainty. Instead, preimage backchaining takes uncertainty into account throughout the whole planning process. <p> Our work is a direct continuation of a series of work on preimage backchaining. We focus most of our discussion on this series. Preimage backchaining considers the following class of motion planning problems <ref> [32] </ref>: A plan is a sequence (more generally, an algorithm) of motion commands, each defined by a commanded direction of motion d and a termination condition TC. <p> Goal recognition, hence the termination condition of a command, often depends on the region from where the command is executed. This region, which is precisely the preimage of the goal for that command, also depends on the termination condition. This recursive dependence was noted in <ref> [32] </ref>. Despite this difficulty, Canny [7] described a complete planner with very few restrictive assumptions in it. This planner generates an r-step plan by reducing the input problem to deciding the satisfiability of a semi-algebraic formula with 2r alternating existential and universal quantifiers.
Reference: [33] <author> Mahadevan, S. and Connell, J., </author> <title> Automatic Programming of Behavior-based Robots using Reinforcement Learning, </title> <type> Research Rep., </type> <institution> IBM T.J. Watson Research Center, </institution> <address> Yorktown Heights, NY, </address> <year> 1990. </year>
Reference-contexts: Similar notions have been previously introduced in the literature with different names, e.g., landmarks [30], atomic regions [5], signature neighborhoods <ref> [33] </ref>, perceptual equivalent classes [13], sensory uncertainty field [38], and visual constraints [21, 19]. Our landmarks are mainly aimed at simplifying the selection of the set of states that the robot may traverse and the synthesis of the state-recognition functions.
Reference: [34] <author> Mason, </author> <title> M.T., Automatic Planning of Fine Motions: Correctness and Completeness, </title> <booktitle> Proc. of the IEEE Int. Conf. on Robotics and Automation, </booktitle> <address> Atlanta, GA, 492-503, </address> <year> 1984. </year>
Reference-contexts: Various approaches have been proposed, which are applicable to one domain, or the other, or both. They include skeleton refinement [31, 39, 4, 36], inductive learning from experiments [15], iterative removal of contacts [25, 10, 22], and preimage backchaining <ref> [32, 34, 16] </ref>. Skeleton refinement, inductive learning, and iterative removal of contacts essentially operate in two phases: a motion plan is first generated assuming no uncertainty and then transformed to deal with uncertainty. Instead, preimage backchaining takes uncertainty into account throughout the whole planning process. <p> A complete planner is one which returns a correct plan whenever one exists, and failure otherwise. The above problem formulation admits many variants. For example, one may introduce time and consider uncertainty in the robot velocity, allowing the construction of more sophisticated termination conditions <ref> [34, 16] </ref>. The workspace model (e.g., the location and the shape of the obstacles) may also be subject to errors, yielding 5 a third type of uncertainty [11]. For the sake of simplicity we will not discuss these variants here (see [23]).
Reference: [35] <author> Natarajan, B.K., </author> <title> The Complexity of Fine Motion Planning, </title> <journal> Int. J. of Robotics Research, </journal> <volume> 7(2) </volume> <pages> 36-42, </pages> <year> 1988. </year>
Reference-contexts: Such a decision takes double exponential time in r. Moreover, the smallest r for which a plan may exist grows with the complexity of the environment. Actually, various forms of the above motion planning problem have been proven intrinsically hard <ref> [6, 35, 7] </ref>.
Reference: [36] <author> Pertin-Troccaz, J. and Puget, P., </author> <title> Dealing with Uncertainty in Robot Planning Using Program Proving Techniques, </title> <booktitle> Proc. of the 4th Int. Symp. on Robotics Research, </booktitle> <address> Santa-Cruz, CA, 455-466, </address> <year> 1987. </year>
Reference-contexts: Two main application domains have been considered: part mating for mechanical assembly and mobile robot navigation. Various approaches have been proposed, which are applicable to one domain, or the other, or both. They include skeleton refinement <ref> [31, 39, 4, 36] </ref>, inductive learning from experiments [15], iterative removal of contacts [25, 10, 22], and preimage backchaining [32, 34, 16].
Reference: [37] <author> Schoppers, M.J., </author> <title> Representation and Automatic Synthesis of Reaction Plans, </title> <type> Ph.D. Dissertation, </type> <institution> Dept. of Computer Science, University of Illinois at Urbana-Champaign, Urbana, IL, </institution> <year> 1989. </year>
Reference-contexts: Each rule is attached to some region of the robot configuration space and specifies the motion command to be executed if this region is attained. Such a plan is reminiscent of a reaction plan as proposed in <ref> [8, 14, 37] </ref>. Creating landmarks requires some prior engineering of the robot and/or its environment. <p> However, it may be preferable to use more sophisticated probabilistic distributions at execution time to better use all sources of information then available. Reaction plans have been previously proposed as a way to deal with uncertainty at planning time <ref> [37, 8, 14] </ref>. Such plans consist of goal-oriented rules triggered by the data available at execution time. In particular, Schoppers [37] developed the notion of a universal plan whose rules cover all possible situations that may occur at execution time. The plans generated by our planner are very similar. <p> Reaction plans have been previously proposed as a way to deal with uncertainty at planning time [37, 8, 14]. Such plans consist of goal-oriented rules triggered by the data available at execution time. In particular, Schoppers <ref> [37] </ref> developed the notion of a universal plan whose rules cover all possible situations that may occur at execution time. The plans generated by our planner are very similar. They consist of motion commands attached to regions of the robot's configuration space.
Reference: [38] <author> Takeda, H. and Latombe, </author> <title> J.C., Sensory Uncertainty Field for Mobile Robot Navigation, </title> <booktitle> Proc. of IEEE Int. Conf. on Robotics and Automation, Nice, </booktitle> <pages> 2465-2472, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: Similar notions have been previously introduced in the literature with different names, e.g., landmarks [30], atomic regions [5], signature neighborhoods [33], perceptual equivalent classes [13], sensory uncertainty field <ref> [38] </ref>, and visual constraints [21, 19]. Our landmarks are mainly aimed at simplifying the selection of the set of states that the robot may traverse and the synthesis of the state-recognition functions. Instead, research like the one described in [13] is aimed at automating state selection and state recognition. <p> For example, the notion of a "sensory uncertainty field" (suf) is introduced in <ref> [38] </ref>. At every possible point q in the configuration space, the suf estimates the range of possible errors in the sensed configuration that the navigation system would 24 compute by matching the sensory data against a prior model of the workspace, if the robot was at q.
Reference: [39] <author> Taylor, </author> <title> R.H., Synthesis of Manipulator Control Programs from Task-Level Specifications, </title> <type> Ph.D. Dissertation, </type> <institution> Dept. of Computer Science, Stanford University, </institution> <year> 1976. </year>
Reference-contexts: Two main application domains have been considered: part mating for mechanical assembly and mobile robot navigation. Various approaches have been proposed, which are applicable to one domain, or the other, or both. They include skeleton refinement <ref> [31, 39, 4, 36] </ref>, inductive learning from experiments [15], iterative removal of contacts [25, 10, 22], and preimage backchaining [32, 34, 16].
Reference: [40] <author> Zhang, Z. and Faugeras, O., </author> <title> A 3D World Model Builder with a Mobile Robot, </title> <journal> The Int. F. of Robotics Research, </journal> <volume> 11(4) </volume> <pages> 269-285, </pages> <year> 1992. </year> <month> 37 </month>
Reference-contexts: Over the past decade, there has also been a substantial amount of work at reducing uncertainty (mainly position uncertainty) while a robot is moving. For example, for mobile robots, many techniques have been proposed to combine the estimates provided by both dead-reckoning and environmental sensing (e.g., see <ref> [1, 9, 29, 40] </ref>). These techniques address the problem of tracking a selected motion plan as well as possible, not the problem of generating this plan.
References-found: 40

