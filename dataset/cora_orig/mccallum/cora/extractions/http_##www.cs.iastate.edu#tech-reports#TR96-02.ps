URL: http://www.cs.iastate.edu/tech-reports/TR96-02.ps
Refering-URL: http://www.cs.iastate.edu/tech-reports/catalog.html
Root-URL: http://www.cs.iastate.edu
Email: email: danwell@iastate.edu  
Title: An Arithmetic Test Suite for Genetic Programming  
Author: Dan Ashlock Jim Lathrop 
Address: Ames, IA, 50010,  
Affiliation: Mathematics Department Iowa State University,  
Date: April 2, 1996  
Abstract: In this paper we explore a number of ideas for enhancing the techniques of genetic programming in the context of a very simple test environment that nevertheless possesses some degree of algorithmic subtlety. We term this genetic programming environment plus-one-recall-store (PORS). This genetic programming environment is quite simple having only a pair of terminals and a pair of operations. The terminals are the number one and recall from an external memory. The operations are a unary store operation and binary addition, +, on natural numbers. In this paper we present the PORS environment, present a mathematical description of its properties, and then focus on testing the use of Markov chains in generating, crossing over, and mutating evolving programs. We obtain a surprising indication of the correct situations in which to use Markov chains during evolutionary program induction. y Computer Science Department, Iowa State University, Ames Iowa, 50010, email: jil@iastate.edu. This research was supported in part by National Science Foundation Grant CCR-9157382, with matching funds from Rockwell International, Microwave Systems Corporation, and the Amoco Foundation. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Peter J. Angeline and Jordan B. Pollack. </author> <title> Coevolving high-level representations. </title> <editor> In Christopher Langton, editor, </editor> <booktitle> Artificial Life III, volume 17 of Santa Fe Institute Studies in the Sciences of Complexity, </booktitle> <pages> pages 55-71, </pages> <address> Reading, 1994. </address> <publisher> Addison-Wesley. </publisher>
Reference-contexts: Whenever an operation associated with an ADF is called, the parse tree for the ADF is executed. 3 ADFs are only one possible subroutine-like structure for genetic program-ming. There is another such structure. In their paper on co-evolving high level representations Angeline and Pollack <ref> [1] </ref> define the process of module acquisition in which tree fragments which are used by many parse trees are transformed into new operations dynamically during evolution. The tree fragments are saved in a library and some effort is spent deciding when to remove modules from the library. <p> They take whatever value is computed in the parse tree T and multiply it by two and three respectively. These macros are the same as the modules discussed in Angeline and Pollack's work on coevolving high level representations <ref> [1] </ref>, but we do not dynamically acquire them during the process of evolution.
Reference: [2] <editor> Kenneth Kinnear. </editor> <booktitle> Advances in Genetic Programming. </booktitle> <publisher> The MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1994. </year>
Reference-contexts: We are using standard analogs to sex and mutation of the sort described in Koza's foundational text for genetic programming [3]. Readers interested in additional discussion and examples of genetic programming should consult <ref> [2] </ref>. 1.2 The Test Environment Although the PORS test environment has very few operations and terminals, it contains both easy and hard problems for use in testing the performance of genetic programming environments. The language has two terminals, the number 1 and a recall command.
Reference: [3] <editor> John R. Koza. </editor> <booktitle> Genetic Programming. </booktitle> <publisher> The MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1992. </year>
Reference-contexts: The details of the genetic programming system we will use are contained in the experimental descriptions later in the paper. We are using standard analogs to sex and mutation of the sort described in Koza's foundational text for genetic programming <ref> [3] </ref>. Readers interested in additional discussion and examples of genetic programming should consult [2]. 1.2 The Test Environment Although the PORS test environment has very few operations and terminals, it contains both easy and hard problems for use in testing the performance of genetic programming environments.
Reference: [4] <author> Craig Reynolds. </author> <title> An evolved, vision-based behavioral model of coordinated group motion. </title> <editor> In Jean-Arcady Meyer, Herbert L. Roiblat, and 27 Stewart Wilson, editors, </editor> <booktitle> From Animals to Animats 2, </booktitle> <pages> pages 384-392. </pages> <publisher> MIT Press, </publisher> <year> 1992. </year>
Reference-contexts: This is a strongly eleitist mating scheme. Steady state genetic algorithms are described very well by Reynolds <ref> [4] </ref> and were discovered independently by Syswerda [5] and Whitley [7]. We decided to use the steady state algorithm because we are measuring success by computing evolutionary time until a correct answer appears in our population.
Reference: [5] <author> Gilbert Syswerda. </author> <title> A study of reproduction in generational and steady state genetic algorithms. </title> <booktitle> In Foundations of Genetic Algorithms, </booktitle> <pages> pages 94-101. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1991. </year>
Reference-contexts: This is a strongly eleitist mating scheme. Steady state genetic algorithms are described very well by Reynolds [4] and were discovered independently by Syswerda <ref> [5] </ref> and Whitley [7]. We decided to use the steady state algorithm because we are measuring success by computing evolutionary time until a correct answer appears in our population. A steady state algorithm gives much finer time resolution than a standard genetic algorithm with discrete, simultaneous generations.
Reference: [6] <author> Astro Teller. </author> <title> The evolution of mental models. </title> <editor> In Kenneth Kinnear, editor, </editor> <booktitle> Advances in Genetic Programming, chapter 9. </booktitle> <publisher> The MIT Press, </publisher> <year> 1994. </year>
Reference-contexts: Thus far in genetic algorithms people have tried to enhance their original population and mutation operators by choosing something other than a uniform distribution on the nodes that make up their random parse trees. An example of this appears in Teller's experiment with evolved controllers for virtual bulldozers <ref> [6] </ref>. The bias in the probability of selection of various program nodes can be viewed as containing some knowledge Teller had about the problem he was trying to solve. 12 Using Markov chains extends this idea.
Reference: [7] <author> Darrel Whitley. </author> <title> The genitor algorithm and selection pressure: why rank based allocation of reproductive trials is best. </title> <booktitle> In Proceedings of the 3rd ICGA, </booktitle> <pages> pages 116-121. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1989. </year> <month> 28 </month>
Reference-contexts: This is a strongly eleitist mating scheme. Steady state genetic algorithms are described very well by Reynolds [4] and were discovered independently by Syswerda [5] and Whitley <ref> [7] </ref>. We decided to use the steady state algorithm because we are measuring success by computing evolutionary time until a correct answer appears in our population. A steady state algorithm gives much finer time resolution than a standard genetic algorithm with discrete, simultaneous generations.
References-found: 7

