URL: ftp://ftp.cs.orst.edu/pub/tgd/papers/biome-nn.ps.gz
Refering-URL: http://www.cs.orst.edu/~tgd/cv/pubs.html
Root-URL: 
Email: chown@cs.orst.edu  tgd@cs.orst.edu  
Title: A comparison of neural network and process-based models for vegetation distribution under global climate change  
Author: Eric Chown Thomas G. Dietterich 
Date: November 14, 1997  
Address: Corvallis, OR 97331-3202  
Affiliation: Department of Computer Science Oregon State University  
Abstract: Ecological models based on physical, chemical, and biological processes are difficult to develop and calibrate. Neural network methods provide an attractive alternative where the model is constructed automatically. We compared the MAPSS global vegetation model to a collection of neural network models trained on a data set covering current climate and vegetation distribution in the coterminous United States. Completely automated methods were employed to calibrate MAPSS and to train the neural networks. The models were then compared on two tasks: prediction of current vegetation distribution given current climate and prediction of future vegetation distribution given future 2fiCO 2 climates produced by the OSU, GFDL, and UKMO global climate models. For predicting under current climate, the neural network models are more accurate than MAPSS. Unfortunately, the predictive accuracy of the models under future climate models cannot be measured without knowing future vegetation distribution. However, an upper bound on the accuracy can be computed using a statistic called the classification scatter. On future climate scenarios, the neural network models exhibit much higher classification scatter than MAPSS, which means that the highest accuracy that they could achieve is substantially less than the highest potential accuracy of MAPSS. This suggests|but does not prove|that process-based models such as MAPSS will make better predictions than neural network models for future climate scenarios. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Barnard, E., & Cole, R. A. </author> <year> (1989). </year> <title> A neural-net training program based on conjugate-gradient optimization. </title> <type> Tech. rep. CSE 89-014, </type> <institution> Oregon Graduate Institute, Beaverton, </institution> <address> OR. </address>
Reference: <author> Caruana, R. </author> <year> (1997). </year> <title> Multitask Learning. </title> <type> Ph.D. thesis, </type> <institution> Carnegie Mellon University, </institution> <address> Pittsburgh, PA. </address>
Reference: <author> Dietterich, T. G., Hild, H., & Bakiri, G. </author> <year> (1995). </year> <title> A comparison of ID3 and backpropagation for English text-to-speech mapping. </title> <journal> Machine Learning, </journal> <volume> 18, </volume> <pages> 51-80. </pages>
Reference-contexts: Whenever a highly flexible function approximator, such as a neural network, is applied to fit data, there is a danger of overfitting|that is, of memorizing the training data and failing to generalize well to new data points. Results of several studies, including our own work <ref> (Dietterich, Hild, & Bakiri, 1995) </ref> and the very thorough work of Caruana (1997) have shown that the best predictive accuracy for this form of neural network is obtained by using a large number of hidden units combined with the technique known as early stopping (Lang, Hinton, & Waibel, 1990).
Reference: <author> Duan, Q., Sorooshian, S., & Gupta, V. </author> <year> (1992). </year> <title> Effective and efficient global optimization of conceptual rainfall-runoff models. </title> <journal> Water Resources Research, </journal> <volume> 28 (4), </volume> <pages> 1015-1031. </pages>
Reference: <author> Efron, B., & Tibshirani, R. J. </author> <year> (1993). </year> <title> An Introduction to the Bootstrap. </title> <publisher> Chapman and Hall, </publisher> <address> New York, NY. </address>
Reference-contexts: Method % Correct Predictions Neural Network 68.35 MAPSS 61.75 Of course we can't repeat the experiment of gathering multiple data sets and training on each of them. However, we can simulate this process through a technique known as "bootstrapping" <ref> (Efron & Tibshirani, 1993) </ref>. The idea is to generate a series of "bootstrap replicate data sets" from our initial data set. If the given data set contains n data points, we generate a boostrap replicate data set by drawing n points randomly with replacement from the given data set.
Reference: <author> Gupta, V. K., & Sorooshian, S. </author> <year> (1985). </year> <title> The automatic calibration of conceptual catchment models using derivative-based optimization algorithms. </title> <journal> Water Resources Research, </journal> <volume> 21 (4), </volume> <pages> 473-485. </pages>
Reference: <author> Hsu, K., Gupta, H. V., & Sorooshian, S. </author> <year> (1995). </year> <title> Artificial neural network modeling of the rainfall-runoff process. </title> <journal> Water Resources Research, </journal> <volume> 31, </volume> <pages> 2517-2530. </pages>
Reference: <author> Klepper, O., & Hendrix, E. M. T. </author> <year> (1994). </year> <title> A method for robust calibration of ecological models under different types of uncertainty. </title> <journal> Ecological Modelling, </journal> <volume> 74, </volume> <pages> 161-182. </pages>
Reference: <author> Lang, K. J., Hinton, G. E., & Waibel, A. </author> <year> (1990). </year> <title> A time-delay neural network architecture for isolated word recognition. </title> <booktitle> Neural Networks, </booktitle> <volume> 3 (1), </volume> <pages> 23-43. </pages>
Reference-contexts: several studies, including our own work (Dietterich, Hild, & Bakiri, 1995) and the very thorough work of Caruana (1997) have shown that the best predictive accuracy for this form of neural network is obtained by using a large number of hidden units combined with the technique known as early stopping <ref> (Lang, Hinton, & Waibel, 1990) </ref>. Early stopping works as follows. Suppose we have a total of N data points available for training the neural network. We randomly set aside a subset of N h of these points to form the halting set.
Reference: <author> Michell, J. F. B., & Warrilow, D. A. </author> <year> (1987). </year> <title> Summer dryness in northern mid latitudes due to increased CO2. </title> <journal> Nature, </journal> <volume> 330, </volume> <pages> 238-240. </pages>
Reference: <author> Neilson, R. P. </author> <year> (1995). </year> <title> A model for predicting continental-scale vegetation distribution and water balance. </title> <journal> Ecological Applications, </journal> <volume> 5, </volume> <pages> 362-385. </pages> <note> 9 Press, </note> <author> W. H., Teukolsky, S. A., Vetterling, W. T., & Flannery, B. P. </author> <year> (1992). </year> <title> Numerical Recipes in C (2d edition). </title> <address> Cambridge:New York, NY. </address>
Reference-contexts: Process models attempt to model the physical, chemical, and biological processes underlying ecological phenemena. Examples of such models include the global circulation models (Michell & Warrilow, 1987; Wetherald & Manabe, 1988; Schlesinger & Zhao, 1989) and global vegetation models <ref> (Neilson, 1995) </ref>. The construction of these models is difficult and time-consuming. The modeler must have expertise in many scientific fields. <p> These vegetation classes were based on the vegetation classes produced by an earlier hand-calibrated version of MAPSS that was run on a high-resolution climate data set where each cell was 10km square <ref> (Neilson, 1995) </ref>. It might seem that this would give MAPSS an unfair advantage, because it appears to guarantee that the target vegetation classes can be produced by MAPSS.
Reference: <author> Schlesinger, M. E., & Zhao, Z. C. </author> <year> (1989). </year> <title> Seasonal climatic change introduced by double CO2 as simulated by the OSU attomospheric GCM/mixed-layer ocean model. </title> <journal> Journal of Climatology, </journal> <volume> 2, </volume> <pages> 429-495. </pages>
Reference: <author> Tan, S. S., & Smeins, F. E. </author> <year> (1996). </year> <title> Predicting grassland community changes with an artificial neural network model. </title> <journal> Ecological Modelling, </journal> <volume> 84, </volume> <pages> 91-97. </pages> <month> VEMAP-Members </month> <year> (1995). </year> <title> Vegetation/ecosystem modeling and analysis project: Comparing biogeography and biogeochemistry models in a continental-scale study of terrestrial ecosystem responses to climate change and co2 doubling. Global Biogeochemical Cycles, </title> <type> 9. </type>
Reference: <author> Wetherald, R. T., & Manabe, S. </author> <year> (1988). </year> <title> Cloud feedback processes in a general circulation model. </title> <journal> Journal of Atmospheric Science, </journal> <volume> 45, </volume> <month> 1397-1415. </month> <title> 10 MAPSS runs (bottom). Note that the areas of agreement are much more sparse for the neural network runs. </title> <type> 11 </type>
References-found: 14

