URL: ftp://ftp.cs.rochester.edu/pub/u/rao/papers/iccv95.ps.Z
Refering-URL: http://www.cs.rochester.edu/u/rao/papers.html
Root-URL: 
Email: frao,danag@cs.rochester.edu  
Title: Object Indexing using an Iconic Sparse Distributed Memory  
Author: Rajesh P.N. Rao and Dana H. Ballard 
Address: Rochester, NY 14627, USA  
Affiliation: Department of Computer Science, University of Rochester  
Abstract: A general-purpose object indexing technique is described that combines the virtues of principal component analysis with the favorable matching properties of high-dimensional spaces to achieve high precision recognition. An object is represented by a set of high-dimensional iconic feature vectors comprised of the responses of derivative of Gaussian filters at a range of orientations and scales. Since these filters can be shown to form the eigenvectors of arbitrary images containing both natural and man-made structures, they are well-suited for indexing in disparate domains. The indexing algorithm uses an active vision system in conjunction with a modified form of Kanerva's sparse distributed memory which facilitates interpolation between views and provides a convenient platform for learning the association between an object's appearance and its identity. The robustness of the indexing method was experimentally confirmed by subjecting the method to a range of viewing conditions and the accuracy was verified using a well-known model database containing a number of complex 3D objects under varying pose. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Aloimonos, A. Bandopadhay, and I. Weiss. </author> <title> Active vision. </title> <journal> IJCV, </journal> <volume> 1 </volume> (4):333-356, 1988. 
Reference-contexts: Such descriptions are attractive as they are easily adapted for the manipulation requirements of robotic assembly tasks. However, they have proved very difficult to extract from the image owing to the fact that geometric and photometric properties are relatively uncorrelated. Insights gained from work on active/animate vision <ref> [1, 2, 4] </ref> seem to suggest that simpler iconic descriptions of objects based on their photometric properties may often suffice for many visual tasks [18].
Reference: [2] <editor> Ruzena Bajcsy. </editor> <title> Active perception. </title> <booktitle> In Proceedings of the IEEE, </booktitle> <volume> volume 76, </volume> <pages> pages 996-1005, </pages> <month> August </month> <year> 1988. </year>
Reference-contexts: Such descriptions are attractive as they are easily adapted for the manipulation requirements of robotic assembly tasks. However, they have proved very difficult to extract from the image owing to the fact that geometric and photometric properties are relatively uncorrelated. Insights gained from work on active/animate vision <ref> [1, 2, 4] </ref> seem to suggest that simpler iconic descriptions of objects based on their photometric properties may often suffice for many visual tasks [18].
Reference: [3] <author> Dana H. Ballard and Rajesh P.N. Rao. </author> <title> Seeing behind occlusions. </title> <booktitle> In Proc. of ECCV, </booktitle> <pages> pages 274-285, </pages> <year> 1994. </year>
Reference-contexts: We have previously shown <ref> [3] </ref> that the use of an active binocular head allows stereo to be used for segmenting an occluder by using zero disparity filtering [6]. <p> between views besides offering the additional advantages of constant indexing time (O (M ) = O (1) where M is the number of address/storage locations) and the possibility of greater storage capacity over sequential memory due to 3 A more sophisticated strategy for handling partial occlusions is de scribed in <ref> [3] </ref>. the multiplexing inherent in the SDM combined with the use of more than one response vector per object. * Real-Time Recognition: Iconic techniques such as the one proposed in this paper have been greeted with considerable skepticism in the past since they have been computation-intensive.
Reference: [4] <author> D.H. Ballard. </author> <title> Animate vision. </title> <journal> Artificial Intelligence, </journal> <volume> 48 </volume> <pages> 57-86, </pages> <year> 1991. </year>
Reference-contexts: Such descriptions are attractive as they are easily adapted for the manipulation requirements of robotic assembly tasks. However, they have proved very difficult to extract from the image owing to the fact that geometric and photometric properties are relatively uncorrelated. Insights gained from work on active/animate vision <ref> [1, 2, 4] </ref> seem to suggest that simpler iconic descriptions of objects based on their photometric properties may often suffice for many visual tasks [18].
Reference: [5] <author> Roland T. Chin and Charles R. Dyer. </author> <title> Model-based recognition in robot vision. </title> <journal> ACM Computing Surveys, </journal> <volume> 18(1) </volume> <pages> 67-108, </pages> <month> March </month> <year> 1986. </year>
Reference-contexts: 1 Introduction The earliest models of objects for computer vision emphasized geometrical descriptions based on shape <ref> [20, 5] </ref>. Such descriptions are attractive as they are easily adapted for the manipulation requirements of robotic assembly tasks. However, they have proved very difficult to extract from the image owing to the fact that geometric and photometric properties are relatively uncorrelated.
Reference: [6] <author> David J. Coombs. </author> <title> Real-Time Gaze Holding in Binocular Robot Vision. </title> <type> PhD thesis, </type> <institution> University of Rochester Computer Science Dept., </institution> <year> 1992. </year> <note> Available as Technical Report 415. </note>
Reference-contexts: We have previously shown [3] that the use of an active binocular head allows stereo to be used for segmenting an occluder by using zero disparity filtering <ref> [6] </ref>. The zero disparity filter is a simple non-linear image filter that suppresses features that have non-zero disparity; in other words, it only passes image energy in the horopter.
Reference: [7] <author> William T. Freeman and Edward H. Adelson. </author> <title> The design and use of steerable filters. </title> <journal> IEEE Trans. Pattern Analysis and Machine Intelligence, </journal> <volume> 13(9) </volume> <pages> 891-906, </pages> <month> September </month> <year> 1991. </year>
Reference-contexts: In our experiments, we used five octave-separated scales. An attractive property of the index is that it can be made rotation-invariant about the viewing axis when scale is unchanged. This can be done by exploiting the steerability <ref> [7] </ref> of the basis functions. First, a canonical orientation (say, horizontal) is assumed. <p> For normalization, the entire set of filter responses can be rotated to the canonical orientation using a set of interpolation functions as derived by Freeman and Adelson <ref> [7] </ref> r 0 i+1 X r i;j 0 ;s k j 0 i (ff); (5) where i = 1; 2; 3; j = 1; : : : ; i + 1; s = s min ; : : : ; s max , and 1 h i k j 0 2
Reference: [8] <author> D. </author> <title> Gabor. </title> <journal> Theory of communication. J IEE, </journal> <volume> 93 </volume> <pages> 429-459, </pages> <year> 1946. </year>
Reference-contexts: Finally, while it is relatively well-known that the class of functions that simultaneously minimize the product of the standard deviation of the spatial position sensitivity and spatial frequency sensitivity (as given by the uncertainty principle from Fourier theory) are the complex-Gabor elementary functions <ref> [8] </ref>, a relatively lesser known fact is that the class of real-valued functions that minimize the above conjoint localization metric are in fact the Gaussian derivative functions as first noted by Gabor himself ([8] p. 441; see also [22]). 3 The Multiscale Iconic Index Our iconic representation for objects is inspired
Reference: [9] <author> Peter J.B. Hancock, Roland J. Baddeley, and Leslie S. Smith. </author> <title> The principal components of natural images. </title> <journal> Network, </journal> <volume> 3 </volume> <pages> 61-70, </pages> <year> 1992. </year>
Reference-contexts: Sanger [21] extended this work to obtain the first k principal components and noted that when iteratively applied to natural image patches, his network converged to approximations of oriented first- and second-derivative operators. Hancock et al. <ref> [9] </ref> used Sanger's network to extract the first few principal components of an ensemble of natural images windowed by a Gaussian in order to avoid the distortions that may have been caused by the use of square windows in Sanger's work.
Reference: [10] <author> Pentti Kanerva. </author> <title> Sparse Distributed Memory. </title> <publisher> Bradford Books, </publisher> <address> Cambridge, MA, </address> <year> 1988. </year>
Reference-contexts: The process of object indexing itself is realized within the framework of an active vision system used in conjunction with a modified form of Kanerva's sparse distributed memory <ref> [10] </ref>; the memory facilitates interpolation between different views of an object and provides a convenient platform for learning the association between an object's appearance and its identity. <p> One way of accomplishing this is to use an associative memory. A model of associative memory that is specifically geared towards storage and retrieval of high-dimensional vectors is Kanerva's Sparse Distributed Memory (SDM) <ref> [10] </ref>. SDM was developed by Kanerva in an attempt to model human long-term memory.
Reference: [11] <author> Pentti Kanerva. </author> <title> Sparse distributed memory and related models. </title> <editor> In Mohamad H. Hassoun, editor, </editor> <booktitle> Associative Neural Memories, </booktitle> <pages> pages 50-76. </pages> <publisher> New York : Oxford University Press, </publisher> <year> 1993. </year>
Reference-contexts: The statistically reconstructed data vector d 0 should be the same as the original data vector provided the capacity of the SDM <ref> [11] </ref> has not been exceeded. The intuitive reason for this is as follows: When storing a data vector d using an n-dimensional address vector a, each of the selected locations receives one copy of the data. <p> This biases the sum vector in the direction of d and hence, d is output with high probability. A more rigorous argument can be found in <ref> [11] </ref>. 4.2 Using SDM for Visual Recognition The model of SDM used in our method differs from the one proposed by Kanerva in the following ways: * The addresses are no longer binary but correspond to multivalued response vectors whose range is de termined by the range of filter outputs. 1 <p> In fact, the organization of SDM is strikingly similar to the organization of the human cerebellum. In particular, the cerebellar model proposed by the late David Marr [14] (and also the CMAC of James Albus) are closely related to generalized forms of the SDM as discussed in <ref> [11] </ref>. learning associations between object appearance and object identity. * The normalized dot product is used as the distance metric instead of the Hamming distance. <p> Kanerva <ref> [11] </ref> estimates the capacity of the SDM to be about 5% of the number of storage locations; thus, with only 1000 storage locations, the number of potentially distinguishable objects is still 50 which is an extremely large number, even after factoring out the number of different views for an object.
Reference: [12] <author> James D. Keeler. </author> <title> Comparison between Kanerva's SDM and Hopfield-type neural networks. </title> <journal> Cognitive Science, </journal> <volume> 12 </volume> <pages> 299-329, </pages> <year> 1988. </year>
Reference-contexts: Therefore, if addresses are picked randomly, a large number of locations will never be activated while a number of locations will be selected so often that their contents will resemble noise. The way out of this dilemma is to pick addresses according to the distribution of the data <ref> [12] </ref>. In our case, we simply use an initial subset of the training response vectors. When all address locations have subsequently been filled, the address space can be allowed to self-organize using the well-known competitive Hebbian learning rule (or the Kohonen rule) as suggested by Keeler in [12]. <p> of the data <ref> [12] </ref>. In our case, we simply use an initial subset of the training response vectors. When all address locations have subsequently been filled, the address space can be allowed to self-organize using the well-known competitive Hebbian learning rule (or the Kohonen rule) as suggested by Keeler in [12]. Assume that the number of response vectors (each n-element long) currently stored is m. Let A represent the m fi n matrix of magnitude-normalized (i.e. r i =jjr i jj) response vectors from the objects. Assume that we have stored response vectors for p objects. <p> This in fact corresponds to a generalized Hebbian learning rule as noted in <ref> [12] </ref>. 4.2.2 Retrieving Object Identity Let r be a response vector obtained from one of the points in the current foveal region.
Reference: [13] <author> V.K. Kumar, D. Casasent, and H. Murakami. </author> <title> Principal-component imagery for statistical pattern recognition correlators. </title> <journal> Optical Engineering, </journal> <volume> 21(1) </volume> <pages> 43-47, </pages> <year> 1982. </year>
Reference-contexts: Further support for using the oriented derivative-of-Gaussian operators comes from the observation that correlation filters generated by principal component expansion maximize signal-to-noise ratio and yield much sharper correlation peaks than traditional raw image cross-correlation techniques (see, for instance, <ref> [13] </ref>).
Reference: [14] <author> David Marr. </author> <title> A theory of cerebellar cortex. </title> <journal> J. Physiol. (London), </journal> <volume> 202 </volume> <pages> 437-470, </pages> <year> 1969. </year>
Reference-contexts: In fact, the organization of SDM is strikingly similar to the organization of the human cerebellum. In particular, the cerebellar model proposed by the late David Marr <ref> [14] </ref> (and also the CMAC of James Albus) are closely related to generalized forms of the SDM as discussed in [11]. learning associations between object appearance and object identity. * The normalized dot product is used as the distance metric instead of the Hamming distance. <p> phases in the algorithms of the previous section during either storage or retrieval : (a) Figure-ground segmentation, (b) Visual preprocessing to extract filter responses, and (c) Memory access. 2 Note that s is a new representation in an m-dimensional space and correspondsto the codon representationof input in Marr's cerebellar model <ref> [14] </ref>.
Reference: [15] <author> Hiroshi Murase and Shree K. Nayar. </author> <title> Visual learning and recognition of 3D objects from appearance. </title> <journal> IJCV, </journal> <volume> 14 </volume> <pages> 5-24, </pages> <year> 1995. </year>
Reference-contexts: In recent years, there has been considerable interest in the use of PCA for both synthesis and analysis. For example, PCA has recently been applied quite successfully to synthesize basis functions for recognition of faces [23] and arbitrary 3D objects <ref> [15] </ref>. Researchers analyzing the human visual pathway have found PCA to be the crucial link between the profiles of cortical receptive fields and the statistics of natural images. <p> By sacrificing specialization for a particular class of objects, we achieve wider applicability and by using fixed basis functions which were learned during an initial development phase, we avoid the high computational overhead involved in recomputing new basis functions upon the introduction of new objects as necessitated by previous methods <ref> [15, 23] </ref>. Further support for using the oriented derivative-of-Gaussian operators comes from the observation that correlation filters generated by principal component expansion maximize signal-to-noise ratio and yield much sharper correlation peaks than traditional raw image cross-correlation techniques (see, for instance, [13]). <p> Finally, the 3D recognition performance of the indexing technique was tested on the Columbia object database that was originally used in <ref> [15] </ref> by Murase and Nayar. Figure 6 (a) shows the segmented images of 20 3D objects in the database for a given pose. During the training phase, 36 images of each object at 10 ffi increments in pose were used to extract response vectors for storage in the SDM.
Reference: [16] <author> Erkki Oja. </author> <title> A simplified neuron model as a principal component analyzer. </title> <journal> J. Math. Biology, </journal> <volume> 15 </volume> <pages> 267-273, </pages> <year> 1982. </year>
Reference-contexts: Researchers analyzing the human visual pathway have found PCA to be the crucial link between the profiles of cortical receptive fields and the statistics of natural images. Oja <ref> [16] </ref> first noted that a simple one-layer feedforward neural-network employing a form of the Heb-bian learning rule acted as a principal component analyzer. PCA network.
Reference: [17] <author> T. Poggio and F. Girosi. </author> <title> Networks for approximation and learning. </title> <journal> Proc. IEEE, </journal> <volume> 78 </volume> <pages> 1481-1497, </pages> <year> 1990. </year>
Reference-contexts: Let D i denote the threshold for the ith address location and let T denote the nonlinear threshold function defined on m-element vectors whose ith component is given by : 0 otherwise (12) Note that T can in general be an arbitrary radial basis func tion <ref> [17] </ref>.
Reference: [18] <author> Rajesh P.N. Rao and Dana H. Ballard. </author> <title> An active vision architecture based on iconic representations. </title> <type> Technical Report 548, </type> <institution> Department of Computer Science, University of Rochester, </institution> <year> 1995. </year>
Reference-contexts: Insights gained from work on active/animate vision [1, 2, 4] seem to suggest that simpler iconic descriptions of objects based on their photometric properties may often suffice for many visual tasks <ref> [18] </ref>. This paper investigates the use of an iconic description comprised of photometric features at a local image patch as a medium for efficient object indexing in active vision systems. <p> Larger changes in scale are handled by a scale interpolation strategy which accounts for scale changes by interpolating with responses across scales as illustrated in Figure 5 (d) (see <ref> [18] </ref> for further details). In the experiment shown in Figure 5 (e), we exposed a model object separately to illumination from a 60W bulb at a radial distance of 2 feet from four different directions (labeled 0, 1, 2, and 3). <p> centroid were used. (d) summarizes the experimental parameters. (e) Recognition rate (fraction of test images correctly recognized) plotted as a function of number of vectors used per object in a given pose. allows the use of simple interpolation strategies for achieving invariance in the presence of drastic changes in scale <ref> [18] </ref>. * Tolerance to Changes in Viewing Conditions: Mi nor occlusions 3 or modest perspective changes and interference caused by varying background lying in the receptive fields of the largest scale filters are tolerated because a large number of measurements are used per point; distortions in a few components act as
Reference: [19] <author> Rajesh P.N. Rao and Dana H. Ballard. </author> <title> Natural basis functions and topographic memory for face recognition. </title> <booktitle> In Proc. of IJCAI, </booktitle> <year> 1995. </year> <note> (To appear). </note>
Reference-contexts: When more than one vector is used per object, the output label is obtained by thresholding the cumulative sum vector over the different object vectors. An alternative here is to use separate SDMs for the different foveal locations, thereby yielding a topographic memory <ref> [19] </ref>. 5 Implementation The algorithms described in the previous section have been implemented on an active vision system comprised of a binocular head with two color CCD television cameras that provide input to a Datacube M axV ideo T M MV200 pipeline image-processing system.
Reference: [20] <author> L.G. Roberts. </author> <title> Machine perception of three-dimensional solids. </title> <editor> In James T. Tippett et al., editor, </editor> <booktitle> Optical and Electro-Optical Information Processing. </booktitle> <address> Cambridge: </address> <publisher> MIT Press, </publisher> <year> 1965. </year>
Reference-contexts: 1 Introduction The earliest models of objects for computer vision emphasized geometrical descriptions based on shape <ref> [20, 5] </ref>. Such descriptions are attractive as they are easily adapted for the manipulation requirements of robotic assembly tasks. However, they have proved very difficult to extract from the image owing to the fact that geometric and photometric properties are relatively uncorrelated.
Reference: [21] <author> Terence David Sanger. </author> <title> Optimal unsupervised learning in a single-layer linear feedforward neural network. </title> <booktitle> Neural Networks, </booktitle> <volume> 2 </volume> <pages> 459-473, </pages> <year> 1989. </year>
Reference-contexts: This choice also obviates using mixed derivatives (as in (b)) since the other oriented filters yield a complete basis. Sanger <ref> [21] </ref> extended this work to obtain the first k principal components and noted that when iteratively applied to natural image patches, his network converged to approximations of oriented first- and second-derivative operators.
Reference: [22] <author> David G. Stork and Hugh R. Wilson. </author> <title> Do Gabor functions provide appropriate descriptions of visual cortical receptive fields? J. </title> <journal> Optical Society of America A, </journal> <volume> 7(8) </volume> <pages> 1362-1373, </pages> <year> 1990. </year>
Reference-contexts: by the uncertainty principle from Fourier theory) are the complex-Gabor elementary functions [8], a relatively lesser known fact is that the class of real-valued functions that minimize the above conjoint localization metric are in fact the Gaussian derivative functions as first noted by Gabor himself ([8] p. 441; see also <ref> [22] </ref>). 3 The Multiscale Iconic Index Our iconic representation for objects is inspired by the existence of natural basis functions as outlined in the previous section.
Reference: [23] <author> Matthew Turk and Alex Pentland. </author> <title> Eigenfaces for recognition. </title> <journal> Journal of Cognitive Neuroscience, </journal> <volume> 3(1) </volume> <pages> 71-86, </pages> <year> 1991. </year>
Reference-contexts: In recent years, there has been considerable interest in the use of PCA for both synthesis and analysis. For example, PCA has recently been applied quite successfully to synthesize basis functions for recognition of faces <ref> [23] </ref> and arbitrary 3D objects [15]. Researchers analyzing the human visual pathway have found PCA to be the crucial link between the profiles of cortical receptive fields and the statistics of natural images. <p> By sacrificing specialization for a particular class of objects, we achieve wider applicability and by using fixed basis functions which were learned during an initial development phase, we avoid the high computational overhead involved in recomputing new basis functions upon the introduction of new objects as necessitated by previous methods <ref> [15, 23] </ref>. Further support for using the oriented derivative-of-Gaussian operators comes from the observation that correlation filters generated by principal component expansion maximize signal-to-noise ratio and yield much sharper correlation peaks than traditional raw image cross-correlation techniques (see, for instance, [13]).
Reference: [24] <author> R.A. Young. </author> <title> The Gaussian derivative theory of spatial vision: Analysis of cortical cell receptive field line-weighting profiles. </title> <journal> General Motors Research Publication GMR-4920, </journal> <year> 1985. </year>
Reference-contexts: They observed that the eigenvectors that the network converged to were very close approximations of the different oriented derivative-of-Gaussian operators that have been shown to provide the best fit to primate cortical receptive field profiles among the different mathematical profiles suggested in the literature <ref> [24] </ref>. We employed Sanger's network to ascertain whether the results of Hancock et al. remained true for collections of images containing equal proportions of natural and man-made stimuli.
References-found: 24

