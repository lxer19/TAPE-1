URL: http://www.ri.cmu.edu/afs/cs.cmu.edu/user/jkr/www/papers/Integrated_Off_Road_System.ps.gz
Refering-URL: http://www.ri.cmu.edu/afs/cs/project/alv/member/www/projects/DAMN.html
Root-URL: 
Title: Abstract  
Abstract: In this paper, we report on experiments with a core system for autonomous navigation in outdoor natural terrain. The system consists of three parts: a perception module which processes range images to identify untraversable regions of the terrain, a local map management module which maintains a representation of the environment in the vicinity of the vehicle, and a planning module which issues commands to the vehicle controller. Our approach uses reactive planning for generating commands to drive the vehicle along with early traversability evaluation, in which the perception module decides which parts of the terrain are traversable as soon as a new image is taken. We argue that our approach leads to a robust and efficient navigation system. We illustrate our approach by an experiment in which a vehicle travelled autonomously for one kilometer through unmapped cross-country terrain. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. Brooks and A. Flynn. </author> <title> Fast, Cheap, and Out of Control: A Robot Invasion of the Solar System. </title> <journal> J. British Interplanetary Society, </journal> <volume> 42(10) </volume> <pages> 478-485, </pages> <year> 1989. </year>
Reference-contexts: Other efforts include: The VAP project which is also based on stereo vision [2]; the PANORAMA Esprit project [15]; the MIT rovers which rely on simple sensing modalities <ref> [1] </ref>. Most of these percep . This research was partly sponsored by ARPA, under contracts Perception for Outdoor Navigation (contract number DACA76-89-C-0014, monitored by the US Army Topographic Engineering Center) and Unmanned Ground Vehicle System (contract number DAAE07-90-C-R059, monitored by TACOM). J. Rosenblatt was supported by a Hughes Research Fellowship. <p> DAMN (Figure 9) is a behavior-based architecture <ref> [1] </ref>.
Reference: [2] <author> G. Giralt and L. Boissier. </author> <title> The French Planetary Rover VAP: Concept and Current Developments. </title> <booktitle> In Proc. IEEE Intl. Workshop on Intelligent Robots and Systems, </booktitle> <pages> pp. 1391-1398, </pages> <address> Raleigh, </address> <year> 1992. </year>
Reference-contexts: JPLs Robby used stereo vision [9] as the basis of its perception system and has been demonstrated over a 100 m traverse in outdoor terrain. Other efforts include: The VAP project which is also based on stereo vision <ref> [2] </ref>; the PANORAMA Esprit project [15]; the MIT rovers which rely on simple sensing modalities [1]. Most of these percep .
Reference: [3] <author> M. Hebert. </author> <title> Pixel-Based Range Image Processing for Autonomous Driving. </title> <booktitle> Proc. IEEE Robotics and Automation. </booktitle> <month> May </month> <year> 1994. </year>
Reference-contexts: We have implemented a different version of the perception module which processes the range data scanline per scanline and reports new obstacles every time a new scanline is processed. We describe such an approach in a separate paper in these proceedings <ref> [3] </ref>. The other major factor in overall system performance is the distributed and asynchronous nature of the system. In particular, the message traffic between perception, Ganesha, and the behaviors may become heavy enough to introduce significant delays in the system. <p> In doing this, we retain the basic functionality of early traversability evaluation and of reactive planning while eliminating the network communication problems. Preliminary results on combining line processing and single module operation are also reported in <ref> [3] </ref>.
Reference: [4] <author> M. Hebert, E. Krotkov. </author> <title> 3D Measurements from Imaging Laser Radars. </title> <booktitle> Image and Vision Computing 10(3), </booktitle> <month> April </month> <year> 1992. </year>
Reference: [5] <author> A. Kelly, T. Stentz, M. Hebert. </author> <title> Terrain Map Building for Fast Navigation on Rugged Outdoor Terrain. </title> <booktitle> In Proc. of the SPIE Conference on Mobile Robots, </booktitle> <year> 1992. </year>
Reference-contexts: In particular, even a small error in rotation angles between two images may introduce enough discrepancy between the corresponding elevation terrain maps to create artificial obstacles at the interface between the two maps. (We refer the reader to <ref> [5] </ref> for a more quantitative description of this problem.) Therefore, it is preferable to not merge images explicitly and to rely on fast processing to compensate for the sparsity of the data.
Reference: [6] <author> I.S. Kweon. </author> <title> Modeling Rugged Terrain by Mobile Robots with Multiple Sensors. </title> <type> Ph.D. thesis, </type> <institution> Robotics Institute, Carnegie Mellon University, </institution> <month> January, </month> <year> 1991. </year>
Reference: [7] <author> D. Langer and C. Thorpe. </author> <title> Sonar-Based Outdoor Vehicle Navigation and Collision Avoidance. </title> <booktitle> In Proc. IROS 92. </booktitle> <year> 1992. </year>
Reference-contexts: The goal of this paper is to present and discuss the performance of the overall system. Detailed descriptions of its components may be found in <ref> [7] </ref> for the local map module, [12] for the planning component, and in [8] for the complete system description. 2 System Overview To illustrate our approach, we will describe a set of perception and navigation modules which constitute the core of a cross-country navigation system. <p> In the current system, the local map module is a general purpose module called Ganesha <ref> [7] </ref>. In this system, the active map extends from 0 to 20 meters in front of the vehicle and 10 meters on both sides.
Reference: [8] <author> D. Langer, J.K. Rosenblatt, M. Hebert, </author> <title> Off-Road Navigation, </title> <journal> submitted to Special Issue of IEEE Transactions on Robotics and Automation, </journal> <year> 1993. </year>
Reference-contexts: The goal of this paper is to present and discuss the performance of the overall system. Detailed descriptions of its components may be found in [7] for the local map module, [12] for the planning component, and in <ref> [8] </ref> for the complete system description. 2 System Overview To illustrate our approach, we will describe a set of perception and navigation modules which constitute the core of a cross-country navigation system.

References-found: 8

