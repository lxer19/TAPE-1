URL: http://www.cs.berkeley.edu/~iyer/lawn111.ps.gz
Refering-URL: http://www.cs.berkeley.edu/~iyer/
Root-URL: 
Title: Optimizing Matrix Multiply using PHiPAC: a Portable, High-Performance, ANSI C Coding Methodology  
Author: Jeff Bilmes Krste Asanovic Jim Demmel Dominic Lam Chee-Whye Chin 
Date: August 8, 1996  
Web: http://www.netlib.org/lapack/lawns  
Note: LAPACK Working Note 111, UTK,  GEMM.  
Abstract: BLAS3 operations have great potential for aggressive optimization. Unfortunately, they usually need to be hand-coded for a specific machine and compiler to achieve near-peak performance. We have developed a methodology whereby near-peak performance on a wide range of systems can be achieved automatically for such routines. First, by analyzing current machines and C compilers, we've developed guidelines for writing Portable, High-Performance, ANSI C (PHiPAC, pronounced "fee-pack"). Second, rather than code by hand, we produce parameterized code generators. Third, we write search scripts that find the best parameters for a given system. We report on a BLAS GEMM compatible multilevel cache-blocked matrix multiply generator that produces code achieving performance in excess of 90% of peak on the Sparcstation-20/61, IBM RS/6000-590, HP 712/80i, and 80% of peak on the SGI Indigo R4k. On the IBM, HP, and SGI, the resulting routine is often faster than the vendorsupplied BLAS 
Abstract-found: 1
Intro-found: 1
Reference: [ABB + 92] <author> E. Anderson, Z. Bai, C. Bischof, J. Demmel, J. Dongarra, J. Du Croz, A. Greenbaum, S. Hammarling, A. McKenney, S. Ostrouchov, and D. Sorensen. </author> <note> LAPACK users' guide, release 1.0. In SIAM, Philadelphia, </note> <year> 1992. </year>
Reference-contexts: We also plan to use the same coefficients to find a parameter set that works well on a set of systems. At some point, PHiPAC will be integrated with Bo K-agstrom's GEMM based BLAS3 package [BLL93]. The PHiPAC routines might also be integrated into LAPACK <ref> [ABB + 92] </ref>. In the more distant future, the matrix multiply code will dynamically adjust its L1 blocking size according to various criteria [LRW91]. This will increase performance for certain pathological combinations of matrix dimensions and cache structure. Other generators, such as FFT and sort, are planned.
Reference: [ACF95] <author> B. Alpern, L. Carter, and J. Ferrante. </author> <title> Space-limited procedures: A methodology for portable high-performance. </title> <booktitle> In International Working Conference on Massively Parallel 16 Programming Models, </booktitle> <year> 1995. </year>
Reference-contexts: The author acknowledges the support of ARPA contract DAAL03-91-C-0047 (University of Tennessee Subcontract ORA4466.02). -CS Division, University of California at Berkeley. The author acknowledges the support of ARPA contract DAAL03-91-C-0047 (University of Tennessee Subcontract ORA4466.02). 1 matrix-multiplication as a test case | a short list includes <ref> [WL91, LRW91, MS95, ACF95, CFH95, SMP + 96] </ref>. 1 While these compiler heuristics generate reasonably good code in general, they tend not to generate near-peak code for any one operation. A high-level language's semantics might also obstruct aggressive compiler optimizations. <p> The PHiPAC methodology has three components. First, we have developed a generic model of current C compilers and microprocessors that provides guidelines for producing portable high-performance ANSI C code. Second, rather than hand-code particular routines, we write parameterized generators <ref> [ACF95, MS95] </ref> that produce code according to our guidelines. Third, we write scripts that automatically tune code for a particular system by varying the generators' parameters and benchmarking the resulting routines. Using this methodology, we have produced a portable, BLAS-compatible matrix multiply generator.
Reference: [AGZ94] <author> R.C. Agarwal, F.G. Gustavson, and M. Zubair. </author> <title> IBM Engineering and Scientific Subroutine Library, Guide and Reference, 1994. Available through IBM branch offices. </title>
Reference-contexts: 1 Introduction The use of a standard matrix-vector library interface, such as BLAS [LHKK79, DCHH88, DCDH90], enables portable application code to obtain high-performance provided that an optimized library (e.g., <ref> [AGZ94, KHM94] </ref>) is available and affordable. Developing an optimized library, however, is a difficult and time-consuming task. Matrix-vector library routines have a large design space.
Reference: [BAD + ] <author> J. Bilmes, K. Asanovic, J. Demmel, D. Lam, and C.W. Chin. </author> <note> The PHiPAC WWW home page. http://www.icsi.berkeley.edu/~bilmes/phipac. </note>
Reference-contexts: We nevertheless have implemented a FORTRAN BLAS GEMM compatible interface to our routines <ref> [BAD + ] </ref>. 4 Search Scripts For each combination of generator parameters and compilation options, the PHiPAC matrix multiply search script calls the generator, compiles the resulting routine, links it with timing code, and benchmarks the resulting executable. <p> In our search scripts, we assume that we have all machine specific information, such as the number of integer and floating-point registers and sizes of each level of cache, available at the start of the search. 4.1 Naive Parameter Search In the initial PHiPAC alpha release <ref> [BAD + ] </ref>, we use a simple brute force search. <p> The other two curves are the vendorsupplied SDOT routine, and the PHiPAC generated code. a generator and searching a parameter space, instead of coding directly in a target language. The PHiPAC alpha release <ref> [BAD + ] </ref> contains the matrix multiply generator, the naive search scripts written in perl, and timing libraries. We have also written parameterized generators for matrix-vector and vector-matrix multiply, dot product, AXPY, convolution, and outer-product.
Reference: [BLL93] <author> B.K-agstrom, P. Ling, and C. Van Loan. </author> <title> Portable high performance GEMM-based level 3 blas. In R.F. </title> <editor> Sincovec et al., editor, </editor> <booktitle> Parallel Processing for Scientific Computing, </booktitle> <pages> pages 339-346, </pages> <address> Philadelphia, 1993. </address> <publisher> SIAM Publications. </publisher>
Reference-contexts: We also plan to use the same coefficients to find a parameter set that works well on a set of systems. At some point, PHiPAC will be integrated with Bo K-agstrom's GEMM based BLAS3 package <ref> [BLL93] </ref>. The PHiPAC routines might also be integrated into LAPACK [ABB + 92]. In the more distant future, the matrix multiply code will dynamically adjust its L1 blocking size according to various criteria [LRW91]. This will increase performance for certain pathological combinations of matrix dimensions and cache structure.
Reference: [BLS91] <author> D. H. Bailey, K. Lee, and H. D. Simon. </author> <title> Using Strassen's algorithm to accelerate the solution of linear systems. </title> <journal> J. Supercomputing, </journal> <volume> 4 </volume> <pages> 97-371, </pages> <year> 1991. </year>
Reference-contexts: Developing an optimized library, however, is a difficult and time-consuming task. Matrix-vector library routines have a large design space. Even excluding algorithmic variants such as Strassen's method <ref> [BLS91] </ref> for matrix multiplication, blocking sizes, loop nesting permuta tions, register allocation, and instruction scheduling, can all be varied. The routines could be manually written in assembly code, but fully exploring the design space might be infeasible, and the resulting code might be unusable or suboptimal on a different system.
Reference: [CFH95] <author> L. Carter, J. Ferrante, and S. Flynn Hummel. </author> <title> Hierarchical tiling for improved superscalar performance. </title> <booktitle> In International Parallel Processing Symposium, </booktitle> <month> April </month> <year> 1995. </year>
Reference-contexts: The author acknowledges the support of ARPA contract DAAL03-91-C-0047 (University of Tennessee Subcontract ORA4466.02). -CS Division, University of California at Berkeley. The author acknowledges the support of ARPA contract DAAL03-91-C-0047 (University of Tennessee Subcontract ORA4466.02). 1 matrix-multiplication as a test case | a short list includes <ref> [WL91, LRW91, MS95, ACF95, CFH95, SMP + 96] </ref>. 1 While these compiler heuristics generate reasonably good code in general, they tend not to generate near-peak code for any one operation. A high-level language's semantics might also obstruct aggressive compiler optimizations. <p> The K loop updates the set of pointers to the A source block, one of which is used for loop termination. the register-tiled code in <ref> [CFH95] </ref>. Local variables c00 through c22 hold a complete C destination block. Variables A0 through A2 point to successive rows of the A source matrix block, and variable B points to the first row of the B source matrix block.
Reference: [DCDH90] <author> J. Dongarra, J. Du Croz, I. Duff, and S. Hammarling. </author> <title> A set of level 3 basic linear algebra subprograms. </title> <journal> ACM Trans. Math. Soft., </journal> <volume> 16(1) </volume> <pages> 1-17, </pages> <month> March </month> <year> 1990. </year>
Reference-contexts: 1 Introduction The use of a standard matrix-vector library interface, such as BLAS <ref> [LHKK79, DCHH88, DCDH90] </ref>, enables portable application code to obtain high-performance provided that an optimized library (e.g., [AGZ94, KHM94]) is available and affordable. Developing an optimized library, however, is a difficult and time-consuming task. Matrix-vector library routines have a large design space.
Reference: [DCHH88] <author> J. Dongarra, J. Du Cros, S. Hammarling, and R.J. Hanson. </author> <title> An extended set of FORTRAN basic linear algebra subroutines. </title> <journal> ACM Trans. Math. Soft., </journal> <volume> 14 </volume> <pages> 1-17, </pages> <month> March </month> <year> 1988. </year>
Reference-contexts: 1 Introduction The use of a standard matrix-vector library interface, such as BLAS <ref> [LHKK79, DCHH88, DCDH90] </ref>, enables portable application code to obtain high-performance provided that an optimized library (e.g., [AGZ94, KHM94]) is available and affordable. Developing an optimized library, however, is a difficult and time-consuming task. Matrix-vector library routines have a large design space.
Reference: [GL89] <author> G.H. Golub and C.F. Van Loan. </author> <title> Matrix Computations. </title> <publisher> Johns Hopkins University Press, </publisher> <year> 1989. </year>
Reference-contexts: A collection of routines produced by mm gen can be used for a complete BLAS-compatible GEMM. mm gen produces a cache-blocked matrix multiply <ref> [GL89, LRW91, MS95] </ref>, restructuring the algorithm for unit stride, and reducing the number of cache misses and unnecessary loads and stores.
Reference: [KHM94] <author> C. Kamath, R. Ho, </author> <title> and D.P. Manley. DXML: A high-performance scientific subroutine library. </title> <journal> Digital Technical Journal, </journal> <volume> 6(3) </volume> <pages> 44-56, </pages> <month> Summer </month> <year> 1994. </year>
Reference-contexts: 1 Introduction The use of a standard matrix-vector library interface, such as BLAS [LHKK79, DCHH88, DCDH90], enables portable application code to obtain high-performance provided that an optimized library (e.g., <ref> [AGZ94, KHM94] </ref>) is available and affordable. Developing an optimized library, however, is a difficult and time-consuming task. Matrix-vector library routines have a large design space.
Reference: [LHKK79] <author> C. Lawson, R. Hanson, D. Kincaid, and F. Krogh. </author> <title> Basic linear algebra subprograms for FORTRAN usage. </title> <journal> ACM Trans. Math. Soft., </journal> <volume> 5 </volume> <pages> 308-323, </pages> <year> 1979. </year>
Reference-contexts: 1 Introduction The use of a standard matrix-vector library interface, such as BLAS <ref> [LHKK79, DCHH88, DCDH90] </ref>, enables portable application code to obtain high-performance provided that an optimized library (e.g., [AGZ94, KHM94]) is available and affordable. Developing an optimized library, however, is a difficult and time-consuming task. Matrix-vector library routines have a large design space.
Reference: [LRW91] <author> M. S. Lam, E. E. Rothberg, and M. E. Wolf. </author> <title> The cache performance and optimizations of blocked algorithms. </title> <booktitle> In Proceedings of the Fourth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 63-74, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: The author acknowledges the support of ARPA contract DAAL03-91-C-0047 (University of Tennessee Subcontract ORA4466.02). -CS Division, University of California at Berkeley. The author acknowledges the support of ARPA contract DAAL03-91-C-0047 (University of Tennessee Subcontract ORA4466.02). 1 matrix-multiplication as a test case | a short list includes <ref> [WL91, LRW91, MS95, ACF95, CFH95, SMP + 96] </ref>. 1 While these compiler heuristics generate reasonably good code in general, they tend not to generate near-peak code for any one operation. A high-level language's semantics might also obstruct aggressive compiler optimizations. <p> A collection of routines produced by mm gen can be used for a complete BLAS-compatible GEMM. mm gen produces a cache-blocked matrix multiply <ref> [GL89, LRW91, MS95] </ref>, restructuring the algorithm for unit stride, and reducing the number of cache misses and unnecessary loads and stores. <p> Under control of command line parameters, mm gen can produce blocking code for any number of levels of memory hierarchy, including register, L1 cache, TLB, L2 cache, and so on. mm gen's code can also perform copy optimization <ref> [LRW91] </ref>, optionally with a different accumulator precision. <p> We explain by example the code 6 for L1 cache blocking and register blocking where M 0 = 3, K 0 = 2, and N 0 = 3, and describe the scheme used for further blocking levels. mm gen does not vary the loop permutation <ref> [MS95, LRW91] </ref> because the resulting gains in locality are subsumed by the method described below. The outer M loop in Figure 2 maintains pointers c0 and a0 to rows of register blocks in the A and C matrices. <p> " B += Bstride; " _a0 = A0 [0]; " _a1 = A1 [0]; " _a2 = A2 [0]; " " B += Bstride; " _a0 = A0 [1]; " _a1 = A1 [1]; " _a2 = A2 [1]; " - 10 but to minimize the probability of cache misses <ref> [LRW91] </ref>, they should be made smaller. For the DfiD square case, this occurs roughly when 3D 2 = L1 where L1 is the L1 cache size. <p> At some point, PHiPAC will be integrated with Bo K-agstrom's GEMM based BLAS3 package [BLL93]. The PHiPAC routines might also be integrated into LAPACK [ABB + 92]. In the more distant future, the matrix multiply code will dynamically adjust its L1 blocking size according to various criteria <ref> [LRW91] </ref>. This will increase performance for certain pathological combinations of matrix dimensions and cache structure. Other generators, such as FFT and sort, are planned. We wish to thank the International Computer Science Institute for its support. We also wish to thank Nelson Morgan who provided the initial impetus for this project.
Reference: [MS95] <author> J.D. McCalpin and M. Smotherman. </author> <title> Automatic benchmark generation for cache optimization of matrix algorithms. </title> <editor> In R. Geist and S. Junkins, editors, </editor> <booktitle> Proceedings of the 33rd Annual Southeast Conference, </booktitle> <pages> pages 195-204, </pages> <address> New York, NY, </address> <month> March </month> <year> 1995. </year> <institution> Association for Computing Machinery, ACM. </institution>
Reference-contexts: The author acknowledges the support of ARPA contract DAAL03-91-C-0047 (University of Tennessee Subcontract ORA4466.02). -CS Division, University of California at Berkeley. The author acknowledges the support of ARPA contract DAAL03-91-C-0047 (University of Tennessee Subcontract ORA4466.02). 1 matrix-multiplication as a test case | a short list includes <ref> [WL91, LRW91, MS95, ACF95, CFH95, SMP + 96] </ref>. 1 While these compiler heuristics generate reasonably good code in general, they tend not to generate near-peak code for any one operation. A high-level language's semantics might also obstruct aggressive compiler optimizations. <p> The PHiPAC methodology has three components. First, we have developed a generic model of current C compilers and microprocessors that provides guidelines for producing portable high-performance ANSI C code. Second, rather than hand-code particular routines, we write parameterized generators <ref> [ACF95, MS95] </ref> that produce code according to our guidelines. Third, we write scripts that automatically tune code for a particular system by varying the generators' parameters and benchmarking the resulting routines. Using this methodology, we have produced a portable, BLAS-compatible matrix multiply generator. <p> A collection of routines produced by mm gen can be used for a complete BLAS-compatible GEMM. mm gen produces a cache-blocked matrix multiply <ref> [GL89, LRW91, MS95] </ref>, restructuring the algorithm for unit stride, and reducing the number of cache misses and unnecessary loads and stores. <p> We explain by example the code 6 for L1 cache blocking and register blocking where M 0 = 3, K 0 = 2, and N 0 = 3, and describe the scheme used for further blocking levels. mm gen does not vary the loop permutation <ref> [MS95, LRW91] </ref> because the resulting gains in locality are subsumed by the method described below. The outer M loop in Figure 2 maintains pointers c0 and a0 to rows of register blocks in the A and C matrices.
Reference: [SMP + 96] <author> R. Saavedra, W. Mao, D. Park, J. Chame, and S. Moon. </author> <title> The combined effectiveness of unimodular transformations, tiling, and software prefetching. </title> <booktitle> In Proceedings of the 10th International Parallel Processing Symposium. IEEE Computer Society, </booktitle> <month> April 15-19 </month> <year> 1996. </year>
Reference-contexts: The author acknowledges the support of ARPA contract DAAL03-91-C-0047 (University of Tennessee Subcontract ORA4466.02). -CS Division, University of California at Berkeley. The author acknowledges the support of ARPA contract DAAL03-91-C-0047 (University of Tennessee Subcontract ORA4466.02). 1 matrix-multiplication as a test case | a short list includes <ref> [WL91, LRW91, MS95, ACF95, CFH95, SMP + 96] </ref>. 1 While these compiler heuristics generate reasonably good code in general, they tend not to generate near-peak code for any one operation. A high-level language's semantics might also obstruct aggressive compiler optimizations.
Reference: [WL91] <author> M. E. Wolf and M. S. Lam. </author> <title> A data locality optimizing algorithm. </title> <booktitle> In Proceedings of the ACM SIGPLAN'91 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 30-44, </pages> <month> June </month> <year> 1991. </year>
Reference-contexts: The author acknowledges the support of ARPA contract DAAL03-91-C-0047 (University of Tennessee Subcontract ORA4466.02). -CS Division, University of California at Berkeley. The author acknowledges the support of ARPA contract DAAL03-91-C-0047 (University of Tennessee Subcontract ORA4466.02). 1 matrix-multiplication as a test case | a short list includes <ref> [WL91, LRW91, MS95, ACF95, CFH95, SMP + 96] </ref>. 1 While these compiler heuristics generate reasonably good code in general, they tend not to generate near-peak code for any one operation. A high-level language's semantics might also obstruct aggressive compiler optimizations.
Reference: [Wol96] <author> M. Wolfe. </author> <title> High performance compilers for parallel computing. </title> <publisher> Addison-Wesley, </publisher> <year> 1996. </year> <month> 17 </month>
Reference-contexts: Cache misses are costly. * A TLB holding a limited number of page table entries, typically 64 pages of 4 KB each. TLB misses are costly. 1 A longer list appears in <ref> [Wol96] </ref>. 2 * The cheapest memory addressing mode is base register plus immediate offset. * Branches are costly.
References-found: 17

