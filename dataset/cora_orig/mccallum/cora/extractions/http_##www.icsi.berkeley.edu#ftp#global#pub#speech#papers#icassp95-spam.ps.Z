URL: http://www.icsi.berkeley.edu/ftp/global/pub/speech/papers/icassp95-spam.ps.Z
Refering-URL: http://www.icsi.berkeley.edu/real/spam.html
Root-URL: http://www.icsi.berkeley.edu
Email: suling@icsi.berkeley.edu  
Phone: Tel: (510) 642-4274, Fax: (510) 643-7684  
Title: STOCHASTIC PERCEPTUAL MODELS OF SPEECH  
Author: Nelson Morgan, Herve Bourlard, Steven Greenberg, Hynek Hermansky, and Su-Lin Wu Greenberg, and Wu) fmorgan, bourlard, steveng, hynek, 
Note: Morgan,  
Address: 1947 Center St, Suite 600, Berkeley, CA. 94704  
Affiliation: International Computer Science Institute, Berkeley, California  University of California at Berkeley (for  Faculte Polytechnique, Mons, Belgium (for Bourlard) Oregon Graduate Institute (for Hermansky)  
Abstract: We have recently developed a statistical model of speech that avoids a number of current constraining assumptions for statistical speech recognition systems, particularly the model of speech as a sequence of stationary segments consisting of uncorrelated acoustic vectors. We further wish to focus statistical modeling power on perceptually-dominant and information-rich portions of the speech signal, which may also be the parts of the speech signal with a better chance to withstand adverse acoustical conditions. We describe here some of the theory, along with some preliminary experiments. These experiments suggest that the regions of acoustic signal containing significant spectral change are critical to the recognition of continuous speech. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> H. Bourlard and N. Morgan, </author> <title> Connectionist Speech Recognition A Hybrid Approach, </title> <publisher> Kluwer Academic Press, </publisher> <year> 1994 </year>
Reference-contexts: Discriminant models are trained to distinguish among all classes, including the non-Avent class. In the simplest scheme, the training data are automatically aligned using dynamic programming, and a discriminant system (e.g., a neural network) is trained on the new segmentation. These two steps are iterated, as discussed in <ref> [1] </ref>. Section 3 introduces an approach that actually minimizes the probability of errors at the global or utterance level [2]). <p> The goal of recognition is to find the most probable word or sentence j maximizing the a posteriori probability of M j given the data (X), i.e., M j = argmax M i In the discriminant HMM approach that is described in <ref> [1] </ref>, a local acoustic probability estimate is required, namely, p (q n ` n1 ; q n2 ` 1 ; X) (2) for all n = 1; : : : ; N and all possible states q ` (` = 1; : : : ; L) making up M i . <p> Alternatively one net can be used to estimate avent class probabilities, and another to estimate the probability of avent/non-avent. See <ref> [1] </ref> for related approaches to MLP training for the case of phone-like units. intervening non-perceiving states. 3. IMPROVED MAP ESTIMATION As discussed in [1], training of transition-based models has a number of inherent difficulties. <p> Alternatively one net can be used to estimate avent class probabilities, and another to estimate the probability of avent/non-avent. See <ref> [1] </ref> for related approaches to MLP training for the case of phone-like units. intervening non-perceiving states. 3. IMPROVED MAP ESTIMATION As discussed in [1], training of transition-based models has a number of inherent difficulties. This led us to develop the theory for an approach to the training of local posterior probability estimators that maximizes the estimate of global posteriors for the correct models [2].
Reference: [2] <author> H. Bourlard, Y. Konig, and N. Morgan, </author> <title> REMAP: Recursive Estimation and Maximization of A posteriori Probabilities, </title> <type> ICSI Technical Report TR-94-064, </type> <year> 1994. </year>
Reference-contexts: These two steps are iterated, as discussed in [1]. Section 3 introduces an approach that actually minimizes the probability of errors at the global or utterance level <ref> [2] </ref>). This process focuses modeling power on the perceptually-dominant and information-rich portions of the speech signal, which may also be the parts of the speech signal with a better chance to withstand adverse acoustical conditions. <p> We also have recently developed some related theory (REMAP) that suggests how a SPAM-based system could be trained to maximize the global posterior probabilities for the correct models of an utterance (the MAP estimate) <ref> [2] </ref>. This will minimize the probability of utterance error, taking advantage of the perceptually-based assumptions of SPAM. 2. THEORETICAL FRAMEWORK We first define notation and basic terms: * A set of avents (auditory events): Q = fq 0 ; q 1 ; : : : ; q K g. <p> : ; K If we assume that the probability of an avent is indepen dent of the previous avent, we can also use: p (q n nd ); (5) or, if we disregard the (n): p (q n nd ): (6) During dynamic programming (or the REMAP procedure - see <ref> [2] </ref>), these probabilities will have to be estimated for all possible q ` (according to the topology of the models) and all possible (n) (if used). <p> IMPROVED MAP ESTIMATION As discussed in [1], training of transition-based models has a number of inherent difficulties. This led us to develop the theory for an approach to the training of local posterior probability estimators that maximizes the estimate of global posteriors for the correct models <ref> [2] </ref>. In this approach, we use a forward-backward-like recursion to generate targets for the local network that push the network towards improved global discrimination. The simplest form of this approach uses a local probability that incorporates first-order dependence, namely p (q n ` jq n1 nc ). <p> The simplest form of this approach uses a local probability that incorporates first-order dependence, namely p (q n ` jq n1 nc ). However, the technique can be generalized to dependence on M previous states, and it is shown in <ref> [2] </ref> that the approach can further be used to train estimators of SPAM probabilities such as (4). Other than the general advantage of modifying local training to maximize globally optimal criteria, this approach removes (in principle) a number of practical difficulties with SPAM training.
Reference: [3] <author> R. Drullman, J. Festen, and R. Plomp, </author> <title> Effect of temporal smearing on speech reception, </title> <journal> J. Acoust. Soc. Am. </journal> <volume> 95 (2), </volume> <month> February </month> <year> 1994 </year>
Reference-contexts: Perceptual experiments A series of preliminary perceptual experiments have been performed in our laboratory, designed to ascertain the temporal locations of the information-laden components of the speech signal. These experiments are a direct outgrowth of previous studies published by Furui [4] and Drullman et al. <ref> [3] </ref>. Furui has shown for isolated Japanese consonant-vowel syllables that the most significant perceptual information is concentrated in regions associated with a large amount of spectral change.
Reference: [4] <author> S. Furui, </author> <title> On the Role of Spectral Transition for Speech Perception J. </title> <journal> Acoust. Soc. Am. </journal> <volume> 80, (4), </volume> <pages> 1016-1025, </pages> <year> 1986 </year>
Reference-contexts: 1. INTRODUCTION In [8], we proposed a perceptual model of speech as a sequence of Auditory Events (Avents), separated by relatively stationary periods (ca. 50-150 ms). We hypothesize that avents occur when the spectrum and amplitude are rapidly changing (as in <ref> [4] </ref>). These speech dynamics are precisely those likely to generate enhanced activity in the upper stations of the auditory pathway, and may be fundamental components for the perception of continuous speech. <p> Perceptual experiments A series of preliminary perceptual experiments have been performed in our laboratory, designed to ascertain the temporal locations of the information-laden components of the speech signal. These experiments are a direct outgrowth of previous studies published by Furui <ref> [4] </ref> and Drullman et al. [3]. Furui has shown for isolated Japanese consonant-vowel syllables that the most significant perceptual information is concentrated in regions associated with a large amount of spectral change.
Reference: [5] <author> O. Ghitza and M.M. Sondhi. </author> <title> Hidden markov models with templates as non-stationary states: an application to speech recognition. </title> <booktitle> Computer Speech and Language, </booktitle> <volume> 2 </volume> <pages> 101-119, </pages> <year> 1993. </year>
Reference-contexts: Related work for the case of likelihoods (as opposed to the posteriors of our model) can be found in a number of sources, e.g., <ref> [5] </ref>. We have just begun to explore the consequences of this hypothesis experimentally. Preliminary experiments with isolated digits suggest robust properties for the case of additive noise recorded in a moving automobile.
Reference: [6] <author> S. Greenberg, </author> <title> The Representation of Speech in the Auditory Periphery. </title> <journal> Journal of Phonetics, </journal> <volume> 16 </volume> <pages> 1-151, </pages> <year> 1988 </year>
Reference-contexts: A statistical framework that is more commensurate with higher-level auditory function is a better match to front-end modules that attempt to incorporate properties of the auditory periphery <ref> [6] </ref>, particularly when similar temporal auditory properties are incorporated [7]. We have named this new framework the Stochastic Perceptual Auditory-event-based (Avent) Model, or SPAM.
Reference: [7] <author> H. Hermansky and N. Morgan, </author> <title> Towards handling the acoustic environment in spoken language processing. </title> <booktitle> In Proceedings ICSLP, </booktitle> <volume> volume 1, </volume> <pages> 85-88, </pages> <address> Banff, Al-berta, Canada, </address> <year> 1992 </year>
Reference-contexts: A statistical framework that is more commensurate with higher-level auditory function is a better match to front-end modules that attempt to incorporate properties of the auditory periphery [6], particularly when similar temporal auditory properties are incorporated <ref> [7] </ref>. We have named this new framework the Stochastic Perceptual Auditory-event-based (Avent) Model, or SPAM. <p> Our preliminary informal listening results indicate that temporal modulations between 2 and 6 Hz are the most important for maintaining speech intelligi-bilty, with intellibility approaching that of low-pass filtering the speech envelope below 8 Hz. This 2-6 Hz bandpass is similar to that used in RASTA <ref> [7] </ref>, suggesting further confirmation of the auditory plausibility of this technique. 4.2. Machine classification experiments In an initial recognition experiment we learned 44 types of phonetic transitions that occur in a telephone database of digits and two control words (yes and no).
Reference: [8] <author> N. Morgan, H. Bourlard, S. Greenberg, and H. Her-mansky, </author> <title> Stochastic Perceptual Auditory-Event-Based Models for Speech Recognition. </title> <booktitle> In Proceedings ICSLP, </booktitle> <pages> pp 1943-46, </pages> <address> Yokohama, Japan, </address> <year> 1994 </year>
Reference-contexts: 1. INTRODUCTION In <ref> [8] </ref>, we proposed a perceptual model of speech as a sequence of Auditory Events (Avents), separated by relatively stationary periods (ca. 50-150 ms). We hypothesize that avents occur when the spectrum and amplitude are rapidly changing (as in [4]).
Reference: [9] <author> M.J. Russell, K.M. Ponting, S.M. Peeling, S.R. Browning, J.S. Bridle, and R.K. Moore, </author> <title> "The ARM Continuous Speech Recognition System", </title> <booktitle> IEEE Proc. Intl. Conf. on Acoustics, Speech, and Signal Processing, </booktitle> <address> Al-buquerque, NM, </address> <year> 1990. </year>
Reference-contexts: This is reminiscent of an approach proposed in <ref> [9] </ref>. In that method, similar consecutive acoustic frames were dropped, leaving only the first frame and the length of the dropped sequence as input variables for the training and recognition process. <p> However, both approaches empha size dynamic portions of the speech signal, incorporate implicit duration modelling and remove correlation between successive frames. These effects make the recognition pro cess more consistent with HMM assumptions. In <ref> [9] </ref>, this was shown to improve recognition performance. <p> as that achieved by a phone-based system with roughly the same number of parameters, we note the following: * The SPAM system used a simple probability that did not include dependence on the previous avent or on the time between them (6); these characteristics may be critical to the idea <ref> [9] </ref>. * The phone-based system used automatically-generated alignments that had been optimized for that system; the SPAM system used the same alignments. * We still have some difficulty estimating the probabilities of avent vs. non-avent.
References-found: 9

