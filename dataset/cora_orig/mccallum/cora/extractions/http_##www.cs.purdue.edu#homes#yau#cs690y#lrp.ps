URL: http://www.cs.purdue.edu/homes/yau/cs690y/lrp.ps
Refering-URL: http://www.cs.purdue.edu/homes/yau/cs690y/
Root-URL: http://www.cs.purdue.edu
Title: Lazy Receiver Processing (LRP): A Network Subsystem Architecture for Server Systems  
Author: Peter Druschel and Gaurav Banga 
Address: Houston, TX 77005  
Affiliation: Department of Computer Science Rice University  
Abstract: The explosive growth of the Internet, the widespread use of WWW-related applications, and the increased reliance on client-server architectures places interesting new demands on network servers. In particular, the operating system running on such systems needs to manage the machine's resources in a manner that maximizes and maintains throughput under conditions of high load. We propose and evaluate a new network subsystem architecture that provides improved fairness, stability, and increased throughput under high network load. The architecture is hardware independent and does not degrade network latency or bandwidth under normal load conditions. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Bas, V. Buch, W. Vogels, and T. von Eicken. U-Net: </author> <title> A user-level network interface for parallel and distributed computing. </title> <booktitle> In Proceedings of the Fifteenth ACM Symposium on Operating System Principles, </booktitle> <pages> pages 40-53, </pages> <year> 1995. </year>
Reference-contexts: 1 Introduction Most work on operating system support for high-speed networks to date has focused on improving message latency and on delivering the network's full bandwidth to application programs <ref> [1, 5, 7, 21] </ref>. More recently, researchers have started to look at resource management issues in network servers such as LAN servers, firewall gateways, and WWW servers [16, 17]. <p> Demultiplexing in the network adaptor and multiple NI channels have been used to implement low-latency, high-bandwidth, user-level communication <ref> [1, 5] </ref>. Protocol processing by user-level threads at application priority has been used in user-level network subsystem implementations [10, 11, 23]. <p> To evaluate packet demultiplex-ing in the network adaptor (NI demux), we used instead the SBA-200 firmware developed by Cornell University's 9 QoS attributes or IPv6 flows could be used in an LRP based IP gateway to provide more fine-grained resource control. U-Net project <ref> [1] </ref>. This firmware performs demultiplex--ing based on the ATM virtual circuit identifier (VCI). A signaling scheme was used that ensures that a separate ATM VCI is assigned for traffic terminating or originating at each socket. <p> Furthermore, both BSD and LRP with our device driver perform significantly better than SunOS with the Fore ATM driver in terms of latency and UDP bandwidth. This is due to performance problems with the Fore driver, as discussed in detail in <ref> [1] </ref>. SunOS exhibits a performance anomaly that causes its base round-trip latencyas measured on otherwise idle machinesto drop by almost 300 secs, when a compute-bound background process is running on both the client and the server machine. <p> De-multiplexing immediately at the network interface point is necessary for maintaining network quality of service (QoS) [22], it enables user-level implementations of network subsystems [2, 7, 11, 21, 23], it facilitates copy-avoidance by allowing smart placement of data in main memory <ref> [1, 2, 5, 6] </ref>, and it allows proper resource accounting in the network subsystem [14, 19]. This paper argues that early demultiplexing also facilitates fairness and stability of network subsystems under conditions of overload. LRP uses early demultiplexing as a key component of its architecture. <p> To the best of our knowledge, the behavior of user-level network subsystems under overload has not been studied. U-Net <ref> [1] </ref> and Application Device Channels (ADC) [4, 5] share with NI-LRP the approach of using the network interface to demultiplex incoming packets and placing them on queues associated with communication endpoints. With U-Net and ADCs, the endpoint queues are mapped into the address space of application processes. <p> A user-level network subsystem's resilience to livelock depends then on the overhead of packet demultiplexing on the host. When demultiplexing and packet discard are performed by the NI as in <ref> [1, 5] </ref>, the system should be free of livelock. When these tasks are performed by the OS kernel as in [7, 11, 23], the rate at which the system experiences livelock depends on the overhead of packet demultiplexing (as in SOFT-LRP).
Reference: [2] <author> G. Buzzard, D. Jacobson, S. Marovich, and J. Wilkes. Hamlyn: </author> <title> A high-performance network interface with sender-based memory management. </title> <booktitle> In Proceedings of the Hot Interconnects III Symposium, </booktitle> <address> Palo Alto, CA, </address> <month> Aug. </month> <year> 1995. </year>
Reference-contexts: Many researchers have noted the importance of early demultiplexing to high-performance networking. De-multiplexing immediately at the network interface point is necessary for maintaining network quality of service (QoS) [22], it enables user-level implementations of network subsystems <ref> [2, 7, 11, 21, 23] </ref>, it facilitates copy-avoidance by allowing smart placement of data in main memory [1, 2, 5, 6], and it allows proper resource accounting in the network subsystem [14, 19]. <p> De-multiplexing immediately at the network interface point is necessary for maintaining network quality of service (QoS) [22], it enables user-level implementations of network subsystems [2, 7, 11, 21, 23], it facilitates copy-avoidance by allowing smart placement of data in main memory <ref> [1, 2, 5, 6] </ref>, and it allows proper resource accounting in the network subsystem [14, 19]. This paper argues that early demultiplexing also facilitates fairness and stability of network subsystems under conditions of overload. LRP uses early demultiplexing as a key component of its architecture.
Reference: [3] <author> R. P. Draves, B. N. Bershad, R. F. Rashid, and R. W. Dean. </author> <title> Using continuations to implement thread management and communication in operating systems. </title> <booktitle> In Proceedings of 13th ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 122-36. </pages> <institution> Association for Computing Machinery SIGOPS, </institution> <month> October </month> <year> 1991. </year>
Reference-contexts: Therefore, it is not necessary to assign a private runtime stack to the APP thread; a single per CPU stack can be used instead. The resulting per-process space overhead of APP is one thread control block. This overhead can be further reduced through the use of continuations <ref> [3] </ref>. The exact choice of a mechanism for APP greatly depends on the facilities available in a particular UNIX kernel. In our current prototype implementation, a kernel process is dedicated to TCP processing. 3.5 Other protocol processing Processing for certain network packets cannot be directly attributed to any application process.
Reference: [4] <author> P. Druschel. </author> <title> Operating systems support for high--speed networking. </title> <type> Technical Report TR 94-24, </type> <institution> Department of Computer Science, University of Ari-zona, </institution> <month> Oct. </month> <year> 1994. </year>
Reference-contexts: To the best of our knowledge, the behavior of user-level network subsystems under overload has not been studied. U-Net [1] and Application Device Channels (ADC) <ref> [4, 5] </ref> share with NI-LRP the approach of using the network interface to demultiplex incoming packets and placing them on queues associated with communication endpoints. With U-Net and ADCs, the endpoint queues are mapped into the address space of application processes.
Reference: [5] <author> P. Druschel, B. S. Davie, and L. L. Peterson. </author> <title> Experiences with a high-speed network adaptor: A software perspective. </title> <booktitle> In Proceedings of the SIG-COMM '94 Conference, </booktitle> <pages> pages 2-13, </pages> <address> London, UK, </address> <month> Aug. </month> <year> 1994. </year>
Reference-contexts: 1 Introduction Most work on operating system support for high-speed networks to date has focused on improving message latency and on delivering the network's full bandwidth to application programs <ref> [1, 5, 7, 21] </ref>. More recently, researchers have started to look at resource management issues in network servers such as LAN servers, firewall gateways, and WWW servers [16, 17]. <p> Demultiplexing in the network adaptor and multiple NI channels have been used to implement low-latency, high-bandwidth, user-level communication <ref> [1, 5] </ref>. Protocol processing by user-level threads at application priority has been used in user-level network subsystem implementations [10, 11, 23]. <p> De-multiplexing immediately at the network interface point is necessary for maintaining network quality of service (QoS) [22], it enables user-level implementations of network subsystems [2, 7, 11, 21, 23], it facilitates copy-avoidance by allowing smart placement of data in main memory <ref> [1, 2, 5, 6] </ref>, and it allows proper resource accounting in the network subsystem [14, 19]. This paper argues that early demultiplexing also facilitates fairness and stability of network subsystems under conditions of overload. LRP uses early demultiplexing as a key component of its architecture. <p> To the best of our knowledge, the behavior of user-level network subsystems under overload has not been studied. U-Net [1] and Application Device Channels (ADC) <ref> [4, 5] </ref> share with NI-LRP the approach of using the network interface to demultiplex incoming packets and placing them on queues associated with communication endpoints. With U-Net and ADCs, the endpoint queues are mapped into the address space of application processes. <p> A user-level network subsystem's resilience to livelock depends then on the overhead of packet demultiplexing on the host. When demultiplexing and packet discard are performed by the NI as in <ref> [1, 5] </ref>, the system should be free of livelock. When these tasks are performed by the OS kernel as in [7, 11, 23], the rate at which the system experiences livelock depends on the overhead of packet demultiplexing (as in SOFT-LRP).
Reference: [6] <author> P. Druschel and L. L. Peterson. Fbufs: </author> <title> A high-bandwidth cross-domain transfer facility. </title> <booktitle> In Proceedings of the Fourteenth ACM Symposium on Operating System Principles, </booktitle> <pages> pages 189-202, </pages> <month> Dec. </month> <year> 1993. </year>
Reference-contexts: In particular, it ensures fairness in the case where application processes receive high volumes of network traffic. Early demultiplexinga key component of LRP's designhas been used in many systems to support application-specific network protocols [11, 23], to avoid data copying <ref> [6, 21] </ref>, and to preserve network quality-of-service guarantees for real-time communication [10]. Demultiplexing in the network adaptor and multiple NI channels have been used to implement low-latency, high-bandwidth, user-level communication [1, 5]. <p> De-multiplexing immediately at the network interface point is necessary for maintaining network quality of service (QoS) [22], it enables user-level implementations of network subsystems [2, 7, 11, 21, 23], it facilitates copy-avoidance by allowing smart placement of data in main memory <ref> [1, 2, 5, 6] </ref>, and it allows proper resource accounting in the network subsystem [14, 19]. This paper argues that early demultiplexing also facilitates fairness and stability of network subsystems under conditions of overload. LRP uses early demultiplexing as a key component of its architecture.
Reference: [7] <author> A. Edwards, G. Watson, J. Lumley, D. Banks, C. Calamvokis, and C. Dalton. </author> <title> User-space protocols deliver high performance to applications on a low-cost gb/s LAN. </title> <booktitle> In Proceedings of the SIG-COMM '94 Conference, </booktitle> <pages> pages 14-23, </pages> <address> London, UK, </address> <month> Aug. </month> <year> 1994. </year>
Reference-contexts: 1 Introduction Most work on operating system support for high-speed networks to date has focused on improving message latency and on delivering the network's full bandwidth to application programs <ref> [1, 5, 7, 21] </ref>. More recently, researchers have started to look at resource management issues in network servers such as LAN servers, firewall gateways, and WWW servers [16, 17]. <p> Many researchers have noted the importance of early demultiplexing to high-performance networking. De-multiplexing immediately at the network interface point is necessary for maintaining network quality of service (QoS) [22], it enables user-level implementations of network subsystems <ref> [2, 7, 11, 21, 23] </ref>, it facilitates copy-avoidance by allowing smart placement of data in main memory [1, 2, 5, 6], and it allows proper resource accounting in the network subsystem [14, 19]. <p> With U-Net and ADCs, the endpoint queues are mapped into the address space of application processes. More conventional user-level networking subsystems <ref> [7, 11, 23] </ref> share with SOFT-LRP the early demulti-plexing of incoming packets by the OS kernel (software). Demultiplexed packets are then handed to the appropriate application process using an upcall. In all user-level network subsystems, protocol processing is performed by user-level threads. <p> When demultiplexing and packet discard are performed by the NI as in [1, 5], the system should be free of livelock. When these tasks are performed by the OS kernel as in <ref> [7, 11, 23] </ref>, the rate at which the system experiences livelock depends on the overhead of packet demultiplexing (as in SOFT-LRP). Since the systems described in the literature use interpreted packet filters for demultiplexing, the overhead is likely to be high, and livelock protection poor.
Reference: [8] <author> D. Engler and M. F. Kaashoek. DPF: </author> <title> Fast, flexible message demultiplexing using dynamic code generation. </title> <booktitle> In Proceedings of the SIGCOMM '96 Conference, </booktitle> <pages> pages 53-59, </pages> <address> Palo Alto, CA, </address> <month> Aug. </month> <year> 1996. </year>
Reference-contexts: Packet filters [12, 18, 25] are mechanisms that implement early demultiplexing without sacrificing layering and modularity in the network subsystem. In the most recent incarnations of packet filters, dynamic code generation is used to eliminate the overhead of the earlier interpreted versions <ref> [8] </ref>. Architecturally, the design of LRP is related to user-level network subsystems. Unlike LRP, the main goal of these prior works is to achieve low communication latency and high bandwidth by removing protection boundaries from the critical send/receive path, and/or by en abling application-specific customization of protocol services.
Reference: [9] <author> K. Jeffay. </author> <title> On Latency Management in Time-Shared Operating Systems. </title> <booktitle> In Proceedings of the 11th IEEE Workshop on Real-Time Operating Systems and Software, </booktitle> <pages> pages 86-90, </pages> <address> Seattle, WA, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: Livelock and other negative effects of BSD's interrupt-driven network processing model can be viewed as an instance of a priority inversion problem. The real-time OS community has developed techniques for avoiding priority inversion in communication systems in order to provide quality of service guarantees for real-time data streams <ref> [9, 10] </ref>. RT-Mach's network subsystem [10], which is based on the Mach user-level network implementation [11], performs early demultiplexing, and then hands incoming packets for processing to a real-time thread with a priority and resource reservation appropriate for the packet's stream.
Reference: [10] <author> C. Lee, K. Yoshida, C. Mercer, and R. Rajkumar. </author> <title> Predictable communication protocol processing in real-time Mach. </title> <booktitle> In the proceedings of IEEE Real-time Technology and Applications Symposium, </booktitle> <month> June </month> <year> 1996. </year>
Reference-contexts: Early demultiplexinga key component of LRP's designhas been used in many systems to support application-specific network protocols [11, 23], to avoid data copying [6, 21], and to preserve network quality-of-service guarantees for real-time communication <ref> [10] </ref>. Demultiplexing in the network adaptor and multiple NI channels have been used to implement low-latency, high-bandwidth, user-level communication [1, 5]. Protocol processing by user-level threads at application priority has been used in user-level network subsystem implementations [10, 11, 23]. <p> Demultiplexing in the network adaptor and multiple NI channels have been used to implement low-latency, high-bandwidth, user-level communication [1, 5]. Protocol processing by user-level threads at application priority has been used in user-level network subsystem implementations <ref> [10, 11, 23] </ref>. What is new in LRP's design is (1) the lazy, delayed processing of incoming network packets, and (2) the combination and application of the above techniques to provide stability, fairness, and increased throughput under high load. A full discussion of related work is given in Section 5. <p> Livelock and other negative effects of BSD's interrupt-driven network processing model can be viewed as an instance of a priority inversion problem. The real-time OS community has developed techniques for avoiding priority inversion in communication systems in order to provide quality of service guarantees for real-time data streams <ref> [9, 10] </ref>. RT-Mach's network subsystem [10], which is based on the Mach user-level network implementation [11], performs early demultiplexing, and then hands incoming packets for processing to a real-time thread with a priority and resource reservation appropriate for the packet's stream. <p> The real-time OS community has developed techniques for avoiding priority inversion in communication systems in order to provide quality of service guarantees for real-time data streams [9, 10]. RT-Mach's network subsystem <ref> [10] </ref>, which is based on the Mach user-level network implementation [11], performs early demultiplexing, and then hands incoming packets for processing to a real-time thread with a priority and resource reservation appropriate for the packet's stream.
Reference: [11] <author> C. Maeda and B. N. Bershad. </author> <title> Protocol service decomposition for high-performance networking. </title> <booktitle> In Proceedings of the Fourteenth ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 244-255, </pages> <year> 1993. </year>
Reference-contexts: In particular, it ensures fairness in the case where application processes receive high volumes of network traffic. Early demultiplexinga key component of LRP's designhas been used in many systems to support application-specific network protocols <ref> [11, 23] </ref>, to avoid data copying [6, 21], and to preserve network quality-of-service guarantees for real-time communication [10]. Demultiplexing in the network adaptor and multiple NI channels have been used to implement low-latency, high-bandwidth, user-level communication [1, 5]. <p> Demultiplexing in the network adaptor and multiple NI channels have been used to implement low-latency, high-bandwidth, user-level communication [1, 5]. Protocol processing by user-level threads at application priority has been used in user-level network subsystem implementations <ref> [10, 11, 23] </ref>. What is new in LRP's design is (1) the lazy, delayed processing of incoming network packets, and (2) the combination and application of the above techniques to provide stability, fairness, and increased throughput under high load. A full discussion of related work is given in Section 5. <p> Many researchers have noted the importance of early demultiplexing to high-performance networking. De-multiplexing immediately at the network interface point is necessary for maintaining network quality of service (QoS) [22], it enables user-level implementations of network subsystems <ref> [2, 7, 11, 21, 23] </ref>, it facilitates copy-avoidance by allowing smart placement of data in main memory [1, 2, 5, 6], and it allows proper resource accounting in the network subsystem [14, 19]. <p> With U-Net and ADCs, the endpoint queues are mapped into the address space of application processes. More conventional user-level networking subsystems <ref> [7, 11, 23] </ref> share with SOFT-LRP the early demulti-plexing of incoming packets by the OS kernel (software). Demultiplexed packets are then handed to the appropriate application process using an upcall. In all user-level network subsystems, protocol processing is performed by user-level threads. <p> When demultiplexing and packet discard are performed by the NI as in [1, 5], the system should be free of livelock. When these tasks are performed by the OS kernel as in <ref> [7, 11, 23] </ref>, the rate at which the system experiences livelock depends on the overhead of packet demultiplexing (as in SOFT-LRP). Since the systems described in the literature use interpreted packet filters for demultiplexing, the overhead is likely to be high, and livelock protection poor. <p> The real-time OS community has developed techniques for avoiding priority inversion in communication systems in order to provide quality of service guarantees for real-time data streams [9, 10]. RT-Mach's network subsystem [10], which is based on the Mach user-level network implementation <ref> [11] </ref>, performs early demultiplexing, and then hands incoming packets for processing to a real-time thread with a priority and resource reservation appropriate for the packet's stream. Like LRP, the system employs early demultiplexing, schedules protocol processing at a priority appropriate to the data's receiver, and charges resources to the receiver.
Reference: [12] <author> S. McCanne and V. Jacobson. </author> <title> The BSD packet filter: A new architecture for user-level packet capture. </title> <booktitle> In Proceedings of the USENIX '93 Winter Conference, </booktitle> <pages> pages 259-269, </pages> <month> Jan. </month> <year> 1993. </year>
Reference-contexts: This paper argues that early demultiplexing also facilitates fairness and stability of network subsystems under conditions of overload. LRP uses early demultiplexing as a key component of its architecture. Packet filters <ref> [12, 18, 25] </ref> are mechanisms that implement early demultiplexing without sacrificing layering and modularity in the network subsystem. In the most recent incarnations of packet filters, dynamic code generation is used to eliminate the overhead of the earlier interpreted versions [8].
Reference: [13] <author> M. K. McKusick, K. Bostic, M. J. Karels, and J. S. Quarterman. </author> <title> The Design and Implementation of the 4.4BSD Operating System. </title> <publisher> Addison-Wesley Publishing Company, </publisher> <year> 1996. </year>
Reference-contexts: Further results show increased fairness in resource allocation, traffic separation, and increased throughput under high load. The rest of this paper is organized as follows. Section 2 gives a brief overview of the network subsystem found in BSD UNIX-derived systems <ref> [13] </ref> and identifies problems that arise when a system of this type is used as a network server. The design of the LRP network architecture is presented in Section 3. Section 4 gives a quantitative performance evaluation of our prototype implementation. <p> Finally, we argue that these problems are important by discussing common sources of high network traffic. To simplify the discussion, we focus on the TCP/UDP/IP protocol suite, and on BSD-derived UNIX systems <ref> [13] </ref>. Similar problems arise with other protocol suites, in System V-derived UNIX systems, and in many commercial non-UNIX operating systems. Figure 1 illustrates the BSD networking architecture. 2.1 Overview On the receiving side, the arrival of a network packet is signaled by an interrupt.
Reference: [14] <author> J. C. </author> <title> Mogul. </title> <type> Personal communication, </type> <month> Nov. </month> <year> 1992. </year>
Reference-contexts: interface point is necessary for maintaining network quality of service (QoS) [22], it enables user-level implementations of network subsystems [2, 7, 11, 21, 23], it facilitates copy-avoidance by allowing smart placement of data in main memory [1, 2, 5, 6], and it allows proper resource accounting in the network subsystem <ref> [14, 19] </ref>. This paper argues that early demultiplexing also facilitates fairness and stability of network subsystems under conditions of overload. LRP uses early demultiplexing as a key component of its architecture.
Reference: [15] <author> J. C. Mogul. </author> <title> Network behavior of a busy web server and its clients. </title> <type> Technical Report WRL 95/5, </type> <institution> DEC Western Research Laboratory, </institution> <address> Palo Alto, CA, </address> <year> 1995. </year>
Reference-contexts: It should be noted that, independent of the use of LRP, an Internet server must limit the number of active connections to maintain stability. A related issue is how well LRP works with a large number of established connections, as has been observed on busy Internet servers <ref> [15] </ref>. SOFT-LRP uses one extra mbuf compared to 4.4BSD for each established TCP connection, so SOFT-LRP should scale well to large numbers of active connections. <p> affect NI-LRP's behavior in the normal case. a sufficiently large user community, a server could easily be subjected to such rates. 5 Related Work Experiences with DEC's 1994 California Election HTTP server reveal many of the problems of a conventional network subsystem architecture when used as a busy HTTP server <ref> [15] </ref>. Mogul [16] suggests that novel OS support may be required to satisfy the needs of busy servers. Mogul and Ramakrishnan [17] devise and evaluate a set of techniques for improving the overload behavior of an interrupt-driven network architecture.
Reference: [16] <author> J. C. Mogul. </author> <title> Operating system support for busy internet servers. </title> <booktitle> In Proceedings of the Fifth Workshop on Hot Topics in Operating Systems (HotOS-V), </booktitle> <address> Orcas Island, WA, </address> <month> May </month> <year> 1995. </year>
Reference-contexts: More recently, researchers have started to look at resource management issues in network servers such as LAN servers, firewall gateways, and WWW servers <ref> [16, 17] </ref>. <p> avoid known performance problems with 0 40 80 120 160 0 5000 10000 15000 20000 HTTP transfers per second SYN packet rate (pkts/sec) 4.4 BSD 3 3 3 3 3 3 SOFT-LRP + + + + + + + + + + + BSD's PCB lookup function in HTTP servers <ref> [16] </ref>, the TCP TIME WAIT period was set to 500ms, instead of the default 30 seconds. The test were run for long periods of time to ensure steady-state behavior. <p> Mogul <ref> [16] </ref> suggests that novel OS support may be required to satisfy the needs of busy servers. Mogul and Ramakrishnan [17] devise and evaluate a set of techniques for improving the overload behavior of an interrupt-driven network architecture.
Reference: [17] <author> J. C. Mogul and K. K. Ramakrishnan. </author> <title> Eliminating receive livelock in an interrupt-driven kernel. </title> <booktitle> In Proc. of the 1996 Usenix Technical Conference, </booktitle> <pages> pages 99-111, </pages> <year> 1996. </year>
Reference-contexts: More recently, researchers have started to look at resource management issues in network servers such as LAN servers, firewall gateways, and WWW servers <ref> [16, 17] </ref>. <p> Mogul [16] suggests that novel OS support may be required to satisfy the needs of busy servers. Mogul and Ramakrishnan <ref> [17] </ref> devise and evaluate a set of techniques for improving the overload behavior of an interrupt-driven network architecture. These techniques avoid receiver livelock by temporarily disabling hardware interrupts and using polling under conditions of overload. Disabling interrupts limits the interrupt rate and causes early packet discard by the network interface.
Reference: [18] <author> J. C. Mogul, R. F. Rashid, and M. J. Accetta. </author> <title> The packet filter: An efficient mechanism for user-level network code. </title> <booktitle> In Proceedings of the Eleventh ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 39-51, </pages> <month> Nov. </month> <year> 1987. </year>
Reference-contexts: This paper argues that early demultiplexing also facilitates fairness and stability of network subsystems under conditions of overload. LRP uses early demultiplexing as a key component of its architecture. Packet filters <ref> [12, 18, 25] </ref> are mechanisms that implement early demultiplexing without sacrificing layering and modularity in the network subsystem. In the most recent incarnations of packet filters, dynamic code generation is used to eliminate the overhead of the earlier interpreted versions [8].
Reference: [19] <author> A. B. Montz et al. </author> <title> Scout: A communications-oriented operating system. </title> <type> Technical Report TR 94-20, </type> <institution> Department of Computer Science, University of Arizona, </institution> <month> June </month> <year> 1994. </year>
Reference-contexts: interface point is necessary for maintaining network quality of service (QoS) [22], it enables user-level implementations of network subsystems [2, 7, 11, 21, 23], it facilitates copy-avoidance by allowing smart placement of data in main memory [1, 2, 5, 6], and it allows proper resource accounting in the network subsystem <ref> [14, 19] </ref>. This paper argues that early demultiplexing also facilitates fairness and stability of network subsystems under conditions of overload. LRP uses early demultiplexing as a key component of its architecture.
Reference: [20] <author> K. K. Ramakrishnan. </author> <title> Scheduling issues for interfacing to high speed networks. </title> <booktitle> In Proc. Globe-com'92 IEEE Global Telecommunications Conference, </booktitle> <pages> pages 622-626, </pages> <address> Orlando, FL, </address> <month> Dec. </month> <year> 1992. </year>
Reference-contexts: As a result, overheads associated with dispatching and handling of interrupts and increased context switching can limit the throughput of a server under load. Under high load from the network, the system can enter a state known as receiver livelock <ref> [20] </ref>. In this state, the system spends all of its resources processing incoming network packets, only to discard them later because no CPU time is left to service the receiving application programs. For instance, consider the behavior of the system under increasing load from incoming UDP packets 2 .
Reference: [21] <author> J. M. Smith and C. B. S. Traw. </author> <title> Giving applications access to Gb/s networking. </title> <journal> IEEE Network, </journal> <volume> 7(4) </volume> <pages> 44-52, </pages> <month> July </month> <year> 1993. </year>
Reference-contexts: 1 Introduction Most work on operating system support for high-speed networks to date has focused on improving message latency and on delivering the network's full bandwidth to application programs <ref> [1, 5, 7, 21] </ref>. More recently, researchers have started to look at resource management issues in network servers such as LAN servers, firewall gateways, and WWW servers [16, 17]. <p> In particular, it ensures fairness in the case where application processes receive high volumes of network traffic. Early demultiplexinga key component of LRP's designhas been used in many systems to support application-specific network protocols [11, 23], to avoid data copying <ref> [6, 21] </ref>, and to preserve network quality-of-service guarantees for real-time communication [10]. Demultiplexing in the network adaptor and multiple NI channels have been used to implement low-latency, high-bandwidth, user-level communication [1, 5]. <p> Many researchers have noted the importance of early demultiplexing to high-performance networking. De-multiplexing immediately at the network interface point is necessary for maintaining network quality of service (QoS) [22], it enables user-level implementations of network subsystems <ref> [2, 7, 11, 21, 23] </ref>, it facilitates copy-avoidance by allowing smart placement of data in main memory [1, 2, 5, 6], and it allows proper resource accounting in the network subsystem [14, 19].
Reference: [22] <author> D. L. Tennenhouse. </author> <title> Layered multiplexing considered harmful. </title> <editor> In H. Rudin and R. Williamson, editors, </editor> <booktitle> Protocols for High-Speed Networks, </booktitle> <pages> pages 143-148, </pages> <address> Amsterdam, 1989. </address> <publisher> North-Holland. </publisher>
Reference-contexts: A direct quantitative comparison between LRP and their system is difficult, because of differing hardware/software environments and benchmarks. Many researchers have noted the importance of early demultiplexing to high-performance networking. De-multiplexing immediately at the network interface point is necessary for maintaining network quality of service (QoS) <ref> [22] </ref>, it enables user-level implementations of network subsystems [2, 7, 11, 21, 23], it facilitates copy-avoidance by allowing smart placement of data in main memory [1, 2, 5, 6], and it allows proper resource accounting in the network subsystem [14, 19].
Reference: [23] <author> C. Thekkath, T. Nguyen, E. Moy, and E. Lazowska. </author> <title> Implementing network protocols at user level. </title> <booktitle> In Proceedings of the SIGCOMM '93 Symposium, </booktitle> <pages> pages 64-73, </pages> <month> Sept. </month> <year> 1993. </year>
Reference-contexts: In particular, it ensures fairness in the case where application processes receive high volumes of network traffic. Early demultiplexinga key component of LRP's designhas been used in many systems to support application-specific network protocols <ref> [11, 23] </ref>, to avoid data copying [6, 21], and to preserve network quality-of-service guarantees for real-time communication [10]. Demultiplexing in the network adaptor and multiple NI channels have been used to implement low-latency, high-bandwidth, user-level communication [1, 5]. <p> Demultiplexing in the network adaptor and multiple NI channels have been used to implement low-latency, high-bandwidth, user-level communication [1, 5]. Protocol processing by user-level threads at application priority has been used in user-level network subsystem implementations <ref> [10, 11, 23] </ref>. What is new in LRP's design is (1) the lazy, delayed processing of incoming network packets, and (2) the combination and application of the above techniques to provide stability, fairness, and increased throughput under high load. A full discussion of related work is given in Section 5. <p> Many researchers have noted the importance of early demultiplexing to high-performance networking. De-multiplexing immediately at the network interface point is necessary for maintaining network quality of service (QoS) [22], it enables user-level implementations of network subsystems <ref> [2, 7, 11, 21, 23] </ref>, it facilitates copy-avoidance by allowing smart placement of data in main memory [1, 2, 5, 6], and it allows proper resource accounting in the network subsystem [14, 19]. <p> With U-Net and ADCs, the endpoint queues are mapped into the address space of application processes. More conventional user-level networking subsystems <ref> [7, 11, 23] </ref> share with SOFT-LRP the early demulti-plexing of incoming packets by the OS kernel (software). Demultiplexed packets are then handed to the appropriate application process using an upcall. In all user-level network subsystems, protocol processing is performed by user-level threads. <p> When demultiplexing and packet discard are performed by the NI as in [1, 5], the system should be free of livelock. When these tasks are performed by the OS kernel as in <ref> [7, 11, 23] </ref>, the rate at which the system experiences livelock depends on the overhead of packet demultiplexing (as in SOFT-LRP). Since the systems described in the literature use interpreted packet filters for demultiplexing, the overhead is likely to be high, and livelock protection poor.
Reference: [24] <author> G. Wright and W. Stevens. </author> <title> TCP/IP Illustrated Volume 2. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1995. </year>
Reference-contexts: Note that LRP does not depend on a specific network adaptor or ATM networks. SOFT-LRP can be used with any network and NI. The LRP architecture was implemented as follows. We modified the TCP/UDP/IP network subsystem that comes with the 4.4 BSD-Lite distribution <ref> [24] </ref> to optionally implement LRP. The resulting code was then downloaded into the SunOS kernel as a loadable kernel module and attached to the socket layer as a new protocol family (PF LRP). A custom device driver was developed for the FORE network adaptor.
Reference: [25] <author> M. Yuhara, B. N. Bershad, C. Maeda, and J. E. Moss. </author> <title> Efficient packet demultiplexing for multiple endpoints and large messages. </title> <booktitle> In Winter 1994 Usenix Conference, </booktitle> <pages> pages 153-165, </pages> <month> Jan. </month> <year> 1994. </year>
Reference-contexts: This paper argues that early demultiplexing also facilitates fairness and stability of network subsystems under conditions of overload. LRP uses early demultiplexing as a key component of its architecture. Packet filters <ref> [12, 18, 25] </ref> are mechanisms that implement early demultiplexing without sacrificing layering and modularity in the network subsystem. In the most recent incarnations of packet filters, dynamic code generation is used to eliminate the overhead of the earlier interpreted versions [8].
References-found: 25

