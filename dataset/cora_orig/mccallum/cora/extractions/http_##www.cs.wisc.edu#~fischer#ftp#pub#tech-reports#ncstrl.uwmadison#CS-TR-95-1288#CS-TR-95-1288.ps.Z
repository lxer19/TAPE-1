URL: http://www.cs.wisc.edu/~fischer/ftp/pub/tech-reports/ncstrl.uwmadison/CS-TR-95-1288/CS-TR-95-1288.ps.Z
Refering-URL: http://www.cs.wisc.edu/~fischer/ftp/pub/tech-reports/ncstrl.uwmadison/CS-TR-95-1288/
Root-URL: http://www.cs.wisc.edu
Title: GOAL-ORIENTED MEMORY ALLOCATION IN DATABASE MANAGEMENT SYSTEMS  
Author: By Kurt Patrick Brown 
Degree: A DISSERTATION SUBMITTED IN PARTIAL FULFILLMENT OF THE REQUIREMENTS FOR THE DEGREE OF DOCTOR OF PHILOSOPHY (COMPUTER SCIENCES) at the  
Date: 1995  
Address: WISCONSIN MADISON  
Affiliation: UNIVERSITY OF  
Abstract-found: 0
Intro-found: 1
Reference: [Abbott 91] <author> R. K. Abbott, </author> <title> Scheduling Real-Time Transactions: A Performance Evaluation, </title> <type> PhD Thesis, </type> <institution> Princeton University, 1991 (Princeton CS TR-331-91). </institution>
Reference-contexts: Mechanisms very different from the ones presented in this thesis are required for real-time database systems <ref> [Abbott 91, Pang 94b] </ref>.
Reference: [Belady 66] <institution> A Study of Replacement Algorithms for a Virtual Storage Computer, IBM Systems Journal, </institution> <month> 5(2), </month> <year> 1966. </year>
Reference-contexts: To estimate hit rate as a function of memory, the Dynamic Tuning algorithm adopts observations from Belady's virtual memory study <ref> [Belady 66] </ref>, modeling the hit rate function as 1 a=M b , where M is the memory allocation and the constants a and b are specific to a particular combination of workload and buffer page replacement policy. <p> The concavity theorem says that the slope of the hit rate curve never increases as more memory is added to an optimal buffer replacement policy, where an optimal buffer replacement policy is defined as one that always chooses the least valuable page to replace (e.g. Belady's MIN algorithm <ref> [Belady 66] </ref>). While optimal replacement policies are not realizable in practice because they require knowledge of future reference patterns, it will be argued shortly that the behavior of industrial-strength DBMS replacement policies are optimal enough that hit rate concavity applies to them as well.
Reference: [Boral 90] <author> H. Boral et al, </author> <title> "Prototyping Bubba: A Highly Parallel Database System," </title> <journal> IEEE Trans. on Knowledge and Data Engineering, </journal> <volume> 2(1), </volume> <month> March </month> <year> 1990. </year>
Reference: [Bitton 83] <author> D. Bitton, D. DeWitt, C. Turbyfill, </author> <title> Benchmarking Database Systems A Systematic Approach, </title> <booktitle> Proc. 9th Int'l VLDB Conf, </booktitle> <address> Florence, Italy, </address> <month> October </month> <year> 1983. </year>
Reference-contexts: The DBMIN portion of the database is a subset of the original Wisconsin Benchmark Database <ref> [Bitton 83] </ref>, except that here we scale up the number of tuples in each relation by a factor of ten. The TPC-C benchmark represents an order-entry application for a wholesale distribution company. Its files and associated B+ tree indexes are summarized in Table 3.
Reference: [Brown 92] <author> K. Brown, M. Carey, D. Dewitt, M. Mehta, J. Naughton, </author> <title> Resource Allocation and Scheduling for Mixed Database Workloads, </title> <type> Computer Sciences Technical Report #1095, </type> <institution> Department of Computer Sciences, University of Wisconsin, Madison, </institution> <month> July </month> <year> 1992. </year>
Reference-contexts: In addition to the classic relational DBMS problem workload consisting of short transactions running concurrently with long decision support queries <ref> [Pirahesh 90, Brown 92, DeWitt 92] </ref>, we can expect to see workloads comprising an even wider range of resource demands and execution times in the future.
Reference: [Brown 93a] <author> K. Brown, M. Carey, M. Livny, </author> <title> Managing Memory to Meet Multiclass Workload Response Time Goals, </title> <booktitle> Proc. 19th Int'l VLDB Conf, </booktitle> <address> Dublin, Ireland, </address> <month> August </month> <year> 1993. </year>
Reference-contexts: Clearly, if automated goal-driven performance tuning for database management systems is to become a reality, comprehensive algorithms need to be developed and evaluated. The goal-oriented memory and MPL management algorithms presented in <ref> [Brown 93a] </ref>, [Brown 94], and [Brown 95] represent a step in the direction of goal-oriented DBMS resource allocation. <p> First, Section 4.1 reviews two previous goal-oriented disk buffer memory allocation algorithms, Dynamic Tuning [Chung 94] and Fragment Fencing <ref> [Brown 93a] </ref>, highlighting both their features and their limitations. Section 4.2 then presents the Class Fencing algorithm. Class Fencing is based on a concept called hit rate concavity, which allows it to be more responsive, stable, and robust (as compared to the previous algorithms), while remaining relatively simple to implement. <p> It is also difficult to determine if a curve-fitting estimate will be optimistic or 1 2.5% of the total buffer pool was the chunk size used in [Chung 94]. Similarly, Fragment Fencing caps its per-step changes in memory allocation at 10% of the buffer pool <ref> [Brown 93a] </ref>. 31 pessimistic. More complex, higher order functions have the same problem; the model equation will only give a good estimate for those hit rate curves that look similar to the model equation. <p> These minimum amounts are called target residencies and are analogous to a working set size for each fragment. When a class's hit rate needs to be increased by some amount, all of the fragments referenced by the class are sorted in order of decreasing class temperature <ref> [Copeland 88, Brown 93a] </ref>, which is their size-normalized access frequency (in references per page per second). <p> It is passive in the sense that it does not explicitly direct the appropriate pages into the buffer pool; it only prevents their ejection from the pool by the DBMS's native replacement policy. 4.1.4 Fragment Fencing Issues A potential problem with a fragment-oriented approach, as noted in <ref> [Brown 93a] </ref>, is what happens when references within a fragment are not uniform. Since Fragment Fencing measures the actual hit rates of each fragment, it can easily test for violations of the uniform reference assumption by comparing the estimated hit rate to the actual hit rate. <p> Another problem with Fragment Fencing has to do with its passive memory allocation mechanism. Keeping the DBMS's replacement policy in the dark with regard to which buffer frames are fenced or not provides a high degree of independence from the underlying replacement policy <ref> [Brown 93a] </ref>; unfortunately, it also has the potential for significant overhead. Because the replacement policy is unaware of which frames are 33 fenced, it is forced to waste time inspecting frames that seem like good candidates only to be overruled by Fragment Fencing. <p> For index pages themselves, it is possible to use reference frequency statistics or information about the last few references to insure that more valuable index pages are not replaced by less valuable index pages <ref> [Copeland 88, O'Neil 93, Brown 93a] </ref>. <p> Both goal and no-goal classes were allowed to use disk buffer frames from the global 1 An earlier version of M&M that was paired with the Fragment Fencing controller <ref> [Brown 93a] </ref> for disk buffer classes was described and analyzed in both [Brown 94] and [Mehta 94]. 56 pool, but if a goal class could not meet its goal simply by competing for frames in the global pool, a local pool was set aside for its private use in addition to <p> Developing a controller that uses two knobs (memory and MPL) to control a class is much more difficult than developing one that adjusts only a single knob (such as those in <ref> [Brown 93a] </ref>, [Mehta 93], and [Chung 94]). The search space for a single-knob controller is one dimensional; the only decision required is whether to turn the knob up or down. With two knobs, the controller is faced with a two-dimensional search space.
Reference: [Brown 93b] <author> K. Brown, M. Carey, M. Livny, </author> <title> Towards an Autopilot in the DBMS Performance Cockpit, </title> <booktitle> Proc. 5th Int'l High Performance Transaction Processing Workshop, Asilomar, </booktitle> <address> CA, </address> <month> September </month> <year> 1993. </year>
Reference-contexts: As the complexity of database systems is increasing, while their cost is declining at the same time, manually adjusting low-level DBMS performance knobs will become increasingly impractical, as has been argued previously <ref> [Nikolaou 92, Brown 93b, Selinger 93, Weikum 93] </ref>. Ideally, the DBMS should simply accept per-class performance goals as inputs, and it should adjust its own low-level knobs in order to achieve them; this self-tuning capability is called goal-oriented resource allocation [Nikolaou 92]. <p> The idea is not to eliminate all knobs in order to develop a self-tuning DBMS that always knows what's best in any situation (an elusive goal, to be sure), but rather to hide the low-level knobs behind an autopilot <ref> [Brown 93b] </ref> that can translate high-level performance requirements into low-level knob settings. Because this thesis concentrates on the mechanisms needed to achieve this objective for three specific knobs, the user-interface it presents leaves something to be desired.
Reference: [Brown 94] <author> K. Brown, M. Mehta, M. Carey, M. Livny, </author> <title> Towards Automated Performance Tuning for Complex Workloads, </title> <booktitle> Proc. 20th Int'l VLDB Conf, </booktitle> <address> Santiago, Chile, </address> <month> September </month> <year> 1994. </year>
Reference-contexts: Clearly, if automated goal-driven performance tuning for database management systems is to become a reality, comprehensive algorithms need to be developed and evaluated. The goal-oriented memory and MPL management algorithms presented in [Brown 93a], <ref> [Brown 94] </ref>, and [Brown 95] represent a step in the direction of goal-oriented DBMS resource allocation. <p> Both goal and no-goal classes were allowed to use disk buffer frames from the global 1 An earlier version of M&M that was paired with the Fragment Fencing controller [Brown 93a] for disk buffer classes was described and analyzed in both <ref> [Brown 94] </ref> and [Mehta 94]. 56 pool, but if a goal class could not meet its goal simply by competing for frames in the global pool, a local pool was set aside for its private use in addition to any global frames it managed to obtain.
Reference: [Brown 95] <author> K. Brown, M. Carey, M. Livny, </author> <title> Goal-Oriented Buffer Management Revisited, </title> <note> submitted for publication, </note> <month> July, </month> <year> 1994. </year>
Reference-contexts: Clearly, if automated goal-driven performance tuning for database management systems is to become a reality, comprehensive algorithms need to be developed and evaluated. The goal-oriented memory and MPL management algorithms presented in [Brown 93a], [Brown 94], and <ref> [Brown 95] </ref> represent a step in the direction of goal-oriented DBMS resource allocation.
Reference: [Chen 93] <author> C. Chen, N. Roussopoulos, </author> <title> Adaptive Database Buffer Allocation Using Query Feedback, </title> <booktitle> Proc. 19th Int'l VLDB Conf, </booktitle> <address> Dublin, Ireland, </address> <month> August </month> <year> 1993. </year>
Reference-contexts: Estimate E2 predicts a required memory allocation of M3. With one more estimate using points O2 and O3, the target hit 5 A straight line approximation of buffer hit rate functions was also used in <ref> [Chen 93] </ref> to predict a memory allocation that maximizes marginal gain [Ng 91]. 37 rate is achieved. If any estimate's line were to cross the M max limit instead of the target hit rate, then the target hit rate is unachievable.
Reference: [Carey 85] <author> M. Carey, M. Livny, and H. Lu, </author> <title> "Dynamic Task Allocation in a Distributed Database System," </title> <booktitle> Proc. of the Fifth Int'l. Conf. on Distributed Computing Systems, </booktitle> <address> Denver, CO, </address> <month> May </month> <year> 1985. </year>
Reference-contexts: The research literature on multiclass resource allocation has proposed methods for distribution of scarce resources that are based on the notion of uniform performance degradation across all classes, either relative to some theoretical optimal performance <ref> [Carey 85, Mehta 93, Davison 95] </ref> or relative to explicitly stated performance goals [Nikolaou 92, Ferg 93, Chung 94]. However, it is likely that administrators will want much more control in determining how much each class suffers in a degraded mode of operation [Pang 95]. <p> However, its emphasis was on self-tuning algorithms that optimized system-wide objectives, and it did not specifically address the problem of achieving per-class performance goals. 1 A similar objective function was actually introduced much earlier, in <ref> [Carey 85] </ref>, in the context of work related to load balancing for distributed database queries. 23 2.3.4 Today's State of the Art In summary, we note that very few examples of goal-oriented resource management algorithms exist in the literature.
Reference: [Carey 89] <author> M. Carey, R. Jauhari, M. Livny, </author> <title> Priority in DBMS Resource Scheduling, </title> <booktitle> Proc. 15th Int'l. VLDB Conf., </booktitle> <address> Amsterdam, The Netherlands, </address> <month> August </month> <year> 1989. </year>
Reference-contexts: For example, they may want to order classes by their perceived importance so that more important classes receive whatever resources are available and only the less important classes suffer [Nikolaou 92]. More well-understood priority-based allocation techniques can be used to solve this problem (e.g. <ref> [Carey 89, Jauhari 90a, Jauhari 90b] </ref>). Even if one assumes a non-degraded steady-state mode of operation, of course it is still important to be able to detect unachievable goals.
Reference: [Cheng 84] <author> J. Cheng et al, </author> <title> IBM Database 2 Performance: Design, Implementation, and Tuning, </title> <journal> IBM Systems Journal, </journal> <volume> 23(2), </volume> <year> 1984. </year>
Reference-contexts: While it would be impossible to offer any definitive statement about the likelihood of hit rate knees in real-world buffer managers, we conducted a small empirical study of two simulated buffer managers, one modeled after DB2/MVS <ref> [Cheng 84, Teng 84, IBM 93a] </ref> and the other modeled after DB2/6000 [IBM 93b].
Reference: [Chou 85] <author> H. Chou and D. DeWitt, </author> <title> An Evaluation of Buffer Management Strategies for Relational Database Systems, </title> <booktitle> Proc. 11th Int'l VLDB Conf., </booktitle> <address> Stockholm, Sweden, </address> <month> August </month> <year> 1985. </year>
Reference-contexts: For both of these buffer managers, the hit rate functions were mapped for both the TPC A/B and C benchmarks, as well as for all of the canonical database reference patterns documented in the DBMIN Query Locality Set Model <ref> [Chou 85] </ref>. None of the observed hit rate functions showed a knee. <p> If all classes can meet their goals with the existing allocation mechanism, then no local buffer managers exist and the system's behavior is indistinguishable from that of a non-goal-oriented system. 6 A similar sharing technique was used by the DBMIN algorithm <ref> [Chou 85] </ref>. Class Fencing differs from that approach in that DBMIN partitioned memory on the basis of file instances and used a different replacement policy for each instance. <p> All the workloads in this section are formed using various combinations of three workload classes that have been previously defined elsewhere: the TPC-C benchmark from the Transaction Processing Council [TPC 94], and two query types from a previously published performance study of the DBMIN buffer management algorithm <ref> [Chou 85] </ref>. A 24 MB, eight disk version of the simulated DBMS described in Chapter 3 is used to run the workloads. <p> 4.8 - U Table 3: Database characteristics The database model consists of a two-part database, with one part taken directly from the TPC-C benchmark [TPC 94] using a scale factor of one (one warehouse), and the other drawn from a previously published performance study of the DBMIN buffer management algorithm <ref> [Chou 85] </ref>. The DBMIN portion of the database is a subset of the original Wisconsin Benchmark Database [Bitton 83], except that here we scale up the number of tuples in each relation by a factor of ten. The TPC-C benchmark represents an order-entry application for a wholesale distribution company. <p> DBMIN Query 2 (Q2): The Q2 class is a non-clustered index scan of DBMIN file A with a 1% selectivity 45 <ref> [Chou 85] </ref>. Because file A and its index can fit entirely in memory, this class is very sensitive to its buffer hit rate and is therefore more easily controlled than the TPC-C class. <p> The Q2 class is configured with a relatively small number of terminals (10) and exhibits a low degree of response time variance. DBMIN Query 3 (Q3): The Q3 class is an index nested loops join of DBMIN files A and B <ref> [Chou 85] </ref>. File A is scanned using a clustered index with a 2% selectivity, and file B is scanned directly. When Q2 and Q3 are running together in the same workload, they share the common file A, causing their performance to be somewhat linked.
Reference: [Chou 85b] <author> H. Chou, </author> <title> Buffer Management of Database Systems, </title> <type> PhD Thesis, </type> <institution> University of Wisconsin, Madi-son, </institution> <year> 1985. </year>
Reference: [Chu 72] <author> W. Chu and H. Opderbeck, </author> <title> The Page Fault Frequency Replacement Algorithm, </title> <booktitle> Proc. 1972 AFIPS Fall Joint Computer Conf., </booktitle> <volume> Vol 41, </volume> <publisher> AFIPS Press, </publisher> <address> Montvale, NJ, </address> <month> Dec. </month> <year> 1972. </year>
Reference: [Chung 94] <author> J. Chung, D. Ferguson, G. Wang, C. Nikolaou, J. Teng, </author> <title> Goal Oriented Dynamic Buffer Pool Management for Database Systems, </title> <institution> IBM Research Report RC19807, </institution> <month> October, </month> <year> 1994. </year> <month> 91 </month>
Reference-contexts: The research literature on multiclass resource allocation has proposed methods for distribution of scarce resources that are based on the notion of uniform performance degradation across all classes, either relative to some theoretical optimal performance [Carey 85, Mehta 93, Davison 95] or relative to explicitly stated performance goals <ref> [Nikolaou 92, Ferg 93, Chung 94] </ref>. However, it is likely that administrators will want much more control in determining how much each class suffers in a degraded mode of operation [Pang 95]. <p> Rather, they need only determine the correct relative response times when comparing between different routing possibilities. The second offshoot from [Nikolaou 92] was an algorithm, called Dynamic Tuning <ref> [Chung 94] </ref>, for goal-oriented multi-class disk buffer allocation. Dynamic Tuning is also a feedback-based algorithm with a system-wide orientation (their system-wide observation interval is called a tuning interval). <p> First, Section 4.1 reviews two previous goal-oriented disk buffer memory allocation algorithms, Dynamic Tuning <ref> [Chung 94] </ref> and Fragment Fencing [Brown 93a], highlighting both their features and their limitations. Section 4.2 then presents the Class Fencing algorithm. <p> This abstract framework will be used in the remainder of this section to describe the Dynamic Tuning and Fragment Fencing algorithms, and it will be used again in Section 4.2 to explain the new Class Fencing algorithm. 29 4.1.1 Dynamic Tuning Description The Dynamic Tuning algorithm <ref> [Chung 94] </ref> differs from other goal-oriented algorithms ([Ferg 93, Brown 93a, Brown 94]) in one important respect: response time goals are specified with respect to low-level buffer management requests (i.e., in terms of target service times for individual get page requests) as opposed to overall transaction response times. <p> Whatever the model equation, any real curve that doesn't fit the model will be estimated with low accuracy. It is also difficult to determine if a curve-fitting estimate will be optimistic or 1 2.5% of the total buffer pool was the chunk size used in <ref> [Chung 94] </ref>. Similarly, Fragment Fencing caps its per-step changes in memory allocation at 10% of the buffer pool [Brown 93a]. 31 pessimistic. <p> This approach is simple and effective for classes that do not share data, but some provision needs to be made for classes that do share buffer pages. Sharing is not discussed in <ref> [Chung 94] </ref>. 4.1.3 Fragment Fencing Description Fragment Fencing's response time estimator makes the simplifying assumption that response time and buffer miss rate are directly proportional. <p> Developing a controller that uses two knobs (memory and MPL) to control a class is much more difficult than developing one that adjusts only a single knob (such as those in [Brown 93a], [Mehta 93], and <ref> [Chung 94] </ref>). The search space for a single-knob controller is one dimensional; the only decision required is whether to turn the knob up or down. With two knobs, the controller is faced with a two-dimensional search space.
Reference: [Coffman 73] <author> E. Coffman and P. Denning, </author> <title> Operating Systems Theory, </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs NJ, </address> <year> 1973. </year>
Reference: [Copeland 88] <author> G. Copeland, W. Alexander, E. Boughter, T. Keller, </author> <title> Data Placement in Bubba, </title> <booktitle> Proc. ACM SIGMOD '88 Conf., </booktitle> <address> Chicago, IL, </address> <month> June </month> <year> 1988. </year>
Reference-contexts: These minimum amounts are called target residencies and are analogous to a working set size for each fragment. When a class's hit rate needs to be increased by some amount, all of the fragments referenced by the class are sorted in order of decreasing class temperature <ref> [Copeland 88, Brown 93a] </ref>, which is their size-normalized access frequency (in references per page per second). <p> For index pages themselves, it is possible to use reference frequency statistics or information about the last few references to insure that more valuable index pages are not replaced by less valuable index pages <ref> [Copeland 88, O'Neil 93, Brown 93a] </ref>.
Reference: [Cornell 89] <author> D. Cornell and P. Yu, </author> <title> Integration of Buffer Management and Query Optimization in a Relational Database Environment, </title> <booktitle> Proc. 15th Int'l VLDB Conf., </booktitle> <address> Amsterdam, The Netherlands, </address> <month> August </month> <year> 1989. </year>
Reference: [Dan 95] <author> A. Dan, P.S. Yu, J.-Y. Chung, </author> <title> Characterization of Database Access Pattern for Analytic Prediction of Buffer Hit Probability, </title> <journal> VLDB Journal, </journal> <volume> 4(1), </volume> <month> January </month> <year> 1995. </year>
Reference-contexts: To our knowledge, no one has explicitly stated it in the form we do here, although some previous work has exploited the notion of concavity in any case <ref> [Dan 95] </ref>. 3 This notion of page value is synonymous with the concept of marginal gain defined in [Ng 91]. 35 knowledge of the total number of pages that will be scanned [Stone 81]. <p> None of the observed hit rate functions showed a knee. Additional empirical evidence for concavity is provided by Dan et al <ref> [Dan 95] </ref>, where hit rate functions derived from actual traces of DB2/MVS customers were also seen to be free of knees. 4 This is certainly true for relational systems, but less so for object-oriented systems that support navigational access. 36 While acknowledging that hit rate function knees are possible in the
Reference: [Davison 94] <author> D. Davison, G. Graefe, </author> <title> Memory-Contention Responsive Hash Joins, </title> <booktitle> Proc. 20th Int'l VLDB Conf, </booktitle> <address> Santiago, Chile, </address> <month> September </month> <year> 1994. </year>
Reference-contexts: Not only are the admission and initial allocation of query operators determined by a bidding process, but their allocations may also be dynamically adjusted in-flight in order to insure that resources are always being used by the highest bidder (i.e. adaptive query processing algorithms <ref> [Pang 93a, Pang 93b, Davison 94] </ref> are exploited in this scheme). While both Broker M and Broker M D were shown to outperform the adaptive algorithm of [Mehta 93], it is not clear how such an approach could be used for goal-oriented allocation. <p> One way to address the problem of goal-class memory waits is to implement memory adaptive query operators, such as those described in <ref> [Zeller 90, Pang 93a, Pang 93b, Davison 94] </ref>, that can dynamically adjust their working storage requirements during the execution of the operation. Using these algorithms, the no-goal class can be throttled back to the new, smaller global pool size.
Reference: [Davison 95] <author> D. Davison, G. Graefe, </author> <title> Dynamic Resource Brokering for Multi-User Query Execution, </title> <booktitle> Proc. ACM SIGMOD Conf, </booktitle> <address> San Jose, CA, </address> <month> May </month> <year> 1995. </year>
Reference-contexts: The research literature on multiclass resource allocation has proposed methods for distribution of scarce resources that are based on the notion of uniform performance degradation across all classes, either relative to some theoretical optimal performance <ref> [Carey 85, Mehta 93, Davison 95] </ref> or relative to explicitly stated performance goals [Nikolaou 92, Ferg 93, Chung 94]. However, it is likely that administrators will want much more control in determining how much each class suffers in a degraded mode of operation [Pang 95]. <p> The adaptive algorithm is also feedback based and uses a system-wide orientation. Another technique for allocating memory and controlling admission for multi-user query workloads is the dynamic resource broker approach of <ref> [Davison 95] </ref>. [Davison 95] describes two algorithms, Broker M , and Broker M D, that allocate resources to the highest bidding query operator (Broker M allocates memory only, and Broker M D allocates both memory and disk bandwidth). <p> The adaptive algorithm is also feedback based and uses a system-wide orientation. Another technique for allocating memory and controlling admission for multi-user query workloads is the dynamic resource broker approach of <ref> [Davison 95] </ref>. [Davison 95] describes two algorithms, Broker M , and Broker M D, that allocate resources to the highest bidding query operator (Broker M allocates memory only, and Broker M D allocates both memory and disk bandwidth).
Reference: [DeWitt 84] <author> D. DeWitt et al, </author> <title> "Implementation Techniques for Main Memory Database Systems," </title> <booktitle> Proc. ACM SIGMOD Conf., </booktitle> <address> Boston, MA, </address> <month> June </month> <year> 1984. </year>
Reference-contexts: experiments will be presented in the performance evaluation sections of Chapters 4 and 5. 3.3 Workload Model The simulated workloads used in the performance evaluation sections of Chapters 4 and 5 are various combinations of single-tuple index selects, full file scans, index scans, index nested-loop joins and hybrid hash joins <ref> [DeWitt 84] </ref>. Since the simulator used in this thesis was originally built to model a parallel shared-nothing database system, all operators in a query tree run in parallel within their own lightweight processes and communicate with each other using a message passing paradigm. <p> The configuration consists of a single 30 MIP processor, 8 MB of memory, and eight disks. 4 The workload consists of three classes: queries, transactions, and big queries. The query class is a consumer of working storage memory. It consists of hybrid hash join queries <ref> [DeWitt 84] </ref> whose performance is related to the amount of memory allocated for their in-memory join hash tables. <p> Because a min query requires many more I/Os than one running at its maximum memory requirement (roughly three times as many in the case of a hash join <ref> [DeWitt 84] </ref>), any increase in the probability of a minimum allocation for the queries of a given class will necessarily increase the class's average execution time (i.e. response time minus waiting time). <p> The query class models a working storage class with longer execution times (tens of seconds or minutes). The individual queries consist of binary hybrid hash joins of two randomly chosen query files (see Table 12). The hybrid hash join algorithm <ref> [DeWitt 84] </ref> is used here because it is generally accepted as a good ad hoc join method. Allocating the maximum amount of memory to a join query will allow it to execute with the minimum number of I/Os, i.e. with a single scan of each relation.
Reference: [DeWitt 90] <author> D. DeWitt et al, </author> <title> "The Gamma Database Machine Project," </title> <journal> IEEE Trans. on Knowledge and Data Engineering, </journal> <volume> 2(1), </volume> <month> March </month> <year> 1990. </year>
Reference-contexts: Table 2 shows the simulated instruction counts used in experiments throughout this thesis; they are based on measurements taken from the Gamma parallel database system prototype <ref> [DeWitt 90] </ref>. 27 Function # Instructions read a record from buffer page 300 write a record to buffer page 100 insert an entry in hash table 100 probe a hash table 200 test an index entry 50 copy an 8K msg 10000 start an I/O 5000 apply a predicate 100 initiate
Reference: [DeWitt 92] <author> D. DeWitt and J. Gray, </author> <title> Parallel Database Systems: The Future of High Performance Database Processing, </title> <journal> CACM, </journal> <volume> 35(6), </volume> <month> June, </month> <year> 1992. </year>
Reference-contexts: In addition to the classic relational DBMS problem workload consisting of short transactions running concurrently with long decision support queries <ref> [Pirahesh 90, Brown 92, DeWitt 92] </ref>, we can expect to see workloads comprising an even wider range of resource demands and execution times in the future.
Reference: [Denning 80] <author> P. Denning, </author> <title> Working Sets Past and Present, </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-6(1), </volume> <month> January </month> <year> 1980. </year>
Reference: [Easton 75] <author> W. Easton, </author> <title> Model for Interactive Data Base Reference String, </title> <journal> IBM Journal of Research and Development, </journal> <volume> 19(6), </volume> <month> November </month> <year> 1975. </year>
Reference: [Easton 79] <author> M. Easton, P. Franaszek, </author> <title> Use Bit Scanning in Replacement Decisions, </title> <journal> IEEE Transactions on Computing, </journal> <volume> 28(2), </volume> <month> February </month> <year> 1979. </year>
Reference: [Effel 84] <author> W. Effelsberg and T. Haerder, </author> <title> Principles of Database Buffer Management, </title> <journal> ACM TODS, </journal> <volume> 9(4), </volume> <month> Dec. </month> <year> 1984. </year>
Reference: [Falou 91] <author> C. Faloutsos, R. Ng, T. Sellis, </author> <title> Predictive Load Control for Flexible Buffer Allocation, </title> <booktitle> Proc. 17th Int'l VLDB Conf., </booktitle> <address> Barcelona, Spain, </address> <month> September </month> <year> 1991. </year>
Reference: [Ferg 93] <author> D. Ferguson, C. Nikolaou, L. Geargiadis, </author> <title> Goal Oriented, Adaptive Transaction Routing for High Performance Transaction Processing Systems, </title> <booktitle> Proc. 2nd Int'l Conf. on Parallel and Distributed Systems, </booktitle> <address> San Diego CA, </address> <month> January </month> <year> 1993. </year>
Reference-contexts: Response time metrics can be specified as average, maximum, or percentile values. Combinations of multiple metrics are also common, such as a target throughput that is subject to a maximum or a 90th percentile response time constraint. Following other work in this area <ref> [Nikolaou 92, Ferg 93] </ref>, this thesis will adopt an average response time metric. Average response times are not only a commonly used performance metric in themselves, but they are also easily converted into average throughput metrics, given the number of attached terminals (clients) and their average think times. <p> The research literature on multiclass resource allocation has proposed methods for distribution of scarce resources that are based on the notion of uniform performance degradation across all classes, either relative to some theoretical optimal performance [Carey 85, Mehta 93, Davison 95] or relative to explicitly stated performance goals <ref> [Nikolaou 92, Ferg 93, Chung 94] </ref>. However, it is likely that administrators will want much more control in determining how much each class suffers in a degraded mode of operation [Pang 95]. <p> This is the same value that was used in the goal-oriented transaction routing algorithm of <ref> [Ferg 93] </ref>. Exponential weighting is ideal when a class is in steady state; in this case it is desirable to avoid resource allocation changes in response to the natural statistical fluctuations of a class. <p> The work from this group spawned several algorithms that we 21 review in this section and that influenced subsequent releases of MVS as well as IBM's CICS TP Monitor. The first offshoot of [Nikolaou 92] was a pair of algorithms for goal-oriented transaction routing in distributed transaction processing systems <ref> [Ferg 93] </ref>. These two algorithms are feedback-based and use a system-wide orientation. Both algorithms attempt to predict the effect of a transaction routing decision on the response times of each transaction class. <p> Chapter 4. 2.3.3 Other Related Work While it does not specifically accept response time goals, the adaptive memory allocation and MPL adjustment algorithm described in [Mehta 93] is relevant here because its objective of maximizing fairness is very close to the objective of the goal-oriented transaction routing algorithms described in <ref> [Ferg 93] </ref>.
Reference: [Fujitsu 90] <author> Fujistsu America, Inc. </author> <title> M2265 Technical Manual, part number 41FH5048E-01, </title> <institution> Fujistsu America Technical Assistance Center, </institution> <address> San Jose, CA, 1-800-826-6112. </address>
Reference-contexts: In all cases, the number of terminals is chosen to provide average disk utilizations in the range of 50 to 60%. The simulated hardware configuration contains eight disks that are modeled after the Fujitsu Model M2266 (1 GB, 5.25) disk drive <ref> [Fujitsu 90] </ref>. While the simulated disks include a model of the actual Fujitsu disk cache, the simulated disk caches are disabled in this thesis as a result of our prior experience in prototyping goal-oriented algorithms in DB2/6000 (IBM's relational database for Unix [IBM 93b]).
Reference: [Graefe 89] <author> G. Graefe and K. Ward, </author> <title> Dynamic Query Evaluation Plans, </title> <booktitle> Proc. ACM SIGMOD '89 Conf., </booktitle> <address> Portland, OR, </address> <month> May </month> <year> 1989. </year>
Reference: [Gray 87] <author> J. Gray and F. Putzolu, </author> <title> The 5 Minute Rule for Trading Memory for Disk Access and the 10 Byte Rule for Trading Memory for CPU Time, </title> <booktitle> Proc. ACM SIGMOD '87 Conf., </booktitle> <address> San Francisco, CA, </address> <year> 1987. </year>
Reference: [Gray 91] <author> J. Gray ed., </author> <title> The Benchmark Handbook, </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo CA, </address> <year> 1991. </year> <month> 92 </month>
Reference: [Haas 90] <author> L. Haas et al, </author> <title> Starburst Mid-Flight: As the Dust Clears, </title> <journal> IEEE Trans. on Knowledge and Data Eng., </journal> <volume> 2(1), </volume> <month> March </month> <year> 1990. </year>
Reference-contexts: Random accesses to pages are generally made via indexes, 4 and there are a number of techniques available to insure that more valuable index pages are not replaced by less valuable data pages <ref> [Haas 90, O'Neil 93, Johnson 94] </ref>. For index pages themselves, it is possible to use reference frequency statistics or information about the last few references to insure that more valuable index pages are not replaced by less valuable index pages [Copeland 88, O'Neil 93, Brown 93a].
Reference: [Hong 91] <author> W. Hong and M. Stonebraker, </author> <title> Optimization of Parallel Query Execution Plans in XPRS, </title> <booktitle> Proc. 1st Int'l PDIS Conf., </booktitle> <address> Miami, FL, </address> <month> Dec. </month> <year> 1991. </year>
Reference-contexts: While there has been no published work to date on query optimization techniques for satisfying multiclass performance goals, some early work has been done on run-time selection of query plans based on resource availability <ref> [Hong 91, Ioannidis 92] </ref>.
Reference: [IBM 93a] <author> IBM Corporation, </author> <title> IBM Database 2 Version 3 Performance Monitoring and Tuning SC26-4888, </title> <institution> IBM Corporation, </institution> <address> San Jose CA, </address> <month> December </month> <year> 1993. </year>
Reference-contexts: The buffer pool consists of a set of main memory page frames of 8K bytes each. The buffer manager is modeled after that of DB2/MVS <ref> [Teng 84, IBM 93a] </ref>. <p> While it would be impossible to offer any definitive statement about the likelihood of hit rate knees in real-world buffer managers, we conducted a small empirical study of two simulated buffer managers, one modeled after DB2/MVS <ref> [Cheng 84, Teng 84, IBM 93a] </ref> and the other modeled after DB2/6000 [IBM 93b].
Reference: [IBM 93b] <institution> IBM Corporation, Database 2 AIX/6000 Administration Guide SC09-1571, IBM Corporation, </institution> <address> North York, Ontario, Canada, </address> <month> October </month> <year> 1993. </year>
Reference-contexts: While the simulated disks include a model of the actual Fujitsu disk cache, the simulated disk caches are disabled in this thesis as a result of our prior experience in prototyping goal-oriented algorithms in DB2/6000 (IBM's relational database for Unix <ref> [IBM 93b] </ref>). This prototyping work 25 showed that the simulator's disk cache hit rates were much higher than those observed in the real system. <p> For example, if 80% of the buffer pool is fenced off in order to achieve aggressive response time goals, then 80% of the candidate pages for replacement will be overruled. This problem is particularly troublesome for clock-based replacement policies (like that of DB2/6000 <ref> [IBM 93b] </ref>) because fenced frames may cluster together physically in the buffer table; when the clock hand moves into such a cluster, it may have to inspect a large number of consecutive frames before finding one that can be replaced. <p> While it would be impossible to offer any definitive statement about the likelihood of hit rate knees in real-world buffer managers, we conducted a small empirical study of two simulated buffer managers, one modeled after DB2/MVS [Cheng 84, Teng 84, IBM 93a] and the other modeled after DB2/6000 <ref> [IBM 93b] </ref>. For both of these buffer managers, the hit rate functions were mapped for both the TPC A/B and C benchmarks, as well as for all of the canonical database reference patterns documented in the DBMIN Query Locality Set Model [Chou 85].
Reference: [IBM 93c] <institution> IBM Corporation, </institution> <note> MVS/ESA Version 4.3 Initialization and Tuning Guide GC28-1643, </note> <institution> IBM Corporation, </institution> <address> Poughkeepsie NY, </address> <month> March </month> <year> 1993. </year>
Reference-contexts: However, IBM's MVS operating system has provided goal-oriented resource allocation facilities for some time, and its interfaces for specifying goals and mapping transactions to classes serves as an existence proof that this problem can be solved <ref> [IBM 93c, IBM 95] </ref>. This thesis assumes the existence of similar mechanisms. 1.3 Criteria for Success Before presenting new mechanisms for achieving multiclass performance goals, it will be helpful to define (abstractly) how these mechanisms should be evaluated. <p> just as described repeats indefinitely for every class. 2.3 Related Work In this section we review the limited amount of previous work in the area of goal-oriented resource management. 2.3.1 The MVS Operating System The earliest known attempt at goal-oriented resource management for multiclass workloads is IBM's MVS operating system <ref> [Lorin 81, Pierce 83, IBM 93c] </ref>. The System Resources Manager (SRM) is the component of MVS that is responsible for achieving goals, and like all other proposed algorithms, it is feedback-based.
Reference: [IBM 95] <institution> IBM Corporation, </institution> <note> MVS/ESA Version 5 Planning: </note> <institution> Workload Management GC28-1493, IBM Corporation, </institution> <address> Poughkeepsie NY, </address> <month> March </month> <year> 1995. </year>
Reference-contexts: However, IBM's MVS operating system has provided goal-oriented resource allocation facilities for some time, and its interfaces for specifying goals and mapping transactions to classes serves as an existence proof that this problem can be solved <ref> [IBM 93c, IBM 95] </ref>. This thesis assumes the existence of similar mechanisms. 1.3 Criteria for Success Before presenting new mechanisms for achieving multiclass performance goals, it will be helpful to define (abstractly) how these mechanisms should be evaluated. <p> As of the latest MVS release, in addition to service rates (which are now called velocity goals <ref> [IBM 95] </ref>), average and percentile response time goals are now supported. Response time goals are recommended for those classes with a throughput high enough to insure at least 20 completions during the observation interval, and velocity goals are recommended for classes with lower throughputs.
Reference: [Johnson 94] <author> T. Johnson, D. Shasha, </author> <title> 2Q: A Low Overhead High Performance Buffer Management Replacement Algorithm, </title> <booktitle> Proc. 20th Int'l VLDB Conf, </booktitle> <address> Santiago, Chile, </address> <month> September </month> <year> 1994. </year>
Reference-contexts: Random accesses to pages are generally made via indexes, 4 and there are a number of techniques available to insure that more valuable index pages are not replaced by less valuable data pages <ref> [Haas 90, O'Neil 93, Johnson 94] </ref>. For index pages themselves, it is possible to use reference frequency statistics or information about the last few references to insure that more valuable index pages are not replaced by less valuable index pages [Copeland 88, O'Neil 93, Brown 93a].
Reference: [Ioannidis 92] <author> Y. Ioannidis, R. Ng, K. Shim, T. Sellis, </author> <title> Parametric Query Optimization, </title> <booktitle> Proc. 18th Int'l VLDB Conf., </booktitle> <address> Vancouver, B.C., </address> <month> August </month> <year> 1992. </year>
Reference-contexts: While there has been no published work to date on query optimization techniques for satisfying multiclass performance goals, some early work has been done on run-time selection of query plans based on resource availability <ref> [Hong 91, Ioannidis 92] </ref>.
Reference: [Jauhari 90a] <author> R. Jauhari, M. Carey, M. Livny, Priority-Hints: </author> <title> An Algorithm for Priority-Based Buffer Management, </title> <booktitle> Proc. 16th Int'l VLDB Conf., </booktitle> <address> Brisbane, Austrailia, </address> <month> August </month> <year> 1990. </year>
Reference-contexts: For example, they may want to order classes by their perceived importance so that more important classes receive whatever resources are available and only the less important classes suffer [Nikolaou 92]. More well-understood priority-based allocation techniques can be used to solve this problem (e.g. <ref> [Carey 89, Jauhari 90a, Jauhari 90b] </ref>). Even if one assumes a non-degraded steady-state mode of operation, of course it is still important to be able to detect unachievable goals.
Reference: [Jauhari 90b] <author> R. Jauhari, </author> <title> Priority Scheduling in Database Management Systems, </title> <type> PhD Thesis, </type> <institution> University of Wisconsin, Madison, </institution> <note> 1990 (available as UW Madison CS Technical Report CS-TR-90-959). </note>
Reference-contexts: For example, they may want to order classes by their perceived importance so that more important classes receive whatever resources are available and only the less important classes suffer [Nikolaou 92]. More well-understood priority-based allocation techniques can be used to solve this problem (e.g. <ref> [Carey 89, Jauhari 90a, Jauhari 90b] </ref>). Even if one assumes a non-degraded steady-state mode of operation, of course it is still important to be able to detect unachievable goals.
Reference: [Kaplan 80] <author> J. Kaplan, </author> <title> Buffer Management Policies in a Database Environment,, </title> <type> Masters Thesis, </type> <institution> UC Berkeley, </institution> <year> 1980. </year>
Reference: [Lazowska 84] <author> E. Lazowska, J. Zahoran, G.S. Graham, K. Sevcik, </author> <title> Quantitative System Performance: Computer System Analysis Using Queueing Network Models, </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1984. </year>
Reference-contexts: It is normally performed manually by someone familiar with the workload and the computing system, i.e. a database or system administrator. While there are a wide variety of criteria that can be used in defining classes, Lazowska et al have provided a good summary <ref> [Lazowska 84] </ref>. They suggest that: * Classes should consist of transactions that have similar service demands at each system resource. <p> The external workload source for the system is modeled by a fixed set of simulated terminals, so the simulator models a closed queueing system <ref> [Lazowska 84] </ref>. Each terminal submits a stream of transactions of a particular class, one after another. In between submissions, each terminal thinks (i.e. waits) for a random, exponentially distributed amount of simulated time.
Reference: [Livny 87] <author> M. Livny, S. Koshafian, H. Boral, </author> <title> Multi-Disk Management Algorithms, </title> <booktitle> Proc. ACM SIGMET-RICS Conf., </booktitle> <address> Alberta, Canada, </address> <month> May </month> <year> 1987. </year>
Reference-contexts: These files and indices are modeled at the page level; an extent-based disk storage allocation scheme is assumed, and the B+ tree index pages can be laid out to represent either a clustered or non-clustered index. All database files are fully declustered <ref> [Livny 87] </ref> over all disks in the configuration (except for those files with fewer pages than there are disks).
Reference: [Lorin 81] <author> H. Lorin and H. Deitel, </author> <title> Operating Systems (chapter 9: Resource Management), </title> <publisher> Addison Wesley, </publisher> <address> Reading MA, </address> <year> 1981. </year>
Reference-contexts: just as described repeats indefinitely for every class. 2.3 Related Work In this section we review the limited amount of previous work in the area of goal-oriented resource management. 2.3.1 The MVS Operating System The earliest known attempt at goal-oriented resource management for multiclass workloads is IBM's MVS operating system <ref> [Lorin 81, Pierce 83, IBM 93c] </ref>. The System Resources Manager (SRM) is the component of MVS that is responsible for achieving goals, and like all other proposed algorithms, it is feedback-based.
Reference: [Mehta 93] <author> M. Mehta and D. DeWitt, </author> <title> Dynamic Memory Allocation for Multiple-Query Workloads, </title> <booktitle> Proc. 19 Int'l VLDB Conf., </booktitle> <address> Dublin, Ireland, </address> <month> August </month> <year> 1993. </year>
Reference-contexts: The research literature on multiclass resource allocation has proposed methods for distribution of scarce resources that are based on the notion of uniform performance degradation across all classes, either relative to some theoretical optimal performance <ref> [Carey 85, Mehta 93, Davison 95] </ref> or relative to explicitly stated performance goals [Nikolaou 92, Ferg 93, Chung 94]. However, it is likely that administrators will want much more control in determining how much each class suffers in a degraded mode of operation [Pang 95]. <p> The specifics of Dynamic Tuning's controller design will be discussed further in Chapter 4. 2.3.3 Other Related Work While it does not specifically accept response time goals, the adaptive memory allocation and MPL adjustment algorithm described in <ref> [Mehta 93] </ref> is relevant here because its objective of maximizing fairness is very close to the objective of the goal-oriented transaction routing algorithms described in [Ferg 93]. <p> While both Broker M and Broker M D were shown to outperform the adaptive algorithm of <ref> [Mehta 93] </ref>, it is not clear how such an approach could be used for goal-oriented allocation. Because of the difficulty of accurately characterizing response time functions, it would seem difficult to develop a bidding currency that would be able to achieve per-class response time goals. <p> Developing a controller that uses two knobs (memory and MPL) to control a class is much more difficult than developing one that adjusts only a single knob (such as those in [Brown 93a], <ref> [Mehta 93] </ref>, and [Chung 94]). The search space for a single-knob controller is one dimensional; the only decision required is whether to turn the knob up or down. With two knobs, the controller is faced with a two-dimensional search space.
Reference: [Mehta 94] <author> M. Mehta, </author> <title> Resource Allocation in Parallel Shared-Nothing Database Systems, </title> <type> PhD Thesis, </type> <institution> University of Wisconsin, Madison, </institution> <year> 1994. </year>
Reference-contexts: Both goal and no-goal classes were allowed to use disk buffer frames from the global 1 An earlier version of M&M that was paired with the Fragment Fencing controller [Brown 93a] for disk buffer classes was described and analyzed in both [Brown 94] and <ref> [Mehta 94] </ref>. 56 pool, but if a goal class could not meet its goal simply by competing for frames in the global pool, a local pool was set aside for its private use in addition to any global frames it managed to obtain.
Reference: [Ng 91] <author> R. Ng, C. Faloutsos, T. Sellis, </author> <title> Flexible Buffer Allocation Based on Marginal Gains, </title> <booktitle> Proc. ACM SIGMOD '91 Conf., </booktitle> <address> Denver, CO, </address> <month> May </month> <year> 1991. </year>
Reference-contexts: To our knowledge, no one has explicitly stated it in the form we do here, although some previous work has exploited the notion of concavity in any case [Dan 95]. 3 This notion of page value is synonymous with the concept of marginal gain defined in <ref> [Ng 91] </ref>. 35 knowledge of the total number of pages that will be scanned [Stone 81]. <p> Estimate E2 predicts a required memory allocation of M3. With one more estimate using points O2 and O3, the target hit 5 A straight line approximation of buffer hit rate functions was also used in [Chen 93] to predict a memory allocation that maximizes marginal gain <ref> [Ng 91] </ref>. 37 rate is achieved. If any estimate's line were to cross the M max limit instead of the target hit rate, then the target hit rate is unachievable.
Reference: [Nikolaou 92] <author> C. Nikolaou, D. Ferguson, P. Constantopoulos, </author> <title> Towards Goal Oriented Resource Management, </title> <institution> IBM Research Report RC17919, </institution> <month> April </month> <year> 1992. </year>
Reference-contexts: As the complexity of database systems is increasing, while their cost is declining at the same time, manually adjusting low-level DBMS performance knobs will become increasingly impractical, as has been argued previously <ref> [Nikolaou 92, Brown 93b, Selinger 93, Weikum 93] </ref>. Ideally, the DBMS should simply accept per-class performance goals as inputs, and it should adjust its own low-level knobs in order to achieve them; this self-tuning capability is called goal-oriented resource allocation [Nikolaou 92]. <p> Ideally, the DBMS should simply accept per-class performance goals as inputs, and it should adjust its own low-level knobs in order to achieve them; this self-tuning capability is called goal-oriented resource allocation <ref> [Nikolaou 92] </ref>. Given a performance objective for each class in a multiclass workload, there are a number of mechanisms that a goal-oriented DBMS can use to achieve them: load control, transaction routing, CPU and disk scheduling, memory management, data placement, processor allocation, query optimization, etc. <p> The following criteria should be satisfied by any goal-oriented resource allocation algorithm before it can be considered for implementation in a real DBMS: Accuracy: The observed performance for goal classes should be close to their stated goals. A convenient way to quantify accuracy is the performance index <ref> [Nikolaou 92] </ref>, which is simply the observed performance metric divided by the performance goal. A performance index of one is ideal, while an index that is greater than or less than one indicates a violated or exceeded goal. <p> Response time metrics can be specified as average, maximum, or percentile values. Combinations of multiple metrics are also common, such as a target throughput that is subject to a maximum or a 90th percentile response time constraint. Following other work in this area <ref> [Nikolaou 92, Ferg 93] </ref>, this thesis will adopt an average response time metric. Average response times are not only a commonly used performance metric in themselves, but they are also easily converted into average throughput metrics, given the number of attached terminals (clients) and their average think times. <p> normally be no smaller than the number of transactions required to achieve a statistically significant sample. 2.1.2 Degraded Versus Non-Degraded Modes If the system configuration is not powerful enough to satisfy the performance goals for all classes in steady state, then it is said to be operating in degraded mode <ref> [Nikolaou 92] </ref>. This thesis concentrates primarily on non-degraded modes of operation, and it does so for two reasons. <p> The research literature on multiclass resource allocation has proposed methods for distribution of scarce resources that are based on the notion of uniform performance degradation across all classes, either relative to some theoretical optimal performance [Carey 85, Mehta 93, Davison 95] or relative to explicitly stated performance goals <ref> [Nikolaou 92, Ferg 93, Chung 94] </ref>. However, it is likely that administrators will want much more control in determining how much each class suffers in a degraded mode of operation [Pang 95]. <p> For example, they may want to order classes by their perceived importance so that more important classes receive whatever resources are available and only the less important classes suffer <ref> [Nikolaou 92] </ref>. More well-understood priority-based allocation techniques can be used to solve this problem (e.g. [Carey 89, Jauhari 90a, Jauhari 90b]). Even if one assumes a non-degraded steady-state mode of operation, of course it is still important to be able to detect unachievable goals. <p> been evolving for nearly 20 years, and as such, it represents the most complete solution to goal-oriented resource allocation that exists today. 2.3.2 Goal-Oriented DBMS Research The earliest published research paper on goal-oriented resource management in a database context was a pioneering paper from Christos Nikolaou's group at IBM Yorktown <ref> [Nikolaou 92] </ref>. This paper defined the problem of goal-oriented resource allocation, described alternative ways to specify goals, introduced the notion of performance indices, and described work in progress on the problem of goal-oriented resource management for distributed transaction processing systems. <p> The work from this group spawned several algorithms that we 21 review in this section and that influenced subsequent releases of MVS as well as IBM's CICS TP Monitor. The first offshoot of <ref> [Nikolaou 92] </ref> was a pair of algorithms for goal-oriented transaction routing in distributed transaction processing systems [Ferg 93]. These two algorithms are feedback-based and use a system-wide orientation. Both algorithms attempt to predict the effect of a transaction routing decision on the response times of each transaction class. <p> Rather, they need only determine the correct relative response times when comparing between different routing possibilities. The second offshoot from <ref> [Nikolaou 92] </ref> was an algorithm, called Dynamic Tuning [Chung 94], for goal-oriented multi-class disk buffer allocation. Dynamic Tuning is also a feedback-based algorithm with a system-wide orientation (their system-wide observation interval is called a tuning interval).
Reference: [O'Neil 93] <author> E. O'Neil, P. O'Neil, G. Weikum, </author> <title> The LRU-K Page Replacement Algorithm For Database Disk Buffering, </title> <booktitle> Proc. ACM SIGMOD '93 Conf., </booktitle> <address> Washington D.C., </address> <month> May </month> <year> 1993. </year> <month> 93 </month>
Reference-contexts: Random accesses to pages are generally made via indexes, 4 and there are a number of techniques available to insure that more valuable index pages are not replaced by less valuable data pages <ref> [Haas 90, O'Neil 93, Johnson 94] </ref>. For index pages themselves, it is possible to use reference frequency statistics or information about the last few references to insure that more valuable index pages are not replaced by less valuable index pages [Copeland 88, O'Neil 93, Brown 93a]. <p> For index pages themselves, it is possible to use reference frequency statistics or information about the last few references to insure that more valuable index pages are not replaced by less valuable index pages <ref> [Copeland 88, O'Neil 93, Brown 93a] </ref>.
Reference: [Pang 93a] <author> H. Pang, M. Carey, M. Livny, </author> <title> Partially Preemptible Hash Joins, </title> <booktitle> Proc. ACM SIGMOD '93 Conf., </booktitle> <address> Washington D.C., </address> <month> May </month> <year> 1993. </year>
Reference-contexts: Not only are the admission and initial allocation of query operators determined by a bidding process, but their allocations may also be dynamically adjusted in-flight in order to insure that resources are always being used by the highest bidder (i.e. adaptive query processing algorithms <ref> [Pang 93a, Pang 93b, Davison 94] </ref> are exploited in this scheme). While both Broker M and Broker M D were shown to outperform the adaptive algorithm of [Mehta 93], it is not clear how such an approach could be used for goal-oriented allocation. <p> One way to address the problem of goal-class memory waits is to implement memory adaptive query operators, such as those described in <ref> [Zeller 90, Pang 93a, Pang 93b, Davison 94] </ref>, that can dynamically adjust their working storage requirements during the execution of the operation. Using these algorithms, the no-goal class can be throttled back to the new, smaller global pool size.
Reference: [Pang 93b] <author> H. Pang, M. Carey, M. Livny, </author> <title> Memory Adaptive External Sorts and Sort-Merge Joins, </title> <booktitle> Proc. 19 Int'l VLDB Conf., </booktitle> <address> Dublin, Ireland, </address> <month> August </month> <year> 1993. </year>
Reference-contexts: Not only are the admission and initial allocation of query operators determined by a bidding process, but their allocations may also be dynamically adjusted in-flight in order to insure that resources are always being used by the highest bidder (i.e. adaptive query processing algorithms <ref> [Pang 93a, Pang 93b, Davison 94] </ref> are exploited in this scheme). While both Broker M and Broker M D were shown to outperform the adaptive algorithm of [Mehta 93], it is not clear how such an approach could be used for goal-oriented allocation. <p> One way to address the problem of goal-class memory waits is to implement memory adaptive query operators, such as those described in <ref> [Zeller 90, Pang 93a, Pang 93b, Davison 94] </ref>, that can dynamically adjust their working storage requirements during the execution of the operation. Using these algorithms, the no-goal class can be throttled back to the new, smaller global pool size.
Reference: [Pang 94a] <author> H. Pang, M. Carey, M. Livny, </author> <title> Managing Memory for Real-Time Queries, </title> <booktitle> Proc. ACM SIGMOD '94 Conf., </booktitle> <address> Minneapolis MN, </address> <month> May </month> <year> 1994. </year>
Reference: [Pang 94b] <author> H. Pang, </author> <title> Query Processing in Firm Real-Time Database Systems, </title> <type> PhD Thesis, </type> <institution> University of Wisconsin, Madison, </institution> <year> 1994. </year>
Reference-contexts: Mechanisms very different from the ones presented in this thesis are required for real-time database systems <ref> [Abbott 91, Pang 94b] </ref>.
Reference: [Pang 95] <author> H. Pang, M. Carey, M. Livny, </author> <title> Query Scheduling in Real-Time Database Systems", </title> <note> to appear in Trans. </note> <institution> of Knowledge and Data Engineering, </institution> <month> August </month> <year> 1995. </year>
Reference-contexts: However, it is likely that administrators will want much more control in determining how much each class suffers in a degraded mode of operation <ref> [Pang 95] </ref>. For example, they may want to order classes by their perceived importance so that more important classes receive whatever resources are available and only the less important classes suffer [Nikolaou 92].
Reference: [Patel 93] <author> J. Patel, M. Carey, M. Vernon, </author> <title> Accurate Modeling of the Hybrid Hash Join Algorithm, </title> <booktitle> Proc. ACM SIGMETRICS '94, </booktitle> <address> Nashville, TN, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: Techniques from queuing theory could be applied to account for these delays, but predicting such delays even for a single hash join running alone on a centralized DBMS turns out to be non-trivial due to complexities such as caching disk controllers and intra-operator concurrency <ref> [Patel 93] </ref>. At best, the application of queuing theory to complex database workloads is a difficult open research challenge. Because of the difficulty of accurately predicting class response times as a function of resources allocated, the only feasible approach is based on feedback.
Reference: [Pierce 83] <author> B. Pierce, </author> <title> The Most Misunderstood Parts of the SRM, </title> <booktitle> Proc. SHARE 61 (IBM users group), </booktitle> <address> New York NY, </address> <month> August </month> <year> 1983. </year>
Reference-contexts: just as described repeats indefinitely for every class. 2.3 Related Work In this section we review the limited amount of previous work in the area of goal-oriented resource management. 2.3.1 The MVS Operating System The earliest known attempt at goal-oriented resource management for multiclass workloads is IBM's MVS operating system <ref> [Lorin 81, Pierce 83, IBM 93c] </ref>. The System Resources Manager (SRM) is the component of MVS that is responsible for achieving goals, and like all other proposed algorithms, it is feedback-based. <p> The MVS SRM has four primary knobs that it controls for each class: multiprogramming level, memory allocation (i.e. working set size), processor scheduling, and I/O subsystem scheduling. It uses a set of fairly simple heuristics to guide the controllers for these knobs <ref> [Pierce 83] </ref> unfortunately, detailed information on the heuristics is not available since MVS is a commercial product. Although it represents a significant example of related work, the MVS SRM is not the answer to the goal-oriented resource allocation problem for mixed database workloads.
Reference: [Pirahesh 90] <author> H. Pirahesh, et al, </author> <title> "Parallelism in Relational Database Systems: </title> <booktitle> Architectural Issues and Design Approaches," IEEE 2nd Int'l Symposium on Databases in Parallel and Distributed Systems, </booktitle> <address> Dublin, Ireland, </address> <month> July </month> <year> 1990. </year>
Reference-contexts: In addition to the classic relational DBMS problem workload consisting of short transactions running concurrently with long decision support queries <ref> [Pirahesh 90, Brown 92, DeWitt 92] </ref>, we can expect to see workloads comprising an even wider range of resource demands and execution times in the future.
Reference: [Reiter 76] <author> A. Reiter, </author> <title> A Study of Buffer Management Policies For Data Management Systems, </title> <type> MRC Technical Summary Report #1619, </type> <institution> Mathematics Research Center, University of Wisconsin, Madison, </institution> <month> March </month> <year> 1976. </year>
Reference: [Robinson 90] <author> J. Robinson and M. Devarakonda, </author> <title> Data Cache Management Using Frequency-Based Replacement, </title> <booktitle> Proc. SIGMETRICS '90 Conf., </booktitle> <address> Boulder, CO, </address> <month> May </month> <year> 1990. </year>
Reference: [Sacco 82] <author> G. Sacco and M. Schkolnick, </author> <title> A Mechanism for Managing the Buffer Pool in a Relational Database System Using the Hot Set Model Proc. </title> <booktitle> 8th Int'l VLDB Conf., </booktitle> <address> Mexico City, </address> <month> September </month> <year> 1982. </year>
Reference: [Sacco 86] <author> G. Sacco and M. Schkolnick, </author> <title> Buffer Management in Relational Database Systems, </title> <journal> ACM TODS, </journal> <volume> 11(4), </volume> <month> December </month> <year> 1986. </year>
Reference: [Selinger 93] <author> P. Selinger, </author> <title> Predictions and Challenges for Database Systems in the Year 2000, </title> <booktitle> Proc. 19th Int'l VLDB Conf, </booktitle> <address> Dublin, Ireland, </address> <month> August </month> <year> 1993. </year>
Reference-contexts: As the complexity of database systems is increasing, while their cost is declining at the same time, manually adjusting low-level DBMS performance knobs will become increasingly impractical, as has been argued previously <ref> [Nikolaou 92, Brown 93b, Selinger 93, Weikum 93] </ref>. Ideally, the DBMS should simply accept per-class performance goals as inputs, and it should adjust its own low-level knobs in order to achieve them; this self-tuning capability is called goal-oriented resource allocation [Nikolaou 92].
Reference: [Stone 81] <author> M. Stonebraker, </author> <title> Operating System Support for Database Management, </title> <journal> CACM, </journal> <volume> 24(7). </volume> <month> July </month> <year> 1981. </year>
Reference-contexts: the form we do here, although some previous work has exploited the notion of concavity in any case [Dan 95]. 3 This notion of page value is synonymous with the concept of marginal gain defined in [Ng 91]. 35 knowledge of the total number of pages that will be scanned <ref> [Stone 81] </ref>. Random accesses to pages are generally made via indexes, 4 and there are a number of techniques available to insure that more valuable index pages are not replaced by less valuable data pages [Haas 90, O'Neil 93, Johnson 94].
Reference: [Teng 84] <author> J. Teng and R. Gumaer, </author> <title> Managing IBM Database 2 Buffers to Maximize Performance, </title> <journal> IBM Systems Journal, </journal> <volume> 23(2), </volume> <year> 1984. </year>
Reference-contexts: The buffer pool consists of a set of main memory page frames of 8K bytes each. The buffer manager is modeled after that of DB2/MVS <ref> [Teng 84, IBM 93a] </ref>. <p> While it would be impossible to offer any definitive statement about the likelihood of hit rate knees in real-world buffer managers, we conducted a small empirical study of two simulated buffer managers, one modeled after DB2/MVS <ref> [Cheng 84, Teng 84, IBM 93a] </ref> and the other modeled after DB2/6000 [IBM 93b].
Reference: [TPC 94] <institution> Transaction Processing Performance Council, TPC Benchmark C, Revision 2.0, </institution> <month> 20 October </month> <year> 1993, </year> <title> and TPC Benchmark D, </title> <note> Working Draft 7.0, </note> <month> 6 May </month> <year> 1994, </year> <title> C/O Shanley Public Relations, 777 N. </title> <booktitle> First St, </booktitle> <address> San Jose, CA. </address>
Reference-contexts: All the workloads in this section are formed using various combinations of three workload classes that have been previously defined elsewhere: the TPC-C benchmark from the Transaction Processing Council <ref> [TPC 94] </ref>, and two query types from a previously published performance study of the DBMIN buffer management algorithm [Chou 85]. A 24 MB, eight disk version of the simulated DBMS described in Chapter 3 is used to run the workloads. <p> DBMIN file B 182 100K 2223 72.3 - U DBMIN unclustered idx B 12 100K 147 4.8 - U DBMIN clustered idx B 12 100K 147 4.8 - U Table 3: Database characteristics The database model consists of a two-part database, with one part taken directly from the TPC-C benchmark <ref> [TPC 94] </ref> using a scale factor of one (one warehouse), and the other drawn from a previously published performance study of the DBMIN buffer management algorithm [Chou 85]. <p> U/H and U/C are special distributions defined in the TPC-C benchmark that can be roughly described as uniform with hot spots and uniform with cold spots, respectively (see <ref> [TPC 94] </ref> for a detailed description). <p> Because we are primarily interested in the page reference patterns of these classes, all of the workload classes are read-only. The specific behavior of the classes is described in the following paragraphs. TPC-C: This simulated workload class faithfully duplicates the reference patterns of the TPC-C benchmark as specified in <ref> [TPC 94] </ref>. TPC-C models an order-entry business and is composed of a mix of five different transaction types. These queries are mostly index scans of varying selectivities that produce the reference frequencies and patterns shown in Table 3 (a detailed description is provided in [TPC 94]). <p> the TPC-C benchmark as specified in <ref> [TPC 94] </ref>. TPC-C models an order-entry business and is composed of a mix of five different transaction types. These queries are mostly index scans of varying selectivities that produce the reference frequencies and patterns shown in Table 3 (a detailed description is provided in [TPC 94]). As stated earlier, TPC-C exhibits a high degree of locality. The order line and order line index files receive over one third of the references, and the access to both is highly skewed, giving this workload a relatively high hit rate at a low cost in memory. <p> As in Chapter 4, the transactions represent a disk buffer class with short (sub-second) execution times, although here the transactions are modeled on the TPC-A benchmark <ref> [TPC 94] </ref> instead of TPC-C. The transaction class performs single-record index selects on 4 files: big, medium, small, and tiny (see Table 12).
Reference: [van den Berg 93] <author> J. van den Berg, D. Towsley, </author> <title> Properties of the Miss Ratio for a 2-Level Storage Model with LRU or FIFO Replacement Strategy and Independent Reference, </title> <journal> IEEE Trans. on Computers, </journal> <volume> 42(4), </volume> <month> April </month> <year> 1993. </year>
Reference-contexts: It can therefore prefetch sequentially accessed pages just before they are referenced, and once they are referenced, it can toss or retain these pages based on 2 A similar theorem has been proven by van den Berg and Towsley <ref> [van den Berg 93] </ref> for the case of an IRM reference pattern coupled with an LRU replacement policy.
Reference: [Weikum 93] <author> G. Weikum et al, </author> <title> The COMFORT Project Project Synopsis, </title> <booktitle> Proc. 2nd Int'l Conf. on Parallel and Distributed Information Systems, </booktitle> <address> San Diego CA, </address> <month> January </month> <year> 1993. </year> <month> 94 </month>
Reference-contexts: As the complexity of database systems is increasing, while their cost is declining at the same time, manually adjusting low-level DBMS performance knobs will become increasingly impractical, as has been argued previously <ref> [Nikolaou 92, Brown 93b, Selinger 93, Weikum 93] </ref>. Ideally, the DBMS should simply accept per-class performance goals as inputs, and it should adjust its own low-level knobs in order to achieve them; this self-tuning capability is called goal-oriented resource allocation [Nikolaou 92]. <p> Because of the difficulty of accurately characterizing response time functions, it would seem difficult to develop a bidding currency that would be able to achieve per-class response time goals. Finally, the COMFORT project at ETH Zurich deserves mention since it was directed toward automated DBMS performance tuning <ref> [Weikum 93] </ref>.
Reference: [Yu 93] <author> P. Yu and D. Cornell, </author> <title> Buffer Management Based on Return on Consumption in a Multi-Query Environment, </title> <journal> VLDB Journal, </journal> <volume> 2(1), </volume> <month> Jan </month> <year> 1993. </year>
Reference-contexts: In this region of operation, the reduction in MPL queuing provided by a higher MPL outweighs the penalty of a reduced memory allocation per query. These observations support the conclusions of Cornell and Yu <ref> [Yu 93] </ref>, who showed that the best query performance is obtained when queries are allocated either their minimum or maximum memory requirements. M&M exploits the Cornell and Yu results, as will be explained in Section 5.3. <p> At the other end of the spectrum, for small available memory amounts, the best response time is obtained with high MPLs and a per-query memory allocation close to the minimum requirement. These results confirm the memory allocation heuristic derived by Cornell and Yu <ref> [Yu 93] </ref>, which states that the best return on consumption is obtained by allocating only the minimum or the maximum memory requirement of any individual query. Return on consumption is a measure of response time improvement versus the space-time cost of memory. <p> In other words: 6 Both the min/max heuristic and the conclusion that a join query's return on consumption is largest for a maximum allocation were shown to hold for hash-based, sort-merge, and nested loops join methods <ref> [Yu 93] </ref>. 65 Heuristic 2 Do not increase the MPL of a class if there are fewer than 0.5 waiters in its MPL queue, on average.
Reference: [Zeller 90] <author> H. Zeller, J. Gray, </author> <title> An Adaptive Hash Join Algorithm for Multiuser Environments Proc. </title> <booktitle> 16th Int'l VLDB Conf., </booktitle> <address> Melbourne, Australia, </address> <month> August </month> <year> 1990. </year>
Reference-contexts: One way to address the problem of goal-class memory waits is to implement memory adaptive query operators, such as those described in <ref> [Zeller 90, Pang 93a, Pang 93b, Davison 94] </ref>, that can dynamically adjust their working storage requirements during the execution of the operation. Using these algorithms, the no-goal class can be throttled back to the new, smaller global pool size.
References-found: 75

