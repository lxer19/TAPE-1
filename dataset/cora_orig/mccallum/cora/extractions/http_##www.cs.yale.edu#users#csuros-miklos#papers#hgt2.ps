URL: http://www.cs.yale.edu/users/csuros-miklos/papers/hgt2.ps
Refering-URL: http://www.cs.yale.edu/users/csuros-miklos/papers.html
Root-URL: http://www.cs.yale.edu
Title: Recovering Evolutionary Trees through Harmonic Greedy Triplets  
Author: Miklos Cs-uros Ming-Yang Kao 
Date: June 27, 1998  
Abstract: This paper presents a simple new learning algorithm, called Harmonic Greedy Triplets, based on a greedy selection of triplets of close taxa. By explicitly studying the deviations of the estimated distances from their true values in the Jukes-Cantor [13] model, we show that the algorithm requires input sequences of only polynomial lengths to recover the correct tree topology with high probability. Our theoretical analysis is supported by simulated experiments in which the algorithm achieved high success rates in reconstructing a large tree from short sequences.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. Agarwala, V. Bafna, M. Farach, B. Narayanan, M. Paterson, and M. </author> <title> Thorup. On the approximability of numerical taxonomy: fitting distances by tree metrics. </title> <booktitle> Proceedings of the 7th Annual ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <pages> 365-372, </pages> <year> 1996. </year>
Reference-contexts: Finding an evolutionary tree among all possible trees that fits the observed distances the best according to some metric is provably NP-hard in most cases (for L 1 and L 2 metric norms, see [4], and for L 1 , see <ref> [1] </ref>). This paper presents a simple new algorithm coupled with an analysis of estimation errors, which enables us to prove that the algorithm builds the correct evolutionary tree with high probability from sequences of polynomial length.
Reference: [2] <author> A. Ambainis, R. Desper, M. Farach, and S. Kannan. </author> <title> Nearly tight bounds on the learnability of evolution. </title> <booktitle> Proceedings of the 38th Annual Symposium on Foundations of Computer Science, </booktitle> <pages> 524-533, </pages> <year> 1997. </year>
Reference-contexts: Their algorithm needs a sample of size O f 2 (12g) 2diameter to recover the correct topology with probability 1 o (1). It was stated in <ref> [2] </ref> that despite the significant difference of sample size requirements in the case of unbalanced trees, practical applications often deal with fairly balanced phylogenies, in which case the algorithms perform comparably.
Reference: [3] <author> J. Cavender. </author> <title> Taxonomy with confidence. </title> <journal> Mathematical Biosciences, </journal> <volume> 40 </volume> <pages> 271-280, </pages> <year> 1978. </year>
Reference-contexts: Parsimony methods [10], which perhaps are the most popular among them, attempt to find the tree that minimizes the number of mutations leading to the observed sequences. Parsimony is an NP-hard problem [5]; moreover, it is not even a consistent method <ref> [3, 9] </ref>, i.e., increasing the length of sample sequences generated by an evolutionary tree ad infinitum may still not result in inferring the correct topology. Distance-based methods first calculate pairwise evolutionary distances between taxa from the observed sequences and build the tree from the resulting distance matrix. <p> It is also often assumed that the sequence changes occur at each aligned position independently, according to the same transition probabilities, which may differ on the edges. This insightful model of evolution is called the Cavender-Farris Tree (CFT) model <ref> [3] </ref>. In this section, we focus on the case of a binary alphabet. In the CFT model, the characters of a set of aligned binary sequences are generated using an edge-weighted binary tree.
Reference: [4] <author> W. H. E. Day. </author> <title> Computational complexity of inferring phylogenies from dissimilarity matrices. </title> <journal> Bulletin of Mathematical Biology, </journal> <volume> 49 </volume> <pages> 461-467, </pages> <year> 1987. </year>
Reference-contexts: Finding an evolutionary tree among all possible trees that fits the observed distances the best according to some metric is provably NP-hard in most cases (for L 1 and L 2 metric norms, see <ref> [4] </ref>, and for L 1 , see [1]). This paper presents a simple new algorithm coupled with an analysis of estimation errors, which enables us to prove that the algorithm builds the correct evolutionary tree with high probability from sequences of polynomial length.
Reference: [5] <author> W. H. E. Day, D. S. Johnson, and D. Sankoff. </author> <title> The computational complexity of inferring rooted phylogenies by parsimony. </title> <journal> Mathematical Biosciences, </journal> <volume> 81 </volume> <pages> 33-42, </pages> <year> 1986. </year>
Reference-contexts: Parsimony methods [10], which perhaps are the most popular among them, attempt to find the tree that minimizes the number of mutations leading to the observed sequences. Parsimony is an NP-hard problem <ref> [5] </ref>; moreover, it is not even a consistent method [3, 9], i.e., increasing the length of sample sequences generated by an evolutionary tree ad infinitum may still not result in inferring the correct topology.
Reference: [6] <author> P. L. Erd-os, K. Rice, M. A. Steel, L. A. Szekely, and T. J. Warnow. </author> <title> The short quartet method. </title> <journal> Mathematical Modeling and Scientific Computing, </journal> <note> to appear. 16 </note>
Reference-contexts: Our study is supported by simulated experiments, which show high success rates on short sample sequences. We have knowledge of only one method with comparable statistical power and experimental performance, namely, the Short Quartet Method <ref> [6] </ref>. However, the Short Quartet Method (SQM) may not return a tree at all, which is not the case for our Harmonic Greedy Triplets (HGT) algorithm, largely due to the fact that we aim to use a small non-redundant set of taxon triplets to build the tree. <p> The efficiency limits 3 of such methods are well captured by the notion of the tree's depth, which we define as follows, similarly to Erd-os et al. <ref> [6] </ref>. Root depth of a tree is the shortest path's length leading from the root to a leaf. For an arbitrary edge e, the edge depth of e is defined as the maximum of the root depths of the two subtrees obtained by removing e. <p> The diameter of a CFT with n leaves is larger than twice the depth, is always (log n), and can be as large as fi (n) for unbalanced trees. The importance of the depth vs. diameter difference was pointed out by Erd-os et al. <ref> [6] </ref>. Their Short Quartet Method uses distances of close nodes, which results in the fact that a sample of size O f 2 (12g) 4depth enough to recover the correct topology with probability 1 o (1), where f denotes the minimum edge weight and g denotes the maximum edge weight. <p> In fact, for most trees, depth is O (log log n) while diameter is (log n) or ( p n), depending on the distribution <ref> [6] </ref>. 2 Algorithm 2.1 Model of sequence evolution Our model of sequence evolution is the Jukes-Cantor model [13], which in the case of a binary alphabet corresponds to the Cavendar-Farris model. <p> This concludes the proof of Theo rem 2.2. Success rates on a 50-taxon caterpillar. The horizontal axis shows the sample sequence lengths and the vertical axis shows the mutation probabilities. Shading shows the relative success rate from among 10 experiments. a binary alphabet. 3 Experimental results Erd-os et al. <ref> [6] </ref> evaluated their Short Quartet Method experimentally, simulating binary sequence evolution on a 50-taxon caterpillar. The caterpillar tree is well suited for demonstrating that large trees can be recovered from short sequences if the terminal taxa are close to each other. <p> The greedy selection of triplets based on their average closeness guarantees the polynomial sample length requirements of our algorithm and results in better experimental performance. Another polynomial time algorithm has also been introduced recently, the Short Quartet Method <ref> [6] </ref>. Our algorithm achieves comparable experimental success rates and the same asymptotic sample requirements as SQM. Moreover, on short sequences it has better experimental performance than that of SQM.
Reference: [7] <author> M. Farach and S. Kannan. </author> <title> Efficient algorithms inverting evolution. </title> <booktitle> Proceedings of the 28th Annual ACM Symposium on Theory of Computing, </booktitle> <pages> 230-236, </pages> <year> 1996. </year>
Reference-contexts: In addition, HGT achieved better success rates than SQM in reconstructing a large tree from short sequences of 500-1000 characters. Our algorithm's performance is superior to such other distance-based methods as the widely used Neighbor Joining [17] and that of Farach and Kannan <ref> [7] </ref>. The rest of the paper is organized as follows. We briefly introduce the Cavender-Farris model of evolution of binary sequences in x 1.1, and discuss the computational difficulties of distance-based methods in x 1.2. Section 2 details our algorithm and proves its sample size requirements and running time. <p> Our algorithm, like that of Erd-os et al., only uses distances of close nodes and has the same asymptotic sample size requirements. An example of different approaches is Farach and Kannan's method <ref> [7] </ref>. Their algorithm first "fixes" the distances ^ derived from the sample in order to make the distance matrix additive and thus possible to be generated by a tree.
Reference: [8] <author> J. S. Farris. </author> <title> Estimating phylogenetic trees from distance matrices. </title> <journal> The American Naturalist, </journal> <volume> 106 </volume> <pages> 645-668, </pages> <year> 1972. </year>
Reference-contexts: Note that the manner in which the root is labeled only bears importance on rooting the tree. Regardless of the root labeling, the unrooted tree can be built using the labelings of the terminal taxa. For a discussion on rooting, see e.g., <ref> [8, 14] </ref>. We assign a binary random variable to each node, corresponding to that node's labeling. The CFT generates the joint probability distribution for these random variables. In particular, each CFT with n leaves generates a probability distribution over binary vectors of length n. <p> The idea of using triplets for tree building is not new, Neighbor Joining [17], distance Wagner <ref> [8] </ref> and other distance methods are based on the idea of determining the internal nodes as centers of triplets. The greedy selection of triplets based on their average closeness guarantees the polynomial sample length requirements of our algorithm and results in better experimental performance.
Reference: [9] <author> J. Felsenstein. </author> <title> Cases in which parsimony or compatibility methods will be positively misleading. </title> <journal> Systematic Zoology, </journal> <volume> 22 </volume> <pages> 240-249, </pages> <year> 1978. </year>
Reference-contexts: Parsimony methods [10], which perhaps are the most popular among them, attempt to find the tree that minimizes the number of mutations leading to the observed sequences. Parsimony is an NP-hard problem [5]; moreover, it is not even a consistent method <ref> [3, 9] </ref>, i.e., increasing the length of sample sequences generated by an evolutionary tree ad infinitum may still not result in inferring the correct topology. Distance-based methods first calculate pairwise evolutionary distances between taxa from the observed sequences and build the tree from the resulting distance matrix.
Reference: [10] <author> J. Felsenstein. </author> <title> Numerical methods for inferring evolutionary trees. </title> <journal> The Quarterly Review of Biology, </journal> <volume> 57 </volume> <pages> 379-404, </pages> <year> 1982. </year>
Reference-contexts: 1 Introduction Procedures used in the reconstruction of the evolutionary tree are principal tools of biology. Such algorithms compare aligned character sequences for the taxa in question in order to infer their evolutionary relationships <ref> [10, 14] </ref>. Originally, these characters were most often categorical variables of morphological features, but newer studies have made full use of available biomolecular sequences. <p> Unfortunately, many current methods suffer from theoretical or practical drawbacks requiring long sequences in order to recover the correct tree topology. Parsimony methods <ref> [10] </ref>, which perhaps are the most popular among them, attempt to find the tree that minimizes the number of mutations leading to the observed sequences.
Reference: [11] <author> W. M. Fitch and E. Margoliash. </author> <title> Construction of phylogenetic trees. </title> <journal> Science, </journal> <volume> 155 </volume> <pages> 279-284, </pages> <year> 1967. </year>
Reference-contexts: Given any triplet of external nodes X, Y and Z, their distances from the center P can be obtained from the pairwise distances as XP = 2 (This simple equation is well-known in the literature and appears as early as in 1967 <ref> [11] </ref>.) Our algorithm selects triplets of external nodes to find the internal nodes by using the distance estimation ^ XP = 2 given that all the pairwise distance values are finite.
Reference: [12] <author> W. Hoeffding. </author> <title> Probability inequalities for sums of bounded random variables. </title> <journal> Journal of the American Statistical Association, </journal> <volume> 58 </volume> <pages> 13-30, </pages> <year> 1963. </year>
Reference-contexts: ^ XY 1 * = Pr i=1 ) and XY ( N X (I X i Y i XY ) N XY * : Since 1=(m 1) I X i Y i 1 and IE [ I X i Y i XY ] = 0, we can use Hoeffding's inequality <ref> [12] </ref> on sums of independent bounded random variables and obtain Equations (5) and (6). 2.3 Triplet centers Let the distance of two nodes X and Y be XY = ln XY : (7) X Y Z Since closeness is multiplicative, distance is an additive measure along any path in the tree.
Reference: [13] <author> T. H. Jukes and C. H. Cantor. </author> <title> Evolution of protein molecules. </title> <editor> in H. N. Munro, ed. </editor> <title> Mammalian Protein Metabolism, </title> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1969, </year> <pages> pp. 21-132. </pages>
Reference-contexts: In fact, for most trees, depth is O (log log n) while diameter is (log n) or ( p n), depending on the distribution [6]. 2 Algorithm 2.1 Model of sequence evolution Our model of sequence evolution is the Jukes-Cantor model <ref> [13] </ref>, which in the case of a binary alphabet corresponds to the Cavendar-Farris model.
Reference: [14] <author> M. Nei. </author> <title> Molecular Evolutionary Genetics. </title> <publisher> Columbia University Press, </publisher> <address> New York, </address> <year> 1987. </year>
Reference-contexts: 1 Introduction Procedures used in the reconstruction of the evolutionary tree are principal tools of biology. Such algorithms compare aligned character sequences for the taxa in question in order to infer their evolutionary relationships <ref> [10, 14] </ref>. Originally, these characters were most often categorical variables of morphological features, but newer studies have made full use of available biomolecular sequences. <p> Note that the manner in which the root is labeled only bears importance on rooting the tree. Regardless of the root labeling, the unrooted tree can be built using the labelings of the terminal taxa. For a discussion on rooting, see e.g., <ref> [8, 14] </ref>. We assign a binary random variable to each node, corresponding to that node's labeling. The CFT generates the joint probability distribution for these random variables. In particular, each CFT with n leaves generates a probability distribution over binary vectors of length n.
Reference: [15] <author> M. Noro, R. Masuda, I. A. Dubrovo, M. C. Yoshida, and M. Kato. </author> <title> Molecular phylogenetic inference of the woolly mammoth Mammuthus primigenius, based on complete sequences of mitochondrial cytochrome b and 12S ribosomal RNA genes. </title> <journal> Journal of Molecular Evolution, </journal> <volume> 46 </volume> <pages> 314-326, </pages> <year> 1998. </year>
Reference-contexts: In order to rule out ambiguity, we require that all the mutation probabilities lie strictly between 0 and 1=2. Our task is to construct a hypothesis CFT based on the input sample. Thus, our primary goal 2 The example is taken from Nore et al. <ref> [15] </ref> who used the sequences of 12S ribosomal RNA and cytochrome b in mitochondrial DNA to establish the phylogenetic relationships between the woolly mammoth and its extant relatives.
Reference: [16] <author> C.-Y. Ou, C. A. Cieselski, G. Myers, C. I. Bandea, C.-C. Luo, B. T. M. Korber, J. I. Mullins, G. Schochetman, R. L. Berkelman, A. N. Economou, J. J. Witte, L. J. Furman, G. A. Satten, K. A. MacInnes, J. W. Curran, and H. W. Jaffe. </author> <title> Molecular epidemiology of HIV transmission in a dental practice. </title> <journal> Science, </journal> <volume> 256 </volume> <pages> 1165-1171, </pages> <year> 1992. </year>
Reference-contexts: Tree inference algorithms not only have allowed the exploration of evolutionary inter-species relationships but also have led to the discovery of new proteins and found their function in epidemiology to deduce transmission chains of diseases, such as AIDS <ref> [16] </ref>. Unfortunately, many current methods suffer from theoretical or practical drawbacks requiring long sequences in order to recover the correct tree topology. Parsimony methods [10], which perhaps are the most popular among them, attempt to find the tree that minimizes the number of mutations leading to the observed sequences.
Reference: [17] <author> N. Saitou and M. Nei. </author> <title> The neighbor-joining method: a new method for reconstructing phylo-genetic trees. Molecular Biology and Evolution, </title> <booktitle> 4 </booktitle> <pages> 406-425, </pages> <year> 1987. </year> <month> 17 </month>
Reference-contexts: In addition, HGT achieved better success rates than SQM in reconstructing a large tree from short sequences of 500-1000 characters. Our algorithm's performance is superior to such other distance-based methods as the widely used Neighbor Joining <ref> [17] </ref> and that of Farach and Kannan [7]. The rest of the paper is organized as follows. We briefly introduce the Cavender-Farris model of evolution of binary sequences in x 1.1, and discuss the computational difficulties of distance-based methods in x 1.2. <p> The idea of using triplets for tree building is not new, Neighbor Joining <ref> [17] </ref>, distance Wagner [8] and other distance methods are based on the idea of determining the internal nodes as centers of triplets. The greedy selection of triplets based on their average closeness guarantees the polynomial sample length requirements of our algorithm and results in better experimental performance.
References-found: 17

