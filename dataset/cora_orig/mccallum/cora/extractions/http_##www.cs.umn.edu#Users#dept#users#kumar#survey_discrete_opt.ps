URL: http://www.cs.umn.edu/Users/dept/users/kumar/survey_discrete_opt.ps
Refering-URL: http://www.cs.umn.edu/Users/dept/users/kumar/
Root-URL: http://www.cs.umn.edu
Email: Email: ananth@cs.umn.edu kumar@cs.umn.edu  
Phone: Phone: (612) 624 8083  
Title: A Survey of Parallel Search Algorithms for Discrete Optimization Problems  
Author: Ananth Y. Grama and Vipin Kumar 
Address: 4-192, 200 Union Street S.E. Minneapolis, MN 55455  
Affiliation: Department of Computer Science, University of Minnesota  
Abstract: Discrete optimization problems (DOPs) arise in various applications such as planning, scheduling, computer aided design, robotics, game playing and constraint directed reasoning. Often, a DOP is formulated in terms of finding a (minimum cost) solution path in a graph from an initial node to a goal node and solved by graph/tree search methods. Availability of parallel computers has created substantial interest in exploring parallel formulations of these graph and tree search methods. This article provides a survey of various parallel search algorithms such as Backtracking, IDA*, A*, Branch-and-Bound techniques and Dynamic Programming. It addresses issues related to load balancing, communication costs, scalability and the phenomenon of speedup anomalies in parallel search. Discrete optimization problems (DOPs) arise in various applications such as planning, scheduling, computer aided design, robotics, game playing and constraint directed reasoning. Formally, a DOP can be stated as follows : Given a finite discrete set X and a function f (x) defined on the elements of X, find an optimal element x opt , such that, f (x opt ) = minff (x)=x*Xg. In certain problems, the aim is to find any member of a solution set S ae X. These problems can also be easily stated in the above format by making f (x) = 0 for all x*S, and f (x) = 1 for all other elements of X. In most problems of practical interest, the set X is quite large. Consequently, exhaustive enumeration of elements in X to determine x opt is not feasible. Often, elements of X can be viewed as paths in graphs/trees, the cost function can be defined in terms of the cost of the arcs, and the DOP can be formulated in terms of finding a (minimum cost) solution path in the graph from an initial node to a goal node. Branch and bound [85], dynamic programming [14] and heuristic 
Abstract-found: 1
Intro-found: 1
Reference: [1] <institution> AAAI-88 Workshop on Parallel Algorithms for Machine Intelligence, </institution> <address> St. Paul, Minneapolis, </address> <month> August </month> <year> 1988. </year> <editor> Organizers: V. Kumar, L. N. Kanal, P.S. </editor> <booktitle> Gopalakrishnan; Sponsored by American Association for Artificial Intelligence. </booktitle>
Reference: [2] <institution> Proceedings of International Joint Conference on Artificial Intelligence-89 Workshop on Parallel Algorithms for Machine Intelligence, </institution> <year> 1989. </year> <editor> Organizers: V. Kumar, L. N. Kanal, P.S. </editor> <booktitle> Gopalakrishnan; Sponsored by American Association for Artificial Intelligence. </booktitle>
Reference: [3] <author> T. S. Abdelrahman and T. N. Mudge. </author> <title> Parallel branch-and-bound algorithms on hypercube multiprocessors. </title> <booktitle> In Proceedings of the Third Conference on Hypercubes, Concurrent Computers, and Applications, </booktitle> <pages> pages 1492-1499, </pages> <address> New York, NY, 1988. </address> <publisher> ACM Press. </publisher>
Reference: [4] <author> A. Agarwal and M. M. Klawe. </author> <title> Applications of generalized matrix searching to geometric algorithms. </title> <journal> Discrete Applied Mathematics, </journal> <volume> 27 </volume> <pages> 3-24, </pages> <year> 1990. </year> <month> 32 </month>
Reference-contexts: Based on these two classification criteria, it is possible to classify most DP formulations as serial-monadic, serial-polyadic, nonserial-monadic, and nonserial-polyadic. This classification, first proposed by Li and Wah [91] is important because it helps in designing parallel formulations for these algorithms. Different formulations of DP have been presented <ref> [77, 61, 91, 37, 4, 156, 28] </ref>. 2 General Algorithmic Issues in Parallel Formulations This section discusses some of the general aspects related to parallel formulations of an algorithm. Various terms used in subsequent sections are also defined here. <p> Furthermore, this categorization is not strong enough to allow development of generic parallel algorithms for each category. A number of new DP algorithms have been proposed which make use of such problem characteristics as sparsity, convexity and concavity <ref> [14, 37, 4, 156, 28] </ref>. Parallel formulations of many of these need to be investigated. A number of programming environments have been developed for implementing parallel search. These include DIB [33], Chare-Kernel [139], MANIP [151] and PICOS [133].
Reference: [5] <author> D. P. Agrawal, V. K. Janakiram, and Ram Mehrotra. </author> <title> A randomized parallel branch and bound algorithm. </title> <booktitle> In Proceedings of International Conference on Parallel Processing, </booktitle> <year> 1988. </year>
Reference-contexts: However these schemes appear to be far less scalable than those that do not require prioritization. A number of parallel formulations (based on receiver and sender initiated generation/transfer schemes) have been experimentally and analytically studied <ref> [35, 30, 119, 139, 125, 137, 5, 114, 11, 41, 75] </ref>. Finkel and Manber [33] present performance results for a number of problems such as the Traveling salesman problem and Knights tour for the Crystal multicomputer developed at the 16 University of Wisconsin.
Reference: [6] <author> A. V. Aho, John E. Hopcroft, and J. D. Ullman. </author> <title> The Design and Analysis of Computer Algorithms. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1974. </year>
Reference-contexts: Applications of this technique are in such varied domains as artificial intelligence, task planning, optimal control etc. <ref> [14, 15, 109, 153, 86, 6] </ref>. DP views a problem as a set of interdependent subproblems. It solves subproblems and uses the results to solve larger subproblems until the entire problem is solved.
Reference: [7] <author> A. V. Aho and J. D. Ullman. </author> <title> The Theory of Parsing, Translation and Compiling: Volume 1, Parsing. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1972. </year>
Reference-contexts: Kumar et al. [74] investigate parallel algorithms for this DP formulation. A large class of optimization problems can be formulated as nonserial-polyadic DP formulations. Examples of these problems are: optimal triangularization of polygons, optimal binary search trees [21], the matrix parenthesization problem [21], and the CYK parser <ref> [7] </ref>. The serial complexity of the 29 standard DP formulation for all these problems is O (n 3 ). Parallel formulations have been proposed in [49] that use O (n) processors on a hypercube and solve these problems in O (n 2 ) time.
Reference: [8] <author> S. G. Akl. </author> <title> The Design and Analysis of Parallel Algorithms. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1989. </year>
Reference-contexts: Since each processor has complete information about subproblem costs at preceding stages, no communication is needed other than the all-to-all broadcast and the next iteration can begin. Faster parallel formulations for hypercubes can be derived using various parallel matrix-vector product algorithms <ref> [74, 8, 16] </ref>. Li and Wah [91] show that solving monadic serial DP formulations is equivalent to multiplying a string of matrices. Note that the problem of multiplying two matrices has much more concurrency than the problem of matrix-vector multiplication.
Reference: [9] <author> S. G. Akl, D. T. Bernard, and R. J. Jordan. </author> <title> Design and implementation of a parallel tree search algorithm. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> PAMI-4:192-203, </volume> <year> 1982. </year>
Reference-contexts: Hence the simple solution discussed above cannot be used to develop an effective parallel formulation of ff fi. A number of researchers have developed parallel formulations of ff fi <ref> [9, 13, 30, 48, 94, 99, 31, 105, 119, 100] </ref>. In particular, methods developed in [30, 105, 119] have shown reasonable speedups on dozens of processors (e:g:, in Monien [105], a speedup of 12 is reported on 16 processors for chess). <p> Typical game trees are strongly ordered in nature. If this ordering information is not taken into consideration, parallel ff fi ends up searching a far bigger space than serial ff fi (which increases the search overhead). The techniques that use ordering information reduce the overall effectiveness of load balancing <ref> [9, 32] </ref>. Hence, an appropriate balance needs to be struck 17 in using ordering information in the load balancing algorithm. Another such tradeoff is in terms of the communication overhead for communicating the ff fi bounds and the pruning achieved due to them.
Reference: [10] <author> S. Arvindam, Vipin Kumar, and V. Nageshwara Rao. </author> <title> Floorplan optimization on multiprocessors. </title> <booktitle> In Proceedings of the 1989 International Conference on Computer Design, </booktitle> <year> 1989. </year> <note> Also published as Technical Report ACT-OODS-241-89, </note> <institution> Microelectornics and Computer Corporation, Austin, TX. </institution>
Reference-contexts: Monien et al. [107] show linear speedups on a network of transputers for a variety of combinatorial problems. Kumar et al. <ref> [75, 10, 11, 12] </ref> show linear speedups for problems such as 15 puzzle, tautology verification, and automatic test pattern generation for various architectures such as a 128 processor BBN Butterfly, 128 processor Intel Hypercube, a 1024 processor nCUBE2, and a 128 processor Symult 2010. <p> Parallel formulations of DFBB have been shown to yield near linear speedups for many problems and architectures. For example, Arvindam et al. <ref> [10] </ref> show near linear speedups on a 1024 processor Ncube T M , a 128 processor Symult T M and a network of 16 SUN workstations in the context of the floorplan optimization problem for VLSI circuits.
Reference: [11] <author> S. Arvindam, Vipin Kumar, and V. Nageshwara Rao. </author> <title> Efficient parallel algorithms for search problems: Applications in VLSI CAD. </title> <booktitle> In Proceedings of the Frontiers 90 Conference on Massively Parallel Computation, </booktitle> <year> 1990. </year>
Reference-contexts: However these schemes appear to be far less scalable than those that do not require prioritization. A number of parallel formulations (based on receiver and sender initiated generation/transfer schemes) have been experimentally and analytically studied <ref> [35, 30, 119, 139, 125, 137, 5, 114, 11, 41, 75] </ref>. Finkel and Manber [33] present performance results for a number of problems such as the Traveling salesman problem and Knights tour for the Crystal multicomputer developed at the 16 University of Wisconsin. <p> Monien et al. [107] show linear speedups on a network of transputers for a variety of combinatorial problems. Kumar et al. <ref> [75, 10, 11, 12] </ref> show linear speedups for problems such as 15 puzzle, tautology verification, and automatic test pattern generation for various architectures such as a 128 processor BBN Butterfly, 128 processor Intel Hypercube, a 1024 processor nCUBE2, and a 128 processor Symult 2010.
Reference: [12] <author> S. Arvindam, Vipin Kumar, V. Nageshwara Rao, and Vineet Singh. </author> <title> Automatic test pattern generation on multiprocessors. </title> <journal> Parallel Computing, </journal> <volume> 17(12) </volume> <pages> 1323-1342, </pages> <month> December </month> <year> 1991. </year>
Reference-contexts: Monien et al. [107] show linear speedups on a network of transputers for a variety of combinatorial problems. Kumar et al. <ref> [75, 10, 11, 12] </ref> show linear speedups for problems such as 15 puzzle, tautology verification, and automatic test pattern generation for various architectures such as a 128 processor BBN Butterfly, 128 processor Intel Hypercube, a 1024 processor nCUBE2, and a 128 processor Symult 2010. <p> Thus parallel DFS compensates for the lost performance in the case in which the heuristic is correct. Results from this model have been verified on the parallel formulation of a DFS algorithm, called PODEM, which uses very powerful heuristics to order the search tree <ref> [12] </ref>. PODEM is a popular algorithm used in automatic test pattern generation for combinatorial circuits. In the parallel formulation of PODEM [12], consistently superlinear speedups were demonstrated on a 128 processor Symult s2010 computer for problems with small number of solutions (very few faults in the circuit). 6 Parallel Dynamic Programming <p> Results from this model have been verified on the parallel formulation of a DFS algorithm, called PODEM, which uses very powerful heuristics to order the search tree <ref> [12] </ref>. PODEM is a popular algorithm used in automatic test pattern generation for combinatorial circuits. In the parallel formulation of PODEM [12], consistently superlinear speedups were demonstrated on a 128 processor Symult s2010 computer for problems with small number of solutions (very few faults in the circuit). 6 Parallel Dynamic Programming Parallel formulations of DP differ significantly for different serial DP algorithms.
Reference: [13] <author> G. M. Baudet. </author> <title> The Design and Analysis of Algorithms for Asynchronous Multiprocessors. </title> <type> PhD thesis, </type> <institution> Carnegie-Mellon University, </institution> <address> Pittsburgh, PA, </address> <year> 1978. </year>
Reference-contexts: Hence the simple solution discussed above cannot be used to develop an effective parallel formulation of ff fi. A number of researchers have developed parallel formulations of ff fi <ref> [9, 13, 30, 48, 94, 99, 31, 105, 119, 100] </ref>. In particular, methods developed in [30, 105, 119] have shown reasonable speedups on dozens of processors (e:g:, in Monien [105], a speedup of 12 is reported on 16 processors for chess).
Reference: [14] <author> R. Bellman and S. Dreyfus. </author> <title> Applied Dynamic Programming. </title> <publisher> Princeton University Press, </publisher> <address> Princeton, NJ, </address> <year> 1962. </year>
Reference-contexts: Applications of this technique are in such varied domains as artificial intelligence, task planning, optimal control etc. <ref> [14, 15, 109, 153, 86, 6] </ref>. DP views a problem as a set of interdependent subproblems. It solves subproblems and uses the results to solve larger subproblems until the entire problem is solved. <p> The solution to a subproblem is expressed as a function of solutions to one or more subproblems at the preceding levels. A special class of problems solved using DP are characterized by the Principle of Optimality defined by Bellman <ref> [14] </ref>. <p> Furthermore, this categorization is not strong enough to allow development of generic parallel algorithms for each category. A number of new DP algorithms have been proposed which make use of such problem characteristics as sparsity, convexity and concavity <ref> [14, 37, 4, 156, 28] </ref>. Parallel formulations of many of these need to be investigated. A number of programming environments have been developed for implementing parallel search. These include DIB [33], Chare-Kernel [139], MANIP [151] and PICOS [133].
Reference: [15] <author> U. Bertele and F. Brioschi. </author> <title> Nonserial Dynamic Programming. </title> <publisher> Academic Press, </publisher> <address> New York, NY, </address> <year> 1972. </year>
Reference-contexts: Applications of this technique are in such varied domains as artificial intelligence, task planning, optimal control etc. <ref> [14, 15, 109, 153, 86, 6] </ref>. DP views a problem as a set of interdependent subproblems. It solves subproblems and uses the results to solve larger subproblems until the entire problem is solved.
Reference: [16] <author> D. P. Bertsekas and J. N. Tsitsiklis. </author> <title> Parallel and Distributed Computation: Numerical Methods. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1989. </year>
Reference-contexts: This is akin to horizontal slicing of the matrix and the vector. Each processor computes the cost C (i) of the entries assigned to it. Computation of each entry takes O (n) time. This is followed by an all-to-all broadcast <ref> [16] </ref> during which solution costs of the subproblems at that stage are made known to all the processors. This operation takes O (n) time on a wide range of architectures from a linear array to a hypercube. <p> Since each processor has complete information about subproblem costs at preceding stages, no communication is needed other than the all-to-all broadcast and the next iteration can begin. Faster parallel formulations for hypercubes can be derived using various parallel matrix-vector product algorithms <ref> [74, 8, 16] </ref>. Li and Wah [91] show that solving monadic serial DP formulations is equivalent to multiplying a string of matrices. Note that the problem of multiplying two matrices has much more concurrency than the problem of matrix-vector multiplication.
Reference: [17] <author> Robert Bixby. </author> <title> Two applications of linear programming. </title> <booktitle> In Proceedings of the Workshop on Parallel Computing of Discrete Optimization Problems, </booktitle> <year> 1991. </year>
Reference-contexts: Many parallel formulations of best-first search have been applied to various problems. These have been shown to yield good (in some cases even near linear) speedups for moderate (&lt; 100) number of processors on large problem instances. Bixby <ref> [17] </ref> presents a parallel branch-and-bound algorithm for solving the symmetric traveling salesman problem. He also presents solutions of the LP relaxations of airline crew-scheduling models.
Reference: [18] <author> T. L. Cannon and K. L. Hoffman. </author> <title> Large scale 0-1 linear programming on distributed workstations. </title> <note> Working Paper, </note> <month> February </month> <year> 1989. </year>
Reference: [19] <author> D. J. Challou, M. Gini, and Vipin Kumar. </author> <title> Parallel search algorithms for robot motion planning. </title> <type> Technical Report R 92-65, </type> <institution> Department of Computer Science University of Minnesota, Minneapolis, MN, </institution> <year> 1992. </year> <note> Also appears in the working notes of the 1993 AAAI Spring Symposium on Innovative Applications of Massive Parallelism. </note>
Reference: [20] <author> E. Charniak and D. McDermott. </author> <title> Introduction to Artificial Intelligence. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1985. </year>
Reference-contexts: For practical problems, in depth-first search, it is much cheaper to incrementally build the state associated with each node rather than copy and/or create the new node from scratch <ref> [132, 20] </ref>. This also introduces additional inefficiency. Furthermore, the memory requirement at 15 a processor is potentially unbounded, as a processor may be required to store an arbitrarily large number of work pieces during execution.
Reference: [21] <author> Thomas H. Cormen, Charles E. Leiserson, and Ronald L. Rivest. </author> <title> Introduction to Algorithms. </title> <publisher> MIT Press, McGraw-Hill, </publisher> <address> New York, NY, </address> <year> 1990. </year>
Reference-contexts: Each subproblem uses solutions from only two subproblems at the previous level. Kumar et al. [74] investigate parallel algorithms for this DP formulation. A large class of optimization problems can be formulated as nonserial-polyadic DP formulations. Examples of these problems are: optimal triangularization of polygons, optimal binary search trees <ref> [21] </ref>, the matrix parenthesization problem [21], and the CYK parser [7]. The serial complexity of the 29 standard DP formulation for all these problems is O (n 3 ). <p> Kumar et al. [74] investigate parallel algorithms for this DP formulation. A large class of optimization problems can be formulated as nonserial-polyadic DP formulations. Examples of these problems are: optimal triangularization of polygons, optimal binary search trees <ref> [21] </ref>, the matrix parenthesization problem [21], and the CYK parser [7]. The serial complexity of the 29 standard DP formulation for all these problems is O (n 3 ). Parallel formulations have been proposed in [49] that use O (n) processors on a hypercube and solve these problems in O (n 2 ) time.
Reference: [22] <author> H. Crowder, E. L. Johnson, and M. Padberg. </author> <title> Solving large-scale zero-one linear programming problem. </title> <journal> Operations Research, </journal> <volume> 2 </volume> <pages> 803-834, </pages> <year> 1983. </year>
Reference: [23] <author> William J. Dally. </author> <title> A VLSI Architecture for Concurrent Data Structures. </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, MA, </address> <year> 1987. </year>
Reference-contexts: A number of communication strategies have been proposed by researchers that address these two objectives. 4.1.1 Quantitative Load Balancing Strategies Random Communication Strategy In the random communication strategy, each processor periodically puts some of its best nodes into the OPEN list of a randomly selected processor 21 strategy. <ref> [147, 23, 79] </ref>. This ensures that if some processor has a good part of the search space, then others get a part of it. Although the scheme is designed to explicitly address quantitative load balancing, it also implicitly ensures a measure of qualitative load balance.
Reference: [24] <author> R. Dehne, A. Ferreira, and A. Rau-Chaplin. </author> <title> A massively parallel knowledge-base server using a hypercube multiprocessor. </title> <type> Technical Report SCS-TR-170, </type> <institution> Carleton University, </institution> <year> 1990. </year> <month> 33 </month>
Reference: [25] <author> J. D. DeMello, J. L. Calvet, and J. M. Garcia. </author> <title> Vectorization and multitasking of dynamic programming in control: experiments on a CRAY-2. </title> <journal> Parallel Computing, </journal> <volume> 13 </volume> <pages> 261-269, </pages> <year> 1990. </year>
Reference-contexts: They also present a smarter mapping that does not have this drawback, and show near-linear speedup on a mesh embedded in a 256 processor nCUBE2 parallel computer for the matrix parenthesization problem. Dantas et al. <ref> [25] </ref> use vectorized formulations of DP for the Cray to solve optimal control problems. An important characteristic of DP techniques with respect to their parallel formulations is the density of dependencies between various levels in the multistage graph.
Reference: [26] <author> E. W. Dijkstra, W. H. Seijen, and A. J. M. Van Gasteren. </author> <title> Derivation of a termination detection algorithm for a distributed computation. </title> <journal> Information Processing Letters, </journal> <volume> 16-5:217-219, </volume> <year> 1983. </year>
Reference-contexts: On shared address space architectures (e.g., Sequent, BBN Butterfly), a globally shared variable is used to keep track of the number of idle processors. On message passing computers (e.g., the Intel Hypercube, nCUBE), algorithms such as Dijkstra's token termination detection algorithm <ref> [26] </ref> can be used. This approach has been used by a number of researchers and tested in the context of different problems and architectures [129, 80, 57, 118, 95].
Reference: [27] <author> S. Dutt and N. R. Mahapatra. </author> <title> Parallel a* algorithms and their performance on hypercube multiprocessors. </title> <booktitle> In Proceedings of the Seventh International Parallel Processing Symposium, </booktitle> <pages> pages 797-803, </pages> <year> 1993. </year> <note> To appear in the Journal of Parallel and Distributed Computing, </note> <month> Sept </month> <year> 1994. </year>
Reference-contexts: This scheme can be modified for other networks. One such modification is the nearest-neighbor round-robin scheme in which each processor communicates only with its nearest neighbors in a round-robin fashion <ref> [27, 96] </ref>. A generalization of this scheme defines a neighborhood for each processor within which round-robin communication is performed. 4.1.2 Qualitative Load Balancing Strategies Rao and Kumar [79] propose a communication scheme referred to as the blackboard communication strategy. <p> This is done by allowing transfer of nodes only if the heuristic value of the node is better than a certain threshold. This ensures that good nodes in the search tree are uniformly distributed among various processors. In <ref> [27, 96] </ref>, the nearest-neighbor round-robin strategy is combined with a qualitative load balancing scheme. This scheme, referred to as quality equalizing (QE) strategy in [27], is analytically studied and compared with round-robin and random communication strategies. <p> This ensures that good nodes in the search tree are uniformly distributed among various processors. In [27, 96], the nearest-neighbor round-robin strategy is combined with a qualitative load balancing scheme. This scheme, referred to as quality equalizing (QE) strategy in <ref> [27] </ref>, is analytically studied and compared with round-robin and random communication strategies. The performance of the QE strategy is shown to be better than the round-robin and random communication strategies without qualitative load balance [27]. 4.1.3 Experimental and Analytical Results The effectiveness of different parallel formulations is strongly dependent upon the <p> This scheme, referred to as quality equalizing (QE) strategy in <ref> [27] </ref>, is analytically studied and compared with round-robin and random communication strategies. The performance of the QE strategy is shown to be better than the round-robin and random communication strategies without qualitative load balance [27]. 4.1.3 Experimental and Analytical Results The effectiveness of different parallel formulations is strongly dependent upon the characteristics of the problem being solved. Kumar et al. [79] experimentally evaluate the relationship between the characteristics of the search spaces and the suitability of various parallel formulations.
Reference: [28] <author> D. Eppstein, Z. Ghalil, and R. Giancarlo. </author> <title> Speeding up dynamic programming. </title> <booktitle> In Proceedings of 29th IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pages 488-496, </pages> <year> 1988. </year>
Reference-contexts: Based on these two classification criteria, it is possible to classify most DP formulations as serial-monadic, serial-polyadic, nonserial-monadic, and nonserial-polyadic. This classification, first proposed by Li and Wah [91] is important because it helps in designing parallel formulations for these algorithms. Different formulations of DP have been presented <ref> [77, 61, 91, 37, 4, 156, 28] </ref>. 2 General Algorithmic Issues in Parallel Formulations This section discusses some of the general aspects related to parallel formulations of an algorithm. Various terms used in subsequent sections are also defined here. <p> Furthermore, this categorization is not strong enough to allow development of generic parallel algorithms for each category. A number of new DP algorithms have been proposed which make use of such problem characteristics as sparsity, convexity and concavity <ref> [14, 37, 4, 156, 28] </ref>. Parallel formulations of many of these need to be investigated. A number of programming environments have been developed for implementing parallel search. These include DIB [33], Chare-Kernel [139], MANIP [151] and PICOS [133].
Reference: [29] <author> M. Evett, James Hendler, Ambujashka Mahanti, and Dana Nau. PRA*: </author> <title> A memory-limited heuristic search procedure for the connection machine. </title> <booktitle> In Proceedings of the Third Symposium on the Frontiers of Massively Parallel Computation, </booktitle> <pages> pages 145-149, </pages> <year> 1990. </year>
Reference-contexts: Manzini [98] shows that this method ensures a good distribution of promising nodes among all processors. Distributing nodes in this fashion will cause performance degradation, as each node generation results in a corresponding communication cycle. Evett et al. <ref> [29] </ref> present a similar scheme called PRA* (parallel retracting A*), which is designed to operate under limited memory conditions. In this formulation, each node is hashed to a unique processor. If a processor receives more nodes than it can locally store, then it retracts nodes with poorer heuristic values. <p> Further, the single biggest deterrent to the use of best-first search is its large memory requirement. Some parallel best-first search formulations have been proposed that are designed to operate under limited memory constraints <ref> [29] </ref>. The nature and performance of these schemes is not clearly understood. The occurrence of consistent superlinear speedup on certain problems implies that the sequential DFS algorithm is suboptimal for these problems and that parallel DFS time sliced on one processor dominates sequential DFS.
Reference: [30] <author> Chris Ferguson and Richard Korf. </author> <title> Distributed tree search and its application to alpha-beta pruning. </title> <booktitle> In Proceedings of the 1988 National Conference on Artificial Intelligence, </booktitle> <month> August </month> <year> 1988. </year>
Reference-contexts: For highly irregular search spaces, stack splitting is more likely to yield subtasks which are of comparable size, 10 splitting. 11 Subtask generation scheme! Sender Initiated Receiver Initiated Work transfer strategy! Sender Initiated Receiver Initiated Receiver Initiated Splitting strategy# Node Splitting Ranade [125] Furuichi et al. [35] Ferguson and Korf <ref> [30] </ref> Shu and Kale [139] Monien et al. [105] Finkel and Manber [33] Karp and Zhang [59, 60] Stack Splitting Kumar et al. [81, 128, 75] Finkel and Manber [33] Table 1: Taxonomy of parallel formulations of DFS. as it gives out nodes at various levels of the stack. <p> In contrast, node splitting can yield subtasks which are of widely differing sizes since subtrees rooted at different nodes in a tree can be of vastly different sizes. Typically, load balancing schemes utilizing node splitting <ref> [35, 125, 30, 119, 60, 59] </ref> require more work transfers compared to those using stack splitting. Subtask Distribution : Issues relating to when work available at a processor is split and how it is distributed are critical parameters of a parallel formulation. <p> However, on machines that have hardware support for concurrent access to a global pointer (e.g., the hardware fetch and add [38]), the global round robin scheme would perform better than random polling. Parallel DFS using sender initiated subtask distribution has been proposed by a number of researchers <ref> [30, 119, 35, 139, 125] </ref>. These use different techniques for task generation and transfer as shown in Table 1. Ichiyoshi et al. propose the single level and multi level sender based scheme [35]. These schemes are illustrated in Figure 7. <p> A leaf processor is allocated to another subtask generator when its designated subtask generator runs out of work. For l = 1, the multi and single level schemes are identical. Kimura et al. [66] present detailed scalability analysis of these schemes. Ferguson and Korf <ref> [30, 119] </ref> present a work distribution scheme, called Distributed Tree Search (DTS), in which processors are allocated to different parts of the search tree dynamically. Initially all the processors are assigned to the root. <p> If a processor finishes searching its part of the tree sooner than others, it is reassigned to an unexplored part of another processors' tree. DTS has been shown to be quite effective in the context of parallel ff fi search on a 32 processor hypercube <ref> [30] </ref>. A number of techniques using randomized allocation have been presented in the context of parallel depth-first search [125, 139, 137, 55]. <p> However these schemes appear to be far less scalable than those that do not require prioritization. A number of parallel formulations (based on receiver and sender initiated generation/transfer schemes) have been experimentally and analytically studied <ref> [35, 30, 119, 139, 125, 137, 5, 114, 11, 41, 75] </ref>. Finkel and Manber [33] present performance results for a number of problems such as the Traveling salesman problem and Knights tour for the Crystal multicomputer developed at the 16 University of Wisconsin. <p> Hence the simple solution discussed above cannot be used to develop an effective parallel formulation of ff fi. A number of researchers have developed parallel formulations of ff fi <ref> [9, 13, 30, 48, 94, 99, 31, 105, 119, 100] </ref>. In particular, methods developed in [30, 105, 119] have shown reasonable speedups on dozens of processors (e:g:, in Monien [105], a speedup of 12 is reported on 16 processors for chess). <p> Hence the simple solution discussed above cannot be used to develop an effective parallel formulation of ff fi. A number of researchers have developed parallel formulations of ff fi [9, 13, 30, 48, 94, 99, 31, 105, 119, 100]. In particular, methods developed in <ref> [30, 105, 119] </ref> have shown reasonable speedups on dozens of processors (e:g:, in Monien [105], a speedup of 12 is reported on 16 processors for chess). The speedups obtained here are much less than those obtained for DFS formulations (e:g:, see [128]).
Reference: [31] <author> R. A. Finkel and J. P. Fishburn. </author> <title> Parallelism in alpha-beta search. </title> <journal> Artificial Intelligence, </journal> <volume> 19 </volume> <pages> 89-106, </pages> <year> 1982. </year>
Reference-contexts: Hence the simple solution discussed above cannot be used to develop an effective parallel formulation of ff fi. A number of researchers have developed parallel formulations of ff fi <ref> [9, 13, 30, 48, 94, 99, 31, 105, 119, 100] </ref>. In particular, methods developed in [30, 105, 119] have shown reasonable speedups on dozens of processors (e:g:, in Monien [105], a speedup of 12 is reported on 16 processors for chess).
Reference: [32] <author> R. A. Finkel and J. P. Fishburn. </author> <title> Improved speedup bounds for parallel alpha-beta search. </title> <journal> Pattern Analysis and Machine Intelligence, </journal> <volume> 5,No.1:89-92, </volume> <year> 1983. </year>
Reference-contexts: Typical game trees are strongly ordered in nature. If this ordering information is not taken into consideration, parallel ff fi ends up searching a far bigger space than serial ff fi (which increases the search overhead). The techniques that use ordering information reduce the overall effectiveness of load balancing <ref> [9, 32] </ref>. Hence, an appropriate balance needs to be struck 17 in using ordering information in the load balancing algorithm. Another such tradeoff is in terms of the communication overhead for communicating the ff fi bounds and the pruning achieved due to them.
Reference: [33] <author> Raphael A. Finkel and Udi Manber. </author> <title> DIB a distributed implementation of backtracking. </title> <journal> ACM Transactions of Programming Languages and Systems, </journal> <volume> 9 No. 2 </volume> <pages> 235-256, </pages> <month> April </month> <year> 1987. </year>
Reference-contexts: subtasks which are of comparable size, 10 splitting. 11 Subtask generation scheme! Sender Initiated Receiver Initiated Work transfer strategy! Sender Initiated Receiver Initiated Receiver Initiated Splitting strategy# Node Splitting Ranade [125] Furuichi et al. [35] Ferguson and Korf [30] Shu and Kale [139] Monien et al. [105] Finkel and Manber <ref> [33] </ref> Karp and Zhang [59, 60] Stack Splitting Kumar et al. [81, 128, 75] Finkel and Manber [33] Table 1: Taxonomy of parallel formulations of DFS. as it gives out nodes at various levels of the stack. <p> transfer strategy! Sender Initiated Receiver Initiated Receiver Initiated Splitting strategy# Node Splitting Ranade [125] Furuichi et al. [35] Ferguson and Korf [30] Shu and Kale [139] Monien et al. [105] Finkel and Manber <ref> [33] </ref> Karp and Zhang [59, 60] Stack Splitting Kumar et al. [81, 128, 75] Finkel and Manber [33] Table 1: Taxonomy of parallel formulations of DFS. as it gives out nodes at various levels of the stack. In contrast, node splitting can yield subtasks which are of widely differing sizes since subtrees rooted at different nodes in a tree can be of vastly different sizes. <p> Parallel formulations of DFS in this class are discussed in <ref> [33, 105, 75, 81] </ref>. In this formulation, each processor searches a disjoint part of the tree in a depth-first fashion. When a goal is found, all of them quit. <p> This selection should be made so as to minimize overheads due to load imbalance, communication requests, and contention over any shared data structures. For example, consider two techniques, random polling and global round robin discussed in <ref> [75, 33] </ref>. In random polling, a processor is selected at random and the work request is targeted to this processor. In global round robin, a global pointer is maintained at a designated processor. This pointer determines the target of a 13 work request. <p> However these schemes appear to be far less scalable than those that do not require prioritization. A number of parallel formulations (based on receiver and sender initiated generation/transfer schemes) have been experimentally and analytically studied [35, 30, 119, 139, 125, 137, 5, 114, 11, 41, 75]. Finkel and Manber <ref> [33] </ref> present performance results for a number of problems such as the Traveling salesman problem and Knights tour for the Crystal multicomputer developed at the 16 University of Wisconsin. Monien et al. [107] show linear speedups on a network of transputers for a variety of combinatorial problems. <p> Parallel formulations of many of these need to be investigated. A number of programming environments have been developed for implementing parallel search. These include DIB <ref> [33] </ref>, Chare-Kernel [139], MANIP [151] and PICOS [133]. Continued work on these programming environments is of prime importance, as they can potentially simplify the development of production level software for solving optimization problems.
Reference: [34] <author> Roger Frye and Jacek Myczkowski. </author> <title> Exhaustive search of unstructured trees on the connection machine. </title> <type> Technical report, </type> <institution> Thinking Machines Corporation, </institution> <address> Cambridge, MA, </address> <year> 1990. </year>
Reference-contexts: In addition, several redistribution techniques have also been proposed. Recent work has shown that SIMD architectures such as CM2 T M can also be used to implement parallel DFS algorithms effectively. Frye <ref> [34] </ref> presents an implementation of DFS on the CM2 for a block puzzle. Powley et al.[118] and Mahanti et al.[95] present parallel IDA* for solving the 15 puzzle problem on CM2 T M . Powley's and Mahanti's formulations use different triggering and redistribution mechanisms.
Reference: [35] <author> M. Furuichi, K. Taki, and N. Ichiyoshi. </author> <title> A multi-level load balancing scheme for OR-parallel exhaustive search programs on the Multi-PSI. </title> <booktitle> In Proceedings of the Second ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, </booktitle> <pages> pages 50-59, </pages> <year> 1990. </year>
Reference-contexts: For highly irregular search spaces, stack splitting is more likely to yield subtasks which are of comparable size, 10 splitting. 11 Subtask generation scheme! Sender Initiated Receiver Initiated Work transfer strategy! Sender Initiated Receiver Initiated Receiver Initiated Splitting strategy# Node Splitting Ranade [125] Furuichi et al. <ref> [35] </ref> Ferguson and Korf [30] Shu and Kale [139] Monien et al. [105] Finkel and Manber [33] Karp and Zhang [59, 60] Stack Splitting Kumar et al. [81, 128, 75] Finkel and Manber [33] Table 1: Taxonomy of parallel formulations of DFS. as it gives out nodes at various levels of <p> In contrast, node splitting can yield subtasks which are of widely differing sizes since subtrees rooted at different nodes in a tree can be of vastly different sizes. Typically, load balancing schemes utilizing node splitting <ref> [35, 125, 30, 119, 60, 59] </ref> require more work transfers compared to those using stack splitting. Subtask Distribution : Issues relating to when work available at a processor is split and how it is distributed are critical parameters of a parallel formulation. <p> Subtasks generated using the selected generation strategy must be distributed among other processors. Subtasks can be delivered to processors needing them, either on demand (i:e:, when they are idle) <ref> [35] </ref> or without demand [125, 139, 137]. The former is called sender initiated work transfer and the latter is called receiver initiated work transfer. Based on the two generation strategies and two transfer strategies, it is possible to visualize four classes of subtask distribution schemes. <p> However, on machines that have hardware support for concurrent access to a global pointer (e.g., the hardware fetch and add [38]), the global round robin scheme would perform better than random polling. Parallel DFS using sender initiated subtask distribution has been proposed by a number of researchers <ref> [30, 119, 35, 139, 125] </ref>. These use different techniques for task generation and transfer as shown in Table 1. Ichiyoshi et al. propose the single level and multi level sender based scheme [35]. These schemes are illustrated in Figure 7. <p> Parallel DFS using sender initiated subtask distribution has been proposed by a number of researchers [30, 119, 35, 139, 125]. These use different techniques for task generation and transfer as shown in Table 1. Ichiyoshi et al. propose the single level and multi level sender based scheme <ref> [35] </ref>. These schemes are illustrated in Figure 7. In the single level scheme, a designated processor called MANAGER generates a large number of subtasks and gives them one by one to the requesting processors on demand. <p> In this case, the MANAGER becomes the bottleneck. Hence, this scheme does not have a good scalability. The multi level scheme tries to circumvent the subtask generation bottleneck <ref> [35] </ref> of the single level scheme through multiple level subtask generation. In this scheme, all processors are arranged in the form of an m-ary tree of depth l. The task of super-subtask generation is given to the root processor. <p> However these schemes appear to be far less scalable than those that do not require prioritization. A number of parallel formulations (based on receiver and sender initiated generation/transfer schemes) have been experimentally and analytically studied <ref> [35, 30, 119, 139, 125, 137, 5, 114, 11, 41, 75] </ref>. Finkel and Manber [33] present performance results for a number of problems such as the Traveling salesman problem and Knights tour for the Crystal multicomputer developed at the 16 University of Wisconsin.
Reference: [36] <author> M. Garey and D. S. Johnson. </author> <title> Computers and Intractability. </title> <publisher> Freeman, </publisher> <address> San Francisco, CA, </address> <year> 1979. </year>
Reference: [37] <author> Zvi Ghalil and Kunsoo Park. </author> <title> Dynamic programming with convexity, concavity and sparsity. </title> <journal> Theoretical Computer Science, </journal> <volume> 92 </volume> <pages> 49-76, </pages> <year> 1992. </year>
Reference-contexts: Based on these two classification criteria, it is possible to classify most DP formulations as serial-monadic, serial-polyadic, nonserial-monadic, and nonserial-polyadic. This classification, first proposed by Li and Wah [91] is important because it helps in designing parallel formulations for these algorithms. Different formulations of DP have been presented <ref> [77, 61, 91, 37, 4, 156, 28] </ref>. 2 General Algorithmic Issues in Parallel Formulations This section discusses some of the general aspects related to parallel formulations of an algorithm. Various terms used in subsequent sections are also defined here. <p> Furthermore, this categorization is not strong enough to allow development of generic parallel algorithms for each category. A number of new DP algorithms have been proposed which make use of such problem characteristics as sparsity, convexity and concavity <ref> [14, 37, 4, 156, 28] </ref>. Parallel formulations of many of these need to be investigated. A number of programming environments have been developed for implementing parallel search. These include DIB [33], Chare-Kernel [139], MANIP [151] and PICOS [133].
Reference: [38] <author> A. Gottlieb, R. Grishman, C. P. Kruskal, K. P. McAuliffe, L. Rudolph, and M. Snir. </author> <title> The NYU ultracomputer - designing a MIMD, shared memory parallel computer. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-32, No. 2 </volume> <pages> 175-189, </pages> <month> February </month> <year> 1983. </year>
Reference-contexts: Consequently, when the number of processors increases, its performance degrades. In contrast, random polling results in more work requests but does not suffer from contention over shared data structures. However, on machines that have hardware support for concurrent access to a global pointer (e.g., the hardware fetch and add <ref> [38] </ref>), the global round robin scheme would perform better than random polling. Parallel DFS using sender initiated subtask distribution has been proposed by a number of researchers [30, 119, 35, 139, 125]. These use different techniques for task generation and transfer as shown in Table 1.
Reference: [39] <author> Ananth Grama, Anshul Gupta, and Vipin Kumar. </author> <title> Isoefficiency function: A scalability metric for parallel algorithms and architectures. </title> <journal> IEEE Parallel and Distributed Technology, Special Issue on Parallel and Distributed Systems: From Theory to Practice, </journal> <volume> 1 </volume> (3):12-21, 1993. 
Reference-contexts: We call such algorithms scalable parallel algorithms. The rate at which the problem size must grow with respect to the number of processors to keep the efficiency fixed determines the degree of scalability of a parallel algorithm <ref> [39, 76, 81, 74] </ref> and is called the isoefficiency function.
Reference: [40] <author> Ananth Grama, V. Kumar, and P. M. Pardalos. </author> <title> Parallel processing of discrete optimization problems. </title> <booktitle> In Encyclopaedia of Microcomputers, </booktitle> <pages> pages 129-157. </pages> <publisher> Marcel Dekker Inc., </publisher> <address> New York, NY, </address> <year> 1992. </year>
Reference: [41] <author> Ananth Grama, Vipin Kumar, and V. Nageshwara Rao. </author> <title> Experimental evaluation of load balancing techniques for the hypercube. </title> <booktitle> In Proceedings of the Parallel Computing '91 Conference, </booktitle> <pages> pages 497-514, </pages> <year> 1991. </year>
Reference-contexts: However these schemes appear to be far less scalable than those that do not require prioritization. A number of parallel formulations (based on receiver and sender initiated generation/transfer schemes) have been experimentally and analytically studied <ref> [35, 30, 119, 139, 125, 137, 5, 114, 11, 41, 75] </ref>. Finkel and Manber [33] present performance results for a number of problems such as the Traveling salesman problem and Knights tour for the Crystal multicomputer developed at the 16 University of Wisconsin. <p> Kumar, Ananth and Rao <ref> [41, 75, 81, 128] </ref> have investigated the scalability and performance of many of these schemes for a variety of architectures such as hypercubes, meshes and networks of workstations. 3.2 Parallel Formulations of DFBB Parallel formulations of DFBB are similar to those of DFS.
Reference: [42] <author> L. J. Guibas, H. T. Kung, and C. D. Thompson. </author> <title> Direct VLSI Implementation of Combinatorial Algorithms. </title> <booktitle> In Proceedings of Conference on Very Large Scale Integration, California Institute of Technology, </booktitle> <pages> pages 509-525, </pages> <year> 1979. </year>
Reference-contexts: Parallel formulations have been proposed in [49] that use O (n) processors on a hypercube and solve these problems in O (n 2 ) time. A systolic array algorithm has been proposed by Guibas et al. <ref> [42] </ref> that uses O (n 2 ) processing cells and solves the problem in O (n) time. These and other parallel formulations are discussed by Kumar et al. in [74]. Faster algorithms for solving this problem use a large number of processors to gain small improvements in time. <p> Huang et al. [45] present a similar algorithm for CREW-PRAM models which run in O ( p n log n) time on O (n 3:5 log n) processors. Karypis and Kumar [63] analyze three different mappings of the systolic algorithm presented by Guibas et al. <ref> [42] </ref> and experimentally evaluate them in the context of the matrix multiplication parenthesization problem on an nCUBE2.
Reference: [43] <author> Jiawei Hong and Xiaonan Tan. </author> <title> Dynamic cyclic load balancing on hypercube. </title> <booktitle> In Proceedings of the Fourth Conference on Hypercubes, Concurrent Computers, and Applications, </booktitle> <year> 1989. </year> <month> 34 </month>
Reference-contexts: The performance of many of these formulations has been theoretically shown to be within a small factor off from the optimal. Continuing work in this area has focused on determining tighter bounds for various formulations while making fewer assumptions [60, 59]. There are a number of load balancing techniques <ref> [43, 56, 65, 137, 138, 155] </ref> that are applicable only if an estimate of the amount of work is available. If we could devise some technique to estimate the amount of unfinished work in a (partially searched) state space tree, then all these parallel formulations could be applied to DFS.
Reference: [44] <author> Ellis Horowitz and Sartaj Sahni. </author> <title> Fundamentals of Computer Algorithms. </title> <publisher> Computer Science Press, </publisher> <address> Rockville, MD, </address> <year> 1978. </year>
Reference-contexts: This model is validated by experiments on synthetic state-space trees modeling the 27 hackers problem [141], the 15-puzzle problem and the n-Queens problem <ref> [44] </ref>. (In these experiments, serial and parallel DFS do not use any heuristic ordering, and select successors arbitrarily.) The basic reason for this phenomenon is that parallel search can invest resources into multiple regions of the search frontier concurrently.
Reference: [45] <author> S. H. S. Huang, H. Liu, and V. Vishwanathan. </author> <title> A sub-linear parallel algorithm for some dynamic programming problems. </title> <booktitle> In Proceedings of 1990 International Conference on Parallel Processing, </booktitle> <pages> pages III-261-III-264, </pages> <year> 1990. </year>
Reference-contexts: Rytter [136] uses the parallel pebble game on trees to reduce the number of processors required to O (n 6 = log n) for a CREW-PRAM model and O (n 6 ) for a hypercube while still solving it in O (log 2 n) time. Huang et al. <ref> [45] </ref> present a similar algorithm for CREW-PRAM models which run in O ( p n log n) time on O (n 3:5 log n) processors.
Reference: [46] <author> S.-R. Huang and Larry S. Davis. </author> <title> A tight upper bound for the speedup of parallel best-first branch-and-bound algorithms. </title> <type> Technical report, </type> <institution> Center for Automation Research, University of Maryland, College Park, MD, </institution> <year> 1987. </year>
Reference-contexts: In most parallel formulations of A*, different processors concurrently expand different frontier nodes. Conceptually, these formulations differ in the data structures used to implement the priority queue of the A* algorithm <ref> [104, 106, 107, 122, 121, 123, 46, 151] </ref>. Given P processors, the simplest parallel strategy is to let each parallel processor work on one of the P current best nodes in the OPEN list. <p> Given P processors, the simplest parallel strategy is to let each parallel processor work on one of the P current best nodes in the OPEN list. This strategy is called the centralized strategy <ref> [104, 123, 46] </ref> because each processor gets work from the global OPEN list. As discussed in [52], this strategy should not result in much redundant search. Figure 8 illustrates this strategy. <p> Even on shared address space computers, contention for OPEN would limit the speedup to (T exp + T access )=T access , where T exp is the average time for one node expansion, and T access is the average time for accessing OPEN per node expansion <ref> [46] </ref>. Note that the access to CLOSED does not cause contention, as different processors would manipulate different nodes. One way to avoid the contention due to centralized OPEN list is to let each processor have its 19 20 own local OPEN list.
Reference: [47] <author> S.-R. Huang and Larry S. Davis. </author> <title> Parallel iterative A* search: An admissible distributed heuristic search algorithm. </title> <booktitle> In Proceedings of the International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 23-29, </pages> <year> 1989. </year>
Reference-contexts: Round-Robin Communication Strategies In the round-robin communication strategy, each processor communicates by periodically putting some of its best nodes in the OPEN list of a processor chosen in a round-robin fashion <ref> [47] </ref>. Since this potentially requires communication between all pairs of processors, the scheme is particularly suited to high bandwidth, low diameter communication networks. This scheme can be modified for other networks.
Reference: [48] <author> M. M. Huntbach and F. Warren Burton. </author> <title> Alpha-beta search on virtual tree machines. </title> <journal> Information Science, </journal> <volume> 44 </volume> <pages> 3-17, </pages> <year> 1988. </year>
Reference-contexts: Hence the simple solution discussed above cannot be used to develop an effective parallel formulation of ff fi. A number of researchers have developed parallel formulations of ff fi <ref> [9, 13, 30, 48, 94, 99, 31, 105, 119, 100] </ref>. In particular, methods developed in [30, 105, 119] have shown reasonable speedups on dozens of processors (e:g:, in Monien [105], a speedup of 12 is reported on 16 processors for chess).
Reference: [49] <author> Oscar H. Ibarra, T. C. Pong, and Stephen M. Sohn. </author> <title> Parallel recognition and parsing on the hypercube. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 40(6) </volume> <pages> 764-770, </pages> <month> June </month> <year> 1991. </year>
Reference-contexts: Examples of these problems are: optimal triangularization of polygons, optimal binary search trees [21], the matrix parenthesization problem [21], and the CYK parser [7]. The serial complexity of the 29 standard DP formulation for all these problems is O (n 3 ). Parallel formulations have been proposed in <ref> [49] </ref> that use O (n) processors on a hypercube and solve these problems in O (n 2 ) time. A systolic array algorithm has been proposed by Guibas et al. [42] that uses O (n 2 ) processing cells and solves the problem in O (n) time.
Reference: [50] <author> M. Imai, Y. Tateizumi, Y. Yoshida, and T. Fukumura. </author> <title> The architecture and efficiency of DON: A combinatorial problem oriented multicomputer system. </title> <booktitle> In Proceedings of International Conference on Distributed Computing Systems, </booktitle> <year> 1984. </year>
Reference-contexts: An instance of speedup anomaly is shown in Figure 11 (a). A speedup of less than P attributed to excess work done by the parallel formulation compared to the sequential formulation is called termed as a deceleration anomaly <ref> [51, 82, 104, 50, 148] </ref>. An instance of deceleration anomaly is illustrated in Figure 11 (b). The speedup obtained in some 26 cases may actually be less than 1, i.e. the parallel formulation is in fact slower than the sequential formulation.
Reference: [51] <author> M. Imai, Y. Yoshida, and T. Fukumura. </author> <title> A parallel searching scheme for multiprocessor systems and its application to combinatorial problems. </title> <booktitle> In Proceedings of International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 416-418, </pages> <year> 1979. </year>
Reference-contexts: A number of researchers have observed and analyzed the existence of speedup anomalies. Using P processing elements, an acceleration anomaly manifests itself in the form of a speedup greater than P <ref> [51, 82, 70, 92, 108, 129] </ref>. An instance of speedup anomaly is shown in Figure 11 (a). A speedup of less than P attributed to excess work done by the parallel formulation compared to the sequential formulation is called termed as a deceleration anomaly [51, 82, 104, 50, 148]. <p> An instance of speedup anomaly is shown in Figure 11 (a). A speedup of less than P attributed to excess work done by the parallel formulation compared to the sequential formulation is called termed as a deceleration anomaly <ref> [51, 82, 104, 50, 148] </ref>. An instance of deceleration anomaly is illustrated in Figure 11 (b). The speedup obtained in some 26 cases may actually be less than 1, i.e. the parallel formulation is in fact slower than the sequential formulation. <p> An instance of deceleration anomaly is illustrated in Figure 11 (b). The speedup obtained in some 26 cases may actually be less than 1, i.e. the parallel formulation is in fact slower than the sequential formulation. This is termed as detrimental anomaly <ref> [92, 51, 82, 104] </ref>. Lai and Sahni [82] present early work on quantifying the existence of speedup anomalies in best-first search. They show that given an instance of a problem, there exists a number k such that there is little advantage in expanding more than k nodes in parallel.
Reference: [52] <author> Keki B. Irani and Yi Fong Shih. </author> <title> Parallel a* and ao* algorithms: An optimality criterion and performance evaluation. </title> <booktitle> In Proceedings of International Conference on Parallel Processing, </booktitle> <pages> pages 274-277, </pages> <year> 1986. </year>
Reference-contexts: Given P processors, the simplest parallel strategy is to let each parallel processor work on one of the P current best nodes in the OPEN list. This strategy is called the centralized strategy [104, 123, 46] because each processor gets work from the global OPEN list. As discussed in <ref> [52] </ref>, this strategy should not result in much redundant search. Figure 8 illustrates this strategy.
Reference: [53] <author> Virendra K. Janakiram, Dharma P. Agrawal, and Ram Mehrotra. </author> <title> Randomized parallel algorithms for prolog programs and backtracking applications. </title> <booktitle> In Proceedings of International Conference on Parallel Processing, </booktitle> <pages> pages 278-281, </pages> <year> 1987. </year>
Reference: [54] <author> Virendra K. Janakiram, Dharma P. Agrawal, and Ram Mehrotra. </author> <title> A randomized parallel backtracking algorithm. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-37 (12), </volume> <year> 1988. </year>
Reference: [55] <author> C. Kaklamanis and G. Persiano. </author> <title> Branch-and-bound and backtrack search on mesh-connected arrays of processors. </title> <booktitle> In Proceedings of Fourth Annual Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 118-126, </pages> <year> 1992. </year>
Reference-contexts: DTS has been shown to be quite effective in the context of parallel ff fi search on a 32 processor hypercube [30]. A number of techniques using randomized allocation have been presented in the context of parallel depth-first search <ref> [125, 139, 137, 55] </ref>. In depth-first search of trees, the expansion of a node corresponds to performing a certain amount of useful computation and generation of successor nodes, which can be treated as subtasks.
Reference: [56] <author> L. V. Kale. </author> <title> Comparing the performance of two dynamic load distribution methods. </title> <booktitle> In Proceedings of 1988 International Conference on Parallel Processing, </booktitle> <pages> pages 8-12, </pages> <year> 1988. </year>
Reference-contexts: The performance of many of these formulations has been theoretically shown to be within a small factor off from the optimal. Continuing work in this area has focused on determining tighter bounds for various formulations while making fewer assumptions [60, 59]. There are a number of load balancing techniques <ref> [43, 56, 65, 137, 138, 155] </ref> that are applicable only if an estimate of the amount of work is available. If we could devise some technique to estimate the amount of unfinished work in a (partially searched) state space tree, then all these parallel formulations could be applied to DFS.
Reference: [57] <author> L. V. Kale and V. Saletore. </author> <title> Efficient parallel execution of IDA* on shared and distributed-memory multiprocessors. </title> <booktitle> In The Sixth Distributed Memory Computing Conference Proceedings, </booktitle> <year> 1991. </year>
Reference-contexts: On message passing computers (e.g., the Intel Hypercube, nCUBE), algorithms such as Dijkstra's token termination detection algorithm [26] can be used. This approach has been used by a number of researchers and tested in the context of different problems and architectures <ref> [129, 80, 57, 118, 95] </ref>.
Reference: [58] <editor> L. N. Kanal and Vipin Kumar. </editor> <booktitle> Search in Artificial Intelligence. </booktitle> <publisher> Springer-Verlag, </publisher> <address> New York, NY, </address> <year> 1988. </year>
Reference-contexts: 1 Sequential Algorithms for Solving Discrete Optimization Prob lems Here we provide a brief overview of sequential search algorithms. For detailed descriptions, see <ref> [110, 115, 58] </ref>. 1.1 Depth-First Search 2 1. program depth first search 2. select initial node and place on stack 3. repeat 4. begin 5. select node from the top of the stack 6. if (selected node is not the solution) 7. begin 8. generate successors (if any) of selected node;
Reference: [59] <author> R. Karp and Y. Zhang. </author> <title> A randomized parallel branch-and-bound procedure. </title> <booktitle> In Proceedings of 20th Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 290-300, </pages> <year> 1988. </year>
Reference-contexts: comparable size, 10 splitting. 11 Subtask generation scheme! Sender Initiated Receiver Initiated Work transfer strategy! Sender Initiated Receiver Initiated Receiver Initiated Splitting strategy# Node Splitting Ranade [125] Furuichi et al. [35] Ferguson and Korf [30] Shu and Kale [139] Monien et al. [105] Finkel and Manber [33] Karp and Zhang <ref> [59, 60] </ref> Stack Splitting Kumar et al. [81, 128, 75] Finkel and Manber [33] Table 1: Taxonomy of parallel formulations of DFS. as it gives out nodes at various levels of the stack. <p> In contrast, node splitting can yield subtasks which are of widely differing sizes since subtrees rooted at different nodes in a tree can be of vastly different sizes. Typically, load balancing schemes utilizing node splitting <ref> [35, 125, 30, 119, 60, 59] </ref> require more work transfers compared to those using stack splitting. Subtask Distribution : Issues relating to when work available at a processor is split and how it is distributed are critical parameters of a parallel formulation. <p> The performance of many of these formulations has been theoretically shown to be within a small factor off from the optimal. Continuing work in this area has focused on determining tighter bounds for various formulations while making fewer assumptions <ref> [60, 59] </ref>. There are a number of load balancing techniques [43, 56, 65, 137, 138, 155] that are applicable only if an estimate of the amount of work is available.
Reference: [60] <author> R. Karp and Y. Zhang. </author> <title> Randomized parallel algorithms for backtrack search and branch-and-bound computation. </title> <journal> Journal of ACM, </journal> <volume> 40 </volume> <pages> 765-789, </pages> <year> 1993. </year>
Reference-contexts: comparable size, 10 splitting. 11 Subtask generation scheme! Sender Initiated Receiver Initiated Work transfer strategy! Sender Initiated Receiver Initiated Receiver Initiated Splitting strategy# Node Splitting Ranade [125] Furuichi et al. [35] Ferguson and Korf [30] Shu and Kale [139] Monien et al. [105] Finkel and Manber [33] Karp and Zhang <ref> [59, 60] </ref> Stack Splitting Kumar et al. [81, 128, 75] Finkel and Manber [33] Table 1: Taxonomy of parallel formulations of DFS. as it gives out nodes at various levels of the stack. <p> In contrast, node splitting can yield subtasks which are of widely differing sizes since subtrees rooted at different nodes in a tree can be of vastly different sizes. Typically, load balancing schemes utilizing node splitting <ref> [35, 125, 30, 119, 60, 59] </ref> require more work transfers compared to those using stack splitting. Subtask Distribution : Issues relating to when work available at a processor is split and how it is distributed are critical parameters of a parallel formulation. <p> The performance of many of these formulations has been theoretically shown to be within a small factor off from the optimal. Continuing work in this area has focused on determining tighter bounds for various formulations while making fewer assumptions <ref> [60, 59] </ref>. There are a number of load balancing techniques [43, 56, 65, 137, 138, 155] that are applicable only if an estimate of the amount of work is available.
Reference: [61] <author> R. M. Karp and M. H. </author> <title> Held. Finite state processes and dynamic programming. </title> <journal> SIAM Journal of Applied Math, </journal> <volume> 15 </volume> <pages> 693-718, </pages> <year> 1967. </year>
Reference-contexts: Based on these two classification criteria, it is possible to classify most DP formulations as serial-monadic, serial-polyadic, nonserial-monadic, and nonserial-polyadic. This classification, first proposed by Li and Wah [91] is important because it helps in designing parallel formulations for these algorithms. Different formulations of DP have been presented <ref> [77, 61, 91, 37, 4, 156, 28] </ref>. 2 General Algorithmic Issues in Parallel Formulations This section discusses some of the general aspects related to parallel formulations of an algorithm. Various terms used in subsequent sections are also defined here.
Reference: [62] <author> Richard M. Karp and Yanjun Zhang. </author> <title> A randomized parallel branch-and-bound procedure. </title> <booktitle> In Proceedings of the ACM Annual Symposium on Theory of Computing, </booktitle> <pages> pages 290-300, </pages> <year> 1988. </year> <month> 35 </month>
Reference-contexts: Roucairol [135] presents parallel best-first branch and bound formulations for shared address space computers and uses these to solve the Multiknapsack and Quadratic assignment problems. Some parallel best-first search algorithms have been analytically studied. Karp and Zhang <ref> [62] </ref> analyze the search overhead of parallel best-first branch-and-bound (i:e:, A*) using random distribution of nodes for a specific model of search trees. Renolet et al. [133] use Monte Carlo simulations to model performance of parallel best-first search.
Reference: [63] <author> George Karypis and Vipin Kumar. </author> <title> Efficient Parallel Mappings of a Dynamic Programming Algorithm. </title> <type> Technical Report TR 92-59, </type> <institution> Computer Science Department, University of Minnesota, Minneapolis, MN, </institution> <year> 1992. </year>
Reference-contexts: Huang et al. [45] present a similar algorithm for CREW-PRAM models which run in O ( p n log n) time on O (n 3:5 log n) processors. Karypis and Kumar <ref> [63] </ref> analyze three different mappings of the systolic algorithm presented by Guibas et al. [42] and experimentally evaluate them in the context of the matrix multiplication parenthesization problem on an nCUBE2.
Reference: [64] <author> George Karypis and Vipin Kumar. </author> <title> Unstructured Tree Search on SIMD Parallel Computers. </title> <type> Technical Report 92-21, </type> <institution> Computer Science Department, University of Minnesota, </institution> <year> 1992. </year> <note> A short version appears in Supercomputing '92 Proceedings, pages 453-462, </note> <year> 1992. </year>
Reference-contexts: Powley et al.[118] and Mahanti et al.[95] present parallel IDA* for solving the 15 puzzle problem on CM2 T M . Powley's and Mahanti's formulations use different triggering and redistribution mechanisms. Both schemes however report similar results for the 15 puzzle. Karypis and Kumar <ref> [64] </ref> present a new load balancing technique which is shown to be highly scalable on SIMD architectures.
Reference: [65] <author> R. Keller and F. Lin. </author> <title> Simulated performance of a reduction based multiprocessor. </title> <booktitle> IEEE Computer, </booktitle> <month> July </month> <year> 1984. </year>
Reference-contexts: The performance of many of these formulations has been theoretically shown to be within a small factor off from the optimal. Continuing work in this area has focused on determining tighter bounds for various formulations while making fewer assumptions [60, 59]. There are a number of load balancing techniques <ref> [43, 56, 65, 137, 138, 155] </ref> that are applicable only if an estimate of the amount of work is available. If we could devise some technique to estimate the amount of unfinished work in a (partially searched) state space tree, then all these parallel formulations could be applied to DFS.
Reference: [66] <author> Kouichi Kimura and Ichiyoshi Nobuyuki. </author> <title> Probabilistic analysis of the efficiency of the dynamic load distribution. </title> <booktitle> In The Sixth Distributed Memory Computing Conference Proceedings, </booktitle> <year> 1991. </year>
Reference-contexts: A leaf processor is allocated to another subtask generator when its designated subtask generator runs out of work. For l = 1, the multi and single level schemes are identical. Kimura et al. <ref> [66] </ref> present detailed scalability analysis of these schemes. Ferguson and Korf [30, 119] present a work distribution scheme, called Distributed Tree Search (DTS), in which processors are allocated to different parts of the search tree dynamically. Initially all the processors are assigned to the root.
Reference: [67] <author> T. C. Koopmans and M. J. Beckmann. </author> <title> Assignment problems and the location of economic activities. </title> <journal> Econo-metrica, </journal> <volume> 25 </volume> <pages> 53-76, </pages> <year> 1957. </year>
Reference: [68] <author> R. E. Korf. </author> <title> Depth-first iterative-deepening: An optimal admissible tree search. </title> <journal> Artificial Intelligence, </journal> <volume> 27 </volume> <pages> 97-109, </pages> <year> 1985. </year>
Reference-contexts: It might appear that IDA* performs a lot of redundant work in successive iterations. But for many interesting problems, the redundant work performed is minimal and the algorithm finds an optimal solution <ref> [68] </ref>. IDA* search procedure can be derived from the iterative deepening depth-first search procedure by replacing the depth bound by the cost bound. 1.2 Best-First Search Best-first search techniques use heuristics to direct search to spaces which are more likely to yield solutions.
Reference: [69] <author> Richard Korf. </author> <title> Optimal path finding algorithms. </title> <editor> In L. N. Kanal and Vipin Kumar, editors, </editor> <booktitle> Search in Artificial Intelligence. </booktitle> <publisher> Springer-Verlag, </publisher> <address> New York, NY, </address> <year> 1988. </year>
Reference-contexts: But for some other problems (e:g:, finding the shortest path in a reasonably well connected graph), unfolded graphs can be exponentially bigger than the original graphs <ref> [69] </ref>. We will discuss communication strategies for tree and graph search separately. 4.1 Communication Strategies for Parallel Tree Search Formulations Parallel formulations of best-first search must address two issues: * Quantitative load balancing: This ensures that all processors expand approximately equal number of nodes in the tree.
Reference: [70] <author> W. Kornfeld. </author> <title> The use of parallelism to implement a heuristic search. </title> <booktitle> In Proceedings of International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 575-580, </pages> <year> 1981. </year>
Reference-contexts: A number of researchers have observed and analyzed the existence of speedup anomalies. Using P processing elements, an acceleration anomaly manifests itself in the form of a speedup greater than P <ref> [51, 82, 70, 92, 108, 129] </ref>. An instance of speedup anomaly is shown in Figure 11 (a). A speedup of less than P attributed to excess work done by the parallel formulation compared to the sequential formulation is called termed as a deceleration anomaly [51, 82, 104, 50, 148].
Reference: [71] <author> V. Kumar, P. S. Gopalkrishnan, and L. N. Kanal. </author> <title> Parallel Algorithms for Machine Intelligence and Vision. </title> <publisher> Springer-Verlag, </publisher> <address> New York, NY, </address> <year> 1990. </year>
Reference: [72] <author> V. Kumar and L. N. Kanal. </author> <title> A general branch-and-bound formulations for understanding and synthesizing and/or tree search procedures. </title> <journal> Artificial Intelligence, </journal> <volume> 21 </volume> <pages> 179-198, </pages> <year> 1983. </year>
Reference-contexts: The classical ff fi game tree search algorithm can also be viewed as a depth-first branch-and-bound algorithm <ref> [72, 78] </ref>. Unfortunately, the information about the current best solution (which in this case is the current best winning strategy) cannot be captured in a single number. Hence the simple solution discussed above cannot be used to develop an effective parallel formulation of ff fi.
Reference: [73] <author> V. Kumar and L. N. Kanal. </author> <title> Parallel branch-and-bound formulations for and/or tree search. </title> <journal> IEEE Transactions Pattern Analysis and Machine Intelligence, </journal> <volume> PAMI-6:768-778, </volume> <year> 1984. </year>
Reference-contexts: The exact nature of this tradeoff is not clearly understood and is a subject of continuing research. 3.3 Parallel Formulations of IDA* There are two approaches to parallelizing IDA*. In one approach, different processors work on different iterations of IDA* independently <ref> [73] </ref>. This approach is not very suitable for finding optimal solutions. A solution found by a processor is provably optimal only if all the other processors have also exhausted search space until that iteration and no better solution has been found.
Reference: [74] <author> Vipin Kumar, Ananth Grama, Anshul Gupta, and George Karypis. </author> <title> Introduction to Parallel Computing: Algorithm Design and Analysis. </title> <address> Benjamin/Cummings, Redwod City, </address> <year> 1994. </year>
Reference-contexts: Architecture Related Issues : Suitability of a parallel search formulation depends strongly on the features of the underlying architecture. Parallel computers can be thought of as belonging to one of two classes: SIMD (Single Instruction, Multiple Data streams), or MIMD (Multiple Instruction, Multiple Data streams) machines <ref> [74] </ref>. In SIMD machines, all the processors execute the same instructions at any given point of time. In MIMD machines, each processor executes a possibly different program asynchronously. <p> Hence, the load balancing schemes developed for MIMD architectures may not perform well on SIMD architectures. Another important architectural feature is whether the parallel computer is a message passing computer or a shared address space computer <ref> [74] </ref>. Shared address space parallel computers have global memory that can be directly addressed by all processors. In message passing computers, each processor has its own local memory, and processors can communicate only by exchanging messages over the communication network. A number of search techniques use global data structures. <p> We call such algorithms scalable parallel algorithms. The rate at which the problem size must grow with respect to the number of processors to keep the efficiency fixed determines the degree of scalability of a parallel algorithm <ref> [39, 76, 81, 74] </ref> and is called the isoefficiency function. <p> We had earlier classified DP algorithms into four classes, namely, serial-monadic, serial-polyadic, nonserial-monadic, and nonserial-polyadic. Parallel formulations of the problems in each of the four DP categories have certain similarities. Each of these are investigated separately in <ref> [74] </ref>. In this section we, describe problems in two classes, serial-monadic and nonserial-polyadic. The graph corresponding to a serial-monadic DP formulation is a multistage (or levelized graph). <p> Since each processor has complete information about subproblem costs at preceding stages, no communication is needed other than the all-to-all broadcast and the next iteration can begin. Faster parallel formulations for hypercubes can be derived using various parallel matrix-vector product algorithms <ref> [74, 8, 16] </ref>. Li and Wah [91] show that solving monadic serial DP formulations is equivalent to multiplying a string of matrices. Note that the problem of multiplying two matrices has much more concurrency than the problem of matrix-vector multiplication. <p> If the knapsack has a capacity c, then there are c subproblems to be solved at each of the n levels (n being the total number of objects). Each subproblem uses solutions from only two subproblems at the previous level. Kumar et al. <ref> [74] </ref> investigate parallel algorithms for this DP formulation. A large class of optimization problems can be formulated as nonserial-polyadic DP formulations. Examples of these problems are: optimal triangularization of polygons, optimal binary search trees [21], the matrix parenthesization problem [21], and the CYK parser [7]. <p> A systolic array algorithm has been proposed by Guibas et al. [42] that uses O (n 2 ) processing cells and solves the problem in O (n) time. These and other parallel formulations are discussed by Kumar et al. in <ref> [74] </ref>. Faster algorithms for solving this problem use a large number of processors to gain small improvements in time. Therefore, the efficiency obtained from these formulations is poor.
Reference: [75] <author> Vipin Kumar, Ananth Grama, and V. Nageshwara Rao. </author> <title> Scalable load balancing techniques for parallel computers. </title> <type> Technical Report 91-55, </type> <institution> Computer Science Department, University of Minnesota, </institution> <year> 1991. </year> <note> To appear in Journal of Distributed and Parallel Computing, </note> <year> 1994. </year>
Reference-contexts: Load balancing can be viewed as a two phase process : task partitioning and subtask distribution. We discuss these two processes in some detail here. Task Partitioning : The two most commonly used techniques for task partitioning are Stack Splitting and Node Splitting. Stack splitting and node splitting <ref> [75, 81] </ref> are illustrated in Figures 5 (b) and (c) respectively. Here, when a work transfer is made, work in the donor's stack is split into two stacks one of which is given to the requester. <p> scheme! Sender Initiated Receiver Initiated Work transfer strategy! Sender Initiated Receiver Initiated Receiver Initiated Splitting strategy# Node Splitting Ranade [125] Furuichi et al. [35] Ferguson and Korf [30] Shu and Kale [139] Monien et al. [105] Finkel and Manber [33] Karp and Zhang [59, 60] Stack Splitting Kumar et al. <ref> [81, 128, 75] </ref> Finkel and Manber [33] Table 1: Taxonomy of parallel formulations of DFS. as it gives out nodes at various levels of the stack. <p> Parallel formulations of DFS in this class are discussed in <ref> [33, 105, 75, 81] </ref>. In this formulation, each processor searches a disjoint part of the tree in a depth-first fashion. When a goal is found, all of them quit. <p> This selection should be made so as to minimize overheads due to load imbalance, communication requests, and contention over any shared data structures. For example, consider two techniques, random polling and global round robin discussed in <ref> [75, 33] </ref>. In random polling, a processor is selected at random and the work request is targeted to this processor. In global round robin, a global pointer is maintained at a designated processor. This pointer determines the target of a 13 work request. <p> In global round robin, a global pointer is maintained at a designated processor. This pointer determines the target of a 13 work request. Every time a work request is made, the pointer is read and incremented (modulo the number of processors). As shown in <ref> [75] </ref>, the global round robin scheme minimizes the total number of work requests for a wide class of search trees. However, contention among processors for the global pointer causes a bottleneck [75]. Consequently, when the number of processors increases, its performance degrades. <p> As shown in <ref> [75] </ref>, the global round robin scheme minimizes the total number of work requests for a wide class of search trees. However, contention among processors for the global pointer causes a bottleneck [75]. Consequently, when the number of processors increases, its performance degrades. In contrast, random polling results in more work requests but does not suffer from contention over shared data structures. <p> This corresponds to an optimal scalability of O (P log P ) for a hypercube using the isoefficiency metric described in <ref> [81, 75] </ref>. This scheme localizes all communication, and thus has less communication overhead compared to Shu's scheme. To maintain the depth-first nature of search, nodes are assigned priorities and are maintained in local heaps at each processor. <p> However these schemes appear to be far less scalable than those that do not require prioritization. A number of parallel formulations (based on receiver and sender initiated generation/transfer schemes) have been experimentally and analytically studied <ref> [35, 30, 119, 139, 125, 137, 5, 114, 11, 41, 75] </ref>. Finkel and Manber [33] present performance results for a number of problems such as the Traveling salesman problem and Knights tour for the Crystal multicomputer developed at the 16 University of Wisconsin. <p> Monien et al. [107] show linear speedups on a network of transputers for a variety of combinatorial problems. Kumar et al. <ref> [75, 10, 11, 12] </ref> show linear speedups for problems such as 15 puzzle, tautology verification, and automatic test pattern generation for various architectures such as a 128 processor BBN Butterfly, 128 processor Intel Hypercube, a 1024 processor nCUBE2, and a 128 processor Symult 2010. <p> Kumar, Ananth and Rao <ref> [41, 75, 81, 128] </ref> have investigated the scalability and performance of many of these schemes for a variety of architectures such as hypercubes, meshes and networks of workstations. 3.2 Parallel Formulations of DFBB Parallel formulations of DFBB are similar to those of DFS.
Reference: [76] <author> Vipin Kumar and Anshul Gupta. </author> <title> Analyzing scalability of parallel algorithms and architectures. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <note> 1994 (to appear). A short version of the paper appears in the Proceedings of the 1991 International Conference on Supercomputing, and as an invited paper in the Proceedings of 29th Annual Allerton Conference on Communication, Control and Computing, </note> <year> 1991. </year>
Reference-contexts: We call such algorithms scalable parallel algorithms. The rate at which the problem size must grow with respect to the number of processors to keep the efficiency fixed determines the degree of scalability of a parallel algorithm <ref> [39, 76, 81, 74] </ref> and is called the isoefficiency function.
Reference: [77] <author> Vipin Kumar and L. N. Kanal. </author> <title> The CDP: A unifying formulation for heuristic search, dynamic programming, and branch-and-bound. </title> <editor> In L. N. Kanal and Vipin Kumar, editors, </editor> <booktitle> Search in Artificial Intelligence, </booktitle> <pages> pages 1-27. </pages> <publisher> Springer-Verlag, </publisher> <address> New York, NY, </address> <year> 1988. </year>
Reference-contexts: property that irrespective of the initial state and decision, the remaining decisions must constitute an optimal decision sequence with respect to the state resulting from the first decision. 6 A general form of DP and a general version of the principle of optimality is given by Kumar and Kanal in <ref> [77] </ref>. It is possible to classify various DP formulations on the basis of the dependencies between subproblems and the composition function. <p> Based on these two classification criteria, it is possible to classify most DP formulations as serial-monadic, serial-polyadic, nonserial-monadic, and nonserial-polyadic. This classification, first proposed by Li and Wah [91] is important because it helps in designing parallel formulations for these algorithms. Different formulations of DP have been presented <ref> [77, 61, 91, 37, 4, 156, 28] </ref>. 2 General Algorithmic Issues in Parallel Formulations This section discusses some of the general aspects related to parallel formulations of an algorithm. Various terms used in subsequent sections are also defined here.
Reference: [78] <author> Vipin Kumar, Dana Nau, and L. N. Kanal. </author> <title> General branch-and-bound formulation for and/or graph and game tree search. </title> <editor> In L. N. Kanal and Vipin Kumar, editors, </editor> <booktitle> Search in Artificial Intelligence. </booktitle> <publisher> Springer-Verlag, </publisher> <address> New York, NY, </address> <year> 1988. </year>
Reference-contexts: The classical ff fi game tree search algorithm can also be viewed as a depth-first branch-and-bound algorithm <ref> [72, 78] </ref>. Unfortunately, the information about the current best solution (which in this case is the current best winning strategy) cannot be captured in a single number. Hence the simple solution discussed above cannot be used to develop an effective parallel formulation of ff fi.
Reference: [79] <author> Vipin Kumar, K. Ramesh, and V. Nageshwara Rao. </author> <title> Parallel best-first search of state-space graphs: A summary of results. </title> <booktitle> In Proceedings of the 1988 National Conference on Artificial Intelligence, </booktitle> <pages> pages 122-126, </pages> <month> August </month> <year> 1988. </year>
Reference-contexts: A number of communication strategies have been proposed by researchers that address these two objectives. 4.1.1 Quantitative Load Balancing Strategies Random Communication Strategy In the random communication strategy, each processor periodically puts some of its best nodes into the OPEN list of a randomly selected processor 21 strategy. <ref> [147, 23, 79] </ref>. This ensures that if some processor has a good part of the search space, then others get a part of it. Although the scheme is designed to explicitly address quantitative load balancing, it also implicitly ensures a measure of qualitative load balance. <p> One such modification is the nearest-neighbor round-robin scheme in which each processor communicates only with its nearest neighbors in a round-robin fashion [27, 96]. A generalization of this scheme defines a neighborhood for each processor within which round-robin communication is performed. 4.1.2 Qualitative Load Balancing Strategies Rao and Kumar <ref> [79] </ref> propose a communication scheme referred to as the blackboard communication strategy. In this strategy, there is a shared BLACKBOARD through which nodes are switched among processors as follows. <p> The performance of the QE strategy is shown to be better than the round-robin and random communication strategies without qualitative load balance [27]. 4.1.3 Experimental and Analytical Results The effectiveness of different parallel formulations is strongly dependent upon the characteristics of the problem being solved. Kumar et al. <ref> [79] </ref> experimentally evaluate the relationship between the characteristics of the search spaces and the suitability of various parallel formulations. They studied the performance of the random, ring, and blackboard communication strategies in the context of the 15 puzzle, the vertex cover and the traveling salesman problem on a BBN butterfly.
Reference: [80] <author> Vipin Kumar and V. N. Rao. </author> <title> Scalable parallel formulations of depth-first search. </title> <editor> In Vipin Kumar, P. S. Gopalakrishnan, and L. N. Kanal, editors, </editor> <booktitle> Parallel Algorithms for Machine Intelligence and Vision. </booktitle> <publisher> Springer-Verlag, </publisher> <address> New York, NY, </address> <year> 1990. </year> <month> 36 </month>
Reference-contexts: This is a consequence of the fact that a processor working with a smaller cost bound may find a solution with a lower cost after another processor working with a higher cost bound finds one. Another more effective approach is to execute each iteration of IDA* via parallel DFS <ref> [80, 81, 128] </ref>. Since all processors work with the same cost bound, each processor stores this value locally and performs DFS on its own part of the tree. <p> On message passing computers (e.g., the Intel Hypercube, nCUBE), algorithms such as Dijkstra's token termination detection algorithm [26] can be used. This approach has been used by a number of researchers and tested in the context of different problems and architectures <ref> [129, 80, 57, 118, 95] </ref>.
Reference: [81] <author> Vipin Kumar and V. Nageshwara Rao. </author> <title> Parallel depth-first search, part II: Analysis. </title> <journal> International Journal of Parallel Programming, </journal> <volume> 16 </volume> (6):501-519, December 1987. 
Reference-contexts: We call such algorithms scalable parallel algorithms. The rate at which the problem size must grow with respect to the number of processors to keep the efficiency fixed determines the degree of scalability of a parallel algorithm <ref> [39, 76, 81, 74] </ref> and is called the isoefficiency function. <p> Load balancing can be viewed as a two phase process : task partitioning and subtask distribution. We discuss these two processes in some detail here. Task Partitioning : The two most commonly used techniques for task partitioning are Stack Splitting and Node Splitting. Stack splitting and node splitting <ref> [75, 81] </ref> are illustrated in Figures 5 (b) and (c) respectively. Here, when a work transfer is made, work in the donor's stack is split into two stacks one of which is given to the requester. <p> scheme! Sender Initiated Receiver Initiated Work transfer strategy! Sender Initiated Receiver Initiated Receiver Initiated Splitting strategy# Node Splitting Ranade [125] Furuichi et al. [35] Ferguson and Korf [30] Shu and Kale [139] Monien et al. [105] Finkel and Manber [33] Karp and Zhang [59, 60] Stack Splitting Kumar et al. <ref> [81, 128, 75] </ref> Finkel and Manber [33] Table 1: Taxonomy of parallel formulations of DFS. as it gives out nodes at various levels of the stack. <p> Parallel formulations of DFS in this class are discussed in <ref> [33, 105, 75, 81] </ref>. In this formulation, each processor searches a disjoint part of the tree in a depth-first fashion. When a goal is found, all of them quit. <p> This corresponds to an optimal scalability of O (P log P ) for a hypercube using the isoefficiency metric described in <ref> [81, 75] </ref>. This scheme localizes all communication, and thus has less communication overhead compared to Shu's scheme. To maintain the depth-first nature of search, nodes are assigned priorities and are maintained in local heaps at each processor. <p> Kumar, Ananth and Rao <ref> [41, 75, 81, 128] </ref> have investigated the scalability and performance of many of these schemes for a variety of architectures such as hypercubes, meshes and networks of workstations. 3.2 Parallel Formulations of DFBB Parallel formulations of DFBB are similar to those of DFS. <p> This is a consequence of the fact that a processor working with a smaller cost bound may find a solution with a lower cost after another processor working with a higher cost bound finds one. Another more effective approach is to execute each iteration of IDA* via parallel DFS <ref> [80, 81, 128] </ref>. Since all processors work with the same cost bound, each processor stores this value locally and performs DFS on its own part of the tree.
Reference: [82] <author> T. H. Lai and Sartaj Sahni. </author> <title> Anomalies in parallel branch and bound algorithms. </title> <journal> Communications of the ACM, </journal> <pages> pages 594-602, </pages> <year> 1984. </year>
Reference-contexts: A number of researchers have observed and analyzed the existence of speedup anomalies. Using P processing elements, an acceleration anomaly manifests itself in the form of a speedup greater than P <ref> [51, 82, 70, 92, 108, 129] </ref>. An instance of speedup anomaly is shown in Figure 11 (a). A speedup of less than P attributed to excess work done by the parallel formulation compared to the sequential formulation is called termed as a deceleration anomaly [51, 82, 104, 50, 148]. <p> An instance of speedup anomaly is shown in Figure 11 (a). A speedup of less than P attributed to excess work done by the parallel formulation compared to the sequential formulation is called termed as a deceleration anomaly <ref> [51, 82, 104, 50, 148] </ref>. An instance of deceleration anomaly is illustrated in Figure 11 (b). The speedup obtained in some 26 cases may actually be less than 1, i.e. the parallel formulation is in fact slower than the sequential formulation. <p> An instance of deceleration anomaly is illustrated in Figure 11 (b). The speedup obtained in some 26 cases may actually be less than 1, i.e. the parallel formulation is in fact slower than the sequential formulation. This is termed as detrimental anomaly <ref> [92, 51, 82, 104] </ref>. Lai and Sahni [82] present early work on quantifying the existence of speedup anomalies in best-first search. They show that given an instance of a problem, there exists a number k such that there is little advantage in expanding more than k nodes in parallel. <p> An instance of deceleration anomaly is illustrated in Figure 11 (b). The speedup obtained in some 26 cases may actually be less than 1, i.e. the parallel formulation is in fact slower than the sequential formulation. This is termed as detrimental anomaly [92, 51, 82, 104]. Lai and Sahni <ref> [82] </ref> present early work on quantifying the existence of speedup anomalies in best-first search. They show that given an instance of a problem, there exists a number k such that there is little advantage in expanding more than k nodes in parallel.
Reference: [83] <author> T. H. Lai and A. Sprague. </author> <title> Performance of parallel branch-and-bound algorithms. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-34(10), </volume> <month> October </month> <year> 1985. </year>
Reference-contexts: They also show that for a one-to-one lower bound function, anomalies occur when 1 &lt; P 1 &lt; P 2 &lt; 2 (P 1 1). Lai and Sprague <ref> [84, 83] </ref> also present an analytical model and derive characteristics of the lower bound function for which anomalies are guaranteed not to occur as the number of processors is increased.
Reference: [84] <author> T. H. Lai and A. Sprague. </author> <title> A note on anomalies in parallel branch-and-bound algorithms with one-to-one bounding functions. </title> <journal> Information Processing Letters, </journal> <volume> 23 </volume> <pages> 119-122, </pages> <month> October </month> <year> 1986. </year>
Reference-contexts: They also show that for a one-to-one lower bound function, anomalies occur when 1 &lt; P 1 &lt; P 2 &lt; 2 (P 1 1). Lai and Sprague <ref> [84, 83] </ref> also present an analytical model and derive characteristics of the lower bound function for which anomalies are guaranteed not to occur as the number of processors is increased.
Reference: [85] <author> E. L. Lawler and D. Woods. </author> <title> Branch-and-bound methods: A survey. </title> <journal> Operations Research, </journal> <volume> 14, </volume> <year> 1966. </year>
Reference: [86] <author> J. Lee, E. Shragowitz, and S. Sahni. </author> <title> A hypercube algorithm for the 0/1 knapsack problem. </title> <booktitle> In Proceedings of International Conference on Parallel Processing, </booktitle> <pages> pages 699-706, </pages> <year> 1987. </year>
Reference-contexts: Applications of this technique are in such varied domains as artificial intelligence, task planning, optimal control etc. <ref> [14, 15, 109, 153, 86, 6] </ref>. DP views a problem as a set of interdependent subproblems. It solves subproblems and uses the results to solve larger subproblems until the entire problem is solved.
Reference: [87] <author> J. Lee, E. Shragowitz, and S. Sahni. </author> <title> A hypercube algorithm for the 0/1 knapsack problem. </title> <journal> Journal of Parallel and Distributed Computing, </journal> (5):438-456, 1988. 
Reference-contexts: When the dependencies become sparse, efficient parallel algorithms have to be specially designed using the structure inherent 30 in the DP formulation. Examples of such problems are DP algorithms for solving the 0/1 Knapsack problem and the single source shortest path problem. Lee et al. <ref> [87] </ref> use a divide-and-conquer strategy for parallelizing the DP algorithm for the 0/1 knapsack problem on a MIMD message passing computer.
Reference: [88] <author> D. B. Leifker and L. N. Kanal. </author> <title> A hybrid sss*/alpha-beta algorithm for parallel search of game trees. </title> <booktitle> In Proceedings of International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 1044-1046, </pages> <year> 1985. </year>
Reference: [89] <author> Guo-Jie Li and B. W. Wah. </author> <title> How good are parallel and ordered depth-first searches. </title> <editor> In K. Hwang, S. M. Jacobs, and E. E. Swartzlander, editors, </editor> <booktitle> Proceedings of the 1986 International Conference on Parallel Processing, </booktitle> <pages> pages 992-999. </pages> <publisher> IEEE Computer Society Press, </publisher> <year> 1986. </year>
Reference-contexts: If the cutoff depth is too deep, then it may not result in larger average grain size and if it is too shallow, subtrees to be searched sequentially may be too large and of widely differing sizes. Saletore and Kale [137] and Li and Wah <ref> [89] </ref> present parallel formulations in which nodes are assigned priorities and are expanded accordingly. By doing this, they are able to ensure that the nodes are expanded in the same order as the corresponding sequential formulation.
Reference: [90] <author> Guo-Jie Li and Benjamin W. Wah. </author> <title> Computational efficiency of parallel approximate branch-and-bound algorithms. </title> <booktitle> In International Conference on Parallel Processing, </booktitle> <pages> pages 473-480, </pages> <year> 1984. </year>
Reference-contexts: Hence, if a parallel algorithm happens to explore the better nodes first, then it can result in acceleration anomalies, and vice versa. Li and Wah <ref> [90, 92] </ref> and Wah et al. [148] investigate dominance relations and heuristic functions and their effect on detrimental and acceleration anomalies. They show that detrimental anomalies in depth-first, breadth-first and specific classes of best-first search can be avoided by augmenting the heuristic values with path numbers.
Reference: [91] <author> Guo-Jie Li and Benjamin W. Wah. </author> <title> Parallel processing of serial dynamic programming problems. </title> <booktitle> In Proceedings of COMPSAC 85, </booktitle> <pages> pages 81-89, </pages> <year> 1985. </year>
Reference-contexts: Based on these two classification criteria, it is possible to classify most DP formulations as serial-monadic, serial-polyadic, nonserial-monadic, and nonserial-polyadic. This classification, first proposed by Li and Wah <ref> [91] </ref> is important because it helps in designing parallel formulations for these algorithms. Different formulations of DP have been presented [77, 61, 91, 37, 4, 156, 28]. 2 General Algorithmic Issues in Parallel Formulations This section discusses some of the general aspects related to parallel formulations of an algorithm. <p> Based on these two classification criteria, it is possible to classify most DP formulations as serial-monadic, serial-polyadic, nonserial-monadic, and nonserial-polyadic. This classification, first proposed by Li and Wah [91] is important because it helps in designing parallel formulations for these algorithms. Different formulations of DP have been presented <ref> [77, 61, 91, 37, 4, 156, 28] </ref>. 2 General Algorithmic Issues in Parallel Formulations This section discusses some of the general aspects related to parallel formulations of an algorithm. Various terms used in subsequent sections are also defined here. <p> It can be shown easily that that the computation of R (S i ) is similar to the product of the arc cost matrix between stages S i and S i+1 and R i+1 provided the addition operation is substituted by `MIN' and multiplication is substituted by addition <ref> [91] </ref>. Further, for the example given in Figure 12, R (S) for the first stage is identical to C (0), as it has only one node in the first stage. <p> Since each processor has complete information about subproblem costs at preceding stages, no communication is needed other than the all-to-all broadcast and the next iteration can begin. Faster parallel formulations for hypercubes can be derived using various parallel matrix-vector product algorithms [74, 8, 16]. Li and Wah <ref> [91] </ref> show that solving monadic serial DP formulations is equivalent to multiplying a string of matrices. Note that the problem of multiplying two matrices has much more concurrency than the problem of matrix-vector multiplication.
Reference: [92] <author> Guo-Jie Li and Benjamin W. Wah. </author> <title> Coping with anomalies in parallel branch-and-bound algorithms. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-35, </volume> <month> June </month> <year> 1986. </year>
Reference-contexts: A number of researchers have observed and analyzed the existence of speedup anomalies. Using P processing elements, an acceleration anomaly manifests itself in the form of a speedup greater than P <ref> [51, 82, 70, 92, 108, 129] </ref>. An instance of speedup anomaly is shown in Figure 11 (a). A speedup of less than P attributed to excess work done by the parallel formulation compared to the sequential formulation is called termed as a deceleration anomaly [51, 82, 104, 50, 148]. <p> An instance of deceleration anomaly is illustrated in Figure 11 (b). The speedup obtained in some 26 cases may actually be less than 1, i.e. the parallel formulation is in fact slower than the sequential formulation. This is termed as detrimental anomaly <ref> [92, 51, 82, 104] </ref>. Lai and Sahni [82] present early work on quantifying the existence of speedup anomalies in best-first search. They show that given an instance of a problem, there exists a number k such that there is little advantage in expanding more than k nodes in parallel. <p> Hence, if a parallel algorithm happens to explore the better nodes first, then it can result in acceleration anomalies, and vice versa. Li and Wah <ref> [90, 92] </ref> and Wah et al. [148] investigate dominance relations and heuristic functions and their effect on detrimental and acceleration anomalies. They show that detrimental anomalies in depth-first, breadth-first and specific classes of best-first search can be avoided by augmenting the heuristic values with path numbers.
Reference: [93] <author> Y. Li and P. M. Pardalos. </author> <title> Parallel algorithms for the quadratic assignment problem. </title> <editor> In P. M. Pardalos, editor, </editor> <booktitle> Advances in Optimization and Parallel Computing, </booktitle> <pages> pages 177-189. </pages> <publisher> North-Holland, </publisher> <address> Amersterdam, The Netherlands, </address> <year> 1992. </year>
Reference: [94] <author> Gary Lindstrom. </author> <title> The key node method: A highly parallel alpha-beta algorithm. </title> <type> Technical Report 83-101, </type> <institution> Computer Science Department, University of Utah, </institution> <address> Salt Lake City, </address> <year> 1983. </year>
Reference-contexts: Hence the simple solution discussed above cannot be used to develop an effective parallel formulation of ff fi. A number of researchers have developed parallel formulations of ff fi <ref> [9, 13, 30, 48, 94, 99, 31, 105, 119, 100] </ref>. In particular, methods developed in [30, 105, 119] have shown reasonable speedups on dozens of processors (e:g:, in Monien [105], a speedup of 12 is reported on 16 processors for chess).
Reference: [95] <author> A. Mahanti and C. Daniels. </author> <title> SIMD parallel heuristic search. </title> <journal> Artificial Intelligence, </journal> <year> 1992. </year>
Reference-contexts: On message passing computers (e.g., the Intel Hypercube, nCUBE), algorithms such as Dijkstra's token termination detection algorithm [26] can be used. This approach has been used by a number of researchers and tested in the context of different problems and architectures <ref> [129, 80, 57, 118, 95] </ref>.
Reference: [96] <author> N. R. Mahapatra and S. Dutt. </author> <title> Scalable duplicate pruning strategies for parallel a* graph search. </title> <booktitle> In Proceedings of the Fifth IEEE Symposium on Parallel and Distributed Processing, </booktitle> <year> 1993. </year>
Reference-contexts: This scheme can be modified for other networks. One such modification is the nearest-neighbor round-robin scheme in which each processor communicates only with its nearest neighbors in a round-robin fashion <ref> [27, 96] </ref>. A generalization of this scheme defines a neighborhood for each processor within which round-robin communication is performed. 4.1.2 Qualitative Load Balancing Strategies Rao and Kumar [79] propose a communication scheme referred to as the blackboard communication strategy. <p> This is done by allowing transfer of nodes only if the heuristic value of the node is better than a certain threshold. This ensures that good nodes in the search tree are uniformly distributed among various processors. In <ref> [27, 96] </ref>, the nearest-neighbor round-robin strategy is combined with a qualitative load balancing scheme. This scheme, referred to as quality equalizing (QE) strategy in [27], is analytically studied and compared with round-robin and random communication strategies.
Reference: [97] <author> B. Mans, T. Mautor, and C. Roucairol. </author> <title> Recent exact and approximate algorithms for the quadratic assignment problem. </title> <booktitle> In Proceedings of APMOD 93, Volume of Extended Abstracts, </booktitle> <address> Budapest, Hungary, </address> <pages> pages 395-402. </pages>
Reference: [98] <author> G. Manzini and M. Somalvico. </author> <title> Probabilistic performance analysis of heuristic search using parallel hash tables. </title> <booktitle> In Proceedings of the International Symposium on Artificial Intelligence and Mathematics, </booktitle> <year> 1990. </year>
Reference-contexts: For a random hash function, the load balancing property of this distribution strategy is similar to the random distribution technique discussed in the previous subsection. Manzini <ref> [98] </ref> shows that this method ensures a good distribution of promising nodes among all processors. Distributing nodes in this fashion will cause performance degradation, as each node generation results in a corresponding communication cycle.
Reference: [99] <author> T. A. Marsland and M. Campbell. </author> <title> Parallel search of strongly ordered game trees. </title> <journal> Computing Surveys, </journal> <volume> 14 </volume> <pages> 533-551, </pages> <year> 1982. </year>
Reference-contexts: Hence the simple solution discussed above cannot be used to develop an effective parallel formulation of ff fi. A number of researchers have developed parallel formulations of ff fi <ref> [9, 13, 30, 48, 94, 99, 31, 105, 119, 100] </ref>. In particular, methods developed in [30, 105, 119] have shown reasonable speedups on dozens of processors (e:g:, in Monien [105], a speedup of 12 is reported on 16 processors for chess).
Reference: [100] <author> T. A. Marsland and F. Popowich. </author> <title> Parallel game tree search. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> PAMI-7(4):442-452, </volume> <month> July </month> <year> 1985. </year> <month> 37 </month>
Reference-contexts: Hence the simple solution discussed above cannot be used to develop an effective parallel formulation of ff fi. A number of researchers have developed parallel formulations of ff fi <ref> [9, 13, 30, 48, 94, 99, 31, 105, 119, 100] </ref>. In particular, methods developed in [30, 105, 119] have shown reasonable speedups on dozens of processors (e:g:, in Monien [105], a speedup of 12 is reported on 16 processors for chess).
Reference: [101] <author> T. Mautor and C. Roucairol. </author> <title> Difficulties of exact methods for solving the quadratic assignment problem. </title> <booktitle> In In DIMACS Series in Discrete Mathematics and Theoretical Computer Science - DIMACS Workshop on Quadratic Assignment Problems, Rutgers, </booktitle> <address> New Jersey. </address>
Reference: [102] <author> G. P. McKeown, V. J. Rayward-Smith, and S. A. </author> <title> Rush. Parallel Branch-and-Bound, </title> <booktitle> chapter 5, </booktitle> <pages> pages 111-150. </pages> <booktitle> Advanced Topics in Computer Science. </booktitle> <publisher> Blackwell Scientific Publications, Oxford, </publisher> <address> UK, </address> <year> 1992. </year>
Reference: [103] <author> Donald Miller. </author> <title> Exact distributed algorithms for travelling salesman problem. </title> <booktitle> In Proceedings of the Workshop On Parallel Computing of Discrete Optimization Problems, </booktitle> <year> 1991. </year>
Reference-contexts: Bixby [17] presents a parallel branch-and-bound algorithm for solving the symmetric traveling salesman problem. He also presents solutions of the LP relaxations of airline crew-scheduling models. Miller et al. <ref> [103] </ref> present parallel formulations of the best-first branch and bound technique for solving the asymmetric traveling salesman problem on heterogeneous network computer architectures. Roucairol [135] presents parallel best-first branch and bound formulations for shared address space computers and uses these to solve the Multiknapsack and Quadratic assignment problems.
Reference: [104] <author> Joseph Mohan. </author> <title> Experience with two parallel programs solving the traveling salesman problem. </title> <booktitle> In Proceedings of International Conference on Parallel Processing, </booktitle> <pages> pages 191-193, </pages> <year> 1983. </year>
Reference-contexts: In most parallel formulations of A*, different processors concurrently expand different frontier nodes. Conceptually, these formulations differ in the data structures used to implement the priority queue of the A* algorithm <ref> [104, 106, 107, 122, 121, 123, 46, 151] </ref>. Given P processors, the simplest parallel strategy is to let each parallel processor work on one of the P current best nodes in the OPEN list. <p> Given P processors, the simplest parallel strategy is to let each parallel processor work on one of the P current best nodes in the OPEN list. This strategy is called the centralized strategy <ref> [104, 123, 46] </ref> because each processor gets work from the global OPEN list. As discussed in [52], this strategy should not result in much redundant search. Figure 8 illustrates this strategy. <p> An instance of speedup anomaly is shown in Figure 11 (a). A speedup of less than P attributed to excess work done by the parallel formulation compared to the sequential formulation is called termed as a deceleration anomaly <ref> [51, 82, 104, 50, 148] </ref>. An instance of deceleration anomaly is illustrated in Figure 11 (b). The speedup obtained in some 26 cases may actually be less than 1, i.e. the parallel formulation is in fact slower than the sequential formulation. <p> An instance of deceleration anomaly is illustrated in Figure 11 (b). The speedup obtained in some 26 cases may actually be less than 1, i.e. the parallel formulation is in fact slower than the sequential formulation. This is termed as detrimental anomaly <ref> [92, 51, 82, 104] </ref>. Lai and Sahni [82] present early work on quantifying the existence of speedup anomalies in best-first search. They show that given an instance of a problem, there exists a number k such that there is little advantage in expanding more than k nodes in parallel.
Reference: [105] <author> B. Monien, R. Feldmann, P. Mysliwietz, and O. Vornberger. </author> <title> Parrallel game tree search by dynamic tree decomposition. </title> <editor> In Vipin Kumar, P. S. Gopalakrishnan, and L. N. Kanal, editors, </editor> <booktitle> Parallel Algorithms for Machine Intelligence and Vision. </booktitle> <publisher> Springer-Verlag, </publisher> <address> New York, NY, </address> <year> 1990. </year>
Reference-contexts: more likely to yield subtasks which are of comparable size, 10 splitting. 11 Subtask generation scheme! Sender Initiated Receiver Initiated Work transfer strategy! Sender Initiated Receiver Initiated Receiver Initiated Splitting strategy# Node Splitting Ranade [125] Furuichi et al. [35] Ferguson and Korf [30] Shu and Kale [139] Monien et al. <ref> [105] </ref> Finkel and Manber [33] Karp and Zhang [59, 60] Stack Splitting Kumar et al. [81, 128, 75] Finkel and Manber [33] Table 1: Taxonomy of parallel formulations of DFS. as it gives out nodes at various levels of the stack. <p> Parallel formulations of DFS in this class are discussed in <ref> [33, 105, 75, 81] </ref>. In this formulation, each processor searches a disjoint part of the tree in a depth-first fashion. When a goal is found, all of them quit. <p> Hence the simple solution discussed above cannot be used to develop an effective parallel formulation of ff fi. A number of researchers have developed parallel formulations of ff fi <ref> [9, 13, 30, 48, 94, 99, 31, 105, 119, 100] </ref>. In particular, methods developed in [30, 105, 119] have shown reasonable speedups on dozens of processors (e:g:, in Monien [105], a speedup of 12 is reported on 16 processors for chess). <p> Hence the simple solution discussed above cannot be used to develop an effective parallel formulation of ff fi. A number of researchers have developed parallel formulations of ff fi [9, 13, 30, 48, 94, 99, 31, 105, 119, 100]. In particular, methods developed in <ref> [30, 105, 119] </ref> have shown reasonable speedups on dozens of processors (e:g:, in Monien [105], a speedup of 12 is reported on 16 processors for chess). The speedups obtained here are much less than those obtained for DFS formulations (e:g:, see [128]). <p> A number of researchers have developed parallel formulations of ff fi [9, 13, 30, 48, 94, 99, 31, 105, 119, 100]. In particular, methods developed in [30, 105, 119] have shown reasonable speedups on dozens of processors (e:g:, in Monien <ref> [105] </ref>, a speedup of 12 is reported on 16 processors for chess). The speedups obtained here are much less than those obtained for DFS formulations (e:g:, see [128]). It is not even clear whether parallel ff fi formulations can make effective use of thousands of processors.
Reference: [106] <author> B. Monien and O. Vornberger. </author> <title> The ring machine. </title> <type> Technical report, </type> <institution> University of Paderborn, </institution> <address> FRG, </address> <year> 1985. </year> <note> Also in Computers and Artificial Intelligence, 3(1987). </note>
Reference-contexts: In most parallel formulations of A*, different processors concurrently expand different frontier nodes. Conceptually, these formulations differ in the data structures used to implement the priority queue of the A* algorithm <ref> [104, 106, 107, 122, 121, 123, 46, 151] </ref>. Given P processors, the simplest parallel strategy is to let each parallel processor work on one of the P current best nodes in the OPEN list.
Reference: [107] <author> B. Monien and O. Vornberger. </author> <title> Parallel processing of combinatorial search trees. </title> <booktitle> In Proceedings of International Workshop on Parallel Algorithms and Architectures, </booktitle> <year> 1987. </year>
Reference-contexts: Finkel and Manber [33] present performance results for a number of problems such as the Traveling salesman problem and Knights tour for the Crystal multicomputer developed at the 16 University of Wisconsin. Monien et al. <ref> [107] </ref> show linear speedups on a network of transputers for a variety of combinatorial problems. <p> In most parallel formulations of A*, different processors concurrently expand different frontier nodes. Conceptually, these formulations differ in the data structures used to implement the priority queue of the A* algorithm <ref> [104, 106, 107, 122, 121, 123, 46, 151] </ref>. Given P processors, the simplest parallel strategy is to let each parallel processor work on one of the P current best nodes in the OPEN list.
Reference: [108] <author> B. Monien, O. Vornberger, and E. Spekenmeyer. </author> <title> Superlinear speedup for parallel backtracking. </title> <type> Technical Report 30, </type> <institution> University of Paderborn, </institution> <address> FRG, </address> <year> 1986. </year>
Reference-contexts: A number of researchers have observed and analyzed the existence of speedup anomalies. Using P processing elements, an acceleration anomaly manifests itself in the form of a speedup greater than P <ref> [51, 82, 70, 92, 108, 129] </ref>. An instance of speedup anomaly is shown in Figure 11 (a). A speedup of less than P attributed to excess work done by the parallel formulation compared to the sequential formulation is called termed as a deceleration anomaly [51, 82, 104, 50, 148].
Reference: [109] <author> H. Ney. </author> <title> Dynamic programming as a technique for pattern recognition. </title> <booktitle> In Proceedings of 6th International Conference on Pattern Recognition, </booktitle> <pages> pages 1119-1125, </pages> <year> 1982. </year>
Reference-contexts: Applications of this technique are in such varied domains as artificial intelligence, task planning, optimal control etc. <ref> [14, 15, 109, 153, 86, 6] </ref>. DP views a problem as a set of interdependent subproblems. It solves subproblems and uses the results to solve larger subproblems until the entire problem is solved.
Reference: [110] <author> Nils J. Nilsson. </author> <booktitle> Principles of Artificial Intelligence. </booktitle> <publisher> Tioga, </publisher> <address> Palo Alto, CA, </address> <year> 1980. </year>
Reference-contexts: 1 Sequential Algorithms for Solving Discrete Optimization Prob lems Here we provide a brief overview of sequential search algorithms. For detailed descriptions, see <ref> [110, 115, 58] </ref>. 1.1 Depth-First Search 2 1. program depth first search 2. select initial node and place on stack 3. repeat 4. begin 5. select node from the top of the stack 6. if (selected node is not the solution) 7. begin 8. generate successors (if any) of selected node;
Reference: [111] <author> P. M. Pardalos and J. Crouse. </author> <title> A parallel algorithm for the quadratic assignment problem. </title> <booktitle> In Supercomputing `89 Proceedings, </booktitle> <pages> pages 351-360. </pages> <publisher> ACM Press, </publisher> <address> New York, NY, </address> <year> 1989. </year>
Reference: [112] <author> P. M. Pardalos and G. P. Rodgers. </author> <title> Parallel branch-and-bound algorithms for unconstrainted quadratic zero-one programming. </title> <editor> In R. Sharda et al., editors, </editor> <booktitle> Impacts of Recent Computer Advances on Operations Research, </booktitle> <pages> pages 131-143. </pages> <publisher> North-Holland, </publisher> <address> Amersterdam, The Netherlands, </address> <year> 1989. </year>
Reference: [113] <author> P. M. Pardalos and G. P. Rodgers. </author> <title> Parallel branch-and-bound algorithms for quadratic zero-one programming on a hypercube architecture. </title> <journal> Annals of Operations Research, </journal> <volume> 22 </volume> <pages> 271-292, </pages> <year> 1990. </year>
Reference: [114] <author> Srinivas Patil and Prithviraj Banerjee. </author> <title> A parallel branch-and-bound algorithm for test generation. </title> <type> 9(3), </type> <month> March </month> <year> 1990. </year>
Reference-contexts: However these schemes appear to be far less scalable than those that do not require prioritization. A number of parallel formulations (based on receiver and sender initiated generation/transfer schemes) have been experimentally and analytically studied <ref> [35, 30, 119, 139, 125, 137, 5, 114, 11, 41, 75] </ref>. Finkel and Manber [33] present performance results for a number of problems such as the Traveling salesman problem and Knights tour for the Crystal multicomputer developed at the 16 University of Wisconsin.
Reference: [115] <author> Judea Pearl. </author> <title> Heuristics-Intelligent Search Strategies for Computer Problem Solving. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1984. </year>
Reference-contexts: 1 Sequential Algorithms for Solving Discrete Optimization Prob lems Here we provide a brief overview of sequential search algorithms. For detailed descriptions, see <ref> [110, 115, 58] </ref>. 1.1 Depth-First Search 2 1. program depth first search 2. select initial node and place on stack 3. repeat 4. begin 5. select node from the top of the stack 6. if (selected node is not the solution) 7. begin 8. generate successors (if any) of selected node;
Reference: [116] <author> G. Plateau, C. Roucairol, and I. Valabregue. </author> <title> Algorithm PR2 for the parallel size reduction of the 0/1 multik-napsack problem. </title> <institution> In INRIA Rapports de Recherche, </institution> <address> number 811, </address> <year> 1988. </year>
Reference: [117] <author> C. Powley and R. Korf. </author> <title> Single agent parallel window search: A summary of results. </title> <booktitle> In Proceedings of the International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 36-41, </pages> <year> 1989. </year>
Reference: [118] <author> C. Powley, R. Korf, and C. Ferguson. </author> <title> IDA* on the connection machine. </title> <journal> Artificial Intelligence, </journal> <year> 1992. </year>
Reference-contexts: On message passing computers (e.g., the Intel Hypercube, nCUBE), algorithms such as Dijkstra's token termination detection algorithm [26] can be used. This approach has been used by a number of researchers and tested in the context of different problems and architectures <ref> [129, 80, 57, 118, 95] </ref>.
Reference: [119] <author> Curt Powley, Chris Ferguson, and Richard Korf. </author> <title> Parallel heuristic search: Two approaches. </title> <editor> In Vipin Kumar, P. S. Gopalakrishnan, and L. N. Kanal, editors, </editor> <booktitle> Parallel Algorithms for Machine Intelligence and Vision. </booktitle> <publisher> Springer-Verlag, </publisher> <address> New York, NY, </address> <year> 1990. </year>
Reference-contexts: In contrast, node splitting can yield subtasks which are of widely differing sizes since subtrees rooted at different nodes in a tree can be of vastly different sizes. Typically, load balancing schemes utilizing node splitting <ref> [35, 125, 30, 119, 60, 59] </ref> require more work transfers compared to those using stack splitting. Subtask Distribution : Issues relating to when work available at a processor is split and how it is distributed are critical parameters of a parallel formulation. <p> However, on machines that have hardware support for concurrent access to a global pointer (e.g., the hardware fetch and add [38]), the global round robin scheme would perform better than random polling. Parallel DFS using sender initiated subtask distribution has been proposed by a number of researchers <ref> [30, 119, 35, 139, 125] </ref>. These use different techniques for task generation and transfer as shown in Table 1. Ichiyoshi et al. propose the single level and multi level sender based scheme [35]. These schemes are illustrated in Figure 7. <p> A leaf processor is allocated to another subtask generator when its designated subtask generator runs out of work. For l = 1, the multi and single level schemes are identical. Kimura et al. [66] present detailed scalability analysis of these schemes. Ferguson and Korf <ref> [30, 119] </ref> present a work distribution scheme, called Distributed Tree Search (DTS), in which processors are allocated to different parts of the search tree dynamically. Initially all the processors are assigned to the root. <p> However these schemes appear to be far less scalable than those that do not require prioritization. A number of parallel formulations (based on receiver and sender initiated generation/transfer schemes) have been experimentally and analytically studied <ref> [35, 30, 119, 139, 125, 137, 5, 114, 11, 41, 75] </ref>. Finkel and Manber [33] present performance results for a number of problems such as the Traveling salesman problem and Knights tour for the Crystal multicomputer developed at the 16 University of Wisconsin. <p> Hence the simple solution discussed above cannot be used to develop an effective parallel formulation of ff fi. A number of researchers have developed parallel formulations of ff fi <ref> [9, 13, 30, 48, 94, 99, 31, 105, 119, 100] </ref>. In particular, methods developed in [30, 105, 119] have shown reasonable speedups on dozens of processors (e:g:, in Monien [105], a speedup of 12 is reported on 16 processors for chess). <p> Hence the simple solution discussed above cannot be used to develop an effective parallel formulation of ff fi. A number of researchers have developed parallel formulations of ff fi [9, 13, 30, 48, 94, 99, 31, 105, 119, 100]. In particular, methods developed in <ref> [30, 105, 119] </ref> have shown reasonable speedups on dozens of processors (e:g:, in Monien [105], a speedup of 12 is reported on 16 processors for chess). The speedups obtained here are much less than those obtained for DFS formulations (e:g:, see [128]).
Reference: [120] <author> Michael J. Quinn. </author> <title> Designing Efficient Algorithms for Parallel Computers. </title> <publisher> McGraw-Hill, </publisher> <address> New York, NY, </address> <year> 1987. </year> <month> 38 </month>
Reference: [121] <author> Michael J. Quinn. </author> <title> Analysis and implementation of branch-and-bound algorithms on a Hypercube multicom--puter. </title> <journal> IEEE Transactions on Computers, </journal> <year> 1989. </year>
Reference-contexts: In most parallel formulations of A*, different processors concurrently expand different frontier nodes. Conceptually, these formulations differ in the data structures used to implement the priority queue of the A* algorithm <ref> [104, 106, 107, 122, 121, 123, 46, 151] </ref>. Given P processors, the simplest parallel strategy is to let each parallel processor work on one of the P current best nodes in the OPEN list.
Reference: [122] <author> Michael J. Quinn and Narsingh Deo. </author> <title> Parallel graph algorithms. </title> <journal> ACM Computing Surveys, </journal> <volume> 16,No 3 </volume> <pages> 319-348, </pages> <month> September </month> <year> 1984. </year>
Reference-contexts: In most parallel formulations of A*, different processors concurrently expand different frontier nodes. Conceptually, these formulations differ in the data structures used to implement the priority queue of the A* algorithm <ref> [104, 106, 107, 122, 121, 123, 46, 151] </ref>. Given P processors, the simplest parallel strategy is to let each parallel processor work on one of the P current best nodes in the OPEN list.
Reference: [123] <author> Michael J. Quinn and Narsingh Deo. </author> <title> An upper bound for the speedup of parallel branch-and-bound algorithms. </title> <type> Technical report, </type> <institution> Purdue University, </institution> <address> Pullman, Washington, </address> <year> 1984. </year>
Reference-contexts: In most parallel formulations of A*, different processors concurrently expand different frontier nodes. Conceptually, these formulations differ in the data structures used to implement the priority queue of the A* algorithm <ref> [104, 106, 107, 122, 121, 123, 46, 151] </ref>. Given P processors, the simplest parallel strategy is to let each parallel processor work on one of the P current best nodes in the OPEN list. <p> Given P processors, the simplest parallel strategy is to let each parallel processor work on one of the P current best nodes in the OPEN list. This strategy is called the centralized strategy <ref> [104, 123, 46] </ref> because each processor gets work from the global OPEN list. As discussed in [52], this strategy should not result in much redundant search. Figure 8 illustrates this strategy.
Reference: [124] <author> Michael J. Quinn and Narsingh Deo. </author> <title> An upper bound for the speedup of parallel branch-and-bound algorithms. </title> <journal> BIT, </journal> <volume> 26,No 1, </volume> <month> March </month> <year> 1986. </year>
Reference-contexts: Quinn and Deo <ref> [124] </ref> derive an upper bound on the speedup attainable by any parallel formulation of branch and bound algorithm using the best bound search strategy. They show that parallel branch and bound can achieve nearly linear or even superlinear speedups under appropriate conditions.
Reference: [125] <author> A. G. Ranade. </author> <title> Optimal speedup for backtrack search on a butterfly network. </title> <booktitle> In Proceedings of the Third ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <year> 1991. </year>
Reference-contexts: For highly irregular search spaces, stack splitting is more likely to yield subtasks which are of comparable size, 10 splitting. 11 Subtask generation scheme! Sender Initiated Receiver Initiated Work transfer strategy! Sender Initiated Receiver Initiated Receiver Initiated Splitting strategy# Node Splitting Ranade <ref> [125] </ref> Furuichi et al. [35] Ferguson and Korf [30] Shu and Kale [139] Monien et al. [105] Finkel and Manber [33] Karp and Zhang [59, 60] Stack Splitting Kumar et al. [81, 128, 75] Finkel and Manber [33] Table 1: Taxonomy of parallel formulations of DFS. as it gives out nodes <p> In contrast, node splitting can yield subtasks which are of widely differing sizes since subtrees rooted at different nodes in a tree can be of vastly different sizes. Typically, load balancing schemes utilizing node splitting <ref> [35, 125, 30, 119, 60, 59] </ref> require more work transfers compared to those using stack splitting. Subtask Distribution : Issues relating to when work available at a processor is split and how it is distributed are critical parameters of a parallel formulation. <p> Subtasks generated using the selected generation strategy must be distributed among other processors. Subtasks can be delivered to processors needing them, either on demand (i:e:, when they are idle) [35] or without demand <ref> [125, 139, 137] </ref>. The former is called sender initiated work transfer and the latter is called receiver initiated work transfer. Based on the two generation strategies and two transfer strategies, it is possible to visualize four classes of subtask distribution schemes. <p> However, on machines that have hardware support for concurrent access to a global pointer (e.g., the hardware fetch and add [38]), the global round robin scheme would perform better than random polling. Parallel DFS using sender initiated subtask distribution has been proposed by a number of researchers <ref> [30, 119, 35, 139, 125] </ref>. These use different techniques for task generation and transfer as shown in Table 1. Ichiyoshi et al. propose the single level and multi level sender based scheme [35]. These schemes are illustrated in Figure 7. <p> DTS has been shown to be quite effective in the context of parallel ff fi search on a 32 processor hypercube [30]. A number of techniques using randomized allocation have been presented in the context of parallel depth-first search <ref> [125, 139, 137, 55] </ref>. In depth-first search of trees, the expansion of a node corresponds to performing a certain amount of useful computation and generation of successor nodes, which can be treated as subtasks. <p> In contrast, for all other load balancing schemes discussed up to this point, the memory requirement of parallel depth-first search remains similar to that of serial depth-first search. Ranade <ref> [125] </ref> presents a variant of the above scheme for execution on butterfly networks or hypercubes. This scheme uses a dynamic algorithm to embed nodes of a binary search tree into a butterfly network. <p> However these schemes appear to be far less scalable than those that do not require prioritization. A number of parallel formulations (based on receiver and sender initiated generation/transfer schemes) have been experimentally and analytically studied <ref> [35, 30, 119, 139, 125, 137, 5, 114, 11, 41, 75] </ref>. Finkel and Manber [33] present performance results for a number of problems such as the Traveling salesman problem and Knights tour for the Crystal multicomputer developed at the 16 University of Wisconsin.
Reference: [126] <author> S. Ranka and S. Sahni. </author> <title> Hypercube Algorithms for Image Processing and Pattern Recognition. </title> <publisher> Springer-Verlag, </publisher> <address> New York, NY, </address> <year> 1990. </year>
Reference: [127] <author> V. Nageshwara Rao. </author> <title> Parallel Processing of Heuristic Search. </title> <type> PhD thesis, </type> <institution> University of Texas, Austin, TX, </institution> <year> 1990. </year>
Reference: [128] <author> V. Nageshwara Rao and V. Kumar. </author> <title> Parallel depth-first search, part I: Implementation. </title> <journal> International Journal of Parallel Programming, </journal> <volume> 16 </volume> (6):479-499, December 1987. 
Reference-contexts: scheme! Sender Initiated Receiver Initiated Work transfer strategy! Sender Initiated Receiver Initiated Receiver Initiated Splitting strategy# Node Splitting Ranade [125] Furuichi et al. [35] Ferguson and Korf [30] Shu and Kale [139] Monien et al. [105] Finkel and Manber [33] Karp and Zhang [59, 60] Stack Splitting Kumar et al. <ref> [81, 128, 75] </ref> Finkel and Manber [33] Table 1: Taxonomy of parallel formulations of DFS. as it gives out nodes at various levels of the stack. <p> Apart from these, all the other restrictions on applicability of this scheme are the same as those for Shu and Kale's [139] scheme. The problem of performing a communication for each node expansion can be alleviated by enforcing a granularity control over the partitioning and transferring process <ref> [128, 139] </ref>. It is , however, not clear whether mechanisms for effective granularity control can be derived for highly irregular state space trees. One possible method [128] of granularity control works by not giving away nodes below a certain "cutoff " depth. Search below this depth is done sequentially. <p> It is , however, not clear whether mechanisms for effective granularity control can be derived for highly irregular state space trees. One possible method <ref> [128] </ref> of granularity control works by not giving away nodes below a certain "cutoff " depth. Search below this depth is done sequentially. This clearly reduces the number of communications. <p> Kumar, Ananth and Rao <ref> [41, 75, 81, 128] </ref> have investigated the scalability and performance of many of these schemes for a variety of architectures such as hypercubes, meshes and networks of workstations. 3.2 Parallel Formulations of DFBB Parallel formulations of DFBB are similar to those of DFS. <p> In particular, methods developed in [30, 105, 119] have shown reasonable speedups on dozens of processors (e:g:, in Monien [105], a speedup of 12 is reported on 16 processors for chess). The speedups obtained here are much less than those obtained for DFS formulations (e:g:, see <ref> [128] </ref>). It is not even clear whether parallel ff fi formulations can make effective use of thousands of processors. There are a number of conflicting factors impacting the performance of parallel DFS in the case of ff fi. Typical game trees are strongly ordered in nature. <p> This is a consequence of the fact that a processor working with a smaller cost bound may find a solution with a lower cost after another processor working with a higher cost bound finds one. Another more effective approach is to execute each iteration of IDA* via parallel DFS <ref> [80, 81, 128] </ref>. Since all processors work with the same cost bound, each processor stores this value locally and performs DFS on its own part of the tree.
Reference: [129] <author> V. Nageshwara Rao, V. Kumar, and K. Ramesh. </author> <title> A parallel implementation of iterative-deepening-a*. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence (AAAI-87), </booktitle> <pages> pages 878-882, </pages> <year> 1987. </year>
Reference-contexts: On message passing computers (e.g., the Intel Hypercube, nCUBE), algorithms such as Dijkstra's token termination detection algorithm [26] can be used. This approach has been used by a number of researchers and tested in the context of different problems and architectures <ref> [129, 80, 57, 118, 95] </ref>. <p> A number of researchers have observed and analyzed the existence of speedup anomalies. Using P processing elements, an acceleration anomaly manifests itself in the form of a speedup greater than P <ref> [51, 82, 70, 92, 108, 129] </ref>. An instance of speedup anomaly is shown in Figure 11 (a). A speedup of less than P attributed to excess work done by the parallel formulation compared to the sequential formulation is called termed as a deceleration anomaly [51, 82, 104, 50, 148].
Reference: [130] <author> V. Nageshwara Rao and Vipin Kumar. </author> <title> Superlinear speedup in state-space search. </title> <booktitle> In Proceedings of the 1988 Foundation of Software Technology and Theoretical Computer Science, number 338 in Lecture Notes in Computer Science, </booktitle> <pages> pages 161-174. </pages> <publisher> Springer-Verlag, </publisher> <year> 1988. </year>
Reference-contexts: They show that parallel branch and bound can achieve nearly linear or even superlinear speedups under appropriate conditions. Their analytical model indicates that acceleration anomalies are unlikely unless there are a large number of subproblems with the same lower bound as the solution cost. Kumar and Rao <ref> [130, 131] </ref> analyze the average speedup in parallel DFS for two different types of models. In the first model, no heuristic information is available to order the successors of a node.
Reference: [131] <author> V. Nageshwara Rao and Vipin Kumar. </author> <title> On the efficicency of parallel backtracking. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 4(4) </volume> <pages> 427-437, </pages> <month> April </month> <year> 1993. </year> <note> Also available as Technical Report TR 90-55, </note> <institution> Department of Computer Science, University of Minnesota, Minneapolis, MN. </institution>
Reference-contexts: They show that parallel branch and bound can achieve nearly linear or even superlinear speedups under appropriate conditions. Their analytical model indicates that acceleration anomalies are unlikely unless there are a large number of subproblems with the same lower bound as the solution cost. Kumar and Rao <ref> [130, 131] </ref> analyze the average speedup in parallel DFS for two different types of models. In the first model, no heuristic information is available to order the successors of a node.
Reference: [132] <author> V. Nageshwara Rao, Vipin Kumar, and Richard Korf. </author> <title> Depth-first vs best-first search. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligenc e (AAAI-91), </booktitle> <year> 1991. </year>
Reference-contexts: For practical problems, in depth-first search, it is much cheaper to incrementally build the state associated with each node rather than copy and/or create the new node from scratch <ref> [132, 20] </ref>. This also introduces additional inefficiency. Furthermore, the memory requirement at 15 a processor is potentially unbounded, as a processor may be required to store an arbitrarily large number of work pieces during execution.
Reference: [133] <author> C. Renolet, M. Diamond, and J. Kimbel. </author> <title> Analytical and heuristic modeling of distributed algorithms. </title> <type> Technical Report E3646, </type> <institution> FMC Corporation, Advanced Systems Center, Minneapolis, MN, </institution> <year> 1989. </year>
Reference-contexts: Some parallel best-first search algorithms have been analytically studied. Karp and Zhang [62] analyze the search overhead of parallel best-first branch-and-bound (i:e:, A*) using random distribution of nodes for a specific model of search trees. Renolet et al. <ref> [133] </ref> use Monte Carlo simulations to model performance of parallel best-first search. <p> Parallel formulations of many of these need to be investigated. A number of programming environments have been developed for implementing parallel search. These include DIB [33], Chare-Kernel [139], MANIP [151] and PICOS <ref> [133] </ref>. Continued work on these programming environments is of prime importance, as they can potentially simplify the development of production level software for solving optimization problems.
Reference: [134] <author> C. Roucairol. </author> <title> A parallel branch-and-bound algorithm for the quadratic assignment problem. </title> <journal> Discrete Applied Mathematics, </journal> <volume> 18 </volume> <pages> 211-225, </pages> <year> 1987. </year>
Reference: [135] <author> C. Roucairol. </author> <title> Parallel branch-and-bound on shared-memory multiprocessors. </title> <booktitle> In Proceedings of the Workshop On Parallel Computing of Discrete Optimization Problems, </booktitle> <year> 1991. </year>
Reference-contexts: He also presents solutions of the LP relaxations of airline crew-scheduling models. Miller et al. [103] present parallel formulations of the best-first branch and bound technique for solving the asymmetric traveling salesman problem on heterogeneous network computer architectures. Roucairol <ref> [135] </ref> presents parallel best-first branch and bound formulations for shared address space computers and uses these to solve the Multiknapsack and Quadratic assignment problems. Some parallel best-first search algorithms have been analytically studied.
Reference: [136] <author> W. Rytter. </author> <title> Efficient parallel computations for dynamic programming. </title> <journal> Theoretical Computer Science, </journal> <volume> 59 </volume> <pages> 297-307, </pages> <year> 1988. </year>
Reference-contexts: Therefore, the efficiency obtained from these formulations is poor. For example, the generalized method of parallelizing such programs described by Valiant et al. [143] directly leads to formulations which run in O (log 2 n) time on O (n 9 ) processors. Rytter <ref> [136] </ref> uses the parallel pebble game on trees to reduce the number of processors required to O (n 6 = log n) for a CREW-PRAM model and O (n 6 ) for a hypercube while still solving it in O (log 2 n) time.
Reference: [137] <author> Vikram Saletore and L. V. Kale. </author> <title> Consistent linear speedup to a first solution in parallel state-space search. </title> <booktitle> In Proceedings of the 1990 National Conference on Artificial Intelligence, </booktitle> <pages> pages 227-233, </pages> <year> 1990. </year>
Reference-contexts: Subtasks generated using the selected generation strategy must be distributed among other processors. Subtasks can be delivered to processors needing them, either on demand (i:e:, when they are idle) [35] or without demand <ref> [125, 139, 137] </ref>. The former is called sender initiated work transfer and the latter is called receiver initiated work transfer. Based on the two generation strategies and two transfer strategies, it is possible to visualize four classes of subtask distribution schemes. <p> DTS has been shown to be quite effective in the context of parallel ff fi search on a 32 processor hypercube [30]. A number of techniques using randomized allocation have been presented in the context of parallel depth-first search <ref> [125, 139, 137, 55] </ref>. In depth-first search of trees, the expansion of a node corresponds to performing a certain amount of useful computation and generation of successor nodes, which can be treated as subtasks. <p> If the cutoff depth is too deep, then it may not result in larger average grain size and if it is too shallow, subtrees to be searched sequentially may be too large and of widely differing sizes. Saletore and Kale <ref> [137] </ref> and Li and Wah [89] present parallel formulations in which nodes are assigned priorities and are expanded accordingly. By doing this, they are able to ensure that the nodes are expanded in the same order as the corresponding sequential formulation. <p> However these schemes appear to be far less scalable than those that do not require prioritization. A number of parallel formulations (based on receiver and sender initiated generation/transfer schemes) have been experimentally and analytically studied <ref> [35, 30, 119, 139, 125, 137, 5, 114, 11, 41, 75] </ref>. Finkel and Manber [33] present performance results for a number of problems such as the Traveling salesman problem and Knights tour for the Crystal multicomputer developed at the 16 University of Wisconsin. <p> The performance of many of these formulations has been theoretically shown to be within a small factor off from the optimal. Continuing work in this area has focused on determining tighter bounds for various formulations while making fewer assumptions [60, 59]. There are a number of load balancing techniques <ref> [43, 56, 65, 137, 138, 155] </ref> that are applicable only if an estimate of the amount of work is available. If we could devise some technique to estimate the amount of unfinished work in a (partially searched) state space tree, then all these parallel formulations could be applied to DFS.
Reference: [138] <author> Kang Shin and Yi Chieh Chang. </author> <title> Load sharing in hypercube multicomputers for real time applications. </title> <booktitle> In Proceedings of the Fourth Conference on Hypercubes, Concurrent Computers, and Applications, </booktitle> <year> 1989. </year>
Reference-contexts: The performance of many of these formulations has been theoretically shown to be within a small factor off from the optimal. Continuing work in this area has focused on determining tighter bounds for various formulations while making fewer assumptions [60, 59]. There are a number of load balancing techniques <ref> [43, 56, 65, 137, 138, 155] </ref> that are applicable only if an estimate of the amount of work is available. If we could devise some technique to estimate the amount of unfinished work in a (partially searched) state space tree, then all these parallel formulations could be applied to DFS.
Reference: [139] <author> Wei Shu and L. V. Kale. </author> <title> A dynamic scheduling strategy for the chare-kernel system. </title> <booktitle> In Proceedings of Supercomputing Conference, </booktitle> <pages> pages 389-398, </pages> <year> 1989. </year>
Reference-contexts: spaces, stack splitting is more likely to yield subtasks which are of comparable size, 10 splitting. 11 Subtask generation scheme! Sender Initiated Receiver Initiated Work transfer strategy! Sender Initiated Receiver Initiated Receiver Initiated Splitting strategy# Node Splitting Ranade [125] Furuichi et al. [35] Ferguson and Korf [30] Shu and Kale <ref> [139] </ref> Monien et al. [105] Finkel and Manber [33] Karp and Zhang [59, 60] Stack Splitting Kumar et al. [81, 128, 75] Finkel and Manber [33] Table 1: Taxonomy of parallel formulations of DFS. as it gives out nodes at various levels of the stack. <p> Subtasks generated using the selected generation strategy must be distributed among other processors. Subtasks can be delivered to processors needing them, either on demand (i:e:, when they are idle) [35] or without demand <ref> [125, 139, 137] </ref>. The former is called sender initiated work transfer and the latter is called receiver initiated work transfer. Based on the two generation strategies and two transfer strategies, it is possible to visualize four classes of subtask distribution schemes. <p> However, on machines that have hardware support for concurrent access to a global pointer (e.g., the hardware fetch and add [38]), the global round robin scheme would perform better than random polling. Parallel DFS using sender initiated subtask distribution has been proposed by a number of researchers <ref> [30, 119, 35, 139, 125] </ref>. These use different techniques for task generation and transfer as shown in Table 1. Ichiyoshi et al. propose the single level and multi level sender based scheme [35]. These schemes are illustrated in Figure 7. <p> DTS has been shown to be quite effective in the context of parallel ff fi search on a 32 processor hypercube [30]. A number of techniques using randomized allocation have been presented in the context of parallel depth-first search <ref> [125, 139, 137, 55] </ref>. In depth-first search of trees, the expansion of a node corresponds to performing a certain amount of useful computation and generation of successor nodes, which can be treated as subtasks. <p> In depth-first search of trees, the expansion of a node corresponds to performing a certain amount of useful computation and generation of successor nodes, which can be treated as subtasks. In the Randomized Allocation Strategy proposed by Shu and Kale <ref> [139] </ref>, every time a node is expanded, all of the newly generated successor nodes are assigned to randomly chosen processors. The random allocation of subtasks ensures a degree of load balance over the processors. There are however some practical difficulties with the implementation of this scheme. <p> This adds an additional overhead of managing heaps, but may help in reducing the overall memory requirement. Apart from these, all the other restrictions on applicability of this scheme are the same as those for Shu and Kale's <ref> [139] </ref> scheme. The problem of performing a communication for each node expansion can be alleviated by enforcing a granularity control over the partitioning and transferring process [128, 139]. It is , however, not clear whether mechanisms for effective granularity control can be derived for highly irregular state space trees. <p> Apart from these, all the other restrictions on applicability of this scheme are the same as those for Shu and Kale's [139] scheme. The problem of performing a communication for each node expansion can be alleviated by enforcing a granularity control over the partitioning and transferring process <ref> [128, 139] </ref>. It is , however, not clear whether mechanisms for effective granularity control can be derived for highly irregular state space trees. One possible method [128] of granularity control works by not giving away nodes below a certain "cutoff " depth. Search below this depth is done sequentially. <p> However these schemes appear to be far less scalable than those that do not require prioritization. A number of parallel formulations (based on receiver and sender initiated generation/transfer schemes) have been experimentally and analytically studied <ref> [35, 30, 119, 139, 125, 137, 5, 114, 11, 41, 75] </ref>. Finkel and Manber [33] present performance results for a number of problems such as the Traveling salesman problem and Knights tour for the Crystal multicomputer developed at the 16 University of Wisconsin. <p> Parallel formulations of many of these need to be investigated. A number of programming environments have been developed for implementing parallel search. These include DIB [33], Chare-Kernel <ref> [139] </ref>, MANIP [151] and PICOS [133]. Continued work on these programming environments is of prime importance, as they can potentially simplify the development of production level software for solving optimization problems.
Reference: [140] <author> Douglas R. Smith. </author> <title> Random trees and the analysis of branch and bound proceedures. </title> <journal> Journal of the ACM, </journal> <volume> 31 No. 1, </volume> <year> 1984. </year>
Reference: [141] <author> H. S. Stone and P. Sipala. </author> <title> The average complexity of depth-first search with backtracking and cutoff. </title> <journal> IBM Journal of Research and Development, </journal> <month> May </month> <year> 1986. </year>
Reference-contexts: For this model, analysis shows that on the average, the speedup obtained is (i) linear when distribution of solutions is uniform, and (ii) superlinear when distribution of solutions is non-uniform. This model is validated by experiments on synthetic state-space trees modeling the 27 hackers problem <ref> [141] </ref>, the 15-puzzle problem and the n-Queens problem [44]. (In these experiments, serial and parallel DFS do not use any heuristic ordering, and select successors arbitrarily.) The basic reason for this phenomenon is that parallel search can invest resources into multiple regions of the search frontier concurrently.
Reference: [142] <author> S. Teng. </author> <title> Adaptive parallel algorithms for integral knapsack problems. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 8 </volume> <pages> 400-406, </pages> <year> 1990. </year>
Reference: [143] <author> L. G. Valiant, S. Skyum, S. Berkowitz, and C. Rackoff. </author> <title> Fast parallel computation of polynomials using few processors. </title> <journal> SIAM Journal of Computing, </journal> <volume> 12(4) </volume> <pages> 641-644, </pages> <year> 1983. </year>
Reference-contexts: Faster algorithms for solving this problem use a large number of processors to gain small improvements in time. Therefore, the efficiency obtained from these formulations is poor. For example, the generalized method of parallelizing such programs described by Valiant et al. <ref> [143] </ref> directly leads to formulations which run in O (log 2 n) time on O (n 9 ) processors.
Reference: [144] <author> O. Vornberger. </author> <title> Load balancing in a network of transputers. </title> <booktitle> In Proceedings of Second International Workshop on Distributed Algorithms, </booktitle> <year> 1987. </year>
Reference: [145] <author> O. Vornberger. </author> <title> The personal supercomputer: A network of transputers. </title> <booktitle> In Proceedings of the 1987 International Conference on Supercomputing, </booktitle> <year> 1987. </year>
Reference: [146] <author> Olivier Vornberger. </author> <title> Implementing branch-and-bound in a ring of processors. </title> <type> Technical Report 29, </type> <institution> University of Paderborn, </institution> <address> FRG, </address> <year> 1986. </year>
Reference-contexts: If communication cost is low (e.g., on shared address space multiprocessors) then it would be best to perform communication after every node expansion. Ring Communication Strategy In the ring communication strategy, different processors are assumed to be connected in a virtual ring <ref> [146, 151] </ref>. Each processor periodically puts some of its best nodes into the OPEN list of its neighbor in the ring. This allows transfer of good work from one processor to another.
Reference: [147] <author> Olivier Vornberger. </author> <title> Load balancing in a network of transputers. </title> <booktitle> In 2nd International Workshop on Distributed Parallel Algorithms, </booktitle> <year> 1987. </year>
Reference-contexts: A number of communication strategies have been proposed by researchers that address these two objectives. 4.1.1 Quantitative Load Balancing Strategies Random Communication Strategy In the random communication strategy, each processor periodically puts some of its best nodes into the OPEN list of a randomly selected processor 21 strategy. <ref> [147, 23, 79] </ref>. This ensures that if some processor has a good part of the search space, then others get a part of it. Although the scheme is designed to explicitly address quantitative load balancing, it also implicitly ensures a measure of qualitative load balance.
Reference: [148] <author> B. W. Wah, Guo-Jie Li, and C. F. Yu. </author> <title> The status of MANIP|a multicomputer architecture for solving combinatorial extremum-search problems. </title> <booktitle> In Proceedings of 11th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 56-63, </pages> <year> 1984. </year>
Reference-contexts: An instance of speedup anomaly is shown in Figure 11 (a). A speedup of less than P attributed to excess work done by the parallel formulation compared to the sequential formulation is called termed as a deceleration anomaly <ref> [51, 82, 104, 50, 148] </ref>. An instance of deceleration anomaly is illustrated in Figure 11 (b). The speedup obtained in some 26 cases may actually be less than 1, i.e. the parallel formulation is in fact slower than the sequential formulation. <p> Hence, if a parallel algorithm happens to explore the better nodes first, then it can result in acceleration anomalies, and vice versa. Li and Wah [90, 92] and Wah et al. <ref> [148] </ref> investigate dominance relations and heuristic functions and their effect on detrimental and acceleration anomalies. They show that detrimental anomalies in depth-first, breadth-first and specific classes of best-first search can be avoided by augmenting the heuristic values with path numbers.
Reference: [149] <author> Benjamin W. Wah, Guo-Jie Li, and C. F. Yu. </author> <title> Multiprocessing of combinatorial search problems. </title> <editor> In Vipin Kumar, P. S. Gopalakrishnan, and L. N. Kanal, editors, </editor> <booktitle> Parallel Algorithms for Machine Intelligence and Vision. </booktitle> <publisher> Springer-Verlag, </publisher> <address> New York, NY, </address> <year> 1990. </year>
Reference-contexts: Parallel formulations of AND/OR tree search are more complicated than AND tree or OR tree search. AND/OR tree search will be discussed here in the context of dynamic programming problems. A more rigorous discussion of parallel AND/OR tree search can be found in <ref> [149] </ref>. 25 5 Speedup Anomalies in Parallel Formulations of Search Algo rithms In parallel search algorithms, the speedup can differ greatly from one execution to another. This is because the search space examined by different processors can be different for different executions.
Reference: [150] <author> Benjamin W. Wah, Guo-Jie Li, and Chee Fen Yu. </author> <title> Multiprocessing of combinatorial search problems. </title> <booktitle> IEEE Computer, </booktitle> <pages> pages 93-108, </pages> <month> June </month> <year> 1985. </year>
Reference: [151] <author> Benjamin W. Wah and Y. W. Eva Ma. </author> <title> Manip|a multicomputer architecture for solving combinatorial extremum-search problems. </title> <journal> IEEE Transactions on Computers, </journal> <volume> c-33, </volume> <month> May </month> <year> 1984. </year>
Reference-contexts: In most parallel formulations of A*, different processors concurrently expand different frontier nodes. Conceptually, these formulations differ in the data structures used to implement the priority queue of the A* algorithm <ref> [104, 106, 107, 122, 121, 123, 46, 151] </ref>. Given P processors, the simplest parallel strategy is to let each parallel processor work on one of the P current best nodes in the OPEN list. <p> If communication cost is low (e.g., on shared address space multiprocessors) then it would be best to perform communication after every node expansion. Ring Communication Strategy In the ring communication strategy, different processors are assumed to be connected in a virtual ring <ref> [146, 151] </ref>. Each processor periodically puts some of its best nodes into the OPEN list of its neighbor in the ring. This allows transfer of good work from one processor to another. <p> Parallel formulations of many of these need to be investigated. A number of programming environments have been developed for implementing parallel search. These include DIB [33], Chare-Kernel [139], MANIP <ref> [151] </ref> and PICOS [133]. Continued work on these programming environments is of prime importance, as they can potentially simplify the development of production level software for solving optimization problems.
Reference: [152] <author> Benjamin W. Wah and C. F. Yu. </author> <title> Stochastic modelling of branch-and-bound algorithms with best-first search. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-11, </volume> <month> September </month> <year> 1985. </year>
Reference-contexts: Karp and Zhang [62] analyze the search overhead of parallel best-first branch-and-bound (i:e:, A*) using random distribution of nodes for a specific model of search trees. Renolet et al. [133] use Monte Carlo simulations to model performance of parallel best-first search. Wah and Yu <ref> [152] </ref> also present stochastic models to analyze performance of parallel formulations of depth-first branch-and-bound and best-first 24 branch-and-bound search. 4.2 Communication Strategies for Parallel Graph Search A natural way to ensure replication checking in parallel graph search is to implicitly and statically assign each node to a distinct processor.
Reference: [153] <author> D. White. </author> <title> Dynamic Programming. </title> <publisher> Oliver and Boyd, Edinburgh, </publisher> <address> UK, </address> <year> 1969. </year>
Reference-contexts: Applications of this technique are in such varied domains as artificial intelligence, task planning, optimal control etc. <ref> [14, 15, 109, 153, 86, 6] </ref>. DP views a problem as a set of interdependent subproblems. It solves subproblems and uses the results to solve larger subproblems until the entire problem is solved.
Reference: [154] <author> Herbert S. Wilf. </author> <title> Algorithms and Complexity. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1986. </year>
Reference: [155] <author> Marc Willebeek-LeMair and Anthony P Reeves. </author> <title> Distributed dynamic load balancing. </title> <booktitle> In Proceedings of the Fourth Conference on Hypercubes, Concurrent Computers, and Applications, </booktitle> <year> 1989. </year>
Reference-contexts: The performance of many of these formulations has been theoretically shown to be within a small factor off from the optimal. Continuing work in this area has focused on determining tighter bounds for various formulations while making fewer assumptions [60, 59]. There are a number of load balancing techniques <ref> [43, 56, 65, 137, 138, 155] </ref> that are applicable only if an estimate of the amount of work is available. If we could devise some technique to estimate the amount of unfinished work in a (partially searched) state space tree, then all these parallel formulations could be applied to DFS.
Reference: [156] <author> F. F. Yao. </author> <title> Efficient dynamic programming using quadrangle inequalities. </title> <booktitle> In Proceedings of 12th ACM Symposium on Theory of Computing, </booktitle> <pages> pages 429-435, </pages> <year> 1980. </year> <month> 40 </month>
Reference-contexts: Based on these two classification criteria, it is possible to classify most DP formulations as serial-monadic, serial-polyadic, nonserial-monadic, and nonserial-polyadic. This classification, first proposed by Li and Wah [91] is important because it helps in designing parallel formulations for these algorithms. Different formulations of DP have been presented <ref> [77, 61, 91, 37, 4, 156, 28] </ref>. 2 General Algorithmic Issues in Parallel Formulations This section discusses some of the general aspects related to parallel formulations of an algorithm. Various terms used in subsequent sections are also defined here. <p> Furthermore, this categorization is not strong enough to allow development of generic parallel algorithms for each category. A number of new DP algorithms have been proposed which make use of such problem characteristics as sparsity, convexity and concavity <ref> [14, 37, 4, 156, 28] </ref>. Parallel formulations of many of these need to be investigated. A number of programming environments have been developed for implementing parallel search. These include DIB [33], Chare-Kernel [139], MANIP [151] and PICOS [133].
References-found: 156

