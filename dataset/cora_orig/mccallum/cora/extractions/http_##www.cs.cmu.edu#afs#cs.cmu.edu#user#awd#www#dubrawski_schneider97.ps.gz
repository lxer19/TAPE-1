URL: http://www.cs.cmu.edu/afs/cs.cmu.edu/user/awd/www/dubrawski_schneider97.ps.gz
Refering-URL: http://www.cs.cmu.edu/afs/cs/user/awd/www/papers.html
Root-URL: 
Title: Memory Based Stochastic Optimization for Validation and Tuning of Function Approximators  
Author: Artur Dubrawski and Jeff Schneider 
Date: January 4-7, 1997  
Note: 6th International Workshop on  
Address: 5000 Forbes Avenue Pittsburgh, PA 15213  Fort Lauderdale, Florida, USA,  
Affiliation: The Robotics Institute Carnegie Mellon University  Artificial Intelligence and Statistics,  
Abstract: This paper focuses on the optimization of hyper-parameters for function approximators. We describe a kind of racing algorithm for continuous optimization problems that spends less time evaluating poor parameter settings and more time honing its estimates in the most promising regions of the parameter space. The algorithm is able to automatically optimize the parameters of a function approximator with less computation time. We demonstrate the algorithm on the problem of finding good parameters for a memory based learner and show the tradeoffs involved in choosing the right amount of computation to spend on each evaluation.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> C. Atkeson. </author> <title> Using local models to control movement. </title> <booktitle> In Advances in Neural Information Processing Systems, </booktitle> <year> 1989. </year>
Reference-contexts: The new setting is evaluated with a resampling scheme and the process repeats. Each of these parts is described in this section. 2.1 Memory based model of a function approximator's performance We use a form of locally weighted regression (LWR) <ref> [3, 1] </ref> called Bayesian locally weighted regression [11] to build a model from data. Constructing the model consists only of storing all the data points in an efficient structure (see [5] for more information on the techniques used).
Reference: [2] <author> G. Box and N. Draper. </author> <title> Empirical Model Building and Response Surfaces. </title> <publisher> Wiley, </publisher> <year> 1987. </year>
Reference-contexts: The case where the evaluations are perfectly accurate, or deterministic, is well studied and there are many algorithms ranging from well understood gradient-based methods to simulated annealing and poorly understood genetic algorithms. Common approaches to the case where the evaluations are noisy, include genetic algorithms, response surface methods <ref> [2] </ref>, and descendants of the method presented by Robbins and Monro [12][9]. These methods rely on the most recent data obtained to create a local model in the current region of interest.
Reference: [3] <author> W. Cleveland and S. Delvin. </author> <title> Locally weighted regression: An approach to regression analysis by local fitting. </title> <journal> Journal of the American Statistical Association, </journal> <pages> pages 596-610, </pages> <month> September </month> <year> 1988. </year>
Reference-contexts: The new setting is evaluated with a resampling scheme and the process repeats. Each of these parts is described in this section. 2.1 Memory based model of a function approximator's performance We use a form of locally weighted regression (LWR) <ref> [3, 1] </ref> called Bayesian locally weighted regression [11] to build a model from data. Constructing the model consists only of storing all the data points in an efficient structure (see [5] for more information on the techniques used).
Reference: [4] <author> M. </author> <title> DeGroot. Optimal Statistical Decisions. </title> <publisher> McGraw-Hill, </publisher> <year> 1970. </year>
Reference-contexts: The result of a prediction is a t distribution on the output that is well defined and reasonable in the absence of data (see [11] and <ref> [4] </ref> for details). 2.2 The optimization algorithms Each of the optimization algorithms described below makes its decision with information gained by querying a Bayesian LWR model constructed from all past experiments (Fig. 2). * PMAX searches the current nonlinear model for its optimum and suggests it.
Reference: [5] <author> K. Deng and A. Moore. </author> <title> Multiresolution instance-based learning. </title> <booktitle> In International Joint Conference on Artificial Intelligence, </booktitle> <year> 1995. </year>
Reference-contexts: Constructing the model consists only of storing all the data points in an efficient structure (see <ref> [5] </ref> for more information on the techniques used). When a query, x q , is made, each of the stored data points receives a weight w i = exp (kx i x q k 2 =K). K is the kernel width which controls the amount of localness in the regression.
Reference: [6] <author> A. Dubrawski. </author> <title> Memory-based stochastic optimization for automated tuning of neural network's high level parameters. </title> <booktitle> In 4th International Symposium on Intelligent Robotic Systems, </booktitle> <year> 1996. </year>
Reference-contexts: These methods rely on the most recent data obtained to create a local model in the current region of interest. Memory based stochastic optimization [11] improves on this by using all the data to create a global nonlinear model, which is used in the selection of experiments. Dubrawski <ref> [6] </ref> demonstrated its use on the problem of tuning neural network hyper-parameters. We use the term hyper-parameter to refer to high-level settings such as learning rates, network architecture, or smoothing coefficients, as opposed to parameters that are set during training such as specific weights in a neural network.
Reference: [7] <author> L. Kaelbling. </author> <title> Learning in Embedded Systems. </title> <type> PhD thesis, </type> <institution> Stanford University, </institution> <month> June </month> <year> 1990. </year>
Reference-contexts: Its main use is to make a final recommendation after experimentation is complete and we use it to evaluate progress during optimization. * IEMAX applies Kaelbling's Interval Estimation algorithm <ref> [7] </ref> in the continuous case using the Bayesian LWR confidence intervals. It suggests an experiment at the point whose upper confidence interval (95th percentile) is best.
Reference: [8] <author> J. F. Kreider and J. S. Haberl. </author> <title> The great energy predictor shootout, </title> <month> June </month> <year> 1993. </year>
Reference-contexts: Second, the optimization of its own hyper-parameters for the cooling load data is the target of the optimizer in our experiments. The data set is taken from the Building Energy Predictor Shootout <ref> [8] </ref>. It contains four numeric input features which are potential predictors of a single numeric output attribute (the cooling load). The performance of Bayesian LWR depends, given the data, on the particular setting of the algorithm's parameters: the kernel width and the weighted importance of each of the input features.
Reference: [9] <author> H. Kushner and D. Clark. </author> <title> Stochastic Approximation Methods for Constrained and Unconstrained Systems. </title> <publisher> Springer-Verlag, </publisher> <year> 1978. </year>
Reference: [10] <author> O. Maron and A. Moore. </author> <title> Hoeffding races: Accelerating model selection search for classification and function approximation. </title> <booktitle> In Advances in Neural Information Processing Systems (NIPS-6), </booktitle> <year> 1993. </year>
Reference-contexts: We are interested in efficient search algorithms for finding good sets of function approximator hyper-parameters. We focus on the computational issues of finding a single best set of hyper-parameters by means of N-fold cross validation. Maron and Moore <ref> [10] </ref> showed how racing can be used to speed up parameter tuning for function approximators. The problem was to determine the best model from a discrete set of possible models. Racing begins by spending a little computation to get a rough estimate of the value of each model. <p> Therefore, we use that as the final test of the optimizer's performance. The task can be stated as "search the space to find the parameter settings which minimize the l-o-o cross validation error over the entire training set." 3.1 Racing in continuous spaces In <ref> [10] </ref> racing was shown on the problem of selecting the best function approximator from a discrete set of choices that were assumed to be unrelated. Small amounts of computation yielded noisy estimates of the value of each choice, and successively more computation was spent evaluating the most promising ones.
Reference: [11] <author> A. Moore and J. Schneider. </author> <title> Memory based stochastic optimization. </title> <booktitle> In Advances in Neural Information Processing Systems (NIPS-8), </booktitle> <year> 1995. </year>
Reference-contexts: These methods rely on the most recent data obtained to create a local model in the current region of interest. Memory based stochastic optimization <ref> [11] </ref> improves on this by using all the data to create a global nonlinear model, which is used in the selection of experiments. Dubrawski [6] demonstrated its use on the problem of tuning neural network hyper-parameters. <p> The new setting is evaluated with a resampling scheme and the process repeats. Each of these parts is described in this section. 2.1 Memory based model of a function approximator's performance We use a form of locally weighted regression (LWR) [3, 1] called Bayesian locally weighted regression <ref> [11] </ref> to build a model from data. Constructing the model consists only of storing all the data points in an efficient structure (see [5] for more information on the techniques used). <p> The result of a prediction is a t distribution on the output that is well defined and reasonable in the absence of data (see <ref> [11] </ref> and [4] for details). 2.2 The optimization algorithms Each of the optimization algorithms described below makes its decision with information gained by querying a Bayesian LWR model constructed from all past experiments (Fig. 2). * PMAX searches the current nonlinear model for its optimum and suggests it.
Reference: [12] <author> H. Robbins and S. Monro. </author> <title> A stochastic approximation method. </title> <journal> Annals of Mathematical Statistics, </journal> <volume> 22 </volume> <pages> 400-407, </pages> <year> 1951. </year>
References-found: 12

