URL: http://www.cs.unc.edu/Research/aipdesign/europar.ps
Refering-URL: http://www.cs.unc.edu/Research/aipdesign/
Root-URL: http://www.cs.unc.edu
Phone: 2  3  
Title: A Refinement Methodology for Developing Data-Parallel Applications  
Author: Lars Nyland, Jan Prins, Allen Goldberg, Peter Mills, John Reif and Robert Wagner 
Address: Chapel Hill, NC 27599-3175 USA  3260 Hillview Ave., Palo Alto, CA USA  Durham, NC 27708 USA  
Affiliation: 1 Dept. of Computer Science, University of North Carolina  Kestrel Institute,  Dept. of Computer Science, Duke University,  
Abstract: Data-parallelism is a relatively well-understood form of parallel computation, yet developing simple applications can involve substantial efforts to express the problem in low-level data-parallel notations. We describe a process of software development for data-parallel applications starting from high-level specifications, generating repeated refinements of designs to match different architectural models and performance constraints, supporting a development activity with cost-benefit analysis. Primary issues are algorithm choice, correctness and efficiency, followed by data decomposition, load balancing and message-passing coordination. Development of a data-parallel multitarget tracking application is used as a case study, showing the progression from high to low-level refinements. We conclude by describing tool support for the process.
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> B. Alpern, L. Carter, and E. Feig. </author> <title> Uniform memory hierarchies. </title> <booktitle> In Proc. Foundations of Computer Science, </booktitle> <year> 1990. </year>
Reference-contexts: For large problems on fixed size machines, work-efficient algorithms give the best performance. Analysis for parallel architectures. The analysis techniques at this stage are based on medium--level parallel computing cost models such as LogP [6], BSP [12], and HMM <ref> [1] </ref> that can be used to estimate communication and memory performance. The model parameters of the algorithm are obtained analytically (when possible, or by instrumenting a prototype of the algorithm).
Reference: 2. <author> John K. Antonio. </author> <title> Architectural influences on task scheduling: A case study implementation of the jpda algorithm. </title> <type> Technical Report RL-TR-94-200, </type> <institution> Rome Laboratory, </institution> <month> Nov. </month> <year> 1994. </year>
Reference-contexts: The first is the column-recursive joint probability data association (CR-JPDA) algorithm, since it has been the subject of parallel implementation studies <ref> [8, 2] </ref>. Zhou and Bose also present a parallel MTT algorithm, the tree-search joint probability data association filter (ZB-JPDAF) algorithm, that performs much worse than the CR-JPDA in the worst case, but has claims of better performance in average and highly likely cases [14].
Reference: 3. <author> J. Backus. </author> <title> Can programming be liberated from the von neumann style? a functional style and its algebra of programs. </title> <journal> Comm. of the ACM, </journal> <volume> 21(8) </volume> <pages> 613-641, </pages> <year> 1978. </year>
Reference-contexts: Our methodology is based on the spiral model of software development with prototyping, a model favored by the software engineering community. During the risk analysis phase of development, development relies on concise high-level, executable notations for data parallel problems, such as FP, Sisal, Nesl and Proteus <ref> [3, 5, 4, 9] </ref>. The next phase is migration and integration (perhaps automatic) to achieve an efficient application that can be tested and deployed. As new requirements or target architectures are introduced, the development repeats the cycle.
Reference: 4. <author> Guy E. Blelloch. </author> <title> Programming parallel algorithms. </title> <journal> CACM, </journal> <volume> 39(3), </volume> <month> Mar. </month> <year> 1996. </year>
Reference-contexts: Our methodology is based on the spiral model of software development with prototyping, a model favored by the software engineering community. During the risk analysis phase of development, development relies on concise high-level, executable notations for data parallel problems, such as FP, Sisal, Nesl and Proteus <ref> [3, 5, 4, 9] </ref>. The next phase is migration and integration (perhaps automatic) to achieve an efficient application that can be tested and deployed. As new requirements or target architectures are introduced, the development repeats the cycle. <p> Different designs are matched to different languages and different parallel architectures. Translation from the design notation may be manual or automatic; the automatic translation of nested data-parallel programs to vector models is an active area of research <ref> [11, 4] </ref>. 3 Case Studies: Multitarget Tracking In this section, we turn our attention to an example, demonstrating the methodology and the reliance on particular tools used for the process. <p> Performance analysis tools that provide information about highly optimized programs are key to achieving this goal. Portable compilation targets. Architecture-independent compilation targets ensure the porta bility and longevity of parallel applications, as is demonstrated by the Nesl project <ref> [4] </ref>, the Sisal project [5], and the Fortran-M project [7]. 5 Conclusions We have proposed a tree-based refinement strategy for developing data-parallel applications. As development progresses down the tree, algorithms are specialized, perhaps to meet architectural and performance considerations. Branches represent different algorithms or different specializations.
Reference: 5. <author> David C. Cann. </author> <title> SISAL 1.2: A brief introduction and tutorial. </title> <type> Technical report, </type> <institution> Lawrence Livermore National Laboratory, </institution> <year> 1993. </year>
Reference-contexts: Our methodology is based on the spiral model of software development with prototyping, a model favored by the software engineering community. During the risk analysis phase of development, development relies on concise high-level, executable notations for data parallel problems, such as FP, Sisal, Nesl and Proteus <ref> [3, 5, 4, 9] </ref>. The next phase is migration and integration (perhaps automatic) to achieve an efficient application that can be tested and deployed. As new requirements or target architectures are introduced, the development repeats the cycle. <p> Performance analysis tools that provide information about highly optimized programs are key to achieving this goal. Portable compilation targets. Architecture-independent compilation targets ensure the porta bility and longevity of parallel applications, as is demonstrated by the Nesl project [4], the Sisal project <ref> [5] </ref>, and the Fortran-M project [7]. 5 Conclusions We have proposed a tree-based refinement strategy for developing data-parallel applications. As development progresses down the tree, algorithms are specialized, perhaps to meet architectural and performance considerations. Branches represent different algorithms or different specializations.
Reference: 6. <author> D. Culler, R. Karp, D. Patterson, A. Sahay, K. E. Schauser, E. Santos, R. Subramonian, and T. von Eicken. </author> <title> LogP: Towards a realistic model of parallel computation. </title> <booktitle> In Proc. Symposium on Principles and Practice of Parallel Programming, </booktitle> <year> 1993. </year>
Reference-contexts: For large problems on fixed size machines, work-efficient algorithms give the best performance. Analysis for parallel architectures. The analysis techniques at this stage are based on medium--level parallel computing cost models such as LogP <ref> [6] </ref>, BSP [12], and HMM [1] that can be used to estimate communication and memory performance. The model parameters of the algorithm are obtained analytically (when possible, or by instrumenting a prototype of the algorithm).
Reference: 7. <author> Ian Foster. </author> <title> Designing and building parallel programs. </title> <publisher> Addison Wesley, </publisher> <year> 1995. </year>
Reference-contexts: Performance analysis tools that provide information about highly optimized programs are key to achieving this goal. Portable compilation targets. Architecture-independent compilation targets ensure the porta bility and longevity of parallel applications, as is demonstrated by the Nesl project [4], the Sisal project [5], and the Fortran-M project <ref> [7] </ref>. 5 Conclusions We have proposed a tree-based refinement strategy for developing data-parallel applications. As development progresses down the tree, algorithms are specialized, perhaps to meet architectural and performance considerations. Branches represent different algorithms or different specializations.
Reference: 8. <author> Richard A. Games, John D. Ramsdell, and Joseph J. Rushanan. </author> <title> Techniques for real-time parallel processing: Sensor processing case studies. </title> <type> Technical Report MTR 93B0000186, </type> <institution> MITRE, </institution> <month> April </month> <year> 1994. </year>
Reference-contexts: The first is the column-recursive joint probability data association (CR-JPDA) algorithm, since it has been the subject of parallel implementation studies <ref> [8, 2] </ref>. Zhou and Bose also present a parallel MTT algorithm, the tree-search joint probability data association filter (ZB-JPDAF) algorithm, that performs much worse than the CR-JPDA in the worst case, but has claims of better performance in average and highly likely cases [14]. <p> What follows is a suggested set of tools to support the design methodology described here. Parallel programming language for prototyping. The brevity, clarity, and analyzability of our Proteus implementations along with other implementations (Sisal implementation in <ref> [8] </ref>) make a strong argument for using high-level languages for prototyping. High-level programming languages help the developer gain intuition and insight about the inner workings of com plex algorithms prior to exploring optimizations for high-performance. Repository version manager.
Reference: 9. <author> Allen Goldberg, Peter Mills, Lars Nyland, Jan Prins, John Reif, and James Riely. </author> <title> Specification and development of parallel algorithms with the proteus system. </title> <editor> In G. Blelloch, M. Chandy, and S. Jagannathan, editors, </editor> <title> Specification of Parallel Algorithms. </title> <publisher> American Mathematical Society, </publisher> <year> 1994. </year>
Reference-contexts: Our methodology is based on the spiral model of software development with prototyping, a model favored by the software engineering community. During the risk analysis phase of development, development relies on concise high-level, executable notations for data parallel problems, such as FP, Sisal, Nesl and Proteus <ref> [3, 5, 4, 9] </ref>. The next phase is migration and integration (perhaps automatic) to achieve an efficient application that can be tested and deployed. As new requirements or target architectures are introduced, the development repeats the cycle. <p> Refinement and translation steps in the development of data-parallel applications in figure 1 between the dashed lines, occurs in a high-level design notation. We've chosen a data-parallel subset of Proteus <ref> [9] </ref> as our design notation. An initial implementation of specification provides a starting point that provides a foundation for correctness, analysis, information-conveyance and measurement purposes.
Reference: 10. <author> Lars S. Nyland, Jan F. Prins, Allen T. Goldberg, Peter H. Mills, John H. Reif, and Robert A. Wagner. </author> <title> A design methodology for data-parallel applications. </title> <type> Technical report, </type> <institution> Univ. of N. Carolina, </institution> <year> 1995. </year> <note> Available as http://www.cs.unc.edu/Research/aipdesign. </note>
Reference-contexts: These two implementations are written in Proteus, and serve the purpose of achieving a baseline implementation with no initial concern for parallelism. The two implementations are concise, requiring about 40 lines of Proteus each. They were validated against one another prior to further development (details in <ref> [10] </ref>). The first descendent of the CR-JPDA targets parallelism, it is a nested data-parallel implementation in Proteus, which is suitable for automatic translation to C with vector operations. The initial version of the ZB-JPDAF, written in Proteus, is also suitable for translation to C with vector operations. <p> And finally, a paper study was performed to estimate the performance of a variety of message-passing implementations of the CR-JPDA [13]. 3.3 Results of the Implementation Study A brief description of the variants of multitarget tracking programs follows. For a complete description, including code and analysis, see <ref> [10] </ref>. Nested Data-parallel Implementations. Prototyping the CR-JPDA and the ZB-JPDAF with a high-level language yielded quick development and concise descriptions on which further implementations can be based.
Reference: 11. <author> Jan Prins and Daniel Palmer. </author> <title> Transforming high-level data-parallel programs into vector operations. </title> <booktitle> In Proceedings of Principles and Practice of Parallel Programming, </booktitle> <pages> pages 119-128, </pages> <address> San Diego, CA, </address> <year> 1993. </year>
Reference-contexts: Different designs are matched to different languages and different parallel architectures. Translation from the design notation may be manual or automatic; the automatic translation of nested data-parallel programs to vector models is an active area of research <ref> [11, 4] </ref>. 3 Case Studies: Multitarget Tracking In this section, we turn our attention to an example, demonstrating the methodology and the reliance on particular tools used for the process.
Reference: 12. <author> Leslie G Valiant. </author> <title> A bridging model for parallel computation. </title> <journal> CACM, </journal> <volume> 33(8):103, </volume> <month> August </month> <year> 1990. </year>
Reference-contexts: For large problems on fixed size machines, work-efficient algorithms give the best performance. Analysis for parallel architectures. The analysis techniques at this stage are based on medium--level parallel computing cost models such as LogP [6], BSP <ref> [12] </ref>, and HMM [1] that can be used to estimate communication and memory performance. The model parameters of the algorithm are obtained analytically (when possible, or by instrumenting a prototype of the algorithm).
Reference: 13. <author> Robert A. Wagner. </author> <title> Task parallel implementation of the jpda algorithm. </title> <type> Technical report, </type> <institution> Department of Computer Science, Duke University, Durham, </institution> <address> NC 27708-0129, </address> <month> June </month> <year> 1995. </year>
Reference-contexts: An SPMD version of the CR-JPDA was developed, to explore assignment of work to processors, and alternate memory decompositions that improved performance. And finally, a paper study was performed to estimate the performance of a variety of message-passing implementations of the CR-JPDA <ref> [13] </ref>. 3.3 Results of the Implementation Study A brief description of the variants of multitarget tracking programs follows. For a complete description, including code and analysis, see [10]. Nested Data-parallel Implementations. <p> Both of the attempts to improve performance were successful, with good load-balancing leading to good scaling behavior. Message-passing Studies. Our final study looked at the CR-JPDA as it might be implemented on a message-passing architecture (described fully in <ref> [13] </ref>). A simple model was developed to describe the computation and communication costs of different decompositions of the CR-JPDA. The initial implementation was based on the simple observation that M processors could be used to compute results with almost no communication.
Reference: 14. <author> B. Zhou and N. K. Bose. </author> <title> An efficient algorithm for data association in multitarget tracking. </title> <journal> IEEE Trans. on Aerospace and Electronic Systems, </journal> <volume> 31(1) </volume> <pages> 458-468, </pages> <year> 1995. </year> <title> This article was processed using the L A T E X macro package with LLNCS style </title>
Reference-contexts: Zhou and Bose also present a parallel MTT algorithm, the tree-search joint probability data association filter (ZB-JPDAF) algorithm, that performs much worse than the CR-JPDA in the worst case, but has claims of better performance in average and highly likely cases <ref> [14] </ref>. The CR-JPDA is a specific association strategy that uses a weighted average of returns.
References-found: 14

