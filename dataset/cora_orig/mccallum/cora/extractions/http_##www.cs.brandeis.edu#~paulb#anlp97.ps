URL: http://www.cs.brandeis.edu/~paulb/anlp97.ps
Refering-URL: http://www.cs.brandeis.edu/~paulb/pub.html
Root-URL: http://www.cs.brandeis.edu
Email: paulb@cs.brandeis.edu  
Title: A Lexicon for Underspecified Semantic Tagging  
Author: Paul Buitelaar 
Note: ical knowledge for specific domains.  
Address: Waltham, MA 02254-9110, USA  
Affiliation: Dept. of Computer Science Brandeis University  
Abstract:  
Abstract-found: 1
Intro-found: 1
Reference: <author> Brill, Eric. </author> <year> 1992. </year> <title> A simple rule-based part of speech tagger. </title> <booktitle> In Proceedings of the Third Conference on Applied Natural Language Processing. ACL. </booktitle>
Reference-contexts: CoreLex is implemented as a database of associative arrays, which allows a fast lookup of this information in pattern matching. 3.2 Class-Sensitive Pattern Matching The pattern matcher runs over corpora that are: part-of-speech tagged using a widely used tagger <ref> (Brill, 1992) </ref>; stemmed by using an experimental system that extends the Porter stemmer, a stemming algorithm widely used in information retrieval, with the Celex database on English morphology; (partly) semantically tagged using the CoreLex set of un-derspecified semantic tags as discussed in the previous section.
Reference: <author> Buitelaar, Paul. </author> <title> forthcoming. CoreLex: An Adaptable Semantic Lexicon with Systematic Pol-ysemous Classes. </title> <type> Ph.D. thesis, </type> <institution> Brandeis University, Department of Computer Science. </institution>
Reference: <author> Church, K. W. and P. Hanks. </author> <year> 1990. </year> <title> Word association norms, mutual information, and lexicography. </title> <journal> Computational Linguistics, </journal> <volume> 16 </volume> <pages> 22-29. </pages>
Reference-contexts: For this purpose the pattern matcher keeps two separate arrays, one that collects knowledge only on CoreLex nouns and the other collecting knowledge on all nouns. The classifier uses mutual information (MI) scores rather than the raw frequences of the occurring patterns <ref> (Church and Hanks, 1990) </ref>. Computing MI scores is by now a standard procedure for measuring the co-occurrence between objects relative to their overall occurrence.
Reference: <author> Copestake, A. and E. Briscoe. </author> <year> 1992. </year> <title> Lexical operations in a unification-based framework. </title> <editor> In James Pustejovsky and Sabine Bergler, editors, </editor> <title> Lexical Semantics and Knowledge Representation. </title> <booktitle> Lecture Notes in Artificial Intelligence 627, </booktitle> <pages> pages 22-29, </pages> <address> Berlin. </address> <publisher> Springer Verlag. </publisher>
Reference-contexts: In CoreLex homonyms are simply assigned two or more underspecified semantic types, that need to be 1 See the literature on animal grinding, for instance <ref> (Copestake and Briscoe, 1992) </ref> disambiguated in a traditional way.
Reference: <author> Grefenstette, Gregory. </author> <year> 1994. </year> <title> Explorations in Automatic Thesaurus Discovery. </title> <publisher> Kluwer Academic Press, </publisher> <address> Boston. </address>
Reference-contexts: For this we use the Jaccard measure that compares objects relative to the attributes they share <ref> (Grefenstette, 1994) </ref>. In our case the `attributes' are the different linguistic constructions a noun occurs in: headnoun-verb, adjective-headnoun, modifiernoun-headnoun, etc.
Reference: <author> Hindle, Donald. </author> <year> 1990. </year> <title> Noun classification from predicate-argument structures. </title> <booktitle> In Proceedings of the 28th Annual Meeting of the ACL, </booktitle> <pages> pages 268-275. </pages>
Reference-contexts: MI is defined in general as follows: I (x y) = log 2 P (x) P (y) We can use this definition to derive an estimate of the connectedness between words, in terms of collocations (Smadja, 1993), but also in terms of phrases and grammatical relations <ref> (Hindle, 1990) </ref>.
Reference: <author> Hobbs, J., M. Stickel, P. Martin, and D. Edwards. </author> <year> 1993. </year> <title> Interpretation as abduction. </title> <journal> Artificial Intelligence, </journal> <volume> 63. </volume>
Reference-contexts: Relating the data obtained in step 2. to one or more qualia roles Step 1. is trivial, but steps 2. through 4. form a complex process of constructing a corpus specific semantic lexicon that is to be used in additional processing for knowledge intensive reasoning steps (i.e. abduction <ref> (Hobbs et al., 1993) </ref>) that would solve metaphoric, metonymic and other non-literal use of language. 3.1 Assignment of CoreLex Tags The first step in analyzing a new corpus involves tagging each noun that is in CoreLex with an un-derspecified semantic tag.
Reference: <author> Killgariff, Adam. </author> <year> 1992. </year> <title> Polysemy. </title> <type> Ph.D. thesis, </type> <institution> University of Sussex, </institution> <address> Brighton. </address>
Reference-contexts: The example illustrates the fact that disambiguation between related senses is not always possible, which leads to the further question if a discrete distinction between such senses is desirable at all. A number of researchers have answered this question negatively (see eg: (Pustejovsky, 1995) <ref> (Killgariff, 1992) </ref>). <p> These numbers suggest a stronger emphasis in research on systematic polysemy and less on homonyms, an approach that is advocated here (see also <ref> (Killgariff, 1992) </ref>). In CoreLex homonyms are simply assigned two or more underspecified semantic types, that need to be 1 See the literature on animal grinding, for instance (Copestake and Briscoe, 1992) disambiguated in a traditional way.
Reference: <author> Krieger, Hans-Ulrich and Ulrich Schaefer. </author> <year> 1994a. </year> <title> Tdl-a type description language for hpsg. part1: Overview. </title> <type> Technical Report RR-94-37, </type> <institution> DFKI, Saarbruecken, Germany. </institution>
Reference-contexts: Predicate-argument structure finally, is derived from verb-headnoun and headnoun-verb constructions. The semantic lexicon that is generated in such a way comes in two formats: T DL, a Type Description Language based on typed feature-logic <ref> (Krieger and Schaefer, 1994a) </ref> (Krieger and Schae-fer, 1994b) and HTML, the markup language for the World Wide Web. The first provides a constraint-based formalism that allows CoreLex lexicons to be used straightforwardly in constraint-based grammars.
Reference: <author> Krieger, Hans-Ulrich and Ulrich Schaefer. </author> <year> 1994b. </year> <title> Tdl-a type description language for hpsg. part2: Reference manual. </title> <type> Technical Report D-94-14, </type> <institution> DFKI, Saarbruecken, Germany. </institution>
Reference-contexts: Predicate-argument structure finally, is derived from verb-headnoun and headnoun-verb constructions. The semantic lexicon that is generated in such a way comes in two formats: T DL, a Type Description Language based on typed feature-logic (Krieger and Schaefer, 1994a) <ref> (Krieger and Schae-fer, 1994b) </ref> and HTML, the markup language for the World Wide Web. The first provides a constraint-based formalism that allows CoreLex lexicons to be used straightforwardly in constraint-based grammars.
Reference: <author> Pustejovsky, J., B. Boguraev, M. </author> <month> Verhagen, </month> <pages> P.P. </pages>
Reference: <author> Buitelaar, and M. Johnston. </author> <year> 1997. </year> <title> Semantic indexing and typed hyperlinking. </title> <booktitle> In AAAI Spring 1997 Workshop on Natural Language Processing for the World Wibe Web. </booktitle>
Reference: <author> Pustejovsky, James. </author> <year> 1995. </year> <title> The Generative Lexicon. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference-contexts: The example illustrates the fact that disambiguation between related senses is not always possible, which leads to the further question if a discrete distinction between such senses is desirable at all. A number of researchers have answered this question negatively (see eg: <ref> (Pustejovsky, 1995) </ref> (Killgariff, 1992)). <p> More specifically, it is to be `structured in such a way that it reflects the lexical semantics of a language in systematic and predictable ways' <ref> (Pustejovsky, Boguraev, and Johnston, 1995) </ref>. This assumption is fundamentally different from the design philosophies behind existing lexical semantic resources like WordNet that do not account for any regularities between senses. <p> These representations are based on Generative Lexicon theory (GL), using qualia roles and (dotted) types <ref> (Pustejovsky, 1995) </ref>. Qualia roles distinguish different semantic aspects: formal indicates semantic type; constitutive part-whole information; agentive and telic associated events (the first dealing with the origin of the object, the second with its purpose). Each role is typed to a specific class of lexical items.
Reference: <author> Pustejovsky, James, Bran Boguraev, and Michael Johnston. </author> <year> 1995. </year> <title> A core lexical engine: The contextual determination of word sense. </title> <type> Technical report, </type> <institution> Department of Computer Science, Bran-deis University. </institution>
Reference-contexts: The example illustrates the fact that disambiguation between related senses is not always possible, which leads to the further question if a discrete distinction between such senses is desirable at all. A number of researchers have answered this question negatively (see eg: <ref> (Pustejovsky, 1995) </ref> (Killgariff, 1992)). <p> More specifically, it is to be `structured in such a way that it reflects the lexical semantics of a language in systematic and predictable ways' <ref> (Pustejovsky, Boguraev, and Johnston, 1995) </ref>. This assumption is fundamentally different from the design philosophies behind existing lexical semantic resources like WordNet that do not account for any regularities between senses. <p> These representations are based on Generative Lexicon theory (GL), using qualia roles and (dotted) types <ref> (Pustejovsky, 1995) </ref>. Qualia roles distinguish different semantic aspects: formal indicates semantic type; constitutive part-whole information; agentive and telic associated events (the first dealing with the origin of the object, the second with its purpose). Each role is typed to a specific class of lexical items.
Reference: <author> Smadja, Frank. </author> <year> 1993. </year> <title> Retrieving collocations from text: </title> <journal> Xtract. Computational Linguistics, </journal> <volume> 19(1). </volume>
Reference-contexts: MI is defined in general as follows: I (x y) = log 2 P (x) P (y) We can use this definition to derive an estimate of the connectedness between words, in terms of collocations <ref> (Smadja, 1993) </ref>, but also in terms of phrases and grammatical relations (Hindle, 1990).
Reference: <author> Stevenson, Mark and Yorick Wilks. </author> <year> 1997. </year> <title> The grammar of sense: </title> <note> Is word-sense tagging much more than part-of-speech tagging? To appear in a Special Issue of Computational Linguistics on Word sense Disambiguation. </note>
Reference-contexts: tagging Semantic tagging has mostly been considered as nothing more than disambiguation to be performed along the same lines as part-of-speech tagging: given n lexical items each with m senses apply linguistic heuristics and/or statistical measures to pick the most likely sense for each lexical item (see eg: (Yarowsky, 1992) <ref> (Stevenson and Wilks, 1997) </ref>). I do not believe this to be the right approach because it blurs the distinction between `related' (systematic polysemy) and `unrelated' senses (homonymy : bank bank).
Reference: <author> Yarowsky, David. </author> <year> 1992. </year> <title> Word sense disambiguation using statistical models of roget's categories trained on large corpora. </title> <booktitle> In Proceedings of COL-ING92, </booktitle> <pages> pages 454-460. </pages>
Reference-contexts: Underspecified semantic tagging Semantic tagging has mostly been considered as nothing more than disambiguation to be performed along the same lines as part-of-speech tagging: given n lexical items each with m senses apply linguistic heuristics and/or statistical measures to pick the most likely sense for each lexical item (see eg: <ref> (Yarowsky, 1992) </ref> (Stevenson and Wilks, 1997)). I do not believe this to be the right approach because it blurs the distinction between `related' (systematic polysemy) and `unrelated' senses (homonymy : bank bank).
References-found: 17

