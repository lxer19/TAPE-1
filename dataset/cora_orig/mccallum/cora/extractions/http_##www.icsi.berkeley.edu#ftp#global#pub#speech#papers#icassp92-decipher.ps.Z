URL: http://www.icsi.berkeley.edu/ftp/global/pub/speech/papers/icassp92-decipher.ps.Z
Refering-URL: http://www.icsi.berkeley.edu/real/papers.html
Root-URL: http://www.icsi.berkeley.edu
Title: CONNECTIONIST PROBABILITY ESTIMATION IN THE DECIPHER SPEECH RECOGNITION SYSTEM probability estimation can improve performance of
Author: Steve Renals Nelson Morgan Michael Cohen and Horacio Franco 
Note: connectionist  
Address: 1947 Center St., Berkeley CA 94704, USA  Menlo Park CA 94025, USA  
Affiliation: International Computer Science Institute,  SRI International,  
Abstract: Previously, we have demonstrated that feed-forward networks may be used to estimate local output probabilities in hidden Markov model (HMM) speech recognition systems. Here these connectionist techniques are integrated into the DECIPHER system, with experiments being performed using the speaker independent DARPA RM database. Our results indicate that: 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> H. Bourlard and C. J. Wellekens. </author> <title> Links between Markov models and multi-layer perceptrons. </title> <editor> In David S. Touret-zky, editor, </editor> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <volume> volume 2, </volume> <pages> pages 502-510. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo CA, </address> <year> 1989. </year>
Reference-contexts: 1 INTRODUCTION Previous investigations, both theoretical and experimental, have indicated that feed-forward networks (typically, multilayer perceptrons, MLPs) may be used to estimate local HMM output probabilities <ref> [1, 6] </ref>. Our previous published results have generally concentrated on speaker-dependent databases using an unsophisticated recognition system. In this paper, we extend our experiments to the speaker independent DARPA Resource Management (RM) task, incorporating our connectionist methods into SRI's DECIPHER [3], a state of the art continuous speech recognition system. <p> More stringently, it has been proved that networks trained as classifiers (i.e. a `hard' class labelling for each frame) output posterior probability estimates at the minimum of a relative entropy or least squares objective function <ref> [1, 4] </ref>. 1 For convenience, we shall consider `class' and `HMM state' to be synonymous. `Failure is an opportunity to learn.' In 1988 N. Morgan and H. Bourlard [unsurprisingly unpublished] first used these methods in the DECIPHER system.
Reference: [2] <author> M. Cohen. </author> <title> Phonological Structures for Speech Recognition. </title> <type> PhD thesis, </type> <institution> University of California at Berkeley, </institution> <year> 1989. </year>
Reference-contexts: Probabilities of pronunciations are estimated by the forward-backward algorithm, after tying together instances of the same phonological process in different words. Phonological rules can be specified to apply across words, adding initial or final arcs which are constrained to connect only to arcs fulfilling the context of the rule <ref> [2, 3] </ref>. Context dependent phone models include word-specific phone, triphone, generalised triphone, cross-word triphone (constrained to connect to appropriate contexts), and left and right biphone (and generalised biphone). All these models are smoothed together, along with context independent models, using the deleted interpolation algorithm.
Reference: [3] <author> Michael Cohen, Hy Murveit, Jared Bernstein, Patti Price, and Mitch Weintraub. </author> <title> The DECIPHER speech recognition system. </title> <booktitle> In Proceedings IEEE International Conference on Acoustics, Speech and Signal Processing, </booktitle> <pages> pages 77-80, </pages> <address> Albuquerque, </address> <year> 1990. </year>
Reference-contexts: Our previous published results have generally concentrated on speaker-dependent databases using an unsophisticated recognition system. In this paper, we extend our experiments to the speaker independent DARPA Resource Management (RM) task, incorporating our connectionist methods into SRI's DECIPHER <ref> [3] </ref>, a state of the art continuous speech recognition system. There are several reasons why probability estimation using MLPs is an attractive approach: MLPs are well matched to discriminative objective functions. Although an MLP is a parametric model, a large network defines an extremely flexible set of functions. <p> Probabilities of pronunciations are estimated by the forward-backward algorithm, after tying together instances of the same phonological process in different words. Phonological rules can be specified to apply across words, adding initial or final arcs which are constrained to connect only to arcs fulfilling the context of the rule <ref> [2, 3] </ref>. Context dependent phone models include word-specific phone, triphone, generalised triphone, cross-word triphone (constrained to connect to appropriate contexts), and left and right biphone (and generalised biphone). All these models are smoothed together, along with context independent models, using the deleted interpolation algorithm.
Reference: [4] <author> Herbert Gish. </author> <title> A probabilistic approach to the understanding and training of neural network classifiers. </title> <booktitle> In Proceedings IEEE International Conference on Acoustics, Speech and Signal Processing, </booktitle> <pages> pages 1361-1364, </pages> <address> Al-buquerque, </address> <year> 1990. </year>
Reference-contexts: More stringently, it has been proved that networks trained as classifiers (i.e. a `hard' class labelling for each frame) output posterior probability estimates at the minimum of a relative entropy or least squares objective function <ref> [1, 4] </ref>. 1 For convenience, we shall consider `class' and `HMM state' to be synonymous. `Failure is an opportunity to learn.' In 1988 N. Morgan and H. Bourlard [unsurprisingly unpublished] first used these methods in the DECIPHER system.
Reference: [5] <author> N. Morgan, J. Beck, P. Kohn, J. Bilmes, E. Allman, and J. Beer. </author> <title> The ring array processor (rap): A multiprocessing peripheral for connectionist applications. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <note> page In Press, </note> <year> 1992. </year>
Reference-contexts: Stochastic gradient descent training typically required about 10 passes through the training database of 1.3 million frames. This required less than 24 hours compute time, using a 5-board RAP (Ring Array Processor) <ref> [5] </ref>, containing 20 TI TMS320C30 DSPs, each with 256kB of SRAM and 16MB of DRAM. To train an MLP we require a bootstrap model to produce time-aligned phonetic labels.
Reference: [6] <author> N. Morgan, H. Hermansky, H. Bourlard, C. Wooters, and P. Kohn. </author> <title> Continuous speech recognition using PLP analysis with multi-layer perceptrons. </title> <booktitle> In Proceedings IEEE International Conference on Acoustics, Speech and Signal Processing, </booktitle> <pages> pages 49-52, </pages> <address> Toronto, </address> <year> 1991. </year>
Reference-contexts: 1 INTRODUCTION Previous investigations, both theoretical and experimental, have indicated that feed-forward networks (typically, multilayer perceptrons, MLPs) may be used to estimate local HMM output probabilities <ref> [1, 6] </ref>. Our previous published results have generally concentrated on speaker-dependent databases using an unsophisticated recognition system. In this paper, we extend our experiments to the speaker independent DARPA Resource Management (RM) task, incorporating our connectionist methods into SRI's DECIPHER [3], a state of the art continuous speech recognition system. <p> Certainly a 1/2 n gain sequence results in faster training than a 1/n sequence. to static ones, and a multi-frame input (typically we use - 4 frames of context), offers an improvement over single frame input <ref> [6] </ref>. 5. The word transition penalty used in the Viterbi search should be increased in the case of multi-frame input.
Reference: [7] <author> Steve Renals, Nelson Morgan, and Herve Bourlard. </author> <title> Probability estimation by feed-forward networks in continuous speech recognition. </title> <booktitle> In Proceedings IEEE Workshop on Neural Networks for Signal Processing, </booktitle> <pages> pages 309-318, </pages> <address> Princeton NJ, </address> <year> 1991. </year>
Reference-contexts: simple, efficient imple mentation in parallel hardware. 2 TRAINING AND RECOGNITION ISSUES In connectionist training, the posterior probability of an output class (HMM state) 1 given the acoustic data, p (q j |x) is estimated; (scaled) likelihoods, needed for HMM recognition may be obtained from these posteriors via Bayes' rule <ref> [7] </ref>. This is in contrast to the maximum likelihood training usually employed, where the likelihood of the data given the class p (x|q j ) is estimated directly, by fitting parameters to a PDF for each class. <p> Thus we must factor out the data estimates of these priors <ref> [7] </ref>. 2. To train large networks efficiently a stochastic gradient descent procedure should be adopted (i.e. `per pattern' or `online' weight update). This is the case because the training set is large and redundant.
Reference: [8] <author> H. Robbins and S. Munro. </author> <title> A stochastic approximation method. </title> <journal> Annals of Mathematical Statisitics, </journal> <volume> 29 </volume> <pages> 400-407, </pages> <year> 1951. </year>
Reference-contexts: This time-dependent reduction in stochastic gradient descent step-size (gain) may be understood in terms of the constraints on the gain sequence given by stochastic approximation theory <ref> [8] </ref> 2 . After each succeeding epoch the step size is further reduced, until once again there is no improvement on the validation set. Training is then halted. 4. Input representation is important.
References-found: 8

