URL: http://www.cs.dartmouth.edu/~rus/papers/info/podp.ps.Z
Refering-URL: http://www.cs.dartmouth.edu/~rus/papers/info/info.html
Root-URL: http://www.cs.dartmouth.edu
Email: rus@cs.dartmouth.edu  summers@cs.cornell.edu  
Title: Geometric Algorithms and Experiments for Automated Document Structuring  
Author: Daniela Rus Kristen Summers 
Keyword: document analysis, document structure, information capture and access  
Address: Hanover, NH 03755  Ithaca, NY 14853  
Affiliation: Department of Computer Science Dartmouth College  Department of Computer Science Cornell University  
Abstract: We present and analyze algorithms for the automated segmentation and classification of layout structures in electronic documents. The key idea is to use the patterns in the distribution of white space in a document to recognize and interpret its components. The segmentation algorithm divides the document into a hierarchy of logical elements; the classification algorithms classify these divisions as base-text, tables, indented lists, polygonal drawings, and graphs. We present experimental data and discuss an information access application. Our methodology allows the automatic markup of documents (for instance in the sgml format) and the creation of multi-level indices and browsing tools for electronic libraries. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> G. Salton. </author> <title> Automatic Text Processing: The Transformation, Analysis, and Retrieval of Information by Computer. </title> <publisher> Addison-Wesley Publishing Company, </publisher> <address> Reading, </address> <year> 1989. </year>
Reference-contexts: 1 Introduction In today's continuously growing digital information landscape, locating useful information requires flexible browsing and searching capabilities. Existing tools include word-based systems <ref> [1, 2, 3, 4] </ref> that give keyword access to documents. However, these tools give little information about the visual content of documents or about the relative connections between various pieces. <p> Release 03/29/03 Orbiter Deflection Maneuver 04/18/03 Titan Probe Entry 06/30/03 - Iapetus Flyby 05/20/04 - Dione Flyby 09/12/04 - Enceladus Flyby 08/14/05 - Iapetus Flyby 12/31/06 End of Primary Mission Definition 4.1 Vertical structure: The white space density graph of B is the polygonal line wdg : [0; m] ! <ref> [0; 1] </ref> defined by the points wdg (i) = 1 n j=0 w (B i;j ); 8i 2 N " [0; m]. <p> In evaluating the performance and errors, we rely on the ideas of precision and recall from information retrieval. In the realm of IR, these are defined as follows <ref> [1] </ref>: Precision = Relevant retrieved Total retrieved Recall = Relevant retrieved Total relevant We analogize logical groupings to relevant documents and formed groupings to retrieved docu ments. <p> We have implemented this by using our segmentation and classification algorithms on postscript files and by using the mark-up required by the Smart system for information retrieval 21 <ref> [1] </ref>. By restricting ourselves to the postscript files rather than generic, scanned-in images, we are able to label fully the nodes of our tree. That is, we are able to classify nodes as sections, subsections, theorems, proofs, definitions, figures, figure captions, etc. <p> This last would allow users the flexibility to create documents in the format of their choice; these could be automatically integrated with retrieval systems (like the Smart retrieval system <ref> [1] </ref>) that usually rely on mark-up for indexing. Acknowledgments We thank two anonymous reviewers for their careful reading of an earlier draft. Their many insightful suggestions have considerably improved this paper. We are very grateful to John Hopcroft for proposing the problem and for his guidance and support.
Reference: [2] <author> M. A. Hearst. </author> <title> Contextualizing retrieval of full-length documents. </title> <type> Technical Report UCB/CSD-94-789, </type> <institution> University of California, Berkeley, </institution> <year> 1994. </year>
Reference-contexts: 1 Introduction In today's continuously growing digital information landscape, locating useful information requires flexible browsing and searching capabilities. Existing tools include word-based systems <ref> [1, 2, 3, 4] </ref> that give keyword access to documents. However, these tools give little information about the visual content of documents or about the relative connections between various pieces.
Reference: [3] <author> D. Cutting, D. Karger, J. Pedersen, and J. Tukey. Scatter/gather: </author> <title> A cluster-based approach to browsing large document collections. </title> <booktitle> In Proceedings of the Fifteenth Annual International ACM/SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <pages> pages 318-329, </pages> <address> Copenhagen, June 1992. </address> <publisher> ACM Press. </publisher>
Reference-contexts: 1 Introduction In today's continuously growing digital information landscape, locating useful information requires flexible browsing and searching capabilities. Existing tools include word-based systems <ref> [1, 2, 3, 4] </ref> that give keyword access to documents. However, these tools give little information about the visual content of documents or about the relative connections between various pieces.
Reference: [4] <author> B. Kahle. </author> <title> Overview of wide area information servers, 1991. WAIS on-line documentation. </title>
Reference-contexts: 1 Introduction In today's continuously growing digital information landscape, locating useful information requires flexible browsing and searching capabilities. Existing tools include word-based systems <ref> [1, 2, 3, 4] </ref> that give keyword access to documents. However, these tools give little information about the visual content of documents or about the relative connections between various pieces.
Reference: [5] <author> C. F. Goldfarb. </author> <title> The SGML Handbook. </title> <publisher> Clarendon Press, Oxford, </publisher> <year> 1990. </year>
Reference-contexts: Consideration of the logical locations of word occurrence (for instance, in the abstract versus a later section) can be used for improved weighting schemes in information retrieval systems. Logical structure may be directly mapped to automated markup in a format such as sgml <ref> [5] </ref>. Documents may be indexed according to the presence of (and relationships between) various logical structures.
Reference: [6] <author> A. Jain and S. Bhattacharjee. </author> <title> Address block location on envelopes using gabor filters. </title> <journal> Pattern Recognition, </journal> <volume> 25(12), </volume> <year> 1992. </year>
Reference-contexts: Subsections, itemized lists, and figures are examples of layout components. 3 1.2 Previous Work Most work on document structuring applies only to documents whose format is known in advance and/or finds only a flat set of divisions. The systems in <ref> [6, 7, 8, 9] </ref>, have both of these characteristics. They divide pages of one format type each into a single set of segments. <p> They divide pages of one format type each into a single set of segments. The approaches are appropriate for their specific applications, namely, segmenting pages of technical journals [7, 9] into text and graphics, locating address blocks in letters <ref> [6] </ref>, and separating tables into their cells [8]. [10] describes a system that relies on far less specific knowledge about formatting; it divides pages into text blocks and then divides the blocks into lines, in order to develop a reading order.
Reference: [7] <author> G. Nagy, S. Seth, and M. Vishwanathan. </author> <title> A prototype document image analysis system for technical journals. </title> <journal> Computer, </journal> <volume> 25(7), </volume> <year> 1992. </year>
Reference-contexts: Subsections, itemized lists, and figures are examples of layout components. 3 1.2 Previous Work Most work on document structuring applies only to documents whose format is known in advance and/or finds only a flat set of divisions. The systems in <ref> [6, 7, 8, 9] </ref>, have both of these characteristics. They divide pages of one format type each into a single set of segments. <p> The systems in [6, 7, 8, 9], have both of these characteristics. They divide pages of one format type each into a single set of segments. The approaches are appropriate for their specific applications, namely, segmenting pages of technical journals <ref> [7, 9] </ref> into text and graphics, locating address blocks in letters [6], and separating tables into their cells [8]. [10] describes a system that relies on far less specific knowledge about formatting; it divides pages into text blocks and then divides the blocks into lines, in order to develop a reading
Reference: [8] <author> M. A. Rahgozar, Z. Fan, and E. V. Rainero. </author> <title> Tabular document recognition. </title> <booktitle> In SPIE Proceedings, </booktitle> <address> San Jose, </address> <month> February </month> <year> 1994. </year>
Reference-contexts: Subsections, itemized lists, and figures are examples of layout components. 3 1.2 Previous Work Most work on document structuring applies only to documents whose format is known in advance and/or finds only a flat set of divisions. The systems in <ref> [6, 7, 8, 9] </ref>, have both of these characteristics. They divide pages of one format type each into a single set of segments. <p> They divide pages of one format type each into a single set of segments. The approaches are appropriate for their specific applications, namely, segmenting pages of technical journals [7, 9] into text and graphics, locating address blocks in letters [6], and separating tables into their cells <ref> [8] </ref>. [10] describes a system that relies on far less specific knowledge about formatting; it divides pages into text blocks and then divides the blocks into lines, in order to develop a reading order. <p> be a block of text of n rows and m columns and w : fcjc is a character g ! f0; 1g with w (" ") = 1 and 8c 6= " "; w (c) = 0. 9 This section is based on [18]. 10 In this, we differ from <ref> [8] </ref>, where the goal is to find the grid structure in a text component known to be a table. 15 08/22/96 Titan IV/Centaur Launch 03/29/97 - 66 Maja Asteroid Flyby 06/08/98 Earth Gravity Assist 02/06/00 - Jupiter Gravity Assist 12/06/02 - Saturn Arrival 03/27/03 Titan Probe Release 03/29/03 Orbiter Deflection Maneuver
Reference: [9] <author> D. Wang and S. N. Srihari. </author> <title> Classification of newspaper image blocks using texture analysis. Computer Vision, </title> <journal> Graphics, and Image Processing, </journal> <volume> 47 </volume> <pages> 327-352, </pages> <year> 1989. </year>
Reference-contexts: Subsections, itemized lists, and figures are examples of layout components. 3 1.2 Previous Work Most work on document structuring applies only to documents whose format is known in advance and/or finds only a flat set of divisions. The systems in <ref> [6, 7, 8, 9] </ref>, have both of these characteristics. They divide pages of one format type each into a single set of segments. <p> The systems in [6, 7, 8, 9], have both of these characteristics. They divide pages of one format type each into a single set of segments. The approaches are appropriate for their specific applications, namely, segmenting pages of technical journals <ref> [7, 9] </ref> into text and graphics, locating address blocks in letters [6], and separating tables into their cells [8]. [10] describes a system that relies on far less specific knowledge about formatting; it divides pages into text blocks and then divides the blocks into lines, in order to develop a reading
Reference: [10] <author> H. S. Baird. </author> <title> Anatomy of a versatile page reader. </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> 80(7), </volume> <year> 1992. </year> <month> 31 </month>
Reference-contexts: They divide pages of one format type each into a single set of segments. The approaches are appropriate for their specific applications, namely, segmenting pages of technical journals [7, 9] into text and graphics, locating address blocks in letters [6], and separating tables into their cells [8]. <ref> [10] </ref> describes a system that relies on far less specific knowledge about formatting; it divides pages into text blocks and then divides the blocks into lines, in order to develop a reading order.
Reference: [11] <author> M. Mizuno, Y. Tsuji, T. Tanaka, H. Tanaka, M. Iwashita, and T. Temma. </author> <title> Document recognition system with layout structure generator. </title> <journal> NEC Research and Development, </journal> <volume> 32(2) </volume> <pages> 430-437, </pages> <month> July </month> <year> 1991. </year>
Reference-contexts: Again, there is only one level of divisions above the level of text lines, which is all that is needed for the purpose. The systems in <ref> [11, 12] </ref> find a logical document hierarchy composed of paragraphs, subsections, and sections, based on knowledge of standard printers' formatting rules. These rules form a grammar, and documents can be parsed accordingly.
Reference: [12] <author> S. Tsujimoto and H. Asada. </author> <title> Major components of a complete text reading system. </title> <booktitle> In Proceedings of the IEEE, </booktitle> <volume> volume 80, </volume> <year> 1992. </year>
Reference-contexts: Again, there is only one level of divisions above the level of text lines, which is all that is needed for the purpose. The systems in <ref> [11, 12] </ref> find a logical document hierarchy composed of paragraphs, subsections, and sections, based on knowledge of standard printers' formatting rules. These rules form a grammar, and documents can be parsed accordingly.
Reference: [13] <author> G. Porter and E. Rainero. </author> <title> Document reconstruction: A system for recovering document structure from layout. </title> <booktitle> In Proceedings of the Conference on Electronic Publishing, </booktitle> <pages> pages 127-141, </pages> <year> 1992. </year>
Reference-contexts: The systems in [11, 12] find a logical document hierarchy composed of paragraphs, subsections, and sections, based on knowledge of standard printers' formatting rules. These rules form a grammar, and documents can be parsed accordingly. In <ref> [13] </ref>, tree manipulation is used to build logical hierarchies that also include intermediate structures; knowledge of the formatting rules for a particular document's style is required. (For example, a document may be known to have been formatted with the L a T E X article style.) This kind of approach has
Reference: [14] <author> P. D. Bruza and T. W. C. Huibers. </author> <title> Detecting the erosion of hierarchic information structures. </title> <booktitle> In Proceedings of the Workshop on Principles of Document Processing, </booktitle> <address> Seeheim, </address> <year> 1994. </year>
Reference-contexts: A parser built on top of the Unix utility ps2ascii is used for postscript documents. 3 Not only does this apply to documents found by browsing the internet, but it may also apply to more limited collections surprisingly often; <ref> [14] </ref> suggests that people tend to violate formatting rules, even when they write the rules themselves. 4 The next component of the system is responsible for dividing the document into a hierarchy of layout blocks, which we represent as a tree.
Reference: [15] <author> D. Rus and D. Subramanian. </author> <title> Multi-media RISSC Informatics: Retrieving Information with Simple Structural Components. </title> <booktitle> In Proceedings of the ACM Conference on Information and Knowledge Management, </booktitle> <address> Washington DC, </address> <month> November </month> <year> 1993. </year>
Reference-contexts: Our current implementation for step (1) divides the document into text blocks and blank blocks. Each document line in such a block constitutes a sub-block. Other segmentation algorithms are possible, such as the one proposed in <ref> [15] </ref>. Step (2) of the algorithm builds the actual hierarchy. The details of steps (a), (b), and (c) are described in the next section. Intuitively, at each iteration the algorithm builds the next level by discovering repetitions. <p> (2) distributed access of remote electronic repositories, by providing partial models of documents that essentially "compress" the data at a various levels of detail; (3) 30 conceptualizing the search of electronic documents by providing support for retrieval with non-linguistic cues, an approach illustrated by examples throughout this paper and in <ref> [17, 15] </ref>; and (4) uniformly marking-up generic documents for other retrieval purposes by automatically recognizing the logical components of documents.
Reference: [16] <author> L. Lamport. </author> <title> L a T E X: A Document Preparation System. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, </address> <year> 1986. </year>
Reference-contexts: In the case of a scanned-in document, we are not assured that all significant font changes are readily identifiable in this manner. Furthermore, font types as well as sizes carry significant information. For example, the L a T E X environment description <ref> [16] </ref> includes a boldface heading at the beginning of each item.
Reference: [17] <author> J. Allan, J. Davis, D. Krafft, D. Rus, and D. Subramanian. </author> <title> Information agents for building hyperlinks, </title> <year> 1993. </year>
Reference-contexts: For example, the answers for queries such as "find precision recall measures for the CACM collection," "find performance graphs of the Byzantine agreement protocol," and "find a list of assumptions in this paper" <ref> [17] </ref> can be better filtered by using the conventions for data presentation (e.g., in the form of tables and graphs), in connection with a topic classifier. 4.1 A Classifier for Tables 9 Webster's Seventh Dictionary defines a table as a systematic arrangement of data usually in rows and columns for ready <p> (2) distributed access of remote electronic repositories, by providing partial models of documents that essentially "compress" the data at a various levels of detail; (3) 30 conceptualizing the search of electronic documents by providing support for retrieval with non-linguistic cues, an approach illustrated by examples throughout this paper and in <ref> [17, 15] </ref>; and (4) uniformly marking-up generic documents for other retrieval purposes by automatically recognizing the logical components of documents.
Reference: [18] <author> C. Lewis, D. Rus, and M. Scott. </author> <title> A structure detector for tables. </title> <type> Forthcoming Technical Report. </type>
Reference-contexts: of the vertical character projection.) Let B be a block of text of n rows and m columns and w : fcjc is a character g ! f0; 1g with w (" ") = 1 and 8c 6= " "; w (c) = 0. 9 This section is based on <ref> [18] </ref>. 10 In this, we differ from [8], where the goal is to find the grid structure in a text component known to be a table. 15 08/22/96 Titan IV/Centaur Launch 03/29/97 - 66 Maja Asteroid Flyby 06/08/98 Earth Gravity Assist 02/06/00 - Jupiter Gravity Assist 12/06/02 - Saturn Arrival 03/27/03 <p> that our treatment of table recognition allows for the recognition of tables with multi-line records and errors (to within some specified or probabilistically computed parameters.) This efficient and robust table detector has been implemented and used to build information agents for retrieval tasks whose answers are found in tabular form <ref> [18] </ref>. 19 2 6 6 6 6 6 6 6 6 t 1 t 2 t 4 t 6 t 8 t 9 t 10 t 1 t 2 t 4 t 6 t 8 t 9 t 10 t 1 t 2 t 4 t 0 t 8 t 9
Reference: [19] <author> D. Sankoff and J. Kruskal. </author> <title> Time warps, string edits, and macromolecules: the theory and practice of sequence comparison. </title> <publisher> Addison-Wesley, </publisher> <year> 1983. </year>
Reference-contexts: Now consider Figure 10. This table lacks the lexical regularity of Table 9, because there are small irregularities in the lexical structure of the columns. To express this more rigorously, let M be a metric for string comparison (we use the Levenstein metric <ref> [19] </ref>.) Given * &gt; 0, two 16 100a Introduction to Computer Programming 4 Lec1 TR 9:05 Ives 120 Wagner Lec2 TR 11:15 Ives 120 100b Introduction to Computer Programming 4 Lec1 TR 9:05 Olin 255 Van Loan Lec2 TR 11:15 Ives 110 101 The Computer Age 3 TR 1:25 Upson B17
Reference: [20] <author> H. Kucera and W. Francis. </author> <title> Computational Analysis of Presentday American English. </title> <publisher> Brown University Press, </publisher> <address> Providence, RI, </address> <year> 1967. </year>
Reference-contexts: The analysis makes the following assumptions: * The average word length that occurs in text is known. For English, <ref> [20] </ref> have determined that the average word length of distinct words is 8.1 characters, but of word occurrences in written text, it is 4.7 characters.
Reference: [21] <institution> Splus Reference Manual. Statistical Sciences, Inc., </institution> <year> 1991. </year>
Reference-contexts: This is due to the fact that the lengths of words and of the spacing between them are variable, and their occurrences in a line of text are random. We have tested the independence of the distribution of white space by extensive experiments with Splus <ref> [21] </ref>. This implies that the blank spaces of a line have a binomial distribution. 12 Let B be a block of text of n rows and m columns.
Reference: [22] <author> D. Kozen. </author> <title> The Design and Analysis of Algorithms. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1992. </year>
Reference-contexts: If t ij = t i 0 j 0 the data in row i and column j and the data in row i 0 and column j 0 are *-similar. The type matrix for the table in Figure 10 is given in Figure 13. A GCD algorithm <ref> [22] </ref> can be used to determine the type, if any, of the overall matrix and thus to decide whether the matrix represents a table.
Reference: [23] <author> D. Conelly and B. Paddock. </author> <title> XDOC data format: </title> <type> Technical specification. </type> <institution> Xerox Imaging Systems, Inc., </institution> <address> Peabody, MA, </address> <year> 1993. </year>
Reference-contexts: This usage presumes prior knowledge of the portions of the document that constitute figures. In many cases, such an assumption is reasonable. For example, in a PostScript document representation, identifiable commands indicate the inclusion of figures; similarly in the xdoc format, generated by the ScanWorX optical character recognition software <ref> [23] </ref>, figures are separated from text and represented differently. Nonetheless, this distinction may not always be readily available. An ascii text file, such as an electronic news or mail message, will not provide such convenient separations.
Reference: [24] <author> G. Eliot. Daniel Deronda. </author> <title> The World's Classics. </title> <publisher> Oxford University Press, Oxford, </publisher> <year> 1984. </year>
Reference-contexts: We 16 Titles are usually printed in a larger size than authors' names or printed above them, but consider the novel Daniel Deronda by George Eliot. The cover to the paperback Oxford edition <ref> [24] </ref> contains two lines: one with the author's name, and one with the title.
Reference: [25] <author> D. Rus and J. Allan. </author> <title> Image indexing using the hausdorff metric. </title> <type> Forthcoming Technical Report. 32 </type>
Reference-contexts: The system is then used to compute the hyperlinks between layout pieces. Hyperlinks between the figures in the collection of documents are computed using the Hausdorff matching algorithm <ref> [25] </ref>. 21 Smart indexes documents by keywords and uses a vector space model for retrieval. 28 isolated paragraph and the (lower) two-line paragraph. The left side shows level 1.
References-found: 25

