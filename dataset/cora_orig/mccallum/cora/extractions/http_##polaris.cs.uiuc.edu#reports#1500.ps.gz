URL: http://polaris.cs.uiuc.edu/reports/1500.ps.gz
Refering-URL: http://polaris.cs.uiuc.edu/polaris/rep2.html
Root-URL: http://www.cs.uiuc.edu
Title: THE DESIGN OF AN EFFICIENT AND PORTABLE INTERFACE BETWEEN A PARALLELIZING COMPILER AND ITS TARGET MACHINE  
Author: BY JEE MYEONG KU 
Degree: 1993 THESIS Submitted in partial fulfillment of the requirements for the degree of Master of Science in Electrical Engineering in the Graduate College of the  
Address: 1995 Urbana, Illinois  
Affiliation: B.S., University of Illinois,  University of Illinois at Urbana-Champaign,  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> T. Anderson, E. Lazowska, and H. Levy. </author> <title> The performance implications of thread management alternatives for shared-memory multiprocessors. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 38(12) </volume> <pages> 1631-1694, </pages> <month> December </month> <year> 1989. </year>
Reference-contexts: The threads either spin-wait or are put to sleep until work is assigned. Anderson, Lazowska, and Levy provide a general description of an abstract thread package <ref> [1] </ref>. There are six thread operations. They are thread creation, thread startup, thread block, thread resume, thread finish, and signal a blocked thread.
Reference: [2] <author> M. Berry, D. Chen, P. Koss, D. Kuck, L. Pointer, S. Lo, Y. Pang, R. Roloff, A. Sameh, E. Clementi, S. Chin, D. Schneider, G. Fox, P. Messina, D. Walker, C. Hsiung, J. Schwarzmeier, K. Lue, S. Orszag, F. Seidl, O. Johnson, G. Swanson, R. Goodrum, and J. Martin. </author> <title> The Perfect Club Benchmarks: Effective Performance Evalution of Supercomputers. </title> <journal> International Journal of Supercomputer Applications, </journal> <month> Fall </month> <year> 1989, </year> <pages> 3(3) 5-40, </pages> <month> Fall </month> <year> 1989. </year>
Reference-contexts: The Polaris parallelizing compiler, which deals with source-to-source transformations in Fortran, is a research compiler that has been developed to prove the effectiveness of these techniques [11]. Its effectiveness was determined by observing the speedups of the Perfect Benchmark programs on the SGI Challenge <ref> [2] </ref>. The Perfect Benchmarks are real-application programs that can provide a better insight into the true ability of the parallelizing compilers. From the speedups obtained, it is clear that the Polaris compiler makes effective use of the advanced techniques needed for successful parellelization. <p> To test the effectiveness of the two parts of the Polaris backend, programs from three different suites were used. Six codes were used from the Perfect Benchmark suite <ref> [2] </ref>. They are ARC2D, BDNA, FLO52, MDG, OCEAN, 21 22 and TRFD. ARC2D is a finite-difference code by NASA Ames Research Center that solves a two-dimensional fluid flow problem by using the Euler and Navier-Stokes equations. BDNA is a molecular dynamics simulation program of biomolecules in water.
Reference: [3] <author> William Blume and Rudolf Eigenmann. </author> <title> The Range Test: A Dependence Test for Symbolic, Non-linear Expressions. </title> <booktitle> Proceedings of Supercomputing '94, </booktitle> <address> Washington D.C., </address> <pages> pages 528-537, </pages> <month> November </month> <year> 1994. </year>
Reference-contexts: To gain good speedups, it is not enough to apply a linear data dependence analysis. The Polaris compiler is able to find more data independent loops by using symbolic and nonlinear analyses. To handle complicated symbolic dependences, a symbolic dependence test called the range test was developed <ref> [3] </ref>. The range test proves that a loop is parallel by proving that the range of elements in one iteration do not overlap with the range of other iterations. Using the range test, it is possible to evaluate nonlinear array indices with nonlinear loop bounds. <p> Since the new variable DYN0 should be local to NEW SBR, it is declared and dynamically allocated here. In this example, the symbolic range is determined to be from one to the value of PASS. To determine the symbolic size of the variables, the range analysis must be used <ref> [3] </ref>. 33 The range analysis can determine the size of an array by calculating the lowest and highest indices that are referenced. Therefore, it must first be a variable of type POINTER, which is PTR in this case.
Reference: [4] <author> William Blume and Rudolf Eigenmann. </author> <title> Performance Analysis of Parallelizing Compilers on the Perfect BenchmarksP . rograms. </title> <journal> IEEE Transactions of Parallel and Distributed Systems, </journal> <volume> 3(6) </volume> <pages> 643-656, </pages> <month> November </month> <year> 1992. </year>
Reference-contexts: Although they work well on small test loops that are easily parallelizable, most real serial programs are more difficult to parallelize. Nevertheless, recent research in the parallelizing compiler technology has shown that an effective compiler is possible if several important techniques are used for parallelization <ref> [4] </ref>. The Polaris parallelizing compiler, which deals with source-to-source transformations in Fortran, is a research compiler that has been developed to prove the effectiveness of these techniques [11]. Its effectiveness was determined by observing the speedups of the Perfect Benchmark programs on the SGI Challenge [2].
Reference: [5] <author> William Blume, Rudolf Eigenmann, Keith Faigin, John Grout, Jay Hoeflinger, David Padua, Paul Petersen, William Pottenger, Lawrence Rauchwerger, Peng Tu, and Stephen Weatherford. </author> <title> Polaris: The Next Generation in Parallelizing Compilers. </title> <booktitle> Proceedings of the Workshop on Languages and Compilers for Parallel Computing, </booktitle> <address> Ithaca, New York, pages 10.1 - 10.18, </address> <month> August </month> <year> 1994. </year>
Reference-contexts: Polaris is implemented in C++, allowing for a clear structure and high data abstraction. The techniques that were determined to be necessary are built into Polaris. They include interprocedural analysis through inlining, symbolic and nonlinear data dependence analysis, scalar and array privatization, advanced induction, and reduction recognition. <ref> [5] </ref>. 6 If there is a subroutine call inside a loop, the loop cannot be parallelized without an in--terprocedural analysis that tells the state of the variables used in the called subroutine. One way of doing interprocedural analysis is by inlining the called subroutines at the point of the call. <p> The table shows that in the large loops that take up a large percentage of the execution time, parallelization of the loop greatly improves performance. This is true for the two loops of BDNA, ACTFOR do240 and ACTFOR do500, which take up 94.4% of the total serial execution time <ref> [5] </ref>. The same is true for INTERF do1000, which takes up 91.9% of the total serial time [5]. The parallelization of these large loops speeds up the entire program significantly. <p> This is true for the two loops of BDNA, ACTFOR do240 and ACTFOR do500, which take up 94.4% of the total serial execution time <ref> [5] </ref>. The same is true for INTERF do1000, which takes up 91.9% of the total serial time [5]. The parallelization of these large loops speeds up the entire program significantly. There are cases in which the transformed version is slower, because of the loop overheads, the initialization and the summation of the expanded temporary variables. This case applies to ACTFOR do720, MPOLES do70, and FIXCOM do20.
Reference: [6] <author> SGI Documentation. </author> <title> Fortran 77 language reference manual. Silicon Graphics, </title> <publisher> Inc., </publisher> <year> 1994. </year>
Reference-contexts: Flash mode minimizes the effect that the background workload of the system can have on the performance of the program. 2.2.2 The SGI Fortran directive language The SGI Fortran compiler parallelizes loops based on the information given through the directives. The parallel directive is called a DOACROSS <ref> [6] </ref>, which allows various clauses that specify the variables used in the loop body that are shared (SHARE) and private (LOCAL). It is possible to privatize scalar and array variables using the private clause. When a variable is privatized, each thread has its own copy of the variable. <p> It therefore has to be dynamically allocated. On the SGI it requires another variable of type POINTER, which is related to this variable <ref> [6] </ref>. In order to use the variable in the subroutine INNER, both variables must be passed. The variable PTR can be passed through the common block because its size is statically determined, but the variable DYNAMIC must be passed through the argument list.
Reference: [7] <author> SGI Documentation. </author> <title> Fortran 77 Programmer's Guide and associated man pages. Silicon Graphics, </title> <publisher> Inc., </publisher> <year> 1994. </year>
Reference-contexts: Otherwise, it will be run on one thread. The IF clause saves overhead in executing small loops where the parallel version is actually slower than the serial version. The breaking point between the serial and parallel versions is about 400 CPU cycles, which amount to about 100 floating-point operations <ref> [7] </ref>. The Polaris compiler provides a simple static analyzer that checks the number of iterations and statements to calculate an expression inside the IF clause. The Polaris directive is also called IF. It is also possible to specify different scheduling algorithms through the MP SCHEDTYPE clause. <p> One way is through COMMON blocks. A common block allows all variables associated with it to be allocated together in the memory so that multiple program units can share the data <ref> [7] </ref>. Not all variables, however, can be in the common block. These variables include local variables, variables that appear in the argument list of one of the program units, and variables whose total array size is not known at compile time.
Reference: [8] <author> R. Eigenmann, J. Hoeflinger, Z. Li, and D. Padua. </author> <title> Experience in the automatic paral-lelization of four Perfect-Benchmark programs. </title> <booktitle> In Proceedings of 4-th Workshop on Programming Languages and Compilers for Parallel Computing. </booktitle> <publisher> Pitman/MIT Press, </publisher> <month> August </month> <year> 1991. </year>
Reference-contexts: The compiler is the result of a study on identifying effective program transformations of the Perfect Benchmark suite <ref> [8] </ref>. Since several studies on the Perfect Benchmarks had shown that the transformations are effective and automatable, the Polaris compiler was built to prove that a parallelizing compiler could indeed be an effective way of improving parallel performance of serial codes automatically.
Reference: [9] <author> M. Galles and E. Williams. </author> <title> Performance optimizations, implementation, and verification of the sgi challenge multiprocessor. </title> <type> Technical report, </type> <institution> Silicon Graphics Computer Systems, </institution> <year> 1994. </year>
Reference-contexts: Up to eight processors can be used in parallel per execution. Its shared memory of 1 Gbytes is connected to the processors through the POWERpath-2 coherent interconnect <ref> [9] </ref>. The 13 interconnect is a split transaction bus that can sustain 1.2 Gbytes per second and 9.5 million transactions per second. It uses a snoopy write-invalidate cache-coherence protocol that is similar to the Illinois Protocol [12]. Each cache line is 128 bytes long.
Reference: [10] <author> John M. Mellor-Crummey and Michael L. Scott. </author> <title> Algorithms for scalable synchronization on shared-memory multiprocessors. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 9(1) </volume> <pages> 21-65, </pages> <month> November </month> <year> 1991. </year>
Reference-contexts: Trying to grab the lock again as soon as possible may be less efficient than waiting before access. Since the test-and-set function makes only one attempt at obtaining the lock, a custom LOCK function was built. The waiting strategy used is called delayed backoff <ref> [10] </ref>. With the delayed backoff strategy, the waiting time increases by a constant factor as the number of attempts increases. If the constant factor is 2, then the waiting time is 1 after the first failure, but it becomes 2 after the second, and then 4, 8, and so on.
Reference: [11] <author> D. Padua, R. Eigenmann, J. Hoeflinger, P. Petersen, P. Tu, S. Weatherford, and K. Faigin. </author> <title> Polaris: A New-Generation Parallelizing Compiler for MPP's. </title> <type> Technical Report 1306, </type> <institution> Univ. of Illinois at Urbana-Champaign, Center for Supercomputing Res. & Dev., </institution> <month> June </month> <year> 1993. </year>
Reference-contexts: The Polaris parallelizing compiler, which deals with source-to-source transformations in Fortran, is a research compiler that has been developed to prove the effectiveness of these techniques <ref> [11] </ref>. Its effectiveness was determined by observing the speedups of the Perfect Benchmark programs on the SGI Challenge [2]. The Perfect Benchmarks are real-application programs that can provide a better insight into the true ability of the parallelizing compilers.
Reference: [12] <author> M. Papamarcos and J. Patel. </author> <title> A low overhead coherent solution for multiprocessors with private cache memories. </title> <booktitle> In Proceedings of the 11th International Symposium on Computer Architecture. IEEE, </booktitle> <year> 1984. </year>
Reference-contexts: The 13 interconnect is a split transaction bus that can sustain 1.2 Gbytes per second and 9.5 million transactions per second. It uses a snoopy write-invalidate cache-coherence protocol that is similar to the Illinois Protocol <ref> [12] </ref>. Each cache line is 128 bytes long. It uses the MIPS R4400 RISC processors, which have a clock speed of 150 MHz. Its peak performance is 75 MFLOPS, resulting in a total of 900 MFLOPS of performance. The machine supports various types of operating system level scheduling.
Reference: [13] <author> William Pottenger and Rudolf Eigenmann. </author> <title> Parallelization in the Presence of Generalized Induction and Reduction Variables. </title> <type> Technical Report 1396, </type> <institution> Univ. of Illinois at Urbana-Champaign, Center for Supercomputing Research & Development, </institution> <month> January </month> <year> 1995. </year>
Reference-contexts: ; : : : ; ff n ) + fi where ff i and fi must not contain any reference to A and where A is not referenced anywhere else in the loop unless the statement in which it is referenced is another reduction statement involving the same reduction expression <ref> [13] </ref>. If n is equal to 0, then A is simply a scalar variable. 2.1.3 The Polaris backend All the techniques mentioned above belong in the Polaris compiler frontend of Figure 1.1.

References-found: 13

