URL: ftp://softlib.rice.edu/pub/CRPC-TRs/reports/CRPC-TR92241.ps.gz
Refering-URL: http://www.crpc.rice.edu/CRPC/softlib/TRs_online.html
Root-URL: 
Title: Productive Parallel Programming: The PCN Approach  
Author: Ian Foster, Robert Olson, and Steven Tuecke 
Keyword: PCN, program composition, parallel programming, reuse, templates.  
Address: Argonne, IL 60439  
Affiliation: Mathematics and Computer Science Division Argonne National Laboratory,  
Abstract: We describe the PCN programming system, focusing on those features designed to improve the productivity of scientists and engineers using parallel supercomputers. These features include a simple notation for the concise specification of concurrent algorithms, the ability to incorporate existing Fortran and C code into parallel applications, facilities for reusing parallel program components, a portable toolkit that allows applications to be developed on a workstation or small parallel computer and run unchanged on supercomputers, and integrated debugging and performance analysis tools. We survey representative scientific applications and identify problem classes for which PCN has proved particularly useful.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Chandy, C., and Taylor, S., </author> <title> An Introduction to Parallel Programming, </title> <editor> Jones and Bartlett, </editor> <year> 1991. </year>
Reference-contexts: The programming notation used in the PCN system is Program Composition Notation (PCN). PCN extends sequential programming with two simple ideas | concurrent composition and single-assignment variables | and defines how these ideas interact with conventional sequential constructs <ref> [1, 6] </ref>. The PCN system also incorporates two additional constructs | virtual topologies and port arrays | that allow the definition and reuse of parallel program structures called cells and templates [4]. Our description of the PCN language is divided into five parts.
Reference: [2] <author> Chern, I., and Foster, I., </author> <title> Design and parallel implementation of two methods for solving PDEs on the sphere, </title> <booktitle> Proc. Conf. on Parallel Computational Fluid Dynamics, </booktitle> <address> Stuttgart, Germany, </address> <publisher> Elsevier Science Publishers B.V., </publisher> <year> 1991. </year>
Reference-contexts: For example, the first two applications operational on the 528-processor, 30 Gflops Intel Touchstone Delta system | a geophysical modeling code and a fluid dynamics code | were both PCN programs <ref> [2, 7] </ref>. <p> The code was developed to permit detailed studies of both the method's accuracy and the long-term behavior of fundamental modes of the atmospheric circulation. The code integrates existing Fortran and C code into a parallel framework implemented in PCN <ref> [2] </ref>. An icosahedral-hexagonal grid can be structured as 10 nfin meshes plus two separate polar points. The parallel algorithm decomposes each mesh into c 2 submeshes, giving 10 c 2 + 2 subdomains, two with one point and the rest with (n/c) 2 points. <p> Mesh Structures. The structure of many different mesh-based applications can be captured in one- or two-dimensional mesh templates. A two-dimensional mesh template forms a building block for both the icosahedral code and another climate modeling code based on overlapping stereographic meshes <ref> [2] </ref> (3800 lines C, 640 lines PCN).
Reference: [3] <author> Foster, I., </author> <title> Automatic generation of self-scheduling programs, </title> <journal> IEEE Trans. Parallel and Distributed Systems, </journal> <volume> 2(1) </volume> <pages> 68-78, </pages> <year> 1991. </year>
Reference-contexts: Programmers can use this facility to implement application-specific extensions to the PCN language. For example, the transformation system has been used to implement specialized composition operators that generate self-scheduling computations <ref> [3] </ref>. 5.2 Network Implementation The network implementation of PCN (net-PCN) allows users to treat a set of workstations as a parallel computer. <p> Self-Scheduling Structures. A self-scheduling program incorporates code to dynamically map tasks to idle processors; although this approach introduces additional overhead relative to a static schedule, it is essential for some very dynamic problems. Self-scheduling programs can be constructed easily in PCN because of the simplicity of process migration <ref> [3] </ref>. (The global address space provided by the compiler means that processes can be migrated as data structures.) Self-scheduling applications include codes for aligning genetic sequences, computing phylogenetic trees, and predicting protein structure. (Computational biology is a rich source of applications for self-scheduling techniques, because of the frequent use of heuristics.)
Reference: [4] <author> Foster, I., </author> <title> Information hiding in parallel programs, </title> <type> Preprint MCS-P290-0292, </type> <institution> Ar-gonne National Laboratory, </institution> <year> 1992. </year>
Reference-contexts: The PCN system also incorporates two additional constructs | virtual topologies and port arrays | that allow the definition and reuse of parallel program structures called cells and templates <ref> [4] </ref>. Our description of the PCN language is divided into five parts. These describe in turn the constructs used to specify concurrency, communication and synchronization, non-determinism, mapping, and composition of process ensembles. 3.1 Concurrency Syntax is similar to that of the C programming language. <p> the reuse of parallel code is based on what we term a software cell: a set of processes created within a virtual topology to perform some distinct function such as a reduction or a mesh computation, and provided with one or more port arrays for communication with other program components <ref> [4] </ref>. We have already seen several examples of cells: for instance, the procedure ring in the preceding section implements a cell that performs ring pipeline computations. The interface to a PCN cell consists simply of the port arrays and definitional variables that are its arguments. <p> On some parallel computers, it may be desirable to place two or more subdomains on the same processor. 15 Implementation. The development of the parallel code is simplified if mapping is spec-ified with respect to a virtual topology with the same shape as the problem domain <ref> [4] </ref>. We define an ico mesh topology containing ten cfic meshes and two polar processors (Figure 1) and map functions rhombus (i) and pole (i) that embed subtopologies corresponding to a single mesh or pole in an ico mesh. These functions are defined as follows.
Reference: [5] <author> Foster, I., and Taylor, S., Strand: </author> <title> New Concepts in Parallel Programming, </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, N.J., </address> <year> 1989. </year>
Reference-contexts: A shared definitional variable would not be very useful if it could only be used to exchange a single value. Fortunately, simple techniques allow a 4 single variable to be used to communicate a stream of values <ref> [5] </ref>. A stream acts like a queue: the producer places elements on one end, and the consumer (s) take them off the other. Stream communication is achieved by the incremental construction of linked list structures. The technique makes use of a data type called the tuple.
Reference: [6] <author> Foster, I., and Tuecke, S., </author> <title> Parallel Programming with PCN, </title> <type> Technical Report ANL-91/32, </type> <institution> Argonne National Laboratory, </institution> <year> 1991. </year>
Reference-contexts: The programming notation used in the PCN system is Program Composition Notation (PCN). PCN extends sequential programming with two simple ideas | concurrent composition and single-assignment variables | and defines how these ideas interact with conventional sequential constructs <ref> [1, 6] </ref>. The PCN system also incorporates two additional constructs | virtual topologies and port arrays | that allow the definition and reuse of parallel program structures called cells and templates [4]. Our description of the PCN language is divided into five parts. <p> These tools are integrated with other com-ponents to form a toolkit that supports debugging, performance tuning, and integration of Fortran and C code, and that allows programs to be executed on a wide variety of parallel computers and workstation networks <ref> [6] </ref>. <p> This algorithm dynamically creates a process tree; data is produced at the leaves, flows up the tree to the root (being reduced at each node) and then back down to the leaves to yield the final solution <ref> [6] </ref>. The code is defined with respect to a tree virtual topology; the map function that defines this topology specifies how the complete structure 20 is embedded in a parallel computer.
Reference: [7] <author> Harrar, H., Keller, H., Lin, D., and Taylor, S., </author> <title> Parallel computation of Taylor-vortex flows, </title> <booktitle> Proc. Conf. on Parallel Computational Fluid Dynamics, </booktitle> <address> Stuttgart, Germany, </address> <publisher> Elsevier Science Publishers B.V., </publisher> <year> 1991. </year>
Reference-contexts: For example, the first two applications operational on the 528-processor, 30 Gflops Intel Touchstone Delta system | a geophysical modeling code and a fluid dynamics code | were both PCN programs <ref> [2, 7] </ref>. <p> Other mesh-based applications include a computational fluid dynamics code developed by Harrar et al. for computing Taylor-vortex flows, based on a torus structure <ref> [7] </ref> (5300 lines Fortran, 900 lines PCN); a finite-element code for simulating flow in Titan rocket engines (9000 lines Fortran, 180 lines PCN); and a parallel implementation of the mesoscale weather model MM4 (15000 lines Fortran, 250 lines PCN).
Reference: [8] <author> Herrarte, V., and Lusk, E., </author> <title> Studying parallel program behavior with Upshot, </title> <type> Technical Report ANL-91/15, </type> <institution> Argonne National Laboratory, </institution> <year> 1991. </year>
Reference-contexts: A powerful data exploration tool permits graphical exploration of profile data. The use of Gauge is illustrated in a subsequent section. 14 Upshot. Upshot is a trace analysis tool that can provide insights into the fine-grained operation of parallel programs <ref> [8] </ref>. Upshot requires that the programmer instrument a program with calls to event logging primitives. These events are automatically recorded and written to a file when a program runs. A graphical trace analysis tool allows the programmer to examine temporal dependencies between events.
Reference: [9] <author> Kesselman, C., </author> <title> Integrating Performance Analysis with Performance Improvement in Parallel Programs, </title> <type> Technical Report UCLA-CS-TR-91-03, </type> <institution> UCLA, </institution> <year> 1991. </year>
Reference-contexts: Two such tools, Gauge and Upshot, have been integrated into PCN. Gauge. Gauge is an execution profiler: it collects information about the amount of time that each processor spends in different parts of a program <ref> [9] </ref>. It also collects procedure call counts, message counts, and idle time information.
Reference: [10] <author> Olson, R., </author> <title> Using host-control, </title> <type> Technical Memo ANL/MCS-TM-154, </type> <institution> Argonne National Laboratory, </institution> <year> 1991. </year>
Reference-contexts: A useful component of Net-PCN is a utility program called host-control, which provides facilities for managing a network computation. This utility allows the user to inquire about the status of nodes available to Net-PCN, add and delete nodes, and execute programs <ref> [10] </ref>. 5.3 PDB: A Parallel Debugger Debugging tools that assist in the location of logical errors are, of course, a critical component of any programming system. PCN's unconventional language constructs, in particular its lightweight processes and dataflow synchronization, require specialized debugging support.
Reference: [11] <author> Whitehead, A., </author> <title> An Introduction to Mathematics, </title> <publisher> Oxford University Press, </publisher> <year> 1958. </year>
Reference-contexts: This issue is discussed in Section 4.1. 3 Notation Programming is rarely easy, but an appropriate notation can make it less difficult. As Whitehead observed of mathematics: "By relieving the brain of all unnecessary work, a good notation sets it free to concentrate on more advanced problems" <ref> [11] </ref>. In parallel programming, a good notation should express concurrency, communication, synchronization, and mapping straightforwardly and clearly. It should also discourage nondeterminism, just as a mathematical notation avoids ambiguity. The programming notation used in the PCN system is Program Composition Notation (PCN).
Reference: [12] <author> Wright, S., </author> <title> Stable parallel algorithms for two point boundary value problems, </title> <type> Preprint MCS-P178-0990, </type> <institution> Argonne National Laboratory, and SIAM J. Sci. Statist. Comput., </institution> <note> 1992 (in press). 23 </note>
Reference-contexts: Tree Structures. Tree and butterfly structures are used in many codes to perform parallel reductions. A good example of a code based entirely on a tree structure is one developed by Wright to solve two-point boundary value problems <ref> [12] </ref> (700 lines Fortran, 50 lines PCN). This algorithm dynamically creates a process tree; data is produced at the leaves, flows up the tree to the root (being reduced at each node) and then back down to the leaves to yield the final solution [6].
References-found: 12

