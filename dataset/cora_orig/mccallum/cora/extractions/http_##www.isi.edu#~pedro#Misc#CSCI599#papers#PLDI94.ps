URL: http://www.isi.edu/~pedro/Misc/CSCI599/papers/PLDI94.ps
Refering-URL: http://www.isi.edu/~pedro/Misc/CSCI599/papers/presentations.html
Root-URL: http://www.isi.edu
Title: A General Data Dependence Test for Dynamic, Pointer-Based Data Structures  
Author: Joseph Hummel Laurie J. Hendren Alexandru Nicolau 
Address: Irvine  
Affiliation: U. of California, Irvine  McGill University  U. of California,  
Abstract: In this paper we present a new technique for performing more accurate data dependence testing in the presence of dynamic, pointer-based data structures. We will demonstrate its effectiveness by breaking false dependences that existing approaches cannot, and provide results which show that removing these dependences enables significant parallelization of a real application. 
Abstract-found: 1
Intro-found: 1
Reference: [App85] <author> Andrew W. Appel. </author> <title> An efficient program for many-body simulation. </title> <journal> SIAM J. Sci. Stat. Comput., </journal> <volume> 6(1) </volume> <pages> 85-103, </pages> <year> 1985. </year>
Reference-contexts: Firstly, there is an increasing use of languages which support pointers, in particular C, C++, Ada, and FORTRAN90. Secondly, pointers and dynamic data structures are important tools for achieving good performance. For example, octrees are important data structures in computational geometry [Sam90] and N-body simulations <ref> [App85, BH86, WS92] </ref>, as are sparse matrices in circuit simulations [Kun86, SWG91] and many other applications. Existing techniques are either overly conservative in the presence of dynamic data structures, or work well for only a small set of structures (linked-lists and trees).
Reference: [Bak90] <author> H. Baker. </author> <title> Unify and conquer (garbage, updating, aliasing, </title> ...) <booktitle> in functional languages. In Pro 227 ceedings of the '90 ACM Conference on LISP and Functional Programming, </booktitle> <month> June </month> <year> 1990. </year>
Reference-contexts: Such analysis is useful in many related problems, e.g. reference counting and memory lifetimes <ref> [Hud86, ISY88, RM88, Har89, Bak90, WH92] </ref> as well as memory placement [Har89, HA93]. In particular, Harrison [Har89] performs extensive analysis of dynamically allocated memory; this work has been extended in [HA93].
Reference: [Ban93] <author> U. Banerjee. </author> <title> Loop Transformations for Restructuring Compilers: The Foundations. </title> <publisher> Kluwer, </publisher> <year> 1993. </year>
Reference-contexts: 1 Introduction and Motivation High-performance architectures rely upon powerful optimizing and parallelizing compilers to increase program performance. One of the critical features of such compilers is accurate data dependence analysis [Ken90]. A good deal of work has been done in the area of array analysis (see <ref> [PW86, ZC90, Ban93] </ref> for extensive references), with notable success. However, fl Please direct correspondence to jhummel@ics.uci.edu.
Reference: [BH86] <author> Josh Barnes and Piet Hut. </author> <title> A hierarchical O(NlogN) force-calculation algorithm. </title> <journal> Nature, </journal> <volume> 324 </volume> <pages> 446-449, </pages> <month> 4 December </month> <year> 1986. </year> <title> The code can be obtained from Prof. </title> <institution> Barnes at the University of Hawaii, or from jhummel@ics.uci.edu. </institution>
Reference-contexts: Firstly, there is an increasing use of languages which support pointers, in particular C, C++, Ada, and FORTRAN90. Secondly, pointers and dynamic data structures are important tools for achieving good performance. For example, octrees are important data structures in computational geometry [Sam90] and N-body simulations <ref> [App85, BH86, WS92] </ref>, as are sparse matrices in circuit simulations [Kun86, SWG91] and many other applications. Existing techniques are either overly conservative in the presence of dynamic data structures, or work well for only a small set of structures (linked-lists and trees). <p> Access paths are straightforward to collect, since standard flow analysis techniques map nicely (and accurately) into regular expressions. Various forms of path collection are discussed in [LH88, HN90, Deu92]. 3.3 An Example We consider an example involving leaf-linked trees, a data structure used e.g. in N-body simulations <ref> [BH86] </ref>. In our case we consider binary trees, an instance of which is shown in Figure 3. Also shown in the figure are a set of axioms which we assume hold at the start of our example.
Reference: [CBC93] <author> J. Choi, M. Burke, and P. Carini. </author> <title> Efficient flow-sensitive interprocedural computation of pointer-induced aliases and side-effects. </title> <booktitle> In Proceedings of the ACM 20th Symposium on Principles of Programming Languages, </booktitle> <pages> pages 232-245, </pages> <month> January </month> <year> 1993. </year>
Reference-contexts: Yes / No / Maybe memory refs info about data structure info about Tester Dependence 2.3 Extending Solutions to PTDP There exist numerous approaches to the pointer target dependence problem <ref> [Cou86, HPR89, LMSS91, LR92, CBC93, MLR + 93, EGH94] </ref>, all of which follow a similar analysis and dependence testing framework: the program is analyzed (perhaps interprocedu-rally), and at each program point the set of aliased variables is computed. Dependence testing is then performed by simply intersecting the appropriate sets.
Reference: [Cou86] <author> D. Coutant. </author> <title> Retargetable high-level alias analysis. </title> <booktitle> In Proceedings of the ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 110-118, </pages> <month> January </month> <year> 1986. </year>
Reference-contexts: Yes / No / Maybe memory refs info about data structure info about Tester Dependence 2.3 Extending Solutions to PTDP There exist numerous approaches to the pointer target dependence problem <ref> [Cou86, HPR89, LMSS91, LR92, CBC93, MLR + 93, EGH94] </ref>, all of which follow a similar analysis and dependence testing framework: the program is analyzed (perhaps interprocedu-rally), and at each program point the set of aliased variables is computed. Dependence testing is then performed by simply intersecting the appropriate sets.
Reference: [CWZ90] <author> D.R. Chase, M. Wegman, and F.K. Zadek. </author> <title> Analysis of pointers and structures. </title> <booktitle> In Proceedings of the SIGPLAN `90 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 296-310, </pages> <year> 1990. </year>
Reference-contexts: It should be noted that the conservativeness of such k-limited approaches has been addressed to some degree by the work of Chase et. al. <ref> [CWZ90] </ref>, and later improved upon by Plevyak et. al. [PCK94].
Reference: [DDQ78] <author> P. Denning, J. Dennis, and J. Qualitz. </author> <title> Machines, Languages, and Computation. </title> <publisher> Prentice-Hall, </publisher> <year> 1978. </year>
Reference-contexts: Given two regular expressions R1 and R2, R1 R2 if M 1 " complement (M 2) = ;, where M 1 and M 2 are the DFAs constructed from R1 and R2, respectively. The algorithmic details are discussed in <ref> [HU79, DDQ78] </ref>. However, if only T 1 or T 2 is true, it may still be possible to prove no dependence.
Reference: [Deu92] <author> A. Deutsch. </author> <title> A storeless model of aliasing and its abstractions using finite representations of right-regular equivalence relations. </title> <booktitle> In Proceedings of the IEEE 1992 International Conference on Computer Languages, </booktitle> <pages> pages 2-13, </pages> <month> April </month> <year> 1992. </year>
Reference-contexts: Dependence testing is then performed by simply intersecting the appropriate sets. This scheme works well in PTDP since pointers generally refer to named memory locations|i.e. variables. However, such store-based approaches <ref> [Deu92] </ref> do not extend well to the domain of dynamic, pointer-based data structures, for the simple reason that pointers may now refer to a seemingly infinite number of memory locations, while the dependence test is designed for a fixed number of memory locations. <p> The general idea is to name memory locations by relation to one another, and then test for intersecting relations. Given the potential complexity and number of such relations, the difficulty is designing an accurate dependence test. These approaches are sometimes referred to as storeless approaches <ref> [Deu92] </ref>. Larus et. al. [LH88] presented a technique for naming memory locations using path expressions. <p> This approach is potentially less expensive than that of Larus, yet also precise for trees. However, it fails to present a general dependence test, and does not handle cyclic data structures. The notion of access paths is also used by Deutsch <ref> [Deu92] </ref>. He discusses a method of alias analysis based on a new, potentially more powerful form of data structure analysis. However, a general dependence test is not presented. Finally, Guarna [Gua88] took a different approach and used syntax trees as a naming scheme. <p> Access paths are straightforward to collect, since standard flow analysis techniques map nicely (and accurately) into regular expressions. Various forms of path collection are discussed in <ref> [LH88, HN90, Deu92] </ref>. 3.3 An Example We consider an example involving leaf-linked trees, a data structure used e.g. in N-body simulations [BH86]. In our case we consider binary trees, an instance of which is shown in Figure 3.
Reference: [EGH94] <author> M. Emami, R. Ghiya, and L. Hendren. </author> <title> Context-sensitive interprocedural points-to analysis in the presence of function pointers. </title> <booktitle> In Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation, </booktitle> <month> June </month> <year> 1994. </year>
Reference-contexts: Yes / No / Maybe memory refs info about data structure info about Tester Dependence 2.3 Extending Solutions to PTDP There exist numerous approaches to the pointer target dependence problem <ref> [Cou86, HPR89, LMSS91, LR92, CBC93, MLR + 93, EGH94] </ref>, all of which follow a similar analysis and dependence testing framework: the program is analyzed (perhaps interprocedu-rally), and at each program point the set of aliased variables is computed. Dependence testing is then performed by simply intersecting the appropriate sets.
Reference: [Gua88] <author> Vincent A. Guarna Jr. </author> <title> A technique for analyzing pointer and structure references in parallel restructuring compilers. </title> <booktitle> In Proceedings of the International Conference on Parallel Processing, </booktitle> <volume> volume 2, </volume> <pages> pages 212-220, </pages> <year> 1988. </year>
Reference-contexts: The notion of access paths is also used by Deutsch [Deu92]. He discusses a method of alias analysis based on a new, potentially more powerful form of data structure analysis. However, a general dependence test is not presented. Finally, Guarna <ref> [Gua88] </ref> took a different approach and used syntax trees as a naming scheme. These trees are then intersected to detect dependences.
Reference: [HA93] <author> W. Ludwell Harrison III and Z. Ammarguellat. </author> <title> A program's eye view of Miprac. </title> <editor> In U. Baner-jee, D. Gelernter, A. Nicolau, and D. Padua, editors, </editor> <booktitle> Fifth International Workshop on Languages and Compilers for Parallel Computing, volume 757 of Lecture Notes in Computer Science, </booktitle> <pages> pages 512-537. </pages> <publisher> Springer-Verlag, </publisher> <year> 1993. </year>
Reference-contexts: Such analysis is useful in many related problems, e.g. reference counting and memory lifetimes [Hud86, ISY88, RM88, Har89, Bak90, WH92] as well as memory placement <ref> [Har89, HA93] </ref>. In particular, Harrison [Har89] performs extensive analysis of dynamically allocated memory; this work has been extended in [HA93]. From this analysis it is possible to discover various properties of a data structure (e.g. its treeness), and thus prove that certain dependences are not possible. <p> Such analysis is useful in many related problems, e.g. reference counting and memory lifetimes [Hud86, ISY88, RM88, Har89, Bak90, WH92] as well as memory placement [Har89, HA93]. In particular, Harrison [Har89] performs extensive analysis of dynamically allocated memory; this work has been extended in <ref> [HA93] </ref>. From this analysis it is possible to discover various properties of a data structure (e.g. its treeness), and thus prove that certain dependences are not possible. However, a general technique of dependence testing which exploits this information is not presented.
Reference: [Har89] <author> W. Ludwell Harrison III. </author> <title> The interprocedu-ral analysis and automatic parallelization of Scheme programs. </title> <journal> Lisp and Symbolic Computation, </journal> 2(3/4):179-396, 1989. 
Reference-contexts: Such analysis is useful in many related problems, e.g. reference counting and memory lifetimes <ref> [Hud86, ISY88, RM88, Har89, Bak90, WH92] </ref> as well as memory placement [Har89, HA93]. In particular, Harrison [Har89] performs extensive analysis of dynamically allocated memory; this work has been extended in [HA93]. <p> Such analysis is useful in many related problems, e.g. reference counting and memory lifetimes [Hud86, ISY88, RM88, Har89, Bak90, WH92] as well as memory placement <ref> [Har89, HA93] </ref>. In particular, Harrison [Har89] performs extensive analysis of dynamically allocated memory; this work has been extended in [HA93]. From this analysis it is possible to discover various properties of a data structure (e.g. its treeness), and thus prove that certain dependences are not possible. <p> Such analysis is useful in many related problems, e.g. reference counting and memory lifetimes [Hud86, ISY88, RM88, Har89, Bak90, WH92] as well as memory placement [Har89, HA93]. In particular, Harrison <ref> [Har89] </ref> performs extensive analysis of dynamically allocated memory; this work has been extended in [HA93]. From this analysis it is possible to discover various properties of a data structure (e.g. its treeness), and thus prove that certain dependences are not possible.
Reference: [HDE + 93] <author> L. Hendren, C. Donawa, M. Emami, G. Gao, Justiani, and B. Sridharan. </author> <title> Designing the Mc-CAT compiler based on a family of structured intermediate representations. </title> <editor> In U. Banerjee, D. Gelernter, A. Nicolau, and D. Padua, editors, </editor> <booktitle> Fifth International Workshop on Languages and Compilers for Parallel Computing, volume 757 of Lecture Notes in Computer Science, </booktitle> <pages> pages 406-420. </pages> <publisher> Springer-Verlag, </publisher> <year> 1993. </year>
Reference-contexts: We assume the existence of two statement executions S and T , where S precedes T and each accesses a single field relative to some pointer (we assume that expressions involving multiple fields have already been simplified into this format <ref> [HDE + 93] </ref>): S: . . . p-&gt;f . . . ; T : . . . q-&gt;g . . . ; Furthermore, either S performs a write to p-&gt;f, T performs a write to q-&gt;g, or both, with no intervening write to the memory location denoted by p-&gt;f .
Reference: [HHN92] <author> L. Hendren, J. Hummel, and A. Nicolau. </author> <title> Abstractions for recursive pointer data structures: Improving the analysis and transformation of imperative programs. </title> <booktitle> In Proceedings of the SIG-PLAN '92 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 249-260, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: Axioms can be collected automatically (using many of the techniques discussed in Section 2), or supplied by the programmer (and perhaps automatically verified). In the latter case, note that axioms can be specified indirectly using a higher level of abstraction, e.g. the ADDS data structure description language <ref> [HHN92] </ref> or graph types [KS93]. Access paths are straightforward to collect, since standard flow analysis techniques map nicely (and accurately) into regular expressions.
Reference: [HHN94] <author> J. Hummel, L. Hendren, and A. Nicolau. </author> <title> A language for conveying the aliasing properties of dynamic, pointer-based data structures. </title> <booktitle> In Proceedings of the 8th International Parallel Processing Symposium, </booktitle> <month> April </month> <year> 1994. </year>
Reference-contexts: Though exceedingly simple in nature, a set of aliasing axioms is able to describe quite complicated data structures, such as sparse matrices (see Section 5) and two-dimensional range trees (a leaf-linked tree of leaf-linked trees, used in computational geometry [PS85]). See <ref> [HHN94] </ref> for a more complete discussion. 3.2 Supporting Framework As pictured in Figure 2 (and discussed in Section 2.2), an accurate dependence test for PDSDP requires two types of information: information about the data structure, and information about the referenced memory locations.
Reference: [HN90] <author> Laurie J. Hendren and Alexandru Nicolau. </author> <title> Par-allelizing programs with recursive data structures. </title> <journal> IEEE Trans. on Parallel and Distributed Computing, </journal> <volume> 1(1) </volume> <pages> 35-47, </pages> <month> January </month> <year> 1990. </year>
Reference-contexts: It should be noted that more accurate mapping strategies may in fact exist; Larus et. al. did not address this (we explored the idea, but found our solutions to be inadequate). Hendren et. al. <ref> [HN90] </ref> discussed a similar technique for naming memory locations, in this case using a simpler form of paths. Paths are collected in a path matrix such that all paths between memory locations of interest are known. <p> Access paths are straightforward to collect, since standard flow analysis techniques map nicely (and accurately) into regular expressions. Various forms of path collection are discussed in <ref> [LH88, HN90, Deu92] </ref>. 3.3 An Example We consider an example involving leaf-linked trees, a data structure used e.g. in N-body simulations [BH86]. In our case we consider binary trees, an instance of which is shown in Figure 3.
Reference: [HPR89] <author> Susan Horwitz, Phil Pfeiffer, and Thomas Reps. </author> <title> Dependence analysis for pointer variables. </title> <booktitle> In Proceedings of the SIGPLAN '89 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 28-40, </pages> <month> June </month> <year> 1989. </year>
Reference-contexts: Yes / No / Maybe memory refs info about data structure info about Tester Dependence 2.3 Extending Solutions to PTDP There exist numerous approaches to the pointer target dependence problem <ref> [Cou86, HPR89, LMSS91, LR92, CBC93, MLR + 93, EGH94] </ref>, all of which follow a similar analysis and dependence testing framework: the program is analyzed (perhaps interprocedu-rally), and at each program point the set of aliased variables is computed. Dependence testing is then performed by simply intersecting the appropriate sets.
Reference: [HU79] <author> J. Hopcroft and J. Ullman. </author> <title> Introduction to Automata Theory, Languages, and Computation. </title> <publisher> Addison-Wesley, </publisher> <year> 1979. </year>
Reference-contexts: Given two regular expressions R1 and R2, R1 R2 if M 1 " complement (M 2) = ;, where M 1 and M 2 are the DFAs constructed from R1 and R2, respectively. The algorithmic details are discussed in <ref> [HU79, DDQ78] </ref>. However, if only T 1 or T 2 is true, it may still be possible to prove no dependence.
Reference: [Hud86] <author> P. Hudak. </author> <title> A semantic model of reference counting and its abstraction. </title> <booktitle> In Proceedings of the 1986 ACM Conference on LISP and Functional Programming, </booktitle> <year> 1986. </year>
Reference-contexts: Such analysis is useful in many related problems, e.g. reference counting and memory lifetimes <ref> [Hud86, ISY88, RM88, Har89, Bak90, WH92] </ref> as well as memory placement [Har89, HA93]. In particular, Harrison [Har89] performs extensive analysis of dynamically allocated memory; this work has been extended in [HA93].
Reference: [ISY88] <author> K. Inoue, H. Seki, and H. Yagi. </author> <title> Analysis of functional programs to detect run-time garbage cells. </title> <journal> ACM TOPLAS, </journal> <volume> 10(4) </volume> <pages> 555-578, </pages> <month> October </month> <year> 1988. </year>
Reference-contexts: Such analysis is useful in many related problems, e.g. reference counting and memory lifetimes <ref> [Hud86, ISY88, RM88, Har89, Bak90, WH92] </ref> as well as memory placement [Har89, HA93]. In particular, Harrison [Har89] performs extensive analysis of dynamically allocated memory; this work has been extended in [HA93].
Reference: [JM82] <author> N. D. Jones and S. Muchnick. </author> <title> A flexible approach to interprocedural data flow analysis and programs with recursive data structures. </title> <booktitle> In 9th ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 66-74, </pages> <year> 1982. </year>
Reference-contexts: The typical solution is to retain the dependence test from PTDP, and adopt a k-limited data structure analysis <ref> [JM82] </ref>. Given a set of dynamically-allocated memory locations, this has the effect of assigning k unique names to the first k memory locations, and a single summary name to all remaining memory locations. This quickly becomes overly conservative|consider a loop, for example.
Reference: [Ken90] <author> K. Kennedy. </author> <title> Foreword of Supercompilers for Parallel and Vector Computers, 1990. The text is written by Hans Zima with Barbara Chap-man, </title> <note> available from the ACM Press. </note>
Reference-contexts: 1 Introduction and Motivation High-performance architectures rely upon powerful optimizing and parallelizing compilers to increase program performance. One of the critical features of such compilers is accurate data dependence analysis <ref> [Ken90] </ref>. A good deal of work has been done in the area of array analysis (see [PW86, ZC90, Ban93] for extensive references), with notable success. However, fl Please direct correspondence to jhummel@ics.uci.edu.
Reference: [KKK90] <author> David Klappholz, Apostolos D. Kallis, and Xi-angyun Kang. </author> <title> Refined C: An update. </title> <editor> In David Gelernter, Alexandru Nicolau, and David Padua, editors, </editor> <booktitle> Languages and Compilers for Parallel Computing, </booktitle> <pages> pages 331-357. </pages> <publisher> The MIT Press, </publisher> <year> 1990. </year>
Reference-contexts: The effect system [LG88] is a language-based approach in which the effect of a statement must be explicitly associated with a region of memory; this enables the compiler e.g. to perform coarse-grain dependence testing. Klappholz et. al. <ref> [KKK90] </ref> discuss another language-based approach in which dependence testing relies upon programmer-supplied partition statements and software tagging. 3 Overview of Our Approach Our approach is most similar to that of Larus et. al. [LH88], since we also base our naming scheme on regular expressions.
Reference: [KS93] <author> N. Klarlund and M. Schwartzbach. </author> <title> Graph types. </title> <booktitle> In Proceedings of the ACM 20th Symposium on Principles of Programming Languages, </booktitle> <pages> pages 196-205, </pages> <month> January </month> <year> 1993. </year>
Reference-contexts: In the latter case, note that axioms can be specified indirectly using a higher level of abstraction, e.g. the ADDS data structure description language [HHN92] or graph types <ref> [KS93] </ref>. Access paths are straightforward to collect, since standard flow analysis techniques map nicely (and accurately) into regular expressions. Various forms of path collection are discussed in [LH88, HN90, Deu92]. 3.3 An Example We consider an example involving leaf-linked trees, a data structure used e.g. in N-body simulations [BH86].
Reference: [Kun86] <author> K. Kundert. </author> <title> Sparse matrix techniques. </title> <editor> In A. Ruehli, editor, </editor> <title> Circuit Analysis, </title> <booktitle> Simulation and Design, </booktitle> <pages> pages 281-324. </pages> <publisher> Elsevier Science Publishers B.V. (North-Holland), </publisher> <pages> 186. </pages>
Reference-contexts: Secondly, pointers and dynamic data structures are important tools for achieving good performance. For example, octrees are important data structures in computational geometry [Sam90] and N-body simulations [App85, BH86, WS92], as are sparse matrices in circuit simulations <ref> [Kun86, SWG91] </ref> and many other applications. Existing techniques are either overly conservative in the presence of dynamic data structures, or work well for only a small set of structures (linked-lists and trees). <p> This may even be user controllable, e.g. via a compiler option. 5 Results To demonstrate the effectiveness of our dependence test, a prototype was implemented and applied in a realistic situation|sparse matrices as used e.g. in circuit simulations <ref> [Kun86] </ref>. Sparse matrices are often implemented using orthogonal lists [Sta80], an example of which is shown in fundamental operations performed on sparse matrices are scaling, factoring, and solving; in terms of execution time, scaling and solving are linear in the size of the data structure, whereas factoring is quadratic.
Reference: [Lan92] <author> W. Landi. </author> <title> Undecidability of static analysis. </title> <journal> ACM Letters on Programming Languages and Systems, </journal> <volume> 1(4), </volume> <month> December </month> <year> 1992. </year>
Reference-contexts: However, in the worst case, each intermediate proof may in turn involve kleene star components. This has a multiplicative 3 Note that the problem of static analysis in the presence of pointers has been shown to be undecidable <ref> [Lan92] </ref>. In relation to our work, this undecidability result corresponds to the problem of performing accurate data structure and memory reference analysis (see Figure 2). 225 effect, resulting in a proof with a worst-case exponen-tial time complexity of O (c n ).
Reference: [LG88] <author> J. M. Lucassen and D. K. Gifford. </author> <title> Polymorphic effect systems. </title> <booktitle> In Proceedings 15th ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 47-57, </pages> <year> 1988. </year> <month> 228 </month>
Reference-contexts: However, a general technique of dependence testing which exploits this information is not presented. Neirynck et. al. [NPD89] developed an abstract interpretation approach capable of coarse-grain dependence testing on higher-order applicative programs. The effect system <ref> [LG88] </ref> is a language-based approach in which the effect of a statement must be explicitly associated with a region of memory; this enables the compiler e.g. to perform coarse-grain dependence testing.
Reference: [LH88] <author> James R. Larus and Paul N. Hilfinger. </author> <title> De--tecting conflicts between structure accesses. </title> <booktitle> In Proceedings of the SIGPLAN '88 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 21-34, </pages> <month> June </month> <year> 1988. </year>
Reference-contexts: The general idea is to name memory locations by relation to one another, and then test for intersecting relations. Given the potential complexity and number of such relations, the difficulty is designing an accurate dependence test. These approaches are sometimes referred to as storeless approaches [Deu92]. Larus et. al. <ref> [LH88] </ref> presented a technique for naming memory locations using path expressions. <p> Klappholz et. al. [KKK90] discuss another language-based approach in which dependence testing relies upon programmer-supplied partition statements and software tagging. 3 Overview of Our Approach Our approach is most similar to that of Larus et. al. <ref> [LH88] </ref>, since we also base our naming scheme on regular expressions. <p> Access paths are straightforward to collect, since standard flow analysis techniques map nicely (and accurately) into regular expressions. Various forms of path collection are discussed in <ref> [LH88, HN90, Deu92] </ref>. 3.3 An Example We consider an example involving leaf-linked trees, a data structure used e.g. in N-body simulations [BH86]. In our case we consider binary trees, an instance of which is shown in Figure 3. <p> Note that an APM does not summarize all possible paths between vertices in a data structure, only paths explicitly traversed by the program. The key observation is that whenever possible, access paths should be collected in reference to fixed vertices in the data structure (Larus et. al. <ref> [LH88] </ref> collected access paths in this manner). We will refer to these vertices as handles. Handles are associated with pointer variables, and a new handle hp is created each time its associated pointer variable p is assigned to.
Reference: [LMSS91] <author> J. Loeliger, R. Metzger, M. Seligman, and S. Stroud. </author> <title> Pointer target tracking an empirical study. </title> <booktitle> In Proceedings of Supercomputing '91, </booktitle> <pages> pages 14-23, </pages> <month> November </month> <year> 1991. </year>
Reference-contexts: Yes / No / Maybe memory refs info about data structure info about Tester Dependence 2.3 Extending Solutions to PTDP There exist numerous approaches to the pointer target dependence problem <ref> [Cou86, HPR89, LMSS91, LR92, CBC93, MLR + 93, EGH94] </ref>, all of which follow a similar analysis and dependence testing framework: the program is analyzed (perhaps interprocedu-rally), and at each program point the set of aliased variables is computed. Dependence testing is then performed by simply intersecting the appropriate sets.
Reference: [LR92] <author> W. Landi and B. Ryder. </author> <title> A safe approximation algorithm for interprocedural pointer aliasing. </title> <booktitle> In Proceedings of the SIGPLAN '92 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 235-248, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: Yes / No / Maybe memory refs info about data structure info about Tester Dependence 2.3 Extending Solutions to PTDP There exist numerous approaches to the pointer target dependence problem <ref> [Cou86, HPR89, LMSS91, LR92, CBC93, MLR + 93, EGH94] </ref>, all of which follow a similar analysis and dependence testing framework: the program is analyzed (perhaps interprocedu-rally), and at each program point the set of aliased variables is computed. Dependence testing is then performed by simply intersecting the appropriate sets.
Reference: [MLR + 93] <author> T. Marlowe, W. Landi, B. Ryder, J. Choi, M. Burke, and P. Carini. </author> <title> Pointer-induced aliasing: A clarification. </title> <journal> ACM SIGPLAN Notices, </journal> <volume> 28(9) </volume> <pages> 67-70, </pages> <month> September </month> <year> 1993. </year>
Reference-contexts: Yes / No / Maybe memory refs info about data structure info about Tester Dependence 2.3 Extending Solutions to PTDP There exist numerous approaches to the pointer target dependence problem <ref> [Cou86, HPR89, LMSS91, LR92, CBC93, MLR + 93, EGH94] </ref>, all of which follow a similar analysis and dependence testing framework: the program is analyzed (perhaps interprocedu-rally), and at each program point the set of aliased variables is computed. Dependence testing is then performed by simply intersecting the appropriate sets.
Reference: [NPD89] <author> A. Neirynck, P. Panangaden, and A. J. De-mers. </author> <title> Effect analysis in higher-order languages. </title> <journal> International Journal of Parallel Programming, </journal> <volume> 18(1) </volume> <pages> 1-37, </pages> <year> 1989. </year>
Reference-contexts: From this analysis it is possible to discover various properties of a data structure (e.g. its treeness), and thus prove that certain dependences are not possible. However, a general technique of dependence testing which exploits this information is not presented. Neirynck et. al. <ref> [NPD89] </ref> developed an abstract interpretation approach capable of coarse-grain dependence testing on higher-order applicative programs. The effect system [LG88] is a language-based approach in which the effect of a statement must be explicitly associated with a region of memory; this enables the compiler e.g. to perform coarse-grain dependence testing.
Reference: [PCK94] <author> J. Plevyak, A. Chien, and V. Karamcheti. </author> <title> Analysis of dynamic structures for efficient parallel execution. </title> <editor> In U. Banerjee, D. Gelernter, A. Nicolau, and D. Padua, editors, </editor> <booktitle> Sixth International Workshop on Languages and Compilers for Parallel Computing, volume 768 of Lecture Notes in Computer Science, </booktitle> <pages> pages 37-56. </pages> <publisher> Springer-Verlag, </publisher> <year> 1994. </year>
Reference-contexts: It should be noted that the conservativeness of such k-limited approaches has been addressed to some degree by the work of Chase et. al. [CWZ90], and later improved upon by Plevyak et. al. <ref> [PCK94] </ref>.
Reference: [PS85] <author> F. Preparata and M. Shamos. </author> <title> Computational Geometry: An Introdution. </title> <publisher> Springer-Verlag, </publisher> <year> 1985. </year>
Reference-contexts: Though exceedingly simple in nature, a set of aliasing axioms is able to describe quite complicated data structures, such as sparse matrices (see Section 5) and two-dimensional range trees (a leaf-linked tree of leaf-linked trees, used in computational geometry <ref> [PS85] </ref>). See [HHN94] for a more complete discussion. 3.2 Supporting Framework As pictured in Figure 2 (and discussed in Section 2.2), an accurate dependence test for PDSDP requires two types of information: information about the data structure, and information about the referenced memory locations.
Reference: [PW86] <author> David A. Padua and Michael J. Wolfe. </author> <title> Advanced compiler optimization for supercomputers. </title> <journal> Communications of the ACM, </journal> <volume> 29(12), </volume> <month> De-cember </month> <year> 1986. </year>
Reference-contexts: 1 Introduction and Motivation High-performance architectures rely upon powerful optimizing and parallelizing compilers to increase program performance. One of the critical features of such compilers is accurate data dependence analysis [Ken90]. A good deal of work has been done in the area of array analysis (see <ref> [PW86, ZC90, Ban93] </ref> for extensive references), with notable success. However, fl Please direct correspondence to jhummel@ics.uci.edu.
Reference: [RM88] <author> C. Ruggieri and T. P. Murtagh. </author> <title> Lifetime analysis of dynamically allocated objects. </title> <booktitle> In Proceedings of the 15th ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 285-293, </pages> <year> 1988. </year>
Reference-contexts: Such analysis is useful in many related problems, e.g. reference counting and memory lifetimes <ref> [Hud86, ISY88, RM88, Har89, Bak90, WH92] </ref> as well as memory placement [Har89, HA93]. In particular, Harrison [Har89] performs extensive analysis of dynamically allocated memory; this work has been extended in [HA93].
Reference: [Sam90] <author> Hanan Samet. </author> <title> Applications of Spatial Data Structures: Computer Graphics, Image Processing, and GIS. </title> <publisher> Addison-Wesley, </publisher> <year> 1990. </year>
Reference-contexts: Firstly, there is an increasing use of languages which support pointers, in particular C, C++, Ada, and FORTRAN90. Secondly, pointers and dynamic data structures are important tools for achieving good performance. For example, octrees are important data structures in computational geometry <ref> [Sam90] </ref> and N-body simulations [App85, BH86, WS92], as are sparse matrices in circuit simulations [Kun86, SWG91] and many other applications. Existing techniques are either overly conservative in the presence of dynamic data structures, or work well for only a small set of structures (linked-lists and trees).
Reference: [Sta80] <author> Thomas A. Standish. </author> <title> Data Structure Techniques. </title> <publisher> Addison-Wesley, </publisher> <year> 1980. </year>
Reference-contexts: This may even be user controllable, e.g. via a compiler option. 5 Results To demonstrate the effectiveness of our dependence test, a prototype was implemented and applied in a realistic situation|sparse matrices as used e.g. in circuit simulations [Kun86]. Sparse matrices are often implemented using orthogonal lists <ref> [Sta80] </ref>, an example of which is shown in fundamental operations performed on sparse matrices are scaling, factoring, and solving; in terms of execution time, scaling and solving are linear in the size of the data structure, whereas factoring is quadratic. We shall focus on factorization here.
Reference: [SWG91] <author> J. Singh, W. Weber, and A. Gupta. </author> <title> SPLASH: Stanford parallel applications for shared-memory. </title> <type> Technical Report CSL-TR-91-469, </type> <institution> Stanford University, </institution> <year> 1991. </year> <note> FTP to mo-jave.stanford.edu. </note>
Reference-contexts: Secondly, pointers and dynamic data structures are important tools for achieving good performance. For example, octrees are important data structures in computational geometry [Sam90] and N-body simulations [App85, BH86, WS92], as are sparse matrices in circuit simulations <ref> [Kun86, SWG91] </ref> and many other applications. Existing techniques are either overly conservative in the presence of dynamic data structures, or work well for only a small set of structures (linked-lists and trees).
Reference: [WH92] <author> E. Wang and P. Hilfinger. </author> <title> Analysis of recursive types in LISP-like languages. </title> <booktitle> In Proceedings of the '92 ACM Conference on LISP and Functional Programming, </booktitle> <pages> pages 216-225, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: Such analysis is useful in many related problems, e.g. reference counting and memory lifetimes <ref> [Hud86, ISY88, RM88, Har89, Bak90, WH92] </ref> as well as memory placement [Har89, HA93]. In particular, Harrison [Har89] performs extensive analysis of dynamically allocated memory; this work has been extended in [HA93].
Reference: [WS92] <author> M. Warren and J. Salmon. </author> <title> Astrophysical n-body simulations using hierarchical tree data structures. </title> <booktitle> In Proceedings of Supercomputing 1992, </booktitle> <pages> pages 570-576, </pages> <month> November </month> <year> 1992. </year>
Reference-contexts: Firstly, there is an increasing use of languages which support pointers, in particular C, C++, Ada, and FORTRAN90. Secondly, pointers and dynamic data structures are important tools for achieving good performance. For example, octrees are important data structures in computational geometry [Sam90] and N-body simulations <ref> [App85, BH86, WS92] </ref>, as are sparse matrices in circuit simulations [Kun86, SWG91] and many other applications. Existing techniques are either overly conservative in the presence of dynamic data structures, or work well for only a small set of structures (linked-lists and trees).
Reference: [ZC90] <author> Hans Zima and Barbara Chapman. </author> <title> Supercom-pilers for Parallel and Vector Computers. </title> <publisher> ACM Press, </publisher> <year> 1990. </year>
Reference-contexts: 1 Introduction and Motivation High-performance architectures rely upon powerful optimizing and parallelizing compilers to increase program performance. One of the critical features of such compilers is accurate data dependence analysis [Ken90]. A good deal of work has been done in the area of array analysis (see <ref> [PW86, ZC90, Ban93] </ref> for extensive references), with notable success. However, fl Please direct correspondence to jhummel@ics.uci.edu.
References-found: 43

