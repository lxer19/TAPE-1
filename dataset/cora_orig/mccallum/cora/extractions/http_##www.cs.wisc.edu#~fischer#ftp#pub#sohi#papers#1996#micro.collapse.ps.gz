URL: http://www.cs.wisc.edu/~fischer/ftp/pub/sohi/papers/1996/micro.collapse.ps.gz
Refering-URL: http://www.cs.wisc.edu/~fischer/ftp/pub/sohi/papers/1996/
Root-URL: http://www.cs.wisc.edu
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> T. M. Austin and G. S. Sohi. </author> <title> Dynamic dependency analysis of ordinary programs. </title> <booktitle> In Proceedings of the 19th International Symposium on Computer Architecture, </booktitle> <pages> pages 342-351, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: Functionality for the collapsing of multiple operations has been advanced in a number of proposals for floating point and fixed point instructions [14, 16, 19]. The performance limit studies published in the literature <ref> [1, 3, 6, 7, 20] </ref> are primarily based on the assumption that true dependence paths through the dynamic dependence graph place a limit on performance. <p> A device that includes the majority of the functions a collapsing fixed point unit can perform, was proposed in [17]. Several studies have examined the limits of instruction level parallelism with a variety of control and resource models <ref> [1, 3, 6, 7, 20] </ref>. However, no limit study has examined the impact of data dependence collapsing and speculation on instruction parallelism.
Reference: [2] <author> T. M. Austin and G. S. Sohi. </author> <title> Zero-cycle loads: Microar-chitecture support for reducing load latency. </title> <booktitle> In Proceedings of the 28th Annual ACM/IEEE International Symposium and Workshop on Microarchitecture, </booktitle> <pages> pages 82-92, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: Section 4 addresses the experimental framework and assumptions. Section 5 contains the discussion of the obtained results. Section 6 will conclude the study. 2. Related Work Several schemes for reducing the effects of execution and memory dependences have been proposed <ref> [2, 5, 9, 19] </ref>. These techniques are claimed to have minimal or no impact on the clock cycle. Mechanisms for remedying the effects of memory dependences using early memory loads were introduced in [2, 5]. In [5] the combination of three strategies is proposed. <p> Related Work Several schemes for reducing the effects of execution and memory dependences have been proposed [2, 5, 9, 19]. These techniques are claimed to have minimal or no impact on the clock cycle. Mechanisms for remedying the effects of memory dependences using early memory loads were introduced in <ref> [2, 5] </ref>. In [5] the combination of three strategies is proposed. The first identifies data dependences required for address generation that can be resolved immediately. <p> This approach allows the processor to execute load instructions in parallel with instructions preceding the loads, achieving a zero cycle load execution time when the speculation is found to be correct. Austin <ref> [2] </ref> exploits the fact that small offsets are suitable for simple fast address calculation and determines memory addresses early in the pipeline for those cases. This enables the load instructions to issue early and effectively hide the load-use latency.
Reference: [3] <author> M. Butler, T.-Y. Yeh, Y. N. Patt, M. Alsup, H. Scales, and M. Shebanow. </author> <title> Single instruction stream parallelism is greater than two. </title> <booktitle> In Proceedings of the 18th International Symposium on Computer Architecture, </booktitle> <month> May </month> <year> 1991. </year>
Reference-contexts: Functionality for the collapsing of multiple operations has been advanced in a number of proposals for floating point and fixed point instructions [14, 16, 19]. The performance limit studies published in the literature <ref> [1, 3, 6, 7, 20] </ref> are primarily based on the assumption that true dependence paths through the dynamic dependence graph place a limit on performance. <p> A device that includes the majority of the functions a collapsing fixed point unit can perform, was proposed in [17]. Several studies have examined the limits of instruction level parallelism with a variety of control and resource models <ref> [1, 3, 6, 7, 20] </ref>. However, no limit study has examined the impact of data dependence collapsing and speculation on instruction parallelism.
Reference: [4] <author> T. F. Chen and J. L. Baer. </author> <title> Effective hardware-based data prefetching for high performance processors. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 44(5) </volume> <pages> 609-623, </pages> <month> May </month> <year> 1995. </year>
Reference-contexts: A different approach that predicts data values instead of addresses has been proposed in [9] for invariant data values loaded from memory. Numerous other schemes for prefetching data in the memory hierarchy have been proposed for further references see <ref> [4, 12] </ref>. Prefetching schemes do not consider the possibility of speculative instruction execution us ing predicted addresses. The address prediction techniques used for prefetching can be applicable for prediction in d-speculation, however. Data dependence collapsing functionality has been advanced in a number of proposals.
Reference: [5] <author> R. J. Eickemeyer and S. Vassiliadis. </author> <title> A load instruction unit for pipelined processors. </title> <journal> IBM Journal of Research and Development, </journal> <volume> 37(4) </volume> <pages> 547-564, </pages> <month> July </month> <year> 1993. </year>
Reference-contexts: This technique has been used for branches (control dependences) for some time, but has also been proposed for memory addresses <ref> [5] </ref> and for data loaded from memory [9]. * The second method can reduce the latency by combin-ing a dependence among multiple dependent instructions into a single instruction. <p> Section 4 addresses the experimental framework and assumptions. Section 5 contains the discussion of the obtained results. Section 6 will conclude the study. 2. Related Work Several schemes for reducing the effects of execution and memory dependences have been proposed <ref> [2, 5, 9, 19] </ref>. These techniques are claimed to have minimal or no impact on the clock cycle. Mechanisms for remedying the effects of memory dependences using early memory loads were introduced in [2, 5]. In [5] the combination of three strategies is proposed. <p> Related Work Several schemes for reducing the effects of execution and memory dependences have been proposed [2, 5, 9, 19]. These techniques are claimed to have minimal or no impact on the clock cycle. Mechanisms for remedying the effects of memory dependences using early memory loads were introduced in <ref> [2, 5] </ref>. In [5] the combination of three strategies is proposed. The first identifies data dependences required for address generation that can be resolved immediately. <p> These techniques are claimed to have minimal or no impact on the clock cycle. Mechanisms for remedying the effects of memory dependences using early memory loads were introduced in [2, 5]. In <ref> [5] </ref> the combination of three strategies is proposed. The first identifies data dependences required for address generation that can be resolved immediately. The second is used for the case in which dependences can not be resolved immediately; it predicts the address using a table where memory access patterns are stored. <p> The table we consider is a 4096 entry direct mapped table. The 14 least significant bits of a load instruction address is the index into the table. The algorithm used for prediction and the table entry information is identical to the two delta strategy in <ref> [5] </ref> 1 . The delta size in our table is 32 bits. To the previously proposed table, we add a 2 bit saturating counter for each table entry to represent the confidence in issuing a load with a predicted address. <p> When the correct address becomes available and a misprediction 1 Note that the load speculation mechanism uses a subset of the mechanisms presented in <ref> [5] </ref>. is detected, only the instructions dependent on the load are affected. In the simulator, these instructions can not issue before the cycle that the load with the correct address completes execution. No restriction on the number of loads that can be load-speculated is imposed.
Reference: [6] <author> N. P. Jouppi and D. Wall. </author> <title> Available instruction-level parallelism for superscalar and superpipelined machines. </title> <booktitle> In Proceedings of the 3rd International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <month> April </month> <year> 1989. </year>
Reference-contexts: Functionality for the collapsing of multiple operations has been advanced in a number of proposals for floating point and fixed point instructions [14, 16, 19]. The performance limit studies published in the literature <ref> [1, 3, 6, 7, 20] </ref> are primarily based on the assumption that true dependence paths through the dynamic dependence graph place a limit on performance. <p> A device that includes the majority of the functions a collapsing fixed point unit can perform, was proposed in [17]. Several studies have examined the limits of instruction level parallelism with a variety of control and resource models <ref> [1, 3, 6, 7, 20] </ref>. However, no limit study has examined the impact of data dependence collapsing and speculation on instruction parallelism.
Reference: [7] <author> M. S. Lam and R. P. Wilson. </author> <title> Limits of control flow on parallelism. </title> <booktitle> In Proceedings of the 19th International Symposium on Computer Architecture, </booktitle> <pages> pages 46-57, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: Functionality for the collapsing of multiple operations has been advanced in a number of proposals for floating point and fixed point instructions [14, 16, 19]. The performance limit studies published in the literature <ref> [1, 3, 6, 7, 20] </ref> are primarily based on the assumption that true dependence paths through the dynamic dependence graph place a limit on performance. <p> A device that includes the majority of the functions a collapsing fixed point unit can perform, was proposed in [17]. Several studies have examined the limits of instruction level parallelism with a variety of control and resource models <ref> [1, 3, 6, 7, 20] </ref>. However, no limit study has examined the impact of data dependence collapsing and speculation on instruction parallelism.
Reference: [8] <author> J. R. Larus. </author> <title> Efficient program tracing. </title> <journal> IEEE Computer, </journal> <volume> 26(5) </volume> <pages> 52-61, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: The benchmarks 026.compress, 008.espresso, 0.23 eqntott and 022.li are from the SPECINT92 suite and 099.go and 132.ijpeg are from the SPECINT95 suite. The benchmarks were compiled using the gcc version 2.6.3 at -O4 optimization level (go and ijpeg benchmarks compiled at -O3 optimization). The traces were generated by qpt2 <ref> [8] </ref> and do not include system code. For those benchmarks longer than 250 million instructions, only the first 250 million instructions of each benchmark trace were simulated due to time constraints. Nop operations were ignored and are not included in the simulations.
Reference: [9] <author> M. H. Lipasti, C. B. Wilkerson, and J. P. Shen. </author> <title> Value locality and data speculation. </title> <booktitle> In Proceedings of the 7th International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <month> October </month> <year> 1996. </year>
Reference-contexts: This technique has been used for branches (control dependences) for some time, but has also been proposed for memory addresses [5] and for data loaded from memory <ref> [9] </ref>. * The second method can reduce the latency by combin-ing a dependence among multiple dependent instructions into a single instruction. Functionality for the collapsing of multiple operations has been advanced in a number of proposals for floating point and fixed point instructions [14, 16, 19]. <p> Section 4 addresses the experimental framework and assumptions. Section 5 contains the discussion of the obtained results. Section 6 will conclude the study. 2. Related Work Several schemes for reducing the effects of execution and memory dependences have been proposed <ref> [2, 5, 9, 19] </ref>. These techniques are claimed to have minimal or no impact on the clock cycle. Mechanisms for remedying the effects of memory dependences using early memory loads were introduced in [2, 5]. In [5] the combination of three strategies is proposed. <p> This enables the load instructions to issue early and effectively hide the load-use latency. A different approach that predicts data values instead of addresses has been proposed in <ref> [9] </ref> for invariant data values loaded from memory. Numerous other schemes for prefetching data in the memory hierarchy have been proposed for further references see [4, 12]. Prefetching schemes do not consider the possibility of speculative instruction execution us ing predicted addresses.
Reference: [10] <author> N. Malik, R. J. Eickemeyer, and S. Vassiliadis. </author> <title> Interlock collapsing alu for increased instruction-level parallelism. </title> <booktitle> In Proceedings of the 25th Annual ACM/IEEE International Symposium and Workshop on Microarchitecture, </booktitle> <month> September </month> <year> 1992. </year>
Reference-contexts: The proposed solution takes into account a general CISC instruction set that includes the functionality of RISC and post-RISC based instruction sets. The performance of such a proposal for some realistic machine organizations was reported in <ref> [10] </ref> and a single cycle implementation of a subset of this proposal was implemented in POWER 2 [21]. A device that includes the majority of the functions a collapsing fixed point unit can perform, was proposed in [17]. <p> A related work [15] used static program representation and profiling weights to calculate the frequencies of sequences (pairs, triples and quads) of dependent instructions within and across basic blocks. This work however did not examine the impact on latency/parallelism. In <ref> [10, 18] </ref>, performance studies were conducted to characterize the effects of interlock (dependence) collapsing functionality on parallelism for a variety of resource and control models. The dependence collapsing performed in these studies was restricted to collapsing only consecutive instructions within a single basic block.
Reference: [11] <author> S. McFarling. </author> <title> Combining branch predictors. </title> <note> In DEC WRL TN-36, </note> <month> June </month> <year> 1993. </year>
Reference-contexts: The maximum issue width establishes the maximum attainable instruction level parallelism. For all configurations simulated, conditional branches are predicted using the bi-modalN/gshareN+1 scheme proposed in <ref> [11] </ref> with 8kByte cost. All other branches and jumps (indirect, unconditional, call and return) are assumed to be always predicted correctly. The performance of the predictor is shown in Table 2.
Reference: [12] <author> S. Mehrotra and L. Harrison. </author> <title> Examination of a memory access classification scheme for pointer intensive and numeric programs. </title> <booktitle> In Proceedings of the 10th International Conference on Supercomputing, </booktitle> <month> May </month> <year> 1996. </year>
Reference-contexts: A different approach that predicts data values instead of addresses has been proposed in [9] for invariant data values loaded from memory. Numerous other schemes for prefetching data in the memory hierarchy have been proposed for further references see <ref> [4, 12] </ref>. Prefetching schemes do not consider the possibility of speculative instruction execution us ing predicted addresses. The address prediction techniques used for prefetching can be applicable for prediction in d-speculation, however. Data dependence collapsing functionality has been advanced in a number of proposals. <p> This is understandable because the load-speculation mechanism is based on stride prediction, and it does not perform well with pointer-based codes. Special load units for pointer-based codes have been proposed <ref> [12] </ref>, however, there is no scheme known to us that combines load-speculation mechanisms for both pointer chasing and non pointer chasing codes. It is of interest, therefore, as a future research topic to investigate load-speculation mecha Benchmarks nisms that can provide satisfactory performance for both non-pointer and pointer chasing benchmarks.
Reference: [13] <author> S. </author> <title> MICROSYSTEMS. The SPARC Architecture Manual. </title> <publisher> Prentice Hall, </publisher> <year> 1992. </year>
Reference-contexts: We report the contribution for each collapsing category as well as the distance between collapsed instructions. 4. Simulation Framework To measure the impact of data speculation and dependence collapsing on parallelism we developed a trace driven simulator for the SPARC v.8 Architecture <ref> [13] </ref>. Our test set includes the benchmarks shown in Table 1. The benchmarks 026.compress, 008.espresso, 0.23 eqntott and 022.li are from the SPECINT92 suite and 099.go and 132.ijpeg are from the SPECINT95 suite.
Reference: [14] <author> R. K. Montoye, E. Hokenek, and S. L. Runyon. </author> <title> Design of the ibm risc system/6000 floating-point execution unit. </title> <journal> IBM Journal of Researchand Development, </journal> <volume> 34(1) </volume> <pages> 59-70, </pages> <month> January </month> <year> 1990. </year>
Reference-contexts: Functionality for the collapsing of multiple operations has been advanced in a number of proposals for floating point and fixed point instructions <ref> [14, 16, 19] </ref>. The performance limit studies published in the literature [1, 3, 6, 7, 20] are primarily based on the assumption that true dependence paths through the dynamic dependence graph place a limit on performance. <p> Data dependence collapsing functionality has been advanced in a number of proposals. Collapsing for specific instances of floating point operations with new instruction definitions has been proposed and implemented in a number of processors. The multiply-add operation was used in the RS/6000 <ref> [14, 16] </ref> and since then it has been incorporated in other superscalar pipelined processors [21]. A general scheme capable of collapsing a dependence pair involving fixed point arithmetic and logical instructions was proposed in [19].
Reference: [15] <author> A. Moshovos. </author> <title> Increasing instruction level parallelism through instruction coallescing. </title> <type> private communication, </type> <year> 1995. </year>
Reference-contexts: Several studies have examined the limits of instruction level parallelism with a variety of control and resource models [1, 3, 6, 7, 20]. However, no limit study has examined the impact of data dependence collapsing and speculation on instruction parallelism. A related work <ref> [15] </ref> used static program representation and profiling weights to calculate the frequencies of sequences (pairs, triples and quads) of dependent instructions within and across basic blocks. This work however did not examine the impact on latency/parallelism.
Reference: [16] <author> R. R. Oehler and R. D. Groves. </author> <title> Ibm risc system/6000 processor architecture. </title> <journal> IBM Journal of Research and Development, </journal> <volume> 34(1) </volume> <pages> 23-36, </pages> <month> January </month> <year> 1990. </year>
Reference-contexts: Functionality for the collapsing of multiple operations has been advanced in a number of proposals for floating point and fixed point instructions <ref> [14, 16, 19] </ref>. The performance limit studies published in the literature [1, 3, 6, 7, 20] are primarily based on the assumption that true dependence paths through the dynamic dependence graph place a limit on performance. <p> Data dependence collapsing functionality has been advanced in a number of proposals. Collapsing for specific instances of floating point operations with new instruction definitions has been proposed and implemented in a number of processors. The multiply-add operation was used in the RS/6000 <ref> [14, 16] </ref> and since then it has been incorporated in other superscalar pipelined processors [21]. A general scheme capable of collapsing a dependence pair involving fixed point arithmetic and logical instructions was proposed in [19].
Reference: [17] <author> J. Phillips and S. Vassiliadis. </author> <title> High performance 3-1 interlock collapsing alu's. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 43(3) </volume> <pages> 257-268, </pages> <month> March </month> <year> 1994. </year>
Reference-contexts: A device that includes the majority of the functions a collapsing fixed point unit can perform, was proposed in <ref> [17] </ref>. Several studies have examined the limits of instruction level parallelism with a variety of control and resource models [1, 3, 6, 7, 20]. However, no limit study has examined the impact of data dependence collapsing and speculation on instruction parallelism. <p> This is a relatively optimistic approach intended to explore the envelope of the performance potential. The assumed mechanisms extend proposed devices <ref> [17] </ref> with the ability of collapsing shift operations and 4-1 dependence expressions. Shift operations are added in our study because they appear frequently in the instruction mix of programs (about 6%) and shift distances are dominated by a few values.
Reference: [18] <author> S. Vassiliadis, B. Blaner, and R. J. Eickemeyer. Scism: </author> <title> A scalable compound instruction set machine architecture. </title> <journal> IBM Journal of Research and Development, </journal> <volume> 38(1) </volume> <pages> 59-78, </pages> <month> January </month> <year> 1994. </year>
Reference-contexts: A related work [15] used static program representation and profiling weights to calculate the frequencies of sequences (pairs, triples and quads) of dependent instructions within and across basic blocks. This work however did not examine the impact on latency/parallelism. In <ref> [10, 18] </ref>, performance studies were conducted to characterize the effects of interlock (dependence) collapsing functionality on parallelism for a variety of resource and control models. The dependence collapsing performed in these studies was restricted to collapsing only consecutive instructions within a single basic block.
Reference: [19] <author> S. Vassiliadis, J. Phillips, and B. Blanner. </author> <title> Interlock collapsing alu's. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 42(7) </volume> <pages> 825-839, </pages> <month> July </month> <year> 1993. </year>
Reference-contexts: Functionality for the collapsing of multiple operations has been advanced in a number of proposals for floating point and fixed point instructions <ref> [14, 16, 19] </ref>. The performance limit studies published in the literature [1, 3, 6, 7, 20] are primarily based on the assumption that true dependence paths through the dynamic dependence graph place a limit on performance. <p> Section 4 addresses the experimental framework and assumptions. Section 5 contains the discussion of the obtained results. Section 6 will conclude the study. 2. Related Work Several schemes for reducing the effects of execution and memory dependences have been proposed <ref> [2, 5, 9, 19] </ref>. These techniques are claimed to have minimal or no impact on the clock cycle. Mechanisms for remedying the effects of memory dependences using early memory loads were introduced in [2, 5]. In [5] the combination of three strategies is proposed. <p> The multiply-add operation was used in the RS/6000 [14, 16] and since then it has been incorporated in other superscalar pipelined processors [21]. A general scheme capable of collapsing a dependence pair involving fixed point arithmetic and logical instructions was proposed in <ref> [19] </ref>. The proposed solution takes into account a general CISC instruction set that includes the functionality of RISC and post-RISC based instruction sets.
Reference: [20] <author> D. W. Wall. </author> <title> Limits of instruction level parallelism. </title> <booktitle> In Proceedings of the 4th International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 176-188, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: Functionality for the collapsing of multiple operations has been advanced in a number of proposals for floating point and fixed point instructions [14, 16, 19]. The performance limit studies published in the literature <ref> [1, 3, 6, 7, 20] </ref> are primarily based on the assumption that true dependence paths through the dynamic dependence graph place a limit on performance. <p> A device that includes the majority of the functions a collapsing fixed point unit can perform, was proposed in [17]. Several studies have examined the limits of instruction level parallelism with a variety of control and resource models <ref> [1, 3, 6, 7, 20] </ref>. However, no limit study has examined the impact of data dependence collapsing and speculation on instruction parallelism. <p> For those benchmarks longer than 250 million instructions, only the first 250 million instructions of each benchmark trace were simulated due to time constraints. Nop operations were ignored and are not included in the simulations. Simulation Methodology: Our simulation methodology is similar to that used by Wall <ref> [20] </ref>. Instructions are fetched and placed in a window, from which instructions are chosen to issue.
Reference: [21] <author> S. Weiss and J. E. Smith. </author> <title> Inside IBM Power and PowerPC. </title> <publisher> Morgan Kaufmann Publishers Inc., </publisher> <address> San Mateo, CA, </address> <year> 1994. </year>
Reference-contexts: Collapsing for specific instances of floating point operations with new instruction definitions has been proposed and implemented in a number of processors. The multiply-add operation was used in the RS/6000 [14, 16] and since then it has been incorporated in other superscalar pipelined processors <ref> [21] </ref>. A general scheme capable of collapsing a dependence pair involving fixed point arithmetic and logical instructions was proposed in [19]. The proposed solution takes into account a general CISC instruction set that includes the functionality of RISC and post-RISC based instruction sets. <p> The performance of such a proposal for some realistic machine organizations was reported in [10] and a single cycle implementation of a subset of this proposal was implemented in POWER 2 <ref> [21] </ref>. A device that includes the majority of the functions a collapsing fixed point unit can perform, was proposed in [17]. Several studies have examined the limits of instruction level parallelism with a variety of control and resource models [1, 3, 6, 7, 20].
References-found: 21

