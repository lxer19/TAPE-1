URL: ftp://ftp.cs.ucsd.edu/pub/sfink/pub/jpdc98.ps.gz
Refering-URL: http://www.cs.ucsd.edu/~sfink/pub.html
Root-URL: http://www.cs.ucsd.edu
Title: Efficient Run-time Support for Irregular Block-Structured Applications  
Author: Stephen J. Fink, Scott B. Baden Scott R. Kohn 
Address: San Diego  
Affiliation: Department of Computer Science and Engineering University of California,  Center for Applied Scientific Computing Lawrence Livermore National Laboratory  UCSD School of Engineering  
Note: to appear in J. Parallel and Distributed Computing  This work was supported in part by ONR contract N00014-93-1-0152 and by the DOE Computational Science Graduate Fellowship Program. Computer time on the Intel Paragon at the San Diego Supercomputer Center was provided by a  block grant. Access to the IBM SP2 was provided by the Cornell Theory Center.  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Agrawal, G., Sussman, A., and Saltz, J. </author> <title> An integrated runtime and compile-time approach for parallelizing structured and block structured applications. </title> <journal> IEEE Trans. on Parallel and Distrib. Systems 6, </journal> <month> 7 (July </month> <year> 1995), </year> <pages> 747-54. </pages>
Reference-contexts: For example, in Figure 1b, the irregularly-shaped fine level communicates with the irregularly-shaped coarse level in the shadow cast by the fine level. KeLP represents a data motion pattern between XArrays using the MotionPlan abstraction. The MotionPlan is a first-class communication schedule <ref> [16, 1] </ref> object that encodes a set of array section copy operations between XArrays (Fig. 4). The programmer builds and modifies a MotionPlan using Region calculus operations described in the previous sub-section. KeLP data structures communicate via block copy operations. <p> In general, many sticky issues regarding parallel library and language interoperability remain unaddressed, and deserve more attention in future work. 11 to appear in J. Parallel and Distributed Computing 4 Implementation KeLP's abstractions permit implementation of communication based on the inspector/executor paradigm <ref> [1] </ref>. The Mover class performs run-time processing of the communication pattern stored in a MotionPlan. That is, the Mover analyzes the MotionPlan and generates message-passing calls to realize the communication pattern. We compare this implementation strategy to a model without inspector/executor analysis. <p> This prevents some optimizations such as posting for contiguous messages directly into user data structures. KeLP eliminates the need for one-sided communication by disallowing block copy operations from inside a for all loop. Instead, all block copy operations are treated as collective communication. Following the inspector/executor paradigm <ref> [1] </ref>, all processors store a locally relevant piece of the distributed communication pattern (MotionPlan). No costly global synchronization is required to detect termination of data movement. In the current Mover implementation, each processor generates MPI non-blocking messsages 12 to appear in J. <p> Such tuning effort may be too time-consuming for some programmers. We speculate that in most cases an optimized KeLP implementation will be at least as efficient as a straightforward hand-coded message-passing version. 6 Related work KeLP combines the structural abstraction concepts of LPARX [24] and inspector/executor communication analysis <ref> [16, 1] </ref>. The structural abstraction model uses geometric abstractions to describe data layout and data motion in irregular dynamic structured applications [24]. Structural abstraction derives from the domain abstractions used in the FIDIL programming language [21]. LPARX 17 to appear in J. <p> Parashar and Browne employ similar techniques in a DAGH, a software infrastructure for parallel structure adaptive mesh refinement applications [34]. KeLP's block-structured inspector/executor implementation is based on concepts introduced in the Multiblock PARTI <ref> [1] </ref> run time system. Multiblock PARTI supports regular block distributions for dynamic arrays, but does not directly support irregular block decompositions as in systems like KeLP. Multiblock PARTI provides two common communication patterns, one to fill in ghost regions and one that moves data over regular sections.
Reference: [2] <author> Alpern, B., Carter, L., and Ferrante, J. </author> <title> Modeling parallel computers as memory hierarchies. </title> <editor> In Giloi, W. K., Jahnichen, S., and Shriver, B. D. (Eds.). </editor> <title> Programming Models for Massively Parallel Computers. </title> <publisher> IEEE Comput. Soc. Press, Los Alamitos, </publisher> <address> CA, </address> <year> 1993, </year> <month> pp.116-23. </month>
Reference-contexts: These structures give rise to unpredictable, irregular communication patterns, making parallel programming of irregular calculations especially challenging. In order to get good performance on today's non-uniform parallel memory hierarchies <ref> [2] </ref>, the programmer must judiciously exploit parallelism and locality in the application to match the hardware capabilities. To ease the programmer's burden, programming languages and libraries can hide many low-level details of a parallel implementation [20, 24, 16, 1, 12, 10, 35, 15, 11, 23, 28, 4].
Reference: [3] <author> Bailey, D., Harris, T., Saphir, W., Wijngaart, R., Woo, A., and Yarrow, M. </author> <title> The NAS parallel benchmarks 2.0. </title> <type> Tech. Rep. </type> <institution> NAS-95-020, NASA Ames Research Center, Moffet Field, </institution> <address> CA, </address> <month> Dec. </month> <year> 1995. </year>
Reference-contexts: In this paper, we compare KeLP performance against hand-coded MPI implementations of the NAS Multigrid (MG) and Fourier Transform (FT) benchmarks <ref> [3] </ref>, as well as the SUMMA matrix multiply algorithm [40]. Running on the IBM SP2 with up to 64 processors, KeLP codes achieves performance comparable to hand-coded versions using message-passing directly. <p> A Grid is an array of objects, all of the same type, whose index space is a Region. For example, the Fortran-90 array defined as real A [3:7] corresponds to a one-dimensional Grid A of real with region (A) = <ref> [3; 7] </ref>. A Grid G may not span multiple processor memories; rather, it lives in a single address space. For convenience, most KeLP Region calculus operations are defined over Grids. <p> The methodology used in this comparison is as follows. We obtained three publicly available block-structured MPI codes for reference. The first two codes, NAS-FT and NAS-MG, are application kernels from the NAS Parallel Benchmark MPI implementations version 2.1 <ref> [3] </ref>. The third code, the Scalable Universal Matrix Multiply Algorithm (SUMMA), is the matrix multiply kernel appearing in [40]. For each code, we translated the MPI version into KeLP by allocating the distributed data structures using KeLP, and replacing all MPI communication with KeLP primitives.
Reference: [4] <author> Balay, S., Gropp, W. D., McInnes, L. C., and Smith, B. R. </author> <title> Efficient management of parallelism in object-oriented numerical software libraries. </title> <editor> In Arge, E., Bruaset, A. M., and Langtangen, H. P. (Eds.). </editor> <booktitle> Modern Software Tools in Scientific Computing. </booktitle> <publisher> Birkhauser Press, </publisher> <year> 1997. </year> <note> To appear. </note>
Reference-contexts: The Multiblock PARTI communication schedule is an opaque object over which the user has limited control. In contrast, KeLP exposes the schedule to the programmer as a first class mutable object, which may be manipulated, modified and interpreted according to the programmer's needs. The design of the PETSc library <ref> [4] </ref> follows some of the same principles used in KeLP. PETSc provides first-class objects to represent index sets that describe gather/scatter operations, and performs inspector/executor analysis of communication patterns. PETSc does not support irregular grid collections nor irregular partitionings of rectangular domains. <p> Parallel and Distributed Computing KeLP applies to block-structured applications, where the arrangement of blocks and communication patterns between blocks are potentially irregularly. KeLP does not support fine-grained data structures and communication patterns, as supported by systems such as CHAOS [41], CHAOS++ [12], PETSc <ref> [4] </ref>, pC++ [7], and Multipol [10]. KeLP is not appropriate for more irregular calculations such as those involving sparse arrays, lists, trees, or asynchronous parallelism. 7 Conclusion We have introduced a small set of geometric programming abstractions for managing data layout and communication in dynamic block-structured applications.
Reference: [5] <author> Berger, M. J. and Colella, P. </author> <title> Local adaptive mesh refinement for shock hydrodynamics. </title> <address> JCP 82, </address> <month> 1 (May </month> <year> 1989), </year> <pages> 64-84. </pages>
Reference-contexts: Naturally, each scientific application uses a distinct set of data motion patterns. For example, a shock hydrodynamics code will demand a set of data motion patterns which match the conservative differencing schemes used for hyperbolic PDEs <ref> [5] </ref>. KeLP has been employed in several projects demanding run-time partitioning and communication patterns, including structured adaptive mesh refinement applications [27, 33] and studies of load-balancing in heterogeneous computing environments [6, 18]. In heterogeneous computing environments, even uniform problems can present tricky data layout and data motion problems.
Reference: [6] <author> Berman, F., Wolski, R., Figueira, S., Schopf, J., and Shao, G. </author> <title> Application-level scheduling on distributed heterogeneous networks. </title> <booktitle> Proceedings of Supercomputing '96. </booktitle> <month> November </month> <year> 1996. </year>
Reference-contexts: KeLP has been employed in several projects demanding run-time partitioning and communication patterns, including structured adaptive mesh refinement applications [27, 33] and studies of load-balancing in heterogeneous computing environments <ref> [6, 18] </ref>. In heterogeneous computing environments, even uniform problems can present tricky data layout and data motion problems. For example, on a heterogeneous collection of processors, load balancing concerns will dictate an irregular work decomposition even for a uniform problem [22].
Reference: [7] <author> Bodin, F., Beckman, P., Gannon, D., Botwals, J., Narayana, S., Srinivas, S., and Winnicka, B. </author> <title> Distributed pC++: Basic ideas for an object parallel language. </title> <journal> Journal of Scientific Programming 2, </journal> <volume> 3 (1993), </volume> <pages> 7-22. </pages>
Reference-contexts: A Grid is an array of objects, all of the same type, whose index space is a Region. For example, the Fortran-90 array defined as real A [3:7] corresponds to a one-dimensional Grid A of real with region (A) = <ref> [3; 7] </ref>. A Grid G may not span multiple processor memories; rather, it lives in a single address space. For convenience, most KeLP Region calculus operations are defined over Grids. <p> DOCK includes two classes, Processor and Decomposition, that implement first-class C++ versions of the virtual processor arrays and templates in High Performance Fortran [20]. The DOCK classes are modeled after similar classes introduced in pC++ <ref> [7] </ref>. Using the DOCK mapping classes, we first declare a virtual processor array. By default, the Processors2 object creates a 2D logical processor array corresponding to the physical processor set (2). Next, we must decompose the global domain across the virtual processor set. <p> Structural abstraction derives from the domain abstractions used in the FIDIL programming language [21]. LPARX 17 to appear in J. Parallel and Distributed Computing uses an asynchronous communication model, as do several other parallel languages and libraries <ref> [15, 23, 7, 11, 10] </ref>. An asynchronous communication model is most appropriate for applications where run-time preprocessing of the communication pattern is impossible. However, when communication dependences can be computed beforehand, run-time preprocessing can significantly reduce communication overheads and synchronization. <p> Parallel and Distributed Computing KeLP applies to block-structured applications, where the arrangement of blocks and communication patterns between blocks are potentially irregularly. KeLP does not support fine-grained data structures and communication patterns, as supported by systems such as CHAOS [41], CHAOS++ [12], PETSc [4], pC++ <ref> [7] </ref>, and Multipol [10]. KeLP is not appropriate for more irregular calculations such as those involving sparse arrays, lists, trees, or asynchronous parallelism. 7 Conclusion We have introduced a small set of geometric programming abstractions for managing data layout and communication in dynamic block-structured applications.
Reference: [8] <author> Briggs, W. L. </author> <title> A Multigrid Tutorial. </title> <publisher> SIAM, </publisher> <address> Philadelphia, PA, </address> <year> 1987. </year> <note> 20 to appear in J. Parallel and Distributed Computing </note>
Reference-contexts: We present Kernel Lattice Parallelism (KeLP), a C++ class library that provides high-level abstractions to manage data layout and data motion for dynamic block-structured applications. Block structures arise in many scientific applications ranging from finite difference methods for partial differential equations <ref> [8] </ref> to blocked algorithms for numerical linear algebra [13]. In these applications, computational structures arise as uniform rectangular arrays of data, which communicate in potentially irregular patterns. KeLP supports a small set of geometric programming abstractions to represent data layout and data motion patterns.
Reference: [9] <author> Bylaska, E. J., Kohn, S. R., Baden, S. B., Edelman, A., Kawai, R., Ong, M. E. G., and Weare, J. H. </author> <title> Scalable parallel numerical methods and software tools for material design. </title> <booktitle> Proceedings of the Seventh SIAM Conference on Parallel Processing for Scientific Computing. </booktitle> <publisher> SIAM, </publisher> <address> Philadelpha, PA, </address> <month> Feb. </month> <year> 1995, </year> <pages> pp. 219-24. </pages>
Reference-contexts: Such flexibility is vital for block-structured applications with complex or irregular data motion patterns based on run-time characteristics of the application. Consider, for example, an adaptive multigrid method which has been employed in ab-initio materials design <ref> [9, 25] </ref>. This application contains dynamically adapting collections of 3D blocks of data, arising in response to error in the computed numerical solution. The error in the solution varies non-uniformly in space according to 3 to appear in J. Parallel and Distributed Computing evolving conditions in the data. <p> Thus, we may confidently expect similar KeLP overheads even when the underlying problem structure is irregular. 5.2 Adaptive Multigrid Lda3d is a 3D adaptive multigrid eigenvalue solver used in ab initio materials science simulations <ref> [24, 9] </ref>. This application was originally coded in LPARX and then ported to KeLP. The lda3d algorithm demands complex irregular communication to transfer data within and between levels of the mesh hierarchy (see Figure 1b). MotionPlans and the Region calculus provide a natural paradigm to describe these data motion patterns.
Reference: [10] <author> Wen, C.-P., Chakrabarti, S., Deprit, E., Krishnamurthy, A., and Yelick, K. </author> <title> Runtime support for portable distributed data structures. </title> <editor> In Szymanski, B. K. and Norwell, B. (Eds.). </editor> <title> Languages, Compilers, and Run-Time Systems for Scalable Computers. </title> <publisher> Kluwer Academic Publishers, Norwell, </publisher> <address> MA, </address> <year> 1996, </year> <pages> pp. 111-20. </pages>
Reference-contexts: Structural abstraction derives from the domain abstractions used in the FIDIL programming language [21]. LPARX 17 to appear in J. Parallel and Distributed Computing uses an asynchronous communication model, as do several other parallel languages and libraries <ref> [15, 23, 7, 11, 10] </ref>. An asynchronous communication model is most appropriate for applications where run-time preprocessing of the communication pattern is impossible. However, when communication dependences can be computed beforehand, run-time preprocessing can significantly reduce communication overheads and synchronization. <p> Parallel and Distributed Computing KeLP applies to block-structured applications, where the arrangement of blocks and communication patterns between blocks are potentially irregularly. KeLP does not support fine-grained data structures and communication patterns, as supported by systems such as CHAOS [41], CHAOS++ [12], PETSc [4], pC++ [7], and Multipol <ref> [10] </ref>. KeLP is not appropriate for more irregular calculations such as those involving sparse arrays, lists, trees, or asynchronous parallelism. 7 Conclusion We have introduced a small set of geometric programming abstractions for managing data layout and communication in dynamic block-structured applications.
Reference: [11] <author> Chandy, K. and Kesselman, C. </author> <title> Compositional C++: Compositional parallel programming. </title> <booktitle> Languages and Compilers for Parallel Computing. Fifth International Workshop Proceedings. </booktitle> <publisher> Springer-Verlag, </publisher> <address> New Haven, CT, </address> <month> Aug. </month> <year> 1992, </year> <pages> pp. 124-44. </pages>
Reference-contexts: Structural abstraction derives from the domain abstractions used in the FIDIL programming language [21]. LPARX 17 to appear in J. Parallel and Distributed Computing uses an asynchronous communication model, as do several other parallel languages and libraries <ref> [15, 23, 7, 11, 10] </ref>. An asynchronous communication model is most appropriate for applications where run-time preprocessing of the communication pattern is impossible. However, when communication dependences can be computed beforehand, run-time preprocessing can significantly reduce communication overheads and synchronization.
Reference: [12] <author> Chang, C., Sussman, A., and Saltz, J. </author> <title> Support for distributed dynamic data structures in C++. </title> <type> Technical Report CS-TR-3266, </type> <institution> University of Maryland Computer Science Department, College Park, MD, </institution> <month> Jan. </month> <year> 1995. </year>
Reference-contexts: Parallel and Distributed Computing KeLP applies to block-structured applications, where the arrangement of blocks and communication patterns between blocks are potentially irregularly. KeLP does not support fine-grained data structures and communication patterns, as supported by systems such as CHAOS [41], CHAOS++ <ref> [12] </ref>, PETSc [4], pC++ [7], and Multipol [10]. KeLP is not appropriate for more irregular calculations such as those involving sparse arrays, lists, trees, or asynchronous parallelism. 7 Conclusion We have introduced a small set of geometric programming abstractions for managing data layout and communication in dynamic block-structured applications.
Reference: [13] <author> Choi, J., Demmel, J., Dhillon, I., Dongarra, J., Ostrouchov, S., Petitet, A., Stanley, K., Walker, D., and Whaley, R. C. </author> <title> ScaLAPACK: a portable linear algebra library for distributed memory computers. design issues and performance. </title> <booktitle> Applied Parallel Computing. Computation in Physics, Chemistry and Engineering Science. Second International Workshop. PARA `95. </booktitle> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <month> August </month> <year> 1995, </year> <pages> pp. 95-106. </pages>
Reference-contexts: We present Kernel Lattice Parallelism (KeLP), a C++ class library that provides high-level abstractions to manage data layout and data motion for dynamic block-structured applications. Block structures arise in many scientific applications ranging from finite difference methods for partial differential equations [8] to blocked algorithms for numerical linear algebra <ref> [13] </ref>. In these applications, computational structures arise as uniform rectangular arrays of data, which communicate in potentially irregular patterns. KeLP supports a small set of geometric programming abstractions to represent data layout and data motion patterns.
Reference: [14] <author> Choudhary, A., Bordawekar, R., Harry, M., Krishnaiyer, R., Ponnusamy, R., Singh, T., and Thakur, R. </author> <title> PASSION: Parallel and scalable software for I/O. </title> <type> Technical Report SCCS-636, </type> <institution> NPAC, Syracuse, </institution> <address> NY, </address> <month> Sept. </month> <year> 1994. </year>
Reference-contexts: PETSc provides first-class objects to represent index sets that describe gather/scatter operations, and performs inspector/executor analysis of communication patterns. PETSc does not support irregular grid collections nor irregular partitionings of rectangular domains. Run-time scheduled communication mechanisms have proven useful in several other contexts. The PASSION <ref> [14] </ref> and Jovian [36] systems pre-process communication patterns to optimize parallel I/O. Communication schedules have traditionally been considered for message-passing architectures. However, recent work [32, 17] has shown that inspector/executor techniques may be necessary to achieve good performance on distributed shared-memory architectures as well.
Reference: [15] <author> Culler, D., Dusseau, A., Goldstein, S., Krishnamurthy, A., Lumetta, S., Eicken, T., and Yelick, K. </author> <title> Parallel programming in Split-C. </title> <booktitle> Proc. Supercomputing '93. </booktitle> <publisher> IEEE Comput. Soc. Press, Los Alamitos, </publisher> <address> CA, </address> <month> Nov. </month> <year> 1993, </year> <pages> pp. 262-73. </pages>
Reference-contexts: Structural abstraction derives from the domain abstractions used in the FIDIL programming language [21]. LPARX 17 to appear in J. Parallel and Distributed Computing uses an asynchronous communication model, as do several other parallel languages and libraries <ref> [15, 23, 7, 11, 10] </ref>. An asynchronous communication model is most appropriate for applications where run-time preprocessing of the communication pattern is impossible. However, when communication dependences can be computed beforehand, run-time preprocessing can significantly reduce communication overheads and synchronization.
Reference: [16] <author> Das, R., Uysal, M., Saltz, J., and Hwang, Y.-S. </author> <title> Communication optimizations for irregular scientific computations on distributed memory architectures. </title> <journal> J. Parallel and Distrib. Comput. </journal> <volume> 22, </volume> <month> 3 (Sept. </month> <year> 1994), </year> <pages> 462-479. </pages> <note> 21 to appear in J. Parallel and Distributed Computing </note>
Reference-contexts: For example, in Figure 1b, the irregularly-shaped fine level communicates with the irregularly-shaped coarse level in the shadow cast by the fine level. KeLP represents a data motion pattern between XArrays using the MotionPlan abstraction. The MotionPlan is a first-class communication schedule <ref> [16, 1] </ref> object that encodes a set of array section copy operations between XArrays (Fig. 4). The programmer builds and modifies a MotionPlan using Region calculus operations described in the previous sub-section. KeLP data structures communicate via block copy operations. <p> Such tuning effort may be too time-consuming for some programmers. We speculate that in most cases an optimized KeLP implementation will be at least as efficient as a straightforward hand-coded message-passing version. 6 Related work KeLP combines the structural abstraction concepts of LPARX [24] and inspector/executor communication analysis <ref> [16, 1] </ref>. The structural abstraction model uses geometric abstractions to describe data layout and data motion in irregular dynamic structured applications [24]. Structural abstraction derives from the domain abstractions used in the FIDIL programming language [21]. LPARX 17 to appear in J.
Reference: [17] <author> Falsafi, B., Lebeck, A. R., Reinhardt, S. K., Schoinas, I., Hill, M. D., Larus, J. R., Rogers, A., and Wood, D. A. </author> <title> Application-specific protocols for user-level shared memory. </title> <booktitle> Proc. Supercomputing '94. </booktitle> <publisher> IEEE Comput. Soc. Press, Los Alamitos, </publisher> <address> CA, </address> <month> November </month> <year> 1994, </year> <pages> pp. 380-9. </pages>
Reference-contexts: Run-time scheduled communication mechanisms have proven useful in several other contexts. The PASSION [14] and Jovian [36] systems pre-process communication patterns to optimize parallel I/O. Communication schedules have traditionally been considered for message-passing architectures. However, recent work <ref> [32, 17] </ref> has shown that inspector/executor techniques may be necessary to achieve good performance on distributed shared-memory architectures as well. Tempest [37] allows the programmer to write application-specific communication protocols for a distributed shared-memory architecture.
Reference: [18] <author> Figueira, S. M. </author> <title> Modeling the Effects of Contention on Application Performance in Multi-User Environments. </title> <type> Ph.D. thesis, </type> <institution> University of California at San Diego, </institution> <year> 1996. </year>
Reference-contexts: KeLP has been employed in several projects demanding run-time partitioning and communication patterns, including structured adaptive mesh refinement applications [27, 33] and studies of load-balancing in heterogeneous computing environments <ref> [6, 18] </ref>. In heterogeneous computing environments, even uniform problems can present tricky data layout and data motion problems. For example, on a heterogeneous collection of processors, load balancing concerns will dictate an irregular work decomposition even for a uniform problem [22].
Reference: [19] <author> Fox, G., Hiranandani, S., Kennedy, K., Koelbel, C., Kremer, U., Tseng, C., and Wu, M. </author> <title> Fortran D language specification. </title> <type> Technical Report TR90-141, </type> <institution> Dept. of Computer Science, Rice University, Houston, TX, </institution> <month> December </month> <year> 1989. </year>
Reference-contexts: For these cases, we may wish to reuse the partitioning code in a Domain Specific Library (DSL) that implements policies germane to an application class. For example, KeLP includes a DSL called DOCK (DecOmposition Classes for KeLP) that implements standard Fortran-D style block decompositions <ref> [19] </ref> for regular applications. DOCK includes two classes, Processor and Decomposition, that implement first-class C++ versions of the virtual processor arrays and templates in High Performance Fortran [20]. The DOCK classes are modeled after similar classes introduced in pC++ [7].
Reference: [20] <author> High Performance Fortran Forum,. </author> <title> High performance fortran language specification. </title> <institution> Rice University, Houston, Texas, </institution> <month> May </month> <year> 1993. </year>
Reference-contexts: For example, KeLP includes a DSL called DOCK (DecOmposition Classes for KeLP) that implements standard Fortran-D style block decompositions [19] for regular applications. DOCK includes two classes, Processor and Decomposition, that implement first-class C++ versions of the virtual processor arrays and templates in High Performance Fortran <ref> [20] </ref>. The DOCK classes are modeled after similar classes introduced in pC++ [7]. Using the DOCK mapping classes, we first declare a virtual processor array. By default, the Processors2 object creates a 2D logical processor array corresponding to the physical processor set (2).
Reference: [21] <author> Hilfinger, P. N. and Colella, P. FIDIL: </author> <title> A languages for scientific programming. </title> <type> Tech. Rep. </type> <institution> UCRL-98057, Lawrence Livermore Nat. Lab., Livermore, </institution> <address> CA, </address> <month> Jan. </month> <year> 1988. </year>
Reference-contexts: The structural abstraction model uses geometric abstractions to describe data layout and data motion in irregular dynamic structured applications [24]. Structural abstraction derives from the domain abstractions used in the FIDIL programming language <ref> [21] </ref>. LPARX 17 to appear in J. Parallel and Distributed Computing uses an asynchronous communication model, as do several other parallel languages and libraries [15, 23, 7, 11, 10]. An asynchronous communication model is most appropriate for applications where run-time preprocessing of the communication pattern is impossible.
Reference: [22] <author> Kaddoura, M., Ranka, S., and Wang, A. </author> <title> Array decompositions for nonuniform computational environments. </title> <journal> J. Parallel and Distrib. Comput. </journal> <volume> 36, </volume> <month> 2 (August </month> <year> 1996), </year> <pages> 91-105. </pages>
Reference-contexts: In heterogeneous computing environments, even uniform problems can present tricky data layout and data motion problems. For example, on a heterogeneous collection of processors, load balancing concerns will dictate an irregular work decomposition even for a uniform problem <ref> [22] </ref>. KeLP's mechanisms simplify the expression of such irregular block data decompositions and communication patterns at run-time.
Reference: [23] <author> Kale, L. and Krishnan, S. CHARM++: </author> <title> a portable concurrent object oriented system based on C++. </title> <journal> SIGPLAN Notices 28, </journal> <month> 10 (October </month> <year> 1993), </year> <pages> 91-108. </pages>
Reference-contexts: Structural abstraction derives from the domain abstractions used in the FIDIL programming language [21]. LPARX 17 to appear in J. Parallel and Distributed Computing uses an asynchronous communication model, as do several other parallel languages and libraries <ref> [15, 23, 7, 11, 10] </ref>. An asynchronous communication model is most appropriate for applications where run-time preprocessing of the communication pattern is impossible. However, when communication dependences can be computed beforehand, run-time preprocessing can significantly reduce communication overheads and synchronization.
Reference: [24] <author> Kohn, S. R. </author> <title> A Parallel Software Infrastructure for Dynamic Block-Irregular Scientific Calculations. </title> <type> Ph.D. thesis, </type> <institution> University of California at San Diego, </institution> <year> 1995. </year>
Reference-contexts: KeLP's data orchestration model separates the description of communication patterns from the interpretation of these patterns. The programmer uses intuitive geometric constructs to express dependence patterns among dynamic collections of arrays. Additionally, KeLP utilizes structural abstraction, introduced in the LPARX programming system <ref> [24, 26] </ref>, to separate the description of data decompositions from the underlying storage implementation. KeLP's innovation lies in first-class communication schedule objects, called MotionPlans, which the programmer can define and manipulate with intuitive geometric operations. <p> The second set, consisting of Grid, XArray, and Mover, instantiate storage or communication activity. Their interpretation depends on the target architecture's communication and storage characteristics. 2.1 Data Layout Abstractions KeLP manages data layout with an extended verison of the structural abstraction model, introduced in the LPARX programming system <ref> [24, 26] </ref>. With structural abstraction, a geometric abstraction stores the structure a data set separately from the data itself. KeLP inherits four core data decomposition abstractions from LPARX: Point, Region, Grid, and XArray. KeLP extends the model with a fifth abstraction, the FloorPlan. <p> The Mover class performs run-time processing of the communication pattern stored in a MotionPlan. That is, the Mover analyzes the MotionPlan and generates message-passing calls to realize the communication pattern. We compare this implementation strategy to a model without inspector/executor analysis. LPARX <ref> [24] </ref>, the predecessor of KeLP, implements an asynchronous communication strategy without run-time communication analysis. Whereas KeLP and LPARX employ the same coarse grain data parallel computation model, the two systems differ on where data motion operations may occur. <p> The next application, an adaptive multigrid eigenvalue solver, exercises the full expressive power of KeLP's abstractions. This application requires five different types of communication patterns between dynamic irregular collections of grids. We show that KeLP's inspector/executor analysis substantially improves performance compared to a LPARX <ref> [24] </ref> implementation relying on one-sided communication. Finally, using a uniform finite difference method, we show how to optimize MotionPlans using KeLP primitives to reduce communication costs. In this example, high-level tuning of the MotionPlan reduces reduces communication costs by a up to factor of two. 13 to appear in J. <p> Thus, we may confidently expect similar KeLP overheads even when the underlying problem structure is irregular. 5.2 Adaptive Multigrid Lda3d is a 3D adaptive multigrid eigenvalue solver used in ab initio materials science simulations <ref> [24, 9] </ref>. This application was originally coded in LPARX and then ported to KeLP. The lda3d algorithm demands complex irregular communication to transfer data within and between levels of the mesh hierarchy (see Figure 1b). MotionPlans and the Region calculus provide a natural paradigm to describe these data motion patterns. <p> Such tuning effort may be too time-consuming for some programmers. We speculate that in most cases an optimized KeLP implementation will be at least as efficient as a straightforward hand-coded message-passing version. 6 Related work KeLP combines the structural abstraction concepts of LPARX <ref> [24] </ref> and inspector/executor communication analysis [16, 1]. The structural abstraction model uses geometric abstractions to describe data layout and data motion in irregular dynamic structured applications [24]. Structural abstraction derives from the domain abstractions used in the FIDIL programming language [21]. LPARX 17 to appear in J. <p> implementation will be at least as efficient as a straightforward hand-coded message-passing version. 6 Related work KeLP combines the structural abstraction concepts of LPARX <ref> [24] </ref> and inspector/executor communication analysis [16, 1]. The structural abstraction model uses geometric abstractions to describe data layout and data motion in irregular dynamic structured applications [24]. Structural abstraction derives from the domain abstractions used in the FIDIL programming language [21]. LPARX 17 to appear in J. Parallel and Distributed Computing uses an asynchronous communication model, as do several other parallel languages and libraries [15, 23, 7, 11, 10].
Reference: [25] <author> Kohn, S. R. and Baden, S. B. </author> <title> A parallel software infrastructure for structured adaptive mesh methods. </title> <booktitle> Proc. Supercomputing '95. </booktitle> <address> San Diego, CA, </address> <month> Dec. </month> <year> 1995. </year>
Reference-contexts: Such flexibility is vital for block-structured applications with complex or irregular data motion patterns based on run-time characteristics of the application. Consider, for example, an adaptive multigrid method which has been employed in ab-initio materials design <ref> [9, 25] </ref>. This application contains dynamically adapting collections of 3D blocks of data, arising in response to error in the computed numerical solution. The error in the solution varies non-uniformly in space according to 3 to appear in J. Parallel and Distributed Computing evolving conditions in the data.
Reference: [26] <author> Kohn, S. R. and Baden, S. B. </author> <title> Irregular coarse-grain data parallelism under LPARX. </title> <editor> J. </editor> <booktitle> Scientific Programming 5, 3 (Fall 1996), </booktitle> <pages> 185-201. </pages>
Reference-contexts: KeLP's data orchestration model separates the description of communication patterns from the interpretation of these patterns. The programmer uses intuitive geometric constructs to express dependence patterns among dynamic collections of arrays. Additionally, KeLP utilizes structural abstraction, introduced in the LPARX programming system <ref> [24, 26] </ref>, to separate the description of data decompositions from the underlying storage implementation. KeLP's innovation lies in first-class communication schedule objects, called MotionPlans, which the programmer can define and manipulate with intuitive geometric operations. <p> The second set, consisting of Grid, XArray, and Mover, instantiate storage or communication activity. Their interpretation depends on the target architecture's communication and storage characteristics. 2.1 Data Layout Abstractions KeLP manages data layout with an extended verison of the structural abstraction model, introduced in the LPARX programming system <ref> [24, 26] </ref>. With structural abstraction, a geometric abstraction stores the structure a data set separately from the data itself. KeLP inherits four core data decomposition abstractions from LPARX: Point, Region, Grid, and XArray. KeLP extends the model with a fifth abstraction, the FloorPlan.
Reference: [27] <author> Kohn, S. R., Weare, J., Ong, E., and Baden, S. </author> <title> Parallel adaptive mesh refinement for electronic structure calculations. </title> <booktitle> Proceedings of the Eighth SIAM Conference on Parallel Processing for Scientific Computing. </booktitle> <month> March </month> <year> 1997. </year> <note> To appear. </note>
Reference-contexts: For example, a shock hydrodynamics code will demand a set of data motion patterns which match the conservative differencing schemes used for hyperbolic PDEs [5]. KeLP has been employed in several projects demanding run-time partitioning and communication patterns, including structured adaptive mesh refinement applications <ref> [27, 33] </ref> and studies of load-balancing in heterogeneous computing environments [6, 18]. In heterogeneous computing environments, even uniform problems can present tricky data layout and data motion problems.
Reference: [28] <author> Lin, C. and Snyder, L. </author> <title> ZPL:an array sublanguage. </title> <editor> In Banerjee, U., Gelernter, D., Nicolau, A., and Padua, D. (Eds.). </editor> <booktitle> Languages and Compilers for Parallel Computing, 6th International Workshop Proceedings, </booktitle> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1994, </year> <pages> pp. 96-114. </pages> <note> 22 to appear in J. Parallel and Distributed Computing </note>
Reference: [29] <author> Merlin, J. and Baden, S. </author> <title> Managing multiple HPF invocations using KeLP. </title> <note> In preparation. </note>
Reference-contexts: Interfaces to other extrinsic languages are possible. Some KeLP users use extrinsic numerical routines in C, and a simple interface to an HPF compiler has been implemented by Merlin and Baden <ref> [29] </ref>. 3.3 Data Motion The fillGhost () function (Figure 9) fills in the ghost cells for each processor's partition in an XArray (Figure 8c). We now describe the KeLP code to effect this data motion. First we declare a MotionPlan data structure to hold the communication pattern (1).
Reference: [30] <editor> Message Passing Interface Forum,. </editor> <title> MPI: A message-passing interface standard, </title> <month> June </month> <year> 1995. </year>
Reference-contexts: For example, on a heterogeneous collection of processors, load balancing concerns will dictate an irregular work decomposition even for a uniform problem [22]. KeLP's mechanisms simplify the expression of such irregular block data decompositions and communication patterns at run-time. KeLP requires only basic message passing capabilities (MPI <ref> [30] </ref>) and has been ported to the IBM SP2, Cray T3E, Intel Paragon, SGI Power Challenge Array, SGI Origin 2000, clusters of workstations and single processor workstations.
Reference: [31] <editor> Message Passing Interface Forum,. </editor> <title> MPI-2: Extensions to the message-pasing interface. </title> <type> Draft, </type> <month> November </month> <year> 1996. </year>
Reference-contexts: Since each SPMD process does not execute all iterations of the loop, process i does not know the communication activity generated by process j if i 6= j. Thus, block copy operations must be implemented with one-sided communication mechanisms <ref> [31] </ref>. To ensure memory consistency with one-sided communication, at the end of the for all loop all processors participate in a global synchronization point. The barrier ensures that all block copies complete before the program may proceed and potentially modify Grid data.
Reference: [32] <author> Mukherjee, S. S., Sharma, S. D., Hill, M. D., Larus, J. R., Rogers, A., and Saltz, J. </author> <title> Efficient support for irregular applications on distributed memory machines. </title> <journal> SIGPLAN Notices 30, </journal> <month> 8 (Aug. </month> <year> 1995), </year> <pages> 68-79. </pages>
Reference-contexts: Run-time scheduled communication mechanisms have proven useful in several other contexts. The PASSION [14] and Jovian [36] systems pre-process communication patterns to optimize parallel I/O. Communication schedules have traditionally been considered for message-passing architectures. However, recent work <ref> [32, 17] </ref> has shown that inspector/executor techniques may be necessary to achieve good performance on distributed shared-memory architectures as well. Tempest [37] allows the programmer to write application-specific communication protocols for a distributed shared-memory architecture.
Reference: [33] <author> Myers, C. </author> <title> Abstractions, accomodations and applications: Thoughts on developing object-oriented software using someone else's class library. </title> <address> POOMA 96. Santa Fe, NM, </address> <month> February </month> <year> 1996. </year>
Reference-contexts: For example, a shock hydrodynamics code will demand a set of data motion patterns which match the conservative differencing schemes used for hyperbolic PDEs [5]. KeLP has been employed in several projects demanding run-time partitioning and communication patterns, including structured adaptive mesh refinement applications <ref> [27, 33] </ref> and studies of load-balancing in heterogeneous computing environments [6, 18]. In heterogeneous computing environments, even uniform problems can present tricky data layout and data motion problems.
Reference: [34] <author> Parashar, M. and Browne, J. C. Dagh: </author> <title> A data-management infrastructure for parallel adaptive mesh refinement techniques. </title> <type> Draft, </type> <year> 1995. </year>
Reference-contexts: Structural abstraction also appears other software targeting structured adaptive finite difference solvers. Rendleman et al. have developed BOXLIB, a library for implementing adaptive meesh refinement on single processor computers [38]. Parashar and Browne employ similar techniques in a DAGH, a software infrastructure for parallel structure adaptive mesh refinement applications <ref> [34] </ref>. KeLP's block-structured inspector/executor implementation is based on concepts introduced in the Multiblock PARTI [1] run time system. Multiblock PARTI supports regular block distributions for dynamic arrays, but does not directly support irregular block decompositions as in systems like KeLP.
Reference: [35] <author> Parsons, R. and Quinlan, D. </author> <title> Run-time recognition of task parallelism within the P++ parallel array class library. </title> <booktitle> Proceedings of the Scalable Parallel Libraries Conference. </booktitle> <publisher> IEEE Comput. Soc. Press, Los Alamitos, </publisher> <address> CA, </address> <month> Oct. </month> <year> 1994, </year> <pages> pp. 77-86. </pages>
Reference: [36] <author> R.Bennett,, Bryant, K., Sussman, A., Das, R., and Saltz, J. Jovian: </author> <title> A framework for optimizing parallel I/O. </title> <booktitle> Proc. 1994 Scalable Parallel Libraries Conference. IEEE Comp. </booktitle> <publisher> Soc. Press, Los Alamitos, </publisher> <address> CA, </address> <year> 1994, </year> <pages> pp. 10-20. </pages>
Reference-contexts: PETSc provides first-class objects to represent index sets that describe gather/scatter operations, and performs inspector/executor analysis of communication patterns. PETSc does not support irregular grid collections nor irregular partitionings of rectangular domains. Run-time scheduled communication mechanisms have proven useful in several other contexts. The PASSION [14] and Jovian <ref> [36] </ref> systems pre-process communication patterns to optimize parallel I/O. Communication schedules have traditionally been considered for message-passing architectures. However, recent work [32, 17] has shown that inspector/executor techniques may be necessary to achieve good performance on distributed shared-memory architectures as well.
Reference: [37] <author> Reinhardt, S. K., Larus, J. R., and Wood, D. A. Typhoon and tempest: </author> <title> User-level shared memory. </title> <booktitle> Proceedings of the 21st Annual International Symposium on Computer Architecture. </booktitle> <publisher> IEEE Comput. Soc. Press, Los Alamitos, </publisher> <address> CA, </address> <year> 1994, </year> <pages> pp. 325-36. </pages>
Reference-contexts: The PASSION [14] and Jovian [36] systems pre-process communication patterns to optimize parallel I/O. Communication schedules have traditionally been considered for message-passing architectures. However, recent work [32, 17] has shown that inspector/executor techniques may be necessary to achieve good performance on distributed shared-memory architectures as well. Tempest <ref> [37] </ref> allows the programmer to write application-specific communication protocols for a distributed shared-memory architecture. One interesting Tempest protocol builds a communication schedule transparently, and reuses it where appropriate. 18 to appear in J.
Reference: [38] <author> Rendleman, C., Bell, V. B. J., Crutchfield, B., Howell, L., and Welcome, M. </author> <title> Boxlib users guide and manual: A library for managing rectangular domains. edition 1.99. </title> <type> Technical report, </type> <institution> Center for Computational Science and Engineering, Lawrence Livermore National Laboratory, </institution> <year> 1995. </year>
Reference-contexts: However, when communication dependences can be computed beforehand, run-time preprocessing can significantly reduce communication overheads and synchronization. Structural abstraction also appears other software targeting structured adaptive finite difference solvers. Rendleman et al. have developed BOXLIB, a library for implementing adaptive meesh refinement on single processor computers <ref> [38] </ref>. Parashar and Browne employ similar techniques in a DAGH, a software infrastructure for parallel structure adaptive mesh refinement applications [34]. KeLP's block-structured inspector/executor implementation is based on concepts introduced in the Multiblock PARTI [1] run time system.
Reference: [39] <author> Snyder, L. </author> <title> Foundations of practical parallel programming languages. </title> <editor> In Volkert, J. (Ed.). </editor> <booktitle> Parallel Computation. Second International ACPC Conference Proceedings. </booktitle> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1993, </year> <pages> pp. </pages> <month> 115-34. </month> <title> 23 to appear in J. Parallel and Distributed Computing a) b) Example of inter-level transfer operations required for structured adaptive mesh refinement. [40] van de Geign, </title> <editor> R. and Watts, J. SUMMA: </editor> <title> Scalable universal matrix multiplication algorithm. </title> <type> Technical Report TR-95-13, </type> <institution> Department of Computer Sciences, University of Texas, Austin, TX, </institution> <month> April </month> <year> 1995. </year>
Reference-contexts: Section 4 discusses the implementation. Section 5 presents performance results for various applications. Section 6 discusses related work and Section 7 summarizes the results. 2 Programming Model KeLP's programming model relies on two levels of control flow, resembling the X and Y program levels in Snyder's Phase Abstractions model <ref> [39] </ref>. Programs begin with a single logical thread of control. Periodically, the KeLP program enters a for all loop in which each loop iteration executes independently on exactly one SPMD process (Figure 2). 4 to appear in J.

References-found: 39

