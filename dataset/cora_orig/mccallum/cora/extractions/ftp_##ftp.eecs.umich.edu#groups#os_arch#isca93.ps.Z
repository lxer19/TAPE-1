URL: ftp://ftp.eecs.umich.edu/groups/os_arch/isca93.ps.Z
Refering-URL: http://www.eecs.umich.edu/UMichMP/NT/papers.html
Root-URL: http://www.cs.umich.edu
Title: Abstract  
Keyword: 50%. Keywords: T ranslation Lookaside Buffer (TLB), Simulation, Hardware Monitoring, Operating Systems.  
Abstract: An increasing number of architectures provide virtual memor y support thr ough softwar emanaged TLBs. However , softwar e management can impose considerable penalties, which are highly dependent on the operating system s structure and its use of vir - tual memor y. This work explor es softwar emanaged TLB design tradeoffs and their interaction with a range of operating systems including monolithic and microkernel designs. Through hardware monitoring and simulation, we explor e TLB performance for benchmarks r unning on a MIPS R2000-based workstation r un Results: New operating systems ar e changing the r elative fr e-quency of different types of TLB misses, some of which may not be efficiently handled by current architectures. For the same application binaries, total TLB ser vice time varies by as much as an order of magnitude under differ ent operating systems. Reducing the handling cost for kernel TLB misses reduces total TLB service time up to 40%. For TLBs between 32 and 128 slots, each doubling of the TLB size reduces total TLB service time by as much as ning Ultrix, OSF/1, and three versions of Mach 3.0. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Kane, G. and J. Heinrich, </author> <title> MIPS RISC Architecture Prentice-Hall, </title> <publisher> Inc. </publisher>
Reference-contexts: 1 Introduction Many computers support virtual memory by providing hardware-managed translation lookaside buf fers (TLBs). However , some computer architectures, including the MIPS RISC <ref> [1] </ref> and the DEC Alpha [2], have shifted TLB management responsibility into the operating system. These software-managed TLBs can simplify hardware design and provide greater exibility in page table structure, but typically have slower refi ll times than hardware managed TLBs [3]. <p> To regain the lost TLB performance, the architecture could vector all L1K misses through the uTLB handler, as is done in the newer R4000 processor . Based on our timing and analysis of the 1. The newer MIPS R4000 processor <ref> [1] </ref> implements both of these changes.
Reference: [2] <author> Digital, </author> <title> Alpha Architecture Handbook . 1992, </title> <institution> USA: Digital Equipment Corporation. </institution>
Reference-contexts: 1 Introduction Many computers support virtual memory by providing hardware-managed translation lookaside buf fers (TLBs). However , some computer architectures, including the MIPS RISC [1] and the DEC Alpha <ref> [2] </ref>, have shifted TLB management responsibility into the operating system. These software-managed TLBs can simplify hardware design and provide greater exibility in page table structure, but typically have slower refi ll times than hardware managed TLBs [3].
Reference: [3] <author> DeMoney, M., J. Moore, and J. Mashey. </author> <title> Operating system support on a RISC COMPCON </title>
Reference-contexts: These software-managed TLBs can simplify hardware design and provide greater exibility in page table structure, but typically have slower refi ll times than hardware managed TLBs <ref> [3] </ref>. Design Tradeoffs for Software-Managed TLBs David Nagle, Richard Uhlig, Tim Stanley, Stuart Sechrest, Trevor Mudge & Richard Brown Department of Electrical Engineering and Computer Science University of Michigan email: uhlig@eecs.umich.edu, bassoon@eecs.umich.edu Presented at the IEEE/ACM 20th Annual International Sympo sium on Computer Architecture, May 1993. IEEE 1993. <p> Yet, few studies have examined these effects, with most confined to a single operating system <ref> [3, 5] </ref>. However, differences between operating systems can be substantial. To illustrate this point, we ran our benchmark suite on each of the operating systems listed in Table 1. <p> The R2000 supports two different types of TLB miss vectors. The first, called the user TLB (uTLB) vector , is used to trap on missing translations for L1U pages. This vector is justifi ed by the fact TLB misses on L1U PTEs are typically the most frequent <ref> [3] </ref>. All other TLB miss types (such as those caused by references to kernel pages, invalid pages or read-only pages) and all other interrupts and exceptions trap to a second vector, called the generic exception vector. <p> However , before suggesting changes, it is helpful to consider the motivations behind the design of the R2000 TLB. The MIPS R2000 TLB design is based on two principal assumptions <ref> [3] </ref>. First, L1U misses are assumed to be the most frequent (&gt; 95%) of all TLB miss types. Second, all OS text and most of the OS data structures (with the exception of user page tables) are assumed to be unmapped. <p> The 8 lower slots are intended to accommodate a traditional UNIX task (which requires at least three L2 PTEs) and UNIX kernel (2 PTEs for kernel data), with three L2 PTEs left for additional data segments <ref> [3] </ref>. Our measurements ( Table 5 ) demonstrate that these design choices make sense for a traditional UNIX operating system such as Ultrix. For Ultrix, L1U misses constitute 98.3% of all misses. The remaining miss types impose only a small penalty . <p> This partitioning is appropriate for an operating system like Ultrix <ref> [3] </ref>. However , as OS designs migrate and decompose functionality into separate user space tasks, having only 8 lower slots becomes insuf ficient.
Reference: [4] <author> Accetta, M., ach: </author> <title> A new kernel foundation for UNIX development Summer 1986 USENIX Conference 1986. </title> <booktitle> USENIX. </booktitle>
Reference-contexts: IEEE 1993. This work was supported by Defense Advanced Research Projects Agency under DARP A/ARO Contract Number DAAL03-90-C 0028 and a National Science Foundation Graduate Fellowship. At the same time, operating systems such as Mach 3.0 <ref> [4] </ref> are moving functionality into user processes and making greater use of virtual memory for mapping data structures held within the kernel. These and related operating system trends place greater stress upon the TLB by increasing miss rates and, hence, decreasing overall system performance. <p> Many of these services, however , can be moved into separate server tasks, increasing the modularity and extensibility of the operating system [8]. For this reason, numerous microkernel-based operating systems have been developed in recent years (e.g. Chorus [19], Mach 3.0 <ref> [4] </ref>, V [20]). By migrating these services into separate user level tasks, operating systems like Mach 3.0 fundamentally change the behavior of the system for two reasons. First, moving OS services into user space requires both their program text and data structures to be mapped.
Reference: [5] <author> Clark, D.W . and J.S. </author> <title> Emer , Performance of the V AX-11/780 translation buffer: Simulation and measur ement. </title> <journal> ACM Transactions on Computer Systems, </journal> <year> 1985. </year> <pages> 31-62. </pages>
Reference-contexts: In their 1985 study, Clark and Emer examined the cost of hardware TLB management by monitoring a VAX-11/780. For their workloads, 5% to 8% of a user programs run time was spent handling TLB misses <ref> [5] </ref>. More recent papers have investigated the TLBs impact on user program performance. Chen, Bor g and Jouppi [6], using traces generated from the SPEC benchmarks, determined that the amount of physical memory mapped by the TLB is strongly linked to the TLB miss rate. <p> Code annotation tools like pixie [13] or AE [14] generate user level address traces for a single task. However, more complex tools are required in order to obtain realistic systemwide address traces that account for multiprocess workloads and the operating system itself <ref> [5, 15] </ref>. Second, trace-driven simulation can consume considerable processing and stor - age resources. Some researchers have overcome the storage resource problem by consuming traces on-the- y [6, 15]. <p> Yet, few studies have examined these effects, with most confined to a single operating system <ref> [3, 5] </ref>. However, differences between operating systems can be substantial. To illustrate this point, we ran our benchmark suite on each of the operating systems listed in Table 1.
Reference: [6] <author> Chen, J.B., A. Borg, </author> <title> and N.P. Jouppi. </title> <booktitle> A simulation based study of TLB performance The 19th Annual International Symposium on Computer Architecture . 1992. </booktitle> <address> Gold Coast, Australia: </address> <publisher> IEEE. </publisher>
Reference-contexts: For their workloads, 5% to 8% of a user programs run time was spent handling TLB misses [5]. More recent papers have investigated the TLBs impact on user program performance. Chen, Bor g and Jouppi <ref> [6] </ref>, using traces generated from the SPEC benchmarks, determined that the amount of physical memory mapped by the TLB is strongly linked to the TLB miss rate. <p> Second, trace-driven simulation can consume considerable processing and stor - age resources. Some researchers have overcome the storage resource problem by consuming traces on-the- y <ref> [6, 15] </ref>. This technique requires that system operation be suspended for extended periods of time while the trace is processed, thus introducing distortion at regular intervals. Third, tracedriven simula tion assumes that address traces are invariant to changes in the structural parameters or management policies of a simulated TLB. <p> Of course, even larger TLBs may be needed to support lar ge applications such as CAD programs. However, this study is limited to TLB support for operating systems running a modest workload. The reader is referred to <ref> [6] </ref> for a detailed discussion of TLB support for lar ge applications. 0 20 40 60 80 100 Time (sec) Number of Upper Slots Other L3 L1U Slots The total cost of TLB miss servicing for all seven benchmarks run under OSF/1.
Reference: [7] <author> Talluri, M., </author> <booktitle> radeoffs in suppor ting two page sizes in The 19th Annual International Symposium on Computer Architecture . 1992. </booktitle> <address> Gold Coast, Australia: </address> <publisher> IEEE. </publisher>
Reference-contexts: For a reasonable range of page sizes, the amount of the address space that could be mapped was more important than the page size chosen. Talluri et al. <ref> [7] </ref> have shown that although older TLBs (as in the VAX-11/780) mapped lar ge regions of memory, TLBs in newer architectures like the MIPS do This paper was pr esented at the 20th International Symposium on Computer Architecture, San Diego, California, May 1993 (pages 27-38) not. <p> The MIPS R4000 actually has 48 double slots. Two PTEs can reside in one double slot if their virtual mappings are to consecutive pages in the vir tual address space. <ref> [7] </ref> I I 32 64 128 256 512 5 15 25 Total Time (sec) Number of Upper Slots 2-way 8-way I Full mpeg_play under Mach3+AFSout video_play under Mach 3.0 compress under OSF/1 I 32 64 128 256 512 20 60 100 140 Total Time (sec) Number of Upper Slots 2-way 8-way
Reference: [8] <author> Anderson, T.E., </author> <title> he interaction of ar chitecture and operating system design Fourth International Confer - ence on Architectural Suppor t for Pr ogramming Languages and Operating Systems . 1991. </title> <address> Santa Clara, California: </address> <publisher> ACM. </publisher>
Reference-contexts: Several recent papers [8-10] have pointed out that changes in the structure of operating systems are altering the utilization of the TLB. For example, Anderson et al. <ref> [8] </ref> compared an old-style monolithic operating system (Mach 2.5) and a newer microkernel operating system (Mach 3.0), and found a 600% increase in TLB misses requiring a full kernel entry . Kernel TLB misses were far and away the most frequently invoked system primitive for the Mach 3.0 kernel. <p> Many of these services, however , can be moved into separate server tasks, increasing the modularity and extensibility of the operating system <ref> [8] </ref>. For this reason, numerous microkernel-based operating systems have been developed in recent years (e.g. Chorus [19], Mach 3.0 [4], V [20]). By migrating these services into separate user level tasks, operating systems like Mach 3.0 fundamentally change the behavior of the system for two reasons. <p> Operating system functionality can be further decomposed into individual server tasks. The resulting system is more exible and can provide a higher degree of fault tolerance. Unfortunately, experience with fully decomposed systems has shown severe performance problems. Anderson et al. <ref> [8] </ref> com pared the performance of a monolithic Mach 2.5 and a microker - nel Mach 3.0 operating system with a substantial portion of the file system functionality running as a separate AFS cache manager task. Their results demonstrate a signifi cant performance gap 1.
Reference: [9] <author> Ousterhout, J., </author> <title> Why aren't operating systems getting faster as fast as hardware? WRL Technical Note, </title> <year> 1989. </year> <month> (TN-11). </month>
Reference-contexts: IOzone A sequential fi le I/O benchmark that writes and then reads a 10 Megabyte file. Written by Bill Nor cott. jpeg_play xloadimage program written by Jim Frost. Displays four JPEG images. John Ousterhout s Modifi ed Andrew Benchmark <ref> [9] </ref>. mpeg_play mpeg_play V2.0 from the Berkeley Plateau Research Group. Displays 610 frames from a compressed video file [23]. ousterhout John Ousterhouts benchmark suite from [9]. video_play A modifi ed version of mpeg_play that displays 610 frames from an uncompressed video file. <p> Written by Bill Nor cott. jpeg_play xloadimage program written by Jim Frost. Displays four JPEG images. John Ousterhout s Modifi ed Andrew Benchmark <ref> [9] </ref>. mpeg_play mpeg_play V2.0 from the Berkeley Plateau Research Group. Displays 610 frames from a compressed video file [23]. ousterhout John Ousterhouts benchmark suite from [9]. video_play A modifi ed version of mpeg_play that displays 610 frames from an uncompressed video file. Operating System Description Ultrix Version 3.1 from Digital Equipment Corporation. OSF/1 OSF/1 1.0 is the Open Software Foundations ver sion of Mach 2.5.
Reference: [10] <author> Welch, B. </author> <title> T he fi le system belongs in the kernel USENIX Mach Symposium Pr oceedings . 1991. </title> <address> Monterey, California: </address> <publisher> USENIX. </publisher>
Reference: [11] <author> Nagle, D., R. Uhlig, and T. Mudge, </author> <title> Monster: A tool for analyzing the interaction between operating systems and computer ar chitectures . 1992, </title> <institution> The University of Michi-gan. </institution>
Reference-contexts: Monster is comprised of a monitored DECstation 3100 attached logic analyzer and a controlling workstation. Monster s capabilities are described more completely in <ref> [11] </ref>. In this study, we used Monster to obtain the TLB miss handling costs by instrumenting each OS kernel with marker instructions that denoted the entry and exit points of various code segments (e.g. kernel entry , TLB miss handler , kernel exit).
Reference: [12] <author> Alexander, C.A., W.M. Keshlear , and F. Briggs, </author> <title> Translation buffer performance in a UNIX envir onment. Computer Architecture News, </title> <year> 1985. </year>
Reference-contexts: than can be obtained using a system clock with its coarser resolution or, as is often done, by repeating a code fragment N times and then dividing the total time spent by N. 3.2 TLB Simulation with Tapeworm Many previous TLB studies have used tracedriven simulation to explore design tradeoffs <ref> [5-7, 12] </ref>. However , there are a number of difficulties with tracedriven TLB simulation. First, it is dif fi-cult to obtain accurate traces. Code annotation tools like pixie [13] or AE [14] generate user level address traces for a single task.
Reference: [13] <institution> MIPS Computer Systems, I., </institution> <note> RISCompiler Languages Programmer's Guide . 1988, MIPS. </note>
Reference-contexts: However , there are a number of difficulties with tracedriven TLB simulation. First, it is dif fi-cult to obtain accurate traces. Code annotation tools like pixie <ref> [13] </ref> or AE [14] generate user level address traces for a single task. However, more complex tools are required in order to obtain realistic systemwide address traces that account for multiprocess workloads and the operating system itself [5, 15].
Reference: [14] <author> Larus, J.R., </author> <title> Abstract Execution: A technique for effi ciently tracing pr ograms . 1990, </title> <institution> University of Wisconsin-Madi son. </institution>
Reference-contexts: However , there are a number of difficulties with tracedriven TLB simulation. First, it is dif fi-cult to obtain accurate traces. Code annotation tools like pixie [13] or AE <ref> [14] </ref> generate user level address traces for a single task. However, more complex tools are required in order to obtain realistic systemwide address traces that account for multiprocess workloads and the operating system itself [5, 15]. Second, trace-driven simulation can consume considerable processing and stor - age resources.
Reference: [15] <author> Agarwal, A., J. Hennessy, and M. Horowitz, </author> <title> Cache perfor mance of operating system and multipr ogramming work-loads. </title> <journal> ACM Transactions on Computer Systems, 1988. </journal> <volume> (Number 4): </volume> <pages> p. 393-431. </pages>
Reference-contexts: Code annotation tools like pixie [13] or AE [14] generate user level address traces for a single task. However, more complex tools are required in order to obtain realistic systemwide address traces that account for multiprocess workloads and the operating system itself <ref> [5, 15] </ref>. Second, trace-driven simulation can consume considerable processing and stor - age resources. Some researchers have overcome the storage resource problem by consuming traces on-the- y [6, 15]. <p> Second, trace-driven simulation can consume considerable processing and stor - age resources. Some researchers have overcome the storage resource problem by consuming traces on-the- y <ref> [6, 15] </ref>. This technique requires that system operation be suspended for extended periods of time while the trace is processed, thus introducing distortion at regular intervals. Third, tracedriven simula tion assumes that address traces are invariant to changes in the structural parameters or management policies of a simulated TLB.
Reference: [16] <author> McKusick, </author> <title> M.K., A fast file system for UNIX. </title> <journal> ACM Transactions on Computer Systems, </journal> <year> 1984. </year> <month> 197. </month>
Reference-contexts: Each of these systems includes a standard UNIX fi le system (UFS) <ref> [16] </ref>. Two additional versions of Mach 3.0 include the Andrew file system (AFS) cache manager [17]. One version places the AFS cache manager in the Mach Unix Server while the other migrates the AFS cache manager into a separate server task.
Reference: [17] <author> Satyanarayanan, M., </author> <title> Scalable, secur e, and highly available distributed fi le access. </title> <booktitle> IEEE Computer, 1990. p. </booktitle> <pages> 9-21. </pages>
Reference-contexts: Each of these systems includes a standard UNIX fi le system (UFS) [16]. Two additional versions of Mach 3.0 include the Andrew file system (AFS) cache manager <ref> [17] </ref>. One version places the AFS cache manager in the Mach Unix Server while the other migrates the AFS cache manager into a separate server task. To obtain measurements, all of the operating systems were instrumented with counters and markers.
Reference: [18] <author> Rashid, R., </author> <title> Machine-independent vir tual memor y management for paged unipr ocessor and multipr ocessor architectures. </title> <journal> IEEE Transactions on Computers, </journal> <year> 1988. </year>
Reference-contexts: Each task has its own level 1 (L1) page table, which is maintained by machine-independent pmap code <ref> [18] </ref>. Because the user page tables can require several megabytes of space, they are themselves stored in the virtual address space. This is supported through level 2 (L2 or kernel) page tables, which also map other kernel data.
Reference: [19] <author> Dean, R.W. and F. </author> <title> Armand. Data movement in kernelized systems Micro-kernels and Other Kernel Architectures 1991. </title> <address> Seattle, Washington: </address> <publisher> USENIX. </publisher>
Reference-contexts: Many of these services, however , can be moved into separate server tasks, increasing the modularity and extensibility of the operating system [8]. For this reason, numerous microkernel-based operating systems have been developed in recent years (e.g. Chorus <ref> [19] </ref>, Mach 3.0 [4], V [20]). By migrating these services into separate user level tasks, operating systems like Mach 3.0 fundamentally change the behavior of the system for two reasons. First, moving OS services into user space requires both their program text and data structures to be mapped.
Reference: [20] <author> Cheriton, </author> <title> D.R., The V kernel: A software base for distrib uted systems. </title> <journal> IEEE Software, </journal> <year> 1984. </year>
Reference-contexts: Many of these services, however , can be moved into separate server tasks, increasing the modularity and extensibility of the operating system [8]. For this reason, numerous microkernel-based operating systems have been developed in recent years (e.g. Chorus [19], Mach 3.0 [4], V <ref> [20] </ref>). By migrating these services into separate user level tasks, operating systems like Mach 3.0 fundamentally change the behavior of the system for two reasons. First, moving OS services into user space requires both their program text and data structures to be mapped.
Reference: [21] <author> Uhlig, R., </author> <booktitle> Software TLB management in OSF/1 and Mach 3.0 . 1993, </booktitle> <institution> University of Michigan. </institution>
Reference-contexts: The PTE replacement policy is FIFO for the lower slots and Random for the upper slots. The PTE placement policy stores L2 PTEs in the lower slots and all other PTEs in the upper slots. The effectiveness of these and other software-based techniques are examined in a related work <ref> [21] </ref>. 5.1 Additional TLB Miss Vectors The data in Table 5 show a signifi cant increase in L1K misses for OSF/1 and Mach 3.0 when compared against Ultrix. This increase is due to both systems reliance on dynamic allocation of kernel mapped memory .
Reference: [22] <author> Heald, R.A. and J.C. Holst. </author> <title> 6ns cycle 256 kb cache memory and memor y management unit IEEE International SolidState Circuits Conference . 1993. </title> <address> San Francisco, CA: </address> <publisher> IEEE. </publisher>
Reference-contexts: These three graphs show that reducing associativity to enable the construction of lar ger TLBs is an ef fective technique for reducing TLB misses. 1. Current-mode sensing avoids some of the problems associated with large CMOS CAMs <ref> [22] </ref>.
Reference: [23] <author> Patel, K., B.C. Smith, and L.A. Rowe, </author> <title> Performance of a software MPEG video decoder . 1992, </title> <institution> University of Cali-fornia, Berkeley. </institution>
Reference-contexts: Written by Bill Nor cott. jpeg_play xloadimage program written by Jim Frost. Displays four JPEG images. John Ousterhout s Modifi ed Andrew Benchmark [9]. mpeg_play mpeg_play V2.0 from the Berkeley Plateau Research Group. Displays 610 frames from a compressed video file <ref> [23] </ref>. ousterhout John Ousterhouts benchmark suite from [9]. video_play A modifi ed version of mpeg_play that displays 610 frames from an uncompressed video file. Operating System Description Ultrix Version 3.1 from Digital Equipment Corporation. OSF/1 OSF/1 1.0 is the Open Software Foundations ver sion of Mach 2.5.
Reference: [24] <author> Patterson, D. and Hennessy , J., </author> <title> Computer ar chitecture A quantitative appr oach . 1990. </title> <publisher> Mor gan Kaufmann Publishers, </publisher> <address> Inc.San Mateo, California. </address>
Reference-contexts: Throughout the range of TLB sizes, increasing associativity reduces the total TLB handling time. These figures illustrate the general rule-of-thumb that doubling the size of a caching structure will yield about the same performance as doubling the degree of associativ ity <ref> [24] </ref>. Some benchmarks, however, can perform badly for TLBs with a small degree of set associativity. For example, the bottom graph in Figure 9 shows the total TLB miss handling time for the press benchmark under OSF/1. For a 2-way set-associative TLB, compress displays pathological behavior .
References-found: 24

