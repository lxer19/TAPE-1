URL: http://www.cs.umd.edu/users/debanjan/psfiles/infocom98c.ps
Refering-URL: http://www.cs.umd.edu/users/debanjan/pages/onepage.html
Root-URL: 
Email: frengel,kandlur,debanjang@watson.ibm.com  ashish@eecs.umich.edu  
Title: Exploring the Performance Impact of QoS Support in TCP/IP Protocol Stacks  
Author: Robert Engely, Dilip Kandlury, Ashish Mehraz and Debanjan Sahay 
Address: 30 Saw Mill River Rd Hawthorne, NY 10532  Ann Arbor, MI 48109  
Affiliation: yIBM T.J. Watson Research Center  zReal-Time Computing Lab Department of EECS The University of Michigan  
Abstract: Significant efforts are being made by the Internet Engineering Task Force (IETF) to enhance the service model of the Internet to support integrated services for voice, video, and data transport. This is being done via a new resource reservation protocol (RSVP) and associated service classes for handling of traffic at network routers and end hosts. Given that the new service model is expected to be widely deployed and utilized, it is important to understand its performance impact on hosts and routers. This paper explores the performance impact of supporting QoS guarantees on communication in TCP/IP protocol stacks at end hosts, in the context of an RSVP-based QoS architecture developed and implemented earlier by the authors. We first demonstrate the efficacy of the architecture in providing the desired QoS to individual connections via application-level experiments on an ATM network. In these experiments we show the impact of our architecture on UDP sessions and TCP connections. We then identify and measure, via detailed kernel-based profiling, the overheads imposed by all components comprising the QoS support provided, such as traffic policing, traffic shaping, and buffer management. Our measurements reveal that traffic policing overheads are largely offset by savings due to per-session buffer pre-allocation, and, for ATM networks, a faster path through the network interface layer. In the latter case the data path latency for compliant packets can even be slightly smaller than the default best-effort data path latency. Traffic shaping presents more challenges, primarily because of interactions with the operating system CPU scheduler. We discuss the performance implications of traffic shaping and suggest techniques to reduce or mask some of the associated overheads. fl This work was performed while visiting the IBM T.J. Watson Research Center.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. Braden, D. Clark, and S. Shenker, </author> <title> "Integrated services in the Internet architecture: An overview", Request for Comments RFC 1633, </title> <month> July </month> <year> 1994, </year> <note> Xerox PARC. </note>
Reference-contexts: Significant efforts are being made by the Internet Engineering Task Force (IETF) to enhance the service model of the Internet to support integrated services for voice, video, and data transport <ref> [1] </ref>. This in turn implies that the existing communication subsystems running TCP/IP protocol stacks in Internet hosts be modified for QoS-sensitive traffic handling according to integrated services standards. <p> In the IETF's vision, applications request and reserve resources in the network and at end hosts using an end-to-end receiver-initiated Resource ReSerVation Protocol (RSVP) [2, 3]. Resource management is performed via per-flow traffic shaping and scheduling for various service classes <ref> [1] </ref>, such as guaranteed service [4] and controlled load service [5]. The guaranteed service is intended for applications requiring firm guarantees on loss-less on-time datagram delivery. <p> Our work builds upon and relates to several recent research efforts, as discussed below. Integrated Services on the Internet: The service model for integrated services on the Internet and expected requirements of applications are discussed in <ref> [26, 1, 27] </ref>. and the service classes under consideration by the IETF outlined in [4, 5].
Reference: [2] <author> L. Zhang, S. Deering, D. Estrin, S. Shenker, and D. Zappala, "RSVP: </author> <title> A new resource ReSerVation Protocol", </title> <journal> IEEE Network, </journal> <pages> pp. 8-18, </pages> <month> September </month> <year> 1993. </year>
Reference-contexts: In the IETF's vision, applications request and reserve resources in the network and at end hosts using an end-to-end receiver-initiated Resource ReSerVation Protocol (RSVP) <ref> [2, 3] </ref>. Resource management is performed via per-flow traffic shaping and scheduling for various service classes [1], such as guaranteed service [4] and controlled load service [5]. The guaranteed service is intended for applications requiring firm guarantees on loss-less on-time datagram delivery.
Reference: [3] <author> R. Braden, L. Zhang, S. Berson, S. Herzog, and S. Jamin, </author> <title> "Resource ReSerVation Protocol (RSVP) version 1 functional specification", Internet Draft draft-ietf-rsvp-spec-12.txt, </title> <month> May </month> <year> 1996, </year> <month> ISI/PARC/USC. </month>
Reference-contexts: In the IETF's vision, applications request and reserve resources in the network and at end hosts using an end-to-end receiver-initiated Resource ReSerVation Protocol (RSVP) <ref> [2, 3] </ref>. Resource management is performed via per-flow traffic shaping and scheduling for various service classes [1], such as guaranteed service [4] and controlled load service [5]. The guaranteed service is intended for applications requiring firm guarantees on loss-less on-time datagram delivery.
Reference: [4] <author> S. Shenker, C. Partridge, and Roch Guerin, </author> <title> "Specification of guaranteed quality of service", Internet Draft draft-ietf-intserv-guaranteed-svc-04.txt, </title> <month> June </month> <year> 1996, </year> <month> Xerox/BBN/IBM. </month>
Reference-contexts: In the IETF's vision, applications request and reserve resources in the network and at end hosts using an end-to-end receiver-initiated Resource ReSerVation Protocol (RSVP) [2, 3]. Resource management is performed via per-flow traffic shaping and scheduling for various service classes [1], such as guaranteed service <ref> [4] </ref> and controlled load service [5]. The guaranteed service is intended for applications requiring firm guarantees on loss-less on-time datagram delivery. <p> Integrated Services on the Internet: The service model for integrated services on the Internet and expected requirements of applications are discussed in [26, 1, 27]. and the service classes under consideration by the IETF outlined in <ref> [4, 5] </ref>. Various issues in supporting quality of service in IP-ATM networks are also being examined [28, 29, 30], including the use of RSVP for end-to-end signaling across ATM networks [31] and for integrated services using RSVP over ATM [32].
Reference: [5] <author> John Wroclawski, </author> <title> "Specification of controlled-load network element service", Internet Draft draft-ietf-intserv-ctrl-load-svc-02.txt, </title> <address> June 1996, </address> <publisher> MIT. </publisher>
Reference-contexts: Resource management is performed via per-flow traffic shaping and scheduling for various service classes [1], such as guaranteed service [4] and controlled load service <ref> [5] </ref>. The guaranteed service is intended for applications requiring firm guarantees on loss-less on-time datagram delivery. <p> Integrated Services on the Internet: The service model for integrated services on the Internet and expected requirements of applications are discussed in [26, 1, 27]. and the service classes under consideration by the IETF outlined in <ref> [4, 5] </ref>. Various issues in supporting quality of service in IP-ATM networks are also being examined [28, 29, 30], including the use of RSVP for end-to-end signaling across ATM networks [31] and for integrated services using RSVP over ATM [32].
Reference: [6] <author> Tsipora Barzilai, Dilip Kandlur, Ashish Mehra, Debanjan Saha, and Steve Wise, </author> <title> "Design and implementation of an RSVP-based quality of service architecture for integrated services Internet", </title> <booktitle> in Proc. Int'l Conf. on Distributed Computing Systems, </booktitle> <month> May </month> <year> 1997. </year>
Reference-contexts: In earlier work we have designed and implemented architectural extensions to the sockets-based communication subsystem that enable RSVP-based integrated services infrastructure in the Internet <ref> [6] </ref>. One of the primary goals of our service architecture is to blend the QoS support with the existing TCP/IP stack and socket API, preserving the structure of the Unix networking subsystem. <p> Finally, Section 7 concludes the paper. 2 Architectural Overview and QoS Components We now give an overview of the RSVP-based QoS architecture for end hosts, and the components that comprise this architecture. Additional details on the internals of the architecture can be found in <ref> [6] </ref>. are using rsvp signaling for resource reservation. The applications use an rsvp api (rapi) library to communicate with the rsvp daemon running on the host. The rsvp daemon is responsible for translating the rapi calls into rsvp signaling messages and local resource management function calls. <p> If the attached nic does not support QoS functions, as in legacy Ethernet and Token Ring networks, ndd extensions are required to support per-connection QoS via packet queueing and scheduling <ref> [6] </ref>. For a packet associated with a reservation, the socket layer obtains a buffer by calling qos alloc (), which transfers control to the QOSMGR. It first checks whether the application has enabled policing for that reservation (by setting the police flag) (step 1). <p> Coupled with an appropriate buffer management policy, the variations in the scheduling delay can also be accommodated. As mentioned in Section 2, for legacy nics with appropriate queueing and scheduling supported by the ndd, datalink-level shaping serves as an alternative to session-level shaping <ref> [6] </ref>. With datalink-level scheduling, the packet scheduler operates in a non work-conserving fashion, injecting compliant packets into the network either in the context of an executing application thread, or on receipt of a transmission-complete interrupt notification for the previous packet transmission.
Reference: [7] <author> David Mosberger, Larry L. Peterson, Patrick G. Bridges, and Sean O'Malley, </author> <title> "Analysis of techniques to improve protocol processing latency", </title> <booktitle> in Proc. of ACM SIGCOMM, </booktitle> <pages> pp. 73-84, </pages> <month> October </month> <year> 1996. </year>
Reference-contexts: Protocol stack performance and optimizations of existing implementations has been the subject of numerous research articles, including some very recent ones <ref> [7, 8, 9] </ref>. However, all these studies focus on the traditional best 1 We are primarily concerned with servers, and hence the data transmission path. 2 effort data path. <p> Furthermore, the decision to shape traffic on a particular reservation is based on the service class of that reservation. Protocol Processing and Data Transfer Optimizations: Several recent efforts have focused on optimizing the performance of the data transfer path in TCP/IP protocol stacks, including protocol processing latency <ref> [7, 8, 9] </ref> and user-level handling of network data [35, 36, 37, 38, 39] to increase throughput via data copy minimization.
Reference: [8] <author> Trevor Blackwell, </author> <title> "Speeding up protocols for small messages", </title> <booktitle> in Proc. of ACM SIGCOMM, </booktitle> <pages> pp. 85-95, </pages> <month> October </month> <year> 1996. </year>
Reference-contexts: Protocol stack performance and optimizations of existing implementations has been the subject of numerous research articles, including some very recent ones <ref> [7, 8, 9] </ref>. However, all these studies focus on the traditional best 1 We are primarily concerned with servers, and hence the data transmission path. 2 effort data path. <p> Furthermore, the decision to shape traffic on a particular reservation is based on the service class of that reservation. Protocol Processing and Data Transfer Optimizations: Several recent efforts have focused on optimizing the performance of the data transfer path in TCP/IP protocol stacks, including protocol processing latency <ref> [7, 8, 9] </ref> and user-level handling of network data [35, 36, 37, 38, 39] to increase throughput via data copy minimization.
Reference: [9] <author> Robbert van Renesse, </author> <title> "Masking the overhead of protocol layering", </title> <booktitle> in Proc. of ACM SIGCOMM, </booktitle> <pages> pp. 96-104, </pages> <month> October </month> <year> 1996. </year>
Reference-contexts: Protocol stack performance and optimizations of existing implementations has been the subject of numerous research articles, including some very recent ones <ref> [7, 8, 9] </ref>. However, all these studies focus on the traditional best 1 We are primarily concerned with servers, and hence the data transmission path. 2 effort data path. <p> Furthermore, the decision to shape traffic on a particular reservation is based on the service class of that reservation. Protocol Processing and Data Transfer Optimizations: Several recent efforts have focused on optimizing the performance of the data transfer path in TCP/IP protocol stacks, including protocol processing latency <ref> [7, 8, 9] </ref> and user-level handling of network data [35, 36, 37, 38, 39] to increase throughput via data copy minimization.
Reference: [10] <author> Dawson Engler and M. Frans Kaashoek, "DPF: </author> <title> Fast, flexible message demultiplexing using dynamic code generation", </title> <booktitle> in Proc. of ACM SIGCOMM, </booktitle> <pages> pp. 53-59, </pages> <month> October </month> <year> 1996. </year>
Reference-contexts: The traffic classification function is thus a statically compiled packet filter, as opposed to a dynamically generated one <ref> [10] </ref>. 2.2 Data Transfer During data transfer on a QoS connection, the socket layer interacts with QOSMGR to obtain a buffer for each packet generated by the application. <p> A general classifier for real-time packet forwarding is described in [40]. Packet filters [41, 42, 43] provide general and flexible classification of incoming packets to application end-points. More recently, dynamic code generation techniques have been applied to realize very efficient packet filters <ref> [10] </ref>. 20 Packet Handling on Reception: While we have focused on the transmission path, for end-to-end QoS packets arriving at a destination host must be classified as above and processed as per their associated QoS.
Reference: [11] <author> David D. Clark and David L. Tennenhouse, </author> <title> "Architectural considerations for a new generation of communication protocols", </title> <booktitle> in Proc. of ACM SIGCOMM, </booktitle> <pages> pp. 200-208, </pages> <month> September </month> <year> 1990. </year>
Reference-contexts: Note that in our architecture, applications output packets to the socket layer. Thus, our architecture is naturally suited to techniques such as application-level framing <ref> [11] </ref> and can be used with protocols such as RTP [12]. For example, it supports user-level fragmentation and protocol processing performed in the application's address space. Accordingly, it is well-suited to multi-threaded multimedia applications that have distinct data generator and data exporter threads.
Reference: [12] <author> H. Schulzrinne, S. Casner, R. Frederick, and Van Jacobson, "RTP: </author> <title> A transport protocol for real-time applications", Request for Comments RFC 1889, </title> <month> January </month> <year> 1996, </year> <note> GMD/Precept Software/PARC/LBNL. </note>
Reference-contexts: Note that in our architecture, applications output packets to the socket layer. Thus, our architecture is naturally suited to techniques such as application-level framing [11] and can be used with protocols such as RTP <ref> [12] </ref>. For example, it supports user-level fragmentation and protocol processing performed in the application's address space. Accordingly, it is well-suited to multi-threaded multimedia applications that have distinct data generator and data exporter threads.
Reference: [13] <author> Netperf Homepage, </author> ", <note> http://www.cup.hp.com/netperf/NetperfPage.html. </note>
Reference-contexts: The QoS Manager may, however, perform traffic policing and shaping to control the buffer usage and handle traffic that is in excess of the specified TSpec. For our experiments we have extended netperf <ref> [13] </ref> to interact with the QOSMGR and create QoS sessions. We have instrumented netperf to permit the creation of sessions with different options for local traffic control and collect user-level statistics for the packet transmission time.
Reference: [14] <author> M. Laubach, </author> <title> "Classical ip and arp over atm", Request for Comments RFC 1577, </title> <month> January </month> <year> 1994, </year> <institution> Hewlett Packard Laboratories. </institution>
Reference-contexts: We first describe the operation of these three mechanisms over an ATM network and contrast them with the default behavior (best effort without reservation and preallocation). Default IP traffic is handled over the ATM network using the Classical IP over ATM standards <ref> [14] </ref>. 9 In order to send IP packets to a destination across the ATM network, a best-effort VC is setup to that destination. It is possible to configure the maximum bandwidth for these connnections, which sets the peak rate for the ATM VC.
Reference: [15] <author> E. Crawly et al., </author> <title> "A framework for integrated services and rsvp over atm", </title> <type> IETF draft, </type> <month> July </month> <year> 1997, </year> <title> Gigapacket Networks. </title>
Reference-contexts: In all our experiments the best effort bandwidth was set to 10 Mb/s. When a reservation is established, a new virtual connection is created using the traffic parameters specified for the reservation using the mapping rules specified in <ref> [15, 16] </ref>. In our implementation, when neither traffic policing nor shaping is requested, the session data is directed to the VC that was created for the session (the session VC).
Reference: [16] <author> Mark W. Garret and Marty Borden, </author> <title> "Interoperation of controlled-load and guaranteed services with atm", </title> <type> IETF draft, </type> <month> March </month> <year> 1997, </year> <note> Bellcore/New Oak Communications. </note>
Reference-contexts: In all our experiments the best effort bandwidth was set to 10 Mb/s. When a reservation is established, a new virtual connection is created using the traffic parameters specified for the reservation using the mapping rules specified in <ref> [15, 16] </ref>. In our implementation, when neither traffic policing nor shaping is requested, the session data is directed to the VC that was created for the session (the session VC).
Reference: [17] <author> Wu-Chang Feng, Dilip Kandlur, Debanjan Saha, and Kang Shin, </author> <title> "Understanding tcp dynamics in an integrated services internet", </title> <booktitle> in Proc. 7th International NOSSDAV Workshop, </booktitle> <month> May </month> <year> 1997. </year>
Reference-contexts: In more complex network scenarios, where the TCP connection crosses several links and the round-trip delay is significant, traffic shaping at the source offers some advantages by presenting a well spaced out flow to the network <ref> [17] </ref>. 4 QoS Component Overheads The results of the previous section demonstrate the efficacy of the QoS architecture in providing QoS to applications.
Reference: [18] <author> Carl Waldspurger, </author> <title> Lottery and Stride Scheduling: Flexible Proportional-Share Resource Management, </title> <type> PhD thesis, Technical Report, </type> <institution> MIT/LCS/TR-667, Laboratory for CS, MIT, </institution> <month> September </month> <year> 1995. </year> <month> 22 </month>
Reference-contexts: The scheduling delay associated with session-level shaping can be largely eliminated (or at least made predictable) by employing QoS-sensitive CPU scheduling policies, as discussed next. 5.2 QoS-Sensitive CPU Scheduling Recently several QoS-sensitive scheduling policies such as stride scheduling <ref> [18] </ref>, proportional share [19], and hierarchical scheduling [20] have been proposed. <p> Similar results can be expected if the queueing discipline used at routers for supporting IP integrated services does not preserve packet ordering. Our work complements recent work on QoS-sensitive CPU scheduling of applications <ref> [18, 19, 20] </ref> and protocol processing [22, 23, 24, 25] at end hosts. While these efforts focus on CPU scheduling, our primary focus is on the QoS support architecture exported to sockets based applications.
Reference: [19] <author> Ion Stoica, Hussein Abdel-Wahab, Kevin Jeffay, Sanjoy K. Baruah, Johannes E. Gehrke, and C. Greg Plaxton, </author> <title> "A proportional share resource allocation algorithm for real-time time-shared systems", </title> <booktitle> in Proc. 17th Real-Time Systems Symposium, </booktitle> <pages> pp. 288-299, </pages> <month> December </month> <year> 1996. </year>
Reference-contexts: The scheduling delay associated with session-level shaping can be largely eliminated (or at least made predictable) by employing QoS-sensitive CPU scheduling policies, as discussed next. 5.2 QoS-Sensitive CPU Scheduling Recently several QoS-sensitive scheduling policies such as stride scheduling [18], proportional share <ref> [19] </ref>, and hierarchical scheduling [20] have been proposed. <p> Similar results can be expected if the queueing discipline used at routers for supporting IP integrated services does not preserve packet ordering. Our work complements recent work on QoS-sensitive CPU scheduling of applications <ref> [18, 19, 20] </ref> and protocol processing [22, 23, 24, 25] at end hosts. While these efforts focus on CPU scheduling, our primary focus is on the QoS support architecture exported to sockets based applications.
Reference: [20] <author> Pawan Goyal, X. Guo, and Harrick M. Vin, </author> <title> "A hierarchical CPU scheduler for multimedia operating systems", </title> <booktitle> in Proc. 2nd OSDI Symposium, </booktitle> <pages> pp. 107-121, </pages> <month> October </month> <year> 1996. </year>
Reference-contexts: The scheduling delay associated with session-level shaping can be largely eliminated (or at least made predictable) by employing QoS-sensitive CPU scheduling policies, as discussed next. 5.2 QoS-Sensitive CPU Scheduling Recently several QoS-sensitive scheduling policies such as stride scheduling [18], proportional share [19], and hierarchical scheduling <ref> [20] </ref> have been proposed. These policies ensure that the CPU is allocated to individual threads in the order of their associated QoS requirements and at the granularity of a certain quantum, i.e., each thread executes at the most for a quantum each time it is selected to run. <p> Similar results can be expected if the queueing discipline used at routers for supporting IP integrated services does not preserve packet ordering. Our work complements recent work on QoS-sensitive CPU scheduling of applications <ref> [18, 19, 20] </ref> and protocol processing [22, 23, 24, 25] at end hosts. While these efforts focus on CPU scheduling, our primary focus is on the QoS support architecture exported to sockets based applications.
Reference: [21] <author> C. Liu and J. Layland, </author> <title> "Scheduling algorithms for multiprogramming in hard real-time environment", </title> <journal> Journal of the ACM, </journal> <volume> vol. 1, </volume> <pages> pp. 46-61, </pages> <month> January </month> <year> 1973. </year>
Reference-contexts: Similarly, real-time operating systems typically provide support for periodic fixed-priority and dynamic priority CPU scheduling, such as rate monotonic (RM) and earliest deadline first (EDF), respectively <ref> [21] </ref>. While such QoS-sensitive CPU scheduling policies suffice for computation activities, the granularity of the CPU scheduling quantum may be too coarse for accurate scheduling and traffic shaping of application data exporter threads.
Reference: [22] <author> R. Gopalakrishnan and G. M. Parulkar, </author> <title> "A real-time upcall facility for protocol processing with QoS guarantees", </title> <booktitle> in Proc. ACM Symp. on Operating Systems Principles, </booktitle> <address> p. 231, </address> <month> December </month> <year> 1995. </year>
Reference-contexts: This suggests that the data exporter threads, i.e., those performing fragmentation and other processing of network data, be scheduled for execution using fine-grain preemption. Such fine-grain multiplexing of communication threads has been adopted and analyzed in <ref> [22, 23] </ref> for RM scheduling, and in [24, 25] for EDF scheduling, respectively. <p> Similar results can be expected if the queueing discipline used at routers for supporting IP integrated services does not preserve packet ordering. Our work complements recent work on QoS-sensitive CPU scheduling of applications [18, 19, 20] and protocol processing <ref> [22, 23, 24, 25] </ref> at end hosts. While these efforts focus on CPU scheduling, our primary focus is on the QoS support architecture exported to sockets based applications. With appropriate CPU scheduling support, our QoS architecture enables new and legacy applications to utilize end-to-end QoS on communication.
Reference: [23] <author> R. Gopalakrishnan and G. M. Parulkar, </author> <title> "Bringing real-time scheduling theory and practice closer for multimedia computing", </title> <booktitle> in Proc. of ACM SIGMETRICS, </booktitle> <pages> pp. 1-12, </pages> <month> May </month> <year> 1996. </year>
Reference-contexts: This suggests that the data exporter threads, i.e., those performing fragmentation and other processing of network data, be scheduled for execution using fine-grain preemption. Such fine-grain multiplexing of communication threads has been adopted and analyzed in <ref> [22, 23] </ref> for RM scheduling, and in [24, 25] for EDF scheduling, respectively. <p> Similar results can be expected if the queueing discipline used at routers for supporting IP integrated services does not preserve packet ordering. Our work complements recent work on QoS-sensitive CPU scheduling of applications [18, 19, 20] and protocol processing <ref> [22, 23, 24, 25] </ref> at end hosts. While these efforts focus on CPU scheduling, our primary focus is on the QoS support architecture exported to sockets based applications. With appropriate CPU scheduling support, our QoS architecture enables new and legacy applications to utilize end-to-end QoS on communication.
Reference: [24] <author> Ashish Mehra, Atri Indiresan, and Kang G. Shin, </author> <title> "Resource management for real-time communication: Making theory meet practice", </title> <booktitle> in Proc. 2nd Real-Time Technology and Applications Symposium, </booktitle> <pages> pp. 130-138, </pages> <month> June </month> <year> 1996. </year>
Reference-contexts: This suggests that the data exporter threads, i.e., those performing fragmentation and other processing of network data, be scheduled for execution using fine-grain preemption. Such fine-grain multiplexing of communication threads has been adopted and analyzed in [22, 23] for RM scheduling, and in <ref> [24, 25] </ref> for EDF scheduling, respectively. The architecture described in [25] decouples protocol processing priority from application priority, deriving the former derived from the traffic and QoS specification on each connection. 19 Accurate traffic shaping is realized via EDF scheduling of protocol processing threads. <p> Similar results can be expected if the queueing discipline used at routers for supporting IP integrated services does not preserve packet ordering. Our work complements recent work on QoS-sensitive CPU scheduling of applications [18, 19, 20] and protocol processing <ref> [22, 23, 24, 25] </ref> at end hosts. While these efforts focus on CPU scheduling, our primary focus is on the QoS support architecture exported to sockets based applications. With appropriate CPU scheduling support, our QoS architecture enables new and legacy applications to utilize end-to-end QoS on communication.
Reference: [25] <author> Ashish Mehra, Atri Indiresan, and Kang G. Shin, </author> <title> "Structuring communication software for quality-of-service guarantees", </title> <booktitle> in Proc. 17th Real-Time Systems Symposium, </booktitle> <pages> pp. 144-154, </pages> <month> December </month> <year> 1996. </year>
Reference-contexts: This suggests that the data exporter threads, i.e., those performing fragmentation and other processing of network data, be scheduled for execution using fine-grain preemption. Such fine-grain multiplexing of communication threads has been adopted and analyzed in [22, 23] for RM scheduling, and in <ref> [24, 25] </ref> for EDF scheduling, respectively. The architecture described in [25] decouples protocol processing priority from application priority, deriving the former derived from the traffic and QoS specification on each connection. 19 Accurate traffic shaping is realized via EDF scheduling of protocol processing threads. <p> Such fine-grain multiplexing of communication threads has been adopted and analyzed in [22, 23] for RM scheduling, and in [24, 25] for EDF scheduling, respectively. The architecture described in <ref> [25] </ref> decouples protocol processing priority from application priority, deriving the former derived from the traffic and QoS specification on each connection. 19 Accurate traffic shaping is realized via EDF scheduling of protocol processing threads. <p> An alternative approach which also utilizes early demultiplexing of arriving packets, but performs packet reassembly in a QoS-sensitive fashion via EDF scheduling of protocol processing, is described in <ref> [25] </ref>. 7 Conclusions In this paper we have studied the performance impact of supporting QoS communication in tcp/ip protocol stacks. This study was conducted on a prototype implementation of a new QoS architecture for an rsvp-based integrated services Internet. <p> Similar results can be expected if the queueing discipline used at routers for supporting IP integrated services does not preserve packet ordering. Our work complements recent work on QoS-sensitive CPU scheduling of applications [18, 19, 20] and protocol processing <ref> [22, 23, 24, 25] </ref> at end hosts. While these efforts focus on CPU scheduling, our primary focus is on the QoS support architecture exported to sockets based applications. With appropriate CPU scheduling support, our QoS architecture enables new and legacy applications to utilize end-to-end QoS on communication.
Reference: [26] <author> D. D. Clark, S. Shenker, and L. Zhang, </author> <title> "Supporting real-time applications in an integrated services packet network: Architecture and mechanism", </title> <booktitle> in Proc. of ACM SIGCOMM, </booktitle> <pages> pp. 14-26, </pages> <month> August </month> <year> 1992. </year>
Reference-contexts: Our work builds upon and relates to several recent research efforts, as discussed below. Integrated Services on the Internet: The service model for integrated services on the Internet and expected requirements of applications are discussed in <ref> [26, 1, 27] </ref>. and the service classes under consideration by the IETF outlined in [4, 5].
Reference: [27] <author> Sally Floyd and Van Jacobson, </author> <title> "Link-sharing and resource management models for packet networks", </title> <journal> IEEE/ACM Trans. Networking, </journal> <volume> vol. 3, </volume> <month> August </month> <year> 1995. </year>
Reference-contexts: Our work builds upon and relates to several recent research efforts, as discussed below. Integrated Services on the Internet: The service model for integrated services on the Internet and expected requirements of applications are discussed in <ref> [26, 1, 27] </ref>. and the service classes under consideration by the IETF outlined in [4, 5].
Reference: [28] <author> R. Cole, D. Shur, and C. Villamizar, </author> <title> "IP over ATM: A framework document", </title> <booktitle> Work in Progress, </booktitle> <month> April </month> <year> 1995, </year> <institution> ATT Bell Laboratories, ANS. </institution>
Reference-contexts: Various issues in supporting quality of service in IP-ATM networks are also being examined <ref> [28, 29, 30] </ref>, including the use of RSVP for end-to-end signaling across ATM networks [31] and for integrated services using RSVP over ATM [32]. Network and Protocol Support for QoS: The Tenet protocol suite [33] provides real-time communication support in wide-area networks (WANs).
Reference: [29] <author> M. Perez, F. Liaw, A. Mankin, E. Hoffman, D. Grossman, and A. Malis, </author> <title> "ATM signaling support for IP over ATM", Request for Comments RFC 1755, </title> <month> February </month> <year> 1995, </year> <note> ISI, Fore, Motoral Codex, Ascom Timeplex. </note>
Reference-contexts: Various issues in supporting quality of service in IP-ATM networks are also being examined <ref> [28, 29, 30] </ref>, including the use of RSVP for end-to-end signaling across ATM networks [31] and for integrated services using RSVP over ATM [32]. Network and Protocol Support for QoS: The Tenet protocol suite [33] provides real-time communication support in wide-area networks (WANs).
Reference: [30] <author> M. Borden, E. Crawley, B. Davie, and S. Batsell, </author> <title> "Integration of real-time services in an IP-ATM network architecture", Request for Comments RFC 1821, </title> <month> August </month> <year> 1995, </year> <title> Bay Networks, Bellcore, </title> <publisher> NRL. </publisher>
Reference-contexts: Various issues in supporting quality of service in IP-ATM networks are also being examined <ref> [28, 29, 30] </ref>, including the use of RSVP for end-to-end signaling across ATM networks [31] and for integrated services using RSVP over ATM [32]. Network and Protocol Support for QoS: The Tenet protocol suite [33] provides real-time communication support in wide-area networks (WANs).
Reference: [31] <author> Alex Birman, Victor Firiou, Roch Guerin, and Dilip Kandlur, </author> <title> "Provisioning of RSVP-based services over a large ATM network", </title> <institution> IBM Research Report, </institution> <month> October </month> <year> 1995. </year>
Reference-contexts: Various issues in supporting quality of service in IP-ATM networks are also being examined [28, 29, 30], including the use of RSVP for end-to-end signaling across ATM networks <ref> [31] </ref> and for integrated services using RSVP over ATM [32]. Network and Protocol Support for QoS: The Tenet protocol suite [33] provides real-time communication support in wide-area networks (WANs).
Reference: [32] <author> S. Berson and L. Berger, </author> <title> "IP integrated services with RSVP over ATM", Internet Draft draft-ietf-issll-atm-support-02.txt, </title> <month> November </month> <year> 1996, </year> <note> ISI/FORE Systems. </note>
Reference-contexts: Various issues in supporting quality of service in IP-ATM networks are also being examined [28, 29, 30], including the use of RSVP for end-to-end signaling across ATM networks [31] and for integrated services using RSVP over ATM <ref> [32] </ref>. Network and Protocol Support for QoS: The Tenet protocol suite [33] provides real-time communication support in wide-area networks (WANs). While they also develop architectural enhancements for a sockets based communication subsystem, the protocol suite adopted does not conform to IETF standards for integrated services.
Reference: [33] <author> Anindo Banerjea, Dominic Ferrari, Bruce Mah, Mark Moran, Dinesh C. Verma, and Hui Zhang, </author> <title> "The Tenet real-time protocol suite: Design, implementation, and experiences", </title> <journal> IEEE/ACM Trans. Networking, </journal> <volume> vol. 4, </volume> <pages> pp. 1-11, </pages> <month> February </month> <year> 1996. </year>
Reference-contexts: Various issues in supporting quality of service in IP-ATM networks are also being examined [28, 29, 30], including the use of RSVP for end-to-end signaling across ATM networks [31] and for integrated services using RSVP over ATM [32]. Network and Protocol Support for QoS: The Tenet protocol suite <ref> [33] </ref> provides real-time communication support in wide-area networks (WANs). While they also develop architectural enhancements for a sockets based communication subsystem, the protocol suite adopted does not conform to IETF standards for integrated services. Moreover, they do not provide support for network interfaces with widely differing capabilities.
Reference: [34] <author> R. Ahuja, S. Keshav, and H. Saran, </author> <title> "Design, implementation, and performance of a native mode ATM transport layer", </title> <booktitle> in Proc. IEEE INFOCOM, </booktitle> <pages> pp. 206-214, </pages> <month> March </month> <year> 1996. </year>
Reference-contexts: While they also develop architectural enhancements for a sockets based communication subsystem, the protocol suite adopted does not conform to IETF standards for integrated services. Moreover, they do not provide support for network interfaces with widely differing capabilities. The native-mode ATM transport layer described in <ref> [34] </ref> also performs traffic policing and shaping while copying application data into kernel buffers. However, our design is applicable to general TCP/IP protocol stacks, including legacy LAN and ATM interfaces, participating in an integrated services Internet.
Reference: [35] <author> Chris Maeda and Brian N. Bershad, </author> <title> "Protocol service decomposition for high-performance networking", </title> <booktitle> in Proc. ACM Symp. on Operating Systems Principles, </booktitle> <pages> pp. 244-255, </pages> <month> December </month> <year> 1993. </year>
Reference-contexts: Protocol Processing and Data Transfer Optimizations: Several recent efforts have focused on optimizing the performance of the data transfer path in TCP/IP protocol stacks, including protocol processing latency [7, 8, 9] and user-level handling of network data <ref> [35, 36, 37, 38, 39] </ref> to increase throughput via data copy minimization. All of these efforts are geared towards traditional best-effort traffic, and as such are complementary to our work, which focuses on the performance impact of supporting QoS in TCP/IP protocol stacks.
Reference: [36] <author> C. A. Thekkath, T. D. Nguyen, E. Moy, and E. Lazowska, </author> <title> "Implementing network protocols at user level", </title> <booktitle> in Proc. of ACM SIGCOMM, </booktitle> <pages> pp. 64-73, </pages> <address> San Francisco, California, </address> <month> October </month> <year> 1993. </year>
Reference-contexts: Protocol Processing and Data Transfer Optimizations: Several recent efforts have focused on optimizing the performance of the data transfer path in TCP/IP protocol stacks, including protocol processing latency [7, 8, 9] and user-level handling of network data <ref> [35, 36, 37, 38, 39] </ref> to increase throughput via data copy minimization. All of these efforts are geared towards traditional best-effort traffic, and as such are complementary to our work, which focuses on the performance impact of supporting QoS in TCP/IP protocol stacks.
Reference: [37] <author> Peter Druschel, Larry L. Peterson, and Bruce S. Davie, </author> <title> "Experiences with a high-speed network adaptor: A software perspective", </title> <booktitle> in Proc. of ACM SIGCOMM, </booktitle> <pages> pp. 2-13, </pages> <address> London, UK, </address> <month> August </month> <year> 1994. </year>
Reference-contexts: Protocol Processing and Data Transfer Optimizations: Several recent efforts have focused on optimizing the performance of the data transfer path in TCP/IP protocol stacks, including protocol processing latency [7, 8, 9] and user-level handling of network data <ref> [35, 36, 37, 38, 39] </ref> to increase throughput via data copy minimization. All of these efforts are geared towards traditional best-effort traffic, and as such are complementary to our work, which focuses on the performance impact of supporting QoS in TCP/IP protocol stacks.
Reference: [38] <author> A. Edwards, G. Watson, J. Lumley, D. Banks, C. Clamvokis, and C. Dalton, </author> <title> "User-space protocols deliver high performance to applications on a low-cost Gb/s LAN", </title> <booktitle> in Proc. of ACM SIGCOMM, </booktitle> <pages> pp. 14-24, </pages> <address> London, UK, </address> <month> August </month> <year> 1994. </year> <month> 23 </month>
Reference-contexts: Protocol Processing and Data Transfer Optimizations: Several recent efforts have focused on optimizing the performance of the data transfer path in TCP/IP protocol stacks, including protocol processing latency [7, 8, 9] and user-level handling of network data <ref> [35, 36, 37, 38, 39] </ref> to increase throughput via data copy minimization. All of these efforts are geared towards traditional best-effort traffic, and as such are complementary to our work, which focuses on the performance impact of supporting QoS in TCP/IP protocol stacks.
Reference: [39] <author> V. Buch, T. von Eicken, A. Basu, and W. Vogels, "U-Net: </author> <title> A user-level network interface for parallel and distributed computing", </title> <booktitle> in Proc. ACM Symp. on Operating Systems Principles, </booktitle> <pages> pp. 40-53, </pages> <month> December </month> <year> 1995. </year>
Reference-contexts: Protocol Processing and Data Transfer Optimizations: Several recent efforts have focused on optimizing the performance of the data transfer path in TCP/IP protocol stacks, including protocol processing latency [7, 8, 9] and user-level handling of network data <ref> [35, 36, 37, 38, 39] </ref> to increase throughput via data copy minimization. All of these efforts are geared towards traditional best-effort traffic, and as such are complementary to our work, which focuses on the performance impact of supporting QoS in TCP/IP protocol stacks.
Reference: [40] <author> Ian Wakeman, Atanu Ghosh, Jon Crowcroft, Van Jacobson, and Sally Floyd, </author> <title> "Implementing real-time packet forwarding policies using Streams", </title> <booktitle> in Proc. USENIX Winter 1995 Technical Conference, </booktitle> <pages> pp. 71-82, </pages> <month> January </month> <year> 1995. </year>
Reference-contexts: While this provides us with very efficient classification for outgoing traffic at the sending hosts, more general mechanisms are needed to classify packets at intermediate routers and receiving hosts. A general classifier for real-time packet forwarding is described in <ref> [40] </ref>. Packet filters [41, 42, 43] provide general and flexible classification of incoming packets to application end-points.
Reference: [41] <author> Steven McCanne and Van Jacobson, </author> <title> "The BSD packet filter: A new architecture for user-level packet capture", </title> <booktitle> in Proc. of Winter USENIX, </booktitle> <year> 1993. </year>
Reference-contexts: While this provides us with very efficient classification for outgoing traffic at the sending hosts, more general mechanisms are needed to classify packets at intermediate routers and receiving hosts. A general classifier for real-time packet forwarding is described in [40]. Packet filters <ref> [41, 42, 43] </ref> provide general and flexible classification of incoming packets to application end-points.
Reference: [42] <author> M. Yuhara, Brian N. Bershad, Chris Maeda, and J. E. B. Moss, </author> <title> "Efficient packet demultiplexing for multiple endpoints and large messages", </title> <booktitle> in Proc. of Winter USENIX, </booktitle> <year> 1994. </year>
Reference-contexts: While this provides us with very efficient classification for outgoing traffic at the sending hosts, more general mechanisms are needed to classify packets at intermediate routers and receiving hosts. A general classifier for real-time packet forwarding is described in [40]. Packet filters <ref> [41, 42, 43] </ref> provide general and flexible classification of incoming packets to application end-points.
Reference: [43] <author> M. L. Bailey, B. Gopal, M. A. Pagels, L. L. Peterson, and P. Sarkar, "PATHFINDER: </author> <title> A pattern-based packet classifier", </title> <booktitle> in Proc. of ACM SIGCOMM, </booktitle> <pages> pp. 115-123, </pages> <address> London, UK, </address> <month> August </month> <year> 1994. </year>
Reference-contexts: While this provides us with very efficient classification for outgoing traffic at the sending hosts, more general mechanisms are needed to classify packets at intermediate routers and receiving hosts. A general classifier for real-time packet forwarding is described in [40]. Packet filters <ref> [41, 42, 43] </ref> provide general and flexible classification of incoming packets to application end-points.
Reference: [44] <author> Peter Druschel and Gauran Banga, </author> <title> "Lazy receiver processing (LRP): A network subsystem architecture for server systems", </title> <booktitle> in Proc. 2nd OSDI Symposium, </booktitle> <pages> pp. 261-275, </pages> <month> October </month> <year> 1996. </year> <month> 24 </month>
Reference-contexts: The processing of an arrived packet can be delayed until the application receives the data, as in LRP <ref> [44] </ref>. While this works well for best-effort traffic, appropriate OS support is still needed to ensure the application is scheduled to run in a QoS-sensitive fashion.
References-found: 44

