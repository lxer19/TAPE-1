URL: http://www.cs.cmu.edu/afs/cs.cmu.edu/Web/People/thrun/papers/thrun.nips7.rule-extraction.ps.gz
Refering-URL: http://www.cs.cmu.edu/afs/cs.cmu.edu/Web/People/thrun/papers/thrun.nips7.rule-extraction.html
Root-URL: http://www.cs.cmu.edu
Email: E-mail: thrun@carbon.informatik.uni-bonn.de  
Title: Extracting Rules from Artificial Neural Networks with Distributed Representations  
Author: Sebastian Thrun G. Tesauro, D. Touretzky, and T. Leen, 
Date: 1995  
Note: to appear in: Advances in Neural Information Processing Systems 7  eds.,  
Address: Romerstr. 164, D-53117 Bonn, Germany  
Affiliation: University of Bonn Department of Computer Science III  
Abstract: Although artificial neural networks have been applied in a variety of real-world scenarios with remarkable success, they have often been criticized for exhibiting a low degree of human comprehensibility. Techniques that compile compact sets of symbolic rules out of artificial neural networks offer a promising perspective to overcome this obvious deficiency of neural network representations. This paper presents an approach to the extraction of if-then rules from artificial neural networks. Its key mechanism is validity interval analysis, which is a generic tool for extracting symbolic knowledge by propagating rule-like knowledge through Backpropagation-style neural networks. Empirical studies in a robot arm domain illustrate the appropriateness of the proposed method for extracting rules from networks with real-valued and distributed representations.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. W. Craven and J. W. Shavlik. </author> <title> Learning symbolic rules using artificial neural networks. </title> <editor> In Paul E. Utgoff, editor, </editor> <booktitle> Proceedings of the Tenth International Conference on Machine Learning, 1993. </booktitle> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: While in these and other approaches neural networks have frequently found to outperform more traditional approaches, one of their major shortcomings is their low degree of human comprehensibility. In recent years, a variety of approaches for compiling rules out of networks have been proposed. Most approaches <ref> [1, 3, 4, 6, 7, 16, 17] </ref> compile networks into sets of rules with equivalent structure: Each processing unit is mapped into a separate rule-or a small set of rules-, and the ingoing weights are interpreted as preconditions to this rule. <p> In order to simplify the presentation, let us assume without loss of generality (a) that the network is layered and fully connected between two adjacent layers 1 , and (b) that there is an interval [a i ; b i ] <ref> [0; 1] </ref> in I for every unit in P and S. 2 Consider a single weight layer, connecting a layer of preceding units, denoted by P , to a layer of succeeding units, denoted by S (cf. Fig. 1). <p> i and b i for units i 2 S, new bounds a i and b i are 1 This assumption simplifies the description of VI-Analysis, although VI-Analysis can also be applied to arbitrary non-layered, partially connected network architectures, as well as recurrent networks not examined here. 2 The canonical interval <ref> [0; 1] </ref> corresponds to the state of maximum ignorance about the activation of a unit, and hence is the default interval if no more specific interval is known. 3 Here &lt; denotes the set of real numbers extended by 1. <p> The convergence of VI-Analysis follows from the fact that the update rule that intervals are changed monotonically, since they can only shrink or stay the same. Recall that the input of VI-Analysis is a set of intervals I <ref> [0; 1] </ref> n that constrain the activations of the network. VI-Analysis generates a refined set of intervals, I 0 I, so that all admissible activation values in the original intervals I are also in the refined intervals I 0 .
Reference: [2] <author> M. W. Craven and J. W. Shavlik. </author> <title> Using sampling and queries to extract rules from trained neural networks. </title> <booktitle> In Proceedings of the Eleventh International Conference on Machine Learning, 1994. </booktitle> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: In all our experiments, however, we observed reasonably fast convergence of the VI-Algorithm, and we successfully managed to extract rules from larger networks in reasonable amounts of time. Recently, Craven and Shavlik proposed a more efficient search method which can be applied in conjunction with VI-Analysis <ref> [2] </ref>. (b) Language. Currently VI-Analysis is limited to the extraction of if-then rules with linear preconditions. While in [14] it has been shown how to generalize VI-Analysis to rules expressed by arbitrary linear constraints, a more powerful rule language is clearly desirable. (c) Linear optimization.
Reference: [3] <author> L.-M. Fu. </author> <title> Integration of neural heuristics into knowledge-based inference. </title> <journal> Connection Science, </journal> <volume> 1(3) </volume> <pages> 325-339, </pages> <year> 1989. </year>
Reference-contexts: While in these and other approaches neural networks have frequently found to outperform more traditional approaches, one of their major shortcomings is their low degree of human comprehensibility. In recent years, a variety of approaches for compiling rules out of networks have been proposed. Most approaches <ref> [1, 3, 4, 6, 7, 16, 17] </ref> compile networks into sets of rules with equivalent structure: Each processing unit is mapped into a separate rule-or a small set of rules-, and the ingoing weights are interpreted as preconditions to this rule.
Reference: [4] <author> C. L. Giles and C. W. Omlin. </author> <title> Rule refinement with recurrent neural networks. </title> <booktitle> In Proceedings of the IEEE International Conference on Neural Network, 1993. IEEE Neural Network Council. </booktitle>
Reference-contexts: While in these and other approaches neural networks have frequently found to outperform more traditional approaches, one of their major shortcomings is their low degree of human comprehensibility. In recent years, a variety of approaches for compiling rules out of networks have been proposed. Most approaches <ref> [1, 3, 4, 6, 7, 16, 17] </ref> compile networks into sets of rules with equivalent structure: Each processing unit is mapped into a separate rule-or a small set of rules-, and the ingoing weights are interpreted as preconditions to this rule.
Reference: [5] <author> Y. LeCun, B. Boser, J. S. Denker, D. Henderson, R. E. Howard, W. Hubbard, and L. D. Jackel. </author> <title> Backpropagation applied to handwritten zip code recognition. </title> <journal> Neural Computation, </journal> <volume> 1 </volume> <pages> 541-551, </pages> <year> 1990. </year>
Reference-contexts: 1 Introduction In the last few years artificial neural networks have been applied successfully to a variety of real-world problems. For example, neural networks have been successfully applied in the area of speech generation [12] and recognition [18], vision and robotics [8], handwritten character recognition <ref> [5] </ref>, medical diagnostics [11], and game playing [13]. While in these and other approaches neural networks have frequently found to outperform more traditional approaches, one of their major shortcomings is their low degree of human comprehensibility.
Reference: [6] <author> J. J. Mahoney and R. J. Mooney. </author> <title> Combining neural and symbolic learning to revise probabilistic rule bases. </title> <editor> In J. E. Moody, S. J. Hanson, and R. P. Lippmann, editors, </editor> <booktitle> Advances in Neural Information Processing Systems 5, 1993. </booktitle> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: While in these and other approaches neural networks have frequently found to outperform more traditional approaches, one of their major shortcomings is their low degree of human comprehensibility. In recent years, a variety of approaches for compiling rules out of networks have been proposed. Most approaches <ref> [1, 3, 4, 6, 7, 16, 17] </ref> compile networks into sets of rules with equivalent structure: Each processing unit is mapped into a separate rule-or a small set of rules-, and the ingoing weights are interpreted as preconditions to this rule.
Reference: [7] <author> C. McMillan, M. C. Mozer, and P. Smolensky. </author> <title> Rule induction through integrated symbolic and subsymbolic processing. </title> <editor> In J. E. Moody, S. J. Hanson, and R. P. Lippmann, editors, </editor> <booktitle> Advances in Neural Information Processing Systems 4, 1992. </booktitle> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: While in these and other approaches neural networks have frequently found to outperform more traditional approaches, one of their major shortcomings is their low degree of human comprehensibility. In recent years, a variety of approaches for compiling rules out of networks have been proposed. Most approaches <ref> [1, 3, 4, 6, 7, 16, 17] </ref> compile networks into sets of rules with equivalent structure: Each processing unit is mapped into a separate rule-or a small set of rules-, and the ingoing weights are interpreted as preconditions to this rule.
Reference: [8] <author> D. A. Pomerleau. ALVINN: </author> <title> an autonomous land vehicle in a neural network. </title> <type> Technical Report CMU-CS-89-107, </type> <institution> Computer Science Dept. Carnegie Mellon University, </institution> <address> Pittsburgh PA, </address> <year> 1989. </year>
Reference-contexts: 1 Introduction In the last few years artificial neural networks have been applied successfully to a variety of real-world problems. For example, neural networks have been successfully applied in the area of speech generation [12] and recognition [18], vision and robotics <ref> [8] </ref>, handwritten character recognition [5], medical diagnostics [11], and game playing [13]. While in these and other approaches neural networks have frequently found to outperform more traditional approaches, one of their major shortcomings is their low degree of human comprehensibility.
Reference: [9] <author> W. H. </author> <title> Press. Numerical recipes in C : the art of scientific computing. </title> <publisher> Cambridge University Press, </publisher> <address> Cambridge [Cambridgeshire], New York, </address> <year> 1988. </year>
Reference-contexts: These, plus the validity intervals for all units k 2 P, form a set of linear constraints on the activations x k in layer P. Linear programming is now employed to refine all interval bounds one-by-one. programming <ref> [9] </ref>, so that those activation values which are inconsistent with other intervals are excluded. <p> Linear programming allows to maximize or minimize arbitrary linear combinations of the variables x j while not violating a set of linear constraints <ref> [9] </ref>. Hence, linear programming can be applied to refine lower and upper bounds for validity intervals one-by-one. In VI-Analysis, constraints are propagated in two phases: 1. Forward phase. <p> Likewise, b i is set to b i if b i &lt; b i . Notice that the min/max operator is computed within the bounds imposed by Eq. 1, using the Simplex algorithm (linear programming) <ref> [9] </ref>. 2. Backward phase. <p> There are several limitations of the current approach that warrant future research. (a) Speed. While the one-to-one compilation of networks into rules is fast, rule extraction via VI-Analysis requires multiple runs of linear programming, each of which can be computationally expensive <ref> [9] </ref>. Searching the rule space without domain-specific search heuristics can thus be a most time-consuming undertaking. In all our experiments, however, we observed reasonably fast convergence of the VI-Algorithm, and we successfully managed to extract rules from larger networks in reasonable amounts of time.
Reference: [10] <author> J. R. Quinlan. </author> <title> Induction of decision trees. </title> <journal> Machine Learning, </journal> <volume> 1 </volume> <pages> 81-106, </pages> <year> 1986. </year>
Reference-contexts: In discrete domains, such a strategy amounts to searching directed acyclic graphs in breadth-first manner. Obviously, there is a variety of alternative techniques to generate meaningful rule hypotheses. For example, one might employ a symbolic learning technique such as decision tree learning <ref> [10] </ref> to the same training data that was used for training the network. The rules, which are a result of the symbolic approach, constitute hypotheses that can be checked using VI-Analysis. 4 Empirical Results In this section we will be interested in extracting rules in a real-valued robot arm domain.
Reference: [11] <author> J. Rennie. </author> <title> Cancer catcher: Neural net catches errors that slip through pap tests. </title> <journal> Scientific American, </journal> <volume> 262, </volume> <month> May </month> <year> 1990. </year>
Reference-contexts: 1 Introduction In the last few years artificial neural networks have been applied successfully to a variety of real-world problems. For example, neural networks have been successfully applied in the area of speech generation [12] and recognition [18], vision and robotics [8], handwritten character recognition [5], medical diagnostics <ref> [11] </ref>, and game playing [13]. While in these and other approaches neural networks have frequently found to outperform more traditional approaches, one of their major shortcomings is their low degree of human comprehensibility. In recent years, a variety of approaches for compiling rules out of networks have been proposed.
Reference: [12] <author> T. J. Sejnowski and C. R. Rosenberg. Nettalk: </author> <title> A parallel network that learns to read aloud. </title> <type> Technical Report JHU/EECS-86/01, </type> <institution> Johns Hopkins University, </institution> <year> 1986. </year>
Reference-contexts: 1 Introduction In the last few years artificial neural networks have been applied successfully to a variety of real-world problems. For example, neural networks have been successfully applied in the area of speech generation <ref> [12] </ref> and recognition [18], vision and robotics [8], handwritten character recognition [5], medical diagnostics [11], and game playing [13]. While in these and other approaches neural networks have frequently found to outperform more traditional approaches, one of their major shortcomings is their low degree of human comprehensibility.
Reference: [13] <author> G. J. Tesauro. </author> <title> Practical issues in temporal difference learning. </title> <journal> Machine Learning, </journal> <volume> 8, </volume> <year> 1992. </year>
Reference-contexts: For example, neural networks have been successfully applied in the area of speech generation [12] and recognition [18], vision and robotics [8], handwritten character recognition [5], medical diagnostics [11], and game playing <ref> [13] </ref>. While in these and other approaches neural networks have frequently found to outperform more traditional approaches, one of their major shortcomings is their low degree of human comprehensibility. In recent years, a variety of approaches for compiling rules out of networks have been proposed.
Reference: [14] <author> S. Thrun. </author> <title> Extracting provably correct rules from artificial neural networks. </title> <type> Technical Report IAI-TR-93-5, </type> <institution> University of Bonn, Institut fur Informatik III, D-53117 Bonn, </institution> <month> May </month> <year> 1993. </year>
Reference-contexts: It does this by iteratively refining the validity intervals, excluding activations that are provably inconsistent with other intervals. In what follows we will present the general VI-Analysis algorithm, which can be found in more detail elsewhere <ref> [14] </ref>. Let n denote the total number of units in the network, and let x i denote the (output) activation of unit i (i = 1; : : : ; n). If unit i is an input unit, its activation value will simply be the external input value. <p> Detecting inconsistencies is the driving mechanism for the verification and extraction of rules presented in turn. 3 Rule Extraction The rules considered in this paper are propositional if-then rules. Although VI-Analysis is able to prove rules expressed by arbitrary linear constraints <ref> [14] </ref>, for the sake of simplicity we will consider only rules where the precondition is given by a set of intervals for the individual input values, and the output is a single target category. <p> Assume, without loss of generality, the network has a single output unit, and input patterns are classified as members of class C if and only if the output activation, x out , is larger than a threshold c (see <ref> [14] </ref> for networks with multiple output units). A rule conjecture I ! C is then verified by showing that there is no input vector ~x 2 I that falls into the opposite class, :C. <p> In this way randomly generated instances can be used as seeds for rules, which are then generalized via VI-Analysis. 2. General-to-specific. An alternative way to extract rules, which has been studied in more detail elsewhere <ref> [14] </ref>, works from general to specific. General-to-specific rule search maintains a list of non-proven conjectures, R. R is initialized with the most general rules (like everything is in C and nothing is in C). VI-Analysis is then applied to prove rules in R. <p> For example, in the MONK's problems [15], VI-Analysis successfully extracted compact target side view. The grey area indicates safe positions for the tip of the manipulator. concepts using the originally published weight sets. These results can be found in <ref> [14] </ref>. 5 Discussion In this paper we have presented a mechanism for the extraction of rules from Backpropagation-style neural networks. There are several limitations of the current approach that warrant future research. (a) Speed. <p> Recently, Craven and Shavlik proposed a more efficient search method which can be applied in conjunction with VI-Analysis [2]. (b) Language. Currently VI-Analysis is limited to the extraction of if-then rules with linear preconditions. While in <ref> [14] </ref> it has been shown how to generalize VI-Analysis to rules expressed by arbitrary linear constraints, a more powerful rule language is clearly desirable. (c) Linear optimization. Linear programming analyzes multiple weight layers independently, resulting in an overly careful refinement of intervals. This effect can prevent from detecting correct rules.
Reference: [15] <author> S. Thrun, J. Bala, E. Bloedorn, I. Bratko, B. Cestnik, J. Cheng, K. De Jong, S. Dzeroski, D. Fisher, S. E. Fahlman, R. Hamann, K. Kaufman, S. Keller, I. Kononenko, J. Kreuziger, R. S. Michalski, T.M. Mitchell, P. Pachowicz, Y. Reich, H. Vafaie, W. Van de Welde, W. Wenzel, J. Wnek, and J. Zhang. </author> <title> The MONK's problems a performance comparison of different learning algorithms. </title> <type> Technical Report CMU-CS-91-197, </type> <institution> Carnegie Mellon University, </institution> <address> Pittsburgh, PA, </address> <month> December </month> <year> 1991. </year>
Reference-contexts: Such general rules were frequently found in the robot arm domain. This concludes the brief description of the experimental results. Not mentioned here are results with different size networks, and results obtained for the MONK's benchmark problems. For example, in the MONK's problems <ref> [15] </ref>, VI-Analysis successfully extracted compact target side view. The grey area indicates safe positions for the tip of the manipulator. concepts using the originally published weight sets.
Reference: [16] <author> G. Towell and J. W. Shavlik. </author> <title> Interpretation of artificial neural networks: Mapping knowledge-based neural networks into rules. </title> <editor> In J. E. Moody, S. J. Hanson, and R. P. Lippmann, editors, </editor> <booktitle> Advances in Neural Information Processing Systems 4, 1992. </booktitle> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: While in these and other approaches neural networks have frequently found to outperform more traditional approaches, one of their major shortcomings is their low degree of human comprehensibility. In recent years, a variety of approaches for compiling rules out of networks have been proposed. Most approaches <ref> [1, 3, 4, 6, 7, 16, 17] </ref> compile networks into sets of rules with equivalent structure: Each processing unit is mapped into a separate rule-or a small set of rules-, and the ingoing weights are interpreted as preconditions to this rule.
Reference: [17] <author> V. Tresp and J. Hollatz. </author> <title> Network structuring and training using rule-based knowledge. </title> <editor> In J. E. Moody, S. J. Hanson, and R. P. Lippmann, editors, </editor> <booktitle> Advances in Neural Information Processing Systems 5, 1993. </booktitle> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: While in these and other approaches neural networks have frequently found to outperform more traditional approaches, one of their major shortcomings is their low degree of human comprehensibility. In recent years, a variety of approaches for compiling rules out of networks have been proposed. Most approaches <ref> [1, 3, 4, 6, 7, 16, 17] </ref> compile networks into sets of rules with equivalent structure: Each processing unit is mapped into a separate rule-or a small set of rules-, and the ingoing weights are interpreted as preconditions to this rule.
Reference: [18] <author> A. H. Waibel. </author> <title> Modular construction of time-delay neural networks for speech recognition. </title> <journal> Neural Computation, </journal> <volume> 1 </volume> <pages> 39-46, </pages> <year> 1989. </year>
Reference-contexts: 1 Introduction In the last few years artificial neural networks have been applied successfully to a variety of real-world problems. For example, neural networks have been successfully applied in the area of speech generation [12] and recognition <ref> [18] </ref>, vision and robotics [8], handwritten character recognition [5], medical diagnostics [11], and game playing [13]. While in these and other approaches neural networks have frequently found to outperform more traditional approaches, one of their major shortcomings is their low degree of human comprehensibility.
References-found: 18

