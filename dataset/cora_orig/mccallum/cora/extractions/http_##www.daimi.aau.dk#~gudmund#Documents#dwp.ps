URL: http://www.daimi.aau.dk/~gudmund/Documents/dwp.ps
Refering-URL: http://www.daimi.aau.dk/~gudmund/
Root-URL: http://www.daimi.aau.dk
Title: Dynamic Word Problems  
Author: Gudmund Skovbjerg Frandsen Peter Bro Miltersen Sven Skyum 
Keyword: Q j  
Address: Ny Munkegade, Building 540 DK-8000 Aarhus C Denmark  
Affiliation: BRICS Department of Computer Science University of Aarhus  
Abstract: Let M be a fixed finite monoid. We consider the problem of implementing a data type containing a vector x = (x 1 ; x 2 ; : : : ; x n ) 2 M n , initially (1; 1; : : : ; 1), with two kinds of operations, for each i 2 f1; : : : ; ng and a 2 M, an operation change i;a which changes x i to a and a single operation product returning Q n i=1 x i . This is the dynamic word problem for M . If we in addition for each j 2 f1; : : : ; ng have an operation prefix j i=1 x i , we get the dynamic prefix problem for M. We analyze the complexity of these problems in the cell probe or decision assignment tree model for two natural cell sizes, 1 bit and log n bits. We obtain a partial classification of the complexity based on algebraic properties of M. 1 Introduction and summary of results returning
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D. Angluin, L.G. Valiant: </author> <title> Fast Probabilistic Algorithms for Hamil-tonian Circuits and Matchings, </title> <journal> J. Comput. System Sci. </journal> <month> 18 </month> <year> (1979) </year> <month> 155-193. </month>
Reference-contexts: Lower bounds in the B = log n model are also lower bounds for the complexity of implementing the type on a random access computer <ref> [1] </ref>, i.e., a unit cost random access machine with word size bounded by O (log n) .
Reference: [2] <author> D.A. Barrington, </author> <title> Bounded-width polynomial-size branching programs recognize exactly those languages in NC 1 , J. </title> <institution> Comput. System Sci. </institution> <month> 38 </month> <year> (1989) </year> <month> 150-164. </month>
Reference-contexts: Barrington and Therien [4] refine this result by relating the exact depth required by a polynomial size, unbounded fan-in circuit solving the word problem of a group-free monoid to the position of the monoid in a hierarchy, the "dot-depth" hierarchy. For monoids containing groups, Barrington <ref> [2] </ref> shows that for a solvable monoid, i.e., a monoid where all contained groups are solvable, the word problem is in ACC, i.e., can be computed by polynomial size, constant depth circuits containing AND, OR and MOD-q gates for some fixed integer q, while the word problem for a non-solvable monoid
Reference: [3] <author> D.A. Mix Barrington, K. Compton, H. Straubing, D. Therien, </author> <title> Regular Languages in NC 1 , J. </title> <journal> Comput. System Sci. </journal> <pages> 44(1992) 478-499. </pages>
Reference-contexts: A similar situation arises in parallel complexity, e.g., a regular language may be in AC 0 , while the word problem for its syntactic monoid is not [6]. However, in the parallel case, the situation has been completely resolved by Barrington, Compton, Straubing and Therien <ref> [3] </ref>. We provide a sufficient condition for a regular language to be as hard as its syntactic monoid in the dynamic case, but we don't know anything in general about languages violating the condition. <p> language, i.e., if L can be defined from the letters of the alphabet using the boolean operations and concatenation, the dynamic membership problem for L can be solved in time O (log log n) on a random access machine, since the syntactic monoid of a star free language is group-free <ref> [3] </ref>. However, bounds obtained in this way are not necessarily optimal as the following example tells us: Let L = f0; 1g fl 0. The dynamic membership problem for L can be solved in constant time. <p> In the parallel case, however, the complexity of regular languages is now well understood <ref> [3] </ref>. 14 It would be nice to have a similar complete understanding of the dy-namic complexity of regular languages. However, we will settle for the following theorem which gives a sufficient condition for a regular language to be as hard as its syntactic monoid.
Reference: [4] <author> D.A. Mix Barrington, D. Therien, </author> <title> Finite monoids and the fine structure of NC 1 , J. </title> <publisher> Assoc. Comput. Mach. </publisher> <month> 35 </month> <year> (1988) </year> <month> 941-952. </month>
Reference-contexts: Furthermore, Chandra, Fortune and Lipton show that if the monoid is in fact group-free, i.e., does not contain a nontrivial group, the prefix problem is in AC 0 and the size of the circuit can be made almost linear. Barrington and Therien <ref> [4] </ref> refine this result by relating the exact depth required by a polynomial size, unbounded fan-in circuit solving the word problem of a group-free monoid to the position of the monoid in a hierarchy, the "dot-depth" hierarchy.
Reference: [5] <author> R.B. Boppana, M. Sipser: </author> <title> The Complexity of Finite Functions, </title> <editor> in: J. van Leuuwen, ed., </editor> <booktitle> Handbook of Theoretical Computer Science, </booktitle> <volume> Vol. </volume> <publisher> A (Elsevier, </publisher> <address> Amsterdam, </address> <year> 1990) </year> <month> 757-804. </month>
Reference-contexts: If n &gt; (p 1) l+1 l!, then the collection contains as a subcollection a sunflower with p petals. For a proof, see Boppana and Sipser <ref> [5] </ref>. Note that they state a slightly different version of the lemma, because they require the collection to be of distinct sets. However, only the base case of the induction has to be modified to convert their proof into a proof of the above lemma.
Reference: [6] <author> A.K. Chandra, S. Fortune, R. Lipton, </author> <title> Unbounded fan-in circuits and associative functions, </title> <booktitle> in: Proc. 15th ACM Symp. on Theory of Computing (1983) 25-27. </booktitle>
Reference-contexts: From a parallel point of view, there is not much difference between word and prefix 3 problems, since the prefixes can be computed independently. A tight re-lationship between the complexity and algebraic properties of the monoid has been shown in a series of papers. Chandra, Fortune and Lipton <ref> [6] </ref> note that if the monoid contains a non-trivial group as a subset, the word problem is not in AC 0 , i.e., can not be computed by polynomial size, unbounded fan-in, constant depth, AND-OR circuits. <p> The B = log n upper bound for group-free monoids is proved by an application of the Krohn-Rhodes decomposition theorem [14] (which was also used to show that the prefix problem for the same class of monoids is in AC 0 <ref> [6] </ref>). The data structure uses Van Emde Boas trees [8]. <p> A similar situation arises in parallel complexity, e.g., a regular language may be in AC 0 , while the word problem for its syntactic monoid is not <ref> [6] </ref>. However, in the parallel case, the situation has been completely resolved by Barrington, Compton, Straubing and Therien [3]. <p> It is interesting to note that a similar phenomenon arises when considering the parallel complexity of regular languages <ref> [6] </ref>, a regular language may be in AC 0 even when the word problem for its syntactic monoid is not.
Reference: [7] <author> R.F. Cohen, R. Tamassia, </author> <title> Dynamic Expression Trees and their Applications, </title> <booktitle> in Proc. 2nd Annual ACM-SIAM Symp. on Discrete Algorithms (1991) 52-61. </booktitle>
Reference-contexts: Is this correspondence purely accidental, or can we establish some kind of formal correspondence, linking parallel and dynamic complexity? Indeed, Cohen and Tamassia <ref> [7] </ref> and Mil-tersen et al [15] consider this question and have several partial results on when one can and when one can not transfer information between the two worlds.
Reference: [8] <author> P. van Emde Boas, R. Kaas, E. Zijlstra, </author> <title> Design and implementation of an efficient priority queue, </title> <journal> Math. </journal> <note> Systems Theory 10 (1977) 99-127. </note>
Reference-contexts: The data structure uses Van Emde Boas trees <ref> [8] </ref>. The lower bound for non-commutative groups is proved by reducing Z r -PREFIX (n) to M -WORD (n). 1 We actually show the bound for a slightly larger class of monoids, see Theorem 10. 5 The only significant gap for B = 1 is the gap for non-commutative monoids. <p> NEIGHBOUR (n) can be implemented on a machine with cell size O (log n) with all operations being O (log log n) using the Van Emde Boas tree of Van Emde Boas, Kaas and Zijlstra <ref> [8] </ref>. Theorem 9 If M is a group-free monoid, M -RANGE (n) can be implemented on a random access computer with cell size O (log n), so that all operations take time O (log log n). 11 Proof The proof is by induction in the size of M .
Reference: [9] <author> M.L. Fredman: </author> <title> Observations on the complexity of generating quasi-Gray codes, </title> <journal> SIAM J. Comput. </journal> <volume> 7 (1978) 134-146. </volume> <pages> 16 </pages>
Reference-contexts: The model in which we consider implementing the data type is the cell probe or decision assignment tree model, previously considered by Fred-man <ref> [9, 10] </ref> and Fredman and Saks [11].
Reference: [10] <author> M.L. Fredman: </author> <title> The Complexity of Maintaining an Array and Com--puting its Partial Sums, </title> <journal> J. Assoc. Comput. Mach. </journal> <month> 29 </month> <year> (1982) </year> <month> 250-260. </month>
Reference-contexts: The model in which we consider implementing the data type is the cell probe or decision assignment tree model, previously considered by Fred-man <ref> [9, 10] </ref> and Fredman and Saks [11]. <p> Furthermore, in any implementation, some operation will require access to ( log n log log n ) cells. This result is due to Fredman <ref> [10] </ref> (who only states it for M = Z 2 , but the proof is easily seen to hold in general). * If M is any finite monoid, then for cell size B = log n, M -PREFIX (n) can be implemented with complexity O ( log n log log n <p> The corresponding lower bound is based on a Ramsey-like theorem, the Erdos-Rado sunflower lemma. The B = 1 lower bound for non-commutative monoids is based on a technique due to Fredman <ref> [10] </ref>, used previously for getting the B = 1 prefix lower bound mentioned above. <p> Therefore jCj log p and hence l log p and thus l log n l+1 O (log (l + p 2 log log n 1 o (1). Non-commutative monoids For the B = 1 lower bound for non-commutative monoids, we are going to apply a technique due to Fredman <ref> [10] </ref>. Fredman's technique is best described as a reduction from a special data type, WHICH-SIDE (n), maintaining a value t 2 f1; : : : ; ng with two operations: * For each i 2 f1; : : : ; ng, an operation init i , putting t := i. <p> All operations performed after the first one must be of this type. The proof of Theorem 5 in <ref> [10] </ref> is easily modified to show the following lemma. Lemma 6 (Fredman) In any implementation of WHICH-SIDE (n) with cell size B = 1, at least ( log n log log n ) cells are accessed by some operation in the worst case.
Reference: [11] <author> M.L. Fredman, </author> <title> M.E. Saks: The Cell Probe Complexity of Dynamic Data Structures, </title> <booktitle> in: Proc. 21st Ann. ACM Symp. on Theory of Computing (1989) 345-354. </booktitle>
Reference-contexts: The model in which we consider implementing the data type is the cell probe or decision assignment tree model, previously considered by Fred-man [9, 10] and Fredman and Saks <ref> [11] </ref>. In this model, the complexity of a computation is the number of cells accessed in the random access memory containing the data structure during the computation, while the computation itself is for free (and information about which operation to perform is also given for free). <p> Indeed, the best known lower bound for a language in P for the number of cells touched by a change or query operation seems to be (log n) for B = 1 [15] and ( log n log log n ) for B = log n <ref> [11] </ref>. This again corresponds to the world of parallel complexity where no lower bound on (bounded fan-in) depth for problems in P better than (log n) is known, i.e., P = NC 1 is unresolved. <p> If M = Z r for some r 2, then in any implementation, some operation will require access to ( log n log log n ) cells. This result is due to Fredman and Saks <ref> [11] </ref> (who again only state it for M = Z 2 , but the proof holds in 4 Word problem Cell size Type of monoid Lower bound Upper bound commutative group fi (1) B = 1 commutative non-group 1 2 log log n O (1) 2 log log n + O
Reference: [12] <author> M. Furst, J. Saxe, M. Sipser, </author> <title> Parity, circuits and the polynomial time hierarchy, </title> <journal> Math. </journal> <note> Systems Theory 17(1984) 13-27. </note>
Reference-contexts: This is a corollary to the result of Furst, Saxe and Sipser <ref> [12] </ref> that parity, and in general, modulo counting is not in AC 0 . The tighter bounds later shown by Hastad [13] imply that depth fi (log n= log log n) is sufficient and necessary if polynomial size is to be retained.
Reference: [13] <author> J. Hastad, </author> <title> Computational limitations for small depth circuits, </title> <publisher> (MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1986). </year>
Reference-contexts: This is a corollary to the result of Furst, Saxe and Sipser [12] that parity, and in general, modulo counting is not in AC 0 . The tighter bounds later shown by Hastad <ref> [13] </ref> imply that depth fi (log n= log log n) is sufficient and necessary if polynomial size is to be retained.
Reference: [14] <author> K. Krohn, J. Rhodes, </author> <title> Algebraic theory of machines. I. Prime decomposition theorem for finite semigroups and machines, </title> <journal> Trans. Am. Math. Soc. </journal> <month> 116 </month> <year> (1965) </year> <month> 450-464. </month>
Reference-contexts: The B = log n upper bound for group-free monoids is proved by an application of the Krohn-Rhodes decomposition theorem <ref> [14] </ref> (which was also used to show that the prefix problem for the same class of monoids is in AC 0 [6]). The data structure uses Van Emde Boas trees [8]. <p> We actually implement a more general data type, M -RANGE (n), where we for each pair (i; j) have an operation range i;j returning Q j We use the following lemma, a consequence of the Krohn-Rhodes decomposition theorem <ref> [14] </ref>. Lemma 8 (Krohn and Rhodes) Let M be a group-free monoid.
Reference: [15] <author> P.B. Miltersen, S. Subramaniam, J.S. Vitter, R. Tamassia, </author> <title> A complexity theoretic approach to incremental computation, </title> <note> Theoretical Computer Science 130 (1994) 203-236. </note> <year> (1993) </year> <month> 640-649. </month>
Reference-contexts: Firstly, dynamic word problems can be regarded as a special case of a very general class of natural data structure problems, dynamic language membership problems, considered by Miltersen et al <ref> [15] </ref>. A problem in this class is given by a language L f0; 1g fl . We are supposed to implement a data type L-MEMBER containing a string x 2 f0; 1g fl with three kinds of operations: * init (n). <p> We seem to be far from answering the P versus incr-POLYLOGTIME question. Indeed, the best known lower bound for a language in P for the number of cells touched by a change or query operation seems to be (log n) for B = 1 <ref> [15] </ref> and ( log n log log n ) for B = log n [11]. This again corresponds to the world of parallel complexity where no lower bound on (bounded fan-in) depth for problems in P better than (log n) is known, i.e., P = NC 1 is unresolved. <p> Is this correspondence purely accidental, or can we establish some kind of formal correspondence, linking parallel and dynamic complexity? Indeed, Cohen and Tamassia [7] and Mil-tersen et al <ref> [15] </ref> consider this question and have several partial results on when one can and when one can not transfer information between the two worlds.
Reference: [16] <author> A.C. Yao, </author> <title> Separating the polynomial-time hierarchy by oracles, </title> <booktitle> in: Proc. 26th Ann. IEEE Symp. on Foundations of Computer Science (1985) 1-10. </booktitle>
References-found: 16

