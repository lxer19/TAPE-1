URL: ftp://theory.lcs.mit.edu/pub/cilk/lu-msthesis.ps.Z
Refering-URL: http://theory.lcs.mit.edu/~cilk/papers.html
Root-URL: 
Title: Heterogeneous Multithreaded Computing  
Author: by Howard J. Lu Howard J. Lu. 
Degree: Submitted to the Department of Electrical Engineering and Computer Science in Partial Fulfillment of the Requirements for the Degrees of Bachelor of Science in Computer Science and Engineering and Master of Engineering in Electrical Engineering and Computer Science  All rights reserved. The author hereby grants to M.I.T. permission to reproduce and to distribute copies of this thesis document in whole or in part, and to grant others the right to do so. Author  Certified by Charles E. Leiserson Thesis Supervisor Accepted by F.R. Morgenthaler  
Note: Copyright 1995  
Date: May 1995  May 17, 1995  
Affiliation: at the Massachusetts Institute of Technology  Department of Electrical Engineering and Computer Science  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Robert D. Blumofe, Christopher F. Joerg, Bradley C. Kuszmaul, Charles E. Leiserson, Keith H. Randall, and Yuli Zhou. Cilk: </author> <title> An Efficient Multithreaded Runtime System. </title> <booktitle> To appear in the Symposium on Principles and Practice of Parallel Programming , Santa Barbara, </booktitle> <address> California, </address> <month> July </month> <year> 1994. </year>
Reference-contexts: In this thesis, we examine the problems introduced by differences in data representation, speed, and scale. We also show both practically and analytically that a runtime system can run efficiently in a heterogeneous environment. We have chosen to investigate these problems using the Cilk runtime system <ref> [1] </ref>. Cilk is a C-based runtime system that supports the execution of multithreaded programs in a continuation passing style across a homogeneous set of workers. We have chosen Cilk because it is simple, portable, and provably efficient in a homogeneous environment. <p> We analyze the implications of running in a heterogeneous environment of different scales in section 5. And in section 6, we present some implementation details for constructing Cilk to run heterogeneously with respect to data representation, speed, and scale. 2 Cilk We have chosen the Cilk multithreaded runtime system <ref> [1] </ref> to study the issues of heterogeneous multithreaded computing, because Cilk is portable, simple, and provably efficient. In this section, we justify our choice of Cilk as our vehicle to study the issues of heterogeneous multithreaded computing. We also present background information about the Cilk runtime system.
Reference: [2] <author> Robert D. Blumofe and Charles E. Leiserson. </author> <title> Scheduling Multithreaded Computations by Work Stealing. </title> <booktitle> In Conferences in Foundations of Computer Science , Santa Fe, </booktitle> <address> New Mexico, </address> <month> November </month> <year> 1994. </year> <note> IEEE. </note>
Reference-contexts: Having heterogeneous workers also poses the problem that the slowest workers might always be hoarding the computation, slowing down the total execution time of the program. Blumofe and Leiserson <ref> [2] </ref> showed that in a P-worker homogeneous environment, the execution time of a fully strict Cilk program with T 1 total work and a critical path of length T was T P = O ( T 1 /P + T ). <p> Recalling that the effective parallelism in a homogeneous environment is T 1 /T , heterogeneity in speed only affects the effective parallelism by a constant factor, 1/(sp max ). Because the Cilk scheduler provides a view of multithreaded computations as directed acyclic graphs (dags) of tasks, Blumofe and Leiserson <ref> [2] </ref> were able to quantify the space requirements, execution time, and communication cost of a fully strict Cilk program running across P homogeneous processors in terms of measurements of this dag. <p> This proof follows directly from the proof in the homogeneous case <ref> [2] </ref>. Therefore, running Cilk programs with workers of differing performances does not affect the communication costs. To summarize, allowing workers to possess different performances does not affect the theoretical bounds on the space and communication of the execution of a multithreaded Cilk program. <p> We also assume that the time s to perform a steal operation is uniform across all of the workers. Similar to the work of Blumofe and Leiserson <ref> [2] </ref>, we use an accounting argument to analyze the running time of the Cilk workstealing scheduling algorithm. We assume that a fully strict multithreaded computation with work T 1 and critical path length T is executing in a heterogeneous environment of P workers. <p> We place a bound on the total number of steals that are performed in a computation instead. It has been shown that in the Cilk workstealing algorithm, with probability at least 1-e, the execution terminates with at most O ( P (T + lg (1/ e))) steals performed <ref> [2] </ref>. So, the expected number of steals is O (PT ). Let n i denote the number of steals performed by the ith worker throughout the computation. Therefore, we have S i=1 i n = O ( P (T + lg (1/e))). <p> We conclude that after the program has completed its execution, there are sp i n i dollars in the Steal i bucket. 15 Placing a bound on the number of dollars in the Wait bucket follows directly from the contention analysis of Blumofe and Leiserson <ref> [2] </ref>. According to Blumofe and Leiserson, the total delay incurred by M random requests made by P workers is O (M + PlgP + Plg (1/ e)) with probability at least 1- e, and the expected delay is at most O (M ).
Reference: [3] <author> Robert D. Blumofe and David S. Park. </author> <title> Scheduling Large-Scale Parallel Computations on Network of Workstations. </title> <booktitle> In Proceedings of the Third International Symposium on High Performance Distributed Computing , San Francisco, </booktitle> <address> California, </address> <month> August </month> <year> 1994. </year>
Reference-contexts: In this thesis, we show that Cilk is provably efficient in heterogeneous environments as well. To demonstrate the practicality and feasibility of a runtime system operating across a heterogeneous environment, we have produced two heterogeneous implementations of Cilk. The first runs on the MIT Phish network of workstations <ref> [3] </ref>, an environment in which the workers are of the same scale but are heterogeneous with respect to their performance speeds. The second implementation runs on the PVM message-passing layer [6]. <p> Because of this, Cilk can be easily ported to different computers. Cilk can therefore be run across a diverse set of workers, such as the Connection Machine CM5 MPP, the Intel Paragon MPP, the Silicon Graphics Power Challenge SMP, the MIT Phish network of workstations <ref> [3] </ref>, and on the PVM message-passing layer [6]. We also chose Cilk because it is efficient, both empirically and theoretically. The Cilk scheduling algorithm allows us to view a multithreaded computation as a bounded-degree directed acyclic graph of tasks. <p> Cilk on top of this layer, we are able to run Cilk programs across such a worker pool. 6 Implementation In this section, we present some of the details and problems that were encountered when we modified the implementation of Cilk that ran on the MIT Phish network of workstations <ref> [3] </ref> and the implementation on the PVM message-passing layer [6]. The major implementation difficulty encountered was that the mechanism for starting up a Cilk program was no longer valid. Originally, a Cilk program was executed by simply running the program simultaneously across the nodes of a multiprocessor.
Reference: [4] <author> D. Cohen. </author> <title> On Holy Wars and a Plea for Peace. </title> <journal> Computer , Vol. </journal> <volume> 14, No. 10, </volume> <month> October </month> <year> 1981, </year> <pages> pp. 48-54. </pages>
Reference-contexts: The main problem with a system in which workers represent data differently is that more support is necessary for these workers to communicate. For example, one instance of this language barrier is the famous Endian byte ordering problem <ref> [4] </ref>. There is one school of thought, Big Endian, which believes that bytes should be ordered by placing the most significant byte as the leftmost byte.
Reference: [5] <author> Thorsten von Eicken, David E. Culler, Seth Copen Goldstein, Klaus Erik Schauser. </author> <title> Active Messages: a Mechanism for Integrated Communication and Computation. </title> <booktitle> In Proceedings of the 19th International Symposium on Computer Architecture , Gold Coast, </booktitle> <address> Australia, </address> <month> May </month> <year> 1992. </year> <note> ACM. </note>
Reference-contexts: When a memory reference is sent in a message, it is translated into the appropriate index into the table. Upon reception, the index is translated into a memory reference in the recipients memory. We implemented this solution in the Cilk runtime system to support active messages <ref> [5] </ref>. An active message is essentially a data message and a memory reference to a piece of code, called a handler procedure. Upon reception of the message, the recipient invokes the handler procedure on the rest of the message.
Reference: [6] <author> V.S. Sunderam. </author> <title> PVM: A Framework for Parallel Distributed Computing. </title> <journal> Concurrency: Practice and Experience, </journal> <volume> 2(4) </volume> <pages> 315-339, </pages> <month> December </month> <year> 1990. </year>
Reference-contexts: The first runs on the MIT Phish network of workstations [3], an environment in which the workers are of the same scale but are heterogeneous with respect to their performance speeds. The second implementation runs on the PVM message-passing layer <ref> [6] </ref>. This implementation allows execution of a multithreaded program on any virtual computer composed of workers of different performances and scale. In generating these two implementations of Cilk, we discovered the problem that heterogeneous workers could store data differently, requiring some form of translation to allow communication between workers. <p> Cilk can therefore be run across a diverse set of workers, such as the Connection Machine CM5 MPP, the Intel Paragon MPP, the Silicon Graphics Power Challenge SMP, the MIT Phish network of workstations [3], and on the PVM message-passing layer <ref> [6] </ref>. We also chose Cilk because it is efficient, both empirically and theoretically. The Cilk scheduling algorithm allows us to view a multithreaded computation as a bounded-degree directed acyclic graph of tasks. <p> to run Cilk programs across such a worker pool. 6 Implementation In this section, we present some of the details and problems that were encountered when we modified the implementation of Cilk that ran on the MIT Phish network of workstations [3] and the implementation on the PVM message-passing layer <ref> [6] </ref>. The major implementation difficulty encountered was that the mechanism for starting up a Cilk program was no longer valid. Originally, a Cilk program was executed by simply running the program simultaneously across the nodes of a multiprocessor. <p> Furthermore, PVM also provides a mechanism for running programs on machines of different scales and speeds <ref> [6] </ref>. Because of this mechanism, we were able to concentrate our efforts on building applications for Cilk and doing theoretical analysis. 7 Conclusion We have shown that it is practical to extend the Cilk runtime system from running on a homogeneous environment to running in a heterogeneous one.
References-found: 6

