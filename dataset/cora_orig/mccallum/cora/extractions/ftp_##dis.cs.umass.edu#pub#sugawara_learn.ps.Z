URL: ftp://dis.cs.umass.edu/pub/sugawara_learn.ps.Z
Refering-URL: http://dis.cs.umass.edu/research/coordination-learn.html
Root-URL: 
Email: sugawara@ntt-20.ntt.jp lesser@cs.umass.edu  
Title: Learning Coordination Plans in Distributed Problem-Solving Environments Topics: Learning and Adaptation in Multi-agent Worlds; Coordination;
Author: Toshiharu Sugawara Victor Lesser 
Note: CFP  This research was supported in part by a grant from ARPA contract N00014-92-J-1698, an ONR contract N00014-92-J-1450, and a grant from Network General Corporation. The content of the information does not necessarily reflect the position or the policy of the organizations supporting this research, and no official endorsement should be inferred.  
Address: Atsugi, Kanagawa 243-01 Amherst, MA 01003 Japan USA  
Affiliation: NTT Basic Research Labs. Department of Computer Science 3-1 Wakamiya, Morinosato University of Massachusetts  
Abstract: Coordination is an essential technique in cooperative, distributed multi-agent systems. However, sophisticated coordination strategies are not always cost-effective in all problem-solving situations. This paper presents a learning method to acquire coordination plans for specific problem-solving situations so that the appropriate type of coordination strategy is used. This learning is accomplished by recording and analyzing traces of inferences after problem solving. The analysis results in identification of situations where inappropriate coordination strategies have caused redundant activities or the lack of timely execution of important activities, thus degrading system performance. Based on this identification, situation-specific coordination plans are created which use additional non-local information about activities in the networks to remedy the problem. An example from a real distributed problem-solving application involving diagnosis of a local area network is described. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Case, J., Fedor, M., Schoffstall, M. and Davin, J. </author> <title> "A Simple Network Management Protocol (SNMP)," </title> <address> RFC1157, </address> <year> 1990. </year>
Reference-contexts: This plan, which is not the optimal way to gather this statistic, produces only an approximate value for RTT. A better plan would have been to use the Simple Network Management Protocol (SNMP), which is a communication protocol designed for acquiring network management data <ref> [1] </ref>, but this was not possible in the example since the adjacent network routers did not implement it.
Reference: [2] <author> Corkill, D. D. and Lesser, V. R., </author> <title> "The Use of Meta-Level Control for Coordination in a Distributed Problem Solving Network" (long paper), </title> <booktitle> Proc. of the Eighth International Joint Conference on Artificial Intelligence, </booktitle> <month> August </month> <year> 1983, </year> <pages> pp. 748-756, </pages> <address> Karlsruhe, FRG. </address> <note> (Also published in Computer Architectures for Artificial Intelligence Applications, </note> <editor> Benjamin W. Wah and G.-J. Li (eds.), </editor> <publisher> IEEE Computer Society Press, </publisher> <pages> pp. 507-515, </pages> <year> 1986.) </year>
Reference-contexts: This basic paradigm of monitoring, analysis and replanning (learning, in this case) is very similar to the one laid out but never implemented for use in organizational self-design <ref> [2] </ref> and a partially implemented approach to meta-level control for a single-agent system [8]. 4 Learning Steps This section details the steps of the learning process using the example problem discussed previously. 4.1 Recording Inference Traces An agent must be able to record traces of reasoning for analysis by the learning
Reference: [3] <author> Decker, K. and Lesser, V. R. </author> <title> "Quantitative Modeling of Complex Environments," International Journal of Intelligent Systems in Accounting, Finance and Management, special issue on Mathematical and Computational Models of Organizations: Models and Characteristics of Agent Behavior, </title> <year> 1993. </year>
Reference-contexts: The existence of this problem and the fact that it was caused by the LODES agents themselves will be the trigger for the learning component to be invoked. 3 The Learning Framework Our approach to learning coordination rules can be described in the coordination model proposed by Decker and Lesser <ref> [3, 4] </ref> based on generic coordination relationships. <p> this model, each agent makes scheduling decisions based on a subjective view of its own and other agents' task structures and the relationships among these tasks (such as enable, facilitate, and support-relations 1 ) and 1 This is a new relationship that was not in the original formulation discussed in <ref> [3] </ref> and relates to how a task in one agent can effect the subjective view of another agent's task structure by changing the importance rating of its tasks. <p> The execution of a task means that all the subtasks are executed in a manner consistent with the specified partial order. A subtask may further be divided into smaller subtasks. The individual task that cannot be divided into subtasks is called an operation (in <ref> [3] </ref>, this is called a method), which must be an executable form. There are usually a number of different tasks that can be used to achieve a goal. The LODES planner specifies the alternative task structures to achieve a specific diagnostic goal and then selects an appropriate task among them.
Reference: [4] <author> Decker, K.S. and Lesser, </author> <title> V.R. "Designing a Family of Coordination Algorithms," </title> <booktitle> in Proceedings of the 13th International Workshop of Distributed Aritificial Intelligence, </booktitle> <month> July </month> <year> 1994. </year>
Reference-contexts: The existence of this problem and the fact that it was caused by the LODES agents themselves will be the trigger for the learning component to be invoked. 3 The Learning Framework Our approach to learning coordination rules can be described in the coordination model proposed by Decker and Lesser <ref> [3, 4] </ref> based on generic coordination relationships.
Reference: [5] <author> DeJong, G. </author> <title> "Generalizations Based on Explanations," </title> <booktitle> Proc. of 7th IJCAI, </booktitle> <pages> pp. 67-69, </pages> <year> 1981. </year>
Reference-contexts: In the remainder of the paper, we develop this distributed learning component in detail, based on EBL techniques <ref> [5, 12] </ref> using a limited domain model and inductive techniques such as comparative analysis [9], and discuss the implementation of these ideas in a real distributed problem-solving system, LODES [15, 16], which performs internetwork diagnosis. 2 An Example Problem The LODES network diagnosis system observes message traffic on the network in
Reference: [6] <author> Durfee, E. H., Lesser, V. R. and Corkill, D. D., </author> <title> "Coherent Cooperation Among Communicating Problem Solvers," </title> <journal> IEEE Transactions on Computers, </journal> <volume> Vol. 36, Issue 11, </volume> <month> November </month> <year> 1987, </year> <pages> pp. 1275-1291. </pages> <note> (Also published in Readings in Distributed Artificial Intelligence, </note> <editor> A. Bond and L. Gasser (eds.), </editor> <publisher> Morgan Kaufmann Publishers, </publisher> <address> California, </address> <year> 1988, </year> <pages> pp. 268-284.) </pages>
Reference-contexts: If an agent has a view of the task structures of other agents it can make more informed choices <ref> [6, 7, 11] </ref>. Another difficulty is that even with the availability of this type of meta-level information, there is still residual uncertainty about outcomes of tasks and what future tasks will be coming into the system which may result in agents still exhibiting non-coherent behavior.
Reference: [7] <author> Durfee, E. H. and Lesser, V. R., </author> <title> "Partial Global Planning: A Coordination Framework for Distributed Hypothesis Formation," </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics, </journal> <volume> 21(5) </volume> <pages> 1167-1183, </pages> <month> September/October </month> <year> 1991. </year>
Reference-contexts: If an agent has a view of the task structures of other agents it can make more informed choices <ref> [6, 7, 11] </ref>. Another difficulty is that even with the availability of this type of meta-level information, there is still residual uncertainty about outcomes of tasks and what future tasks will be coming into the system which may result in agents still exhibiting non-coherent behavior.
Reference: [8] <author> Hudlicka, E. and Lesser, V. R., </author> <title> "Meta-Level Control Through Fault Detection and Diagnosis," </title> <booktitle> Proc. of the 1984 National Conference on AI, </booktitle> <year> 1984, </year> <pages> pp. 153-161. </pages>
Reference-contexts: This basic paradigm of monitoring, analysis and replanning (learning, in this case) is very similar to the one laid out but never implemented for use in organizational self-design [2] and a partially implemented approach to meta-level control for a single-agent system <ref> [8] </ref>. 4 Learning Steps This section details the steps of the learning process using the example problem discussed previously. 4.1 Recording Inference Traces An agent must be able to record traces of reasoning for analysis by the learning component. <p> This process of comparison is called comparative analysis (CA) <ref> [8] </ref>. In this example, however, since L1 ...
Reference: [9] <author> Hudlicka, E. and Lesser, V. R., </author> <title> "Modeling and Diagnosing Problem-Solving System Behavior," </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics, </journal> <volume> Vol. 17, Number 3, </volume> <month> May/June </month> <year> 1987, </year> <pages> pp. 407-419. </pages> <note> (Also published in Readings in Distributed Artificial Intelligence, </note> <editor> A. Bond and L. Gasser (eds.), </editor> <publisher> Morgan Kaufmann Publishers, </publisher> <address> California, </address> <year> 1988, </year> <pages> pp. 490-502.) 14 </pages>
Reference-contexts: In the remainder of the paper, we develop this distributed learning component in detail, based on EBL techniques [5, 12] using a limited domain model and inductive techniques such as comparative analysis <ref> [9] </ref>, and discuss the implementation of these ideas in a real distributed problem-solving system, LODES [15, 16], which performs internetwork diagnosis. 2 An Example Problem The LODES network diagnosis system observes message traffic on the network in order to detect and analyze situations which indicate a hardware or software problem in
Reference: [10] <author> Kinney, M. and Tsatsoulis, </author> <title> C.,"Learning Communication Strategies in Dis--tributed Agent Environments," </title> <note> Working Paper CECASE-WP-93-4, </note> <institution> Center for Excellence in Computer-Aided Systems Engineering, The University of Kansas, Lawrence, </institution> <year> 1993. </year>
Reference-contexts: This approach to learning in a multiagent system is quite different in character from reinforcement learning approaches or statistical approaches to learning rules and parameters done by other researchers <ref> [10, 13, 14] </ref>. 13
Reference: [11] <author> Lesser, V. R., </author> <title> "A Retrospective View of FA/C Distributed Problem Solving," </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics, </journal> <volume> 21(6) </volume> <pages> 1347-1362, </pages> <address> Nov/Dec. </address> <year> 1991. </year>
Reference-contexts: If an agent has a view of the task structures of other agents it can make more informed choices <ref> [6, 7, 11] </ref>. Another difficulty is that even with the availability of this type of meta-level information, there is still residual uncertainty about outcomes of tasks and what future tasks will be coming into the system which may result in agents still exhibiting non-coherent behavior. <p> Thus, for specific problem-solving situations, due to the inherent uncertainty in agents' activities and the cost of meta-level processing, it may not be worthwhile to acquire a complete view of other agents' activities, and thus some level of non-coherent activity may be the optimal coordination strategy <ref> [11] </ref>. For example, coordination to avoid redundant activities may be unnecessary if processing resources are not overloaded and if the communication channel is neither expensive nor overloaded. In this case, local problem solving is done more efficiently where there is no additional overhead for coordination.
Reference: [12] <author> Mitchell, T. M., Keller, R. M. and Kedar-Cabelli, S. T. </author> <title> "Explanation-Based Generalizations: A Unifying View," </title> <journal> Machine Learning, </journal> <volume> Vol. 1, </volume> <pages> pp. 47-80, </pages> <year> 1986. </year>
Reference-contexts: In the remainder of the paper, we develop this distributed learning component in detail, based on EBL techniques <ref> [5, 12] </ref> using a limited domain model and inductive techniques such as comparative analysis [9], and discuss the implementation of these ideas in a real distributed problem-solving system, LODES [15, 16], which performs internetwork diagnosis. 2 An Example Problem The LODES network diagnosis system observes message traffic on the network in
Reference: [13] <author> Sen, S., Sekaran, M. and Hale, J., </author> <title> "Learning to coordinate without sharing information," </title> <booktitle> Proc. of AAAI94, </booktitle> <pages> pp. 426-431, </pages> <year> 1994. </year>
Reference-contexts: This approach to learning in a multiagent system is quite different in character from reinforcement learning approaches or statistical approaches to learning rules and parameters done by other researchers <ref> [10, 13, 14] </ref>. 13
Reference: [14] <author> Shoham, Y. and Tennenholtz, M., </author> <title> "Emergent Conventions in Multi-Agent Systems: initial experimental results and observations," </title> <booktitle> Proc. of KR-92, </booktitle> <year> 1992. </year>
Reference-contexts: This approach to learning in a multiagent system is quite different in character from reinforcement learning approaches or statistical approaches to learning rules and parameters done by other researchers <ref> [10, 13, 14] </ref>. 13
Reference: [15] <author> Sugawara, T. </author> <title> "A Cooperative LAN Diagnostic and Observation Expert System," </title> <booktitle> Proc. of IEEE Phoenix Conf. on Comp. and Comm., </booktitle> <pages> pp. 667-674, </pages> <year> 1990. </year>
Reference-contexts: In the remainder of the paper, we develop this distributed learning component in detail, based on EBL techniques [5, 12] using a limited domain model and inductive techniques such as comparative analysis [9], and discuss the implementation of these ideas in a real distributed problem-solving system, LODES <ref> [15, 16] </ref>, which performs internetwork diagnosis. 2 An Example Problem The LODES network diagnosis system observes message traffic on the network in order to detect and analyze situations which indicate a hardware or software problem in the network.
Reference: [16] <author> Sugawara, T. and Murakami, K. </author> <title> "A Multiagent Diagnostic System for In-ternetwork Problems," </title> <booktitle> Proc. of INET'92, </booktitle> <address> Kobe, Japan, </address> <year> 1992. </year>
Reference-contexts: In the remainder of the paper, we develop this distributed learning component in detail, based on EBL techniques [5, 12] using a limited domain model and inductive techniques such as comparative analysis [9], and discuss the implementation of these ideas in a real distributed problem-solving system, LODES <ref> [15, 16] </ref>, which performs internetwork diagnosis. 2 An Example Problem The LODES network diagnosis system observes message traffic on the network in order to detect and analyze situations which indicate a hardware or software problem in the network.
Reference: [17] <author> Sugawara, T. and Lesser, V. R. </author> <title> "On-Line Learning of Coordination Plans," </title> <type> COINS Technical Report, 93-27, </type> <institution> Univ. of Massachusetts, </institution> <year> 1993. </year> <note> (The shorter version of this paper is also published in Proc. of the 12th Int. Workshop on Distributed AI, 1993.) 15 </note>
Reference-contexts: Two cases are possible depending on the result of the 2 This is done by the meta-level controller within an agent or by an external monitor for specific (shared) resources (such as network resource or database). What kinds of events are detected are described in <ref> [17] </ref>. It is also assumed that an agent locally records an abstracted trace of its recent problem-solving actions which can be reviewed on-line by the learning component. 4 reproduction. <p> L7 diagnose the same secondary problem in this example, agents can identify the situation by comparing their traces 3 This approach assumes that we have stored some amount of history in the agent about past problem-solving experiences in a way to facilitate such analysis <ref> [17] </ref>. 10 Table 1 (a): Comparative Analysis (L5 and L6) Variables values in L5 values in L6 Adjacent networks Net4, Net6 Net5 and Net7 eliminated Adjacent routers R4, R5 R6, R7 eliminated End-nodes (L1, L7) (L1, L7) Src-MAC xx:xx:xx:f:2a:3b xx:xx:xx:0:12:8c eliminated Dst-MAC xx:xx:xx:f:2a:3a xx:xx:xx:0:2f:7e eliminated Type-of-Storm ICMP-Echoes ICMP-Echoes MaxThrput1 10,000,000 64,000 <p> The learning enables the agents to create their plans based on more accurate and appropriate views about agent networks, task relations and their environments as illustrated in Fig. 4 (b). An efficiency-oriented example is described in <ref> [17] </ref>. 6 Conclusion Although coordination is an essential technique for cooperative distributed problem solving, there needs to be a balance between too much or too little coordination since both can degrade overall system performance.
References-found: 17

