URL: http://www.cs.umass.edu/~dprecup/publications/McGeoch-Precup-Cohen-IDA97.ps
Refering-URL: http://www.cs.umass.edu/~dprecup/publications.html
Root-URL: 
Email: ccm@cs.amherst.edu  precup,cohen@cs.umass.edu  
Title: How to Find Big-Oh in Your Data Set (and How Not To)  
Author: C. C. McGeoch D. Precup P. R. Cohen 
Date: January 31, 1997  
Address: Amherst College, Amherst, MA 01002  Amherst, MA 01003  
Affiliation: Department of Mathematics and Computer Science,  Department of Computer Science, University of Massachussetts  
Abstract: The empirical curve bounding problem is defined as follows. Suppose data vectors X; Y are presented such that E(Y [i]) = f (X[i]) where f (x) is an unknown function. The problem is to analyze X; Y and obtain complexity bounds O(g u (x)) and (g l (x)) on the function f (x). As no algorithm for empirical curve bounding can be guaranteed correct, we consider heuristics. Five heuristic algorithms are presented here, together with analytical results guaranteeing correctness for certain families of functions. Experimental evaluations of the correctness and tightness of bounds obtained by the rules for several constructed functions f (x) and real datasets are described. A hybrid method is shown to have very good performance on some kinds of functions, suggesting a general, iterative refinement procedure in which diagnostic features of the results of applying particular methods can be used to select additional methods. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. C. </author> <title> Atkinson (1987) Plots, Transformations and Regression: an Introduction to Graphical Methods of Diagnostic Regression Analysis, </title> <publisher> Oxford Science. </publisher>
Reference-contexts: With standard normality assumptions about an added random error term, it is possible to calculate confidence intervals for the estimate b; see <ref> [1] </ref> or [5] for details. 2.5 The Difference Rule. The Difference heuristic extends Newton's divided difference method for polynomial interpolation (see [15] for an introduction) to be defined when Y contains random noise and nonpolynomial terms.
Reference: [2] <author> R. A. Becker, J. A. Chambers, and A. R. </author> <title> Wilks (1988) The New S Language: A Programming Enviornment for Data Analysis and Graphics, </title> <publisher> Wadsworth & Brooks/Cole. </publisher>
Reference-contexts: Much is known about numerical robustness, best choice of design points, and (non)convergence when k d. 3 Experimental Results The rules have been implemented in the S language <ref> [2] </ref>, designed for statistical and graphical computations. The experiments were carried out on a Sun SPARCstation ELC, using functions running within the Splus statistical/graphics package; some supporting experiments were conducted using the CLASP statistical/graphics package, and the method labelled HY in Figure 1 was implemented in C.
Reference: [3] <author> J. L. Bentley, D. S. Johnson, F. T. Leighton, and C. C. </author> <title> McGeoch (1983) "An experimental study of bin packing," </title> <booktitle> Proceedings of the 21st Allerton Conference on Communication, Control, and Computing, </booktitle> <institution> University of Illinois, </institution> <address> Urbana-Champaign. </address> <pages> pp 51-60. </pages>
Reference-contexts: Data sets 1 and 2 are the expected costs of Quicksort and Insertion Sort, for which formulas are known exactly [9]. Sets 3 through 6 are from experiments on the FFD and FF rules for bin packing <ref> [3] </ref>, [4]. Sets 7 and 8 are from experiments on distances in random graphs having uniform edge weights [11]. The X vectors have various ranges and intervals; except for the first two cases, the Y s represent means of several independent trials. Results appear in Figure 2.
Reference: [4] <author> J. L. Bentley, D. S. Johnson, C. C. McGeoch and L. A. </author> <title> McGeoch (1984). "Some unexpected expected behavior results for bin packing," </title> <booktitle> Proceedings of the 16th Symposium on Theory of Computing, ACM, </booktitle> <address> NY. </address> <pages> pp 279-298. </pages>
Reference-contexts: Data sets 1 and 2 are the expected costs of Quicksort and Insertion Sort, for which formulas are known exactly [9]. Sets 3 through 6 are from experiments on the FFD and FF rules for bin packing [3], <ref> [4] </ref>. Sets 7 and 8 are from experiments on distances in random graphs having uniform edge weights [11]. The X vectors have various ranges and intervals; except for the first two cases, the Y s represent means of several independent trials. Results appear in Figure 2.
Reference: [5] <author> G. P. Box, W. G. Hunter, and J. S. </author> <title> Hunter (1978) Statistics for Experimenters, </title> <publisher> Wiley & Sons. </publisher>
Reference-contexts: For example, if Y = X 2 , then a plot of X vs p Y would produce a straight line, as would a plot of X 2 vs Y . The Box-Cox ([1], <ref> [5] </ref>) transformation on Y is parameterized by . This transformation is applied together with a "straightness" statistic that permits comparisons across different parameter levels. <p> With standard normality assumptions about an added random error term, it is possible to calculate confidence intervals for the estimate b; see [1] or <ref> [5] </ref> for details. 2.5 The Difference Rule. The Difference heuristic extends Newton's divided difference method for polynomial interpolation (see [15] for an introduction) to be defined when Y contains random noise and nonpolynomial terms.
Reference: [6] <author> J. M. Chambers et al. </author> <title> (1983) Graphical Methods for Data Analysis, </title> <publisher> Duxbury Press. </publisher>
Reference: [7] <author> P. R. </author> <title> Cohen (1995) Empirical Methods for Artificial Intelligence, </title> <publisher> the MIT Press. </publisher>
Reference: [8] <author> T. Cormen, C. Leiserson and R. </author> <title> Rivest (1990) Introduction to Algorithms, </title> <publisher> the MIT Press. </publisher>
Reference: [9] <author> D. E. </author> <title> Knuth (1981), The Art of Computer Programming: Vol. 3 Sorting and Searching, </title> <publisher> Addison Wesley. </publisher>
Reference-contexts: The data sets were not originally intended for this purpose and may give more realistic indications of performance. Data sets 1 and 2 are the expected costs of Quicksort and Insertion Sort, for which formulas are known exactly <ref> [9] </ref>. Sets 3 through 6 are from experiments on the FFD and FF rules for bin packing [3], [4]. Sets 7 and 8 are from experiments on distances in random graphs having uniform edge weights [11].
Reference: [10] <author> C. C. </author> <title> McGeoch (1992), "Analyzing algorithms by simulation: Variance reduction techniques and simulation speedups," </title> <journal> ACM Computing Surveys. </journal> <volume> (245)2, </volume> <pages> pp. 195-212. </pages>
Reference-contexts: For example, a robust linear fit would probably make more sense than linear regression as an oracle for slope. Encouragingly, it is usually possible to reduce variance in data by increasing the number of trials or by applying variance reduction techniques <ref> [10] </ref>. With greater variance in Y the Power and the BoxCox rules more frequently return claims of close, which are hard to evaluate. Large variance has less impact when the change in Y is large.
Reference: [11] <author> C. C. </author> <title> McGeoch (1995) "All pairs shortest paths and the essential subgraph," </title> <journal> Algorithmica (13), </journal> <pages> pp. 426-441. </pages>
Reference-contexts: Sets 3 through 6 are from experiments on the FFD and FF rules for bin packing [3], [4]. Sets 7 and 8 are from experiments on distances in random graphs having uniform edge weights <ref> [11] </ref>. The X vectors have various ranges and intervals; except for the first two cases, the Y s represent means of several independent trials. Results appear in Figure 2. The left column presents the best analytical bounds known for each.
Reference: [12] <author> J. O. </author> <title> Rawlings (1988) Applied Regression Analysis: A Research Tool, </title> <publisher> Wadsworth & Brooks/Cole. </publisher>
Reference-contexts: In our implementation, if the rule is unable to find an initial DownUp curve within preset limits, it stops and reports the original guess provided by the user. 2.3 Power Rule The Power Rule (PW) modifies a standard method for curve-fitting (see <ref> [12] </ref>). Suppose that F P contains functions f (x) = cx d for positive c and d. Let y = f (x). Transforming x 0 = ln (x) and y 0 = ln (y), we obtain y 0 = dx 0 + c.
Reference: [13] <author> C. </author> <title> Schaffer (1990) Domain-Independent Scientific Function Finding, </title> <type> Ph.D. Thesis, Technical Report LCSR-TR-149, </type> <institution> Department of Computer Science, Rutgers University. </institution>
Reference-contexts: We can find no techniques in the data analysis literature designed for finding bounds on data, although much is known about fitting curves to data (see sec. 5). Approaches to domain-independent function finding <ref> [13] </ref> might be adapted to curve bounding and some are considered here. For any finite set of points X there are functions f (x) of arbitrarily high degree but indistinguishable from the constant c at those points.
Reference: [14] <author> R. Sedgewick (1975), Quicksort. Ph. D. </author> <type> Thesis, </type> <institution> Stanford University. </institution>
Reference: [15] <author> J. Soer and R. </author> <title> Bulirsch (1993) Introduction to Numerical Analysis, </title> <publisher> Springer-Verlag. </publisher>
Reference-contexts: With standard normality assumptions about an added random error term, it is possible to calculate confidence intervals for the estimate b; see [1] or [5] for details. 2.5 The Difference Rule. The Difference heuristic extends Newton's divided difference method for polynomial interpolation (see <ref> [15] </ref> for an introduction) to be defined when Y contains random noise and nonpolynomial terms. The method iterates numerical differentiation on X and Y until the data appears non-increasing, according to the Trend oracle.
Reference: [16] <author> J. W. </author> <title> Tukey (1977) Exploratory Data Analysis, </title> <publisher> Addison-Wesley. </publisher>
Reference-contexts: This approach was abandoned early in this research. The second is based on Tukey's <ref> [16] </ref> "ladder of transformations." This approach also gives contradictory results depending on whether the transformation is applied to Y or X.
Reference: [17] <author> L. </author> <title> Weisner (1938) Introduction to the Theory of Equations., </title> <publisher> Macmillan. </publisher>
Reference-contexts: If x r &gt; 0, then the ratio shows an initial decrease followed by an eventual increase. These properties are established by an application of Descartes' Rule of Signs <ref> [17] </ref>, which bounds the number of sign changes in the derivative of the ratio. If a plot of a finite sample of the ratio (X vs Y =f (X)) shows an eventual increasing trend, then (2) must hold.
References-found: 17

