URL: http://www.ai.univie.ac.at/~juffi/publications/ecml-94.ps.gz
Refering-URL: http://www.ai.univie.ac.at/~juffi/publications/publications.html
Root-URL: 
Email: juffi@ai.univie.ac.at  
Title: Fossil: A Robust Relational Learner  
Author: Johannes Furnkranz 
Address: Schottengasse 3 A-1010 Vienna Austria  
Affiliation: Austrian Research Institute for Artificial Intelligence  
Abstract: The research reported in this paper describes Fossil, an ILP system that uses a search heuristic based on statistical correlation. This algorithm implements a new method for learning useful concepts in the presence of noise. In contrast to Foil's stopping criterion, which allows theories to grow in complexity as the size of the training sets increases, we propose a new stopping criterion that is independent of the number of training examples. Instead, Fossil's stopping criterion depends on a search heuristic that estimates the utility of literals on a uniform scale. In addition we outline how this feature can be used for top-down pruning and present some preliminary results. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> Kamal M. Ali and Michael J. Pazzani. HYDRA: </author> <title> A noise-tolerant relational concept learning algorithm. </title> <booktitle> In Proceedings of the Thirteenth Joint International Conference on Artificial Intelligence, </booktitle> <pages> pages 1064-1071, </pages> <address> Chambery, France, </address> <year> 1993. </year>
Reference-contexts: While the descriptions induced by Foil for the large training sets were totally incomprehensible 6 This Problem is known as the Small Disjuncts Problem [13] and has recently been addressed with an relational learning algorithm using probabilistic concept descrip tions <ref> [1] </ref>. Fig. 2. A Comparison of Foil and Fossil with different training set sizes illegal (A,B,C,D,E,F) :- C = E. illegal (A,B,C,D,E,F) :- D = F. illegal (A,B,C,D,E,F) :- adjacent (A,E), adjacent (B,F). Fig. 3.
Reference: 2. <author> D. Angluin and P. Laird. </author> <title> Learning from noisy examples. </title> <journal> Machine Learning, </journal> <volume> 2(4) </volume> <pages> 343-370, </pages> <year> 1988. </year>
Reference-contexts: Background knowledge consists of the predicates X &lt; Y, X = Y and adjacent (X,Y) 3 . Recursion was not allowed for efficiency reasons. Class noise in the training instances was generated according to the Classification Noise Process described in <ref> [2] </ref>.
Reference: 3. <author> Ivan Bratko and Igor Kononenko. </author> <title> Learning diagnostic rules from incomplete and noisy data. </title> <editor> In B. Phelps, editor, </editor> <booktitle> Interactions in AI and Statistical Methods, </booktitle> <pages> pages 142-153, </pages> <address> London, </address> <year> 1986. </year>
Reference-contexts: 1 Introduction Being able to deal with noisy domains is a must for learning algorithms that are meant to learn concepts from real-world data. Significant effort has been made into investigating the effect of noisy data on attribute-value learning algorithms (see e.g. <ref> [22, 3, 4, 17] </ref>). Not surprisingly, noise handling methods have also entered the rapidly growing field of Inductive Logic Programming [15].
Reference: 4. <author> L. Breiman, J. Friedman, R. Olshen, and C. Stone. </author> <title> Classification and Regression Trees. </title> <publisher> Wadsworth & Brooks, </publisher> <address> Pacific Grove, CA, </address> <year> 1984. </year>
Reference-contexts: 1 Introduction Being able to deal with noisy domains is a must for learning algorithms that are meant to learn concepts from real-world data. Significant effort has been made into investigating the effect of noisy data on attribute-value learning algorithms (see e.g. <ref> [22, 3, 4, 17] </ref>). Not surprisingly, noise handling methods have also entered the rapidly growing field of Inductive Logic Programming [15]. <p> Coincidentially, the learned concepts are of about equal complexity at this point. The curve for the predictive accuracy is U-shaped, similar to some results from Decision Tree learning (see e.g. <ref> [4] </ref>). There is a transition from overfitting the noise to over-generalizing the rules. A low setting of C has a tendency to fit the noise, because most of the literals 3 Because of a misunderstanding our definition of adjacent actually was adjacent or equal.
Reference: 5. <author> Clifford A. Brunk and Michael J. Pazzani. </author> <title> An investigation of noise-tolerant relational concept learning algorithms. </title> <booktitle> In Proceedings of the 8th International Workshop on Machine Learning, </booktitle> <pages> pages 389-393, </pages> <address> Evanston, Illinois, </address> <year> 1991. </year>
Reference-contexts: Not surprisingly, noise handling methods have also entered the rapidly growing field of Inductive Logic Programming [15]. Linus [16] relies directly on the noise handling abilities of decision tree learning algorithms, others, like mFoil [9] and REP <ref> [5] </ref>, have adapted well-known methods from attribute-value learning for the ILP framework. This paper presents Fossil, a Foil-like algorithm [20] that uses a search heuristic based on statistical correlation (Sect. 2). <p> In particular we see some relationship to pruning methods used e.g. in <ref> [5] </ref> or [25]. The major difference, however, is that we get a series of different concept descriptions in a general to specific order (top-down) as opposed to pruning methods the generate a most specific theory first and then successively generalize it (bottom-up).
Reference: 6. <author> Wray Buntine and Tim Niblett. </author> <title> A further comparison of splitting rules for decision-tree induction. </title> <journal> Machine Learning, </journal> <volume> 8 </volume> <pages> 75-85, </pages> <year> 1992. </year>
Reference-contexts: of tuples T c 0 (which in general will have a different size) and the process continues as described in [20]. 2.2 Interesting Features of the Correlation Heuristic The information gain heuristic used in C4.5 [22] and Foil has been extensively compared to other search heuristics in decision tree generation <ref> [18, 6] </ref> and Inductive Logic Programming [14]. The general consensus seems to be that it is hard to improve on this heuristic in terms of predictive accuracy in learning from noise-free data.
Reference: 7. <author> Peter Clark and Robin Boswell. </author> <title> Rule induction with CN2: Some recent improve-ments. </title> <booktitle> In Proceedings of the 5th European Working Session of Learning, </booktitle> <pages> pages 151-163, </pages> <address> Porto, Portugal, </address> <year> 1991. </year>
Reference-contexts: converges towards a useful theory. 4.4 Comparison with mFoil mFoil [9] is an algorithm based on Foil that has adapted several features from the CN2 learning algorithm, such as the use of the Laplace and m-estimate as a search heuristic and the use of significance testing as a stopping criterion <ref> [7] </ref>. These methods have proved very effective for noise handling. In addition mFoil uses beam search (default beam width 5) and can make use of mode and type information to reduce the search space, features that are scheduled to be incorporated into Fossil in the near future.
Reference: 8. <author> Luc De Raedt and Maurice Bruynooghe. </author> <title> Indirect relevance and bias in inductive concept learning. </title> <journal> Knowledge Acquisition, </journal> <volume> 2 </volume> <pages> 365-390, </pages> <year> 1990. </year>
Reference-contexts: In the light of [24] a method like this may be viewed as automatically shifting the Overfitting Avoidance Bias, in some respect similar to Clint, where a shift of Languate Bias is realized by learning in increasingly complex representation languages <ref> [8] </ref>.
Reference: 9. <author> Saso Dzeroski and Ivan Bratko. </author> <title> Handling noise in Inductive Logic Programming. </title> <booktitle> In Proceedings of the International Workshop on Inductive Logic Programming, </booktitle> <address> Tokyo, Japan, </address> <year> 1992. </year>
Reference-contexts: Not surprisingly, noise handling methods have also entered the rapidly growing field of Inductive Logic Programming [15]. Linus [16] relies directly on the noise handling abilities of decision tree learning algorithms, others, like mFoil <ref> [9] </ref> and REP [5], have adapted well-known methods from attribute-value learning for the ILP framework. This paper presents Fossil, a Foil-like algorithm [20] that uses a search heuristic based on statistical correlation (Sect. 2). <p> It was mainly this improvement that lead to a relatively good performance of Fossil at tests on the mesh data (32% as opposed to 21% for mFoil <ref> [9] </ref>) 2 This has actually happened several times, and is evident in the result with 50% Noise (i.e. random classification) in Table 1, where Fossil did not learn a single clause in any of the 10 training sets. 4 Experimental Evaluation 4.1 Setup of the Experiments For the experiments in this <p> Statistical measures usually improve with the size of the training sets and so does the quality of the rules induced by Fossil. While both Foil and Fossil successively improve their predictive accuracy with increasing training set sizes, only Fossil converges towards a useful theory. 4.4 Comparison with mFoil mFoil <ref> [9] </ref> is an algorithm based on Foil that has adapted several features from the CN2 learning algorithm, such as the use of the Laplace and m-estimate as a search heuristic and the use of significance testing as a stopping criterion [7]. These methods have proved very effective for noise handling. <p> However, one of the points to make here is that a good value of the m parameter is not only dependent on the amount of noise (as can be seen from the results given in <ref> [9] </ref> and [10]), but also on the size of the example set. Fossil's cutoff parameter on the other hand seems to do reasonably well at different levels of noise and at different training set sizes. <p> However, with this approach one has no guarantee that one does not miss a better theory with a different m. The results given in <ref> [9] </ref> also indicate that the choice of a good m depends on the amount of noise in the data, while our experiments in Sect. 4.4 also suggest a dependence on the size of the training set.
Reference: 10. <author> Saso Dzeroski and Ivan Bratko. </author> <title> Using the m-estimate in Inductive Logic Programming. In Logical Approaches to Machine Learning, </title> <booktitle> Workshop Notes of the 10th European Conference on AI, </booktitle> <address> Vienna, Austria, </address> <year> 1992. </year>
Reference-contexts: Thus a noise level of in our experiments is roughly equivalent to a noise level of 2 in the results reported e.g. in <ref> [11, 10] </ref>. Fig. 1. Experiments with different settings for the Cutoff will have a correlation above the threshold. 5 Conversely, a too optimistic setting of C results in over-generalization as too few literals have a correlation above the threshold. <p> In the first series we compared the behavior of the two systems with 10 training sets of 100 instances each at different noise levels, which has been the standard procedure for evaluating many ILP systems <ref> [20, 11, 10, 19] </ref>. In the second experiment we evaluated both programs at a constant noise level of 10%, but with an increasing number of training instances. According to the results of the previous experiments we set C = 0:3 and never changed this setting. Comparison at Different Noise Levels. <p> However, one of the points to make here is that a good value of the m parameter is not only dependent on the amount of noise (as can be seen from the results given in [9] and <ref> [10] </ref>), but also on the size of the example set. Fossil's cutoff parameter on the other hand seems to do reasonably well at different levels of noise and at different training set sizes.
Reference: 11. <author> Saso Dzeroski and Nada Lavrac. </author> <title> Learning relations from noisy examples: An empirical comparison of LINUS and FOIL. </title> <booktitle> In Proceedings of the 8th International Workshop on Machine Learning, </booktitle> <pages> pages 399-402, </pages> <address> Evanston, Illinois, </address> <year> 1991. </year>
Reference-contexts: Thus a noise level of in our experiments is roughly equivalent to a noise level of 2 in the results reported e.g. in <ref> [11, 10] </ref>. Fig. 1. Experiments with different settings for the Cutoff will have a correlation above the threshold. 5 Conversely, a too optimistic setting of C results in over-generalization as too few literals have a correlation above the threshold. <p> In the first series we compared the behavior of the two systems with 10 training sets of 100 instances each at different noise levels, which has been the standard procedure for evaluating many ILP systems <ref> [20, 11, 10, 19] </ref>. In the second experiment we evaluated both programs at a constant noise level of 10%, but with an increasing number of training instances. According to the results of the previous experiments we set C = 0:3 and never changed this setting. Comparison at Different Noise Levels.
Reference: 12. <author> Johannes Furnkranz. Fossil: </author> <title> A robust relational learner. </title> <type> Technical Report TR-93-28, </type> <institution> Austrian Research Institute for Artificial Intelligence, </institution> <year> 1993. </year> <note> Extended version. </note>
Reference-contexts: converged towards the simple, approximate theory of Fig. 3. 7 In fact, in 8 of 10 training sets with 2000 examples exactly this theory was learned, while in the other two the literal A "== C had been added to the first clause, which still gives a 97.98% correct theory <ref> [12] </ref>. What seems to be responsible for the drastic increase in the complexity of the learned clauses is that Foil's stopping criterion [20] is dependent on the size of the training set. In the KRK domain it performs very well on sample sizes of 100 training examples. <p> found in Table 2. 7 This theory correctly classifies all but 4060 of the 262,144 possible domain examples (98.45%). 2940 positions (1.12%)with WK and WR on the same squares and 1120 positions (0.43%) where the WK is between WR and BK on the same row or file are erroneously classified <ref> [12] </ref>. (Remember that we have defined adjacent to mean adjacent or equal). Table 2.
Reference: 13. <author> R. Holte, L. Acker, and B. Porter. </author> <title> Concept learning and the problem of small disjuncts. </title> <booktitle> In Proceedings of the 11th International Joint Conference on Artificial Intelligence, </booktitle> <address> Detroit, MI, </address> <year> 1989. </year>
Reference-contexts: While the descriptions induced by Foil for the large training sets were totally incomprehensible 6 This Problem is known as the Small Disjuncts Problem <ref> [13] </ref> and has recently been addressed with an relational learning algorithm using probabilistic concept descrip tions [1]. Fig. 2. A Comparison of Foil and Fossil with different training set sizes illegal (A,B,C,D,E,F) :- C = E. illegal (A,B,C,D,E,F) :- D = F. illegal (A,B,C,D,E,F) :- adjacent (A,E), adjacent (B,F).
Reference: 14. <author> Nada Lavrac, Bojan Cestnik, and Saso Dzeroski. </author> <title> Search heuristics in empirical Inductive Logic Programming. In Logical Approaches to Machine Learning, </title> <booktitle> Workshop Notes of the 10th European Conference on AI, </booktitle> <address> Vienna, Austria, </address> <year> 1992. </year>
Reference-contexts: In the following description of its adaptation as a search heuristic for the Inductive Logic Programming algorithm Foil, we will follow the notational conventions used in <ref> [14] </ref>. Suppose Fossil has learned a partial clause c. Let the set of tuples T c of size n (c), containing n (c) positive and n (c) negative instances, be the current training set. We arbitrarily assign the numeric values +1 and 1 for the logical values true and false. <p> in general will have a different size) and the process continues as described in [20]. 2.2 Interesting Features of the Correlation Heuristic The information gain heuristic used in C4.5 [22] and Foil has been extensively compared to other search heuristics in decision tree generation [18, 6] and Inductive Logic Programming <ref> [14] </ref>. The general consensus seems to be that it is hard to improve on this heuristic in terms of predictive accuracy in learning from noise-free data.
Reference: 15. <author> Nada Lavrac and Saso Dzeroski. </author> <title> Inductive Logic Programming: Techniques and Applications. </title> <publisher> Ellis Horwood, </publisher> <year> 1993. </year>
Reference-contexts: Significant effort has been made into investigating the effect of noisy data on attribute-value learning algorithms (see e.g. [22, 3, 4, 17]). Not surprisingly, noise handling methods have also entered the rapidly growing field of Inductive Logic Programming <ref> [15] </ref>. Linus [16] relies directly on the noise handling abilities of decision tree learning algorithms, others, like mFoil [9] and REP [5], have adapted well-known methods from attribute-value learning for the ILP framework.
Reference: 16. <author> Nada Lavrac, Saso Dzeroski, and Marko Grobelnik. </author> <title> Learning nonrecursive definitions of relations with LINUS. </title> <booktitle> In Proceedings of the European Working Session on Learning, Porto, </booktitle> <address> Portugal, </address> <year> 1991. </year>
Reference-contexts: Significant effort has been made into investigating the effect of noisy data on attribute-value learning algorithms (see e.g. [22, 3, 4, 17]). Not surprisingly, noise handling methods have also entered the rapidly growing field of Inductive Logic Programming [15]. Linus <ref> [16] </ref> relies directly on the noise handling abilities of decision tree learning algorithms, others, like mFoil [9] and REP [5], have adapted well-known methods from attribute-value learning for the ILP framework. This paper presents Fossil, a Foil-like algorithm [20] that uses a search heuristic based on statistical correlation (Sect. 2).
Reference: 17. <author> John Mingers. </author> <title> An empirical comparison of pruning methods for decision tree induction. </title> <journal> Machine Learning, </journal> <volume> 4 </volume> <pages> 227-243, </pages> <year> 1989. </year>
Reference-contexts: 1 Introduction Being able to deal with noisy domains is a must for learning algorithms that are meant to learn concepts from real-world data. Significant effort has been made into investigating the effect of noisy data on attribute-value learning algorithms (see e.g. <ref> [22, 3, 4, 17] </ref>). Not surprisingly, noise handling methods have also entered the rapidly growing field of Inductive Logic Programming [15]. <p> Pruning and learning are interleaved in this algorithm and can influence each other. InDecision Tree Learning several methods for selecting the best tree from a series of trees pruned to a different degree have been developed <ref> [17] </ref>. We hope that we can adapt some of these methods for relational learning and in particular make them "incremental", i.e. interleave them with the learning process in a way that generates as few unnecessary and expensive theories as possible.
Reference: 18. <author> John Mingers. </author> <title> An empirical comparison of selection measures for decision-tree induction. </title> <journal> Machine Learning, </journal> <volume> 3 </volume> <pages> 319-342, </pages> <year> 1989. </year>
Reference-contexts: of tuples T c 0 (which in general will have a different size) and the process continues as described in [20]. 2.2 Interesting Features of the Correlation Heuristic The information gain heuristic used in C4.5 [22] and Foil has been extensively compared to other search heuristics in decision tree generation <ref> [18, 6] </ref> and Inductive Logic Programming [14]. The general consensus seems to be that it is hard to improve on this heuristic in terms of predictive accuracy in learning from noise-free data.
Reference: 19. <author> Stephen Muggleton, Michael Bain, Jean Hayes-Michie, and Donald Michie. </author> <title> An experimental comparison of human and machine learning formalisms. </title> <booktitle> In Proceedings of the 6th International Workshop on Machine Learning, </booktitle> <pages> pages 113-118, </pages> <year> 1989. </year>
Reference-contexts: (i.e. random classification) in Table 1, where Fossil did not learn a single clause in any of the 10 training sets. 4 Experimental Evaluation 4.1 Setup of the Experiments For the experiments in this paper we have used the domain of recognizing illegal chess positions in the KRK end game <ref> [19] </ref>. The goal is to learn the concept of an illegal white-to-move position with only white king, white rook and black king on the board. The goal predicate is illegal (A,B,C,D,E,F) where the parameters correspond to the row and file coordinates of the pieces in the above order. <p> In the first series we compared the behavior of the two systems with 10 training sets of 100 instances each at different noise levels, which has been the standard procedure for evaluating many ILP systems <ref> [20, 11, 10, 19] </ref>. In the second experiment we evaluated both programs at a constant noise level of 10%, but with an increasing number of training instances. According to the results of the previous experiments we set C = 0:3 and never changed this setting. Comparison at Different Noise Levels.
Reference: 20. <author> John Ross Quinlan. </author> <title> Learning logical definitions from relations. </title> <journal> Machine Learning, </journal> <volume> 5 </volume> <pages> 239-266, </pages> <year> 1990. </year>
Reference-contexts: Linus [16] relies directly on the noise handling abilities of decision tree learning algorithms, others, like mFoil [9] and REP [5], have adapted well-known methods from attribute-value learning for the ILP framework. This paper presents Fossil, a Foil-like algorithm <ref> [20] </ref> that uses a search heuristic based on statistical correlation (Sect. 2). One of the nice features of this heuristic is that it gives a reliable measure of the heuristic value of a literal on an absolute and uniform scale. <p> The set T c is then extended to a new set of tuples T c 0 (which in general will have a different size) and the process continues as described in <ref> [20] </ref>. 2.2 Interesting Features of the Correlation Heuristic The information gain heuristic used in C4.5 [22] and Foil has been extensively compared to other search heuristics in decision tree generation [18, 6] and Inductive Logic Programming [14]. <p> In the first series we compared the behavior of the two systems with 10 training sets of 100 instances each at different noise levels, which has been the standard procedure for evaluating many ILP systems <ref> [20, 11, 10, 19] </ref>. In the second experiment we evaluated both programs at a constant noise level of 10%, but with an increasing number of training instances. According to the results of the previous experiments we set C = 0:3 and never changed this setting. Comparison at Different Noise Levels. <p> What seems to be responsible for the drastic increase in the complexity of the learned clauses is that Foil's stopping criterion <ref> [20] </ref> is dependent on the size of the training set. In the KRK domain it performs very well on sample sizes of 100 training examples. The more this number increases, the more bits are allowed for the theory to explain the data.
Reference: 21. <author> John Ross Quinlan. </author> <title> Determinate literals in inductive logic programming. </title> <booktitle> In Proceedings of the 8th International Workshop on Machine Learning, </booktitle> <pages> pages 442-446, </pages> <year> 1991. </year>
Reference-contexts: However, some of them might be very useful, if they introduce new variables. The current version of Fossil ignores this problem by treating undefined cases as having correlation 0 and thus has severe problems in learning programs that need determinate literals <ref> [21] </ref>. Setting the heuristic value for the undefined cases to a value D &gt; 0 might be a simple solution for some of the pathological cases, because in that case Fossil would add literals with undefined correlation values whenever no other literal has a correlation &gt; D.
Reference: 22. <author> John Ross Quinlan. C4.5: </author> <title> Programs for Machine Learning. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1993. </year>
Reference-contexts: 1 Introduction Being able to deal with noisy domains is a must for learning algorithms that are meant to learn concepts from real-world data. Significant effort has been made into investigating the effect of noisy data on attribute-value learning algorithms (see e.g. <ref> [22, 3, 4, 17] </ref>). Not surprisingly, noise handling methods have also entered the rapidly growing field of Inductive Logic Programming [15]. <p> The set T c is then extended to a new set of tuples T c 0 (which in general will have a different size) and the process continues as described in [20]. 2.2 Interesting Features of the Correlation Heuristic The information gain heuristic used in C4.5 <ref> [22] </ref> and Foil has been extensively compared to other search heuristics in decision tree generation [18, 6] and Inductive Logic Programming [14]. The general consensus seems to be that it is hard to improve on this heuristic in terms of predictive accuracy in learning from noise-free data.
Reference: 23. <author> John Ross Quinlan and R. M. Cameron-Jones. </author> <title> FOIL: A midterm report. </title> <booktitle> In Proceedings of the European Conference on Machine Learning, </booktitle> <pages> pages 3-20, </pages> <address> Vienna, Austria, </address> <year> 1993. </year>
Reference-contexts: In this experiment we compared Foil4 to Fossil at different noise levels. In order to have a fair comparison to Fossil where backtracking is not implemented, we used two versions of Foil, regular Foil4 and a new version, Foil-NBT, where Foil4's extensive mechanisms of backing up and regrowing clauses <ref> [23] </ref> were not allowed. Surprisingly this version performed better than the original Foil4 in noisy data as can be seen from the results of Table 1.
Reference: 24. <author> Cullen Schaffer. </author> <title> Overfitting avoidance as bias. </title> <journal> Machine Learning, </journal> <volume> 10 </volume> <pages> 153-178, </pages> <year> 1993. </year>
Reference-contexts: In the light of <ref> [24] </ref> a method like this may be viewed as automatically shifting the Overfitting Avoidance Bias, in some respect similar to Clint, where a shift of Languate Bias is realized by learning in increasingly complex representation languages [8].
Reference: 25. <author> A. Srinivasan, S. H. Muggleton, and M. E. Bain. </author> <title> Distinguishing noise from exceptions in non-monotonic learning. </title> <booktitle> In Proceedings of the International Workshop on Inductive Logic Programming, </booktitle> <address> Tokyo, Japan, </address> <year> 1992. </year> <title> This article was processed using the L a T E X macro package with LLNCS style </title>
Reference-contexts: In particular we see some relationship to pruning methods used e.g. in [5] or <ref> [25] </ref>. The major difference, however, is that we get a series of different concept descriptions in a general to specific order (top-down) as opposed to pruning methods the generate a most specific theory first and then successively generalize it (bottom-up).
References-found: 25

