URL: http://www.cs.ucsd.edu/users/mihir/papers/eakd.ps.gz
Refering-URL: http://www.cs.ucsd.edu/users/mihir/papers/key-distribution.html
Root-URL: http://www.cs.ucsd.edu
Title: Entity Authentication and Key Distribution  
Author: Mihir Bellare Phillip Rogaway 
Keyword: Key words: authentication, computer security, cryptographic protocols, cryptography, distributed systems, key distribution.  
Address: San Diego, 9500 Gilman Drive, La Jolla, CA 92093.  CA 95616, USA.  
Affiliation: Department of Computer Science Engineering, Mail Code 0114, University of California at  Department of Computer Science, University of California at Davis, Davis,  
Note: Springer-Verlag. This is the full version.  
Email: E-mail: mihir@cs.ucsd.edu  E-mail: rogaway@cs.davis.edu  
Date: August 1993  
Abstract: An abridged version of this paper appears in Advances in Cryptology - Crypto '93 Proceedings, Abstract Entity authentication and key distribution are central cryptographic problems in distributed computing|but up until now, they have lacked even a meaningful definition. One consequence is that incorrect and inefficient protocols have proliferated. This paper provides the first treatment of these problems in the complexity-theoretic framework of modern cryptography. Addressed in detail are two problems of the symmetric, two-party setting: mutual authentication and authenticated key exchange. For each we present a definition, protocol, and proof that the protocol meets its goal, assuming the (minimal) assumption of pseudorandom function. When this assumption is appropriately instantiated, the protocols given are practical and efficient. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. Abadi and M. Tuttle, </author> <title> "A semantics for a logic of authentication," </title> <booktitle> Proceedings of the 10th ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pp. 201-216, </pages> <month> August </month> <year> 1991. </year>
Reference: [2] <author> M. Bellare, J. Kilian, and P. Rogaway, </author> <title> "The security of cipher block chaining," </title> <booktitle> Advances in Cryptology - Crypto 94 Proceedings. </booktitle>
Reference-contexts: However the definitions of authenticated key exchange and formal proof of correctness of AKEP1 that we will provide later will be independent of discussions of authenticated exchange of text. Security Of 2PP. Combining ideas from our proof of Theorem 4.4 with a lemma from <ref> [2] </ref>, we can show that a special case of the protocol 2PP of [6] meets our definition of a secure mutual authentication. <p> Specifically, assume that the "encryption" function E being used in 2PP is a PRF; assume nonces are instantiated with random values; and assume jIj = 2 and authenticating parties are guaranteed to have distinct identities. The CBC Lemma of <ref> [2] </ref> (stated here informally as Lemma D.1) says that the function being used in their protocol, namely the CBC of E, will also be a PRF. Given this, one can trace through our proof as given in Appendix A and check that it extends. Discussion.
Reference: [3] <author> M. Bellare and O. Goldreich, </author> <title> "On defining proofs of knowledge," </title> <booktitle> Advances in Cryptology | Proceedings of CRYPTO 92, </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1992. </year>
Reference-contexts: The notion of a zero-knowledge "proof of knowledge" <ref> [22, 13, 35, 9, 14, 3] </ref> has underlied identification protocols in the smart card model. But the definition of an interactive proof does not attempt to model attacks in which responses of entities are played off against one another, as is required for the distributed setting.
Reference: [4] <author> M. Bellare and P. Rogaway, </author> <title> "Random oracles are practical: a paradigm for designing efficient protocols," </title> <booktitle> Proceedings of 1st ACM Conference on Computer and Communications Security, </booktitle> <month> November </month> <year> 1993. </year>
Reference-contexts: The computational complexity is minimally more than that of MAP1, and the communication complexity is identical. A useful instantiation in this regard is to use f 0 = DES, exploiting the fact that DES is a permutation to get a uniformly distributed session key. 5 See <ref> [4] </ref> for another viewpoint. 20 Acknowledgments We thank Bob Blakley, Oded Goldreich, Amir Herzberg, Phil Janson, and the member of the CRYPTO 93 committee for all of their comments and suggestions.
Reference: [5] <editor> Th. Beth, M. Frisch and G. Simmons (Eds.), </editor> <title> Public-Key Cryptography: State of the Art and Future Directions, </title> <booktitle> E.I.S.S. Workshop, Oberwolfach, </booktitle> <address> Germany, </address> <month> July </month> <year> 1991, </year> <title> Final Report. </title> <booktitle> Lecture Notes in Computer Science, </booktitle> <volume> Vol. 578, </volume> <publisher> Springer-Verlag, </publisher> <year> 1991. </year>
Reference-contexts: The failure of the informal approach to designing correct authentication protocols has led to widespread recognition of the need for better foundations. By now the continued absence of a formal definition is a recognized deficiency. See, for example, [11] and <ref> [5, p. 59] </ref>. A different line of work aimed at improving the design and analysis of entity authentication protocols begins with the paper of Burrows, Abadi and Needham [8].
Reference: [6] <author> R. Bird, I. Gopal, A. Herzberg, P. Janson, S. Kutten, R. Molva and M. Yung, </author> <title> "Systematic design of two-party authentication protocols," </title> <booktitle> Advances in Cryptology | Proceedings of CRYPTO 91, </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1991. </year>
Reference-contexts: Most importantly, the adversary can start up entirely new "instances" of any of the parties, modeling the ability of communicating agents to simultaneously engage in many sessions at once; this gives us the ability to model the kinds of attacks that were suggested by <ref> [6] </ref>. Formally, each party will be modeled by an infinite collection of oracles which the adversary may run. These oracles only interact with the adversary, they never directly interact with one another. See Section 3. <p> Protocols. Having defined mutual authentication and authenticated key exchange, we provide protocols to achieve these ends. Four protocols are specifically discussed in this paper. Protocol MAP1, which is an extension of the protocol 2PP of <ref> [6] </ref>, is a mutual authentication protocol for an arbitrary set I of players. Protocol MAP2 is an extension of MAP1, allowing arbitrary text strings to be authenticated along with its flows. Protocol AKEP1 is a simple authenticated key exchange which uses MAP2 to do the key distribution. <p> An important step in the process was that of Bird, Gopal, Herzberg, Janson, Kutten, Molva and Yung <ref> [6] </ref>. They drew attention to this area by pointing to new classes of attacks, called "interleaving attacks," which they used to break existing protocols, and they suggested a protocol (2PP) defeated by none of the interleaving attacks they considered. <p> When our work was announced, the authors of <ref> [6] </ref> told us that they understood this limitation and had themselves been planning to work on general definitions; they also told us that the CBC assumption of their paper [6, Definition 2.1] was intended for proving security under a general definition. Mentioned in the introduction of [6] is an idea of <p> When our work was announced, the authors of [6] told us that they understood this limitation and had themselves been planning to work on general definitions; they also told us that the CBC assumption of their paper <ref> [6, Definition 2.1] </ref> was intended for proving security under a general definition. <p> announced, the authors of <ref> [6] </ref> told us that they understood this limitation and had themselves been planning to work on general definitions; they also told us that the CBC assumption of their paper [6, Definition 2.1] was intended for proving security under a general definition. Mentioned in the introduction of [6] is an idea of "matching histories." Diffie, van Oorschot and Wiener [11] expand on this to introduce a notion of "matching protocol runs." They refine this idea to a level of precision adequate to help them separate out what are and what are not "meaningful" attacks on the protocols they <p> Although [11] stops short of providing any formal definition or proof, the basic notion these authors describe is the same as ours and is the basis of a definition of entity authentication. Thus there is a clear refinement of definitional ideas first from <ref> [6] </ref> to [11], and then from [11] to our work. The failure of the informal approach to designing correct authentication protocols has led to widespread recognition of the need for better foundations. By now the continued absence of a formal definition is a recognized deficiency. <p> Security Of 2PP. Combining ideas from our proof of Theorem 4.4 with a lemma from [2], we can show that a special case of the protocol 2PP of <ref> [6] </ref> meets our definition of a secure mutual authentication. Specifically, assume that the "encryption" function E being used in 2PP is a PRF; assume nonces are instantiated with random values; and assume jIj = 2 and authenticating parties are guaranteed to have distinct identities. <p> We stress the importance, in our security considerations, of the CBC and Hash Lemmas of Appendix D; the lack of such lemmas has lead in the past to more complex assumptions about the security of CBC and other constructions (e.g., <ref> [6, Definition 2.1] </ref>). 6.2 Efficiency and Implementation Issues in our Protocols We suggest that the random challenges be 64 bits.
Reference: [7] <author> M. Blum and S. Micali, </author> <title> "How to generate cryptographically strong sequences of pseudorandom bits," </title> <journal> SIAM Journal on Computing 13(4), </journal> <month> 850-864 (November </month> <year> 1984). </year>
Reference-contexts: The early 1980s saw the proposal of a fundamental and radical idea to get beyond iterative, attack-responsive design of cryptographic protocols: Goldwasser and Micali [21], followed by Blum-Micali <ref> [7] </ref> and Yao [39], suggested that security could be proved under "standard" and well-believed complexity theoretic assumptions (e.g., the assumed intractability of factoring). <p> By 1985 provable security had been achieved for probabilistic encryption [21], pseudorandom number generation <ref> [7, 39] </ref> and digital signatures [23]. It was then the opinion of many researchers that provable security was in hand for all of the "basic" cryptographic primitives. Attention turned to other issues, such as reducing the complexity assumptions needed to achieve provable security or increasing the efficiency of the constructions.
Reference: [8] <author> M. Burrows, M. Abadi and R. Needham, </author> <title> "A logic for authentication," </title> <note> DEC Systems Research Center Technical Report 39, </note> <month> February </month> <year> 1990. </year> <booktitle> Earlier versions in Proceedings of the Second Conference on Theoretical Aspects of Reasoning about Knowledge, 1988, and Proceedings of the Twelfth ACM Symposium on Operating Systems Principles, </booktitle> <year> 1989. </year>
Reference-contexts: By now the continued absence of a formal definition is a recognized deficiency. See, for example, [11] and [5, p. 59]. A different line of work aimed at improving the design and analysis of entity authentication protocols begins with the paper of Burrows, Abadi and Needham <ref> [8] </ref>. This "logic-based" approach attempts to "reason" that an authentication protocol is correct as it evolves the set of "beliefs" of its participants.
Reference: [9] <author> G. Brassard, C. Cr epeau, S. Laplante and C. L eger, </author> <title> "Computationally convincing proofs of knowledge," </title> <booktitle> Proc. of the 8th STACS, </booktitle> <year> 1991. </year> <month> 21 </month>
Reference-contexts: The notion of a zero-knowledge "proof of knowledge" <ref> [22, 13, 35, 9, 14, 3] </ref> has underlied identification protocols in the smart card model. But the definition of an interactive proof does not attempt to model attacks in which responses of entities are played off against one another, as is required for the distributed setting.
Reference: [10] <author> Y. Desmedt, C. Goutier, S. Bengio, </author> <title> "Special uses and abuses of the Fiat-Shamir passport protocol," </title> <booktitle> Advances in Cryptology | Proceedings of CRYPTO 87, </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1988. </year>
Reference-contexts: We will see, however, that message authentication is a useful tool for entity authentication. Much discussed in the literature is the "mafia fraud" (or "grandmaster chess problem"), in which an adversary faithfully relays messages between communication partners; in some settings (cf. <ref> [10] </ref>) this constitutes a damaging attack. Protection against such attacks is addressed in [12].
Reference: [11] <author> W. Diffie, P. van Oorschot and M. Wiener, </author> <title> "Authentication and authenticated key exchanges," Designs, Codes and Cryptography, </title> <type> 2, </type> <month> 107-125 </month> <year> (1992). </year>
Reference-contexts: Mentioned in the introduction of [6] is an idea of "matching histories." Diffie, van Oorschot and Wiener <ref> [11] </ref> expand on this to introduce a notion of "matching protocol runs." They refine this idea to a level of precision adequate to help them separate out what are and what are not "meaningful" attacks on the protocols they consider. Although [11] stops short of providing any formal definition or proof, <p> idea of "matching histories." Diffie, van Oorschot and Wiener <ref> [11] </ref> expand on this to introduce a notion of "matching protocol runs." They refine this idea to a level of precision adequate to help them separate out what are and what are not "meaningful" attacks on the protocols they consider. Although [11] stops short of providing any formal definition or proof, the basic notion these authors describe is the same as ours and is the basis of a definition of entity authentication. Thus there is a clear refinement of definitional ideas first from [6] to [11], and then from [11] to our <p> Although <ref> [11] </ref> stops short of providing any formal definition or proof, the basic notion these authors describe is the same as ours and is the basis of a definition of entity authentication. Thus there is a clear refinement of definitional ideas first from [6] to [11], and then from [11] to our work. The failure of the informal approach to designing correct authentication protocols has led to widespread recognition of the need for better foundations. By now the continued absence of a formal definition is a recognized deficiency. See, for example, [11] and [5, p. 59]. <p> Although <ref> [11] </ref> stops short of providing any formal definition or proof, the basic notion these authors describe is the same as ours and is the basis of a definition of entity authentication. Thus there is a clear refinement of definitional ideas first from [6] to [11], and then from [11] to our work. The failure of the informal approach to designing correct authentication protocols has led to widespread recognition of the need for better foundations. By now the continued absence of a formal definition is a recognized deficiency. See, for example, [11] and [5, p. 59]. <p> first from [6] to <ref> [11] </ref>, and then from [11] to our work. The failure of the informal approach to designing correct authentication protocols has led to widespread recognition of the need for better foundations. By now the continued absence of a formal definition is a recognized deficiency. See, for example, [11] and [5, p. 59]. A different line of work aimed at improving the design and analysis of entity authentication protocols begins with the paper of Burrows, Abadi and Needham [8]. <p> Given this, one can trace through our proof as given in Appendix A and check that it extends. Discussion. Our definition is very strong|perhaps the strongest possible natural definition. In asking that flows match exactly it may be criticized as too strong; as pointed out by <ref> [11] </ref>, certain parts of protocol flows might be "irrelevant" for the authentication, and perhaps one ought to allow them to be ignored in matching. Such extensions seem valuable, especially for the asymmetric case.
Reference: [12] <author> D. Dolev, C. Dwork and M. Naor, </author> <title> "Non-malleable cryptography," </title> <booktitle> Proceedings of the Twenty Third Annual Symposium on the Theory of Computing, ACM, </booktitle> <year> 1991. </year>
Reference-contexts: Much discussed in the literature is the "mafia fraud" (or "grandmaster chess problem"), in which an adversary faithfully relays messages between communication partners; in some settings (cf. [10]) this constitutes a damaging attack. Protection against such attacks is addressed in <ref> [12] </ref>.
Reference: [13] <author> U. Feige, A. Fiat and A. Shamir, </author> <title> "Zero knowledge proofs of identity," </title> <journal> Journal of Cryptology, </journal> <volume> Vol. 1, </volume> <pages> pp. </pages> <month> 77-94 </month> <year> (1987). </year>
Reference-contexts: The notion of a zero-knowledge "proof of knowledge" <ref> [22, 13, 35, 9, 14, 3] </ref> has underlied identification protocols in the smart card model. But the definition of an interactive proof does not attempt to model attacks in which responses of entities are played off against one another, as is required for the distributed setting. <p> More closely related to the approach we adopt is the idea of a non-transferable proof, a notion for (asymmetric, unilateral) authentication due to Feige, Fiat and Shamir <ref> [13] </ref>. Here an (honest) claimant P interacts with a (cheating) verifier ~ V , and then a ( ~ V -conspiring cheating) prover ~ P tries to convince an (honest) verifier V that she ( ~ P ) is really P .
Reference: [14] <author> U. Feige and A. Shamir, </author> <title> "Witness Indistinguishable and Witness Hiding Protocols," </title> <booktitle> Proceedings of the Twenty Second Annual Symposium on the Theory of Computing, ACM, </booktitle> <year> 1990. </year>
Reference-contexts: The notion of a zero-knowledge "proof of knowledge" <ref> [22, 13, 35, 9, 14, 3] </ref> has underlied identification protocols in the smart card model. But the definition of an interactive proof does not attempt to model attacks in which responses of entities are played off against one another, as is required for the distributed setting.
Reference: [15] <author> A. Fiat and A. Shamir, </author> <title> "How to prove yourself: practical solutions to identification and signature problems," </title> <booktitle> Advances in Cryptology - Crypto 86 Proceedings, Lecture Notes in Computer Science Vol. </booktitle> <volume> 263, </volume> <publisher> Springer-Verlag, </publisher> <editor> A. Odlyzko, ed., </editor> <year> 1986. </year>
Reference: [16] <author> O. Goldreich, </author> <title> "Foundations of cryptography," class notes, </title> <institution> Technion University, Computer Science Department, </institution> <month> Spring </month> <year> 1989. </year>
Reference-contexts: When this inquiry is made, the key is no longer fresh, and any partner's key is declared unfresh, too. Fresh keys must remain "protected." We formalize the adversary's inability to gain any helpful information about them along the lines of formalizations of security for probabilistic encryption <ref> [21, 16, 17] </ref>. Protocols. Having defined mutual authentication and authenticated key exchange, we provide protocols to achieve these ends. Four protocols are specifically discussed in this paper. <p> Protecting Fresh Session Keys. We want that the adversary should be unable to understand anything interesting about a fresh session key. This can be formalized along the lines of security of probabilistic encryption; the particular formalization we will adapt is that of (polynomial) indistinguishability of encryptions <ref> [21, 16, 17] </ref>. We demand that at the end of a secure AKE the adversary should be unable to distinguish a fresh session key ff from a random element of S k . We proceed as follows. <p> The formalization of the adversary's being unable to learn anything about a fresh session key could also have been made by adapting the notion of "semantic security" of encryptions <ref> [21, 16, 17] </ref> to our setting. Roughly, we would say the following. Let E be any polynomial time adversary and let Q k ~ be any collection of functions indexed by the security parameter k and possible views ~ of the adversary.
Reference: [17] <author> O. Goldreich, </author> <title> "A uniform complexity treatment of encryption and zero-knowledge," </title> <journal> Journal of Cryptology, </journal> <volume> Vol. 6, </volume> <pages> pp. </pages> <month> 21-53 </month> <year> (1993). </year>
Reference-contexts: When this inquiry is made, the key is no longer fresh, and any partner's key is declared unfresh, too. Fresh keys must remain "protected." We formalize the adversary's inability to gain any helpful information about them along the lines of formalizations of security for probabilistic encryption <ref> [21, 16, 17] </ref>. Protocols. Having defined mutual authentication and authenticated key exchange, we provide protocols to achieve these ends. Four protocols are specifically discussed in this paper. <p> Protecting Fresh Session Keys. We want that the adversary should be unable to understand anything interesting about a fresh session key. This can be formalized along the lines of security of probabilistic encryption; the particular formalization we will adapt is that of (polynomial) indistinguishability of encryptions <ref> [21, 16, 17] </ref>. We demand that at the end of a secure AKE the adversary should be unable to distinguish a fresh session key ff from a random element of S k . We proceed as follows. <p> The formalization of the adversary's being unable to learn anything about a fresh session key could also have been made by adapting the notion of "semantic security" of encryptions <ref> [21, 16, 17] </ref> to our setting. Roughly, we would say the following. Let E be any polynomial time adversary and let Q k ~ be any collection of functions indexed by the security parameter k and possible views ~ of the adversary.
Reference: [18] <author> O. Goldreich, S. Goldwasser and S. Micali, </author> <title> "How to construct random functions," </title> <journal> Journal of the ACM, </journal> <volume> Vol. 33, No. 4, </volume> <pages> 210-217, </pages> <year> (1986). </year>
Reference-contexts: This efficiency was designed into our protocols in part through the choice of the underlying primitive| namely, a pseudorandom function. In theory, pseudorandom functions and other important cryptographic primitives (one-way functions, pseudorandom generators, digital signatures) are equivalent <ref> [26, 24, 18, 33] </ref>, since the 5 existence of any one of these implies the existence of the others. 2 In practice, pseudorandom functions (with the right domain and range) are a highly desirable starting point for efficient protocols in the symmetric setting. <p> Authenticating Messages. Message authentication via pseudo-random functions <ref> [18, 19] </ref> is a tool in our entity authentication protocols. Let f be a pseudorandom function family [18]. Denote by f a : f0; 1g L (k) ! f0; 1g l (k) the function specified by key a. <p> Authenticating Messages. Message authentication via pseudo-random functions [18, 19] is a tool in our entity authentication protocols. Let f be a pseudorandom function family <ref> [18] </ref>. Denote by f a : f0; 1g L (k) ! f0; 1g l (k) the function specified by key a. <p> For any string x 2 f0; 1g L (k) define [x] a = (x; f a (x)); this will serve as an authentication of message x <ref> [18, 19] </ref>. For any i 2 I , [i : x] a will serve as i's authentication of message x. A Protocol For Mutual Authentication. Our first protocol (called "MAP1," for "mutual authentication protocol one") is represented by Figure 2. <p> A probabilistic encryption of string ff 2 f0; 1g (k) is defined by fffg a 2 def a 2 (r)ff), with r selected at random <ref> [18] </ref>. Party B chooses the session key ff from S k and sets Text 2 to be fffg a 2 . The strings Text 1 and Text 3 of MAP2 are set to . This protocol, which we call AKEP1, is shown in Figure 4.
Reference: [19] <author> O. Goldreich, S. Goldwasser and S. Micali, </author> <title> "On the cryptographic applications of random functions," </title> <booktitle> Advances in Cryptology | Proceedings of CRYPTO 84, </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1984. </year>
Reference-contexts: Authenticating Messages. Message authentication via pseudo-random functions <ref> [18, 19] </ref> is a tool in our entity authentication protocols. Let f be a pseudorandom function family [18]. Denote by f a : f0; 1g L (k) ! f0; 1g l (k) the function specified by key a. <p> For any string x 2 f0; 1g L (k) define [x] a = (x; f a (x)); this will serve as an authentication of message x <ref> [18, 19] </ref>. For any i 2 I , [i : x] a will serve as i's authentication of message x. A Protocol For Mutual Authentication. Our first protocol (called "MAP1," for "mutual authentication protocol one") is represented by Figure 2.
Reference: [20] <author> O. Goldreich, S. Micali and A. Wigderson, </author> <title> "How to play any mental game," </title> <booktitle> Proceedings of the Nineteenth Annual Symposium on the Theory of Computing, ACM, </booktitle> <year> 1987, </year> <pages> 218-229. </pages>
Reference-contexts: These oracles only interact with the adversary, they never directly interact with one another. See Section 3. Note how this differs from the models underlying notions such as interactive proofs [22] or secure function evaluation <ref> [38, 20] </ref>. In the former case the communication is trusted and it is one of the parties who may be adversarial; in the later case, individual parties may be good or bad, but their communication proceeds in a simple and orderly manner.
Reference: [21] <author> S. Goldwasser and S. Micali, </author> <title> "Probabilistic encryption," </title> <journal> Journal of Computer and System Sciences Vol. </journal> <volume> 28, </volume> <month> 270-299 (April </month> <year> 1984). </year>
Reference-contexts: The early 1980s saw the proposal of a fundamental and radical idea to get beyond iterative, attack-responsive design of cryptographic protocols: Goldwasser and Micali <ref> [21] </ref>, followed by Blum-Micali [7] and Yao [39], suggested that security could be proved under "standard" and well-believed complexity theoretic assumptions (e.g., the assumed intractability of factoring). <p> By 1985 provable security had been achieved for probabilistic encryption <ref> [21] </ref>, pseudorandom number generation [7, 39] and digital signatures [23]. It was then the opinion of many researchers that provable security was in hand for all of the "basic" cryptographic primitives. <p> In particular, we offer protocols whose security can be guaranteed from weak complexity-theoretic assumptions, bringing assurance to an area which has been fraught with uncertainty. The definitional ideas needed to treat these problems are novel. Notions like indistinguishability <ref> [21, 22] </ref> and simulatability [22] which were so successful in formalizing other cryptographic primitives are not enough for this setting. In fact, we have to begin by re-defining the very model which underlies the communication. Model. <p> When this inquiry is made, the key is no longer fresh, and any partner's key is declared unfresh, too. Fresh keys must remain "protected." We formalize the adversary's inability to gain any helpful information about them along the lines of formalizations of security for probabilistic encryption <ref> [21, 16, 17] </ref>. Protocols. Having defined mutual authentication and authenticated key exchange, we provide protocols to achieve these ends. Four protocols are specifically discussed in this paper. <p> Protecting Fresh Session Keys. We want that the adversary should be unable to understand anything interesting about a fresh session key. This can be formalized along the lines of security of probabilistic encryption; the particular formalization we will adapt is that of (polynomial) indistinguishability of encryptions <ref> [21, 16, 17] </ref>. We demand that at the end of a secure AKE the adversary should be unable to distinguish a fresh session key ff from a random element of S k . We proceed as follows. <p> The formalization of the adversary's being unable to learn anything about a fresh session key could also have been made by adapting the notion of "semantic security" of encryptions <ref> [21, 16, 17] </ref> to our setting. Roughly, we would say the following. Let E be any polynomial time adversary and let Q k ~ be any collection of functions indexed by the security parameter k and possible views ~ of the adversary.
Reference: [22] <author> S. Goldwasser, S. Micali and C. Rackoff, </author> <title> "The knowledge complexity of interactive proof systems," </title> <journal> SIAM J. of Comp., </journal> <volume> Vol. 18, No. 1, </volume> <pages> pp. 186-208, </pages> <month> February </month> <year> 1989. </year>
Reference-contexts: In particular, the primitives and tools formalized and understood in the theoretical community today (e.g. encryption, signatures, zero-knowledge <ref> [22] </ref>, proofs of knowledge, identification) don't seem adequate to treat these problems. 1.3 Provable security for entity authentication We provide entity authentication and key distribution with provable security, raising these goals to the same level as primitives such as encryption, pseudorandom generators, or digital signatures. <p> In particular, we offer protocols whose security can be guaranteed from weak complexity-theoretic assumptions, bringing assurance to an area which has been fraught with uncertainty. The definitional ideas needed to treat these problems are novel. Notions like indistinguishability <ref> [21, 22] </ref> and simulatability [22] which were so successful in formalizing other cryptographic primitives are not enough for this setting. In fact, we have to begin by re-defining the very model which underlies the communication. Model. <p> In particular, we offer protocols whose security can be guaranteed from weak complexity-theoretic assumptions, bringing assurance to an area which has been fraught with uncertainty. The definitional ideas needed to treat these problems are novel. Notions like indistinguishability [21, 22] and simulatability <ref> [22] </ref> which were so successful in formalizing other cryptographic primitives are not enough for this setting. In fact, we have to begin by re-defining the very model which underlies the communication. Model. <p> Formally, each party will be modeled by an infinite collection of oracles which the adversary may run. These oracles only interact with the adversary, they never directly interact with one another. See Section 3. Note how this differs from the models underlying notions such as interactive proofs <ref> [22] </ref> or secure function evaluation [38, 20]. In the former case the communication is trusted and it is one of the parties who may be adversarial; in the later case, individual parties may be good or bad, but their communication proceeds in a simple and orderly manner. <p> The notion of a zero-knowledge "proof of knowledge" <ref> [22, 13, 35, 9, 14, 3] </ref> has underlied identification protocols in the smart card model. But the definition of an interactive proof does not attempt to model attacks in which responses of entities are played off against one another, as is required for the distributed setting.
Reference: [23] <author> S. Goldwasser, S. Micali and R. Rivest, </author> <title> "A digital signature scheme secure against adaptive chosen-message attacks," </title> <journal> SIAM Journal of Computing, </journal> <volume> Vol. 17, No. 2, </volume> <pages> 281-308, </pages> <month> April </month> <year> 1988. </year>
Reference-contexts: By 1985 provable security had been achieved for probabilistic encryption [21], pseudorandom number generation [7, 39] and digital signatures <ref> [23] </ref>. It was then the opinion of many researchers that provable security was in hand for all of the "basic" cryptographic primitives. Attention turned to other issues, such as reducing the complexity assumptions needed to achieve provable security or increasing the efficiency of the constructions. <p> This appealing definition models a world of smart-card claimants and untrusted verifiers|but, again, not a distributed system of always-running processes. Entity authentication is not to be confused with message authentication or signing <ref> [23] </ref>; here the goal is to authenticate a document rather than an entity, and the model is different. We will see, however, that message authentication is a useful tool for entity authentication.
Reference: [24] <author> J. H -astad, </author> <title> "Pseudo-random generators under uniform assumptions," </title> <booktitle> Proceedings of the Twenty Second Annual Symposium on the Theory of Computing, ACM, </booktitle> <year> 1990. </year> <month> 22 </month>
Reference-contexts: This efficiency was designed into our protocols in part through the choice of the underlying primitive| namely, a pseudorandom function. In theory, pseudorandom functions and other important cryptographic primitives (one-way functions, pseudorandom generators, digital signatures) are equivalent <ref> [26, 24, 18, 33] </ref>, since the 5 existence of any one of these implies the existence of the others. 2 In practice, pseudorandom functions (with the right domain and range) are a highly desirable starting point for efficient protocols in the symmetric setting.
Reference: [25] <author> R. Impagliazzo and M. Luby, </author> <title> "One-way functions are essential for complexity based cryp-tography," </title> <booktitle> Proceedings of the Thirtieth Annual Symposium on the Foundations of Computer Science, IEEE, </booktitle> <year> 1989. </year>
Reference-contexts: Thus while a negative result implies that something is wrong, a positive 2 We remark that the existence of a secure mutual authentication protocol implies the existence of a one-way function, as can be shown using techniques of <ref> [25] </ref>; thus mutual authentication also exists if and only if one-way functions do. 6 result gives no assurance that everything is all right. The notion of a zero-knowledge "proof of knowledge" [22, 13, 35, 9, 14, 3] has underlied identification protocols in the smart card model.
Reference: [26] <author> R. Impagliazzo, L. Levin and M. Luby, </author> <title> "Pseudo-random generation from one-way functions," </title> <booktitle> Proceedings of the Twenty First Annual Symposium on the Theory of Computing, ACM, </booktitle> <year> 1989. </year>
Reference-contexts: This efficiency was designed into our protocols in part through the choice of the underlying primitive| namely, a pseudorandom function. In theory, pseudorandom functions and other important cryptographic primitives (one-way functions, pseudorandom generators, digital signatures) are equivalent <ref> [26, 24, 18, 33] </ref>, since the 5 existence of any one of these implies the existence of the others. 2 In practice, pseudorandom functions (with the right domain and range) are a highly desirable starting point for efficient protocols in the symmetric setting.
Reference: [27] <author> ISO/IEC 9798-2, </author> <title> "Information technology Security techniques Entity authentication - Part 2: Entity authentication using symmetric techniques." </title> <type> Draft 12, </type> <month> September </month> <year> 1992. </year>
Reference: [28] <author> M. Luby and C. Rackoff, </author> <title> "How to construct pseudorandom permutations from pseudorandom functions," </title> <journal> SIAM J. Computing, </journal> <volume> Vol. 17, No. 2, </volume> <month> April </month> <year> 1988. </year>
Reference-contexts: Again the parties share a 2k bit LL-key a 1 ; a 2 , with a 1 being used as the key in MAP1 (so L (k) = 4k). Let f 0 be a pseudorandom permutation family <ref> [28] </ref>; f 0 a 2 specifies a permutation on f0; 1g k . Define the protocol AKEP2 by having its flows be identical to MAP1, with a 1 being used for message authentication. Each accepting party outputs session key ff = g (f 0 a 2 (R B )). <p> Let's begin by discussing the primitives. Primitives. The algorithm of the DES specifies for each 64 bit key a a permutation DES a from f0; 1g 64 to f0; 1g 64 . The viewpoint adopted here |suggested by Luby and Rackoff <ref> [28, 29] </ref>| is to regard DES as a pseudo-random permutation, with respect to practical computation. The MD5 function [32] maps an arbitrary string x into a 128-bit string MD5 (x). It is intended that this function be a collision-free hash function, with respect to practical computation.
Reference: [29] <author> M. Luby and C. Rackoff, </author> <title> "A study of password security," </title> <type> manuscript. </type>
Reference-contexts: Let's begin by discussing the primitives. Primitives. The algorithm of the DES specifies for each 64 bit key a a permutation DES a from f0; 1g 64 to f0; 1g 64 . The viewpoint adopted here |suggested by Luby and Rackoff <ref> [28, 29] </ref>| is to regard DES as a pseudo-random permutation, with respect to practical computation. The MD5 function [32] maps an arbitrary string x into a 128-bit string MD5 (x). It is intended that this function be a collision-free hash function, with respect to practical computation.
Reference: [30] <author> R. Molva, G. Tsudik, E. Van Herreweghen and S. Zatti, </author> <title> "Kryptoknight authentication and key distribution system, </title> <address> ESORICS 92, Toulouse, France, </address> <month> November </month> <year> 1992. </year>
Reference: [31] <author> R. Needham and M. Schroeder, </author> <title> "Using encryption for authentication in large networks of computers," </title> <journal> Communications of the ACM, </journal> <volume> Vol. 21, No. 12, </volume> <pages> 993-999, </pages> <month> December </month> <year> 1978. </year>
Reference: [32] <author> R. Rivest, </author> <title> "The MD5 message-digest algorithm," IETF Network Working Group, </title> <type> RFC 1321, </type> <month> April </month> <year> 1992. </year>
Reference-contexts: The viewpoint adopted here |suggested by Luby and Rackoff [28, 29]| is to regard DES as a pseudo-random permutation, with respect to practical computation. The MD5 function <ref> [32] </ref> maps an arbitrary string x into a 128-bit string MD5 (x). It is intended that this function be a collision-free hash function, with respect to practical computation. The Problem And Our Design Philosophy.
Reference: [33] <author> J. Rompel, </author> <title> "One-way functions are necessary and sufficient for secure signatures," </title> <booktitle> Proceedings of the Twenty Second Annual Symposium on the Theory of Computing, ACM, </booktitle> <year> 1990. </year>
Reference-contexts: This efficiency was designed into our protocols in part through the choice of the underlying primitive| namely, a pseudorandom function. In theory, pseudorandom functions and other important cryptographic primitives (one-way functions, pseudorandom generators, digital signatures) are equivalent <ref> [26, 24, 18, 33] </ref>, since the 5 existence of any one of these implies the existence of the others. 2 In practice, pseudorandom functions (with the right domain and range) are a highly desirable starting point for efficient protocols in the symmetric setting.
Reference: [34] <author> K. Sakurai and T. Itoh, </author> <title> "On the discrepancy between serial and parallel of zero-knowledge protocols," </title> <booktitle> Advances in Cryptology - Crypto 92 Proceedings, Lecture Notes in Computer Science Vol. </booktitle> <volume> 740, </volume> <publisher> Springer-Verlag, </publisher> <editor> E. Brickell, ed., </editor> <year> 1993. </year>
Reference: [35] <author> M. Tompa and H. Woll, </author> <title> "Random self-reducibility and zero-knowledge interactive proofs of possession of information," </title> <institution> University of California (San Diego) Computer Science and Engineering Dept. </institution> <note> Technical Report Number CS92-244 (June 1992). (Preliminary version in Proceedings of the Twenty Eighth Annual Symposium on the Foundations of Computer Science, IEEE, </note> <year> 1987.) </year>
Reference-contexts: The notion of a zero-knowledge "proof of knowledge" <ref> [22, 13, 35, 9, 14, 3] </ref> has underlied identification protocols in the smart card model. But the definition of an interactive proof does not attempt to model attacks in which responses of entities are played off against one another, as is required for the distributed setting.
Reference: [36] <author> G. Tsudik, </author> <title> "Message authentication with one-way hash functions," </title> <booktitle> Proceedings of Info-com 92. </booktitle>
Reference-contexts: This construction is justified by Corollary D.3. In software this is significantly more efficient than the CBC construction, requiring one hash and two DES operations. (3) The Pure Hash PRF. Let f a (x) be the first l=2 bits of H (x : a). This construction was suggested in <ref> [36] </ref> as a message authentication code; we suggest the stronger assumption that it is a PRF.
Reference: [37] <author> T. Woo and S. Lam, </author> <title> "A semantic model for authentication protocols," </title> <booktitle> Proceedings 1993 IEEE Symposium on Research in Security and Privacy, </booktitle> <pages> pp. 178-195, </pages> <month> May </month> <year> 1993. </year>
Reference: [38] <author> A. Yao, </author> <title> "Protocols for secure computation," </title> <booktitle> Proceedings of the Twenty Third Annual Symposium on the Foundations of Computer Science, IEEE, </booktitle> <year> 1982. </year>
Reference-contexts: These oracles only interact with the adversary, they never directly interact with one another. See Section 3. Note how this differs from the models underlying notions such as interactive proofs [22] or secure function evaluation <ref> [38, 20] </ref>. In the former case the communication is trusted and it is one of the parties who may be adversarial; in the later case, individual parties may be good or bad, but their communication proceeds in a simple and orderly manner.
Reference: [39] <author> Yao, A. C., </author> <title> "Theory and applications of trapdoor functions," </title> <booktitle> Proceedings of the Twenty Third Annual Symposium on the Foundations of Computer Science, IEEE, </booktitle> <year> 1982. </year> <month> 23 </month>
Reference-contexts: The early 1980s saw the proposal of a fundamental and radical idea to get beyond iterative, attack-responsive design of cryptographic protocols: Goldwasser and Micali [21], followed by Blum-Micali [7] and Yao <ref> [39] </ref>, suggested that security could be proved under "standard" and well-believed complexity theoretic assumptions (e.g., the assumed intractability of factoring). <p> By 1985 provable security had been achieved for probabilistic encryption [21], pseudorandom number generation <ref> [7, 39] </ref> and digital signatures [23]. It was then the opinion of many researchers that provable security was in hand for all of the "basic" cryptographic primitives. Attention turned to other issues, such as reducing the complexity assumptions needed to achieve provable security or increasing the efficiency of the constructions.
References-found: 39

