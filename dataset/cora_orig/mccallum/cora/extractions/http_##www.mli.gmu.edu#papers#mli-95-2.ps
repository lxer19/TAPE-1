URL: http://www.mli.gmu.edu/papers/mli-95-2.ps
Refering-URL: http://www.mli.gmu.edu/kpubs.html
Root-URL: 
Title: A Partial Memory Incremental Learning Methodology And Its Application To Computer Intrusion Detection  
Author: Marcus A. Maloof and Ryszard S. Michalski 
Date: March 1995  
Pubnum: MLI 95-2  
Abstract-found: 0
Intro-found: 1
Reference: <author> Anderson, D.; Frivold, T.; Tamaru, A.; and Valdes, A. </author> <title> (1994a) Next Generation Intrusion Detection Expert System (NIDES): software design, product specification, and version description document. SRI International Software Design Document A002 Version Description Document A005. </title> <booktitle> SRI International, </booktitle> <address> Menlo Park, CA. </address>
Reference-contexts: The IDES system later evolved into the Next Generation Intrusion Detection Expert System (NIDES), both of which were developed at SRI International <ref> (Anderson et al. 1994a) </ref>. Figure 2.3 shows the NIDES architecture.
Reference: <author> Anderson, D.; Frivold, T.; and Valdes, A. </author> <title> (1994b) Next Generation Intrusion Detection Expert System (NIDES): </title> <type> final technical report. SRI International Final Technical Report A008. </type> <institution> SRI International, </institution> <address> Menlo Park, CA. </address>
Reference: <author> Bala, J. W.; Michalski, R. S.; and Pachowicz, P. W. </author> <title> (1994) Progress on vision through learning at George Mason University. </title> <booktitle> Proceedings of the 1994 Image Understanding Workshop, </booktitle> <address> 191207. </address>
Reference-contexts: And although the neural network had faster recognition times, AQ rules can serve as the basis for a neural network architecture that will achieve equally fast recognition times <ref> (Bala et al. 1994) </ref>. There are other issues to be considered, however, especially for systems that must adapt to a changing environment. The first issue relates to the types of information that can be learned, which include continuous, linear, symbolic, and structured data.
Reference: <author> Ballard, D., and Brown, C. </author> <title> (1993) Principles of animate vision. </title> <editor> In Aloimonos, Y., ed., </editor> <title> Active Perception. </title> <type> 245282. </type> <address> Hillsdale, NJ: </address> <publisher> Lawrence Erlbaum Associates. </publisher>
Reference-contexts: If one or more of these factors does change, the entire development process is repeated to produce a system capable of coping with the new scenario. New applications, such as intelligent agents (e.g., Maes 1994) and active vision <ref> (e.g., Ballard and Brown 1993) </ref>, require autonomous or semi-autonomous functioning and adaptation to changes in the domain, the environment, or the user. Such requirements suggest that incremental learning, as opposed to batch learning, is needed.
Reference: <author> Bhandaru, M. K., and Murty, M. N. </author> <title> (1991) Incremental learning from examples using HC-expressions. </title> <journal> Pattern Recognition 24.4:273282. </journal>
Reference: <author> Bloedorn, E.; Wnek, J.; Michalski, R. S.; and Kaufman, K. </author> <title> (1993) AQ17 A multistrategy learning system: the method and users guide. Reports of the Machine Learning and Inference Laboratory, MLI 9312. Center for Machine Learning and Inference, </title> <institution> George Mason University, Fairfax, VA. </institution>
Reference-contexts: For the feed-forward neural network, the training data was scaled using a uniform interval method which involved mapping the real range of each attribute into the range [0, 1]. AQ15c requires discrete-valued attributes, so the SCALE implementation <ref> (Bloedorn et al. 1993) </ref> of the ChiMerge algorithm (Kerber 1992) was used. The ChiMerge algorithm merges real-valued attributes into discrete intervals using the chisquare statistic to correlate intervals to classes.
Reference: <author> Cohen, L. J. </author> <title> (1977) The probable and provable. </title> <publisher> Oxford: Oxford University Press. DARPA Neural Network Study (1988) Fairfax, </publisher> <address> VA: </address> <publisher> AFCEA International Press. </publisher>
Reference-contexts: The incremental learning ideas expressed in this report will serve as the foundation for an implementation, which will allow better opportunities for experimentation. Directions with regards to an implementation include optimization of incrementally learned rules and investigating Baconian support mechanisms <ref> (Cohen 1977) </ref> for rule conflict resolution. Baconian support mechanisms should be investigated because during inference, ties often result between two or more classes when the degrees of match for the decision classes are equal. In this situation, AQ employs an ad hoc mechanism to select a decision class.
Reference: <author> Davis, J. H. </author> <year> (1981) </year> <month> CONVART: </month> <title> a program for constructive induction on time dependent data. </title> <type> Masters Thesis. </type> <institution> Department of Computer Science, University of Illinois at Urbana-Champaign, Urbana, IL. </institution>
Reference: <author> Debar, H.; Becker, M.; and Siboni, D. </author> <title> (1992) A neural network component for an intrusion detection system. </title> <booktitle> Proceedings of the 1992 IEEE Computer Society Symposium on Research in Security and Privacy, </booktitle> <pages> 240250. </pages>
Reference: <author> Denning, D. E. </author> <title> (1987) An intrusion-detection model. </title> <journal> IEEE Transactions on Software Engineering. </journal> <note> SE-13.2 (February) 222232. </note>
Reference-contexts: Although incremental learning is needed in application areas such as intelligent agents and active vision, the application considered here is a dynamic knowledge-based system for computer intrusion detection <ref> (Denning 1987) </ref>. To apply the proposed partial memory incremental learning methodology to the problem of detecting intruders in a computer system, training examples were extracted from a Unix audit file and represented using VL 1 .
Reference: <author> Fahlman, S. E. </author> <title> (1988) An empirical study of learning speed in backpropagation networks. </title> <type> Technical Report CMU-CS-88-182. </type> <institution> Department of Computer Science, Carnegie-Mellon University, Pittsburg, PA. </institution> <note> 24 Hong, </note> <author> J.; Mozetic, I.; and Michalski, R. S. </author> <title> (1986) AQ15: incremental learning of attribute-based descriptions from examples, the method and users guide. </title> <institution> UIUCDCS-F-86-949. Department of Computer Science, University of Illinois at Urbana-Champaign, Urbana, IL. </institution>
Reference: <author> Javitz, H. S., and Valdes, A. </author> <title> (1994) The NIDES Statistical Component: description and justification. </title> <booktitle> SRI International Annual Report A010. SRI International, </booktitle> <address> Menlo Park, CA. </address>
Reference-contexts: The IDES system later evolved into the Next Generation Intrusion Detection Expert System (NIDES), both of which were developed at SRI International (Anderson et al. 1994a). Figure 2.3 shows the NIDES architecture. Statistical Component Rulebased Component Audit-Data Generation User Interface Resolver Audit-Data Collection Archiver The NIDES statistical component <ref> (Javitz and Valdes 1994) </ref> detects anomalous behaviors in users, groups of users, and in the global computing system by developing profiles, which are histories of long-term computing activity. <p> Because of AQs flexible matching algorithm, the intrusion detection system not only produces a decision or classification (i.e., a users identity), but it also provides a measure of certainty using the degree of match. The degree of match functions similarly to the abnormality measure in NIDES <ref> (Javitz and Valdes 1994) </ref>. For example, assume we have 13 two users, daffy and coyote, and that daffys session has been logged and sent to the system for interpretation.
Reference: <author> Kerber, R. </author> <year> (1992) </year> <month> ChiMerge: </month> <title> discretization of numeric attributes. </title> <booktitle> AAAI-92. </booktitle> <pages> 123128. </pages>
Reference-contexts: For the feed-forward neural network, the training data was scaled using a uniform interval method which involved mapping the real range of each attribute into the range [0, 1]. AQ15c requires discrete-valued attributes, so the SCALE implementation (Bloedorn et al. 1993) of the ChiMerge algorithm <ref> (Kerber 1992) </ref> was used. The ChiMerge algorithm merges real-valued attributes into discrete intervals using the chisquare statistic to correlate intervals to classes. For example, the minchar attribute, which is the minimum number of characters transferred during a session, ranged from 0.0 to 18747.28.
Reference: <author> Lunt, T. F.; Jagannathan, R.; Lee, R.; Whitehurst, A.; and Listgarten, S. </author> <title> (1989) Knowledge-based intrusion detection. </title> <booktitle> Proceedings of the Annual Artificial Intelligence Systems in Government Conference, </booktitle> <pages> 102107. </pages>
Reference-contexts: Statistical Approaches Dennings (1987) seminal paper laid the foundations for the Intrusion Detection Expert System (IDES) which uses a statistical component for anomaly detection and a rule-based component for detecting known intruder behaviors <ref> (Lunt et al. 1989) </ref>. The IDES system later evolved into the Next Generation Intrusion Detection Expert System (NIDES), both of which were developed at SRI International (Anderson et al. 1994a). Figure 2.3 shows the NIDES architecture.
Reference: <author> Maes, P. </author> <title> (1994) Agents that reduce work and information overload. </title> <journal> Communications of the ACM 37.7 (July) 3140. </journal>
Reference-contexts: If one or more of these factors does change, the entire development process is repeated to produce a system capable of coping with the new scenario. New applications, such as intelligent agents <ref> (e.g., Maes 1994) </ref> and active vision (e.g., Ballard and Brown 1993), require autonomous or semi-autonomous functioning and adaptation to changes in the domain, the environment, or the user. Such requirements suggest that incremental learning, as opposed to batch learning, is needed.
Reference: <author> Michalski, R. S. </author> <title> (1969) On the quasi-minimal solution of the general covering problem. </title> <booktitle> Fifth International Symposium on Information Processing, </booktitle> <address> A3:125128. </address>
Reference-contexts: 1 Introduction This paper discusses work in progress and introduces a partial memory incremental learning methodology. The methodology is based on the AQ inductive learning algorithm and consequently uses Variable-Valued Logic (VL 1 ) as a representation language <ref> (Michalski 1969, 1972, 1973, 1980) </ref>. The proposed methodology is incremental in that (a) static concepts are incrementally learned, and (b) incrementally changing concepts are learned. We conjecture that in both cases, completeness and consistency is maintained. <p> Negative concept examples either are explicitly labeled as such, or in a multiple concept learning context, are formed by the remaining training examples for all other concepts. The set covering problem is known to be NP-complete, but the AQ algorithm <ref> (Michalski 1969) </ref> solves the set covering problem in a quasi-optimal manner. <p> The best predictive accuracy during experiment was 94%. Average CPU time for network learning was 580 seconds, although recognition took on average 0.17 seconds. AQ15c Results AQ15c (Wnek 1994) is the latest implementation of the AQ algorithm <ref> (Michalski 1969) </ref>. The AQ algorithm heuristically solves the set covering problem to learn a symbolic concept expressed in VL 1 using both logical and statistical information. The best performing parameters for AQ were as follows. Maxstar was set at 10.
Reference: <author> Michalski, R. S. </author> <title> (1972) A variable-valued logic system as applied to picture description and recognition. </title> <booktitle> IFIP Working Conference on Graphic Languages, </booktitle> <pages> 2147. </pages>
Reference: <author> Michalski, R. S. </author> <title> (1973) AQVAL/1 computer implementation of a variable-valued logic system VL 1 and examples of its application to pattern recognition. </title> <booktitle> First International Joint Conference on Pattern Recognition, </booktitle> <pages> 317. </pages>
Reference-contexts: Each potential representation language for expressing examples and learned concepts carries a representational bias. This bias ultimately affects what knowledge can be represented and learned. The AQ15c concept learning system (Wnek 1994) uses an attributional representation language based on Variable-Valued Logic, or VL 1 <ref> (Michalski 1973) </ref>, to learn decision rules from training examples. We begin by defining a representation space for the problem which is formed from a finite set of relevant attributes and finite attribute domains.
Reference: <author> Michalski, R. S. </author> <title> (1980) Pattern recognition as rule-guided inductive inference. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence 2.4:349361. </journal>
Reference: <author> Mukherjee, B.; Heberlein, L. T.; and Levitt, K. N. </author> <title> (1994) Network intrusion detection. </title> <journal> IEEE Network 8.3 (May-June) 2641. </journal>
Reference-contexts: Again, these measures are compared to historical use. Other statistically-based intrusion detection systems include Wisdom & Sense (Vaccaro 1989) and Haystack (Smaha 1988). Haystack is also the core of the Distributed Intrusion Detection System <ref> (Mukherjee et al. 1994) </ref>. Neural Network Approaches Debar et al. (1992) describe a recurrent neural network component for detecting anomalous user behavior by learning Unix command sequences (see Figure 2.4). Each command from a predefined set of commands was assigned to an input neuron of the network.
Reference: <author> Reinke, R. E., and Michalski, R. S. </author> <title> (1988) Incremental learning of concept descriptions: a method and experimental results. </title> <editor> In Hayes, J. E.; Michie, D.; and Richards, J., eds., </editor> <booktitle> Machine Intelligence 11, </booktitle> <volume> 263288. </volume> <publisher> Oxford: Clarendon Press. </publisher>
Reference-contexts: The proposed methodology is incremental in that (a) static concepts are incrementally learned, and (b) incrementally changing concepts are learned. We conjecture that in both cases, completeness and consistency is maintained. The proposed methodology maintains and uses a partial memory model <ref> (Reinke and Michalski 1988) </ref>, in which representative examples are maintained throughout the learning process that maximally expand and constrain learned concepts. <p> Formula 1 yields a real number in the range [0, 1] where 0 represents no match and 1 represents complete match. 2 . 3 Taxonomy for Incremental Learning Incremental learning is the direct or indirect iterative modification or refinement of concepts from sets of training examples distributed over time <ref> (Reinke and Michalski 1988) </ref>. Referring to Figure 2.2, incremental learning can be accomplished using one of three memory models: no memory, partial memory, and full memory.
Reference: <author> Rumelhart, D. E.; Hinton, G. E.; and Williams, R. J. </author> <title> (1986) Learning internal representations by error propagation. </title> <editor> In Rumelhart, D. E., and McClelland, J. L., eds., </editor> <booktitle> Parallel Distributed Processing: Explorations in the Microstructure of Cognition, </booktitle> <volume> Vol. 1, </volume> <pages> 318362. </pages> <address> Cambridge MA: </address> <publisher> MIT Press. </publisher>
Reference-contexts: The model used here was trained with the Quickprop algorithm (Fahlman 1986), which is a fast variant of the backpropagation algorithm <ref> (Rumelhart et al. 1986) </ref>. The network architecture consisted of 21 continuous inputs, one for each attribute, 15 hidden units, and 9 linear output units, one for each class.
Reference: <author> Smaha, S. E. </author> <year> (1988) </year> <month> Haystack: </month> <title> an intrusion detection system. </title> <booktitle> Proceedings of the Fourth Aerospace Computer Security Applications Conference, </booktitle> <pages> 3744. </pages>
Reference-contexts: Finally, counting measures are simply counts of various system measures, such as number of CPU seconds and number of characters read or written. Again, these measures are compared to historical use. Other statistically-based intrusion detection systems include Wisdom & Sense (Vaccaro 1989) and Haystack <ref> (Smaha 1988) </ref>. Haystack is also the core of the Distributed Intrusion Detection System (Mukherjee et al. 1994). Neural Network Approaches Debar et al. (1992) describe a recurrent neural network component for detecting anomalous user behavior by learning Unix command sequences (see Figure 2.4).
Reference: <author> Teng, H. S.; Chen, K.; and Lu, S. C-Y. </author> <title> (1990) Security audit trail analysis using inductively generated predictive rules. </title> <booktitle> Proceedings of the Sixth Conference on Artificial Intelligence Applications, </booktitle> <pages> 2429. </pages>
Reference-contexts: No experimental results were reported, although the authors did comment that about 9.5% of the rules generated with an entropy value of less than 0.25 could explain or cover more than 63.5% of the security events over a given period of time <ref> (Teng et al. 1990, p. 28) </ref>. Audit-Data Generation Detection Module Profile Generation User Interface 3 Methodology Viewing an intrusion detection application as a concept learning problem gives rise to two distinct phases (see Figure 3.2).
Reference: <author> Vaccaro, H. S. </author> <title> (1989) Detection of anomalous computer session activity. </title> <booktitle> Proceedings of the 1989 IEEE Symposium on Research in Security and Privacy, </booktitle> <volume> 280289. 25 Weiss, </volume> <editor> S. M. and Kulikowski, C. A. </editor> <title> (1992) Computer systems that learn: classification and prediction methods from statistics, neural nets, </title> <booktitle> machine learning and expert systems. </booktitle> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Finally, counting measures are simply counts of various system measures, such as number of CPU seconds and number of characters read or written. Again, these measures are compared to historical use. Other statistically-based intrusion detection systems include Wisdom & Sense <ref> (Vaccaro 1989) </ref> and Haystack (Smaha 1988). Haystack is also the core of the Distributed Intrusion Detection System (Mukherjee et al. 1994). Neural Network Approaches Debar et al. (1992) describe a recurrent neural network component for detecting anomalous user behavior by learning Unix command sequences (see Figure 2.4).
Reference: <author> Wnek, J. </author> <title> (1994) A fast implementation of the AQ-based inductive learning program for large datasets: AQ15c. Reports of the Machine Learning and Inference Laboratory, MLI 943. Center for Machine Learning and Inference, </title> <institution> George Mason University, Fairfax, </institution> <note> VA (to appear). </note>
Reference-contexts: Symbolic use profiles for the computer systems users were learned using the AQ inductive learning algorithm . Experimental comparisons were made between AQ15c <ref> (Wnek 1994) </ref>, the most recent implementation of the AQ algorithm, a feed-forward neural network (Zurada 1992), a nonsymbolic learning algorithm, and k-nearest neighbor (Weiss and Kulikowski 1992), a statistical pattern recognition technique. These results demonstrate that AQ has distinct advantages over neural networks and k-nearest neighbor (k-nn). <p> Each potential representation language for expressing examples and learned concepts carries a representational bias. This bias ultimately affects what knowledge can be represented and learned. The AQ15c concept learning system <ref> (Wnek 1994) </ref> uses an attributional representation language based on Variable-Valued Logic, or VL 1 (Michalski 1973), to learn decision rules from training examples. We begin by defining a representation space for the problem which is formed from a finite set of relevant attributes and finite attribute domains. <p> Under strict matching conventions, a decision class is assigned if one of the rules in the associated cover is true. A rule is true if all of its selectors are true. Figure 5.1 shows two rules induced using AQ15c <ref> (Wnek 1994) </ref>. The objective is to induce a set of hypotheses that describes the training examples in a maximally general way. The difficulty arises with the term maximally general. When phrased in this manner, the problem of finding a maximally general description is an instance of the set covering problem. <p> The AQ algorithm guarantees completeness and consistency of learned concepts. Completeness 5 means that a learned concept covers all positive examples. Consistency means that a learned concept does not cover any negative examples. AQ15c <ref> (Wnek 1994) </ref> is the most recent implementation of the AQ algorithm. 2 . 2 Recognition Through Flexible Matching After learning and validation, induced concepts can be incorporated into a system and deployed. As new observations come to the system, it must classify these events. <p> Consequently, even if we had an admissible rule induction algorithm, our inability to gather all training examples pertaining to a concept makes it impossible to learn the optimal concept. Several flexible matching schemes exist to calculate the degree of match between examples and concepts <ref> (see Wnek 1994) </ref>. The method used for experiments presented in this paper 6 is computed as follows. <p> This is discussed in future work. The average predictive accuracy the neural network achieved for a 100 run experiment was 85%. The best predictive accuracy during experiment was 94%. Average CPU time for network learning was 580 seconds, although recognition took on average 0.17 seconds. AQ15c Results AQ15c <ref> (Wnek 1994) </ref> is the latest implementation of the AQ algorithm (Michalski 1969). The AQ algorithm heuristically solves the set covering problem to learn a symbolic concept expressed in VL 1 using both logical and statistical information. The best performing parameters for AQ were as follows. Maxstar was set at 10.
Reference: <author> Zurada, J. M. </author> <title> (1992) Introduction to artificial neural systems. </title> <address> St. Paul, MN: </address> <publisher> West Publishing. </publisher>
Reference-contexts: Symbolic use profiles for the computer systems users were learned using the AQ inductive learning algorithm . Experimental comparisons were made between AQ15c (Wnek 1994), the most recent implementation of the AQ algorithm, a feed-forward neural network <ref> (Zurada 1992) </ref>, a nonsymbolic learning algorithm, and k-nearest neighbor (Weiss and Kulikowski 1992), a statistical pattern recognition technique. These results demonstrate that AQ has distinct advantages over neural networks and k-nearest neighbor (k-nn).
References-found: 27

