URL: http://cobar.cs.umass.edu/pubfiles/ir-131.ps
Refering-URL: http://cobar.cs.umass.edu/pubfiles/
Root-URL: 
Email: cahoong@cs.umass.edu  
Title: The Hardware/Software Balancing Act for Information Retrieval on Symmetric Multiprocessors  
Author: Zhihong Lu Kathryn S. McKinley Brendon Cahoon fzlu, mckinley, 
Address: Amherst, MA 01003  
Affiliation: Department of Computer Science University of Massachusetts  
Abstract: In this paper, we investigate how to exploit a symmetric multiprocessor to build high performance IR servers. Although the problem can be solved by throwing lots of CPU and disk resources at it, the important questions are how much of which hardware and what software structure is needed to effectively exploit hardware resources. We have found, to our surprise, that in some cases adding hardware degrades performance rather than improves it. We compare the performance of multithreading and multitasking and show that multiple threads are needed to fully utilize hardware resources. Our investigation is based on InQuery, a state-of-the-art full-text information retrieval engine, that is widely used in Web search engines, large libraries, companies, and government agencies such as In-foseek, Library of Congress, White House, West Publishing, and Lotus. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> AltaVista. </author> <note> http://www.altavista.digital.com. </note>
Reference-contexts: Web searching is a special case of the more general information retrieval (IR) problem of locating documents relevant to the information need of users. Until recently, parallel computers were an expensive and special-purpose tool. Today, most hardware vendors offer affordable symmetric multiprocessors (SMP). Web searching engines, such as AltaVista <ref> [1] </ref> and Infos-eek [15], handle tremendous loads by exploiting the parallelism implicit in their tasks and use SMPs to support their services.
Reference: [2] <author> AltaVista. </author> <title> About AltaVista search. </title> <address> http://www.altavista.digital.com/av/content/about.htm. </address>
Reference-contexts: The average document size of the Tipster 1 collection is 2.3 KB, which is very close to the average Web page size (around 2 KB according to the figures published by AltaVista <ref> [2] </ref> 2 ). The simulator only accepts natural language queries. <p> Our validation demonstrates that all queries fall within 40% of the actual system, and of the queries we do not accurately simulate, 2 AltaVista claims that its entire Web space is 60 GB and it indexes 30 million Web pages <ref> [2] </ref>. we usually over estimate rather than under estimate. We are more accurate on long queries. We describe this validation in more detail in Appendix A. 3.2 The Parallel IR server In this section, we describe the multithreaded and multitasking IR server implementations.
Reference: [3] <author> P. Bailey and D. Hawking. </author> <title> A parallel architecture for query processing over a terabyte of text. </title> <type> Technical Report TR-CS-96-04, </type> <institution> The Australian National University, </institution> <month> June </month> <year> 1996. </year>
Reference-contexts: Unfortunately, commercial systems have not published the hardware and software configurations they use to achieve high performance. The previous research investigates either the IR system on massively parallel processing (MPP) architecture <ref> [3, 11, 13, 18, 20, 21, 22] </ref>, or it investigates only a subset of the system on SMP architecture such as the disk system [17] or it compares the cost factors of SMP architecture with other architectures [10]. <p> Although there have been a number of papers regarding to using multiprocessor machines for information retrieval <ref> [3, 10, 11, 13, 17, 18, 20, 21, 22] </ref>, most of them use a distributed memory, massively parallel processing (MPP) architecture [3, 11, 13, 18, 20, 21, 22]. Couvreur et al. analyze the tradeoff between performance and cost when searching large text collections. <p> Although there have been a number of papers regarding to using multiprocessor machines for information retrieval [3, 10, 11, 13, 17, 18, 20, 21, 22], most of them use a distributed memory, massively parallel processing (MPP) architecture <ref> [3, 11, 13, 18, 20, 21, 22] </ref>. Couvreur et al. analyze the tradeoff between performance and cost when searching large text collections. They use simulation models to investigate three different hardware architectures: a mainframe, a collection of RISC processors connected by a network and a special purpose machine [10]. <p> Bailey and Hawking report their IR system on Fujitsu AP1000, which is a 128-node distributed-memory multicomputers and each node has a 25 MHZ CPU and 16 MB memory <ref> [3] </ref>. Cringean et al. and Efraimidis et al. implement their IR systems on a transputer network, which belongs to the MIMD class of parallel computers [11, 13].
Reference: [4] <author> E.W. Brown, J.P Callan, W.B. Croft, and J.E.B. Moss. </author> <title> Supporting full-text information retrieval with a persistent object store. </title> <booktitle> In Proceedings of the 4th International Conference on Extending Database Technology (EDBT), </booktitle> <pages> pages 363-378, </pages> <address> Cam-bridge, UK, </address> <month> March </month> <year> 1994. </year>
Reference-contexts: An inverted file contains term keys, their corresponding lists of documents, and frequency and po 2 sition information in the original document files. Either a custom B* tree [9] package with concurrency control or the Mneme persistent object store <ref> [4] </ref> manages the inverted files. The indexing overhead for a collection of documents is 30% to 40% of its original data size. For example, a 1.2 GB Tipster 1 collection [7] needs 0.5 GB extra disk space to store indexes.
Reference: [5] <author> B. Cahoon and K. S. McKinley. </author> <title> Performance evaluation of a distributed architecture for information retrieval. </title> <booktitle> In Proceedings of the Nineteenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <pages> pages 110-118, </pages> <address> Zurich, Switzerland, </address> <month> August </month> <year> 1996. </year>
Reference-contexts: A document command requests a document using its document identifier. The response includes the complete text of the document. 3.1.2 Simulation Model and Validation We use a simulation model we previously built for In-Query work <ref> [5, 6] </ref>. The simulation model is driven by empirical timing measurements from the actual system. We model three basic IR operations: query evaluation, obtaining summary information, and retrieving documents. We measure CPU, I/O bus, and disk usage for each operation, but do not measure the memory and cache effects. <p> The simulator only accepts natural language queries. Two parameters, query length and query term frequency, determine the characteristics of a query. (See <ref> [5, 6] </ref> for more details.) Because we use a more recent version of InQuery on a DEC AlphaServer 2100 5/250 clocked at 250 MHz instead of an MIPS R3000 clocked at 40 MHz, we validate query response time of our simulator again. <p> The parallel IR server exploits parallelism as follows: (1) It executes multiple IR commands in parallel by either multitasking or multithreading; and (2) It executes one command against multiple partitions of a collection in parallel. 3.2.1 Multithreading vs. Multitasking Since we already had single-threaded servers for uniprocessor machines <ref> [5, 6] </ref>, we implemented a parallel server via multitasking. This version simply uses a light-weight broker and multiple executables of the single-threaded server on the same machine, communicating by message passing [5, 6]. <p> Multitasking Since we already had single-threaded servers for uniprocessor machines <ref> [5, 6] </ref>, we implemented a parallel server via multitasking. This version simply uses a light-weight broker and multiple executables of the single-threaded server on the same machine, communicating by message passing [5, 6]. The broker assigns an IR command to one or multiple available processes, depending on the IR command type and the collection partitioning. Another natural implementation of a parallel InQuery server is to use a thread package to build a shared-everything version, i.e., a multithreaded version. <p> We extend the simulator to model threads, multiple CPUs, and multiple disks. The system parameters also include the original parameters for a single-threaded system <ref> [5, 6] </ref>: query length, query term frequency, client arrival rate, and collection size. Table 1 presents all the parameters and the values we use in our experiments and validation.
Reference: [6] <author> B. Cahoon and K. S. McKinley. </author> <title> Evaluating the performance of distributed architectures for information retrieval using a variety of workloads. </title> <note> Submitted for publication, </note> <year> 1997. </year>
Reference-contexts: A document command requests a document using its document identifier. The response includes the complete text of the document. 3.1.2 Simulation Model and Validation We use a simulation model we previously built for In-Query work <ref> [5, 6] </ref>. The simulation model is driven by empirical timing measurements from the actual system. We model three basic IR operations: query evaluation, obtaining summary information, and retrieving documents. We measure CPU, I/O bus, and disk usage for each operation, but do not measure the memory and cache effects. <p> The simulator only accepts natural language queries. Two parameters, query length and query term frequency, determine the characteristics of a query. (See <ref> [5, 6] </ref> for more details.) Because we use a more recent version of InQuery on a DEC AlphaServer 2100 5/250 clocked at 250 MHz instead of an MIPS R3000 clocked at 40 MHz, we validate query response time of our simulator again. <p> The parallel IR server exploits parallelism as follows: (1) It executes multiple IR commands in parallel by either multitasking or multithreading; and (2) It executes one command against multiple partitions of a collection in parallel. 3.2.1 Multithreading vs. Multitasking Since we already had single-threaded servers for uniprocessor machines <ref> [5, 6] </ref>, we implemented a parallel server via multitasking. This version simply uses a light-weight broker and multiple executables of the single-threaded server on the same machine, communicating by message passing [5, 6]. <p> Multitasking Since we already had single-threaded servers for uniprocessor machines <ref> [5, 6] </ref>, we implemented a parallel server via multitasking. This version simply uses a light-weight broker and multiple executables of the single-threaded server on the same machine, communicating by message passing [5, 6]. The broker assigns an IR command to one or multiple available processes, depending on the IR command type and the collection partitioning. Another natural implementation of a parallel InQuery server is to use a thread package to build a shared-everything version, i.e., a multithreaded version. <p> We extend the simulator to model threads, multiple CPUs, and multiple disks. The system parameters also include the original parameters for a single-threaded system <ref> [5, 6] </ref>: query length, query term frequency, client arrival rate, and collection size. Table 1 presents all the parameters and the values we use in our experiments and validation.
Reference: [7] <author> J. P. Callan, W. B. Croft, and J. Broglio. </author> <title> TREC and TIPSTER experiments with INQUERY. </title> <booktitle> Information Processing & Management, </booktitle> <volume> 31(3) </volume> <pages> 327-343, </pages> <month> May/June </month> <year> 1995. </year>
Reference-contexts: In this paper, we investigate how to balance hardware and software resources to exploit a symmetric multiprocessor (SMP) architecture to build high performance IR servers. Our IR server is based on InQuery <ref> [7, 8, 23] </ref>, a state-of-the-art full-text information retrieval engine that is widely used in Web search engines, large libraries, companies, and governments such as Infoseek, Library of Congress, White House, West Publishing, and Lotus [16]. <p> Section 5 compares this work to previous work, and Section 6 summarizes our results and concludes. 3 A Parallel Information Re trieval Server This section describes the implementation of our parallel IR server and simulator. We begin with a brief description of the InQuery retrieval engine <ref> [7, 8, 16] </ref>, the features we model, and a validation of our simulation of this basic functionality. <p> InQuery uses an inference network model, which applies Bayesian inference networks to represent documents and queries, and views information retrieval as an inference or evidential reasoning process <ref> [7, 8, 23] </ref>. In this paper, we use "collection" to refer to a set of documents, and "database" to refer to an indexed collection. <p> Either a custom B* tree [9] package with concurrency control or the Mneme persistent object store [4] manages the inverted files. The indexing overhead for a collection of documents is 30% to 40% of its original data size. For example, a 1.2 GB Tipster 1 collection <ref> [7] </ref> needs 0.5 GB extra disk space to store indexes. The InQuery server supports a wide range of IR commands such as query, document, and relevance feedback. The three basic IR commands we model are query, summary, and document commands. InQuery accepts both natural language and structured queries. <p> queries, with an average of 2 terms per query that mimic those found in the query set down loaded from the Web server for searching the 103rd Congressional Record [12], and use an observed query term frequency distribution obtained from their distribution in the Tipster 1 collection and query sets <ref> [7] </ref>. We vary the arrival rate and the collection size in order to examine the scalability of the server as the number of clients and the size of the collection increases.
Reference: [8] <author> J. P. Callan, W. B. Croft, and S. M. Harding. </author> <title> The INQUERY retrieval system. </title> <booktitle> In Proceedings of the 3rd International Conference on Database and Expert System Applications, </booktitle> <address> Valencia, Spain, </address> <month> September </month> <year> 1992. </year>
Reference-contexts: In this paper, we investigate how to balance hardware and software resources to exploit a symmetric multiprocessor (SMP) architecture to build high performance IR servers. Our IR server is based on InQuery <ref> [7, 8, 23] </ref>, a state-of-the-art full-text information retrieval engine that is widely used in Web search engines, large libraries, companies, and governments such as Infoseek, Library of Congress, White House, West Publishing, and Lotus [16]. <p> Section 5 compares this work to previous work, and Section 6 summarizes our results and concludes. 3 A Parallel Information Re trieval Server This section describes the implementation of our parallel IR server and simulator. We begin with a brief description of the InQuery retrieval engine <ref> [7, 8, 16] </ref>, the features we model, and a validation of our simulation of this basic functionality. <p> InQuery uses an inference network model, which applies Bayesian inference networks to represent documents and queries, and views information retrieval as an inference or evidential reasoning process <ref> [7, 8, 23] </ref>. In this paper, we use "collection" to refer to a set of documents, and "database" to refer to an indexed collection.
Reference: [9] <author> Douglas Comer. </author> <title> Ubiquitous B-Tree. </title> <journal> ACM Computing Surveys, </journal> <volume> 11(2) </volume> <pages> 121-137, </pages> <year> 1979. </year>
Reference-contexts: An inverted file contains term keys, their corresponding lists of documents, and frequency and po 2 sition information in the original document files. Either a custom B* tree <ref> [9] </ref> package with concurrency control or the Mneme persistent object store [4] manages the inverted files. The indexing overhead for a collection of documents is 30% to 40% of its original data size.
Reference: [10] <author> T. R. Couvreur, R. N. Benzel, S. F. Miller, D. N. Zeitler, D. L. Lee, M. Singhai, N. Shivaratri, and W. Y. P. Wong. </author> <title> An analysis of performance and cost factors in searching large text databases using parallel search systems. </title> <journal> Journal of the American Society for Information Science, </journal> <volume> 7(45) </volume> <pages> 443-464, </pages> <year> 1994. </year>
Reference-contexts: previous research investigates either the IR system on massively parallel processing (MPP) architecture [3, 11, 13, 18, 20, 21, 22], or it investigates only a subset of the system on SMP architecture such as the disk system [17] or it compares the cost factors of SMP architecture with other architectures <ref> [10] </ref>. In this paper, we investigate how to balance hardware and software resources to exploit a symmetric multiprocessor (SMP) architecture to build high performance IR servers. <p> All experiments measure response time, CPU and disk utilization, and determine the largest arrival rate at which the system supports a response time under 10 seconds. We chose 10 seconds arbitrarily as our cutoff point for a reasonable response time. Previous work <ref> [10] </ref> uses a larger value, up to 40 seconds. Commercial web searchers support response times faster than 10 seconds, but use optimization not implemented in InQuery such as caching query results for frequently executed queries. <p> Although there have been a number of papers regarding to using multiprocessor machines for information retrieval <ref> [3, 10, 11, 13, 17, 18, 20, 21, 22] </ref>, most of them use a distributed memory, massively parallel processing (MPP) architecture [3, 11, 13, 18, 20, 21, 22]. Couvreur et al. analyze the tradeoff between performance and cost when searching large text collections. <p> Couvreur et al. analyze the tradeoff between performance and cost when searching large text collections. They use simulation models to investigate three different hardware architectures: a mainframe, a collection of RISC processors connected by a network and a special purpose machine <ref> [10] </ref>. They use different search algorithms on different hardware architectures. The experiments using a mainframe are most related to our work. They measure the response time under different query arrival rates and identify the query arrival rate the system can support within 30-40 seconds.
Reference: [11] <author> J. K. Cringean, R. England, G. A. Mason, and P. Willett. </author> <title> Parallel text searching in serial files using a processor farm. </title> <booktitle> In Proceedings of the Thirteenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <address> Brussels, Belgium, </address> <month> September </month> <year> 1990. </year>
Reference-contexts: Unfortunately, commercial systems have not published the hardware and software configurations they use to achieve high performance. The previous research investigates either the IR system on massively parallel processing (MPP) architecture <ref> [3, 11, 13, 18, 20, 21, 22] </ref>, or it investigates only a subset of the system on SMP architecture such as the disk system [17] or it compares the cost factors of SMP architecture with other architectures [10]. <p> Although there have been a number of papers regarding to using multiprocessor machines for information retrieval <ref> [3, 10, 11, 13, 17, 18, 20, 21, 22] </ref>, most of them use a distributed memory, massively parallel processing (MPP) architecture [3, 11, 13, 18, 20, 21, 22]. Couvreur et al. analyze the tradeoff between performance and cost when searching large text collections. <p> Although there have been a number of papers regarding to using multiprocessor machines for information retrieval [3, 10, 11, 13, 17, 18, 20, 21, 22], most of them use a distributed memory, massively parallel processing (MPP) architecture <ref> [3, 11, 13, 18, 20, 21, 22] </ref>. Couvreur et al. analyze the tradeoff between performance and cost when searching large text collections. They use simulation models to investigate three different hardware architectures: a mainframe, a collection of RISC processors connected by a network and a special purpose machine [10]. <p> Cringean et al. and Efraimidis et al. implement their IR systems on a transputer network, which belongs to the MIMD class of parallel computers <ref> [11, 13] </ref>. Our work instead uses a SMP and investigates the system performance when processing multiple queries. 6 Conclusion In this paper, we investigate building a parallel information retrieval server using a symmetric multiprocessor to improve the system performance.
Reference: [12] <author> W. B. Croft, R. Cook, and D. Wilder. </author> <title> Providing government information on the internet: Experiences with THOMAS. </title> <booktitle> In The Second International Conference on the Theory and Practice of Digital Libraries, </booktitle> <address> Austin, TX, </address> <month> June </month> <year> 1995. </year>
Reference-contexts: We assume the client arrival rate as a Poisson process. Each client issues a query and waits for response. For each query, the server performs two operations: query evaluation and retrieving the corresponding summaries. Since users typically enter short queries <ref> [12] </ref>, we experiment with a query set that consists of 1000 short queries, with an average of 2 terms per query that mimic those found in the query set down loaded from the Web server for searching the 103rd Congressional Record [12], and use an observed query term frequency distribution obtained <p> Since users typically enter short queries <ref> [12] </ref>, we experiment with a query set that consists of 1000 short queries, with an average of 2 terms per query that mimic those found in the query set down loaded from the Web server for searching the 103rd Congressional Record [12], and use an observed query term frequency distribution obtained from their distribution in the Tipster 1 collection and query sets [7].
Reference: [13] <author> P. Efraimidis, C. Glymidakis, B. Mamalis, P. Spirakis, and B. Tampakas. </author> <title> Parallel text retrieval on a high performance supercomputer using the vector space model. </title> <booktitle> In Proceedings of the Eighteenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <pages> pages 58-66, </pages> <address> Seattle, WA, </address> <year> 1995. </year>
Reference-contexts: Unfortunately, commercial systems have not published the hardware and software configurations they use to achieve high performance. The previous research investigates either the IR system on massively parallel processing (MPP) architecture <ref> [3, 11, 13, 18, 20, 21, 22] </ref>, or it investigates only a subset of the system on SMP architecture such as the disk system [17] or it compares the cost factors of SMP architecture with other architectures [10]. <p> Although there have been a number of papers regarding to using multiprocessor machines for information retrieval <ref> [3, 10, 11, 13, 17, 18, 20, 21, 22] </ref>, most of them use a distributed memory, massively parallel processing (MPP) architecture [3, 11, 13, 18, 20, 21, 22]. Couvreur et al. analyze the tradeoff between performance and cost when searching large text collections. <p> Although there have been a number of papers regarding to using multiprocessor machines for information retrieval [3, 10, 11, 13, 17, 18, 20, 21, 22], most of them use a distributed memory, massively parallel processing (MPP) architecture <ref> [3, 11, 13, 18, 20, 21, 22] </ref>. Couvreur et al. analyze the tradeoff between performance and cost when searching large text collections. They use simulation models to investigate three different hardware architectures: a mainframe, a collection of RISC processors connected by a network and a special purpose machine [10]. <p> Cringean et al. and Efraimidis et al. implement their IR systems on a transputer network, which belongs to the MIMD class of parallel computers <ref> [11, 13] </ref>. Our work instead uses a SMP and investigates the system performance when processing multiple queries. 6 Conclusion In this paper, we investigate building a parallel information retrieval server using a symmetric multiprocessor to improve the system performance.
Reference: [14] <editor> D. Harman, editor. </editor> <booktitle> The First Text REtrieval Conference (TREC-1). National Institute of Standards and Technology Special Publication 200-217, </booktitle> <address> Gaithersburg, MD, </address> <year> 1992. </year>
Reference-contexts: We model the collection by obtaining term and document statistics from 1.2 GB Tipster 1 text collection, a well known and used standard test collection distributed by National Institute of Standards and Technology for testing and comparing the current text retrieval techniques <ref> [14] </ref>. The Tipster 1 collection consists of full-text articles coming from Associate Press Newswire, Wall Street Journal, and Computer Selects (Ziff-Davis Publishing), and abstracts from DOE publications. <p> We use 1.2 GB Tipster 1 text collection built as a single database and on a single disk. The inverted file (.5 GB) thus fits in memory (1 GB). The query set is 50 queries generated from the description fields of Tipster topics 51-100 <ref> [14] </ref>. Each query is simply a sum of the terms, with an average of 8 terms per query. We simulate the query arrival as a Poisson process. In the multithreaded version, the server starts a set of threads and then assigns each query to a single thread.
Reference: [15] <author> Infoseek. </author> <note> http://guide.infoseek.com. </note>
Reference-contexts: Until recently, parallel computers were an expensive and special-purpose tool. Today, most hardware vendors offer affordable symmetric multiprocessors (SMP). Web searching engines, such as AltaVista [1] and Infos-eek <ref> [15] </ref>, handle tremendous loads by exploiting the parallelism implicit in their tasks and use SMPs to support their services.
Reference: [16] <author> InQuery. </author> <title> An information engine for the U.S. economy. </title> <address> http://ciir.cs.umass.edu/info/highlights.html. </address>
Reference-contexts: Our IR server is based on InQuery [7, 8, 23], a state-of-the-art full-text information retrieval engine that is widely used in Web search engines, large libraries, companies, and governments such as Infoseek, Library of Congress, White House, West Publishing, and Lotus <ref> [16] </ref>. Our work is novel because it investigates a real, proven effective system under a variety of realistic workloads and hardware configurations on an SMP architecture with multithreading. Our results provide insights for building high performance IR servers for searching the Web and other environments using a symmetric multiprocessor. <p> Section 5 compares this work to previous work, and Section 6 summarizes our results and concludes. 3 A Parallel Information Re trieval Server This section describes the implementation of our parallel IR server and simulator. We begin with a brief description of the InQuery retrieval engine <ref> [7, 8, 16] </ref>, the features we model, and a validation of our simulation of this basic functionality. <p> We also describe the multithreaded and multitasking implementations, and validate our simulator against the multithreaded implementation. 3.1 InQuery Retrieval Engine 3.1.1 InQuery InQuery is one of the most powerful and advanced full-text information retrieval engines in commercial or government use today <ref> [16] </ref>. Infoseek, one of most popular Web search engines, is based on the InQuery technology.
Reference: [17] <author> B-S. Jeong and E. Omiecinski. </author> <title> Inverted file partitioning schemes in multiple disk systems. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 6(2) </volume> <pages> 142-153, </pages> <month> February </month> <year> 1995. </year>
Reference-contexts: The previous research investigates either the IR system on massively parallel processing (MPP) architecture [3, 11, 13, 18, 20, 21, 22], or it investigates only a subset of the system on SMP architecture such as the disk system <ref> [17] </ref> or it compares the cost factors of SMP architecture with other architectures [10]. In this paper, we investigate how to balance hardware and software resources to exploit a symmetric multiprocessor (SMP) architecture to build high performance IR servers. <p> Although there have been a number of papers regarding to using multiprocessor machines for information retrieval <ref> [3, 10, 11, 13, 17, 18, 20, 21, 22] </ref>, most of them use a distributed memory, massively parallel processing (MPP) architecture [3, 11, 13, 18, 20, 21, 22]. Couvreur et al. analyze the tradeoff between performance and cost when searching large text collections. <p> Besides measuring response time, we also measure the system utilization and identify bottlenecks. Jeong and Omiecinski investigate two inverted file partitioning schemes in a shared-everything multiprocessor system <ref> [17] </ref>. One scheme partitions the posting file by term identifiers while the other scheme partitions the posting file by document identifiers. They focus on the effect of adding disks on system performance. They show that response time decreases as the number of disks increases up to some threshold.
Reference: [18] <author> B. Mamalis, O. Spirakis, and Tampakas. </author> <title> Parallel techniques for efficient searching over very large text collections. </title> <booktitle> In Proceedings of The Fifth Text REtrieval Conference (TREC-5), </booktitle> <address> Gaithersburg, MD, </address> <year> 1996. </year> <institution> National Institute of Standards and Technology Special Publication. </institution>
Reference-contexts: Unfortunately, commercial systems have not published the hardware and software configurations they use to achieve high performance. The previous research investigates either the IR system on massively parallel processing (MPP) architecture <ref> [3, 11, 13, 18, 20, 21, 22] </ref>, or it investigates only a subset of the system on SMP architecture such as the disk system [17] or it compares the cost factors of SMP architecture with other architectures [10]. <p> Although there have been a number of papers regarding to using multiprocessor machines for information retrieval <ref> [3, 10, 11, 13, 17, 18, 20, 21, 22] </ref>, most of them use a distributed memory, massively parallel processing (MPP) architecture [3, 11, 13, 18, 20, 21, 22]. Couvreur et al. analyze the tradeoff between performance and cost when searching large text collections. <p> Although there have been a number of papers regarding to using multiprocessor machines for information retrieval [3, 10, 11, 13, 17, 18, 20, 21, 22], most of them use a distributed memory, massively parallel processing (MPP) architecture <ref> [3, 11, 13, 18, 20, 21, 22] </ref>. Couvreur et al. analyze the tradeoff between performance and cost when searching large text collections. They use simulation models to investigate three different hardware architectures: a mainframe, a collection of RISC processors connected by a network and a special purpose machine [10].
Reference: [19] <author> Open Software Foundation. </author> <title> OSF DCE Application Development Guide Core Components, </title> <year> 1994. </year>
Reference-contexts: Another natural implementation of a parallel InQuery server is to use a thread package to build a shared-everything version, i.e., a multithreaded version. We use the POSIX thread libraries <ref> [19] </ref>. Because threads within a process share the same virtual address space, context switching between threads is less expensive than between processes. In addition, the cooperating threads communicate by simply accessing synchronized global or static variables; thus, we expect the multithreading to be more efficient than the multitasking.
Reference: [20] <author> C. Stanfill. </author> <title> Partitioned posting files: A parallel inverted file structure for information retrieval. </title> <booktitle> In Proceedings of the Thirteenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <pages> pages 413-428, </pages> <address> Brussels, BELGIUM, </address> <year> 1990. </year>
Reference-contexts: Unfortunately, commercial systems have not published the hardware and software configurations they use to achieve high performance. The previous research investigates either the IR system on massively parallel processing (MPP) architecture <ref> [3, 11, 13, 18, 20, 21, 22] </ref>, or it investigates only a subset of the system on SMP architecture such as the disk system [17] or it compares the cost factors of SMP architecture with other architectures [10]. <p> Although there have been a number of papers regarding to using multiprocessor machines for information retrieval <ref> [3, 10, 11, 13, 17, 18, 20, 21, 22] </ref>, most of them use a distributed memory, massively parallel processing (MPP) architecture [3, 11, 13, 18, 20, 21, 22]. Couvreur et al. analyze the tradeoff between performance and cost when searching large text collections. <p> Although there have been a number of papers regarding to using multiprocessor machines for information retrieval [3, 10, 11, 13, 17, 18, 20, 21, 22], most of them use a distributed memory, massively parallel processing (MPP) architecture <ref> [3, 11, 13, 18, 20, 21, 22] </ref>. Couvreur et al. analyze the tradeoff between performance and cost when searching large text collections. They use simulation models to investigate three different hardware architectures: a mainframe, a collection of RISC processors connected by a network and a special purpose machine [10]. <p> The other related studies use MPPs and focus on how to speed up single query processing. Stanfill et al. implement their IR system on the connection machine (CM), which is a fine-grained, massively parallel distributed-memory SIMD architecture with up to 65,536 processing elements <ref> [20, 21, 22] </ref>. Bailey and Hawking report their IR system on Fujitsu AP1000, which is a 128-node distributed-memory multicomputers and each node has a 25 MHZ CPU and 16 MB memory [3].
Reference: [21] <author> C. Stanfill and B. Kahle. </author> <title> Parallel free-text search on the connection machine system. </title> <journal> Communications of the ACM, </journal> <volume> 29(12) </volume> <pages> 1229-1239, </pages> <month> December </month> <year> 1986. </year>
Reference-contexts: Unfortunately, commercial systems have not published the hardware and software configurations they use to achieve high performance. The previous research investigates either the IR system on massively parallel processing (MPP) architecture <ref> [3, 11, 13, 18, 20, 21, 22] </ref>, or it investigates only a subset of the system on SMP architecture such as the disk system [17] or it compares the cost factors of SMP architecture with other architectures [10]. <p> Although there have been a number of papers regarding to using multiprocessor machines for information retrieval <ref> [3, 10, 11, 13, 17, 18, 20, 21, 22] </ref>, most of them use a distributed memory, massively parallel processing (MPP) architecture [3, 11, 13, 18, 20, 21, 22]. Couvreur et al. analyze the tradeoff between performance and cost when searching large text collections. <p> Although there have been a number of papers regarding to using multiprocessor machines for information retrieval [3, 10, 11, 13, 17, 18, 20, 21, 22], most of them use a distributed memory, massively parallel processing (MPP) architecture <ref> [3, 11, 13, 18, 20, 21, 22] </ref>. Couvreur et al. analyze the tradeoff between performance and cost when searching large text collections. They use simulation models to investigate three different hardware architectures: a mainframe, a collection of RISC processors connected by a network and a special purpose machine [10]. <p> The other related studies use MPPs and focus on how to speed up single query processing. Stanfill et al. implement their IR system on the connection machine (CM), which is a fine-grained, massively parallel distributed-memory SIMD architecture with up to 65,536 processing elements <ref> [20, 21, 22] </ref>. Bailey and Hawking report their IR system on Fujitsu AP1000, which is a 128-node distributed-memory multicomputers and each node has a 25 MHZ CPU and 16 MB memory [3].
Reference: [22] <author> C. Stanfill, R. Thau, and D. Waltz. </author> <title> A parallel indexed algorithm for information retrieval. </title> <booktitle> In Proceedings of the Twelfth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <pages> pages 88-97, </pages> <address> Cam-bridge, MA, </address> <month> June </month> <year> 1989. </year>
Reference-contexts: Unfortunately, commercial systems have not published the hardware and software configurations they use to achieve high performance. The previous research investigates either the IR system on massively parallel processing (MPP) architecture <ref> [3, 11, 13, 18, 20, 21, 22] </ref>, or it investigates only a subset of the system on SMP architecture such as the disk system [17] or it compares the cost factors of SMP architecture with other architectures [10]. <p> Although there have been a number of papers regarding to using multiprocessor machines for information retrieval <ref> [3, 10, 11, 13, 17, 18, 20, 21, 22] </ref>, most of them use a distributed memory, massively parallel processing (MPP) architecture [3, 11, 13, 18, 20, 21, 22]. Couvreur et al. analyze the tradeoff between performance and cost when searching large text collections. <p> Although there have been a number of papers regarding to using multiprocessor machines for information retrieval [3, 10, 11, 13, 17, 18, 20, 21, 22], most of them use a distributed memory, massively parallel processing (MPP) architecture <ref> [3, 11, 13, 18, 20, 21, 22] </ref>. Couvreur et al. analyze the tradeoff between performance and cost when searching large text collections. They use simulation models to investigate three different hardware architectures: a mainframe, a collection of RISC processors connected by a network and a special purpose machine [10]. <p> The other related studies use MPPs and focus on how to speed up single query processing. Stanfill et al. implement their IR system on the connection machine (CM), which is a fine-grained, massively parallel distributed-memory SIMD architecture with up to 65,536 processing elements <ref> [20, 21, 22] </ref>. Bailey and Hawking report their IR system on Fujitsu AP1000, which is a 128-node distributed-memory multicomputers and each node has a 25 MHZ CPU and 16 MB memory [3].
Reference: [23] <author> H. R. </author> <title> Turtle. Inference Networks for Document Retrieval. </title> <type> PhD thesis, </type> <institution> University of Massachusetts, </institution> <month> February </month> <year> 1991. </year>
Reference-contexts: In this paper, we investigate how to balance hardware and software resources to exploit a symmetric multiprocessor (SMP) architecture to build high performance IR servers. Our IR server is based on InQuery <ref> [7, 8, 23] </ref>, a state-of-the-art full-text information retrieval engine that is widely used in Web search engines, large libraries, companies, and governments such as Infoseek, Library of Congress, White House, West Publishing, and Lotus [16]. <p> InQuery uses an inference network model, which applies Bayesian inference networks to represent documents and queries, and views information retrieval as an inference or evidential reasoning process <ref> [7, 8, 23] </ref>. In this paper, we use "collection" to refer to a set of documents, and "database" to refer to an indexed collection.
References-found: 23

