URL: ftp://ftp.cse.cuhk.edu.hk/pub/techreports/94/tr-94-14.ps.gz
Refering-URL: ftp://ftp.cs.cuhk.hk/pub/techreports/README.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: fjlee,wltamg@cs.cuhk.hk  
Title: Towards the Integration of Artificial Neural Networks and Constraint Logic Programming  
Author: J.H.M. Lee and V.W.L. Tam 
Address: Hong Kong  
Affiliation: Department of Computer Science The Chinese University of Hong Kong  
Abstract: In this paper, we present a general framework for integrating artificial neural networks (ANN) into constraint logic programming for solving CSP's. This framework is realized in a novel programming language PROCLANN, which uses the standard goal reduction strategy as frontend to generate constraints for an efficient backend ANN-based constraint-solver. PRO-CLANN retains the simple and elegant declarative semantics of constraint logic programming. Its operational semantics is probabilistic in nature but it possesses soundness and completeness results. An initial prototype of PROCLANN is constructed and provides empirical evidence that PROCLANN compares favourably against the state of art in CLP implementations on certain hard instances of CSP. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> E.H.L. Aarts and J.H.M. Korst. </author> <title> Boltzmann machines for traveling salesman problems. </title> <journal> European Journal of Operational Research, </journal> <volume> 39 </volume> <pages> 79-95, </pages> <year> 1989. </year>
Reference-contexts: There has been recent interest in applying ANN to optimization and CSP. For examples, Hopfield network, the Boltzmann Machine and the elastic network have been used in the traveling salesman problems <ref> [9, 1, 6] </ref>, the Tangram puzzles [12] and the N-queens problem [15] with satisfactory results. Wang and Tsang [19, 17] propose GENET, a generic ANN model, for solving general CSP's with binary constraints.
Reference: [2] <author> A. Davenport, E.P.K. Tsang, C.J. Wang, and K. Zhu. GENET: </author> <title> A connectionist architecture for solving constraint satisfaction problems by iterative improvement. </title> <note> In (to appear) Proceedings of AAAI'94, </note> <year> 1994. </year>
Reference-contexts: Constraints generated will be passed to the incremental GENET running in the massively parallel backend. Second, the incremental GENET model supports only binary constraints. A GENET architecture for solving general constraints such as illegal and atmost constraints in the car-sequencing problem is presented in <ref> [2] </ref>. It is interesting to check if the model can be adapted for all general constraints. Third, we use the GENET model only as a case study. Other ANN models should be investigated.
Reference: [3] <author> M. Dincbas, H. Simonis, and P. Van Hentenryck. </author> <title> Solving the car-sequencing problem in constraint logic programming. </title> <booktitle> In Proceedings of the Euro-pean Conference on Artificial Intelligence, </booktitle> <pages> pages 290-295, </pages> <year> 1988. </year>
Reference-contexts: Van Hentenryck [18] introduces consistency techniques [13] into logic programming so that constraints are used actively to prune search space a priori. The framework is realized in the CHIP language [5], which has been successfully applied to solving numerous industrial applications <ref> [3, 4] </ref>. CHIP's execution mechanism is still based on tree search and backtracking, which are main barriers to efficient solving of some hard or large-scale CSP's. There has been recent interest in applying ANN to optimization and CSP.
Reference: [4] <author> M. Dincbas, H. Simonis, and P. Van Hentenryck. </author> <title> Solving large combinatorial problems in logic programming. </title> <journal> Journal of Logic Programming, </journal> <volume> 8 </volume> <pages> 75-93, </pages> <year> 1990. </year>
Reference-contexts: Van Hentenryck [18] introduces consistency techniques [13] into logic programming so that constraints are used actively to prune search space a priori. The framework is realized in the CHIP language [5], which has been successfully applied to solving numerous industrial applications <ref> [3, 4] </ref>. CHIP's execution mechanism is still based on tree search and backtracking, which are main barriers to efficient solving of some hard or large-scale CSP's. There has been recent interest in applying ANN to optimization and CSP.
Reference: [5] <author> M. Dincbas, P. Van Hentenryck, H. Simonis, A. Aggoun, T. Graf, and F. Berthier. </author> <title> The constraint logic programming language CHIP. </title> <booktitle> In Proceedings of the International Conference on Fifth Generation Computer Systems (FGCS'88), </booktitle> <pages> pages 693-702, </pages> <address> Tokyo, Japan, </address> <month> December </month> <year> 1988. </year>
Reference-contexts: Van Hentenryck [18] introduces consistency techniques [13] into logic programming so that constraints are used actively to prune search space a priori. The framework is realized in the CHIP language <ref> [5] </ref>, which has been successfully applied to solving numerous industrial applications [3, 4]. CHIP's execution mechanism is still based on tree search and backtracking, which are main barriers to efficient solving of some hard or large-scale CSP's. There has been recent interest in applying ANN to optimization and CSP.
Reference: [6] <author> R. Durbin and D. Willshaw. </author> <title> An analogue approach to the traveling salesman problem using an elastic net method. </title> <journal> Nature, </journal> <volume> 326 </volume> <pages> 689-691, </pages> <year> 1987. </year>
Reference-contexts: There has been recent interest in applying ANN to optimization and CSP. For examples, Hopfield network, the Boltzmann Machine and the elastic network have been used in the traveling salesman problems <ref> [9, 1, 6] </ref>, the Tangram puzzles [12] and the N-queens problem [15] with satisfactory results. Wang and Tsang [19, 17] propose GENET, a generic ANN model, for solving general CSP's with binary constraints.
Reference: [7] <author> P. Eklund and F. Klawonn. </author> <title> Neural fuzzy logic programming. </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> 3(5) </volume> <pages> 815-818, </pages> <month> September </month> <year> 1992. </year>
Reference-contexts: The logic programming part of the execution mechanism generates the corresponding neural network of the CSP, which is then submitted to the backend ANN-based constraint-solver for further scrutiny. This way we obtain the best of both worlds: an easy-to-program language with high efficiency. There has been other attempts <ref> [7, 14] </ref>, with different motivations, in the amalgamation of logic programming and ANN. These approaches are all translational, in which a set of logical formula is translated into a neural network and theorem proving becomes an energy minimization process.
Reference: [8] <author> R.M. Haralick and G.L. Elliot. </author> <title> Increasing tree search efficiency for constraint satisfaction problems. </title> <journal> Artificial Intelligence, </journal> <volume> 14 </volume> <pages> 263-313, </pages> <year> 1980. </year>
Reference-contexts: The PROCLANN graph-coloring program is shown in figure 1. The results are presented in table 1. The CPU time reported in the table is the median time 3 over ten runs. Note that the first-fail principle <ref> [8] </ref> is used in labeling in the CHIP program. CHIP cannot manage to solve either one of the cases for 125 vertices within 48 hours. For the cases of 250 vertices, CHIP runs out of memory on our machine with 32M memory.
Reference: [9] <author> J.J. Hopfield and D. Tank. </author> <title> "Neural" computation of decisions in optimization problems. </title> <journal> Biological Cybernetics, </journal> <volume> 52 </volume> <pages> 141-152, </pages> <year> 1985. </year>
Reference-contexts: There has been recent interest in applying ANN to optimization and CSP. For examples, Hopfield network, the Boltzmann Machine and the elastic network have been used in the traveling salesman problems <ref> [9, 1, 6] </ref>, the Tangram puzzles [12] and the N-queens problem [15] with satisfactory results. Wang and Tsang [19, 17] propose GENET, a generic ANN model, for solving general CSP's with binary constraints.
Reference: [10] <author> J. Jaffar and J-L. Lassez. </author> <title> Constraint logic programming. </title> <booktitle> In Proceedings of the 14th ACM POPL Conference, </booktitle> <pages> pages 111-119, </pages> <address> Munich, </address> <month> Jan-uary </month> <year> 1987. </year>
Reference-contexts: This design decision is justifiable by the fact that goal reduction is used only to inject constraints into a neural network but not to perform searching. The operational semantics of PROCLANN is similar to that of the CLP scheme <ref> [10] </ref> but the use of an ANN-based constraint-solver is made explicit in the PROCLANN Computation Model , which is both sound and probabilistically complete. 3.1 Syntax and declarative semantics Since we are interested in CSP, we need the notion of domains and domain variables [18], abbreviated as d-variables. <p> To differentiate d-variables from Herbrand variables, we call the latter h-variables. The constraint domain D in consideration defines a set C of primitive constraints. PROCLANN only supports binary constraints. As specified in the CLP scheme <ref> [10] </ref>, the equality constraint #= 1 is in C. An atom is any standard atomic formula whose predicate symbol is different from those of the primitive constraints.
Reference: [11] <author> D. Johnson, C. Aragon, L. McGeoch, and C. Schevon. </author> <title> Optimization by simulated annealing: an experimental evaluation; part 2 graph coloring and number partitioning. </title> <journal> Operations Research, </journal> <volume> 39(3) </volume> <pages> 378-406, </pages> <year> 1991. </year>
Reference-contexts: It is a practical CSP which has many useful applications, such as production scheduling. We compare PRO-CLANN and CHIP on a set of hard graph-coloring problems described in <ref> [11] </ref>. The PROCLANN graph-coloring program is shown in figure 1. The results are presented in table 1. The CPU time reported in the table is the median time 3 over ten runs. Note that the first-fail principle [8] is used in labeling in the CHIP program.
Reference: [12] <author> Oflazer K. </author> <title> Solving tangram puzzles : A connectionist approach. </title> <journal> International Journal of Neural Systems, </journal> <volume> 8(5) </volume> <pages> 603-616, </pages> <year> 1993. </year>
Reference-contexts: There has been recent interest in applying ANN to optimization and CSP. For examples, Hopfield network, the Boltzmann Machine and the elastic network have been used in the traveling salesman problems [9, 1, 6], the Tangram puzzles <ref> [12] </ref> and the N-queens problem [15] with satisfactory results. Wang and Tsang [19, 17] propose GENET, a generic ANN model, for solving general CSP's with binary constraints. A massively parallel implementation of GENET may attain a theoretical speedup in the order of 10 8 over sequential heuristic search.
Reference: [13] <author> A.K. Mackworth. </author> <title> Consistency in networks of relations. </title> <journal> AI Journal, </journal> <volume> 8(1) </volume> <pages> 99-118, </pages> <year> 1977. </year>
Reference-contexts: 1 Motivation and related work The problem at hand is that of constraint satisfaction problems (CSP) defined in the sense of Mack-worth <ref> [13] </ref>. CSP is a general problem which occur in many areas of applications, such as computer vision, planning, resource allocation in scheduling and temporal reasoning, etc. There are two concerns when handling CSP's: programming and efficient execution. The former is well addressed by logic programming in Prolog. <p> The basic backtracking tree-search execution strategy of Prolog, however, usually produces unacceptable performance on a computer even on medium size problems, as the tree contains too many possibilities to be exhaustively searched. Van Hentenryck [18] introduces consistency techniques <ref> [13] </ref> into logic programming so that constraints are used actively to prune search space a priori. The framework is realized in the CHIP language [5], which has been successfully applied to solving numerous industrial applications [3, 4]. <p> Let V i denotes the value assigned to Z i . There are two constraints: (1) V i + V i+1 is even and (2) either V 1 = 2 or V 5 = 2. defined in the sense of Mackworth <ref> [13] </ref>. Figure 3 (b) is the corresponding network topology in GENET. Each column of 3 nodes represents a cluster for each domain variable. Each connection weight W ij between nodes i and j is initially set to -1. The cross inhibitory connections are constructed according to constraint 1.
Reference: [14] <author> T.J. Reynolds, H.H. Teh, </author> <title> and B.T. Low. </title> <booktitle> Neural logic programming. In Proceedings of the 2nd International IEEE Conference on Tools for A.I., </booktitle> <pages> pages 485-491, </pages> <year> 1990. </year>
Reference-contexts: The logic programming part of the execution mechanism generates the corresponding neural network of the CSP, which is then submitted to the backend ANN-based constraint-solver for further scrutiny. This way we obtain the best of both worlds: an easy-to-program language with high efficiency. There has been other attempts <ref> [7, 14] </ref>, with different motivations, in the amalgamation of logic programming and ANN. These approaches are all translational, in which a set of logical formula is translated into a neural network and theorem proving becomes an energy minimization process.
Reference: [15] <author> O. Shagrir. </author> <title> A neural net with self-inhibiting units for the n-queens problem. </title> <journal> International Journal of Neural Systems, </journal> <volume> 8(3) </volume> <pages> 249-252, </pages> <year> 1993. </year>
Reference-contexts: There has been recent interest in applying ANN to optimization and CSP. For examples, Hopfield network, the Boltzmann Machine and the elastic network have been used in the traveling salesman problems [9, 1, 6], the Tangram puzzles [12] and the N-queens problem <ref> [15] </ref> with satisfactory results. Wang and Tsang [19, 17] propose GENET, a generic ANN model, for solving general CSP's with binary constraints. A massively parallel implementation of GENET may attain a theoretical speedup in the order of 10 8 over sequential heuristic search.
Reference: [16] <author> E.P.K. Tsang. </author> <title> Foundations of Constraint Satisfaction. </title> <publisher> Academic Press, </publisher> <year> 1993. </year>
Reference-contexts: GENET handles only binary constraints over finite domains. This apparent jeopardy to the expressiveness of PROCLANN is resolved by the fact that, with finite domains, all non-binary constraints can readily be transformed into binary constraints <ref> [16] </ref>. We have not yet investigated its effect on efficiency. The GENET algorithm is semi-decidable, just as the be-haviour of most other random-based algorithms. So is PROCLANN. Therefore, there is no notion of finite failure of PROCLANN and it cannot be used to detect inconsistent CSP's.
Reference: [17] <author> E.P.K. Tsang and C.J. Wang. </author> <title> A generic neural network approach for constraint satisfaction problems. </title> <editor> In G Taylor, editor, </editor> <booktitle> Neural Network Applications, </booktitle> <pages> pages 12-22. </pages> <publisher> Springer-Verlag, </publisher> <year> 1992. </year>
Reference-contexts: There has been recent interest in applying ANN to optimization and CSP. For examples, Hopfield network, the Boltzmann Machine and the elastic network have been used in the traveling salesman problems [9, 1, 6], the Tangram puzzles [12] and the N-queens problem [15] with satisfactory results. Wang and Tsang <ref> [19, 17] </ref> propose GENET, a generic ANN model, for solving general CSP's with binary constraints. A massively parallel implementation of GENET may attain a theoretical speedup in the order of 10 8 over sequential heuristic search. Wang and Tsang [20] also propose a cascadable VLSI design for GENET. <p> It means that if the CSP specified by the program is solvable, then there always exists a successful derivation and the answer network obtained has non-zero probability to converge to any solution of the CSP. 4 GENET We have chosen the GENET model <ref> [19, 17] </ref> to demonstrate the feasibility of our proposal. GENET is a generic neural network simulator that can be used to solve general CSP's with finite domains. To illustrate how a GENET network is constructed for a CSP, let us take a simple but tight 2 binary CSP as example.
Reference: [18] <author> P. Van Hentenryck. </author> <title> Constraint Satisfaction in Logic Programming. </title> <publisher> The MIT Press, </publisher> <year> 1989. </year>
Reference-contexts: The basic backtracking tree-search execution strategy of Prolog, however, usually produces unacceptable performance on a computer even on medium size problems, as the tree contains too many possibilities to be exhaustively searched. Van Hentenryck <ref> [18] </ref> introduces consistency techniques [13] into logic programming so that constraints are used actively to prune search space a priori. The framework is realized in the CHIP language [5], which has been successfully applied to solving numerous industrial applications [3, 4]. <p> to that of the CLP scheme [10] but the use of an ANN-based constraint-solver is made explicit in the PROCLANN Computation Model , which is both sound and probabilistically complete. 3.1 Syntax and declarative semantics Since we are interested in CSP, we need the notion of domains and domain variables <ref> [18] </ref>, abbreviated as d-variables. A domain is a finite set of constants. Each d-variable has the form X d , where d is the associated domain of X d . To differentiate d-variables from Herbrand variables, we call the latter h-variables. <p> If a clause has no guard, the "|" can be omitted. Thus a clause has the same declarative reading as a Horn clause with domain variables <ref> [18] </ref>. A program is a set of clauses. A query in PROCLANN is simply a clause without the head and the guard. The concepts of truth, model, and logical consequences of PROCLANN are equivalent to those of CHIP [18]. <p> has the same declarative reading as a Horn clause with domain variables <ref> [18] </ref>. A program is a set of clauses. A query in PROCLANN is simply a clause without the head and the guard. The concepts of truth, model, and logical consequences of PROCLANN are equivalent to those of CHIP [18]. We conclude this subsection by a PROCLANN program shown in figure 1 for the graph-coloring problem of figure 2. The built-in predicate in/2 declares that each element of L is a list of d-variables with domain f1; : : : ; ng. <p> X 1 X X X 6 4 2 CHIP <ref> [18] </ref>, we have three cases to consider in the new definition. 1. If a h-variable X is unified with a d-variable Y e , unification succeeds and the binding fX=Y e g is generated. 2.
Reference: [19] <author> C.J. Wang and E.P.K. Tsang. </author> <title> Solving constraint satisfaction problems using neural networks. </title> <booktitle> In Proceedings of the IEE 2nd Conference on Artificial Neural Networks, </booktitle> <pages> pages 295-299, </pages> <year> 1991. </year>
Reference-contexts: There has been recent interest in applying ANN to optimization and CSP. For examples, Hopfield network, the Boltzmann Machine and the elastic network have been used in the traveling salesman problems [9, 1, 6], the Tangram puzzles [12] and the N-queens problem [15] with satisfactory results. Wang and Tsang <ref> [19, 17] </ref> propose GENET, a generic ANN model, for solving general CSP's with binary constraints. A massively parallel implementation of GENET may attain a theoretical speedup in the order of 10 8 over sequential heuristic search. Wang and Tsang [20] also propose a cascadable VLSI design for GENET. <p> It means that if the CSP specified by the program is solvable, then there always exists a successful derivation and the answer network obtained has non-zero probability to converge to any solution of the CSP. 4 GENET We have chosen the GENET model <ref> [19, 17] </ref> to demonstrate the feasibility of our proposal. GENET is a generic neural network simulator that can be used to solve general CSP's with finite domains. To illustrate how a GENET network is constructed for a CSP, let us take a simple but tight 2 binary CSP as example.
Reference: [20] <author> C.J. Wang and E.P.K. Tsang. </author> <title> A cascadable VLSI design for GENET. </title> <booktitle> In Proceedings of the Oxford VLSI Workshop, </booktitle> <year> 1992. </year>
Reference-contexts: Wang and Tsang [19, 17] propose GENET, a generic ANN model, for solving general CSP's with binary constraints. A massively parallel implementation of GENET may attain a theoretical speedup in the order of 10 8 over sequential heuristic search. Wang and Tsang <ref> [20] </ref> also propose a cascadable VLSI design for GENET. ANN, while efficient, can be difficult to program. Translating a CSP into a neural network is often a tedious and error-prone task. This is where logic programming can help. We propose to integrate constraint logic programming and ANN.
References-found: 20

