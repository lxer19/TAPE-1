URL: http://www.robotics.stanford.edu/~hhg/doc/ISRR98/isrr98.ps.gz
Refering-URL: http://www.robotics.stanford.edu/~hhg/doc/ISRR98/
Root-URL: http://www.robotics.stanford.edu
Email: emails:fhhg,guibas,latombe,lavalle,dlin,motwani,tomasig@cs.stanford.edu  
Title: Motion Planning with Visibility Constraints: Building Autonomous Observers  
Author: H. Gonzalez-Ba~nos L. Guibas J.C. Latombe S.M. LaValle D. Lin R. Motwani C. Tomasi 
Date: October 3-7, 1997  
Address: Hayama, Japan,  Stanford, CA 94305, USA  
Affiliation: of Robotics Research  Department of Computer Science Stanford University,  
Note: The Eighth International Symposium  
Abstract: Autonomous Observers are mobile robots that cooperatively perform vision tasks. Their design raises new issues in motion planning, where visibility constraints and motion obstructions must be simultaneously taken into account. This paper presents the concept of an Autonomous Observer and its applications. It discusses three problems in motion planning with visibility constraints: model building, target finding, and target tracking. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Banta, J. E., Y. Zhien, X. Z. Wang, G. Zhang, M. T. Smith, and M. </author> <month> Abidi </month> <year> (1995). </year> <title> A best-next-view algorithm for three-dimensional scene reconstruction using range images. </title> <booktitle> In Proc. SPIE, </booktitle> <volume> Vol. 2588, </volume> <pages> 418-429. </pages>
Reference: <author> Briggs, A. J. and B. R. </author> <title> Donald (1997). Robust geometric algorithms for sensor planning. In Algorithms for Robotic Motion and Manipulation (WAFR'96), </title> <type> 197-212. </type> <institution> J.P Laumond and M. </institution>
Reference-contexts: But, while the goal of the latter problem is to track the object as long as it is visible in the images, AOs must move to avoid potential visual obstruction by obstacles and keep the target in their field of view. Planning AO motions also relates to sensor placement <ref> (Briggs and Donald 1997) </ref> and active sensing (Maver and Bajcsy 1993). In this paper we present our ongoing research on three specific planning problems related to the design of a team of AOs: i) model building, ii) target finding, and iii) target tracking.
Reference: <editor> Overmars (eds.), A K Peters, </editor> <address> Wellesley, MA. </address>
Reference: <author> Crass, D., I. Suzuki, and M. </author> <title> Yamashita (1995). Searching for a mobile intruder in a corridor the open edge variant of the polygon search problem. </title> <journal> Int. J. of Comp. Geom. and Appl. </journal> <volume> 5 (4), </volume> <pages> 397-412. </pages>
Reference-contexts: Non-geometric pursuit-evasion problems have been studied in graphs (e.g., (Parsons 1976)). A problem similar to ours is analyzed in <ref> (Crass et al. 1995) </ref>.
Reference: <author> Guibas, L. J., J. C. Latombe, S. M. LaValle, D. Lin, and R. </author> <title> Motwani (1997). Visibility-based pursuit-evasion in a polygonal environment. </title> <booktitle> In Proc. 5th Workshop on Algorithms and Data Structures (WADS'97), </booktitle> <publisher> Springer Verlag, </publisher> <pages> 17-30. </pages>
Reference-contexts: However, even when h = 0, small geometric differences may affect N ; e.g., in Fig. 3 the rightmost environment requires two AOs, while the other two require a single AO. We have established the following worst-case bounds on N <ref> (Guibas et al. 1997) </ref>: For simply-connected environments (h = 0), N = O (lg n); there exist environments such that N = (lg n). <p> Formultiply-connected environments (h &gt; 0), N = O ( h + lg n); there exist environments such that N = ( p Note that the art-gallery problem in an n-sided polygon with h holes requires b (n + h)=3c static guards (O'Rourke 1997). In <ref> (Guibas et al. 1997) </ref> we also show that com puting N for a given environment is NP-hard. Single-AO Planner. The NP-hardness of computing N led us to investigate and develop a complete planner for the case of a single AO. <p> Such a decomposition has already been used in robot localization (Guibas et al. 1997; Talluri and Aggarwal 1996); it generates O (n 3 ) cells for a simple polygon. To obtain conservative cells only, slightly fewer lines are needed than in a pure edge-visibility decomposition <ref> (Guibas et al. 1997) </ref>. A directed information state graph G is built and searched using this cell decomposition. For each cell , a set of vertices are included in G for each possible labeling of the gap edges.
Reference: <author> Guibas, L. J., R. Motwani, and P. </author> <title> Raghavan (1997). The robot localization problem. </title> <booktitle> In Algorithmics Foundations of Robotics (WAFR'94), </booktitle> <pages> 269-282. </pages>
Reference-contexts: However, even when h = 0, small geometric differences may affect N ; e.g., in Fig. 3 the rightmost environment requires two AOs, while the other two require a single AO. We have established the following worst-case bounds on N <ref> (Guibas et al. 1997) </ref>: For simply-connected environments (h = 0), N = O (lg n); there exist environments such that N = (lg n). <p> Formultiply-connected environments (h &gt; 0), N = O ( h + lg n); there exist environments such that N = ( p Note that the art-gallery problem in an n-sided polygon with h holes requires b (n + h)=3c static guards (O'Rourke 1997). In <ref> (Guibas et al. 1997) </ref> we also show that com puting N for a given environment is NP-hard. Single-AO Planner. The NP-hardness of computing N led us to investigate and develop a complete planner for the case of a single AO. <p> Such a decomposition has already been used in robot localization (Guibas et al. 1997; Talluri and Aggarwal 1996); it generates O (n 3 ) cells for a simple polygon. To obtain conservative cells only, slightly fewer lines are needed than in a pure edge-visibility decomposition <ref> (Guibas et al. 1997) </ref>. A directed information state graph G is built and searched using this cell decomposition. For each cell , a set of vertices are included in G for each possible labeling of the gap edges.
Reference: <editor> K. Goldberg et al. (eds.), A K Peters, </editor> <address> Wellesley, MA. </address>
Reference: <author> Hutchinson, S., G. D. Hager, and P. </author> <title> Corke (1996). A tutorial on visual servo control. </title> <journal> IEEE Tr. on Robotics and Automation 12 (5), </journal> <pages> 313-326. </pages>
Reference-contexts: In our case, AO mobility makes it possible to significantly reduce this number. Target tracking has an obvious connection to visual tracking of a moving object in an image sequence <ref> (Hutchinson et al. 1996) </ref>. But, while the goal of the latter problem is to track the object as long as it is visible in the images, AOs must move to avoid potential visual obstruction by obstacles and keep the target in their field of view.
Reference: <author> Kakusho, K., T. Kitahashi, K. Kondo, and J. </author> <title> Latombe (1995). Continuous purposive sensing and motion for 2d map building. </title> <booktitle> In Proc. IEEE Int. Conf. of Syst., Man and Cyb., </booktitle> <pages> 1472-1477. </pages>
Reference-contexts: One reason is inherent to the next-best-view problem itself: it is a local planning problem <ref> (Kakusho et al. 1995) </ref>, so that a sequence of next-best views to build a complete model may yield too many sensing operations. In our case, each sensing operation is rather expensive: it requires acquiring 3-D and texture data, and merging this data with the current model.
Reference: <author> LaValle, S. M., H. H. Gonzalez-B~anos, C. Becker, and J. C. </author> <title> Latombe (1997). Motion strategies for maintaining visibility of a moving target. </title> <booktitle> In Proc. IEEE Int. Conf. on Rob. and Automation. </booktitle>
Reference-contexts: The faster the planner and the more efficient the motion strategies, the better. This led us to develop two planning algorithms, depending on target predictability: (1) For fully predictable targets, we have developed an off-line planner that computes an optimal solution for a given criterion <ref> (LaValle et al. 1997) </ref>. Fig. 8 shows two examples computed by this plan (a) (b) ner. The target is displayed as a black disc and the AO as a white disc.
Reference: <author> Maver, J. and R. </author> <title> Bajcsy (1993). Occlusions as a guide for planning the next view. </title> <journal> IEEE Tr. on Pattern Analysis and Machine Intelligence 15 (5), </journal> <pages> 417-433. </pages>
Reference-contexts: Planning AO motions also relates to sensor placement (Briggs and Donald 1997) and active sensing <ref> (Maver and Bajcsy 1993) </ref>. In this paper we present our ongoing research on three specific planning problems related to the design of a team of AOs: i) model building, ii) target finding, and iii) target tracking.
Reference: <author> O'Rourke, J. </author> <year> (1997). </year> <title> Visibility. </title> <booktitle> In Handbook of Discrete and Computational Geometry, </booktitle> <pages> 467-479. </pages>
Reference: <editor> J.E. Goodman and J. O'Rourke (eds.), </editor> <publisher> CRC Press, </publisher> <address> Boca Raton, FL. </address>
Reference: <author> Parsons, T. D. </author> <year> (1976). </year> <title> Pursuit-evasion in a graph. </title> <booktitle> In Theory and Application of Graphs, </booktitle> <pages> 426-441. </pages>
Reference-contexts: This strategy must be such that, as the AOs move, their visibility region (i.e., the region that they collectively see) deforms and sweeps F so that the target has eventually no remaining place where to hide. Non-geometric pursuit-evasion problems have been studied in graphs (e.g., <ref> (Parsons 1976) </ref>). A problem similar to ours is analyzed in (Crass et al. 1995).
Reference: <editor> Y. Alavi and D. Lick (eds.), </editor> <booktitle> Lecture Notes in Mathematics 642, </booktitle> <publisher> Springer Verlag, </publisher> <address> Berlin. </address>
Reference: <author> Pito, R. </author> <year> (1995). </year> <title> A solution to the next best view problem for automated CAD model acquisition of free-form objects using range cameras. </title> <type> Technical Report 95-23, </type> <institution> GRASP Lab., U. of Penn-sylvania. </institution>
Reference: <author> Talluri, R. and J. K. </author> <title> Aggarwal (1996). Mobile robot self-localization using model-image feature correspondence. </title> <journal> IEEE Tr. on Robotics and Automation 12 (1), </journal> <pages> 63-77. </pages>
References-found: 17

