URL: ftp://www-flash.stanford.edu/pub/flash/ISCA90.ps.Z
Refering-URL: http://www.cs.umd.edu/users/keleher/syllabus.818.html
Root-URL: 
Title: Memory Consistency and Event Ordering in Scalable Shared-Memory Multiprocessors  
Author: Kourosh Gharachorloo, Daniel Lenoski, James Laudon, Phillip Gibbons, Anoop Gupta, and John Hennessy 
Address: CA 94305  
Affiliation: Computer Systems Laboratory Stanford University,  
Abstract: Scalable shared-memory multiprocessors distribute memory among the processors and use scalable interconnection networks to provide high bandwidth and low latency communication. In addition, memory accesses are cached, buffered, and pipelined to bridge the gap between the slow shared memory and the fast processors. Unless carefully controlled, such architectural optimizations can cause memory accesses to be executed in an order different from what the programmer expects. The set of allowable memory access orderings forms the memory consistency model or event ordering model for an architecture. This paper introduces a new model of memory consistency, called release consistency, that allows for more buffering and pipelining than previously proposed models. A framework for classifying shared accesses and reasoning about event ordering is developed. The release consistency model is shown to be equivalent to the sequential consistency model for parallel programs with sufficient synchronization. Possible performance gains from the less strict constraints of the release consistency model are explored. Finally, practical implementation issues are discussed, concentrating on issues relevant to scalable architectures. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Sarita Adve and Mark Hill. </author> <type> Personal communication. </type> <month> March </month> <year> 1990. </year>
Reference: [2] <author> Forest Baskett, Tom Jermoluk, and Doug Solomon. </author> <title> The 4D-MP graphics superworkstation: Computing + graphics = 40 MIPS + 40 MFLOPS and 100,000 lighted polygons per second. </title> <booktitle> In Proceedings of the 33rd IEEE Computer Society International Conference - COMPCON 88, </booktitle> <pages> pages 468-471, </pages> <month> February </month> <year> 1988. </year>
Reference-contexts: The architecture consists of several processing nodes connected through a low-latency scalable interconnection network. Physical memory is distributed among the nodes. Each processing node, or cluster, is a Silicon Graphics POWER Station 4D/240 <ref> [2] </ref> consisting of four high-performance processors with their individual caches and a portion of the shared memory. A bus-based snoopy scheme keeps caches coherent within a cluster while inter-cluster coherence is maintained using a distributed directory-based protocol.
Reference: [3] <author> W. C. Brantley, K. P. McAuliffe, and J. Weiss. </author> <title> RP3 processor-memory element. </title> <booktitle> In Proceedings of the 1985 International Conference on Parallel Processing, </booktitle> <pages> pages 782-789, </pages> <year> 1985. </year>
Reference-contexts: We refer to the mechanism for delaying the issue of accesses as a fence <ref> [3, 5, 13] </ref>. We define a general set of fence operations and demonstrate how these fence operations can be used to implement the consistency models presented earlier.
Reference: [4] <author> Michel Dubois, Christoph Scheurich, and Faye Briggs. </author> <title> Memory access buffering in multiprocessors. </title> <booktitle> Page 11 In Proceedings of the 13th Annual International Sym--posium on Computer Architecture, </booktitle> <pages> pages 434-442, </pages> <month> June </month> <year> 1986. </year>
Reference-contexts: More generally, the consistency model specifies what event orderings are legal when several processes are accessing a common set of locations. Several memory consistency models have been proposed in the literature: examples include sequential consistency [7], processor consistency [5], and weak consistency <ref> [4] </ref>. The sequential consistency model [7] requires the execution of a parallel program to appear as some interleaving of the execution of the parallel processes on a sequential machine. <p> A system architect must balance the design by providing a memory consistency model that allows for high performance implementations and is acceptable to the program 1 mer. In this paper, we present a new consistency model called release consistency, which extends the weak consistency model <ref> [4] </ref> by utilizing additional information about shared accesses. Section 2 presents a brief overview of previously proposed consistency models. The motivation and framework for release consistency is presented in Section 3. Section 4 considers equivalences among the several models given proper information about shared accesses. <p> Readers familiar with the first three models and the event ordering terminology may wish to skip to Section 3. To facilitate the description of different event orderings, we present formal definitions for the stages that a memory request goes through. The following two definitions are from Dubois et al. <ref> [4, 10] </ref>. In the following, P i refers to processor i. <p> This scheme has the advantage of providing the user with a reasonable programming model, while permitting multiple memory accesses to be pipelined. The disadvantage is that all synchronization accesses must be identified by the programmer or compiler. The weak consistency model proposed by Dubois et al. <ref> [4] </ref> is based on the above idea. They distinguish between ordinary shared accesses and synchronization accesses, where the latter are used to control concurrency between several processes and to maintain the integrity of ordinary shared data. <p> They distinguish between ordinary shared accesses and synchronization accesses, where the latter are used to control concurrency between several processes and to maintain the integrity of ordinary shared data. The conditions to ensure weak consistency are given below (slightly different from the conditions given in <ref> [4] </ref>).
Reference: [5] <author> James R. Goodman. </author> <title> Cache consistency and sequential consistency. </title> <type> Technical Report no. 61, </type> <institution> SCI Committee, </institution> <month> March </month> <year> 1989. </year>
Reference-contexts: More generally, the consistency model specifies what event orderings are legal when several processes are accessing a common set of locations. Several memory consistency models have been proposed in the literature: examples include sequential consistency [7], processor consistency <ref> [5] </ref>, and weak consistency [4]. The sequential consistency model [7] requires the execution of a parallel program to appear as some interleaving of the execution of the parallel processes on a sequential machine. <p> (B) before a store is allowed to perform with respect to any other processor, all previous load accesses must be globally performed and all previous store accesses must be performed. 2.2 Processor Consistency To relax some of the orderings imposed by sequential consistency, Goodman introduces the concept of processor consistency <ref> [5] </ref>. Processor consistency requires that writes issued from a processor may not be observed in any order other than that in which they were issued. However, the order in which writes from two processors occur, as observed by themselves or a third processor, need not be identical. <p> Specifically, he relies on programmers to use explicit synchronization rather than depending on the memory system to guarantee strict event ordering. Good-man also points out that many existing multiprocessors (e.g., VAX 8800) satisfy processor consistency, but do not satisfy sequential consistency. The description given in <ref> [5] </ref> does not specify the ordering of read accesses completely. We have defined the following conditions for processor consistency. <p> We refer to the mechanism for delaying the issue of accesses as a fence <ref> [3, 5, 13] </ref>. We define a general set of fence operations and demonstrate how these fence operations can be used to implement the consistency models presented earlier.
Reference: [6] <author> Anoop Gupta, Milind Tambe, Dirk Kalp, Charles Forgy, and Allen Newell. </author> <title> Parallel implementation of OPS5 on the Encore multiprocessor: Results and analysis. </title> <journal> International Journal of Parallel Programming, </journal> <volume> 17(2) </volume> <pages> 95-124, </pages> <year> 1988. </year>
Reference-contexts: Finally, the lock is released. The processor then moves on to do the same sequence of operations on another bucket. Such operations are common in several applications (for example, token hash tables in OPS5 <ref> [6] </ref>). The locality of data in such an application is low since the hash table can be large and several other processors may have modified an entry from the last time it was accessed. Therefore, the read and write accesses will miss often.
Reference: [7] <author> Leslie Lamport. </author> <title> How to make a multiprocessor computer that correctly executes multiprocess programs. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-28(9):241-248, </volume> <month> September </month> <year> 1979. </year>
Reference-contexts: More generally, the consistency model specifies what event orderings are legal when several processes are accessing a common set of locations. Several memory consistency models have been proposed in the literature: examples include sequential consistency <ref> [7] </ref>, processor consistency [5], and weak consistency [4]. The sequential consistency model [7] requires the execution of a parallel program to appear as some interleaving of the execution of the parallel processes on a sequential machine. <p> More generally, the consistency model specifies what event orderings are legal when several processes are accessing a common set of locations. Several memory consistency models have been proposed in the literature: examples include sequential consistency <ref> [7] </ref>, processor consistency [5], and weak consistency [4]. The sequential consistency model [7] requires the execution of a parallel program to appear as some interleaving of the execution of the parallel processes on a sequential machine. <p> In presenting the event ordering conditions to satisfy each model, we assume that the implementation avoids deadlock by ensuring that accesses that occur previously in program order eventually get performed (globally performed). 2.1 Sequential Consistency Lamport <ref> [7] </ref> defines sequential consistency as follows.
Reference: [8] <author> Dan Lenoski, James Laudon, Kourosh Gharachorloo, Anoop Gupta, and John Hennessy. </author> <title> The directory-based cache coherence protocol for the DASH multiprocessor. </title> <booktitle> In Proceedings of the 17th Annual International Symposium on Computer Architecture, </booktitle> <month> May </month> <year> 1990. </year>
Reference-contexts: Architectural optimizations that reduce memory latency are especially important for scalable multiprocessor architectures. As a result of the distributed memory and general interconnection networks used by such multiprocessors <ref> [8, 9, 12] </ref>, requests issued by a processor to distinct memory modules may execute out of order. Caching of data further complicates the ordering of accesses by introducing multiple copies of the same location. <p> The problem is split between ordering accesses to the same memory block and those to different memory blocks. General solutions to achieve the proper ordering are given along with the particular solutions employed in the DASH prototype system <ref> [8] </ref>. <p> Consequently, a load may return a value from a processor's cache, with no indication of whether the responsible store has performed with respect to all processors. For this reason, PC-based models are an attractive alternative for update-based coherence schemes. 6.3 The DASH Prototype The DASH multiprocessor <ref> [8] </ref>, currently being built at Stanford, implements many of the features discussed in the previous sections. The architecture consists of several processing nodes connected through a low-latency scalable interconnection network. Physical memory is distributed among the nodes. <p> Of particular interest to this paper are the protocol and hardware features that are aimed at implementing the release consistency model. Further details on the protocol are given in <ref> [8] </ref>. The processor boards of the 4D/240 are designed to work only with the simple snoopy protocol of the bus. The base, single-bus system implements a processor consistency model. The single bus guarantees that operations cannot be observed out of order, and no acknowledgements are necessary.
Reference: [9] <author> G. F. Pfister, W. C. Brantley, D. A. George, S. L. Har-vey, W. J. Kleinfelder, K. P. McAuliffe, E. A. Melton, V. A. Norton, and J. Weiss. </author> <title> The IBM research parallel processor prototype (RP3): Introduction and architecture. </title> <booktitle> In Proceedings of the 1985 International Conference on Parallel Processing, </booktitle> <pages> pages 764-771, </pages> <year> 1985. </year>
Reference-contexts: Architectural optimizations that reduce memory latency are especially important for scalable multiprocessor architectures. As a result of the distributed memory and general interconnection networks used by such multiprocessors <ref> [8, 9, 12] </ref>, requests issued by a processor to distinct memory modules may execute out of order. Caching of data further complicates the ordering of accesses by introducing multiple copies of the same location.
Reference: [10] <author> C. Scheurich and M. Dubois. </author> <title> Correct memory operation of cache-based multiprocessors. </title> <booktitle> In Proceedings of the 14th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 234-243, </pages> <month> June </month> <year> 1987. </year>
Reference-contexts: Readers familiar with the first three models and the event ordering terminology may wish to skip to Section 3. To facilitate the description of different event orderings, we present formal definitions for the stages that a memory request goes through. The following two definitions are from Dubois et al. <ref> [4, 10] </ref>. In the following, P i refers to processor i. <p> Scheurich and Dubois <ref> [10, 11] </ref> have described event order restrictions that guarantee sequential consistency. Condition 2.1 presents sufficient conditions for providing sequential consistency (these differ slightly from conditions given in [10]). <p> Scheurich and Dubois [10, 11] have described event order restrictions that guarantee sequential consistency. Condition 2.1 presents sufficient conditions for providing sequential consistency (these differ slightly from conditions given in <ref> [10] </ref>).
Reference: [11] <author> Christoph Scheurich. </author> <title> Access Ordering and Coherence in Shared Memory Multiprocessors. </title> <type> PhD thesis, </type> <institution> University of Southern California, </institution> <month> May </month> <year> 1989. </year>
Reference-contexts: Scheurich and Dubois <ref> [10, 11] </ref> have described event order restrictions that guarantee sequential consistency. Condition 2.1 presents sufficient conditions for providing sequential consistency (these differ slightly from conditions given in [10]).
Reference: [12] <author> G. E. Schmidt. </author> <title> The Butterfly parallel processor. </title> <booktitle> In Proceedings of the Second International Conference on Supercomputing, </booktitle> <pages> pages 362-365, </pages> <year> 1987. </year>
Reference-contexts: Architectural optimizations that reduce memory latency are especially important for scalable multiprocessor architectures. As a result of the distributed memory and general interconnection networks used by such multiprocessors <ref> [8, 9, 12] </ref>, requests issued by a processor to distinct memory modules may execute out of order. Caching of data further complicates the ordering of accesses by introducing multiple copies of the same location.
Reference: [13] <author> Dennis Shasha and Marc Snir. </author> <title> Efficient and correct execution of parallel programs that share memory. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 10(2) </volume> <pages> 282-312, </pages> <month> April </month> <year> 1988. </year>
Reference-contexts: Finally, Section 3.3 presents the release consistency model and discusses how it exploits the extra information about accesses. 3.1 Categorization of Shared Memory Ac cesses We first describe the notions of conflicting accesses (as presented in <ref> [13] </ref>) and competing accesses. Two accesses are conflicting if they are to the same memory location and at least one of the accesses is a store. 1 Consider a pair of conflicting accesses a 1 and a 2 on different processors. <p> Given such programs, we have proved the following equivalences: SC = W Csc = RCsc. This is done by proving RCsc SC for PL programs and using the relation SC W Csc RCsc. Our proof technique is based on an extension of the formalism presented by Shasha and Snir <ref> [13] </ref>. We have included the proof for RCsc SC in the appendix. A similar proof can be used to show P C = W Cpc = RCpc for PL programs under the processor consistency model. <p> We refer to the mechanism for delaying the issue of accesses as a fence <ref> [3, 5, 13] </ref>. We define a general set of fence operations and demonstrate how these fence operations can be used to implement the consistency models presented earlier.
References-found: 13

