URL: http://csg-www.lcs.mit.edu:8001/Users/vivek/ps/Sark89.ps
Refering-URL: http://csg-www.lcs.mit.edu:8001/Users/vivek/sark_pub.html
Root-URL: 
Title: Determining Average Program Execution Times and their Variance  
Author: Vivek Sarkar T. J. P. O. 
Address: Box 704, Yorktown Heights, NY 10598  
Affiliation: IBM Research  Watson Research Center  
Abstract: This paper presents a general framework for determining average program execution times and their variance, based on the program's interval structure and control dependence graph. Average execution times and variance values are computed using frequency information from an optimized counter-based execution profile of the program.
Abstract-found: 1
Intro-found: 1
Reference: [ABC + 87] <author> Frances Allen, Michael Burke, Philippe Charles, Ron Cytron, and Jeanne Ferrante. </author> <title> An Overview of the PTRAN Analysis System for Multiprocessing. </title> <booktitle> Proceedings of the ACM 1987 International Conference on Supercomputing, </booktitle> <year> 1987. </year> <note> Also published in The Journal of Parallel and Distributed Computing, </note> <month> Oct., </month> <year> 1988, </year> <pages> 5(5) pages 617-640. </pages>
Reference-contexts: This framework for estimating execution times has been implemented as part of the PTRAN (Parallel Translation) project at IBM Research <ref> [ABC + 87] </ref>. The PTRAN system contains a program database which can be conveniently used to store the frequency, execution time and variance information. <p> Currently, the primary use of execution time information in PTRAN is in automatically partitioning the input program into tasks for parallel execution. 2 Program Representation This section describes the program representations used for estimating execution times. These representations are used in PTRAN <ref> [ABC + 87] </ref>, and the approach described here is based on the PTRAN implementation. The initial representation is assumed to be the traditional control flow graph [ASU86]. The nodes of the control flow graph may represent arbitrary units of computation | basic blocks, statements, operations or instructions.
Reference: [ASU86] <author> A.V. Aho, R. Sethi, and J.D. Ullman. </author> <title> Com pilers: Principles, Techniques, and Tools. </title> <publisher> Addison-Wesley, </publisher> <year> 1986. </year>
Reference-contexts: In this paper, we present a general framework for estimating average execution times in a program. This approach is based on the interval structure <ref> [ASU86] </ref> and the control dependence relation [FOW87], both of which can be derived from an arbitrary reducible control flow graph. Therefore, this framework supports general, unstructured programs, rather than the special case of structured programs that was addressed earlier when dealing with Sisal. <p> These representations are used in PTRAN [ABC + 87], and the approach described here is based on the PTRAN implementation. The initial representation is assumed to be the traditional control flow graph <ref> [ASU86] </ref>. The nodes of the control flow graph may represent arbitrary units of computation | basic blocks, statements, operations or instructions. The only requirement is that the control flow graph should contain all control flow relations of interest. <p> The only requirement is that the control flow graph should contain all control flow relations of interest. As in other code analysis and optimization techniques, we assume that the control flow graph is reducible. Node splitting <ref> [ASU86] </ref> is a standard approach that can be used to transform an irreducible control flow graph into a reducible control flow graph.
Reference: [Bur87] <author> Michael Burke. </author> <title> An Interval-Based Approach to Exhaustive and Incremental Interproce-dural Data Flow Analysis. </title> <type> Technical report, </type> <institution> IBM Research, </institution> <month> August </month> <year> 1987. </year> <note> Report RC12702. </note>
Reference-contexts: A reducible control flow graph has a unique depth-first spanning tree and hence a unique interval structure which can be easily computed from the control flow graph <ref> [Bur87, SS79] </ref>. The intervals identify the loops in the program. The other program representation we use is the forward control dependence graph [Hsi88, CHH89] based on the control dependence relation defined in [FOW87]. <p> The label U is used to identify an unconditional branch from a node. All nodes in the original control flow graph have type = OT HER. We first determine the interval structure of CF G <ref> [Bur87, SS79] </ref>. The intervals are summarized in a mapping called HDR, where HDR (n) = h indicates that node h is the header of the interval containing node n.
Reference: [CF87] <author> Ron Cytron and Jeanne Ferrante. </author> <title> An Improved Control Dependence Algorithm. </title> <type> Technical report, </type> <institution> IBM, </institution> <year> 1987. </year> <type> Tech. Report RC 13291. </type>
Reference-contexts: Based on this definition, we can build a control dependence graph, CDG, containing exactly the edges of the form (x; y; l) that satisfy the above conditions <ref> [FOW87, CF87, CFR + 89] </ref>. However, we will find it more convenient to use an acyclic form of the control dependence graph obtained by ignoring all back edges in CDG.
Reference: [CFR + 89] <author> Ron Cytron, Jeanne Ferrante, Barry K. Rosen, Mark N. Wegman, and F. Kenneth Zadeck. </author> <title> An Efficient Method for Computing Static Single Assignment Form. </title> <booktitle> Sixteenth Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 25-35, </pages> <month> Jan-uary </month> <year> 1989. </year>
Reference-contexts: Based on this definition, we can build a control dependence graph, CDG, containing exactly the edges of the form (x; y; l) that satisfy the above conditions <ref> [FOW87, CF87, CFR + 89] </ref>. However, we will find it more convenient to use an acyclic form of the control dependence graph obtained by ignoring all back edges in CDG.
Reference: [CHH89] <author> Ron Cytron, Michael Hind, and Wilson Hsieh. </author> <title> Automatic Generation of DAG Parallelism. </title> <booktitle> Proceedings of the ACM SIGPLAN '89 Conference on Programming Language Design and Implementation, Portland, Ore-gon, </booktitle> <volume> 24(7) </volume> <pages> 54-68, </pages> <month> June </month> <year> 1989. </year>
Reference-contexts: A reducible control flow graph has a unique depth-first spanning tree and hence a unique interval structure which can be easily computed from the control flow graph [Bur87, SS79]. The intervals identify the loops in the program. The other program representation we use is the forward control dependence graph <ref> [Hsi88, CHH89] </ref> based on the control dependence relation defined in [FOW87]. <p> However, we will find it more convenient to use an acyclic form of the control dependence graph obtained by ignoring all back edges in CDG. This is the forward control dependence graph <ref> [Hsi88, CHH89] </ref>. graph, F CDG, corresponding to the extended control flow graph, ECF G, shown in Figure 2. The tuples enclosed in &lt; ::: &gt; and [:::] brackets provide frequency and execution time values, which are discussed later.
Reference: [CHR78] <author> W. P. Crowley, C. P. Hendrickson, and T. E. Rudy. </author> <title> The SIMPLE code. </title> <type> Technical re port, </type> <institution> Lawrence Livermore Laboratory, </institution> <year> 1978. </year> <note> UCID 17715. </note>
Reference-contexts: The benchmark programs used are: * LOOPS | a program that executes all 24 Liver more Loops [McM86]. * SIMPLE | a benchmark for computational fluid dynamics and heat flow <ref> [CHR78] </ref>. The problem size used was 100 fi 100, with N CY CLES = 10.
Reference: [CK74] <author> John Cocke and Ken Kennedy. </author> <title> Profitability Computations on Program Flow Graphs. </title> <type> Technical report, </type> <institution> IBM, </institution> <year> 1974. </year> <type> Tech. Report RC 5123. </type>
Reference-contexts: An early study of execution frequencies in Fortran program was reported in [Knu71], which discusses both the sampling-based and counter-based approaches to execution profiling. <ref> [CK74] </ref> presented an approach for determining average execution frequencies from transition probabilities in a control flow graph.
Reference: [FERN84] <author> J. A. Fisher, J. R. Ellis, J. C. Ruttenberg, and A. Nicolau. </author> <title> Parallel Processing: A Smart Compiler and a Dumb Machine. </title> <booktitle> Proceedings of the ACM Symposium on Compiler Construction, </booktitle> <pages> pages 37 - 47, </pages> <month> June </month> <year> 1984. </year>
Reference-contexts: We use frequency information to estimate average execution times and variances, but this approach to execution profiling based on control dependence and counter variables would be useful for any code optimization that needs frequency information e.g. register allocation [Wal86], trace scheduling <ref> [FERN84] </ref>, optimization of delayed branches [MH86]. This framework for estimating execution times has been implemented as part of the PTRAN (Parallel Translation) project at IBM Research [ABC + 87]. The PTRAN system contains a program database which can be conveniently used to store the frequency, execution time and variance information. <p> It is only recently that automatic program optimizations have been proposed that use frequency information e.g. trace scheduling <ref> [FERN84] </ref>, register allocation [Wal86], optimization of delayed branches [MH86], partitioning and scheduling of parallel programs [SH86a, SH86b]. Given its growing importance, execution profile information ought to become an indispensable component of future programming systems, and the availability of the frequency information will no doubt motivate its use in new optimizations.
Reference: [FOW87] <author> J. Ferrante, K. Ottenstein, and J. Warren. </author> <title> The Program Dependence Graph and its Use in Optimization. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 9(3) </volume> <pages> 319-349, </pages> <month> July </month> <year> 1987. </year>
Reference-contexts: In this paper, we present a general framework for estimating average execution times in a program. This approach is based on the interval structure [ASU86] and the control dependence relation <ref> [FOW87] </ref>, both of which can be derived from an arbitrary reducible control flow graph. Therefore, this framework supports general, unstructured programs, rather than the special case of structured programs that was addressed earlier when dealing with Sisal. <p> The intervals identify the loops in the program. The other program representation we use is the forward control dependence graph [Hsi88, CHH89] based on the control dependence relation defined in <ref> [FOW87] </ref>. <p> Similarly, if there is more than one "last" node (e.g. due to RETURN statements), then step 5 should be modified to insert an edge from each such node to ST OP . We now turn to the notion of control dependence as defined in <ref> [FOW87] </ref>: Definition 2 Let x and y be nodes in a control flow graph. y is control dependent on x with label l if and only if 1. y does not post-dominate x 2. there exists a directed path P from x to y with all intermediate nodes post-dominated by y <p> Based on this definition, we can build a control dependence graph, CDG, containing exactly the edges of the form (x; y; l) that satisfy the above conditions <ref> [FOW87, CF87, CFR + 89] </ref>. However, we will find it more convenient to use an acyclic form of the control dependence graph obtained by ignoring all back edges in CDG.
Reference: [FS87] <institution> Philippe Flajolet and Jean-Marc Steyaert. </institution>
Reference-contexts: The approach works reasonably well for simple Lisp functions like REVERSE and UNION, but it appears that it would be too restrictive to be useful for larger programs. <ref> [FS87] </ref> and [HC88] discuss approaches for automatic average-case analysis of special classes of programs. The work in [FS87] is applicable to recursive descent procedures over recursively defined data structures that can be expressed in their language PL-tree e.g. tree matching, binary search. [HC88] describes approaches for simple probabilistic programs and a <p> The approach works reasonably well for simple Lisp functions like REVERSE and UNION, but it appears that it would be too restrictive to be useful for larger programs. <ref> [FS87] </ref> and [HC88] discuss approaches for automatic average-case analysis of special classes of programs. The work in [FS87] is applicable to recursive descent procedures over recursively defined data structures that can be expressed in their language PL-tree e.g. tree matching, binary search. [HC88] describes approaches for simple probabilistic programs and a simple functional programming language.
References-found: 11

