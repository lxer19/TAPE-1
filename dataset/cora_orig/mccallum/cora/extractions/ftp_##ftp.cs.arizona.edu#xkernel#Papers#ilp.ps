URL: ftp://ftp.cs.arizona.edu/xkernel/Papers/ilp.ps
Refering-URL: http://www.cs.arizona.edu/xkernel/bibliography.html
Root-URL: http://www.cs.arizona.edu
Title: Increasing Network Throughput by Integrating Protocol Layers  
Author: Mark B. Abbott and Larry L. Peterson 
Address: Tucson, AZ 85721  
Affiliation: Department of Computer Science The University of Arizona  
Abstract: Integrating protocol data manipulations is a strategy for increasing the throughput of network protocols. The idea is to combine a series of protocol layers into a pipeline so as to access message data more efficiently. This paper introduces a widely-applicable technique for integrating protocols. This technique not only improves performance, but also preserves the modularity of protocol layers by automatically integrating independently expressed protocols. The paper also describes a prototype integration tool, and studies the performance limits and scalability of protocol integration. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. B. Abbott. </author> <title> A Language-Based Approach to Protocol Implementation. </title> <type> PhD thesis, </type> <institution> University of Arizona, </institution> <month> August </month> <year> 1993. </year> <note> In preparation. </note>
Reference-contexts: A compiler could attribute a syntax or runtime 25 error to the particular offending protocol. The protocol implementation language Morpheus proposed in [2] is an ideal candidate because it is exclusively for protocol implementation. The design of Morpheus is extended to incorporate protocol integration in <ref> [1] </ref>. 8 Barriers to Integration There are situations where integration is prevented either by the functionality of a protocol or by the mapping of protocols onto address spaces. We have identified the following barriers to integration: Control Transfer. <p> The lazy messages technique is discussed in more detail in <ref> [1] </ref>. The Packet Filter [11] technique 26 addresses a related problem, that of anticipating the application to which a message will ultimately be demultiplexed.
Reference: [2] <author> M. B. Abbott and L. L. Peterson. </author> <title> A language-based approach to protocol implementation. </title> <journal> IEEE/ACM Transactions on Networking, </journal> <volume> 1(1), </volume> <month> Feb. </month> <year> 1993. </year> <note> To appear. </note>
Reference-contexts: A compiler could attribute a syntax or runtime 25 error to the particular offending protocol. The protocol implementation language Morpheus proposed in <ref> [2] </ref> is an ideal candidate because it is exclusively for protocol implementation.
Reference: [3] <author> D. D. Clark, V. Jacobson, J. Romkey, and H. Salwen. </author> <title> An analysis of TCP processing overhead. </title> <journal> IEEE Communications Magazine, </journal> <volume> 27(6) </volume> <pages> 23-29, </pages> <month> June </month> <year> 1989. </year>
Reference-contexts: 1 Introduction Data manipulatione.g., encryption, presentation formatting, compression, computing checksumsis one of the costliest aspects of data transfer <ref> [3, 4, 6] </ref>. This is because reading, and possibly writing, each byte of data in a message involves memory loads or stores, which are relatively slow operations on modern RISC architectures. Clark and Tennenhouse [4] suggest a strategy, called Integrated Layer Processing (ILP), for addressing this problem. <p> code generated by a compiler is generally not as efficient as the code that could be directly programmed in assembler language, but the small performance loss is more than offset by the advantages of high-level languages. 2.1 Related Work In several working TCP/IP implementations, checksumming and copying have been integrated <ref> [3] </ref>. This is a degenerate case of ILP in that the two data manipulations belong to the same protocol. Hence the problems of reconciling different views of messages, satisfying ordering constraints, and preserving modularity do not arise.
Reference: [4] <author> D. D. Clark and D. L. Tennenhouse. </author> <title> Architectural considerations for a new generation of protocols. </title> <booktitle> In Proceedings of the SIGCOMM '90 Symposium, </booktitle> <pages> pages 200-208, </pages> <month> Sept. </month> <year> 1990. </year> <month> 27 </month>
Reference-contexts: 1 Introduction Data manipulatione.g., encryption, presentation formatting, compression, computing checksumsis one of the costliest aspects of data transfer <ref> [3, 4, 6] </ref>. This is because reading, and possibly writing, each byte of data in a message involves memory loads or stores, which are relatively slow operations on modern RISC architectures. Clark and Tennenhouse [4] suggest a strategy, called Integrated Layer Processing (ILP), for addressing this problem. <p> This is because reading, and possibly writing, each byte of data in a message involves memory loads or stores, which are relatively slow operations on modern RISC architectures. Clark and Tennenhouse <ref> [4] </ref> suggest a strategy, called Integrated Layer Processing (ILP), for addressing this problem. In this paper, we refer to ILP as protocol integration, or simply integration. The aim of integration is to improve throughput by reducing the number of loads and stores of message data performed by protocols. <p> This is possible because the data word remains in a register between the two data manipulations. Hence, integrating the for-loops results in the elimination of one load and one store per word of data. Clark and Tennenhouse <ref> [4] </ref> quantify the potential advantage of this technique by fusing some simple data manipulation loops. They report a 48% improvement in throughput when combining checksum and copy, and a 7% improvement when combining ASN.1 integer conversion and checksum. <p> Our technique meets the second, arbitrary functionality standard. In doing so, it establishes guidelines forimposes constraints onprotocol specifications. Note that this is consistent with the original meaning of ILP <ref> [4] </ref>: ILP also refers to the design principle that protocol specifications should not preclude the application of the ILP implementation strategy. When viewed from the perspective of the first, arbitrary specification standard, these constraints become limitations of our technique, that is, they they exclude some protocol definitions. <p> First, while the preceding examples suggest important techniques, their generality is limited because the techniques are tailored to the particular situations. Second, the performance comparisons in the Gunningberg et al. paper, as well as those reported in <ref> [4] </ref>, assume that no message data remains cached between data manipulations in the strictly layered case. In 2 Unlike DES, ost data manipulations have a low processing-to-memory ratio. <p> One strategy is to relegate fragmentation/reassembly to the bottom of the protocol graph. Gunningberg et al. [8] conclude that for multimedia applications and gigabit networks we will see fragmentation only at the lowest layers or not at all, and Clark and Tennenhouse's Application Level Framing <ref> [4] </ref> also places fragmentation/reassembly at the bottom of the protocol graph. Random Access. The sequential data access provided by integration is inadequate for protocols that need random access. An example of such a protocol is the image transfer protocol described in [13].
Reference: [5] <author> K. D. Cooper, M. W. Hall, and L. Torczon. </author> <title> An experiment with inline substitution. </title> <journal> SoftwarePractice and Experience, </journal> <volume> 21(6) </volume> <pages> 581-601, </pages> <month> June 91. </month>
Reference-contexts: We have not observed any degradation attributable to inlining in our experiments integrating up to 15 (simple) layers. In general, inlining seems to have little effect on caching and virtual memory. Experiments reported in <ref> [5] </ref> showed no obvious evidence of either instruction cache overflow or thrashing, and the previous reports they cited showed similar results. 5 Reconciling Different Views of Data The preceding sections addressed the problem of integrating arbitrary data manipulations outside the context of protocols.
Reference: [6] <author> P. Druschel, M. B. Abbott, M. A. Pagels, and L. L. Peterson. </author> <title> Analysis of I/O subsystem design in multimedia workstations. </title> <booktitle> In Third International Workshop on Network and Operating System Support for Digital Audio and Visual, </booktitle> <pages> pages 251-263, </pages> <address> San Diego, Calif., </address> <month> Nov. </month> <year> 1992. </year>
Reference-contexts: 1 Introduction Data manipulatione.g., encryption, presentation formatting, compression, computing checksumsis one of the costliest aspects of data transfer <ref> [3, 4, 6] </ref>. This is because reading, and possibly writing, each byte of data in a message involves memory loads or stores, which are relatively slow operations on modern RISC architectures. Clark and Tennenhouse [4] suggest a strategy, called Integrated Layer Processing (ILP), for addressing this problem. <p> Furthermore, the discrepancy between processor and memory performance is expected to get worse. Caches offer only a partial solution to this problem. While caches are very effective in reducing memory accesses for many computations, the characteristics of strictly layered message processing are such that caching is not as effective <ref> [6, 7] </ref>. Furthermore, there is still a cost for accessing the cachetypically 1 to 4 clock cycles [9]. This cost must be paid by every data manipulation protocol, for every word of data. In addition, there are delay slots following each read access which may not all be fillable.
Reference: [7] <author> P. Druschel, M. B. Abbott, M. A. Pagels, and L. L. Peterson. </author> <title> Network subsystem design: A case for an integrated data path. </title> <journal> IEEE Network Magazine, </journal> <month> July </month> <year> 1993. </year> <note> To appear. </note>
Reference-contexts: Furthermore, the discrepancy between processor and memory performance is expected to get worse. Caches offer only a partial solution to this problem. While caches are very effective in reducing memory accesses for many computations, the characteristics of strictly layered message processing are such that caching is not as effective <ref> [6, 7] </ref>. Furthermore, there is still a cost for accessing the cachetypically 1 to 4 clock cycles [9]. This cost must be paid by every data manipulation protocol, for every word of data. In addition, there are delay slots following each read access which may not all be fillable.
Reference: [8] <author> P. Gunningberg, C. Partridge, T. Sirotkin, and B. Victor. </author> <title> Delayed evaluation of gigabit protocols. </title> <booktitle> In Proceedings of the 2nd MultiG Workshop, </booktitle> <year> 1991. </year>
Reference-contexts: Hence the problems of reconciling different views of messages, satisfying ordering constraints, and preserving modularity do not arise. Furthermore, the particular data manipulations involved are regular enough to allow them to be combined in a simple for-loop. Gunningberg, et al. <ref> [8] </ref> investigated integrating some more interesting data manipulations, and incorporated message header writing. The three data manipulations they considered were a simple presentation encoding, checksumming, and DES (Data Encryption Standard) encryption. <p> Even fragments that arrive unduplicated and in order do not generally have the higher level headers needed by higher protocols. One strategy is to relegate fragmentation/reassembly to the bottom of the protocol graph. Gunningberg et al. <ref> [8] </ref> conclude that for multimedia applications and gigabit networks we will see fragmentation only at the lowest layers or not at all, and Clark and Tennenhouse's Application Level Framing [4] also places fragmentation/reassembly at the bottom of the protocol graph. Random Access.
Reference: [9] <author> J. L. Hennessy and D. A. Patterson. </author> <title> Computer Architecture A Quantitative Approach. </title> <publisher> Morgan Kaufmann Publishers, Inc., </publisher> <address> San Mateo, CA, </address> <year> 1990. </year>
Reference-contexts: Finally, we identify some architectural considerations that would permit future protocols to be integrated more efficiently and more comprehensively. 1.1 Motivation for Integration The load and store operations required by data manipulations are expensive, typically ranging from 8 to 32 clock cycles per memory access in 1990 <ref> [9] </ref>, in contrast to other operations that complete in a single cycle on modern RISC architectures. Furthermore, the discrepancy between processor and memory performance is expected to get worse. Caches offer only a partial solution to this problem. <p> While caches are very effective in reducing memory accesses for many computations, the characteristics of strictly layered message processing are such that caching is not as effective [6, 7]. Furthermore, there is still a cost for accessing the cachetypically 1 to 4 clock cycles <ref> [9] </ref>. This cost must be paid by every data manipulation protocol, for every word of data. In addition, there are delay slots following each read access which may not all be fillable.
Reference: [10] <author> B. W. Kernighan and D. M. Ritchie. </author> <title> The m4 macro processor. In Unix Programmer's Supplementary Documents Volume 1. </title> <institution> University of California at Berkeley, </institution> <month> Apr. </month> <year> 1986. </year>
Reference-contexts: In our experiments, the compilers have done so successfully, utilizing registers as expected. Specifically, the prototype integrator is simply the macro processor m4 <ref> [10] </ref> applied to appropriate input and include files. A protocol's send or deliver operation is input as six code fragments. The CKSUM protocol is used as an example in Table 9.
Reference: [11] <author> J. C. Mogul, R. F. Rashid, and M. J. Accetta. </author> <title> The packet filter: An efficient mechanism for user-level network code. </title> <booktitle> In Proceedings of the Eleventh ACM Symposium on Operating System Principles, </booktitle> <pages> pages 39-51, </pages> <month> Nov. </month> <year> 1987. </year>
Reference-contexts: However, it is not generally compatible with existing network architectures. As an alternative, the software on a host could determine the application data boundary by some means specific to its particular protocol suite, perhaps by peeking ahead at particular header fields as is done in the Packet Filter <ref> [11] </ref>. This unilateral approach is consistent with any network architecture. 5.2 Integrating Applications It is desirable to integrate as many data manipulations as possible to derive the greatest throughput increase. <p> The lazy messages technique is discussed in more detail in [1]. The Packet Filter <ref> [11] </ref> technique 26 addresses a related problem, that of anticipating the application to which a message will ultimately be demultiplexed.
Reference: [12] <author> S. W. O'Malley and L. L. Peterson. </author> <title> A dynamic network architecture. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 10(2) </volume> <pages> 110-143, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: Thus, neither the sending nor receiving side of this protocol can efficiently manipulate data in a stream. Runtime Protocol Path. For some protocols, there is more than one possible next protocol. Examples include demultiplexing, the generalized routing exemplified in <ref> [12] </ref>, and message forwarding (since a message can either continue up the protocol graph if its destination is local, or be sent back down the protocol graph if it should be forwarded).
Reference: [13] <author> C. J. Turner and L. L. Peterson. </author> <title> Image transfer: An end-to-end design. </title> <booktitle> In Proceedings of the SIGCOMM '92 Symposium, </booktitle> <address> Baltimore, Maryland, </address> <month> Aug. </month> <year> 1992. </year> <month> 28 </month>
Reference-contexts: Random Access. The sequential data access provided by integration is inadequate for protocols that need random access. An example of such a protocol is the image transfer protocol described in <ref> [13] </ref>. This protocol's data manipulation reorders data so that pixels that are adjacent in the original data (an image) are spread far apart from each other as the data is transmitted over the network in packets.
References-found: 13

