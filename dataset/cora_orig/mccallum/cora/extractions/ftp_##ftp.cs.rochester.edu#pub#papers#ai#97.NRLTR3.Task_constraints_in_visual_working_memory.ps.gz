URL: ftp://ftp.cs.rochester.edu/pub/papers/ai/97.NRLTR3.Task_constraints_in_visual_working_memory.ps.gz
Refering-URL: http://www.cs.rochester.edu/trs/ai-trs.html
Root-URL: 
Title: Task Constraints in Visual Working Memory  
Author: Mary M. Hayhoe, David G. Bensinger, and Dana H. Ballard 
Address: Rochester, NY 14627, USA  
Affiliation: Center for Visual Science University of Rochester  
Abstract-found: 0
Intro-found: 0
Reference: [Albano and King, 1989] <author> Albano, J. and King, W. </author> <year> (1989). </year> <title> Rapid adaptation of saccadic amplitude in humans and monkeys. </title> <journal> Investigative Ophthalmology and Visual Science, </journal> <volume> 30 </volume> <pages> 883-893. </pages>
Reference-contexts: In this case changes of stimulus position during a saccade of as much as 40 per cent can go unnoticed by the subject <ref> [Albano and King, 1989] </ref>. The issue of the complexity of the visual representation is often confused with the issue of whether visual information is integrated across different eye positions.
Reference: [Bajcsy, 1985] <editor> Bajcsy, R. </editor> <year> (1985). </year> <title> Active perception vs. passive perception. </title> <booktitle> In Proc., Workshop on Computer Vision, </booktitle> <pages> pages 55-59. 35 </pages>
Reference: [Ballard, 1991] <author> Ballard, D. </author> <year> (1991). </year> <title> Animate vision: An evolutionary step in computational vision. </title> <journal> J. of the Inst. of Electronics, Information, and Communication Engineers, </journal> <volume> 74(4) </volume> <pages> 343-348. </pages>
Reference: [Ballard et al., 1992] <author> Ballard, D., Hayhoe, M., Li, F., and Whitehead, S. </author> <year> (1992). </year> <title> Eye hand coordination in a sequential task. </title> <journal> Proc. Royal Soc Lond B, </journal> <volume> 337 </volume> <pages> 331-339. </pages>
Reference-contexts: Thus subjects showed a very strong preference for using eye movements to acquire information from the display as needed, rather than using visual memory. (A variety of other aspects of performance have been investigated in our previous work, but are not relevant for the current investigation <ref> [Ballard et al., 1992, Ballard et al., 1995, Pelz, 1995] </ref>. The first experiment to probe the extent of the memory across different fixations examines the consequences of changing the color of blocks in the model area during saccades from the Workspace to the Model. <p> If subjects are obliged to use memory by removing the display, however, only 2 blocks can be copied without error <ref> [Ballard et al., 1992] </ref>. These observations suggest that the fixations are indeed diagnostic of information-gathering state.
Reference: [Ballard et al., 1995] <author> Ballard, D., Hayhoe, M., and Pelz, J. </author> <year> (1995). </year> <title> Memory representations in natural tasks. </title> <journal> J Cognitive Neuroscience, </journal> <volume> 7 </volume> <pages> 66-80. </pages>
Reference-contexts: By exploring the types of change that affect performance, we can identify the information that is retained. Experiment 1: Single Block Changes One of the observations we have previously made about performance of the block copying task is that subjects behave in a very stereotypical way <ref> [Ballard et al., 1995] </ref>. Since only one block can be moved at a time, we break down performance into a description of single block moves. These can be categorized into the sequences diagrammed in Figure 2a. <p> Thus subjects showed a very strong preference for using eye movements to acquire information from the display as needed, rather than using visual memory. (A variety of other aspects of performance have been investigated in our previous work, but are not relevant for the current investigation <ref> [Ballard et al., 1992, Ballard et al., 1995, Pelz, 1995] </ref>. The first experiment to probe the extent of the memory across different fixations examines the consequences of changing the color of blocks in the model area during saccades from the Workspace to the Model. <p> This is interesting since the peripheral location must be selected as the saccade target somehow, and it appears that this target selection process involves a different kind of information from that acquired during foveation. This is consistent with a special computational role for foveation <ref> [Ballard et al., 1995] </ref>. The increased effectivness of the display changes in the second experiment is also important. This increase is observed both before and after pickup, even though the additional blocks that were 30 changed were not the ones being worked on. <p> In previous work we have examined this question by manipulating various aspects of the task in ways that vary the need for fixations. The frequency of model fixations can be reduced by stimulus manipulations that allow visual chunking, for example, and by display configurations that require large head movements <ref> [Ballard et al., 1995, Pelz, 1995] </ref>. If subjects are obliged to use memory by removing the display, however, only 2 blocks can be copied without error [Ballard et al., 1992]. These observations suggest that the fixations are indeed diagnostic of information-gathering state. <p> These observations suggest that the fixations are indeed diagnostic of information-gathering state. In addition, the task dependency we observe in the present experiments, supports our earlier suggestion <ref> [Ballard et al., 1995] </ref> that the two fixations in the model area serve a different purpose: the first 31 fixation in the model area is to acquire color information, and that the second fixation is for relative location of the current block. <p> However, the result that the same display changes affect fixation durations depending on the observer's momentary place in the task suggests that human vision may create only those perceptual descriptions that are currently necessary, and that fixation plays a crucial role in this process <ref> [Ballard et al., 1995, Ballard et al., 1996] </ref>. The task dependency observed here provides a context for interpreting results of a range of experiments which use the technique of changing the visual stimulus during a saccade.
Reference: [Ballard et al., 1996] <author> Ballard, D., Hayhoe, M., Pook, P., and Rao, R. </author> <title> ((in press) 1996). Deictic codes for the embodiment of cognition. </title> <journal> Behavioral and Brain Sciences. </journal>
Reference-contexts: One possible mechanism for realizing this is described in [Rao and Ballard, 1996]. This work is also discussed in <ref> [Ballard et al., 1996] </ref>. One important issue in considering the copying task is the extent to which the fixations actually reflect the immediate visual representation. For example, the relative slowness of the hand movements might allow extra fixations that are not really necessary. <p> However, the result that the same display changes affect fixation durations depending on the observer's momentary place in the task suggests that human vision may create only those perceptual descriptions that are currently necessary, and that fixation plays a crucial role in this process <ref> [Ballard et al., 1995, Ballard et al., 1996] </ref>. The task dependency observed here provides a context for interpreting results of a range of experiments which use the technique of changing the visual stimulus during a saccade. <p> One way of understanding this difference is to distinguish between the two different levels of description relevant to task performance. Our everyday experience of the world may reflect events over a longer time scale than those revealed by individual fixations <ref> [Ballard et al., 1996] </ref>. Perceptual insensitivity to display changes makes sense if conscious experience corresponds to brain state at a time scale of the task, using task relevant variables such as 'Next block', 'Pickup' and 'Putdown'. This time scale and variables describe short term memory. <p> This would compete with events pertinent to the task, if we view short term memory as a (capacity limited) system that functions with a small number of variables <ref> [Ballard et al., 1996] </ref>. Acknowledgements This research was supported by the National Institutes of Health under grants EY05729 and 1-P41-RR09283.
Reference: [Bridgeman et al., 1975] <author> Bridgeman, B., Hendry, D., and Stark, L. </author> <year> (1975). </year> <title> Failure to detect displacement of the visual world during saccadic eye movements. </title> <journal> Vision Research, </journal> <volume> 15 </volume> <pages> 719-722. </pages>
Reference: [Bridgeman et al., 1994] <author> Bridgeman, B., van der Heijden, A., </author> <title> and B.Velichkovsky (1994). A theory of visual stability across saccadic eye movements. </title> <journal> Behavioral and Brain Sciences, </journal> <volume> 17 </volume> <pages> 247-292. </pages>
Reference: [Brooks, 1986] <author> Brooks, R. </author> <year> (1986). </year> <title> A robust layered control system for a mobile robot. </title> <journal> IEEE J. Robotics and Automation, </journal> <volume> 2 </volume> <pages> 14-22. </pages>
Reference: [Churchland et al., 1994] <author> Churchland, P., Ramachandran, V., and Sejnowski, T. </author> <year> (1994). </year> <title> A critique of pure vision. </title> <editor> In Koch, C. and Davis, J., editors, </editor> <booktitle> Large-Scale Neuronal Theories of the Brain, </booktitle> <pages> pages 23-60. </pages> <publisher> MIT Press (A Bradford Book), </publisher> <address> Cambridge, MA. </address> <month> 36 </month>
Reference-contexts: This is an important result for a number of reasons. The first is that it suggests that visual processing may be much more task driven, or top down, than is commonly supposed, even for simple feature information such as color. This view has also been presented by <ref> [Churchland et al., 1994] </ref> as well as in earlier work [O'Regan and Levy-Schoen, 1983, O'Regan, 1992, Nakayama, 1990].
Reference: [Duebel and Bridgeman, 1995] <author> Duebel, H. and Bridgeman, B. </author> <year> (1995). </year> <title> Fourth purkinje image sig-nals reveal eye-lens deviations and retinal image distortions during saccades. </title> <journal> Vision Research, </journal> <volume> 35 </volume> <pages> 529-538. </pages>
Reference-contexts: It was also necessary to set a minimum duration of 30 msec for defining saccade termination, to avoid erroneously labeling the overshoots in the DPI tracker as a separate fixation. These overshoots result from inertial motion of the lens following a high velocity movement and are discussed in <ref> [Duebel and Bridgeman, 1995] </ref>. 14 Our primary focus was on the duration of the fixations in the model area following a color change, since changing information critical for task performance should be disruptive and lead to longer fixations.
Reference: [Eriksen and Eriksen, 1971] <author> Eriksen, C. and Eriksen, B. </author> <year> (1971). </year> <title> Visual perception processimg rates and backward and forward masking. </title> <journal> Journal of Experimental Psychology, </journal> <volume> 89 </volume> <pages> 306-313. </pages>
Reference-contexts: During this period the observer must get the color, select a corresponding color in the resource area, and initiate the saccade. These processes go in parallel to some extent, and estimates of the time required to acquire simple feature information are in the range of 100-300 msec <ref> [Eriksen and Eriksen, 1971, T.Salthouse et al., 1981] </ref>, so 40 msec seems unlikely to be long enough for complete acquisition of a new color.
Reference: [Grimes and McConkie, 1995] <author> Grimes, J. and McConkie, G. </author> <note> (to appear, </note> <year> 1995). </year> <title> On the insensitivity of the human visual system to image changes made during saccades. </title> <editor> In Akins, K., editor, </editor> <title> Problems in Perception. </title> <publisher> Oxford University Press, Oxford, </publisher> <address> UK. </address>
Reference: [Hayhoe et al., 1991] <author> Hayhoe, M., Lachter, J., and Feldman, J. </author> <year> (1991). </year> <title> Integration of form across saccadic eye movements. </title> <journal> Perception, </journal> <volume> 20 </volume> <pages> 393-402. </pages>
Reference-contexts: The issues are separate, however. Humans can clearly integrate visual information across eye movements when they are required to do so <ref> [Hayhoe et al., 1992, Hayhoe et al., 1991] </ref>, and some ability to relate information across time and space is necessary for coordinated action.
Reference: [Hayhoe et al., 1992] <author> Hayhoe, M., Lachter, J., and Moller, P. </author> <year> (1992). </year> <title> Spatial memory and integration across saccadic eye movements. </title> <editor> In Rayner, K., editor, </editor> <title> Eye Movements and Visual Cognition: </title> <journal> Scene Perception and Reading, </journal> <pages> pages 130-145. </pages> <publisher> Springer-Verlag, </publisher> <address> New York. </address>
Reference-contexts: The issues are separate, however. Humans can clearly integrate visual information across eye movements when they are required to do so <ref> [Hayhoe et al., 1992, Hayhoe et al., 1991] </ref>, and some ability to relate information across time and space is necessary for coordinated action.
Reference: [Irwin, 1991] <author> Irwin, D. </author> <year> (1991). </year> <title> Information integration across saccadic eye movements. </title> <journal> Cognitive Psychology, </journal> <volume> 23 </volume> <pages> 420-456. </pages>
Reference: [Karn, 1995] <author> Karn, K. </author> <year> (1995). </year> <title> Spatial Representations for Programming Saccadic Eye Movements. </title> <institution> Doctoral Disertation (Dept. of Brain and Cognitive Science) The University of Rochester, Rochester, </institution> <address> New York. </address> <month> 37 </month>
Reference-contexts: This was determined by measuring the display change with a fast photodetector and comparing photodetector output with the eye position signal from the tracker <ref> [Karn, 1995] </ref>. Procedure Ss copied the block pattern as described above, and were asked only to complete the task as quickly and accurately as possible.
Reference: [Li and Matin, 1990] <author> Li, W. and Matin, L. </author> <year> (1990). </year> <title> Saccadic suppression of displacement:influence of postsaccadic exposure duration and of saccadic stimulus elimination. </title> <journal> Vision Research, </journal> <volume> 30 </volume> <pages> 945-955. </pages>
Reference: [Marr, 1982] <author> Marr, D. </author> <year> (1982). </year> <title> Vision. W.H. </title> <publisher> Freeman and Co., Oxford. </publisher>
Reference-contexts: The idea of an elaborate scene model is perhaps clearest in the computer vision literature, where until recently the goal of the models has been primarily one of reconstruction of a general purpose, task independent representation of the visual world <ref> [Marr, 1982] </ref>.
Reference: [McConkie and Currie, 1996] <author> McConkie, G. and Currie, C. </author> <title> ((in press) 1996). Visual stability across saccades while viewing complex pictures. </title> <journal> Journal of Experimental Psychology:Human Perception and Performance. </journal>
Reference: [McConkie and Rayner, 1976] <author> McConkie, G. and Rayner, K. </author> <year> (1976). </year> <title> Identifying the span of the effective stimulus in reading: Literature review and theories of reading. </title> <editor> In Singer, H. and Ruddell, R., editors, </editor> <booktitle> Theoretical Models and Processes of Reading, </booktitle> <pages> pages 137-162. </pages> <institution> International Reading Association, Newark, DE. </institution>
Reference-contexts: For example, experiments in reading show that certain changes in the parafoveal word that is the target for the next saccade, such as case changes, go undetected <ref> [McConkie and Rayner, 1976, McConkie and Zola, 1979] </ref>. Such results are usually interpreted in terms of the level of the pre 32 served information (features/ semantic content etc). In a reading paradigm, the ongoing task is to extract meaning.
Reference: [McConkie and Zola, 1979] <author> McConkie, G. and Zola, D. </author> <year> (1979). </year> <title> Is visual information integrated across successive fixations in reading? Perception and Psychophysics, </title> <booktitle> 25 </booktitle> <pages> 221-224. </pages>
Reference-contexts: For example, experiments in reading show that certain changes in the parafoveal word that is the target for the next saccade, such as case changes, go undetected <ref> [McConkie and Rayner, 1976, McConkie and Zola, 1979] </ref>. Such results are usually interpreted in terms of the level of the pre 32 served information (features/ semantic content etc). In a reading paradigm, the ongoing task is to extract meaning.
Reference: [Nakayama, 1990] <author> Nakayama, K. </author> <year> (1990). </year> <title> The iconic bottleneck and the tenuous link between early visual processing and perception. </title> <editor> In Blakemore, C., editor, </editor> <booktitle> Vision: Coding and Efficiency, </booktitle> <pages> pages 411-422. </pages> <publisher> Cambridge University Press. </publisher>
Reference-contexts: The first is that it suggests that visual processing may be much more task driven, or top down, than is commonly supposed, even for simple feature information such as color. This view has also been presented by [Churchland et al., 1994] as well as in earlier work <ref> [O'Regan and Levy-Schoen, 1983, O'Regan, 1992, Nakayama, 1990] </ref>. The idea of an elaborate scene model is perhaps clearest in the computer vision literature, where until recently the goal of the models has been primarily one of reconstruction of a general purpose, task independent representation of the visual world [Marr, 1982].
Reference: [O'Regan, 1992] <author> O'Regan, J. </author> <year> (1992). </year> <title> Solving the `real' mysteries of visual perception: The world as an outside memory. </title> <journal> Canadian J. Psychology, </journal> <volume> 46 </volume> <pages> 461-488. 38 </pages>
Reference-contexts: The first is that it suggests that visual processing may be much more task driven, or top down, than is commonly supposed, even for simple feature information such as color. This view has also been presented by [Churchland et al., 1994] as well as in earlier work <ref> [O'Regan and Levy-Schoen, 1983, O'Regan, 1992, Nakayama, 1990] </ref>. The idea of an elaborate scene model is perhaps clearest in the computer vision literature, where until recently the goal of the models has been primarily one of reconstruction of a general purpose, task independent representation of the visual world [Marr, 1982].
Reference: [O'Regan and Levy-Schoen, 1983] <author> O'Regan, J. and Levy-Schoen, A. </author> <year> (1983). </year> <title> Integrating visual information from successive fixations: Does trans-saccadic fusion exist? Vision Research, </title> <booktitle> 23 </booktitle> <pages> 765-769. </pages>
Reference-contexts: The first is that it suggests that visual processing may be much more task driven, or top down, than is commonly supposed, even for simple feature information such as color. This view has also been presented by [Churchland et al., 1994] as well as in earlier work <ref> [O'Regan and Levy-Schoen, 1983, O'Regan, 1992, Nakayama, 1990] </ref>. The idea of an elaborate scene model is perhaps clearest in the computer vision literature, where until recently the goal of the models has been primarily one of reconstruction of a general purpose, task independent representation of the visual world [Marr, 1982].
Reference: [O'Regan et al., 1996] <author> O'Regan, J. K., Rensink, R. A., and Clark, J. </author> <year> (1996). </year> <title> Mud splashes render picture changes invisible. </title> <journal> Investigative Ophthalmology and Visual Science (Suppl), </journal> <volume> 37 </volume> <pages> 213-213. </pages>
Reference: [Pelz, 1995] <author> Pelz, J. </author> <year> (1995). </year> <title> Visual representations in a natural visuo-motor task. </title> <type> Technical Report PhD thesis, </type> <institution> University of Rochester. </institution>
Reference-contexts: Thus subjects showed a very strong preference for using eye movements to acquire information from the display as needed, rather than using visual memory. (A variety of other aspects of performance have been investigated in our previous work, but are not relevant for the current investigation <ref> [Ballard et al., 1992, Ballard et al., 1995, Pelz, 1995] </ref>. The first experiment to probe the extent of the memory across different fixations examines the consequences of changing the color of blocks in the model area during saccades from the Workspace to the Model. <p> In previous work we have examined this question by manipulating various aspects of the task in ways that vary the need for fixations. The frequency of model fixations can be reduced by stimulus manipulations that allow visual chunking, for example, and by display configurations that require large head movements <ref> [Ballard et al., 1995, Pelz, 1995] </ref>. If subjects are obliged to use memory by removing the display, however, only 2 blocks can be copied without error [Ballard et al., 1992]. These observations suggest that the fixations are indeed diagnostic of information-gathering state.
Reference: [Pollatsek and Rayner, 1990] <author> Pollatsek, A. and Rayner, K. </author> <year> (1990). </year> <title> Eye movements and lexical access in reading. </title> <editor> In Balota, D., d'Arcais, G. F., and Rayner, K., editors, </editor> <booktitle> Comprehension Processes in Reading, </booktitle> <pages> pages 143-164. </pages> <publisher> Lawrence Erlbaum Associates, Publisher, </publisher> <address> Hillsdale, NJ. </address>
Reference: [Pollatsek and Rayner, 1992] <author> Pollatsek, A. and Rayner, K. </author> <year> (1992). </year> <title> What is integrated across fixations? In Rayner, </title> <editor> K., editor, </editor> <title> Eye Movements and Visual Cognition: </title> <journal> Scene Perception and Reading, </journal> <pages> pages 161-1991. </pages> <publisher> Springer-Verlag, </publisher> <address> New York. </address>
Reference: [Rao and Ballard, 1996] <author> Rao, R. and Ballard, D. </author> <year> (1996). </year> <title> An active vision architecture based on iconic representations. </title> <journal> Artificial Intelligence, </journal> <volume> 78 </volume> <pages> 461-505. </pages>
Reference-contexts: In this case, changes in the color of neighboring blocks changes the contextual information and this may be necessary for programming the saccade to the target block before pickup and for the return saccade to the model after pickup. One possible mechanism for realizing this is described in <ref> [Rao and Ballard, 1996] </ref>. This work is also discussed in [Ballard et al., 1996]. One important issue in considering the copying task is the extent to which the fixations actually reflect the immediate visual representation.
Reference: [Rensink et al., 1996] <author> Rensink, R., O'Regan, J., and Clark, J. </author> <year> (1996). </year> <title> To see or not to see: the need for attention to perceive changes in scenes. </title> <journal> Investigative Ophthalmology and Visual Science (Suppl), </journal> <volume> 37 </volume> <pages> 213-213. 39 </pages>
Reference: [Rock et al., 1992] <author> Rock, I., Linnett, E., Grant, P., and Mack, A. </author> <year> (1992). </year> <title> Perception without attention: results of a new method. </title> <journal> Cognitive Psychology, </journal> <volume> 24 </volume> <pages> 502-534. </pages>
Reference: [Simons, 1996] <author> Simons, D. </author> <year> (1996). </year> <title> In sight, out of mind: When object representations fail. </title> <journal> Psychological Science. </journal>
Reference: [T.Salthouse et al., 1981] <author> T.Salthouse, C.Lewis, Diener, D., and Somberg, B. </author> <year> (1981). </year> <title> Stimulus processing during eye fixation. </title> <journal> Journal of Experimental Psychology:HPP, </journal> <volume> 7 </volume> <pages> 611-623. 40 </pages>
Reference-contexts: During this period the observer must get the color, select a corresponding color in the resource area, and initiate the saccade. These processes go in parallel to some extent, and estimates of the time required to acquire simple feature information are in the range of 100-300 msec <ref> [Eriksen and Eriksen, 1971, T.Salthouse et al., 1981] </ref>, so 40 msec seems unlikely to be long enough for complete acquisition of a new color.
References-found: 34

