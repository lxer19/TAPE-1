URL: http://robotics.eecs.berkeley.edu/~janka/PATH/mou_final.ps.gz
Refering-URL: http://robotics.eecs.berkeley.edu/~janka/PATH/stereo_drive.html
Root-URL: http://www.cs.berkeley.edu
Author: Principal Investigator: Prof. Jitendra Malik Postdoctoral Researches: Camillo J. Taylor, Philip McLauchlan, Jana Kosecka 
Address: Berkeley, CA 94720  
Affiliation: Department of Electrical Engineering and Computer Sciences University of California at Berkeley  
Abstract: Development of Binocular Stereopsis for Vehicle Lateral Control, Longitudinal Control and Obstacle Detection PATH MOU-257 Final Report 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D. Beymer, P.F. McLauchlan, B. Coifman, and J. Malik. </author> <title> A real-time computer vision system for measuring traffic parameters. </title> <booktitle> In Proc. of the IEEE Conf. on Computer Vision and Pattern Recognition, </booktitle> <year> 1997. </year>
Reference-contexts: This aspect is of vital importance in the context of sensing for control, where the sensor is required to return accurate error feedback during the whole period of the control task. Moreover we have demonstrated in previous work <ref> [1] </ref> that vehicle tracking using features can be made robust both to partial occlusion of the vehicles and to lighting changes in the environment.
Reference: [2] <author> A. Blake, R. Curwen, and A. Zisserman. </author> <title> A framework for spatiotemporal control in the tracking of visual contours. </title> <journal> International Journal of Computer Vision, </journal> <volume> 11(2) </volume> <pages> 127-146, </pages> <month> October </month> <year> 1993. </year>
Reference: [3] <author> P.J. Burt, J.R. Bergen, R. Hingorani, R. Kolczynski, W. A. Lee, A. Leung, J. Lubin, and H. Shvaytser. </author> <title> Object tracking with a moving camera. </title> <booktitle> In Proc. IEEE Workshop on Visual Motion, </booktitle> <pages> pages 2-12, </pages> <year> 1989. </year>
Reference: [4] <author> T.H. Cormen, C.E. Leiserson, and R.L. Rives. </author> <title> Introduction to Algorithms. </title> <publisher> MIT Press, </publisher> <year> 1994. </year>
Reference: [5] <editor> E.D. Dickmanns and B.D. Mysliwetz. </editor> <title> Recursive 3-d road and relative ego-state recognition. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 14(2) </volume> <pages> 199-213, </pages> <month> February </month> <year> 1992. </year>
Reference-contexts: In case of vision-based algorithms for longitudinal control, in spite of the fact that the context of highways and vehicles is clearly very structured, we avoided using direct scene models in the low-level tracking algorithms, and this distinguishes our work from that of Dickmanns's group <ref> [5] </ref>, for instance. We draw on the large amount of work on scene reconstruction from multiple images in unstructured scenes, in particular the work on robust motion segmentation [22], and affine reconstruction [20].
Reference: [6] <author> S.M. Fairley, I.D. Reid, and D.W. Murray. </author> <title> Transfer of fixation for an active stereo platform via affine structure recovery. </title> <booktitle> In Proc. 5th Int'l Conf. on Computer Vision, Boston, </booktitle> <pages> pages 1100-1105. </pages> <publisher> IEEE Computer Society Press, </publisher> <year> 1995. </year>
Reference: [7] <author> M.A. Fischler and R.C. Bolles. </author> <title> Random sample concensus: A paradigm for model fitting with applications to image analysis and automated cartography. </title> <journal> Comm. ACM, </journal> <volume> 24(6) </volume> <pages> 381-395, </pages> <year> 1981. </year>
Reference-contexts: The method that has recently been proposed to achieve this is to select a set of feature matches that are globally consistent, in the sense of satisfying the rigidity constraint. We follow [21] and apply the RANSAC algorithm of Fischler & Bolles <ref> [7] </ref> to compute a large subset of feature matches consistent with a single set of 2D transformation parameters. Part of the stereo matching algorithm is also an algorithm for enforcing uniqueness of individual matches.
Reference: [8] <author> C. Harris. </author> <title> Tracking with rigid models. </title> <editor> In A. Blake and A. Yuille, editors, </editor> <title> Active Vision. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1992. </year>
Reference: [9] <author> H. Kikuchi, M. Ishiyama, and T Nakajima. </author> <title> Development of laser radar for radar brake system. </title> <booktitle> In Proceedings of the International Symposium on Advanced Vehicle Control, </booktitle> <pages> pages 385-389, </pages> <institution> Tsukuba Research Centre, </institution> <address> AIST, MITI, Japan, </address> <year> 1994. </year>
Reference-contexts: In our work we explored possibility of using vision which can potentially provide higher bandwidth (30/60Hz) output than is available from the laser radar system <ref> [9] </ref>. Our approach combines shape reconstruction (2D planar reconstruction rather than the usual 3D) from stereo/motion with motion estimation, using recently developed robust and efficient feature matching methods. <p> The look-ahead distance used in all experiments was L = v 0.9s. 18 angle. 19 The experimental setup for the vision-based tracker for longitudinal control is illustrated in synchronized video and laser radar <ref> [9] </ref>. We selected an initial window surrounding the lead vehicle, although subsequent processing was completely automatic. Figure 9 show some example images, with the tracking results superimposed. The corner features are shown as small crosses, white for those matched over time or in stereo, and black for unmatched features.
Reference: [10] <author> D. Koller, J. Weber, and J. Malik. </author> <title> Robust multiple car tracking with occlusion reasoning. </title> <booktitle> In Proc. 3rd European Conf. on Computer Vision, Stockholm, </booktitle> <volume> volume 1, </volume> <pages> pages 189-196, </pages> <month> May </month> <year> 1994. </year>
Reference: [11] <author> J. Kosecka, R. Blasi, C.J. Taylor, and J. Malik. </author> <title> Vision-based lateral control of vehicles. </title> <booktitle> In Proc. Intelligent Transportation Systems Conference, </booktitle> <address> Boston, </address> <year> 1997. </year>
Reference: [12] <author> P. F. McLauchlan and J. Malik. </author> <title> Vision for longitudinal control. </title> <editor> In A. Clark, editor, </editor> <booktitle> Proc. 8th British Machine Vision Conf., </booktitle> <publisher> Essex. BMVA Press, </publisher> <year> 1997. </year>
Reference: [13] <author> P. F. McLauchlan and J. Malik. </author> <title> Vision for longitudinal vehicle control. </title> <booktitle> In Proc. Intelligent Transportation Systems Conference, </booktitle> <address> Boston, </address> <year> 1997. </year>
Reference-contexts: We now describe briefly some of the problems. More detailed description can be found in <ref> [13] </ref>. 3.2 Fixation/Scene Reconstruction In [17] a fixation technique was described that allows a single "fixation point" to be chosen from a cluster of tracked features, in a way that is robust to losing track of individual features, while allowing the same object point to be fixated over time. <p> Part of the stereo matching algorithm is also an algorithm for enforcing uniqueness of individual matches. Both algorithms are described in more detail in <ref> [13] </ref>. 3.5 Layered Tracking The frame-rate (30Hz) performance of the tracker results from the coordination of two separate tracking algorithms, a frame-rate correlator which computes the motion in both images, and the corner feature-based fixation algorithm, which runs at 3-5Hz depending on the size of the region used for the corner
Reference: [14] <author> P.F. McLauchlan and D.W. Murray. </author> <title> A unifying framework for structure and motion recovery from image sequences. </title> <booktitle> In Proc. 5th Int'l Conf. on Computer Vision, </booktitle> <address> Boston, </address> <month> June </month> <year> 1995. </year>
Reference-contexts: This is the method we have implemented. The reconstruction technique detailed below is a 2D affine version of the Variable State Dimension Filter (VSDF) algorithm <ref> [14] </ref>.
Reference: [15] <author> P.A.Beardsley, A.Zisserman, and D.W.Murray. </author> <title> Sequential updating of projective and affine structure from motion. </title> <journal> International Journal of Computer Vision, </journal> <volume> 23(3), </volume> <year> 1997. </year>
Reference: [16] <author> K. Pahlavan, T. Uhlin, and J.O. Eklundh. </author> <title> Dynamic fixation and active perception. </title> <journal> IJCV, </journal> <volume> 17(2) </volume> <pages> 113-135, </pages> <month> February </month> <year> 1996. </year>
Reference: [17] <author> I. D. Reid and D. W. Murray. </author> <title> Active tracking of foveated feature clusters using affine structure. </title> <journal> International Journal of Computer Vision, </journal> <volume> 18(1) </volume> <pages> 1-20, </pages> <month> April </month> <year> 1996. </year>
Reference-contexts: We now describe briefly some of the problems. More detailed description can be found in [13]. 3.2 Fixation/Scene Reconstruction In <ref> [17] </ref> a fixation technique was described that allows a single "fixation point" to be chosen from a cluster of tracked features, in a way that is robust to losing track of individual features, while allowing the same object point to be fixated over time.
Reference: [18] <author> J. Shi and C. Tomasi. </author> <title> Good features to track. </title> <booktitle> In Proc. of the IEEE Conf. on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 593-600, </pages> <year> 1994. </year>
Reference-contexts: The drift problem can be eliminated in correlation trackers by fixing the template used for correlation, converting it into a position-based tracker; however then the tracker will work only for a short time, because relatively small motions, especially rotations, will break the tracker, although Shi & Tomasi <ref> [18] </ref> suggest a partial solution to that problem through an affinely deformable template. Correlation with a fixed template forms 14 the lower level of our tracker, and we use it in such a way that a single template is used for only a short period of time.
Reference: [19] <author> S. M. Smith. ASSET-2: </author> <title> Real-Time Motion Segmentation and Shape Tracking. </title> <booktitle> In Proc. 5th Int'l Conf. on Computer Vision, Boston, </booktitle> <pages> pages 237-244, </pages> <year> 1995. </year>
Reference: [20] <author> C. Tomasi and T. Kanade. </author> <title> Shape and motion from image streams under orthography: A factorization approach. </title> <journal> International Journal of Computer Vision, </journal> <volume> 9(2) </volume> <pages> 137-154, </pages> <year> 1992. </year>
Reference-contexts: We draw on the large amount of work on scene reconstruction from multiple images in unstructured scenes, in particular the work on robust motion segmentation [22], and affine reconstruction <ref> [20] </ref>. These approaches are able to take advantage of the redundant information in images, because they latch onto whatever features are available, whereas model-based methods are restricted to the features associated with the chosen model. <p> We employ the variable state dimension filter algorithm which achieves virtually the same accuracy as previously used batch algorithms <ref> [20] </ref>, but has the advantages of being recursive, not requiring complete data, and allowing new features to be added to the reconstruction as they appear and discarded features to be removed.
Reference: [21] <author> P.H.S. Torr, P.A. Beardsley, and D.W. Murray. </author> <title> Robust vision. </title> <editor> In E. Hancock, editor, </editor> <booktitle> Proc. 5th British Machine Vision Conf., </booktitle> <address> York, </address> <pages> pages 145-154. </pages> <publisher> BMVA Press, </publisher> <year> 1994. </year>
Reference-contexts: The method that has recently been proposed to achieve this is to select a set of feature matches that are globally consistent, in the sense of satisfying the rigidity constraint. We follow <ref> [21] </ref> and apply the RANSAC algorithm of Fischler & Bolles [7] to compute a large subset of feature matches consistent with a single set of 2D transformation parameters. Part of the stereo matching algorithm is also an algorithm for enforcing uniqueness of individual matches.
Reference: [22] <author> P.H.S. Torr, A. Zisserman, and S.J. Maybank. </author> <title> Robust detection of degenerate configurations for the fundamental matrix. </title> <booktitle> In Proc. 5th Int'l Conf. on Computer Vision, Boston, </booktitle> <pages> pages 1037-1042, </pages> <year> 1995. </year>
Reference-contexts: We draw on the large amount of work on scene reconstruction from multiple images in unstructured scenes, in particular the work on robust motion segmentation <ref> [22] </ref>, and affine reconstruction [20]. These approaches are able to take advantage of the redundant information in images, because they latch onto whatever features are available, whereas model-based methods are restricted to the features associated with the chosen model.
Reference: [23] <author> Z. Zhang and O. Faugeras. </author> <title> 3D Dynamic Scene Analysis. </title> <publisher> Springer-Verlag, </publisher> <year> 1992. </year>
Reference: [24] <author> Jitendra Malik, Camillo J. Taylor, Joseph Weber, Dieter Koller and Quang-Tuan Luong. </author> <title> A combined approach to stereopsis and lane finding. UCB-ITS-PRR-97-27, California PATH, </title> <type> final report, </type> <year> 1997. </year> <month> 25 </month>
Reference-contexts: Within this proposal we explored the feasibility of the use of visual sensing as a part of the Advanced Vehicle Control System (AVCS). The basic theoretical foundation on which this work was based had been developed under a previous program <ref> [24] </ref>. In this phase of the research program we demonstrated improved versions of the proposed algorithms, real-time implementations and a novel stereo tracking algorithm for longitudinal control.
Reference: [25] <author> Robert. S. Blasi. </author> <title> A study of lateral controllers for the stereo drive project. </title> <type> Master's thesis, </type> <institution> Department of Computer Science, University of California at Berkeley, </institution> <year> 1997. </year>
Reference-contexts: The delay element adds an additional phase lag over the whole range of frequencies having a clear destabilizing effect on the overall system and limiting the system's bandwidth. More detailed analysis can be found in <ref> [30, 25] </ref>. Controller Design. Analysis reveals that up to 15 m/s the lookahead one can guarantee satisfactory damping of the closed loop poles of V 1 (s) and compensate for the delay using simple unity feedback control with proportional gain in the forward loop.
Reference: [26] <author> E. D. Dickmanns and B. D. Mysliwetz. </author> <title> Recursive 3-D road and relative ego-state estimation. </title> <journal> IEEE Transactions on PAMI, </journal> <volume> 14(2) </volume> <pages> 199-213, </pages> <month> February </month> <year> 1992. </year>
Reference-contexts: Several sensing technologies have been proposed for use in an Advanced Vehicle Control System, including vision, magnetic sensors and active range sensors. Some of the most influential work on visually guided control of autonomous vehicles has been done by E.D.Dickmanns and his colleagues <ref> [26] </ref>. In their system vision was used to provide input for both lateral and longitudinal control of the vehicle on free roads as well as in the presence of other vehicles. <p> Their analysis showed that closed loop stability for this controller can always be obtained by increasing the look-ahead distance to an appropriate value. Dickmanns, et al <ref> [26] </ref> developed a Kalman-filter based observer which estimated the state of the vehicle with respect to the road along with the road geometry and used the estimate for full state feedback using a pole-placement method.
Reference: [27] <author> B. Espiau, F. Chaumette, and P. Rives. </author> <title> A new approach to visual servoing in robotics. </title> <journal> IEEE Transactions on Robotics and Automation, </journal> <volume> 8(3):313 - 326, </volume> <month> June </month> <year> 1992. </year>
Reference-contexts: Several aspects of this problem have been examined extensively in the past, both in the psychophysics literature [31] as well as in control theoretic studies. In the kinematic setting there have been several attempts to formulate the vision-based steering task in the image plane <ref> [36, 27] </ref>. A stability analysis was provided for an omnidirectional mobile base trying to align itself with a straight road [27] or non-holonomic mobile base following an arbitrary ground analytic curve [32]. <p> In the kinematic setting there have been several attempts to formulate the vision-based steering task in the image plane [36, 27]. A stability analysis was provided for an omnidirectional mobile base trying to align itself with a straight road <ref> [27] </ref> or non-holonomic mobile base following an arbitrary ground analytic curve [32]. The controllers designed based on kinematic models were either tested in simulation or in experiments at speeds below 20 m/s. However at higher speeds dynamic effects are quite pertinent and the need for a dynamic model becomes apparent.
Reference: [28] <author> Arthur Gelb et al. </author> <title> Applied optimal estimation. </title> <publisher> MIT Press, </publisher> <year> 1994. </year>
Reference-contexts: The gain matrix L can be chosen in a number of ways <ref> [28] </ref>, depending on the assumptions one makes about the availability of noise statistics and the criterion one chooses to optimize. 13 3 Vision for longitudinal vehicle control Another modality of the automated vehicle is a longitudinal control system which combines both laser radar and vision sensors, enabling throttle and brake control
Reference: [29] <author> J. Guldner, H.-S. Tan, and S. Patwarddhan. </author> <title> Analysis of automated steering control for highway vehicles with look-down lateral reference systems. Vehicle System Dynamics (to appear), </title> <year> 1996. </year>
Reference-contexts: Further studies typically use a small and fixed look-ahead distance and the control objective is formulated either at the look-ahead distance <ref> [29] </ref> or at the center of gravity of the vehicle [34]. An analysis of the tradeoffs between the performance requirements and robustness of the system can be found in [29]. <p> Further studies typically use a small and fixed look-ahead distance and the control objective is formulated either at the look-ahead distance <ref> [29] </ref> or at the center of gravity of the vehicle [34]. An analysis of the tradeoffs between the performance requirements and robustness of the system can be found in [29]. We discuss the problem of automated steering using computer vision, focusing on the analysis of the problem and controller design choice. <p> This is typically expressed in terms of jerk, corresponding to the rate of change of acceleration. For a comfortable ride no frequency above 0.1-0.5 Hz should be amplified in the path to lateral acceleration <ref> [29] </ref>. Additional road following criteria can be specified in terms of maximal allowable offset y Lmax as a response to the step change in curvature as well as bandwidth requirements on the transfer function F (s) = y L (s) K ref (s) .
Reference: [30] <author> Jana Kosecka. </author> <title> Vision-based lateral control of vehicles:look-ahead and delay issues. Internal Memo, </title> <institution> Department of EECS, University of California Berkeley, </institution> <year> 1997. </year>
Reference-contexts: The lateral dynamics equations are obtained by computing the net lateral force and torque act ing on the vehicle following Newton-Euler equations <ref> [30] </ref> and choosing _ and v y , as state variables. <p> The delay element adds an additional phase lag over the whole range of frequencies having a clear destabilizing effect on the overall system and limiting the system's bandwidth. More detailed analysis can be found in <ref> [30, 25] </ref>. Controller Design. Analysis reveals that up to 15 m/s the lookahead one can guarantee satisfactory damping of the closed loop poles of V 1 (s) and compensate for the delay using simple unity feedback control with proportional gain in the forward loop.
Reference: [31] <author> M. F. Land and D. N. Lee. </author> <title> Where we look when we steer? Nature, </title> <type> 369(30), </type> <month> June </month> <year> 1994. </year>
Reference-contexts: Several aspects of this problem have been examined extensively in the past, both in the psychophysics literature <ref> [31] </ref> as well as in control theoretic studies. In the kinematic setting there have been several attempts to formulate the vision-based steering task in the image plane [36, 27].
Reference: [32] <author> Yi Ma, Jana Kosecka, and Shankar Sastry. </author> <title> Vision guided navigation for a nonholonomic mobile robot. </title> <note> In submitted to CDC'98, </note> <year> 1997. </year>
Reference-contexts: A stability analysis was provided for an omnidirectional mobile base trying to align itself with a straight road [27] or non-holonomic mobile base following an arbitrary ground analytic curve <ref> [32] </ref>. The controllers designed based on kinematic models were either tested in simulation or in experiments at speeds below 20 m/s. However at higher speeds dynamic effects are quite pertinent and the need for a dynamic model becomes apparent.
Reference: [33] <author> U. Ozguner, K. A. Unyelioglu, and C. Hatipoglu. </author> <title> An analytical study of vehicle steering control. </title> <booktitle> In Proceedings of the 4th IEEE Conference on Control Applications, </booktitle> <pages> pages 125 - 130, </pages> <year> 1995. </year>
Reference-contexts: A number of other groups throughout the country explored the possibility of using visual sensing for vehicle guidance both in outdoor and indoor environments <ref> [36, 33] </ref> concentrating primarily on the lane keeping or path following modality on the free roads. For vision-based lateral control we undertook to explore a strategy which uses direcly the information from the vision at some look-ahead distance. <p> However at higher speeds dynamic effects are quite pertinent and the need for a dynamic model becomes apparent. The control problem in a dynamic setting, using measurements ahead of the vehicle, has been explored by <ref> [33] </ref> who proposed a constant control law proportional to the offset from the centerline at a look-ahead distance. Their analysis showed that closed loop stability for this controller can always be obtained by increasing the look-ahead distance to an appropriate value.
Reference: [34] <author> H. Peng. </author> <title> Vehicle Lateral Control for Highway Automation. </title> <type> PhD thesis, </type> <institution> Department of Mechanical Engineering, University of California, Berkeley, </institution> <year> 1992. </year>
Reference-contexts: Further studies typically use a small and fixed look-ahead distance and the control objective is formulated either at the look-ahead distance [29] or at the center of gravity of the vehicle <ref> [34] </ref>. An analysis of the tradeoffs between the performance requirements and robustness of the system can be found in [29]. We discuss the problem of automated steering using computer vision, focusing on the analysis of the problem and controller design choice. <p> Within this setting we explore the role of lookahead, its relation to the vision processing delay, longitudinal velocity and road geometry. 2.1 Modeling The dynamics of the vehicle can be described by a detailed 6-DOF nonlinear model <ref> [34] </ref>. Since it is possible to decouple the longitudinal and lateral dynamics, a linearized model of the lateral vehicle dynamics is used for controller design.
Reference: [35] <author> Chuck E. Thorpe, Martial Herbert, Takeo Kanade and Steve Shafer. </author> <title> Vision and navigation for the Carnegie-Mellon Navlab. </title> <journal> In IEEE Trans. Pattern Analysis and Machine Intelligence, </journal> <volume> 10(3) </volume> <pages> 342-361, </pages> <year> 1988. </year>
Reference-contexts: In the United States one of the leading efforts has been the CMU NavLab Project <ref> [35] </ref> which has employed a variety of different sensing and control strategies including a neural network based lane following algorithm called ALVINN.
Reference: [36] <author> D. Raviv and M. Herman. </author> <title> A 'non-reconstruction' approach for road following. </title> <booktitle> In Proceedings of the SPIE, editor, Intelligent Robots and Computer Vision, </booktitle> <pages> pages 2-12, </pages> <year> 1991. </year>
Reference-contexts: A number of other groups throughout the country explored the possibility of using visual sensing for vehicle guidance both in outdoor and indoor environments <ref> [36, 33] </ref> concentrating primarily on the lane keeping or path following modality on the free roads. For vision-based lateral control we undertook to explore a strategy which uses direcly the information from the vision at some look-ahead distance. <p> Several aspects of this problem have been examined extensively in the past, both in the psychophysics literature [31] as well as in control theoretic studies. In the kinematic setting there have been several attempts to formulate the vision-based steering task in the image plane <ref> [36, 27] </ref>. A stability analysis was provided for an omnidirectional mobile base trying to align itself with a straight road [27] or non-holonomic mobile base following an arbitrary ground analytic curve [32].
Reference: [37] <author> Camillo J. Taylor, Jitendra Malik, and Joseph Weber. </author> <title> A real-time approach to stereopsis and lane-finding. </title> <booktitle> In Proceedings of the 1996 IEEE Intelligent Vehicles Symposium, </booktitle> <pages> pages 207-213, </pages> <address> Seikei University, Tokyo, Japan, </address> <month> September 19-20 </month> <year> 1996. </year> <month> 26 </month>
References-found: 37

