URL: ftp://info.mcs.anl.gov/pub/tech_reports/reports/P331.ps.Z
Refering-URL: http://www.mcs.anl.gov/publications/abstracts/abstracts92.htm
Root-URL: http://www.mcs.anl.gov
Title: An Infeasible-Interior-Point Algorithm for Linear Complementarity Problems  
Author: Stephen Wright 
Affiliation: DIVISION, ARGONNE NATIONAL LABORATORY  
Note: PREPRINT MCS-P331-1092, MCS  
Date: October 15, 1992  
Abstract: In this paper, we discuss a polynomial and Q-subquadratically convergent algorithm for linear complementarity problems that does not require feasibility of the initial point or the subsequent iterates. The algorithm is a modification of the linearly convergent method of Zhang and requires the solution of at most two linear systems with the same coefficient matrix at each iteration. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Ji, F. Potra, and S. Huang, </author> <title> A predictor-corrector method for linear complementarity problems with polynomial complexity and superlinear convergence, </title> <type> Tech. Rep. 18, </type> <institution> Department of Mathematics, The University of Iowa, Iowa City, Iowa, </institution> <month> August </month> <year> 1991. </year>
Reference-contexts: It is well known that convex quadratic programming problems and linear programming problems can be expressed as linear complementarity problems; the same is true of extended linear-quadratic programming problems (see Rockafellar [9]). Much research has been devoted to interior point methods for (1). Recently, Ji, Potra, and Huang <ref> [1] </ref> proposed a predictor-corrector algorithm with polynomial complexity and superlinear convergence, while the predictor-corrector algorithm of Ye and Anstreicher [11] is polynomial and Q-quadratic. <p> [0; 1), ~oe 2 [0; 1), solve " Y k X k x k # " X k Y k e + ~oe k e : (2) Choose ~ff = arg min OE (x k + ffx k ; y k + ffy k ) (3) subject to ff 2 <ref> [0; 1] </ref>; (4a) y k + ffy k &gt; 0; (4c) (x k i )(y k i ) (~fl=n)(x k + ffx k ) T (y k + ffy k ); i = 1; ; n: (4e) It has been noted previously that (2) are simply the equations obtained by applying <p> Finally, we examine OE (x k + ffx k ; y k + ffy k ) for ff 2 <ref> [0; 1] </ref>. <p> ffn (1 k ) k + ff 2 (x k ) T y k + (1 ff)r k : If (x k ) T y k 0, then, since k &lt; 1 by (31), OE (x k + ffx k ; y k + ffy k ) is decreasing on <ref> [0; 1] </ref>. Otherwise, the unconstrained minimum occurs at ff min = 2 (x k ) T y k 2 (x k ) T y k 2nC 4 C 5 2 C 6 k But from (31), (3=2)C 6 k 2 and so ff min 1. <p> Again, we deduce that OE (x k + ffx k ; y k + ffy k ) is decreasing on <ref> [0; 1] </ref>. This implies that the value of ~ff chosen by the algorithm is the largest value that satisfies (4), and so k ; as required. <p> + ffy k ) = k [1 ff (1 k )] + ff 2 (x k ) T y k : (39) The argument in the last part of Lemma 6.1, in particular, formulae (34) and (35), can be applied to show that the quadratic function (39) is decreasing on <ref> [0; 1] </ref>.
Reference: [2] <author> M. Kojima, N. Meggido, and S. Mizuno, </author> <title> A primal-dual exterior point algorithm for linear programming, </title> <type> Tech. Rep. RJ 8500, </type> <institution> IBM Alamaden Research Center, </institution> <address> San Jose, Calif., </address> <year> 1991. </year>
Reference-contexts: Also, minor modifications to a solution to a "nearby" problem can produce an excellent starting point for the present problem | an advantage when the underlying problem to be solved is nonlinear. Infeasible algorithms for linear programming have been proposed by Kojima, Meggido, and Mizuno <ref> [2] </ref>, Kojima, Mizuno, and Todd [3], and Potra [7, 8]. Of these, only Potra's algorithms have both polynomial complexity and superlinear convergence properties.
Reference: [3] <author> M. Kojima, S. Mizuno, and M. Todd, </author> <title> Infeasible interior-point primal-dual potential-reduction algorithms for linear programming, </title> <type> Tech. Rep. 1023, </type> <institution> School of Operations Research and Industrial Engineering, Cornell University, </institution> <address> Ithaca, New York, </address> <month> August </month> <year> 1992. </year>
Reference-contexts: Infeasible algorithms for linear programming have been proposed by Kojima, Meggido, and Mizuno [2], Kojima, Mizuno, and Todd <ref> [3] </ref>, and Potra [7, 8]. Of these, only Potra's algorithms have both polynomial complexity and superlinear convergence properties. Potra's methods are of the predictor-corrector type and require three systems of linear equations (two of which have the same coefficient matrix) to be solved at each iteration.
Reference: [4] <author> I. J. Lustig, R. E. Marsten, and D. F. Shanno, </author> <title> Computational experience with a globally convergent primal-dual predictor-corrector algorithm for linear programming, </title> <type> Tech. Rep. SOR 92-10, </type> <institution> Program in Statistics and Operations Research, Department of Civil Engineering and Operations Research, Princeton University, Princeton, </institution> <address> New Jersey, </address> <month> September </month> <year> 1992. </year>
Reference-contexts: These infeasible-interior-point methods more nearly reflect computational practice (see, for example, Lustig, Marsten, and Shanno <ref> [4] </ref>). Also, minor modifications to a solution to a "nearby" problem can produce an excellent starting point for the present problem | an advantage when the underlying problem to be solved is nonlinear.
Reference: [5] <author> R. D. C. Monteiro and S. J. Wright, </author> <title> A globally and superlinearly convergent potential reduction interior point method for convex programming, </title> <type> Tech. Rep. </type> <institution> MCS-P316-0792, Mathematics and Computer Science Division, Argonne National Laboratory, Argonne, Illinois, </institution> <month> August </month> <year> 1992. </year>
Reference-contexts: The proof of (19b) is similar. Bounds on the remaining components x k B and y k N are more difficult to obtain. We need the following lemma, which is similar to results obtained by Ye and Anstreicher [11, Lemma 3.5] and Monteiro and Wright <ref> [5, Lemma 3.6] </ref>. For clarity, we drop the superscript k from vectors and matrices in the following two results.
Reference: [6] <author> F. Potra, </author> <title> On Q-order and R-order of convergence, </title> <journal> Journal of Optimization Theory and Applications, </journal> <volume> 63 (1989), </volume> <pages> pp. 415-431. 22 </pages>
Reference-contexts: 1) log fl t k log fl; that is, the first term on the right hand side of (42) will eventually dominate the third term and, in fact, lim t k = 0: Dividing (42) by log k , we have lim inf log k+1 = 2: (43) From Potra <ref> [6] </ref>, (43) implies that the Q-order of convergence for f k g is 2. The argument for fOE k g is similar. Finally, we show that the threshold condition (29) will eventually be met and, hence, that subquadratic convergence will be obtained.
Reference: [7] <author> F. A. Potra, </author> <title> An infeasible interior-point predictor-corrector algorithm for linear pro-gramming, </title> <type> Tech. Rep. 26, </type> <institution> Department of Mathematics, University of Iowa, Iowa City, Iowa, </institution> <month> June </month> <year> 1992. </year> <title> [8] , A quadratically convergent infeasible interior-point algorithm for linear programming, </title> <type> Tech. Rep. 28, </type> <institution> Department of Mathematics, University of Iowa, Iowa City, Iowa, </institution> <month> July </month> <year> 1992. </year>
Reference-contexts: Infeasible algorithms for linear programming have been proposed by Kojima, Meggido, and Mizuno [2], Kojima, Mizuno, and Todd [3], and Potra <ref> [7, 8] </ref>. Of these, only Potra's algorithms have both polynomial complexity and superlinear convergence properties. Potra's methods are of the predictor-corrector type and require three systems of linear equations (two of which have the same coefficient matrix) to be solved at each iteration.
Reference: [9] <author> R. T. Rockafellar, </author> <title> Computational schemes for large-scale problems in extended linear-quadratic programming, </title> <journal> Mathematical Programming, </journal> <volume> 48 (1990), </volume> <pages> pp. 447-474. </pages>
Reference-contexts: It is well known that convex quadratic programming problems and linear programming problems can be expressed as linear complementarity problems; the same is true of extended linear-quadratic programming problems (see Rockafellar <ref> [9] </ref>). Much research has been devoted to interior point methods for (1). Recently, Ji, Potra, and Huang [1] proposed a predictor-corrector algorithm with polynomial complexity and superlinear convergence, while the predictor-corrector algorithm of Ye and Anstreicher [11] is polynomial and Q-quadratic.
Reference: [10] <author> Y. Ye, </author> <title> On the Q-order of convergence of interior-point algorithms for linear programming, </title> <type> Tech. Rep. 91-17, </type> <institution> Department of Management Sciences, University of Iowa, </institution> <month> Oc-tober </month> <year> 1991. </year>
Reference-contexts: For (ii), we use (37a). Since k+1 fl t k (1 fl) k ; we have log k+1 2 log k + log (3C 6 ) t k log fl log (1 fl): (42) We can now use an argument like that of Ye <ref> [10] </ref>.
Reference: [11] <author> Y. Ye and K. Anstreicher, </author> <title> On quadratic and O( p nL) convergence of a predictor-corrector algorithm for LCP, </title> <type> Tech. Rep. 91-20, </type> <institution> Department of Management Sciences, University of Iowa, </institution> <month> November </month> <year> 1991. </year>
Reference-contexts: Much research has been devoted to interior point methods for (1). Recently, Ji, Potra, and Huang [1] proposed a predictor-corrector algorithm with polynomial complexity and superlinear convergence, while the predictor-corrector algorithm of Ye and Anstreicher <ref> [11] </ref> is polynomial and Q-quadratic. In the latter paper, it was assumed only that a strictly feasible point and a strictly complementary solution (one for which max (x fl i ; y fl i ) &gt; 0 for i = 1; ; n) exist for (1). <p> In this paper, we propose modifications of Zhang's algorithm that retain polynomial complexity and have the added feature that the sequence f k g converges superlinearly to zero with Q-order 2. Only the mild assumptions of Ye and Anstreicher <ref> [11] </ref> are required. Our method requires the solution of at most two linear systems of equations with the same coefficient matrix at each iteration. <p> The proof of (19b) is similar. Bounds on the remaining components x k B and y k N are more difficult to obtain. We need the following lemma, which is similar to results obtained by Ye and Anstreicher <ref> [11, Lemma 3.5] </ref> and Monteiro and Wright [5, Lemma 3.6]. For clarity, we drop the superscript k from vectors and matrices in the following two results. <p> These conditions are that (w; z) is feasible with respect to (21) and " B w oe k k X 1 D 2 N e N 2 R M T NB #! 12 where R (:) denotes the range space of a matrix. Ye and Anstreicher <ref> [11, Lemma 3.4] </ref> prove that R M T NB #! " 0 I ; and so (22) becomes " B w oe k k X 1 D 2 N e N 2 R M BB M BN #! We now show that (x B ; y N ) satisfies (23).
Reference: [12] <author> Y. Zhang, </author> <title> On the convergence of an infeasible interior-point algorithm for linear programming and other problems, </title> <type> Tech. Rep. 92-07, </type> <institution> Department of Mathematics and Statistics, University of Maryland, Baltimore County, </institution> <month> April </month> <year> 1992. </year>
Reference-contexts: Potra's methods are of the predictor-corrector type and require three systems of linear equations (two of which have the same coefficient matrix) to be solved at each iteration. The only infeasible-interior-point algorithm for more general problems than linear programs that we are aware of is due to Zhang <ref> [12] </ref>. He analyzes an algorithm for a class of problems that includes (1) and proves Q-linear convergence of the complementarity gap k = (x k ) T y k =n to zero. Polynomial complexity is obtained for a particular choice of starting point. <p> The condition (4e), usually referred to as a centering condition, ensures that the iterates do not prematurely approach the edge of the non-negative orthant. The condition (4d) is a relaxation of the condition enforced by Zhang <ref> [12, formula (5.7)] </ref> to ensure that feasibility is given a higher priority than complementarity (Zhang uses ~ fi = 0). Potra's algorithms replace (4d) with an equality condition in which ~ fi = 0. <p> By (4d), k (1 fi k1 )(1 ff k1 ) k1 i=0 giving the first inequality. The second inequality follows from n k OE k OE 0 = n 0 + ky 0 M x 0 hk: Zhang <ref> [12] </ref> defines an "auxiliary sequence" (u k ; v k ) by defining an initial point (u 0 ; v 0 ) such that (u 0 ; v 0 ) (x 0 ; y 0 ); v 0 = M u 0 + h; and subsequent iterates by u k+1 = <p> Lemma 3.3 (Zhang <ref> [12, Lemma 4.1] </ref>) For k 0, (i) v k = M u k + h; (iii) If ff K = 1 for some K 0, then (x k ; y k ) = (u k ; v k ) and therefore (x k ; y k ) is strictly feasible for <p> Proof. We have from Lemma 3.5 that i 2 B; x k i fl k k ) y k fl k k i fl k k C 2 4 Linear Convergence and Polynomial Complexity In this section, we modify some results of Zhang <ref> [12] </ref> to show that the algorithm of Section 2 produces a sequence fOE k g that converges Q-linearly. When the starting point is chosen appropriately, the method has polynomial complexity. <p> Minor modifications of the proofs of Lemma 6.2 and Theorem 7.1 in Zhang <ref> [12] </ref> yield (12). <p> Minor modifications of the proofs of Lemma 6.2 and Theorem 7.1 in Zhang [12] yield (12). Since, from Lemma 3.2, we have (x k ) T y k ^ fi k (x 0 ) T y 0 ; we can modify the proof of Zhang <ref> [12, Lemma 6.1] </ref> to show that k n ! 1=2 " (x 0 u 0 ) T y fl + (y 0 v 0 ) T x fl + (x 0 u 0 ) T (y 0 v 0 ) # Since oe k 2 [0; 1) and fl k fl <p> Proof. Consider a safe step with 0 &lt; oe oe k 1=2. As in the proof of Theorem 7.1 of Zhang <ref> [12] </ref>, we can show that OE k+1 (1 ffi k )OE k ; where ffi k 1 n (1 fl k )oe 1 n (1 2fl)oe &gt; 0; where the second inequality follows from fl k 2 (fl; 2fl]. <p> When a successful fast step is taken, we have by definition that OE k+1 aeOE k : The result follows by setting ffi = min 1 n (1 2fl)oe ; 1 ae : (15) The complexity result depends on a particular choice of starting point. Zhang <ref> [12] </ref> sug- gests the following choice. <p> Then there is an integer K * such that K * = O (n 2 log (1=*)); Proof. As in Zhang <ref> [12, Lemma 7.1] </ref>, with minor modifications, it can be shown that if we choose ! = lim sup ! k ; then ! = O (n). Equation (15) then implies that ffi ffi=n 2 , for some ffi &gt; 0 independent of n.
Reference: [13] <author> Y. Zhang and D. Zhang, </author> <title> Superlinear convergence of infeasible interior-point methods for linear programming, </title> <type> Tech. Rep. 92-15, </type> <institution> Department of Mathematics and Statistics, University of Maryland, Baltimore County, </institution> <month> September </month> <year> 1992. </year> <month> 23 </month>
Reference-contexts: Only the mild assumptions of Ye and Anstreicher [11] are required. Our method requires the solution of at most two linear systems of equations with the same coefficient matrix at each iteration. When this report was about to be issued, we received a new report by Zhang and Zhang <ref> [13] </ref> that describes an infeasible-interior-point algorithm that is similar to ours in some respects. They allow relaxed versions of the centering condition and the feasibility dominance condition (cf. below (4e) and (4d), respectively) to be used on some iterations, and they obtain similar convergence properties.
References-found: 12

