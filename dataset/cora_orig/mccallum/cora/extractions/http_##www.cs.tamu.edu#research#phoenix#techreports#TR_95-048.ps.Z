URL: http://www.cs.tamu.edu/research/phoenix/techreports/TR_95-048.ps.Z
Refering-URL: http://www.cs.tamu.edu/research/phoenix/papers_bib.html
Root-URL: 
Email: fganeshb,poochg@cs.tamu.edu  peter.kessler@eng.sun.com  
Title: Replicated Naming Service in Spring  
Author: Ganesha Beedubail Udo Pooch and Peter B. Kessler 
Address: College Station, TX 77843.  2550 Garcia Avenue, Mountain View, CA 94043.  
Affiliation: Department of Computer Science, Texas A&M University,  Sun Microsystems, Inc.,  
Abstract: Technical Report (TR 95-048) December 1995. Abstract This paper presents the design and implementation of a Replicated Naming Service (RNS) for the Spring (a microkernel based distributed object oriented) Operating System and a new replica consistency protocol. The design develops a mechanism to replicate the existing naming service by using subcontract abstraction provided by Spring and the inheritance feature of object oriented systems. The replication service is transparent to the clients of the naming service, i.e., no change needs to be made to the client to use the RNS (not even recompilation). We also describe a Master/Slave protocol designed for replica consistency and fault tolerance. This protocol just uses one round of message passing (one phase protocol), whereas the other existing protocols use more than one round of message exchange (two or more phases). The protocol is specified in terms of remote procedure calls (RPC). This makes the implementation of the protocol very portable on heterogeneous systems which support a common RPC mechanism (like the OSF DCE RPC). Another interesting feature of this protocol is that it is self contained (it does not assume the existence of any lower level reliable services). The failure detection and group membership features are seamlessly integrated into the protocol. The paper also presents the preliminary results measured from the prototype implementation. y Part of this work was done when this author was working at Sun Microsystems, Inc., CA. during Summer 1995. Contact this author at ganeshb@cs.tamu.edu for any communications regarding this paper. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Mitchel et al., </author> <title> "An overview of the spring system," </title> <booktitle> In Proceedings of of Compcon Spring 1994, </booktitle> <month> February </month> <year> 1994. </year>
Reference-contexts: When an object is replicated on multiple machines that fail independently, the probability of the availability of the object increases. In this paper we will present the design and the implementation of the mechanism that provides the Replicated Naming Service (RNS) in Spring <ref> [1] </ref>, a microkernel based distributed object oriented operating system. In Spring, the name service is viewed as an object, like any other object in the system. Thus we hope the lessons learned from replicating the name service could be applied to replicating any general object. <p> We will also describe, in brief, the components of Spring that are 5 Arjuna also uses single copy passive replication, similar to coordinator cohort scheme. 4 relevant to this work. 3.1 Overview of Spring OS Spring is a microkernel based object oriented distributed operating system <ref> [1] </ref>. All services in Spring (user services as well as system services) are implemented as objects. All objects in Spring have well defined interfaces, and these interfaces are defined in an Interface Definition Language (IDL). <p> Object invocations across the network are handled by network proxies. Network proxies connect the nuclei of different machines transparently. Spring provides other standard system services as user level objects. These include file system service, machine name service, TCP/UDP/IP service, tty service etc. For details refer to <ref> [1] </ref>. 3.2 Spring Naming Service Spring provides a uniform name service. Any object can be bound to any name. This applies whether the object is local to a process, local to a machine, or resident elsewhere in the network.
Reference: [2] <author> G. Beedubail, P. Kessler, and U. Pooch, </author> <title> "Object replication in spring using subcontracts," </title> <type> Technical Report TR95-041, </type> <institution> Computer Science Department,Texas A&M University, </institution> <month> Septem-ber </month> <year> 1995. </year>
Reference-contexts: Thus we hope the lessons learned from replicating the name service could be applied to replicating any general object. This work was motivated when we were designing a framework for object replication in Spring. The details of this work can be found in <ref> [2] </ref>. There we assumed that, we have a fault tolerant naming service (FTNS) available. This is the normal assumption made in most of the replication algorithms either implicitly or explicitly [3, 4, 5, 6, 7, 8, 9, 10]. Thus to make our scheme in [2] work, we needed to implement a <p> this work can be found in <ref> [2] </ref>. There we assumed that, we have a fault tolerant naming service (FTNS) available. This is the normal assumption made in most of the replication algorithms either implicitly or explicitly [3, 4, 5, 6, 7, 8, 9, 10]. Thus to make our scheme in [2] work, we needed to implement a FTNS. We choose the replication scheme for providing FTNS because replication provides higher availability compared to checkpointing [11] scheme. Since replicated objects are available on multiple machines, they may be able to share the load of client requests.
Reference: [3] <author> K. P. Birman et al., </author> <title> "Implementing fault-tolerant distributed objects," </title> <journal> IEEE Trans. Softw. Eng., </journal> <volume> vol. 6, no. 11, </volume> <pages> pp. 502-508, </pages> <month> June </month> <year> 1985. </year>
Reference-contexts: The details of this work can be found in [2]. There we assumed that, we have a fault tolerant naming service (FTNS) available. This is the normal assumption made in most of the replication algorithms either implicitly or explicitly <ref> [3, 4, 5, 6, 7, 8, 9, 10] </ref>. Thus to make our scheme in [2] work, we needed to implement a FTNS. We choose the replication scheme for providing FTNS because replication provides higher availability compared to checkpointing [11] scheme. <p> Operations on the log are applied to the system in the background. Thus the disk access is removed from the critical path and good response time is achieved. In <ref> [3] </ref>, Birman et. al. describe a technique to implement k-resilient distributed objects. They use a coordinator-cohort scheme, a variation of the primary-backup scheme.
Reference: [4] <author> M. C. Little, </author> <title> Object Replication in a Distributed System, </title> <type> PhD thesis, </type> <institution> Computer Science Dept., University of Newcastle upon Tyne, </institution> <month> September </month> <year> 1991. </year>
Reference-contexts: The details of this work can be found in [2]. There we assumed that, we have a fault tolerant naming service (FTNS) available. This is the normal assumption made in most of the replication algorithms either implicitly or explicitly <ref> [3, 4, 5, 6, 7, 8, 9, 10] </ref>. Thus to make our scheme in [2] work, we needed to implement a FTNS. We choose the replication scheme for providing FTNS because replication provides higher availability compared to checkpointing [11] scheme. <p> A higher level application protocol should make sure that all the replicas get their client calls in the same order. In [5] Bir-man et. al. describe how totally ordered, reliable broadcasts can be used to maintain replicated data (active replication). Object replication in the Arjuna <ref> [4] </ref> uses active replication 5 . The replication algorithm uses the support of naming and binding service and the atomic action service provided by Arjuna system. A higher level group locking protocol (issued by the application program) avoids the need for a reliable ordered broadcast. <p> The reader can refer to [17, 18] for additional reading on replication. The naming and binding service of Arjuna [19] and the directory service of Amoeba [16] provide the same (conceptual) functionality as our RNS. In [19] reliability is achieved by atomic transactions provided by Arjuna <ref> [4] </ref> and in [16] the service is implemented using the reliable communication service provided by the underlying system. Similarly all of the above work uses the reliable ordered multicast, atomic transaction two or more phases of message exchanges for achieving the object replication. Some researchers assume synchronized clocks [6, 14].
Reference: [5] <author> T. Joseph and K. Birman, </author> <title> "Exploiting replication in distributed systems," In Distributed Systems, </title> <editor> S. Mullender, </editor> <booktitle> editor, </booktitle> <pages> pp. 319-367, </pages> <publisher> Addison-Wesley, </publisher> <year> 1988. </year> <month> 13 </month>
Reference-contexts: The details of this work can be found in [2]. There we assumed that, we have a fault tolerant naming service (FTNS) available. This is the normal assumption made in most of the replication algorithms either implicitly or explicitly <ref> [3, 4, 5, 6, 7, 8, 9, 10] </ref>. Thus to make our scheme in [2] work, we needed to implement a FTNS. We choose the replication scheme for providing FTNS because replication provides higher availability compared to checkpointing [11] scheme. <p> The circus system described by Cooper [9] is an example of active replication. Here, all the replicas (called the members of a troupe) execute the client calls independently. A higher level application protocol should make sure that all the replicas get their client calls in the same order. In <ref> [5] </ref> Bir-man et. al. describe how totally ordered, reliable broadcasts can be used to maintain replicated data (active replication). Object replication in the Arjuna [4] uses active replication 5 . The replication algorithm uses the support of naming and binding service and the atomic action service provided by Arjuna system.
Reference: [6] <author> N. Budhiraja et al., </author> <title> "The primary-backup approach," In Distributed Systems, 2ed Edition, </title> <editor> S. Mullender, </editor> <booktitle> editor, </booktitle> <pages> pp. 199-216, </pages> <publisher> Addison-Wesley, </publisher> <year> 1993. </year>
Reference-contexts: The details of this work can be found in [2]. There we assumed that, we have a fault tolerant naming service (FTNS) available. This is the normal assumption made in most of the replication algorithms either implicitly or explicitly <ref> [3, 4, 5, 6, 7, 8, 9, 10] </ref>. Thus to make our scheme in [2] work, we needed to implement a FTNS. We choose the replication scheme for providing FTNS because replication provides higher availability compared to checkpointing [11] scheme. <p> Alsberg and Day [13] proposed one of the earliest primary-backup protocols. The paper presents the error detection and recovery schemes for two-host resiliency (tolerating one failure) and the extension of this concept to n hosts. In <ref> [6] </ref>, Budhiraja et. al. present some theoretical aspects of the primary backup approach. Their system assumes closely synchronized clocks in the system. <p> Similarly all of the above work uses the reliable ordered multicast, atomic transaction two or more phases of message exchanges for achieving the object replication. Some researchers assume synchronized clocks <ref> [6, 14] </ref>. Our work uses higher level communication primitive (i.e., is RPC) for implementing the fault tolerant master-slave (primary-backup) replica consistency algorithm (this is a one-phase protocol).
Reference: [7] <author> K. Yap, P. Jalote, and S. Tripati, </author> <title> "Fault tolerant remote procedure call," </title> <booktitle> In International Conf. Distributed Computing Systems, </booktitle> <pages> pp. 48-54, </pages> <year> 1988. </year>
Reference-contexts: The details of this work can be found in [2]. There we assumed that, we have a fault tolerant naming service (FTNS) available. This is the normal assumption made in most of the replication algorithms either implicitly or explicitly <ref> [3, 4, 5, 6, 7, 8, 9, 10] </ref>. Thus to make our scheme in [2] work, we needed to implement a FTNS. We choose the replication scheme for providing FTNS because replication provides higher availability compared to checkpointing [11] scheme.
Reference: [8] <author> F. Schneider, </author> <title> "Implementing fault tolerant services using the state machine approach: A tutorial," </title> <journal> ACM Computing Surveys, </journal> <volume> vol. 22, no. 4, </volume> <pages> pp. 299-319, </pages> <month> December </month> <year> 1990. </year>
Reference-contexts: The details of this work can be found in [2]. There we assumed that, we have a fault tolerant naming service (FTNS) available. This is the normal assumption made in most of the replication algorithms either implicitly or explicitly <ref> [3, 4, 5, 6, 7, 8, 9, 10] </ref>. Thus to make our scheme in [2] work, we needed to implement a FTNS. We choose the replication scheme for providing FTNS because replication provides higher availability compared to checkpointing [11] scheme. <p> This approach is known as active replication or the state machine approach <ref> [8] </ref>. 2) Designate one server as the primary and all others as backups. Clients make requests by sending messages only to the primary. The primary forwards the requests to the backups (so that, backups can synchronize their state with the primary) and then responds to the client 3 .
Reference: [9] <author> E. C. Cooper, </author> <title> "Replicated distributed programs," </title> <booktitle> In ACM Symp. on Oper. Syst. Princ., </booktitle> <pages> pp. 63-78, </pages> <year> 1985. </year>
Reference-contexts: The details of this work can be found in [2]. There we assumed that, we have a fault tolerant naming service (FTNS) available. This is the normal assumption made in most of the replication algorithms either implicitly or explicitly <ref> [3, 4, 5, 6, 7, 8, 9, 10] </ref>. Thus to make our scheme in [2] work, we needed to implement a FTNS. We choose the replication scheme for providing FTNS because replication provides higher availability compared to checkpointing [11] scheme. <p> In [15], Spiewak describes a framework for replicating objects in Spring OS using primary backup algorithm. Here the replicas are periodically updated. Thus the replicas will not always be in a mutually consistent state. The circus system described by Cooper <ref> [9] </ref> is an example of active replication. Here, all the replicas (called the members of a troupe) execute the client calls independently. A higher level application protocol should make sure that all the replicas get their client calls in the same order.
Reference: [10] <author> G. Beedubail et al., </author> <title> "Fault tolerant objects in distributed systems using hot replication," </title> <booktitle> In Proc. of 15th Int'l Phoenix Conf. on Computers and Communications (IPCCC'96), </booktitle> <address> Phoenix, AZ, </address> <month> March </month> <year> 1996. </year>
Reference-contexts: The details of this work can be found in [2]. There we assumed that, we have a fault tolerant naming service (FTNS) available. This is the normal assumption made in most of the replication algorithms either implicitly or explicitly <ref> [3, 4, 5, 6, 7, 8, 9, 10] </ref>. Thus to make our scheme in [2] work, we needed to implement a FTNS. We choose the replication scheme for providing FTNS because replication provides higher availability compared to checkpointing [11] scheme. <p> The coordinator also forwards the result of any external action to the cohorts (called retained results). Thus the cohorts will have all the information to take over as a coordinator if the original coordinator fails. In <ref> [10] </ref>, Beedubail et. al. extend the primary backup protocol for nested object invocation (i.e., to service a client request object can invoke the services of other objects). That scheme assumes the existence of a reliable multicast and a fault tolerant naming service.
Reference: [11] <author> G. Beedubail et al., </author> <title> "An algorithm for supporting fault tolerant objects in distributed object oriented operating systems," </title> <booktitle> In Proc. of International Workshop on Object-Orientation in Operating Systems, </booktitle> <month> August </month> <year> 1995. </year>
Reference-contexts: Thus to make our scheme in [2] work, we needed to implement a FTNS. We choose the replication scheme for providing FTNS because replication provides higher availability compared to checkpointing <ref> [11] </ref> scheme. Since replicated objects are available on multiple machines, they may be able to share the load of client requests. The scope of this work was to develop a fault tolerant naming service that can be shared by all the Spring machines in a network.
Reference: [12] <author> A. D. Birrel and B. J. Nelson, </author> <title> "Implementing remote procedure calls," </title> <journal> ACM Transactions on Computer Systesm, </journal> <volume> vol. 2, no. 1, </volume> <pages> pp. 39-59, </pages> <month> February </month> <year> 1984. </year>
Reference-contexts: Thus many of the system vendors provide RPC support either directly in their Operating System (e.g.:SUN RPC) or as a middleware (e.g.: OSF DCE RPC). A detailed discussion about RPC is given in <ref> [12] </ref>. In our algorithm, processes communicate only when it is necessary (no periodic messages for detecting failures). Thus if there is no (useful) activity (client requests) in the system, no communication takes place, even when the servers fail.
Reference: [13] <author> P. Alsberg and J. Day, </author> <title> "A principle for resilient sharing of distributed resrources," </title> <booktitle> In Proc. Of Second Intl' Conf. on Software Engg., </booktitle> <address> San Francisco, CA., </address> <pages> pp. 562-570, </pages> <year> 1976. </year>
Reference-contexts: If the primary fails, then one of the backups becomes the primary. This approach is known as the primary-backup or the primary copy approach <ref> [13] </ref>. All the research on object replication are variations or combinations of the above two basic strategies 4 . Alsberg and Day [13] proposed one of the earliest primary-backup protocols. <p> If the primary fails, then one of the backups becomes the primary. This approach is known as the primary-backup or the primary copy approach <ref> [13] </ref>. All the research on object replication are variations or combinations of the above two basic strategies 4 . Alsberg and Day [13] proposed one of the earliest primary-backup protocols. The paper presents the error detection and recovery schemes for two-host resiliency (tolerating one failure) and the extension of this concept to n hosts. In [6], Budhiraja et. al. present some theoretical aspects of the primary backup approach.
Reference: [14] <author> B. Liskov et al., </author> <title> "Replication in the harp file system," </title> <type> Technical Report MIT/LCS/TM-456, </type> <institution> Massachusetts Institute Of Technology, </institution> <month> August </month> <year> 1991. </year>
Reference-contexts: Their system assumes closely synchronized clocks in the system. They classify the primary-backup algorithms as blocking and non-blocking and provide lower bounds (under various failure conditions) on the degree of replication, blocking time and failover time for any primary-backup algorithm. The Harp File System also uses a primary-backup protocol <ref> [14] </ref>. It is assumed that the system clocks are closely synchronized and all the machines are equipped with a uninterrupted power supply (UPS). The protocol keeps a log of updates on volatile memory (the UPS is necessary to write back this log to disk in case of power failure). <p> Similarly all of the above work uses the reliable ordered multicast, atomic transaction two or more phases of message exchanges for achieving the object replication. Some researchers assume synchronized clocks <ref> [6, 14] </ref>. Our work uses higher level communication primitive (i.e., is RPC) for implementing the fault tolerant master-slave (primary-backup) replica consistency algorithm (this is a one-phase protocol).
Reference: [15] <author> J. S. Spiewak, </author> <title> "Replication in spring: A new subcontract," </title> <type> Technical Report CS-95-16, </type> <institution> Brown University, </institution> <month> May </month> <year> 1995. </year>
Reference-contexts: In [10], Beedubail et. al. extend the primary backup protocol for nested object invocation (i.e., to service a client request object can invoke the services of other objects). That scheme assumes the existence of a reliable multicast and a fault tolerant naming service. In <ref> [15] </ref>, Spiewak describes a framework for replicating objects in Spring OS using primary backup algorithm. Here the replicas are periodically updated. Thus the replicas will not always be in a mutually consistent state. The circus system described by Cooper [9] is an example of active replication.
Reference: [16] <author> M. F. Kaasshoek, A. S. Tanenbaum, and K. Verstoep, </author> <title> "Using group communication to implement a fault-tolerant directory service," </title> <booktitle> In International Conf. Distributed Computing Systems, </booktitle> <pages> pp. 130-139, </pages> <year> 1993. </year>
Reference-contexts: The replication algorithm uses the support of naming and binding service and the atomic action service provided by Arjuna system. A higher level group locking protocol (issued by the application program) avoids the need for a reliable ordered broadcast. In <ref> [16] </ref> Kaashoek et.al., describe the fault tolerant directory service implemented in the Amoeba distributed operating system. They use the closed group communication service supported in Amoeba to implement the directory service. The reader can refer to [17, 18] for additional reading on replication. <p> They use the closed group communication service supported in Amoeba to implement the directory service. The reader can refer to [17, 18] for additional reading on replication. The naming and binding service of Arjuna [19] and the directory service of Amoeba <ref> [16] </ref> provide the same (conceptual) functionality as our RNS. In [19] reliability is achieved by atomic transactions provided by Arjuna [4] and in [16] the service is implemented using the reliable communication service provided by the underlying system. <p> The reader can refer to [17, 18] for additional reading on replication. The naming and binding service of Arjuna [19] and the directory service of Amoeba <ref> [16] </ref> provide the same (conceptual) functionality as our RNS. In [19] reliability is achieved by atomic transactions provided by Arjuna [4] and in [16] the service is implemented using the reliable communication service provided by the underlying system. Similarly all of the above work uses the reliable ordered multicast, atomic transaction two or more phases of message exchanges for achieving the object replication. Some researchers assume synchronized clocks [6, 14].
Reference: [17] <author> T. Mann, A. Hisgen, and G. Swart, </author> <title> "An algorithm for data replication," </title> <type> Technical Report 46, </type> <institution> DEC Systems Research Center, </institution> <address> Palo Alto, CA, </address> <month> June </month> <year> 1989. </year>
Reference-contexts: In [16] Kaashoek et.al., describe the fault tolerant directory service implemented in the Amoeba distributed operating system. They use the closed group communication service supported in Amoeba to implement the directory service. The reader can refer to <ref> [17, 18] </ref> for additional reading on replication. The naming and binding service of Arjuna [19] and the directory service of Amoeba [16] provide the same (conceptual) functionality as our RNS.
Reference: [18] <author> E. N. Elnozahy and W. Zwaenepoel, </author> <title> "Replicated distributed processes in manetho," </title> <booktitle> In Digest of papers: The 22 nd Int. Symp. Fault-Tolerant Comp., </booktitle> <pages> pp. 18-27, </pages> <year> 1992. </year>
Reference-contexts: In [16] Kaashoek et.al., describe the fault tolerant directory service implemented in the Amoeba distributed operating system. They use the closed group communication service supported in Amoeba to implement the directory service. The reader can refer to <ref> [17, 18] </ref> for additional reading on replication. The naming and binding service of Arjuna [19] and the directory service of Amoeba [16] provide the same (conceptual) functionality as our RNS.
Reference: [19] <author> M.C.Little, D.L.McCue, and S. Shrivastava, </author> <title> "Maintaining information about persistent replicated objects in a distributed system," </title> <booktitle> In International Conf. Distributed Computing Systems, </booktitle> <pages> pp. 491-498, </pages> <year> 1993. </year>
Reference-contexts: They use the closed group communication service supported in Amoeba to implement the directory service. The reader can refer to [17, 18] for additional reading on replication. The naming and binding service of Arjuna <ref> [19] </ref> and the directory service of Amoeba [16] provide the same (conceptual) functionality as our RNS. In [19] reliability is achieved by atomic transactions provided by Arjuna [4] and in [16] the service is implemented using the reliable communication service provided by the underlying system. <p> The reader can refer to [17, 18] for additional reading on replication. The naming and binding service of Arjuna <ref> [19] </ref> and the directory service of Amoeba [16] provide the same (conceptual) functionality as our RNS. In [19] reliability is achieved by atomic transactions provided by Arjuna [4] and in [16] the service is implemented using the reliable communication service provided by the underlying system.
Reference: [20] <author> S. Radia, M. Nelson, and M. Powell, </author> <title> "The spring name service," </title> <type> Technical Report SMLI-9316, </type> <institution> Sun Microsystems Laboratories, </institution> <year> 1993. </year>
Reference-contexts: In Spring, the NS is implemented by one or more object managers called name servers. Name servers implement the context objects. Figure 1 shows a naming graph partitioned into three parts, implemented by two name servers <ref> [20] </ref>. For more details about Spring NS refer to [20]. 5 by this context is implemented in name server 2 and name server 1. 3.3 Overview of Replicated Naming Service (RNS) In this section we will briefly discuss our design for the replication of the NS in Spring. <p> In Spring, the NS is implemented by one or more object managers called name servers. Name servers implement the context objects. Figure 1 shows a naming graph partitioned into three parts, implemented by two name servers <ref> [20] </ref>. For more details about Spring NS refer to [20]. 5 by this context is implemented in name server 2 and name server 1. 3.3 Overview of Replicated Naming Service (RNS) In this section we will briefly discuss our design for the replication of the NS in Spring. First we will describe how the RNS appears to the user. <p> Thus we used the inheritance feature of the IDL. Figure 3 shows our inheritance diagram. The naming context interface currently implements all the functions required by a naming service <ref> [20] </ref>. repl ctx mgr implements the server for the RNS. Since it inherits from naming context, all the NS operations are available in repl ctx mgr. The repl ctx mgr also implements the replica consistency algorithm.
Reference: [21] <author> G. Hamilton, M. Powell, and J. Mitchell, "Subcontract: </author> <title> A flexible base for distributed programming," </title> <booktitle> In Proc. of 14th Symposium on Operating Systems Principles, </booktitle> <month> December </month> <year> 1993. </year> <month> 14 </month>
Reference-contexts: The transparency is achieved by dynamically loading the replica consistency protocol module when the client is accessing a replicated service (the Spring subcontract 6 This is achieved by the subcontract facility provided by the Spring OS. The details of subcontract mechanism is given in <ref> [21] </ref>. Understanding of subcontract is not necessary for our discussion here. 8 performs the dynamic loading). 4 Fault Tolerant Replica Consistency Algorithm In this section we will describe the working logic of our replica consistency algorithm. The appendix shows the detailed pseudo code and the proof sketch for the protocol.
References-found: 21

