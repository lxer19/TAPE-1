URL: ftp://das-ftp.harvard.edu/techreports/tr-10-92.ps.gz
Refering-URL: http://www.umiacs.umd.edu/research/EXPAR/papers/3548/node18.html
Root-URL: 
Title: Direct Bulk-Synchronous Parallel Algorithms  
Author: Alexandros V. Gerbessiotis and Leslie G. Valiant 
Address: Cambridge, Massachusetts  
Affiliation: Center for Research in Computing Technology Harvard University  
Pubnum: TR-10-92  
Abstract-found: 0
Intro-found: 0
Reference: [1] <author> R. Aleliunas. </author> <title> Randomized parallel computation. </title> <booktitle> In ACM SIGACT-SIGOPS Symposium on Principles of Distributed Computing, </booktitle> <pages> pages 60-72, </pages> <month> August </month> <year> 1982. </year> <month> q </month>
Reference-contexts: This ensures that there is never any contention at the destination processors. We shall analyse the performance of this algorithm using the delay sequence argument introduced in <ref> [1] </ref>, [15]. We construct a directed graph where each task (j; k) is a node.
Reference: [2] <author> Richard J. Anderson and Gary L. Miller. </author> <title> Optical communication for pointer based algorithms. </title> <type> Technical Report CRI 88-14, </type> <year> 1988. </year>
Reference-contexts: Any component that has more than one message directed at it fails to receive any of them and sends no acknowledgement. This model was suggested by Anderson and Miller <ref> [2] </ref> and also discussed by Hartmann and Redfield [7]. It models a variety of schemes for optical interconnects (eg [7], [11], [12]) that have been proposed for efficient all-to-all dynamic communication (although at present none of them is competitive with electronic methods).
Reference: [3] <author> D. Angluin and L. G. Valiant. </author> <title> Fast probabilistic algorithms for Hamiltonian circuits and matchings. </title> <journal> J. Computer and System Sciences, </journal> <volume> 18 </volume> <pages> 155-193, </pages> <year> 1979. </year>
Reference-contexts: We then use the following bound for the right tail of the binomial distribution <ref> [3] </ref>.
Reference: [4] <editor> Martin Dietzfelbinger and Friedhelm Meyer auf der Heide. </editor> <title> A new universal class of hash functions and dynamic hashing in real time. </title> <booktitle> International Colloqium on Automata, Languages and Programming, </booktitle> <volume> 443 </volume> <pages> 6-19, </pages> <year> 1990. </year>
Reference-contexts: The time bounds hold with high probability assuming the availability of easily computed hash functions, that behave as perfect random functions when distributing addresses to memory blocks. We can use functions as in <ref> [4] </ref>, or use pipelining to evaluate several applications at a time of a possibly less easily computed hash function. Let log x, lg x be the logarithms of x to the base e and two respectively.
Reference: [5] <author> G. C. Fox, M. A. Johnson, G. A. Lyzenga, S. W. Otto, J. K. Salmon, and D. W. Walker. </author> <title> Solving Problems on Concurrent Processors, Vol 1: General Techniques and Regular Problems. </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, New Jersey, </address> <year> 1988. </year>
Reference-contexts: Below we show that even if pivoting is added the BSP can execute this algorithm one-optimally within a suitable range of parameters. The algorithm uses a scattered distribution of the data among the processors to even out processor utilisation (c.f. <ref> [5] </ref>). For simplicity we shall assume here that p p p are both integers and that p is a power of two.
Reference: [6] <author> W. D. Frazer and A. C. McKellar. Samplesort: </author> <title> A sampling approach to minimal storage tree sorting. </title> <journal> Journal of the ACM, </journal> <volume> 17:3:496-507, </volume> <year> 1970. </year>
Reference-contexts: The algorithm is one-optimal in computation, when comparison and arithmetic operations are counted, for a range of the parameters p, n and L, and also one-optimal in communication if g is appropriately bounded. The algorithm derives from quicksort <ref> [6] </ref> and uses the technique of over-sampling previously used in [[14], [9]] in a parallel context. Let X = fx 1 ; : : : ; x N g be a set of input keys ordered such that x i &lt; x i+1 , for 1 i N 1. <p> The following was proved in <ref> [6] </ref>: Claim 1 For all i, p i (j) = p (j) = s1 (k1) s1 N : It can be deduced that for any 0 &lt; * &lt; 1 the sum of p (j), for j &gt; d (1 + *)(N k + 1)=ke is bounded above by N p
Reference: [7] <author> Alfred Hartmann and Steve Redfield. </author> <title> Design sketches for optical crossbar switches intended for large scale parallel processing applications. Optical Engineering, </title> <address> 29:3:315-327, </address> <month> April </month> <year> 1989. </year>
Reference-contexts: Any component that has more than one message directed at it fails to receive any of them and sends no acknowledgement. This model was suggested by Anderson and Miller [2] and also discussed by Hartmann and Redfield <ref> [7] </ref>. It models a variety of schemes for optical interconnects (eg [7], [11], [12]) that have been proposed for efficient all-to-all dynamic communication (although at present none of them is competitive with electronic methods). <p> Any component that has more than one message directed at it fails to receive any of them and sends no acknowledgement. This model was suggested by Anderson and Miller [2] and also discussed by Hartmann and Redfield <ref> [7] </ref>. It models a variety of schemes for optical interconnects (eg [7], [11], [12]) that have been proposed for efficient all-to-all dynamic communication (although at present none of them is competitive with electronic methods). Since the S fl PRAM seems an elegant and potentially important model the question of simulating the BSP on it is of interest.
Reference: [8] <author> C. A. R. Hoare. </author> <title> Quicksort. </title> <journal> Computer Journal, </journal> <volume> 5 </volume> <pages> 10-15, </pages> <year> 1962. </year>
Reference-contexts: The cost is that of sequential sorting by some algorithm such as <ref> [8] </ref>, [18]. ] Stage 1 : The P = Right Left + 1 processors participating in this call send between them a set of k s of their elements, randomly chosen, to processor Left. [ Analysis of Stage 1: This stage is itself a superstep.
Reference: [9] <author> J. S. Huang and Y. C. Chow. </author> <title> Parallel sorting and data partitioning by sampling. </title> <booktitle> IEEE Computer Society's Seventh International Computer Software and Applications Conference, </booktitle> <pages> pages 627-631, </pages> <month> November </month> <year> 1983. </year>
Reference-contexts: The algorithm is one-optimal in computation, when comparison and arithmetic operations are counted, for a range of the parameters p, n and L, and also one-optimal in communication if g is appropriately bounded. The algorithm derives from quicksort [6] and uses the technique of over-sampling previously used in [[14], <ref> [9] </ref>] in a parallel context. Let X = fx 1 ; : : : ; x N g be a set of input keys ordered such that x i &lt; x i+1 , for 1 i N 1.
Reference: [10] <author> V. F. Kolchin, B. A. Sevastyanov, and V. P. Chistyakov. </author> <title> Random Allocations. Translation ed. A.V. </title> <publisher> Balakrsishnan, Halsted Press, </publisher> <year> 1978. </year>
Reference-contexts: This follows from the fact (see <ref> [10] </ref>, page 96, for a proof) that if, for any constant c, cp log p balls are thrown randomly into p urns then with some constant probability there will be at least c 1 (c) log p balls in at least one urn for some c 1 (c) &gt; c. <p> Also, the randomly chosen samples need not be assembled at one processor, prior to being distributed for parallel sorting. Their random selection could be performed in parallel also (e.g. [14]). Acknowledgement We are grateful to Thanasis Tsantilas for helpful discussions on similar parallel sorting algorithms and for bringing reference <ref> [10] </ref> to our attention.
Reference: [11] <author> Richard A. Linke. </author> <title> Power distribution in a planar-waveguide based broadcast star network. </title> <journal> IEEE Photonics Technology Letters, </journal> <volume> 3:9:850-852, </volume> <month> September </month> <year> 1991. </year>
Reference-contexts: Any component that has more than one message directed at it fails to receive any of them and sends no acknowledgement. This model was suggested by Anderson and Miller [2] and also discussed by Hartmann and Redfield [7]. It models a variety of schemes for optical interconnects (eg [7], <ref> [11] </ref>, [12]) that have been proposed for efficient all-to-all dynamic communication (although at present none of them is competitive with electronic methods). Since the S fl PRAM seems an elegant and potentially important model the question of simulating the BSP on it is of interest.
Reference: [12] <author> Eric S. Maniloff, Kristina M. Johnson, and J. H. Reif. </author> <title> Holographic routing network for parallel processing machines. In Holographic Optics II: </title> <booktitle> Principles and Applications, Proc. </booktitle> <editor> SPIE (G. M. Morris, ed.), </editor> <volume> 1136 </volume> <pages> 283-289, </pages> <year> 1989. </year>
Reference-contexts: This model was suggested by Anderson and Miller [2] and also discussed by Hartmann and Redfield [7]. It models a variety of schemes for optical interconnects (eg [7], [11], <ref> [12] </ref>) that have been proposed for efficient all-to-all dynamic communication (although at present none of them is competitive with electronic methods). Since the S fl PRAM seems an elegant and potentially important model the question of simulating the BSP on it is of interest.
Reference: [13] <author> D. Nassimi and S. Sahni. </author> <title> Parallel permutation and sorting algorithms and a new generalized connection network. </title> <journal> Journal of the ACM, </journal> <volume> 29:3:642:667, </volume> <month> July </month> <year> 1982. </year>
Reference-contexts: In appropriate circumstances its performance can be improved by any one of a variety of alternative methods. For example the sorting of the samples could be performed by parallel algorithms either by using our algorithm recursively, or some completely different one (e.g. <ref> [13] </ref>). Also, the randomly chosen samples need not be assembled at one processor, prior to being distributed for parallel sorting. Their random selection could be performed in parallel also (e.g. [14]).
Reference: [14] <author> J. H. Reif and L. G. Valiant. </author> <title> A logarithmic time sort for linear size networks. </title> <journal> Journal of the ACM, </journal> <volume> 34 </volume> <pages> 60-76, </pages> <month> January </month> <year> 1987. </year>
Reference-contexts: Also, the randomly chosen samples need not be assembled at one processor, prior to being distributed for parallel sorting. Their random selection could be performed in parallel also (e.g. <ref> [14] </ref>). Acknowledgement We are grateful to Thanasis Tsantilas for helpful discussions on similar parallel sorting algorithms and for bringing reference [10] to our attention.
Reference: [15] <author> E. Upfal. </author> <title> Efficient schemes for parallel communication. </title> <booktitle> In ACM SIGACT-SIGOPS Symposium on Principles of Distributed Computing, </booktitle> <pages> pages 55-59, </pages> <month> August </month> <year> 1982. </year>
Reference-contexts: This ensures that there is never any contention at the destination processors. We shall analyse the performance of this algorithm using the delay sequence argument introduced in [1], <ref> [15] </ref>. We construct a directed graph where each task (j; k) is a node.
Reference: [16] <author> L. G. Valiant. </author> <title> General purpose parallel architectures. </title> <booktitle> In Handbook of Theoretical Computer Science (J. </booktitle> <editor> van Leeuwen, ed.), </editor> <publisher> North Holland, </publisher> <pages> pages 945-971, </pages> <year> 1990. </year>
Reference-contexts: If h 1 is the maximum number sent and h 2 the maximum number received we are taking h = maxfh 1 ; h 2 g here, although h = h 1 + h 2 is possible too <ref> [16] </ref>. <p> We note that time g is charged for each message delivery (when performed in bulk). When we discuss "time", in this context, as the number of such operations, this extra factor of g is implied as far as actual time. i) The simulation is the one given in <ref> [16] </ref>. After the distribution of w p log p tasks to each processor of the BSP , as described above, these tasks are completed in one superstep.
Reference: [17] <author> L. G. Valiant. </author> <title> A bridging model for parallel computation. </title> <journal> Communications of the ACM, </journal> <volume> 33 </volume> <pages> 103-111, </pages> <month> August </month> <year> 1990. </year>
Reference-contexts: 1 The Model The bulk-synchronous parallel or BSP model as described in <ref> [17] </ref> consists of three parts: (i) a number of processor/memory components. <p> These message transmissions, however, would have to respect the superstep rules. 2 Background The BSP model was originally suggested as a possible "bridging" model to serve as a standard interface between the language and architecture levels in parallel computation. Two modes of programming were envisaged <ref> [17] </ref>: automatic mode where programs are written in a high level language that hides memory distribution from the user (e.g. PRAM style), and direct mode where the programmer retains control of memory allocation. This paper is concerned with the direct mode. <p> The two routing operations take time at most g (ndn=pe + pdn=pe) g (n 2 =p + n + n + p) which gives the claimed bound on . 5 Broadcasting and Parallel Prefix BSP algorithms for broadcasting and parallel prefix were discussed in <ref> [17] </ref>. The broadcasting algorithm uses a t-ary tree, for some appropriate t. The initial message is at the root and in each superstep t copies of each existing copy of the message is made and sent to t distinct processors.
Reference: [18] <author> M. H. van Emden. </author> <title> Increasing the efficiency of quicksort. </title> <journal> Communications of the ACM, </journal> <volume> 13:9:563-567, </volume> <year> 1970. </year>
Reference-contexts: The cost is that of sequential sorting by some algorithm such as [8], <ref> [18] </ref>. ] Stage 1 : The P = Right Left + 1 processors participating in this call send between them a set of k s of their elements, randomly chosen, to processor Left. [ Analysis of Stage 1: This stage is itself a superstep.
References-found: 18

