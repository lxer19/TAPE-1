URL: ftp://ftp.ai.univie.ac.at/papers/oefai-tr-92-37.ps.Z
Refering-URL: http://www.ai.univie.ac.at/cgi-bin/biblio_ora/?author=Pfahringer&sort_by_year=yes&tailor=1&keyword=bp_lit&loc=0
Root-URL: 
Email: bernhard@ai.univie.ac.at, john@ai.univie.ac.at  
Phone: Tel: +43-1-533 61 12  
Title: A CLP Schema to Integrate Specialized Solvers and its Application to Natural Language Processing  
Author: Bernhard Pfahringer, Johannes Matiasek 
Date: December 28, 1992  
Address: Schottengasse 3, A-1010 Vienna, Austria  
Affiliation: Austrian Research Institute for Artificial Intelligence  
Abstract: The problem of combining different constraint solvers has been mentioned among others by [25], [13], [17], [20] without giving satisfactory solutions. We propose a general framework for implementing specialized reasoners/constraint solvers in a logic programming environment using semantic unification. It allows for a modular and declarative definition of the interactions of such reasoners. This is achieved by by using attributed variables [15] as a data-structure relating a variable to the set of all constraints for this variable. Conditional rewrite rules specify simplification and possible interactions of these constraints. A few examples will demonstrate constraints relating to single variables and interactions thereof. We will demonstrate, how this framework leads to a very natural and concise formulation of principles, grammar and lexicon in a hpsg like formalism. Furthermore the necessity of extending the framework to handle constraints relating two or more variables will be discussed. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Balari S., Varile G.B., Damas L., Moreira N.: CLG(n): </author> <title> Constraint Logic Grammars, </title> <booktitle> in Karlgren H.(ed.), Proceedings of the 13th International Conference on Computational Linguistics, </booktitle> <institution> University of Helsinki, Finland, pp.7-12, </institution> <year> 1990. </year>
Reference-contexts: The declarative specification of the principles as they are suffices. 10 Comparing our approach to the implementation of hpsg described in <ref> [1] </ref>, we note the following advantage of our approach: In contrary to their problems of gaining reasonable efficiency our approach benefits from what could be called indexing. Every variable is related to exactly those constraints that are relevant for this variable and to no other constraint whatsoever.
Reference: [2] <author> Berwick R.: </author> <title> Principles of Principle-Based Parsing, </title> <editor> in Berwick R., Abney S., Tenny C.: </editor> <title> Principle-Based Parsing, </title> <publisher> Kluwer, </publisher> <address> Dordrecht, </address> <year> 1991. </year>
Reference-contexts: Instead they model 7 language by (possibly typed) feature structures and rely on unification as the operation to combine these feature structures. Phrase structure rules are replaced by the lexicon and by universal and language specific principles <ref> [2] </ref>. Subcategorization requirements (i.e. which arguments a word may take) are specified in the lexicon. The principles constrain the feature structures themselves, thus restricting the possible combinations and shapes of feature structures to the grammatical ones.
Reference: [3] <author> Bratko I., Mozetic I., Lavrac N.: </author> <title> Kardio A Study in Deep and Qualitative Knowledge for Expert Systems, </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1989. </year>
Reference-contexts: But there remains a second question to be answered. Can comparable efficiency be achieved? We have done a proof-of-concept implementation. Avars are used as a low-level device to implement an interpreter handling our generalized rewrite rules. As a testbed for simple domain-variables we chose the KARDIO system <ref> [3] </ref>, where diagnosis considerably benefits from pruning of the search space due to domain variable interactions. First results were not encouraging, runtimes were 2.5 times larger than for the low-level implementation.
Reference: [4] <author> Buchberger E., Garner E., Heinz W., Matiasek J., Pfahringer B.: </author> <title> VIE-DU Dialogue by Unification, </title> <booktitle> in Kaindl H.(ed.), 7. </booktitle> <address> Osterreichische Artificial-Intelligence-Tagung, </address> <publisher> Springer, </publisher> <address> Berlin, pp.42-51, </address> <year> 1991. </year>
Reference-contexts: have to be well-typed , that means every (non-atomic) type determines which attibutes are admissible for it, and which types the values of these attributes must belong to, e.g. sign ==&gt; [phon: phon, synsem: synsem]. 2 The implementation described here is used within the natural language consulting system VieDU (cf. <ref> [4] </ref>) being developed at the Austrian Research Institute for Artificial Intelligence, for further details of the grammar itself see [10]. 8 word ==&gt; []. phrase ==&gt; [dtrs: const_struc]. headed_phrase ==&gt; [dtrs: headed_struc]. Subtypes inherit the slots of their supertypes.
Reference: [5] <author> Carlsson M., Widen J.: </author> <title> Sicstus Prolog Users Manual , Swedish Institute of Computer Science, </title> <address> SICS/R-88/88007C, </address> <year> 1990. </year>
Reference-contexts: An implementation in a modified version of SicstusProlog <ref> [5] </ref> is described in [14]. Instead of metaterms attributed variables (abbrevi-ated as avars from now on) are introduced as an additional data-type, which allow logical variables to be directly qualified by arbitrary user-defined attributes.
Reference: [6] <author> Colmerauer A.: </author> <title> Opening the Prolog III Universe, </title> <note> BYTE , August 1987. </note>
Reference-contexts: Let us have a look at two very simple solvers handling finite domains [11] and a very simple form of dif/2 <ref> [6] </ref> to understand problems of this approach in section 2. Section 3 will introduce our framework to remedy problems.
Reference: [7] <author> Dershowitz N.: </author> <title> Termination, </title> <booktitle> Proceedings Rewriting Techniques and Appli cations, </booktitle> <publisher> Springer, </publisher> <address> Heidelberg, </address> <year> 1985 </year>
Reference-contexts: Conditional rewrite rules allow for a declarative and modular specification of such an integration. Furthermore they open the possibility of using well-known algorithms and results from research in rewrite rule systems such as proving properties like termination <ref> [7] </ref>, completeness, etc. for solvers and combinations thereof. Right now we are investigating more interesting/complex constraint theories exhibiting interactions of two or more variables. These seem to fit into our framework, too, albeit less elegantly.
Reference: [8] <author> Elcock E.W., Hoddinott O.: </author> <title> Comments on Kornfeld's "Equality for Prolog": E-unification as a Mechanism for Augmenting the Prolog Search Strategy, </title> <booktitle> in Proceedings of the Fifth National Conference on Artificial Intelligence (AAAI-86), </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> Los Altos, CA, </address> <year> 1986. </year>
Reference-contexts: We will briefly sketch three different methods described in the literature and discuss their drawbacks. * Kornfeld's E-unification: [16] proposes the following way of extending uni fication. Any failed unification triggers an attempt to prove the equality of the terms using some defined equality theory. But <ref> [8] </ref> shows that this approach is unsound, incomplete, and unnecessarily inefficient. * Metaterms [13] and Metastructures [21] are both aimed at overcoming some of the problems with E-Unification. Since both approaches are very similar, we will restrain our discussion to metaterms.
Reference: [9] <author> Hanus M.: </author> <title> Improving Control of Logic Programs by Using Functional Logic Languages, </title> <editor> in Bruynooghe M. and Wirsing M.(eds.), </editor> <booktitle> Programming Language Implementation and Logic Programming, </booktitle> <publisher> Springer, LNCS 631, </publisher> <year> 1992. </year>
Reference-contexts: Allowing pairs of attributes to be rewritten to a single attribute allows of course for an arbitrary number of attributes to be rewritten to a single attribute and it is this feature that constitutes the power of this schema! This should be compared to languages like ALF <ref> [9] </ref>, where functional logic programs are proved by means of conditional rewrite rules, but which rewrite only single goals, thereby achieving power equivalent to Prolog programs annotated with wait-declarations like described in [19].
Reference: [10] <author> Heinz, W. and J. Matiasek: </author> <title> Argument Structure and Case Assignment in German, </title> <editor> in J. Nerbonne, K. Netter and C. Pollard (eds.), </editor> <title> German Grammar in HPSG, </title> <publisher> CSLI Lecture Notes, CSLI, </publisher> <address> Stanford, </address> <note> to appear. </note>
Reference-contexts: types the values of these attributes must belong to, e.g. sign ==&gt; [phon: phon, synsem: synsem]. 2 The implementation described here is used within the natural language consulting system VieDU (cf. [4]) being developed at the Austrian Research Institute for Artificial Intelligence, for further details of the grammar itself see <ref> [10] </ref>. 8 word ==&gt; []. phrase ==&gt; [dtrs: const_struc]. headed_phrase ==&gt; [dtrs: headed_struc]. Subtypes inherit the slots of their supertypes. The specifications have to be consistent with the type lattice of course.
Reference: [11] <editor> Hentenryck P.van, Dincbas M.: </editor> <booktitle> Domains in Logic Programming, in Proceed ings of the Fifth National Conference on Artificial Intelligence (AAAI-86), </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> Los Altos, CA, </address> <year> 1986. </year>
Reference-contexts: Let us have a look at two very simple solvers handling finite domains <ref> [11] </ref> and a very simple form of dif/2 [6] to understand problems of this approach in section 2. Section 3 will introduce our framework to remedy problems. <p> Section 3 will introduce our framework to remedy problems. Section 4 will apply this framework to natural language processing and finally section 5 will discuss results and give an outlook. 2 Finite Domains, Dif Finite domains are finite sets defining the set of legal values for a given variable <ref> [11] </ref>, [12]. Treatment of domain-variables is superficially simplified here, allowing only for attaching domains to variables and for unification of such variables.
Reference: [12] <author> Hentenryck P.van: </author> <title> Constraint Satisfaction in Logic Programming, </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1989. </year> <month> 13 </month>
Reference-contexts: Section 4 will apply this framework to natural language processing and finally section 5 will discuss results and give an outlook. 2 Finite Domains, Dif Finite domains are finite sets defining the set of legal values for a given variable [11], <ref> [12] </ref>. Treatment of domain-variables is superficially simplified here, allowing only for attaching domains to variables and for unification of such variables.
Reference: [13] <author> Holzbaur C.: </author> <title> Specification of Constraint Based Inference Mechanisms through Extended Unification, </title> <institution> Institut fuer Med.Kybernetik u. AI, Univer-sitaet Wien, Dissertation, </institution> <year> 1990. </year>
Reference-contexts: Any failed unification triggers an attempt to prove the equality of the terms using some defined equality theory. But [8] shows that this approach is unsound, incomplete, and unnecessarily inefficient. * Metaterms <ref> [13] </ref> and Metastructures [21] are both aimed at overcoming some of the problems with E-Unification. Since both approaches are very similar, we will restrain our discussion to metaterms. Metaterms are introduced as an additional data-type into the respective Prolog system in addition to logical variables, constants, and terms. <p> Cut-and-paste of appropriate code fragments is the only solution. Specifying possible interactions of attributes, which could presumably cut down the search space early on, is even more complicated, as it requires detailed knowledge of the protocol of the respective base attributes. The work-around proposed in both <ref> [13] </ref> and [25], namely introducing one monolithic attribute taking care of everything, is not a modular design and it is questionable if a specification of the correct behavior of this single monolithic attribute can be derived automatically from the definitions of the base attributes, at least when using such complex low-level <p> We only have to add one more rewrite rule: dom (L),difs (_,D) =&gt; dom (L1) :- remove_difs (L,D,L1). Now the same query yields: ?- domain (X,[1,2,3]), dif (X,3). attributes (X, [dom ([1,2])]) The formulation of the above examples in our framework compares very favorably to the one given in <ref> [13] </ref> with respect to the amount and complexity of user code. Certainly our framework is more adequate from a specificational point of view. But there remains a second question to be answered. Can comparable efficiency be achieved? We have done a proof-of-concept implementation.
Reference: [14] <author> Holzbaur C.: </author> <title> A Variant of SicstusProlog featuring Extensible Unification, </title> <institution> Institut fuer Med.Kybernetik u. AI, Universitaet Wien, </institution> <year> 1992. </year>
Reference-contexts: An implementation in a modified version of SicstusProlog [5] is described in <ref> [14] </ref>. Instead of metaterms attributed variables (abbrevi-ated as avars from now on) are introduced as an additional data-type, which allow logical variables to be directly qualified by arbitrary user-defined attributes. <p> Treatment of domain-variables is superficially simplified here, allowing only for attaching domains to variables and for unification of such variables. Using the modified SicstusProlog proposed in <ref> [14] </ref>, this can be specified by the following clauses: domain (X,L) :- attach_attribute (X,dom (X,L)). combine_attributes (dom (X1,L1),dom (X2,L2)) : detach_attribute (X1), X1 = X2, intersection (L1,L2,L3), L3 "== [], ( L3 = [SingleValue] -&gt; detach_attribute (X2), X2 = SingleValue ; update_attribute (X2,dom (X2,L3)) ). verify_attribute (dom (X,L),Value) : memberchk (Value,L),
Reference: [15] <author> Huitouze S.le: </author> <title> A new data structure for implementing extensions to Prolog, </title> <editor> in Deransart P., Maluszunski J.(eds.), </editor> <booktitle> Programming Language Implementation and Logic Programming, </booktitle> <publisher> Springer, Heidelberg, </publisher> <pages> 136-150, </pages> <year> 1990. </year>
Reference-contexts: Unification will dereference such chains of metaterms before trying to unify the respective terms. This specification is cognitively too complex and involved when compared to the typical usage of a metaterm: restricting the domain of possible values for a given logical variable. * Attributed Variables <ref> [15] </ref> provide a much simpler solution to the problem than metaterms. An implementation in a modified version of SicstusProlog [5] is described in [14].
Reference: [16] <author> Kornfeld W.A.: </author> <title> Equality for Prolog, </title> <booktitle> in Proceedings of the 8th International Joint Conference on Artificial Intelligence, </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> Los Altos, CA, </address> <year> 1983. </year>
Reference-contexts: We will briefly sketch three different methods described in the literature and discuss their drawbacks. * Kornfeld's E-unification: <ref> [16] </ref> proposes the following way of extending uni fication. Any failed unification triggers an attempt to prove the equality of the terms using some defined equality theory.
Reference: [17] <author> Lim P., Stuckey P.: </author> <title> A Constraint Logic Programming Shell, </title> <editor> in Deransart P., Maluszunski J.(eds.), </editor> <booktitle> Programming Language Implementation and Logic Programming, </booktitle> <publisher> Springer, </publisher> <address> Heidelberg, </address> <year> 1990 </year>
Reference-contexts: Unifying an ordinary variable and an avar succeeds with the ordinary variable getting bound to the avar. This schema for unification is identical to the one proposed by <ref> [17] </ref> in their constraint logic programming shell (CLPS).
Reference: [18] <author> Miranker D.P., Brant D.A., Lofaso B., Gadbois D.: </author> <title> On the Performance of Lazy Matching in Production Systems, </title> <booktitle> in Proceedings of the 8th National Conference on Artificial Intelligence, </booktitle> <publisher> AAAI Press, </publisher> <address> Menlo Park, CA, </address> <year> 1990. </year>
Reference-contexts: The ultimate goal is to reduce the overhead to less than ten percent when the constraint stores contain just a few attributes (especially for the case of single attributes) and to reasonably bound the search for larger constraint stores using ideas from production systems <ref> [18] </ref>. Regarding application in natural language processing the most interesting phenomena is of course handling of disjunctions. Once we have completed a reasonably sized lexicon, empirical comparisons will be performed to other approaches like those discussed in [26].
Reference: [19] <author> Naish L.: </author> <title> Negation and Control in Prolog, </title> <institution> University of Melbourne, </institution> <month> 85/12, </month> <year> 1985. </year>
Reference-contexts: is this feature that constitutes the power of this schema! This should be compared to languages like ALF [9], where functional logic programs are proved by means of conditional rewrite rules, but which rewrite only single goals, thereby achieving power equivalent to Prolog programs annotated with wait-declarations like described in <ref> [19] </ref>. Additionally we still need a way of specifying compatibility of single attributes with non-attribute values (the verify attribute/2 pendant). A special predicate verify/2, for which the user must define clauses for each attribute, takes care of this.
Reference: [20] <author> Nelson G., Oppen D.: </author> <title> Simplification by Cooperating Decision Procedures, </title> <type> TOPLAS , 1(2), </type> <month> April </month> <year> 1980. </year>
Reference: [21] <author> Neumerkel U.: </author> <title> Extensible Unification by Metastructures, </title> <booktitle> Proc. </booktitle> <address> META90, </address> <year> 1990. </year>
Reference-contexts: Any failed unification triggers an attempt to prove the equality of the terms using some defined equality theory. But [8] shows that this approach is unsound, incomplete, and unnecessarily inefficient. * Metaterms [13] and Metastructures <ref> [21] </ref> are both aimed at overcoming some of the problems with E-Unification. Since both approaches are very similar, we will restrain our discussion to metaterms. Metaterms are introduced as an additional data-type into the respective Prolog system in addition to logical variables, constants, and terms.
Reference: [22] <author> Pfahringer B.: CLP(gRel): </author> <title> Explicit Manipulation of (ground) Relational De pendencies in Logic Programming, </title> <type> OeFAI Technical Report 92-03, </type> <institution> Vienna, </institution> <year> 1992 </year>
Reference-contexts: Unfortunately such simple disjunctions are rather rare. A slightly more general version allowing for arbitrary ground feature structures, which must be free of path equations, can be specified in analogy to the work described in <ref> [22] </ref> generalizing finite domains to ground n-ary relations. More interesting are of course disjunctions involving arbitrary feature structures including path equations. We are just experimenting with a schema of postponing these as long 11 as there is some other deterministic computation to be done.
Reference: [23] <author> Pollard, C. and I. Sag: </author> <title> Information-Based Syntax and Semantics, </title> <booktitle> Vol. 1: Fundamentals, CSLI Lecture Notes 13, </booktitle> <publisher> CSLI, Stanford, </publisher> <year> 1987. </year>
Reference-contexts: Subcategorization requirements (i.e. which arguments a word may take) are specified in the lexicon. The principles constrain the feature structures themselves, thus restricting the possible combinations and shapes of feature structures to the grammatical ones. This is especially true for hpsg <ref> [23, 24] </ref>, where a system of typed feature structures is used as a basis for the description of language. <p> A language (more precisely the sign tokens of that language) can be described by the conjunction of the universal and language specific principles conjoined with the disjunction of the lexical signs and grammar rules of that language <ref> [23, p. 44] </ref>. Although formalisms such as hpsg provide very elegant and descriptive means to describe language, problems may arise, if one wants to implement such a formalism directly.
Reference: [24] <author> Pollard, C., and I. Sag, </author> <title> Head-Driven Phrase Structure Grammar, </title> <note> To be published by University of Chicago Press and CSLI Publications, in press. </note>
Reference-contexts: Subcategorization requirements (i.e. which arguments a word may take) are specified in the lexicon. The principles constrain the feature structures themselves, thus restricting the possible combinations and shapes of feature structures to the grammatical ones. This is especially true for hpsg <ref> [23, 24] </ref>, where a system of typed feature structures is used as a basis for the description of language. <p> We will show that the CLP-framework described above provides a basis for an efficient, direct implementation of an hpsg grammar. 2 4.1 Implementing typed feature structures as constraints on variables First we will describe the kind of feature structures hpsg deals with (following the conventions of <ref> [24] </ref>). Feature structures are typed , i.e. every node is labelled with the type it belongs to. These types form a lattice, part of which is shown below. object ..&gt; sign. sign ..&gt; word. sign ..&gt; phrase. phrase ..&gt; headed_phrase.
Reference: [25] <author> Schroedl S.: </author> <title> FIDO: Implementation eines Constraint Logic Programming Systems Finite Domains, </title> <type> Diploma Thesis, </type> <institution> University of Saarbruecken, Germany, </institution> <year> 1991 </year>
Reference-contexts: Cut-and-paste of appropriate code fragments is the only solution. Specifying possible interactions of attributes, which could presumably cut down the search space early on, is even more complicated, as it requires detailed knowledge of the protocol of the respective base attributes. The work-around proposed in both [13] and <ref> [25] </ref>, namely introducing one monolithic attribute taking care of everything, is not a modular design and it is questionable if a specification of the correct behavior of this single monolithic attribute can be derived automatically from the definitions of the base attributes, at least when using such complex low-level specifications as
Reference: [26] <author> Trost H.(ed.): </author> <title> Coping with Linguistic Ambiguity in Typed Feature For malisms, </title> <booktitle> Proceedings of a workshop held at ECAI'92, </booktitle> <year> 1992. </year> <month> 14 </month>
Reference-contexts: at clause entry and exit, and "applies a rewriting process to the whole list from time to time". 4.3 Feature Structures and Disjunction Handling of disjunctions appears to be a crucial point in efficiently processing natural language and has therefore attracted a lot of attention in the last few years <ref> [26] </ref>. Disjunctions result from two different sources, namely the grammar and the lexicon. For disjunctive grammar rules usually enumeration of the different choices via backtracking leads to acceptable runtimes, as the number of such disjunctions is typically rather small. <p> Regarding application in natural language processing the most interesting phenomena is of course handling of disjunctions. Once we have completed a reasonably sized lexicon, empirical comparisons will be performed to other approaches like those discussed in <ref> [26] </ref>. Acknowledgements This work was supported by the Austrian Federal Ministry of Science and Research. The second author was supported by the Austrian Fonds zur Forderung der wissenschaftlichen Forschung, Grant No. P7986-PHY.
References-found: 26

