URL: http://theory.lcs.mit.edu/~luca/pubs/dimacs97.ps
Refering-URL: http://theory.lcs.mit.edu/~luca/papers.html
Root-URL: 
Title: A Case Study of De-randomization Methods for Combinatorial Approximation Algorithms  
Author: Jose D. P. Rolim Luca Trevisan 
Date: October 30, 1997  
Abstract: We study three different de-randomization methods that are often applied to approximate combinatorial optimization problems. We analyze the conditional probabilities method in connection with randomized rounding for routing, packing and covering integer linear programming problems. We show extensions of such methods for non-independent randomized rounding for the assignment problem. The second method, the so called random walks is exemplified with algorithms for dense instances of some NP problems. Another often used method is the bounded independence technique; we explicit this method for the sparsest cut and maximum concurrent flow problems.
Abstract-found: 1
Intro-found: 1
Reference: [AD91] <author> D. Avis and M. Deza. </author> <title> The cut cone, l 1 embeddability, complexity, and multicommodity flows. </title> <journal> Networks, </journal> <volume> 21 </volume> <pages> 595-617, </pages> <year> 1991. </year>
Reference-contexts: Shmoys' survey [Shm96] presents a very complete account on the known results and their history. Regarding the results mentioned in this section, the relation between embeddings in ` 1 metrics and the Sparsest Cut problems was first noted in <ref> [AD91] </ref>. Theorem 5.2 was independently discovered by Linial, London and Rabinovich [LLR95] and by Aumann and Rabani [AR]. The randomized embedding in ` 1 metrics appeared in a preliminary version [LLR94] of the paper of Linial, London and Rabinovich.
Reference: [AFK96] <author> S. Arora, A. Frieze, and H. Kaplan. </author> <title> A new rounding procedure for the assignment problem with applications to dense graph arrangement problems. </title> <booktitle> In Proceedings of the 37th IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pages 21-30, </pages> <year> 1996. </year>
Reference-contexts: on the unit-cost RAM model of computation, if it is only required to output a value that approximates the Max CUT (rather than an approximately optimum partition). 4 Advanced Use of Rounding: the Assignment Problem Another example of algorithm using a combined de-randomization method is an approximation method developed by <ref> [AFK96] </ref> for assignment problems for dense graphs. In an assignment problem, there are n tasks that have to be assigned to n people (so that each person is assigned to exactly one task), possibly under some additional constraint, and some objective function has to be minimized or maximized. <p> We can thus invoke Theorem 2.3. Attributions and Related Work. All the results of this section are due to Arora, Frieze and Kaplan <ref> [AFK96] </ref>. 5 Bounded Independence In this section we consider a case where randomization is used to construct a combinatorial object, and de-randomization involves an alternative explicit construction of such an object.
Reference: [AKK95] <author> S. Arora, D. Karger, and M. Karpinski. </author> <title> Polynomial time approximation schemes for dense instances of NP-hard problems. </title> <booktitle> In Pro 21 ceedings of the 27th ACM Symposium on Theory of Computing, </booktitle> <pages> pages 284-293, </pages> <year> 1995. </year>
Reference-contexts: Also, all the dense versions of Max SNP problems, when formulated as PIP, have a multilinear objective function. Attributions and Related Work. Approximation schemes for dense problems are in <ref> [AKK95] </ref>. A more efficient randomized approximation scheme for dense Max CUT is in [dlV]. An alternative more efficient approximation scheme for dense Max CUT and Max k-CUT has been developed in [FK96] using an algorithmic version of Szemeredy's regularity lemma.
Reference: [AR] <author> Y. Aumann and Y. Rabani. </author> <title> An O(log k) approximate min-cut max-flow theorem and approximation algorithm. </title> <journal> SIAM Journal on Computing. </journal> <note> To appear. </note>
Reference-contexts: Regarding the results mentioned in this section, the relation between embeddings in ` 1 metrics and the Sparsest Cut problems was first noted in [AD91]. Theorem 5.2 was independently discovered by Linial, London and Rabinovich [LLR95] and by Aumann and Rabani <ref> [AR] </ref>. The randomized embedding in ` 1 metrics appeared in a preliminary version [LLR94] of the paper of Linial, London and Rabinovich. The deterministic embedding was found later, by the same authors, and appears in [LLR95].
Reference: [Aro97] <author> S. Arora. </author> <title> Nearly linear time approximation schemes for Euclidean TSP and other geometric problems. </title> <type> Manuscript, </type> <year> 1997. </year>
Reference-contexts: Open questions. We remark that for some important network optimization problems, only randomized approximation algorithms are known. One example is the all-terminal network reliability problem (Karger (1995)), a #P -hard counting problem. A more important one is the Euclidean TSP and Steiner Tree problems, for which Arora <ref> [Aro97] </ref> developed randomized quasi-linear time approximation schemes. Arora's algorithms are trivially de-randomizable, but the trivial de-randomization increases the running time. A quasi-linear time de-randomized algorithm would be a major result. 2 Random Rounding and Conditional Expecta tion The framework is as follows.
Reference: [AS92] <author> N. Alon and J. Spencer. </author> <title> The Probabilistic Method. </title> <publisher> Wiley Inter-science, </publisher> <year> 1992. </year>
Reference-contexts: The proof of correctness is the same. Attributions and Related Work. The method of conditional prob abilities is a standard way to obtain deterministic constructions out of an existence proof that involves the probabilistic method. A clear exposition is in <ref> [AS92] </ref>. Pessimistic estimators are defined in [Rag88]. 2.1 Rounding Integer Linear Programs Randomized rounding is an algorithmic technique that is suitable of de-randomization using conditional probabilities. The general framework is as follows: we have a problem that can be formulated as an integer linear program (ILP) with 0/1 variables.
Reference: [Ber97] <author> B. Berger. </author> <title> The fourth moment method. </title> <journal> SIAM Journal on Computing, </journal> <volume> 26(4) </volume> <pages> 1188-1207, </pages> <year> 1997. </year>
Reference-contexts: The deterministic embedding was found later, by the same authors, and appears in [LLR95]. The deterministic mapping of ` 2 metrics into ` 1 metrics using 4-wise independence (Theorem 5.6) is attributed to <ref> [Ber97] </ref> in [LLR95]. A deterministic O (log k)-approximate algorithm for Sparsest Cut was also discovered by Garg [Gar95]. Acknowledgements We are grateful to Sanjeev Arora and Oded Goldreich for prompt answers to some questions of ours.
Reference: [BR94] <author> M. Bellare and J. Rompel. </author> <title> Randomness-efficient oblivious sampling. </title> <booktitle> In Proceedings of the 35th IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pages 276-287, </pages> <year> 1994. </year>
Reference-contexts: There only n O (1=* 2 ) such walks, so de-randomization can be done in polynomial time. An alternative way of de-randomizing this sampling phase is via a technique called iterated sam pling <ref> [BR94] </ref> which is also an oblivious method using less random bits but more points than the method just described.
Reference: [dlV] <author> W.F. de la Vega. </author> <title> MAXCUT has a randomized approximation scheme in dense graphs. Random Structures and Algorithms. </title> <note> To appear. </note>
Reference-contexts: Also, all the dense versions of Max SNP problems, when formulated as PIP, have a multilinear objective function. Attributions and Related Work. Approximation schemes for dense problems are in [AKK95]. A more efficient randomized approximation scheme for dense Max CUT is in <ref> [dlV] </ref>. An alternative more efficient approximation scheme for dense Max CUT and Max k-CUT has been developed in [FK96] using an algorithmic version of Szemeredy's regularity lemma. A linear-time randomization approximation scheme for dense Max CUT appears in [GGR96].
Reference: [FK96] <author> A. Frieze and R. Kannan. </author> <title> The regularity lemma and approximation schemes for dense problems. </title> <booktitle> In Proceedings of the 37th IEEE Symposium on Foundations of Computer Science, </booktitle> <year> 1996. </year>
Reference-contexts: Attributions and Related Work. Approximation schemes for dense problems are in [AKK95]. A more efficient randomized approximation scheme for dense Max CUT is in [dlV]. An alternative more efficient approximation scheme for dense Max CUT and Max k-CUT has been developed in <ref> [FK96] </ref> using an algorithmic version of Szemeredy's regularity lemma. A linear-time randomization approximation scheme for dense Max CUT appears in [GGR96]. An efficient de-randomization of the algorithm of [GGR96] is still an open question.
Reference: [Gar95] <author> N. Garg. </author> <title> A deterministic O(log k)-approximate algorithm for the sparsest cut problem. Manuscript cited in [Shm96], </title> <year> 1995. </year>
Reference-contexts: The deterministic mapping of ` 2 metrics into ` 1 metrics using 4-wise independence (Theorem 5.6) is attributed to [Ber97] in [LLR95]. A deterministic O (log k)-approximate algorithm for Sparsest Cut was also discovered by Garg <ref> [Gar95] </ref>. Acknowledgements We are grateful to Sanjeev Arora and Oded Goldreich for prompt answers to some questions of ours.
Reference: [GGR96] <author> O. Goldreich, S. Goldwasser, and D. Ron. </author> <title> Property testing and its connection with learning and approximation. </title> <booktitle> In Proceedings of the 37th IEEE Symposium on Foundations of Computer Science, </booktitle> <year> 1996. </year>
Reference-contexts: An alternative more efficient approximation scheme for dense Max CUT and Max k-CUT has been developed in [FK96] using an algorithmic version of Szemeredy's regularity lemma. A linear-time randomization approximation scheme for dense Max CUT appears in <ref> [GGR96] </ref>. An efficient de-randomization of the algorithm of [GGR96] is still an open question. Interestingly, the algorithm of [GGR96] runs in constant time, on the unit-cost RAM model of computation, if it is only required to output a value that approximates the Max CUT (rather than an approximately optimum partition). 4 <p> An alternative more efficient approximation scheme for dense Max CUT and Max k-CUT has been developed in [FK96] using an algorithmic version of Szemeredy's regularity lemma. A linear-time randomization approximation scheme for dense Max CUT appears in <ref> [GGR96] </ref>. An efficient de-randomization of the algorithm of [GGR96] is still an open question. Interestingly, the algorithm of [GGR96] runs in constant time, on the unit-cost RAM model of computation, if it is only required to output a value that approximates the Max CUT (rather than an approximately optimum partition). 4 Advanced Use of Rounding: the Assignment Problem Another <p> A linear-time randomization approximation scheme for dense Max CUT appears in <ref> [GGR96] </ref>. An efficient de-randomization of the algorithm of [GGR96] is still an open question. Interestingly, the algorithm of [GGR96] runs in constant time, on the unit-cost RAM model of computation, if it is only required to output a value that approximates the Max CUT (rather than an approximately optimum partition). 4 Advanced Use of Rounding: the Assignment Problem Another example of algorithm using a combined de-randomization method is an
Reference: [Gil93] <author> D. Gillman. </author> <title> A chernoff bound for random walks on expander graphs. </title> <booktitle> In Proceedings of the 34th IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pages 680-691, </pages> <year> 1993. </year>
Reference-contexts: An alternative way, which gives better results, is first to generate a nearly random starting point and then to sample every point along a single trajectory of the random walk <ref> [Gil93] </ref>. It is shown there that the convergence to (A) has error probability exponentially small in the length of the random walk and the square of the size of the deviation from (A). For the uniform probability distribution (A) = , if jAj = n. <p> In order to sample O (m) points almost uniformly from a set S, we build a constant 8 degree expander with vertex set S and set up a random walk of length m on S. The vertices on the random walk correspond to the m points to be sampled <ref> [Gil93] </ref>.
Reference: [GW94] <author> M. Goemans and D. Williamson. </author> <title> New 3/4-approximation algorithms for the maximum satisfiability problem. </title> <journal> SIAM Journal on Discrete Mathematics, </journal> <volume> 7(4) </volume> <pages> 656-666, </pages> <year> 1994. </year> <note> Preliminary version in Proc. of IPCO'93. 22 </note>
Reference-contexts: Random rounding has been introduced by Raghavan and Thompson [RT87]. The de-randomized rounding using a pessimistic estimator is due to Raghavan [Rag88]. Both results are also presented in Raghavan's PhD Thesis [Rag86]. Random rounding has been used to develop approximation algorithms for the Maximum Satisfiability problem <ref> [GW94] </ref> and the Constraint Satisfaction problem [Tre96]. In these algorithms, the probability distribution used to round the variables is not the solution of the relaxation, but rather a convex combination of the solution of the relaxation and of the uniform distribution.
Reference: [LLR94] <author> N. Linial, E. London, and Y. Rabinovich. </author> <title> The geometry of graphs and some of its algorithmic applications. </title> <booktitle> In Proceedings of the 35th IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pages 577-591, </pages> <year> 1994. </year>
Reference-contexts: Theorem 5.2 was independently discovered by Linial, London and Rabinovich [LLR95] and by Aumann and Rabani [AR]. The randomized embedding in ` 1 metrics appeared in a preliminary version <ref> [LLR94] </ref> of the paper of Linial, London and Rabinovich. The deterministic embedding was found later, by the same authors, and appears in [LLR95]. The deterministic mapping of ` 2 metrics into ` 1 metrics using 4-wise independence (Theorem 5.6) is attributed to [Ber97] in [LLR95].
Reference: [LLR95] <author> N. Linial, E. London, and Y. Rabinovich. </author> <title> The geometry of graphs and some of its algorithmic applications. </title> <journal> Combinatorica, </journal> <volume> 15(2) </volume> <pages> 215-245, </pages> <year> 1995. </year>
Reference-contexts: Regarding the results mentioned in this section, the relation between embeddings in ` 1 metrics and the Sparsest Cut problems was first noted in [AD91]. Theorem 5.2 was independently discovered by Linial, London and Rabinovich <ref> [LLR95] </ref> and by Aumann and Rabani [AR]. The randomized embedding in ` 1 metrics appeared in a preliminary version [LLR94] of the paper of Linial, London and Rabinovich. The deterministic embedding was found later, by the same authors, and appears in [LLR95]. <p> 5.2 was independently discovered by Linial, London and Rabinovich <ref> [LLR95] </ref> and by Aumann and Rabani [AR]. The randomized embedding in ` 1 metrics appeared in a preliminary version [LLR94] of the paper of Linial, London and Rabinovich. The deterministic embedding was found later, by the same authors, and appears in [LLR95]. The deterministic mapping of ` 2 metrics into ` 1 metrics using 4-wise independence (Theorem 5.6) is attributed to [Ber97] in [LLR95]. A deterministic O (log k)-approximate algorithm for Sparsest Cut was also discovered by Garg [Gar95]. <p> The deterministic embedding was found later, by the same authors, and appears in <ref> [LLR95] </ref>. The deterministic mapping of ` 2 metrics into ` 1 metrics using 4-wise independence (Theorem 5.6) is attributed to [Ber97] in [LLR95]. A deterministic O (log k)-approximate algorithm for Sparsest Cut was also discovered by Garg [Gar95]. Acknowledgements We are grateful to Sanjeev Arora and Oded Goldreich for prompt answers to some questions of ours.
Reference: [Rag86] <author> P. Raghavan. </author> <title> Randomized Rounding and Discrete Ham-Sandwich Theorems: Provably Good Algorithms for Routing and Packing Problems. </title> <type> PhD thesis, </type> <institution> University of California at Berkeley, </institution> <year> 1986. </year>
Reference-contexts: Attributions and Related Work. Random rounding has been introduced by Raghavan and Thompson [RT87]. The de-randomized rounding using a pessimistic estimator is due to Raghavan [Rag88]. Both results are also presented in Raghavan's PhD Thesis <ref> [Rag86] </ref>. Random rounding has been used to develop approximation algorithms for the Maximum Satisfiability problem [GW94] and the Constraint Satisfaction problem [Tre96].
Reference: [Rag88] <author> P. Raghavan. </author> <title> Probabilistic construction of deterministic algorithms: approximating packing integer programs. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 37 </volume> <pages> 130-143, </pages> <year> 1988. </year>
Reference-contexts: The proof of correctness is the same. Attributions and Related Work. The method of conditional prob abilities is a standard way to obtain deterministic constructions out of an existence proof that involves the probabilistic method. A clear exposition is in [AS92]. Pessimistic estimators are defined in <ref> [Rag88] </ref>. 2.1 Rounding Integer Linear Programs Randomized rounding is an algorithmic technique that is suitable of de-randomization using conditional probabilities. The general framework is as follows: we have a problem that can be formulated as an integer linear program (ILP) with 0/1 variables. <p> The very notion of pessimistic estimator has been introduced in order to prove Theorem 2.3 <ref> [Rag88] </ref>. Attributions and Related Work. Random rounding has been introduced by Raghavan and Thompson [RT87]. The de-randomized rounding using a pessimistic estimator is due to Raghavan [Rag88]. Both results are also presented in Raghavan's PhD Thesis [Rag86]. <p> The very notion of pessimistic estimator has been introduced in order to prove Theorem 2.3 <ref> [Rag88] </ref>. Attributions and Related Work. Random rounding has been introduced by Raghavan and Thompson [RT87]. The de-randomized rounding using a pessimistic estimator is due to Raghavan [Rag88]. Both results are also presented in Raghavan's PhD Thesis [Rag86]. Random rounding has been used to develop approximation algorithms for the Maximum Satisfiability problem [GW94] and the Constraint Satisfaction problem [Tre96].
Reference: [RT87] <author> P. Raghavan and C.D. Thompson. </author> <title> Randomized rounding: a technique for provably good algorithms and algorithmic proofs. </title> <journal> Com-binatorica, </journal> <volume> 7 </volume> <pages> 365-374, </pages> <year> 1987. </year>
Reference-contexts: The very notion of pessimistic estimator has been introduced in order to prove Theorem 2.3 [Rag88]. Attributions and Related Work. Random rounding has been introduced by Raghavan and Thompson <ref> [RT87] </ref>. The de-randomized rounding using a pessimistic estimator is due to Raghavan [Rag88]. Both results are also presented in Raghavan's PhD Thesis [Rag86]. Random rounding has been used to develop approximation algorithms for the Maximum Satisfiability problem [GW94] and the Constraint Satisfaction problem [Tre96].
Reference: [Shm96] <author> D. Shmoys. </author> <title> Cut problems and their applications to divide-and-conquer. </title> <editor> In D. Hochbaum, editor, </editor> <booktitle> Approximation Algorithms for NP-Hard Problems, </booktitle> <pages> pages 192-235. </pages> <publisher> PWS Publishing, </publisher> <year> 1996. </year>
Reference-contexts: Such a solution is O (log k)-approximate. Attributions and Related Work. There has been a lot of research on the approximability of the Sparsest Cut problem and the related Multi Cut problem. Shmoys' survey <ref> [Shm96] </ref> presents a very complete account on the known results and their history. Regarding the results mentioned in this section, the relation between embeddings in ` 1 metrics and the Sparsest Cut problems was first noted in [AD91].
Reference: [Sri95] <author> A. Srinivasan. </author> <title> Improved approximations of packing and covering problems. </title> <booktitle> In Proceedings of the 27th ACM Symposium on Theory of Computing, </booktitle> <pages> pages 268-276, </pages> <year> 1995. </year>
Reference-contexts: The de-randomization of these algorithms is easier since, basically, any 0/1 solution is feasible. Theorem 2.2 can be improved in special cases, for example for resource-constrained scheduling problem [SS96] and for packing and covering integer linear programs <ref> [Sri95] </ref>. In both cases, the authors de-randomize their round ing schema using new pessimistic estimators. 3 Extensions of Random Rounding and Random Walks Another useful de-randomization technique is based on random walks on graphs.
Reference: [SS96] <author> A. Srivastav and P. Stangier. </author> <title> Algorithmic chernoff-hoeffding inequalities in integer programming. Random Structures and Algorithms, </title> <note> 1996. Preliminary version in Proc. of ISAAC'94. </note>
Reference-contexts: The de-randomization of these algorithms is easier since, basically, any 0/1 solution is feasible. Theorem 2.2 can be improved in special cases, for example for resource-constrained scheduling problem <ref> [SS96] </ref> and for packing and covering integer linear programs [Sri95]. In both cases, the authors de-randomize their round ing schema using new pessimistic estimators. 3 Extensions of Random Rounding and Random Walks Another useful de-randomization technique is based on random walks on graphs.
Reference: [Tre96] <author> L. Trevisan. </author> <title> Positive linear programming, parallel approximation, </title> <booktitle> and PCP's. In Proceedings of the 4th European Symposium on Algorithms, </booktitle> <pages> pages 62-75. </pages> <publisher> LNCS 1136, Springer-Verlag, </publisher> <year> 1996. </year> <month> 23 </month>
Reference-contexts: The de-randomized rounding using a pessimistic estimator is due to Raghavan [Rag88]. Both results are also presented in Raghavan's PhD Thesis [Rag86]. Random rounding has been used to develop approximation algorithms for the Maximum Satisfiability problem [GW94] and the Constraint Satisfaction problem <ref> [Tre96] </ref>. In these algorithms, the probability distribution used to round the variables is not the solution of the relaxation, but rather a convex combination of the solution of the relaxation and of the uniform distribution. The de-randomization of these algorithms is easier since, basically, any 0/1 solution is feasible.
References-found: 23

