URL: http://www.cs.berkeley.edu/~lazzaro/biblio/recog.ps.gz
Refering-URL: http://www.cs.berkeley.edu/~lazzaro/biblio/bib.html
Root-URL: 
Email: lazzaro@cs.berkeley.edu, johnw@cs.berkeley.edu  
Title: Speech Recognition Experiments with Silicon Auditory Models  
Author: John Lazzaro and John Wawrzynek 
Address: Berkeley, CA 94720-1776  
Affiliation: CS Division UC Berkeley  
Abstract: We have developed a real-time system to transform an audio signal into several specialized representations of sound. The system uses analog circuit models of biological audition to compute these representations. We report on a speech recognizer that uses this system for feature extraction, and we evaluate the performance of this speech recognition system on a speaker-independent 13-word recognition task.
Abstract-found: 1
Intro-found: 1
Reference: <author> Bhadkamkar, N. A. </author> <year> (1994). </year> <title> Binaural source localizer chip using subthreshold analog CMOS. </title> <booktitle> 1994 IEEE International Conference on Neural Networks, </booktitle> <volume> 3, </volume> <pages> 1866-1870. </pages>
Reference: <author> Boll, S. </author> <year> (1979). </year> <title> Suppression of acoustic noise in speech using spectral subtraction. </title> <journal> Trans. on ASSP, </journal> <volume> ASSP27:2, </volume> <pages> 113-120. </pages>
Reference-contexts: A variety of techniques for robust feature extraction in noisy environments have been developed for use with conventional front-ends for speech recognition. Adapting these techniques to function with auditory representations is a promising avenue of research. One popular method of speech enhancement in noise is spectral subtraction <ref> (Boll, 1979) </ref>. In this approach, a spectral model of the background noise in the recent past is generated, and subtracted from the current input.
Reference: <author> Bourlard, H. and Morgan, N. </author> <year> (1994). </year> <title> Connectionist speech recognition : a hybrid approach. </title> <address> Boston, Mass: </address> <publisher> Kluwer Academic Publishers. </publisher>
Reference-contexts: An alternative approach for mapping a feature vector into a phoneme probability vector is to use a multi-layer perceptron (MLP) architecture, trained with the backpropagation algorithm. This approach, as described in <ref> (Bourlard and Morgan, 1994) </ref>, is more tolerant of feature vectors whose elements are correlated. The speech recognition results we present in this paper all use this MLP-based recognizer.
Reference: <author> Brown, G. J. and Cooke, M. P. </author> <year> (1994). </year> <title> Computational auditory scene analysis. </title> <booktitle> Computer Speech and Language, 8:4, </booktitle> <pages> 297-336. </pages>
Reference-contexts: Computation time is a major limitation in the engineering application of auditory models. For example, the complete sound separation system described in <ref> (Brown and Cooke, 1994) </ref> operates at approximately 4000 times real time, running under UNIX on a Sun SPARCstation 1. For most engineering applications, auditory models must process input in real time; for many of these applications, an auditory model implementation also needs to be low-cost and low-power.
Reference: <author> Chandrakasan, A. P. and Brodersen, R. W. </author> <year> (1995). </year> <title> Low power digital CMOS design. </title> <address> Boston, Mass: </address> <publisher> Kluwer Academic Publishers. </publisher>
Reference: <author> Coggins, R., Jabri, M., Flower, B., Pickard, S. </author> <year> (1995). </year> <title> A hybrid analog and digital VLSI neural network for intracardiac morphology classification. </title> <journal> IEEE Journal Solid State Circuits, </journal> <volume> 30:5, </volume> <pages> 542-550. </pages>
Reference-contexts: For such micropower systems to become a reality, micropower implementations of pattern-recognition functions must also be available: a recent report on a nanopower neural-network recognition structure <ref> (Coggins et al., 1995) </ref>, used in an implantable cardiac morphology classification system, is an example of progress in this area. Standard analog performance measurements (S/N ratio, dynamic range, ect.) aren't sufficient for determining the suitability of analog implementations of non-linear, multi-stage auditory models for a particular application.
Reference: <author> Colomes, C., Lever, M., Rault, J. B., and Dehery, Y. F. </author> <year> (1995). </year> <title> A perceptual model applied to audio bit-rate reduction. </title> <journal> J. Audio Eng. Soc., </journal> <volume> 43:4, </volume> <pages> 233-239. </pages>
Reference-contexts: Current engineering applications of auditory models under study include speech recognition (Jackowoski et al., 1995; Ghitza, 1998; Seneff, 1988), sound separation (Cooke et al., 1994), and masking models for MPEG-audio encoding <ref> (Colomes et al., 1995) </ref>. Computation time is a major limitation in the engineering application of auditory models. For example, the complete sound separation system described in (Brown and Cooke, 1994) operates at approximately 4000 times real time, running under UNIX on a Sun SPARCstation 1.
Reference: <author> Cooke, M., Beet, S., and Crawford, M. </author> <year> (1993). </year> <title> Visual Representations of Speech Signals, </title> <address> New York: </address> <publisher> Wiley. </publisher>
Reference: <author> Cooke, M., Green, P., Crawford, M. </author> <year> (1994). </year> <title> Handling missing data in speech recognition. </title> <booktitle> 1994 International Conference on Spoken Language Processing, </booktitle> <volume> 3, </volume> <pages> 1555-1558. </pages>
Reference-contexts: Current engineering applications of auditory models under study include speech recognition (Jackowoski et al., 1995; Ghitza, 1998; Seneff, 1988), sound separation <ref> (Cooke et al., 1994) </ref>, and masking models for MPEG-audio encoding (Colomes et al., 1995). Computation time is a major limitation in the engineering application of auditory models. <p> Computation time is a major limitation in the engineering application of auditory models. For example, the complete sound separation system described in <ref> (Brown and Cooke, 1994) </ref> operates at approximately 4000 times real time, running under UNIX on a Sun SPARCstation 1. For most engineering applications, auditory models must process input in real time; for many of these applications, an auditory model implementation also needs to be low-cost and low-power. <p> Several research groups have done initial work on changing core speech recognition technology to be more amenable to auditory representations. These methods take different approaches to the problem; one recent publication uses the visual scene analysis concept of occlusion as a starting point <ref> (Cooke et al., 1994) </ref>, while other recent work is motivated by the importance transient information in the speech signal (Morgan et al., 1994). Attacking the problem from the representation side, research in mapping in high-dimensional spaces into low-dimensional features has been recently applied to cochlear models (Intrator, 1993). 8.
Reference: <author> Ghitza, O. </author> <year> (1988). </year> <title> Temporal non-place information in the auditory nerve firing patterns as a front-end for speech recognition in a noisy environment. </title> <journal> Journal of Phonetics, </journal> <volume> 16:1, </volume> <pages> 109-123. </pages>
Reference: <author> Hermansky, H. </author> <year> (1990). </year> <title> Perceptual linear predictive (PLP) analysis of speech. </title> <journal> Journal Acoustical Society of America, </journal> <volume> 87:4, </volume> <pages> 1738-1752. </pages>
Reference: <author> Hermansky, H. and Morgan, N. </author> <year> (1994). </year> <title> RASTA processing of speech. </title> <journal> IEEE Transactions of Speech and Audio Processing, </journal> <volume> 2:4, </volume> <pages> 578-589. </pages>
Reference: <author> Intrator, N. </author> <year> (1993). </year> <title> Combining exploratory projection pursuit and projection pursuit regression with application to neural networks. </title> <journal> Neural Computation, </journal> <volume> 5, </volume> <pages> 443-455. </pages>
Reference-contexts: Attacking the problem from the representation side, research in mapping in high-dimensional spaces into low-dimensional features has been recently applied to cochlear models <ref> (Intrator, 1993) </ref>. 8. SUMMARY In this paper, we have evaluated the suitability of analog implementations of auditory models, using an empirical approach: we integrated a multi-representation analog auditory model with a speech recognition system, and measured the performance of the system on a speaker-independent, telephone-quality 13-word recognition task.
Reference: <author> Jackowoski, C. R., Vo, H. D. H., Lippmann, R. P. </author> <year> (1995). </year> <title> A comparison of signal processing front ends for automatic word recognition. </title> <journal> IEEE Transactions of Speech and Audio Processing, </journal> <volume> 3:4, </volume> <pages> 286-293. </pages>
Reference-contexts: We see the following areas as important elements of such a research effort: Improved Circuit Techniques. The 4.1% error of the multi-representation system, for clean speech, is distinctly inferior to the 1.8% error for J-RASTA-PLP on the same task. In contrast, studies of software implementations of similar auditory models <ref> (Jackowoski et al., 1995) </ref> typically show comparable performance in comparison with conventional front-ends. The shortcomings of our analog circuit implementation, including limited signal-to-noise ratio, limited dynamic range, and inaccuracy due to parameter variation and temperature-related drift, may play a role in this difference.
Reference: <author> Lazzaro, J. P. and Mead C. </author> <year> (1989a). </year> <title> Silicon models of pitch perception. </title> <booktitle> Proc. </booktitle> <institution> Natl. Acad. Sci. USA, </institution> <month> 86, </month> <pages> 9597-9601. </pages>
Reference: <author> Lazzaro, J. P. and Mead C. </author> <year> (1989b). </year> <title> Silicon models of auditory localization. </title> <journal> Neural Computation, </journal> <volume> 1, </volume> <pages> 47-57. </pages>
Reference: <author> Lazzaro, J. P. and Mead, C. </author> <year> (1989c). </year> <title> Circuit models of sensory transduction in the cochlea. In Analog VLSI Implementations of Neural Networks, Mead, Ismail, </title> <editor> (eds.), </editor> <publisher> Norwell, </publisher> <address> MA: </address> <publisher> Kluwer, </publisher> <pages> 85-101. </pages>
Reference-contexts: These operations include time differentiation, half-wave rectification, amplitude compression, and the conversion of the analog waveform representation into probabilistic trains of fixed-width, fixed-height spikes <ref> (Lazzaro and Mead, 1989c) </ref>. Each of the 119 cascade outputs is coded by 6 probabilistic spiking circuits. Note that no time averaging has been done in this signal processing chain; the cycle-by-cycle waveform shape is fully coded in each set of 6 spiking outputs.
Reference: <author> Lazzaro, J. </author> <title> P (1991). A silicon model of an auditory neural representation of spectral shape. </title> <journal> IEEE Journal Solid State Circuits, </journal> <volume> 26, </volume> <pages> 772-777. </pages>
Reference-contexts: In our chip processing chain, two signal processing blocks follow the sensory transduction block, that may be used to model a variety of known and proposed secondary representations. The first processing block (Figure 2) implements temporal autocorrelation, in a manner described in detail in <ref> (Lazzaro, 1991) </ref>. The six spiking outputs associated with each cochlear output are sent into a single temporal autocorrelator, which produces a single output. Six parameters fix the autocorrelation time constant and autocorrelation window size at both ends of the representation; autocorrelation parameters for intermediate taps are exponentially interpolated.
Reference: <author> Lazzaro, J. P. </author> <year> (1992). </year> <title> Temporal adaptation in a silicon auditory nerve. </title> <editor> In Moody, J., Hanson, S., Lippmann, R. (eds), </editor> <booktitle> Advances in Neural Information Processing Systems 4. </booktitle> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann Publishers. </publisher>
Reference-contexts: These parameters support a wide range of adaptive responses, including temporal adaptation behaviors typical of auditory nerve fibers, as well as behaviors typical of on-cell neurons in the cochlear nucleus. The circuits used in the temporal adaptation block are described in detail in <ref> (Lazzaro, 1992) </ref>. bottom trace shows adaptive response. Bar length is 5ms. As shown in Figure 4, the final outputs of the auditory model take the form of pulse trains. These pulses are fixed-width, fixed-height, and occur asynchronously; they are not synchronized by a global clock.
Reference: <author> Lazzaro, J. P., Wawrzynek, J., Mahowald., M., Sivilotti, M., and Gillespie, D. </author> <year> (1993). </year> <title> Silicon auditory processors as computer peripherals. </title> <journal> IEEE Journal of Neural Networks 4:3, </journal> <pages> 523-528. </pages>
Reference-contexts: The information sent by a spike is fully encoded by its moment of onset. In collaboration with other researchers, we have developed efficient methods to transmit the information from an array of asynchronous spiking circuits off chip <ref> (Lazzaro et al., 1993) </ref>, and to combine the information from several chips to form a single data stream in an efficient way (Laz-zaro and Wawrzynek, 1995a).
Reference: <author> Lazzaro, J. P., Wawrzynek, J., and Kramer, </author> <title> A (1994). Systems technologies for silicon auditory models. </title> <journal> IEEE Micro, </journal> <volume> 14:3, </volume> <pages> 7-15. </pages>
Reference-contexts: The onset timestamp has a resolution of 20s; event lists are strictly ordered with respect to onset times. We designed a software environment, Aer, to support real-time, low-latency visualization of data from the multi-converter system <ref> (Lazzaro et al., 1994) </ref>. The environment also supports a scripting language for the automatic collection of system response to large sound databases. 3. <p> These improvements may directly translate to improvements in speech recognition scores, bringing silicon auditory models to the performance of their software counterparts. Parameter drift due to inadequate temperature compensation is another area for improvement, the temperature compensation approach we use in our multi-representation is primitive <ref> (Lazzaro et al., 1994) </ref>, and parameter drift may be a significant source of recognition error, as Figure 16 suggests. Improvements in this area are straightforward, using techniques such as those described in (Vittoz, 1985). Enhanced Auditory Models.
Reference: <author> Lazzaro, J. P. and Wawrzynek, J. </author> <year> (1995a). </year> <title> A multi-sender asynchronous extension to the address-event protocol. </title> <editor> In Dally, W. J., Poulton, J. W., Ishii, A. T. (eds), </editor> <booktitle> 16th Conference on Advanced Research in VLSI, </booktitle> <pages> 158-169. </pages>
Reference: <author> Lazzaro, J. P. and Wawrzynek, J. </author> <year> (1995b). </year> <title> Silicon models for auditory scene analysis. </title> <editor> In Touretzky, D. S., Mozer, M. C., and Hasselmo, M. E. </editor> <booktitle> (eds) Advances in Neural Information Processing Systems 8, </booktitle> <address> Cambridge,Mass: </address> <publisher> MIT Press. </publisher>
Reference: <author> Liu, W., Andreou, A., and Goldstein, M. </author> <year> (1992). </year> <title> Voiced-speech representation by an analog silicon model of the auditory periphery. </title> <journal> IEEE Transactions of Neural Networks 3:3, </journal> <note> 477-487 Lyon, </note> <author> R. F., and Mead, C. </author> <year> (1988). </year> <title> An analog electronic cochlea. </title> <journal> IEEE Trans. Acoust., Speech, Signal Processing 36, </journal> <pages> 1119-1134. </pages>
Reference: <author> Lyon, R. F. </author> <year> (1991). </year> <title> CCD correlators for auditory models. </title> <booktitle> IEEE Asilomar Conference on Signals, Systems, and Computers, </booktitle> <year> 1991, </year> <pages> 785-789. </pages>
Reference: <author> Ma, K. W. </author> <year> (1995). </year> <title> Applying Large Vocabulary Hybrid HMM-MLP Methods to Telephone Recognition of Digits and Natural Numbers. </title> <institution> International Computer Science Institute Technical Report, TR-95-024. </institution>
Reference-contexts: Although early studies of speech recognition in noisy conditions using auditory models reported encouraging results (Ghitza, 1998; Seneff, 1988), later studies found no significant noise robustness qualities for auditory models <ref> (Lippmann, 1995) </ref>, and the data in Figure 14 confirms this finding.
Reference: <author> Morgan, N., Bourlard, H., Greenberg, S., and Hermansky, H. </author> <year> (1994). </year> <title> Stochastic perceptual auditory-event-based models for speech recognition. </title> <booktitle> 1994 International Conference on Spoken Language Processing, </booktitle> <volume> 4, </volume> <pages> 1943-1946. </pages>
Reference-contexts: An alternative approach for mapping a feature vector into a phoneme probability vector is to use a multi-layer perceptron (MLP) architecture, trained with the backpropagation algorithm. This approach, as described in <ref> (Bourlard and Morgan, 1994) </ref>, is more tolerant of feature vectors whose elements are correlated. The speech recognition results we present in this paper all use this MLP-based recognizer. <p> These methods take different approaches to the problem; one recent publication uses the visual scene analysis concept of occlusion as a starting point (Cooke et al., 1994), while other recent work is motivated by the importance transient information in the speech signal <ref> (Morgan et al., 1994) </ref>. Attacking the problem from the representation side, research in mapping in high-dimensional spaces into low-dimensional features has been recently applied to cochlear models (Intrator, 1993). 8.
Reference: <author> Sachs, M. B. and Young. E. D. </author> <year> (1980). </year> <title> Effects of nonlinearities on speech encoding in the auditory nerve. </title> <journal> J. Acoust. Soc. Am, </journal> <volume> 68:3, </volume> <pages> 858-875. </pages> <editor> van Schaik, A., Fragniere, E., and Vittoz, E. </editor> <year> (1995). </year> <title> Improved silicon cochlea using compatible lateral bipolar transistors. </title> <editor> In Tourestzky, D. et al., </editor> <booktitle> (eds) Advances in Neural Information Processing Systems 8, </booktitle> <address> Cambridge,Mass: </address> <publisher> MIT Press. </publisher>
Reference-contexts: To generate this spectral shape representation, the autocorrelator associated with each cochlear channel is tuned so that the best frequency of the cochlear channel matches the first peak of the autocorrelation function <ref> (Sachs and Young, 1980) </ref>. Figure 3 illustrates the algorithm: Figure 3 (a) shows the frequency response of a cochlear output, Figure 3 (b) shows the output of a temporal autocorrelator tuned to the best frequency of the cochlear output, and filter.
Reference: <author> Seneff, S. </author> <year> (1988). </year> <title> A Joint Synchrony/Mean-Rate Model of Auditory Speech Processing. </title> <journal> Journal of Phonetics, </journal> <volume> 16:1, </volume> <pages> 55-76. </pages>
Reference: <author> Vittoz, E. A. </author> <year> (1985). </year> <title> The design of high-performance analog circuits on CMOS chips. </title> <journal> IEEE Journal Solid State Circuits, </journal> <volume> 20:3, </volume> <pages> 657-665. </pages>
Reference-contexts: Improvements in this area are straightforward, using techniques such as those described in <ref> (Vittoz, 1985) </ref>. Enhanced Auditory Models. The cochlear model in our special-purpose analog-to-digital converter chip is an extreme simplification of physiological cochlear processing; software-based auditory models used in other speech recognition studies share most of these simplifications.
Reference: <author> Watts, L., Kerns, D. A., Lyon, R. F., and Mead, C. </author> <year> (1992). </year> <title> Improved Implementation of the Silicon Cochlea. </title> <journal> IEEE Journal Solid State Circuits, </journal> <volume> 27:5, </volume> <pages> 692-700. </pages>
Reference-contexts: For example, a recent publication on cochlear design techniques reports a 51-channel cochlear filterbank that consumes only 11 microwatts at 5 volts <ref> (Watts et al., 1992) </ref>. Voltage and process scaling, and advances in circuit design, could reduce power consumption even further.
Reference: <author> Woodland, P. C., Odell, J. J., Valtchev, V., and Young, S. J. </author> <year> (1994). </year> <title> Large vocabulary continuous speech recognition using HTK. </title> <journal> ICASSP-94, </journal> <volume> 2, </volume> <month> II/125-8. </month>
References-found: 32

