URL: http://www.cs.columbia.edu/CAVE/papers/nayar/nayar-murase-mani_tr-95.ps.gz
Refering-URL: http://www.cs.columbia.edu/CAVE/visual-learn-recog.html
Root-URL: http://www.cs.columbia.edu
Email: nayar@cs.columbia.edu  murase@siva.ntt.jp  
Title: Dimensionality of Illumination Manifolds in Eigenspace  
Author: Shree K. Nayar and Hiroshi Murase 
Date: August, 1994 Revised: September 1995  
Address: New York, NY 10027, USA  3-1, Morinosato Wakamiya, Atsugi-shi Kanagawa 243-01, Japan  
Affiliation: Department of Computer Science Columbia University,  NTT Basic Research Labs  
Pubnum: CUCS-021-94  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> R. Epstein, P. W. Hallinan, and A. L. Yuille, </author> <title> "52 Eigenimages Suffice: An Empirical Investigation of Low-Dimensional Lighting Models," </title> <booktitle> Proc. of IEEE Workshop on Physics Based Modeling in Computer Vision, </booktitle> <pages> pp. 108-116, </pages> <address> Boston, </address> <month> June </month> <year> 1995. </year>
Reference-contexts: In particular, for Lambertian surfaces of arbitrary texture, the entire illumination manifold can be constructed from just three images taken using known illuminants. Alternatively, the dimensionality of the illumination manifold is exactly 3. This result is supported by a detailed empirical investigation reported recently by Epstien et al. <ref> [1] </ref>. We use the above bound on the manifold dimensionality to show that novel images of the object can be recognized from just three projections on the illumination manifold without the explicit construction of the manifold.
Reference: [2] <author> B. V. Funt and M. S. Drew, </author> <title> "Color Space Analsyis of Mutual Illumination," </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> Vol. 15, No. 12, </volume> <pages> pp. 1319-1325, </pages> <month> December </month> <year> 1993. </year>
Reference: [3] <author> H. Murase and S. K. Nayar, </author> <title> "Visual Learning and Recognition of 3D Objects from Appearance," </title> <journal> International Journal of Computer Vision, </journal> <volume> Vol. 14, No. 1, </volume> <pages> pp. 5-24, </pages> <month> January, </month> <year> 1995. </year>
Reference-contexts: During recognition, novel images are projected into the eigenspace. The closest manifold and the exact location of the closest point on the manifold reveal the task parameters. The parametric eigenspace representation has found several important applications. These include learning [4] and real-time recognition of 3D objects <ref> [3] </ref>, positioning and tracking of 3D objects by a robot manipulator [9], and illumination planning for robust object recognition [5]. Recently, a recognition system with 100 complex objects in its database was developed that is solely based on appearance matching [3]. <p> These include learning [4] and real-time recognition of 3D objects <ref> [3] </ref>, positioning and tracking of 3D objects by a robot manipulator [9], and illumination planning for robust object recognition [5]. Recently, a recognition system with 100 complex objects in its database was developed that is solely based on appearance matching [3]. The sheer efficiency of appearance matching enables the system to accomplish both recognition and pose estimation in real time using nothing more than a standard workstation equipped with an image sensor (see Figure 1). <p> All of the acquired images are use to compute E. It is assumed here that E is less sensitive to illumination variations than pose variations. This is typically the case when dealing with objects of complex shape and textural properties (see <ref> [3] </ref>). Next, all images of an object are projected to eigenspace. The expression in (17) can be used compute eigenspace projections corresponding to any desired number of source directions. In [4], the projections due to both pose and illumination variations are interpolated and the resulting manifold is densely resampled. <p> The entire manifold, that represents both pose and illumination variations, is then densely resampled and stored as a discrete one. During on-line recognition, a nearest neighbor algorithm is used to find the object and its pose and illumination parameters as described in <ref> [3] </ref>. 11 9 Experiments Two sets of experiments were conducted to verify the theoretical results presented above. The first is related to the efficiency of learning; the construction of the illumination manifold of an object in given pose.
Reference: [4] <author> H. Murase and S. K. Nayar, </author> <title> "Learning and Recognition of 3D Objects from Appearance," </title> <booktitle> Proc. of IEEE Workshop on Qualitative Vision, </booktitle> <pages> pp. 39-50, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: 1 Introduction Appearance matching techniques are fast becoming popular in machine vision. Recent applications include face recognition [17] and the real-time recognition of complex 3D objects <ref> [4] </ref>. A representation of object appearance called the parametric eigenspace has resulted from this work [4]. For a given vision application, a visual workspace is first defined as the range of visual appearances that result from varying the parameters of the task. <p> 1 Introduction Appearance matching techniques are fast becoming popular in machine vision. Recent applications include face recognition [17] and the real-time recognition of complex 3D objects <ref> [4] </ref>. A representation of object appearance called the parametric eigenspace has resulted from this work [4]. For a given vision application, a visual workspace is first defined as the range of visual appearances that result from varying the parameters of the task. <p> During recognition, novel images are projected into the eigenspace. The closest manifold and the exact location of the closest point on the manifold reveal the task parameters. The parametric eigenspace representation has found several important applications. These include learning <ref> [4] </ref> and real-time recognition of 3D objects [3], positioning and tracking of 3D objects by a robot manipulator [9], and illumination planning for robust object recognition [5]. Recently, a recognition system with 100 complex objects in its database was developed that is solely based on appearance matching [3]. <p> The bases of E are then the normalized eigenvectors of the covariance matrix computed from an image set, one that typically includes images of a large number of objects taken at different poses and illumination conditions during a learning (or training) stage <ref> [4] </ref>. Suppose the dimensionality of the eigenspace is d. The eigenvectors e s ; s = 1; 2; :::::d are those with the largest eigenvalues s of the covariance matrix, such that, 1 2 :::: d . <p> Scale and brightness normalizations are applied to all object images before they are either used to construct eigenspace representations or to recognize novel object images <ref> [4] </ref>. The scale normalization ensures that both appearance representation and recognition are invariant to the magnification of the imaging system under weak-perspective projection. The brightness normalization is used to achieve invariance to the intensity of illumination. <p> The above results imply that we do not need to take a large number of images by sampling the entire illumination space for each pose of each object as done in <ref> [4] </ref>. For any given object pose, the entire illumination manifold can be constructed from the projections of just the three basis images. <p> In practice, such an eigenspace is computed from a large image set obtained by varying pose and illumination in small increments <ref> [4] </ref>. Given the above results, it is possible to dramatically reduce the number of images that are required during learning. We now need to vary object pose in small increments and take only three images for each pose corresponding to the independent basis illuminants 1 . <p> This is typically the case when dealing with objects of complex shape and textural properties (see [3]). Next, all images of an object are projected to eigenspace. The expression in (17) can be used compute eigenspace projections corresponding to any desired number of source directions. In <ref> [4] </ref>, the projections due to both pose and illumination variations are interpolated and the resulting manifold is densely resampled. The resulting points are stored in a database and serve as a discrete appearance representation of the object. Given a novel image, a segmentation algorithm is used to extract object regions. <p> Given that 10 d 30 in most previous applications of parametric eigenspaces <ref> [4] </ref> [9] [5], what we have above is an overdetermined linear system that is easily solved to obtain an estimate ~ of the source coefficients. Since the object in the novel image is unknown, the estimate ~ may or may not correspond to a point on the illumination manifold.
Reference: [5] <author> H. Murase and S. K. Nayar, </author> <title> "Illumination Planning for Object Recognition in Structured Environments," </title> <booktitle> Proc. of IEEE Intl. Conf. on Computer Vision and Pattern Recognition, Seattle, </booktitle> <pages> pp. 31-38, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: The parametric eigenspace representation has found several important applications. These include learning [4] and real-time recognition of 3D objects [3], positioning and tracking of 3D objects by a robot manipulator [9], and illumination planning for robust object recognition <ref> [5] </ref>. Recently, a recognition system with 100 complex objects in its database was developed that is solely based on appearance matching [3]. <p> Given that 10 d 30 in most previous applications of parametric eigenspaces [4] [9] <ref> [5] </ref>, what we have above is an overdetermined linear system that is easily solved to obtain an estimate ~ of the source coefficients. Since the object in the novel image is unknown, the estimate ~ may or may not correspond to a point on the illumination manifold.
Reference: [6] <author> S. K. Nayar, S. A. Nene, and H. Murase, </author> <title> "Real-Time 100 Object Recognition System," CUCS-025-95, </title> <type> Technical Report, </type> <institution> Department of Computer Science, Columbia University, </institution> <address> New York, </address> <month> September, </month> <year> 1995. </year>
Reference-contexts: In other words, all the results derived thus far remain valid in each band. Appearance manifolds of an object can then be constructed independently for each band (as in <ref> [6] </ref>) and recognition is deemed successful if all bands of a novel image are found to match the same object in the appearance database. Alternatively, an image vector can be constructed by concatenating the multiple bands of the color image.
Reference: [7] <author> S. K. Nayar and M. Oren, </author> <title> "Visual Appearance of Matte Surfaces," </title> <journal> SCIENCE, </journal> <volume> Vol. 267, </volume> <pages> pp. 1153-1156, </pages> <month> February </month> <year> 1995. </year> <month> 15 </month>
Reference-contexts: Surface reflection is a nonlinear function of viewpoint. In contrast, the body component is relatively less viewpoint dependent. Though the dependence can be significant in the case of surfaces with high macroscopic roughness (see [14] <ref> [7] </ref>), many man-made objects (for instance, those with matte paints) as well as some natural surfaces can be approximated by a linear model.
Reference: [8] <author> S. K. Nayar and H. Murase, </author> <title> "On the Dimensionality of Illumination Manifolds in Eigenspace," CUCS-021-94, </title> <type> Technical Report, </type> <institution> Department of Computer Science, Columbia University, </institution> <address> New York, </address> <month> August </month> <year> 1994. </year>
Reference-contexts: In contrast, the function space associated with object reflectance is more concise and hence conducive to analysis. It is possible to establish, under certain reflectance assumptions, a closed-form relationship between illumination parameters and manifold structure <ref> [8] </ref>. Given that the eigenspaces we use are linear subspaces, the class of linear reflectance functions [15][16] is of particular interest to us. We show that for this reflectance class the structure of the illumination manifold is completely determined from a small number of samples of the manifold.
Reference: [9] <author> S. K. Nayar, H. Murase, and S. A. Nene, </author> <title> "Learning, Positioning, and Tracking Visual Appearance," </title> <booktitle> Proc. of IEEE Intl. Conf. on Robotics and Automation, </booktitle> <address> San Diego, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: The closest manifold and the exact location of the closest point on the manifold reveal the task parameters. The parametric eigenspace representation has found several important applications. These include learning [4] and real-time recognition of 3D objects [3], positioning and tracking of 3D objects by a robot manipulator <ref> [9] </ref>, and illumination planning for robust object recognition [5]. Recently, a recognition system with 100 complex objects in its database was developed that is solely based on appearance matching [3]. <p> Given that 10 d 30 in most previous applications of parametric eigenspaces [4] <ref> [9] </ref> [5], what we have above is an overdetermined linear system that is easily solved to obtain an estimate ~ of the source coefficients. Since the object in the novel image is unknown, the estimate ~ may or may not correspond to a point on the illumination manifold.
Reference: [10] <author> S. K. Nayar and Y. Gong, </author> <title> "Colored Interreflections and Shape Recovery," </title> <booktitle> Proc. of DARPA Image Understanding Workshop, </booktitle> <address> San Diego, CA, </address> <year> 1992. </year>
Reference: [11] <author> S. K. Nayar, K. Ikeuchi, and T. Kanade, </author> <title> "Surface Reflection: Geometrical and Physical Perspectives," </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> Vol. 13, No. 7, </volume> <pages> pp. 611-634, </pages> <month> July </month> <year> 1991. </year>
Reference-contexts: If Dim (p) = Dim (q) = k, we have a k-order linear reflectance model (see [15][16]). When is the linear reflectance model valid in practice? In general, reflectance functions can be viewed as the combination of surface (specular) and body (diffuse) components <ref> [11] </ref>. Surface reflection is a nonlinear function of viewpoint. In contrast, the body component is relatively less viewpoint dependent.
Reference: [12] <author> S. K. Nayar, K. Ikeuchi, and T. Kanade, </author> <title> "Shape from Interreflections," </title> <journal> International Journal of Computer Vision, </journal> <volume> Vol. 2, No. 3, </volume> <pages> pp. 173-195, </pages> <year> 1991. </year>
Reference-contexts: In <ref> [12] </ref>, the above brightness equation was analyzed to show that the concave surface behaves exactly like a Lambertian one without interreflections, but with a different set of surface normals and albedo values.
Reference: [13] <author> E. Oja, </author> <title> Subspace methods of Pattern Recognition, </title> <publisher> Research Studies Press, </publisher> <address> Hertfordshire, </address> <year> 1983. </year>
Reference-contexts: For a given vision application, a visual workspace is first defined as the range of visual appearances that result from varying the parameters of the task. This workspace is sampled to obtain an image set that is used to compute a low-dimensional linear subspace <ref> [13] </ref>, called the eigenspace, in which the visual workspace is represented by one or more parametrized manifolds. During recognition, novel images are projected into the eigenspace. The closest manifold and the exact location of the closest point on the manifold reveal the task parameters. <p> Alternatively, an image vector can be constructed by concatenating the multiple bands of the color image. Appearance representation in subspaces is invariant to the order of concatenation since this order only alters the order of values in the principle vectors (dimensions) of the subspace <ref> [13] </ref>. However, since the linear combinations of the previous sections can be expected to differ between bands, a concatenated vector cannot be assumed to represent any single linear combination. <p> Here, some of the results related to color-rank in [15] could lead to interesting results. 7 7 Illumination Manifold in Eigenspace We are now equipped to analyze the dimensionality of illumination manifolds in eigenspaces. An eigenspace E is an image subspace that is typically computed using the Karhunen-Loeve transform <ref> [13] </ref>. The bases of E are then the normalized eigenvectors of the covariance matrix computed from an image set, one that typically includes images of a large number of objects taken at different poses and illumination conditions during a learning (or training) stage [4].
Reference: [14] <author> M. Oren and S. K. Nayar, </author> <title> "Generalization of the Lambertian Model and Implications for Machine Vision," </title> <journal> International Journal of Computer Vision, </journal> <volume> Vol. 14, No. </volume> <pages> 2-3, pp. 227-251, </pages> <month> April, </month> <year> 1995. </year>
Reference-contexts: Surface reflection is a nonlinear function of viewpoint. In contrast, the body component is relatively less viewpoint dependent. Though the dependence can be significant in the case of surfaces with high macroscopic roughness (see <ref> [14] </ref> [7]), many man-made objects (for instance, those with matte paints) as well as some natural surfaces can be approximated by a linear model.
Reference: [15] <author> A. P. Petrov, </author> <title> "Color and Grassman-Cayley coordinates of shape,"in Human Vision, Visual Processing and Digital Display II, </title> <booktitle> SPIE Proc., </booktitle> <volume> Vol. 1453, </volume> <pages> pp. 342-352, </pages> <year> 1991. </year>
Reference-contexts: It is therefore not surprising that the three brightness values corresponding to the basis illuminants can be used to predict brightness for any desired source vector. The linear combination of (7) has been used in its explicit form for the analysis of surface color <ref> [15] </ref> as well as specularity detection and photometric recognition [16]. It is immediate that expression (7) holds independently for all points on the imaged object. <p> However, since the linear combinations of the previous sections can be expected to differ between bands, a concatenated vector cannot be assumed to represent any single linear combination. Here, some of the results related to color-rank in <ref> [15] </ref> could lead to interesting results. 7 7 Illumination Manifold in Eigenspace We are now equipped to analyze the dimensionality of illumination manifolds in eigenspaces. An eigenspace E is an image subspace that is typically computed using the Karhunen-Loeve transform [13].
Reference: [16] <author> A. Shashua, </author> <title> "On Photometric Issues in 3D Visual Recognition from a Single 2D Image," </title> <type> Technical Report, </type> <institution> Artificial Intelligence Lab., MIT, </institution> <year> 1993. </year>
Reference-contexts: The linear combination of (7) has been used in its explicit form for the analysis of surface color [15] as well as specularity detection and photometric recognition <ref> [16] </ref>. It is immediate that expression (7) holds independently for all points on the imaged object.
Reference: [17] <author> M. A. Turk and A. P. Pentland, </author> <title> "Face Recognition Using Eigenfaces," </title> <booktitle> Proc. of IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pp. 586-591, </pages> <month> June </month> <year> 1991. </year>
Reference-contexts: 1 Introduction Appearance matching techniques are fast becoming popular in machine vision. Recent applications include face recognition <ref> [17] </ref> and the real-time recognition of complex 3D objects [4]. A representation of object appearance called the parametric eigenspace has resulted from this work [4].
Reference: [18] <author> R. J. Woodham, </author> <title> "Photometric method for determining surface orientation from multiple images," </title> <journal> Optical Engineering, </journal> <volume> Vol. 19, </volume> <pages> pp. 139-144, </pages> <year> 1980. </year> <month> 16 </month>
Reference-contexts: However, it turns intuitive when one notes that the three brightness values in (x) and the three corresponding sources fl contain all the information required to estimate the albedo (x) and the unit normal vector ^ n (x) as done in the case of photometric stereo <ref> [18] </ref>. It is therefore not surprising that the three brightness values corresponding to the basis illuminants can be used to predict brightness for any desired source vector.
References-found: 18

