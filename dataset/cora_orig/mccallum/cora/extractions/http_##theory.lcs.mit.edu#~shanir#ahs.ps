URL: http://theory.lcs.mit.edu/~shanir/ahs.ps
Refering-URL: http://theory.lcs.mit.edu/tds/dds.html
Root-URL: 
Title: Counting Networks  
Author: James Aspnes Maurice Herlihy Nir Shavit 
Date: August 4, 1993  
Abstract: Many fundamental multi-processor coordination problems can be expressed as counting problems: processes must cooperate to assign successive values from a given range, such as addresses in memory or destinations on an interconnection network. Conventional solutions to these problems perform poorly because of synchronization bottlenecks and high memory contention. Motivated by observations on the behavior of sorting networks, we offer a new approach to solving such problems, by introducing counting networks, a new class of networks that can be used to count. We give two counting network constructions, one of depth log n(1 + log n)=2 using n log n(1 + log n)=4 "gates," and a second of depth log 2 n using n log 2 n=2 gates. These networks avoid the sequential bottlenecks inherent to earlier solutions, and substantially lower the memory contention. Finally, to show that counting networks are not merely mathematical creatures, we provide experimental evidence that they outperform conventional synchroniza tion techniques under a variety of circumstances. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Agarwal and M. Cherian. </author> <booktitle> Adaptive Backoff Synchronization Techniques 16th Symposium on Computer Architecture, </booktitle> <month> June </month> <year> 1989. </year>
Reference-contexts: We define Bitonic [w] to be the network constructed by passing the outputs from two Bitonic [w=2] networks into a Merger [w] network, where the induction is grounded in the Bitonic <ref> [1] </ref> network which contains no balancers and simply passes its input directly to its output. This construction gives us a network consisting of log w+1 layers each consisting of w=2 balancers. 3.1 Proof of Correctness In this section we show that Bitonic [w] is a counting network. <p> Work is also needed in experimental directions, comparing counting networks to other techniques, for example those based on exponential backoff <ref> [1] </ref>, and for understanding their behavior in architectures other than the single-bus architecture provided by the Encore. We have made a start in this direction by comparing the performance of counting networks to that of known methods using the ASIM simulator of the MIT Alewife machine [19].
Reference: [2] <author> A. Agarwal et al. </author> <title> The MIT Alewife Machine: A Large-Scale Distributed-Memory Multiprocessor. </title> <booktitle> In Proceedings of Workshop on Scalable Shared Memory Multiprocessors. </booktitle> <publisher> Kluwer Academic Publishers, </publisher> <year> 1991. </year> <note> An extended version of this paper has been submitted for publication, and appears as MIT/LCS Memo TM-454, </note> <year> 1991. </year>
Reference: [3] <author> E. Aharonson and H. Attiya. </author> <title> Counting Network with Arbitrary Fan-Out. </title> <booktitle> In 3rd Symposium on Discrete Algorithms, </booktitle> <pages> pages 104-113. ACM-SIAM, </pages> <month> January </month> <year> 1992. </year>
Reference-contexts: We have made a start in this direction by deriving constructions and lower bounds for linearizable counting networks [20], networks which guarantee that the values assigned to tokens reflect the real-time order of their traversals. Aharonson and Attiya <ref> [3] </ref>, Felton, LaMarca, and Ladner [11], and Hardavellas, Karakos, and Mavronicolas [17] have investigated the structure of counting networks with fan-in greater than two.
Reference: [4] <author> M. Ajtai, J. Komlos and E. Szemeredi. </author> <title> An O(n log n) sorting network. </title> <booktitle> In Proceedings of the 15th ACM Symposium on the Theory of Computing, </booktitle> <pages> 1-9, </pages> <year> 1983. </year>
Reference-contexts: In this paper, we offer a new approach to solving such problems, by introducing counting networks, a new class of networks that can be used to count. Counting networks, like sorting networks <ref> [4, 7, 8] </ref>, are constructed from simple two-input two-output computing elements called balancers, connected to one another by wires. <p> To illustrate this property, consider an execution in which tokens traverse the network sequentially, one completely after the other. Figure 2 shows such an execution on a Bitonic <ref> [4] </ref> counting network which we will define formally in Section 3. As can be seen, the network moves input tokens to output wires in increasing order modulo w.
Reference: [5] <author> T.E. Anderson. </author> <title> The performance implications of spin-waiting alternatives for shared-memory multiprocessors. </title> <type> Technical Report 89-04-03, </type> <institution> University of Washington, </institution> <address> Seattle, WA 98195, </address> <month> April </month> <year> 1989. </year>
Reference-contexts: In practice, the performance of many shared-memory algorithms is often limited by conflicts at certain widely-shared memory locations, often called hot spots [30]. Reducing hot-spot conflicts has been the focus of hardware architecture design [15, 16, 22, 29] and experimental work in software <ref> [5, 13, 14, 25, 27] </ref>. Counting networks are also non-blocking: processes that undergo halting failures or delays while using a counting network do not prevent other processes from making progress. <p> tokens makes a transition in time (S), then approximately w=2 tokens emerge from the network every (S) time units, yielding a throughput of w=2 (S). is an increasing function whose exact form depends on the particular architecture, but similar measures of degradation have been observed in practice to grow linearly <ref> [5, 25] </ref>. The throughput of an oversaturated network is therefore maximized by choosing w and d to minimize S, bringing it as close as possible to 1.
Reference: [6] <author> J. Aspnes, M.P. Herlihy, and N. Shavit. </author> <booktitle> Counting Networks and Multi-Processor Coordination In Proceedings of the 23rd Annual Symposium on Theory of Computing, </booktitle> <address> May 1991, New Orleans, Louisiana. </address>
Reference: [7] <author> K.E. Batcher. </author> <title> Sorting networks and their applications. </title> <booktitle> In Proceedings of AFIPS Joint Computer Conference, </booktitle> <volume> 32 </volume> <pages> 338-334, </pages> <year> 1968. </year>
Reference-contexts: In this paper, we offer a new approach to solving such problems, by introducing counting networks, a new class of networks that can be used to count. Counting networks, like sorting networks <ref> [4, 7, 8] </ref>, are constructed from simple two-input two-output computing elements called balancers, connected to one another by wires. <p> Sorting A balancing network and a comparison network are isomorphic if one can be constructed from the other by replacing balancers by comparators or vice versa. The counting networks introduced in this paper are isomorphic to the Bitonic sorting network of Batcher <ref> [7] </ref> and to the Periodic Balanced sorting network of Dowd, Perl, Rudolph and Saks [9]. There is a sense in which constructing counting networks is "harder" than constructing sorting networks: Theorem 2.4 If a balancing network counts, then its isomorphic comparison network sorts, but not vice versa. <p> In this section we describe how to construct a counting network whose width is any power of 2. The layout of this network is isomorphic to Batcher's famous Bitonic sorting network <ref> [7, 8] </ref>, though its behavior and correctness arguments are completely different. We give an inductive construction, as this will later aid us in proving its correctness. Define the width w balancing network Merger [w] as follows.
Reference: [8] <author> T.H. Cormen, C.E. Leiserson, and R. L. Rivest. </author> <title> Introduction to Algorithms MIT Press, </title> <address> Cambridge MA, </address> <year> 1990. </year>
Reference-contexts: In this paper, we offer a new approach to solving such problems, by introducing counting networks, a new class of networks that can be used to count. Counting networks, like sorting networks <ref> [4, 7, 8] </ref>, are constructed from simple two-input two-output computing elements called balancers, connected to one another by wires. <p> or as load balancers [28], and that they deserve further attention. 2 Networks That Count 2.1 Counting Networks Counting networks belong to a larger class of networks called balancing networks, constructed from wires and computing elements called balancers, in a manner similar to the 2 way in which comparison networks <ref> [8] </ref> are constructed from wires and comparators. We begin by describing balancing networks. A balancer is a computing element with two input wires and two output wires 2 (see on its output wires. <p> w designated input wires x 0 ; x 1 ; ::; x w1 (which are not connected to output wires of balancers), w designated output wires y 0 ; y 1 ; ::; y w1 2 In Figure 1 as well as in the sequel, we adopt the notation of <ref> [8] </ref> and and draw wires as horizontal lines with balancers stretched vertically. 3 (similarly unconnected), and containing no cycles. Let the state of a network at a given time be defined as the union of the states of all its component balancers. <p> There is a sense in which constructing counting networks is "harder" than constructing sorting networks: Theorem 2.4 If a balancing network counts, then its isomorphic comparison network sorts, but not vice versa. Proof: It is easy to verify that balancing networks isomorphic to the Even-Odd or Insertion sorting networks <ref> [8] </ref> are not counting networks. 7 For the other direction, we construct a mapping from the comparison network tran-sitions to the isomorphic balancing network transitions. By the 0-1 principle [8], a comparison network which sorts all sequences of 0's and 1's is a sorting network. <p> Proof: It is easy to verify that balancing networks isomorphic to the Even-Odd or Insertion sorting networks <ref> [8] </ref> are not counting networks. 7 For the other direction, we construct a mapping from the comparison network tran-sitions to the isomorphic balancing network transitions. By the 0-1 principle [8], a comparison network which sorts all sequences of 0's and 1's is a sorting network. <p> In this section we describe how to construct a counting network whose width is any power of 2. The layout of this network is isomorphic to Batcher's famous Bitonic sorting network <ref> [7, 8] </ref>, though its behavior and correctness arguments are completely different. We give an inductive construction, as this will later aid us in proving its correctness. Define the width w balancing network Merger [w] as follows. <p> The final stage of the network combines each y A i and y B i in a single balancer, yielding final outputs z 2i and z 2i+1 . Figure 5 describes the recursive construction of a Block <ref> [8] </ref> network. The Periodic [2k] network consists of log k Block [2k] networks joined so that the i th output wire of one is the i th wire of the next. Figure 6 is a Periodic [8] counting network 3 This recursive construction is quite different from the one used by <p> Figure 5 describes the recursive construction of a Block <ref> [8] </ref> network. The Periodic [2k] network consists of log k Block [2k] networks joined so that the i th output wire of one is the i th wire of the next. Figure 6 is a Periodic [8] counting network 3 This recursive construction is quite different from the one used by Dowd et al.
Reference: [9] <author> M. Dowd, Y. Perl, L. Rudolph, and M. </author> <title> Saks. </title> <journal> The Periodic Balanced Sorting Network Journal of the ACM, </journal> <volume> 36(4) </volume> <pages> 738-757, </pages> <month> October </month> <year> 1989. </year>
Reference-contexts: The counting networks introduced in this paper are isomorphic to the Bitonic sorting network of Batcher [7] and to the Periodic Balanced sorting network of Dowd, Perl, Rudolph and Saks <ref> [9] </ref>. There is a sense in which constructing counting networks is "harder" than constructing sorting networks: Theorem 2.4 If a balancing network counts, then its isomorphic comparison network sorts, but not vice versa. <p> Each stage of this periodic network is interesting in its own right, since it can be used to achieve barrier synchronization with low contention. This counting network is isomorphic to the elegant balanced periodic sorting network of Dowd, Perl, Rudolph, and Saks <ref> [9] </ref>. However, its behavior, and therefore also our proof of correctness, are fundamentally different. We start by defining chains and cochains, notions taken from [9]. <p> This counting network is isomorphic to the elegant balanced periodic sorting network of Dowd, Perl, Rudolph, and Saks <ref> [9] </ref>. However, its behavior, and therefore also our proof of correctness, are fundamentally different. We start by defining chains and cochains, notions taken from [9]. Given a sequence x = fx i ji = 0; : : : ; n 1g, it is convenient to represent each index (subscript) as a binary string. A level i chain of x is a subsequence of x whose indices have the same i low-order bits. <p> By Lemma 4.2, if the level i 1 chains of z have the step property, so do the level i 1 chains of y. By Theorem 2.4, the proof of Theorem 4.4 constitutes a simple alternative proof that the balanced periodic comparison network of <ref> [9] </ref> is a sorting network. 15 5 Implementation and Applications In a MIMD shared-memory architecture, a balancer can be represented as a record with two fields: toggle is a boolean value that alternates between 0 and 1, and next is a 2-element array of pointers to successor balancers.
Reference: [10] <author> C.S. Ellis and T.J. Olson. </author> <title> Algorithms for parallel memory allocation. </title> <journal> Journal of Parallel Programming, </journal> <volume> 17(4) </volume> <pages> 303-345, </pages> <month> August </month> <year> 1988. </year>
Reference-contexts: A shared counter is simply an object that issues the numbers 0 to m 1 in response to m requests by processes. Shared counters are central to a number of shared-memory synchronization algorithms (e.g., <ref> [10, 12, 16, 31] </ref>). A producer/consumer buffer is a data structure in which items inserted by a pool of producer processes are removed by a pool of consumer processes. <p> one processor at a time, while the other processors wait. 16 balancer = [toggle: boolean, next: array [0..1] of ptr to balancer] traverse (b: balancer) loop until leaf (b) i := rmw (b.toggle := : b.toggle) b := b.next [i] end loop end traverse 5.1 Shared Counter A shared counter <ref> [12, 10, 16, 31] </ref> is a data structure that issues consecutive integers in response to increment requests. More formally, in any quiescent state in which m increment requests have been received, the values 0 to m1 have been issued in response.
Reference: [11] <author> E.W. Felton, A. LaMarca, and R. Ladner. </author> <title> Building Counting Networks from Larger Balancers. </title> <type> Technical Report 93-04-09, </type> <institution> University of Washington, </institution> <address> Seattle, WA 98195, </address> <month> April </month> <year> 1993. </year>
Reference-contexts: We have made a start in this direction by deriving constructions and lower bounds for linearizable counting networks [20], networks which guarantee that the values assigned to tokens reflect the real-time order of their traversals. Aharonson and Attiya [3], Felton, LaMarca, and Ladner <ref> [11] </ref>, and Hardavellas, Karakos, and Mavronicolas [17] have investigated the structure of counting networks with fan-in greater than two.
Reference: [12] <author> E. Freudenthal and A. </author> <booktitle> Gottlieb Process Coordination with Fetch-and-Increment In Proceedings of the 4th International Conference on Architecture Support for Programming Languages and Operating Systems, </booktitle> <address> April 1991, Santa Clara, California. </address>
Reference-contexts: A shared counter is simply an object that issues the numbers 0 to m 1 in response to m requests by processes. Shared counters are central to a number of shared-memory synchronization algorithms (e.g., <ref> [10, 12, 16, 31] </ref>). A producer/consumer buffer is a data structure in which items inserted by a pool of producer processes are removed by a pool of consumer processes. <p> one processor at a time, while the other processors wait. 16 balancer = [toggle: boolean, next: array [0..1] of ptr to balancer] traverse (b: balancer) loop until leaf (b) i := rmw (b.toggle := : b.toggle) b := b.next [i] end loop end traverse 5.1 Shared Counter A shared counter <ref> [12, 10, 16, 31] </ref> is a data structure that issues consecutive integers in response to increment requests. More formally, in any quiescent state in which m increment requests have been received, the values 0 to m1 have been issued in response.
Reference: [13] <author> D. Gawlick. </author> <title> Processing 'hot spots' in high performance systems. </title> <booktitle> In Proceedings COMP-CON'85, </booktitle> <year> 1985. </year> <month> 34 </month>
Reference-contexts: In practice, the performance of many shared-memory algorithms is often limited by conflicts at certain widely-shared memory locations, often called hot spots [30]. Reducing hot-spot conflicts has been the focus of hardware architecture design [15, 16, 22, 29] and experimental work in software <ref> [5, 13, 14, 25, 27] </ref>. Counting networks are also non-blocking: processes that undergo halting failures or delays while using a counting network do not prevent other processes from making progress.
Reference: [14] <author> J. Goodman, M. Vernon, and P. Woest. </author> <title> A set of efficient synchronization primitives for a large-scale shared-memory multiprocessor. </title> <booktitle> In 3rd International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <month> April </month> <year> 1989. </year>
Reference-contexts: In practice, the performance of many shared-memory algorithms is often limited by conflicts at certain widely-shared memory locations, often called hot spots [30]. Reducing hot-spot conflicts has been the focus of hardware architecture design [15, 16, 22, 29] and experimental work in software <ref> [5, 13, 14, 25, 27] </ref>. Counting networks are also non-blocking: processes that undergo halting failures or delays while using a counting network do not prevent other processes from making progress.
Reference: [15] <author> A. Gottlieb, R. Grishman, C.P. Kruskal, K.P. McAuliffe, L. Rudolph, and M. Snir. </author> <title> The NYU ultracomputer designing an mimd parallel computer. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-32(2):175-189, </volume> <month> February </month> <year> 1984. </year>
Reference-contexts: This decomposition has two performance benefits: It eliminates serial bottlenecks and reduces memory contention. In practice, the performance of many shared-memory algorithms is often limited by conflicts at certain widely-shared memory locations, often called hot spots [30]. Reducing hot-spot conflicts has been the focus of hardware architecture design <ref> [15, 16, 22, 29] </ref> and experimental work in software [5, 13, 14, 25, 27]. Counting networks are also non-blocking: processes that undergo halting failures or delays while using a counting network do not prevent other processes from making progress.
Reference: [16] <author> A. Gottlieb, B.D. Lubachevsky, and L. Rudolph. </author> <title> Basic techniques for the efficient coordination of very large numbers of cooperating sequential processors. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 5(2) </volume> <pages> 164-189, </pages> <month> April </month> <year> 1983. </year>
Reference-contexts: This decomposition has two performance benefits: It eliminates serial bottlenecks and reduces memory contention. In practice, the performance of many shared-memory algorithms is often limited by conflicts at certain widely-shared memory locations, often called hot spots [30]. Reducing hot-spot conflicts has been the focus of hardware architecture design <ref> [15, 16, 22, 29] </ref> and experimental work in software [5, 13, 14, 25, 27]. Counting networks are also non-blocking: processes that undergo halting failures or delays while using a counting network do not prevent other processes from making progress. <p> A shared counter is simply an object that issues the numbers 0 to m 1 in response to m requests by processes. Shared counters are central to a number of shared-memory synchronization algorithms (e.g., <ref> [10, 12, 16, 31] </ref>). A producer/consumer buffer is a data structure in which items inserted by a pool of producer processes are removed by a pool of consumer processes. <p> one processor at a time, while the other processors wait. 16 balancer = [toggle: boolean, next: array [0..1] of ptr to balancer] traverse (b: balancer) loop until leaf (b) i := rmw (b.toggle := : b.toggle) b := b.next [i] end loop end traverse 5.1 Shared Counter A shared counter <ref> [12, 10, 16, 31] </ref> is a data structure that issues consecutive integers in response to increment requests. More formally, in any quiescent state in which m increment requests have been received, the values 0 to m1 have been issued in response. <p> The buffer algorithm used here is essentially that of Gottlieb, Lubachevsky, and Rudolph <ref> [16] </ref>. The buffer is 17 a w-element array buff [0::w 1]. There are two w-width counting networks, a producer network, and a consumer network. A producer starts by traversing the producer network, leaving the network on wire i. <p> Each bitonic network has a slightly higher throughput than its periodic counterpart. 6.3 Producer/Consumer Buffers We compare the performance of several producer/consumer buffers implemented using the algorithm of Gottlieb, Lubachevsky, and Rudolph <ref> [16] </ref> discussed in Section 5. Each implementation has 8 producer processes, which continually produce items, and 8 consumer processes, which continually consume items. If a producer (consumer) process finds its buffer slot full (empty), it spins until the slot becomes empty (full).
Reference: [17] <author> N. Hardavellas, D. Karakos, and M. Mavronicolas. </author> <title> Notes on Sorting and Counting Networks. </title> <note> in Proceedings of WDAG'93, to appear. </note>
Reference-contexts: We have made a start in this direction by deriving constructions and lower bounds for linearizable counting networks [20], networks which guarantee that the values assigned to tokens reflect the real-time order of their traversals. Aharonson and Attiya [3], Felton, LaMarca, and Ladner [11], and Hardavellas, Karakos, and Mavronicolas <ref> [17] </ref> have investigated the structure of counting networks with fan-in greater than two. Klugerman and Plaxton [23] have shown an explicit network construction of depth O (c log fl n log n) for some small constant c, and an existential proof of a network of depth O (log n).
Reference: [18] <author> D. Hensgen and R.Finkel and U. Manber. </author> <title> Two algorithms for barrier synchronization. </title> <journal> International Journal of Parallel Programming, </journal> <volume> 17(1) </volume> <pages> 1-17, </pages> <year> 1988. </year>
Reference-contexts: We construct a barrier for n processes, where n = 0 mod w, using a width-w threshold counter. The construction is an adaptation of the "sense-reversing" barrier construction of <ref> [18] </ref> as follows. Just as for the counter construction, we associate a local counter c i with each output wire i. Let F be a boolean flag, initially false.
Reference: [19] <author> M.P. Herlihy, B.H. Lim, and N. Shavit. </author> <title> Low Contention Load Balancing on Large Scale Multiprocessors. </title> <booktitle> In 4th Annual ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <month> June </month> <year> 1992, </year> <pages> pp. 219-227. </pages>
Reference-contexts: We have made a start in this direction by comparing the performance of counting networks to that of known methods using the ASIM simulator of the MIT Alewife machine <ref> [19] </ref>. Preliminary results show that there is a substantial gain in performance due to parallelism on such distributed memory machines.
Reference: [20] <author> M.P. Herlihy, N. Shavit, and O. Waarts. </author> <title> Low-Contention Linearizable Counting. </title> <booktitle> In 32th IEEE Symposium on Foundations of Computer Science, </booktitle> <month> October </month> <year> 1991, </year> <pages> pp. 526-535. </pages>
Reference-contexts: Work is needed to develop other primitives, to derive upper and lower bounds and new performance measures. We have made a start in this direction by deriving constructions and lower bounds for linearizable counting networks <ref> [20] </ref>, networks which guarantee that the values assigned to tokens reflect the real-time order of their traversals. Aharonson and Attiya [3], Felton, LaMarca, and Ladner [11], and Hardavellas, Karakos, and Mavronicolas [17] have investigated the structure of counting networks with fan-in greater than two.
Reference: [21] <author> D. Kranz, R. Halstead, and E. Mohr. "Mul-T, </author> <title> A High-Performance Parallel Lisp", </title> <booktitle> ACM SIGPLAN '89 Conference on Programming Language Design and Implementation, </booktitle> <address> Port-land, OR, </address> <month> June </month> <year> 1989, </year> <pages> pp. 81-90. </pages>
Reference-contexts: In the remainder of this section, we present the results of timing experiments for several data structures implemented using counting networks. As a control, we compare these figures to those produced by more conventional implementations using spin locks These implementations were done on an Encore Multimax, using Mul-T <ref> [21] </ref>, a parallel dialect of Lisp. The spin lock is a simple "test-and-test-and-set" loop [26] written in assembly language, and provided by the Mul-T run-time system.
Reference: [22] <author> C.P. Kruskal, L. Rudolph, and M. Snir. </author> <title> Efficient synchronization on multiprocessors with shared memory. </title> <booktitle> In Fifth ACM SIGACT-SIGOPS Symposium on Principles of Distributed Computing, </booktitle> <month> August </month> <year> 1986. </year>
Reference-contexts: This decomposition has two performance benefits: It eliminates serial bottlenecks and reduces memory contention. In practice, the performance of many shared-memory algorithms is often limited by conflicts at certain widely-shared memory locations, often called hot spots [30]. Reducing hot-spot conflicts has been the focus of hardware architecture design <ref> [15, 16, 22, 29] </ref> and experimental work in software [5, 13, 14, 25, 27]. Counting networks are also non-blocking: processes that undergo halting failures or delays while using a counting network do not prevent other processes from making progress.
Reference: [23] <author> M. Klugerman and C.G. Plaxton. </author> <title> Small-depth Counting Networks. </title> <booktitle> In ACM Symposium on the Theory of Computing???. </booktitle>
Reference-contexts: Aharonson and Attiya [3], Felton, LaMarca, and Ladner [11], and Hardavellas, Karakos, and Mavronicolas [17] have investigated the structure of counting networks with fan-in greater than two. Klugerman and Plaxton <ref> [23] </ref> have shown an explicit network construction of depth O (c log fl n log n) for some small constant c, and an existential proof of a network of depth O (log n).
Reference: [24] <author> N.A. Lynch and M.R. Tuttle. </author> <title> Hierarchical Correctness Proofs for Distributed Algorithms. </title> <booktitle> In Sixth ACM SIGACT-SIGOPS Symposium on Principles of Distributed Computing, </booktitle> <month> August </month> <year> 1987, </year> <pages> pp. 137-151. </pages> <note> Full version available as MIT Technical Report MIT/LCS/TR-387. </note>
Reference-contexts: Although balancer transitions can occur concurrently, it is convenient to model them using an interleaving semantics in the style of Lynch and Tuttle <ref> [24] </ref>.
Reference: [25] <author> J.M. Mellor-Crummey and M.L. Scott. </author> <title> Algorithms for scalable synchronization on shared-memory multiprocessors. </title> <type> Technical Report Technical Report 342, </type> <institution> University of Rochester, Rochester, </institution> <address> NY 14627, </address> <month> April </month> <year> 1990. </year>
Reference-contexts: In practice, the performance of many shared-memory algorithms is often limited by conflicts at certain widely-shared memory locations, often called hot spots [30]. Reducing hot-spot conflicts has been the focus of hardware architecture design [15, 16, 22, 29] and experimental work in software <ref> [5, 13, 14, 25, 27] </ref>. Counting networks are also non-blocking: processes that undergo halting failures or delays while using a counting network do not prevent other processes from making progress. <p> tokens makes a transition in time (S), then approximately w=2 tokens emerge from the network every (S) time units, yielding a throughput of w=2 (S). is an increasing function whose exact form depends on the particular architecture, but similar measures of degradation have been observed in practice to grow linearly <ref> [5, 25] </ref>. The throughput of an oversaturated network is therefore maximized by choosing w and d to minimize S, bringing it as close as possible to 1.
Reference: [26] <author> L. Rudolph, </author> <title> Decentralized cache scheme for an MIMD parallel processor. </title> <booktitle> In 11th Annual Computing Architecture Conference, </booktitle> <year> 1983, </year> <pages> pp. 340-347. 35 </pages>
Reference-contexts: As a control, we compare these figures to those produced by more conventional implementations using spin locks These implementations were done on an Encore Multimax, using Mul-T [21], a parallel dialect of Lisp. The spin lock is a simple "test-and-test-and-set" loop <ref> [26] </ref> written in assembly language, and provided by the Mul-T run-time system.
Reference: [27] <author> J.M. </author> <title> Mellor-Crummey and M.L. </title> <booktitle> Scott Synchronization without Contention In Proceedings of the 4th International Conference on Architecture Support for Programming Languages and Operating Systems, </booktitle> <address> April 1991, Santa Clara, California. </address> ??? 
Reference-contexts: In practice, the performance of many shared-memory algorithms is often limited by conflicts at certain widely-shared memory locations, often called hot spots [30]. Reducing hot-spot conflicts has been the focus of hardware architecture design [15, 16, 22, 29] and experimental work in software <ref> [5, 13, 14, 25, 27] </ref>. Counting networks are also non-blocking: processes that undergo halting failures or delays while using a counting network do not prevent other processes from making progress.
Reference: [28] <author> D. Peleg and E. Upfal. </author> <title> The token distribution problem. </title> <booktitle> In 27th IEEE Symposium on Foundations of Computer Science, </booktitle> <month> October </month> <year> 1986. </year>
Reference-contexts: In summary, counting networks represent a new class of concurrent algorithms. They have a rich mathematical structure, they provide effective solutions to important problems, and they perform well in practice. We believe that counting networks have other potential uses, for example as interconnection networks [32] or as load balancers <ref> [28] </ref>, and that they deserve further attention. 2 Networks That Count 2.1 Counting Networks Counting networks belong to a larger class of networks called balancing networks, constructed from wires and computing elements called balancers, in a manner similar to the 2 way in which comparison networks [8] are constructed from wires <p> Finally, we point out that smoothing networks, balancing networks that smooth but do not necessarily count, are interesting in their own right since they can be used as hardware solutions to problems such as load balancing (cf. <ref> [28] </ref>). 32 9 Acknowledgments Orli Waarts made many important remarks. The serialization lemma and the observation that smoothing + sorting = counting, are products of our cooperation with her and with Eli Gafni, to whom we are also in debt.
Reference: [29] <author> G.H. Pfister et al. </author> <title> The IBM research parallel processor prototype (RP3): introduction and architecture. </title> <booktitle> In International Conference on Parallel Processing, </booktitle> <year> 1985. </year>
Reference-contexts: This decomposition has two performance benefits: It eliminates serial bottlenecks and reduces memory contention. In practice, the performance of many shared-memory algorithms is often limited by conflicts at certain widely-shared memory locations, often called hot spots [30]. Reducing hot-spot conflicts has been the focus of hardware architecture design <ref> [15, 16, 22, 29] </ref> and experimental work in software [5, 13, 14, 25, 27]. Counting networks are also non-blocking: processes that undergo halting failures or delays while using a counting network do not prevent other processes from making progress.
Reference: [30] <author> G.H. Pfister and A. Norton. </author> <title> `hot spot' contention and combining in multistage interconnection networks. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-34(11):933-938, </volume> <month> November </month> <year> 1985. </year>
Reference-contexts: This decomposition has two performance benefits: It eliminates serial bottlenecks and reduces memory contention. In practice, the performance of many shared-memory algorithms is often limited by conflicts at certain widely-shared memory locations, often called hot spots <ref> [30] </ref>. Reducing hot-spot conflicts has been the focus of hardware architecture design [15, 16, 22, 29] and experimental work in software [5, 13, 14, 25, 27].
Reference: [31] <author> H.S. Stone. </author> <title> Database applications of the fetch-and-add instruction. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-33(7):604-612, </volume> <month> July </month> <year> 1984. </year>
Reference-contexts: A shared counter is simply an object that issues the numbers 0 to m 1 in response to m requests by processes. Shared counters are central to a number of shared-memory synchronization algorithms (e.g., <ref> [10, 12, 16, 31] </ref>). A producer/consumer buffer is a data structure in which items inserted by a pool of producer processes are removed by a pool of consumer processes. <p> one processor at a time, while the other processors wait. 16 balancer = [toggle: boolean, next: array [0..1] of ptr to balancer] traverse (b: balancer) loop until leaf (b) i := rmw (b.toggle := : b.toggle) b := b.next [i] end loop end traverse 5.1 Shared Counter A shared counter <ref> [12, 10, 16, 31] </ref> is a data structure that issues consecutive integers in response to increment requests. More formally, in any quiescent state in which m increment requests have been received, the values 0 to m1 have been issued in response.
Reference: [32] <author> U. Vishkin. </author> <title> A parallel-design distributed-implementation (PDDI) general purpose computer. </title> <journal> Theoretical Computer Science, </journal> <volume> 32 </volume> <pages> 157-172, </pages> <year> 1984. </year> <month> 36 </month>
Reference-contexts: In summary, counting networks represent a new class of concurrent algorithms. They have a rich mathematical structure, they provide effective solutions to important problems, and they perform well in practice. We believe that counting networks have other potential uses, for example as interconnection networks <ref> [32] </ref> or as load balancers [28], and that they deserve further attention. 2 Networks That Count 2.1 Counting Networks Counting networks belong to a larger class of networks called balancing networks, constructed from wires and computing elements called balancers, in a manner similar to the 2 way in which comparison networks
References-found: 32

