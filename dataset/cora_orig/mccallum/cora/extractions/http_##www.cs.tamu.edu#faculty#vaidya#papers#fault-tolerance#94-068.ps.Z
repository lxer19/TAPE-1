URL: http://www.cs.tamu.edu/faculty/vaidya/papers/fault-tolerance/94-068.ps.Z
Refering-URL: http://www.cs.tamu.edu/faculty/vaidya/Vaidya-ftc.html
Root-URL: http://www.cs.tamu.edu
Title: Another Two-Level Failure Recovery Scheme: Performance Impact of Checkpoint Placement and Checkpoint Latency  
Author: Nitin H. Vaidya 
Keyword: Experimental measurements of checkpoint latency and checkpoint overhead for  
Note: four applications are presented.  
Address: College Station, TX 77843-3112  
Affiliation: Department of Computer Science Texas A&M University  
Pubnum: Technical Report 94-068  
Email: E-mail: vaidya@cs.tamu.edu  
Date: December 1994  
Abstract: This report deals with the design and evaluation of a "two-level" failure recovery scheme for distributed systems. In our previous work [30, 32], we motivated a "two-level" recovery approach that tolerates the more probable failures with a low overhead, and less probable failures with possibly higher overhead. The two-level approach can achieve a smaller overhead as compared to traditional recovery schemes. The contributions of this report are summarized below: * We present and evaluate a "two-level" recovery scheme that is suitable for a network of workstations, each workstation having a local disk. The recovery scheme presented in the report can tolerate transient processor failures with a low overhead, while other failures require a larger overhead. The report presents analysis of the average (expected) task completion time using the proposed scheme. This scheme has been implemented on a workstation cluster. Our analysis indicates that the proposed two-level recovery scheme can achieve better performance as compared to existing "one-level" recovery schemes. * The report also evaluates the impact of checkpoint latency on the performance of the recovery scheme. To our knowledge, no analysis of the performance impact of checkpoint latency has been carried out previously. fl References [32, 30] present material related to this report. The interested reader can obtain these references via anonymous ftp from ftp.cs.tamu.edu:/pub/vaidya. y This report was revised several times in January 1995. The purpose of these revisions was to add Sections 10 and 11, and to revise Section 1. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> L. Alvisi, B. Hoppe, and K. Marzullo, </author> <title> "Nonblocking and orphan-free message logging protocols," </title> <booktitle> in Digest of papers: The 23 rd Int. Symp. Fault-Tolerant Comp., </booktitle> <pages> pp. 145-154, </pages> <month> 42 </month> <year> 1993. </year>
Reference-contexts: scheme, it is assumed that a single process is scheduled on each processor. 1 (This assumption is not necessary for the scheme proposed and analyzed later in this report.) The two component recovery schemes are summarized here: * The first component is the single process failure tolerance scheme presented in <ref> [1] </ref>. In this scheme, the processes periodically take checkpoints (which need not be consistent with each other). The checkpoint of a process can be saved in any volatile storage except that of its own processor. The messages are saved by their senders in their volatile storage.
Reference: [2] <institution> Anonymous referee's comments on a 1995 SIGMETRICS paper [32], </institution> <month> January </month> <year> 1995. </year>
Reference-contexts: We refer to recovery schemes having this capability as two-level recovery schemes. This approach can be generalized to multi-level recovery [30]. It was recently brought to our attention <ref> [2] </ref> that, for transaction-oriented systems, Gelenbe [8] previously proposed an approach similar to the multi-level recovery approach. Gelenbe's work is summarized in Section 11. Most existing recovery schemes are "one-level" in the sense that their actions during failure-free execution are designed to tolerate the worst case failure scenario. <p> This definition can also be extended to multi-level recovery schemes. 38 It was recently brought to our attention <ref> [2] </ref> that Gelenbe [8] previously proposed a "multiple checkpointing" approach that is very similar to the "multi-level" approach that we advocate in this report. Gelenbe divides system failures into multiple (n) categories according to their severity. <p> The MAT multiplication program is similar to that presented by Plank et al. [19]. The FFT program was provided by Akhilesh Kumar of Texas A&M University. We thank the anonymous referee of one of our papers <ref> [2] </ref> who pointed us to the related work by Gelenbe [8].
Reference: [3] <author> K. M. Chandy, J. C. Browne, C. W. Dissly, and W. R. Uhrig, </author> <title> "Analytic models for rollback and recovery strategies in data base systems," </title> <journal> IEEE Trans. Softw. Eng., </journal> <volume> vol. 1, </volume> <pages> pp. 100-110, </pages> <month> March </month> <year> 1975. </year>
Reference-contexts: If the failure is detected when t time units of computation was performed after checkpoint CP, then it is assumed that t units of execution is required to re-do the lost computation (in absence of further failures), excluding checkpoint overhead. In the past, many researchers have assumed (e.g., <ref> [3] </ref>) that the time required to re-do the computation is fi t for some constant fi. Thus, we assume fi = 1 here. This assumption is reasonable for parallel applications of interest. <p> Significant effort has been devoted in the past for analytically determining optimal checkpoint intervals for checkpointing and rollback recovery schemes <ref> [3, 7, 12, 25, 33, 34] </ref>. Due to the complexity of the expressions for the two-level recovery scheme under consideration, an analytical approach for determining optimal k and is not very attractive. Instead, we choose to determine the optimal values numerically. <p> These curves are not always convex, unlike the traditional checkpointing and rollback schemes (e.g., <ref> [3] </ref>). The curve for k = 1 is also shown in Figure 10. When k = 1, all the checkpoints are stable checkpoints, and the two-level recovery scheme reduces to traditional checkpointing schemes. Therefore, as shown previously [3], the curve for k = 1 is convex and has exactly one minimum. <p> curves are not always convex, unlike the traditional checkpointing and rollback schemes (e.g., <ref> [3] </ref>). The curve for k = 1 is also shown in Figure 10. When k = 1, all the checkpoints are stable checkpoints, and the two-level recovery scheme reduces to traditional checkpointing schemes. Therefore, as shown previously [3], the curve for k = 1 is convex and has exactly one minimum. As seen in Figure 10, k = 4 can achieve a lower overhead as compared to k = 1; 2; 3. than k = 5; 6; 7 also.
Reference: [4] <author> K. M. Chandy and L. Lamport, </author> <title> "Distributed snapshots: Determining global states in distributed systems," </title> <journal> ACM Trans. Comp. Syst., </journal> <volume> vol. 3, </volume> <pages> pp. 63-75, </pages> <month> February </month> <year> 1985. </year>
Reference-contexts: processor failure tolerance scheme presented in [31] instead of a single process failure tolerance scheme, as described below. 2 A consistent checkpoint consists of one checkpoint per process such that a message sent after the check point of one process is not received by another process before taking its checkpoint <ref> [4, 11] </ref>. 4 Therefore, these checkpoints are called N-checkpoints. For this component scheme, the failure-free overhead per checkpoint interval is denoted by C N . Volatile storage access is cheaper than accessing the shared stable storage. Therefore, C 1 is expected to be smaller than C N . <p> It is clear that r p. The analysis presented here becomes applicable to this model if p is replaced by r in all the expressions derived in the report. 4 Checkpointing Scheme The processes periodically take consistent checkpoints using some consistent checkpointing algorithm, for example, Chandy-Lamport <ref> [4] </ref>. (For uni-process applications, trivially, any checkpoint of the process is a "consistent" checkpoint.) The consistent checkpoints are assumed to be equidistant. (In practice, the checkpoints will not be exactly equidistant, 7 but can be made approximately equidistant.) Every k-th consistent checkpoint is stored on the stable storage, all other checkpoints
Reference: [5] <author> E. N. Elnozahy, D. B. Johnson, and W. Zwaenepoel, </author> <title> "The performance of consistent checkpointing," </title> <booktitle> in Symposium on Reliable Distributed Systems, </booktitle> <year> 1992. </year>
Reference-contexts: Two extreme cases occur when k = 1 or k = . When k = 1, all the consistent checkpoints are stable checkpoints this corresponds to traditional implementations of consistent checkpointing (e.g. <ref> [5] </ref>). When k = , the recovery scheme takes only local checkpoints. In this case, if a permanent processor failure or a local storage failure occurs, the application must be restarted from the beginning. <p> Taking only stable checkpoints is not likely to be optimal in most cases. This is interesting, as most past implementations take only stable checkpoints (e.g., <ref> [5] </ref>), and therefore are often sub-optimal. 9 Impact of Checkpoint Latency on Performance Increasing the checkpoint latency does not increase the failure-free execution time of the application. However, it does increase the "window of vulnerability" of a given checkpoint. <p> The SPARCstation-10 workstation has about 17 Mbyte RAM memory free to be used by an application. The page size on this machine is 4096 bytes (or 1024 words). Two methods for taking individual process checkpoints are presently evaluated. (Both the methods have been previously used by other researchers also <ref> [5, 14, 19] </ref>.) * "Sequential-checkpoint" : In this method, when a process wants to take a checkpoint, it saves its state on the storage, and then proceeds with the computation. The computation is not overlapped with the checkpointing operation.
Reference: [6] <author> S. Garg and K. F. Wong, </author> <title> "Analysis of an improved distributed checkpointing algorithm," </title> <type> Tech. Rep. </type> <institution> WUCS-93-37, Dept. of Comp. Sc., Washington University, </institution> <month> June </month> <year> 1993. </year>
Reference: [7] <author> E. Gelenbe and D. Derochette, </author> <title> "Performance of rollback recovery systems under intermittent failures," </title> <journal> Comm. ACM, </journal> <volume> vol. 21, </volume> <pages> pp. 493-499, </pages> <month> June </month> <year> 1978. </year>
Reference-contexts: Checkpoint latency is usually at least as large as the checkpoint overhead. (As stated in Section 1, our analysis does not consider implementations where the latency is smaller than checkpoint overhead.) 3 Our assumption is similar to [10]. Some researchers <ref> [7] </ref> assume that the checkpoint overhead is exponentially distributed, though, to our knowledge there has been no experimental justification of this assumption. 8 For many implementations of checkpointing (e.g., copy-on-write), checkpoint latency is larger than the checkpoint overhead. 4 Let the checkpoint latency for a local checkpoint be L l and <p> Significant effort has been devoted in the past for analytically determining optimal checkpoint intervals for checkpointing and rollback recovery schemes <ref> [3, 7, 12, 25, 33, 34] </ref>. Due to the complexity of the expressions for the two-level recovery scheme under consideration, an analytical approach for determining optimal k and is not very attractive. Instead, we choose to determine the optimal values numerically.
Reference: [8] <author> E. Gelenbe, </author> <title> "A model for roll-back recovery with multiple checkpoints," </title> <booktitle> in 2nd Int. Conf. on Software Engineering, </booktitle> <pages> pp. 251-255, </pages> <month> October </month> <year> 1976. </year>
Reference-contexts: We refer to recovery schemes having this capability as two-level recovery schemes. This approach can be generalized to multi-level recovery [30]. It was recently brought to our attention [2] that, for transaction-oriented systems, Gelenbe <ref> [8] </ref> previously proposed an approach similar to the multi-level recovery approach. Gelenbe's work is summarized in Section 11. Most existing recovery schemes are "one-level" in the sense that their actions during failure-free execution are designed to tolerate the worst case failure scenario. <p> It demonstrates that two-level recovery can achieve a better performance than a one-level recovery scheme. Although a large number of researchers have analyzed checkpointing and recovery [3, 6, 7, 9, 10, 12, 13, 17, 22, 25, 26, 28, 33, 34], to our knowledge, except for Gelenbe <ref> [8] </ref>, no analysis of two-level recovery schemes has been attempted by other researchers. * Another objective of this report is to analyze the impact of checkpoint latency on the performance of the recovery schemes. Checkpoint latency is the duration of time it takes to establish a checkpoint. <p> This definition can also be extended to multi-level recovery schemes. 38 It was recently brought to our attention [2] that Gelenbe <ref> [8] </ref> previously proposed a "multiple checkpointing" approach that is very similar to the "multi-level" approach that we advocate in this report. Gelenbe divides system failures into multiple (n) categories according to their severity. The system takes n types of checkpoints, each type of checkpoint designed for one type of failures. <p> occurrence, while Gelenbe characterizes a "type" of failure according to how "difficult" it is to recover from the failure. (A failure of type 1 is less "difficult" than a failure of type 2 if a checkpoint for failure type 2 can be used to recover from a type 1 failure <ref> [8] </ref>.) To our knowledge, Gelenbe did not present specific multi-level schemes for distributed systems. His analysis as such may not be applicable to the multi-level schemes of our interest, for two reasons: * Gelenbe assumes the failures of different types to be governed by Poisson process. <p> The MAT multiplication program is similar to that presented by Plank et al. [19]. The FFT program was provided by Akhilesh Kumar of Texas A&M University. We thank the anonymous referee of one of our papers [2] who pointed us to the related work by Gelenbe <ref> [8] </ref>.
Reference: [9] <author> E. Gelenbe, </author> <title> "On the optimum checkpointing interval," </title> <journal> J. ACM, </journal> <volume> vol. 2, </volume> <pages> pp. 259-270, </pages> <month> April </month> <year> 1979. </year>
Reference: [10] <author> V. Grassi, L. Donatiello, and S. Tucci, </author> <title> "On the optimal checkpointing of critical tasks and transaction-oriented systems," </title> <journal> IEEE Trans. Softw. Eng., </journal> <volume> vol. 18, </volume> <pages> pp. 72-77, </pages> <month> Jan-uary </month> <year> 1992. </year>
Reference-contexts: Checkpoint latency is usually at least as large as the checkpoint overhead. (As stated in Section 1, our analysis does not consider implementations where the latency is smaller than checkpoint overhead.) 3 Our assumption is similar to <ref> [10] </ref>.
Reference: [11] <author> R. Koo and S. Toueg, </author> <title> "Checkpointing and rollback-recovery for distributed systems," </title> <journal> IEEE Trans. Softw. Eng., </journal> <volume> vol. 13, </volume> <pages> pp. 23-31, </pages> <month> January </month> <year> 1987. </year>
Reference-contexts: Most existing recovery schemes are "one-level" in the sense that their actions during failure-free execution are designed to tolerate the worst case failure scenario. For example, the traditional consistent checkpointing algorithms are designed to tolerate simultaneous failure of all components in the system <ref> [11, 20] </ref>. The two-level recovery approach can achieve lower overhead than one-level schemes by differentiating between the more probable failures and the less probable failures. Previously, we demonstrated that, it is often advantageous to use two-level recovery schemes as compared to traditional one-level recovery schemes [30, 32]. <p> processor failure tolerance scheme presented in [31] instead of a single process failure tolerance scheme, as described below. 2 A consistent checkpoint consists of one checkpoint per process such that a message sent after the check point of one process is not received by another process before taking its checkpoint <ref> [4, 11] </ref>. 4 Therefore, these checkpoints are called N-checkpoints. For this component scheme, the failure-free overhead per checkpoint interval is denoted by C N . Volatile storage access is cheaper than accessing the shared stable storage. Therefore, C 1 is expected to be smaller than C N .
Reference: [12] <author> V. G. Kulkarni, V. F. Nicola, and K. S. Trivedi, </author> <title> "Effects of checkpointing and queueing on program performance," </title> <journal> Commun. Statist.-Stochastic Models, </journal> <volume> vol. 4, no. 6, </volume> <pages> pp. 615-648, </pages> <year> 1990. </year>
Reference-contexts: Significant effort has been devoted in the past for analytically determining optimal checkpoint intervals for checkpointing and rollback recovery schemes <ref> [3, 7, 12, 25, 33, 34] </ref>. Due to the complexity of the expressions for the two-level recovery scheme under consideration, an analytical approach for determining optimal k and is not very attractive. Instead, we choose to determine the optimal values numerically.
Reference: [13] <author> P. L'Ecuyer and J. Malenfant, </author> <title> "Computing optimal checkpointing strategies for rollback and recovery systems," </title> <journal> IEEE Trans. Computers, </journal> <volume> vol. 37, </volume> <pages> pp. 491-496, </pages> <month> April </month> <year> 1988. </year>
Reference: [14] <author> J. Leon, A. L. Fisher, and P. Steenkiste, </author> <title> "Fail-safe PVM: A portable package for distributed programming with transparent recovery," </title> <type> Tech. Rep. </type> <institution> CMU-CS-93-124, School of Computer Science, Carnegie Mellon University, Pittsburgh, </institution> <month> February </month> <year> 1993. </year> <month> 43 </month>
Reference-contexts: The SPARCstation-10 workstation has about 17 Mbyte RAM memory free to be used by an application. The page size on this machine is 4096 bytes (or 1024 words). Two methods for taking individual process checkpoints are presently evaluated. (Both the methods have been previously used by other researchers also <ref> [5, 14, 19] </ref>.) * "Sequential-checkpoint" : In this method, when a process wants to take a checkpoint, it saves its state on the storage, and then proceeds with the computation. The computation is not overlapped with the checkpointing operation.
Reference: [15] <author> K. Li, J. F. Naughton, and J. S. Plank, </author> <title> "Low-latency, concurrent checkpointing for parallel programs," </title> <journal> IEEE Trans. Par. Distr. Syst., </journal> <volume> vol. 5, </volume> <pages> pp. 874-879, </pages> <month> August </month> <year> 1994. </year>
Reference-contexts: Checkpoint overhead is the increase in the execution time of an application due to a checkpoint. In simple-minded implementations of checkpointing, checkpoint latency equals the checkpoint overhead. However, in some (more efficient) implementations, checkpoint latency is much larger than the checkpoint overhead (e.g., copy-on-write <ref> [15] </ref>). In this report, we study the impact of checkpoint latency on the average performance overhead. To our knowledge, there has not been any previous work on modeling and analysis of checkpoint latency. Terminology: Plank [20] uses the term checkpoint time to denote what we call checkpoint latency.
Reference: [16] <author> D. Long, J. Carroll, and C. Park, </author> <title> "A study of the reliability of internet sites," </title> <booktitle> in Proc. Symp. Rel. Distr. Systems, </booktitle> <pages> pp. 177-186, </pages> <year> 1991. </year>
Reference-contexts: In this report, we present analytical results for a hypothetical task. The chosen parameter values are motivated by the experimental results presented in Section 10, and reference <ref> [16] </ref>. Conclusions drawn from the numerical results presented in this section are applicable to a wide range of parameters. Assuming the parameters shown in Table 1, assume L s = C s and L l = C l .
Reference: [17] <author> V. F. Nicola and J. M. van Spanje, </author> <title> "Comparative analysis of different models of check-pointing and recovery," </title> <journal> IEEE Trans. Softw. Eng., </journal> <volume> vol. 16, </volume> <pages> pp. 807-821, </pages> <month> August </month> <year> 1990. </year>
Reference: [18] <author> D. A. Patterson and J. L. Hennessy, </author> <title> Computer Organization & Design: The Hardware/Software Interface. </title> <publisher> Morgan Kaufmann Publishers, </publisher> <year> 1994. </year>
Reference-contexts: This report analyzes an approach to reduce the average performance overhead. The design principle "make the common case fast" has been successfully used in designing many components of a computer system (e.g., cache memory, RISC <ref> [18] </ref>) and some aspects of checkpointing and rollback [21, 36]. However, the designers of distributed rollback recovery schemes have largely ignored this guideline. In any system, some failure scenarios have a greater probability of occurring as compared to other failure scenarios.
Reference: [19] <author> J. S. Plank, M. Beck, G. Kingsley, and K. Li, "Libckpt: </author> <title> Transparent checkpointing under Unix," </title> <booktitle> in Usenix Winter 1995 Technical Conference, </booktitle> <address> New Orleans, </address> <month> January </month> <year> 1995. </year>
Reference-contexts: Failures can occur during normal operation, during checkpointing or during recovery. (A failure can occur before the system has recovered from a previous failure.) Recovery is 4 Example: In some implementations, when a process wants to take a checkpoint, it forks a child process <ref> [19] </ref>. The child process saves the state (which is identical to the parent process' state when it executed fork), while the parent process continues to perform computation. <p> The SPARCstation-10 workstation has about 17 Mbyte RAM memory free to be used by an application. The page size on this machine is 4096 bytes (or 1024 words). Two methods for taking individual process checkpoints are presently evaluated. (Both the methods have been previously used by other researchers also <ref> [5, 14, 19] </ref>.) * "Sequential-checkpoint" : In this method, when a process wants to take a checkpoint, it saves its state on the storage, and then proceeds with the computation. The computation is not overlapped with the checkpointing operation. <p> Acknowledgements The checkpointer used in our experimental evaluation is based on a checkpointer written by Bennet Yee and David Applegate of Carnegie Mellon University during 1986-88. The MAT multiplication program is similar to that presented by Plank et al. <ref> [19] </ref>. The FFT program was provided by Akhilesh Kumar of Texas A&M University. We thank the anonymous referee of one of our papers [2] who pointed us to the related work by Gelenbe [8].
Reference: [20] <author> J. S. Plank, </author> <title> Efficient Checkpointing on MIMD Architectures. </title> <type> PhD thesis, </type> <institution> Dept. of Computer Science, Princeton University, </institution> <month> June </month> <year> 1993. </year>
Reference-contexts: Most existing recovery schemes are "one-level" in the sense that their actions during failure-free execution are designed to tolerate the worst case failure scenario. For example, the traditional consistent checkpointing algorithms are designed to tolerate simultaneous failure of all components in the system <ref> [11, 20] </ref>. The two-level recovery approach can achieve lower overhead than one-level schemes by differentiating between the more probable failures and the less probable failures. Previously, we demonstrated that, it is often advantageous to use two-level recovery schemes as compared to traditional one-level recovery schemes [30, 32]. <p> In this report, we study the impact of checkpoint latency on the average performance overhead. To our knowledge, there has not been any previous work on modeling and analysis of checkpoint latency. Terminology: Plank <ref> [20] </ref> uses the term checkpoint time to denote what we call checkpoint latency. Plank uses the term checkpoint latency to mean something else. Note: As will be elaborated in Section 10, it turns out that checkpoint latency can sometimes be smaller than checkpoint overhead. This is somewhat counter-intuitive. <p> In this method, computation is overlapped with checkpointing, therefore, checkpoint overhead may be expected to be smaller than the checkpoint latency. Also, the checkpoint overhead with this method may be expected to be smaller than sequential-checkpointing. 6 Plank <ref> [20] </ref> presents measurements of checkpoint latency and overhead for applications executed on an iPSC/860 multicomputer. These measurements, however, do not provide information regarding the relationship between local and stable checkpoint overheads and latencies. 30 In either method, the executable code is not saved as a part of the checkpoint.
Reference: [21] <author> D. K. Pradhan and N. H. Vaidya, </author> <title> "Roll-forward checkpointing scheme: A novel fault-tolerant architecture," </title> <journal> IEEE Trans. Computers, </journal> <volume> vol. 43, </volume> <pages> pp. 1163-1174, </pages> <month> October </month> <year> 1994. </year>
Reference-contexts: This report analyzes an approach to reduce the average performance overhead. The design principle "make the common case fast" has been successfully used in designing many components of a computer system (e.g., cache memory, RISC [18]) and some aspects of checkpointing and rollback <ref> [21, 36] </ref>. However, the designers of distributed rollback recovery schemes have largely ignored this guideline. In any system, some failure scenarios have a greater probability of occurring as compared to other failure scenarios. In the context of failure recovery, the "common case" consists of the more probable failure scenarios. <p> The two approaches are similar, however, in that they both take two types of checkpoints. We previously proposed a roll-forward recovery scheme <ref> [21, 29] </ref> for duplex systems that tolerates single processor failures with a low overhead, and multiple failures with a high overhead.
Reference: [22] <author> A. Reuter, </author> <title> "Performance analysis of recovery techniques," </title> <journal> ACM Trans. Database Systems, </journal> <volume> vol. 9, </volume> <pages> pp. 526-559, </pages> <month> December </month> <year> 1984. </year>
Reference: [23] <author> C. Schimmel, </author> <title> UNIX Systems for Modern Architectures. </title> <publisher> Addison-Wesley, </publisher> <year> 1994. </year>
Reference-contexts: The checkpoint size was varied by changing the size of each set of data points. The remaining two applications were synthetic. In the present-day Unix implementations (and its variants), the fork command is implemented using the copy-on-write technique <ref> [23] </ref>. Hence, the checkpoint overhead of forked-checkpoint may be expected to depend on the program's locality of reference. Therefore, we implemented two types of locality: * "Low-locality" (LL) : The pseudo-code for this application is presented in Figure 17 (a).
Reference: [24] <author> R. D. Schlichting and F. B. Schneider, </author> <title> "Fail-stop processors: An approach to designing fault-tolerant computing systems," </title> <journal> ACM Trans. Comp. Syst., </journal> <volume> vol. 1, </volume> <pages> pp. 222-238, </pages> <month> August </month> <year> 1983. </year>
Reference-contexts: If the probability of correlated failure of the two cards is small, then the scheme proposed in the report is useful for this system. Failure Model In this report, we consider only fail-stop failures <ref> [24] </ref>. We first describe the failure model assumed in this report, followed by another failure model that may be applicable to some systems. The analysis presented in the report assumes the first model, however, the analysis is applicable to the second model with a minor modification.
Reference: [25] <author> K. Shin, T.-H. Lin, and Y.-H. Lee, </author> <title> "Optimal checkpointing of real-time tasks," </title> <journal> IEEE Trans. Computers, </journal> <volume> vol. 36, </volume> <pages> pp. 1328-1341, </pages> <month> November </month> <year> 1987. </year>
Reference-contexts: Significant effort has been devoted in the past for analytically determining optimal checkpoint intervals for checkpointing and rollback recovery schemes <ref> [3, 7, 12, 25, 33, 34] </ref>. Due to the complexity of the expressions for the two-level recovery scheme under consideration, an analytical approach for determining optimal k and is not very attractive. Instead, we choose to determine the optimal values numerically.
Reference: [26] <author> A. N. Tantawi and M. Ruschitzka, </author> <title> "Performance analysis of checkpointing strategies," </title> <journal> ACM Trans. Comp. Syst., </journal> <volume> vol. 2, </volume> <pages> pp. 123-144, </pages> <month> May </month> <year> 1984. </year>
Reference: [27] <author> K. S. Trivedi, </author> <title> Probability and Statistics with Reliability, Queueing and Computer Science Applications. </title> <publisher> Prentice-Hall, </publisher> <year> 1988. </year>
Reference-contexts: No failure occurs after this rollback. (The next section explains the meaning of various states in Figure 7.) 7.1.1 Markov Chain for the Execution of a Type 2 Segment To evaluate the expected execution time of the task, we construct a finite-state Markov chain <ref> [27] </ref>. Markov chains have been used for evaluating expected execution time by Ziv and Bruck also [35]. The procedure for constructing the Markov chain is presented later, we first present some preliminaries. The Markov chain has an unique start state and an unique absorbing state. <p> Let N s denote the expected number of entries into state s. Clearly, N 0 = N k = 1. The other N s 's can be obtained using standard techniques <ref> [27] </ref>, as follows. <p> Observe that, in most cases, the checkpoint overheads increase almost linearly with checkpoint size the rate of increase depends on where the checkpoint is stored and whether the checkpoint is sequential or forked. For most measurements of average execution time presented in the following, the standard deviation <ref> [27] </ref> of the execution time is less than 0.4% of the average execution time. For some measurements the standard deviation is larger than 0.4%, but never exceeds 1% of the average execution time.
Reference: [28] <author> S. J. Upadhyaya and K. K. Saluja, </author> <title> "An experimental study to determine task size for rollback recovery schemes," </title> <journal> IEEE Trans. Computers, </journal> <volume> vol. 37, </volume> <pages> pp. 872-877, </pages> <month> July </month> <year> 1988. </year>
Reference: [29] <author> N. H. Vaidya, </author> <title> Low-Cost Schemes for Fault Tolerance. </title> <type> PhD thesis, </type> <institution> University of Massachusetts-Amherst, </institution> <month> February </month> <year> 1993. </year> <title> Available from UMI Dissertation Services, Ann Arbor, Michigan. Order number 9316722. </title> <type> 44 </type>
Reference-contexts: The two approaches are similar, however, in that they both take two types of checkpoints. We previously proposed a roll-forward recovery scheme <ref> [21, 29] </ref> for duplex systems that tolerates single processor failures with a low overhead, and multiple failures with a high overhead.
Reference: [30] <author> N. H. Vaidya, </author> <title> "A case for multi-level distributed recovery schemes," </title> <type> Tech. Rep. 94-043, </type> <institution> Computer Science Department, Texas A&M University, College Station, </institution> <month> May </month> <year> 1994. </year> <note> Available via anonymous ftp from ftp.cs.tamu.edu in directory /pub/vaidya. </note>
Reference-contexts: The above guideline suggests that a recovery scheme should provide low-overhead protection against more probable failures, providing protection against other failures with, possibly, a higher overhead. We refer to recovery schemes having this capability as two-level recovery schemes. This approach can be generalized to multi-level recovery <ref> [30] </ref>. It was recently brought to our attention [2] that, for transaction-oriented systems, Gelenbe [8] previously proposed an approach similar to the multi-level recovery approach. Gelenbe's work is summarized in Section 11. <p> The two-level recovery approach can achieve lower overhead than one-level schemes by differentiating between the more probable failures and the less probable failures. Previously, we demonstrated that, it is often advantageous to use two-level recovery schemes as compared to traditional one-level recovery schemes <ref> [30, 32] </ref>. In this report we present design and analysis of a new two-level recovery scheme. Also, the report summarizes 2 the two-level recovery scheme analyzed in our previous work [30, 32]. <p> Previously, we demonstrated that, it is often advantageous to use two-level recovery schemes as compared to traditional one-level recovery schemes <ref> [30, 32] </ref>. In this report we present design and analysis of a new two-level recovery scheme. Also, the report summarizes 2 the two-level recovery scheme analyzed in our previous work [30, 32]. This report achieves three objectives: * The report carries out a detailed analysis of the proposed two-level recovery scheme and presents performance results. It demonstrates that two-level recovery can achieve a better performance than a one-level recovery scheme. <p> Impact of checkpoint latency is analyzed in Section 9. Section 10 discusses an experimental implementation of the proposed scheme. Related work is discussed in Section 11. The report concludes with Section 12. 3 2 Brief Description of a Two-Level Scheme <ref> [30, 32] </ref> This section summarizes a two-level recovery scheme that was proposed and analyzed previously [30, 32]. This two-level recovery scheme is useful in an environment consisting of disk-less workstations that can access a stable storage over the network. <p> Section 10 discusses an experimental implementation of the proposed scheme. Related work is discussed in Section 11. The report concludes with Section 12. 3 2 Brief Description of a Two-Level Scheme <ref> [30, 32] </ref> This section summarizes a two-level recovery scheme that was proposed and analyzed previously [30, 32]. This two-level recovery scheme is useful in an environment consisting of disk-less workstations that can access a stable storage over the network. In the environment under consideration, small number of failures are more probable than a large number of failures. <p> For this component scheme, the failure-free overhead per checkpoint interval is denoted by C N . Volatile storage access is cheaper than accessing the shared stable storage. Therefore, C 1 is expected to be smaller than C N . The two-level recovery scheme consists of the above two components <ref> [30, 32] </ref>. The two-level scheme takes 1-checkpoints more frequently and N -checkpoints less frequently. As the 1-checkpoints are taken more frequently, recovery overhead for a single processor failure is smaller. Also, overhead of taking 1-checkpoints is lower than that of N -checkpoints. As demonstrated in [30, 32], the two-level scheme can <p> of the above two components <ref> [30, 32] </ref>. The two-level scheme takes 1-checkpoints more frequently and N -checkpoints less frequently. As the 1-checkpoints are taken more frequently, recovery overhead for a single processor failure is smaller. Also, overhead of taking 1-checkpoints is lower than that of N -checkpoints. As demonstrated in [30, 32], the two-level scheme can achieve better performance as compared to either component recovery scheme. To further clarify the concept of two-level recovery, the tables below present an analogy of the two-level recovery scheme with cache memory organizations.
Reference: [31] <author> N. H. Vaidya, </author> <title> "Some thoughts on distributed recovery," </title> <type> Tech. Rep. 94-044, </type> <institution> Computer Science Department, Texas A&M University, College Station, </institution> <month> June </month> <year> 1994. </year> <note> Available via anonymous ftp from ftp.cs.tamu.edu in directory /pub/vaidya. </note>
Reference-contexts: Such a checkpoint is useful to recover from an arbitrary number of failures. 1 This limitation can be eliminated using the single processor failure tolerance scheme presented in <ref> [31] </ref> instead of a single process failure tolerance scheme, as described below. 2 A consistent checkpoint consists of one checkpoint per process such that a message sent after the check point of one process is not received by another process before taking its checkpoint [4, 11]. 4 Therefore, these checkpoints are
Reference: [32] <author> N. H. Vaidya, </author> <title> "A case for two-level distributed recovery schemes," </title> <booktitle> in SIGMET-RICS/Performance, </booktitle> <month> May </month> <year> 1995. </year>
Reference-contexts: The two-level recovery approach can achieve lower overhead than one-level schemes by differentiating between the more probable failures and the less probable failures. Previously, we demonstrated that, it is often advantageous to use two-level recovery schemes as compared to traditional one-level recovery schemes <ref> [30, 32] </ref>. In this report we present design and analysis of a new two-level recovery scheme. Also, the report summarizes 2 the two-level recovery scheme analyzed in our previous work [30, 32]. <p> Previously, we demonstrated that, it is often advantageous to use two-level recovery schemes as compared to traditional one-level recovery schemes <ref> [30, 32] </ref>. In this report we present design and analysis of a new two-level recovery scheme. Also, the report summarizes 2 the two-level recovery scheme analyzed in our previous work [30, 32]. This report achieves three objectives: * The report carries out a detailed analysis of the proposed two-level recovery scheme and presents performance results. It demonstrates that two-level recovery can achieve a better performance than a one-level recovery scheme. <p> Impact of checkpoint latency is analyzed in Section 9. Section 10 discusses an experimental implementation of the proposed scheme. Related work is discussed in Section 11. The report concludes with Section 12. 3 2 Brief Description of a Two-Level Scheme <ref> [30, 32] </ref> This section summarizes a two-level recovery scheme that was proposed and analyzed previously [30, 32]. This two-level recovery scheme is useful in an environment consisting of disk-less workstations that can access a stable storage over the network. <p> Section 10 discusses an experimental implementation of the proposed scheme. Related work is discussed in Section 11. The report concludes with Section 12. 3 2 Brief Description of a Two-Level Scheme <ref> [30, 32] </ref> This section summarizes a two-level recovery scheme that was proposed and analyzed previously [30, 32]. This two-level recovery scheme is useful in an environment consisting of disk-less workstations that can access a stable storage over the network. In the environment under consideration, small number of failures are more probable than a large number of failures. <p> For this component scheme, the failure-free overhead per checkpoint interval is denoted by C N . Volatile storage access is cheaper than accessing the shared stable storage. Therefore, C 1 is expected to be smaller than C N . The two-level recovery scheme consists of the above two components <ref> [30, 32] </ref>. The two-level scheme takes 1-checkpoints more frequently and N -checkpoints less frequently. As the 1-checkpoints are taken more frequently, recovery overhead for a single processor failure is smaller. Also, overhead of taking 1-checkpoints is lower than that of N -checkpoints. As demonstrated in [30, 32], the two-level scheme can <p> of the above two components <ref> [30, 32] </ref>. The two-level scheme takes 1-checkpoints more frequently and N -checkpoints less frequently. As the 1-checkpoints are taken more frequently, recovery overhead for a single processor failure is smaller. Also, overhead of taking 1-checkpoints is lower than that of N -checkpoints. As demonstrated in [30, 32], the two-level scheme can achieve better performance as compared to either component recovery scheme. To further clarify the concept of two-level recovery, the tables below present an analogy of the two-level recovery scheme with cache memory organizations.
Reference: [33] <author> K. Wong and M. Franklin, </author> <title> "Distributed computing systems and checkpointing," </title> <booktitle> in Proc. 2nd Int. Symp. High Perf. Distr. Comp., </booktitle> <address> Spokane, Washington, </address> <pages> pp. 224-233, </pages> <month> July </month> <year> 1993. </year>
Reference-contexts: Significant effort has been devoted in the past for analytically determining optimal checkpoint intervals for checkpointing and rollback recovery schemes <ref> [3, 7, 12, 25, 33, 34] </ref>. Due to the complexity of the expressions for the two-level recovery scheme under consideration, an analytical approach for determining optimal k and is not very attractive. Instead, we choose to determine the optimal values numerically.
Reference: [34] <author> J. W. Young, </author> <title> "A first order approximation to the optimum checkpoint interval," </title> <journal> Comm. ACM, </journal> <volume> vol. 17, </volume> <pages> pp. 530-531, </pages> <month> September </month> <year> 1974. </year>
Reference-contexts: Significant effort has been devoted in the past for analytically determining optimal checkpoint intervals for checkpointing and rollback recovery schemes <ref> [3, 7, 12, 25, 33, 34] </ref>. Due to the complexity of the expressions for the two-level recovery scheme under consideration, an analytical approach for determining optimal k and is not very attractive. Instead, we choose to determine the optimal values numerically.
Reference: [35] <author> A. Ziv and J. Bruck, </author> <title> "Analysis of checkpointing schemes for multiprocessor systems," </title> <type> Tech. Rep. RJ 9593, </type> <institution> IBM Almaden Research Center, </institution> <month> November </month> <year> 1993. </year>
Reference-contexts: Markov chains have been used for evaluating expected execution time by Ziv and Bruck also <ref> [35] </ref>. The procedure for constructing the Markov chain is presented later, we first present some preliminaries. The Markov chain has an unique start state and an unique absorbing state. For a given k, the Markov chain contains 2k + 1 states.
Reference: [36] <author> A. Ziv and J. Bruck, </author> <title> "Efficient checkpointing over local area network," </title> <booktitle> in IEEE Workshop on Fault-Tolerant Parallel and Distributed Systems, </booktitle> <address> College Station, </address> <month> June </month> <year> 1994. </year> <month> 45 </month>
Reference-contexts: This report analyzes an approach to reduce the average performance overhead. The design principle "make the common case fast" has been successfully used in designing many components of a computer system (e.g., cache memory, RISC [18]) and some aspects of checkpointing and rollback <ref> [21, 36] </ref>. However, the designers of distributed rollback recovery schemes have largely ignored this guideline. In any system, some failure scenarios have a greater probability of occurring as compared to other failure scenarios. In the context of failure recovery, the "common case" consists of the more probable failure scenarios. <p> access type served by latency address in cache cache small address not in cache main mem. large average access latency = small Two-level recovery scheme failure scenario failure tolerated by overhead single failure 1st component scheme small other 2nd component scheme large average performance overhead = small Ziv and Bruck <ref> [36] </ref> present a checkpointing and rollback scheme for duplex systems, that also takes two types of checkpoints, similar to the above two-level scheme. Section 11 discusses their scheme. The rest of this report presents another two-level recovery scheme and its performance evaluation. <p> Ziv and Bruck <ref> [36] </ref> present a checkpointing and rollback scheme for duplex systems. Although it does not satisfy the above definition of two-level schemes, their scheme also takes two types of checkpoints (similar to the schemes we have proposed). <p> If a failure is detected, then the previous k checkpoints are compared (sequentially) until 40 an error-free checkpoint is found. The duplex system then rolls back to this checkpoint. By restricting checkpoint comparison (during failure-free operation) to every k-th checkpoint, <ref> [36] </ref> reduces overhead of the recovery scheme, as compared to a scheme that compares the states at each checkpoint. Our approach differs from [36] in that we attempt to minimize the average overhead by distinguishing between more probable and less probable failures. [36] improves the overhead (for duplex systems) by decoupling <p> The duplex system then rolls back to this checkpoint. By restricting checkpoint comparison (during failure-free operation) to every k-th checkpoint, <ref> [36] </ref> reduces overhead of the recovery scheme, as compared to a scheme that compares the states at each checkpoint. Our approach differs from [36] in that we attempt to minimize the average overhead by distinguishing between more probable and less probable failures. [36] improves the overhead (for duplex systems) by decoupling checkpoint saving and checkpoint comparison. The two approaches are similar, however, in that they both take two types of checkpoints. <p> comparison (during failure-free operation) to every k-th checkpoint, <ref> [36] </ref> reduces overhead of the recovery scheme, as compared to a scheme that compares the states at each checkpoint. Our approach differs from [36] in that we attempt to minimize the average overhead by distinguishing between more probable and less probable failures. [36] improves the overhead (for duplex systems) by decoupling checkpoint saving and checkpoint comparison. The two approaches are similar, however, in that they both take two types of checkpoints.
References-found: 36

