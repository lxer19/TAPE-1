URL: http://www.mli.gmu.edu/papers/maloof.aaai95.ps
Refering-URL: http://www.mli.gmu.edu/kpubs.html
Root-URL: 
Email: maloof, michalski-@aic.gmu.edu  
Title: Learning Evolving Concepts Using Partial-Memory Approach  Machine Learning and Inference Laboratory  
Author: Marcus A. Maloof and Ryszard S. Michalski* George Mason 
Address: Fairfax, VA 22030  
Affiliation: University  Institute of Computer Science, Polish Academy of Sciences  
Date: November 10-12, 1995  
Note: Working Notes of the 1995 AAAI Fall Symposium on Active Learning, 7073 Boston, MA,  *Also with the  
Abstract: This paper addresses the problem of learning evolving concepts, that is, concepts whose meaning gradually evolves in time. Solving this problem is important to many applications, for example, building intelligent agents for helping users in Internet search, active vision, automatically updating knowledge-bases, or acquiring profiles of users of telecommunication networks. Requirements for a learning architecture supporting such applications include the ability to incrementally modify concept definitions to accommodate new information, fast learning and recognition rates, low memory needs, and the understandability of computer-created concept descriptions. To address these requirements, we propose a learning architecture based on Variable-Valued Logic, the Star Methodology, and the AQ algorithm. The method uses a partial-memory approach, which means that in each step of learning, the system remembers the current concept descriptions and specially selected representative examples from the past experience. The developed method has been experimentally applied to the problem of computer system intrusion detection. The results show significant advantages of the method in learning speed and memory requirements with only slight decreases in predictive accuracy and concept simplicity when compared to traditional batch-style learning in which all training examples are provided at once. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Aha, D. W.; Kibler, D.; and, Albert, M. K. </author> <year> 1991. </year> <note> Instance-based learning algorithms. Mac hine Learning 6: 3766. </note>
Reference: <author> Hong, J.; Mozetic, I.; and Michalski, R. S. </author> <year> 1986. </year> <title> AQ15: Incremental Learning of Attribute-Based Descriptions from Examples, the Method and Users Guide. </title> <type> Technical Report UIUCDCS-F-86-949. </type> <institution> Department of Computer Science, University of Illinois at Urbana-Champaign. </institution>
Reference-contexts: With an evolutionary scheme, existing knowledge is modified based on new training examples. STAGGER (Schlimmer 1987) is an incremental learning systems that takes an evolutionary approach. With a revolutionary approach, old knowledge is discarded and new knowledge is learned from the given training examples. AQ15 <ref> (Hong et al. 1986) </ref> is an example of an incremental learning system that takes a revolutionary approach. Finally, a hybrid approach takes elements from both the revolutionary and evolutionary approaches.
Reference: <author> Maloof, M. A., and Michalski, R. S. </author> <year> 1995. </year> <title> A Partial-Memory Incremental Learning Methodology and Its Application to Intrusion Detection. </title> <booktitle> Proceedings of the 7th IEEE International Conference on Tools with Artificial Intelligence. November 58, </booktitle> <address> Washington, </address> <publisher> DC (forthcoming). </publisher>
Reference-contexts: Results demonstrate that partial-memory incremental learning yielded significant improvements in learning time and memory requirements at the cost of slightly lower predictive accuracy and slightly more complex concept descriptions when compared to traditional batch learning in which all examples are provided at once <ref> (Maloof & Michalski 1995) </ref>. Background In conventional learning methods, concepts are assumed to be constant, that is, their inherent meaning does not change. The goal of the learner is to capture this meaning by observing concept examples, which can be given at once (batch learning) and incrementally.
Reference: <author> Michalski, R. S. </author> <year> 1969. </year> <title> On the Quasi-Minimal Solution of the General Covering Problem. </title> <booktitle> Fifth International Symposium on Information Processing, A3: </booktitle> <pages> 125128. </pages>
Reference-contexts: To address these requirements, we have developed a novel incremental learning methodology based on Variable-Valued Logic (Michalski 1973), the Star Methodology (Michalski 1983), and the AQ algorithm <ref> (Michalski 1969) </ref>. The method operates in a partial-memory mode (Reinke & Michalski 1988) in which the system maintains a set of representative examples derived from past experience. A training example is considered representative if it expands or constrains concepts in the event space.
Reference: <author> Michalski, R. S. </author> <year> 1973. </year> <title> AQVAL/1 Computer Implementation of a Variable-Valued Logic System VL 1 and Examples of Its Application to Pattern Recognition. </title> <booktitle> First International Joint Conference on Pattern Recognition, </booktitle> <pages> 317. </pages>
Reference-contexts: It is also important that the system is able to learn and recognize concepts quickly and employs easy to understand symbolic concept descriptions. To address these requirements, we have developed a novel incremental learning methodology based on Variable-Valued Logic <ref> (Michalski 1973) </ref>, the Star Methodology (Michalski 1983), and the AQ algorithm (Michalski 1969). The method operates in a partial-memory mode (Reinke & Michalski 1988) in which the system maintains a set of representative examples derived from past experience.
Reference: <author> Michalski, R. S. </author> <year> 1983. </year> <title> A Theory and Methodology of Inductive Learning. </title> <editor> In Michalski, R. S.; Carbonell, J. G.; and Mitchell, T. M., eds., </editor> <booktitle> Machine Learning: An Artificial Intelligence Approach, </booktitle> <volume> Vol. 1, </volume> <pages> 83134. </pages> <address> Palo Alto, CA: </address> <publisher> Tioga Publishing Michalski, </publisher> <editor> R. S. </editor> <year> 1985. </year> <title> Knowledge Repair Mechanisms: Evolution vs. Revolution. </title> <booktitle> In Proceedings of the Third International Machine Learning Workshop, </booktitle> <pages> 116119. </pages>
Reference-contexts: It is also important that the system is able to learn and recognize concepts quickly and employs easy to understand symbolic concept descriptions. To address these requirements, we have developed a novel incremental learning methodology based on Variable-Valued Logic (Michalski 1973), the Star Methodology <ref> (Michalski 1983) </ref>, and the AQ algorithm (Michalski 1969). The method operates in a partial-memory mode (Reinke & Michalski 1988) in which the system maintains a set of representative examples derived from past experience. A training example is considered representative if it expands or constrains concepts in the event space.
Reference: <author> Mitchell, T.; Caruana, R.; Freitag, D.; McDermott, J.; and Zabowski, D. </author> <year> 1994. </year> <title> Experience with a Learning Personal Assistant. </title> <journal> Communications of the ACM 37(7): </journal> <volume> 8191. </volume>
Reference-contexts: AQ15 (Hong et al. 1986) is an example of an incremental learning system that takes a revolutionary approach. Finally, a hybrid approach takes elements from both the revolutionary and evolutionary approaches. CAP <ref> (Mitchell et al. 1994) </ref>, for example, learns new decision rules from training data and incorporates these new rules into the existing knowledge-base.
Reference: <author> Reinke, R. E., and Michalski, R. S. </author> <year> 1988. </year> <title> Incremental Learning of Concept Descriptions: A Method and Experimental Results. </title> <editor> In Hayes, J. E.; Michie, D.; and Richards, J., eds., </editor> <booktitle> Machine Intelligence 11, </booktitle> <volume> 263288. </volume> <publisher> Oxford: Clarendon Press. </publisher>
Reference-contexts: To address these requirements, we have developed a novel incremental learning methodology based on Variable-Valued Logic (Michalski 1973), the Star Methodology (Michalski 1983), and the AQ algorithm (Michalski 1969). The method operates in a partial-memory mode <ref> (Reinke & Michalski 1988) </ref> in which the system maintains a set of representative examples derived from past experience. A training example is considered representative if it expands or constrains concepts in the event space. <p> The work presented here uses a partial-memory mode. Aha and Kibler (1992) also use a partial-memory mode, but for instance-based learning which does not form generalized concept descriptions. Finally, under a full-memory mode, all past training examples are maintained and used in the process of modifying existing hypothesis. AQ15 <ref> (Reinke & Michalski 1988, Hong et al. 1986) </ref> operates using a full-memory mode. Learning evolving concepts adds another layer of difficulty to the process of incremental learning. Concepts can no longer be assumed to be constant.
Reference: <author> Schlimmer, J. C. </author> <title> (1987) Incremental Adjustment of Representations for Learning. </title> <booktitle> In Proceedings of the Fourth International Workshop on Machine Learning, </booktitle> <pages> 7990. </pages>
Reference-contexts: Incremental learning is inherently a temporal process. Incremental learning can be conducted using either an evolutionary or revolutionary scheme (Michalski 1985). With an evolutionary scheme, existing knowledge is modified based on new training examples. STAGGER <ref> (Schlimmer 1987) </ref> is an incremental learning systems that takes an evolutionary approach. With a revolutionary approach, old knowledge is discarded and new knowledge is learned from the given training examples. AQ15 (Hong et al. 1986) is an example of an incremental learning system that takes a revolutionary approach. <p> Incremental learning systems can work in one of three different modes: no-memory, partial-memory, or full-memory. In the no-memory mode, the system does not use any past training examples for modifying or updating the currently held hypotheses. STAGGER <ref> (Schlimmer 1987) </ref> uses a no-memory mode. In a partial-memory mode, a subset of all previously seen training examples is maintained and used for subsequent learning. The work presented here uses a partial-memory mode.
References-found: 9

