URL: http://vibes.cs.uiuc.edu/Publications/Papers/PACT98.ps.gz
Refering-URL: http://vibes.cs.uiuc.edu/Publications/publications.htm
Root-URL: http://www.cs.uiuc.edu
Phone: Telephone:  
Title: creating new collective works for resale or redistribution  
Address: 445 Hoes Lane P.O. Box 1331 Piscataway, NJ 08855-1331, USA.  
Affiliation: Service Center  
Note: Copyright 1998 IEEE. Published in the Proceedings of PACT'98, 12-18 October 1998 in Paris, France. Personal use of this material is permitted. However, permission to reprint/republish this material for advertising or promotional purposes or for  to servers or lists, or to reuse any copyrighted component of this work in other works, must be obtained from the IEEE. Contact: Manager, Copyrights and Permissions IEEE  Intl. 732-562-3966.  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> V. Adve, A. Carle, E. Granston, S. Hiranandani, K. Kennedy, C. Koelbel, J. Mellor-Crummey, and S. Warren. </author> <title> Requirements for data parallel programming environments. </title> <booktitle> IEEE Parallel & Distributed Technology, </booktitle> <address> 2(3):4858, </address> <month> Fall </month> <year> 1994. </year>
Reference-contexts: However, that effort has not yet reached an ideal stage. Some methods derive a prediction for a specific combination of number of processors (P ) and problem size (N ), like in <ref> [1] </ref>, [5] and [10]. Others provide a symbolic model that can be evaluated at desired combinations of N and P , but either have a very limited application domain, as in [11], or require several executions of the program for model calibration, as in [3].
Reference: [2] <author> V. S. Adve, J. Mellor-Crummey, M. Anderson, K. Kennedy, J.-C. Wang, and D. A. Reed. </author> <title> An integrated compilation and performance analysis environment for data parallel programs. </title> <booktitle> In Proceedings of Supercomputing'95, </booktitle> <address> San Diego, </address> <month> December </month> <year> 1995. </year>
Reference-contexts: We construct the prediction model for the complete application by concatenating the models from its constituent fragments. As an example, we analyze the performance of the Erlebacher program, an 800 line, ten procedure benchmark 3 written by Thomas Eidson, at ICASE <ref> [2, 4] </ref>. Erlebacher solves 3-D partial differential equations via tridiagonal solves using Alternating-Direction-Implicit (ADI) integration. The program operates in succession on each of the three dimensions (X, Y and Z). In each dimension, derivatives are computed, followed by forward and backward substitution steps.
Reference: [3] <author> M. J. Clement and M. J. Quinn. </author> <title> Symbolic performance prediction of scalable parallel programs. </title> <booktitle> In Proceedings of the 9 th International Parallel Processing Symposium, </booktitle> <month> April </month> <year> 1995. </year>
Reference-contexts: Others provide a symbolic model that can be evaluated at desired combinations of N and P , but either have a very limited application domain, as in [11], or require several executions of the program for model calibration, as in <ref> [3] </ref>. There has been no proposed method, so far, that provides a first-order, easily derivable model of the application's execution time (and of the execution times for internal code sections) as a function of the number of processors and problem size. Our symbolic scalability prediction method targets precisely this area.
Reference: [4] <author> T. M. Eidson and G. Erlebacher. </author> <title> Implementation of a fully-balanced periodic tridiagonal solver on a parallel distributed memory architecture. </title> <type> Technical Report TR-94-37, </type> <institution> ICASE, </institution> <year> 1994. </year>
Reference-contexts: We construct the prediction model for the complete application by concatenating the models from its constituent fragments. As an example, we analyze the performance of the Erlebacher program, an 800 line, ten procedure benchmark 3 written by Thomas Eidson, at ICASE <ref> [2, 4] </ref>. Erlebacher solves 3-D partial differential equations via tridiagonal solves using Alternating-Direction-Implicit (ADI) integration. The program operates in succession on each of the three dimensions (X, Y and Z). In each dimension, derivatives are computed, followed by forward and backward substitution steps.
Reference: [5] <author> T. Fahringer. </author> <title> Automatic Performance Prediction of Parallel Programs. </title> <publisher> Kluwer Academic Publishers, Norwell, </publisher> <address> Mas-sachusetts, </address> <year> 1996. </year>
Reference-contexts: However, that effort has not yet reached an ideal stage. Some methods derive a prediction for a specific combination of number of processors (P ) and problem size (N ), like in [1], <ref> [5] </ref> and [10]. Others provide a symbolic model that can be evaluated at desired combinations of N and P , but either have a very limited application domain, as in [11], or require several executions of the program for model calibration, as in [3].
Reference: [6] <author> D. Levine, D. Callahan, and J. Dongarra. </author> <title> Test Suite for Vec-torizing Compilers. </title> <year> 1991. </year>
Reference-contexts: Collection of Loops We consider the collection of loops prepared by Levine et al <ref> [6] </ref>. That collection consists of a variety of loop nests that represent different constructs intended to test the analysis capabilities of a vectorizing compiler. It comprises distinct types of computations that occur frequently on scientific applications.
Reference: [7] <author> D. B. Loveman. </author> <title> High Performance Fortran. </title> <booktitle> IEEE Parallel & Distributed Technology, </booktitle> <address> 1(1):2542, </address> <month> February </month> <year> 1993. </year>
Reference-contexts: 1. Introduction Performance variability and the effort required to write explicitly parallel code have long limited the widespread use of parallel systems. Data parallel languages, like High Performance Fortran (HPF) <ref> [7] </ref>, have been proposed to lessen the parallel programming burden.
Reference: [8] <author> C. L. Mendes. </author> <title> Performance Scalability Prediction on Mul-ticomputers. </title> <type> PhD thesis, </type> <institution> University of Illinois at Urbana-Champaign, </institution> <month> May </month> <year> 1997. </year>
Reference-contexts: Figure 3 shows some of our prediction results, in comparison to the observed execution times on the Intel Paragon. The results for other loop nests, with a more complete analysis of the prediction results, can be found in <ref> [8] </ref>. Those results show that, in general, our predictions correctly estimate the limits bounding the observed execution times for nearly all cases. <p> Our results indicate that loop nests 20 and 70 are expected to dominate the execution, across all the examined range of values for P and N . Execution of Erlebacher on the Intel Paragon confirmed these predictions (for details, see <ref> [8] </ref>). Loop nests 20 and 70 constitute the bottlenecks in the Erlebacher code. Their poor scalability comes from the fact that the employed version of the Fortran D95 compiler generated messages inside each iteration of the innermost loops, to communicate values required by the dependences carried by those loops.
Reference: [9] <author> J. Panetta, E. Voigt, and C. L. Mendes. </author> <title> A portable compiler for High Performance Fortran. </title> <booktitle> In Proceedings of the 9 th Brazilian Symposium on Computer Architecture and High Performance Processing, </booktitle> <pages> pages 601604, </pages> <address> Campos do Jordao, </address> <month> October </month> <year> 1997. </year>
Reference-contexts: Our current efforts are focused in two main directions. First, we are incorporating these techniques to another HPF compiler that has a different code generation model, strongly based on user inserted annotations (in the form of directives, including OpenMP constructs), and targets both distributed and shared memory systems <ref> [9] </ref>. Our second and most ambitious effort is to integrate this methodology to an existing graphical tool for instrumenting application source code and browsing performance data.
Reference: [10] <author> M. Parashar, S. Hariri, T. Haupt, and G. C. Fox. </author> <title> Interpreting the performance of HPF/Fortran 90D. </title> <booktitle> In Proceedings of Supercomputing'94, </booktitle> <pages> pages 743752, </pages> <address> Washington, </address> <month> November </month> <year> 1994. </year>
Reference-contexts: However, that effort has not yet reached an ideal stage. Some methods derive a prediction for a specific combination of number of processors (P ) and problem size (N ), like in [1], [5] and <ref> [10] </ref>. Others provide a symbolic model that can be evaluated at desired combinations of N and P , but either have a very limited application domain, as in [11], or require several executions of the program for model calibration, as in [3].
Reference: [11] <author> A. J. C. van Gemund. </author> <title> Compile-time performance prediction of parallel systems. </title> <booktitle> In Proceedings of the 8 th International Conference on Modeling Techniques and Tools for Computer Performance Evaluation, </booktitle> <pages> pages 299313, </pages> <address> Heidel-berg, </address> <month> September </month> <year> 1995. </year>
Reference-contexts: Others provide a symbolic model that can be evaluated at desired combinations of N and P , but either have a very limited application domain, as in <ref> [11] </ref>, or require several executions of the program for model calibration, as in [3].
References-found: 11

