URL: ftp://softlib.rice.edu/pub/CRPC-TRs/reports/CRPC-TR94484-S.ps.gz
Refering-URL: http://www.crpc.rice.edu/CRPC/softlib/TRs_online.html
Root-URL: 
Title: Combining Dependence and Data-Flow Analyses to Optimize Communication  
Author: Ken Kennedy Nenad Nedeljkovic 
Address: P.O. Box 1892 Houston, TX 77251-1892  
Affiliation: Rice University  
Note: Center for Research on Parallel Computation  
Date: September, 1994  
Pubnum: CRPC-TR94484-S  
Abstract: A modified version of this paper will appear in the Proceedings of the 9th International Parallel Process ing Symposium, IPPS '95. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> V. Adve, C. Koelbel, and J. Mellor-Crummey. </author> <title> Performance analysis of data-parallel programs. </title> <type> Technical Report CRPC-TR94405, </type> <institution> Center for Research on Parallel Computation, Rice University, </institution> <month> May </month> <year> 1994. </year>
Reference-contexts: of the difference coming from eliminating redundant messages and increasing the overlap of communication with computation | exactly the optimizations that we propose to automate. (Although hand-coded versions of some benchmarks described in [20] were up to 50% faster (Dgefa and Er-lebacher), these improvements were due to aggressive program transformations <ref> [1] </ref>, which are beyond the scope of this paper.) After translating original Fortran D programs into SPMD-style Fortran code, the resulting programs were hand-instrumented to reflect the optimizations that would be performed using our combined analysis.
Reference: [2] <author> S. Amarasinghe and M. Lam. </author> <title> Communication optimization and code generation for distributed memory machines. </title> <booktitle> In Proceedings of the SIGPLAN '93 Conference on Programming Language Design and Implementation, </booktitle> <address> Albuquerque, NM, </address> <month> June </month> <year> 1993. </year>
Reference-contexts: Using global flow analysis of array regions they are able to eliminate these redundancies, but since their global read and write are monolithic operations, they do not try to overlap communication with computation. Communication optimization described by Amarasinghe and Lam in <ref> [2] </ref> is based on the last write tree representation.
Reference: [3] <author> V. Balasundaram, G. Fox, K. Kennedy, and U. Kremer. </author> <title> An interactive environment for data partitioning and distribution. </title> <booktitle> In Proceedings of the 5th Distributed Memory Computing Conference, </booktitle> <address> Charleston, SC, </address> <month> April </month> <year> 1990. </year>
Reference-contexts: The most important optimization for these references is message vectorization. It uses the level of loop-carried true dependences to decide if the communication can be hoisted out of the loop, in which case many small messages are replaced with one large message. This algorithm was first described in <ref> [3] </ref> and [6], and its implementation in the Fortran D compiler is detailed in [20]. In order to avoid communicating redundant data, the compiler applies message coalescing, which combines messages for different references to the same array.
Reference: [4] <author> H. Berryman and J. Saltz. </author> <title> A manual for PARTI runtime primitives. </title> <type> ICASE Interim Report 13, </type> <institution> Institute for Computer Application in Science and Engineering, Hampton, VA, </institution> <month> September </month> <year> 1990. </year>
Reference-contexts: For example, in the Read problem TAKE init set for each node includes all the array portions referenced at that point in the program [12]. For irregular problems, determining which of these references require communication is done at run time through calls to Parti/Chaos library routines (Gather) <ref> [4] </ref>. However, in regular codes, it is often possible for the compiler to extract much more static information and determine at compile time which references are non-local.
Reference: [5] <author> B. Chapman, P. Mehrotra, and H. Zima. </author> <title> Vienna Fortran | A Fortran language extension for distributed memory multiprocessors. </title> <editor> In J. Saltz and P. Mehrotra, editors, </editor> <title> Languages, Compilers, and Run-Time Environments for Distributed Memory Machines. </title> <publisher> North-Holland, </publisher> <address> Amsterdam, The Netherlands, </address> <year> 1992. </year>
Reference-contexts: In recent years significant efforts have been made to develop programming languages that provide shared address space in order to free the programmer from the burden of manipulating messages directly. Data-parallel languages, such as Fortran D [17], Vienna Fortran <ref> [5] </ref>, and High Performance Fortran (HPF) [19], provide directives for the programmer to specify how data should be distributed among processors.
Reference: [6] <author> M. Gerndt. </author> <title> Updating distributed variables in local computations. </title> <journal> Concurrency: Practice and Experience, </journal> <volume> 2(3) </volume> <pages> 171-193, </pages> <month> September </month> <year> 1990. </year>
Reference-contexts: It uses the level of loop-carried true dependences to decide if the communication can be hoisted out of the loop, in which case many small messages are replaced with one large message. This algorithm was first described in [3] and <ref> [6] </ref>, and its implementation in the Fortran D compiler is detailed in [20]. In order to avoid communicating redundant data, the compiler applies message coalescing, which combines messages for different references to the same array.
Reference: [7] <author> C. Gong, R. Gupta, and R. Melhem. </author> <title> Compilation techniques for optimizing communication on distributed-memory systems. </title> <booktitle> In Proceedings of the 1993 International Conference on Parallel Processing, </booktitle> <address> St. Charles, IL, </address> <month> August </month> <year> 1993. </year>
Reference-contexts: The combined approach allows us to perform more extensive optimizations than either of the two components would do on its own. There have been several attempts to use data-flow analysis in order to optimize communication <ref> [8, 7, 11] </ref>. Most of these efforts have focused on extending the existing data-flow analysis methods to work with some form of array section descriptors. In contrast, our data-flow analysis uses bit vectors (with each bit representing an array portion) and is thus likely to be more efficient. <p> Using this information we could split the array portion communicated into parts corresponding to array portions in reaching communications. (This is similar to splitting in <ref> [7] </ref>, but we only perform splitting when initializing the data-flow framework.) Since we are only interested in control-flow reachability without taking array kill information into account, this approach does not require array data-flow analysis. <p> Gong et al. describe a data-flow analysis algorithm that propagates array portions in order to determine communication placement <ref> [7] </ref>. They combine multiple communication optimizations, but their technique has several restrictions: they handle only singly nested loops and one-dimensional arrays, and their propagation algorithm is based on the structured control flow. <p> However, they do not present any experimental data that would indicate whether the cost of their analysis would be justified in practice by the need for extra precision. Much like in <ref> [7] </ref>, their Sends are performed "as early as legally possible", but Recvs (or rather Waits for non-blocking Recvs) are inserted "at the reference to non-local data", causing the same problem as discussed above. 6 Conclusions We have presented a method for optimizing communication when compiling HPF-like languages.
Reference: [8] <author> E. Granston and A. Veidenbaum. </author> <title> Detecting redundant accesses to array data. </title> <booktitle> In Proceedings of Supercomputing '91, </booktitle> <address> Albuquerque, NM, </address> <month> November </month> <year> 1991. </year>
Reference-contexts: The combined approach allows us to perform more extensive optimizations than either of the two components would do on its own. There have been several attempts to use data-flow analysis in order to optimize communication <ref> [8, 7, 11] </ref>. Most of these efforts have focused on extending the existing data-flow analysis methods to work with some form of array section descriptors. In contrast, our data-flow analysis uses bit vectors (with each bit representing an array portion) and is thus likely to be more efficient. <p> Granston and Veidenbaum apply combined flow and dependence analysis to detect redundant global memory accesses in parallel programs <ref> [8] </ref>. Using global flow analysis of array regions they are able to eliminate these redundancies, but since their global read and write are monolithic operations, they do not try to overlap communication with computation.
Reference: [9] <author> T. Gross and P. Steenkiste. </author> <title> Structured dataflow analysis for arrays and its use in an optimizing compiler. </title> <journal> Software| Practice and Experience, </journal> <volume> 20(2) </volume> <pages> 133-155, </pages> <month> February </month> <year> 1990. </year>
Reference-contexts: If we are willing to pay the full price of array data-flow analysis, such as that described in <ref> [9] </ref>, better precision could be achieved by using reaching array section definitions as the basis for splitting.
Reference: [10] <author> M. Gupta and E. Schonberg. </author> <title> A framework for exploiting data availability to optimize communication. </title> <booktitle> In Proceedings of the Sixth Workshop on Languages and Compilers for Parallel Computing, </booktitle> <address> Portland, OR, </address> <month> August </month> <year> 1993. </year>
Reference-contexts: In the most recent work on optimizing communication, Gupta et al. show how partial redundancy elimination can be applied to available section descriptors [11]. The available section descriptor extends an array section descriptor with the mapping of the array section 14 onto the virtual processor grid <ref> [10] </ref>. Since we opt for the efficiency of bit-vector based flow analysis, and analyze array sections only in the initialization phase, it is possible that their method will be more precise.
Reference: [11] <author> M. Gupta, E. Schonberg, and H. Srinivasan. </author> <title> A unified data-flow framework for optimizing communication. </title> <booktitle> In Proceedings of the Seventh Workshop on Languages and Compilers for Parallel Computing, </booktitle> <address> Ithaca, NY, </address> <month> August </month> <year> 1994. </year>
Reference-contexts: The combined approach allows us to perform more extensive optimizations than either of the two components would do on its own. There have been several attempts to use data-flow analysis in order to optimize communication <ref> [8, 7, 11] </ref>. Most of these efforts have focused on extending the existing data-flow analysis methods to work with some form of array section descriptors. In contrast, our data-flow analysis uses bit vectors (with each bit representing an array portion) and is thus likely to be more efficient. <p> In contrast, our approach provides placement points for both Sends and Recvs, which are provably balanced [13]. In the most recent work on optimizing communication, Gupta et al. show how partial redundancy elimination can be applied to available section descriptors <ref> [11] </ref>. The available section descriptor extends an array section descriptor with the mapping of the array section 14 onto the virtual processor grid [10].
Reference: [12] <author> R. v. Hanxleden. </author> <title> Handling irregular problems with Fortran D | A preliminary report. </title> <booktitle> In Proceedings of the Fourth Workshop on Compilers for Parallel Computers, </booktitle> <address> Delft, The Netherlands, </address> <month> December </month> <year> 1993. </year>
Reference-contexts: For example, in the Read problem TAKE init set for each node includes all the array portions referenced at that point in the program <ref> [12] </ref>. For irregular problems, determining which of these references require communication is done at run time through calls to Parti/Chaos library routines (Gather) [4]. However, in regular codes, it is often possible for the compiler to extract much more static information and determine at compile time which references are non-local. <p> For example, all Comm sets shown in Figure 1, would go into TAKE init sets for their corresponding locations in the program. In contrast to the original analysis of irregular problems <ref> [12] </ref>, where TAKE init sets contain all referenced portions of distributed arrays, our consumption sets will be smaller whenever the elements to be communicated can be determined at compile time. More precise consumption sets will often open ground for more optimization opportunities, as shown by the example in Figure 2. <p> data-flow analysis. 1 Note the difference between partially redundant communication, which is redundant on some control-flow paths, and partly redundant communication, for which only some of the participating messages are redundant. 11 4 Preliminary Experience The implementation of the Give-N-Take framework that provides bit-vector based analysis has been described in <ref> [12] </ref>. We have modified the existing framework to include the support for handling array portions that can be represented with RSDs. Although the framework can now take some advantage of compile-time knowledge about array elements accessed, full propagation of dependence-based communication analysis has not yet been implemented.
Reference: [13] <author> R. v. Hanxleden and K. Kennedy. </author> <title> A code placement framework and its application to communication generation. </title> <type> Technical Report CRPC-TR93337-S, </type> <institution> Center for Research on Parallel Computation, Rice University, </institution> <month> October </month> <year> 1993. </year>
Reference-contexts: If communication is hoisted out of the loop or if a message is split, as suggested, into several Send statements, simply inserting a Recv just before the data are needed is not satisfactory. In contrast, our approach provides placement points for both Sends and Recvs, which are provably balanced <ref> [13] </ref>. In the most recent work on optimizing communication, Gupta et al. show how partial redundancy elimination can be applied to available section descriptors [11]. The available section descriptor extends an array section descriptor with the mapping of the array section 14 onto the virtual processor grid [10].
Reference: [14] <author> R. v. Hanxleden and K. Kennedy. </author> <title> Give-N-Take | A balanced code placement framework. </title> <booktitle> In Proceedings of the SIGPLAN '94 Conference on Programming Language Design and Implementation, </booktitle> <address> Orlando, FL, </address> <month> June </month> <year> 1994. </year>
Reference-contexts: On the other hand, communication caused by irregular array references (those where subscripts are not linear combinations of loop induction variables, but for example array lookups) is optimized via the powerful Give-N-Take code placement framework <ref> [14] </ref>. Although this framework provides global analysis on the control flow graph, its current limitation is the treatment of arrays as indivisible units. Because of this, it does not take advantage of certain optimization opportunities that come from the compile-time knowledge about array references. <p> In these cases it is hardly possible to extract any significant compile-time knowledge about array sections accessed, and therefore dependence analysis is of little use. Instead, the Fortran D compiler prototype uses the analysis provided by the Give-N-Take code placement framework <ref> [14] </ref>. This very general framework uses a producer-consumer concept where references to potentially non-local data are viewed as consumption, and the communication that fetches the data represents the production whose placement needs to be determined. <p> The algorithm for data-flow analysis then propagates this information globally, by evaluating the complex equations described in <ref> [14] </ref>. The result of the analysis is given by output variables that indicate where the production of data should be placed. If we are only trying to satisfy references to non-local data, the production will be in the form of global Read (Gather) statements. <p> Once the input variables are initialized, we proceed with the Give-N-Take analysis as described in <ref> [14] </ref>. All lattice operations needed to evaluate data-flow equations are performed on bit vectors. It would be possible to modify the framework so that it performs lattice operations on array portions themselves, instead of using just bits that represent those array portions.
Reference: [15] <author> P. Havlak and K. Kennedy. </author> <title> An implementation of interprocedural bounded regular section analysis. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 2(3) </volume> <pages> 350-360, </pages> <month> July </month> <year> 1991. </year>
Reference-contexts: created using indices local to each processor, at this point we still represent communication sets in terms of global indices from the original Fortran D program. 6 The current Fortran D compiler prototype uses regular section descriptors (RSDs) to represent the sets of array elements that need to be communicated <ref> [15] </ref>. These RSDs are augmented to handle simple forms of boundary conditions [20]. While this representation is sufficient for one-dimensional BLOCK and CYCLIC distributions currently supported by the compiler, a more general representation is necessary for communication sets that arise with BLOCK CYCLIC and multi-dimensional distributions.
Reference: [16] <author> S. Hiranandani, K. Kennedy, and C.-W. Tseng. </author> <title> Compiler optimizations for Fortran D on MIMD distributed-memory machines. </title> <booktitle> In Proceedings of Supercomputing '91, </booktitle> <address> Albuquerque, NM, </address> <month> November </month> <year> 1991. </year>
Reference-contexts: Therefore, it is extremely important to reduce the amount of communication inserted by the compiler. In the Fortran D compiler prototype developed at Rice University, communication resulting from regular array references (those references where subscripts are linear combinations of loop induction variables) is optimized based primarily on dependence analysis <ref> [16] </ref>. The most important optimizations performed are message vectorization (which hoists communication out of loops thus combining multiple single-element messages into a single vectorized message) and message coalescing (which combines messages resulting from different references to the same array) [18].
Reference: [17] <author> S. Hiranandani, K. Kennedy, and C.-W. Tseng. </author> <title> Compiling Fortran D for MIMD distributed-memory machines. </title> <journal> Communications of the ACM, </journal> <volume> 35(8) </volume> <pages> 66-80, </pages> <month> August </month> <year> 1992. </year>
Reference-contexts: Managing this communication explicitly is a very tedious and error-prone process. In recent years significant efforts have been made to develop programming languages that provide shared address space in order to free the programmer from the burden of manipulating messages directly. Data-parallel languages, such as Fortran D <ref> [17] </ref>, Vienna Fortran [5], and High Performance Fortran (HPF) [19], provide directives for the programmer to specify how data should be distributed among processors.
Reference: [18] <author> S. Hiranandani, K. Kennedy, and C.-W. Tseng. </author> <title> Evaluation of compiler optimizations for Fortran D on MIMD distributed-memory machines. </title> <booktitle> In Proceedings of the 1992 ACM International Conference on Supercomputing, </booktitle> <address> Washington, DC, </address> <month> July </month> <year> 1992. </year>
Reference-contexts: The most important optimizations performed are message vectorization (which hoists communication out of loops thus combining multiple single-element messages into a single vectorized message) and message coalescing (which combines messages resulting from different references to the same array) <ref> [18] </ref>. However, the effectiveness of optimizations is limited by the fact that most of the analysis is performed for a single loop nest at a time, and very little is done to optimize communication across arbitrary control flow.
Reference: [19] <author> C. Koelbel, D. Loveman, R. Schreiber, G. Steele, Jr., and M. Zosel. </author> <title> The High Performance Fortran Handbook. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1994. </year>
Reference-contexts: In recent years significant efforts have been made to develop programming languages that provide shared address space in order to free the programmer from the burden of manipulating messages directly. Data-parallel languages, such as Fortran D [17], Vienna Fortran [5], and High Performance Fortran (HPF) <ref> [19] </ref>, provide directives for the programmer to specify how data should be distributed among processors. Using the distribution directives, compilers for these languages (which are often source-to-source translators) generate SPMD-style fl This work was supported in part by ARPA contract DABT63-92-C-0038. and NSF Cooperative Agreement Number CCR-9120008.
Reference: [20] <author> C.-W. Tseng. </author> <title> An Optimizing Fortran D Compiler for MIMD Distributed-Memory Machines. </title> <type> PhD thesis, </type> <institution> Dept. of Computer Science, Rice University, </institution> <month> January </month> <year> 1993. </year> <month> 16 </month>
Reference-contexts: This algorithm was first described in [3] and [6], and its implementation in the Fortran D compiler is detailed in <ref> [20] </ref>. In order to avoid communicating redundant data, the compiler applies message coalescing, which combines messages for different references to the same array. In the absence of data-flow analysis, this optimization is performed only within a single loop nest, and thus many opportunities for eliminating redundant messages may be missed. <p> These RSDs are augmented to handle simple forms of boundary conditions <ref> [20] </ref>. While this representation is sufficient for one-dimensional BLOCK and CYCLIC distributions currently supported by the compiler, a more general representation is necessary for communication sets that arise with BLOCK CYCLIC and multi-dimensional distributions. <p> In our experiment we used Livermore 18 explicit hydrodynamics kernel and Shallow weather prediction program written by Paul Swartztrauber, National Center for Atmospheric Research (NCAR). Both benchmarks are highly data-parallel and significant speedups were reported when they were compiled with the existing Fortran D compiler <ref> [20] </ref>. However, hand-coded versions were still up to 25% faster, with most of the difference coming from eliminating redundant messages and increasing the overlap of communication with computation | exactly the optimizations that we propose to automate. (Although hand-coded versions of some benchmarks described in [20] were up to 50% faster <p> the existing Fortran D compiler <ref> [20] </ref>. However, hand-coded versions were still up to 25% faster, with most of the difference coming from eliminating redundant messages and increasing the overlap of communication with computation | exactly the optimizations that we propose to automate. (Although hand-coded versions of some benchmarks described in [20] were up to 50% faster (Dgefa and Er-lebacher), these improvements were due to aggressive program transformations [1], which are beyond the scope of this paper.) After translating original Fortran D programs into SPMD-style Fortran code, the resulting programs were hand-instrumented to reflect the optimizations that would be performed using our <p> This optimization tries to combine multiple messages corresponding to different arrays into a single message, in an attempt to reduce the startup overhead. Although aggregation might introduce extra buffering cost, it is claimed in <ref> [20] </ref> that this optimization Program Problem Size Proc Elim. Redund. Comm. Comm/Comp.
References-found: 20

