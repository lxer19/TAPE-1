URL: ftp://publications.ai.mit.edu/ai-publications/1000-1499/AIM-1164.ps.Z
Refering-URL: http://www.ai.mit.edu/projects/cbcl/web-pis/poggio/memos.html
Root-URL: 
Title: Networks and the Best Approximation Property  
Author: Federico Girosi and Tomaso Poggio 
Date: 1164 October 1989  45  
Affiliation: MASSACHUSETTS INSTITUTE OF TECHNOLOGY ARTIFICIAL INTELLIGENCE LABORATORY and CENTER FOR BIOLOGICAL INFORMATION PROCESSING WHITAKER COLLEGE  
Pubnum: A.I. Memo No.  C.B.I.P. Paper No.  
Abstract: Networks can be considered as approximation schemes. Multilayer networks of the backpropagation type can approximate arbitrarily well continuous functions (Cybenko, 1989; Funahashi, 1989; Stinchcombe and White, 1989). We prove that networks derived from regularization theory and including Radial Basis Functions (Poggio and Girosi, 1989), have a similar property. From the point of view of approximation theory, however, the property of approximating continuous functions arbitrarily well is not sufficient for characterizing good approximation schemes. More critical is the property of best approximation. The main result of this paper is that multilayer networks, of the type used in backpropagation, are not best approximation. For regularization networks (in particular Radial Basis Function networks) we prove existence and uniqueness of best approximation. This paper describes research done within the Center for Biological Information Processing, in the Department of Brain and Cognitive Sciences, and at the Artificial Intelligence Laboratory. This research is sponsored by a grant from the Office of Naval Research (ONR), Cognitive and Neural Sciences Division; by the Artificial Intelligence Center of Hughes Aircraft Corporation; by the Alfred P. Sloan Foundation; by the National Science Foundation. Support for the A. I. Laboratory's artificial intelligence research is provided by the Advanced Research Projects Agency of the Department of Defense under Army contract DACA76-85-C-0010, and in part by ONR contract N00014-85-K-0124. c fl Massachusetts Institute of Technology,1994
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. Bertero. </author> <title> Regularization methods for linear inverse problems. </title> <editor> In C. G. Talenti, editor, </editor> <title> Inverse Problems. </title> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1986. </year>
Reference: [2] <author> M. Bertero, T. Poggio, and V. Torre. </author> <title> Ill-posed problems in early vision. </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> 76 </volume> <pages> 869-889, </pages> <year> 1988. </year>
Reference: [3] <author> D. Braess. </author> <title> Nonlinear Approximation Theory. </title> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1986. </year>
Reference: [4] <author> D.S. Broomhead and D. Lowe. </author> <title> Multivariable functional interpolation and adaptive networks. </title> <journal> Complex Systems, </journal> <volume> 2 </volume> <pages> 321-355, </pages> <year> 1988. </year>
Reference: [5] <author> S.M. Carrol and B.W. Dickinson. </author> <title> Construction of neural nets using the Radon transform. </title> <booktitle> In Proceedings of the International Joint Conference on Neural Networks, pages I-607-I-611, </booktitle> <address> Washington D.C., </address> <month> June </month> <year> 1989. </year> <journal> IEEE TAB Neural Network Committee. </journal> <volume> 14 </volume>
Reference: [6] <author> E.W. </author> <title> Cheney. Introduction to approximation theory. </title> <publisher> Chelsea Publishing Company, </publisher> <address> New York, </address> <year> 1981. </year>
Reference: [7] <author> G. Cybenko. </author> <title> Continuous valued neural networks with two hidden layers are sufficient. </title> <type> Technical report, </type> <institution> Dept. of Computer Sciences, Tufts Univ., </institution> <address> Medford, MA, </address> <year> 1988. </year>
Reference: [8] <author> G. Cybenko. </author> <title> Approximation by superposition of a sigmoidal function. </title> <journal> Math. Control Systems Signals, </journal> <volume> 2(4) </volume> <pages> 303-314, </pages> <year> 1989. </year>
Reference: [9] <author> C. de Boor. </author> <title> On the approximation by fl-Polynomials. In I.J. Schoenberg, editor, Approximation with special emphasis on spline functions, </title> <address> pages 157-183. </address> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1969. </year>
Reference: [10] <author> K. Funahashi. </author> <title> On the approximate realization of continuous mappings by neural networks. </title> <booktitle> Neural Networks, </booktitle> <volume> 2 </volume> <pages> 183-192, </pages> <year> 1989. </year>
Reference: [11] <author> I.M. Gelfand and G.E. Shilov. </author> <title> Generalized functions. Vol. 1: Properties and Operations. </title> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1964. </year>
Reference: [12] <author> E. Hartman, K. Keeler, and J.M. Kowalski. </author> <title> Layered neural networks with gaussian hidden units as universal approximators. </title> <note> (submitted for publication), </note> <year> 1989. </year>
Reference: [13] <author> C.R. Hobby and J.R. Rice. </author> <title> Approximation from a curve of functions. </title> <journal> Arch. Rat. Mech. Anal., </journal> <volume> 27 </volume> <pages> 91-106, </pages> <year> 1967. </year>
Reference: [14] <author> C. A. Micchelli. </author> <title> Interpolation of scattered data: distance matrices and conditionally positive definite functions. Constructive Approximation, </title> <booktitle> 2 </booktitle> <pages> 11-22, </pages> <year> 1986. </year>
Reference: [15] <author> J. Moody and C. Darken. </author> <title> Fast learning in networks of locally-tuned processing units. </title> <journal> Neural Computation, </journal> <volume> 1(2) </volume> <pages> 281-294, </pages> <year> 1989. </year>
Reference: [16] <author> B. Moore and T. Poggio. </author> <title> Representations properties of multilayer feedforward networks. </title> <booktitle> In Abstracts of the first annual INNS meeting, </booktitle> <pages> page 502, </pages> <address> New York, 1988. </address> <publisher> Pergamon Press. </publisher>
Reference: [17] <author> V.A. Morozov. </author> <title> Methods for solving incorrectly posed problems. </title> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1984. </year>
Reference: [18] <author> T. Poggio and F. Girosi. </author> <title> A theory of networks for approximation and learning. </title> <journal> A.I. </journal> <volume> Memo No. </volume> <pages> 1140, </pages> <institution> Artificial Intelligence Laboratory, Massachusetts Institute of Technology, </institution> <year> 1989. </year>
Reference: [19] <author> J.R. Rice. </author> <title> The approximation of functions, </title> <journal> Vol. </journal> <volume> 1. </volume> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1964. </year>
Reference: [20] <author> J.R. Rice. </author> <title> The approximation of functions, </title> <journal> Vol. </journal> <volume> 2. </volume> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1969. </year>
Reference: [21] <author> W. </author> <title> Rudin. Functional Analysis. </title> <publisher> McGraw-Hill, </publisher> <address> New York, </address> <year> 1973. </year>
Reference: [22] <author> D. E. Rumelhart, G. E. Hinton, and R. J. Williams. </author> <title> Learning internal representations by error propagation. </title> <booktitle> In Parallel Distributed Processing, chapter 8, </booktitle> <pages> pages 318-362. </pages> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1986. </year> <month> 15 </month>
Reference: [23] <author> D. E. Rumelhart, G. E. Hinton, and R. J. Williams. </author> <title> Learning representations by back--propagating errors. </title> <journal> Nature, </journal> <volume> 323(9) </volume> <pages> 533-536, </pages> <month> October </month> <year> 1986a. </year>
Reference: [24] <author> T. J. Sejnowski and C. R. Rosenberg. </author> <title> Parallel networks that learn to pronounce english text. </title> <journal> Complex Systems, </journal> <volume> 1 </volume> <pages> 145-168, </pages> <year> 1987. </year>
Reference: [25] <author> M. Stinchcombe and H. White. </author> <title> Universal approximation using feedforward networks with non-sigmoid hidden layer activation functions. </title> <booktitle> In Proceedings of the International Joint Conference on Neural Networks, pages I-607-I-611, </booktitle> <address> Washington D.C., </address> <month> June </month> <year> 1989. </year> <institution> IEEE TAB Neural Network Committee. </institution>
Reference: [26] <author> M.H. Stone. </author> <title> Applications of the theory of Boolean rings to general topology. </title> <journal> AMS Transactions, </journal> <volume> 41 </volume> <pages> 375-481, </pages> <year> 1937. </year>
Reference: [27] <author> M.H. Stone. </author> <title> The generalized Weierstrass approximation theorem. </title> <journal> Mathematics Magazine, </journal> <volume> 21 </volume> <pages> 167-183, 237-254, </pages> <year> 1948. </year>
Reference: [28] <author> A. N. </author> <title> Tikhonov. Solution of incorrectly formulated problems and the regularization method. </title> <journal> Soviet Math. Dokl., </journal> <volume> 4 </volume> <pages> 1035-1038, </pages> <year> 1963. </year>
Reference: [29] <author> A. N. Tikhonov and V. Y. Arsenin. </author> <title> Solutions of Ill-posed Problems. </title> <editor> W. H. Winston, </editor> <address> Washington, D.C., </address> <year> 1977. </year>
Reference: [30] <author> K. Yosida. </author> <title> Functional Analysis. </title> <publisher> Springer, </publisher> <address> Berlin, </address> <year> 1974. </year> <month> 16 </month>
References-found: 30

