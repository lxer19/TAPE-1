URL: ftp://ftp.cogsci.indiana.edu/pub/mcgraw.carbot.ps
Refering-URL: http://rstcorp.com/~gem/gem.pubs-archive.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: meeden@cs.indiana.edu gem@cogsci.indiana.edu blank@cs.indiana.edu  
Title: Emergent Control and Planning in an Autonomous Vehicle Methodology Given that a connectionist controller will
Author: Lisa Meeden and Gary McGraw and Douglas Blank 
Keyword: Autonomous agents  
Address: Bloomington, Indiana 47405  
Note: Research on Concepts and Cognition  The control networks  
Affiliation: Department of Computer Science Center for  Indiana University  
Abstract: We use a connectionist network trained with reinforcement to control both an autonomous robot vehicle and a simulated robot. We show that given appropriate sensory data and architectural structure, a network can learn to control the robot for a simple navigation problem. We then investigate a more complex goal-based problem and examine the plan-like behavior that emerges. An autonomous agent can be abstractly defined as a mapping from a sequence of sensory inputs to an appropriate action in response to these percepts. Such an agent is autonomous to the extent that its behavior is determined by its immediate inputs and past experience, rather than by its built-in control (Russell & Wefald, 1991). We are interested in investigating the cognitive capabilities of autonomous agents. We believe that cognitive behavior can emerge from the reactive, situated activity of autonomous agents. Some consensus exists about how to design autonomous agents. There should be a relatively direct coupling between perception and action, control should be distributed and decentralized, and most importantly, there should be a dynamic interaction between the environment and the agent (Maes, 1990). However, no such consensus exists on the best method to implement these design features. Connectionist networks can easily accommodate all these design features and we believe they can be effective mechanisms for controlling autonomous agents. This paper focuses on exploring connectionist designs for controlling simple navigation in an autonomous vehicle. We conclude by applying the successful design features to a more difficult problem and examine the plan-like behavior that emerges. We examine these implementation questions by testing network controllers for both a real and simulated robot in a very simple environment, using as experimental variables both type of sensory data, type of training subtasks, and amount of memory. To train the network controllers, we use a reinforcement learning algorithm which converts abstract measures of goodness (reward and punishment) into specific teacher signals. The environment, called the "playpen", is a rectangular box (2 fi 4 feet) with a light in one corner. The reinforcement training problems we investigate involve coordination of motor activity with the information being supplied by the sensors. The navigation problem, which we refer to as avoid and move, reinforces the robot for moving in the playpen while avoiding the walls. The more difficult problem, light as food, adds a goal state in order to simulate hunger, and reinforces the robot for periodically seeking and avoiding the light while still avoiding the walls and moving. By holding a problem constant and varying sensory ability we can determine to what extent the addition of more sensors helps the robot succeed at its problem. Similarly, we can evaluate the utility of contextual memory and different training subtasks such as auto-association and prediction. Our robot, called carbot, is a modified toy car (6 fi 9 inches) controlled by a programmable mini-board (designed by (Martin, 1992)). Carbot was inexpensive to build, primarily because it makes use of primitive sensors|no lasers, video, or sonar. It has two servomotors; one controls forward and backward motion and the other steering. The robot has two types of physical sensors: digital touch sensors on the front and back bumpers, and analog light sensors on stalks near the back. The light sensors are directed 30 degrees to each side of carbot. Carbot is controlled by a remote connectionist network that communicates with the mini-board. The network gathers input data from the sensors and determines how to set the motors for the next time step. Figure 1 shows the standard network used in our experiments. There are four discrete sets of input units; three are for sensors and one is for context memory. The first set represents the previous state of the two motors| two units per motor. The first motor unit represents the spin direction of the rear motor (this determines direction of motion|forward or backward). The second unit designates the state of the motor as on or off. The third unit represents the spin direction of the front motor (this determines the direction of turning|left or right). Note that in order to turn carbot must have both motors 
Abstract-found: 1
Intro-found: 0
Reference: <author> Ackley, D. H. and Littman, M. L. </author> <year> 1990. </year> <title> Generalization and scaling in reinforcement learning. </title> <editor> In Touretsky, D. S., editor, </editor> <booktitle> Advances in Neural Information Processing Systems 2, </booktitle> <pages> pages 550-557. </pages> <address> San Mateo, CA: </address> <publisher> Morgan Kauf-mann. </publisher>
Reference: <author> Chapman, D. and Agre, P. E. </author> <year> 1987. </year> <title> Abstract reasoning as emergent from concrete activity. </title> <editor> In Georgeff, M. P. and Lansky, A. L., editors, </editor> <booktitle> Reasoning about actions and plans: Proceedings of the 1986 Workshop, </booktitle> <pages> pages 411-424. </pages> <address> Los Altos, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Elman, J. L. </author> <year> 1990. </year> <title> Finding structure in time. </title> <journal> Cognitive Science, </journal> <volume> 14 </volume> <pages> 179-212. </pages>
Reference: <author> Maes, P. </author> <year> 1990. </year> <title> Guest editorial: Designing autonomous agents. </title> <booktitle> Robotics and Autonomous Systems, </booktitle> (6):1-2. 
Reference: <author> Martin, F. </author> <year> 1992. </year> <title> Mini board 2.0 technical reference. </title> <publisher> MIT Media Lab, </publisher> <address> Cambridge MA 02139. </address>
Reference: <author> Russell, S. and Wefald, E. </author> <year> 1991. </year> <title> Do the Right Thing: Studies in Limited Rationality. </title> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
References-found: 6

