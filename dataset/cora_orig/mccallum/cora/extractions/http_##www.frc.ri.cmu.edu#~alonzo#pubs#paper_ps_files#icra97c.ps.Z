URL: http://www.frc.ri.cmu.edu/~alonzo/pubs/paper_ps_files/icra97c.ps.Z
Refering-URL: http://www.frc.ri.cmu.edu/~alonzo/pubs/pubs.html
Root-URL: 
Note: Page 1 Abstract  
Abstract: For autonomously navigating vehicles, the automatic generation of dense geometric models of the environment is a computation-ally expensive process. Using first principles, it is possible to quantify the relationship between the raw throughput required of the perception system and the maximum safely achievable speed of the vehicle. We show that terrain mapping perception is of polynomial complexity in the response distance. To the degree that geometric perception consumes time, it also degrades real-time response characteristics. Given this relationship, several strategies of adaptive geometric perception arise which are practical for autonomous vehicles. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. Daily et al., </author> <title> Autonomous Cross Country Navigation with the ALV, </title> <booktitle> In Proc. of the 1988 IEEE International Conference on Robotics and Automation, </booktitle> <address> Philadelphia, Pa, </address> <note> April 1988; pp. 718-726. </note>
Reference: [2] <author> H. P. Moravec, </author> <title> Obstacle Avoidance and Navigation in the Real World by a Seeing Robot Rover, </title> <type> Ph. D. Thesis, </type> <institution> Stanford University, </institution> <year> 1980. </year>
Reference: [3] <author> A. J. Kelly, </author> <title> An Intelligent Predictive Control Approach to the High-Speed, Cross Country Autonomous Navigation Problem, </title> <type> Ph. D. thesis, </type> <institution> Robotics Institute, Carnegie Mellon University, </institution> <month> June </month> <year> 1995. </year>
Reference: [4] <author> A. Kelly, and A. Stentz, </author> <title> Analysis of Requirements of Rough Terrain Autonomous Mobility: Part I: Throughput and Response, </title> <booktitle> IEEE International Conference on Robotics and Automation, </booktitle> <address> Albu-querque, New Mexico, </address> <month> April </month> <year> 1997. </year>
Reference-contexts: Yet, the evidence for this need has not been based on any underlying theory. This paper is concerned with the problem of estimating the computational complexity of perception in typical outdoor mobility scenarios. It is one of three related papers <ref> [4] </ref>, [5] in these proceedings of which [4] and [5] should be read first. <p> Yet, the evidence for this need has not been based on any underlying theory. This paper is concerned with the problem of estimating the computational complexity of perception in typical outdoor mobility scenarios. It is one of three related papers <ref> [4] </ref>, [5] in these proceedings of which [4] and [5] should be read first. <p> We will employ the following assumptions: Horizontal field of view is fixed at 80, 120, 170, and 215 for each increasing reaction time respectively based on analy sis presented in <ref> [4] </ref>. Sensor frame rate is set to 2 Hz because this is a typical value for a laser rangefinder with a wide VFOV. Minimum acuity will be used because this is actually the most stringent requirement beyond some range.
Reference: [5] <author> A. Kelly, and A. Stentz, </author> <title> Analysis of Requirements of Rough Terrain Autonomous Mobility: Part II: Resolution and Accuracy, </title> <booktitle> IEEE International Conference on Robotics and Automation, </booktitle> <address> Albu-querque, New Mexico, </address> <month> April </month> <year> 1997. </year>
Reference-contexts: Yet, the evidence for this need has not been based on any underlying theory. This paper is concerned with the problem of estimating the computational complexity of perception in typical outdoor mobility scenarios. It is one of three related papers [4], <ref> [5] </ref> in these proceedings of which [4] and [5] should be read first. <p> Yet, the evidence for this need has not been based on any underlying theory. This paper is concerned with the problem of estimating the computational complexity of perception in typical outdoor mobility scenarios. It is one of three related papers [4], <ref> [5] </ref> in these proceedings of which [4] and [5] should be read first.
Reference: [6] <author> L. Matthies, A. Kelly, T. Litwin, </author> <title> Obstacle Detection for Unmanned Ground Vehicles: A Progress Report., </title> <note> to appear in IEEE International Symposium on Intelligent Vehicles. </note>
Reference: [7] <author> L. Matthies, </author> <title> Stereo Vision for Planetary Rovers, </title> <journal> International Journal of Computer Vision, </journal> <volume> 8:1, </volume> <pages> 71-91, </pages> <year> 1992. </year>
Reference: [8] <author> R. T. Dunlay and D. G. Morgenthaler, </author> <title> Obstacle Detection and Avoidance from Range Data, </title> <booktitle> In Proc. SPIE Mobile Robots Conference, </booktitle> <address> Cambridge, Mass., </address> <year> 1986 </year>
Reference: [9] <author> E.D. Dickmanns. </author> <title> Dynamic computer vision for mobile robot control, </title> <booktitle> Proceedings of the 19th International Symposium and Exposition on Robots, </booktitle> <pages> pp. 314-27; </pages>
Reference: [10] <author> K. E. Olin and David Tseng. </author> <title> Autonomous Cross Country Navigation, </title> <journal> IEEE Expert, </journal> <month> August </month> <year> 1991. </year>
Reference: [11] <author> M. Hebert, T. Kanade, and I. Kweon. </author> <title> 3-D Vision Techniques for Autonomous Vehicles, </title> <type> Technical Report CMU-RI-TR-88-12, </type> <institution> The Robotics Institute, Carnegie Mellon University, </institution> <year> 1988 </year>

References-found: 11

