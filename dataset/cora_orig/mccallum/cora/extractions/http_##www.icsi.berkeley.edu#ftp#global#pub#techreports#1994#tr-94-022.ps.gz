URL: http://www.icsi.berkeley.edu/ftp/global/pub/techreports/1994/tr-94-022.ps.gz
Refering-URL: http://www.icsi.berkeley.edu/ftp/global/pub/techreports/1994/
Root-URL: http://www.icsi.berkeley.edu
Title: On the Relationship between Synthesizing and Tagging  
Phone: (510) 643-9153 FAX (510) 643-7684  
Author: Hans Werner Guesgen 
Address: I 1947 Center St. Suite 600 Berkeley, California 94704-1198  
Affiliation: INTERNATIONAL COMPUTER SCIENCE INSTITUTE  
Pubnum: TR-94-022  
Abstract: During recent years, various constraint satisfaction algorithms have been developed. Among them are Freuder's synthesizing algorithm and our tagging method. We will compare the two approaches in this paper and work out commonalities and differences. The purpose of this paper is to give a deeper insight into existing methods (rather than introducing new ones). Although the algorithms we chose for our investigation might not be the most valuable ones from the viewpoint of applications, they illustrate important and interesting principles of constraint satisfaction. fl On leave from the Computer Science Department at the University of Auckland, Private Bag 92019, Auckland, New Zealand, email: hans@cs.auckland.ac.nz. The author has been supported by the University of Auckland Research Fund under the grant numbers A18/XXXXX/62090/3414014 and A18/XXXXX/62090/F3414025. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> P.R. Cooper and M.J. Swain. </author> <title> Parallelism and domain dependence in constraint satisfaction. </title> <type> Technical Report 255, </type> <institution> University of Rochester, Computer Science Department, Rochester, </institution> <address> New York, </address> <year> 1988. </year>
Reference-contexts: Examples of local propagation algorithms are the well-known AC-x algorithms [11, 12], (massively) parallel versions of which can be found in <ref> [1, 10, 13, 14] </ref>. The basic idea of tagging is to provide the domain values with tags and to apply the local propagation algorithm to the tagged values.
Reference: [2] <author> E.C. Freuder. </author> <title> Synthesizing constraint expressions. </title> <journal> Communications of the ACM, </journal> <volume> 21 </volume> <pages> 958-966, </pages> <year> 1978. </year>
Reference-contexts: 1 Introduction Unlike many other papers in the area of constraint satisfaction, this paper does not introduce any new method, technique, or algorithm. On the contrary, it takes two existing constraint satisfaction algorithms and discusses their common aspects and differences. The two algorithms are: Synthesizing Algorithm In <ref> [2] </ref>, Freuder introduced an approach to constraint satisfaction based on generating higher order constraints. The algorithm starts with a binary constraint network.
Reference: [3] <author> H.W. Guesgen. CONSAT: </author> <title> A System for Constraint Satisfaction. </title> <booktitle> Research Notes in Artificial Intelligence. </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, California, </address> <year> 1989. </year>
Reference-contexts: The same holds for the tagging method. This method even works for hierarchical constraint networks, i.e., constraint networks whose components may be other (hierarchical) constraint networks <ref> [3] </ref>. Last but not least, a remark is in order regarding finite versus infinite relations: 6 Infinite Constraints Both algorithms work with networks of finite constraints, i.e., constraints whose relations have a finite number of elements. <p> A pattern-characterizable relation is a possibly infinite relation whose elements can be specified by a finite number of patterns. We implemented pattern-characterizable relations in the constraint satisfaction system CONSAT <ref> [3] </ref>, and we incorporated them into the tagging method. 6 Conclusion Although the synthesizing algorithm and the tagging method were developed at different places, at different times, and independently of each other, they have many things in common.
Reference: [4] <author> H.W. Guesgen. </author> <title> A universal constraint programming language. </title> <booktitle> In Proc. IJCAI-89, </booktitle> <pages> pages 60-65, </pages> <address> Detroit, Michigan, </address> <year> 1989. </year> <month> 7 </month>
Reference-contexts: In the case of the example network N , the algorithm has to fill four positions in each full tag. 1 In <ref> [4] </ref>, a more efficient way to evaluate constraints is discussed.
Reference: [5] <author> H.W. Guesgen. </author> <title> Relational connectionist networks. </title> <booktitle> In Proc. ANNES-93, </booktitle> <pages> pages 23-28, </pages> <address> Dunedin, New Zealand, </address> <year> 1993. </year>
Reference-contexts: We will focus on the tuple variant in the following; details of the Godel number variant can be found in <ref> [5] </ref>. We distinguish between two types of tags: Those that are assigned to the values when single constraints are evaluated and those that are used in constraint networks. The tags that are assigned when a constraint is evaluated are called subtags, and we use integers to represent them.
Reference: [6] <author> H.W. Guesgen and J. Hertzberg. </author> <title> A Perspective of Constraint-Based Reasoning. </title> <booktitle> Lecture Notes in Artificial Intelligence 597. </booktitle> <publisher> Springer, </publisher> <address> Berlin, Germany, </address> <year> 1992. </year>
Reference-contexts: To make this point even stronger, neglect for a moment that there is a difference between variables and constraints. This can be achieved by using the concept of dynamic constraints as introduced in <ref> [6] </ref>. Dynamic constraints play the role of both variables and constraints. When formulating a given CSP as a dynamic CSP, the difference between synthesizing and tagging almost boils down to a syntactic difference only. The paper certainly doesn't provide an exhaustive comparison of synthesizing and tagging.
Reference: [7] <author> H.W. Guesgen, K. Ho, </author> <title> and P.N. Hilfinger. A tagging method for parallel constraint satisfaction. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 16 </volume> <pages> 72-75, </pages> <year> 1992. </year>
Reference-contexts: It successively computes 3-ary, 4-ary, etc. constraints and adds them to the network until a n-ary constraint is computed, where n is the number of variables in the network. This n-ary constraint represents the solution of the problem represented by the constraint network. Tagging Method In <ref> [7] </ref>, we suggested a method which extends a standard filtering algorithm like the Waltz algorithm (i.e., an algorithm usually computing arc consistency) such that it can be used to compute globally consistent solutions. The idea is to associate tags with the values propagated in the network.
Reference: [8] <author> K. Ho, P.N. Hilfinger, and H.W. Guesgen. </author> <title> Optimistic parallel discrete relaxation. </title> <booktitle> In Proc. IJCAI-93, </booktitle> <pages> pages 268-273, </pages> <address> Chambery, France, </address> <year> 1993. </year>
Reference-contexts: The latter, for example, can be implemented in a straightforward way on a parallel computer by using the optimistic discrete relaxation scheme described in <ref> [8] </ref>. The idea of this scheme is to organize the full tags in a lattice structure. Parallel tagging can proceed as long as full tags are filled according to the lattice structure. Whenever the lattice structure is violated (which actually doesn't occur very often), certain computation steps must be repeated. <p> The paper certainly doesn't provide an exhaustive comparison of synthesizing and tagging. For example, we haven't compared synthesizing and tagging when applied to identical test data (like the test data used in <ref> [8] </ref> to evaluate the performance of tagging in parallel). This might give further insights into the two approaches and is certainly worth to be investigated in future research.
Reference: [9] <author> W. Hower. </author> <title> Constraint satisfaction via partially parallel propagation steps. </title> <editor> In B. Fronhofer and G. Wrightson, editors, </editor> <booktitle> Parallelization in Inference Systems, </booktitle> <pages> pages 234-242. </pages> <publisher> Springer Verlag, </publisher> <address> Berlin, Germany, </address> <year> 1992. </year>
Reference-contexts: Parallel tagging can proceed as long as full tags are filled according to the lattice structure. Whenever the lattice structure is violated (which actually doesn't occur very often), certain computation steps must be repeated. See <ref> [9] </ref> for details of how the synthesizing algorithms can be implemented in parallel. Let us now look at the arity of the constraints in the network. So far, we have assumed that a binary constraint network be given, i.e., a network whose constraints have at most an arity of two.
Reference: [10] <author> S. Kasif. </author> <title> Parallel solutions to constraint satisfaction problems. </title> <booktitle> In Proc. KR-89, </booktitle> <pages> pages 180-188, </pages> <address> Toronto, Canada, </address> <year> 1989. </year>
Reference-contexts: Examples of local propagation algorithms are the well-known AC-x algorithms [11, 12], (massively) parallel versions of which can be found in <ref> [1, 10, 13, 14] </ref>. The basic idea of tagging is to provide the domain values with tags and to apply the local propagation algorithm to the tagged values.
Reference: [11] <author> A.K. Mackworth. </author> <title> Consistency in networks of relations. </title> <journal> Artificial Intelligence, </journal> <volume> 8 </volume> <pages> 99-118, </pages> <year> 1977. </year>
Reference-contexts: Examples of local propagation algorithms are the well-known AC-x algorithms <ref> [11, 12] </ref>, (massively) parallel versions of which can be found in [1, 10, 13, 14]. The basic idea of tagging is to provide the domain values with tags and to apply the local propagation algorithm to the tagged values.
Reference: [12] <author> R. Mohr and T.C. Henderson. </author> <title> Arc and path consistency revisited. </title> <journal> Artificial Intelligence, </journal> <volume> 28 </volume> <pages> 225-233, </pages> <year> 1986. </year>
Reference-contexts: Examples of local propagation algorithms are the well-known AC-x algorithms <ref> [11, 12] </ref>, (massively) parallel versions of which can be found in [1, 10, 13, 14]. The basic idea of tagging is to provide the domain values with tags and to apply the local propagation algorithm to the tagged values.
Reference: [13] <author> A. Rosenfeld. </author> <title> Networks of automata: Some applications. </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics, </journal> <volume> 5 </volume> <pages> 380-383, </pages> <year> 1975. </year>
Reference-contexts: Examples of local propagation algorithms are the well-known AC-x algorithms [11, 12], (massively) parallel versions of which can be found in <ref> [1, 10, 13, 14] </ref>. The basic idea of tagging is to provide the domain values with tags and to apply the local propagation algorithm to the tagged values.
Reference: [14] <author> A. Samal and T.C. Henderson. </author> <title> Parallel consistent labeling algorithms. </title> <journal> International Journal of Parallel Programming, </journal> <volume> 16 </volume> <pages> 341-364, </pages> <year> 1987. </year> <month> 8 </month>
Reference-contexts: Examples of local propagation algorithms are the well-known AC-x algorithms [11, 12], (massively) parallel versions of which can be found in <ref> [1, 10, 13, 14] </ref>. The basic idea of tagging is to provide the domain values with tags and to apply the local propagation algorithm to the tagged values.
References-found: 14

