URL: http://www.cs.brown.edu/people/dgk/Papers/tacs94.ps
Refering-URL: http://www.cs.brown.edu/people/dgk/papers.html
Root-URL: http://www.cs.brown.edu/
Title: Constraint Programming and Database Query Languages  
Author: Paris C Kanellakis and Dina Q Goldin 
Address: Providence, RI 02192, USA  
Affiliation: Brown University,  
Abstract: The declarative programming paradigms used in constraint languages can lead to powerful extensions of Codd's relational data model. The development of constraint database query languages from logical database query languages has many similarities with the development of constraint logic programming from logic programming, but with the additional requirements of data efficient, set-at-a-time, and bottom-up evaluation. In this overview of constraint query languages (CQLs) we first present the framework of [41]. The principal idea is that: "the k-tuple (or record) data type can be generalized by a conjunction of quantifier-free constraints over k variables". The generalization must preserve various language properties of the relational data model, e.g., the calculus/algebra equivalence, and have time complexity polynomial in the size of the data. We next present an algebra for dense order constraints that is simpler to evaluate than the calculus described in [41], and we sharpen some of the related data complexity bounds. We note that CQLs are applicable to spatial databases. This is because these languages have "spatial point set" as the semantics of their record data type and because existing multi-dimensional searching data structures can support I/O efficient access to sets of records. Finally, we observe that CQLs can be augmented with complex object data types, aggregate operations, and null-values, just like the relational data model.
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> S. Abiteboul, C. Beeri. </author> <title> On the Power of Languages for the Manipulation of Complex Objects. </title> <note> INRIA Research Report 846, </note> <year> 1988. </year>
Reference-contexts: Many aggregate primitives have low data complexity [5]. Introducing aggregates in a CQL for attributes ranging over an infinite set is harder, since it typically involves integration, and is a topic of current research [50]. Complex Objects: The second extension involves complex objects. As described in <ref> [1, 2] </ref> complex objects are built using tuple and finite-set data type constructors. Generalized tuples are tuple constructors, but they also have some of the properties of finite-set constructors. This subtelty is best illustrated by an example. Example 9. Consider a convex polygon in 2-dimensional space. <p> For example, null values can be introduced with existential quantification in constraints. Finite complex objects <ref> [1, 2] </ref> and aggregation [45] over finite sets can co-exist with infinite relations.
Reference: 2. <author> S. Abiteboul and P. Kanellakis. </author> <title> Database Theory Column: Query Languages for Complex Object Databases. </title> <journal> SIGACT News, </journal> <volume> 21, </volume> <pages> pp. 9-18, </pages> <year> 1990. </year>
Reference-contexts: Many aggregate primitives have low data complexity [5]. Introducing aggregates in a CQL for attributes ranging over an infinite set is harder, since it typically involves integration, and is a topic of current research [50]. Complex Objects: The second extension involves complex objects. As described in <ref> [1, 2] </ref> complex objects are built using tuple and finite-set data type constructors. Generalized tuples are tuple constructors, but they also have some of the properties of finite-set constructors. This subtelty is best illustrated by an example. Example 9. Consider a convex polygon in 2-dimensional space. <p> For example, null values can be introduced with existential quantification in constraints. Finite complex objects <ref> [1, 2] </ref> and aggregation [45] over finite sets can co-exist with infinite relations.
Reference: 3. <author> S. Abiteboul and V. Vianu. </author> <title> Datalog Extensions for Database Queries and Updates. </title> <journal> J. Comput. System Sci., </journal> <volume> 43 (1991), </volume> <pages> pp. 62-124. </pages>
Reference-contexts: For example: Relational calculus [20] + the theory of real closed fields [68, 23, 8, 48, 60]; Relational calculus [20] + the theory of real (or Presburger) addition [29, 30, 9, 15]; Relational calculus [20] + the theory of discrete order with constants. Inflationary Datalog : <ref> [3, 32, 47] </ref> + the theory of dense order with constants [28]; Inflationary Datalog : + the theory of equality on an infinite domain with constants. (4) The semantics of a CQL is based on that of the decidable logical theory, by interpreting database atoms as shorthands for formulas of the
Reference: 4. <author> A.K. Aylamazyan, </author> <title> M.M. Gilula, A.P. Stolboushkin, G.F. Schwartz. Reduction of the Relational Model with Infinite Domain to the Case of Finite Domains. </title> <journal> Proc. USSR Acad. of Science (Doklady), </journal> <volume> 286(2) </volume> <pages> 308-311, </pages> <year> 1986. </year>
Reference-contexts: CQLs also extend the approach to safe queries of <ref> [4, 35, 44, 58] </ref>. The example CQLs of [41] are applicable to spatial databases, where dense order is present. Temporal databases require the development of analogous frameworks for the theory of discrete order with constants see [39]. <p> The analogue for the relational model is that relations are finite structures, and queries are supposed to preserve this finiteness. This is a requirement that creates various "safety" problems in relational databases [20, 69]. The precise analogue in relational databases is the notion of weak safety of <ref> [4] </ref>. Evaluation of a query corresponds to an instance of a decision problem.
Reference: 5. <author> D.A. Barrington, N. Immerman, H. Straubing. </author> <title> On Uniformity within NC 1 . JCSS, </title> <type> 41 </type> <institution> 274-306,1990. </institution>
Reference-contexts: Also, by a slight modification of [36, 73] Inflationary Datalog : with dense linear order expresses exactly PTIME (this is the = in the table above). It is possible to strengthen the LOGSPACE bounds to uniform AC 0 , using random-access Alternating TMs <ref> [5, 16] </ref> with a fixed number of alternations and a logarithmic time bound. The same applies to relational calculus (Inflationary Datalog : ) with equality constraints over an infinite domain. Let us now look at a fairly rich constraint theory. <p> Aggregates: The first important extension involves aggregate operations (e.g., maximum, average etc), see [45]. Introducing aggregates in a CQL is identical with the relational data model if an attribute ranges over a finite set. Many aggregate primitives have low data complexity <ref> [5] </ref>. Introducing aggregates in a CQL for attributes ranging over an infinite set is harder, since it typically involves integration, and is a topic of current research [50]. Complex Objects: The second extension involves complex objects.
Reference: 6. <author> M. Baudinet, M. Niezette, P. Wolper. </author> <title> On the Representation of Infinite Temporal Data and Queries. </title> <booktitle> Proc. 10th ACM PODS, </booktitle> <pages> 280-290, </pages> <year> 1991. </year>
Reference-contexts: Constraint use for database logic program analysis is also relevant here, e.g., [13, 14, 70, 71]. (3) We have addressed the spatial applications of CQLs. Constraints offer useful approaches to temporal databases as well. For recent developments in temporal databases we refer to <ref> [6, 18, 61] </ref>. The subject of temporal constraints has also been addressed extensively in the artificial intelligence literature (which we unfortunately do not have the space or expertise to survey here).
Reference: 7. <author> R. Bayer, E. McCreight. </author> <title> Organization of Large Ordered Indexes. </title> <journal> Acta Informatica, </journal> <volume> 1 </volume> <pages> 173-189, </pages> <year> 1972. </year>
Reference-contexts: Without the ability to perform such searches relational databases on secondary storage would have been impractical. I/O efficient (i.e., logarithmic or constant) use of secondary storage is an additional requirement, beyond low data complexity, whose satisfaction greatly contributes to relational technology. B-trees and their variants B + -trees, <ref> [7, 24] </ref>, are examples of important data structures for implementing relational databases. In particular, let each secondary memory access transmit B units of data, let r be a relation with N tuples, and let us have a B + -tree on the attribute x of r.
Reference: 8. <author> M. Ben-Or, D. Kozen, J. Reif. </author> <title> The Complexity of Elementary Algebra and Geometry. </title> <journal> JCSS, </journal> <volume> 32 </volume> <pages> 251-264, </pages> <year> 1986. </year>
Reference-contexts: The technical tools for this integration were: data complexity [17, 73] from database theory, and quantifier elimination methods from mathematical logic <ref> [28, 29, 68, 23, 8, 48, 60] </ref>. More specifically, finite relations are generalized to finitely representable relations and appropriate algebras for their data manipulation can be developed in this framework. In many cases, the algebras have polynomial time data complexity. <p> A generalized database is a finite set of generalized relations. (3) The syntax of a CQL is the union of an existing database query language and a decidable logical theory. For example: Relational calculus [20] + the theory of real closed fields <ref> [68, 23, 8, 48, 60] </ref>; Relational calculus [20] + the theory of real (or Presburger) addition [29, 30, 9, 15]; Relational calculus [20] + the theory of discrete order with constants. <p> Let us now look at a fairly rich constraint theory. Relational calculus with real polynomial inequality constraints can be evaluated bottom-up in closed form and PTIME data complexity. This is a direct consequence of [23]. More recent results <ref> [8, 48, 60] </ref> place the data complexity in NC. The precise expressibility (in terms of data complexity within NC) for real polynomial constraints is still open. Clarifying the relationship with the data complexity of weaker theories involving addition and multiplication by constants is a topic of interest [25]. <p> How can recursion be combined with linear constraints in a safe fashion? (6) The technology of algorithms for logical theories is still rather complex, but much progress has been accomplished in recent years. For example, see <ref> [8, 48, 60] </ref> for the state-of-the-art in real closed fields.
Reference: 9. <author> L. Berman. </author> <title> Precise Bounds for Presburger Arithmetic and the Reals with Addition. </title> <booktitle> Proc. 18th IEEE FOCS, </booktitle> <pages> pp. 95-99, </pages> <year> 1977. </year>
Reference-contexts: In many cases, the algebras have polynomial time data complexity. This use of data complexity (a common tool for studying expressibility in finite model theory) distinguishes the CQL framework from arbitrary (and inherently exponential) theorem proving <ref> [30, 9, 15] </ref>. Example 1. Let us illustrate database querying and introduce some of its notation. The meaning and use is (or rather should be) intuitively obvious. For formal definitions we refer the reader to [40, 69]. <p> For example: Relational calculus [20] + the theory of real closed fields [68, 23, 8, 48, 60]; Relational calculus [20] + the theory of real (or Presburger) addition <ref> [29, 30, 9, 15] </ref>; Relational calculus [20] + the theory of discrete order with constants.
Reference: 10. <author> A.H. Borning. </author> <title> The Programming Language Aspects of ThingLab, A Constraint-Oriented Simulation Laboratory. </title> <journal> ACM TOPLAS 3:4:353-387, </journal> <year> 1981. </year>
Reference-contexts: Pioneering work in constraint programming goes back to the early 1960's, e.g., Sutherland's SKETCHPAD [67]. The theme has been investigated since the 1970's, e.g., in artificial intelligence [31, 54, 55, 66], in graphical-interfaces <ref> [10] </ref>, and in logic programming languages [37, 22, 27]. The relevant literature and contributions are too large to attempt a survey. Instead we will limit our exposition to recent applications in databases. ? Research was supported by ONR grant N00014-91-J-4052 ARPA Order No. 8225.
Reference: 11. <author> A. Brodsky, J. Jaffar, M.J. Maher. </author> <title> Toward Practical Constraint Databases. </title> <booktitle> Proc. 19th VLDB, </booktitle> <pages> 322-331, </pages> <year> 1993. </year>
Reference-contexts: Are there more subtle ways of adding these extensions to CQLs? For example, adding aggregation operations over infinite sets is motivated by querying about area size and is a challenging problem [50]. (5) Linear constraint databases <ref> [11] </ref> are among the most applicable CQLs, and will certainly be among the first to be implemented. Even for this theoretically simple case the expressive power is not fully understood [25].
Reference: 12. <author> A. Brodsky, C. Lassez. </author> <title> Separability of Polyhedra and a New Approach to Spatial Storage. </title> <booktitle> in [42]. </booktitle>
Reference-contexts: How do various optimization methods (such as selection propagation, join ordering and other algebraic transformations, magic sets etc) combine with CQLs? This would involve extending [58]. For some recent research in this direction we refer to <ref> [34, 52, 56, 65, 12] </ref>. Constraint use for database logic program analysis is also relevant here, e.g., [13, 14, 70, 71]. (3) We have addressed the spatial applications of CQLs. Constraints offer useful approaches to temporal databases as well.
Reference: 13. <author> A. Brodsky, Y. Sagiv. </author> <title> Inference of Monotonicity Constraints in Datalog Programs. </title> <booktitle> Proc. 8th ACM PODS, </booktitle> <pages> 190-200, </pages> <year> 1989. </year>
Reference-contexts: integrity constraint maintenance algorithms. 2 The CQL framework of [41] provided a unified view of some previous database research: for example, on the power of constraints for the implicit specification of temporal data [19], for extending relational algebra [33, 46], for magic set evaluation [58], and for logic program analysis <ref> [13] </ref>. CQLs also extend the approach to safe queries of [4, 35, 44, 58]. The example CQLs of [41] are applicable to spatial databases, where dense order is present. Temporal databases require the development of analogous frameworks for the theory of discrete order with constants see [39]. <p> For some recent research in this direction we refer to [34, 52, 56, 65, 12]. Constraint use for database logic program analysis is also relevant here, e.g., <ref> [13, 14, 70, 71] </ref>. (3) We have addressed the spatial applications of CQLs. Constraints offer useful approaches to temporal databases as well. For recent developments in temporal databases we refer to [6, 18, 61].
Reference: 14. <author> A. Brodsky, Y. Sagiv. </author> <title> Inference of Inequality Constraints in Logic Programs. </title> <booktitle> Proc. 10th ACM PODS, </booktitle> <pages> 227-241, </pages> <year> 1991. </year>
Reference-contexts: For some recent research in this direction we refer to [34, 52, 56, 65, 12]. Constraint use for database logic program analysis is also relevant here, e.g., <ref> [13, 14, 70, 71] </ref>. (3) We have addressed the spatial applications of CQLs. Constraints offer useful approaches to temporal databases as well. For recent developments in temporal databases we refer to [6, 18, 61].
Reference: 15. <author> A.R. Bruss, A.R. Meyer. </author> <title> On Time-Space Classes and their Relation to the Theory of Real Addition. </title> <booktitle> Proc. 10th ACM STOC, </booktitle> <pages> pp. 233-239, </pages> <year> 1978. </year>
Reference-contexts: In many cases, the algebras have polynomial time data complexity. This use of data complexity (a common tool for studying expressibility in finite model theory) distinguishes the CQL framework from arbitrary (and inherently exponential) theorem proving <ref> [30, 9, 15] </ref>. Example 1. Let us illustrate database querying and introduce some of its notation. The meaning and use is (or rather should be) intuitively obvious. For formal definitions we refer the reader to [40, 69]. <p> For example: Relational calculus [20] + the theory of real closed fields [68, 23, 8, 48, 60]; Relational calculus [20] + the theory of real (or Presburger) addition <ref> [29, 30, 9, 15] </ref>; Relational calculus [20] + the theory of discrete order with constants.
Reference: 16. <author> S.R. Buss. </author> <title> The Formula Value Problem is in ALOGTIME. </title> <booktitle> Proc. 19th ACM STOC, </booktitle> <pages> pp. 123-131, </pages> <year> 1987. </year>
Reference-contexts: Also, by a slight modification of [36, 73] Inflationary Datalog : with dense linear order expresses exactly PTIME (this is the = in the table above). It is possible to strengthen the LOGSPACE bounds to uniform AC 0 , using random-access Alternating TMs <ref> [5, 16] </ref> with a fixed number of alternations and a logarithmic time bound. The same applies to relational calculus (Inflationary Datalog : ) with equality constraints over an infinite domain. Let us now look at a fairly rich constraint theory.
Reference: 17. <author> A.K. Chandra, D. Harel. </author> <title> Structure and Complexity of Relational Queries. </title> <journal> JCSS, </journal> <volume> 25:1:99-128, </volume> <year> 1982. </year>
Reference-contexts: One key intuition came from CLP: a conjunction of quantifier-free constraints over k variables, where k depends on the database schema and not the instance, is the correct generalization of the k-tuple or record or ground fact. The technical tools for this integration were: data complexity <ref> [17, 73] </ref> from database theory, and quantifier elimination methods from mathematical logic [28, 29, 68, 23, 8, 48, 60]. More specifically, finite relations are generalized to finitely representable relations and appropriate algebras for their data manipulation can be developed in this framework. <p> The LOGSPACE data complexity analysis is from <ref> [17] </ref>. In the following table we list some theories with upper bounds on their data complexities.
Reference: 18. <author> J. Chomicki. </author> <title> Ptime Query Processing in Temporal Deductive Databases. </title> <booktitle> Proc. 9th ACM PODS, </booktitle> <pages> 379-391, </pages> <year> 1990. </year>
Reference-contexts: Constraint use for database logic program analysis is also relevant here, e.g., [13, 14, 70, 71]. (3) We have addressed the spatial applications of CQLs. Constraints offer useful approaches to temporal databases as well. For recent developments in temporal databases we refer to <ref> [6, 18, 61] </ref>. The subject of temporal constraints has also been addressed extensively in the artificial intelligence literature (which we unfortunately do not have the space or expertise to survey here).
Reference: 19. <author> J. Chomicki, T. Imielinski. </author> <title> Relational Specifications of Infinite Query Answers. </title> <booktitle> Proc. ACM SIGMOD, </booktitle> <pages> 174-183, </pages> <year> 1989. </year>
Reference-contexts: Constraint programming is a high-level programming style, which is often supported by integrity constraint maintenance algorithms. 2 The CQL framework of [41] provided a unified view of some previous database research: for example, on the power of constraints for the implicit specification of temporal data <ref> [19] </ref>, for extending relational algebra [33, 46], for magic set evaluation [58], and for logic program analysis [13]. CQLs also extend the approach to safe queries of [4, 35, 44, 58]. The example CQLs of [41] are applicable to spatial databases, where dense order is present.
Reference: 20. <author> E.F. Codd. </author> <title> A Relational Model for Large Shared Data Banks. </title> <journal> CACM, </journal> <volume> 13:6:377-387, </volume> <year> 1970. </year>
Reference-contexts: Starting with the Japanese 5th Generation Project, these connections were explored in depth during the last decade. The declarative style of database query languages is an important aspect of database systems, that has been at the core of the relational data model since Codd's pioneering work <ref> [20] </ref>. Indeed, having such a language for ad-hoc database querying is a requirement in today's commercial relational technology. Querying in Codd's relational calculus is a form of limited (but very successful) constraint programming. <p> A generalized database is a finite set of generalized relations. (3) The syntax of a CQL is the union of an existing database query language and a decidable logical theory. For example: Relational calculus <ref> [20] </ref> + the theory of real closed fields [68, 23, 8, 48, 60]; Relational calculus [20] + the theory of real (or Presburger) addition [29, 30, 9, 15]; Relational calculus [20] + the theory of discrete order with constants. <p> A generalized database is a finite set of generalized relations. (3) The syntax of a CQL is the union of an existing database query language and a decidable logical theory. For example: Relational calculus <ref> [20] </ref> + the theory of real closed fields [68, 23, 8, 48, 60]; Relational calculus [20] + the theory of real (or Presburger) addition [29, 30, 9, 15]; Relational calculus [20] + the theory of discrete order with constants. <p> For example: Relational calculus <ref> [20] </ref> + the theory of real closed fields [68, 23, 8, 48, 60]; Relational calculus [20] + the theory of real (or Presburger) addition [29, 30, 9, 15]; Relational calculus [20] + the theory of discrete order with constants. <p> The analogue for the relational model is that relations are finite structures, and queries are supposed to preserve this finiteness. This is a requirement that creates various "safety" problems in relational databases <ref> [20, 69] </ref>. The precise analogue in relational databases is the notion of weak safety of [4]. Evaluation of a query corresponds to an instance of a decision problem. <p> As in Codd's relational algebra <ref> [20, 40] </ref>, we will define basic algebraic operations projection (), selection (&), natural join (1), union ([), difference (), and renaming (%), which map one or more generalized relations to a new generalized relation. Algebraic queries over generalized databases are composed of these basic operations. <p> See [38] for definitions of TMs and PRAMs. We assume a standard binary encoding of generalized relations. The CQL framework is interesting because many combinations of database query languages and decidable theories have PTIME data complexity. &gt;From Codd's original work <ref> [20] </ref> it follows that: relational calculus on finite sets can be evaluated bottom-up in closed form and LOGSPACE data complexity. The LOGSPACE data complexity analysis is from [17]. In the following table we list some theories with upper bounds on their data complexities.
Reference: 21. <author> J. Cohen. </author> <title> Constraint Logic Programming Languages. </title> <journal> CACM, </journal> <volume> 33:7:52-68, </volume> <year> 1990. </year>
Reference-contexts: For more information on CLP see the surveys in <ref> [21, 51] </ref>, the proceedings of logic programming conferences and of recent workshops on the subject, e.g., [42]. In particular, the advances in CLP are very relevant for database applications (which brings us to the subject of this paper). One reason is the many connections between databases and logic programming.
Reference: 22. <author> A. Colmerauer. </author> <title> An Introduction to Prolog III. </title> <journal> CACM, </journal> <volume> 33:7:69-90, </volume> <year> 1990. </year>
Reference-contexts: Pioneering work in constraint programming goes back to the early 1960's, e.g., Sutherland's SKETCHPAD [67]. The theme has been investigated since the 1970's, e.g., in artificial intelligence [31, 54, 55, 66], in graphical-interfaces [10], and in logic programming languages <ref> [37, 22, 27] </ref>. The relevant literature and contributions are too large to attempt a survey. Instead we will limit our exposition to recent applications in databases. ? Research was supported by ONR grant N00014-91-J-4052 ARPA Order No. 8225. <p> Perhaps one of the most important advances in constraint programming in the 1980's has been the development of Constraint Logic Programming (CLP) as a general-purpose framework for computations, e.g., in CLP (&lt;) [37], in Prolog III <ref> [22] </ref>, and in CHIP [27, 72]. For more information on CLP see the surveys in [21, 51], the proceedings of logic programming conferences and of recent workshops on the subject, e.g., [42].
Reference: 23. <author> G.E. Collins. </author> <title> Quantifier Elimination for Real Closed Fields by Cylindrical Algebraic Decomposition. </title> <booktitle> Proc. 2nd GI conference on Automata Theory and Languages, </booktitle> <volume> LNCS 33, </volume> <pages> pp. 512-532, </pages> <publisher> Springer-Verlag, </publisher> <year> 1975. </year>
Reference-contexts: The technical tools for this integration were: data complexity [17, 73] from database theory, and quantifier elimination methods from mathematical logic <ref> [28, 29, 68, 23, 8, 48, 60] </ref>. More specifically, finite relations are generalized to finitely representable relations and appropriate algebras for their data manipulation can be developed in this framework. In many cases, the algebras have polynomial time data complexity. <p> A generalized database is a finite set of generalized relations. (3) The syntax of a CQL is the union of an existing database query language and a decidable logical theory. For example: Relational calculus [20] + the theory of real closed fields <ref> [68, 23, 8, 48, 60] </ref>; Relational calculus [20] + the theory of real (or Presburger) addition [29, 30, 9, 15]; Relational calculus [20] + the theory of discrete order with constants. <p> Let us now look at a fairly rich constraint theory. Relational calculus with real polynomial inequality constraints can be evaluated bottom-up in closed form and PTIME data complexity. This is a direct consequence of <ref> [23] </ref>. More recent results [8, 48, 60] place the data complexity in NC. The precise expressibility (in terms of data complexity within NC) for real polynomial constraints is still open.
Reference: 24. <author> D. Comer. </author> <title> The Ubiquitous B-Tree. </title> <journal> Computing Surveys, </journal> <volume> 11:2:121-137, </volume> <year> 1979. </year>
Reference-contexts: Without the ability to perform such searches relational databases on secondary storage would have been impractical. I/O efficient (i.e., logarithmic or constant) use of secondary storage is an additional requirement, beyond low data complexity, whose satisfaction greatly contributes to relational technology. B-trees and their variants B + -trees, <ref> [7, 24] </ref>, are examples of important data structures for implementing relational databases. In particular, let each secondary memory access transmit B units of data, let r be a relation with N tuples, and let us have a B + -tree on the attribute x of r.
Reference: 25. <author> S.S. Cosmadakis, G.M. </author> <title> Kuper Expressiveness of First-Order Constraint Languages. </title> <type> Manuscript, </type> <month> December </month> <year> 1993. </year>
Reference-contexts: The precise expressibility (in terms of data complexity within NC) for real polynomial constraints is still open. Clarifying the relationship with the data complexity of weaker theories involving addition and multiplication by constants is a topic of interest <ref> [25] </ref>. Unfortunately, arithmetic (even just integer order) with recursion easily leads to computability of all partial recursive functions. One implication is that there are qualitatively multiple ways of encoding computations in CLP (e.g., [26]. Sufficient conditions that allow closure under recursion are an interesting topic [61]. <p> Even for this theoretically simple case the expressive power is not fully understood <ref> [25] </ref>. What are the right linear programming algorithms for these CQLs? Both linear and integer programming with a fixed number of variables are relevant combinatorial problems in this context.
Reference: 26. <author> J. Cox, K. McAloon, C. Tretkoff. </author> <title> Computational Complexity and Constraint Logic Programming. </title> <journal> Annals of Math. and AI, </journal> <volume> 5 </volume> <pages> 163-190, </pages> <year> 1992. </year>
Reference-contexts: Unfortunately, arithmetic (even just integer order) with recursion easily leads to computability of all partial recursive functions. One implication is that there are qualitatively multiple ways of encoding computations in CLP (e.g., <ref> [26] </ref>. Sufficient conditions that allow closure under recursion are an interesting topic [61].
Reference: 27. <author> M. Dincbas, P. Van Hentenryck, H. Simonis, A. Aggoun, T. Graf, F. Berthier. </author> <title> The Constraint Logic Programming Language CHIP. </title> <booktitle> Proc. Fifth Generation Computer Systems, </booktitle> <address> Tokyo Japan, </address> <year> 1988. </year>
Reference-contexts: Pioneering work in constraint programming goes back to the early 1960's, e.g., Sutherland's SKETCHPAD [67]. The theme has been investigated since the 1970's, e.g., in artificial intelligence [31, 54, 55, 66], in graphical-interfaces [10], and in logic programming languages <ref> [37, 22, 27] </ref>. The relevant literature and contributions are too large to attempt a survey. Instead we will limit our exposition to recent applications in databases. ? Research was supported by ONR grant N00014-91-J-4052 ARPA Order No. 8225. <p> Perhaps one of the most important advances in constraint programming in the 1980's has been the development of Constraint Logic Programming (CLP) as a general-purpose framework for computations, e.g., in CLP (&lt;) [37], in Prolog III [22], and in CHIP <ref> [27, 72] </ref>. For more information on CLP see the surveys in [21, 51], the proceedings of logic programming conferences and of recent workshops on the subject, e.g., [42]. In particular, the advances in CLP are very relevant for database applications (which brings us to the subject of this paper).
Reference: 28. <author> J. Ferrante, J.R. Geiser. </author> <title> An Efficient Decision Procedure for the Theory of Rational Order. </title> <journal> Theoretical Computer Science, </journal> <volume> 4 </volume> <pages> 227-233, </pages> <year> 1977. </year>
Reference-contexts: The technical tools for this integration were: data complexity [17, 73] from database theory, and quantifier elimination methods from mathematical logic <ref> [28, 29, 68, 23, 8, 48, 60] </ref>. More specifically, finite relations are generalized to finitely representable relations and appropriate algebras for their data manipulation can be developed in this framework. In many cases, the algebras have polynomial time data complexity. <p> Inflationary Datalog : [3, 32, 47] + the theory of dense order with constants <ref> [28] </ref>; Inflationary Datalog : + the theory of equality on an infinite domain with constants. (4) The semantics of a CQL is based on that of the decidable logical theory, by interpreting database atoms as shorthands for formulas of the theory. <p> Constants, =, , and &lt; are interpreted respectively as elements, equality, the dense order, and the irreflexive dense order of D. For the first-order theory of dense order see <ref> [28] </ref> and for its data complexity (with and without recursion) see [41]. In this section we present a first-order algebra for dense order constraints, which is equivalent to the calculus of [41] and is simpler.
Reference: 29. <author> J. Ferrante, C. Rackoff. </author> <title> A Decision Procedure for the First Order Theory of Real Addition with Order. </title> <journal> SICOMP, </journal> <volume> 4:1:69-76, </volume> <year> 1975. </year>
Reference-contexts: The technical tools for this integration were: data complexity [17, 73] from database theory, and quantifier elimination methods from mathematical logic <ref> [28, 29, 68, 23, 8, 48, 60] </ref>. More specifically, finite relations are generalized to finitely representable relations and appropriate algebras for their data manipulation can be developed in this framework. In many cases, the algebras have polynomial time data complexity. <p> For example: Relational calculus [20] + the theory of real closed fields [68, 23, 8, 48, 60]; Relational calculus [20] + the theory of real (or Presburger) addition <ref> [29, 30, 9, 15] </ref>; Relational calculus [20] + the theory of discrete order with constants.
Reference: 30. <author> M.J. Fischer, M.O. Rabin. </author> <title> Super-Exponential Complexity of Presburger Arithmetic. </title> <booktitle> SIAM-AMS Proc. volume VII, </booktitle> <publisher> American Mathematical Society, </publisher> <year> 1974. </year>
Reference-contexts: In many cases, the algebras have polynomial time data complexity. This use of data complexity (a common tool for studying expressibility in finite model theory) distinguishes the CQL framework from arbitrary (and inherently exponential) theorem proving <ref> [30, 9, 15] </ref>. Example 1. Let us illustrate database querying and introduce some of its notation. The meaning and use is (or rather should be) intuitively obvious. For formal definitions we refer the reader to [40, 69]. <p> For example: Relational calculus [20] + the theory of real closed fields [68, 23, 8, 48, 60]; Relational calculus [20] + the theory of real (or Presburger) addition <ref> [29, 30, 9, 15] </ref>; Relational calculus [20] + the theory of discrete order with constants.
Reference: 31. <author> E. Freuder. </author> <title> Synthesizing Constraint Expressions. </title> <journal> CACM, </journal> <volume> 21:11, </volume> <year> 1978. </year>
Reference-contexts: Programming with constraints as primitives (or constraint programming) is appealing because constraints are the normal language of discourse for many high-level applications. Pioneering work in constraint programming goes back to the early 1960's, e.g., Sutherland's SKETCHPAD [67]. The theme has been investigated since the 1970's, e.g., in artificial intelligence <ref> [31, 54, 55, 66] </ref>, in graphical-interfaces [10], and in logic programming languages [37, 22, 27]. The relevant literature and contributions are too large to attempt a survey. Instead we will limit our exposition to recent applications in databases. ? Research was supported by ONR grant N00014-91-J-4052 ARPA Order No. 8225.
Reference: 32. <author> Y. Gurevich, S. Shelah. </author> <title> Fixed-Point Extensions of First-Order Logic. </title> <journal> Annals of Pure and Applied Logic, </journal> <volume> 32, </volume> <pages> 265-280, </pages> <year> 1986. </year>
Reference-contexts: For example: Relational calculus [20] + the theory of real closed fields [68, 23, 8, 48, 60]; Relational calculus [20] + the theory of real (or Presburger) addition [29, 30, 9, 15]; Relational calculus [20] + the theory of discrete order with constants. Inflationary Datalog : <ref> [3, 32, 47] </ref> + the theory of dense order with constants [28]; Inflationary Datalog : + the theory of equality on an infinite domain with constants. (4) The semantics of a CQL is based on that of the decidable logical theory, by interpreting database atoms as shorthands for formulas of the
Reference: 33. <author> M.R. Hansen, B.S. Hansen, P. Lucas, P. van Emde Boas. </author> <title> Integrating Relational Databases and Constraint Languages. </title> <booktitle> Computer Languages, </booktitle> <address> 14:2:63-82, </address> <year> 1989. </year>
Reference-contexts: Constraint programming is a high-level programming style, which is often supported by integrity constraint maintenance algorithms. 2 The CQL framework of [41] provided a unified view of some previous database research: for example, on the power of constraints for the implicit specification of temporal data [19], for extending relational algebra <ref> [33, 46] </ref>, for magic set evaluation [58], and for logic program analysis [13]. CQLs also extend the approach to safe queries of [4, 35, 44, 58]. The example CQLs of [41] are applicable to spatial databases, where dense order is present.
Reference: 34. <author> R. Helm, K. Marriott, M. Odersky. </author> <title> Constraint-based Query Optimization for Spatial Databases. </title> <booktitle> Proc. 10th ACM PODS, </booktitle> <pages> 181-191, </pages> <year> 1991. </year>
Reference-contexts: How do various optimization methods (such as selection propagation, join ordering and other algebraic transformations, magic sets etc) combine with CQLs? This would involve extending [58]. For some recent research in this direction we refer to <ref> [34, 52, 56, 65, 12] </ref>. Constraint use for database logic program analysis is also relevant here, e.g., [13, 14, 70, 71]. (3) We have addressed the spatial applications of CQLs. Constraints offer useful approaches to temporal databases as well.
Reference: 35. <author> R. Hull, J. Su. </author> <title> Domain Independence and the Relational Calculus. </title> <type> Technical Report 88-64, </type> <institution> University of Southern California. </institution>
Reference-contexts: CQLs also extend the approach to safe queries of <ref> [4, 35, 44, 58] </ref>. The example CQLs of [41] are applicable to spatial databases, where dense order is present. Temporal databases require the development of analogous frameworks for the theory of discrete order with constants see [39].
Reference: 36. <author> N. Immerman. </author> <title> Relational Queries Computable in Polynomial Time. </title> <journal> Information and Control, </journal> <volume> 68 </volume> <pages> 86-104, </pages> <year> 1986. </year>
Reference-contexts: It corresponds nicely to the intuition that the database size is much larger than the query program size. It seems reasonable to limit computations to efficient ones, i.e., PTIME manipulations of the data. There are characterizations of PTIME <ref> [36, 73] </ref> using Datalog : on finite, ordered structures. So in terms of expressibility , Datalog : would suffice. However, various other CQLs allow for more "natural" and "flexible" expression of queries. 3.1 Data Complexity A query Q has data complexity in PTIME (resp. <p> Polynomial Dense Order Equality Relational Calculus NC AC 0 AC 0 Datalog : Not closed =PTIME PTIME In [41] it was shown that relational calculus (Inflationary Datalog : ) with dense order constraints has LOGSPACE (PTIME) data complexity. Also, by a slight modification of <ref> [36, 73] </ref> Inflationary Datalog : with dense linear order expresses exactly PTIME (this is the = in the table above). It is possible to strengthen the LOGSPACE bounds to uniform AC 0 , using random-access Alternating TMs [5, 16] with a fixed number of alternations and a logarithmic time bound.
Reference: 37. <author> J. Jaffar, J.L. Lassez. </author> <title> Constraint Logic Programming. </title> <booktitle> Proc. 14th ACM POPL, </booktitle> <pages> 111-119, </pages> <year> 1987. </year>
Reference-contexts: Pioneering work in constraint programming goes back to the early 1960's, e.g., Sutherland's SKETCHPAD [67]. The theme has been investigated since the 1970's, e.g., in artificial intelligence [31, 54, 55, 66], in graphical-interfaces [10], and in logic programming languages <ref> [37, 22, 27] </ref>. The relevant literature and contributions are too large to attempt a survey. Instead we will limit our exposition to recent applications in databases. ? Research was supported by ONR grant N00014-91-J-4052 ARPA Order No. 8225. <p> Perhaps one of the most important advances in constraint programming in the 1980's has been the development of Constraint Logic Programming (CLP) as a general-purpose framework for computations, e.g., in CLP (&lt;) <ref> [37] </ref>, in Prolog III [22], and in CHIP [27, 72]. For more information on CLP see the surveys in [21, 51], the proceedings of logic programming conferences and of recent workshops on the subject, e.g., [42].
Reference: 38. <author> D.S. Johnson. </author> <title> A Catalogue of Complexity Classes. </title> <note> Handbook of Theoretical Computer Science, Vol. A, chapter 2, </note> <editor> (J. van Leeuwen editor), </editor> <publisher> North-Holland, </publisher> <year> 1990. </year>
Reference-contexts: By fixing the program size and letting the database grow, one can prove that the evaluation can be performed in PTIME or in NC or in LOGSPACE, depending on the constraints considered (for the various complexity classes see <ref> [38] </ref>). 1.4 Languages, efficiency, efficiency, : : : In the remainder of this paper we explore CQLs with an emphasis on quantifying language efficiency. In Section 2, we present an algebra for dense order constraints (due to Goldin) which is simpler to evaluate than the calculus described in [41]. <p> LOGSPACE, NC) if there is a TM (resp. TM, PRAM) which given input generalized relations d produces some generalized relation representing the output of Q (d) and uses polynomial time (resp. logarithmic space on the work tape, polynomial number of processors running in polylogarithmic parallel time). See <ref> [38] </ref> for definitions of TMs and PRAMs. We assume a standard binary encoding of generalized relations.
Reference: 39. <author> F. Kabanza, J-M. Stevenne, P. Wolper. </author> <title> Handling Infinite Temporal Data. </title> <booktitle> Proc. 9th ACM PODS, </booktitle> <pages> 392-403, </pages> <year> 1990. </year>
Reference-contexts: CQLs also extend the approach to safe queries of [4, 35, 44, 58]. The example CQLs of [41] are applicable to spatial databases, where dense order is present. Temporal databases require the development of analogous frameworks for the theory of discrete order with constants see <ref> [39] </ref>. Complete vs Partial Information: The key concept in CQL, illustrated in the next subsection is that constraints describe point-sets, such that all their points are in the database. With the appropriate constraint theory these point-sets are accurate (and perhaps the most intuitive) representations of spatial objects.
Reference: 40. <author> P.C. Kanellakis. </author> <title> Elements of Relational Database Theory. </title> <booktitle> Handbook of Theoretical Computer Science, </booktitle> <volume> Vol. B, chapter 17, </volume> <editor> (J. van Leeuwen editor), </editor> <publisher> North-Holland, </publisher> <year> 1990. </year>
Reference-contexts: Example 1. Let us illustrate database querying and introduce some of its notation. The meaning and use is (or rather should be) intuitively obvious. For formal definitions we refer the reader to <ref> [40, 69] </ref>. To see that constraints should be part of any database query language consider an example from [41]. <p> For efficiency reasons we require that these constraints be quantifier-free, just like the CLP axioms are quantifier-free. The [41] framework is thus one of complete information. The problem of managing partial information in databases has received a fair amount of attention, see <ref> [40] </ref> for pointers to the database literature. For example, formulas with variables called null-values can be thought of as formulas representing many possible states (of which one is true). They would correspond to constraints that have existential quantifiers. <p> As in Codd's relational algebra <ref> [20, 40] </ref>, we will define basic algebraic operations projection (), selection (&), natural join (1), union ([), difference (), and renaming (%), which map one or more generalized relations to a new generalized relation. Algebraic queries over generalized databases are composed of these basic operations. <p> has the following closure property: if r 0 = OP (r 1 ; : : : ; r n ), then (r 0 ) = OP ((r 1 ); : : : ; (r n )), where OP is the operation of the same name in the relational algebra in <ref> [40] </ref>, and is defined in Definition 8. Remark: In our definitions of operators, we use the notation ff (r) for the variables of a generalized relation r.
Reference: 41. <author> P. C. Kanellakis, G. M. Kuper, P. Z. Revesz. </author> <title> Constraint Query Languages. </title> <booktitle> Proc. 9th ACM PODS, </booktitle> <pages> 299-313, </pages> <year> 1990. </year> <note> Full version available as Brown Univ. Tech. Rep. CS-92-50. To appear in JCSS. </note>
Reference-contexts: Unfortunately, the bottom-up and set-at-a-time style of evaluation emphasized in relational databases, and more recently in knowledge bases, seems to contradict the top-down, depth-first intuition behind CLP. The main contribution of the Constraint Query Language (CQL) framework in <ref> [41] </ref> was to demonstrate that it is possible to bridge the gap between: bottom-up, efficient, declarative database programming and efficient constraint solving. <p> Let us illustrate database querying and introduce some of its notation. The meaning and use is (or rather should be) intuitively obvious. For formal definitions we refer the reader to [40, 69]. To see that constraints should be part of any database query language consider an example from <ref> [41] </ref>. This is a query program with Expenses, Savings and Income input relations, Balanced output relation, and a single linear equation constraint: x is user-id, f is amount spent for food, r for rent, m for miscellaneous, s for transfer to savings, w for wages, and i for interest. <p> Linear equations, although quite simple theoretically, can be interesting from a practical point of view. Also, as illustrated in <ref> [41] </ref>, the simple case of linear equations can be related to the relational database theory theme of query homomorphisms. 2 One point of the above example is that constraints integrate naturally in the core database query syntax (called tableaux in the relational databases of the 1970's and nonrecursive Datalog in the <p> Constraint programming is a high-level programming style, which is often supported by integrity constraint maintenance algorithms. 2 The CQL framework of <ref> [41] </ref> provided a unified view of some previous database research: for example, on the power of constraints for the implicit specification of temporal data [19], for extending relational algebra [33, 46], for magic set evaluation [58], and for logic program analysis [13]. <p> CQLs also extend the approach to safe queries of [4, 35, 44, 58]. The example CQLs of <ref> [41] </ref> are applicable to spatial databases, where dense order is present. Temporal databases require the development of analogous frameworks for the theory of discrete order with constants see [39]. <p> With the appropriate constraint theory these point-sets are accurate (and perhaps the most intuitive) representations of spatial objects. For efficiency reasons we require that these constraints be quantifier-free, just like the CLP axioms are quantifier-free. The <ref> [41] </ref> framework is thus one of complete information. The problem of managing partial information in databases has received a fair amount of attention, see [40] for pointers to the database literature. <p> Reachable (n 1 ; n 2 ) :| Reachable (n 1 ; n 3 ); Reachable (n 3 ; n 2 ) Reachable (n 1 ; n 2 ) :| RC (n 1 ; x; y); RC (n 2 ; x; y) As shown in <ref> [41] </ref> recursive Datalog with dense order is evaluable in polynomial time. The algorithm used there was a bottom-up version of CLP (&lt;). In general, more complex constraints and recursion lead to languages that can compute all partial recursive functions. <p> A very important optimization involves indexing particular variables in the generalized tuples. In the above examples such indexing would correspond to I/O efficient processing of the projections of the rectangles on the x and y dimensions. More specifically, as shown in (the journal version of) <ref> [41] </ref>, if in a CQL the projection of any generalized tuple on x is an interval, then the problem of 1-dimensional searching on x in the constraint data model is a special case of 2-dimensional searching in the relational data model. <p> We will treat this optimization in detail in Section 4 of this paper because we believe that it is the most practical one for spatial databases. Fortunately, current spatial database access methods are applicable to indexing in the CQL framework. Let us now describe this framework as presented in <ref> [41] </ref>. 1.3 The CQL Framework (1) A generalized k-tuple is a quantifier-free conjunction of constraints on k variables, which range over a set D. There are many kinds of generalized tuples depending on the kind of constraints used. In all cases equality constraints among individual variables and constants are allowed. <p> In Section 2, we present an algebra for dense order constraints (due to Goldin) which is simpler to evaluate than the calculus described in <ref> [41] </ref>. In Section 3, we sharpen some of the related data complexity bounds and comment on the current state-of-the-art of data complexity analysis. We also observe that complex object data types can easily be added to the CQL framework. <p> Constants, =, , and &lt; are interpreted respectively as elements, equality, the dense order, and the irreflexive dense order of D. For the first-order theory of dense order see [28] and for its data complexity (with and without recursion) see <ref> [41] </ref>. In this section we present a first-order algebra for dense order constraints, which is equivalent to the calculus of [41] and is simpler. We first assume that the generalized tuples have a specific form, beyond being conjunctions of constraints, this is Definition 1. <p> For the first-order theory of dense order see [28] and for its data complexity (with and without recursion) see <ref> [41] </ref>. In this section we present a first-order algebra for dense order constraints, which is equivalent to the calculus of [41] and is simpler. We first assume that the generalized tuples have a specific form, beyond being conjunctions of constraints, this is Definition 1. It is easy to see that any conjuction of constraints can be transformed into a union of such generalized tuples. <p> A generalized database is a finite set of generalized relations. 2 To conclude this subsection, we would like to compare canonical tuples with the different tuple construct used in <ref> [41] </ref>, called r-configurations. <p> The time of checking whether a generalized tuple is an r-configuration is not constant in the size of D , whereas it is constant for checking whether a tuple is canonical. Therefore an advantage of the canonical tuples here over the r-configurations of <ref> [41] </ref> is that inserts are more efficient. <p> Let r 0 = % x i jy (r). Then, (r 0 ) = % x i jy ((r)). Let us now consider the first-order calculus CQL of <ref> [41] </ref> for dense order. This is relational calculus combined with the decidable theory of dense order with constants. Every query can be expressed semantically as a relational calculus or algebra query on unrestricted (finite or infinite) relations over D n . <p> The LOGSPACE data complexity analysis is from [17]. In the following table we list some theories with upper bounds on their data complexities. Polynomial Dense Order Equality Relational Calculus NC AC 0 AC 0 Datalog : Not closed =PTIME PTIME In <ref> [41] </ref> it was shown that relational calculus (Inflationary Datalog : ) with dense order constraints has LOGSPACE (PTIME) data complexity. Also, by a slight modification of [36, 73] Inflationary Datalog : with dense linear order expresses exactly PTIME (this is the = in the table above).
Reference: 42. <editor> P.C. Kanellakis, J.L. Lassez, V.J. Saraswat. </editor> <booktitle> Proceedings of the Workshop on the Principles and Practice of Constraint Programming (PPCP93). </booktitle> <address> Newport RI, </address> <month> April </month> <year> 1993. </year> <note> Preliminary version available via anonymous ftp from wilma.cs.brown.edu (128.148.33.66) in the directory /pub/ppcp93. To appear from MIT Press. </note>
Reference-contexts: For more information on CLP see the surveys in [21, 51], the proceedings of logic programming conferences and of recent workshops on the subject, e.g., <ref> [42] </ref>. In particular, the advances in CLP are very relevant for database applications (which brings us to the subject of this paper). One reason is the many connections between databases and logic programming. Starting with the Japanese 5th Generation Project, these connections were explored in depth during the last decade.
Reference: 43. <author> P. C. Kanellakis, S. Ramaswamy, D. E. Vengroff, J. S. Vitter. </author> <title> Indexing for Data Models with Constraints and Classes. </title> <booktitle> Proc. 12th ACM PODS, </booktitle> <pages> 233-243, </pages> <year> 1993. </year>
Reference-contexts: Showing the relation between interval management and 2-dimensional range searching 4.3 Optimal Static Indexing for Constraints The first I/O optimal solution for the problem of static interval management in secondary memory was published in <ref> [43] </ref>. Optimal in-core dynamic interval management is one of the basic tools of computational geometry. However, I/O optimal solutions are non-trivial, even for the static case. Let us describe the relationship of interval management on secondary storage and 2-dimensional searching. <p> In fact, such two sided queries will always have their corner on the line X = Y . Such queries are called diagonal corner queries in <ref> [43] </ref>. An optimal solution for answering diagonal corner queries in secondary storage is presented in [43]. [43] presents a semi-dynamic data structure for this problem called the metablock tree that has optimal query I/O time O (log B N +K=B), uses optimal storage O (N=B). <p> In fact, such two sided queries will always have their corner on the line X = Y . Such queries are called diagonal corner queries in <ref> [43] </ref>. An optimal solution for answering diagonal corner queries in secondary storage is presented in [43]. [43] presents a semi-dynamic data structure for this problem called the metablock tree that has optimal query I/O time O (log B N +K=B), uses optimal storage O (N=B). <p> In fact, such two sided queries will always have their corner on the line X = Y . Such queries are called diagonal corner queries in <ref> [43] </ref>. An optimal solution for answering diagonal corner queries in secondary storage is presented in [43]. [43] presents a semi-dynamic data structure for this problem called the metablock tree that has optimal query I/O time O (log B N +K=B), uses optimal storage O (N=B). <p> Existing spatial data structures solve this problem with reasonable efficiency, but there is much room for improvement. While <ref> [43] </ref> and [59] represent advances in this context, the truly elegant and seemingly difficult problem remains open.
Reference: 44. <author> M. Kifer. </author> <title> On Safety, Domain Independence, and Capturability of Database Queries. </title> <booktitle> Proc. International Conference on Databases and Knowledge Bases, </booktitle> <address> Jerusalem Is-rael, </address> <year> 1988. </year>
Reference-contexts: CQLs also extend the approach to safe queries of <ref> [4, 35, 44, 58] </ref>. The example CQLs of [41] are applicable to spatial databases, where dense order is present. Temporal databases require the development of analogous frameworks for the theory of discrete order with constants see [39].
Reference: 45. <author> A. Klug. </author> <title> Equivalence of Relational Algebra and Relational Calculus Query Languages having Aggregate Functions. </title> <journal> JACM, </journal> <volume> 29:3:699-717, </volume> <year> 1982. </year>
Reference-contexts: It is useful because it allows posing queries about the representation itself and not only about the infinite relations represented. There are however some subtle issues that should be researched further. Aggregates: The first important extension involves aggregate operations (e.g., maximum, average etc), see <ref> [45] </ref>. Introducing aggregates in a CQL is identical with the relational data model if an attribute ranges over a finite set. Many aggregate primitives have low data complexity [5]. <p> For example, null values can be introduced with existential quantification in constraints. Finite complex objects [1, 2] and aggregation <ref> [45] </ref> over finite sets can co-exist with infinite relations.
Reference: 46. <author> A. Klug. </author> <title> On Conjunctive Queries Containing Inequalities. </title> <journal> JACM, </journal> <volume> 35:1:146-160, </volume> <year> 1988. </year>
Reference-contexts: Constraint programming is a high-level programming style, which is often supported by integrity constraint maintenance algorithms. 2 The CQL framework of [41] provided a unified view of some previous database research: for example, on the power of constraints for the implicit specification of temporal data [19], for extending relational algebra <ref> [33, 46] </ref>, for magic set evaluation [58], and for logic program analysis [13]. CQLs also extend the approach to safe queries of [4, 35, 44, 58]. The example CQLs of [41] are applicable to spatial databases, where dense order is present.
Reference: 47. <author> P. Kolaitis, C.H. Papadimitriou. </author> <title> Why not Negation by Fixpoint? Proc. </title> <booktitle> 7th ACM PODS, </booktitle> <pages> 231-239, </pages> <year> 1988. </year>
Reference-contexts: For example: Relational calculus [20] + the theory of real closed fields [68, 23, 8, 48, 60]; Relational calculus [20] + the theory of real (or Presburger) addition [29, 30, 9, 15]; Relational calculus [20] + the theory of discrete order with constants. Inflationary Datalog : <ref> [3, 32, 47] </ref> + the theory of dense order with constants [28]; Inflationary Datalog : + the theory of equality on an infinite domain with constants. (4) The semantics of a CQL is based on that of the decidable logical theory, by interpreting database atoms as shorthands for formulas of the
Reference: 48. <author> D. Kozen, C. Yap. </author> <title> Algebraic Cell Decomposition in NC. </title> <booktitle> Proc. 26th IEEE FOCS, </booktitle> <pages> 515-521, </pages> <year> 1985. </year>
Reference-contexts: The technical tools for this integration were: data complexity [17, 73] from database theory, and quantifier elimination methods from mathematical logic <ref> [28, 29, 68, 23, 8, 48, 60] </ref>. More specifically, finite relations are generalized to finitely representable relations and appropriate algebras for their data manipulation can be developed in this framework. In many cases, the algebras have polynomial time data complexity. <p> A generalized database is a finite set of generalized relations. (3) The syntax of a CQL is the union of an existing database query language and a decidable logical theory. For example: Relational calculus [20] + the theory of real closed fields <ref> [68, 23, 8, 48, 60] </ref>; Relational calculus [20] + the theory of real (or Presburger) addition [29, 30, 9, 15]; Relational calculus [20] + the theory of discrete order with constants. <p> Let us now look at a fairly rich constraint theory. Relational calculus with real polynomial inequality constraints can be evaluated bottom-up in closed form and PTIME data complexity. This is a direct consequence of [23]. More recent results <ref> [8, 48, 60] </ref> place the data complexity in NC. The precise expressibility (in terms of data complexity within NC) for real polynomial constraints is still open. Clarifying the relationship with the data complexity of weaker theories involving addition and multiplication by constants is a topic of interest [25]. <p> How can recursion be combined with linear constraints in a safe fashion? (6) The technology of algorithms for logical theories is still rather complex, but much progress has been accomplished in recent years. For example, see <ref> [8, 48, 60] </ref> for the state-of-the-art in real closed fields.
Reference: 49. <author> M. Koubarakis. </author> <title> Foundations of Temporal Constraint Databases. </title> <type> PhD Thesis. </type> <institution> Nat. Tech. Univ. of Athens and Imperial College. </institution> <year> 1993. </year>
Reference-contexts: The subject of temporal constraints has also been addressed extensively in the artificial intelligence literature (which we unfortunately do not have the space or expertise to survey here). For some recent work that connects CQLs to artificial intelligence approaches see <ref> [49] </ref>. (4) As we argued in this paper, extensions to the relational model, involving partial information and complex object data types, can also be applied to CQLs. For example, null values can be introduced with existential quantification in constraints.
Reference: 50. <author> G.M. Kuper. </author> <title> Aggregation in Constraint Databases. </title> <booktitle> in [42]. </booktitle>
Reference-contexts: Many aggregate primitives have low data complexity [5]. Introducing aggregates in a CQL for attributes ranging over an infinite set is harder, since it typically involves integration, and is a topic of current research <ref> [50] </ref>. Complex Objects: The second extension involves complex objects. As described in [1, 2] complex objects are built using tuple and finite-set data type constructors. Generalized tuples are tuple constructors, but they also have some of the properties of finite-set constructors. This subtelty is best illustrated by an example. <p> Finite complex objects [1, 2] and aggregation [45] over finite sets can co-exist with infinite relations. Are there more subtle ways of adding these extensions to CQLs? For example, adding aggregation operations over infinite sets is motivated by querying about area size and is a challenging problem <ref> [50] </ref>. (5) Linear constraint databases [11] are among the most applicable CQLs, and will certainly be among the first to be implemented. Even for this theoretically simple case the expressive power is not fully understood [25].
Reference: 51. <author> W. Leler. </author> <title> Constraint Programming Languages. </title> <publisher> Addison Wesley, </publisher> <year> 1987. </year>
Reference-contexts: For more information on CLP see the surveys in <ref> [21, 51] </ref>, the proceedings of logic programming conferences and of recent workshops on the subject, e.g., [42]. In particular, the advances in CLP are very relevant for database applications (which brings us to the subject of this paper). One reason is the many connections between databases and logic programming.
Reference: 52. <author> A. Levy, Y. Sagiv. </author> <title> Constraints and Redundancy in Datalog. </title> <booktitle> Proc. 11th ACM PODS, </booktitle> <pages> 67-81, </pages> <year> 1992. </year>
Reference-contexts: How do various optimization methods (such as selection propagation, join ordering and other algebraic transformations, magic sets etc) combine with CQLs? This would involve extending [58]. For some recent research in this direction we refer to <ref> [34, 52, 56, 65, 12] </ref>. Constraint use for database logic program analysis is also relevant here, e.g., [13, 14, 70, 71]. (3) We have addressed the spatial applications of CQLs. Constraints offer useful approaches to temporal databases as well.
Reference: 53. <author> E. McCreight. </author> <title> Priority Search Trees. </title> <journal> SIAM J. Computing, </journal> <volume> 14 </volume> <pages> 257-276, </pages> <year> 1985. </year>
Reference-contexts: This is a well-known problem with many elegant solutions from computational geometry [57]. It is a special case of 2-dimensional searching in relational databases, called 1.5-dimensional searching in <ref> [53] </ref>. For example, the priority search trees of [53] are a linear space data structure with logarithmic-time update and search algorithms for in-core processing. Grid-files, R-trees, quad-trees etc, have all been used for solving this problem with good secondary memory access performance. <p> This is a well-known problem with many elegant solutions from computational geometry [57]. It is a special case of 2-dimensional searching in relational databases, called 1.5-dimensional searching in <ref> [53] </ref>. For example, the priority search trees of [53] are a linear space data structure with logarithmic-time update and search algorithms for in-core processing. Grid-files, R-trees, quad-trees etc, have all been used for solving this problem with good secondary memory access performance. In summary: generalized 1-dimensional indexing is dynamic interval management on secondary storage.
Reference: 54. <author> A.K. Mackworth. </author> <title> Consistency in Networks of Relations. </title> <booktitle> AI, </booktitle> <address> 8:1, </address> <year> 1977. </year>
Reference-contexts: Programming with constraints as primitives (or constraint programming) is appealing because constraints are the normal language of discourse for many high-level applications. Pioneering work in constraint programming goes back to the early 1960's, e.g., Sutherland's SKETCHPAD [67]. The theme has been investigated since the 1970's, e.g., in artificial intelligence <ref> [31, 54, 55, 66] </ref>, in graphical-interfaces [10], and in logic programming languages [37, 22, 27]. The relevant literature and contributions are too large to attempt a survey. Instead we will limit our exposition to recent applications in databases. ? Research was supported by ONR grant N00014-91-J-4052 ARPA Order No. 8225.
Reference: 55. <author> U. Montanari. </author> <title> Networks of Constraints: Fundamental Properties and Application to Picture Processing. </title> <journal> Information Science, </journal> <volume> 7, </volume> <year> 1974. </year>
Reference-contexts: Programming with constraints as primitives (or constraint programming) is appealing because constraints are the normal language of discourse for many high-level applications. Pioneering work in constraint programming goes back to the early 1960's, e.g., Sutherland's SKETCHPAD [67]. The theme has been investigated since the 1970's, e.g., in artificial intelligence <ref> [31, 54, 55, 66] </ref>, in graphical-interfaces [10], and in logic programming languages [37, 22, 27]. The relevant literature and contributions are too large to attempt a survey. Instead we will limit our exposition to recent applications in databases. ? Research was supported by ONR grant N00014-91-J-4052 ARPA Order No. 8225.
Reference: 56. <author> I. S. Mumick, S. J. Finkelstein, H. Pirahesh, R. Ramakrishnan. </author> <title> Magic Conditions. </title> <booktitle> Proc. 9th ACM PODS, </booktitle> <pages> 314-330, </pages> <year> 1990. </year>
Reference-contexts: How do various optimization methods (such as selection propagation, join ordering and other algebraic transformations, magic sets etc) combine with CQLs? This would involve extending [58]. For some recent research in this direction we refer to <ref> [34, 52, 56, 65, 12] </ref>. Constraint use for database logic program analysis is also relevant here, e.g., [13, 14, 70, 71]. (3) We have addressed the spatial applications of CQLs. Constraints offer useful approaches to temporal databases as well.
Reference: 57. <author> F.P. Preparata, M.I. Shamos. </author> <title> Computational Geometry: An Introduction. </title> <publisher> Springer-Verlag, </publisher> <year> 1985. </year>
Reference-contexts: Example 2. Let us try to illustrate these points (1-3) with an example. A very common task from computational geometry and spatial databases is the problem of computing all rectangle intersections <ref> [57, 63] </ref>. The database consists of a set of rectangles in the plane (the four rectangles of Figure 1) and we want to compute all pairs of distinct intersecting rectangles. <p> However, one could limit recursion to finite domains as in this example, where recursion happens to be over the finite set of rectangle names. 2 The above examples may be complemented with many other computational geometry tasks, such as computing convex hulls and Voronoi diagrams <ref> [57] </ref>. In these examples the typical computational geometry input of "N arbitrary points" becomes an input database of size N and the task specification becomes a fixed size CQL program. Most natural computational geometry tasks are expressible declaratively using CQLs that combine first-order logic with simple arithmetic constraints. <p> The use of generalized 1-dimensional indexes reduces redundancy of representation and transforms 1-dimensional searching on generalized database attribute x into the problem of dynamic interval management. This is a well-known problem with many elegant solutions from computational geometry <ref> [57] </ref>. It is a special case of 2-dimensional searching in relational databases, called 1.5-dimensional searching in [53]. For example, the priority search trees of [53] are a linear space data structure with logarithmic-time update and search algorithms for in-core processing.
Reference: 58. <author> R. Ramakrishnan. </author> <title> Magic Templates: A Spellbinding Approach to Logic Programs. </title> <booktitle> Proc. 5th International Conference on Logic Programming, </booktitle> <pages> 141-159, </pages> <year> 1988. </year>
Reference-contexts: style, which is often supported by integrity constraint maintenance algorithms. 2 The CQL framework of [41] provided a unified view of some previous database research: for example, on the power of constraints for the implicit specification of temporal data [19], for extending relational algebra [33, 46], for magic set evaluation <ref> [58] </ref>, and for logic program analysis [13]. CQLs also extend the approach to safe queries of [4, 35, 44, 58]. The example CQLs of [41] are applicable to spatial databases, where dense order is present. <p> CQLs also extend the approach to safe queries of <ref> [4, 35, 44, 58] </ref>. The example CQLs of [41] are applicable to spatial databases, where dense order is present. Temporal databases require the development of analogous frameworks for the theory of discrete order with constants see [39]. <p> How do various optimization methods (such as selection propagation, join ordering and other algebraic transformations, magic sets etc) combine with CQLs? This would involve extending <ref> [58] </ref>. For some recent research in this direction we refer to [34, 52, 56, 65, 12]. Constraint use for database logic program analysis is also relevant here, e.g., [13, 14, 70, 71]. (3) We have addressed the spatial applications of CQLs. Constraints offer useful approaches to temporal databases as well.
Reference: 59. <author> S. Ramaswamy, S. Subramanian. </author> <title> Path Caching: A Technique for Optimal External Searching. </title> <note> Manuscript submitted for publication. </note>
Reference-contexts: The metablock data structure also allows inserts in O (log B N + (log 2 B N )=B) amortized I/O time; it is fairly involved and does not allow data points to be deleted. Space-time tradeoffs for this and other related 2-dimensional range searching problems are examined in <ref> [59] </ref>. In this paper it is shown that many elegant data structures like the priority search tree, segment tree and the interval tree|all of which have been used for interval management in-core |can be im plemented in secondary memory with small space overheads. <p> Existing spatial data structures solve this problem with reasonable efficiency, but there is much room for improvement. While [43] and <ref> [59] </ref> represent advances in this context, the truly elegant and seemingly difficult problem remains open.
Reference: 60. <author> J. Renegar. </author> <title> On the Computational Complexity and Geometry of the First-order Theory of the Reals: Parts I-III. </title> <journal> Journal of Symbolic Computation, </journal> <volume> 13 </volume> <pages> 255-352, </pages> <year> 1992. </year>
Reference-contexts: The technical tools for this integration were: data complexity [17, 73] from database theory, and quantifier elimination methods from mathematical logic <ref> [28, 29, 68, 23, 8, 48, 60] </ref>. More specifically, finite relations are generalized to finitely representable relations and appropriate algebras for their data manipulation can be developed in this framework. In many cases, the algebras have polynomial time data complexity. <p> A generalized database is a finite set of generalized relations. (3) The syntax of a CQL is the union of an existing database query language and a decidable logical theory. For example: Relational calculus [20] + the theory of real closed fields <ref> [68, 23, 8, 48, 60] </ref>; Relational calculus [20] + the theory of real (or Presburger) addition [29, 30, 9, 15]; Relational calculus [20] + the theory of discrete order with constants. <p> Let us now look at a fairly rich constraint theory. Relational calculus with real polynomial inequality constraints can be evaluated bottom-up in closed form and PTIME data complexity. This is a direct consequence of [23]. More recent results <ref> [8, 48, 60] </ref> place the data complexity in NC. The precise expressibility (in terms of data complexity within NC) for real polynomial constraints is still open. Clarifying the relationship with the data complexity of weaker theories involving addition and multiplication by constants is a topic of interest [25]. <p> How can recursion be combined with linear constraints in a safe fashion? (6) The technology of algorithms for logical theories is still rather complex, but much progress has been accomplished in recent years. For example, see <ref> [8, 48, 60] </ref> for the state-of-the-art in real closed fields.
Reference: 61. <author> P.Z. Revesz. </author> <title> A Closed Form for Datalog Queries with Integer Order. </title> <booktitle> Proc. 3rd International Conference on Database Theory, </booktitle> <year> 1990, </year> <note> (to appear in TCS). </note>
Reference-contexts: Unfortunately, arithmetic (even just integer order) with recursion easily leads to computability of all partial recursive functions. One implication is that there are qualitatively multiple ways of encoding computations in CLP (e.g., [26]. Sufficient conditions that allow closure under recursion are an interesting topic <ref> [61] </ref>. Note that, non-closure is very easy to show: Let be the query program that consists of the rules S (x; y) :| R (x; y) and S (x; y) :| R (x; z); S (z; y) (i.e., S is the transitive closure of R). <p> Constraint use for database logic program analysis is also relevant here, e.g., [13, 14, 70, 71]. (3) We have addressed the spatial applications of CQLs. Constraints offer useful approaches to temporal databases as well. For recent developments in temporal databases we refer to <ref> [6, 18, 61] </ref>. The subject of temporal constraints has also been addressed extensively in the artificial intelligence literature (which we unfortunately do not have the space or expertise to survey here).
Reference: 62. <author> H. Samet. </author> <title> Applications of Spatial Data Structures: Computer Graphics, Image Processing, and GIS. </title> <publisher> Addison-Wesley, </publisher> <address> Reading MA, </address> <year> 1990. </year>
Reference-contexts: the relational data model to spatial data models. (1) The language framework preserves the declar ative style and the efficiency of relational database languages. (2) The possible applications of constraint databases include both data processing and numerical processing of spatial data. (3) The implementation technology of spatial access methods (see <ref> [62, 63] </ref>) naturally matches the new formalism. Example 2. Let us try to illustrate these points (1-3) with an example. A very common task from computational geometry and spatial databases is the problem of computing all rectangle intersections [57, 63]. <p> It is a central problem in spatial databases for which there are many solutions with good secondary memory access performance, e.g., grid-files, quad-trees, R-trees, hB-trees, k-d-B-trees etc (see the surveys <ref> [62, 63] </ref>). 4.2 Indexing Constraint Databases For generalized databases we can define an analogous problem of 1-dimensional searching on generalized database attribute x using the operations: (i) Find a generalized database that represents all tuples of the input generalized database such that their x attribute satisfies (a 1 x a 2
Reference: 63. <author> H. Samet. </author> <title> The Design and Analysis of Spatial Data Structures. </title> <publisher> Addison-Wesley, </publisher> <address> Reading MA, </address> <year> 1990. </year>
Reference-contexts: the relational data model to spatial data models. (1) The language framework preserves the declar ative style and the efficiency of relational database languages. (2) The possible applications of constraint databases include both data processing and numerical processing of spatial data. (3) The implementation technology of spatial access methods (see <ref> [62, 63] </ref>) naturally matches the new formalism. Example 2. Let us try to illustrate these points (1-3) with an example. A very common task from computational geometry and spatial databases is the problem of computing all rectangle intersections [57, 63]. <p> Example 2. Let us try to illustrate these points (1-3) with an example. A very common task from computational geometry and spatial databases is the problem of computing all rectangle intersections <ref> [57, 63] </ref>. The database consists of a set of rectangles in the plane (the four rectangles of Figure 1) and we want to compute all pairs of distinct intersecting rectangles. <p> It is a central problem in spatial databases for which there are many solutions with good secondary memory access performance, e.g., grid-files, quad-trees, R-trees, hB-trees, k-d-B-trees etc (see the surveys <ref> [62, 63] </ref>). 4.2 Indexing Constraint Databases For generalized databases we can define an analogous problem of 1-dimensional searching on generalized database attribute x using the operations: (i) Find a generalized database that represents all tuples of the input generalized database such that their x attribute satisfies (a 1 x a 2
Reference: 64. <author> V.A. Saraswat. </author> <title> Concurrent Constraint Programming Languages. </title> <type> PhD thesis, </type> <institution> Carnegie Mellon University, </institution> <year> 1989. </year>
Reference-contexts: Constraint logic programming paradigms are currently attracting a great deal of attention in languages for operations research applications [72] and have also impacted the field of concurrent programming language design <ref> [64] </ref>. The use of constraints for operations research and for concurrency is sometimes semantically different from their use here. For example: Constraints can be used to represent the many possible states (of which one is true) of a set of concurrent processes.
Reference: 65. <author> D. Srivastava, R. Ramakrishnan. </author> <title> Pushing Constraint Selections. </title> <booktitle> Proc. 11th ACM PODS, </booktitle> <pages> 301-316, </pages> <year> 1992. </year>
Reference-contexts: How do various optimization methods (such as selection propagation, join ordering and other algebraic transformations, magic sets etc) combine with CQLs? This would involve extending [58]. For some recent research in this direction we refer to <ref> [34, 52, 56, 65, 12] </ref>. Constraint use for database logic program analysis is also relevant here, e.g., [13, 14, 70, 71]. (3) We have addressed the spatial applications of CQLs. Constraints offer useful approaches to temporal databases as well.
Reference: 66. <author> G.L. Steele. </author> <title> The Definition and Implementation of a Computer Programming Language Based on Constraints. </title> <type> Ph.D. thesis, </type> <institution> MIT, </institution> <address> AI-TR 595, </address> <year> 1980. </year>
Reference-contexts: Programming with constraints as primitives (or constraint programming) is appealing because constraints are the normal language of discourse for many high-level applications. Pioneering work in constraint programming goes back to the early 1960's, e.g., Sutherland's SKETCHPAD [67]. The theme has been investigated since the 1970's, e.g., in artificial intelligence <ref> [31, 54, 55, 66] </ref>, in graphical-interfaces [10], and in logic programming languages [37, 22, 27]. The relevant literature and contributions are too large to attempt a survey. Instead we will limit our exposition to recent applications in databases. ? Research was supported by ONR grant N00014-91-J-4052 ARPA Order No. 8225.
Reference: 67. <author> I.E. Sutherland. </author> <title> SKETCHPAD: A Man-Machine Graphical Communication System. </title> <publisher> Spartan Books, </publisher> <year> 1963. </year>
Reference-contexts: Programming with constraints as primitives (or constraint programming) is appealing because constraints are the normal language of discourse for many high-level applications. Pioneering work in constraint programming goes back to the early 1960's, e.g., Sutherland's SKETCHPAD <ref> [67] </ref>. The theme has been investigated since the 1970's, e.g., in artificial intelligence [31, 54, 55, 66], in graphical-interfaces [10], and in logic programming languages [37, 22, 27]. The relevant literature and contributions are too large to attempt a survey.
Reference: 68. <author> A. Tarski. </author> <title> A Decision Method for Elementary Algebra and Geometry. </title> <institution> University of California Press, Berkeley, California, </institution> <year> 1951. </year>
Reference-contexts: The technical tools for this integration were: data complexity [17, 73] from database theory, and quantifier elimination methods from mathematical logic <ref> [28, 29, 68, 23, 8, 48, 60] </ref>. More specifically, finite relations are generalized to finitely representable relations and appropriate algebras for their data manipulation can be developed in this framework. In many cases, the algebras have polynomial time data complexity. <p> A generalized database is a finite set of generalized relations. (3) The syntax of a CQL is the union of an existing database query language and a decidable logical theory. For example: Relational calculus [20] + the theory of real closed fields <ref> [68, 23, 8, 48, 60] </ref>; Relational calculus [20] + the theory of real (or Presburger) addition [29, 30, 9, 15]; Relational calculus [20] + the theory of discrete order with constants.
Reference: 69. <author> J.D. Ullman. </author> <title> Principles of Database Systems. </title> <publisher> Computer Science Press, </publisher> <address> 2 nd Ed., </address> <year> 1982. </year>
Reference-contexts: Example 1. Let us illustrate database querying and introduce some of its notation. The meaning and use is (or rather should be) intuitively obvious. For formal definitions we refer the reader to <ref> [40, 69] </ref>. To see that constraints should be part of any database query language consider an example from [41]. <p> The analogue for the relational model is that relations are finite structures, and queries are supposed to preserve this finiteness. This is a requirement that creates various "safety" problems in relational databases <ref> [20, 69] </ref>. The precise analogue in relational databases is the notion of weak safety of [4]. Evaluation of a query corresponds to an instance of a decision problem.
Reference: 70. <author> R. van der Meyden. </author> <title> The Complexity of Querying Indefinite Data about Linearly Ordered Domains. </title> <booktitle> Proc. 11th ACM PODS, </booktitle> <pages> 331-346, </pages> <year> 1992. </year>
Reference-contexts: For some recent research in this direction we refer to [34, 52, 56, 65, 12]. Constraint use for database logic program analysis is also relevant here, e.g., <ref> [13, 14, 70, 71] </ref>. (3) We have addressed the spatial applications of CQLs. Constraints offer useful approaches to temporal databases as well. For recent developments in temporal databases we refer to [6, 18, 61].
Reference: 71. <author> A. Van Gelder. </author> <title> Deriving Constraints among Argument Sizes in Logic Programs. </title> <booktitle> Proc. 9th ACM PODS, </booktitle> <pages> 47-60, </pages> <year> 1990. </year>
Reference-contexts: For some recent research in this direction we refer to [34, 52, 56, 65, 12]. Constraint use for database logic program analysis is also relevant here, e.g., <ref> [13, 14, 70, 71] </ref>. (3) We have addressed the spatial applications of CQLs. Constraints offer useful approaches to temporal databases as well. For recent developments in temporal databases we refer to [6, 18, 61].
Reference: 72. <author> P. Van Hentenryck. </author> <title> Constraint Satisfaction in Logic Programming. </title> <publisher> MIT Press, </publisher> <year> 1989. </year>
Reference-contexts: Perhaps one of the most important advances in constraint programming in the 1980's has been the development of Constraint Logic Programming (CLP) as a general-purpose framework for computations, e.g., in CLP (&lt;) [37], in Prolog III [22], and in CHIP <ref> [27, 72] </ref>. For more information on CLP see the surveys in [21, 51], the proceedings of logic programming conferences and of recent workshops on the subject, e.g., [42]. In particular, the advances in CLP are very relevant for database applications (which brings us to the subject of this paper). <p> It is easy to see that, just like the relational data model, constraint frameworks can be augmented with partial information constructs, such as null-values, but at the expense of data complexity. Constraint logic programming paradigms are currently attracting a great deal of attention in languages for operations research applications <ref> [72] </ref> and have also impacted the field of concurrent programming language design [64]. The use of constraints for operations research and for concurrency is sometimes semantically different from their use here.
Reference: 73. <author> M.Y. Vardi. </author> <title> The Complexity of Relational Query Languages. </title> <booktitle> Proc. 14th ACM STOC, </booktitle> <pages> 137-146, </pages> <year> 1982. </year>
Reference-contexts: One key intuition came from CLP: a conjunction of quantifier-free constraints over k variables, where k depends on the database schema and not the instance, is the correct generalization of the k-tuple or record or ground fact. The technical tools for this integration were: data complexity <ref> [17, 73] </ref> from database theory, and quantifier elimination methods from mathematical logic [28, 29, 68, 23, 8, 48, 60]. More specifically, finite relations are generalized to finitely representable relations and appropriate algebras for their data manipulation can be developed in this framework. <p> It corresponds nicely to the intuition that the database size is much larger than the query program size. It seems reasonable to limit computations to efficient ones, i.e., PTIME manipulations of the data. There are characterizations of PTIME <ref> [36, 73] </ref> using Datalog : on finite, ordered structures. So in terms of expressibility , Datalog : would suffice. However, various other CQLs allow for more "natural" and "flexible" expression of queries. 3.1 Data Complexity A query Q has data complexity in PTIME (resp. <p> Polynomial Dense Order Equality Relational Calculus NC AC 0 AC 0 Datalog : Not closed =PTIME PTIME In [41] it was shown that relational calculus (Inflationary Datalog : ) with dense order constraints has LOGSPACE (PTIME) data complexity. Also, by a slight modification of <ref> [36, 73] </ref> Inflationary Datalog : with dense linear order expresses exactly PTIME (this is the = in the table above). It is possible to strengthen the LOGSPACE bounds to uniform AC 0 , using random-access Alternating TMs [5, 16] with a fixed number of alternations and a logarithmic time bound.
References-found: 73

