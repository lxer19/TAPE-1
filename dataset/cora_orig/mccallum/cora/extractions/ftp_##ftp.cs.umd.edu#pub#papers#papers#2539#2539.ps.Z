URL: ftp://ftp.cs.umd.edu/pub/papers/papers/2539/2539.ps.Z
Refering-URL: http://www.cs.umd.edu/TRs/TR.html
Root-URL: 
Title: Perturbation Theory for the Singular Value Decomposition  
Author: G. W. Stewart 
Note: 20742. This work was supported in part by the Air Force Office of Sponsored Research under Contract AFOSR-87-0188.  
Address: College Park, MD  
Affiliation: Department of Computer Science and Institute for Advanced Computer Studies, University of Maryland,  
Date: September 1990 CS-TR 2539  
Pubnum: UMIACS-TR-90-124  
Abstract: The singular value decomposition has a number of applications in digital signal processing. However, the the decomposition must be computed from a matrix consisting of both signal and noise. It is therefore important to be able to assess the effects of the noise on the singular values and singular vectors | a problem in classical perturbation theory. In this paper we survey the perturbation theory of the singular value decomposition. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> E. </author> <type> Beltrami (1873). </type> <institution> "Sulle Funzioni Bilineari." Giornale di Matematiche ud uso Degli Studenti Delle Universita, </institution> <month> 11, </month> <pages> 98-106. </pages>
Reference-contexts: The two approaches tend to be complementary and work best in different circumstances. Perturbation bounds are ideal when one has a crude bound on the error, but little specific information about its structure. Perturbations expansions are 1 The singular value decomposition was discovered independently Beltrami <ref> [1, 1873] </ref> and Jor-dan [9, 1874]. Schmidt [12, 1907] used the infinite dimensional analogue of the decomposition in his work on integral equations.
Reference: [2] <author> C. H. </author> <title> Bischof (1990). "Incremental Condition Estimation." </title> <journal> SIAM Journal on Matrix Analysis and Applications, </journal> <volume> 11, </volume> <pages> 312-322. </pages>
Reference-contexts: Second, although the singular value decomposition is widely recommended as a way of detecting rank degeneracy, it is expensive to compute. There are other techniques, based on the QR factorization, that in practice are equally reliable and require far less work <ref> [4, 15, 16, 3, 7, 2] </ref>. Finally, the singular values of a matrix change when the columns of the matrix are scaled. For example, when a column is forced to zero, one of the singular values must also approach zero.
Reference: [3] <author> T. F. </author> <title> Chan (1987). "Rank Revealing QR Factorizations." </title> <journal> Linear Algebra and Its Applications, </journal> <volume> 88/89, </volume> <pages> 67-82. </pages>
Reference-contexts: Second, although the singular value decomposition is widely recommended as a way of detecting rank degeneracy, it is expensive to compute. There are other techniques, based on the QR factorization, that in practice are equally reliable and require far less work <ref> [4, 15, 16, 3, 7, 2] </ref>. Finally, the singular values of a matrix change when the columns of the matrix are scaled. For example, when a column is forced to zero, one of the singular values must also approach zero.
Reference: [4] <author> J. J. Dongarra, J. R. Bunch, C. B. Moler, and G. W. </author> <title> Stewart (1979). LIN-PACK User's Guide. </title> <publisher> SIAM, </publisher> <address> Philadelphia. </address>
Reference-contexts: Second, although the singular value decomposition is widely recommended as a way of detecting rank degeneracy, it is expensive to compute. There are other techniques, based on the QR factorization, that in practice are equally reliable and require far less work <ref> [4, 15, 16, 3, 7, 2] </ref>. Finally, the singular values of a matrix change when the columns of the matrix are scaled. For example, when a column is forced to zero, one of the singular values must also approach zero.
Reference: [5] <author> C. Eckart and G. </author> <title> Young (1939). "A Principal Axis Transformation for Non-Hermitian Matrices." </title> <journal> Bulletin of the American Mathematical Society, </journal> <volume> 45, </volume> <pages> 118-121. </pages>
Reference-contexts: Theorem 3 (Schmidt). The matrix A k is a matrix of rank k that is nearest A in the Frobenius norm. There are three comments to be made about these results. First, the theorem about the minimality of A k is usually attributed to Eckart and Young <ref> [5, 1939] </ref>; however, the theorem was first proved by Schmidt [12, 1907] for integral operators. It was later generalized by Mirsky [11, 1960] to all unitarily invariant norms. Second, although the singular value decomposition is widely recommended as a way of detecting rank degeneracy, it is expensive to compute.
Reference: [6] <author> G. H. Golub and C. F. Van Loan (1989). </author> <title> Matrix Computations (2nd ed.). </title> <publisher> Johns Hopkins University Press, </publisher> <address> Baltimore, Maryland. </address>
Reference-contexts: Perturbations expansions are 1 The singular value decomposition was discovered independently Beltrami [1, 1873] and Jor-dan [9, 1874]. Schmidt [12, 1907] used the infinite dimensional analogue of the decomposition in his work on integral equations. For elementary treatments of the singular value decomposition, see <ref> [6, 13] </ref>. 2 This unfortunate notation creates no end of confusion, since in probability and statistics the letter is traditionally reserved for a standard deviation. Perturbation of the SVD 3 most useful when the error is known, since it provides an approximation to the perturbed object.
Reference: [7] <author> N. J. </author> <title> Higham (1987). "A Survey of Condition Number Estimation for Triangular Matrices." </title> <journal> SIAM Review, </journal> <volume> 29, </volume> <pages> 575-596. </pages> <note> Perturbation of the SVD 13 </note>
Reference-contexts: Second, although the singular value decomposition is widely recommended as a way of detecting rank degeneracy, it is expensive to compute. There are other techniques, based on the QR factorization, that in practice are equally reliable and require far less work <ref> [4, 15, 16, 3, 7, 2] </ref>. Finally, the singular values of a matrix change when the columns of the matrix are scaled. For example, when a column is forced to zero, one of the singular values must also approach zero.
Reference: [8] <author> A. J. Hoffman and H. W. </author> <title> Wielandt (1953). "The Variation of the Spectrum of a Normal Matrix." </title> <journal> Duke Mathematical Journal, </journal> <volume> 20, </volume> <pages> 37-39. </pages>
Reference-contexts: degenerate matrix must have small singular values. 3 Mirsky's theorem in the Frobenius norm and specialized to eigenvalues of a symmetric matrix is sometimes said to be a a corollary of the Hoffman-Wielandt theorem, which bounds the sum of squares of the perturbations of the eigenvalues of a normal matrix <ref> [8] </ref>. However, the latter theorem does not state explicitly how the eigenvalues are to be paired. Perturbation of the SVD 5 Let B be any matrix of rank not greater than k, and let the singular values of B be denoted by 1 n .
Reference: [9] <author> C. </author> <title> Jordan (1874). "Memoire sur les formes bilineaires." </title> <journal> Journal de Mathematiques Pures et Appliquees, Deuxieme Serie, </journal> <volume> 19, </volume> <pages> 35-54. </pages>
Reference-contexts: The two approaches tend to be complementary and work best in different circumstances. Perturbation bounds are ideal when one has a crude bound on the error, but little specific information about its structure. Perturbations expansions are 1 The singular value decomposition was discovered independently Beltrami [1, 1873] and Jor-dan <ref> [9, 1874] </ref>. Schmidt [12, 1907] used the infinite dimensional analogue of the decomposition in his work on integral equations.
Reference: [10] <author> T. </author> <title> Kato (1966). Perturbation Theory for Linear Operators. </title> <publisher> Springer Verlag, </publisher> <address> New York. </address>
Reference-contexts: Perturbation of the SVD 3 most useful when the error is known, since it provides an approximation to the perturbed object. A survey of perturbation bounds may be found in [19]. For perturbation expansions see <ref> [10] </ref>. In this paper we will use two matrix norms, both of which reduce to the Euclidean vector norm kk 2 .
Reference: [11] <author> L. </author> <month> Mirsky </month> <year> (1960). </year> <title> "Symmetric Gage Functions and Unitarily Invariant Norms." </title> <journal> Quarterly Journal of Mathematics, </journal> <volume> 11, </volume> <pages> 50-59. </pages>
Reference-contexts: PERTURBATION BOUNDS FOR SINGULAR VALUES The basic perturbation bounds for the singular values of a matrix are due to Weyl [21] and Mirsky <ref> [11] </ref>. <p> There are three comments to be made about these results. First, the theorem about the minimality of A k is usually attributed to Eckart and Young [5, 1939]; however, the theorem was first proved by Schmidt [12, 1907] for integral operators. It was later generalized by Mirsky <ref> [11, 1960] </ref> to all unitarily invariant norms. Second, although the singular value decomposition is widely recommended as a way of detecting rank degeneracy, it is expensive to compute.
Reference: [12] <author> E. </author> <title> Schmidt (1907). "Zur Theorie der linearen und nichtlinearen Inte-gralgleichungen. I Tiel. Entwicklung willkurlichen Funktionen nach System vorgeschriebener." </title> <journal> Mathematische Annalen, </journal> <volume> 63, </volume> <pages> 433-476. </pages>
Reference-contexts: Perturbation bounds are ideal when one has a crude bound on the error, but little specific information about its structure. Perturbations expansions are 1 The singular value decomposition was discovered independently Beltrami [1, 1873] and Jor-dan [9, 1874]. Schmidt <ref> [12, 1907] </ref> used the infinite dimensional analogue of the decomposition in his work on integral equations. For elementary treatments of the singular value decomposition, see [6, 13]. 2 This unfortunate notation creates no end of confusion, since in probability and statistics the letter is traditionally reserved for a standard deviation. <p> There are three comments to be made about these results. First, the theorem about the minimality of A k is usually attributed to Eckart and Young [5, 1939]; however, the theorem was first proved by Schmidt <ref> [12, 1907] </ref> for integral operators. It was later generalized by Mirsky [11, 1960] to all unitarily invariant norms. Second, although the singular value decomposition is widely recommended as a way of detecting rank degeneracy, it is expensive to compute.
Reference: [13] <author> G. W. </author> <title> Stewart (1974). Introduction to Matrix Computations. </title> <publisher> Academic Press, </publisher> <address> New York. </address>
Reference-contexts: Perturbations expansions are 1 The singular value decomposition was discovered independently Beltrami [1, 1873] and Jor-dan [9, 1874]. Schmidt [12, 1907] used the infinite dimensional analogue of the decomposition in his work on integral equations. For elementary treatments of the singular value decomposition, see <ref> [6, 13] </ref>. 2 This unfortunate notation creates no end of confusion, since in probability and statistics the letter is traditionally reserved for a standard deviation. Perturbation of the SVD 3 most useful when the error is known, since it provides an approximation to the perturbed object.
Reference: [14] <author> G. W. </author> <title> Stewart (1979). "A Note on the Perturbation of Singular Values." </title> <journal> Linear Algebra and Its Applications, </journal> <volume> 28, </volume> <pages> 213-216. </pages>
Reference-contexts: One seldom sees them in applications, since they remain invariant under perturbations of the matrix; but they make their presence know through their effect on small singular values. To see what is going on let us consider another expression for the perturbed singular values <ref> [14, 17] </ref>. Let P be the orthogonal projection onto the column space of A. Let P ? = I P .
Reference: [15] <author> G. W. </author> <title> Stewart (1980). "The Efficient Generation of Random Orthogonal Matrices with an Application to Condition Estimators." </title> <journal> SIAM Journal on Numerical Analysis, </journal> <volume> 17, </volume> <pages> 403-404. </pages>
Reference-contexts: Second, although the singular value decomposition is widely recommended as a way of detecting rank degeneracy, it is expensive to compute. There are other techniques, based on the QR factorization, that in practice are equally reliable and require far less work <ref> [4, 15, 16, 3, 7, 2] </ref>. Finally, the singular values of a matrix change when the columns of the matrix are scaled. For example, when a column is forced to zero, one of the singular values must also approach zero.
Reference: [16] <author> G. W. </author> <title> Stewart (1984). "Rank Degeneracy." </title> <journal> SIAM Journal on Scientific and Statistical Computing, </journal> <volume> 5, </volume> <pages> 403-413. </pages>
Reference-contexts: Second, although the singular value decomposition is widely recommended as a way of detecting rank degeneracy, it is expensive to compute. There are other techniques, based on the QR factorization, that in practice are equally reliable and require far less work <ref> [4, 15, 16, 3, 7, 2] </ref>. Finally, the singular values of a matrix change when the columns of the matrix are scaled. For example, when a column is forced to zero, one of the singular values must also approach zero. <p> In particular, one usually has to know something about the structure of the errors in the elements of the matrix to make a meaningful statement about rank. For more on this problem see <ref> [16] </ref>. 4. PERTURBATION EXPANSIONS In order to obtain a perturbation expansion for a singular value we must place restrictions on the singular value and the error matrix E. Specifically, we must assume that the singular value is simple; i.e., it is not repeated.
Reference: [17] <author> G. W. </author> <title> Stewart (1984). "A Second Order Perturbation Expansion for Small Singular Values." </title> <journal> Linear Algebra and Its Applications, </journal> <volume> 56, </volume> <pages> 231-235. </pages>
Reference-contexts: One seldom sees them in applications, since they remain invariant under perturbations of the matrix; but they make their presence know through their effect on small singular values. To see what is going on let us consider another expression for the perturbed singular values <ref> [14, 17] </ref>. Let P be the orthogonal projection onto the column space of A. Let P ? = I P .
Reference: [18] <author> G. W. </author> <title> Stewart (1988). "Stochastic Perturbation Theory." </title> <type> Technical Report CS-TR2129, </type> <institution> Department of Computer Science, University of Maryland. </institution> <note> To appear in SIAM Review </note> . 
Reference-contexts: For more on the subject of stochastic pertur bation estimates, see <ref> [18] </ref>. However, when there are multiple singular values, Mirsky's bound can be sharp. For example, let A = @ 1 0 1 0 * 1 + * A Perturbation of the SVD 7 The singular values of A are 1 and 1.
Reference: [19] <author> G. W. Stewart and Ji guang Sun (1990). </author> <title> Matrix Perturbation Theory. </title> <publisher> Academic Press, </publisher> <address> Boston. </address>
Reference-contexts: Perturbation of the SVD 3 most useful when the error is known, since it provides an approximation to the perturbed object. A survey of perturbation bounds may be found in <ref> [19] </ref>. For perturbation expansions see [10]. In this paper we will use two matrix norms, both of which reduce to the Euclidean vector norm kk 2 . <p> For it can be shown that kP X P Y k F = 2k sin fik F : 10 Perturbation of the SVD Thus the two measures go to zero at the same rate. For a detailed treatment of metrics between subspaces, see <ref> [19, Ch.2] </ref>. 7. WEDIN'S THEOREM In this section we will present a perturbation bound, due to Wedin [20], for singular subspaces. It is an unusual result in that it provides a single bound for both the right and left singular subspaces corresponding to a set of singular spaces.
Reference: [20] <author> P. A. </author> <month> Wedin </month> <year> (1972). </year> <title> "Perturbation Bounds in Connection with Singular Value Decomposition." </title> <journal> BIT, </journal> <volume> 12, </volume> <pages> 99-111. </pages> <note> 14 Perturbation of the SVD </note>
Reference-contexts: For a detailed treatment of metrics between subspaces, see [19, Ch.2]. 7. WEDIN'S THEOREM In this section we will present a perturbation bound, due to Wedin <ref> [20] </ref>, for singular subspaces. It is an unusual result in that it provides a single bound for both the right and left singular subspaces corresponding to a set of singular spaces. We will need a basis for the singular subspaces we wish to bound.
Reference: [21] <author> H. </author> <title> Weyl (1912). "Das asymptotische Verteilungsgestez der Eigenwert linearer partieller Differentialgleichungen (mit einer Anwendung auf der Theorie der Hohlraumstrahlung)." </title> <journal> Mathematische Annalen, </journal> <volume> 71, </volume> <pages> 441-479. </pages>
Reference-contexts: PERTURBATION BOUNDS FOR SINGULAR VALUES The basic perturbation bounds for the singular values of a matrix are due to Weyl <ref> [21] </ref> and Mirsky [11].
References-found: 21

