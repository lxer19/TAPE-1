URL: http://www.eecs.umich.edu/~tnm/papers/ipps94.ps
Refering-URL: http://www.eecs.umich.edu/~tnm/papers.html
Root-URL: http://www.cs.umich.edu
Title: Abstract  
Abstract: Superscalar microprocessors obtain high performance by exploiting parallelism at the instruction level. To effectively use the instruction-level parallelism found in general purpose, non-numeric code, future processors will need to speculatively execute far beyond instruction fetch limiting conditional branches. One result of this deep speculation is an increase in the number of instruction and data memory references due to the execution of mispre-dicted paths. Using a tool we developed to generate speculative traces from Intel architecture Unix binaries, we examine the differences in cache performance between speculative and non-speculative execution models. The results pertaining to increased memory traffic, mispre-dicted path reference effects, allocation strategies, and speculative write buffers are discussed. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D. Alpert, and D. Avnon, </author> <title> Architecture of the Pen-tium Microprocessor, </title> <booktitle> IEEE Micro, </booktitle> <month> June </month> <year> 1993, </year> <pages> pp. 11-21. </pages>
Reference: [2] <author> J. Gee, M. Hill, D. Pnevmatikatos, A. Smith, </author> <title> Cache Performance of the SPEC Benchmark Suite, Tech-Program Reuse % Program Reuse % cc1 60 espresso 68 compress 52 sc 56 ear 66 xlisp 60 eqntott 60 TABLE 4. Wrong path instruction reuse - The percentage of instruction cache lines allocated during wrong path execution which were later referenced during correct path execution. </title> <type> nical Report UCB/CSD 91/648, </type> <institution> University of Cali-fornia Computer Science Division, Berkeley, </institution> <address> CA. </address>
Reference-contexts: Therefore, it is beneficial to allocate cache lines on all speculative write references prior to branch resolution. 3.6 Instruction Prefetching This study has focused on data cache behavior because the SPEC benchmarks do a poor job of exercising even small instruction caches <ref> [2] </ref>. Pollution and prefetch effects cannot be observed when the full working set fits into the cache. However, we believe that instruction references produced during mispredicted paths could perform prefetches for later instruction references.
Reference: [3] <author> R. Groves, and R Oehler, </author> <title> RISC System/6000 Processor Architecture, </title> <institution> IBM RISC System/6000 Technology, SA23-2619, IBM Corporation, </institution> <year> 1991, </year> <pages> pp. 16-24. </pages>
Reference: [4] <author> E. McLellan, </author> <title> The Alpha AXP Architecture and 21064 Processor, </title> <booktitle> IEEE Micro, </booktitle> <month> June </month> <year> 1993, </year> <pages> pp. 26-47. </pages>
Reference: [5] <author> D. Nagle, R. Uhlig, T. Stanley, T. Mudge, S. Sechrest and R. Brown, </author> <title> Design Tradeoffs for Software-Managed TLBs, </title> <booktitle> Proc. of the 20th Annual International Symposium on Computer Architecture, </booktitle> <month> May </month> <year> 1993, </year> <pages> pp. 27-38. </pages>
Reference-contexts: We used spex and several different cache simulators to model cache performance when speculatively executing SPEC92 applications. It was not our intent to specify an optimal cache configuration for a certain processor based only upon application generated references. Many studies have shown that this leads to meaningless conclusions <ref> [5] </ref>. Instead we examined the differences in cache performance between the speculative and non-speculative execution models. We believe that similar results would be found using a more complete workload containing OS effects.
Reference: [6] <author> J. Pierce, IDtrace: </author> <title> A Trace Generation Tool for the ix86 Instruction Set, </title> <type> Technical report, </type> <institution> Dept. of Electrical Engineering and Computer Science, University of Michigan, </institution> <month> Dec. </month> <year> 1993. </year>
Reference-contexts: Complex ix86 instructions, indirect addressing, and variable instruction lengths are some of the issues which make binary instrumentation difficult and sometimes impossible. In-depth discussion of these issues and some restrictions on applicable programs can be found in <ref> [6] </ref>. The speculative instrumentation adds significantly to the size and runtime of the new binary. Code expansion is roughly 25 times. Runtime is increased by factors of 25-45 for zero depth (no speculation) and 35-65 for depth 10 speculative execution. <p> Indirect call - Indirect calls in instrumented code are handled by a runtime lookup matching the original target address with the new target address in the instrumented code, see <ref> [6] </ref>. If the original address is computed from incorrect data the lookup will fail and wrong path execution is halted. Execution fault - This could be caused by a oating point or divide by zero exception.
Reference: [7] <author> J. Quinlan, and K. Lai, Tynero: </author> <title> A Multiple Cache Simulator, </title> <type> Technical Report, </type> <institution> Intel Corp., Hillsboro, </institution> <address> OR, </address> <month> May </month> <year> 1991. </year>
Reference-contexts: terminations do not compromise the accuracy of the trace. 3 Results To study the effect of speculative execution on cache performance, traces were generated by spex instrumented code and fed into two cache simulators: a modified version of Tynero and a multicache simulator designed to monitor prefetching and pollution effects <ref> [7] </ref>. Both simulators distinguish between correct path references and misses and wrong path references and misses. The test suite consisted of the SPEC92 C benchmarks, see Table 2. All experiments were run on an Intel 50 MHz i486 machine running USL Unix SysVR4.2.
Reference: [8] <author> J.E. Smith, </author> <title> A Study of Branch Prediction Strategies, </title> <booktitle> Proceedings of the 8th International Symposium on Computer Architecture, </booktitle> <month> May </month> <year> 1981, </year> <pages> pp. 135-148. </pages>
Reference-contexts: One dynamic algorithm has a bit per table entry corresponding to the previous direction of the branch. The other has a two or three bit saturating counter per table entry to maintain a weighted history for each branch <ref> [8] </ref>. Another group of prediction algorithms use two-level adaptive training schemes with various size history tables and registers [13]. The final type is a profile algorithm where the direction is determined by looking for the prediction entry in a file.
Reference: [9] <author> M. Smith, </author> <title> Tracing with Pixie, </title> <type> Technical Report, </type> <institution> Center for Integrated Systems, Stanford University. </institution>
Reference: [10] <author> C. Stephens, B. Cogswell, J. Heinlein, G. Palmer, and J. Shen, </author> <title> Instruction Level Profiling and Evaluation of the IBM RS/6000, </title> <booktitle> Proc. of 18th Annual International Symposium on Computer Architecture, </booktitle> <address> Toronto, Canada, </address> <year> 1991, </year> <pages> pp. 180-189. </pages>
Reference: [11] <author> Sun Microsystems Laboratories, Inc., </author> <title> Introduction to SpixTools, </title> <type> Technical Report, </type> <institution> Mountain View, </institution> <address> CA, </address> <month> April </month> <year> 1992. </year>
Reference: [12] <author> D. Wall, </author> <title> Systems for Late Code Modification, </title> <institution> Digital Western Research Laboratory, Research Report, </institution> <month> June </month> <year> 1991. </year>
Reference: [13] <author> T-Y Yeh, and Y. Patt, </author> <title> Two-Level Adaptive Training Branch Prediction, </title> <booktitle> The 24th ACM/IEEE International Symposium and Workshop on Microarchitec-ture, </booktitle> <month> Nov. </month> <year> 1991, </year> <pages> pp. 51-61. </pages>
Reference-contexts: The other has a two or three bit saturating counter per table entry to maintain a weighted history for each branch [8]. Another group of prediction algorithms use two-level adaptive training schemes with various size history tables and registers <ref> [13] </ref>. The final type is a profile algorithm where the direction is determined by looking for the prediction entry in a file. If an entry for a particular branch doesnt exist in the file, one of the above algorithms is used to predict the branch. <p> Finally, the cache write policy is copy-back with write allocation for correct writes. Two branch prediction algorithms are used in this study. Algorithm 1 is a two-level adaptive scheme with a 512 entry, 4-way associative register table and a 4096 entry pattern table containing 2-bit saturating counters <ref> [13] </ref>. This algorithm is expensive in terms of hardware but it achieves excellent accuracy for the benchmarks in our study, see Table 3. It is the algorithm used unless otherwise specified. Algorithm 2 uses a simpler history table of 1024, 2-bit saturating counters.
References-found: 13

