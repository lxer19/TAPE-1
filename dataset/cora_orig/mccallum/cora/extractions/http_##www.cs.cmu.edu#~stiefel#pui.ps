URL: http://www.cs.cmu.edu/~stiefel/pui.ps
Refering-URL: http://www.is.cs.cmu.edu/ISL.multimodal.eye.html
Root-URL: 
Email: stiefel@ira.uka.de, yang+@cs.cmu.edu, ahw@cs.cmu.edu  
Title: Tracking Eyes and Monitoring Eye Gaze  
Author: Rainer Stiefelhagen, Jie Yang, Alex Waibel 
Address: USA  
Affiliation: Interactive Systems Laboratories University of Karlsruhe Germany, Carnegie Mellon University  
Abstract: In this paper, we present a non-intrusive eye tracker which can detect and track a user's eyes in real time as soon as the face appears in the view of the camera without special lighting or any marks on the user's face. We also discuss the problem of gaze monitoring. We employ neural networks to estimate a user's eye gaze using the images of user's both eyes as input to the neural networks. We have collected 4 sets of data from 4 different users using the eye tracker and have trained and tested several neural networks. The eye gaze monitoring system has achieved accuracy of between 1.3 and 1.8 degrees with a user dependent setup and of 1.9 degrees for a multi-user setup. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Shumet Baluja and Dean Pomerleau. </author> <title> Non-intrusive gaze tracking using artificial neural networks. </title> <type> Technical Report CMU-CS-94-102, </type> <institution> Carnegie Mellon University, </institution> <year> 1994. </year>
Reference-contexts: Baluja and Pomerleau proposed a non-intrusive method to estimate the eye-gaze based on a neural network <ref> [1] </ref>. It has been demonstrated that the neural network could accurately estimate the position of the eye gaze on a computer screen given images of the user's eyes as input. However, the system used an active sensing approach by shining light into the user's right eye. <p> ESTIMATING EYE GAZE WITH A NEURAL NET Baluja and Pomerleau demonstrated that a neural network could achieve accurate eye gaze estimation on the screen if stable images of user's eyes could be acquired <ref> [1] </ref>. Motivated by their work, we have trained several neural networks to estimate a user's eye gaze on a computer screen using the eye images obtained with our eye tracker. We use the structure of a three layer network.
Reference: [2] <author> Arne John Glenstrup and Theo Engell-Nielsen. </author> <title> Eye controlled media: Present and future state. </title> <type> Technical report, </type> <institution> University of Copenhagen, </institution> <note> http://www.diku.dk/users/panic/eyegaze/, 1995. </note>
Reference-contexts: Current eye gaze tracking methods basically rely on intrusive techniques such as measuring the reflection of some light (ususally infrared light) that is shone onto the eye, measuring the electric potential of the skin around the eyes or applying special contact lenses that facilitate eye gaze tracking <ref> [2] </ref>. Baluja and Pomerleau proposed a non-intrusive method to estimate the eye-gaze based on a neural network [1]. It has been demonstrated that the neural network could accurately estimate the position of the eye gaze on a computer screen given images of the user's eyes as input.
Reference: [3] <author> Rainer Stiefelhagen, Jie Yang, and Alex Waibel. </author> <title> A model-based gaze tracking system. </title> <booktitle> In Proceedings of IEEE International Joint Symposia on Intelligence and Systems, </booktitle> <pages> pages 304 - 310, </pages> <year> 1996. </year>
Reference-contexts: Details of the tracking of all facial features, and the methods to detect and recover from tracking failure are described in detail in <ref> [3] </ref>. Tracking of the facial features is done in real time and runs at a frame rate of 15-30 frames per second, depending on the size of the found face in the image. 2.3.
Reference: [4] <author> Jie Yang and Alex Waibel. </author> <title> A real-time face tracker. </title> <booktitle> In Proceedings of WACV, </booktitle> <pages> pages 142-147, </pages> <year> 1996. </year>
Reference-contexts: TRACKING EYES AND PREPROCESSING 2.1. Tracking the face To locate the eyes we first try to find the face in the camera image. To find and track the face, we use a statistical color-model consisting of a two-dimensional Gaussian distribution of normalized skin colors <ref> [4] </ref>. The input image is searched for pixels with skin colors and the largest connected region of skin-colored pixels in the camera-image is considered as the region of the face. Figure 1 shows the application of the skin color model to a sample input image.
References-found: 4

