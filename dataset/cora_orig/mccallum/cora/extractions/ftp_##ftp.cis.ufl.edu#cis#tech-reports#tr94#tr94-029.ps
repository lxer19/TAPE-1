URL: ftp://ftp.cis.ufl.edu/cis/tech-reports/tr94/tr94-029.ps
Refering-URL: http://www.cis.ufl.edu/tech-reports/tech-reports/tr94-abstracts.html
Root-URL: http://www.cis.ufl.edu
Title: LOST PIVOT RECOVERY FOR AN UNSYMMETRIC-PATTERN MULTIFRONTAL METHOD  
Author: STEVEN M. HADFIELD AND TIMOTHY A. DAVIS 
Keyword: Key words. LU factorization, unsymmetric sparse matrices, multifrontal methods, parallel algorithms  
Note: AMS subject classifications. 65F50, 65F05  
Abstract: Computer and Information Sciences Department, University of Florida Technical Report TR-94-029. Abstract. The unsymmetric-patternmultifrontal method by Davis and Duff relaxes the assumption of a symmetric pattern matrix and has considerable performance advantages for the factorization of sequences of identically structured sparse matrices with unsymmetric patterns. However, when anticipated pivots become no longer numerically acceptable, standard multifrontal recovery techniques are inadequate. This paper develops a robust lost pivot recovery capability for the unsymmetric pattern multifrontal method. The recovery capability is built into a distributed memory, parallel implementation of the method and both its sequential and parallel performance are evaluated. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> P. R. Amestoy and I. S. Duff, </author> <title> Vectorization of a multiprocessor multifrontal code, </title> <journal> International Journal of Supercomputing Applications, </journal> <volume> 3 (1989), </volume> <pages> pp. 41-59. </pages>
Reference-contexts: Techniques that recover from the loss of these anticipated pivots without having to abandon the previously defined computational structure can significantly improve overall execution time. Until recently all multifrontal methods assumed a symmetric-pattern matrix which results in a corresponding computational structure that is a tree (or forest) <ref> [1, 5, 6, 7, 8, 18] </ref>. This simplified structure allows for a simple lost pivot recovery mechanism. Recently, Davis and Duff have introduced a new multifrontal method that relaxes the assumption of a symmetric pattern [3] and has demonstrated impressive performance advantages over previous methods [19]. <p> With symmetric pattern multifrontal methods, the assembly DAG is a tree (or forest) as each frontal matrix's contribution block can be completely absorbed within a single subsequent frontal matrix <ref> [1, 5, 6, 7, 8, 18] </ref>. With the unsymmetric pattern multifrontal method, the contribution block can be fragmented and portions must be passed to different subsequent frontal matrices which results in more generalized DAG structure.
Reference: [2] <author> T. A. Davis, </author> <title> Users' guide for the unsymmetric-pattern multifrontal package (UMFPACK), </title> <type> Tech. Report TR-93-020, </type> <institution> Computer and Information Sciences Department, University of Florida, </institution> <address> Gainesville, FL, </address> <month> June </month> <year> 1993. </year> <note> (UMFPACK is available via Netlib (linalg/umfpack.shar) or via anonymous ftp to ftp.cis.ufl.edu:pub/umfpack). </note> <author> 22 Hadfield and Davis Fig. 6.4. </author> <title> RDIST3A (matrix 37) Speed-Ups With and Without Lost Pivot Recovery (LPR) </title>
Reference-contexts: The edge set used to define the assembly DAG is called the assembly edge set and denoted by E A . It differs from the true edge set, E T . The E A edge set is generated by the combined analyze-factorize algorithm (UMFPACK <ref> [2, 3] </ref>) for the first matrix in the sequence. There is an edge from A to B in E A if any contributions were assembled from frontal matrix A into frontal matrix B.
Reference: [3] <author> T. A. Davis and I. S. Duff, </author> <title> An unsymmetric-pattern multifrontal method for sparse LU factorization, </title> <note> SIAM J. Matrix Anal. Appl., (submitted March 1993, under revision. Also TR-94-038.). </note>
Reference-contexts: This simplified structure allows for a simple lost pivot recovery mechanism. Recently, Davis and Duff have introduced a new multifrontal method that relaxes the assumption of a symmetric pattern <ref> [3] </ref> and has demonstrated impressive performance advantages over previous methods [19]. In addition to reducing computational requirements, this method exposes considerable parallelism [14, 15]. <p> this set represents a distinct frontal matrix and an equivalence relation is established between these frontal matrices and the original position of their first pivot in the pivot ordering (assuming the necessary permutations have been applied to put the matrix into the pivot ordering used by the initial analyze-factorize routine <ref> [3] </ref>). Hence the ordering of the pivot entries provides the ordering for the set F and a frontal matrix's ID is defined to be the pivot column/row index of the first pivot within the frontal matrix. <p> Within a particular frontal matrix, the specific components (submatrices) will frequently need to be referenced. This will be done using the same notation found in Davis and Duff's original work <ref> [3] </ref>. Specifically, L A refers to the set of row indices that define the rows from the overall matrix that make up the frontal matrix A 2 F. <p> The edge set used to define the assembly DAG is called the assembly edge set and denoted by E A . It differs from the true edge set, E T . The E A edge set is generated by the combined analyze-factorize algorithm (UMFPACK <ref> [2, 3] </ref>) for the first matrix in the sequence. There is an edge from A to B in E A if any contributions were assembled from frontal matrix A into frontal matrix B.
Reference: [4] <author> I. S. Duff, </author> <title> Sparse Matrices and their Uses, </title> <publisher> Academic Press, </publisher> <address> New York and London, </address> <year> 1981. </year>
Reference-contexts: 1. Introduction. Systems of differential-algebraic equations arise in many application areas including circuit simulation, chemical engineering, magnetic resonance spectroscopy, and air pollution modeling <ref> [4, 17, 20, 22] </ref>. Methods for solving such systems frequently produce sequences of identically structured sparse matrices whose patterns can be highly unsymmetric. The LU factorization of these matrices allow their corresponding linear systems to be easily solved.
Reference: [5] <author> I. S. Duff, </author> <title> Parallel implementation of multifrontal schemes, </title> <booktitle> Parallel Computing, 3 (1986), </booktitle> <pages> pp. 193-204. </pages>
Reference-contexts: Techniques that recover from the loss of these anticipated pivots without having to abandon the previously defined computational structure can significantly improve overall execution time. Until recently all multifrontal methods assumed a symmetric-pattern matrix which results in a corresponding computational structure that is a tree (or forest) <ref> [1, 5, 6, 7, 8, 18] </ref>. This simplified structure allows for a simple lost pivot recovery mechanism. Recently, Davis and Duff have introduced a new multifrontal method that relaxes the assumption of a symmetric pattern [3] and has demonstrated impressive performance advantages over previous methods [19]. <p> With symmetric pattern multifrontal methods, the assembly DAG is a tree (or forest) as each frontal matrix's contribution block can be completely absorbed within a single subsequent frontal matrix <ref> [1, 5, 6, 7, 8, 18] </ref>. With the unsymmetric pattern multifrontal method, the contribution block can be fragmented and portions must be passed to different subsequent frontal matrices which results in more generalized DAG structure.
Reference: [6] <author> I. S. Duff, A. M. Erisman, and J. K. Reid, </author> <title> Direct Methods for Sparse Matrices, </title> <publisher> Oxford Science Publications, </publisher> <address> New York, NY, </address> <year> 1989. </year>
Reference-contexts: Techniques that recover from the loss of these anticipated pivots without having to abandon the previously defined computational structure can significantly improve overall execution time. Until recently all multifrontal methods assumed a symmetric-pattern matrix which results in a corresponding computational structure that is a tree (or forest) <ref> [1, 5, 6, 7, 8, 18] </ref>. This simplified structure allows for a simple lost pivot recovery mechanism. Recently, Davis and Duff have introduced a new multifrontal method that relaxes the assumption of a symmetric pattern [3] and has demonstrated impressive performance advantages over previous methods [19]. <p> With symmetric pattern multifrontal methods, the assembly DAG is a tree (or forest) as each frontal matrix's contribution block can be completely absorbed within a single subsequent frontal matrix <ref> [1, 5, 6, 7, 8, 18] </ref>. With the unsymmetric pattern multifrontal method, the contribution block can be fragmented and portions must be passed to different subsequent frontal matrices which results in more generalized DAG structure. <p> Lost Pivot Recovery Issues. Multifrontal methods can address lost pivot recovery with three distinct strategies. First, avoidance tries to preclude the need for recovering lost pivots by relaxing the criteria used to judge potential pivots as being numerically acceptable. This is done via the concept of threshold pivoting <ref> [6] </ref>. Threshold pivoting requires the magnitude of the pivot entry's value to be greater than a threshold parameter () times the magnitude of the largest entry in the column. The threshold parameter is set between 1 and 0.
Reference: [7] <author> I. S. Duff and J. K. Reid, </author> <title> The multifrontal solution of indefinite sparse symmetric linear systems, </title> <journal> ACM Transactions on Mathematical Software, </journal> <volume> 9 (1983), </volume> <pages> pp. </pages> <month> 302-325. </month> <title> [8] , The multifrontal solution of unsymmetric sets of linear equations, </title> <journal> SIAM J. Sci. Statist. Comput., </journal> <volume> 5 (1984), </volume> <pages> pp. 633-641. </pages>
Reference-contexts: Techniques that recover from the loss of these anticipated pivots without having to abandon the previously defined computational structure can significantly improve overall execution time. Until recently all multifrontal methods assumed a symmetric-pattern matrix which results in a corresponding computational structure that is a tree (or forest) <ref> [1, 5, 6, 7, 8, 18] </ref>. This simplified structure allows for a simple lost pivot recovery mechanism. Recently, Davis and Duff have introduced a new multifrontal method that relaxes the assumption of a symmetric pattern [3] and has demonstrated impressive performance advantages over previous methods [19]. <p> With symmetric pattern multifrontal methods, the assembly DAG is a tree (or forest) as each frontal matrix's contribution block can be completely absorbed within a single subsequent frontal matrix <ref> [1, 5, 6, 7, 8, 18] </ref>. With the unsymmetric pattern multifrontal method, the contribution block can be fragmented and portions must be passed to different subsequent frontal matrices which results in more generalized DAG structure.
Reference: [9] <author> S. C. Eisenstat and J. W. H. Liu, </author> <title> Exploiting structural symmetry in unsymmetric sparse symbolic factorization, </title> <journal> SIAM J. Matrix Anal. Appl., </journal> <volume> 13 (1992), </volume> <pages> pp. </pages> <month> 202-211. </month> <title> [10] , Exploiting structural symmetry in a sparse partial pivoting code, </title> <journal> SIAM J. Sci. Statist. Comput., </journal> <volume> 14 (1993), </volume> <pages> pp. 253-257. </pages>
Reference-contexts: This is similar to a formulation of elimination DAGs done by Gilbert and Liu [12] and Eisenstat and Liu <ref> [9, 10] </ref>. The edge set used to define the assembly DAG is called the assembly edge set and denoted by E A . It differs from the true edge set, E T .
Reference: [11] <author> G. A. Geist and M. Heath, </author> <title> Matrix factorization on a hypercube, in Hypercube Multiprocessors 1986, </title> <editor> M. Heath, ed., </editor> <booktitle> Society for Industrial and Applied Mathematics, </booktitle> <address> Philadelphia, PA, </address> <year> 1986, </year> <pages> pp. 161-180. </pages>
Reference-contexts: Intra-frontal matrix lost pivot recovery did not need to be addressed in the theoretical development but is handled within the partial dense factorization routine of step (6) in Figure 5.2. This partial dense factorization routine is based on a pipelined, fan-out algorithm developed by Geist and Heath <ref> [11] </ref> which uses a column-oriented 18 Hadfield and Davis data allocation. In this algorithm, the cooperating processor that holds the next pivot's column will receive the multipliers (column of the L factor) and then update just the next pivot's column with these multipliers.
Reference: [12] <author> J. R. Gilbert and J. W. H. Liu, </author> <title> Elimination structures for unsymmetric sparse LU factors, </title> <journal> SIAM Journal on Matrix Analysis and Applications, </journal> <volume> 14 (1993), </volume> <pages> pp. 334-354. </pages>
Reference-contexts: This is similar to a formulation of elimination DAGs done by Gilbert and Liu <ref> [12] </ref> and Eisenstat and Liu [9, 10]. The edge set used to define the assembly DAG is called the assembly edge set and denoted by E A . It differs from the true edge set, E T .
Reference: [13] <author> S. Hadfield, </author> <title> On the LU Factorization of Sequences of Identically Structured Sparse Matrices within a Distributed Memory Environment, </title> <type> PhD thesis, </type> <institution> University of Florida, </institution> <address> Gainesville, FL, </address> <month> April </month> <year> 1994. </year> <note> (also TR-94-019). </note>
Reference-contexts: Block Triangular Form. Block Triangular Form is significant because it can expose a high level parallelism between assembly sub-DAGS, reduce overall computations (as off-diagonal blocks need not be factorized), and simplify lost pivot recovery <ref> [13] </ref>. The advantages in terms of lost pivot recovery occur as L 00 6= ; and U 00 6= ; for all frontal matrices except the last frontal matrix in each diagonal block F i . A proof can be found in Hadfield's dissertation [13]. 4.3. Foundational Theorems. <p> factorized), and simplify lost pivot recovery <ref> [13] </ref>. The advantages in terms of lost pivot recovery occur as L 00 6= ; and U 00 6= ; for all frontal matrices except the last frontal matrix in each diagonal block F i . A proof can be found in Hadfield's dissertation [13]. 4.3. Foundational Theorems. Three theorems and two corollaries form the foundation upon which most of the lost pivot recovery results are built. These are provided below: Theorem 4.1 (L Ancestor Fill-In). <p> Furthermore, E T is insufficient for lost pivot recovery and must be augmented. Likewise, E A is also insufficient for lost pivot recovery. While these results complicate lost pivot recovery, it is still possible. For details on this more generalized case, see <ref> [13] </ref>. 5. Implementation. The implementation of lost pivot recovery is based on a parallel distributed memory version of the unsymmetric pattern multifrontal method called PRF (for Parallel ReFactor). <p> PRF Factorization Loop Enhanced for Lost Pivot Recovery Details of the processing outlined in Figure 5.2 follow from the theoretical development of the previous section. Detailed descriptions of this processing can be found in <ref> [13] </ref>. A major complicating factor in this implementation is that the recovery structure for an individual failed frontal matrix is duplicated along disjoint control paths. Rows from this structure are absorbed by L ancestors and columns by U ancestors per Corollaries 4.8 and 4.11.
Reference: [14] <author> S. M. Hadfield and T. A. Davis, </author> <title> Analysis of potential parallel implementation of the unsymmetric-pattern multifrontal method for sparse LU factorization, </title> <type> Tech. Report TR-92-017, </type> <institution> Department of Computer and Information Systems, University of Florida, </institution> <address> Gainesville, FL, </address> <year> 1992. </year>
Reference-contexts: Recently, Davis and Duff have introduced a new multifrontal method that relaxes the assumption of a symmetric pattern [3] and has demonstrated impressive performance advantages over previous methods [19]. In addition to reducing computational requirements, this method exposes considerable parallelism <ref> [14, 15] </ref>. With this unsym-metric pattern multifrontal method however, the resulting computational structure fl Department of Mathematical Sciences, US Air Force Academy, Colorado, USA. phone: (719) 472-4470, email: hadfieldsm%dfms%usafa@dfmail.usafa.af.mil y Computer and Information Sciences Department, University of Florida, Gainesville, Florida, USA. phone: (904) 392-1481, email: davis@cis.ufl.edu.
Reference: [15] <author> S. M. Hadfield and T. A. Davis, </author> <title> A parallel unsymmetric-pattern multifrontal method, </title> <journal> SIAM J. Sci. Computing, </journal> <note> (1994). (submitted. Also Univ. of Fl. tech report TR-94-028). </note>
Reference-contexts: Recently, Davis and Duff have introduced a new multifrontal method that relaxes the assumption of a symmetric pattern [3] and has demonstrated impressive performance advantages over previous methods [19]. In addition to reducing computational requirements, this method exposes considerable parallelism <ref> [14, 15] </ref>. With this unsym-metric pattern multifrontal method however, the resulting computational structure fl Department of Mathematical Sciences, US Air Force Academy, Colorado, USA. phone: (719) 472-4470, email: hadfieldsm%dfms%usafa@dfmail.usafa.af.mil y Computer and Information Sciences Department, University of Florida, Gainesville, Florida, USA. phone: (904) 392-1481, email: davis@cis.ufl.edu.
Reference: [16] <author> S. M. Hadfield and T. A. Davis, </author> <title> Potential and achievable parallelism in the unsymmetric-pattern multifrontal LU factorization method for sparse matrices, </title> <booktitle> in Fifth SIAM Conference on Applied Linear Algebra, </booktitle> <year> 1994. </year> <title> (also TR-94-006). UNSYMMETRIC PATTERN MULTIFRONTAL LOST PIVOT RECOVERY 23 </title>
Reference-contexts: Typically significantly fewer pivots were lost and the corresponding degradations in achievable parallelism were significantly less severe. 7. Conclusion. The unsymmetric-pattern multifrontal method of Davis and Duff has proven to have extremely competitive sequential performance [19] and significant parallel potential <ref> [16] </ref>. When the method is applied to sequences of identically structured matrices, the assembly DAG from the analyze-factor operation on the first matrix can be reused for factor-only operations on the subsequent matrices in the sequence.
Reference: [17] <author> K. S. Kundert, </author> <title> Sparse matrix techniques and their applications to circuit simulation, in Circuit Analysis, Simulation and Design, </title> <editor> A. E. Ruehli, ed., </editor> <address> New York: </address> <publisher> North-Holland, </publisher> <year> 1986. </year>
Reference-contexts: 1. Introduction. Systems of differential-algebraic equations arise in many application areas including circuit simulation, chemical engineering, magnetic resonance spectroscopy, and air pollution modeling <ref> [4, 17, 20, 22] </ref>. Methods for solving such systems frequently produce sequences of identically structured sparse matrices whose patterns can be highly unsymmetric. The LU factorization of these matrices allow their corresponding linear systems to be easily solved.
Reference: [18] <author> J. W. H. Liu, </author> <title> The multifrontal method for sparse matrix solution: </title> <journal> Theory and practice, SIAM Review, </journal> <volume> 34 (1992), </volume> <pages> pp. 82-109. </pages>
Reference-contexts: Techniques that recover from the loss of these anticipated pivots without having to abandon the previously defined computational structure can significantly improve overall execution time. Until recently all multifrontal methods assumed a symmetric-pattern matrix which results in a corresponding computational structure that is a tree (or forest) <ref> [1, 5, 6, 7, 8, 18] </ref>. This simplified structure allows for a simple lost pivot recovery mechanism. Recently, Davis and Duff have introduced a new multifrontal method that relaxes the assumption of a symmetric pattern [3] and has demonstrated impressive performance advantages over previous methods [19]. <p> With symmetric pattern multifrontal methods, the assembly DAG is a tree (or forest) as each frontal matrix's contribution block can be completely absorbed within a single subsequent frontal matrix <ref> [1, 5, 6, 7, 8, 18] </ref>. With the unsymmetric pattern multifrontal method, the contribution block can be fragmented and portions must be passed to different subsequent frontal matrices which results in more generalized DAG structure.
Reference: [19] <author> E. G.-Y. Ng, </author> <title> Comparison of some direct methods for solving sparse nonsymmetric linear systems, </title> <booktitle> in 5th SIAM Conference on Applied Linear Algebra, </booktitle> <publisher> SIAM, </publisher> <month> June </month> <year> 1994, </year> <note> p. 140. </note>
Reference-contexts: This simplified structure allows for a simple lost pivot recovery mechanism. Recently, Davis and Duff have introduced a new multifrontal method that relaxes the assumption of a symmetric pattern [3] and has demonstrated impressive performance advantages over previous methods <ref> [19] </ref>. In addition to reducing computational requirements, this method exposes considerable parallelism [14, 15]. <p> Furthermore, these results show the worst of all test cases. Typically significantly fewer pivots were lost and the corresponding degradations in achievable parallelism were significantly less severe. 7. Conclusion. The unsymmetric-pattern multifrontal method of Davis and Duff has proven to have extremely competitive sequential performance <ref> [19] </ref> and significant parallel potential [16]. When the method is applied to sequences of identically structured matrices, the assembly DAG from the analyze-factor operation on the first matrix can be reused for factor-only operations on the subsequent matrices in the sequence.
Reference: [20] <author> S. E. Zitney, </author> <title> Sparse matrix methods for chemical process separation calculations on supercomputers, </title> <booktitle> in Proc. Supercomputing '92, </booktitle> <address> Minneapolis, MN, Nov. 1992, </address> <publisher> IEEE Computer Society Press, </publisher> <pages> pp. 414-423. </pages>
Reference-contexts: 1. Introduction. Systems of differential-algebraic equations arise in many application areas including circuit simulation, chemical engineering, magnetic resonance spectroscopy, and air pollution modeling <ref> [4, 17, 20, 22] </ref>. Methods for solving such systems frequently produce sequences of identically structured sparse matrices whose patterns can be highly unsymmetric. The LU factorization of these matrices allow their corresponding linear systems to be easily solved. <p> Performance results are provided for both sequential and parallel execution time. The three matrix sequences used for this evaluation are RDIST1, RDIST2, and RDIST3A which come from chemical engineering applications <ref> [20, 21] </ref>. Their characteristics are shown in Table 6.1.
Reference: [21] <author> S. E. Zitney and M. A. Stadtherr, </author> <title> Supercomputing strategies for the design and analysis of complex separation systems, </title> <institution> Ind. Eng. Chem. Res., </institution> <month> 32 </month> <year> (1993), </year> <pages> pp. 604-612. </pages>
Reference-contexts: Performance results are provided for both sequential and parallel execution time. The three matrix sequences used for this evaluation are RDIST1, RDIST2, and RDIST3A which come from chemical engineering applications <ref> [20, 21] </ref>. Their characteristics are shown in Table 6.1.
Reference: [22] <author> Z. Zlatev, </author> <title> Sparse matrix techniques for general matrices with real elements: Pivotal strategies, decompositions and applications in ODE software, in Sparsity and Its Applications, </title> <editor> D. J. Evans, ed., </editor> <address> Cambridge, United Kingdom: </address> <publisher> Cambridge University Press, </publisher> <year> 1985, </year> <pages> pp. 185-228. </pages> <note> Note: all University of Florida technical reports in this list of references are available in postscript form via anonymous ftp to ftp.cis.ufl.edu in the directory cis/tech-reports. </note>
Reference-contexts: 1. Introduction. Systems of differential-algebraic equations arise in many application areas including circuit simulation, chemical engineering, magnetic resonance spectroscopy, and air pollution modeling <ref> [4, 17, 20, 22] </ref>. Methods for solving such systems frequently produce sequences of identically structured sparse matrices whose patterns can be highly unsymmetric. The LU factorization of these matrices allow their corresponding linear systems to be easily solved.
References-found: 20

