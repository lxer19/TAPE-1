URL: http://www.cs.brown.edu/courses/cs227/papers/b2/caching.ps
Refering-URL: http://www.cs.brown.edu/courses/cs227/readinglist.html
Root-URL: http://www.cs.brown.edu/
Email: jmh@cs.berkeley.edu, naughton@cs.wisc.edu  
Title: Query Execution Techniques for Caching Expensive Methods  
Author: Joseph M. Hellerstein Jeffrey F. Naughton 
Date: October, 1995  
Address: 1210 W. Dayton St. Madison, WI 53706  
Affiliation: University of Wisconsin Department of Computer Sciences  
Abstract: Object-Relational and Object-Oriented DBMSs allow users to invoke time-consuming ("expensive") methods in their queries. When queries containing these expensive methods are run on data with duplicate values, the dominant part of query execution time is devoted to redundant computation, as methods are invoked repeatedly on the same value. This problem has been studied in the context of programming languages, where "memoization" is the standard solution. In the database literature, sorting has been proposed to deal with this problem. We compare these approaches along with a third solution, a variant of unary hybrid hashing which we call Hybrid Cache. We present a performance study of the three caching techniques in Illustra, which demonstrates that Hybrid Cache always dominates memoization, and significantly outperforms sorting in many instances. In particular, Hybrid Cache is always fastest for caching Boolean predicate methods, while other methods are most efficiently cached by one of Hybrid Cache or sorting, depending on the sizes of the input tuples and method output. Our comparison of sorting and Hybrid Cache provides new insights into the tradeoff between hashing and sorting for unary operations. Additionally, our Hybrid Cache algorithm includes some new optimizations for unary hybrid hashing, which can be used for other hashing applications such as grouping and duplicate elimination. We conclude with a discussion of techniques for caching multiple expensive methods in a single query, and raise some new optimization problems in choosing caching techniques for queries with expensive methods.
Abstract-found: 1
Intro-found: 1
Reference: [BC81] <author> Phillip A. Bernstein and D. W. Chiu. </author> <title> Using Semijoins to Solve Relational Queries. </title> <journal> Journal of the ACM, </journal> <volume> 28(1) </volume> <pages> 25-40, </pages> <year> 1981. </year>
Reference-contexts: Chimenti, et al. [CGK89] note that expensive selection predicates can be viewed as joins between the input relation and an infinite logical relation of input/output pairs for the selection method. In this spirit, one can think of our last optimization as forming the semi-join <ref> [BC81] </ref> of the input relation with the (infinite) Cartesian product of the (infinite) logical relations of the methods, and then re-joining the result of the semi-join with the original relation. This is depicted in Figure 14.
Reference: [Bra84] <author> Kjell Bratbergsengen. </author> <title> Hashing Methods and Relational Algebra Operations. </title> <booktitle> In Proc. 10th International Conference on Very Large Data Bases, </booktitle> <pages> pages 323-333, </pages> <address> Singapore, </address> <month> August </month> <year> 1984. </year>
Reference-contexts: The next algorithm we present makes this decision unnecessary, since it extends memoization to avoid paging. 4 Hybrid Cache The third technique we consider is unary hybrid hashing. Unary hybrid hashing has been used in the past to perform grouping for aggregation or duplicate elimination <ref> [Bra84] </ref>, but to our knowledge this paper represents the first application of the technique to the problem of caching. Unary hybrid hashing is based on the hybrid hash join algorithm [DKO + 84].
Reference: [CGK89] <author> Danette Chimenti, Ruben Gamboa, and Ravi Krishnamurthy. </author> <title> Towards an Open Architecture for LDL. </title> <booktitle> In Proc. 15th International Conference on Very Large Data Bases, </booktitle> <pages> pages 195-203, </pages> <address> Amsterdam, </address> <month> August </month> <year> 1989. </year>
Reference-contexts: Chimenti, et al. <ref> [CGK89] </ref> note that expensive selection predicates can be viewed as joins between the input relation and an infinite logical relation of input/output pairs for the selection method.
Reference: [DKO + 84] <author> David J. DeWitt, Randy H. Katz, Frank Olken, Leonard D. Shapiro, Michael R. Stonebraker, and David Wood. </author> <title> Implementation Techniques for Main Memory Database Systems. </title> <booktitle> In Proc. ACM-SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 1-8, </pages> <address> Boston, </address> <month> June </month> <year> 1984. </year>
Reference-contexts: Unary hybrid hashing has been used in the past to perform grouping for aggregation or duplicate elimination [Bra84], but to our knowledge this paper represents the first application of the technique to the problem of caching. Unary hybrid hashing is based on the hybrid hash join algorithm <ref> [DKO + 84] </ref>. We introduce some minor modifications to unary hybrid hashing, and since we are applying it to the problem of caching we call our variant Hybrid Cache. <p> This is a well-known constraint on hashing; a similar constraint applies to sorting. These constraints can be overcome by recursive application of either partitioning (for hashing) or merging (for sorting) <ref> [DKO + 84, Knu73] </ref>. Our implementation of Hybrid Cache in Illustra includes recursive partitioning to handle this situation. The number of input values v can be estimated by using stored statistics [SAC + 79] or via sampling [HOT88, HNSS95].
Reference: [GM95] <author> A. Gupta and I.S. Mumick. </author> <title> Maintenance of materialized views: Problems, techniques, </title> <journal> and applications. IEEE Data Engineering Bulletin, Special Issue on Materialized Views and Data Warehousing, </journal> <volume> 18(2) </volume> <pages> 3-18, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: Graefe provides an annotated bibliography of these ideas in Section 12.1 of his query processing survey [Gra93]. Persistent caches are akin to materialized views <ref> [GM95] </ref> or function indices [MS86, LS88] | from the point of view of a single query, they represent precomputed methods, rather than caches which are generated and used on the fly.
Reference: [Got74] <author> E. Goto. </author> <title> Monocopy and Associative Algorithms in Extended LISP. </title> <type> Technical Report 74-03, </type> <institution> Information Science Laboratory, University of Tokyo, </institution> <month> May </month> <year> 1974. </year>
Reference-contexts: These papers are orthogonal to this one in that they treat optimization issues, and assume that caching strategies are either efficient or non-existent. The programming language community long ago proposed the use of main-memory hashtables ("memoization") for caching the results of computations <ref> [Mic68, WL73, Got74, SG76] </ref>. It is natural to apply this idea in a database setting for caching expensive methods. However, as we show in this paper, memoization is an inadequate solution for the large volumes of data present in database systems.
Reference: [Gra93] <author> Goetz Graefe. </author> <title> Query Evaluation Techniques for Large Databases. </title> <journal> ACM Computing Surveys, </journal> <volume> 25(2) </volume> <pages> 73-170, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: A large body of orthogonal techniques provide persistent caches, which store method results in relations so that they can be reused across multiple queries over a period of time. Graefe provides an annotated bibliography of these ideas in Section 12.1 of his query processing survey <ref> [Gra93] </ref>. Persistent caches are akin to materialized views [GM95] or function indices [MS86, LS88] | from the point of view of a single query, they represent precomputed methods, rather than caches which are generated and used on the fly. <p> More effective (though somewhat complex) solutions to the problems of hybrid hash join have been proposed by Nakayama, et al. [NKT88]. 4.4 Sort vs. Hash Revisited In analyzing hashing and sorting, Graefe presents the interesting result that hash-based algorithms typically have "dual" sorting algorithms that perform comparably <ref> [Gra93] </ref>. However, we observe in 12 this section that one of his dualities is based on an assumption that does not apply to the problem of caching. <p> This decision can made fairly easily by using the usual cost formulas for non-recursive sorting and hashing; see, for instance, Graefe's query processing survey <ref> [Gra93] </ref>. 6 Open Issues: Caching Multiple Methods The previous sections present a detailed analysis and performance study of caching the results of a single method.
Reference: [Hel94] <author> Joseph M. Hellerstein. </author> <title> Practical Predicate Placement. </title> <booktitle> In Proc. ACM-SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 325-335, </pages> <address> Minneapolis, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: This work was funded by NSF grant IRI-9157357. 1 In previous work we have focused on query optimization techniques to appropriately place time-consuming ("expensive") predicate methods in a query plan <ref> [HS93, Hel94] </ref>. <p> Although this paper focuses on query execution techniques only, we outline directions for further research in query optimization for caches. 1.1 Related Work A increasingly large body of work has addressed the problem of query optimization in the face of expensive predicates ([CGK89], [YKY + 91], [HS93], <ref> [Hel94] </ref>, [KMPS94], etc.). These papers are orthogonal to this one in that they treat optimization issues, and assume that caching strategies are either efficient or non-existent. The programming language community long ago proposed the use of main-memory hashtables ("memoization") for caching the results of computations [Mic68, WL73, Got74, SG76]. <p> As in <ref> [Hel94] </ref>, the "expensive" method we used did not actually do any time-consuming computation; however, its results were cached as if it were truly expensive. Each algorithm that we tested caused the method to be computed exactly once per value. <p> First, the cost of caching needs to be captured in the optimizer and integrated with the predicate placement algorithm. The only previous optimization work which captured the presence of caching assumed that the cost of caching was negligible <ref> [Hel94] </ref>; this assumption may be acceptable in most cases, but this has yet to be determined. Second, the optimizer must be enhanced to choose which caching algorithm to use (if any) for different method inputs and outputs, taking into account issues of "interesting orders" [SAC + 79].
Reference: [HNSS95] <author> Peter J. Haas, Jeffrey F. Naughton, S. Seshadri, </author> <title> and Lynne Stokes. Sampling-Based Estimation of the Number of Distinct Values of an Attribute. </title> <booktitle> In Proc. 21st International Conference on Very Large Data Bases, </booktitle> <address> Zurich, </address> <month> September </month> <year> 1995. </year>
Reference-contexts: Since estimating the number of values during optimization can be difficult <ref> [HNSS95] </ref>, choosing between memoization and sorting can be tricky. The next algorithm we present makes this decision unnecessary, since it extends memoization to avoid paging. 4 Hybrid Cache The third technique we consider is unary hybrid hashing. <p> Our implementation of Hybrid Cache in Illustra includes recursive partitioning to handle this situation. The number of input values v can be estimated by using stored statistics [SAC + 79] or via sampling <ref> [HOT88, HNSS95] </ref>. Unfortunately this estimation is subject to error, so we must consider how the algorithm will behave if estimates are imperfect. If v is estimated too high, h will be too small | i.e., memory will be underutilized during the first two phases of Hybrid Cache.
Reference: [HOT88] <author> Wen-Chi Hou, Gultekin Ozsoyoglu, and Baldeao K. Taneja. </author> <title> Statistical Estimators for Relational Algebra Expressions. </title> <booktitle> In Proc. 7th ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems, </booktitle> <pages> pages 276-287, </pages> <address> Austin, </address> <month> March </month> <year> 1988. </year>
Reference-contexts: Our implementation of Hybrid Cache in Illustra includes recursive partitioning to handle this situation. The number of input values v can be estimated by using stored statistics [SAC + 79] or via sampling <ref> [HOT88, HNSS95] </ref>. Unfortunately this estimation is subject to error, so we must consider how the algorithm will behave if estimates are imperfect. If v is estimated too high, h will be too small | i.e., memory will be underutilized during the first two phases of Hybrid Cache.
Reference: [HS93] <author> Joseph M. Hellerstein and Michael Stonebraker. </author> <title> Predicate Migration: Optimizing Queries With Expensive Predicates. </title> <booktitle> In Proc. ACM-SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 267-276, </pages> <address> Washington, D.C., </address> <month> May </month> <year> 1993. </year>
Reference-contexts: This work was funded by NSF grant IRI-9157357. 1 In previous work we have focused on query optimization techniques to appropriately place time-consuming ("expensive") predicate methods in a query plan <ref> [HS93, Hel94] </ref>. <p> The problem of redundant method invocation can even arise in queries where the method is invoked on a duplicate-free input, such as the key of a relation. This is because optimization techniques such as Predicate Migration <ref> [HS93] </ref> can postpone expensive predicate methods until after joins are performed. The join operation often produces duplicate copies of values in its output; this is even possible if there are no duplicate values in either input. <p> Although this paper focuses on query execution techniques only, we outline directions for further research in query optimization for caches. 1.1 Related Work A increasingly large body of work has addressed the problem of query optimization in the face of expensive predicates ([CGK89], [YKY + 91], <ref> [HS93] </ref>, [Hel94], [KMPS94], etc.). These papers are orthogonal to this one in that they treat optimization issues, and assume that caching strategies are either efficient or non-existent. The programming language community long ago proposed the use of main-memory hashtables ("memoization") for caching the results of computations [Mic68, WL73, Got74, SG76]. <p> In this sense our work is truly orthogonal to the work on persistent caching and common subexpressions, since those approaches can coexist profitably with our work. 3 Correlated SQL subqueries can considered as a form of expensive method <ref> [HS93] </ref>. It has been deomnstrated that the magic sets rewriting can be used to speed up such subqueries [MFPR90, SPL96], even in non-recursive SQL. <p> Since hash accesses by definition have low locality for distinct input values, the operating system paging schemes manage the memory very poorly. This is demonstrated dramatically in Section 5 below. 6 3.2 Sorting: The System R Approach In <ref> [HS93] </ref> it was pointed out that SQL subqueries are a form of expensive method. The authors of the pioneering System R optimization paper [SAC + 79] proposed a scheme to avoid redundant computation of correlated subqueries on identical inputs; their idea is directly applicable to expensive methods in general.
Reference: [Ill94] <institution> Illustra Information Technologies, Inc. </institution> <note> Illustra User's Guide, Illustra Server Release 2.1, </note> <month> June </month> <year> 1994. </year>
Reference-contexts: Hybrid Cache includes some modifications to traditional unary hybrid hashing, which can be applied to grouping and duplicate elimination as well as caching. We also discuss the interaction between these modifications and hybrid hash join techniques. We implemented all three caching algorithms in the Illustra Object-Relational DBMS <ref> [Ill94] </ref>, and we present a performance study of our implementation. The study demonstrates three main results: 1. The commonly proposed memoization technique is extremely inefficient for relations with many values, and its performance is dominated by Hybrid Cache. 2. <p> SQL3's create function command allows methods to be declared variant or not variant, with variant as the default. A variant function is uncacheable; a function that is not variant is assumed to have infinite cache life. SQL3 makes no syntactic provisions for identifying per-statement or per-transaction cache lives <ref> [ISO94, Ill94] </ref>. However, typical time-independent data analysis and manipulation methods can be registered as not variant in an SQL3 system, and hence can be cached. 2.3 Environment for Performance Study Our performance study was run on a development version of Illustra, based on the publicly available version 2.4.1.
Reference: [ISO94] <author> ISO. </author> <title> ISO ANSI Working Draft: Database Language SQL (SQL3) TC X3H2-94-331; ISO/IEC JTC1/SC21/WG3, </title> <year> 1994. </year>
Reference-contexts: SQL3's create function command allows methods to be declared variant or not variant, with variant as the default. A variant function is uncacheable; a function that is not variant is assumed to have infinite cache life. SQL3 makes no syntactic provisions for identifying per-statement or per-transaction cache lives <ref> [ISO94, Ill94] </ref>. However, typical time-independent data analysis and manipulation methods can be registered as not variant in an SQL3 system, and hence can be cached. 2.3 Environment for Performance Study Our performance study was run on a development version of Illustra, based on the publicly available version 2.4.1.
Reference: [KMPS94] <author> Alfons Kemper, Guido Moerkotte, Klaus Peithner, and Michael Steinbrunn. </author> <title> Optimizing Disjunctive Queries with Expensive Predicates. </title> <booktitle> In Proc. ACM-SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 336-347, </pages> <address> Minneapolis, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: Although this paper focuses on query execution techniques only, we outline directions for further research in query optimization for caches. 1.1 Related Work A increasingly large body of work has addressed the problem of query optimization in the face of expensive predicates ([CGK89], [YKY + 91], [HS93], [Hel94], <ref> [KMPS94] </ref>, etc.). These papers are orthogonal to this one in that they treat optimization issues, and assume that caching strategies are either efficient or non-existent. The programming language community long ago proposed the use of main-memory hashtables ("memoization") for caching the results of computations [Mic68, WL73, Got74, SG76]. <p> However, as we show in this paper, memoization is an inadequate solution for the large volumes of data present in database systems. Kemper, Steinbrunn, et al. have proposed "bypass" techniques for optimizing and executing disjunctive queries <ref> [KMPS94, SPMK95] </ref>. This work alleviates some of the problems of redundant computation in disjunctive queries, but does not present a solution to the problem of redundant method invocation in general | for example, it does not avoid duplicate method invocation for the simple thumbnail example above.
Reference: [Knu73] <author> Donald Ervin Knuth. </author> <title> Sorting and Searching, </title> <booktitle> volume 3 of The Art of Computer Programming. </booktitle> <publisher> Addison-Wesley Publishing Co., </publisher> <year> 1973. </year>
Reference-contexts: This is a well-known constraint on hashing; a similar constraint applies to sorting. These constraints can be overcome by recursive application of either partitioning (for hashing) or merging (for sorting) <ref> [DKO + 84, Knu73] </ref>. Our implementation of Hybrid Cache in Illustra includes recursive partitioning to handle this situation. The number of input values v can be estimated by using stored statistics [SAC + 79] or via sampling [HOT88, HNSS95]. <p> Graefe's analysis of the situation leads him to a modification of sorting via replacement selection <ref> [Knu73] </ref>, which allows sort-based grouping and duplicate elimination to utilize an amount of memory closer to the number of tuples in its output rather than that in its input.
Reference: [LS88] <author> C. Lynch and M. Stonebraker. </author> <title> Extended User-Defined Indexing with Application to Textual Databases. </title> <booktitle> In Proc. 14th International Conference on Very Large Data Bases, </booktitle> <pages> pages 306-317, </pages> <address> Los Angeles, </address> <month> August-September </month> <year> 1988. </year> <month> 25 </month>
Reference-contexts: Graefe provides an annotated bibliography of these ideas in Section 12.1 of his query processing survey [Gra93]. Persistent caches are akin to materialized views [GM95] or function indices <ref> [MS86, LS88] </ref> | from the point of view of a single query, they represent precomputed methods, rather than caches which are generated and used on the fly. Persistent caches are used in a way that is analogous to techniques for avoiding recomputation of common relational subexpressions [Sel88].
Reference: [MFPR90] <author> Inderpal Singh Mumick, Sheldon J. Finkelstein, Hamid Pirahesh, and Raghu Ramakrishnan. </author> <title> Magic is Relevant. </title> <booktitle> In Proc. ACM-SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 247-258, </pages> <address> Atlantic City, </address> <month> May </month> <year> 1990. </year>
Reference-contexts: It has been deomnstrated that the magic sets rewriting can be used to speed up such subqueries <ref> [MFPR90, SPL96] </ref>, even in non-recursive SQL. <p> for expensive methods as the techniques presented in this paper: the cost of forming the duplicate-free input set is equivalent to the cost of building a method cache, and on top of this cost magic rewriting requires an additional join and possibly also an additional materialization of the "supplementary" input <ref> [MFPR90] </ref>. For expensive subqueries, there are tradeoffs between magic and caching.
Reference: [Mic68] <author> D. Michie. </author> <title> "Memo" Functions and Machine Learning. </title> <journal> Nature, </journal> (218):19-22, April 1968. 
Reference-contexts: These papers are orthogonal to this one in that they treat optimization issues, and assume that caching strategies are either efficient or non-existent. The programming language community long ago proposed the use of main-memory hashtables ("memoization") for caching the results of computations <ref> [Mic68, WL73, Got74, SG76] </ref>. It is natural to apply this idea in a database setting for caching expensive methods. However, as we show in this paper, memoization is an inadequate solution for the large volumes of data present in database systems. <p> In the programming language and logic programming literature, this technique is often referred to as memoization <ref> [Mic68] </ref>. The algorithm is sketched in Figure 1. For our advertisements example, this hashtable would be keyed on a hash function of product image values (which might be object identifiers or file names), and would store (product image,thumbnail) pairs.
Reference: [ML86] <author> L. F. Mackert and G. M. Lohman. </author> <title> R* Optimizer Validation and Performance Evaluation for Distributed Queries. </title> <booktitle> In Proc. 12th International Conference on Very Large Data Bases, </booktitle> <pages> pages 149-159, </pages> <address> Kyoto, </address> <month> August </month> <year> 1986. </year>
Reference-contexts: In distributed systems, semi-joins minimize communication costs. In method caching, this semi-join-like technique minimizes staging costs. In both cases, the benefits of semi-joins need to be balanced against their costs, namely scanning the input relation twice, removing duplicates, and doing an additional join <ref> [ML86] </ref>. Note that these costs certainly outweigh the benefit derived by a single cache node, and thus semi-join techniques can only be beneficial for multi-method queries. 7 Conclusions and Future Work This paper studies the problem of avoiding redundant method invocation during query processing.
Reference: [MS86] <author> D. Maier and J. Stein. </author> <title> Indexing in an Object-Oriented DBMS. </title> <editor> In Klaus R. Dittrich and Umesh-war Dayal, editors, </editor> <booktitle> Proc. Workshop on Object-Oriented Database Systems, </booktitle> <pages> pages 171-182, </pages> <address> Asilo-mar, </address> <month> September </month> <year> 1986. </year>
Reference-contexts: Graefe provides an annotated bibliography of these ideas in Section 12.1 of his query processing survey [Gra93]. Persistent caches are akin to materialized views [GM95] or function indices <ref> [MS86, LS88] </ref> | from the point of view of a single query, they represent precomputed methods, rather than caches which are generated and used on the fly. Persistent caches are used in a way that is analogous to techniques for avoiding recomputation of common relational subexpressions [Sel88].
Reference: [NKT88] <author> Masaya Nakayama, Masaru Kitsuregawa, and Mikio Takagi. </author> <title> Hash-Partitioned Join Method Using Dynamic Destaging Strategy. </title> <booktitle> In Proc. 14th International Conference on Very Large Data Bases, </booktitle> <pages> pages 468-477, </pages> <address> Los Angeles, </address> <month> August-September </month> <year> 1988. </year>
Reference-contexts: in the building relation, or chooses a poor hash function, the first bucket of the building relation is likely to be too large and have to be paged, resulting in as much as a random I/O operation (seek and write) per tuple of the first bucket of the probing relation <ref> [NKT88] </ref>. By contrast, Hybrid Cache never over-utilizes memory, since its first bucket is dynamically grown to the appropriate size. Both algorithms can underuti-lize memory for the first bucket if estimates are incorrect, but this is less dangerous than over-utilizing memory, which results in paging. <p> More effective (though somewhat complex) solutions to the problems of hybrid hash join have been proposed by Nakayama, et al. <ref> [NKT88] </ref>. 4.4 Sort vs. Hash Revisited In analyzing hashing and sorting, Graefe presents the interesting result that hash-based algorithms typically have "dual" sorting algorithms that perform comparably [Gra93].
Reference: [PHH92] <author> Hamid Pirahesh, Joseph M. Hellerstein, and Waqar Hasan. </author> <title> Extensible/Rule-Based Query Rewrite Optimization in Starburst. </title> <booktitle> In Proc. ACM-SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 39-48, </pages> <address> San Diego, </address> <month> June </month> <year> 1992. </year>
Reference-contexts: methods AS SELECT thumbnail (product image), product image, ad text FROM vals WHERE ad text similar '.*optic.*'; SELECT methods.thumbnail FROM advertisements,methods WHERE advertisements.ad text = methods.ad text AND advertisements.product image = methods.product image; Such rewriting can be done by the user, or by a system with a query rewrite engine <ref> [PHH92] </ref>. Chimenti, et al. [CGK89] note that expensive selection predicates can be viewed as joins between the input relation and an infinite logical relation of input/output pairs for the selection method.
Reference: [SAC + 79] <author> Patricia G. Selinger, M. Astrahan, D. Chamberlin, Raymond Lorie, and T. Price. </author> <title> Access Path Selection in a Relational Database Management System. </title> <booktitle> In Proc. ACM-SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 22-34, </pages> <address> Boston, </address> <month> June </month> <year> 1979. </year>
Reference-contexts: This is demonstrated dramatically in Section 5 below. 6 3.2 Sorting: The System R Approach In [HS93] it was pointed out that SQL subqueries are a form of expensive method. The authors of the pioneering System R optimization paper <ref> [SAC + 79] </ref> proposed a scheme to avoid redundant computation of correlated subqueries on identical inputs; their idea is directly applicable to expensive methods in general. <p> If they are the same, the previous evaluation result can be used again. In some cases, it might even pay to sort the referenced relation on the referenced column in order to avoid re-evaluating subqueries unnecessarily <ref> [SAC + 79] </ref>. In essence, the System R solution is to sort the input relation on the input columns (if it is not already so sorted), and then maintain a cache of only the last input/output pair for the method. <p> These constraints can be overcome by recursive application of either partitioning (for hashing) or merging (for sorting) [DKO + 84, Knu73]. Our implementation of Hybrid Cache in Illustra includes recursive partitioning to handle this situation. The number of input values v can be estimated by using stored statistics <ref> [SAC + 79] </ref> or via sampling [HOT88, HNSS95]. Unfortunately this estimation is subject to error, so we must consider how the algorithm will behave if estimates are imperfect. <p> Second, the optimizer must be enhanced to choose which caching algorithm to use (if any) for different method inputs and outputs, taking into account issues of "interesting orders" <ref> [SAC + 79] </ref>. Third, the optimizer must consider cache sharing, cache ordering, and semi-join-like techniques. As an additional challenge, it would be interesting to integrate the caching ideas in this paper with previous work on persistent caches, function indices, and common subexpression identification.
Reference: [Sel88] <author> Timos Sellis. </author> <title> Multiple Query Optimization. </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 13(1) </volume> <pages> 23-52, </pages> <month> March </month> <year> 1988. </year>
Reference-contexts: Persistent caches are used in a way that is analogous to techniques for avoiding recomputation of common relational subexpressions <ref> [Sel88] </ref>. In order to generate a persistent cache, one may have to compute a method over an input relation with duplicate values; in this scenario, the techniques of this paper can speed the generation of the persistent cache.
Reference: [SG76] <author> M. Sassa and E. Goto. </author> <title> A Hashing Method For Fast Set Operations. </title> <journal> Information Processing Letters, </journal> <volume> 5(2) </volume> <pages> 31-34, </pages> <month> June </month> <year> 1976. </year>
Reference-contexts: These papers are orthogonal to this one in that they treat optimization issues, and assume that caching strategies are either efficient or non-existent. The programming language community long ago proposed the use of main-memory hashtables ("memoization") for caching the results of computations <ref> [Mic68, WL73, Got74, SG76] </ref>. It is natural to apply this idea in a database setting for caching expensive methods. However, as we show in this paper, memoization is an inadequate solution for the large volumes of data present in database systems.
Reference: [SHR + 95] <author> Praveen Seshadri, Joseph M. Hellerstein, Raghu Ramakrishnan, Hamid Pirahesh, and T.Y. Cliff Leung. </author> <title> Cost-Based Optimization for Magic. </title> <note> Submitted for publication, </note> <year> 1995. </year>
Reference-contexts: For expensive subqueries, there are tradeoffs between magic and caching. Seshadri et al. propose new techniques for cost-based optimization of magic <ref> [SHR + 95] </ref>, which can be extended to the problem of choosing whether to use magic or caching for subqueries in a query plan. 2 Background 2.1 To Cache or Not to Cache? Methods with duplicate-free inputs derive no benefit from caching, and one should not pay for the overhead of
Reference: [SPL96] <author> Praveen Seshadri, Hamid Pirahesh, and T.Y. Cliff Leung. </author> <title> Decorrelating Complex Queries. </title> <booktitle> In Proc. 12th IEEE International Conference on Data Engineering, </booktitle> <address> New Orleans, </address> <year> 1996. </year>
Reference-contexts: It has been deomnstrated that the magic sets rewriting can be used to speed up such subqueries <ref> [MFPR90, SPL96] </ref>, even in non-recursive SQL.
Reference: [SPMK95] <author> Michael Steinbrunn, Klaus Peithner, Guido Moerkotte, and Alfons Kemper. </author> <title> Bypassing Joins in Disjunctive Queries. </title> <booktitle> In Proc. 21st International Conference on Very Large Data Bases, </booktitle> <address> Zurich, </address> <month> September </month> <year> 1995. </year>
Reference-contexts: However, as we show in this paper, memoization is an inadequate solution for the large volumes of data present in database systems. Kemper, Steinbrunn, et al. have proposed "bypass" techniques for optimizing and executing disjunctive queries <ref> [KMPS94, SPMK95] </ref>. This work alleviates some of the problems of redundant computation in disjunctive queries, but does not present a solution to the problem of redundant method invocation in general | for example, it does not avoid duplicate method invocation for the simple thumbnail example above.
Reference: [WL73] <author> R. Waldinger and K. N. Levitt. </author> <title> Reasoning About Programs. </title> <booktitle> In Symposium on Principles of Programming Languages, </booktitle> <year> 1973. </year>
Reference-contexts: These papers are orthogonal to this one in that they treat optimization issues, and assume that caching strategies are either efficient or non-existent. The programming language community long ago proposed the use of main-memory hashtables ("memoization") for caching the results of computations <ref> [Mic68, WL73, Got74, SG76] </ref>. It is natural to apply this idea in a database setting for caching expensive methods. However, as we show in this paper, memoization is an inadequate solution for the large volumes of data present in database systems.
Reference: [YKY + 91] <author> Kenichi Yajima, Hiroyuki Kitagawa, Kazunori Yamaguchi, Nobuo Ohbo, and Yuzura Fujiwara. </author> <title> Optimization of Queries Including ADT Functions. </title> <booktitle> In Proc. 2nd International Symposium on Database Systems for Advanced Applications, </booktitle> <pages> pages 366-373, </pages> <address> Tokyo, </address> <month> April </month> <year> 1991. </year> <month> 26 </month>
Reference-contexts: Although this paper focuses on query execution techniques only, we outline directions for further research in query optimization for caches. 1.1 Related Work A increasingly large body of work has addressed the problem of query optimization in the face of expensive predicates ([CGK89], <ref> [YKY + 91] </ref>, [HS93], [Hel94], [KMPS94], etc.). These papers are orthogonal to this one in that they treat optimization issues, and assume that caching strategies are either efficient or non-existent.
References-found: 30

