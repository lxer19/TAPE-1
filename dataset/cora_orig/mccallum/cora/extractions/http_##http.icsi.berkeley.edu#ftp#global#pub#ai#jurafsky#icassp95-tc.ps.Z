URL: http://http.icsi.berkeley.edu/ftp/global/pub/ai/jurafsky/icassp95-tc.ps.Z
Refering-URL: http://http.icsi.berkeley.edu/ftp/global/pub/ai/jurafsky/
Root-URL: http://http.icsi.berkeley.edu
Email: fjurafsky,wooters,tajchman,jsegal,stolcke,fosler,morgang@icsi.berkeley.edu  
Title: USING A STOCHASTIC CONTEXT-FREE GRAMMAR AS A LANGUAGE MODEL FOR SPEECH RECOGNITION  
Author: Daniel Jurafsky, Chuck Wooters Jonathan Segal, Andreas Stolcke Eric Fosler, Gary Tajchman and Nelson Morgan 
Address: 1947 Center Street, Suite 600 Berkeley, CA 94704, USA  Berkeley  
Affiliation: International Computer Science Institute  University of California at  
Note: To appear in ICASSP-95  
Abstract: This paper describes a number of experiments in adding new grammatical knowledge to the Berkeley Restaurant Project (BeRP), our medium-vocabulary (1300 word), speaker-independent, spontaneous continuous-speech understanding system (Jurafsky et al. 1994). We describe an algorithm for using a probabilistic Earley parser and a stochastic context-free grammar (SCFG) to generate word transition probabilities at each frame for a Viterbi decoder. We show that using an SCFG as a language model improves word error rate from 34.6% (bigram) to 29.6% (SCFG), and semantic sentence recognition error from from 39.0% (bigram) to 34.1% (SCFG). In addition, we get a further reduction to 28.8% word error by mixing the bigram and SCFG LMs. We also report on our preliminary results from using discourse-context information in the LM. 
Abstract-found: 1
Intro-found: 1
Reference: <author> GODDEAU, DAVID. </author> <year> 1992. </year> <title> Using probabilistic shift-reduce parsing in speech recognition systems. </title> <booktitle> In ICSLP-92, </booktitle> <address> I.321324, Banff, Canada. </address>
Reference: <author> GOODINE, DAVID, STEPHANIE SENEFF, LYNETTE HIRSCHMAN, & MICHAEL PHILLIPS. </author> <year> 1991. </year> <title> Full integration of speech and language understanding in the MIT spoken language system. </title> <booktitle> In Proceedings of Eurospeech 91, 2426, </booktitle> <address> Genova, Italy. </address>
Reference: <author> HAUENSTEIN, ANDREAS, & HANS H. WEBER. </author> <year> 1994. </year> <title> An investigation of tightly coupled time synchronous speech language interfaces using a unification grammar. </title> <booktitle> In Proceedings of AAAI-94 Workshop on Integration of Natural Language and Speech Processing, </booktitle> <pages> 42-49. </pages>
Reference: <author> JELINEK, FREDERICK, & JOHN D. LAFFERTY. </author> <year> 1991. </year> <title> Computation of the probability of initial substring generation by stochastic context-free grammars. </title> <note> Computational Linguistics 17.315-323. </note>
Reference: <author> JURAFSKY, DANIEL, CHUCK WOOTERS, GARY TAJCHMAN, JONATHAN SEGAL, ANDREAS STOLCKE, ERIC FOSLER, & NELSON MORGAN. </author> <year> 1994. </year> <title> The Berkeley restaurant project. </title> <booktitle> In ICSLP-94, </booktitle> <address> Yokohama, Japan. </address>
Reference-contexts: 1947 Center Street, Suite 600 Berkeley, CA 94704, USA & University of California at Berkeley fjurafsky,wooters,tajchman,jsegal,stolcke,fosler,morgang@icsi.berkeley.edu ABSTRACT This paper describes a number of experiments in adding new grammatical knowledge to the Berkeley Restaurant Project (BeRP), our medium-vocabulary (1300 word), speaker-independent, spontaneous continuous-speech understanding system <ref> (Jurafsky et al. 1994) </ref>. We describe an algorithm for using a probabilistic Earley parser and a stochastic context-free grammar (SCFG) to generate word transition probabilities at each frame for a Viterbi decoder.
Reference: <author> KITA, KENJI, & WAYNE H. WARD. </author> <year> 1991. </year> <title> Incorporating LR parsing into SPHINX. </title> <booktitle> In IEEE ICASSP-91, </booktitle> <address> I.269-272. </address>
Reference: <author> MOORE, ROBERT, FERNANDO PEREIRA, & HY MURVEIT. </author> <year> 1989. </year> <title> Integrating speech and natural-languageprocessing. </title> <booktitle> In Proceedings DARPA Speech and Natural Language Workshop, </booktitle> <pages> 243247. </pages>
Reference: <author> STOLCKE, ANDREAS. </author> <year> 1993. </year> <title> An efficient probabilistic context-free parsing algorithm that computes prefix probabilities. </title> <type> Technical Report TR-93-065, </type> <institution> International Computer Science Institute, Berkeley, CA. </institution> <note> To appear in Computational Linguistics. </note> , & <author> JONATHAN SEGAL. </author> <year> 1994. </year> <title> Precise n-gram probabilities from stochastic context-free grammars. </title> <booktitle> In Proceedings of the 32nd ACL, </booktitle> <pages> 74-79, </pages> <address> Las Cruces, NM. </address>
Reference-contexts: LR parser to actually produce word-transition probabilities. fl Currently at Dept. of Defense y Currently at SRI International z Currently at Voice Processing Corp, 1 Main St, Cambridge, MA 02142: tajchman@vpro.com Our tight coupling model extends these models to general SCFGs by augmenting a probabilistic version of the Earley algorithm <ref> (Stolcke 1993) </ref> to compute word transition probabilities from an SCFG. The system we have augmented, the BeRP system, is a speech understanding system which answers questions about restaurants in the city of Berkeley, California, inspired by earlier consultants like VOYAGER (Zue et al. 1991).
Reference: <author> WOOTERS, CHARLES C., </author> <year> 1993. </year> <title> Lexical Modeling in a Speaker Independent Speech Understanding System. </title> <institution> Berkeley, CA: University of California dissertation. </institution> <note> available as ICSI TR-92-062. </note>
Reference: <author> ZUE, VICTOR, JAMES GLASS, DAVID GOODINE, HONG LEUNG, MICHAEL PHILLIPS, JOSEPH POLIFRONI, & STEPHANIE SENEFF. </author> <year> 1991. </year> <title> Integration of speech recognition and natural language processing in the MIT VOYAGER system. </title> <booktitle> In IEEE ICASSP-91, </booktitle> <address> I.713-716. </address>
Reference-contexts: The system we have augmented, the BeRP system, is a speech understanding system which answers questions about restaurants in the city of Berkeley, California, inspired by earlier consultants like VOYAGER <ref> (Zue et al. 1991) </ref>. BeRP consists of a RASTA-PLP feature extractor, a multilayer perceptron (MLP) phonetic probability estimator, a Viterbi decoder, an HMM lexicon, a natural language interpreter which incorporates a stochastic context-free grammar, and a database of restaurants. The SCFG used in BeRP consists of 1389 hand-written context-free rules.
References-found: 10

