URL: http://www.eecs.umich.edu/PPP/ISCA93.ps
Refering-URL: http://www.eecs.umich.edu/PPP/publist.html
Root-URL: http://www.cs.umich.edu
Title: Abstract The MACS performance model introduced here can be applied to a Machine and Application
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> D. Windheiser and W. Jalby. </author> <title> Behavioral Characterization of Decoupled Access/Execute Architectures, </title> <booktitle> Proceedings of the International Conference on Supercomputing 1991 </booktitle>
Reference-contexts: In contrast, the peak floating point performance claimed for a machine (an M bound) bounds the minimum number of cycles per floating point operation (CPF) ever attained by any application. Total application performance measurements are contrasted with these bounds. We also employ A/X performance measurements <ref> [1] </ref> by which actual performance is measured with floating-point or memory accessing operations removed from the code. Ascending through this hierarchy of models and measurements refines a machine's best possible performance on an application by successively adding constraints on its performance. <p> With this understanding, performance optimization can proceed in a systematic and goaldirected manner to minimize the gap between delivered and deliverable performance. The MACS models are improvements of models originally developed for the Cray vector supercomputer systems [2] [3], the Decoupled Access-Execute (DAE) architecture Astronautics ZS-1 <ref> [1] </ref> [4], and the superscalar IBM RS/ 6000 [4] [5]. We have significantly expanded the functionality of this general performance modeling approach, and illustrate its utility with a detailed case study of the Convex C-240 vector mini-supercomputer [6] [7]. <p> Additional information on the potential performance of an application may be gleaned by measuring the actual performance of modified versions of the application. A logical division of the code into memory access operations and floating point operations suggests itself naturally. <ref> [1] </ref> This view springs from the Decoupled Access Execute (DAE) view of computing as two distinct concurrent processes. The access process ( ) is responsible for ac cessing memory. The execute process ( ), is responsible for executing functional operations on program data.
Reference: [2] <author> J-H. Tang, E. S. Davidson, and J. Tong. </author> <title> Polycyclic Vector Scheduling vs. Chaining on 1-Port Vector Supercomputers, </title> <booktitle> Proceedings of Supercomputing 1988 Conference , pp. </booktitle> <pages> 122-129, </pages> <month> November, </month> <year> 1988. </year>
Reference-contexts: With this understanding, performance optimization can proceed in a systematic and goaldirected manner to minimize the gap between delivered and deliverable performance. The MACS models are improvements of models originally developed for the Cray vector supercomputer systems <ref> [2] </ref> [3], the Decoupled Access-Execute (DAE) architecture Astronautics ZS-1 [1] [4], and the superscalar IBM RS/ 6000 [4] [5]. We have significantly expanded the functionality of this general performance modeling approach, and illustrate its utility with a detailed case study of the Convex C-240 vector mini-supercomputer [6] [7]. <p> the IBM RS/6000, common bottleneck units include the instruction issue unit, the memory interface (load/store) unit, the floating point arithmetic unit (additions/multiplications), and a dependence pseudo-unit to model loop-carried dependence. [4] For vector machines such as the Cray-1, the instruction issue unit is not a bottleneck and can be ignored. <ref> [2] </ref> [3] No true loop-carried dependence cycle appears in the ten LFKs of the case study workload and most memory accesses are unit stride. We thus focus our model of the Convex C-240 exclusively on bottlenecks caused by operations in the vector load/store, add, and multiply function pipes.
Reference: [3] <author> J-H. Tang and E. S. Davidson. </author> <title> An Evaluation of Cray-1 and Cray X-MP Performance on Vectorizable Liver-more Fortran Kernels, </title> <booktitle> Proceedings of the 1988 International Conference on Supercomputing, </booktitle> <month> July, </month> <year> 1988. </year>
Reference-contexts: With this understanding, performance optimization can proceed in a systematic and goaldirected manner to minimize the gap between delivered and deliverable performance. The MACS models are improvements of models originally developed for the Cray vector supercomputer systems [2] <ref> [3] </ref>, the Decoupled Access-Execute (DAE) architecture Astronautics ZS-1 [1] [4], and the superscalar IBM RS/ 6000 [4] [5]. We have significantly expanded the functionality of this general performance modeling approach, and illustrate its utility with a detailed case study of the Convex C-240 vector mini-supercomputer [6] [7]. <p> IBM RS/6000, common bottleneck units include the instruction issue unit, the memory interface (load/store) unit, the floating point arithmetic unit (additions/multiplications), and a dependence pseudo-unit to model loop-carried dependence. [4] For vector machines such as the Cray-1, the instruction issue unit is not a bottleneck and can be ignored. [2] <ref> [3] </ref> No true loop-carried dependence cycle appears in the ten LFKs of the case study workload and most memory accesses are unit stride. We thus focus our model of the Convex C-240 exclusively on bottlenecks caused by operations in the vector load/store, add, and multiply function pipes. <p> Chaining on the Convex C-240 has some inherent limitations, but it appears to be much more flexible than the Cray-1 or even the CrayXMP. <ref> [3] </ref> A chime can include at most one vector operation on each of the three pipelines; regardless of dependence, chimes are also limited by which vector registers are utilized.
Reference: [4] <author> W. MangioneSmith, S. G. Abraham, </author> <title> E.S. Davidson, Architectural vs. Delivered Performance of the IBM RS/6000 and the Astronautics ZS-1, </title> <booktitle> Computer 46, </booktitle> <month> January, </month> <year> 1991. </year>
Reference-contexts: With this understanding, performance optimization can proceed in a systematic and goaldirected manner to minimize the gap between delivered and deliverable performance. The MACS models are improvements of models originally developed for the Cray vector supercomputer systems [2] [3], the Decoupled Access-Execute (DAE) architecture Astronautics ZS-1 [1] <ref> [4] </ref>, and the superscalar IBM RS/ 6000 [4] [5]. We have significantly expanded the functionality of this general performance modeling approach, and illustrate its utility with a detailed case study of the Convex C-240 vector mini-supercomputer [6] [7]. <p> The MACS models are improvements of models originally developed for the Cray vector supercomputer systems [2] [3], the Decoupled Access-Execute (DAE) architecture Astronautics ZS-1 [1] <ref> [4] </ref>, and the superscalar IBM RS/ 6000 [4] [5]. We have significantly expanded the functionality of this general performance modeling approach, and illustrate its utility with a detailed case study of the Convex C-240 vector mini-supercomputer [6] [7]. <p> The performance models are Superscalar machines such as the IBM RS/6000 mimic chaining in single-port vector machines by employing combined multiply-add instruc tions which can be issued simultaneously with one memory load or store (with address update), and test and branch. <ref> [4] </ref> [5] constructed using selected parameters of the machine and static analysis of the high-level application code (A) of interest, the compiler-generated workload (C), and the sched uling (S) of the workload by the compiler. <p> In scalar machines such as the Astronautics ZS-1 and the IBM RS/6000, common bottleneck units include the instruction issue unit, the memory interface (load/store) unit, the floating point arithmetic unit (additions/multiplications), and a dependence pseudo-unit to model loop-carried dependence. <ref> [4] </ref> For vector machines such as the Cray-1, the instruction issue unit is not a bottleneck and can be ignored. [2] [3] No true loop-carried dependence cycle appears in the ten LFKs of the case study workload and most memory accesses are unit stride.
Reference: [5] <author> W. MangioneSmith, T.P. Shih, S. G. Abraham and E. S. Davidson. </author> <title> Approaching a Machine-Application Bound in Delivered Performance on Scientific Code, </title> <journal> IEEE Proceedings Special Issue on Performance Evaluation, </journal> <note> to appear September, </note> <year> 1993. </year>
Reference-contexts: The MACS models are improvements of models originally developed for the Cray vector supercomputer systems [2] [3], the Decoupled Access-Execute (DAE) architecture Astronautics ZS-1 [1] [4], and the superscalar IBM RS/ 6000 [4] <ref> [5] </ref>. We have significantly expanded the functionality of this general performance modeling approach, and illustrate its utility with a detailed case study of the Convex C-240 vector mini-supercomputer [6] [7]. <p> The performance models are Superscalar machines such as the IBM RS/6000 mimic chaining in single-port vector machines by employing combined multiply-add instruc tions which can be issued simultaneously with one memory load or store (with address update), and test and branch. [4] <ref> [5] </ref> constructed using selected parameters of the machine and static analysis of the high-level application code (A) of interest, the compiler-generated workload (C), and the sched uling (S) of the workload by the compiler. <p> The conspicuous t MACS gap raises an appropriate warning flag for this loop. Indead, this loop has significant outer loop overhead, nonuniform memory access strides, and difficulty in vectorizing due to its multiple exits. Outer loop overhead and scalar code could be modeled as in <ref> [5] </ref>. LFK3,9,10: The small gap in Table 4 between t indicates that 86% to 91% of the ideally deliv erable performance has been achieved. t MACS explains 1/3 to 1/2 of the t gap.
Reference: [6] <institution> CONVEX Theory of Operation (C200 Series), CONVEX Computer Corporation Document No. 081-005030-000, </institution> <note> Second Edition, </note> <month> September </month> <year> 1990. </year>
Reference-contexts: We have significantly expanded the functionality of this general performance modeling approach, and illustrate its utility with a detailed case study of the Convex C-240 vector mini-supercomputer <ref> [6] </ref> [7]. As with all vector machines, the delivered performance of the Convex C-240 on a wellvectorized scientific code is primarily related to the efficiency of implementation of inner loops, the architectural flexibility, and the bandwidths and latencies of the machine implementation. <p> As a result, a chime including a vector memory access cannot span a scalar memory access instruction. The chime will be terminated just before the scalar or vector memory reference instruction, whichever comes later. A new chime will begin with the next vector instruction. Although it is unclear from <ref> [6] </ref> [7], some vector instructions utilizing a scalar register as an operand may exhibit resource contention with purely scalar instructions. This effect was not observed in the loops we studied. i 3.4.
Reference: [7] <institution> CONVEX Architecture Reference (C200 Series), CONVEX Computer Corporation Document No. </institution> <address> 081-009330-000, Fifth Edition, </address> <month> September </month> <year> 1990. </year>
Reference-contexts: We have significantly expanded the functionality of this general performance modeling approach, and illustrate its utility with a detailed case study of the Convex C-240 vector mini-supercomputer [6] <ref> [7] </ref>. As with all vector machines, the delivered performance of the Convex C-240 on a wellvectorized scientific code is primarily related to the efficiency of implementation of inner loops, the architectural flexibility, and the bandwidths and latencies of the machine implementation. <p> These bounds thus produce performance goals to strive for, but better explanations of delivered performance require assessing schedule-specific phenomena, and a more detailed machine model. Specially constructed calibration loops were used to verify specific aspects of machine performance and to confirm and clarify the start-up overheads claimed in <ref> [7] </ref>. Calibration loops are simple test loops constructed specifically for evaluating such parameters for a particular machine when detailed knowledge of the machine implementation or its minimum specifications is unavailable or needs to be confirmed. A similar approach is used in [9][10] to characterize memory hierarchy performance. <p> To achieve a a. The extended number of cycles for a vector divide instruction may be masked by other instructions if no resource conflict exists. b. It is claimed in <ref> [7] </ref> that for vector reduction, Z = 1.0. According to Patrick McGehearty at Convex Computer Corporation, Z tor reduction instructions. Calibration loops determined that for vector reduction Z ranged between 1.39 and 1.43. For purposes of the MACS bounds equations, Z was set conservatively at 1.35. <p> The vector registers -v0, v4- are a vector register pair, as are -v1, v5-, -v2, v6-, and -v3, v7-. The following example sequence of operations will not execute in the same chime since there are more than two read references to the vector pair -v2, v6-. <ref> [7] </ref> add.d v2,v6,v6; V6 := V2 + V6 (14) Likewise, the following sequence of operations will not execute in the same chime since there is more than one write reference to the vector pair -v2, v6-. [7] add.d v1,v0,v2; V2 := V1 + V0 (16) If scalar instructions are interspersed among <p> since there are more than two read references to the vector pair -v2, v6-. <ref> [7] </ref> add.d v2,v6,v6; V6 := V2 + V6 (14) Likewise, the following sequence of operations will not execute in the same chime since there is more than one write reference to the vector pair -v2, v6-. [7] add.d v1,v0,v2; V2 := V1 + V0 (16) If scalar instructions are interspersed among vector instructions, chimes of vector instructions will often mask the scalar instructions as there is no resource contention between the ASU and the VP. <p> The chime will be terminated just before the scalar or vector memory reference instruction, whichever comes later. A new chime will begin with the next vector instruction. Although it is unclear from [6] <ref> [7] </ref>, some vector instructions utilizing a scalar register as an operand may exhibit resource contention with purely scalar instructions. This effect was not observed in the loops we studied. i 3.4.
Reference: [8] <author> F. H. McMahon, </author> <title> The Livermore Fortran Kernels: A Computer Test of the Numerical Performance Range, </title> <type> Technical Report UCRL-5375, </type> <institution> Lawrence Livermore National Laboratory, </institution> <month> December </month> <year> 1986. </year>
Reference-contexts: Our performance study of the Convex C-240 focuses on modeling the steady-state performance of the vector processor on vectorized inner loops, which is the first portion of the code to optimize for running a well-suited application on a vector machine. Ten of the Lawrence Livermore Fortran Kernels (LFKs) <ref> [8] </ref> are used as workloads in this case study. This benchmark set contains a variety of inner loops, each small enough to be considered in detail, yet represen tative of many vectorizable scientific codes. Hierarchical Performance Modeling with MACS: A Case Study of the Convex C-240 Eric L.
Reference: [9] <author> K. Gallivan, D. Gannon, W. Jalby, A. Malony, and H. Wijshoff, </author> <title> Behavioral characterization of multiprocessor memory systems, </title> <booktitle> Proceedings of the 1989 ACM SIGMETRICS Conference on Measuring and Modeling Computer Systems, </booktitle> <pages> pp. 79-89, </pages> <publisher> ACM Press, </publisher> <address> New York, </address> <year> 1989. </year>
Reference: [10] <author> K. Gallivan, W. Jalby, A. Malony, and H. Wijshoff, </author> <title> Performance Prediction of Loop Constructs on Multiprocessor Hierarchical Memory Systems, </title> <booktitle> Proceedings of the 1989 International Conference on Supercomputing, </booktitle> <pages> pp. 433-442, </pages> <publisher> ACM Press, </publisher> <address> New York, </address> <year> 1989. </year>
References-found: 10

