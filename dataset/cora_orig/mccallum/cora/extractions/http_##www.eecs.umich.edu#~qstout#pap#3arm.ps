URL: http://www.eecs.umich.edu/~qstout/pap/3arm.ps
Refering-URL: http://www.eecs.umich.edu/~qstout/papers.html
Root-URL: http://www.cs.umich.edu
Title: A Program for Sequential Allocation of Three Bernoulli Populations  
Author: Janis Hardwick Robert Oehmke Quentin F. Stout 
Keyword: and phrases: multi-arm bandit, parallel computing, dynamic programming, adaptive allocation, sequential sampling, clinical trial, high-performance computing, load balancing, recursive equations, design of experiments  
Address: Ann Arbor, Michigan 48109 USA  
Affiliation: University of Michigan  
Abstract: We describe a program for optimizing and analyzing sequential allocation problems involving three Bernoulli populations. Previous researchers had considered this problem computationally intractable, and we know of no prior exact optimizations for such problems, even for very small sample sizes. Despite this, our program is currently able to solve problems of size 200 or more by using a parallel computer, and problems of size 100 on a workstation. We describe the program and the techniques used to enable it to scale to large sample sizes. As an illustrative example, the program is used to create an adaptive sampling procedure that is the optimal solution to a 3-arm bandit problem. The bandit procedure is then compared to two other allocation procedures along various metrics. We also indicate extensions of the program that enable it to solve a variety of related problems. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Armitage, P. </author> <year> (1985), </year> <title> "The search for optimality in clinical trials", </title> <journal> Int`l. Statist. Rev. </journal> <volume> 53, </volume> <pages> pp. 15-24. </pages>
Reference-contexts: The "rules" are somewhat different and thus a bit controversial. Another important impediment to the adoption of adaptive designs has been their analytic and computational intractability. With regard to the computational complexity, for example, typical comments include "the computation involved is prohibitive except for trivially small horizons" <ref> [1] </ref> and "In theory the optimal strategies can always be found by dynamic programming but the computation required is prohibitive" [21]. Note that the "horizon" of an experiment refers to the number of experimental units that are available for the experiment.
Reference: [2] <author> Bather, J.A. and Coad, D.S. </author> <year> (1992), </year> <title> "Sequential procedures for comparing several medical treatments", </title> <journal> Sequential Anal. </journal> <volume> 11, </volume> <pages> pp. 339-376. </pages>
Reference-contexts: Betensky [5, 6], also working with normal outcome variables, has used other hypothesis testing approaches to tackle the 3-arm problem. Bather and Coad <ref> [2] </ref> addressed the multi-armed problem with Bernoulli outcomes, and in this work, they emphasize locating procedures that work well along several criteria but do not attempt to optimize on any given criterion. A number of researchers have also examined multi-arm problems using nonparametric ranking and selection methods.
Reference: [3] <author> Berry, D.A. and Eick, S.G. </author> <year> (1995), </year> <title> "Adaptive assignment versus balanced randomization in clinical trials | a decision-analysis", Stat. </title> <booktitle> in Medicine 14, </booktitle> <pages> pp. 231-246. </pages>
Reference-contexts: It is our understanding that, prior to our work, the largest 2-armed bandit problem that had been solved appeared in the paper of Barry and Eick <ref> [3] </ref>, which reports on work done around 1987. Utilizing a Cray 2 supercomputer, they were able to handle a sample size of n = 200. In early 1991, we began working on improving algorithms for 2-armed bandits. <p> Typically, to do this requires repeated reevaluation of the design, and this ultimately becomes the most time-consuming part of the entire computational process. Prior to our introduction of path induction, each such evaluation was evaluated via backward induction (see, for example, <ref> [3] </ref>). For 3 populations, this requires fi (n 6 ) time per evaluation. With path induction, there is still an initialization step that requires fi (n 6 ) time. However, each subsequent evaluation occurs only over the final states, requiring only fi (n 5 ) time.
Reference: [4] <author> Berry, D.A. and Fristedt, B. </author> <year> (1985), </year> <title> Bandit Problems: Sequential Allocation of Experiments, </title> <publisher> Chapman and Hall. </publisher>
Reference-contexts: They are used to model a variety of optimization and learning problems. In particular, bandits arise in the design of ethical clinical trials in which the goal is to minimize patient failures that occur during the trial. See <ref> [4] </ref> for an in-depth discussion of bandit problems. In many situations, the performance of an adaptive design can be dramatically superior to that of a fixed allocation design in which all sampling decisions have been made in advance.
Reference: [5] <author> Betensky, R.A. </author> <year> (1992), </year> <title> A Study of Sequential Procedures for Comparing Three Treatments, </title> <type> Ph.D. Thesis, </type> <institution> Stanford University. </institution>
Reference-contexts: For example, Siegmund [19] and Coad [8] have applied repeated significance testing to the case where several arms are available and the outcome variables have normal distributions. Betensky <ref> [5, 6] </ref>, also working with normal outcome variables, has used other hypothesis testing approaches to tackle the 3-arm problem.
Reference: [6] <author> Betensky, R.A. </author> <year> (1996), </year> <title> "An O'Brien-Fleming sequential trial for comparing three treatments", </title> <journal> Annals of Statistics 24, </journal> <pages> pp. 1765-1791. </pages>
Reference-contexts: For example, Siegmund [19] and Coad [8] have applied repeated significance testing to the case where several arms are available and the outcome variables have normal distributions. Betensky <ref> [5, 6] </ref>, also working with normal outcome variables, has used other hypothesis testing approaches to tackle the 3-arm problem.
Reference: [7] <author> Buringer, H., Martin, H. and Schriever, K. </author> <year> (1980), </year> <title> Nonparametric Sequential Selection Procedures, </title> <publisher> Birkhauser. </publisher>
Reference-contexts: A number of researchers have also examined multi-arm problems using nonparametric ranking and selection methods. The primary goal of such designs is to select either the best of several arms or a best subset of arms. See [10] and <ref> [7] </ref> for examples of this approach. Whether it's a testing problem or a selection problem, most multi-armed designs incorporate a mechanism for removing obviously poor arms during the experiment.
Reference: [8] <author> Coad, D.S. </author> <year> (1995), </year> <title> "Sequential allocation rules for multi-armed clinical trials", </title> <journal> J. Statist. Comput. Simul., </journal> <volume> 52, </volume> <pages> pp. 239-251. </pages>
Reference-contexts: Until now, however, problems requiring exact solutions to 3-arm bandits have been considered unmanageable. It is useful to recall that a variety of approaches have been taken with the more general problem of sequential sampling from three or more arms. For example, Siegmund [19] and Coad <ref> [8] </ref> have applied repeated significance testing to the case where several arms are available and the outcome variables have normal distributions. Betensky [5, 6], also working with normal outcome variables, has used other hypothesis testing approaches to tackle the 3-arm problem.
Reference: [9] <author> Gittins, J.C. </author> <year> (1989), </year> <title> Multi-Armed Bandit Allocation Indices, </title> <publisher> Wiley. </publisher> <pages> 14 </pages>
Reference-contexts: Very little exact optimization or evaluation has been done. With regard to bandit problems, there is a highly prominent result that defines optimal procedures for a class of multi-armed bandit problems with infinite horizons (see Gittins <ref> [9] </ref> for this result and related work). However, as is the case with the present problem, the computations required to generate the procedure are very difficult.
Reference: [10] <author> Gupta, S.S. and Liang, T. </author> <year> (1989), </year> <title> "Selecting the best binomial population: parametric empir-ical Bayes approach", </title> <journal> J. Statistical Planning and Inference 23, </journal> <pages> pp. 21-31. </pages>
Reference-contexts: A number of researchers have also examined multi-arm problems using nonparametric ranking and selection methods. The primary goal of such designs is to select either the best of several arms or a best subset of arms. See <ref> [10] </ref> and [7] for examples of this approach. Whether it's a testing problem or a selection problem, most multi-armed designs incorporate a mechanism for removing obviously poor arms during the experiment.
Reference: [11] <author> Hardwick, J., Oehmke, R. and Stout, Q.F. </author> <year> (1997), </year> <title> "A parallel program for 3-arm bandits", </title> <booktitle> Computing Science and Statistics 29, </booktitle> <pages> pp. 390-395. </pages>
Reference-contexts: This heuristic runs in fi (m) time and is given in [13], along with comparisons to the optimal subdivision of the s3 loops. We refer to this algorithm as the initial parallel algorithm, and it is the one that was used for the work reported in <ref> [11] </ref>. The changes needed for the initialization phase of path induction are the same as those needed for dynamic programming, since it performs nearly identical calculations in the reverse order.
Reference: [12] <author> Hardwick, J., Oehmke, R. and Stout, Q.F. </author> <year> (1998), </year> <title> "Adaptive allocation in the presence of censoring", </title> <journal> Computing Science and Statistics 30. </journal>
Reference-contexts: In closing, to our knowledge, no non-trivial optimal solutions have been produced for any of the problems just described, with the exception of our preliminary work on the 2-arm model with censoring independent of the arm <ref> [12] </ref>. We are especially interested in making progress on the censored data and delayed response problems because these extensions address important real-world considerations that have long obstructed adaptation of adaptive experimental designs. Acknowledgments Research supported in part by National Science Foundation grants DMS-9157715 and DMS-9504980.
Reference: [13] <author> Hardwick, J., Oehmke, R. and Stout, Q.F., </author> <title> "Scalable parallel implementation of high-dimensional dynamic programming", </title> <note> in preparation. </note>
Reference-contexts: This is important because misallocating a single iteration can represent a significant imbalance if the iteration requires a significant amount of work. This heuristic runs in fi (m) time and is given in <ref> [13] </ref>, along with comparisons to the optimal subdivision of the s3 loops. We refer to this algorithm as the initial parallel algorithm, and it is the one that was used for the work reported in [11]. <p> Further details can be found in <ref> [13] </ref>, along with experimental analyses of the time and space needed by the improved algorithm. It should be noted that such extensive changes come at a cost. Besides being tedious, they are more error-prone, and the resulting code is more difficult to understand and maintain. <p> Using only one processor, we are able to handle sample sizes greater than 100. We are currently conducting studies for larger values of n and more processors, analyzing both the time and space aspects of scalability. The results will be reported in <ref> [13] </ref>. From a statistical vantage point, we plan to evaluate optimal and sub-optimal strategies along multiple criteria and also to examine the operating characteristics of all procedures under consideration. As noted earlier, very little is known about the behavior of 3-arm strategies, especially optimal strategies.
Reference: [14] <author> Hardwick, J. and Stout, Q.F. </author> <year> (1993), </year> <title> "Exact computational analyses for adaptive designs", Adaptive Designs (N. </title> <journal> Flournoy & W.F. Rosenberger, ed.'s), Institute Math. Stat. Lec. </journal> <volume> Notes 25, </volume> <pages> pp. 223-237. </pages>
Reference-contexts: Our goals were to write parallel code that is portable, maintainable, and flexible. In addition, we needed to maintain the 5 serial efficiencies that had previously been exploited for 2-arm bandit-like problems (see <ref> [14] </ref>). The parallel code is written in Fortran 77, with MPI (Message-Passing Interface) for the communication among the processors. These standard languages are available on most parallel computers, and also on distributed systems such as networks of workstations, so the program is quite portable. <p> It is simple to verify that if each of the inner loops is increasing, then an array entry for a specific m value is overwritten (by the corresponding entry for m-1) after all reads of the value corresponding to m have occurred (see <ref> [14] </ref> for a further discussion of this point). This is a well-known space compression technique for sequential allocation and other dynamic programming problems. <p> Thus the total space for the decision array grows approximately as n 6 =720 bytes. In some cases one can use monotonicity properties of the optimal decisions to reduce the space needed (see <ref> [14] </ref>), but since we wanted to develop a general purpose algorithm suitable for arbitrary objective functions this approach was not used. Fortunately, the decision array is written to once, and in later analyses is only read once.
Reference: [15] <author> Hardwick, J. and Stout, Q.F. </author> <year> (1999), </year> <title> "Path induction for evaluating sequential allocation procedures", </title> <journal> SIAM J. Scientific and Statistical Computing, </journal> <note> to appear. </note>
Reference-contexts: Fortunately, the decision array is written to once, and in later analyses is only read once. This is because nearly all analyses can be accomplished via path induction <ref> [15] </ref>, which, after a single initialization pass through the decision array, reduces each evaluation to a computation over the final states.
Reference: [16] <author> Jones, P. </author> <year> (1992), </year> <title> "Multiobjective Bayesian Bandits", Bayesian Statistics 4: </title> <booktitle> Proc. 4 th Valencia Int'l Meeting, </booktitle> <pages> pp. 689-695. </pages>
Reference-contexts: Such problems are stopping rule problems and do not require the treatment described here. However, with the addition of a second random arm, we get the 2-armed bandit which requires a dynamic programming solution. For 2-armed bandits, a typical optimization was carried out by Jones <ref> [16] </ref>, who solved a problem of size n = 25, and noted the difficulties of solving larger problems. Kulkarni and Kulkarni also noted that the computation required for 2-armed bandits make it "impractical to compute the decision even for moderate values of n 50" [17].
Reference: [17] <author> Kulkarni, R. and Kulkarni, V. </author> <year> (1987), </year> <title> "Optimal Bayes procedures for selecting the better of two Bernoulli populations", </title> <journal> J. Statistical Planning and Inference 15, </journal> <pages> pp. 311-330. </pages>
Reference-contexts: Kulkarni and Kulkarni also noted that the computation required for 2-armed bandits make it "impractical to compute the decision even for moderate values of n 50" <ref> [17] </ref>. It is our understanding that, prior to our work, the largest 2-armed bandit problem that had been solved appeared in the paper of Barry and Eick [3], which reports on work done around 1987.
Reference: [18] <author> Palmer, C. </author> <year> (1993), </year> <title> "Selecting the best of k treatments", Adaptive Designs (N. </title> <journal> Flournoy & W.F. Rosenberger, ed.'s), Institute Math. Stat. Lec. </journal> <volume> Notes 25, </volume> <pages> pp. 110-123. </pages>
Reference-contexts: To ascertain the behavior of the procedures for practical 3 sample sizes, simulation studies are typically used. Many excellent procedures have been developed in this manner. Still, we know of only one for which exact optimality has been obtained. Palmer <ref> [18] </ref> optimized a 3-arm knock-out tournament in which one samples equally often from each population, sampling until 1 arm can be eliminated. The experiment continues with equal allocation from the remaining 2 arms.
Reference: [19] <author> Siegmund, D. </author> <year> (1993), </year> <title> "A sequential clinical trial for comparing three treatments", </title> <journal> Annals of Statistics 21, </journal> <pages> pp. 464-483. </pages>
Reference-contexts: Until now, however, problems requiring exact solutions to 3-arm bandits have been considered unmanageable. It is useful to recall that a variety of approaches have been taken with the more general problem of sequential sampling from three or more arms. For example, Siegmund <ref> [19] </ref> and Coad [8] have applied repeated significance testing to the case where several arms are available and the outcome variables have normal distributions. Betensky [5, 6], also working with normal outcome variables, has used other hypothesis testing approaches to tackle the 3-arm problem.
Reference: [20] <author> Simon, R. </author> <year> (1977), </year> <title> "Adaptive treatment assignment methods and clinical trials", </title> <type> Biometrics 33, </type> <pages> pp. 743-744. </pages>
Reference: [21] <author> Wang, Y.-G. </author> <year> (1991), </year> <title> "Sequential allocation in clinical trials", </title> <journal> Comm. in Statistics: Theory and Methods 20, </journal> <pages> pp. 791-805. 15 </pages>
Reference-contexts: With regard to the computational complexity, for example, typical comments include "the computation involved is prohibitive except for trivially small horizons" [1] and "In theory the optimal strategies can always be found by dynamic programming but the computation required is prohibitive" <ref> [21] </ref>. Note that the "horizon" of an experiment refers to the number of experimental units that are available for the experiment. For our purposes here, the horizon is simply the sample size, n, of the experiment.
References-found: 21

