URL: http://www.ius.cs.cmu.edu/IUS/clash_usr0/aej/www/papers/Modeling.DIG-97.fmk.ps.gz
Refering-URL: http://www.ius.cs.cmu.edu/usr/users/aej/www/research/modeling.html
Root-URL: 
Date: May 12-15, 1997.  
Address: Ottawa, Ontario,  
Note: Appearing in the International Conference on Recent Advances in 3-D Digital Imaging and Modeling,  
Abstract: In general, multiple views are required to create a complete 3-D model of an object or of a multi-roomed indoor scene. In this work, we address the problem of merging multiple textured 3-D data sets, each of which corresponds to a different view of a scene or object. There are two steps to the merging process: registration and integration. To register, or align, data sets we use a modified version of the Iterative Closest Point algorithm; our version, which we call color ICP, considers not only 3-D information, but color as well. We show that the use of color decreases registration error by an order of magnitude. Once the 3-D data sets have been registered, we integrate them to produce a seamless, composite 3-D textured model. Our approach to integration uses a 3-D occupancy grid to represent likelihood of spatial occupancy through voting. In addition to occupancy information, we store surface normal in each voxel of the occupancy grid. Surface normal is used to robustly extract a surface from the occupancy grid; on that surface we blend textures from multiple views. . 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> P. Besl and N. McKay. </author> <title> A method of registration of 3-D shapes. </title> <journal> IEEE Trans. Pattern Analysis and Machine Intelligence, </journal> <volume> vol. 12, no. 2, </volume> <pages> pp. 239-256, </pages> <month> February </month> <year> 1992. </year>
Reference-contexts: Given multiple textured data sets recovered using omnidirectional multibaseline stereo, the first step in the 3-D merging process is data set registration. 3. Registration The technique that we use to register all the 3-D data sets is essentially a modification of the Iterative Closest Point algorithm (ICP) <ref> [1] </ref>. In addition to using k-d trees for efficient closest point computations and a dynamic distance threshold [18], our algorithm uses shape and color information to improve the registration beyond that obtained with an ICP algorithm that uses just shape information.
Reference: [2] <author> B. Curless and M. Levoy. </author> <title> A volumetric method for building complex models from range images. </title> <booktitle> Computer Graphics (SIGGRAPH 96), </booktitle> <month> August </month> <year> 1996. </year>
Reference: [3] <author> A. Elfies. </author> <title> Sonar-based real world mapping and navigation. </title> <journal> IEEE Jour. Robotics and Automation, </journal> <volume> vol. RA-3, no. 3, </volume> <pages> pp. 249-265, </pages> <year> 1987. </year>
Reference: [4] <author> K. Higuchi, M. Hebert and K. </author> <title> Ikeuchi. Building 3-D models from unregistered range images. </title> <type> Technical Report CMU-CS-93-214, </type> <institution> Carnegie Mellon University, </institution> <month> November </month> <year> 1993. </year>
Reference: [5] <author> A Hilton, A. Stoddart, J. Illingworth and T Windeatt. </author> <title> Reliable surface reconstruction from multiple range images. </title> <booktitle> Fourth European Conf. on Computer Vision (ECCV `96), </booktitle> <pages> pp. 14-18, </pages> <month> April </month> <year> 1996. </year>
Reference: [6] <author> H. Hoppe, T. DeRose, T. DuChamp, J. McDonald and W. Stuetzle. </author> <title> Surface reconstruction from unorganized points. </title> <booktitle> Computer Graphics (SIGGRAPH 92), </booktitle> <pages> pp. 71-78. </pages> <month> July </month> <year> 1992. </year>
Reference: [7] <author> A. Johnson and S. Kang. </author> <title> Registration and integration of textured 3-D data. </title> <institution> Digital Equipment Corp. Cambridge Research Lab. </institution> <type> Tech. Report CRL 96/4, </type> <month> October </month> <year> 1996. </year>
Reference-contexts: The texture on the complete model is determined through trilinear interpolation of the overlapping textures corresponding to the original data sets. A more detailed description of our work on merging different textured 3-D data sets can be found in <ref> [7] </ref>.
Reference: [8] <author> S. Kang, and R. Szeliski. </author> <title> 3-D scene data recovery using omnidirectional multibaseline stereo. </title> <institution> Digital Equipment Corporation Cambridge Research Lab. </institution> <type> Tech. Report CRL 95/6, </type> <month> October </month> <year> 1995. </year>
Reference-contexts: Recovery of 3-D scene data In our work, we use 3-D data recovered from omnidirectional multibaseline stereo, i.e., using multiple panoramic images <ref> [8] </ref>. Each panoramic image spans a 360 horizontal field of view. <p> This is done without resorting to any intermediate 3-D merging. The omnidirectional multibaseline stereo approach to recover 3-D data and, subsequently, the scene model is summarized in Figure 1. We provide only a brief outline of the approach here; full details can be found in <ref> [8] </ref>. The approach is straightforward: at each camera location in the scene, sequences of images are captured while the camera is rotated about the vertical axis passing through the camera optical center. Each set of images is then composited to produce panoramas at each camera location. <p> For example, a 2000 pixel wide panorama becomes misregistered by one pixel if the estimated rotation is incorrect by 0.18 degrees. Inaccuracies in scene shape introduced by the shape recovery algorithm (omnidirectional stereo <ref> [8] </ref>) are too large to obtain the accuracy in registration needed to blend texture using a traditional ICP algorithm. However, by including color in the closest point computation of the ICP algorithm, the necessary registration accuracy can be obtained.
Reference: [9] <author> C. Kolb. </author> <title> Rayshade User Guide and Reference Manual. </title> <month> August </month> <year> 1994. </year>
Reference: [10] <author> W. Lorensen and H. Cline. </author> <title> Marching Cubes: a high resolution 3D surface construction algorithm. </title> <booktitle> Computer Graphics (SIGGRAPH 87), </booktitle> <pages> pp. 163-169, </pages> <year> 1987. </year>
Reference-contexts: Usually ridge detection requires computation of second order surface derivatives to determine this direction--a computation without a robust solution. The implicit surface function is then polygonized using the standard Marching Cubes algorithm <ref> [10] </ref> with a modified lookup table of 22 cases to prevent the creation of holes in the surface [13]. The consensus surface mesh generated from the 6 synthetic data sets is shown in Figure 7.
Reference: [11] <author> M. Martin and H. Moravec. </author> <title> Robot Evidence Grids. </title> <institution> Carnegie Mellon University Robotics Institute Tech. Report CMU-RI-TR-96-06, </institution> <month> March </month> <year> 1996. </year>
Reference: [12] <author> L. Matthies and S. Shafer. </author> <title> Error modeling in stereo navigation. </title> <journal> IEEE Jour. Robotics and Automation, </journal> <volume> vol. RA-3, no. 3, </volume> <pages> pp. 239-248, </pages> <month> June </month> <year> 1987. </year>
Reference-contexts: The sensor error model G E is an approximation of a true stereo error model and is represented as an ellipsoidal gaussian distribution centered at the measured 3-D point whose axis is oriented along the line of sight <ref> [12] </ref>. The point spread model G S is used to promote the generation of surfaces from discrete data. It is represented as a cylindrical gaussian, centered at the sensed point, whose axis is aligned with the local surface normal. <p> The spread of the gaussian can be characterized by two parameters, s a 2 the variance perpendicular to the viewing direction and s b 2 the variance along the viewing direction. A 2-D slice of the sensor error geometry is shown in Figure 4. Matthies and Shafer <ref> [12] </ref> showed that the variances of the sensor error model should vary depending on the position of the sensed point. To reduce the amount of calculation per point, we have assumed that the variances of the sensor error model are fixed for all points.
Reference: [13] <author> C. Montani, R. Scateni and R. Scopigno. </author> <title> A modified look-up table for implicit disambiguation of Marching Cubes. </title> <journal> Visual Computer, </journal> <volume> vol. 10, </volume> <pages> pp. 353-355, </pages> <year> 1994. </year>
Reference-contexts: The implicit surface function is then polygonized using the standard Marching Cubes algorithm [10] with a modified lookup table of 22 cases to prevent the creation of holes in the surface <ref> [13] </ref>. The consensus surface mesh generated from the 6 synthetic data sets is shown in Figure 7.
Reference: [14] <author> S. Naher and C. Uhrig. </author> <title> The LEDA User Manual. </title> <month> May </month> <year> 1996. </year>
Reference-contexts: Appearing in the International Conference on Recent Advances in 3-D Digital Imaging and Modeling, Ottawa, Ontario, May 12-15, 1997. 5. Implementation The code for our model merging work is written in C++ and uses the Library of Efficient Data types and Algorithms (LEDA) <ref> [14] </ref>. LEDA is a library of data types and algorithms that includes, among others, graph data structures and algorithms to manipulate them. Each vertex, edge, and face of a 3-D scene model has its own data structure, while the connectivity information between the vertices is encoded in a graph.
Reference: [15] <author> H.-Y. Shum, K. Ikeuchi and R. Reddy. </author> <title> Principal component analysis with missing data and its application to object modeling. </title> <journal> Proc. IEEE Computer Vision and Pattern Recognition (CVPR-94), </journal> <pages> pp. 560-565, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: To meet this end, we have developed a volumetric multi-view merging algorithm that integrates the shape and appearance of complex scenes. There has been much research in the area of model creation through multiple view merging. Shum et. al. <ref> [15] </ref>, for example, recover the merged model through simultaneous determination of planar surface parameters and pose of constituent range data sets. They assume, however, that the surfaces of objects can be represented using planar patches.
Reference: [16] <author> K. Waters. J. Rehg, M. Loughlin, S. Kang and D. Terzopoulos. </author> <title> Visual sensing for humans for active public interfaces. </title> <address> Cambridge, UK, </address> <year> 1996 </year>
Reference-contexts: The work described here is used to recover 3-D models of indoor scenes for the on-going Smart Kiosk project at Cambridge Research Lab., Digital Equipment Corp. <ref> [16] </ref>. The Smart Kiosk can be described as an enhanced version of the Automatic Teller Machine, with the added capability of being able to interact with the user through body tracking, and gesture and speech recognition.
Reference: [17] <author> M. Wheeler. </author> <title> Automatic modeling and localization for object recognition. </title> <institution> Carnegie Mellon Univ., School of Computer Science Tech. Report CMU-CS-96-118, </institution> <month> October </month> <year> 1996. </year>
Reference: [18] <author> Z. Zhang. </author> <title> Iterative point matching for registration of freeform curves and surfaces. </title> <booktitle> Intl Jour. Computer Vision, </booktitle> <volume> vol. 13 no. 2, </volume> <pages> pp. 119-152, </pages> <year> 1994. </year> <title> Points (top view) Surface (oblique view) Surface (top view) Textured Surface (oblique view) Close-up #1 (max-blend) Close-up #2 (max-blend) data sets created with omnidirectional multi-baseline stereo of a lab. The texture of the merged model is created using the max texture blending scheme. </title>
Reference-contexts: Registration The technique that we use to register all the 3-D data sets is essentially a modification of the Iterative Closest Point algorithm (ICP) [1]. In addition to using k-d trees for efficient closest point computations and a dynamic distance threshold <ref> [18] </ref>, our algorithm uses shape and color information to improve the registration beyond that obtained with an ICP algorithm that uses just shape information. We call this variant the Color ICP technique; its concept is shown in Figure 2.
References-found: 18

