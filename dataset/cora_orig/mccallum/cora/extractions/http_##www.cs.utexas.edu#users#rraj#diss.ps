URL: http://www.cs.utexas.edu/users/rraj/diss.ps
Refering-URL: http://www.cs.utexas.edu/users/rraj/Pubs/diss.html
Root-URL: http://www.cs.utexas.edu
Title: Sharing Resources in Distributed Systems  
Degree: by Rajmohan Rajaraman, B.Tech., M.S. Dissertation Presented to the Faculty of the Graduate School of  in Partial Fulfillment of the Requirements for the Degree of Doctor of Philosophy  
Date: December 1997  
Address: Austin  Austin  
Affiliation: The University of Texas at  The University of Texas at  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> N. Abramson. </author> <title> The ALOHA system. </title> <editor> In N. Abramson and F. Kuo, editors, </editor> <booktitle> Computer-Communication Networks. </booktitle> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1973. </year>
Reference-contexts: If two or more clients attempt to use the channel simultaneously, then there is a collision, and no client succeeds. The standard Ethernet local area network [92] and the classic ALOHA packet radio network <ref> [1] </ref> are two well-known examples of multiple access channels. (See [29, Chapter 4] for more examples.) An optical computer, which can be viewed as a collection of multiple access channels, is accurately modeled by a 1-collision crossbar. <p> In the absence of replication, a natural approach to resolve contention for MACs is to use randomization to break the symmetry among the clients. This idea is central to many MAC protocols, including the Ethernet protocol [92] and the slotted ALOHA 20 protocol <ref> [1] </ref>, and routing protocols for the optical computer [10, 116, 51]. (For more work in this direction, see [64, 65].) Lower bounds for routing in optical computers appear in [62, 88]. 2.2 The 1 out of ` Protocol Consider the 1 out of ` problem where ` 1. <p> Consider a bin j in U 0 i . The probability that j receives at least c balls is at least: (1 100"" 1 )u 1 x i c 1 where f ("; " 1 ; c) is a constant in <ref> [0; 1] </ref>, dependent on ", " 1 , and c. Let U 0 be the set of bins j such that j is in U 0 i for at least s=2 different values of i. By an averaging argument, we obtain that jU 0 j is at least 49u=50. <p> We denote the average number of tokens by , i.e., = ( v2V w (v))=n. For simplicity, throughout this chapter we assume that is an integer. We assign a unique rank from <ref> [1; w (v)] </ref> to every token at v. The height of a token is its rank minus . The height of a node is the maximum among the heights of all its tokens. <p> For each bad index, there is a reduction by a factor of 1=(1 + ff=(2d)). Hence, there can be at most dlog (1+ff=(2d)) ne bad indices because (1 + ff=(2d)) log (1+ff=(2d)) n n. It follows that at least half of the indices in <ref> [1; 2dlog (1+ff=(2d)) ne] </ref> are good. 4.3 Analysis for Static Synchronous Networks 4.3.1 The Single-Port model In this section, we analyze the single-port load balancing algorithm that is described in Section 4.1.2. <p> Thus, every subset of nodes in S &gt;0 expands, and we will use this expansion property to show that the number of nodes that have at least + 2 log (1+ff=(2d)) n tokens rapidly goes to zero. Recall that at least half of the indices in <ref> [1; 2dlog (1+ff=(2d)) ne] </ref> are good in any time step. Therefore, there exists an index j in [1; 2dlog (1+ff=(2d)) ne] that is good in at least half of those time steps in which jS &gt;0 j n=2. Hence j is good in at least T =4 steps. <p> Recall that at least half of the indices in <ref> [1; 2dlog (1+ff=(2d)) ne] </ref> are good in any time step. Therefore, there exists an index j in [1; 2dlog (1+ff=(2d)) ne] that is good in at least half of those time steps in which jS &gt;0 j n=2. Hence j is good in at least T =4 steps. <p> Without loss of generality, we assume that jS &gt;0 j n=2 holds in at least half of these steps. As shown in Section 4.2, there exists an index j in <ref> [1; 2dlog (1+ff=(2d)) ne] </ref> that is good in at least half of those steps in which jS &gt;0 j n=2. Hence in T steps of the algorithm, j is good in at least T =4 steps. <p> Consider T steps of DS. We assume without loss of generality that jS &gt;0 j n=2 at the start of at least T =2 steps. As shown in Section 4.2, there exists an index j in <ref> [1; 2dlog (1+ff=(2d)) ne] </ref> that is good in at least half of those steps in which jS &gt;0 j n=2. (Recall that index i is good if jS i j ffjS &gt;i j=2d.) If index j is good at the start of step t, we call t a good step. <p> Proof: We only prove the first claim of the lemma. The proof of the second claim is symmetric. 170 It is useful to extend the notion of height to tokens as well. For this purpose, we assign, for every node v, a unique rank from <ref> [1; w t (v)] </ref> to each token at v. Let the height of a token be its rank minus t .
Reference: [2] <author> M. Adler, S. Chakrabarti, M. Mitzenmacher, and L. Rasmussen. </author> <title> Parallel randomized load balancing. </title> <booktitle> In Proceedings of the 27th Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 238-247, </pages> <month> May </month> <year> 1995. </year>
Reference-contexts: Our main technical contribution in this chapter is the derivation of sharp threshold phenomena associated with certain random allocation experiments. Several recent papers have studied similar processes that arise in dynamic resource allocation and parallel load balancing <ref> [2, 25, 108] </ref>. 60 Chapter 3 Fast Fault-Tolerant Concurrent Access to Shared Ob jects 3.1 Introduction In this chapter, we design and analyze a simple local protocol for providing fast concurrent access to shared objects in a faulty distributed network. <p> Any unidirectional algorithm incurs at least T (b) token transmissions to balance b. 155 while the shaded tokens represent the number of tokens less than the average. Note that the nodes have been relabeled so that the value of ` is 0. Hence, the set <ref> [0; 2] </ref> has the maximum total imbalance, 12, which equals the discrepancy of the distribution. By Equation 5.1, the prefix sum vector is (7; 10; 12; 9; 10; 4; 2; 0). Proof: Consider the set S = fi : 0 i m (b)g of nodes.
Reference: [3] <author> M. Adler, P. B. Gibbons, Y. Matias, and V. Ramachandran. </author> <title> Modeling parallel bandwidth: Local vs. global restrictions. </title> <booktitle> In Proceedings of the 9th Annual ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 94-105, </pages> <month> June </month> <year> 1997. </year>
Reference-contexts: For such networks, we need to place global restrictions on the bandwidth, as is done in the PRAM (m) [90] and the QSM (m) [58] models. For a recent study on the implications of local and global bandwidth restrictions, see <ref> [3] </ref>. (We remark that our usage of the terms "local bandwidth" and "global bandwidth" is borrowed from [3].) The DRAM model [81] considers bandwidth restrictions in a more general form by explicitly accounting for congestion across every cut of the underlying network. <p> For a recent study on the implications of local and global bandwidth restrictions, see <ref> [3] </ref>. (We remark that our usage of the terms "local bandwidth" and "global bandwidth" is borrowed from [3].) The DRAM model [81] considers bandwidth restrictions in a more general form by explicitly accounting for congestion across every cut of the underlying network.
Reference: [4] <author> Y. Afek, E. Gafni, and A. Rosen. </author> <title> The slide mechanism with applications to dynamic networks. </title> <booktitle> In Proceedings of the 11th Annual ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pages 35-46, </pages> <month> August </month> <year> 1992. </year>
Reference-contexts: In general, work on dynamic and asynchronous networks has been limited. In work related to load balancing, for instance, an end-to-end communication problem, namely one in which messages are routed from a single source to a single destination, has been studied in <ref> [4, 24] </ref> on dynamic networks. Our scenario is substantially more involved since we are required to move load between several sources and destinations simultaneously. Another result on dynamic networks is the recent analysis of a local algorithm for the approximate multicommodity flow problem [22, 23].
Reference: [5] <author> W. Aiello, B. Awerbuch, B. Maggs, and S. Rao. </author> <title> Approximate load balancing on dynamic and asynchronous networks. </title> <booktitle> In Proceedings of the 25th Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 632-641, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: The performance of an algorithm is measured by the time it takes to balance the tokens, and by the final imbalance it achieves. In Chapter 4, we tightly analyze a simple local algorithm of Aiello et al. <ref> [5] </ref>, in which at each step each node sends a token to each of its neighbors with at least 2d fewer tokens (where d is the degree of the network). <p> An algorithm is said to be stable if there exists such that for all t 0, the imbalance of G at the start of step t is at most . In Chapter 6, we show that the local balancing algorithm of Aiello et al. <ref> [5] </ref> is stable for all networks for " &gt; 0. This result is joint work with S. Muthukrishnan. 1.3 Two Abbreviations for High Probability Bounds Several claims in this dissertation are probabilistic and we differentiate between two kinds of high probability bounds. <p> Figure 4.3 illustrates one step of the multi-port algorithm on the example given in Figure 4.1. This algorithm was first analyzed in <ref> [5] </ref>. (The multi-port algorithm is sometimes referred to as the diffusion method in the load balancing literature [119].) We characterize the performance of a load balancing algorithm by the time that it takes to balance the tokens, and by the final imbalance that it achieves. <p> These models can be classified on the basis of three characteristics: (i) centralized control (e.g., [93, 111]) versus distributed control (e.g., [30, Chapter 7] [42]), (ii) shared memory communication such as the PRAM model (e.g., [27]), uniform communication (e.g., [111]), or fixed-connection network communication (e.g., <ref> [5, 42] </ref>), and (iii) unbounded edge capacity (e.g., [30, Chapter 7] [109]) versus bounded edge capacity (e.g., [5, 101]) (the capacity of an edge is the maximum number of tokens it can transmit per step). <p> centralized control (e.g., [93, 111]) versus distributed control (e.g., [30, Chapter 7] [42]), (ii) shared memory communication such as the PRAM model (e.g., [27]), uniform communication (e.g., [111]), or fixed-connection network communication (e.g., [5, 42]), and (iii) unbounded edge capacity (e.g., [30, Chapter 7] [109]) versus bounded edge capacity (e.g., <ref> [5, 101] </ref>) (the capacity of an edge is the maximum number of tokens it can transmit per step). <p> In contrast, our local algorithm works on any dynamic network that remains connected. On arbitrary topologies, load balancing algorithms that use bounded edge capacity were first proposed and analyzed in <ref> [5] </ref> for the multi-port variant and in [54] 117 for the single-port variant. The associated upper bounds are suboptimal by factors of (log (n)) and ( n), respectively. We improve these results for both single-port and multi-port variants. As remarked earlier, our multi-port results (and those in [5]) hold even for <p> and analyzed in <ref> [5] </ref> for the multi-port variant and in [54] 117 for the single-port variant. The associated upper bounds are suboptimal by factors of (log (n)) and ( n), respectively. We improve these results for both single-port and multi-port variants. As remarked earlier, our multi-port results (and those in [5]) hold even for dynamic or asynchronous networks. In general, work on dynamic and asynchronous networks has been limited. <p> Second, our argument uses an exponential potential function. The analyses in [42, 73, 95], in contrast, use quadratic potential functions. Our potential function and our amortized analysis appear to be necessary since a number of previous attempts using quadratic potential functions yielded suboptimal results <ref> [5, 54] </ref> for local load balancing. 118 4.2 Preliminaries For any network G = (V; E) with n nodes and edge expansion ff, we denote the number of tokens at v 2 V by w (v). <p> We first prove that a variant of the local multi-port algorithm is optimal on dynamic synchronous networks in the same sense as for static synchronous networks. We then use a result of <ref> [5] </ref> that relates the dynamic synchronous and asynchronous models to extend our results to asynchronous networks. In the dynamic synchronous model, the edges of the network may fail or succeed dynamically. <p> We assume that at each step each node knows which of its adjacent edges are live. The local load balancing algorithm for static synchronous networks can be modified to work on dynamic synchronous networks. The algorithm presented here is essentially the same as in <ref> [5] </ref>. Since edges may fail dynamically, a node u may have no knowledge of the height of a neighboring node v and hence may be unable to decide whether to send a token to v. <p> We show that for any of the above events to occur, "many" tokens should have lost height in previous steps. We use a part of this prior potential drop to account for (i) and (ii). At a high level, our proof follows the lines of Lemma 3 of <ref> [5] </ref>. Since the potential functions involved are different, however, the two proofs differ considerably in the details. We have included a complete proof of Lemma 4.7 in Appendix D. The main result follows from Lemmas 4.6 and 4.7. <p> By defining an appropriate potential function for tokens with heights below the average and repeating the analysis done for S &gt;j , we show that in another O (=ff) steps, all nodes have more than O (d 2 (log n)=ff) tokens. As suggested in <ref> [5] </ref>, a simple variant of DS can be defined for asynchronous networks. 139 As shown in [5], the analysis for the dynamic synchronous case can be used for asyn-chronous networks to yield the same time bounds. <p> As suggested in <ref> [5] </ref>, a simple variant of DS can be defined for asynchronous networks. 139 As shown in [5], the analysis for the dynamic synchronous case can be used for asyn-chronous networks to yield the same time bounds.
Reference: [6] <author> M. Ajtai, J. Komlos, and E. Szemeredi. </author> <title> Sorting in c log n parallel steps. </title> <journal> Combi-natorica, </journal> <volume> 3 </volume> <pages> 1-19, </pages> <year> 1983. </year>
Reference-contexts: Peleg and Upfal [97] pioneered this study by identifying certain small-degree expanders as being suitable for load balancing. Their work was extended in [34, 69, 98]. These algorithms either use strong expanders to approximately balance the network, or the AKS sorting network <ref> [6] </ref> to perfectly balance the network. Thus, they do not work on networks of arbitrary topology. Also, these algorithms work by transferring load along fixed paths in the network and, therefore, cannot cope with the changes in the network topology.
Reference: [7] <author> N. Alon, G. Kalai, M. Ricklin, and L. Stockmeyer. </author> <title> Lower bounds on the competitive ratio for mobile user tracking and distributed job scheduling. </title> <journal> Theoretical Computer Science, </journal> <volume> 130 </volume> <pages> 175-201, </pages> <year> 1994. </year> <month> 198 </month>
Reference-contexts: This problem has been studied under a model in which edge capacities are infinite <ref> [7, 21, 46] </ref>. For our model, however, results to date are limited to specific instances of the problem [71]. 178 Appendix A Tails of Probability Distributions Theorems A.1 and A.2 provide bounds on the tails of the binomial and hypergeometric distributions, respectively.
Reference: [8] <author> N. Alon and J. H. Spencer. </author> <title> The Probabilistic Method. </title> <publisher> Wiley, </publisher> <address> New York, NY, </address> <year> 1991. </year>
Reference-contexts: Among other results, we show that Alg2 (n; 3; 1) and Alg2 (n; 2; 2) both terminate in fi (log log n) rounds whp. 2.4.1 Large Deviations For our analysis, we make frequent use of bounds on the tails of the binomial and hypergeometric distributions <ref> [8, 37, 38, 70] </ref>. These bounds are stated in Appendix A. Lemmas 2.6 and 2.7 are obtained from bounds on the tails of the hypergeometric and binomial distributions, respectively. Lemma 2.6: Let S be a set of s balls, and T be a subset of S, t = jT j. <p> Our presentation in this appendix is based on that of <ref> [8] </ref>. A martingale is a sequence X 0 ; : : : ; X m of random variables so that for 0 i &lt; m, E [X i+1 j X i ] = X i . We use Azuma's inequality to obtain bounds on large deviations for martingales. <p> We use Azuma's inequality to obtain bounds on large deviations for martingales. Theorem B.1 (Azuma's Inequality <ref> [8] </ref>): Let X 0 ; : : : ; X k be a martingale with jX i+1 X i j 1, for all 0 i &lt; k.
Reference: [9] <author> H. Alt, T. Hagerup, K. Mehlhorn, and F. P. Preparata. </author> <title> Deterministic simulation of idealized parallel computers on more realistic ones. </title> <journal> SIAM Journal on Computing, </journal> <volume> 16(5) </volume> <pages> 808-835, </pages> <year> 1987. </year>
Reference-contexts: It is easy to see that given any emulation protocol for the c-collision crossbar, we can construct an equally efficient emulation protocol for the c-arbitrary crossbar. The c-arbitrary and c-collision crossbars generalize some models that have been studied previously. The module parallel computer (MPC <ref> [9] </ref>) and the S*PRAM [116] correspond to the 1-arbitrary crossbar model. The local memory PRAM model of An-derson and Miller [10], later studied under the name OCPC (optical communication parallel computer) in [51, 60, 61], corresponds to the 1-collision crossbar model. <p> A deterministic simulation with delay O (log n) was presented in <ref> [9] </ref>; however, their result is non-constructive. Karp, Luby, and Meyer auf der Heide [75] presented a protocol that uses three hash functions and incurs O (log log n) delay. <p> Several researchers have studied simulations of shared memory on other topologies. Non-constructive simulations on networks of bounded degree were presented in <ref> [9] </ref>. Ranade devised a novel routing algorithm for the butterfly which leads to a CRCW PRAM simulation protocol with O (log n) delay [105]. Simulations of different PRAM models have been obtained on the mesh-connected computer [100] and its variants [82].
Reference: [10] <author> R. J. Anderson and G. L. Miller. </author> <title> Optical communication for pointer based algorithms. </title> <type> Technical Report CRI-88-14, </type> <institution> Computer Science Department, University of Southern California, </institution> <year> 1988. </year>
Reference-contexts: The c-arbitrary and c-collision crossbars generalize some models that have been studied previously. The module parallel computer (MPC [9]) and the S*PRAM [116] correspond to the 1-arbitrary crossbar model. The local memory PRAM model of An-derson and Miller <ref> [10] </ref>, later studied under the name OCPC (optical communication parallel computer) in [51, 60, 61], corresponds to the 1-collision crossbar model. The c-arbitrary and c-collision DMM models of [47, 75] are similar to the crossbar models in that the underlying communication network is a complete network. <p> This idea is central to many MAC protocols, including the Ethernet protocol [92] and the slotted ALOHA 20 protocol [1], and routing protocols for the optical computer <ref> [10, 116, 51] </ref>. (For more work in this direction, see [64, 65].) Lower bounds for routing in optical computers appear in [62, 88]. 2.2 The 1 out of ` Protocol Consider the 1 out of ` problem where ` 1.
Reference: [11] <author> T. E. Anderson, M. D. Dahlin, J. N. Neefe, D. A. Patterson, D. S. Rosselli, and R. Y. Wang. </author> <title> Serverless network file systems. </title> <booktitle> In Proceedings of the 15th Symposium on Operating Systems Principles, </booktitle> <pages> pages 109-126, </pages> <year> 1995. </year>
Reference-contexts: Very broadly, existing protocols can be classified into two categories. The first category consists of implementations where a client accesses a given object by consulting the "manager" of the object to locate a copy (examples include [31], [67], and xFS <ref> [11] </ref>). The main drawback with this approach is that the manager is usually implemented as a process running at a single node and thus constitutes a sequential bottleneck.
Reference: [12] <author> M. Andrews, B. Awerbuch, A. Fernandez, J. Kleinberg, T. Leighton, and Z. Liu. </author> <title> Universal stability results for greedy contention-resolution protocols. </title> <booktitle> In Proceedings of the 37th Annual IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pages 380-389, </pages> <month> October </month> <year> 1996. </year>
Reference-contexts: Our model is based on an adversarial model that has been proposed recently for studying routing problems <ref> [12, 32] </ref>. We assume that an adversary controls the online process of token arrival and departure. In each step, the adversary determines the locations and the number of tokens that are to be added to or deleted from the system.
Reference: [13] <author> E. Arjomandi, M. J. Fischer, and N. A. Lynch. </author> <title> Efficiency of synchronous versus asynchronous distributed systems. </title> <journal> Journal of the ACM, </journal> <volume> 30 </volume> <pages> 449-456, </pages> <year> 1983. </year>
Reference-contexts: The time complexity of an algorithm is then defined as the maximum number of rounds 149 taken among all possible schedulings of the components. (See Section 5.5 for a formal description of the asynchronous model.) The above notion of time is based on the model proposed in <ref> [13] </ref> for shared memory systems. An analogous model for message-passing systems was studied in [16]. <p> equivalent to that proposed in [87], where the time complexity of an algorithm is defined to be the longest amount of elapsed real time from the start to the completion of the algorithm, assuming that the time delay between two steps of the same network component is at most unity <ref> [13] </ref>. (The model proposed in [87] has been subsequently used in the study of several distributed computing problems [18, 20].) We generalize our result for the synchronous model to the asynchronous model at the expense of a factor of 2 in the time complexity.
Reference: [14] <author> A. Arora and M. Gouda. </author> <title> Load balancing: An exercise in constrained convergence. </title> <editor> In J-M. Helary and M. Raynal, editors, </editor> <booktitle> Proceedings of the 9th International Workshop on Distributed Algorithms, Lecture Notes in Computer Science, </booktitle> <volume> volume 972, </volume> <pages> pages 183-197. </pages> <publisher> Springer-Verlag, </publisher> <year> 1995. </year>
Reference-contexts: We also show that in both the synchronous and asynchronous models, for every initial token distribution, the message complexity of A is asymptotically optimal among all unidirectional algorithms. 5.1.2 Related Work In recent work <ref> [14] </ref>, asynchronous balancing algorithms on several networks including the ring have been studied. However, the results of [14] are geared towards establishing eventual convergence in the presence of dynamic network changes, while we are interested in determining the time to convergence for static load balancing. <p> also show that in both the synchronous and asynchronous models, for every initial token distribution, the message complexity of A is asymptotically optimal among all unidirectional algorithms. 5.1.2 Related Work In recent work <ref> [14] </ref>, asynchronous balancing algorithms on several networks including the ring have been studied. However, the results of [14] are geared towards establishing eventual convergence in the presence of dynamic network changes, while we are interested in determining the time to convergence for static load balancing.
Reference: [15] <author> J. Aspnes, M. Herlihy, and N. Shavit. </author> <title> Counting networks. </title> <journal> Journal of the ACM, </journal> <volume> 41 </volume> <pages> 1020-1048, </pages> <year> 1994. </year>
Reference-contexts: In the discussion that follows, we restrict our attention to models of computation with the same basic characteristics as the model considered in this chapter, namely: distributed control, fixed-connection network communication, and bounded edge capacity. Local algorithms restricted to particular networks have been studied on counting networks <ref> [15, 78] </ref>, hypercubes [72, 101], and meshes [68, 93]. Another class of networks on which load balancing has been studied is the class of expanders. Peleg and Upfal [97] pioneered this study by identifying certain small-degree expanders as being suitable for load balancing.
Reference: [16] <author> H. Attiya and M. Mavronicolas. </author> <title> Efficiency of semi-synchronous versus asynchronous networks. </title> <journal> Mathematical Systems Theory, </journal> <volume> 27 </volume> <pages> 547-571, </pages> <year> 1994. </year> <month> 199 </month>
Reference-contexts: An analogous model for message-passing systems was studied in <ref> [16] </ref>.
Reference: [17] <author> Y. Aumann, Z. Kedem, K. V. Palem, and M. O. Rabin. </author> <title> Highly efficient asyn-chronous execution of large-grained parallel programs. </title> <booktitle> In Proceedings of the 34th Annual IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pages 271-280, </pages> <month> November </month> <year> 1993. </year>
Reference-contexts: Thus, IDA can be used to obtain fault-tolerance with only a constant factor space penalty by setting m to fi (log n) and k to fi (m), e.g., k = 2m. This powerful technique is used by Aumann et al. <ref> [17] </ref> as part of an efficient scheme for emulating large-grained PRAM programs on an asynchronous parallel machine. In our protocol, we use the same technique to store the "primary" copy of each object.
Reference: [18] <author> B. Awerbuch. </author> <title> Complexity of network synchronization. </title> <journal> Journal of the ACM, </journal> <volume> 32 </volume> <pages> 804-823, </pages> <year> 1985. </year>
Reference-contexts: longest amount of elapsed real time from the start to the completion of the algorithm, assuming that the time delay between two steps of the same network component is at most unity [13]. (The model proposed in [87] has been subsequently used in the study of several distributed computing problems <ref> [18, 20] </ref>.) We generalize our result for the synchronous model to the asynchronous model at the expense of a factor of 2 in the time complexity. <p> Our result for the asynchronous model is similar in spirit to that of [20], in that our asynchronous algorithm is not obtained by using a general synchronizer <ref> [18] </ref> in 150 conjunction with an algorithm optimized for a synchronous model.
Reference: [19] <author> B. Awerbuch, Y. Bartal, and A. Fiat. </author> <title> Distributed paging for general networks. </title> <booktitle> In Proceedings of the 7th Annual ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <pages> pages 574-583, </pages> <month> January </month> <year> 1996. </year>
Reference-contexts: In future work, we would like to extend our results to models that take into account the differing costs in communication among different nodes. (See <ref> [19, 74, 103] </ref> for recent work in this area.) The parameter c. An important feature of the c-arbitrary crossbar is the parameter c which signifies the bandwidth limitation at each of the nodes of the network. <p> Recent work on locality issues includes algorithms for allocating files on arbitrary networks <ref> [19, 26] </ref>, protocols for accessing nearby objects on restricted classes of networks [74, 103, 117], and caching schemes for the Internet [67]. The most important technical problem left open in this chapter is to extend our analysis to more general models of access patterns. <p> Hence, there is a need for a mechanism to dynamically locate nearby copies of objects. While this problem has been well-studied (see [96] for early work, and <ref> [19, 26, 103] </ref> for recent results), existing solutions either hold for restricted cost models only or suffer from large overhead in storage requirements. (By overhead in storage, we refer to the memory required to store information about the locations of the objects.) Since the above problem has direct applications to the
Reference: [20] <author> B. Awerbuch, L. Cowen, and M. Smith. </author> <title> Efficient asynchronous distributed symmetry breaking. </title> <booktitle> In Proceedings of the 26th Annual ACM Symposium on the Theory of Computing, </booktitle> <pages> pages 214-223, </pages> <year> 1994. </year>
Reference-contexts: longest amount of elapsed real time from the start to the completion of the algorithm, assuming that the time delay between two steps of the same network component is at most unity [13]. (The model proposed in [87] has been subsequently used in the study of several distributed computing problems <ref> [18, 20] </ref>.) We generalize our result for the synchronous model to the asynchronous model at the expense of a factor of 2 in the time complexity. <p> Also related is the result of [39], where a worst-case bound on the number of token migrations is given for a model in which tokens can be transferred between any two nodes. Our result for the asynchronous model is similar in spirit to that of <ref> [20] </ref>, in that our asynchronous algorithm is not obtained by using a general synchronizer [18] in 150 conjunction with an algorithm optimized for a synchronous model.
Reference: [21] <author> B. Awerbuch, S. Kutten, and D. Peleg. </author> <title> Competitive distributed job scheduling. </title> <booktitle> In Proceedings of the 24th Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 571-580, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: This problem has been studied under a model in which edge capacities are infinite <ref> [7, 21, 46] </ref>. For our model, however, results to date are limited to specific instances of the problem [71]. 178 Appendix A Tails of Probability Distributions Theorems A.1 and A.2 provide bounds on the tails of the binomial and hypergeometric distributions, respectively.
Reference: [22] <author> B. Awerbuch and F. T. Leighton. </author> <title> Improved approximation algorithms for the multi-commodity flow problem and local competitive routing in dynamic networks. </title> <booktitle> In Proceedings of the 26th Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 487-496, </pages> <month> May </month> <year> 1994. </year>
Reference-contexts: Our scenario is substantially more involved since we are required to move load between several sources and destinations simultaneously. Another result on dynamic networks is the recent analysis of a local algorithm for the approximate multicommodity flow problem <ref> [22, 23] </ref>. While their result has several applications including the end-to-end communication problem mentioned above, it does not seem to extend to load balancing. Our result on load balancing uses similar techniques; however, our algorithm and analysis are simpler and we obtain worst-case optimal bounds for our problem.
Reference: [23] <author> B. Awerbuch and T. Leighton. </author> <title> A simple local-control approximation algorithm for multi-commodity flow. </title> <booktitle> In Proceedings of the 34th Annual IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pages 459-468, </pages> <month> October </month> <year> 1993. </year>
Reference-contexts: Our scenario is substantially more involved since we are required to move load between several sources and destinations simultaneously. Another result on dynamic networks is the recent analysis of a local algorithm for the approximate multicommodity flow problem <ref> [22, 23] </ref>. While their result has several applications including the end-to-end communication problem mentioned above, it does not seem to extend to load balancing. Our result on load balancing uses similar techniques; however, our algorithm and analysis are simpler and we obtain worst-case optimal bounds for our problem.
Reference: [24] <author> B. Awerbuch, Y. Mansour, and N. Shavit. </author> <title> End-to-end communication with polynomial overhead. </title> <booktitle> In Proceedings of the 30th Annual IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pages 358-363, </pages> <month> October </month> <year> 1989. </year> <month> 200 </month>
Reference-contexts: In general, work on dynamic and asynchronous networks has been limited. In work related to load balancing, for instance, an end-to-end communication problem, namely one in which messages are routed from a single source to a single destination, has been studied in <ref> [4, 24] </ref> on dynamic networks. Our scenario is substantially more involved since we are required to move load between several sources and destinations simultaneously. Another result on dynamic networks is the recent analysis of a local algorithm for the approximate multicommodity flow problem [22, 23].
Reference: [25] <author> Y. Azar, A. Z. Broder, A. R. Karlin, and E. Upfal. </author> <title> Balanced allocations. </title> <booktitle> In Proceedings of the 26th Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 593-602, </pages> <month> May </month> <year> 1994. </year>
Reference-contexts: Our main technical contribution in this chapter is the derivation of sharp threshold phenomena associated with certain random allocation experiments. Several recent papers have studied similar processes that arise in dynamic resource allocation and parallel load balancing <ref> [2, 25, 108] </ref>. 60 Chapter 3 Fast Fault-Tolerant Concurrent Access to Shared Ob jects 3.1 Introduction In this chapter, we design and analyze a simple local protocol for providing fast concurrent access to shared objects in a faulty distributed network.
Reference: [26] <author> Y. Bartal, A. Fiat, and Y. Rabani. </author> <title> Competitive algorithms for distributed data management. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 51 </volume> <pages> 341-358, </pages> <year> 1995. </year>
Reference-contexts: Recent work on locality issues includes algorithms for allocating files on arbitrary networks <ref> [19, 26] </ref>, protocols for accessing nearby objects on restricted classes of networks [74, 103, 117], and caching schemes for the Internet [67]. The most important technical problem left open in this chapter is to extend our analysis to more general models of access patterns. <p> Hence, there is a need for a mechanism to dynamically locate nearby copies of objects. While this problem has been well-studied (see [96] for early work, and <ref> [19, 26, 103] </ref> for recent results), existing solutions either hold for restricted cost models only or suffer from large overhead in storage requirements. (By overhead in storage, we refer to the memory required to store information about the locations of the objects.) Since the above problem has direct applications to the
Reference: [27] <author> H. Bast and T. Hagerup. </author> <title> Fast parallel space allocation, estimation and integer sorting. </title> <journal> Information and Computation, </journal> <volume> 123 </volume> <pages> 72-110, </pages> <year> 1995. </year>
Reference-contexts: A number of models have been proposed for studying load balancing problems. These models can be classified on the basis of three characteristics: (i) centralized control (e.g., [93, 111]) versus distributed control (e.g., [30, Chapter 7] [42]), (ii) shared memory communication such as the PRAM model (e.g., <ref> [27] </ref>), uniform communication (e.g., [111]), or fixed-connection network communication (e.g., [5, 42]), and (iii) unbounded edge capacity (e.g., [30, Chapter 7] [109]) versus bounded edge capacity (e.g., [5, 101]) (the capacity of an edge is the maximum number of tokens it can transmit per step).
Reference: [28] <author> E. Berlekamp and L. Welch. </author> <title> Error correction of algebraic block codes. </title> <type> U.S. Patent Number 4,633,470. </type>
Reference-contexts: Unless the noisy fragments can be easily identified as such, the client cannot efficiently reconstruct the object using IDA. In such a noisy setting, it would be worthwhile to consider variants of our protocol based on the Berlekamp-Welch decoder <ref> [28] </ref> (see also [110, Appendix A]), which tolerates noise in a constant fraction of the fragments. We would like to extend our protocols to other interesting models of distributed computation that incorporate asynchrony or locality information.
Reference: [29] <author> D. Bertsekas and R. Gallager. </author> <title> Data Networks. </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, New Jersey, </address> <year> 1992. </year>
Reference-contexts: If two or more clients attempt to use the channel simultaneously, then there is a collision, and no client succeeds. The standard Ethernet local area network [92] and the classic ALOHA packet radio network [1] are two well-known examples of multiple access channels. (See <ref> [29, Chapter 4] </ref> for more examples.) An optical computer, which can be viewed as a collection of multiple access channels, is accurately modeled by a 1-collision crossbar.
Reference: [30] <author> D. P. Bertsekas and J. N. Tsitsiklis. </author> <title> Parallel and Distributed Computation: Numerical Methods. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1989. </year>
Reference-contexts: A number of models have been proposed for studying load balancing problems. These models can be classified on the basis of three characteristics: (i) centralized control (e.g., [93, 111]) versus distributed control (e.g., <ref> [30, Chapter 7] </ref> [42]), (ii) shared memory communication such as the PRAM model (e.g., [27]), uniform communication (e.g., [111]), or fixed-connection network communication (e.g., [5, 42]), and (iii) unbounded edge capacity (e.g., [30, Chapter 7] [109]) versus bounded edge capacity (e.g., [5, 101]) (the capacity of an edge is the maximum <p> be classified on the basis of three characteristics: (i) centralized control (e.g., [93, 111]) versus distributed control (e.g., <ref> [30, Chapter 7] </ref> [42]), (ii) shared memory communication such as the PRAM model (e.g., [27]), uniform communication (e.g., [111]), or fixed-connection network communication (e.g., [5, 42]), and (iii) unbounded edge capacity (e.g., [30, Chapter 7] [109]) versus bounded edge capacity (e.g., [5, 101]) (the capacity of an edge is the maximum number of tokens it can transmit per step).
Reference: [31] <author> M. A. </author> <title> Blaze. Caching in large-scale distributed file systems. </title> <type> Technical Report TR-397-92, </type> <institution> Department of Computer Science, Princeton University, </institution> <month> January </month> <year> 1993. </year> <type> PhD Thesis. </type>
Reference-contexts: Very broadly, existing protocols can be classified into two categories. The first category consists of implementations where a client accesses a given object by consulting the "manager" of the object to locate a copy (examples include <ref> [31] </ref>, [67], and xFS [11]). The main drawback with this approach is that the manager is usually implemented as a process running at a single node and thus constitutes a sequential bottleneck.
Reference: [32] <author> A. Borodin, J. Kleinberg, P. Raghavan, M. Sudan, and D. P. Williamson. </author> <title> Adversarial queueing theory. </title> <booktitle> In Proceedings of the 28th Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 376-385, </pages> <month> May </month> <year> 1996. </year>
Reference-contexts: Our model is based on an adversarial model that has been proposed recently for studying routing problems <ref> [12, 32] </ref>. We assume that an adversary controls the online process of token arrival and departure. In each step, the adversary determines the locations and the number of tokens that are to be added to or deleted from the system.
Reference: [33] <author> C. M. Bowman, P. B. Danzig, D. R. Hardy, U. Manber, and M. F. Schwartz. </author> <title> The Harvest information discovery and access system. </title> <booktitle> In Proceedings of the 2nd International World Wide Web Conference, </booktitle> <pages> pages 763-771, </pages> <month> October </month> <year> 1994. </year>
Reference-contexts: Instead of sending each request for a given object through a central server, the protocols in the second category forward the request along a path in a tree of nodes, the root of which is the "owner" of the object (examples include [74] and Harvest <ref> [33, 36] </ref>). An advantage of this approach is that if several copies of a given object exist, then a request to the object is satisfied within a small number of forwardings along the path.
Reference: [34] <author> A. Broder, A. M. Frieze, E. Shamir, and E. Upfal. </author> <title> Near-perfect token distribution. </title> <booktitle> Random Structures and Algorithms, </booktitle> <pages> pages 559-572, </pages> <month> 5 </month> <year> 1994. </year> <month> 201 </month>
Reference-contexts: Another class of networks on which load balancing has been studied is the class of expanders. Peleg and Upfal [97] pioneered this study by identifying certain small-degree expanders as being suitable for load balancing. Their work was extended in <ref> [34, 69, 98] </ref>. These algorithms either use strong expanders to approximately balance the network, or the AKS sorting network [6] to perfectly balance the network. Thus, they do not work on networks of arbitrary topology.
Reference: [35] <author> J. L. Carter and M. N. Wegman. </author> <title> Universal classes of hash functions. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 18 </volume> <pages> 143-154, </pages> <year> 1979. </year>
Reference-contexts: is drawn uniformly at random from F k m;n , then Pr [h (x i ) = y i for all i in [j]] = 1=n j : p m;n can be constructed as in [75] using the families H n d ;n and H 1 m;n d defined in <ref> [35] </ref> and [107] respectively. (Here d is an appropriate constant.) A hash function h chosen uniformly at random from F k m;n is defined as r ffi s, where r and s are chosen uniformly at random from H n d ;n and H 1 m;n d respectively. <p> Both r and s can be evaluated in constant time <ref> [107, 35] </ref>, and hence the same is true of h. In order to analyze the 1 out of ` protocol, we restrict our attention to the atmost n memory requests of the processors.
Reference: [36] <author> A. Chankhunthod, P. Danzig, C. Neerdaels, M. Schwartz, and K. Worrell. </author> <title> A hierarchical Internet object cache. </title> <booktitle> In Proceedings of the USENIX 1996 Technical Conference, </booktitle> <pages> pages 22-26, </pages> <month> January </month> <year> 1996. </year>
Reference-contexts: Instead of sending each request for a given object through a central server, the protocols in the second category forward the request along a path in a tree of nodes, the root of which is the "owner" of the object (examples include [74] and Harvest <ref> [33, 36] </ref>). An advantage of this approach is that if several copies of a given object exist, then a request to the object is satisfied within a small number of forwardings along the path.
Reference: [37] <author> H. Chernoff. </author> <title> A measure of the asymptotic efficiency for tests of a hypothesis based on the sum of observations. </title> <journal> Annals of Mathematical Statistics, </journal> <volume> 23 </volume> <pages> 493-509, </pages> <year> 1952. </year>
Reference-contexts: It is straightforward to prove using Chernoff bounds <ref> [37] </ref> that if c is O (1), then the preceding scheme requires fi (log n= log log n) time with high probability to emulate one step of the EREW PRAM. (By the phrase "with high probability", we mean "with probability 1 1=n (1) ".) In Chapter 2, we analyze a class <p> Among other results, we show that Alg2 (n; 3; 1) and Alg2 (n; 2; 2) both terminate in fi (log log n) rounds whp. 2.4.1 Large Deviations For our analysis, we make frequent use of bounds on the tails of the binomial and hypergeometric distributions <ref> [8, 37, 38, 70] </ref>. These bounds are stated in Appendix A. Lemmas 2.6 and 2.7 are obtained from bounds on the tails of the hypergeometric and binomial distributions, respectively. Lemma 2.6: Let S be a set of s balls, and T be a subset of S, t = jT j. <p> By a straightforward Chernoff-type argument <ref> [37] </ref>, we can show that a constant fraction of the client requests for A are satisfied at the current step, establishing Invariant 2. Cache management. Each node has a cache for holding extra object copies. <p> Let a 3 and a 4 be real constants such that for p a 0 log n=n, a 4 np B (n; p) a 3 np wvhp; a 3 and a 4 may be obtained from standard Chernoff bounds <ref> [37] </ref> given in Theorem A.1. Lemma 3.12: Let rounds 0 through r 1 be good. If object A i is bad in rounds 0 through r, then wvhp we have d i (j) = j and e i (j) = j + 1 for 0 j &lt; r. <p> By setting 125 T = d (4 ln 4)=("-2 )e, we obtain E [ t+T ] t =4. By Markov's inequality, the probability that t+T t =2 is at most 1=2. Therefore, using standard Chernoff bounds <ref> [37] </ref>, we can show that in T 0 = 8aT d (log 0 + log n)e steps, T 0 &gt; 1 with probability at most O (1=( 0 ) a + 1=n a ) for any constant a &gt; 0.
Reference: [38] <author> V. Chvatal. </author> <title> The tail of the hypergeometric distribution. </title> <journal> Discrete Mathematics, </journal> <volume> 25 </volume> <pages> 285-287, </pages> <year> 1979. </year>
Reference-contexts: Among other results, we show that Alg2 (n; 3; 1) and Alg2 (n; 2; 2) both terminate in fi (log log n) rounds whp. 2.4.1 Large Deviations For our analysis, we make frequent use of bounds on the tails of the binomial and hypergeometric distributions <ref> [8, 37, 38, 70] </ref>. These bounds are stated in Appendix A. Lemmas 2.6 and 2.7 are obtained from bounds on the tails of the hypergeometric and binomial distributions, respectively. Lemma 2.6: Let S be a set of s balls, and T be a subset of S, t = jT j. <p> It follows from bounds on the tail of the hy-pergeometric distribution <ref> [38] </ref>, given in Theorem A.2, that a constant fraction of the messages in N (A j ; i; t) are attempted by nodes in U 0 . <p> Then, for any real " 0, Pr [t 0 (p + ")s 0 ] e 2" 2 s 0 Pr [t 0 (p ")s 0 ] e 2" 2 s 0 Proof: By <ref> [38, 70] </ref>, Pr [t 0 (p + ")s 0 ] e 2" 2 s 0 179 The lower bound on t 0 can be proved by using the upper bound on s 0 t 0 .
Reference: [39] <author> E. Cohen. </author> <title> On the convergence span of greedy load balancing. </title> <journal> Information Processing Letters, </journal> <volume> 52 </volume> <pages> 181-182, </pages> <year> 1994. </year>
Reference-contexts: However, the results of [14] are geared towards establishing eventual convergence in the presence of dynamic network changes, while we are interested in determining the time to convergence for static load balancing. Also related is the result of <ref> [39] </ref>, where a worst-case bound on the number of token migrations is given for a model in which tokens can be transferred between any two nodes.
Reference: [40] <author> G. Cornuejols, G. L. Nemhauser, and L. A. Wolsey. </author> <title> The uncapacitated facility location problem. </title> <editor> In P. Mirchandani and R. Francis, editors, </editor> <booktitle> Discrete Location Theory, </booktitle> <pages> pages 119-171. </pages> <publisher> John Wiley and Sons, Inc., </publisher> <address> New York, New York, </address> <year> 1990. </year>
Reference-contexts: For a nonuniform network, however, we would like the placement of copies of any object to be determined by the current distribution of requests for the object across the network. This leads us to a well-studied problem in combinatorial optimization, the facility location problem (e.g., see <ref> [40] </ref>). While the facility location problem is NP-complete, constant-factor approximation algorithms for important special cases have been obtained recently [84, 106].
Reference: [41] <author> D. E. Culler, R. M. Karp, D. A. Patterson, A. Sahay, K. E. Schauser, E. Santos, R. Subramonian, and T. von Eicken. </author> <title> LogP: Towards a realistic model of parallel computation. </title> <booktitle> In Proceedings of the 4th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, </booktitle> <pages> pages 1-12, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: This feature is motivated by the observation that with rapidly growing speeds and capacities of communication links, the network-node interface is increasingly limiting the performance of the network <ref> [41] </ref> [99, Chapter 9]. Restrictions on local bandwidth play a significant role in the BSP [115], LogP [41], and QSM (g) [58] models as well. The gap parameter of these models places an upper bound on the rate at which a single node may send or receive messages. <p> This feature is motivated by the observation that with rapidly growing speeds and capacities of communication links, the network-node interface is increasingly limiting the performance of the network <ref> [41] </ref> [99, Chapter 9]. Restrictions on local bandwidth play a significant role in the BSP [115], LogP [41], and QSM (g) [58] models as well. The gap parameter of these models places an upper bound on the rate at which a single node may send or receive messages. However, BSP and LogP differ from the c-arbitrary crossbar on one significant point.
Reference: [42] <author> G. Cybenko. </author> <title> Dynamic load balancing for distributed memory multiprocessors. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 2 </volume> <pages> 279-301, </pages> <year> 1989. </year>
Reference-contexts: A number of models have been proposed for studying load balancing problems. These models can be classified on the basis of three characteristics: (i) centralized control (e.g., [93, 111]) versus distributed control (e.g., [30, Chapter 7] <ref> [42] </ref>), (ii) shared memory communication such as the PRAM model (e.g., [27]), uniform communication (e.g., [111]), or fixed-connection network communication (e.g., [5, 42]), and (iii) unbounded edge capacity (e.g., [30, Chapter 7] [109]) versus bounded edge capacity (e.g., [5, 101]) (the capacity of an edge is the maximum number of tokens <p> These models can be classified on the basis of three characteristics: (i) centralized control (e.g., [93, 111]) versus distributed control (e.g., [30, Chapter 7] [42]), (ii) shared memory communication such as the PRAM model (e.g., [27]), uniform communication (e.g., [111]), or fixed-connection network communication (e.g., <ref> [5, 42] </ref>), and (iii) unbounded edge capacity (e.g., [30, Chapter 7] [109]) versus bounded edge capacity (e.g., [5, 101]) (the capacity of an edge is the maximum number of tokens it can transmit per step). <p> First, the analysis of the rapid convergence of random walks [73, 95] relies on averaging arbitrary probabilities across any edge. This corresponds to sending an arbitrary (possibly nonintegral) load along an edge, which is forbidden in our model. In this sense, the analysis in <ref> [42] </ref> (and all references in the unbounded capacity model) are similar to the random walk analysis. Second, our argument uses an exponential potential function. The analyses in [42, 73, 95], in contrast, use quadratic potential functions. <p> In this sense, the analysis in [42] (and all references in the unbounded capacity model) are similar to the random walk analysis. Second, our argument uses an exponential potential function. The analyses in <ref> [42, 73, 95] </ref>, in contrast, use quadratic potential functions.
Reference: [43] <editor> A. Czumaj, Meyer auf der Heide F., and V. Stemann. </editor> <title> Shared memory simulations with triple-logarithmic delay. </title> <booktitle> In Proceedings of the 3rd Annual European Symposium on Algorithms, </booktitle> <pages> pages 46-59, </pages> <month> September </month> <year> 1995. </year>
Reference-contexts: Czumaj, Meyer auf der Heide, and Stemann presented two randomized protocols for DMMs with O (log log n=(log log log n)) [44] and O (log log log n log fl n) <ref> [43] </ref> delay whp, respectively. Their protocols consist of certain preprocessing steps in which all the nodes of the DMM cooperate in estimating certain quantities associated with the PRAM step (e.g, the number of requests directed to each module). Hence, these protocols are more complicated than the ones we consider here. <p> Hence, these protocols are more complicated than the ones we consider here. Moreover, the simulations of <ref> [44, 43] </ref> do not apply directly to the crossbar model which, as mentioned before, is not as powerful as the DMM model.
Reference: [44] <editor> A. Czumaj, F. Meyer auf der Heide, and V. Stemann. </editor> <title> Improved optimal shared memory simulations, and the power of reconfiguration. </title> <booktitle> In Proceedings of the 3rd Israel Symposium on Theory of Computing and Systems, </booktitle> <pages> pages 11-19, </pages> <year> 1995. </year> <month> 202 </month>
Reference-contexts: Subsequent to our work, faster protocols for EREW PRAM emulation on the closely related DMM model have been obtained. Czumaj, Meyer auf der Heide, and Stemann presented two randomized protocols for DMMs with O (log log n=(log log log n)) <ref> [44] </ref> and O (log log log n log fl n) [43] delay whp, respectively. Their protocols consist of certain preprocessing steps in which all the nodes of the DMM cooperate in estimating certain quantities associated with the PRAM step (e.g, the number of requests directed to each module). <p> Hence, these protocols are more complicated than the ones we consider here. Moreover, the simulations of <ref> [44, 43] </ref> do not apply directly to the crossbar model which, as mentioned before, is not as powerful as the DMM model.
Reference: [45] <author> S. Deering and D. Cheriton. </author> <title> Multicast routing in datagram internetworks and extended LANs. </title> <journal> ACM Transactions on Computer Systems, </journal> <pages> pages 85-111, </pages> <year> 1990. </year>
Reference-contexts: A variety of other well-known methods have been used for solving this problem, including broadcast, combining [105], and multicast <ref> [45] </ref>. However, the class of architectures that support the efficient implementation of these methods is restricted. For example, a single-bus network can efficiently support broadcast, which enables an arbitrary subset of the processors to obtain copies of a single object at the same time.
Reference: [46] <author> X. Deng, H. N. Liu, L. Long, and B. Xiao. </author> <title> Competitive analysis of network load balancing. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 40 </volume> <pages> 162-172, </pages> <year> 1997. </year>
Reference-contexts: This problem has been studied under a model in which edge capacities are infinite <ref> [7, 21, 46] </ref>. For our model, however, results to date are limited to specific instances of the problem [71]. 178 Appendix A Tails of Probability Distributions Theorems A.1 and A.2 provide bounds on the tails of the binomial and hypergeometric distributions, respectively.
Reference: [47] <editor> M. Dietzfelbinger and F. Meyer auf der Heide. </editor> <title> Simple, efficient shared memory simulations. </title> <booktitle> In Proceedings of the 5th Annual ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 110-119, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: We remark that prior to our work, Karp, Luby, and Meyer auf der Heide [75], and subsequently, Dietzfelbinger and Meyer auf der Heide <ref> [47] </ref>, presented protocols that achieve the O (log log n) delay bound while incurring only a constant factor increase in space. Our results improve on previous results in two ways. First, our results hold for all values of c, while previous emulations required c to be sufficiently large. <p> The local memory PRAM model of An-derson and Miller [10], later studied under the name OCPC (optical communication parallel computer) in [51, 60, 61], corresponds to the 1-collision crossbar model. The c-arbitrary and c-collision DMM models of <ref> [47, 75] </ref> are similar to the crossbar models in that the underlying communication network is a complete network. <p> If c = O (1), we can conclude that the preceding scheme requires (lg n= lg lg n) time whp 1 to emulate one step of the EREW PRAM. On the other hand, Dietzfelbinger and Meyer auf der Heide <ref> [47] </ref> have recently shown that a bound of O (lg lg n) time per EREW PRAM step is attainable for constant c. <p> Thus, at the expense of increasing the storage requirement by a factor of 3, the running time of the emulation is exponentially decreased. In the protocol of <ref> [47] </ref>, a read or write operation of memory location x by EREW PRAM processor i is emulated by having processor i of the c-collision crossbar access 2 out of the 3 copies corresponding to memory location x. The analysis presented in [47] requires some slack in the constants; in particular, they <p> In the protocol of <ref> [47] </ref>, a read or write operation of memory location x by EREW PRAM processor i is emulated by having processor i of the c-collision crossbar access 2 out of the 3 copies corresponding to memory location x. The analysis presented in [47] requires some slack in the constants; in particular, they require c 3, and are only able to analyze the protocol when it is used to emulate "n processors at a time, where " is 1 Recall that the term whp, which is defined in Section 1.3, means with probability 1 <p> time, where " is 1 Recall that the term whp, which is defined in Section 1.3, means with probability 1 n ff for some constant ff. 17 a sufficiently small positive constant. (Thus, the overall running time of the protocol is increased by a factor of 1=".) The protocol of <ref> [47] </ref> is easily generalized to the "a out of b problem", in which b hash functions are used, and each node of the c-collision crossbar is required to access a out of b copies of a particular memory location. <p> Interestingly, this is not the case; rather, as discussed in Section 2.6, our reduction yields a faster a out of b protocol than is obtained via the natural generalization of <ref> [47] </ref> for virtually all possible values of a and b. 2.1.2 Related Work The ideas of hashing and replication have played a central role in almost all of the known shared memory simulations. Mehlhorn and Vishkin [91] proposed distributing the shared objects using universal hashing. <p> A deterministic simulation with delay O (log n) was presented in [9]; however, their result is non-constructive. Karp, Luby, and Meyer auf der Heide [75] presented a protocol that uses three hash functions and incurs O (log log n) delay. Subsequently, Dietzfelbinger and Meyer auf der Heide <ref> [47] </ref> proved the same bound for a much simpler protocol which forms the basis for our work. Subsequent to our work, faster protocols for EREW PRAM emulation on the closely related DMM model have been obtained. <p> Each round is executed in a synchronous fashion. We refer to this protocol as the 1 out of ` protocol. (This is analogous to Access Schedule 2 of <ref> [47] </ref>, defined for the 2 out of 3 problem.) 2.3 Sketch of the Analysis In order to understand the execution of the 1 out of ` protocol, let us consider the underlying process in an equivalent balls-and-bins setup. Assume for simplicity that the protocol is running on a 1-collision crossbar. <p> For given a and b, the analysis of the generic protocol can be done using the approach of Subsection 2.4.3, but involves more complicated calculations and recurrences. A different analysis of this protocol for the 2 out of 3 case is given in <ref> [47] </ref>, where an O (log log n) upper bound is shown when the collision factor is greater than 3. <p> One way to reduce delay is to introduce parallel slackness by emulating a non-constant number of EREW PRAM processors on a node of the crossbar. The concept of parallel slackness has been used by <ref> [47, 63, 75] </ref> to obtain work-optimal emulations. A work-optimal emulation with delay d (n) is a protocol that emulates a d (n)-processor EREW PRAM on an n-processor crossbar in O (d (n)) time.
Reference: [48] <author> D. Eager, D. Lazowska, and J. Zahorjan. </author> <title> Adaptive load sharing in homogeneous distributed systems. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 12 </volume> <pages> 662-675, </pages> <year> 1986. </year>
Reference-contexts: Our results for static load balancing also apply to certain problems where the load is dynamic, that is, the total load varies with time 1 . Dynamic load balancing is required in a wide variety of applications, including operating systems <ref> [48, 83] </ref>, combinatorial optimization problems [80], adaptive mesh partitioning [68, 118], and fine-grain functional programming [59]. In certain problems arising in these applications, it is possible to divide the overall computation into phases, where the distributed system alternates between static load balancing and executing a portion of the workload. <p> any algorithm will 116 take at least d=ffe steps to balance the network to within one token. 4.1.3 Related Work Load balancing has been studied extensively because it arises in a wide variety of settings including adaptive mesh partitioning [68, 118], fine-grain functional programming [59], job scheduling in operating systems <ref> [48, 83] </ref>, and distributed tree searching [76, 86]. A number of models have been proposed for studying load balancing problems.
Reference: [49] <author> S. Fortune and J. Wyllie. </author> <title> Parallelism in random access machines. </title> <booktitle> In Proceedings of the 10th Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 114-118, </pages> <month> May </month> <year> 1978. </year>
Reference-contexts: We begin by reviewing the definitions of these two computational models. An EREW PRAM <ref> [49] </ref> is a collection of n processors along with a global shared memory. Input and output are provided in the shared memory. In a single computational step, each processor can read or write one memory location.
Reference: [50] <author> J. E. Gehrke, C. G. Plaxton, and R. Rajaraman. </author> <title> Rapid convergence of a local load balancing algorithm for asynchronous rings. </title> <booktitle> In Proceedings of the 11th International Workshop on Distributed Algorithms, </booktitle> <month> September </month> <year> 1997. </year> <note> To appear. </note>
Reference-contexts: The results in Chapter 5 are joint work with Johannes Gehrke and Greg Plaxton, and appear in <ref> [50] </ref>. 1.2.3 Dynamic Load Balancing In order to study the dynamic aspect of load balancing, we introduce the adversarial model in Chapter 6. In this model, tokens are created and/or destroyed in each step, and an adversary decides the number of these tokens and the location of each token.
Reference: [51] <author> M. Gereb-Graus and T. Tsantilas. </author> <title> Efficient optical communication in parallel computers. </title> <booktitle> In Proceedings of the 4th Annual ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 41-48, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: The module parallel computer (MPC [9]) and the S*PRAM [116] correspond to the 1-arbitrary crossbar model. The local memory PRAM model of An-derson and Miller [10], later studied under the name OCPC (optical communication parallel computer) in <ref> [51, 60, 61] </ref>, corresponds to the 1-collision crossbar model. The c-arbitrary and c-collision DMM models of [47, 75] are similar to the crossbar models in that the underlying communication network is a complete network. <p> This idea is central to many MAC protocols, including the Ethernet protocol [92] and the slotted ALOHA 20 protocol [1], and routing protocols for the optical computer <ref> [10, 116, 51] </ref>. (For more work in this direction, see [64, 65].) Lower bounds for routing in optical computers appear in [62, 88]. 2.2 The 1 out of ` Protocol Consider the 1 out of ` problem where ` 1.
Reference: [52] <author> B. Ghosh, F. T. Leighton, B. M. Maggs, S. Muthukrishnan, C. G. Plaxton, R. Ra-jaraman, A. W. Richa, R. E. Tarjan, and D. Zuckerman. </author> <title> Tight analyses of two local load balancing algorithms. </title> <booktitle> In Proceedings of the 27th Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 548-558, </pages> <month> May </month> <year> 1995. </year>
Reference-contexts: The results in Chapter 4 are joint work with Bhaskar Ghosh, Tom Leighton, Bruce Maggs, S. Muthukrishnan, Greg Plaxton, Andrea Richa, Robert Tarjan, and David Zuckerman, and have appeared in <ref> [52] </ref>. One shortcoming of our results in Chapter 4 is that the bounds on the final imbalance and the time taken to achieve the final imbalance are not optimal for all initial distributions. In Chapter 5, we establish a "universal" near-optimality result for the special class of ring networks.
Reference: [53] <author> B. Ghosh, F. T. Leighton, B. M. Maggs, S. Muthukrishnan, C. G. Plaxton, R. Ra-jaraman, A. W. Richa, R. E. Tarjan, and D. Zuckerman. </author> <title> Tight analyses of two local 203 load balancing algorithms. </title> <booktitle> In Proceedings of the 27th Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 548-558, </pages> <month> May </month> <year> 1995. </year>
Reference-contexts: However, even after reducing the global imbalance to a small value, the time for either of these algorithms to reach a locally balanced state can be quite large. For example, it is shown in <ref> [53] </ref> that after reaching a state that is globally balanced to within O ((d log n)=) tokens, the multi-port 146 algorithm may take another (n 1=2 ) steps to reach a state that is locally balanced to within 2d tokens. (A similar result for the single-port algorithm is also contained in <p> that after reaching a state that is globally balanced to within O ((d log n)=) tokens, the multi-port 146 algorithm may take another (n 1=2 ) steps to reach a state that is locally balanced to within 2d tokens. (A similar result for the single-port algorithm is also contained in <ref> [53] </ref>.) Performance ratio for all distributions. It is open whether the time taken by the local balancing approach is asymptotically optimal for all distributions on all networks. We believe that an improved analysis will require substantially new techniques that consider the particular topology of the given network in greater detail.
Reference: [54] <author> B. Ghosh and S. Muthukrishnan. </author> <title> Dynamic load balancing in parallel and distributed networks by random matchings. </title> <booktitle> In Proceedings of the 6th Annual ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 226-235, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: We also obtain tight bounds on a randomized algorithm of Ghosh and Muthukrishnan <ref> [54] </ref> which balances load across edges chosen in a random matching. <p> Otherwise, a token is sent from the node with more tokens to the node with fewer. Figure 4.2 illustrates one step of the single-port algorithm on the example given in Figure 4.1. This algorithm was first analyzed in <ref> [54] </ref>. (The single-port algorithm is sometimes referred to as the dimension-exchange method in the load balancing literature [119].) The multi-port algorithm is 113 The bold edges are the edges that are chosen in the random matching. simpler and deterministic. <p> In contrast, our local algorithm works on any dynamic network that remains connected. On arbitrary topologies, load balancing algorithms that use bounded edge capacity were first proposed and analyzed in [5] for the multi-port variant and in <ref> [54] </ref> 117 for the single-port variant. The associated upper bounds are suboptimal by factors of (log (n)) and ( n), respectively. We improve these results for both single-port and multi-port variants. As remarked earlier, our multi-port results (and those in [5]) hold even for dynamic or asynchronous networks. <p> Second, our argument uses an exponential potential function. The analyses in [42, 73, 95], in contrast, use quadratic potential functions. Our potential function and our amortized analysis appear to be necessary since a number of previous attempts using quadratic potential functions yielded suboptimal results <ref> [5, 54] </ref> for local load balancing. 118 4.2 Preliminaries For any network G = (V; E) with n nodes and edge expansion ff, we denote the number of tokens at v 2 V by w (v). <p> In order to prove the upper bound on E [ i ], we place a lower bound on E [m i ] that is obtained from the following lemma of <ref> [54] </ref>. Lemma 4.2 ([54]): For any edge e 2 E, the probability that e is selected in the matching is at least 1=(8d).
Reference: [55] <author> P. Gibbons, Y. Matias, and V. Ramachandran. </author> <title> The QRQW PRAM: Accounting for contention in parallel algorithms. </title> <booktitle> In Proceedings of the 5th Annual ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <pages> pages 638-648, </pages> <month> January </month> <year> 1994. </year> <note> To appear in SIAM Journal on Computing. </note>
Reference-contexts: As mentioned in Section 1.1.1, the c-arbitrary crossbar is a distributed memory model that addresses the issue of contention by placing a restriction on the bandwidth at each node. Among shared memory models, a well-studied model that addresses contention is the QRQW PRAM <ref> [57, 55, 56] </ref>. The QRQW PRAM extends the EREW 16 PRAM model by allowing simultaneous access to a cell in any step and allowing processor instructions to be pipelined. <p> On the other hand, the cost of implementing broadcast in a distributed network with point-to-point connections is significant. Our hashing techniques are loosely related to Valiant's hashing-based combining mechanism for simulating CRCW PRAM algorithms on parallel computers [114]. In other related work, Gibbons, Matias, and Ramachandran <ref> [55] </ref> adopt a different approach to account for contention in parallel algorithms. They introduce the QRQW PRAM 64 model, which permits concurrent reading and writing but at a cost proportional to the number of readers/writers to a memory location in a given step. <p> They introduce the QRQW PRAM 64 model, which permits concurrent reading and writing but at a cost proportional to the number of readers/writers to a memory location in a given step. The focus of our algorithm design and analysis is different. While <ref> [55] </ref> and [114] are primarily concerned with the problem of PRAM emulation, we have optimized our protocol to obtain fast performance (e.g., expected O (1) time) on a more restricted class of access patterns.
Reference: [56] <author> P. Gibbons, Y. Matias, and V. Ramachandran. </author> <title> The queue-read queue-write asynchronous PRAM model. </title> <booktitle> In Proceedings of Euro-Par'96, Lecture Notes in Computer Science, </booktitle> <pages> pages 279-292. </pages> <publisher> Springer-Verlag, </publisher> <month> August </month> <year> 1996. </year> <note> To appear in the special issue of Theoretical Computer Science on Parallel Computing. </note>
Reference-contexts: As mentioned in Section 1.1.1, the c-arbitrary crossbar is a distributed memory model that addresses the issue of contention by placing a restriction on the bandwidth at each node. Among shared memory models, a well-studied model that addresses contention is the QRQW PRAM <ref> [57, 55, 56] </ref>. The QRQW PRAM extends the EREW 16 PRAM model by allowing simultaneous access to a cell in any step and allowing processor instructions to be pipelined.
Reference: [57] <author> P. B. Gibbons, Y. Matias, and V. Ramachandran. </author> <title> Efficient low-contention parallel algorithms. </title> <booktitle> In Proceedings of the 6th Annual ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 236-247, </pages> <month> June </month> <year> 1994. </year> <note> To appear in the special issue of Theoretical Computer Science on Parallel Computing. </note>
Reference-contexts: As mentioned in Section 1.1.1, the c-arbitrary crossbar is a distributed memory model that addresses the issue of contention by placing a restriction on the bandwidth at each node. Among shared memory models, a well-studied model that addresses contention is the QRQW PRAM <ref> [57, 55, 56] </ref>. The QRQW PRAM extends the EREW 16 PRAM model by allowing simultaneous access to a cell in any step and allowing processor instructions to be pipelined.
Reference: [58] <author> P. B. Gibbons, Y. Matias, and V. Ramachandran. </author> <title> Can a shared-memory model serve as a bridging model for parallel computation? In Proceedings of the 9th Annual ACM Symposium on Parallel Algorithms and Architectures, </title> <address> pages 72-83, </address> <month> June </month> <year> 1997. </year>
Reference-contexts: This feature is motivated by the observation that with rapidly growing speeds and capacities of communication links, the network-node interface is increasingly limiting the performance of the network [41] [99, Chapter 9]. Restrictions on local bandwidth play a significant role in the BSP [115], LogP [41], and QSM (g) <ref> [58] </ref> models as well. The gap parameter of these models places an upper bound on the rate at which a single node may send or receive messages. However, BSP and LogP differ from the c-arbitrary crossbar on one significant point. <p> These models may not be appropriate for networks where the bandwidth of the network as a whole is the limiting factor. For such networks, we need to place global restrictions on the bandwidth, as is done in the PRAM (m) [90] and the QSM (m) <ref> [58] </ref> models.
Reference: [59] <author> B. Goldberg and P. Hudak. </author> <title> Implementing functional programs on a hypercube multiprocessor. </title> <booktitle> In Proceedings of the 4th Conference on Hypercubes, Concurrent Computers and Applications, </booktitle> <pages> pages 489-503, </pages> <year> 1989. </year>
Reference-contexts: Dynamic load balancing is required in a wide variety of applications, including operating systems [48, 83], combinatorial optimization problems [80], adaptive mesh partitioning [68, 118], and fine-grain functional programming <ref> [59] </ref>. In certain problems arising in these applications, it is possible to divide the overall computation into phases, where the distributed system alternates between static load balancing and executing a portion of the workload. <p> an initial token distribution such that any algorithm will 116 take at least d=ffe steps to balance the network to within one token. 4.1.3 Related Work Load balancing has been studied extensively because it arises in a wide variety of settings including adaptive mesh partitioning [68, 118], fine-grain functional programming <ref> [59] </ref>, job scheduling in operating systems [48, 83], and distributed tree searching [76, 86]. A number of models have been proposed for studying load balancing problems.
Reference: [60] <author> L. A. Goldberg and M. Jerrum. </author> <title> A sub-logarithmic communication algorithm for the completely connected optical communication parallel computer. </title> <type> Technical Re 204 port ECS-LFCS-92-234, </type> <institution> Laboratory for Foundations of Computer Science, De--partment of Computer Science, University of Edinburgh, </institution> <month> September </month> <year> 1992. </year>
Reference-contexts: The module parallel computer (MPC [9]) and the S*PRAM [116] correspond to the 1-arbitrary crossbar model. The local memory PRAM model of An-derson and Miller [10], later studied under the name OCPC (optical communication parallel computer) in <ref> [51, 60, 61] </ref>, corresponds to the 1-collision crossbar model. The c-arbitrary and c-collision DMM models of [47, 75] are similar to the crossbar models in that the underlying communication network is a complete network.
Reference: [61] <author> L. A. Goldberg, M. Jerrum, F. T. Leighton, and S. B. Rao. </author> <title> A doubly logarithmic communication algorithm for the completely connected optical communication parallel computer. </title> <booktitle> In Proceedings of the 5th Annual ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 300-309, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: The module parallel computer (MPC [9]) and the S*PRAM [116] correspond to the 1-arbitrary crossbar model. The local memory PRAM model of An-derson and Miller [10], later studied under the name OCPC (optical communication parallel computer) in <ref> [51, 60, 61] </ref>, corresponds to the 1-collision crossbar model. The c-arbitrary and c-collision DMM models of [47, 75] are similar to the crossbar models in that the underlying communication network is a complete network.
Reference: [62] <author> L. A. Goldberg, M. Jerrum, and P. D. Mackenzie. </author> <title> An ( p log log n) lower bound for routing on optical networks. </title> <booktitle> In Proceedings of the 6th Annual ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 147-156, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: This idea is central to many MAC protocols, including the Ethernet protocol [92] and the slotted ALOHA 20 protocol [1], and routing protocols for the optical computer [10, 116, 51]. (For more work in this direction, see [64, 65].) Lower bounds for routing in optical computers appear in <ref> [62, 88] </ref>. 2.2 The 1 out of ` Protocol Consider the 1 out of ` problem where ` 1. Let the ` hash functions be labeled h i , 0 i &lt; `, and the shared memory request of node j be for cell x j .
Reference: [63] <author> L. A. Goldberg, Y. Matias, and S. B. Rao. </author> <title> An optical simulation of shared memory. </title> <booktitle> In Proceedings of the 6th Annual ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 257-267, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: One way to reduce delay is to introduce parallel slackness by emulating a non-constant number of EREW PRAM processors on a node of the crossbar. The concept of parallel slackness has been used by <ref> [47, 63, 75] </ref> to obtain work-optimal emulations. A work-optimal emulation with delay d (n) is a protocol that emulates a d (n)-processor EREW PRAM on an n-processor crossbar in O (d (n)) time.
Reference: [64] <author> A. G. Greenberg, P. Flajolet, and R. E. Ladner. </author> <title> Estimating the multiplicities of conflicts to speed their resolution in multiple access channels. </title> <journal> Journal of the ACM, </journal> <volume> 34 </volume> <pages> 289-325, </pages> <year> 1987. </year>
Reference-contexts: This idea is central to many MAC protocols, including the Ethernet protocol [92] and the slotted ALOHA 20 protocol [1], and routing protocols for the optical computer [10, 116, 51]. (For more work in this direction, see <ref> [64, 65] </ref>.) Lower bounds for routing in optical computers appear in [62, 88]. 2.2 The 1 out of ` Protocol Consider the 1 out of ` problem where ` 1.
Reference: [65] <author> A. G. Greenberg and S. Winograd. </author> <title> A lower bound on the time needed in the worst case to resolve conflicts deterministically in multiple access channels. </title> <journal> Journal of the ACM, </journal> <volume> 32 </volume> <pages> 589-596, </pages> <year> 1985. </year>
Reference-contexts: This idea is central to many MAC protocols, including the Ethernet protocol [92] and the slotted ALOHA 20 protocol [1], and routing protocols for the optical computer [10, 116, 51]. (For more work in this direction, see <ref> [64, 65] </ref>.) Lower bounds for routing in optical computers appear in [62, 88]. 2.2 The 1 out of ` Protocol Consider the 1 out of ` problem where ` 1.
Reference: [66] <author> J. D. Guyton and M. F. Schwartz. </author> <title> Locating nearby copies of replicated Internet servers. </title> <booktitle> In Proceedings of ACM SIGCOMM, </booktitle> <pages> pages 288-298, </pages> <year> 1995. </year>
Reference-contexts: 103] for recent results), existing solutions either hold for restricted cost models only or suffer from large overhead in storage requirements. (By overhead in storage, we refer to the memory required to store information about the locations of the objects.) Since the above problem has direct applications to the Internet <ref> [66, 117] </ref>, an efficient solution would be of great interest. 177 Sharing Processors In the second part of the dissertation, we analyzed the effectiveness of a local balancing strategy in which each node repeatedly balances its load with its neighbors.
Reference: [67] <author> J. S. Gwertzman and M. Seltzer. </author> <title> The case for geographical push-caching. </title> <booktitle> In Proceedings of the 5th Workshop on Hot Topics in Operating Systems, </booktitle> <pages> pages 51-57, </pages> <month> May </month> <year> 1995. </year>
Reference-contexts: Very broadly, existing protocols can be classified into two categories. The first category consists of implementations where a client accesses a given object by consulting the "manager" of the object to locate a copy (examples include [31], <ref> [67] </ref>, and xFS [11]). The main drawback with this approach is that the manager is usually implemented as a process running at a single node and thus constitutes a sequential bottleneck. <p> Recent work on locality issues includes algorithms for allocating files on arbitrary networks [19, 26], protocols for accessing nearby objects on restricted classes of networks [74, 103, 117], and caching schemes for the Internet <ref> [67] </ref>. The most important technical problem left open in this chapter is to extend our analysis to more general models of access patterns.
Reference: [68] <author> A. Heirich and S. Taylor. </author> <title> A parabolic theory of load balance. </title> <type> Technical Report Caltech-CS-TR-93-22, </type> <institution> Caltech Scalable Concurrent Computation Lab, </institution> <month> March </month> <year> 1993. </year>
Reference-contexts: Our results for static load balancing also apply to certain problems where the load is dynamic, that is, the total load varies with time 1 . Dynamic load balancing is required in a wide variety of applications, including operating systems [48, 83], combinatorial optimization problems [80], adaptive mesh partitioning <ref> [68, 118] </ref>, and fine-grain functional programming [59]. In certain problems arising in these applications, it is possible to divide the overall computation into phases, where the distributed system alternates between static load balancing and executing a portion of the workload. <p> 2d=ffe steps, while there exists an initial token distribution such that any algorithm will 116 take at least d=ffe steps to balance the network to within one token. 4.1.3 Related Work Load balancing has been studied extensively because it arises in a wide variety of settings including adaptive mesh partitioning <ref> [68, 118] </ref>, fine-grain functional programming [59], job scheduling in operating systems [48, 83], and distributed tree searching [76, 86]. A number of models have been proposed for studying load balancing problems. <p> Local algorithms restricted to particular networks have been studied on counting networks [15, 78], hypercubes [72, 101], and meshes <ref> [68, 93] </ref>. Another class of networks on which load balancing has been studied is the class of expanders. Peleg and Upfal [97] pioneered this study by identifying certain small-degree expanders as being suitable for load balancing. Their work was extended in [34, 69, 98].
Reference: [69] <author> K. Herley. </author> <title> A note on the token distribution problem. </title> <journal> Information Processing Letters, </journal> <volume> 28 </volume> <pages> 329-334, </pages> <year> 1991. </year>
Reference-contexts: Another class of networks on which load balancing has been studied is the class of expanders. Peleg and Upfal [97] pioneered this study by identifying certain small-degree expanders as being suitable for load balancing. Their work was extended in <ref> [34, 69, 98] </ref>. These algorithms either use strong expanders to approximately balance the network, or the AKS sorting network [6] to perfectly balance the network. Thus, they do not work on networks of arbitrary topology.
Reference: [70] <author> W. Hoeffding. </author> <title> Probability inequalities for sums of bounded random variables. </title> <journal> Journal of the American Statistical Association, </journal> <volume> 58 </volume> <pages> 13-30, </pages> <year> 1963. </year>
Reference-contexts: Among other results, we show that Alg2 (n; 3; 1) and Alg2 (n; 2; 2) both terminate in fi (log log n) rounds whp. 2.4.1 Large Deviations For our analysis, we make frequent use of bounds on the tails of the binomial and hypergeometric distributions <ref> [8, 37, 38, 70] </ref>. These bounds are stated in Appendix A. Lemmas 2.6 and 2.7 are obtained from bounds on the tails of the hypergeometric and binomial distributions, respectively. Lemma 2.6: Let S be a set of s balls, and T be a subset of S, t = jT j. <p> Then, for any real " 0, Pr [t 0 (p + ")s 0 ] e 2" 2 s 0 Pr [t 0 (p ")s 0 ] e 2" 2 s 0 Proof: By <ref> [38, 70] </ref>, Pr [t 0 (p + ")s 0 ] e 2" 2 s 0 179 The lower bound on t 0 can be proved by using the upper bound on s 0 t 0 .
Reference: [71] <author> B. Hoppe and E. Tardos. </author> <title> The quickest transshipment problem. </title> <booktitle> In Proceedings of the 6th Annual ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <pages> pages 512-521, </pages> <month> January </month> <year> 1996. </year>
Reference-contexts: This problem has been studied under a model in which edge capacities are infinite [7, 21, 46]. For our model, however, results to date are limited to specific instances of the problem <ref> [71] </ref>. 178 Appendix A Tails of Probability Distributions Theorems A.1 and A.2 provide bounds on the tails of the binomial and hypergeometric distributions, respectively.
Reference: [72] <author> J. Jaja and K. W. Ryu. </author> <title> Load balancing and routing on the hypercube and related networks. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 14 </volume> <pages> 431-435, </pages> <year> 1992. </year>
Reference-contexts: Local algorithms restricted to particular networks have been studied on counting networks [15, 78], hypercubes <ref> [72, 101] </ref>, and meshes [68, 93]. Another class of networks on which load balancing has been studied is the class of expanders. Peleg and Upfal [97] pioneered this study by identifying certain small-degree expanders as being suitable for load balancing. Their work was extended in [34, 69, 98].
Reference: [73] <author> M. R. Jerrum and A. Sinclair. </author> <title> Conductance and the rapid mixing property for Markov chains: The approximation of the permanent resolved. </title> <booktitle> In Proceedings of the 20th Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 235-244, </pages> <month> May </month> <year> 1988. </year>
Reference-contexts: Indeed the convergence bounds in both cases depend on the expansion properties of the underlying network and they are established using potential function arguments. There are however two important differences. First, the analysis of the rapid convergence of random walks <ref> [73, 95] </ref> relies on averaging arbitrary probabilities across any edge. This corresponds to sending an arbitrary (possibly nonintegral) load along an edge, which is forbidden in our model. In this sense, the analysis in [42] (and all references in the unbounded capacity model) are similar to the random walk analysis. <p> In this sense, the analysis in [42] (and all references in the unbounded capacity model) are similar to the random walk analysis. Second, our argument uses an exponential potential function. The analyses in <ref> [42, 73, 95] </ref>, in contrast, use quadratic potential functions.
Reference: [74] <author> D. Karger, E. Lehman, T. Leighton, M. Levine, D. Lewin, and R. Panigrahy. </author> <title> Relieving hot spots on the World Wide Web. </title> <booktitle> In Proceedings of the 29th Annual ACM Symposium on the Theory of Computing, </booktitle> <pages> pages 654-663, </pages> <month> May </month> <year> 1997. </year>
Reference-contexts: In future work, we would like to extend our results to models that take into account the differing costs in communication among different nodes. (See <ref> [19, 74, 103] </ref> for recent work in this area.) The parameter c. An important feature of the c-arbitrary crossbar is the parameter c which signifies the bandwidth limitation at each of the nodes of the network. <p> Instead of sending each request for a given object through a central server, the protocols in the second category forward the request along a path in a tree of nodes, the root of which is the "owner" of the object (examples include <ref> [74] </ref> and Harvest [33, 36]). An advantage of this approach is that if several copies of a given object exist, then a request to the object is satisfied within a small number of forwardings along the path. <p> Recent work on locality issues includes algorithms for allocating files on arbitrary networks [19, 26], protocols for accessing nearby objects on restricted classes of networks <ref> [74, 103, 117] </ref>, and caching schemes for the Internet [67]. The most important technical problem left open in this chapter is to extend our analysis to more general models of access patterns.
Reference: [75] <author> R. Karp, M. Luby, and F. Meyer auf der Heide. </author> <title> Efficient PRAM simulation on a distributed memory machine. </title> <booktitle> In Proceedings of the 24th Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 318-326, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: We remark that prior to our work, Karp, Luby, and Meyer auf der Heide <ref> [75] </ref>, and subsequently, Dietzfelbinger and Meyer auf der Heide [47], presented protocols that achieve the O (log log n) delay bound while incurring only a constant factor increase in space. Our results improve on previous results in two ways. <p> The local memory PRAM model of An-derson and Miller [10], later studied under the name OCPC (optical communication parallel computer) in [51, 60, 61], corresponds to the 1-collision crossbar model. The c-arbitrary and c-collision DMM models of <ref> [47, 75] </ref> are similar to the crossbar models in that the underlying communication network is a complete network. <p> A deterministic simulation with delay O (log n) was presented in [9]; however, their result is non-constructive. Karp, Luby, and Meyer auf der Heide <ref> [75] </ref> presented a protocol that uses three hash functions and incurs O (log log n) delay. Subsequently, Dietzfelbinger and Meyer auf der Heide [47] proved the same bound for a much simpler protocol which forms the basis for our work. <p> `1 2 [n] j , j 2 [k + 1], it holds that if h is drawn uniformly at random from F k m;n , then Pr [h (x i ) = y i for all i in [j]] = 1=n j : p m;n can be constructed as in <ref> [75] </ref> using the families H n d ;n and H 1 m;n d defined in [35] and [107] respectively. (Here d is an appropriate constant.) A hash function h chosen uniformly at random from F k m;n is defined as r ffi s, where r and s are chosen uniformly at <p> One way to reduce delay is to introduce parallel slackness by emulating a non-constant number of EREW PRAM processors on a node of the crossbar. The concept of parallel slackness has been used by <ref> [47, 63, 75] </ref> to obtain work-optimal emulations. A work-optimal emulation with delay d (n) is a protocol that emulates a d (n)-processor EREW PRAM on an n-processor crossbar in O (d (n)) time.
Reference: [76] <author> R. Karp and Y. Zhang. </author> <title> A randomized parallel branch-and-bound procedure. </title> <journal> Journal of the ACM, </journal> <volume> 40 </volume> <pages> 765-789, </pages> <year> 1993. </year>
Reference-contexts: least d=ffe steps to balance the network to within one token. 4.1.3 Related Work Load balancing has been studied extensively because it arises in a wide variety of settings including adaptive mesh partitioning [68, 118], fine-grain functional programming [59], job scheduling in operating systems [48, 83], and distributed tree searching <ref> [76, 86] </ref>. A number of models have been proposed for studying load balancing problems.
Reference: [77] <author> R. M. Karp. </author> <title> Parallel combinatorial computing. </title> <editor> In J. P. Mesirov, editor, </editor> <booktitle> Very Large Scale Computation in the 21st Century, </booktitle> <pages> pages 221-238. </pages> <institution> Society for Industrial and Applied Mathematics, </institution> <year> 1991. </year> <month> 206 </month>
Reference-contexts: Parallel computations such as large-scale partial differential equations, finite element methods, branch-and-bound computations, and ray tracing, can be divided into a large number of small computational tasks and distributed among the processors at the start of the overall computation (see <ref> [77, 118] </ref> for some examples). Another important application of static load balancing arises in certain packet routing problems, where the initial distribution of packets may be irregular.
Reference: [78] <author> M. R. Klugerman and C. G. Plaxton. </author> <title> Small-depth counting networks. </title> <booktitle> In Proceed--ings of the 24th Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 417-428, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: In the discussion that follows, we restrict our attention to models of computation with the same basic characteristics as the model considered in this chapter, namely: distributed control, fixed-connection network communication, and bounded edge capacity. Local algorithms restricted to particular networks have been studied on counting networks <ref> [15, 78] </ref>, hypercubes [72, 101], and meshes [68, 93]. Another class of networks on which load balancing has been studied is the class of expanders. Peleg and Upfal [97] pioneered this study by identifying certain small-degree expanders as being suitable for load balancing.
Reference: [79] <author> L. Lamport and N. Lynch. </author> <title> Distributed computing: Models and methods. </title> <editor> In J. van Leeuwen, editor, </editor> <booktitle> Handbook of Theoretical Computer Science, Volume B: Formal Models and Semantics, </booktitle> <pages> pages 1157-1199. </pages> <publisher> Elsevier/MIT Press, </publisher> <year> 1990. </year>
Reference-contexts: Our next result concerns an asynchronous model of computation, in which local computations may be performed at arbitrary speeds and messages may be delayed arbitrarily, subject to the constraint that each message is eventually delivered and each computation is eventually performed <ref> [79] </ref>. In order to measure the time complexity in the asynchronous model, we define a round to be a minimal sequence of steps in which each component of the ring (i.e., each node or edge) is scheduled at least once.
Reference: [80] <author> E. L. Lawler and D. E. Wood. </author> <title> Branch and bound methods: a survey. </title> <journal> Operations Research, </journal> <volume> 14 </volume> <pages> 699-719, </pages> <year> 1966. </year>
Reference-contexts: Our results for static load balancing also apply to certain problems where the load is dynamic, that is, the total load varies with time 1 . Dynamic load balancing is required in a wide variety of applications, including operating systems [48, 83], combinatorial optimization problems <ref> [80] </ref>, adaptive mesh partitioning [68, 118], and fine-grain functional programming [59]. In certain problems arising in these applications, it is possible to divide the overall computation into phases, where the distributed system alternates between static load balancing and executing a portion of the workload.
Reference: [81] <author> C. E. Leiserson and B. M. Maggs. </author> <title> Communication-efficient parallel graph algorithms for distributed random-access machines. </title> <journal> Algorithmica, </journal> <volume> 3 </volume> <pages> 53-77, </pages> <year> 1988. </year>
Reference-contexts: For a recent study on the implications of local and global bandwidth restrictions, see [3]. (We remark that our usage of the terms "local bandwidth" and "global bandwidth" is borrowed from [3].) The DRAM model <ref> [81] </ref> considers bandwidth restrictions in a more general form by explicitly accounting for congestion across every cut of the underlying network.
Reference: [82] <author> V. Leppanen. </author> <title> Studies on the Realization of PRAM. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, University of Turku, </institution> <month> November </month> <year> 1996. </year>
Reference-contexts: Ranade devised a novel routing algorithm for the butterfly which leads to a CRCW PRAM simulation protocol with O (log n) delay [105]. Simulations of different PRAM models have been obtained on the mesh-connected computer [100] and its variants <ref> [82] </ref>. From the point of view of contention resolution, our work is related to the vast body of research on routing protocols for multiple-access channels (MACs) and optical computers.
Reference: [83] <author> F. C. H. Lin and R. M. Keller. </author> <title> The gradient model load balancing method. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 13 </volume> <pages> 32-38, </pages> <year> 1986. </year>
Reference-contexts: Our results for static load balancing also apply to certain problems where the load is dynamic, that is, the total load varies with time 1 . Dynamic load balancing is required in a wide variety of applications, including operating systems <ref> [48, 83] </ref>, combinatorial optimization problems [80], adaptive mesh partitioning [68, 118], and fine-grain functional programming [59]. In certain problems arising in these applications, it is possible to divide the overall computation into phases, where the distributed system alternates between static load balancing and executing a portion of the workload. <p> any algorithm will 116 take at least d=ffe steps to balance the network to within one token. 4.1.3 Related Work Load balancing has been studied extensively because it arises in a wide variety of settings including adaptive mesh partitioning [68, 118], fine-grain functional programming [59], job scheduling in operating systems <ref> [48, 83] </ref>, and distributed tree searching [76, 86]. A number of models have been proposed for studying load balancing problems.
Reference: [84] <author> J.-H. Lin and J. S. Vitter. </author> <title> *-approximations with minimum packing constraint violation. </title> <booktitle> In Proceedings of the 24th Annual ACM Symposium on the Theory of Computing, </booktitle> <pages> pages 771-782, </pages> <month> May </month> <year> 1997. </year>
Reference-contexts: This leads us to a well-studied problem in combinatorial optimization, the facility location problem (e.g., see [40]). While the facility location problem is NP-complete, constant-factor approximation algorithms for important special cases have been obtained recently <ref> [84, 106] </ref>.
Reference: [85] <author> M. Livny and M. Melman. </author> <title> Load balancing in homogeneous broadcast distributed systems. </title> <journal> ACM Performance Evaluation Review, </journal> <volume> 11(1) </volume> <pages> 47-55, </pages> <year> 1982. </year>
Reference-contexts: In order to make the study of dynamic load balancing somewhat tractable, most of the previous work has assumed either a particular statistical model of load variation or a specific network topology (for example, see <ref> [85, 111] </ref>). We adopt a different approach by proposing a model that allows an adversary to control the on-line job arrival process. Our results in this area are limited in scope. <p> Since an arbitrary on-line process is difficult to analyze, previous work in this area has typically made certain probabilistic assumptions about the token arrival process (for example, see <ref> [85, 111] </ref>). We depart from this approach and instead study a simplified scenario of load balancing under a model that does not rely on any probabilistic assumptions about the process of token generation and destruction.
Reference: [86] <author> R. Luling and B. Monien. </author> <title> Load balancing for distributed branch and bound algorithms. </title> <booktitle> In Proceedings of the 6th International Parallel Processing Symposium, </booktitle> <pages> pages 543-549, </pages> <month> March </month> <year> 1992. </year>
Reference-contexts: least d=ffe steps to balance the network to within one token. 4.1.3 Related Work Load balancing has been studied extensively because it arises in a wide variety of settings including adaptive mesh partitioning [68, 118], fine-grain functional programming [59], job scheduling in operating systems [48, 83], and distributed tree searching <ref> [76, 86] </ref>. A number of models have been proposed for studying load balancing problems.
Reference: [87] <author> N. Lynch and M. Fisher. </author> <title> On describing the behavior and implementation of distributed systems. </title> <journal> Theoretical Computer Science, </journal> <volume> 13 </volume> <pages> 17-43, </pages> <year> 1981. </year> <month> 207 </month>
Reference-contexts: An analogous model for message-passing systems was studied in [16]. Moreover, our model is equivalent to that proposed in <ref> [87] </ref>, where the time complexity of an algorithm is defined to be the longest amount of elapsed real time from the start to the completion of the algorithm, assuming that the time delay between two steps of the same network component is at most unity [13]. (The model proposed in [87] <p> <ref> [87] </ref>, where the time complexity of an algorithm is defined to be the longest amount of elapsed real time from the start to the completion of the algorithm, assuming that the time delay between two steps of the same network component is at most unity [13]. (The model proposed in [87] has been subsequently used in the study of several distributed computing problems [18, 20].) We generalize our result for the synchronous model to the asynchronous model at the expense of a factor of 2 in the time complexity.
Reference: [88] <author> P. D. MacKenzie, C. G. Plaxton, and R. Rajaraman. </author> <title> On contention resolution pro-tocols and associated probabilistic phenomena. </title> <booktitle> In Proceedings of the 26th Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 153-162, </pages> <month> May </month> <year> 1994. </year>
Reference-contexts: The results 5 in this chapter are joint work with Phil Mackenzie and Greg Plaxton, and have appeared in <ref> [88] </ref>. A natural emulation scheme is to map each location of the EREW PRAM shared memory (and hence, each shared object) to the memory module of a randomly chosen node of the crossbar. <p> This idea is central to many MAC protocols, including the Ethernet protocol [92] and the slotted ALOHA 20 protocol [1], and routing protocols for the optical computer [10, 116, 51]. (For more work in this direction, see [64, 65].) Lower bounds for routing in optical computers appear in <ref> [62, 88] </ref>. 2.2 The 1 out of ` Protocol Consider the 1 out of ` problem where ` 1. Let the ` hash functions be labeled h i , 0 i &lt; `, and the shared memory request of node j be for cell x j .
Reference: [89] <editor> B. M. Maggs, F. Meyer auf der Heide, B. Vocking, and M. </editor> <title> Westermann. Exploiting locality for data management in systems if limited bandwidth. </title> <booktitle> In Proceedings of the 38th Annual IEEE Symposium on Foundations of Computer Science, </booktitle> <month> October </month> <year> 1997. </year> <note> To appear. </note>
Reference-contexts: All of the current solutions devised for this problem, however, assume centralized control; it would be interesting to obtain solutions that can be adapted to a dynamic and distributed environment. (For recent related work in this area on specific network topologies, see <ref> [89] </ref>.) * Locating nearby copies of objects: In a nonuniform network, changes in the pattern of accesses across the network may cause changes in the locations of object copies. Hence, there is a need for a mechanism to dynamically locate nearby copies of objects.
Reference: [90] <author> Y. Mansour, N. Nisan, and U. Vishkin. </author> <title> Trade-offs between communication throughput and parallel time. </title> <booktitle> In Proceedings of the 26th Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 372-381, </pages> <month> May </month> <year> 1994. </year>
Reference-contexts: These models may not be appropriate for networks where the bandwidth of the network as a whole is the limiting factor. For such networks, we need to place global restrictions on the bandwidth, as is done in the PRAM (m) <ref> [90] </ref> and the QSM (m) [58] models.
Reference: [91] <author> K. Mehlhorn and U. Vishkin. </author> <title> Randomized and deterministic simulations of PRAMs by parallel machines with restricted granularity of parallel memories. </title> <journal> Acta Informatica, </journal> <volume> 21 </volume> <pages> 339-374, </pages> <year> 1984. </year>
Reference-contexts: Mehlhorn and Vishkin <ref> [91] </ref> proposed distributing the shared objects using universal hashing. Upfal and Wigderson [113] were the first to use replication in the context of shared memory simulations. They presented a deterministic protocol with delay O (log n (log log n) 2 ).
Reference: [92] <author> R. Metcalfe and D. Boggs. </author> <title> Ethernet: Distributed packet switching for local computer networks. </title> <journal> Communications of the ACM, </journal> <volume> 19(7) </volume> <pages> 395-404, </pages> <year> 1976. </year>
Reference-contexts: If two or more clients attempt to use the channel simultaneously, then there is a collision, and no client succeeds. The standard Ethernet local area network <ref> [92] </ref> and the classic ALOHA packet radio network [1] are two well-known examples of multiple access channels. (See [29, Chapter 4] for more examples.) An optical computer, which can be viewed as a collection of multiple access channels, is accurately modeled by a 1-collision crossbar. <p> In the absence of replication, a natural approach to resolve contention for MACs is to use randomization to break the symmetry among the clients. This idea is central to many MAC protocols, including the Ethernet protocol <ref> [92] </ref> and the slotted ALOHA 20 protocol [1], and routing protocols for the optical computer [10, 116, 51]. (For more work in this direction, see [64, 65].) Lower bounds for routing in optical computers appear in [62, 88]. 2.2 The 1 out of ` Protocol Consider the 1 out of `
Reference: [93] <editor> F. Meyer auf der Heide, B. Oesterdiekhoff, and R. </editor> <title> Wanka. Strongly adaptive token distribution. </title> <journal> Algorithmica, </journal> <volume> 15 </volume> <pages> 413-427, </pages> <year> 1996. </year>
Reference-contexts: A number of models have been proposed for studying load balancing problems. These models can be classified on the basis of three characteristics: (i) centralized control (e.g., <ref> [93, 111] </ref>) versus distributed control (e.g., [30, Chapter 7] [42]), (ii) shared memory communication such as the PRAM model (e.g., [27]), uniform communication (e.g., [111]), or fixed-connection network communication (e.g., [5, 42]), and (iii) unbounded edge capacity (e.g., [30, Chapter 7] [109]) versus bounded edge capacity (e.g., [5, 101]) (the capacity <p> Local algorithms restricted to particular networks have been studied on counting networks [15, 78], hypercubes [72, 101], and meshes <ref> [68, 93] </ref>. Another class of networks on which load balancing has been studied is the class of expanders. Peleg and Upfal [97] pioneered this study by identifying certain small-degree expanders as being suitable for load balancing. Their work was extended in [34, 69, 98]. <p> Therefore, m (X [ A (X)) jA (X)j. 141 Theorem 1 of <ref> [93] </ref> obtains tight bounds on the centralized complexity of load balancing in terms of the function m. We restate the theorem using our notation and terminology. Before stating the theorem, we need one additional notation. <p> Since the number of steps is an integer, the desired claim follows. By using the techniques of <ref> [93] </ref>, we can modify the proof of Lemma 4.10 to show that any network G with node expansion and initial imbalance can be globally balanced to within 3 tokens in at most 2d (1 + )=e steps. <p> The proofs of Theorem 1 of <ref> [93] </ref> and Lemma 4.10 can be modified to establish the following result for the multi-port model. Lemma 4.11: Assume the multi-port model. <p> For all X V , we have (i) jI (X) jXjj minfjXj; jXjg (see proof of Lemma 4.10), and (ii) jM (X; X)j ff minfjXj; jXjg. It follows from (i) and (ii) that T d=ffe. We modify the proofs of Theorem 1 and Lemma 4 of <ref> [93] </ref> (where the single-port model was assumed) to establish the desired claims for the multi-port model. We transform the load balancing problem on G to a network flow problem on a directed graph H = (V 0 ; E 0 ) which is constructed as follows.
Reference: [94] <editor> F. Meyer auf der Heide, C. Scheideler, and V. Stemann. </editor> <title> Exploiting storage redundancy to speed up randomized shared memory simulations. </title> <booktitle> In Proceedings of the 12th Annual Symposium on Theoretical Aspects of Computer Science, Lecture Notes in Computer Science, </booktitle> <volume> volume 900, </volume> <pages> pages 267-278. </pages> <publisher> Springer-Verlag, </publisher> <month> March </month> <year> 1995. </year>
Reference-contexts: Therefore, while the revised protocol experiences only a quadratic slowdown in running time, the generic protocol will suffer an exponential increase in running time with increasing a. (We remark here that our notion of the generic protocol does not include the protocol studied in <ref> [94] </ref> that is shown to have a running time that is polynomial in a when a, b, and c are suitably chosen.) The basic idea outlined above can be used to solve any a out of b problem by choosing any a + 1 hash functions and solving the corresponding a
Reference: [95] <author> M. Mihail. </author> <title> Conductance and convergence of Markov chains A combinatorial treatment of expanders. </title> <booktitle> In Proceedings of the 30th Annual IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pages 526-531, </pages> <month> October </month> <year> 1989. </year> <month> 208 </month>
Reference-contexts: Indeed the convergence bounds in both cases depend on the expansion properties of the underlying network and they are established using potential function arguments. There are however two important differences. First, the analysis of the rapid convergence of random walks <ref> [73, 95] </ref> relies on averaging arbitrary probabilities across any edge. This corresponds to sending an arbitrary (possibly nonintegral) load along an edge, which is forbidden in our model. In this sense, the analysis in [42] (and all references in the unbounded capacity model) are similar to the random walk analysis. <p> In this sense, the analysis in [42] (and all references in the unbounded capacity model) are similar to the random walk analysis. Second, our argument uses an exponential potential function. The analyses in <ref> [42, 73, 95] </ref>, in contrast, use quadratic potential functions.
Reference: [96] <author> S. J. Mullender and P. M. B. Vitanyi. </author> <title> Distributed match-making. </title> <journal> Algorithmica, </journal> <volume> 3 </volume> <pages> 367-391, </pages> <year> 1988. </year>
Reference-contexts: Hence, there is a need for a mechanism to dynamically locate nearby copies of objects. While this problem has been well-studied (see <ref> [96] </ref> for early work, and [19, 26, 103] for recent results), existing solutions either hold for restricted cost models only or suffer from large overhead in storage requirements. (By overhead in storage, we refer to the memory required to store information about the locations of the objects.) Since the above problem
Reference: [97] <author> D. Peleg and E. Upfal. </author> <title> The generalized packet routing problem. </title> <journal> Theoretical Computer Science, </journal> <volume> 53 </volume> <pages> 281-293, </pages> <year> 1987. </year>
Reference-contexts: In these problems, routing is performed by first redistributing the packets among the processors in a balanced manner, and then invoking standard routing techniques such as permutation routing or k-k-routing <ref> [97] </ref>. Our results for static load balancing also apply to certain problems where the load is dynamic, that is, the total load varies with time 1 . <p> Local algorithms restricted to particular networks have been studied on counting networks [15, 78], hypercubes [72, 101], and meshes [68, 93]. Another class of networks on which load balancing has been studied is the class of expanders. Peleg and Upfal <ref> [97] </ref> pioneered this study by identifying certain small-degree expanders as being suitable for load balancing. Their work was extended in [34, 69, 98]. These algorithms either use strong expanders to approximately balance the network, or the AKS sorting network [6] to perfectly balance the network.
Reference: [98] <author> D. Peleg and E. Upfal. </author> <title> The token distribution problem. </title> <journal> SIAM Journal on Computing, </journal> <volume> 18 </volume> <pages> 229-243, </pages> <year> 1989. </year>
Reference-contexts: Another class of networks on which load balancing has been studied is the class of expanders. Peleg and Upfal [97] pioneered this study by identifying certain small-degree expanders as being suitable for load balancing. Their work was extended in <ref> [34, 69, 98] </ref>. These algorithms either use strong expanders to approximately balance the network, or the AKS sorting network [6] to perfectly balance the network. Thus, they do not work on networks of arbitrary topology.
Reference: [99] <author> L. L. Peterson and B. S. Davie. </author> <title> Computer Networks: A Systems Approach. Chapter 9. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Francisco, California, </address> <year> 1996. </year>
Reference-contexts: This feature is motivated by the observation that with rapidly growing speeds and capacities of communication links, the network-node interface is increasingly limiting the performance of the network [41] <ref> [99, Chapter 9] </ref>. Restrictions on local bandwidth play a significant role in the BSP [115], LogP [41], and QSM (g) [58] models as well. The gap parameter of these models places an upper bound on the rate at which a single node may send or receive messages.
Reference: [100] <author> A. Pietracaprina, G. Pucci, and J. F. Sibeyn. </author> <title> Constructive deterministic PRAM simulation on a mesh-connected computer. </title> <booktitle> In Proceedings of the 6th Annual ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 248-256, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: Non-constructive simulations on networks of bounded degree were presented in [9]. Ranade devised a novel routing algorithm for the butterfly which leads to a CRCW PRAM simulation protocol with O (log n) delay [105]. Simulations of different PRAM models have been obtained on the mesh-connected computer <ref> [100] </ref> and its variants [82]. From the point of view of contention resolution, our work is related to the vast body of research on routing protocols for multiple-access channels (MACs) and optical computers.
Reference: [101] <author> C. G. Plaxton. </author> <title> Load balancing, selection, and sorting on the hypercube. </title> <booktitle> In Proceedings of the 1st Annual ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 64-73, </pages> <month> June </month> <year> 1989. </year>
Reference-contexts: centralized control (e.g., [93, 111]) versus distributed control (e.g., [30, Chapter 7] [42]), (ii) shared memory communication such as the PRAM model (e.g., [27]), uniform communication (e.g., [111]), or fixed-connection network communication (e.g., [5, 42]), and (iii) unbounded edge capacity (e.g., [30, Chapter 7] [109]) versus bounded edge capacity (e.g., <ref> [5, 101] </ref>) (the capacity of an edge is the maximum number of tokens it can transmit per step). <p> Local algorithms restricted to particular networks have been studied on counting networks [15, 78], hypercubes <ref> [72, 101] </ref>, and meshes [68, 93]. Another class of networks on which load balancing has been studied is the class of expanders. Peleg and Upfal [97] pioneered this study by identifying certain small-degree expanders as being suitable for load balancing. Their work was extended in [34, 69, 98]. <p> The local algorithm balances in ( log n) time, while there exists an O ( p log n + log 2 n) time load balancing algorithm for the hypercube <ref> [101] </ref> which is optimal for sufficiently large.
Reference: [102] <author> C. G. Plaxton and R. Rajaraman. </author> <title> Fast fault-tolerant concurrent access to shared objects. </title> <booktitle> In Proceedings of the 37th Annual IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pages 570-579, </pages> <month> October </month> <year> 1996. </year>
Reference-contexts: The results in Chapter 3 are joint work with Greg Plaxton and have appeared in <ref> [102] </ref>. 1.2 Sharing Processors A natural approach towards harnessing the aggregate processing power of a distributed system is to balance the workload among the nodes of the system.
Reference: [103] <author> C. G. Plaxton, R. Rajaraman, and A. W. Richa. </author> <title> Accessing nearby copies of replicated objects in a distributed environment. </title> <booktitle> In Proceedings of the 9th Annual ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 311-320, </pages> <month> June </month> <year> 1997. </year>
Reference-contexts: In future work, we would like to extend our results to models that take into account the differing costs in communication among different nodes. (See <ref> [19, 74, 103] </ref> for recent work in this area.) The parameter c. An important feature of the c-arbitrary crossbar is the parameter c which signifies the bandwidth limitation at each of the nodes of the network. <p> Recent work on locality issues includes algorithms for allocating files on arbitrary networks [19, 26], protocols for accessing nearby objects on restricted classes of networks <ref> [74, 103, 117] </ref>, and caching schemes for the Internet [67]. The most important technical problem left open in this chapter is to extend our analysis to more general models of access patterns. <p> Hence, there is a need for a mechanism to dynamically locate nearby copies of objects. While this problem has been well-studied (see [96] for early work, and <ref> [19, 26, 103] </ref> for recent results), existing solutions either hold for restricted cost models only or suffer from large overhead in storage requirements. (By overhead in storage, we refer to the memory required to store information about the locations of the objects.) Since the above problem has direct applications to the
Reference: [104] <author> M. O. Rabin. </author> <title> Efficient dispersal of information for security, load balancing and fault tolerance. </title> <journal> Journal of the ACM, </journal> <volume> 36 </volume> <pages> 335-348, </pages> <year> 1989. </year>
Reference-contexts: Unfortunately, this results in an (log n)-fold increase in the space needed to store each object. The theory of erasure codes, however, provides a convenient method for achieving fault-tolerance while paying only a constant factor space penalty. For example, using Rabin's Information Dispersal Algorithm <ref> [104] </ref> (IDA), for any k &gt; m, a given b-bit string can be encoded as a set of k (b=m)-bit strings of length m, with the property that any m of the (b=m)-bit strings suffice to reconstruct the original b-bit string. <p> We choose to replicate whole copies of objects, as opposed to fragments, so that the encode-decode overhead associated with IDA can be avoided on retrieval of popular objects. This may be viewed as a minor optimization since the overhead of IDA is actually quite small <ref> [104] </ref>. 68 In our protocol, a client process attempting to read a particular object A sends fi (log n) messages, one to each of the fi (log n) servers in block 0 of A, and O (1) messages to a randomly chosen set of servers in each of the fi (log <p> the function h A is chosen such that for any i in [b], block B i (A) is mapped to a subset of jB i (A)j nodes chosen independently and uniformly at random. (Note that several servers associated with different objects may be mapped to the same node.) Using IDA <ref> [104] </ref>, we encode A as a set of b 0 fragments such that any b 0 =4 fragments suffice to decode A. For each i in [b 0 ], h A (S i (A)) stores the ith fragment of A.
Reference: [105] <author> A. G. Ranade. </author> <title> How to emulate shared memory. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 42 </volume> <pages> 307-326, </pages> <year> 1991. </year> <month> 209 </month>
Reference-contexts: Several researchers have studied simulations of shared memory on other topologies. Non-constructive simulations on networks of bounded degree were presented in [9]. Ranade devised a novel routing algorithm for the butterfly which leads to a CRCW PRAM simulation protocol with O (log n) delay <ref> [105] </ref>. Simulations of different PRAM models have been obtained on the mesh-connected computer [100] and its variants [82]. From the point of view of contention resolution, our work is related to the vast body of research on routing protocols for multiple-access channels (MACs) and optical computers. <p> A variety of other well-known methods have been used for solving this problem, including broadcast, combining <ref> [105] </ref>, and multicast [45]. However, the class of architectures that support the efficient implementation of these methods is restricted. For example, a single-bus network can efficiently support broadcast, which enables an arbitrary subset of the processors to obtain copies of a single object at the same time.
Reference: [106] <author> D. Shmoys, E. Tardos, and K. Aardal. </author> <title> Approximation algorithms for facility location problems. </title> <booktitle> In Proceedings of the 29th Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 265-274, </pages> <month> May </month> <year> 1997. </year>
Reference-contexts: This leads us to a well-studied problem in combinatorial optimization, the facility location problem (e.g., see [40]). While the facility location problem is NP-complete, constant-factor approximation algorithms for important special cases have been obtained recently <ref> [84, 106] </ref>.
Reference: [107] <author> A. Siegel. </author> <title> On universal classes of fast high performance hash functions, their time-space tradeoff, and their applications. </title> <booktitle> In Proceedings of the 30th IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pages 20-25, </pages> <month> November </month> <year> 1989. </year> <note> Revised version. </note>
Reference-contexts: uniformly at random from F k m;n , then Pr [h (x i ) = y i for all i in [j]] = 1=n j : p m;n can be constructed as in [75] using the families H n d ;n and H 1 m;n d defined in [35] and <ref> [107] </ref> respectively. (Here d is an appropriate constant.) A hash function h chosen uniformly at random from F k m;n is defined as r ffi s, where r and s are chosen uniformly at random from H n d ;n and H 1 m;n d respectively. <p> Both r and s can be evaluated in constant time <ref> [107, 35] </ref>, and hence the same is true of h. In order to analyze the 1 out of ` protocol, we restrict our attention to the atmost n memory requests of the processors.
Reference: [108] <author> V. Stemann. </author> <title> Parallel balanced allocations. </title> <booktitle> In Proceedings of the 8th Annual ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 261-269, </pages> <month> June </month> <year> 1996. </year>
Reference-contexts: Our main technical contribution in this chapter is the derivation of sharp threshold phenomena associated with certain random allocation experiments. Several recent papers have studied similar processes that arise in dynamic resource allocation and parallel load balancing <ref> [2, 25, 108] </ref>. 60 Chapter 3 Fast Fault-Tolerant Concurrent Access to Shared Ob jects 3.1 Introduction In this chapter, we design and analyze a simple local protocol for providing fast concurrent access to shared objects in a faulty distributed network.
Reference: [109] <author> R. Subramanian and I. D. Scherson. </author> <title> An analysis of diffusive load balancing. </title> <booktitle> In Proceedings of the 6th Annual ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 220-225, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: the basis of three characteristics: (i) centralized control (e.g., [93, 111]) versus distributed control (e.g., [30, Chapter 7] [42]), (ii) shared memory communication such as the PRAM model (e.g., [27]), uniform communication (e.g., [111]), or fixed-connection network communication (e.g., [5, 42]), and (iii) unbounded edge capacity (e.g., [30, Chapter 7] <ref> [109] </ref>) versus bounded edge capacity (e.g., [5, 101]) (the capacity of an edge is the maximum number of tokens it can transmit per step).
Reference: [110] <author> M. Sudan. </author> <title> Efficient Checking of Polynomials and Proofs and the Hardness of Approximation Problems. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, University of California at Berkeley, </institution> <month> October </month> <year> 1992. </year>
Reference-contexts: Unless the noisy fragments can be easily identified as such, the client cannot efficiently reconstruct the object using IDA. In such a noisy setting, it would be worthwhile to consider variants of our protocol based on the Berlekamp-Welch decoder [28] (see also <ref> [110, Appendix A] </ref>), which tolerates noise in a constant fraction of the fragments. We would like to extend our protocols to other interesting models of distributed computation that incorporate asynchrony or locality information.
Reference: [111] <author> A. N. Tantawi and D. Towsley. </author> <title> Optimal static load balancing in distributed computer systems. </title> <journal> Journal of the ACM, </journal> <volume> 32 </volume> <pages> 445-465, </pages> <year> 1985. </year>
Reference-contexts: In order to make the study of dynamic load balancing somewhat tractable, most of the previous work has assumed either a particular statistical model of load variation or a specific network topology (for example, see <ref> [85, 111] </ref>). We adopt a different approach by proposing a model that allows an adversary to control the on-line job arrival process. Our results in this area are limited in scope. <p> Our results in this area are limited in scope. It is possible 1 While we have used the term "static" or "dynamic" as a property of the load, some papers in the load balancing literature use the term as a property of the algorithm. These papers (for example, see <ref> [111] </ref>) define a static load balancing algorithm (resp., dynamic load balancing algorithm) to be an algorithm in which the decision of transferring load does not depend (resp., may depend) on the current system state. 9 that suitable enhancements of our model will be useful in the study of more realistic problems. <p> A number of models have been proposed for studying load balancing problems. These models can be classified on the basis of three characteristics: (i) centralized control (e.g., <ref> [93, 111] </ref>) versus distributed control (e.g., [30, Chapter 7] [42]), (ii) shared memory communication such as the PRAM model (e.g., [27]), uniform communication (e.g., [111]), or fixed-connection network communication (e.g., [5, 42]), and (iii) unbounded edge capacity (e.g., [30, Chapter 7] [109]) versus bounded edge capacity (e.g., [5, 101]) (the capacity <p> These models can be classified on the basis of three characteristics: (i) centralized control (e.g., [93, 111]) versus distributed control (e.g., [30, Chapter 7] [42]), (ii) shared memory communication such as the PRAM model (e.g., [27]), uniform communication (e.g., <ref> [111] </ref>), or fixed-connection network communication (e.g., [5, 42]), and (iii) unbounded edge capacity (e.g., [30, Chapter 7] [109]) versus bounded edge capacity (e.g., [5, 101]) (the capacity of an edge is the maximum number of tokens it can transmit per step). <p> Since an arbitrary on-line process is difficult to analyze, previous work in this area has typically made certain probabilistic assumptions about the token arrival process (for example, see <ref> [85, 111] </ref>). We depart from this approach and instead study a simplified scenario of load balancing under a model that does not rely on any probabilistic assumptions about the process of token generation and destruction.
Reference: [112] <author> R. M. Thomas. </author> <title> A majority consensus approach to concurrency control for multiple copy databases. </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 4 </volume> <pages> 180-209, </pages> <year> 1979. </year>
Reference-contexts: One of their main observations, which has been used in several subsequent replication-based simulations, including ours, was that it is sufficient to access a majority of the copies. (The "majority trick" had been proposed earlier for concurrency control in replicated databases <ref> [112] </ref>.) Following the work of Upfal and Wigderson, several EREW PRAM emulations on the crossbar have been proposed. A deterministic simulation with delay O (log n) was presented in [9]; however, their result is non-constructive.
Reference: [113] <author> E. Upfal and A. Wigderson. </author> <title> How to share memory in a distributed system. </title> <journal> Journal of the ACM, </journal> <volume> 34 </volume> <pages> 116-127, </pages> <year> 1987. </year>
Reference-contexts: Mehlhorn and Vishkin [91] proposed distributing the shared objects using universal hashing. Upfal and Wigderson <ref> [113] </ref> were the first to use replication in the context of shared memory simulations. They presented a deterministic protocol with delay O (log n (log log n) 2 ).
Reference: [114] <author> L. Valiant. </author> <title> A combining mechanism for parallel computers. </title> <type> Technical Report TR-24-92, </type> <institution> Center for Research in Computing Technology, Harvard University, </institution> <month> January </month> <year> 1992. </year>
Reference-contexts: On the other hand, the cost of implementing broadcast in a distributed network with point-to-point connections is significant. Our hashing techniques are loosely related to Valiant's hashing-based combining mechanism for simulating CRCW PRAM algorithms on parallel computers <ref> [114] </ref>. In other related work, Gibbons, Matias, and Ramachandran [55] adopt a different approach to account for contention in parallel algorithms. <p> They introduce the QRQW PRAM 64 model, which permits concurrent reading and writing but at a cost proportional to the number of readers/writers to a memory location in a given step. The focus of our algorithm design and analysis is different. While [55] and <ref> [114] </ref> are primarily concerned with the problem of PRAM emulation, we have optimized our protocol to obtain fast performance (e.g., expected O (1) time) on a more restricted class of access patterns.
Reference: [115] <author> L. G. Valiant. </author> <title> A bridging model for parallel computation. </title> <journal> Communications of the ACM, </journal> <volume> 33(8) </volume> <pages> 103-111, </pages> <year> 1990. </year> <month> 210 </month>
Reference-contexts: This feature is motivated by the observation that with rapidly growing speeds and capacities of communication links, the network-node interface is increasingly limiting the performance of the network [41] [99, Chapter 9]. Restrictions on local bandwidth play a significant role in the BSP <ref> [115] </ref>, LogP [41], and QSM (g) [58] models as well. The gap parameter of these models places an upper bound on the rate at which a single node may send or receive messages. However, BSP and LogP differ from the c-arbitrary crossbar on one significant point.
Reference: [116] <author> L. G. Valiant. </author> <title> General purpose parallel architectures. </title> <editor> In J. van Leeuwen, editor, </editor> <booktitle> Handbook of Theoretical Computer Science, Volume A: Algorithms and Complexity, </booktitle> <pages> pages 943-971. </pages> <publisher> Elsevier/MIT Press, </publisher> <year> 1990. </year>
Reference-contexts: It is easy to see that given any emulation protocol for the c-collision crossbar, we can construct an equally efficient emulation protocol for the c-arbitrary crossbar. The c-arbitrary and c-collision crossbars generalize some models that have been studied previously. The module parallel computer (MPC [9]) and the S*PRAM <ref> [116] </ref> correspond to the 1-arbitrary crossbar model. The local memory PRAM model of An-derson and Miller [10], later studied under the name OCPC (optical communication parallel computer) in [51, 60, 61], corresponds to the 1-collision crossbar model. <p> This idea is central to many MAC protocols, including the Ethernet protocol [92] and the slotted ALOHA 20 protocol [1], and routing protocols for the optical computer <ref> [10, 116, 51] </ref>. (For more work in this direction, see [64, 65].) Lower bounds for routing in optical computers appear in [62, 88]. 2.2 The 1 out of ` Protocol Consider the 1 out of ` problem where ` 1.
Reference: [117] <author> M. Van Steen, F. J. Hauck, and A. S. Tanenbaum. </author> <title> A model for worldwide tracking of distributed objects. </title> <booktitle> In Proceedings of TINA'96, </booktitle> <pages> pages 203-212, </pages> <month> September </month> <year> 1996. </year>
Reference-contexts: Recent work on locality issues includes algorithms for allocating files on arbitrary networks [19, 26], protocols for accessing nearby objects on restricted classes of networks <ref> [74, 103, 117] </ref>, and caching schemes for the Internet [67]. The most important technical problem left open in this chapter is to extend our analysis to more general models of access patterns. <p> 103] for recent results), existing solutions either hold for restricted cost models only or suffer from large overhead in storage requirements. (By overhead in storage, we refer to the memory required to store information about the locations of the objects.) Since the above problem has direct applications to the Internet <ref> [66, 117] </ref>, an efficient solution would be of great interest. 177 Sharing Processors In the second part of the dissertation, we analyzed the effectiveness of a local balancing strategy in which each node repeatedly balances its load with its neighbors.
Reference: [118] <author> R. D. Williams. </author> <title> Performance of dynamic load balancing algorithms for unstructured mesh calculations. </title> <journal> Concurrency: Practice and Experience, </journal> <volume> 3 </volume> <pages> 457-481, </pages> <year> 1991. </year>
Reference-contexts: Parallel computations such as large-scale partial differential equations, finite element methods, branch-and-bound computations, and ray tracing, can be divided into a large number of small computational tasks and distributed among the processors at the start of the overall computation (see <ref> [77, 118] </ref> for some examples). Another important application of static load balancing arises in certain packet routing problems, where the initial distribution of packets may be irregular. <p> Our results for static load balancing also apply to certain problems where the load is dynamic, that is, the total load varies with time 1 . Dynamic load balancing is required in a wide variety of applications, including operating systems [48, 83], combinatorial optimization problems [80], adaptive mesh partitioning <ref> [68, 118] </ref>, and fine-grain functional programming [59]. In certain problems arising in these applications, it is possible to divide the overall computation into phases, where the distributed system alternates between static load balancing and executing a portion of the workload. <p> 2d=ffe steps, while there exists an initial token distribution such that any algorithm will 116 take at least d=ffe steps to balance the network to within one token. 4.1.3 Related Work Load balancing has been studied extensively because it arises in a wide variety of settings including adaptive mesh partitioning <ref> [68, 118] </ref>, fine-grain functional programming [59], job scheduling in operating systems [48, 83], and distributed tree searching [76, 86]. A number of models have been proposed for studying load balancing problems.
Reference: [119] <author> C.-Z. Xu and F. C. M. Lau. </author> <title> Iterative dynamic load balancing in multicomputers. </title> <journal> Journal of the Operational Research Society, </journal> <volume> 45 </volume> <pages> 786-796, </pages> <year> 1994. </year> <month> 211 </month>
Reference-contexts: Figure 4.2 illustrates one step of the single-port algorithm on the example given in Figure 4.1. This algorithm was first analyzed in [54]. (The single-port algorithm is sometimes referred to as the dimension-exchange method in the load balancing literature <ref> [119] </ref>.) The multi-port algorithm is 113 The bold edges are the edges that are chosen in the random matching. simpler and deterministic. <p> Figure 4.3 illustrates one step of the multi-port algorithm on the example given in Figure 4.1. This algorithm was first analyzed in [5]. (The multi-port algorithm is sometimes referred to as the diffusion method in the load balancing literature <ref> [119] </ref>.) We characterize the performance of a load balancing algorithm by the time that it takes to balance the tokens, and by the final imbalance that it achieves.
References-found: 119

