URL: http://www.cs.berkeley.edu/~padmanab/papers/masters-tr.ps.gz
Refering-URL: http://www.cs.berkeley.edu/~padmanab/
Root-URL: 
Email: padmanab@CS.Berkeley.EDU  
Title: Improving World Wide Web Latency  
Author: Venkata N. Padmanabhan 
Date: May, 1995  
Affiliation: Computer Science Division University of California at Berkeley  
Pubnum: Report No. UCB/CSD-95-875  
Abstract: The HTTP protocol, as currently used in the World Wide Web, uses a separate TCP connection for each file requested. This adds significant and unnecessary overhead, especially in the number of network round trips required. We analyse the costs of this approach and propose simple modifications to HTTP that, while interoperating with unmodified implementations, avoid the unnecessary network costs. We have implemented our modifications, and our measurements show that they dramatically reduce latencies. We have also investigated the effectiveness of a scheme to mask network latency by prefetching files likely to be requested next, while the user is browsing through the currently displayed page. Our results indicate a significant benefit from prefetching at the cost of an increase in network traffic.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Tim Berners-Lee. </author> <title> "Hypertext Transfer Protocol (HTTP)", Internet Draft draft-ietf-iiir-http-00.txt, </title> <type> IETF, </type> <month> November, </month> <year> 1993. </year> <note> This is a working draft. </note>
Reference-contexts: When the network path is congested, queuing delays can increase the RTT by large factors. This means that, in order to avoid network latency, we must avoid the cost of round trips through the network. Unfortunately, the Hypertext Transport Protocol (HTTP) <ref> [1] </ref>, as it is currently used in the Web, incurs many more round trips than necessary. <p> Requests and responses are expressed in a simple ASCII format. The precise specification of HTTP is in a state of flux. Most existing implementations conform to <ref> [1] </ref>. A revision of the specification is in progress.
Reference: [2] <author> N.Borenstein, N.Freed. </author> <title> "MIME (Multipurpose Internet Mail Extensions) Part One: Mechanisms for Specifying and Describing the Format of Internet Message Bodies", </title> <type> RFC 1521, </type> <institution> Internet Engineering Task Force, </institution> <month> September, </month> <year> 1993. </year>
Reference-contexts: If the "Content-Length" field is present, it indicates the size of the Data field and hence the end of the message. 2. The "Content-Type" field may specify a "boundary" delimiter, following the syntax for MIME multipart messages <ref> [2] </ref>. 3. The server (but not the client) may indicate the end of the message simply by closing the TCP connection after the last data byte.
Reference: [3] <author> R.Braden. </author> <title> "Requirements for Internet Hosts Communication Layers", </title> <type> RFC 1122, </type> <institution> Internet Enginnering Task Force, </institution> <month> October, </month> <year> 1989. </year>
Reference-contexts: This last configuration reflects a widely-used technique meant to avoid IP fragmentation <ref> [3] </ref>; more modern practice could use the full available packet size [9]. In each configuration, we measured throughput for a large variety of connection lengths and a few popular TCP buffer (maximum window) sizes.
Reference: [4] <author> CompuServ, </author> <title> Incorporated. Graphics Interchange Format Standard, </title> <year> 1987. </year>
Reference-contexts: As we noted earlier, one sample showed a mean document size of about 13K bytes, and a median of under 2K bytes. About 45% of these retrievals were for Graphics Interchange Format <ref> [4] </ref> (GIF) files, used for both inline and out-of-line images. This sub-sample showed a slightly larger mean and a slightly smaller median; our guess is that the very large GIF files were not inline images. The proposed use of JPEG for inline images will tend to reduce these sizes.
Reference: [5] <author> Steven Glassman. </author> <title> "A Caching Relay for the World Wide Web", </title> <booktitle> Proceedings of the First International World Wide Web Conference, Geneva, </booktitle> <pages> pages 314-329, </pages> <month> May, </month> <year> 1994. </year>
Reference-contexts: A server has no way of knowing which of the inline images in a document are in the client's cache. Since the GETALL method causes the server to return all the images, this seems to defeat the purpose of the client's image cache (or of a caching relay <ref> [5] </ref>). GETALL is still useful in situations where the client knows that it has no relevant images cached (for example, if its cache contains no images from the server in question).
Reference: [6] <author> James Griffioen and Randy Appleton. </author> <title> "Reducing File System Latency using a Predictive Approach", </title> <booktitle> Proceedings of the 1994 Summer USENIX Technical Conference, </booktitle> <address> Boston MA, </address> <month> June, </month> <year> 1994. </year>
Reference-contexts: It is clear that the effectiveness of prefetching critically depends on how good the predictions we make are. We use a scheme based on that proposed by Griffioen and Appleton <ref> [6] </ref> in the context of file systems, with a few modifications. Details of the our scheme and a discussion of our results are the subject of the second half of this report. The rest of this report is organized as follows. <p> Also if multiple requests are being scheduled in any way, this request could be assigned a lower priority than the more immediate fetches. 7.2 Prediction algorithm Our prediction algorithm is based on that described by Griffioen and Appleton <ref> [6] </ref>. However, there are a few noteworthy differences. <p> So our scheme does not require any kernel modifications. Second, the scheme described in <ref> [6] </ref> does not try to maintain a distinction between accesses by different processes (the clients in the context of a file system). This could cause it to (incorrectly) think of independent accesses (by different processes) that just happen to occur close together in time, as related.
Reference: [7] <author> Van Jacobson. </author> <title> "Congestion Avoidance and Control", </title> <booktitle> Proceedings of the ACM SIGCOMM Conference, </booktitle> <address> Stanford, CA, </address> <month> August, </month> <year> 1988. </year>
Reference-contexts: The proposed use of JPEG for inline images will tend to reduce these sizes. Unfortunately, TCP does not fully utilize the available network bandwidth for the first few round-trips of a connection. This is because modern TCP implementations use a technique called slow-start <ref> [7] </ref> to avoid network congestion. The slow-start approach requires the TCP sender to open its "congestion window" gradually, doubling the number of packets each round-trip time.
Reference: [8] <institution> Raj Jain "The Art of Computer Systems Performance Analysis", John Wiley & Sons, Inc., </institution> <year> 1991. </year>
Reference-contexts: It is likely, though we are not sure, that most accesses to the Web server in question are made from hosts with similar network connectivity as Berkeley, so our model would still be a good approximation. We use a linear regression technique <ref> [8] </ref> to model the time to prefetch a file. The basic idea is to come up with a linear model that minimizes the sum of squared errors, while ignoring outliers. A scatter plot of the data points and the line obtained from the regression model is shown in figure 14.
Reference: [9] <author> Jeffrey C. Mogul and Stephen Deering. </author> <title> "Path MTU Discovery", </title> <type> RFC 1191, </type> <institution> Network Information Center, SRI International, </institution> <month> November, </month> <year> 1990. </year>
Reference-contexts: This last configuration reflects a widely-used technique meant to avoid IP fragmentation [3]; more modern practice could use the full available packet size <ref> [9] </ref>. In each configuration, we measured throughput for a large variety of connection lengths and a few popular TCP buffer (maximum window) sizes.
Reference: [10] <author> Jeffrey C. </author> <title> Mogul. </title> <booktitle> "The Case for Persistent-Connection HTTP", Proceedings of the ACM SIG-COMM Conference (to appear), </booktitle> <address> Boston, MA, </address> <month> August, </month> <year> 1995. </year>
Reference-contexts: Finally, Netscape does not avoid the paying the cost of slow start repeatedly. There is at least one other work <ref> [10] </ref> that discusses these issues, and makes a strong case for persistent HTTP connections. 22 Acknowledgements I would like to thank Dr.
Reference: [11] <author> Venkata N. Padmanabhan and Jeffrey C. Mogul. </author> <title> "Improving HTTP Latency", </title> <booktitle> Proceedings of the Second International World Wide Web Conference, </booktitle> <address> Chicago, IL, </address> <pages> pages 995-1005, </pages> <month> October, </month> <year> 1994. </year>
Reference-contexts: We then present results measured using prototype implementations, which confirm that our changes result in significantly improved response times. This material is based on our earlier paper <ref> [11] </ref>. During the course of our work, Simon Spero published an analysis of HTTP [15], which reached conclusions similar to ours. However, we know of no other project, besides our own, that has implemented the consequent modifications to HTTP, or that has quantified the results.
Reference: [12] <author> J.Postel. </author> <title> "Transmission Control Protocol", </title> <type> RFC 793, </type> <institution> Network Information Center, SRI International, </institution> <month> September, </month> <year> 1981. </year>
Reference-contexts: We omit a lot of detail not directly relevant to HTTP latency. The HTTP protocol is layered over a reliable bidirectional byte stream, normally TCP <ref> [12] </ref>. Each HTTP interaction consists of a request sent from the client to the server, followed by a response sent from the server to the client. Requests and responses are expressed in a simple ASCII format. The precise specification of HTTP is in a state of flux. <p> It would be quite expensive to re-authenticate principals on each HTTP request. * Although the TCP connections may be active for only a few seconds, the TCP specification requires that the host which closed the connection remember certain per-connection information for four minutes <ref> [12] </ref> (although many implementations do violate this specification and use a much shorter timer.) A busy server could end up with its tables full of connections in this "TIME-WAIT" state, either leaving no room for new connections, or at least imposing excessive connection table management costs.
Reference: [13] <author> J.Postel, J.Reynolds. </author> <title> "Telnet Protocol Specification", </title> <type> RFC 854, </type> <institution> Network Information Center, SRI International, </institution> <month> May, </month> <year> 1983. </year> <month> 23 </month>
Reference-contexts: on its way to the client: Boundary delimiter The server can safely insert a boundary delimiter (perhaps as simple as a single character) if it can examine the entire data stream and "escape" any instance of the delimiter that appears in the data (as is done in the Telnet protocol <ref> [13] </ref>). This requires both the server and client to examine each byte of data, which is clearly inefficient. Blocked data transmission protocol The server could read data from the script and send it to the client in arbitrary-length blocks, each preceded by a length indicator.
Reference: [14] <author> J.Postel, J.Reynolds. </author> <title> "File Transfer Protocol (FTP)", </title> <type> RFC 959, </type> <institution> Network Information Center, SRI International, </institution> <month> October, </month> <year> 1985. </year>
Reference-contexts: The advantage of this approach over ours is that it does not require any modifications to existing servers. However, there are several drawbacks. Using multiple connections would be unfair to other protocols, such as the file transfer protocol (FTP) <ref> [14] </ref>, that use a single connection to retrieve data (ignoring the control connection of FTP). Further, a bunch of TCP connections would be less regulated than a single connection.
Reference: [15] <author> Simon E. Spero. </author> <title> "Analysis of HTTP Performance Problems", </title> <address> URL http://elanor.oit.unc.edu/http-prob.html, July, </address> <year> 1994. </year> <month> 24 </month>
Reference-contexts: We then present results measured using prototype implementations, which confirm that our changes result in significantly improved response times. This material is based on our earlier paper [11]. During the course of our work, Simon Spero published an analysis of HTTP <ref> [15] </ref>, which reached conclusions similar to ours. However, we know of no other project, besides our own, that has implemented the consequent modifications to HTTP, or that has quantified the results. Another approach for avoiding the cost of network round trips is to "hide" them from the user.
References-found: 15

