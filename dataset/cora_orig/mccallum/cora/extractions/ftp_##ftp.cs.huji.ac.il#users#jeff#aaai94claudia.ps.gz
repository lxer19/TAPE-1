URL: ftp://ftp.cs.huji.ac.il/users/jeff/aaai94claudia.ps.gz
Refering-URL: http://www.cs.huji.ac.il/labs/dai/DAI98/seminars.html
Root-URL: http://www.cs.huji.ac.il
Email: clag@cs.huji.ac.il, jeff@cs.huji.ac.il  
Title: Emergent Coordination through the Use of Cooperative State-Changing Rules  
Author: Claudia V. Goldman and Jeffrey S. Rosenschein 
Address: Givat Ram, Jerusalem, Israel  
Affiliation: Computer Science Department Hebrew University  
Abstract: Researchers in Distributed Artificial Intelligence have suggested that it would be worthwhile to isolate "aspects of cooperative behavior," general rules that cause agents to act in ways conducive to cooperation. One kind of cooperative behavior is when agents independently alter the environment to make it easier for everyone to function effectively. Cooperative behavior of this kind might be to put away a hammer that one finds lying on the floor, knowing that another agent will be able to find it more easily later on. We examine the effect a specific "cooperation rule" has on agents in the multi-agent Tileworld domain. Agents are encouraged to increase tiles' degrees of freedom, even when the tile is not involved in an agent's own primary plan. The amount of extra work an agent is willing to do is captured in the agent's cooperation level. Results from simulations are presented. We present a way of characterizing domains as multi-agent deterministic finite automata, and characterizing cooperative rules as transformations of these automata. We also discuss general characteristics of cooperative state-changing rules. It is shown that a relatively simple, easily calculated rule can sometimes improve global system performance in the Tileworld. Coordination emerges from agents who use this rule of cooperation, without any explicit coordination or negotiation. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Conry, S. E.; Meyer, R. A.; and Lesser, V. R. </author> <year> 1988. </year> <title> Multistage negotiation in distributed planning. </title> <editor> In Bond, A. H., and Gasser, L., eds., </editor> <booktitle> Readings in Distributed Artificial Intelligence. </booktitle> <address> San Mateo, California: </address> <publisher> Morgan Kaufmann Publishers, Inc. </publisher> <pages> 367-384. </pages>
Reference: <author> Davis, R. </author> <year> 1981. </year> <title> A model for planning in a multi-agent environment: steps toward principles for teamwork. </title> <type> Working Paper 217, </type> <institution> Massachusetts Institute of Technology AI Laboratory. </institution>
Reference-contexts: An agent that acts predictably, shares its information, and defers globally constraining choices as long as possible, will be an easier one with which to coordinate. Work in this area includes early research by Davis and his colleagues at MIT <ref> (Davis 1981) </ref>, and some of the RAND work on cooperative behavior in the air traffic control domain (McArthur, Steeb, & Cammarata 1982). Multi-agent reactive systems have also been analyzed, where solutions are arrived at dynamically by reactive agents (eco-agents) in multi-agent environments (Ferber & Drogoul 1992).
Reference: <author> Durfee, E. H. </author> <year> 1988. </year> <title> Coordination of Distributed Problem Solvers. </title> <address> Boston: </address> <publisher> Kluwer Academic Publishers. </publisher>
Reference: <author> Ephrati, E., and Rosenschein, J. S. </author> <year> 1993. </year> <title> Multi-agent planning as a dynamic search for social consensus. </title> <booktitle> In Proceedings of the Thirteenth International Joint Conference on Artificial Intelligence, </booktitle> <pages> 423-429. </pages>
Reference: <author> Ferber, J., and Drogoul, A. </author> <year> 1992. </year> <title> Using reactive multi-agent systems in simulation and problem solving. </title> <editor> In Avouris, N. M., and Gasser, L., eds., </editor> <booktitle> Distributed Artificial Intelligence: Theory and Praxis. </booktitle> <publisher> Kluwer Academic Press. </publisher> <pages> 53-80. </pages>
Reference-contexts: Multi-agent reactive systems have also been analyzed, where solutions are arrived at dynamically by reactive agents (eco-agents) in multi-agent environments <ref> (Ferber & Drogoul 1992) </ref>. More recently, Tennenholtz, Shoham, and Moses have considered how social laws for artificial agent societies could be developed and evaluated (Ten-nenholtz & Moses 1989; Shoham & Tennenholtz 1992b; 1992a).
Reference: <author> Genesereth, M. R.; Ginsberg, M. L.; and Rosenschein, J. S. </author> <year> 1986. </year> <title> Cooperation without communication. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> 51-57. </pages>
Reference: <author> Gmytrasiewicz, P., and Durfee, E. H. </author> <year> 1992. </year> <title> A logic of knowledge and belief for recursive modeling: Preliminary report. </title> <booktitle> In Proceedings of the Tenth National Conference on Artificial Intelligence, </booktitle> <pages> 628-634. </pages>
Reference: <author> Grosz, B., and Kraus, S. </author> <year> 1993. </year> <title> Collaborative plans for group activities. </title> <booktitle> In Proceedings of the Thirteenth International Joint Conference on Artificial Intelligence, </booktitle> <pages> 367-373. </pages>
Reference: <author> Hanks, S.; Pollack, M. E.; and Cohen, P. R. </author> <year> 1993. </year> <title> Benchmarks, test beds, controlled experimentation, and the design of agent architectures. </title> <journal> AI Magazine 17-42. </journal>
Reference-contexts: We call this amount of extra work the cooperation level of the agent. Simulations We have run simulations using the MICE distributed agent testbed (Montgomery et al. 1992) to statistically analyze the efficacy of different cooperation levels <ref> (Hanks, Pollack, & Cohen 1993) </ref>. In all the experiments, the agents have positive, static and predefined cooperation levels.
Reference: <author> Kraus, S., and Wilkenfeld, J. </author> <year> 1991. </year> <title> Negotiations over time in a multi agent environment: Preliminary report. </title> <booktitle> In Proceedings of the Twelfth International Joint Conference on Artificial Intelligence, </booktitle> <pages> 56-61. </pages>
Reference: <author> Kraus, S. </author> <year> 1993. </year> <title> Agents contracting tasks in non-collaborative environments. </title> <booktitle> In Proceedings of the Eleventh National Conference on Artificial Intelligence, </booktitle> <pages> 243-248. </pages>
Reference: <author> Kreifelts, T., and Martial, F. </author> <year> 1990. </year> <title> A negotiation framework for autonomous agents. </title> <booktitle> In Proceedings of the Second European Workshop on Modeling Autonomous Agents and Multi-Agent Worlds, </booktitle> <pages> 169-182. </pages>
Reference: <author> Kuwabara, K., and Lesser, V. R. </author> <year> 1989. </year> <title> Extended protocol for multistage negotiation. </title> <booktitle> In Proceedings of the Ninth Workshop on Distributed Artificial Intelligence, </booktitle> <pages> 129-161. </pages>
Reference: <author> Lewis, H. R., and Papadimitriou, C. H. </author> <year> 1981. </year> <title> Elements of the theory of computation. </title> <publisher> Prentice-Hall, Inc. </publisher>
Reference-contexts: We define a multi-agent deterministic finite automaton, based on the standard definition of a deterministic finite automaton <ref> (Lewis & Papadimitriou 1981) </ref>. Definition .1 A multi-agent deterministic finite automaton (MADFA) is a quintuple M = (K; ; ffi; s; F ): * K is a finite set of states, the set of the multi-agent world states, * is an alphabet.
Reference: <author> Malone, T.; Fikes, R.; and Howard, M. </author> <year> 1988. </year> <title> Enterprise: A market-like task scheduler for distributed computing environments. </title> <editor> In Huberman, B. A., ed., </editor> <booktitle> The Ecology of Computation. </booktitle> <address> Amsterdam: </address> <publisher> North-Holland Publishing Company. </publisher> <pages> 177-205. </pages>
Reference: <author> McArthur, D.; Steeb, R.; and Cammarata, S. </author> <year> 1982. </year> <title> A framework for distributed problem solving. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> 181-184. </pages>
Reference-contexts: Work in this area includes early research by Davis and his colleagues at MIT (Davis 1981), and some of the RAND work on cooperative behavior in the air traffic control domain <ref> (McArthur, Steeb, & Cammarata 1982) </ref>. Multi-agent reactive systems have also been analyzed, where solutions are arrived at dynamically by reactive agents (eco-agents) in multi-agent environments (Ferber & Drogoul 1992).
Reference: <author> Montgomery, T. A.; Lee, J.; Musliner, D. J.; Durfee, E. H.; Damouth, D.; and So, Y. </author> <year> 1992. </year> <title> MICE Users Guide. </title> <institution> Artificial Intelligence Laboratory, Department of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, Michigan. </institution>
Reference-contexts: We call this amount of extra work the cooperation level of the agent. Simulations We have run simulations using the MICE distributed agent testbed <ref> (Montgomery et al. 1992) </ref> to statistically analyze the efficacy of different cooperation levels (Hanks, Pollack, & Cohen 1993). In all the experiments, the agents have positive, static and predefined cooperation levels.
Reference: <author> Pollack, M. E., and Ringuette, M. </author> <year> 1990. </year> <title> Introducing the Tileworld: Experimentally evaluating agent architectures. </title> <booktitle> In Proceedings of The National Conference on Artificial Intelligence, </booktitle> <pages> 183-189. </pages>
Reference-contexts: Rather, they induce the agents to perform extra work that will transform the world into one in which the work of all agents might be done more easily. Tileworld Interactions The Domain Consider agent interactions in a multi-agent version of the Tileworld <ref> (Pollack & Ringuette 1990) </ref>. Agents can move only through navigable discrete squares; moving from one square to another costs one unit. Agents are programmed to roam the grid and push tiles into holes. In our simulations, we considered two ways in which agents decide which tile to go after.
Reference: <author> Shoham, Y., and Tennenholtz, M. </author> <year> 1992a. </year> <title> Emergent conventions in multi-agent systems: initial experimental results and observations (preliminary report). </title> <booktitle> In Principles of knowledge representation and reasoning: Proceedings of the Third International Conference(KR92). </booktitle>
Reference: <author> Shoham, Y., and Tennenholtz, M. </author> <year> 1992b. </year> <title> On the synthesis of useful social laws for artificial agent societies (preliminary report). </title> <booktitle> In Proceedings of the Tenth National Conference on Artificial Intelligence. </booktitle>
Reference: <author> Smith, R. G. </author> <year> 1978. </year> <title> A Framework for Problem Solving in a Distributed Processing Environment. </title> <type> Ph.D. Dissertation, </type> <institution> Stanford University. </institution>
Reference: <author> Sycara, K. </author> <year> 1988. </year> <title> Resolving goal conflicts via negotiation. </title> <booktitle> In Proceedings of the Seventh National Conference on Artificial Intelligence, </booktitle> <pages> 245-250. </pages>
Reference: <author> Sycara, K. </author> <year> 1989. </year> <title> Argumentation: Planning other agents' plans. </title> <booktitle> In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <pages> 517-523. </pages>
Reference: <author> Tennenholtz, M., and Moses, Y. </author> <year> 1989. </year> <title> On cooperation in a multi-entity model. </title> <booktitle> In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <pages> 918-923. </pages>
Reference: <author> Zlotkin, G., and Rosenschein, J. S. </author> <year> 1993a. </year> <title> Compromise in negotiation: Exploiting worth functions over states. </title> <type> Technical Report 93-3, </type> <institution> Leibniz Center for Computer Science, Hebrew University. </institution>
Reference-contexts: Agents need to laboriously go around barriers to get into position and push a tile into a hole. Consider, for example, the simple interaction shown in Figure 1 (a variation of an example from <ref> (Zlotkin & Rosenschein 1993a) </ref>). Assume that agent A 1 wants to fill holes 1 and 2, and that agent A 2 wants to fill holes 2 and 3 (perhaps the agents were assigned these goals a priori ).
Reference: <author> Zlotkin, G., and Rosenschein, J. S. </author> <year> 1993b. </year> <title> A domain theory for task oriented negotiation. </title> <booktitle> In Proceedings of the Thirteenth International Joint Conference on Artificial Intelligence, </booktitle> <pages> 416-422. </pages>
References-found: 26

