URL: ftp://ftp.cis.ufl.edu/pub/faculty/vemuri/laa.ps.gz
Refering-URL: http://www.cis.ufl.edu/~vemuri/vp02.html
Root-URL: http://www.cis.ufl.edu
Email: email: lai@scr.siemens.com  email: vemuri@cise.ufl.edu  
Phone: 2  
Title: Sherman-Morrison-Woodbury Formula-based Algorithms for the Surface Smoothing Problem  
Author: Shang-Hong Lai and B. C. Vemuri Dr. B. C. Vemuri 
Note: Address of Correspondence:  This research was supported in part by the NSF grant ECS-9210648  
Address: Princeton, NJ 08540  Gainesville, FL 32611  Gainesville, FL 32611  
Affiliation: 1 Siemens Corporate Research  Department of Computer Information Sciences University of Florida,  Department of Computer Information Sciences University of Florida  
Abstract: Surface smoothing applied to range/elevation data acquired using a variety of sources has been a very active area of research in computational vision over the past decade. Generalized splines have emerged as the single most popular approximation tool to this end. In this paper we present a new and fast algorithm for solving the surface smoothing problem using a membrane, a thin-plate, or a thin-plate-membrane spline for data containing discontinuities. Our approach involves imbeding the surface smoothing problem specified on an irregular domain (in the sense of discontinuties and boundaries) in a rectangular region using the capacitance matrix method based on the Sherman-Morrison-Woodbury formula of matrix analysis. This formula is used in converting the problem of solving the original linear system resulting from a finite element discretization of the variational formulation of the surface smoothing problem to solving a Lyapunov matrix equation or a cascade of two Lyapunov matrix equations. The reduced problem can then be solved very efficiently using the ADI method and the bi-conjugate gradient technique. Our solution requires the generation of a dense capacitance matrix for which we propose a practical and efficient solution. We demonstrate the efficiency of our algorithm via experiments on sparse data surface smoothing with performance comparisons to the conjugate gradient and hierarchical basis preconditioned conjugate gradient algorithms. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. Dryja. </author> <title> A finite element-capacitance matrix method for the elliptic problem,. </title> <journal> SIAM J. Numer. Anal., </journal> <volume> 20(4) </volume> <pages> 671-680, </pages> <year> 1983. </year>
Reference-contexts: The domain is a region of interest over which the data is specified. (x; y) and t (x; y) are called continuity control functions, they constitute an explicit representation of depth and orientation discontinuities, respectively. The functions range over the interval <ref> [0; 1] </ref> and need not vary continuously. Setting the continuity control functions and t is tantamount to prior knowledge of the location of the discontinuities. Such knowledge may be obtained from other sources of information such as registered multi-sensor data. <p> Since several preconditioners have been well developed for the capacitance matrix in DD, Proskurowski and Vassilevski [12] regarded them as the inverses of the preconditioners in DI. Among them, Dryja's preconditioner <ref> [1] </ref> is based on the square root 22 of the finite difference analog of (d 2 =ds 2 ) along the boundary of the domain.
Reference: [2] <author> J. Duchon. </author> <title> Splines minimizing rotation-invariant semi-norms in sobolev spaces. </title> <editor> In A. Dodd and B. Eckmann, editors, </editor> <title> Constructive Theory of Functions of Several Variables, </title> <address> pages 85-100. Berlin: </address> <publisher> Springer-Verlag, </publisher> <year> 1977. </year> <month> 27 </month>
Reference-contexts: The goal is to find a u that minimizes the total potential energy E (v) in equation 3. Two different approaches have been proposed for solving the above variational problem. One is the reproducing kernel Hilbert space approach <ref> [2, 10, 20] </ref>, which gives an analytical expression for the smoothing spline solution.
Reference: [3] <author> R.W. Freund, G. H. Golub, and N.M. Nachtigal. </author> <title> Iterative solution of linear system. </title> <booktitle> In Acta Numerica 1992, </booktitle> <pages> pages 57-100. </pages> <publisher> Cambridge University Press, </publisher> <year> 1992. </year>
Reference-contexts: The linear system with the capacitance matrix in step 3 is dense and nonsymmetric and needs to be solved very efficiently. Our solution to this linear system is obtained by using the BCG (Bi-Conjugate Gradient) algorithm <ref> [3] </ref> if the size of the capacitance matrix is large or Gaussian elimination [4] when it is small. <p> To be more specific, division by 0 (or a number very close to 0) may occur inside the BCG iterations. These breakdowns may be avoided by using the look-ahead Lanczos algorithm or the quasi-minimal residual (QMR) algorithm <ref> [3] </ref>. In the BCG algorithm, two matrix-vector multiplications are required in each iteration. Since the matrix C is dense, the multiplication takes O (p 2 ) operations.
Reference: [4] <author> G.H. Golub and C.F. Van Loan. </author> <title> Matrix Computations. </title> <publisher> The Johns Hopkins University Press, </publisher> <address> 2nd edition, </address> <year> 1989. </year>
Reference-contexts: Then, the solution to the linear system Kx = b can be obtained by solving a well-structured linear system K 0 x = b 0 with a modified right-hand side b 0 . The derivation is based on the Sherman-Morrison-Woodbury formula <ref> [4] </ref> (K 0 + UV T ) 1 = K 1 0 U (I + V T K 1 0 ; (8) where K 0 is nonsingular, I 2 &lt; pfip is the identity matrix, and the matrix (I + V T K 1 0 U) is non-singular. <p> The linear system with the capacitance matrix in step 3 is dense and nonsymmetric and needs to be solved very efficiently. Our solution to this linear system is obtained by using the BCG (Bi-Conjugate Gradient) algorithm [3] if the size of the capacitance matrix is large or Gaussian elimination <ref> [4] </ref> when it is small. <p> In the discrete parabolic operator case, the corresponding condition number of A is bounded by a constant. From equation 41, we can see that the number of iterations needed is bounded by a constant number for a given error tolerance. For the latter, when the Frobenius norm <ref> [4] </ref> error reduction is used instead of the absolute term-wise error reduction in equation 39, we can show that the number of iterations needed for a given error tolerance is bounded by a constant number under a mild assumption that the spectrum of the right-hand side is upper bounded by a
Reference: [5] <author> W. W. Hager. </author> <title> Updating the inverse of a matrix. </title> <journal> SIAM Review, </journal> <volume> 31(2) </volume> <pages> 221-239, </pages> <month> June </month> <year> 1989. </year>
Reference-contexts: The matrix (I + V T K 1 0 U) is called the capacitance matrix <ref> [5] </ref> and is denoted by C. Note that the capacitance matrix C is nonsingular when both U and V are of full-column rank. Consequently, we choose the matrices U and V such that the respective column vectors of these two matrices are linearly independent.
Reference: [6] <author> S. H. Lai and B. C. Vemuri. </author> <title> An O(N ) iterative solution to the Poisson equations in low-level vision problems . Technical Report UF-CIS, </title> <institution> TR-93-035, Dept. of CISE, University of Florida, </institution> <month> November </month> <year> 1994. </year>
Reference-contexts: We use the alternating direction implicit (ADI) method to solve these Lyapunov matrix equations in a constant number of iterations for a given error tolerance with each iteration taking O (N ) time, where N is the number of nodes in the discretization <ref> [7, 6] </ref>. The modified right-hand side is obtained by solving a smaller dense and nonsymmetric capacitance matrix linear system using a bi-conjugate gradient algorithm. For the generation of this dense capacitance matrix for which we propose a practical and efficient solution. <p> Notice that the matrix A 0 in equation 18 is symmetric positive definite tridiagonal matrix. We can use the ADI (Alternating Direction Implicit) method to solve this Lyapunov matrix equation in O (N ) operations <ref> [7, 6] </ref>. We will describe the ADI method in the next section. As shown in the beginning of this section, the solution to the linear system Kx = b can be obtained by solving an equivalent linear system K 0 x = b 0 with a modified RHS. <p> the number of iterations needed for a given error tolerance is bounded by a constant number under a mild assumption that the spectrum of the right-hand side is upper bounded by a function of k!k 2 (! is the frequency domain vector valued variable) of degree less than 1 (see <ref> [7, 6] </ref> for details). Hence, the number of iterations needed in ADI for a given error tolerance is independent of the size of the problem for both cases.
Reference: [7] <author> S. H. Lai and B. C. Vemuri. </author> <title> An O(N ) iterative solution to the Poisson equations in low-level vision problems. </title> <booktitle> In IEEE conference on Computer Vision & Pattern Recognition, </booktitle> <pages> pages 9-14, </pages> <address> Seattle, Washington, </address> <month> June </month> <year> 1994. </year>
Reference-contexts: We use the alternating direction implicit (ADI) method to solve these Lyapunov matrix equations in a constant number of iterations for a given error tolerance with each iteration taking O (N ) time, where N is the number of nodes in the discretization <ref> [7, 6] </ref>. The modified right-hand side is obtained by solving a smaller dense and nonsymmetric capacitance matrix linear system using a bi-conjugate gradient algorithm. For the generation of this dense capacitance matrix for which we propose a practical and efficient solution. <p> Notice that the matrix A 0 in equation 18 is symmetric positive definite tridiagonal matrix. We can use the ADI (Alternating Direction Implicit) method to solve this Lyapunov matrix equation in O (N ) operations <ref> [7, 6] </ref>. We will describe the ADI method in the next section. As shown in the beginning of this section, the solution to the linear system Kx = b can be obtained by solving an equivalent linear system K 0 x = b 0 with a modified RHS. <p> the number of iterations needed for a given error tolerance is bounded by a constant number under a mild assumption that the spectrum of the right-hand side is upper bounded by a function of k!k 2 (! is the frequency domain vector valued variable) of degree less than 1 (see <ref> [7, 6] </ref> for details). Hence, the number of iterations needed in ADI for a given error tolerance is independent of the size of the problem for both cases.
Reference: [8] <author> D. Lee and J. H. Shiau. </author> <title> Thin plate splines with discontinuities and fast algorithms for their computation. </title> <journal> SIAM J. Scientific Computing, </journal> <volume> 15(6) </volume> <pages> 1311-1330, </pages> <month> November </month> <year> 1994. </year>
Reference-contexts: Numerous solution methods exist for the surface smoothing problem in approximation theory literature <ref> [13, 14, 10, 20, 15, 8] </ref>. Most of these do not deal with data containing discontinuities in the surface or its orientation. <p> Additionally, we can easily incorporate discontinuities of any order into the solution when using the finite element approach [19] whereas, the ability to incorporate discontinuities for the reproducing kernel Hilbert space approach is very limited <ref> [8] </ref>. In this paper, we use the finite element discretization approach to solve the above discussed variational principle. To compute a numerical solution to the above minimization problem, we first discretize the func 3 tionals E s and E d using finite element techniques [19].
Reference: [9] <author> A. Lu and E. L. </author> <title> Wachspress. Solution of Lyapunov equations by alternating direction implicit iteration. </title> <journal> Computers Math. Applic., </journal> <volume> 21(9) </volume> <pages> 43-58, </pages> <year> 1991. </year>
Reference-contexts: for the Lyapunov equation, the formation of matrix C, and the solution to the linear system Cy = V T x will be given. 3.1 ADI Method for the Lyapunov Equation (Stages (1) and (4) of the algorithm) The ADI method for solving a Lyapunov matrix equation is described in <ref> [9] </ref>. <p> The solution to this minimax problem gives the optimum set of ADI parameters. Computing the optimal choice of the ADI parameters is described in <ref> [9] </ref>. The minimax analysis also provides the solution to the number of iterations needed in ADI to achieve a specified error tolerance * in X such that k4X J k *kX true k.
Reference: [10] <author> J. Meinguet. </author> <title> Multivariate interpolation at arbitrary points made simple. </title> <journal> Journal of Applied Mathematics and Physics, </journal> <volume> 30 </volume> <pages> 292-304, </pages> <year> 1979. </year>
Reference-contexts: The goal in early vision is to recover the surface shape along with an explicit representation of the discontinuities from the noisy measurements. This problem, with the exclusion of discontinuities, is primarily the surface smoothing problem of approximation theory <ref> [13, 14, 10, 20] </ref>. In this paper, we will not address the automatic detection of depth/orientation discontinuities however, their location is assumed to be known a priori and the algorithms for surface smoothing will provide scope for explicitly incorporating the discontinuities at known locations into the solution. <p> Numerous solution methods exist for the surface smoothing problem in approximation theory literature <ref> [13, 14, 10, 20, 15, 8] </ref>. Most of these do not deal with data containing discontinuities in the surface or its orientation. <p> The goal is to find a u that minimizes the total potential energy E (v) in equation 3. Two different approaches have been proposed for solving the above variational problem. One is the reproducing kernel Hilbert space approach <ref> [2, 10, 20] </ref>, which gives an analytical expression for the smoothing spline solution.
Reference: [11] <author> D.P. O'Leary. </author> <title> A note on the capacitance matrix algorithm, substructuring, and mixed or Neumann boundary conditions,. </title> <journal> Applied Numerical Mathematics, </journal> <volume> 3 </volume> <pages> 339-345, </pages> <year> 1987. </year>
Reference-contexts: This choice is inspired by the rank augmenting method for singular matrices in the capacitance matrix method described in <ref> [11] </ref> and yields a nonsingular matrix with nice properties, which transforms the problem of solving the linear system Kx = b into solving a Lyapunov matrix equation.
Reference: [12] <author> W. Proskurowski and P. Vassilevski. </author> <title> Preconditioning capacitance matrix problems in domain imbedding,. </title> <journal> SIAM J. Sci. Comput., </journal> <volume> 15(1) </volume> <pages> 77-88, </pages> <year> 1994. </year>
Reference-contexts: In the worse case, it could takes p iterations, which lead to an O (p 3 ) algorithm. However, the rate of convergence for a conjugate gradient type algorithm usually can be improved with appropriate preconditioning. Proskurowski and Vassilevski <ref> [12] </ref> applied several preconditioning techniques for the capacitance matrix in the domain decomposition (DD) to the capacitance matrix in domain imbedding (DI) for the second order elliptic problems based on the observation that DD and DI are usually complementary, i.e. the capacitance matrix in DI is the inverse of the capacitance <p> Since several preconditioners have been well developed for the capacitance matrix in DD, Proskurowski and Vassilevski <ref> [12] </ref> regarded them as the inverses of the preconditioners in DI. Among them, Dryja's preconditioner [1] is based on the square root 22 of the finite difference analog of (d 2 =ds 2 ) along the boundary of the domain.
Reference: [13] <author> C. H. Reinsch. </author> <title> Smoothing by spline functions. </title> <journal> Numer. Math., </journal> <volume> 10 </volume> <pages> 177-183, </pages> <year> 1967. </year> <month> 28 </month>
Reference-contexts: The goal in early vision is to recover the surface shape along with an explicit representation of the discontinuities from the noisy measurements. This problem, with the exclusion of discontinuities, is primarily the surface smoothing problem of approximation theory <ref> [13, 14, 10, 20] </ref>. In this paper, we will not address the automatic detection of depth/orientation discontinuities however, their location is assumed to be known a priori and the algorithms for surface smoothing will provide scope for explicitly incorporating the discontinuities at known locations into the solution. <p> Numerous solution methods exist for the surface smoothing problem in approximation theory literature <ref> [13, 14, 10, 20, 15, 8] </ref>. Most of these do not deal with data containing discontinuities in the surface or its orientation.
Reference: [14] <author> L.L. Schumaker. </author> <title> Fitting surfaces to scattered data. </title> <editor> In G.G. Lorentz, C.K. Chui, and L.L. Schumaker, editors, </editor> <booktitle> Approximation Theory II, </booktitle> <pages> pages 203-267. </pages> <address> New York: </address> <publisher> Academic, </publisher> <year> 1976. </year>
Reference-contexts: The goal in early vision is to recover the surface shape along with an explicit representation of the discontinuities from the noisy measurements. This problem, with the exclusion of discontinuities, is primarily the surface smoothing problem of approximation theory <ref> [13, 14, 10, 20] </ref>. In this paper, we will not address the automatic detection of depth/orientation discontinuities however, their location is assumed to be known a priori and the algorithms for surface smoothing will provide scope for explicitly incorporating the discontinuities at known locations into the solution. <p> Numerous solution methods exist for the surface smoothing problem in approximation theory literature <ref> [13, 14, 10, 20, 15, 8] </ref>. Most of these do not deal with data containing discontinuities in the surface or its orientation.
Reference: [15] <author> R. Sibson and G. Stone. </author> <title> Computation of thin-plate splines. </title> <journal> SIAM J. Scientific Computing, </journal> <volume> 12(6) </volume> <pages> 1304-1313, </pages> <month> November </month> <year> 1991. </year>
Reference-contexts: Numerous solution methods exist for the surface smoothing problem in approximation theory literature <ref> [13, 14, 10, 20, 15, 8] </ref>. Most of these do not deal with data containing discontinuities in the surface or its orientation.
Reference: [16] <author> B. Smith and O. Wildlund. </author> <title> A domain decomposition algorithm using a hierachical basis. </title> <journal> SIAM J. Sci. Statist. Comput., </journal> <volume> 11 </volume> <pages> 1212-1226, </pages> <year> 1990. </year>
Reference-contexts: Dryja proved that this preconditioner is spectrally equivalent to the capacitance matrix for the second order elliptic problem, which means the iterative algorithm can converge in a constant number of iterations with this preconditioning. Smith and Widlund <ref> [16] </ref> used the hierarchical basis preconditioner [21] for the capacitance matrix in the second order elliptic problems. Unfortunately, these preconditioners can not be directly applied to the capacitance matrix arising from the surface smoothing problem presented in this paper.
Reference: [17] <author> R. Szeliski. </author> <title> Fast surface interpolation using hierarchical basis functions. </title> <journal> IEEE Trans. Pattern Anal. Machine Intell., </journal> <volume> 12(6) </volume> <pages> 513-528, </pages> <year> 1990. </year>
Reference-contexts: The other approach for minimizing the above energy functional is by use of a finite element technique to directly discretize the variational principle <ref> [19, 17] </ref> or numerically solve the PDE corresponding to the necessary condition for a minimum of the variational principle [19]. Then, the energy functional in equation 3 becomes a function of the nodal variables used in the discretization. <p> Discretization of this PDE leads to a system of algebraic equations as given in equation 7. This large n 2 fi n 2 sparse linear system can be solved using iterative techniques such as SOR (Successive Over-Relaxation), multi-grid method [18] or hierarchical conjugate gradient <ref> [17] </ref>, ..., etc. The convergence of these methods deteriorates in 4 the presence of discontinuities. In this paper, we develop a fast algorithm to solve the above linear system which accounts for the data and discontinuity locations in a unified manner. <p> We demonstrate the computational efficiency of our algorithm compared to the conjugate gradient (CG) algorithm and hierarchical basis preconditioned conjugate gradient (HBCG) algorithm <ref> [17, 21] </ref> via the experiments. These algorithms were tested on 64 fi 64 and 128 fi 128 discretization meshes. The input data set is very sparse and contains only 15 data points randomly distributed in the plane as shown in figure 2.
Reference: [18] <author> D. Terzopoulos. </author> <title> Image analysis using multigrid relaxation methods. </title> <journal> IEEE Trans. Pattern Anal. Machine Intell., </journal> <volume> 8 </volume> <pages> 129-139, </pages> <year> 1986. </year>
Reference-contexts: In this formulation, surface smoothing is treated as an energy minimization problem involving terms corresponding to a smoothness constraint and a data constraint. Smoothness constraints are expressed in the form of a Tikhonov or a controlled continuity stabilizer <ref> [18] </ref>. A thin 1 plate (C 1 ) or a membrane (C 0 ) surface is considered as Tikhonov stabilizers and a convex combina-tion of the two is called a controlled continuity stabilizer. In this framework, all data constraints are treated as penalty terms. <p> Discretization of this PDE leads to a system of algebraic equations as given in equation 7. This large n 2 fi n 2 sparse linear system can be solved using iterative techniques such as SOR (Successive Over-Relaxation), multi-grid method <ref> [18] </ref> or hierarchical conjugate gradient [17], ..., etc. The convergence of these methods deteriorates in 4 the presence of discontinuities. In this paper, we develop a fast algorithm to solve the above linear system which accounts for the data and discontinuity locations in a unified manner.
Reference: [19] <author> D. Terzopoulos. </author> <title> The computation of visible-surface representations. </title> <journal> IEEE Trans. Pattern Anal. Machine Intell., </journal> <volume> 10(4) </volume> <pages> 417-438, </pages> <year> 1988. </year>
Reference-contexts: The goal is to minimize the strain energy in the constrained thin-plate, membrane, or a thin-plate-membrane surface. When using the controlled continuity stabilizer, the solution surface will comprise of thin-plate patches away from orientation discontinuities and membrane strips along loci of orientation discontinuities <ref> [19] </ref>. The solution surface is defined by a configuration of minimal energy E of a physical system comprised of the thin plate patches, the membrane strips, and the springs. <p> The other approach for minimizing the above energy functional is by use of a finite element technique to directly discretize the variational principle <ref> [19, 17] </ref> or numerically solve the PDE corresponding to the necessary condition for a minimum of the variational principle [19]. Then, the energy functional in equation 3 becomes a function of the nodal variables used in the discretization. <p> The other approach for minimizing the above energy functional is by use of a finite element technique to directly discretize the variational principle [19, 17] or numerically solve the PDE corresponding to the necessary condition for a minimum of the variational principle <ref> [19] </ref>. Then, the energy functional in equation 3 becomes a function of the nodal variables used in the discretization. The above functional minimization problem is reduced to minimizing this function with respect to the nodal variables. <p> Additionally, we can easily incorporate discontinuities of any order into the solution when using the finite element approach <ref> [19] </ref> whereas, the ability to incorporate discontinuities for the reproducing kernel Hilbert space approach is very limited [8]. In this paper, we use the finite element discretization approach to solve the above discussed variational principle. <p> In this paper, we use the finite element discretization approach to solve the above discussed variational principle. To compute a numerical solution to the above minimization problem, we first discretize the func 3 tionals E s and E d using finite element techniques <ref> [19] </ref>. For an irregular domian , we can use the domain imbedding technique and discretize the problem on a rectangular domain. For ease of exposition, the domain is assumed to be rectangular in the rest of this paper. <p> form is a quadratic in x when the continuity control functions (x; y) and t (x; y) are assumed to be constants, i.e., E s (x) = 2 where K s 2 &lt; n 2 fin 2 is a very large sparse and block banded matrix containing the computational molecules <ref> [19] </ref> from the membrane or thin-plate smoothness constraint. The resulting energy function is a quadratic in x E (x) = 2 with K = K s + K d and b = K d d. <p> The minimum of equation 6 is found by solving the large sparse linear system Kx = b (7) Another way of approaching the solution to the minimization of the energy E is using calculus of variations <ref> [19] </ref>. The necessary condition for the minimum of the energy functional is a partial differential equation called the Euler-Lagrange equation. Discretization of this PDE leads to a system of algebraic equations as given in equation 7. <p> The matrix K is a sum of two matrices K s and K d , with K s containing the membrane or thin-plate molecules <ref> [19] </ref> defined on the interior and boundary of . The K d matrix is a diagonal matrix containing non-zero weights. <p> Focusing on the surface smoothing problem in a rectangular domain, the discretization of the data compatibility energy and the membrane smoothness energy leads to the stiffness matrix K that can be formed from the computational molecules given in <ref> [19] </ref>. Note that we have the data constraint molecule in every node all over the domain for the dense data case. The membrane molecule exists between most neighboring nodes except those separated by the discontinuities.
Reference: [20] <author> G. Wahba. </author> <title> Spline Models for Observational Data. </title> <institution> Society for Industrial and Applied Mathematics, </institution> <address> Philadelphia, </address> <year> 1990. </year>
Reference-contexts: The goal in early vision is to recover the surface shape along with an explicit representation of the discontinuities from the noisy measurements. This problem, with the exclusion of discontinuities, is primarily the surface smoothing problem of approximation theory <ref> [13, 14, 10, 20] </ref>. In this paper, we will not address the automatic detection of depth/orientation discontinuities however, their location is assumed to be known a priori and the algorithms for surface smoothing will provide scope for explicitly incorporating the discontinuities at known locations into the solution. <p> Numerous solution methods exist for the surface smoothing problem in approximation theory literature <ref> [13, 14, 10, 20, 15, 8] </ref>. Most of these do not deal with data containing discontinuities in the surface or its orientation. <p> The goal is to find a u that minimizes the total potential energy E (v) in equation 3. Two different approaches have been proposed for solving the above variational problem. One is the reproducing kernel Hilbert space approach <ref> [2, 10, 20] </ref>, which gives an analytical expression for the smoothing spline solution.
Reference: [21] <author> H. Yeserentant. </author> <title> On multi-level splitting of finite element spaces. </title> <journal> Numeriche Mathematik, </journal> <volume> 49 </volume> <pages> 379-412, </pages> <year> 1986. </year>
Reference-contexts: Dryja proved that this preconditioner is spectrally equivalent to the capacitance matrix for the second order elliptic problem, which means the iterative algorithm can converge in a constant number of iterations with this preconditioning. Smith and Widlund [16] used the hierarchical basis preconditioner <ref> [21] </ref> for the capacitance matrix in the second order elliptic problems. Unfortunately, these preconditioners can not be directly applied to the capacitance matrix arising from the surface smoothing problem presented in this paper. <p> We demonstrate the computational efficiency of our algorithm compared to the conjugate gradient (CG) algorithm and hierarchical basis preconditioned conjugate gradient (HBCG) algorithm <ref> [17, 21] </ref> via the experiments. These algorithms were tested on 64 fi 64 and 128 fi 128 discretization meshes. The input data set is very sparse and contains only 15 data points randomly distributed in the plane as shown in figure 2.
References-found: 21

