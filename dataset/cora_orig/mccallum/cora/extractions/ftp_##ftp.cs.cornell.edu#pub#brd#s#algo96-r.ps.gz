URL: ftp://ftp.cs.cornell.edu/pub/brd/s/algo96-r.ps.gz
Refering-URL: http://www.cs.cornell.edu/Info/People/brd/brd.html
Root-URL: 
Email: brd@cs.cornell.edu  
Title: Mobile Robot Self-Localization Without Explicit Landmarks  
Author: Russell G. Brown Bruce R. Donald 
Date: November 19, 1996  
Address: 4130 Upson Hall Albuquerque, NM 87185-1008  rgbrown@isrc.sandia.gov Ithaca, NY 14853  
Affiliation: Intelligent Systems Robotics Center Robotics and Vision Laboratory MS-1008 Department of Computer Science Sandia National Laboratories  Cornell University  
Abstract: Localization is the process of determining the robot's location within its environment. More precisely, it is a procedure which takes as input a geometric map, a current estimate of the robot's pose, and sensor readings, and produces as output an improved estimate of the robot's current pose (position and orientation). We describe a combinatorially precise algorithm which performs mobile robot localization using a geometric model of the world and a point-and-shoot ranging device. We also describe a rasterized version of this algorithm which we've implemented on a real mobile robot equipped with a laser rangefinder we designed. Both versions of the algorithm allow for uncertainty in the data returned by the range sensor. We also present experimental results for the rasterized algorithm, obtained using our mobile robots at Cornell. 
Abstract-found: 1
Intro-found: 1
Reference: [AH91] <author> Sami Atiya and Greg Hager. </author> <title> Real-time vision-based robot localization. </title> <booktitle> In Proceedings of 40 the 1991 IEEE International Conference on Robotics and Automation, </booktitle> <pages> pages 639-644, </pages> <address> Sacramento, CA, </address> <year> 1991. </year>
Reference-contexts: Their beacons are such features as "peaks", "pits", "ridges", and "ravines"; these are appropriate to navigation in rough natural terrains. Several attempts have been made to use computer vision to detect and locate beacons ([CC92], <ref> [AH91] </ref>, and [RWA + 92]). [CC92] use an Extended Kalman Filter to estimate position from odom-etry, sonar data, and the location of visually detected landmarks. They select their landmarks by hand, choosing objects with strong vertical edges. <p> They select their landmarks by hand, choosing objects with strong vertical edges. This work is similar to that of [MR88] and [Kle92], except that the landmarks here are extracted from an image. They support their work with rudimentary experimental evidence. <ref> [AH91] </ref> presents an algorithm that determines both the correspondence between observed landmarks (vertical edges in the environment) and an a priori map, and the location of the robot from that correspondence. They detect and locate their visual landmarks using stereo vision techniques.
Reference: [AHU83] <author> A.V. Aho, J.E. Hopcroft, and J.D. Ullman. </author> <title> Data Structures and Algorithms. </title> <publisher> Addison-Wesley, </publisher> <year> 1983. </year>
Reference-contexts: Since specialized signal/image processing hardware is capable of performing this operation very quickly, discrete convolution is a very useful operation for rasterized-algorithms. Figure 13 shows a sample rasterized convolution. Floodfill/Brushfire Algorithms Breadth First Search <ref> [AHU83] </ref> is an often-used order for visiting nodes in a graph, in which we visit/examine/compute upon the nodes adjacent to the start node first, then those that are at distance two from the start, then those at distance three, and so on until all nodes have been visited.
Reference: [AST92] <author> P. K. Agarwal, M. Sharir, and S. Toledo. </author> <title> Applications of parametric searching in geometric optimization. </title> <booktitle> In Proc. Third ACM-SIAM Symp. on Discrete Algorithms, </booktitle> <pages> pages 72-82, </pages> <year> 1992. </year>
Reference-contexts: Parametric search typically takes a serial decision procedure that operates in time O (T (n)) and a parallel decision algorithm that operates in parallel time O (P (n)), and produces a minimization procedure that operates in time O (T (n) log k (P (n))) for some positive integer k. <ref> [AST92] </ref> shows how this mechanism can be applied to finding the minimum hausdorff distance [HK90] between two point sets. We can use a similar approach to develop an algorithm to compute the smallest uncertainty ball, * min , such that F P * min (M; Z) is nonempty. [AST92] take a <p> integer k. <ref> [AST92] </ref> shows how this mechanism can be applied to finding the minimum hausdorff distance [HK90] between two point sets. We can use a similar approach to develop an algorithm to compute the smallest uncertainty ball, * min , such that F P * min (M; Z) is nonempty. [AST92] take a decision procedure with worst case time O (m 2 n 2 log (mn)) and are able to obtain a minimization procedure that takes worst case time O (m 2 n 2 log 3 (mn)).
Reference: [BL91] <author> J. Barraquand and J. C. Latombe. </author> <title> Robot motion planning: A distributed representation approach. </title> <journal> International Journal of Robotics Research, </journal> <volume> 10(6) </volume> <pages> 628-649, </pages> <year> 1991. </year>
Reference-contexts: We believe that algorithms operating on discretized arrays are useful, in that they are often easier to implement than the original combinatorial algorithms, and they often run faster. See [Lat92], <ref> [BL91] </ref>, [LP83], [LRDG90], [HK93], [CK92] for examples of how rasterization can be applied to robotics algorithms. In this section, we define rasterized algorithms, and define some basic building blocks from which rasterized algorithms can be built.
Reference: [BR91] <author> J.R. </author> <title> Beveridge and E.M. Riseman. Hallway navigation in perspective. </title> <type> Technical report, </type> <institution> University of Massachusetts at Amherst, Computer and Information Sciences Department, </institution> <month> June </month> <year> 1991. </year>
Reference: [Bro95] <author> R. G. Brown. </author> <title> Algorithms for Mobile Robot Localization and Building Flexible, Robust, Easy to Use Mobile Robots. </title> <type> PhD thesis, </type> <institution> Cornell University, </institution> <address> Ithaca, NY, </address> <month> May </month> <year> 1995. </year>
Reference-contexts: The robot must occupy that position to get range vectors x, y, and z in map M . mobile robot, Lily, at the Cornell Computer Science Robotics and Vision Laboratory. This paper is based on a portion of the Cornell Computer Science doctoral thesis <ref> [Bro95] </ref>. The main concept underlying the localization algorithms presented in this paper is that of the feasible pose. <p> For experiments performed to date using our robots, we have been able to use orientational odometry with fair success; however, robots with less fortunate kinematics may not permit this. For example, see the description of the treaded robot Camel in <ref> [Bro95] </ref>. It is probable that we could perform localization in R 2 fi S 1 by computing feasible pose sets in R fiS 1 directly.
Reference: [CC92] <author> Frederic Chenavier and James L. Crowley. </author> <title> Position estimation for a mobile robot using vision and odometry. </title> <booktitle> In Proc. of the 1992 IEEE International Conference on Robotics and Automation, </booktitle> <pages> pages 2588-2593, </pages> <address> Nice, France, </address> <year> 1992. </year>
Reference-contexts: Their beacons are such features as "peaks", "pits", "ridges", and "ravines"; these are appropriate to navigation in rough natural terrains. Several attempts have been made to use computer vision to detect and locate beacons (<ref> [CC92] </ref>, [AH91], and [RWA + 92]). [CC92] use an Extended Kalman Filter to estimate position from odom-etry, sonar data, and the location of visually detected landmarks. They select their landmarks by hand, choosing objects with strong vertical edges.
Reference: [CGH + 93] <author> L.P. Chew, M.T. Goodrich, D.P. Huttenlocher, K. Kedem, J.M. Kleinberg, and D. Kravets. </author> <title> Geometric pattern matching under Euclidean motion. </title> <booktitle> In Proc. Fifth Canadian Conference on Computational Geometry, </booktitle> <pages> pages 151-156, </pages> <address> Waterloo, Ontario, </address> <month> August </month> <year> 1993. </year>
Reference-contexts: The current best algorithm for this problem (proposed by <ref> [CGH + 93] </ref>) has an upper time bound of O (m 3 n 3 log 2 (mn)), for two sets P with complexity m and Q with complexity n.
Reference: [CK92] <author> L.P. Chew and K. Kedem. </author> <title> Improvements on approximate pattern matching problems. </title> <editor> In O. Nurmi and E. Ukkonen, editors, </editor> <booktitle> Proc. Third Scandinavian Workshop on Algorithm Theory. Lecture Notes in Computer Science 621, </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1992. </year> <month> 41 </month>
Reference-contexts: We believe that algorithms operating on discretized arrays are useful, in that they are often easier to implement than the original combinatorial algorithms, and they often run faster. See [Lat92], [BL91], [LP83], [LRDG90], [HK93], <ref> [CK92] </ref> for examples of how rasterization can be applied to robotics algorithms. In this section, we define rasterized algorithms, and define some basic building blocks from which rasterized algorithms can be built. We then present rasterized versions of the translation-only (R 2 ) localization algorithms presented in section 2.2.2.
Reference: [DKM92] <author> B. R. Donald, D. Kapur, and J. Mundy. </author> <title> Symbolic and Numerical Computation for Artificial Intelligence. </title> <publisher> Academic Press, Harcourt Jovanovich, </publisher> <year> 1992. </year>
Reference-contexts: To our view, such a lacuna would be as serious as omitting the asymptotic bounds. Rasterization is not a mere "engineering detail" but, rather, an integral part of any systematic attempt to develop physical geometric algorithms that are to be implemented and used in practice. See <ref> [DKM92] </ref> for a methodology for the integrated co-development of combinatorially precise and rasterized geometric algorithms.
Reference: [Don89] <author> B. Donald. </author> <title> Error Detection and Recovery in Robotics, </title> <booktitle> volume 336 of Lecture Notes in Computer Science. </booktitle> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1989. </year>
Reference-contexts: Appendix A 1 A more efficient algorithm is given later, in Theorem 8. 16 is a condensed treatment of material found in, among other places, [PS85], [NP82], <ref> [Don89] </ref>, and [Lat92]. The last paragraph of Appendix A describes a version of the polygon arrangement algorithm which outputs the depth of coverage of polygons of two different colors (e. g., how many red polygons cover a given member of the arrangement and also how many blue cover that member). <p> Appendix A: The Plane Sweep In this appendix, we review the family of algorithms known as "plane sweeps". The following discussion is a condensed treatment of material found in, among other places, [PS85], [NP82], <ref> [Don89] </ref>, and [Lat92]. Suppose we have a set of n line segments in the plane, and we want to determine all of the intersections between them. <p> The ability to compute multicolored arrangements in this fashion is a key part of the localization algorithms we will describe next. The plane sweep algorithm is a key subpart of many computational geometric algorithms. For other instances of applications using the plane-sweep see, for example, <ref> [PS85, Don89, Lat92] </ref>).
Reference: [Dru87] <author> Drumheller. </author> <title> Mobile robot localization using sonar. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> PAMI-9(2), </volume> <year> 1987. </year>
Reference: [Elf87] <author> A. Elfes. </author> <title> Sonar-based real-world mapping and navigation. </title> <journal> IEEE Journal of Robotics and Automation, </journal> <volume> RA-3(3), </volume> <year> 1987. </year>
Reference-contexts: Note that all of our algorithms handle uncertainly in sensor measurements robustly. The Underlying Spatial Representation The map-making technique we chose for this system is a variant of the statistical occupancy grid. Moravec and Elfes introduced this method of map-making in <ref> [Elf87, Mor89, ME85] </ref> as a way of making detailed geometric maps using noisy sensors (sonar rangefinders, in their case). A simple occupancy grid is a bitmap, where ones represent occupied cells and zeroes vacant cells. <p> This sensor uses a non-colocated transmitter-receiver pair to track regions of constant depth. They use this sensor as part of a localization algorithm for a moving mobot in an indoor environment. Moravec and Elfes introduced the statistical occupancy grid method of map-making in <ref> [Elf87, Mor89, ME85] </ref> as a way of making detailed geometric maps using noisy sensors (sonar rangefinders, in their case). A statistical occupancy grid is an array, where the contents of each cell is based on the confidence that the part of the environment corresponding to that cell is occupied.
Reference: [GLP85] <author> W. Eric L. Grimson and Tomas Lozano-Perez. </author> <title> Recognition and localization of overlapping parts from sparse data in two and three dimensions. </title> <booktitle> In Proceedings of the 1985 IEEE International Conference on Robotics and Automation, </booktitle> <pages> pages 61-66, </pages> <address> St. Louis, MO, </address> <year> 1985. </year>
Reference: [GMR91] <author> L. J. Guibas, R. Motwani, and P. Raghavan. </author> <title> The robot localization problem in two dimensions. </title> <booktitle> In Symposium on Discrete Algorithms, </booktitle> <pages> pages 259-268, </pages> <year> 1991. </year>
Reference-contexts: Some work has been done toward developing localization techniques and algorithms that operate by comparing geometric representations of the robot's environment with instantaneous sensory data, in such a way as to provide estimates of the robot's pose within its map: Guibas, et al <ref> [GMR91] </ref>, present the localization problem as a matching problem between a world polygon and a visibility polygon. The visibility polygon represents the output of a swept rangefinder. This algorithm provides a list of poses within the world polygon from which the view is consistent with the range-finder polygon.
Reference: [GSO92] <author> Javier Gonzalez, Anthony Stentz, and Anibal Ollero. </author> <title> An iconic position estimator for a 2d laser rangefinder. </title> <booktitle> In Proc. of the 1992 IEEE International Conference on Robotics and Automation, </booktitle> <pages> pages 2646-2651, </pages> <address> Nice, France, </address> <year> 1992. </year>
Reference-contexts: test, which he defines as an additional constraint on sonar: that "an admissible robot configuration must not imply that any sonar ray penetrates a solid object." His algorithm returns the interpretation that passes the sonar barrier test and has the greatest amount of sonar contour in contact with the walls. <ref> [GSO92] </ref> use a similar approach, except that they use maps made by the robot (both a map made of line segments and a 6 map of cells), use a laser rangefinder to obtain their sensory data, and use an iterative algorithm to match their maps against their sensory data. [HMB92] use
Reference: [HK90] <author> D. P. Huttenlocher and K. Kedem. </author> <title> Efficiently computing the hausdorff distance for point sets under translation. </title> <booktitle> In Proc. of the Sixth ACM Symposium on Computational Geometry, </booktitle> <pages> pages 340-349, </pages> <year> 1990. </year>
Reference-contexts: (T (n)) and a parallel decision algorithm that operates in parallel time O (P (n)), and produces a minimization procedure that operates in time O (T (n) log k (P (n))) for some positive integer k. [AST92] shows how this mechanism can be applied to finding the minimum hausdorff distance <ref> [HK90] </ref> between two point sets.
Reference: [HK93] <author> D.P. Huttenlocher and K. Kedem. </author> <title> Distance metrics for comparing shapes in the plane. </title> <booktitle> In Symbolic and Numerical Computation for Artificial Intelligence, </booktitle> <pages> pages 201-219. </pages> <publisher> Academic Press, </publisher> <year> 1993. </year>
Reference-contexts: We believe that algorithms operating on discretized arrays are useful, in that they are often easier to implement than the original combinatorial algorithms, and they often run faster. See [Lat92], [BL91], [LP83], [LRDG90], <ref> [HK93] </ref>, [CK92] for examples of how rasterization can be applied to robotics algorithms. In this section, we define rasterized algorithms, and define some basic building blocks from which rasterized algorithms can be built. We then present rasterized versions of the translation-only (R 2 ) localization algorithms presented in section 2.2.2.
Reference: [HMB92] <author> Alois A. Holenstein, Markus A. Muller, and Essam Badreddin. </author> <title> Mobile robot localization in a structured environment cluttered with obstacles. </title> <booktitle> In Proc. of the 1992 IEEE International Conference on Robotics and Automation, </booktitle> <pages> pages 2576-2581, </pages> <address> Nice, France, </address> <year> 1992. </year>
Reference-contexts: walls. [GSO92] use a similar approach, except that they use maps made by the robot (both a map made of line segments and a 6 map of cells), use a laser rangefinder to obtain their sensory data, and use an iterative algorithm to match their maps against their sensory data. <ref> [HMB92] </ref> use sonar data to perform localization: They extract "edge", "wall", "corner", and "unknown" features from this data, then find the transformation that maps each sensed feature onto a map feature of the same type. They then plot the transformations and look for clusters of similar transforms.
Reference: [Jaz70] <author> A. H. Jazwinski. </author> <title> Stochastic Processes and Filtering Theory. </title> <publisher> Academic Press, </publisher> <year> 1970. </year>
Reference: [KK91] <author> In So Kweon and Takeo Kanade. </author> <title> Extracting topographic features for outdoor mobile robotics. </title> <booktitle> In Proceedings of the 1991 IEEE International Conference on Robotics and Automation, </booktitle> <pages> pages 1992-1997, </pages> <address> Sacramento, CA, </address> <year> 1991. </year>
Reference-contexts: They use a Kalman Filter to combine the "measured" location of nearby beacons with the "expected" location (based on odometry and the robot's map) to compute new pose estimates. <ref> [KK91] </ref> is an example of outdoor beacon-based navigation. Their beacons are such features as "peaks", "pits", "ridges", and "ravines"; these are appropriate to navigation in rough natural terrains.
Reference: [Kle92] <author> Lindsay Kleeman. </author> <title> Optimal estimation of position and heading for mobile robots using ultrasonic beacons and dead-reckoning. </title> <booktitle> In Proc. of the 1992 IEEE International Conference on Robotics and Automation, </booktitle> <pages> pages 2582-2587, </pages> <address> Nice, France, </address> <year> 1992. </year>
Reference-contexts: If the robot can detect the angles to three beacons at known locations, it can use trigonometry to solve for its own position. <ref> [Kle92] </ref> achieves a similar result using active sonar beacons | elapsed times between the receptions of chirps from the series of known-location emitters enable the robot to compute its location; in fact, [Kle92] uses an Iterated Extended Kalman Filter ([Jaz70]) to merge pose estimates based on the active beacons with that <p> the angles to three beacons at known locations, it can use trigonometry to solve for its own position. <ref> [Kle92] </ref> achieves a similar result using active sonar beacons | elapsed times between the receptions of chirps from the series of known-location emitters enable the robot to compute its location; in fact, [Kle92] uses an Iterated Extended Kalman Filter ([Jaz70]) to merge pose estimates based on the active beacons with that based on dead reckoning. [LDWC90] defines a geometric beacon as "a special class of target which can be reliably observed in successive sensor measurements (a beacon), and which can be accurately described <p> They select their landmarks by hand, choosing objects with strong vertical edges. This work is similar to that of [MR88] and <ref> [Kle92] </ref>, except that the landmarks here are extracted from an image. They support their work with rudimentary experimental evidence. [AH91] presents an algorithm that determines both the correspondence between observed landmarks (vertical edges in the environment) and an a priori map, and the location of the robot from that correspondence.
Reference: [Kle94] <author> J. Kleinberg. </author> <title> The localization problem for mobile robots. </title> <booktitle> In Proc. 35th IEEE Symposium on Foundations of Computer Science, </booktitle> <year> 1994. </year>
Reference-contexts: A more fundamental difficulty with this algorithm is that, in general, obtaining the visibility polygon, as a list of vertices and edges, is extremely difficult with any physically realizable sensor. 5 Kleinberg, in <ref> [Kle94] </ref> also presents an algorithm which approaches mobile robot localization from a theoretical viewpoint. He provides an online search algorithm by which a mobile robot moving within its environment can uniquely determine its location without access to an a priori map. <p> disambiguate the robot's current pose using instantaneous range data obtained from the robot's current pose, what is the best motion the robot can make to obtain data that will give it a more unique pose estimate? Work in this direction might be based on Kleinberg's online localization algorithm, presented in <ref> [Kle94] </ref>. Conclusion Much work has been done on mobile robot navigation problems. What we have done is to provide exact combinatorial algorithms with complexity analyses for the localization aspect of navigation and to provide rasterized versions of these algorithms which are suitable for execution upon a mobile robot.
Reference: [Lat92] <author> J.-C. Latombe. </author> <title> Robot Motion planning. </title> <publisher> Kluwer, </publisher> <year> 1992. </year> <month> 42 </month>
Reference-contexts: Appendix A 1 A more efficient algorithm is given later, in Theorem 8. 16 is a condensed treatment of material found in, among other places, [PS85], [NP82], [Don89], and <ref> [Lat92] </ref>. The last paragraph of Appendix A describes a version of the polygon arrangement algorithm which outputs the depth of coverage of polygons of two different colors (e. g., how many red polygons cover a given member of the arrangement and also how many blue cover that member). <p> The planar map used thus far in the paper is essentially the Configuration Space of a 19 point robot moving among planar obstacles (for a more detailed discussion of Configuration Spaces, see [LP83] or <ref> [Lat92] </ref>). The Configuration Space of a point robot with orientation is essentially the map we would use for R 2 fi S 1 localization. By convolving that three-dimensional set with a set of range probes, we can formulate D and E sets analogous to the ones computed in the plane. <p> Given 20 an algorithm that runs on geometric descriptions, convert (by hand) the algorithm to perform on a discretized grid. We believe that algorithms operating on discretized arrays are useful, in that they are often easier to implement than the original combinatorial algorithms, and they often run faster. See <ref> [Lat92] </ref>, [BL91], [LP83], [LRDG90], [HK93], [CK92] for examples of how rasterization can be applied to robotics algorithms. In this section, we define rasterized algorithms, and define some basic building blocks from which rasterized algorithms can be built. <p> Appendix A: The Plane Sweep In this appendix, we review the family of algorithms known as "plane sweeps". The following discussion is a condensed treatment of material found in, among other places, [PS85], [NP82], [Don89], and <ref> [Lat92] </ref>. Suppose we have a set of n line segments in the plane, and we want to determine all of the intersections between them. <p> The ability to compute multicolored arrangements in this fashion is a key part of the localization algorithms we will describe next. The plane sweep algorithm is a key subpart of many computational geometric algorithms. For other instances of applications using the plane-sweep see, for example, <ref> [PS85, Don89, Lat92] </ref>).
Reference: [LDWC90] <author> J. Leonard, H. Durrant-Whyte, and I. J. Cox. </author> <title> Dynamic map building for an autonomous mobile robot. </title> <booktitle> In Proceedings of the 1990 IEEE/RSJ International Conference on Intelligent Robot Systems, </booktitle> <year> 1990. </year>
Reference-contexts: using active sonar beacons | elapsed times between the receptions of chirps from the series of known-location emitters enable the robot to compute its location; in fact, [Kle92] uses an Iterated Extended Kalman Filter ([Jaz70]) to merge pose estimates based on the active beacons with that based on dead reckoning. <ref> [LDWC90] </ref> defines a geometric beacon as "a special class of target which can be reliably observed in successive sensor measurements (a beacon), and which can be accurately described in terms of a concise geometric parameterization." The beacons they use are typically walls, corners, and cylinders.
Reference: [LP83] <author> T. Lozano-Perez. </author> <title> Spatial planning: A configuration space approach. </title> <journal> IEEE Transactions on Computers, </journal> <note> C-32(2):108-120, 1983. Also MIT A.I. Memo 605, </note> <month> Dec. </month> <year> 1982. </year>
Reference-contexts: Figure 4 demonstrates this interpretation. Given a range vector z, then, we can compute the possible locations of the robot. Before we can define feasible pose precisely, we need a few definitions: The Minkowski sum of two sets, X Y (as described in <ref> [LP83] </ref>) is the vector sum of all points in X with all points in Y : X Y = fx + y j x 2 X; y 2 Y g: X Y is the vector sum of X with the 180 degree rotation of Y : X Y = fx y <p> The darker, unoccluded grey squares key the shading of E (M; z i ). 13 14 with two curved corners in the center is the intersection, F P (M; fz1; z2; z3g). also compute E = M `(0; z) in linear time: <ref> [LP83] </ref> showed that B A, for convex polygons B and A with b and a vertices, respectively, can be computed in time fi (a + b). <p> The planar map used thus far in the paper is essentially the Configuration Space of a 19 point robot moving among planar obstacles (for a more detailed discussion of Configuration Spaces, see <ref> [LP83] </ref> or [Lat92]). The Configuration Space of a point robot with orientation is essentially the map we would use for R 2 fi S 1 localization. <p> We believe that algorithms operating on discretized arrays are useful, in that they are often easier to implement than the original combinatorial algorithms, and they often run faster. See [Lat92], [BL91], <ref> [LP83] </ref>, [LRDG90], [HK93], [CK92] for examples of how rasterization can be applied to robotics algorithms. In this section, we define rasterized algorithms, and define some basic building blocks from which rasterized algorithms can be built.
Reference: [LRDG90] <author> J. Lengyel, M. Reichert, B. Donald, and D. Greenberg. </author> <title> Real-time robot motion planning using rasterizing computer graphics hardware. </title> <institution> Department of Computer Science Technical Report TR 90-1122, Cornell University Department of Computer Science, </institution> <month> May </month> <year> 1990. </year>
Reference-contexts: We believe that algorithms operating on discretized arrays are useful, in that they are often easier to implement than the original combinatorial algorithms, and they often run faster. See [Lat92], [BL91], [LP83], <ref> [LRDG90] </ref>, [HK93], [CK92] for examples of how rasterization can be applied to robotics algorithms. In this section, we define rasterized algorithms, and define some basic building blocks from which rasterized algorithms can be built. <p> We can define obstacle cells in the array as those that cannot be flooded. If we do this, then the contours define the distance to the nearest source cell via a path that does not cross any obstacle cell. In fact, <ref> [LRDG90] </ref> makes use of this property to design a very fast robot path planner that computes the shortest path from anywhere in the robot's configuration space to a specified goal.
Reference: [Mar82] <author> D. Marr. </author> <title> Vision. </title> <editor> W. H. </editor> <publisher> Freeman and Company, </publisher> <address> New York, </address> <year> 1982. </year>
Reference-contexts: The operation denoted , applied to a rasterized domain, is exactly the operation that is known in digital signal processing [OW83, OS89], image processing, and computer vision circles <ref> [MH79, Mar82] </ref> as convolution. In digital filter design, for example, a common application of convolution is the Finite Impulse Response filter, whose output is computed by convolving a linear or rectangular region with a sampled input.
Reference: [MDW93] <author> J.M. Manyika and H.F. Durrant-Whyte. </author> <title> A tracking sonar sensor for vehicle guidance. </title> <booktitle> In Proc. of the 1993 IEEE International Conference on Robotics and Automation, </booktitle> <volume> volume 2, </volume> <pages> pages 424-429, </pages> <address> Atlanta, Ga, </address> <year> 1993. </year>
Reference-contexts: Because of the physical and visual unclutteredness of hallway scenes, they are able to use the motion of detected edges to detect the robot's position and motion relative to the walls, corners, and doorways in its environment. <ref> [MDW93] </ref> present a sonar sensor which is capable of tracking environment features. This sensor uses a non-colocated transmitter-receiver pair to track regions of constant depth. They use this sensor as part of a localization algorithm for a moving mobot in an indoor environment.
Reference: [ME85] <author> H. P. Moravec and A. Elfes. </author> <title> High resolution maps from wide angle sonar. </title> <booktitle> In Proceedings of the 1985 IEEE International Conference on Robotics and Automation, </booktitle> <pages> pages 116-121, </pages> <address> St. Louis, MO, </address> <year> 1985. </year>
Reference-contexts: Note that all of our algorithms handle uncertainly in sensor measurements robustly. The Underlying Spatial Representation The map-making technique we chose for this system is a variant of the statistical occupancy grid. Moravec and Elfes introduced this method of map-making in <ref> [Elf87, Mor89, ME85] </ref> as a way of making detailed geometric maps using noisy sensors (sonar rangefinders, in their case). A simple occupancy grid is a bitmap, where ones represent occupied cells and zeroes vacant cells. <p> This sensor uses a non-colocated transmitter-receiver pair to track regions of constant depth. They use this sensor as part of a localization algorithm for a moving mobot in an indoor environment. Moravec and Elfes introduced the statistical occupancy grid method of map-making in <ref> [Elf87, Mor89, ME85] </ref> as a way of making detailed geometric maps using noisy sensors (sonar rangefinders, in their case). A statistical occupancy grid is an array, where the contents of each cell is based on the confidence that the part of the environment corresponding to that cell is occupied.
Reference: [Meg83] <author> N. Megiddo. </author> <title> Applying parallel computation algorithms in the design of serial algorithms. </title> <journal> JACM, </journal> <volume> 30 </volume> <pages> 852-865, </pages> <year> 1983. </year>
Reference-contexts: Corollary 9 follows from theorem 8 using the same arguments used to get from theorem 6 to corollary 7. Finally, we wish to consider the problem of determining the minimum uncertainty, *, such that F P * (M; Z) is nonempty. Megiddo, in <ref> [Meg83] </ref>, provides a mechanism for transforming decision procedures into minimization procedures, for some problems.
Reference: [MH79] <author> D. Marr and E. Hildreth. </author> <title> Theory of edge detection. </title> <note> Artificial Intelligence Laboratory Memo 518, </note> <institution> Massachusetts Institute of Technology Artificial Intelligence Laboratory, </institution> <month> April </month> <year> 1979. </year>
Reference-contexts: The operation denoted , applied to a rasterized domain, is exactly the operation that is known in digital signal processing [OW83, OS89], image processing, and computer vision circles <ref> [MH79, Mar82] </ref> as convolution. In digital filter design, for example, a common application of convolution is the Finite Impulse Response filter, whose output is computed by convolving a linear or rectangular region with a sampled input.
Reference: [Mor89] <author> H. P. Moravec. </author> <title> Sensor fusion in certainty grids for mobile robots. </title> <editor> In A. Casals, editor, </editor> <title> Sensor Devices and Systems for Robotics. </title> <publisher> Springer-Verlag, </publisher> <year> 1989. </year>
Reference-contexts: Note that all of our algorithms handle uncertainly in sensor measurements robustly. The Underlying Spatial Representation The map-making technique we chose for this system is a variant of the statistical occupancy grid. Moravec and Elfes introduced this method of map-making in <ref> [Elf87, Mor89, ME85] </ref> as a way of making detailed geometric maps using noisy sensors (sonar rangefinders, in their case). A simple occupancy grid is a bitmap, where ones represent occupied cells and zeroes vacant cells. <p> This sensor uses a non-colocated transmitter-receiver pair to track regions of constant depth. They use this sensor as part of a localization algorithm for a moving mobot in an indoor environment. Moravec and Elfes introduced the statistical occupancy grid method of map-making in <ref> [Elf87, Mor89, ME85] </ref> as a way of making detailed geometric maps using noisy sensors (sonar rangefinders, in their case). A statistical occupancy grid is an array, where the contents of each cell is based on the confidence that the part of the environment corresponding to that cell is occupied.
Reference: [MR88] <author> Clare D. McGillem and Theodore S. Rappaport. </author> <title> Infra-red location system for navigation of autonomous vehicles. </title> <booktitle> In Proc. of the 1988 IEEE International Conference on Robotics and Automation, </booktitle> <pages> pages 1236-1238, </pages> <address> Philadelphia, PA, </address> <year> 1988. </year>
Reference-contexts: Active beacons are objects in the environment that emit a signal which the robot can sense; passive beacons are natural features in the environment, such as corners, straight line segments, and vertical edges, that the robot has a good chance of identifying. <ref> [MR88] </ref> describes a localization system consisting of a directional infrared detector system and a set of beacons that emit modulated infrared signals. <p> They select their landmarks by hand, choosing objects with strong vertical edges. This work is similar to that of <ref> [MR88] </ref> and [Kle92], except that the landmarks here are extracted from an image.
Reference: [NP82] <author> J. Neivergelt and F. P. Preparata. </author> <title> Plane-sweep algorithms for intersecting geometric figures. </title> <journal> CACM, </journal> <volume> 25(10) </volume> <pages> 739-747, </pages> <year> 1982. </year>
Reference-contexts: Appendix A 1 A more efficient algorithm is given later, in Theorem 8. 16 is a condensed treatment of material found in, among other places, [PS85], <ref> [NP82] </ref>, [Don89], and [Lat92]. <p> The standard arrangement-computing plane-sweep algorithm runs on this collection of polygons (which has a total of 2n edges) in time O ((n + s) log n), as shown by <ref> [NP82] </ref>. We modify the sweep-line data structure so that each segment on the sweep-line knows how many polygons of D (M; z) (color these polygons red) and how many polygons of @(E (M; z)) (color these polygons blue) cover it. <p> Appendix A: The Plane Sweep In this appendix, we review the family of algorithms known as "plane sweeps". The following discussion is a condensed treatment of material found in, among other places, [PS85], <ref> [NP82] </ref>, [Don89], and [Lat92]. Suppose we have a set of n line segments in the plane, and we want to determine all of the intersections between them.
Reference: [OS89] <author> A. V. Oppenheim and R. W. Schafer. </author> <title> Discrete Time Signal Processing. </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, New Jersey, </address> <year> 1989. </year>
Reference-contexts: Since all finite sets of discrete points have finite cardinality, we can compute P Q for any pair of finite rasterized sets, P and Q. The operation denoted , applied to a rasterized domain, is exactly the operation that is known in digital signal processing <ref> [OW83, OS89] </ref>, image processing, and computer vision circles [MH79, Mar82] as convolution. In digital filter design, for example, a common application of convolution is the Finite Impulse Response filter, whose output is computed by convolving a linear or rectangular region with a sampled input.
Reference: [OW83] <author> A. V. Oppenheim and A. S. Willsky. </author> <title> Signals and Systems. </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, New Jersey, </address> <year> 1983. </year>
Reference-contexts: Since all finite sets of discrete points have finite cardinality, we can compute P Q for any pair of finite rasterized sets, P and Q. The operation denoted , applied to a rasterized domain, is exactly the operation that is known in digital signal processing <ref> [OW83, OS89] </ref>, image processing, and computer vision circles [MH79, Mar82] as convolution. In digital filter design, for example, a common application of convolution is the Finite Impulse Response filter, whose output is computed by convolving a linear or rectangular region with a sampled input.
Reference: [PS85] <author> F. P. Preparata and M. Shamos. </author> <title> Computational Geometry: An Introduction. </title> <publisher> Springer-Verlag, </publisher> <year> 1985. </year>
Reference-contexts: Appendix A 1 A more efficient algorithm is given later, in Theorem 8. 16 is a condensed treatment of material found in, among other places, <ref> [PS85] </ref>, [NP82], [Don89], and [Lat92]. <p> Appendix A: The Plane Sweep In this appendix, we review the family of algorithms known as "plane sweeps". The following discussion is a condensed treatment of material found in, among other places, <ref> [PS85] </ref>, [NP82], [Don89], and [Lat92]. Suppose we have a set of n line segments in the plane, and we want to determine all of the intersections between them. <p> The ability to compute multicolored arrangements in this fashion is a key part of the localization algorithms we will describe next. The plane sweep algorithm is a key subpart of many computational geometric algorithms. For other instances of applications using the plane-sweep see, for example, <ref> [PS85, Don89, Lat92] </ref>).
Reference: [RG93] <author> S. Ratering and M. Gini. </author> <title> Robot navigation in a known environment with unknown moving obstacles. </title> <booktitle> In Proc. of the 1993 IEEE International Conference on Robotics and Automation, </booktitle> <volume> volume 1, </volume> <pages> pages 25-30, </pages> <address> Atlanta, Ga, </address> <year> 1993. </year> <month> 43 </month>
Reference: [Ruc93] <author> W.J. Rucklidge. </author> <title> Lower bounds for the complexity of the Hausdorff distance. </title> <booktitle> In Proc. Fifth Canadian Conference on Computational Geometry, </booktitle> <pages> pages 145-150, </pages> <address> Waterloo, On-tario, </address> <month> August </month> <year> 1993. </year>
Reference-contexts: This bound appears to be close to optimal (within O (log k (mn))). <ref> [Ruc93] </ref> Theta-Slice Approximating R 2 fi S 1 Localization Perhaps a more practical method of handling rotational uncertainty in the localization process is to approximate the procedure just outlined by performing translation-only localization at a set of discrete rotations.
Reference: [RWA + 92] <author> Yuval Roth, Annie S. Wu, Remzi H. Arpaci, Terry Weymouth, and Ramesh Jain. </author> <title> Model-driven pose correction. </title> <booktitle> In Proc. of the 1992 IEEE International Conference on Robotics and Automation, </booktitle> <pages> pages 2625-2630, </pages> <address> Nice, France, </address> <year> 1992. </year>
Reference-contexts: Their beacons are such features as "peaks", "pits", "ridges", and "ravines"; these are appropriate to navigation in rough natural terrains. Several attempts have been made to use computer vision to detect and locate beacons ([CC92], [AH91], and <ref> [RWA + 92] </ref>). [CC92] use an Extended Kalman Filter to estimate position from odom-etry, sonar data, and the location of visually detected landmarks. They select their landmarks by hand, choosing objects with strong vertical edges. <p> They detect and locate their visual landmarks using stereo vision techniques. They present results of extensive experimentation in an uncluttered (empty) interior environment, indicating that their system works very reliably in this context. <ref> [RWA + 92] </ref> use images and odometry in a very novel way: They compute controlled hallucinations, which are mockup 3D renderings of their robot's immediate environment, based on an a priori map and a dead-reckoning estimate of pose.
Reference: [SHD86] <author> T.M. Silberberg, D.A. Harwood, and L.S. Davis. </author> <title> Object recognition using oriented model points. Computer Vision, </title> <journal> Graphics and Image Processing, </journal> <volume> 35 </volume> <pages> 47-71, </pages> <year> 1986. </year>
Reference-contexts: They then plot the transformations and look for clusters of similar transforms. This is similar to several matching algorithms based on the Hough Transform. See, for example, <ref> [SHD86] </ref>. Beveridge and Riseman ([BR91]) use a 3D, perspective-based computer vision matching algorithm to track a robot's progress as it navigates in hallways.
Reference: [TL92] <author> H. Takeda and J.C. Latombe. </author> <title> Planning the motions of a mobile robot in a sensory uncertainty field. </title> <type> Stanford CS Technical Report STAN-C-92-1424, </type> <institution> Stanford University, Department of Computer Science, </institution> <month> April </month> <year> 1992. </year> <month> 44 </month>
References-found: 43

