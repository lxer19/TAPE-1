URL: http://vlsicad.cs.ucla.edu/~abk/papers/conference/c58.ps
Refering-URL: http://vlsicad.cs.ucla.edu/~abk/publications.html
Root-URL: http://www.cs.ucla.edu
Email: cheese@cs.ucla.edu and abk@cs.ucla.edu  
Title: SIMPLE EIGENVECTOR-BASED CIRCUIT CLUSTERING CAN BE EFFECTIVE  
Author: Charles J. Alpert Andrew B. Kahng 
Address: Los Angeles, CA 90095-1596 USA  
Affiliation: UCLA Computer Science Department,  
Abstract: Clustering has proven effective in improving the quality of VLSI netlist partitioning and placement algorithms. A wide variety of clustering schemes have been proposed, including random walks [13], iterative matching [7], and fairly complicated spectral techniques [1] [8]. Like [1] and [8], we use eigenvectors to compute a clustering, but do so in the simplest, most obvious manner. Our algorithm first computes a d-digit code for each module v i according to the signs of the i th entries in a set of d eigenvectors. Then, modules with the same code are assigned to the same cluster. Despite its simplicity, this new clustering algorithm is strongly motivated by theoretical results for both spectral bipartitioning [6] and multi-dimensional vector partitioning [4]. The algorithm also has linear time complexity (not including the eigenvector computation) and is at least as effective as previous clustering algorithms in terms of two-phase Fiduccia-Mattheyses bipartitioning. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> C. J. Alpert and A. B. Kahng, </author> <title> "Geometric Embeddings for Faster and Better Multi-Way Netlist Partitioning," </title> <booktitle> Proc. ACM/IEEE Design Automation Conf., </booktitle> <year> 1993, </year> <pages> pp. 743-748. </pages>
Reference-contexts: These algorithms merge connected modules together in a greedy, bottom-up fashion. More complicated approaches are based on random walks [13], clique compression [9], graph traversals [2], simulated annealing [19], k l connectivity [11], and top-down ratio cut [21]. Finally, two spectral approaches <ref> [1] </ref> [8] each form a d-dimensional geometric embedding of modules, using the coordinates defined by (entries of) the first d eigen-vectors. The embedding forms a d-dimensional representation of the original netlist in which each module maps to a point in d-space. <p> The embedding forms a d-dimensional representation of the original netlist in which each module maps to a point in d-space. As discussed in Section 3, the embedding possesses many properties which make it a well-suited geometric representation of the netlist. Given this embedding, Alpert and Kahng <ref> [1] </ref> perform bottom-up clustering based on a min-diameter criterion, while Chan et al. [8] construct a d-way clustering by first selecting a set of d orthogonal "prototype" vectors and then clustering each module to its closest "prototype" according to a directional cosine metric. <p> We have tested the quality of these cluster-ings via two-phase FM; our experiments show that simple eigenvector-based clustering produces bipartitionings with cuts that are at least as good as previous methods <ref> [1] </ref> [2] [19]. Thus, eigenvector-based clustering can be both simple and effective. 2. <p> Hall [14] showed that the optimal solution according to the objective f (~x) = i=1 j=1 2 such that jj~xjj 2 = 1 and P n i=1 x i = 0, is given by ~x = ~ 2 . (The trivial solution ~x = ~ 1 = <ref> [1; 1; : : : ; 1] </ref> cannot be scaled to satisfy both constraints.) If ~x is the indicator vector for the partitioning fP 1 ; P 2 g of the graph represented by A, then f (~x) is exactly the total weight of edges cut by the partitioning solution. <p> These benchmarks are available from the site http://ballade.cs.ucla.edu/~cheese. Our clusterings were constructed using d = 11 (i.e., 10 nontrivial eigenvectors) 4 , and we compare to the clustering algorithms WINDOW [2], ANNEAL [19], and AGG <ref> [1] </ref>. WINDOW first traverses the graph to induce a linear ordering of the modules, then splits the ordering into a clustering via dynamic programming. ANNEAL is the simulated annealing based algorithm used by Timberwolf to perform a "three-phase" cell placement.
Reference: [2] <author> C. J. Alpert and A. B. Kahng, </author> <title> "A General Framework for Vertex Orderings, With Applications to Netlist Clustering," </title> <booktitle> IEEE Intl. Conf. on Computer-Aided Design, </booktitle> <year> 1994, </year> <pages> pp. </pages> <note> 63-67 (extended version to appear in Trans. on VLSI Systems). </note>
Reference-contexts: Simple approaches include iterative matching [7] and agglomerative connectivity-based merging [15]. These algorithms merge connected modules together in a greedy, bottom-up fashion. More complicated approaches are based on random walks [13], clique compression [9], graph traversals <ref> [2] </ref>, simulated annealing [19], k l connectivity [11], and top-down ratio cut [21]. Finally, two spectral approaches [1] [8] each form a d-dimensional geometric embedding of modules, using the coordinates defined by (entries of) the first d eigen-vectors. <p> We have tested the quality of these cluster-ings via two-phase FM; our experiments show that simple eigenvector-based clustering produces bipartitionings with cuts that are at least as good as previous methods [1] <ref> [2] </ref> [19]. Thus, eigenvector-based clustering can be both simple and effective. 2. <p> These benchmarks are available from the site http://ballade.cs.ucla.edu/~cheese. Our clusterings were constructed using d = 11 (i.e., 10 nontrivial eigenvectors) 4 , and we compare to the clustering algorithms WINDOW <ref> [2] </ref>, ANNEAL [19], and AGG [1]. WINDOW first traverses the graph to induce a linear ordering of the modules, then splits the ordering into a clustering via dynamic programming. ANNEAL is the simulated annealing based algorithm used by Timberwolf to perform a "three-phase" cell placement. <p> This scheme has recently been shown to significantly outperform traditional random or last-in-first-out (FIFO) tie-breaking schemes [12], and consequently the two-phase FM results reported for WINDOW, ANNEAL, and AGG are superior to those reported in <ref> [2] </ref>. The lowest number of cut nets observed is reported in Table 1, with the average cut sizes given in parentheses. We also ran FM without clustering, and these results are given in the third column of the Table.
Reference: [3] <author> C. J. Alpert and A. B. Kahng, </author> <title> "Recent Directions in Netlist Partitioning: A Survey," Integration: </title> <journal> the VLSI Journal, </journal> <pages> 19(1-2), </pages> <year> 1995, </year> <pages> pp. 1-81. </pages>
Reference-contexts: Since clustering serves to reduce instance complexity, it has nearly universal application in VLSI CAD areas ranging from timing-driven layout to high-level synthesis. The clustering literature contains many strategies with varying complexities (see <ref> [3] </ref> for a survey). Simple approaches include iterative matching [7] and agglomerative connectivity-based merging [15]. These algorithms merge connected modules together in a greedy, bottom-up fashion.
Reference: [4] <author> C. J. Alpert and S.-Z. Yao, </author> <title> "Spectral Partitioning: The More Eigenvectors, the Better," </title> <booktitle> Proc. ACM/IEEE Design Automation Conf., </booktitle> <year> 1995, </year> <pages> pp. 195-200. </pages>
Reference-contexts: In contrast to complicated geometric clustering techniques, our algorithm is completely obvious and, in addition, has strong theoretical motivation. We show that this algorithm is a natural extension of spectral bipartitioning [6] and also follows the recent result of <ref> [4] </ref> which establishes the equivalence of min-cut graph partitioning and an eigenvector-based vector partitioning formulation. We have tested the quality of these cluster-ings via two-phase FM; our experiments show that simple eigenvector-based clustering produces bipartitionings with cuts that are at least as good as previous methods [1] [2] [19]. <p> Thus, our clustering is optimal with respect to projection magnitudes, and is a natural extension of spectral biparti tioning in that this clustering is as "close" as possible to the first d eigenvectors. 3.2. Relation to Vector Partitioning Recently, Alpert and Yao <ref> [4] </ref> showed that min-cut k-way graph partitioning exactly reduces to the following vec tor partitioning problem: given a set of vectors Y = f~y 1 ; ~y 2 ; : : : ; ~y n g in d-dimensional space, partition the vectors into subsets fS 1 ; S 2 ; :
Reference: [5] <author> S. T. Barnard and H. D. Simon, </author> <title> "A Fast Multilevel Implementation of Recursive Spectral Bisection for Partitioning Unstructured Problems," </title> <booktitle> Proceedings of the Seventh SIAM Conference on Parallel Processing for Scientific Computing, </booktitle> <year> 1993, </year> <pages> pp. 627-632. </pages>
Reference-contexts: In addition, much research is currently devoted to speeding up spectral computations via parallel and multilevel methods. For example, Barnard and Simon <ref> [5] </ref> use a multilevel contraction method to approximate the second eigenvector for a finite element graph with 262,620 nodes and 764,268 edges (in 152 seconds); the subsequent partitioning of this eigenvector led to a lower cut than pure spectral bisection. to the same cluster if they are in the same spectral
Reference: [6] <author> E. R. Barnes, </author> <title> "An Algorithm for Partitioning the Nodes of a Graph," </title> <note> Siam J. Algorithms and Discrete Methods (3)4, </note> <year> 1992, </year> <pages> pp. 541-549. </pages>
Reference-contexts: In contrast to complicated geometric clustering techniques, our algorithm is completely obvious and, in addition, has strong theoretical motivation. We show that this algorithm is a natural extension of spectral bipartitioning <ref> [6] </ref> and also follows the recent result of [4] which establishes the equivalence of min-cut graph partitioning and an eigenvector-based vector partitioning formulation. <p> The well-known spectral bipartition-ing algorithm <ref> [6] </ref> computes the second eigenvector ~ 2 of Q and sets x i to 1 if i2 0 and x i to 0 otherwise (assuming no cluster size constraints).
Reference: [7] <author> T. Bui, C. Heigham, C. Jones, and T. Leighton, </author> <title> "Improving the Performance of the Kernighan-Lin and Simulated Annealing Graph Bisection Algorithms," </title> <booktitle> Proc. ACM/IEEE Design Automation Conf., </booktitle> <year> 1989, </year> <pages> pp. 775-778. </pages>
Reference-contexts: 1. INTRODUCTION Clustering of netlist hypergraphs can effectively reduce the complexity of VLSI CAD problem instances, particularly for system partitioning and layout. For netlist bipartition-ing, the two-phase Fiduccia-Mattheyses (FM) methodology <ref> [7] </ref> [10] has led to several leading results in recent years. In this approach, the netlist is first decomposed into disjoint clusters, i.e., subsets of modules, which induce a contracted netlist. <p> Since clustering serves to reduce instance complexity, it has nearly universal application in VLSI CAD areas ranging from timing-driven layout to high-level synthesis. The clustering literature contains many strategies with varying complexities (see [3] for a survey). Simple approaches include iterative matching <ref> [7] </ref> and agglomerative connectivity-based merging [15]. These algorithms merge connected modules together in a greedy, bottom-up fashion. More complicated approaches are based on random walks [13], clique compression [9], graph traversals [2], simulated annealing [19], k l connectivity [11], and top-down ratio cut [21].
Reference: [8] <author> P. K. Chan, M. D. F. Schlag and J. Zien, </author> <title> "Spectral K-Way Ratio Cut Partitioning and Clustering", </title> <journal> IEEE Trans. on CAD 13(9), </journal> <year> 1994, </year> <pages> pp. 1088-1096. </pages>
Reference-contexts: These algorithms merge connected modules together in a greedy, bottom-up fashion. More complicated approaches are based on random walks [13], clique compression [9], graph traversals [2], simulated annealing [19], k l connectivity [11], and top-down ratio cut [21]. Finally, two spectral approaches [1] <ref> [8] </ref> each form a d-dimensional geometric embedding of modules, using the coordinates defined by (entries of) the first d eigen-vectors. The embedding forms a d-dimensional representation of the original netlist in which each module maps to a point in d-space. <p> As discussed in Section 3, the embedding possesses many properties which make it a well-suited geometric representation of the netlist. Given this embedding, Alpert and Kahng [1] perform bottom-up clustering based on a min-diameter criterion, while Chan et al. <ref> [8] </ref> construct a d-way clustering by first selecting a set of d orthogonal "prototype" vectors and then clustering each module to its closest "prototype" according to a directional cosine metric. <p> Thus, ~ 2 can be viewed as the optimal, although illegal, partitioning solution; the spectral bipartitioning algorithm finds the legal indicator vector ~x closest to ~ 2 . Chan et al. <ref> [8] </ref> have shown that the d best non-discrete solutions to Equation (1) are given by ~ 1 ; ~ 2 ; : : : ; ~ d under the constraint that all solutions are mutually orthogonal.
Reference: [9] <author> J. Cong and M. </author> <title> Smith "A Parallel Bottom-up Clustering Algorithm with Applications to Circuit Partitioning in VLSI Design" Proc. </title> <booktitle> ACM/IEEE Design Automation Conf. </booktitle> <year> 1993, </year> <pages> pp. 755-760. </pages>
Reference-contexts: The clustering literature contains many strategies with varying complexities (see [3] for a survey). Simple approaches include iterative matching [7] and agglomerative connectivity-based merging [15]. These algorithms merge connected modules together in a greedy, bottom-up fashion. More complicated approaches are based on random walks [13], clique compression <ref> [9] </ref>, graph traversals [2], simulated annealing [19], k l connectivity [11], and top-down ratio cut [21]. Finally, two spectral approaches [1] [8] each form a d-dimensional geometric embedding of modules, using the coordinates defined by (entries of) the first d eigen-vectors.
Reference: [10] <author> C.M Fiduccia and R. M. Mattheyses, </author> <title> "A Linear Time Heuristic for Improving Network Partitions", </title> <booktitle> Proc. ACM/IEEE Design Automation Conf., </booktitle> <year> 1982, </year> <pages> pp. 175-181. </pages>
Reference-contexts: 1. INTRODUCTION Clustering of netlist hypergraphs can effectively reduce the complexity of VLSI CAD problem instances, particularly for system partitioning and layout. For netlist bipartition-ing, the two-phase Fiduccia-Mattheyses (FM) methodology [7] <ref> [10] </ref> has led to several leading results in recent years. In this approach, the netlist is first decomposed into disjoint clusters, i.e., subsets of modules, which induce a contracted netlist.
Reference: [11] <author> J. Garbers, H. J. Promel and A. Steger, </author> <title> "Finding Clusters in VLSI Circuits" Proc. </title> <booktitle> IEEE Intl. Conf. on Computer-Aided Design, </booktitle> <year> 1990, </year> <pages> pp. 520-523. </pages>
Reference-contexts: Simple approaches include iterative matching [7] and agglomerative connectivity-based merging [15]. These algorithms merge connected modules together in a greedy, bottom-up fashion. More complicated approaches are based on random walks [13], clique compression [9], graph traversals [2], simulated annealing [19], k l connectivity <ref> [11] </ref>, and top-down ratio cut [21]. Finally, two spectral approaches [1] [8] each form a d-dimensional geometric embedding of modules, using the coordinates defined by (entries of) the first d eigen-vectors.
Reference: [12] <author> L. Hagen, J.-H. Huang, and A. B. Kahng, </author> <title> "On Implementation Choices for Iterative Improvement Partitioning Algorithms", </title> <booktitle> Proc. European Design Automation Conf., </booktitle> <month> September, </month> <year> 1995. </year>
Reference-contexts: Finally, AGG also uses a d-dimensional spectral embedding, but clusters according to the Euclidean distance metric. For each benchmark and each clustering, we ran two-phase FM 100 times with unit areas and exact bisection size constraints on the partitions. Our FM code was obtained from the authors of <ref> [12] </ref> and uses a last-in-first-out (LIFO) tie-breaking scheme in the gain buckets. This scheme has recently been shown to significantly outperform traditional random or last-in-first-out (FIFO) tie-breaking schemes [12], and consequently the two-phase FM results reported for WINDOW, ANNEAL, and AGG are superior to those reported in [2]. <p> Our FM code was obtained from the authors of <ref> [12] </ref> and uses a last-in-first-out (LIFO) tie-breaking scheme in the gain buckets. This scheme has recently been shown to significantly outperform traditional random or last-in-first-out (FIFO) tie-breaking schemes [12], and consequently the two-phase FM results reported for WINDOW, ANNEAL, and AGG are superior to those reported in [2]. The lowest number of cut nets observed is reported in Table 1, with the average cut sizes given in parentheses. <p> Surprisingly, the improvement of two-phase FM results over flat FM is not that impressive, especially for the three largest benchmarks. One possible explanation is that LIFO tie-breaking significantly improves "standard" FM, leaving less room for improvement by clustering; this observation was confirmed in <ref> [12] </ref>. Although SIMPLE two-phase results are not definitively superior, we find the simplicity (even naivete) of the clustering algorithm to be its most attractive quality.
Reference: [13] <author> L. Hagen and A. B. Kahng, </author> <title> "A New Approach to Effective Circuit Clustering", </title> <booktitle> Proc. IEEE Intl. Conf. on Computer-Aided Design, </booktitle> <year> 1992, </year> <pages> pp. 422-427. </pages>
Reference-contexts: The clustering literature contains many strategies with varying complexities (see [3] for a survey). Simple approaches include iterative matching [7] and agglomerative connectivity-based merging [15]. These algorithms merge connected modules together in a greedy, bottom-up fashion. More complicated approaches are based on random walks <ref> [13] </ref>, clique compression [9], graph traversals [2], simulated annealing [19], k l connectivity [11], and top-down ratio cut [21]. Finally, two spectral approaches [1] [8] each form a d-dimensional geometric embedding of modules, using the coordinates defined by (entries of) the first d eigen-vectors.
Reference: [14] <author> K.M. Hall, </author> <title> "An r-dimensional Quadratic Placement Algorithm", </title> <journal> Manag. Sci., </journal> <volume> 17, </volume> <pages> pp. 219-229, </pages> <year> 1970. </year>
Reference-contexts: This choice of ~x maximizes ~x ~ 2 , i.e., ~x is the indicator vector that maximally projects onto ~ 2 . Hall <ref> [14] </ref> showed that the optimal solution according to the objective f (~x) = i=1 j=1 2 such that jj~xjj 2 = 1 and P n i=1 x i = 0, is given by ~x = ~ 2 . (The trivial solution ~x = ~ 1 = [1; 1; : : :
Reference: [15] <author> S. Hauck and G. Borriello, </author> <title> "An Evaluation of Biparti-tioning Techniques", </title> <booktitle> Proc. Chapel Hill Conf. on Adv. Research in VLSI, </booktitle> <year> 1995. </year>
Reference-contexts: Similar "two-phase" strategies can also be applied to cell placement, e.g., Sun and Sechen [19] use a two-level hierarchical clustering strategy (actually a "three-phase" approach) within the simulated-annealing based Timberwolf placement package. Applying clustering to FM is not inherently limited to two phases - Hauck and Borriello <ref> [15] </ref> have experimented with a multilevel technique which continues to run clustering phases as long as user-specified cluster size constraints are satisfied. Since clustering serves to reduce instance complexity, it has nearly universal application in VLSI CAD areas ranging from timing-driven layout to high-level synthesis. <p> Since clustering serves to reduce instance complexity, it has nearly universal application in VLSI CAD areas ranging from timing-driven layout to high-level synthesis. The clustering literature contains many strategies with varying complexities (see [3] for a survey). Simple approaches include iterative matching [7] and agglomerative connectivity-based merging <ref> [15] </ref>. These algorithms merge connected modules together in a greedy, bottom-up fashion. More complicated approaches are based on random walks [13], clique compression [9], graph traversals [2], simulated annealing [19], k l connectivity [11], and top-down ratio cut [21].
Reference: [16] <author> B. Mohar, </author> <title> "The Laplacian Spectrum of Graphs", </title> <editor> in Y. Alavi and et al., editors, </editor> <booktitle> Graph Theory, Combinatorics, and Applications, </booktitle> <year> 1991, </year> <pages> pp. 871-898. </pages>
Reference-contexts: Empirically, we observe a strong correlation between the cutsize of the graph given by A and number of nets cut by H. 2 Using the eigenvectors of Q, rather than of A, offers several advantages <ref> [16] </ref>. For example, the number of eigenvalues of Q equal to zero is also the number of connected components of H.
Reference: [17] <author> B. M. Riess, K. Doll, and F. M. Johannes, </author> <title> "Partitioning Very Large Circuits Using Analytical Placement Techniques", </title> <booktitle> Proc. ACM/IEEE Design Automation Conf., </booktitle> <year> 1994, </year> <pages> pp. 646-651. </pages>
Reference: [18] <author> D. S. Scott, </author> <title> "LASO2 Documentation", </title> <type> technical report, </type> <institution> CS Dept., University of Texas at Austin, </institution> <year> 1980. </year>
Reference-contexts: The theoretical equivalence (or unequivalence) of Q and A has not yet been established. 3 Our experiments show that computing eigenvectors with LASO code <ref> [18] </ref> is relatively efficient. For example, Sparc-1000 (single processor) runtimes were respectively 133 seconds and Clustering Algorithm 1. Compute an adjacency matrix A from H (V; E), e.g., via a clique net model. 2.
Reference: [19] <author> W. Sun and C. Sechen, </author> <title> "Efficient and Effective Placements for Very Large Circuits" Proc. </title> <booktitle> IEEE Intl. Conf. on Computer-Aided Design, </booktitle> <year> 1993, </year> <pages> pp. 170-177. </pages>
Reference-contexts: Similar "two-phase" strategies can also be applied to cell placement, e.g., Sun and Sechen <ref> [19] </ref> use a two-level hierarchical clustering strategy (actually a "three-phase" approach) within the simulated-annealing based Timberwolf placement package. <p> Simple approaches include iterative matching [7] and agglomerative connectivity-based merging [15]. These algorithms merge connected modules together in a greedy, bottom-up fashion. More complicated approaches are based on random walks [13], clique compression [9], graph traversals [2], simulated annealing <ref> [19] </ref>, k l connectivity [11], and top-down ratio cut [21]. Finally, two spectral approaches [1] [8] each form a d-dimensional geometric embedding of modules, using the coordinates defined by (entries of) the first d eigen-vectors. <p> We have tested the quality of these cluster-ings via two-phase FM; our experiments show that simple eigenvector-based clustering produces bipartitionings with cuts that are at least as good as previous methods [1] [2] <ref> [19] </ref>. Thus, eigenvector-based clustering can be both simple and effective. 2. <p> These benchmarks are available from the site http://ballade.cs.ucla.edu/~cheese. Our clusterings were constructed using d = 11 (i.e., 10 nontrivial eigenvectors) 4 , and we compare to the clustering algorithms WINDOW [2], ANNEAL <ref> [19] </ref>, and AGG [1]. WINDOW first traverses the graph to induce a linear ordering of the modules, then splits the ordering into a clustering via dynamic programming. ANNEAL is the simulated annealing based algorithm used by Timberwolf to perform a "three-phase" cell placement.
Reference: [20] <author> R.-S. Tsay and E. S. Kuh, </author> <title> "A Unified Approach to Partitioning and Placement", </title> <journal> IEEE Trans. Circuits and Systems, </journal> <volume> 38(5), </volume> <year> 1991, </year> <pages> pp. 521-533. </pages>
Reference-contexts: We adopt the weight function f (jej) = 6 jej (jej+1) since it is the appropriate weighting scheme for linear placement <ref> [20] </ref>. 1 Let D = (d ij ) be a diagonal matrix with d ii = P n j=1 a ij . The n fi n Lapla-cian matrix of A is given by Q = D A.
Reference: [21] <author> Y.-C. A. Wei and C.-K. Cheng, </author> <title> "An Improved Two-Way Partitioning Algorithm with Stable Performance, </title> <journal> IEEE Trans. Computer-Aided Design, </journal> <volume> 10(12), </volume> <year> 1991, </year> <pages> pp. 1502-1511. </pages>
Reference-contexts: Simple approaches include iterative matching [7] and agglomerative connectivity-based merging [15]. These algorithms merge connected modules together in a greedy, bottom-up fashion. More complicated approaches are based on random walks [13], clique compression [9], graph traversals [2], simulated annealing [19], k l connectivity [11], and top-down ratio cut <ref> [21] </ref>. Finally, two spectral approaches [1] [8] each form a d-dimensional geometric embedding of modules, using the coordinates defined by (entries of) the first d eigen-vectors. The embedding forms a d-dimensional representation of the original netlist in which each module maps to a point in d-space.
References-found: 21

