URL: http://elysium.cs.ucdavis.edu/~nico/seminar/papers/khalidi.ps.gz
Refering-URL: http://elysium.cs.ucdavis.edu/~nico/seminar/samorodin.html
Root-URL: http://www.cs.ucdavis.edu
Email: Email: office@usenix.org  
Title: Solaris MC: A Multi Computer OS  
Phone: 1. Phone: 510 528-8649 2. FAX: 510 548-5738 3.  4.  
Author: Yousef A. Khalidi, Jose M. Bernabeu, Vlada Matena, Ken Shirriff, and Moti Thadani 
Affiliation: Sun Microsystems Laboratories  
Web: WWW URL: http://www.usenix.org  
Date: January 1996  
Note: The following paper was originally published in the Proceedings of the USENIX 1996 Annual Technical Conference San Diego, California,  For more information about USENIX Association contact:  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> T.E. Anderson, D.E. Culler, D.A. Patterson, </author> <title> A Case for NOW (Networks of Workstations), </title> <booktitle> IEEE Micro, </booktitle> <month> February, </month> <year> 1995. </year>
Reference-contexts: As processor speed increases, traditional SMPs will support an even smaller number of CPUs. Powerful, modular, and scalable computing systems can be built using inexpensive computing nodes coupled with highspeed interconnection networks. Such clustered systems can take the form of loosely-coupled systems, built out of workstations <ref> [1] </ref>, massively-parallel systems (e.g. [24]), or perhaps as a collection of small SMPs interconnected through a low-latency high-bandwidth network. The key to using clustered systems is to provide a singlesystem image operating system allowing them to be used as general purpose computers.
Reference: [2] <author> A. Barak and A. Litman, </author> <title> MOS: A Multicomputer Distributed Operating System, </title> <journal> SoftwarePrac-tice & Experience, </journal> <volume> vol. 15(8), </volume> <month> August </month> <year> 1985. </year>
Reference-contexts: One can view Solaris MC as a transition from the centralized Solaris operating system toward a more modular and distributed OS like Spring. Solaris MC uses ideas from earlier distributed operating systems such as Sprite [19], LOCUS [20], OSF/1 AD TNC [26], MOS <ref> [2] </ref>, and Spring. One key difference from other systems is that Solaris MC shows how a commercial operating system can be extended to a cluster while keeping the existing application base. In addition, Solaris MC uses an object-oriented approach to define new kernel components.
Reference: [3] <author> N. Batlivala, et al., </author> <title> Experience with SVR4 over CHORUS, </title> <booktitle> Proceedings of USENIX Workshop on Microkernels & Other Kernel Architectures, </booktitle> <month> April </month> <year> 1992. </year>
Reference: [4] <author> N. J. Boden, D. Cohen, R.E. Felderman, A.E. Kulawik, C.L. Seitz, J.N. Seizovic, W. Su, Myri-net: </author> <title> A Gigabit-per-Second Local Area Network, </title> <booktitle> IEEE Micro, </booktitle> <month> February </month> <year> 1995. </year>
Reference-contexts: The xdoor layer implements a reference counting mechanism for ORB and application structures. Together, the handler and xdoor layers support efficient parameter passing for inter address-space, inter- and intra-node invocations. The transport layer defines the interface that a transport (such as Ethernet or Myrinet <ref> [4] </ref>) has to satisfy to be used by the xdoor layer . <p> The hardware prototype currently consists of sixteen dual-processor SparcStation 10 and 20 machines, partitioned into two or more clusters. The developers workstations act as front-end machines to the Solaris MC cluster. We use a variety of networks as the system interconnect, including 100baseT ethernet and Myrinet <ref> [4] </ref>. 9.
Reference: [5] <author> F. Douglis and J. Ousterhout, </author> <title> Transparent Process Migration: Design Alternatives and the Sprite Implementation, </title> <journal> Software--Practice & Experience, </journal> <volume> vol. 21(8), </volume> <month> August </month> <year> 1991. </year>
Reference-contexts: The policy decisions on load balancing will be built on top of the migration mechanisms; one possibility is to use a migration daemon, as in Sprite <ref> [5] </ref>, that will decide which nodes should receive processes. However, we believe that the main use of process migration will be for planned shutdown of cluster nodes, rather than fine load balancing across the cluster; load balancing will largely be managed by placement of processes at exec time.
Reference: [6] <author> Intel Corporation, </author> <title> Intel Paragon XP/S Supercomputer Spec Sheet, </title> <year> 1992. </year>
Reference: [7] <author> Yousef A. Khalidi and Michael N. Nelson, </author> <title> Extensible File Systems in Spring, </title> <booktitle> Proceedings of the 14th Symposium on Operating Systems Principles (SOSP), </booktitle> <month> December </month> <year> 1993. </year>
Reference-contexts: Solaris MC imports from Spring the idea of using a CORBA compliant object model [18] as the communication mechanism, the Spring virtual memory and file system architecture <ref> [7, 10, 9] </ref>, and the use of C++ as the implementation language. One can view Solaris MC as a transition from the centralized Solaris operating system toward a more modular and distributed OS like Spring. <p> This interface allows PXFS to be implemented without kernel modifications. The PXFS file system provides extensive caching for high performance using the caching approach from Spring <ref> [7] </ref>, and provides zero-copy bulk I/O movement to move large data objects ef ficiently. This section discusses these features of PXFS in more detail. PXFS interposes on file operations at the vnode/ VFS interface and forwards them to the vnode layer where the file resides, as shown in Figure 1. <p> PXFS uses extensive caching on the clients to reduce the number of remote object invocations. attribute caching protocols. The design of PXFS was influenced by the Spring file system and its caching architecture <ref> [7, 17, 16] </ref>. A client cache is implemented through a cached object on the client to manage the cached data and a cacher object on the server to maintain consistency. For data, the client has a memcache object and the server has a mempager object.
Reference: [8] <author> Yousef A. Khalidi and Michael N. Nelson, </author> <title> An Implementation of UNIX on an Object-oriented Operating System, </title> <booktitle> Proceedings of Winter 93 USENIX Conference, </booktitle> <month> January </month> <year> 1993. </year>
Reference: [9] <author> Yousef A. Khalidi and Michael N. Nelson, </author> <title> The Spring Virtual Memory System, </title> <institution> Sun Microsys-tems Laboratories Technical Report SMLI-TR-93-09, </institution> <month> February </month> <year> 1993. </year>
Reference-contexts: Solaris MC imports from Spring the idea of using a CORBA compliant object model [18] as the communication mechanism, the Spring virtual memory and file system architecture <ref> [7, 10, 9] </ref>, and the use of C++ as the implementation language. One can view Solaris MC as a transition from the centralized Solaris operating system toward a more modular and distributed OS like Spring.
Reference: [10] <author> Yousef A. Khalidi and Michael N. Nelson, </author> <title> A Flexible External Paging Interface, </title> <booktitle> Proceedings of the Usenix conference on Microkernels and Other Architectures, </booktitle> <month> September </month> <year> 1993. </year>
Reference-contexts: Solaris MC imports from Spring the idea of using a CORBA compliant object model [18] as the communication mechanism, the Spring virtual memory and file system architecture <ref> [7, 10, 9] </ref>, and the use of C++ as the implementation language. One can view Solaris MC as a transition from the centralized Solaris operating system toward a more modular and distributed OS like Spring.
Reference: [11] <author> Steven R. Kleiman, Vnodes: </author> <title> An Architecture for Multiple File System Types in Sun UNIX, </title> <booktitle> Proceedings of 86 Summer Usenix Conference, </booktitle> <pages> pp. 238-247, </pages> <month> June </month> <year> 1986. </year>
Reference-contexts: The global file system uses coherency protocols to preserve the UNIX file access semantics even if the file is accessed concurrently from multiple nodes. This file system, called the proxy file system (PXFS), is built on top of the existing Solaris file system at the vnode <ref> [11] </ref> interface. This interface allows PXFS to be implemented without kernel modifications. The PXFS file system provides extensive caching for high performance using the caching approach from Spring [7], and provides zero-copy bulk I/O movement to move large data objects ef ficiently.
Reference: [12] <author> N. Kronenberg, H. Levy, and W. Strecker, VAX-clusters: </author> <title> A Closely-Coupled Distributed Systems, </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> vol. 4(2), </volume> <month> May </month> <year> 1986. </year>
Reference: [13] <author> Mark Linton and Douglas Pan, </author> <title> Interface Translation and Implementation Filtering, </title> <booktitle> Proceedings of the USENIX C++ Conference, </booktitle> <year> 1994. </year>
Reference-contexts: The stubs used by the client code, as well as the skeletons used by the server code are generated automatically from the IDL interface def inition by a CORBA IDL to C++ compiler. We currently use a modified version of the Fresco IDL to C++ compiler <ref> [13] </ref>. 6.2 The Run time System The different components of the system communicate using the services of the ORB.
Reference: [14] <author> C. Maeda, B.N. Bershad, </author> <title> Protocol Service Decomposition for High-performance Networking, </title> <booktitle> Proceedings of the 14th Symposium on Operating Systems Principles (SOSP), </booktitle> <month> December </month> <year> 1993. </year>
Reference-contexts: The data may , however, be addressed to an application running on a different node. Solaris MC includes an enhanced implementation of the programmable Mach packet filter <ref> [14, 25] </ref>, which extracts relevant information from each packet and matches it against state information maintained by the host system. Once the destination node within the multi-computer system is discovered, the packet is delivered to that node over the system interconnect.
Reference: [15] <author> James G. Mitchell, et al., </author> <title> An Overview of the Spring System, </title> <booktitle> Proceedings of Compcon Spring 1994, </booktitle> <month> February </month> <year> 1994. </year>
Reference-contexts: Finally, Solaris MC illustrates how C++ can be used for kernel development, coexisting with previous code. Leverages Spring technology Solaris MC illustrates how the distributed techniques developed by Spring OS <ref> [15] </ref> can be migrated into a commercial operating system. Solaris MC imports from Spring the idea of using a CORBA compliant object model [18] as the communication mechanism, the Spring virtual memory and file system architecture [7, 10, 9], and the use of C++ as the implementation language. <p> The memcache vnode is used as the paged vnode for the VOP_MAP operations on the proxy vnode. Memcache searches the local cache for the page. If it is not available, 2. Solaris doors is a new IPC mechanism in Solaris 2.5 that is based on the Spring IPC mechanism <ref> [15] </ref>. memcache requests the page from the associated m e m p a g e r.
Reference: [16] <author> Michael N. Nelson, Graham Hamilton, and Yousef A. Khalidi, </author> <title> A Framework for Caching in an Object-Oriented System, </title> <booktitle> Proceedings of the 3rd International Workshop on Object Orientation in Operating Systems, </booktitle> <month> December </month> <year> 1993. </year>
Reference-contexts: PXFS uses extensive caching on the clients to reduce the number of remote object invocations. attribute caching protocols. The design of PXFS was influenced by the Spring file system and its caching architecture <ref> [7, 17, 16] </ref>. A client cache is implemented through a cached object on the client to manage the cached data and a cacher object on the server to maintain consistency. For data, the client has a memcache object and the server has a mempager object.
Reference: [17] <author> Michael N. Nelson, Yousef A. Khalidi, and Peter W. Madany, </author> <title> Experience Building a File System on a Highly Modular Operating System, </title> <booktitle> Proceedings of the 4th Symposium on Experiences with Distributed and Multiprocessor Systems (SEDMS IV), </booktitle> <month> September </month> <year> 1993. </year>
Reference-contexts: PXFS uses extensive caching on the clients to reduce the number of remote object invocations. attribute caching protocols. The design of PXFS was influenced by the Spring file system and its caching architecture <ref> [7, 17, 16] </ref>. A client cache is implemented through a cached object on the client to manage the cached data and a cacher object on the server to maintain consistency. For data, the client has a memcache object and the server has a mempager object.
Reference: [18] <author> Object Management Group, </author> <title> The Common Object Request Broker: Architecture and Specification, Revision 1.2, </title> <month> December </month> <year> 1993. </year>
Reference-contexts: Leverages Spring technology Solaris MC illustrates how the distributed techniques developed by Spring OS [15] can be migrated into a commercial operating system. Solaris MC imports from Spring the idea of using a CORBA compliant object model <ref> [18] </ref> as the communication mechanism, the Spring virtual memory and file system architecture [7, 10, 9], and the use of C++ as the implementation language. One can view Solaris MC as a transition from the centralized Solaris operating system toward a more modular and distributed OS like Spring. <p> These two requirements led us to decide on the adoption of an object oriented approach to the design of Solaris MC. From the available possibilities we decided to adopt the CORBA ( Common Object Request Broker Architecture) <ref> [18] </ref> object model, as the best suited for our purposes. CORBA is an architecture with mechanisms for objects to make requests and receive responses in a heterogeneous distributed environment, somewhat similar to RPCs. CORBA provides a strong separation between interfaces and implementations.
Reference: [19] <author> J. Ousterhout, A. Cherenson, F. Douglis, M. Nel-son, and B. Welch, </author> <title> The Sprite Network Operating System, </title> <booktitle> IEEE Computer, </booktitle> <month> February </month> <year> 1988. </year>
Reference-contexts: One can view Solaris MC as a transition from the centralized Solaris operating system toward a more modular and distributed OS like Spring. Solaris MC uses ideas from earlier distributed operating systems such as Sprite <ref> [19] </ref>, LOCUS [20], OSF/1 AD TNC [26], MOS [2], and Spring. One key difference from other systems is that Solaris MC shows how a commercial operating system can be extended to a cluster while keeping the existing application base.
Reference: [20] <author> G. Popek and B. Walker, </author> <title> The LOCUS Distributed System Architecture, </title> <publisher> MIT Press, </publisher> <year> 1985. </year>
Reference-contexts: One can view Solaris MC as a transition from the centralized Solaris operating system toward a more modular and distributed OS like Spring. Solaris MC uses ideas from earlier distributed operating systems such as Sprite [19], LOCUS <ref> [20] </ref>, OSF/1 AD TNC [26], MOS [2], and Spring. One key difference from other systems is that Solaris MC shows how a commercial operating system can be extended to a cluster while keeping the existing application base. In addition, Solaris MC uses an object-oriented approach to define new kernel components.
Reference: [21] <author> G. Hamilton, M. L. Powell, and J. G. Mitchell, Subcontract: </author> <title> A exible Base for Distributed Programming, </title> <booktitle> Proceedings of the 14th Symposium on Operating Systems Principles (SOSP), </booktitle> <month> Decem-ber </month> <year> 1993. </year>
Reference-contexts: The handler is responsible for preparing inter domain requests to the object whose reference it handles. A handler is also in charge of performing marshaling of its associated references, as well as of local (to an address space) reference counting. The handler layer implements the subcontract paradigm <ref> [21] </ref>, providing exible means of introducing multiple object manipulation mechanisms, such as zero-copy. In order to perform an invocation on its object, a handler is associated with one or more xdoors. The xdoor layer implements an RPC-like inter process communication mechanism.
Reference: [22] <author> Glenn C. Skinner and Thomas K. Wong, </author> <title> Stacking Vnodes: A Progress Report. </title> <booktitle> Proceedings of the Summer 1993 Usenix Conference, </booktitle> <year> 1993. </year>
Reference: [23] <author> Sun Microsystems, Inc. </author> <title> IDL Programmers Guide, </title> <year> 1992. </year>
Reference-contexts: CORBA also includes reference counting. In order to perform a request on an object, the client code must obtain a reference to that object, allowing the system to keep track of the number of references. Interfaces are defined by using CORBAs Interface Definition Language (IDL) <ref> [23] </ref>. IDL allows the def i-nition of interfaces by specifying the set of operations the interface accepts (similar to C function declarations), as well as the set of exceptions any given operation may raise. Interfaces can be composed using interface inheritance mechanisms, including multiple inheritance.
Reference: [24] <institution> Thinking Machines Corp., </institution> <note> The Connection Machine System: CM-5, </note> <year> 1993. </year>
Reference-contexts: Powerful, modular, and scalable computing systems can be built using inexpensive computing nodes coupled with highspeed interconnection networks. Such clustered systems can take the form of loosely-coupled systems, built out of workstations [1], massively-parallel systems (e.g. <ref> [24] </ref>), or perhaps as a collection of small SMPs interconnected through a low-latency high-bandwidth network. The key to using clustered systems is to provide a singlesystem image operating system allowing them to be used as general purpose computers.
Reference: [25] <author> M. Yuhara, C. Maeda, B.N. Bershad, J.E.B. Moss, </author> <title> Efficient Packet Demultiplexing for Multiple Endpoints and Large Messages, </title> <booktitle> Proceedings of Winter 94 USENIX Conference, </booktitle> <month> January </month> <year> 1994. </year>
Reference-contexts: The data may , however, be addressed to an application running on a different node. Solaris MC includes an enhanced implementation of the programmable Mach packet filter <ref> [14, 25] </ref>, which extracts relevant information from each packet and matches it against state information maintained by the host system. Once the destination node within the multi-computer system is discovered, the packet is delivered to that node over the system interconnect.

References-found: 25

