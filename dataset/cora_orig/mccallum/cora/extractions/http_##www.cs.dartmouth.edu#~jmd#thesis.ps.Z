URL: http://www.cs.dartmouth.edu/~jmd/thesis.ps.Z
Refering-URL: http://www.cs.dartmouth.edu/~jmd/decs/DECSpage.html
Root-URL: http://www.cs.dartmouth.edu
Title: COMPRESSING THE X GRAPHICS PROTOCOL  
Author: John Moffatt Danskin 
Degree: A DISSERTATION PRESENTED TO THE FACULTY  IN CANDIDACY FOR THE DEGREE OF DOCTOR OF PHILOSOPHY RECOMMENDED FOR ACCEPTANCE BY THE DEPARTMENT OF COMPUTER SCIENCE  
Date: January 1995  
Affiliation: OF PRINCETON UNIVERSITY  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Adobe Systems Incorporated, </author> <title> "POSTSCRIPT language reference manual," </title> <publisher> Addison-Wesley Publishing Company, Inc. </publisher> <year> 1985 </year>
Reference: [2] <author> Andrews, Edmund L., "A. T. & T. </author> <title> sees the future in games," The New York Times, Business Day, pages D1 and D5, </title> <month> July 29, </month> <year> 1993 </year>
Reference-contexts: A few years ago, it might have been considered frivolous to include game traces in a suite like this, but very large companies are now seriously investigating the possibility of charging people to play games over the telephone and cable networks <ref> [2] </ref>. Probably X will not be the major graphics protocol for graphics games, but X traces may still provide a useful characterization of the traffic. Xtetris animates a simple arrangement of falling rectangles while listening for keyboard and mouse button events.
Reference: [3] <author> Arden, Michelle J., James Gosling, and David S. H. Rosenthal, </author> <title> "The NeWS book : an introduction to the Networked extensible Window System," </title> <publisher> Springer Verlag, </publisher> <year> 1989. </year>
Reference: [4] <author> Baker, Mary G., John H. Hartman, Michael D. Kupfer, Ken W. Shirriff, and John L. Osterhout, </author> <title> "Measurements of a distributed file system," </title> <booktitle> Proceedings of the Thirteenth ACM Symposium on Operation System Principles, </booktitle> <month> October </month> <year> 1991, </year> <pages> pp 198-212 </pages>
Reference-contexts: Passive logging was therefore not a viable alternative for us. An approach which would have helped control the size of the traces and the impact of the instrumentation was taken by Ousterhout et al [33] and Baker et al <ref> [4] </ref> who gathered abstracted traces of the UNIX filesystem by recording just open, close, and file pointer repositioning operations, omitting reads and writes. Abstracting their traces allowed much longer traces and reduced the impact of instrumentation tremendously.
Reference: [5] <author> Bell, Timothy C., John G. Cleary, and Ian H. Witten, </author> <title> "Text Compression," </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1990 </year>
Reference-contexts: Table 6 shows pseudo code for encoding. Decoding is analogous to encoding. This section should have given you the flavor of the arithmetic coding process. For a full description of how to encode and decode, see <ref> [5] </ref>. 4.1.2 Predictive Models To the extent that the model's probability estimates are accurate and fully express all available knowledge, this arithmetic coding procedure is optimal. <p> The values used to index a predictive model could be any values known to both the encoder and the decoder at the current point in the input. The type of context based model illustrated in Table 7 compresses English text most effectively at 3rd or 4th order <ref> [5] </ref>. A complete 4th order model would incorporate 2 40 frequencies, so successful implementations make provisions for blending estimates from lower order models with estimates from higher order models when higher order 4.2. PRECONDITIONING DATA FOR COMPRESSION 69 statistics are incomplete. <p> We have to try to use some other knowledge about the input to assign a reasonable probability to unseen symbols. For a discussion of the zero-frequency problem, see <ref> [5] </ref>. One reasonable approach might be to assign unit frequency to each unseen symbol, increasing this frequency as the symbols occur. <p> The literature suggests that the technique used by SDC is noticeably better than maintaining the escape symbol at a minimum, and insignificantly worse than incrementing by 1 2 instead of by 1 <ref> [5] </ref>. In practice, results will depend completely on the input. <p> The results of applying exclusions in this case are shown in Table 10 The first technique (no exclusions) is known as "lazy exclusions." Typically, exclusions give an improvement of about 5%, in compression when compared to lazy exclusions, while doubling the computational cost <ref> [5] </ref>. SDC implements blended contexts using the lazy exclusion method, accepting slightly poorer compression performance for greatly reduced computational overhead. 4.3.4 Update Policy Whenever a symbol (including the escape symbol) is encoded or decoded using a given model, its frequency in that model is incremented. <p> Before a symbol (in this case, "escape" or 'd') is sent, the impossible symbols are temporarily deleted from the sub-model in question, increasing the probabilities of the remaining symbols. In practice, exclusions yield an improvement of about 5% in compression for twice the computational cost <ref> [5] </ref>. SDC does not implement exclusions for performance reasons. 4.3. <p> In this way, higher order models can be found in O (o log n) time, where o is the order of the model. These trees of models are called forward trees. Bell, Cleary and Witten <ref> [5] </ref> improve on this scheme with an extra pointer per node (called a vine pointer), pointing to a context with one fewer character, so that in case there was no pointer to a third model 'LZ7' at the record for '7' in the model 'LZ', a pointer to the model for <p> HBX uses one of the best text compression algorithms available: Moffatt's PPMC' <ref> [30, 5] </ref>. PPMC' uses a hierarchical predictive model which uses the escape technique to blend probabilities from models of orders three through zero. The contexts indexing the predictive models are the previous three, two, one and zero characters, respectively. See Section 4.3.3 for an example of 5.2.
Reference: [6] <author> Blaze, Matt, </author> <title> "NFS Tracing by Passive Network Monitoring," </title> <booktitle> Proceedings of the 1992 USENIX Winter Technical Conference. </booktitle>
Reference-contexts: As long as the data could be logged locally (as opposed to sending it over the network), tracing would have no practical effect on the measured stream. Blaze <ref> [6] </ref> implemented an eavesdropping system like this for NFS, which uses the UDP datagram protocol [41] for transport. I chose not to implement a passive system because I had a requirement of zero packet loss: X is a byte-stream protocol.
Reference: [7] <author> Card, Stuart K, Thomas P Moran, and Allen Newell, </author> <title> "The psychology of human-computer interaction," </title> <address> Hillsdale, N.J., </address> <publisher> L. Erlbaum Associates, </publisher> <year> 1983 </year>
Reference-contexts: An effective compression process cannot waste bits shifting gears between compression techniques. 2. Graphics protocols support interactive applications. Humans can detect, and are affected by feedback delays exceeding 100ms <ref> [7] </ref>. Delays can arise either from the compression architecture, or from insufficient network bandwidth. For instance, MPEG video compression is not suitable for interactive applications because of the intense computation required for high quality transmission. 3. <p> For instance, handwriting performance falls off dramatically with visual feedback delays of 150ms [24]. If the instrumentation adds a latency which is a large fraction of 100ms, then many interactive operations (such as keystroke echo) which previously appeared instantaneous will take a noticeable amount of time <ref> [7] </ref>. This would distract the user, affecting typing performance and the content of the trace. The effect of excessive latency would be even more severe for users using drawing programs where mouse tracking has to appear instantaneous.
Reference: [8] <author> Cameron, R.D., </author> <title> "Source encoding using syntactic information source models," </title> <journal> IEEE Transactions on Information Theory. </journal> <pages> (34)4 pp 843-850, </pages> <note> July 1988 129 130 BIBLIOGRAPHY </note>
Reference-contexts: Even now there are laptop computers with faster CPUs than the one I used for development. The main contribution of HBX has been the introduction of a conceptual framework for compressing structured data. Some work of a similar flavor has been done on compressing Pascal programs <ref> [8, 25] </ref>, but the leap from the special case of Pascal to the general case of structured data was not made at that time. 6.3 Future Work The SDC technique should be applicable to a wide variety of compression and network bandwidth problems, for instance RPC across slow networks.
Reference: [9] <author> Cleary, J. and I. Witten, </author> <title> "Data compression using adaptive coding and partial string matching," </title> <journal> IEEE Trans. Communications, COM-32, </journal> <volume> No 4., </volume> <month> 396-402 </month> <year> (1984) </year>
Reference-contexts: This process serves to keep memory use constant, rather than proportional to the size of the input. 4.3.6 Data Structures Some arithmetic coders, optimized for small alphabets <ref> [9] </ref>, maintain symbols and frequencies in 4 linear arrays. The first array maps from symbol indices to indices in a frequency table (the second array). The second array maintains the frequencies corresponding to the symbols in non-ascending order. <p> Moffatt used a data structure for word-based text compression which was based on balanced binary trees [31], after the (not necessarily balanced) binary trees used by Cleary and Witten <ref> [9] </ref> to implement higher order character-based text compression. Storing each model in a balanced tree structure allows IntervalOf (Symbol), SymbolOf (num), and Update (Symbol) to complete in O (log n) time, while using space proportional to the number of symbols actually instantiated in the model.
Reference: [10] <author> Cormen, Thomas H., Charles E. Leiserson, and Ronald L. Rivest. </author> <title> "Introduction to algorithms," </title> <publisher> The MIT Press, Cambidge MA and McGraw-Hill Book Company, </publisher> <address> New York, </address> <year> 1990 </year>
Reference: [11] <author> Cornelius, David, "XRemote: </author> <title> a serial line protocol for X" 6th Annual X Technical Conference, </title> <address> Boston, MA, </address> <year> 1992 </year>
Reference-contexts: In Chapter 3, I introduce the reader to the Xremote compression protocol. Xre-mote <ref> [11] </ref> is a transformation of the X protocol designed (by Network Computing Devices, Inc.) as a way to efficiently implement X connections over serial lines. This protocol is widely used to support X sessions across telephone lines for home use. The anecdotal evidence is that user satisfaction is low. <p> Chapter 3 Performance of Xremote Whenever network bandwidth is a limiting factor, there is an opportunity for compression (assuming redundancy in the bitstream). This is the case for X connections using normal telephone service, ISDN, and even sometimes Ethernet. Xremote <ref> [11] </ref> is a transformation of the X protocol designed (by NCD) to efficiently implement X connections over serial lines. Right now, Xremote seems to be the most commonly used such system. There is a follow-on to Xremote called LBX [16], but it is still in the design stage.
Reference: [12] <author> Danskin, John and Pat Hanrahan, </author> <title> "Profiling the X Protocol,"1994 SigMetrics conference on measurement and modeling of computer systems. </title> <note> Full paper in Technical Report CS-TR-442-94, </note> <institution> Department of Computer Science, Princeton University, Princeton, NJ, </institution> <month> January </month> <year> 1994. </year>
Reference: [13] <author> Danskin, John and Pat Hanrahan, </author> <title> "Compression Performance of the Xremote Protocol," 1994 Data Compression Conference. </title> <note> Full paper in Technical Report CS-TR-441-94, </note> <institution> Department of Computer Science, Princeton University, Prince-ton, NJ, </institution> <month> January </month> <year> 1994. </year>
Reference: [14] <author> Droms Ralph and Wayne R. Dyksen, </author> <title> "Performance measurements of the X window system communication protocol," </title> <journal> Software Practice and Experience vol. </journal> <volume> 20, no. S2, </volume> <month> May </month> <year> 1991. </year>
Reference-contexts: The subjects were warned that their sessions were not strictly private, but that I would do my best to keep their contents secure. The tracing technique which I adopted was derived from work by Droms and Dyksen <ref> [14] </ref>. They realized that if X clients and the X server converse using Berkeley sockets and TCP/IP, it would be easy to interpose a program between client and server which forwarded traffic in both directions while keeping a complete log. <p> Train information allows us to make some inferences as to good and bad system decisions. We know that the client issues at least one system call per train, and we can estimate TCP/IP [40, 39] header overhead from the train size as was done in <ref> [14] </ref>. In three out of the four traces shown, most trains are less than 100 bytes long, implying that most TCP packets will also be under 100 bytes. The TCP/IP protocol will add 48 bytes of header information to each packet, implying an overhead of at least 50%.
Reference: [15] <author> Foley, J. D., and A. Van Dam, </author> <title> "Fundamentals of Interactive Computer Graphics," </title> <publisher> Addison Wesley, </publisher> <year> 1982, </year> <title> p 180 </title>
Reference-contexts: What kind of geometry? 2D or 3D? Floating point or integer? For the purposes of this thesis, I am only interested in 2D integer geometry, because that is what X does. The Tektronix 4006-1 vector graphics terminal (see <ref> [15] </ref>) had a 10 bit coordinate space. Commands were specified in 7 bits each. Specification of a full 20 bit XY pair required 4 commands, with 2 bits of each command specifying which part of 1.3.
Reference: [16] <author> Fulton Jim, and Chris Kent Kantarjiev, </author> <title> "An update on low bandwidth X (LBX)," </title> <booktitle> Proceedings of the 7th Annual X Technical Conference, </booktitle> <month> January </month> <year> 1993, </year> <institution> O'Reilly and Associates. </institution>
Reference-contexts: Xremote [11] is a transformation of the X protocol designed (by NCD) to efficiently implement X connections over serial lines. Right now, Xremote seems to be the most commonly used such system. There is a follow-on to Xremote called LBX <ref> [16] </ref>, but it is still in the design stage. In this chapter, we will study the performance of the Xremote protocol with the aim of finding opportunities for further compression. I implemented and instrumented the compression portion of the Xremote protocol. <p> Unfortunately, by treating the X protocol almost as an unstructured byte-stream, Xremote just scratches the surface of what is possible in graphics protocol compression. Will LBX <ref> [16] </ref>, the logical successor of Xremote, fix Xremote's problems? LBX promises to fill in some gaping holes by skipping over padding in the protocol, and caching server responses to standard queries. Image performance may be improved, as the status update promises special image compression code.
Reference: [17] <author> Gettys, James, Philip L. Karlton, and Scott Mcgregor, </author> <title> "The X Window System, </title> <note> Version 11," Software Practice and Experience vol. 20(S2), S2/35-S2/67, October 1991 BIBLIOGRAPHY 131 </note>
Reference-contexts: Communication in X is asynchronous; that is, the client is not suspended while waiting for notification of request completion. The designers of the X protocol went to great lengths to remove unnecessary round trip delays for performance reasons <ref> [17] </ref>. Even with commands that do require replies, it is possible to send several requests, and then receive several replies, with only one round trip delay.
Reference: [18] <author> Griswold, Ralph E., and Madge T. Griswold, </author> <title> "The icon programming language," </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs NJ, </address> <year> 1990 </year>
Reference: [19] <author> Guazzo, M., </author> <title> "A general minimum redundancy source coding algorithm," </title> <journal> IEEE Trans. Information Theory, </journal> <volume> IT-26 (1), </volume> <pages> 15-25, </pages> <month> January </month> <year> 1980. </year>
Reference-contexts: How to achieve this lower bound was not at all obvious. In fact, it was 29 years before an efficient technique was discovered <ref> [46, 19, 42] </ref>. set of symbols S i with probabilities p i summing to 1, the symbols occupy disjoint intervals covering [0 1).
Reference: [20] <author> Held, Gilbert. </author> <title> "The Complete Modem Reference," </title> <publisher> John Wiley & Sons, Inc. </publisher> <year> 1991 </year>
Reference: [21] <author> Hennessy, John L., and David A. Patterson, </author> <title> "Computer architecture: a quantitative approach," </title> <publisher> Morgan Kaufmann Publishers, Inc., </publisher> <address> San Mateo California, </address> <year> 1990 </year>
Reference: [22] <author> Jacobson, V., </author> <title> "Compressing TCP/IP headers for low-speed serial links," </title> <booktitle> SRI International, </booktitle> <address> Menlo Park, CA, </address> <month> Feb. </month> <year> 1990., </year> <month> RFC-1144 </month>
Reference-contexts: The TCP/IP protocol will add 48 bytes of header information to each packet, implying an overhead of at least 50%. Although this might be tolerable for a fast network, it is a disaster for a slow one. CSLIP/PPP (Compressed Serial line IP <ref> [22] </ref> layered on the Point to Point Protocol [50]) would be a very efficient network protocol for an X session traversing a slow point to point connection since it only adds about 7 bytes of header information to each packet. <p> In an important application, it might be worthwhile for a programmer to map predictive models or transformations onto selected arguments or types of arguments by hand, as was done with Xremote. The CSLIP (compressed serial line IP) protocol <ref> [22] </ref>, was generated by experimentally determining which IP fields change often, and which IP fields change only occasionally. Applying the adaptive statistical techniques used in HBX to the IP protocol should result in a considerably leaner protocol than the static CSLIP scheme. 6.3.
Reference: [23] <author> Inglis, Stuart, and Ian H. Witten, </author> <title> "Compression-based template matching," </title> <booktitle> Proceedings 1994 Data Compression Conference, </booktitle> <address> March 29-31 Snowbird Utah pp 106-115. </address>
Reference-contexts: Figure 22 shows the pattern of pixels used to index the predictive model for the next bit in the input image. This 6 bit pattern (similar patterns appear throughout the literature: see for example <ref> [23] </ref>), picks up both horizontal and vertical patterns in the input image, providing a kind of cheap 2D compression. I experimented with larger and smaller patterns, but this one seemed to give the best compression on my trace suite. <p> This is a much harder problem than the one I have addressed here because of the noise and registration issues associated with scanning. A recent system, which achieved 37.8:1 lossless compression on a library catalog scanned at 400dpi was described in <ref> [23] </ref>. (The high compression ratio is because of all of the white space in a scanned document. HBX's compression ratio is lower because its input has denser content.) Another example of an application where it is easy to establish an upper bound for compression is simple text transfer.
Reference: [24] <author> H. Kalmus, D. B. Fry and P. </author> <title> Denes, "Effects of Delayed Visual Control on Writing, Drawing and Tracing," Language Speech, </title> <booktitle> 1960, v3, </booktitle> <pages> pp 96-108 </pages>
Reference-contexts: If the tracing system slows down the system too much, the user will act differently. Visual feedback delays can adversely affect hand to eye coordination just as audio feedback delays can make it difficult to talk. For instance, handwriting performance falls off dramatically with visual feedback delays of 150ms <ref> [24] </ref>. If the instrumentation adds a latency which is a large fraction of 100ms, then many interactive operations (such as keystroke echo) which previously appeared instantaneous will take a noticeable amount of time [7]. This would distract the user, affecting typing performance and the content of the trace.
Reference: [25] <author> Katajainen, J., M., Penttonen, and J., Teuhola, </author> <title> "Syntax-directed compression of program files," </title> <journal> Software-Practice and Experience, </journal> <volume> 16(3), </volume> <pages> 269-276 </pages>
Reference-contexts: Even now there are laptop computers with faster CPUs than the one I used for development. The main contribution of HBX has been the introduction of a conceptual framework for compressing structured data. Some work of a similar flavor has been done on compressing Pascal programs <ref> [8, 25] </ref>, but the leap from the special case of Pascal to the general case of structured data was not made at that time. 6.3 Future Work The SDC technique should be applicable to a wide variety of compression and network bandwidth problems, for instance RPC across slow networks.
Reference: [26] <author> Manasse, Mark, </author> <type> personal communication, </type> <month> Jan 93. </month>
Reference-contexts: Since these offsets were often small, Tektronix designed the terminal so that the 5 most significant bits defaulted to zero if their commands were skipped. This feature provided compression approaching 2:1 very inexpensively. Mark Manasse at DEC SRC developed a low bandwidth 2D graphics protocol called SL <ref> [26] </ref>.
Reference: [27] <author> Massalin, Henry, </author> <title> "Superoptimizer | a look at the smallest program," </title> <booktitle> Second International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pp 122-126, </pages> <year> 1987 </year>
Reference-contexts: This process is repeated until the expected performance improvement resulting from another profile and re-code cycle is not worth the cost of the cycle. (It is extremely rare to find a sequence of more than a few computer instructions that cannot be improved on. See <ref> [27] </ref>.) As a relatively new program compressing a complex and important protocol, HBX's compression performance will probably continue to improve for some years. The possibility of optimization afforded by SDC is a marked improvement over monolithic single model compression algorithms which have a fixed level of performance.
Reference: [28] <author> McConnell, Kenneth R., Dennis Bodson, and Richard Schaphorst, "FAX: </author> <title> digital facsimile technology and applications," Second Edition, </title> <publisher> Artech House, </publisher> <address> Boston, </address> <year> 1992 </year>
Reference-contexts: Probably most of the work that has been done on bi-level image compression has been for FAX machines which send facsimiles of documents across normal phone lines. 16 CHAPTER 1. INTRODUCTION Essentially all modern FAX machines use an International Telegraph and Telephone Consultative Committee (CCITT) group 3 FAX protocol <ref> [28] </ref>. This protocol presently supports two compression options. * The first group 3 FAX compression technique is one dimensional, running across scanlines. Each scanline is broken into runs of black or white pixels. <p> Afterwards, the locations of beginnings and endings of runs are tracked from one scanline to the next, with short codes for small displacements. There are special codes to deal with new runs, disappearing runs, and runs that move too far. For more detail, see [32] or <ref> [28] </ref>. This scheme achieves an average of about 12.9:1 compression, with a high compression ratio of 32.4:1 for the nearly all white document 2, and a low compression ratio of 6.5:1 for the densely formatted document 4.
Reference: [29] <author> Moffatt, Alistair, </author> <title> "Linear time adaptive arithmetic coding," </title> <journal> Trans. Information Theory, </journal> <volume> Vol 36, No. </volume> <pages> 2, </pages> <address> March 1990 132 BIBLIOGRAPHY </address>
Reference-contexts: Moffatt developed an implicit tree structure for the frequency array which trivially supports O (log n) updates, and which is, in fact, linear because a heap-like move to top policy for popular symbols allows update time to be bounded by a constant <ref> [29] </ref>. Unfortunately, this structure, as described, like the previous array based structures, presupposes a maximum alphabet size, and is thus not practical for large alphabets, or for high order contexts where many models containing just a few symbols may exist.
Reference: [30] <author> Moffatt, A., </author> <title> "A note on the PPM data compression algorithm," </title> <type> Research Report 88/7, </type> <institution> Department of Computer Science, University of Melbourne, </institution> <address> Parkville, Victoria, Australia. </address>
Reference-contexts: HBX uses one of the best text compression algorithms available: Moffatt's PPMC' <ref> [30, 5] </ref>. PPMC' uses a hierarchical predictive model which uses the escape technique to blend probabilities from models of orders three through zero. The contexts indexing the predictive models are the previous three, two, one and zero characters, respectively. See Section 4.3.3 for an example of 5.2.
Reference: [31] <author> Moffatt, Alistair, </author> <title> "Word-based text compression," </title> <journal> Software-Practice and Experience, </journal> <volume> Vol. </volume> <month> 19(2) 185-198 February </month> <year> 1989 </year>
Reference-contexts: Moffatt used a data structure for word-based text compression which was based on balanced binary trees <ref> [31] </ref>, after the (not necessarily balanced) binary trees used by Cleary and Witten [9] to implement higher order character-based text compression.
Reference: [32] <author> Netravali, Arun, N. and Barry G. </author> <title> Haskell "Digital pictures, representation and compression," </title> <publisher> Plenum Press, </publisher> <address> New York, </address> <year> 1988 </year>
Reference-contexts: The lengths of the runs are coded using a static Huffman table, mapping common run lengths onto short codes and rare run lengths onto long codes. This scheme achieves an average of about 8:1 compression across the 8 CCITT test documents <ref> [32] </ref>, with a compression ratio as high as 16.7:1 for a nearly all white document (document 2), and as low as 4.9:1 for a document densely covered with text (document 4). * The second group 3 FAX compression technique is two dimensional, running between scanlines. <p> Afterwards, the locations of beginnings and endings of runs are tracked from one scanline to the next, with short codes for small displacements. There are special codes to deal with new runs, disappearing runs, and runs that move too far. For more detail, see <ref> [32] </ref> or [28]. This scheme achieves an average of about 12.9:1 compression, with a high compression ratio of 32.4:1 for the nearly all white document 2, and a low compression ratio of 6.5:1 for the densely formatted document 4.
Reference: [33] <author> Ousterhout, John K., Herve Da Costa, David Harrison, John A. Kunze, Mike Kupfer, and James G. </author> <title> Thompson "A trace-driven analysis of the UNIX 4.2 BSD file system," </title> <booktitle> Proceedings of the Tenth ACM Symposium on Operating Systems Principles December 1985, </booktitle> <pages> pp 15-24 </pages>
Reference-contexts: Passive logging was therefore not a viable alternative for us. An approach which would have helped control the size of the traces and the impact of the instrumentation was taken by Ousterhout et al <ref> [33] </ref> and Baker et al [4] who gathered abstracted traces of the UNIX filesystem by recording just open, close, and file pointer repositioning operations, omitting reads and writes. Abstracting their traces allowed much longer traces and reduced the impact of instrumentation tremendously.
Reference: [34] <author> Papadakis, Thomas, </author> <title> "Skip lists and probabilistic ananalysis of algorithms," </title> <type> PhD. </type> <institution> Thesis in Computer Science, University of Waterloo, </institution> <address> Ontario Canada, </address> <year> 1993 </year>
Reference-contexts: Furthermore, SDC deletes infrequently used models, which makes it inconvenient to maintain pointers between models. SDC maps from contexts to models using a balanced tree (a deterministic skip list <ref> [34] </ref>, a variant of the red-black tree).
Reference: [35] <author> Patterson, David, A., and John L. Hennessy, </author> <title> "Computer organization & design: </title> <publisher> The hardware/software interface" Morgan Kaufmann Publishers, </publisher> <address> San Mateo Cal-ifornia, </address> <year> 1994. </year>
Reference-contexts: Averaged across the trace suite, the tradeoff point on the test machine is reached when n 44Kbps. However, this point increases linearly with CPU performance, and CPU performance is increasing by 54% per year <ref> [35] </ref>. Figure 29 illustrates this point by plotting the HBX-Xremote crossover point as a function of expected CPU performance for the next few years. Given readily available 14.4Kbps modems, and a 74.7 SPECint CPU, HBX outperforms Xremote (and thus LZ78 based compression) across every trace. <p> Given readily available 14.4Kbps modems, and a 74.7 SPECint CPU, HBX outperforms Xremote (and thus LZ78 based compression) across every trace. The breakeven point between HBX and Xremote is almost 100Kbps for document previewing. Using 5.5. RESOURCE REQUIREMENTS 105 according to the 54% increase per year of <ref> [35] </ref>. The machine used as the basis point for this extrapolation was the DEC 3000 AXP 400 with a SPECint92 rating of 74.7. The Y axis indicates available network bandwidth in bits per second.
Reference: [36] <author> Peterson, James L., "XSCOPE: </author> <title> A debugging and performance tool for X11" Information Processing 89: </title> <booktitle> Proceedings of the IFIP 89 Congress, </booktitle> <month> August </month> <year> 1989, </year> <pages> pp 49-54 </pages>
Reference-contexts: Complete data integrity is guaranteed at the price of a little performance. Droms and Dyksen used their traces to characterize the load on an Ethernet due to an X session. Another program which uses the interposition technique for snooping on X traffic is xscope by Peterson <ref> [36] </ref>. I used Peterson's table lookup technique for matching X queries with X replies. 2.4 Gathering Data On UNIX systems X clients determine the address and method for connecting to the X server from an environment variable.
Reference: [37] <author> Pike R. </author> <title> "The blit: a multiplexed graphics terminal," </title> <journal> AT&T Bell Laboratories Technical Journal, </journal> <volume> Vol. 63, No. 8, </volume> <pages> pp 1607-1631, </pages> <month> October </month> <year> 1984 </year>
Reference: [38] <author> Pike R. </author> <type> Personal communication, </type> <month> Fri Jul 22 01:51:31 </month> <year> 1994. </year>
Reference: [39] <author> Postel J. Ed., </author> <title> "Internet Protocol Specification," </title> <booktitle> SRI International, </booktitle> <address> Menlo Park, CA, </address> <month> Sept. </month> <year> 1981. </year> <month> RFC-791 </month>
Reference-contexts: Train information allows us to make some inferences as to good and bad system decisions. We know that the client issues at least one system call per train, and we can estimate TCP/IP <ref> [40, 39] </ref> header overhead from the train size as was done in [14]. In three out of the four traces shown, most trains are less than 100 bytes long, implying that most TCP packets will also be under 100 bytes.
Reference: [40] <author> Postel J. Ed., </author> <title> "Transmission Control Protocol Specification," </title> <booktitle> SRI International, </booktitle> <address> Menlo Park, CA, </address> <month> Sept. </month> <year> 1981. </year> <note> RFC-793 BIBLIOGRAPHY 133 </note>
Reference-contexts: Train information allows us to make some inferences as to good and bad system decisions. We know that the client issues at least one system call per train, and we can estimate TCP/IP <ref> [40, 39] </ref> header overhead from the train size as was done in [14]. In three out of the four traces shown, most trains are less than 100 bytes long, implying that most TCP packets will also be under 100 bytes.
Reference: [41] <author> Postel J., </author> <title> "User Datagram Protocol," </title> <booktitle> SRI International, </booktitle> <address> Menlo Park, CA, </address> <month> Aug. </month> <year> 1980. </year> <month> RFC-768 </month>
Reference-contexts: As long as the data could be logged locally (as opposed to sending it over the network), tracing would have no practical effect on the measured stream. Blaze [6] implemented an eavesdropping system like this for NFS, which uses the UDP datagram protocol <ref> [41] </ref> for transport. I chose not to implement a passive system because I had a requirement of zero packet loss: X is a byte-stream protocol. Losing a single packet could cause us to lose track of X message boundaries.
Reference: [42] <author> Rissanen, J. J., and G. G. Langdon, </author> <title> "Arithmetic coding," </title> <journal> IBM J. Research and Development, </journal> <volume> 23(2), </volume> <pages> 149-162, </pages> <month> March </month> <year> 1979. </year>
Reference-contexts: How to achieve this lower bound was not at all obvious. In fact, it was 29 years before an efficient technique was discovered <ref> [46, 19, 42] </ref>. set of symbols S i with probabilities p i summing to 1, the symbols occupy disjoint intervals covering [0 1).
Reference: [43] <author> Romkey, J., </author> <title> "A Nonstandard for Transmission of IP Datagrams Over Serial Lines," </title> <booktitle> SRI International, </booktitle> <address> Menlo Park, CA, </address> <month> June </month> <year> 1988, </year> <month> RFC-1055 </month>
Reference: [44] <author> Rost, Randi J., Jeffrey D. Friedberg, and Peter L. </author> <title> Nishimoto "PEX: a network-transparent 3D graphics system," </title> <journal> IEEE Computer Graphics and Applications, v9, </journal> <volume> n4, </volume> <month> July </month> <year> 1989, </year> <pages> pp 14-26 </pages>
Reference: [45] <author> Rubin, Paul and Jay Fenlason, </author> <title> "Gawk pattern scanning and processing language," man page for gawk, Free Software Foundation, </title> <note> 1993, ftp from prep.ai.mit.edu </note>
Reference: [46] <author> Rubin, F., </author> <title> "Arithmetic stream coding using fixed precision registers," </title> <journal> IEEE Trans. Information Theory, </journal> <volume> IT-25 (6), </volume> <pages> 672-675, </pages> <month> November </month> <year> 1979. </year>
Reference-contexts: How to achieve this lower bound was not at all obvious. In fact, it was 29 years before an efficient technique was discovered <ref> [46, 19, 42] </ref>. set of symbols S i with probabilities p i summing to 1, the symbols occupy disjoint intervals covering [0 1).
Reference: [47] <author> Scheifler Robert W., </author> <title> "The X Window System Protocol," </title> <institution> M.I.T. Laboratory for Computer Science. </institution> <year> 1988. </year>
Reference: [48] <author> Scheifler, Robert W. and Jim Gettys, </author> <title> "The X Window System," </title> <journal> Transactions on Graphics 5(2), </journal> <pages> 79-109, </pages> <month> April </month> <year> 1986, </year> <note> and Software Practice and Experience vol. 20(S2), S2/5-S2/34, </note> <month> October </month> <year> 1991 </year>
Reference-contexts: X does not support a PolyNoop command. When X11 was designed in 1986, UNIX workstations connected via Ethernet typically achieved data rates of from 62.5 K bytes per second to 125 K bytes per second, and peak character display rates were from 5K to 30K characters per second <ref> [48] </ref>. The slowest (and major) tracing configuration has lower bandwidth than the untraced setup, but would possibly have been one of the fastest machines available in 1986. <p> The X round-trip latency was measured in 1986 in <ref> [48] </ref>. There the X round trip latency was reported as 15 to 30 milliseconds. We now measure X round trip latency for a traced connection at just over 5 milliseconds.
Reference: [49] <author> Shannon, C. E., </author> <title> "A mathematical theory of communication," </title> <journal> Bell System Technical Journal, </journal> <volume> 27, </volume> <pages> 398-403, </pages> <month> July </month> <year> 1948 </year>
Reference-contexts: LZ78 can only hope for repeated substrings. The data could be completely predictable and yet lack any more common substrings than a random string. LZ78's predictive model is hardwired into the algorithm. Compression of structured data requires more flexibility. 4.1.1 From Probabilities to Bits In 1948 Shannon <ref> [49] </ref> established a lower bound on message size of ( i=1 Where p i is the probability of each event. How to achieve this lower bound was not at all obvious.
Reference: [50] <author> Simpson, W. A. </author> <title> "Point-to-Point Protocol (PPP) for the transmission of multi-protocol datagrams over point-to-point links," </title> <booktitle> SRI International, </booktitle> <address> Menlo Park, CA, </address> <month> May </month> <year> 1992. </year> <month> RFC-1331 </month>
Reference-contexts: Although this might be tolerable for a fast network, it is a disaster for a slow one. CSLIP/PPP (Compressed Serial line IP [22] layered on the Point to Point Protocol <ref> [50] </ref>) would be a very efficient network protocol for an X session traversing a slow point to point connection since it only adds about 7 bytes of header information to each packet.
Reference: [51] <author> Storer, James A., </author> <title> "Data compression: methods and theory," </title> <publisher> Computer Science Press, </publisher> <address> Rockville Maryland, </address> <year> 1988. </year> <note> 134 BIBLIOGRAPHY </note>
Reference: [52] <author> Thomas, S. W., J. McKie, S. Davies, K. Turkowski, J. A. Woods, and J. W. Orost. </author> <title> "Compress (version 4.0) program and documentation," </title> <note> available from joe@petsd.uucp, </note> <year> 1985. </year>
Reference-contexts: Whenever an entry is about to be made in the dictionary which would require a 13 bit index, CLEAR is sent, and the encoder and decoder both reset their dictionaries. This scheme is very similar to the LZC scheme described in <ref> [52] </ref>.
Reference: [53] <author> Welch, T. A., </author> <title> "A technique for high-performance data compression," </title> <journal> IEEE Computer, </journal> <volume> 17 (6), </volume> <pages> 8-19, </pages> <month> June </month> <year> 1984. </year>
Reference: [54] <author> Ziv, J. and Lempel, A. </author> <title> "Compression of individual sequences via variable-rate coding," </title> <journal> IEEE Trans. Information Theory, </journal> <volume> IT-24 (5), </volume> <pages> 530-536, </pages> <month> September </month> <year> 1978 </year>
Reference-contexts: When the network transmits data as fast as the computer can produce it, spending cycles on compression is counterproductive. When the computer must wait for the network, cycles spent on compression are well-spent. Many modems now implement a version of the LZ78 <ref> [54] </ref> compression algorithm. This hardware compression algorithm speeds ASCII file transfers, usually by over 2:1, but has little or no effect on binary file transfers, and actually increases the latency of keystroke echoing. <p> Finally, I expected that chunking and coalescing together would hurt because the LZW coder would no longer start off aligned with the beginning of each message. Figure 15 shows the result of the experiment the basic algorithm <ref> [54] </ref>, and dropping the reference to Welsh, who popularized it. For consistency I will continue to use the LZW terminology used in the Xremote documentation. 3.3.
References-found: 54

