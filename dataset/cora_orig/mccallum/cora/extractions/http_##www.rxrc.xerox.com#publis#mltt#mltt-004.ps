URL: http://www.rxrc.xerox.com/publis/mltt/mltt-004.ps
Refering-URL: http://grid.let.rug.nl/~erikt/st98/lrtlab.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: grefen@xerox.fr, tapanai@xerox.fr  
Title: What is a word, What is a sentence? Problems of Tokenization  
Author: Gregory Grefenstette, Pasi Tapanainen 
Date: July 7-10, 1994.  
Note: Appeared in 3rd Conference on Computational Lexicography and Text Research. COMPLEX'94, Budapest,  
Address: 38240 Meylan, France  
Affiliation: Rank Xerox Research Centre Grenoble Laboratory  
Abstract: Any linguistic treatment of freely occurring text must provide an answer to what is considered as a token. In artificial languages, the definition of what is considered as a token can be precisely and unambiguously defined. Natural languages, on the other hand, display such a rich variety that there are many ways to decide upon what will be considered as a unit for a computational approach to text. Here we will discuss tokenization as a problem for computational lexicography. Our discussion will cover the aspects of what is usually considered preprocessing of text in order to prepare it for some automated treatment. We present the roles of tokenization, methods of tokenizing, grammars for recognizing acronyms, abbreviations, and regular expressions such as numbers and dates. We present the problems encountered and discuss the effects of seemingly innocent choices.
Abstract-found: 1
Intro-found: 1
Reference: <author> Brill, E. </author> <year> (1992). </year> <title> A simple Rule-Based part of speech tagger. </title> <booktitle> In Proceedings of the Third conference on Applied Natural Language Processing, Trento, Italy. ACL. </booktitle>
Reference-contexts: For example, available statistical tagging programs which choose parts of speech for words using their immediate context <ref> (Brill, 1992) </ref> cannot treat the case where a surface form might correspond to one or two tokens. 5 Conclusion As we have seen, the problem of preparing raw text for a linguistic treatment raises many problems.
Reference: <author> Francis, W. N. and Kucera, H. </author> <year> (1982). </year> <title> Frequency Analysis of English. </title> <publisher> Houghton Mi*in Company, </publisher> <address> Boston. </address>
Reference-contexts: Suppose that the word small-town was split at the end of line by the typesetting, then this filter would return the string smalltown as one token. In order to test just how often this might happen in reality, we took the Brown corpus <ref> (Francis and Kucera, 1982) </ref>, a corpus whose tokenization was hand corrected, and ran it through a typesetting program (nroff) which introduced end-line hyphenations. The Brown corpus contains about 1 million words.
Reference: <author> Mller, H., Amerl, V., and Natalis, G. </author> <year> (1980). </year> <title> Worterkennungsverfahren als Grundlage einer Universalmethode zur automatischen Segmentierung von Texten in Stze. Ein Verfahren zur maschinellen Satzgrenzendestimmung im Englischen. Sprache und Datenverarbeitung, </title> <type> 1. </type>
Reference-contexts: In this technical report, they mention other work applied to solving this problem using regression analysis based on the individual probabilities of words appearing before punctuation (Riley, 1989), and rules based on the lexical endings of words surrounding punctuation <ref> (Mller et al., 1980) </ref>. 4.3 Morphologically Analyzed Words A major question that must be answered by the designer of the tokenizer is whether there exists a one-to-one correspondence between a token and a set of classes, or can a token correspond to a sequence of classes.
Reference: <author> Nunberg, G. </author> <year> (1990). </year> <booktitle> The Linguistics of Punctuation. C.S.L.I. Lecture Notes, Number 19. Center for the Study of Language and Information, </booktitle> <address> Stanford, CA. </address>
Reference-contexts: In this case, the sentence ending period is absorbed in the abbreviation-ending period <ref> (Nunberg, 1990) </ref>. regular expression Correct Errors Full Stop [A-Za-z]". 1327 52 14 [A-Z][bcdfghj-np-tvxz]+". 1938 44 26 Totals 3835 96 106 This means that, without consulting a lexicon, but only by using the structure of the words we will correctly recognize 3935 of the non-numeric token-ending periods as part of an abbreviation
Reference: <author> Palmer, D. D. and Hearst, M. A. </author> <year> (1994). </year> <title> Adaptive sentence boundary disambigation. </title> <type> Technical Report UCB/CSD 94/797, </type> <institution> University of California, Berkeley, Computer Science Division. </institution>
Reference: <author> Riley, M. D. </author> <year> (1989). </year> <title> Some applications of tree-based modelling to speech and language indexing. </title> <booktitle> In Proceedings of the DARPA Speech and Natural Language Workshop, </booktitle> <pages> pages 339-352. </pages> <publisher> Morgan Kaufmann. </publisher> <pages> 11 </pages>
Reference-contexts: Since they do not use capitalization clues, this technique might be applied to languages such as German, or to all-upper case text. In this technical report, they mention other work applied to solving this problem using regression analysis based on the individual probabilities of words appearing before punctuation <ref> (Riley, 1989) </ref>, and rules based on the lexical endings of words surrounding punctuation (Mller et al., 1980). 4.3 Morphologically Analyzed Words A major question that must be answered by the designer of the tokenizer is whether there exists a one-to-one correspondence between a token and a set of classes, or can
References-found: 6

