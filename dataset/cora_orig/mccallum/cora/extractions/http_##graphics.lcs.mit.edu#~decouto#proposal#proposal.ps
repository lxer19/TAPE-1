URL: http://graphics.lcs.mit.edu/~decouto/proposal/proposal.ps
Refering-URL: http://graphics.lcs.mit.edu/~decouto/
Root-URL: 
Title: "Argus: Instrumentation for Rapidly Acquiring Dense Pose Imagery"  
Author: Douglas S. J. De Couto 
Date: December 9, 1997  
Note: Master of Engineering Thesis Proposal:  
Abstract: This paper motivates and describes the thesis work that will be done as part of the author's Master of Engineering degree requirements. We present the primary thesis of the work: it is desirable, feasible, and practical to build a device for rapidly acquiring dense pose image datasets. Pose images are digital images tagged with estimates of the camera's 6 degree-of-freedom (DOF) position and orientation (pose). We describe how such a device is useful for building an end-to-end system which can automatically reconstruct three-dimensional (3D) models of the real world. We list the tasks that will be performed for the author's thesis, including a central deliverable of the thesis: a pose image data set acquired using Argus. Argus is a device which is designed to rapidly acquire large pose image data sets.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Coorg, Satyan, Neel Master, and Seth Teller. </author> <title> "Acquisition of a Large Pose-Mosaic Dataset." </title> <note> Submitted for publication. 8 </note>
Reference-contexts: This system starts with a pose image dataset, which is currently collected manually. Then, the pose estimate for each image in the dataset is refined using correlation and correspondences between multiple images <ref> [1] </ref>. After refinement, one of three different reconstruction approaches developed by the City Project can be used to automatically produce a 3D model. <p> Also, camera orientation had to be manually recorded from a specially built pan-tilt camera mount, and the absolute rotation around the camera's pan axis had to be determined by post-processing the image data using custom software with manual assistance <ref> [1] </ref>.
Reference: [2] <author> Coorg, Satyan, and Seth Teller. </author> <title> "Matching and Pose Refinement with Cam--era Pose Estimates." </title> <booktitle> In Proceedings of the 1997 Image Understanding Workshop, </booktitle> <address> New Orleans. </address>
Reference-contexts: Then, the pose estimate for each image in the dataset is refined using correlation and correspondences between multiple images [1]. After refinement, one of three different reconstruction approaches developed by the City Project can be used to automatically produce a 3D model. The first approach, described in <ref> [2] </ref>, is a geometric approach that uses incidence 2 counting in an absolute 3D coordinate system to match features extruded from each image. This approach also performs pose refinement. The second approach constructs dense depth maps using epipolar images in a local algorithm [4].
Reference: [3] <author> Chou, George T., and Seth Teller. </author> <title> "Multi-Image Correspondence Using Geometric and Structural Constraints." </title> <booktitle> In Proceedings of the 1997 Image Understanding Workshop, </booktitle> <address> New Orleans. </address>
Reference-contexts: This approach also performs pose refinement. The second approach constructs dense depth maps using epipolar images in a local algorithm [4]. Finally, the third approach directly attacks the correspondence problem in 3D using multi-image triangulation, treating each potential correspondence as a hypothesis whose certainty can evolve <ref> [3] </ref>. This approach can incrementally process images. Once the 3D model is reconstructed using one of the above approaches, it can be explored in a virtual walk through.
Reference: [4] <author> Mellor, J. P., Tomas Lozano-Perez, and Seth Teller. </author> <title> "Dense Depth Maps for Epipolar Images. </title> <institution> MIT AI Lab Technical Memo 1593, </institution> <year> 1997. </year>
Reference-contexts: The first approach, described in [2], is a geometric approach that uses incidence 2 counting in an absolute 3D coordinate system to match features extruded from each image. This approach also performs pose refinement. The second approach constructs dense depth maps using epipolar images in a local algorithm <ref> [4] </ref>. Finally, the third approach directly attacks the correspondence problem in 3D using multi-image triangulation, treating each potential correspondence as a hypothesis whose certainty can evolve [3]. This approach can incrementally process images.
Reference: [5] <author> Daigh, Raymond C. </author> <title> "High Reliability Navigation for Autonomous Vehicles." </title> <booktitle> The Institute of Navigation 52nd Annual Meeting. </booktitle> <address> Cambridge, </address> <month> June </month> <year> 1996. </year>
Reference-contexts: There are other systems that use integrated GPS and inertial navigation systems to acquire positioning data. For example, RAHCO International developed an unmanned tracked vehicle designed for "hazardous environmental remedia-tion" (moving nuclear waste) <ref> [5] </ref>. That system also incorporated an electronic compass, gyro, and track velocity sensors, and could stay within 1 foot of a commanded path when moving. Another system was developed at Draper Laboratories to guide "ram-air parafoils" (parachutes) using a combined GPS and inertial navigation system.
Reference: [6] <editor> Grejner-Brzezinska, Dorota A. </editor> <booktitle> "Positioning Accuracy of the GPSVan TM ." The Institute of Navigation 52nd Annual Meeting. </booktitle> <address> Cambridge, </address> <month> June </month> <year> 1996. </year>
Reference-contexts: Also, there was no 3D data derived from the films acquired in the Aspen project. However, it did pursue at one level the same idea as the City Project: making a real scene available in a simulated environment. 4 The GPSVan <ref> [6] </ref> is used to map features on highways and railroad tracks. It uses a stereo camera system mounted onto a vehicle equipped with an integrated navigation system that employs GPS and inertial navigation technologies.
Reference: [7] <author> Hattis, Philip D., and Richard Benney. </author> <title> "Demonstration of Precision Guided Ram-Air Parafoil Airdrop Using GPS/INS Navigation." </title> <booktitle> The Institute of Navigation 52nd Annual Meeting. </booktitle> <address> Cambridge, </address> <month> June </month> <year> 1996. </year>
Reference: [8] <author> Kalman, Rudolf E. </author> <title> "A New Approach to Linear Filtering and Prediction Problems." </title> <journal> Transactions of the ASME|Journal of Basic Engineering, </journal> <pages> pp. 34-45, </pages> <month> March </month> <year> 1960. </year>
Reference-contexts: It uses a stereo camera system mounted onto a vehicle equipped with an integrated navigation system that employs GPS and inertial navigation technologies. The navigation system uses differential GPS, so a GPS base station must be deployed to use the system. Also, a Kalman filter <ref> [8] </ref> [11] is used to integrate the GPS and inertial sensors and derive an optimal 3D position estimate. Argus is different from the GPSVan in several ways, despite the fact that they both share the same sort of navigation system.
Reference: [9] <author> Lippman, Andrew B. "Movie-Maps: </author> <title> An Application of the Optical Video Disc to Computer Graphics." </title> <booktitle> In SIGGRAPH 80 Conference Proceedings, </booktitle> <pages> pp. 32-42, </pages> <year> 1980. </year>
Reference-contexts: Also, aerial photography and satellite imagery provide long range pictures, while the pictures obtained by Argus are relatively close range. Finally, aerial photography and satellite imagery provide data from directly overhead, while the Argus data will cover scenes of interest from many different directions. The Aspen project <ref> [9] </ref> filmed the streets of Aspen using a special camera dolly that was moved along predefined paths. The resulting films were stored on videodiscs with some control data, allowing a "virtual tour" of Aspen.
Reference: [10] <author> Digital Photogrammetry: </author> <title> An Addendum to the Manual of Photogrammetry. </title> <booktitle> American Society for Photogrammetry and Remote Sensing, </booktitle> <year> 1996. </year>
Reference-contexts: The pose data used in aerial photography is obtained using a combination of instrumentation, ground markers, and manual effort. Sometimes aerial photography uses GPS or integrated navigation technologies to obtain the pose data, just as we do with Argus <ref> [10] </ref>. Satellite data is registered by performing calculations about the satellite's orbit and sensor orientation; further calculations are performed to map the satellite data into the appropriate coordinate system.
Reference: [11] <author> Welch, Greg, and Gary Bishop. </author> <title> "An Introduction to the Kalman Filter." </title> <note> At http://www.cs.unc.edu/ welch/kalman/kalman.html, </note> <year> 1997. </year>
Reference-contexts: It uses a stereo camera system mounted onto a vehicle equipped with an integrated navigation system that employs GPS and inertial navigation technologies. The navigation system uses differential GPS, so a GPS base station must be deployed to use the system. Also, a Kalman filter [8] <ref> [11] </ref> is used to integrate the GPS and inertial sensors and derive an optimal 3D position estimate. Argus is different from the GPSVan in several ways, despite the fact that they both share the same sort of navigation system.
Reference: [12] <author> Xiong, Rebecca. "CityScape: </author> <title> A Virtual Navigation System Applying Stratified Rendering." M.S. </title> <type> Thesis. </type> <institution> MIT, </institution> <month> May </month> <year> 1996. </year> <month> 9 </month>
Reference-contexts: However, since the models resulting from the automatic reconstruction process are likely to be large, the City Project has also developed stratified rendering techniques which allow these large models to be explored interactively <ref> [12] </ref>. Argus is being developed to address the very first stage of the City Project: acquiring pose image datasets. We have taken a manual dataset of pose images that covers our office park, Technology Square, using a digital camera mounted on an indexed pan-tilt head, attached to a tripod base.
References-found: 12

