URL: http://www.uni-paderborn.de/fachbereich/AG/agmadh/Scripts/GENERAL/Interactive/Sudan-paper.ps.gz
Refering-URL: http://www.uni-paderborn.de/fachbereich/AG/agmadh/WWW/english/scripts.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Talk given at workshop on Algebraic Methods in Complexity Theory On the role of algebra
Author: Madhu Sudan 
Abstract:  
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. ARORA. </author> <title> Probabilistic Checking of Proofs and Hardness of Approximation Problems. </title> <type> Ph. D. Thesis, </type> <institution> Computer Science Division, University of California at Berkeley, </institution> <year> 1994. </year>
Reference-contexts: Hopefully this intuition will help the more motivated reader in understanding the complete proofs of the various results described here, which may be found in the original papers or alternatively in the dissertations of Arora <ref> [1] </ref> or this author [37]. fl IBM Thomas J. Watson Research Center, P.O. Box 218, Yorktown Heights, NY 10598, U.S.A. email: madhu@watson.ibm.com. 2 Probabilistically checkable proofs We start by describing the traditional connection between proof checking and complexity theory. <p> Giving details of the works in all these papers is beyond the scope of this article and we refer the reader to Arora <ref> [1] </ref> or Sudan [37] for further details. We state the theorem that culminates from these results. Theorem 10 ([34, 3, 2, 21]) For all * &gt; 0, there exist [k 2+* ; k; 1=4] codes over alphabets of size 2 polylog k , that are (2; 1=8 *) locally checkable.
Reference: [2] <author> S. ARORA, C. LUND, R. MOTWANI, M. SUDAN AND M. SZEGEDY. </author> <title> Proof verification and intractability of approximation problems. </title> <booktitle> Proceedings of the Thirty Third Annual Symposium on the Foundations of Computer Science, IEEE, </booktitle> <year> 1992. </year>
Reference-contexts: The developments have gone on to provide different proof checking characterizations of other complexity classes including NEXPTIME, due to Babai, Fortnow and Lund [6] and NP, due to Arora and Safra [3] and Arora, Lund, Motwani, Sudan and Szegedy <ref> [2] </ref>. The effect of these characterizations was highly amplified by the connection to world of combinatorial optimization discovered by Feige, Goldwasser, Lovasz, Safra and Szegedy [17]. They turned these characterizations of NEXPTIME and NP into hardness result for the approximability of the clique size in graphs. <p> They turned these characterizations of NEXPTIME and NP into hardness result for the approximability of the clique size in graphs. Further notable successes along these lines came in the works of Bellare and Rogaway [10] and Feige and Lovasz [19] and Arora, Lund, Motwani, Sudan and Szegedy <ref> [2] </ref>. For further details, the reader is referred to the survey articles by Babai [4], Goldreich [24] or Johnson [26]. <p> This connection describes why PCP may be considered a natural variant of NP. However some very surprising and strong characterizations of NP are now available in terms of PCP. The characterization below was proved by Arora, Lund, Motwani, Sudan and Szegedy <ref> [2] </ref>. <p> Perhaps even more significant than the tight analysis is the paradigm developed by Coppersmith for the proof of a local checkability property, which has become a standard in the works of Gemmell, Lipton, Rubinfeld, Sudan and Wigderson [23]; Rubinfeld and Sudan [33, 34]; Arora, Lund, Motwani, Sudan and Szegedy <ref> [2] </ref> and Friedl and Sudan [21]. We now turn our attention to the local checkability properties of low-degree codes, for larger degree. The task of testing such functions has been studied in the recent past in numerous papers (see [6, 7, 23, 17, 33, 34, 3, 2, 32, 21]). <p> We now turn our attention to the local checkability properties of low-degree codes, for larger degree. The task of testing such functions has been studied in the recent past in numerous papers (see <ref> [6, 7, 23, 17, 33, 34, 3, 2, 32, 21] </ref>). Of these a subset of the papers focuses on the task of testing the total-degree of polynomials [23, 33, 34, 2, 21] and a different subset focuses on individual degree testing [6, 7, 17, 3, 32]. <p> The task of testing such functions has been studied in the recent past in numerous papers (see [6, 7, 23, 17, 33, 34, 3, 2, 32, 21]). Of these a subset of the papers focuses on the task of testing the total-degree of polynomials <ref> [23, 33, 34, 2, 21] </ref> and a different subset focuses on individual degree testing [6, 7, 17, 3, 32]. The latter family does not directly provide us with the best possible locally-checkable codes, but nevertheless plays a crucial role in the analysis of the former family. <p> In particular the work of Arora and Safra [3] (see also subsequent work by Polishchuk and Spielman [32]) is the prime reason for the improved analysis of the low-degree test in the work of Arora, Lund, Motwani, Sudan and Szegedy <ref> [2] </ref>. Giving details of the works in all these papers is beyond the scope of this article and we refer the reader to Arora [1] or Sudan [37] for further details. We state the theorem that culminates from these results. <p> This similarity in the two cases is not coincidental and the reader is urged to look at the full papers for more details on the connections. The NP = [ k PCP (k log; C) result of Arora, Lund, Motwani, Sudan and Szegedy <ref> [2] </ref> is obtained by combining the two different ensuing PCP results by the recursive composition paradigm of Arora and Safra [3]. Once again details of this can be found in [2]. 6 Conclusion The aim of this hastily written article was to bring to light the different elements of algebra that <p> The NP = [ k PCP (k log; C) result of Arora, Lund, Motwani, Sudan and Szegedy <ref> [2] </ref> is obtained by combining the two different ensuing PCP results by the recursive composition paradigm of Arora and Safra [3]. Once again details of this can be found in [2]. 6 Conclusion The aim of this hastily written article was to bring to light the different elements of algebra that play a role in the results on efficient proof verification. <p> We conclude by describing this sequence of results: * Bellare, Goldwasser, Lund and Russell [9] initiated the investigation of how small can the constant C be in Theorem 3. In a surprising result they show how this number can be reduced (from some unmentioned but huge constant in <ref> [2] </ref>) to 29 bits! The number has reduced, steadily but not dramatically, even since with Feige and Kilian [18] achieving 24 bits, and in an unpublished work Bellare, Goldreich and Sudan achieving 16.87 bits on the average. * The verifier created by Bellare, Goldwasser, Lund and Russell [9] and the subsequent <p> need not be increased by large factors an increase from n to n 1+* suffices for there to exist a verifier who probes the proof in only a constant number of bits. * Unfortunately, the Polishchuk and Spielman [32] result increases the constant C back to the level used in <ref> [2] </ref>. Is it possible to reduce the number of probes and the proof size simultaneously? This question was considered by Friedl and Sudan [21] who show that with a slightly super-quadratic blowup the proof can be made robust enough that 165 bits probed into the proof suffice.
Reference: [3] <author> S. ARORA AND S. SAFRA. </author> <title> Probabilistic checking of proofs: a new characterization of NP. </title> <booktitle> Proceedings of the Thirty Third Annual Symposium on the Foundations of Computer Science, IEEE, </booktitle> <year> 1992. </year>
Reference-contexts: The developments have gone on to provide different proof checking characterizations of other complexity classes including NEXPTIME, due to Babai, Fortnow and Lund [6] and NP, due to Arora and Safra <ref> [3] </ref> and Arora, Lund, Motwani, Sudan and Szegedy [2]. The effect of these characterizations was highly amplified by the connection to world of combinatorial optimization discovered by Feige, Goldwasser, Lovasz, Safra and Szegedy [17]. <p> The notion of a probabilistic oracle machine used below was introduced by Fortnow, Rompel and Sipser [20], and the parameterization of the resources used by the verifier was implicit in the work of Feige, Goldwasser, Lovasz, Safra and Szegedy [17] and explicit in the following defintion of Arora and Safra <ref> [3] </ref>. Definition 2 (PCP [3]) For functions r; q : Z + ! Z + , we define the class PCP (r; q) as follows: A language L 2 PCP (r; q) if there exists a probabilistic polynomial time oracle machine V , accessing a polynomial sized oracle , such that <p> probabilistic oracle machine used below was introduced by Fortnow, Rompel and Sipser [20], and the parameterization of the resources used by the verifier was implicit in the work of Feige, Goldwasser, Lovasz, Safra and Szegedy [17] and explicit in the following defintion of Arora and Safra <ref> [3] </ref>. Definition 2 (PCP [3]) For functions r; q : Z + ! Z + , we define the class PCP (r; q) as follows: A language L 2 PCP (r; q) if there exists a probabilistic polynomial time oracle machine V , accessing a polynomial sized oracle , such that for all x 2 <p> However some very surprising and strong characterizations of NP are now available in terms of PCP. The characterization below was proved by Arora, Lund, Motwani, Sudan and Szegedy [2]. They built upon an earlier characterization, due to Arora and Safra <ref> [3] </ref>, which showed that NP = [ k&gt;0 PCP (k log n; p All characterizations of this form owe their origin to the characterization of NEXPTIME due to Babai, Fortnow and Lund [6], which led to containment results of the form NP PCP (polylog n; polylog n) (due to Babai, Fortnow, <p> The work of Arora and Safra <ref> [3] </ref> gave the first exact characterization of NP in terms of PCP with low-query complexity. Theorem 3 ([3, 2]) 9C &lt; 1, such that NP = [ k&gt;0 PCP (k log n; C). Let us try to understand the theorem above in terms of the impact on proof checking. <p> We now turn our attention to the local checkability properties of low-degree codes, for larger degree. The task of testing such functions has been studied in the recent past in numerous papers (see <ref> [6, 7, 23, 17, 33, 34, 3, 2, 32, 21] </ref>). Of these a subset of the papers focuses on the task of testing the total-degree of polynomials [23, 33, 34, 2, 21] and a different subset focuses on individual degree testing [6, 7, 17, 3, 32]. <p> Of these a subset of the papers focuses on the task of testing the total-degree of polynomials [23, 33, 34, 2, 21] and a different subset focuses on individual degree testing <ref> [6, 7, 17, 3, 32] </ref>. The latter family does not directly provide us with the best possible locally-checkable codes, but nevertheless plays a crucial role in the analysis of the former family. <p> The latter family does not directly provide us with the best possible locally-checkable codes, but nevertheless plays a crucial role in the analysis of the former family. In particular the work of Arora and Safra <ref> [3] </ref> (see also subsequent work by Polishchuk and Spielman [32]) is the prime reason for the improved analysis of the low-degree test in the work of Arora, Lund, Motwani, Sudan and Szegedy [2]. <p> Theorem 10 ([34, 3, 2, 21]) For all * &gt; 0, there exist [k 2+* ; k; 1=4] codes over alphabets of size 2 polylog k , that are (2; 1=8 *) locally checkable. The existence of such codes along with a recursive technique developed by Arora and Safra <ref> [3] </ref> is used by Arora, Lund Motwani, Sudan and Szegedy to construct good codes over a binary alphabet that is (p; fl) locally-checkable for p &lt; 1 and fl &gt; 0. The recursive technique of Arora and Safra [3] deserves special mention. <p> such codes along with a recursive technique developed by Arora and Safra <ref> [3] </ref> is used by Arora, Lund Motwani, Sudan and Szegedy to construct good codes over a binary alphabet that is (p; fl) locally-checkable for p &lt; 1 and fl &gt; 0. The recursive technique of Arora and Safra [3] deserves special mention. In a sense, it provides a proof-checking analog of the recursive construction used earlier to combine the Reed-Solomon codes with Hadamard codes. 5 Polynomials and complexity theory We are now on the last leg of this journey through the results in complexity theory. <p> The NP = [ k PCP (k log; C) result of Arora, Lund, Motwani, Sudan and Szegedy [2] is obtained by combining the two different ensuing PCP results by the recursive composition paradigm of Arora and Safra <ref> [3] </ref>. Once again details of this can be found in [2]. 6 Conclusion The aim of this hastily written article was to bring to light the different elements of algebra that play a role in the results on efficient proof verification.
Reference: [4] <author> L. BABAI. </author> <title> Transparent (holographic) proofs. This STACS not yet defined! </title> . 
Reference-contexts: Further notable successes along these lines came in the works of Bellare and Rogaway [10] and Feige and Lovasz [19] and Arora, Lund, Motwani, Sudan and Szegedy [2]. For further details, the reader is referred to the survey articles by Babai <ref> [4] </ref>, Goldreich [24] or Johnson [26]. The motivation of this writeup is to focus on certain algebraic elements used in the construction of these efficiently checkable proofs (or more correctly the efficient verfication of proofs) and justify their participation in the construction.
Reference: [5] <author> L. BABAI AND L. FORTNOW. Arithmetization: </author> <title> A new method in structural complexity theory. </title> <journal> Computational Complexity, </journal> <volume> 1 </volume> <pages> 41-66, </pages> <year> 1991. </year>
Reference-contexts: Thus in actuality these papers don't really separate the two aspects of the works from one another. There does exist one major exception to this rule the work of Babai and Fortnow <ref> [5] </ref>. Their work extracts algebraic characterizations of ]P and PSPACE and uses that to explain the existence of efficient interactive proofs that exist for the two classes. This work in turn motivated the search for a similar explanation of the PCP characterization of NP.
Reference: [6] <author> L. BABAI, L. FORTNOW, AND C. LUND. </author> <title> Nondeterministic exponential time has two-prover interactive protocols. Computational Complexity, </title> <booktitle> 1 (1991), </booktitle> <pages> 3-40. </pages>
Reference-contexts: These developments started with the interactive proofs for ]P, and PSPACE due to Lund, Fortnow, Karloff and Nisan [28] and Shamir [35] respectively. The developments have gone on to provide different proof checking characterizations of other complexity classes including NEXPTIME, due to Babai, Fortnow and Lund <ref> [6] </ref> and NP, due to Arora and Safra [3] and Arora, Lund, Motwani, Sudan and Szegedy [2]. The effect of these characterizations was highly amplified by the connection to world of combinatorial optimization discovered by Feige, Goldwasser, Lovasz, Safra and Szegedy [17]. <p> They built upon an earlier characterization, due to Arora and Safra [3], which showed that NP = [ k&gt;0 PCP (k log n; p All characterizations of this form owe their origin to the characterization of NEXPTIME due to Babai, Fortnow and Lund <ref> [6] </ref>, which led to containment results of the form NP PCP (polylog n; polylog n) (due to Babai, Fortnow, Levin and Szegedy [7]) and NP PCP (log n loglog n; log n loglog n) (due to Feige, Goldwasser, Lovasz, Safra and Szegedy [17]). <p> We now turn our attention to the local checkability properties of low-degree codes, for larger degree. The task of testing such functions has been studied in the recent past in numerous papers (see <ref> [6, 7, 23, 17, 33, 34, 3, 2, 32, 21] </ref>). Of these a subset of the papers focuses on the task of testing the total-degree of polynomials [23, 33, 34, 2, 21] and a different subset focuses on individual degree testing [6, 7, 17, 3, 32]. <p> Of these a subset of the papers focuses on the task of testing the total-degree of polynomials [23, 33, 34, 2, 21] and a different subset focuses on individual degree testing <ref> [6, 7, 17, 3, 32] </ref>. The latter family does not directly provide us with the best possible locally-checkable codes, but nevertheless plays a crucial role in the analysis of the former family. <p> This work in turn motivated the search for a similar explanation of the PCP characterization of NP. Such a characterization was extracted eventually by this author [37] based on the works of Babai, Fortnow and Lund <ref> [6] </ref> and the subsequent work of Babai, Fortnow, Levin and Szegedy [7]. The characterization is based on the notion of a construction rule for a sequence of polynomials. <p> The following characterization is described in [37] and uses the works of Babai, Fortnow, Lund <ref> [6] </ref> and Babai, Fortnow, Levin and Szegedy [7]. Theorem 13 ([37]) Every language in NP is (log; log; log loglog ; polylog; polylog) polynomial describable.
Reference: [7] <author> L. BABAI, L. FORTNOW, L. LEVIN, AND M. SZEGEDY. </author> <title> Checking computations in polylogarithmic time. </title> <booktitle> Proceedings of the Twenty Third Annual Symposium on the Theory of Computing, ACM, </booktitle> <year> 1991. </year>
Reference-contexts: The next definition is a culmination of a sequence of efforts which owe their origins to the work of Goldwasser, Micali and Rackoff [25]; Babai and Moran [8]; Ben-Or, Goldwasser, Kilian and Wigderson [12]; Fortnow, Rompel and Sipser [20]; Babai, Fortnow, Levin and Szegedy <ref> [7] </ref>. <p> NP = [ k&gt;0 PCP (k log n; p All characterizations of this form owe their origin to the characterization of NEXPTIME due to Babai, Fortnow and Lund [6], which led to containment results of the form NP PCP (polylog n; polylog n) (due to Babai, Fortnow, Levin and Szegedy <ref> [7] </ref>) and NP PCP (log n loglog n; log n loglog n) (due to Feige, Goldwasser, Lovasz, Safra and Szegedy [17]). The work of Arora and Safra [3] gave the first exact characterization of NP in terms of PCP with low-query complexity. <p> We now turn our attention to the local checkability properties of low-degree codes, for larger degree. The task of testing such functions has been studied in the recent past in numerous papers (see <ref> [6, 7, 23, 17, 33, 34, 3, 2, 32, 21] </ref>). Of these a subset of the papers focuses on the task of testing the total-degree of polynomials [23, 33, 34, 2, 21] and a different subset focuses on individual degree testing [6, 7, 17, 3, 32]. <p> Of these a subset of the papers focuses on the task of testing the total-degree of polynomials [23, 33, 34, 2, 21] and a different subset focuses on individual degree testing <ref> [6, 7, 17, 3, 32] </ref>. The latter family does not directly provide us with the best possible locally-checkable codes, but nevertheless plays a crucial role in the analysis of the former family. <p> This work in turn motivated the search for a similar explanation of the PCP characterization of NP. Such a characterization was extracted eventually by this author [37] based on the works of Babai, Fortnow and Lund [6] and the subsequent work of Babai, Fortnow, Levin and Szegedy <ref> [7] </ref>. The characterization is based on the notion of a construction rule for a sequence of polynomials. <p> The following characterization is described in [37] and uses the works of Babai, Fortnow, Lund [6] and Babai, Fortnow, Levin and Szegedy <ref> [7] </ref>. Theorem 13 ([37]) Every language in NP is (log; log; log loglog ; polylog; polylog) polynomial describable.
Reference: [8] <author> L. BABAI AND S. MORAN. </author> <title> Arthur-Merlin games: A randomized proof system and a hierarchy of complexity classes. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 36 </volume> <pages> 254-276, </pages> <year> 1988. </year>
Reference-contexts: If the assertion is not true then no proof works. The next definition is a culmination of a sequence of efforts which owe their origins to the work of Goldwasser, Micali and Rackoff [25]; Babai and Moran <ref> [8] </ref>; Ben-Or, Goldwasser, Kilian and Wigderson [12]; Fortnow, Rompel and Sipser [20]; Babai, Fortnow, Levin and Szegedy [7].
Reference: [9] <author> M. BELLARE, S. GOLDWASSER, C. LUND AND A. RUSSELL. </author> <title> Efficient probabilistically checkable proofs and applications to approximation. </title> <booktitle> Proceedings of the Twenty Fifth Annual Symposium on the Theory of Computing, ACM, 1993. See also Errata sheet in Proceedings of the Twenty Sixth Annual Symposium on the Theory of Computing, ACM, </booktitle> <year> 1994. </year>
Reference-contexts: The exact bound specified below on is stronger than that in the work of Blum, Luby and Rubinfeld, [15], and is due to Bellare, Goldwasser, Lund and Russell <ref> [9] </ref>. (In what appears below we generalize our notation slightly to use (f; g) to denote the probability that two functions disagree which is the same as the distance between the words corresponding to f and g.) Theorem 8 (Linearity Test: [15]) If a function f : Z m 2 ! <p> Since Theorem 3 was discovered, a significant amount or work has gone into making these proof systems efficient and large degree of success has been achieved. We conclude by describing this sequence of results: * Bellare, Goldwasser, Lund and Russell <ref> [9] </ref> initiated the investigation of how small can the constant C be in Theorem 3. <p> huge constant in [2]) to 29 bits! The number has reduced, steadily but not dramatically, even since with Feige and Kilian [18] achieving 24 bits, and in an unpublished work Bellare, Goldreich and Sudan achieving 16.87 bits on the average. * The verifier created by Bellare, Goldwasser, Lund and Russell <ref> [9] </ref> and the subsequent works, require a proof to be blown by enormous (though only polynomially larger) factors.
Reference: [10] <author> M. BELLARE AND P. ROGAWAY. </author> <title> The complexity of approximating a nonlinear program. Complexity of Numerical Optimization, </title> <editor> Ed. P.M. Pardalos, </editor> <booktitle> World Scientific (1993). </booktitle>
Reference-contexts: They turned these characterizations of NEXPTIME and NP into hardness result for the approximability of the clique size in graphs. Further notable successes along these lines came in the works of Bellare and Rogaway <ref> [10] </ref> and Feige and Lovasz [19] and Arora, Lund, Motwani, Sudan and Szegedy [2]. For further details, the reader is referred to the survey articles by Babai [4], Goldreich [24] or Johnson [26].
Reference: [11] <author> M. BELLARE AND M. SUDAN. </author> <title> Improved non-approximability results. </title> <booktitle> Proceedings of the Twenty Sixth Annual Symposium on the Theory of Computing, ACM, </booktitle> <year> 1994. </year>
Reference: [12] <author> M. BEN-OR, S. GOLDWASSER, J. KILIAN AND A. WIGDERSON. </author> <title> Multi-Prover interactive proofs: How to remove intractability assumptions. </title> <booktitle> Proceedings of the Twentieth Annual Symposium on the Theory of Computing, ACM, </booktitle> <year> 1988. </year>
Reference-contexts: If the assertion is not true then no proof works. The next definition is a culmination of a sequence of efforts which owe their origins to the work of Goldwasser, Micali and Rackoff [25]; Babai and Moran [8]; Ben-Or, Goldwasser, Kilian and Wigderson <ref> [12] </ref>; Fortnow, Rompel and Sipser [20]; Babai, Fortnow, Levin and Szegedy [7].
Reference: [13] <author> P. BERMAN AND G. SCHNITGER. </author> <title> On the complexity of approximating the independent set problem. </title> <booktitle> Information and Computation 96, </booktitle> <month> 77-94 </month> <year> (1992). </year>
Reference: [14] <author> M. BLUM AND S. KANNAN. </author> <title> Program correctness checking : : : and the design of programs that check their work. </title> <booktitle> Proceedings of the Twenty First Annual Symposium on the Theory of Computing, ACM, </booktitle> <year> 1989. </year>
Reference-contexts: This breakthrough was achieved by Blum, Luby and Rubinfeld [15] in their effort to find simple verification mechanisms for programs in the spirit of Blum and Kannan <ref> [14] </ref>.
Reference: [15] <author> M. BLUM, M. LUBY AND R. RUBINFELD. </author> <title> Self-testing/correcting with applications to numerical problems. </title> <booktitle> Proceedings of the Twenty Second Annual Symposium on the Theory of Computing, ACM, </booktitle> <year> 1990. </year>
Reference-contexts: This breakthrough was achieved by Blum, Luby and Rubinfeld <ref> [15] </ref> in their effort to find simple verification mechanisms for programs in the spirit of Blum and Kannan [14]. The exact bound specified below on is stronger than that in the work of Blum, Luby and Rubinfeld, [15], and is due to Bellare, Goldwasser, Lund and Russell [9]. (In what appears <p> This breakthrough was achieved by Blum, Luby and Rubinfeld <ref> [15] </ref> in their effort to find simple verification mechanisms for programs in the spirit of Blum and Kannan [14]. The exact bound specified below on is stronger than that in the work of Blum, Luby and Rubinfeld, [15], and is due to Bellare, Goldwasser, Lund and Russell [9]. (In what appears below we generalize our notation slightly to use (f; g) to denote the probability that two functions disagree which is the same as the distance between the words corresponding to f and g.) Theorem 8 (Linearity Test: <p> and is due to Bellare, Goldwasser, Lund and Russell [9]. (In what appears below we generalize our notation slightly to use (f; g) to denote the probability that two functions disagree which is the same as the distance between the words corresponding to f and g.) Theorem 8 (Linearity Test: <ref> [15] </ref>) If a function f : Z m 2 ! Z 2 is a function which satisfies Pr 2 then there exists a linear function g such that (f; g) &lt; :1 The consequence of the above theorem is the first non-trivial locally-checkable code which can be probed at p = <p> Aside: Before we go on to describe the local checkability properties of higher-degree codes, we digress for a moment to pay our tribute to an invaluable source for information on the testability of the Hadamard codes Don Coppersmith. The Linearity Test Theorem in Blum, Luby and Rubinfeld <ref> [15] </ref> is more general and applies to the case of testing homomorphisms among groups. The proof presented by Blum, Luby and Rubinfeld [15] is different from, and simpler than, their original one and is attributed to Don Coppersmith. <p> The Linearity Test Theorem in Blum, Luby and Rubinfeld <ref> [15] </ref> is more general and applies to the case of testing homomorphisms among groups. The proof presented by Blum, Luby and Rubinfeld [15] is different from, and simpler than, their original one and is attributed to Don Coppersmith.
Reference: [16] <author> R. DEMILLO AND R. LIPTON. </author> <title> A probabilistic remark on algebraic program testing. </title> <journal> Information Processing Letters, </journal> <volume> 7(4) </volume> <pages> 193-195, </pages> <month> June </month> <year> 1978. </year>
Reference-contexts: The code used above is a special case of a family of codes well-known in the coding theory literature as the Reed-Solomon codes (cf. [30]). The relative distance achieved by the code is k=n = 1=2 and this is proven by the following property of polynomials. Theorem 7 (cf. <ref> [16, 36, 38] </ref>) Let m be a positive integer and let f; g : F m ! F , be distinct m-variate polynomials of total degree 1 at most d. Then f and g disagree in at least d=jF j fraction of their inputs.
Reference: [17] <author> U. FEIGE, S. GOLDWASSER, L. LOVASZ, S. SAFRA, AND M. SZEGEDY. </author> <title> Approximating clique is almost NP-complete. </title> <booktitle> Proceedings of the Thirty Second Annual Symposium on the Foundations of Computer Science, IEEE, </booktitle> <year> 1991. </year>
Reference-contexts: The effect of these characterizations was highly amplified by the connection to world of combinatorial optimization discovered by Feige, Goldwasser, Lovasz, Safra and Szegedy <ref> [17] </ref>. They turned these characterizations of NEXPTIME and NP into hardness result for the approximability of the clique size in graphs. Further notable successes along these lines came in the works of Bellare and Rogaway [10] and Feige and Lovasz [19] and Arora, Lund, Motwani, Sudan and Szegedy [2]. <p> The notion of a probabilistic oracle machine used below was introduced by Fortnow, Rompel and Sipser [20], and the parameterization of the resources used by the verifier was implicit in the work of Feige, Goldwasser, Lovasz, Safra and Szegedy <ref> [17] </ref> and explicit in the following defintion of Arora and Safra [3]. <p> of NEXPTIME due to Babai, Fortnow and Lund [6], which led to containment results of the form NP PCP (polylog n; polylog n) (due to Babai, Fortnow, Levin and Szegedy [7]) and NP PCP (log n loglog n; log n loglog n) (due to Feige, Goldwasser, Lovasz, Safra and Szegedy <ref> [17] </ref>). The work of Arora and Safra [3] gave the first exact characterization of NP in terms of PCP with low-query complexity. Theorem 3 ([3, 2]) 9C &lt; 1, such that NP = [ k&gt;0 PCP (k log n; C). <p> We now turn our attention to the local checkability properties of low-degree codes, for larger degree. The task of testing such functions has been studied in the recent past in numerous papers (see <ref> [6, 7, 23, 17, 33, 34, 3, 2, 32, 21] </ref>). Of these a subset of the papers focuses on the task of testing the total-degree of polynomials [23, 33, 34, 2, 21] and a different subset focuses on individual degree testing [6, 7, 17, 3, 32]. <p> Of these a subset of the papers focuses on the task of testing the total-degree of polynomials [23, 33, 34, 2, 21] and a different subset focuses on individual degree testing <ref> [6, 7, 17, 3, 32] </ref>. The latter family does not directly provide us with the best possible locally-checkable codes, but nevertheless plays a crucial role in the analysis of the former family.
Reference: [18] <author> U. FEIGE AND J. KILIAN. </author> <title> Two prover protocols low error at affordable rates. </title> <booktitle> Proceedings of the Twenty Sixth Annual Symposium on the Theory of Computing, ACM, </booktitle> <year> 1994. </year>
Reference-contexts: In a surprising result they show how this number can be reduced (from some unmentioned but huge constant in [2]) to 29 bits! The number has reduced, steadily but not dramatically, even since with Feige and Kilian <ref> [18] </ref> achieving 24 bits, and in an unpublished work Bellare, Goldreich and Sudan achieving 16.87 bits on the average. * The verifier created by Bellare, Goldwasser, Lund and Russell [9] and the subsequent works, require a proof to be blown by enormous (though only polynomially larger) factors.
Reference: [19] <author> U. FEIGE AND L. LOVASZ. </author> <title> Two-prover one-round proof systems: Their power and their problems. </title> <booktitle> Proceedings of the Twenty Fourth Annual Symposium on the Theory of Computing, ACM, </booktitle> <year> 1992. </year>
Reference-contexts: They turned these characterizations of NEXPTIME and NP into hardness result for the approximability of the clique size in graphs. Further notable successes along these lines came in the works of Bellare and Rogaway [10] and Feige and Lovasz <ref> [19] </ref> and Arora, Lund, Motwani, Sudan and Szegedy [2]. For further details, the reader is referred to the survey articles by Babai [4], Goldreich [24] or Johnson [26].
Reference: [20] <author> L. FORTNOW, J. ROMPEL, AND M. SIPSER. </author> <title> On the power of multi-prover interactive protocols. </title> <booktitle> Proceedings of the Third Annual Conference on Structure in Complexity Theory, IEEE, </booktitle> <year> 1988. </year>
Reference-contexts: If the assertion is not true then no proof works. The next definition is a culmination of a sequence of efforts which owe their origins to the work of Goldwasser, Micali and Rackoff [25]; Babai and Moran [8]; Ben-Or, Goldwasser, Kilian and Wigderson [12]; Fortnow, Rompel and Sipser <ref> [20] </ref>; Babai, Fortnow, Levin and Szegedy [7]. The notion of a probabilistic oracle machine used below was introduced by Fortnow, Rompel and Sipser [20], and the parameterization of the resources used by the verifier was implicit in the work of Feige, Goldwasser, Lovasz, Safra and Szegedy [17] and explicit in the <p> which owe their origins to the work of Goldwasser, Micali and Rackoff [25]; Babai and Moran [8]; Ben-Or, Goldwasser, Kilian and Wigderson [12]; Fortnow, Rompel and Sipser <ref> [20] </ref>; Babai, Fortnow, Levin and Szegedy [7]. The notion of a probabilistic oracle machine used below was introduced by Fortnow, Rompel and Sipser [20], and the parameterization of the resources used by the verifier was implicit in the work of Feige, Goldwasser, Lovasz, Safra and Szegedy [17] and explicit in the following defintion of Arora and Safra [3].
Reference: [21] <author> K. FRIEDL AND M. SUDAN. </author> <title> Some improvements to total degree tests. </title> <booktitle> Proceedings of the Third Israel Symposium on Theory and Computing Systems, </booktitle> <year> 1995. </year>
Reference-contexts: than the tight analysis is the paradigm developed by Coppersmith for the proof of a local checkability property, which has become a standard in the works of Gemmell, Lipton, Rubinfeld, Sudan and Wigderson [23]; Rubinfeld and Sudan [33, 34]; Arora, Lund, Motwani, Sudan and Szegedy [2] and Friedl and Sudan <ref> [21] </ref>. We now turn our attention to the local checkability properties of low-degree codes, for larger degree. The task of testing such functions has been studied in the recent past in numerous papers (see [6, 7, 23, 17, 33, 34, 3, 2, 32, 21]). <p> We now turn our attention to the local checkability properties of low-degree codes, for larger degree. The task of testing such functions has been studied in the recent past in numerous papers (see <ref> [6, 7, 23, 17, 33, 34, 3, 2, 32, 21] </ref>). Of these a subset of the papers focuses on the task of testing the total-degree of polynomials [23, 33, 34, 2, 21] and a different subset focuses on individual degree testing [6, 7, 17, 3, 32]. <p> The task of testing such functions has been studied in the recent past in numerous papers (see [6, 7, 23, 17, 33, 34, 3, 2, 32, 21]). Of these a subset of the papers focuses on the task of testing the total-degree of polynomials <ref> [23, 33, 34, 2, 21] </ref> and a different subset focuses on individual degree testing [6, 7, 17, 3, 32]. The latter family does not directly provide us with the best possible locally-checkable codes, but nevertheless plays a crucial role in the analysis of the former family. <p> Is it possible to reduce the number of probes and the proof size simultaneously? This question was considered by Friedl and Sudan <ref> [21] </ref> who show that with a slightly super-quadratic blowup the proof can be made robust enough that 165 bits probed into the proof suffice. It remains open if we can ever get linear sized proofs with (small) constant probe complexity.
Reference: [22] <author> K. FRIEDL, ZS. H ATS AGI, AND A. SHEN. </author> <title> Low-degree tests. </title> <booktitle> Proceedings of the Fifth Symposium on Discrete Algorithms, ACM, </booktitle> <year> 1994. </year>
Reference: [23] <author> P. GEMMELL, R. LIPTON, R. RUBINFELD, M. SUDAN, AND A. WIGDERSON. </author> <title> Self-testing/correcting for polynomials and for approximate functions. </title> <booktitle> Proceedings of the Twenty Third Annual Symposium on the Theory of Computing, ACM, </booktitle> <year> 1991. </year>
Reference-contexts: Perhaps even more significant than the tight analysis is the paradigm developed by Coppersmith for the proof of a local checkability property, which has become a standard in the works of Gemmell, Lipton, Rubinfeld, Sudan and Wigderson <ref> [23] </ref>; Rubinfeld and Sudan [33, 34]; Arora, Lund, Motwani, Sudan and Szegedy [2] and Friedl and Sudan [21]. We now turn our attention to the local checkability properties of low-degree codes, for larger degree. <p> We now turn our attention to the local checkability properties of low-degree codes, for larger degree. The task of testing such functions has been studied in the recent past in numerous papers (see <ref> [6, 7, 23, 17, 33, 34, 3, 2, 32, 21] </ref>). Of these a subset of the papers focuses on the task of testing the total-degree of polynomials [23, 33, 34, 2, 21] and a different subset focuses on individual degree testing [6, 7, 17, 3, 32]. <p> The task of testing such functions has been studied in the recent past in numerous papers (see [6, 7, 23, 17, 33, 34, 3, 2, 32, 21]). Of these a subset of the papers focuses on the task of testing the total-degree of polynomials <ref> [23, 33, 34, 2, 21] </ref> and a different subset focuses on individual degree testing [6, 7, 17, 3, 32]. The latter family does not directly provide us with the best possible locally-checkable codes, but nevertheless plays a crucial role in the analysis of the former family.
Reference: [24] <author> O. GOLDREICH. </author> <title> A taxonomy of proof systems. SIGACT News, Complexity Theory Column, Two part series appears in December 1993, and March 1994. </title>
Reference-contexts: Further notable successes along these lines came in the works of Bellare and Rogaway [10] and Feige and Lovasz [19] and Arora, Lund, Motwani, Sudan and Szegedy [2]. For further details, the reader is referred to the survey articles by Babai [4], Goldreich <ref> [24] </ref> or Johnson [26]. The motivation of this writeup is to focus on certain algebraic elements used in the construction of these efficiently checkable proofs (or more correctly the efficient verfication of proofs) and justify their participation in the construction.
Reference: [25] <author> S. GOLDWASSER, S. MICALI, AND C. RACKOFF. </author> <title> The knowledge complexity of interactive proof systems. </title> <journal> SIAM Journal on Computing, </journal> <volume> 18 </volume> <pages> 186-208, </pages> <year> 1989. </year>
Reference-contexts: If the assertion is true, then there must exist a short proof . If the assertion is not true then no proof works. The next definition is a culmination of a sequence of efforts which owe their origins to the work of Goldwasser, Micali and Rackoff <ref> [25] </ref>; Babai and Moran [8]; Ben-Or, Goldwasser, Kilian and Wigderson [12]; Fortnow, Rompel and Sipser [20]; Babai, Fortnow, Levin and Szegedy [7].
Reference: [26] <author> D. JOHNSON. </author> <title> The tale of the second prover. </title> <journal> Journal of Algorithms, </journal> <volume> 13 </volume> <pages> 502-524, </pages> <year> 1992. </year> <title> Part of The NP-Completeness Column: An Ongoing Guide. </title>
Reference-contexts: Further notable successes along these lines came in the works of Bellare and Rogaway [10] and Feige and Lovasz [19] and Arora, Lund, Motwani, Sudan and Szegedy [2]. For further details, the reader is referred to the survey articles by Babai [4], Goldreich [24] or Johnson <ref> [26] </ref>. The motivation of this writeup is to focus on certain algebraic elements used in the construction of these efficiently checkable proofs (or more correctly the efficient verfication of proofs) and justify their participation in the construction.
Reference: [27] <author> R. KARP. </author> <title> Reducibility among combinatorial problems. Complexity of Computer Computations, </title> <editor> Miller and Thatcher (eds.), </editor> <publisher> Plenum Press, </publisher> <address> New York (1972). </address>
Reference: [28] <author> C. LUND, L. FORTNOW, H. KARLOFF, AND N. NISAN. </author> <title> Algebraic methods for interactive proof systems. </title> <booktitle> Proceedings of the Thirty First Annual Symposium on the Foundations of Computer Science, IEEE, </booktitle> <year> 1990. </year>
Reference-contexts: 1 Introduction The reader of this writeup is assumed to be slightly familiar with the series of developments in complexity theory relating to proof checking over the last five years. These developments started with the interactive proofs for ]P, and PSPACE due to Lund, Fortnow, Karloff and Nisan <ref> [28] </ref> and Shamir [35] respectively. The developments have gone on to provide different proof checking characterizations of other complexity classes including NEXPTIME, due to Babai, Fortnow and Lund [6] and NP, due to Arora and Safra [3] and Arora, Lund, Motwani, Sudan and Szegedy [2].
Reference: [29] <author> C. LUND AND M. YANNAKAKIS. </author> <title> On the hardness of approximating minimization problems. </title> <booktitle> Proceedings of the Twenty Fifth Annual Symposium on the Theory of Computing, ACM, </booktitle> <year> 1993. </year>
Reference: [30] <author> F. MACWILLIAMS AND N. SLOANE. </author> <title> The Theory of Error-Correcting Codes. </title> <publisher> North-Holland. </publisher> <year> 1981. </year>
Reference-contexts: The encoding C (m) = C (m) (0) C (m) (n1) is given by C (m) (i) = M ( i ). The code used above is a special case of a family of codes well-known in the coding theory literature as the Reed-Solomon codes (cf. <ref> [30] </ref>). The relative distance achieved by the code is k=n = 1=2 and this is proven by the following property of polynomials.
Reference: [31] <author> C. PAPADIMITRIOU AND M. YANNAKAKIS. </author> <title> Optimization, approximation, and complexity classes. </title> <booktitle> Proceedings of the Twentieth Annual Symposium on the Theory of Computing, ACM, </booktitle> <year> 1988. </year>
Reference: [32] <author> A. POLISHCHUK AND D. SPIELMAN. </author> <title> Nearly-linear size holographic proofs. </title> <booktitle> Proceedings of the Twenty Sixth Annual Symposium on the Theory of Computing, ACM, </booktitle> <year> 1994. </year>
Reference-contexts: We now turn our attention to the local checkability properties of low-degree codes, for larger degree. The task of testing such functions has been studied in the recent past in numerous papers (see <ref> [6, 7, 23, 17, 33, 34, 3, 2, 32, 21] </ref>). Of these a subset of the papers focuses on the task of testing the total-degree of polynomials [23, 33, 34, 2, 21] and a different subset focuses on individual degree testing [6, 7, 17, 3, 32]. <p> Of these a subset of the papers focuses on the task of testing the total-degree of polynomials [23, 33, 34, 2, 21] and a different subset focuses on individual degree testing <ref> [6, 7, 17, 3, 32] </ref>. The latter family does not directly provide us with the best possible locally-checkable codes, but nevertheless plays a crucial role in the analysis of the former family. <p> The latter family does not directly provide us with the best possible locally-checkable codes, but nevertheless plays a crucial role in the analysis of the former family. In particular the work of Arora and Safra [3] (see also subsequent work by Polishchuk and Spielman <ref> [32] </ref>) is the prime reason for the improved analysis of the low-degree test in the work of Arora, Lund, Motwani, Sudan and Szegedy [2]. <p> Polishchuk and Spielman <ref> [32] </ref> investigate the question of how small the proofs could be and show that proofs need not be increased by large factors an increase from n to n 1+* suffices for there to exist a verifier who probes the proof in only a constant number of bits. * Unfortunately, the Polishchuk <p> question of how small the proofs could be and show that proofs need not be increased by large factors an increase from n to n 1+* suffices for there to exist a verifier who probes the proof in only a constant number of bits. * Unfortunately, the Polishchuk and Spielman <ref> [32] </ref> result increases the constant C back to the level used in [2].
Reference: [33] <author> R. RUBINFELD AND M. SUDAN. </author> <title> Testing polynomial functions efficiently and over rational domains. </title> <booktitle> Proceedings of the Third Symposium on Discrete Algorithms, ACM, </booktitle> <year> 1994. </year>
Reference-contexts: Perhaps even more significant than the tight analysis is the paradigm developed by Coppersmith for the proof of a local checkability property, which has become a standard in the works of Gemmell, Lipton, Rubinfeld, Sudan and Wigderson [23]; Rubinfeld and Sudan <ref> [33, 34] </ref>; Arora, Lund, Motwani, Sudan and Szegedy [2] and Friedl and Sudan [21]. We now turn our attention to the local checkability properties of low-degree codes, for larger degree. <p> We now turn our attention to the local checkability properties of low-degree codes, for larger degree. The task of testing such functions has been studied in the recent past in numerous papers (see <ref> [6, 7, 23, 17, 33, 34, 3, 2, 32, 21] </ref>). Of these a subset of the papers focuses on the task of testing the total-degree of polynomials [23, 33, 34, 2, 21] and a different subset focuses on individual degree testing [6, 7, 17, 3, 32]. <p> The task of testing such functions has been studied in the recent past in numerous papers (see [6, 7, 23, 17, 33, 34, 3, 2, 32, 21]). Of these a subset of the papers focuses on the task of testing the total-degree of polynomials <ref> [23, 33, 34, 2, 21] </ref> and a different subset focuses on individual degree testing [6, 7, 17, 3, 32]. The latter family does not directly provide us with the best possible locally-checkable codes, but nevertheless plays a crucial role in the analysis of the former family.
Reference: [34] <author> R. RUBINFELD AND M. SUDAN. </author> <title> Robust characterizations of polynomials with applications to program testing. </title> <type> Technical Report RC 19156, </type> <institution> IBM Research Division, T. J. Watson Research Center, </institution> <address> Yorktown Heights, NY 10598, </address> <month> September </month> <year> 1993. </year>
Reference-contexts: The former parameter p is the number of letters of the received word that are scanned by the probabilistic error-detector. The latter parameter is the probability with which the error-detector detects errors if the received word is not uniquely decodable. The following formalism is due to Rubinfeld and Sudan <ref> [34] </ref>. Definition 6 ([34]) For a positive integer p and a positive real number fl, an [n; k; ffi]-code C over the alphabet is (p; fl)-locally checkable if the following exist * A probability space which can be efficiently sampled. * Functions q 1 ; q 2 ; : : : <p> Perhaps even more significant than the tight analysis is the paradigm developed by Coppersmith for the proof of a local checkability property, which has become a standard in the works of Gemmell, Lipton, Rubinfeld, Sudan and Wigderson [23]; Rubinfeld and Sudan <ref> [33, 34] </ref>; Arora, Lund, Motwani, Sudan and Szegedy [2] and Friedl and Sudan [21]. We now turn our attention to the local checkability properties of low-degree codes, for larger degree. <p> We now turn our attention to the local checkability properties of low-degree codes, for larger degree. The task of testing such functions has been studied in the recent past in numerous papers (see <ref> [6, 7, 23, 17, 33, 34, 3, 2, 32, 21] </ref>). Of these a subset of the papers focuses on the task of testing the total-degree of polynomials [23, 33, 34, 2, 21] and a different subset focuses on individual degree testing [6, 7, 17, 3, 32]. <p> The task of testing such functions has been studied in the recent past in numerous papers (see [6, 7, 23, 17, 33, 34, 3, 2, 32, 21]). Of these a subset of the papers focuses on the task of testing the total-degree of polynomials <ref> [23, 33, 34, 2, 21] </ref> and a different subset focuses on individual degree testing [6, 7, 17, 3, 32]. The latter family does not directly provide us with the best possible locally-checkable codes, but nevertheless plays a crucial role in the analysis of the former family.
Reference: [35] <author> A. SHAMIR. </author> <title> IP = PSPACE. </title> <booktitle> Proceedings of the Thirty First Annual Symposium on the Foundations of Computer Science, IEEE, </booktitle> <year> 1990. </year>
Reference-contexts: These developments started with the interactive proofs for ]P, and PSPACE due to Lund, Fortnow, Karloff and Nisan [28] and Shamir <ref> [35] </ref> respectively. The developments have gone on to provide different proof checking characterizations of other complexity classes including NEXPTIME, due to Babai, Fortnow and Lund [6] and NP, due to Arora and Safra [3] and Arora, Lund, Motwani, Sudan and Szegedy [2].
Reference: [36] <author> J. T. Schwartz. </author> <title> Fast probabilistic algorithms for verification of probabilistic identities. </title> <journal> Journal of the ACM, v. </journal> <volume> 27, </volume> <pages> 701-717, </pages> <year> 1980. </year>
Reference-contexts: The code used above is a special case of a family of codes well-known in the coding theory literature as the Reed-Solomon codes (cf. [30]). The relative distance achieved by the code is k=n = 1=2 and this is proven by the following property of polynomials. Theorem 7 (cf. <ref> [16, 36, 38] </ref>) Let m be a positive integer and let f; g : F m ! F , be distinct m-variate polynomials of total degree 1 at most d. Then f and g disagree in at least d=jF j fraction of their inputs.
Reference: [37] <author> M. SUDAN. </author> <title> Efficient Checking of Polynomials and Proofs and the Hardness of Approximation Problems. </title> <type> Ph.D. Thesis, </type> <institution> Computer Science Division, University of California at Berkeley. </institution> <year> 1992. </year>
Reference-contexts: Hopefully this intuition will help the more motivated reader in understanding the complete proofs of the various results described here, which may be found in the original papers or alternatively in the dissertations of Arora [1] or this author <ref> [37] </ref>. fl IBM Thomas J. Watson Research Center, P.O. Box 218, Yorktown Heights, NY 10598, U.S.A. email: madhu@watson.ibm.com. 2 Probabilistically checkable proofs We start by describing the traditional connection between proof checking and complexity theory. This connection is fundamental to the definition of the complexity class NP. <p> Giving details of the works in all these papers is beyond the scope of this article and we refer the reader to Arora [1] or Sudan <ref> [37] </ref> for further details. We state the theorem that culminates from these results. Theorem 10 ([34, 3, 2, 21]) For all * &gt; 0, there exist [k 2+* ; k; 1=4] codes over alphabets of size 2 polylog k , that are (2; 1=8 *) locally checkable. <p> This work in turn motivated the search for a similar explanation of the PCP characterization of NP. Such a characterization was extracted eventually by this author <ref> [37] </ref> based on the works of Babai, Fortnow and Lund [6] and the subsequent work of Babai, Fortnow, Levin and Szegedy [7]. The characterization is based on the notion of a construction rule for a sequence of polynomials. <p> The following characterization is described in <ref> [37] </ref> and uses the works of Babai, Fortnow, Lund [6] and Babai, Fortnow, Levin and Szegedy [7]. Theorem 13 ([37]) Every language in NP is (log; log; log loglog ; polylog; polylog) polynomial describable. The result of Babai, Fortnow, Levin and Szegedy NP PCP (polylog; polylog) is shown by Sudan [37] <p> <ref> [37] </ref> and uses the works of Babai, Fortnow, Lund [6] and Babai, Fortnow, Levin and Szegedy [7]. Theorem 13 ([37]) Every language in NP is (log; log; log loglog ; polylog; polylog) polynomial describable. The result of Babai, Fortnow, Levin and Szegedy NP PCP (polylog; polylog) is shown by Sudan [37] to be an immediate consequence of this characterization and the local checkability properties of polynomials described in Section 4. Implicit in the work of Arora, Lund, Motwani, Sudan and Szegedy is also a different containment result for NP.
Reference: [38] <author> R. ZIPPEL. </author> <title> Probabilistic algorithms for sparse polynomials. </title> <booktitle> EUROSAM '79, Lecture Notes in Computer Science, </booktitle> <volume> 72 </volume> <pages> 216-226, </pages> <year> 1979. </year>
Reference-contexts: The code used above is a special case of a family of codes well-known in the coding theory literature as the Reed-Solomon codes (cf. [30]). The relative distance achieved by the code is k=n = 1=2 and this is proven by the following property of polynomials. Theorem 7 (cf. <ref> [16, 36, 38] </ref>) Let m be a positive integer and let f; g : F m ! F , be distinct m-variate polynomials of total degree 1 at most d. Then f and g disagree in at least d=jF j fraction of their inputs.
References-found: 38

