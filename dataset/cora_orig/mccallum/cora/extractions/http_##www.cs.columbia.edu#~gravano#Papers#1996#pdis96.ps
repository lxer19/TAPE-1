URL: http://www.cs.columbia.edu/~gravano/Papers/1996/pdis96.ps
Refering-URL: http://www.cs.columbia.edu/~gravano/publications.html
Root-URL: http://www.cs.columbia.edu
Email: fhector,gravano,shivag@cs.stanford.edu  
Title: dSCAM: Finding Document Copies Across Multiple Databases  
Author: Hector Garca-Molina Luis Gravano Narayanan Shivakumar 
Address: Stanford, CA 94305-9040, USA  
Affiliation: Computer Science Department Stanford University  
Abstract: The advent of the Internet has made the illegal dissemination of copyrighted material easy. An important problem is how to automatically detect when a "new" digital document is "suspiciously close" to existing ones. The SCAM project at Stanford University has addressed this problem when there is a single registered-document database. However, in practice, text documents may appear in many autonomous databases, and one would like to discover copies without having to exhaustively search in all databases. Our approach, dSCAM, is a distributed version of SCAM that keeps succinct metainformation about the contents of the available document databases. Given a suspicious document S, dSCAM uses its information to prune all databases that cannot contain any document that is close enough to S, and hence the search can focus on the remaining sites. We also study how to query the remaining databases so as to minimize different querying costs. We empirically study the pruning and searching schemes, using a collection of 50 databases and two sets of test documents. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> P. J. Denning. </author> <title> Editorial: Plagiarism in the web. </title> <journal> Communications of the ACM, </journal> <volume> 38(12), </volume> <month> December </month> <year> 1995. </year>
Reference-contexts: 1 Introduction In a renowned 1995 case <ref> [1] </ref>, an author, who we will refer to as Mr. X for legal reasons, plagiarized several technical reports and conference papers, and resubmitted them under his own name to other conferences and journals. <p> The Stanford Copy Analysis Mechanism (SCAM) [5, 6] played an important role in identifying the papers that Mr. X had plagiarized. (See <ref> [7, 1] </ref> for further details.) SCAM is a registration server mechanism that helps flag document-copyright violations in Digital Libraries. The target is not simply academic plagiarism, but any type of copying that can financially hurt authors and commercial publishers. <p> In effect, F 3 (S) F 3 (D 2 ) 5 + 5 3 = 2:27 &lt; * = 2:5. For the remaining cases, Accept (w 1 ; F 1 (S)) = <ref> [1; 1] </ref>, Accept (w 2 ; F 2 (S)) = [2; 5], and Accept (w 4 ; F 4 (S)) = [5; 17]. Then, c (S; D 1 ) = fw 1 ; w 2 g, and c (S; D 2 ) = fw 3 g. <p> Also note that the Range technique does not use the R i statistics. Example 1 (cont.) Consider the db statistics and the suspicious document S. We have already computed Accept (w 1 ; F 1 (S)) = <ref> [1; 1] </ref>, Accept (w 2 ; F 2 (S)) = [2; 5], Accept (w 3 ; F 3 (S)) = [2; 5], and Accept (w 4 ; F 4 (S)) = [5; 17].
Reference: [2] <author> A. Tal and R. Alonso. </author> <title> Commit protocols for externalized-commit heterogeneous database systems. </title> <booktitle> Distributed and Parallel Databases, </booktitle> <volume> 2(2) </volume> <pages> 209-34, </pages> <month> April </month> <year> 1994. </year>
Reference-contexts: The topics of these papers ranged from Steiner routing in VLSI CAD, to massively parallel genetic algorithms, complexity theory, and network protocols. Mr. X also plagiarized papers from the database field, notably a paper in DAPD by Tal and Alonso <ref> [2] </ref> on three-phase locking, a paper in VLDB fl This material is based upon work supported by the National Science Foundation under Cooperative Agreement IRI-9411306. Funding for this cooperative agreement is also provided by DARPA, NASA, and the industrial partners of the Stanford Digital Libraries Project. <p> Assuming * = 2:5 (a value that worked well in the experiments in [5]), Accept (w 3 ; F 3 (S)) = Accept (w 3 ; 3) = <ref> [2; 5] </ref>. Thus, w 3 is in c (S; D 2 ), the closeness set for S and D 2 , because F 3 (D 2 ) = 5 is in Accept (w 3 ; F 3 (S)). <p> In effect, F 3 (S) F 3 (D 2 ) 5 + 5 3 = 2:27 &lt; * = 2:5. For the remaining cases, Accept (w 1 ; F 1 (S)) = [1; 1], Accept (w 2 ; F 2 (S)) = <ref> [2; 5] </ref>, and Accept (w 4 ; F 4 (S)) = [5; 17]. Then, c (S; D 1 ) = fw 1 ; w 2 g, and c (S; D 2 ) = fw 3 g. <p> Also note that the Range technique does not use the R i statistics. Example 1 (cont.) Consider the db statistics and the suspicious document S. We have already computed Accept (w 1 ; F 1 (S)) = [1; 1], Accept (w 2 ; F 2 (S)) = <ref> [2; 5] </ref>, Accept (w 3 ; F 3 (S)) = [2; 5], and Accept (w 4 ; F 4 (S)) = [5; 17]. Also, dSCAM knows, for example, that word w 2 appears in db with in-document frequencies between [f 2 (db); F 2 (db)] = [3; 8]. <p> Example 1 (cont.) Consider the db statistics and the suspicious document S. We have already computed Accept (w 1 ; F 1 (S)) = [1; 1], Accept (w 2 ; F 2 (S)) = <ref> [2; 5] </ref>, Accept (w 3 ; F 3 (S)) = [2; 5], and Accept (w 4 ; F 4 (S)) = [5; 17]. Also, dSCAM knows, for example, that word w 2 appears in db with in-document frequencies between [f 2 (db); F 2 (db)] = [3; 8]. <p> Also, dSCAM knows, for example, that word w 2 appears in db with in-document frequencies between [f 2 (db); F 2 (db)] = [3; 8]. Then, the interesting range of frequencies of w 2 in db is [m 2 ; M 2 ] = [3; 8] " <ref> [2; 5] </ref> = [3; 5]. The maximum such frequency is M 2 (db; S) = 5. (Notice that there is no document D in db with F 2 (D) = 5.
Reference: [3] <author> Y. E. Ioannidis, R. T. Ng, K. Shim, and T. K. Sel-lis. </author> <title> Parametric query optimization. </title> <booktitle> In Proceedings of the 18th International Conference on Very Large Data Bases, </booktitle> <pages> pages 103-14, </pages> <address> Vancouver, </address> <month> August </month> <year> 1992. </year>
Reference-contexts: Any opinions, finding, and conclusions or recommendations expressed in this material are those of the author (s) and do not necessarily reflect the views of the National Science Foundation or the other sponsors. '92 by Ioannidis et al. <ref> [3] </ref> on parametric query optimization, and a paper in ICDE '90 by Leung and Muntz [4] on temporal query processing. The Stanford Copy Analysis Mechanism (SCAM) [5, 6] played an important role in identifying the papers that Mr. <p> Also, dSCAM knows, for example, that word w 2 appears in db with in-document frequencies between [f 2 (db); F 2 (db)] = <ref> [3; 8] </ref>. Then, the interesting range of frequencies of w 2 in db is [m 2 ; M 2 ] = [3; 8] " [2; 5] = [3; 5]. <p> Also, dSCAM knows, for example, that word w 2 appears in db with in-document frequencies between [f 2 (db); F 2 (db)] = <ref> [3; 8] </ref>. Then, the interesting range of frequencies of w 2 in db is [m 2 ; M 2 ] = [3; 8] " [2; 5] = [3; 5]. The maximum such frequency is M 2 (db; S) = 5. (Notice that there is no document D in db with F 2 (D) = 5. <p> Then, the interesting range of frequencies of w 2 in db is [m 2 ; M 2 ] = [3; 8] " [2; 5] = <ref> [3; 5] </ref>. The maximum such frequency is M 2 (db; S) = 5. (Notice that there is no document D in db with F 2 (D) = 5.
Reference: [4] <author> T. Y. C. Leung and R. Muntz. </author> <title> Query processing for temporal databases. </title> <booktitle> In Proceedings of the 6th International Conference on Data Engineering, </booktitle> <pages> pages 200-8, </pages> <month> February </month> <year> 1990. </year>
Reference-contexts: and conclusions or recommendations expressed in this material are those of the author (s) and do not necessarily reflect the views of the National Science Foundation or the other sponsors. '92 by Ioannidis et al. [3] on parametric query optimization, and a paper in ICDE '90 by Leung and Muntz <ref> [4] </ref> on temporal query processing. The Stanford Copy Analysis Mechanism (SCAM) [5, 6] played an important role in identifying the papers that Mr. X had plagiarized. (See [7, 1] for further details.) SCAM is a registration server mechanism that helps flag document-copyright violations in Digital Libraries.
Reference: [5] <author> Narayanan Shivakumar and Hector Garca-Molina. </author> <title> SCAM: A copy detection mechanism for digital documents. </title> <booktitle> In Proceedings of the 2 nd International Conference in Theory and Practice of Digital Libraries (DL'95), </booktitle> <address> Austin, Texas, </address> <month> June </month> <year> 1995. </year>
Reference-contexts: The Stanford Copy Analysis Mechanism (SCAM) <ref> [5, 6] </ref> played an important role in identifying the papers that Mr. X had plagiarized. (See [7, 1] for further details.) SCAM is a registration server mechanism that helps flag document-copyright violations in Digital Libraries. <p> We have explored <ref> [5, 6] </ref> a variety of overlap measures. For example, we can say that S and D overlap if they contain at least some fraction of common sentences. <p> More precisely, given a fixed * &gt; 2, the closeness set for S and D, c (S; D), contains the words w i with a similar number of occurrences in the two documents <ref> [5] </ref>: w i 2 c (S; D) , F i (D) F i (D) &lt; * where F i (d) is the frequency of word w i in document d. If either F i (S) or F i (D) are zero, then w i is not in the closeness set. <p> Assuming * = 2:5 (a value that worked well in the experiments in <ref> [5] </ref>), Accept (w 3 ; F 3 (S)) = Accept (w 3 ; 3) = [2; 5]. <p> Assuming * = 2:5 (a value that worked well in the experiments in [5]), Accept (w 3 ; F 3 (S)) = Accept (w 3 ; 3) = <ref> [2; 5] </ref>. Thus, w 3 is in c (S; D 2 ), the closeness set for S and D 2 , because F 3 (D 2 ) = 5 is in Accept (w 3 ; F 3 (S)). <p> In effect, F 3 (S) F 3 (D 2 ) 5 + 5 3 = 2:27 &lt; * = 2:5. For the remaining cases, Accept (w 1 ; F 1 (S)) = [1; 1], Accept (w 2 ; F 2 (S)) = <ref> [2; 5] </ref>, and Accept (w 4 ; F 4 (S)) = [5; 17]. Then, c (S; D 1 ) = fw 1 ; w 2 g, and c (S; D 2 ) = fw 3 g. <p> For the remaining cases, Accept (w 1 ; F 1 (S)) = [1; 1], Accept (w 2 ; F 2 (S)) = [2; 5], and Accept (w 4 ; F 4 (S)) = <ref> [5; 17] </ref>. Then, c (S; D 1 ) = fw 1 ; w 2 g, and c (S; D 2 ) = fw 3 g. After finding the closeness set for S and D, SCAM computes the similarity sim (S; D) between the two documents. <p> So, for T = 0:80, SCAM would not consider D 2 to be a potential copy of S. However, SCAM would find D 1 suspiciously close to S. Even though the SCAM similarity does not take into account word sequencing, the experiments in <ref> [5, 6] </ref> show that it detects potential copies relatively well. In these experiments, conducted with 50,000 netnews articles, false positives were very rare: the similarity measure flagged unrelated documents as copies (because they shared common vocabulary) in only 0:01% of the cases. <p> Also note that the Range technique does not use the R i statistics. Example 1 (cont.) Consider the db statistics and the suspicious document S. We have already computed Accept (w 1 ; F 1 (S)) = [1; 1], Accept (w 2 ; F 2 (S)) = <ref> [2; 5] </ref>, Accept (w 3 ; F 3 (S)) = [2; 5], and Accept (w 4 ; F 4 (S)) = [5; 17]. Also, dSCAM knows, for example, that word w 2 appears in db with in-document frequencies between [f 2 (db); F 2 (db)] = [3; 8]. <p> Example 1 (cont.) Consider the db statistics and the suspicious document S. We have already computed Accept (w 1 ; F 1 (S)) = [1; 1], Accept (w 2 ; F 2 (S)) = <ref> [2; 5] </ref>, Accept (w 3 ; F 3 (S)) = [2; 5], and Accept (w 4 ; F 4 (S)) = [5; 17]. Also, dSCAM knows, for example, that word w 2 appears in db with in-document frequencies between [f 2 (db); F 2 (db)] = [3; 8]. <p> We have already computed Accept (w 1 ; F 1 (S)) = [1; 1], Accept (w 2 ; F 2 (S)) = [2; 5], Accept (w 3 ; F 3 (S)) = [2; 5], and Accept (w 4 ; F 4 (S)) = <ref> [5; 17] </ref>. Also, dSCAM knows, for example, that word w 2 appears in db with in-document frequencies between [f 2 (db); F 2 (db)] = [3; 8]. <p> Also, dSCAM knows, for example, that word w 2 appears in db with in-document frequencies between [f 2 (db); F 2 (db)] = [3; 8]. Then, the interesting range of frequencies of w 2 in db is [m 2 ; M 2 ] = [3; 8] " <ref> [2; 5] </ref> = [3; 5]. The maximum such frequency is M 2 (db; S) = 5. (Notice that there is no document D in db with F 2 (D) = 5. <p> Then, the interesting range of frequencies of w 2 in db is [m 2 ; M 2 ] = [3; 8] " [2; 5] = <ref> [3; 5] </ref>. The maximum such frequency is M 2 (db; S) = 5. (Notice that there is no document D in db with F 2 (D) = 5. <p> Furthermore, such prevention schemes can be broken by using software emulators [16] and recording documents. Instead of placing restrictions on the distribution of documents, another approach to protecting digital documents (one we subscribe to) is to detect illegal copies using registration server mechanisms such as SCAM <ref> [5, 6] </ref> or COPS [16]. Once we know a document to be an illegal copy, it is sometimes useful to know the originator of the illegal copy.
Reference: [6] <author> Narayanan Shivakumar and Hector Garca-Molina. </author> <title> Building a scalable and accurate copy detection mechanism. </title> <booktitle> In Proceedings of the 1 st ACM Conference on Digital Libraries (DL'96), </booktitle> <address> Bethesda, Maryland, </address> <month> March </month> <year> 1996. </year>
Reference-contexts: The Stanford Copy Analysis Mechanism (SCAM) <ref> [5, 6] </ref> played an important role in identifying the papers that Mr. X had plagiarized. (See [7, 1] for further details.) SCAM is a registration server mechanism that helps flag document-copyright violations in Digital Libraries. <p> We have explored <ref> [5, 6] </ref> a variety of overlap measures. For example, we can say that S and D overlap if they contain at least some fraction of common sentences. <p> The following table shows the frequency of the words in the documents. Document F 1 F 2 F 3 F 4 S 1 3 3 9 D 2 0 8 5 0 1 It also helps to ignore altogether words that occur frequently across documents <ref> [6] </ref>. Our experiments of Section 7 use the stop words in [6]. <p> Document F 1 F 2 F 3 F 4 S 1 3 3 9 D 2 0 8 5 0 1 It also helps to ignore altogether words that occur frequently across documents <ref> [6] </ref>. Our experiments of Section 7 use the stop words in [6]. For example, w 3 appears three times in S (F 3 (S) = 3), five times in D 2 (F 3 (D 2 ) = 5), and it does not appear in D 1 (F 3 (D 1 ) = 0). <p> So, for T = 0:80, SCAM would not consider D 2 to be a potential copy of S. However, SCAM would find D 1 suspiciously close to S. Even though the SCAM similarity does not take into account word sequencing, the experiments in <ref> [5, 6] </ref> show that it detects potential copies relatively well. In these experiments, conducted with 50,000 netnews articles, false positives were very rare: the similarity measure flagged unrelated documents as copies (because they shared common vocabulary) in only 0:01% of the cases. <p> Furthermore, such prevention schemes can be broken by using software emulators [16] and recording documents. Instead of placing restrictions on the distribution of documents, another approach to protecting digital documents (one we subscribe to) is to detect illegal copies using registration server mechanisms such as SCAM <ref> [5, 6] </ref> or COPS [16]. Once we know a document to be an illegal copy, it is sometimes useful to know the originator of the illegal copy.
Reference: [7] <author> Narayanan Shivakumar and Hector Garca-Molina. </author> <note> Information on SCAM. Available as http://- www-db.stanford.edu/~shiva/SCAM/scamInfo.- html. </note>
Reference-contexts: The Stanford Copy Analysis Mechanism (SCAM) [5, 6] played an important role in identifying the papers that Mr. X had plagiarized. (See <ref> [7, 1] </ref> for further details.) SCAM is a registration server mechanism that helps flag document-copyright violations in Digital Libraries. The target is not simply academic plagiarism, but any type of copying that can financially hurt authors and commercial publishers.
Reference: [8] <author> Tak W. Yan and Hector Garca-Molina. </author> <title> Duplicate detection in information dissemination. </title> <booktitle> In Proceedings of the 1995 Very Large Databases Conference (VLDB'95), </booktitle> <address> Zurich, Switzerland, </address> <month> September </month> <year> 1995. </year>
Reference-contexts: The target is not simply academic plagiarism, but any type of copying that can financially hurt authors and commercial publishers. SCAM is also useful for removing duplicates and near-duplicates in information retrieval systems <ref> [8] </ref>. Essentially, SCAM keeps a large database of documents along with indices to support efficient retrieval of stored documents that are "potential copies." SCAM attempts to find not just identical copies, but also cases of "substantial" overlap. <p> Also, dSCAM knows, for example, that word w 2 appears in db with in-document frequencies between [f 2 (db); F 2 (db)] = <ref> [3; 8] </ref>. Then, the interesting range of frequencies of w 2 in db is [m 2 ; M 2 ] = [3; 8] " [2; 5] = [3; 5]. <p> Also, dSCAM knows, for example, that word w 2 appears in db with in-document frequencies between [f 2 (db); F 2 (db)] = <ref> [3; 8] </ref>. Then, the interesting range of frequencies of w 2 in db is [m 2 ; M 2 ] = [3; 8] " [2; 5] = [3; 5]. The maximum such frequency is M 2 (db; S) = 5. (Notice that there is no document D in db with F 2 (D) = 5.
Reference: [9] <author> R. E. Kahn. Deposit, </author> <title> registration and recordation in an electronic copyright management system. </title> <type> Technical report, </type> <institution> Corporation for National Research Initiatives, Reston, Virginia, </institution> <month> August </month> <year> 1992. </year>
Reference-contexts: Documents flagged by SCAM have to be checked manually for actual violations since the copying may have been legal and since SCAM may produce some false positives. The basic SCAM system requires a database of registered documents. In the future, publishers may indeed establish such "copyright registration servers" <ref> [9] </ref>, and these servers can then automatically check public sources such as netnews articles and WWW/FTP sites for copies of the registered documents.
Reference: [10] <author> Luis Gravano, Hector Garca-Molina, and Anthony Tomasic. </author> <title> The effectiveness of GlOSS for the text-database discovery problem. </title> <booktitle> In Proceedings of the 1994 ACM SIGMOD Conference, </booktitle> <month> May </month> <year> 1994. </year>
Reference-contexts: For the discovery phase, we build on previous work in the resource-discovery area, more specifically, on the GlOSS approach <ref> [10, 11] </ref>. The idea is to collect in advance "metainformation" about the candidate databases. This can include, for example, information on how frequently terms appear in documents at a particular database. <p> small overlaps in text. dSCAM builds on work in the resource-discovery area. (See [20, 21] for surveys.) This work usually focuses on finding the "best" sources for a query, where the best sources are usually those with the largest number of "relevant" documents for the query. (See for example [22], <ref> [10, 11] </ref>, and [23].) These schemes are not tuned to choose databases with a potential copy of a suspicious document, in the sense of Section 2.
Reference: [11] <author> Luis Gravano and Hector Garca-Molina. </author> <title> Generalizing GlOSS for vector-space databases and broker hierarchies. </title> <booktitle> In Proceedings of the 21st International Conference on Very Large Data Bases (VLDB'95), </booktitle> <pages> pages 78-89, </pages> <month> September </month> <year> 1995. </year>
Reference-contexts: For the discovery phase, we build on previous work in the resource-discovery area, more specifically, on the GlOSS approach <ref> [10, 11] </ref>. The idea is to collect in advance "metainformation" about the candidate databases. This can include, for example, information on how frequently terms appear in documents at a particular database. <p> small overlaps in text. dSCAM builds on work in the resource-discovery area. (See [20, 21] for surveys.) This work usually focuses on finding the "best" sources for a query, where the best sources are usually those with the largest number of "relevant" documents for the query. (See for example [22], <ref> [10, 11] </ref>, and [23].) These schemes are not tuned to choose databases with a potential copy of a suspicious document, in the sense of Section 2.
Reference: [12] <author> Thomas H. Cormen, Charles E. Leiserson, and Ronald L. Rivest. </author> <title> Introduction to algorithms. </title> <publisher> The MIT Press, </publisher> <year> 1991. </year>
Reference-contexts: Thus, p i = Sel (w i ; db). By minimizing the added selectivity we will tend to minimize the number of documents that we retrieve from db. We will find an optimal solution for this problem by reducing it to the 0-1 knapsack problem <ref> [12] </ref>. The new formulation of the problem is as follows. A thief robbing a store finds N items (the words). The ith item is worth p i dollars (the selectivity of word w i ) and weighs C i (db; S) pounds (the maximum contribution of w i ). <p> Assuming that T , the C i 's, and the p i 's have a fixed number of significant decimals, we can use dynamic programming to solve the problem in O (T N ) time, where N is the number of words in the suspicious document <ref> [12] </ref>. 7 Experiments This section presents experimental results for dSCAM.
Reference: [13] <author> Gerard Salton. </author> <title> Automatic text processing: the transformation, analysis, and retrieval of information by computer. </title> <publisher> Addison Wesley, </publisher> <year> 1989. </year>
Reference-contexts: However, if all a database has is a Boolean-query interface, we have no choice but to ask the right queries to the database to extract all the potential copies of a suspicious document. (How to deal with a vector-space query interface <ref> [13] </ref> is part of our future work.) The results above show that we can do substantially better than the brute-force approach (i.e., when we use all the words in the suspicious document to build a big "or" query) by writing the queries as in Section 6.
Reference: [14] <author> G. J. Popek and C. S. Kline. </author> <title> Encryption and secure computer networks. </title> <journal> ACM Computing Surveys, </journal> <volume> 11(4) </volume> <pages> 331-356, </pages> <month> December </month> <year> 1979. </year>
Reference-contexts: Some systems favor the copy prevention approach, for example, by physically isolating information (e.g., by placing information on standalone CD-ROM systems), by using special-purpose hardware for authorization <ref> [14] </ref>, or by using active documents (e.g., documents encapsulated by programs [15]). We believe such prevention schemes are cumbersome, and may make it difficult for honest users to share information. Furthermore, such prevention schemes can be broken by using software emulators [16] and recording documents.
Reference: [15] <author> G. N. Griswold. </author> <title> A method for protecting copyright on networks. In Joint Harvard MIT Workshop on Technology Strategies for Protecting Intellectual Property in the Networked Multimedia Environment, </title> <month> April </month> <year> 1993. </year>
Reference-contexts: Some systems favor the copy prevention approach, for example, by physically isolating information (e.g., by placing information on standalone CD-ROM systems), by using special-purpose hardware for authorization [14], or by using active documents (e.g., documents encapsulated by programs <ref> [15] </ref>). We believe such prevention schemes are cumbersome, and may make it difficult for honest users to share information. Furthermore, such prevention schemes can be broken by using software emulators [16] and recording documents.
Reference: [16] <author> Sergey Brin, James Davis, and Hector Garca-Molina. </author> <title> Copy detection mechanisms for digital documents. </title> <booktitle> In Proceedings of the ACM SIGMOD Annual Conference, </booktitle> <address> San Jose, </address> <month> May </month> <year> 1995. </year>
Reference-contexts: We believe such prevention schemes are cumbersome, and may make it difficult for honest users to share information. Furthermore, such prevention schemes can be broken by using software emulators <ref> [16] </ref> and recording documents. Instead of placing restrictions on the distribution of documents, another approach to protecting digital documents (one we subscribe to) is to detect illegal copies using registration server mechanisms such as SCAM [5, 6] or COPS [16]. <p> Furthermore, such prevention schemes can be broken by using software emulators <ref> [16] </ref> and recording documents. Instead of placing restrictions on the distribution of documents, another approach to protecting digital documents (one we subscribe to) is to detect illegal copies using registration server mechanisms such as SCAM [5, 6] or COPS [16]. Once we know a document to be an illegal copy, it is sometimes useful to know the originator of the illegal copy. <p> This tool is mainly intended for file management applications, and detection of files that are very similar, but not for detecting small text overlaps. The COPS <ref> [16] </ref> and SCAM registration servers however were developed to detect even small overlaps in text. dSCAM builds on work in the resource-discovery area. (See [20, 21] for surveys.) This work usually focuses on finding the "best" sources for a query, where the best sources are usually those with the largest number
Reference: [17] <author> J. Brassil, S. Low, N. Maxemchuk, and L. O'Gorman. </author> <title> Document marking and identification using both line and word shifting. </title> <type> Technical report, </type> <institution> AT&T Bell Laboratories, </institution> <year> 1994. </year>
Reference-contexts: For the remaining cases, Accept (w 1 ; F 1 (S)) = [1; 1], Accept (w 2 ; F 2 (S)) = [2; 5], and Accept (w 4 ; F 4 (S)) = <ref> [5; 17] </ref>. Then, c (S; D 1 ) = fw 1 ; w 2 g, and c (S; D 2 ) = fw 3 g. After finding the closeness set for S and D, SCAM computes the similarity sim (S; D) between the two documents. <p> We have already computed Accept (w 1 ; F 1 (S)) = [1; 1], Accept (w 2 ; F 2 (S)) = [2; 5], Accept (w 3 ; F 3 (S)) = [2; 5], and Accept (w 4 ; F 4 (S)) = <ref> [5; 17] </ref>. Also, dSCAM knows, for example, that word w 2 appears in db with in-document frequencies between [f 2 (db); F 2 (db)] = [3; 8]. <p> Once we know a document to be an illegal copy, it is sometimes useful to know the originator of the illegal copy. There have been several proposals <ref> [17, 18] </ref> to add unique "watermarks" to documents (encoded in word spacing or in images) so that one can trace back to the original buyer of that illegal document. A variety of mechanisms have been suggested for registration servers.
Reference: [18] <author> A. Choudhury, N. Maxemchuk, S. Paul, and H. Schulzrinne. </author> <title> Copyright protection for electronic publishing over computer networks. </title> <type> Technical report, </type> <institution> AT&T Bell Laboratories, </institution> <year> 1994. </year>
Reference-contexts: Once we know a document to be an illegal copy, it is sometimes useful to know the originator of the illegal copy. There have been several proposals <ref> [17, 18] </ref> to add unique "watermarks" to documents (encoded in word spacing or in images) so that one can trace back to the original buyer of that illegal document. A variety of mechanisms have been suggested for registration servers.
Reference: [19] <author> U. Manber and S. Wu. Glimpse: </author> <title> A tool to search through entire file systems. </title> <booktitle> In Proceedings of the Winter USENIX Conference, </booktitle> <month> January </month> <year> 1994. </year>
Reference-contexts: There have been several proposals [17, 18] to add unique "watermarks" to documents (encoded in word spacing or in images) so that one can trace back to the original buyer of that illegal document. A variety of mechanisms have been suggested for registration servers. In <ref> [19] </ref>, a few words in a document are chosen as anchors and checksums of a following window of characters are computed. "Similar" files can then be found by comparing these checksums that are registered into a database.
Reference: [20] <author> Michael F. Schwartz, Alan Emtage, Brewster Kahle, and B. Clifford Neuman. </author> <title> A comparison of Internet resource discovery approaches. </title> <journal> Computer Systems, </journal> <volume> 5(4), </volume> <year> 1992. </year>
Reference-contexts: The COPS [16] and SCAM registration servers however were developed to detect even small overlaps in text. dSCAM builds on work in the resource-discovery area. (See <ref> [20, 21] </ref> for surveys.) This work usually focuses on finding the "best" sources for a query, where the best sources are usually those with the largest number of "relevant" documents for the query. (See for example [22], [10, 11], and [23].) These schemes are not tuned to choose databases with a
Reference: [21] <author> Katia Obraczka, Peter B. Danzig, and Shih-Hao Li. </author> <title> Internet resource discovery services. </title> <booktitle> IEEE Computer, </booktitle> <month> September </month> <year> 1993. </year>
Reference-contexts: The COPS [16] and SCAM registration servers however were developed to detect even small overlaps in text. dSCAM builds on work in the resource-discovery area. (See <ref> [20, 21] </ref> for surveys.) This work usually focuses on finding the "best" sources for a query, where the best sources are usually those with the largest number of "relevant" documents for the query. (See for example [22], [10, 11], and [23].) These schemes are not tuned to choose databases with a
Reference: [22] <author> James P. Callan, Zhihong Lu, and W. Bruce Croft. </author> <title> Searching distributed collections with inference networks. </title> <booktitle> In Proceedings of the 18 th Annual SIGIR Conference, </booktitle> <year> 1995. </year>
Reference-contexts: even small overlaps in text. dSCAM builds on work in the resource-discovery area. (See [20, 21] for surveys.) This work usually focuses on finding the "best" sources for a query, where the best sources are usually those with the largest number of "relevant" documents for the query. (See for example <ref> [22] </ref>, [10, 11], and [23].) These schemes are not tuned to choose databases with a potential copy of a suspicious document, in the sense of Section 2.
Reference: [23] <author> Mark A. Sheldon, Andrzej Duda, Ron Weiss, James W. O'Toole, and David K. Gifford. </author> <title> A content routing system for distributed information servers. </title> <booktitle> In Proceedings of the 4 th International Conference on Extending Database Technology, </booktitle> <year> 1994. </year>
Reference-contexts: text. dSCAM builds on work in the resource-discovery area. (See [20, 21] for surveys.) This work usually focuses on finding the "best" sources for a query, where the best sources are usually those with the largest number of "relevant" documents for the query. (See for example [22], [10, 11], and <ref> [23] </ref>.) These schemes are not tuned to choose databases with a potential copy of a suspicious document, in the sense of Section 2.
References-found: 23

