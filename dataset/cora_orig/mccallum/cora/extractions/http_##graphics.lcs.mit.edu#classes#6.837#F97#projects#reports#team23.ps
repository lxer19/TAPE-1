URL: http://graphics.lcs.mit.edu/classes/6.837/F97/projects/reports/team23.ps
Refering-URL: http://graphics.lcs.mit.edu/classes/6.837/F97/projects/reports.html
Root-URL: 
Email: gering@ai.mit.edu  ekogan@mit.edu  igorlord@mit.edu  
Title: 3DSculptor Integrated Haptic Sculpting and Volume Rendering of MRI Data  
Author: David Gering Edward Kogan Igor Lyubashevskiy 
Abstract: 1. Abstract 
Abstract-found: 1
Intro-found: 1
Reference: 1. <institution> SensAble Technologies, </institution> <note> http://www.sensable.com </note>
Reference-contexts: Our project was to take a first step and experiment with the usefulness of combining haptic rendering with volume rendering. We use the PHANToM (SensAble Technologies, Cambridge MA) <ref> [1] </ref> haptic interface as a virtual tool that can drill away any data it touches or restore data that has already been drilled away. 2.3 Prior Work Sculpting has been used as a volumetric modeling technique in 1991 [2], except the haptic device was a "poor man's force feedback unit" made
Reference: 2. <author> TA Galyean. </author> <title> "Sculpting: An Interactive Volumetric Modeling Technique." </title> <journal> Computer Graphics, </journal> <volume> 25(4) </volume> <pages> 267-274, </pages> <month> July </month> <year> 1991. </year>
Reference-contexts: We use the PHANToM (SensAble Technologies, Cambridge MA) [1] haptic interface as a virtual tool that can drill away any data it touches or restore data that has already been drilled away. 2.3 Prior Work Sculpting has been used as a volumetric modeling technique in 1991 <ref> [2] </ref>, except the haptic device was a "poor man's force feedback unit" made with bungee cords, and surface rendering was employed via the Marching Cubes method [3]. Better haptic devices were then developed at MIT [4] that made it easier to program touch interaction with virtual objects [5].
Reference: 3. <author> WE Lorenson and HE Cline. </author> <title> "Marching Cubes: A high resolution 3D surface construction algorithm." </title> <journal> Computer Graphics, </journal> <volume> 21(4) </volume> <pages> 163-169, </pages> <month> July </month> <year> 1987. </year>
Reference-contexts: touches or restore data that has already been drilled away. 2.3 Prior Work Sculpting has been used as a volumetric modeling technique in 1991 [2], except the haptic device was a "poor man's force feedback unit" made with bungee cords, and surface rendering was employed via the Marching Cubes method <ref> [3] </ref>. Better haptic devices were then developed at MIT [4] that made it easier to program touch interaction with virtual objects [5]. This device was just recently integrated with volume rendering [6].
Reference: 4. <author> TH Massie. </author> <title> "Design of a Three Degree of Freedom Force-Reflecting Haptic Interface." </title> <type> SB thesis, </type> <institution> MIT EECS Department, </institution> <month> May </month> <year> 1993. </year>
Reference-contexts: Better haptic devices were then developed at MIT <ref> [4] </ref> that made it easier to program touch interaction with virtual objects [5]. This device was just recently integrated with volume rendering [6].
Reference: 5. <author> K Salisbury, D Brock, T Massie, N Swarup, </author> <title> C Zilles. "Haptic Rendering: Programming Touch Interaction with Virtual Objects.", 1995 Symposium on Interactive 3D Graphics, </title> <address> pp123-130, </address> <year> 1995. </year>
Reference-contexts: Better haptic devices were then developed at MIT [4] that made it easier to program touch interaction with virtual objects <ref> [5] </ref>. This device was just recently integrated with volume rendering [6]. Our approach employs a similar means of using hardware to speed the volume rendering [7], but differs slightly in our multi-threaded, tightly coupled system architecture that achieves good interactivity, and our application to OCS.
Reference: 6. <author> RS Avila, LM Sobierajski, </author> <title> "A Haptic Interation Method for Volume Visualization." </title> <booktitle> IEEE Visualization '96, </booktitle> <month> Oct </month> <year> 1996. </year>
Reference-contexts: Better haptic devices were then developed at MIT [4] that made it easier to program touch interaction with virtual objects [5]. This device was just recently integrated with volume rendering <ref> [6] </ref>. Our approach employs a similar means of using hardware to speed the volume rendering [7], but differs slightly in our multi-threaded, tightly coupled system architecture that achieves good interactivity, and our application to OCS.
Reference: 7. <author> LM Sobierajski, </author> <title> RS Avila, "A Hardware Acceleration Method for Volumetric Ray Tracing." </title>
Reference-contexts: Better haptic devices were then developed at MIT [4] that made it easier to program touch interaction with virtual objects [5]. This device was just recently integrated with volume rendering [6]. Our approach employs a similar means of using hardware to speed the volume rendering <ref> [7] </ref>, but differs slightly in our multi-threaded, tightly coupled system architecture that achieves good interactivity, and our application to OCS. We relied on the techniques presented in lecture and Hearn and Baker to create a rendering pipeline from scratch, handle geometric transformations, implement ray-casting, and support various viewing options. 3. <p> computed and stored as: ray_stop = ray_origin + ray_direction * t1 ray_length = Magnitude (ray_stop - ray_start) num_steps = ray_length / step_size 4.5.3 Polygon Assisted Ray Casting (PARC) The second way to compute the ray_start and num_steps employs the graphics hardware as a faster alternative to the bounding box method <ref> [7] </ref>. The Open GL depth function is set such that if a point on a polygon has a depth less than that already stored in the depth buffer, then the buffer is overwritten.
Reference: 8. <institution> The Visualization Toolkit, </institution> <note> http://www.cs.rpi.edu/~martink </note>
Reference-contexts: In the hands of a novice operator, the system could crash or produce incorrect results, but experienced operators can really have fun with it. We originally planned on constructing the graphical user interface using Tcl/Tk, and perform the volume rendering and medical data reading using the Visualization Toolkit (VTK) <ref> [8] </ref>. However, VTK is a complex hierarchy of object-oriented classes structured to run on multiple platforms and graphics libraries. We needed a simple volume rendering pipeline that could be very tightly coupled with the haptics rendering to provide the fastest possible updates to produce an interactive system.

References-found: 8

