URL: http://www.ri.cmu.edu/afs/cs.cmu.edu/project/scandal/public/papers/pipelining-spaa97.ps.gz
Refering-URL: http://www.ri.cmu.edu/afs/cs.cmu.edu/project/scandal/public/papers/pipelining-spaa97.html
Root-URL: 
Email: fguyb,mrmillerg@cs.cmu.edu  
Title: Pipelining with Futures  
Author: Guy E. Blelloch Margaret Reid-Miller 
Address: Pittsburgh, PA 15213-3890  
Affiliation: School of Computer Science Carnegie Mellon University  
Abstract: Pipelining has been used in the design of many PRAM algorithms to reduce their asymptotic running time. Paul, Vishkin and Wagener (PVW) used the approach in a parallel implementation of 2-3 trees. The approach was later used by Cole in the first O(lg n) time sorting algorithm on the PRAM not based on the AKS sorting network, and has since been used to improve the time of several other algorithms. Although the approach has improved the asymptotic time of many algorithms, there are two practical problems: maintaining the pipeline is quite complicated for the programmer, and it forces the code to be executed in a highly synchronous manner, making it harder to schedule for locality or space efficiency. In this paper we show how futures (a parallel language construct) can be used to implement pipelining without requiring the user to code it explicitly, allowing for much simpler code and more asynchronous execution. A runtime system then manages the pipelining implicitly. As with user-managed pipelining, we show how the technique reduces the depth of many algorithms by a logarithmic factor over the nonpipelined version. We describe and analyze four algorithms for which this is the case: a parallel merging algorithm on trees, a parallel version of insertion into and deletion from randomized balanced trees (treaps), and insertion into a variant of the PVW 2-3 trees. To determine the runtime of algorithms we first analyze algorithms in a language-based cost model in terms of the work w and depth d of computations, and then show universal bounds for implementing the language on various machine models. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. Abramsky. </author> <title> Computational interpretations of linear logic. </title> <journal> Theoretical Computer Science, </journal> <volume> 111 </volume> <pages> 3-57, </pages> <year> 1993. </year>
Reference-contexts: Linear code has been studied extensively in the programming language community in the context of various memory optimizations, such as updating functional data in place or simplifying memory management <ref> [26, 31, 5, 1, 18] </ref>. Linearizing code does not affect the performance of any of the algorithms we have considered in this paper. For example, consider the body of the split code in Figure 2, lines 4-11.
Reference: [2] <author> M. Ajtai, J. Komlos, and E. Szemeredi. </author> <title> An O(n lg n) sorting network. </title> <booktitle> In Proc. ACM Symposium on Theory of Computing, </booktitle> <pages> pages 1-9, </pages> <month> Apr. </month> <year> 1983. </year>
Reference-contexts: A similar idea was then used by Cole [19] to develop the first O (lg n) time sorting algorithm for the PRAM that was not based on the AKS sorting network <ref> [2] </ref>, which has very large constants. The algorithm is based on parallel mergesort, and it uses a parallel merge that takes O (lg n) time.
Reference: [3] <author> C. R. Aragon and R. G. Seidel. </author> <title> Randomized search trees. </title> <booktitle> In Proc. Symposium on Foundations of Computer Science, </booktitle> <pages> pages 540-545, </pages> <year> 1989. </year>
Reference-contexts: We show that, by using the same code but implementing it with futures, the depth is reduced to O (lg n), which meets previous depth bounds. The next two algorithms use a parallel implementation of the treap data structure <ref> [3] </ref>. We show randomized algorithms for inserting m keys into and deleting m keys from a treap of size n in O (lg n + lg m) expected depth and O (m lg (n=m)) expected work. Like the merge algorithm, the code is very simple. <p> The recursive call for the left (right) subtree supplies an offset which is the old offset minus (plus) half the subtree size. The analysis of the depth of the algorithm is similar to the analysis of meld in the next section. 4 Treap Meld Treaps <ref> [3] </ref> are balanced search trees that provide for search, insertion, and deletion of keys and can be used for maintaining a dynamic dictionary. Associated with each key in a treap is a random priority value. <p> That is, the treaps have valid t -values, t 1 and t 2 , with t 1 &lt; t and t 2 &lt; t. Since the expected heights of the two treaps is O (lg n) and O (lg m) <ref> [3] </ref>, the expected depth to meld them is O (lg n + lg m). Theorem 4.4 The expected work to meld two treaps of size n and m; m &lt; n is O (m lg (n=m)). Proof. See [29].
Reference: [4] <author> M. J. Atallah, R. Cole, and M. T. Goodrich. </author> <title> Cascading divide-and-conquer: A technique for designing parallel algorithms. </title> <journal> SIAM Journal of Computing, </journal> <volume> 18(3) </volume> <pages> 499-532, </pages> <month> June </month> <year> 1989. </year>
Reference-contexts: The basic idea of Cole's mergesort was later used in a technique called cascading divide-and-conquer, which improved the time of many computational geometry algorithms <ref> [4] </ref>. Although pipelining has lead to theoretical improvements in algorithms, from a practical point of view pipelining can be very cumbersome for the programmer|managing the pipeline involves careful timing among the pipeline tasks and assumes a highly synchronous model.
Reference: [5] <author> H. Baker. </author> <title> Lively linear lisp | `Look Ma, no garbage!'. </title> <journal> ACM SIGPLAN Notices, </journal> <volume> 27(8) </volume> <pages> 89-98, </pages> <month> Aug. </month> <year> 1992. </year>
Reference-contexts: Linear code has been studied extensively in the programming language community in the context of various memory optimizations, such as updating functional data in place or simplifying memory management <ref> [26, 31, 5, 1, 18] </ref>. Linearizing code does not affect the performance of any of the algorithms we have considered in this paper. For example, consider the body of the split code in Figure 2, lines 4-11.
Reference: [6] <author> H. G. Baker and C. Hewitt. </author> <title> The incremental garbage collection of processes. </title> <journal> ACM Sigplan Notices, </journal> <volume> 12(8) </volume> <pages> 55-59, </pages> <month> Aug. </month> <year> 1977. </year>
Reference-contexts: The central idea of this paper is to show that many algorithms can be automatically pipelined using the futures construct, alleviating these problems. The futures construct was developed in the late 70s for expressing parallelism in programming languages <ref> [21, 6] </ref> and has been included in several programming languages [24, 25, 15, 17, 16]. Conceptually the future construct forks a new thread t 1 to calculate a value (evaluate an expression) and immediately returns a pointer to where the result of t 1 will be written.
Reference: [7] <author> G. Blelloch, P. Gibbons, and Y. Matias. </author> <title> Provably efficient scheduling for languages with fine-grained parallelism. </title> <booktitle> In Proc. ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 1-12, </pages> <month> July </month> <year> 1995. </year>
Reference-contexts: This gives freedom to the implementation as to how to schedule the tasks. The implementation, for example, could optimize the schedule for either space efficiency <ref> [12, 7, 8] </ref> or locality [13]. On a uniprocessor the implementation could run the code in a purely sequential mode without any need for synchronization. We are not yet sure how general the approach is.
Reference: [8] <author> G. Blelloch, P. Gibbons, Y. Matias, and G. Narlikar. </author> <title> Space-efficient scheduling of parallelism with synchronization variables. </title> <booktitle> In Proc. ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <month> June </month> <year> 1997. </year>
Reference-contexts: This gives freedom to the implementation as to how to schedule the tasks. The implementation, for example, could optimize the schedule for either space efficiency <ref> [12, 7, 8] </ref> or locality [13]. On a uniprocessor the implementation could run the code in a purely sequential mode without any need for synchronization. We are not yet sure how general the approach is.
Reference: [9] <author> G. Blelloch. </author> <title> Scans as primitive parallel operations. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-38(11):1526-1538, </volume> <month> Nov. </month> <year> 1989. </year>
Reference-contexts: Our implementation also implies time bounds of O (gw=p + d (T s (p) + L)) on the BSP [30], O (w=p + d lg p) on an Asynchronous EREW PRAM [20], and O (w=p + d) on the EREW Scan model <ref> [9] </ref>. The conversion to linear code is a simple manipulation that can be done by a compiler. Although this conversion can potentially increase the work and/or depth of a computation, it does not for any of the algorithms described in this paper. <p> We now consider the main result of this section. Here we state the bounds in terms of the EREW scan model <ref> [9] </ref>, which is the EREW extended with a unit-time scan (all-prefix-sums) operation. <p> The array split can be implemented by broadcasting the pivot, comparing the array elements to it, executing two scans to determine the final locations of the array elements, and writing the values to these locations (see <ref> [9] </ref> for example). Each can be implemented with O (n) work and O (1) depth in a similar way as described above.
Reference: [10] <author> G. Blelloch. </author> <title> Programming parallel algorithms. </title> <journal> Communications of the ACM, </journal> <volume> 39(3) </volume> <pages> 85-97, </pages> <month> Mar. </month> <year> 1996. </year>
Reference-contexts: This paper is part of our larger research theme of studying language-based cost models, as opposed to machine-based models, and is an extension of our work on the NESL programming language and its corresponding cost model based on work and depth (summarized in <ref> [10] </ref>). Acknowledgements We would like to thank Jonathan Hardwick and Girija Narlikar for looking over drafts of this paper and making several useful comments.
Reference: [11] <author> G. Blelloch and J. Greiner. </author> <title> A provable time and space efficient implementation of NESL. </title> <booktitle> In Proc. ACM SIGPLAN International Conference on Functional Programming, </booktitle> <month> May </month> <year> 1996. </year>
Reference-contexts: The model, as defined here, is basically the PSL (Parallel Speculative -Calculus) [23], augmented with arrays as in NESL <ref> [11] </ref>. Although the PSL only considered the pure - Calculus with arithmetic operations, the syntactic sugar we have included only affects work and depth by a constant factor.
Reference: [12] <author> R. D. Blumofe and C. E. Leiserson. </author> <title> Space-efficient scheduling of multithreaded computations. </title> <booktitle> In Proc. ACM Symposium on the Theory of Computing, </booktitle> <pages> pages 362-371, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: of our model to the PRAM comes from the allocation of tasks to processors and not by the pipelining itself; in the PRAM the processor allocation needs to be done by the user and often requires significant effort. 2 2 The Model As with the work of Blumofe and Leiserson <ref> [12, 13] </ref> we model a computation as a set of threads and the cost as a directed acyclic graph (DAG). Threads can fork new threads using a future, and can synchronize by requesting a value written by another thread. <p> Since, on each step, the implementation processes minfjSj; pg actions, and S holds all the ready actions (by definition), the implementation will execute a greedy schedule of the computation DAG. The number of steps is therefore bound by w=p + d <ref> [12] </ref> and the total time by O (w=p + d). We now outline how to handle the array split operation used in the 2-6 trees. <p> This gives freedom to the implementation as to how to schedule the tasks. The implementation, for example, could optimize the schedule for either space efficiency <ref> [12, 7, 8] </ref> or locality [13]. On a uniprocessor the implementation could run the code in a purely sequential mode without any need for synchronization. We are not yet sure how general the approach is.
Reference: [13] <author> R. D. Blumofe and C. E. Leiserson. </author> <title> Scheduling mul-tithreaded computations by work stealing. </title> <booktitle> In Proc. Symposium on Foundations of Computer Science, </booktitle> <pages> pages 356-368, </pages> <month> Nov. </month> <year> 1994. </year> <month> 10 </month>
Reference-contexts: of our model to the PRAM comes from the allocation of tasks to processors and not by the pipelining itself; in the PRAM the processor allocation needs to be done by the user and often requires significant effort. 2 2 The Model As with the work of Blumofe and Leiserson <ref> [12, 13] </ref> we model a computation as a set of threads and the cost as a directed acyclic graph (DAG). Threads can fork new threads using a future, and can synchronize by requesting a value written by another thread. <p> This gives freedom to the implementation as to how to schedule the tasks. The implementation, for example, could optimize the schedule for either space efficiency [12, 7, 8] or locality <ref> [13] </ref>. On a uniprocessor the implementation could run the code in a purely sequential mode without any need for synchronization. We are not yet sure how general the approach is.
Reference: [14] <author> R. P. Brent. </author> <title> The parallel evaluation of general arith-metic expressions. </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> 21(2) </volume> <pages> 201-206, </pages> <year> 1974. </year>
Reference-contexts: In both cases the work is O (m lg n). To complete the analysis we next consider implementations of the language-based model on various machines. The work and depth costs along with Brent's scheduling principle <ref> [14] </ref> imply that, given a computation with depth d and work w, there is a schedule of actions onto processors such that the computation will run in w=p + d time on a p processor PRAM.
Reference: [15] <author> D. Callahan and B. Smith. </author> <title> A future-based parallel language for a general-purpose highly-parallel computer. </title> <editor> In D. Padua, D. Gelernter, and A. Nicolau, editors, </editor> <booktitle> Languages and Compilers for Parallel Computing, Research Monographs in Parallel and Distributed Computing, </booktitle> <pages> pages 95-113. </pages> <publisher> The MIT Press, </publisher> <year> 1990. </year>
Reference-contexts: The central idea of this paper is to show that many algorithms can be automatically pipelined using the futures construct, alleviating these problems. The futures construct was developed in the late 70s for expressing parallelism in programming languages [21, 6] and has been included in several programming languages <ref> [24, 25, 15, 17, 16] </ref>. Conceptually the future construct forks a new thread t 1 to calculate a value (evaluate an expression) and immediately returns a pointer to where the result of t 1 will be written. This pointer can then be passed to other threads.
Reference: [16] <author> M. C. Carlisle, A. Rogers, J. H. Reppy, and L. J. Hendren. </author> <title> Early experiences with OLDEN (parallel programming). </title> <booktitle> In Proc. 6th International Workshop on Languages and Compilers for Parallel Computing, </booktitle> <pages> pages 1-20. </pages> <publisher> Springer-Verlag, </publisher> <month> Aug. </month> <year> 1993. </year>
Reference-contexts: The central idea of this paper is to show that many algorithms can be automatically pipelined using the futures construct, alleviating these problems. The futures construct was developed in the late 70s for expressing parallelism in programming languages [21, 6] and has been included in several programming languages <ref> [24, 25, 15, 17, 16] </ref>. Conceptually the future construct forks a new thread t 1 to calculate a value (evaluate an expression) and immediately returns a pointer to where the result of t 1 will be written. This pointer can then be passed to other threads.
Reference: [17] <author> R. Chandra, A. Gupta, and J. Hennessy. </author> <title> COOL: A Language for Parallel Programming. </title> <editor> In D. Padua, D. Gel-ernter, and A. Nicolau, editors, </editor> <booktitle> Languages and Compilers for Parallel Computing, Research Monographs in Parallel and Distributed Computing, </booktitle> <pages> pages 126-148. </pages> <publisher> The MIT Press, </publisher> <year> 1990. </year>
Reference-contexts: The central idea of this paper is to show that many algorithms can be automatically pipelined using the futures construct, alleviating these problems. The futures construct was developed in the late 70s for expressing parallelism in programming languages [21, 6] and has been included in several programming languages <ref> [24, 25, 15, 17, 16] </ref>. Conceptually the future construct forks a new thread t 1 to calculate a value (evaluate an expression) and immediately returns a pointer to where the result of t 1 will be written. This pointer can then be passed to other threads.
Reference: [18] <author> J. L. Chirimar, C. A. Gunter, and J. G. Riecke. </author> <title> Reference counting as a computational interpretation of linear logic. </title> <journal> Journal of Functional Programming, </journal> <volume> 6(2) </volume> <pages> 195-244, </pages> <month> Mar. </month> <year> 1996. </year>
Reference-contexts: Linear code has been studied extensively in the programming language community in the context of various memory optimizations, such as updating functional data in place or simplifying memory management <ref> [26, 31, 5, 1, 18] </ref>. Linearizing code does not affect the performance of any of the algorithms we have considered in this paper. For example, consider the body of the split code in Figure 2, lines 4-11.
Reference: [19] <author> R. Cole. </author> <title> Parallel merge sort. </title> <journal> SIAM Journal of Computing, </journal> <volume> 17(4) </volume> <pages> 770-785, </pages> <month> Aug. </month> <year> 1988. </year>
Reference-contexts: The idea is that when task i is working on level j of the tree, task i + 1 can work on level j 1, and so on. A similar idea was then used by Cole <ref> [19] </ref> to develop the first O (lg n) time sorting algorithm for the PRAM that was not based on the AKS sorting network [2], which has very large constants. The algorithm is based on parallel mergesort, and it uses a parallel merge that takes O (lg n) time.
Reference: [20] <author> R. Cole and O. Zajicek. </author> <title> The APRAM: Incorporating asynchrony into the PRAM model. </title> <booktitle> In Proc. ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 169-178, </pages> <month> June </month> <year> 1989. </year>
Reference-contexts: Our implementation also implies time bounds of O (gw=p + d (T s (p) + L)) on the BSP [30], O (w=p + d lg p) on an Asynchronous EREW PRAM <ref> [20] </ref>, and O (w=p + d) on the EREW Scan model [9]. The conversion to linear code is a simple manipulation that can be done by a compiler. <p> The bounds we prove on the scan model imply bounds of O (w=p + d lg p) time on the plain EREW PRAM, O (gw=p + d (T s + L)) on the BSP [30], and O (w=p + d lg p) on an Asynchronous EREW PRAM <ref> [20] </ref> using standard simulations. Lemma 7.1 (Implementation of Futures) Any linearized future-based computation with w work and d depth can be simulated on an EREW scan model in O (w=p + d) time. Proof.
Reference: [21] <author> D. P. Friedman and D. S. Wise. </author> <title> Aspects of applicative programming for parallel processing. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-27(4):289-296, </volume> <month> Apr. </month> <year> 1978. </year>
Reference-contexts: The central idea of this paper is to show that many algorithms can be automatically pipelined using the futures construct, alleviating these problems. The futures construct was developed in the late 70s for expressing parallelism in programming languages <ref> [21, 6] </ref> and has been included in several programming languages [24, 25, 15, 17, 16]. Conceptually the future construct forks a new thread t 1 to calculate a value (evaluate an expression) and immediately returns a pointer to where the result of t 1 will be written.
Reference: [22] <author> J.-Y. Girard. </author> <title> Linear logic. </title> <journal> Theoretical Computer Science, </journal> <volume> 50 </volume> <pages> 1-102, </pages> <year> 1987. </year>
Reference-contexts: The linearity restriction is such that any code can easily be converted to be linear, although this can come at the cost of increasing the work or depth of an algorithm. The linearity restriction on code is based on ideas from linear logic <ref> [22] </ref>. In the context of this paper linearizing code implies that whenever a variable is referenced more than once in the code a copy is made implicitly for each use [26].
Reference: [23] <author> J. Greiner and G. Blelloch. </author> <title> A provably time-efficient parallel implementation of full speculation. </title> <booktitle> In Proc. ACM Symposium on Principals of Programming Languages, </booktitle> <pages> pages 309-321, </pages> <month> Jan. </month> <year> 1996. </year>
Reference-contexts: We first consider a language-based cost model based on futures and analyze the algorithms in this model. We then show universal bounds for implementing the model on various machine models. For the language-based model we use a slight variation of the PSL model <ref> [23] </ref>. In this model computations are viewed as dynamically unfolding DAGs where each node is a unit of computation (action) and each edge between nodes represents a dependence implied by the language. <p> We are therefore interested in universal results that place bounds on the time taken by an implementation on various machine models, including all online costs for scheduling and management of futures. Previous results on implementing the PSL <ref> [23] </ref> have shown that any computation with w work and d depth can be implemented online on an CRCW PRAM in O (w=p + d T f (p)) time, where T f (p) is the time for a fetch-and-add (or multi-prefix) on p processors. <p> The model, as defined here, is basically the PSL (Parallel Speculative -Calculus) <ref> [23] </ref>, augmented with arrays as in NESL [11]. Although the PSL only considered the pure - Calculus with arithmetic operations, the syntactic sugar we have included only affects work and depth by a constant factor. <p> The bounds include all costs for handling the suspension and reactivation of threads required by the futures and the cost of scheduling tasks on processors. The implementation is based on that described in <ref> [23] </ref>, but we show that for certain types of code we can improve the bounds. <p> Since multiple threads could suspend on a single cell on any given time step, the implementation needs to be able to add the threads to a queue in parallel. Previ 2 It is also possible to show that t i+1 = t i + 2k b 8 ous work <ref> [23] </ref> has shown that by using dynamically growing arrays to implement the queues in parallel, any computation with w work and d depth will run in O (w=p + d T f (p)) time on a CRCW PRAM, where T f (p) is the latency of a work-efficient fetch-and-add operation on
Reference: [24] <author> R. H. Halstead. </author> <title> MultiLisp: A Language for Concurrent Symbolic Computation. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 7(4) </volume> <pages> 501-538, </pages> <month> Oct. </month> <year> 1985. </year>
Reference-contexts: The central idea of this paper is to show that many algorithms can be automatically pipelined using the futures construct, alleviating these problems. The futures construct was developed in the late 70s for expressing parallelism in programming languages [21, 6] and has been included in several programming languages <ref> [24, 25, 15, 17, 16] </ref>. Conceptually the future construct forks a new thread t 1 to calculate a value (evaluate an expression) and immediately returns a pointer to where the result of t 1 will be written. This pointer can then be passed to other threads. <p> The interesting part of the implementation is handling the suspension and reactivation of threads due to reading and writing to future cells. As suggested for the implementation of Multilisp <ref> [24] </ref>, a queue can be associate with each future cell so that when a thread suspends waiting for a write on that cell, it is added to the queue, and when the write occurs, all the threads on the associated queue are returned to the active set S.
Reference: [25] <author> D. A. Krantz, R. H. Halstead, Jr., and E. Mohr. </author> <month> Mul-T: </month>
Reference-contexts: The central idea of this paper is to show that many algorithms can be automatically pipelined using the futures construct, alleviating these problems. The futures construct was developed in the late 70s for expressing parallelism in programming languages [21, 6] and has been included in several programming languages <ref> [24, 25, 15, 17, 16] </ref>. Conceptually the future construct forks a new thread t 1 to calculate a value (evaluate an expression) and immediately returns a pointer to where the result of t 1 will be written. This pointer can then be passed to other threads.
References-found: 25

