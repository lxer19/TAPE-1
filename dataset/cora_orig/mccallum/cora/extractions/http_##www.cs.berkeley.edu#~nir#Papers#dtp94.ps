URL: http://www.cs.berkeley.edu/~nir/Papers/dtp94.ps
Refering-URL: http://http.cs.berkeley.edu/~nir/publications.html
Root-URL: 
Email: nir@cs.stanford.edu  daphne@cs.berkeley.edu  
Title: Qualitative Planning under Assumptions: A Preliminary Report  
Author: Nir Friedman Daphne Koller 
Address: Stanford, CA 94305  Berkeley, CA 94720  
Affiliation: Department of Computer Science Stanford University  Computer Science Division University of California, Berkeley  
Abstract: Most planners constructed up to now are qualitative: they deal with uncertainty by considering all possible outcomes of each plan, without quantifying their relative likelihood. They then choose a plan that deals with the worst-case scenario. However, it is clearly infeasible to plan for every possible contingency. Even beyond the purely computational considerations, planning for highly unlikely worst-case scenarios can force the agent to choose an overly cautious plan with low utility. One common way to avoid this problem is to make assumptions about the behavior of the world, i.e., assume that certain contingencies are impossible. In this paper, we analyze the paradigm of qualitative planning under assumptions, using decision-theoretic tools. We present conditions that guarantee the existence of optimal assumptions (ones inducing the agent to choose the plan with maximum expected utility). Finally, we sketch how assumptions can be constructed for a certain restricted class of plan ning problems.
Abstract-found: 1
Intro-found: 1
Reference: [DKKN93] <author> T. Dean, L. P. Kaelbling, J. Kirman, and A. Nicholson. </author> <title> Planning with deadlines in stochastic domains. </title> <booktitle> In Proc. National Conference on Artificial Intelligence (AAAI '93), </booktitle> <pages> pages 574-579, </pages> <year> 1993. </year>
Reference-contexts: While this is a very ambitious goal, we believe that progress can be made in domains of certain types. In this paper we did not examine the computational benefits of assumption making. Such an analysis would be applicable to both qualitative and decision-theoretic planning <ref> [DKKN93] </ref>. Finally, there is a close connection between assumptions and default rules. As we pointed out, assumptions are defeasible: an agent might discover that an assumption he made was wrong. In this case, the agent should stop and replan, using a new set of assumptions [FHN72, Wil88].
Reference: [DW91] <author> T. Dean and M. P. Wellman. </author> <title> Planning and Control. </title> <publisher> Morgan Kaufmann, </publisher> <year> 1991. </year>
Reference-contexts: The leaves of the tree represent final states, and are labelled with the utility of that state for the agent. As usual in the literature <ref> [DW91] </ref>, we represent utilities as real numbers. Intuitively, each path from the root to a leaf represents one possible sequence of events leading to a final state.
Reference: [Elk90] <author> C. Elkan. </author> <title> Incremental approximate planning. </title> <booktitle> In Proc. National Conference on Artificial Intelligence (AAAI '90), </booktitle> <pages> pages 145-150, </pages> <year> 1990. </year>
Reference-contexts: This is an implicit assumption about the world. Since assumptions are defeasible, actual systems must monitor the execution of the plan, and replan if necessary [FHN72, Wil88]. Certain planners can be viewed as making assumptions (which are later dropped) in order to quickly derive an abstract or approximate plan <ref> [Sac74, Elk90, GH92] </ref>. In this paper, we ignore the computational benefits of making assumptions, and focus on the issue of constructing assumptions that induce the agent to construct a better plan. <p> In this case, the agent should stop and replan, using a new set of assumptions [FHN72, Wil88]. The process of replacing an assumption with a new one is closely related to belief revision. The connection between assumptions and defaults is not limited to this aspect. For example, in <ref> [Elk90, GH92] </ref>, defaults are used in the planning process in order to focus the search on the difficult aspects of the plan. That is, there is a default assumption that certain subgoals, that are relatively easy to achieve, are in fact achievable.
Reference: [FHN72] <author> R. E. Fikes, P. E. Hart, and N. J. Nils-son. </author> <title> Learning and executing generalized robot plans. </title> <journal> Artificial Intelligence, </journal> <volume> 3 </volume> <pages> 251-288, </pages> <year> 1972. </year>
Reference-contexts: The popular STRIPS assumption [FN71] postulates (among other things [Lif86]) that each plan only has one conceivable outcome. This is an implicit assumption about the world. Since assumptions are defeasible, actual systems must monitor the execution of the plan, and replan if necessary <ref> [FHN72, Wil88] </ref>. Certain planners can be viewed as making assumptions (which are later dropped) in order to quickly derive an abstract or approximate plan [Sac74, Elk90, GH92]. <p> Finally, there is a close connection between assumptions and default rules. As we pointed out, assumptions are defeasible: an agent might discover that an assumption he made was wrong. In this case, the agent should stop and replan, using a new set of assumptions <ref> [FHN72, Wil88] </ref>. The process of replacing an assumption with a new one is closely related to belief revision. The connection between assumptions and defaults is not limited to this aspect.
Reference: [FN71] <author> R. E. Fikes and N. J. Nilsson. </author> <title> STRIPS: A new approach to the application of theorem proving to problem solving. </title> <journal> Artificial Intelligence, </journal> <volume> 2 </volume> <pages> 189-208, </pages> <year> 1971. </year>
Reference-contexts: Systems that use assumptions must monitor the execution of the plan, and replan (using a new set of assumptions) when it fails to achieve its predicated effect. We can view the so called traditional planners as doing qualitative planning under assumptions. The popular STRIPS assumption <ref> [FN71] </ref> postulates (among other things [Lif86]) that each plan only has one conceivable outcome. This is an implicit assumption about the world. Since assumptions are defeasible, actual systems must monitor the execution of the plan, and replan if necessary [FHN72, Wil88].
Reference: [FS77] <author> J. A. Feldman and R. F. Sproull. </author> <booktitle> Decision theory and artificial intelligence II: The hungry monkey. Cognitive Science, </booktitle> <volume> 1 </volume> <pages> 158-192, </pages> <year> 1977. </year>
Reference-contexts: Traditional planning problems can be represented in this form by setting the utility at each leaf to be a certain high value if the goal is achieved (and a low value if it is not), minus the cost of the actions taken on the way <ref> [FS77] </ref>. In general, of course, the agent may not have complete information about the state of the world [Moo85].
Reference: [GH92] <author> M. L. Ginsberg and H. W. Holbrook. </author> <title> What defaults can do that hierarchies can't. </title> <booktitle> In Proceedings 1992 Nonmonotonic Reasoning Workshop, </booktitle> <address> Plymouth, VT, </address> <year> 1992. </year>
Reference-contexts: This is an implicit assumption about the world. Since assumptions are defeasible, actual systems must monitor the execution of the plan, and replan if necessary [FHN72, Wil88]. Certain planners can be viewed as making assumptions (which are later dropped) in order to quickly derive an abstract or approximate plan <ref> [Sac74, Elk90, GH92] </ref>. In this paper, we ignore the computational benefits of making assumptions, and focus on the issue of constructing assumptions that induce the agent to construct a better plan. <p> In this case, the agent should stop and replan, using a new set of assumptions [FHN72, Wil88]. The process of replacing an assumption with a new one is closely related to belief revision. The connection between assumptions and defaults is not limited to this aspect. For example, in <ref> [Elk90, GH92] </ref>, defaults are used in the planning process in order to focus the search on the difficult aspects of the plan. That is, there is a default assumption that certain subgoals, that are relatively easy to achieve, are in fact achievable.
Reference: [GN87] <author> M. R. Genesereth and N. J. Nilsson. </author> <booktitle> Logical Foundations of Artificial Intelligence. </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> Los Altos, CA, </address> <year> 1987. </year>
Reference-contexts: Such planners are typically cautious: they try to construct a plan that guarantees the agent certain minimal utility (e.g., reaching the goal) in all circumstances <ref> [GN87] </ref>. (see also [McD87] for a critical view of this approach.) Quantitative planners maintain a probabilistic model of the world, where each possible outcome is assigned a probability. Such planners construct a plan that achieves the maximum expected utility.
Reference: [HBH89] <author> D. E. Heckerman, J. S. Breese, and E. J. Horvitz. </author> <title> The compilation of decision models. </title> <booktitle> In Proc. Fifth Workshop on Uncertainty in Artificial Intelligence, </booktitle> <year> 1989. </year>
Reference-contexts: More precisely, we postulate an underlying probabilistic model for the world, and define the value of the plan in terms of its expected utility. A similar approach has also been used in the context of knowledge compilation <ref> [LSF86, Hor87, HBH89] </ref>. For example, in the previous example, we assume that there is some probability that the car will fail to start, and use that probability to assign expected utilities to various plans that involve turning the key in the ignition.
Reference: [Hor87] <author> E. J. Horvitz. </author> <title> Problem-solving design: Reasoning about computational value, tradeoffs, and resources. </title> <booktitle> In Proc. NASA Artificial Intelligence Forum, </booktitle> <pages> pages 26-43, </pages> <year> 1987. </year>
Reference-contexts: More precisely, we postulate an underlying probabilistic model for the world, and define the value of the plan in terms of its expected utility. A similar approach has also been used in the context of knowledge compilation <ref> [LSF86, Hor87, HBH89] </ref>. For example, in the previous example, we assume that there is some probability that the car will fail to start, and use that probability to assign expected utilities to various plans that involve turning the key in the ignition.
Reference: [Lif86] <author> V. Lifschitz. </author> <title> On the semantics of STRIPS. </title> <editor> In M. P. Georgeff and A. L. Lansky, editors, </editor> <booktitle> Reasoning about Actions and Plans: Proceedings of the 1986 Workshop, </booktitle> <pages> pages 1-9. </pages> <publisher> Morgan Kauf-mann, </publisher> <year> 1986. </year>
Reference-contexts: We can view the so called traditional planners as doing qualitative planning under assumptions. The popular STRIPS assumption [FN71] postulates (among other things <ref> [Lif86] </ref>) that each plan only has one conceivable outcome. This is an implicit assumption about the world. Since assumptions are defeasible, actual systems must monitor the execution of the plan, and replan if necessary [FHN72, Wil88].
Reference: [LR57] <author> R. D. Luce and H. Raiffa. </author> <title> Games and Decisions. </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1957. </year>
Reference-contexts: We conclude with discussion and open questions. 2 The framework It is convenient to describe any specific planning problem as a tree representing a game between the agent and nature <ref> [LR57] </ref>. The nodes of the tree denote instantaneous snapshots of the world at different points in time.
Reference: [LSF86] <author> C. P. Langlotz, E. H. Shortliffe, and L. M. Fa-gan. </author> <title> Using decision theory to justify heuristics. </title> <booktitle> In Proc. National Conference on Artificial Intelligence (AAAI '86), </booktitle> <pages> pages 215-219, </pages> <year> 1986. </year>
Reference-contexts: More precisely, we postulate an underlying probabilistic model for the world, and define the value of the plan in terms of its expected utility. A similar approach has also been used in the context of knowledge compilation <ref> [LSF86, Hor87, HBH89] </ref>. For example, in the previous example, we assume that there is some probability that the car will fail to start, and use that probability to assign expected utilities to various plans that involve turning the key in the ignition.
Reference: [McD87] <author> D. McDermott. </author> <title> A critique of pure reasoning. </title> <journal> Computational Intelligence, </journal> <volume> 3(3) </volume> <pages> 151-160, </pages> <year> 1987. </year>
Reference-contexts: Such planners are typically cautious: they try to construct a plan that guarantees the agent certain minimal utility (e.g., reaching the goal) in all circumstances [GN87]. (see also <ref> [McD87] </ref> for a critical view of this approach.) Quantitative planners maintain a probabilistic model of the world, where each possible outcome is assigned a probability. Such planners construct a plan that achieves the maximum expected utility.
Reference: [Moo85] <author> R. C. Moore. </author> <title> A formal theory of knowledge and action. </title> <editor> In J. Hobbs and R. C. Moore, editors, </editor> <booktitle> Formal Theories of the Commonsense World, </booktitle> <pages> pages 319-358. </pages> <publisher> Ablex Publishing Corp., </publisher> <address> Nor-wood, NJ, </address> <year> 1985. </year>
Reference-contexts: In general, of course, the agent may not have complete information about the state of the world <ref> [Moo85] </ref>. In order to represent this, the decision nodes belonging to the agent are partitioned into information sets V A 1 ; : : : ; V A Intuitively, the agent cannot differentiate between different nodes in the same information set.
Reference: [Pea89] <author> J. Pearl. </author> <title> Probabilistic semantics for nonmono-tonic reasoning: A survey. </title> <editor> In R. J. Brach-man, H. J. Levesque, and R. Reiter, editors, </editor> <booktitle> Proc. First International Conference on Principles of Knowledge Representation and Reasoning (KR '89), </booktitle> <pages> pages 505-516, </pages> <year> 1989. </year>
Reference-contexts: Using the techniques of Section 4, we can determine (based on the probabilities and utilities in the domain) when we can safely assume that a contingency does not happen. This extends the the idea of probabilistic semantics for defaults <ref> [Pea89] </ref> (e.g., *-semantics) to incorporate utilities. We are currently investigating these and other connections between assumptions and defaults.
Reference: [Sac74] <author> E. Sacerdoti. </author> <title> Planning in a hierarchy of abstraction spaces. </title> <journal> Artificial Intelligence, </journal> <volume> 5 </volume> <pages> 115-135, </pages> <year> 1974. </year>
Reference-contexts: This is an implicit assumption about the world. Since assumptions are defeasible, actual systems must monitor the execution of the plan, and replan if necessary [FHN72, Wil88]. Certain planners can be viewed as making assumptions (which are later dropped) in order to quickly derive an abstract or approximate plan <ref> [Sac74, Elk90, GH92] </ref>. In this paper, we ignore the computational benefits of making assumptions, and focus on the issue of constructing assumptions that induce the agent to construct a better plan.
Reference: [Wil88] <author> D. E. Wilkins. </author> <title> Practical Planning: Extending the Classical AI Planning Paradigm. </title> <publisher> Morgan Kaufmann, </publisher> <address> Los Altos, CA, </address> <year> 1988. </year>
Reference-contexts: The popular STRIPS assumption [FN71] postulates (among other things [Lif86]) that each plan only has one conceivable outcome. This is an implicit assumption about the world. Since assumptions are defeasible, actual systems must monitor the execution of the plan, and replan if necessary <ref> [FHN72, Wil88] </ref>. Certain planners can be viewed as making assumptions (which are later dropped) in order to quickly derive an abstract or approximate plan [Sac74, Elk90, GH92]. <p> Finally, there is a close connection between assumptions and default rules. As we pointed out, assumptions are defeasible: an agent might discover that an assumption he made was wrong. In this case, the agent should stop and replan, using a new set of assumptions <ref> [FHN72, Wil88] </ref>. The process of replacing an assumption with a new one is closely related to belief revision. The connection between assumptions and defaults is not limited to this aspect.
References-found: 18

