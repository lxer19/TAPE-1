URL: http://www.cs.dartmouth.edu/~jmd/Xconference.ps.Z
Refering-URL: http://www.cs.dartmouth.edu/~jmd/decs/DECSpage.html
Root-URL: http://www.cs.dartmouth.edu
Title: Previewing PostScript over a Telephone in 3 Seconds Per Page  
Author: John M. Danskin 
Abstract: I have developed an X Protocol compression scheme called Higher Bandwidth X (HBX). This paper describes one aspect of HBX: POSTSCRIPT previewing. Using statistical models and arithmetic coding, HBX compresses the X protocol stream resulting from using ghostscript to preview documents by about 20:1, roughly 8 times the compression achieved by Xremote on the same stream. This is about 12 bits per source character after compression, implying a transmission time of about 3 seconds per page for normally formatted documents (3600 characters per page) using a standard 14400 bps modem. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Bell, Timothy C., John G. Cleary, and Ian H. Witten, </author> <title> "Text Compression," </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1990 </year>
Reference-contexts: These histograms are used to generate an expected probability distribution for the values of fields in messages in the X protocol. Given a probability distribution and a value, HBX uses arithmetic coding (see <ref> [1] </ref>) to produce log 2 p bits of output for each field, where p was the estimated probability of the field assuming the actual value. To the extent that the probability estimates are accurate, this scheme achieves Shannon's lower bound for the size of a message [25]. <p> Details of histogram creation, deletion and pruning of predicted values are explained in more detail in [8]. The contexts used for predicting messages used by ghostscript are explained in Section 5. The escape code technique outlined here for switching between histograms is nicely described in <ref> [1] </ref>. 2. Some fields cannot be effectively predicted by histograms alone. For instance, sequence numbers and timestamp values do not often repeat and are thus very poor candidates for prediction with raw histograms. HBX associates a predictive expression with every X message field.
Reference: [2] <author> Cameron, R.D., </author> <title> "Source encoding using syntactic information source models," </title> <journal> IEEE Transactions on Information Theory. </journal> <pages> (34)4 pp 843-850, </pages> <month> July </month> <year> 1988 </year>
Reference: [3] <author> Cleary, J. and I. Witten, </author> <title> "Data compression using adaptive coding and partial string matching," </title> <journal> IEEE Trans. Communications, COM-32, </journal> <volume> No 4., </volume> <month> 396-402 </month> <year> (1984) </year>
Reference: [4] <author> Cornelius, David, "XRemote: </author> <title> a serial line protocol for X" 6th Annual X Technical Conference, </title> <address> Boston, MA, </address> <year> 1992 </year>
Reference-contexts: Section 8 discusses the limits of compression and further opportunities for compression on this trace. Section 9 summarizes and discusses HBX. Finally, Section 10 contains a status report for the HBX project. Competing Systems Xremote The compression system closest to HBX in design and purpose is the Xremote <ref> [4] </ref> compression protocol for X. <p> New streams are identified with a "NewStream" token, and streams whose sockets have closed are shut down with "CloseStream" tokens. These three extra tokens provide enough information for demultiplexing and stream management. This multiplexing system is similar to the system used by Xremote which is discussed in <ref> [4] </ref>. Messages in these two half duplex streams are logged into two files (client-to-server and server-to-client) with their length, a global sequence number, a unique timestamp, and a magic number which was used to increase programmer confidence in correct parsing of the logged data.
Reference: [5] <author> Danskin, John and Pat Hanrahan, </author> <title> "Profiling the X Protocol,"1994 SigMetrics conference on measurement and modeling of computer systems. </title> <note> Full paper in Technical Report CS-TR-442-94, </note> <institution> Department of Computer Science, Princeton University, Princeton, NJ, </institution> <month> January </month> <year> 1994. </year>
Reference: [6] <author> Danskin, John and Pat Hanrahan, </author> <title> "Compression Performance of the Xremote Protocol," 1994 Data Compression Conference. </title> <note> Full paper in Technical Report CS-TR-441-94, </note> <institution> Department of Computer Science, Princeton University, Princeton, NJ, </institution> <month> January </month> <year> 1994. </year>
Reference-contexts: For the types of data streams considered in this paper, the Delta Compactor is ineffective, and the LZ coder delivers roughly 2.3:1 compression. For more details on Xremote performance see [8] or <ref> [6] </ref>. Fax protocols are not used to compress X, but they are used to transmit documents over phone lines, which is the application I am considering. Note that FAX compression ratios cannot be compared with X protocol compression ratios because the inputs are different.
Reference: [7] <author> Danskin, John, </author> <title> "Higher Bandwidth X," </title> <booktitle> ACM Multimedia 94, Second ACM International Conference on Multimedia. </booktitle> <address> 15-20 October 1994, San Francisco California. </address> <pages> pp 89-96. </pages>
Reference-contexts: This turns large random looking numbers (absolute mouse positions) into small random looking numbers (relative mouse positions), which are much more efficiently predicted by a histogram. By using linear extrapolation to predict mouse positions instead, HBX makes these numbers even smaller and more predictable <ref> [8, 7] </ref>. (Quadratic extrapolation seemed promising, but turned out not to be an improvement over linear extrapolation in practice.) Since encoding simply subtracts an actual value from a predicted value, actual values can be reconstituted in decoding by simply adding the transmitted value to the predicted value.
Reference: [8] <author> Danskin, John, </author> <title> "Compressing graphics protocols for networks, or higher bandwidth X," </title> <type> PhD Thesis, </type> <institution> Department of Computer Science, Princeton University, Princeton, NJ. </institution> <note> Available as Princeton Technical Report CS-TR-465-94. </note>
Reference-contexts: They are very fast, and the LZ coder can be quite effective on the right kind of input. For the types of data streams considered in this paper, the Delta Compactor is ineffective, and the LZ coder delivers roughly 2.3:1 compression. For more details on Xremote performance see <ref> [8] </ref> or [6]. Fax protocols are not used to compress X, but they are used to transmit documents over phone lines, which is the application I am considering. Note that FAX compression ratios cannot be compared with X protocol compression ratios because the inputs are different. <p> For other fields, context strings are carefully assembled from previously coded data to isolate appropriate histograms. Details of histogram creation, deletion and pruning of predicted values are explained in more detail in <ref> [8] </ref>. The contexts used for predicting messages used by ghostscript are explained in Section 5. The escape code technique outlined here for switching between histograms is nicely described in [1]. 2. Some fields cannot be effectively predicted by histograms alone. <p> This turns large random looking numbers (absolute mouse positions) into small random looking numbers (relative mouse positions), which are much more efficiently predicted by a histogram. By using linear extrapolation to predict mouse positions instead, HBX makes these numbers even smaller and more predictable <ref> [8, 7] </ref>. (Quadratic extrapolation seemed promising, but turned out not to be an improvement over linear extrapolation in practice.) Since encoding simply subtracts an actual value from a predicted value, actual values can be reconstituted in decoding by simply adding the transmitted value to the predicted value. <p> For this paper, traces were gathered by running ghostscript non-interactively at full speed. Logging performance measurements suggest that tracing was not a bottleneck for this trace, so that the traces presented represent true system performance. The performance impact of tracing with XTee is discussed further in <ref> [8] </ref>. Ghostscript Traces The experiments presented in this paper are based on two traces from the ghostscript application: ghostscript and ghost2. Images from these traces are presented in Figure 3. The ghostscript trace was generated by a short letter. <p> Any information that has already been encoded can be used to help predict new information. Coordinates values are predicted assuming even lines of text. Small images (character glyphs) are cached whole and predicted as if they were characters in English text. Experimental Results 2.5:1 compression on this trace <ref> [8] </ref>. When I took the trace, the ghostscript program generated about 150K bits/sec. After compression, ghostscript generated less than 7.5K bits/sec which means that with the workstation I used to generate this trace, ghostscript could easily run at full speed over a 14.4Kbps modem.
Reference: [9] <author> Droms Ralph and Wayne R. Dyksen, </author> <title> "Performance measurements of the X window system communication protocol," </title> <journal> Software Practice and Experience vol. </journal> <volume> 20, no. S2, </volume> <month> May </month> <year> 1991. </year>
Reference-contexts: Poor predictions may lead to higher bit rates, but will never lead to inaccurate results. Tracing X In order to make repeatable experiments, I needed to gather X protocol traces. The tracing technique which I adopted was derived from work by Droms and Dyksen <ref> [9] </ref>. They realized that if X clients and the X server converse using Berkeley sockets and TCP/IP, it would be easy to interpose a program between client and server which forwarded traffic in both directions while keeping a complete log.
Reference: [10] <author> Fulton Jim, and Chris Kent Kantarjiev, </author> <title> "An update on low bandwidth X (LBX)," </title> <booktitle> Proceedings of the 7th Annual X Technical Conference, </booktitle> <month> January </month> <year> 1993, </year> <institution> O'Reilly and Associates. </institution> <month> 16 </month>
Reference: [11] <author> Gettys, James, Philip L. Karlton, and Scott Mcgregor, </author> <title> "The X Window System, </title> <note> Version 11," Software Practice and Experience vol. 20(S2), S2/35-S2/67, </note> <month> October </month> <year> 1991 </year>
Reference: [12] <author> Guazzo, M., </author> <title> "A general minimum redundancy source coding algorithm," </title> <journal> IEEE Trans. Information Theory, </journal> <volume> IT-26 (1), </volume> <pages> 15-25, </pages> <month> January </month> <year> 1980. </year>
Reference: [13] <author> Held, Gilbert. </author> <title> "The Complete Modem Reference," </title> <publisher> John Wiley & Sons, Inc. </publisher> <year> 1991 </year>
Reference: [14] <author> Inglis, Stuart, and Ian H. Witten, </author> <title> "Compression-based template matching," </title> <booktitle> Proceedings 1994 Data Compression Conference, </booktitle> <address> March 29-31 Snowbird Utah pp 106-115. </address>
Reference-contexts: This 6 bit pattern (similar patterns appear throughout the literature: see for example <ref> [14] </ref>), picks up both horizontal and vertical patterns in the input image, providing a kind of cheap 2D compression. I experimented with larger and smaller patterns, but this one seemed to give the best compression on my trace suite. <p> This is a much harder problem than the one I have addressed here because of the noise and registration issues associated with scanning. A recent system, which achieved 37.8:1 lossless compression on a library catalog scanned at 400dpi was described in <ref> [14] </ref>. (The high compression ratio is because of all of the white space in a scanned document. HBX's compression ratio is lower because its input has denser content.) In this example HBX has achieved a 5.5:1 expansion with respect to the compressed source text.
Reference: [15] <author> Katajainen, J., M., Penttonen, and J., Teuhola, </author> <title> "Syntax-directed compression of program files," </title> <journal> Software-Practice and Experience, </journal> <volume> 16(3), </volume> <pages> 269-276 </pages>
Reference: [16] <author> McConnell, Kenneth R., Dennis Bodson, and Richard Schaphorst, "FAX: </author> <title> digital facsimile technology and applications," Second Edition, </title> <publisher> Artech House, </publisher> <address> Boston, </address> <year> 1992 </year>
Reference-contexts: The multiple boxes on the server side show that although there is only one X server, there can be many connections and reader/writer pairs. sultative Committee (CCITT) group 3 FAX protocol <ref> [16] </ref>. This protocol presently supports two compression options. * The first group 3 FAX compression technique is one dimensional, running across scan-lines. Each scanline is broken into runs of black or white pixels. <p> Afterwards, the locations of beginnings and endings of runs are tracked from one scanline to the next, with short codes for small displacements. There are special codes to deal with new runs, disappearing runs, and runs that move too far. For more detail, see [19] or <ref> [16] </ref>. This scheme achieves an average of about 12.9:1 compression, with a high compression ratio of 32.4:1 for the nearly all white document 2, and a low compression ratio of 6.5:1 for the densely formatted document 4.
Reference: [17] <author> Moffatt, A., </author> <title> "A note on the PPM data compression algorithm," </title> <type> Research Report 88/7, </type> <institution> Department of Computer Science, University of Melbourne, Parkville, Victoria, Aus-tralia. </institution>
Reference: [18] <author> Moffatt, Alistair, </author> <title> "Word-based text compression," </title> <journal> Software-Practice and Experience, </journal> <volume> Vol. </volume> <month> 19(2) 185-198 February </month> <year> 1989 </year>
Reference: [19] <author> Netravali, Arun, N. and Barry G. </author> <title> Haskell "Digital pictures, representation and compression," </title> <publisher> Plenum Press, </publisher> <address> New York, </address> <year> 1988 </year>
Reference-contexts: The lengths of the runs are coded using a static Huffman table, mapping common run lengths onto short codes and rare run lengths onto long codes. This scheme achieves an average of about 8:1 compression across the 8 CCITT test documents <ref> [19] </ref>, with a compression ratio as high as 16.7:1 for a nearly all white document (document 2), and as low as 4.9:1 for a document densely covered with text (document 4). * The second group 3 FAX compression technique is two dimensional, running between scanlines. <p> Afterwards, the locations of beginnings and endings of runs are tracked from one scanline to the next, with short codes for small displacements. There are special codes to deal with new runs, disappearing runs, and runs that move too far. For more detail, see <ref> [19] </ref> or [16]. This scheme achieves an average of about 12.9:1 compression, with a high compression ratio of 32.4:1 for the nearly all white document 2, and a low compression ratio of 6.5:1 for the densely formatted document 4.
Reference: [20] <author> Peterson, James L., "XSCOPE: </author> <title> A debugging and performance tool for X11" Information Processing 89: </title> <booktitle> Proceedings of the IFIP 89 Congress, </booktitle> <month> August </month> <year> 1989, </year> <pages> pp 49-54 </pages>
Reference-contexts: Complete data integrity is guaranteed at the price of a little performance. Droms and Dyksen used their traces to characterize the load on an Ethernet due to an X session. Another program which uses the interposition technique for snooping on X traffic is xscope by Peterson <ref> [20] </ref>. I used Peterson's table lookup technique for matching X queries with X replies. On UNIX systems, X clients determine the address and method for connecting to the X server from an environment variable.
Reference: [21] <author> Rissanen, J. J., and G. G. Langdon, </author> <title> "Arithmetic coding," </title> <journal> IBM J. Research and Development, </journal> <volume> 23(2), </volume> <pages> 149-162, </pages> <month> March </month> <year> 1979. </year>
Reference: [22] <author> Rubin, F., </author> <title> "Arithmetic stream coding using fixed precision registers," </title> <journal> IEEE Trans. Information Theory, </journal> <volume> IT-25 (6), </volume> <pages> 672-675, </pages> <month> November </month> <year> 1979. </year>
Reference: [23] <author> Scheifler Robert W., </author> <title> "The X Window System Protocol," </title> <institution> M.I.T. Laboratory for Computer Science. </institution> <year> 1988. </year>
Reference: [24] <author> Scheifler, Robert W. and Jim Gettys, </author> <title> "The X Window System," </title> <journal> Transactions on Graphics 5(2), </journal> <pages> 79-109, </pages> <month> April </month> <year> 1986, </year> <note> and Software Practice and Experience vol. 20(S2), S2/5-S2/34, </note> <month> October </month> <year> 1991 </year>
Reference: [25] <author> Shannon, C. E., </author> <title> "A mathematical theory of communication," </title> <journal> Bell System Technical Journal, </journal> <volume> 27, </volume> <pages> 398-403, </pages> <month> July </month> <year> 1948 </year>
Reference-contexts: To the extent that the probability estimates are accurate, this scheme achieves Shannon's lower bound for the size of a message <ref> [25] </ref>. Finding good predictive models is the challenge. HBX's predictive technique has two legs: 1. HBX maintains a set of histograms representing frequencies of values in various contexts. These histograms are indexed with context strings which are created by small registered state machines associated with fields in X messages.
Reference: [26] <author> Storer, James A., </author> <title> "Data compression: methods and theory," </title> <publisher> Computer Science Press, </publisher> <address> Rockville Maryland, </address> <year> 1988. </year> <month> 17 </month>
Reference: [27] <author> Thomas, S. W., J. McKie, S. Davies, K. Turkowski, J. A. Woods, and J. W. Orost. </author> <title> "Compress (version 4.0) program and documentation," </title> <note> available from joe@petsd.uucp, </note> <year> 1985. </year>
Reference: [28] <author> Welch, T. A., </author> <title> "A technique for high-performance data compression," </title> <journal> IEEE Computer, </journal> <volume> 17 (6), </volume> <pages> 8-19, </pages> <month> June </month> <year> 1984. </year>
Reference: [29] <author> Ziv, J. and Lempel, A. </author> <title> "Compression of individual sequences via variable-rate coding," </title> <journal> IEEE Trans. Information Theory, </journal> <volume> IT-24 (5), </volume> <pages> 530-536, </pages> <editor> September 1978 Author Information John M. </editor> <title> Danskin is an Assistant Professor of Computer Science at Dartmouth College. He is interested in application specific data compression and application specific channel coding. He can be reached at jmd@cs.dartmouth.edu. </title> <type> 18 </type>
Reference-contexts: LZ78 Coder: implements the LZ78 dictionary based text compression algorithm <ref> [29] </ref> on the X message byte stream. Both of these pipelined components work by removing repeated byte-strings from the input stream. They are very fast, and the LZ coder can be quite effective on the right kind of input.
References-found: 29

