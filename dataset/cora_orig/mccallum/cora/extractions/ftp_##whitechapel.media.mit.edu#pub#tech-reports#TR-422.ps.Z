URL: ftp://whitechapel.media.mit.edu/pub/tech-reports/TR-422.ps.Z
Refering-URL: http://www-white.media.mit.edu/cgi-bin/tr_pagemaker/
Root-URL: http://www.media.mit.edu
Email: kbrussel@media.mit.edu  
Title: for Reconstruction  
Author: Kenneth B. Russell 
Address: 20 Ames Street; Cambridge, MA 02139  
Affiliation: Vision and Modeling Group MIT Media Laboratory  
Note: Eigenheads  This work was supported in part by British Telecom and Texas Instruments.  
Abstract: MIT Media Laboratory Perceptual Computing Section Technical Report 422 Also appears as MIT thesis for the degree of Bachelor of Science in Electrical Engineering and Computer Science Supervised by Alex P. Pentland Abstract A framework is presented for recovering the 3D structure and visual appearance of a human head from sparse data obtained from a real-time tracking system. An eigenvector decomposition of CyberWare-scanned heads is used to code incoming information. Modular eigenspaces are used to decorrelate eigenfeatures (eyes, nose, and mouth) from the rest of the head data. We observe that the modular eigenspace encoding often does not perform as well as a single eigen-space, and offer reasons for this based on experimental evidence. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Jebara, Tony S. and Alex Pentland. </author> <title> "Parametrized Structure from Motion for 3D Adaptive Feedback Tracking of Faces," MIT Media Laboratory, </title> <type> Perceptual Computing Technical Report #401. </type>
Reference-contexts: offer reasons for this based on experimental evidence. 1.2 Description of the Project The primary goal of this project was to create a system which, when presented with examples of 3D models of human heads, could then take incomplete data from a head tracking system (such as that described in <ref> [1] </ref>) and produce a new 3D model which best approximates the user's head. The 3D head models used as examples were obtained using CyberWare scanners (see Figure 1.1 for an example). <p> The output is a cylindrical coordinate depth map, as well as an associated texture map, of the user's head; these can be combined to reconstruct a 3D model. When viewed as 2D images instead of 3D models, these scans look like an "unwrapped" version of the head. FLIRT <ref> [1] </ref> (Face Localization for Invariant Recognition and Tracking) uses a single video camera connected to a Silicon Graphics Indy workstation to find certain facial features such as the eyes and corners of the mouth.
Reference: [2] <author> Turk, Matthew and Alex Pentland. </author> <title> "Eigenfaces for Recognition," </title> <journal> Journal of Cognitive Neuroscience, </journal> <volume> Vol. 3, No. 1, </volume> <year> 1991. </year>
Reference-contexts: A linear estimator based on the example heads was used to fill in the data which the tracking system could not supply. 1.3 Prior Work Principal component analysis was proposed for the problem of face recognition in <ref> [2] </ref>. Modular approaches to the eigenface technique were described in [3]. <p> containing these vectors as its columns) by finding the covariance matrix of this data set and then finding the eigenvectors of that covariance matrix. (Actually, we perform an well-known equivalent operation which prevents the need to compute the full 65,000 by 65,000 covariance matrix; this is described in, for example, <ref> [2] </ref>, and is equivalent to the singular value decomposition.) The eigenvectors of a covariance matrix can be chosen orthonormal, because a covariance matrix is by definition symmetric [7, p. 273].
Reference: [3] <author> Moghaddam, Baback and Alex Pentland. </author> <title> "Face Recognition using View-Based and Modular Eigenspaces," Automatic Systems for the Identification and Inspection of Humans, </title> <booktitle> SPIE, </booktitle> <volume> Vol. 2277, </volume> <month> July </month> <year> 1994. </year>
Reference-contexts: An eigenvector decomposition of the example heads was used as the coding mechanism for the reconstruction pipeline. This technique is efficient; encoding an incoming head requires just taking the dot product with the eigenvectors. It has also been shown to be effective for both recognition ([2], <ref> [3] </ref>) and reconstruction ([4]). Modular eigenspaces were used to semi-independently code regions of the face such as the eyes, nose, and mouth at higher resolution. <p> A linear estimator based on the example heads was used to fill in the data which the tracking system could not supply. 1.3 Prior Work Principal component analysis was proposed for the problem of face recognition in [2]. Modular approaches to the eigenface technique were described in <ref> [3] </ref>. A technique for recovering 3D information from a 2D image, using a statistical model built from scans of peoples' heads, was published in [4]. 3 image and the data corresponding to the face region is unmapped into cylindrical coordinates, creating a sparse texture map. <p> This eliminates the need to encode information about the orientation of the user's head in the eigenspace. The merits of this "view-based" approach are discussed in <ref> [3] </ref>. (align, alignToFLIRT) 2. The aligned models are converted back into cylindrical-coordinate range and texture files, which now have the property that the eyes, nose, and mouth of each of the heads are in approximately the same 2D location in all of the data files. (iv2float) 3. <p> It seemed at the end of the project that the first thing that should have been done was carefully consider the previous work in the field (namely, <ref> [3] </ref> and [4]). Once these papers had been reviewed, it seemed that some of the problems we had encountered during implementation might have been avoided by earlier consideration of these works.
Reference: [4] <author> Atick, Joseph J., Paul A. Griffin and A. Norman Redlich. </author> <title> "Statistical Approach to Shape from Shading: Reconstruction of Three-Dimensional Face Surfaces from Single Two-Dimensional Images," </title> <journal> Neural Computation, </journal> <volume> Vol 8, </volume> <year> 1996. </year>
Reference-contexts: Modular approaches to the eigenface technique were described in [3]. A technique for recovering 3D information from a 2D image, using a statistical model built from scans of peoples' heads, was published in <ref> [4] </ref>. 3 image and the data corresponding to the face region is unmapped into cylindrical coordinates, creating a sparse texture map. Two views of the reconstructed model from this data are shown. 1.4 Contributions The contributions of this work are twofold. <p> Two views of the reconstructed model from this data are shown. 1.4 Contributions The contributions of this work are twofold. First, this system may be unique in using modular eigenspaces for reconstruction of head models. Second, rather than operating on photographs as in <ref> [4] </ref>, it uses incomplete data from a real-time tracking system as input to the reconstruction mechanism. 1.5 Organization The rest of this document is organized as follows. Chapter 2 describes the precise pipeline, both preprocessing and runtime, of the reconstruction mechanism. <p> For example, illumination correction might help the problem of protruding eigenfeatures; however, the complete solution to this problem would involve the full shape from shading computation described in <ref> [4] </ref>, and would probably reduce the reconstruction step from "interactive time" (a few seconds) to an o*ine computation. <p> In general, as the data set shrinks, the eigenvectors of the data set look more and more like the input vectors rather than like their modes. We found that our eigenheads looked very much like the original data set, as opposed to deformation modes of the head (see <ref> [4] </ref> for a good example). At the time of this writing we had only 27 head scans to form our eigenspaces. For comparison, the shape from shading experiments done in [4] used a well-known database of 347 CyberWare-scanned air force pilots. <p> that our eigenheads looked very much like the original data set, as opposed to deformation modes of the head (see <ref> [4] </ref> for a good example). At the time of this writing we had only 27 head scans to form our eigenspaces. For comparison, the shape from shading experiments done in [4] used a well-known database of 347 CyberWare-scanned air force pilots. A large amount of time went into rewriting basic input/output code several times, to conform to FLIRT's file formats and to avoid forcing the existing system to change. <p> It seemed at the end of the project that the first thing that should have been done was carefully consider the previous work in the field (namely, [3] and <ref> [4] </ref>). Once these papers had been reviewed, it seemed that some of the problems we had encountered during implementation might have been avoided by earlier consideration of these works.
Reference: [5] <author> Arun, K. S., T. S. Huang, and S. D. Blostein. </author> <title> "Least-Squares Fitting of Two 3-D Point Sets," </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> Vol. PAMI-9, No. 5, </volume> <month> September </month> <year> 1987. </year>
Reference-contexts: To alleviate these problems, a new alignment program was written, which used solely rigid transformations (one translation and one rotation) to align these four points on the heads. The algorithm for this alignment is derived in <ref> [5] </ref>, and can be summarized as follows: 1.
Reference: [6] <author> Azarbayejani, Ali and Alex Pentland. </author> <title> "Recursive Estimation of Motion, Structure and Focal Length," </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <month> June </month> <year> 1995. </year>
Reference-contexts: The three-dimensional alignment and (sparse) structure of the head is estimated using a 2 two images are the range and texture data, respectively. Kalman filter as described in <ref> [6] </ref>. Using this positional information, an "average head" model is aligned to the user's head and the video image of the user is projected onto the model.
Reference: [7] <author> Strang, Gilbert. </author> <title> Introduction to Linear Algebra. </title> <address> Wellesley, MA: </address> <publisher> Wellesley-Cambridge Press, </publisher> <year> 1993. </year> <month> 28 </month>
Reference-contexts: an well-known equivalent operation which prevents the need to compute the full 65,000 by 65,000 covariance matrix; this is described in, for example, [2], and is equivalent to the singular value decomposition.) The eigenvectors of a covariance matrix can be chosen orthonormal, because a covariance matrix is by definition symmetric <ref> [7, p. 273] </ref>. Let A be the matrix of normalized eigenvectors of the covariance matrix of a data set, where each row is one eigenvector.
References-found: 7

