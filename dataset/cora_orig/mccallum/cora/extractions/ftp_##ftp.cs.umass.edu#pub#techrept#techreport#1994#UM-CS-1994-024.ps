URL: ftp://ftp.cs.umass.edu/pub/techrept/techreport/1994/UM-CS-1994-024.ps
Refering-URL: http://dis.cs.umass.edu/publications.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Note: Contents  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> D. Adams and Y. Pao, </author> <title> "High Order Neural Networks for Sonar Signal Discrimination" DARPA Artificial Neural Network Technology, 1991 Program Review, </title> <booktitle> Vol II Proceedings, </booktitle> <pages> pp. 409-422 </pages>
Reference-contexts: ANNs have resulted in improved performance on subtasks of the speech recognition task and on the overall task. Lippman [35] provides a good review of the state of the art in using ANNs for speech recognition. ANNs have also demonstrated good performance for Sonar <ref> [1, 36] </ref> and Radar [26] domains. The ANN approaches accept as input a fixed set of features and use one of several training techniques [49] for inducing a classifier.
Reference: [2] <author> T. Ash, </author> <title> "Dynamic Node Creation in Backpropagation Networks", </title> <type> (ICS Report 8901), </type> <address> San Diego, CA., </address> <institution> Institute of Cognitive Science, University of California 1989. </institution>
Reference-contexts: Classification performance is sensitive to these parameters. Several approaches for automatically selecting them for a given classification task are currently available <ref> [2, 28] </ref>. <p> The higher the degree of freedom, the greater the need for training data to establish them adequately <ref> [31, 49, 2] </ref>. When labeled training data is relatively sparse, symbolic approaches may be more appropriate. Training Unit based Training Data Requirements: Where the basic training unit may be shared among the different object classes, training data requirements are reduced.
Reference: [3] <author> A. Averbach, L. Bahl, R. Bakis, P. Brown, A. Cole, G. Dagett, S. Das, K. Davies, S. de Gennaro, P. de Souza, E. Epstein, D. Fraleigh, F. Jelinek, S. Katz, B. Lewis, R. Mercer, A. Nadas, D. Nahamoo, M. Picheny, G. Schichman, P. Spinelli, </author> <title> "An IBM-PC Based Large Vocabulary Isolated Utterance Speech Recognizer", </title> <booktitle> Proc. IEEE ICASSP, </booktitle> <pages> pp. 53-56, </pages> <address> Tokyo, Japan, </address> <month> April </month> <year> 1986. </year>
Reference-contexts: Re-estimation allows the assimilation of the statistical characteristics of the training data, in turn optimizing performance on the training set. We present below a brief description of several HMM based recognition systems and indicate their common features. Tangora <ref> [3] </ref>, designed for speaker-independent isolated word recognition, handles vocabulary sizes of 5,000 to 20,000 words. It uses a VQ front-end, operating with a single codebook of 200 elements and uses word units for training. The SPHINX [31] system for speaker-independent connected speech recognition handles 997 words.
Reference: [4] <author> B. Bhanu, S. Lee, and J. Ming, </author> <title> "Self-Optimizing Control System for Adaptive Image Segmentation", </title> <booktitle> Proc. of the DARPA Image Understanding Workshop, </booktitle> <address> Pittsburgh, PA., </address> <month> Sept. </month> <year> 1990. </year> <pages> pp. 583-595. </pages>
Reference: [5] <author> N. Bitar, E.Dorken, D. Paneras and H. Nawab, </author> <title> "Integration of STFT and Wigner Analysis in a Knowledge-Based Sound Understanding System", </title> <booktitle> IEEE ICASSP '92 Proceedings, </booktitle> <month> March </month> <year> 1992. </year>
Reference-contexts: When the signal processing results obtained from the application of two or more distinct SPAs from a family of functionally-similar SPAs are contradictory, we have a data-data discrepancy. It indicates a need for SPA/parameter adaptation. For instance, Bitar et al <ref> [5] </ref> describe the use of the Pseudo-Wigner Distribution (PWD) [10] in conjunction with the STFT [40] to detect time resolution inadequacies. A data-expectation discrepancy is encountered when the signal processing results do not support our expectations.
Reference: [6] <author> A. Bregman, </author> <title> "Auditory Scene Analysis: The Perceptual Organization of Sound", </title> <publisher> MIT Press, </publisher> <year> 1990. </year>
Reference-contexts: Weintraub [53] uses a computational model for separating speech based on the following: pitch, periodicity, possible rate of change within a frequency channel and over consecutive channels. Ming and Bhanu [37] present an adaptive approach to image segmentation. In the SUT, psycho-acoustic criteria <ref> [6] </ref> are used in grouping frequency components. The adaptive front-end seeks to expose and separate adequately the various components. <p> Before we discuss issues of search effort we present an example. 7 Example The following example describes the sequence of events that would ensue when modeling two very similar acoustic-events that have identical representations with respect to the default processing context. The acoustic-events are modeled as a synchronized 23 <ref> [6] </ref> set of frequency components [11]. We shall discuss repercussions on search effort and model database consistency based on the availability of previously encountered training instances for purposes of re-use.
Reference: [7] <author> O. Camps, L. Shapiro, and R. Haralick, "PREMIO: </author> <title> The Use of Prediction in CAD Model-Based Vision System", </title> <type> Technical Report no. </type> <institution> EE-ISL-89-01, University of Washington, </institution> <address> Seattle, </address> <month> July, </month> <year> 1989. </year> <month> 33 </month>
Reference-contexts: Mori et al collect statistics during training to build a table of classification ambiguities and their disambiguating features to realize greater recognition efficiency. The acquired object models are implicit in the sense that they are distributed in disambiguation plans. 4.2.3 Recognition as an Interpretation Task PREMIO <ref> [7] </ref> maintains explicit models of the objects and the world. The sensors (characterized in terms of position and resolution) and light sources are modeled as part of the world. In addition, PREMIO maintains models of physical processes that could cause errors in feature matching.
Reference: [8] <author> N. Carver, </author> <title> Sophisticated Control for Interpretation: Planning to Resolve Uncer--tainty, </title> <type> Ph.D. Thesis, </type> <institution> Dept. of Computer Science, Univ. of Massachusetts, </institution> <year> 1990. </year>
Reference: [9] <author> C. Chen, P. </author> <title> Mulgoankar,"Automatic Vision Programming,"CVGIP: </title> <booktitle> Image Understanding, </booktitle> <volume> Vol. 55, No. 2, </volume> <month> March, </month> <pages> pp. 170-183, </pages> <year> 1992. </year>
Reference-contexts: The advantage of transparent representations is that they can be used to direct feature extraction for meeting the recognition goal. 4.2.1 Algorithm Generation Approaches Predominantly for the visual domain, algorithm generation approaches <ref> [9, 17, 27, 30] </ref> have been explored. Their objective is to acquire recognition strategies given a high-level task description such as to assert the presence or absence of an object in an image or determine its pose.
Reference: [10] <author> T.Claasen and W. Meclenbrauker, </author> <title> "The Wigner Distribution: A tool for Time-Frequency Signal Analysis", </title> <journal> Phillips J. Res., </journal> <volume> vol. 35, </volume> <pages> pp. 276-350, </pages> <year> 1980. </year>
Reference-contexts: When the signal processing results obtained from the application of two or more distinct SPAs from a family of functionally-similar SPAs are contradictory, we have a data-data discrepancy. It indicates a need for SPA/parameter adaptation. For instance, Bitar et al [5] describe the use of the Pseudo-Wigner Distribution (PWD) <ref> [10] </ref> in conjunction with the STFT [40] to detect time resolution inadequacies. A data-expectation discrepancy is encountered when the signal processing results do not support our expectations. It indicates that either the expectations are invalid, or that the data processing (SPAs and/or parameters) is inappropriate.
Reference: [11] <author> L. Cohen, </author> <title> "What is a Multicomponent Signal?", </title> <publisher> IEEE, </publisher> <year> 1992. </year>
Reference-contexts: The acoustic-events are modeled as a synchronized 23 [6] set of frequency components <ref> [11] </ref>. We shall discuss repercussions on search effort and model database consistency based on the availability of previously encountered training instances for purposes of re-use.
Reference: [12] <author> M. Cohen, </author> <title> "Hybrid Neural Network/Hidden Markov Model Speech Recognition", </title> <booktitle> DARPA Artificial Neural Network Technology, 1991 Program Review, Vol II Proceedings, </booktitle> <pages> pp. 254-273. </pages>
Reference-contexts: Yet another illustration of the problem is found in the domain of vision where "pose" varies with the observation perspective. Radar and Sonar data are typically contaminated with noise. Subsymbolic approaches, such as artificial neural nets (ANNs) [49], hidden Markov models (HMMs) [48] and hybrids thereof <ref> [12] </ref> have successfully been used for object modeling in systems with fixed front-ends for feature extraction. These approaches have yielded performance improvements over hand-crafted versions. In comparison, little work has been done with object model acquisition for systems with adaptive front-ends.
Reference: [13] <author> B. Dawant and B. Jansen, </author> <title> "Coupling Numerical and Symbolic Methods for Signal Interpretation", </title> <journal> IEEE transactions on Systems, Man Cybernetics, </journal> <volume> Vol. 21, No. 1, </volume> <month> Jan/Feb </month> <year> 1991. </year>
Reference-contexts: The content does not necessarily reflect the position or the policy of the Government, and no official endorsement should be inferred. 3 Systems <ref> [13, 17, 33, 37] </ref> have emerged. These systems adapt their signal processing front-end in response to variations in the incoming signal data. Recognition in adaptive perceptual systems proceeds through the interaction of two processes: feature extraction and interpretation/matching.
Reference: [14] <author> G.R. Doddington, </author> <title> "Phonetically Sensitive Discriminants for Improved Speech Recognition", </title> <booktitle> Proceedings IEEE ICASSP, </booktitle> <pages> pp. 556-559, </pages> <address> Glasgow, Scotland, </address> <month> May </month> <year> 1989. </year>
Reference-contexts: The AT&T digit recognition system [47] and the Texas Instruments system <ref> [14] </ref> are word-based 5 speaker-independent digit recognition systems. In the digit recognition task, grammar constraints are minimal: any digit may appear after any other. This places a greater need for good acoustic matching to achieve high performance.
Reference: [15] <author> E. Dorken, H. Nawab, and V. Lesser, </author> <title> "Extended Model Variety Analysis for Integrated Processing and Understanding of Signals", </title> <booktitle> IEEE ICASSP '92 Proceedings, </booktitle> <month> March </month> <year> 1992. </year>
Reference: [16] <author> E. Dorken, </author> <title> "Approximate Processing and Knowledge-Based Reasoning of NonStationary Signals", </title> <type> PhD Thesis, </type> <institution> Dept. of Electrical Engineering, Boston University, </institution> <year> 1993. </year>
Reference: [17] <author> B. Draper, </author> <title> "Learning Object Recognition Strategies", </title> <type> PhD Thesis, </type> <institution> Dept. of Computer Science, University of Massachusetts, CMPSCI TR93-50, </institution> <year> 1993. </year>
Reference-contexts: The content does not necessarily reflect the position or the policy of the Government, and no official endorsement should be inferred. 3 Systems <ref> [13, 17, 33, 37] </ref> have emerged. These systems adapt their signal processing front-end in response to variations in the incoming signal data. Recognition in adaptive perceptual systems proceeds through the interaction of two processes: feature extraction and interpretation/matching. <p> Systems that acquire object models [31, 34, 36] have predominantly employed fixed signal processing front-ends. Systems that learn recognition strategies <ref> [17, 30, 37] </ref>, have instead employed adaptive signal processing front-ends. This latter class of systems dynamically select SPAs with preset parameters from a large but finite set in order to meet the needs of the recognition task at hand. We shall examine both classes of learning systems. <p> The advantage of transparent representations is that they can be used to direct feature extraction for meeting the recognition goal. 4.2.1 Algorithm Generation Approaches Predominantly for the visual domain, algorithm generation approaches <ref> [9, 17, 27, 30] </ref> have been explored. Their objective is to acquire recognition strategies given a high-level task description such as to assert the presence or absence of an object in an image or determine its pose. <p> The recognition strategies in many of these systems are basically search trees, constructed by applying a set of rules that determine relevant features of the unknown image in order to establish object identity. The SLS <ref> [17] </ref> uses decision trees [46] to represent recognition strategies. Common to all the systems is that they address issues of feature selection and ordering.
Reference: [18] <author> L. Erman, R. Hayes-Roth, V. Lesser, D. Reddy, </author> <title> "The Hearsay II Speech Understanding System: Integrating Knowledge to Resolve Uncertainty", </title> <journal> Computing Surveys, </journal> <volume> Vol. 12, </volume> <month> June </month> <year> 1980. </year>
Reference-contexts: The first step involves the initialization of the processing context using past experience where available when the learning is supervised. The main modeling loop seeks to resolve processing and interpretation discrepancies at successively higher levels of data abstraction (most perceptual systems <ref> [18, 24, 33] </ref> maintain data at multiple levels of abstraction). This involves processing the data, checking for discrepancies, diagnosing the same and reprocessing the 22 data after adapting the SPAs and their parameters accordingly.
Reference: [19] <author> U. Fayyad, </author> <type> Personal communication, </type> <address> Amherst, MA, </address> <month> June </month> <year> 1993. </year>
Reference: [20] <author> K. Fukunaga, </author> <title> "Introduction to Statistical Pattern Recognition", </title> <publisher> Academic Press, </publisher> <address> London, </address> <year> 1990. </year> <month> 34 </month>
Reference-contexts: For each object, a large set of images is obtained by automatically varying pose and illumination, which is then compacted using principal-component techniques <ref> [20] </ref>. The resulting lower-dimensional representational subspace, called eigenspace, is parameterized by pose and illumination. Each object is represented as a hypersurface in this space. Given an unknown input image, the recognition system projects the image onto the eigenspace. Object identity is established by the hypersurface the projection meets.
Reference: [21] <author> D. </author> <title> Gabor, </title> <journal> "Theory of Communication", Journal of the Institute of Electrical Engineers, </journal> <volume> 93, </volume> <pages> pp. 429-441, </pages> <year> 1946. </year>
Reference-contexts: Resolving a discrepancy at a given level in the data abstraction could entail data reprocessing at one or more lower levels of data abstraction. Further, discrepancies involving quantum mechanically related dimensions cannot be simultaneously removed <ref> [21] </ref>, e.g., time and frequency. Under such circumstances it becomes necessary to resolve each individually and combine the information, through the use of domain knowledge, to generate a composite model that meets our interpretation needs. Processing assumptions are explicitly maintained in order to reason about the uncertainties they introduce.
Reference: [22] <author> S.I. Gallant, </author> <title> "Connectionist Expert Systems", </title> <journal> CACM, </journal> <volume> Vol .31, No. 2, </volume> <month> February </month> <year> 1988. </year>
Reference-contexts: Symbolically represented objects allow access to information that may be used to guide this manner of reprocessing. In particular, when objects may co-occur, they are useful in predicting evidence interaction. In contrast, subsymbolic object models are relatively inaccessible to such interpretation and prediction tasks. Gallant <ref> [22] </ref> extracts rules from a connectionist-based expert system. Compared to the reasoning power that must be captured to address recognition for complex perceptual scenarios, the expert system is simple. Further advances are definitely required before the knowledge captured in subsymbolic classifiers can be exploited to guide interpretation.
Reference: [23] <author> R. </author> <title> Gray, </title> <journal> "Vector Quantization' IEEE ASSP Magazine, </journal> <volume> Vol. 1, No. 2, </volume> <pages> pp. 4-29, </pages> <month> April </month> <year> 1984. </year>
Reference-contexts: These approaches are distinguished in their use of fixed front-ends for feature extraction, use of vector quantization 3 (VQ) <ref> [23] </ref> techniques for data compression and the large number of object classes that they model. In particular, we discuss subsym-bolic object model acquisition systems that use HMM and ANN techniques. HMMs in Speech Recognition: Hidden Markov Models [31, 45, 48] have been predominantly used in speech recognition.
Reference: [24] <author> A.R. Hanson and E.M. Riseman, </author> <title> "VISIONS: A Computer System for Interpreting Scenes", in Computer Vision Systems, </title> <editor> Hanson and Riseman (eds.), </editor> <address> N.Y.: </address> <publisher> Academic Press, </publisher> <year> 1978. </year> <pages> pp 303-333. </pages>
Reference-contexts: The first step involves the initialization of the processing context using past experience where available when the learning is supervised. The main modeling loop seeks to resolve processing and interpretation discrepancies at successively higher levels of data abstraction (most perceptual systems <ref> [18, 24, 33] </ref> maintain data at multiple levels of abstraction). This involves processing the data, checking for discrepancies, diagnosing the same and reprocessing the 22 data after adapting the SPAs and their parameters accordingly.
Reference: [25] <author> B. Hayes-Roth, R. Washington, R. Hewett, </author> <title> and A Seiver, "Intelligent Monitoring and Control", </title> <booktitle> IJCAI `89 Proceedings pp. </booktitle> <pages> 243-249. </pages>
Reference: [26] <author> S. Haykin and T.K. Bhattacharya, </author> <title> "Adaptive Radar Detection using Supervised Learning in Time-Frequency Domain", </title> <booktitle> in </booktitle> ??. 
Reference-contexts: ANNs have resulted in improved performance on subtasks of the speech recognition task and on the overall task. Lippman [35] provides a good review of the state of the art in using ANNs for speech recognition. ANNs have also demonstrated good performance for Sonar [1, 36] and Radar <ref> [26] </ref> domains. The ANN approaches accept as input a fixed set of features and use one of several training techniques [49] for inducing a classifier.
Reference: [27] <author> Ikeuchi, K. and Hong, </author> <title> K.S. "Determining Linear Shape Change: Toward Automatic Generation of Object Recognition Programs," </title> <booktitle> CGVIP: Image Understanding, </booktitle> <volume> 53(2): </volume> <month> 154-170 </month> <year> (1991). </year>
Reference-contexts: The advantage of transparent representations is that they can be used to direct feature extraction for meeting the recognition goal. 4.2.1 Algorithm Generation Approaches Predominantly for the visual domain, algorithm generation approaches <ref> [9, 17, 27, 30] </ref> have been explored. Their objective is to acquire recognition strategies given a high-level task description such as to assert the presence or absence of an object in an image or determine its pose.
Reference: [28] <author> E. Karnin, </author> " <title> A Simple Procedure for Pruning back-propagation Trained Neural Networks", </title> <journal> IEEE Trans. on Neural Networks, </journal> <volume> 1, </volume> <pages> pp. 239-242, </pages> <year> 1990 </year>
Reference-contexts: Classification performance is sensitive to these parameters. Several approaches for automatically selecting them for a given classification task are currently available <ref> [2, 28] </ref>.
Reference: [29] <author> F. Klassner, </author> <title> "Data Reprocessing and Assumption Representation in Signal Understanding Systems", </title> <type> Technical Report 92-52, </type> <institution> Computer Science Dept, University of Massachusetts, </institution> <year> 1992. </year>
Reference: [30] <author> C. Kohl, A. Hanson, E. Riseman, </author> <title> "A Goal-Directed Intermediate Level Executive for Image Interpretation", </title> <booktitle> Proc. 1987 of the Joint International Conference on Artificial Intelligence. </booktitle>
Reference-contexts: Systems that acquire object models [31, 34, 36] have predominantly employed fixed signal processing front-ends. Systems that learn recognition strategies <ref> [17, 30, 37] </ref>, have instead employed adaptive signal processing front-ends. This latter class of systems dynamically select SPAs with preset parameters from a large but finite set in order to meet the needs of the recognition task at hand. We shall examine both classes of learning systems. <p> The advantage of transparent representations is that they can be used to direct feature extraction for meeting the recognition goal. 4.2.1 Algorithm Generation Approaches Predominantly for the visual domain, algorithm generation approaches <ref> [9, 17, 27, 30] </ref> have been explored. Their objective is to acquire recognition strategies given a high-level task description such as to assert the presence or absence of an object in an image or determine its pose.
Reference: [31] <author> K. Lee, </author> <title> "Large-Vocabulary Speaker Independent Continuous Speech Recognition: The SPINX System", </title> <type> PhD Thesis, </type> <institution> Dept. of Computer Science, Carnegie Mellon University, </institution> <year> 1988, </year> <note> Technical Report No. CMU-CS-88-148. </note>
Reference-contexts: Systems that acquire object models <ref> [31, 34, 36] </ref> have predominantly employed fixed signal processing front-ends. Systems that learn recognition strategies [17, 30, 37], have instead employed adaptive signal processing front-ends. <p> In particular, we discuss subsym-bolic object model acquisition systems that use HMM and ANN techniques. HMMs in Speech Recognition: Hidden Markov Models <ref> [31, 45, 48] </ref> have been predominantly used in speech recognition. They are a generalization of dynamic programming and provide a rigorous approach to developing robust statistical models. <p> They are a generalization of dynamic programming and provide a rigorous approach to developing robust statistical models. In HMMs, the view of measuring acoustic similarity as a template matching problem is generalized to a problem of finding an optimal path (using the Viterbi algorithm) through a recognition model <ref> [31] </ref>. The probability of the speech data given a recognition model is computed. The major advantage in HMMs, from a time normalization perspective, is that a local constraint function can be re-estimated, or optimized, by an iterative training procedure. <p> Tangora [3], designed for speaker-independent isolated word recognition, handles vocabulary sizes of 5,000 to 20,000 words. It uses a VQ front-end, operating with a single codebook of 200 elements and uses word units for training. The SPHINX <ref> [31] </ref> system for speaker-independent connected speech recognition handles 997 words. It uses VQ, maintaining three codebooks of 256 prototype vectors each (for cepstral coefficients, differenced cepstral coefficients and power with differenced power). <p> The higher the degree of freedom, the greater the need for training data to establish them adequately <ref> [31, 49, 2] </ref>. When labeled training data is relatively sparse, symbolic approaches may be more appropriate. Training Unit based Training Data Requirements: Where the basic training unit may be shared among the different object classes, training data requirements are reduced.
Reference: [32] <author> V. Lesser, H. Nawab, M. Bhandaru, Z. Cvetanovic, E. Dorken, I. Gallastegi, and F. Klassner, </author> <title> Integrated Signal Processing and Signal Understanding, </title> <type> Technical Report 91-34, </type> <institution> Computer Science Dept., University of Massachusetts, </institution> <year> 1991. </year> <note> Also available as: </note> <author> H. Nawab and V. Lesser, </author> <title> "Integrated Processing and Understanding of Signals", Chapter 6, Knowledge-Based Signal Processing, </title> <editor> A. Oppenheim and H. Nawab, editors, </editor> <publisher> Prentice Hall, </publisher> <address> New Jersey, </address> <year> 1991. </year> <month> 35 </month>
Reference-contexts: Knowledge about the SPAs, their parameters and the domain is used to reason about the discrepancies and suggest alternate processing contexts. The learning paradigm will be discussed in the context of the SUT <ref> [32] </ref>, an adaptive perceptual systems for non-speech sound recognition. The sounds, also known as acoustic-events, may occur together. Examples of acoustic events are: a foot step, telephone ring, and a hair dryer coming on. See Figure 4 for the SUT model for a hair dryer operating at high speed. <p> We shall revisit this concept in Section 8.3. the broken contours of (b) due to insufficient time resolution. 3 SUT Before we go further, we briefly describe the Sound Understanding Testbed (SUT) <ref> [32] </ref> and the recognition task being addressed. The SUT seeks to identify acoustic-events given waveform data (a sequence of time-amplitude pairs). <p> Vadala [51] developed a semi-automatic approach for acquiring sound source models requiring multiple levels of data abstraction. Adaptive Front-End: Vadala's [51] semi-automatic approach for sound source model acquisition is based on the principles of the SUT <ref> [32, 33] </ref>. It requires user guidance based on "viewing" and "listening" to the acoustic signal to estimate the key SPA parameters such as the STFT window length and number of peaks to select from the spectra.
Reference: [33] <author> V. Lesser, H. Nawab, I. Gallastegi, F. Klassner, "IPUS: </author> <title> An Architecture for Inte--grated Signal Processing and Signal Interpretation in Complex Environments", </title> <booktitle> AAAI-93, </booktitle> <address> Washington, USA, </address> <year> 1993. </year> <note> A more detailed version will be appearing in AIJ in 1995. </note>
Reference-contexts: The content does not necessarily reflect the position or the policy of the Government, and no official endorsement should be inferred. 3 Systems <ref> [13, 17, 33, 37] </ref> have emerged. These systems adapt their signal processing front-end in response to variations in the incoming signal data. Recognition in adaptive perceptual systems proceeds through the interaction of two processes: feature extraction and interpretation/matching. <p> SPA-correlates obtained under different parameterizations of an SPA are however comparable through the use of knowledge about the underlying signal processing theory that is used as the basis for the SPA implementation <ref> [33] </ref>. An SPA parameterization may expose some salient aspects of an object while obscuring others. For instance, consider the analysis of time-amplitude waveform data corresponding to an acoustic-event composed of two constant-frequency components with an inter-component spacing of 15 Hz. <p> The SUT seeks to identify acoustic-events given waveform data (a sequence of time-amplitude pairs). The SUT is based on the IPUS (Integrated Processing and Understanding of Signals) architecture <ref> [33] </ref> which views the process of signal understanding as a bi-directional search in the space of SPAs and their parameters. <p> Vadala [51] developed a semi-automatic approach for acquiring sound source models requiring multiple levels of data abstraction. Adaptive Front-End: Vadala's [51] semi-automatic approach for sound source model acquisition is based on the principles of the SUT <ref> [32, 33] </ref>. It requires user guidance based on "viewing" and "listening" to the acoustic signal to estimate the key SPA parameters such as the STFT window length and number of peaks to select from the spectra. <p> Especially interesting is that PREMIO addresses reasoning about models (of objects and the world) to make predictions. This is very useful while addressing recognition for complex scenarios where multiple objects may co-occur. Signal understanding is addressed in a similar fashion in the SUT <ref> [33] </ref> framework. 4.3 Limitations of Existing Approaches The existing systems fall broadly into two categories: those that learn object models and those that learn recognition strategies. However, for the purpose of discussing their limitations, we categorize them based on whether they deal with symbolic or subsymbolic object models. <p> To generate reliable object hypotheses it may be necessary to selectively combine, through the use of domain knowledge, SPA-correlates with distinct precisions for quantum mechanically related dimensions. This is being explored in the SUT <ref> [33] </ref>. Intrinsic unpredictability arises in objects that display time variant behavior (the ring of the telephone, sound of a vacuum cleaner in use). To increase the likelihood of obtaining a distinguishing set of features, some systems use a large set of SPAs and parameters. <p> The issue of partitioning data into groups or regions is an important first step of any recognition system. It is known as the segmentation problem by vision researchers, speaker segregation by speech researchers and component grouping in the SUT <ref> [33] </ref>. Parson [43] uses harmonic selection to separate speech from the interfering speech of a second talker before applying VQ based speech recognition techniques. <p> We need a mechanism to automate the identification of features which facilitates the object modeling task. 5 Discrepancies and Diagnosis We briefly discuss discrepancy detection and diagnosis <ref> [33] </ref>, which form the backbone of our learning approach. Discrepancies fall into three categories: data-data, data-expectation, and violation. The key is to use these different discrepancies to control search in the SPA/parameter space to induce more efficiently appropriate symbolic descriptions of the objects. <p> The first step involves the initialization of the processing context using past experience where available when the learning is supervised. The main modeling loop seeks to resolve processing and interpretation discrepancies at successively higher levels of data abstraction (most perceptual systems <ref> [18, 24, 33] </ref> maintain data at multiple levels of abstraction). This involves processing the data, checking for discrepancies, diagnosing the same and reprocessing the 22 data after adapting the SPAs and their parameters accordingly. <p> Default Processing Context: same as before. Assumption: Model database contains only the models for Simple-Steady-1 and Simple-Steady-2. We examine the sequence of events that would ensue during a SUT recognition run operating in Configuration II <ref> [33] </ref>, which is very similar to that illustrated in Figure 1. The spectral data obtained on STFT analysis is grouped over time into spectral-activity bands, which are used to index into the model database. <p> Continuing with the hair dryer example, this would translate to using the specialized SPA for the detection of harmonics (which in the course of blind search would not have been used due to its associated cost). In the SUT <ref> [33] </ref>, Configuration II, the approximate knowledge available in the spectral bands is used to generate sound source hypotheses. These in turn generate expectations for specific support units which are tested for using specialized SPAs as necessary. In the model acquisition system, we will exploit generic models in a similar fashion.
Reference: [34] <author> R.Lippmann, E. Martin, D. Paul, </author> <title> "Multi-style Training for Robust Isolated-word Speech Recognition", </title> <booktitle> Proceedings of IEEE ICASSP, </booktitle> <pages> pp. 705-708, </pages> <address> Dallas, TX, </address> <month> April </month> <year> 1987. </year>
Reference-contexts: Systems that acquire object models <ref> [31, 34, 36] </ref> have predominantly employed fixed signal processing front-ends. Systems that learn recognition strategies [17, 30, 37], have instead employed adaptive signal processing front-ends.
Reference: [35] <author> R. Lippmann, </author> <title> "Review of Neural Networks for Speech Recognition", Readings in Speech Recognition, Edited by: </title> <editor> Alex Waibel and Kai-Fu Lee, </editor> <publisher> Morgan Kaufmann Publishers, Inc. </publisher> <address> San Mateo, CA, </address> <year> 1990. </year>
Reference-contexts: ANNs have resulted in improved performance on subtasks of the speech recognition task and on the overall task. Lippman <ref> [35] </ref> provides a good review of the state of the art in using ANNs for speech recognition. ANNs have also demonstrated good performance for Sonar [1, 36] and Radar [26] domains.
Reference: [36] <author> S. Luse, H. McBeth, </author> <title> "Passive Sonar Detection/Classification", </title> <booktitle> DARPA Artificial Neural Network Technology, 1991 Program Review, Vol II Proceedings, </booktitle> <pages> pp. 450-479. </pages>
Reference-contexts: Systems that acquire object models <ref> [31, 34, 36] </ref> have predominantly employed fixed signal processing front-ends. Systems that learn recognition strategies [17, 30, 37], have instead employed adaptive signal processing front-ends. <p> ANNs have resulted in improved performance on subtasks of the speech recognition task and on the overall task. Lippman [35] provides a good review of the state of the art in using ANNs for speech recognition. ANNs have also demonstrated good performance for Sonar <ref> [1, 36] </ref> and Radar [26] domains. The ANN approaches accept as input a fixed set of features and use one of several training techniques [49] for inducing a classifier. <p> Classification success is directly dependent on whether the selected features are sufficient to distinguish among the classes. Consequently, a lot of care goes into the selection of these features. For instance, Luse et al <ref> [36] </ref> investigated a whole class of signal processing algorithms: Gabor Wavelets, Generalized Time Frequency Representation (GTFR), Choi-Williams distribution, Fourier Power Spectra, Higher-Ordered Spectra, and the Wigner-Ville distribution, before concluding that the GTFR best suited their classification task.
Reference: [37] <author> J. Ming, B. Bhanu, </author> <title> "A Multistrategy Learning Approach for Target Model Recognition, Acquisition, and Refinement", </title> <booktitle> Proc. of the DARPA Image Understanding Workshop, </booktitle> <address> Pittsburgh, PA., </address> <month> Sept. </month> <year> 1990. </year> <pages> pp. 742-756. </pages>
Reference-contexts: The content does not necessarily reflect the position or the policy of the Government, and no official endorsement should be inferred. 3 Systems <ref> [13, 17, 33, 37] </ref> have emerged. These systems adapt their signal processing front-end in response to variations in the incoming signal data. Recognition in adaptive perceptual systems proceeds through the interaction of two processes: feature extraction and interpretation/matching. <p> Typically the object models have been hand-crafted, a tedious and error prone activity that constitutes a knowledge acquisition bottleneck. Automating model acquisition for adaptive perceptual systems has received relatively limited attention <ref> [37, 38, 51] </ref>. Much of this effort relies on human intervention such as suggesting alternate SPA parameterizations when feature inadequacies are encountered, or in the initialization of critical parameters. In the case of vision applications, the availability of adequately segmented images is assumed [37, 39]. <p> Much of this effort relies on human intervention such as suggesting alternate SPA parameterizations when feature inadequacies are encountered, or in the initialization of critical parameters. In the case of vision applications, the availability of adequately segmented images is assumed <ref> [37, 39] </ref>. <p> Systems that acquire object models [31, 34, 36] have predominantly employed fixed signal processing front-ends. Systems that learn recognition strategies <ref> [17, 30, 37] </ref>, have instead employed adaptive signal processing front-ends. This latter class of systems dynamically select SPAs with preset parameters from a large but finite set in order to meet the needs of the recognition task at hand. We shall examine both classes of learning systems. <p> Vadala also derived a general telephone model by combining the individual telephone models. Our intention is to extend his work to more objects, and fully automate the model acquisition process. Fixed front-end: We shall next discuss two successful systems <ref> [39, 37] </ref> for object model acquisition in the visual domain based on fixed signal processing front-ends. The front-ends are characterized as fixed because the image segmentation is fixed and the set of features available for model representation is fixed. <p> Partial object occlusion is not addressed. Consequently, a fixed signal processing front-end is sufficient and the learning subsystem concerns itself only with variations in object illumination and pose in the construction of robust models. Symbolic Descriptions Ming and Bhanu in TRIPLE <ref> [37] </ref> combine structured conceptual clustering (SCC) and explanation based learning (EBL) techniques to acquire and refine object models for aircraft recognition. New object models are acquired as and when the objects are encountered and models revised when better training data becomes available. <p> Weintraub [53] uses a computational model for separating speech based on the following: pitch, periodicity, possible rate of change within a frequency channel and over consecutive channels. Ming and Bhanu <ref> [37] </ref> present an adaptive approach to image segmentation. In the SUT, psycho-acoustic criteria [6] are used in grouping frequency components. The adaptive front-end seeks to expose and separate adequately the various components.
Reference: [38] <author> R. De Mori, L. Lam and M. Gilloux, </author> <title> "Learning and Plan Refinement in a Knowledge-Based System for Automatic Speech Recognition", </title> <booktitle> IEEE 1987, </booktitle> <pages> pp. 246-262. </pages>
Reference-contexts: Typically the object models have been hand-crafted, a tedious and error prone activity that constitutes a knowledge acquisition bottleneck. Automating model acquisition for adaptive perceptual systems has received relatively limited attention <ref> [37, 38, 51] </ref>. Much of this effort relies on human intervention such as suggesting alternate SPA parameterizations when feature inadequacies are encountered, or in the initialization of critical parameters. In the case of vision applications, the availability of adequately segmented images is assumed [37, 39]. <p> In contrast to active recognition, for passive recognition, the ability to reason with the object models would be more advantageous. For instance, it would enable sharing the effort involved in confirming and eliminating various candidate hypotheses. 4.2.2 Recognition as a Planning Task Mori et al <ref> [38] </ref> address the task of identifying speaking modes or styles within short time intervals. Information about speaking modes can be used to achieve better performance in connected speech recognition. <p> The above process is repeated until the induced description performs satisfactorily on a large population of speakers and several speaking modes. 15 As with all incremental learning systems, a description may be rendered inade-quate with the arrival of new instances. Mori et al <ref> [38] </ref> address this issue by first attempting to specialize the description and if that fails to meet classification needs, then extract additional features from the speech signal. The implementation relies on significant user interaction, requiring user guidance about features to extract when the disambiguation goal is not met. <p> In addition, a priori the number of distinct object classes have to be specified. The system built by Mori et al <ref> [38] </ref> for disambiguating elements of the "E" set, in the event of failure to disambiguate among possible object classes seeks human guidance in the form of further features to explore. These are then extracted and the process of acquiring recognition strategies continues. <p> Such an approach is inadequate for complex scenarios that are characterized by varying signal-to-noise ratio, possible object masking/occlusion and 20 unpredictable object activity. Such scenarios require the power of adaptive feature extraction to give improved recognition performance. Exceptions to the above are the systems of Mori et al <ref> [38] </ref> and Vadala [51], which cope with adaptive feature extraction, learning recognition strategies and object models respectively. Both systems however require user interaction; the former requiring assistance when a classification ambiguity is detected and the latter requiring assistance in the initial selection of the SPAs and some of their parameters.
Reference: [39] <author> H. Murase and S. Nayar, </author> <title> "Learning Object Models from Appearance", </title> <booktitle> AAA93, </booktitle> <pages> pp. 836-843, </pages> <address> Washington, </address> <month> July </month> <year> 1993. </year>
Reference-contexts: Much of this effort relies on human intervention such as suggesting alternate SPA parameterizations when feature inadequacies are encountered, or in the initialization of critical parameters. In the case of vision applications, the availability of adequately segmented images is assumed <ref> [37, 39] </ref>. <p> Murase and Nayar <ref> [39] </ref> acquire object models that do not use multiple levels of data abstraction for visual object recognition. Vadala [51] developed a semi-automatic approach for acquiring sound source models requiring multiple levels of data abstraction. <p> Vadala also derived a general telephone model by combining the individual telephone models. Our intention is to extend his work to more objects, and fully automate the model acquisition process. Fixed front-end: We shall next discuss two successful systems <ref> [39, 37] </ref> for object model acquisition in the visual domain based on fixed signal processing front-ends. The front-ends are characterized as fixed because the image segmentation is fixed and the set of features available for model representation is fixed. <p> The front-ends are characterized as fixed because the image segmentation is fixed and the set of features available for model representation is fixed. Visual Appearance Murase and Nayar <ref> [39] </ref> address the problem of learning object models from images for object recognition and pose estimation.
Reference: [40] <author> H. Nawab and T. Quatieri, </author> <title> "Short-Time Fourier Transform", </title> <booktitle> Advanced Topics in Signal Processing, </booktitle> <publisher> Prentice Hall, </publisher> <address> New Jersey, </address> <year> 1988. </year>
Reference-contexts: With a sampling frequency of 10 KHz, a Fourier Transform based algorithm for frequency analysis would be unable to expose the relevant frequency detail unless a data window that affords the minimum required frequency resolution is used. This is illustrated using the Short-Time Fourier Transform (STFT) algorithm <ref> [40] </ref> for spectral analysis in Figure 1. Note that the uncertainty in frequency spread i.e., "width" of each component reduces when the data is processed with greater frequency resolution. <p> Secondly, certain SPA parameterizations afford a view of the signal data that leads 5 to a simple 1 physical explanation. For instance, consider the analysis of a near-linear rising chirp 2 sound sampled at a frequency of 8KHz. If the signal data is processed using the STFT algorithm <ref> [40] </ref> with a small window and narrow decimation (128 and 64 data points respectively) before connecting peaks in consecutive spectra, we would obtain results as shown in Figure 2a. <p> It indicates a need for SPA/parameter adaptation. For instance, Bitar et al [5] describe the use of the Pseudo-Wigner Distribution (PWD) [10] in conjunction with the STFT <ref> [40] </ref> to detect time resolution inadequacies. A data-expectation discrepancy is encountered when the signal processing results do not support our expectations. It indicates that either the expectations are invalid, or that the data processing (SPAs and/or parameters) is inappropriate.
Reference: [41] <author> J. Naylor, S. Boll, </author> <title> "Techniques for Suppression of Interfering Talker in Co-channel Speech", </title> <booktitle> Proceedings of IEEE ICASSP, </booktitle> <pages> pp. 205-208, </pages> <address> Dallas, TX, </address> <month> April </month> <year> 1987. </year>
Reference: [42] <author> H. Nii, E. Feigenbaum, J. Anton, A. Rockmore, </author> <title> "Signal-to-Symbol Transformation: HASP/SIAP Case Study", </title> <journal> AI Magazine. </journal> <volume> Vol. 3 (2), </volume> <pages> pp. 23-35, </pages> <month> Spring </month> <year> 1982. </year>
Reference: [43] <author> T.W. Parson's, </author> <title> "Separation of Speech from Interfering Speech by Means of Harmonic Selection", </title> <journal> Journal of Acoustic Society of America, </journal> <volume> vol 60, no. 4, </volume> <pages> pp. 911-918, </pages> <month> Oct. </month> <year> 1976. </year> <month> 36 </month>
Reference-contexts: The issue of partitioning data into groups or regions is an important first step of any recognition system. It is known as the segmentation problem by vision researchers, speaker segregation by speech researchers and component grouping in the SUT [33]. Parson <ref> [43] </ref> uses harmonic selection to separate speech from the interfering speech of a second talker before applying VQ based speech recognition techniques. Weintraub [53] uses a computational model for separating speech based on the following: pitch, periodicity, possible rate of change within a frequency channel and over consecutive channels.
Reference: [44] <author> Y. Peng and J. Reggia, </author> <title> "Plausibility of Diagnostic Hypotheses: The Nature of Simplicity", </title> <booktitle> AAAI 86 Proceedings, </booktitle> <pages> pp 140-145. </pages>
Reference: [45] <author> J. Picone, </author> <title> "Continuous Speech Recognition Using Hidden Markov Models", </title> <journal> IEEE ASSP Magazine, </journal> <pages> pp. 26-41, </pages> <month> July </month> <year> 1990. </year>
Reference-contexts: In particular, we discuss subsym-bolic object model acquisition systems that use HMM and ANN techniques. HMMs in Speech Recognition: Hidden Markov Models <ref> [31, 45, 48] </ref> have been predominantly used in speech recognition. They are a generalization of dynamic programming and provide a rigorous approach to developing robust statistical models.
Reference: [46] <author> J.R. Quinlan, </author> <title> "Induction of Decision Trees", </title> <journal> Machine Learning Vol.1, </journal> <volume> No.1, </volume> <pages> pp. 81-106, </pages> <year> 1986. </year>
Reference-contexts: The recognition strategies in many of these systems are basically search trees, constructed by applying a set of rules that determine relevant features of the unknown image in order to establish object identity. The SLS [17] uses decision trees <ref> [46] </ref> to represent recognition strategies. Common to all the systems is that they address issues of feature selection and ordering.
Reference: [47] <author> L.R. Rabiner, J.G. Wilpon, F.K. Soong, </author> <title> "High Performance Digit Recognition Using Hidden Markov Models", </title> <booktitle> Proceedings IEEE ICASSP, </booktitle> <pages> pp. 119-122, </pages> <address> New York, </address> <month> April </month> <year> 1988. </year>
Reference-contexts: However, the high degree of similarity among them enabled the use of clustering techniques to achieve data compression to yield a smaller set of generalized triphones. 10 straints from the limited application domain to aid in the recognition task. The AT&T digit recognition system <ref> [47] </ref> and the Texas Instruments system [14] are word-based 5 speaker-independent digit recognition systems. In the digit recognition task, grammar constraints are minimal: any digit may appear after any other. This places a greater need for good acoustic matching to achieve high performance.
Reference: [48] <author> L. Rabiner, </author> <title> "A Tutorial on Hidden Markov Models and Selected Applications in Speech Recognition", </title> <journal> The IEEE , Vol. </journal> <volume> 77, No. 2, </volume> <pages> pp. 257-285, </pages> <month> February </month> <year> 1989. </year>
Reference-contexts: Yet another illustration of the problem is found in the domain of vision where "pose" varies with the observation perspective. Radar and Sonar data are typically contaminated with noise. Subsymbolic approaches, such as artificial neural nets (ANNs) [49], hidden Markov models (HMMs) <ref> [48] </ref> and hybrids thereof [12] have successfully been used for object modeling in systems with fixed front-ends for feature extraction. These approaches have yielded performance improvements over hand-crafted versions. In comparison, little work has been done with object model acquisition for systems with adaptive front-ends. <p> In particular, we discuss subsym-bolic object model acquisition systems that use HMM and ANN techniques. HMMs in Speech Recognition: Hidden Markov Models <ref> [31, 45, 48] </ref> have been predominantly used in speech recognition. They are a generalization of dynamic programming and provide a rigorous approach to developing robust statistical models.
Reference: [49] <author> D.E. Rumelhart, </author> <title> J.L.McClelland and the PDP Research Group, Parallel Distributed Processing, Explorations in the Microstructure of Cognition, Vol. I: Foundations, A Bradford Book, </title> <publisher> MIT Press, </publisher> <year> 1986. </year>
Reference-contexts: Yet another illustration of the problem is found in the domain of vision where "pose" varies with the observation perspective. Radar and Sonar data are typically contaminated with noise. Subsymbolic approaches, such as artificial neural nets (ANNs) <ref> [49] </ref>, hidden Markov models (HMMs) [48] and hybrids thereof [12] have successfully been used for object modeling in systems with fixed front-ends for feature extraction. These approaches have yielded performance improvements over hand-crafted versions. In comparison, little work has been done with object model acquisition for systems with adaptive front-ends. <p> This places a greater need for good acoustic matching to achieve high performance. In the Texas Instruments system, a discrimination transformation was designed to maximize discrimination between the correctly recognized data and the confusion class for each state in the HMM word model. ANNs in Perceptual Systems: ANNs <ref> [49] </ref> have been extensively exploited in recognition tasks chiefly because they are capable of representing a variety of statistical properties of data distributions in an automatic manner. They are good at generalization and in the retrieval of stored patterns that most closely resemble an input pattern. <p> ANNs have also demonstrated good performance for Sonar [1, 36] and Radar [26] domains. The ANN approaches accept as input a fixed set of features and use one of several training techniques <ref> [49] </ref> for inducing a classifier. Several net architectural parameters such as the number of input and output nodes, training method, number of hidden layers, number of nodes within them, and learning rate require careful selection. Classification performance is sensitive to these parameters. <p> The higher the degree of freedom, the greater the need for training data to establish them adequately <ref> [31, 49, 2] </ref>. When labeled training data is relatively sparse, symbolic approaches may be more appropriate. Training Unit based Training Data Requirements: Where the basic training unit may be shared among the different object classes, training data requirements are reduced.
Reference: [50] <author> R. W. Schafer, </author> <title> L.R. Rabiner, "Digital Representation of Speech Signals", Readings in Speech Recognition, Edited by: </title> <editor> Alex Waibel and Kai-Fu Lee, </editor> <publisher> Morgan Kaufman Publishers, Inc. </publisher> <address> San Mateo, California, </address> <year> 1990. </year>
Reference: [51] <author> C. Vadala, </author> <title> "Gathering and Evaluating Evidence for Sound Producing Events", </title> <type> Masters Thesis, </type> <institution> Dept of Biomedical Engineering, Boston University, </institution> <month> January </month> <year> 1992. </year>
Reference-contexts: Typically the object models have been hand-crafted, a tedious and error prone activity that constitutes a knowledge acquisition bottleneck. Automating model acquisition for adaptive perceptual systems has received relatively limited attention <ref> [37, 38, 51] </ref>. Much of this effort relies on human intervention such as suggesting alternate SPA parameterizations when feature inadequacies are encountered, or in the initialization of critical parameters. In the case of vision applications, the availability of adequately segmented images is assumed [37, 39]. <p> Murase and Nayar [39] acquire object models that do not use multiple levels of data abstraction for visual object recognition. Vadala <ref> [51] </ref> developed a semi-automatic approach for acquiring sound source models requiring multiple levels of data abstraction. Adaptive Front-End: Vadala's [51] semi-automatic approach for sound source model acquisition is based on the principles of the SUT [32, 33]. <p> Murase and Nayar [39] acquire object models that do not use multiple levels of data abstraction for visual object recognition. Vadala <ref> [51] </ref> developed a semi-automatic approach for acquiring sound source models requiring multiple levels of data abstraction. Adaptive Front-End: Vadala's [51] semi-automatic approach for sound source model acquisition is based on the principles of the SUT [32, 33]. <p> Consequently, such systems have relied on hand-crafted symbolic object models, and as a result they have only partially addressed the knowledge acquisition bottleneck. Adaptive front-ends and Human Guidance: Vadala's <ref> [51] </ref> system for acquiring sound source models, as an initial first step in the modeling of each sound, seeks significant human guidance to adapt some key SPA parameters. In addition, a priori the number of distinct object classes have to be specified. <p> Such scenarios require the power of adaptive feature extraction to give improved recognition performance. Exceptions to the above are the systems of Mori et al [38] and Vadala <ref> [51] </ref>, which cope with adaptive feature extraction, learning recognition strategies and object models respectively. Both systems however require user interaction; the former requiring assistance when a classification ambiguity is detected and the latter requiring assistance in the initial selection of the SPAs and some of their parameters.
Reference: [52] <author> R.L. Watrous, L. Shastri, A.H. Waibel, </author> <title> "Learned Phonetic Discrimination Using Connectionist Networks", </title> <booktitle> European Conference on Speech Technology, </booktitle> <pages> pp 377-380, </pages> <address> Edinburgh 1987. </address>
Reference: [53] <author> M. Weintraub, </author> <title> "A Computational Model for Separating Two Simultaneous Talkers", </title> <booktitle> IEEE ICASSP 86, Tokyo, </booktitle> <pages> pp. 81-84, </pages> <year> 1986. </year> <month> 37 </month>
Reference-contexts: It is known as the segmentation problem by vision researchers, speaker segregation by speech researchers and component grouping in the SUT [33]. Parson [43] uses harmonic selection to separate speech from the interfering speech of a second talker before applying VQ based speech recognition techniques. Weintraub <ref> [53] </ref> uses a computational model for separating speech based on the following: pitch, periodicity, possible rate of change within a frequency channel and over consecutive channels. Ming and Bhanu [37] present an adaptive approach to image segmentation. In the SUT, psycho-acoustic criteria [6] are used in grouping frequency components.
References-found: 53

