URL: ftp://ftp.cs.bham.ac.uk/pub/tech-reports/1996/CSRP-96-07.ps.gz
Refering-URL: http://www.cs.bham.ac.uk/~rmp/eebic/index.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: E-mail: fR.Poli,B.S.Logang@cs.bham.ac.uk  
Title: On the Relations Between Search and Evolutionary Algorithms  
Author: Riccardo Poli and Brian Logan 
Address: Birmingham B15 2TT United Kingdom  
Affiliation: School of Computer Science The University of Birmingham  
Abstract: Technical Report: CSRP-96-7 March 1996 Abstract Evolutionary algorithms are powerful techniques for optimisation whose operation principles are inspired by natural selection and genetics. In this paper we discuss the relation between evolutionary techniques, numerical and classical search methods and we show that all these methods are instances of a single more general search strategy, which we call the `evolutionary computation cookbook'. By combining the features of classical and evolutionary methods in different ways new instances of this general strategy can be generated, i.e. new evolutionary (or classical) algorithms can be designed. One such algorithm, GA fl , is described.
Abstract-found: 1
Intro-found: 1
Reference: [1] <editor> Thomas Back and Hans-Paul Schwefel. </editor> <title> An overview of evolutionary algorithms for parameter optimization. </title> <journal> Evolutionary Computation, </journal> <volume> 1(1) </volume> <pages> 1-23, </pages> <year> 1993. </year>
Reference-contexts: 1 Introduction Evolutionary algorithms (EAs) are powerful optimisation techniques inspired by genetics and natural selection <ref> [6, 5, 2, 1, 9] </ref>. EAs are often referred to as global optimisation methods, to stress the fact that they can effectively explore very large solutions spaces without becoming trapped by local minima. <p> Simulated annealing is also similar to hill climbing (or gradient descent) but sometimes accepts a successor which is worse than its parent in order to escape local minima/maxima. 2.3 Evolutionary algorithms Evolutionary algorithms work using strategies inspired by nature <ref> [6, 5, 2, 1, 9] </ref>. As they are usually driven either by a quality (or cost) measure or by a quality comparison predicate, they can be considered informed search algorithms.
Reference: [2] <editor> Lawrence Davis, editor. </editor> <booktitle> Handbook of Genetic Algorithms. </booktitle> <publisher> Van Nostrand Reinhold, </publisher> <address> New York, </address> <year> 1991. </year>
Reference-contexts: 1 Introduction Evolutionary algorithms (EAs) are powerful optimisation techniques inspired by genetics and natural selection <ref> [6, 5, 2, 1, 9] </ref>. EAs are often referred to as global optimisation methods, to stress the fact that they can effectively explore very large solutions spaces without becoming trapped by local minima. <p> Simulated annealing is also similar to hill climbing (or gradient descent) but sometimes accepts a successor which is worse than its parent in order to escape local minima/maxima. 2.3 Evolutionary algorithms Evolutionary algorithms work using strategies inspired by nature <ref> [6, 5, 2, 1, 9] </ref>. As they are usually driven either by a quality (or cost) measure or by a quality comparison predicate, they can be considered informed search algorithms.
Reference: [3] <author> Thomas Dean, James Allen, and Yiannis Aloimonos. </author> <booktitle> Artificial Intelligence: Theory and Practice. </booktitle> <publisher> The Benjamin/Cummings Publishing Company, </publisher> <address> Redwood City, California, </address> <year> 1995. </year>
Reference-contexts: We draw some final conclusions in Section 5. 2 Evolutionary and non-evolutionary search algo rithms 2.1 Classical search algorithms Search algorithms are fundamental problem solving methods in artificial intelligence <ref> [12, 3, 11] </ref>. In order to solve a problem it is necessary: a) to represent its solutions (these are seen as points in what is called the search space for the problem) and b) to design some search operators which given one solution generate new candidate solutions.
Reference: [4] <editor> Marco Dorigo. </editor> <title> Genetic and non-genetic operators in ALECSYS. </title> <journal> Evolutionary Computation, </journal> <volume> 1(2) </volume> <pages> 151-164, </pages> <year> 1993. </year>
Reference-contexts: However they are not without their limitations. In particular, the choice of a good problem-specific representation and a good set of problem-specific genetic operators can 1 make a considerable difference to the efficiency, effectiveness and often even the feasibility of the search <ref> [4, 8, 9] </ref>. Similar problems arise in classical GOFAI (Good Old Fashioned Artificial Intelligence) state space search, where the selection of appropriate problem representations and operators has long been one of the central concerns. This suggests that it is important to explore the parallels between classical and evolutionary approaches.
Reference: [5] <author> David E. Goldberg. </author> <title> Genetic Algorithms in Search, Optimization, and Machine Learning. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Massachusetts, </address> <year> 1989. </year>
Reference-contexts: 1 Introduction Evolutionary algorithms (EAs) are powerful optimisation techniques inspired by genetics and natural selection <ref> [6, 5, 2, 1, 9] </ref>. EAs are often referred to as global optimisation methods, to stress the fact that they can effectively explore very large solutions spaces without becoming trapped by local minima. <p> Simulated annealing is also similar to hill climbing (or gradient descent) but sometimes accepts a successor which is worse than its parent in order to escape local minima/maxima. 2.3 Evolutionary algorithms Evolutionary algorithms work using strategies inspired by nature <ref> [6, 5, 2, 1, 9] </ref>. As they are usually driven either by a quality (or cost) measure or by a quality comparison predicate, they can be considered informed search algorithms.
Reference: [6] <author> John Holland. </author> <title> Adaptation in Natural and Artificial Systems. </title> <publisher> MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <note> second edition, </note> <year> 1992. </year>
Reference-contexts: 1 Introduction Evolutionary algorithms (EAs) are powerful optimisation techniques inspired by genetics and natural selection <ref> [6, 5, 2, 1, 9] </ref>. EAs are often referred to as global optimisation methods, to stress the fact that they can effectively explore very large solutions spaces without becoming trapped by local minima. <p> Simulated annealing is also similar to hill climbing (or gradient descent) but sometimes accepts a successor which is worse than its parent in order to escape local minima/maxima. 2.3 Evolutionary algorithms Evolutionary algorithms work using strategies inspired by nature <ref> [6, 5, 2, 1, 9] </ref>. As they are usually driven either by a quality (or cost) measure or by a quality comparison predicate, they can be considered informed search algorithms.
Reference: [7] <author> John R. Koza. </author> <title> Genetic Programming: On the Programming of Computers by Means of Natural Selection. </title> <publisher> MIT Press, </publisher> <year> 1992. </year>
Reference-contexts: As GAs often use binary representations for the solutions of a problem, crossover and mutation are usually bit-string manipulation operators. However, various alternative representations such as permutation lists or parse trees are used in algorithms derived from the basic GA, e.g. genetic programming <ref> [7] </ref>. Many other variants of the basic scheme exist. 2.3.2 Evolutionary Strategies Evolutionary Strategies (ESs) are parameter optimisation techniques. In ESs chromosomes are vectors of real valued parameters. Various forms of ESs exist: (1 + 1) ES uses a population consisting of only one individual.
Reference: [8] <author> Zbigniew Michalewicz. </author> <title> A hierarchy of evolution programs: An experimental study. </title> <journal> Evolutionary Computation, </journal> <volume> 1(1) </volume> <pages> 51-76, </pages> <year> 1993. </year>
Reference-contexts: However they are not without their limitations. In particular, the choice of a good problem-specific representation and a good set of problem-specific genetic operators can 1 make a considerable difference to the efficiency, effectiveness and often even the feasibility of the search <ref> [4, 8, 9] </ref>. Similar problems arise in classical GOFAI (Good Old Fashioned Artificial Intelligence) state space search, where the selection of appropriate problem representations and operators has long been one of the central concerns. This suggests that it is important to explore the parallels between classical and evolutionary approaches.
Reference: [9] <author> Zbigniew Michalewicz. </author> <title> Genetic Algorithms + Data Structures = Evolution Programs. </title> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <note> second edition, </note> <year> 1994. </year>
Reference-contexts: 1 Introduction Evolutionary algorithms (EAs) are powerful optimisation techniques inspired by genetics and natural selection <ref> [6, 5, 2, 1, 9] </ref>. EAs are often referred to as global optimisation methods, to stress the fact that they can effectively explore very large solutions spaces without becoming trapped by local minima. <p> However they are not without their limitations. In particular, the choice of a good problem-specific representation and a good set of problem-specific genetic operators can 1 make a considerable difference to the efficiency, effectiveness and often even the feasibility of the search <ref> [4, 8, 9] </ref>. Similar problems arise in classical GOFAI (Good Old Fashioned Artificial Intelligence) state space search, where the selection of appropriate problem representations and operators has long been one of the central concerns. This suggests that it is important to explore the parallels between classical and evolutionary approaches. <p> Simulated annealing is also similar to hill climbing (or gradient descent) but sometimes accepts a successor which is worse than its parent in order to escape local minima/maxima. 2.3 Evolutionary algorithms Evolutionary algorithms work using strategies inspired by nature <ref> [6, 5, 2, 1, 9] </ref>. As they are usually driven either by a quality (or cost) measure or by a quality comparison predicate, they can be considered informed search algorithms.
Reference: [10] <author> J. Pearl. </author> <title> a fl * an algorithm using search effort estimates. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 4(4) </volume> <pages> 392-399, </pages> <year> 1982. </year>
Reference-contexts: Unfortunately, the huge amount of memory and computation required by classical A fl to solve this kind of problems has prevented us from being able to perform the comparison. However, we have been able to use a variant of A fl known as A fl * (see <ref> [10] </ref>) which is guaranteed to find solutions that can be worse than optimal by at most *. A plan produced by A fl * with * = 0:1 is shown in Figure 5 (b).
Reference: [11] <author> S. J. Russell and P. Norvig. </author> <title> Artificial Intelligence: A Modern Approach. </title> <publisher> Prendice Hall, </publisher> <address> Englewood Cliffs, New Jersey, </address> <year> 1995. </year>
Reference-contexts: We draw some final conclusions in Section 5. 2 Evolutionary and non-evolutionary search algo rithms 2.1 Classical search algorithms Search algorithms are fundamental problem solving methods in artificial intelligence <ref> [12, 3, 11] </ref>. In order to solve a problem it is necessary: a) to represent its solutions (these are seen as points in what is called the search space for the problem) and b) to design some search operators which given one solution generate new candidate solutions.
Reference: [12] <author> P. H. Winston. </author> <booktitle> Artificial Intelligence. </booktitle> <publisher> Addison-Wesley, </publisher> <address> third edition, </address> <year> 1992. </year> <month> 12 </month>
Reference-contexts: We draw some final conclusions in Section 5. 2 Evolutionary and non-evolutionary search algo rithms 2.1 Classical search algorithms Search algorithms are fundamental problem solving methods in artificial intelligence <ref> [12, 3, 11] </ref>. In order to solve a problem it is necessary: a) to represent its solutions (these are seen as points in what is called the search space for the problem) and b) to design some search operators which given one solution generate new candidate solutions.
References-found: 12

