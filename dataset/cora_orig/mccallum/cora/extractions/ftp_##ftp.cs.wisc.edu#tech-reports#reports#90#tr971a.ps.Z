URL: ftp://ftp.cs.wisc.edu/tech-reports/reports/90/tr971a.ps.Z
Refering-URL: 
Root-URL: 
Title: PARALLEL CONSTRAINT DISTRIBUTION  
Author: M. C. FERRIS AND O. L. MANGASARIAN 
Keyword: Key words. Parallel Optimization, Augmented Lagrangians, Quadratic Programs, Convex Programs  
Abstract: Constraints of a mathematical program are distributed among parallel processors together with an appropriately constructed augmented Lagrangian for each processor, which contains Lagrangian information on the constraints handled by the other processors. Lagrange multiplier information is then exchanged between processors. Convergence is established under suitable conditions for strongly convex quadratic programs and for general convex programs. 1. Introduction. We are concerned with the problem 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D. Bertsekas, </author> <title> Constrained Optimization and Lagrange Multiplier Methods, </title> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1982. </year>
Reference-contexts: Considerable experimentation with various Lagrangian terms [3] has highlighted the difference between theoretical convergence and computational efficiency. We believe that we now have effective modified objectives for each processor that can best be described as augmented Lagrangian functions <ref> [19, 20, 1] </ref>. The modified objectives are made up of the original objective function plus augmented Lagrangian terms involving the constraints handled by the other processors. <p> Note that the objectives of the subproblems (2.2) are quadratic augmented Lagrangians <ref> [19, 20, 1] </ref> perturbed by the linear terms x T l r i l . The motivation of this reformulation is that in each subproblem some constraints are treated explicitly as constraints while the remaining ones are treated as augmented Lagrangian terms in the objective function. <p> The updating of the multipliers is done by solving the subproblems explicitly rather than the traditional, and often slow, gradient updating scheme in the dual space of the augmented Lagrangian approach <ref> [1] </ref>. Hence our method does not use a gradient or a proximal point multiplier updating scheme.
Reference: [2] <author> R. Cottle, J.-S. Pang, and R. Stone, </author> <title> The Linear Complementarity Problem, </title> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1991. </year>
Reference-contexts: The convergence conditions for splitting nonsymmetric LCP's are quite stringent <ref> [2, Chapter 5] </ref> and not useful for our proposed applications here. We have therefore settled on choices for the parameters p i jl and r i l which are different to those in (2.19), and which generate a symmetric positive semidefinite M .
Reference: [3] <author> R. De Leone and O. Mangasarian, </author> <title> Parallel proximal point decomposition of linear programming constraints. </title> <booktitle> SIAM National Meeting, </booktitle> <address> Chicago, Illinois, </address> <month> July 16-20, </month> <year> 1990. </year>
Reference-contexts: Other recently proposed decomposition methods and applications thereof can be found in [22, 8, 5, 21]. The key to our approach lies in the precise form of the modified objective function to be optimized by each processor. Considerable experimentation with various Lagrangian terms <ref> [3] </ref> has highlighted the difference between theoretical convergence and computational efficiency. We believe that we now have effective modified objectives for each processor that can best be described as augmented Lagrangian functions [19, 20, 1].
Reference: [4] <author> A. de Pierro and A. Iusem, </author> <title> Convergence properties of iterative methods for symmetric positive semidefinite linear complementarity problems, </title> <type> tech. report, </type> <institution> Instituto de Matematica, Elasticita e Ciencia da Computacao, Universidade Estadual de Campinas, </institution> <address> CP 6065, Camp-inas, 13081, SP, Brazil, </address> <year> 1990. </year>
Reference-contexts: research supported by the Air Force Office of Scientific Research Grant AFOSR-89-0410 and National Science Foundation Grants DCR-8521228 and CCR-8723091 y Computer Sciences Department, University of Wisconsin, 1210 West Dayton Street, Madison, Wisconsin 53706 1 proposed in [11, Algorithm 2.1] for which full sequential convergence has just recently been established <ref> [9, 4, 17] </ref>. In Section 3 we establish a weaker convergence of the PCD algorithm (Theorem 3.2) for the general convex program (1.1) with a strongly convex objective function. <p> then determining z i+1 by using a step-size , that is z i+1 = (1 )z i + z i+1 ; 2 (0; 1](2.16) Under assumption (2.14) the whole sequence fz i g generated by (2.15) and (2.16) con verges to a solution of (2.12) provided the latter is solvable <ref> [9, 4, 17] </ref>.
Reference: [5] <author> J. Eckstein and D. Bertsekas, </author> <title> On the Douglas-Rachford splitting method and the proximal point algorithm for maximal monotone operators, </title> <booktitle> Mathematical Programming, </booktitle> <year> (1991). </year> <note> To appear. </note>
Reference-contexts: We then solve each of these k sub-problems independently, share Lagrange multiplier information among the processors and repeat. Other recently proposed decomposition methods and applications thereof can be found in <ref> [22, 8, 5, 21] </ref>. The key to our approach lies in the precise form of the modified objective function to be optimized by each processor. Considerable experimentation with various Lagrangian terms [3] has highlighted the difference between theoretical convergence and computational efficiency.
Reference: [6] <author> M. Ferris, </author> <title> Parallel constraint distribution for convex quadratic programs, </title> <type> Tech. Report 1009, </type> <institution> Computer Sciences Department, University of Wisconsin, Madison, Wisconsin 53706, </institution> <year> 1991. </year>
Reference-contexts: Further experimentation is needed to determine the best splitting. We now proceed to show how the parameters p i l are chosen and to justify these choices from the point of view of convergent matrix splitting. A simpler splitting approach for constraint distribution for quadratic programs is given in <ref> [6] </ref>.
Reference: [7] <author> D. Gay, </author> <title> Electronic mail distribution of linear programming test problems, </title> <journal> COAL Newsletter, </journal> <volume> 13 (1985), </volume> <pages> pp. 10-12. </pages>
Reference-contexts: The first three are homemade test problems, while the last two, AFIRO and ADLittle, are from the NETLIB collection <ref> [7] </ref>. In the tables, an empty column entry signifies that we did not perform the computation. The character * signifies that the algorithm did not terminate.
Reference: [8] <author> S.-P. Han, </author> <title> A decomposition method and its application to convex programming, </title> <journal> Mathematics of Operations Research, </journal> <volume> 14 (1989), </volume> <pages> pp. 237-248. </pages>
Reference-contexts: We then solve each of these k sub-problems independently, share Lagrange multiplier information among the processors and repeat. Other recently proposed decomposition methods and applications thereof can be found in <ref> [22, 8, 5, 21] </ref>. The key to our approach lies in the precise form of the modified objective function to be optimized by each processor. Considerable experimentation with various Lagrangian terms [3] has highlighted the difference between theoretical convergence and computational efficiency.
Reference: [9] <author> Z.-Q. Luo and P. Tseng, </author> <title> On the convergence of a matrix splitting algorithm for the symmetric monotone linear complementarity problem, </title> <type> Tech. Report LIDS-P-1884, </type> <institution> MIT, Cambridge, Massachusetts, </institution> <year> 1989. </year> <note> To appear, SIAM Journal on Control and Optimization. </note>
Reference-contexts: research supported by the Air Force Office of Scientific Research Grant AFOSR-89-0410 and National Science Foundation Grants DCR-8521228 and CCR-8723091 y Computer Sciences Department, University of Wisconsin, 1210 West Dayton Street, Madison, Wisconsin 53706 1 proposed in [11, Algorithm 2.1] for which full sequential convergence has just recently been established <ref> [9, 4, 17] </ref>. In Section 3 we establish a weaker convergence of the PCD algorithm (Theorem 3.2) for the general convex program (1.1) with a strongly convex objective function. <p> The key to the convergence of our algorithm, for the quadratic case, is the choice of the parameters p i jl and r i l in such a way that the PCD algorithm is equivalent to a convergent iterative matrix-splitting method <ref> [11, 9, 14, 17] </ref> for a symmetric linear complementarity problem in the dual variables of the problem. This choice is by no means unique and we have experimented computationally with a number of choices for the p i jl and r i l which we report on in Section 4. <p> then determining z i+1 by using a step-size , that is z i+1 = (1 )z i + z i+1 ; 2 (0; 1](2.16) Under assumption (2.14) the whole sequence fz i g generated by (2.15) and (2.16) con verges to a solution of (2.12) provided the latter is solvable <ref> [9, 4, 17] </ref>. <p> Thus if is chosen sufficiently small, and specifically such that 0 &lt; 1 and &lt; 2 (min eigenvalue (B) / max eigenvalue (M ))(2.30) it follows that (2.13) above (which is condition (6) of [11]) and (2.14) above (which is condition (4.1) of <ref> [9] </ref>) are satisfied. Hence, since the LCP (2.12) is solvable, the sequence fz i g converges [9, Theorem 2 and Example 3] to a solution of the LCP (2.12), and by z i+1 = (1 )z i + z i+1 , so does the sequence fz i g. <p> Hence, since the LCP (2.12) is solvable, the sequence fz i g converges <ref> [9, Theorem 2 and Example 3] </ref> to a solution of the LCP (2.12), and by z i+1 = (1 )z i + z i+1 , so does the sequence fz i g.

Reference: [15] <author> O. Mangasarian and R. Meyer, </author> <title> Nonlinear perturbation of linear programs, </title> <journal> SIAM Journal on Control and Optimization, </journal> <volume> 17 (1979), </volume> <pages> pp. 745-752. </pages>
Reference-contexts: In order to strongly convexify the objective we have used the least two-norm formulation <ref> [15, 12] </ref>, where for * 2 (0; *] for some * &gt; 0, the solution of minimize b T y + * 2 y T y subject to A T y c (4.2) is the least two-norm solution of (4.1).
Reference: [16] <author> B. Murtagh and M. Saunders, </author> <title> MINOS 5.0 user's guide, </title> <type> Technical Report SOL 83.20, </type> <institution> Stan-ford University, </institution> <month> December </month> <year> 1983. </year>
Reference-contexts: The PCD Algorithm 3.2 of Section 3 was implemented on the Sequent Symmetry S-81 shared memory multiprocessor. The subproblems were solved on each processor using MINOS 5.3, a more recent version of <ref> [16] </ref>. The explicit constraints in each subproblem remained fixed throughout the computation but the blocks were not chosen to satisfy the linear independence assumption. We have used the following heuristic scheme to update the augmented Lagrangian parameter, fl.
Reference: [17] <author> J.-S. Pang, </author> <title> Convergence of splitting and Newton methods for complementarity problems: An application of some sensitivity results, </title> <institution> department of Mathematical Sciences, The Johns Hopkins University, </institution> <address> Baltimore, MD 21218, </address> <month> Sept. </month> <year> 1990. </year>
Reference-contexts: research supported by the Air Force Office of Scientific Research Grant AFOSR-89-0410 and National Science Foundation Grants DCR-8521228 and CCR-8723091 y Computer Sciences Department, University of Wisconsin, 1210 West Dayton Street, Madison, Wisconsin 53706 1 proposed in [11, Algorithm 2.1] for which full sequential convergence has just recently been established <ref> [9, 4, 17] </ref>. In Section 3 we establish a weaker convergence of the PCD algorithm (Theorem 3.2) for the general convex program (1.1) with a strongly convex objective function. <p> The key to the convergence of our algorithm, for the quadratic case, is the choice of the parameters p i jl and r i l in such a way that the PCD algorithm is equivalent to a convergent iterative matrix-splitting method <ref> [11, 9, 14, 17] </ref> for a symmetric linear complementarity problem in the dual variables of the problem. This choice is by no means unique and we have experimented computationally with a number of choices for the p i jl and r i l which we report on in Section 4. <p> then determining z i+1 by using a step-size , that is z i+1 = (1 )z i + z i+1 ; 2 (0; 1](2.16) Under assumption (2.14) the whole sequence fz i g generated by (2.15) and (2.16) con verges to a solution of (2.12) provided the latter is solvable <ref> [9, 4, 17] </ref>.
Reference: [18] <author> J.-S. Pang and D. Chan, </author> <title> Iterative methods for variational and complementarity problems, </title> <journal> Mathematical Programming, </journal> <volume> 24 (1982), </volume> <pages> pp. 284-313. </pages>
Reference-contexts: Unfortunately, to establish convergence, we need to assume that the distance between successive values of the multipliers approaches zero. We believe this assumption may be considerably relaxed and probably eliminated if one uses ideas of nonlinear Jacobi relaxation <ref> [18] </ref> for solving nonlinear complementarity problems. A word about our notation now. <p> it is possible under suitable assumptions to solve for x i+1 1 in terms of (s i+1 1 ; s i 2 in terms of (s i 1 ; s i+1 2 ), in which case the PCD Algorithm of (3.2) can be rewritten as the following nonlinear Jacobi iteration <ref> [18] </ref> for solving a nonlinear complementarity problem s i+1 1 ; s i 1 + 2 = flg 2 (x 2 (s i 2 )) + s i+1 (3.3) Improved convergence proofs (see, for example, [18]) may be possible, based on this equivalent Jacobi iteration instead of (3.2). 4. <p> case the PCD Algorithm of (3.2) can be rewritten as the following nonlinear Jacobi iteration <ref> [18] </ref> for solving a nonlinear complementarity problem s i+1 1 ; s i 1 + 2 = flg 2 (x 2 (s i 2 )) + s i+1 (3.3) Improved convergence proofs (see, for example, [18]) may be possible, based on this equivalent Jacobi iteration instead of (3.2). 4. Computational experience. We have tested out the algorithms of the previous sections on some linear programming problems.
Reference: [19] <author> R. Rockafellar, </author> <title> Augmented Lagrange multiplier functions and duality in nonconvex programming, </title> <journal> SIAM Journal on Control, </journal> <volume> 12 (1974), </volume> <pages> pp. </pages> <month> 268-285. </month> <title> [20] , Augmented Lagrangians and applications of the proximal point algorithm in convex programming, </title> <journal> Mathematics of Operations Research, </journal> <volume> 1 (1976), </volume> <pages> pp. 97-116. </pages>
Reference-contexts: Considerable experimentation with various Lagrangian terms [3] has highlighted the difference between theoretical convergence and computational efficiency. We believe that we now have effective modified objectives for each processor that can best be described as augmented Lagrangian functions <ref> [19, 20, 1] </ref>. The modified objectives are made up of the original objective function plus augmented Lagrangian terms involving the constraints handled by the other processors. <p> Note that the objectives of the subproblems (2.2) are quadratic augmented Lagrangians <ref> [19, 20, 1] </ref> perturbed by the linear terms x T l r i l . The motivation of this reformulation is that in each subproblem some constraints are treated explicitly as constraints while the remaining ones are treated as augmented Lagrangian terms in the objective function.
Reference: [21] <author> R. Rockafellar and R.-B. Wets, </author> <title> Scenarios and policy aggregation in optimization under uncertainty, </title> <journal> Mathematics of Operations Research, </journal> <volume> 10 (1991), </volume> <pages> pp. 119-147. </pages>
Reference-contexts: We then solve each of these k sub-problems independently, share Lagrange multiplier information among the processors and repeat. Other recently proposed decomposition methods and applications thereof can be found in <ref> [22, 8, 5, 21] </ref>. The key to our approach lies in the precise form of the modified objective function to be optimized by each processor. Considerable experimentation with various Lagrangian terms [3] has highlighted the difference between theoretical convergence and computational efficiency.
Reference: [22] <author> J. Spingarn, </author> <title> Applications of the method of partial inverses to convex programming, </title> <journal> Mathematical Programming, </journal> <volume> 32 (1985), </volume> <pages> pp. 199-223. 17 </pages>
Reference-contexts: We then solve each of these k sub-problems independently, share Lagrange multiplier information among the processors and repeat. Other recently proposed decomposition methods and applications thereof can be found in <ref> [22, 8, 5, 21] </ref>. The key to our approach lies in the precise form of the modified objective function to be optimized by each processor. Considerable experimentation with various Lagrangian terms [3] has highlighted the difference between theoretical convergence and computational efficiency.
References-found: 16

