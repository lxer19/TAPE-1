URL: http://www.merl.com/reports/TR94-09v2/TR94-09v2.ps.gz
Refering-URL: http://www.merl.com/reports/TR94-09v2/index.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: osborne@merl.com  
Title: DART: A LAN Interface for Low Overhead Communication  Newsletter on Interconnection Networks for High Performance  
Author: Randy Osborne 
Address: Cambridge, Massachusetts 02139  
Note: To appear in Special Issue of the IEEE Technical Committee on Computer Architecture (TCCA)  Computing Systems,  Copyright c Mitsubishi Electric Research Laboratories, 1994 201 Broadway,  
Date: July 1994  Fall 1994  
Affiliation: MITSUBISHI ELECTRIC RESEARCH LABORATORIES CAMBRIDGE RESEARCH CENTER  
Pubnum: TR-94-09v2  
Abstract: This article presents a low level protocol and network interface architecture for low overhead communication in a distributed memory computing environment | such as workstations and PCs connected via a high speed LAN. We use both sender information and destination information to demultiplex messages directly to where they are needed. The network interface filters incoming messages, separating data delivery from synchronization so as to enable the optimization of simple data delivery while leaving more difficult synchronization to the host processor. To perform this filtering the interface has a small set of simple operations and a small amount of state. We have designed an interface architecture called DART which specializes these ideas to ATM networks. We have built an in-kernel software implementation of this interface with stock workstation and ATM interface cards. This implementation currently achieves a best case application to application latency of 24.5sec. With a hardware version of DART, we expect to achieve latencies of under 10sec for a 155Mbps ATM LAN and under 3sec for a 622Mbps ATM LAN in the workstation LAN environment. This work may not be copied or reproduced in whole or in part for any commercial purpose. Permission to copy in whole or in part without payment of fee is granted for nonprofit educational and research purposes provided that all such whole or partial copies include the following: a notice that such copying is by permission of Mitsubishi Electric Research Laboratories of Cambridge, Massachusetts; an acknowledgment of the authors and individual contributions to the work; and all applicable portions of the copyright notice. Copying, reproduction, or republishing for any other purpose shall require a license with payment of fee to Mitsubishi Electric Research Laboratories. All rights reserved. 
Abstract-found: 1
Intro-found: 1
Reference: [Be94] <author> M. Blumrich and et al. </author> <title> Virtual Memory Mapped Network Interface for the SHRIMP Multicomputer. </title> <booktitle> In Intl Symposium on Computer Architecture, </booktitle> <month> April </month> <year> 1994. </year>
Reference-contexts: However, we use DART in a filtering role for depositing messages, rather than for direct computation (i.e. it is not the main processor) and we provide full protected, multiuser communication. SHRIMP <ref> [Be94] </ref> and Hamlyn [Wil92] adopt a similar emphasis on increasing the participation of the sender to minimize the required functionality at the destination. However both differ from DART in some major ways: they both support only direct addressing and both pin endpoint pages.
Reference: [BP93] <author> D. Banks and M. Prudence. </author> <title> A High-Performance Network Architecture for a PARISC Workstation. </title> <journal> Journal of Selected Areas in Communications, </journal> <pages> pages 191-202, </pages> <month> February </month> <year> 1993. </year>
Reference-contexts: By low overhead communication we mean both low latency and low impact on the host processor. We regard high bandwidth in this environment as a solved problem (see e.g. <ref> [Dav93, BP93, TS93] </ref>). Our objective is a low cost interface to support applications in parallel, distributed, and real-time computing. Low latency is essential for parallel computing.
Reference: [Dav93] <author> B. Davie. </author> <title> The Architecture and Implementation of a High-Speed Host Interface. </title> <journal> Journal of Selected Areas in Communications, </journal> <pages> pages 228-239, </pages> <month> February </month> <year> 1993. </year>
Reference-contexts: By low overhead communication we mean both low latency and low impact on the host processor. We regard high bandwidth in this environment as a solved problem (see e.g. <ref> [Dav93, BP93, TS93] </ref>). Our objective is a low cost interface to support applications in parallel, distributed, and real-time computing. Low latency is essential for parallel computing.
Reference: [De87] <author> W. Dally and et al. </author> <title> Architecture of a Message-Driven Processor. </title> <booktitle> In Intl Symposium on Computer Architecture, </booktitle> <year> 1987. </year>
Reference-contexts: We plan to use this software implementation to evaluate the hybrid deposit model and DART for higher level protocols and applications. 4 Related Work The per cell processing architecture of DART is similar in principle to the message-driven processor (MDP) <ref> [De87] </ref>. However, we use DART in a filtering role for depositing messages, rather than for direct computation (i.e. it is not the main processor) and we provide full protected, multiuser communication.
Reference: [DLM94] <author> C. Dubnicki, K. Li, and M. Mesarina. </author> <title> Network Interface Support for User-Level Buffer Management. In Parallel Computer Routing and Comm. </title> <booktitle> Workshop, </booktitle> <institution> Univ. of Washington, </institution> <month> May </month> <year> 1994. </year>
Reference-contexts: In addition, Hamlyn supports only one delayed action queue per node whereas there can be any number in DART. A simpler version of SHRIMP has a limited form of hybrid addressing without indirection <ref> [DLM94] </ref>. MINI only MERL-TR-94-09v2 July 1994 6 supports direct addressing [MBH94]. Like DART, Axon [SP90] has self describing packets for direct deposit at the destination. However, Axon lacks hardware support for flexible sender and destination-based addressing, hybrid interrupt control, and register operations.
Reference: [Ke94a] <author> P. Keleher and et al. TreadMarks: </author> <title> Distributed Shared Memory on Standard Workstations and Operating Systems. </title> <booktitle> In Proc. of Winter Usenix Conf., </booktitle> <month> January </month> <year> 1994. </year>
Reference-contexts: This is about 10 times faster than the fastest conventional approach (using Fore System's AAL3/4 implementation) on the same hardware <ref> [Ke94a] </ref>. With our DART interface, we expect to achieve latencies of under 10sec for a 155Mbps ATM LAN and under 3sec for a 622Mbps ATM LAN in the workstation LAN environment (for one transit of a fast ATM switch).
Reference: [Ke94b] <author> J. Kuskin and et al. </author> <title> The Stanford FLASH Multiprocessor. </title> <booktitle> In Intl Symposium on Computer Architecture, </booktitle> <month> April </month> <year> 1994. </year>
Reference-contexts: Other interface architectures also do this, but either just do simple DMA or are expensive like the high speed MAGIC interface in FLASH <ref> [Ke94b] </ref>.
Reference: [MBH94] <author> R. Minnich, D. Burns, and F. Hady. </author> <title> A 1.2Gbit/sec, 1 microsend latency ATM Interface. In Hot Interconnects II, </title> <month> August </month> <year> 1994. </year>
Reference-contexts: In addition, Hamlyn supports only one delayed action queue per node whereas there can be any number in DART. A simpler version of SHRIMP has a limited form of hybrid addressing without indirection [DLM94]. MINI only MERL-TR-94-09v2 July 1994 6 supports direct addressing <ref> [MBH94] </ref>. Like DART, Axon [SP90] has self describing packets for direct deposit at the destination. However, Axon lacks hardware support for flexible sender and destination-based addressing, hybrid interrupt control, and register operations. Acknowledgments Development of the hybrid deposit model benefited from discussions with Peter Steenkiste and Thomas Gross at CMU.
Reference: [Osb94] <author> R. Osborne. </author> <title> A Hybrid Deposit Model for Low Overhead Communication in High Speed LANs. </title> <booktitle> 4th IFIP International Workshop on Protocols for High Speed Networks., </booktitle> <month> August </month> <year> 1994. </year>
Reference-contexts: More complex operations can be achieved using multiple compound messages. For further information on the hybrid deposit model see <ref> [Osb94] </ref>. <p> Remote reads are handled without the interrupting the host processor. Exceptions arising due to error traps, TLB misses, and unimplemented operations cause an interrupt to the host processor. A variant of DART interprets the operation field as an "instruction" pointer to an opcode and operand at the destination (see <ref> [Osb94] </ref> for details). Many implementation details require further evaluation before DART implementation can begin. We are targeting the PCI bus and plan to use a cheap i960 embedded processor to implement the Operation Logic.
Reference: [Se93] <author> J. Subhlok and et al. </author> <title> Programming Task and Data Parallelism on a Multicomputer. </title> <booktitle> In Proc. of ACM Sympos. on Principles and Practice of Parallel Programming, </booktitle> <pages> pages 13-22, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: This idea exploits the sender's knowledge, shifting more of the burden to the sender, in order to simplify the message processing at the destination. In effect, the sender uses its knowledge to pre-demultiplex the messages. <ref> [Se93] </ref> termed a sender-based subset of this idea the "deposit" model. In our case, the deposit action (address and interrupt generation) is a function of both sender and destination information, so we call our scheme a "hybrid deposit" model. Our variation also supports protected, user level communication.
Reference: [SP90] <author> J. Sterbenz and G. Parulka. Axon: </author> <title> A High Speed Communication Architecture for Distributed Applications. </title> <booktitle> In Proceedings of IEEE INFOCOM, </booktitle> <year> 1990. </year>
Reference-contexts: In addition, Hamlyn supports only one delayed action queue per node whereas there can be any number in DART. A simpler version of SHRIMP has a limited form of hybrid addressing without indirection [DLM94]. MINI only MERL-TR-94-09v2 July 1994 6 supports direct addressing [MBH94]. Like DART, Axon <ref> [SP90] </ref> has self describing packets for direct deposit at the destination. However, Axon lacks hardware support for flexible sender and destination-based addressing, hybrid interrupt control, and register operations. Acknowledgments Development of the hybrid deposit model benefited from discussions with Peter Steenkiste and Thomas Gross at CMU.
Reference: [TS93] <author> C. Traw and J. Smith. </author> <title> Hardware/Software Organization of a High-Performance ATM Host Interface. </title> <journal> Journal of Selected Areas in Communications, </journal> <pages> pages 240-253, </pages> <month> February </month> <year> 1993. </year> <editor> [von92] von Eicken et al. </editor> <title> Active Messages: A Mechanism for Integrated Communication and Computation. </title> <booktitle> In Intl Symposium on Computer Architecture, </booktitle> <pages> pages 256-266, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: By low overhead communication we mean both low latency and low impact on the host processor. We regard high bandwidth in this environment as a solved problem (see e.g. <ref> [Dav93, BP93, TS93] </ref>). Our objective is a low cost interface to support applications in parallel, distributed, and real-time computing. Low latency is essential for parallel computing.
Reference: [Wil92] <author> J. Wilkes. Hamlyn: </author> <title> An Interface for Sender-based Communication. </title> <type> Technical Report HPL-OSR-92-13, </type> <institution> HP Labs, </institution> <month> November </month> <year> 1992. </year> <month> MERLTR-94-09v2 July </month> <year> 1994 </year>
Reference-contexts: However, we use DART in a filtering role for depositing messages, rather than for direct computation (i.e. it is not the main processor) and we provide full protected, multiuser communication. SHRIMP [Be94] and Hamlyn <ref> [Wil92] </ref> adopt a similar emphasis on increasing the participation of the sender to minimize the required functionality at the destination. However both differ from DART in some major ways: they both support only direct addressing and both pin endpoint pages.
References-found: 13

