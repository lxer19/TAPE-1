URL: http://www.research.microsoft.com/~toddpro/papers/popl96.ps
Refering-URL: http://www.research.microsoft.com/~toddpro/
Root-URL: http://www.research.microsoft.com
Title: Filter Fusion  
Author: Todd A. Proebsting Scott A. Watterson 
Affiliation: University of Arizona  University of Arizona  
Abstract-found: 0
Intro-found: 1
Reference: [Abb93] <author> Mark B. Abbott. </author> <title> A Language-Based Approach to Protocol Implementation. </title> <type> PhD thesis, </type> <institution> University of Arizona, </institution> <year> 1993. </year>
Reference-contexts: By automating ILP, Filter Fusion allows the programmer to retain modular design without sacrificing performance. Abbot partially automated ILP for network applications <ref> [Abb93] </ref>. His system has two significant drawbacks, however: it cannot handle arbitrary control-flow within a filter, and it assumes the typical network data layout that partitions header and data. His protocols had three stages: initial, data manipulation, and final. <p> The data-accessing overhead in most encryption methods (e.g., RSA, DES) is dwarfed by intensive computation, and therefore gains little from Filter Fusion. The PES filter is not intended to model an actual encryption method, but rather to model another lightweight data manipulation <ref> [Abb93] </ref>. Our third experiment used more new filters. We added a decryption phase, another byteswapping phase, and a decode phase to the previous experiment. To verify the correctness of FFC-generated code, we created the following composition.
Reference: [ASU86] <author> A. V. Aho, R. Sethi, and J. D. Ullman. </author> <booktitle> Compilers: Principles, Techniques, and Tools. </booktitle> <publisher> Addison-Wesley, </publisher> <address> Reading, Mas-sachusetts, </address> <year> 1986. </year>
Reference: [BD77] <author> R. M. Burstall and John Darlington. </author> <title> A transformation system for developing recursive programs. </title> <journal> Journal of the ACM, </journal> <volume> 24(1) </volume> <pages> 44-67, </pages> <month> January </month> <year> 1977. </year>
Reference-contexts: Partial evaluation, listlessness, and deforestation exploit, in one way or another, the basic unfold/instantiate/fold framework originally proposed by Burstall and Dar-lington to improve programs <ref> [BD77] </ref>. While this system automated program transformation rather than program analysis, its framework was revolutionary. Recently, partial evaluation has been the dominant paradigm for eliminating unnecessary computation from programs [JGS93].
Reference: [CJRS89] <author> David D. Clark, Van Jacobson, John Romkey, and Howard Salwen. </author> <title> An analysis of tcp processing overhead. </title> <journal> IEEE Communications Magazine, </journal> <month> June </month> <year> 1989. </year>
Reference-contexts: These manipulations form the protocol stack. Redundant memory access can dominate the processing time for these applications. A technique called Integrated Layer Processing (ILP) optimizes these data ma nipulations [CT90]. ILP, a generalization of loop jamming or loop fusion, does increase performance <ref> [CT90, CJRS89, DAPP93] </ref>. Clark and Tennenhouse report dramatic performance improvements from ILP [CT90]. Based on their results, they argue for less modular programming|when efficiency is critical and sequential data manipulations are too costly, the programmer must abandon abstraction and merge protocols.
Reference: [CT90] <author> David D. Clark and David L. Tennen-house. </author> <title> Architectural considerations for a new generation of protocols. </title> <booktitle> In Proceedings of the SIGCOMM '90 Symposium, </booktitle> <pages> pages 200-208, </pages> <month> September </month> <year> 1990. </year>
Reference-contexts: Network applications often require many simple manipulations of each network packet. These manipulations form the protocol stack. Redundant memory access can dominate the processing time for these applications. A technique called Integrated Layer Processing (ILP) optimizes these data ma nipulations <ref> [CT90] </ref>. ILP, a generalization of loop jamming or loop fusion, does increase performance [CT90, CJRS89, DAPP93]. Clark and Tennenhouse report dramatic performance improvements from ILP [CT90]. <p> These manipulations form the protocol stack. Redundant memory access can dominate the processing time for these applications. A technique called Integrated Layer Processing (ILP) optimizes these data ma nipulations [CT90]. ILP, a generalization of loop jamming or loop fusion, does increase performance <ref> [CT90, CJRS89, DAPP93] </ref>. Clark and Tennenhouse report dramatic performance improvements from ILP [CT90]. Based on their results, they argue for less modular programming|when efficiency is critical and sequential data manipulations are too costly, the programmer must abandon abstraction and merge protocols. <p> Redundant memory access can dominate the processing time for these applications. A technique called Integrated Layer Processing (ILP) optimizes these data ma nipulations <ref> [CT90] </ref>. ILP, a generalization of loop jamming or loop fusion, does increase performance [CT90, CJRS89, DAPP93]. Clark and Tennenhouse report dramatic performance improvements from ILP [CT90]. Based on their results, they argue for less modular programming|when efficiency is critical and sequential data manipulations are too costly, the programmer must abandon abstraction and merge protocols. By automating ILP, Filter Fusion allows the programmer to retain modular design without sacrificing performance.
Reference: [DAPP93] <author> Peter Druschel, Mark B. Abbott, Michael A. Pagels, and Larry L. Pe-terson. </author> <title> Network subsystem design: A case for an integrated data path. </title> <journal> IEEE Network Magazine, </journal> <month> July </month> <year> 1993. </year>
Reference-contexts: These manipulations form the protocol stack. Redundant memory access can dominate the processing time for these applications. A technique called Integrated Layer Processing (ILP) optimizes these data ma nipulations [CT90]. ILP, a generalization of loop jamming or loop fusion, does increase performance <ref> [CT90, CJRS89, DAPP93] </ref>. Clark and Tennenhouse report dramatic performance improvements from ILP [CT90]. Based on their results, they argue for less modular programming|when efficiency is critical and sequential data manipulations are too costly, the programmer must abandon abstraction and merge protocols.
Reference: [GG90] <author> Ralph E. Griswold and Madge T. Gris-wold. </author> <title> The Icon Programming Language. </title> <publisher> Prentice Hall, </publisher> <year> 1990. </year>
Reference-contexts: The algorithm describes the steps to compute the untrimmed graph. Trimming the graph of dangling put nodes is straightforward. Also, a little additional bookkeeping is necessary to transform put's and get's into assignment and reads of temporaries. 6 Experimental Results FFC is a 200-line Icon program <ref> [GG90] </ref>. FFC is a preprocessor that generates C code from a compact specification language. We tested FFC's code against modular and hand-integrated implementations on a variety of platforms and compilers. The modular implementation uses arrays for communicating values between adjacent filters.
Reference: [JGS93] <author> Neil D. Jones, Carsten K. Gomard, and Peter Sestoft. </author> <title> Partial Evaluation and Automatic Program Generation. </title> <publisher> Prentice-Hall, </publisher> <address> New York, </address> <year> 1993. </year>
Reference-contexts: While this system automated program transformation rather than program analysis, its framework was revolutionary. Recently, partial evaluation has been the dominant paradigm for eliminating unnecessary computation from programs <ref> [JGS93] </ref>. While an oversimplification, partial evaluation strengthens Burstall and Darlington's work by maintaining significant state information|the state of the static values| at all program points during transformation. Partial evaluation has been applied to functional languages with much more success than to imperative languages.
Reference: [MMO + 95] <author> A. B. Montz, D. Mosberger, S. W. O'Malley, L. L. Peterson, and T. A. Proebsting. </author> <title> Scout: A communications-oriented operating system. </title> <booktitle> In Proceedings of the 5th Workshop on Hot Topics in Operating Systems, </booktitle> <pages> pages 58-61. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> May </month> <year> 1995. </year>
Reference-contexts: FFC places few restrictions on the filters it integrates. It handles arbitrary control flow and data manipulations within each each filter. 2 Related Work 2.1 Network Programming FFC is part of the compiler suite of the Scout project <ref> [MMO + 95] </ref>. Scout aims to deliver high-performance systems software|especially communications-oriented operating systems. The Scout compilers do non-traditional optimizations, like Filter Fusion, to increase software performance and to liberate the programmer from tedious, error-prone tasks [OPM94]. Network applications often require many simple manipulations of each network packet.
Reference: [OPM94] <author> Sean O'Malley, Todd A. Proebsting, and A. Brady Montz. </author> <title> USC: A universal stub compiler. </title> <booktitle> In Proceedings of SIGCOMM 94 Conference on Communications Architectures, Protocols and Applications, </booktitle> <pages> pages 295-306, </pages> <month> August </month> <year> 1994. </year>
Reference-contexts: Scout aims to deliver high-performance systems software|especially communications-oriented operating systems. The Scout compilers do non-traditional optimizations, like Filter Fusion, to increase software performance and to liberate the programmer from tedious, error-prone tasks <ref> [OPM94] </ref>. Network applications often require many simple manipulations of each network packet. These manipulations form the protocol stack. Redundant memory access can dominate the processing time for these applications. A technique called Integrated Layer Processing (ILP) optimizes these data ma nipulations [CT90].
Reference: [Wad84] <author> Philip Wadler. </author> <title> Listlessness is better than laziness: Lazy evaluation and garbage collection at compile-time. </title> <booktitle> In Proceedings of theACM Symposium on Lisp and Functional Programming, </booktitle> <pages> pages 45-52, </pages> <month> August </month> <year> 1984. </year>
Reference-contexts: Partially evaluating adjacent filters with respect to a given composition results in a fusion of those filters. Restricting the optimization to composing filters simplifies the partial evaluation considerably. Filter Fusion most strongly resembles Wadler's listless transformer <ref> [Wad84] </ref>. This functional programming optimization composes functions that create and utilize lists into code that avoids building intermediate lists. Like listlessness, Filter Fusion symbolically executes programs to create a graph representations of the residual, composed program that eliminates intermediate steps (list manipulations for listlessness, and reads/writes for Filter Fusion).
Reference: [Wad90] <author> Philip Wadler. </author> <title> Deforestation: Transforming programs to eliminate trees. </title> <journal> Theoretical Computer Science, </journal> <volume> 73 </volume> <pages> 231-248, </pages> <year> 1990. </year>
Reference-contexts: We developed Filter Fusion without knowledge of the listless transformer. Deforestation is related to listlessness and Filter Fusion, because it too eliminates intermediate structures through symbolic execution <ref> [Wad90] </ref>. 3 Filters A linear composition of filters specifies the path data will follow from source to sink: Source ! Filter 1 ! ! Filter N ! Sink In a modular implementation, the source produces all of the data before passing it to the first filter.
References-found: 12

