URL: ftp://pscs.physics.lsa.umich.edu/pub/papers/pscs-96-001.ps.gz
Refering-URL: http://www.cs.bham.ac.uk/~wbl/biblio/gp-bibliography.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: bmulloy@umich.edu, rlriolo@umich.edu, savit@umich.edu  
Phone: (313) 763-3233  
Author: Brian S. Mulloy Rick L. Riolo Robert S. Savit 
Address: Ann Arbor MI USA 48109-1120  
Affiliation: Program for Study of Complex Systems (PSCS) University of Michigan,  
Abstract: An investigation into the dynamics of Genetic Programming applied to chaotic time series prediction is reported. An interesting characteristic of adaptive search techniques is their ability to perform well in many problem domains while failing in others. Because of Genetic Programming's flexible tree structure, any particular problem can be represented in myriad forms. These representations have variegated effects on search performance. Therefore, an aspect of fundamental engineering significance is to find a representation which, when acted upon by Genetic Programming operators, optimizes search performance. We discover, in the case of chaotic time series prediction, that the representation commonly used in this domain does not yield optimal solutions. Instead, we find that the population converges onto one "accurately replicating" tree before other trees can be explored. To correct for this premature convergence we make a simple modification to the crossover operator. In this paper we review previous work with GP time series prediction, pointing out an anomalous result related to overlearning, and report the improvement effected by our modified crossover operator. 
Abstract-found: 1
Intro-found: 1
Reference: [Altenberg, 1994] <author> Altenberg, Lee. </author> <title> The Evolution of Evolvability in Genetic Programming. </title> <editor> In Kinnear, Kim (editor). </editor> <booktitle> Advances in Genetic Programming. </booktitle> <publisher> Cambrige, </publisher> <address> MA: </address> <publisher> The MIT Press. </publisher> <pages> Pages 47-74. </pages>
Reference-contexts: However, the building block hypothesis has not been confirmed <ref> [O'Reilly and Oppacher, 1994, Altenberg, 1994] </ref>. internal node count multiplied by the probability of in-ternal crossover. <p> over twenty runs of both the generation in which the best of run tree was found and the mean squared errors of the training and test sets. 11 The tree is equivalent because division by zero with the protected division operator, %, returns 1. 12 This terminology was used by <ref> [Altenberg, 1994] </ref>. for the FONTX run producing tree T 2. The population does not converge. Table 4: Comparison of average statistics from Normal Crossover (NX) and Modified Crossover (FONTX) for 20 runs each. Method Gen.
Reference: [Casdagli, 1989] <author> Casdagli, Martin. </author> <year> 1989. </year> <title> Nonlinear Prediction of Chaotic Time Series. </title> <journal> Physica D. </journal> <volume> Volume 35. </volume> <pages> Pages 335-356. </pages>
Reference-contexts: Our method of generating the map is described in section 3.1. 2.2 Comparing Performance of Predictors In order to evaluate the performance of different predictors we use the method also used by [Iba, 1995]. This method is due to <ref> [Casdagli, 1989] </ref>.
Reference: [Casdagli, 1992] <author> Casdagli, Martin et al. </author> <year> 1992. </year> <title> Nonlinear Modeling of Chaotic Time Series: Theory and Applications. </title> <editor> In Hyun, Jong and John Stringer (editors). </editor> <booktitle> Applied Chaos. </booktitle> <publisher> John Wiley and Sons, Inc. </publisher> <pages> Pages 335-380. </pages>
Reference: [Farmer and Sidorowich, 1987] <editor> Farmer, Doyne and John J. Sidorowich. </editor> <year> 1987. </year> <title> Predicting Chaotic Time Series. </title> <journal> Physical Review Letters. </journal> <volume> Volume 59, Number 8. </volume> <pages> Pages 845-848. </pages>
Reference-contexts: The equation for the discretized map is bx (t ) c ax (t) ; (1) with a = 0:1, b = 0:2, c = 10:0 and = 17. 3 This is a commonly studied map for time series prediction research <ref> [Farmer and Sidorowich, 1987] </ref>. Our method of generating the map is described in section 3.1. 2.2 Comparing Performance of Predictors In order to evaluate the performance of different predictors we use the method also used by [Iba, 1995]. This method is due to [Casdagli, 1989]. <p> The earliest work with GP time series prediction was that of Koza [Koza, 1992, pp. 507-513] who considered the logistic map. Koza performed short-term prediction, estimating the current value, x (t), with a GP generated 3 With these parameters the attractor dimension was estimated to be 2.1 <ref> [Farmer and Sidorowich, 1987] </ref>. function of the previous map value, ~ f (x (t 1)).
Reference: [Green and Savit, 1991] <author> Green, Matthew L. and Robert Savit. </author> <year> 1991. </year> <title> Dependent variables in broad band continuous time series. </title> <journal> Physica D. </journal> <volume> Volume 50. </volume> <pages> Pages 521-544. </pages>
Reference-contexts: not depend in any way on the 400 point test set. 5 The 17 seed values for this time series are 1:097410, 1:128060, 1:145130, 1:147970, 1:139460, 1:123850, 1:105310, 1:087330, 1:073410, 1:069520, 1:054130; the rest of the time series can be generated from these data. 6 See also the paper of <ref> [Green and Savit, 1991] </ref> in which the question of which variables contain the most information relevant to a specific criterion is discussed. 7 This function set may not be the optimal function set. The sin, cos, and k 10 functions are not necessary to express a robust nonlinear function.
Reference: [Iba et al, 1993] <author> Iba, Hitoshi, Takio Kurita , Hugo de Garis and Taisuke Sato. </author> <year> 1993. </year> <title> System Identification using Structured Genetic Algorithms. </title> <editor> In For-rest, Stephanie. (editor). </editor> <booktitle> Proceedings of the Fifth International Conference on Genetic Algorithms. </booktitle> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher> <pages> Pages 279-286. </pages>
Reference-contexts: This problem proved to be too difficult for the GP methods used. Many of the solutions found were simply constants in time and the other solutions did not even qualitatively resemble the original time series. However, <ref> [Iba et al, 1993] </ref> had introduced "a new GA (Genetic Algorithm)-based approach to the solution of system identification" and applied it to another time series prediction problem. <p> STROGANOFF was applied to the tasks of time series prediction and pattern recognition. The time series considered was also generated with the Mackey-Glass equation. However, the version used by <ref> [Iba et al, 1993] </ref> had a lower attractor dimension than that used by [Oakley, 1994] and the prediction task was short-term 1 Here short-term prediction is taken to mean prediction of only the next value, x (t+1), of a time series.
Reference: [Iba, 1995] <editor> Iba, Hitoshi. </editor> <year> 1995. </year> <title> A Numerical Approach to Genetic Programming for System Identification. </title> <type> Electrotechnical Laboratory technical report ETL-TR-95-23. </type> <institution> Tsukuba Science City, </institution> <address> Japan. </address> <year> 1995. </year> <note> (contact iba@etl.go.jp). </note>
Reference-contexts: Generally short-term prediction is an easier problem than long-term. 2 The methods used by [Oakley, 1994] and the others are described in more detail in section 2.3 of this paper. instead of long-term. Later, <ref> [Iba, 1995] </ref> compared the performance of STROGANOFF to the performance of a traditional GP. He showed that STROGANOFF performed better than traditional GP on the Mackey-Glass time series, and also on the Ikeda map [Ikeda, 1979] and the Lorenz equation [Lorenz, 1963]. <p> We find two causes for GP's reportedly poor performance and present a solution which gives qualitatively better results than those previously reported for traditional GP. First, we show that the over-fitting reported by <ref> [Iba, 1995] </ref> is not a typical result. Rather, Iba's result may have been a pathological anomaly. Second, we show that GP converges prematurely when performing a short-term time series prediction. We present a solution to this problem of convergence and report the resulting increase in GP performance. <p> Our method of generating the map is described in section 3.1. 2.2 Comparing Performance of Predictors In order to evaluate the performance of different predictors we use the method also used by <ref> [Iba, 1995] </ref>. This method is due to [Casdagli, 1989]. <p> N = 10 3 in <ref> [Iba, 1995] </ref> and we use the same number of evaluation points in this study. In the results section we use this measure to compare the performances among different solutions. 2.3 Previous Work The following is a more detailed review of the work of previous authors. <p> The second method presented here may prove to be a better use of the data. The most recent GP study is that of <ref> [Iba, 1995] </ref>, which is primarily a comparison between the STROGANOFF method and traditional GP 4 . STROGANOFF and GP were both applied to the task of short term prediction on several chaotic maps [Iba, 1995]. The methods and results of [Iba, 1995] will be studied in detail in sections 3 and <p> The most recent GP study is that of <ref> [Iba, 1995] </ref>, which is primarily a comparison between the STROGANOFF method and traditional GP 4 . STROGANOFF and GP were both applied to the task of short term prediction on several chaotic maps [Iba, 1995]. The methods and results of [Iba, 1995] will be studied in detail in sections 3 and 4 of this paper. 3 Methods 3.1 Time Series Generation To generate the Mackey-Glass time series with = 17, 17 double precision pseudo-random numbers are generated. <p> The most recent GP study is that of <ref> [Iba, 1995] </ref>, which is primarily a comparison between the STROGANOFF method and traditional GP 4 . STROGANOFF and GP were both applied to the task of short term prediction on several chaotic maps [Iba, 1995]. The methods and results of [Iba, 1995] will be studied in detail in sections 3 and 4 of this paper. 3 Methods 3.1 Time Series Generation To generate the Mackey-Glass time series with = 17, 17 double precision pseudo-random numbers are generated. <p> The automatic discovery of useful terminals is an interesting and perhaps fundamental issue for both time series prediction research and GP dynamics research. As a first step toward understanding this issue we investigate the terminal set used by <ref> [Iba, 1995] </ref>, which employs the ten previous map values and an ephemeral random constant, T = fx (t) ; x (t 1) ; :::; x (t 10) ; Rg : The ephemeral random constant ranges from [1:0; 1:0]. The function set used is due to [Oakley, 1994]. <p> The standardized fitness, s, in this case is the same as the raw fitness, r. The adjusted fitness, a, of each individual is the traditional GP value a = 1:0=(1:0 + s). The parameters we use are exactly those reported in <ref> [Iba, 1995] </ref>: The population size is 5000, the number of generations is 101 (including the first random population). The initial population is generated using the ramped-half-and-half method. The maximum depth of new individuals is 6. The maximum depth of individual after crossover is 17. <p> Instead if two one-node trees are selected for crossover, they are both discarded and new trees are selected from the population. 4 Results This section begins with the investigation of overlearn-ing as reported by <ref> [Iba, 1995] </ref>. Then the results of our two experimental runs are given. Please note that the tree considered in section 4.1 is found in a run whose results are described in section 4.2. This order of presentation was chosen to keep two strands of thought separate. <p> The first strand is that a given GP tree, once found, does not inherently suffer from overlearning of the training data. The second thought relates to premature convergence and depends upon contrasting our two experimental runs. The first set of runs are a replication of the previous work of <ref> [Iba, 1995] </ref> and the results of this run are referred to as "Normal Crossover" (NX). <p> Study Mean Squared Train Error Mean Squared Test Error log 10 ~ f NX 6:69 fi 10 5 6:52 fi 10 5 -1.44 plished (see Section 3.3) and is referred to as "forbid one-node tree crossover" (FONTX). Furthermore, for purposes of comparison the results reported by <ref> [Iba, 1995] </ref> are referred to as "Previously Reported Results" (PRR). 4.1 Overlearning In the results reported by [Iba, 1995] the best tree found was which is equivalent to ~ f (x (t)) = 2x (t 1) x (t 2) : This tree, as will be reported in section 4.2, is found <p> Furthermore, for purposes of comparison the results reported by <ref> [Iba, 1995] </ref> are referred to as "Previously Reported Results" (PRR). 4.1 Overlearning In the results reported by [Iba, 1995] the best tree found was which is equivalent to ~ f (x (t)) = 2x (t 1) x (t 2) : This tree, as will be reported in section 4.2, is found in 13 of 20 runs performed in this study. <p> Table 4.1 shows the mean squared error observed in the training and test sets, as well as the measure in equation 2 calculated over 10 3 evaluation points, for tree T 1. The results as reported by <ref> [Iba, 1995] </ref> (PRR) and as observed in this study (NX) are shown in Table 4.1. As can be seen, the comparative measure values, log 10 are very nearly identical between the two studies. <p> However, there is a large discrepancy between the two studies in how training data relates to test data. In this study we find the difference between training and test data to be essentially negligible. However, the difference reported by <ref> [Iba, 1995] </ref> is more than an order of magnitude. What is the origin of this discrepancy? Although the time series used in each study is generated from the same Mackey-Glass mapping, the actual values in a particular series may differ. <p> A statistical summary of Figure 4.1 is given in Table 4.1. Clearly, a performance decrease of two orders of magnitude between training data and test data is not expected for tree T 1 on this prediction problem. Furthermore, the values reported by <ref> [Iba, 1995] </ref> are out of the range of the maximum and minimum values over the 1000 data points (i.e 6:50 fi 10 6 &lt; 5:7 fi 10 5 and 1:5 fi 10 4 &gt; 7:9 fi 10 5 ). Therefore it seems likely that the results reported by [Iba, 1995] are <p> reported by <ref> [Iba, 1995] </ref> are out of the range of the maximum and minimum values over the 1000 data points (i.e 6:50 fi 10 6 &lt; 5:7 fi 10 5 and 1:5 fi 10 4 &gt; 7:9 fi 10 5 ). Therefore it seems likely that the results reported by [Iba, 1995] are an anomaly. In the remainder of the results section we will not refer to these seemingly anomalous data. However we will consider other results reported by [Iba, 1995]. 4.2 Normal Crossover (NX) Now we consider the problem of premature convergence. <p> Therefore it seems likely that the results reported by <ref> [Iba, 1995] </ref> are an anomaly. In the remainder of the results section we will not refer to these seemingly anomalous data. However we will consider other results reported by [Iba, 1995]. 4.2 Normal Crossover (NX) Now we consider the problem of premature convergence. We perform 20 runs using normal crossover (NX). <p> The tree T 1 is interesting, because in the previous study by <ref> [Iba, 1995] </ref> it was the best tree overall found by traditional GP. The mean squared error of each tree over the training and testing sets is given in Table 4.2. One can see that the difference between training and test performance is negligible for each tree. <p> Method Gen. Best Found Mean Squared Train Error Mean Squared Test Error NX 4:8 1:0 fi 10 4 9:8 fi 10 5 FONTX 31:3 6:0 fi 10 5 5:8 fi 10 5 5 Discussion and Conclusions We now summarize our investigation. First, <ref> [Iba, 1995] </ref> reported that GP had over-learned its training data; while the performance of a particular tree on a set of training data had been acceptable, when the same tree was applied to other data its performance diminished by two orders of magnitude. We reproduced the simulations performed by [Iba, 1995], <p> First, <ref> [Iba, 1995] </ref> reported that GP had over-learned its training data; while the performance of a particular tree on a set of training data had been acceptable, when the same tree was applied to other data its performance diminished by two orders of magnitude. We reproduced the simulations performed by [Iba, 1995], finding the same results except for the phenomenon of overlearning. To verify our results we applied the found solution tree to 10 3 different data sets. We showed that the GP solution did not exhibit the reported overlearning on any of the 10 3 trials.
Reference: [Ikeda, 1979] <author> Ikeda, K. </author> <year> 1979. </year> <title> Multiple-valued Stationary Sate and its Instability of the Transmitted Light by a Ring Cavity System. </title> <journal> Opt. Commun. </journal> <volume> Volume 30. </volume> <pages> Pages 257-261. </pages>
Reference-contexts: Later, [Iba, 1995] compared the performance of STROGANOFF to the performance of a traditional GP. He showed that STROGANOFF performed better than traditional GP on the Mackey-Glass time series, and also on the Ikeda map <ref> [Ikeda, 1979] </ref> and the Lorenz equation [Lorenz, 1963]. In summary, although the above mentioned studies of traditional GP on the logistic equation and of a hybridized GP on the Mackey-Glass equation have shown encouraging results, traditional GP has not performed well on the Mackey-Glass equation.
Reference: [Ivakhnenko, 1971] <author> Ivakhnenko A. G. </author> <year> 1971. </year> <title> Polynomial Thoery of Complex Systems. </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics Volume 1, </journal> <volume> Number 4. </volume> <pages> Pages 364-378. </pages>
Reference-contexts: This new paradigm, called STROGANOFF (STructured Representation On Genetic Algorithms for NOn-linear Function Fitting), was a hybrid of both GP and a "method of heuristic self-organization" due to <ref> [Ivakhnenko, 1971] </ref>. STROGANOFF was applied to the tasks of time series prediction and pattern recognition. The time series considered was also generated with the Mackey-Glass equation.
Reference: [Koza, 1992] <author> Koza, John. </author> <year> 1992. </year> <title> Genetic Programming: On the Programming of Computers by means of Natural Selection. </title> <address> Cambridge, MA: </address> <publisher> The MIT Press. </publisher>
Reference-contexts: 1 Introduction Applications of Genetic Programming (GP) to the task of chaotic time series prediction have had mixed results. The following is a brief review of previous studies. The first study was done by <ref> [Koza, 1992, pp. 507-513] </ref> who applied GP to the task of predicting next values of the logistic equation. The results of this short-term 1 prediction were expectably good. As noted by [Koza, 1992, pp. 508], the logistic equation is one the simplest equations which displays chaotic behavior. <p> The following is a brief review of previous studies. The first study was done by [Koza, 1992, pp. 507-513] who applied GP to the task of predicting next values of the logistic equation. The results of this short-term 1 prediction were expectably good. As noted by <ref> [Koza, 1992, pp. 508] </ref>, the logistic equation is one the simplest equations which displays chaotic behavior. More challenging problems would need to be studied to prove GP as a paradigm capable of performing chaotic time-series prediction. <p> In the results section we use this measure to compare the performances among different solutions. 2.3 Previous Work The following is a more detailed review of the work of previous authors. The earliest work with GP time series prediction was that of Koza <ref> [Koza, 1992, pp. 507-513] </ref> who considered the logistic map. Koza performed short-term prediction, estimating the current value, x (t), with a GP generated 3 With these parameters the attractor dimension was estimated to be 2.1 [Farmer and Sidorowich, 1987]. function of the previous map value, ~ f (x (t 1)). <p> This inability to produce trees which display essentially null behavior (introns) may inhibit the fitness of the GP (see [Nordin and Banzhaf, 1995]). 8 Protected division returns 1:0 if the denominator is 0 and returns the result of division otherwise <ref> [Koza, 1992] </ref>. The test set is used to evaluate performance only after the GP has found its best tree. <p> Across the different groups of 20 runs we use the same 20 initial populations. 3.3 Crossover We use two types of the Crossover operator in the experiments reported in this paper. The first type is just "normal Crossover" (NX), as described in <ref> [Koza, 1992] </ref>. The second type differs from the first only in that we forbid one-node tree crossovers (FONTX). These two crossover operators are described in more detail below. For normal crossover, upon selection of two parent trees a node in each tree is chosen at random. <p> Because there is only one root node in any tree, the probability of selecting the root node is just the inverse of the 9 The justification for this distribution is to promote the "recombining of small substructures or building blocks" <ref> [Koza, 1992] </ref>. However, the building block hypothesis has not been confirmed [O'Reilly and Oppacher, 1994, Altenberg, 1994]. internal node count multiplied by the probability of in-ternal crossover. <p> We pointed out that GP generally lost its best trees the generation after they were found. This could be remedied by enforcing a rule which would keep the best of the population from generation to generation (i.e. an elitist policy <ref> [Koza, 1992] </ref>. From the point of view of time series analysis, one can investigate the use of more sophisticated fitness measures. We have done preliminary runs with a metric due to [Manuca and Savit, 1996].
Reference: [Lorenz, 1963] <author> Lorenz, E. N. </author> <year> 1963. </year> <title> Deterministic Non-Periodic Flow. </title> <journal> J. Atmos. Sci. </journal> <volume> Volume 20. </volume> <pages> Pages 130-141. </pages>
Reference-contexts: Later, [Iba, 1995] compared the performance of STROGANOFF to the performance of a traditional GP. He showed that STROGANOFF performed better than traditional GP on the Mackey-Glass time series, and also on the Ikeda map [Ikeda, 1979] and the Lorenz equation <ref> [Lorenz, 1963] </ref>. In summary, although the above mentioned studies of traditional GP on the logistic equation and of a hybridized GP on the Mackey-Glass equation have shown encouraging results, traditional GP has not performed well on the Mackey-Glass equation.
Reference: [Mackey and Glass, 1977] <author> Mackey, M.C. and Glass L. </author> <year> 1977. </year> <title> Oscillation and Chaos in Physiological Control Systems. </title> <journal> Science. </journal> <volume> Volume 197. </volume> <pages> Pages 287-289. </pages>
Reference-contexts: A more difficult task was attempted by [Oakley, 1994], who studied a more complicated time series and a far more challenging prediction task. The time series studied was produced by the Mackey-Glass equation <ref> [Mackey and Glass, 1977] </ref>. The prediction task considered was a non-standard long term prediction akin to a squared-error regression 2 . This problem proved to be too difficult for the GP methods used. <p> A simple method, and the one considered in this paper, is the sum of squared errors between the actual time series values and the predicted values, S = t x (t + 1) e f (x (t)) : The time series considered in this study is the Mackey-Glass equation <ref> [Mackey and Glass, 1977] </ref> with the parameters given below.
Reference: [Manuca and Savit, 1996] <author> Manuca, Radu and Robert Savit. </author> <year> 1996. </year> <title> Model Misspecification Tests, Model Building and Predictability in Complex Systems. </title> <editor> Physica D. </editor> <publisher> In press. </publisher>
Reference-contexts: From the point of view of time series analysis, one can investigate the use of more sophisticated fitness measures. We have done preliminary runs with a metric due to <ref> [Manuca and Savit, 1996] </ref>. Our results have been encouraging. [Prugel-Bennett and Shapiro, 1994] have studied the effects of increasing selection pressure during the evolution of a GA. We have applied this concept very roughly to GP.
Reference: [McPhee and Miller, 1995] <author> McPhee, Nicholas Freitag and Justin Darwin Miller. </author> <year> 1995. </year> <title> Accurate Replication in Genetic Programming. </title> <editor> In Eshelman, Larry J. (editor). </editor> <booktitle> Proceedings of the Sixth International Conference on Genetic Algorithms. </booktitle> <address> San Francisco, CA: </address> <publisher> Morgan Kaufmann. </publisher> <pages> Pages 303-309. </pages>
Reference-contexts: The first set of runs are a replication of the previous work of [Iba, 1995] and the results of this run are referred to as "Normal Crossover" (NX). The second method differs from the first only in the way crossover is accom 10 <ref> [McPhee and Miller, 1995] </ref> have studied, both experimentally and theoretically, the causes and effects of crossover degenerating into reproduction (called "accurate reproduction"). They point out that accurate reproduction, tree growth, and the discovery of solution trees may be related phenomena. Our results strengthen this hypothesis.
Reference: [Nordin and Banzhaf, 1995] <author> Nordin, Peter and Wolf-gang Banzhaf. </author> <year> 1995. </year> <title> Complexity Compression and Evolution. </title> <editor> In Eshelman, Larry J. (editor). </editor> <booktitle> Proceedings of the Sixth International Conference on Genetic Algorithms. </booktitle> <address> San Francisco, CA: </address> <publisher> Morgan Kauf-mann. </publisher> <pages> Pages 310-317. </pages>
Reference-contexts: This inability to produce trees which display essentially null behavior (introns) may inhibit the fitness of the GP (see <ref> [Nordin and Banzhaf, 1995] </ref>). 8 Protected division returns 1:0 if the denominator is 0 and returns the result of division otherwise [Koza, 1992]. The test set is used to evaluate performance only after the GP has found its best tree.
Reference: [Oakley, 1994] <author> Oakley, Howard. </author> <year> 1994. </year> <title> Two Scientific Applications of Genetic Programming: Stack Filters and Non-Linear Equation Fitting to Chaotic Data. </title> <editor> In Kinnear, Kim (editor). </editor> <booktitle> Advances in Genetic Programming. </booktitle> <publisher> Cambrige, </publisher> <address> MA: </address> <publisher> The MIT Press. </publisher> <pages> Pages 369-389. </pages>
Reference-contexts: As noted by [Koza, 1992, pp. 508], the logistic equation is one the simplest equations which displays chaotic behavior. More challenging problems would need to be studied to prove GP as a paradigm capable of performing chaotic time-series prediction. A more difficult task was attempted by <ref> [Oakley, 1994] </ref>, who studied a more complicated time series and a far more challenging prediction task. The time series studied was produced by the Mackey-Glass equation [Mackey and Glass, 1977]. The prediction task considered was a non-standard long term prediction akin to a squared-error regression 2 . <p> STROGANOFF was applied to the tasks of time series prediction and pattern recognition. The time series considered was also generated with the Mackey-Glass equation. However, the version used by [Iba et al, 1993] had a lower attractor dimension than that used by <ref> [Oakley, 1994] </ref> and the prediction task was short-term 1 Here short-term prediction is taken to mean prediction of only the next value, x (t+1), of a time series. <p> Whereas long-term prediction is taken to mean prediction of t = 2 or more steps into the future, x (t + t ). Generally short-term prediction is an easier problem than long-term. 2 The methods used by <ref> [Oakley, 1994] </ref> and the others are described in more detail in section 2.3 of this paper. instead of long-term. Later, [Iba, 1995] compared the performance of STROGANOFF to the performance of a traditional GP. <p> Another study was that of <ref> [Oakley, 1994] </ref>, who considered the discretized version of the delay differential equation due to Mackey and Glass discussed in the previous section. <p> The function set used is due to <ref> [Oakley, 1994] </ref>. The only requirement of the function set is its ability to produce nonlinear expressions. The function set 7 is F = +; ; fl; %; sin; cos; k 10 where % represents protected division 8 and k 10 represents the raising of a number to the tenth power.
Reference: [O'Reilly and Oppacher, 1994] <author> O'Reilly, Una-May and Franz Oppacher. </author> <year> 1994. </year> <title> The Troubling Aspects of a Building Block Hypothesis for Genetic Programming. </title> <institution> Santa Fe Institute Working Paper 94-02-001. </institution> <year> 1994. </year>
Reference-contexts: However, the building block hypothesis has not been confirmed <ref> [O'Reilly and Oppacher, 1994, Altenberg, 1994] </ref>. internal node count multiplied by the probability of in-ternal crossover.
Reference: [Prugel-Bennett and Shapiro, 1994] <author> Prugel-Bennett A. and J.L. Shapiro. </author> <year> 1994. </year> <title> Analysis of Genetic Algorithms using Statistical Mechanics. </title> <journal> Physical Review Letters. </journal> <volume> Volume 72, Number 9. </volume> <pages> Pages 1305-1309. </pages>
Reference-contexts: From the point of view of time series analysis, one can investigate the use of more sophisticated fitness measures. We have done preliminary runs with a metric due to [Manuca and Savit, 1996]. Our results have been encouraging. <ref> [Prugel-Bennett and Shapiro, 1994] </ref> have studied the effects of increasing selection pressure during the evolution of a GA. We have applied this concept very roughly to GP. Surprisingly, in the time series prediction task considered in this paper we found better results than any presented here.
References-found: 18

