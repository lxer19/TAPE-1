URL: http://www.cs.bu.edu/techreports/94-016-phys-based-comb-of-views.ps.Z
Refering-URL: http://cs-www.bu.edu/techreports/Home.html
Root-URL: 
Title: Physically-Based Combinations of Views: Representing Rigid and Nonrigid Motion  
Author: Stan Sclaroff Alex P. Pentland 
Date: Nov. 1994.  
Note: Appeared in Proc. of the IEEE Workshop on Nonrigid and Articulate Motion,  
Address: TR94-016  Austin, TX,  111 Cummington St., Boston MA 02215 20 Ames St., Cambridge MA 02139  
Affiliation: Boston University Computer Science Dept.  Computer Science Dept. Perceptual Computing Section Boston University The MIT Media Laboratory  
Abstract: Nonrigid motion can be described as morphing or blending between extremal shapes, e.g., heart motion can be described as transitioning between the systole and diastole states. Using physically-based modeling techniques, shape similarity can be measured in terms of forces and strain. This provides a physically-based coordinate system in which motion is characterized in terms of physical similarity to a set of extremal shapes. Having such a low-dimensional characterization of nonrigid motion allows for the recognition and the comparison of different types of nonrigid motion. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> K. Bathe. </author> <title> Finite Element Procedures in Engineering Analysis. </title> <publisher> Prentice-Hall, </publisher> <year> 1982. </year>
Reference-contexts: the dynamic equilibrium equation: M U + D _ U + KU = R; (2) where R is the load vector whose entries are the spring forces between each feature point and the body surface, and where M, D, and K are the element mass, damping, and stiffness matrices, respectively <ref> [1; 12] </ref>. 2.2 Modal Representation The FEM governing equations can be decoupled by posing the equations in a basis defined by the M-orthogonalized eigenvectors of K. <p> The i form columns in the transform and ! 2 i are elements of the diagonal matrix 2 . We will assume Rayleigh damping (i.e., D = a 0 M + a 1 K), thus the damping matrix will also diagonalized by this transform <ref> [1] </ref>. This generalized coordinate transform is then used to transform between nodal point displacements U and decou-pled modal displacements ~ U, U = ~ U.
Reference: [2] <author> A. Baumberg and D. Hogg. </author> <title> Learning flexible models from image sequences. </title> <booktitle> In Proc. </booktitle> <address> ECCV, </address> <month> May </month> <year> 1994. </year>
Reference: [3] <author> A. Blake, R. Curwen, and A. Zisserman. </author> <title> A framework for spatiotemporal control in the tracking of visual contours. </title> <journal> IJCV, </journal> <volume> 11(2) </volume> <pages> 127-146, </pages> <year> 1993. </year>
Reference-contexts: This led to the development of algorithms which include a priori constraints on the types of allowable deformations for motion tracking <ref> [3; 4; 5; 8] </ref>. Cootes et al.[6; 2] use trainable snakes for capturing the invariant properties of a class of shapes, by finding the principle variations of a snake via the Karhunen-Loeve transform.
Reference: [4] <author> F. Bookstein. </author> <title> Principal warps: Thin-plate splines and the decomposition of deformations. </title> <journal> IEEE PAMI, </journal> <volume> 11(6) </volume> <pages> 567-585, </pages> <month> June </month> <year> 1989. </year>
Reference-contexts: This led to the development of algorithms which include a priori constraints on the types of allowable deformations for motion tracking <ref> [3; 4; 5; 8] </ref>. Cootes et al.[6; 2] use trainable snakes for capturing the invariant properties of a class of shapes, by finding the principle variations of a snake via the Karhunen-Loeve transform.
Reference: [5] <author> I. Cohen, N. Ayache, and P. Sulger. </author> <title> Tracking points on de-formable objects. </title> <booktitle> In Proc. </booktitle> <address> ECCV, </address> <month> May </month> <year> 1992. </year>
Reference-contexts: This led to the development of algorithms which include a priori constraints on the types of allowable deformations for motion tracking <ref> [3; 4; 5; 8] </ref>. Cootes et al.[6; 2] use trainable snakes for capturing the invariant properties of a class of shapes, by finding the principle variations of a snake via the Karhunen-Loeve transform.
Reference: [6] <author> T. Cootes, D. Cooper, C. Taylor, and J. Graham. </author> <title> Trainable method of parametric shape description. </title> <journal> Image and Vision Computing, </journal> <volume> 10(5) </volume> <pages> 289-294, </pages> <month> June </month> <year> 1992. </year>
Reference: [7] <author> T. Darrell and A. Pentland. </author> <title> Space-time gestures. </title> <booktitle> In Proc. </booktitle> <address> CVPR, </address> <month> June </month> <year> 1993. </year>
Reference-contexts: First, we are interested not only in recognizing shapes, but also in describing motion (including nonrigid and articulated motion). We want to derive a low-dimensional parametric representation of motion that can be used to recognize and compare motion trajectories, in the manner of Darrell and Pentland <ref> [7] </ref>. Second, we cannot be restricted to a linear framework. Nonrigid motions are inherently nonlinear, although they are often physically smooth.
Reference: [8] <author> J. Duncan, R. Owen, L. Staib, and P. Anandan. </author> <title> Measurement of non-rigid motion using contour shape descriptors. </title> <booktitle> In Proc. </booktitle> <address> CVPR, </address> <month> June </month> <year> 1991. </year>
Reference-contexts: This led to the development of algorithms which include a priori constraints on the types of allowable deformations for motion tracking <ref> [3; 4; 5; 8] </ref>. Cootes et al.[6; 2] use trainable snakes for capturing the invariant properties of a class of shapes, by finding the principle variations of a snake via the Karhunen-Loeve transform.
Reference: [9] <author> B. Horn. </author> <title> Closed-form solution of absolute orientation using unit quarternions. </title> <journal> JOSA-A, </journal> <volume> 4 </volume> <pages> 629-642, </pages> <year> 1987. </year>
Reference-contexts: All vector fields are linear and can therefore be precomputed. When aligning the images requires a large rotation, then this linearization of the rotational field becomes invalid. In such cases, we must include an additional alignment step which is accomplished in closed form via Horn's quaternion-based method <ref> [9] </ref>. In the modified technique, we first align the two point sets using the rotation, translation, and scale recovered using the Horn method. The points can now be further aligned by recov ering the modal deformations ~ U as described previously.
Reference: [10] <author> I. Kakadiaris, D. Metaxas, R. </author> <title> Bajcsy. Active part-decomposition, shape and motion estimation of articulated objects: a physics-based approach. </title> <booktitle> In Proc. </booktitle> <address> CVPR, </address> <month> June </month> <year> 1994. </year>
Reference-contexts: In a future version of the system, the modal model will include articulated shapes and anisotropic materials. In addition, our system can perform physics-based active part detection along the lines of <ref> [10] </ref>. 6 5 Summary We can obtain a parametric description of rigid, nonrigid, or articulated motion in terms of its similarity to known extremal views, thus providing us with a low-dimensional parameterization of the motion.
Reference: [11] <author> M. Kass, A. Witkin, and D. Terzopoulos. Snakes: </author> <title> Active contour models. </title> <journal> IJCV, </journal> <volume> 1 </volume> <pages> 321-331, </pages> <year> 1987. </year>
Reference-contexts: For instance, most biological objects are flexible and articulated. To describe these deformations, therefore, it is reasonable to model the physics by 1 which real objects deform. This rationale led to the physi-cal modeling paradigm of active contours or snakes <ref> [11] </ref>. A snake has a predefined structure which incorporates knowledge about the shape and its resistance to deformation. By allowing the user to specify forces that are a function of sensor measurements, the intrinsic dynamic behavior of a physical model can be used to solve fitting, interpolation, or correspondence problems.
Reference: [12] <author> A. Pentland and S. Sclaroff. </author> <title> Closed-form solutions for physically-based shape modeling and recognition. </title> <journal> IEEE PAMI, </journal> <volume> 13(7) </volume> <pages> 715-729, </pages> <month> July </month> <year> 1991. </year>
Reference-contexts: the dynamic equilibrium equation: M U + D _ U + KU = R; (2) where R is the load vector whose entries are the spring forces between each feature point and the body surface, and where M, D, and K are the element mass, damping, and stiffness matrices, respectively <ref> [1; 12] </ref>. 2.2 Modal Representation The FEM governing equations can be decoupled by posing the equations in a basis defined by the M-orthogonalized eigenvectors of K. <p> We can now rewrite Eq. 2 in terms of these generalized or modal displacements, obtaining a decoupled system of equations: ~ U + ~ D allowing for closed-form solution to the equilibrium problem <ref> [12] </ref>. Given this equilibrium solution in the two images, point correspondences can be obtained directly. By discarding high frequency modes the amount of computation required can be minimized without significantly altering correspondence accuracy. <p> Moreover, such a set of modal amplitudes provides a robust, canonical description of shape in terms of deformations applied to the original elastic body. This allows them to be used directly for object recognition <ref> [12] </ref>. 2.3 Modal Matching Perhaps the major limitation of previous methods is the requirement that every object be described as the deformations of a single prototype object. This implicitly imposes an a priori parameterization upon the sensor data, and therefore implicitly determines the correspondences between data and prototype.
Reference: [13] <author> T. Poggio and F. Girosi. </author> <title> A theory of networks for approximation and learning. Memo No. </title> <type> 1140, </type> <institution> MIT AI Lab, </institution> <address> Cambridge, MA, </address> <month> July </month> <year> 1989. </year>
Reference-contexts: By measuring the amount of deformation between the new image and extremal views, we locate the new image in the coordinate system defined by the polytope. This approach to describing motion is related to the view-based shape recognition proposals of Ullman and Basri [19] and Poggio, et al. <ref> [13] </ref>. It entails description by interpolating among examples, rather than description by some more abstract, view-independent representation. However, it differs from their proposals in two important ways. First, we are interested not only in recognizing shapes, but also in describing motion (including nonrigid and articulated motion). <p> The result is a low-dimensional parametric representation of the object's motion that is qualitatively related to the underlying physical parameters. This approach to describing motion is related to the view-based shape recognition proposals of Ullman, et al. [19] and Poggio, et al. <ref> [13] </ref>. It is description by interpolating among examples, rather than description by some more abstract, view-independent representation.
Reference: [14] <author> S. Sclaroff and A. Pentland. </author> <title> A modal framework for correspondence and recognition. </title> <booktitle> In Proc. </booktitle> <address> ICCV, </address> <month> May </month> <year> 1993. </year>
Reference-contexts: This initial work was applied in the area of finding corresponding features in static imagery <ref> [14] </ref> and serves as the foundation for our new representation for nonrigid motion. 2.1 Finite Element Method The major advantage of the finite element method is that it uses the Galerkin method of surface interpolation. <p> For each image we start with feature point locations, which are used as nodes in building a finite element model of the shape. A Gaussian is centered at each node, and these Gaussians are used as Galerkin interpolants in constructing the mass and stiffness matrices <ref> [14] </ref>. The use of Galerkin interpolants reduces the effects of missing or dislocated features. We then compute the modes of free vibration of this model using Eq. 3. The modes of an object form an orthogonal object-centered coordinate system for describing feature locations. <p> The points that have the most similar and unambiguous coordinates are then matched, with the remaining correspondences determined by using the physical model as a smoothness constraint <ref> [14] </ref>. Currently, the algorithm has the limitation that it cannot reliably match largely occluded or partial objects. Finally, given correspondences between many of the feature points on two objects, we can measure their difference in shape.
Reference: [15] <author> S. Sclaroff and A. Pentland. </author> <title> Modal Matching for Correspondence and Recognition. Vision and Modeling TR-201, </title> <publisher> MIT Media Lab, </publisher> <month> May </month> <year> 1993. </year> <note> To appear in IEEE PAMI. </note>
Reference-contexts: This separation of rigid and nonrigid flow also allows us to examine rigid and nonrigid motions separately. For more details see <ref> [15] </ref>. (b) (a). The first six nonrigid modes for the heart image are shown in (b). 4 Examples Fig. 4 (a) shows an X-ray image of a heart ventricle together with its bounding contour.
Reference: [16] <author> G. Scott and H. Longuet-Higgins. </author> <title> An algorithm for associating the features of two images. </title> <journal> In Proc. Royal Society of London B, </journal> <volume> 244 </volume> <pages> 21-26, </pages> <year> 1991. </year>
Reference: [17] <author> L. Shapiro and J. Brady. </author> <title> Feature-based correspondence: an eigenvector approach. </title> <journal> Image and Vision Computing, </journal> <volume> 10(5) </volume> <pages> 283-288, </pages> <month> June </month> <year> 1992. </year>
Reference: [18] <author> E. Shavit and A. Jepson. </author> <title> Motion understanding using phase portraits. </title> <booktitle> In Proc. IJCAI Looking at People Workshop, </booktitle> <month> August </month> <year> 1993. </year>
Reference-contexts: As can be seen, the beating of the heart forms a nice phase portrait in this physically-based similarity shape space. Such phase portraits can be used to analyze and recognize motion using methods described by Shavit and Jepson <ref> [18] </ref>. The general methods can also be extended to model articulated motions, although for large, complex articulated motions the correspondence problem becomes too hard to solve by the method described above. Fig. 6 (a) shows two extremal views of a moving, articulating hand.
Reference: [19] <author> S. Ullman and R. Basri. </author> <title> Recognition by linear combinations of models. </title> <journal> IEEE PAMI, </journal> <volume> 13(10) </volume> <pages> 992-1006, </pages> <year> 1991. </year>
Reference-contexts: By measuring the amount of deformation between the new image and extremal views, we locate the new image in the coordinate system defined by the polytope. This approach to describing motion is related to the view-based shape recognition proposals of Ullman and Basri <ref> [19] </ref> and Poggio, et al. [13]. It entails description by interpolating among examples, rather than description by some more abstract, view-independent representation. However, it differs from their proposals in two important ways. <p> The result is a low-dimensional parametric representation of the object's motion that is qualitatively related to the underlying physical parameters. This approach to describing motion is related to the view-based shape recognition proposals of Ullman, et al. <ref> [19] </ref> and Poggio, et al. [13]. It is description by interpolating among examples, rather than description by some more abstract, view-independent representation.
Reference: [20] <author> G. Wolberg. </author> <title> Digital Image Warping. </title> <publisher> IEEE Computer Society Press, </publisher> <year> 1990. </year> <month> 7 </month>
Reference-contexts: If the artist selects control point correspondences that produce a geometrically smooth deformation field and a smooth transition in grey level, then a visually compelling transition from the first image to the second is obtained <ref> [20] </ref>. This suggests an important way to obtain a parametric description of rigid, nonrigid, or articulated motion: interpolate between known views.
References-found: 20

