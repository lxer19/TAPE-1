URL: http://www.cs.umn.edu/Users/dept/users/kumar/lb-SIMD.ps
Refering-URL: http://www.cs.umn.edu/Users/dept/users/kumar/
Root-URL: http://www.cs.umn.edu
Email: karypis@cs.umn.edu kumar@cs.umn.edu  
Title: Unstructured Tree Search on SIMD Parallel Computers  
Author: George Karypis and Vipin Kumar 
Note: This work was supported by Army Research Office grant #28408-MA-SDI to the University of Minnesota and by the Army High Performance  
Date: TR 92-21, April 1992  
Address: Minneapolis, MN 55455  
Affiliation: Department of Computer Science, University of Minnesota  Computing Research Center at the University of Minnesota.  
Abstract: In this paper, we present new methods for load balancing of unstructured tree computations on large-scale SIMD machines, and analyze the scalability of these and other existing schemes. An efficient formulation of tree search on a SIMD machine comprises of two major components: (i) a triggering mechanism, which determines when the search space redistribution must occur to balance search space over processors; and (ii) a scheme to redistribute the search space. We have devised a new redistribution mechanism and a new triggering mechanism. Either of these can be used in conjunction with triggering and redistribution mechanisms developed by other researchers. We analyze the scalability of these mechanisms, and verify the results experimentally. The analysis and experiments show that our new load balancing methods are highly scalable on SIMD architectures. Their scalability is shown to be no worse than that of the best load balancing schemes on MIMD architectures. We verify our theoretical results by implementing the 15-puzzle problem on a CM-2 1 SIMD parallel computer. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. Arvindam, Vipin Kumar, and V. Nageshwara Rao. </author> <title> Efficient Parallel Algorithms for Search Problems: Applications in VLSI CAD. </title> <booktitle> In Proceedings of the Frontiers 90 Conference on Massively Parallel Computation, </booktitle> <month> October </month> <year> 1990. </year>
Reference-contexts: We call this splitting mechanism the alpha-splitting mechanism. As demonstrated by experiments on MIMD machines <ref> [25, 1, 8, 17, 23] </ref> it is possible to find alpha-splitting mechanisms for most tree search problems. The total number of nodes expanded in parallel search can often be higher or lower than the number of nodes expanded by serial search [33, 30, 23] leading to speedup anomalies.
Reference: [2] <author> S. Arvindam, Vipin Kumar, V. Nageshwara Rao, and Vineet Singh. </author> <title> Automatic test Pattern Generation on Multiprocessors. </title> <journal> Parallel Computing, </journal> <volume> 17, number 12 </volume> <pages> 1323-1342, </pages> <month> December </month> <year> 1991. </year>
Reference: [3] <author> Guy E. Blelloch. </author> <title> Scans as Primitive Parallel Operations. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 11 </volume> <pages> 1526-1538, </pages> <year> 1989. </year>
Reference-contexts: During the setup step we match idle processors to busy processors by using sum-scans <ref> [3] </ref>. In the case of GP we also perform some bookkeeping calculations, involving sum-scans, in order to maintain the global pointer. The complexity of the sum-scan 10 is O (log P ) for a hypercube and O ( p P ) for a mesh.
Reference: [4] <author> Chris Ferguson and Richard Korf. </author> <title> Distributed Tree Search and its Application to Alpha-Beta Pruning. </title> <booktitle> In Proceedings of the 1988 National Conference on Artificial Intelligence, </booktitle> <month> August </month> <year> 1988. </year>
Reference: [5] <author> Raphael A. Finkel and Udi Manber. </author> <title> DIB A Distributed implementation of Backtracking. </title> <journal> ACM Trans. of Progr. Lang. and Systems, </journal> <volume> 9 No. 2 </volume> <pages> 235-256, </pages> <month> April </month> <year> 1987. </year>
Reference-contexts: We can compute the upper bound for T lb by using a technique that was originally developed in the context of Parallel Depth First Search on MIMD computers <ref> [5, 20] </ref>. In dynamic load balancing, the communication overheads are caused by work transfers. The total number of work transfers defines an upper bound on the total communication overhead.
Reference: [6] <author> Roger Frye and Jacek Myczkowski. </author> <title> Exhaustive Search of Unstructured Trees on the Connection Machine. </title> <institution> In Thinking Machines Corporation Technical Report, </institution> <year> 1990. </year>
Reference-contexts: Recent research has shown that data parallel SIMD architectures can also be used to implement parallel tree search algorithms effectively. Frye and Myczkowski <ref> [6] </ref> presents an implementation of a depth-first tree (DFS) search algorithm on the CM-2 for a block puzzle. Powley, Korf and Ferguson [30] and Mahanti and Daniels [23] present parallel formulations of a tree search algorithm IDA*, for solving the 15 puzzle problem on CM-2.
Reference: [7] <author> M. Furuichi, K. Taki, and N. Ichiyoshi. </author> <title> A Multi-Level Load Balancing Scheme for OR-Parallel Exhaustive Search Programs on the Multi-PSI. </title> <booktitle> In Proceedings of the 2nd ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, </booktitle> <year> 1990. </year> <month> pp.50-59. </month>
Reference: [8] <author> Ananth Grama, Vipin Kumar, and V. Nageshwara Rao. </author> <title> Experimental Evaluation of Load Balancing Techniques for the Hypercube. </title> <booktitle> In Proceedings of the Parallel Computing 91 Conference, </booktitle> <year> 1991. </year>
Reference-contexts: The isoeffi-ciency metric has been found to be quite useful in characterizing scalability of a number 2 of algorithms [9, 21, 32, 38, 41, 42]. In particular, it has helped determine optimal load balancing schemes for tree search for a variety of MIMD architectures <ref> [20, 8, 17] </ref>. In this paper, we present new methods for load balancing of unstructured tree computations on large-scale SIMD machines, and analyze the scalability of these and pre-existing schemes. <p> We call this splitting mechanism the alpha-splitting mechanism. As demonstrated by experiments on MIMD machines <ref> [25, 1, 8, 17, 23] </ref> it is possible to find alpha-splitting mechanisms for most tree search problems. The total number of nodes expanded in parallel search can often be higher or lower than the number of nodes expanded by serial search [33, 30, 23] leading to speedup anomalies.
Reference: [9] <author> Anshul Gupta and Vipin Kumar. </author> <title> On the scalability of FFT on Parallel Computers. </title> <booktitle> In Proceedings of the Frontiers 90 Conference on Massively Parallel Computation, </booktitle> <month> October </month> <year> 1990. </year> <note> An extended version of the paper is available as a technical report from the Department of Computer Science, and as TR 90-20 from Army High Performance Computing Research Center, </note> <institution> University of Minnesota, </institution> <address> Minneapolis, MN 55455. </address>
Reference-contexts: Scalability analysis of a parallel algorithm and architecture combination is very useful in extrapolating these conclusions [10, 11, 18, 20]. The isoeffi-ciency metric has been found to be quite useful in characterizing scalability of a number 2 of algorithms <ref> [9, 21, 32, 38, 41, 42] </ref>. In particular, it has helped determine optimal load balancing schemes for tree search for a variety of MIMD architectures [20, 8, 17].
Reference: [10] <author> John L. Gustafson. </author> <title> Reevaluating Amdahl's Law. </title> <journal> Communications of the ACM, </journal> <volume> 31(5) </volume> <pages> 532-533, </pages> <year> 1988. </year>
Reference-contexts: Hence any conclusions drawn on a set of experimental results may become invalid by changes in any one of the above parameters. Scalability analysis of a parallel algorithm and architecture combination is very useful in extrapolating these conclusions <ref> [10, 11, 18, 20] </ref>. The isoeffi-ciency metric has been found to be quite useful in characterizing scalability of a number 2 of algorithms [9, 21, 32, 38, 41, 42].
Reference: [11] <author> John L. Gustafson, Gary R. Montry, and Robert E. Benner. </author> <title> Development of Parallel Methods for a 1024-Processor Hypercube. </title> <journal> SIAM Journal on Scientific and Statistical Computing, </journal> <volume> 9 No. 4 </volume> <pages> 609-638, </pages> <year> 1988. </year>
Reference-contexts: Hence any conclusions drawn on a set of experimental results may become invalid by changes in any one of the above parameters. Scalability analysis of a parallel algorithm and architecture combination is very useful in extrapolating these conclusions <ref> [10, 11, 18, 20] </ref>. The isoeffi-ciency metric has been found to be quite useful in characterizing scalability of a number 2 of algorithms [9, 21, 32, 38, 41, 42].
Reference: [12] <author> W. Daniel Hillis. </author> <title> The Connection Machine. </title> <publisher> MIT Press, </publisher> <year> 1991. </year>
Reference-contexts: After each load balancing phase, at least one node expansion cycle is completed before the triggering condition is tested again. A very simple and intuitive scheme [30, 34] is to trigger a load balancing phase when the 2 This is done using the rendezvous allocation scheme described in <ref> [12] </ref>. 4 p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p
Reference: [13] <author> Ellis Horowitz and Sartaj Sahni. </author> <title> Fundamentals of Computer Algorithms. </title> <publisher> Computer Science Press, </publisher> <address> Rockville, Maryland, </address> <year> 1978. </year>
Reference-contexts: 1 Introduction Tree search is central to solving a variety of problems in artificial intelligence [14, 29], combinatorial optimization <ref> [13, 22] </ref>, operations research [27] and Monte-Carlo evaluations of functional integrals [35]. The trees that need to be searched for most practical problems happen to be quite large, and for many tree search algorithms, different parts can be searched relatively independently. <p> Often strong heuristics are available to prune the tree at various nodes. The tree can be generated using different methods. Depth-first method is used in many important tree search algorithms such as Depth-First Branch and Bound [16], IDA fl [15], Backtracking <ref> [13] </ref>. In this paper we only consider parallel depth-first-search on SIMD machines. A common method used for parallel depth-first-search of dynamically generated trees on a SIMD machine [30, 23, 34] is as follows.
Reference: [14] <editor> Laveen Kanal and Vipin Kumar. </editor> <booktitle> Search in Artificial Intelligence. </booktitle> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1988. </year>
Reference-contexts: 1 Introduction Tree search is central to solving a variety of problems in artificial intelligence <ref> [14, 29] </ref>, combinatorial optimization [13, 22], operations research [27] and Monte-Carlo evaluations of functional integrals [35]. The trees that need to be searched for most practical problems happen to be quite large, and for many tree search algorithms, different parts can be searched relatively independently.
Reference: [15] <author> Richard E. Korf. </author> <title> Depth-First Iterative-Deepening: An Optimal Admissible Tree Search. </title> <journal> Artificial Intelligence, </journal> <volume> 27 </volume> <pages> 97-109, </pages> <year> 1985. </year> <month> 31 </month>
Reference-contexts: Often strong heuristics are available to prune the tree at various nodes. The tree can be generated using different methods. Depth-first method is used in many important tree search algorithms such as Depth-First Branch and Bound [16], IDA fl <ref> [15] </ref>, Backtracking [13]. In this paper we only consider parallel depth-first-search on SIMD machines. A common method used for parallel depth-first-search of dynamically generated trees on a SIMD machine [30, 23, 34] is as follows. <p> In general, when fi &gt; 0, the value of the optimal static trigger will be smaller than the one given by equation (18) 5 . 5 Static Triggering: Experimental Results We solved various instances of the 15-puzzle problem [26] taken from <ref> [15] </ref>, on a CM-2 massively parallel SIMD computer. 15-puzzle is a 4 fi 4 square tray containing 15 square tiles. The remaining sixteenth square is uncovered. Each tile has a number on it. A tile that is adjacent to the blank space can be slid into that space. <p> IDA fl is the best known sequential depth-first-search algorithm to find optimal solution paths for the 15-puzzle problem <ref> [15] </ref>, and generates highly irregular search trees. We have parallelized IDA fl to test the effectiveness of the various load balancing algorithms. The same algorithm was also used in [30, 23]. Our parallel implementations of IDA fl find all the solutions of the puzzle up to a given tree depth.
Reference: [16] <author> Vipin Kumar. </author> <title> DEPTH-FIRST SEARCH. </title> <editor> In Stuart C. Shapiro, editor, </editor> <booktitle> Encyclopaedia of Artificial Intelligence: </booktitle> <volume> Vol 2, </volume> <pages> pages 1004-1005. </pages> <publisher> John Wiley and Sons, Inc., </publisher> <address> New York, </address> <year> 1987. </year> <note> Revised version appears in the second edition of the encyclopedia to be published in 1992. </note>
Reference-contexts: Often strong heuristics are available to prune the tree at various nodes. The tree can be generated using different methods. Depth-first method is used in many important tree search algorithms such as Depth-First Branch and Bound <ref> [16] </ref>, IDA fl [15], Backtracking [13]. In this paper we only consider parallel depth-first-search on SIMD machines. A common method used for parallel depth-first-search of dynamically generated trees on a SIMD machine [30, 23, 34] is as follows.
Reference: [17] <author> Vipin Kumar, Ananth Grama, and V. Nageshwara Rao. </author> <title> Scalable Load Balancing Techniques for Parallel Computers. </title> <type> Technical report, Tech Report 91-55, </type> <institution> Computer Science Department, University of Minnesota, </institution> <year> 1991. </year>
Reference-contexts: The isoeffi-ciency metric has been found to be quite useful in characterizing scalability of a number 2 of algorithms [9, 21, 32, 38, 41, 42]. In particular, it has helped determine optimal load balancing schemes for tree search for a variety of MIMD architectures <ref> [20, 8, 17] </ref>. In this paper, we present new methods for load balancing of unstructured tree computations on large-scale SIMD machines, and analyze the scalability of these and pre-existing schemes. <p> We call this splitting mechanism the alpha-splitting mechanism. As demonstrated by experiments on MIMD machines <ref> [25, 1, 8, 17, 23] </ref> it is possible to find alpha-splitting mechanisms for most tree search problems. The total number of nodes expanded in parallel search can often be higher or lower than the number of nodes expanded by serial search [33, 30, 23] leading to speedup anomalies. <p> In the rest of the analysis, we will use this upper bound as an estimate of the total number of load balancing phases (our experimental results here as well as for MIMD <ref> [17] </ref> demonstrate that it is a good approximation).
Reference: [18] <author> Vipin Kumar and Anshul Gupta. </author> <title> Analyzing Scalability of Parallel Algorithms and Architectures. </title> <type> Technical report, </type> <institution> TR-91-18, Computer Science Department, University of Minnesota, </institution> <month> June </month> <year> 1991. </year> <note> A short version of the paper appears in the Proceedings of the 1991 International Conference on Supercomputing, Germany, and as an invited paper in the Proc. of 29th Annual Allerton Conference on Communuication, Control and Computing, Urbana,IL, </note> <month> October </month> <year> 1991. </year>
Reference-contexts: The reason is that the performance of different schemes may be impacted quite differently by changes in hardware characteristics (such as interconnection network, CPU speed, speed of communication channels etc.), number of processors, and the size of the problem instance being solved <ref> [18] </ref>. Hence any conclusions drawn on a set of experimental results may become invalid by changes in any one of the above parameters. Scalability analysis of a parallel algorithm and architecture combination is very useful in extrapolating these conclusions [10, 11, 18, 20]. <p> Hence any conclusions drawn on a set of experimental results may become invalid by changes in any one of the above parameters. Scalability analysis of a parallel algorithm and architecture combination is very useful in extrapolating these conclusions <ref> [10, 11, 18, 20] </ref>. The isoeffi-ciency metric has been found to be quite useful in characterizing scalability of a number 2 of algorithms [9, 21, 32, 38, 41, 42]. <p> Algorithms with isoefficiencies of O (P log c small constant c, are also reasonably optimal for practical purposes. For a more rigorous discussion on the isoefficiency metric and scalability analysis, the reader is referred to <ref> [20, 18] </ref>. 3.3 Cost of each load balancing phase In both nGP and GP matching schemes, each load balancing phase requires a setup step and a work transfer step. During the setup step we match idle processors to busy processors by using sum-scans [3].
Reference: [19] <editor> Vipin Kumar, Dana Nau, and Laveen Kanal. </editor> <title> General Branch-and-bound Formulation for AND/OR Graph and Game Tree Search. </title> <editor> In Laveen Kanal and Vipin Kumar, editors, </editor> <booktitle> Search in Artificial Intelligence. </booktitle> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1988. </year>
Reference-contexts: In this scheme after each node expansion cycle the processors that have work check to see if their neighbors are idle. If this is the case then they transfer work to them. This scheme is similar to the nearest neighbor load balancing schemes for MIMD machines. As shown in <ref> [19] </ref> the isoefficiency for a hypercube is (P log 2 1+ 1 ff 2 ), while the isoefficiency for a mesh is (c p P ) where c &gt; 1.
Reference: [20] <author> Vipin Kumar and V. Nageshwara Rao. </author> <title> Parallel Depth-First Search, Part II: Analysis. </title> <journal> International Journal of Parallel Programming, </journal> <volume> 16 </volume> (6):501-519, 1987. 
Reference-contexts: Hence any conclusions drawn on a set of experimental results may become invalid by changes in any one of the above parameters. Scalability analysis of a parallel algorithm and architecture combination is very useful in extrapolating these conclusions <ref> [10, 11, 18, 20] </ref>. The isoeffi-ciency metric has been found to be quite useful in characterizing scalability of a number 2 of algorithms [9, 21, 32, 38, 41, 42]. <p> The isoeffi-ciency metric has been found to be quite useful in characterizing scalability of a number 2 of algorithms [9, 21, 32, 38, 41, 42]. In particular, it has helped determine optimal load balancing schemes for tree search for a variety of MIMD architectures <ref> [20, 8, 17] </ref>. In this paper, we present new methods for load balancing of unstructured tree computations on large-scale SIMD machines, and analyze the scalability of these and pre-existing schemes. <p> Algorithms with isoefficiencies of O (P log c small constant c, are also reasonably optimal for practical purposes. For a more rigorous discussion on the isoefficiency metric and scalability analysis, the reader is referred to <ref> [20, 18] </ref>. 3.3 Cost of each load balancing phase In both nGP and GP matching schemes, each load balancing phase requires a setup step and a work transfer step. During the setup step we match idle processors to busy processors by using sum-scans [3]. <p> We can compute the upper bound for T lb by using a technique that was originally developed in the context of Parallel Depth First Search on MIMD computers <ref> [5, 20] </ref>. In dynamic load balancing, the communication overheads are caused by work transfers. The total number of work transfers defines an upper bound on the total communication overhead.
Reference: [21] <author> Vipin Kumar and Vineet Singh. </author> <title> Scalability of Parallel Algorithms for the All-Pairs Shortest Path Problem: A Summary of Results. </title> <booktitle> In Proceedings of the International Conference on Parallel Processing, </booktitle> <year> 1990. </year> <note> Extended version appears in Journal of Parallel and Distributed Processing (special issue on massively parallel computation), Volume 13, 124-138, </note> <year> 1991. </year>
Reference-contexts: Scalability analysis of a parallel algorithm and architecture combination is very useful in extrapolating these conclusions [10, 11, 18, 20]. The isoeffi-ciency metric has been found to be quite useful in characterizing scalability of a number 2 of algorithms <ref> [9, 21, 32, 38, 41, 42] </ref>. In particular, it has helped determine optimal load balancing schemes for tree search for a variety of MIMD architectures [20, 8, 17].
Reference: [22] <author> Karp R. M. </author> <title> Challenges in Combinatorial Computing. </title> <note> To appear January 1991. </note>
Reference-contexts: 1 Introduction Tree search is central to solving a variety of problems in artificial intelligence [14, 29], combinatorial optimization <ref> [13, 22] </ref>, operations research [27] and Monte-Carlo evaluations of functional integrals [35]. The trees that need to be searched for most practical problems happen to be quite large, and for many tree search algorithms, different parts can be searched relatively independently. <p> Many efficient load balancing schemes have already been developed for dynamically partitioning large irregular trees for MIMD parallel computers [2, 4, 5, 7, 24, 25, 28, 31, 36, 37, 39, 40], whereas until recently, it was common wisdom that such irregular problems cannot be solved on large-scale SIMD parallel computers <ref> [22] </ref>. Recent research has shown that data parallel SIMD architectures can also be used to implement parallel tree search algorithms effectively. Frye and Myczkowski [6] presents an implementation of a depth-first tree (DFS) search algorithm on the CM-2 for a block puzzle.
Reference: [23] <author> A. Mahanti and C. Daniels. </author> <title> SIMD Parallel Heuristic Search. </title> <note> To appear in Artificial Intelligence, 1992. Also available as a technical report, </note> <institution> University of Maryland, Computer Science Department. </institution>
Reference-contexts: Frye and Myczkowski [6] presents an implementation of a depth-first tree (DFS) search algorithm on the CM-2 for a block puzzle. Powley, Korf and Ferguson [30] and Mahanti and Daniels <ref> [23] </ref> present parallel formulations of a tree search algorithm IDA*, for solving the 15 puzzle problem on CM-2. The load balancing mechanisms used in the implementations of Frye, Powley, and Ma-hanti are different from each other. <p> Depth-first method is used in many important tree search algorithms such as Depth-First Branch and Bound [16], IDA fl [15], Backtracking [13]. In this paper we only consider parallel depth-first-search on SIMD machines. A common method used for parallel depth-first-search of dynamically generated trees on a SIMD machine <ref> [30, 23, 34] </ref> is as follows. At any time, all the processors are either in a search phase or in a load balancing phase. <p> Also, the terms busy and active processors will be used interchangeably. 2.1 Previous Schemes for Load Balancing The first scheme we study is similar to the one proposed in <ref> [30, 23] </ref>. In this algorithm, the triggering condition is computed after each node expansion cycle in the searching phase. If this condition is satisfied, then a load balancing phase is initiated. In the load balancing phase, idle processors are matched one-on-one with busy processors. <p> These schemes differ in the matching scheme, triggering condition and whether 7 or not we perform multiple work transfers during each load balancing phase. Name Comments Number of work transfers in a single load balancing phase nGP-S x This scheme is similar to <ref> [30, 23] </ref> single nGP-D P This scheme is similar to [30] multiple nGP-D K New scheme single GP-S x New scheme single GP-D P New scheme multiple GP-D K New scheme single Table 1: The different dynamic load balancing schemes studied. 3 Analysis Framework In this section we introduce some assumptions <p> We call this splitting mechanism the alpha-splitting mechanism. As demonstrated by experiments on MIMD machines <ref> [25, 1, 8, 17, 23] </ref> it is possible to find alpha-splitting mechanisms for most tree search problems. The total number of nodes expanded in parallel search can often be higher or lower than the number of nodes expanded by serial search [33, 30, 23] leading to speedup anomalies. <p> As demonstrated by experiments on MIMD machines [25, 1, 8, 17, 23] it is possible to find alpha-splitting mechanisms for most tree search problems. The total number of nodes expanded in parallel search can often be higher or lower than the number of nodes expanded by serial search <ref> [33, 30, 23] </ref> leading to speedup anomalies. <p> IDA fl is the best known sequential depth-first-search algorithm to find optimal solution paths for the 15-puzzle problem [15], and generates highly irregular search trees. We have parallelized IDA fl to test the effectiveness of the various load balancing algorithms. The same algorithm was also used in <ref> [30, 23] </ref>. Our parallel implementations of IDA fl find all the solutions of the puzzle up to a given tree depth. <p> Our parallel implementations of IDA fl find all the solutions of the puzzle up to a given tree depth. This ensures that the number of nodes expanded by the serial and the parallel search is the same, and thus we avoid having to consider superlinear speedup effects <ref> [33, 30, 23] </ref>. We obtained experimental results using both the nGP and the GP matching schemes for different values of static threshold x. In our implementation, each node expansion cycle takes about 30ms while each load balancing phase takes about 13ms. <p> Due to poorer load balancing the D P -triggering scheme performs more node expansion cycles than the D K -triggering scheme. 8 Related Work Mahanti and Daniels proposed two dynamic load balancing algorithms, FESS and FEGS, in <ref> [23] </ref>. In both these schemes a load balancing phase is initiated as soon as one processor becomes idle and the matching scheme used is similar to nGP . <p> The first scheme is similar to nGP-S x with the difference that each busy processor gives one piece of work to as many idle processors as many pieces of work it has. Clearly this scheme has a poor splitting mechanism. Also as shown in <ref> [23] </ref>, extending this algorithm in such a way so that the total number of nodes is evenly distributed among the processors the memory requirements of this algorithm become unbounded. The second algorithm is based on nearest neighbor communication.
Reference: [24] <author> B. Monien and O. Vornberger. </author> <title> Parallel Processing of Combinatorial Search Trees. </title> <booktitle> In Proceedings of International Workshop on Parallel Algorithms and Architectures, </booktitle> <month> May </month> <year> 1987. </year>
Reference: [25] <author> V. Nageshwara Rao and Vipin Kumar. </author> <title> Parallel Depth-First Search, Part I: Implementation. </title> <journal> International Journal of Parallel Programming, </journal> <volume> 16 </volume> (6):479-499, 1987. 
Reference-contexts: We call this splitting mechanism the alpha-splitting mechanism. As demonstrated by experiments on MIMD machines <ref> [25, 1, 8, 17, 23] </ref> it is possible to find alpha-splitting mechanisms for most tree search problems. The total number of nodes expanded in parallel search can often be higher or lower than the number of nodes expanded by serial search [33, 30, 23] leading to speedup anomalies.
Reference: [26] <author> Nils J. Nilsson. </author> <booktitle> Principles of Artificial Intelligence. </booktitle> <publisher> Tioga Press, </publisher> <year> 1980. </year>
Reference-contexts: In general, when fi &gt; 0, the value of the optimal static trigger will be smaller than the one given by equation (18) 5 . 5 Static Triggering: Experimental Results We solved various instances of the 15-puzzle problem <ref> [26] </ref> taken from [15], on a CM-2 massively parallel SIMD computer. 15-puzzle is a 4 fi 4 square tray containing 15 square tiles. The remaining sixteenth square is uncovered. Each tile has a number on it.
Reference: [27] <author> Christos H. Papadimitriou and Kenneth Steiglitz. </author> <title> Combinatorial Optimization, Algorithms and Complexity. </title> <publisher> Prentice Hall, </publisher> <year> 1982. </year>
Reference-contexts: 1 Introduction Tree search is central to solving a variety of problems in artificial intelligence [14, 29], combinatorial optimization [13, 22], operations research <ref> [27] </ref> and Monte-Carlo evaluations of functional integrals [35]. The trees that need to be searched for most practical problems happen to be quite large, and for many tree search algorithms, different parts can be searched relatively independently.
Reference: [28] <author> Srinivas Patil and Prithviraj Banerjee. </author> <title> A Parallel Branch and Bound Algorithm for Test Generation. </title> <journal> In IEEE Transactions on Computer Aided Design, </journal> <volume> Vol. 9, No. 3, </volume> <month> March </month> <year> 1990. </year>
Reference: [29] <author> Judea Pearl. </author> <title> Heuristics Intelligent Search Strategies for Computer Problem Solving. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1984. </year>
Reference-contexts: 1 Introduction Tree search is central to solving a variety of problems in artificial intelligence <ref> [14, 29] </ref>, combinatorial optimization [13, 22], operations research [27] and Monte-Carlo evaluations of functional integrals [35]. The trees that need to be searched for most practical problems happen to be quite large, and for many tree search algorithms, different parts can be searched relatively independently.
Reference: [30] <author> C. Powley, R. Korf, and C. Ferguson. </author> <title> IDA* on the Connection Machine. </title> <note> To appear in Artificial Intelligence, 1992. Also available as a technical report, </note> <institution> Department of Computer Science, UCLA. </institution> <month> 32 </month>
Reference-contexts: Recent research has shown that data parallel SIMD architectures can also be used to implement parallel tree search algorithms effectively. Frye and Myczkowski [6] presents an implementation of a depth-first tree (DFS) search algorithm on the CM-2 for a block puzzle. Powley, Korf and Ferguson <ref> [30] </ref> and Mahanti and Daniels [23] present parallel formulations of a tree search algorithm IDA*, for solving the 15 puzzle problem on CM-2. The load balancing mechanisms used in the implementations of Frye, Powley, and Ma-hanti are different from each other. <p> Depth-first method is used in many important tree search algorithms such as Depth-First Branch and Bound [16], IDA fl [15], Backtracking [13]. In this paper we only consider parallel depth-first-search on SIMD machines. A common method used for parallel depth-first-search of dynamically generated trees on a SIMD machine <ref> [30, 23, 34] </ref> is as follows. At any time, all the processors are either in a search phase or in a load balancing phase. <p> Also, the terms busy and active processors will be used interchangeably. 2.1 Previous Schemes for Load Balancing The first scheme we study is similar to the one proposed in <ref> [30, 23] </ref>. In this algorithm, the triggering condition is computed after each node expansion cycle in the searching phase. If this condition is satisfied, then a load balancing phase is initiated. In the load balancing phase, idle processors are matched one-on-one with busy processors. <p> After each load balancing phase, at least one node expansion cycle is completed before the triggering condition is tested again. A very simple and intuitive scheme <ref> [30, 34] </ref> is to trigger a load balancing phase when the 2 This is done using the rendezvous allocation scheme described in [12]. 4 p p p p p p p p p p p p p p p p p p p p p p p p p p p <p> An alternative to static triggering is to use a trigger value that changes dynamically in order to adapt itself to the characteristics of the problem. We call this kind of triggering scheme dynamic triggering D. A dynamic triggering scheme was proposed and analyzed by Powley, Ferguson and Korf <ref> [30] </ref>. For the rest of this paper we will refer to it as the D P - triggering scheme. <p> For the D P -triggering scheme to perform well, it is necessary that multiple work transfers are performed within each load balancing phase until all (or most) of the processors receive work <ref> [30] </ref> (the reason for this is given in Section 6.1). Hence every time we use the D P - triggering scheme, we perform multiple work transfers. All load balancing schemes are listed in Table 1. <p> These schemes differ in the matching scheme, triggering condition and whether 7 or not we perform multiple work transfers during each load balancing phase. Name Comments Number of work transfers in a single load balancing phase nGP-S x This scheme is similar to <ref> [30, 23] </ref> single nGP-D P This scheme is similar to [30] multiple nGP-D K New scheme single GP-S x New scheme single GP-D P New scheme multiple GP-D K New scheme single Table 1: The different dynamic load balancing schemes studied. 3 Analysis Framework In this section we introduce some assumptions <p> Name Comments Number of work transfers in a single load balancing phase nGP-S x This scheme is similar to [30, 23] single nGP-D P This scheme is similar to <ref> [30] </ref> multiple nGP-D K New scheme single GP-S x New scheme single GP-D P New scheme multiple GP-D K New scheme single Table 1: The different dynamic load balancing schemes studied. 3 Analysis Framework In this section we introduce some assumptions and basic terminology necessary to understand the analysis. <p> As demonstrated by experiments on MIMD machines [25, 1, 8, 17, 23] it is possible to find alpha-splitting mechanisms for most tree search problems. The total number of nodes expanded in parallel search can often be higher or lower than the number of nodes expanded by serial search <ref> [33, 30, 23] </ref> leading to speedup anomalies. <p> IDA fl is the best known sequential depth-first-search algorithm to find optimal solution paths for the 15-puzzle problem [15], and generates highly irregular search trees. We have parallelized IDA fl to test the effectiveness of the various load balancing algorithms. The same algorithm was also used in <ref> [30, 23] </ref>. Our parallel implementations of IDA fl find all the solutions of the puzzle up to a given tree depth. <p> Our parallel implementations of IDA fl find all the solutions of the puzzle up to a given tree depth. This ensures that the number of nodes expanded by the serial and the parallel search is the same, and thus we avoid having to consider superlinear speedup effects <ref> [33, 30, 23] </ref>. We obtained experimental results using both the nGP and the GP matching schemes for different values of static threshold x. In our implementation, each node expansion cycle takes about 30ms while each load balancing phase takes about 13ms. <p> Particularly, it was shown that even though the D P -triggering scheme has been shown to perform reasonably well <ref> [30] </ref>, under certain circumstances it can perform arbitrarily poorly. Also, it was shown that the overheads of the D K -triggering scheme are bounded and they can not be higher than twice the overheads of the optimal static triggering scheme.
Reference: [31] <author> Abhiram Ranade. </author> <title> Optimal Speedup for Backtrack Search on a Butterfly Network. </title> <booktitle> In Proceedings of the Third ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <year> 1991. </year>
Reference: [32] <author> S. Ranka and S. Sahni. </author> <title> Hypercube Algorithms for Image Processing and Pattern Recognition. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1990. </year>
Reference-contexts: Scalability analysis of a parallel algorithm and architecture combination is very useful in extrapolating these conclusions [10, 11, 18, 20]. The isoeffi-ciency metric has been found to be quite useful in characterizing scalability of a number 2 of algorithms <ref> [9, 21, 32, 38, 41, 42] </ref>. In particular, it has helped determine optimal load balancing schemes for tree search for a variety of MIMD architectures [20, 8, 17].
Reference: [33] <author> V. Nageshwara Rao and Vipin Kumar. </author> <title> On the Efficicency of Parallel Depth-First Search. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <note> (to appear), 1992. available as a technical report TR 90-55, </note> <institution> Computer Science Department, University of Minnesota. </institution>
Reference-contexts: As demonstrated by experiments on MIMD machines [25, 1, 8, 17, 23] it is possible to find alpha-splitting mechanisms for most tree search problems. The total number of nodes expanded in parallel search can often be higher or lower than the number of nodes expanded by serial search <ref> [33, 30, 23] </ref> leading to speedup anomalies. <p> Our parallel implementations of IDA fl find all the solutions of the puzzle up to a given tree depth. This ensures that the number of nodes expanded by the serial and the parallel search is the same, and thus we avoid having to consider superlinear speedup effects <ref> [33, 30, 23] </ref>. We obtained experimental results using both the nGP and the GP matching schemes for different values of static threshold x. In our implementation, each node expansion cycle takes about 30ms while each load balancing phase takes about 13ms.
Reference: [34] <author> Jasec Myczkowski Roger Frye. </author> <title> Exhaustive Search of Unstructured Trees on the Connection Machine. </title> <type> Technical report, </type> <institution> Thinking Machines Corporation, </institution> <year> 1990. </year>
Reference-contexts: Depth-first method is used in many important tree search algorithms such as Depth-First Branch and Bound [16], IDA fl [15], Backtracking [13]. In this paper we only consider parallel depth-first-search on SIMD machines. A common method used for parallel depth-first-search of dynamically generated trees on a SIMD machine <ref> [30, 23, 34] </ref> is as follows. At any time, all the processors are either in a search phase or in a load balancing phase. <p> After each load balancing phase, at least one node expansion cycle is completed before the triggering condition is tested again. A very simple and intuitive scheme <ref> [30, 34] </ref> is to trigger a load balancing phase when the 2 This is done using the rendezvous allocation scheme described in [12]. 4 p p p p p p p p p p p p p p p p p p p p p p p p p p p <p> FEGS performs better than FESS and due to better work distribution the number of load balancing phases is reduced. Frye and Myczkowski proposed two dynamic load balancing algorithms in <ref> [34] </ref>. The first scheme is similar to nGP-S x with the difference that each busy processor gives one piece of work to as many idle processors as many pieces of work it has. Clearly this scheme has a poor splitting mechanism.
Reference: [35] <author> Jasec Myczkowski Roger Frye. </author> <title> Load Balancing Algorithms on the Connection Machine and their Use in Monte-Carlo Methods. </title> <booktitle> In Proceedings of the Unstructured Scientific Computation on Multiprocessors Conference, </booktitle> <year> 1992. </year>
Reference-contexts: 1 Introduction Tree search is central to solving a variety of problems in artificial intelligence [14, 29], combinatorial optimization [13, 22], operations research [27] and Monte-Carlo evaluations of functional integrals <ref> [35] </ref>. The trees that need to be searched for most practical problems happen to be quite large, and for many tree search algorithms, different parts can be searched relatively independently.
Reference: [36] <author> Vikram Saletore and L. V. Kale. </author> <title> Consistent Linear Speedup to a First Solution in Parallel State-Space Search. </title> <booktitle> In Proceedings of the 1990 National Conference on Artificial Intelligence, </booktitle> <pages> pages 227-233, </pages> <month> August </month> <year> 1990. </year>
Reference: [37] <author> Wei Shu and L. V. Kale. </author> <title> A Dynamic Scheduling Strategy for the Chare-Kernel System. </title> <booktitle> In Proceedings of Supercomputing 89, </booktitle> <pages> pages 389-398, </pages> <year> 1989. </year>
Reference: [38] <author> Vineet Singh, Vipin Kumar, Gul Agha, and Chris Tomlinson. </author> <title> Scalability of parallel sorting on mesh multicomputers. </title> <booktitle> In Proceedings of the Fifth International Parallel Processing Symposium, </booktitle> <month> March </month> <year> 1991. </year> <note> Extended version available as a technical report (number TR 90-45) from the department of computer science, </note> <institution> University of Minnesota, Minneapolis, MN 55455, </institution> <note> and as TR ACT-SPA-298-90 from MCC, Austin, Texas. </note>
Reference-contexts: Scalability analysis of a parallel algorithm and architecture combination is very useful in extrapolating these conclusions [10, 11, 18, 20]. The isoeffi-ciency metric has been found to be quite useful in characterizing scalability of a number 2 of algorithms <ref> [9, 21, 32, 38, 41, 42] </ref>. In particular, it has helped determine optimal load balancing schemes for tree search for a variety of MIMD architectures [20, 8, 17].
Reference: [39] <author> Benjamin W. Wah, G.J. Li, and C. F. Yu. </author> <title> Multiprocessing of Combinatorial Search Problems. </title> <journal> IEEE Computers, </journal> <month> June </month> <year> 1985 1985. </year>
Reference: [40] <author> Benjamin W. Wah and Y. W. Eva Ma. </author> <title> MANIP A Multicomputer Architecture for Solving Combinatorial Extremum-Search Problems. </title> <journal> IEEE Transactions on Computers, </journal> <volume> c-33, </volume> <month> May </month> <year> 1984. </year>
Reference: [41] <author> Jinwoon Woo and Sartaj Sahni. </author> <title> Hypercube Computing : connected Components. </title> <journal> Journal of Supercomputing, </journal> <year> 1991. </year>
Reference-contexts: Scalability analysis of a parallel algorithm and architecture combination is very useful in extrapolating these conclusions [10, 11, 18, 20]. The isoeffi-ciency metric has been found to be quite useful in characterizing scalability of a number 2 of algorithms <ref> [9, 21, 32, 38, 41, 42] </ref>. In particular, it has helped determine optimal load balancing schemes for tree search for a variety of MIMD architectures [20, 8, 17].
Reference: [42] <author> Jinwoon Woo and Sartaj Sahni. </author> <title> Computing Biconnected Components on a Hypercube. </title> <journal> Journal of Supercomputing, </journal> <month> June </month> <year> 1991. </year> <month> 33 </month>
Reference-contexts: Scalability analysis of a parallel algorithm and architecture combination is very useful in extrapolating these conclusions [10, 11, 18, 20]. The isoeffi-ciency metric has been found to be quite useful in characterizing scalability of a number 2 of algorithms <ref> [9, 21, 32, 38, 41, 42] </ref>. In particular, it has helped determine optimal load balancing schemes for tree search for a variety of MIMD architectures [20, 8, 17].
References-found: 42

