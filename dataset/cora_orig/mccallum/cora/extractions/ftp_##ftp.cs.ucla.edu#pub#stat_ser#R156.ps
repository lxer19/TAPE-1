URL: ftp://ftp.cs.ucla.edu/pub/stat_ser/R156.ps
Refering-URL: http://www.pstat.ucsb.edu/~karcher/Workshop/BNWorkshopOtherBNLinks.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: A THEORY OF INFERRED CAUSATION perceive causal relationships in uncon trolled observations. 2. the task
Author: Judea Pearl &lt; judea@cs:ucla:edu &gt; T.S. Verma &lt; verma@cs:ucla:edu &gt; 
Note: 1. the clues that might prompt people to  
Address: Los Angeles, CA 90024  Los Angeles, CA 90024  
Affiliation: Cognitive Systems Laboratory Computer Science Department University of California  Cognitive Systems Laboratory Computer Science Department University of California  
Abstract: This paper concerns the empirical basis of causation, and addresses the following issues: We propose a minimal-model semantics of causation, and show that, contrary to common folklore, genuine causal influences can be distinguished from spurious covariations following standard norms of inductive reasoning. We also establish a sound characterization of the conditions under which such a distinction is possible. We provide an effective algorithm for inferred causation and show that, for a large class of data the algorithm can uncover the direction of causal influences as defined above. Finally, we ad dress the issue of non-temporal causation.
Abstract-found: 1
Intro-found: 1
Reference: [Bobrow, 1985] <author> Bobrow, D. </author> <year> (1985). </year> <title> Qualitative Rea soning about Physical Systems. </title> <publisher> MIT Press, </publisher> <address> Cam--bridge, MA. </address>
Reference-contexts: Tasks involving changing environments require causal theories which make formal distinctions between causation and logical implication [Geffner, 1989, Lifschitz, 1987, Pearl, 1988a, Shoham, 1988]. In applications such as diagnosis [Patil et al., 1982, Reiter, 1987], qualitative physics <ref> [Bobrow, 1985] </ref>, and plan recognition [Kautz, 1987, Wilensky, 1983], a central task is that of finding a satisfactory explanation to a given set of observations, fl This paper is a modified version of one presented at the Second International Conference conference on the Principles of Knowledge Representation and Reasoning, Cam-bridge, Massachusetts,
Reference: [Cartwright, 1989] <author> Cartwright, N. </author> <year> (1989). </year> <title> Nature Capacities and Their Measurements. </title> <publisher> Clarendon Press, Oxford. </publisher>
Reference-contexts: disabilities") in the spirit of Glymour [Glymour et al., 1987] and Simon [Simon, 1954]. 1 See [Dechter and Pearl, 1990] for a treatment of causation in the context of categorical data. 2 Some of the popular quotes are: "No causation without manipulation", [Holland, 1986], "No causes in, no causes out", <ref> [Cartwright, 1989] </ref> "No computer program can take account of variables that are not in the analysis", [Cliff, 1983]. This paper is organized as follows. <p> However, it turns out that for stable distributions, conditions (2) and (3) are sufficient to guarantee that the association between X and Y is non-spurious, thus justifying Definition 14 for genuine causation. The intuition goes as follows (see Figure 3): If the de 9 Cartwright <ref> [Cartwright, 1989] </ref> offers a sufficiency proof in the context of linear models. pendency between Z and Y (and similarly, between X and Y ) is spurious, namely, X and Y are merely manifestations of some common cause W , there is no reason then for X to screen-off Y from Z, <p> Adherence to this maxim explains why humans reach consensus regarding the directionality and nonspuriousness of causal relationships, in the face of opposing alternatives, perfectly consistent with experience. Echoing Cartwright <ref> [Cartwright, 1989] </ref> we summarize our claim with the slogan "No Causes In, Some Causes Out". From a methodological viewpoint, our theory should settle some of the on going disputes regarding the validity of path-analytic approaches to causal modeling in the social sciences [Freedman, 1987, Ling, 1983]. <p> For example, 1000 samples taken from the process shown in Eq. (5), each containing ten successive X,Y pairs, were sufficient for recovering its double-chain structure (and the correct direction of time). The greater the noise, 13 See also Cartwright <ref> [Cartwright, 1989] </ref> for a similar position, and for a survey of the literature. the quicker the recovery.
Reference: [Cliff, 1983] <author> Cliff, N. </author> <year> (1983). </year> <title> Some cautions concerning the application of causal modeling methods. Multivariate behavioral research, </title> <note> 18:115 - 126. </note> <author> [de Kleer and Brown, 1986] de Kleer, J. and Brown, J. S. </author> <year> (1986). </year> <title> Theories of causal ordering. </title> <journal> Artificial Intelligence, </journal> <volume> 29(1):33 - 62. </volume>
Reference-contexts: [Dechter and Pearl, 1990] for a treatment of causation in the context of categorical data. 2 Some of the popular quotes are: "No causation without manipulation", [Holland, 1986], "No causes in, no causes out", [Cartwright, 1989] "No computer program can take account of variables that are not in the analysis", <ref> [Cliff, 1983] </ref>. This paper is organized as follows. In Section 2 we define the notions of causal models and causal theories, and describe the task of causal modeling as an identification game scientists play against Nature.
Reference: [Dechter and Pearl, 1990] <author> Dechter, R. and Pearl, J. </author> <year> (1990). </year> <title> Directional constraint networks: A relational framework for causal modeling. </title> <type> Technical Report R-153, </type> <institution> UCLA Cognitive Systems Laboratory. </institution>
Reference-contexts: chronological information can significantly simplify the modeling task.) Such semantics should be applicable, therefore, to the organization of concurrent events or events whose chronological precedence cannot be determined with precision, (e.g. "old age explains disabilities") in the spirit of Glymour [Glymour et al., 1987] and Simon [Simon, 1954]. 1 See <ref> [Dechter and Pearl, 1990] </ref> for a treatment of causation in the context of categorical data. 2 Some of the popular quotes are: "No causation without manipulation", [Holland, 1986], "No causes in, no causes out", [Cartwright, 1989] "No computer program can take account of variables that are not in the analysis", [Cliff,
Reference: [Eells and Sober, 1983] <author> Eells, E. and Sober, E. </author> <year> (1983). </year> <title> Probabilistic causality. </title> <journal> Philosophy of Science, </journal> <volume> 50:35 - 57. </volume>
Reference: [Fisher, 1953] <author> Fisher, R. A. </author> <year> (1953). </year> <title> Design of Experiments. </title> <publisher> Oliver and Boyd, London. </publisher>
Reference-contexts: This belief, shaped and nurtured by generations of statisticians <ref> [Fisher, 1953, Keynes, 1939, Ling, 1983, Niles, 1922] </ref> has been a major hindrance in the way of developing a satisfactory, non-circular account of causation.
Reference: [Forbus and Gentner, 1986] <author> Forbus, K. D. and Gen-tner, D. </author> <year> (1986). </year> <title> Causal reasoning about quantities. </title> <booktitle> Proceedings Cognitive Science Society, </booktitle> <pages> pages 196 - 207. </pages>
Reference-contexts: say, "b causes a" or "c causes both a and b." The question of choosing an appropriate causal ordering received some attention in qualitative physics, where certain interactions attain directionality despite the instantaneous and symmetrical nature of the underlying equations, as in "current causing a voltage drop across the resistor" <ref> [Forbus and Gentner, 1986] </ref>. In some systems causal ordering is defined as the ordering at which subsets of variables can be solved independently of others [Iwasaki and Simon, 1986], in other systems it follows the way a disturbance is propagated from one variable to others [de Kleer and Brown, 1986].
Reference: [Freedman, 1987] <author> Freedman, D. </author> <year> (1987). </year> <title> As others see us: A case study in path analysis (with discussion). </title> <journal> Journal of Educational Statistics, </journal> <volume> 12:101 - 223. </volume>
Reference-contexts: Echoing Cartwright [Cartwright, 1989] we summarize our claim with the slogan "No Causes In, Some Causes Out". From a methodological viewpoint, our theory should settle some of the on going disputes regarding the validity of path-analytic approaches to causal modeling in the social sciences <ref> [Freedman, 1987, Ling, 1983] </ref>. It shows that the basic philosophy governing path-analytic methods is legitimate, faithfully adhering to the traditional norms of scientific investigation.
Reference: [Frydenberg, 1989] <author> Frydenberg, M. </author> <year> (1989). </year> <title> The chain graph markov property. </title> <type> Technical Report 186, </type> <institution> Department of Theoretical Statistics, University of Aarhus, Denmark. </institution>
Reference-contexts: Thus, tests for preference and equivalence can often be reduced to tests of induced dependencies which, in turn, can be determined directly from the topology of the dags, without ever concerning ourselves with the set of parameters. (For example, see Theorem 1 below and <ref> [Frydenberg, 1989, Pearl et al., 1989, Verma and Pearl, 1990] </ref>). Definition 5 A latent structure L is minimal with respect to a class L of latent structures iff for every L 0 2 L, L L 0 whenever L 0 L.
Reference: [Gardenfors, 1988] <author> Gardenfors, P. </author> <year> (1988). </year> <title> Causation and the dynamics of belief. </title> <editor> In Harper, W. and Skyrms, B., editors, </editor> <booktitle> Causation in Decision, Belief Change and Statistics II, </booktitle> <pages> pages 85 - 104. </pages> <publisher> Kluwer Academic Publishers. </publisher>
Reference-contexts: This belief, shaped and nurtured by generations of statisticians [Fisher, 1953, Keynes, 1939, Ling, 1983, Niles, 1922] has been a major hindrance in the way of developing a satisfactory, non-circular account of causation. In the words of Gardenfords <ref> [Gardenfors, 1988, page 193] </ref>: In order to distinguish genuine from spurious causes, we must already know the causally relevant background factors. ... Further, the extra amount of information is substantial: In order to determine whether C is a cause of E, all causally relevant background factors must be available.
Reference: [Geffner, 1989] <author> Geffner, H. </author> <year> (1989). </year> <title> Default Reasoning: Causal and Conditional Theories. </title> <type> PhD thesis, </type> <institution> UCLA Computer Science Department, </institution> <address> Los Angeles, CA. </address>
Reference-contexts: 1 Introduction The study of causation is central to the understanding of human reasoning. Tasks involving changing environments require causal theories which make formal distinctions between causation and logical implication <ref> [Geffner, 1989, Lifschitz, 1987, Pearl, 1988a, Shoham, 1988] </ref>.
Reference: [Geiger et al., 1990] <author> Geiger, D., Paz, A., and Pearl, J. </author> <year> (1990). </year> <title> Learning causal trees from dependence information. </title> <booktitle> In Proceedings, AAAI-90, </booktitle> <pages> pages 770 - 776, </pages> <address> Boston, MA. </address>
Reference-contexts: Stability precludes deterministic constraints. Less restrictive assumptions are treated in <ref> [Geiger et al., 1990] </ref>. 6 i.e. converging arrows emanating from non-adjacent nodes, such as a ! c b in Figure 1 (a). structure is sparse (see [Spirtes and Glymour, 1991, Verma and Pearl, 1990] for such algorithms).
Reference: [Glymour et al., 1987] <author> Glymour, C., Scheines, R., Spirtes, P., and Kelly, K. </author> <year> (1987). </year> <title> Discovering Causal Structure. </title> <publisher> Academic Press, </publisher> <address> New York. </address>
Reference-contexts: be determined without resorting to chronological information. (Although, when available, chronological information can significantly simplify the modeling task.) Such semantics should be applicable, therefore, to the organization of concurrent events or events whose chronological precedence cannot be determined with precision, (e.g. "old age explains disabilities") in the spirit of Glymour <ref> [Glymour et al., 1987] </ref> and Simon [Simon, 1954]. 1 See [Dechter and Pearl, 1990] for a treatment of causation in the context of categorical data. 2 Some of the popular quotes are: "No causation without manipulation", [Holland, 1986], "No causes in, no causes out", [Cartwright, 1989] "No computer program can take
Reference: [Good, 1983] <author> Good, I. J. </author> <year> (1983). </year> <title> A causal calculus. </title> <journal> British Journal for Philosophy of Science, </journal> <note> 11 and 12 and 13:305 - 328 and 43 - 51 and 88. reprinted as Ch. </note> <institution> 21 in Good Thinking University of Minnesota Press, Minneapolis, MN. </institution>
Reference-contexts: Sup-pes [Suppes, 1970] has argued convincingly that most causal utterances in ordinary conversation reflect prob abilistic, not categorical relations 1 . Thus, probability theory should provide a natural language for capturing causation <ref> [Reichenbach, 1956, Good, 1983] </ref>. This is especially true when we attempt to infer causation from (noisy) observations probability calculus remains an unchallenged formalism when it comes to translating statistical data into a system of revisable beliefs. <p> Temporal precedence is normally assumed essential for defining causation, and it is undoubtedly one of the most important clues that people use to distinguish causal from other types of associations. Accordingly, most theories of causation invoke an explicit requirement that a cause precedes its effect in time <ref> [Good, 1983, Reichenbach, 1956, Shoham, 1988, Suppes, 1970] </ref>. Yet temporal information alone cannot distinguish genuine causation from spurious associations caused by unknown factors. <p> I (Z 1 ; Y jS) Definition 11 was formulated in [Pearl, 1990] as a relation between events (rather than variables) with the added condition P (Y jX) &gt; P (Y ) in the spirit of <ref> [Good, 1983, Reichenbach, 1956, Suppes, 1970] </ref>. Condition 1 in Definition 12 may be established either by statistical methods (per Definition 11) or by other sources of information e.g., experimental studies or temporal succession (i.e. that Z precedes X in time).
Reference: [Granger, 1988] <author> Granger, C. W. J. </author> <year> (1988). </year> <title> Causality testing in a decision science. </title> <editor> In Harper, W. and Skyrms, B., editors, </editor> <title> Causation in Decision, Belief Change and Statistics I, </title> <booktitle> pages 1 - 20. </booktitle> <publisher> Kluwer Academic Publishers. </publisher>
Reference: [Holland, 1986] <author> Holland, P. </author> <year> (1986). </year> <title> Statistics and causal inference. </title> <journal> Journal of the American Statistical Association, </journal> <volume> 81:945 - 960. </volume>
Reference-contexts: be determined with precision, (e.g. "old age explains disabilities") in the spirit of Glymour [Glymour et al., 1987] and Simon [Simon, 1954]. 1 See [Dechter and Pearl, 1990] for a treatment of causation in the context of categorical data. 2 Some of the popular quotes are: "No causation without manipulation", <ref> [Holland, 1986] </ref>, "No causes in, no causes out", [Cartwright, 1989] "No computer program can take account of variables that are not in the analysis", [Cliff, 1983]. This paper is organized as follows. <p> Therefore, our definitions are in line with the paradigm of "no causation without manipulation" <ref> [Holland, 1986] </ref>). The difference is only that the variable Z, acting as a virtual control of X, must be identified within the data itself. The IC-algorithm provides a systematic way of searching for variables Z that qualify as virtual controls.
Reference: [Iwasaki and Simon, 1986] <author> Iwasaki, Y. and Simon, H. A. </author> <year> (1986). </year> <title> Causality in device behavior. </title> <journal> Artificial Intelligence, </journal> <volume> 29(1):3 - 32. </volume>
Reference-contexts: In some systems causal ordering is defined as the ordering at which subsets of variables can be solved independently of others <ref> [Iwasaki and Simon, 1986] </ref>, in other systems it follows the way a disturbance is propagated from one variable to others [de Kleer and Brown, 1986].
Reference: [Kautz, 1987] <author> Kautz, H. </author> <year> (1987). </year> <title> A formal Theory of Plan Recognition. </title> <type> PhD thesis, </type> <institution> University of Rochester, Rochester, N.Y. </institution>
Reference-contexts: Tasks involving changing environments require causal theories which make formal distinctions between causation and logical implication [Geffner, 1989, Lifschitz, 1987, Pearl, 1988a, Shoham, 1988]. In applications such as diagnosis [Patil et al., 1982, Reiter, 1987], qualitative physics [Bobrow, 1985], and plan recognition <ref> [Kautz, 1987, Wilensky, 1983] </ref>, a central task is that of finding a satisfactory explanation to a given set of observations, fl This paper is a modified version of one presented at the Second International Conference conference on the Principles of Knowledge Representation and Reasoning, Cam-bridge, Massachusetts, April 1991. and the meaning
Reference: [Kenny, 1979] <author> Kenny, D. A. </author> <year> (1979). </year> <title> Correlation and Causality. </title> <publisher> Wiley, </publisher> <address> New York. </address>
Reference-contexts: Unfortunately, such models are often employed in the social and behavioral sciences e.g. <ref> [Kenny, 1979] </ref>. On the practical side, we have shown that the assumption of model minimality, together with that of "stability" (no accidental independencies) lead to an effective algorithm of recovering causal structures, transparent as well as latent.
Reference: [Keynes, 1939] <author> Keynes, J. M. </author> <year> (1939). </year> <title> Professor tin-bergen's method. </title> <journal> Economic Journal, 49:560. </journal>
Reference-contexts: This belief, shaped and nurtured by generations of statisticians <ref> [Fisher, 1953, Keynes, 1939, Ling, 1983, Niles, 1922] </ref> has been a major hindrance in the way of developing a satisfactory, non-circular account of causation.
Reference: [Lifschitz, 1987] <author> Lifschitz, V. </author> <year> (1987). </year> <title> Formal theories of action. </title> <booktitle> In Workshop of the Frame Problem in AI, </booktitle> <pages> pages 35 - 57, </pages> <address> Kansas. </address>
Reference-contexts: 1 Introduction The study of causation is central to the understanding of human reasoning. Tasks involving changing environments require causal theories which make formal distinctions between causation and logical implication <ref> [Geffner, 1989, Lifschitz, 1987, Pearl, 1988a, Shoham, 1988] </ref>.
Reference: [Ling, 1983] <author> Ling, R. </author> <year> (1983). </year> <title> Review of "Correlation and Causation" by D. Kenny. </title> <journal> Journal of the American Statistical Association, </journal> <pages> pages 489 - 491. </pages>
Reference-contexts: This belief, shaped and nurtured by generations of statisticians <ref> [Fisher, 1953, Keynes, 1939, Ling, 1983, Niles, 1922] </ref> has been a major hindrance in the way of developing a satisfactory, non-circular account of causation. <p> Echoing Cartwright [Cartwright, 1989] we summarize our claim with the slogan "No Causes In, Some Causes Out". From a methodological viewpoint, our theory should settle some of the on going disputes regarding the validity of path-analytic approaches to causal modeling in the social sciences <ref> [Freedman, 1987, Ling, 1983] </ref>. It shows that the basic philosophy governing path-analytic methods is legitimate, faithfully adhering to the traditional norms of scientific investigation.
Reference: [Mitchell, 1982] <author> Mitchell, T. M. </author> <year> (1982). </year> <title> Generalization as search. </title> <journal> Artificial Intelligence, </journal> <volume> 18:203 - 226. </volume>
Reference-contexts: It should also be interesting to explore how the new criteria for causation could benefit current research in machine learning. In some sense, our method resembles a search through elements of a version space <ref> [Mitchell, 1982] </ref>, where each hypothesis stands for a causal theory. Unfortunately, this is where the resemblance ends.
Reference: [Niles, 1922] <author> Niles, H. E. </author> <year> (1922). </year> <title> Correlation, causation, and Wright theory of "path coefficients". Genetics, </title> <address> 7:258 - 273. </address>
Reference-contexts: This belief, shaped and nurtured by generations of statisticians <ref> [Fisher, 1953, Keynes, 1939, Ling, 1983, Niles, 1922] </ref> has been a major hindrance in the way of developing a satisfactory, non-circular account of causation.
Reference: [Patil et al., 1982] <author> Patil, R. S., Szolovitz, P., and Schwartz, W. B. </author> <year> (1982). </year> <title> Causal understanding of patient illness in patient diagnosis. </title> <booktitle> In Proceedings of AAAI-82, </booktitle> <pages> pages 345 - 348. </pages>
Reference-contexts: 1 Introduction The study of causation is central to the understanding of human reasoning. Tasks involving changing environments require causal theories which make formal distinctions between causation and logical implication [Geffner, 1989, Lifschitz, 1987, Pearl, 1988a, Shoham, 1988]. In applications such as diagnosis <ref> [Patil et al., 1982, Reiter, 1987] </ref>, qualitative physics [Bobrow, 1985], and plan recognition [Kautz, 1987, Wilensky, 1983], a central task is that of finding a satisfactory explanation to a given set of observations, fl This paper is a modified version of one presented at the Second International Conference conference on the
Reference: [Pearl, 1978] <author> Pearl, J. </author> <year> (1978). </year> <title> On the connection between the complexity and credibility of inferred models. </title> <journal> International Journal of General Systems, </journal> <volume> 4:255 - 264. </volume>
Reference-contexts: One reason scientists prefer simpler models is that such models are more constrained, thus more falsifiable; they provide the scientist with less opportunities to overfit the data hindsightedly and, therefore attain greater credibility <ref> [Pearl, 1978, Popper, 1959] </ref>. We also note that the set of dependencies induced by a causal model provides a measure of its expressive power, i.e., its power of mimicing other models.
Reference: [Pearl, 1988a] <author> Pearl, J. </author> <year> (1988a). </year> <title> Embracing causality in formal reasoning. </title> <journal> Artificial Intelligence, </journal> <volume> 35(2):259 - 71. </volume>
Reference-contexts: 1 Introduction The study of causation is central to the understanding of human reasoning. Tasks involving changing environments require causal theories which make formal distinctions between causation and logical implication <ref> [Geffner, 1989, Lifschitz, 1987, Pearl, 1988a, Shoham, 1988] </ref>. <p> Transferred to our chain a c b, we can preclude c from being a cause of a if we find another means (b) of potentially controlling c without affecting a <ref> [Pearl, 1988a, p. 396] </ref>. Determining the direction of causal influences from nontemporal data raises some interesting philosophical questions about the nature of time and causal explanations.
Reference: [Pearl, 1988b] <author> Pearl, J. </author> <year> (1988b). </year> <title> Probabilistic Reasoning in Intelligent Systems. </title> <address> Morgan-Kaufman, San Mateo, CA. </address>
Reference-contexts: To facilitate an effective proof theory, we rule out such eventualities, and impose a restriction on the distribution called "stability" (or "dag-isomorphism" in <ref> [Pearl, 1988b] </ref>). It conveys the assumption that all vanishing dependencies are struc tural, not formed by incidental equalities of numerical parameters 5 . Definition 8 Let I (P) denote the set of all conditional independence relationships embodieded in P . <p> Note that (1) and (2) imply (by the axioms of conditional independence <ref> [Pearl, 1988b] </ref>) that X and Y are dependent, namely, :I (X; Y ). @ @ ff? Y X @ @R @ @R V Z W Conditions (1) through (3) constitute the traditional premises behind controlled statistical experiments, with (1) reflecting the requirement that units selected for the expirement be chosen at
Reference: [Pearl, 1990] <author> Pearl, J. </author> <year> (1990). </year> <title> Probabilistic and qualitative abduction. </title> <booktitle> In Proceedings of AAAI Spring Symposium on Abduction, </booktitle> <pages> pages 155 - 158, </pages> <month> Stan-ford. </month>
Reference-contexts: Z 2 and X are independent given S Succinctly, using the predicates I and :I to denote independence and dependence respectively, the conditions above can be written: 1. :I (Z 1 ; XjS) 3. I (Z 1 ; Y jS) Definition 11 was formulated in <ref> [Pearl, 1990] </ref> as a relation between events (rather than variables) with the added condition P (Y jX) &gt; P (Y ) in the spirit of [Good, 1983, Reichenbach, 1956, Suppes, 1970].
Reference: [Pearl et al., 1989] <author> Pearl, J., Geiger, D., and Verma, T. S. </author> <year> (1989). </year> <title> The logic of influence diagrams. </title> <editor> In Oliver, R. M. and Smith, J. Q., editors, </editor> <title> Influence Diagrams, Belief Networks and Decision Analysis, </title> <booktitle> pages 67 - 87. </booktitle> <publisher> John Wiley and Sons, Ltd., </publisher> <address> Sussex, England. </address>
Reference-contexts: Thus, tests for preference and equivalence can often be reduced to tests of induced dependencies which, in turn, can be determined directly from the topology of the dags, without ever concerning ourselves with the set of parameters. (For example, see Theorem 1 below and <ref> [Frydenberg, 1989, Pearl et al., 1989, Verma and Pearl, 1990] </ref>). Definition 5 A latent structure L is minimal with respect to a class L of latent structures iff for every L 0 2 L, L L 0 whenever L 0 L.
Reference: [Popper, 1959] <author> Popper, K. R. </author> <year> (1959). </year> <title> The Logic of Scientific Discovery. </title> <publisher> Basic Books, </publisher> <address> New York. </address>
Reference-contexts: One reason scientists prefer simpler models is that such models are more constrained, thus more falsifiable; they provide the scientist with less opportunities to overfit the data hindsightedly and, therefore attain greater credibility <ref> [Pearl, 1978, Popper, 1959] </ref>. We also note that the set of dependencies induced by a causal model provides a measure of its expressive power, i.e., its power of mimicing other models.
Reference: [Reichenbach, 1956] <author> Reichenbach, H. </author> <year> (1956). </year> <title> The Di--rection of Time. </title> <institution> University of California Press, Berkeley. </institution>
Reference-contexts: Sup-pes [Suppes, 1970] has argued convincingly that most causal utterances in ordinary conversation reflect prob abilistic, not categorical relations 1 . Thus, probability theory should provide a natural language for capturing causation <ref> [Reichenbach, 1956, Good, 1983] </ref>. This is especially true when we attempt to infer causation from (noisy) observations probability calculus remains an unchallenged formalism when it comes to translating statistical data into a system of revisable beliefs. <p> Temporal precedence is normally assumed essential for defining causation, and it is undoubtedly one of the most important clues that people use to distinguish causal from other types of associations. Accordingly, most theories of causation invoke an explicit requirement that a cause precedes its effect in time <ref> [Good, 1983, Reichenbach, 1956, Shoham, 1988, Suppes, 1970] </ref>. Yet temporal information alone cannot distinguish genuine causation from spurious associations caused by unknown factors. <p> I (Z 1 ; Y jS) Definition 11 was formulated in [Pearl, 1990] as a relation between events (rather than variables) with the added condition P (Y jX) &gt; P (Y ) in the spirit of <ref> [Good, 1983, Reichenbach, 1956, Suppes, 1970] </ref>. Condition 1 in Definition 12 may be established either by statistical methods (per Definition 11) or by other sources of information e.g., experimental studies or temporal succession (i.e. that Z precedes X in time). <p> The sufficiency of these premises is clearly not a theorem of probability theory, as it relies on temporal relationships among the variables. However, it can be derived from probability theory together with Re-ichenbach's principle <ref> [Reichenbach, 1956] </ref>, stating that every dependence :I (X; Y ) requires a causal explanation, namely either one of the variables causes the other, or there must be a variable W preceding X and Y such that I (X; Y jW ) (see Figure 2). <p> governed by two coupled Markov chains, X t = ffX t1 + fiY t1 + ~ t Y t = flX t1 + ffiY t1 + ~ 0 t ; has only one statistical time the one coinciding with 10 This principle, known as Reichenbach's "conjunctive fork" or "common-cause" criterion <ref> [Reichenbach, 1956, Suppes and Zaniotti, 1981] </ref> has been criticized by Salmon [Salmon, 1984], who showed that some events would qualify as causal explanations though they fail to meet Re-ichenbach's criterion. <p> The temporal bias postulated earlier can be expressed as follows: Conjecture 1 (Temporal Bias) In most natural phenomenon, the physical time coincides with at least one statistical time. Reichenbach <ref> [Reichenbach, 1956] </ref> attributed the asymmetry associated with his conjunctive fork to the second law of thermodynamics.
Reference: [Reiter, 1987] <author> Reiter, R. </author> <year> (1987). </year> <title> A theory of diagnosis from first principles. </title> <journal> Artificial Intelligence, </journal> <volume> 32(1):57 - 95. </volume>
Reference-contexts: 1 Introduction The study of causation is central to the understanding of human reasoning. Tasks involving changing environments require causal theories which make formal distinctions between causation and logical implication [Geffner, 1989, Lifschitz, 1987, Pearl, 1988a, Shoham, 1988]. In applications such as diagnosis <ref> [Patil et al., 1982, Reiter, 1987] </ref>, qualitative physics [Bobrow, 1985], and plan recognition [Kautz, 1987, Wilensky, 1983], a central task is that of finding a satisfactory explanation to a given set of observations, fl This paper is a modified version of one presented at the Second International Conference conference on the
Reference: [Rubin, 1989] <author> Rubin, H. </author> <year> (1989). </year> <title> Discussion of "The Logic of Influence Diagrams" by Pearl at al. </title> <editor> In Oliver, R. M. and Smith, J. Q., editors, </editor> <title> Influence Diagrams, Belief Networks and Decision Analysis, </title> <booktitle> pages 83 - 85. </booktitle> <publisher> John Wiley and Sons, Ltd., </publisher> <address> Sussex, England. </address>
Reference-contexts: We shall first uncover the intuition behind Definition 14, assuming the availability of temporal information, then (in Section 8) generalize to non temporal data, per Definition 12. The common intuition about causation is captured by the heuristic definition <ref> [Rubin, 1989] </ref>: "X is a cause for Y if an external agent interfering only with X can affect Y " .
Reference: [Salmon, 1984] <author> Salmon, W. </author> <year> (1984). </year> <title> Scientific explanation and the causal structure of the world. </title> <publisher> Princeton University Press., Princeton. </publisher>
Reference-contexts: + fiY t1 + ~ t Y t = flX t1 + ffiY t1 + ~ 0 t ; has only one statistical time the one coinciding with 10 This principle, known as Reichenbach's "conjunctive fork" or "common-cause" criterion [Reichenbach, 1956, Suppes and Zaniotti, 1981] has been criticized by Salmon <ref> [Salmon, 1984] </ref>, who showed that some events would qualify as causal explanations though they fail to meet Re-ichenbach's criterion. Salmon admits, however, that when a conjunctive forks does occur, the screening off variable is expected to be the cause of the other two, not the effect [Salmon, 1984, p. 167]. <p> Salmon admits, however, that when a conjunctive forks does occur, the screening off variable is expected to be the cause of the other two, not the effect <ref> [Salmon, 1984, p. 167] </ref>. He notes that it is difficult to find physically meaningful examples where a response variable renders its two causes conditionally independent (although this would not violate any axiom of probability theory).
Reference: [Shoham, 1988] <author> Shoham, Y. </author> <year> (1988). </year> <title> Reasoning About Change. </title> <publisher> MIT Press, </publisher> <address> Boston, MA. </address>
Reference-contexts: 1 Introduction The study of causation is central to the understanding of human reasoning. Tasks involving changing environments require causal theories which make formal distinctions between causation and logical implication <ref> [Geffner, 1989, Lifschitz, 1987, Pearl, 1988a, Shoham, 1988] </ref>. <p> Temporal precedence is normally assumed essential for defining causation, and it is undoubtedly one of the most important clues that people use to distinguish causal from other types of associations. Accordingly, most theories of causation invoke an explicit requirement that a cause precedes its effect in time <ref> [Good, 1983, Reichenbach, 1956, Shoham, 1988, Suppes, 1970] </ref>. Yet temporal information alone cannot distinguish genuine causation from spurious associations caused by unknown factors.
Reference: [Simon, 1954] <author> Simon, H. </author> <year> (1954). </year> <title> Spurious correlations: A causal interpretation. </title> <journal> Journal American Statistical Association, </journal> <volume> 49:469 - 492. </volume>
Reference-contexts: information. (Although, when available, chronological information can significantly simplify the modeling task.) Such semantics should be applicable, therefore, to the organization of concurrent events or events whose chronological precedence cannot be determined with precision, (e.g. "old age explains disabilities") in the spirit of Glymour [Glymour et al., 1987] and Simon <ref> [Simon, 1954] </ref>. 1 See [Dechter and Pearl, 1990] for a treatment of causation in the context of categorical data. 2 Some of the popular quotes are: "No causation without manipulation", [Holland, 1986], "No causes in, no causes out", [Cartwright, 1989] "No computer program can take account of variables that are not
Reference: [Skyrms, 1986] <author> Skyrms, B. </author> <year> (1986). </year> <title> Causal Necessity. </title> <publisher> Yale University Press, </publisher> <address> New Haven, CT. </address>
Reference: [Spirtes and Glymour, 1991] <author> Spirtes, P. and Glymour, C. </author> <year> (1991). </year> <title> An algorithm for fast recovery of sparse causal graphs. </title> <journal> Social Science Computer Review, </journal> <volume> 9. </volume>
Reference-contexts: Stability precludes deterministic constraints. Less restrictive assumptions are treated in [Geiger et al., 1990]. 6 i.e. converging arrows emanating from non-adjacent nodes, such as a ! c b in Figure 1 (a). structure is sparse (see <ref> [Spirtes and Glymour, 1991, Verma and Pearl, 1990] </ref> for such algorithms). Unfortunately, the constraints that a latent structure impose upon the distribution cannot be completely characterized by any set of dependency statements. <p> Acknowledgement We are grateful to Clark Glymour for posing the problem of equivalence in latent structures. Some of the problems treated in this paper were independently explored by Glymour, Spirtes and Schienes <ref> [Spirtes et al., 1989, Spirtes and Glymour, 1991] </ref>, and we thank them for sharing this information with us. Discussions and correspondence with P. Bentler, D. Geiger, C. Granger, M. Hanssens, J. de Leeuw, S. Lloyd, R. Otte, A. Paz, B. Skyrms and P. Suppes are greatly appreciated.
Reference: [Spirtes et al., 1989] <author> Spirtes, P., Glymour, C., and Scheines, R. </author> <year> (1989). </year> <title> Causality from probability. </title> <type> Technical Report CMU-LCL-89-4, </type> <institution> Department of Philosophy Carnegie-Mellon University. </institution>
Reference-contexts: This search is exponential in general, but simplifies significantly when the underlying 5 It is possible to show that, if the parameters are chosen at random from any reasonable distribution, then any unstable distribution has measure zero <ref> [Spirtes et al., 1989] </ref>. Stability precludes deterministic constraints. <p> Acknowledgement We are grateful to Clark Glymour for posing the problem of equivalence in latent structures. Some of the problems treated in this paper were independently explored by Glymour, Spirtes and Schienes <ref> [Spirtes et al., 1989, Spirtes and Glymour, 1991] </ref>, and we thank them for sharing this information with us. Discussions and correspondence with P. Bentler, D. Geiger, C. Granger, M. Hanssens, J. de Leeuw, S. Lloyd, R. Otte, A. Paz, B. Skyrms and P. Suppes are greatly appreciated.
Reference: [Spohn, 1983] <author> Spohn, W. </author> <year> (1983). </year> <title> Deterministic and probabilistic reasons and causes. </title> <journal> Erkenntnis, </journal> <volume> 19:371 - 396. </volume>
Reference: [Suppes, 1970] <author> Suppes, P. </author> <year> (1970). </year> <title> A Probabilistic Theory of Causation. </title> <publisher> North Holland, Amsterdam. </publisher>
Reference-contexts: While the notion of causation is often associated with those of necessity and functional dependence, causal expressions often tolerate exceptions, primarily due to missing variables and coarse description. We say, for example, "reckless driving causes accidents" or "you will fail this course because of your laziness". Sup-pes <ref> [Suppes, 1970] </ref> has argued convincingly that most causal utterances in ordinary conversation reflect prob abilistic, not categorical relations 1 . Thus, probability theory should provide a natural language for capturing causation [Reichenbach, 1956, Good, 1983]. <p> Temporal precedence is normally assumed essential for defining causation, and it is undoubtedly one of the most important clues that people use to distinguish causal from other types of associations. Accordingly, most theories of causation invoke an explicit requirement that a cause precedes its effect in time <ref> [Good, 1983, Reichenbach, 1956, Shoham, 1988, Suppes, 1970] </ref>. Yet temporal information alone cannot distinguish genuine causation from spurious associations caused by unknown factors. <p> I (Z 1 ; Y jS) Definition 11 was formulated in [Pearl, 1990] as a relation between events (rather than variables) with the added condition P (Y jX) &gt; P (Y ) in the spirit of <ref> [Good, 1983, Reichenbach, 1956, Suppes, 1970] </ref>. Condition 1 in Definition 12 may be established either by statistical methods (per Definition 11) or by other sources of information e.g., experimental studies or temporal succession (i.e. that Z precedes X in time).
Reference: [Suppes and Zaniotti, 1981] <author> Suppes, P. and Zaniotti, M. </author> <year> (1981). </year> <title> When are probabilistic explanations possible? Synthese, </title> <address> 48:191 - 199. </address>
Reference-contexts: governed by two coupled Markov chains, X t = ffX t1 + fiY t1 + ~ t Y t = flX t1 + ffiY t1 + ~ 0 t ; has only one statistical time the one coinciding with 10 This principle, known as Reichenbach's "conjunctive fork" or "common-cause" criterion <ref> [Reichenbach, 1956, Suppes and Zaniotti, 1981] </ref> has been criticized by Salmon [Salmon, 1984], who showed that some events would qualify as causal explanations though they fail to meet Re-ichenbach's criterion.
Reference: [Verma, 1991] <author> Verma, T. S. </author> <year> (1991). </year> <title> Invariant properties of causal models. </title> <type> Technical report, </type> <institution> UCLA Cognitive Systems Laboratory. </institution>
Reference-contexts: Here we assume that Nature is at liberty to impose arbitrary functional relationships between each effect and its causes and then to perturb these relationships by introducing arbitrary (yet mutually independent) disturbances. These disturbances reflect "hidden" or unmeasurable conditions and exceptions 3 Proofs can be found in <ref> [Verma, 1991] </ref>. which Nature chooses to govern by some undisclosed probability function.
Reference: [Verma and Pearl, 1990] <author> Verma, T. S. and Pearl, J. </author> <year> (1990). </year> <title> Equivalence and synthesis of causal models. </title> <booktitle> In Proceedings 6th Conference on Uncertainty in AI, </booktitle> <pages> pages 220 - 227. </pages>
Reference-contexts: Thus, tests for preference and equivalence can often be reduced to tests of induced dependencies which, in turn, can be determined directly from the topology of the dags, without ever concerning ourselves with the set of parameters. (For example, see Theorem 1 below and <ref> [Frydenberg, 1989, Pearl et al., 1989, Verma and Pearl, 1990] </ref>). Definition 5 A latent structure L is minimal with respect to a class L of latent structures iff for every L 0 2 L, L L 0 whenever L 0 L. <p> The following theorem, which is founded upon the depen dency information, states necessary and sufficient conditions for equivalence of causal models which contain no hidden variables. Theorem 1 <ref> [Verma and Pearl, 1990] </ref> When U = O, two causal models are equivalent iff their dags have the same links and same set of uncoupled head-to-head nodes 6 . <p> Stability precludes deterministic constraints. Less restrictive assumptions are treated in [Geiger et al., 1990]. 6 i.e. converging arrows emanating from non-adjacent nodes, such as a ! c b in Figure 1 (a). structure is sparse (see <ref> [Spirtes and Glymour, 1991, Verma and Pearl, 1990] </ref> for such algorithms). Unfortunately, the constraints that a latent structure impose upon the distribution cannot be completely characterized by any set of dependency statements. <p> Unfortunately, the constraints that a latent structure impose upon the distribution cannot be completely characterized by any set of dependency statements. However, the maximal set of sound constraints can be identified <ref> [Verma and Pearl, 1990] </ref> and it is this set that permits us to recover sound fragments of latent structures. 5 Recovering Latent Structures When Nature decides to "hide" some variables, the ob served distribution ^ P need no longer be stable relative to the observable set O, i.e. ^ P may
Reference: [Wilensky, 1983] <author> Wilensky, R. </author> <year> (1983). </year> <title> Planning and understanding. </title> <publisher> Addison Wesley. </publisher>
Reference-contexts: Tasks involving changing environments require causal theories which make formal distinctions between causation and logical implication [Geffner, 1989, Lifschitz, 1987, Pearl, 1988a, Shoham, 1988]. In applications such as diagnosis [Patil et al., 1982, Reiter, 1987], qualitative physics [Bobrow, 1985], and plan recognition <ref> [Kautz, 1987, Wilensky, 1983] </ref>, a central task is that of finding a satisfactory explanation to a given set of observations, fl This paper is a modified version of one presented at the Second International Conference conference on the Principles of Knowledge Representation and Reasoning, Cam-bridge, Massachusetts, April 1991. and the meaning
Reference: [Wright, 1925] <author> Wright, S. </author> <year> (1925). </year> <title> Corn and hog correlations. </title> <type> Technical Report 1300, U.S. </type> <institution> Department of Agriculture. </institution>
Reference-contexts: To further test such claims one may need to either conduct experimental studies, or consult a richer data set where virtual control variables are found. In testing this modeling scheme on real life data, we have examined the observations reported in Se-wal Wright's seminal paper "Corn and Hog Correlations" <ref> [Wright, 1925] </ref>. As expected, corn-price (X) can clearly be identified as a cause of hog-price (Y ), not the other way around.
References-found: 47

