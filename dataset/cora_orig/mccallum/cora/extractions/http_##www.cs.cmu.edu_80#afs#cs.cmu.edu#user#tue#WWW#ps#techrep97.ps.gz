URL: http://www.cs.cmu.edu:80/afs/cs.cmu.edu/user/tue/WWW/ps/techrep97.ps.gz
Refering-URL: http://www.cs.cmu.edu:80/afs/cs.cmu.edu/user/tue/WWW/resume.html
Root-URL: 
Title: Modeling and Interpreting Multimodal Inputs: A Semantic Integration Approach  
Author: Minh Tue Vo and Alex Waibel 
Address: Pittsburgh, PA 15213  
Affiliation: School of Computer Science Carnegie Mellon University  
Date: December 1997  
Pubnum: CMU-CS-97-192  
Abstract: Modern user interfaces can take advantage of multiple input modalities such as speech, gestures, handwriting... to increase robustness and flexibility. The construction of such multimodal interfaces would be greatly facilitated by a unified framework that provides methods to characterize and interpret multimodal inputs. In this paper we describe a semantic model and a multimodal grammar structure for a broad class of multimodal applications. We also present a set of grammar-based Java tools that facilitate the construction of multimodal input processing modules, including a connectionist network for multimodal semantic integration. This research was sponsored by the DARPA under Department of the Navy, Naval Research Office under grant number N00014-93-1-0806, and Project GENOA under grant number 97047-ISX/ SOW-600066. Views and conclusions contained in this document are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of the DARPA or the U.S. Government. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Ando, H., Kitahara, Y., and Hataoka, N., </author> <title> Evaluation of Multimodal Interface Using Spoken Language and Pointing Gesture On Interior Design System, </title> <booktitle> Proc. </booktitle> <address> ICSLP94 (Yoko hama, Japan, </address> <month> Sept. </month> <journal> 1994), </journal> <volume> Vol. 2, </volume> <pages> pp. 567-570. </pages>
Reference: [2] <author> Gamma, E., Helm, R., Johnson, R., and Vlissides, J., </author> <title> Design Patterns: </title> <booktitle> Elements of Reus able ObjectOriented Software , Addison-Wesley, </booktitle> <year> 1995. </year>
Reference-contexts: It we were to implement this as a polymorphic recursive method on GObject, it would be necessary to add one method for each operation we want to support. We chose instead to apply the Visitor design pattern <ref> [2] </ref>. The Visitor pattern is ideal for this because the number of grammar object types is fixed, whereas the number of possible operations is unlimited. <p> We have implemented an object-oriented, drag-and-drop grammar editor that employs exactly this paradigm. 5.1.1 Graphical Display of Grammar Components In our implementation the graphical user interface (GUI) elements are cleanly separated from the underlying grammar representation using the Observable/Observer design pattern <ref> [2] </ref>, similar to the model-view approach in the Smalltalk programming environment. Each GObject has one or more associated observers or views, represented by subclasses of a GObject-View root class (Figure 6 shows some views captured from a computer display).
Reference: [3] <author> Gorin, A.L., Levinson, S., Gertner, A., and Goldman, E., </author> <title> Adaptive Acquisition of Lan guage, </title> <booktitle> Computer, Speech and Language , Vol. </booktitle> <volume> 5, No. 2, </volume> <month> April </month> <year> 1991, </year> <pages> pp. 101-132. </pages>
Reference-contexts: There is also a bias connection with weight . The output with the highest activation is selected as the most probable hypothesis given the input sequence. This network architecture was first proposed by Gorin et al. <ref> [3] </ref>. Although the simplifying independence assumption does not usually hold in practice, this mutual information network has been shown to learn input-output associations quite successfully [3][9][14]. The input independence assumption implies that classification does not depend on the order of the input tokens. <p> These probabilities can be estimated by a simple counting procedure <ref> [3] </ref>. In Section 5.5 we will describe how the weights can be automatically generated from a grammar-based input model. Thus our network architecture enjoys a definite advantage over backpropagation networks since the training time is drastically reduced or eliminated altogether. <p> Thus our network architecture enjoys a definite advantage over backpropagation networks since the training time is drastically reduced or eliminated altogether. In principle the mutual information network is capable of learning incrementally during actual use, as demonstrated by Gorin et al. <ref> [3] </ref>. The MS-MIN inherits this capability; however, we need to conduct more experiments to determine to what degree this is true in practice, when the task domains are complex and a lot of training data must be used to achieve adequate coverage. 4.
Reference: [4] <author> Gorin, A.L., </author> <title> On Automated Language Acquisition, </title> <journal> J. Acoust. Soc. Am. </journal> , <volume> Vol. 97, No. 6, </volume> <month> June </month> <year> 1995, </year> <pages> pp. 3441-3461. </pages>
Reference-contexts: To take into account the fact that adjacent input tokens sometimes form phrases or sentence fragments having significant information contents, we can introduce higher-order input units which are activated when particular token sequences occur <ref> [4] </ref>. Since the number of high-order input units can explode quite rapidly, we prune away units that are not useful for classification. This can be done using a measure called salience which is indicative of input relevancy with respect to classification [4]. <p> units which are activated when particular token sequences occur <ref> [4] </ref>. Since the number of high-order input units can explode quite rapidly, we prune away units that are not useful for classification. This can be done using a measure called salience which is indicative of input relevancy with respect to classification [4]. The mutual information network architecture is depicted in Figure 2. 3.2. The Multi-State Mutual Information Network The basic mutual information network described above assigns a single label to each input sequence.
Reference: [5] <author> Haffner, P., Franzini, M., and Waibel, A., </author> <title> Integrating Time Alignment and Neural Net works for High Performance Continuous Speech Recognition, </title> <booktitle> Proc. ICASSP91 (Tor onto, </booktitle> <address> Canada, </address> <month> May </month> <year> 1991), </year> <journal> Vol. </journal> <volume> 1, </volume> <pages> pp. 105-108. </pages>
Reference: [6] <author> Haffner, P. and Waibel, A., </author> <title> Multi-State Time Delay Neural Networks for Continuous Speech Recognition, </title> <booktitle> Advances in Neural Network Information Processing Systems 4 , Morgan Kaufmann Publishers, </booktitle> <year> 1992, </year> <pages> pp. 135-142. </pages>
Reference: [7] <author> Hauptmann, A., </author> <title> Speech and Gestures for Graphic Image Manipulation, </title> <booktitle> Proc. </booktitle> <address> CHI89 (Austin, Texas, </address> <month> April-May </month> <year> 1989), </year> <pages> pp. 241-245. </pages>
Reference: [8] <author> Koons, D.B., Sparrell, C.J., and Thorisson, K.R., </author> <title> Integrating Simultaneous Input From Speech, Gaze, and Hand Gestures, Intelligent Multimedia Interfaces , Maybury, M.T. </title> <editor> (Ed.) </editor> <publisher> (MIT Press, </publisher> <year> 1993), </year> <pages> pp. 257-276. </pages>
Reference: [9] <author> Miller, L.G. and Gorin, A.L., </author> <title> Structured Networks for Adaptive Language Acquisition, </title> <journal> Int. J. Pattern Recog. Artificial Intell. </journal> , <volume> Vol. 7, No. 4, </volume> <year> 1993, </year> <pages> pp. </pages> <month> 873-898. </month> <title> Modeling and Interpreting Multimodal Inputs: A Semantic Integration Approach 22 </title>
Reference: [10] <author> Mitchell, </author> <title> T.M., </title> <booktitle> Machine Learning , WCB/McGraw-Hill, </booktitle> <year> 1997. </year>
Reference-contexts: hypothesis, or the output class having the greatest a posteriori probability given the input: If we make the simplifying assumption that the input tokens are independent as well as condi tionally independent given the target output, the above equation can be rewritten as This is essentially a naive Bayes classifier <ref> [10] </ref>. Since the logarithm function is monotonically increasing, we have where is the mutual information of input t m and output c n The right hand side of the above equation can be realized by a connectionist network.
Reference: [11] <author> Ney, H., </author> <title> The Use of a OneStage Dynamic Programming Algorithm for Connected Word Recognition, </title> <journal> IEEE Transactions on Acoustics, Speech and Signal Processing , Vol. </journal> <volume> 32, No. 2, </volume> <year> 1984, </year> <pages> pp. 263-271. </pages>
Reference-contexts: Using a dynamic programming algorithm similar to the Viterbi search or Dynamic Time Warping in speech recognizers <ref> [11] </ref>, we can find an input segmentation and a corresponding label assignment that maximize the path score. Multiple input modalities are accommodated by implementing the path score maximi zation algorithm over more than one input dimension, where each dimension extends along one input stream.
Reference: [12] <author> Oviatt, S.L., Cohen, P.R., and Wang, M., </author> <title> Toward Interface Design for Human Language Technology: Modality and Structure as Determinants of Linguistic Complexity, </title> <journal> Speech Communication (Netherlands), </journal> <volume> Vol. 15, </volume> <pages> Nos. 3-4, </pages> <month> Dec. </month> <year> 1994, </year> <pages> pp. 283-300. </pages>
Reference: [13] <editor> Rumelhart, D.E. and McClelland, J.L., </editor> <booktitle> Parallel Distributed Processing: Exploration in the Microstructure of Cognition (Vols. </booktitle> <volume> 1 & 2), </volume> <publisher> MIT Press, </publisher> <year> 1986. </year>
Reference-contexts: Training the MS-MIN In backpropagation neural networks, the connection weights are incrementally adjusted dur ing training by a gradient descent algorithm to minimize a classification error function <ref> [13] </ref>. In contrast, the weights in a mutual information network can be computed directly from occur FIGURE 3.
Reference: [14] <author> Sankar, A. and Gorin, A.L., </author> <title> Adaptive Language Acquisition in a Multisensory Device, Artificial Neural Networks for Speech and Vision , Mammone, </title> <editor> R. (Ed.) </editor> <publisher> (Chapman and Hall, </publisher> <address> London, </address> <year> 1993), </year> <pages> pp. 324-356. </pages>
Reference: [15] <author> Vo, M.T. and Waibel, A., </author> <title> Multimodal Human-Computer Interaction, </title> <booktitle> Proc. </booktitle> <address> ISSD93 (Waseda, Japan, </address> <year> 1993). </year>
Reference: [16] <author> Vo, M.T., Houghton, R., Yang, J., Bub, U., Meier, U., Waibel, A., and Duchnowski, P., </author> <title> Multimodal Learning Interfaces, </title> <booktitle> Proc. ARPA SLT Workshop 95 (Austin, </booktitle> <address> Texas, </address> <year> 1995). </year>
Reference: [17] <author> Vo, M.T. and Wood, C., </author> <title> Building an application framework for speech and pen input integration in multimodal learning interfaces, </title> <booktitle> Proc. </booktitle> <address> ICASSP96 (Atlanta, Georgia, </address> <month> May </month> <year> 1996). </year>
Reference-contexts: Combining inputs at the signal level is difficult at best and does not present any obvious way of characterizing semantics in a general, domain-independent manner. Combining partial interpretations is possible and practical <ref> [17] </ref>; in fact, the semantic representation employed in this process (as described in [17]) was the inspiration for the semantic model described here. We will show that it is possible to derive a semantic interpretation from the combination of intermediate symbolic input representations. 2.3. <p> Combining inputs at the signal level is difficult at best and does not present any obvious way of characterizing semantics in a general, domain-independent manner. Combining partial interpretations is possible and practical <ref> [17] </ref>; in fact, the semantic representation employed in this process (as described in [17]) was the inspiration for the semantic model described here. We will show that it is possible to derive a semantic interpretation from the combination of intermediate symbolic input representations. 2.3.
Reference: [18] <author> Waibel, A., Vo, M.T., Duchnowski, P., and Manke, S., </author> <title> Multimodal Interfaces, </title> <booktitle> Artificial Intelligence Review , Special Volume on Integration of Natural Language and Vision Pro cessing , McKevitt, </booktitle> <editor> P. (Ed.), </editor> <volume> Vol. 10, </volume> <pages> Nos. 3-4, </pages> <year> 1995. </year>
Reference: [19] <author> Ward, W., </author> <title> Understanding Spontaneous Speech: </title> <booktitle> the Phoenix System, Proc. </booktitle> <address> ICASSP91 (Toronto, Canada, </address> <month> May </month> <year> 1991), </year> <pages> Vol.1, pp. 365-367. </pages>
Reference-contexts: The usual approach for speech-enabled applications is to develop a grammar that characterize spoken inputs <ref> [19] </ref>. We need to generalize this notion to encompass more than just the speech modality. Given a semantic model, the task of interpreting a multimodal input event consists of mapping the event to its corresponding semantic characterization in the model. <p> This approach is exemplified by the Air Travel Information Service (ATIS) system described in <ref> [19] </ref>. It is possible to employ the grammar used for interpretation as a user input model, i.e., a model that characterizes the kind of sentences we can expect from the users. However, we believe it is advantageous to put some separation between the notions of modeling and interpreting user input. <p> of a label specifying the modality; a NonTerm is a nonterminal node consisting of one or more sequences, each of which con tains one or more NonTerm or Literal; a Literal is a terminal node containing a text string. structure described here is equivalent to a recursive transition network formulation <ref> [19] </ref> which can represent any context-free grammar. There exist syntactic descriptions of context-free grammars that include notations for optional or repeating elements. These are only syntactic sugar notations that are convenient but not necessary, since they can be expressed using only the basic notations. <p> Visual Grammar Designer Traditional grammars are usually represented textually in some descriptive language such as Backus-Naur Form (BNF) or Phoenix <ref> [19] </ref>. It is rather difficult to follow these textual descrip FIGURE 7.
References-found: 19

