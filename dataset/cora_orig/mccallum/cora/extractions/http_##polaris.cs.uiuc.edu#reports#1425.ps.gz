URL: http://polaris.cs.uiuc.edu/reports/1425.ps.gz
Refering-URL: http://polaris.cs.uiuc.edu/tech_reports.html
Root-URL: http://www.cs.uiuc.edu
Email: lchoi@csrd.uiuc.edu yew@cs.umn.edu  
Phone: (217)333-0969 (612)625-7387  
Title: Eliminating Stale Data References through Array Data-Flow Analysis  
Author: Lynn Choi Pen-Chung Yew 
Note: This work is supported in part by the National Science Foundation under Grant No. MIP 89-20891 and MIP 93-07910.  
Address: Urbana, IL 61801-1351 Minneapolis, MN 55455-0519  
Affiliation: Center for Supercomputing R D Department of Computer Science University of Illinois University of Minnesota  
Abstract: In this paper, we develop a compiler algorithm for detecting references to stale data in shared-memory multiprocessors. The algorithm consists of two key analysis techniques, stale reference detection and locality preserving analysis. While the stale reference detection finds the memory reference patterns that may violate cache coherence, the locality preserving analysis minimizes the number of such stale references by analyzing both temporal and spatial reuses. By computing the regions referenced by arrays inside loops, we extend the previous scalar algorithms [9, 11] for more precise analysis. Gated single assignment [3] is used to compute equality and comparison between the array regions involving symbolic expressions. We have implemented the algorithm on the Polaris parallelizing compiler [21] and show the analysis results for Perfect benchmarks. The results indicate that for some of the benchmark programs, the difference is significant, implying the necessity of array analysis. However, for other programs, the scalar analysis gives comparable accuracy compared to array analysis. This is due to many undecidable symbolic computation for array references. Execution-driven simulations are used to verify the algorithm and to demonstrate how unnecessary cache misses can be eliminated by the automatic stale reference detection. The algorithm can be used to implement cache coherence in the shared-memory multiprocessors that do not have hardware directories such as Cray T3D [15]. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. V. Adve, V. S. Adve, M. D. Hill, and M. K. Vernon. </author> <title> Comparison of Hardware and Software Cache Coherence Schemes. </title> <booktitle> Proceedings of the 18th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 298-308, </pages> <month> May </month> <year> 1991. </year> <month> 23 </month>
Reference-contexts: In this approach, cache coherence is maintained locally without directory hardware, avoiding the complexity and the overhead associated with the hardware directories. Although the performance of such schemes have been demonstrated through simulations [6, 19, 20], most of those studies assume either perfect compile-time analysis or analytic models <ref> [1] </ref> without real compiler implementations. It is still unknown how effectively the compiler can detect potential stale references and what kind of performance can be obtained by using a real compiler.
Reference: [2] <author> R. Arpaci, D. Culler, A. Krishnamurthy, S. Steinberg, and K. Yelick. </author> <title> Emprical Evaluation of the CRAY-T3D: A Compiler Perspective. </title> <booktitle> Proceedings of the 22nd Annual International Symposium on Computer Architecture, </booktitle> <month> June </month> <year> 1995. </year>
Reference-contexts: For example in Cray T3D, lack of cache coherence mechanism forces each cache line loaded by a remote read not to be cached (by an uncacheable load instruction) or to be flushed, which prohibits the usefulness of caches for remote memory access <ref> [2] </ref>. On the other hand, in many research machines [13, 17, 18], the directory-based hardware coherence protocols have been studied to enforce the cache coherence. However, those protocols require complex and expensive hardware cache/directory controllers. Several compiler-directed coherence schemes have been proposed [7, 11, 19, 20].
Reference: [3] <author> R. Ballance, A. Maccabe, and K. Ottenstein. </author> <title> The Program Dependence Web: a Representation Supporting Control Data- and Demand-Driven Interpretation of Imperative Languages. </title> <booktitle> Proceedings of the SIGPLAN '90 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 257-271, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: It allows us to compute the values and the conditions of symbolic expressions. Such propagation will terminate at the confluence points of the control flow graph. To propagate information across the confluence points, we use a second technique, a gated single assignment (GSA) form <ref> [3] </ref> to determine the relationship between symbolic expressions when their values depend on the 1 branch conditions [24]. Two key analysis techniques are used to identify potential stale references: (1) stale reference pattern detection, and (2) locality preserving analysis.
Reference: [4] <author> M. Berry and et. al. </author> <title> The Perfect Club Benchmarks: Effective Performance Evaluation of Supercomputers. </title> <journal> International Journal of Supercomputer Applications, </journal> <volume> 3(3) </volume> <pages> 5-40, </pages> <month> Fall, </month> <year> 1989. </year>
Reference-contexts: All these compiler algorithms have been implemented in the Polaris parallelizing compiler, and experimentation results on Perfect benchmarks <ref> [4] </ref> are discussed. Execution-driven simulations are used to verify the compiler marking and to demonstrate the performance of stale reference detection. 1.1 Stale reference condition Memory event ordering Let's first define the ordering of events which leads to a stale reference. <p> Since inlining is most effective for small procedures, we selectively inline a procedure whenever its size (determined in terms of references) is less than a threshold value. 4 Experimentation We have implemented these compiler algorithms in the Polaris parallelizing compiler. Perfect benchmark suites <ref> [4] </ref> are chosen as our target applications. They are first parallelized by the Polaris compiler [21]. In the parallelized codes, the parallelism is expressed in terms of DOALL loops.
Reference: [5] <author> D. Callahan and K. Kennedy. </author> <title> Analysis of Interprocedural Side Effects in a Parallel Programming Environment. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 5 </volume> <pages> 517-550, </pages> <year> 1988. </year>
Reference-contexts: A subarray consists of a subscripted variable and one or more ranges for some of the indices in its subscript expression. A range is represented by a lower bound, a upper bound and a stride. The notion of a subarray is an extension to the regular section used in <ref> [5] </ref>. <p> There have been many studies on array data-flow algorithms. Feautrier [14] gave an algorithm to calculate them exactly. Pugh [23] developed some exact techniques that are substan 22 tially faster than Feautrier's. Our implementation is based on the regular section analysis <ref> [5] </ref>, which is less accurate but allows large programs to be analyzed efficiently. 6 Conclusion Private caches can greatly improve the performance of large-scale shared-memory multiprocessors if they can be used to cache remote shared data. However, maintaining cache coherence for such systems are still a challenge.
Reference: [6] <author> Yung-Chin Chen and Alenander V. Veidenbaum. </author> <title> Comparison and Analysis of Software and Directory Coherence Schemes. </title> <booktitle> Proceedings Supercomputing'91, </booktitle> <pages> pages 818-829, </pages> <month> November </month> <year> 1991. </year>
Reference-contexts: Several compiler-directed coherence schemes have been proposed [7, 11, 19, 20]. In this approach, cache coherence is maintained locally without directory hardware, avoiding the complexity and the overhead associated with the hardware directories. Although the performance of such schemes have been demonstrated through simulations <ref> [6, 19, 20] </ref>, most of those studies assume either perfect compile-time analysis or analytic models [1] without real compiler implementations. It is still unknown how effectively the compiler can detect potential stale references and what kind of performance can be obtained by using a real compiler.
Reference: [7] <author> Hoichi Cheong. </author> <title> Life Span Strategy A Compiler-Based Approach to Cache Coherence. </title> <booktitle> Proceedings of the 1992 International Conference on Supercomputing, </booktitle> <month> July </month> <year> 1992. </year>
Reference-contexts: On the other hand, in many research machines [13, 17, 18], the directory-based hardware coherence protocols have been studied to enforce the cache coherence. However, those protocols require complex and expensive hardware cache/directory controllers. Several compiler-directed coherence schemes have been proposed <ref> [7, 11, 19, 20] </ref>. In this approach, cache coherence is maintained locally without directory hardware, avoiding the complexity and the overhead associated with the hardware directories. <p> The techniques developed here are general enough to be applied to existing compiler-directed coherence schemes <ref> [7, 8, 11] </ref>. We use a combination of interval and data-flow analysis techniques to determine memory reference patterns which can lead to stale data accesses. To obtain more precise array access information, we compute the array region referenced by each array reference. <p> In a scalar analysis, even a write to a single element of an array is interpreted as a write to the entire array. This conservative scalar analysis often creates unnecessary cache misses either through invalidations or by redundant accesses to main memory <ref> [7, 8, 11] </ref>. These unnecessary memory accesses can be avoided by a more precise analysis. In the following, we will demonstrate how array access information can refine the stale reference detection. First, we describe our framework for array data-flow analysis such as GSA and subarray descriptors in section 2.
Reference: [8] <author> Hoichi Cheong and Alex Veidenbaum. </author> <title> A Cache Coherence Scheme with Fast Selective Invalidation. </title> <booktitle> Proceedings of The 15th Annual International Symposium on Computer Architecture, </booktitle> <pages> page 299, </pages> <month> June </month> <year> 1988. </year>
Reference-contexts: The techniques developed here are general enough to be applied to existing compiler-directed coherence schemes <ref> [7, 8, 11] </ref>. We use a combination of interval and data-flow analysis techniques to determine memory reference patterns which can lead to stale data accesses. To obtain more precise array access information, we compute the array region referenced by each array reference. <p> In a scalar analysis, even a write to a single element of an array is interpreted as a write to the entire array. This conservative scalar analysis often creates unnecessary cache misses either through invalidations or by redundant accesses to main memory <ref> [7, 8, 11] </ref>. These unnecessary memory accesses can be avoided by a more precise analysis. In the following, we will demonstrate how array access information can refine the stale reference detection. First, we describe our framework for array data-flow analysis such as GSA and subarray descriptors in section 2.
Reference: [9] <author> Hoichi Cheong and Alexander V. Veidenbaum. </author> <title> Stale Data Detection and Coherence Enforcement Using Flow Analysis. </title> <booktitle> Proceedings of the 1988 International Conference on Parallel Processing, I, </booktitle> <address> Architecture:138-145, </address> <month> August </month> <year> 1988. </year>
Reference-contexts: Otherwise, there are dependences among concurrent tasks. To detect stale data reference from a source program, the previous 1 The region can be a parallel loop or an entire procedure in our analysis. 2 compiler algorithms <ref> [25, 9, 11] </ref> look for the following memory reference patterns that consist of (a) a read or a write, (b) one or more epoch boundaries, (c) a write, (d) one or more epoch boundaries, and (e) a read. <p> We call this sequence of events a stale reference sequence. 1.2 Array data-flow analysis Previous compiler algorithms <ref> [9, 11] </ref> treat an entire array as a single variable, which leads to conservative estimation of potential stale references. <p> the array algorithm is directly proportional to the percentage of the shared memory references and the relative decrease in the potential stale references marked by the array algorithm over the scalar algorithm. 5 Discussion 5.1 Previous work There have been several studies on the compiler algorithms for stale reference detection <ref> [9, 11] </ref>. Among them, only Cheong and Veidenbaum included a compiler implementation study using Parafrase 1 [9] . They pioneered a combination of scalar data-flow analysis and graph algorithms to find potential stale references. <p> Among them, only Cheong and Veidenbaum included a compiler implementation study using Parafrase 1 <ref> [9] </ref> . They pioneered a combination of scalar data-flow analysis and graph algorithms to find potential stale references. In [11], we proposed a simpler algorithm that also produces additional information for a new compiler-directed cache coherence scheme. That algorithm eliminates the graph construction phase of [9], but it may overestimate the <p> implementation study using Parafrase 1 <ref> [9] </ref> . They pioneered a combination of scalar data-flow analysis and graph algorithms to find potential stale references. In [11], we proposed a simpler algorithm that also produces additional information for a new compiler-directed cache coherence scheme. That algorithm eliminates the graph construction phase of [9], but it may overestimate the potential stale references by summarizing information from multiple control flow paths. Both algorithms treat each array as a single variable. There have been many studies on array data-flow algorithms. Feautrier [14] gave an algorithm to calculate them exactly.
Reference: [10] <author> Lynn Choi and Pen-Chung Yew. </author> <title> Data-Flow Analysis for Cache Coherence: Beyond Procedural Boundaries. </title> <note> in preparation. </note>
Reference-contexts: A more sophisticated interprocedural analysis is beyond the scope of this paper, and is described in <ref> [10] </ref>. Cache invalidation at procedure boundary We can avoid the side effects of procedure calls by invalidating the entire cache after each call site. Since we start from a clean cache after the call, the side effect from the procedure need not be considered.
Reference: [11] <author> Lynn Choi and Pen-Chung Yew. </author> <title> A Compiler-Directed Cache Coherence Scheme with Improved Intertask Locality. </title> <booktitle> Proceedings of the Supercomputing'94, </booktitle> <month> November </month> <year> 1994. </year>
Reference-contexts: On the other hand, in many research machines [13, 17, 18], the directory-based hardware coherence protocols have been studied to enforce the cache coherence. However, those protocols require complex and expensive hardware cache/directory controllers. Several compiler-directed coherence schemes have been proposed <ref> [7, 11, 19, 20] </ref>. In this approach, cache coherence is maintained locally without directory hardware, avoiding the complexity and the overhead associated with the hardware directories. <p> The techniques developed here are general enough to be applied to existing compiler-directed coherence schemes <ref> [7, 8, 11] </ref>. We use a combination of interval and data-flow analysis techniques to determine memory reference patterns which can lead to stale data accesses. To obtain more precise array access information, we compute the array region referenced by each array reference. <p> Otherwise, there are dependences among concurrent tasks. To detect stale data reference from a source program, the previous 1 The region can be a parallel loop or an entire procedure in our analysis. 2 compiler algorithms <ref> [25, 9, 11] </ref> look for the following memory reference patterns that consist of (a) a read or a write, (b) one or more epoch boundaries, (c) a write, (d) one or more epoch boundaries, and (e) a read. <p> We call this sequence of events a stale reference sequence. 1.2 Array data-flow analysis Previous compiler algorithms <ref> [9, 11] </ref> treat an entire array as a single variable, which leads to conservative estimation of potential stale references. <p> In a scalar analysis, even a write to a single element of an array is interpreted as a write to the entire array. This conservative scalar analysis often creates unnecessary cache misses either through invalidations or by redundant accesses to main memory <ref> [7, 8, 11] </ref>. These unnecessary memory accesses can be avoided by a more precise analysis. In the following, we will demonstrate how array access information can refine the stale reference detection. First, we describe our framework for array data-flow analysis such as GSA and subarray descriptors in section 2. <p> Similarly, by representing the subarray fields in the GSA form, we can perform subarray operations involving symbolic loop bounds. 2.3 Stale reference detection The algorithm for stale reference detection is an improved version of the algorithm shown in <ref> [11] </ref>. <p> refine the algorithm both to accommodate multi-word cache blocks as well as to refine analysis for array regions. 3 Algorithms 3.1 Stale reference detection Because the epoch boundary information is essential in identifying potential stale references, we include parallel constructs in our control flow graph, called the epoch flow graph <ref> [11] </ref>. Figure 5 shows the control flow graph for the program example in Figure 3 and its corresponding epoch flow graph. Note that, to reflect the control flow of the parallel execution, back edges of parallel loops are removed in the epoch flow graph. <p> the array algorithm is directly proportional to the percentage of the shared memory references and the relative decrease in the potential stale references marked by the array algorithm over the scalar algorithm. 5 Discussion 5.1 Previous work There have been several studies on the compiler algorithms for stale reference detection <ref> [9, 11] </ref>. Among them, only Cheong and Veidenbaum included a compiler implementation study using Parafrase 1 [9] . They pioneered a combination of scalar data-flow analysis and graph algorithms to find potential stale references. <p> Among them, only Cheong and Veidenbaum included a compiler implementation study using Parafrase 1 [9] . They pioneered a combination of scalar data-flow analysis and graph algorithms to find potential stale references. In <ref> [11] </ref>, we proposed a simpler algorithm that also produces additional information for a new compiler-directed cache coherence scheme. That algorithm eliminates the graph construction phase of [9], but it may overestimate the potential stale references by summarizing information from multiple control flow paths.
Reference: [12] <author> Ron Cytron, Jeanne Ferrante, and Barry K. Rosen. </author> <title> Efficiently Computing Static Single Assignment Form and the Control Dependence Graph. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 13(4) </volume> <pages> 451-490, </pages> <month> Oct. </month> <year> 1991. </year> <month> 24 </month>
Reference-contexts: SSA <ref> [12] </ref> is a representation of a program in which each use of a variable is reached by exactly a single definition of the variable. It allows us to track the value of a variable by its name. <p> A backward demand-driven symbolic analysis is used next to compute values and conditions 6 across the confluence points of the control flow graph [24]. In addition to the above 3 functions, another function called ff (array, subscript, value) <ref> [12] </ref> is used to replace the array assignment statement. The semantics of the ff function is that a part of the array will take the value for the specified subscript while the rest of the array will remain as before. This representation maintains the single assignment property for the arrays.
Reference: [13] <author> A. Agarwal et al. </author> <title> The MIT Alewife Machine: A Large-Scale Distributed-Memory Multi--processor. </title> <booktitle> Proceedings of Workshop on Scalable Shared Memory Multiprocessors, </booktitle> <year> 1991. </year>
Reference-contexts: On the other hand, in many research machines <ref> [13, 17, 18] </ref>, the directory-based hardware coherence protocols have been studied to enforce the cache coherence. However, those protocols require complex and expensive hardware cache/directory controllers. Several compiler-directed coherence schemes have been proposed [7, 11, 19, 20].
Reference: [14] <author> Paul Feautrier. </author> <title> Dataflow Analysis of Array and Scalar References. </title> <journal> International Journal of Parallel Programming, </journal> <volume> 20(1), </volume> <month> Feb. </month> <year> 1991. </year>
Reference-contexts: That algorithm eliminates the graph construction phase of [9], but it may overestimate the potential stale references by summarizing information from multiple control flow paths. Both algorithms treat each array as a single variable. There have been many studies on array data-flow algorithms. Feautrier <ref> [14] </ref> gave an algorithm to calculate them exactly. Pugh [23] developed some exact techniques that are substan 22 tially faster than Feautrier's.
Reference: [15] <author> Cray Research Inc. </author> <title> Cray T3D System Architecture Overview. </title> <month> Mar. </month> <year> 1993. </year>
Reference-contexts: 1 Introduction Recent MPP systems such as Cray T3D <ref> [15] </ref> and IBM SP2 are realized by powerful off-the-shelf microprocessors with on-chip caches, commodity memory modules, and low-latency high-bandwidth interconnection networks. For those machines that provide a shared memory address space, it is usually expensive to implement cache coherent shared memory using the hardware primitives provided.
Reference: [16] <author> M. S. Lam J. Torrellas and J. L. Hennessy. </author> <title> False Sharing and Spatial Locality in Multiprocessor Caches. </title> <journal> IEEE Transactions on Computers, C-43 No.6:651-663, </journal> <month> June </month> <year> 1994. </year>
Reference-contexts: On one hand, code optimizations usually decrease the frequency of private references. While private references are eliminated by register allocation and other optimizations, shared data consistency prevents existing compilers from optimizing shared data <ref> [16] </ref>. On the other hand, code generation such as address calculation will increase the frequency of private references due to spill codes. Note that both back-end compiler issues usually affect only private references.
Reference: [17] <author> J. Kuskin, D. Ofelt, M. Heinrich, and J. Heinlein et al. </author> <title> The Stanford FLASH Multiprocessor. </title> <booktitle> Proceedings of The 21st Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 302-313, </pages> <month> April 18-21, </month> <year> 1994. </year>
Reference-contexts: On the other hand, in many research machines <ref> [13, 17, 18] </ref>, the directory-based hardware coherence protocols have been studied to enforce the cache coherence. However, those protocols require complex and expensive hardware cache/directory controllers. Several compiler-directed coherence schemes have been proposed [7, 11, 19, 20].
Reference: [18] <author> D. Lenoski, J. Laudon, K. Gharachorloo, A. Gupta, and J. Hennessy. </author> <title> The Directory-Based Cache Coherence Protocol for the DASH Computer. </title> <booktitle> Proceedings of the 17th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 148-159, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: On the other hand, in many research machines <ref> [13, 17, 18] </ref>, the directory-based hardware coherence protocols have been studied to enforce the cache coherence. However, those protocols require complex and expensive hardware cache/directory controllers. Several compiler-directed coherence schemes have been proposed [7, 11, 19, 20].
Reference: [19] <author> A. Louri and H. Sung. </author> <title> A Compiler Directed Cache Coherence Scheme with Fast and Parallel Explicit Invalidation. </title> <booktitle> Proceedings of the 1992 International Conference on Parallel Processing, I, </booktitle> <address> Architecture:I-2-I-9, </address> <month> August </month> <year> 1992. </year>
Reference-contexts: On the other hand, in many research machines [13, 17, 18], the directory-based hardware coherence protocols have been studied to enforce the cache coherence. However, those protocols require complex and expensive hardware cache/directory controllers. Several compiler-directed coherence schemes have been proposed <ref> [7, 11, 19, 20] </ref>. In this approach, cache coherence is maintained locally without directory hardware, avoiding the complexity and the overhead associated with the hardware directories. <p> Several compiler-directed coherence schemes have been proposed [7, 11, 19, 20]. In this approach, cache coherence is maintained locally without directory hardware, avoiding the complexity and the overhead associated with the hardware directories. Although the performance of such schemes have been demonstrated through simulations <ref> [6, 19, 20] </ref>, most of those studies assume either perfect compile-time analysis or analytic models [1] without real compiler implementations. It is still unknown how effectively the compiler can detect potential stale references and what kind of performance can be obtained by using a real compiler.
Reference: [20] <author> S. L. Min and J.-L. Baer. </author> <title> Design and Analysis of a Scalable Cache Coherence Scheme Based on Clocks and Timestamps. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> III(1):25-44, </volume> <month> January </month> <year> 1992. </year>
Reference-contexts: On the other hand, in many research machines [13, 17, 18], the directory-based hardware coherence protocols have been studied to enforce the cache coherence. However, those protocols require complex and expensive hardware cache/directory controllers. Several compiler-directed coherence schemes have been proposed <ref> [7, 11, 19, 20] </ref>. In this approach, cache coherence is maintained locally without directory hardware, avoiding the complexity and the overhead associated with the hardware directories. <p> Several compiler-directed coherence schemes have been proposed [7, 11, 19, 20]. In this approach, cache coherence is maintained locally without directory hardware, avoiding the complexity and the overhead associated with the hardware directories. Although the performance of such schemes have been demonstrated through simulations <ref> [6, 19, 20] </ref>, most of those studies assume either perfect compile-time analysis or analytic models [1] without real compiler implementations. It is still unknown how effectively the compiler can detect potential stale references and what kind of performance can be obtained by using a real compiler.
Reference: [21] <author> D. A. Padua, R. Eigenmann, J. Hoeflinger, P. Peterson, P. Tu, S. Weatherford, and K. Faign. </author> <title> Polaris: A New-Generation Parallelizing Compiler for MPPs. In CSRD Rept. No. </title> <type> 1306. </type> <institution> Univ. of Illinois at Urbana-Champaign., </institution> <month> June, </month> <year> 1993. </year>
Reference-contexts: It is still unknown how effectively the compiler can detect potential stale references and what kind of performance can be obtained by using a real compiler. In this paper, we develop and implement a compiler algorithm on Polaris <ref> [21] </ref> parallelizing compiler to test the feasibility and the performance of a compiler scheme, which can be easily incorporated to implement cache coherence for existing MPP systems that do not have hardware directories. <p> Perfect benchmark suites [4] are chosen as our target applications. They are first parallelized by the Polaris compiler <ref> [21] </ref>. In the parallelized codes, the parallelism is expressed in terms of DOALL loops. Then, we process the parallelized source codes using both scalar and array flow analysis version of the algorithms given in section 3.
Reference: [22] <author> David K. Poulsen and Pen-Chung Yew. </author> <title> Execution-Driven Tools for Parallel Simulation of Parallel Architectures and Applications. </title> <booktitle> Proceedings Supercomputing 93, </booktitle> <pages> pages 860-869, </pages> <month> November </month> <year> 1993. </year>
Reference-contexts: Then, we process the parallelized source codes using both scalar and array flow analysis version of the algorithms given in section 3. Cache invalidate operations are inserted at the beginning of procedures and after each call site, while small procedures are selectively inlined. 18 Simulation Execution-driven simulations <ref> [22] </ref> are used to verify the compiler algorithms and to determine the performance of the stale reference detection. All the simulations assume a 16-processor, distributed shared-memory architecture similar to Cray T3D. Each processor contains a 64-KB direct-mapped cache with 4-word cache lines.
Reference: [23] <author> William Pugh and David Wonnacott. </author> <title> An Evaluation of Exact Methods for Analysis of Value-based Array Data Dependences. </title> <booktitle> Sixth Annual Workshop on Programming Languages and Compilers for Parallel Computing, </booktitle> <month> August </month> <year> 1993. </year> <month> 25 </month>
Reference-contexts: Both algorithms treat each array as a single variable. There have been many studies on array data-flow algorithms. Feautrier [14] gave an algorithm to calculate them exactly. Pugh <ref> [23] </ref> developed some exact techniques that are substan 22 tially faster than Feautrier's.
Reference: [24] <author> Peng Tu. </author> <title> Automatic Array Privatization and Demand-Driven Symbolic Analysis. </title> <type> Technical report, </type> <institution> Univ. of Illinois at Urbana-Champaign, Dept. of Computer Science, </institution> <year> 1995. </year> <type> Ph.D. Thesis. </type>
Reference-contexts: Such propagation will terminate at the confluence points of the control flow graph. To propagate information across the confluence points, we use a second technique, a gated single assignment (GSA) form [3] to determine the relationship between symbolic expressions when their values depend on the 1 branch conditions <ref> [24] </ref>. Two key analysis techniques are used to identify potential stale references: (1) stale reference pattern detection, and (2) locality preserving analysis. The stale reference detection algorithm finds memory reference sequences that may violate cache coherence by using a def-use chain analysis. <p> Section 6 concludes the paper. 2 A framework for array data-flow analysis In our analysis, we identify the region of an array that are referenced by each array reference and treat it as a distinct variable. The data values to be analyzed include scalar variable, subscripted variable, and subarray <ref> [24] </ref>. A subscripted variable consists of an array identifier and a subscript expression, representing a single array element referenced. A subarray consists of a subscripted variable and one or more ranges for some of the indices in its subscript expression. <p> In the global symbolic forward substitution, information is propagated until it terminates at the confluence points in the control flow graph. A backward demand-driven symbolic analysis is used next to compute values and conditions 6 across the confluence points of the control flow graph <ref> [24] </ref>. In addition to the above 3 functions, another function called ff (array, subscript, value) [12] is used to replace the array assignment statement.
Reference: [25] <author> A. V. Veidenbaum. </author> <title> A Compiler-Assisted Cache Coherence Solution for Multiprocessors. </title> <booktitle> Proceedings of the 1986 International Conference on Parallel Processing, </booktitle> <pages> pages 1029-1035, </pages> <month> August </month> <year> 1986. </year>
Reference-contexts: Execution-driven simulations are used to verify the compiler marking and to demonstrate the performance of stale reference detection. 1.1 Stale reference condition Memory event ordering Let's first define the ordering of events which leads to a stale reference. The following sequence of events <ref> [25] </ref> creates a stale reference at runtime: (1) Processor P i reads or writes to a memory location x at time T a ; (2) Another processor P j (j 6= i) writes to x later at time T b (&gt; T a ); (3) Processor P i reads the copy <p> Otherwise, there are dependences among concurrent tasks. To detect stale data reference from a source program, the previous 1 The region can be a parallel loop or an entire procedure in our analysis. 2 compiler algorithms <ref> [25, 9, 11] </ref> look for the following memory reference patterns that consist of (a) a read or a write, (b) one or more epoch boundaries, (c) a write, (d) one or more epoch boundaries, and (e) a read.
Reference: [26] <author> Michael E. Wolf. </author> <title> Improving Locality and Parallelism in Nested Loops. </title> <type> Technical report, </type> <institution> Stanford University, Dept. of Computer Science, </institution> <month> August </month> <year> 1992. </year> <type> Ph.D. Thesis. </type>
Reference-contexts: The algorithm is based on a new condition for a stale access. It considers implicit RAW (read-after-write) and WAW (write-after-write) dependences caused by multi-word cache lines (see section 1.1). To further refine reference marking, two locality preserving analysis techniques are used to exploit both temporal and spatial reuses <ref> [26] </ref> in a program. To refine reference marking for both group temporal and spatial reuses, we mark the initial occurrence of upwardly-exposed uses in a program region 1 for potential stale data references. <p> Since each potential stale reference implies a remote memory access instead of a cache hit, we should minimize the number of potential stale references marked at compile time by utilizing both the temporal and spatial locality in a program as much as possible. Wolf <ref> [26] </ref> discussed 4 different types of reuses in a loop as shown in Table 7. Note that the self reuses are inherently loop-specific while group reuses are not.
References-found: 26

