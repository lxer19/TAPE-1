URL: ftp://ftp.imag.fr/pub/CALCUL_FORMEL/RAPPORT/1996/RT157-a.ps.gz
Refering-URL: http://www-lmc.imag.fr/CF/publi.html
Root-URL: http://www.imag.fr
Title: RAPPORT TECHNIQUE Some algorithms for matrix polynomials  
Author: G. Villard 
Note: RT157 Part 1 Mars 96  
Abstract-found: 0
Intro-found: 1
Reference: 1. <author> D. Augot and P. Camion. </author> <title> The minimal polynomials, characteristic subspaces, normal bases and the Frobenius form. </title> <type> Technical Report 2006, </type> <institution> INRIA France, </institution> <month> August </month> <year> 1993. </year>
Reference-contexts: This fact shows us that provided a factorization of the characteristic polynomial is known, B can be brought into a corresponding special form. This approach is used in <ref> [1] </ref> for sequential algorithms over finite fields using an irreducible decomposition of the characteristic polynomial. But it is not clear that these algorithms can lead to fast parallel ones and it may be hard to factor fast in parallel. <p> Let us compute the last vectors of the chains of length kp ff ; again, the longest chains with kp ff = k m p ff = will be particular cases. The ends of chain are columns of E k = B <ref> [1] </ref> (x)N kp ff (x)M kp ff (x): It is sufficient to prove the claim of the lemma respectively for the three matrices of the above right-hand term. First consider B [1] (x). <p> The ends of chain are columns of E k = B <ref> [1] </ref> (x)N kp ff (x)M kp ff (x): It is sufficient to prove the claim of the lemma respectively for the three matrices of the above right-hand term. First consider B [1] (x). We view it as a matrix polynomial (of degree d 1 if the minimum polynomial (x) is of degree d): B [1] (x) = (B fl (x)) [1] = (x d1 ) [1] + B d2 (x d2 ) [1] + : : : + B 1 d1 x <p> First consider B <ref> [1] </ref> (x). We view it as a matrix polynomial (of degree d 1 if the minimum polynomial (x) is of degree d): B [1] (x) = (B fl (x)) [1] = (x d1 ) [1] + B d2 (x d2 ) [1] + : : : + B 1 d1 x d + C 1 (6) But since K is of characteristic p, C 1 j = C j is equal to zero if <p> First consider B <ref> [1] </ref> (x). We view it as a matrix polynomial (of degree d 1 if the minimum polynomial (x) is of degree d): B [1] (x) = (B fl (x)) [1] = (x d1 ) [1] + B d2 (x d2 ) [1] + : : : + B 1 d1 x d + C 1 (6) But since K is of characteristic p, C 1 j = C j is equal to zero if j 6= k 0 p ff <p> First consider B <ref> [1] </ref> (x). We view it as a matrix polynomial (of degree d 1 if the minimum polynomial (x) is of degree d): B [1] (x) = (B fl (x)) [1] = (x d1 ) [1] + B d2 (x d2 ) [1] + : : : + B 1 d1 x d + C 1 (6) But since K is of characteristic p, C 1 j = C j is equal to zero if j 6= k 0 p ff 1 for some integer k <p> First consider B <ref> [1] </ref> (x). We view it as a matrix polynomial (of degree d 1 if the minimum polynomial (x) is of degree d): B [1] (x) = (B fl (x)) [1] = (x d1 ) [1] + B d2 (x d2 ) [1] + : : : + B 1 d1 x d + C 1 (6) But since K is of characteristic p, C 1 j = C j is equal to zero if j 6= k 0 p ff 1 for some integer k 0 .
Reference: 2. <author> D. Bini and V. Pan. </author> <title> Polynomial and matrix computations. </title> <publisher> Birkhauser, </publisher> <year> 1994. </year>
Reference-contexts: The transformation ~ P is obtained using lemmata 3.1 and 3.3. It remains to compute the power sums. In the regular case, the sums with multiplicities are computed by Newton's identities as shown in <ref> [2] </ref>. For the general case, one can first search for the greatest exponent fi to apply lemma 3.2. This clearly be done in O (log n) polynomial divisions between the O i (x)'s having the same roots but with different multiplicities.
Reference: 3. <author> A. Borodin, J. von zur Gathen, and J. Hopcroft. </author> <title> Fast parallel matrix and gcd computations. </title> <journal> Information and Control, </journal> <volume> 52 </volume> <pages> 241-256, </pages> <year> 1982. </year>
Reference-contexts: These latter factors can be chosen polynomials in x p ff as fl i is. This yields a matrix M kp ff (x) that satifies the claimed property. Finally, for N kp ff (x). The nullspace of a matrix can be obtained <ref> [3] </ref> by computing a maximal linearly independent set of columns, then a maximal linearly independent set of rows and by inverting the corresponding submatrix. <p> This consists in computing the Hermite normal form H u (x) of U oe;o (in N C 2 K from [13,27]) and to compute Bezout's indentities between the diagonal entries of H u (x) and the diagonal entries of S (x) (using the algorithm in <ref> [3] </ref>).
Reference: 4. <author> S.A. Cook. </author> <title> A taxonomy of problems with fast parallel algorithms. </title> <journal> Inf. Control, </journal> <volume> 64 </volume> <pages> 2-22, </pages> <year> 1985. </year>
Reference-contexts: From a practical point of view, fast sequential and parallel algorithms are known to compute the normal forms themselves. The problems of computing the Frobenius and the Smith form are in class P (sequential polynomial-time problems) and in classes N C K and N C. We refer to <ref> [4] </ref> for the definitions of the boolean parallel complexity class N C and to [8] for the arithmetic parallel complexity class N C K . Concerning the computation of transformations for the forms, the problems were not so well overcomed.
Reference: 5. <author> M.A. Frumkin. </author> <title> Polynomial time algorithms in the theory of linear diophantine equations. </title> <booktitle> In Fundamentals of Computation Theory, </booktitle> <pages> pages 386-392. </pages> <publisher> LNCS 56, Springer, </publisher> <address> New-York, </address> <year> 1977. </year>
Reference: 6. <author> F.R. Gantmacher. </author> <title> Theorie des matrices. </title> <address> Dunod, Paris, France, </address> <year> 1966. </year>
Reference-contexts: All the above algorithms are sequential elimination processes that can be randomized to give fast sequential and parallel solutions. A different approach has been only recently used for algorithmic purposes. It is based on the following theorem about characteristic subspaces of a matrix <ref> [6] </ref>. Theorem 1.3 Let B a n fi n matrix with entries in K and let O (x) be its characteristic polynomial. <p> Each Jordan block of dimension k of J is associated to k columns in L, the corresponding vectors form a so called Jordan chain of length k <ref> [6] </ref>. <p> The following classical results are derived from <ref> [6] </ref>. Let B fl (x) denote the reduced adjoint matrix of x B: (x B) 1 = B fl (x)= (x) where (x) is the minimum polynomial of B. <p> Over the rationals or finite fields the problem is in N C 2 . Proof. We refer to <ref> [6] </ref> for this construction. Let [j 1 ; j 2 ; : : : ; j k ] be k consecutive columns of a Jordan block J k ( i ) of dimension k of J . <p> Then we will see that symbolically the transformation matrix can be computed as announced. 11 If the successive transforms of the adjoint B fl (x), using (2) entry-wise, are denoted by B [k] : we know <ref> [6] </ref> that (B i I)B [0] ( i ) = 0; (B i I)B [i] ( i ) = B [i1] ( i ); 2 i k: (5) We denote by the length of the longest Jordan chain associated to i . <p> From (5) the last n r k+1 columns of B [k] ( i )N k ( i ) are eigenvectors. They belong to chains of lengths greater than k <ref> [6] </ref>. Now, we isolate the one belonging to chains of length k exactly. If r k denotes the rank of B [k] , they are r k 2r k+1 such eigenvectors. <p> The set of the chains constructed this way for all lengths k, 1 k n and all eigenvalues i , 1 i l, give the columns of a transformation matrix from B to its Jordan form <ref> [6] </ref>. For k = , the computation is a particular case of the above construction. The eigenvectors are directly found to form a maximal linearly independent set of columns of B [0] (x) = (B fl (x)) [0] = B fl (x).
Reference: 7. <author> J. von zur Gathen. </author> <title> Parallel algorithms for algebraic problems. </title> <journal> SIAM J. Comp., </journal> <volume> 13(4) </volume> <pages> 802-824, </pages> <year> 1984. </year>
Reference-contexts: To construct the Jordan chains giving the columns of L, one can take, up to constants 1=k!, certain linear combinations of the column vectors of the successive derivatives of B fl (x). To ensure the algorithm works over any field, as done in <ref> [7] </ref> for the squarefree decomposition, we define: (x n ) [k] = C k By linearity, this gives a mapping K [x] ! K [x] such that for any polynomial a (x), (a (x)) [k] = k! dx k ; k! 6= 0: (2) Lemma 3.1 For each B in M
Reference: 8. <author> J. von zur Gathen. </author> <title> Parallel arithmetic computations: a survey. </title> <booktitle> In Proc. 12th Int. Symp. Math. Found. Comput. Sci., </booktitle> <pages> pages 93-112. </pages> <publisher> LNCS 233, Springer Verlag, </publisher> <year> 1986. </year>
Reference-contexts: The problems of computing the Frobenius and the Smith form are in class P (sequential polynomial-time problems) and in classes N C K and N C. We refer to [4] for the definitions of the boolean parallel complexity class N C and to <ref> [8] </ref> for the arithmetic parallel complexity class N C K . Concerning the computation of transformations for the forms, the problems were not so well overcomed. <p> For any commutative field K, the problem can be solved in a polynomial number of operations in K. 26 Conclusion As pointed out by von zur Gathen <ref> [8] </ref>, complexity studies aim at understanding how the solutions of problems depends on the ground field; from this point of view the most satisfactory methods do not depend on the field at all.
Reference: 9. <author> T. Gautier. </author> <title> Calcul formel et parallelisme : conception du systeme Givaro et applications au calcul dans les extensions algebriques. </title> <type> PhD thesis, </type> <institution> INPG, Grenoble, France, </institution> <year> 1996. </year>
Reference-contexts: Proof. Up to the time complexity, this is theorem 7 of [23]. As shown there, the property on the fl i (x)'s is satified by computing a gcd-free basis. Using the algorithm in <ref> [9] </ref> this is done in O (log 2 n) arithmetic or boolean steps using polynomially many processors. 2 3 A transformation for the Frobenius form From the previous theorem concerning the Jordan form, we are going to develop an algorithm to compute a transformation P for the Frobenius form.
Reference: 10. <author> M. Giesbrecht. </author> <title> Nearly optimal algorithms for canonical matrix forms. </title> <journal> SIAM Journal on Computing, </journal> <note> 1994. To appear. </note>
Reference-contexts: The n steps of the elimination process can be avoided by randomization to give Monte-Carlo or Las Vegas algorithms. The key idea used in [21,10] is that a random construction of a transformation matrix leads with high probability to the form. This approach gives fast parallel probabilistic algorithms <ref> [10] </ref>. Algorithms to compute the Smith normal form has been first given for matrices of integers. Computing the diagonalization by repeated triangularizations of the matrix and of its transpose leads to polynomial-time algorithms [5,16].
Reference: 11. <author> T. Gomez-Diaz. </author> <type> Quelques applications de l'evaluation dynamique . PhD thesis, </type> <institution> Univer-site de Limoges, France, </institution> <year> 1994. </year>
Reference-contexts: But it is not clear that these algorithms can lead to fast parallel ones and it may be hard to factor fast in parallel. The approach can also be used to develop fast algorithms over any fields as it has been simultaneously shown in <ref> [11] </ref> in sequential and in [23,25] for parallel aspects. Introducing the linear factors x i , 1 i l, of O (x) and using an arithmetic on algebraic numbers, the Jordan, the Frobenius and the Smith normal forms can be computed fast in parallel in a deterministic way.
Reference: 12. <author> N. Jacobson. </author> <title> Basic Algebra I. W.H. </title> <publisher> Freeman and Company, </publisher> <year> 1974. </year>
Reference-contexts: For the theoretical aspects the reader may refer to [18,6]. The forms are well understood if considered as giving informations about a module decomposition <ref> [12] </ref>. From a practical point of view, fast sequential and parallel algorithms are known to compute the normal forms themselves. The problems of computing the Frobenius and the Smith form are in class P (sequential polynomial-time problems) and in classes N C K and N C. <p> This will be proven using Newton's identities <ref> [12] </ref> over any fields. The only complication requiring some extra care will concern computations over fields of characteristic p, p &gt; 0. Lemma 3.2 Let K be a field of characteristic p, p &gt; 0. <p> They can be computed as k = k =q where the k 's are the power sums of the zeros of O (x) (themselves obtained by Newton's identities <ref> [12] </ref>). And, as claimed, P is a matrix in M n;n (K): P ij = p ij + p ij 1 + : : : + p ij n1 2 K: (12) Secondly, if the division by q is not allowed. We are going to use lemma 3.2. <p> Our approach is an extension of the one in [20] for computing normal forms of ma trices. In this latter paper, following the classical approach <ref> [12] </ref>, the author computes transformations for the Frobenius normal form of a constant matrix, from transformations for the Smith normal form of an associated polynomial matrix. <p> Equivalently, let the entries of the last oe columns of U 1 (x) be denoted by u (j) i (x), 1 j oe and 1 i o , then <ref> [12] </ref> oe cyclic vectors P j to build P are given by: P j = u 1 (x)c 1 + : : : + u (j) o ; 1 j oe: (21) These relations can be easily used to compute a transformation P for the Frobenius form, once a transformation U
Reference: 13. <author> E. Kaltofen, M.S. Krishnamoorthy, and B.D. Saunders. </author> <title> Fast parallel computation of Hermite and Smith forms of polynomials matrices. </title> <journal> SIAM J. Alg. Disc. Meth., </journal> <volume> 8 4, </volume> <pages> pp 683-690, </pages> <year> 1987. </year>
Reference-contexts: The first polynomial-time algorithm to compute the Smith form over Q [x] appeared in <ref> [13] </ref>, it is based on the Chinese remainder algorithm. Then it has been established in [26] that the form 6 and associated unimodular transformations can be computed over any ring K [x], with coefficient lengths remaining polynomially bounded over Q [x].
Reference: 14. <author> E. Kaltofen, M.S. Krishnamoorthy, and B.D. Saunders. </author> <title> Parallel algorithms for matrix normal forms. </title> <journal> Linear Algebra and its Applications, </journal> <volume> 136 </volume> <pages> 189-208, </pages> <year> 1990. </year>
Reference-contexts: The Hermite normal form has been originally developed for square matrices [18], it is triangular and unique if the matrix is nonsingular. We are going to follow a treatment found in <ref> [14] </ref> giving the canonical form for right or left equivalence of arbitrary matrices over a principal ideal domain. For arbitrary rectangle matrices, only an echelon form can be obtained, by extension we will also call it Hermite normal form.
Reference: 15. <author> R. Kannan. </author> <title> Solving systems of linear equations over polynomials. </title> <journal> Theoretical Computer Science, </journal> <volume> 39 </volume> <pages> 69-88, </pages> <year> 1985. </year>
Reference-contexts: Algorithms to compute the Smith normal form has been first given for matrices of integers. Computing the diagonalization by repeated triangularizations of the matrix and of its transpose leads to polynomial-time algorithms [5,16]. The same approach has been proposed for polynomial matrices <ref> [15] </ref>; this bounds the degrees of the polynomials involved during the calculations, but seems to be inadequate to bound the coefficients of those polynomials in particular over the rational polynomials.
Reference: 16. <author> R. Kannan and A. Bachem. </author> <title> Polynomial algorithms for computing the Smith and Hermite normal forms of an integer matrix. </title> <journal> SIAM J. Comput., </journal> <volume> 8 4, </volume> <pages> pp 499-507, </pages> <year> 1979. </year>
Reference: 17. <author> H. Luneburg. </author> <title> On rational form of endomorphims : a primer to constructive algebra. </title> <booktitle> Wissenschaftsverlag, Mannheim, </booktitle> <year> 1987. </year>
Reference-contexts: This unique form F is called the Frobenius normal form of B. 1.2 Previous algorithms and limitations We overview the known methods and algorithms before introducing our new approach. The first polynomial-time algorithms to compute the Frobenius form has been independently proposed in <ref> [17] </ref> and in [22]. They are polynomial-time in the dimension of the matrix, and also in the coefficient lengths for concrete fields such as the field of the field of the rationals Q or GF q , the finite field with q elements.
Reference: 18. <author> C.C. MacDuffee. </author> <title> The theory of matrices. </title> <publisher> Chelsea, </publisher> <address> New-York, </address> <year> 1956. </year> <month> 27 </month>
Reference-contexts: A (x) = U (x)A 0 (x)). If A (x) = U (x)A 0 (x)V (x) then A (x) and A 0 (x) are said to be equivalent. The Hermite normal form has been originally developed for square matrices <ref> [18] </ref>, it is triangular and unique if the matrix is nonsingular. We are going to follow a treatment found in [14] giving the canonical form for right or left equivalence of arbitrary matrices over a principal ideal domain. <p> Proof. The matrices U (x) and S (x) are left coprime, there exist <ref> [18] </ref> two matrices X (x) and Y (x) such that: U (x)X (x) + S (x)Y (x) = I o : (25) We are going to prove the result in two steps.
Reference: 19. <author> K. Martin and J.M. Olazabal. </author> <title> An algorithm to compute the change basis for the rational form of K-endomorphisms. </title> <journal> Extracta Mathematicae, </journal> <volume> 6 </volume> <pages> 89-91, </pages> <year> 1992. </year>
Reference-contexts: These algorithms consist in elimination processes and are consequently highly sequential. They can be adjusted to compute an associated transformation matrix over K even for small fields <ref> [19] </ref>. The n steps of the elimination process can be avoided by randomization to give Monte-Carlo or Las Vegas algorithms. The key idea used in [21,10] is that a random construction of a transformation matrix leads with high probability to the form. This approach gives fast parallel probabilistic algorithms [10].
Reference: 20. <author> T. Mulders. </author> <title> Computation of normal forms for matrices. </title> <booktitle> In Algoritmen In De Algebra, A Seminar on Algebraic Algorithms, </booktitle> <year> 1993. </year> <institution> University of Nijmegen, Netherlands. </institution>
Reference-contexts: This will lead, at x5, to a reduction of the latter problem to the former and, at x6, to an algorithm based on this reduction and on theorem 3.2. Our approach is an extension of the one in <ref> [20] </ref> for computing normal forms of ma trices. In this latter paper, following the classical approach [12], the author computes transformations for the Frobenius normal form of a constant matrix, from transformations for the Smith normal form of an associated polynomial matrix. <p> This has been used in <ref> [20] </ref>.
Reference: 21. <author> P. Ozello. </author> <title> A probalistic algorithm to compute the Frobenius form of a matrix. </title> <type> Technical Report RR 653M, </type> <institution> IMAG, Grenoble, France, </institution> <month> March </month> <year> 1987. </year>
Reference: 22. <author> P. Ozello. </author> <title> Calcul exact des formes de Jordan et de Frobenius d'une matrice. </title> <type> PhD thesis, </type> <institution> Universite Scientifique et Medicale de Grenoble, France, </institution> <year> 1987. </year>
Reference-contexts: This unique form F is called the Frobenius normal form of B. 1.2 Previous algorithms and limitations We overview the known methods and algorithms before introducing our new approach. The first polynomial-time algorithms to compute the Frobenius form has been independently proposed in [17] and in <ref> [22] </ref>. They are polynomial-time in the dimension of the matrix, and also in the coefficient lengths for concrete fields such as the field of the field of the rationals Q or GF q , the finite field with q elements.
Reference: 23. <author> J.L. Roch and G. Villard. </author> <title> Parallel computations with algebraic numbers, a case study: Jordan normal form of matrices. </title> <booktitle> In Parallel Architectures and Languages Europe 94, </booktitle> <address> Athens Greece, </address> <publisher> LNCS 817, </publisher> <month> July </month> <year> 1994. </year>
Reference-contexts: This form is called the Jordan form of B. From <ref> [23] </ref> we know that the form can be computed fast in parallel. <p> The indeterminates are associated to generalized eigenvalues, fl i (x), that are equal if and only if the corresponding eigenvalues have the same Jordan structure and are relatively prime otherwise. Proof. Up to the time complexity, this is theorem 7 of <ref> [23] </ref>. As shown there, the property on the fl i (x)'s is satified by computing a gcd-free basis. <p> The two other indeterminates ~ 3 and ~ 4 each give one column in L, they are associated to a unique generalized eigenvalue fl 3;4 (x). 2 As a corollary of theorem 2.2, using nullspace computations over algebraic numbers <ref> [23] </ref>, an associated transformation matrix represented by a matrix L ( ~ 1 ; : : : ; ~ l ) in M n;n (K [ ~ 1 ; : : : ; ~ l ]) can also be computed. The following classical results are derived from [6]. <p> We may thus apply directly a parallel arithmetic on algebraic numbers as introduced in <ref> [23] </ref>. The eigenvalues are represented as polynomials in K [x]=(fl i (x)). The matrices B [k] (x) given by (4) are computed in parallel modulo fl i (x). Then we apply proposition 4 in [23] (for maximal linearly independent set of columns and nullspace computation over algebraic numbers) to compute N <p> We may thus apply directly a parallel arithmetic on algebraic numbers as introduced in <ref> [23] </ref>. The eigenvalues are represented as polynomials in K [x]=(fl i (x)). The matrices B [k] (x) given by (4) are computed in parallel modulo fl i (x). Then we apply proposition 4 in [23] (for maximal linearly independent set of columns and nullspace computation over algebraic numbers) to compute N k (x) and M k (x), with the understanding that ~ N k (x) is a suitable matrix for all the roots of fl i (x). <p> For all the roots of a given generalized eigenvalue, the entries of the vectors of the associated chains are polynomials with the same coefficients since this true by construction <ref> [23] </ref> for the matrices N k (x) and M k (x). The matrix L ( ~ 1 ; : : : ; ~ l ) has been computed conformable to the Jordan 12 form. <p> The matrix L ( ~ 1 ; : : : ; ~ l ) has been computed conformable to the Jordan 12 form. Finally, the announced complexity is valid since it holds for matrix product, for a maximal linearly independent set of columns and for the nullspace <ref> [23] </ref>. 2 We give a complement to this lemma that will be useful to show that the target transformation P = LM will be actually computed over K (theorem 3.2). This will be proven using Newton's identities [12] over any fields. <p> Indeed, even if the rank of B is the same for all the roots, the choice of the columns may depend on them. We refer to <ref> [23] </ref> for a satifying solution that consists in weighting the columns by suitable factors of the generalized eigenvalue. These latter factors can be chosen polynomials in x p ff as fl i is. This yields a matrix M kp ff (x) that satifies the claimed property.
Reference: 24. <author> A. Storjohann. </author> <title> Computation of Hermite and Smith normal forms of matrices. </title> <type> Master's thesis, </type> <institution> 1994. University of Waterloo, Canada. </institution>
Reference: 25. <author> G. Villard. </author> <title> Fast parallel computation of the Smith normal form of polynomial matrices. </title> <booktitle> In International Symposium on Symbolic and Algebraic Computation, </booktitle> <publisher> Oxford, UK, </publisher> <pages> pages 312 - 317. </pages> <publisher> ACM Press, </publisher> <month> July </month> <year> 1994. </year>
Reference-contexts: Even though this is probably easy if K is such that polynomial factorization is in N C K . We will need the following result of <ref> [25] </ref> to compute the form itself. Theorem 3.1 The problem of computing the Frobenius normal form F in M n;n (K) of a matrix B in M n;n (K) is in N C 2 K .
Reference: 26. <author> G. Villard. </author> <title> Generalized subresultants for computing the Smith normal form of polynomial matrices. </title> <journal> Journal of Symbolic Computation, </journal> <volume> 20 </volume> <pages> 269-286, </pages> <year> 1995. </year>
Reference-contexts: The first polynomial-time algorithm to compute the Smith form over Q [x] appeared in [13], it is based on the Chinese remainder algorithm. Then it has been established in <ref> [26] </ref> that the form 6 and associated unimodular transformations can be computed over any ring K [x], with coefficient lengths remaining polynomially bounded over Q [x].
Reference: 27. <author> G. Villard. </author> <title> Computing Popov and Hermite forms of polynomial matrices. </title> <booktitle> In International Symposium on Symbolic and Algebraic Computation, </booktitle> <address> Zurich, Suisse. </address> <publisher> ACM Press, </publisher> <month> July </month> <year> 1996. </year>

References-found: 27

