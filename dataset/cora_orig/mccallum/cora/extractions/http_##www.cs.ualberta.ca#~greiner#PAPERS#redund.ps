URL: http://www.cs.ualberta.ca/~greiner/PAPERS/redund.ps
Refering-URL: http://www.cs.ualberta.ca/~greiner/PAPERS/
Root-URL: 
Title: Finding Optimal Derivation Strategies in Redundant Knowledge Bases  
Author: Russell Greiner 
Date: August 14, 1990  
Address: Toronto, Ontario M5S 1A4  
Affiliation: Department of Computer Science University of Toronto  
Abstract: A backward chaining process uses a collection of rules to reduce a given goal to a sequence of data-base retrievals. A "derivation strategy" is an ordering on these steps, specifying when to use each rule and when to perform each retrieval. Given the costs of reductions and retrievals, and the a priori likelihood that each particular retrieval will succeed, one can compute the expected cost of any strategy, for answering a specific query from a given knowledge base. [Smi89] presents an algorithm that finds the minimal cost strategy in time (essentially) linear in the number of rules, for any disjunctive, irredundant knowledge base. This paper proves that the addition of redundancies renders this task NP-hard. Many Explanation-Based Learning systems work by adding in redundancies; this shows the complexities inherent in their task.
Abstract-found: 1
Intro-found: 1
Reference: [BJY89] <author> Danilo Bruschi, Deborah Joseph, and Paul Young. </author> <title> A structural overview of np optimization problems. </title> <booktitle> In Proceedings of the Second International Symposium on Optimal Algorithms. Springer-Verlag Lecture Notes in Computer Science, </booktitle> <year> 1989. </year>
Reference-contexts: One involves coping with the OptDS task's inherent intractability by seeking efficient algorithms that return "approximately optimal" derivation strategies. [GO90] begins to address this task; see also <ref> [BJY89] </ref>. Another direction is to apply this same form of analysis to more general situations. The first obvious arena is handling conjunctive and recursive knowledge bases. Another is to combine this approach with other control strategy mechanisms | including conjunct ordering [SG85] and forward chaining [TG87].
Reference: [Cho90] <author> Cindy Chow. </author> <title> Obtaining an efficient derivational strategies for a conjunctive search space. </title> <type> Master's thesis, </type> <institution> University of Toronto, </institution> <year> 1990. </year>
Reference-contexts: the probability that a rule may fail to reduce a goal to a subgoal, due to constants appearing in the rules; see [Lik88] and [Smi89]. (2) This note assumes that we know, a priori, the probability that each retrieval will succeed, and is not concerned with how they were obtained. <ref> [Smi89, Lik88, Cho90] </ref> present one way of estimating these values, based on the distribution of assertions present in the knowledge base; [GO90] presents a different model. 3 Guardian ( fl) R gp P g = 0:01 Parent ( fl) Father ( fl) L f L p P P P P P
Reference: [DM86] <author> Gerald DeJong and Raymond Mooney. </author> <title> Explanation-based learning: An alternative view. </title> <journal> Machine Learning, </journal> <volume> 1(2) </volume> <pages> 145-76, </pages> <year> 1986. </year>
Reference-contexts: Furthermore, this rule is placed first: the "improved" system will try this new rule first in subsequent queries, before the other rules are attempted. This is the basis for the recent Explanation-Based Learning (EBL) systems <ref> [MKKC86, DM86] </ref>, as well as Chunking [Ros83, RN82, LNR86] and MacroOps [FHN72]. A major objective of these learning systems is efficiency: to improve the overall future performance of the system.
Reference: [FHN72] <author> Richard Fikes, Peter E. Hart, and Nils J. Nilsson. </author> <title> Learning and executing generalized robot plans. </title> <journal> Artificial Intelligence: An International Journal, </journal> <volume> 3 </volume> <pages> 251-288, </pages> <month> July </month> <year> 1972. </year>
Reference-contexts: Furthermore, this rule is placed first: the "improved" system will try this new rule first in subsequent queries, before the other rules are attempted. This is the basis for the recent Explanation-Based Learning (EBL) systems [MKKC86, DM86], as well as Chunking [Ros83, RN82, LNR86] and MacroOps <ref> [FHN72] </ref>. A major objective of these learning systems is efficiency: to improve the overall future performance of the system.
Reference: [GJ79] <author> Michael R. Garey and David S. Johnson. </author> <title> Computers and Intractability: A Guide to the Theory of NP-Completeness. </title> <editor> W. H. </editor> <publisher> Freeman and Company, </publisher> <address> New York, </address> <year> 1979. </year>
Reference-contexts: To show that OptDS is NP-hard, we reduce the NP-complete "Exact Covering" task <ref> [GJ79] </ref> to it. 7 Definition 3.7 (EC Decision Problem) INSTANCE: A collection of sets, C = f c i g i .
Reference: [GN87] <author> Michael R. Genesereth and Nils J. Nilsson. </author> <booktitle> Logical Foundations of Artificial Intelligence. </booktitle> <publisher> Morgan Kaufmann Publishers, Inc., </publisher> <address> Los Altos, CA, </address> <year> 1987. </year> <month> 15 </month>
Reference-contexts: potential "solution paths" for a given query | as there can be many rules (a.k.a. operators) that each reduce the goal to a new set of subgoals, and each of these subgoals can, itself, have many possible reductions, etc.; ultimately "bottoming out" with a sequence of data base retrievals. (See <ref> [GN87] </ref>.) There are several ways of addressing this combinatorial complexity. One involves ordering the set of rules, so the first rule selected for a given (sub)goal is the one viewed as most cost effective.
Reference: [GO90] <author> Russell Greiner and Pekka Orponen. </author> <title> Probably approximately optimal satisficing strat-egy. </title> <type> Technical Report KRR-90-1, </type> <institution> University of Toronto, </institution> <year> 1990. </year>
Reference-contexts: see [Lik88] and [Smi89]. (2) This note assumes that we know, a priori, the probability that each retrieval will succeed, and is not concerned with how they were obtained. [Smi89, Lik88, Cho90] present one way of estimating these values, based on the distribution of assertions present in the knowledge base; <ref> [GO90] </ref> presents a different model. 3 Guardian ( fl) R gp P g = 0:01 Parent ( fl) Father ( fl) L f L p P P P P P P P P P Mother ( fl) L m R xy = reduction step L y = lookup step 2 = <p> One involves coping with the OptDS task's inherent intractability by seeking efficient algorithms that return "approximately optimal" derivation strategies. <ref> [GO90] </ref> begins to address this task; see also [BJY89]. Another direction is to apply this same form of analysis to more general situations. The first obvious arena is handling conjunctive and recursive knowledge bases. <p> on the "probability values" associated with each retrieval. [Smi89] uses the distribution of propositions in the knowledge base as an estimate for these values; another approach involves 14 extrapolating these values from a set of observations, each of the form "query involved database fact t " for some t (see <ref> [GO90] </ref>). 4.3 Results This research was motivated by the goal of evaluating the standard Explanation-Based Learning task, taking seriously the view that EBL is a method for improving the future performance of a reasoning system.
Reference: [Gre89] <author> Russell Greiner. </author> <title> Finding the optimal derivation strategy in a redundant knowledge base. </title> <type> Technical Report KRR-TR-89-9, </type> <institution> University of Toronto, </institution> <month> August </month> <year> 1989. </year>
Reference-contexts: It obviously never makes sense to use a redundant S derivation strategy to solve a specific query, as there is always an irredundant S strategy that is functionally equivalent (i.e., will find an answer whenever the redundant S strategy does) and that takes strictly less time. (See <ref> [Gre89, Lemma 3.1] </ref>.) Here, fi 5 = hR gf L f R gp R pm L m L g i is such a reduced, irredundant S strategy for fi 4 . (Notice fi 5 is the subsequence of fi 4 that omits both the second L f lookup and the now <p> 1 s l i iff the conclusion of r 1 matches the conclusion of s 1 and the antecedent of r k matches the antecedent of s l (i.e., both paths lead from the same subgoal, and arrive at the same subgoal), and they share no 5 The extended paper, <ref> [Gre89] </ref>, presents yet other classes of knowledge bases in which we can efficiently find optimal derivation strategies. 7 steps in common (i.e., fr i g i " fs j g j = fg).
Reference: [Kar72] <author> Richard M. Karp. </author> <title> Reducibility among combinatorial problems. </title> <editor> In Raymond E. Miller and James W. Thatcher, editors, </editor> <booktitle> Complexity of Computer Computations, </booktitle> <pages> pages 85-103. </pages> <publisher> Plenum Press, </publisher> <address> New York, </address> <year> 1972. </year>
Reference-contexts: cost is 3L. (To see this, observe that Lemma 3.3 means that E [fi] 3L implies T [fi] E [fi] + 1 2 3L + 1 2 , meaning T [fi] 3L as 7 This proof is an extension of Karp's proof that the "Steiner Tree decision problem" is NP-hard <ref> [Kar72] </ref>. 10 G () C1 n 1 () . . . fi . . . Ci () ` ` ` ` ` ` ` ` ` ` . . .
Reference: [Lik88] <author> Joseph Likuski. </author> <title> Integrating redundant learned rules in a knowledge base. </title> <type> Master's thesis, </type> <institution> University of Toronto, </institution> <month> October </month> <year> 1988. </year>
Reference-contexts: We would then need to distinguish the different appearances of each rule. 2 (1) The expected cost can depend on other factors as well, including the probability that a rule may fail to reduce a goal to a subgoal, due to constants appearing in the rules; see <ref> [Lik88] </ref> and [Smi89]. (2) This note assumes that we know, a priori, the probability that each retrieval will succeed, and is not concerned with how they were obtained. [Smi89, Lik88, Cho90] present one way of estimating these values, based on the distribution of assertions present in the knowledge base; [GO90] presents <p> the probability that a rule may fail to reduce a goal to a subgoal, due to constants appearing in the rules; see [Lik88] and [Smi89]. (2) This note assumes that we know, a priori, the probability that each retrieval will succeed, and is not concerned with how they were obtained. <ref> [Smi89, Lik88, Cho90] </ref> present one way of estimating these values, based on the distribution of assertions present in the knowledge base; [GO90] presents a different model. 3 Guardian ( fl) R gp P g = 0:01 Parent ( fl) Father ( fl) L f L p P P P P P <p> It is easy to extend this analysis to cover this more general case in which rules may include constants; see [Smi89] and <ref> [Lik88] </ref>. 3.1 Irredundant Derivation Subspaces A derivation strategy is redundant S iff it includes the same step more than once; e.g., fi 4 = hR gf L f R gp R pm L m R pf L f L g i is redundant S as it includes L f (i.e., asks <p> This means we can immediately determine which rule to follow up from each subgoal, leading to an efficient algorithm for this class of knowledge bases. Lemma 3.1 (from <ref> [Lik88, Lemma 3.2] </ref>) Let K be an irredundant knowledge base that includes a path of rules from some query, , to the subgoal, , whose final step involves the rule R n : ) S n . Let fi 1 be the optimal strategy for from K. <p> It is trivial to show that fi 3 is a complete strategy for deriving from K 0 , as fi 1 is; and that E [fi 3 ] = E [fi 1 ]. 2 Lemma 3.2 (from <ref> [Lik88, Theorem 5.1] </ref>) Let K be a -direct-KB, whose maximal redundant P path sets are ft i g k i=1 , where each t i = ffl i j g j=1 contains fl i 1 which is a -direct rule (i.e., fl i 1 leads directly to ).
Reference: [LNR86] <author> John E. Laird, Allan Newell, and Paul S. Rosenbloom. </author> <title> Chunking in SOAR: The anatomy of a general learning mechanism. </title> <journal> Machine Learning, </journal> <volume> 1(1) </volume> <pages> 11-46, </pages> <year> 1986. </year>
Reference-contexts: Furthermore, this rule is placed first: the "improved" system will try this new rule first in subsequent queries, before the other rules are attempted. This is the basis for the recent Explanation-Based Learning (EBL) systems [MKKC86, DM86], as well as Chunking <ref> [Ros83, RN82, LNR86] </ref> and MacroOps [FHN72]. A major objective of these learning systems is efficiency: to improve the overall future performance of the system.
Reference: [Min85] <author> Steven Minton. </author> <title> Selectively generalizing plans for problem solving. </title> <booktitle> In IJCAI-85, </booktitle> <pages> pages 596-99, </pages> <address> Los Angeles, </address> <month> August </month> <year> 1985. </year>
Reference-contexts: Many systems implicitly employ the "obvious" assumption that "the future will mirror the past" | that the future questions will correspond to the questions asked until now. This suggests preserving every observed rule-sequence as a new redundant rule. Recent empirical evidence <ref> [Min85, Min88] </ref>, however, has confirmed some of the obvious problems inherent in this "save all redundant rules" approach: these new rules can slow down the overall performance of the complete system. That is, it is not always advantageous to incorporate a proposed redundant rule into an existing knowledge base.
Reference: [Min88] <author> Steven Minton. </author> <title> Quantitative results concerning the utility of explanation-based learning. </title> <booktitle> In AAAI-88, </booktitle> <pages> pages 564-69, </pages> <address> San Mateo, CA, August 1988. </address> <publisher> Morgan Kaufmann Publishers, Inc. </publisher>
Reference-contexts: Many systems implicitly employ the "obvious" assumption that "the future will mirror the past" | that the future questions will correspond to the questions asked until now. This suggests preserving every observed rule-sequence as a new redundant rule. Recent empirical evidence <ref> [Min85, Min88] </ref>, however, has confirmed some of the obvious problems inherent in this "save all redundant rules" approach: these new rules can slow down the overall performance of the complete system. That is, it is not always advantageous to incorporate a proposed redundant rule into an existing knowledge base. <p> Below are some comments about this claim: * This result only holds for disjunctive, function-free, fact-irredundant knowledge bases. In particular, it does not apply if any rule's antecedent includes more than one conjunct. (See <ref> [Min88] </ref>.) * This result applies only when the initial knowledge base is irredundant. We saw the situation is much more complicated when we consider arbitrarily redundant knowledge bases.
Reference: [MKKC86] <author> Thomas M. Mitchell, Richard M. Keller, and Smadar T. Kedar-Cabelli. </author> <title> Example-based generalization: A unifying view. </title> <journal> Machine Learning, </journal> <volume> 1(1) </volume> <pages> 47-80, </pages> <year> 1986. </year>
Reference-contexts: Furthermore, this rule is placed first: the "improved" system will try this new rule first in subsequent queries, before the other rules are attempted. This is the basis for the recent Explanation-Based Learning (EBL) systems <ref> [MKKC86, DM86] </ref>, as well as Chunking [Ros83, RN82, LNR86] and MacroOps [FHN72]. A major objective of these learning systems is efficiency: to improve the overall future performance of the system.
Reference: [RN82] <author> Paul S. Rosenbloom and Allan Newell. </author> <title> Learning by chunking: Summary of a task and a model. </title> <booktitle> In AAAI-82, </booktitle> <address> Pittsburgh, </address> <month> August </month> <year> 1982. </year>
Reference-contexts: Furthermore, this rule is placed first: the "improved" system will try this new rule first in subsequent queries, before the other rules are attempted. This is the basis for the recent Explanation-Based Learning (EBL) systems [MKKC86, DM86], as well as Chunking <ref> [Ros83, RN82, LNR86] </ref> and MacroOps [FHN72]. A major objective of these learning systems is efficiency: to improve the overall future performance of the system.
Reference: [Ros83] <author> Paul S. Rosenbloom. </author> <title> The Chunking of Goal Hierarchies: A Model of Practice and Stimulus-Response Compatibility. </title> <type> PhD thesis, </type> <institution> Carnegie-Mellon University, </institution> <month> August </month> <year> 1983. </year>
Reference-contexts: Furthermore, this rule is placed first: the "improved" system will try this new rule first in subsequent queries, before the other rules are attempted. This is the basis for the recent Explanation-Based Learning (EBL) systems [MKKC86, DM86], as well as Chunking <ref> [Ros83, RN82, LNR86] </ref> and MacroOps [FHN72]. A major objective of these learning systems is efficiency: to improve the overall future performance of the system.
Reference: [Rus85] <author> Stuart Russell. </author> <note> The Compleat Guide to MRS, June 1985. Stanford KSL Report HPP-85-12. </note>
Reference-contexts: a worse strategy, as E [fi 6 ] = 2:8r + 2:575` is always more than E [fi 3 ] = 2:75r + 2:425`. 8 This argues for a reasoning system that can guide its derivation process by selecting which rules to fire at each time | such as MRS <ref> [Rus85] </ref>. 13 (The optimal ordering for this expanded knowledge base, by the way, is fi 6a = hR gp R pm L m R gf L f L g i, when r = 1 and ` = 2.) * Section 1 mentioned two ways of improving the expected cost of a
Reference: [SG85] <author> David E. Smith and Michael R. Genesereth. </author> <title> Ordering conjunctive queries. </title> <journal> Artificial Intelligence: An International Journal, </journal> <volume> 26(2) </volume> <pages> 171-215, </pages> <month> May </month> <year> 1985. </year>
Reference-contexts: Another direction is to apply this same form of analysis to more general situations. The first obvious arena is handling conjunctive and recursive knowledge bases. Another is to combine this approach with other control strategy mechanisms | including conjunct ordering <ref> [SG85] </ref> and forward chaining [TG87]. The third is to obtain more accurate empirical values. For example, we have assumed that the costs of reductions and lookups (read "r" and "`") are uniform for any rule or proposition.
Reference: [SK75] <author> H. A. Simon and J. B. Kadane. </author> <title> Optimal problem-solving search: All-or-none solutions. </title> <journal> Artificial Intelligence: An International Journal, </journal> <volume> 6 </volume> <pages> 235-247, </pages> <year> 1975. </year>
Reference: [Smi89] <author> David E. Smith. </author> <title> Controlling backward inference. </title> <journal> Artificial Intelligence: An International Journal, </journal> <volume> 39(2) </volume> <pages> 145-208, </pages> <month> June </month> <year> 1989. </year> <note> (Also Stanford Technical Report LOGIC-86-68). </note>
Reference-contexts: Section 2 provides a formal definition of "derivation strategies", shows there can be an exponential number of them, and provides a framework for comparing different ones. It also discusses Smith's result <ref> [Smi89] </ref>, which states that this task is (essentially) linear in the number of rules for a certain class of irredundant knowledge bases. <p> We would then need to distinguish the different appearances of each rule. 2 (1) The expected cost can depend on other factors as well, including the probability that a rule may fail to reduce a goal to a subgoal, due to constants appearing in the rules; see [Lik88] and <ref> [Smi89] </ref>. (2) This note assumes that we know, a priori, the probability that each retrieval will succeed, and is not concerned with how they were obtained. [Smi89, Lik88, Cho90] present one way of estimating these values, based on the distribution of assertions present in the knowledge base; [GO90] presents a different <p> the probability that a rule may fail to reduce a goal to a subgoal, due to constants appearing in the rules; see [Lik88] and [Smi89]. (2) This note assumes that we know, a priori, the probability that each retrieval will succeed, and is not concerned with how they were obtained. <ref> [Smi89, Lik88, Cho90] </ref> present one way of estimating these values, based on the distribution of assertions present in the knowledge base; [GO90] presents a different model. 3 Guardian ( fl) R gp P g = 0:01 Parent ( fl) Father ( fl) L f L p P P P P P <p> Even for the tiny K 1 knowledge base, with n = 7, there are 13;700 different strategies, of which 6! = 720 are complete and minimal, and of these, 36 respect the "subgoal precedence order" (e.g., only perform the L f step after R pf , etc.). Smith <ref> [Smi89] </ref>, however, shows how to compute the optimal derivation strategy in a time (essentially) proportional to the number of rules, for any disjunctive, function-free, fact-irredundant, rule-irredundant knowledge base. 3 Disjunctive means that all of the rules are of the form A () ) C (); hence, it excludes rules of the <p> It is easy to extend this analysis to cover this more general case in which rules may include constants; see <ref> [Smi89] </ref> and [Lik88]. 3.1 Irredundant Derivation Subspaces A derivation strategy is redundant S iff it includes the same step more than once; e.g., fi 4 = hR gf L f R gp R pm L m R pf L f L g i is redundant S as it includes L f <p> Preliminary empirical observations show that these costs depend on the number of variables, etc. A related point is our reliance on the "probability values" associated with each retrieval. <ref> [Smi89] </ref> uses the distribution of propositions in the knowledge base as an estimate for these values; another approach involves 14 extrapolating these values from a set of observations, each of the form "query involved database fact t " for some t (see [GO90]). 4.3 Results This research was motivated by the
Reference: [TG87] <author> Richard J. Treitel and Michael R. Genesereth. </author> <title> Choosing orders for rules. </title> <journal> Journal of Automated Reasoning, </journal> <volume> 3(4) </volume> <pages> 395-432, </pages> <month> December </month> <year> 1987. </year> <month> 16 </month>
Reference-contexts: Another direction is to apply this same form of analysis to more general situations. The first obvious arena is handling conjunctive and recursive knowledge bases. Another is to combine this approach with other control strategy mechanisms | including conjunct ordering [SG85] and forward chaining <ref> [TG87] </ref>. The third is to obtain more accurate empirical values. For example, we have assumed that the costs of reductions and lookups (read "r" and "`") are uniform for any rule or proposition. Preliminary empirical observations show that these costs depend on the number of variables, etc.
References-found: 21

