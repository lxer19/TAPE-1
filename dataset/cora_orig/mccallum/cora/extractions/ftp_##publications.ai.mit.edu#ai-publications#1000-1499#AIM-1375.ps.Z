URL: ftp://publications.ai.mit.edu/ai-publications/1000-1499/AIM-1375.ps.Z
Refering-URL: http://www.ai.mit.edu/projects/cbcl/web-pis/poggio/memos.html
Root-URL: 
Title: Optical Flow from 1D Correlation: Application to a simple Time-To-Crash Detector  
Author: Nicola Ancona and Tomaso Poggio 
Note: Copyright c Massachusetts Institute of Technology, 1993  
Date: 1375 October 1993  74  
Affiliation: MASSACHUSETTS INSTITUTE OF TECHNOLOGY ARTIFICIAL INTELLIGENCE LABORATORY and CENTER FOR BIOLOGICAL AND COMPUTATIONAL LEARNING  
Pubnum: A.I. Memo No.  C.B.C.L. Paper No.  
Abstract: In the first part of this paper paper we show that a new technique exploiting 1D correlation of 2D or even 1D patches between successive frames may be sufficient to compute a satisfactory estimation of the optical flow field. The algorithm is well-suited to VLSI implementations. The sparse measurements provided by the technique can be used to compute qualitative properties of the flow for a number of different visual tasks. In particular, the second part of the paper shows how to combine our 1D correlation technique with a scheme for detecting expansion or rotation ([5]) in a simple algorithm which also suggests interesting biological implications. The algorithm provides a rough estimate of time-to-crash. It was tested on real image sequences. We show its performance and compare the results to previous approaches. This memo describes research done within the Center for Biological and Computational Learning in the Department of Brain and Cognitive Sciences, at the Artificial Intelligence Laboratory at MIT, and at the Robotic and Automation Laboratory of the Tecnopolis CSATA in Bari, Italy. This research was sponsored by grants from the Office of Naval Research under contracts N00014-91-J-1270 and N00014-92-J-1879; by grants from the National Science Foundation under contracts IRI-8719394 and 8814612-MIP; and by a grant from the National Institutes of Health under contract NIH 2-S07-RR07047. Additional support was provided by the North Atlantic Treaty Organization, Hughes Research Laboratories, ATR Audio and Visual Perception Research Laboratories, Mitsubishi Electric Corporation, Sumitomo Metal Industries, and Siemens AG. Support for the A.I. Laboratory's artificial intelligence research is provided by ONR contract N00014-91-J-4038. Tomaso Poggio is supported by the Uncas and Helen Whitaker Chair at the Whitaker College, Massachusetts Institute of Technology. Partial support was provided by the Italian PRO-ART section of PROMETHEUS. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Koch Christof, Andrew Moore, Wyeth Bair, Timothy Horiuchi, Brooks Bishofberger, and John Laz-zaro. </author> <title> Computing motion using analog vlsi vision chips: An experimental comparison among four approaches. </title> <booktitle> In IEEE Workshop on Visual Motion., </booktitle> <year> 1991. </year>
Reference-contexts: Optical flow algorithms based on patchwise correlation of filtered images perform in a satisfactory way [3] and better in practice than most other approaches (see <ref> [1] </ref>). Their main drawback is computational complexity that forbid at present useful VLSI implementations. In this paper we show that 1D patchwise correlation may provide a sufficiently accurate estimate of the optical flow 1 . <p> In all experiments the movement of the vehicle was a forward translation along a straight trajectory. We have verified the results obtained from our 1D-2D approach with the standard winner-take-all (2D-2D) scheme [3] <ref> [1] </ref>. composed of 100 frames. Each image of the sequence is first convolved with a Gaussian filter having = 0:5.
Reference: [2] <author> R. Cipolla and A. Blake. </author> <title> Surface orientation and time to contact from image divergence and deformation. </title> <booktitle> In Second European Conference on Computer Vision, </booktitle> <pages> pages 187 - 202, </pages> <address> Santa Margherita Ligure - Italy, </address> <year> 1992. </year>
Reference-contexts: We label this technique the 1D-1D scheme since it involves 1D correlations of 1D patches. 2 closed contour. Each of the elementary motion detectors could be replaced by a single detector normal to the circle. 3 A crash detector: the Green theorem scheme As described in [5] (see also <ref> [2] </ref>), the divergence of the optical field ru (x; y) is a differential measure of the local expansion (ru (x; y) = @u x (x;y) @u y (x;y) @y ). For a linear field (i.e. u (x) = Ax), the divergence of u is the same everywhere. <p> Similar considerations may apply to some of the motion selective cortical cells. 5.3 The Time-to-Crash detector The TTC detector we have simulated is not the only possible scheme. Others are possible (see for instance <ref> [2] </ref>) that take into account more complex motions than just frontal approach to a horizontal surface. It is also conceivable that the scheme we suggest may be simplified even further in certain situations.
Reference: [3] <author> J. Little, H. Bulthoff, and T. Poggio. </author> <title> Parallel optical flow using local voting. </title> <booktitle> In IEEE 2nd International Conference in Computer Vision, </booktitle> <year> 1988. </year>
Reference-contexts: In this paper we propose an efficient algorithm for computing the optical flow which performs well in a number of experiments with sequences of real images and is well suited to a VLSI implementation. Optical flow algorithms based on patchwise correlation of filtered images perform in a satisfactory way <ref> [3] </ref> and better in practice than most other approaches (see [1]). Their main drawback is computational complexity that forbid at present useful VLSI implementations. In this paper we show that 1D patchwise correlation may provide a sufficiently accurate estimate of the optical flow 1 . <p> other insects rely for landing on what appears to be a qualitative estimate of the time-to-crash! 2.1 1D correlation of 2D patches A possible approach for an approximative estimate of the optical flow is to use a 1D correlation scheme between two successive frames, instead of 2D correlation, as in <ref> [3] </ref>. The basic idea underlying the full 2D correlation technique that we label 2D-2D in this paper 2 is to measure, for each desired location, the (x; y) shift that maximizes the correlation between 2D patches centered around the desired location in successive frames. <p> The L 2 distance has very similar properties to the correlation measure 3 . In the context of this paper, minimizing the L 2 distance is exactly equivalent to maximizing the correlation (the observation is due to F. Girosi). As noticed before <ref> [3] </ref>, the previous idea can be regarded as an approximation of a regularization solution to the problem of computing the optical flow 4 . Usually, one does not use grey values directly but rather some filtered version of the image, for instance through a Laplacian-of-a-Gaussian filter (see [3]), possibly at different <p> As noticed before <ref> [3] </ref>, the previous idea can be regarded as an approximation of a regularization solution to the problem of computing the optical flow 4 . Usually, one does not use grey values directly but rather some filtered version of the image, for instance through a Laplacian-of-a-Gaussian filter (see [3]), possibly at different resolutions. Let us call D (ffi x ; ffi y ) the L 2 distance between 2 patches in 2 frames at location (x; y) as a function of the shift vector (ffi x ; ffi y ). <p> The key aspect of this approach is its reduction of the complexity of the problem, while maintaining a good estimation of the flow field: a complete two-dimensional search required in the winner-take-all scheme <ref> [3] </ref> is reduced to two one-dimensional searches. Let us call v max the maximum velocity expected on the image plane. In [3] the search space size to scan is (2v max + 1) 2 for each point; in our approach, its size is limited to 2 (2v max + 1). 2.2 <p> this approach is its reduction of the complexity of the problem, while maintaining a good estimation of the flow field: a complete two-dimensional search required in the winner-take-all scheme <ref> [3] </ref> is reduced to two one-dimensional searches. Let us call v max the maximum velocity expected on the image plane. In [3] the search space size to scan is (2v max + 1) 2 for each point; in our approach, its size is limited to 2 (2v max + 1). 2.2 1D correlation of 1D patches So far we have discussed that 1D correlation of 2D patches gives a satisfactory estimate of <p> In all experiments the movement of the vehicle was a forward translation along a straight trajectory. We have verified the results obtained from our 1D-2D approach with the standard winner-take-all (2D-2D) scheme <ref> [3] </ref> [1]. composed of 100 frames. Each image of the sequence is first convolved with a Gaussian filter having = 0:5.
Reference: [4] <author> T. Poggio and F. Girosi. </author> <title> Networks for approximation and learning. </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> 78(9), </volume> <month> September </month> <year> 1990b. </year>
Reference: [5] <author> T. Poggio, A. Verri, and V. Torre. </author> <title> Green theorems and qualitative properties of the optical flow. </title> <type> Technical Report A.I. Memo No. 1289, </type> <institution> Artificial Intelligence Laboratory, Massachusetts Institute of Technology, </institution> <address> Cambridge, MA, </address> <year> 1991. </year>
Reference-contexts: In this paper we show that 1D patchwise correlation may provide a sufficiently accurate estimate of the optical flow 1 . We will then show with experiments on real image sequences how to apply this technique to measure time-to-crash, by exploiting a recently proposed scheme <ref> [5] </ref>. The latter scheme, which is robust and invariant to the position of the focus of expansion or the center of rotation, relies on sparse measurements of either the normal or the tangential component of the optical flow (relative to a closed contour). <p> We label this technique the 1D-1D scheme since it involves 1D correlations of 1D patches. 2 closed contour. Each of the elementary motion detectors could be replaced by a single detector normal to the circle. 3 A crash detector: the Green theorem scheme As described in <ref> [5] </ref> (see also [2]), the divergence of the optical field ru (x; y) is a differential measure of the local expansion (ru (x; y) = @u x (x;y) @u y (x;y) @y ). For a linear field (i.e. u (x) = Ax), the divergence of u is the same everywhere. <p> As described in <ref> [5] </ref>, each elementary detector evaluates the tangential flow component at the contour of the receptive field (see fig.5). <p> Figures 10 shows the optical flows computed by the two methods using two successive images of the sequence. The position of the focus of expansion was computed by using the approach described in [11]. We have used the method described in [11] and <ref> [5] </ref> to verify the TTC estimation. To compute the TTC at a point by using the method in [11], we used an area of 81 fi 81 pixels around that point. The points were 10 pixels apart. To compute TTC by using the method described in [5], we used a lattice <p> described in [11] and <ref> [5] </ref> to verify the TTC estimation. To compute the TTC at a point by using the method in [11], we used an area of 81 fi 81 pixels around that point. The points were 10 pixels apart. To compute TTC by using the method described in [5], we used a lattice of overlapping motion detectors. The distance between two points on the lattice was 10 pixels. Each detectors had a receptive field of ray r = 40 pixels. <p> Performing a linear best fit on the TTC measurements, we obtain a slope of m = 1:036 by using the optical flows computed by 2D-2D and the method described in [11], and m = 1:139 by using the optical flows computed by 1D-2D and the method described in <ref> [5] </ref>. Comparing the true TTC (straight line in fig. 11) with the TTC measures obtained by using the second method, we estimate an absolute error in the mean of 2:63, with a standard deviation of 3:35 frame unit.
Reference: [6] <author> T. Poggio, W. Yang, and V. Torre. </author> <title> Optical flow: Computational properties and networks, biological and analog. In The Neuron as a Computational Unit Proceedings, </title> <address> Cambridge, UK, </address> <month> June </month> <year> 1988. </year> <note> Scientific Applications International Corporation. </note>
Reference-contexts: Other "robust" distance metric may be used, such as the sum of absolute values. 4 And in turn several definitions of the optical flow such as Horn and Schunk's, can be shown to be approximations of the correlation technique <ref> [6] </ref>. 1 for the computation of the x and y components of the optical flow. flow estimate is u fl = s fl =t, where t is the interframe interval.
Reference: [7] <author> Tomaso Poggio and Werner Reichardt. </author> <title> Considerations on models of movement detection. </title> <journal> Kybernetik, </journal> <volume> 13 </volume> <pages> 223-227, </pages> <year> 1973. </year>
Reference-contexts: Radially oriented (for expansion and contraction), two input elementary motion detectors such as the correlation model <ref> [8, 9, 7, 10] </ref> or approximations of it are likely to be adequate. <p> interframe interval in our implementation and is the delay in Reichardt's model 5 , k represents 5 We have written here the quadratic version of Reichardt's model; the same argument carries over to the standard model with multiplication: for the basic equivalence of the the quadratic and multiplication version see <ref> [7] </ref>) the shift in our computation of D and represents the separation between the inputs to Reichardt's modules, I i (t) is the image value (in general spatially and temporally filtered) at location i and time t and the sum P is taken over the 2D patch of detectors of the
Reference: [8] <author> W. Reichardt. </author> <title> Autocorrelation, a principle for evaluation of sensory information by the central nervous system. In W.A. </title> <editor> Rosenblith, editor, </editor> <booktitle> Principles of Sensory Communication, </booktitle> <pages> pages 303-317, </pages> <address> New York, 1961. </address> <publisher> John Wiley and Sons. </publisher>
Reference-contexts: Radially oriented (for expansion and contraction), two input elementary motion detectors such as the correlation model <ref> [8, 9, 7, 10] </ref> or approximations of it are likely to be adequate.
Reference: [9] <author> W. Reichardt. </author> <title> Evaluation of optical motion information by movement detectors. </title> <journal> J. Computational Physics, </journal> <volume> 161 </volume> <pages> 533-547, </pages> <year> 1987. </year>
Reference-contexts: Radially oriented (for expansion and contraction), two input elementary motion detectors such as the correlation model <ref> [8, 9, 7, 10] </ref> or approximations of it are likely to be adequate.
Reference: [10] <author> J.P.H van Santen and G. Sperling. </author> <title> Temporal covari-ance model of human motion perception. </title> <journal> Journal of Optical Society of America A, </journal> <volume> 1 </volume> <pages> 451-473, </pages> <year> 1984. </year>
Reference-contexts: Radially oriented (for expansion and contraction), two input elementary motion detectors such as the correlation model <ref> [8, 9, 7, 10] </ref> or approximations of it are likely to be adequate.
Reference: [11] <author> A. Verri and M. Campani. </author> <title> An algebraic procedure for the computation of optical flow from first order derivatives of the image brightness. </title> <booktitle> In IEEE Work. on Robust Comp. Vision, </booktitle> <address> Seattle, </address> <year> 1990. </year>
Reference-contexts: Figures 10 shows the optical flows computed by the two methods using two successive images of the sequence. The position of the focus of expansion was computed by using the approach described in <ref> [11] </ref>. We have used the method described in [11] and [5] to verify the TTC estimation. To compute the TTC at a point by using the method in [11], we used an area of 81 fi 81 pixels around that point. The points were 10 pixels apart. <p> Figures 10 shows the optical flows computed by the two methods using two successive images of the sequence. The position of the focus of expansion was computed by using the approach described in <ref> [11] </ref>. We have used the method described in [11] and [5] to verify the TTC estimation. To compute the TTC at a point by using the method in [11], we used an area of 81 fi 81 pixels around that point. The points were 10 pixels apart. <p> The position of the focus of expansion was computed by using the approach described in <ref> [11] </ref>. We have used the method described in [11] and [5] to verify the TTC estimation. To compute the TTC at a point by using the method in [11], we used an area of 81 fi 81 pixels around that point. The points were 10 pixels apart. To compute TTC by using the method described in [5], we used a lattice of overlapping motion detectors. The distance between two points on the lattice was 10 pixels. <p> Performing a linear best fit on the TTC measurements, we obtain a slope of m = 1:036 by using the optical flows computed by 2D-2D and the method described in <ref> [11] </ref>, and m = 1:139 by using the optical flows computed by 1D-2D and the method described in [5].

References-found: 11

