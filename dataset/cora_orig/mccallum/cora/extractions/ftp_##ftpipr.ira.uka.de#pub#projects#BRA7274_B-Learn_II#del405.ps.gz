URL: ftp://ftpipr.ira.uka.de/pub/projects/BRA7274_B-Learn_II/del405.ps.gz
Refering-URL: http://wwwipr.ira.uka.de/projects/blearn/blearnpub.html
Root-URL: 
Title: Workpackage 4 Navigation Deliverable 405: Learning Techniques for Mobile Systems  
Author: Michael Kaiser (UKA) Volker Klingspor (UDO) Katharina Morik (UDO) Anke Rieger (UDO) Marco Accame (UGE) Jose del R. Millan (ICB) 
Date: October 20, 1995  
Note: ESPRIT BRA No. 7274 "B-Learn II"  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> M. Accame and F.G.B. De Natale. </author> <title> Neural tuned edge extraction in visual sensing. </title> <editor> In M. Kaiser, editor, </editor> <booktitle> Proceedings of the 3rd European Workshop on Learning Robots (EWLR-3), </booktitle> <address> Heraklion, Crete, Greece, </address> <month> April </month> <year> 1995. </year>
Reference-contexts: In the former case the ANNs control the camera intrinsic parameters settings [33], whereas in the latter they act onto the thresholds of the Canny Algorithm <ref> [31, 1] </ref>. 4 TRANSFERRING SKILLS AND KNOWLEDGE TO MOBILE ROBOTS 21 Based on the intermediate experimental results, an alternative strategy for the neural tuning of the Edge Extraction process has been developed and refined during the last months of the project: according to this, the ANNs don't deal any more with <p> For the results shown in Fig. 34, the task was to find the best out of several possible skillls. The Q value for each skill was initialized randomly. The reinforcement signal r was selected randomly from <ref> [0:9; 1] </ref> if the optimal EO was executed, and to a random value in [0; 1] otherwise. <p> The Q value for each skill was initialized randomly. The reinforcement signal r was selected randomly from [0:9; 1] if the optimal EO was executed, and to a random value in <ref> [0; 1] </ref> otherwise. Obviously, the number of trials needed to find the optimal action (here, achieving P (e = a opt jC) &gt; 0:9 was the convergence criterion) depended on both the learning rate and the number of alternative actions that were available.
Reference: [2] <author> H. Asada and B.-H. Yang. </author> <title> Skill acquisition from human experts through pattern processing of teaching data. </title> <booktitle> In Proceedings of the 1989 IEEE International Conference on Robotics and Automation, </booktitle> <year> 1989. </year>
Reference-contexts: To this aim, the formalism to be used to represent these functions has to be selected first. This is in general done ad hoc, i.e., the representation is chosen to be suitable for learning a specific skill under specific conditions <ref> [2, 63, 23] </ref>. However, an untrained user cannot be expected to perform this selection for every skill he/she wants the robot to acquire. Therefore, it is necessary that the representation can be constructed from the training data. <p> Both requirements exclude, for instance, multilayer perceptrons (MLPs) or conventional decision-tree techniques [63, 45, 74] from being used in a general approach. Also, the specification of the functional form of the skill by the user, which reduces skill learning to the identification of numerical parameters <ref> [2] </ref>, is not an appropriate solution. The investigation of several function approximation techniques throughout B-Learn II [59, 33, 17, 65, 34, 3, 21, 48, 49, 52, 50] lead to the selection of neural networks based on local receptive fields [54], such as Radial-Basis Function Networks (RBFs) [62].
Reference: [3] <author> C. Baroglio, A. Giordana, M. Kaiser, M. Nuttin, and R. Piola. </author> <title> Learning controllers for industrial robots. </title> <booktitle> Machine Learning, </booktitle> <year> 1996. </year>
Reference-contexts: Secondly, we adopt the argument followed also in workpackage 2 [58, 59] and in our previous work [51, 47]: For representing elementary robot skills, we apply neural networks representing the target function locally. As shown in <ref> [3, 59] </ref>, these networks have a direct symbolic interpretation. 8. <p> Also, the specification of the functional form of the skill by the user, which reduces skill learning to the identification of numerical parameters [2], is not an appropriate solution. The investigation of several function approximation techniques throughout B-Learn II <ref> [59, 33, 17, 65, 34, 3, 21, 48, 49, 52, 50] </ref> lead to the selection of neural networks based on local receptive fields [54], such as Radial-Basis Function Networks (RBFs) [62]. <p> The investigation of several function approximation techniques throughout B-Learn II [59, 33, 17, 65, 34, 3, 21, 48, 49, 52, 50] lead to the selection of neural networks based on local receptive fields [54], such as Radial-Basis Function Networks (RBFs) [62]. Such networks can be built from training data <ref> [54, 57, 3, 43] </ref>, which is extremely important in a setting that asks for automatization of the learning phase. Additionally, these networks do also allow for directly assessing the knowledge that is available with respect to a particular situation. <p> During this demonstration, the ultrasonic measurements as well as the commands given by the operator were recorded (Fig. 27). The RBF network representing the initial skill was constructed through application of the clustering algorithm described in <ref> [3] </ref>, which resulted in 23 clusters in the hidden layer.
Reference: [4] <author> A. G. Barto, R. S. Sutton, and C. W. Anderson. </author> <title> Neuronlike elements that can solve difficult learning control problems. </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics, </journal> <pages> pages 835-846, </pages> <year> 1983. </year>
Reference-contexts: Then, we define the termination criterion as hypercube with the goal state as its center and a suitable width. 4.1.2 Autonomous learning of basic mobility skills A possibility to learn basic mobility skills autonomously is to follow the line of reinforcement learning <ref> [4, 84] </ref>. The robot then has to learn suitable reactions directly from a feedback signal, which, in the simplest case, is positive as soon as the robot achieves the goal (e.g., it passes the door), and is negative otherwise. <p> To solve this task, two different learning rules, namely temporal difference (TD) methods [72] and associative search (AS) <ref> [4, 84] </ref> are used, where TD methods are employed to predict the total future reward and AS is used to update the situation-action mapping based on the estimation given by TD.
Reference: [5] <author> E. Charniak. </author> <title> Passing markers: A theory of contextual influence in language comprehension. </title> <journal> Cognitive Science, </journal> <volume> 7, </volume> <year> 1983. </year>
Reference-contexts: Based on this idea, we can apply a simple marker passing method <ref> [5] </ref>, [22] to the DFA. Assume, that the robot has perceived a sequence of observations bf 1 : : : bf k during a period of time, in which no change of direction of movement took place.
Reference: [6] <author> M. Deck. Interaktive Akquisition von Elementarfahigkeiten fur mobile Roboter. </author> <type> Master's thesis, </type> <institution> Universitat Karlsruhe, Fakultat fur Informatik, Institut fur Prozerechentechnik und Robotik, </institution> <year> 1995. </year>
Reference-contexts: However, the critic network grew from 46 to 65 clusters. While the error criterion was sufficiently wide, the termination criterion had to be extended. Sensitivity analysis To analyze the sensitivity of the off-line learned skill, we performed a second set of experiments (see also <ref> [6] </ref>). Here, we the skill was the sensor-based motion around a corner (Fig. 29 left). corner used for test 3. This skill was demonstrated ten times, resulting in example files containing between 40 and 52 samples each.
Reference: [7] <author> R. Dillmann, M. Kaiser, and A. Ude. </author> <title> Acquisition of elementary robot skills from human demonstration. </title> <booktitle> In International Symposium on Intelligent Robotics Systems, </booktitle> <address> Pisa, Italy, </address> <year> 1995. </year>
Reference-contexts: Moreover, such a sensor does in general not suffer from drop outs, i.e., while the sensor readings may be noisy, individual perception components will not be missing completly. For preprocessing such examples, statistic means are therefore often valid <ref> [7, 35] </ref>. In case of a mobile robot, the situation is different. First, the distance measuring sensors in use do in general not allow for scanning the environment at a high rate. <p> Based on knowledge of relevant actions, such a dependency can be used to identify relevant perceptions <ref> [7] </ref>, if sufficiently many samples have been taken during the demonstration. 1. Let ((y (0); u (0)); : : : ; (y (T ); u (T ))) be a sequence of sensor measurements y (t) and ac tions u (t) resulting from a demonstration. 2.
Reference: [8] <author> R. Dillmann, M. Kaiser, F. Wallner, and P. Weckesser. PRIAMOS: </author> <title> An advanced mobile system for service, inspection, and surveillance tasks. </title> <editor> In T. Kanade H. Bunke, H. Noltemeier, editor, </editor> <title> Modelling and Planning for Sensor Based Intelligent Robot Systems. </title> <publisher> World Scientific, </publisher> <year> 1995. </year>
Reference-contexts: For the mobile robot PRIAMOS <ref> [10, 8] </ref>, collision avoidance means to actively alter the geometrically planned path of the robot based on the current measurements of its 24 ultrasonic sensors. In this particular case, the initial collision avoidance skill was acquired by means of a user demonstration. <p> This also corresponds to the final focus of B-Learn II, which can shortly be described as developing methods that allow for easier application and programming of robots especially for not production-oriented tasks <ref> [8, 30] </ref>. If the realization of learning capabilities in robots should serve this purpose, the next step, i.e., to ask the human user for examples, feedback, etc. is obvious.
Reference: [9] <author> R. Dillmann, J. Kreuziger, and F. Wallner. PRIAMOS: </author> <title> An experimental platform for reflexive navigation. </title> <booktitle> In Proceedings of the International Conference on Intelligent Autonomous Systems (IAS '93), </booktitle> <year> 1993. </year> <note> REFERENCES 63 </note>
Reference: [10] <author> R. Dillmann, J. Kreuziger, and F. Wallner. PRIAMOS: </author> <title> an experimental platform for reflexive navigation. </title> <booktitle> Robotics and Autonomous Systems, </booktitle> <volume> 11, </volume> <year> 1993. </year>
Reference-contexts: For the mobile robot PRIAMOS <ref> [10, 8] </ref>, collision avoidance means to actively alter the geometrically planned path of the robot based on the current measurements of its 24 ultrasonic sensors. In this particular case, the initial collision avoidance skill was acquired by means of a user demonstration.
Reference: [11] <author> A. Elfes. </author> <title> Sonar based real world mapping and navigation. </title> <journal> IEEE Transactions on Robotics and Automation, </journal> <volume> 3(3) </volume> <pages> 249-265, </pages> <year> 1987. </year>
Reference-contexts: The robot continuously observes its surroundings in order to improve the world model. Fig. 5 shows the mapping steps performed during an example run. A number of probability grids <ref> [11] </ref> are generated due to sonar reflections or imprecise object models that result in unexpected echoes. Grids caused by reflection can be deleted in further grid-integration steps as these measurements are only sparse and typically do not produce significant grid structures.
Reference: [12] <author> J. Evans. HelpMate: </author> <title> An autonomous mobile robot courier for hospitals. </title> <booktitle> In IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS '94), </booktitle> <address> Munich, Germany, </address> <year> 1994. </year>
Reference: [13] <author> R. Fikes and N. J. Nilsson. </author> <title> Strips: A new approach to the application of theorem proving to problem solving. </title> <journal> Artificial Intelligence, </journal> <volume> 2 </volume> <pages> 189-208, </pages> <year> 1971. </year>
Reference-contexts: To plan actions, an operator must not only consist of the situation in which it is applicable, but also of the situation, that arises from applying it, to be able to chain multiple operators. In the STRIPS-approach <ref> [13] </ref>, operators are presented as structures with a list of preconditions, of facts to be deleted, and facts to be added; add- and delete-list define the new situation.
Reference: [14] <author> S. J. Fortune. </author> <title> Computing in Euclidean Geometry, chapter Voronoi Diagrams and Delaunay Triangulations. </title> <publisher> World Scientific, </publisher> <year> 1991. </year>
Reference-contexts: For mobile robots, a topological graph (Fig. 20) of the environment is such a representation. To autmatically generate topological graphs from a geometrical model of the environment, literature often proposes Voronoi diagrams <ref> [14, 61] </ref>. Voronoi diagrams are solutions of minimal distance problems. Edges of a Voronoi diagram represent points in space that feature an equal distance to two distinct points of a given set of subspaces.
Reference: [15] <author> H. Friedrich, </author> <title> editor. Learning from Examples versus Programming by Demonstration, </title> <address> Tahoe City, California, </address> <year> 1995. </year> <booktitle> 12th International Conference on Machine Learning. </booktitle>
Reference-contexts: During navigation, at any time instant t, the robot reads the current sensor state d t i = r t i = 1; : : :; 16, where R = 15 and r t i 2 <ref> [0; 15] </ref> is the output of infrared sensor i at time t. In addition, the goal direction detection system 2 returns the number #p of the most active photosensor. <p> Consequently, during the course of B-Learn II, one of the key points turned out to be the interaction of the learning system with the user <ref> [15, 28] </ref>. This also corresponds to the final focus of B-Learn II, which can shortly be described as developing methods that allow for easier application and programming of robots especially for not production-oriented tasks [8, 30].
Reference: [16] <author> B. Fritzke. </author> <title> A growing neural gas network learns topologies. </title> <booktitle> In Advances in Neural Information Processing Systems 7 (NIPS-7). </booktitle> <publisher> MIT Press, </publisher> <year> 1995. </year>
Reference-contexts: In the case of autonomous robot it can also be difficult to determine beforehand the correct number of units in the map to represent efficiently the sensory space. Therefore, based on the Fritzke's work in "growing neural gas" model <ref> [16] </ref>, we have developed a Dynamical Self-Organizing Map (DSOM) to overcome the above problems and to fulfill the requirements of real time operation and on-line learning of behavior-oriented autonomous robots. The DSOM network consists of two major components: 1.
Reference: [17] <author> A. Giordana, M. Kaiser, and M. Nuttin. </author> <title> On the reduction of costs for robot controller synthesis. </title> <booktitle> In International Symposium on Intelligent Robotic Systems (IRS '94), </booktitle> <pages> pages 187 - 197, </pages> <address> Grenoble, France, </address> <year> 1994. </year>
Reference-contexts: Also, the specification of the functional form of the skill by the user, which reduces skill learning to the identification of numerical parameters [2], is not an appropriate solution. The investigation of several function approximation techniques throughout B-Learn II <ref> [59, 33, 17, 65, 34, 3, 21, 48, 49, 52, 50] </ref> lead to the selection of neural networks based on local receptive fields [54], such as Radial-Basis Function Networks (RBFs) [62].
Reference: [18] <author> V. Gullapalli. </author> <title> A stochastic reinforcement learning algorithm for learning real valued functions. </title> <booktitle> Neural Networks, </booktitle> <volume> 3 </volume> <pages> 671-692, </pages> <year> 1990. </year>
Reference-contexts: The task is therefore to refine a continuous real-valued function on the basis of a delayed reinforcement signal. Gullapalli's approach based on SRV units <ref> [18, 19] </ref> provides a suitable starting point for solving this task, which can formally be described as follows: Given: An initial skill represented by function C s ; t s ; and e s , a model r s that acts as a critic, and an external feedback source providing a
Reference: [19] <author> V. Gullapalli, J. A. Franklin, and H. Benbrahim. </author> <title> Acquiring robot skills via reinforcement learning. </title> <journal> IEEE Control Systems Magazine, </journal> <volume> 14(1):13 - 24, </volume> <year> 1994. </year>
Reference-contexts: The task is therefore to refine a continuous real-valued function on the basis of a delayed reinforcement signal. Gullapalli's approach based on SRV units <ref> [18, 19] </ref> provides a suitable starting point for solving this task, which can formally be described as follows: Given: An initial skill represented by function C s ; t s ; and e s , a model r s that acts as a critic, and an external feedback source providing a <p> If only a weak function that can be provided by an unexperienced user is applied, adaptation can take a long time. On the other hand, a sophisticated evaluation function or sophisticated adaptation mechanisms often incorporates a lot of knowledge about the function to be learned (e.g., <ref> [73, 19] </ref>). Then, it might even be easier to directly encoded the control function.
Reference: [20] <author> Stevan Harnad. </author> <title> The symbol grounding problem. </title> <journal> Physica D, </journal> <volume> 42 </volume> <pages> 335-346, </pages> <year> 1990. </year>
Reference-contexts: Secondly, to allow the user to efficiently control and maintain the robot, the low-level numerical representations used by the robot have to be translated into an understandable form. Both aspects are related to the problem of symbol grounding <ref> [20] </ref>. The tasks to be solved in this scenario are mostly related to knowledge transfer and knowledge acquisition. Both aspects are strongly linked with the idea of learning, so they became key points in B-Learn II (see also section 2). <p> We have shown that a first order representation * can deal with the problem of deriving high-level concepts from numeric data, which includes the problem of symbol grounding <ref> [20] </ref>. * allows a very nice handling of time, allowing the representation of chains of intervals (when linking successing basic features), of perceptions of different sensors and sensor groups at the same time, and the integration of action and sensing. * simplifies the integration of different sensors and sensor systems, because
Reference: [21] <author> J. Heikkonen, J. del R. Millan, and E. Cuesta. </author> <title> Incremental learning from basic reflexes in an autonomous mobile robot. </title> <booktitle> In International Conference on Engineering Applications of Neural Networks, </booktitle> <address> Helsinki, Finland, </address> <year> 1995. </year>
Reference-contexts: Also, the specification of the functional form of the skill by the user, which reduces skill learning to the identification of numerical parameters [2], is not an appropriate solution. The investigation of several function approximation techniques throughout B-Learn II <ref> [59, 33, 17, 65, 34, 3, 21, 48, 49, 52, 50] </ref> lead to the selection of neural networks based on local receptive fields [54], such as Radial-Basis Function Networks (RBFs) [62]. <p> This improvement allows to avoid dangerous actions resulting from exploration (for further details see [49, 52]. A second approach to learn reactive navigation skills that is based on self-organizing maps (SOM) [41, 42]. In order to learn continuously and incrementally, we have developed a dynamical self-organizing map (DSOM) <ref> [21] </ref>, where units are added incrementally as they are required to better cover the experienced part of the sensory space. The robot uses some basic reflexes to select an action every time it perceives a sensory situation sufficiently different from previous ones.
Reference: [22] <author> J. A. Hendler. </author> <title> Integrating marker-passing and problem solving. </title> <editor> In J. Allen, J. Hendler, and A. Tate, editors, </editor> <booktitle> Readings in Planning, </booktitle> <pages> pages 275-287. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1990. </year>
Reference-contexts: Based on this idea, we can apply a simple marker passing method [5], <ref> [22] </ref> to the DFA. Assume, that the robot has perceived a sequence of observations bf 1 : : : bf k during a period of time, in which no change of direction of movement took place.
Reference: [23] <author> S. Hirai, H. Noguchi, and K. Iwata. </author> <title> Transplantation of human skillful motion to manipulators in insertion of deformable tubes. </title> <booktitle> In IEEE Internation Conference on Robotics and Automation, pages 1900 - 1905, </booktitle> <address> Nagoya, Japan, </address> <year> 1995. </year>
Reference-contexts: To this aim, the formalism to be used to represent these functions has to be selected first. This is in general done ad hoc, i.e., the representation is chosen to be suitable for learning a specific skill under specific conditions <ref> [2, 63, 23] </ref>. However, an untrained user cannot be expected to perform this selection for every skill he/she wants the robot to acquire. Therefore, it is necessary that the representation can be constructed from the training data.
Reference: [24] <author> F. Jelinek. </author> <title> Continuous speech recognition by statistical methods. Procs. </title> <journal> of the IEEE, </journal> <volume> 64 </volume> <pages> 532-556, </pages> <year> 1976. </year>
Reference-contexts: Each ffi ij satisfies the condition 0 ffi ij 1; 1 i; j jQj. fl denotes the observation probability distribution, which, following <ref> [24] </ref>, is associated with state transitions. <p> As there may be several possible paths, we use the Viterbi algorithm <ref> [24] </ref> to determine the state sequence, which maximizes this probability. We interpret the maximal acceptance probability of a sequence as posterior probability P (cjbf 1 : : : bf k ) of the concept c, which has been recognized most probably.
Reference: [25] <author> M. Kaiser. </author> <note> Learning from undiscounted delayed rewards. to appear, </note> <year> 1996. </year>
Reference-contexts: To solve this temporal credit assignment problem, usually exponentially discounted rewards are used. However, our approach has been to use an exponentially discounted adaptation rate. For real-world adaptation, this has shown to exhibit several advantages <ref> [25] </ref>. For updating the region list, we simply include or exclude the final state x: If a new goal or error state must be learned, a corresponding region is inserted.
Reference: [26] <author> M. Kaiser, M. Deck, A. Retey, K. Berns, and W. Ilg. </author> <title> Using neural networks for real-world adaptive control. In Neural Networks: Producing Dependable Systems, </title> <address> Solihull, UK, </address> <month> November </month> <year> 1995. </year>
Reference-contexts: The actual mechanism used for this adaptation depends on the representation of the functions as well as on the information contained in the feedback <ref> [26] </ref>. The minimum feedback that is assumed to be available in the context of learning from human demonstrations is an evaluation of the performance of the robot after the application of an individual skill. <p> We found that despite the networks' theoretical capability of total approximation, many other aspects must be taken into account when using neural networks for real-world adaptive control <ref> [65, 34, 26] </ref>: * the amount and quality of a-priori knowledge, * the costs of taking samples from the system, * the quality of knowledge usable for adaptation, * the costs of non-optimal control and exploration, * the dimension of the input space, and * the estimated statistic and systematic errors.
Reference: [27] <author> M. Kaiser and R. Dillmann. </author> <title> Hierarchical learning of efficient skill application for autonomous robots. </title> <booktitle> In International Symposium on Intelligent Robotics Systems, </booktitle> <address> Pisa, Italy, </address> <year> 1995. </year>
Reference-contexts: If, for instance, the elementary operations belonging to a certain class (e.g., all Docking-EOs) are only executed in a known context, with the context information being linked to the environment, this strategy may be represented by the skills assigned to the edges of a topological map <ref> [78, 79, 27] </ref>.
Reference: [28] <author> M. Kaiser and H. Friedrich. </author> <title> Transferring human knowledge to robots. </title> <booktitle> In Meeting GI Special Interest Group Machine Learning, </booktitle> <address> Dortmund, Germany, </address> <year> 1995. </year> <note> Also available via anonymous ftp from ftpipr.ira.uka.de. </note>
Reference-contexts: Consequently, during the course of B-Learn II, one of the key points turned out to be the interaction of the learning system with the user <ref> [15, 28] </ref>. This also corresponds to the final focus of B-Learn II, which can shortly be described as developing methods that allow for easier application and programming of robots especially for not production-oriented tasks [8, 30].
Reference: [29] <author> M. Kaiser, H. Friedrich, and R. Dillmann. </author> <title> Obtaining good performance from a bad teacher. </title> <booktitle> In International Conference on Machine Learning, Workshop on Programming by Demonstration, </booktitle> <address> Tahoe City, California, </address> <year> 1995. </year> <note> REFERENCES 64 </note>
Reference-contexts: In the ideal case, these data represent the skill to be acquired perfectly. In reality, however, this will seldom be the case. Several sources of suboptimality exist that result in disturbances of the above equation <ref> [29] </ref>, the most prominent being 1. the existence of incorrect actions that must be corrected at a later instance and 2. the human tendency to perform "bang-bang" instead of smooth control. The effect of these suboptimalities cannot be neglected. <p> The subsequent training of the network was performed until all actions u the network produced fulfilled the criterion u = ffu fl with 0:7 &lt; ff 1:0; where u fl is the action performed by the human operator (see also <ref> [29] </ref>). Similarly, the model network was generated and trained on sampled data. The reinforcement signal needed for o*ine training was generated by the operator.
Reference: [30] <author> M. Kaiser, V. Klingspor, J. del R. Millan, M. Accame, F. Wallner, and R. Dillmann. </author> <title> Using machine learning techniques in real-world mobile robots. </title> <journal> IEEE Expert, </journal> <year> 1995. </year>
Reference-contexts: This also corresponds to the final focus of B-Learn II, which can shortly be described as developing methods that allow for easier application and programming of robots especially for not production-oriented tasks <ref> [8, 30] </ref>. If the realization of learning capabilities in robots should serve this purpose, the next step, i.e., to ask the human user for examples, feedback, etc. is obvious.
Reference: [31] <author> M. Kaiser, V. Klingspor, J. del R. Millan, and M. Accame. </author> <title> B-Learn II - D 404. B-Learn II - ESPRIT BRA Project No. </title> <type> 7274, </type> <year> 1994. </year>
Reference-contexts: PRIAMOS operates in an office environment and moves on a path that has been planned according to a specified mission <ref> [31, 78, 79] </ref>. The robot continuously observes its surroundings in order to improve the world model. Fig. 5 shows the mapping steps performed during an example run. A number of probability grids [11] are generated due to sonar reflections or imprecise object models that result in unexpected echoes. <p> First, we investigated the potential of reinforcement learning for autonomously learning such basic mobility skills (safe elementary operations). Second, we used human demonstrations of such elementary operations as examples, i.e., as the basis of learning. 4.1.1 Acquiring basic mobility skills from human demonstrations In Deliverable 404 <ref> [31] </ref>, we already presented the basic approach to the acquisition of basic mobility skills from human demonstrations. <p> In the former case the ANNs control the camera intrinsic parameters settings [33], whereas in the latter they act onto the thresholds of the Canny Algorithm <ref> [31, 1] </ref>. 4 TRANSFERRING SKILLS AND KNOWLEDGE TO MOBILE ROBOTS 21 Based on the intermediate experimental results, an alternative strategy for the neural tuning of the Edge Extraction process has been developed and refined during the last months of the project: according to this, the ANNs don't deal any more with <p> The approach introduced in the second year of activity provided learning capabilities to the Edge Extraction Module, teaching an ANN to give the correct tuning of the thresholds even in presence of changes of the environment conditions. The ANN is fed by a number of features (see <ref> [31] </ref> for details) describing the histogram of occurrence of the strength of the maxima points. <p> Since it necessary to transform the selected visual primitives in a common format, the visual primitives (which lie in the two-dimensional domain of the image) are mapped into the three dimensional coordinates of the robot world using the distance information provided by other sensors and the camera parameters (see <ref> [31] </ref> for details). 4.3 Learning and representing operational concepts Operational Concepts are a mean to enable the user to understand easily what the robot is doing. In general, this task requires to build abstract descriptions of situations and actions the robot encounters. <p> To combine perceptions and actions in a concept description is the basic idea of operational concepts [56, 37]. For learning these concepts, several techniques have been developed within B-Learn II. As far as this has not already been done in <ref> [32, 33, 31] </ref>, these techniques as well as a data preparation tool used to support their easy application, are described now. 4.3.1 Data preparation Whenever machine learning algorithms are applied to complex domains, several data engineering problems have to be solved. <p> Such a plan is usually found by goal-directed search, starting with the list of open goals and trying to solve each goal. In Deliverable 404 <ref> [31] </ref>, we presented another representation of operators we called operational concepts because they cannot only be used for planing but also for object recognition. <p> Otherwise, a new unlabelled region covering the current state is inserted, thereby excluding the region from the error or the termination criterion. 4.4.2 Generating a topological representation The adaptation of an individual skill has already been discussed in Deliverable 404 <ref> [31] </ref> and in section 4.4.1. For solving the problem of choosing the most suitable from a set of skills, we first require an abstract representation of the robot's task space. <p> In B-Learn II's workpackages 2 and 4 <ref> [31, 59, 60] </ref>, we have exploited the potential of neural networks as trainable model-free function approximators for solving such control tasks.
Reference: [32] <author> M. Kaiser, V. Klingspor, J. del R. Millan, C. Moneta, K. Morik, and A. Rieger. </author> <title> B-Learn II - D 401. B-Learn II ESPRIT BRA Project No. </title> <type> 7274, </type> <year> 1993. </year>
Reference-contexts: Given such an hierarchical representation, the second group of learning tasks is devoted to enabling the robot to use these representations, i.e., to acquire action knowledge. Consequently, in Deliverable 401 <ref> [32] </ref>, we identified the eight learning tasks shown again in Fig. 4. During the course of B-Learn II, the following approaches to solving these tasks were developed: 1. Acquiring basic mobility skills: This task is related to building the robot's basic operative intelligence. <p> To combine perceptions and actions in a concept description is the basic idea of operational concepts [56, 37]. For learning these concepts, several techniques have been developed within B-Learn II. As far as this has not already been done in <ref> [32, 33, 31] </ref>, these techniques as well as a data preparation tool used to support their easy application, are described now. 4.3.1 Data preparation Whenever machine learning algorithms are applied to complex domains, several data engineering problems have to be solved.
Reference: [33] <author> M. Kaiser, V. Klingspor, J. del R. Millan, C. Moneta, K. Morik, and A. Rieger. </author> <title> B-Learn II - D 402. B-Learn II ESPRIT BRA Project No. </title> <type> 7274, </type> <year> 1993. </year>
Reference-contexts: Also, the specification of the functional form of the skill by the user, which reduces skill learning to the identification of numerical parameters [2], is not an appropriate solution. The investigation of several function approximation techniques throughout B-Learn II <ref> [59, 33, 17, 65, 34, 3, 21, 48, 49, 52, 50] </ref> lead to the selection of neural networks based on local receptive fields [54], such as Radial-Basis Function Networks (RBFs) [62]. <p> In particular, the efforts were focused onto the regulation of the Camera and the Edge Extractor, which shown to be by far the most critical to be controlled autonomously. In the former case the ANNs control the camera intrinsic parameters settings <ref> [33] </ref>, whereas in the latter they act onto the thresholds of the Canny Algorithm [31, 1]. 4 TRANSFERRING SKILLS AND KNOWLEDGE TO MOBILE ROBOTS 21 Based on the intermediate experimental results, an alternative strategy for the neural tuning of the Edge Extraction process has been developed and refined during the last <p> This cycle is iterated until an acceptable average quality of the current image has been obtained. The evaluation of the image quality is performed by computing a set of features related to both the gradient magnitude and the histogram analysis <ref> [33, 53] </ref>. <p> Some experiment revealed that an ANN control of these parameters does not take considerable advantages over a heuristic setting, and the more traditional solution was preferred. However, the approach results simpler than the one formerly used <ref> [33] </ref>, giving a significant computational speed-up. 2. A preliminary post-processing on the lines saved by the selection based on the Hough Transform is aimed at melting and joining lines which belong to a common visual primitive. <p> To combine perceptions and actions in a concept description is the basic idea of operational concepts [56, 37]. For learning these concepts, several techniques have been developed within B-Learn II. As far as this has not already been done in <ref> [32, 33, 31] </ref>, these techniques as well as a data preparation tool used to support their easy application, are described now. 4.3.1 Data preparation Whenever machine learning algorithms are applied to complex domains, several data engineering problems have to be solved. <p> It is particularly notable that the number of the required iterations of the evaluation-tuning-acquisition loop in the Camera Module is almost always one, even in the case of worst acquisitions, and the percentage of satisfactory regulation approaches 90% (see <ref> [33] </ref>). As a matter of facts, it can be stated that the training process resulted to be effective. In other words, at least within the adopted test-bed, the employed ANNs revealed on the average the capability of performing a one-shot tuning of the sensor's intrinsic parameters.
Reference: [34] <author> M. Kaiser, A. Retey, and R. Dillmann. </author> <title> Designing neural networks for adaptive control. </title> <booktitle> In IEEE International Conference on Decision and Control (34th CDC), </booktitle> <year> 1995. </year>
Reference-contexts: Also, the specification of the functional form of the skill by the user, which reduces skill learning to the identification of numerical parameters [2], is not an appropriate solution. The investigation of several function approximation techniques throughout B-Learn II <ref> [59, 33, 17, 65, 34, 3, 21, 48, 49, 52, 50] </ref> lead to the selection of neural networks based on local receptive fields [54], such as Radial-Basis Function Networks (RBFs) [62]. <p> We found that despite the networks' theoretical capability of total approximation, many other aspects must be taken into account when using neural networks for real-world adaptive control <ref> [65, 34, 26] </ref>: * the amount and quality of a-priori knowledge, * the costs of taking samples from the system, * the quality of knowledge usable for adaptation, * the costs of non-optimal control and exploration, * the dimension of the input space, and * the estimated statistic and systematic errors.
Reference: [35] <author> M. Kaiser, A. Retey, and R. Dillmann. </author> <title> Robot skill acquisition via human demonstration. </title> <booktitle> In Proceedings of the International Conference on Advanced Robotics (ICAR '95), </booktitle> <year> 1995. </year>
Reference-contexts: human demonstration is to approximate the functions C s ; r s ; t s ; and e s from data obtained during human performance of the skill s: What is special about basic mobility skills? During the demonstration of manipulation skills, usually a force/torque sensor provides the robot's perceptions <ref> [59, 60, 35] </ref>. Such a sensor is able to deliver information at a rate of at least 30 [Hz]; such that a demonstration of 20 seconds length results in more than 600 single training samples. <p> Moreover, such a sensor does in general not suffer from drop outs, i.e., while the sensor readings may be noisy, individual perception components will not be missing completly. For preprocessing such examples, statistic means are therefore often valid <ref> [7, 35] </ref>. In case of a mobile robot, the situation is different. First, the distance measuring sensors in use do in general not allow for scanning the environment at a high rate.
Reference: [36] <author> P. Katenkamp. </author> <title> Beispielbasierte Konstruktion von Reglerstrukturen. </title> <type> Master's thesis, </type> <institution> Universitat Karlsruhe, Fakultat fur Informatik, Institut fur Prozerechentechnik und Robotik, </institution> <year> 1995. </year>
Reference-contexts: Other approaches to solve the problem of structural learnigng have recently been investigated in a cooperation between UKA and UTO in the context of workpackage 2 <ref> [36, 60] </ref>. 4 TRANSFERRING SKILLS AND KNOWLEDGE TO MOBILE ROBOTS 41 The only kind of information that can be expected from the user during the skill application and refinement process is an evaluation after the termination of the skill execution 7 .
Reference: [37] <author> V. Klingspor and K. Morik. </author> <title> Towards concept formation grounded on perception and action of a mobile robot. </title> <booktitle> In Proceedings of the 4th Intern. Conference on Intelligent Autonomous Systems (IAS-4), </booktitle> <address> Karlsruhe, </address> <year> 1995. </year>
Reference-contexts: However, if objects are represented both in terms of robot actions and robot perceptions, both concepts and can be easily distinguished. To combine perceptions and actions in a concept description is the basic idea of operational concepts <ref> [56, 37] </ref>. For learning these concepts, several techniques have been developed within B-Learn II. <p> waiting for an already ready task. 4 TRANSFERRING SKILLS AND KNOWLEDGE TO MOBILE ROBOTS 35 4 TRANSFERRING SKILLS AND KNOWLEDGE TO MOBILE ROBOTS 36 4.3.4 Planning and controling robots by operational concepts Whereas most of our work within this project concerns the task of recognizing instances of the learned concepts <ref> [37] </ref>, we designed the representation with the aim to plan sequences of actions, to execute these plans, and to supervise the execution [40].
Reference: [38] <author> Volker Klingspor. GRDT: </author> <title> Enhancing model-based learning for its application in robot navigation. </title> <editor> In Stefan Wrobel, editor, </editor> <booktitle> Proc. of the Fourth International Workshop on Inductive Logic Programming, GMD-Studien Nr. </booktitle> <volume> 237, </volume> <pages> pages 107-122, </pages> <address> St. Augustin, Germany, </address> <year> 1994. </year> <institution> GMD. </institution>
Reference-contexts: 4.3.1). * We developed a learning algorithm, learning how to calculate qualitativ data from quantitative data [83]. * The special requirements for learning in robotics yielded in new developed learning algorithms, which are tailor-made for the robot learning tasks, but are general enough to be used as usual logic-based learners <ref> [44, 46, 38] </ref>. 6 DESIGNING LEARNING MOBILE ROBOTS 61 6.4 Technical and methodological issues In contrast to most applications of machine learning, in B-Learn II we did not focus on learning only on a specific level of abstraction (like only learning abstract descriptions or only learning reactive behavior).
Reference: [39] <author> Volker Klingspor, Katharina Morik, and Anke Rieger. </author> <title> Learning concepts from sensor data of a mobile robot. </title> <journal> Machine Learning Journal, </journal> <note> 1996. to appear. </note>
Reference-contexts: An illustrative application of the operations for composing training/test sets for the subtask of learning how to derive sensor features from basic features can be found in [66]. 4.3.2 Application of probabilistic automata In [56] and <ref> [39] </ref>, we have used inductive logic programming algorithms, which learn deterministic rules, represented as Horn clauses, e.g., s_jump (Tr,S,T1,T4,parallel) &lt;- stable (Tr,Or,S,T1,T2,Grad1) & incr_peak (Tr,Or,S,T2,T3,Grad2) & stable (Tr,Or,S,T3,T4,Grad3). The premises of these rules can be considered as sequences of temporally ordered observations 3 , the conclusions as concept classifications.
Reference: [40] <author> Volker Klingspor and Stefan Sklorz. </author> <title> Representing, learning, and executing operational concepts. </title> <editor> In M. Kaiser, editor, </editor> <booktitle> Proc. of the 3rd European Workshop on Learning Robots, </booktitle> <year> 1995. </year>
Reference-contexts: There is a second problem with using a monolithic inference engine: The complete performance system not only consists of a forward chaining part to derive concepts from sensory data, but also a backward chaining part to control the robot, by aid of the operational concepts <ref> [40] </ref>. Therefore, a general inference engine should support different control structures, namely forward and backward chaining. The backward chaining (action) part must know exactly, how far forward chaining (perception) has proceeded, in order to react to the perceptions as soon as possible. <p> ROBOTS 36 4.3.4 Planning and controling robots by operational concepts Whereas most of our work within this project concerns the task of recognizing instances of the learned concepts [37], we designed the representation with the aim to plan sequences of actions, to execute these plans, and to supervise the execution <ref> [40] </ref>. To plan actions, an operator must not only consist of the situation in which it is applicable, but also of the situation, that arises from applying it, to be able to chain multiple operators.
Reference: [41] <author> T. Kohonen. </author> <title> Self-organized formation of topologically correct feature maps. </title> <journal> Biological Cybernetics, </journal> <pages> pages 59 - 69, </pages> <year> 1982. </year>
Reference-contexts: This improvement allows to avoid dangerous actions resulting from exploration (for further details see [49, 52]. A second approach to learn reactive navigation skills that is based on self-organizing maps (SOM) <ref> [41, 42] </ref>. In order to learn continuously and incrementally, we have developed a dynamical self-organizing map (DSOM) [21], where units are added incrementally as they are required to better cover the experienced part of the sensory space.
Reference: [42] <author> T. Kohonen. </author> <title> Self-Organizing Maps. </title> <publisher> Springer Verlag, </publisher> <address> Heidelberg, </address> <year> 1995. </year>
Reference-contexts: This improvement allows to avoid dangerous actions resulting from exploration (for further details see [49, 52]. A second approach to learn reactive navigation skills that is based on self-organizing maps (SOM) <ref> [41, 42] </ref>. In order to learn continuously and incrementally, we have developed a dynamical self-organizing map (DSOM) [21], where units are added incrementally as they are required to better cover the experienced part of the sensory space.
Reference: [43] <author> T.-Y. Kwok and D.-Y. Yeung. </author> <title> Constructive feedforward neural networks for regression problems: A survey. </title> <type> Technical Report HKUST-CS95-43, </type> <institution> Hong Kong University of Science and Technology, Department of Computer Science, </institution> <year> 1995. </year>
Reference-contexts: The investigation of several function approximation techniques throughout B-Learn II [59, 33, 17, 65, 34, 3, 21, 48, 49, 52, 50] lead to the selection of neural networks based on local receptive fields [54], such as Radial-Basis Function Networks (RBFs) [62]. Such networks can be built from training data <ref> [54, 57, 3, 43] </ref>, which is extremely important in a setting that asks for automatization of the learning phase. Additionally, these networks do also allow for directly assessing the knowledge that is available with respect to a particular situation.
Reference: [44] <author> Guido Lindner. </author> <note> Logikbasiertes Lernen in relationalen Datenbanken. LS-8 Report No. 12, </note> <institution> University of Dortmund, Lehrstuhl Informatik VIII, D-44221 Dortmund, </institution> <month> September </month> <year> 1994. </year>
Reference-contexts: 4.3.1). * We developed a learning algorithm, learning how to calculate qualitativ data from quantitative data [83]. * The special requirements for learning in robotics yielded in new developed learning algorithms, which are tailor-made for the robot learning tasks, but are general enough to be used as usual logic-based learners <ref> [44, 46, 38] </ref>. 6 DESIGNING LEARNING MOBILE ROBOTS 61 6.4 Technical and methodological issues In contrast to most applications of machine learning, in B-Learn II we did not focus on learning only on a specific level of abstraction (like only learning abstract descriptions or only learning reactive behavior).
Reference: [45] <author> S. Liu and H. Asada. </author> <title> Teaching and learning of deburring robots using neural networks. </title> <booktitle> In Proceedings of the IEEE International Conference on Robotics and Automation, </booktitle> <address> Atlanta, Georgia, </address> <year> 1993. </year>
Reference-contexts: Therefore, it is necessary that the representation can be constructed from the training data. Secondly, the chosen representation must allow for incremental learning, since online adaptation of the skill is mandatory. Both requirements exclude, for instance, multilayer perceptrons (MLPs) or conventional decision-tree techniques <ref> [63, 45, 74] </ref> from being used in a general approach. Also, the specification of the functional form of the skill by the user, which reduces skill learning to the identification of numerical parameters [2], is not an appropriate solution.
Reference: [46] <institution> Marcus Lubbe. Datengesteuertes Lernen von syntaktischen Einschrankungen des Hypothesen-raums fur modellbasiertes Lernen. </institution> <note> LS-8 Report No. 15, </note> <institution> University of Dortmund, Lehrstuhl Informatik VIII, D-44221 Dortmund, </institution> <month> March </month> <year> 1995. </year>
Reference-contexts: In addition to the results concerning robotics, we provide results to the machine learning community: * The training data consists of a huge amount of data, we provided a learning tool that learns from data stored by a database management system (ORACLE) <ref> [46] </ref>. * For testing the learning algorithms and the representation, many different variations of representing the same data is needed. To be able to handle these variatons is crucial, when learning results feed back to the choice of the parameters for calculating basic features [83]. <p> 4.3.1). * We developed a learning algorithm, learning how to calculate qualitativ data from quantitative data [83]. * The special requirements for learning in robotics yielded in new developed learning algorithms, which are tailor-made for the robot learning tasks, but are general enough to be used as usual logic-based learners <ref> [44, 46, 38] </ref>. 6 DESIGNING LEARNING MOBILE ROBOTS 61 6.4 Technical and methodological issues In contrast to most applications of machine learning, in B-Learn II we did not focus on learning only on a specific level of abstraction (like only learning abstract descriptions or only learning reactive behavior).
Reference: [47] <author> J. del R. Millan. </author> <title> Building reactive path-finders through reinforcement connectionist learning: Three issues and an architecture. </title> <booktitle> In Proceedings of the Tenth European Conference on Artificial Intelligence, </booktitle> <pages> pages 661 - 665, </pages> <year> 1992. </year>
Reference-contexts: Secondly, we adopt the argument followed also in workpackage 2 [58, 59] and in our previous work <ref> [51, 47] </ref>: For representing elementary robot skills, we apply neural networks representing the target function locally. As shown in [3, 59], these networks have a direct symbolic interpretation. 8.
Reference: [48] <author> J. del R. Millan. </author> <title> Learning efficient reactive behavioral sequences from basic reflexes in a goal-directed autonomous robot. </title> <booktitle> In Proceedings of the third International Conference on Simulation of Adaptive Behavior, </booktitle> <year> 1994. </year> <note> REFERENCES 65 </note>
Reference-contexts: Also, the specification of the functional form of the skill by the user, which reduces skill learning to the identification of numerical parameters [2], is not an appropriate solution. The investigation of several function approximation techniques throughout B-Learn II <ref> [59, 33, 17, 65, 34, 3, 21, 48, 49, 52, 50] </ref> lead to the selection of neural networks based on local receptive fields [54], such as Radial-Basis Function Networks (RBFs) [62].
Reference: [49] <author> J. del R. Millan. </author> <title> Reinforcement learning of goal-directed obstacle-avoiding reaction strategies in an autonomous mobile robot. </title> <booktitle> Robotics and Autonomous Systems, </booktitle> <volume> 15(3), </volume> <year> 1995. </year>
Reference-contexts: Also, the specification of the functional form of the skill by the user, which reduces skill learning to the identification of numerical parameters [2], is not an appropriate solution. The investigation of several function approximation techniques throughout B-Learn II <ref> [59, 33, 17, 65, 34, 3, 21, 48, 49, 52, 50] </ref> lead to the selection of neural networks based on local receptive fields [54], such as Radial-Basis Function Networks (RBFs) [62]. <p> The third improvement is the use of a counter-based scheme to concentrate the search around the best currently known actions, depending on the specific experience of the robot. This improvement allows to avoid dangerous actions resulting from exploration (for further details see <ref> [49, 52] </ref>. A second approach to learn reactive navigation skills that is based on self-organizing maps (SOM) [41, 42].
Reference: [50] <author> J. del R. Millan. </author> <title> Rapid, safe, and incremental learning of navigation strategies. </title> <journal> IEEE Transactions on Systems, Man and Cybernetics, </journal> <volume> 26(6), </volume> <year> 1996. </year>
Reference-contexts: Also, the specification of the functional form of the skill by the user, which reduces skill learning to the identification of numerical parameters [2], is not an appropriate solution. The investigation of several function approximation techniques throughout B-Learn II <ref> [59, 33, 17, 65, 34, 3, 21, 48, 49, 52, 50] </ref> lead to the selection of neural networks based on local receptive fields [54], such as Radial-Basis Function Networks (RBFs) [62].
Reference: [51] <author> J. del R. Millan and C. Torras. </author> <title> A reinforcement connectionist approach to robot path finding in non-maze-like environments. </title> <journal> Machine Learning, </journal> <volume> 8:363 - 395, </volume> <year> 1992. </year>
Reference-contexts: Secondly, we adopt the argument followed also in workpackage 2 [58, 59] and in our previous work <ref> [51, 47] </ref>: For representing elementary robot skills, we apply neural networks representing the target function locally. As shown in [3, 59], these networks have a direct symbolic interpretation. 8.
Reference: [52] <author> J. del R. Millan and C. Torras. </author> <title> Efficient reinforcement learning of navigation strategies in an autonomous robot. </title> <editor> In V. Graefe, editor, </editor> <booktitle> Intelligent Robots and Systems. </booktitle> <publisher> Elsevier Science, </publisher> <year> 1995. </year>
Reference-contexts: Also, the specification of the functional form of the skill by the user, which reduces skill learning to the identification of numerical parameters [2], is not an appropriate solution. The investigation of several function approximation techniques throughout B-Learn II <ref> [59, 33, 17, 65, 34, 3, 21, 48, 49, 52, 50] </ref> lead to the selection of neural networks based on local receptive fields [54], such as Radial-Basis Function Networks (RBFs) [62]. <p> The third improvement is the use of a counter-based scheme to concentrate the search around the best currently known actions, depending on the specific experience of the robot. This improvement allows to avoid dangerous actions resulting from exploration (for further details see <ref> [49, 52] </ref>. A second approach to learn reactive navigation skills that is based on self-organizing maps (SOM) [41, 42].
Reference: [53] <author> C. Moneta and F.G.B. De Natale. </author> <title> Adaptive control in visual sensing. </title> <booktitle> In Proceedings of the IMACS International Symposium on Signal Processing, Robotics, and Neural Networks, </booktitle> <year> 1994. </year>
Reference-contexts: This cycle is iterated until an acceptable average quality of the current image has been obtained. The evaluation of the image quality is performed by computing a set of features related to both the gradient magnitude and the histogram analysis <ref> [33, 53] </ref>.
Reference: [54] <author> J. Moody and C. Darken. </author> <title> Learning with localized receptive fields. </title> <editor> In T. Sejnowski D. Touretzky, G. Hinton, editor, </editor> <booktitle> Proceedings of the Connectionist Models Summer School. </booktitle> <institution> Carnegie Mellon University, </institution> <year> 1988. </year>
Reference-contexts: The investigation of several function approximation techniques throughout B-Learn II [59, 33, 17, 65, 34, 3, 21, 48, 49, 52, 50] lead to the selection of neural networks based on local receptive fields <ref> [54] </ref>, such as Radial-Basis Function Networks (RBFs) [62]. Such networks can be built from training data [54, 57, 3, 43], which is extremely important in a setting that asks for automatization of the learning phase. <p> The investigation of several function approximation techniques throughout B-Learn II [59, 33, 17, 65, 34, 3, 21, 48, 49, 52, 50] lead to the selection of neural networks based on local receptive fields [54], such as Radial-Basis Function Networks (RBFs) [62]. Such networks can be built from training data <ref> [54, 57, 3, 43] </ref>, which is extremely important in a setting that asks for automatization of the learning phase. Additionally, these networks do also allow for directly assessing the knowledge that is available with respect to a particular situation.
Reference: [55] <author> K. Morik, S. Wrobel, J.-U. Kietz, and W. Emde. </author> <title> Knowledge Acquisition and Machine Learning Theory, Methods, and Applications. </title> <publisher> Academic Press, </publisher> <address> London, </address> <year> 1993. </year>
Reference-contexts: Some efforts have been made in order to support the layout of the knowledge representation language by a system, define sets of defining predicates for a learning goal, and to automatically adjust the representation language <ref> [55] </ref>, [85]. However, there are additional tasks that are not yet supported by tools. Hence, it was our goal to provide a general tool for the preparation of data for relational learning.
Reference: [56] <author> Katharina Morik and Anke Rieger. </author> <title> Learning action-oriented perceptual features for robot navigation. </title> <editor> In Attilio Giordana, editor, </editor> <booktitle> Learning Robots Proceedings of ECML Workshop. </booktitle> <year> 1993. </year>
Reference-contexts: However, if objects are represented both in terms of robot actions and robot perceptions, both concepts and can be easily distinguished. To combine perceptions and actions in a concept description is the basic idea of operational concepts <ref> [56, 37] </ref>. For learning these concepts, several techniques have been developed within B-Learn II. <p> An illustrative application of the operations for composing training/test sets for the subtask of learning how to derive sensor features from basic features can be found in [66]. 4.3.2 Application of probabilistic automata In <ref> [56] </ref> and [39], we have used inductive logic programming algorithms, which learn deterministic rules, represented as Horn clauses, e.g., s_jump (Tr,S,T1,T4,parallel) &lt;- stable (Tr,Or,S,T1,T2,Grad1) & incr_peak (Tr,Or,S,T2,T3,Grad2) & stable (Tr,Or,S,T3,T4,Grad3).
Reference: [57] <author> M.T. Musavi, W. Ahmed, K.H. Chan, </author> <title> K.B. Faris, and D.M. Hummels. On the training of radial basis function classifiers. Neural Networks, </title> <address> 5:595 - 603, </address> <year> 1992. </year>
Reference-contexts: The investigation of several function approximation techniques throughout B-Learn II [59, 33, 17, 65, 34, 3, 21, 48, 49, 52, 50] lead to the selection of neural networks based on local receptive fields [54], such as Radial-Basis Function Networks (RBFs) [62]. Such networks can be built from training data <ref> [54, 57, 3, 43] </ref>, which is extremely important in a setting that asks for automatization of the learning phase. Additionally, these networks do also allow for directly assessing the knowledge that is available with respect to a particular situation.
Reference: [58] <author> M. Nuttin, A. Giordana, M. Kaiser, and R. </author> <title> Suarez. B-Learn II - D 202. B-Learn II ESPRIT BRA Project No. </title> <type> 7274, </type> <year> 1993. </year>
Reference-contexts: Firstly, operational concepts do exactly what is required - an instance of a concept is detected if the robot has performed a certain sequence of actions that resulted in an appropriate sequence of perceptions. Secondly, we adopt the argument followed also in workpackage 2 <ref> [58, 59] </ref> and in our previous work [51, 47]: For representing elementary robot skills, we apply neural networks representing the target function locally. As shown in [3, 59], these networks have a direct symbolic interpretation. 8.
Reference: [59] <author> M. Nuttin, A. Giordana, M. Kaiser, and R. </author> <title> Suarez. B-Learn II - D 203. B-Learn II ESPRIT BRA Project No. </title> <type> 7274, </type> <year> 1994. </year>
Reference-contexts: Firstly, operational concepts do exactly what is required - an instance of a concept is detected if the robot has performed a certain sequence of actions that resulted in an appropriate sequence of perceptions. Secondly, we adopt the argument followed also in workpackage 2 <ref> [58, 59] </ref> and in our previous work [51, 47]: For representing elementary robot skills, we apply neural networks representing the target function locally. As shown in [3, 59], these networks have a direct symbolic interpretation. 8. <p> Secondly, we adopt the argument followed also in workpackage 2 [58, 59] and in our previous work [51, 47]: For representing elementary robot skills, we apply neural networks representing the target function locally. As shown in <ref> [3, 59] </ref>, these networks have a direct symbolic interpretation. 8. <p> During the last year of B-Learn II, we extended this approach, also following developments of workpackage 2 <ref> [59, 60] </ref>, in order to allow for an automatic preprocessing of sampled data as well as an easy configuration of the learning techniques in use. <p> human demonstration is to approximate the functions C s ; r s ; t s ; and e s from data obtained during human performance of the skill s: What is special about basic mobility skills? During the demonstration of manipulation skills, usually a force/torque sensor provides the robot's perceptions <ref> [59, 60, 35] </ref>. Such a sensor is able to deliver information at a rate of at least 30 [Hz]; such that a demonstration of 20 seconds length results in more than 600 single training samples. <p> Also, the specification of the functional form of the skill by the user, which reduces skill learning to the identification of numerical parameters [2], is not an appropriate solution. The investigation of several function approximation techniques throughout B-Learn II <ref> [59, 33, 17, 65, 34, 3, 21, 48, 49, 52, 50] </ref> lead to the selection of neural networks based on local receptive fields [54], such as Radial-Basis Function Networks (RBFs) [62]. <p> In B-Learn II's workpackages 2 and 4 <ref> [31, 59, 60] </ref>, we have exploited the potential of neural networks as trainable model-free function approximators for solving such control tasks.
Reference: [60] <author> M. Nuttin, A. Giordana, M. Kaiser, and R. </author> <title> Suarez. B-Learn II - D 204. B-Learn II ESPRIT BRA Project No. </title> <type> 7274, </type> <year> 1995. </year>
Reference-contexts: During the last year of B-Learn II, we extended this approach, also following developments of workpackage 2 <ref> [59, 60] </ref>, in order to allow for an automatic preprocessing of sampled data as well as an easy configuration of the learning techniques in use. <p> human demonstration is to approximate the functions C s ; r s ; t s ; and e s from data obtained during human performance of the skill s: What is special about basic mobility skills? During the demonstration of manipulation skills, usually a force/torque sensor provides the robot's perceptions <ref> [59, 60, 35] </ref>. Such a sensor is able to deliver information at a rate of at least 30 [Hz]; such that a demonstration of 20 seconds length results in more than 600 single training samples. <p> Apart from the identification of relevant perception components, the techniques to perform this kind of preprocessing are equal to those discussed in deliverable 204 <ref> [60] </ref>. However, in 4 TRANSFERRING SKILLS AND KNOWLEDGE TO MOBILE ROBOTS 13 case of manipulation skills that require compliant motion, often a direct and constant dependency between the change in perceptions (e.g., forces and torques) and the commanded actions exists. <p> I.e., by checking the activation of the individual clusters available in such a network, it is possible to easily distinguish if the network is recalling an example it has seen before or if it is generalizing. For building C s and r s ; the clustering algorithm described in <ref> [60] </ref> is applied to generate the initial network. Afterwards, the resulting networks are trained with error backpropagation. <p> For C s ; training proceeds until the convergence criterion u fl = ffu; ffi ff ff 1; 0 &lt; ffi ff &lt; 1 is fulfilled for all given actions u and all learned actions u fl : As described in <ref> [60] </ref>, the choice of ffi ff depends on the quality of the human demonstration. Usually, we have ffi ff 2 [0:6; 0:8]: Due to the uncertainty about the human's performance, the convergence criterion for the approximation of r s is also not very strict. <p> Other approaches to solve the problem of structural learnigng have recently been investigated in a cooperation between UKA and UTO in the context of workpackage 2 <ref> [36, 60] </ref>. 4 TRANSFERRING SKILLS AND KNOWLEDGE TO MOBILE ROBOTS 41 The only kind of information that can be expected from the user during the skill application and refinement process is an evaluation after the termination of the skill execution 7 . <p> In B-Learn II's workpackages 2 and 4 <ref> [31, 59, 60] </ref>, we have exploited the potential of neural networks as trainable model-free function approximators for solving such control tasks.
Reference: [61] <author> A. Okabe, B. Boots, and K. Sugihara. </author> <title> Saptial Tessellations: Concepts and Applications of Voronoi Diagrams. </title> <publisher> Wiley & Sons, </publisher> <year> 1992. </year>
Reference-contexts: For mobile robots, a topological graph (Fig. 20) of the environment is such a representation. To autmatically generate topological graphs from a geometrical model of the environment, literature often proposes Voronoi diagrams <ref> [14, 61] </ref>. Voronoi diagrams are solutions of minimal distance problems. Edges of a Voronoi diagram represent points in space that feature an equal distance to two distinct points of a given set of subspaces.
Reference: [62] <author> T. Poggio and F. Girosi. </author> <title> Networks for approximation and learning. </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> 78(9) </volume> <pages> 1481-1497, </pages> <month> September </month> <year> 1990. </year>
Reference-contexts: The investigation of several function approximation techniques throughout B-Learn II [59, 33, 17, 65, 34, 3, 21, 48, 49, 52, 50] lead to the selection of neural networks based on local receptive fields [54], such as Radial-Basis Function Networks (RBFs) <ref> [62] </ref>. Such networks can be built from training data [54, 57, 3, 43], which is extremely important in a setting that asks for automatization of the learning phase. Additionally, these networks do also allow for directly assessing the knowledge that is available with respect to a particular situation.
Reference: [63] <author> D. A. Pomerleau. </author> <title> Efficient training of artificial neural networks for autonomous navigation. </title> <journal> Neural Computation, </journal> <volume> 3:88 - 97, </volume> <year> 1991. </year>
Reference-contexts: To this aim, the formalism to be used to represent these functions has to be selected first. This is in general done ad hoc, i.e., the representation is chosen to be suitable for learning a specific skill under specific conditions <ref> [2, 63, 23] </ref>. However, an untrained user cannot be expected to perform this selection for every skill he/she wants the robot to acquire. Therefore, it is necessary that the representation can be constructed from the training data. <p> Therefore, it is necessary that the representation can be constructed from the training data. Secondly, the chosen representation must allow for incremental learning, since online adaptation of the skill is mandatory. Both requirements exclude, for instance, multilayer perceptrons (MLPs) or conventional decision-tree techniques <ref> [63, 45, 74] </ref> from being used in a general approach. Also, the specification of the functional form of the skill by the user, which reduces skill learning to the identification of numerical parameters [2], is not an appropriate solution.
Reference: [64] <author> P. Reignier, V. Hansen, and J.L. Crowley. </author> <title> Incremental supervised learning for mobile robot reactive control. </title> <booktitle> In Intelligent Autonomous Systems 4 (IAS-4), </booktitle> <pages> pages 287 - 294. </pages> <publisher> IOS Press, </publisher> <year> 1995. </year>
Reference-contexts: In this particular case, the initial collision avoidance skill was acquired by means of a user demonstration. Similar to the work described in <ref> [64] </ref>, the robot was driven manually through the environment. During this demonstration, the ultrasonic measurements as well as the commands given by the operator were recorded (Fig. 27).
Reference: [65] <author> A. Retey. </author> <title> Konnektionistische Verfahren zur Analyse und Modellierung dynamischer Systeme. </title> <type> Master's thesis, </type> <institution> Universitat Karlsruhe, Fakultat fur Informatik, Institut fur Prozerechentechnik und Robotik, </institution> <year> 1995. </year>
Reference-contexts: Also, the specification of the functional form of the skill by the user, which reduces skill learning to the identification of numerical parameters [2], is not an appropriate solution. The investigation of several function approximation techniques throughout B-Learn II <ref> [59, 33, 17, 65, 34, 3, 21, 48, 49, 52, 50] </ref> lead to the selection of neural networks based on local receptive fields [54], such as Radial-Basis Function Networks (RBFs) [62]. <p> We found that despite the networks' theoretical capability of total approximation, many other aspects must be taken into account when using neural networks for real-world adaptive control <ref> [65, 34, 26] </ref>: * the amount and quality of a-priori knowledge, * the costs of taking samples from the system, * the quality of knowledge usable for adaptation, * the costs of non-optimal control and exploration, * the dimension of the input space, and * the estimated statistic and systematic errors.
Reference: [66] <author> A. Rieger. </author> <title> Data preparation for inductive learning in robotics. </title> <booktitle> In Working Notes of the IJCAI-Workshop on Data Engineering for Inductive Learning, </booktitle> <year> 1995. </year> <note> also available as LS8-Report 19, </note> <institution> University of Dortmund. </institution>
Reference-contexts: In this section, we have sketched the general data preparation operations, which are provided by our tool. An illustrative application of the operations for composing training/test sets for the subtask of learning how to derive sensor features from basic features can be found in <ref> [66] </ref>. 4.3.2 Application of probabilistic automata In [56] and [39], we have used inductive logic programming algorithms, which learn deterministic rules, represented as Horn clauses, e.g., s_jump (Tr,S,T1,T4,parallel) &lt;- stable (Tr,Or,S,T1,T2,Grad1) & incr_peak (Tr,Or,S,T2,T3,Grad2) & stable (Tr,Or,S,T3,T4,Grad3).
Reference: [67] <author> A. Rieger. </author> <title> Inferring probabilistic automata from sensor data for robot navigation. </title> <booktitle> In Procs. of the 3rd European Workshop on Learning Robots, </booktitle> <year> 1995. </year> <note> also available as LS-8 Report 18, </note> <institution> University of Dortmund. </institution>
Reference-contexts: In the former case, it supports the decision, which concept has been recognized most probably. More technical details and an illustration of the method with the subtask of learning how to derive sensor features from basic features can be found in <ref> [67] </ref> and [68]. Future work will include extensive experiments on the data for a performance evaluation of both, deterministic and probabilistic, automata models. There are several possibilities for post-processing of the automata models, in order to improve their performance.
Reference: [68] <author> A. Rieger. </author> <title> Learning to guide a robot via perceptions. </title> <booktitle> In Procs. of the Third European Workshop on Planning, </booktitle> <year> 1995. </year> <note> REFERENCES 66 </note>
Reference-contexts: In the former case, it supports the decision, which concept has been recognized most probably. More technical details and an illustration of the method with the subtask of learning how to derive sensor features from basic features can be found in [67] and <ref> [68] </ref>. Future work will include extensive experiments on the data for a performance evaluation of both, deterministic and probabilistic, automata models. There are several possibilities for post-processing of the automata models, in order to improve their performance.
Reference: [69] <author> Celine Rouveirol and Jean Fran~cois Puget. </author> <title> Beyond inversion of resolution. </title> <editor> In B.W. Porter and R.J. Mooney, editors, </editor> <booktitle> Proc. Seventh Intern. Conf. on Machine Learning, </booktitle> <pages> pages 122-130, </pages> <address> Palo Alto, CA, 1990. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: [70] <author> R. D. Schraft. </author> <title> Serviceroboter - ein Beitrag zur Innovation im Dienstleistungswesen. </title> <institution> Fraunhofer -Institut fur Produktionstechnik und Automatisierung (IPA), </institution> <year> 1994. </year>
Reference: [71] <author> Horst Spandl and Knut Pitschke. </author> <title> Lernen von Makro-Trajektorien fur einen autonomen Roboter. </title> <booktitle> KI, </booktitle> <pages> pages 12-16, </pages> <year> 1991. </year>
Reference-contexts: The graphs found by the first approach can be stored and used as macro operators in further situations, corresponding to the work on learning macro-trajectories <ref> [71] </ref>, but on a conceptual level. 4 TRANSFERRING SKILLS AND KNOWLEDGE TO MOBILE ROBOTS 39 4.4 Efficient application of basic mobility skills The efficient application and refinement of basic mobility skills has to consider two levels of abstraction (Fig. 19).
Reference: [72] <author> R. S. Sutton. </author> <title> Learning to predict by methods of temporal difference. </title> <journal> Machine Learning, </journal> <volume> 3:9 - 44, </volume> <year> 1988. </year>
Reference-contexts: To solve this task, two different learning rules, namely temporal difference (TD) methods <ref> [72] </ref> and associative search (AS) [4, 84] are used, where TD methods are employed to predict the total future reward and AS is used to update the situation-action mapping based on the estimation given by TD.
Reference: [73] <author> S. B. Thrun. </author> <title> Efficient exploration in reinforcement learning. </title> <type> Technical Report CMU-CS-92-102, </type> <institution> Carnegie-Mellon University, </institution> <year> 1992. </year>
Reference-contexts: If only a weak function that can be provided by an unexperienced user is applied, adaptation can take a long time. On the other hand, a sophisticated evaluation function or sophisticated adaptation mechanisms often incorporates a lot of knowledge about the function to be learned (e.g., <ref> [73, 19] </ref>). Then, it might even be easier to directly encoded the control function.
Reference: [74] <author> T. Urbancic and I. Bratko. </author> <title> Reconstructing human skill with machine learning. </title> <booktitle> In Proceedings of the ECAI '94, </booktitle> <address> Amsterdam, </address> <year> 1994. </year>
Reference-contexts: Therefore, it is necessary that the representation can be constructed from the training data. Secondly, the chosen representation must allow for incremental learning, since online adaptation of the skill is mandatory. Both requirements exclude, for instance, multilayer perceptrons (MLPs) or conventional decision-tree techniques <ref> [63, 45, 74] </ref> from being used in a general approach. Also, the specification of the functional form of the skill by the user, which reduces skill learning to the identification of numerical parameters [2], is not an appropriate solution.
Reference: [75] <author> F. Wallner and R. Dillmann. </author> <title> Efficient mapping of dynamic environment by use of sonar and active stereo-vision. </title> <booktitle> In International Symposium on Intelligent Robotic Systems `94, </booktitle> <address> Grenoble, </address> <year> 1994. </year>
Reference-contexts: To build a map of the environment, we found that conventional techniques were quite able to perform this task, so we also relied on those <ref> [75, 76] </ref>. As the mapping principle has not been completely described in any of the deliverables, we give a short example in section 3. 4. Learning multi-level concepts descriptions and 5. Learning concept structures: The key idea for the solution of these tasks is that of operational concepts.
Reference: [76] <author> F. Wallner, R. Graf, and R. Dillmann. </author> <title> Real-time map refinement by fusing sonar and active stereo vision. </title> <booktitle> In IEEE International Conference on Robotics and Automation, </booktitle> <year> 1995. </year>
Reference-contexts: To build a map of the environment, we found that conventional techniques were quite able to perform this task, so we also relied on those <ref> [75, 76] </ref>. As the mapping principle has not been completely described in any of the deliverables, we give a short example in section 3. 4. Learning multi-level concepts descriptions and 5. Learning concept structures: The key idea for the solution of these tasks is that of operational concepts.
Reference: [77] <author> F. Wallner, R. Graf, and R. Dillmann. </author> <title> Real-time map refinement by fusing sonar and active stereo-vision. </title> <booktitle> In IEEE International Conference on Robotics and Automation, </booktitle> <address> Nagoya, </address> <year> 1995. </year>
Reference-contexts: and tuning of these skills then becomes an integral part of an hierarchical adaptation process: as soon as tuning doesn't yield the required performance, the creation of a new skill, i.e., the solution of learning task 1 becomes again necessary. 3 Mapping the robot's environment The following example (see also <ref> [77] </ref>) surveys the working principle of PRIAMOS' map building and refinement procedure. PRIAMOS operates in an office environment and moves on a path that has been planned according to a specified mission [31, 78, 79]. The robot continuously observes its surroundings in order to improve the world model.
Reference: [78] <author> F. Wallner, M. Kaiser, H. Friedrich, and R. Dillmann. </author> <title> Integrated topological and geometrical planning in a learning mobile robot. </title> <booktitle> In IEEE/RSJ International Conference on Intelligent Robots and Systems, </booktitle> <address> Munich, Germany, </address> <year> 1994. </year>
Reference-contexts: Acquiring basic mobility skills: This task is related to building the robot's basic operative intelligence. We tackle it by means of two complementary approaches, i.e., through autonomous learning and by learning from human demonstrations. However, since appropriate conventional for both geometrical and topological planning exist <ref> [78, 79] </ref>, we apply those techniques for standard tasks and learn only those skills that are difficult to model analytically and require high reactivity. 2. <p> PRIAMOS operates in an office environment and moves on a path that has been planned according to a specified mission <ref> [31, 78, 79] </ref>. The robot continuously observes its surroundings in order to improve the world model. Fig. 5 shows the mapping steps performed during an example run. A number of probability grids [11] are generated due to sonar reflections or imprecise object models that result in unexpected echoes. <p> If, for instance, the elementary operations belonging to a certain class (e.g., all Docking-EOs) are only executed in a known context, with the context information being linked to the environment, this strategy may be represented by the skills assigned to the edges of a topological map <ref> [78, 79, 27] </ref>.
Reference: [79] <author> F. Wallner, M. Kaiser, H. Friedrich, and R. Dillmann. </author> <title> A multilevel learning approach to mobile robot path planning. </title> <editor> In V. Graefe, editor, </editor> <booktitle> Intelligent Robots and Systems. </booktitle> <publisher> Elsevier Science, </publisher> <year> 1995. </year>
Reference-contexts: Acquiring basic mobility skills: This task is related to building the robot's basic operative intelligence. We tackle it by means of two complementary approaches, i.e., through autonomous learning and by learning from human demonstrations. However, since appropriate conventional for both geometrical and topological planning exist <ref> [78, 79] </ref>, we apply those techniques for standard tasks and learn only those skills that are difficult to model analytically and require high reactivity. 2. <p> PRIAMOS operates in an office environment and moves on a path that has been planned according to a specified mission <ref> [31, 78, 79] </ref>. The robot continuously observes its surroundings in order to improve the world model. Fig. 5 shows the mapping steps performed during an example run. A number of probability grids [11] are generated due to sonar reflections or imprecise object models that result in unexpected echoes. <p> If, for instance, the elementary operations belonging to a certain class (e.g., all Docking-EOs) are only executed in a known context, with the context information being linked to the environment, this strategy may be represented by the skills assigned to the edges of a topological map <ref> [78, 79, 27] </ref>.
Reference: [80] <author> C. J. C. H. Watkins. </author> <title> Learning with delayed rewards. </title> <type> PhD thesis, </type> <institution> University of Cambridge, </institution> <year> 1989. </year>
Reference-contexts: The task on this level can therefore be stated as Given: A context C requiring the execution of an EO of a specific class. Determine: The EO e that maximizes a given evaluation criterion related to C. 5 LEARNING IN THE REAL WORLD: EXPERIMENTAL EVALUATION 45 Q-Learning <ref> [80, 81] </ref> is an appropriate technique for solving this learning task.
Reference: [81] <author> C. J. C. H. Watkins. </author> <title> A technical note on Q-Learning. </title> <journal> Machine Learning, </journal> <volume> 8, </volume> <year> 1992. </year>
Reference-contexts: The task on this level can therefore be stated as Given: A context C requiring the execution of an EO of a specific class. Determine: The EO e that maximizes a given evaluation criterion related to C. 5 LEARNING IN THE REAL WORLD: EXPERIMENTAL EVALUATION 45 Q-Learning <ref> [80, 81] </ref> is an appropriate technique for solving this learning task.
Reference: [82] <author> P. Wellman, V. Krovi, and V. Kumar. </author> <title> An adaptive mobility system for the disabled. </title> <booktitle> In IEEE International Conference on Robotics and Automation, </booktitle> <address> San Diego, California, </address> <year> 1994. </year>
Reference: [83] <author> Stefanie Wessel. </author> <title> Lernen qualitativer Merkmale aus numerischen Robotersensordaten. </title> <type> Master's thesis, </type> <institution> Universitat Dortmund, </institution> <year> 1995. </year>
Reference-contexts: To be able to handle these variatons is crucial, when learning results feed back to the choice of the parameters for calculating basic features <ref> [83] </ref>. <p> different variations and allowing to generate and inspect the data, and to start learning runs. * Testing learning needs the selection of training and test data, based on syntactical and statistical criteria (see Sect. 4.3.1). * We developed a learning algorithm, learning how to calculate qualitativ data from quantitative data <ref> [83] </ref>. * The special requirements for learning in robotics yielded in new developed learning algorithms, which are tailor-made for the robot learning tasks, but are general enough to be used as usual logic-based learners [44, 46, 38]. 6 DESIGNING LEARNING MOBILE ROBOTS 61 6.4 Technical and methodological issues In contrast to
Reference: [84] <author> R. J. Williams. </author> <title> Simple statistical gradient-following algorithms for connectionist reinforcement learning. </title> <booktitle> Machine Learning, </booktitle> <pages> pages 229 -256, </pages> <year> 1992. </year>
Reference-contexts: Then, we define the termination criterion as hypercube with the goal state as its center and a suitable width. 4.1.2 Autonomous learning of basic mobility skills A possibility to learn basic mobility skills autonomously is to follow the line of reinforcement learning <ref> [4, 84] </ref>. The robot then has to learn suitable reactions directly from a feedback signal, which, in the simplest case, is positive as soon as the robot achieves the goal (e.g., it passes the door), and is negative otherwise. <p> To solve this task, two different learning rules, namely temporal difference (TD) methods [72] and associative search (AS) <ref> [4, 84] </ref> are used, where TD methods are employed to predict the total future reward and AS is used to update the situation-action mapping based on the estimation given by TD.
Reference: [85] <author> S. Wrobel. </author> <title> Concept Formation and Knowledge Revision. </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1994. </year>
Reference-contexts: Some efforts have been made in order to support the layout of the knowledge representation language by a system, define sets of defining predicates for a learning goal, and to automatically adjust the representation language [55], <ref> [85] </ref>. However, there are additional tasks that are not yet supported by tools. Hence, it was our goal to provide a general tool for the preparation of data for relational learning.
References-found: 85

