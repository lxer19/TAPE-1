URL: http://polaris.cs.uiuc.edu/reports/826.ps.gz
Refering-URL: http://polaris.cs.uiuc.edu/tech_reports.html
Root-URL: http://www.cs.uiuc.edu
Title: Matrix Visualization in the Design of Numerical Algorithms  
Author: Allan M. Tuchman Michael W. Berry 
Date: May 1989  
Abstract: 1 Center for Supercomputing Research and Development, University of Illinois at Urbana-Champaign, 305 Talbot Laboratory, 104 South Wright Street, Urbana, IL, 61801-2932. Research supported by the U.S. Department of Energy under Grant No. DE-FG02-85-ER25001, National Science Foundation Grant No. NSF MIP-8410110, and the Air Force Office of Scientific Research Grants Nos. AFOSR-F49620-86-C-0136 and AFOSR-85-0211. tuchman%uicsrd@a.cs.uiuc.edu (217) 244-0048 2 Center for Supercomputing Research and Development, University of Illinois at Urbana-Champaign, 305 Talbot Laboratory, 104 South Wright Street, Ur-bana, IL, 61801-2932. Research supported by the U.S. Department of Energy under Grant No. DE-FG02-85-ER25001, National Science Foundation Grants Nos. NSF MIP-8410110, CCR-8717942 and CCR-890003N (NCSA/Cray Research), and the AT&T Corporation under Grant No. AT&T-AFFL-67-SAMEH. berry%uicsrd@a.cs.uiuc.edu (217) 244-0047 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. Berry and A. Sameh. </author> <title> Multiprocessor jacobi schemes for dense symmetric eigenvalue and singular value decompositions. </title> <type> Technical Report 546, </type> <institution> University of Illinois at Urbana-Champaign, Center for Supercomputing Research and Development, </institution> <year> 1986. </year>
Reference-contexts: Thus we can realize the decomposition in (1) after deter mining the matrix ~ V in (4). 15 As discussed in <ref> [1] </ref> and [3], the matrix ~ V is constructed via (i; j) plane rotations so that r T where r i designates the i-th column of R R ~ V. <p> A parallel scheme for ordering the (i; j) plane rotations used in the orthogonalization of the columns of R is given in <ref> [1] </ref> and [3]. Sweeps of n (n 1)=2 plane rotations are applied to R until convergence is achieved.
Reference: [2] <author> M. Berry and A. Sameh. </author> <title> A hybrid scheme for the singular value decomposition on a multiprocessor. </title> <address> Leuven, Belgium, </address> <month> August </month> <year> 1988. </year> <title> NATO Adv. Study Institute on Digital Signal Processing and Numerical Linear Algebra. </title>
Reference-contexts: Given the increasing availability of multiprocessor computer systems, there is also great interest in developing fast parallel algorithms for computing the singular value decomposition. In the preceding sections, we discuss a recent hybrid multiprocessor SVD method by Berry and Sameh ([3] and <ref> [2] </ref>) whose behavior has been extensively analyzed through the use of MatVu. 13 2.2 Definition Suppose A is a real m by n matrix with m n, and rank (A) = r. <p> The impact of the visualization of the block diagonal form (8) lies in 19 the speedups that have been obtained for this hybrid method over conven-tional SVD algorithms on machines such as the Cray X-MP/416 and Cray 2. As indicated in <ref> [2] </ref> for computing (1) when p = 4, the hybrid SVD method (referred to as HYJAC) can be 2 to 4 times faster than optimal 1 CPU implementations of classical bi-diagonalization SVD methods ([8] and [18]) on the Cray 2 (using macrotasking) and the Cray X-MP/416 (using microtasking), respectively.
Reference: [3] <author> M. Berry and A. Sameh. </author> <title> Parallel algorithms for the singular value and dense symmetric eigenvalue problems. </title> <type> Technical Report 761, </type> <institution> University of Illinois at Urbana-Champaign, Center for Supercomputing Research and Development, </institution> <year> 1988. </year> <note> To appear in Journal of Computational and Applied Math. </note>
Reference-contexts: Thus we can realize the decomposition in (1) after deter mining the matrix ~ V in (4). 15 As discussed in [1] and <ref> [3] </ref>, the matrix ~ V is constructed via (i; j) plane rotations so that r T where r i designates the i-th column of R R ~ V. <p> A parallel scheme for ordering the (i; j) plane rotations used in the orthogonalization of the columns of R is given in [1] and <ref> [3] </ref>. Sweeps of n (n 1)=2 plane rotations are applied to R until convergence is achieved. <p> An important discovery from this effort has been the eventual convergence of the iteration matrix S k to a preliminary block diagonal form in the presence of clustered spectra (singular values which are extremely close in value). As discussed in <ref> [3] </ref>, after a critical number of sweeps, c, we can obtain S c = B B B B B B @ T 2 T p C C C C C C A so that the eigenpairs of each T i ; (1; 2; :::; p), where p is the number of
Reference: [4] <author> C. Bischoff and C. Van Loan. </author> <title> The WY representation for products of householder matrices. </title> <type> Technical Report TR 85-681, </type> <institution> Cornell University, Department of Computer Science, </institution> <year> 1985. </year> <month> 28 </month>
Reference: [5] <author> O. Brewer, J. Dongarra, and D. Sorensen. </author> <title> Tools to aid in the analysis of memory access patterns for fortran programs. </title> <note> LAPACK Working Note #6 ANL/MCS-TM-120, </note> <institution> Argonne National Laboratory, Mathematics and Computer Science Division, </institution> <month> June </month> <year> 1988. </year>
Reference-contexts: We attempt to show the usefulness and ease of matrix visualization. It is important to distinguish this work as a type of data structure visualization and different from current work in algorithm animation. Computer graphics has been used in MAP to display memory access patterns in Fortran programs <ref> [5] </ref>. This package denotes access of matrix elements by color coding. MAP depends on a preprocessor to instrument a program with data collection calls. At execution time a trace file is written for subsequent rendering by the display program.
Reference: [6] <author> Marc H. Brown. </author> <title> Exploring algorithms using Balsa-II. </title> <journal> Computer, </journal> <volume> 21(5) </volume> <pages> 14-36, </pages> <year> 1988. </year>
Reference-contexts: The next level of interaction will allow the user to indicate an element with a mouse or other pointing device. The element's value will be displayed, perhaps with other user-specified information. A broader area for consideration is the general visualization of data structures. Brown <ref> [6] </ref> shows the utility and viability of algorithm animation. He also mentions the importance of future work in this area, such as data structure visualization with a data structure browser and a way for the user to 23 define the display format of data structures.
Reference: [7] <author> Timothy A. Davis and Edward S. Davidson. </author> <title> Pairwise reduction for the direct, parallel solution of sparse unsymmetric sets of linear equations. </title> <journal> Transactions on Computer, </journal> <month> December </month> <year> 1988. </year>
Reference-contexts: The usefulness of graphics in these problems has long been recognized [9]. New sparse linear solvers based on Gaussian elimination have been developed <ref> [7] </ref> using graphics to visualize the effectiveness of pivoting heuristics and reordering algorithms. The tradeoff of parallelism with fill in (of zero elements) was observed in developing the algorithm. Here, the magnitude of each element is not displayed, only the distinction between zero and non-zero elements. A monochrome display suffices. <p> In the display of final results one can show for example 22 the magnitude of the off-diagonal elements for a visual interpretation of the accuracy or error in a solution. Such displays are also helpful (again like print statements) in program debugging. Davis <ref> [7] </ref> used graphics extensively for debugging the data structure manipulations associated with the solution of sparse linear systems. 4 Directions MatVu and similar tools will continue to be used for linear algebra problems. They will support other common matrix storage modes: sparse and symmetric.
Reference: [8] <author> J. Dongarra, J. Bunch, C. Moler, and G. W. Stewart. </author> <title> LINPACK Users' Guide. </title> <publisher> SIAM, </publisher> <address> Philadelphia, </address> <year> 1979. </year>
Reference: [9] <author> W. Morven Gentleman and Alan George. </author> <title> Sparse matrix software. </title> <editor> In J. R. Bunch and D. J. Rose, editors, </editor> <booktitle> Sparse Matrix Computations, </booktitle> <pages> pages 243-261. </pages> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1976. </year>
Reference-contexts: The usefulness of graphics in these problems has long been recognized <ref> [9] </ref>. New sparse linear solvers based on Gaussian elimination have been developed [7] using graphics to visualize the effectiveness of pivoting heuristics and reordering algorithms. The tradeoff of parallelism with fill in (of zero elements) was observed in developing the algorithm.
Reference: [10] <author> G. Golub and C. Van Loan. </author> <title> Matrix Computations. </title> <publisher> Johns Hopkins University Press, </publisher> <address> Baltimore, </address> <year> 1983. </year>
Reference: [11] <author> Donald Hearn and M. Pauline Baker. </author> <title> Computer Graphics. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, N.J., </address> <year> 1986. </year> <month> 29 </month>
Reference-contexts: We have no immediate need for graphical input of matrix values or locator information, but have not excluded such interaction from our design. 1.2 Graphics and Display Issues The graphics concepts and algorithms are quite basic (see <ref> [11] </ref>). All the display algorithms are two-dimensional, and involve window and viewport transformations, polygon fill (usually supported in hardware), and the use 5 of color maps. In contrast to state-of-the-art photo-realistic images, we are not interested in antialiasing the matrix (filtering specifically to compensate for sampling at a low frequency).
Reference: [12] <author> M. R. Hestenes. </author> <title> Inversion of matrices by biorthogonalization and re-lated results. </title> <journal> J. Soc. Indust. Appl. Math., </journal> <volume> 6 </volume> <pages> 51-90, </pages> <year> 1958. </year>
Reference: [13] <author> H. F. Kaiser. </author> <title> The JK method: a procedure for finding the eigenvectors and eigenvalues of a real symmetric matrix. </title> <journal> The Computer Journal, </journal> <volume> 15(33) </volume> <pages> 271-273, </pages> <year> 1972. </year>
Reference-contexts: For rank deficient matrices A (i.e. r &lt; n), the n by n upper-triangular matrix R will be singular. 14 Applying the one-sided Jacobi method ([12], <ref> [13] </ref>, [15]) to the n by n up-per triangular matrix R (which may be singular) from the block Householder factorization of A, we determine an n by r matrix ~ V having orthogonal columns, as a product of plane rotations so that R ~ V = ~ Q = (~q 1
Reference: [14] <author> Allen D. Malony and Daniel A. Reed. </author> <title> Visualizing parallel computer system performance. </title> <editor> In Ingrid Bucher, Margaret Simmons, and Re-becca Koskela, editors, </editor> <booktitle> Instrumentation for Parallel Computer Systems. </booktitle> <publisher> Addison-Wesley, </publisher> <year> 1989. </year>
Reference: [15] <author> J. C. Nash. </author> <title> A one-sided transformation method for the singular value decomposition and algebraic eigenproblem. </title> <journal> The Computer Journal, </journal> <volume> 18(1) </volume> <pages> 74-76, </pages> <year> 1975. </year>
Reference-contexts: For rank deficient matrices A (i.e. r &lt; n), the n by n upper-triangular matrix R will be singular. 14 Applying the one-sided Jacobi method ([12], [13], <ref> [15] </ref>) to the n by n up-per triangular matrix R (which may be singular) from the block Householder factorization of A, we determine an n by r matrix ~ V having orthogonal columns, as a product of plane rotations so that R ~ V = ~ Q = (~q 1 ;
Reference: [16] <author> Daniel A. Reed and R. M. Fujimoto. </author> <title> Hypercube implementation of the simplex algorithm. </title> <booktitle> In Proceedings of the Third Conference on Hypercube Computers and Concurrent Applications, </booktitle> <address> Pasadena, CA, </address> <month> Jan </month> <year> 1988. </year>
Reference: [17] <author> Gruia-Catalin Roman and Kenneth C. Cox. </author> <title> A declarative approach to visualizing concurrent computations. </title> <journal> Computer, </journal> <volume> 22(10) </volume> <pages> 25-36, </pages> <month> October </month> <year> 1989. </year>
Reference-contexts: At execution time a trace file is written for subsequent rendering by the display program. An nice performance evaluation tool, MAP does not interact with an executing program, nor does it show the contents of a data structure. In <ref> [17] </ref> an abstraction function is used to map computational states to objects. A rendering function maps the objects into images. Again, the objects are removed from the actual data structures by this abstraction.
Reference: [18] <author> B. Smith et al. </author> <title> Matrix Eigensystem Routines - EISPACK Guide. </title> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <note> second edition, </note> <year> 1976. </year>
Reference-contexts: As indicated in [2] for computing (1) when p = 4, the hybrid SVD method (referred to as HYJAC) can be 2 to 4 times faster than optimal 1 CPU implementations of classical bi-diagonalization SVD methods ([8] and <ref> [18] </ref>) on the Cray 2 (using macrotasking) and the Cray X-MP/416 (using microtasking), respectively.
Reference: [19] <author> Colin Ware. </author> <title> Color sequences for univariate maps: Theory, experiments, and principles. </title> <journal> Computer Graphics and Applications, </journal> <volume> 8(5) </volume> <pages> 41-49, </pages> <year> 1988. </year>
Reference-contexts: Therefore, we provide a default map, and several other choices. Our maps are based on a rainbow (varying hues through blue, green, yellow and red, with all saturated colors at a constant lightness), a grey scale map, and a color map very similar to Ware's experimental map <ref> [19] </ref> (which provides a smooth transition from black through 1 SunView is a trademark of Sun Microsystems, Inc. 7 deep blue, dark red, orange, yellow, and finally white). We have found em-pirically that these are intuitive and satisfactory. Ware's map is especially useful as it monotonically increases in luminence.
Reference: [20] <author> J. Wilkinson. </author> <title> Almost diagonal matrices with multiple or close eigen-values. </title> <journal> Linear Algebra Appl., </journal> <volume> 1 </volume> <pages> 1-12, </pages> <year> 1968. </year> <month> 31 </month>
References-found: 20

