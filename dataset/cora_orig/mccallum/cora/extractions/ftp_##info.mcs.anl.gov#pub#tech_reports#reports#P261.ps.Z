URL: ftp://info.mcs.anl.gov/pub/tech_reports/reports/P261.ps.Z
Refering-URL: http://www.mcs.anl.gov/publications/abstracts/abstracts91.htm
Root-URL: http://www.mcs.anl.gov
Title: IDENTIFIABLE SURFACES IN CONSTRAINED OPTIMIZATION  
Author: STEPHEN J. WRIGHT 
Keyword: Key words. Constrained optimization, active set identification  
Affiliation: DIVISION, ARGONNE NATIONAL LABORATORY  
Note: PREPRINT MCS-P261-0891, MCS  AMS(MOS) subject classifications. 90C25, 53A07, 26B10  
Abstract: The concept of a "class-C p identifiable surface" of a convex set in Euclidean space in introduced. We show how the smoothness of these surfaces is related to the smoothness of the projection operator, and present finite identification results for certain algorithms for minimization of a function over this set. The work uses a partially geometric view of constrained optimization to generalize previous finite identification results. 1. Introduction. Here, we investigate the problem 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. V. Burke and J. J. Mor e, </author> <title> On the identification of active constraints, </title> <journal> SIAM Journal on Numerical Analysis, </journal> <volume> 25 (1988), </volume> <pages> pp. 1197-1211. </pages>
Reference-contexts: This condition, which is a geometric generalization of the strict complementarity condition of nonlinear programming, has been used in the convergence analysis of Dunn [3] and Burke and More <ref> [1] </ref>. Both these papers specify similar classes of subsets of that are finitely identifiable by gradient projection and Newton-like algorithms. <p> WRIGHT It is easy to show that open facets are convex. When is polyhedral, it can be partitioned into open facets, but when has some curved boundaries, this is not the case. As an example, consider the set defined in <ref> [1, equation (2.2)] </ref>: 1 = f ( 1 ; 2 ) j 2 1 2 The open facets in this set are its interior, the point (0; 1) and the edges f (0; 2 ) j 2 &lt; 1g and f (1; 2 ) j 2 &lt; 0g. <p> This property is analogous to that described for open facets in Theorem 2.8 of Burke and More <ref> [1] </ref>. Lemma 2.2. Suppose that S is as in Lemma 2.1 with p 2. <p> Theorem 2.3. Let S be an open facet in . Then S is a class-C 1 identifiable surface. Proof. The case S = int () is trivially true. Consider S ae @. Burke and More <ref> [1] </ref> show that any open facet S is the relative interior of a quasipolyhedral face. <p> Suppose that (i) Assumption 1 and (2) hold at some point x fl ; (ii) rF is continuous at x fl ; (iii) x fl 2 S, where S is a class-C p identifiable surface of with p 1; (iv) there is oe &gt; 0 such that oe k 2 <ref> [oe; 1] </ref> for all k; and (v) the sequence fx k g generated by (9)-(12) converges to x fl . Then x k 2 S for all k sufficiently large. Proof. <p> = x fl rF (x fl ), we can apply Definition 2 to find ffi &gt; 0 such that x fl rF (x fl ) + ffiB ae K: By construction of K, this implies that x fl oerF (x fl ) + oeffiB ae K for all oe 2 <ref> [oe; 1] </ref>: Now, choose k such that, for all k k, kx k x fl k + krF (x k ) rF (x fl )k oeffi: Then k [x k oe k rF (x k )] [x fl oe k rF (x fl )]k oeffi; and so x k oe k <p> that is, the defect E (x) = x P (x rF (x)), restricted to S, has an isolated zero at x fl ; (iii) given any oe &gt; 0, there is ae 3 = ae 3 (oe) &gt; 0 such that kx x fl k ae 3 ; oe 2 <ref> [oe; 1] </ref> ) P (x oerF (x)) 2 S; (iv) x fl is a stable local attractor for the gradient projection algorithm, and the sequences fx k g that approach x fl eventually enter and remain in S. Proof. <p> ae 2 , v is close enough to T S (x fl ) and kvk is small enough that v T r 2 F (x fl + fi 1 v) + i=1 i r 2 g i (x fl + fi 1 v) v 2 for all fi 1 2 <ref> [0; 1] </ref>. Hence, from (17), F (x fl + v) F (x fl ) 4 12 STEPHEN J. <p> The fact that F 2 C 2 in a neighborhood of x fl means that it is possible to choose a oe 2 (0; 1) such that, for x k is in this neighborhood, any oe k satisfying (10)-(12) lies in <ref> [oe; 1] </ref>. We turn now to Newton-like methods for (1). <p> 0 2 is chosen, and for each k 0, the following subproblem is solved to find a search direction p k : min rF (x k ) T p k + 2 k B k p k ; x k + p k 2 :(33) A steplength oe k 2 <ref> [0; 1] </ref> is chosen, usually with the help of some "sufficient decrease" criterion, and the next iterate is obtained by setting x k+1 = x k + oe k p k :(34) A simple result, similar to Theorem 3.1, follows: Theorem 3.3.
Reference: [2] <author> F. H. Clarke, </author> <title> Optimization and Nonsmooth Analysis, </title> <publisher> John Wiley, </publisher> <address> New York, </address> <year> 1983. </year>
Reference-contexts: cone K ae Rl n , we use K ffi to denote the polar of K, and define the lineality lin (K) to be (K ffi ) ? ; b) Let T (x) and N (x) denote the tangent and normal cones, respectively, to at x, as defined in Clarke <ref> [2] </ref>. <p> Then (i) T S (y) = fs j s T rg i (y) = 0; i = 1; ; rg, where T S (:) is the tangent cone with respect to S, as defined in <ref> [2] </ref>; (ii) lin (T (y)) ? = aff (N (y)) = spanfrg i (y) j i = 1; ; rg = T S (y) ? ; and (iii) if p 2, the projection of r 2 g i (y) onto T S (y) is positive semidefinite.
Reference: [3] <author> J. C. Dunn, </author> <title> On the convergence of projected gradient processes to singular critical points, </title> <journal> Journal of Optimization Theory and Applications, </journal> <volume> 55 (1987), </volume> <pages> pp. 203-216. </pages>
Reference-contexts: To prove the finite identification ("capture") results, we assume a nondegeneracy condition due to Dunn <ref> [3] </ref>. This is stated simply as rF (x fl ) 2 ri (N (x fl ));(2) where ri (fl) is the relative interior of fl ae Rl n , that is, the interior of fl relative to aff (fl), the affine hull of fl. <p> This condition, which is a geometric generalization of the strict complementarity condition of nonlinear programming, has been used in the convergence analysis of Dunn <ref> [3] </ref> and Burke and More [1]. Both these papers specify similar classes of subsets of that are finitely identifiable by gradient projection and Newton-like algorithms. We define these "open facets" as in [3]: Definition 1. a) For any closed convex cone K ae Rl n , we use K ffi to <p> generalization of the strict complementarity condition of nonlinear programming, has been used in the convergence analysis of Dunn <ref> [3] </ref> and Burke and More [1]. Both these papers specify similar classes of subsets of that are finitely identifiable by gradient projection and Newton-like algorithms. We define these "open facets" as in [3]: Definition 1. a) For any closed convex cone K ae Rl n , we use K ffi to denote the polar of K, and define the lineality lin (K) to be (K ffi ) ? ; b) Let T (x) and N (x) denote the tangent and normal cones, respectively, <p> Finite Identification in Constrained Optimization Algorithms. We turn now to algorithms for solving the optimization problem (1). In analyzing the gradient projection algorithm, we use the work of Dunn <ref> [3, x2] </ref>, who gave a framework for proving "capture" results. <p> : Now, choosing ae 2 = min ( ae 3 ; ff=(4c 3 )), the desired result follows, with ff 2 = ff=(8c 2 ). (iii) The proof of this part is identical to that of Theorem 3.1, and hence is omitted. (iv) This follows from Theorem 2.1 of Dunn <ref> [3] </ref>, after we make the following observations. Part (i) of this theorem implies that x fl is a uniformly proper local minimizer of F in .
Reference: [4] <author> H. Federer, </author> <title> Geometric Measure Theory, </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1969. </year>
Reference-contexts: Fitzpatrick and Phelps [5, Theorem 3.10] prove the converse. The case of p = 2 is most interesting. It is a classical result <ref> [4, p. 216] </ref> that, since P is Lipschitz continuous, it is differentiable almost everywhere. Below, we extend Theorem 2.5 to sets with piecewise smooth boundaries, by showing that class-C p identifiable surfaces generate open regions in Rl n n in which P is C p1 . Theorem 2.6.
Reference: [5] <author> S. Fitzpatrick and R. R. Phelps, </author> <title> Differentiability of the metric projection in Hilbert space, </title> <journal> Transactions of the American Mathematical Society, </journal> <volume> 270 (1982), </volume> <pages> pp. 483-501. </pages>
Reference-contexts: Proof. This follows trivially, by identifying g i , i 2 A with g i , i = 1; ; r, in Definition 2. We now consider smoothness of the projection operator P (:). The motivation for this comes from the work of Holmes [7] and Fitzpatrick and Phelps <ref> [5] </ref>, who consider closed convex sets with smooth boundaries. <p> WRIGHT Holmes proves the following result: Theorem 2.5. [7, Theorem 2]. If has a C p boundary, for p 2, then the projection operator P (:) is C p1 in Rl n n, and P 0 (y) is invertible in lin (T (P (y))). Fitzpatrick and Phelps <ref> [5, Theorem 3.10] </ref> prove the converse. The case of p = 2 is most interesting. It is a classical result [4, p. 216] that, since P is Lipschitz continuous, it is differentiable almost everywhere. <p> The continuity condition alone is not sufficient, as an example from Fitzpatrick and Phelps <ref> [5, p. 496] </ref> illustrates. Define 4 = f ( 1 ; 2 ) j 2 j 1 j + 1 g: There is a corner in 4 at (0; 0), and the set has four maximal class-C 1 identifiable surfaces: the corner, the interior, and the two edges.
Reference: [6] <author> D. Gilbarg and N. S. Trudinger, </author> <title> Elliptic Partial Differential Equations of Second Order, </title> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1983. </year>
Reference-contexts: a class-C p identifiable surface is, in a certain sense, a generalization of the concept of a class-C p;ff boundary of a bounded domain ae Rl n , as used extensively in the theory of partial differential equations (see, for example, the definition on page 94 of Gilbarg and Trudinger <ref> [6] </ref>). In fact, if is convex, closed and bounded, and its boundary @ is of class-C p;0 according to the latter definition, then it can be partitioned into a class-C 1 identifiable surface (int ()) and a class-C p identifiable surface (@). <p> By showing that this definition is equivalent to a local C p parametrization of the boundary, Holmes [7] essentially shows that a C p boundary (by the definition above) is the same as a class-C p;0 boundary, as defined in <ref> [6] </ref>. Hence, as discussed earlier, @ is a class-C p identifiable surface. 8 STEPHEN J. WRIGHT Holmes proves the following result: Theorem 2.5. [7, Theorem 2].
Reference: [7] <author> R. B. Holmes, </author> <title> Smoothness of certain metric projections on Hilbert space, </title> <journal> Transactions of the American Mathematical Society, </journal> <volume> 183 (1973), </volume> <pages> pp. 87-100. </pages>
Reference-contexts: Proof. This follows trivially, by identifying g i , i 2 A with g i , i = 1; ; r, in Definition 2. We now consider smoothness of the projection operator P (:). The motivation for this comes from the work of Holmes <ref> [7] </ref> and Fitzpatrick and Phelps [5], who consider closed convex sets with smooth boundaries. <p> By showing that this definition is equivalent to a local C p parametrization of the boundary, Holmes <ref> [7] </ref> essentially shows that a C p boundary (by the definition above) is the same as a class-C p;0 boundary, as defined in [6]. Hence, as discussed earlier, @ is a class-C p identifiable surface. 8 STEPHEN J. WRIGHT Holmes proves the following result: Theorem 2.5. [7, Theorem 2]. <p> Hence, as discussed earlier, @ is a class-C p identifiable surface. 8 STEPHEN J. WRIGHT Holmes proves the following result: Theorem 2.5. <ref> [7, Theorem 2] </ref>. If has a C p boundary, for p 2, then the projection operator P (:) is C p1 in Rl n n, and P 0 (y) is invertible in lin (T (P (y))). Fitzpatrick and Phelps [5, Theorem 3.10] prove the converse.
Reference: [8] <author> S. Lang, </author> <title> Analysis II, </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1969. </year>
Reference-contexts: The first result follows immediately from (5) and the implicit function theorem (see, for example, Lang <ref> [8, page 125] </ref>) by noting that the coefficient matrix in (7) is nonsingular. For the second result, let Z 2 Rl nfi (nr) be a matrix of full rank such that rg (y) T Z = 0. By Lemma 2.1 (ii), the columns of Z span lin (T (P (y))).
Reference: [9] <author> E. W. Sachs, </author> <title> Newton's method for singular constrained optimization problems, </title> <journal> Applied Mathematics and Optimization, </journal> <volume> 11 (1984), </volume> <pages> pp. 247-276. </pages>
Reference-contexts: Proof. The proof rests on a result of Sachs <ref> [9, Theorem 2.1] </ref>. <p> WRIGHT where the second inequality follows from Theorem 3.2 (i). Hence (35) follows by setting ff 1 = ff 1 =2. Applying <ref> [9, Theorem 2.1] </ref> with a = ff 1 ; ae = ae 1 ; V = fx j kx x fl k &lt; 2 ae 1 g; we obtain the desired result, with ae 4 = min ae 1 ; 3L ; ff 4 = 2 ff 1 (Note that [9, <p> <ref> [9, Theorem 2.1] </ref> with a = ff 1 ; ae = ae 1 ; V = fx j kx x fl k &lt; 2 ae 1 g; we obtain the desired result, with ae 4 = min ae 1 ; 3L ; ff 4 = 2 ff 1 (Note that [9, Theorem 2.1] continues to hold when oe = 0.) The final statement in the theorem follows from Theorem 3.3.
References-found: 9

