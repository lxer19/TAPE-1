URL: http://www.cs.umn.edu/Users/dept/users/boley/reports/rtls95.ps.gz
Refering-URL: http://www.cs.umn.edu/Users/dept/users/boley/reports/
Root-URL: http://www.cs.umn.edu
Title: Recursive Total Least Squares: An Alternative to Using the Discrete Kalman Filter in Robot Navigation  
Author: Daniel L. Boley and Erik S. Steinmetz Karen T. Sutherland 
Address: Minneapolis, MN 55455 La Crosse, WI 54601  
Affiliation: Department of Computer Science Department of Computer Science University of Minnesota University of Wisconsin LaCrosse  
Abstract: In the robot navigation problem, noisy sensor data must be filtered to obtain the best estimate of the robot position. The discrete Kalman filter, commonly used for prediction and detection of signals in communication and control problems, has become a popular method to reduce the effect of uncertainty from the sensor data. However, in the domain of robot navigation, sensor readings are not only uncertain, but can also be relatively infrequent, compared to traditional signal processing applications. Hence, there is a need for a filter that is capable of converging with many fewer readings than the Kalman filter. To this end, we propose the use of a Recursive Total Least Squares Filter. This filter is easily updated to incorporate new sensor data, and in our experiments converged faster and to greater accuracy than the Kalman filter. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> N. Ayache and O. D. Faugeras. </author> <title> Maintaining representations of the environment of a mobile robot. </title> <journal> IEEE Transactions on Robotics and Automation, </journal> <volume> 5(6) </volume> <pages> 804-819, </pages> <month> December </month> <year> 1989. </year>
Reference-contexts: Although originally designed as an estimator for dynamical systems, the filter is used in many applications as a static state estimator [13]. Also, due to the fact that functions are frequently non-linear, the extended Kalman filter (EKF) rather than the Kalman filter itself is often used <ref> [1, 11] </ref>. In this case, the function is linearized by taking a first order Taylor expansion. This linear approximation is then used as the Kalman filter equation. <p> In the first set of experiments, we simulated a simple robot navigation problem typical of that faced by an actual mobile robot <ref> [1, 6, 11] </ref>. The robot has identified a single landmark in a two-dimensional environment and knows the landmark location on a map. It does not know its own position. It moves in a straight line and with a known uniform velocity.
Reference: [2] <author> D. L. Boley and K. T. Sutherland. </author> <title> Recursive total least squares: An alternative to the discrete Kalman filter. </title> <type> Technical Report CS TR 93-32, </type> <institution> University of Minnesota, </institution> <month> April </month> <year> 1993. </year>
Reference-contexts: A brief summary of the Kalman filter can be found in <ref> [2] </ref> and a complete description in [9]. One of the main advantages of using the Kalman filter is that it is recursive, eliminating the necessity for storing large amounts of data. It requires a good initial estimate of the solution. <p> Details on the updating process can be found in [15, 10]. We can adapt the ULV Decomposition to solve the Total Least Squares (TLS) problem Ax b, where new measurements b are continually being added, as originally proposed in <ref> [2] </ref>. The adaptation of the ULV to the TLS problem has also been analyzed independently in great detail in [19], though the recursive updating process was not discussed at length. <p> If k b V 22 k is too close to zero (according to a user supplied tolerance), then we can adjust the rank boundary b r down to obtain a more robust, but approxi mate solution <ref> [2] </ref>. * Find an orthogonal matrix Q such that b V 22 Q = (0; : : : ; 0; ff), and let v be the last column of b V 12 Q. Then compute the new approximate TLS solution according to the formula b x = v=ff.
Reference: [3] <author> N. K. Bose, H. C. Kim, and H. M. Valenzuela. </author> <title> Recursive implementation of total least squares algorithm for image reconstruction from noisy, </title> <booktitle> under-sampled multiframes. In Proceedings of 1993 International Conference on Acoustics, Speech and Signal Processing, pages V-269-V-272. IEEE, </booktitle> <month> May </month> <year> 1993. </year>
Reference: [4] <author> C. E. Davila. </author> <title> Efficient recursive total least squares algorithm for FIR adaptive filtering. </title> <journal> IEEE Trans. Sig. Proc., </journal> <volume> 42(2) </volume> <pages> 268-280, </pages> <year> 1994. </year>
Reference-contexts: The vector x corresponding to the optimal (E; f ) is called the TLS solution. Recently, some recursive TLS filters have been developed for applications in signal processing <ref> [4, 5, 20] </ref>. Davila 3 [4] used a Kalman filter to obtain a fast update for the eigenvector corresponding to the smallest eigenvalue of the covariance matrix. This eigenvector was then used to solve a symmetric TLS problem for the filter. <p> The vector x corresponding to the optimal (E; f ) is called the TLS solution. Recently, some recursive TLS filters have been developed for applications in signal processing [4, 5, 20]. Davila 3 <ref> [4] </ref> used a Kalman filter to obtain a fast update for the eigenvector corresponding to the smallest eigenvalue of the covariance matrix. This eigenvector was then used to solve a symmetric TLS problem for the filter.
Reference: [5] <author> R. D. DeGroat. </author> <title> Noniterative subspace tracking. </title> <journal> IEEE Transactions on Signal Processing, </journal> <volume> 40(3) </volume> <pages> 571-577, </pages> <month> March </month> <year> 1992. </year>
Reference-contexts: The vector x corresponding to the optimal (E; f ) is called the TLS solution. Recently, some recursive TLS filters have been developed for applications in signal processing <ref> [4, 5, 20] </ref>. Davila 3 [4] used a Kalman filter to obtain a fast update for the eigenvector corresponding to the smallest eigenvalue of the covariance matrix. This eigenvector was then used to solve a symmetric TLS problem for the filter. <p> He replaced all the eigenvalues in the noise subspace with their average, and did the same for the eigenvalues in the signal subspace, obtaining an approximation which would be accurate if the exact eigenvalues could be grouped into two clusters of known dimensions. In <ref> [5] </ref>, DeGroat used this approach combined with the averaging technique used in [20], again assuming that the singular values could be grouped into two clusters. Recently, Bose et al.[3] applied Davila's algorithm to reconstruct images from noisy, undersampled frames after converting complex-valued image data into equivalent real data.
Reference: [6] <author> H. Durrant-White, E. Bell, and P. Avery. </author> <title> The design of a radar-based navigation system for large outdoor vehicles. </title> <booktitle> In Proceedings of 1995 International Conference on Robotics and Automation, </booktitle> <pages> pages 764-769. </pages> <publisher> IEEE, </publisher> <month> June </month> <year> 1995. </year>
Reference-contexts: In the first set of experiments, we simulated a simple robot navigation problem typical of that faced by an actual mobile robot <ref> [1, 6, 11] </ref>. The robot has identified a single landmark in a two-dimensional environment and knows the landmark location on a map. It does not know its own position. It moves in a straight line and with a known uniform velocity.
Reference: [7] <author> G. H. Golub and C. F. V. Loan. </author> <title> Matrix Computations. </title> <publisher> Johns Hopkins, </publisher> <address> 2nd edition, </address> <year> 1989. </year>
Reference-contexts: Sensing in robot navigation, often done using camera images, is a time consuming process. To be useful, a method must succeed with relatively few readings. * An underlying assumption in any least squares estimation is that the entries in the data matrix are error-free <ref> [7] </ref>, e.g., the time intervals at which measurements are taken are exact. In many actual applications, the errors in the data matrix can be at least as great as the measurement errors. In such cases, the Kalman filter can give poor results.
Reference: [8] <author> G. Hager and M. Mintz. </author> <title> Computational methods for task-directed sensor data fusion and sensor planning. </title> <journal> The International Journal of Robotics Research, </journal> <volume> 10(4) </volume> <pages> 285-313, </pages> <month> August </month> <year> 1991. </year>
Reference-contexts: As demonstrated by Mintz et al <ref> [8] </ref>, the criterion of optimality depends critically on the specific model being used.
Reference: [9] <author> S. Haykin. </author> <title> Adaptive Filter Theory. </title> <publisher> Prentice Hall, </publisher> <address> 2nd edition, </address> <year> 1991. </year>
Reference-contexts: A brief summary of the Kalman filter can be found in [2] and a complete description in <ref> [9] </ref>. One of the main advantages of using the Kalman filter is that it is recursive, eliminating the necessity for storing large amounts of data. It requires a good initial estimate of the solution. It also assumes that the noise obeys a weighted white gaussian distribution. <p> a ULV Decomposition of the matrix (A; b) and an approximate TLS solution to Ax b, our task is to find a TLS solution b x to the augmented system b A b x b b, where b A = A fi ; and is an optional exponential forgetting factor <ref> [9] </ref>. The RTLS Algorithm: * Start with [L; V; r], the ULV Decomposition of (A; b), and the coefficients a T ; fi for the new incoming equation a T x = fi. 5 * Compute the updated ULV Decomposition for the system augmented with the new incoming equation.
Reference: [10] <author> S. Hosur, A. H. Tewfik, and D. Boley. </author> <title> Multiple subspace ULV algorithm and LMS tracking. </title> <editor> In M. Moonen and B. D. Moor, editors, </editor> <booktitle> 3rd Int'l Workshop on SVD and Signal Processing, </booktitle> <pages> pages 295-302. </pages> <publisher> Elsevier, </publisher> <month> August </month> <year> 1995. </year> <institution> Leuven, Belgium. </institution>
Reference-contexts: In this way, it is possible to track the leading r-dimensional signal subspace or the remaining noise subspace relatively cheaply. Details on the updating process can be found in <ref> [15, 10] </ref>. We can adapt the ULV Decomposition to solve the Total Least Squares (TLS) problem Ax b, where new measurements b are continually being added, as originally proposed in [2].
Reference: [11] <author> A. Kosaka and A. C. Kak. </author> <title> Fast vision-guided mobile robot navigation using model- based reasoning and prediction of uncertainties. CVGIP: </title> <booktitle> Image Understanding, </booktitle> <volume> 56(3) </volume> <pages> 271-329, </pages> <month> November </month> <year> 1992. </year> <month> 14 </month>
Reference-contexts: Although originally designed as an estimator for dynamical systems, the filter is used in many applications as a static state estimator [13]. Also, due to the fact that functions are frequently non-linear, the extended Kalman filter (EKF) rather than the Kalman filter itself is often used <ref> [1, 11] </ref>. In this case, the function is linearized by taking a first order Taylor expansion. This linear approximation is then used as the Kalman filter equation. <p> In the first set of experiments, we simulated a simple robot navigation problem typical of that faced by an actual mobile robot <ref> [1, 6, 11] </ref>. The robot has identified a single landmark in a two-dimensional environment and knows the landmark location on a map. It does not know its own position. It moves in a straight line and with a known uniform velocity.
Reference: [12] <author> H. Schneiderman and M. Nashman. </author> <title> A discriminating feature tracker for vision-based autonomous driving. </title> <journal> IEEE Transactions on Robotics and Automation, </journal> <volume> 10(6) </volume> <pages> 769-775, </pages> <month> December </month> <year> 1994. </year>
Reference-contexts: It can easily fall into a local minimum when an initial estimate of the solution is poor, often the type of situation faced by robot navigators. Although limited modifications can be made to the Kalman approach to improve robustness to noise <ref> [12] </ref>, our work in outdoor navigation [17], where measurements are expensive to obtain and have significant error inherent to the system, motivated 2 1 2 3 4 5 2 4 1 2 3 4 5 2 4 to the line of best fit is minimized.
Reference: [13] <author> R. C. Smith and P. Cheeseman. </author> <title> On the representation and estimation of spatial uncertainty. </title> <journal> The International Journal of Robotics Research, </journal> <volume> 5(4) </volume> <pages> 56-68, </pages> <month> Winter </month> <year> 1986. </year>
Reference-contexts: The Kalman filter is guaranteed to be optimal only in that it is guaranteed to find the best solution in the least squares sense. Although originally designed as an estimator for dynamical systems, the filter is used in many applications as a static state estimator <ref> [13] </ref>. Also, due to the fact that functions are frequently non-linear, the extended Kalman filter (EKF) rather than the Kalman filter itself is often used [1, 11]. In this case, the function is linearized by taking a first order Taylor expansion.
Reference: [14] <author> H. W. Sorenson. </author> <title> Least-squares estimation: from Gauss to Kalman. </title> <journal> IEEE Spectrum, </journal> <pages> pages 63-68, </pages> <month> July </month> <year> 1970. </year>
Reference-contexts: In such cases, the Kalman filter can give poor results. Two additional problems occur when using the EKF: * The linearization process itself has the potential to introduce significant error into the problem. * The EKF is not guaranteed to be optimal or to even converge <ref> [14] </ref>. It can easily fall into a local minimum when an initial estimate of the solution is poor, often the type of situation faced by robot navigators.
Reference: [15] <author> G. W. Stewart. </author> <title> Updating a rank-revealing ULV decomposition. </title> <journal> SIAM J. Matrix Analysis, </journal> <volume> 14(2), </volume> <year> 1993. </year>
Reference-contexts: We seek a method that can obtain a good approximation to the TLS solution, but which admits rapid updating as new data samples arrive. One such method is the so-called ULV Decomposition, first introduced by Stewart <ref> [15] </ref> as a means to obtain an approximate SVD which can be 4 easily updated as new data arrives, without making any a priori assumptions about the overall distribution of the singular values. <p> In this way, it is possible to track the leading r-dimensional signal subspace or the remaining noise subspace relatively cheaply. Details on the updating process can be found in <ref> [15, 10] </ref>. We can adapt the ULV Decomposition to solve the Total Least Squares (TLS) problem Ax b, where new measurements b are continually being added, as originally proposed in [2].
Reference: [16] <author> K. T. Sutherland. </author> <title> Ordering landmarks in a view. </title> <booktitle> In Proceedings 1994 ARPA Image Understanding Workshop, </booktitle> <month> November </month> <year> 1994. </year>
Reference-contexts: Future work includes utilizing the filter in navigation problems with actual outdoor terrain data and combining its use with the higher level reasoning described in <ref> [16] </ref>. 13
Reference: [17] <author> K. T. Sutherland and W. B. Thompson. </author> <title> Localizing in unstructured environments: Dealing with the errors. </title> <journal> IEEE Transactions on Robotics and Automation, </journal> <volume> 10(6) </volume> <pages> 740-754, </pages> <month> December </month> <year> 1994. </year>
Reference-contexts: It can easily fall into a local minimum when an initial estimate of the solution is poor, often the type of situation faced by robot navigators. Although limited modifications can be made to the Kalman approach to improve robustness to noise [12], our work in outdoor navigation <ref> [17] </ref>, where measurements are expensive to obtain and have significant error inherent to the system, motivated 2 1 2 3 4 5 2 4 1 2 3 4 5 2 4 to the line of best fit is minimized. <p> We assume that the robot has no instrument such as a compass which could be used to register its compass heading. Such instruments can give varying, incorrect readings in outdoor, unstructured environments <ref> [17] </ref>, so that it is useful to design and evaluate methods to obtain heading information from external sources. Such heading information could be used independently or as corrections to estimates from internal sources. The robot knows the location of the two landmarks on a map (ground coordinate system).
Reference: [18] <author> S. Van Huffel and J. Vandewalle. </author> <title> The Total Least Squares Problem Computational Aspects and Analysis. </title> <publisher> SIAM, </publisher> <address> Philadelphia, </address> <year> 1991. </year>
Reference-contexts: This second method is known in the statistical literature as orthogonal regression and in numerical analysis as total least squares (TLS) <ref> [18] </ref>. <p> The most common algorithms to compute the TLS solution are based on the Singular Value Decomposition (SVD), a non-recursive matrix decomposition which is computationally expensive to update. The TLS problem can be solved by the SVD using Algorithm 3.1 of <ref> [18] </ref>. The main computation cost of that algorithm occurs in the computation of the SVD. That cost is O (p 3 ) for each update. The basic solution method is sketched as follows. <p> If v p is too small or zero, then the TLS solution may be too big or nonexistent, in which case an approximate solution of reasonable size can be obtained by using the next smallest singular values (s) <ref> [18] </ref>. In cases such as the applications considered in this paper where the exact TLS solution is still corrupted by external effects such as noise, it suffices to obtain an approximate TLS solution at much less cost.
Reference: [19] <author> S. Van Huffel and H. Zha. </author> <title> An efficient total least squares algorithm based on a rank-revealing two-sided orthogonal decomposition. Numerical Algorithms, </title> <address> 4(1-2):101-133, </address> <month> January </month> <year> 1993. </year>
Reference-contexts: We can adapt the ULV Decomposition to solve the Total Least Squares (TLS) problem Ax b, where new measurements b are continually being added, as originally proposed in [2]. The adaptation of the ULV to the TLS problem has also been analyzed independently in great detail in <ref> [19] </ref>, though the recursive updating process was not discussed at length. For our specific purposes, let A be an nfi (p1) matrix and b be an n-vector, where p is fixed and n is growing as new measurements arrive.
Reference: [20] <author> K.-B. Yu. </author> <title> Recursive updating the eigenvalue decomposition of a covariance matrix. </title> <journal> IEEE Transactions on Signal Processing, </journal> <volume> 39(5) </volume> <pages> 1136-1145, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: The vector x corresponding to the optimal (E; f ) is called the TLS solution. Recently, some recursive TLS filters have been developed for applications in signal processing <ref> [4, 5, 20] </ref>. Davila 3 [4] used a Kalman filter to obtain a fast update for the eigenvector corresponding to the smallest eigenvalue of the covariance matrix. This eigenvector was then used to solve a symmetric TLS problem for the filter. <p> It was not explained how the algorithm might be modified for the case where the smallest eigenvalue is multiple (i.e., corresponding to a noise subspace of dimension higher than one), or variable (i.e., of unknown multiplicity). In <ref> [20] </ref>, Yu described a method for the fast update of an approximate eigendecomposition of a covariance matrix. <p> In [5], DeGroat used this approach combined with the averaging technique used in <ref> [20] </ref>, again assuming that the singular values could be grouped into two clusters. Recently, Bose et al.[3] applied Davila's algorithm to reconstruct images from noisy, undersampled frames after converting complex-valued image data into equivalent real data.
References-found: 20

