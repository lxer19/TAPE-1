URL: ftp://softlib.rice.edu/pub/CRPC-TRs/reports/CRPC-TR96650.ps.gz
Refering-URL: http://www.crpc.rice.edu/CRPC/softlib/TRs_online.html
Root-URL: 
Title: Trust-Region Interior-Point Algorithms for a Class of Nonlinear Programming Problems  
Author: by Lus Nunes Vicente Thomas A. Badgwell Danny C. Sorensen Richard A. Tapia 
Degree: A Thesis Submitted in Partial Fulfillment of the Requirements for the Degree Doctor of Philosophy Approved, Thesis Committee: John E. Dennis, Chairman Noah Harding Professor of Computational and Applied Mathematics  Professor of Chemical Engineering Mahmoud El-Alem Professor of Mathematics, Alexandria  Professor of Computational and Applied Mathematics  Noah Harding Professor of Computational  
Date: March, 1996  
Address: Houston, Texas  
Affiliation: RICE UNIVERSITY  University, Egypt  and Applied Mathematics  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> N. Alexandrov, </author> <title> Multilevel Algorithms for Nonlinear Equations and Equality Constrained Optimization, </title> <type> PhD thesis, </type> <institution> Department of Computational and Applied Mathematics, Rice University, Houston, Texas 77251, USA, </institution> <year> 1993. </year> <type> Tech. Rep. </type> <institution> TR93-20. </institution>
Reference-contexts: Otherwise compute the quasi-Newton step H 1 k g k , and if it is inside the trust region, set s k = H 1 k g k . If not, consider the convex combination s (ff) = (1 ff)c k ffH 1 k g k , ff 2 <ref> [0; 1] </ref>, and pick ff fl such that ks (ff fl )k = ffi k . Set s k = s (ff fl ). A dogleg step is depicted in Figure 2.1 for a value of ff fl strictly between one and zero. <p> See also Alexandrov <ref> [1] </ref>. We recommend the surveys given in [35] and [118] for an overview of these different trust-region globalizations. Trust-region algorithms have been applied also to optimization problems with equality and inequality constraints.
Reference: [2] <author> L. Armijo, </author> <title> Minimization of functions having Lipschitz-continuous first partial derivatives, </title> <journal> Pacific J. Math., </journal> <volume> 16 (1966), </volume> <pages> pp. 1-3. </pages>
Reference-contexts: If for all k, s k = k d k satisfies (2.3)-(2.4) and the direction d k is descent, then lim cos ( k )kg k k = 0: Some of the ground work that led to this result was provided by Armijo <ref> [2] </ref> and Goldstein [65]. It was established by Wolfe [144], [145] and Zoutendijk [158], under the assumption that the gradient is Lipschitz continuous. However this condition can be relaxed and one can see that uniform continuity is enough (see Fletcher [53][Theorem 2.5.1]).
Reference: [3] <author> R. Barret, M. Berry, T. F. Chan, J. Demmel, J. Donato, J. Don-garra, V. Eijkhout, R. Pozo, C. Romine, and H. van der Vorst, </author> <title> Templates for the Solution of Linear Systems: Building Blocks for Iterative Methods, </title> <publisher> SIAM, </publisher> <address> Philadelphia, Pennsylvania, </address> <year> 1994. </year>
Reference-contexts: These calculations are reported in Section 5.8 and summarized in the first line of Table 6.1 containing number of iterations. We introduce inexactness into this problem by solv ing these tridiagonal systems inexactly. For this purpose we tested several iterative methods like GMRES, QMR, and BiCGSTAB from the library <ref> [3] </ref>. The results are quite similar and we report here those obtained with GMRES (10) flfl . Since we have flfl In GMRES (p), the number p denotes the dimension of the Krylov basis K p .
Reference: [4] <author> L. T. Biegler, J. Nocedal, and C. Schmid, </author> <title> A reduced Hessian method for large-scale constrained optimization, </title> <journal> SIAM J. Optim., </journal> <volume> 5 (1995), </volume> <pages> pp. 314-347. </pages>
Reference-contexts: This cross term can be approximated by finite differences, by secant updates, or by zero <ref> [4] </ref>. There has been significant activity in studying the local rate of convergence of secant updates for reduced SQP algorithms. See the papers [4], [114], [147] and the references therein. y BFGS is an abbreviation for the names Broyden, Fletcher, Goldfarb, and Shanno who in 1970 independently discovered this secant update. <p> This cross term can be approximated by finite differences, by secant updates, or by zero <ref> [4] </ref>. There has been significant activity in studying the local rate of convergence of secant updates for reduced SQP algorithms. See the papers [4], [114], [147] and the references therein. y BFGS is an abbreviation for the names Broyden, Fletcher, Goldfarb, and Shanno who in 1970 independently discovered this secant update. <p> A linearization of (5.1) gives C y (x)s y + C u (x)s u = C (x); (5.2) D (x) 2 W (x) T r 2 @ s u A = D (x) 2 W (x) T rf (x);(5.3) 78 and W (x) T rf (x) for x 2 <ref> [0; 4] </ref>. D (x) 2 W (x) T rf (x) for x 2 [0; 4]. where 0 denotes the (n m) fi m matrix with zero entries. Equation (5.2) is the linearized state equation. The matrix E (x) was defined in (4.25), Section 4.4. <p> (x)s u = C (x); (5.2) D (x) 2 W (x) T r 2 @ s u A = D (x) 2 W (x) T rf (x);(5.3) 78 and W (x) T rf (x) for x 2 <ref> [0; 4] </ref>. D (x) 2 W (x) T rf (x) for x 2 [0; 4]. where 0 denotes the (n m) fi m matrix with zero entries. Equation (5.2) is the linearized state equation. The matrix E (x) was defined in (4.25), Section 4.4.
Reference: [5] <author> P. T. Boggs, </author> <title> Sequential quadratic programming, </title> <note> in Acta Numerica 1995, </note> <editor> A. Iserles, ed., </editor> <publisher> Cambridge University Press, </publisher> <address> Cambridge, London, New York, </address> <year> 1995, </year> <pages> pp. 1-51. </pages>
Reference-contexts: SQP algorithms are very successful for the solution of constrained optimization problems. See e.g. <ref> [5] </ref>, [59], [91], [108]. They are often quasi-Newton type algorithms in the sense that they rely on a Newton iteration and approximate second-order derivatives. The primary goal of these algorithms is to find a point that satisfies the first-order necessary optimality conditions. <p> programming subproblem (3.3) are equal to the Newton step on the system of first order necessary optimality conditions rf (x) + J (x) T = 0; given by the solution of the linear system 0 r 2 k 1 0 s 1 0 r x ` k 1 See Boggs <ref> [5] </ref> for an extensive survey on SQP algorithms.
Reference: [6] <author> P. T. Boggs, J. W. Tolle, and A. J. Kearsley, </author> <title> A practical algorithm for general large scale nonlinear optimization problems, </title> <type> Tech. Rep. NISTIR 5407, </type> <institution> Computing and Applied Mathematics Laboratory, National Institute of Standards and Statistics, </institution> <year> 1994. </year> <note> To appear in SIAM J. Optim. </note>
Reference-contexts: In a recent paper 123 [149], the impact of inexactness in reduced-gradient methods for design optimization has been analyzed. In nonlinear programming, inexactness has been studied by <ref> [6] </ref>, [28], [34], [54], [92], [110], [146] among others. The papers [34], [54], [92], [110] investigating SQP algorithms mostly study the influence of inexactness on the local convergence rate. In [110] conditions on the inexactness are given that guarantee descent in the merit function.
Reference: [7] <author> J. F. Bonnans and C. Pola, </author> <title> A trust region interior point algorithm for linearly constrained optimization, </title> <type> Tech. Rep. </type> <year> 1948, </year> <note> INRIA, </note> <year> 1993. </year>
Reference-contexts: In our context, the affine scaling interior-point algorithm is also of interest, because it does not interfere with the structure of the problem. To apply this algorithm, no additional information is required from the user. This or similar interior-point approaches have recently also been used e.g. in <ref> [7] </ref>, [25], [94], [95], [118]. The advantage of the approach in [23] is that the scaling matrix is determined by the distance of the iterates to the bounds and by the direction of the gradient.
Reference: [8] <author> M. A. Branch, T. F. Coleman, and Y. Li, </author> <title> A subspace, interior, and conjugate gradient method for large-scale bound-constrained minimization problems, </title> <type> Tech. Rep. </type> <institution> CTC95TR217, Advancing Computing Research Institute, Cornell University, </institution> <year> 1995. </year> <month> 155 </month>
Reference-contexts: We show in Section 6.3 that these conditions are satisfied for many other reasonable ways to compute s q 5.7.1 Computation of the Tangential Component In this section we show how to derive conjugate-gradient algorithms to compute (s k ) u . In <ref> [8] </ref>, Branch, Coleman, and Li propose other practical algorithms to compute steps for trust-region subproblems that come from optimization problems with simple bounds. They use three dimensional subspace approximations and conjugate gradients. Let us consider first the decoupled trust-region approach given in Section 5.2.2.
Reference: [9] <author> P. N. Brown, </author> <title> A local convergence theory for combined inexact-Newton finite-difference projection methods, </title> <journal> SIAM J. Numer. Anal., </journal> <volume> 24 (1987), </volume> <pages> pp. 407-434. </pages>
Reference-contexts: In the context of systems of nonlinear equations, inexact or truncated Newton methods have been proposed and analyzed by many authors. Some of the pioneering work in this area can be found in [32], [135]. More recent references are <ref> [9] </ref>, [10], [43], [44], [45]. Most of the recent papers investigate the use of Krylov subspace methods for the solution of linear systems, like GMRES [127], in inexact Newton methods.
Reference: [10] <author> P. N. Brown and Y. Saad, </author> <title> Hybrid Krylov methods for nonlinear systems of equations, </title> <journal> SIAM J. Sci. Statist. Comput., </journal> <volume> 11 (1990), </volume> <pages> pp. </pages> <month> 450-481. </month> <title> [11] , Convergence theory of nonlinear Newton-Krylov algorithms, </title> <journal> SIAM J. Op-tim., </journal> <volume> 4 (1994), </volume> <pages> pp. 297-330. </pages>
Reference-contexts: In the context of systems of nonlinear equations, inexact or truncated Newton methods have been proposed and analyzed by many authors. Some of the pioneering work in this area can be found in [32], [135]. More recent references are [9], <ref> [10] </ref>, [43], [44], [45]. Most of the recent papers investigate the use of Krylov subspace methods for the solution of linear systems, like GMRES [127], in inexact Newton methods. <p> In this case one can apply nonsymmetric transpose-free Krylov subspace methods based on minimum residual approximations, such as GMRES [127] or TFQMR [55]. In the context of nonlinear system solving the use of such methods is described by Brown and Saad <ref> [10] </ref>, [11].
Reference: [12] <author> J. Burger and M. Pogu, </author> <title> Functional and numerical solution of a control problem originating from heat transfer, </title> <journal> J. Optim. Theory Appl., </journal> <volume> 68 (1991), </volume> <pages> pp. 49-73. </pages>
Reference-contexts: In this section we introduce a simplified model for the heating of a probe in a kiln discussed by Burger and Pogu <ref> [12] </ref>. The temperature y (x; t) inside the probe is governed by a nonlinear parabolic partial differential equation. The spatial domain is given by (0; 1). The boundary x = 1 is the inside of the probe and x = 0 is the boundary of the probe -. <p> The goal is to control the heating process in such a way that the temperature inside the probe follows a certain desired temperature profile y d (t). The control u (t) acts on the boundary x = 0. The problem can be formulated as follows <ref> [12] </ref>: minimize 1 Z T subject to t (y (x; t)) @y (y (0; t))@ x y (0; t) = g y (0; t) u (t) ; t 2 (0; T ); y (x; 0) = y 0 (x); x 2 (0; 1); where y 2 L 2 (0; T ; <p> Here u low ; u upp 2 L 1 (0; T ) are given functions. It is shown in <ref> [12] </ref> that if the functions t and satisfy 0 &lt; t 1 t (t) t 2 ; jt 0 (t)j t 3 ; then the state equation has a unique solution in the state space n o The notation x used here for the spatial variables should not be confused with <p> If the partial differential equation and the integral are discretized, we obtain an optimization problem of the form (4.1). The discretization uses finite elements and was introduced in <ref> [12] </ref> (see also [74], [89]). The spatial domain (0; 1) is divided into N x subintervals of equidistant length, and the spatial discretization is done using piecewise linear finite elements. The time discretization is performed by partitioning the interval [0; T ] into N t equidistant subintervals.
Reference: [13] <author> J. V. Burke, </author> <title> A robust trust region method for constrained nonlinear programming problems, </title> <journal> SIAM J. Optim., </journal> <volume> 2 (1992), </volume> <pages> pp. 325-347. </pages>
Reference-contexts: See also Alexandrov [1]. We recommend the surveys given in [35] and [118] for an overview of these different trust-region globalizations. Trust-region algorithms have been applied also to optimization problems with equality and inequality constraints. See the work by Burke <ref> [13] </ref>, Burke, More, and Toraldo [14], Conn, Gould, and Toint [29], [30], and Yuan [154]. In this thesis we deal with a trust-region globalization of reduced SQP algorithms.
Reference: [14] <author> J. V. Burke, J. J. More, and G. Toraldo, </author> <title> Convergence properties of trust region methods for linear and convex constraints, </title> <journal> Math. Programming, </journal> <volume> 47 (1990), </volume> <pages> pp. 305-336. </pages>
Reference-contexts: See also Alexandrov [1]. We recommend the surveys given in [35] and [118] for an overview of these different trust-region globalizations. Trust-region algorithms have been applied also to optimization problems with equality and inequality constraints. See the work by Burke [13], Burke, More, and Toraldo <ref> [14] </ref>, Conn, Gould, and Toint [29], [30], and Yuan [154]. In this thesis we deal with a trust-region globalization of reduced SQP algorithms.
Reference: [15] <author> R. H. Byrd, J. Nocedal, and R. B. Schnabel, </author> <title> Representations of quasi-Newton matrices and their use in limited memory methods, </title> <journal> Math. Programming, </journal> <volume> 63 (1994), </volume> <pages> pp. 129-156. </pages>
Reference-contexts: The starting vector was x 0 = 0. For both the decoupled and the coupled approaches, we did tests using approximations to reduced and to full Hessians. We approximate these matrices with the limited memory BFGS representations given in <ref> [15] </ref> with a memory size of 5 pairs of vectors. For the reduced Hessian we use a null-space secant update (see [114], [147]).
Reference: [16] <author> R. H. Byrd and R. B. Schnabel, </author> <title> Continuity of the null space basis and constrained optimization, </title> <journal> Math. Programming, </journal> <volume> 35 (1986), </volume> <pages> pp. 32-41. </pages>
Reference-contexts: The continuity of an orthogonal null-space basis Z (x) for N (J (x)) has been discussed in <ref> [16] </ref>, [26], [58]. A straightforward implementation of the QR factorization of J (x) T might produce a discontinuous null-space orthogonal basis Z (x). However, Coleman and Sorensen [26] showed how to modify the QR factorization in such a way that Z (x) inherits the smoothness of J (x) T .
Reference: [17] <author> R. H. Byrd, R. B. Schnabel, and G. A. Shultz, </author> <title> A trust region algorithm for nonlinearly constrained optimization, </title> <journal> SIAM J. Numer. Anal., </journal> <volume> 24 (1987), </volume> <pages> pp. </pages> <month> 1152-1170. </month> <title> [18] , Approximate solution of the trust region problem by minimization over two-dimensional subspaces, </title> <journal> Math. Programming, </journal> <volume> 40 (1988), </volume> <pages> pp. 247-263. </pages>
Reference-contexts: The reduced SQP algorithm has been globalized with trust regions by Byrd and Omojokon [115], Byrd, Schnabel, and Shultz <ref> [17] </ref>, Coleman and Yuan [27], Dennis, El-Alem, and Maciel [35], Dennis and Vicente [42], El-Alem [48], [49], Lalee, Nocedal, and Plantenga [91], Plantenga [118], and Zhang and Zhu [156]. See also Alexandrov [1]. We recommend the surveys given in [35] and [118] for an overview of these different trust-region globalizations. <p> We focus on this issue in Section 3.4. 2. The decomposition of the step considered in references <ref> [17] </ref>, [27], [48], [49], [91], [115], [118], [156] is the normal decomposition (3.6). In many application problems there are other reasonable decompositions of the step. This is clearly the case for the class of problems introduced in Chapter 4. <p> The algorithms we introduce in this thesis use a quasi-normal decomposition. 3. The choice of Lagrange multipliers is associated intimately with the type of step decomposition. Most of the researchers <ref> [17] </ref>, [27], [48], [49], [91], [115], [118], [156] considered the least-squares multipliers (3.9) or variations thereof. The work given in [35], [42] departs from the former references by assuming a more general form for the multipliers. <p> The augmented Lagrangian has been used in [35], [42], [48], [49], [156], the ` 1 penalty function in <ref> [17] </ref>, the ` 2 penalty function in [27], and the ` 2 penalty function without constraint term squared in [91], [115], [118]. x The Thesis [115] was directed by Professor R. H. Byrd.
Reference: [19] <author> R. G. Carter, </author> <title> On the global convergence of trust region algorithms using inexact gradient information, </title> <journal> SIAM J. Numer. Anal., </journal> <volume> 28 (1991), </volume> <pages> pp. 251-265. </pages>
Reference-contexts: The assumption on the Hessian approximation H k can be weakened. Powell [122] proved a convergence result in the case where there is a bound on the second-order approximation H k that depends linearly on the iteration counter k. Carter <ref> [19] </ref> established analogous results for the case where the gradients g k = rf (x k ) are approximated rather than computed exactly.
Reference: [20] <author> A. </author> <title> Cauchy, </title> <institution> Methode generale pour la resolution des systemes d'equations simultanees, Compte Rendu des Seances de L'Academie des Sciences XXV, </institution> <month> (1847), </month> <pages> pp. 536-538. 156 </pages>
Reference-contexts: (c) subject to kck ffi k ; c 2 spanfg k g; and it is given by c k = &gt; &lt; g T g k if g T ffi k ; kg k k g k otherwise. (2.6) The primitive form of a steepest-descent algorithm was discovered by Cauchy <ref> [20] </ref> in 1847.
Reference: [21] <author> M. Celis, J. E. Dennis, and R. A. Tapia, </author> <title> A trust region strategy for nonlinear equality constrained optimization, in Numerical Optimization 1984, </title> <publisher> SIAM, </publisher> <address> Philadelphia, Pennsylvania, </address> <year> 1985, </year> <pages> pp. 71-82. </pages>
Reference-contexts: Globalizations of SQP algorithms were given by Celis, Dennis, and Tapia <ref> [21] </ref> (see also Yuan [152] and Zhang [157]), Conn, Gould, and Toint [30], El-Alem [47], Fletcher [52], Vardi [141] (see also El-Hallabi [51]), and Powell and Yuan [123].
Reference: [22] <author> E. M. Cliff, M. Heinkenschloss, and A. Shenoy, </author> <title> An optimal control problem for flows with discontinuities, </title> <type> Tech. Rep. </type> <institution> ICAM Report 95-09-02, Interdisciplinary Center for Applied Mathematics, Virginia Polytechnic Institute and State University, Blacksburg, </institution> <address> VA 24061, </address> <year> 1995. </year>
Reference-contexts: This class of problems is rich, and we continue to find new applications on a regular basis. The linearization of the nonlinear state equation yields the (discretized) linearized state equation and the corresponding adjoint equation. Efficient solutions of the linear system corresponding to these equations exist for many applications <ref> [22] </ref>, [75], [149], and the optimization algorithm ought to take advantage of it. This linearization also offers a tremendous amount of structure. In particular, we use it to obtain a matrix whose columns form a nonorthogonal basis for the null space of the Jacobian matrix of the nonlinear equality constraints. <p> These numerical results are very satisfactory and indicate the effectiveness of our algorithms. Our implementation has been used successfully to solve control problems in fluid flow <ref> [22] </ref>, [75]. 5 necessary optimality conditions: our result for problem (1.1) generalizes those obtained by the indicated authors for simpler problem classes. 1.4 Other Contributions We present a brief survey of trust regions for unconstrained optimization that covers only the most important trust-region ideas used in our algorithms. <p> There are optimal control problems arising in fluid flow for which a discretization also is of the form (4.1) (see e.g. Cliff, Heinkenschloss, and Shenoy <ref> [22] </ref> and Heinkenschloss [75]). Other applications include optimal design and parameter identification problems. <p> This is a great advantage. In some of the numerical experiments reported in <ref> [22] </ref>, [75], this improved the performance of our algorithms significantly, it avoided artificial ill-conditioning, and it enhanced the quality of the solution computed for a given stopping tolerance. 74 Chapter 5 Trust-Region Interior-Point Reduced SQP Algorithms for a Class of Nonlinear Programming Problems Nonlinear programming problems of the form (4.1) originating <p> We applied them to a boundary nonlinear parabolic control problem, see Section 5.8, and a distributed nonlinear elliptic control problem, see Section 6.5. The numerical results are quite satisfactory. Our algorithms have also been applied successfully to optimal control problems arising in fluid flow <ref> [22] </ref>, [75]. This chapter is organized as follows. In Section 5.1, we discuss the application of Newton's method to the system of nonlinear equations arising from the first-order 76 necessary optimality conditions. This is important for the derivation of our TRIP reduced SQP algorithms.
Reference: [23] <author> T. F. Coleman and Y. Li, </author> <title> An interior trust region approach for nonlinear minimization subject to bounds, </title> <type> Tech. Rep. </type> <institution> TR93-1342, Department of Computer Science, Cornell University, </institution> <year> 1993. </year> <note> To appear in SIAM J. </note> <author> Optim. </author> <title> [24] , On the convergence of interior-reflective Newton methods for nonlinear minimization subject to bounds, </title> <journal> Math. Programming, </journal> <volume> 67 (1994), </volume> <pages> pp. 189-224. </pages>
Reference-contexts: This is very important since many problems in this class are ill-conditioned.) 3. An interior-point strategy to handle the bounds on the control variables u. (We adapt to our contex a primal-dual affine scaling algorithm proposed by Coleman and Li <ref> [23] </ref> for optimization problems with simple bounds. We accomplish this by taking advantage of the structure of our class of problems. <p> In this situation the coupled approach is better, and so we include both. For the treatment of the bound constraints on u we use a primal-dual affine scaling interior-point algorithm introduced by Coleman and Li <ref> [23] </ref> for problems with simple bounds. Interior-point approaches are attractive for problems with a large number of bounds. In our context, the affine scaling interior-point algorithm is also of interest, because it does not interfere with the structure of the problem. <p> To apply this algorithm, no additional information is required from the user. This or similar interior-point approaches have recently also been used e.g. in [7], [25], [94], [95], [118]. The advantage of the approach in <ref> [23] </ref> is that the scaling matrix is determined by the distance of the iterates to the bounds and by the direction of the gradient. This dependence on the direction of the gradient is important for global convergence and its good effect can be seen in numerical examples, see e.g. <p> In Section 5.4, Theorem 5.4.1, we establish global convergence of the iterates to solutions of the first-order necessary optimality conditions. This result is established under very mild assumptions on the steps, the quadratic models, and the Lagrange multipliers. It simultaneously extends the results presented recently by Coleman and Li <ref> [23] </ref> for simple bounds and those of Dennis, El-Alem, and Maciel [35] (see Theorem 3.6.1 in this thesis) for equality constraints. Under additional conditions, we show convergence of the iterates to nondegenerate solutions of the second-order necessary optimality conditions in Theorem 5.5.2, Section 5.5. <p> Under additional conditions, we show convergence of the iterates to nondegenerate solutions of the second-order necessary optimality conditions in Theorem 5.5.2, Section 5.5. This latter result simultaneously extends those by Coleman and Li <ref> [23] </ref> for simple bounds and those by Dennis and Vicente [42] (see Theorem 3.6.3 in this thesis) for equality constraints. See Figures 1.1 and 1.2. A q-quadratic rate of convergence is proven in Section 5.6. <p> The derivative of (D (x) 2 ) ii does not exist if = 0. In this case we set the corresponding quantities in the Jacobian to zero (see references <ref> [23] </ref>, [24]). This gives the equation (5.3). <p> See Section 3.4.1 for more details. 5.2.2 The Tangential Component The computation of the tangential component (s k ) u follows a trust-region globaliza-tion of the Newton step (5.6). Following Coleman and Li <ref> [23] </ref> we symmetrize (5.6) and get D k W T k s u = D k W T q where D k = D (x k ), E k = E (x k ), and H k denotes a symmetric approximation to the Hessian matrix r 2 xx ` k . <p> To accomplish this, just as in the unconstrained case [106], [132], in the box-constrained case <ref> [23] </ref>, and in the equality-constrained case [42], [48], we need to make sure that s u satisfies an appropriate fraction of optimal decrease condition. First we consider the decoupled approach and let o d k be an optimal solution of the trust-region subproblem (5.17)-(5.18). <p> A possible redefinition of the actual and pre dicted decreases is obtained by subtracting the term 1 2 (s k ) T k (s k ) u from both ared (s k ; k ) and pred (s k ; k ). This type of modification was suggested in <ref> [23] </ref> for optimization with simple bounds, and it does not affect the global and local results given in this and in the following chapters. <p> It is not difficult to see that when the equality constraints of problem (3.1) reduce to the equality constraints of problem (4.1), Assumptions 5.1-5.5 given above imply Assumptions 3.1-3.5 given in Chapter 3. Assumption 5.6 is used by Coleman and Li <ref> [23] </ref> for optimization problems with simple bounds. <p> The following result finally establishes global convergence to a nondegenerate point satisfying the second-order necessary optimality conditions. If no equality constraints are considered, the proof reduces to the proof of Lemma 3.8 of Coleman and Li <ref> [23] </ref>. Theorem 5.5.2 Let fx k g be a bounded sequence of iterates generated by the TRIP Reduced SQP Algorithms 5.2.1 under Assumptions 5.1-5.6 and Conditions 5.1-5.3. Then fx k g has a limit point x fl satisfying the first-order necessary optimality conditions. <p> We proved in Chapter 5 global and local convergence results for these algorithms that include as special cases both the results established for equality constraints [35], [42] and those for simple bounds <ref> [23] </ref>. (See Figures 1.1 and 1.2.) We are satisfied with the sharpness of the results.
Reference: [25] <author> T. F. Coleman and J. Liu, </author> <title> An interior Newton method for quadratic programming, </title> <type> Tech. Rep. </type> <institution> TR93-1388, Department of Computer Science, Cornell University, </institution> <year> 1993. </year>
Reference-contexts: In our context, the affine scaling interior-point algorithm is also of interest, because it does not interfere with the structure of the problem. To apply this algorithm, no additional information is required from the user. This or similar interior-point approaches have recently also been used e.g. in [7], <ref> [25] </ref>, [94], [95], [118]. The advantage of the approach in [23] is that the scaling matrix is determined by the distance of the iterates to the bounds and by the direction of the gradient.
Reference: [26] <author> T. F. Coleman and D. C. Sorensen, </author> <title> A note on the computation of an orthonormal basis for the null space of a matrix, </title> <journal> Math. Programming, </journal> <volume> 29 (1984), </volume> <pages> pp. 234-242. </pages>
Reference-contexts: The continuity of an orthogonal null-space basis Z (x) for N (J (x)) has been discussed in [16], <ref> [26] </ref>, [58]. A straightforward implementation of the QR factorization of J (x) T might produce a discontinuous null-space orthogonal basis Z (x). However, Coleman and Sorensen [26] showed how to modify the QR factorization in such a way that Z (x) inherits the smoothness of J (x) T . <p> The continuity of an orthogonal null-space basis Z (x) for N (J (x)) has been discussed in [16], <ref> [26] </ref>, [58]. A straightforward implementation of the QR factorization of J (x) T might produce a discontinuous null-space orthogonal basis Z (x). However, Coleman and Sorensen [26] showed how to modify the QR factorization in such a way that Z (x) inherits the smoothness of J (x) T .
Reference: [27] <author> T. F. Coleman and W. Yuan, </author> <title> A new trust region algorithm for equality constrained optimization, </title> <type> Tech. Rep. </type> <institution> TR95-1477, Department of Computer Science, Cornell University, </institution> <year> 1995. </year>
Reference-contexts: The reduced SQP algorithm has been globalized with trust regions by Byrd and Omojokon [115], Byrd, Schnabel, and Shultz [17], Coleman and Yuan <ref> [27] </ref>, Dennis, El-Alem, and Maciel [35], Dennis and Vicente [42], El-Alem [48], [49], Lalee, Nocedal, and Plantenga [91], Plantenga [118], and Zhang and Zhu [156]. See also Alexandrov [1]. We recommend the surveys given in [35] and [118] for an overview of these different trust-region globalizations. <p> We focus on this issue in Section 3.4. 2. The decomposition of the step considered in references [17], <ref> [27] </ref>, [48], [49], [91], [115], [118], [156] is the normal decomposition (3.6). In many application problems there are other reasonable decompositions of the step. This is clearly the case for the class of problems introduced in Chapter 4. <p> The algorithms we introduce in this thesis use a quasi-normal decomposition. 3. The choice of Lagrange multipliers is associated intimately with the type of step decomposition. Most of the researchers [17], <ref> [27] </ref>, [48], [49], [91], [115], [118], [156] considered the least-squares multipliers (3.9) or variations thereof. The work given in [35], [42] departs from the former references by assuming a more general form for the multipliers. <p> The augmented Lagrangian has been used in [35], [42], [48], [49], [156], the ` 1 penalty function in [17], the ` 2 penalty function in <ref> [27] </ref>, and the ` 2 penalty function without constraint term squared in [91], [115], [118]. x The Thesis [115] was directed by Professor R. H. Byrd.
Reference: [28] <author> A. R. Conn, N. I. M. Gould, A. Sartenaer, and P. L. Toint, </author> <title> Global convergence of a class of trust region algorithms for optimization using inexact projections onto convex constraints, </title> <journal> SIAM J. Optim., </journal> <volume> 3 (1993), </volume> <pages> pp. 164-221. </pages>
Reference-contexts: In a recent paper 123 [149], the impact of inexactness in reduced-gradient methods for design optimization has been analyzed. In nonlinear programming, inexactness has been studied by [6], <ref> [28] </ref>, [34], [54], [92], [110], [146] among others. The papers [34], [54], [92], [110] investigating SQP algorithms mostly study the influence of inexactness on the local convergence rate. In [110] conditions on the inexactness are given that guarantee descent in the merit function.
Reference: [29] <author> A. R. Conn, N. I. M. Gould, and P. L. Toint, </author> <title> Global convergence of a class of trust region algorithms for optimization problems with simple bounds, </title> <journal> SIAM J. Numer. Anal., </journal> <volume> 25 (1988), </volume> <pages> pp. </pages> <month> 433-460. </month> <title> [30] , A globally convergent augmented Lagrangian algorithm for optimization with general constraints and simple bounds, </title> <journal> SIAM J. Numer. Anal., </journal> <volume> 28 (1991), </volume> <pages> pp. 545-572. 157 </pages>
Reference-contexts: We recommend the surveys given in [35] and [118] for an overview of these different trust-region globalizations. Trust-region algorithms have been applied also to optimization problems with equality and inequality constraints. See the work by Burke [13], Burke, More, and Toraldo [14], Conn, Gould, and Toint <ref> [29] </ref>, [30], and Yuan [154]. In this thesis we deal with a trust-region globalization of reduced SQP algorithms.
Reference: [31] <author> E. J. Cramer, J. E. Dennis, P. D. Frank, R. M. Lewis, and G. R. Shubin, </author> <title> Problem formulation for multidisciplinary optimization, </title> <journal> SIAM J. Op-tim., </journal> <volume> 4 (1994), </volume> <pages> pp. 754-776. </pages>
Reference-contexts: Furthermore, a solution of the linearized state equation is naturally decomposed into two components, a quasi-normal component and a tangential component. The algorithms that we propose and analyze in this thesis are based on an all-at-once approach (see <ref> [31] </ref>), where states y and controls u are treated as independent variables. 1.2 Algorithms and Convergence Theory Although there are algorithms available for the solution of nonlinear programming problems that are more general than (1.1), the family of algorithms presented in this thesis is unique in the consequent use of structure
Reference: [32] <author> R. S. Dembo, S. C. Eisenstat, and T. Steihaug, </author> <title> Inexact Newton methods, </title> <journal> SIAM J. Numer. Anal., </journal> <volume> 19 (1982), </volume> <pages> pp. 400-408. </pages>
Reference-contexts: In the context of systems of nonlinear equations, inexact or truncated Newton methods have been proposed and analyzed by many authors. Some of the pioneering work in this area can be found in <ref> [32] </ref>, [135]. More recent references are [9], [10], [43], [44], [45]. Most of the recent papers investigate the use of Krylov subspace methods for the solution of linear systems, like GMRES [127], in inexact Newton methods.
Reference: [33] <author> R. S. Dembo and T. Steihaug, </author> <title> Truncated-Newton algorithms for large-scale unconstrained optimization, </title> <journal> Math. Programming, </journal> <volume> 19 (1983), </volume> <pages> pp. 190-212. </pages>
Reference-contexts: The results for the solution of systems of nonlinear equations have been extended to analyze inexact Newton methods for the solution of unconstrained optimization problems, e.g. <ref> [33] </ref>, [109], [111], inexact Gauss-Newton methods [99], and complementarity problems [117]. In a recent paper 123 [149], the impact of inexactness in reduced-gradient methods for design optimization has been analyzed. In nonlinear programming, inexactness has been studied by [6], [28], [34], [54], [92], [110], [146] among others.
Reference: [34] <author> R. S. Dembo and U. Tulowitzki, </author> <title> Sequential truncated quadratic programming, </title> <note> in Numerical Optimization 1984, </note> <author> P. T. Boggs, R. H. Byrd, and R. B. Schnabel, </author> <title> eds., </title> <publisher> SIAM, </publisher> <address> Philadelphia, </address> <year> 1985, </year> <pages> pp. 83-101. </pages>
Reference-contexts: In a recent paper 123 [149], the impact of inexactness in reduced-gradient methods for design optimization has been analyzed. In nonlinear programming, inexactness has been studied by [6], [28], <ref> [34] </ref>, [54], [92], [110], [146] among others. The papers [34], [54], [92], [110] investigating SQP algorithms mostly study the influence of inexactness on the local convergence rate. In [110] conditions on the inexactness are given that guarantee descent in the merit function. <p> In a recent paper 123 [149], the impact of inexactness in reduced-gradient methods for design optimization has been analyzed. In nonlinear programming, inexactness has been studied by [6], [28], <ref> [34] </ref>, [54], [92], [110], [146] among others. The papers [34], [54], [92], [110] investigating SQP algorithms mostly study the influence of inexactness on the local convergence rate. In [110] conditions on the inexactness are given that guarantee descent in the merit function.
Reference: [35] <author> J. E. Dennis, M. El-Alem, and M. C. Maciel, </author> <title> A global convergence theory for general trust-region-based algorithms for equality constrained optimization, </title> <type> Tech. Rep. </type> <institution> TR92-28, Department of Computational and Applied Mathematics, Rice University, </institution> <year> 1992. </year> <note> To appear in SIAM J. Optim. </note>
Reference-contexts: The trust-region technique we use is similar to those that Byrd and Omojokon [115], Dennis, El-Alem, and Maciel <ref> [35] </ref>, and Dennis and Vicente [42] proposed for equality-constrained optimization. Besides assuring global convergence, trust regions regularize ill-conditioned second-order derivatives of the quadratic subproblems. This is very important since many problems in this class are ill-conditioned.) 3. <p> The ability to converge globally to points satisfying the second-order necessary optimality conditions is natural for trust-regions, and it has been shown in the literature for different classes of problems and different trust-region algorithms. We prove this property also for a family of general trust-region algorithms <ref> [35] </ref>, [42] for equality-constrained optimization that use nonorthogonal null-space basis and quasi-normal components. <p> The various trust-region globalizations suggested in the literature for these algorithms are surveyed in Section 3.3. The algorithm that we focus on this chapter is very similar to the trust-region globalizations of the reduced SQP algorithm suggested and analyzed by Byrd and Omojokon [115] and Dennis, El-Alem, and Maciel <ref> [35] </ref>. It is described in great detail in Section 3.4. Then Sections 3.5 and 3.6 present the global convergence for this algorithm. The global convergence to a point satisfying the first-order necessary optimality conditions has been proved in [35]. <p> and analyzed by Byrd and Omojokon [115] and Dennis, El-Alem, and Maciel <ref> [35] </ref>. It is described in great detail in Section 3.4. Then Sections 3.5 and 3.6 present the global convergence for this algorithm. The global convergence to a point satisfying the first-order necessary optimality conditions has been proved in [35]. Our contribution is to prove global convergence to a point satisfying the second-order necessary optimality conditions. See also Dennis and Vicente [42]. The conditions imposed to obtain this result are shown to be satisfied in Section 3.7 for the normal component and the least-squares multipliers. <p> The reduced SQP algorithm has been globalized with trust regions by Byrd and Omojokon [115], Byrd, Schnabel, and Shultz [17], Coleman and Yuan [27], Dennis, El-Alem, and Maciel <ref> [35] </ref>, Dennis and Vicente [42], El-Alem [48], [49], Lalee, Nocedal, and Plantenga [91], Plantenga [118], and Zhang and Zhu [156]. See also Alexandrov [1]. We recommend the surveys given in [35] and [118] for an overview of these different trust-region globalizations. <p> trust regions by Byrd and Omojokon [115], Byrd, Schnabel, and Shultz [17], Coleman and Yuan [27], Dennis, El-Alem, and Maciel <ref> [35] </ref>, Dennis and Vicente [42], El-Alem [48], [49], Lalee, Nocedal, and Plantenga [91], Plantenga [118], and Zhang and Zhu [156]. See also Alexandrov [1]. We recommend the surveys given in [35] and [118] for an overview of these different trust-region globalizations. Trust-region algorithms have been applied also to optimization problems with equality and inequality constraints. See the work by Burke [13], Burke, More, and Toraldo [14], Conn, Gould, and Toint [29], [30], and Yuan [154]. <p> We address these issues in the following points. 1. The choice of trust-region subproblems now seems a settled question. Most of the references cited for trust-region reduced SQP algorithms <ref> [35] </ref>, [42], [48], [49], [91], [115], [118] consider essentially the same choice of trust-region subproblems 33 that was introduced first by Byrd and Omojokon [115] x . We focus on this issue in Section 3.4. 2. <p> One important feature of these decompositions is that s q is not orthogonal to N (J (x)) and that W (x) does not have orthogonal columns. We called such decompositions quasi-normal. In the context of trust regions this was addressed first in Dennis, El-Alem, and Maciel <ref> [35] </ref> and later in Dennis and Vicente [42]. The algorithms we introduce in this thesis use a quasi-normal decomposition. 3. The choice of Lagrange multipliers is associated intimately with the type of step decomposition. <p> The choice of Lagrange multipliers is associated intimately with the type of step decomposition. Most of the researchers [17], [27], [48], [49], [91], [115], [118], [156] considered the least-squares multipliers (3.9) or variations thereof. The work given in <ref> [35] </ref>, [42] departs from the former references by assuming a more general form for the multipliers. For example, in the class of problems described in Chapter 4, the most reasonable choice of multipliers is not the least-squares update but the so-called adjoint update. 4. <p> The augmented Lagrangian has been used in <ref> [35] </ref>, [42], [48], [49], [156], the ` 1 penalty function in [17], the ` 2 penalty function in [27], and the ` 2 penalty function without constraint term squared in [91], [115], [118]. x The Thesis [115] was directed by Professor R. H. Byrd. <p> H. Byrd. The trust-region algorithm proposed here is usually referred as the Byrd and Omojokon algorithm. 34 Let us describe briefly the trust-region globalization analyzed by Dennis, El-Alem, and Maciel <ref> [35] </ref>. The components of the step s q k are only required to satisfy a fraction of Cauchy decrease (or simple decrease) on the corresponding trust-region subproblem. A key assumption that is imposed on the quasi-normal component s q is that it has to be O (kC k k). <p> In this globalization the augmented Lagrangian is used as a merit function combined with the El-Alem's scheme [47] to update the penalty parameter. The main result proved in <ref> [35] </ref> is global convergence to a stationary point (see Theorem 3.6.1). It is important to remark that this result is obtained under very mild conditions on the components of the step, on the multipliers estimates, and on the Hessian approximations. Thus, the Dennis, El-Alem, and Maciel [35] result is similar to <p> main result proved in <ref> [35] </ref> is global convergence to a stationary point (see Theorem 3.6.1). It is important to remark that this result is obtained under very mild conditions on the components of the step, on the multipliers estimates, and on the Hessian approximations. Thus, the Dennis, El-Alem, and Maciel [35] result is similar to the result given by Powell [121] for unconstrained optimization and described in Theorem 2.3.1 (see Figure 1.1). <p> The actual decrease ared (s k ; k ) at the iteration k is given by ared (s k ; k ) = L (x k ; k ; k ) L (x k+1 ; k+1 ; k ): The predicted decrease (see <ref> [35] </ref>) is the following: pred (s k ; k ) = L (x k ; k ; k ) k (J k s k + C k ) + k kJ k s k + C k k 2 : 40 Other forms of predicted decrease were proposed in the literature <p> We remark that the rules to update the trust radius in the previous algorithm can be much more complicated but these suffice to prove convergence results and to understand the trust-region mechanism. 3.4.4 General Assumptions In order to establish global convergence results, we use the general assumptions given in <ref> [35] </ref>. Let be an open subset of IR n such that for all iterations k, x k and x k + s k are in . <p> Theorem 3.6.1 (Dennis, El-Alem, and Maciel <ref> [35] </ref>) If Assumptions 3.1-3.4 hold and the components of the step satisfy Condition 3.1, then lim inf k rf k k + kC k k = 0: (3.41) In this section we assume that the components of the step, the quadratic model, and the multiplier estimates are computed to satisfy Conditions <p> Now we prove Theorem 3.6.2. The proof of (3.42), although simpler, has the same structure as the proof of (3.41) given in <ref> [35] </ref>. Proof of Theorem 3.6.2 We prove by contradiction that lim inf We show that the supposed existence of a * tol &gt; 0 such that kg k k + kC k k + fl k &gt; * tol ; (3.44) for all k, leads to a contradiction. <p> This result is established under very mild assumptions on the steps, the quadratic models, and the Lagrange multipliers. It simultaneously extends the results presented recently by Coleman and Li [23] for simple bounds and those of Dennis, El-Alem, and Maciel <ref> [35] </ref> (see Theorem 3.6.1 in this thesis) for equality constraints. Under additional conditions, we show convergence of the iterates to nondegenerate solutions of the second-order necessary optimality conditions in Theorem 5.5.2, Section 5.5. <p> k kg (see Assumption 5.4) whereas estimate (5.58) comes from (3.38) and inequality (5.39). 5.4 Global Convergence to a First-Order Point The proof of global convergence to a point satisfying the first-order necessary optimality conditions (Theorem 5.4.1) established in this section follows the structure of the convergence theory presented in <ref> [35] </ref> for the equality-constrained optimization problem. This proof is by contradiction and is based on Condition 5.1. We show that the supposition k D k g k k + kC k k &gt; * tol ; for all k, leads to a contradiction. <p> Under Condition 5.1, if k D k g k k + kC k k &gt; * tol for all k then the sequences f k g and fL k g are bounded and ffi k is uniformly bounded away from zero. 100 Proof See Lemmas 7.9-7.13, 8.2 in <ref> [35] </ref>. Our first global convergence result follows. Theorem 5.4.1 Under Assumptions 5.1-5.6 and Condition 5.1 the sequences of iterates generated by the TRIP Reduced SQP Algorithms 5.2.1 satisfy lim inf k rf k k + kC k k = 0: (5.64) Proof The proof is by contradiction. <p> We proved in Chapter 5 global and local convergence results for these algorithms that include as special cases both the results established for equality constraints <ref> [35] </ref>, [42] and those for simple bounds [23]. (See Figures 1.1 and 1.2.) We are satisfied with the sharpness of the results.
Reference: [36] <author> J. E. Dennis, M. Heinkenschloss, and L. N. Vicente, </author> <title> Trust-region interior-point SQP algorithms for a class of nonlinear programming problems, </title> <type> Tech. Rep. </type> <institution> TR94-45, Department of Computational and Applied Mathematics, Rice University, </institution> <year> 1994. </year> <note> Revised November 1995. Appeared also as Tech. Rep. </note> <institution> 94-12-01, Interdisciplinary Center for Applied Mathematics, Virginia Polytechnic Institute and State University. </institution>
Reference-contexts: The assumptions we use to prove these results reduce to the weakest assumptions used to establish similar results in the special cases of unconstrained, equality-constrained, and box-constrained optimization. Our theoretical results, also reported 4 in Dennis, Heinkenschloss, and Vicente <ref> [36] </ref>, generalize similar ones obtained for these simpler problem classes. This is schematized in Figures 1.1 and 1.2. 1.3 Inexact Analysis and Implementation Neither the analysis of the TRIP reduced SQP algorithms nor their implementation would be complete without studying their behavior under the presence of inexactness. <p> Our algorithms are reduced SQP algorithms that use trust-region interior-point (TRIP) techniques to guarantee global convergence and to handle the bound constraints on the controls (see also Dennis, Heinkenschloss, and Vicente <ref> [36] </ref>). As we described in Chapter 4, the structure of optimal control problems given in Section 4.1 can be used to implement and analyze SQP algorithms.
Reference: [37] <author> J. E. Dennis and H. H. W. Mei, </author> <title> Two new unconstrained optimization algorithms which use function and gradient values, </title> <journal> J. Optim. Theory Appl., </journal> <volume> 28 (1979), </volume> <pages> pp. 453-482. </pages>
Reference-contexts: Dennis and Mei <ref> [37] </ref> proposed the so-called double dogleg algorithm. Byrd, Schnabel, and Shultz [18], [130] introduced indefinite dogleg algorithms using two dimensional sub spaces. Now we turn our attention to algorithms for computing steps s k that satisfy the fraction of optimal decrease (2.10).
Reference: [38] <author> J. E. Dennis and J. J. Mor e, </author> <title> Quasi-Newton methods, motivation and theory, </title> <journal> SIAM Rev., </journal> <volume> 19 (1977), </volume> <pages> pp. 46-89. </pages>
Reference-contexts: If H k is positive definite and y T k s k &gt; 0, then H k+1 is also positive definite. The fundamental material about secant updates can be found in the classical references <ref> [38] </ref>, [39]. 31 The Normal Decomposition A popular step decomposition, which amounts to special choices for s q the normal decomposition: s k = s n k = s n k ; (3.6) k is the minimum norm solution of the linearized constraints, and the columns of Z k form an
Reference: [39] <author> J. E. Dennis and R. B. Schnabel, </author> <title> Numerical Methods for Unconstrained Optimization and Nonlinear Equations, </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, New Jersey, </address> <year> 1983. </year> <title> [40] , A view of unconstrained optimization, </title> <booktitle> in Handbooks in Operations Research and Management Science, </booktitle> <editor> G. L. Nemhauser, A. H. G. R. Kan, and M. J. Todd, eds., </editor> <publisher> North Holland, </publisher> <address> Amsterdam, </address> <year> 1988. </year> <note> (Vol. 1, Optimization). 158 </note>
Reference-contexts: The proofs of these basic results can be found in many textbooks like <ref> [39] </ref>, [116]. A quasi-Newton method for the solution of (2.1) generates a sequence of iterates fx k g and steps fs k g such that x k+1 = x k + s k . <p> However this condition can be relaxed and one can see that uniform continuity is enough (see Fletcher [53][Theorem 2.5.1]). Some practical line-search algorithms are described by More and Thuente [107]. For more references see also the books <ref> [39] </ref>, [112], [116] and the review papers [40], [113]. From Theorem 2.2.1, a key ingredient to obtain global convergence to a stationary point is to keep the angle k between g k and d k uniformly bounded away from 2 . <p> Set s k = s (ff fl ). A dogleg step is depicted in Figure 2.1 for a value of ff fl strictly between one and zero. The dogleg algorithm is well defined for H k positive definite (see for instance <ref> [39] </ref>) and can be extended to the case where H k is indefinite. <p> The proof for the dogleg algorithm depends strongly on the positive definiteness of H k and can be found in <ref> [39] </ref>. <p> If H k is positive definite and y T k s k &gt; 0, then H k+1 is also positive definite. The fundamental material about secant updates can be found in the classical references [38], <ref> [39] </ref>. 31 The Normal Decomposition A popular step decomposition, which amounts to special choices for s q the normal decomposition: s k = s n k = s n k ; (3.6) k is the minimum norm solution of the linearized constraints, and the columns of Z k form an orthogonal
Reference: [41] <author> J. E. Dennis and L. N. Vicente, </author> <title> Trust-region interior-point algorithms for minimization problems with simple bounds, </title> <type> Tech. Rep. </type> <institution> TR94-42, Department of Computational and Applied Mathematics, Rice University, </institution> <year> 1994. </year> <note> Revised November 1995. To appear in Springer Lecture Notes Festschrift fur Professor Dr. </note> <author> Klaus Ritter. </author> <title> [42] , On the convergence theory of general trust-region-based algorithms for equality-constrained optimization, </title> <type> Tech. Rep. </type> <institution> TR94-36, Department of Computational and Applied Mathematics, Rice University, </institution> <year> 1994. </year> <note> Revised September 1995. </note>
Reference-contexts: They are valid also if the matrices D k and D k are rede fined respectively as D p p k with p 1. In <ref> [41] </ref>, different forms for this affine scaling matrices are discussed. 5.6 Local Rate of Convergence We now analyze the local behavior of Algorithms 5.2.1 under Conditions 5.1, 5.3, and 5.4.
Reference: [43] <author> P. Deuflhard, </author> <title> Global inexact Newton methods for very large scale nonlinear problems, </title> <booktitle> Impact of Computing in Science and Engineering, 4 (1991), </booktitle> <pages> pp. 366-393. </pages>
Reference-contexts: In the context of systems of nonlinear equations, inexact or truncated Newton methods have been proposed and analyzed by many authors. Some of the pioneering work in this area can be found in [32], [135]. More recent references are [9], [10], <ref> [43] </ref>, [44], [45]. Most of the recent papers investigate the use of Krylov subspace methods for the solution of linear systems, like GMRES [127], in inexact Newton methods.
Reference: [44] <author> S. C. Eisenstat and H. F. Walker, </author> <title> Globally convergent inexact Newton methods, </title> <journal> SIAM J. Optim., </journal> <volume> 4 (1994), </volume> <pages> pp. </pages> <month> 393-422. </month> <title> [45] , Choosing the forcing terms in an inexact Newton method, </title> <journal> SIAM J. Sci. Statist. Comput., </journal> <volume> 17 (1996), </volume> <pages> pp. 16-32. </pages>
Reference-contexts: In the context of systems of nonlinear equations, inexact or truncated Newton methods have been proposed and analyzed by many authors. Some of the pioneering work in this area can be found in [32], [135]. More recent references are [9], [10], [43], <ref> [44] </ref>, [45]. Most of the recent papers investigate the use of Krylov subspace methods for the solution of linear systems, like GMRES [127], in inexact Newton methods. <p> Since the quasi-normal component of the step can be viewed as one step of Newton's method (with a trust-region globalization) towards feasibility of C (y; u) = 0 for fixed u, there is a close relationship with the studies of inexact Newton methods for systems of nonlinear equations <ref> [44] </ref>, [45]. The computation of the tangential component using the coupled approach is another issue that needs further investigation. In particular the loss of symmetry due to the inexactness and the use of nonsymmetric iterative methods for the solution of these subproblems deserves attention (see [101]). 154

Reference: [50] <author> A. S. El-Bakry, R. A. Tapia, Y. Zhang, and T. Tsuchiya, </author> <title> On the formulation and theory of the Newton interior-point method for nonlinear programming, </title> <type> Tech. Rep. </type> <institution> TR92-40, Department of Computational and Applied Mathematics, Rice University, </institution> <year> 1992. </year> <note> Revised April 1995. To appear in J. Op-tim. Theory Appl. </note>
Reference-contexts: As a possible alternative for the affine scaling interior-point strategy, we have in mind the use of primal-dual interior-point algorithms. For general nonlinear programs of the form (4.20) these algorithms have been studied in <ref> [50] </ref>, [98], [148] where they are referred also as Newton or quasi-Newton interior-point methods. The formulation and analysis of the TRIP reduced SQP algorithms in an infinite dimensional framework is another research topic that deserves to be investigated.
Reference: [51] <author> M. El-Hallabi, </author> <title> A global convergence theory for arbitrary norm trust-region algorithms for equality constrained optimization, </title> <type> Tech. Rep. </type> <institution> TR93-60, Department of Computational and Applied Mathematics, Rice University, </institution> <year> 1993. </year> <month> Revised May </month> <year> 1995. </year>
Reference-contexts: Globalizations of SQP algorithms were given by Celis, Dennis, and Tapia [21] (see also Yuan [152] and Zhang [157]), Conn, Gould, and Toint [30], El-Alem [47], Fletcher [52], Vardi [141] (see also El-Hallabi <ref> [51] </ref>), and Powell and Yuan [123].
Reference: [52] <author> R. Fletcher, </author> <title> An ` 1 penalty method for nonlinear constraints, </title> <note> in Numerical Optimization 1984, </note> <author> P. T. Boggs, R. H. Byrd, and R. B. Schnabel, </author> <title> eds., </title> <publisher> SIAM, </publisher> <address> Philadelphia, </address> <year> 1985, </year> <pages> pp. </pages> <month> 26-40. </month> <title> [53] , Practical Methods of Optimization, </title> <publisher> John Wiley & Sons, </publisher> <address> Chichester, </address> <note> second ed., </note> <year> 1987. </year>
Reference-contexts: Globalizations of SQP algorithms were given by Celis, Dennis, and Tapia [21] (see also Yuan [152] and Zhang [157]), Conn, Gould, and Toint [30], El-Alem [47], Fletcher <ref> [52] </ref>, Vardi [141] (see also El-Hallabi [51]), and Powell and Yuan [123].
Reference: [54] <author> R. Fontecilla, </author> <title> On inexact quasi-Newton methods for constrained optimization, </title> <note> in Numerical Optimization 1984, </note> <author> P. T. Boggs, R. H. Byrd, and R. B. Schnabel, </author> <title> eds., </title> <publisher> SIAM, </publisher> <address> Philadelphia, </address> <year> 1985, </year> <pages> pp. 102-118. </pages>
Reference-contexts: In a recent paper 123 [149], the impact of inexactness in reduced-gradient methods for design optimization has been analyzed. In nonlinear programming, inexactness has been studied by [6], [28], [34], <ref> [54] </ref>, [92], [110], [146] among others. The papers [34], [54], [92], [110] investigating SQP algorithms mostly study the influence of inexactness on the local convergence rate. In [110] conditions on the inexactness are given that guarantee descent in the merit function. <p> In a recent paper 123 [149], the impact of inexactness in reduced-gradient methods for design optimization has been analyzed. In nonlinear programming, inexactness has been studied by [6], [28], [34], <ref> [54] </ref>, [92], [110], [146] among others. The papers [34], [54], [92], [110] investigating SQP algorithms mostly study the influence of inexactness on the local convergence rate. In [110] conditions on the inexactness are given that guarantee descent in the merit function.
Reference: [55] <author> R. Freund, </author> <title> A transpose-free quasi-minimal residual algorithm for non-Hermitian linear systems, </title> <journal> SIAM J. Sci. Statist. Comput., </journal> <volume> 14 (1993), </volume> <pages> pp. 470-482. </pages>
Reference-contexts: In this case one can apply nonsymmetric transpose-free Krylov subspace methods based on minimum residual approximations, such as GMRES [127] or TFQMR <ref> [55] </ref>. In the context of nonlinear system solving the use of such methods is described by Brown and Saad [10], [11]. <p> The condition (6.27) is implied by the positive definiteness of the symmetric part of C y (x k ), a condition also important for the convergence of nonsymmetric Krylov subspace methods [72]. If V l and W l+1 are not orthogonal, e.g. if TFQMR <ref> [55] </ref> is used, then (6.25) is not equivalent to (6.23). However, as in the context of linear system solving, one can solve (6.25) for z and use (6.24) as a quasi-normal component.
Reference: [56] <author> D. M. Gay, </author> <title> Computing optimal locally constrained steps, </title> <journal> SIAM J. Sci. Statist. Comput., </journal> <volume> 2 (1981), </volume> <pages> pp. 186-197. </pages>
Reference-contexts: Proposition 2.3.2 The trust-region subproblem (2.2) has no solutions at the boundary fs : ksk = ffi k g if and only if H k is positive definite and kH 1 A proof of this simple fact can be found in [106]. Proposition 2.3.3 (Gay <ref> [56] </ref> and Sorensen [132]) The step o k is an optimal solution of the trust-region subproblem (2.2) if and only if ko k k ffi k and there exists fl k 0 such that H k + fl k I n is positive semi-definite; (2.11) (H k + fl k I <p> They showed that the algorithm computes a step s k satisfying the optimal decrease conditions (2.10). Their algorithm and corresponding Fortran implementation GQTPAR are based on previous work done by Gay <ref> [56] </ref> and Sorensen [132]. To compute 2 (fl) and 0 2 (fl), algorithms of the More and Sorensen type require a Cholesky factorization R T fl R fl of H k + flI n whenever this matrix is positive definite. <p> More [103] showed how to generalize these theorems for trust-region constraints of the form kS k sk ffi k , where fS k g is a sequence of nonsingular scaling matrices. Related results can be found in references <ref> [56] </ref>, [106], [130], [132]. 2.3.4 Tikhonov Regularization In this section we show how the Tikhonov regularization [138] for ill-conditioned linear least-squares is related to a particular trust-region subproblem. This is one of many arguments that justify the use of trust regions as a regularization technique.
Reference: [57] <author> I. M. Gel'fand, </author> <title> Some problems in the theory of quasilinear equations, </title> <journal> Amer. Math. Soc. Transl., </journal> <volume> 29 (1963), </volume> <pages> pp. 295-381. </pages>
Reference-contexts: The state equation (4.27) is related to the time dependent problem @y @t = y + e y ; t &gt; 0, that arises in thermal self-ignition of a chemically active mixture of gases in a vessel as described in Gel'fand <ref> [57] </ref>. 73 For g (y) = e y , u = 0, and d = 0, the state equation (4.27) reduces to the Bratu problem: y = e y ; in ; (4.30) This problem models diffusion phenomena in combustion and semiconductors and has become a standard test problem for solvers
Reference: [58] <author> P. E. Gill, W. Murray, M. Saunders, G. W. Stewart, and M. H. Wright, </author> <title> Properties of a representation of a basis for the null space, </title> <journal> Math. Programming, </journal> <volume> 33 (1985), </volume> <pages> pp. 172-186. </pages>
Reference-contexts: The continuity of an orthogonal null-space basis Z (x) for N (J (x)) has been discussed in [16], [26], <ref> [58] </ref>. A straightforward implementation of the QR factorization of J (x) T might produce a discontinuous null-space orthogonal basis Z (x). However, Coleman and Sorensen [26] showed how to modify the QR factorization in such a way that Z (x) inherits the smoothness of J (x) T .
Reference: [59] <author> P. E. Gill, W. Murray, M. A. Saunders, and M. H. Wright, </author> <title> User's guide for NPSOL (version 4.0): A FORTRAN package for nonlinear programming, </title> <type> Technical Report SOL 86-2, </type> <institution> Systems Optimization Laboratory, Depart 160 ment of Operations Research, Stanford University, Stanford, </institution> <address> CA 94305-4022, </address> <year> 1986. </year>
Reference-contexts: SQP algorithms are very successful for the solution of constrained optimization problems. See e.g. [5], <ref> [59] </ref>, [91], [108]. They are often quasi-Newton type algorithms in the sense that they rely on a Newton iteration and approximate second-order derivatives. The primary goal of these algorithms is to find a point that satisfies the first-order necessary optimality conditions.
Reference: [60] <author> P. E. Gill, W. Murray, and M. H. Wright, </author> <title> Practical Optimization, </title> <publisher> Academic Press, INC., </publisher> <address> San Diego, </address> <year> 1981. </year> <title> [61] , Some theoretical properties of an augmented Lagrangian merit function, </title> <type> Technical Report SOL 86-6, </type> <institution> Systems Optimization Laboratory, Department of Operations Research, Stanford University, Stanford, </institution> <address> CA 94305-4022, </address> <year> 1986. </year>
Reference-contexts: The next two propositions review the optimality conditions for problem (3.1). For proofs and related material see the books [53], <ref> [60] </ref>, [96], [112]. Proposition 3.1.1 (First-Order Necessary Optimality Conditions) If the regular point x fl is a local minimizer of (3.1), then there exists a fl 2 IR m such that C (x fl ) = 0 and The vector fl is the vector of Lagrange multipliers.
Reference: [62] <author> R. Glowinski, </author> <title> Numerical Methods for Nonlinear Variational Problems, </title> <publisher> Springer-Verlag, </publisher> <address> Berlin, Heidelberg, New York, Tokyo, </address> <year> 1984. </year>
Reference-contexts: semiconductors and has become a standard test problem for solvers of systems of nonlinear equations (see the description by Glowinski and Keller in the collection of nonlinear model problems assembled by More [104].) The numerical treatment by finite element methods and the solvability of the Bratu problem is discussed in <ref> [62, Section IV.2] </ref>, [63]. For the discretization of this optimal control problem one can use piecewise linear finite elements for both the states and the controls.
Reference: [63] <author> R. Glowinski, H. B. Keller, and L. Reinhart, </author> <title> Continuation-conjugate gradient methods for the least-squares solution of nonlinear boundary value problems, </title> <journal> SIAM J. Sci. Statist. Comput., </journal> <volume> 6 (1985), </volume> <pages> pp. 793-832. </pages>
Reference-contexts: become a standard test problem for solvers of systems of nonlinear equations (see the description by Glowinski and Keller in the collection of nonlinear model problems assembled by More [104].) The numerical treatment by finite element methods and the solvability of the Bratu problem is discussed in [62, Section IV.2], <ref> [63] </ref>. For the discretization of this optimal control problem one can use piecewise linear finite elements for both the states and the controls. <p> Heinkenschloss (ICAM, Virginia Polytechnic Institute and State University) with piecewise linear finite elements on a uniform triangulation obtained by first subdividing the x and the y subinterval into a sample of subintervals and then cutting each resulting subsquare into two 147 triangles (see for instance <ref> [63] </ref>). The same discretization was used for the states and the controls. The norms used for the states and controls are the discretizations of the H 1 () and L 2 () norms.
Reference: [64] <author> S. Goldfeld, R. Quandt, and H. Trotter, </author> <title> Maximization by quadratic hill climbing, </title> <journal> Econometrica, </journal> <volume> 34 (1966), </volume> <pages> pp. 541-551. </pages>
Reference-contexts: (2.3)-(2.4), and the condition number (H k ) of H k is uniformly bounded, then fx k g satisfies lim kg k k = 0: 2.3 The Trust-Region Technique The development of trust regions started with the work of Levenberg [93] (1944), Marquardt [97] (1963), and Goldfeld, Quandt, and Trotter <ref> [64] </ref> (1966). A few years later Powell [120], [121] (1970, 1975), Hebden [71] (1973), and More [102] (1978) opened the field of research in this area. Trust-region algorithms are efficient and robust techniques to solve unconstrained optimization problems.
Reference: [65] <author> A. A. Goldstein, </author> <title> On steepest descent, </title> <journal> SIAM J. Control Optim., </journal> <volume> 3 (1965), </volume> <pages> pp. 147-151. </pages>
Reference-contexts: If for all k, s k = k d k satisfies (2.3)-(2.4) and the direction d k is descent, then lim cos ( k )kg k k = 0: Some of the ground work that led to this result was provided by Armijo [2] and Goldstein <ref> [65] </ref>. It was established by Wolfe [144], [145] and Zoutendijk [158], under the assumption that the gradient is Lipschitz continuous. However this condition can be relaxed and one can see that uniform continuity is enough (see Fletcher [53][Theorem 2.5.1]). Some practical line-search algorithms are described by More and Thuente [107].
Reference: [66] <author> G. H. Golub and C. F. Van Loan, </author> <title> Matrix Computations, </title> <publisher> The John Hopkins University Press, </publisher> <address> Baltimore and London, </address> <note> second ed., </note> <year> 1989. </year>
Reference: [67] <author> G. H. Golub and U. von Matt, </author> <title> Quadratically constrained least squares and quadratic problems, </title> <journal> Numer. Math., </journal> <volume> 59 (1991), </volume> <pages> pp. 561-580. </pages>
Reference-contexts: The trust-region constraint is enforced by scaling the solution. 6.3.1 Methods that Use the Transpose There are various ways to compute the quasi-normal component s q k for large-scale problems. For example, one can use the Conjugate-Gradient Algorithm 2.3.2, or one can use the Lanczos bidiagonalization as described in <ref> [67] </ref>. Both methods compute an approximate solution of (6.19) from a subspace that contains the negative gradient C y (x k ) T C k of the least squares functional 1 2 kC y (x k )(s q ) y + C k k 2 . <p> In Theorem 3.8.1, Section 3.8, we pointed out the 132 numerical difficulties that these trust-region subproblems are likely to offer to algorithms that compute steps satisfying a fraction of optimal decrease condition. The Lanczos bidiagonalization algorithm in <ref> [67] </ref> is another algorithm that computes steps satisfying this property when applied to the trust-region subproblem (6.19). 6.3.2 Methods that Are Transpose Free The Conjugate-Gradient Algorithm 2.3.2, the Lanczos bidiagonalization algorithm [67], and the algorithms in [129], [133] require the computation of matrix-vector products of the form C y (x k <p> The Lanczos bidiagonalization algorithm in <ref> [67] </ref> is another algorithm that computes steps satisfying this property when applied to the trust-region subproblem (6.19). 6.3.2 Methods that Are Transpose Free The Conjugate-Gradient Algorithm 2.3.2, the Lanczos bidiagonalization algorithm [67], and the algorithms in [129], [133] require the computation of matrix-vector products of the form C y (x k )d y and C y (x k ) T d y for a given d y in IR m .
Reference: [68] <author> J. Goodman, </author> <title> Newton's method for constrained optimization, </title> <journal> Math. Programming, </journal> <volume> 33 (1985), </volume> <pages> pp. 162-171. </pages>
Reference-contexts: The letter q stands for quotient and distinguishes the q-quadratic rate from the r-rate, where r stands for root. See [116][Chapter 9]. 32 least-squares multipliers (3.9). An elegant proof of this latter result was provided by Goodman <ref> [68] </ref>. <p> This is related to Goodman's approach <ref> [68] </ref> for an orthogonal 77 null-space basis and equality constraints (see the discussion at the end of Section 3.2). Although D (x) 2 is usually discontinuous at points where = 0, the function D (x) 2 W (x) T rf (x) is continuous (but not differentiable) at such points.
Reference: [69] <author> C. W. Groetsch, </author> <title> Generalized Inverses of Linear Operators, </title> <publisher> Marcel Dekker, Inc., </publisher> <address> New York, Basel, </address> <year> 1977. </year>
Reference-contexts: There are situations where, due to the lack of an inverse or a continuous inverse for A, the solution to (2.20) does not depend continuously on b (see for instance <ref> [69] </ref>).
Reference: [70] <author> W. A. Gruver and E. W. Sachs, </author> <title> Algorithmic Methods In Optimal Control, </title> <publisher> Pitman, </publisher> <address> London, </address> <year> 1980. </year>
Reference-contexts: Its solution is part of the evaluation of the objective function ^ f (u). The reduced problem can be solved by a Newton-like method. For optimal control problems, many algorithms follow this approach and use projection techniques <ref> [70] </ref>, [119] to handle the bounds on the variables u. The reduced problem (4.8) is important since it leads us to the use of reduced SQP algorithms.
Reference: [71] <author> M. D. Hebden, </author> <title> An algorithm for minimization using exact second order derivatives, </title> <type> Tech. Rep. T.P. 515, </type> <institution> Atomic Energy Research Establishment, </institution> <address> Har-well, England, </address> <year> 1973. </year> <month> 161 </month>
Reference-contexts: A few years later Powell [120], [121] (1970, 1975), Hebden <ref> [71] </ref> (1973), and More [102] (1978) opened the field of research in this area. Trust-region algorithms are efficient and robust techniques to solve unconstrained optimization problems. An excellent survey in this area was written by More [103] in 1983. Let us describe how the trust-region technique works. <p> Reinsch [125] and Hebden <ref> [71] </ref> were the first to observe that Newton's method performs better when applied to (2.15).

Reference: [76] <author> M. Heinkenschloss and L. N. Vicente, TRIP: </author> <title> A Package for the Solution of a Class of Constrained Optimization Problems; User's Guide. In preparation. [77] , Analysis of inexact trust-region interior-point SQP algorithms, </title> <type> Tech. Rep. </type> <institution> TR95-18, Department of Computational and Applied Mathematics, Rice University, </institution> <year> 1995. </year> <note> Appeared also as Tech. Rep. </note> <institution> 95-06-01, Interdisciplinary Center for Applied Mathematics, Virginia Polytechnic Institute and State University. </institution>
Reference-contexts: To our knowledge, inexactness for SQP algorithms with trust-region globalizations has not been studied in the literature. In practice the TRIP reduced SQP algorithms are robust and efficient techniques for a variety of problems. The implementation of these algorithms is currently being beta-tested with the intent of electronic distribution <ref> [76] </ref>. The current implementation provides the user with a number of alternatives to compute the steps and to approximate second-order derivatives. There are two versions, one in Fortran 77 and one in Matlab. <p> The updates (5.94), (5.95), and (5.96) satisfy the requirement given by Assumption 5.4 needed to prove global convergence to a point satisfying the first-order necessary optimality conditions. 5.8 Numerical Example We implemented the TRIP Reduced SQP Algorithms 5.2.1 in Fortran 77. This implementation is described in <ref> [76] </ref>. In this section we report numerical results for the boundary control problem introduced in Section 4.5.1. These results demonstrate the effectiveness of the algorithms. We use the formula (5.91) to compute the quasi-normal component, and Algorithms 5.7.1 and 5.7.2 to calculate the tangential component. <p> In the implementation, the LINPACK subroutine DGTSL was used to solve the tridiagonal systems. As we pointed out in Section 4.6, the inner products and norms used in the TRIP reduced SQP algorithms are not necessarily the Euclidean ones. In our implementation <ref> [76] </ref>, we call subroutines to calculate the inner products hy 1 ; y 2 i and hu 1 ; u 2 i with y 1 ; y 2 2 IR m and u 1 ; u 2 2 IR nm . <p> The implementation is described in <ref> [76] </ref>. The numerical test computations were done on a Sun Sparcstation 10 in double precision Fortran 77. We solved the two examples described in Section 4.5 with a regularization parameter fl = 10 3 . The numerical results are satisfactory and revealed interesting properties of these algorithms. <p> The implementation covers several step computations and second-order approximations. The numerical results reported in Sections 5.8 and 6.5 were quite satisfactory and confirmed most of our theoretical findings. The software that produced these results currently is being beta-tested with the intent of electronic distribution <ref> [76] </ref>. Chapter 3 demonstrates global convergence to a point satisfying the second-order necessary optimality conditions for a family of trust-region algorithms for equality-constrained optimization and presents a detailed analysis of the trust-region subprob-lem for the linearized constraints.
Reference: [78] <author> M. R. Hestenes and E. </author> <title> Stiefel, Methods of conjugate gradients for solving linear systems, </title> <institution> J. Res. Nat. Bur. Standards, </institution> <month> 49 </month> <year> (1952), </year> <pages> pp. 409-436. </pages>
Reference-contexts: The dogleg algorithm is well defined for H k positive definite (see for instance [39]) and can be extended to the case where H k is indefinite. A possible way to accomplish this is to generalize the use of the classical conjugate-gradient algorithm of Hestenes and Stiefel <ref> [78] </ref> for the solution of the linear system H k s = g k with H k positive definite. Steihaug [134] and Toint [139] adapted this algorithm for the solution of the trust-region subproblem (2.2). Here two new situations have to be considered.
Reference: [79] <author> K. Ito and K. Kunisch, </author> <title> The augmented Lagrangian method for parameter estimation in elliptic systems, </title> <journal> SIAM J. Control Optim., </journal> <volume> 28 (1990), </volume> <pages> pp. 113-136. </pages>
Reference-contexts: The so-called all-at-once approach treats both y and u as independent variables. All-at-once approaches were proposed to solve optimal control problems among many others in [74], <ref> [79] </ref>, [82], [83], [85], [86], [87], [89]. For the optimal control problems that we consider in this thesis, the all-at-once approach is based on the formulation (4.7) (actually (4.1) if we include the bound constraints on the controls).
Reference: [80] <author> W. Karush, </author> <title> Minima of Functions of Several Variables with Inequalities as Side Constraints, </title> <type> Master's thesis, </type> <institution> Department of Mathematics, University of Chicago, </institution> <year> 1939. </year>
Reference-contexts: These conditions provide a powerful characterization of local minimizers in nonlinear programming and are used in many different fields of mathematics and science. They were discovered independently by Karush <ref> [80] </ref> in 1939 and by Kuhn and Tucker [84] in 1951. One can see these conditions as an extension of the Lagrange multiplier theory for problems with equality constraints (see Propositions 3.1.1 and 3.1.2) to problems with both equality and inequality constraints.
Reference: [81] <author> C. T. Kelley, </author> <title> Iterative Methods for Linear and Nonlinear Equations, </title> <publisher> SIAM, </publisher> <address> Philadelphia, Pennsylvania, </address> <year> 1995. </year>
Reference-contexts: In many iterative methods, like for instance Krylov subspace methods (see the books [72], <ref> [81] </ref>), the norms kr k k and k^r k k can be computed efficiently with few extra operations.
Reference: [82] <author> C. T. Kelley and E. W. Sachs, </author> <title> Solution of optimal control problems by a pointwise projected Newton method, </title> <journal> SIAM J. Control Optim., </journal> <volume> 33 (1995), </volume> <pages> pp. 1731-1757. 162 </pages>
Reference-contexts: The so-called all-at-once approach treats both y and u as independent variables. All-at-once approaches were proposed to solve optimal control problems among many others in [74], [79], <ref> [82] </ref>, [83], [85], [86], [87], [89]. For the optimal control problems that we consider in this thesis, the all-at-once approach is based on the formulation (4.7) (actually (4.1) if we include the bound constraints on the controls).
Reference: [83] <author> C. T. Kelley and S. J. Wright, </author> <title> Sequential quadratic programming for certain parameter identification problems, </title> <journal> Math. Programming, </journal> <volume> 51 (1991), </volume> <pages> pp. 281-305. </pages>
Reference-contexts: The so-called all-at-once approach treats both y and u as independent variables. All-at-once approaches were proposed to solve optimal control problems among many others in [74], [79], [82], <ref> [83] </ref>, [85], [86], [87], [89]. For the optimal control problems that we consider in this thesis, the all-at-once approach is based on the formulation (4.7) (actually (4.1) if we include the bound constraints on the controls). <p> A purely local analysis for the case with no bounds constraints has being given in <ref> [83] </ref>, [86], [87], [89]. However, we consider here the much more difficult issue of incorporating all this structure into an algorithm that converges globally and handles bound constraints on the control variables u. 75 The global convergence of our algorithms is guaranteed by a trust-region strategy.
Reference: [84] <author> H. W. Kuhn and A. W. Tucker, </author> <title> Nonlinear programming, </title> <booktitle> in Proceedings of the Second Berkeley Symposium on Mathematical Statistics and Probability, </booktitle> <editor> J. Neyman, ed., </editor> <publisher> University of California Press, </publisher> <year> 1951. </year>
Reference-contexts: These conditions provide a powerful characterization of local minimizers in nonlinear programming and are used in many different fields of mathematics and science. They were discovered independently by Karush [80] in 1939 and by Kuhn and Tucker <ref> [84] </ref> in 1951. One can see these conditions as an extension of the Lagrange multiplier theory for problems with equality constraints (see Propositions 3.1.1 and 3.1.2) to problems with both equality and inequality constraints.
Reference: [85] <author> K. Kunisch and G. Peichl, </author> <title> Estimation of a temporally and spatially varying diffusion coefficient in a parabolic system by an augmented Lagrangian technique, </title> <journal> Numer. Math., </journal> <volume> 59 (1991), </volume> <pages> pp. 473-509. </pages>
Reference-contexts: The so-called all-at-once approach treats both y and u as independent variables. All-at-once approaches were proposed to solve optimal control problems among many others in [74], [79], [82], [83], <ref> [85] </ref>, [86], [87], [89]. For the optimal control problems that we consider in this thesis, the all-at-once approach is based on the formulation (4.7) (actually (4.1) if we include the bound constraints on the controls).
Reference: [86] <author> K. Kunisch and E. Sachs, </author> <title> Reduced SQP methods for parameter identification problems, </title> <journal> SIAM J. Numer. Anal., </journal> <volume> 29 (1992), </volume> <pages> pp. 1793-1820. </pages>
Reference-contexts: The so-called all-at-once approach treats both y and u as independent variables. All-at-once approaches were proposed to solve optimal control problems among many others in [74], [79], [82], [83], [85], <ref> [86] </ref>, [87], [89]. For the optimal control problems that we consider in this thesis, the all-at-once approach is based on the formulation (4.7) (actually (4.1) if we include the bound constraints on the controls). <p> A purely local analysis for the case with no bounds constraints has being given in [83], <ref> [86] </ref>, [87], [89]. However, we consider here the much more difficult issue of incorporating all this structure into an algorithm that converges globally and handles bound constraints on the control variables u. 75 The global convergence of our algorithms is guaranteed by a trust-region strategy.
Reference: [87] <author> F.-S. Kupfer, </author> <title> Reduced Successive Quadratic Programming in Hilbert Space with Applications to Optimal Control, </title> <type> PhD thesis, </type> <institution> Universitat Trier, Fb-IV, Mathematik, D-54286 Trier, Germany, </institution> <year> 1992. </year>
Reference-contexts: The so-called all-at-once approach treats both y and u as independent variables. All-at-once approaches were proposed to solve optimal control problems among many others in [74], [79], [82], [83], [85], [86], <ref> [87] </ref>, [89]. For the optimal control problems that we consider in this thesis, the all-at-once approach is based on the formulation (4.7) (actually (4.1) if we include the bound constraints on the controls). <p> The goal is to move towards optimality and feasibility at the same time, and this offers significant advantages. SQP algorithms are of particular interest since they allow use of the structure of optimal control problems, see e.g. <ref> [87] </ref>, [88]. As we saw in Chapter 3 for equality-constrained optimization they do not require the (possibly very expensive) solution of the nonlinear state equation C (y; u) = 0 at every iteration. <p> A purely local analysis for the case with no bounds constraints has being given in [83], [86], <ref> [87] </ref>, [89]. However, we consider here the much more difficult issue of incorporating all this structure into an algorithm that converges globally and handles bound constraints on the control variables u. 75 The global convergence of our algorithms is guaranteed by a trust-region strategy.
Reference: [88] <author> F.-S. Kupfer and E. W. Sachs, </author> <title> A prospective look at SQP methods for semilinear parabolic control problems, in Optimal Control of Partial Differential Equations, Irsee 1990, </title> <editor> K.-H. Hoffmann and W. Krabs, eds., </editor> <volume> vol. 149, </volume> <booktitle> Springer Lect. Notes in Control and Information Sciences, </booktitle> <year> 1991, </year> <pages> pp. </pages> <month> 143-157. </month> <title> [89] , Numerical solution of a nonlinear parabolic control problem by a reduced SQP method, </title> <journal> Computational Optimization and Applications, </journal> <volume> 1 (1992), </volume> <pages> pp. 113-135. </pages>
Reference-contexts: The goal is to move towards optimality and feasibility at the same time, and this offers significant advantages. SQP algorithms are of particular interest since they allow use of the structure of optimal control problems, see e.g. [87], <ref> [88] </ref>. As we saw in Chapter 3 for equality-constrained optimization they do not require the (possibly very expensive) solution of the nonlinear state equation C (y; u) = 0 at every iteration.
Reference: [90] <author> J. L. </author> <title> Lagrange, Oeuvres de Lagrange, Volumes XI and XII, </title> <publisher> Gauthier-Villars, Paris, </publisher> <pages> 1888-1889. </pages>
Reference-contexts: Although it is the name of Lagrange <ref> [90] </ref> that is associated with the optimality conditions for optimization problems with equality constraints, credit should be given also to Euler (see the discussion in [112][Chapter 14, Section 9]). In the eighteen century the two mathematicians solved problems in calculus of variations using optimality conditions for equality constraints.
Reference: [91] <author> M. Lalee, J. Nocedal, and T. Plantenga, </author> <title> On the implementation of an algorithm for large-scale equality constrained optimization. </title> <note> Submitted for publication, </note> <year> 1994. </year>
Reference-contexts: SQP algorithms are very successful for the solution of constrained optimization problems. See e.g. [5], [59], <ref> [91] </ref>, [108]. They are often quasi-Newton type algorithms in the sense that they rely on a Newton iteration and approximate second-order derivatives. The primary goal of these algorithms is to find a point that satisfies the first-order necessary optimality conditions. <p> The reduced SQP algorithm has been globalized with trust regions by Byrd and Omojokon [115], Byrd, Schnabel, and Shultz [17], Coleman and Yuan [27], Dennis, El-Alem, and Maciel [35], Dennis and Vicente [42], El-Alem [48], [49], Lalee, Nocedal, and Plantenga <ref> [91] </ref>, Plantenga [118], and Zhang and Zhu [156]. See also Alexandrov [1]. We recommend the surveys given in [35] and [118] for an overview of these different trust-region globalizations. Trust-region algorithms have been applied also to optimization problems with equality and inequality constraints. <p> We address these issues in the following points. 1. The choice of trust-region subproblems now seems a settled question. Most of the references cited for trust-region reduced SQP algorithms [35], [42], [48], [49], <ref> [91] </ref>, [115], [118] consider essentially the same choice of trust-region subproblems 33 that was introduced first by Byrd and Omojokon [115] x . We focus on this issue in Section 3.4. 2. The decomposition of the step considered in references [17], [27], [48], [49], [91], [115], [118], [156] is the normal <p> SQP algorithms [35], [42], [48], [49], <ref> [91] </ref>, [115], [118] consider essentially the same choice of trust-region subproblems 33 that was introduced first by Byrd and Omojokon [115] x . We focus on this issue in Section 3.4. 2. The decomposition of the step considered in references [17], [27], [48], [49], [91], [115], [118], [156] is the normal decomposition (3.6). In many application problems there are other reasonable decompositions of the step. This is clearly the case for the class of problems introduced in Chapter 4. <p> The algorithms we introduce in this thesis use a quasi-normal decomposition. 3. The choice of Lagrange multipliers is associated intimately with the type of step decomposition. Most of the researchers [17], [27], [48], [49], <ref> [91] </ref>, [115], [118], [156] considered the least-squares multipliers (3.9) or variations thereof. The work given in [35], [42] departs from the former references by assuming a more general form for the multipliers. <p> The augmented Lagrangian has been used in [35], [42], [48], [49], [156], the ` 1 penalty function in [17], the ` 2 penalty function in [27], and the ` 2 penalty function without constraint term squared in <ref> [91] </ref>, [115], [118]. x The Thesis [115] was directed by Professor R. H. Byrd. The trust-region algorithm proposed here is usually referred as the Byrd and Omojokon algorithm. 34 Let us describe briefly the trust-region globalization analyzed by Dennis, El-Alem, and Maciel [35]. <p> Other schemes to update the penalty parameter were suggested in the literature. El-Alem [48], [49] proposed a nonmonotone scheme to update the penalty parameter for which he proved many convergence results, including global convergence to points satisfying the second-order necessary optimality conditions. Lalee, Nocedal, and Plantenga <ref> [91] </ref> proposed and tested another nonmonotone scheme for the penalty parameter, but they did not provide any convergence analysis. The general reduced trust-region SQP algorithm is given below. Algorithm 3.4.1 (Trust-Region Reduced SQP Algorithm) 1 Choose x 0 , ffi 0 , and 0 . Set 1 1.
Reference: [92] <author> F. Leibfritz and E. W. Sachs, </author> <title> Numerical solution of parabolic state constrained control problems using SQP- and interior-point-methods, in Large Scale Optimization: State of the Art, </title> <editor> W. W. Hager, D. Hearn, and P. Pardalos, eds., </editor> <publisher> Kluwer, </publisher> <year> 1994, </year> <pages> pp. 251-264. 163 </pages>
Reference-contexts: In a recent paper 123 [149], the impact of inexactness in reduced-gradient methods for design optimization has been analyzed. In nonlinear programming, inexactness has been studied by [6], [28], [34], [54], <ref> [92] </ref>, [110], [146] among others. The papers [34], [54], [92], [110] investigating SQP algorithms mostly study the influence of inexactness on the local convergence rate. In [110] conditions on the inexactness are given that guarantee descent in the merit function. <p> In a recent paper 123 [149], the impact of inexactness in reduced-gradient methods for design optimization has been analyzed. In nonlinear programming, inexactness has been studied by [6], [28], [34], [54], <ref> [92] </ref>, [110], [146] among others. The papers [34], [54], [92], [110] investigating SQP algorithms mostly study the influence of inexactness on the local convergence rate. In [110] conditions on the inexactness are given that guarantee descent in the merit function.
Reference: [93] <author> K. Levenberg, </author> <title> A method for the solution of certain nonlinear problems in least squares, </title> <journal> Quart. Appl. Math., </journal> <volume> 2 (1944), </volume> <pages> pp. 164-168. </pages>
Reference-contexts: k = k H 1 k g k satisfies 13 (2.3)-(2.4), and the condition number (H k ) of H k is uniformly bounded, then fx k g satisfies lim kg k k = 0: 2.3 The Trust-Region Technique The development of trust regions started with the work of Levenberg <ref> [93] </ref> (1944), Marquardt [97] (1963), and Goldfeld, Quandt, and Trotter [64] (1966). A few years later Powell [120], [121] (1970, 1975), Hebden [71] (1973), and More [102] (1978) opened the field of research in this area. Trust-region algorithms are efficient and robust techniques to solve unconstrained optimization problems.
Reference: [94] <author> Y. Li, </author> <title> On global convergence of a trust region and affine scaling method for non-linearly constrained minimization, </title> <type> Tech. Rep. </type> <institution> CTC94TR197, Advanced Computing Research Institute, Cornell University, </institution> <year> 1994. </year> <title> [95] , A trust region and affine scaling method for nonlinearly constrained minimization, </title> <type> Tech. Rep. </type> <institution> CTC94TR198, Advanced Computing Research Institute, Cornell University, </institution> <year> 1994. </year>
Reference-contexts: In our context, the affine scaling interior-point algorithm is also of interest, because it does not interfere with the structure of the problem. To apply this algorithm, no additional information is required from the user. This or similar interior-point approaches have recently also been used e.g. in [7], [25], <ref> [94] </ref>, [95], [118]. The advantage of the approach in [23] is that the scaling matrix is determined by the distance of the iterates to the bounds and by the direction of the gradient.
Reference: [96] <author> D. Luenberger, </author> <title> Linear and Nonlinear Programming, </title> <publisher> Addison-Wesley Publishing Company, </publisher> <address> Massachusetts, </address> <year> 1989. </year>
Reference-contexts: The next two propositions review the optimality conditions for problem (3.1). For proofs and related material see the books [53], [60], <ref> [96] </ref>, [112]. Proposition 3.1.1 (First-Order Necessary Optimality Conditions) If the regular point x fl is a local minimizer of (3.1), then there exists a fl 2 IR m such that C (x fl ) = 0 and The vector fl is the vector of Lagrange multipliers.
Reference: [97] <author> D. W. Marquardt, </author> <title> An algorithm for least squares estimation of nonlinear parameters, </title> <journal> SIAM J. Math. Anal., </journal> <volume> 11 (1963), </volume> <pages> pp. 431-441. </pages>
Reference-contexts: H 1 k g k satisfies 13 (2.3)-(2.4), and the condition number (H k ) of H k is uniformly bounded, then fx k g satisfies lim kg k k = 0: 2.3 The Trust-Region Technique The development of trust regions started with the work of Levenberg [93] (1944), Marquardt <ref> [97] </ref> (1963), and Goldfeld, Quandt, and Trotter [64] (1966). A few years later Powell [120], [121] (1970, 1975), Hebden [71] (1973), and More [102] (1978) opened the field of research in this area. Trust-region algorithms are efficient and robust techniques to solve unconstrained optimization problems.
Reference: [98] <author> H. J. Martinez, Z. Parada, and R. A. Tapia, </author> <title> On the characterization of q-superlinear convergence of quasi-Newton interior-point methods for nonlinear programming, </title> <institution> Boletin de la Sociedad Matematica Mexicana, </institution> <month> 1 </month> <year> (1995), </year> <pages> pp. 1-12. </pages>
Reference-contexts: As a possible alternative for the affine scaling interior-point strategy, we have in mind the use of primal-dual interior-point algorithms. For general nonlinear programs of the form (4.20) these algorithms have been studied in [50], <ref> [98] </ref>, [148] where they are referred also as Newton or quasi-Newton interior-point methods. The formulation and analysis of the TRIP reduced SQP algorithms in an infinite dimensional framework is another research topic that deserves to be investigated.
Reference: [99] <author> J. M. Martinez, </author> <title> An algorithm for solving sparse nonlinear least squares problems, </title> <journal> Computing, </journal> <volume> 39 (1987), </volume> <pages> pp. 307-325. </pages>
Reference-contexts: The results for the solution of systems of nonlinear equations have been extended to analyze inexact Newton methods for the solution of unconstrained optimization problems, e.g. [33], [109], [111], inexact Gauss-Newton methods <ref> [99] </ref>, and complementarity problems [117]. In a recent paper 123 [149], the impact of inexactness in reduced-gradient methods for design optimization has been analyzed. In nonlinear programming, inexactness has been studied by [6], [28], [34], [54], [92], [110], [146] among others.
Reference: [100] <author> J. M. Martinez and S. A. Santos, </author> <title> A trust-region strategy for minimization on arbitrary domains, </title> <journal> Math. Programming, </journal> <volume> 68 (1995), </volume> <pages> pp. 267-301. </pages>
Reference-contexts: We will be more precise later. More general forms of this simple trust-region subproblem are considered in the papers [73], <ref> [100] </ref>, [103], [105], [136], [140], [153]. 2.2 Line Searches If a line search is used, one might ask the step s k = k d k to satisfy the Armijo Goldstein-Wolfe conditions: f (x k + s k ) f (x k ) + 1 g T rf (x k +
Reference: [101] <author> J. C. Meza and W. W. Symes, </author> <title> Conjugate residual methods for almost symmetric linear systems, </title> <journal> J. Optim. Theory Appl., </journal> <volume> 72 (1992), </volume> <pages> pp. 415-440. </pages>
Reference-contexts: The computation of the tangential component using the coupled approach is another issue that needs further investigation. In particular the loss of symmetry due to the inexactness and the use of nonsymmetric iterative methods for the solution of these subproblems deserves attention (see <ref> [101] </ref>). 154

Reference: [106] <author> J. J. Mor e and D. C. Sorensen, </author> <title> Computing a trust region step, </title> <journal> SIAM J. Sci. Statist. Comput., </journal> <volume> 4 (1983), </volume> <pages> pp. 553-572. </pages>
Reference-contexts: Proposition 2.3.2 The trust-region subproblem (2.2) has no solutions at the boundary fs : ksk = ffi k g if and only if H k is positive definite and kH 1 A proof of this simple fact can be found in <ref> [106] </ref>. <p> k = p + t q (2.16) where p solves (H k 1 (H k )I n )p = g k , the vector q is a eigenvector corresponding to 1 (H k ), and t is such that kp + t qk = ffi k : More and Sorensen <ref> [106] </ref> proposed an algorithm that combines the application of Newton's method to (2.15) for the easy case with (2.16) for the hard case. They showed that the algorithm computes a step s k satisfying the optimal decrease conditions (2.10). <p> Theorem 2.3.3 (More and Sorensen <ref> [106] </ref>, [132]) Let fx k g be a sequence generated by the Trust-Region Algorithm 2.3.3 with H k = r 2 f (x k ) where s k satisfies the fraction of optimal decrease (2.10). <p> More [103] showed how to generalize these theorems for trust-region constraints of the form kS k sk ffi k , where fS k g is a sequence of nonsingular scaling matrices. Related results can be found in references [56], <ref> [106] </ref>, [130], [132]. 2.3.4 Tikhonov Regularization In this section we show how the Tikhonov regularization [138] for ill-conditioned linear least-squares is related to a particular trust-region subproblem. This is one of many arguments that justify the use of trust regions as a regularization technique. <p> One of the purposes of this chapter is to analyze under what modifications and conditions this trust-region reduced SQP algorithm possesses global convergence to a point that satisfies the second-order necessary optimality conditions. Our goal is to generalize the result given by More and Sorensen <ref> [106] </ref>, [132] for unconstrained optimization and described in Theorem 2.3.3 (see Figure 1.2). <p> We saw in Section 3.7 that the normal component gives a fraction of optimal decrease for the trust-region subproblem for the linearized constraints. To compute a step s q k that satisfies this property, we can also use the techniques proposed in <ref> [106] </ref>, [126], [133] and described in Section 2.3.1. In the next theorem we show that the trust-region subproblem (3.14), due to its particular structure, tends to fall in the hard case in the latest stages of Algorithm 3.4.1. This result is relevant in our opinion since the algorithms proposed in [106], <p> <ref> [106] </ref>, [126], [133] and described in Section 2.3.1. In the next theorem we show that the trust-region subproblem (3.14), due to its particular structure, tends to fall in the hard case in the latest stages of Algorithm 3.4.1. This result is relevant in our opinion since the algorithms proposed in [106], [126], [133] for the solution of trust-region subproblems deal with the hard case. <p> To accomplish this, just as in the unconstrained case <ref> [106] </ref>, [132], in the box-constrained case [23], and in the equality-constrained case [42], [48], we need to make sure that s u satisfies an appropriate fraction of optimal decrease condition. First we consider the decoupled approach and let o d k be an optimal solution of the trust-region subproblem (5.17)-(5.18).
Reference: [107] <author> J. J. Mor e and D. Thuente, </author> <title> Line search algorithms with guaranteed sufficient decrease, </title> <journal> ACM Trans. Math. Software, </journal> <volume> 20 (1994), </volume> <pages> pp. 286-307. </pages>
Reference-contexts: It was established by Wolfe [144], [145] and Zoutendijk [158], under the assumption that the gradient is Lipschitz continuous. However this condition can be relaxed and one can see that uniform continuity is enough (see Fletcher [53][Theorem 2.5.1]). Some practical line-search algorithms are described by More and Thuente <ref> [107] </ref>. For more references see also the books [39], [112], [116] and the review papers [40], [113]. From Theorem 2.2.1, a key ingredient to obtain global convergence to a stationary point is to keep the angle k between g k and d k uniformly bounded away from 2 .
Reference: [108] <author> W. Murray and F. J. Prieto, </author> <title> A sequential quadratic programming algorithm using an incomplete solution of the subproblem, </title> <journal> SIAM J. Optim., </journal> <volume> 5 (1995), </volume> <pages> pp. 590-640. </pages>
Reference-contexts: SQP algorithms are very successful for the solution of constrained optimization problems. See e.g. [5], [59], [91], <ref> [108] </ref>. They are often quasi-Newton type algorithms in the sense that they rely on a Newton iteration and approximate second-order derivatives. The primary goal of these algorithms is to find a point that satisfies the first-order necessary optimality conditions.
Reference: [109] <author> S. G. Nash, </author> <title> Newton-like minimization via the Lanczos method, </title> <journal> SIAM J. Nu-mer. Anal., </journal> <volume> 21 (1984), </volume> <pages> pp. </pages> <month> 770-788. </month> <title> [110] , Solving nonlinear programming problems using truncated-Newton techniques, </title> <note> in Numerical Optimization 1984, </note> <author> P. T. Boggs, R. H. Byrd, and R. B. Schnabel, </author> <title> eds., </title> <publisher> SIAM, </publisher> <address> Philadelphia, </address> <year> 1985, </year> <pages> pp. 119-136. </pages>
Reference-contexts: The results for the solution of systems of nonlinear equations have been extended to analyze inexact Newton methods for the solution of unconstrained optimization problems, e.g. [33], <ref> [109] </ref>, [111], inexact Gauss-Newton methods [99], and complementarity problems [117]. In a recent paper 123 [149], the impact of inexactness in reduced-gradient methods for design optimization has been analyzed. In nonlinear programming, inexactness has been studied by [6], [28], [34], [54], [92], [110], [146] among others.
Reference: [111] <author> S. G. Nash and J. Nocedal, </author> <title> A numerical study of the limited memory BFGS method and the truncated-Newton method for large scale optimization, </title> <journal> SIAM J. Optim., </journal> <volume> 1 (1991), </volume> <pages> pp. 358-372. </pages>
Reference-contexts: The results for the solution of systems of nonlinear equations have been extended to analyze inexact Newton methods for the solution of unconstrained optimization problems, e.g. [33], [109], <ref> [111] </ref>, inexact Gauss-Newton methods [99], and complementarity problems [117]. In a recent paper 123 [149], the impact of inexactness in reduced-gradient methods for design optimization has been analyzed. In nonlinear programming, inexactness has been studied by [6], [28], [34], [54], [92], [110], [146] among others.
Reference: [112] <author> S. G. Nash and A. Sofer, </author> <title> Linear and Nonlinear Programming, </title> <publisher> McGraw-Hill, </publisher> <address> New York, </address> <year> 1996. </year>
Reference-contexts: However this condition can be relaxed and one can see that uniform continuity is enough (see Fletcher [53][Theorem 2.5.1]). Some practical line-search algorithms are described by More and Thuente [107]. For more references see also the books [39], <ref> [112] </ref>, [116] and the review papers [40], [113]. From Theorem 2.2.1, a key ingredient to obtain global convergence to a stationary point is to keep the angle k between g k and d k uniformly bounded away from 2 . <p> The next two propositions review the optimality conditions for problem (3.1). For proofs and related material see the books [53], [60], [96], <ref> [112] </ref>. Proposition 3.1.1 (First-Order Necessary Optimality Conditions) If the regular point x fl is a local minimizer of (3.1), then there exists a fl 2 IR m such that C (x fl ) = 0 and The vector fl is the vector of Lagrange multipliers.
Reference: [113] <author> J. Nocedal, </author> <title> Theory of algorithms for unconstrained optimization, </title> <journal> Acta Nu-merica, </journal> <year> (1992), </year> <pages> pp. 199-242. </pages>
Reference-contexts: However this condition can be relaxed and one can see that uniform continuity is enough (see Fletcher [53][Theorem 2.5.1]). Some practical line-search algorithms are described by More and Thuente [107]. For more references see also the books [39], [112], [116] and the review papers [40], <ref> [113] </ref>. From Theorem 2.2.1, a key ingredient to obtain global convergence to a stationary point is to keep the angle k between g k and d k uniformly bounded away from 2 .
Reference: [114] <author> J. Nocedal and M. L. Overton, </author> <title> Projected Hessian updating algorithms for nonlinearly constrained optimization, </title> <journal> SIAM J. Numer. Anal., </journal> <volume> 22 (1985), </volume> <pages> pp. 821-850. </pages>
Reference-contexts: This cross term can be approximated by finite differences, by secant updates, or by zero [4]. There has been significant activity in studying the local rate of convergence of secant updates for reduced SQP algorithms. See the papers [4], <ref> [114] </ref>, [147] and the references therein. y BFGS is an abbreviation for the names Broyden, Fletcher, Goldfarb, and Shanno who in 1970 independently discovered this secant update. <p> These multipliers are the solution of the linear least-squares problem minimize fl flrf k + J T k fl and are given by k = (J k J T k Y T It is easy to show (see e.g. <ref> [114] </ref>) that the Newton step (s k ; k ) obtained by solving (3.4) can be expressed as follows: s k = s n k ; (3.10) k = J T k ) 1 C k ; (3.11) k = Z T xx ` k Z k Z T xx ` <p> We approximate these matrices with the limited memory BFGS representations given in [15] with a memory size of 5 pairs of vectors. For the reduced Hessian we use a null-space secant update (see <ref> [114] </ref>, [147]). The initial approximation chosen was flI nm for the reduced Hessian and flI n for the full Hessian, where fl is the user specified regularization parameter in the objective function (4.26).
Reference: [115] <author> E. O. Omojokon, </author> <title> Trust Region Algorithms for Optimization with Nonlinear Equality and Inequality Constraints, </title> <type> PhD thesis, </type> <institution> University of Colorado, </institution> <year> 1989. </year> <month> 165 </month>
Reference-contexts: Trust regions to guarantee global convergence, i.e. that convergence is attained from any starting point. (A trust region is imposed appropriately on the quasi-normal and tangential components constraining the respective quadratic programming subproblems. The trust-region technique we use is similar to those that Byrd and Omojokon <ref> [115] </ref>, Dennis, El-Alem, and Maciel [35], and Dennis and Vicente [42] proposed for equality-constrained optimization. Besides assuring global convergence, trust regions regularize ill-conditioned second-order derivatives of the quadratic subproblems. This is very important since many problems in this class are ill-conditioned.) 3. <p> The various trust-region globalizations suggested in the literature for these algorithms are surveyed in Section 3.3. The algorithm that we focus on this chapter is very similar to the trust-region globalizations of the reduced SQP algorithm suggested and analyzed by Byrd and Omojokon <ref> [115] </ref> and Dennis, El-Alem, and Maciel [35]. It is described in great detail in Section 3.4. Then Sections 3.5 and 3.6 present the global convergence for this algorithm. The global convergence to a point satisfying the first-order necessary optimality conditions has been proved in [35]. <p> The reduced SQP algorithm has been globalized with trust regions by Byrd and Omojokon <ref> [115] </ref>, Byrd, Schnabel, and Shultz [17], Coleman and Yuan [27], Dennis, El-Alem, and Maciel [35], Dennis and Vicente [42], El-Alem [48], [49], Lalee, Nocedal, and Plantenga [91], Plantenga [118], and Zhang and Zhu [156]. See also Alexandrov [1]. <p> We address these issues in the following points. 1. The choice of trust-region subproblems now seems a settled question. Most of the references cited for trust-region reduced SQP algorithms [35], [42], [48], [49], [91], <ref> [115] </ref>, [118] consider essentially the same choice of trust-region subproblems 33 that was introduced first by Byrd and Omojokon [115] x . We focus on this issue in Section 3.4. 2. The decomposition of the step considered in references [17], [27], [48], [49], [91], [115], [118], [156] is the normal decomposition <p> The choice of trust-region subproblems now seems a settled question. Most of the references cited for trust-region reduced SQP algorithms [35], [42], [48], [49], [91], <ref> [115] </ref>, [118] consider essentially the same choice of trust-region subproblems 33 that was introduced first by Byrd and Omojokon [115] x . We focus on this issue in Section 3.4. 2. The decomposition of the step considered in references [17], [27], [48], [49], [91], [115], [118], [156] is the normal decomposition (3.6). In many application problems there are other reasonable decompositions of the step. <p> algorithms [35], [42], [48], [49], [91], <ref> [115] </ref>, [118] consider essentially the same choice of trust-region subproblems 33 that was introduced first by Byrd and Omojokon [115] x . We focus on this issue in Section 3.4. 2. The decomposition of the step considered in references [17], [27], [48], [49], [91], [115], [118], [156] is the normal decomposition (3.6). In many application problems there are other reasonable decompositions of the step. This is clearly the case for the class of problems introduced in Chapter 4. <p> The algorithms we introduce in this thesis use a quasi-normal decomposition. 3. The choice of Lagrange multipliers is associated intimately with the type of step decomposition. Most of the researchers [17], [27], [48], [49], [91], <ref> [115] </ref>, [118], [156] considered the least-squares multipliers (3.9) or variations thereof. The work given in [35], [42] departs from the former references by assuming a more general form for the multipliers. <p> The augmented Lagrangian has been used in [35], [42], [48], [49], [156], the ` 1 penalty function in [17], the ` 2 penalty function in [27], and the ` 2 penalty function without constraint term squared in [91], <ref> [115] </ref>, [118]. x The Thesis [115] was directed by Professor R. H. Byrd. The trust-region algorithm proposed here is usually referred as the Byrd and Omojokon algorithm. 34 Let us describe briefly the trust-region globalization analyzed by Dennis, El-Alem, and Maciel [35]. <p> The augmented Lagrangian has been used in [35], [42], [48], [49], [156], the ` 1 penalty function in [17], the ` 2 penalty function in [27], and the ` 2 penalty function without constraint term squared in [91], <ref> [115] </ref>, [118]. x The Thesis [115] was directed by Professor R. H. Byrd. The trust-region algorithm proposed here is usually referred as the Byrd and Omojokon algorithm. 34 Let us describe briefly the trust-region globalization analyzed by Dennis, El-Alem, and Maciel [35].
Reference: [116] <author> J. M. Ortega and W. C. Rheinboldt, </author> <title> Iterative Solution of Nonlinear Equations in Several Variables, </title> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1970. </year>
Reference-contexts: The proofs of these basic results can be found in many textbooks like [39], <ref> [116] </ref>. A quasi-Newton method for the solution of (2.1) generates a sequence of iterates fx k g and steps fs k g such that x k+1 = x k + s k . <p> However this condition can be relaxed and one can see that uniform continuity is enough (see Fletcher [53][Theorem 2.5.1]). Some practical line-search algorithms are described by More and Thuente [107]. For more references see also the books [39], [112], <ref> [116] </ref> and the review papers [40], [113]. From Theorem 2.2.1, a key ingredient to obtain global convergence to a stationary point is to keep the angle k between g k and d k uniformly bounded away from 2 .
Reference: [117] <author> J. S. Pang, </author> <title> Inexact Newton methods for the nonlinear complementarity problem, </title> <journal> Math. Programming, </journal> <volume> 36 (1986), </volume> <pages> pp. 54-71. </pages>
Reference-contexts: The results for the solution of systems of nonlinear equations have been extended to analyze inexact Newton methods for the solution of unconstrained optimization problems, e.g. [33], [109], [111], inexact Gauss-Newton methods [99], and complementarity problems <ref> [117] </ref>. In a recent paper 123 [149], the impact of inexactness in reduced-gradient methods for design optimization has been analyzed. In nonlinear programming, inexactness has been studied by [6], [28], [34], [54], [92], [110], [146] among others.
Reference: [118] <author> T. Plantenga, </author> <title> Large-Scale Nonlinear Constrained Optimization using Trust Regions, </title> <type> PhD thesis, </type> <institution> Northwestern University, Evanston, Illinois, </institution> <year> 1994. </year>
Reference-contexts: The reduced SQP algorithm has been globalized with trust regions by Byrd and Omojokon [115], Byrd, Schnabel, and Shultz [17], Coleman and Yuan [27], Dennis, El-Alem, and Maciel [35], Dennis and Vicente [42], El-Alem [48], [49], Lalee, Nocedal, and Plantenga [91], Plantenga <ref> [118] </ref>, and Zhang and Zhu [156]. See also Alexandrov [1]. We recommend the surveys given in [35] and [118] for an overview of these different trust-region globalizations. Trust-region algorithms have been applied also to optimization problems with equality and inequality constraints. <p> by Byrd and Omojokon [115], Byrd, Schnabel, and Shultz [17], Coleman and Yuan [27], Dennis, El-Alem, and Maciel [35], Dennis and Vicente [42], El-Alem [48], [49], Lalee, Nocedal, and Plantenga [91], Plantenga <ref> [118] </ref>, and Zhang and Zhu [156]. See also Alexandrov [1]. We recommend the surveys given in [35] and [118] for an overview of these different trust-region globalizations. Trust-region algorithms have been applied also to optimization problems with equality and inequality constraints. See the work by Burke [13], Burke, More, and Toraldo [14], Conn, Gould, and Toint [29], [30], and Yuan [154]. <p> We address these issues in the following points. 1. The choice of trust-region subproblems now seems a settled question. Most of the references cited for trust-region reduced SQP algorithms [35], [42], [48], [49], [91], [115], <ref> [118] </ref> consider essentially the same choice of trust-region subproblems 33 that was introduced first by Byrd and Omojokon [115] x . We focus on this issue in Section 3.4. 2. The decomposition of the step considered in references [17], [27], [48], [49], [91], [115], [118], [156] is the normal decomposition (3.6). <p> [35], [42], [48], [49], [91], [115], <ref> [118] </ref> consider essentially the same choice of trust-region subproblems 33 that was introduced first by Byrd and Omojokon [115] x . We focus on this issue in Section 3.4. 2. The decomposition of the step considered in references [17], [27], [48], [49], [91], [115], [118], [156] is the normal decomposition (3.6). In many application problems there are other reasonable decompositions of the step. This is clearly the case for the class of problems introduced in Chapter 4. <p> The algorithms we introduce in this thesis use a quasi-normal decomposition. 3. The choice of Lagrange multipliers is associated intimately with the type of step decomposition. Most of the researchers [17], [27], [48], [49], [91], [115], <ref> [118] </ref>, [156] considered the least-squares multipliers (3.9) or variations thereof. The work given in [35], [42] departs from the former references by assuming a more general form for the multipliers. <p> The augmented Lagrangian has been used in [35], [42], [48], [49], [156], the ` 1 penalty function in [17], the ` 2 penalty function in [27], and the ` 2 penalty function without constraint term squared in [91], [115], <ref> [118] </ref>. x The Thesis [115] was directed by Professor R. H. Byrd. The trust-region algorithm proposed here is usually referred as the Byrd and Omojokon algorithm. 34 Let us describe briefly the trust-region globalization analyzed by Dennis, El-Alem, and Maciel [35]. <p> To apply this algorithm, no additional information is required from the user. This or similar interior-point approaches have recently also been used e.g. in [7], [25], [94], [95], <ref> [118] </ref>. The advantage of the approach in [23] is that the scaling matrix is determined by the distance of the iterates to the bounds and by the direction of the gradient.
Reference: [119] <author> E. Polak, </author> <title> Computational Methods in Optimization. A Unified Approach, </title> <publisher> Academic Press, </publisher> <address> New York, London, Paris, San Diego, San Francisco, </address> <year> 1971. </year>
Reference-contexts: Its solution is part of the evaluation of the objective function ^ f (u). The reduced problem can be solved by a Newton-like method. For optimal control problems, many algorithms follow this approach and use projection techniques [70], <ref> [119] </ref> to handle the bounds on the variables u. The reduced problem (4.8) is important since it leads us to the use of reduced SQP algorithms.
Reference: [120] <author> M. J. D. Powell, </author> <title> A new algorithm for unconstrained optimization, in Nonlinear Programming, </title> <editor> J. B. Rosen, O. L. Mangasarian, and K. Ritter, eds., </editor> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1970. </year> <title> [121] , Convergence properties of a class of minimization algorithms, in Nonlinear Programming 2, </title> <editor> O. L. Mangasarian, R. R. Meyer, and S. M. Robinson, eds., </editor> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1975, </year> <pages> pp. </pages> <month> 1-27. </month> <title> [122] , On the global convergence of trust region algorithms for unconstrained minimization, </title> <journal> Math. Programming, </journal> <volume> 29 (1984), </volume> <pages> pp. 297-303. </pages>
Reference-contexts: A few years later Powell <ref> [120] </ref>, [121] (1970, 1975), Hebden [71] (1973), and More [102] (1978) opened the field of research in this area. Trust-region algorithms are efficient and robust techniques to solve unconstrained optimization problems. An excellent survey in this area was written by More [103] in 1983. <p> The first is due to Powell <ref> [120] </ref>, and it is called the dogleg algorithm. The idea behind this algorithm is very simple and is described below. Algorithm 2.3.1 (Dogleg Algorithm (H k Positive Definite)) Compute the Cauchy step c k . If kc k k = ffi k then set s k = c k .
Reference: [123] <author> M. J. D. Powell and Y. Yuan, </author> <title> A trust region algorithm for equality constrained optimization, </title> <journal> Math. Programming, </journal> <volume> 49 (1991), </volume> <pages> pp. 189-211. </pages>
Reference-contexts: Globalizations of SQP algorithms were given by Celis, Dennis, and Tapia [21] (see also Yuan [152] and Zhang [157]), Conn, Gould, and Toint [30], El-Alem [47], Fletcher [52], Vardi [141] (see also El-Hallabi [51]), and Powell and Yuan <ref> [123] </ref>. The reduced SQP algorithm has been globalized with trust regions by Byrd and Omojokon [115], Byrd, Schnabel, and Shultz [17], Coleman and Yuan [27], Dennis, El-Alem, and Maciel [35], Dennis and Vicente [42], El-Alem [48], [49], Lalee, Nocedal, and Plantenga [91], Plantenga [118], and Zhang and Zhu [156].
Reference: [124] <editor> J. Raphson, Analysis Aequationum Universalis Seu Ad Aequationes Alge-braicas Resolvendas Methodus Generalis, et Expedita, Ex nova Infinitarum Se-rierum Doctrina, Deducta Ac Demonstrata, </editor> <address> London, 1690. Original in British Library, London. </address>
Reference-contexts: Newton's method is credited to Newton (see [143]) in the 1660's for finding a root of a nonlinear equation with one variable using a technique similar to Newton's method, but where the calculations are organized differently. Raphson <ref> [124] </ref> plays an important role in this discovery by rederiving Newton's technique in a way that is very close to what is used nowadays. The multidimensional version of Newton's method is due to Simpson [131] in 1740.
Reference: [125] <author> C. H. Reinsch, </author> <title> Smoothing by spline functions II, </title> <journal> Numer. Math., </journal> <volume> 16 (1971), </volume> <pages> pp. 451-454. </pages>
Reference-contexts: Reinsch <ref> [125] </ref> and Hebden [71] were the first to observe that Newton's method performs better when applied to (2.15).
Reference: [126] <author> F. Rendl and H. Wolkowicz, </author> <title> A semidefinite framework for trust region subproblems with applications to large scale minimization, </title> <type> Tech. Rep. 94-32, CORR, </type> <year> 1994. </year>
Reference-contexts: Recent new algorithms to compute a step that satisfies a fraction of optimal decrease that are very promising for large problems have been proposed by Rendl and Wolkowicz <ref> [126] </ref>, Sorensen [133], and Santos and Sorensen [129]. They rely on different parametrizations of the trust-region subproblem (2.2). Instead of a Cholesky factorization, these algorithms require only matrix-vector products. <p> We saw in Section 3.7 that the normal component gives a fraction of optimal decrease for the trust-region subproblem for the linearized constraints. To compute a step s q k that satisfies this property, we can also use the techniques proposed in [106], <ref> [126] </ref>, [133] and described in Section 2.3.1. In the next theorem we show that the trust-region subproblem (3.14), due to its particular structure, tends to fall in the hard case in the latest stages of Algorithm 3.4.1. This result is relevant in our opinion since the algorithms proposed in [106], [126], <p> <ref> [126] </ref>, [133] and described in Section 2.3.1. In the next theorem we show that the trust-region subproblem (3.14), due to its particular structure, tends to fall in the hard case in the latest stages of Algorithm 3.4.1. This result is relevant in our opinion since the algorithms proposed in [106], [126], [133] for the solution of trust-region subproblems deal with the hard case.
Reference: [127] <author> Y. Saad and M. H. Schultz, </author> <title> GMRES a generalized minimal residual algorithm for solving nonsymmetric linear systems, </title> <journal> SIAM J. Sci. Statist. Comput., </journal> <volume> 7 (1986), </volume> <pages> pp. 856-869. 166 </pages>
Reference-contexts: Some of the pioneering work in this area can be found in [32], [135]. More recent references are [9], [10], [43], [44], [45]. Most of the recent papers investigate the use of Krylov subspace methods for the solution of linear systems, like GMRES <ref> [127] </ref>, in inexact Newton methods. These Krylov subspace methods are attractive because they monitor the residual norm of the linear system in an efficient way and only require Jacobian times a vector, not the Jacobian in explicit form. <p> In this case one can apply nonsymmetric transpose-free Krylov subspace methods based on minimum residual approximations, such as GMRES <ref> [127] </ref> or TFQMR [55]. In the context of nonlinear system solving the use of such methods is described by Brown and Saad [10], [11].
Reference: [128] <author> C. M. Samuelson, </author> <title> The Dikin-Karmarkar Principle for Steepest Descent, </title> <type> PhD thesis, </type> <institution> Department of Computational and Applied Mathematics, Rice University, Houston, Texas 77251, USA, </institution> <year> 1992. </year> <type> Tech. Rep. </type> <institution> TR92-29. </institution>
Reference-contexts: When applied to our class of problems, the Coleman-Li affine scaling is given by the matrices D k and D k . A study of the Dikin-Karmarkar affine scaling for steepest descent is given in <ref> [128] </ref>. For our class of problems, this scaling is given by (K k ) ii = minf1; (u k a) i ; (b u k ) i g; i = 1; : : : ; n m; (5.99) and has no dual information built in.
Reference: [129] <author> S. A. Santos and D. C. Sorensen, </author> <title> A new matrix-free algorithm for the large-scale trust-region subproblem, </title> <type> Tech. Rep. </type> <institution> TR95-20, Department of Computational and Applied Mathematics, Rice University, </institution> <year> 1994. </year>
Reference-contexts: Recent new algorithms to compute a step that satisfies a fraction of optimal decrease that are very promising for large problems have been proposed by Rendl and Wolkowicz [126], Sorensen [133], and Santos and Sorensen <ref> [129] </ref>. They rely on different parametrizations of the trust-region subproblem (2.2). Instead of a Cholesky factorization, these algorithms require only matrix-vector products. The material in the following paragraph follows the exposition in [129], [133]. 20 The motivation for the new parametrization is that 1 ff + q k (s) = 2 <p> promising for large problems have been proposed by Rendl and Wolkowicz [126], Sorensen [133], and Santos and Sorensen <ref> [129] </ref>. They rely on different parametrizations of the trust-region subproblem (2.2). Instead of a Cholesky factorization, these algorithms require only matrix-vector products. The material in the following paragraph follows the exposition in [129], [133]. 20 The motivation for the new parametrization is that 1 ff + q k (s) = 2 @ s A @ k 1 0 1 1 The new one-dimensional function depends on the parameter ff and is defined as 3 (fl; ff) ff fl (ff): Let fl (ff) be <p> 3 , independent of k, such that kC k k 2 kC y (x k )(s k ) y + C k k 2 2 kC k k minf 3 kC k k; ffi k g: Another family of methods to solve large-scale trust-region subproblems is proposed and analyzed in <ref> [129] </ref>, [133]. We described briefly these algorithms in Section 2.3.1 and mentioned that they compute steps satisfying a fraction of optimal decrease condition of the type (2.10). <p> The Lanczos bidiagonalization algorithm in [67] is another algorithm that computes steps satisfying this property when applied to the trust-region subproblem (6.19). 6.3.2 Methods that Are Transpose Free The Conjugate-Gradient Algorithm 2.3.2, the Lanczos bidiagonalization algorithm [67], and the algorithms in <ref> [129] </ref>, [133] require the computation of matrix-vector products of the form C y (x k )d y and C y (x k ) T d y for a given d y in IR m . <p> Our implementation of the TRIP reduced SQP algorithms will be subject to many improvements. We have in mind for instance the computation of the quasi-normal and tangential components by adapting to our context the algorithms proposed in <ref> [129] </ref>, [133]. Testing the effectiveness of the coupled approach for ill-conditioned problems is part of our future plans. The conditions on the inexactness described in Chapter 6, and summarized in Section 6.2, are sufficient to guarantee global convergence to a point satisfying the first-order necessary optimality conditions.
Reference: [130] <author> G. A. Shultz, R. B. Schnabel, and R. H. Byrd, </author> <title> A family of trust-region-based algorithms for unconstrained minimization with strong global convergence properties, </title> <journal> SIAM J. Numer. Anal., </journal> <volume> 22 (1985), </volume> <pages> pp. 47-67. </pages>
Reference-contexts: Dennis and Mei [37] proposed the so-called double dogleg algorithm. Byrd, Schnabel, and Shultz [18], <ref> [130] </ref> introduced indefinite dogleg algorithms using two dimensional sub spaces. Now we turn our attention to algorithms for computing steps s k that satisfy the fraction of optimal decrease (2.10). Typically these algorithms are based on Newton type iterations and rely on the following propositions. <p> More [103] showed how to generalize these theorems for trust-region constraints of the form kS k sk ffi k , where fS k g is a sequence of nonsingular scaling matrices. Related results can be found in references [56], [106], <ref> [130] </ref>, [132]. 2.3.4 Tikhonov Regularization In this section we show how the Tikhonov regularization [138] for ill-conditioned linear least-squares is related to a particular trust-region subproblem. This is one of many arguments that justify the use of trust regions as a regularization technique.
Reference: [131] <author> T. Simpson, </author> <title> Essays on several Curious and Useful Subjects, In Speculative and Mix'd Mathematicks, Ilustrated by a Variety of Examples, </title> <journal> London, </journal> <volume> 1740. </volume>
Reference-contexts: Raphson [124] plays an important role in this discovery by rederiving Newton's technique in a way that is very close to what is used nowadays. The multidimensional version of Newton's method is due to Simpson <ref> [131] </ref> in 1740. See the survey paper by Ypma [150]. 11 It is well-known that the basic quasi-Newton algorithm is not globally convergent to a stationary point [39][Figure 6.3.2]. If we want to start with any choice of x 0 and still guarantee convergence, then we need a globalization strategy.
Reference: [132] <author> D. C. Sorensen, </author> <title> Newton's method with a model trust region modification, </title> <journal> SIAM J. Numer. Anal., </journal> <volume> 19 (1982), </volume> <pages> pp. </pages> <month> 409-426. </month> <title> [133] , Minimization of a large scale quadratic function subject to an ellipsoidal constraint, </title> <type> Tech. Rep. </type> <institution> TR94-27, Department of Computational and Applied Mathematics, Rice University, </institution> <year> 1994. </year>
Reference-contexts: Proposition 2.3.2 The trust-region subproblem (2.2) has no solutions at the boundary fs : ksk = ffi k g if and only if H k is positive definite and kH 1 A proof of this simple fact can be found in [106]. Proposition 2.3.3 (Gay [56] and Sorensen <ref> [132] </ref>) The step o k is an optimal solution of the trust-region subproblem (2.2) if and only if ko k k ffi k and there exists fl k 0 such that H k + fl k I n is positive semi-definite; (2.11) (H k + fl k I n ) o <p> They showed that the algorithm computes a step s k satisfying the optimal decrease conditions (2.10). Their algorithm and corresponding Fortran implementation GQTPAR are based on previous work done by Gay [56] and Sorensen <ref> [132] </ref>. To compute 2 (fl) and 0 2 (fl), algorithms of the More and Sorensen type require a Cholesky factorization R T fl R fl of H k + flI n whenever this matrix is positive definite. <p> Theorem 2.3.3 (More and Sorensen [106], <ref> [132] </ref>) Let fx k g be a sequence generated by the Trust-Region Algorithm 2.3.3 with H k = r 2 f (x k ) where s k satisfies the fraction of optimal decrease (2.10). <p> More [103] showed how to generalize these theorems for trust-region constraints of the form kS k sk ffi k , where fS k g is a sequence of nonsingular scaling matrices. Related results can be found in references [56], [106], [130], <ref> [132] </ref>. 2.3.4 Tikhonov Regularization In this section we show how the Tikhonov regularization [138] for ill-conditioned linear least-squares is related to a particular trust-region subproblem. This is one of many arguments that justify the use of trust regions as a regularization technique. <p> One of the purposes of this chapter is to analyze under what modifications and conditions this trust-region reduced SQP algorithm possesses global convergence to a point that satisfies the second-order necessary optimality conditions. Our goal is to generalize the result given by More and Sorensen [106], <ref> [132] </ref> for unconstrained optimization and described in Theorem 2.3.3 (see Figure 1.2). <p> To accomplish this, just as in the unconstrained case [106], <ref> [132] </ref>, in the box-constrained case [23], and in the equality-constrained case [42], [48], we need to make sure that s u satisfies an appropriate fraction of optimal decrease condition. First we consider the decoupled approach and let o d k be an optimal solution of the trust-region subproblem (5.17)-(5.18).
Reference: [134] <author> T. Steihaug, </author> <title> The conjugate gradient method and trust regions in large scale optimization, </title> <journal> SIAM J. Numer. Anal., </journal> <volume> 20 (1983), </volume> <pages> pp. </pages> <month> 626-637. </month> <title> [135] , Local and superlinear convergence for truncated iterated projections methods, </title> <journal> Math. Programming, </journal> <volume> 27 (1983), </volume> <pages> pp. 176-190. </pages>
Reference-contexts: A possible way to accomplish this is to generalize the use of the classical conjugate-gradient algorithm of Hestenes and Stiefel [78] for the solution of the linear system H k s = g k with H k positive definite. Steihaug <ref> [134] </ref> and Toint [139] adapted this algorithm for the solution of the trust-region subproblem (2.2). Here two new situations have to be considered. First H k might not be positive definite. <p> The proof for the dogleg algorithm depends strongly on the positive definiteness of H k and can be found in [39]. The proof for conjugate gradients is given in <ref> [134] </ref> and uses the fact that s i+1 is the optimal solution of the quadratic q k (s) in the Krylov subspace K i (H k ; g k ) = span n o Other generalizations of the dogleg idea were suggested in the literature. <p> They use three dimensional subspace approximations and conjugate gradients. Let us consider first the decoupled trust-region approach given in Section 5.2.2. If we ignore the bound constraints for the moment, we can apply the Conjugate-Gradient Algorithm 2.3.2 proposed by Steihaug <ref> [134] </ref> and Toint [139] to solve the problem minimize k (s u ) subject to k D 1 k s u k ffi k : However we also need to incorporate the constraints k (a u k ) s u k (b u k ): This leads to the following algorithm: <p> Dropping this precondi-tioner means that the conjugate-gradient iterates do not necessarily increase in this norm (see <ref> [134] </ref>). As a result, if the quasi-Newton step W T 1 g k exists and is inside the trust region, Algorithm 5.7.2 can terminate prematurely by stopping at the boundary of the trust region.
Reference: [136] <author> R. Stern and H. Wolkowitz, </author> <title> Indefinite trust region subproblems and nonsymmetric eigenvalue perturbations. </title> <note> To appear in SIAM J. Optim., </note> <year> 1995. </year>
Reference-contexts: We will be more precise later. More general forms of this simple trust-region subproblem are considered in the papers [73], [100], [103], [105], <ref> [136] </ref>, [140], [153]. 2.2 Line Searches If a line search is used, one might ask the step s k = k d k to satisfy the Armijo Goldstein-Wolfe conditions: f (x k + s k ) f (x k ) + 1 g T rf (x k + s k )
Reference: [137] <author> S. W. Thomas, </author> <title> Sequential Estimation Techniques for Quasi-Newton Algorithms, </title> <type> PhD thesis, </type> <institution> Cornell University, </institution> <address> Ithaka, New York, </address> <year> 1975. </year>
Reference-contexts: Let f be continuously differentiable and bounded below in L (x 0 ) = fx 2 IR n : f (x) f (x 0 )g. If fH k g is bounded, then lim inf kg k k = 0: (2.19) 22 Theorem 2.3.2 (Thomas <ref> [137] </ref>) If in addition to the assumptions of Theorem 2.1, f is uniformly continuous in L (x 0 ) then lim kg k k = 0: The proofs of these theorems can be found in [103].
Reference: [138] <author> A. N. Tichonoff, </author> <title> Methods for the regularization of optimal control problems, </title> <journal> Dokl. Akad. Nauk., Soviet Maths., </journal> <volume> 162 (1965), </volume> <pages> pp. 761-763. </pages>
Reference-contexts: Related results can be found in references [56], [106], [130], [132]. 2.3.4 Tikhonov Regularization In this section we show how the Tikhonov regularization <ref> [138] </ref> for ill-conditioned linear least-squares is related to a particular trust-region subproblem. This is one of many arguments that justify the use of trust regions as a regularization technique. <p> In our framework the trust region serves a dual purpose. Besides ensuring global convergence, trust regions also introduce a regularization of the subproblems which is related to the Tikhonov regularization <ref> [138] </ref> as we saw in Section 2.3.4. For the solution of optimal control problems, the partitioning of the variables into states y and controls u motivates a partial decoupling of step components that leads to interesting alternatives for the choice of the trust regions.
Reference: [139] <author> P. L. Toint, </author> <title> Towards an efficient sparsity exploiting Newton method for minimization, in Sparse Matrices and Their Uses, </title> <editor> I. S. Duff, ed., </editor> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1981, </year> <pages> pp. </pages> <month> 57-87. </month> <title> 167 [140] , Global convergence of a class of trust-region methods for nonconvex minimization in Hilbert space, </title> <journal> IMA J. Numer. Anal., </journal> <volume> 8 (1988), </volume> <pages> pp. 231-252. </pages>
Reference-contexts: A possible way to accomplish this is to generalize the use of the classical conjugate-gradient algorithm of Hestenes and Stiefel [78] for the solution of the linear system H k s = g k with H k positive definite. Steihaug [134] and Toint <ref> [139] </ref> adapted this algorithm for the solution of the trust-region subproblem (2.2). Here two new situations have to be considered. First H k might not be positive definite. <p> They use three dimensional subspace approximations and conjugate gradients. Let us consider first the decoupled trust-region approach given in Section 5.2.2. If we ignore the bound constraints for the moment, we can apply the Conjugate-Gradient Algorithm 2.3.2 proposed by Steihaug [134] and Toint <ref> [139] </ref> to solve the problem minimize k (s u ) subject to k D 1 k s u k ffi k : However we also need to incorporate the constraints k (a u k ) s u k (b u k ): This leads to the following algorithm: Algorithm 5.7.1 (Computation
Reference: [141] <author> A. Vardi, </author> <title> A trust region algorithm for equality constrained minimization: convergence properties and implementation, </title> <journal> SIAM J. Numer. Anal., </journal> <volume> 22 (1985), </volume> <pages> pp. 575-591. </pages>
Reference-contexts: Globalizations of SQP algorithms were given by Celis, Dennis, and Tapia [21] (see also Yuan [152] and Zhang [157]), Conn, Gould, and Toint [30], El-Alem [47], Fletcher [52], Vardi <ref> [141] </ref> (see also El-Hallabi [51]), and Powell and Yuan [123].
Reference: [142] <author> L. N. Vicente, </author> <title> What happens when we trust a region that is a line, </title> <type> Tech. Rep. </type> <institution> TR95-10, Department of Computational and Applied Mathematics, Rice University, </institution> <year> 1995. </year>
Reference-contexts: A major difference between the global convergence results given in Corollary 2.2.1 and Theorem 2.3.2 is that a uniform bound on H 1 k is required for line searches but 24 not for trust regions. The study by Vicente <ref> [142] </ref> shows that this is related with the flexibility that trust-region algorithms have to choose the type of direction. The criteria to accept a step in line searches and in trust regions are very similar.
Reference: [143] <author> D. T. Whiteside, ed., </author> <title> The Mathematical Papers of Issac Newton (Volumes I-VII), </title> <publisher> Cambridge University Press, Cambridge, </publisher> <pages> 1967-1976. </pages>
Reference-contexts: If in addition H k is positive definite, then this quasi-Newton step s k = H 1 k g k is the unconstrained minimizer of q k (s). In Newton's method, we have H k = r 2 f (x k ). Newton's method is credited to Newton (see <ref> [143] </ref>) in the 1660's for finding a root of a nonlinear equation with one variable using a technique similar to Newton's method, but where the calculations are organized differently.
Reference: [144] <author> P. Wolfe, </author> <title> Convergent conditions for ascent methods, </title> <journal> SIAM Rev., </journal> <volume> 11 (1969), </volume> <pages> pp. </pages> <month> 226-235. </month> <title> [145] , Convergent conditions for ascent methods. II: Some corrections, </title> <journal> SIAM Rev., </journal> <volume> 13 (1971), </volume> <pages> pp. 185-188. </pages>
Reference-contexts: It was established by Wolfe <ref> [144] </ref>, [145] and Zoutendijk [158], under the assumption that the gradient is Lipschitz continuous. However this condition can be relaxed and one can see that uniform continuity is enough (see Fletcher [53][Theorem 2.5.1]). Some practical line-search algorithms are described by More and Thuente [107].
Reference: [146] <author> S. J. Wright, </author> <title> Interior point methods for optimal control of discrete-time systems, </title> <journal> J. Optim. Theory Appl., </journal> <volume> 77 (1993), </volume> <pages> pp. 161-187. </pages>
Reference-contexts: In a recent paper 123 [149], the impact of inexactness in reduced-gradient methods for design optimization has been analyzed. In nonlinear programming, inexactness has been studied by [6], [28], [34], [54], [92], [110], <ref> [146] </ref> among others. The papers [34], [54], [92], [110] investigating SQP algorithms mostly study the influence of inexactness on the local convergence rate. In [110] conditions on the inexactness are given that guarantee descent in the merit function.
Reference: [147] <author> Y. Xie, </author> <title> Reduced Hessian Algorithms for Solving Large-Scale Equality Constrained Optimization Problems, </title> <type> PhD thesis, </type> <institution> Dept. of Computer Science, University of Colorado, </institution> <year> 1991. </year>
Reference-contexts: This cross term can be approximated by finite differences, by secant updates, or by zero [4]. There has been significant activity in studying the local rate of convergence of secant updates for reduced SQP algorithms. See the papers [4], [114], <ref> [147] </ref> and the references therein. y BFGS is an abbreviation for the names Broyden, Fletcher, Goldfarb, and Shanno who in 1970 independently discovered this secant update. <p> We approximate these matrices with the limited memory BFGS representations given in [15] with a memory size of 5 pairs of vectors. For the reduced Hessian we use a null-space secant update (see [114], <ref> [147] </ref>). The initial approximation chosen was flI nm for the reduced Hessian and flI n for the full Hessian, where fl is the user specified regularization parameter in the objective function (4.26).
Reference: [148] <author> H. Yamashita, </author> <title> A globally convergent primal-dual interior-point method for constrained optimization, </title> <type> tech. rep., </type> <institution> Mathematical Systems Institute, </institution> <address> Japan, </address> <year> 1992. </year>
Reference-contexts: As a possible alternative for the affine scaling interior-point strategy, we have in mind the use of primal-dual interior-point algorithms. For general nonlinear programs of the form (4.20) these algorithms have been studied in [50], [98], <ref> [148] </ref> where they are referred also as Newton or quasi-Newton interior-point methods. The formulation and analysis of the TRIP reduced SQP algorithms in an infinite dimensional framework is another research topic that deserves to be investigated. Our implementation of the TRIP reduced SQP algorithms will be subject to many improvements.
Reference: [149] <author> D. P. Young, W. P. Huffman, R. G. Melvin, M. B. Bieterman, C. L. Hilmes, and F. T. Johnson, </author> <title> Inexactness and global convergence in design optimization, </title> <booktitle> in 5th AIAA/NASA/USAF/ISSMO Symposium on Multidisciplinary Analysis and Optimization, </booktitle> <month> September </month> <year> 1994. </year>
Reference-contexts: The linearization of the nonlinear state equation yields the (discretized) linearized state equation and the corresponding adjoint equation. Efficient solutions of the linear system corresponding to these equations exist for many applications [22], [75], <ref> [149] </ref>, and the optimization algorithm ought to take advantage of it. This linearization also offers a tremendous amount of structure. In particular, we use it to obtain a matrix whose columns form a nonorthogonal basis for the null space of the Jacobian matrix of the nonlinear equality constraints. <p> The results for the solution of systems of nonlinear equations have been extended to analyze inexact Newton methods for the solution of unconstrained optimization problems, e.g. [33], [109], [111], inexact Gauss-Newton methods [99], and complementarity problems [117]. In a recent paper 123 <ref> [149] </ref>, the impact of inexactness in reduced-gradient methods for design optimization has been analyzed. In nonlinear programming, inexactness has been studied by [6], [28], [34], [54], [92], [110], [146] among others.
Reference: [150] <author> T. Ypma, </author> <title> Historical development of the Newton-Raphson method, </title> <journal> SIAM Rev., </journal> <volume> 37 (1995), </volume> <pages> pp. 531-551. 168 </pages>
Reference-contexts: Raphson [124] plays an important role in this discovery by rederiving Newton's technique in a way that is very close to what is used nowadays. The multidimensional version of Newton's method is due to Simpson [131] in 1740. See the survey paper by Ypma <ref> [150] </ref>. 11 It is well-known that the basic quasi-Newton algorithm is not globally convergent to a stationary point [39][Figure 6.3.2]. If we want to start with any choice of x 0 and still guarantee convergence, then we need a globalization strategy.
Reference: [151] <author> H. Yserentant, </author> <title> On the multi-level splitting of finite element spaces, </title> <journal> Numer. Math., </journal> <volume> 49 (1986), </volume> <pages> pp. 379-412. </pages>
Reference-contexts: The linearized state and adjoint equations are solved using GMRES (20) preconditioned from the left with the inverse Laplacian. To apply this preconditioner, one has to compute the solution of the discrete Laplace equation with different right hand sides. This was done using multilevel preconditioned conjugate gradients <ref> [151] </ref>. Note that for g (y) = e y , the problem is self-adjoint. Therefore a conjugate-gradient algorithm could have been used instead of GMRES.
Reference: [152] <author> Y. Yuan, </author> <title> On a subproblem of trust region algorithms for constrained optimization, </title> <journal> Math. Programming, </journal> <volume> 47 (1990), </volume> <pages> pp. </pages> <month> 53-63. </month> <title> [153] , A dual algorithm for minimizing a quadratic function with two quadratic constraints, </title> <journal> J. Comput. Math., </journal> <volume> 9 (1991), </volume> <pages> pp. </pages> <month> 348-359. </month> <title> [154] , On the convergence of a new trust region algorithm, </title> <journal> Numer. Math., </journal> <volume> 70 (1995), </volume> <pages> pp. 515-539. </pages>
Reference-contexts: Globalizations of SQP algorithms were given by Celis, Dennis, and Tapia [21] (see also Yuan <ref> [152] </ref> and Zhang [157]), Conn, Gould, and Toint [30], El-Alem [47], Fletcher [52], Vardi [141] (see also El-Hallabi [51]), and Powell and Yuan [123].
Reference: [155] <author> J. Zhang, N. Kim, and L. Lasdon, </author> <title> An improved successive linear programming algorithm, </title> <institution> Management Sci., </institution> <month> 31 </month> <year> (1985), </year> <pages> pp. 1312-1331. </pages>
Reference-contexts: During the course of finding such a step the trust radius can be decreased below ffi min . To our knowledge Zhang, Kim, and Lasdon <ref> [155] </ref> were the first to suggest this modification.
Reference: [156] <author> J. Z. Zhang and D. T. Zhu, </author> <title> Projected quasi-Newton algorithm with trust region for constrained optimization, </title> <journal> J. Optim. Theory Appl., </journal> <volume> 67 (1990), </volume> <pages> pp. 369-393. </pages>
Reference-contexts: The reduced SQP algorithm has been globalized with trust regions by Byrd and Omojokon [115], Byrd, Schnabel, and Shultz [17], Coleman and Yuan [27], Dennis, El-Alem, and Maciel [35], Dennis and Vicente [42], El-Alem [48], [49], Lalee, Nocedal, and Plantenga [91], Plantenga [118], and Zhang and Zhu <ref> [156] </ref>. See also Alexandrov [1]. We recommend the surveys given in [35] and [118] for an overview of these different trust-region globalizations. Trust-region algorithms have been applied also to optimization problems with equality and inequality constraints. <p> We focus on this issue in Section 3.4. 2. The decomposition of the step considered in references [17], [27], [48], [49], [91], [115], [118], <ref> [156] </ref> is the normal decomposition (3.6). In many application problems there are other reasonable decompositions of the step. This is clearly the case for the class of problems introduced in Chapter 4. <p> The algorithms we introduce in this thesis use a quasi-normal decomposition. 3. The choice of Lagrange multipliers is associated intimately with the type of step decomposition. Most of the researchers [17], [27], [48], [49], [91], [115], [118], <ref> [156] </ref> considered the least-squares multipliers (3.9) or variations thereof. The work given in [35], [42] departs from the former references by assuming a more general form for the multipliers. <p> The augmented Lagrangian has been used in [35], [42], [48], [49], <ref> [156] </ref>, the ` 1 penalty function in [17], the ` 2 penalty function in [27], and the ` 2 penalty function without constraint term squared in [91], [115], [118]. x The Thesis [115] was directed by Professor R. H. Byrd.
Reference: [157] <author> Y. Zhang, </author> <title> Computing a Celis-Dennis-Tapia trust-region step for equality constrained optimization, </title> <journal> Math. Programming, </journal> <volume> 55 (1992), </volume> <pages> pp. 109-124. </pages>
Reference-contexts: Globalizations of SQP algorithms were given by Celis, Dennis, and Tapia [21] (see also Yuan [152] and Zhang <ref> [157] </ref>), Conn, Gould, and Toint [30], El-Alem [47], Fletcher [52], Vardi [141] (see also El-Hallabi [51]), and Powell and Yuan [123].
Reference: [158] <author> G. Zoutendijk, </author> <title> Nonlinear Programming, Computational Methods, in Integer and Nonlinear Programming, </title> <editor> J. Abadie, ed., </editor> <publisher> North-Holland, </publisher> <address> Amsterdam, </address> <year> 1970, </year> <pages> pp. 37-86. </pages>
Reference-contexts: It was established by Wolfe [144], [145] and Zoutendijk <ref> [158] </ref>, under the assumption that the gradient is Lipschitz continuous. However this condition can be relaxed and one can see that uniform continuity is enough (see Fletcher [53][Theorem 2.5.1]). Some practical line-search algorithms are described by More and Thuente [107].
References-found: 125

