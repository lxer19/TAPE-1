URL: http://www.cs.helsinki.fi/~tpkarkka/wsp96-final.ps.gz
Refering-URL: http://www.cs.helsinki.fi/research/pmdm/publications/
Root-URL: 
Email: fJuha.Karkkainen,Esko.Ukkoneng@cs.Helsinki.FI  
Title: Lempel-Ziv Parsing and Sublinear-Size Index Structures for String Matching (Extended Abstract)  
Author: Juha Karkkainen Esko Ukkonen 
Note: N m log m), where L is the number of occurrences found.  
Address: P.O. Box 26 (Teollisuuskatu 23), FIN-00014 University of Helsinki, Finland  
Affiliation: Department of Computer Science,  
Abstract: String matching over a long text can be significantly speeded up with an index structure formed by preprocessing the text. For very long texts, the size of such an index can be a problem. This paper presents the first sublinear-size index structure. The new structure is based on Lempel-Ziv parsing of the text and has size linear in N , the size of the Lempel-Ziv parse. For a text of length n, N = O(n= log n) and can be still smaller if the text is compressible. With the new index structure, all occurrences of a pattern string of length m can be found in time O(m 2 + (m + L) log N + p
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> A. Amir, G. Benson, and M. Farach. </author> <title> Let sleeping files lie: Pattern matching in Z-compressed files. </title> <booktitle> In Proc. 5th ACM-SIAM Symposium on Discrete Algorithms (SODA), </booktitle> <pages> pages 705-714, </pages> <year> 1994. </year>
Reference-contexts: The basic two-phase technique based on Lempel-Ziv parsing has also been applied to searching q-grams [16]. The actual data structures, however, are very different from the ones described here. Technically related is also the problem of compressed matching <ref> [1, 9] </ref> which asks one to find the occurrences of P in T directly from the LZ compressed representation of T . The problem is quite different but the solutions utilize the same properties of LZ parsing as we do. <p> If [x i ; y i ] contains [x; y], then T [x + o i : : : y + o i ] is a secondary occurrence. Example 4. For the text T of Example 1, the intervals [x i ; y i ] are <ref> [1; 3] </ref>, [5; 5], [3; 5] and [6; 10], and the corresponding offsets o i are 1, 1, 5 and 6. The first phrase of T is empty and the corresponding interval is omitted here.
Reference: 2. <author> A. Andersson, N. J. Larsson, and K. Swansson. </author> <title> Suffix trees on words. </title> <booktitle> In Proc. 7th Symposium on Combinatorial Pattern Matching (CPM), </booktitle> <year> 1996. </year> <note> To appear. </note>
Reference-contexts: Note that for solving the existence problem the primary search alone is enough. A totally different possibility to construct a small index structure is to build a sparse suffix tree, i.e., a suffix tree that represents only a subset of all suffixes <ref> [11, 23, 17, 2] </ref>. In this way, all occurrences of P that overlap the starting point of a suffix that is present in the tree can easily be found. The other occurrences are difficult and lead to a brute-force search.
Reference: 3. <author> A. Andersson and S. Nilsson. </author> <title> Improved behaviour of tries by adaptive branching. </title> <journal> Inf. Process. Lett., </journal> <volume> 46(6) </volume> <pages> 295-300, </pages> <month> July </month> <year> 1993. </year>
Reference-contexts: Although linear in size, a suffix tree can be uneconomically large to be really attractive in practical applications. The size depends on implementation details and the structure of the text, but will never be as low as 10n bytes. Suffix arrays [20, 11] (size 5n bytes), level-compressed tries <ref> [3, 4] </ref> (size about 11n bytes), suffix cactuses [15] (size 9n bytes), and suffix binary search trees [13] (size about 10n bytes) are alternative smaller data structures with almost the same properties as the suffix tree. <p> If [x i ; y i ] contains [x; y], then T [x + o i : : : y + o i ] is a secondary occurrence. Example 4. For the text T of Example 1, the intervals [x i ; y i ] are <ref> [1; 3] </ref>, [5; 5], [3; 5] and [6; 10], and the corresponding offsets o i are 1, 1, 5 and 6. The first phrase of T is empty and the corresponding interval is omitted here. <p> Example 4. For the text T of Example 1, the intervals [x i ; y i ] are [1; 3], [5; 5], <ref> [3; 5] </ref> and [6; 10], and the corresponding offsets o i are 1, 1, 5 and 6. The first phrase of T is empty and the corresponding interval is omitted here.
Reference: 4. <author> A. Andersson and S. Nilsson. </author> <title> Efficient implementation of suffix trees. </title> <journal> Software| Practice and Experience, </journal> <volume> 25(2) </volume> <pages> 129-141, </pages> <month> Feb. </month> <year> 1995. </year>
Reference-contexts: Although linear in size, a suffix tree can be uneconomically large to be really attractive in practical applications. The size depends on implementation details and the structure of the text, but will never be as low as 10n bytes. Suffix arrays [20, 11] (size 5n bytes), level-compressed tries <ref> [3, 4] </ref> (size about 11n bytes), suffix cactuses [15] (size 9n bytes), and suffix binary search trees [13] (size about 10n bytes) are alternative smaller data structures with almost the same properties as the suffix tree.
Reference: 5. <author> E. F. Barbosa, G. Navarro, R. Baeza-Yates, C. Perleberg, and N. Ziviani. </author> <title> Optimized binary search and text retrieval. </title> <booktitle> In Proc. 3rd Annual European Symposium on Algorithms, </booktitle> <volume> ESA '95, </volume> <pages> pages 311-326, </pages> <year> 1995. </year>
Reference-contexts: Their space requirement is still high for large n and it can be impossible to store the entire data structure in the fast memory. Using suffix trees and arrays in secondary memory environment is considered e.g. in <ref> [11, 5] </ref>. As the slow secondary memory operations can, in practice, destroy the good theoretical performance, there is a need to find small alternatives for suffix trees and arrays, even at the cost of increased search times. <p> If [x i ; y i ] contains [x; y], then T [x + o i : : : y + o i ] is a secondary occurrence. Example 4. For the text T of Example 1, the intervals [x i ; y i ] are [1; 3], <ref> [5; 5] </ref>, [3; 5] and [6; 10], and the corresponding offsets o i are 1, 1, 5 and 6. The first phrase of T is empty and the corresponding interval is omitted here. <p> Example 4. For the text T of Example 1, the intervals [x i ; y i ] are [1; 3], [5; 5], <ref> [3; 5] </ref> and [6; 10], and the corresponding offsets o i are 1, 1, 5 and 6. The first phrase of T is empty and the corresponding interval is omitted here.
Reference: 6. <author> J. L. Bentley. </author> <title> Multidimensional binary search trees used for associative searching. </title> <journal> Commun. ACM, </journal> <volume> 18(9) </volume> <pages> 509-517, </pages> <month> Sept. </month> <year> 1975. </year>
Reference-contexts: It is the two-dimensional case of the multidimensional binary search tree or k-d tree of Bentley <ref> [6] </ref>. The 2-d tree is like ordinary binary search tree except the odd levels use the x-coordinate as the discriminator and the even levels use the y-coordinate as the discriminator. The 2-d tree for N points can be constructed in O (N log N ) time [6]. <p> k-d tree of Bentley <ref> [6] </ref>. The 2-d tree is like ordinary binary search tree except the odd levels use the x-coordinate as the discriminator and the even levels use the y-coordinate as the discriminator. The 2-d tree for N points can be constructed in O (N log N ) time [6]. The range query in a 2-d tree works in the obvious way by continuing the search in one or both subtrees of each node depending on the result of comparisons in the node. <p> Example 4. For the text T of Example 1, the intervals [x i ; y i ] are [1; 3], [5; 5], [3; 5] and <ref> [6; 10] </ref>, and the corresponding offsets o i are 1, 1, 5 and 6. The first phrase of T is empty and the corresponding interval is omitted here.
Reference: 7. <author> J. L. Bentley and D. Wood. </author> <title> An optimal worst-case algorithm for reporting intersections of rectangles. </title> <journal> IEEE Trans. Computers, </journal> <volume> 29(7) </volume> <pages> 571-577, </pages> <month> July </month> <year> 1980. </year>
Reference-contexts: In the general case, one does not assume that the pairs are intervals (x y). Another closely related computational geometry problem is the interval intersection problem, for which there exists a number of data structures such as the segment tree <ref> [7] </ref>, the interval tree [8] and the priority search tree [22]. The last of the three is the most suitable for our purposes due to its small space requirement. The priority search tree, invented by McCreight [22], was originally designed for solving semi-infinite range queries in two-dimensional space.
Reference: 8. <author> H. Edelsbrunner. </author> <title> A new approach to rectangle intersections. </title> <journal> International Journal of Computer Mathematics, </journal> <volume> 13(3-4):209-229, </volume> <year> 1983. </year>
Reference-contexts: In the general case, one does not assume that the pairs are intervals (x y). Another closely related computational geometry problem is the interval intersection problem, for which there exists a number of data structures such as the segment tree [7], the interval tree <ref> [8] </ref> and the priority search tree [22]. The last of the three is the most suitable for our purposes due to its small space requirement. The priority search tree, invented by McCreight [22], was originally designed for solving semi-infinite range queries in two-dimensional space.
Reference: 9. <author> M. Farach and M. </author> <title> Thorup. String matching in Lempel-Ziv compressed strings. </title> <booktitle> In Proc. ACM Symposium on Theory of Computing (STOC), </booktitle> <pages> pages 703-712, </pages> <year> 1995. </year>
Reference-contexts: As essential building blocks of the index structure we introduce two new data structures, the 2-d tree for strings and the two-dimensional heap. Both may have applications beyond the present context. Our search algorithm is based on a special property of LZ parsing of T , already noted in <ref> [9] </ref>: The first occurrence (from left to right) of P in T must overlap the last symbol of some block produced by the LZ parsing. <p> The basic two-phase technique based on Lempel-Ziv parsing has also been applied to searching q-grams [16]. The actual data structures, however, are very different from the ones described here. Technically related is also the problem of compressed matching <ref> [1, 9] </ref> which asks one to find the occurrences of P in T directly from the LZ compressed representation of T . The problem is quite different but the solutions utilize the same properties of LZ parsing as we do. <p> The scheme occurs in several variations. Our variation is the original from the seminal paper by Lempel and Ziv [19] which preceded the papers describing their famous data compression methods [26, 27]. The notation is borrowed from <ref> [9] </ref>. <p> The proof is immediate by contradiction. As the boundary symbols occur in text locations U i + L i for 1 i N , we have the following. Proposition 4 <ref> [9] </ref>.
Reference: 10. <author> E. R. Fiala and D. H. Greene. </author> <title> Data compression with finite windows. </title> <journal> Commun. ACM, </journal> <volume> 32(4) </volume> <pages> 490-505, </pages> <month> Apr. </month> <year> 1989. </year>
Reference-contexts: All of our results, including Theorem 2, still hold for this variation. The advantage of this variation is that the parse can be constructed in O (N ) space (and O (n log c) time) using a sparse suffix tree. The data compression method of Fiala and Greene <ref> [10] </ref> is based on this variation. The size of our index structure will be proportional to the length N of Z. We next derive a bound for N (cf. [19]). Lemma 1. <p> Example 4. For the text T of Example 1, the intervals [x i ; y i ] are [1; 3], [5; 5], [3; 5] and <ref> [6; 10] </ref>, and the corresponding offsets o i are 1, 1, 5 and 6. The first phrase of T is empty and the corresponding interval is omitted here.
Reference: 11. <author> G. H. Gonnet, R. A. Baeza-Yates, and T. Snider. </author> <title> Lexicographical indices for text: Inverted files vs. pat trees. </title> <type> Technical Report OED-91-01, </type> <institution> Centre for the New OED, University of Waterloo, </institution> <year> 1991. </year>
Reference-contexts: Although linear in size, a suffix tree can be uneconomically large to be really attractive in practical applications. The size depends on implementation details and the structure of the text, but will never be as low as 10n bytes. Suffix arrays <ref> [20, 11] </ref> (size 5n bytes), level-compressed tries [3, 4] (size about 11n bytes), suffix cactuses [15] (size 9n bytes), and suffix binary search trees [13] (size about 10n bytes) are alternative smaller data structures with almost the same properties as the suffix tree. <p> Their space requirement is still high for large n and it can be impossible to store the entire data structure in the fast memory. Using suffix trees and arrays in secondary memory environment is considered e.g. in <ref> [11, 5] </ref>. As the slow secondary memory operations can, in practice, destroy the good theoretical performance, there is a need to find small alternatives for suffix trees and arrays, even at the cost of increased search times. <p> Note that for solving the existence problem the primary search alone is enough. A totally different possibility to construct a small index structure is to build a sparse suffix tree, i.e., a suffix tree that represents only a subset of all suffixes <ref> [11, 23, 17, 2] </ref>. In this way, all occurrences of P that overlap the starting point of a suffix that is present in the tree can easily be found. The other occurrences are difficult and lead to a brute-force search. <p> However, due to O (m) time string comparisons the search time increases to O (m p N + l). Fortunately, this can be improved on by using a technique from one-dimensional prefix matching. The searching in a suffix array <ref> [20, 11] </ref> is essentially binary searching. With naive string comparisons the search time in a suffix array of N strings would be O (m log N + l), where l is the size of the answer.
Reference: 12. <author> M. Gu, M. Farach, and R. Beigel. </author> <title> An efficient algorithm for dynamic text indexing. </title> <booktitle> In Proc. 5th ACM-SIAM Symposium on Discrete Algorithms (SODA), </booktitle> <pages> pages 697-704, </pages> <year> 1994. </year>
Reference-contexts: The problem is quite different but the solutions utilize the same properties of LZ parsing as we do. Finally, we note that the subproblem of finding block matches in the dynamic text indexing algorithm of Gu, Farach and Beigel <ref> [12] </ref> resembles an on-line (no preprocessing) version of our primary searching. 2 LZ Parsing The Lempel-Ziv scheme of data compression is based on parsing the string into consecutive disjoint blocks that follow the internal repetitive structure of the string. The scheme occurs in several variations. <p> As a result the total primary search time can be reduced to O (m 2 + m log N + N m log m + L 1 ) ?? . To find the interesting periodicities in the pattern, we use a data structure called the border tree <ref> [12] </ref>. The border tree was originally used for answering prefix-suffix queries, which is indeed closely related to finding periodicities. We build two border trees, one for the prefixes and the other for the suffixes of the pattern.
Reference: 13. <author> R. W. Irving. </author> <title> Suffix binary search trees. </title> <type> Technical report TR-1995-7, </type> <institution> Computing Science Department, University of Glasgow, </institution> <month> Apr. </month> <year> 1995. </year>
Reference-contexts: The size depends on implementation details and the structure of the text, but will never be as low as 10n bytes. Suffix arrays [20, 11] (size 5n bytes), level-compressed tries [3, 4] (size about 11n bytes), suffix cactuses [15] (size 9n bytes), and suffix binary search trees <ref> [13] </ref> (size about 10n bytes) are alternative smaller data structures with almost the same properties as the suffix tree. Their space requirement is still high for large n and it can be impossible to store the entire data structure in the fast memory. <p> With precomputed information about the longest common prefixes (LCPs) between some of the strings, Manber and Myers [20] have reduced the time to O (m+log N +l). The technique has also been described for the general suffix binary search tree <ref> [13] </ref>. The LCP technique also applies for the 2-d tree which is a two-dimensional binary tree.
Reference: 14. <author> P. Jacquet and W. Szpankowski. </author> <title> Asymptotic behavior of the lempel-ziv parsing scheme and digital search trees. </title> <institution> Theoretical Comput. Sci., 144(1-2):161-197, </institution> <month> June </month> <year> 1995. </year>
Reference-contexts: The expec ted value of N has been shown to be about nh= log n, where h is the entropy of the text, for various versions of LZ parsing and various models of randomness (see, e.g., <ref> [14] </ref> and references therein). Some empirical measurements of N are given in Table 1. Random text represents the worst case, uncompressible text. Table 1.
Reference: 15. <author> J. Karkkainen. </author> <title> Suffix cactus: A cross between suffix tree and suffix array. </title> <booktitle> In Proc. 6th Symposium on Combinatorial Pattern Matching, </booktitle> <volume> CPM 95, </volume> <pages> pages 191-204, </pages> <year> 1995. </year>
Reference-contexts: The size depends on implementation details and the structure of the text, but will never be as low as 10n bytes. Suffix arrays [20, 11] (size 5n bytes), level-compressed tries [3, 4] (size about 11n bytes), suffix cactuses <ref> [15] </ref> (size 9n bytes), and suffix binary search trees [13] (size about 10n bytes) are alternative smaller data structures with almost the same properties as the suffix tree.
Reference: 16. <author> J. Karkkainen and E. Sutinen. </author> <title> Lempel-Ziv index for q-grams. </title> <type> Manuscript, </type> <year> 1996. </year>
Reference-contexts: This is in contrast with the method of the present paper that also finds such secondary occurrences fast using the properties of LZ parsing. The basic two-phase technique based on Lempel-Ziv parsing has also been applied to searching q-grams <ref> [16] </ref>. The actual data structures, however, are very different from the ones described here. Technically related is also the problem of compressed matching [1, 9] which asks one to find the occurrences of P in T directly from the LZ compressed representation of T . <p> The solutions to the primary and secondary searches can be changed, independent of each other. This may allow, for example, methods with different space-time trade-offs. A very different variation, in all aspects, applied to a slightly different problem is given in <ref> [16] </ref>. Table 2. The key properties of the whole index.
Reference: 17. <author> J. Karkkainen and E. Ukkonen. </author> <title> Sparse suffix trees. </title> <booktitle> In Proc. 2nd Annual International Computing and Combinatorics Conference (COCOON), </booktitle> <year> 1996. </year> <note> To appear. </note>
Reference-contexts: Note that for solving the existence problem the primary search alone is enough. A totally different possibility to construct a small index structure is to build a sparse suffix tree, i.e., a suffix tree that represents only a subset of all suffixes <ref> [11, 23, 17, 2] </ref>. In this way, all occurrences of P that overlap the starting point of a suffix that is present in the tree can easily be found. The other occurrences are difficult and lead to a brute-force search.
Reference: 18. <author> D. T. Lee and C. K. Wong. </author> <title> Worst-case analysis for region and partial region searches in multidimensional binary search trees and balanced quad trees. </title> <journal> Acta Inf., </journal> <volume> 9(1) </volume> <pages> 23-29, </pages> <month> Jan. </month> <year> 1977. </year>
Reference-contexts: The range query in a 2-d tree works in the obvious way by continuing the search in one or both subtrees of each node depending on the result of comparisons in the node. Lee and Wong <ref> [18] </ref> have shown that the range query in a balanced 2-d tree of N points takes O ( p N + l) time in the worst case, where l is the size of the answer. As noted earlier, the 2DPM problem can be interpreted as a two-dimensional range query.
Reference: 19. <author> A. Lempel and J. Ziv. </author> <title> On the complexity of finite sequences. </title> <journal> IEEE Trans. Inform. Theory, </journal> <volume> IT-22(1):75-81, </volume> <month> Jan. </month> <year> 1976. </year>
Reference-contexts: The scheme occurs in several variations. Our variation is the original from the seminal paper by Lempel and Ziv <ref> [19] </ref> which preceded the papers describing their famous data compression methods [26, 27]. The notation is borrowed from [9]. <p> The data compression method of Fiala and Greene [10] is based on this variation. The size of our index structure will be proportional to the length N of Z. We next derive a bound for N (cf. <ref> [19] </ref>). Lemma 1. Let T be a text over alphabet of size c and let Z be an LZ parse of T . There are at most c k blocks of length at most k in Z. Proof.
Reference: 20. <author> U. Manber and G. Myers. </author> <title> Suffix arrays: A new method for on-line string searches. </title> <journal> SIAM J. Comput., </journal> <volume> 22(5) </volume> <pages> 935-948, </pages> <month> Oct. </month> <year> 1993. </year>
Reference-contexts: Although linear in size, a suffix tree can be uneconomically large to be really attractive in practical applications. The size depends on implementation details and the structure of the text, but will never be as low as 10n bytes. Suffix arrays <ref> [20, 11] </ref> (size 5n bytes), level-compressed tries [3, 4] (size about 11n bytes), suffix cactuses [15] (size 9n bytes), and suffix binary search trees [13] (size about 10n bytes) are alternative smaller data structures with almost the same properties as the suffix tree. <p> However, due to O (m) time string comparisons the search time increases to O (m p N + l). Fortunately, this can be improved on by using a technique from one-dimensional prefix matching. The searching in a suffix array <ref> [20, 11] </ref> is essentially binary searching. With naive string comparisons the search time in a suffix array of N strings would be O (m log N + l), where l is the size of the answer. <p> With naive string comparisons the search time in a suffix array of N strings would be O (m log N + l), where l is the size of the answer. With precomputed information about the longest common prefixes (LCPs) between some of the strings, Manber and Myers <ref> [20] </ref> have reduced the time to O (m+log N +l). The technique has also been described for the general suffix binary search tree [13]. The LCP technique also applies for the 2-d tree which is a two-dimensional binary tree. <p> Compute the lexicographical ordering of the strings from the suffix tree by a lexicographical depth-first traversal in O (N ) time. 3. Compute the LCP-values by string comparisons. For a detailed description of the LCP-values we refer to <ref> [20] </ref>. For the present purpose, it is enough to know that to compute the LCP-values for position i, we need to find the LCPs between the string at position i and two other strings. By Lemma 5, the total time taken by this step is then O (n).
Reference: 21. <author> E. M. McCreight. </author> <title> A space-economical suffix tree construction algorithm. </title> <journal> J. ACM, </journal> <volume> 23(2) </volume> <pages> 262-272, </pages> <month> Apr. </month> <year> 1976. </year>
Reference-contexts: It can be constructed in time O (n log c) and space O (n), where n = jT j is the length of T and c = jj is the size of the alphabet <ref> [25, 21, 24] </ref>. The existence of an occurrence of P in T can be detected using the suffix tree in time O (m log c) and all occurrences can be listed in time O (m log c + L), where m = jPj and L is the number of occurrences.
Reference: 22. <author> E. M. McCreight. </author> <title> Priority search trees. </title> <journal> SIAM J. Comput., </journal> <volume> 14(2) </volume> <pages> 257-276, </pages> <month> May </month> <year> 1985. </year>
Reference-contexts: Another closely related computational geometry problem is the interval intersection problem, for which there exists a number of data structures such as the segment tree [7], the interval tree [8] and the priority search tree <ref> [22] </ref>. The last of the three is the most suitable for our purposes due to its small space requirement. The priority search tree, invented by McCreight [22], was originally designed for solving semi-infinite range queries in two-dimensional space. <p> for which there exists a number of data structures such as the segment tree [7], the interval tree [8] and the priority search tree <ref> [22] </ref>. The last of the three is the most suitable for our purposes due to its small space requirement. The priority search tree, invented by McCreight [22], was originally designed for solving semi-infinite range queries in two-dimensional space. With the priority search tree the interval containment problem with N intervals can be answered in time O (log N + l), where l is the size of the result.
Reference: 23. <author> D. R. Morrison. </author> <title> PATRICIA|Practical Algorithm To Retrieve Information Coded in Alphanumeric. </title> <journal> J. ACM, </journal> <volume> 15(4) </volume> <pages> 514-534, </pages> <month> Oct. </month> <year> 1968. </year>
Reference-contexts: Note that for solving the existence problem the primary search alone is enough. A totally different possibility to construct a small index structure is to build a sparse suffix tree, i.e., a suffix tree that represents only a subset of all suffixes <ref> [11, 23, 17, 2] </ref>. In this way, all occurrences of P that overlap the starting point of a suffix that is present in the tree can easily be found. The other occurrences are difficult and lead to a brute-force search.
Reference: 24. <author> E. Ukkonen. </author> <title> On-line construction of suffix-trees. </title> <journal> Algorithmica, </journal> <volume> 14(3) </volume> <pages> 249-260, </pages> <month> Sept. </month> <year> 1995. </year>
Reference-contexts: It can be constructed in time O (n log c) and space O (n), where n = jT j is the length of T and c = jj is the size of the alphabet <ref> [25, 21, 24] </ref>. The existence of an occurrence of P in T can be detected using the suffix tree in time O (m log c) and all occurrences can be listed in time O (m log c + L), where m = jPj and L is the number of occurrences.
Reference: 25. <author> P. Weiner. </author> <title> Linear pattern matching algorithms. </title> <booktitle> In Proc. IEEE 14th Annual Symposium on Switching and Automata Theory, </booktitle> <pages> pages 1-11, </pages> <year> 1973. </year>
Reference-contexts: It can be constructed in time O (n log c) and space O (n), where n = jT j is the length of T and c = jj is the size of the alphabet <ref> [25, 21, 24] </ref>. The existence of an occurrence of P in T can be detected using the suffix tree in time O (m log c) and all occurrences can be listed in time O (m log c + L), where m = jPj and L is the number of occurrences.
Reference: 26. <author> J. Ziv and A. Lempel. </author> <title> A universal algorithm for sequential data compression. </title> <journal> IEEE Trans. Inform. Theory, </journal> <volume> IT-23(3):337-343, </volume> <month> May </month> <year> 1977. </year>
Reference-contexts: The scheme occurs in several variations. Our variation is the original from the seminal paper by Lempel and Ziv [19] which preceded the papers describing their famous data compression methods <ref> [26, 27] </ref>. The notation is borrowed from [9].
Reference: 27. <author> J. Ziv and A. Lempel. </author> <title> Compression of individual sequences via variable-rate coding. </title> <journal> IEEE Trans. Inform. Theory, </journal> <volume> IT-24(5):530-536, </volume> <month> Sept. </month> <year> 1978. </year> <title> This article was processed using the L A T E X 2 " macro package with CUP CS class </title>
Reference-contexts: The scheme occurs in several variations. Our variation is the original from the seminal paper by Lempel and Ziv [19] which preceded the papers describing their famous data compression methods <ref> [26, 27] </ref>. The notation is borrowed from [9].
References-found: 27

