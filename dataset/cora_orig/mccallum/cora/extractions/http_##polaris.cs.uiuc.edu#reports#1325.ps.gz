URL: http://polaris.cs.uiuc.edu/reports/1325.ps.gz
Refering-URL: http://polaris.cs.uiuc.edu/tech_reports.html
Root-URL: http://www.cs.uiuc.edu
Title: A Compiler-Directed Cache Coherence Scheme with Improved Intertask Locality  
Author: Lynn Choi Pen-Chung Yew 
Address: Urbana, IL 61801-1351 Minneapolis, MN 55455-0519  
Affiliation: Center for Supercomputing R D Department of Computer Science University of Illinois University of Minnesota  
Abstract: In this paper 1 , we introduce a compiler-directed coherence scheme which can exploit most of the temporal and spatial locality across task boundaries. It requires only an extended tag field per cache word, one modified memory access instruction, and a counter called the epoch counter in each processor. By using the epoch counter as a system-wide version number, the scheme simplifies the cache hardware of previous version control [5] or timestamp-based schemes [12], but still exploits most of the temporal and spatial locality across task boundaries. We present a compiler algorithm to generate the appropriate memory access instructions for the proposed scheme. The algorithm is based on a data flow analysis technique. It identifies potential stale references by examining memory reference patterns in a source program. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> L. M. Censier and P. Feautrier. </author> <title> A New Solution to Coherence Problems in Multicache Systems. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-27(12):1112-1118, </volume> <month> December, </month> <year> 1978. </year>
Reference-contexts: Having multiple cached copies of a shared memory location, however, can lead to erroneous program behavior unless coherence is maintained. Existing solutions for large-scale multiprocessors include hardware directories <ref> [1, 10] </ref> and software techniques [2, 3, 5, 6, 11, 12, 14, 15]. By maintaining sharing information at runtime, directory-based schemes can identify stale data accurately, preserving more 1 This work is support in part by the National Science Foundation under Grant No. MIP 89-20891, MIP 93-07910. ISSN 1063-9535. <p> To decide a cache hit, each memory access compares its CVN for the variable with the BVN of the corresponding cache copy. Assume that at the time of LOAD B, a conflict miss occurs, replacing the cache line that contains A [0], A <ref> [1] </ref>, A [2] and A [3] with the new cache line that contains B. Since LOAD B only updates the BVN of the variable B, the BVN's for the variable C, D and E in the same cache line are unknown. <p> Since LOAD B only updates the BVN of the variable B, the BVN's for the variable C, D and E in the same cache line are unknown. In addition, when A [0] is accessed again, the BVN's of A <ref> [1] </ref>, A [2] and A [3] in the same cache line are lost. Although only 2 read accesses (LOAD B and LOAD A [0]) are the real misses due to the conflict, four additional misses occur due to the incomplete version information.
Reference: [2] <author> Hoichi Cheong. </author> <title> Life Span Strategy A Compiler-Based Approach to Cache Coherence. </title> <booktitle> Proceedings of the 1992 International Conference on Supercomputing, </booktitle> <month> July </month> <year> 1992. </year>
Reference-contexts: Having multiple cached copies of a shared memory location, however, can lead to erroneous program behavior unless coherence is maintained. Existing solutions for large-scale multiprocessors include hardware directories [1, 10] and software techniques <ref> [2, 3, 5, 6, 11, 12, 14, 15] </ref>. By maintaining sharing information at runtime, directory-based schemes can identify stale data accurately, preserving more 1 This work is support in part by the National Science Foundation under Grant No. MIP 89-20891, MIP 93-07910. ISSN 1063-9535. Copyright (c) 1994 IEEE. <p> In this paper, we propose a compiler-directed scheme which preserves most of temporal and spatial locality across task boundaries. In this scheme, each epoch is assigned a unique epoch number similar to the version number in previous schemes <ref> [2, 5, 6, 12] </ref>. The epoch number is maintained at runtime using a counter called the epoch counter. Each data in a cache is associated with a time-tag that records the epoch number in which the cache copy is created. <p> Preserving spatial locality is difficult in version or timestamp-based schemes because on a miss, version information cannot be determined for the preloaded variables in the same cache line (see section 2.2). Similar situations occur in several recent schemes <ref> [2, 6, 14] </ref>. Our scheme can also avoid flushing the entire cache when the epoch counter overflows by using an overflow reset mechanism. In the following, we first characterize existing compiler-directed schemes in section 2.1 and discuss our motivation for the proposed scheme in section 2.2. <p> The fast selective invalidation scheme [3] combines the techniques of prevention and detection, and extends the simple invalidation scheme to exploit intertask locality for safe (e.g., read-only) accesses. The life span strategy <ref> [2] </ref>, Peir and So's scheme [14] and the generational algorithm [6] allow invalidation on a per-variable basis. In these schemes, a variable is not invalidated until the next write to that variable occurs in a different task. <p> An up-to-date copy is brought in if it is stale. 2.2 Limitation on multi-word cache lines In some existing compiler-directed schemes that exploit temporal locality across task boundaries <ref> [2, 5, 12, 14] </ref>, version information is maintained for each cache copy, which is used to determine whether the copy is SI FSI VC/Time Lifespan Two-Phase Invalidation Coherence Prevention Detection, Avoidance Detection, Detection, Technique Prevention Prevention Avoidance Intertask None Read-only Temporal Temporal Temporal, Locality Data Spatial Storage O (c) O (c) <p> O (logN) + O (N) O (logN) Overhead Version Storage Runtime invalidate invalidate version lookup invalidate epoch counter Overhead for each access (shifting increment and version update cache columns) SI: Simple Invalidation [15], FSI: Fast Selective Invalidation [3], VC: Version Control Scheme [5], Time: Timestamp-based scheme [12], Lifespan: Lifespan strategy <ref> [2] </ref>, Two-Phase Invalidation: Our proposed scheme which locality is to be preserved while c denotes a constant. stale or not. However, the version information is lost on the replacement of a cache line unless the version information is stored back to the memory. <p> However, the version information is lost on the replacement of a cache line unless the version information is stored back to the memory. This is not a problem for a single-word cache line since the version information is provided by hardware [5, 12] or by an operand <ref> [2, 14] </ref> in every memory access instruction. However, with multi-word cache lines or with hardware prefetching schemes, it is a problem because it is quite difficult for a compiler to know exactly which variables are allocated in the same cache line for every cache line. <p> Furthermore, to provide version information for every word in a cache line, the memory instructions used in <ref> [2, 14] </ref> should have as many operands as the number of words in a line. For the timestamp-based schemes, they require the cache controller to recompute the version information of each word sequentially by looking up its version storage [5, 12]. <p> The intratask locality can still be captured if these preloaded variables are invalidated at task boundaries. As an example, let's look at Figure 2 which shows the situation in the version control scheme. Several other compiler-directed schemes <ref> [6, 2, 12, 14] </ref> have a similar problem. In this scheme, the birth version number (BVN) is associated with every data item in the cache. In addition, the processor keeps track of the current version number (CVN) for each variable in a separate local memory, called version store. <p> To decide a cache hit, each memory access compares its CVN for the variable with the BVN of the corresponding cache copy. Assume that at the time of LOAD B, a conflict miss occurs, replacing the cache line that contains A [0], A [1], A <ref> [2] </ref> and A [3] with the new cache line that contains B. Since LOAD B only updates the BVN of the variable B, the BVN's for the variable C, D and E in the same cache line are unknown. <p> Since LOAD B only updates the BVN of the variable B, the BVN's for the variable C, D and E in the same cache line are unknown. In addition, when A [0] is accessed again, the BVN's of A [1], A <ref> [2] </ref> and A [3] in the same cache line are lost. Although only 2 read accesses (LOAD B and LOAD A [0]) are the real misses due to the conflict, four additional misses occur due to the incomplete version information. <p> For consistency, the memory should be up-to-date at synchronization points. 3.2 Coherence mechanism and its hard ware support In our cache coherence scheme, each epoch is assigned a unique epoch number which is similar to the version number in previous schemes <ref> [2, 5, 6, 12] </ref>. The epoch number is stored in a n-bit register, called the epoch counter (R counter ), and incremented at the end of every epoch. denotes a time-tag. 4-word line size. <p> The hardware cost can thus be reduced substantially. Our simulations show that it can eliminate most of the unnecessary invalidations caused by the overflows using a small time tag. Recently, several new schemes have been proposed to address the above problems <ref> [2, 14] </ref>. In these schemes, every memory instruction stores the version information as part of the cache state. To exploit n levels of task locality, those schemes require n bits of state information per cache word. <p> The scheme only requires log 2 n bits to exploit n levels of intertask locality as opposed to n bits for the bit vector information used in the lifespan strategy <ref> [2] </ref> or Peir and So's scheme [14]. From our simulation results, 16 levels of intertask locality is usually enough to keep most of temporal locality.
Reference: [3] <author> Hoichi Cheong and Alex Veidenbaum. </author> <title> A Cache Coherence Scheme with Fast Selective Invalidation. </title> <booktitle> Proceedings of The 15th Annual International Symposium on Computer Architecture, </booktitle> <pages> page 299, </pages> <month> June </month> <year> 1988. </year>
Reference-contexts: Having multiple cached copies of a shared memory location, however, can lead to erroneous program behavior unless coherence is maintained. Existing solutions for large-scale multiprocessors include hardware directories [1, 10] and software techniques <ref> [2, 3, 5, 6, 11, 12, 14, 15] </ref>. By maintaining sharing information at runtime, directory-based schemes can identify stale data accurately, preserving more 1 This work is support in part by the National Science Foundation under Grant No. MIP 89-20891, MIP 93-07910. ISSN 1063-9535. Copyright (c) 1994 IEEE. <p> Simple invalidation [15] maintains cache coherence by flushing the cache at task boundaries. If there is no read-write dependences among processors, e.g., during the parallel execution of a doall loop, no stale accesses will occur in each processor. The fast selective invalidation scheme <ref> [3] </ref> combines the techniques of prevention and detection, and extends the simple invalidation scheme to exploit intertask locality for safe (e.g., read-only) accesses. The life span strategy [2], Peir and So's scheme [14] and the generational algorithm [6] allow invalidation on a per-variable basis. <p> None Read-only Temporal Temporal Temporal, Locality Data Spatial Storage O (c) O (c) O (logN) + O (N) O (logN) Overhead Version Storage Runtime invalidate invalidate version lookup invalidate epoch counter Overhead for each access (shifting increment and version update cache columns) SI: Simple Invalidation [15], FSI: Fast Selective Invalidation <ref> [3] </ref>, VC: Version Control Scheme [5], Time: Timestamp-based scheme [12], Lifespan: Lifespan strategy [2], Two-Phase Invalidation: Our proposed scheme which locality is to be preserved while c denotes a constant. stale or not. <p> To decide a cache hit, each memory access compares its CVN for the variable with the BVN of the corresponding cache copy. Assume that at the time of LOAD B, a conflict miss occurs, replacing the cache line that contains A [0], A [1], A [2] and A <ref> [3] </ref> with the new cache line that contains B. Since LOAD B only updates the BVN of the variable B, the BVN's for the variable C, D and E in the same cache line are unknown. <p> Since LOAD B only updates the BVN of the variable B, the BVN's for the variable C, D and E in the same cache line are unknown. In addition, when A [0] is accessed again, the BVN's of A [1], A [2] and A <ref> [3] </ref> in the same cache line are lost. Although only 2 read accesses (LOAD B and LOAD A [0]) are the real misses due to the conflict, four additional misses occur due to the incomplete version information.
Reference: [4] <author> Hoichi Cheong and Alexander V. Veidenbaum. </author> <title> Stale Data Detection and Coherence Enforcement Using Flow Analysis. </title> <booktitle> Proceedings of the 1988 International Conference on Parallel Processing, I, </booktitle> <address> Architecture:138-145, </address> <month> August </month> <year> 1988. </year>
Reference-contexts: Existing software coherence schemes use combinations of these techniques (see Table 1). Stale access detection refers to the use of compile time analysis to identify potential references to stale data <ref> [4] </ref>. By identifying these potential stale references at the compile time, the system can be forced to get up-to-date data directly from the main memory, instead of from the cache. Stale access prevention techniques invalidate or update stale cache entries before stale accesses occur. <p> The sequence of events from (1) to (4) is called collectively an RDS (relaxed determining sequence) <ref> [4] </ref>. When an RDS of the variable v precedes a read of v with no reference to v in between, the read of v is considered a potential stale reference, and should be emitted as a Time-Read instruction. <p> We also present a flow analysis algorithm which can identify potential stale references and generate appropriate memory instructions for the proposed scheme. Compared to the algorithm introduced in <ref> [4] </ref>, our algorithm eliminates the graph construction needed for each variable for the RDS detection step [4], and integrates the RDS detection in the flow analysis. We are currently implementing these compiler algorithms in the Polaris parallelizing compiler [13]. <p> We also present a flow analysis algorithm which can identify potential stale references and generate appropriate memory instructions for the proposed scheme. Compared to the algorithm introduced in <ref> [4] </ref>, our algorithm eliminates the graph construction needed for each variable for the RDS detection step [4], and integrates the RDS detection in the flow analysis. We are currently implementing these compiler algorithms in the Polaris parallelizing compiler [13].
Reference: [5] <author> Hoichi Cheong and Alexander V. </author> <note> Veidenbaum. </note>
Reference-contexts: Having multiple cached copies of a shared memory location, however, can lead to erroneous program behavior unless coherence is maintained. Existing solutions for large-scale multiprocessors include hardware directories [1, 10] and software techniques <ref> [2, 3, 5, 6, 11, 12, 14, 15] </ref>. By maintaining sharing information at runtime, directory-based schemes can identify stale data accurately, preserving more 1 This work is support in part by the National Science Foundation under Grant No. MIP 89-20891, MIP 93-07910. ISSN 1063-9535. Copyright (c) 1994 IEEE. <p> In this paper, we propose a compiler-directed scheme which preserves most of temporal and spatial locality across task boundaries. In this scheme, each epoch is assigned a unique epoch number similar to the version number in previous schemes <ref> [2, 5, 6, 12] </ref>. The epoch number is maintained at runtime using a counter called the epoch counter. Each data in a cache is associated with a time-tag that records the epoch number in which the cache copy is created. <p> Using the epoch counter as a system-wide version number has two advantages. First, it eliminates the storage requirement of keeping the version number of each variable as in the version and the timestamp-based schemes <ref> [5, 12] </ref>. It only needs a single systemwide version number during execution. This significantly simplifies the hardware for the cache controller. <p> Stale access avoidance is a more relaxed coherence model than the prevention technique. It allows the existence of stale data but avoids stale accesses to them at run time. Examples of this approach include the timestamp-based scheme [12] and the version control scheme <ref> [5] </ref>. In such schemes, stale data can exist until an access to the data occurs. At that time, by checking the status of the data in the cache, it is decided whether an up-to-date copy is brought in from main memory or not. <p> An up-to-date copy is brought in if it is stale. 2.2 Limitation on multi-word cache lines In some existing compiler-directed schemes that exploit temporal locality across task boundaries <ref> [2, 5, 12, 14] </ref>, version information is maintained for each cache copy, which is used to determine whether the copy is SI FSI VC/Time Lifespan Two-Phase Invalidation Coherence Prevention Detection, Avoidance Detection, Detection, Technique Prevention Prevention Avoidance Intertask None Read-only Temporal Temporal Temporal, Locality Data Spatial Storage O (c) O (c) <p> Locality Data Spatial Storage O (c) O (c) O (logN) + O (N) O (logN) Overhead Version Storage Runtime invalidate invalidate version lookup invalidate epoch counter Overhead for each access (shifting increment and version update cache columns) SI: Simple Invalidation [15], FSI: Fast Selective Invalidation [3], VC: Version Control Scheme <ref> [5] </ref>, Time: Timestamp-based scheme [12], Lifespan: Lifespan strategy [2], Two-Phase Invalidation: Our proposed scheme which locality is to be preserved while c denotes a constant. stale or not. <p> However, the version information is lost on the replacement of a cache line unless the version information is stored back to the memory. This is not a problem for a single-word cache line since the version information is provided by hardware <ref> [5, 12] </ref> or by an operand [2, 14] in every memory access instruction. <p> For the timestamp-based schemes, they require the cache controller to recompute the version information of each word sequentially by looking up its version storage <ref> [5, 12] </ref>. This creates a performance problem since the loss of version information may create unnecessary misses when the cache line is reloaded. It can incur a significant performance loss since the intertask locality cannot be preserved for all the preloaded variables in the same cache line. <p> For consistency, the memory should be up-to-date at synchronization points. 3.2 Coherence mechanism and its hard ware support In our cache coherence scheme, each epoch is assigned a unique epoch number which is similar to the version number in previous schemes <ref> [2, 5, 6, 12] </ref>. The epoch number is stored in a n-bit register, called the epoch counter (R counter ), and incremented at the end of every epoch. denotes a time-tag. 4-word line size. <p> It eliminates the required version storage in the version control <ref> [5] </ref> and the timestamp-based scheme [12]. Our proposed scheme can also avoid flushing the entire cache when the epoch counter overflows by using its two-phase invalidation mechanism. This can be significant because it avoids using a large time tag to reduce the frequency of the time tag overflows. <p> The scheme requires a small amount of hardware support and can be implemented efficiently on a microprocessor with minimal modifications. The uniform version numbering on a per-epoch basis eliminates the performance and implementation problems of the timestamp [12] or version control <ref> [5] </ref> schemes. It also allows us to support multi-word lines without losing spatial locality. We describe the hardware support, memory and cache management operations and the compiler marking algorithms needed to perform correct memory and cache operations.
References-found: 5

