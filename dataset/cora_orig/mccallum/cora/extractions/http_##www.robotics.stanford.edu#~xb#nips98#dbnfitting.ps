URL: http://www.robotics.stanford.edu/~xb/nips98/dbnfitting.ps
Refering-URL: http://www.robotics.stanford.edu/~xb/nips98/index.html
Root-URL: http://www.robotics.stanford.edu
Email: xb@cs.stanford.edu  koller@cs.stanford.edu  
Title: Approximate learning of dynamic models  
Author: Xavier Boyen Daphne Koller 
Address: 1A Stanford, CA 94305-9010  1A Stanford, CA 94305-9010  
Affiliation: Computer Science Dept.  Computer Science Dept.  
Abstract: Inference is a key component in learning probabilistic models from partially observable data. When learning temporal models, each of the many inference phases requires a complete traversal over a potentially very long sequence; furthermore, the data structures propagated in this procedure can be extremely large, making the whole process very demanding. In [2], we describe an approximate inference algorithm for monitoring stochastic processes, and prove bounds on its approximation error. In this paper, we apply this algorithm as an approximate forward propagation step in an EM algorithm for learning temporal Bayesian networks. We also provide a related approximation for the backward step, and prove error bounds for the combined algorithm. We show that EM using our inference algorithm is much faster than EM using exact inference, with no degradation of the quality of the learned model. We then extend our analysis to the online learning task, showing a bound on the error resulting from restricting attention to a small window of observations. We present an online EM learning algorithm for dynamic systems, and show that it learns much faster than standard offline EM.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. Artzrouni and X. Li. </author> <title> A note on the coefficient of ergodicity of a column-allowable nonnegative matrix. Linear algebra and applications, </title> <address> 214:93101, </address> <year> 1995. </year>
Reference-contexts: Lemma 1 ID Proj [ (t) (t) ] ID Proj [ffffff (t1) ; ffffff (t1) ] + ID Proj [fififi (t) ; fififi (t) Based on the results of <ref> [1] </ref>, we show that projective distance contracts when messages are propagated through the stochastic transition matrix, in either direction: Lemma 2 Let k = min fi;j;i 0 ;j 0 :T i;j T i 0 ;j 0 6=0g p (T i;j 0 T i 0 ;j )=(T i;j T i 0 ;j
Reference: [2] <author> X. Boyen and D. Koller. </author> <title> Tractable inference for complex stochastic processes. </title> <booktitle> In Proc. </booktitle> <address> UAI, </address> <year> 1998. </year> <note> To appear. </note>
Reference-contexts: In this paper, we describe and analyze an approach that helps us address both of these problems. In <ref> [2] </ref>, we proposed a new approach to approximate inference in stochastic processes, where approximate distributions that admit compact representation are maintained and propagated. <p> Our analysis relied on a novel result showing that transition through a stochastic process is a contraction for relative entropy (KL-divergence) [3]. Here, we apply this approach to the parameter learning task. This application is not completely straightforward, since our algorithm of <ref> [2] </ref> and the associated analysis only applied to the forward propagation of messages, whereas the inference used in learning algorithms require propagation of information from the entire sequence. <p> Furthermore even highly structured processes do not admit a more compact representation of these messages <ref> [8, 2] </ref>. 3 Belief state approximation In [2], we described a new approach to approximate inference in dynamic systems, which avoids the problem of explicitly maintaining distributions over large spaces. We maintain our belief state (distribution over the current state) using some computationally tractable representation of a distribution. <p> Furthermore even highly structured processes do not admit a more compact representation of these messages [8, 2]. 3 Belief state approximation In <ref> [2] </ref>, we described a new approach to approximate inference in dynamic systems, which avoids the problem of explicitly maintaining distributions over large spaces. We maintain our belief state (distribution over the current state) using some computationally tractable representation of a distribution. <p> We want to apply the same type of approximate inference algorithm to the backward propagation as we did for the forward one, i.e., maintain and propagate a compactly represented approximate backward message fififi (t) In order to guarantee bounds on the accumulated error, we could simply extend our analysis of <ref> [2] </ref> to the backward message. However, this approach turns out to be problematic. Even if we have bounds on relative entropy error of both the forward and backward messages, bounds for the error of the (t) do not follow. <p> We applied our ideas to the task of parameter learning in DBNs, using the approximation scheme of <ref> [2] </ref>, where messages are represented in a factored way as marginals over specified clusters of variables. The clique tree algorithm [10] was used to propagate the messages forward and backward. <p> Our results show that even severe structural approximations have negligible effects on the accuracy of learning. The advantages of approximate inference in the learning setting are even more pronounced than in the case of pure inference <ref> [2] </ref>; here, the small errors caused by approximation are negligible compared to the larger ones induced by the learning itself. Our techniques provide the first feasible approach for learning structured models of complex dynamic systems, with the resulting advantages of generalization and the ability to incorporate prior knowledge.
Reference: [3] <author> T. Cover and J. Thomas. </author> <title> Elements of Information Theory. </title> <publisher> Wiley, </publisher> <year> 1991. </year>
Reference-contexts: We also proved that the accumulated error arising from the repeated approximations remains bounded indefinitely over time. Our analysis relied on a novel result showing that transition through a stochastic process is a contraction for relative entropy (KL-divergence) <ref> [3] </ref>. Here, we apply this approach to the parameter learning task. This application is not completely straightforward, since our algorithm of [2] and the associated analysis only applied to the forward propagation of messages, whereas the inference used in learning algorithms require propagation of information from the entire sequence.
Reference: [4] <author> T. Dean and K. </author> <title> Kanazawa. A model for reasoning about persistence and causation. </title> <journal> Comp. Int., </journal> <volume> 5(3), </volume> <year> 1989. </year>
Reference-contexts: Until now, hidden Markov models (HMMs) [12] have played the largest role as a representation for learning models of stochastic processes. Recently, however, there has been increasing use of more structured models of stochastic processes, such as factored HMMs [8] or dynamic Bayesian networks (DBNs) <ref> [4] </ref>. Such structured decomposed representations allow complex processes over a large number of states to be encoded using a much smaller number of parameters, allowing much better generalization from limited amounts of data [8, 7, 13].
Reference: [5] <author> A.P. Dempster, N.M. Laird, and D.B. Rubin. </author> <title> Maximum-likelihood from incomplete data via the EM algorithm. </title> <journal> Journal of the Royal Statistical Society, </journal> <volume> B39:138, </volume> <year> 1977. </year>
Reference-contexts: Our goal is to learn the model for stochastic process from partially observable data. To simplify our discussion, we focus on the problem of learning parameters for a known structure using the EM (Expectation Maximization) algorithm <ref> [5] </ref>; most of our discussion applies equally to other contexts (e.g., [7]). EM is an iterative procedure that searches over the space of parameter vectors for one which is a local maximum of the likeiihood function the probability of the observed data D given Q.
Reference: [6] <author> J. Forbes, T. Huang, K. Kanazawa, and S.J. Russell. </author> <title> The BATmobile: Towards a Bayesian automated taxi. </title> <booktitle> In Proc. IJCAI, </booktitle> <year> 1995. </year>
Reference-contexts: Then, fififi (t) is obtained by reading off the relevant marginals from the tree ( fififi (t) is implicitly defined as their product). We tested our algorithms on the task of learning the parameters for the BAT network shown on Figure 1 (a), used for traffic monitoring <ref> [6] </ref>. The training set was a fixed sequence of 400 slices, generated from the correct network distribution. Our test metric was the average log-likelihood (per slice) of a fixed test sequence of 50 slices.
Reference: [7] <author> N. Friedman, K. Murphy, and S.J. Russell. </author> <title> Learning the structure of dynamic probabilistic networks. </title> <booktitle> In Proc. </booktitle> <address> UAI, </address> <year> 1998. </year> <note> To appear. </note>
Reference-contexts: Such structured decomposed representations allow complex processes over a large number of states to be encoded using a much smaller number of parameters, allowing much better generalization from limited amounts of data <ref> [8, 7, 13] </ref>. Furthermore, the natural structure of such processes makes it easier for a human expert to incorporate prior knowledge about the domain structure into the model, thereby improving its inductive bias. <p> Furthermore, the natural structure of such processes makes it easier for a human expert to incorporate prior knowledge about the domain structure into the model, thereby improving its inductive bias. Both parameter and structure learning algorithms for dynamic models <ref> [12, 7] </ref> use probabilistic inference as a crucial component. An inference routine is called multiple times in order to fill in missing data with its expected value according to the current hypothesis; the resulting expected sufficient statistics are then used to construct a new hypothesis. <p> Our goal is to learn the model for stochastic process from partially observable data. To simplify our discussion, we focus on the problem of learning parameters for a known structure using the EM (Expectation Maximization) algorithm [5]; most of our discussion applies equally to other contexts (e.g., <ref> [7] </ref>). EM is an iterative procedure that searches over the space of parameter vectors for one which is a local maximum of the likeiihood function the probability of the observed data D given Q. <p> The most obvious extension to our results is an integration of our ideas with structure learning algorithm for DBNs <ref> [7] </ref>. This integration is not completely trivial, as the structural approximation used in our algorithm is designed to produce the expected sufficient statistics required for learning parameters for a given structure.
Reference: [8] <author> Z. Ghahramani and M.I. Jordan. </author> <title> Factorial hidden Markov models. </title> <booktitle> In NIPS 8, </booktitle> <year> 1996. </year>
Reference-contexts: Until now, hidden Markov models (HMMs) [12] have played the largest role as a representation for learning models of stochastic processes. Recently, however, there has been increasing use of more structured models of stochastic processes, such as factored HMMs <ref> [8] </ref> or dynamic Bayesian networks (DBNs) [4]. Such structured decomposed representations allow complex processes over a large number of states to be encoded using a much smaller number of parameters, allowing much better generalization from limited amounts of data [8, 7, 13]. <p> Such structured decomposed representations allow complex processes over a large number of states to be encoded using a much smaller number of parameters, allowing much better generalization from limited amounts of data <ref> [8, 7, 13] </ref>. Furthermore, the natural structure of such processes makes it easier for a human expert to incorporate prior knowledge about the domain structure into the model, thereby improving its inductive bias. <p> Furthermore even highly structured processes do not admit a more compact representation of these messages <ref> [8, 2] </ref>. 3 Belief state approximation In [2], we described a new approach to approximate inference in dynamic systems, which avoids the problem of explicitly maintaining distributions over large spaces. We maintain our belief state (distribution over the current state) using some computationally tractable representation of a distribution. <p> We also presented results for the online learning task, showing that even a very small time window suffices for doing learning. The work most comparable to ours is the variational approach to approximate inference applied to learning factored HMMs <ref> [8] </ref>. While we have not done a direct empirical comparison, our algorithms track exact EM so closely, that any improvement in accuracy would be negligible. Our algorithm is also much simpler, and therefore may be faster.
Reference: [9] <author> R.E. </author> <title> Kalman. A new approach to linear filtering and prediction problems. </title> <journal> J. of Basic Engineering, </journal> <year> 1960. </year>
Reference-contexts: Finally, in the static-0 approach, there is no lookahead at all; only the past and present evidence is used to compute the joint beliefs. The latter case is precisely the technique used in Kalman filters <ref> [9] </ref> for online learning of the process parameters. To minimize the computational burden, all tests were conducted using the 5+5 structural approximation. The running time for the various algorithms are: 0:4 sec/slice for batch EM; 1.4 for dynamic-400; 0:5 for static-400 and for static-4; and 0.3 for static-0.
Reference: [10] <author> S.L. Lauritzen and D.J. Spiegelhalter. </author> <title> Local computations with probabilities on graphical structures and their application to expert systems. </title> <journal> J. Roy. Stat. Soc., </journal> <volume> B 50, </volume> <year> 1988. </year>
Reference-contexts: We applied our ideas to the task of parameter learning in DBNs, using the approximation scheme of [2], where messages are represented in a factored way as marginals over specified clusters of variables. The clique tree algorithm <ref> [10] </ref> was used to propagate the messages forward and backward. For example, to compute fififi (t) from fififi (t+1) , we generate a clique tree over the DBN and incorporate fififi (t+1) in it.
Reference: [11] <author> R.M. Neal and G.E. Hinton. </author> <title> A view of the EM algorithm that justifies incremental, sparse, and other variants. In M.I. Jordan, editor, Learning in Graphical Models. </title> <publisher> Kluwer, </publisher> <year> 1998. </year>
Reference-contexts: Based on these insights, we experimented with various online algorithms that use a small window approximations. Our online algorithms are based on the approach of <ref> [11] </ref>, in which ESS are updated with an exponential decay every few data cases; the parameters are then updated correspondingly. The main problem with frequent parameter updates in the online setting is that they require a recomputation of the messages computed using the old parameters.
Reference: [12] <author> L. Rabiner and B. Juang. </author> <title> An introduction to hidden Markov models. </title> <booktitle> IEEE Acoustics, Speech & Signal Processing, </booktitle> <year> 1986. </year>
Reference-contexts: As in any inductive learning task, the first decision we must make concerns the representation of our learned hypotheses. Until now, hidden Markov models (HMMs) <ref> [12] </ref> have played the largest role as a representation for learning models of stochastic processes. Recently, however, there has been increasing use of more structured models of stochastic processes, such as factored HMMs [8] or dynamic Bayesian networks (DBNs) [4]. <p> Furthermore, the natural structure of such processes makes it easier for a human expert to incorporate prior knowledge about the domain structure into the model, thereby improving its inductive bias. Both parameter and structure learning algorithms for dynamic models <ref> [12, 7] </ref> use probabilistic inference as a crucial component. An inference routine is called multiple times in order to fill in missing data with its expected value according to the current hypothesis; the resulting expected sufficient statistics are then used to construct a new hypothesis.
Reference: [13] <author> G. Zweig and S.J. Russell. </author> <title> Speech recognition with dynamic bayesian networks. </title> <booktitle> In Proc. AAAI, </booktitle> <year> 1998. </year> <note> To appear. </note>
Reference-contexts: Such structured decomposed representations allow complex processes over a large number of states to be encoded using a much smaller number of parameters, allowing much better generalization from limited amounts of data <ref> [8, 7, 13] </ref>. Furthermore, the natural structure of such processes makes it easier for a human expert to incorporate prior knowledge about the domain structure into the model, thereby improving its inductive bias.
References-found: 13

