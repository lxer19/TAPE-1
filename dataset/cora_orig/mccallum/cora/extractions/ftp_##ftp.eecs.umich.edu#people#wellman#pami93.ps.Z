URL: ftp://ftp.eecs.umich.edu/people/wellman/pami93.ps.Z
Refering-URL: http://ai.eecs.umich.edu/people/wellman/Publications.html
Root-URL: http://www.cs.umich.edu
Email: wellman@engin.umich.edu  
Title: Explaining "Explaining Away"  
Author: Michael P. Wellman Max Henrion 
Note: Appeared as a correspondence in IEEE Transactions on Pattern Analysis and Machine Intelligence, 15(3):287-292, 1993.  
Date: March 16, 1994  
Web: henrion@sumex-aim.stanford.edu  
Address: Ann Arbor, MI 48109  444 High St, #400 Palo Alto, CA 94301  
Affiliation: University of Michigan Department of EECS  Rockwell International Science Center  
Abstract: Explaining away is a common pattern of reasoning in which the confirmation of one cause of an observed or believed event reduces the need to invoke alternative causes. The opposite of explaining away also can occur, in which the confirmation of one cause increases belief in another. We provide a general qualitative probabilistic analysis of intercausal reasoning, and identify the property of the interaction among the causes, product synergy, that determines which form of reasoning is appropriate. Product synergy extends the qualitative probabilistic network (QPN) formalism to support qualitative intercausal inference about the directions of change in probabilistic belief. The intercausal relation also justifies Occam's razor, facilitating pruning in search for likely diagnoses. 0 Portions of this paper originally appeared in Proceedings of the Second International Conference on Principles of Knowledge Representation and Reasoning [16]. y Supported by the National Science Foundation under grant IRI-8807061 to Carnegie Mellon and by the Rockwell International Science Center. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Hector Geffner. </author> <title> On the logic of defaults. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pages 449-454, </pages> <address> St. Paul, MN, 1988. </address> <publisher> AAAI. </publisher>
Reference-contexts: Pearl provides these conditions for the special case of linear/Gaussian models [10, page 351]. Geffner provides a probabilistic justification of explaining away in terms of *-semantics <ref> [1] </ref>. Both of these demonstrations are illustrative, but do not capture the full range of situations in which such inference is appropriate. Explaining away is an example of intercausal inference [3]|that is, reasoning between two causes with a common effect|in contrast with pure causal or pure evidential reasoning.
Reference: [2] <author> Hector Geffner. </author> <title> Causal theories for nonmonotonic reasoning. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pages 524-530, </pages> <address> Boston, MA, 1990. </address> <publisher> AAAI. </publisher>
Reference-contexts: Although inference rules implementing explaining away have been well studied <ref> [2, 9] </ref>, precise and general conditions under which this pattern is valid have not appeared in the literature. Pearl provides these conditions for the special case of linear/Gaussian models [10, page 351]. Geffner provides a probabilistic justification of explaining away in terms of *-semantics [1].
Reference: [3] <editor> Max Henrion. </editor> <booktitle> Uncertainty in artificial intelligence: </booktitle> <editor> Is probability epistemologically and heuristically adequate? In J. Mumpower et al., editors, </editor> <booktitle> Expert Judgment and Expert Systems, volume 35 of NATO ISI Series F, </booktitle> <pages> pages 105-130. </pages> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1987. </year>
Reference-contexts: This common and intuitively compelling pattern of reasoning is called explaining away, because one cause explains the observed effect and so reduces the need to invoke other causes. This qualitative pattern of reasoning is entirely compatible with Bayesian inference when probabilistic influences reflect causal relationships <ref> [3, 9] </ref>. It is also the essence of Occam's razor: slice away hypotheses that are unnecessary to account for the evidence.
Reference: [4] <author> Max Henrion. </author> <title> Some practical issues in constructing belief networks. </title> <editor> In Laveen N. Kanal, Tod S. Levitt, and John F. Lemmer, editors, </editor> <booktitle> Uncertainty in Artificial Intelligence 3. </booktitle> <publisher> North-Holland, </publisher> <address> Amsterdam, </address> <year> 1989. </year> <note> REFERENCES 15 </note>
Reference-contexts: If negative product synergy does not seem immediately compelling, one can also derive it as a generalization of the leaky noisy-or <ref> [4, 10] </ref>, a plausible model for either situation. The noisy-or dictates that each of the two causes may be sufficient alone to cause the effect, and that the causal mechanisms are independent.
Reference: [5] <author> Max Henrion. </author> <title> Search-based methods to bound diagnostic probabilities in very large belief nets. </title> <booktitle> In Proceedings of the Seventh Conference on Uncertainty in Artificial Intelligence, </booktitle> <pages> pages 142-150, </pages> <address> Los Angeles, CA, </address> <year> 1991. </year>
Reference-contexts: In one large medical diagnosis application, called qmr-bn (Quick Medical Reference-Belief Network) [13], there are almost 600 diseases, and hence 2 600 potential diagnoses. However, in most cases only a tiny fraction of these diagnoses have substantial probability. Search-based algorithms, such as TopN <ref> [5] </ref>, concentrate on the most probable hypotheses. Given the relative probabilities of the candidate diagnoses, TopN computes bounds on their absolute probabilities. The bounds may be successively narrowed as the search continues. <p> Thus, intercausal analysis provides a suitable basis for an admissibility heuristic. Because qmr-bn uniformly assumes noisy-or relations among diseases and findings, the diseases are always competitive. Initial results for this network, using this pruning criterion, show rapid convergence to narrow probability bounds in most cases <ref> [5] </ref>. The analysis described in this paper generalizes this approach to handle networks not only with noisy-or relations, as in qmr-bn, but with any interactions satisfying negative product synergy. 6 Conclusions Intercausal relations play a central role in the combination of diagnostic and predictive reasoning.
Reference: [6] <author> Max Henrion and Marek J. Druzdzel. </author> <title> Qualitative propagation and scenario-based explanation of probabilistic reasoning. </title> <editor> In Piero P. Bonissone, Max Henrion, Laveen N. Kanal, et al., editors, </editor> <booktitle> Uncertainty in Artificial Intelligence 6. </booktitle> <publisher> North-Holland, </publisher> <address> Amsterdam, </address> <year> 1991. </year>
Reference-contexts: A propositional version of Theorem 1 appears in <ref> [6] </ref>. 3 PROBABILISTIC INTERCAUSAL RELATIONS 7 Definition 2 (product synergy) Let a and b be predecessors of c in G, and let x denote an assignment to c's other predecessors, if any. <p> But qualitative probabilistic inference may be useful even for numerical systems, as a means of explanation to human users in a way that might correspond more directly to intuitive categories <ref> [6] </ref>. We also believe that it may be computationally advantageous to maintain these qualitative distinctions even when numeric information is available. As described in Section 5, intercausal relations qualitatively restrict the reasonable patterns in which to cluster events in compound hypotheses.
Reference: [7] <author> Paul R. Milgrom. </author> <title> Good news and bad news: Representation theorems and applications. </title> <journal> Bell Journal of Economics, </journal> <volume> 12 </volume> <pages> 380-391, </pages> <year> 1981. </year>
Reference-contexts: Again, a and b are causes of c. 3 In writing these ratios here and elsewhere, we assume that all conditional-probability terms are well defined and nonzero. These assumptions could be relaxed at the expense of explicatory complexity. For further discussion of these probabilistic inequalities, see <ref> [7, 15] </ref>. 3 PROBABILISTIC INTERCAUSAL RELATIONS 6 For generality, we allow that there may be other causes of c (collectively represented by x), and that a and b in turn may have causal antecedents (b's are collectively labeled y; a's do not figure in the example).
Reference: [8] <author> Eunok Paek. </author> <title> A circumscriptive theory for causal and evidential support. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pages 545-549. </pages> <publisher> AAAI, </publisher> <year> 1990. </year>
Reference-contexts: This qualitative pattern of reasoning is entirely compatible with Bayesian inference when probabilistic influences reflect causal relationships [3, 9]. It is also the essence of Occam's razor: slice away hypotheses that are unnecessary to account for the evidence. Indeed, Paek <ref> [8] </ref> applies minimization of causal justifications to realize the explaining away pattern in a circumscriptive logic. 1 By convention, uppercase letters denote propositional literals, while lowercase letters denote variables.
Reference: [9] <author> Judea Pearl. </author> <title> Embracing causality in default reasoning. </title> <journal> Artificial Intelligence, </journal> <volume> 35 </volume> <pages> 259-271, </pages> <year> 1988. </year>
Reference-contexts: 1 EXPLAINING AWAY 1 1 Explaining Away Keeping track of the dependency or causal structure among events is critical in uncertain reasoning. One fundamental reason is the inherent asymmetry between predictive (or causal) reasoning, from cause to effect, and diagnostic (or evidential) reasoning, from effect to cause. Pearl <ref> [9] </ref> clearly illustrates this asymmetry with the "sprinkler" example, depicted in Figure 1. <p> This common and intuitively compelling pattern of reasoning is called explaining away, because one cause explains the observed effect and so reduces the need to invoke other causes. This qualitative pattern of reasoning is entirely compatible with Bayesian inference when probabilistic influences reflect causal relationships <ref> [3, 9] </ref>. It is also the essence of Occam's razor: slice away hypotheses that are unnecessary to account for the evidence. <p> Thus variable a, "rain last night," can take on the value A or its negation A. 1 EXPLAINING AWAY 2 Pearl <ref> [9] </ref> uses the revealed asymmetry of inference with respect to causal direction to argue for incorporating causal relations in default reasoning schemes. Although inference rules implementing explaining away have been well studied [2, 9], precise and general conditions under which this pattern is valid have not appeared in the literature. <p> Although inference rules implementing explaining away have been well studied <ref> [2, 9] </ref>, precise and general conditions under which this pattern is valid have not appeared in the literature. Pearl provides these conditions for the special case of linear/Gaussian models [10, page 351]. Geffner provides a probabilistic justification of explaining away in terms of *-semantics [1].
Reference: [10] <author> Judea Pearl. </author> <title> Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1988. </year>
Reference-contexts: Although inference rules implementing explaining away have been well studied [2, 9], precise and general conditions under which this pattern is valid have not appeared in the literature. Pearl provides these conditions for the special case of linear/Gaussian models <ref> [10, page 351] </ref>. Geffner provides a probabilistic justification of explaining away in terms of *-semantics [1]. Both of these demonstrations are illustrative, but do not capture the full range of situations in which such inference is appropriate. <p> In a qualitative probabilistic network, variables are represented as nodes in a graph, with directed edges defining prob 2 QUALITATIVE PROBABILISTIC NETWORKS 4 abilistic relationships. As in Bayesian networks <ref> [10] </ref> and other graphical schemes, connectedness in the graph represents the dependency structure of the underlying probability distribution [11]. However, rather than specify the distribution precisely with numeric probability tables, QPNs merely constrain the conditional probabilities using qualitative influences. <p> If negative product synergy does not seem immediately compelling, one can also derive it as a generalization of the leaky noisy-or <ref> [4, 10] </ref>, a plausible model for either situation. The noisy-or dictates that each of the two causes may be sufficient alone to cause the effect, and that the causal mechanisms are independent.
Reference: [11] <author> Judea Pearl, Dan Geiger, and Thomas Verma. </author> <title> Conditional independence and its representations. </title> <journal> Kybernetika, </journal> <volume> 25 </volume> <pages> 33-44, </pages> <year> 1989. </year>
Reference-contexts: In a qualitative probabilistic network, variables are represented as nodes in a graph, with directed edges defining prob 2 QUALITATIVE PROBABILISTIC NETWORKS 4 abilistic relationships. As in Bayesian networks [10] and other graphical schemes, connectedness in the graph represents the dependency structure of the underlying probability distribution <ref> [11] </ref>. However, rather than specify the distribution precisely with numeric probability tables, QPNs merely constrain the conditional probabilities using qualitative influences. Associated with each edge is a sign, ffi 2 f+; ; 0; ?g, denoting the direction of qualitative influence between nodes.
Reference: [12] <author> Ross D. Shachter. </author> <title> Evidence absorption and propagation through evidence reversals. </title> <booktitle> In Proceedings of the Workshop on Uncertainty in Artificial Intelligence, </booktitle> <pages> pages 303-310, </pages> <address> Windsor, ON, </address> <year> 1989. </year>
Reference-contexts: To represent observation in a probabilistic network, we instantiate the observed node and modify the dependency structure in the graph so that the nodes of interest become conditional on the observation. The evidence instantiation is tantamount to reversing the links from a and b to c <ref> [12] </ref>, as shown in Figure 4b. The signs on the reversed links remain positive, indicating that observing C increases the probability of higher values of a and b.
Reference: [13] <author> M. Shwe, B. Middleton, D. E. Heckerman, et al. </author> <title> Probabilistic diagnosis using a reformulation of the Internist-1/QMR knowledge base: I. The probabilistic model and inference algorithms. </title> <booktitle> Methods of Information in Medicine, </booktitle> <volume> 30 </volume> <pages> 241-255, </pages> <year> 1991. </year>
Reference-contexts: One such approach for diagnosis is to use heuristic search to find the most probable hypotheses that can explain the observed findings. In one large medical diagnosis application, called qmr-bn (Quick Medical Reference-Belief Network) <ref> [13] </ref>, there are almost 600 diseases, and hence 2 600 potential diagnoses. However, in most cases only a tiny fraction of these diagnoses have substantial probability. Search-based algorithms, such as TopN [5], concentrate on the most probable hypotheses.
Reference: [14] <author> Michael P. Wellman. </author> <title> Formulation of Tradeoffs in Planning Under Uncertainty. </title> <publisher> Pitman, </publisher> <address> London, </address> <year> 1990. </year>
Reference: [15] <author> Michael P. Wellman. </author> <title> Fundamental concepts of qualitative probabilistic networks. </title> <journal> Artificial Intelligence, </journal> <volume> 44 </volume> <pages> 257-303, </pages> <year> 1990. </year>
Reference-contexts: Rain and sprinkling independently cause wet grass; drinking amplifies the causal relation between driving and car accidents. We formalize these concepts using the qualitative probabilistic network (QPN) representation <ref> [15] </ref>, an abstraction of Bayesian networks. The analysis of intercausal reasoning extends this formalism by introducing new qualitative characterizations of causal interactions, complementary with the existing QPN synergy relations. In the remainder of this paper, we present a formal analysis of qualitative inter-causal relations. <p> Finally, in Section 5 we present a view of Occam's razor suggested by intercausal relations. 2 Qualitative Probabilistic Networks Our analysis of intercausal inference under uncertainty is based on the QPN formalism for qualitative probabilistic reasoning <ref> [15] </ref>. In a qualitative probabilistic network, variables are represented as nodes in a graph, with directed edges defining prob 2 QUALITATIVE PROBABILISTIC NETWORKS 4 abilistic relationships. As in Bayesian networks [10] and other graphical schemes, connectedness in the graph represents the dependency structure of the underlying probability distribution [11]. <p> Again, a and b are causes of c. 3 In writing these ratios here and elsewhere, we assume that all conditional-probability terms are well defined and nonzero. These assumptions could be relaxed at the expense of explicatory complexity. For further discussion of these probabilistic inequalities, see <ref> [7, 15] </ref>. 3 PROBABILISTIC INTERCAUSAL RELATIONS 6 For generality, we allow that there may be other causes of c (collectively represented by x), and that a and b in turn may have causal antecedents (b's are collectively labeled y; a's do not figure in the example). <p> Even if we knew that the signs on the original links from a to c and b to c were positive, without further constraint the sign on this new intercausal link would be ambiguous <ref> [15] </ref>. <p> To determine the inter-causal implications of this observation, we investigate the interaction relation of a and b on e when c is factored out. This situation is depicted in Figure 5. To propagate intercausal reasoning through indirect evidence, we appeal to another synergy concept, previously introduced for QPNs <ref> [15] </ref>: Definition 3 (additive synergy) Let a and b be predecessors of c in G, and let x denote an assignment to c's other predecessors, if any.
Reference: [16] <author> Michael P. Wellman and Max Henrion. </author> <title> Qualitative intercausal relations, or Explaining "explaining away". </title> <booktitle> In Principles of Knowledge Representation and Reasoning: Proceedings of the Second International Conference, </booktitle> <pages> pages 535-546, </pages> <year> 1991. </year>
Reference-contexts: It is easy to show that the leaky noisy-or relation implies negative 4 EXTENSIONS 8 product synergy with respect to the presence of the effect, and so leads to explaining away <ref> [16] </ref>. This result generalizes straightforwardly to cases with more than two causal variables. In contrast, noisy-nor models|where causes lead to the negation of the effect|exhibit zero product synergy. Now let us reconsider examples for which explaining away does not seem to apply. <p> Although neither subsumes the other in general, when both of the individual influences of each cause on the effect 5 OCCAM'S RAZOR AND INTERCAUSAL REASONING 10 have unambiguous signs (+ or ), then there are entailment relationships between them. See <ref> [16] </ref> for a detailed exposition of these relationships. The following result establishes (for the propositional case) that evidence positively related to the effect maintains intercausal relations given some particular patterns of product and additive synergy.
References-found: 16

