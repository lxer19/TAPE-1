URL: http://www.cse.psu.edu/~ajay/mjxthesis.ps
Refering-URL: http://www.cse.psu.edu/~ajay/research.html
Root-URL: http://www.cse.psu.edu
Title: iv Table of Contents LIST OF FIGURES vi LIST OF TABLES vii Remote Paging System
Note: Chapter 3.  11  
Abstract: Chapter 1. Introduction : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 1 1.1 Case for Remote Paging . . . . . . . . . . . . . . . . . . . . . . . . . 1 1.2 Transfer Unit . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2 1.3 Access Control . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3 1.4 Subpaging Algorithms . . . . . . . . . . . . . . . . . . . . . . . . . . 3 1.5 Contributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4 1.6 Roadmap . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4 Chapter 2. Related Work : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 5 2.1 Improvements in Networks . . . . . . . . . . . . . . . . . . . . . . . . 5 2.2 User-Level Messaging Software . . . . . . . . . . . . . . . . . . . . . 6 2.3 Remote Paging . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7 2.4 Operating System Support for Fine Grain Access . . . . . . . . . . . 8 2.5 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. Arpaci, A. Dusseau, A. Vahdat, T. Anderson, and D. Patterson. </author> <title> The Interaction of Parallel and Sequential Workloads on a Network of Workstations. </title> <booktitle> In Proceedings of the 1995 ACM Sigmetrics Conference on Measurement and Modeling of Computer Systems, </booktitle> <pages> pages 267-278, </pages> <month> May </month> <year> 1995. </year>
Reference-contexts: Figure 1.1 illustrates this point by comparing the transfer times of different data sizes for Myrinet using Fast Messages and a recent disk (a Western Digital Enterprise 9.1 GB Ultra SCSI Harddrive). A recent study <ref> [1] </ref> observes that at any particular instant, a large number of machines on a network are idle. For instance, in a network of 50 workstations, around 30 2 Data Size (in bytes) 0 4 8 12 16 Transfer Time (msec) Disk and Network FM over Myrinet Disk Access Fig. 1.1.
Reference: [2] <author> M. Bern, D. Greene, and A. Raghunathan. </author> <title> Online algorithms for cache sharing. </title> <booktitle> In Proceedings of the 25th ACM Symposium on Theory of Computing, </booktitle> <pages> pages 422-429, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: None of the design issues in our remote paging system precludes the use of MU-Net as the underlying messaging platform. 7 2.3 Remote Paging Most of the early work in remote paging has used a theoretical framework for analyzing its performance. <ref> [2, 3, 5, 23] </ref>. The first implementation on this topic is by Leach et al. [16] where remote paging in the context of the Apollo domain system is described. Each machine in the network has a paging server that accepts paging requests from remote nodes.
Reference: [3] <author> D. Black and D. D. Sleator. </author> <title> Competitive algorithms for replication and migration problems. </title> <type> Technical Report CMU-CS89-201, </type> <institution> Department of Computer Science, Carnegie-Mellon University, </institution> <year> 1989. </year>
Reference-contexts: None of the design issues in our remote paging system precludes the use of MU-Net as the underlying messaging platform. 7 2.3 Remote Paging Most of the early work in remote paging has used a theoretical framework for analyzing its performance. <ref> [2, 3, 5, 23] </ref>. The first implementation on this topic is by Leach et al. [16] where remote paging in the context of the Apollo domain system is described. Each machine in the network has a paging server that accepts paging requests from remote nodes.
Reference: [4] <author> N. J. Boden, D. Cohen, R. E. Felderman A. E. Kulawik, C. L. Seitz, J. N. Seizovic, and W. Su. Myrinet: </author> <title> A gigabit-per-second local area network. </title> <journal> IEEE Micro, </journal> <volume> 15(1) </volume> <pages> 29-36, </pages> <month> February </month> <year> 1995. </year>
Reference-contexts: Until recently, the local disk has been the obvious choice for the swap device because any non-local repository has had to use a relatively slow network. However, recent advances in networking has given us high-bandwidth, switched networks such as ATM [8] and Myrinet <ref> [4] </ref>. Further, low-latency messaging layers such as Active Messages [10] and Fast Messages [17] can exploit almost the entire promised capabilities of these networks by drastically reducing software costs. <p> This system has been implemented on a SPARCsta-tion 20 platform using the Fast Messages [17] layer over Myrinet <ref> [4] </ref> for communication. The novelty of this system is that it is customizable to an application's needs in terms of the transfer unit and the remote subpaging algorithms since most of it is implemented as a user-level library. <p> We also briefly describe related work on remote paging and conclude this chapter with a discussion on implementing fine-grain access control on traditional hardware. 2.1 Improvements in Networks Recent advances in networking technology has resulted in the emergence of high-bandwidth networks such as Myrinet <ref> [4] </ref> (1.28 Gbps) and ATM [8] (155 Mbps). The network interface cards for these high-speed networks have a programmable processor apart from the traditional DMA engines for data transfer. The host CPU can thus relegate some of its work to the network interface processor to improve system throughput. <p> The network interface cards for these high-speed networks have a programmable processor apart from the traditional DMA engines for data transfer. The host CPU can thus relegate some of its work to the network interface processor to improve system throughput. Our system uses Myrinet <ref> [4] </ref> for data transfers between workstations. Myrinet is a switch-based network, and consists of point-to-point links that connect hosts and switches. A link can deliver 1.28 Gbits/sec full duplex bandwidth. Myrinet allows variable length packets and implements hardware flow control.
Reference: [5] <author> M. Chrobak, L. Larmore, N. Reingold, and J. Westbrook. </author> <title> Page migration algorithms using work functions. </title> <type> Technical Report YALE/DCS/RR-910, </type> <institution> Department of Computer Science, Yale University, </institution> <year> 1992. </year>
Reference-contexts: None of the design issues in our remote paging system precludes the use of MU-Net as the underlying messaging platform. 7 2.3 Remote Paging Most of the early work in remote paging has used a theoretical framework for analyzing its performance. <ref> [2, 3, 5, 23] </ref>. The first implementation on this topic is by Leach et al. [16] where remote paging in the context of the Apollo domain system is described. Each machine in the network has a paging server that accepts paging requests from remote nodes.
Reference: [6] <author> D. Comer and J. Griffioen. </author> <title> A new design for distributed systems: The remote memory model. </title> <booktitle> In Proceedings of the Summer 1990 USENIX Conference, </booktitle> <pages> pages 127-135, </pages> <month> June </month> <year> 1990. </year> <month> 36 </month>
Reference-contexts: Each machine in the network has a paging server that accepts paging requests from remote nodes. The system allows local users to statically restrict the amount of physical memory available to the paging server. Comer and Griffioen <ref> [6] </ref> describe a cluster model containing workstations, disk servers, and remote memory servers. The remote memory servers are dedicated machines whose memory (usually large) can be allocated to workstations with heavy paging activity. No client-to-client resource sharing occurs, except through the servers.
Reference: [7] <author> M. D. Dahlin, R. Y. Wang, T. E. Anderson, and D. A. Patterson. </author> <title> Co-operative Caching: Using remote client memory to improve file system performance. </title> <booktitle> In Proceedings of the USENIX Conference on Operating Systems Design and Implementation,, </booktitle> <pages> pages 267-280, </pages> <month> November </month> <year> 1994. </year>
Reference-contexts: They analyze the behavior of this system using a simple queuing model. Franklin et al. [15] examine the use of remote memory in a client-server DBMS system. Their system has a centralized database server containing disks for stable storage and a large memory cache. Dahlin et al. <ref> [7] </ref> evaluate several algorithms for utilizing remote memory, the best of which is called N-chance forwarding. In this scheme, when a node is about to replace 8 a page, it checks whether that page is the last copy in the cluster.
Reference: [8] <author> M. de Prycker. </author> <title> Asynchronous Transfer Mode: solution for broadband ISDN. </title> <publisher> Ellis Horword, </publisher> <address> West Sussex England, </address> <year> 1992. </year>
Reference-contexts: Until recently, the local disk has been the obvious choice for the swap device because any non-local repository has had to use a relatively slow network. However, recent advances in networking has given us high-bandwidth, switched networks such as ATM <ref> [8] </ref> and Myrinet [4]. Further, low-latency messaging layers such as Active Messages [10] and Fast Messages [17] can exploit almost the entire promised capabilities of these networks by drastically reducing software costs. <p> We also briefly describe related work on remote paging and conclude this chapter with a discussion on implementing fine-grain access control on traditional hardware. 2.1 Improvements in Networks Recent advances in networking technology has resulted in the emergence of high-bandwidth networks such as Myrinet [4] (1.28 Gbps) and ATM <ref> [8] </ref> (155 Mbps). The network interface cards for these high-speed networks have a programmable processor apart from the traditional DMA engines for data transfer. The host CPU can thus relegate some of its work to the network interface processor to improve system throughput.
Reference: [9] <author> T. Von Eicken, A. Basu, V. Buch, and W. Vogels. U-Net: </author> <title> A User-Level Network Interface for Parallel Distributed Computing. </title> <booktitle> In Proceedings of the 15th ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 40-53, </pages> <month> December </month> <year> 1995. </year>
Reference-contexts: But interfaces such as the Myrinet interface card, provide a programmable processor. This processor can execute kernel-level code that can initiate data transfers directly to and from (pre-informed) user memory. Using this principle, U-Net <ref> [9] </ref> has eliminated the kernel from the critical path to provide user-level access to the network. For our system, we have used Fast Messages [17] over Myrinet for communication. <p> The drawback though is that it does not support multiple application processes to use the network concurrently. Drawing from the ideas of U-Net <ref> [9] </ref>, an ongoing effort is the development of a messaging layer for Myrinet called MU-Net [19] that supports protected, concurrent, user-level network access for multiple application processes.
Reference: [10] <author> T. Von Eicken, D. E. Culler, S. C. Goldstein, and K. E. Schauser. </author> <title> Active Messages: A mechanism for integrated communication and computation. </title> <booktitle> In Proceedings of the 19th International Symposium on Computer Architecture, </booktitle> <pages> pages 256-266, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: However, recent advances in networking has given us high-bandwidth, switched networks such as ATM [8] and Myrinet [4]. Further, low-latency messaging layers such as Active Messages <ref> [10] </ref> and Fast Messages [17] can exploit almost the entire promised capabilities of these networks by drastically reducing software costs. As a result, it is now a lot less expensive to go out on the network and access the physical memory of another machine than accessing the local disk.
Reference: [11] <author> Schoinas et. al. </author> <title> Implementing Fine-Grain Distributed Shared Memory On Commodity SMP Workstations. </title> <type> Technical report, </type> <institution> University of Wisconsin at Madison, Department of Computer Science, </institution> <year> 1996. </year>
Reference-contexts: Our goal is to provide remote paging mechanisms on off-the-shelf workstations and networking hardware, so that they can be readily used in commonplace platforms. Hence, we do not want custom MMU hardware for implementing access control at a finer granularity. In this exercise, we use the Wisconsin Blizzard-E <ref> [11] </ref> drivers on commodity hardware, to implement access control for subpages on SPARCstation 20 platforms. These drivers modify Solaris' cacheability assumptions about memory and devices, and provide ioctl calls to the user programs to implement fine grain access control. <p> This however requires that this software be very efficient to not slow down the normal execution significantly. The second approach uses memory faults by manipulating ECC bits to implement fine-grain access on traditional hardware. The Wisconsin Blizzard-E <ref> [11] </ref> uses this technique on the Solaris 2.4 kernel running on SPARCstation 20 platforms. It extends the kernel with two loadable device drivers the Blizzard Driver (BLZSYSD) and the ECC Memory Driver (ECCMEMD). <p> However, not all traditional hardware for virtual memory can be programmed for alternate or variable transfer units. Hence, for finer-grain (smaller than a page) access control, we have to resort to other means. In this exercise, we have used the loadable driver subsystem from the Wisconsin Blizzard-E <ref> [11] </ref> that provides fine-grain access control for the SPARCstation 20 platform running the Solaris 2.4 operating system. These drivers deliberately force uncorrectable errors in the memory's error correcting code (ECC) and use virtual memory aliases in addition to implement fine-grain access control. <p> This scheme is expected to perform better than the Eager scheme under such situations since the polling time in a SIGBUS handler is likely to become lower because of the smaller number of subpages being sent. 17 3.4 Summary Our remote subpaging system uses the Wisconsin Blizzard-E <ref> [11] </ref> fine grain access control mechanism to regulate accesses to subpages. The choice of page size and the subpaging algorithm is implemented entirely at the user-level.
Reference: [12] <author> H. A. Jamrozik et.al. </author> <title> Reducing Network Latency Using subpages in a Global Memory Environment. </title> <booktitle> In Proceedings of the seventh ACM Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 258-267, </pages> <month> Octo-ber </month> <year> 1996. </year> <month> 37 </month>
Reference-contexts: Voelker, Levy, and Lazowska [22] study the benefit of using load information in global memory replacement policies. They show that global memory systems can gain substantially from load balancing requests, and suboptimal replacement decisions do not really hurt performance. Jamrozik and Levy <ref> [12] </ref> show the advantage of using subpages to improve performance in a remote-memory environment with trace-driven simulation. <p> The closest study to this work is by Jamrozik et al. <ref> [12] </ref> where the benefit of subpages to improve performance is shown via trace-driven simulation. They have validated their system by a prototype implementation on DEC Alpha workstations connected by ATM. They modify the PAL code associated with the memory system to implement fine-grain access control. <p> If the application accesses the portion of the page that is behind the faulted subpage, a SIGBUS is incurred. The motivation for this approach draws from a finding in a recent study <ref> [12] </ref> that in a subpaging system, most of the accesses to a page are in the region that is ahead of the faulted subpage with 70% of them being on the immediately next subpage in the forward direction.
Reference: [13] <author> M. J. Feeley, W. E. Morgan, F. H. Pighin, A. R. Karlin, H. M. Levy, and C. A. Thekkath. </author> <title> Implementing global memory management in a Workstation cluster. </title> <booktitle> In Proceedings of the 15th ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 201-212, </pages> <month> December </month> <year> 1995. </year>
Reference-contexts: In this scheme, when a node is about to replace 8 a page, it checks whether that page is the last copy in the cluster. If so, the page is forwarded to a randomly-picked node. Else, the page is discarded. Feeley, Levy and Thekkath <ref> [13] </ref> examine a global memory management issues in a workstation cluster. Their objective is to use a single, unified, but distributed memory management algorithm at the lowest level of the operating system.
Reference: [14] <author> E. W. Felten and J. Zahorjan. </author> <title> Issues in the implementation of a remote memory paging system. </title> <type> Technical Report 91-03-09, </type> <institution> Department of Computer Science and Engineering, University of Washington, </institution> <month> March </month> <year> 1991. </year>
Reference-contexts: Comer and Griffioen [6] describe a cluster model containing workstations, disk servers, and remote memory servers. The remote memory servers are dedicated machines whose memory (usually large) can be allocated to workstations with heavy paging activity. No client-to-client resource sharing occurs, except through the servers. Felten and Zahorjan <ref> [14] </ref> generalize this idea to use memory on idle client machines for backing store. When a machine becomes idle, its kernel activates an otherwise dormant memory server, which registers itself for remote use.
Reference: [15] <author> M. J. Franklin, M. J. Carey, and M. Livny. </author> <title> Global memory management in client-server DBMS architectures. </title> <booktitle> In Proceedings of the 18th VLDB Conference, </booktitle> <pages> pages 596-609, </pages> <month> August </month> <year> 1992. </year>
Reference-contexts: Whenever a kernel replaces a page, it queries a central registry to locate active memory servers, picking one at random to receive this victim page. They analyze the behavior of this system using a simple queuing model. Franklin et al. <ref> [15] </ref> examine the use of remote memory in a client-server DBMS system. Their system has a centralized database server containing disks for stable storage and a large memory cache. Dahlin et al. [7] evaluate several algorithms for utilizing remote memory, the best of which is called N-chance forwarding.
Reference: [16] <author> P. J. Leach, P. H. Levine, B. P. Douros, J. A. Hamilton, D. L. Nelson, and B. L. Stumpf. </author> <title> The architecture of an integrated local network. </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> 1(5) </volume> <pages> 842-857, </pages> <month> November </month> <year> 1983. </year>
Reference-contexts: The first implementation on this topic is by Leach et al. <ref> [16] </ref> where remote paging in the context of the Apollo domain system is described. Each machine in the network has a paging server that accepts paging requests from remote nodes. The system allows local users to statically restrict the amount of physical memory available to the paging server.
Reference: [17] <author> S. Pakin, M. Lauria, and A. Chien. </author> <title> High Performance Messaging on Workstations: Illinois Fast Messages (FM) for Myrinet. </title> <booktitle> In Supercomputing '95, </booktitle> <year> 1995. </year>
Reference-contexts: However, recent advances in networking has given us high-bandwidth, switched networks such as ATM [8] and Myrinet [4]. Further, low-latency messaging layers such as Active Messages [10] and Fast Messages <ref> [17] </ref> can exploit almost the entire promised capabilities of these networks by drastically reducing software costs. As a result, it is now a lot less expensive to go out on the network and access the physical memory of another machine than accessing the local disk. <p> This system has been implemented on a SPARCsta-tion 20 platform using the Fast Messages <ref> [17] </ref> layer over Myrinet [4] for communication. The novelty of this system is that it is customizable to an application's needs in terms of the transfer unit and the remote subpaging algorithms since most of it is implemented as a user-level library. <p> This processor can execute kernel-level code that can initiate data transfers directly to and from (pre-informed) user memory. Using this principle, U-Net [9] has eliminated the kernel from the critical path to provide user-level access to the network. For our system, we have used Fast Messages <ref> [17] </ref> over Myrinet for communication. Currently, this provides the most efficient messaging library for Myrinet giving one way latencies as low as 11 usecs (for 8 byte messages) and bandwidths as high as 30 MBps. <p> ? Can we offer the applications the flexibility to choose from a menu of subpaging algorithms and allow these applications to coexist ? To investigate these issues, we have developed a remote subpaging system on SPARCstation 20 platforms connected by Myrinet employing a user-level, low-latency, high-bandwidth messaging layer (Fast Messages <ref> [17] </ref>). In this thesis, we specifically concentrate on issues in implementing the remote paging system at the machine where the application is executing, which we shall call the client, and use a simple server to store and retrieve these pages at the remote machine.
Reference: [18] <author> D. J. Scales, K. Gharachorloo, and C. A. Thekkath. </author> <title> Shasta: A Low Overhead, Software-Only Approach for Supporting Fine-Grain Shared Memory. </title> <booktitle> In Seventh International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 174-185, </pages> <month> November </month> <year> 1996. </year>
Reference-contexts: These drivers modify Solaris' cacheability assumptions about memory and devices, and provide ioctl calls to the user programs to implement fine grain access control. We have chosen this approach over the all-software Shasta <ref> [18] </ref> approach. 1.4 Subpaging Algorithms If the underlying system's page size cannot be altered, physical memory allocation has to be still done on the traditional page basis and not on a subpage basis (or else, adjacent virtual pages may not necessarily be physically adjacent). <p> However, this hardware may not necessarily support customizable page sizes. There have been two ways of 9 controlling access at a finer granularity. First, as in the Shasta <ref> [18] </ref> system, the control can be implemented in software at each memory reference. This however requires that this software be very efficient to not slow down the normal execution significantly. The second approach uses memory faults by manipulating ECC bits to implement fine-grain access on traditional hardware.
Reference: [19] <author> D. N. </author> <title> Seed. MU-Net: Protected User-Level Messaging for Myrinet. </title> <type> Master's thesis, </type> <institution> Penn State University, </institution> <month> May </month> <year> 1997. </year> <month> 38 </month>
Reference-contexts: The drawback though is that it does not support multiple application processes to use the network concurrently. Drawing from the ideas of U-Net [9], an ongoing effort is the development of a messaging layer for Myrinet called MU-Net <ref> [19] </ref> that supports protected, concurrent, user-level network access for multiple application processes. <p> With the current implementation of Fast Messages for Myrinet on Solaris, we are limited to a single application process per node. Recently, a protected multi-user messaging layer for SPARCstations on Myrinet called MU-Net <ref> [19] </ref> has been developed, to which this system can be moved. This would help evaluate the subpaging system with multiple applications executing concurrently. 35
Reference: [20] <institution> The Spec92 Benchmark Suite, </institution> <note> Release 1.1 , 1992. </note>
Reference-contexts: First, we examine the time spent in the different components of the system using microbenchmarks. Next, we evaluate its performance using traces from three of the Spec92 <ref> [20] </ref> benchmarks with different subpage sizes and subpaging schemes. Finally, we look at how an actual Quicksort application performs with different subpage sizes and subpaging algorithms. <p> These operations may seem expensive but they are still cheaper than the disk accesses shown in Figure 1.1. 4.2 Experiments with Traces In this section, we evaluate the performance of the subpaging system by using three traces from the Spec92 benchmarks suite <ref> [20] </ref> namely gcc, compress, and espresso, which exhibit different memory access patterns. We have used data traces with at least 20 Subpage Size (in bytes) 0 2 4 Time (x 100 usecs) Set Subpage Valid Remote Subpage Fetch Fig. 4.1.
Reference: [21] <author> M. Talluri and M. D. Hill. </author> <title> Surpassing the TLB performance of superpages with less operating system support. </title> <booktitle> In Proceedings of the 6th Int. Conf. on Arch. Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 171-182, </pages> <month> October </month> <year> 1994. </year>
Reference-contexts: While it may appear to the reader that a 11% saving in execution time is not very significant, we should note that page sizes on machines are likely to get larger (to improve TLB coverage <ref> [21] </ref> as the 31 physical memory on the machines keeps growing). <p> savings in execution time even at the optimal size are seen to be better by not more than 15% compared to that at fullpage size among the applications that we have seen, we should note that page sizes on machines are likely to get larger 33 to improve TLB coverage <ref> [21] </ref> as the physical memory on the machines keeps growing. Hence, transfer units smaller than a page over the network will become even more important with this trend.
Reference: [22] <author> G. Voelker, H. Jamrozik, M. Vernon, H. Levy, and E. Lazowska. </author> <title> Managing Server Load in Global Memory Systems. </title> <booktitle> In Proceedings of the 1997 ACM Sigmetrics Conference on Performance Measurement, Modeling, and Evaluation, </booktitle> <pages> pages 127-136, </pages> <month> June </month> <year> 1997. </year>
Reference-contexts: The implementation has been done on a cluster of DEC Alpha workstations connected by ATM and running OSF/1. They show a 150-350% improvement in performance with this system for a suite of memory-intensive programs. Voelker, Levy, and Lazowska <ref> [22] </ref> study the benefit of using load information in global memory replacement policies. They show that global memory systems can gain substantially from load balancing requests, and suboptimal replacement decisions do not really hurt performance.
Reference: [23] <author> J. Westbrook. </author> <title> Randomized algorithms for multiprocessor page migration. </title> <booktitle> DIMACS Series in Discrete Mathematics and Theoretical Computer Science, </booktitle> <volume> 7, </volume> <year> 1992. </year>
Reference-contexts: None of the design issues in our remote paging system precludes the use of MU-Net as the underlying messaging platform. 7 2.3 Remote Paging Most of the early work in remote paging has used a theoretical framework for analyzing its performance. <ref> [2, 3, 5, 23] </ref>. The first implementation on this topic is by Leach et al. [16] where remote paging in the context of the Apollo domain system is described. Each machine in the network has a paging server that accepts paging requests from remote nodes.
References-found: 23

