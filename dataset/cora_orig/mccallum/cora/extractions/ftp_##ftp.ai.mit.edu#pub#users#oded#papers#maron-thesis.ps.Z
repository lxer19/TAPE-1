URL: ftp://ftp.ai.mit.edu/pub/users/oded/papers/maron-thesis.ps.Z
Refering-URL: http://www.ai.mit.edu/people/oded/
Root-URL: 
Title: Learning from Ambiguity  
Author: by Oded Maron Tomas Lozano-Perez Cecil H. Green Arthur C. Smith 
Degree: (1994) Submitted to the Department of Electrical Engineering and Computer Science in partial fulfillment of the requirements for the degree of Doctor of Philosophy at the  All rights reserved. Author  Certified by  Professor of Computer Science and Engineering Thesis Supervisor Accepted by  Chairman, Departmental Committee on Graduate Students  
Date: June 1998  May 20, 1998  
Address: (1992)  
Affiliation: Sc.B., Brown University  M.S., Massachusetts Institute of Technology  MASSACHUSETTS INSTITUTE OF TECHNOLOGY  c Massachusetts Institute of Technology 1998.  Department of Electrical Engineering and Computer Science  
Abstract-found: 0
Intro-found: 1
Reference: [ Atkeson et al., 1997 ] <author> C. G. Atkeson, A. W. Moore, and S. A. Schaal. </author> <title> Locally weighted learning. </title> <editor> In David W. Aha, editor, </editor> <title> Lazy Learning. </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1997. </year>
Reference-contexts: Because the noise is usually Gaussian, most algorithms assume that with enough examples, the noise can be washed out. Other algorithms take a more proactive approach; for example, k-Nearest-Neighbor and other such variants <ref> [ Atkeson et al., 1997 ] </ref> smooth out noise through voting schemes. [ Kearns and Vazirani, 1994 ] show that PAC-learning from noisy examples can be reduced to the standard PAC model. [ Norton, 1994 ] shows that ambiguity can arise not only from an uncertain example, but also from an
Reference: [ Auer et al., 1996 ] <author> Peter Auer, Phil M. Long, and A. Srinivasan. </author> <title> Approximating hyper-rectangles: learning and pseudorandom sets. </title> <booktitle> In Proceedings of the 1996 Conference on Computational Learning Theory, </booktitle> <year> 1996. </year>
Reference-contexts: In addition, there are 200 instances per bag in the experiments of Figure 2-8, making it a harder task. The other development was less fortunate: <ref> [ Auer et al., 1996 ] </ref> showed that Long and Tan's independence assumption is necessary for any efficiently PAC-learnable algorithm. Specifically, they showed that if there is an algorithm to efficiently PAC-learn from multiple-instance examples that are distributed arbitrarily, then it is also possible to efficiently PAC-learn DNF formulas. <p> However, in most cases examined in this thesis, maxDD found the best concept or one which performed well. 7.1.1 Overview of the MULTINST algorithm We describe a simplified version of the MULTINST algorithm, based on <ref> [ Auer et al., 1996 ] </ref> . We assume there is a distribution D over a d-dimensional feature space. Every instance is drawn independently from D. Each contains exactly r instances, and is labeled positive if at least one of the instances falls within the target APR.
Reference: [ Auer, 1997 ] <author> Peter Auer. </author> <title> On learning from multi-instance examples: Empirical evalu-taion of a theoretical approach. </title> <booktitle> In Proceedings of the 14th International Conference on Machine Learning, </booktitle> <year> 1997. </year>
Reference-contexts: Results of various algorithms on the MUSK datasets are presented in Table 4.2. The results of the APR algorithms, backpropagation, and C4.5 are taken from [ Diet-terich et al., 1997 ] . The results of the MULTINST algorithm are taken from <ref> [ Auer, 1997 ] </ref> . Backpropagation and C4.5 are popular supervised learning algorithms which use a neural network and a decision tree, respectively, to represent the learned concept. <p> Auer, Long, and their colleagues soon published two interesting developments. <ref> [ Auer, 1997 ] </ref> gave a new algorithm that improved on Long and Tan's bounds and did not require the features to be independent. <p> performs well on many types of ambiguity, or will we continue to fill in the ambiguity spectrum of Figure 1-1 in a piecemeal fashion? * Another question for future investigation is whether we can learn more complicated hypothesis classes than hyper-rectangles (as in [ Dietterich et al., 1997 ] and <ref> [ Auer, 1997 ] </ref> ) or points with scaled features (as in this work).
Reference: [ Bach et al., 1996 ] <author> J.R. Bach, C.Fuller, A. Gupta, A. Hampapur, B. Horowitz, R. Humphrey, R.C. Jain, and C. Shu. </author> <title> Virage image search engine: an open framework for image management. </title> <booktitle> In Symposium on Electronic Imaging: Science and Technology Storage and Retrieval of Image and Video Databases, </booktitle> <volume> volume 4, </volume> <pages> pages 76-87, </pages> <year> 1996. </year>
Reference: [ Bell and Sejnowski, 1995 ] <author> A. Bell and T. Sejnowski. </author> <title> An information-maximization approach to blind source seperation and blind deconvolution. </title> <journal> Neural Computation, </journal> <volume> 7 </volume> <pages> 1129-1159, </pages> <year> 1995. </year>
Reference-contexts: The algorithm attempts to learn the structure of the underlying source of the examples. Some instances of unsupervised learning are clustering [ Cheeseman et al., 1988 ] , Principal Component Analysis [ Chatfield and Collins, 1980 ] , and Independent Component Analysis <ref> [ Bell and Sejnowski, 1995, Comon, 1994 ] </ref> . In Reinforcement Learning the goal is to learn a policy, which is a mapping from states to actions. Examples are not labeled with the correct action; instead an occasional reinforcement signal which denotes the utility of some state is received.
Reference: [ Belongie et al., 1998 ] <author> S. Belongie, C. Carson, H. Greenspan, and J. Malik. </author> <title> Color-and texture based image segmentation using em and its application to content-based image retrieval. </title> <booktitle> In International Conference on Computer Vision, </booktitle> <year> 1998. </year> <month> 114 </month>
Reference: [ Blum and Kalai, 1998 ] <author> A. Blum and A. Kalai. </author> <title> A note on learning from multiple--instance examples. </title> <note> To appear in Machine Learning, </note> <year> 1998. </year>
Reference-contexts: Specifically, they showed that if there is an algorithm to efficiently PAC-learn from multiple-instance examples that are distributed arbitrarily, then it is also possible to efficiently PAC-learn DNF formulas. It is generally assumed that PAC-learning DNF formulas is hard. <ref> [ Blum and Kalai, 1998 ] </ref> affirm Auer's proofs. In addition, they show that learning from multiple-instance examples can be reduced to learning with one-sided noise, two-sided noise, and learning in the statistical query model [ Kearns and Vazirani, 1994 ] .
Reference: [ Buchanan and Mitchell, 1978 ] <author> B. G. Buchanan and T. M. Mitchell. </author> <title> Model-directed learning of production rules. </title> <editor> In D. A. Waterman and F. Hayes-Roth, editors, </editor> <title> Pattern-Directed Inference Systems. </title> <publisher> Academic Press, </publisher> <year> 1978. </year>
Reference-contexts: It estimates the density of instances along each feature of the APR, and expands the bounds of the APR so that the estimated probability of excluding a positive instance is *. Although Multiple-Instance problems have been encountered before (for example, in Meta-Dendral <ref> [ Buchanan and Mitchell, 1978 ] </ref> ), they were transformed into a traditional supervised learning problem. Dietterich et al.'s paper is important because it was the first to give an algorithm specifically for learning from Multiple-Instance examples, and also because it achieved impressive results on the musk data set. <p> This is an ambiguous learning problem because a labeled example (DFA) represents a variety of different strings. Unfortunately, Cohen shows that it is hard to PAC-learn from these examples, even if the alphabet size is limited to three characters. The Meta-DENDRAL program <ref> [ Buchanan and Mitchell, 1978 ] </ref> receives training pairs of molecules and their mass-abundance curve. Its goal is to learn how molecules disintegrate during mass-spectrometry | which bonds are broken and which atoms migrate.
Reference: [ Chatfield and Collins, 1980 ] <author> Christopher Chatfield and Alexander J. Collins. </author> <title> Introduction to Multivariate Analysis. </title> <publisher> Chapman and Hall, </publisher> <year> 1980. </year>
Reference-contexts: In unsupervised learning, the examples are not labeled. The algorithm attempts to learn the structure of the underlying source of the examples. Some instances of unsupervised learning are clustering [ Cheeseman et al., 1988 ] , Principal Component Analysis <ref> [ Chatfield and Collins, 1980 ] </ref> , and Independent Component Analysis [ Bell and Sejnowski, 1995, Comon, 1994 ] . In Reinforcement Learning the goal is to learn a policy, which is a mapping from states to actions.
Reference: [ Cheeseman et al., 1988 ] <author> Peter Cheeseman, James Kelly, Matthew Self, John Stutz, Will Taylor, and Don Freeman. </author> <title> Autoclass: A bayesian classification system. </title> <booktitle> In Proceedings of the Fifth International Workshop on Machine Learning. </booktitle> <publisher> Morgan Kaufmann, </publisher> <year> 1988. </year>
Reference-contexts: In unsupervised learning, the examples are not labeled. The algorithm attempts to learn the structure of the underlying source of the examples. Some instances of unsupervised learning are clustering <ref> [ Cheeseman et al., 1988 ] </ref> , Principal Component Analysis [ Chatfield and Collins, 1980 ] , and Independent Component Analysis [ Bell and Sejnowski, 1995, Comon, 1994 ] . In Reinforcement Learning the goal is to learn a policy, which is a mapping from states to actions.
Reference: [ Cohen, 1996 ] <author> William W. Cohen. </author> <title> The dual dfa learning problem: Hardness results for programming by demonstration and learning first-order representations. </title> <booktitle> In Proceedings of the 1996 Conference on Computational Learning Theory, </booktitle> <year> 1996. </year>
Reference-contexts: As would be expected, local maxima present a major difficulty for the algorithm. A classic Machine Learning problem is learning a Deterministic Finite-State Automata (DFA) from a series of strings which are labeled according to whether they are accepted by the DFA or not. <ref> [ Cohen, 1996 ] </ref> examines the dual of this problem: given a sequence of DFAs, each labeled positive or negative, find a string that is accepted by positive examples and not by negative ones.
Reference: [ Comon, 1994 ] <author> P. Comon. </author> <title> Independent component analysis, a new concept? Signal Processing, </title> <booktitle> 36 </booktitle> <pages> 287-314, </pages> <year> 1994. </year>
Reference-contexts: The algorithm attempts to learn the structure of the underlying source of the examples. Some instances of unsupervised learning are clustering [ Cheeseman et al., 1988 ] , Principal Component Analysis [ Chatfield and Collins, 1980 ] , and Independent Component Analysis <ref> [ Bell and Sejnowski, 1995, Comon, 1994 ] </ref> . In Reinforcement Learning the goal is to learn a policy, which is a mapping from states to actions. Examples are not labeled with the correct action; instead an occasional reinforcement signal which denotes the utility of some state is received.
Reference: [ Dammkoehler et al., 1989 ] <author> R. A. Dammkoehler, S. F. Karasek, E. F. B. Shands, and G. R. Marshall. </author> <title> Constrained search of conformational hyperspace. </title> <journal> Journal of Computer-Aided Molecular Design, </journal> <volume> 3 </volume> <pages> 3-21, </pages> <year> 1989. </year>
Reference-contexts: Without such an alignment, the number of instances per bag increases dramatically because each conformation must be represented in every orientation and with varying ray centers. In that case, a preferable representation would be an orientation-independent one, such as the pharmacophore model of <ref> [ Dammkoehler et al., 1989 ] </ref> or [ Leach, 1996 ] . Another possible representation would be to place many ray-centers throughout 3D space, with only one ray coming out of each one.
Reference: [ Dasarathy, 1991 ] <author> B. V. Dasarathy. </author> <title> Nearest Neighbor Norms: NN Patern Classifac-tion Techniques. </title> <publisher> IEEE Computer Society Press, </publisher> <year> 1991. </year>
Reference-contexts: The label can 11 be a class, in which case the learning task is called classification, or a continuous signal, in which case the task is called regression. Some concept representations used to learn from labeled examples include decision trees [ Quinlan, 1992 ] , nearest neighbor <ref> [ Dasarathy, 1991 ] </ref> , neural networks [ Rumelhart et al., 1986 ] , and Bayesian networks [ Pearl, 1988 ] . In unsupervised learning, the examples are not labeled. The algorithm attempts to learn the structure of the underlying source of the examples.
Reference: [ Dayan and Zemel, 1995 ] <author> Peter Dayan and Richard S. Zemel. </author> <title> Competition and multiple cause models. </title> <journal> Neural Computation, </journal> <volume> 7 </volume> <pages> 565-579, </pages> <year> 1995. </year>
Reference-contexts: The lesson to be learned from this example is that without problem-specific knowledge one cannot afford to treat any instance as an outlier. One example of using domain knowledge to create a better evidence combination function occurs in [ Keeler et al., 1991a ] and <ref> [ Dayan and Zemel, 1995 ] </ref> . Unlike the noisy-or model, which assumes that there is at least one cause, they assume that there is exactly one cause. <p> In [ Keeler et al., 1991b ] , they show that the assumption can be relaxed by using noisy-or to combine evidence (as in Chapter 2 and [ Saund, 1995 ] ). In a different context, <ref> [ Dayan and Zemel, 1995 ] </ref> show that both summation of likelihood ratios and noisy-or can be suitable models of combining evidence.
Reference: [ Decatur, 1994 ] <author> Scott Decatur. </author> <title> Statistical queries and faulty pac oracles. </title> <booktitle> In Proceeding of the Sixth Annual ACM Workshop on Computational Learning Theory, </booktitle> <pages> pages 262-268. </pages> <publisher> ACM Press, </publisher> <month> July </month> <year> 1994. </year> <month> 115 </month>
Reference-contexts: The noise is added either to the value of the label or to the features used to describe the example. Normally, it is assumed that the noise is Gaussian. However, models where the noise is brought about by a malicious adversary have also been explored <ref> [ Decatur, 1994 ] </ref> . Because the noise is usually Gaussian, most algorithms assume that with enough examples, the noise can be washed out.
Reference: [ Dietterich et al., 1994 ] <author> T. G. Dietterich, A. Jain, R. Lathrop, and T. Lozano-Perez. </author> <title> A comparison of dynamic reposing and tangent distance for drug activity prediction. </title> <booktitle> In Advances in Neural Information Processing Systems 6. </booktitle> <publisher> Morgan Kauffman, </publisher> <year> 1994. </year>
Reference-contexts: Run PWDD using the best scaling vector. * Find the scaling vector c s that maximizes the following quantity: max fmax j ij )gg This requires only one gradient based optimization, but the number of local maxima can be high. * Perform a two-step optimization process similar to dynamic reposing <ref> [ Dietterich et al., 1994 ] </ref> . Pick an initial scaling, and find instances with high Diverse Density. Find a scaling (by maxDD, for example) to optimize the Diverse Density of all of them. Use this scaling to find instances with high Diverse Density, and repeat. <p> The other main difference is that the ISR 100 architecture forces the bag generator to be part of the learning mechanism of the network, while we construct the learner and bag generator separately. Dynamic reposing <ref> [ Jain et al., 1994, Dietterich et al., 1994 ] </ref> is an algorithm for handling examples that are ambiguous both in pose (like TDNN and ISR) and in containing multiple instances. It was applied to drug discovery problems as described in Chapter 4.
Reference: [ Dietterich et al., 1997 ] <author> T. G. Dietterich, R. H. Lathrop, and T. Lozano-Perez. </author> <title> Solving the multiple-instance problem with axis-parallel rectangles. </title> <journal> Artificial Intelligence Journal, </journal> <volume> 89, </volume> <year> 1997. </year>
Reference-contexts: There are many possible ways of describing a conformation (instance). In this thesis, we use a ray-representation <ref> [ Jain et al., 1994, Dietterich et al., 1997 ] </ref> for a conformation. From a central point in the molecule, k rays are drawn out uniformly in three dimensions. Each ray is extended until it hits the surface of the molecule. <p> The first paper to state and name the Multiple-Instance framework was <ref> [ Dietterich et al., 1997 ] </ref> . This paper was concerned with developing an algorithm to tackle the drug discovery problem. Our setup of the drug discovery problem, namely the ray representation of molecular shape, is taken from that paper. <p> Is there some unifying learning algorithm that performs well on many types of ambiguity, or will we continue to fill in the ambiguity spectrum of Figure 1-1 in a piecemeal fashion? * Another question for future investigation is whether we can learn more complicated hypothesis classes than hyper-rectangles (as in <ref> [ Dietterich et al., 1997 ] </ref> and [ Auer, 1997 ] ) or points with scaled features (as in this work).
Reference: [ Flickner et al., 1995 ] <author> M. Flickner, Harpreet S. Sawhney, Jonathan Ashley, Qian Huang, Byron Dom, Monika Gorkani, Jim Hafner, Denis Lee, Dragutin Petkovic, David Steele, and Peter Yanker. </author> <title> Query by image and video content: The qbic system. </title> <journal> IEEE Computer, </journal> <volume> 28 </volume> <pages> 23-32, </pages> <year> 1995. </year>
Reference-contexts: Many of the existing image-querying systems work on entire images or in user-specified regions by using distribution of color, texture and structural properties. The QBIC system <ref> [ Flickner et al., 1995 ] </ref> and the Virage system [ Bach et 1 This chapter describes joint work with Aparna Lakshmi Ratan [ Maron and Lakshmi Ratan, 1998 ] . al., 1996 ] are examples of such systems.
Reference: [ Girosi et al., 1995 ] <author> F. Girosi, M. Jones, and T. Poggio. </author> <title> Regularization theory and neural networks architectures. </title> <journal> Neural Computation, </journal> <volume> 7 </volume> <pages> 219-269, </pages> <year> 1995. </year>
Reference-contexts: This gives us a natural bias toward simpler concepts (i.e., concepts that use fewer features). Normally, Machine Learning algorithms need to add a regularizing term (e.g., [ Rissanen, 1978 ] , <ref> [ Girosi et al., 1995 ] </ref> ) to prevent overfitting with an overly complicated concept. 3.1.3 Learning disjunctive concepts There is no conceptual difference between learning a single point-and-scaling concept and learning a disjunction of d of them.
Reference: [ Hirsh, 1990 ] <author> Haym Hirsh. </author> <title> Incremental version-space merging: a general framework for concept learning. </title> <publisher> Kluwer Academic, </publisher> <year> 1990. </year>
Reference-contexts: Therefore, each example agrees with many different 99 structures. Norton uses background knowledge to assign probabilities to structures, combines the evidence from the training example, and picks the most likely concept. Norton's work is an outgrowth of Hirsh's bounded inconsistency learner <ref> [ Hirsh, 1990 ] </ref> . The bounded inconsistency model assumes that every example is made up of some true source example corrupted by a noise model.
Reference: [ Huang et al., 1997 ] <author> J. Huang, S. Ravikumar, M. Mitra, W. Zhu, and R. Zabih. </author> <title> Image indexing using color correlograms. </title> <booktitle> In Computer Vision and Pattern Recognition, </booktitle> <year> 1997. </year>
Reference: [ Husbands and Isbell, 1998 ] <author> P. Husbands and C. Isbell. </author> <title> The parallel problems server: A client-server model for large scale scientific computation. </title> <booktitle> In Proceedings of the Third International Conference on Vector and Parallel Processing, </booktitle> <year> 1998. </year>
Reference-contexts: If the distance metric changes (as it does when learning 54 with point-and-scaling concept class), the expensive operation of recalculation must be performed on the tree. A more promising avenue is the parallelization of the Diverse Density calculation. Using the Parallel Problem Server <ref> [ Husbands and Isbell, 1998 ] </ref> , a parallel implementation of maxDD and PWDD is being developed for document retrieval applications similar to the image database application described in Chapter 6. 55 Chapter 4 An application to drug discovery In the following three chapters, we discuss applications of Multiple-Instance learning and
Reference: [ Jain et al., 1994 ] <author> A. N. Jain, T. G. Dietterich, R. H. Lathrop, D. Chapman, R. E. Critchlow Jr., B. E. Bauer, T. A. Webster, and T. Lozano-Perez. </author> <title> Compass: A shape-based machine learning tool for drug design. </title> <journal> Journal of Computer-Aided Molecular Design, </journal> <volume> 8 </volume> <pages> 635-652, </pages> <year> 1994. </year>
Reference-contexts: In addition, conformations whose energy is higher than some bound over the global energy minimum are not sampled at all <ref> [ Jain et al., 1994 ] </ref> . The bound is chosen so as to accept conformations which may be energetically reachable on binding. above, either the conformation (s) corresponding to the one global minimum or to all three local minima would be picked as viable conformations. <p> There are many possible ways of describing a conformation (instance). In this thesis, we use a ray-representation <ref> [ Jain et al., 1994, Dietterich et al., 1997 ] </ref> for a conformation. From a central point in the molecule, k rays are drawn out uniformly in three dimensions. Each ray is extended until it hits the surface of the molecule. <p> Each conformation is represented by 162 rays, along with four additional features that specify the location of a unique oxygen atom common to all the molecules, for a total of 166 features. All molecules have been roughly aligned using the COMPASS program <ref> [ Jain et al., 1994 ] </ref> . 4.4 Experiments We ran maxDD, optimizing both location and feature weights (using the point-and-scaling concept class), on MUSK1 and MUSK2. To measure the generalizing capability of the learned concept, we perform several iterations of 10-fold cross validation. <p> The other main difference is that the ISR 100 architecture forces the bag generator to be part of the learning mechanism of the network, while we construct the learner and bag generator separately. Dynamic reposing <ref> [ Jain et al., 1994, Dietterich et al., 1994 ] </ref> is an algorithm for handling examples that are ambiguous both in pose (like TDNN and ISR) and in containing multiple instances. It was applied to drug discovery problems as described in Chapter 4.
Reference: [ Kaelbling et al., 1996 ] <author> L. P. Kaelbling, M. L. Littman, and A. W. Moore. </author> <title> Reinforcement learning: A survey. </title> <journal> Journal of Artificial Intelligence Research, </journal> <volume> 4, </volume> <year> 1996. </year> <month> 116 </month>
Reference-contexts: Examples are not labeled with the correct action; instead an occasional reinforcement signal which denotes the utility of some state is received. Reinforcement Learning methods are reviewed in [ Sutton and Barto, 1998 ] and <ref> [ Kaelbling et al., 1996 ] </ref> . One way to relate these three frameworks is to look at the ambiguity of the training examples by determining how much information the label of an example conveys. In supervised learning, every example is perfectly labeled, so there is no ambiguity. <p> Multiple-Instance learning falls in the middle 98 of the spectrum, as does Reinforcement Learning <ref> [ Sutton and Barto, 1998, Kaelbling et al., 1996 ] </ref> . In Reinforcement Learning, the teacher (or the world) provides an occasional reinforcement signal, but the specific value of being at some state (or which action to take) is usually not given.
Reference: [ Kauer, 1991 ] <author> J. S. Kauer. </author> <title> Contributions of topography and parallel processing to odor coding in the vertebrate olfactory pathway. </title> <booktitle> Trends in Neurosciences, </booktitle> <volume> 14(2) </volume> <pages> 79-85, </pages> <year> 1991. </year>
Reference-contexts: We would like to learn what shape makes a molecule musky (allows us to smell it). 2 The nose senses smells through a combination of receptors <ref> [ Kauer, 1991 ] </ref> , but for these purposes, this is a reasonable approximation. 60 data number number number average number set of bags positive negative instances per bag MUSK1 92 47 45 5.17 MUSK2 102 39 63 64.69 Table 4.1: Summary descriptions of the two MUSK datasets.
Reference: [ Kearns and Vazirani, 1994 ] <author> Michael J. Kearns and Umesh V. Vazirani. </author> <title> An Introduction to Computational Learning Theory. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1994. </year>
Reference-contexts: It is generally assumed that PAC-learning DNF formulas is hard. [ Blum and Kalai, 1998 ] affirm Auer's proofs. In addition, they show that learning from multiple-instance examples can be reduced to learning with one-sided noise, two-sided noise, and learning in the statistical query model <ref> [ Kearns and Vazirani, 1994 ] </ref> . They also slightly improve Auer et al.'s sample bounds to ~ O ( d 2 n * 2 ) 1 . <p> Because the noise is usually Gaussian, most algorithms assume that with enough examples, the noise can be washed out. Other algorithms take a more proactive approach; for example, k-Nearest-Neighbor and other such variants [ Atkeson et al., 1997 ] smooth out noise through voting schemes. <ref> [ Kearns and Vazirani, 1994 ] </ref> show that PAC-learning from noisy examples can be reduced to the standard PAC model. [ Norton, 1994 ] shows that ambiguity can arise not only from an uncertain example, but also from an uncertain representation. Norton attempts to learn DNA promoter sequences from examples.
Reference: [ Keeler et al., 1991a ] <author> James D. Keeler, David E. Rumelhart, and Wee-Kheng Leow. </author> <title> Integrated segmentation and recognition of hand-printed numerals. </title> <booktitle> In Advances in Neural Information Processing Systems 3. </booktitle> <publisher> Morgan Kauffman, </publisher> <year> 1991. </year>
Reference-contexts: The lesson to be learned from this example is that without problem-specific knowledge one cannot afford to treat any instance as an outlier. One example of using domain knowledge to create a better evidence combination function occurs in <ref> [ Keeler et al., 1991a ] </ref> and [ Dayan and Zemel, 1995 ] . Unlike the noisy-or model, which assumes that there is at least one cause, they assume that there is exactly one cause. <p> Each example is labeled, but it is not known when the speaker begins uttering the letter and for how long the enunciation lasts. If these details were known about each example, then the learning task would be simple. An extension of TDNN is the Integrated Segmentation and Recognition system <ref> [ Keeler et al., 1991a ] </ref> . The ISR network is given an image with one or more handwritten characters, a label that identifies the characters that appear, but not the pose or location of the characters. This is similar to the image database retrieval problem addressed in Chapter 6.
Reference: [ Keeler et al., 1991b ] <author> James D. Keeler, David E. Rumelhart, and Wee-Kheng Leow. </author> <title> Integrated segmentation and recognition of hand-printed numerals. </title> <type> Technical report, MCC Technical Report ACT-NN-010-91, </type> <year> 1991. </year>
Reference-contexts: First, they assume that there is only one occurrence of each type of character in the image, whereas there is no such limitation in the Multiple-Instance learning framework. This assumption leads to their method of combining evidence through a summation of likelihood ratios (as discussed in Section 2.3.2). In <ref> [ Keeler et al., 1991b ] </ref> , they show that the assumption can be relaxed by using noisy-or to combine evidence (as in Chapter 2 and [ Saund, 1995 ] ).
Reference: [ Lang, 1989 ] <author> Kevin J. Lang. </author> <title> A Time-Delay Neural Network Architecture for Speech Recognition. </title> <type> Phd dissertation, </type> <institution> Carnegie Mellon University, School of Computer Science, </institution> <year> 1989. </year>
Reference-contexts: This is similar to the idea behind Diverse Density, where we find the intersection of the positive bags. A Time Delay Neural Network <ref> [ Waibel et al., 1989, Lang, 1989 ] </ref> is an architecture that allows the network to find time-invariant patterns in the examples. Its original motivation was to build a classifier to distinguish spoken letters.
Reference: [ Leach, 1996 ] <author> Andrew R. Leach. </author> <title> Molecular Modeling: </title> <booktitle> principles and applications. </booktitle> <publisher> Longman, </publisher> <address> Harlow, England, </address> <year> 1996. </year>
Reference-contexts: In that case, a preferable representation would be an orientation-independent one, such as the pharmacophore model of [ Dammkoehler et al., 1989 ] or <ref> [ Leach, 1996 ] </ref> . Another possible representation would be to place many ray-centers throughout 3D space, with only one ray coming out of each one.
Reference: [ Lipson et al., 1997 ] <author> P. Lipson, E. Grimson, and P. Sinha. </author> <title> Context and configuration based scene classification. </title> <booktitle> In Computer Vision and Pattern Recognition, </booktitle> <year> 1997. </year>
Reference-contexts: If we consider the domain of natural scene classification, these absolute properties can vary between images of the same class. Recent work ( <ref> [ Lipson et al., 1997 ] </ref> ) in scene classification illustrates that predefined flexible templates that describe the relative color and spatial properties in the image can be used effectively for this task. The flexible templates constructed by Lipson [ Lipson et al., 1997 ] encode the scene classes as a <p> Recent work ( <ref> [ Lipson et al., 1997 ] </ref> ) in scene classification illustrates that predefined flexible templates that describe the relative color and spatial properties in the image can be used effectively for this task. The flexible templates constructed by Lipson [ Lipson et al., 1997 ] encode the scene classes as a set of image patches and qualitative relationships between those patches. Each image patch has properties in the color and luminance channels. <p> A more worthy adversary for a concept learned from examples is one which was hand-crafted based on domain knowledge of a particular image type. Figure 6-5 shows that the performance of the learned mountain concept is competitive with a hand-crafted mountain template from <ref> [ Lipson et al., 1997 ] </ref> . Lipson's classifier was modified to give a ranking of each image, rather than its class. The test set consists of 80 mountains, 80 fields, and 80 waterfalls. It is disjoint from the training set.
Reference: [ Long and Tan, 1996 ] <author> P. M. Long and L. Tan. </author> <title> Pac-learning axis alligned rectangles with respect to product distributions from multiple-instance examples. </title> <booktitle> In Proceedings of the 1996 Conference on Computational Learning Theory, </booktitle> <year> 1996. </year>
Reference-contexts: In fact, it likely represents an upper bound on performance for the musk data set because some of the parameters of the algorithm were trained on MUSK1 and tested on MUSK2. Because Multiple-Instance learning is a neatly stated problem, it soon attracted the attention of theoreticians. Long and Tan <ref> [ Long and Tan, 1996 ] </ref> showed that it is possible to PAC-learn [ Valiant, 1984 ] an axis-parallel concept from Multiple-Instance examples, but gave an algorithm with a very high bound on its running time.
Reference: [ Maron and Lakshmi Ratan, 1998 ] <author> O. Maron and A. Lakshmi Ratan. </author> <title> Multiple-instance learning for natural scene classification. </title> <booktitle> In Machine Learning: Proceedings of the 15th International Conference, </booktitle> <year> 1998. </year>
Reference-contexts: In this application, we describe a range of possible bag generators, and show results from experiments using a variety of different generators. These results are taken from <ref> [ Maron and Lakshmi Ratan, 1998 ] </ref> . In Chapter 7, we discuss other work on Multiple-Instance learning and on learning from ambiguous examples in general. Finally, future work and conclusions are presented in Chapter 8. Appendix A details the computation of Diverse Density and its derivatives. <p> Many of the existing image-querying systems work on entire images or in user-specified regions by using distribution of color, texture and structural properties. The QBIC system [ Flickner et al., 1995 ] and the Virage system [ Bach et 1 This chapter describes joint work with Aparna Lakshmi Ratan <ref> [ Maron and Lakshmi Ratan, 1998 ] </ref> . al., 1996 ] are examples of such systems. Some recent systems that try to incorporate some spatial information into their color feature sets include [ Smith and Chang, 1996, Huang et al., 1997, Belongie et al., 1998 ] .
Reference: [ Maron and Lozano-Perez, 1998 ] <author> O. Maron and T. Lozano-Perez. </author> <title> A framework for multiple-instance learning. </title> <booktitle> In Advances in Neural Information Processing Systems 10. </booktitle> <publisher> MIT Press, </publisher> <year> 1998. </year> <month> 117 </month>
Reference-contexts: This technique was first introduced in <ref> [ Maron and Lozano-Perez, 1998 ] </ref> . A more detailed discussion of the algorithm, a formal derivation, its mathematical assumptions, and its variants are given in Chapters 2 and 3. The applications in the previous section have hinted at the approach taken in this thesis.
Reference: [ Minka and Picard, 1996 ] <author> T. Minka and R. </author> <title> Picard. Interactive learning using a soci-ety of models. </title> <booktitle> In Computer Vision and Pattern Recognition, </booktitle> <year> 1996. </year>
Reference-contexts: All of the systems described above require users to specify precisely the salient regions and templates that they want. Minka and Picard <ref> [ Minka and Picard, 1996 ] </ref> introduced a learning component in their system. They use positive and negative examples to learn which members of a set of image groupings (similarity measures) should be used. The image groupings occur within and across images and are based on color and texture cues.
Reference: [ Mitchell, 1978 ] <author> Tom M. Mitchell. </author> <title> Version spaces: an approach to concept learning. </title> <type> Phd dissertation, </type> <institution> Stanford University, Dept. of Electrical Engineering, </institution> <year> 1978. </year>
Reference-contexts: Norton's work is an outgrowth of Hirsh's bounded inconsistency learner [ Hirsh, 1990 ] . The bounded inconsistency model assumes that every example is made up of some true source example corrupted by a noise model. In addition, given a noisy example, one can efficiently describe the version space <ref> [ Mitchell, 1978 ] </ref> that covers all concepts that agree with the possible true sources of that example. Each example is therefore represented by an "expanded" version space, and the intersection of all the version spaces contains concepts that are consistent with the training data.
Reference: [ Morozov, 1984 ] <author> V. A. Morozov. </author> <title> Methods for solving incorrectly posed problems. </title> <publisher> Springer Verlag, </publisher> <year> 1984. </year>
Reference-contexts: For better accuracy, the evaluation of the concept should be done on multiple partitions of the data into training and testing sets. This is known as cross-validation. A second approach uses ideas from Minimum Description Length [ Rissanen, 1978 ] , Regularization theory <ref> [ Morozov, 1984 ] </ref> , PAC learning theory [ Valiant, 1984 ] , and Structural Risk Minimization [ Vapnik, 1995 ] .
Reference: [ Murphy and Aha, 1996 ] <author> P. M. Murphy and D. W. Aha. </author> <title> Uci repository of machine learning databases. for more information contact ml-repository@ics.uci.edu, </title> <year> 1996. </year>
Reference-contexts: Another possible representation would be to place many ray-centers throughout 3D space, with only one ray coming out of each one. The distances along each ray would represent the shape of the molecule. 4.3 The MUSK datasets A publicly available dataset (deposited at <ref> [ Murphy and Aha, 1996 ] </ref> ) was generated as described in the previous section describes positive and negative examples of musks.
Reference: [ Norton, 1994 ] <author> Steven W. Norton. </author> <title> Learning to recognize promoter sequences in e. coli by modeling uncertainty in the training data. </title> <booktitle> In Proceedings of the Twelfth National Conference on Artificial Intelligence. </booktitle> <publisher> MIT Press, </publisher> <year> 1994. </year>
Reference-contexts: Other algorithms take a more proactive approach; for example, k-Nearest-Neighbor and other such variants [ Atkeson et al., 1997 ] smooth out noise through voting schemes. [ Kearns and Vazirani, 1994 ] show that PAC-learning from noisy examples can be reduced to the standard PAC model. <ref> [ Norton, 1994 ] </ref> shows that ambiguity can arise not only from an uncertain example, but also from an uncertain representation. Norton attempts to learn DNA promoter sequences from examples. However, there is no such thing as a universal description of a promoter sequence.
Reference: [ Omohundro, 1991 ] <author> S. M. Omohundro. </author> <title> Bumptrees for efficient function, constraint, and classification learning. </title> <editor> In Lippmann, Moody, and Touretzky, editors, </editor> <booktitle> Advances in Neural Information Processing Systems 3, </booktitle> <address> San Mateo, CA, 1991. </address> <publisher> Morgan Kauf-mann. </publisher>
Reference-contexts: This implies that a Diverse Density calculation requires O (N ) space and O (N ) time, where N is the total number of instances in all bags. There are techniques for calculating Nearest Neighbor in sub-linear time. Bump trees <ref> [ Omohundro, 1991 ] </ref> and k-d trees [ Preparata and Shamos, 1985 ] are examples of such techniques, and they can be used to approximate Diverse Density. The main difficulty with using them during learning is that they assume that the distance metric is held constant.
Reference: [ Pearl, 1988 ] <author> Judea Pearl. </author> <title> Probabilistic reasoning in intelligent systems: networks of plausible inference. </title> <publisher> Morgan Kaufmann, </publisher> <year> 1988. </year>
Reference-contexts: Some concept representations used to learn from labeled examples include decision trees [ Quinlan, 1992 ] , nearest neighbor [ Dasarathy, 1991 ] , neural networks [ Rumelhart et al., 1986 ] , and Bayesian networks <ref> [ Pearl, 1988 ] </ref> . In unsupervised learning, the examples are not labeled. The algorithm attempts to learn the structure of the underlying source of the examples. <p> a combination of the distances from each instance to the potential concept c t . 2.3 Ways to estimate Pr (t j B i ) 2.3.1 Using noisy-or to estimate a density One way to estimate the likelihood of a hypothesized concept given a single bag is to use noisy-or <ref> [ Pearl, 1988 ] </ref> . Noisy-or is an idea from Bayesian Networks, where it is used to calculate the probability of a binary event with multiple possible causes. In the noisy-or model, it is assumed that the event can only happen if at least one of the causations occurred.
Reference: [ Preparata and Shamos, 1985 ] <author> F. P. Preparata and M. I. Shamos. </author> <title> Computational geometry: an introduction. </title> <publisher> Springer-Verlag, </publisher> <year> 1985. </year>
Reference-contexts: This implies that a Diverse Density calculation requires O (N ) space and O (N ) time, where N is the total number of instances in all bags. There are techniques for calculating Nearest Neighbor in sub-linear time. Bump trees [ Omohundro, 1991 ] and k-d trees <ref> [ Preparata and Shamos, 1985 ] </ref> are examples of such techniques, and they can be used to approximate Diverse Density. The main difficulty with using them during learning is that they assume that the distance metric is held constant.
Reference: [ Press et al., 1992 ] <author> W. H. Press, S. A. Teukolsky, W. T. Vetterling, and B. P. Flan-nery. </author> <title> Numerical Recipes in C: </title> <booktitle> the art of scientific computing. </booktitle> <publisher> Cambridge University Press, </publisher> <address> New York, </address> <note> second edition, </note> <year> 1992. </year>
Reference-contexts: For example, this bounds the maximum contribution of a negative instance (or a positive bag with all distant instances) to be approximately 16. Gradient based optimization We use a two-step gradient ascent routine. The routine first performs performs line searches (lnsrch in <ref> [ Press et al., 1992 ] </ref> ) along the gradient direction using a loose convergence criterion. After the first step converges, the second step performs a quasi-newton search (dfpmin in [ Press et al., 1992 ] ) from that point. <p> Gradient based optimization We use a two-step gradient ascent routine. The routine first performs performs line searches (lnsrch in <ref> [ Press et al., 1992 ] </ref> ) along the gradient direction using a loose convergence criterion. After the first step converges, the second step performs a quasi-newton search (dfpmin in [ Press et al., 1992 ] ) from that point. The number of iterations allowed for each optimization was at least two times the number of dimensions of the search space. 111 Details of the difficult artificial dataset The generation of bags was described in Chapter 2.
Reference: [ Quinlan, 1992 ] <author> J. R. Quinlan. C4.5: </author> <title> programs for machine learning. </title> <publisher> Morgan Kauf-mann, </publisher> <year> 1992. </year>
Reference-contexts: The label can 11 be a class, in which case the learning task is called classification, or a continuous signal, in which case the task is called regression. Some concept representations used to learn from labeled examples include decision trees <ref> [ Quinlan, 1992 ] </ref> , nearest neighbor [ Dasarathy, 1991 ] , neural networks [ Rumelhart et al., 1986 ] , and Bayesian networks [ Pearl, 1988 ] . In unsupervised learning, the examples are not labeled.
Reference: [ Rissanen, 1978 ] <author> J. Rissanen. </author> <title> Modeling by shortest data description. </title> <journal> Automatica, </journal> <volume> 14 </volume> <pages> 465-471, </pages> <year> 1978. </year>
Reference-contexts: The scalings chosen by maxDD will be as big as is required to keep the negative instances away, and no bigger. This gives us a natural bias toward simpler concepts (i.e., concepts that use fewer features). Normally, Machine Learning algorithms need to add a regularizing term (e.g., <ref> [ Rissanen, 1978 ] </ref> , [ Girosi et al., 1995 ] ) to prevent overfitting with an overly complicated concept. 3.1.3 Learning disjunctive concepts There is no conceptual difference between learning a single point-and-scaling concept and learning a disjunction of d of them. <p> For better accuracy, the evaluation of the concept should be done on multiple partitions of the data into training and testing sets. This is known as cross-validation. A second approach uses ideas from Minimum Description Length <ref> [ Rissanen, 1978 ] </ref> , Regularization theory [ Morozov, 1984 ] , PAC learning theory [ Valiant, 1984 ] , and Structural Risk Minimization [ Vapnik, 1995 ] .
Reference: [ Rumelhart et al., 1986 ] <author> David E. Rumelhart, James L. McClelland, </author> <title> and the PDP re-search Group. Parallel distributed processing: explorations in the microstructure of cognition. </title> <publisher> MIT Press, </publisher> <year> 1986. </year>
Reference-contexts: Some concept representations used to learn from labeled examples include decision trees [ Quinlan, 1992 ] , nearest neighbor [ Dasarathy, 1991 ] , neural networks <ref> [ Rumelhart et al., 1986 ] </ref> , and Bayesian networks [ Pearl, 1988 ] . In unsupervised learning, the examples are not labeled. The algorithm attempts to learn the structure of the underlying source of the examples.
Reference: [ Saund, 1995 ] <author> Eric Saund. </author> <title> A multiple cause mixture model for unsupervised learning. </title> <journal> Neural Computation, </journal> <volume> 7 </volume> <pages> 51-71, </pages> <year> 1995. </year>
Reference-contexts: This assumption leads to their method of combining evidence through a summation of likelihood ratios (as discussed in Section 2.3.2). In [ Keeler et al., 1991b ] , they show that the assumption can be relaxed by using noisy-or to combine evidence (as in Chapter 2 and <ref> [ Saund, 1995 ] </ref> ). In a different context, [ Dayan and Zemel, 1995 ] show that both summation of likelihood ratios and noisy-or can be suitable models of combining evidence.
Reference: [ Smith and Chang, 1996 ] <author> J. Smith and S. Chang. Visualseek: </author> <title> a fully automated content-based image query system. </title> <booktitle> In Proceedings of the ACM International Conference on Multimedia. </booktitle> <publisher> Morgan Kaufmann, </publisher> <year> 1996. </year>
Reference: [ Sutton and Barto, 1998 ] <author> Richard S. Sutton and Andrew G. Barto. </author> <title> Reinforcement Learning: An Introduction. </title> <publisher> MIT Press/Bradford Books, </publisher> <address> Cambridge, MA, </address> <year> 1998. </year>
Reference-contexts: In Reinforcement Learning the goal is to learn a policy, which is a mapping from states to actions. Examples are not labeled with the correct action; instead an occasional reinforcement signal which denotes the utility of some state is received. Reinforcement Learning methods are reviewed in <ref> [ Sutton and Barto, 1998 ] </ref> and [ Kaelbling et al., 1996 ] . One way to relate these three frameworks is to look at the ambiguity of the training examples by determining how much information the label of an example conveys. <p> Multiple-Instance learning falls in the middle 98 of the spectrum, as does Reinforcement Learning <ref> [ Sutton and Barto, 1998, Kaelbling et al., 1996 ] </ref> . In Reinforcement Learning, the teacher (or the world) provides an occasional reinforcement signal, but the specific value of being at some state (or which action to take) is usually not given.
Reference: [ Trippi, 1995 ] <author> Robert R. Trippi. </author> <title> Chaos & Nonlinear Dynamics in the Financial Markets: Theory, Evidence, and Applications. </title> <address> McGraw-Hill/Irwin, </address> <year> 1995. </year>
Reference-contexts: In addition, we examine a particular set of molecules (musks) and show results of Diverse Density and other learning algorithms on this task. 1.2.2 Stock prediction The stock market is one of the most noisy (some would even say chaotic <ref> [ Trippi, 1995 ] </ref> ) and popular domains for Machine Learning techniques. One reason for the apparent high amount of noise in the stock market is that most price changes are caused by unpredictable current events and public sentiment, rather than by fundamental financial and economic reasons.
Reference: [ Valiant, 1984 ] <author> L. G. Valiant. </author> <title> A theory of the learnable. </title> <journal> Communications of the ACM, </journal> <volume> 27(11) </volume> <pages> 1134-1142, </pages> <month> November </month> <year> 1984. </year>
Reference-contexts: This is known as cross-validation. A second approach uses ideas from Minimum Description Length [ Rissanen, 1978 ] , Regularization theory [ Morozov, 1984 ] , PAC learning theory <ref> [ Valiant, 1984 ] </ref> , and Structural Risk Minimization [ Vapnik, 1995 ] . <p> Because Multiple-Instance learning is a neatly stated problem, it soon attracted the attention of theoreticians. Long and Tan [ Long and Tan, 1996 ] showed that it is possible to PAC-learn <ref> [ Valiant, 1984 ] </ref> an axis-parallel concept from Multiple-Instance examples, but gave an algorithm with a very high bound on its running time.
Reference: [ Vapnik, 1995 ] <author> Vladimir Naumovich Vapnik. </author> <title> The nature of statistical learning theory. </title> <publisher> Springer, </publisher> <year> 1995. </year>
Reference-contexts: This is known as cross-validation. A second approach uses ideas from Minimum Description Length [ Rissanen, 1978 ] , Regularization theory [ Morozov, 1984 ] , PAC learning theory [ Valiant, 1984 ] , and Structural Risk Minimization <ref> [ Vapnik, 1995 ] </ref> . All these theories attempt to capture analytically the tradeoff between complexity of the hypothesis class and ability to generalize. 3.2 Pointwise Diverse Density 2 The maxDD algorithm's goal is to return a concept that maximizes Diverse Density.
Reference: [ Waibel et al., 1989 ] <author> Alexander Waibel, Toshiyuki Hanazawa, Geoffrey Hinton, Kiy-ohiro Shikano, and Kevin J. Lang. </author> <title> Phoneme recognition using time-delay neural networks. </title> <journal> IEEE Transactions on Acoustics, Speech and Signal Processing, </journal> <volume> 37(3), </volume> <month> March </month> <year> 1989. </year> <month> 119 </month>
Reference-contexts: This is similar to the idea behind Diverse Density, where we find the intersection of the positive bags. A Time Delay Neural Network <ref> [ Waibel et al., 1989, Lang, 1989 ] </ref> is an architecture that allows the network to find time-invariant patterns in the examples. Its original motivation was to build a classifier to distinguish spoken letters.
References-found: 54

