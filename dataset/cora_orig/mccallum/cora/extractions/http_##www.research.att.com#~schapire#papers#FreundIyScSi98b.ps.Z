URL: http://www.research.att.com/~schapire/papers/FreundIyScSi98b.ps.Z
Refering-URL: http://www.research.att.com/~yoav/publications.html
Root-URL: 
Email: yoav@research.att.com  rajiyer@mit.edu  schapire@research.att.com  singer@research.att.com  
Title: Machine Learning: Proceedings of the Fifteenth InternationalConference, 1998. An Efficient Boosting Algorithm for Combining Preferences  
Author: Yoav Freund Raj Iyer Robert E. Schapire Yoram Singer 
Affiliation: AT&T Labs  MIT Laboratory for Computer Science  AT&T Labs  AT&T Labs  
Abstract: The problem of combining preferences arises in several applications, such as combining the results of different search engines. This work describes an efficient algorithm for combining multiple preferences. We first give a formal framework for the problem. We then describe and analyze a new boosting algorithm for combining preferences called RankBoost. We also describe an efficient implementation of the algorithm for a restricted case. We discuss two experiments we carried out to assess the performance of RankBoost. In the first experiment, we used the algorithm to combine different WWW search strategies, each of which is a query expansion for a given domain. For this task, we compare the performance of RankBoost to the individual search strategies. The second experiment is a collaborative-filtering task for making movie recommendations. Here, we present results comparing RankBoost to nearest-neighbor and regression algorithms. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Brian T. Bartell, Garrison W. Cottrell, and Richard K. Belew. </author> <title> Automatic combination of multiple ranked retrieval systems. </title> <booktitle> In Proceedings of the 17th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <year> 1994. </year>
Reference-contexts: Despite the wide range of applications that use and com-bine rankings, this problem has received relatively little attention in the machine-learning community. The few methods that have been devised for combining rankings tend to be based either on nearest-neighbor methods [9, 14] or numerical-optimization techniques <ref> [1, 3] </ref>. In the latter case, the rankings are viewed as real-valued scores and the problem of combining different rankings reduces to numerical search for a set of parameters that will minimize the disparity between the combined scores and the feedback of a user. <p> Thus, if we are using weak hypotheses with range restricted to f0; 1g, we should attempt to find h which tends to minimize this value of Z and we should then set ff accordingly. For weak hypotheses with range <ref> [0; 1] </ref>, we can use a third method based on an approximation of Z. Specifically, note that e ffx 1 + x 2 e ff for all real ff and x 2 [1; +1]. <p> For weak hypotheses with range [0; 1], we can use a third method based on an approximation of Z. Specifically, note that e ffx 1 + x 2 e ff for all real ff and x 2 <ref> [1; +1] </ref>. <p> Thus, to approximately minimize Z using weak hypotheses with range <ref> [0; 1] </ref>, we can attempt to maximize jrj as defined in Eq. (3) and then set ff as in Eq. (4). <p> For the remainder of this section, we show how to choose the best feature, threshold and default score. Let us fix t and drop it from all subscripts to simplify the notation. Since the ranges of our weak hypotheses are bounded in <ref> [0; 1] </ref>, we can use the third method 1 described in Section 3.2 to guide us in our search for a weak hypothesis. Recall that, according to this method, the weak learner should seek a weak hypothesis which maximizes jrj as given by Eq. (3). <p> The definitions can be extended by assuming that ties are broken randomly and taking expectations (details omitted for lack of space). All our measures have range <ref> [0; 1] </ref>, with a value 0 being a perfect score. Disagreement. Disagreement is the fraction of distinct pairs of instances which are misordered by H (with respect to c). If c were used to construct a feedback function, this would be equivalent to the ranking loss of H. Predicted-rank-of-top (PROT). <p> Predicted-rank-of-top (PROT). This is the minimum rank (according to H) of any of the truly top-rated instances (according to c). The score is then rescaled to have a possible range of <ref> [0; 1] </ref>. Coverage. This is the maximum rank (according to H) of any of the truly top-rated instances (according to c). The score is then rescaled to have a possible range of [0; 1]. (Note that coverage and PROT are equal if there is a unique top-rated instances according to c.) <p> The score is then rescaled to have a possible range of <ref> [0; 1] </ref>. Coverage. This is the maximum rank (according to H) of any of the truly top-rated instances (according to c). The score is then rescaled to have a possible range of [0; 1]. (Note that coverage and PROT are equal if there is a unique top-rated instances according to c.) Rank-of-predicted-top (ROPT). This is the number of instances ranked strictly higher (according to c) than the predicted top-rated instance (according to H). <p> This is the number of instances ranked strictly higher (according to c) than the predicted top-rated instance (according to H). The score is then rescaled to have a possible range of <ref> [0; 1] </ref>. We now describe our experimental results. We ran a series of three tests, examining the performance of the algorithms as we varied the number of features, the density of the features (number of movies ranked by each user), and the density of the feedback.
Reference: [2] <author> Peter L. Bartlett. </author> <title> The sample complexity of pattern classification with neural networks: the size of the weights is more important than the size of the network. </title> <journal> IEEE Transactions on Information Theory, </journal> <note> 1998 (to appear). </note>
Reference-contexts: Note that this theorem only concerns performance on the training data. As in more standard classification problems, the loss on a separate test set can also be theoretically bounded given appropriate assumptions using uniform-convergence theory <ref> [2, 7, 12, 15] </ref>.
Reference: [3] <author> Rich Caruana, Shumeet Baluja, and Tom Mitchell. </author> <title> Using the future to sort out the present: Rankprop and multitask learning for medical risk evaluation. </title> <booktitle> In Advances in Neural Information Processing Systems 8, </booktitle> <pages> pages 959-965, </pages> <year> 1996. </year>
Reference-contexts: Despite the wide range of applications that use and com-bine rankings, this problem has received relatively little attention in the machine-learning community. The few methods that have been devised for combining rankings tend to be based either on nearest-neighbor methods [9, 14] or numerical-optimization techniques <ref> [1, 3] </ref>. In the latter case, the rankings are viewed as real-valued scores and the problem of combining different rankings reduces to numerical search for a set of parameters that will minimize the disparity between the combined scores and the feedback of a user.
Reference: [4] <author> William W. Cohen, Robert E. Schapire, and Yoram Singer. </author> <title> Learning to order things. </title> <booktitle> In Advances in Neural Information Processing Systems 10, </booktitle> <year> 1998. </year>
Reference-contexts: While the above (and other) approaches might work well in practice, they still do not guarantee that the combined system will match the user's preference when we view the scores as a means to express preferences. Recently, Cohen, Schapire and Singer <ref> [4] </ref> proposed a framework for manipulating and combining multiple rankings in order to directly minimize the number of disagreements. <p> For instance, approaches that learn to combine similarity scores are not applicable since the similarity scores of Web search engines are often unavailable. In order to test RankBoost on this task, we used the data of Cohen, Schapire and Singer <ref> [4] </ref>. Their goal was to simulate the problem of building a domain-specific search engine. As test cases, they picked two fairly narrow classes of queriesretrieving the homepages of machine-learning researchers (ML), and retrieving the homepages of universities (UNIV).
Reference: [5] <author> O. Etzioni, S. Hanks, T. Jiang, R. M. Karp, O. Madani, and O. Waarts. </author> <title> Efficient information gathering on the internet. </title> <booktitle> In 37th Annual Symposium on Foundations of Computer Science, </booktitle> <year> 1996. </year>
Reference-contexts: This distinction becomes very important when we combine the rankings of many users who often use completely different ranges of scores to express identical preferences. Situations where we need to combine the ranking of different models also arise in meta-searching problems <ref> [5] </ref> and in information-retrieval problems [11, 10]. In this paper, we introduce and analyze an efficient algorithm called RankBoost for combining multiple rank fl Research conducted while visiting AT&T Labs and with support from an NSF Graduate Fellowship. ings.
Reference: [6] <author> Yoav Freund and Robert E. Schapire. </author> <title> A decision-theoretic generalization of on-line learning and an application to boosting. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 55(1) </volume> <pages> 119-139, </pages> <month> August </month> <year> 1997. </year>
Reference-contexts: In this paper, we introduce and analyze an efficient algorithm called RankBoost for combining multiple rank fl Research conducted while visiting AT&T Labs and with support from an NSF Graduate Fellowship. ings. This algorithm is based on Freund and Schapire's <ref> [6] </ref> AdaBoost algorithm and its recent successor developed by Schapire and Singer [13]. Similar to other boosting algorithms, RankBoost works by combining many weak rankings of the given instances. Each of these may be only weakly correlated with the target ranking that we are attempting to approximate. <p> Output the final hypothesis: H (x) = T X ff t h t (x): 3 A boosting algorithm for the ranking task In this section, we describe an approach to the ranking problem based on a machine learning method called boosting, in particular, Freund and Schapire's <ref> [6] </ref> AdaBoost algorithm and its successor developed by Schapire and Singer [13]. Boosting is a method of producing highly accurate prediction rules by combining many weak rules which may be only moderately accurate.
Reference: [7] <author> David Haussler. </author> <title> Decision theoretic generalizations of the PAC model for neural net and other learning applications. </title> <journal> Information and Computation, </journal> <volume> 100(1) </volume> <pages> 78-150, </pages> <year> 1992. </year>
Reference-contexts: Note that this theorem only concerns performance on the training data. As in more standard classification problems, the loss on a separate test set can also be theoretically bounded given appropriate assumptions using uniform-convergence theory <ref> [2, 7, 12, 15] </ref>.
Reference: [8] <author> Will Hill, Larry Stead, Mark Rosenstein, and George Furnas. </author> <title> Recommending and evaluating choices in a virtual community of use. </title> <booktitle> In Human Factors in Computing Systems CHI'95 Conference Proceedings, </booktitle> <pages> pages 194-201, </pages> <year> 1995. </year>
Reference-contexts: 1 Introduction Consider the following movie-recommendation task, sometimes called a collaborative-filtering problem <ref> [8, 14] </ref>. In this task, a new user, Alice, seeks recommendations of movies that she is likely to enjoy. A collaborative-filtering system first asks Alice to rank movies that she has already seen. <p> In these experiments, we ran RankBoost for 100 rounds. 4 From `http://www.research.digital.com/SRC/eachmovie/'. 7 We compared the performance of RankBoost on this data set to two other algorithms, a regression algorithm and a nearest-neighbor algorithm. Regression. We used a regression algorithm similar to the ones used by Hill and others <ref> [8] </ref>. The regression algorithm employs the assumption that the preferences of a target user Alice can be described as a linear combination of the preferences of other users. Formally, let ~a be a row vector whose components are the scores Alice assigned to movies (discarding unranked movies).
Reference: [9] <author> Paul Resnick, Neophytos Iacovou, Mitesh Sushak, Peter Bergstrom, and John Riedl. Grouplens: </author> <title> An open architecture for collaborative filtering of netnews. </title> <booktitle> In Proceedings of Computer Supported Cooperative Work, </booktitle> <year> 1995. </year>
Reference-contexts: Despite the wide range of applications that use and com-bine rankings, this problem has received relatively little attention in the machine-learning community. The few methods that have been devised for combining rankings tend to be based either on nearest-neighbor methods <ref> [9, 14] </ref> or numerical-optimization techniques [1, 3]. In the latter case, the rankings are viewed as real-valued scores and the problem of combining different rankings reduces to numerical search for a set of parameters that will minimize the disparity between the combined scores and the feedback of a user.
Reference: [10] <author> Gerard Salton. </author> <title> Automatic text processing: the transformation, analysis and retrieval of information by computer. </title> <publisher> Addison-Wesley, </publisher> <year> 1989. </year>
Reference-contexts: This distinction becomes very important when we combine the rankings of many users who often use completely different ranges of scores to express identical preferences. Situations where we need to combine the ranking of different models also arise in meta-searching problems [5] and in information-retrieval problems <ref> [11, 10] </ref>. In this paper, we introduce and analyze an efficient algorithm called RankBoost for combining multiple rank fl Research conducted while visiting AT&T Labs and with support from an NSF Graduate Fellowship. ings.
Reference: [11] <author> Gerard Salton and Michael J. McGill. </author> <title> Introduction to Modern Information Retrieval. </title> <publisher> McGraw-Hill, </publisher> <year> 1983. </year>
Reference-contexts: This distinction becomes very important when we combine the rankings of many users who often use completely different ranges of scores to express identical preferences. Situations where we need to combine the ranking of different models also arise in meta-searching problems [5] and in information-retrieval problems <ref> [11, 10] </ref>. In this paper, we introduce and analyze an efficient algorithm called RankBoost for combining multiple rank fl Research conducted while visiting AT&T Labs and with support from an NSF Graduate Fellowship. ings.
Reference: [12] <author> Robert E. Schapire, Yoav Freund, Peter Bartlett, and Wee Sun Lee. </author> <title> Boosting the margin: A new explanation for the effectiveness of voting methods. </title> <journal> Annals of Statistics, </journal> <note> to appear. </note>
Reference-contexts: Note that this theorem only concerns performance on the training data. As in more standard classification problems, the loss on a separate test set can also be theoretically bounded given appropriate assumptions using uniform-convergence theory <ref> [2, 7, 12, 15] </ref>.
Reference: [13] <author> Robert E. Schapire and Yoram Singer. </author> <title> Improved boosting algorithms using confidence-rated predictions. </title> <booktitle> In Proceedings of the Eleventh Annual Conference on Computational Learning Theory, </booktitle> <year> 1998. </year>
Reference-contexts: This algorithm is based on Freund and Schapire's [6] AdaBoost algorithm and its recent successor developed by Schapire and Singer <ref> [13] </ref>. Similar to other boosting algorithms, RankBoost works by combining many weak rankings of the given instances. Each of these may be only weakly correlated with the target ranking that we are attempting to approximate. <p> T X ff t h t (x): 3 A boosting algorithm for the ranking task In this section, we describe an approach to the ranking problem based on a machine learning method called boosting, in particular, Freund and Schapire's [6] AdaBoost algorithm and its successor developed by Schapire and Singer <ref> [13] </ref>. Boosting is a method of producing highly accurate prediction rules by combining many weak rules which may be only moderately accurate.
Reference: [14] <editor> Upendra Shardanand and Pattie Maes. </editor> <title> Social information filtering: Algorithms for automating word of mouth. </title> <booktitle> In Human Factors in Computing Systems CHI'95 Conference Proceedings, </booktitle> <year> 1995. </year>
Reference-contexts: 1 Introduction Consider the following movie-recommendation task, sometimes called a collaborative-filtering problem <ref> [8, 14] </ref>. In this task, a new user, Alice, seeks recommendations of movies that she is likely to enjoy. A collaborative-filtering system first asks Alice to rank movies that she has already seen. <p> Despite the wide range of applications that use and com-bine rankings, this problem has received relatively little attention in the machine-learning community. The few methods that have been devised for combining rankings tend to be based either on nearest-neighbor methods <ref> [9, 14] </ref> or numerical-optimization techniques [1, 3]. In the latter case, the rankings are viewed as real-valued scores and the problem of combining different rankings reduces to numerical search for a set of parameters that will minimize the disparity between the combined scores and the feedback of a user.
Reference: [15] <author> V. N. Vapnik. </author> <title> Estimation of Dependences Based on Empirical Data. </title> <publisher> Springer-Verlag, </publisher> <year> 1982. </year> <month> 9 </month>
Reference-contexts: Note that this theorem only concerns performance on the training data. As in more standard classification problems, the loss on a separate test set can also be theoretically bounded given appropriate assumptions using uniform-convergence theory <ref> [2, 7, 12, 15] </ref>.
References-found: 15

