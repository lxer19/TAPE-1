URL: http://www.cs.umn.edu/Research/Agassiz/Paper/gu.super95.ps.Z
Refering-URL: http://www.cs.umn.edu/Research/Agassiz/agassiz_pubs.html
Root-URL: http://www.cs.umn.edu
Email: fgu,lig@cs.umn.edu, ghlee@ee.umn.edu  
Title: Symbolic Array Dataflow Analysis for Array Privatization and Program Parallelization 1  
Author: Junjie Gu Zhiyuan Li Gyungho Lee 
Address: 200 Union Street S.E. Minneapolis, MN 55455  
Affiliation: Department of Computer Science Department of Electrical Engineering University of Minnesota  
Note: To appear in Proceedings of Supercomputing'95: AHPCRC Preprint 95-034  
Abstract: Array dataflow information plays an important role for successful automatic parallelization of Fortran programs. This paper proposes a powerful symbolic array dataflow analysis to support array privatization and loop parallelization for programs with arbitrary control flow graphs and acyclic call graphs. Our scheme summarizes array access information using guarded array regions and propagates such regions over a Hierarchical Supergraph (HSG). The use of guards allows us to use the information in IF conditions to sharpen the array dataflow analysis and thereby to handle difficult cases which elude other existing techniques. The guarded array regions retain the simplicity of set operations for regular array regions in common cases, and they enhance regular array regions in complicated cases by using guards to handle complex symbolic expressions and array shapes. Scalar values that appear in array subscripts and loop limits are substituted on the fly during the array information propagation, which disambiguates the symbolic values precisely for set operations. We present efficient algorithms that implement our scheme. Initial experiments of applying our analysis to Perfect Benchmarks show promising results of improved array privatization. Key words: Parallelizing compiler, array dataflow analysis, interprocedural analysis, array privatization, symbolic analysis. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A.V. Aho, R. Sethi, and J.D. Ullman. </author> <booktitle> Compilers: Principles, Techniques, and Tools. </booktitle> <publisher> Addison-Wesley, </publisher> <address> Reading, Mass., </address> <year> 1986. </year>
Reference-contexts: Therefore, A is privatizable in loop I. existing algorithms [27, 22, 37], an use of A (jmax) will be deemed as possibly upwards exposed <ref> [1, ch 10] </ref> in each iteration, and A (jmax) is also deemed as possibly written in the previous iterations. Therefore the existing algorithms would assume a loop-carried flow dependence which prevents array A to be privatized.
Reference: [2] <author> J. R. Allen and K. Kennedy. </author> <title> Automatic translation of FORTRAN programs to vector form. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 9(4) </volume> <pages> 491-542, </pages> <month> October </month> <year> 1984. </year>
Reference-contexts: This kind of arrays usually serves as a temporary working space within an iteration and the array values in different iterations are unrelated. Using the same array for all iterations causes unnecessary loop-carried output and anti- dependences <ref> [20, 2] </ref> which prevent DO loops from being parallelized. Array privatization is a technique that creates a distinct copy of an array for each processor such that storage conflicts can be eliminated without violating program semantics.
Reference: [3] <author> V. Balasundaram. </author> <title> A mechanism for keeping useful internal information in parallel programming tools: The data access descriptor. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 9 </volume> <pages> 154-170, </pages> <year> 1990. </year>
Reference-contexts: Numerical methods normally do not apply to array subscripts and loop limits that contain unknown symbolic terms [34]. The second approach, originally proposed to handle call statements, uses array range triples to represent regular array regions which summarize the array elements accessed by one or several references <ref> [10, 17, 3, 9] </ref>. <p> An empty array region is represented by ; and an unknown array region is represented by . The regular array region defined above is more restrictive than the regular sections used in the ParaScope environment at Rice University <ref> [10, 3, 17] </ref>. Where more complex array shapes arise, however, we can always add more information to the guards in GAR's to describe the shapes more precisely (more on this issue in Section 5), which we have not found necessary for array privatization in practice so far.
Reference: [4] <author> Utpal Banerjee. </author> <title> Dependence Analysis for Supercomputing. </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1988. </year>
Reference-contexts: There exist three main approaches to memory disambiguation. The first one, numerical methods, establishes algebraic equations between array subscripts and determines whether the equations are solvable subject to 4 the loop limits and dependence directions <ref> [4, 5, 31, 24, 25, 19, 38] </ref>. Numerical methods normally do not apply to array subscripts and loop limits that contain unknown symbolic terms [34].
Reference: [5] <author> Utpal Banerjee. </author> <title> Loop Transformations for Restructuring Compilers: The Foundations. </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1993. </year>
Reference-contexts: There exist three main approaches to memory disambiguation. The first one, numerical methods, establishes algebraic equations between array subscripts and determines whether the equations are solvable subject to 4 the loop limits and dependence directions <ref> [4, 5, 31, 24, 25, 19, 38] </ref>. Numerical methods normally do not apply to array subscripts and loop limits that contain unknown symbolic terms [34].
Reference: [6] <author> M. Berry, D. Chen, P. Koss, D. Kuck, and S. Lo. </author> <title> The Perfect club benchmarks: Effective performance evaluation of supercomputers. </title> <type> Technical Report CSRD-827, </type> <institution> University of Illinois, Urbana, IL, </institution> <month> May </month> <year> 1989. </year>
Reference-contexts: The examples in Figure 1 illustrate such cases. In these three examples, privatizing the array A will make it possible to parallelize the I loops. Figure 1 (a) shows a simplified version of a loop from the MDG program (routine interf) <ref> [6] </ref>. It is a difficult example which requires inferences between IF conditions. Although both A and B are privatizable, we will discuss A only, since B is a simple case.
Reference: [7] <author> Blume and Eigenmann. </author> <title> Symbolic analysis techniques needed or the effective parallelization of Perfect benchmarks. </title> <type> Technical report, </type> <institution> Dept. of Computer Science, University of Illinois, </institution> <year> 1994. </year>
Reference-contexts: 1 Introduction Recent experiments show that there exists significant performance difference between automatically and manually parallelized codes <ref> [7, 8] </ref>. One important factor causing such a discrepancy is related to array variables. Quite often, array elements written in one iteration of a DO loop are used in the same iteration before being overwritten in the next iteration.
Reference: [8] <author> W. Blume and R. Eigenman. </author> <title> Performance analysis of parallelizing compilers on the Perfect benchmarks programs. </title> <journal> IEEE Trans. on Parallel and Distributed Systems, </journal> <volume> 3(6) </volume> <pages> 643-656, </pages> <month> November </month> <year> 1992. </year>
Reference-contexts: 1 Introduction Recent experiments show that there exists significant performance difference between automatically and manually parallelized codes <ref> [7, 8] </ref>. One important factor causing such a discrepancy is related to array variables. Quite often, array elements written in one iteration of a DO loop are used in the same iteration before being overwritten in the next iteration.
Reference: [9] <author> William Blume and Rudolf Eigenmann. </author> <title> The range test: A dependence test for non-linear expressions. </title> <type> Technical Report CSRD-Report-1345, </type> <institution> Center for Supercomputing Research and Development, University of Illinois at Urbana-Champaign, </institution> <month> April </month> <year> 1994. </year>
Reference-contexts: Numerical methods normally do not apply to array subscripts and loop limits that contain unknown symbolic terms [34]. The second approach, originally proposed to handle call statements, uses array range triples to represent regular array regions which summarize the array elements accessed by one or several references <ref> [10, 17, 3, 9] </ref>.
Reference: [10] <author> D. Callahan and K. Kennedy. </author> <title> Analysis of interprocedural side effects in a parallel programming environment. </title> <booktitle> In ACM SIGPLAN '86 Symp. Compiler Construction, </booktitle> <pages> pages 162-175, </pages> <month> June </month> <year> 1986. </year>
Reference-contexts: Numerical methods normally do not apply to array subscripts and loop limits that contain unknown symbolic terms [34]. The second approach, originally proposed to handle call statements, uses array range triples to represent regular array regions which summarize the array elements accessed by one or several references <ref> [10, 17, 3, 9] </ref>. <p> An empty array region is represented by ; and an unknown array region is represented by . The regular array region defined above is more restrictive than the regular sections used in the ParaScope environment at Rice University <ref> [10, 3, 17] </ref>. Where more complex array shapes arise, however, we can always add more information to the guards in GAR's to describe the shapes more precisely (more on this issue in Section 5), which we have not found necessary for array privatization in practice so far. <p> in step 1 and 2. (If loop-carried anti- dependences are considered separately, they should be detected using DE i instead of U E i in the above formula, where DE i is the downwards exposed use set of iteration i.) Although the formulas above resemble those in previous works, e.g. <ref> [10] </ref>, previous works do not use the flow-sensitive sets and thus are less precise. 9 4 Algorithms for symbolic array dataflow analysis In this section, we present algorithms to calculate the M OD and U E information by propagating the GAR's over a hierarchical supergraph (HSG).
Reference: [11] <author> E. Duesterwald, R. Gupta, </author> <title> and M.L. Soffa. A practical data flow framework for array reference analysis and its use in optimizations. </title> <booktitle> In ACM SIGPLAN '93 Conf. on Programming Language Design and Implementation, </booktitle> <pages> pages 68-77, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: Feautrier [14] suggests to establish a source function for each array use to indicate which definitions will define the value for each distinct array element of the array use reference. Maydan et al [27, 28] simplify Feautrier's method by using a Last-Write-Tree (LWT). Duesterwald et al <ref> [11] </ref> compute the dependence distance for each reaching definition within a loop. Pugh and Wonnacott [32] use a set of constraints to describe array dataflow problems and solve them basically by Fourier-Motzkin variable elimination.
Reference: [12] <author> R. Eigenmann, J. Hoeflinger, G. Jaxon, Z. Li, and D. Padua. </author> <title> Experience with Fortran program restructuring for Cedar multiprocessor. </title> <journal> Concurrency Experience and Practice, </journal> <volume> 5(7) </volume> <pages> 553-573, </pages> <month> October </month> <year> 1993. </year>
Reference-contexts: Speedups for all others are measured on Alliant Fx/8 of 8 processors with vector units in each [13]. 2: T1: Symbolic Analysis. T2: IF Condition Analysis T3: Interprocedural Analysis. summarizes the effect of array privatization on five Perfect benchmarking programs <ref> [22, 13, 12] </ref>. The fourth column of Table 1 shows the percentage of the sequential execution time (over the whole program) of each loop which is made parallel after array privatization. This percentage indicates the significance of each loop.
Reference: [13] <author> R. Eigenmann, J. Hoeflinger, Z. Li, and D. Padua. </author> <title> Experience in the automatic parallelization of four Perfect benchmark programs. </title> <booktitle> In Lecture Notes in Computer Science, </booktitle> <volume> 589. </volume> <publisher> Springer-Verlag, </publisher> <year> 1992. </year>
Reference-contexts: Speedups for ARC2D loops are estimates based on the maximal number of parallel iterations. Speedups for all others are measured on Alliant Fx/8 of 8 processors with vector units in each <ref> [13] </ref>. 2: T1: Symbolic Analysis. T2: IF Condition Analysis T3: Interprocedural Analysis. summarizes the effect of array privatization on five Perfect benchmarking programs [22, 13, 12]. <p> Speedups for all others are measured on Alliant Fx/8 of 8 processors with vector units in each [13]. 2: T1: Symbolic Analysis. T2: IF Condition Analysis T3: Interprocedural Analysis. summarizes the effect of array privatization on five Perfect benchmarking programs <ref> [22, 13, 12] </ref>. The fourth column of Table 1 shows the percentage of the sequential execution time (over the whole program) of each loop which is made parallel after array privatization. This percentage indicates the significance of each loop.
Reference: [14] <author> Paul Feautrier. </author> <title> Dataflow analysis of array and scalar references. </title> <journal> International Journal of Parallel Programming, </journal> <volume> 2(1) </volume> <pages> 23-53, </pages> <month> February </month> <year> 1991. </year>
Reference-contexts: Previous works on array dataflow analysis can be divided into two categories. The first one attempts to gather flow information for each array element and to acquire an exact, complete array data flow information for all array elements. Feautrier <ref> [14] </ref> suggests to establish a source function for each array use to indicate which definitions will define the value for each distinct array element of the array use reference. Maydan et al [27, 28] simplify Feautrier's method by using a Last-Write-Tree (LWT).
Reference: [15] <author> E.D. Granston and A.V. Veidenbaum. </author> <title> Detecting redundant accesses to array data. </title> <booktitle> In Supercomputing '91, </booktitle> <month> November </month> <year> 1991. </year>
Reference-contexts: Simple set operations such as union, intersection, and difference, are performed on such units. Works by Gross and Steenkiste [16], Rosene [33], Li [22], Tu and Padua [37], and Granston and Veidenbaum <ref> [15] </ref>, can roughly be included in this category. These works do 3 not provide as many details about reaching-definitions as the first category. However, they handle more complex program constructs such as IF statements.
Reference: [16] <author> T. Gross and P Steenkiste. </author> <title> Structured dataflow analysis for arrays and its use in an optimizing compiler. </title> <journal> Software Practice and Experience, </journal> <volume> 20(2) </volume> <pages> 133-155, </pages> <month> February </month> <year> 1990. </year>
Reference-contexts: Instead, a set of array elements of a regular shape, called a regular array region or section, is treated as a single unit. Simple set operations such as union, intersection, and difference, are performed on such units. Works by Gross and Steenkiste <ref> [16] </ref>, Rosene [33], Li [22], Tu and Padua [37], and Granston and Veidenbaum [15], can roughly be included in this category. These works do 3 not provide as many details about reaching-definitions as the first category. However, they handle more complex program constructs such as IF statements.
Reference: [17] <author> P. Havlak and K. Kennedy. </author> <title> An implementation of interprocedural bounded regular section analysis. </title> <journal> IEEE Trans. on Parallel and Distributed Systems, </journal> <volume> 2(3), </volume> <year> 1991. </year>
Reference-contexts: Numerical methods normally do not apply to array subscripts and loop limits that contain unknown symbolic terms [34]. The second approach, originally proposed to handle call statements, uses array range triples to represent regular array regions which summarize the array elements accessed by one or several references <ref> [10, 17, 3, 9] </ref>. <p> An empty array region is represented by ; and an unknown array region is represented by . The regular array region defined above is more restrictive than the regular sections used in the ParaScope environment at Rice University <ref> [10, 3, 17] </ref>. Where more complex array shapes arise, however, we can always add more information to the guards in GAR's to describe the shapes more precisely (more on this issue in Section 5), which we have not found necessary for array privatization in practice so far.
Reference: [18] <author> F. Irigoin, P. Jouvelot, and R. Triolet. </author> <title> Semantical interprocedural parallelization: An overview of the PIPS project. </title> <booktitle> In International Conference on Supercomputing, </booktitle> <pages> pages 244-251, </pages> <year> 1991. </year>
Reference-contexts: Due to the nested structures of DO loops and routines, a hierarchy is derived among the HSG nodes, with the flow subgraph at the highest level representing the main program. The HSG resembles the HSCG used by the PIPS project <ref> [18] </ref>. Figure 3 and Figure 5 show two HSG examples. Note that the flow subgraph of a routine is never duplicated for different calls to the same routine unless the called routine is duplicated to enhance its potential parallelism. We assume that the program contains no recursive calls.
Reference: [19] <author> X. Kong, D. Klappholz, and K. Psarris. </author> <title> The I test: An improved dependence test for automatic parallelization and vectorization. </title> <journal> IEEE Trans. on Parallel and Distributed Systems, </journal> <volume> 2(3), </volume> <year> 1991. </year>
Reference-contexts: There exist three main approaches to memory disambiguation. The first one, numerical methods, establishes algebraic equations between array subscripts and determines whether the equations are solvable subject to 4 the loop limits and dependence directions <ref> [4, 5, 31, 24, 25, 19, 38] </ref>. Numerical methods normally do not apply to array subscripts and loop limits that contain unknown symbolic terms [34].
Reference: [20] <author> D.J. Kuck. </author> <title> The Structure of Computers and Computations, volume 1. </title> <publisher> John Wiley & Sons, </publisher> <year> 1978. </year>
Reference-contexts: This kind of arrays usually serves as a temporary working space within an iteration and the array values in different iterations are unrelated. Using the same array for all iterations causes unnecessary loop-carried output and anti- dependences <ref> [20, 2] </ref> which prevent DO loops from being parallelized. Array privatization is a technique that creates a distinct copy of an array for each processor such that storage conflicts can be eliminated without violating program semantics. <p> For array privatization and loop parallelization, analysis at the loop iteration level normally suffices. Conventional data dependence analysis is the predecessor of all current works on array dataflow analysis. In his pioneering work, D.J. Kuck defines flow dependences, anti- dependences and output dependences <ref> [20] </ref>. While the latter two are due to multi-assignments in imperative languages, a flow dependence is defined between two statements, one of which reads the value written by the other. Thus, the original definition of flow dependences is precisely a reaching-definition relation.
Reference: [21] <author> R. Kuhn. </author> <title> Optimization And Interconnection Complexity for: Parallel Processors, Single-Stage Networks, And Decision Trees. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, University of Illinois at Urbana-Champaign,, </institution> <month> Feb </month> <year> 1980. </year>
Reference-contexts: The third approach, which is the most general but also the most time consuming, represents the set of referenced array elements by a set of inequalities and equations and uses Fourier-Motzkin pairwise elimination or integer programming to determine the feasibility of the set <ref> [21, 36, 35, 31] </ref>. The third approach can take IF conditions into account, while the other two do not. Pugh and Wonnacott [30] also discuss an extension of the Omega test [31] which computes certain array reaching-definitions for special cases without IF statements.
Reference: [22] <author> Z. Li. </author> <title> Array privatization for parallel execution of loops. </title> <booktitle> In ACM Int. Conf. on Supercomputing, </booktitle> <pages> pages 313-322, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: Speedups for all others are measured on Alliant Fx/8 of 8 processors with vector units in each [13]. 2: T1: Symbolic Analysis. T2: IF Condition Analysis T3: Interprocedural Analysis. summarizes the effect of array privatization on five Perfect benchmarking programs <ref> [22, 13, 12] </ref>. The fourth column of Table 1 shows the percentage of the sequential execution time (over the whole program) of each loop which is made parallel after array privatization. This percentage indicates the significance of each loop. <p> This percentage indicates the significance of each loop. Array privatization requires a thorough analysis of array data flow and often involves the handling of routine calls. While the effects of IF conditions and CALL statements are shown to be important in practice <ref> [22, 37] </ref>, few existing works handle such cases. The examples in Figure 1 illustrate such cases. In these three examples, privatizing the array A will make it possible to parallelize the I loops. Figure 1 (a) shows a simplified version of a loop from the MDG program (routine interf) [6]. <p> Therefore, A is privatizable in loop I. existing algorithms <ref> [27, 22, 37] </ref>, an use of A (jmax) will be deemed as possibly upwards exposed [1, ch 10] in each iteration, and A (jmax) is also deemed as possibly written in the previous iterations. <p> Instead, a set of array elements of a regular shape, called a regular array region or section, is treated as a single unit. Simple set operations such as union, intersection, and difference, are performed on such units. Works by Gross and Steenkiste [16], Rosene [33], Li <ref> [22] </ref>, Tu and Padua [37], and Granston and Veidenbaum [15], can roughly be included in this category. These works do 3 not provide as many details about reaching-definitions as the first category. However, they handle more complex program constructs such as IF statements. <p> Hence, GAR's retain the efficiency of regular array region operations in common cases, while enhancing the precision when necessary. 3.2 Applications of GAR's 3.2.1 Array Privatization An array A is a privatization candidate in a loop L if its elements are overwritten in different iterations of L (see <ref> [22] </ref>). Such a candidacy can be established by examining the array subscripts: if the subscripts of array A do not contain any induction variables of L, then A is a candidate [22]. A privatization candidate is privatizable if there exist no loop-carried flow dependences in L. <p> is a privatization candidate in a loop L if its elements are overwritten in different iterations of L (see <ref> [22] </ref>). Such a candidacy can be established by examining the array subscripts: if the subscripts of array A do not contain any induction variables of L, then A is a candidate [22]. A privatization candidate is privatizable if there exist no loop-carried flow dependences in L. For an array A in a loop L with an index I, if M OD &lt;i " U E i = ;, then there exists no flow dependence carried by loop L. <p> Live analysis must be performed for privatized arrays in order to determine whether and which last values of the privatized arrays must be copied out of the DO loop. Previous works have addressed this issue <ref> [22, 37, 27] </ref>. 3.2.2 Loop parallelization The essence of loop parallelization is to prove the absence of loop-carried dependences.
Reference: [23] <author> Z. Li. </author> <title> Propagating symbolic relations on an interprocedural and hierarchical control flow graph. </title> <type> Technical Report CSci-93-87, </type> <institution> Computer Science Department, University of Minnesota, Minneapolis, MN, </institution> <year> 1993. </year> <month> 17 </month>
Reference-contexts: The array dataflow analysis is built upon the interprocedural scalar reaching-definition chains and the Hierarchical Supergraph <ref> [23] </ref>. Several conventional data dependence tests are also implemented. The more expensive array dataflow analysis is applied only to loops whose parallelizability cannot be determined by the conventional data dependence tests. The preliminary results are shown in Table 2 and Figure 4.
Reference: [24] <author> Z. Li and P.-C. Yew. </author> <title> Practical methods for exact data dependence analysis. </title> <booktitle> In Languages and Compilers for Parallel Computing, </booktitle> <pages> pages 374-401. </pages> <editor> D. Gelernter, A. Nicolau, and D. Padua (Editors), </editor> <publisher> MIT Press, </publisher> <year> 1991. </year>
Reference-contexts: There exist three main approaches to memory disambiguation. The first one, numerical methods, establishes algebraic equations between array subscripts and determines whether the equations are solvable subject to 4 the loop limits and dependence directions <ref> [4, 5, 31, 24, 25, 19, 38] </ref>. Numerical methods normally do not apply to array subscripts and loop limits that contain unknown symbolic terms [34].
Reference: [25] <author> Z. Li, P.-C. Yew, and C.-Q Zhu. </author> <title> An efficient data dependence analysis for parallelizing compilers. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 1(1) </volume> <pages> 26-34, </pages> <month> January </month> <year> 1990. </year>
Reference-contexts: There exist three main approaches to memory disambiguation. The first one, numerical methods, establishes algebraic equations between array subscripts and determines whether the equations are solvable subject to 4 the loop limits and dependence directions <ref> [4, 5, 31, 24, 25, 19, 38] </ref>. Numerical methods normally do not apply to array subscripts and loop limits that contain unknown symbolic terms [34].
Reference: [26] <author> Vadim Maslov. </author> <title> Lazy array data-flow dependence analysis. </title> <booktitle> In Proceedings of Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 331-325, </pages> <month> Jan. </month> <year> 1994. </year>
Reference-contexts: Most works in this category so far do not handle IF statements, symbolic expressions, or routine calls because these complications make the computation of source functions, LWT's, dependence distances, or the operations on constraints more difficult. Recently, Maslov <ref> [26] </ref> extends the previous works in this category by handling certain IF conditions, but he restricts the program to be well structured and to have no multiple exits from structures, which is not the case in many practical programs.
Reference: [27] <author> D.E. Maydan, S.P. Amarasinghe, and M.S. Lam. </author> <title> Array data-flow analysis and its use in array privatization. </title> <booktitle> In Proc. of the 20th ACM Symp. on Principles of Programming Languages, </booktitle> <pages> pages 2-15, </pages> <month> January </month> <year> 1993. </year>
Reference-contexts: Therefore, A is privatizable in loop I. existing algorithms <ref> [27, 22, 37] </ref>, an use of A (jmax) will be deemed as possibly upwards exposed [1, ch 10] in each iteration, and A (jmax) is also deemed as possibly written in the previous iterations. <p> Feautrier [14] suggests to establish a source function for each array use to indicate which definitions will define the value for each distinct array element of the array use reference. Maydan et al <ref> [27, 28] </ref> simplify Feautrier's method by using a Last-Write-Tree (LWT). Duesterwald et al [11] compute the dependence distance for each reaching definition within a loop. Pugh and Wonnacott [32] use a set of constraints to describe array dataflow problems and solve them basically by Fourier-Motzkin variable elimination. <p> Live analysis must be performed for privatized arrays in order to determine whether and which last values of the privatized arrays must be copied out of the DO loop. Previous works have addressed this issue <ref> [22, 37, 27] </ref>. 3.2.2 Loop parallelization The essence of loop parallelization is to prove the absence of loop-carried dependences.
Reference: [28] <author> Dror E. Maydan. </author> <title> Accurate Analysis of Array References. </title> <type> PhD thesis, </type> <institution> Stanford University, </institution> <month> October </month> <year> 1992. </year>
Reference-contexts: Feautrier [14] suggests to establish a source function for each array use to indicate which definitions will define the value for each distinct array element of the array use reference. Maydan et al <ref> [27, 28] </ref> simplify Feautrier's method by using a Last-Write-Tree (LWT). Duesterwald et al [11] compute the dependence distance for each reaching definition within a loop. Pugh and Wonnacott [32] use a set of constraints to describe array dataflow problems and solve them basically by Fourier-Motzkin variable elimination.
Reference: [29] <author> E. W. Myers. </author> <title> A precise interprocedural data-flow algorithm. </title> <booktitle> In Proceedings of 8th Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 219-230, </pages> <month> Jan. </month> <year> 1981. </year>
Reference-contexts: The HSG in this paper is an enhancement of Myers' supergraph <ref> [29] </ref> which is a composition of the flow subgraphs of all routines in a program.
Reference: [30] <author> W Pugh and D Wonnacott. </author> <title> Eliminating false data dependences using the omega test. </title> <booktitle> In ACM SIGPLAN Conf. on Programming Languages Design and Implementation, </booktitle> <pages> pages 140-151, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: The third approach can take IF conditions into account, while the other two do not. Pugh and Wonnacott <ref> [30] </ref> also discuss an extension of the Omega test [31] which computes certain array reaching-definitions for special cases without IF statements. In this paper, we adopt a combination of the array range triple representation and the (in)equality representation to summarize array references. <p> The predicate simplifier is a key part in the handling of predicates. It is invoked by the GAR simplifier or by GAR operations whenever there are changes to predicates. There exist powerful, but rather time-consuming, general methods, such as integer programming, for predicate simplification <ref> [30] </ref>. Currently, for the sake of efficiency, we implement a limited simplifier which evaluates the truth value of the conjunction of two disjunctions or the disjunction of two relational expressions.
Reference: [31] <author> William Pugh. </author> <title> The omega test: a fast and practical integer programming algorithm for dependence analysis. </title> <booktitle> In Supercomputing'91, </booktitle> <month> November </month> <year> 1991. </year>
Reference-contexts: There exist three main approaches to memory disambiguation. The first one, numerical methods, establishes algebraic equations between array subscripts and determines whether the equations are solvable subject to 4 the loop limits and dependence directions <ref> [4, 5, 31, 24, 25, 19, 38] </ref>. Numerical methods normally do not apply to array subscripts and loop limits that contain unknown symbolic terms [34]. <p> The third approach, which is the most general but also the most time consuming, represents the set of referenced array elements by a set of inequalities and equations and uses Fourier-Motzkin pairwise elimination or integer programming to determine the feasibility of the set <ref> [21, 36, 35, 31] </ref>. The third approach can take IF conditions into account, while the other two do not. Pugh and Wonnacott [30] also discuss an extension of the Omega test [31] which computes certain array reaching-definitions for special cases without IF statements. <p> The third approach can take IF conditions into account, while the other two do not. Pugh and Wonnacott [30] also discuss an extension of the Omega test <ref> [31] </ref> which computes certain array reaching-definitions for special cases without IF statements. In this paper, we adopt a combination of the array range triple representation and the (in)equality representation to summarize array references.
Reference: [32] <author> William Pugh and David Wonnacott. </author> <title> An exact method for analysis of value-based array data dependences. </title> <booktitle> In Lecture Notes in Computer Science 768: Sixth Annual Workshop on Programming Languages and Compilers for Parallel Computing, </booktitle> <address> Portland, OR, </address> <month> August </month> <year> 1993. </year> <note> Springer-Verlag. </note>
Reference-contexts: Maydan et al [27, 28] simplify Feautrier's method by using a Last-Write-Tree (LWT). Duesterwald et al [11] compute the dependence distance for each reaching definition within a loop. Pugh and Wonnacott <ref> [32] </ref> use a set of constraints to describe array dataflow problems and solve them basically by Fourier-Motzkin variable elimination.
Reference: [33] <author> Carl Rosene. </author> <title> Incremental dependence analysis. </title> <type> Technical Report CRPC-TR90044, PhD thesis, </type> <institution> Computer Science Department, Rice University, </institution> <month> March </month> <year> 1990. </year>
Reference-contexts: Instead, a set of array elements of a regular shape, called a regular array region or section, is treated as a single unit. Simple set operations such as union, intersection, and difference, are performed on such units. Works by Gross and Steenkiste [16], Rosene <ref> [33] </ref>, Li [22], Tu and Padua [37], and Granston and Veidenbaum [15], can roughly be included in this category. These works do 3 not provide as many details about reaching-definitions as the first category. However, they handle more complex program constructs such as IF statements.
Reference: [34] <author> Z. Shen, Z. Li, and P.-C. Yew. </author> <title> An empirical study of Fortran programs for parallelizing compilers. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 1(3) </volume> <pages> 356-364, </pages> <month> July </month> <year> 1990. </year>
Reference-contexts: Numerical methods normally do not apply to array subscripts and loop limits that contain unknown symbolic terms <ref> [34] </ref>. The second approach, originally proposed to handle call statements, uses array range triples to represent regular array regions which summarize the array elements accessed by one or several references [10, 17, 3, 9].
Reference: [35] <author> R. Triolet, F. Irigoin, and P. Feautrier. </author> <title> Direct parallelization of CALL statments. </title> <booktitle> In ACM SIGPLAN'86 Sym. on Compiler Construction, </booktitle> <pages> pages 176-185, </pages> <month> July </month> <year> 1986. </year>
Reference-contexts: The third approach, which is the most general but also the most time consuming, represents the set of referenced array elements by a set of inequalities and equations and uses Fourier-Motzkin pairwise elimination or integer programming to determine the feasibility of the set <ref> [21, 36, 35, 31] </ref>. The third approach can take IF conditions into account, while the other two do not. Pugh and Wonnacott [30] also discuss an extension of the Omega test [31] which computes certain array reaching-definitions for special cases without IF statements.
Reference: [36] <author> Remi Triolet. </author> <title> Interprocedural analysis for program restructuring with parafrase. </title> <type> Technical Report CSRD Rpt. </type> <institution> No.538, Center for Supercomputing Research and Development, University of Illinois at Urbana-Champaign, </institution> <month> December </month> <year> 1985. </year>
Reference-contexts: The third approach, which is the most general but also the most time consuming, represents the set of referenced array elements by a set of inequalities and equations and uses Fourier-Motzkin pairwise elimination or integer programming to determine the feasibility of the set <ref> [21, 36, 35, 31] </ref>. The third approach can take IF conditions into account, while the other two do not. Pugh and Wonnacott [30] also discuss an extension of the Omega test [31] which computes certain array reaching-definitions for special cases without IF statements.
Reference: [37] <author> Peng Tu and David Padua. </author> <title> Automatic array privatization. </title> <booktitle> In Proceedings of Sixth Workshop on Languages and Compilers for Parallel Computing, </booktitle> <pages> pages 500-521, </pages> <month> August </month> <year> 1993. </year>
Reference-contexts: This percentage indicates the significance of each loop. Array privatization requires a thorough analysis of array data flow and often involves the handling of routine calls. While the effects of IF conditions and CALL statements are shown to be important in practice <ref> [22, 37] </ref>, few existing works handle such cases. The examples in Figure 1 illustrate such cases. In these three examples, privatizing the array A will make it possible to parallelize the I loops. Figure 1 (a) shows a simplified version of a loop from the MDG program (routine interf) [6]. <p> Therefore, A is privatizable in loop I. existing algorithms <ref> [27, 22, 37] </ref>, an use of A (jmax) will be deemed as possibly upwards exposed [1, ch 10] in each iteration, and A (jmax) is also deemed as possibly written in the previous iterations. <p> Simple set operations such as union, intersection, and difference, are performed on such units. Works by Gross and Steenkiste [16], Rosene [33], Li [22], Tu and Padua <ref> [37] </ref>, and Granston and Veidenbaum [15], can roughly be included in this category. These works do 3 not provide as many details about reaching-definitions as the first category. However, they handle more complex program constructs such as IF statements. <p> Live analysis must be performed for privatized arrays in order to determine whether and which last values of the privatized arrays must be copied out of the DO loop. Previous works have addressed this issue <ref> [22, 37, 27] </ref>. 3.2.2 Loop parallelization The essence of loop parallelization is to prove the absence of loop-carried dependences.

References-found: 37

