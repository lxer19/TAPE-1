URL: http://www.cs.bris.ac.uk/Tools/Reports/Ps/1997-bogacz.ps.gz
Refering-URL: http://www.cs.bris.ac.uk/Tools/Reports/Abstracts/1997-bogacz.html
Root-URL: 
Email: Email: bogacz@ci-1.ci.pwr.wroc.pl Email: cgc@cs.bris.ac.uk  
Title: SUPERVISED COMPETITIVE LEARNING FOR FINDING POSITIONS OF RADIAL BASIS FUNCTIONS  
Author: Rafal Bogacz Christophe Giraud-Carrier 
Address: Bristol  
Affiliation: Computer Science and Management Dep. Department of Computer Science Technical University of Wroclaw University of  
Abstract: This paper introduces the magnetic neural gas (MNG) algorithm, which extends unsupervised competitive learning with class information to improve the positioning of radial basis functions. The basic idea of MNG is to discover heterogeneous clusters (i.e., clusters with data from different classes) and to migrate additional neurons towards them. The discovery is effected by a heterogeneity coefficient associated with each neuron and the migration is guided by introducing a kind of magnetic effect. The performance of MNG is tested on a number of data sets, including the thyroid data set. Results demonstrate promise. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> B. Burdsall and C. Giraud-Carrier. </author> <title> Evolving Fuzzy Prototypes for Efficient Data Clustering. </title> <booktitle> In Proc. of the 2nd International ICSC Symposium on Fuzzy Logic and Applications, </booktitle> <pages> 217-223, </pages> <year> 1997. </year>
Reference-contexts: Whilst computing the output weights is relatively easy, finding the optimal positions of the radial basis functions (i.e., the centroids) is difficult. Moreover, it has been shown to have the greatest effect on perfromance <ref> [1] </ref>. Unsupervised learning is not guaranteed to find the optimal solution. Hence many other techniques are used to find centroids, e.g., genetic algorithms [1], orthogonal least squares [2] and dynamic decay adjustment [3]. This paper introduces the magnetic neural gas (MNG) algorithm. <p> Moreover, it has been shown to have the greatest effect on perfromance <ref> [1] </ref>. Unsupervised learning is not guaranteed to find the optimal solution. Hence many other techniques are used to find centroids, e.g., genetic algorithms [1], orthogonal least squares [2] and dynamic decay adjustment [3]. This paper introduces the magnetic neural gas (MNG) algorithm. MNG extends the classical neural gas learning algorithm [4] with class information to improve the positioning of radial basis functions.
Reference: [2] <author> S. Chen, C. Cowan and P. Grant. </author> <title> Recursive Hybrid Algorithm for Nonlinear System Identification Using Radial Basis Function Networks. </title> <journal> International Journal of Control, </journal> <volume> 55 </volume> <pages> 1051-1070, </pages> <year> 1992. </year>
Reference-contexts: Moreover, it has been shown to have the greatest effect on perfromance [1]. Unsupervised learning is not guaranteed to find the optimal solution. Hence many other techniques are used to find centroids, e.g., genetic algorithms [1], orthogonal least squares <ref> [2] </ref> and dynamic decay adjustment [3]. This paper introduces the magnetic neural gas (MNG) algorithm. MNG extends the classical neural gas learning algorithm [4] with class information to improve the positioning of radial basis functions.
Reference: [3] <author> M. Berthold and J. Diamond. </author> <title> Boosting the Performance of RBF Network with Dynamic Decay Adjustment. </title> <editor> In G. Tesauro, D. Touretzky and T. Leen (Eds.), </editor> <booktitle> Advances in Neural Network Information Processing Systems, </booktitle> <volume> 7, </volume> <year> 1995. </year>
Reference-contexts: Moreover, it has been shown to have the greatest effect on perfromance [1]. Unsupervised learning is not guaranteed to find the optimal solution. Hence many other techniques are used to find centroids, e.g., genetic algorithms [1], orthogonal least squares [2] and dynamic decay adjustment <ref> [3] </ref>. This paper introduces the magnetic neural gas (MNG) algorithm. MNG extends the classical neural gas learning algorithm [4] with class information to improve the positioning of radial basis functions.
Reference: [4] <author> M. Martinez, S. Benkovich and K. Schulten. </author> <title> Neural-Gas Networks for Vector Quantization and Its Application to Times Series Prediction. </title> <journal> IEEE Trans. on Neural Networks, </journal> <volume> 4 </volume> <pages> 558-569, </pages> <year> 1993. </year>
Reference-contexts: Unsupervised learning is not guaranteed to find the optimal solution. Hence many other techniques are used to find centroids, e.g., genetic algorithms [1], orthogonal least squares [2] and dynamic decay adjustment [3]. This paper introduces the magnetic neural gas (MNG) algorithm. MNG extends the classical neural gas learning algorithm <ref> [4] </ref> with class information to improve the positioning of radial basis functions. The basic idea of MNG is to discover heterogeneous clusters (i.e., clusters with data from different classes) and to migrate additional neurons towards them. Section 2 reviews the neural gas learning algorithm. Section 3 describes MNG. <p> Section 2 reviews the neural gas learning algorithm. Section 3 describes MNG. Section 4 presents empirical results. Finally, section 5 concludes the paper. 2. NEURAL GAS ALGORITHM The neural gas (NG) learning algorithm <ref> [4] </ref> is one of the most efficient competitive learning algorithms. <p> That is, when the network is quite stable <ref> [4] </ref> and the algorithm behaves as the winner takes all. To achieve this, an additional parameter a is introduced, which changes its value from 0 at the beginning of learning to 1 at the end.
Reference: [5] <author> S.Haykin. </author> <title> Neural Networks: A Comprehensive Foundation. </title> <publisher> Macmillan College Publishing Company, </publisher> <address> New York, </address> <year> 1994. </year>
Reference-contexts: 1. INTRODUCTION Radial basis function (RBF) networks <ref> [5] </ref> are a class of hybrid connectionist models. Whilst they are essentially three-layer feedforward networks, RBF networks differ from classical multilayer perceptrons. In particular, learning is effected by both supervised and unsupervised techniques. <p> Set thyroid - is the data set about thyroid diseases. Input vectors consist of 21 elements, split into 3 classes. The data from the class healthy patient are 92% of all the data. The remaining 8% belong to two classes representing diseases. The two principal components <ref> [5] </ref> of the data and positions of trained neurons are shown in Figure 5. of Neurons Trained by MNG of Neurons Trained by MNG healthy patient disease 1 disease 2 neuron data - class 1 data - class 2 neuron Each data set was divided into a training set and a
References-found: 5

