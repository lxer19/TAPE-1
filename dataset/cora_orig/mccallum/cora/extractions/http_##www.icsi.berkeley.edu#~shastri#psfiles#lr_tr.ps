URL: http://www.icsi.berkeley.edu/~shastri/psfiles/lr_tr.ps
Refering-URL: http://http.icsi.berkeley.edu/~shastri/
Root-URL: http://www.icsi.berkeley.edu
Email: shastri@icsi.berkeley.edu  
Phone: 510.643.9153  
Title: Learning context-sensitive rules in a connectionist system based on temporal synchrony DRAFT DRAFT DRAFT  
Author: Lokendra Shastri 
Address: 1947 Center Street, Suite 600 Berkeley, CA 94704  
Affiliation: International Computer Science Institute  
Abstract: Recently shruti has been proposed as a connectionist model of rapid reasoning. shruti demonstrates how a network of simple neuron-like elements can encode facts and rules involving n-ary predicates, limited quantification, and concept hierarchies and perform a limited class of reasoning with requisite efficiency. In this paper we show how a shruti-like system can learn context-sensitive rules involving n-ary predicates and variables from observations. The solution involves mapping shruti networks to spatio-temporal networks of the sort used for perceptual processing. The solution allows the system to learn the mapping between roles of antecedent and consequent predicates and the combination of features that role fillers must possess for a rule to be applicable in a given situation. An example of such a rule would be: "if the agent x of walk-into has features `animate' and `solid', and the patient y of walk-into has the feature `solid' then walk-into(x,y) ) hurt(x)". The predicates, roles, and fillers can be viewed as being part of the symbolic level of representation. Each context sensitive rule can therefore be viewed as a mapping from the symbolic level to the symbolic level that is mediated by a semantic filter embedded within a subsymbolic level of representation. The primary burden of learning is to acquire the relevant semantic filters via observations. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Ajjanagadde, V. & Shastri, L. </author> <title> (1990) Rules and variables in neural nets, </title> <journal> Neural Computation. </journal> <volume> 3, </volume> <pages> 121-134. </pages>
Reference: <author> Feldman, J. A. </author> <title> (1982) Dynamic connections in neural networks, </title> <journal> Bio-Cybernetics, </journal> <volume> 46 </volume> <pages> 27-39. </pages> <editor> von der Malsburg, C. </editor> <title> (1986) Am I thinking assemblies? In Brain Theory, </title> <editor> ed. G. Palm & A. Aertsen. </editor> <publisher> Springer-Verlag. </publisher>
Reference: <author> Lange, T. E., & Dyer, M. G. </author> <title> (1989) High-level Inferencing in a Connectionist Network. </title> <journal> Connection Science, </journal> <volume> Vol. 1, No. 2, </volume> <pages> 181-217. </pages>
Reference-contexts: Nodes such as John and Mary correspond to focal nodes of a more complex representation of the individual concepts `John' and `Mary' (Shastri 1991). A rule is encoded by linking the roles of the 2 The model shares a number of features with ROBIN <ref> (Lange & Dyer 1989) </ref> which uses signatures instead of temporal synchrony to solve the dynamic binding problem. 3 own (y; z)], 8x; y [own (x; y) ) can-sell (x; y)], and 8x; y [buy (x; y) ) own (x; y)].
Reference: <author> Mani, D.R. & Shastri, L. </author> <title> (1993) Reflexive Reasoning with Multiple-Instantiation in in a Connectionist Reasoning System with a Typed Hierarchy, </title> <journal> Connection Science, </journal> <volume> Vol. 5, No. 3 & 4, </volume> <pages> 205-242. </pages>
Reference: <author> Shastri, L. </author> <title> (1991) Relevance of Connectionism to AI: A representation and reasoning perspective. </title> <booktitle> In Advances in Connectionist and Neural Computation Theory, </booktitle> <volume> vol. </volume> <pages> 1, </pages> <note> ed. J. </note>
Reference-contexts: Nodes such as John and Mary correspond to focal nodes of a more complex representation of the individual concepts `John' and `Mary' <ref> (Shastri 1991) </ref>.
Reference: <author> Barnden and J. </author> <title> Pollack. </title> <publisher> Ablex. </publisher>
Reference: <author> Shastri, L. & Ajjanagadde, V. </author> <title> (1993) From simple associations to systematic reasoning, </title> <journal> Behavioral and Brain Sciences Vol. </journal> <volume> 16, No. 3, </volume> <pages> 417-494. </pages>
Reference-contexts: As discussed in <ref> (Shastri & Ajjanagadde 1993) </ref> reasoning involving n-ary predicates requires a solution to the dynamic binding problem (Feldman 1982; Malsburg 1986). shruti incorporates a neurally plausible solution to this problem. It represents dynamic bindings between a role and a filler by the synchronous firing of the appropriate role and filler nodes. <p> Only aspects of shruti that are relevant to the current work are presented. Other details may be found in <ref> (Shastri & Ajjanagadde 1993) </ref>. shruti encodes an n-ary predicate as a cluster of nodes which includes n role nodes (these are the circular `nodes' shown in Figure 1, the rectangular nodes are not relevant to our discussion). <p> In <ref> (Shastri & Ajjanagadde 1993) </ref> it was shown that such filters can be hard-wired using -btu and t -or nodes if the restrictions on the role fillers are known. In the present work we demonstrate that a shruti-like system can automatically learn such filters from observations. <p> As discussed in <ref> (Shastri & Ajjanagadde 1993) </ref>, the activation of an entity can be viewed as the activation of its handle node and other nodes representing its features and types.
Reference: <author> Watrous, R.L. & Shastri, L. </author> <title> (1987) Learning phonetic features using connectionist networks. </title>
Reference-contexts: We deal with this problem by mapping shruti onto spatio-temporal networks that can explicitly represent temporal information. One such model is the Temporal Flow Model (TFM) <ref> (Watrous & Shastri 1987) </ref> that has been applied to a number of problems in speech recognition Watrous (1990). TFM supports arbitrary link connectivity across layers, admits recurrent links, and allows variable propagation delays to be associated with links.
Reference: <author> R. L. Watrous and L. Shastri, </author> <booktitle> Proceedings of IJCAI-87, the Tenth International Joint Conference on Artificial Intelligence, </booktitle> <address> Milan, Italy, </address> <month> August </month> <year> 1987. </year> <pages> pp. </pages> <month> 851-854. </month> <title> 13 Watrous, R.L. (1990) Phoneme discrimination using connectionist networks. </title> <journal> J. Accoust. Soc. Am. </journal> <volume> 87 (4) 1753-1772. </volume>
Reference-contexts: We deal with this problem by mapping shruti onto spatio-temporal networks that can explicitly represent temporal information. One such model is the Temporal Flow Model (TFM) <ref> (Watrous & Shastri 1987) </ref> that has been applied to a number of problems in speech recognition Watrous (1990). TFM supports arbitrary link connectivity across layers, admits recurrent links, and allows variable propagation delays to be associated with links.
Reference: <author> Watrous, R.L. </author> <year> (1993) </year> <month> gradsim: </month> <title> A connectionist network simulator using gradient optimization techniques. </title> <type> Technical Report LS92-02, </type> <institution> Siemens Research Laboratory, Princeton, NJ. </institution>
Reference-contexts: The interconnection scheme was as described in Section 3.1 Learning was carried out using gradsim | a system for applying nonlinear gradient optimization techniques to train connectionist networks from examples consisting of time-varying input output patterns <ref> (Watrous 1993) </ref>. Barring a few runs in which the network got stuck at an unsatisfactory local minimum, the optimization lead to a desirable network using the second-order gradient descent algorithm, 12 BFGS. An example run consisted of a training set of 257 patterns.
References-found: 10

