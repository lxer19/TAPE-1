URL: http://www.cs.utexas.edu/users/plaxton/ps/1997/jcss.ps
Refering-URL: http://www.cs.utexas.edu/users/plaxton/html/abc.html
Root-URL: 
Title: Breaking the fi(n log 2 n) Barrier for Sorting with Faults a reversal-fault-tolerant sorting network
Author: Tom Leighton Yuan Ma C. Greg Plaxton Feige, Peleg, Raghavan, and 
Date: 1985,  
Note: answering a question posed by Yao and Yao in  
Abstract: In this paper, we study the problem of constructing a sorting circuit, network, or PRAM algorithm that is tolerant to faults. For the most part, we focus on fault patterns that are random, i.e., where the result of each comparison is independently faulty with probability upper-bounded by some constant. All previous fault-tolerant sorting circuits, networks, and parallel algorithms require (log 2 n) depth and/or (n log 2 n) comparisons to sort n items. In this paper, we construct: * a passive-fault-tolerant sorting circuit with O(n log n log log n) comparators, thereby Upfal in 1990. The results are based on a new analysis of the AKS circuit, which uses a much weaker notion of expansion that can be preserved in the presence of faults. Previously, the AKS circuit was not believed to be fault-tolerant because the expansion properties that were believed to be crucial for the performance of the circuit are destroyed by random faults. Extensions of our results for worst-case faults are also presented. 1 Department of Mathematics and Laboratory for Computer Science, Massachusetts Institute of Technology, 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. Ajtai, J. Komlos, and E. Szemeredi. </author> <title> Sorting in c log n parallel steps. </title> <journal> Combinatorica, </journal> <volume> 3 </volume> <pages> 1-19, </pages> <year> 1983. </year> <title> See also the conference version, </title> <booktitle> which appears in Proceedings of the 15th Annual ACM Symposium on the Theory of Computing, </booktitle> <pages> pages 1-9, </pages> <month> May </month> <year> 1983. </year>
Reference-contexts: O (s log n). (Asymptotically, it makes no difference whether or not the replicators are counted towards the size since an optimal network would make a copy of an item only if the item were to be input to a comparator.) When used in conjunction with the AKS sorting circuit <ref> [1] </ref>, this provides a reversal-fault-tolerant or destructive-fault-tolerant sorting network with O (n log 2 n) size. 1 The Assaf-Upfal method proceeds by making fi (log n) copies of each item and replacing each comparator with fi (log n) comparators, followed by a majority-enhancing device that is constructed from expanders. <p> All of these results are based on a surprisingly strong fault-tolerance property of the AKS circuit <ref> [1] </ref>. <p> Finally, in Section 6, we extend our results to worst-case faults. We remark that this paper is combined from the results presented in [11] and [13]. 2 The Analysis of the AKS Circuit In this section, we show that the AKS circuit <ref> [1] </ref> has certain fault-tolerance properties under both the passive and reversal fault models. <p> Such a task was accomplished by using the so-called separator in [16] (and by using the so-called near-sorting circuit in <ref> [1] </ref>). Informally, a separator is slightly more powerful than a halver in the sense that a separator not only moves most of its inputs to the correct half but also moves most of its "extreme" inputs close to the extreme positions. <p> For now, we merely assume that &gt; 1, which can be ensured by a sufficiently large choice of the constant in equation 12. As in [16], we assign each m-input l-AKS tree node a natural interval as follows: the natural interval of the root is <ref> [1; m] </ref>; if the natural interval of a node X is [ff; fi], then the natural 13 intervals of the left and right children of X are the left and right halves of [ff; fi], respectively.
Reference: [2] <author> V. E. Alekseyev. </author> <title> Sorting algorithms with minimum memory. </title> <journal> Kibernetika, </journal> <volume> 5 </volume> <pages> 99-103, </pages> <year> 1969. </year>
Reference-contexts: Theorem 3.2 There exists an explicit construction of a passive-fault-tolerant selection circuit with asymptotically optimal size of fi (n log n). Proof: An (n log n) lower bound on the size of selection circuits was proved by Alekseyev <ref> [2] </ref> even in the fault-free case (see also Theorem A on pages 234-235 of [9]). In what follows, we give a passive-fault-tolerant construction with O (n log n) size.
Reference: [3] <author> N. Alon and J. H. Spencer. </author> <title> The Probabilistic Method. </title> <publisher> Wiley-Interscience, </publisher> <address> New York, NY, </address> <year> 1991. </year>
Reference-contexts: On the other hand, jSj 4l. Hence, the number of ways of choosing the location of S in A is at most 8l 2 3 4l : (18) By a standard Chernoff bound argument <ref> [3] </ref>, when the location of S in A is given, the probability that inequality 17 holds is at most fi (l) (19) for less than a sufficiently small constant (depending on #). <p> A standard application of the Chernoff bound <ref> [3] </ref> now implies that when is less than a sufficiently small constant, the following inequality holds with probability at least 1 fi (l 1is b i1 ) X b 0 2 X b i1 : (21) By the assumption of Case 1, we have P +1 1is (b i1 + b <p> By Lemma 2.1 and a standard Chernoff bound argument <ref> [3] </ref>, we know that the following inequality holds with probability at least 1 fi ( 1is b i2 l) = 1 fi (bl+jRj) provided that is sufficiently small: X b 0 2 X b i2 : (24) Next, we show that at least 4 jRj registers in N (R) contain a <p> To prove that C fl m 7 -approximate-sorts s with high probability, it suffices to show that the marked 1 will be successfully moved to a register with index w with high probability. When is less than a sufficiently small constant, by a standard Chernoff bound argument <ref> [3] </ref>, with probability at least 1 fi (log r) = 1 fi (log m) , at most log r 3 of the 5 log r marked comparators are faulty. <p> In parallel, we apply a (; 1 jY i j )-fault-tolerant EREW sorting algorithm to Y i for each i n. A standard Chernoff bound argument <ref> [3] </ref> shows that the number of unsorted groups of the form Y i is at most n 1 jY i j + n 4 with probability at least 1 e n 2 4 2 .
Reference: [4] <author> S. Assaf and E. Upfal. </author> <title> Fault-tolerant sorting network. </title> <booktitle> In Proceedings of the 31st Annual IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pages 275-284, </pages> <month> October </month> <year> 1990. </year>
Reference-contexts: Since Yao and Yao, many researchers have studied fault-tolerant circuits, networks, and algorithms for sorting-related problems in various models. (See <ref> [4, 6, 7, 12, 13, 18, 19, 20] </ref>.) Despite all of these efforts, the O (log n)-gap between the trivial upper and lower bounds has remained open for Yao and Yao's question for both sorting and merging. <p> That is, a fault pattern of a circuit or network contains all the information needed to specify the functionality of all the comparators in the circuit or network.) Since 1985, several other fault models have also been formulated for the study of fault-tolerant sorting circuits <ref> [4, 13] </ref>. In the reversal fault model, a faulty comparator outputs the two inputs in reversed order regardless of their input order. <p> In order to tolerate 1 destructive and/or reversal faults, Assaf and Upfal <ref> [4] </ref> introduced a new computational model for the study of the sorting problem. In their new model, more than n registers are allowed to sort n items and replicators are used to copy the item stored in one register to another register. <p> For example, a 2-input sorting network with replicators that is tolerant to any single reversal or destructive fault is illustrated in Figure 1. destructive fault. In <ref> [4] </ref>, Assaf and Upfal described a general method for converting any sorting circuit into a reversal-fault-tolerant or destructive-fault-tolerant sorting network. <p> Whether or not there is an alternative approach to fault-tolerance that can avoid the fi (log n) factor blowup in size (even for the much simpler problem of merging) 1 In this paper, as in <ref> [4] </ref>, we assume that the replicators are fault-free. This is not a particularly unreasonable assumption since replicators can be hard-wired and they do not contain any logic elements. <p> This is not a particularly unreasonable assumption since replicators can be hard-wired and they do not contain any logic elements. In fact, some of our results can be extended to handle a model in which replicators are also allowed to fail. 2 was an interesting open question posed in <ref> [4] </ref>. For destructive faults, this question was re-cently answered by Leighton and Ma [12] with an (n log 2 n) lower bound for both merging and sorting. The question concerning reversal-fault-tolerant sorting networks remained open, however. <p> In this paper, we develop a fault-tolerant sorting circuit, network, and PRAM algorithm that beats the fi (n log 2 n) barrier in each of the preceding models, thereby partially or wholly resolving the questions posed by Yao and Yao [20], Assaf and Upfal <ref> [4] </ref>, and Feige et al. [7]. <p> and O (n log n log log n) size, which resolves the question posed by Yao and Yao [20] to within an O (log log n) factor, (ii) a reversal-fault-tolerant sorting network with size O (n log log 2 3 n), which partially resolves the question of Assaf and Upfal <ref> [4] </ref>, and (iii) a fault-tolerant sorting algorithm that runs in O (log n) steps on an O (n)-processor EREW PRAM, which resolves the question of Feige, et al. [7]. All of these results are based on a surprisingly strong fault-tolerance property of the AKS circuit [1]. <p> This provides the first o (n log 2 n)-size reversal-fault-tolerant sorting network, thereby answering the open question posed by Assaf and Upfal <ref> [4] </ref>. In light of a lower bound established in [12, Theorem 2], this result separates the size complexities of sorting networks with reversal and destructive faults. <p> This is the first reversal-fault-tolerant sorting network of o (n log 2 n) size, and it answers the open question posed by Assaf and Upfal <ref> [4] </ref>. As pointed out in the introduction, we will assume (as in [4]) that the replicators are fault-free. This is not a particularly unreasonable assumption since replicators can be hard-wired and they do not contain any logic elements. <p> This is the first reversal-fault-tolerant sorting network of o (n log 2 n) size, and it answers the open question posed by Assaf and Upfal <ref> [4] </ref>. As pointed out in the introduction, we will assume (as in [4]) that the replicators are fault-free. This is not a particularly unreasonable assumption since replicators can be hard-wired and they do not contain any logic elements. <p> Such an O (log n)-input (; 1 n 2 )-reversal-fault-tolerant sorting network can be constructed by using the Assaf-Upfal method <ref> [4] </ref> with some modifications. Let C be an O (log n)-input sorting circuit with O (log log n) depth, e.g., let C be an AKS circuit with O (log n) inputs. <p> Also, replace each comparator between r i and r j by s comparators that connect r ik and r jk for each k s. After each set of comparators that correspond to a single level in C, apply the expander-like construction of the so-called majority preserver designed in <ref> [4] </ref> to each of the blocks. For any fixed constant r &lt; 1, by carefully choosing the parameters involved in the majority preservers, we can use the argument of [4] to show that with probability at least 1 1 2n 2 , for all i, more than rs of the items <p> of comparators that correspond to a single level in C, apply the expander-like construction of the so-called majority preserver designed in <ref> [4] </ref> to each of the blocks. For any fixed constant r &lt; 1, by carefully choosing the parameters involved in the majority preservers, we can use the argument of [4] to show that with probability at least 1 1 2n 2 , for all i, more than rs of the items contained in R i are the same as that contained in r i in the fault-free case. <p> The details of the construction and its proof of correctness can be found in <ref> [4] </ref>. <p> n processors and P contains at most n + jSj = O (n 3 4 ) items, we can sort P with probability at least 1 1 n 2 by simulating the m-input, O (log m)-time, and O (m log m)-register (; fi (log m) )-destructive-fault-tolerant sorting network designed in <ref> [4] </ref> with m = n + jSj. Based on the sorted order of P , we can derive the approximately correct position for each item in S. <p> unsorted groups is at most O (n 3 3 3+fi Since we have n processors to sort the O (n 3+fi 4 ) unsorted numbers, we can proceed by simulating the m-input, O (log m)-time, and O (m log m)-register (; fi (log m ))-destructive-fault tolerant sorting network designed in <ref> [4] </ref> with m = O (n 3+fi 4 ), which succeeds with probability at least 1 1 n 2 , It is easy to see that the failure probability of the whole algorithm is O ( 1 n 2 ) 1 n . <p> Proof: See [8, Lemma 3.2]. Proof of Theorem 6.5: We first apply the k-approximate-sorting circuit in Theorem 6.4. Then, we use the Assaf-Upfal <ref> [4] </ref> technique followed by n r-MAJORITY networks with O (k) inputs each, as described in Lemma 6.7, for some constant r 2 ( 1 2 ; 1).
Reference: [5] <author> K. E. Batcher. </author> <title> Sorting networks and their applications. </title> <booktitle> In Proceedings of the AFIPS Spring Joint Computer Conference, </booktitle> <volume> volume 32, </volume> <pages> pages 307-314, </pages> <year> 1968. </year>
Reference-contexts: In [16, Section 6], this was handled using Batcher's sorting circuit <ref> [5] </ref>. In our application of the AKS circuit, however, we never need to run the AKS circuit all the way to completion.
Reference: [6] <author> P. Donejko, K. Diks, A. Pelc, and M. Piotrow. </author> <title> Reliable minimum finding comparator networks. </title> <editor> In I. Prvara, B. Rovan, and P. Ruzicka, editors, </editor> <booktitle> Proceedings of the 19th Symposium on Mathematical Foundations of Computer Science (Kosice, </booktitle> <address> Slovakia, </address> <month> August </month> <year> 1995), </year> <pages> LNCS 841, pages 306-315, </pages> <address> New York, 1994. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: Since Yao and Yao, many researchers have studied fault-tolerant circuits, networks, and algorithms for sorting-related problems in various models. (See <ref> [4, 6, 7, 12, 13, 18, 19, 20] </ref>.) Despite all of these efforts, the O (log n)-gap between the trivial upper and lower bounds has remained open for Yao and Yao's question for both sorting and merging. <p> In particular, we will need circuits that isolate extreme items into a small group of registers. Such circuits can be built by adapting the fault-tolerant minimum-finding algorithm of [7] (see Lemma 5.1), or by adapting the passive-fault-tolerant minimum-finding circuit of <ref> [6] </ref>. The details are not simple and are omitted from this paper. Acknowledgements The authors would like to thank Yiqun Yin for suggesting the use of the probabilistic method for a particular problem that arose in the early stages of this research.
Reference: [7] <author> U. Feige, D. Peleg, P. Raghavan, and E. Upfal. </author> <title> Computing with unreliable information. </title> <booktitle> In Proceedings of the 22nd Annual ACM Symposium on the Theory of Computing, </booktitle> <pages> pages 128-137, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: Since Yao and Yao, many researchers have studied fault-tolerant circuits, networks, and algorithms for sorting-related problems in various models. (See <ref> [4, 6, 7, 12, 13, 18, 19, 20] </ref>.) Despite all of these efforts, the O (log n)-gap between the trivial upper and lower bounds has remained open for Yao and Yao's question for both sorting and merging. <p> n even if an answer to any comparison query is incorrect with probability upper bounded by a constant strictly less than 1 2 . (Note that when the fault probability is equal to 1 2 , we cannot obtain any useful information from a comparison.) Feige, Peleg, Raghavan, and Upfal <ref> [7] </ref> designed a randomized fault-tolerant sorting algorithm that uses O (log n) expected time on an O (n)-processor CREW PRAM. They left open the question of whether or not there is a deterministic fault-tolerant sorting algorithm that runs in o (log 2 n) steps on O (n) processors. <p> In this paper, we develop a fault-tolerant sorting circuit, network, and PRAM algorithm that beats the fi (n log 2 n) barrier in each of the preceding models, thereby partially or wholly resolving the questions posed by Yao and Yao [20], Assaf and Upfal [4], and Feige et al. <ref> [7] </ref>. <p> a reversal-fault-tolerant sorting network with size O (n log log 2 3 n), which partially resolves the question of Assaf and Upfal [4], and (iii) a fault-tolerant sorting algorithm that runs in O (log n) steps on an O (n)-processor EREW PRAM, which resolves the question of Feige, et al. <ref> [7] </ref>. All of these results are based on a surprisingly strong fault-tolerance property of the AKS circuit [1]. <p> The main result in this section is a fault-tolerant EREW PRAM sorting algorithm that runs in optimal fi (log n) time on n processors. This answers an open question posed by Feige, Peleg, Raghavan, and Upfal <ref> [7] </ref>. The only previously known o (log 2 n) time fault-tolerant PRAM sorting algorithm on n processors is a randomized algorithm [7]. Theorem 5.1 There exists an explicit deterministic fault-tolerant EREW PRAM sorting algorithm with fi (log n) running time on n processors. <p> This answers an open question posed by Feige, Peleg, Raghavan, and Upfal <ref> [7] </ref>. The only previously known o (log 2 n) time fault-tolerant PRAM sorting algorithm on n processors is a randomized algorithm [7]. Theorem 5.1 There exists an explicit deterministic fault-tolerant EREW PRAM sorting algorithm with fi (log n) running time on n processors. The following lemma is due to Feige, Peleg, Raghavan, and Upfal [7]. Lemma 5.1 ([7]) There exists an explicit deterministic (; fi (log m) )-fault-tolerant EREW PRAM algorithm that <p> known o (log 2 n) time fault-tolerant PRAM sorting algorithm on n processors is a randomized algorithm <ref> [7] </ref>. Theorem 5.1 There exists an explicit deterministic fault-tolerant EREW PRAM sorting algorithm with fi (log n) running time on n processors. The following lemma is due to Feige, Peleg, Raghavan, and Upfal [7]. Lemma 5.1 ([7]) There exists an explicit deterministic (; fi (log m) )-fault-tolerant EREW PRAM algorithm that selects the maximum of m items in fi (log m) time on m processors. Proof: See [7, Theorem 20]. <p> The following lemma is due to Feige, Peleg, Raghavan, and Upfal [7]. Lemma 5.1 ([7]) There exists an explicit deterministic (; fi (log m) )-fault-tolerant EREW PRAM algorithm that selects the maximum of m items in fi (log m) time on m processors. Proof: See <ref> [7, Theorem 20] </ref>. Proof of Theorem 5.1: We use the approach of Theorem 3.1, with modifications to achieve the claimed fi (log n) running time (recall that the depth bound in Theorem 3.1 is O (log n log log n)). <p> Given Yao and Yao's lemma, we can construct circuits, networks, and algorithms by an approach used in [13]. In particular, we will need circuits that isolate extreme items into a small group of registers. Such circuits can be built by adapting the fault-tolerant minimum-finding algorithm of <ref> [7] </ref> (see Lemma 5.1), or by adapting the passive-fault-tolerant minimum-finding circuit of [6]. The details are not simple and are omitted from this paper.
Reference: [8] <author> D. Kleitman, T. Leighton, and Y. Ma. </author> <title> On the design of Boolean circuits that contain partially unreliable gates. </title> <booktitle> In Proceedings of the 35th Annual IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pages 332-346, </pages> <month> November </month> <year> 1994. </year>
Reference-contexts: Proof: See <ref> [8, Lemma 3.2] </ref>. Proof of Theorem 4.4: Our network consists of two parts. <p> Lemma 6.7 ([8]) There exists an explicit construction of a k-reversal-fault-tolerant network with O (k log 2 3 ) size that computes the r-MAJORITY function with O (k) inputs for some con stant r 2 ( 1 2 ; 1). Proof: See <ref> [8, Lemma 3.2] </ref>. Proof of Theorem 6.5: We first apply the k-approximate-sorting circuit in Theorem 6.4. Then, we use the Assaf-Upfal [4] technique followed by n r-MAJORITY networks with O (k) inputs each, as described in Lemma 6.7, for some constant r 2 ( 1 2 ; 1).
Reference: [9] <author> D. E. Knuth. </author> <title> The Art of Computer Programming, Volume 3: Sorting and Searching. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1973. </year>
Reference-contexts: Finally, we point out that all of the comparators used in the constructions of our circuits and networks move the small input to the top register and the large input to the bottom register. Following the notation of Knuth <ref> [9] </ref>, this means that all of our circuits and networks are standard. All of our lower bounds are proved for the general case, i.e., we do not assume that the circuit is standard in the lower bound proofs. <p> In the fault-free case, it has been proved that any non-standard sorting circuit can be converted into a standard sorting circuit with the same depth and size (see Exercise 16 on page 239 of <ref> [9] </ref>). However, we do not know if a similar result is true when the circuit is subject to passive faults. The remainder of the paper is organized as follows. In Section 2, we prove that the AKS circuit has certain useful fault-tolerance properties. <p> It is well known that such a circuit of 2l levels sorts all 2l-input permutations in the fault-free case (for example, see <ref> [9] </ref>). In this paper, we are interested in fault-tolerance properties of various circuits and will use odd-even transposition circuits with more than 2l levels. <p> Proof: An (n log n) lower bound on the size of selection circuits was proved by Alekseyev [2] even in the fault-free case (see also Theorem A on pages 234-235 of <ref> [9] </ref>). In what follows, we give a passive-fault-tolerant construction with O (n log n) size. Let ff be the constant of Lemma 3.2, and let &lt; 1 be a constant upper bound on the failure probability of each comparator.
Reference: [10] <author> T. Leighton. </author> <title> Introduction to Parallel Algorithms and Architectures: Arrays, Trees, and Hypercubes. </title> <publisher> Morgan-Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1992. </year>
Reference-contexts: 1 Introduction Sorting circuits have intrigued and challenged computer scientists for decades. They have also proved to be very useful for a variety of applications, including circuit switching and packet routing <ref> [10] </ref>. In this paper, we study the problem of constructing sorting circuits that are tolerant to a potentially large number of faults. The study of fault-tolerant sorting circuits was initiated by Yao and Yao [20] in 1985.
Reference: [11] <author> T. Leighton and Y. Ma. </author> <title> Breaking the fi(n log 2 n) barrier for sorting with faults. </title> <booktitle> In Proceedings of the 34th Annual IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pages 734-743, </pages> <month> November </month> <year> 1993. </year>
Reference-contexts: In Section 4, we describe the reversal-fault-tolerant approximate-sorting circuits and sorting networks. In Section 5, we describe the fault-tolerant PRAM sorting algorithm. Finally, in Section 6, we extend our results to worst-case faults. We remark that this paper is combined from the results presented in <ref> [11] </ref> and [13]. 2 The Analysis of the AKS Circuit In this section, we show that the AKS circuit [1] has certain fault-tolerance properties under both the passive and reversal fault models.
Reference: [12] <author> T. Leighton and Y. Ma. </author> <title> Tight bounds on the size of fault-tolerant merging and sorting networks with destructive faults. </title> <booktitle> In Proceedings of the 5th Annual ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 30-41, </pages> <month> July </month> <year> 1993. </year>
Reference-contexts: Since Yao and Yao, many researchers have studied fault-tolerant circuits, networks, and algorithms for sorting-related problems in various models. (See <ref> [4, 6, 7, 12, 13, 18, 19, 20] </ref>.) Despite all of these efforts, the O (log n)-gap between the trivial upper and lower bounds has remained open for Yao and Yao's question for both sorting and merging. <p> In fact, some of our results can be extended to handle a model in which replicators are also allowed to fail. 2 was an interesting open question posed in [4]. For destructive faults, this question was re-cently answered by Leighton and Ma <ref> [12] </ref> with an (n log 2 n) lower bound for both merging and sorting. The question concerning reversal-fault-tolerant sorting networks remained open, however. The problem of sorting with faults has also been studied in the PRAM model of computation. <p> This provides the first o (n log 2 n)-size reversal-fault-tolerant sorting network, thereby answering the open question posed by Assaf and Upfal [4]. In light of a lower bound established in <ref> [12, Theorem 2] </ref>, this result separates the size complexities of sorting networks with reversal and destructive faults. In all of the upper bound results of this section (except Lemma 4.4), we will need the assumption that is less than a sufficiently small constant. <p> Solving this recurrence, we find that T (n) = O (log n). 6 Worst-Case Fault-Tolerance In this section, we extend our results for random faults to construct worst-case fault-tolerant sorting circuits, networks, and algorithms. All previous work on worst-case faults seems to have focused on passive or destructive faults <ref> [12, 18, 19, 20] </ref>. We are not aware of any previous work on sorting networks that are tolerant to worst-case reversal faults, and no results were known for PRAM sorting algorithms that are tolerant to worst-case faults. <p> Then, we prove a lower bound on the depth of any k-reversal-fault-tolerant k-approximate-sorting circuit. The most important result in Section 6.2 is the construction of a k-reversal-fault-tolerant k-approximate-sorting network with nontrivial size and depth. In light of a lower bound established in <ref> [12, Theorem 1] </ref>, this result separates the size complexities of sorting networks with worst-case reversal and destructive faults. Theorem 6.2 For any k &lt; n, there is no k-reversal-fault-tolerant (k1)-approximate-sorting circuit. Proof: See Appendix C. Theorem 6.3 Any k-reversal-fault-tolerant k-approximate-sorting circuit has (k log n k ) depth.
Reference: [13] <author> T. Leighton, Y. Ma, and C. G. Plaxton. </author> <title> Highly fault-tolerant sorting circuits. </title> <booktitle> In Proceedings of the 32nd Annual IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pages 458-469, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: Since Yao and Yao, many researchers have studied fault-tolerant circuits, networks, and algorithms for sorting-related problems in various models. (See <ref> [4, 6, 7, 12, 13, 18, 19, 20] </ref>.) Despite all of these efforts, the O (log n)-gap between the trivial upper and lower bounds has remained open for Yao and Yao's question for both sorting and merging. <p> One approach to narrowing the O (log n)-gap was investigated by Leighton, Ma, and Plaxton <ref> [13] </ref>, who constructed an O (n log n log log n) size circuit that sorts any permutation with probability at least 1 1 n . <p> In other words, for a randomly generated fault pattern, there are likely to be some input permutations for which the circuit of <ref> [13] </ref> fails to sort. (Formally, a fault pattern completely specifies which comparators, if any, are faulty and how they are faulty. <p> That is, a fault pattern of a circuit or network contains all the information needed to specify the functionality of all the comparators in the circuit or network.) Since 1985, several other fault models have also been formulated for the study of fault-tolerant sorting circuits <ref> [4, 13] </ref>. In the reversal fault model, a faulty comparator outputs the two inputs in reversed order regardless of their input order. <p> In Section 4, we describe the reversal-fault-tolerant approximate-sorting circuits and sorting networks. In Section 5, we describe the fault-tolerant PRAM sorting algorithm. Finally, in Section 6, we extend our results to worst-case faults. We remark that this paper is combined from the results presented in [11] and <ref> [13] </ref>. 2 The Analysis of the AKS Circuit In this section, we show that the AKS circuit [1] has certain fault-tolerance properties under both the passive and reversal fault models. <p> After these two steps, all items are within O (n ff ) of the correct position, for some constant ff &lt; 1, and we can complete the sort recursively. Given the fault-tolerance of the partial l-AKS circuit, our construction is slightly simpler than that of <ref> [13] </ref>: we do not need a subcircuit to isolate the extreme items. More importantly, by using the fault-tolerance properties of the partial l-AKS circuit, we can prove that our circuit works on all input permutations, whereas the circuit in [13] only works for any fixed input permutation (or most input permutations). <p> partial l-AKS circuit, our construction is slightly simpler than that of <ref> [13] </ref>: we do not need a subcircuit to isolate the extreme items. More importantly, by using the fault-tolerance properties of the partial l-AKS circuit, we can prove that our circuit works on all input permutations, whereas the circuit in [13] only works for any fixed input permutation (or most input permutations). (For a detailed discussion of this aspect, see [13].) The basic approach in this section will be used again later in the paper to construct other fault-tolerant circuits, networks, and algorithms for sorting-related problems. <p> More importantly, by using the fault-tolerance properties of the partial l-AKS circuit, we can prove that our circuit works on all input permutations, whereas the circuit in <ref> [13] </ref> only works for any fixed input permutation (or most input permutations). (For a detailed discussion of this aspect, see [13].) The basic approach in this section will be used again later in the paper to construct other fault-tolerant circuits, networks, and algorithms for sorting-related problems. We first prove two lemmas before proving Theorem 3.1. <p> Even though Yao and Yao considered passive faults only, their proof can actually be extended to deal with reversal faults. Given Yao and Yao's lemma, we can construct circuits, networks, and algorithms by an approach used in <ref> [13] </ref>. In particular, we will need circuits that isolate extreme items into a small group of registers. Such circuits can be built by adapting the fault-tolerant minimum-finding algorithm of [7] (see Lemma 5.1), or by adapting the passive-fault-tolerant minimum-finding circuit of [6].
Reference: [14] <author> T. Leighton and B. Maggs. </author> <title> Expanders might be practical: Fast algorithms for routing around faults in multibutterflies. </title> <booktitle> In Proceedings of the 30th Annual IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pages 458-469, </pages> <month> October </month> <year> 1990. </year>
Reference-contexts: A similar potential function was used in <ref> [14] </ref> to prove certain fault-tolerance properties of the multibutterfly circuit for routing. Unfortunately, our use of the potential function here is much more complex than that in [14]. <p> A similar potential function was used in <ref> [14] </ref> to prove certain fault-tolerance properties of the multibutterfly circuit for routing. Unfortunately, our use of the potential function here is much more complex than that in [14]. The next theorem provides an upper bound on the number of strange items and as such is analogous to inequality 2 in [16].
Reference: [15] <author> A. Lubotzky, R. Phillips, and P. Sarnak. </author> <title> Ramanujan graphs. </title> <journal> Combinatorica, </journal> <volume> 8 </volume> <pages> 261-277, </pages> <year> 1988. </year>
Reference-contexts: Explicit constructions of expanders can be found in <ref> [15] </ref>.) Assign each vertex in A to a register in the top half of the circuit, and assign each vertex in B to a register in the bottom half of the circuit. Partition the edges of the expander into d disjoint matchings.
Reference: [16] <author> M. S. Paterson. </author> <title> Improved sorting networks with O(log N ) depth. </title> <journal> Algorithmica, </journal> <volume> 5 </volume> <pages> 75-92, </pages> <year> 1990. </year>
Reference-contexts: In Section 2.2.1, we describe a (slight) modification of the AKS circuit described by Paterson in <ref> [16] </ref>. In particular, we modify some parameter choice, and replace the so-called separators of [16] by a new family of building blocks that we call partitioners. <p> In Section 2.2.1, we describe a (slight) modification of the AKS circuit described by Paterson in <ref> [16] </ref>. In particular, we modify some parameter choice, and replace the so-called separators of [16] by a new family of building blocks that we call partitioners. In Section 2.2.2, we further modify the AKS circuit into an l-AKS circuit, where l is a parameter to be specified later that corresponds to the amount of fault-tolerance attained by the circuit. <p> In particular, an extremely large constant (much larger than the previously best known constant for the AKS circuit) is hidden behind the O-notation for all of our circuits, networks, and algorithms. 2.2.1 The AKS Circuit In this section, we describe Paterson's version of the AKS circuit <ref> [16] </ref>. For simplicity, we closely follow the description in [16] whenever possible. In particular, we use the same letters to denote the same parameters as in [16] unless otherwise specified. At a high level, the AKS circuit is structured around a complete binary tree. <p> constant (much larger than the previously best known constant for the AKS circuit) is hidden behind the O-notation for all of our circuits, networks, and algorithms. 2.2.1 The AKS Circuit In this section, we describe Paterson's version of the AKS circuit <ref> [16] </ref>. For simplicity, we closely follow the description in [16] whenever possible. In particular, we use the same letters to denote the same parameters as in [16] unless otherwise specified. At a high level, the AKS circuit is structured around a complete binary tree. <p> O-notation for all of our circuits, networks, and algorithms. 2.2.1 The AKS Circuit In this section, we describe Paterson's version of the AKS circuit <ref> [16] </ref>. For simplicity, we closely follow the description in [16] whenever possible. In particular, we use the same letters to denote the same parameters as in [16] unless otherwise specified. At a high level, the AKS circuit is structured around a complete binary tree. For ease of notation, we will refer to the tree to be defined as the AKS tree and refer to each of its nodes as an AKS tree node. <p> Note that " 0 has nothing to do with the parameter " of <ref> [16] </ref>, and it is used only to bound away from 43 48 . In [16], was first chosen to be exactly 43 48 , and later was slightly increased after the effect of "integer rounding" was considered. The particular choice of " 0 is not important. <p> Note that " 0 has nothing to do with the parameter " of <ref> [16] </ref>, and it is used only to bound away from 43 48 . In [16], was first chosen to be exactly 43 48 , and later was slightly increased after the effect of "integer rounding" was considered. The particular choice of " 0 is not important. <p> to be defined in the next part of Section 2.2.1): FL (far-left), CL (center-left), CR (center-right), and FR (far-right) so that jFLj = jFRj = min ( 2 jXj ) and jCLj = jCRj = jXj jFLj; where = 2A 2A = 8 6 fi 10 2 : (6) (In <ref> [16] </ref>, was first set to 1=8 and then slightly increased after the effect of "integer rounding" was considered.) Then, FL [ FR are sent up to the parent of X, and CL and CR are sent down to the left and right child of X, respectively. <p> When the capacity of the root becomes so small (i.e., smaller than a certain constant) that we are about to split the AKS tree into two (unconnected) subtrees, special care is needed to guarantee the performance of the AKS circuit. In <ref> [16, Section 6] </ref>, this was handled using Batcher's sorting circuit [5]. In our application of the AKS circuit, however, we never need to run the AKS circuit all the way to completion. <p> Such a task was accomplished by using the so-called separator in <ref> [16] </ref> (and by using the so-called near-sorting circuit in [1]). Informally, a separator is slightly more powerful than a halver in the sense that a separator not only moves most of its inputs to the correct half but also moves most of its "extreme" inputs close to the extreme positions. <p> Since, as discussed in Section 2.1, we cannot build "-halvers that are both efficient and fault-tolerant, we cannot construct efficient and fault-tolerant separators either. In <ref> [16] </ref>, "-halvers and separators are defined in terms of their functionality. The procedure given for building an "-halver from an expander, and for building a separator from "-halvers, represents only one of many possible constructions. In this paper, we will be interested in the specific construction given in [16], although the <p> In <ref> [16] </ref>, "-halvers and separators are defined in terms of their functionality. The procedure given for building an "-halver from an expander, and for building a separator from "-halvers, represents only one of many possible constructions. In this paper, we will be interested in the specific construction given in [16], although the construction will likely fail to have the properties needed to be "-halvers or separators once faults are introduced. <p> +1 ; )-expander to connect the top half and the bottom half of the m registers in the same fashion as we used to construct the "-halver in Section 2.1. 4 Comparing our -divider with an "-halver, we see that plays a role similar to that of 1 " in <ref> [16] </ref>. In [16], " was set to a particular (small) value. In this paper, however, we will only show the existence of a sufficiently large constant that will ensure certain fault-tolerance properties of the AKS circuit. <p> )-expander to connect the top half and the bottom half of the m registers in the same fashion as we used to construct the "-halver in Section 2.1. 4 Comparing our -divider with an "-halver, we see that plays a role similar to that of 1 " in <ref> [16] </ref>. In [16], " was set to a particular (small) value. In this paper, however, we will only show the existence of a sufficiently large constant that will ensure certain fault-tolerance properties of the AKS circuit. <p> In this paper, however, we will only show the existence of a sufficiently large constant that will ensure certain fault-tolerance properties of the AKS circuit. Such a constant appears to be much larger than the value of 1 " that was chosen in <ref> [16] </ref>. Given the construction of a divider, an m-input ( 0 ; )-partitioner at an AKS tree node X is then constructed by applying -dividers in at most 1 + log 1 0 rounds: We first apply an m-input -divider to all m registers. <p> Thus, top (resp., bottom) in a circuit corresponds to left (resp., right) in the AKS tree. 10 When X is partially full, our construction of a partitioner differs slightly from that of a separator in <ref> [16] </ref>: (i) the number of rounds of dividers used in our partitioner depends on cap (X), and may be less than 1 + log 1 0 , and (ii) we do not use the so-called "virtual elements" which were used in Paterson's separator construction to fill X to its capacity so <p> Although our partitioner (resp., divider) construction is (almost) the same as the separator (resp., halver) construction of <ref> [16] </ref>, a partitioner (resp., divider) is conceptually different from a separator (resp., halver) in that a separator (resp., halver) is defined based on its input-output behavior and a partitioner (resp., divider) is explicitly constructed from bipartite expanders. <p> Integer Rounding Thus far, in the description of register movement, we have specified the "ideal" sizes of various sets of registers as real numbers. In reality, we need to choose such sizes as integers. This can be accomplished by the simple technique introduced in <ref> [16] </ref> as follows. We first let each ideally empty AKS tree node be actually empty. Next, we consider an arbitrary nonempty AKS tree node X. Let T X be the subtree rooted at X. <p> Therefore, we conclude that we can indeed maintain the relationship of equation 9 without letting X contain a negative number of registers. We point out that, the parameters, 16 and 64, in the preceding paragraph are chosen differently from those of <ref> [16] </ref>. In particular, we have defined Z (x) to be a multiple of 16. This ensures that each of the dividers in our partitioner construction has an even number of inputs, as desired. <p> This ensures that each of the dividers in our partitioner construction has an even number of inputs, as desired. This should be compared with Paterson's use of the so-called "virtual elements" in his separator construction when the number of inputs to the separator is not divisible by 16 <ref> [16, pages 83-84] </ref>. Finally, we remark that the capacities of the AKS tree nodes are untouched in our integer rounding scheme, i.e., they remain fractional. Thus, an AKS tree node X may be slightly overloaded up to an additive constant, due to the effect of integer rounding. <p> We first choose a few more parameters and introduce some notation that will be useful in the statement and proof of our main theorem. As in <ref> [16] </ref>, we choose = 36 Instead of using the parameter ffi as in [16], we use a parameter such that = 65 4A 2A ) : (12) In a certain sense, our parameter corresponds to the parameter 1 ffi in [16]. <p> We first choose a few more parameters and introduce some notation that will be useful in the statement and proof of our main theorem. As in <ref> [16] </ref>, we choose = 36 Instead of using the parameter ffi as in [16], we use a parameter such that = 65 4A 2A ) : (12) In a certain sense, our parameter corresponds to the parameter 1 ffi in [16]. <p> As in <ref> [16] </ref>, we choose = 36 Instead of using the parameter ffi as in [16], we use a parameter such that = 65 4A 2A ) : (12) In a certain sense, our parameter corresponds to the parameter 1 ffi in [16]. As we have said in Section 2.2.1, we will only prove that a sufficiently large is good for our purposes, and we will not specify a particular choice of . As a consequence, we will not specify the choice of either. <p> As a consequence, we will not specify the choice of either. For now, we merely assume that &gt; 1, which can be ensured by a sufficiently large choice of the constant in equation 12. As in <ref> [16] </ref>, we assign each m-input l-AKS tree node a natural interval as follows: the natural interval of the root is [1; m]; if the natural interval of a node X is [ff; fi], then the natural 13 intervals of the left and right children of X are the left and right <p> Unfortunately, our use of the potential function here is much more complex than that in [14]. The next theorem provides an upper bound on the number of strange items and as such is analogous to inequality 2 in <ref> [16] </ref>. Recall that, as discussed in Section 2.2, the capacity of an l-AKS tree node is the number of registers (not the number of blocks) in the node. <p> Inequality 31 gives an upper bound on the ratio of the number of items at node Y with strangeness j or more to the capacity of Y , and it will be useful when we upper bound the number of strange items inductively. (It is analogous to inequality 2 in <ref> [16] </ref>.) On the other hand, by the assumption that P (X) &gt; cap (X) and equation 30, X X k k1 &gt; cap (X); where X k denotes the number of k-strange items in X. <p> Then, we prove that these properties can be satisfied with probability at most fi (l log m) . We will consider two cases: k = 1 and k &gt; 1. The case k = 1 is the hard case in <ref> [16] </ref> and proceeds without much additional work once we have Lemma 2.2. Unfortunately, the case k &gt; 1 requires much more work than its fault-free counterpart in [16]. Case 1: k = 1. <p> We will consider two cases: k = 1 and k &gt; 1. The case k = 1 is the hard case in <ref> [16] </ref> and proceeds without much additional work once we have Lemma 2.2. Unfortunately, the case k &gt; 1 requires much more work than its fault-free counterpart in [16]. Case 1: k = 1. At the beginning of the first stage, all items are either at the root or the cold storage, and nothing is strange. Hence, our choice of t guarantees t 2. <p> 37: 2A cap (X) 2 ) cap (X) : (38) Now, adding the quantities in equations 34, 35, and 38, we obtain an upper bound for X 1 in equation 33: X 1 - 2A cap (X) 2 ) cap (X) + 2A (We remark that a corresponding formula in <ref> [16] </ref> contains a term of cap (X) A, which does not appear in our formula.
Reference: [17] <author> N. Pippenger. </author> <title> On networks of noisy gates. </title> <booktitle> In Proceedings of the 26th Annual IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pages 30-36, </pages> <month> October </month> <year> 1985. </year> <month> 59 </month>
Reference-contexts: These fault-tolerance properties will be the cornerstone for most of the fault-tolerant sorting circuits, networks, and algorithms in the paper. 2 A detailed discussion of this phenomena in the context of Boolean circuits with noisy gates can be found in <ref> [17] </ref>. We believe that our new analysis of the AKS circuit is of separate interest in its own right.
Reference: [18] <author> L. Rudolph. </author> <title> A robust sorting network. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 34 </volume> <pages> 344-354, </pages> <year> 1985. </year>
Reference-contexts: Since Yao and Yao, many researchers have studied fault-tolerant circuits, networks, and algorithms for sorting-related problems in various models. (See <ref> [4, 6, 7, 12, 13, 18, 19, 20] </ref>.) Despite all of these efforts, the O (log n)-gap between the trivial upper and lower bounds has remained open for Yao and Yao's question for both sorting and merging. <p> Solving this recurrence, we find that T (n) = O (log n). 6 Worst-Case Fault-Tolerance In this section, we extend our results for random faults to construct worst-case fault-tolerant sorting circuits, networks, and algorithms. All previous work on worst-case faults seems to have focused on passive or destructive faults <ref> [12, 18, 19, 20] </ref>. We are not aware of any previous work on sorting networks that are tolerant to worst-case reversal faults, and no results were known for PRAM sorting algorithms that are tolerant to worst-case faults.
Reference: [19] <author> M. Schimmler and C. Starke. </author> <title> A correction network for N -sorter. </title> <journal> SIAM J. Comput., </journal> <volume> 18 </volume> <pages> 1179-1187, </pages> <year> 1989. </year>
Reference-contexts: Since Yao and Yao, many researchers have studied fault-tolerant circuits, networks, and algorithms for sorting-related problems in various models. (See <ref> [4, 6, 7, 12, 13, 18, 19, 20] </ref>.) Despite all of these efforts, the O (log n)-gap between the trivial upper and lower bounds has remained open for Yao and Yao's question for both sorting and merging. <p> Solving this recurrence, we find that T (n) = O (log n). 6 Worst-Case Fault-Tolerance In this section, we extend our results for random faults to construct worst-case fault-tolerant sorting circuits, networks, and algorithms. All previous work on worst-case faults seems to have focused on passive or destructive faults <ref> [12, 18, 19, 20] </ref>. We are not aware of any previous work on sorting networks that are tolerant to worst-case reversal faults, and no results were known for PRAM sorting algorithms that are tolerant to worst-case faults.
Reference: [20] <author> A. C. Yao and F. F. Yao. </author> <title> On fault-tolerant networks for sorting. </title> <journal> SIAM J. Comput., </journal> <volume> 14 </volume> <pages> 120-128, </pages> <year> 1985. </year>
Reference-contexts: In this paper, we study the problem of constructing sorting circuits that are tolerant to a potentially large number of faults. The study of fault-tolerant sorting circuits was initiated by Yao and Yao <ref> [20] </ref> in 1985. In particular, Yao and Yao proposed a fault model in which a faulty comparator simply outputs its two inputs without comparison (i.e., the items are output in the same order in which they are input); we will refer to such a fault as a passive fault. <p> Since Yao and Yao, many researchers have studied fault-tolerant circuits, networks, and algorithms for sorting-related problems in various models. (See <ref> [4, 6, 7, 12, 13, 18, 19, 20] </ref>.) Despite all of these efforts, the O (log n)-gap between the trivial upper and lower bounds has remained open for Yao and Yao's question for both sorting and merging. <p> In this paper, we develop a fault-tolerant sorting circuit, network, and PRAM algorithm that beats the fi (n log 2 n) barrier in each of the preceding models, thereby partially or wholly resolving the questions posed by Yao and Yao <ref> [20] </ref>, Assaf and Upfal [4], and Feige et al. [7]. In particular, we construct: (i) a passive-fault-tolerant sorting circuit with O (log n log log n) depth and O (n log n log log n) size, which resolves the question posed by Yao and Yao [20] to within an O (log <p> posed by Yao and Yao <ref> [20] </ref>, Assaf and Upfal [4], and Feige et al. [7]. In particular, we construct: (i) a passive-fault-tolerant sorting circuit with O (log n log log n) depth and O (n log n log log n) size, which resolves the question posed by Yao and Yao [20] to within an O (log log n) factor, (ii) a reversal-fault-tolerant sorting network with size O (n log log 2 3 n), which partially resolves the question of Assaf and Upfal [4], and (iii) a fault-tolerant sorting algorithm that runs in O (log n) steps on an O (n)-processor EREW <p> Since a circuit contains at most n 2 comparators at each level, our circuit has O (n log n log log n) size. This provides the first nontrivial upper bound for sorting circuits that tolerate random passive faults, and answers the open question posed by Yao and Yao <ref> [20] </ref> up to an O (log log n) factor. In [20], Yao and Yao conjectured that any passive-fault-tolerant sorting or merging circuit has !(n log n) size. <p> This provides the first nontrivial upper bound for sorting circuits that tolerate random passive faults, and answers the open question posed by Yao and Yao <ref> [20] </ref> up to an O (log log n) factor. In [20], Yao and Yao conjectured that any passive-fault-tolerant sorting or merging circuit has !(n log n) size. <p> The same argument can be used to prove that the circuit has the desired property. To construct an approximate-insertion circuit that receives the unknown item at an arbitrary position, we use the following simple technique to increase the success probability of each comparator, as in <ref> [20] </ref>. If we apply l consecutive comparators, each of which fails to work with probability upper bounded by , to two registers, then the probability that the items contained in the two registers are unsorted after these l consecutive comparators is at most l . <p> Solving this recurrence, we find that T (n) = O (log n). 6 Worst-Case Fault-Tolerance In this section, we extend our results for random faults to construct worst-case fault-tolerant sorting circuits, networks, and algorithms. All previous work on worst-case faults seems to have focused on passive or destructive faults <ref> [12, 18, 19, 20] </ref>. We are not aware of any previous work on sorting networks that are tolerant to worst-case reversal faults, and no results were known for PRAM sorting algorithms that are tolerant to worst-case faults. <p> Although a tight bound on the size of worst-case passive-fault-tolerant sorting circuits was derived by Yao and Yao <ref> [20] </ref> in 1985, our result provides the first asymptotically nontrivial upper bound on the depth of such circuits, and is itself asymptotically optimal over a large range of k. <p> Given the difficulty of proving Theorem 2.1, it is worth pointing out that all of our results for worst-case faults can be proved independently of Theorem 2.1. For this purpose, the substitute for Theorem 2.1 is a lemma that is essentially due to Yao and Yao <ref> [20] </ref>, who proved the lemma for passive faults. In what follows, we define the Hamming distance D (x; y) of any two 0-1 sequences x; y 2 f0; 1g n as the number of positions where x and y differ.
References-found: 20

