URL: ftp://ftp.cs.umd.edu/pub/papers/papers/3518/3518.ps.Z
Refering-URL: http://www.cs.umd.edu/TRs/TR.html
Root-URL: 
Title: DOWNDATING A RANK-REVEALING URV DECOMPOSITION  
Author: YUAN-JYE JASON WU 
Keyword: Key words. rank-revealing factorization, downdating, URV decomposition  
Date: August 31, 1995  
Note: AMS(MOS) subject classifications. 65F20, 65F25, 65F30  
Abstract: The rank-revealing URV decomposition is a useful tool for the subspace tracking problem in digital signal processing. Updating the decomposition is a stable process. However, down- dating a rank-revealing URV decomposition could be unstable because the R factor is ill-conditioned. In this paper, we review some existing downdating algorithms for the full-rank URV decomposition in the absence of U and develop a new combined algorithm. We also show that the combined algorithm has relational stability. For the rank-revealing URV decomposition, we review a two-step method that applies full-rank downdating algorithms to the signal and noise parts separately. We compare several combinations of the full-rank algorithms and demonstrate good performance of our combined algorithm. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. L. Barlow and H. Zha, </author> <title> Stable algorithms for downdating two-sided orthogonal decomposi-tions, </title> <type> Technical Report CSE-93-013, </type> <institution> Department of Computer Science and Engineering, The Pennsylvania State University, </institution> <year> 1993. </year>
Reference-contexts: Park and Elden [10] give a simple and direct method called the two-step procedure to solve this problem. They consider only the LINPACK, CSNE, and reduction algorithms. Similar work is also studied by Barlow and Zha <ref> [1] </ref>. Since we already have algorithms for the full-rank problem, they suggest applying one of these methods to compute the signal (T s ) and noise (C) parts separately in order to keep the large-small structure unchanged. The only additional work required is a connection task.
Reference: [2] <author> A. Bj orck, H. Park, and L. </author> <title> Eld en, Accurate downdating of least squares solutions, </title> <journal> SIAM J. on Matrix Anal. and Appl., </journal> <volume> 15 (1994), </volume> <pages> pp. 549-568. </pages>
Reference-contexts: Under floating-point arithmetic, a breakdown might occur in the LINPACK algorithm when there is a negative computed value under the square root at step 2. In order to have a more accurate result, Bjorck, Park, and Elden <ref> [2] </ref> developed a method called Corrected SemiNormal Equations (CSNE) using the original data matrix in the refinement of [u 1 u m ] and ff. Let u H be the computed result at step 1 in the LINPACK algorithm. <p> Error analysis. In contrast to the methods in which the matrix U is available [7] and [9], none of the downdating algorithms introduced in this chapter is backward stable in the classical sense [14]. In fact, Bjorck, Park and Elden <ref> [2] </ref> stated that no algorithm using the matrix R only to compute the required entries of the matrix U can be backward stable. However, Stewart [11] found an special error property called relational or mixed stability for these algorithms.
Reference: [3] <author> A. W. Bojanczyk, R. P. Brent, P. V. Dooren, and F. R. D. Hoog, </author> <title> A note on downdating the Cholesky factoration, </title> <journal> SIAM Journal on Scientific and Statistical Computing, </journal> <volume> 8 (1987), </volume> <pages> pp. 210-221. </pages>
Reference-contexts: For the LINPACK and CSNE, algo-rithms, we require d hyperbolic rotations. There is only one needed in the reduction algorithm. However, the hyperbolic rotation is not recommended since it is not backward stable <ref> [3] </ref> [13]. Furthermore, if a breakdown occurs at the last step of the reduction algorithm, the assignment of 0 to t dd implies a plane rotation with 90 degree rotation and the hyperbolic rotation cannot be completed. <p> It has been shown that in (12), * k m = m 2 =2 + 9m m + O (m); for the LINPACK algorithm [11], * k m = 4m m; for Chambers' algorithm <ref> [3] </ref>. On the other hand, algorithms involving hyperbolic rotations do not have relational stability because the parameter k m in (12) is not bounded and depends on the tangents of rotation angles [3]. Therefore, the two-step method using hyperbolic rotations is not relationally stable. <p> m + O (m); for the LINPACK algorithm [11], * k m = 4m m; for Chambers' algorithm <ref> [3] </ref>. On the other hand, algorithms involving hyperbolic rotations do not have relational stability because the parameter k m in (12) is not bounded and depends on the tangents of rotation angles [3]. Therefore, the two-step method using hyperbolic rotations is not relationally stable. Our next task is to prove that the reduction algorithm has relational stability. We adopt the notation in [14] that fl (a) represents the floating-point representation of a.
Reference: [4] <author> E. C. Boman, M. F. Griffen, and G. W. Stewart, </author> <title> Direction of arrival and the rank-revealing URV decomposition, </title> <booktitle> in Procedings of ACASSP-91, </booktitle> <address> Washington, DC, 1991, </address> <publisher> IEEE. </publisher>
Reference-contexts: Updating the decomposition is a stable process requiring only O (m 2 ) operations where m is the number of sensors. Applying this updating technique on data sampled by the exponential windowing method can have efficient and effective performance <ref> [4, 8] </ref>. In contrast to the exponential windowing method, some practical signal processing applications use the rectangular windowing method to collect the sample data matrix X. Since the sensors, or receivers, collect the data sequentially, a large set of data will be accumulated over time.
Reference: [5] <author> J. M. Chambers, </author> <title> Regression updating, </title> <journal> Journal of the American Statistical Association, </journal> <year> (1971), </year> <pages> pp. 744-748. </pages>
Reference-contexts: Compute the downdated triangular matrix T using (5). There are four linear triangular systems to solve and three matrix-vector multiplications. The CSNE algorithm needs 6mn + 7m 2 + O (m) flops. 2.2. Chambers' algorithm. Chambers' algorithm <ref> [5] </ref> also avoids applying right rotations. The idea is quite simple.
Reference: [6] <author> J. J. Dongarra, J. R. Bunch, C. B. Moler, and G. W. Stewart, </author> <title> LINPACK User's Guide, </title> <publisher> SIAM, </publisher> <address> Philadelphia, </address> <year> 1979. </year>
Reference-contexts: The original problem can be restated as finding an upper triangular matrix T such that T H T = R H R zz H ; which amounts to downdating a Cholesky factorization. The method in the LINPACK package <ref> [6] </ref> described by Stewart [11] for downdating a Cholesky factorization is a popular choice to solve this kind of problem. Note that U [R H 0] H is a QR factorization of Z.
Reference: [7] <author> P. E. Gill, G. H. Golub, W. Murray, and M. A. Saunders, </author> <title> Methods for modifying matrix factorizations, </title> <journal> Mathematics of Computation, </journal> <volume> 28 (1974), </volume> <pages> pp. 505-535. </pages>
Reference-contexts: Therefore, with b V = V P , we have b X = b U T as a URV decomposition of b X. For those methods described in <ref> [7] </ref> and [9], since the matrix U is explicitly saved, it can be easily modified to the form in (3). However, the matrix U is seldom saved in most applications because the window size is large. Therefore, we only discuss those algorithms that do not use U . <p> If T s is rank deficient, we repartition the matrix, reducing the dimension of T s . 4. Error analysis. In contrast to the methods in which the matrix U is available <ref> [7] </ref> and [9], none of the downdating algorithms introduced in this chapter is backward stable in the classical sense [14]. In fact, Bjorck, Park and Elden [2] stated that no algorithm using the matrix R only to compute the required entries of the matrix U can be backward stable.
Reference: [8] <author> K. J. R. Liu, D. P. O'Leary, G. W. Stewart, and Y.-J. J. Wu, </author> <title> URV ESPRIT for tracking time-varying signals, </title> <journal> IEEE Trans. Signal Processing, </journal> <volume> 42 (1994), </volume> <pages> pp. 3441-3448. </pages>
Reference-contexts: Updating the decomposition is a stable process requiring only O (m 2 ) operations where m is the number of sensors. Applying this updating technique on data sampled by the exponential windowing method can have efficient and effective performance <ref> [4, 8] </ref>. In contrast to the exponential windowing method, some practical signal processing applications use the rectangular windowing method to collect the sample data matrix X. Since the sensors, or receivers, collect the data sequentially, a large set of data will be accumulated over time. <p> The numerical rank d is chosen as the smallest integer such that the norm of the resulting matrix C is less than the tolerance. Suppose that the sizes of the noise collected in sensors are roughly the same. It has been shown in <ref> [8] </ref> that the sum of the squares of the (m d) smallest singular values of the data matrix sampled by the rectangular windowing method satisfies 2 m (m d)* 2 fl (window size) ; where * is the noise size.
Reference: [9] <author> S. J. Olszanskyj and A. W. Bojanczyk, </author> <title> Compact Givens representation of the orthogonal factor in recursive linear squares, </title> <booktitle> in Proceedings of the fifth SIAM conference on Applied Linear Algebra, </booktitle> <editor> J. G. Lewis, ed., </editor> <publisher> SIAM, </publisher> <year> 1994. </year>
Reference-contexts: Therefore, with b V = V P , we have b X = b U T as a URV decomposition of b X. For those methods described in [7] and <ref> [9] </ref>, since the matrix U is explicitly saved, it can be easily modified to the form in (3). However, the matrix U is seldom saved in most applications because the window size is large. Therefore, we only discuss those algorithms that do not use U . <p> If T s is rank deficient, we repartition the matrix, reducing the dimension of T s . 4. Error analysis. In contrast to the methods in which the matrix U is available [7] and <ref> [9] </ref>, none of the downdating algorithms introduced in this chapter is backward stable in the classical sense [14]. In fact, Bjorck, Park and Elden [2] stated that no algorithm using the matrix R only to compute the required entries of the matrix U can be backward stable.
Reference: [10] <author> H. Park and L. </author> <title> Eld en, Downdating the rank-revealing URV decomposition, </title> <journal> SIAM Journal on Matrix Anal. and Appl., </journal> <volume> 16 (1995), </volume> <pages> pp. 138-155. </pages>
Reference-contexts: However, the algorithm breaks down when the argument of the square root at step 1 is non-positive for k &lt; m, and there is no way to recover. When the breakdown happens at k = m, we know that t mm is quite small and Park and Elden <ref> [10] </ref> suggest letting t mm = 0. Thus the matrix T possibly has rank one less than the matrix R. It will be proved in section 4 that this assumption is within an acceptable relative error bound. 5 2.3. Reduction algorithm. <p> It will be proved in section 4 that this assumption is within an acceptable relative error bound. 5 2.3. Reduction algorithm. We now introduce an algorithm that applies right rotations, the reduction algorithm, described by Park and Elden <ref> [10] </ref>. The reduction algorithm works on the problem (2) directly. <p> The LINPACK, CSNE, and Chambers' algorithms have no risk of mixing signal and noise. However, the large-small structure usually implies that R is ill- conditioned and leads to an inaccurate result or a breakdown. Park and Elden <ref> [10] </ref> give a simple and direct method called the two-step procedure to solve this problem. They consider only the LINPACK, CSNE, and reduction algorithms. Similar work is also studied by Barlow and Zha [1].
Reference: [11] <author> G. W. Stewart, </author> <title> The effects of rounding error on an algorithm for downdating a Cholesky fac-torization, </title> <journal> Journal of the Institute for Mathematics and Applications, </journal> <volume> 23 (1979), </volume> <pages> pp. </pages> <year> 203213. </year> <title> [12] , An updating algorithm for subspace tracking, </title> <journal> IEEE Transactions on Signal Processing, </journal> <volume> 40 (1992), </volume> <pages> pp. </pages> <month> 1535-1541. </month> <title> [13] , On the stability of sequential updates and downdates, </title> <type> tech. report, </type> <institution> Inst. for Advanced Computer Studies Report TR-94-30, Computer Science Department Report TR-3238, University of Maryland, College Park, </institution> <year> 1994. </year>
Reference-contexts: The original problem can be restated as finding an upper triangular matrix T such that T H T = R H R zz H ; which amounts to downdating a Cholesky factorization. The method in the LINPACK package [6] described by Stewart <ref> [11] </ref> for downdating a Cholesky factorization is a popular choice to solve this kind of problem. Note that U [R H 0] H is a QR factorization of Z. <p> In fact, Bjorck, Park and Elden [2] stated that no algorithm using the matrix R only to compute the required entries of the matrix U can be backward stable. However, Stewart <ref> [11] </ref> found an special error property called relational or mixed stability for these algorithms. Furthermore, Stewart [13] showed that relational stability can be preserved after a sequence of updates and downdates. <p> It has been shown that in (12), * k m = m 2 =2 + 9m m + O (m); for the LINPACK algorithm <ref> [11] </ref>, * k m = 4m m; for Chambers' algorithm [3]. On the other hand, algorithms involving hyperbolic rotations do not have relational stability because the parameter k m in (12) is not bounded and depends on the tangents of rotation angles [3].

References-found: 11

