URL: ftp://ftp.cc.gatech.edu/pub/gvu/tr/1996/96-14.ps.Z
Refering-URL: http://www.cs.gatech.edu/gvu/reports/1996/
Root-URL: 
Title: Automating The Design of Specification Interpreters  
Author: Kurt Stirewalt, Spencer Rugaber, Gregory Abowd 
Address: Atlanta, Georgia 30332-0280  
Affiliation: College of Computing Georgia Institute of Technology  
Abstract: In this paper, we demonstrate the use of model checking in an automated technique to verify the operationalization of a declarative specification language. We refer to an interpreter synthesizer as a software tool that transforms a declarative specification into an executable interpreter. Iterative approaches to synthesizer generation refine initial synthesizer designs by validating them over a test suite of specifications. Carefully chosen test suites and structural constraints enable inductive reasoning with support from a model checker to assert the correctness of generated interpreters. This iterative approach to synthesizer generation occurred naturally in our work on developing interpreters for declarative human-computer dialogue languages as part of the DARPA MASTERMIND project. We will discuss the issues underlying the translation, operationalization and verification of the hierarchical task language for MASTERMIND. We will also discuss the importance of this semi-automated, iterative approach for assessing nonfunctional design tradeoffs. Keywords: model checking, declarative specification languages, model-based user interfaces, automated verification 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Gregory D. Abowd, Hung-Ming Wang, and An-drew F. Monk. </author> <title> A formal techniqe for automated dialogue development. </title> <editor> In Gary M. Olson and Sue Schuon, editors, </editor> <booktitle> Proceedings of the Symposium on Designing Interactive Systems: Processes, Practices, Methods & Techniques, </booktitle> <pages> pages 219-226. </pages> <publisher> ACM Press, </publisher> <month> August </month> <year> 1995. </year>
Reference-contexts: Applications of model checking to event-based software systems which have a finite state representation have been demonstrated for examining timing requirements [2] and for verifying properties of production rule dialogues in a human-computer interface <ref> [1] </ref>. Model checking is good at pointing out errors in a specification, but it requires a finite state representation of a problem. Wing and Vaziri-Farahani [12] provide an elegant argument justifying the application of model checking technology to software problems with infinite state spaces through finite abstractions.
Reference: [2] <author> Joanne Atlee and John Gannon. </author> <title> State-based model checking of event driven systems requirements. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 19(3), </volume> <month> January </month> <year> 1993. </year>
Reference-contexts: The majority of the work in model checking has been demonstrated on hardware problems, because they are better suited to model checking technology's restriction to finite models. Applications of model checking to event-based software systems which have a finite state representation have been demonstrated for examining timing requirements <ref> [2] </ref> and for verifying properties of production rule dialogues in a human-computer interface [1]. Model checking is good at pointing out errors in a specification, but it requires a finite state representation of a problem.
Reference: [3] <author> J.R. Burch, E.M. Clarke, K.L. McMillan, D.L. Dill, and L.J. Hwang. </author> <title> Symbolic model checking: 10 20 states and beyond. </title> <booktitle> In Proceedings of the 5 th International Symposium on Logic in Computer Science, </booktitle> <month> June </month> <year> 1990. </year>
Reference-contexts: The cause for the recent surge in interest can be linked to developments that have provided for efficient search across very large finite state spaces using symbolic instead of explicit means of representation <ref> [3, 9] </ref>. The majority of the work in model checking has been demonstrated on hardware problems, because they are better suited to model checking technology's restriction to finite models.
Reference: [4] <author> Alan Dix, Janet Finlay, Gergory Abowd, and Russell Beale. </author> <title> Human-Computer Interaction. </title> <publisher> Prentice Hall, </publisher> <address> New York, </address> <year> 1993. </year>
Reference-contexts: A declarative specification language can ease the initial description of such a reactive system, and in the case of graphical user interfaces, the specification language is referred to as dialogue, or task, language <ref> [4] </ref>. In the MASTERMIND project, we are concerned with the development of tools to automate the generation of graphical user interfaces based on declarative task specifications. Our approach is similar to that taken in the model-based user interface community [11]. <p> Features of the language complicated the design of the interpreter synthesizer. This section explores those complications. 3.1 The Language Research in human-computer interaction suggests that hierarchical task analysis is a natural means of dialogue specification <ref> [4] </ref>. The MASTERMIND task language is a visual language for expressing the results of such analysis. It allows designers to specify task hierarchies, hierarchical ordering constraints, and interaction with an external environment in the form of preconditions and effects.
Reference: [5] <author> Nicolas Halbwachs. </author> <title> About synchronous programming and abstract interpretation. </title> <booktitle> In First International Static Analysis Symposium, SAS'94, </booktitle> <pages> pages 179-192, </pages> <year> 1994. </year>
Reference-contexts: Concurrent Mealy Machines treat the produced symbols as events and allow the produced events of one machine to be the consumed events of others. Mealy Machines compose by synchronous parallel composition <ref> [5] </ref> With only seven types of tasks in the language, we need only seven classes of Mealy Machine. Each different class of task ordering is captured by a canonical machine that controls the execution of subtasks by issuing control events.
Reference: [6] <author> David Harel. </author> <title> On visual formalisms. </title> <journal> Communications of the ACM, </journal> <volume> 31(5), </volume> <year> 1988. </year> <pages> Page 11 </pages>
Reference-contexts: This problem necessitates a different representation for the output of the synthesizer. Since simple state machines cannot deal well with parallelism, we look to a system of concurrent state machines <ref> [6] </ref>. 3.4 Concurrent Mealy Machines We chose to make the synthesizer translate each task into a Concurrent Mealy Machine. Mealy Machines [7] are deterministic finite state machines that consume and then produce a symbol at every state transition.
Reference: [7] <author> John E. Hopcroft and Jeffrey D. Ullman. </author> <title> In--troduction to Automata Theory, Languages, and Computation. </title> <publisher> Addison Wesley Publishing Company, </publisher> <year> 1979. </year>
Reference-contexts: Since simple state machines cannot deal well with parallelism, we look to a system of concurrent state machines [6]. 3.4 Concurrent Mealy Machines We chose to make the synthesizer translate each task into a Concurrent Mealy Machine. Mealy Machines <ref> [7] </ref> are deterministic finite state machines that consume and then produce a symbol at every state transition. Concurrent Mealy Machines treat the produced symbols as events and allow the produced events of one machine to be the consumed events of others.
Reference: [8] <author> Daniel Jackson and Craig A. Damon. </author> <title> Elements of style: Analyzing a software design feature with a counterexample detector. </title> <booktitle> In International Symposium on Software Testing and Analysis (ISSTA'96), </booktitle> <year> 1996. </year>
Reference-contexts: Model checking is good at pointing out errors in a specification, but it requires a finite state representation of a problem. Wing and Vaziri-Farahani [12] provide an elegant argument justifying the application of model checking technology to software problems with infinite state spaces through finite abstractions. Jack-son <ref> [8] </ref> used model checking technology to efficiently search a finite pruning of a Z specification state space to detect errors. We are also taking advantage of the error spotting in our iterative approach to verifying a synthesizer generator in this paper.
Reference: [9] <author> K. L. McMillan. </author> <title> Symbolic Model Checking: An Approach to the State Explosion Problem. </title> <type> PhD thesis, </type> <institution> Carnegie Mellon University, </institution> <year> 1992. </year> <month> CMU-CS-92-131. </month>
Reference-contexts: The cause for the recent surge in interest can be linked to developments that have provided for efficient search across very large finite state spaces using symbolic instead of explicit means of representation <ref> [3, 9] </ref>. The majority of the work in model checking has been demonstrated on hardware problems, because they are better suited to model checking technology's restriction to finite models.
Reference: [10] <author> R. Neches, J. Foley, P. Szekely, P. Sukaviriya, P. Luo, S. Kovacevic, and S. Hudson. </author> <title> Knowledgeable development environments using shared design models. </title> <booktitle> In Intelligent Interfaces Workshop, </booktitle> <pages> pages 63-70, </pages> <month> January </month> <year> 1993. </year>
Reference-contexts: Such environments differ in the nature of the specification language, the degree of support for reasoning, and the extent to which the generation of run-time systems is fully automated. MASTERMIND is an environment that specializes in generating highly interactive user interfaces and attaching them to applications <ref> [10] </ref>. The MASTERMIND project involves a number of different models that are relevant for interactive systems design (presentation, application, and task) and we are focusing here on the task model and its associated specification language.
Reference: [11] <author> Pedro Szekely, Ping Luo, and Robert Neches. </author> <title> Beyond interface builders: Model-based interface tools. </title> <booktitle> In Human Factors in Computing Systems | INTERCHI'93, </booktitle> <pages> pages 383-390. </pages> <publisher> Addison Wes-ley, </publisher> <month> April </month> <year> 1993. </year>
Reference-contexts: In the MASTERMIND project, we are concerned with the development of tools to automate the generation of graphical user interfaces based on declarative task specifications. Our approach is similar to that taken in the model-based user interface community <ref> [11] </ref>. One problem that we encountered is the difficulty of formally proving the correctness of an interpreter built for the task specification language. This is a general problem of operationalizing a declarative specification language. Operationalization is the process of generating an interpreter synthesizer for a declarative specification language.
Reference: [12] <author> Jeannette M. Wing and Mandana Vaziri-Farahani. </author> <title> Model checking software systems: A case study. </title> <booktitle> In Third ACM SIGSOFT Symposium on the Foundations of Software Engineering, </booktitle> <month> Oc-tober </month> <year> 1995. </year>
Reference-contexts: Model checking is good at pointing out errors in a specification, but it requires a finite state representation of a problem. Wing and Vaziri-Farahani <ref> [12] </ref> provide an elegant argument justifying the application of model checking technology to software problems with infinite state spaces through finite abstractions. Jack-son [8] used model checking technology to efficiently search a finite pruning of a Z specification state space to detect errors.
References-found: 12

