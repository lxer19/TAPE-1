URL: ftp://ftp.cs.rochester.edu/pub/papers/systems/95.HPDC.Loop_scheduling_for_heterogeneity.ps.Z
Refering-URL: http://www.cs.rochester.edu/u/cierniak/research/papers-short.html
Root-URL: 
Title: In Proceedings of the Fourth International Symposium on High Performance Distributed  Loop Scheduling for Heterogeneity  
Author: Micha Cierniak, Wei Li, Mohammed Javeed Zaki 
Address: Rochester, Rochester, NY 14627  
Affiliation: Computer Science Department, University of  
Date: August 1995  
Pubnum: Computing,  
Abstract: In this paper, we study the problem of scheduling parallel loops at compile-time for a heterogeneous network of machines. We consider heterogeneity in three aspects of parallel programming: program, processor and network. A heterogeneous program has parallel loops with different amount of work in each iteration; heterogeneous processors have different speeds; and a heterogeneous network has different cost of communication between processors. We propose a simple yet comprehensive model for use in compiling for a network of processors, and develop compiler algorithms for generating optimal and sub-optimal schedules of loops for load balancing, communication optimizations and network contention. Experiments show that a significant improvement of performance is achieved using our techniques. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. L. Cheung and A. P. Reeves. </author> <title> High performance computing on a cluster of workstations. </title> <booktitle> Proc. of the 1st Int. Symposium on High Performance Distributed Computing, </booktitle> <pages> pages 152-160, </pages> <month> September </month> <year> 1992. </year>
Reference-contexts: Affinity scheduling [8] is a hybrid static and 2 dynamic scheduling algorithm that takes data locality into account. Research in heterogeneous computing environments has focused on homogeneous applications. The problem of load balancing on a parallel machine with nodes of different performance has been considered in <ref> [1] </ref>, [3] and [5]. An approach for scheduling in a machine with heterogeneous memories has been presented in [14]. Requirements for distributed computing over LAN's have been analyzed in [10]. The rest of this paper is organized as follows.
Reference: [2] <author> M. Cierniak, W. Li, and M. J. Zaki. </author> <title> Loop scheduling for heterogeneity. </title> <type> Technical Report 540, </type> <institution> Computer Science Dept., Univ. of Rochester, </institution> <month> October </month> <year> 1994. </year>
Reference-contexts: The schedule obtained in this way is close to optimal. We call this approach bitonic scheduling <ref> [2] </ref>, since the iterations are assigned to processors in an increasing and decreasing fashion. We shall illustrate this optimization with the following example. Let the number of iterations, n = 10, and the number of processors, p = 3. <p> The work allocated to any proces sor is different by at most two iterations from the work corresponding to the perfect load balance. We can similarly schedule a heterogeneous loop with communication. Details are given in <ref> [2] </ref>. 7 Scheduling for Contention Avoidance Sections 4, 5 and 6 considered a machine model which allowed messages sent from different machines to travel in the network at the same time in parallel. <p> We have shown in <ref> [2] </ref> that the above system of equations has a unique solution. 8 Experiments To verify the proposed scheduling techniques, we conducted experiments and measured the execution time and the speedup of several applications. Where appropriate, we also compare our approach with straightforward scheduling. The results of our experiments are encouraging. <p> All experiments were performed on Sun workstations (SPARCstation 1, SPARCstation LX and SPARCstation 10) connected with an Ethernet network. The Programs were written in C and Fortran, and PVM [4] was used to parallelize them. 8.1 Heterogeneous programs TRIANG <ref> [2] </ref> is a program with a heterogeneous loop used in the experiments presented in this section. for the parallelization from Section 4. We compare our approach with the round-robin scheduling. <p> The architecture-conscious schedules consistently outperform the architecture-oblivious schedules. In spite of the large amount of communication in the program and the high cost of network communication, a satisfactory parallel performance was achieved. 8.3 Contention Avoidance We use LFK10, a program <ref> [2] </ref> based on loop 10 from the Livermore Fortran Kernels, to demonstrate our contention avoidance algorithm. The outermost loop is a doall loop and it is being par-allelized. We assume, however, that for the next stage of 8 computation array must be broadcast to all processors.
Reference: [3] <author> P. E. Crandall and M. J. Quinn. </author> <title> A decomposition advisory system for heterogeneous data-parallel processing. </title> <booktitle> Proc. of the 3rd Int. Symposium on High Performance Distributed Computing, </booktitle> <month> August </month> <year> 1994. </year>
Reference-contexts: Affinity scheduling [8] is a hybrid static and 2 dynamic scheduling algorithm that takes data locality into account. Research in heterogeneous computing environments has focused on homogeneous applications. The problem of load balancing on a parallel machine with nodes of different performance has been considered in [1], <ref> [3] </ref> and [5]. An approach for scheduling in a machine with heterogeneous memories has been presented in [14]. Requirements for distributed computing over LAN's have been analyzed in [10]. The rest of this paper is organized as follows.
Reference: [4] <author> Al Geist, Adam Beguelin, Jack Dongarra, Weicheng Jiang, Robert Manchek, and Vaidy Sunderam. </author> <title> PVM 3 user's guide and reference manual. </title> <type> Technical Report ORNL/TM-12187, </type> <institution> Oak Ridge National Laboratory, Oak Ridge, Tennessee, </institution> <month> May </month> <year> 1993. </year>
Reference-contexts: The last part of this section gives results for our approach to contention avoidance. All experiments were performed on Sun workstations (SPARCstation 1, SPARCstation LX and SPARCstation 10) connected with an Ethernet network. The Programs were written in C and Fortran, and PVM <ref> [4] </ref> was used to parallelize them. 8.1 Heterogeneous programs TRIANG [2] is a program with a heterogeneous loop used in the experiments presented in this section. for the parallelization from Section 4. We compare our approach with the round-robin scheduling.
Reference: [5] <author> A. S. Grimshaw, J. B. Weissman, E. A. West, and E. C. Loyot. Metasystems: </author> <title> An approach combining parallel processing and heterogeneous distributed computing systems. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 21(3) </volume> <pages> 257-270, </pages> <year> 1994. </year>
Reference-contexts: Affinity scheduling [8] is a hybrid static and 2 dynamic scheduling algorithm that takes data locality into account. Research in heterogeneous computing environments has focused on homogeneous applications. The problem of load balancing on a parallel machine with nodes of different performance has been considered in [1], [3] and <ref> [5] </ref>. An approach for scheduling in a machine with heterogeneous memories has been presented in [14]. Requirements for distributed computing over LAN's have been analyzed in [10]. The rest of this paper is organized as follows. <p> Processor i works on iterations b P i1 k=1 z k c + 1 through b k=1 z k c. The schedule obtained in this way is optimal. A similar approach, by distributing the load proportionally to the relative speeds of the processors, has been used with success in <ref> [5] </ref>. 5.2 Homogeneous parallel loops, with communi cation When there is communication, the algorithm in Section 5.1 will not necessarily generate an optimal schedule. Here we present an optimal solution.
Reference: [6] <author> Joseph L. Hammond and Peter J.P. O'Reilly. </author> <title> Performance analysis of local computer networks. </title> <publisher> Addison-Wesley, </publisher> <year> 1986. </year>
Reference-contexts: It serves as a conceptual starting point in compiling for load balancing and communication in such an environment. We consider heterogeneity in both the processor and the network dimensions. We take a very different approach than the work on stochastic models <ref> [6] </ref>, which are intended to model fl This work was supported in part by an NSF Research Initiation Award and ARPA contract F19628-94-C-0057. the performance behavior of the whole system with possibly many jobs running at the same time in an unpredictable way, and are, therefore, more detailed and complicated.
Reference: [7] <author> W. Li and K. Pingali. </author> <title> Access Normalization: Loop restructuring for NUMA compilers. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 11(4), </volume> <month> November </month> <year> 1993. </year> <title> An earlier version appeared in Proc. </title> <booktitle> 5th International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <month> October, </month> <year> 1992. </year>
Reference-contexts: Compile-time static loop scheduling is efficient and introduces no additional runtime overhead. For UMA (Uniform Memory Access) parallel machines, usually loop iterations can be scheduled in block or cyclic fashion [12]. For NUMA (Non-Uniform Memory Access) parallel machines, loop scheduling has to take data distribution into account <ref> [7] </ref>. When the execution time of loop iterations is not predictable at compile-time, runtime dynamic scheduling can be used at the additional runtime cost of managing task allocation. Self-scheduling [13] is the simplest approach in which processors ask for additional work from the task queue when they become idle.
Reference: [8] <author> E. P. Markatos and T. J. LeBlanc. </author> <title> Using processor affinity in loop scheduling on shared-memory multiprocessors. </title> <booktitle> In Proc. Supercomputing '92, </booktitle> <pages> pages 104-113, </pages> <year> 1992. </year>
Reference-contexts: Self-scheduling [13] is the simplest approach in which processors ask for additional work from the task queue when they become idle. Guided self-scheduling [11] reduces the runtime cost by allocating a block of iterations every time. Affinity scheduling <ref> [8] </ref> is a hybrid static and 2 dynamic scheduling algorithm that takes data locality into account. Research in heterogeneous computing environments has focused on homogeneous applications. The problem of load balancing on a parallel machine with nodes of different performance has been considered in [1], [3] and [5].
Reference: [9] <author> A. Nagurney, C. F. Nicholson, and P. M. Bishop. </author> <title> Spatial price equilibrium models with discriminatory ad valorem tariffs: formulation and comparative computation using variational inequalities. In Recent Advances in Spatial Equilibrium Modeling: Methodology and Applications. </title> <publisher> Springer-Verlag, </publisher> <address> Heidelberg, </address> <year> 1995. </year> <month> forthcoming. </month>
Reference-contexts: We show that the architecture-conscious scheduling algorithms result in much better performance than the naive architecture-oblivious scheduling approach. Examples are drawn from a mix of synthetic and real applications, from scientific computing and economics modeling <ref> [9] </ref>. Compile-time static loop scheduling is efficient and introduces no additional runtime overhead. For UMA (Uniform Memory Access) parallel machines, usually loop iterations can be scheduled in block or cyclic fashion [12]. For NUMA (Non-Uniform Memory Access) parallel machines, loop scheduling has to take data distribution into account [7]. <p> In particular, there may be many different configurations with the same base processor equivalent, but their speedups may be different. The second example of the homogeneous loop case is a program for spatial price equilibrium modeling in economics <ref> [9] </ref>. The program applies the methodology of the theory of variational inequalities for formulation and computation of spatial price equilibrium models with discriminatory ad valorem tariffs, which is a widely-used trade policy instrument.
Reference: [10] <author> M. Parashar, S. Hariri, A. G. Mohamed, and G. C. Fox. </author> <title> A requirement analysis for high performance distributed computing over LAN's. </title> <booktitle> Proc. of the 1st Int. Symposium on High Performance Distributed Computing, </booktitle> <pages> pages 142-151, </pages> <month> September </month> <year> 1992. </year>
Reference-contexts: The problem of load balancing on a parallel machine with nodes of different performance has been considered in [1], [3] and [5]. An approach for scheduling in a machine with heterogeneous memories has been presented in [14]. Requirements for distributed computing over LAN's have been analyzed in <ref> [10] </ref>. The rest of this paper is organized as follows. In Section 2, we introduce our program model, which is followed by our machine model in Section 3. In Section 4, we consider scheduling for heterogeneous programs (on homogeneous machines).
Reference: [11] <author> C. Polychronopoulos and D. Kuck. </author> <title> Guided self-scheduling: a practical scheduling scheme for parallel supercomputers. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 36 </volume> <pages> 1425-39, </pages> <month> December </month> <year> 1987. </year>
Reference-contexts: Self-scheduling [13] is the simplest approach in which processors ask for additional work from the task queue when they become idle. Guided self-scheduling <ref> [11] </ref> reduces the runtime cost by allocating a block of iterations every time. Affinity scheduling [8] is a hybrid static and 2 dynamic scheduling algorithm that takes data locality into account. Research in heterogeneous computing environments has focused on homogeneous applications.
Reference: [12] <author> C. D. Polychronopoulos. </author> <title> Parallel Programming and Compilers. </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1988. </year>
Reference-contexts: Examples are drawn from a mix of synthetic and real applications, from scientific computing and economics modeling [9]. Compile-time static loop scheduling is efficient and introduces no additional runtime overhead. For UMA (Uniform Memory Access) parallel machines, usually loop iterations can be scheduled in block or cyclic fashion <ref> [12] </ref>. For NUMA (Non-Uniform Memory Access) parallel machines, loop scheduling has to take data distribution into account [7]. When the execution time of loop iterations is not predictable at compile-time, runtime dynamic scheduling can be used at the additional runtime cost of managing task allocation.
Reference: [13] <author> P. Tang and P.-C. Yew. </author> <title> Processor self-scheduling for multiple nested parallel loops. </title> <booktitle> In Proc. of '86 International Conference On Parallel Processing, </booktitle> <month> August </month> <year> 1986. </year>
Reference-contexts: For NUMA (Non-Uniform Memory Access) parallel machines, loop scheduling has to take data distribution into account [7]. When the execution time of loop iterations is not predictable at compile-time, runtime dynamic scheduling can be used at the additional runtime cost of managing task allocation. Self-scheduling <ref> [13] </ref> is the simplest approach in which processors ask for additional work from the task queue when they become idle. Guided self-scheduling [11] reduces the runtime cost by allocating a block of iterations every time.
Reference: [14] <author> M. J. Zaki, W. Li, and M. Cierniak. </author> <title> Performance impact of processor and memory heterogeneity in a network of machines. </title> <booktitle> In Proc. of the Fourth Heterogeneous Computing Workshop, </booktitle> <month> April </month> <year> 1995. </year>
Reference-contexts: Research in heterogeneous computing environments has focused on homogeneous applications. The problem of load balancing on a parallel machine with nodes of different performance has been considered in [1], [3] and [5]. An approach for scheduling in a machine with heterogeneous memories has been presented in <ref> [14] </ref>. Requirements for distributed computing over LAN's have been analyzed in [10]. The rest of this paper is organized as follows. In Section 2, we introduce our program model, which is followed by our machine model in Section 3. <p> The times can be used to obtain relative speeds of those machines for this particular application <ref> [14] </ref>. In this section we consider programs without contention. In this case our goal is to obtain the best possible load balance using the algorithm in Section 5. We will use the following approach to evaluate the parallelization.
References-found: 14

