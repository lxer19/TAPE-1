URL: http://www.statslab.cam.ac.uk/~gareth/negclt.ps
Refering-URL: http://www.stats.bris.ac.uk/MCMC/pages/list.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: A note on acceptance rate criteria for CLTs for Hastings-Metropolis algorithms  
Author: G.O. Roberts, 
Keyword: 0 Keywords: Hastings algorithms, Metropolis algorithms, Markov chain Monte Carlo, central limit theorems  
Date: July 17, 1997  
Affiliation: Cambridge University  
Abstract: This note considers positive recurrent Markov chains where the probability of remaining in the current state is arbitrarily close to 1. Specifically, conditions are given which ensure the non-existence of central limit theorems for ergodic averages of functionals of the chain. The results are motivated by applications for Metropolis-Hastings algorithms which are constructed in terms of a rejection probability, (where a rejection involves remaining at the current state). Two examples for commonly used algorithms are given, for the independence sampler and the Metropolis adjusted Langevin algorithm. The examples are rather specialised, although in both cases, the problems which arise are typical of problems commonly occurring for the particular algorithm being used. 0 I would like to thank Kerrie Mengersen Jeff Rosenthal and Richard Tweedie for useful conversations on the subject of this paper. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J.E. Besag, P.J. Green, D. Higdon, and K.L. Mengersen. </author> <title> Bayesian computation and stochastic systems (with discussion). </title> <journal> Statistical Science, </journal> <volume> 10 </volume> <pages> 3-66, </pages> <year> 1995. </year>
Reference-contexts: For this reason and for its ease of their implementation, is has become extremely popular simulation tools, especially for statistical applications. The application of these chains to Bayesian analysis, and issues arising in their implementation, is detailed by <ref> [16, 1] </ref>, and [4] among many others. Because of their importance in statistical applications, the stability of ergodic averages is of considerable interest. Positive results ensuring that certain Markov chain Monte Carlo algorithms actually satisfy central limit theorems are given (for example) in [18] and its discussion, [14] and [12].
Reference: [2] <author> K. S. Chan and C. J. </author> <title> Geyer. Discussion of [18], </title> <journal> Ann. Statist., </journal> <volume> 22 </volume> <pages> 1747-1758, </pages> <year> 1994. </year>
Reference-contexts: The simplest and most common procedures for assessing the accuracy of Monte Carlo estimates from Markov chain Monte Carlo approaches are the procedure known as batch mean estimation and window estimation see for example <ref> [2] </ref> or [10]. <p> h does not exist. 3 Aceptance rate criteria 4 Proof For a p N -CLT to hold, we certainly require the limiting variance lim n!1 E (( i=1 h (X i )) 2 )=n to exist (and in fact equal 2 , (see [7] and also the helpful review of <ref> [2] </ref>).
Reference: [3] <author> W. Feller. </author> <title> An introduction to probability theory and its applications, Vol II, </title> <publisher> Wiley, Now York, </publisher> <editor> 2nd ed., </editor> <year> 1971. </year>
Reference-contexts: Note that central limit theorems can still hold even when Var (X) = 1 and X consists of a sequence of IID random variables (see for example Theorem 1a of Section IX.8 in <ref> [3] </ref>). The theorem is often difficult to check in its raw form. Various corollaries are possible in more specialised situations. We content ourselves here with a one-dimensional result. Theorem 3.3 Suppose that X = IR and that () has a density with respect to Lebesgue measure also denoted by ().
Reference: [4] <author> W.R. Gilks, S. Richardson, </author> <title> and D.J. Spiegelhalter. Markov chain Monte Carlo in practice, </title> <publisher> Chapman and Hall, </publisher> <address> London, New York, </address> <year> 1996. </year>
Reference-contexts: For this reason and for its ease of their implementation, is has become extremely popular simulation tools, especially for statistical applications. The application of these chains to Bayesian analysis, and issues arising in their implementation, is detailed by [16, 1], and <ref> [4] </ref> among many others. Because of their importance in statistical applications, the stability of ergodic averages is of considerable interest. Positive results ensuring that certain Markov chain Monte Carlo algorithms actually satisfy central limit theorems are given (for example) in [18] and its discussion, [14] and [12].
Reference: [5] <author> W.K. Hastings. </author> <title> Monte Carlo sampling methods using Markov chains and their applications. </title> <journal> Biometrika, </journal> <volume> 57 </volume> <pages> 97-109, </pages> <year> 1970. </year>
Reference-contexts: We usually assume that Q (x; ) is absolutely continuous with density q (x; y) with respect to some finite reference measure, (although such an assumption is not necessary for the kind of result considered here). In the Metropolis-Hastings algorithm ([9], <ref> [5] </ref>) a proposal generated according to the law Q is then accepted with probability ff (x; y) given by ff (x; y) = minf (y) q (y;x) 1 (x)q (x; y) = 0 Thus actual transitions of the Hastings chain, which we shall denote by = f n ; n 2
Reference: [6] <author> J.S. Liu. </author> <title> Metropolized independent sampling with comparisons to rejection sampling and importance sampling. </title> <journal> Statistics and computing, </journal> <note> to appear, </note> <year> 1996. </year>
Reference-contexts: ; 1g: (15) 4 Examples 6 In Theorem 2.1 of [8], Mengersen and Tweedie, proved that this algorithm is uniformly ergodic if there exists fi &gt; 0 such that q (y) fi; y 2 X (16) and then kP n (x; ) k (1 fi) n : (17) (In fact <ref> [6] </ref> and [17] show how to write down n step transition probabilities for this algorithm, and give a simple expression for its rate of convergence.) Conversely, if for every fi &gt; 0 the set on which (16) fails has positive measure then the algorithm is not even geometrically ergodic. <p> In fact the chain may tend to "get stuck" in regions of low density. This happens when the proposal distribution has lighter tails than the target distribution. Following the example in [8], let be exponential (1), and suppose we use the independence proposal, exponential (). <ref> [6] </ref> shows that for 1, the algorithm is geometrically ergodic with convergence rate = 1 . However for &gt; 1, = 1, that is convergence occurs at a subgeometric rate.
Reference: [7] <author> C. Kipnis and S.R.S. Varadhan. </author> <title> Central limit theorem for additive functionals of reversible Markov processes and applications to simple exclusions. </title> <journal> Comm. Math. Phys., </journal> <volume> 104, </volume> <pages> 1-19, </pages> <year> 1986. </year>
Reference-contexts: When a p N -CLT holds for h and X, alternative formulae are available for 2 when X is reversible (see for example <ref> [7] </ref>). The identity in (7) is important in practice to ensure the conistency of standard Monte Carlo estimators for the asymptotic variance. The main result of this paper is therefore Theorem 3.2 Let X be reversible, and suppose that h is a zero mean function under . <p> implies that a p N -CLT for h does not exist. 3 Aceptance rate criteria 4 Proof For a p N -CLT to hold, we certainly require the limiting variance lim n!1 E (( i=1 h (X i )) 2 )=n to exist (and in fact equal 2 , (see <ref> [7] </ref> and also the helpful review of [2]). <p> What reversibility gives us (by <ref> [7] </ref>) is the fact that if a p N -CLT does hold, its variance must be lim n!1 E (( i=1 h (X i )) 2 )=n.
Reference: [8] <author> K.L. Mengersen and R.L. Tweedie. </author> <title> Rates of convergence of the Hastings and Metropolis algorithms. </title> <journal> Ann. Statist., </journal> <volume> 24: </volume> <pages> 101-121, </pages> <year> 1996. </year>
Reference-contexts: q (x; y) = q (y); x; y 2 X: (14) Assume (x) &gt; 0 and q (x) &gt; 0 for all x so that the acceptance probabilities here take the form ff (x; y) = minf (y) q (x) ; 1g: (15) 4 Examples 6 In Theorem 2.1 of <ref> [8] </ref>, Mengersen and Tweedie, proved that this algorithm is uniformly ergodic if there exists fi &gt; 0 such that q (y) fi; y 2 X (16) and then kP n (x; ) k (1 fi) n : (17) (In fact [6] and [17] show how to write down n step transition <p> In fact the chain may tend to "get stuck" in regions of low density. This happens when the proposal distribution has lighter tails than the target distribution. Following the example in <ref> [8] </ref>, let be exponential (1), and suppose we use the independence proposal, exponential (). [6] shows that for 1, the algorithm is geometrically ergodic with convergence rate = 1 . However for &gt; 1, = 1, that is convergence occurs at a subgeometric rate.
Reference: [9] <author> N. Metropolis, A. Rosenbluth, M. Rosenbluth, A. Teller, and E. Teller. </author> <title> Equations of state calculations by fast computing machines. </title> <journal> J. Chemical Physics, </journal> <volume> 21 </volume> <pages> 1087-1091, </pages> <year> 1953. </year>
Reference: [10] <editor> Markov chain concepts relating to sampling algorithms. </editor> <booktitle> In [4], </booktitle> <pages> 45-58, </pages> <year> 1996. </year>
Reference-contexts: The simplest and most common procedures for assessing the accuracy of Monte Carlo estimates from Markov chain Monte Carlo approaches are the procedure known as batch mean estimation and window estimation see for example [2] or <ref> [10] </ref>.
Reference: [11] <author> G.O. Roberts and J.S. Rosenthal. </author> <title> Optimal scaling of discrete approximations to Langevin diffusions. </title> <institution> University of Cambridge Statistical Laboratory research report 94-11, </institution> <note> 1994 (to appear in J. </note> <editor> Roy. </editor> <publisher> Stat. Assoc., B). </publisher>
Reference-contexts: These algorithms are often very efficient, and can be shown to be superior to random walk Metropolis algorithms (with proposals centered around the current iteration) in certain cases (see for example <ref> [11] </ref>). However for light tailed target densities (lighter than Gaussian), the algorithm can perform badly. 4 Examples 7 Let (x) / expfffjxj fi g for fi &gt; 2.
Reference: [12] <author> G.O. Roberts and J.S. Rosenthal. </author> <title> Geometric Ergodicity and Hybrid Markov Chains. </title> <journal> Electronic communications of probability, </journal> <volume> 2, </volume> <year> 1997. </year>
Reference-contexts: Because of their importance in statistical applications, the stability of ergodic averages is of considerable interest. Positive results ensuring that certain Markov chain Monte Carlo algorithms actually satisfy central limit theorems are given (for example) in [18] and its discussion, [14] and <ref> [12] </ref>. The simplest and most common procedures for assessing the accuracy of Monte Carlo estimates from Markov chain Monte Carlo approaches are the procedure known as batch mean estimation and window estimation see for example [2] or [10].
Reference: [13] <author> G.O. Roberts and A.F.M. Smith. </author> <title> Simple conditions for the convergence of the Gibbs sampler and Metropolis-Hastings algorithms. </title> <journal> Stoch. Proc. Appl., </journal> <volume> 49: </volume> <pages> 207-216, </pages> <year> 1994. </year>
Reference-contexts: The n-step transition probabilities of are then defined by P n (x; A) = P ( n 2 Aj 0 = x); n 2 ZZ + ; x 2 X; A 2 B (X) : Under mild regularity conditions (see for example <ref> [13] </ref>) the algorithm produces a positive recurrent Markov chain converging in distribution to . A characteristic of Metropolis-Hastings chains is that proposed moves are often rejected.
Reference: [14] <author> G.O. Roberts and R.L. Tweedie. </author> <title> Geometric convergence and central limit theorems for multidimensional Hastings and Metropolis algorithms. </title> <journal> Biometrika, </journal> <volume> 83: </volume> <pages> 96-110, </pages> <year> 1996. </year>
Reference-contexts: Because of their importance in statistical applications, the stability of ergodic averages is of considerable interest. Positive results ensuring that certain Markov chain Monte Carlo algorithms actually satisfy central limit theorems are given (for example) in [18] and its discussion, <ref> [14] </ref> and [12]. The simplest and most common procedures for assessing the accuracy of Monte Carlo estimates from Markov chain Monte Carlo approaches are the procedure known as batch mean estimation and window estimation see for example [2] or [10]. <p> This paper considers how properties of the function A () effect convergence properties of the Markov chain. In <ref> [14] </ref>, Roberts and Tweedie demonstrate (essentially) that if A () is not bounded away from zero, then the Markov chain converges at a sub-geometric rate. <p> Our somewhat simplistic approach may not reflect best possible outcomes in specific examples. However, it turns out that this result has wide applicability for Metropolis-Hastings algorithms. 3 Aceptance rate criteria 3 Firstly, we note a related result from <ref> [14] </ref>.
Reference: [15] <author> G.O. Roberts and R.L. Tweedie. </author> <title> Exponential Convergence of Langevin Diffusions and Their Discrete Approximations. </title> <journal> Bernoulli,2, </journal> <volume> 4, </volume> <pages> 341-363, </pages> <year> 1996. </year>
Reference-contexts: However for light tailed target densities (lighter than Gaussian), the algorithm can perform badly. 4 Examples 7 Let (x) / expfffjxj fi g for fi &gt; 2. In <ref> [15] </ref>, Roberts and Tweedie show that the algorithm is geometrically ergodic for 1 fi &lt; 2 and for fi = 2 for small enough values of ffi. the algorithm is sub-geometrically ergodic for fi &lt; 1 or fi &gt; 2. We pursue this latter case further.
Reference: [16] <author> A.F.M. Smith and G.O. Roberts. </author> <title> Bayesian computation via the Gibbs sampler and related Markov chain Monte Carlo methods (with discussion). </title> <journal> J. Roy. Statist. Soc. Ser. B, </journal> <volume> 55 </volume> <pages> 3-24, </pages> <year> 1993. </year>
Reference-contexts: For this reason and for its ease of their implementation, is has become extremely popular simulation tools, especially for statistical applications. The application of these chains to Bayesian analysis, and issues arising in their implementation, is detailed by <ref> [16, 1] </ref>, and [4] among many others. Because of their importance in statistical applications, the stability of ergodic averages is of considerable interest. Positive results ensuring that certain Markov chain Monte Carlo algorithms actually satisfy central limit theorems are given (for example) in [18] and its discussion, [14] and [12].
Reference: [17] <author> R.L. Smith and L. Tierney. </author> <title> Exact transition probabilities for the independence Metropolis sampler. </title> <institution> University of Cambridge Statistical Laboratory research report 96-16, </institution> <year> 1996. </year>
Reference-contexts: (15) 4 Examples 6 In Theorem 2.1 of [8], Mengersen and Tweedie, proved that this algorithm is uniformly ergodic if there exists fi &gt; 0 such that q (y) fi; y 2 X (16) and then kP n (x; ) k (1 fi) n : (17) (In fact [6] and <ref> [17] </ref> show how to write down n step transition probabilities for this algorithm, and give a simple expression for its rate of convergence.) Conversely, if for every fi &gt; 0 the set on which (16) fails has positive measure then the algorithm is not even geometrically ergodic.
Reference: [18] <author> L. Tierney. </author> <title> Markov chains for exploring posterior distributions (with discussion). </title> <journal> Ann. Statist., </journal> <volume> 22 </volume> <pages> 1701-1762, </pages> <year> 1994. </year>
Reference-contexts: Because of their importance in statistical applications, the stability of ergodic averages is of considerable interest. Positive results ensuring that certain Markov chain Monte Carlo algorithms actually satisfy central limit theorems are given (for example) in <ref> [18] </ref> and its discussion, [14] and [12]. The simplest and most common procedures for assessing the accuracy of Monte Carlo estimates from Markov chain Monte Carlo approaches are the procedure known as batch mean estimation and window estimation see for example [2] or [10].
References-found: 18

