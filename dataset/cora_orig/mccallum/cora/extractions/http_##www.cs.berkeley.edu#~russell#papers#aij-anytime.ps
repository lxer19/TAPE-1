URL: http://www.cs.berkeley.edu/~russell/papers/aij-anytime.ps
Refering-URL: http://www.cs.berkeley.edu/~russell/full-log.html
Root-URL: 
Title: Optimal composition of real-time systems  
Author: Shlomo Zilbersteiny and Stuart Russell 
Note: Present address:  To appear in Artificial Intelligence 1  
Address: Berkeley, CA 94720, U.S.A.  Amherst, MA 01003, U.S.A.  
Affiliation: Computer Science Division, University of California  Computer Science Department, Lederle Graduate Research Center, University of Massachusetts,  
Abstract: Real-time systems are designed for environments in which the utility of actions is strongly time-dependent. Recent work by Dean, Horvitz and others has shown that anytime algorithms are a useful tool for real-time system design, since they allow computation time to be traded for decision quality. In order to construct complex systems, however, we need to be able to compose larger systems from smaller, reusable anytime modules. This paper addresses two basic problems associated with composition: how to ensure the interruptibility of the composed system; and how to allocate computation time optimally among the components. The first problem is solved by a simple and general construction that incurs only a small, constant penalty. The second is solved by an off-line compilation process. We show that the general compilation problem is NP-complete. However, efficient local compilation techniques, working on a single program structure at a time, yield globally optimal allocations for a large class of programs. We illustrate these results with two simple applications. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. Boddy and T. L. Dean, </author> <title> Solving time-dependent planning problems, </title> <booktitle> In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <address> Detroit, Michigan (1989) 979-984. </address>
Reference-contexts: A real-time environment can be characterized by a time-dependent utility function. In almost all cases, the deliberation required to select optimal actions will degrade the system's overall utility. It is by now well-understood that a successful system must trade off decision quality for deliberation cost <ref> [1, 4, 16, 21, 28, 31, 32] </ref>. The problem of deliberation cost has been widely discussed in artificial intelligence, economics and philosophy. In artificial intelligence in particular, researchers have proposed a number of meta-level architectures to control the cost of base-level reasoning [5, 6, 8, 12, 16, 27]. <p> (PDP) of an algorithm A is a function D A : R + ! P r (R) that maps computation time to a probability distribution over the quality of the results. 5 An obvious simplification of the PDP is the expected performance profile (EPP), as used by Boddy and Dean <ref> [1] </ref> and by Horvitz [14]: Definition 2.2 The expected performance profile (EPP) of an algorithm A is a function E A : R + ! R that maps computation time to the expected quality of the results. <p> Since performance profiles are normally monotone functions of time, they can be approximated using a simple family of functions. Once the simulation data is gathered, the performance information can be derived by various curve fitting techniques. For example, Boddy and Dean <ref> [1] </ref> used the function: Q (t) = 1 e t to model the expected performance of an anytime planner. Performance distribution profiles can be approximated by applying a similar method to a family of distributions. <p> Many existing programming and automated reasoning techniques produce useful anytime algorithms: search techniques such as iterative deepening; asymptotically correct inference algorithms such as approximate query answering [9, 32], bounded cutset conditioning (see [14]), and variable precision logic [24]; various greedy algorithms (see <ref> [1] </ref>); iterative methods such as Newton's method; adaptive algorithms such as PAC learning algorithms or neural networks; randomized methods such as Monte Carlo algorithms or fingerprinting techniques [17]; and the use of optimal meta-level control of computation [27].
Reference: [2] <author> M. Boddy, </author> <title> Anytime problem solving using dynamic programming, </title> <booktitle> In Proceedings of the Ninth National Conference on Artificial Intelligence, </booktitle> <address> Anaheim, California (1991) 738-743. </address>
Reference: [3] <author> P. Cheeseman, J. Kelly, M. Self, J. Stutz, W. Taylor and D. Freeman, </author> <title> Autoclass: a Bayesian classification system, </title> <booktitle> In Proceedings of the Fifth International Conference on Machine Learning, </booktitle> <year> (1988). </year>
Reference-contexts: The partitioning can be done using any attribute of the input that may influence performance, such as size or a complexity measure. Input classes of similar performance can also be derived automatically using Bayesian statistics by programs such as Autoclass <ref> [3] </ref>. In this paper, we consider conditioning on the input quality.
Reference: [4] <author> B. D'Ambrosio, </author> <title> Resource bounded agents in an uncertain world, </title> <booktitle> In Working Notes of the IJCAI-89 Workshop on Real-Time Artificial Intelligence Problems, </booktitle> <address> Detroit, Michigan (1989). </address>
Reference-contexts: A real-time environment can be characterized by a time-dependent utility function. In almost all cases, the deliberation required to select optimal actions will degrade the system's overall utility. It is by now well-understood that a successful system must trade off decision quality for deliberation cost <ref> [1, 4, 16, 21, 28, 31, 32] </ref>. The problem of deliberation cost has been widely discussed in artificial intelligence, economics and philosophy. In artificial intelligence in particular, researchers have proposed a number of meta-level architectures to control the cost of base-level reasoning [5, 6, 8, 12, 16, 27].
Reference: [5] <author> R. Davis, </author> <title> Meta-rules: Reasoning about control, </title> <booktitle> Artificial Intelligence 15 (1980) 179-222. </booktitle>
Reference-contexts: The problem of deliberation cost has been widely discussed in artificial intelligence, economics and philosophy. In artificial intelligence in particular, researchers have proposed a number of meta-level architectures to control the cost of base-level reasoning <ref> [5, 6, 8, 12, 16, 27] </ref>. One promising approach is to use anytime [7] or flexible [14] algorithms, which allow the execution time to be specified, either as a parameter or by an interrupt, and exhibit a time/quality tradeoff defined by a performance profile.
Reference: [6] <author> T. L. Dean, </author> <title> Intractability and time-dependent planning, </title> <booktitle> In Proceedings of the 1986 Workshop on Reasoning about Actions and Plans, </booktitle> <editor> M. P. Georgeff and A. L. Lansky, eds., </editor> <publisher> Los Altos, California (Morgan Kaufmann, </publisher> <year> 1987). </year>
Reference-contexts: The problem of deliberation cost has been widely discussed in artificial intelligence, economics and philosophy. In artificial intelligence in particular, researchers have proposed a number of meta-level architectures to control the cost of base-level reasoning <ref> [5, 6, 8, 12, 16, 27] </ref>. One promising approach is to use anytime [7] or flexible [14] algorithms, which allow the execution time to be specified, either as a parameter or by an interrupt, and exhibit a time/quality tradeoff defined by a performance profile.
Reference: [7] <author> T. L. Dean and M. Boddy, </author> <title> An analysis of time-dependent planning, </title> <booktitle> In Proceedings of the Seventh National Conference on Artificial Intelligence, </booktitle> <address> Minneapolis, Minnesota (1988) 49-54. </address>
Reference-contexts: The problem of deliberation cost has been widely discussed in artificial intelligence, economics and philosophy. In artificial intelligence in particular, researchers have proposed a number of meta-level architectures to control the cost of base-level reasoning [5, 6, 8, 12, 16, 27]. One promising approach is to use anytime <ref> [7] </ref> or flexible [14] algorithms, which allow the execution time to be specified, either as a parameter or by an interrupt, and exhibit a time/quality tradeoff defined by a performance profile. They provide a simple means by which a system can control its deliberation without significant overhead. <p> They provide a simple means by which a system can control its deliberation without significant overhead. Soon after the introduction of anytime algorithms, it became apparent that their composition presents a vital, non-trivial problem <ref> [7] </ref>. This paper reports the first results on the composition problem showing that real-time systems can be modularly composed of anytime algorithms. Moreover, the meta-level scheduling problem is solved in polynomial time to yield optimal (near-optimal) performance for any tree (directed acyclic graph) structured program. <p> If a contract algorithm is interrupted at any time shorter than its contract time, it may yield no useful results. Both interruptible and contract algorithms have been used in the past. Dean and Boddy's <ref> [7] </ref> definition of anytime algorithms refers to the interruptible case. Techniques such as depth-limited search and 9 alpha-beta search, on the other hand, are more suited for contract algorithms. Although they can produce a suitable result for any given effort limit, they may return meaningless results if interrupted before completion. <p> The compiled module includes code to control the activation of the elementary components with an appropriate time allocation. Optimal scheduling of the elementary components may also require run-time monitoring. The problem addressed by the monitor is similar to the deliberation scheduling 14 problem introduced by Dean and Boddy in <ref> [7] </ref>. Previous solutions to the problem included only a small set of algorithms characterized by non-conditional performance profiles. In this work we have studied the composition and monitoring of an arbitrary number of different algorithms characterized by conditional performance profiles.
Reference: [8] <author> J. Doyle, </author> <title> Rationality and its roles in reasoning, </title> <booktitle> In Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <address> Boston, Massachusetts (1990) 1093-1100. </address>
Reference-contexts: The problem of deliberation cost has been widely discussed in artificial intelligence, economics and philosophy. In artificial intelligence in particular, researchers have proposed a number of meta-level architectures to control the cost of base-level reasoning <ref> [5, 6, 8, 12, 16, 27] </ref>. One promising approach is to use anytime [7] or flexible [14] algorithms, which allow the execution time to be specified, either as a parameter or by an interrupt, and exhibit a time/quality tradeoff defined by a performance profile.
Reference: [9] <author> C. Elkan, </author> <title> Incremental, approximate planning: Abductive default reasoning, </title> <booktitle> In Working Notes of the AAAI Spring Symposium on Planning in Uncertain Environments, </booktitle> <address> Palo Alto, California (1990). </address>
Reference-contexts: Many existing programming and automated reasoning techniques produce useful anytime algorithms: search techniques such as iterative deepening; asymptotically correct inference algorithms such as approximate query answering <ref> [9, 32] </ref>, bounded cutset conditioning (see [14]), and variable precision logic [24]; various greedy algorithms (see [1]); iterative methods such as Newton's method; adaptive algorithms such as PAC learning algorithms or neural networks; randomized methods such as Monte Carlo algorithms or fingerprinting techniques [17]; and the use of optimal meta-level control
Reference: [10] <author> M. R. Garey and D. S. Johnson, </author> <title> Computers and Intractability: A Guide to the Theory of NP-Completeness, </title> <address> San Francisco, </address> <publisher> California (W. H. Freeman and Company, </publisher> <year> 1979). </year>
Reference-contexts: The cost function, Cost (i; j), defines the cost of traveling directly from city i to city j (The cost is not necessarily the Euclidean distance.) The problem is to find an optimal tour, that is, a tour with minimal total cost. The TSP is known to be NP-complete <ref> [10] </ref>, hence it is hard to find an optimal tour when the problem includes a large number of cities. Iterative improvement algorithms can find a good approximation to an optimal solution, and naturally yield an interruptible anytime algorithm. <p> Hence, the verification problem is polynomial and the decision problem is NP. The rest of the proof is by transformation from the PARTIALLY ORDERED KNAPSACK problem, an NP-complete problem in the strong sense <ref> [10] </ref> defined as follows: INSTANCE: Finite set U , partial order on U , for each u 2 U a size s (u) 2 Z + and a value v (u) 2 Z + , and positive integers B and K. <p> We show that the tree-structured GCFE is NP-complete. Theorem 4.4 The tree-structured GCFE problem is NP-complete. Proof: As in the case of the GCFE problem, the verification problem is polynomial and the problem is therefore NP. The rest of the NP-completeness proof is by transformation from the KNAPSACK problem <ref> [10] </ref>, defined as follows: 23 INSTANCE: Finite set U , for each u 2 U a size s (u) 2 Z + and a value v (u) 2 Z + , and positive integers B and K.
Reference: [11] <author> A. Garvey and V. Lesser, </author> <title> Design-to-time real-time scheduling, </title> <journal> In IEEE Transactions on Systems, Man and Cybernetics, </journal> <month> 23(6) </month> <year> (1993). </year>
Reference: [12] <author> M. R. Genesereth, </author> <title> An overview of metalevel architectures, </title> <booktitle> In Proceedings of the Third National Conference on Artificial Intelligence, </booktitle> <address> Washington, D.C. </address> <year> (1983) </year> <month> 119-123. 36 </month>
Reference-contexts: The problem of deliberation cost has been widely discussed in artificial intelligence, economics and philosophy. In artificial intelligence in particular, researchers have proposed a number of meta-level architectures to control the cost of base-level reasoning <ref> [5, 6, 8, 12, 16, 27] </ref>. One promising approach is to use anytime [7] or flexible [14] algorithms, which allow the execution time to be specified, either as a parameter or by an interrupt, and exhibit a time/quality tradeoff defined by a performance profile.
Reference: [13] <author> J. A. Hendler, </author> <title> Real-time planning, </title> <booktitle> In Working Notes of the AAAI Spring Symposium on Planning and Search, </booktitle> <address> Stanford, California (1989). </address>
Reference: [14] <author> E. J. Horvitz, </author> <title> Reasoning about beliefs and actions under computational resource constraints, </title> <booktitle> In Proceedings of the 1987 Workshop on Uncertainty in Artificial Intelligence, </booktitle> <address> Seattle, Washington (1987). </address>
Reference-contexts: In artificial intelligence in particular, researchers have proposed a number of meta-level architectures to control the cost of base-level reasoning [5, 6, 8, 12, 16, 27]. One promising approach is to use anytime [7] or flexible <ref> [14] </ref> algorithms, which allow the execution time to be specified, either as a parameter or by an interrupt, and exhibit a time/quality tradeoff defined by a performance profile. They provide a simple means by which a system can control its deliberation without significant overhead. <p> A is a function D A : R + ! P r (R) that maps computation time to a probability distribution over the quality of the results. 5 An obvious simplification of the PDP is the expected performance profile (EPP), as used by Boddy and Dean [1] and by Horvitz <ref> [14] </ref>: Definition 2.2 The expected performance profile (EPP) of an algorithm A is a function E A : R + ! R that maps computation time to the expected quality of the results. <p> Many existing programming and automated reasoning techniques produce useful anytime algorithms: search techniques such as iterative deepening; asymptotically correct inference algorithms such as approximate query answering [9, 32], bounded cutset conditioning (see <ref> [14] </ref>), and variable precision logic [24]; various greedy algorithms (see [1]); iterative methods such as Newton's method; adaptive algorithms such as PAC learning algorithms or neural networks; randomized methods such as Monte Carlo algorithms or fingerprinting techniques [17]; and the use of optimal meta-level control of computation [27].
Reference: [15] <author> E. J. Horvitz, H. J. Suermondt and G. F. Cooper, </author> <title> Bounded conditioning: Flexible inference for decision under scarce resources, </title> <booktitle> In Proceedings of the 1989 Workshop on Uncertainty in Artificial Intelligence, </booktitle> <address> Windsor, Ontario (1989) 182-193. </address>
Reference: [16] <author> E. J. Horvitz and J. S. Breese, </author> <title> Ideal partition of resources for metareasoning, </title> <type> Technical Report KSL-90-26, </type> <institution> Stanford Knowledge Systems Laboratory, Stanford, California (1990). </institution>
Reference-contexts: A real-time environment can be characterized by a time-dependent utility function. In almost all cases, the deliberation required to select optimal actions will degrade the system's overall utility. It is by now well-understood that a successful system must trade off decision quality for deliberation cost <ref> [1, 4, 16, 21, 28, 31, 32] </ref>. The problem of deliberation cost has been widely discussed in artificial intelligence, economics and philosophy. In artificial intelligence in particular, researchers have proposed a number of meta-level architectures to control the cost of base-level reasoning [5, 6, 8, 12, 16, 27]. <p> The problem of deliberation cost has been widely discussed in artificial intelligence, economics and philosophy. In artificial intelligence in particular, researchers have proposed a number of meta-level architectures to control the cost of base-level reasoning <ref> [5, 6, 8, 12, 16, 27] </ref>. One promising approach is to use anytime [7] or flexible [14] algorithms, which allow the execution time to be specified, either as a parameter or by an interrupt, and exhibit a time/quality tradeoff defined by a performance profile.
Reference: [17] <author> R. M. Karp, </author> <title> An Introduction to Randomized Algorithms, </title> <type> Technical Report TR-90-024, </type> <institution> International Computer Science Institute, Berkeley, California (1990). </institution>
Reference-contexts: inference algorithms such as approximate query answering [9, 32], bounded cutset conditioning (see [14]), and variable precision logic [24]; various greedy algorithms (see [1]); iterative methods such as Newton's method; adaptive algorithms such as PAC learning algorithms or neural networks; randomized methods such as Monte Carlo algorithms or fingerprinting techniques <ref> [17] </ref>; and the use of optimal meta-level control of computation [27]. We conclude this section with an example of a particular anytime algorithm and its performance profile. An Example: The Traveling Salesman Problem The traveling salesman problem (TSP) involves a salesman that must visit n cities.
Reference: [18] <author> R. E. Korf, </author> <title> Depth-first iterative-deepening: An optimal admissible tree search, </title> <booktitle> Artificial Intelligence 27 (1985) 97-109. </booktitle>
Reference: [19] <author> R. E. Korf, </author> <title> Real-time heuristic search, </title> <booktitle> Artificial Intelligence 42(3) (1990) 189-212. </booktitle>
Reference: [20] <editor> E. L. Lawler et al., eds., </editor> <title> The traveling salesman problem: a guided tour of combinatorial optimization, </title> <publisher> New York (Wiley, </publisher> <year> 1987). </year>
Reference-contexts: Iterative improvement algorithms can find a good approximation to an optimal solution, and naturally yield an interruptible anytime algorithm. The anytime traveling salesman algorithm is a randomized algorithm that repeatedly tries to perform a tour improvement step <ref> [20, 22] </ref>. In the general case of tour improvement procedures, r edges in a feasible tour are exchanged for r edges not in that solution as long as the result remains a tour and the cost of that tour is less than the cost of the previous tour.
Reference: [21] <author> V. Lesser, J. Pavlin and E. Durfee, </author> <title> Approximate processing in real-time problem-solving, </title> <journal> AI Magazine 9(1) (1988) 49-61. </journal>
Reference-contexts: A real-time environment can be characterized by a time-dependent utility function. In almost all cases, the deliberation required to select optimal actions will degrade the system's overall utility. It is by now well-understood that a successful system must trade off decision quality for deliberation cost <ref> [1, 4, 16, 21, 28, 31, 32] </ref>. The problem of deliberation cost has been widely discussed in artificial intelligence, economics and philosophy. In artificial intelligence in particular, researchers have proposed a number of meta-level architectures to control the cost of base-level reasoning [5, 6, 8, 12, 16, 27].
Reference: [22] <author> S. Lin and B. W. Kernighan, </author> <title> An effective heuristic algorithm for the Traveling Salesman problem, </title> <note> Operation Research 21 (1973) 498-516. </note>
Reference-contexts: Iterative improvement algorithms can find a good approximation to an optimal solution, and naturally yield an interruptible anytime algorithm. The anytime traveling salesman algorithm is a randomized algorithm that repeatedly tries to perform a tour improvement step <ref> [20, 22] </ref>. In the general case of tour improvement procedures, r edges in a feasible tour are exchanged for r edges not in that solution as long as the result remains a tour and the cost of that tour is less than the cost of the previous tour.
Reference: [23] <author> T. Lozano-P erez and R. A. Brooks, </author> <title> In Solid Modeling by Computers, </title> <editor> M. S. Pickett and J. W. Boyse, eds., </editor> <address> New York, </address> <publisher> (Plenum, </publisher> <year> 1984) </year> <month> 293-327. </month>
Reference-contexts: For a run-time t, T a t T b , the quality of GET-DOMAIN-DESCRIPTION improves from Q a to the maximal quality Q b . Path planning is performed using a coarse-to-fine search algorithm (similar to Lozano-P erez and Brooks <ref> [23] </ref>) that allows for unresolved path segments. In order to make it an anytime algorithm, we vary the abstraction level of the domain description. This allows the algorithm to find a feasible plan quickly, and then repeatedly refine it by replanning a segment of the plan in more detail.
Reference: [24] <author> R. S. Michalski and P. H. Winston, </author> <title> Variable precision logic, </title> <booktitle> Artificial Intelligence 29(2) (1986) 121-146. </booktitle>
Reference-contexts: Many existing programming and automated reasoning techniques produce useful anytime algorithms: search techniques such as iterative deepening; asymptotically correct inference algorithms such as approximate query answering [9, 32], bounded cutset conditioning (see [14]), and variable precision logic <ref> [24] </ref>; various greedy algorithms (see [1]); iterative methods such as Newton's method; adaptive algorithms such as PAC learning algorithms or neural networks; randomized methods such as Monte Carlo algorithms or fingerprinting techniques [17]; and the use of optimal meta-level control of computation [27].
Reference: [25] <author> J. Pearl, </author> <title> Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference, </title> <publisher> Los Altos, California (Morgan-Kaufmann, </publisher> <year> 1988). </year>
Reference-contexts: with general functional expressions: * HILL-CLIMBING-ALLOCATION finds a solution to the global compilation problem directly, but does not guarantee global optimality. * CONDITIONING-ALLOCATION tries all possible allocations to the repeated subexpres-sions, then applies local compilation to the resulting trees (note the analogy to condi tioning methods in belief network evaluation <ref> [25] </ref>). * TRADING-ALLOCATION begins with the allocation determined by local compilation, and then trades time among components so that only one copy of each repeated subexpression ends up with a non-zero allocation. All three methods where developed using the discrete tabular representation of performance profiles.
Reference: [26] <author> A. </author> <title> Pos, Time-Constrained Model-Based Diagnosis, </title> <type> Master Thesis, </type> <institution> Department of Computer Science, University of Twente, </institution> <address> The Netherlands (1993). </address> <month> 37 </month>
Reference: [27] <author> S. J. Russell and E. H. </author> <title> Wefald, </title> <booktitle> Principles of metareasoning, In Proceedings of the First International Conference on Principles of Knowledge Representation and Reasoning, </booktitle> <volume> R.J. </volume> <editor> Brachman et al., eds., </editor> <address> San Mateo, </address> <publisher> California (Morgan Kaufmann, </publisher> <year> 1989). </year>
Reference-contexts: The problem of deliberation cost has been widely discussed in artificial intelligence, economics and philosophy. In artificial intelligence in particular, researchers have proposed a number of meta-level architectures to control the cost of base-level reasoning <ref> [5, 6, 8, 12, 16, 27] </ref>. One promising approach is to use anytime [7] or flexible [14] algorithms, which allow the execution time to be specified, either as a parameter or by an interrupt, and exhibit a time/quality tradeoff defined by a performance profile. <p> cutset conditioning (see [14]), and variable precision logic [24]; various greedy algorithms (see [1]); iterative methods such as Newton's method; adaptive algorithms such as PAC learning algorithms or neural networks; randomized methods such as Monte Carlo algorithms or fingerprinting techniques [17]; and the use of optimal meta-level control of computation <ref> [27] </ref>. We conclude this section with an example of a particular anytime algorithm and its performance profile. An Example: The Traveling Salesman Problem The traveling salesman problem (TSP) involves a salesman that must visit n cities.
Reference: [28] <author> S. J. Russell and E. H. Wefald, </author> <title> Do the Right Thing: Studies in limited rationality, </title> <publisher> Cambridge, Massachusetts (MIT Press, </publisher> <year> 1991). </year>
Reference-contexts: A real-time environment can be characterized by a time-dependent utility function. In almost all cases, the deliberation required to select optimal actions will degrade the system's overall utility. It is by now well-understood that a successful system must trade off decision quality for deliberation cost <ref> [1, 4, 16, 21, 28, 31, 32] </ref>. The problem of deliberation cost has been widely discussed in artificial intelligence, economics and philosophy. In artificial intelligence in particular, researchers have proposed a number of meta-level architectures to control the cost of base-level reasoning [5, 6, 8, 12, 16, 27].
Reference: [29] <author> S. J. Russell and S. Zilberstein, </author> <title> Composing real-time systems, </title> <booktitle> In Proceedings of the Twelfth International Joint Conference on Artificial Intelligence, </booktitle> <address> Sydney, Australia (1991) 212-217. </address>
Reference-contexts: This results, however, in a contract algorithm since interrupting the system during diagnosis leaves one with no treatment recommendation at all. This is the case even if the individual components are themselves interruptible. Thus na ve composition destroys interruptibility. This problem is solved by the following reduction theorem <ref> [29] </ref>: Theorem 2.7 (Reduction) For any contract algorithm A, an interruptible algorithm B can be constructed such that for any particular input q B (4t) q A (t). Proof: Construct B by running A repeatedly with exponentially increasing time limits. If interrupted, return the best result generated so far.
Reference: [30] <author> S. J. Russell, D. Subramanian and R. Parr, </author> <title> Provably bounded optimal agents, </title> <booktitle> In Proceedings of the Thirteenth International Joint Conference on Artificial Intelligence, </booktitle> <address> Chambery, France (1993) 338-344. </address>
Reference: [31] <author> H. A. Simon, </author> <title> Models of bounded rationality, </title> <booktitle> Volume 2, </booktitle> <address> Cambridge, </address> <publisher> Massachusetts (MIT Press, </publisher> <year> 1982). </year>
Reference-contexts: A real-time environment can be characterized by a time-dependent utility function. In almost all cases, the deliberation required to select optimal actions will degrade the system's overall utility. It is by now well-understood that a successful system must trade off decision quality for deliberation cost <ref> [1, 4, 16, 21, 28, 31, 32] </ref>. The problem of deliberation cost has been widely discussed in artificial intelligence, economics and philosophy. In artificial intelligence in particular, researchers have proposed a number of meta-level architectures to control the cost of base-level reasoning [5, 6, 8, 12, 16, 27].
Reference: [32] <author> S. V. Vrbsky and J. W. S. Liu, </author> <title> Producing monotonically improving approximate answers to database queries, </title> <booktitle> In Proceedings of the IEEE Workshop on Imprecise and Approximate Computation, </booktitle> <address> Phoenix, Arizona (1992) 72-76. </address>
Reference-contexts: A real-time environment can be characterized by a time-dependent utility function. In almost all cases, the deliberation required to select optimal actions will degrade the system's overall utility. It is by now well-understood that a successful system must trade off decision quality for deliberation cost <ref> [1, 4, 16, 21, 28, 31, 32] </ref>. The problem of deliberation cost has been widely discussed in artificial intelligence, economics and philosophy. In artificial intelligence in particular, researchers have proposed a number of meta-level architectures to control the cost of base-level reasoning [5, 6, 8, 12, 16, 27]. <p> Many existing programming and automated reasoning techniques produce useful anytime algorithms: search techniques such as iterative deepening; asymptotically correct inference algorithms such as approximate query answering <ref> [9, 32] </ref>, bounded cutset conditioning (see [14]), and variable precision logic [24]; various greedy algorithms (see [1]); iterative methods such as Newton's method; adaptive algorithms such as PAC learning algorithms or neural networks; randomized methods such as Monte Carlo algorithms or fingerprinting techniques [17]; and the use of optimal meta-level control
Reference: [33] <author> L. A. Zadeh, </author> <title> Fuzzy logic and approximate reasoning, </title> <address> Synthese 30 (1975) 407-428. </address>
Reference: [34] <author> S. Zilberstein and S. J. Russell, </author> <title> Efficient resource-bounded reasoning in AT-RALPH, </title> <booktitle> In Proceedings of the First International Conference on AI Planning Systems, </booktitle> <address> College Park, Maryland (1992) 260-266. </address>
Reference: [35] <author> S. Zilberstein and S. J. Russell, </author> <title> Constructing utility-driven real-time systems using anytime algorithms, </title> <booktitle> In Proceedings of the IEEE Workshop on Imprecise and Approximate Computation, </booktitle> <address> Phoenix, Arizona (1992) 6-10. </address>
Reference: [36] <author> S. Zilberstein, </author> <title> Operational Rationality through Compilation of Anytime Algorithms, </title> <type> Ph.D. dissertation, </type> <institution> Computer Science Division, University of California, Berkeley, California (1993). </institution>
Reference-contexts: What if the condition of the patient suddenly requires intervention while the diagnosis component is still running and no treatment has been considered? 7. How should the execution of the composite system be managed so as to optimize overall utility? In other publications, particularly <ref> [36] </ref>, we address these issues in some depth. Here, we focus on item 5, which we call the compilation problem. Given a system composed of anytime algorithms, compilation determines off-line the optimal allocation of time to the components for any given total allocation. <p> The input to the compiler is a compound anytime module, that is, a module composed of several elementary anytime algorithms. The primitive programming language constructs that are used to define compound modules can vary from a small set of simple constructs to a rich programming language <ref> [36] </ref>. The choice of language primitives determine the feasibility and complexity of the compilation problem. Compound modules do not include time allocation code and hence they are not readily executable. In addition to the compound module, the compiler's input includes the performance profiles of the elementary anytime algorithms. <p> We found that the complexity of the compilation process is largely determined by the choice of a run-time monitoring scheme. Active monitoring, that revises the allocation the the components while the system is active, is discussed in <ref> [36] </ref>. <p> Obviously, the maximal volume that can be transported is proportional to the maximal quality among all the individual bin packing algorithms. Additional examples of such compositional operators appear in <ref> [36] </ref>. 4.4 Repeated Subexpressions Local compilation does not produce good results when applied to functional expressions with repeated subexpressions. Using the tree representation, a repeated subexpression corresponds to a repeated sub-tree. <p> Then, the maximal allocation among those is used to increase the value of r. This process is repeated until no additional time is allocated to any of the copies beyond the reserved time allocation r. This time allocation algorithm does not guarantee global optimality <ref> [36] </ref>. Complexity. Using the same notation as above, the complexity of the algorithm is O (t 3 ). This is due to the fact that the complexity of the search for r is O (t ) (since r may be incremented by 1 unit of time in each iteration).
Reference: [37] <author> S. Zilberstein and S. J. Russell, </author> <title> Anytime sensing, planning and action: A practical model for robot control, </title> <booktitle> In Proceedings of the Thirteenth International Joint Conference on Artificial Intelligence, </booktitle> <address> Chambery, France (1993) 1402-1407. </address> <month> 38 </month>
Reference-contexts: This map is used as input to PATH-PLAN that produces the final output a path from Start to Goal. The actual implementation of these anytime modules is described in <ref> [37] </ref>. Figure 11 shows the performance profiles. 18 profiles labeled MIN and MAX show the result of minimal and maximal allocations to the vision component. The domain is represented as a matrix of elementary positions each of which can be either free or occupied by an obstacle.
References-found: 37

