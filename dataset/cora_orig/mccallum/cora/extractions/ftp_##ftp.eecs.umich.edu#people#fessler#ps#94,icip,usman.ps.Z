URL: ftp://ftp.eecs.umich.edu/people/fessler/ps/94,icip,usman.ps.Z
Refering-URL: http://www.eecs.umich.edu/~fessler/papers/conf.html
Root-URL: http://www.cs.umich.edu
Title: BIAS-VARIANCE TRADE-OFFS ANALYSIS USING UNIFORM CR BOUND FOR IMAGES  
Author: M. Usman, A.O. Hero, and J.A. Fessler 
Address: Ann Arbor MI 48109  
Affiliation: University of Michigan,  
Abstract: We apply a uniform Cramer-Rao (CR) bound [1] to study the bias-variance trade-offs in parameter estimation. The uniform CR bound is used to specify achievable and un-achievable regions in the bias-variance trade-off plane. The applications considered in this paper are: 1) two dimensional single photon emission computed tomography (SPECT) system, and 2) one dimensional edge localization. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. O. </author> <month> Hero </month>
Reference-contexts: We use uniform CR bound <ref> [1] </ref> on the variance of biased estimators which divides the bias-variance trade-off plane ffi into achievable and unachievable regions. Different estimators can be placed in the achievable region of the ffi plane and their performance can be effectively com pared. <p> fi n, symmetric, positive definite Fisher information matrix (FIM) F Y = F Y (): var ( ^ 1 ) e T Y e 1 ; (1) where, F Y = E [r T r denotes the (row) gradient vector [ @ @ 1 ; :::; @ e 1 = <ref> [1; 0; :::; 0] </ref> T is an n-element unit vector. While the unbiased CR bound (1) is known to be asymptotically achievable for large number of independent iden tically distributed measurements, in practice, most estima tion algorithms are biased and the unbiased CR bound is inapplicable. 3. <p> The application of the biased CR bound (2) is very restricted due to the fact that it is only applicable to estimators with a given bias gradient r b 1 . In <ref> [1] </ref> Hero gives a `uniform' CR bound on the variance of a single parameter 1 for non singular F Y . <p> This bound is applicable to all biased estima tors whose bias gradient length kr b 1 k satisfies: kr b 1 k 2 ffi 2 &lt; 1: (3) The following theorem is proven in <ref> [1] </ref>. Theorem 1 Let b 1 be an estimator with bias b 1 () whose n-element bias gradient vector r b 1 satisfies (3). Assume that the FIM F Y is non-singular. <p> Then the variance of b 1 is given by: var ( b 1 ) B (; ffi); (4) where B (; ffi) is equal to: B (; ffi) = [e 1 + d min ] T F 1 = 2 e T where e 1 = <ref> [1; 0; :::; 0] </ref> T is an n-element unit vector and: d min = [I + F Y ] 1 e 1 ; (7) and is given by the unique non-negative solution of the following equation involving the monotone decreasing, strictly convex function g () 2 [0; 1]: g () = <p> where e 1 = [1; 0; :::; 0] T is an n-element unit vector and: d min = [I + F Y ] 1 e 1 ; (7) and is given by the unique non-negative solution of the following equation involving the monotone decreasing, strictly convex function g () 2 <ref> [0; 1] </ref>: g () = d T A more general version of Theorem 1, which will not be required here, is given in [5] and applies to singular F Y . <p> It is easy to show that for the Poisson model r ln f Y (y; ) = A T fi fl where ff is a vector operation denoting element-by-element division, and 1 = <ref> [1; 1; :::; 1] </ref> T . For the first set of simulations the smoothing parameter ff was varied (Figure 4). Points on the curves in Figure 4 are labeled by the exponent of ff.
References-found: 1

