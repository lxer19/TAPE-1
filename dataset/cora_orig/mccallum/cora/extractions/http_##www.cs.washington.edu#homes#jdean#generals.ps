URL: http://www.cs.washington.edu/homes/jdean/generals.ps
Refering-URL: http://www.cs.washington.edu/homes/jdean/papers.html
Root-URL: http://www.cs.washington.edu
Title: Call Graph Analysis in the Presence of Higher-Order Functions  
Author: Jeffrey Dean 
Affiliation: Department of Computer Science and Engineering University of Washington  
Abstract-found: 0
Intro-found: 1
Reference: [Aho et al. 86] <author> Alfred V. Aho, Ravi Sethi, and Jeffrey D. Ullman. </author> <booktitle> Compilers: Principles, Techniques, and Tools. </booktitle> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1986. </year>
Reference-contexts: Within a single procedure, standard techniques exist for performing optimizations, such as common subexpression elimination, constant propagation, and dead-code elimination, by tracking values and program properties through a control ow graph (CFG) for the procedure <ref> [Aho et al. 86] </ref>. During data ow analysis and optimization, difficulties arise when dealing with procedure calls. If the compiler does not perform any analysis across procedure boundaries, then conservative assumptions must be made at procedure calls to preserve correctness.
Reference: [Appel & Jim 89] <author> Andrew W. Appel and Trevor Jim. </author> <title> Continuation-passing, closure-passing style. </title> <booktitle> In Conference Record of the Sixteenth Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 293302, </pages> <address> Austin, Texas, </address> <month> January </month> <year> 1989. </year>
Reference-contexts: Since then, CPS-style representations have been adopted by a number of advanced language compilers, including the Orbit Scheme compiler [Kranz 88] and the Standard ML of New Jersey compiler for ML <ref> [Appel & Jim 89] </ref>. None of these compilers perform any significant control or data-ow analysis on programs, however. Proponents of using CPS as an intermediate representation maintain that its uniform approach to handling all control transfers make compilers easier to write and to reason about [Shivers 91a].
Reference: [Ayers 93] <author> Andrew E. Ayers. </author> <title> Control-Flow Analysis of Higher-Order Languages. </title> <type> PhD thesis, </type> <institution> Massachusetts Institute of Technology, </institution> <month> September </month> <year> 1993. </year>
Reference-contexts: Ayers has shown that the complexity of 0CFA analysis has a lower bound of O (C 2 ) and an upper bound of W (C 4 ), where C is the number of call sites in the program <ref> [Ayers 93] </ref>. The actual complexity of the algorithm depends on the sparseness of the final call graph, but in most cases, C is roughly comparable to E, the number of edges in the final call graph. <p> Ayers has shown that the complexity of kCFA analysis has a lower bound of O (C k+2 ) and an upper bound of W (C 2k+4 ), where C is the number of call sites in the program <ref> [Ayers 93] </ref>. He also provides empirical results for a suite of small programs showing that a 1CFA solution takes as much as 100 times longer to compute than a 0CFA solution. <p> con structed Handles call by value result Shiverss 0CFA O (C 2 ) O (E 2 ) Yes Full Scheme Medium - Requires CPS conversion; code for algorithm provided in thesis Handles incomplete programs and side effects; thesis has proofs of correctness; implementation of algorithm is well studied by Ayers <ref> [Ayers 93] </ref> c p +( ) c p +( ) 18 Call Graph Analysis in the Presence of Higher-Order Functions Generals Examination Written Report onerous task than producing a working version of a technique that is described only with mathematical formalism.
Reference: [Callahan et al. 90] <author> David Callahan, Alan Carle, Mary W. Hall, and Ken Kennedy. </author> <title> Constructing the procedure call multigraph. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 16(4):483487, </volume> <year> 1990. </year>
Reference-contexts: If all of the call sites are always invoked, the algorithm computes an exact call graph. Since recursion is included in the Fortran90 standard, and even prior to the adoption of this standard was supported by many Fortran compilers, Callahan et al. extended Ryders algorithm to handle recursive programs <ref> [Callahan et al. 90] </ref>. They use a worklist-based algorithm that, like Ryders algorithm, tracks possible bindings of procedure-valued formals simultaneously for all formals of a routine, rather than individually, like the Hall & Kennedy algorithm.
Reference: [Chambers & Ungar 90] <author> Craig Chambers and David Ungar. </author> <title> Iterative type analysis and extended message splitting: Optimizing dynamically-typed object-oriented programs. </title> <journal> SIGPLAN Notices, </journal> <volume> 25(6):150164, </volume> <month> June </month> <year> 1990. </year> <booktitle> In Proceedings of the ACM SIGPLAN 90 Conference on Programming Language Design and Implementation. </booktitle>
Reference-contexts: The SELF compiler applies this technique to type analysis. Type information is tagged with a path from which it originated so that desirable type information that has been lost as a result of a merge with another path can be regained by splitting apart the merged paths <ref> [Chambers & Ungar 90] </ref>. This technique may prove useful and should be explored for developing adaptive analysis algorithms. Call graph analysis is an important topic because it forms the foundation for interprocedural analysis, and interprocedural analysis is becoming more and more prevalent as compilers attempt to produce more efficient code.
Reference: [Cooper et al. 92] <author> Keith D. Cooper, Mary W. Hall, and Ken Kennedy. </author> <title> Procedure cloning. </title> <booktitle> In Proceedings of 1992 IEEE International Conference on Computer Languages, </booktitle> <pages> pages 96105, </pages> <address> Oakland, CA, </address> <month> April </month> <year> 1992. </year>
Reference-contexts: Although non-conservative call graphs can also be useful for performing program transformations that do not affect program correctness, such as procedure specialization <ref> [Cooper et al. 92] </ref> [Dean et al. 94], most interprocedural analyses do not fall in this category. Therefore, the discussion will be limited to techniques for constructing conservative call graphs.
Reference: [Cousot & Cousot 77] <author> Patrick Cousot and Radhia Cousot. </author> <title> Abstract interpretation: A unified lattice model for static analysis of programs by construction or approximation of fixpoints. </title> <booktitle> In Conference Record of the Fourth ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 238252, </pages> <address> Los Angeles, California, </address> <month> January </month> <year> 1977. </year>
Reference-contexts: A closure is active when an application of the closure has not been completed. Loops are detected when an already active closure is again applied, and at this point, a widening operation is applied to ensure termination <ref> [Cousot & Cousot 77] </ref>. Steensgaard has chosen to widen by smearing together the argument lists from the loop entering call with the argument lists from all of the possible loop closing calls, although other choices of widening operations are possible [Steensgaard 94].
Reference: [Dean et al. 94] <author> Jeffrey Dean, Craig Chambers, and David Grove. </author> <title> Identifying profitable specialization in object-oriented languages. </title> <booktitle> In Proceedings of the Workshop on Partial Evaluation and Semantics-Based Program Manipulation 94, </booktitle> <address> Orlando, FL, </address> <month> June </month> <year> 1994. </year> <note> To appear. </note>
Reference-contexts: Although non-conservative call graphs can also be useful for performing program transformations that do not affect program correctness, such as procedure specialization [Cooper et al. 92] <ref> [Dean et al. 94] </ref>, most interprocedural analyses do not fall in this category. Therefore, the discussion will be limited to techniques for constructing conservative call graphs.
Reference: [Hall & Kennedy 92] <author> Mary W. Hall and Ken Kennedy. </author> <title> Efficient call graph analysis. </title> <journal> ACM Letters on Programming Languages and Systems, </journal> <volume> 1(3):227242, </volume> <month> September </month> <year> 1992. </year>
Reference-contexts: I will examine this issue in more depth in section 6.1. 3 Smearing Algorithms This first class of algorithms are the most efficient but least precise. The three algorithms discussed in this category were developed by Hall & Kennedy <ref> [Hall & Kennedy 92] </ref>, Lakhotia [Lakhotia 93], and Shivers [Shivers 88]. Although they all compute essentially the same call graph, they differ substantially in the language features they support and in the structure of the algorithm. <p> For Fortran programs, which typically have at most one procedure value passed as a parameter <ref> [Hall & Kennedy 92] </ref>, these conditions are rarely encountered, so the algorithm produces the same results as other, more precise algorithms. For other languages that make more extensive use of procedural parameters, the call graph imprecisions will occur more frequently. <p> not improve the time complexity of the precise algorithm, because the whole graph might be marked as imprecise main p b d 6 Call Graph Analysis in the Presence of Higher-Order Functions Generals Examination Written Report in pathological cases, but it could improve the running time of the precise algorithm <ref> [Hall & Kennedy 92] </ref>. <p> Both Hall & Kennedy and Shivers propose a similar, fairly imprecise approach towards handling such assignments <ref> [Hall & Kennedy 92] </ref> [Shivers 91a]. Both approaches involve maintaining a single set g, containing those procedure values that may be bound to any procedure value through assignment. <p> Handling side-effects is another area where the approaches proposed for handling higher-order functions are likely to be insufficient for performing type-determination. The solution of having a single set representing the set of values that have escaped, proposed by both Hall & Kennedy <ref> [Hall & Kennedy 92] </ref> and by Shivers [Shivers 88], is sufficient when relatively few values are stored into data structures. Because type determination involves tracking all values and not just procedure values, this coarse model of side-effects is unlikely to be sufficient precise.
Reference: [Hall 91] <author> Mary W. Hall. </author> <title> Managing Interprocedural Optimization. </title> <type> PhD thesis, </type> <institution> Rice University, </institution> <month> April </month> <year> 1991. </year>
Reference-contexts: When performing aggressive interprocedural optimizations, however, it is desirable to have access to the text of the entire program. To facilitate this, many new compilers such as the Tera compilers [Henry 93] and the ParaScope Fortran compiler <ref> [Hall 91] </ref> delay some compiler tasks, including optimization and code generation, until link-time, when the entire program is available for analysis. <p> The difficulty associated with implementing the algorithms discussed ranges from easy to difficult, as evaluated by my subjective rating shown in the table above. Some algorithms, such as Hall & Kennedys and Callahan et al.s, have been used in working interprocedural optimizing compilers for several years <ref> [Hall 91] </ref>. Some algorithms, including Lakhotias and Ryders, are described with pseudocode, while others, such as the algorithms by Steensgaard and Shivers, are described only in terms of abstract semantic functions.
Reference: [Hall et al. 91] <author> Mary W. Hall, Ken Kennedy, and Kathryn S. McKinley. </author> <title> Interprocedural transformations for parallel code generation. </title> <booktitle> In Proceedings of Supercomputing 91, </booktitle> <pages> pages 424434, </pages> <address> Los Alamitos, CA, </address> <month> November </month> <year> 1991. </year> <journal> IEEE Computer Society. </journal>
Reference-contexts: Recent research on interprocedural optimization has developed algorithms for many areas of optimization, including interprocedural constant propagation [Wegman & Zadeck 85], alias analysis [Landi & Ryder 92] parallelization of loops containing procedure calls <ref> [Hall et al. 91] </ref>, interprocedural register allocation [Wall 86], and inlining [Hwu & Chang 89]. All of these algorithms that apply interprocedural analysis require that a representation of the programs calling structure exists, just as intraprocedural analyses require a representation of the control ow within a procedure.
Reference: [Henry 93] <author> Robert R. Henry. </author> <title> Personal communication. CSE 590K Invited Talk on Tera Computers Compiler Technology, </title> <booktitle> Fall, </booktitle> <year> 1993. </year>
Reference-contexts: When performing aggressive interprocedural optimizations, however, it is desirable to have access to the text of the entire program. To facilitate this, many new compilers such as the Tera compilers <ref> [Henry 93] </ref> and the ParaScope Fortran compiler [Hall 91] delay some compiler tasks, including optimization and code generation, until link-time, when the entire program is available for analysis.
Reference: [Horwitz et al. 90] <author> Susan Horwitz, Thomas Reps, and David Binkley. </author> <title> Interprocedural slicing using dependence graphs. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 12(1):2660, </volume> <month> January </month> <year> 1990. </year>
Reference-contexts: The algorithm is loosely based on Wegman and Zadecks interprocedural constant propagation algorithm. Reusing the existing work on constant propagation is an interesting application of an old technique to a new problem domain. Second, the program is represented using the system dependence graph representation proposed by Horwitz <ref> [Horwitz et al. 90] </ref>. This representation makes both data ow and control edges explicit. Using the data ow edges makes the computation of the call graph a matter of identifying sources of procedure values and using the data ow edges to ow these values through the program.
Reference: [Hudak 86] <author> Paul Hudak. </author> <title> A semantic model of reference counting and its abstraction. </title> <booktitle> In ACM Symposium on LISP and Functional Programming, </booktitle> <pages> pages 351363, </pages> <month> August </month> <year> 1986. </year>
Reference-contexts: Partitioning the analysis based on the call site is something also done by Hudak in his semantic model of reference counting <ref> [Hudak 86] </ref>. Although the Hudak work only addresses reference counting for a first-order language, it is expressed in a non-standard abstract semantics framework that is very similar to the expression of Shiverss algorithms.
Reference: [Hwu & Chang 89] <author> Wen-Mei Hwu and Pohua P. Chang. </author> <title> Inline function expansion for compiling C programs. </title> <journal> SIGPLAN Notices, </journal> <volume> 24(7):246257, </volume> <month> July </month> <year> 1989. </year> <title> In Proceedings of the ACM 21 Call Graph Analysis in the Presence of Higher-Order Functions Generals Examination Written Report SIGPLAN 89 Conference on Programming Language Design and Implementation. </title>
Reference-contexts: Recent research on interprocedural optimization has developed algorithms for many areas of optimization, including interprocedural constant propagation [Wegman & Zadeck 85], alias analysis [Landi & Ryder 92] parallelization of loops containing procedure calls [Hall et al. 91], interprocedural register allocation [Wall 86], and inlining <ref> [Hwu & Chang 89] </ref>. All of these algorithms that apply interprocedural analysis require that a representation of the programs calling structure exists, just as intraprocedural analyses require a representation of the control ow within a procedure.
Reference: [Kranz 88] <author> David Kranz. </author> <title> ORBIT: An Optimizing Compiler for Scheme. </title> <type> PhD thesis, </type> <institution> Yale University, </institution> <month> February </month> <year> 1988. </year> <institution> Department of Computer Science, </institution> <note> Research Report 632. </note>
Reference-contexts: They compute their result, and call the continuation, passing the result of the computation as an argument. The top-level-continuation is called with the result of the program as an argument. Standard Scheme programs can be converted into equivalent CPS-style Scheme programs through straightforward transformations <ref> [Kranz 88] </ref>. Using CPS as a compiler intermediate representation was first proposed by Steele, and he demonstrated its effectiveness in the Rabbit Scheme compiler [Steele 78]. Since then, CPS-style representations have been adopted by a number of advanced language compilers, including the Orbit Scheme compiler [Kranz 88] and the Standard ML <p> Scheme programs through straightforward transformations <ref> [Kranz 88] </ref>. Using CPS as a compiler intermediate representation was first proposed by Steele, and he demonstrated its effectiveness in the Rabbit Scheme compiler [Steele 78]. Since then, CPS-style representations have been adopted by a number of advanced language compilers, including the Orbit Scheme compiler [Kranz 88] and the Standard ML of New Jersey compiler for ML [Appel & Jim 89]. None of these compilers perform any significant control or data-ow analysis on programs, however.
Reference: [Lakhotia 93] <author> Arun Lakhotia. </author> <title> Constructing call multigraphs using dependence graphs. </title> <booktitle> In Conference Record of the Twentieth Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, </booktitle> <pages> pages 273284, </pages> <address> Charleston, South Carolina, </address> <month> January </month> <year> 1993. </year>
Reference-contexts: I will examine this issue in more depth in section 6.1. 3 Smearing Algorithms This first class of algorithms are the most efficient but least precise. The three algorithms discussed in this category were developed by Hall & Kennedy [Hall & Kennedy 92], Lakhotia <ref> [Lakhotia 93] </ref>, and Shivers [Shivers 88]. Although they all compute essentially the same call graph, they differ substantially in the language features they support and in the structure of the algorithm. <p> algorithm that propagates parameter bindings individually, computing a call graph for a procedural language where indirect calls are permitted through procedure variables, global variables are not permitted, parameters are passed by value-result, and aliasing is prohibited by not permitting variables to be passed in multiple positions in a procedure call <ref> [Lakhotia 93] </ref>. The pseudocode presented in the paper had several errors, but once these were resolved, there were two interesting aspects of this work.
Reference: [Landi & Ryder 92] <author> William Landi and Barbara G. Ryder. </author> <title> A safe approximate algorithm for interprocedural pointer aliasing. </title> <journal> SIGPLAN Notices, </journal> <volume> 27(7):235248, </volume> <month> July </month> <year> 1992. </year> <booktitle> In Proceedings of the ACM SIGPLAN 92 Conference on Programming Language Design and Implementation. </booktitle>
Reference-contexts: Recent research on interprocedural optimization has developed algorithms for many areas of optimization, including interprocedural constant propagation [Wegman & Zadeck 85], alias analysis <ref> [Landi & Ryder 92] </ref> parallelization of loops containing procedure calls [Hall et al. 91], interprocedural register allocation [Wall 86], and inlining [Hwu & Chang 89].
Reference: [Palsberg & Schwartzbach 91] <author> Jens Palsberg and Michael I. Schwartzbach. </author> <title> Object-oriented type inference. </title> <journal> SIGPLAN Notices, </journal> <volume> 26(11):146161, </volume> <month> November </month> <year> 1991. </year> <booktitle> In OOPSLA91 Conference Proceedings. </booktitle>
Reference-contexts: Because the problems of control-ow, type inference, and data ow are all interrelated, the problems are solved simultaneously by iterative analysis. Palsberg & Schwartzbach provide an algorithm to perform constraint-based type inference of an object-oriented language supporting inheritance, assignment, and dynamically-dispatched message sends <ref> [Palsberg & Schwartzbach 91] </ref>. Their algorithm analyzes type information owing into a method separately for each call site of the method, and is similar in this respect to Shiverss 1CFA algorithm.
Reference: [Pande & Ryder 94] <author> Hemant D. Pande and Barbara G. Ryder. </author> <title> Static type determination for C++. </title> <booktitle> In Proceedings of Sixth USENIX C++ Technical Conference, </booktitle> <year> 1994. </year> <note> To appear. </note>
Reference-contexts: Pande & Ryder have shown that such a computation for an object-oriented language is NP-hard in the presence of pointers, even if the language is restricted to only allow single-level pointers 15 Call Graph Analysis in the Presence of Higher-Order Functions Generals Examination Written Report <ref> [Pande & Ryder 94] </ref>. As usual, this means that we must be satisfied with an imprecise solution in order to make the problem practical. Many similarities exist between the difficulties posed by higher-order functions and those posed by dynamically-dispatched message sends. <p> Pande & Ryder present a more traditional approach for type determination of C++ programs with single-level pointers <ref> [Pande & Ryder 94] </ref>. Their approach integrates type determination with alias analysis, owing type and alias information around the program until a fixed-point is reached.
Reference: [Plevyak & Chien 94] <author> John Plevyak and Andrew A. Chien. </author> <title> Precise concrete type inference for object-oriented languages. </title> <journal> SIGPLAN Notices, </journal> <volume> 29(11), </volume> <month> November </month> <year> 1994. </year> <note> To appear in OOPSLA94 Conference Proceedings. </note>
Reference-contexts: Plevyak & Chien have developed an algorithm that uses Palsberg & Schwartzbachs basic framework, but which detects regions of imprecision in the call graph and incrementally extends precision within these regions <ref> [Plevyak & Chien 94] </ref>. By initially smearing information together, but incrementally splitting smeared call sites when imprecisions are detected, the algorithm is able to be both precise and efficient. The precision can also be adjusted by altering the heuristics that determine when smeared call sites should be split. <p> call-site specific basis is needed, implying that at least the kCFA algorithms, and perhaps the full-path based algorithms are better candidates for applying to object-oriented languages, although Plevyak & Chien have noted that using a fixed-level of precision, as in Shiverss kCFA algorithms, leads to both efficiency and precision problems <ref> [Plevyak & Chien 94] </ref>. Handling side-effects is another area where the approaches proposed for handling higher-order functions are likely to be insufficient for performing type-determination.
Reference: [Ryder 79] <author> Barbara Ryder. </author> <title> Constructing the call graph of a program. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 5(3):216225, </volume> <year> 1979. </year>
Reference-contexts: 2 : (call-id bar) - foo,bar - Single c 3 call site split for analysis purposes 11 Call Graph Analysis in the Presence of Higher-Order Functions Generals Examination Written Report 5.1 Precise Algorithms for Simple Languages Ryder developed a very precise algorithm for performing call graph analysis of Fortran77 programs <ref> [Ryder 79] </ref>. The Fortran77 standard does not allow recursion, and therefore the call graph cannot contain any cycles. The algorithm exploits this restriction by ensuring that a procedure is processed before any procedures which it calls.
Reference: [Shivers 88] <author> Olin Shivers. </author> <title> Control-flow analysis in scheme. </title> <journal> SIGPLAN Notices, </journal> <volume> 23(7):164174, </volume> <month> July </month> <year> 1988. </year> <booktitle> In Proceedings of the ACM SIGPLAN 88 Conference on Programming Language Design and Implementation. </booktitle>
Reference-contexts: The problem of call graph construction is succinctly defined by Shivers <ref> [Shivers 88] </ref>: For each call site c in program P, what is the set F (c) of functions that c could be a call to? For programs in which every call site is statically-bound to a single procedure constant, a precise call graph can be constructed in a single pass over <p> I will examine this issue in more depth in section 6.1. 3 Smearing Algorithms This first class of algorithms are the most efficient but least precise. The three algorithms discussed in this category were developed by Hall & Kennedy [Hall & Kennedy 92], Lakhotia [Lakhotia 93], and Shivers <ref> [Shivers 88] </ref>. Although they all compute essentially the same call graph, they differ substantially in the language features they support and in the structure of the algorithm. <p> This smearing is necessary to reduce the number of possible functions from infinite to finite, thereby making the problem computable. Shivers first presented an informal description of the 0CFA algorithm <ref> [Shivers 88] </ref>, and subsequently published a more formal, abstract semantics-based description of both the 0CFA and 1CFA algorithms [Shivers 91b]. This section discusses 0CFA, and section 4 contrasts the differences between it and the more precise kCFA algorithms. <p> Handling side-effects is another area where the approaches proposed for handling higher-order functions are likely to be insufficient for performing type-determination. The solution of having a single set representing the set of values that have escaped, proposed by both Hall & Kennedy [Hall & Kennedy 92] and by Shivers <ref> [Shivers 88] </ref>, is sufficient when relatively few values are stored into data structures. Because type determination involves tracking all values and not just procedure values, this coarse model of side-effects is unlikely to be sufficient precise.
Reference: [Shivers 91a] <author> Olin Shivers. </author> <title> Control-Flow Analysis of Higher-Order Languages. </title> <type> PhD thesis, </type> <institution> Carnegie Mellon University, </institution> <month> May </month> <year> 1991. </year> <month> CMU-CS-91-145. </month>
Reference-contexts: Developing an algorithm to compute an exact call graph for a particular execution of a program P written in language L can be done by modifying an interpreter for L to maintain a cache of calls that occur during the execution of P <ref> [Shivers 91a] </ref>. Whenever a call is made from a call site c, the target function f is added to the cache of calls made from that call site. When the program terminates, the call cache contains a record of all procedure calls made from each call site in the program. <p> None of these compilers perform any significant control or data-ow analysis on programs, however. Proponents of using CPS as an intermediate representation maintain that its uniform approach to handling all control transfers make compilers easier to write and to reason about <ref> [Shivers 91a] </ref>. In particular, since all control transfers are represented as procedure invocations, the traditional dichotomy between intraprocedural and interprocedural analysis disappears, allowing all execution paths to be handled uniformly. <p> However, CPS form makes handling certain language features, such as procedure-valued returns, fall out naturally without any additional effort in the analysis. 3.1.2 Shiverss 0CFA Algorithm Shivers has developed a family of algorithms for call graph analysis of Scheme programs that provide varying degrees of precision and complexity <ref> [Shivers 91a] </ref>. The algorithms are referred to as 0CFA (control ow analysis), 1CFA, 2CFA, etc., with the numeric prefix indicating the amount of path information that is maintained separately for different call sites before it is smeared together. <p> Both Hall & Kennedy and Shivers propose a similar, fairly imprecise approach towards handling such assignments [Hall & Kennedy 92] <ref> [Shivers 91a] </ref>. Both approaches involve maintaining a single set g, containing those procedure values that may be bound to any procedure value through assignment. <p> In this case, a conservative model of the potential behavior of the missing pieces of the program is necessary. Of the algorithms examined, only Shivers proposes a scheme for handling incomplete programs <ref> [Shivers 91a] </ref>, but the scheme could be easily adapted to any of the algorithms. The approach involves maintaining a set of escaped functions. Functions are added to this escaped set whenever a function is passed to a routine that is external to the known part of the program.
Reference: [Shivers 91b] <author> Olin Shivers. </author> <title> The semantics of scheme control-flow analysis. </title> <booktitle> In In Proceedings of the Symposium on Partial Evaluation and Semantics-Based Program Manipulation 91, pages 190198, </booktitle> <address> New Haven, CT, </address> <month> June </month> <year> 1991. </year> <note> Published as SIGPLAN Notices 26(9). </note>
Reference-contexts: This smearing is necessary to reduce the number of possible functions from infinite to finite, thereby making the problem computable. Shivers first presented an informal description of the 0CFA algorithm [Shivers 88], and subsequently published a more formal, abstract semantics-based description of both the 0CFA and 1CFA algorithms <ref> [Shivers 91b] </ref>. This section discusses 0CFA, and section 4 contrasts the differences between it and the more precise kCFA algorithms.
Reference: [Steele 78] <author> Guy L. Steele, Jr. Rabbit: </author> <title> A compiler for scheme. </title> <type> Technical Report 474, </type> <institution> MIT AI Lab, </institution> <month> May </month> <year> 1978. </year>
Reference-contexts: Standard Scheme programs can be converted into equivalent CPS-style Scheme programs through straightforward transformations [Kranz 88]. Using CPS as a compiler intermediate representation was first proposed by Steele, and he demonstrated its effectiveness in the Rabbit Scheme compiler <ref> [Steele 78] </ref>. Since then, CPS-style representations have been adopted by a number of advanced language compilers, including the Orbit Scheme compiler [Kranz 88] and the Standard ML of New Jersey compiler for ML [Appel & Jim 89].
Reference: [Steensgaard 94] <author> Bjarne Steensgaard. </author> <title> A polyvariant closure analysis with dynamic abstraction. </title> <type> Unpublished manuscript, </type> <year> 1994. </year>
Reference-contexts: Steensgaard has developed a closure analysis algorithm for a functional subset of Scheme that attempts to maintain separate information for each call site in the programs <ref> [Steensgaard 94] </ref>. Without loops in the call graph, this approach will terminate and will terminate, because there are only a finite number of paths through the call graph and therefore are only a finite number of environments in which functions can be created. <p> Steensgaard has chosen to widen by smearing together the argument lists from the loop entering call with the argument lists from all of the possible loop closing calls, although other choices of widening operations are possible <ref> [Steensgaard 94] </ref>. Steensgaards algorithm provides extremely precise results, but it is very computationally expensive.
Reference: [Wall 86] <author> David W. Wall. </author> <title> Register allocation at link time. </title> <journal> SIGPLAN Notices, </journal> <volume> 21(7):264275, </volume> <month> July </month> <year> 1986. </year> <booktitle> In Proceedings of the ACM SIGPLAN 86 Symposium on Compiler Construction. </booktitle>
Reference-contexts: Recent research on interprocedural optimization has developed algorithms for many areas of optimization, including interprocedural constant propagation [Wegman & Zadeck 85], alias analysis [Landi & Ryder 92] parallelization of loops containing procedure calls [Hall et al. 91], interprocedural register allocation <ref> [Wall 86] </ref>, and inlining [Hwu & Chang 89]. All of these algorithms that apply interprocedural analysis require that a representation of the programs calling structure exists, just as intraprocedural analyses require a representation of the control ow within a procedure.
Reference: [Wegman & Zadeck 85] <author> Mark N. Wegman and F. Kenneth Zadeck. </author> <title> Constant propagation with conditional branches. </title> <booktitle> In Conference Record of the Twelfth Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 291299, </pages> <address> New Orleans, Louisiana, </address> <month> January </month> <year> 1985. </year>
Reference-contexts: Recent research on interprocedural optimization has developed algorithms for many areas of optimization, including interprocedural constant propagation <ref> [Wegman & Zadeck 85] </ref>, alias analysis [Landi & Ryder 92] parallelization of loops containing procedure calls [Hall et al. 91], interprocedural register allocation [Wall 86], and inlining [Hwu & Chang 89].
Reference: [Weihl 80] <author> William E. Weihl. </author> <title> Interprocedural data flow analysis in the presence of pointers, procedure variables and label variables. </title> <booktitle> In Conference Record of the Seventh Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 8394, </pages> <address> Las Vegas, Nevada, </address> <month> January </month> <year> 1980. </year>
Reference-contexts: Weihl has examined the problem of computing an optimal call graph for languages with no aliasing, no nested procedure declarations, and no conditional branches within procedures, and has shown that, even with this restrictive language model, the problem is P-space hard <ref> [Weihl 80] </ref>. It is likely, therefore, that no polynomial time algorithm exists to compute exact call graphs. To make call graph construction practical, then, as with many other compiler problems, an approximation to the optimal solution must be accepted. <p> Weihl presents a more precise method for handling assignments wherein a separate g set of possible values is maintained for each procedure variable <ref> [Weihl 80] </ref>. New elements are added to these sets when new bindings are discovered that reach an assignment to the variable. This change increases the cost of the algorithm, since assignments within procedure bodies must now be processed, rather than just processing call sites. <p> A more fine-grained approach, such as Weihls suggestion of maintaining a separate set for each variable in the program, is likely to be required to obtain precise results <ref> [Weihl 80] </ref>. It seems that type-determination for object-oriented languages, because of the pervasiveness of polymorphic functions and the extensive use of dynamically-dispatched call sites, requires analysis techniques designed to handle frequent use of these features.
References-found: 30

