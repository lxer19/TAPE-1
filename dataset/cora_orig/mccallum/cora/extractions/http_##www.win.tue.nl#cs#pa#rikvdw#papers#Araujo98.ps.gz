URL: http://www.win.tue.nl/cs/pa/rikvdw/papers/Araujo98.ps.gz
Refering-URL: http://www.win.tue.nl/cs/pa/rikvdw/bibl.html
Root-URL: http://www.win.tue.nl
Title: Code Compression Based on Operand Factorization  
Author: Guido Araujo Ricardo Pannain Paulo Centoducatte Mario Cortes 
Note: Relatorio Tecnico IC-98-25 Julho de 1998  
Abstract: O conteudo do presente relatorio e de unica responsabilidade do(s) autor(es). The contents of this report are the sole responsibility of the author(s). 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Charles Lefurgy, Peter Bird, I-Cheng Chen, and Trevor Mudge. </author> <title> Improving code density using compression techniques. </title> <booktitle> In Proceedings of Micro-30: The 30th Annual International Symposium on Microarchitecture, </booktitle> <pages> pages 194-203, </pages> <month> December </month> <year> 1997. </year>
Reference-contexts: It also means more instructions to perform 1 Thumb and MIPS16 have 16-bit instructions 2 the same amount of computation. The net result are 30%-40% smaller programs running 15%-20% slower than programs using standard RISC instructions <ref> [1] </ref>. Another way to reduce the size of RISC programs is to design a processor which can execute compressed code. In order to do that, the decompression engine has to perform real-time code decompression. Moreover, because programs have branch instructions, the engine must also allow for random codeword decompression. <p> Using this approach a 73% compression ratio has been reported for the MIPS instruction set [6, 8]. The decompression engine proposed in the CCRP is also the only implemented real-time RISC decompression engine ever reported in the literature [9]. Lefurgy et al. <ref> [1] </ref> proposed an interesting code compression technique based on dictionary encoding. In [1] object code is parsed and common sequences of instructions are replaced by a single codeword. Only frequent sequences are compressed. Escape bits are used to distinguish between a codeword and an uncompressed instruction. <p> The decompression engine proposed in the CCRP is also the only implemented real-time RISC decompression engine ever reported in the literature [9]. Lefurgy et al. <ref> [1] </ref> proposed an interesting code compression technique based on dictionary encoding. In [1] object code is parsed and common sequences of instructions are replaced by a single codeword. Only frequent sequences are compressed. Escape bits are used to distinguish between a codeword and an uncompressed instruction. The instructions corresponding to each codeword are stored into a dictionary in the decompression engine. <p> The target address is then computed by adding these two. Although this approach restricts the range of branch addresses, few program branches require long range addresses <ref> [1] </ref>, and these can be determined through a small jump table. This technique requires modifications in the control unit of the processor core. Lefurgy et al. studied two compression techniques. The first approach is based on fixed-length codewords. <p> The first approach is based on fixed-length codewords. In the second approach, better compression ratios were achieved through nibble aligned variable length encoding. In this case, average size reductions of 39%, 34%, and 26% have been reported for the PowerPC, ARM and i386 processors <ref> [1] </ref>. In [3] a technique called patternization was proposed to encode bytecode strings. The basic idea behind patternization is to extract all possible instruction patterns from the expression trees in a program. Tree-patterns are compiled into a tree-matching code generator based on iburg [10]. <p> Otherwise, the overhead due to the introduction of call and return instructions can surpass the gains. In Section 4 we show that, in average, the most common instruction patterns are very small. This was also noticed in <ref> [1] </ref>. 3 Operand Factorization The central idea in this paper is the separation of each expression tree in the program into two components: a tree-pattern, formed by the instructions in the expression tree after removing its operands; and a sequence of operands, called operand-pattern, containing the registers and immediates used by <p> This confirms, at an instruction level, the observation made in <ref> [1] </ref> about the role played by small bit strings in program code. On the other hand, it also brings to light a feature of programs that cannot be captured by other compression methods. <p> On the other hand, we have noticed that lower compression ratios (&lt; 50%) can only be achieved if codewords can split across word boundaries. The reason, also noticed in <ref> [1] </ref>, is related to the fact that many common patterns are originated from a single instruction word. Therefore, constraining codewords to a single word considerably limits the compression ratio. An alternative to that is to combine operand 12 factorization and cache-line based compression [6, 8]. <p> For the studied programs it results in 26.7%. The overhead of the IMD, with respect to the uncompressed programs, is shown in Table 2. In average it corresponds to only 2.2% of the original code. 5.4 Branch Target Address We borrow here the ideas developed in [6] and <ref> [1] </ref>. As mentioned before, our compression method can also be used for cache-line based compression. In fact, depending on the final performance of the decompression engine, a cache-line based approach may be very appropri 5 Similar numbers are presented in [16]. 16 ate in our final design. <p> In this case, the LAT/CLB address mapping technique in [6] should be used to compute branch addresses. If that is not the case, the address computation method proposed in <ref> [1] </ref> will be adopted. 6 Experimental Results Three sets of experiments have been designed to determine the best encoding for tree and operand patterns. The objective of the first set was to determine the compression ratio using fixed-length and Huffman encoding.
Reference: [2] <author> Michael Franz and Kistler Thomas. </author> <title> Slim binaries. </title> <journal> Communication of the ACM, </journal> <volume> 40(12) </volume> <pages> 87-94, </pages> <month> december </month> <year> 1997. </year>
Reference-contexts: The key idea here is an operation that factors out the operands (operand-patterns) from the expression trees of a program. The factored expression trees are called tree-patterns. Tree and operand patterns are then encoded separately. Variations of operand factorization have been used before in <ref> [2, 3] </ref>. Our work differs from theirs in the sense that we are mainly interested in finding an encoding which allows efficient implementations of real-time decompression engines. Moreover, we provide a quantitative approach to the problem which verifies the efficacy of our method. <p> The main goal of patternization is to synthesize an efficient virtual machine that can execute compressed code delivered through a network. The use of gzip makes this technique inappropriate for real-time decompression. Slim binaries is a compression technique proposed by Frank and Thomas <ref> [2] </ref> for a platform independent program format. In [2] program abstract syntax trees are compressed into a sequence of symbols from an adaptive dictionary. Similar syntax trees are encoded using the same sequence. <p> The use of gzip makes this technique inappropriate for real-time decompression. Slim binaries is a compression technique proposed by Frank and Thomas <ref> [2] </ref> for a platform independent program format. In [2] program abstract syntax trees are compressed into a sequence of symbols from an adaptive dictionary. Similar syntax trees are encoded using the same sequence. The compression scheme is based on the LZ algorithm, and results in compression rates of up to 50% [2]. <p> In <ref> [2] </ref> program abstract syntax trees are compressed into a sequence of symbols from an adaptive dictionary. Similar syntax trees are encoded using the same sequence. The compression scheme is based on the LZ algorithm, and results in compression rates of up to 50% [2]. Slim binaries are targeted to source level compression. This technique has been used in MC68020-base Macintosh computers since 1993. Liao et al. [11] proposed a compression technique exclusively based on software. Their main idea is to substitute common instruction sequences for sub-routine calls.
Reference: [3] <author> Jean Ernst, William Evans, Christopher W. Fraser, Steven Lucco, and Todd A. Proeb-sting. </author> <title> Code compression. </title> <booktitle> In SIGPLAN Programming Languages Design and Implementation, </booktitle> <year> 1997. </year> <title> 8 This is very common in code generation. </title> <type> 21 </type>
Reference-contexts: The key idea here is an operation that factors out the operands (operand-patterns) from the expression trees of a program. The factored expression trees are called tree-patterns. Tree and operand patterns are then encoded separately. Variations of operand factorization have been used before in <ref> [2, 3] </ref>. Our work differs from theirs in the sense that we are mainly interested in finding an encoding which allows efficient implementations of real-time decompression engines. Moreover, we provide a quantitative approach to the problem which verifies the efficacy of our method. <p> The first approach is based on fixed-length codewords. In the second approach, better compression ratios were achieved through nibble aligned variable length encoding. In this case, average size reductions of 39%, 34%, and 26% have been reported for the PowerPC, ARM and i386 processors [1]. In <ref> [3] </ref> a technique called patternization was proposed to encode bytecode strings. The basic idea behind patternization is to extract all possible instruction patterns from the expression trees in a program. Tree-patterns are compiled into a tree-matching code generator based on iburg [10]. <p> The original expression trees in the program are replaced by their patterns and the sequence of patterns is encoded using gzip. The compressed format is named wire-format, and results in compression ratios close to 30% <ref> [3] </ref>. The main goal of patternization is to synthesize an efficient virtual machine that can execute compressed code delivered through a network. The use of gzip makes this technique inappropriate for real-time decompression.
Reference: [4] <author> Timothy C. Bell, Jhon G. Cleary, and Ian H. Witten. </author> <title> Text Compression. Advanced Reference Series. </title> <publisher> Prentice Hall, </publisher> <address> New Jersey, </address> <year> 1990. </year>
Reference-contexts: Experimental results are analyzed in Section 6. Section 7 resumes the work and proposes two interesting extensions. 2 Related Work A large number of techniques have been proposed in the literature for the file compression problem <ref> [4] </ref>. Many of these techniques are sequential in nature, in the sense that the decompression of the current codeword requires symbols from the partially decompressed string. 2 compression ratio = size of compressed program / size of uncompressed program. 3 A classical example is Lempel-Zvi (LZ) compression [5]. <p> Bounded-Huffman is also used in MPEG-2 [15] and in CCRP [6]. It is useful as a way to restrict the size 11 of the Huffman codeword, thus reducing the complexity of the decompression engine. Since Huffman encoding is an optimal technique <ref> [4] </ref>, encoding part of the symbols using fixed-length codewords will result in higher compression ratios. In Section 6 we show that this overhead can be almost completely eliminated. * VLC Encoding (VLC) This is a variation of the MPEG-2 VLC encoding [15]. <p> Operand-patterns that have immediates can be used to simplify the logic in RGEN. When the operand-pattern encoded by Op contains an immediate, the register bus associated to the immediate operand is not needed and can be made "don't care". For example, the operand-pattern <ref> [r2, r5, 4] </ref> will result in RD = 00010, RS1 = 00101 and RS2 = xxxxx (i.e. "don't care"). Observe that patterns which share registers can also be used to minimize RGEN logic. <p> Patterns which have small contributions do not change much the program entropy 6 . Lower entropy results in small redundancy what causes Huffman compression to approach fixed-length compression <ref> [4] </ref>. By switching from Huffman to fixed-length encoding, at a point when the pattern distribution becomes more uniform, one can minimize the impact of not using Huffman. Consider, for example, program go in Figure 8. <p> Fixed-length 57.7 46.2 48.1 50.5 Huffman 45.4 35.0 35.8 38.2 Bounded-Huffman 46.0 36.6 37.4 39.8 VLC 47.9 37.5 38.3 40.7 Table 3: Average compression ratio after combining encoding methods for tree and operand patterns. 6 Entropy is a measure of the amount of redundant information in a set of symbols <ref> [4] </ref> 7 Not shown in in the graphs. 19 all programs, when the encoding methods for tree and operand patterns are combined. The Bounded-Huffman and VLC compression ratios were determined from the graphs of Figures 8-11 by taking the average of the global minima of all programs.
Reference: [5] <author> A. Lempel and J. Ziv. </author> <title> On the complexity of finite sequences. </title> <journal> IEEE Transaction on Information Theory, </journal> <volume> IT-22(1):75-81, </volume> <month> January </month> <year> 1976. </year>
Reference-contexts: Many of these techniques are sequential in nature, in the sense that the decompression of the current codeword requires symbols from the partially decompressed string. 2 compression ratio = size of compressed program / size of uncompressed program. 3 A classical example is Lempel-Zvi (LZ) compression <ref> [5] </ref>. In LZ compression the dictionary is encoded together with the compressed string. Pointers to previously parsed substrings are used to encode the current substring. Decompression is done by substituting a pointer for the substring it points to. <p> Operand factorization recognizes the fact that any encoding technique which intermixes opcode and operand bits during compression misses the opportunity to capture the high correlation exhibited by tree and operand patterns. For example, an algorithm which performs sequential compression, like LZ <ref> [5] </ref>, is not able 10 to detect the simple tree-pattern formed by lw *,*,* followed by add *,*,*. Any non-sequential algorithm which considers a program as a set of bit strings will also miss that.
Reference: [6] <author> Andrew Wolfe and Alex Channin. </author> <title> Executing compressed programs on an embedded RISC architecture. </title> <booktitle> In Proceedings of Mcro-25: The 25th Annual International Symposium on Microarchitecture, </booktitle> <pages> pages 81-91, </pages> <month> December </month> <year> 1992. </year>
Reference-contexts: This section describes only prior compression techniques that can lead to efficient real-time decompression engines. The first approach to code compression in a RISC architecture was originally proposed by Wolfe and Channin <ref> [6] </ref>. The processor described in [6] is called Code Compression RISC Processor (CCRP). In the CCRP code is compressed one cache-line at a time. Compressed cache lines are fetched from main-memory, uncompressed and put into the instruction cache. Instructions in the cache are exactly as in the original uncompressed program. <p> This section describes only prior compression techniques that can lead to efficient real-time decompression engines. The first approach to code compression in a RISC architecture was originally proposed by Wolfe and Channin <ref> [6] </ref>. The processor described in [6] is called Code Compression RISC Processor (CCRP). In the CCRP code is compressed one cache-line at a time. Compressed cache lines are fetched from main-memory, uncompressed and put into the instruction cache. Instructions in the cache are exactly as in the original uncompressed program. <p> The compression algorithm for the CCRP is based on Huffman encoding [7], and uncompressed program symbols are one byte long. Using this approach a 73% compression ratio has been reported for the MIPS instruction set <ref> [6, 8] </ref>. The decompression engine proposed in the CCRP is also the only implemented real-time RISC decompression engine ever reported in the literature [9]. Lefurgy et al. [1] proposed an interesting code compression technique based on dictionary encoding. <p> They are: * Bounded-Huffman (BH) In Bounded-Huffman an escape bit is appended to the beginning of the codeword, so as to identify if the codeword uses Huffman or fixed-length encoding. Bounded-Huffman is also used in MPEG-2 [15] and in CCRP <ref> [6] </ref>. It is useful as a way to restrict the size 11 of the Huffman codeword, thus reducing the complexity of the decompression engine. Since Huffman encoding is an optimal technique [4], encoding part of the symbols using fixed-length codewords will result in higher compression ratios. <p> The reason, also noticed in [1], is related to the fact that many common patterns are originated from a single instruction word. Therefore, constraining codewords to a single word considerably limits the compression ratio. An alternative to that is to combine operand 12 factorization and cache-line based compression <ref> [6, 8] </ref>. This is an interesting possibility that may be considered in the future. 5 The Decompression Engine Despite of its high compression ratios, variable length encoding implies in low decoding efficiency. <p> For the studied programs it results in 26.7%. The overhead of the IMD, with respect to the uncompressed programs, is shown in Table 2. In average it corresponds to only 2.2% of the original code. 5.4 Branch Target Address We borrow here the ideas developed in <ref> [6] </ref> and [1]. As mentioned before, our compression method can also be used for cache-line based compression. In fact, depending on the final performance of the decompression engine, a cache-line based approach may be very appropri 5 Similar numbers are presented in [16]. 16 ate in our final design. <p> In fact, depending on the final performance of the decompression engine, a cache-line based approach may be very appropri 5 Similar numbers are presented in [16]. 16 ate in our final design. In this case, the LAT/CLB address mapping technique in <ref> [6] </ref> should be used to compute branch addresses. If that is not the case, the address computation method proposed in [1] will be adopted. 6 Experimental Results Three sets of experiments have been designed to determine the best encoding for tree and operand patterns.
Reference: [7] <author> D. A. Huffman. </author> <title> A method for the construction of minimum-redundancy codes. </title> <booktitle> Proceedings of the IRE, </booktitle> <volume> 40(9) </volume> <pages> 1098-1101, </pages> <month> September </month> <year> 1952. </year>
Reference-contexts: A clever encoding of the LAT entries restricts the size of the table. The CCRP uses a Cache Line Address Lookaside Buffer (CLB) to store a set of recently fetched LAT entries. The compression algorithm for the CCRP is based on Huffman encoding <ref> [7] </ref>, and uncompressed program symbols are one byte long. Using this approach a 73% compression ratio has been reported for the MIPS instruction set [6, 8]. The decompression engine proposed in the CCRP is also the only implemented real-time RISC decompression engine ever reported in the literature [9].
Reference: [8] <author> Michael Kozuch and Andrew Wolfe. </author> <title> Compression of embedded system programs. </title> <booktitle> In Proceedings of the IEEE International Conference on Computer Design, </booktitle> <pages> pages 270-277, </pages> <month> October. </month>
Reference-contexts: The compression algorithm for the CCRP is based on Huffman encoding [7], and uncompressed program symbols are one byte long. Using this approach a 73% compression ratio has been reported for the MIPS instruction set <ref> [6, 8] </ref>. The decompression engine proposed in the CCRP is also the only implemented real-time RISC decompression engine ever reported in the literature [9]. Lefurgy et al. [1] proposed an interesting code compression technique based on dictionary encoding. <p> The reason, also noticed in [1], is related to the fact that many common patterns are originated from a single instruction word. Therefore, constraining codewords to a single word considerably limits the compression ratio. An alternative to that is to combine operand 12 factorization and cache-line based compression <ref> [6, 8] </ref>. This is an interesting possibility that may be considered in the future. 5 The Decompression Engine Despite of its high compression ratios, variable length encoding implies in low decoding efficiency.
Reference: [9] <author> Martin Benes, Andrew Wolfe, and Steven M. Nowick. </author> <title> A high-speed asynchronous decompression circuit for embedded processors. </title> <booktitle> In Proceedings of 17th Conference on Advanced Research in VLSI, </booktitle> <address> Los Alamitos, CA, 1997. </address> <publisher> IEEE Society Press. </publisher>
Reference-contexts: Using this approach a 73% compression ratio has been reported for the MIPS instruction set [6, 8]. The decompression engine proposed in the CCRP is also the only implemented real-time RISC decompression engine ever reported in the literature <ref> [9] </ref>. Lefurgy et al. [1] proposed an interesting code compression technique based on dictionary encoding. In [1] object code is parsed and common sequences of instructions are replaced by a single codeword. Only frequent sequences are compressed. Escape bits are used to distinguish between a codeword and an uncompressed instruction.
Reference: [10] <author> C.W. Fraser, D.R. Hanson, and T.A. Proebsting. </author> <title> Engineering a simple, efficient code generator. </title> <journal> Journal of the ACM, </journal> <volume> 22(12) </volume> <pages> 248-262, </pages> <month> March </month> <year> 1993. </year>
Reference-contexts: In [3] a technique called patternization was proposed to encode bytecode strings. The basic idea behind patternization is to extract all possible instruction patterns from the expression trees in a program. Tree-patterns are compiled into a tree-matching code generator based on iburg <ref> [10] </ref>. Expression trees covering is then performed to determine the best set of patterns that covers the program. The original expression trees in the program are replaced by their patterns and the sequence of patterns is encoded using gzip.
Reference: [11] <author> Stan Y. Liao, Srinivas Devadas, and Kurt Keutzer. </author> <title> Code density optimization for embedded DSP processors using data compression techniques. </title> <booktitle> In Proceedings of 16th Conference on Advanced Research in VLSI, </booktitle> <pages> pages 272-285, </pages> <address> Los Alamitos, CA, 1995. </address> <publisher> IEEE Society Press. </publisher>
Reference-contexts: The compression scheme is based on the LZ algorithm, and results in compression rates of up to 50% [2]. Slim binaries are targeted to source level compression. This technique has been used in MC68020-base Macintosh computers since 1993. Liao et al. <ref> [11] </ref> proposed a compression technique exclusively based on software. Their main idea is to substitute common instruction sequences for sub-routine calls. A careful analysis of this method shows that it is effective only if a large number of long instruction 5 sequences can be found.
Reference: [12] <author> Todd A. Proebsting. </author> <title> Optimizing an ANSI C interpreter with superoperators. </title> <booktitle> In ACM Conference on Principles of Programming Languages, </booktitle> <pages> pages 322-332, </pages> <month> January </month> <year> 1995. </year>
Reference-contexts: We call the task of removing operands from an expression tree operand factorization. Operand factorization is not a new concept though. It has been proposed in <ref> [12] </ref> as an encoding technique for bytecode compression. Consider for example, the expression tree in Figure 1 (a). Figure 1 (b) shows the tree-pattern resulting after the operands have been factored out from the original expression tree.
Reference: [13] <author> Gerry Kane and Joe Heinrich. </author> <title> MIPS Risc Architecture. </title> <publisher> Prentice Hall, </publisher> <address> New Jersey, </address> <year> 1992. </year>
Reference-contexts: Tree-patterns in the 4 Bezier method. 8 to tree-patterns. due to operand-patterns. tree-patterns. operand-patterns. 9 horizontal axis are ordered based on their contribution to the program size. Tree-patterns can contribute to at most 35% of all program bits, because tree-patterns correspond only to opcode bits. In the R2000 architecture <ref> [13] </ref> at most 11 bits (i.e. 35.2% of an instruction) are used for opcode. The graph in Figure 4 reveals that 20% of the tree-patterns correspond to approximately 32% of all program bits. A similar graph (Figure 5) was also determined for operand-patterns.
Reference: [14] <author> Martin Benes, Steven M. Nowick, and Andrew Wolfe. </author> <title> A fast asynchronous huffman decoder for decompressed-code embedded processors. </title> <booktitle> In Async98. ACM, </booktitle> <year> 1998. </year>
Reference-contexts: On the other hand, variable length encoding implies in low decoding efficiency. The main issues involved here are: detecting the length of a codeword, extracting and aligning codeword bits. Although these problems can be handled through the design of efficient decoding engines, as in <ref> [14] </ref>, they still represent an overhead to decompression. We studied four different encoding methods to encode tree and operand patterns. The first two methods are fixed-length and Huffman encoding. The other two methods take into consideration the impact they might have in the performance of the decompression engine. <p> Our approach is to trade part of the silicon area gained by an agressive compression, by an improved design of the decompression engine. First, fields T p and Op are extracted from the compressed word. Efficient extraction circuits, like the one proposed in <ref> [14] </ref>, can be used to do that. Second, T p is mapped into a sequence of uncompressed instructions, and Op is used to generate registers and immediate bits for them. This information is fed into an Instruction Assembly Buffer (IAB) that assembles the decompressed instructions.
Reference: [15] <author> Barry G. Haskell, Atul Puri, and Arun N. Netravali. </author> <title> Digital Video: an Introduction to MPEG-2. </title> <publisher> Chapman & Hall. </publisher>
Reference-contexts: They are: * Bounded-Huffman (BH) In Bounded-Huffman an escape bit is appended to the beginning of the codeword, so as to identify if the codeword uses Huffman or fixed-length encoding. Bounded-Huffman is also used in MPEG-2 <ref> [15] </ref> and in CCRP [6]. It is useful as a way to restrict the size 11 of the Huffman codeword, thus reducing the complexity of the decompression engine. Since Huffman encoding is an optimal technique [4], encoding part of the symbols using fixed-length codewords will result in higher compression ratios. <p> Since Huffman encoding is an optimal technique [4], encoding part of the symbols using fixed-length codewords will result in higher compression ratios. In Section 6 we show that this overhead can be almost completely eliminated. * VLC Encoding (VLC) This is a variation of the MPEG-2 VLC encoding <ref> [15] </ref>. In this method, Bounded-Huffman codewords are selected so that the codeword leading zeroes encode the size of the codeword. The goal of this method is to simplify the logic associated to the part of the decoding engine responsible for codeword extraction.
Reference: [16] <author> J.L. Hennessy and D.A. Patterson. </author> <title> Computer Architectures: A Quantitative Approach. </title> <publisher> Morgan Kaufmann, </publisher> <year> 1996. </year> <month> 22 </month>
Reference-contexts: As mentioned before, our compression method can also be used for cache-line based compression. In fact, depending on the final performance of the decompression engine, a cache-line based approach may be very appropri 5 Similar numbers are presented in <ref> [16] </ref>. 16 ate in our final design. In this case, the LAT/CLB address mapping technique in [6] should be used to compute branch addresses.
References-found: 16

