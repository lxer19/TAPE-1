URL: http://www.cs.monash.edu.au/~jono/TechReports/ml95.ps
Refering-URL: http://www.cs.monash.edu.au/~jono/
Root-URL: 
Email: jono@cs.monash.edu.au  D.J.Hand@open.ac.uk  
Title: On Pruning and Averaging Decision Trees  
Author: Jonathan J. Oliver David J. Hand 
Address: 3168, Australia  Milton Keynes, MK7 6AA, U.K.  
Affiliation: Computer Science Dept. Monash University Clayton, Vic.  Statistics Dept. Open University  
Abstract: Pruning a decision tree is considered by some researchers to be the most important part of tree building in noisy domains. While, there are many approaches to pruning, an alternative approach of averaging over decision trees has not received as much attention. We perform an empirical comparison of pruning with the approach of averaging over decision trees. For this comparison we use a computa-tionally efficient method of averaging, namely averaging over the extended fanned set of a tree. Since there are a wide range of approaches to pruning, we compare tree averaging with a traditional pruning approach, along with an optimal pruning approach.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> L.R. Bahl, P.F. Brown, P.V. deSouza, </author> <title> and R.L. Mercer (1989). A tree-based statistical language model for natural language speech recognition. </title> <journal> IEEE Transactions on Acoustics, Speech, and Signal Processing, </journal> <volume> 37 </volume> <pages> 1001-1008. </pages>
Reference: [2] <author> R.A. Baxter and J.J. </author> <title> Oliver (1994). MDL and MML: Similarities and differences. </title> <type> Technical report TR 207, </type> <institution> Department of Computer Science, Monash University, Clayton, </institution> <address> Victoria 3168, Aus-tralia. </address>
Reference: [3] <author> L. Breiman, J.H. Friedman, R.A. Olshen, and C.J. </author> <title> Stone (1984). Classification and Regression Trees. </title> <publisher> Wadsworth, </publisher> <address> Belmont. </address>
Reference: [4] <author> W.L. </author> <title> Buntine (1990). A Theory of Learning Classification Rules. </title> <type> PhD thesis, </type> <institution> School of Computing Science in the University of Technology, Sydney. </institution>
Reference: [5] <author> W.L. </author> <title> Buntine (1992). Learning classification trees. </title> <journal> Statistics and Computing, </journal> <volume> 2 </volume> <pages> 63-73. </pages>
Reference: [6] <author> W.L. </author> <title> Buntine (1993). </title> <type> Personal communication. </type>
Reference: [7] <author> W.L. Buntine and T. </author> <title> Niblett (1992). A further comparison of splitting rules for decision-tree induction. </title> <journal> Machine Learning, </journal> <volume> 8 </volume> <pages> 75-85. </pages>
Reference: [8] <author> L.A. Clark and D. </author> <title> Pregibon (1992). Tree-based models. </title> <editor> In J.M. Chambers and T.J. Hastie, editors, </editor> <booktitle> Statistical Models in S, </booktitle> <pages> pages 377-420. </pages> <publisher> Wadsworth and Brooks, </publisher> <address> California. </address>
Reference: [9] <author> S.B. Gelfand, C.S. Ravishankar, and E.J. </author> <month> Delp </month> <year> (1991). </year> <title> An iterative growing and pruning algorithm for classification tree design. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 13(2) </volume> <pages> 163-174. </pages>
Reference: [10] <author> T. Hastie and D. </author> <title> Pregibon (1990). Shrinking trees. </title> <type> Technical report, </type> <institution> AT&T Bell Laboratories, </institution> <address> Murray Hill, New Jersey 07974, USA. </address>
Reference: [11] <author> I. </author> <title> Kononenko (1992). Combining decisions of multiple rules. </title> <editor> In B. du Boulay and V. Sgurev, editors, </editor> <booktitle> Artificial Intelligence V: Methodology, Systems, Applications, </booktitle> <pages> pages 87-96. </pages> <publisher> Elsevier Science, Amsterdam. </publisher>
Reference: [12] <author> S.W. Kwok and C. </author> <title> Carter (1990). Multiple decision trees. </title> <editor> In R.D. Schachter, T.S. Levitt, L.N. Kanal, and J.F. Lemmer, editors, </editor> <booktitle> Uncertainty in Artificial Intelligence 4, </booktitle> <pages> pages 327-335. </pages> <publisher> Elsevier Science, Amsterdam. </publisher>
Reference: [13] <author> J. </author> <title> Mingers (1989). An empirical comparison of selection measures for decision-tree induction. </title> <journal> Machine Learning, </journal> <volume> 3 </volume> <pages> 319-342. </pages>
Reference: [14] <author> P.M. Murphy and D.W. </author> <title> Aha (1992). UCI repository of machine learning databases. </title>
Reference: [15] <author> J.J. Oliver, D.L. Dowe, and C.S. </author> <title> Wallace (1992). Inferring decision graphs using the minimum message length principle. </title> <editor> In A. Adams and L. Sterling, editors, </editor> <booktitle> Proceedings of the 5th Australian Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 361-367. </pages> <publisher> World Scientific, Singapore. </publisher>
Reference: [16] <author> J.J. Oliver and D.J. </author> <title> Hand (1994a). Averaging over decision stumps. </title> <booktitle> In Lecture Notes in Artificial Intelligence 784, Machine Learning: ECML-94, </booktitle> <pages> pages 231-241. </pages> <publisher> Springer-Verlag, </publisher> <address> Berlin. </address>
Reference: [17] <author> J.J. Oliver and D.J. </author> <title> Hand (1994b). Introduction to minimum encoding inference. </title> <type> Technical report TR 4-94, </type> <institution> Dept. of Statistics, Open Uni., Walton Hall, Milton Keynes, MK7 6AA, UK. </institution> <note> Also available as TR 205 Dept. </note> <institution> Computer Science, Monash Uni., Clayton, </institution> <address> Vic 3168, Australia. </address>
Reference: [18] <author> J.J. Oliver and D.J. </author> <title> Hand (1996). Averaging over decision trees. </title> <journal> Journal of Classification, </journal> <note> To appear. An extended version is available as Technical Report TR 5-94, </note> <institution> Department of Statistics, Open University, Walton Hall, Milton Keynes, MK7 6AA, UK. </institution>
Reference: [19] <author> J.R. </author> <title> Quinlan (1986). Induction of decision trees. </title> <journal> Machine Learning, </journal> <volume> 1 </volume> <pages> 81-106. </pages>
Reference: [20] <author> J.R. </author> <title> Quinlan (1992). Learning with continuous classes. </title> <editor> In A. Adams and L. Sterling, editors, </editor> <booktitle> Proceedings of the 5th Australian Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 343-348. </pages> <publisher> World Scientific, Singapore. </publisher>
Reference: [21] <author> J.R. Quinlan (1993). C4.5: </author> <title> Programs for Machine Learning. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA. </address>
Reference: [22] <author> J.R. Quinlan and R.L. </author> <title> Rivest (1989). Inferring decision trees using the minimum description length principle. </title> <journal> Information and Computation, </journal> <volume> 80 </volume> <pages> 227-248. </pages>
Reference: [23] <author> J. </author> <title> Rissanen (1983). A universal prior for integers and estimation by minimum description length. </title> <journal> Annals of Statistics, </journal> <volume> 11 </volume> <pages> 416-431. </pages>
Reference: [24] <author> J. </author> <title> Rissanen (1987). Stochastic complexity. </title> <journal> Journal of the Royal Statistical Society (Series B), </journal> <volume> 49 </volume> <pages> 223-239. </pages>
Reference: [25] <author> C. </author> <title> Schaffer (1992). Deconstructing the digit recognition problem. </title> <booktitle> In Machine Learning: Proceedings of the Ninth International Workshop, </booktitle> <pages> pages 394-399. </pages>
Reference: [26] <author> C.S. Wallace and J.D. </author> <title> Patrick (1993). Coding decision trees. </title> <journal> Machine Learning, </journal> <volume> 11 </volume> <pages> 7-22. </pages>
References-found: 26

