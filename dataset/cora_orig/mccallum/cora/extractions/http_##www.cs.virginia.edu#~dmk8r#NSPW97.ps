URL: http://www.cs.virginia.edu/~dmk8r/NSPW97.ps
Refering-URL: http://www.cs.virginia.edu/~dmk8r/
Root-URL: http://www.cs.virginia.edu
Email: kienzle@mitre.org  wulf@cs.virginia.edu  
Title: A Practical Approach to Security Assessment  
Author: Darrell M. Kienzle William A. Wulf 
Note: Work performed while the author was with the  and bears no past or present relationship to MITRE.  
Address: Virginia  
Affiliation: The MITRE Corporation  Department of Computer Science University of  University of Virginia Department of Computer Science  
Abstract: Conventional approaches to building and assessing security-critical software are based on the implicit assumption that security is the single most important concern and can be the primary factor driving the software development process. Changes in the marketplace and the nature of security requirements have brought this assumption into question. There is now a large class of systems in which security must compete with other development goals. A risk-driven process model of software development provides a framework for building software that balances conflicting requirements. But a risk-driven process invalidates many of the assumptions made by conventional approaches to the specification and verification of security requirements. This paper presents a new approach to assessing the degree to which software meets its security requirements. It does not propose a new specification notation or analysis technique, but provides a general framework into which existing notations and techniques can be integrated. It allows varying degrees of formality to be used: both across the components of the system, and through the development process. The appropriate degree of formality is whatever degree proves necessary to satisfy the stakeholders in the system that the security goals have been met. This approach has been found to be theoretically appealing as well as useful in practice. Here we give a brief overview of the approach, explain how it integrates into a risk-driven process model, and discuss our early results in using it to assess, and thereby thus guide the development of, the Legion security model. 
Abstract-found: 1
Intro-found: 1
Reference: [BH94] <author> Bowen, J., M. </author> <title> Hinchey, Seven More Myths of Formal Methods, </title> <institution> Oxford University Computing Lab, </institution> <type> Technical Report PRG-TR-7-94, </type> <month> June </month> <year> 1994. </year>
Reference-contexts: If the costs of complete application of formal methods preclude their use, then selective application of those same methods is the only practical alternative. Arguments are often heard that practitioners should be using formal methods and that the factors preventing their use in practice are myths <ref> [Hal90, BH94] </ref>. But the fact remains that the mainstream software engineering community has largely failed to embrace a complete switch to formal methods. Even formal methods proponents have begun to recognize that the selective application of those formal methods may be the only viable alternative [Rus95, CGR95].
Reference: [Boe88] <author> Boehm, B., </author> <title> A Spiral Model of Software Development, </title> <booktitle> IEEE Computer, </booktitle> <month> May </month> <year> 1988, </year> <pages> pp. 61-72. </pages>
Reference-contexts: Existing formal methods appear to work reasonably well in a conventional process model [Cor89, Kem90]. But, as Boehm points out, a waterfall process works well for systems where requirements and design issues are well understood from the outset <ref> [Boe88] </ref>. In the past, many security-critical systems exhibited these characteristics. In that environment, the waterfall model and conventional formal methods were generally adequate. However, they are much less useful in an environment where security and other design goals are in conflict. <p> Similarly, design areas that pose the greatest risks should be explored at a greater level of detail earlier in the process <ref> [Boe88] </ref>. When security is important, the aspects that pose the greatest risk to the verifiability of system security need to be explored early in the process, when changes are most possible and least expensive.
Reference: [Bos95] <author> Boswell, A., </author> <title> Specification and Validation of a Security Policy Model, </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> Vol. 21, No. 2, </volume> <month> Feb. </month> <year> 1995, </year> <pages> pp. 63-68. </pages>
Reference: [CGR95] <author> Craigen, D., S. Gerhart, and T. Ralston, </author> <title> Formal Methods Reality Check: Industrial Usage, </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> Vol. 21, No. 2, </volume> <month> Feb. </month> <year> 1995, </year> <pages> pp. 90-98. </pages>
Reference-contexts: It is true that such an approach is theoretically inferior to the total application of formality areas that might have benefited from the application of formality may be overlooked. But a total application of formality to even reasonably-sized systems has proven to be practically infeasible <ref> [CGR95] </ref>. Selective application of formality is the only practical way in which the appropriate formal techniques can be applied where they can be of most use [Rus95]. It is unrealistic to believe that any system can be completely secure. <p> But the fact remains that the mainstream software engineering community has largely failed to embrace a complete switch to formal methods. Even formal methods proponents have begun to recognize that the selective application of those formal methods may be the only viable alternative <ref> [Rus95, CGR95] </ref>. Furthermore, the MOAT approach does not preclude a completely formal approach. If the resources are available, a completely formal approach can be taken. The MOAT approach does attempt to order the application of these resources, so that: Backtracking is reduced.
Reference: [Cor89] <author> Cornwell, M., </author> <title> A Software Engineering Approach to Designing Trustworthy Software, </title> <booktitle> Proceedings of the IEEE Symposium on Security and Privacy, Oakland 1989, </booktitle> <pages> pp. 148-156. </pages>
Reference-contexts: Most existing research in the engineering of secure software has used formal methods in the context of a straightforward waterfall model of software development. Existing formal methods appear to work reasonably well in a conventional process model <ref> [Cor89, Kem90] </ref>. But, as Boehm points out, a waterfall process works well for systems where requirements and design issues are well understood from the outset [Boe88]. In the past, many security-critical systems exhibited these characteristics. In that environment, the waterfall model and conventional formal methods were generally adequate.
Reference: [DLP79] <author> DeMillo, R., R. Lipton, and A. Perlis, </author> <title> Social Processes and Proofs of Theorems and Programs, </title> <journal> Communications of the ACM, </journal> <volume> Vol. 22, No. 5, </volume> <month> May </month> <year> 1979, </year> <pages> pp. 271-280. </pages>
Reference-contexts: It is unrealistic to believe that any system can be completely secure. Even if a completely secure system was theoretically possible, the very nature of verification limits the confidence that we can have in it <ref> [DLP79, Fet88] </ref>. There will always be something we can do to increase our confidence in the security of the system. <p> Encryption is based on arguments regarding the secrecy of keys, which in turn are based on many different assumptions that might prove faulty. Even in mathematics, we often see multiple proofs of the same theorembecause proofs, like MOATs, are not intended to prove but rather to convince the reader <ref> [DLP79] </ref>, and several arguments may be more convincing than any one. 3.6 Refinement Refinement permits the engineer to revisit a node and replace the argument at that node. Typically this would be used to replace an informal justification with a more formal one.
Reference: [Fet88] <author> Fetzer, J., </author> <title> Program Verification: The Very Idea, </title> <journal> Communications of the ACM, </journal> <volume> Vol. 31, No. 9, </volume> <month> Sept. </month> <year> 1988. </year>
Reference-contexts: It is unrealistic to believe that any system can be completely secure. Even if a completely secure system was theoretically possible, the very nature of verification limits the confidence that we can have in it <ref> [DLP79, Fet88] </ref>. There will always be something we can do to increase our confidence in the security of the system.
Reference: [FKV94] <author> Fraser, M., K. Kumar, and V. Vaishnavi, </author> <title> Strategies for Incorporating Formal Specifications in Software Development, </title> <journal> Communications of the ACM, </journal> <volume> Vol. 37, No. 10, </volume> <month> Oct. </month> <year> 1994, </year> <month> pp.74-86. </month>
Reference-contexts: The open-ended nature of the MOAT approach does have the significant advantage of being amenable to additional justification should the original analysis require strengthening. Fraser, et al <ref> [FKV94] </ref> presented a survey of popular formal specification approaches. In the more general-purpose notations considered, formal notations were provided without methods for the elaboration of specifications written in those notations. Users of these notations are left completely to their own devices when it comes to actually creating a specification.
Reference: [Fri96] <author> Frincke, D., </author> <title> Developing Secure Objects, </title> <booktitle> Proceedings of the 19 th National Information Systems Security Conference, </booktitle> <address> Baltimore Maryland, </address> <month> October </month> <year> 1996, </year> <pages> pp. 410-419. </pages>
Reference-contexts: On a different note, the MOATs approach also appears to be a generalization of some other work in the area of reuse of security verification. Frincke <ref> [Fri96] </ref> discusses the use of design templates with pre-verified security properties. These could be incorporated directly into the MOATs approach by creating a node that merely references those arguments and has children representing the assumptions upon which the reused arguments rely.
Reference: [Hal90] <author> Hall, A., </author> <title> Seven Myths of Formal Methods, </title> <journal> IEEE Software, </journal> <volume> Vol. 7, No. 5, </volume> <month> Sept. </month> <year> 1990. </year>
Reference-contexts: If the costs of complete application of formal methods preclude their use, then selective application of those same methods is the only practical alternative. Arguments are often heard that practitioners should be using formal methods and that the factors preventing their use in practice are myths <ref> [Hal90, BH94] </ref>. But the fact remains that the mainstream software engineering community has largely failed to embrace a complete switch to formal methods. Even formal methods proponents have begun to recognize that the selective application of those formal methods may be the only viable alternative [Rus95, CGR95].
Reference: [Hay85] <author> Hayes, I., </author> <title> Applying Formal Specification to Software Development in Industry, </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> Vol. SE-11, No. 2, </volume> <month> Feb. </month> <year> 1985, </year> <pages> pp. 169-178. </pages>
Reference-contexts: Many published specifications demonstrate the utility of the language and its reusable toolkit at specifying the high-risk element of these systems internal database consistency while essentially ignoring the low-risk the sources of database events and their inputs and outputs <ref> [Hay85] </ref>. Specification of GUI systems is performed largely using screen-painting utilities with which there are no formal semantics associated. Nevertheless, these approaches address the key risks of these systems that they will not be intuitive or will not meet the customers expectations.
Reference: [Hen80] <author> Heninger, K., </author> <title> Specifying Software Requirements for Complex Systems: New Techniques and their Application, </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> Vol. SE-6, No. 1, </volume> <month> Jan. </month> <year> 1980. </year>
Reference-contexts: The input/output forms captured knowledge about the most common failure modes in the hardware / software interface. And the tables represented years of experience with specifying statedriven, process-control software <ref> [Hen80] </ref>. The most successful Z specifications take advantage of the experience gained in using that language to develop large database systems.
Reference: [HK85] <author> Henley, E. J. and H. Kumamoto, </author> <title> Designing for Reliability and Safety Control , Prentice-Hall, </title> <publisher> Inc., </publisher> <address> Englewood Cliffs, New Jersey, </address> <year> 1985, </year> <pages> pp. 407 458. </pages>
Reference-contexts: Both rigorous processes and automated software exist to aid in the automatic construction of fault trees from system diagrams, but even they are based on insight and experience rather than formal reasoning <ref> [RM83, HK85] </ref>. They also require a model of the system that accurately reflects the component interactions and environmental assumptions, which in turn is typically validated using insight rather than logic. Fault trees strike a careful balance between rigor and flexibility.
Reference: [Kem90] <author> Kemmerer, R. A., </author> <title> Integrating Formal Methods into the Development Process, </title> <journal> IEEE Software, </journal> <month> Sept. </month> <year> 1990, </year> <pages> pp. 37-50. </pages>
Reference-contexts: Most existing research in the engineering of secure software has used formal methods in the context of a straightforward waterfall model of software development. Existing formal methods appear to work reasonably well in a conventional process model <ref> [Cor89, Kem90] </ref>. But, as Boehm points out, a waterfall process works well for systems where requirements and design issues are well understood from the outset [Boe88]. In the past, many security-critical systems exhibited these characteristics. In that environment, the waterfall model and conventional formal methods were generally adequate.
Reference: [McC81] <author> McCormick, N. J., </author> <title> Reliability and Risk Analysis , Academic Press, </title> <address> San Diego, California, </address> <year> 1981, </year> <pages> pp. 154-228. </pages>
Reference-contexts: One textbook puts it construction of fault trees is an art as well as a science and comes only through experience and then proceeds to present a list of general heuristics to guide in their construction <ref> [McC81] </ref>. Both rigorous processes and automated software exist to aid in the automatic construction of fault trees from system diagrams, but even they are based on insight and experience rather than formal reasoning [RM83, HK85].
Reference: [PC86] <author> Parnas, D., P. Clements, </author> <title> A Rational Design Process: How and Why to Fake It, </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> Vol. SE-12, No. 2, </volume> <month> Feb. </month> <year> 1986. </year>
Reference-contexts: Both of these approaches are claimed to be quite useful by their authors, and both are accommodated by the MOAT approach. 4.4 The Rational Process The cost-effectiveness of the MOATs approach will depend on the users ability to choose risks well. With perfect foresight however, a rational design process <ref> [PC86] </ref> can be achieved. With less than perfect foresight, the amount of backtracking required will depend on the skill of the user at anticipating risk areas. This is true of every development methodology both those that explicitly acknowledge the role of risk in the development process and those that dont.
Reference: [RM83] <author> Roland, H.E. and B. </author> <title> Moriarty, </title> <publisher> System Safety Engineering and Management , John Wiley and Sons, </publisher> <address> New York, </address> <year> 1983, </year> <pages> pp. 215-271. </pages>
Reference-contexts: Both rigorous processes and automated software exist to aid in the automatic construction of fault trees from system diagrams, but even they are based on insight and experience rather than formal reasoning <ref> [RM83, HK85] </ref>. They also require a model of the system that accurately reflects the component interactions and environmental assumptions, which in turn is typically validated using insight rather than logic. Fault trees strike a careful balance between rigor and flexibility.
Reference: [Rus95] <author> Rushby, J., </author> <title> Formal Methods and their Role in the Certification of Critical Systems, </title> <address> SRI-CSL-95-01, </address> <month> January </month> <year> 1995. </year> <note> http://www.csl.sri.com/csl-95-1.html </note>
Reference-contexts: This is consistent with Rushbys assertion that formal methods should be applied selectively to the hard problems <ref> [Rus95] </ref>. A risk-driven approach permits formal methods to be made more cost-effective, by only expending the costs in the area where the expected returns are greatest. <p> But a total application of formality to even reasonably-sized systems has proven to be practically infeasible [CGR95]. Selective application of formality is the only practical way in which the appropriate formal techniques can be applied where they can be of most use <ref> [Rus95] </ref>. It is unrealistic to believe that any system can be completely secure. Even if a completely secure system was theoretically possible, the very nature of verification limits the confidence that we can have in it [DLP79, Fet88]. <p> But the fact remains that the mainstream software engineering community has largely failed to embrace a complete switch to formal methods. Even formal methods proponents have begun to recognize that the selective application of those formal methods may be the only viable alternative <ref> [Rus95, CGR95] </ref>. Furthermore, the MOAT approach does not preclude a completely formal approach. If the resources are available, a completely formal approach can be taken. The MOAT approach does attempt to order the application of these resources, so that: Backtracking is reduced.
Reference: [Spe96] <author> Spencer, R., </author> <title> Deriving Security Requirements for Applications on Trusted Systems, </title> <booktitle> Proceedings of the 19 th National Information Systems Security Conference, </booktitle> <address> Baltimore Maryland, </address> <month> October </month> <year> 1996, </year> <pages> pp. 420-427. </pages>
Reference-contexts: Frincke [Fri96] discusses the use of design templates with pre-verified security properties. These could be incorporated directly into the MOATs approach by creating a node that merely references those arguments and has children representing the assumptions upon which the reused arguments rely. Spencer <ref> [Spe96] </ref> discusses a checklist-approach to the determination of security requirements. This approach could be approximated in the MOAT approach by using a node with one child for each element in the checklist.
Reference: [WWK96] <author> Wulf, W. A., C. Wang, and D. M. Kienzle, </author> <title> A New Model of Security for Distributed Systems, </title> <booktitle> Proceedings of the New Paradigms in Security Workshop, </booktitle> <address> Lake Arrowhead, California, </address> <year> 1996. </year>
Reference-contexts: MOAT also aids users in helping them structure their arguments informally before attempting to commit them to a formal notation. 5. Empirical Evaluation This approach grew out of our experience in developing the security model for the Legion distributed system <ref> [WWK96] </ref>. It was developed to address the need for organization and preservation of informal discussions about the security ramifications of design alternatives. As time progressed, the approach was modified in order to better meet our needs and to address its shortcomings.
References-found: 20

