URL: http://www.cs.yale.edu/users/rasmussen/lib/papers/cvpr98.ps.gz
Refering-URL: http://www.cs.yale.edu/users/rasmussen/research.html
Root-URL: http://www.cs.yale.edu
Title: Joint Probabilistic Techniques for Tracking Multi-Part Objects  
Author: Christopher Rasmussen Gregory D. Hager 
Address: New Haven, CT 06520-8267  
Affiliation: Center for Computational Vision Control Yale University  
Abstract: Common objects such as people and cars comprise many visual parts and attributes, yet image-based tracking algorithms are often keyed to only one of a target's identifying characteristics. In this paper, we present a framework for combining and sharing information among several state estimation processes operating on the same underlying visual object. Well-known techniques for joint probabilistic data association are adapted to yield increased robustness when multiple trackers attuned to disparate visual cues are deployed simultaneously. We also formulate a measure of tracker confidence, based on distinctiveness and occlusion probability, which permits the deactivation of trackers before erroneous state estimates adversely affect the ensemble. We will discuss experiments focusing on color-region- and snake-based tracking that demonstrate the efficacy of this approach. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Y. Bar-Shalom and T. Fortmann. </author> <title> Tracking and Data Association. </title> <publisher> Academic Press, </publisher> <year> 1988. </year>
Reference-contexts: Moreover, in many situations other moving objects and variegated backgrounds can further aggravate problems of occlusion and distraction <ref> [1, 7] </ref>. As recent work in multi-cue tracking suggests [12], one way toward robust visual tracking is through exploiting several simultaneously measured visual cues in as flexible a fashion as possible. <p> In this paper we develop a framework for constructing vision-based tracking systems that rely on multiple visual cues and part-based decompositions to track complex objects. The probabilistic and joint probabilistic data associa-tion filters introduced in <ref> [1] </ref> serve as a starting point for developing multi-part, multi-attribute tracking methods. <p> 11] can be made less sensitive to distraction (clutter) by exploiting inter-part relationships, and also how target occlusion can be accommodated through measures for deciding to "switch" a component tracking algorithm on or off, which we term variable tracker activation. 2 Data Association Filters The probabilistic data association filter (PDAF) <ref> [1] </ref> is an extension of the Kalman filter [1] that casts the problem of data association, or how to update the state when there are multiple measurements and a single target, in a Bayesian framework. <p> (clutter) by exploiting inter-part relationships, and also how target occlusion can be accommodated through measures for deciding to "switch" a component tracking algorithm on or off, which we term variable tracker activation. 2 Data Association Filters The probabilistic data association filter (PDAF) <ref> [1] </ref> is an extension of the Kalman filter [1] that casts the problem of data association, or how to update the state when there are multiple measurements and a single target, in a Bayesian framework. <p> One step in the Kalman filter is the computation of the innovation - = z ^z, where z is the observed measurement and ^z is the one predicted from the current state X by the measurement equation ^z = H X <ref> [1] </ref>. The PDAF introduces the notion of the combined innovation, computed over the n measurements detected at a given time step as the weighted sum of the individual innovations: - = P n i=1 fi i i. <p> These events encompass all possible interpretations of the data, so P n association probabilities fi i are derived from a uniform noise model for spurious measurements and an assumed normal PDF on the correct measurement. Details are given in <ref> [1] </ref>. The PDAF also develops the idea of a validation gate, or an ellipsoidal volume in measurement space, derived from the current estimate and uncertainty of the target state, such that the probability of a target-originated measurement appearing outside of it is negligible. <p> Such persistent interference, were one to simply run a separate PDAF on each part, could lead to multiple trackers locked onto the same part. The joint probabilistic data association filter (JPDAF) <ref> [1] </ref> deals with this problem by sharing information among separate PDAF trackers in order to more accurately calculate association probabilities. The essential result is an exclusion principle of sorts that prevents two trackers from latching onto the same target. <p> and target t given measurements Z is given by fi jt = fi P (fi j Z)! jt (fi), where: P (fi j Z) = j=1 T Y fl t : (1) contains terms for normalization and scaling, fl t is a prior probability on target t being visible (see <ref> [1] </ref> for details), and N j is the Gaussian PDF N [z j ; ^ z t j ; S t j ] for measurement j (z j is the measurement value, ^ z t j is the predicted measurement value for target t j , and S t j is <p> Details of the calculation of P (O p i ) and P (D p i ) under the constrained JPDAF framework are given below. When (p i ) of the tracker for a part p i with constraint links at least one other part falls below some threshold 2 <ref> [0; 1] </ref>, it is deactivated. This means that its image-based state estimation is switched off discretely, and C ij = 1 for purposes of calculating (2).
Reference: [2] <author> A. Blake, M. Isard, and D. Reynard. </author> <title> Learning to track the visual motion of contours. </title> <journal> Artificial Intelligence, </journal> <volume> No. 78, </volume> <pages> pp. 101-133, </pages> <year> 1995. </year>
Reference-contexts: For many tasks, techniques for tracking generic edges, curves, blobs, and textures have proven to be applicable with minor modifications to tracking hands, arms, heads, faces, and cars <ref> [2, 4, 5, 7] </ref>. Despite these advances, most visual tracking algorithms are quite brittle. In particular, many systems are easily confused in commonly occurring visual situations because of their reliance on a single cue or methodology for locating their target. <p> By its nature, a single part can possess multiple attributes, so it does not make sense to re tain a JPDAF-style exclusion principle that prevents multiple trackers of different modalities from following the same target. However, constraints do apply: a color region tracker and a B-spline snake <ref> [2] </ref> both locked onto a hand, for instance, could be expected to have coincident centers of image mass, or the angle of the major axis of the region could be expected to agree with that of the B-spline. <p> Any other variables that implicitly refer to a particular attribute should be assumed to use a. Note that this formula reduces to (2) when there is only one attribute (m = 1). 4.1 Snakes as Parts An attribute well-suited to combination with color regions is snake tracking <ref> [2, 11] </ref>. We follow [2] by representing a snake as an affine parametrization of a B-spline (only translation is used for state in the experiment below). <p> Note that this formula reduces to (2) when there is only one attribute (m = 1). 4.1 Snakes as Parts An attribute well-suited to combination with color regions is snake tracking [2, 11]. We follow <ref> [2] </ref> by representing a snake as an affine parametrization of a B-spline (only translation is used for state in the experiment below). Linking edge fragments into contours to derive a set of discrete measurements in a manner similar to the color pixel grouping by connectivity is combinatorially problematic.
Reference: [3] <author> C. Bregler. </author> <title> Learning and Recognizing Human Dynamics in Video Sequences. </title> <booktitle> In CVPR '97, </booktitle> <pages> pp. 568-574, </pages> <year> 1997. </year>
Reference-contexts: If the background is a tan brick wall similar in color to skin, the edge cues used by the snake will be sufficient for disambiguation. In short, attending to multiple cues associated with an object can alleviate many difficulties. Approaches to tracking in this spirit have been successful <ref> [3, 13] </ref>, but as yet little work has been done toward creating an extensible system for tracking increasingly complex, multi-part objects through a wide range of poses, backgrounds, and lighting conditions.
Reference: [4] <author> G. Hager and P. Belhumeur. </author> <title> Real-Time Tracking of Image Regions with Changes in Geometry and Illumination. </title> <booktitle> In CVPR '96, </booktitle> <pages> pp. 403-410, </pages> <year> 1996. </year>
Reference-contexts: For many tasks, techniques for tracking generic edges, curves, blobs, and textures have proven to be applicable with minor modifications to tracking hands, arms, heads, faces, and cars <ref> [2, 4, 5, 7] </ref>. Despite these advances, most visual tracking algorithms are quite brittle. In particular, many systems are easily confused in commonly occurring visual situations because of their reliance on a single cue or methodology for locating their target.
Reference: [5] <author> M. Isard and A. Blake. </author> <title> Contour Tracking by Stochastic Propagation of Conditional Density. </title> <booktitle> In ECCV '96, </booktitle> <pages> pp. 343-356, </pages> <year> 1996. </year>
Reference-contexts: For many tasks, techniques for tracking generic edges, curves, blobs, and textures have proven to be applicable with minor modifications to tracking hands, arms, heads, faces, and cars <ref> [2, 4, 5, 7] </ref>. Despite these advances, most visual tracking algorithms are quite brittle. In particular, many systems are easily confused in commonly occurring visual situations because of their reliance on a single cue or methodology for locating their target. <p> Linking edge fragments into contours to derive a set of discrete measurements in a manner similar to the color pixel grouping by connectivity is combinatorially problematic. Rather, we employ an approach adapted from the state sampling technique used in the Condensation algorithm <ref> [5] </ref>. First, n minimally separated samples (n 100) are generated from a normal distribution in the target snake's state space, centered on its current state X. <p> Color and snake measurements are overlaid as boxes and crosses, respectively. described in <ref> [5] </ref>). The top k scoring samples (k t n) are projected to measurement space as putative snake locations. <p> Our current work is proceeding in a variety of directions. Although phrased in terms of classical linear state-estimation techniques, many of the concepts carry over to other types of state estimation| e.g., the Condensation algorithm <ref> [5, 6] </ref>. Experimentally, we are adapting the Condensation algorithm to perform joint color region and contour tracking with the goal of comparing its computational and statistical performance vs. modified JPDAF. Also, the image-to-measurement-set methods for color regions and snakes have thus far been largely heuristically motivated.
Reference: [6] <author> M. Isard and A. Blake. </author> <title> A Mixed-state Condensation Tracker with Automatic Model-switching. </title> <note> To appear in ICCV '98, </note> <year> 1998. </year>
Reference-contexts: Our current work is proceeding in a variety of directions. Although phrased in terms of classical linear state-estimation techniques, many of the concepts carry over to other types of state estimation| e.g., the Condensation algorithm <ref> [5, 6] </ref>. Experimentally, we are adapting the Condensation algorithm to perform joint color region and contour tracking with the goal of comparing its computational and statistical performance vs. modified JPDAF. Also, the image-to-measurement-set methods for color regions and snakes have thus far been largely heuristically motivated.
Reference: [7] <author> D. Koller, J. Weber, and J. Malik. </author> <title> Robust Multiple Car Tracking with Occlusion Reasoning. </title> <booktitle> In ECCV '94, </booktitle> <pages> pp. 189-196, </pages> <year> 1994. </year>
Reference-contexts: For many tasks, techniques for tracking generic edges, curves, blobs, and textures have proven to be applicable with minor modifications to tracking hands, arms, heads, faces, and cars <ref> [2, 4, 5, 7] </ref>. Despite these advances, most visual tracking algorithms are quite brittle. In particular, many systems are easily confused in commonly occurring visual situations because of their reliance on a single cue or methodology for locating their target. <p> Moreover, in many situations other moving objects and variegated backgrounds can further aggravate problems of occlusion and distraction <ref> [1, 7] </ref>. As recent work in multi-cue tracking suggests [12], one way toward robust visual tracking is through exploiting several simultaneously measured visual cues in as flexible a fashion as possible.
Reference: [8] <author> C. Rasmussen and G. Hager. </author> <title> An Adaptive Model for Tracking Objects by Color Alone. </title> <type> Technical Report, </type> <institution> DCS-TR-1200, Yale University, </institution> <year> 1997. </year>
Reference-contexts: The probabilistic and joint probabilistic data associa-tion filters introduced in [1] serve as a starting point for developing multi-part, multi-attribute tracking methods. We show how object state estimation using a mixture of color region and snake trackers <ref> [8, 11] </ref> can be made less sensitive to distraction (clutter) by exploiting inter-part relationships, and also how target occlusion can be accommodated through measures for deciding to "switch" a component tracking algorithm on or off, which we term variable tracker activation. 2 Data Association Filters The probabilistic data association filter (PDAF) <p> We note that it is always possible to combine the information contained within the separate state vectors to obtain a single, consolidated state estimate if desired. 3.1 Color Regions as Parts A uniformly colored region <ref> [8] </ref> part is formally defined by pixel membership in a five-dimensional ellipsoid in image-RGB space with center and scale and (a) (b) (c) (a) Tracking window; (b) Largest connected components of flesh color; (c) Measurements derived from their centroids. rotation given by . For reasons explained in [8], the state X <p> uniformly colored region <ref> [8] </ref> part is formally defined by pixel membership in a five-dimensional ellipsoid in image-RGB space with center and scale and (a) (b) (c) (a) Tracking window; (b) Largest connected components of flesh color; (c) Measurements derived from their centroids. rotation given by . For reasons explained in [8], the state X of a color part is restricted to the ellipsoid center = [x; y; r; g; b] T , while is retained as a fixed parameter. The state is initialized by computing the principal components of manually-sampled target pixels.
Reference: [9] <author> J. Rehg and T. Kanade. </author> <title> Model-based tracking of self-occluding articulated objects. </title> <booktitle> In ICCV '95, </booktitle> <pages> pp. 612-617, </pages> <year> 1995. </year>
Reference-contexts: Consider the problem of tracking a person with the goal of providing not only a rough guess of where they are, but also of furnishing information about the current posture of the head, torso, limbs, and so forth. The articulation of human bodies makes self-occlusion <ref> [9] </ref> (where one part of the body moves in front of the other) and self-distraction (when similar parts|e.g., the hands| are close to one another) common challenges to robust state estimation.
Reference: [10] <author> D. Reynard, A. Wildenberg, A. Blake, and J. Marchant. </author> <title> Learning Dynamics of Complex Motions from Image Sequences. </title> <booktitle> In ECCV '96, </booktitle> <pages> pp. 357-368, </pages> <year> 1996. </year>
Reference-contexts: Since the case above is a rigid linkage, one could use a single position vector in &lt; 2 to describe the system <ref> [10, 11] </ref>. However, we have found that our formulation, which simply biases a probabilistic state estimator to favor an interpretation of the data that best matches the target model, works quite well while retaining a useful degree of modularity and flexibility.
Reference: [11] <author> D. Terzopoulos and R. Szeliski. </author> <title> Tracking with Kalman Snakes. In Active Vision, </title> <editor> A. Blake and A. Yuille, </editor> <booktitle> eds., </booktitle> <pages> pp. 3-20, </pages> <year> 1992. </year>
Reference-contexts: The probabilistic and joint probabilistic data associa-tion filters introduced in [1] serve as a starting point for developing multi-part, multi-attribute tracking methods. We show how object state estimation using a mixture of color region and snake trackers <ref> [8, 11] </ref> can be made less sensitive to distraction (clutter) by exploiting inter-part relationships, and also how target occlusion can be accommodated through measures for deciding to "switch" a component tracking algorithm on or off, which we term variable tracker activation. 2 Data Association Filters The probabilistic data association filter (PDAF) <p> Since the case above is a rigid linkage, one could use a single position vector in &lt; 2 to describe the system <ref> [10, 11] </ref>. However, we have found that our formulation, which simply biases a probabilistic state estimator to favor an interpretation of the data that best matches the target model, works quite well while retaining a useful degree of modularity and flexibility. <p> Any other variables that implicitly refer to a particular attribute should be assumed to use a. Note that this formula reduces to (2) when there is only one attribute (m = 1). 4.1 Snakes as Parts An attribute well-suited to combination with color regions is snake tracking <ref> [2, 11] </ref>. We follow [2] by representing a snake as an affine parametrization of a B-spline (only translation is used for state in the experiment below).
Reference: [12] <author> K. Toyama and G. Hager. </author> <title> Incremental Focus of Attention for Robust Visual Tracking. </title> <booktitle> In CVPR '96, </booktitle> <pages> pp. 189-195, </pages> <year> 1996. </year>
Reference-contexts: Moreover, in many situations other moving objects and variegated backgrounds can further aggravate problems of occlusion and distraction [1, 7]. As recent work in multi-cue tracking suggests <ref> [12] </ref>, one way toward robust visual tracking is through exploiting several simultaneously measured visual cues in as flexible a fashion as possible. For example, a person tracker that regards its target as consisting of two colored regions|a flesh-colored face above a red-colored shirt|and a head silhouette, represented by a snake. <p> Constraining a snake and color region tracker to prefer coincident centers using (3), however, enables both to successfully follow the target along its entire course, as shown in Figure 3 (d). 5 Variable Tracker Activation Tracking failure <ref> [12] </ref> occurs when contact with a target is lost, either from occlusion or because clutter distracts the tracker away from the true target. The JPDAF and constrained JPDAF try to prevent failure due to distraction, but they can not completely eliminate it.
Reference: [13] <author> C. Wren, A. Azarbayejani, T. Darrell, and A. Pentland. Pfinder: </author> <title> Real-Time Tracking of the Human Body. </title> <booktitle> In SPIE, </booktitle> <volume> Vol. 2615, </volume> <year> 1995. </year>
Reference-contexts: If the background is a tan brick wall similar in color to skin, the edge cues used by the snake will be sufficient for disambiguation. In short, attending to multiple cues associated with an object can alleviate many difficulties. Approaches to tracking in this spirit have been successful <ref> [3, 13] </ref>, but as yet little work has been done toward creating an extensible system for tracking increasingly complex, multi-part objects through a wide range of poses, backgrounds, and lighting conditions.
References-found: 13

