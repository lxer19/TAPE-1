URL: http://www.cs.washington.edu/homes/mock/papers/quals.ps
Refering-URL: http://www.cs.washington.edu/homes/mock/papers.html
Root-URL: 
Title: Design and Implementation of Annotations for Dynamic Compilation Quals Report  
Author: Markus U. Mock 
Date: February 10, 1997  
Abstract: Traditional compilers produce all executable code at compile time. Dynamic compilation produces some executable code at run time, tapping additional opportunities for optimization by doing value-specific optimization on values that only become known at run time. There are different approaches to dynamic compilation, from completely manual, imperative approaches to fully automatic dynamic compilation. Annotation-based approaches are an intermediate point between these two extremes. They are easy to use for the programmer and can still provide many opportunities for optimization if they are well-designed. We present the design of simple, expressive annotations that allow us to express optimizations that were found to be useful in a previous system. They are based on two basic primitives makeStatic and makeDynamic that seem to be sufficient to dynamically compile a wide range of applications ranging from numerical codes to interpreter programs. 
Abstract-found: 1
Intro-found: 1
Reference: [APC + 96] <author> Joel Auslander, Matthai Philipose, Craig Chambers, Susan J. Eg-gers, and Brian Bershad. </author> <title> Fast, effective dynamic compilation. </title> <booktitle> In ACM SIGPLAN '96: Programming Language Design and Implementation. </booktitle> <address> Philadelphia, PA, USA, </address> <pages> pages 149-49, </pages> <month> May </month> <year> 1996. </year>
Reference-contexts: This is a safe default. In our first generation system <ref> [APC + 96] </ref> static pointers by default pointed to static data which in many cases lead to surprises for the programmer. 5 the bytecode interpreter discussed later in section 3.1. 2.3 Imperative style systems such as 'C In annotation-based, declarative systems it is the responsibility of the system to create a <p> It also does not provide polyvariant division. Because it does its analysis on ASTs rather than CFGs, it appears that the computed static/dynamic division must be more conservative than the one computed by our first generation system which operates on CFGs <ref> [APC + 96] </ref>. Like Fabius, Tempo doesn't support any control mechanisms for the caching of dynamically generated code. 3 Annotations We now present the design of our annotations. First, we'll state what they can do. <p> As a conservative estimate we use the set of variables that are used for specialization at the current program point minus the variable being removed from these sets by makeDynamic. Reachability Conditions The reachability conditions are identical to our first generation system and are described in <ref> [APC + 96] </ref>. A static merge is defined by the reachability conditions of the merge predecessors. If the reachability conditions of these predecessors are mutually exclusive the merge is static, otherwise it is dynamic [APC + 96]. <p> Reachability Conditions The reachability conditions are identical to our first generation system and are described in <ref> [APC + 96] </ref>. A static merge is defined by the reachability conditions of the merge predecessors. If the reachability conditions of these predecessors are mutually exclusive the merge is static, otherwise it is dynamic [APC + 96].
Reference: [ASU85] <author> Alfred V. Aho, Ravi Sethi, and Jeffrey D. Ullman. </author> <booktitle> Compilers, Principles, Techniques and Tools. </booktitle> <publisher> Addison-Wesley Publishing Company, </publisher> <year> 1985. </year>
Reference-contexts: For the merges only incoming non-back-edges, i.e., advancing or cross edges <ref> [ASU85] </ref>, are considered. The intuition behind this is that policy annotations on variables used for specialization are propagated in roughly textual order downstream and should not extend back beyond the program point of the annotation. u 0 is used to select the non-back-edge (s). <p> fi fe j e is a dynamic branch edge of the CFGg P ostEdges (n) fe j e 2 fi " (n)g EarliestP ostEdges (n) fe j e 2 P ostEdges (n)^ 6 9e 0 2 P ostEdges (n) : e 0 eg where is a depth first topological order <ref> [ASU85] </ref> of the CFG. In the following we write l 2 S as a shorthand for: 9x; p; s : hx; p; s; li 2 S. SuccEdges (n) denotes the set of successor edges of node n.
Reference: [CEA + 96] <author> Craig Chambers, Susan J. Eggers, Joel Auslander, Matthai Phili-pose, Markus Mock, and Przemek Pardyak. </author> <title> Automatic dynamic compilation support for event dispatching in extensible systems. </title> <booktitle> In Proceedings of the Workshop on Compiler Support for Systems Software, </booktitle> <month> February </month> <year> 1996, </year> <month> February </month> <year> 1996. </year> <booktitle> Presented at the Workshop on Compiler Support for Systems Software, </booktitle> <month> February </month> <year> 1996. </year>
Reference-contexts: This is significant because an important application of polyvariance at dynamic merges is multi-way loop unrolling, i.e., unrolling of a loop with more than one path through the loop. This made it impossible, for instance, to optimize a simple dynamic dispatch interpreter <ref> [CEA + 96] </ref>. The code fragment in figure 2 shows the dynamic merge M that caused the problem. <p> The first generation system is unable to handle this case. Consequently, it cannot dynamically compile any interpreter where, for a specific interpreter program, different paths through the interpretation loop are possible, e.g., the dynamic dispatcher <ref> [CEA + 96] </ref> or 1 The static annotations has to be used for loads through static pointers (here bytecodes) because these are not assumed to be transitive, i.e., static pointers are not assumed to point to static data. This is a safe default.
Reference: [CFR + 89] <author> R. Cytron, J. Ferrante, B. K. Rosen, M. N. Wegman, and F. K. Zadeck. </author> <title> An efficient method of computing static single assignment form. </title> <booktitle> In Symposium on Principles of Programming Languages, </booktitle> <pages> pages 25-35. </pages> <publisher> ACM, </publisher> <month> January </month> <year> 1989. </year>
Reference-contexts: These sets are computed as an iterative data flow analysis using the following flow and meet functions. For our analysis we assume the program to be in SSA <ref> [CFR + 89] </ref> form. In SSA form each variable has at most one definition. To guarantee this property at control flow merges, it uses so-called -functions, which select one of multiple reaching definitions.
Reference: [CN96] <author> Charles Consel and Francois Noel. </author> <title> A general approach for run-time specialization and its application to C. </title> <booktitle> In Conference Record of POPL `96: The 23rd ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages. ACM, </booktitle> <month> January </month> <year> 1996. </year>
Reference-contexts: Polyvariant division is also impossible in Fabius because a given function can only be specialized on one subset of its arguments. 2.5 Tempo Tempo <ref> [CN96] </ref> is a run-time specializer for C, structured as an off-line partial evaluator. It does its analysis phases on the abstract syntax tree (AST) produced from the C source code.
Reference: [CUL89] <author> Craig Chambers, Dave Ungar, and E. Lee. </author> <title> An efficient implementation of self, a dynamically-typed object-oriented language based on prototypes. </title> <journal> In Sigplan Notices, </journal> <volume> volume 24, </volume> <pages> pages 49-70, </pages> <month> October </month> <year> 1989. </year>
Reference-contexts: Yet another benefit of dynamic compilation is that it can be an enabling technology for very high-level language features, such as dynamic dispatching of message sends in object-oriented languages <ref> [CUL89] </ref>. A key issue for dynamic compilation is how to identify where and when to compile code dynamically. There are different approaches to this problem.
Reference: [EHK96] <author> Dawson R. Engler, Wilson C. Hsieh, and M. F. Kaashoek. </author> <title> 'C: a language for high-level, efficient, and machine-independent dynamic code generation. </title> <booktitle> In ACM, editor, Symposium on Principles of Programming Languages, </booktitle> <month> January </month> <year> 1996. </year>
Reference-contexts: In imperative systems, such as the 'C system <ref> [EHK96] </ref>, the user has to write the generating extension himself. 'C provides so-called tick-expressions that are used to construct dynamic code. While this approach is versatile and allows the programmer to generate arbitrary code and apply any optimizations to it, it is also error-prone and tedious.
Reference: [GMP + ] <author> Brian Grant, Markus Mock, Matthai Philipose, Craig Chambers, and Susan Eggers. </author> <title> Annotation-direction run-time specialization in C. </title> <booktitle> To appear in the Proceedings of the ACM SIGPLAN Conference on Partial Evaluation and Semantics-Based Program Manipulation, </booktitle> <address> (PEPM'97). </address>
Reference-contexts: The back end of our dynamic compilation system needs the following information for its program transformations, described in <ref> [GMP + ] </ref>: * static/dynamic division information: which computations are static, which are dynamic? * laziness information: which dynamic branches are lazy, which are eager? * caching information: where do we need cache checks and what key is used? What is the size of the cache? Consequently, the output of our
Reference: [JGS93] <author> Neil D. Jones, Carsten K. Gomard, and Peter Sestroft. </author> <title> Partial Evaluation and Automatic Program Generation. </title> <publisher> Prentice Hall, </publisher> <year> 1993. </year> <month> 28 </month>
Reference-contexts: Off-line PE does the BTA before specialization time. On-line PE computes the program division at specialization time when the concrete values of static variables have already become known, which sometimes allows it to produce better code. PE has developed different degrees of program specialization <ref> [JGS93] </ref>. Mono-variant specialization produces only one specialization for a given static program variable. Polyvariant specialization, on the other hand, allows for multiple versions of specialized code for a given static program variable. For each different value of the variable that is specialized, polyvariant specialization produces a separate version of code. <p> Polyvariant division permits multiple divisions of the program allowing for different kinds of specializations for the same program variable. Monovariant division, in contrast, computes only one division of the program. Consider the example, given by Jones et al. <ref> [JGS93] </ref>, and shown, in a slightly modified way, in figure 1: If, initially, x is static and y dynamic, a monovariant division of the program will compute that both x and y are dynamic at point M, because at this point x could depend either on a dynamic computation (x := <p> Much of the partial evaluation work has been carried out in the context of functional languages. For that reason, PE typically does program specialization and division at function granularity, i.e., specialized versions of a function are 3 produced for specific argument values. <ref> [JGS93] </ref> 2.2 Our First Generation System Our previous prototype system is an annotation-based system. Code inside a dynamic region, delimited by the dynamicRegion () annotation, is compiled dynamically.
Reference: [LL96] <author> Mark Leone and Peter Lee. </author> <title> Optimizing ML with run-time code generation. </title> <booktitle> In ACM SIGPLAN '96: Programming Language Design and Implementation. </booktitle> <address> Philadelphia, PA, USA, </address> <pages> pages 137-148. </pages> <publisher> ACM, </publisher> <month> May </month> <year> 1996. </year> <month> 29 </month>
Reference-contexts: While this approach is versatile and allows the programmer to generate arbitrary code and apply any optimizations to it, it is also error-prone and tedious. Particularly, debugging becomes hard because is is impossible to debug the code with dynamic compilation turned off. 2.4 Fabius Fabius <ref> [LL96] </ref> is a dynamic compilation system based on off-line partial evaluation of a functional subset of the ML programming language. Fabius provides support for polyvariant specialization, including specialization if the value of a variable changes (respecialization). Fabius uses a binding time analysis to compute the static/dynamic division of the program.
References-found: 10

