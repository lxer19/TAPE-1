URL: http://www.cis.udel.edu/~pollock/papers/pdcs96.ps
Refering-URL: http://www.cis.udel.edu/~jochen/passages/pubs.htm
Root-URL: http://www.cis.udel.edu
Email: ffenwick,pollockg@cis.udel.edu  
Phone: (302) 831-1953  
Title: Global Compiler Analysis for Optimizing Tuplespace Communication on Distributed Systems  
Author: James B. Fenwick Jr. Lori L. Pollock 
Keyword: static analysis, communication optimization, generative communication model, distributed tu-plespace  
Address: 19716  
Affiliation: Department of Computer and Information Sciences University of Delaware Newark, DE  
Abstract: The generative communication paradigm of parallel programming offers not only simplicity, but power and flexibility. However, the properties of associative access and uncoupled communication that give rise to this power and flexibility also lie at the heart of the compiler and run-time system implementation challenges, especially on distributed memory systems. This paper provides concrete steps towards advanced compile-time analysis and optimization of the uncoupled communication of shared tuplespace. Specifically, we present global analysis techniques for detecting common, yet possibly inefficient, tuple usage patterns at compile time. As part of an optimizing Linda compiler, we have developed and implemented a data flow framework which statically estimates the count of tuples at run-time for each of the tuplespace partitions. We have also designed algorithms for the identification of shared variable tuples and a class of synchronization tuples. Our empirical findings show that over 28% of tuplespace partitions in a suite of real application programs never contain more than one tuple. These results indicate that there is plenty of opportunity for compile-time optimization of communication of Linda programs, and a global static analysis of Linda parallel programs can indeed provide this information to the optimizer, and thus programmers do not have to rely strictly on run-time and peephole optimizations for achieving good performance. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> David Gelernter. </author> <title> Generative communication in linda. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 7(1) </volume> <pages> 80-112, </pages> <month> January </month> <year> 1985. </year>
Reference-contexts: Moreover, distributed memory parallel architectures offer better scalability than shared memory machines. However, it is generally agreed that shared memory parallel programming is easier than explicit message passing programming. The generative communication <ref> [1] </ref> paradigm of parallel programming offers the simplicity of shared memory programming and only a small number of primitives for coordination, while also providing flexibility, power, and the potential to scale like message passing. Rather than sharing variables, processes share a data space. <p> In Section 2, we summarize the essential parts of Linda. Section 3 presents the analysis of tuple usage patterns. Section 4 describes our implementation and experimental study, followed by concluding remarks in Section 5. 2 Linda The best known implementation of the generative communication model is Linda 1 <ref> [1, 11] </ref>. Our work is therefore based on Linda although it applies more generally to any generative communication model implementation. Linda is a coordination language consisting of a small number of primitives which are added into existing sequential languages. These operations perform the communication and synchronization necessary for parallel programming.
Reference: [2] <author> C. Davidson. </author> <title> Technical correspondence on linda in contex. </title> <journal> In Communications of the ACM, </journal> <volume> volume 3210, </volume> <pages> pages 1249-1252. </pages> <month> October </month> <year> 1989. </year>
Reference-contexts: Being an associative memory means that tuples do not have addresses but rather are referenced by their content. Implementing the shared tuplespace on a distributed memory architecture has raised concerns regarding efficiency and performance <ref> [2] </ref>. Compile-time analysis has been developed to structure tuplespace to significantly reduce the associative search cost [3], and run-time strategies have been developed to counteract inefficiencies due to the uncoupling property [4].
Reference: [3] <author> Nicholas John Carriero, Jr. </author> <title> Implementation of Tuple Space Machines. </title> <type> PhD thesis, </type> <institution> Yale University, </institution> <month> December </month> <year> 1987. </year>
Reference-contexts: Implementing the shared tuplespace on a distributed memory architecture has raised concerns regarding efficiency and performance [2]. Compile-time analysis has been developed to structure tuplespace to significantly reduce the associative search cost <ref> [3] </ref>, and run-time strategies have been developed to counteract inefficiencies due to the uncoupling property [4]. <p> Bjornson's dissertation work [4] is the basis for the more successful Linda implementations on distributed memory systems and the basis for our research. This implementation strategy assumes that tuplespace has been partitioned <ref> [3] </ref>. Partitioning tuplespace is a function of the compiler or preprocessor that groups Linda operations into sets such that all tuples produced by operations of a set will only match templates generated by operations of the same set.
Reference: [4] <author> Robert D. Bjornson. </author> <title> Linda on Distributed Memory Multiprocessors. </title> <type> PhD thesis, </type> <institution> Yale University, </institution> <month> November </month> <year> 1992. </year>
Reference-contexts: Implementing the shared tuplespace on a distributed memory architecture has raised concerns regarding efficiency and performance [2]. Compile-time analysis has been developed to structure tuplespace to significantly reduce the associative search cost [3], and run-time strategies have been developed to counteract inefficiencies due to the uncoupling property <ref> [4] </ref>. While it has been demonstrated that distributed tuplespace im-plementations can be efficient for a wide variety of "real" applications encompassing a large scope of parallel algorithm classifications [5, 6, 7], there remains opportunity for improvement through compiler analysis targeting the underlying message passing [8, 9, 10]. <p> The polarity of a field is the property of a field being actual or formal. A Linda terminology convention specifies that out and eval operations create tuples, while in, rd, inp, and rdp operations create templates. Bjornson's dissertation work <ref> [4] </ref> is the basis for the more successful Linda implementations on distributed memory systems and the basis for our research. This implementation strategy assumes that tuplespace has been partitioned [3]. <p> tuple or reduction of the number of communications required. worker () f DATA TYPE data; int index; while (1) f in ("head of queue", ? index); out ("head of queue", index+1); in ("queue data", index, ? data); process (data); g shared variables in a distributed queue The inout collapse optimization <ref> [4] </ref> is one transformation that reduces the number of necessary communications. The "head of queue" operations of Figure 1 qualify for the inout collapse optimization. This transformation combines the two distinct operations into a single operation that updates the tuple at the rendezvous node rather than at the worker node. <p> The efficient distributed-memory barrier synchronization of <ref> [4] </ref> is an example. Thus, identifying the basic synchronization tuple has the additional benefit of allowing even more analysis with potentially greater payoff.
Reference: [5] <author> Ashish Deshpande and Martin Schultz. </author> <title> Efficient parallel programming with linda. </title> <booktitle> In Supercomputing '92 Proceedings, </booktitle> <pages> pages 238-244, </pages> <address> Minneapolis, Minnesota, </address> <month> November </month> <year> 1992. </year>
Reference-contexts: While it has been demonstrated that distributed tuplespace im-plementations can be efficient for a wide variety of "real" applications encompassing a large scope of parallel algorithm classifications <ref> [5, 6, 7] </ref>, there remains opportunity for improvement through compiler analysis targeting the underlying message passing [8, 9, 10].
Reference: [6] <author> Timothy G. Mattson. </author> <title> The efficiency of linda for general purpose scientific programming. </title> <journal> Scientific Programming, </journal> <volume> 3(1) </volume> <pages> 61-71, </pages> <year> 1994. </year>
Reference-contexts: While it has been demonstrated that distributed tuplespace im-plementations can be efficient for a wide variety of "real" applications encompassing a large scope of parallel algorithm classifications <ref> [5, 6, 7] </ref>, there remains opportunity for improvement through compiler analysis targeting the underlying message passing [8, 9, 10].
Reference: [7] <author> Nicholas Carriero and David Gelernter. </author> <title> Learning from our successes. </title> <editor> In Janusz S. Kowalik and Lucio Grandinetti, editors, </editor> <booktitle> Software for Parallel Computation, volume 106 of NATO ASI Series F: Computer and Systems Sciences, </booktitle> <pages> pages 37-45. </pages> <publisher> Springer-Verlag, </publisher> <year> 1992. </year>
Reference-contexts: While it has been demonstrated that distributed tuplespace im-plementations can be efficient for a wide variety of "real" applications encompassing a large scope of parallel algorithm classifications <ref> [5, 6, 7] </ref>, there remains opportunity for improvement through compiler analysis targeting the underlying message passing [8, 9, 10].
Reference: [8] <author> Nicholas Carriero and David Gelernter. </author> <title> A foundation for advanced compile-time analysis of linda programs. </title> <booktitle> In Languages and Compilers for Parallel Computing, </booktitle> <pages> pages 389-404. </pages> <publisher> Springer-Verlag, </publisher> <year> 1992. </year>
Reference-contexts: While it has been demonstrated that distributed tuplespace im-plementations can be efficient for a wide variety of "real" applications encompassing a large scope of parallel algorithm classifications [5, 6, 7], there remains opportunity for improvement through compiler analysis targeting the underlying message passing <ref> [8, 9, 10] </ref>. Carriero and Gelernter discuss potential compile-time analysis to reduce the impact of uncoupled communication [8], but very little optimization analysis for transformation beyond peephole transformations have actually been developed and implemented to our knowledge. <p> Carriero and Gelernter discuss potential compile-time analysis to reduce the impact of uncoupled communication <ref> [8] </ref>, but very little optimization analysis for transformation beyond peephole transformations have actually been developed and implemented to our knowledge. Based on their observations, this paper provides concrete steps towards the advanced compile-time analysis and optimization of the uncoupled communication of shared tu-plespace. <p> be necessary to produce and then consume a tuple, one to send the tuple to the rendezvous node, another to send the template to the rendezvous node, and one more to send the tuple from the rendezvous node to the requesting node. 3 Analysis of Tuple Usage Carriero and Gelernter <ref> [8] </ref> describe three types of tuple usage patterns: messages, streams, and shared variables.
Reference: [9] <author> James B. Fenwick, Jr. and Lori L. Pollock. </author> <title> Identifying tuple usage patterns in an optimizing linda compiler. </title> <booktitle> In Proceedings of Mid-Atlantic Workshop on Programming Languages and Systems (MASPLAS '96), </booktitle> <year> 1996. </year>
Reference-contexts: While it has been demonstrated that distributed tuplespace im-plementations can be efficient for a wide variety of "real" applications encompassing a large scope of parallel algorithm classifications [5, 6, 7], there remains opportunity for improvement through compiler analysis targeting the underlying message passing <ref> [8, 9, 10] </ref>. Carriero and Gelernter discuss potential compile-time analysis to reduce the impact of uncoupled communication [8], but very little optimization analysis for transformation beyond peephole transformations have actually been developed and implemented to our knowledge. <p> Being able to distinguish a tuple (or more properly, a tuple set or partition) as belonging to one of these usage classes would allow compiler transformations to improve program execution. We have developed a data flow analysis framework to characterize the number of tuples in tuplespace partitions <ref> [9] </ref>. Specifically, the data flow answers the question, "May there ever be more than one tuple in a partition at any time during program execution?" This information is crucial to reasoning about how tuples are used and thus finding opportunities for optimization. <p> The first condition for a shared variable is determined from the data flow information computed by the framework described in <ref> [9] </ref>. If this condition is satisfied, then field polarities are checked. For example, consider the two operations in Figure 1 that are in the "head of queue" partition 3 . Never is more than one tuple of this partition in existence at a time. <p> The compiler and tuplespace run-time system have been validated by a suite of benchmark programs consisting of synthetic programs which target specific source or runtime characteristics and real applications programs including matrix multiplication, a 2-dimensional heat equation domain decomposition, and a concurrent wave equation <ref> [9] </ref>. We have run our system on the benchmark programs with encouraging results. In every Linda program, there was at least one tuplespace partition with a tuple count of 1. Overall, more than 33% of the partitions had a tuple count of 1.
Reference: [10] <author> Kenneth Landry and John D. Arthur. </author> <title> Achieving asynchronous speedup while preserving synchronous semantics: An implementation of instructional footprinting in linda. </title> <booktitle> In The 1994 International Conference on Computer Languages, </booktitle> <pages> pages 55-63, </pages> <address> Toulouse, France, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: While it has been demonstrated that distributed tuplespace im-plementations can be efficient for a wide variety of "real" applications encompassing a large scope of parallel algorithm classifications [5, 6, 7], there remains opportunity for improvement through compiler analysis targeting the underlying message passing <ref> [8, 9, 10] </ref>. Carriero and Gelernter discuss potential compile-time analysis to reduce the impact of uncoupled communication [8], but very little optimization analysis for transformation beyond peephole transformations have actually been developed and implemented to our knowledge.
Reference: [11] <author> Nicholas Carriero and David Gelernter. </author> <title> How to Write Parallel Programs, A First Course. </title> <publisher> The MIT Press, </publisher> <year> 1992. </year>
Reference-contexts: In Section 2, we summarize the essential parts of Linda. Section 3 presents the analysis of tuple usage patterns. Section 4 describes our implementation and experimental study, followed by concluding remarks in Section 5. 2 Linda The best known implementation of the generative communication model is Linda 1 <ref> [1, 11] </ref>. Our work is therefore based on Linda although it applies more generally to any generative communication model implementation. Linda is a coordination language consisting of a small number of primitives which are added into existing sequential languages. These operations perform the communication and synchronization necessary for parallel programming. <p> A distributed queue, or stream, is simply an ordered sequence of tuples, and may come in a variety of flavors distinguished by the number of processes removing from and adding to the stream <ref> [11] </ref>. A stream is a single data structure, but involves the cooperative use of more than one tuplespace partition as demonstrated in Figure 1. The "head of queue" partition acts as the shared variable tuple coordinating access to the stream's head among many processes.
Reference: [12] <author> Santosh S. Pande, Dharma P. Agrawal, and Jon Mauney. </author> <title> Compiling functional parallelism on distributed-memory systems. </title> <booktitle> IEEE Parallel & Distributed Technology, </booktitle> <pages> pages 64-76, </pages> <month> Spring </month> <year> 1994. </year>
Reference-contexts: This is how the programmer explicitly creates parallelism. This style of explicit parallelism should be differentiated from other types of parallelism. Functional, task, or DAG parallelism is the parallelism that can be exploited among different operations in a program by using data and control dependences <ref> [12] </ref> targeting a parallelism that is more coarsely grained than loop-level parallelism. Other research [12, 13] may be applied by a Linda compiler to extract these finer grained parallelisms present in individual, explicitly specified Linda processes. <p> Functional, task, or DAG parallelism is the parallelism that can be exploited among different operations in a program by using data and control dependences [12] targeting a parallelism that is more coarsely grained than loop-level parallelism. Other research <ref> [12, 13] </ref> may be applied by a Linda compiler to extract these finer grained parallelisms present in individual, explicitly specified Linda processes.
Reference: [13] <author> Milind Girkar and Constantine D. Polychronopoulos. </author> <title> The hierarchical task graph as a universal intermediate representation. </title> <journal> International Journal of Parallel Programming, </journal> <volume> 22(5) </volume> <pages> 519-551, </pages> <year> 1994. </year>
Reference-contexts: Functional, task, or DAG parallelism is the parallelism that can be exploited among different operations in a program by using data and control dependences [12] targeting a parallelism that is more coarsely grained than loop-level parallelism. Other research <ref> [12, 13] </ref> may be applied by a Linda compiler to extract these finer grained parallelisms present in individual, explicitly specified Linda processes.
Reference: [14] <author> Henri E. Bal. </author> <title> A comparative study of five parallel programming languages. </title> <booktitle> In Distributed Open Systems, </booktitle> <pages> pages 134-151. </pages> <publisher> IEEE, </publisher> <year> 1994. </year>
Reference-contexts: For example, one of the more important contributions of Linda is the introduction of distributed data structures <ref> [14] </ref>. A distributed queue, or stream, is simply an ordered sequence of tuples, and may come in a variety of flavors distinguished by the number of processes removing from and adding to the stream [11].
Reference: [15] <author> James B. Fenwick, Jr. and Lori L. Pollock. </author> <title> Implementing an optimizing linda compiler using suif. </title> <booktitle> In Proceedings of SUIF Compiler Workshop. </booktitle> <address> Stanford, California, </address> <month> January </month> <year> 1996. </year>
Reference-contexts: The algorithm for detecting synchronization tuple usage patterns is very similar to the shared variable usage detection algorithm, and thus not included in this paper. 4 Implementation and Experi mentation We have built an optimizing Linda compiler <ref> [15] </ref> based on the SUIF compiler infrastructure [16], and a distributed tuplespace runtime system [17]. The runtime system executes on a network of Sun 4 workstations connected by Ethernet and is implemented in C in a UNIX environment utilizing the Berkeley socket API for network communication.
Reference: [16] <author> Stanford SUIF Compiler Group. </author> <title> The SUIF Parallelizing Compiler Guide. </title> <institution> Stanford University, </institution> <year> 1994. </year> <note> Version 1.0. </note>
Reference-contexts: The algorithm for detecting synchronization tuple usage patterns is very similar to the shared variable usage detection algorithm, and thus not included in this paper. 4 Implementation and Experi mentation We have built an optimizing Linda compiler [15] based on the SUIF compiler infrastructure <ref> [16] </ref>, and a distributed tuplespace runtime system [17]. The runtime system executes on a network of Sun 4 workstations connected by Ethernet and is implemented in C in a UNIX environment utilizing the Berkeley socket API for network communication.
Reference: [17] <author> James B. Fenwick, Jr. and Lori L. Pollock. </author> <title> Issues and experiences in implementing a distributed tuplespace. </title> <type> Technical Report TR 9706, </type> <institution> University of Delaware, </institution> <year> 1996. </year>
Reference-contexts: algorithm for detecting synchronization tuple usage patterns is very similar to the shared variable usage detection algorithm, and thus not included in this paper. 4 Implementation and Experi mentation We have built an optimizing Linda compiler [15] based on the SUIF compiler infrastructure [16], and a distributed tuplespace runtime system <ref> [17] </ref>. The runtime system executes on a network of Sun 4 workstations connected by Ethernet and is implemented in C in a UNIX environment utilizing the Berkeley socket API for network communication.
References-found: 17

