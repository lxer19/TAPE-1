URL: http://www.cs.dartmouth.edu/~gdavis/papers/jscc.spie96.ps.gz
Refering-URL: http://www.cs.dartmouth.edu/~gdavis/
Root-URL: http://www.cs.dartmouth.edu
Title: Joint Source and Channel Coding for Image Transmission Over Lossy Packet Networks  
Author: Geoffrey Davis and John Danskin 
Keyword: joint source/channel coding, erasure channel, lossy image transmission  
Address: College, Hanover, NH 03755  
Affiliation: Sudikoff Laboratory, Dartmouth  
Email: Email: fgdavis, jmdg@cs.dartmouth.edu  
Phone: 6211  
Date: August 5, 1996  
Abstract: We describe a joint source/channel allocation scheme for transmitting images lossily over block erasure channels such as the Internet. The goal is to reduce image transmission latency. Our subband-level and bitplane-level optimization procedures give rise to an embedded channel coding strategy. Source and channel coding bits are allocated in order to minimize an expected distortion measure. More perceptually important low frequency channels of images are shielded heavily using channel codes; higher frequencies are shielded lightly. The result is a more efficient use of channel codes that can reduce channel coding overhead. This reduction is most pronounced on bursty channels for which the uniform application of channel codes is expensive. We derive optimal source/channel coding tradeoffs for our block erasure channel. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Albanese, J. Bloemer, J. Edmonds, M. Luby, and M. Sudan. </author> <title> Priority encoding transmission. </title> <booktitle> In Proc. Foundations of Computer Sciences, </booktitle> <pages> pages 604-612, </pages> <address> Santa Fe, NM, </address> <year> 1994. </year>
Reference: [2] <author> M. Antonini, M. Barlaud, and P. Mathieu. </author> <title> Image Coding Using Wavelet Transform. </title> <journal> IEEE Trans. Image Proc., </journal> <volume> 1(2) </volume> <pages> 205-220, </pages> <month> Apr. </month> <year> 1992. </year>
Reference-contexts: We perform a 5-level wavelet transform with symmetrized boundaries using the 7/9-tap biorthogonal wavelet of <ref> [2] </ref>. Coefficients are quantized using the embedded quantization scheme of [22] and entropy coded using an adaptive arithmetic coder. There is no training involved. We describe bit allocation in more detail below.
Reference: [3] <author> E. Biersack. </author> <title> Performance evalutaion of forward error correction in ATM networks. </title> <booktitle> In Proc. SIGCOMM, </booktitle> <pages> pages 248-257, </pages> <address> Baltimore, </address> <year> 1992. </year>
Reference-contexts: An alternative strategy is to apply forward error correction (FEC) to packets. Forward error correction must be applied with care, however, since the added redundancy increases network loads and can in some cases actually degrade overall network performance <ref> [3] </ref>. In this paper we consider the problem of how to make the most efficient use of forward error correction for transmission of images over lossy packet networks.
Reference: [4] <author> T. Cover and J. Thomas. </author> <title> Elements of Information Theory. </title> <publisher> John Wiley & Sons, Inc., </publisher> <address> New York, </address> <year> 1991. </year>
Reference-contexts: If our goal is to encode realizations of a collection of independent mean zero Gaussian sources, rather than a single Gaussian source, then for large N the optimal solution is to divide the rN b source coding bits using the standard reverse water-filling algorithm <ref> [4] </ref>. When N is large there is virtually nothing to be gained by varying the allocation of channel codes by subbands in an image. The overall rate R does play a role in determining r for smaller values of N , however.
Reference: [5] <author> C. R. Cunha, A. Bestavros, and M. E. Crovella. </author> <title> Characteristics of WWW client-based traces. </title> <type> Technical Report TR-95-010, </type> <institution> Boston University Computer Science Department, </institution> <year> 1995. </year>
Reference-contexts: 1 INTRODUCTION With the rising popularity of Web browsers, image transmission has become one of the largest uses of Internet bandwidth <ref> [5] </ref>. Responsiveness is essential in interactive applications such as browsers, even more so than perfect image fidelity, since many images have already been distorted by lossy compression techniques.
Reference: [6] <author> R. A. DeVore, B. Jawerth, and B. J. Lucier. </author> <title> Image Compression through Wavelet Transform Coding. </title> <journal> IEEE Trans. Info. Theory, </journal> <volume> 38(2) </volume> <pages> 719-746, </pages> <month> Mar. </month> <year> 1992. </year>
Reference-contexts: As a result, our L 1 -optimized distributions of channel codes are much less flat. They significantly reduce the channel coding overhead by permitting relatively rare losses of high frequency data. Moreover, DeVore et al <ref> [6] </ref> make the case, based on arguments about the frequency sensitivity of the human visual system, that L 1 is a more appropriate distortion measure for images than L 2 .
Reference: [7] <author> N. Farvardin. </author> <title> A study of vector quantization for noisy channels. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> 36(4) </volume> <pages> 799-809, </pages> <month> July </month> <year> 1990. </year>
Reference-contexts: With straight vector quantization, on the other hand, received vectors can be arbitrarily assigned to decoded values. This additional freedom can be used to improve the performance of the coder. Steps towards constructing such channel-optimized vector quantizers have been described in [27] and <ref> [7] </ref>. In each of these works, quantizer indices are assigned so that Hamming distances between codewords correspond to the Euclidean distances between their decoded values. Our construction embodies similar ideas, but entails the use of much lower complexity scalar quantizers.
Reference: [8] <author> M. W. Garrett and M. Vetterli. </author> <title> Joint source/channel coding of statistically multiplexed real-time services on packet networks. </title> <journal> IEEE Transactions on Networking, </journal> <volume> 1(1) </volume> <pages> 71-80, </pages> <month> Feb. </month> <year> 1993. </year>
Reference: [9] <author> A. Gersho. </author> <title> Asymptotically optimal block quantization. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> IT-25(4):373-380, </volume> <month> July </month> <year> 1979. </year>
Reference: [10] <author> H. Gish and J. N. Pierce. </author> <title> Asymptotically efficient quantizing. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> IT-14(5):676-683, </volume> <month> Sept. </month> <year> 1968. </year>
Reference-contexts: Let C j;k and D j;k be the cost and the reduction in distortion obtained from quantizing bitplane k of subband j. We assume that D j;k D j+1;k C j+1;k : This has been verified empirically for our test images. Moreover, analysis of Gish and Pierce <ref> [10] </ref> show that it holds at high rates for entropy coded, uniformly quantized i.i.d. sources. If there were no coupling between the bitplanes, we could find an optimal allocation using Lagrange multipliers.
Reference: [11] <author> B. Hochwald and K. Zeger. </author> <title> Tradeoff between source and channel coding. </title> <type> preprint, </type> <year> 1996. </year>
Reference-contexts: large the right hand side is dominated by the ln (N ) term, and we find that distortion is minimized for r p p (1 p) N For this rate we have D (r) 2 2 2Rr : (8) Related results for the binary symmetric channel may be found in <ref> [11] </ref>. We see that as N tends to infinity, r tends to the channel capacity, p, and the overall distortion tends to the rate-distortion curve for a set of i.i.d. Gaussian samples.
Reference: [12] <author> G. Karlsson and M. Vetterli. </author> <title> Subband coding of video for packet networks. </title> <journal> Optical Engineering, </journal> <volume> 27(7) </volume> <pages> 574-586, </pages> <year> 1988. </year>
Reference-contexts: In each case we provide motivation based on optimal information-theoretic considerations. 1.1 Related Work A number of redundant lossy packet transmission schemes have been examined for images and video. The algorithms of [23] and <ref> [12] </ref> make use of naturally occurring redundancy within images to recover from packet losses. The number of losses that can be sustained is highly image dependent in this case, and only limited compression can be used. Our allocation schemes allow for precise control of the distribution of redundancy.
Reference: [13] <author> C. Leicher. </author> <title> Hierarchical encoding of mpeg sequences using priority encoding transmission (PET). </title> <type> Technical Report TR-94-058, ICSI, </type> <institution> Berkeley, </institution> <address> CA, </address> <month> Nov. </month> <year> 1994. </year>
Reference: [14] <author> A. S. Lewis and G. Knowles. </author> <title> Image compression using the 2-D wavelet transform. </title> <journal> IEEE Trans. on Image Processing, </journal> <volume> 1(2) </volume> <pages> 244-250, </pages> <month> Apr. </month> <year> 1992. </year>
Reference-contexts: We use the total squared error as a distortion measure, but the algorithms described in this paper will function equally well with other additive metrics such as the perceptually weighted metric described in <ref> [14] </ref>.
Reference: [15] <author> E. Posnak, S. Gallindo, A. Stephens, and H. Vin. </author> <title> Techniques for resilient transmission of jpeg video streams. </title> <booktitle> In Proceedings of Multimedia Computing and Networking, San Jose, </booktitle> <volume> volume 2417, </volume> <pages> pages 243-252, </pages> <month> Feb. </month> <year> 1995. </year>
Reference: [16] <author> F. P. Preparata. </author> <title> Holographic dispersal and recovery of information. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> 35(5) </volume> <pages> 1123-1124, </pages> <month> Sept. </month> <year> 1989. </year>
Reference-contexts: As we see in the next section, our experimental results bear out these hypotheses. 2.2 Maximum Distance Separable Codes The codes we use in this paper are based on Rabin's Information Dispersal Algorithm [17] (IDA) and its variants <ref> [16] </ref>. The basic idea is a simple one: our codes consist of N dimensional vectors over a finite field GF (2 c ), where c is a constant that divides b, the total number of bits in a packet.
Reference: [17] <author> M. O. Rabin. </author> <title> Efficient dispersal of information for security, load balancing, and fault tolerance. </title> <journal> Journal of the ACM, </journal> <volume> 36(2) </volume> <pages> 335-348, </pages> <month> Apr. </month> <year> 1989. </year>
Reference-contexts: As we see in the next section, our experimental results bear out these hypotheses. 2.2 Maximum Distance Separable Codes The codes we use in this paper are based on Rabin's Information Dispersal Algorithm <ref> [17] </ref> (IDA) and its variants [16]. The basic idea is a simple one: our codes consist of N dimensional vectors over a finite field GF (2 c ), where c is a constant that divides b, the total number of bits in a packet.
Reference: [18] <author> K. Ramchandran, A. Ortega, and M. Vetterli. </author> <title> Bit allocation for dependent quantization with applications to multiresolution and MPEG video coders. </title> <journal> IEEE Transactions on Image Processing, </journal> <volume> 3(5) </volume> <pages> 533-545, </pages> <month> Sept. </month> <year> 1994. </year>
Reference-contexts: Entropy coding of fine scale bitplanes is conditioned on coarser scale bitplanes, so the loss of a coarse scale bitplane results in the loss of all finer scale bitplanes. Algorithms have been developed for handling such dependent quantization problems for MPEG <ref> [18] </ref>. As we show below, however, in this particular case the coupling budget. Our image quality metric is expected squared distortion, and we have expressed this as a peak signal to noise ratio. The test image is the 512 fi 512 Lena image.
Reference: [19] <author> J. Shapiro. </author> <title> Embedded image coding using zerotrees of wavelet coefficients. </title> <journal> IEEE Transactions on Signal Processing, </journal> <volume> 41(12) </volume> <pages> 3445-3462, </pages> <month> Dec. </month> <year> 1993. </year>
Reference-contexts: A number of recently developed image compression techniques, such as Shapiro's EZW scheme <ref> [19] </ref>, are extremely sensitive to erasures, so this is not an entirely unreasonable distortion model. We will consider better decoding strategies below in section 3.4. <p> There is no training involved. We describe bit allocation in more detail below. This simple scheme, despite its lack of higher level data structures such as zerotrees, yields PSNR's roughly comparable to those of Shapiro's embedded zerotree wavelet coder <ref> [19] </ref> due to its more efficient bit allocation procedure. We have chosen to work with a wavelet-based scheme because of its simplicity and good performance at low bit rates. The ideas presented below can be generalized to other subband-based schemes such as JPEG.
Reference: [20] <author> Y. Shoham and A. Gersho. </author> <title> Efficient bit allocation for an arbitrary set of quantizers. </title> <journal> IEEE Trans. Acoustics, Speech, and Signal Processing, </journal> <volume> 36(9) </volume> <pages> 1445-1453, </pages> <month> Sept. </month> <year> 1988. </year>
Reference-contexts: We use a discrete Lagrange multipliers scheme to minimize D total subject to the constraint. We minimize the sum D total +C total where an appropriate is found using a binary search as described in Shoham and Gersho <ref> [20] </ref>. Because not all cost constraints are achievable using this Lagrangian scheme, we allocate any remaining bits using marginal analysis. 3.2 Bit Allocation for Joint Source/Channel Coding We can optimize the distribution of channel codes for subbands using a simple extension of the above allocation procedure.
Reference: [21] <author> N. Tanabe and N. Farvardin. </author> <title> Subband image coding using entropy-coded quantization over noisy channels. </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> 10(5) </volume> <pages> 926-943, </pages> <year> 1992. </year>
Reference: [22] <author> D. Taubman and A. Zakhor. </author> <title> Multirate 3-D subband coding of video. </title> <journal> IEEE Trans. Image Proc., </journal> <volume> 3(5), </volume> <month> Sept. </month> <year> 1994. </year>
Reference-contexts: We perform a 5-level wavelet transform with symmetrized boundaries using the 7/9-tap biorthogonal wavelet of [2]. Coefficients are quantized using the embedded quantization scheme of <ref> [22] </ref> and entropy coded using an adaptive arithmetic coder. There is no training involved. We describe bit allocation in more detail below.
Reference: [23] <author> C. J. Turner and L. L. Peterson. </author> <title> Image transfer: </title> <booktitle> and end-to-end design. In Proc. SIGCOMM, </booktitle> <pages> pages 258-268, </pages> <year> 1992. </year>
Reference-contexts: In each case we provide motivation based on optimal information-theoretic considerations. 1.1 Related Work A number of redundant lossy packet transmission schemes have been examined for images and video. The algorithms of <ref> [23] </ref> and [12] make use of naturally occurring redundancy within images to recover from packet losses. The number of losses that can be sustained is highly image dependent in this case, and only limited compression can be used. Our allocation schemes allow for precise control of the distribution of redundancy.
Reference: [24] <author> J. B. Weaver, J. Dennis M. Healy, D. W. Warner, S. Chawla, and J. Lu. </author> <title> Mr imaging with a reduced number of encoding steps. </title> <booktitle> In Proc. SPIE: Medical Imaging 2710-79, </booktitle> <address> Newport Beach, </address> <month> Feb. </month> <year> 1996. </year>
Reference-contexts: Moreover, DeVore et al [6] make the case, based on arguments about the frequency sensitivity of the human visual system, that L 1 is a more appropriate distortion measure for images than L 2 . Experiments by Healy et al <ref> [24] </ref> also suggest that the L p norms for small values of p correspond more closely to perceived distortion than does L 2 . We see from figure 5 that the L 1 optimization results in a gradual reduction in the amount of channel coding protection of subbands.
Reference: [25] <author> P. L. Zador. </author> <title> Asymptotic quantization error of continuous signals and the quantization dimension. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> IT-28(2):139-149, </volume> <month> Mar. </month> <year> 1982. </year>
Reference: [26] <author> K. Zeger. </author> <title> Source and channel coding with vector quantization. </title> <type> PhD thesis, </type> <institution> U.C. Santa Barbara, </institution> <year> 1990. </year>
Reference-contexts: Zeger <ref> [26] </ref> has shown that one can obtain better results by transmitting information over a noisy channel using a high resolution vector quantizer with no explicit error control than by using a lower resolution quantizer with forward error correction.
Reference: [27] <author> K. Zeger and A. Gersho. </author> <title> Pseudo-Gray coding. </title> <journal> IEEE Transactions on Communications, </journal> <volume> 38(12) </volume> <pages> 2147-2158, </pages> <month> Dec. </month> <year> 1990. </year>
Reference-contexts: With straight vector quantization, on the other hand, received vectors can be arbitrarily assigned to decoded values. This additional freedom can be used to improve the performance of the coder. Steps towards constructing such channel-optimized vector quantizers have been described in <ref> [27] </ref> and [7]. In each of these works, quantizer indices are assigned so that Hamming distances between codewords correspond to the Euclidean distances between their decoded values. Our construction embodies similar ideas, but entails the use of much lower complexity scalar quantizers.
References-found: 27

