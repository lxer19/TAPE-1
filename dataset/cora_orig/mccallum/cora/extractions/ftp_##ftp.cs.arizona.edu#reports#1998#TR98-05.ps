URL: ftp://ftp.cs.arizona.edu/reports/1998/TR98-05.ps
Refering-URL: http://www.cs.arizona.edu/research/reports.html
Root-URL: http://www.cs.arizona.edu
Title: HINT-BASED COOPERATIVE CACHING  
Author: by Prasenjit Sarkar 
Degree: A Dissertation Submitted to the Faculty of the DEPARTMENT OF COMPUTER SCIENCE In Partial Fulfillment of the Requirements For the Degree of DOCTOR OF PHILOSOPHY In the Graduate College  
Date: 1 9 9 8  
Affiliation: THE UNIVERSITY OF ARIZONA  
Abstract-found: 0
Intro-found: 1
Reference: [Acharya98] <author> Anurag Acharya and Sanjeev Setia. </author> <title> The utility of exploiting idle memory for data intensive computations. </title> <type> Technical Report TRCS98-02, </type> <institution> University of California at Santa Barbara, </institution> <month> February </month> <year> 1998. </year>
Reference-contexts: While this limit seems high, it represents the worst case because the analysis assumes that every client is replacing blocks from the caches of other clients. In a typical distributed file system, not all clients access the cooperative cache at the same time <ref> [Acharya98] </ref>. Under these conditions, best-guess replacement does much better. <p> Though research has shown that client loads may be an issue if idle clients are used as dedicated remote memory servers [Voelker97], these high client loads were not observed in the course of our measurements because idle clients have very low CPU loads in a typical distributed file system <ref> [Acharya98] </ref>. 4.4 Cache Consistency Cooperative caching, for the most part, poses no restrictions on any cache consistency protocol, as discussed in Chapter 2.6.
Reference: [Agarwal91] <author> Anant Agarwal, David Chaiken, Godfrey D'Souza, Kirk John-son, David Kranz, John Kubiatowicz, Kiyoshi Kurihara, Beng-Hong Lim, Gino Maa, Dan Nussbaum, Mike Parkin, and Donald Yeung. </author> <title> The MIT Alewife machine: A large-scale distributed-memory processor. </title> <type> Technical Report MIT/LCS Memo TM-454, </type> <institution> MIT, </institution> <year> 1991. </year>
Reference-contexts: NUMA machines avoid the bottleneck of UMA machines by removing the restriction of a single memory bus. NUMA machines consist of multiple memories and processors connected by multiple busses and an interconnection network <ref> [Lenoski90, Agarwal91, Cray93] </ref>. The chief difference between a distributed file system and a NUMA machine is that one processor is more likely to be separated from another by multiple network hops in a NUMA machine than in a distributed file system.
Reference: [Anderson95] <author> Thomas Anderson, Michael Dahlin, Jeanna Neefe, David Pat-terson, Drew Roselli, and Randolph Wang. </author> <title> Serverless Network File Systems. </title> <booktitle> In Proceedings of the 15th Symposium on Operating System Principles, </booktitle> <pages> pages 109-126, </pages> <month> December </month> <year> 1995. </year>
Reference-contexts: The algorithm was further refined to separate the roles of the server and the manager in the xfs file system <ref> [Anderson95] </ref>. 35 3.1.1 Lookup The N-chance algorithm uses the server to take on the responsibilities of a manager and locate blocks in the client caches. <p> The xfs file system refined the N-chance algorithm by separating the role of the manager from the server, so that the server and the manager reside on separate machines <ref> [Anderson95] </ref>. This refinement reduces the load on the server as communication with the manager can now avoid the server. Additionally, in an attempt to reduce the overhead of contacting the manager, the xfs file system also tries to co-locate managers with clients. <p> All existing evaluations of co-location mechanisms have assumed a single client accessing blocks and have neglected to measure the overhead in the case where multiple clients access shared blocks <ref> [Feeley95, Anderson95] </ref>. A potential improvement to the above scheme is to maintain block location hints in every client, and thus avoid both the cost of communication with a manager and the complexity of a co-location mechanism. <p> This assumption was also made by the designers of the N-chance simulator. The N-chance simulator was modified to incorporate additional functionality used in the xfs file system <ref> [Anderson95] </ref>. In the modified system, a manager preferentially forwards a request to the client caches instead of a server, improving the cooperative cache hit ratio and reducing the number of server accesses.
Reference: [ANSI87] <author> ANSI. </author> <title> Fiber-Distributed Data Interface (FDDI) Token Ring Media Access Control. ANSI X3.139-1987, </title> <month> November </month> <year> 1987. </year>
Reference-contexts: Low-cost microcomputers now provide the computing power for a vast range of applications and have replaced the need for a centralized mainframe-based computing environment in organizations. In tandem, local area networking has also evolved to provide high-bandwidth connections between individual computers <ref> [Forum93, ANSI87, Metcalfe76] </ref>. This has led to the development of distributed systems where many computers share resources and services over a network. While distributed systems provide advantages over a collection of isolated microcomputers, they also introduce new challenging issues [Tannenbaum96].
Reference: [Bach87] <author> Maurice Bach, Mark Luppi, Anna Melamed, </author> <note> and Kang Yueh. </note>
Reference-contexts: If the lookup fails, the client forwards the block request to the server. The server performs a lookup in the server cache and in case of failure, forwards the block request to its disk subsystem. Caching is one of the principal mechanisms of achieving this goal <ref> [Smith82, Leach83, Sandberg85, Popek85, Schroeder85, Bach87, Howard88, Nelson93] </ref>. The use of caches creates a storage hierarchy on top of the file service to filter out accesses to the slower layers of the hierarchy.
References-found: 5

