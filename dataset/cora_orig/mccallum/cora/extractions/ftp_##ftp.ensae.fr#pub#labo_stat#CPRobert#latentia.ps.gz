URL: ftp://ftp.ensae.fr/pub/labo_stat/CPRobert/latentia.ps.gz
Refering-URL: http://www.stats.bris.ac.uk/MCMC/pages/list.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: MCMC Specificities of Latent Variable Models 1  
Author: Christian P. Robert 
Keyword: MCMC methods, mixture models, HMMs, stochastic volatility, state space models, moving average, EM, simulated likelihood, completion, missing variable, convergence control, diagnostics, asymptotic normality, normality test, duality principle, simulated likelihood ratio  
Address: Timbre J340, 18, boulevard A. Pinard, 75675 Paris cedex 14  
Affiliation: Laboratoire de Statistique, Crest, Insee  
Abstract: We derive from analyses of several specific latent variable models an overall review of these models, under the unifying theme of their strong connections with simulated methods like SEM and the Gibbs sampler. We stress that the connection goes both ways, namely that these models were instrumental in designing these new methods, that the convergence properties and convergence diagnostic tools of the associated algorithms are specific to such models, and that hybrid methods like Gibbs maximum likelihood techniques can be proposed in such settings. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Archer, G.E.B. and Titterington, </author> <title> D.M. (1997) Parameter estimation for hidden Markov chains. </title> <type> Tech. report, </type> <institution> University of Glasgow, Department of Statistics. </institution>
Reference: <author> Azzalini, A. and Bowman, A.W. </author> <title> (1990) A look at some data on the Old Faithful geyser. </title> <journal> Applied Statistics 39, </journal> <pages> 357-365. </pages>
Reference: <author> Barnett, G., Kohn, R. and Sheather, S. </author> <title> (1996) Bayesian estimation of an autoregressive model using Markov chain Monte Carlo. </title> <journal> J. </journal> <volume> Econometrics 74, </volume> <pages> 237-254. </pages>
Reference: <author> Baum, L.E., Petrie, T., Soules, G. and Weiss, N. </author> <title> (1970) A maximization technique occurring in the statistical analysis of probabilistic functions of Markov chains. </title> <journal> Ann. Math. Statis. </journal> <volume> 41, </volume> <pages> 164-171. </pages>
Reference-contexts: : :; z i1 ; z i+1 ; : : : ; IP) / p z i1 u p uz i+1 f (x i j u ; u ); (8) but an alternative often advocated in the signal processing literature is to make use of Baum and Petrie' forward-backward formulae <ref> (see, e.g., Baum, Petrie, Soules and Weiss, 1970) </ref>, based on the backward formulae P (x j+1 ; : : : ; x n j z j = i; IP) X p i` P (x j+1 ; : : : ; x n jz j+1 = `; IP) X p i` f
Reference: <author> Billio, M. and Monfort, A. </author> <title> (1998) Switching state space models. </title> <journal> J. Statist. </journal> <note> Plann. Infer. (to appear). </note>
Reference: <author> Billio, M., Monfort, A., and Robert, </author> <title> C.P. (1998a) Bayesian estimation of switching ARMA models. </title> <journal> J. </journal> <note> Econometrics (to appear). </note>
Reference: <author> Billio, M., Monfort, A., and Robert, </author> <title> C.P. (1998b) The Simulated Likelihood Ratio method. </title> <type> Doc. </type> <institution> travail CREST, Insee, Paris. </institution>
Reference: <author> Broniatowski, M., Celeux, G. and Diebolt, J. </author> <title> (1983) Reconnaissance de melanges de densites par un algorithme d'apprentissage probabiliste. </title>
Reference: <editor> In: </editor> <title> Data Analysis and Informatics 3, </title> <editor> E. Diday (Ed.). </editor> <publisher> North-Holland, Amsterdam. </publisher>
Reference: <author> Brooks, S. and Roberts, G. </author> <title> (1998) Diagnosing convergence of Markov chain Monte Carlo algorithms. </title> <journal> Canad. J. Statist. </journal> <note> (to appear). Fig. </note> <month> 12. </month> <title> Successive histograms, Ghosh (1996) T 3-plots and Kolmogorov-Smirnov p-values for the normalised indicator averages j in the case of a mixture of 3 exponential distributions. (Source: </title> <editor> Gruet et al., 1998.) Celeux, G. and Diebolt, J. </editor> <title> (1985) The SEM algorithm: a probabilistic teacher algorithm derived from the EM algorithm for the mixture problem. </title> <journal> Comput. Statist. Quater. </journal> <volume> 2, </volume> <pages> 73-82. </pages>
Reference: <author> Chib, S. </author> <title> (1996) Calculating posterior distributions and modal estimates in Markov mixture models. </title> <journal> J. Econometrics. </journal> <volume> 75, </volume> <pages> 79-97 Cowles, </pages> <editor> M.K. and Carlin, </editor> <title> B.P. (1996) Markov Chain Monte-Carlo convergence diagnostics: a comparative study. </title> <journal> J. Amer. Statist. Assoc. </journal> <volume> 91, </volume> <pages> 883-904. </pages>
Reference-contexts: While convoluted at first sight, this method can be efficiently implemented in settings like latent variable models, where the stabilization of the prior feedback estimator of the density occurs quite quickly. Comparisons with implementations based on the EM algorithm <ref> (Chib, 1996) </ref> lead to different estimates in the Poisson case, thus pointing out that the EM algorithm has converged to a local maxima of the likelihood function (see Robert and Titterington, 1998). Fig. 4.
Reference: <author> Davies, R.B. </author> <title> (1977) Hypothesis testing when a nuisance parameter is present only under the alternative. </title> <journal> Biometrika 64, </journal> <pages> 247-254. </pages>
Reference: <author> Dempster, A.P., Laird, N.M. and Rubin, </author> <title> D.B. (1977) Maximum likelihood from incomplete data via the EM algorithm (with discussion). </title> <journal> J. Royal Statist. Soc. (Ser. </journal> <volume> B) 39, </volume> <pages> 1-38. </pages>
Reference: <author> Diebolt, J. and Ip, E.H.S. </author> <title> (1996) Stochastic EM: method and application. In: Markov chain Monte-Carlo in Practice (Ed. </title> <address> W.R. Gilks, S.T. </address>
Reference: <author> Richardson and D.J. </author> <month> Spiegelhalter), </month> <pages> 259-274. </pages> <publisher> Chapman and Hall, Lon-don. </publisher>
Reference: <author> Diebolt, J. and Robert, </author> <title> C.P. (1993) Discussion of "Bayesian computations via the Gibbs sampler" by A.F.M. </title> <editor> Smith and G. </editor> <title> Roberts. </title> <journal> J. Royal Statist. Soc. (Ser. </journal> <volume> B) 55(1), </volume> <pages> 71-72. </pages>
Reference: <author> Diebolt, J. and Robert, </author> <title> C.P. (1994) Estimation of finite mixture distributions by Bayesian sampling. </title> <journal> J. Royal Statist. Soc. (Ser. B), </journal> <volume> 56, </volume> <pages> 363-375. </pages>
Reference-contexts: highly multimodal surface which usually hinders the implementation of standard optimization methods. * The posterior distributions allow for closed forms expressions (under con-jugacy) but the combinatorial explosion (in the sample size n) of the likelihood L (jx), which involves k n terms, prevents the computation of posterior expressions in practice <ref> (Diebolt and Robert, 1994) </ref>. Some of these issues have been addressed by Mengersen and Robert (1996) who propose a reparameterisation of location-scale mixtures to overcome the difficulties with an improper prior modelling.
Reference: <editor> D'Epifanio, G. (1989) Un approccio all'inferenza basato sulla ricerca di un punto fisso. </editor> <volume> Metron 47, </volume> <pages> 1-4. </pages>
Reference: <author> Gamerman, D. </author> <title> (1997) Markov Chain Monte Carlo. </title> <publisher> Chapman and Hall, London. </publisher>
Reference: <author> Gelfand, A.E. and Smith, A.F.M. </author> <title> (1990) Sampling based approaches to calculating marginal densities. </title> <journal> J. Amer. Statist. Assoc. </journal> <volume> 85, </volume> <pages> 398-409. </pages>
Reference: <author> Gelman, A., Gilks, W.R. and Roberts, </author> <title> G.O. (1996) Efficient Metropolis jumping rules. In: Bayesian Statistics 5, J.O. </title> <editor> Berger, J.M. Bernardo, A.P. Dawid, D.V. Lindley and A.F.M. Smith (Eds.). </editor> <publisher> Oxford University Press, Oxford, </publisher> <pages> 599-608. </pages>
Reference: <author> Geyer, C.J. </author> <title> (1996) Estimation and optimization of functions. In: Markov chain Monte-Carlo in Practice (Ed. W.R. Gilks, S.T. Richardson and D.J. </title> <booktitle> Spiegelhalter), </booktitle> <pages> 241-258. </pages> <publisher> Chapman and Hall, London. </publisher>
Reference: <author> Geyer, C.J. and Thompson, </author> <title> E.A. (1992) Constrained Monte Carlo maximum likelihood for dependent data (with discussion). </title> <journal> J. Royal Statist. Soc. (Ser. </journal> <volume> B) 54, </volume> <pages> 657-699. </pages>
Reference: <author> Geyer, C.J. and Thompson, </author> <title> E.A. (1995) Annealing Markov Chain Monte Carlo with Applications to Ancestral Inference. </title> <journal> J. Amer. Statist. Assoc. </journal> <volume> 90, </volume> <pages> 909-920. </pages>
Reference: <author> Ghosh, J. </author> <title> (1996) A new graphical tool to detect non normality. </title> <journal> J. Royal Statist. Soc. (Ser. </journal> <volume> B) 58, </volume> <pages> 691-702. </pages>
Reference: <author> Gilks, W.R., Richardson, S. and Spiegelhalter, D.I. </author> <title> (1996) Markov Chain Monte Carlo in Practice. </title> <publisher> Chapman and Hall, London. </publisher>
Reference: <author> Goffinet, B., Loisel, P. and Laurent, B. </author> <title> (1992) Testing in normal mixture models when the proportions are known. </title> <journal> Biometrika 79, </journal> <pages> 842-846. </pages>
Reference: <author> Gouri eroux, C. and Monfort, A. </author> <title> (1996) Simulation based Methods in Econometrics. </title> <publisher> Oxford University Press, Oxford. </publisher>
Reference: <author> Gruet, M.A., Philippe, A., and Robert, </author> <title> C.P. (1998) MCMC control spreadsheets for exponential mixture estimation. </title> <type> Doc. </type> <institution> Travail CREST, INSEE. Hamilton, </institution> <month> J.D </month> <year> (1989), </year> <title> A new approach to the economic analysis of nonstationary time series and the business cycle, </title> <journal> Econometrica, </journal> <volume> 57(2), </volume> <pages> 357-384. </pages>
Reference: <author> Izenman, A.J. and Sommer, C.J. </author> <title> (1988) Philatelic mixtures and multimodal densities. </title> <journal> J. Amer. Statist. Assoc. </journal> <volume> 83, </volume> <pages> 941-953. </pages>
Reference: <author> Jaquier, E., Polson, N.G. and Rossi, P.E. </author> <title> (1994) Bayesian analysis of stochastic volatility models (with discussion). </title> <journal> J. Business Economic Stat. </journal> <volume> 12, </volume> <pages> 371-417. </pages>
Reference: <author> Laroque, G. and Salani e, B. </author> <title> (1993) Simulation based estimation of models with lagged latent variables. </title> <editor> J. </editor> <booktitle> Applied Econometrics 8, </booktitle> <pages> 119-133. </pages>
Reference: <author> Lavielle, M. and Moulines, E. </author> <title> (1997) On a stochastic approximation version of the EM algorithm. </title> <journal> Statist. Comput. </journal> <volume> 7(4), </volume> <pages> 229-236. </pages>
Reference: <author> Lindsay, B.G. </author> <title> (1995) Mixture models: Theory, Geometry and Applications. </title> <type> IMS Monographs, Hayward, </type> <institution> California. </institution>
Reference: <author> Liu, J.S., Wong, W.H. and Kong, A. </author> <title> (1994) Covariance structure of the Gibbs sampler with applications to the comparisons of estimators and sampling schemes. </title> <journal> Biometrika 81, </journal> <pages> 27-40. </pages>
Reference: <author> Mengersen, K.L. and Robert, </author> <title> C.P. (1996) Testing for mixtures: a Bayesian entropic approach (with discussion). In: Bayesian Statistics 5, J.O. </title> <editor> Berger, J.M. Bernardo, A.P. Dawid, D.V. Lindley and A.F.M. Smith (Eds.). </editor> <publisher> Oxford University Press, Oxford, </publisher> <pages> 255-276. </pages>
Reference: <author> Mengersen, K.L., Robert, C.P., and Guihenneuc-Jouyaux, C. </author> <title> (1998) MCMC Convergence Diagnostics: a Reviewww (with discussion). In: Bayesian Statistics 6, J.O. </title> <editor> Berger, J.M. Bernardo, A.P. Dawid, D.V. Lindley and A.F.M. Smith (Eds.). </editor> <publisher> Oxford University Press, Oxford (to appear). </publisher>
Reference: <author> Meyn, S.P. and Tweedie, </author> <title> R.L. (1994) Computable bounds for convergence rates of Markov chains. </title> <journal> Ann. Appl. Probab. </journal> <volume> 4, </volume> <pages> 981-1011. </pages>
Reference: <author> Muri, F. </author> <title> (1998) Modelling bacterial genome using hidden Markov models. </title> <booktitle> In: COMPSTAT 98 Proceedings in Computational Statistics. </booktitle> <address> Heidelberg: </address> <publisher> Physica-Verlag. </publisher>
Reference-contexts: Markov model for the Old Faithful geyser dataset and 2; 500 Gibbs iterations for each prior feedback iteration. (Source: Robert and Titterington, 1998.) 4 Switching ARMA models Another step in the extension of mixture models is to create an additional dependency in the observed variables, either as another Markov chain <ref> (see Muri, 1998) </ref> or in an ARMA structure, y t = fl + i=1 q X j * tj ; (9) which depends on a latent state Markov chain s t 2 f0; 1; : : :; M g: y t = fl s t + i=1 i (y ti fl
Reference: <author> Philippe, A. </author> <title> (1997) Processing simulation output by Riemann sums. </title> <journal> J. Statist. Comput. Simul. </journal> <volume> 59(4), </volume> <pages> 295-314. </pages>
Reference: <author> Philippe, A. and Robert, </author> <title> C.P. (1998) Riemann sums for MCMC estimation and control. </title> <type> Tech. Report, </type> <institution> Univ. Rouen. </institution>
Reference-contexts: only works well in dimension 1, is a mix of numerical analysis and Monte Carlo methods, either in its original form, ^ T = t=2 z (t) z (t1) h (z (t) )f (z (t) ) ; z (1) : : : z (T) ; or in its Rao-Blackwellised version <ref> (Philippe and Robert, 1998) </ref>, ^ T = T t=2 T X g (z (t) jy u ) : Moreover, this approximation technique doubles as a control variate device, since, when T goes to infinity, ~ T = T t=2 T X g (z (t) jy u ) goes to 1, for
Reference: <author> Pincus, M. </author> <title> (1968) A closed form solution of certain programming problems. </title> <journal> Oper. Research 18, </journal> <pages> 1225-1228. </pages>
Reference: <author> Richardson, S. and Green, P. </author> <title> (1997) On Bayesian Analysis of Mixtures with an unknown Number of Components (with discussion). </title> <journal> J. Royal Statist. Soc. (Ser. </journal> <volume> B) 59, </volume> <pages> 731-792 Robert, </pages> <editor> C.P. </editor> <title> (1993) Prior Feedback: A Bayesian approach to maximum likelihood estimation. </title> <journal> Comput. Statist. </journal> <volume> 8, </volume> <pages> 279-294. </pages>
Reference-contexts: Note also that the reparameterisation is perfectly fitted for reversible jump MCMC techniques, as in Robert (1997) and Gruet, Philippe and Robert (1998), since the other components are not modified by the so-called split and merge moves <ref> (see Richardson and Green, 1997) </ref>. Fig. 2.
Reference: <author> Robert, </author> <title> C.P. (1996) Inference in mixture models. In: Markov Chain Monte Carlo in Practice, </title> <editor> W.R. Gilks, S. Richardson and D.J. Spiegelhalter (Eds.), </editor> <address> 441-464. </address> <publisher> Chapman and Hall, London. </publisher>
Reference: <author> Robert, </author> <title> C.P. (1997) Discussion of "On Bayesian Analysis of Mixtures with an unknown Number of Components" by S. Richardson and P. Green (1997), </title> <journal> J. Royal Statist. Soc. (Ser. </journal> <volume> B) 59, </volume> <pages> 758-764. </pages>
Reference: <author> Robert, C.P. and Casella, G. </author> <title> (1998) Monte Carlo Statistical Methods. </title> <publisher> Springer Verlag, </publisher> <address> New York (to appear). </address>
Reference-contexts: Poisson mixtures, q 1 P (t 1 ) + (1 q 1 )q 2 P (t 1 t 2 ) + : : : ; also authorise the use of (7) <ref> (see Robert and Titterington, 1998) </ref>. <p> Comparisons with implementations based on the EM algorithm (Chib, 1996) lead to different estimates in the Poisson case, thus pointing out that the EM algorithm has converged to a local maxima of the likelihood function <ref> (see Robert and Titterington, 1998) </ref>. Fig. 4. <p> derived from (z (t) ) as (t) ~ (jz (t) ) : In such cases, as noted in Diebolt and Robert (1993,1994), the probabilis tic properties of (z (t) ) transfer to the chain ( (t) ). (They call this transfer the Duality Principle.) For instance, the following results apply <ref> (see Robert, 1998, for details) </ref>: * If (z (t) ) is ergodic with stationary distribution ~ f (respectively geomet rically ergodic with rate %), ( (t) ) is ergodic (geometrically ergodic with rate %) for every (jz) and its stationary distribution is ~() = (jz) ~ f (z)dz: Fig. 7. <p> only works well in dimension 1, is a mix of numerical analysis and Monte Carlo methods, either in its original form, ^ T = t=2 z (t) z (t1) h (z (t) )f (z (t) ) ; z (1) : : : z (T) ; or in its Rao-Blackwellised version <ref> (Philippe and Robert, 1998) </ref>, ^ T = T t=2 T X g (z (t) jy u ) : Moreover, this approximation technique doubles as a control variate device, since, when T goes to infinity, ~ T = T t=2 T X g (z (t) jy u ) goes to 1, for
Reference: <author> Robert, </author> <title> C.P. and Mengersen, K.L. (1995) Reparametrization issues in mixture estimation and their bearings on the Gibbs sampler. Doc. </title> <type> travail 9538, </type> <institution> CREST, Insee, Paris. </institution>
Reference: <author> Robert, C.P., Ryd en, T. and Titterington, </author> <title> D.M. (1998) Convergence controls for MCMC algorithms, with applications to hidden Markov chains. </title> <type> Tech. Report 98-2, Uni. </type> <institution> of Glasgow. </institution>
Reference-contexts: Poisson mixtures, q 1 P (t 1 ) + (1 q 1 )q 2 P (t 1 t 2 ) + : : : ; also authorise the use of (7) <ref> (see Robert and Titterington, 1998) </ref>. <p> Comparisons with implementations based on the EM algorithm (Chib, 1996) lead to different estimates in the Poisson case, thus pointing out that the EM algorithm has converged to a local maxima of the likelihood function <ref> (see Robert and Titterington, 1998) </ref>. Fig. 4. <p> derived from (z (t) ) as (t) ~ (jz (t) ) : In such cases, as noted in Diebolt and Robert (1993,1994), the probabilis tic properties of (z (t) ) transfer to the chain ( (t) ). (They call this transfer the Duality Principle.) For instance, the following results apply <ref> (see Robert, 1998, for details) </ref>: * If (z (t) ) is ergodic with stationary distribution ~ f (respectively geomet rically ergodic with rate %), ( (t) ) is ergodic (geometrically ergodic with rate %) for every (jz) and its stationary distribution is ~() = (jz) ~ f (z)dz: Fig. 7. <p> only works well in dimension 1, is a mix of numerical analysis and Monte Carlo methods, either in its original form, ^ T = t=2 z (t) z (t1) h (z (t) )f (z (t) ) ; z (1) : : : z (T) ; or in its Rao-Blackwellised version <ref> (Philippe and Robert, 1998) </ref>, ^ T = T t=2 T X g (z (t) jy u ) : Moreover, this approximation technique doubles as a control variate device, since, when T goes to infinity, ~ T = T t=2 T X g (z (t) jy u ) goes to 1, for
Reference: <author> Robert, C.P. and Titterington, M. </author> <title> (1998) Resampling schemes for hidden Markov models and their application for maximum likelihood estimation. </title> <journal> Statist. Comput. </journal> <note> (to appear). </note>
Reference-contexts: Poisson mixtures, q 1 P (t 1 ) + (1 q 1 )q 2 P (t 1 t 2 ) + : : : ; also authorise the use of (7) <ref> (see Robert and Titterington, 1998) </ref>. <p> Comparisons with implementations based on the EM algorithm (Chib, 1996) lead to different estimates in the Poisson case, thus pointing out that the EM algorithm has converged to a local maxima of the likelihood function <ref> (see Robert and Titterington, 1998) </ref>. Fig. 4. <p> derived from (z (t) ) as (t) ~ (jz (t) ) : In such cases, as noted in Diebolt and Robert (1993,1994), the probabilis tic properties of (z (t) ) transfer to the chain ( (t) ). (They call this transfer the Duality Principle.) For instance, the following results apply <ref> (see Robert, 1998, for details) </ref>: * If (z (t) ) is ergodic with stationary distribution ~ f (respectively geomet rically ergodic with rate %), ( (t) ) is ergodic (geometrically ergodic with rate %) for every (jz) and its stationary distribution is ~() = (jz) ~ f (z)dz: Fig. 7. <p> only works well in dimension 1, is a mix of numerical analysis and Monte Carlo methods, either in its original form, ^ T = t=2 z (t) z (t1) h (z (t) )f (z (t) ) ; z (1) : : : z (T) ; or in its Rao-Blackwellised version <ref> (Philippe and Robert, 1998) </ref>, ^ T = T t=2 T X g (z (t) jy u ) : Moreover, this approximation technique doubles as a control variate device, since, when T goes to infinity, ~ T = T t=2 T X g (z (t) jy u ) goes to 1, for
Reference: <author> Roberts, G.O. and Rosenthal, J.S. </author> <title> (1997) Markov chain Monte Carlo: some practical implications of theoretical results. </title> <type> Tech. Report, </type> <institution> Stats. </institution>
Reference: <institution> Lab., U. of Cambridge. </institution>
Reference: <author> Rubinstein, R.Y. </author> <title> (1981) Simulation and the Monte Carlo Method. </title> <editor> J. Wi-ley, </editor> <address> New York. </address>
Reference: <author> Shephard, N. and Pitt, </author> <title> M.K. (1997) Likelihood analysis of non-Gaussian measurement time series. </title> <journal> Biometrika 84, </journal> <pages> 183-204. </pages>
Reference: <author> Smith, A.F.M. and Roberts, </author> <title> G.O. (1993) Bayesian computation via the Gibbs sampler and related Markov chain Monte Carlo methods (with discussion). </title> <journal> J. Royal Statist. Soc. (Ser. </journal> <volume> B) 55, </volume> <pages> 3-24. </pages>
Reference: <author> Tanner, M. and Wong, W. </author> <title> (1987) The calculation of posterior distributions by data augmentation. </title> <journal> J. Amer. Statist. Assoc. </journal> <volume> 82, </volume> <pages> 528-550. </pages>
Reference-contexts: As shown in the previous examples, it often occurs, though, that latent variable models produce two chains (z (t) ) and ( (t) ), which are in duality, either in the strong sense of Data Augmentation <ref> (Tanner and Wong, 1987, Liu, Wong and Kong, 1994) </ref>, or in the weaker sense that ( (t) ) is derived from (z (t) ) as (t) ~ (jz (t) ) : In such cases, as noted in Diebolt and Robert (1993,1994), the probabilis tic properties of (z (t) ) transfer to
Reference: <author> Tierney, L. </author> <title> (1994) Markov chains for exploring posterior distributions (with discussion). </title> <journal> Ann. Statist. </journal> <volume> 22, </volume> <pages> 1701-1786. </pages>
Reference: <author> Titterington, D.M., Smith, A.F.M. and Makov, U.E. </author> <title> (1985) Statis--tical Analysis of Finite Mixture Distributions. </title> <editor> J. </editor> <publisher> Wiley, </publisher> <address> New York. </address>
Reference: <author> Wei, G.C.G. and Tanner, M.A. </author> <title> (1990) A Monte Carlo implementation of the EM algorithm and the poor man's data augmentation algorithm. </title>
Reference: <author> J. </author> <title> Amer. </title> <journal> Statist. Assoc. </journal> <volume> 85, </volume> <pages> 699-704. </pages>
References-found: 59

