URL: http://vis-www.cs.umass.edu/vislib/Text/manmatha/eccv94.ps.gz
Refering-URL: http://vis-www.cs.umass.edu/vislib/Text/manmatha/files.html
Root-URL: 
Email: manmatha@cs.umass.edu  
Title: Measuring the Affine Transform Using Gaussian Filters  
Author: R. Manmatha 
Address: Amherst, MA-01003.  
Affiliation: Computer Science Department, University of Massachusetts,  
Abstract: Image deformations due to relative motion between an observer and an object may be used to infer 3-D structure. Up to first order these deformations can be written in terms of an affine transform. Here, a novel approach is adopted to measuring affine transforms which correctly handles the problem of corresponding deformed patches. The patches are filtered using gaussians and derivatives of gaussians. The problem of finding the affine transform is reduced to that of finding the appropriate deformed filter to use. The method is local and can handle arbitrarily large affine deformations. Experiments demonstrate that this technique can find scale changes and optical flow in situations where other methods fail.
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> J.R. Bergen, P. Anandan, K. J. Hanna, and R. Hingorani. </author> <title> Hierarchical model-based motion estimation. </title> <booktitle> In Proc. 2nd European Conference on Computer Vision, </booktitle> <pages> pages 237-252, </pages> <year> 1992. </year>
Reference-contexts: The equation clearly shows that to recover affine transforms by filtering, one must deform the filter appropriately; a point ignored in previous work <ref> [1, 2, 6, 3] </ref>. The equation is local because the gaussians rapidly decay.
Reference: 2. <author> M. Campani and A. Verri. </author> <title> Motion analysis from optical flow. </title> <booktitle> Computer Vision Graphics and Image Processing:Image Understanding, </booktitle> <volume> 56(12) </volume> <pages> 90-107, </pages> <year> 1992. </year>
Reference-contexts: The equation clearly shows that to recover affine transforms by filtering, one must deform the filter appropriately; a point ignored in previous work <ref> [1, 2, 6, 3] </ref>. The equation is local because the gaussians rapidly decay.
Reference: 3. <author> D. G. Jones and J. Malik. </author> <title> A computational framework for determining stereo correspondence from a set of linear spatial filters. </title> <booktitle> In Proc. 2nd European Conference on Computer Vision, </booktitle> <pages> pages 395-410, </pages> <year> 1992. </year>
Reference-contexts: The equation clearly shows that to recover affine transforms by filtering, one must deform the filter appropriately; a point ignored in previous work <ref> [1, 2, 6, 3] </ref>. The equation is local because the gaussians rapidly decay.
Reference: 4. <author> R. Manmatha. </author> <title> Image matching under affine deformations. In Invited Paper, </title> <booktitle> Proc. of the 27nd Asilomar IEEE Conf. on Signals, Systems and Computers,, </booktitle> <year> 1993. </year>
Reference-contexts: Large scales are handled as before. t 0 is obtained either by a local search or from a coarser level in a pyramid scheme, while ffit is estimated from the equation (see <ref> [4] </ref> for details). Note that since the gaussians are rotation invariant, the translation can be recovered for arbitrary rotations about an axis perpendicular to the image. <p> Fig. 2. Random Dot Sequence Figure (1) shows a dollar bill scaled by 1.4. The algorithm correctly recovers the scale as 1.41. Other experiments with scaled and rotated versions of the dollar bill consistently show good recovery of scale within a few percent. For other examples see <ref> [4] </ref>. 4 Solving for the General Affine The strategy adopted will be to first sample the space of scales and orientations to derive a finite set of filters.
Reference: 5. <author> R. Manmatha and J. Oliensis. </author> <title> Measuring the affine transform i: Scale and rotation. </title> <note> Technical Report Technical Report CMPSCI TR 92-74,University of Mas-sachusetts at Amherst,MA,1992. Also in Proc. of the Darpa Image Understanding Workshop 1993. </note>
Reference-contexts: Deformations can be used to infer local surface geometry and depth from motion. Since a repeating texture pattern can be thought of as a pattern in motion, shape from texture can also be derived from deformations <ref> [5] </ref>. <p> The affine transform is useful because the image projections of a small planar patch from different viewpoints are well approximated by it <ref> [5] </ref>. In Figure (1) the image on the right is scaled 1.4 times the image on the left. Even if the centroids of the two image patches are matched accurately, measuring the affine transform is difficult since the sizes of every portion of the two images differ. <p> For example, Werkhoven and Koenderink's algorithm [6] when run on the images in Figure (1) returns a scale factor of 1.16 while our algorithm does the matching correctly and therefore returns a scale factor of 1.41. For a review of related work see <ref> [5] </ref>. Fig. 1. Dollar Bill scaled 1.4 times 2 Deformation of Filters The initial discussion will assume zero image translation; translation can be recovered as suggested in section 3. It is also assumed that shading and illumination effects can be ignored. <p> Then it may be shown that the output of F 1 filtered with a gaussian is equal to the output of F 2 filtered with a gaussian deformed by the affine transform (see <ref> [5] </ref> for details) i.e. Z Z where the integrals are taken from 1 to 1. <p> Similar equations may be written using derivative of gaussian filters (for details see <ref> [5] </ref>). 3 Solution for the Case of Similarity Transforms To solve (6) requires finding a gaussian of the appropriate scale s given . A brute force search through the space of scale changes is not desirable. Instead a more elegant solution is to linearize the gaussians with respect to . <p> No other scheme is able to do this. 3.1 Experimental Results Experiments on synthetic images show that the affine transform can be recovered to within a few percent (see <ref> [5] </ref>). Figure (2) illustrates the power of this algorithm. A random dot image is scaled by a factor of 1.1 and rotated around an axis perpendicular to the image by 30 deg. On the left is the flow produced by an SSD based pyramid scheme.
Reference: 6. <author> P. Werkhoven and J. J. Koenderinck. </author> <title> Extraction of motion parallax structure in the visual system 1. </title> <journal> Biological Cybernetics, </journal> <year> 1990. </year> <title> This article was processed using the L a T E X macro package with LLNCS style </title>
Reference-contexts: This allows the linearization point to be moved so that arbitrary affine transforms can be solved unlike traditional methods restricted to small affines. The method is local, applicable to arbitrary dimensions and can measure affine transforms in situations where other algorithms fail. For example, Werkhoven and Koenderink's algorithm <ref> [6] </ref> when run on the images in Figure (1) returns a scale factor of 1.16 while our algorithm does the matching correctly and therefore returns a scale factor of 1.41. For a review of related work see [5]. Fig. 1. <p> The equation clearly shows that to recover affine transforms by filtering, one must deform the filter appropriately; a point ignored in previous work <ref> [1, 2, 6, 3] </ref>. The equation is local because the gaussians rapidly decay.
References-found: 6

