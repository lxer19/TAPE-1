URL: http://polaris.cs.uiuc.edu/reports/1418.ps.gz
Refering-URL: http://polaris.cs.uiuc.edu/tech_reports.html
Root-URL: http://www.cs.uiuc.edu
Email: gallivan@csrd.uiuc.edu  srikanth@csrd.uiuc.edu  vandooren@anma.ucl.ac.be  
Title: A BLOCK TOEPLITZ LOOK-AHEAD SCHUR ALGORITHM  
Author: KYLE GALLIVAN SRIKANTH THIRUMALAI PAUL VAN DOOREN Cesame 
Keyword: Block Toeplitz matrix, Schur algorithm, numerical methods, look-ahead.  
Address: Urbana, IL USA  Urbana, IL USA  Louvain-la-Neuve Belgium  
Affiliation: Coordinated Science Laboratory University of Illinois  Coordinated Science Laboratory University of Illinois  Universite Catholique de Louvain  
Abstract: This paper gives a look-ahead Schur algorithm for finding the symmetric factorization of a Hermitian block Toeplitz matrix. The method is based on matrix operations and does not require any relations with orthogonal polynomials. The simplicity of the matrix based approach ought to shed new light on other issues such as parallelism and numerical stability. 1 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Bojanczyk, R. Brent, F. de Hoog and D. Sweet. </author> <title> On the Stability of the Bareiss and Related Toeplitz Factorization Algorithms SIAM J. </title> <note> Matrix Anal. Appl. 15, pp , 1994. </note>
Reference-contexts: grain parallelism [9], (ii) it constructs the factor U in (1) directly, rather than its inverse as in the Levinson algorithm [8], (iii) it exploits better matrix properties such as bandedness and low rank [5] and (iv) it has been shown to have better numerical properties for positive definite T <ref> [1] </ref>. Both algorithms, though, are known to be potentially unstable when T is indefinite. This is the case when the leading principal minors of T are (nearly) singular, since both algorithms implicitly use these submatrices in their recurrence.
Reference: [2] <author> T. Chan and P.C. Hansen. </author> <title> A look-ahead Levinson algorithm for indefinite Toeplitz systems. </title> <journal> SIAM J. Matrix Anal. Appl. </journal> <volume> 13, </volume> <pages> pp 490-506, </pages> <year> 1992. </year>
Reference-contexts: This is the case when the leading principal minors of T are (nearly) singular, since both algorithms implicitly use these submatrices in their recurrence. Remedies for this were proposed for the Schur algorithm [11] and for the Levinson algorithm <ref> [2] </ref> and were essentially based on a look-ahead technique, whereby one "jumps" over the singular submatrices. Although this requires a slight increase in complexity, this is in general quite an effective technique. <p> It does not describe how to construct the transformation H nor how to track the condition number of T 11 . For the latter we refer to techniques as those described in <ref> [2; 6; 3] </ref>. For the construction of the -unitary transformations H we can use skew Householder transformations of block versions of them (see [4]). In [4] issues of efficient parallel implementation of such transformations are also adressed.
Reference: [3] <author> R. Freund and H. Zha. </author> <title> Formally biorthogonal polynomials and a look-ahead Levinson algorithm for general Toeplitz systems. </title> <booktitle> Linear Algebra and its Applications 188-189, </booktitle> <pages> pp 255-303, </pages> <year> 1993. </year>
Reference-contexts: Although this requires a slight increase in complexity, this is in general quite an effective technique. These techniques are linked to the theory of orthogonal polynomials and can become quite involved in the case of look-ahead [6], <ref> [3] </ref>. In this paper we present a matrix based derivation of such a look-ahead method and give the algorithm directly for block Toeplitz matrices. <p> It does not describe how to construct the transformation H nor how to track the condition number of T 11 . For the latter we refer to techniques as those described in <ref> [2; 6; 3] </ref>. For the construction of the -unitary transformations H we can use skew Householder transformations of block versions of them (see [4]). In [4] issues of efficient parallel implementation of such transformations are also adressed.
Reference: [4] <author> K. Gallivan, S. Thirumalai and P. Van Dooren. </author> <title> On solving block Toeplitz systems using a block Schur algorithm. </title> <booktitle> in Intern. Conf. Parallel Processing, Proc. </booktitle> <address> ICPP-94, St. Charles IL, </address> <note> pp III-274-III-281, </note> <year> 1994. </year>
Reference-contexts: For the latter we refer to techniques as those described in [2; 6; 3]. For the construction of the -unitary transformations H we can use skew Householder transformations of block versions of them (see <ref> [4] </ref>). In [4] issues of efficient parallel implementation of such transformations are also adressed. We point out that when T 11 is well conditioned then the transformation H and its construction should give no numerical problems. <p> For the latter we refer to techniques as those described in [2; 6; 3]. For the construction of the -unitary transformations H we can use skew Householder transformations of block versions of them (see <ref> [4] </ref>). In [4] issues of efficient parallel implementation of such transformations are also adressed. We point out that when T 11 is well conditioned then the transformation H and its construction should give no numerical problems.
Reference: [5] <author> K. Gallivan, S. Thirumalai and P. Van Dooren. </author> <title> Regularization Teoplitz least squares problems. </title> <booktitle> Int. Rept. CSL, </booktitle> <institution> Univ. Illinois at Urbana-Champaign, </institution> <year> 1994. </year>
Reference-contexts: Levinson algorithm for various reasons : (i) it is known to be better suited for fine grain parallelism [9], (ii) it constructs the factor U in (1) directly, rather than its inverse as in the Levinson algorithm [8], (iii) it exploits better matrix properties such as bandedness and low rank <ref> [5] </ref> and (iv) it has been shown to have better numerical properties for positive definite T [1]. Both algorithms, though, are known to be potentially unstable when T is indefinite.
Reference: [6] <author> M. Gutknecht. </author> <title> Stable row recurrences for the Pade table and generically superfast look-ahead solvers for non-Hermitian Toeplitz systems. </title> <booktitle> Linear Algebra and its Applications 188-189, </booktitle> <pages> pp 351-421, </pages> <year> 1993. </year>
Reference-contexts: Although this requires a slight increase in complexity, this is in general quite an effective technique. These techniques are linked to the theory of orthogonal polynomials and can become quite involved in the case of look-ahead <ref> [6] </ref>, [3]. In this paper we present a matrix based derivation of such a look-ahead method and give the algorithm directly for block Toeplitz matrices. <p> It does not describe how to construct the transformation H nor how to track the condition number of T 11 . For the latter we refer to techniques as those described in <ref> [2; 6; 3] </ref>. For the construction of the -unitary transformations H we can use skew Householder transformations of block versions of them (see [4]). In [4] issues of efficient parallel implementation of such transformations are also adressed.
Reference: [7] <author> T. Kailath and A. Sayed. </author> <title> Fast algorithms for generalized displacement structrures. </title> <booktitle> in Recent Advances in Mathematical Theory of Systems (H. </booktitle> <editor> Kimura, S. Kodoma, Eds.), </editor> <booktitle> Proc. MTNS-91, </booktitle> <pages> pp 27-32, </pages> <year> 1992. </year>
Reference-contexts: We now derive updating formulas for the Schur complement of a matrix T with low displacement rank, and show that it also has low displacement rank. This part is related to the work of <ref> [7] </ref> as was pointed out to us, but is not contained in it. <p> Finally, notice also that the results presented in this paper can be extended to the non Hermitian case, provided two generator are kept and updated instead of one. For simplicity, we did not develop this here. Acknowledgments We are indebted to V. Olshevsky for pointing out reference <ref> [7] </ref> to us. This research was supported by the National Science Foundation under Grants CCR 9209349 and CCR9120008 and by ARPA under Grant 60NANB2D1272 7
Reference: [8] <author> T. Kailath, A. Vieira and M. Morf. </author> <title> Inverses of Toeplitz operators, innovations and orthogonal polynomials. </title> <journal> SIAM Review 20, </journal> <pages> pp 106-119, </pages> <year> 1978. </year>
Reference-contexts: Also available as CSRD Report Number 1418. 2 in O (n 2 ) operations <ref> [8] </ref>. This algorithm actually derives this decomposition for all leading principal submatrices as well via a simple vector recurrence, which explains the low complexity of the method. Another well known algorithm for the same problem is the Levinson algorithm [10]. <p> Yet, the Schur algorithm has gained a lot of popularity over the Levinson algorithm for various reasons : (i) it is known to be better suited for fine grain parallelism [9], (ii) it constructs the factor U in (1) directly, rather than its inverse as in the Levinson algorithm <ref> [8] </ref>, (iii) it exploits better matrix properties such as bandedness and low rank [5] and (iv) it has been shown to have better numerical properties for positive definite T [1]. Both algorithms, though, are known to be potentially unstable when T is indefinite.
Reference: [9] <author> S.-Y. Kung and Y. Hu. </author> <title> A highly concurrent algorithm and pipelined architecture for solving Toplitz systems. </title> <journal> IEEE Trans. ASSP 31, </journal> <pages> pp 66-76, </pages> <year> 1983. </year>
Reference-contexts: Another well known algorithm for the same problem is the Levinson algorithm [10]. Yet, the Schur algorithm has gained a lot of popularity over the Levinson algorithm for various reasons : (i) it is known to be better suited for fine grain parallelism <ref> [9] </ref>, (ii) it constructs the factor U in (1) directly, rather than its inverse as in the Levinson algorithm [8], (iii) it exploits better matrix properties such as bandedness and low rank [5] and (iv) it has been shown to have better numerical properties for positive definite T [1].
Reference: [10] <author> N. Levinson. </author> <title> The Wiener RMS (root-mean-square) error criterion in filter design and prediction. </title> <journal> J. Math. Phys. </journal> <volume> 25, </volume> <pages> pp 261-278, </pages> <year> 1947. </year>
Reference-contexts: This algorithm actually derives this decomposition for all leading principal submatrices as well via a simple vector recurrence, which explains the low complexity of the method. Another well known algorithm for the same problem is the Levinson algorithm <ref> [10] </ref>.
Reference: [11] <author> D. R. Sweet. </author> <title> The use of pivoting to improve the numerical performance of Toeplitz solvers. in Advanced Algorithms and Architectures for Signal Processing (J.M. Speiser, </title> <editor> Ed.), </editor> <booktitle> Proc. SPIE 696, </booktitle> <pages> pp 8-18, </pages> <year> 1986. </year>
Reference-contexts: Both algorithms, though, are known to be potentially unstable when T is indefinite. This is the case when the leading principal minors of T are (nearly) singular, since both algorithms implicitly use these submatrices in their recurrence. Remedies for this were proposed for the Schur algorithm <ref> [11] </ref> and for the Levinson algorithm [2] and were essentially based on a look-ahead technique, whereby one "jumps" over the singular submatrices. Although this requires a slight increase in complexity, this is in general quite an effective technique.
References-found: 11

