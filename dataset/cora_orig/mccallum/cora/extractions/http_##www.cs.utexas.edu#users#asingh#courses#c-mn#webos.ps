URL: http://www.cs.utexas.edu/users/asingh/courses/c-mn/webos.ps
Refering-URL: http://www.cs.utexas.edu/users/asingh/courses/c-mn/http.html
Root-URL: 
Email: hasingh@cs.utexas.edui  hdheeraj@cs.utexas.edui  heugene@cs.utexas.edui  
Title: The Transport Layer Issues for HTTP  
Author: Amit Singh Dheeraj Pandey Eugene Gorbatov 
Date: May 12, 1998  
Abstract: In traditional operating systems network protocol stack is implemented in the kernel space and managed by network system software. User-level applications are restricted to the interfaces and implementations provided by the underlying operating system. While this organization presents all applications with a uniform view of the network, it is flawed because some application classes suffer from suboptimal performance. The focus of this paper is the design and implementation of a transport protocol whose mechanisms match the requirements of different application classes. To this end, we have implemented an extensible library in application address space that provides a transport layer for HTTP applications. The mechanisms used in the protocol are designed to match the "transactional" behavior of HTTP traffic. We have compared our design with existing approaches and obtained very encouraging results. We found that our protocol reduces access time of HTTP applications by 18%-48% when compared with PHTTP approach. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <institution> RFC 793: TCP </institution>
Reference-contexts: The focus of our project is the design and implementation of efficient transport layer. Transport layer provides end-to-end reliable delivery of data to applications. The current implementation of a transport layer protocol, TCP <ref> [1] </ref>, provides common reliable service to all application classes and controls their usage of the network. Since TCP is designed to meet realibility requirements of all application classes, its implementation supports a common reliability service: eventual, in-order delivery of all data on a unicast connection.
Reference: [2] <author> V. Padmanabhan and J. </author> <title> Mogul "Improving HTTP Latency" </title>
Reference-contexts: While all these mechanisms provide reliable, stable transport protocol, they may be very inefficient for applications that are not "common" in a sense assumed by TCP design. WWW is a very popular internet service that uses HTTP <ref> [2] </ref> protocol to distribute multimedia data to application users. HTTP is implemented on top of TCP protocol that provides it with ordered, realible delivery of its data. However, abstractions of TCP poorly match HTTP application class. HTTP connections are short lived and are characteized by request/response client-server type of communication. <p> In the presence of 3-way handshake kind of transactions, this latency deteriorates to 2 fl RT T + SP T , owing to the synchronization procedure of the handshake. Mogul <ref> [2] </ref> contends that the effects of the initial 3-way handshake would amortize across the length of the long connection. <p> We also compare TAO with the basic HTTP 1.0, the original protocol that was the baseline for Mogul too <ref> [2] </ref>. Keywords: SSR- Slow Start Restart, FC- Forced Closed, file- the bundle, the main (HTML) page and all the inline documents, page- a page would mean individually the main (HTML) page or any of the inline documents.
Reference: [3] <author> Deering, S., Estrin, D., Farinacci, D., Jacabson, V., Gung Liu, C., and Wei, L. </author> <title> "An Architecture for Wide Area Multicast Routing", </title> <booktitle> Proceedings of ACM SIGCOMM '94. </booktitle>
Reference-contexts: Multicasting data to a group of receivers is another example of a popular Internet service provided by IP Multicast protocol. Many applications that enjoy efficient delivery of data provided by IP multicast <ref> [3] </ref> also require this service to be reliable. Several researchers proposed to use sender-intiated TCP-like approach to provide this service [4]. However, as is the case for HTTP, abstractions of TCP poorly match this new application class. TCP uses sequence numbers as its application-independent address space.
Reference: [4] <author> D. Towsley, J. Kurose, S. Pingali, </author> <title> "A Comparison of Sender-Initiated and Receiver-Initiated Reliable Multicast Protocols," </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <month> April </month> <year> 1997. </year>
Reference-contexts: Many applications that enjoy efficient delivery of data provided by IP multicast [3] also require this service to be reliable. Several researchers proposed to use sender-intiated TCP-like approach to provide this service <ref> [4] </ref>. However, as is the case for HTTP, abstractions of TCP poorly match this new application class. TCP uses sequence numbers as its application-independent address space. This naming approach makes very little sense for new members that recently joined the group.
Reference: [5] <author> John Heidemann, </author> <title> "Performance Interactions Between P-HTTP & TCP Implementations", </title> <publisher> USC/ISI </publisher>
Reference-contexts: Section 3 deals with the experimental results, and Section 4 concludes the paper. 2 Background & Motivation The Slow-start restart problem The improvements envisaged in P-HTTP cannot be seen in isolation- these improvements inadvertently interact with the surrounding layers, the transport layer being one of them. Heidemann <ref> [5] </ref> has shown that interactions between P-HTTP and TCP have surprisingly produced exceedingly poor P-HTTP performance. He has attributed such observations to the short-initial-segment-problem and the odd/short-final-segment-problem. One of the other biggest problems relates to the way TCP handles congestion control. <p> The motivation for this algorithm was the observation that some applications such as SMTP and NNTP typically have a negotiation phase followed by a data transfer phase <ref> [5] </ref>. The negotiation phase can artificially open the congestion window; data transfer will then result in a burst of packets which can move the network out of equilibrium, potentially resulting in congestion or packet loss. The primary motivation behind this is congestion avoidance via packet conservation. <p> In the case of P-HTTP, we see this glaring fallacy very conspicuously: a result of reinitializing the congestion window is that, even without a packet loss, P-HTTP connections will frequently slow-start "mid stream" <ref> [5] </ref>. In fact, since users nearly always spend more than the retransmission timeout browsing a given page, P-HTTP will nearly always slow-start when the user follows a link.
Reference: [6] <author> Amy Hughes, Joe Touch, John Heidemann, </author> <title> "Issues in TCP Slow-Start Restart After Idle", </title> <publisher> USC/ISI </publisher>
Reference-contexts: The primary goal of P-HTTP is to avoid the cost of multiple connection setups and slow-starts; the interaction defeats much of the purpose of P-HTTP's optimizations. For TCP implementations that use send-window timers <ref> [6] </ref> to detect idle periods, this means P-HTTP always slow-starts. 3 The 3-way Handshake Problem TCP implements reliability using sequence numbers. Before data transfer can begin, both parties must "synchronize" the connection, i.e., agree on common sequence numbers. <p> For the network routers, it is indistinguishable whether the old connection sent a burst due to NSSR, or a new connection sent a burst due to slow-start bypass. An optimization over sending back-to-back network packets is rate-based pacing, proposed by Heidemann et al. <ref> [6] </ref>, in which a packet burst is paced at a particular predefined rate. This serves as a middle path between SSR and NSSR.
Reference: [7] <author> RFC 1379: </author> <title> Extending TCP For Transactions </title>
Reference-contexts: The synchronization procedure must preserve at-most-once semantics, i.e, be free from replay hazards due to duplicate packets. The TCP developers adopted a synchronization mechanism known as the 3-Way Handshake. Firstly, HTTP traffic are request-response pairs, which in literature are referred to as transactions. Braden <ref> [7] </ref> has argued that the minimum latency that a client can observe in a transaction is RT T + SP T , where RTT is the round-trip-time, and SPT is the server-processing-time. <p> With this, applications wouldn't have to worry too much about the number of "connections" they have opened across the network. The contributions of this paper are: * Using the concepts of Transaction-TCP <ref> [7] </ref> to avoid 3-way handshake and slow-start in new connections * Implementation of a user-level library that provides differential transport services to applica tions * Experimental evaluation that compares the persistent HTTP approach to the multiple con nections approach (Netscape). 3 Design & Implementation After we got convinced that the multiple <p> We called this kind of Web access as READ ONLY request from the client. For the rest of the 10% of Web accesses, which still required an at-most-once guarantee (e.g, CGI queries), we carried over the T-TCP approach proposed by Braden <ref> [7] </ref> in 1993, in which TCP has been modified to work better for transactions. The idea behind T-TCP (read "Transaction TCP") is to reduce the latency time from 2 fl RT T + SP T to RT T + SP T by avoiding the 3-way handshake for transactions. <p> If the CC value is larger than the cached value for this client, the TAO Test succeeds, and the transport layer immediately passes on the data to the application. If on the other hand, the test fails (for reasons, please refer to <ref> [7] </ref>), the transport layer resorts back to the 3-way handshake to confirm the freshness of this SYN packet. Therefore, the TAO test is an optional optimization over the conventional TCP.
Reference: [8] <author> H.Balakrishnan, V.Padmanabhan, S.Seshan, Mark Stemm & R.Katz, </author> <title> "TCP Behaviour Of a Busy Internet Server: Analysis & Improvements" </title>
Reference-contexts: Therefore, we have to look at other competing ways of making the Web faster. Hari et al. <ref> [8] </ref> observe that the persistent connection approach has a drawback that it is specifically tied to HTTP. This means that TCP connection initiated by other non-HTTP applications running on the same machine (such as FTP applications, Netscape plug-ins) would not be able to share the persistent connection with HTTP. <p> We are therefore converging to Netscape's approach to providing pipelining for HTTP transactions: multiple parallel connections to the server independently fetch data from the server, thus pipelining the requests from the client. While Hari et al. <ref> [8] </ref> have argued for kernel-level implementations to look into the problem, our extensibility argument convinces us to pull the transport services into a user-level library, which are tailor made for applications (according to their needs, semantics etc.). <p> The biggest advantage of having connection abstraction in the user space is that it makes them very light-weight. In contrast to Hari et al. <ref> [8] </ref>, who have proposed a kernel implementation, we feel that only a light-weight connection approach can save the day for multiple connection solution, since kernel resource requirements for them are going to be very expensive.
Reference: [9] <author> H.Balakrishnan, S.Seshan, Mark Stemm & R.Katz, </author> <title> "Analyzing Stability in Wide-Area Network Performance" 13 </title>
Reference-contexts: In our approach, multiple connections are going to have short lifetimes. Therefore, we have to look at other ways of bypassing the slow-start problem. 6 The approach to this problem lies in looking at the observation that Stemm et al <ref> [9] </ref> make about the temporal and spatial stability of network performance. Two key observations that they make in [9] are: Internet hosts that are close to each other often have almost identical distributions of throughput. More importantly, throughputs to individual hosts often do not change appreciably for several minutes. <p> Therefore, we have to look at other ways of bypassing the slow-start problem. 6 The approach to this problem lies in looking at the observation that Stemm et al <ref> [9] </ref> make about the temporal and spatial stability of network performance. Two key observations that they make in [9] are: Internet hosts that are close to each other often have almost identical distributions of throughput. More importantly, throughputs to individual hosts often do not change appreciably for several minutes. Consequently, the approach to caching can be extended to congestion windows as well. <p> The latter observation is only a space optimization for heavily-loaded servers that plan to keep the cache in-core, and surely, <ref> [9] </ref> shows that its a valid assumption. 3.3 The Cache Requirement: Is it prohibitory? We evaluated the cache size that an overloaded server would have to maintain to make this approach an effective tool to bypass the 3-way handshake and slow-start for a new connection.
References-found: 9

