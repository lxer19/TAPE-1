URL: http://www.cse.ogi.edu/~walidt/docs/publications/pepm97.ps
Refering-URL: http://www.cse.ogi.edu/~walidt/walidt.html
Root-URL: http://www.cse.ogi.edu
Email: fwalidt,sheardg@cse.ogi.edu  
Title: Multi-Stage Programming with Explicit Annotations  
Author: Walid Taha Tim Sheard 
Affiliation: Oregon Graduate Institute of Science Technology  
Abstract: We introduce MetaML, a statically-typed multi-stage programming language extending Nielson and Nielson's two stage notation to an arbitrary number of stages. MetaML extends previous work by introducing four distinct staging annotations which generalize those published previously [25, 12, 7, 6] We give a static semantics in which type checking is done once and for all before the first stage, and a dynamic semantics which introduces a new concept of cross-stage persistence, which requires that variables available in any stage are also available in all future stages. We illustrate that staging is a manual form of binding time analysis. We explain why, even in the presence of automatic binding time analysis, explicit annotations are useful, especially for programs with more than two stages. A thesis of this paper is that multi-stage languages are useful as programming languages in their own right, and should support features that make it possible for programmers to write staged computations without significantly changing their normal programming style. To illustrate this we provide a simple three stage example, and an extended two-stage example elaborating a number of practical issues. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> C. Consel and O. Danvy. </author> <title> For a better support of static data flow. </title> <editor> In J. Hughes, editor, </editor> <booktitle> Functional Programming Languages and Computer Architecture, </booktitle> <address> Cambridge, Massachusetts, </address> <booktitle> August 1991 (Lecture Notes in Computer Science, </booktitle> <volume> vol. 523), </volume> <pages> pages 496-519. </pages> <address> New York: </address> <publisher> ACM, Berlin: Springer-Verlag, </publisher> <year> 1991. </year>
Reference: [2] <author> Charles Consel and Olivier Danvy. </author> <title> Tutorial notes on partial evaluation. </title> <booktitle> In ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 493-501, </pages> <month> January </month> <year> 1993. </year>
Reference-contexts: Following the annotations, the specializer either performs a computation, or produces text for inclusion in the output (residual) program. The relationship between partial-evaluation and multistage programming is that the intermediate data structure between the two steps is a two-stage annotated program <ref> [2] </ref>, and that the specialization phase is (the first stage in) the execution of the two-stage annotated program produced by BTA. Recently, Gluck and Jtrgensen proposed multi-level BTA and showed that it is an efficient alternative to multiple specialization [9, 10].
Reference: [3] <author> Roberto Di Cosmo. </author> <title> Isomorphisms of Types: from -calculus to information retrieval and language design. </title> <booktitle> Progress in Theoretical Computer Science. </booktitle> <publisher> Birkhauser, </publisher> <year> 1995. </year>
Reference-contexts: Under this proviso (and disregarding termination issues) the composition of these two functions is identity under MetaML's semantics (see Section 10). They define an isomorphism between values of type &lt;A,'c&gt; -&gt; &lt;B,'c&gt; and &lt;A -&gt; B,'c&gt;. <ref> [3] </ref>. We note that back and forth coorespond to 2-level eta-expansion which Danvy finds to be an important element in partial evaluation [5].
Reference: [4] <author> Olivier Danvy. </author> <title> Type-directed partial evaluation. </title> <booktitle> In ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 242-257, </pages> <address> Florida, January 1996. New York: </address> <publisher> ACM. </publisher>
Reference-contexts: It seems that this isomorphism, which MetaML has allowed us to make concrete, is at the heart of concise reduction systems, such as Danvy's type-directed partial evaluator <ref> [4] </ref> and its extensions [27]. Under MetaML's semantics, we can switch between the two types without needing to worry about substitution or variable capture. This has profound implications for the writing of staged functions.
Reference: [5] <author> Olivier Danvy, Karoline Malmkjaer, and Jens Pals-berg. </author> <title> The essence of eta-expansion in partial evaluation. </title> <journal> LISP and Symbolic Computation, </journal> <volume> 1(19), </volume> <year> 1995. </year>
Reference-contexts: They define an isomorphism between values of type &lt;A,'c&gt; -&gt; &lt;B,'c&gt; and &lt;A -&gt; B,'c&gt;. [3]. We note that back and forth coorespond to 2-level eta-expansion which Danvy finds to be an important element in partial evaluation <ref> [5] </ref>. This isomorphism can also be viewed as a formalization of the intuitive equivalence of a symbolic evaluator [23] &lt;A,'c&gt; -&gt; &lt;B,'c&gt; and the syntactic representation of a function &lt;A -&gt; B,'c&gt;. <p> The type rule for run presented in this paper is motivated by the type system for runST [19]. The back and forth functions are similar to multilevel -expansion <ref> [5] </ref>. In MetaML, however, back and forth are not only meta-level concepts or optimizations, but rather, first class functions in the language, and the user can apply them directly to values of the appropriate type. 13 Conclusion We have described an n-stage multi-stage programming language which we call MetaML.
Reference: [6] <author> Rowan Davies. </author> <title> A temporal-logic approach to binding-time analysis. </title> <booktitle> In Proceedings, 11 th Annual IEEE Symposium on Logic in Computer Science, </booktitle> <pages> pages 184-195, </pages> <address> New Brunswick, New Jersey, 27-30 July 1996. </address> <publisher> IEEE Computer Society Press. </publisher>
Reference-contexts: It provides the following extensions not found in previous work on multi-stage systems: * Four distinct staging annotations, which we believe are necessary and sufficient for all multi-stage programming. (Section 5) These annotations generalize and safely combine those published previ ously <ref> [25, 12, 7, 6] </ref>. * A type system ensuring the well-formedness of acceptable multi-stage programs. Type checking is done once and for all before the first stage (Section 10.1). * Variables of any stage are available in all future stages. <p> This feature, in a language which also contains run 1 makes MetaML's annotations strictly more expressive than the languages of Nielsen & Nielsen [25, 24], Davies & Pfenning [7], and Davies <ref> [6] </ref>. We also deal with the interesting technical problem of ensuring the hygienic binding of free variables (Section 10.2) in code expressions. * A non-Hindley-Milner, second order type judgement for the run annotation to ensure that no code is ever run in a context in which it is undefined. <p> This is part of what we mean by having an integrated system. Cross-Stage Persistence can be relaxed by allowing variables to be available at exactly one stage. This seems to have been the case in all multi-stage languages known to us to date <ref> [25, 12, 7, 6] </ref>. The primary difficulty in implementing persistence is the proper hygienic treatment of free variables. We will show how this problem can be solved, thus allowing the user to stage significantly more expressions than was previously possible. <p> Because we are more used to reasoning about functions, this leads us to avoid creating functions of the latter kind except when we need to inspect the code. The type of back is one of the axioms of the logic system motivating the type system of Davies <ref> [6] </ref>. MetaML's type system was motivated purely by operational reasons. At the same time, it is important for the programmer to have both coercions, thereby being able to switch back and forth between the two isomorphic types as the need arises. <p> For the standard part of the language, code (now denoted by h i for conciseness) is a normal type constructor that needs no special treatment and the level n is never changed. Similar type systems have been identified and used by Gomard and Jones [11], Davies & Pfenning <ref> [6] </ref> and Davies [7]. <p> Similar type systems have been identified and used by Gomard and Jones [11], Davies & Pfenning [6] and Davies [7]. An important difference between these type systems and the one in Figure 1 is that in all previous statically-typed multi-stage languages <ref> [25, 7, 6] </ref>, only the following monolithic type rule is used for variables: Var (Monolithic): ( x) = t m n when m = n Whereas we allow the more general condition m n. <p> So rebuilding it more than once performs no useful work. This correctness of this optimization follows from the fact that under our semantics ~ &lt;e&gt; is always equal to e. Facility Example NN [25] GA [11] GB [9] Th [31] HG [12] 2 [7] fl <ref> [6] </ref> M Staging &lt;x.x&gt; 2 2 + 2 + + + + Strong Typing Y 1 N N N Y Y Y Monolithic Variables &lt;x.~(f &lt;x&gt;)&gt; Y Y Y Y Y N Y Y Reflection run or eval N N N Y N Y N Y Lifting lift Y Y Y <p> In particular, not all the language allow reflection in the form of a run or eval function. Most notably, even in the most recent work of Davies, it was not known how eval could be in cluded in the language <ref> [6] </ref>. * Lifting: The ability to convert a value of ground type into its representation as a literal. * Cross-Stage Persistence: This is the most distinguishing feature of MetaML, and has been discussed in detail in this paper. <p> In their work, Hatcliff & Gluck identified language-independence of the internal representation of "code" as an important characteristic of any multi-stage language. * 2 : Davies & Pfenning presented the first statically typed multi-stage language Mini-ML 2 <ref> [6] </ref>. The type system is motivated by constructive modal logic, and a formal proof is presented for the equivalence of binding-time correctness and modal correctness. In contrast, the MetaML type-system was motivated primarily by operational considerations. <p> Also, while Mini-ML 2 can simulate persistance for code values, a stage-zero function, for example, cannot be made persistant. Finally, Mini-ML 2 allows delaying only closed terms, and hence, functions like back are not expressible in the language. * fl : The multi-stage language Mini-ML fl <ref> [6] </ref> is motivated by a linear-time constructive modal logic. While the logic is more restricted than that behind Mini-ML 2 , the language is more expressive, allowing staged expressions to contain monolithic free variables.
Reference: [7] <author> Rowan Davies and Frank Pfenning. </author> <title> A modal analysis of staged computation. </title> <booktitle> In 23rd Annual ACM Symposium on Principles of Programming Languages (POPL'96), </booktitle> <address> St.Petersburg Beach, Florida, </address> <month> January </month> <year> 1996. </year>
Reference-contexts: 1 Introduction Multi-stage languages have recently been proposed as intermediate representations for partial evaluation [12] and runtime code generation <ref> [7] </ref>. These languages generalize the well-known two-level notation of Nielson & Nielson [25] to an arbitrary number of levels. A major thesis of this paper is that multi-stage languages are useful not only as intermediate representations, but also as programming languages in their own right. <p> It provides the following extensions not found in previous work on multi-stage systems: * Four distinct staging annotations, which we believe are necessary and sufficient for all multi-stage programming. (Section 5) These annotations generalize and safely combine those published previ ously <ref> [25, 12, 7, 6] </ref>. * A type system ensuring the well-formedness of acceptable multi-stage programs. Type checking is done once and for all before the first stage (Section 10.1). * Variables of any stage are available in all future stages. <p> This feature, in a language which also contains run 1 makes MetaML's annotations strictly more expressive than the languages of Nielsen & Nielsen [25, 24], Davies & Pfenning <ref> [7] </ref>, and Davies [6]. <p> This is part of what we mean by having an integrated system. Cross-Stage Persistence can be relaxed by allowing variables to be available at exactly one stage. This seems to have been the case in all multi-stage languages known to us to date <ref> [25, 12, 7, 6] </ref>. The primary difficulty in implementing persistence is the proper hygienic treatment of free variables. We will show how this problem can be solved, thus allowing the user to stage significantly more expressions than was previously possible. <p> Similar type systems have been identified and used by Gomard and Jones [11], Davies & Pfenning [6] and Davies <ref> [7] </ref>. <p> Similar type systems have been identified and used by Gomard and Jones [11], Davies & Pfenning [6] and Davies [7]. An important difference between these type systems and the one in Figure 1 is that in all previous statically-typed multi-stage languages <ref> [25, 7, 6] </ref>, only the following monolithic type rule is used for variables: Var (Monolithic): ( x) = t m n when m = n Whereas we allow the more general condition m n. <p> So rebuilding it more than once performs no useful work. This correctness of this optimization follows from the fact that under our semantics ~ &lt;e&gt; is always equal to e. Facility Example NN [25] GA [11] GB [9] Th [31] HG [12] 2 <ref> [7] </ref> fl [6] M Staging &lt;x.x&gt; 2 2 + 2 + + + + Strong Typing Y 1 N N N Y Y Y Monolithic Variables &lt;x.~(f &lt;x&gt;)&gt; Y Y Y Y Y N Y Y Reflection run or eval N N N Y N Y N Y Lifting lift Y
Reference: [8] <author> Nachum Dershowitz. </author> <title> Computing with rewrite systems. </title> <journal> Information and Control, </journal> <volume> 65 </volume> <pages> 122-157, </pages> <year> 1985. </year>
Reference: [9] <author> Robert Gluck and Jesper Jtrgensen. </author> <title> Efficient multi-level generating extensions for program specialization. </title> <booktitle> In Programming Languages, Implementations, Logics and Programs (PLILP'95), volume 982 of Lecture Notes in Computer Science. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1995. </year>
Reference-contexts: Recently, Gluck and Jtrgensen proposed multi-level BTA and showed that it is an efficient alternative to multiple specialization <ref> [9, 10] </ref>. Their underlying annotated language is closely related to MetaML. 4 Why Explicit Annotations? If BTA performs staging automatically, why should programmers stage programs manually? They shouldn't have to, but there are several important reasons why they may want to: Pragmatic. <p> This is exactly the case when computing the multiplication of 2 matrixes. For each row in the first matrix, the dot product of that row will be taken for each column of the second. This example has appeared in several other works <ref> [9, 20] </ref> and we give our version below: Below we give three versions of the inner product function. One (iprod) with no staging annotations, the second (iprod2) with two levels of annotations, and the third (iprod3) with two levels of annotations but constructed with the back2 function. <p> So rebuilding it more than once performs no useful work. This correctness of this optimization follows from the fact that under our semantics ~ &lt;e&gt; is always equal to e. Facility Example NN [25] GA [11] GB <ref> [9] </ref> Th [31] HG [12] 2 [7] fl [6] M Staging &lt;x.x&gt; 2 2 + 2 + + + + Strong Typing Y 1 N N N Y Y Y Monolithic Variables &lt;x.~(f &lt;x&gt;)&gt; Y Y Y Y Y N Y Y Reflection run or eval N N N Y N <p> The language allows the treatment of expressions containing monolithic free variables. They use a "const" construct only for constants of ground type. Our treatment of variables in the formal semantics is inspired by their work. * GB: Gluck and Jtrgensen <ref> [9] </ref> present the novel idea of multi-level BTA, as a very efficient and effective alternate to multiple self-application. An untyped multi-level language based on Scheme is used for the presentation. Our study of MetaML is at a more basic level: MetaML is an abstract calculus.
Reference: [10] <author> Robert Gluck and Jesper Jtrgensen. </author> <title> Fasting binding-time analysis for multi-level specialization. </title> <booktitle> In PSI-96: Andrei Ershov Second International Memorial Conference, Perspectives of System In-formatics, volume 1181 of Lecture Notes in Computer Science. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1996. </year>
Reference-contexts: Recently, Gluck and Jtrgensen proposed multi-level BTA and showed that it is an efficient alternative to multiple specialization <ref> [9, 10] </ref>. Their underlying annotated language is closely related to MetaML. 4 Why Explicit Annotations? If BTA performs staging automatically, why should programmers stage programs manually? They shouldn't have to, but there are several important reasons why they may want to: Pragmatic. <p> While this is very convenient for run-time code generation, it makes the proper specification of MetaML more difficult. For example, we can't use [9]'s "Generic Code Generation functions" to define the language. A latter paper <ref> [10] </ref> demonstrates the impressive efficiency of MBTA, and the use of constraints-solving methods to perform the analysis.
Reference: [11] <author> Carsten K. Gomard and Neil D. Jones. </author> <title> A partial evaluator for untyped lambda calculus. </title> <journal> Journal of Functional Programming, </journal> <volume> 1(1) </volume> <pages> 21-69, </pages> <year> 1991. </year>
Reference-contexts: For the standard part of the language, code (now denoted by h i for conciseness) is a normal type constructor that needs no special treatment and the level n is never changed. Similar type systems have been identified and used by Gomard and Jones <ref> [11] </ref>, Davies & Pfenning [6] and Davies [7]. <p> This optimization is safe since there are no variables in a rebuilt term. So rebuilding it more than once performs no useful work. This correctness of this optimization follows from the fact that under our semantics ~ &lt;e&gt; is always equal to e. Facility Example NN [25] GA <ref> [11] </ref> GB [9] Th [31] HG [12] 2 [7] fl [6] M Staging &lt;x.x&gt; 2 2 + 2 + + + + Strong Typing Y 1 N N N Y Y Y Monolithic Variables &lt;x.~(f &lt;x&gt;)&gt; Y Y Y Y Y N Y Y Reflection run or eval N N N <p> They also sketched guidelines for a multi-stage ("B-level") language. The two-level language is widely used to describe binding-time annotations in the partial evaluation literature. * GA: Gomard and Jones use a statically-typed two-stage language for partial evaluation of the un-typed -calculus <ref> [11] </ref>. The language allows the treatment of expressions containing monolithic free variables. They use a "const" construct only for constants of ground type.
Reference: [12] <author> John Hatcliff and Robert Gluck. </author> <title> Reasoning about hierarchies of online specialization systems. </title> <editor> In Olivier Danvy, Robert Gluck, and Peter Thiemann, editors, </editor> <title> Partial Evaluation, </title> <booktitle> volume 1110 of Lecture Notes in Computer Science, </booktitle> <pages> pages 161-182. </pages> <publisher> Springer-Verlag, </publisher> <year> 1996. </year>
Reference-contexts: 1 Introduction Multi-stage languages have recently been proposed as intermediate representations for partial evaluation <ref> [12] </ref> and runtime code generation [7]. These languages generalize the well-known two-level notation of Nielson & Nielson [25] to an arbitrary number of levels. A major thesis of this paper is that multi-stage languages are useful not only as intermediate representations, but also as programming languages in their own right. <p> It provides the following extensions not found in previous work on multi-stage systems: * Four distinct staging annotations, which we believe are necessary and sufficient for all multi-stage programming. (Section 5) These annotations generalize and safely combine those published previ ously <ref> [25, 12, 7, 6] </ref>. * A type system ensuring the well-formedness of acceptable multi-stage programs. Type checking is done once and for all before the first stage (Section 10.1). * Variables of any stage are available in all future stages. <p> This is part of what we mean by having an integrated system. Cross-Stage Persistence can be relaxed by allowing variables to be available at exactly one stage. This seems to have been the case in all multi-stage languages known to us to date <ref> [25, 12, 7, 6] </ref>. The primary difficulty in implementing persistence is the proper hygienic treatment of free variables. We will show how this problem can be solved, thus allowing the user to stage significantly more expressions than was previously possible. <p> So rebuilding it more than once performs no useful work. This correctness of this optimization follows from the fact that under our semantics ~ &lt;e&gt; is always equal to e. Facility Example NN [25] GA [11] GB [9] Th [31] HG <ref> [12] </ref> 2 [7] fl [6] M Staging &lt;x.x&gt; 2 2 + 2 + + + + Strong Typing Y 1 N N N Y Y Y Monolithic Variables &lt;x.~(f &lt;x&gt;)&gt; Y Y Y Y Y N Y Y Reflection run or eval N N N Y N Y N Y Lifting <p> Thiemann also deals with the issue of variable-arity functions, which is a practical problem when dealing with eval in Scheme. * HG: Hatcliff & Gluck studied a multi-stage flowchart language called S-Graph-n, and thoroughly investigated the issues involved in the implementation of such a language <ref> [12] </ref>. The syntax of S-Graph-n explicitly captures all the information necessary for specifying the staging of a computation: each construct is annotated with a number indicating the stage during which it is to be executed, and all variables are annotated with a number indicating the stage of their availability.
Reference: [13] <author> J. Roger Hindley and Jonathan P. Seldin. </author> <title> Introduction to Cobminators and -Calculus. Number 1 in London Mathematical Society Student Texts. </title> <publisher> Cambridge University Press, </publisher> <year> 1986. </year>
Reference-contexts: We introduce MetaML, a statically-typed multi-stage programming language extending Nielson and Nielson's two-level notation to an arbitrary number of stages (similar to their B-level language). MetaML is an extension of a Hindley-Milner polymorphically-typed [22] call-by-value -calculus <ref> [13] </ref> with support for sums, products, recursion, polymorphism, primitive datatypes and static type-inference.
Reference: [14] <author> Neil D. Jones. </author> <title> Mix ten years later. In Partial Evaluation and Semantics-Based Program Manipulation, New Haven, </title> <journal> Connecticut (Sigplan Notices, </journal> <volume> vol. 26, no. 9, </volume> <month> September </month> <year> 1991), </year> <pages> pages 24-38. </pages> <address> New York: </address> <publisher> ACM, </publisher> <address> New York: </address> <publisher> ACM, </publisher> <month> June </month> <year> 1995. </year>
Reference-contexts: Pedagogical tool. It has been observed that it is sometimes hard for users to understand the workings of partial evaluation systems <ref> [14] </ref>. New users often lack a good mental model of how partial evaluation systems work. Although BTA is an involved process, requiring special expertise, the annotations it produces are relatively simple and easy to understand.
Reference: [15] <author> Neil D. Jones, Carsten K Gomard, and Peter Ses-toft. </author> <title> Partial Evaluation and Automatic Program Generation. </title> <publisher> Prentice-Hall, </publisher> <year> 1993. </year>
Reference-contexts: It provides an approach radically different from, and superior to, the classic "programs-as-strings" view that seems to predominate in many ad-hoc multi-stage software systems. MetaML is tightly integrated in this sense. 3 Relationship to Partial Evaluation Today, the most sophisticated automatic staging techniques are found in partial evaluation systems <ref> [15] </ref>. Partial evaluation optimizes a program using a priori information about some of that program's inputs. The goal is to identify and perform as many computations as possible in a program before run-time. O*ine partial evaluation has two distinct steps, binding-time analysis (BTA) and specialization. <p> Having a programming language with explicit staging annotations would help users of partial evaluation understand more of the issues involved in staged computation, and, hopefully, reduce the steep learning curve currently associated with learning to use a partial evaluator effectively <ref> [15] </ref>. Nielson & Nielson's two-stage notation is the only widely accepted notation for expressing staged computation. But Nielson & Nielson's notation is not widely viewed as a programming language, perhaps because over-bars and under-bars do not appear on the standard keyboard and no implementation of it is in widespread use.
Reference: [16] <author> Simon L. Peyton Jones and John Launchbury. </author> <title> Un-boxed values as first class citizens in a non-strict functional language. </title> <booktitle> In Functional Programming and Computer Architecture, </booktitle> <month> September 91. </month>
Reference-contexts: We believe that MetaML can have positive implications for understanding and communicating ideas about multi-stage programs, partial evaluation and the complex process of binding-time analysis in much the same way that the boxed / unboxed (#) distinction provides a language for understanding boxing optimizations as source-to-source transformations <ref> [16] </ref>. 1 An eval-like operator 2 Why Multi-stage Programs? The concept of a stage arises in a wide variety of situations. For a compiled language, there are two distinct stages: compile-time, and run-time. But three distinct stages appear in the context of program generation: generation, compilation, and execution.
Reference: [17] <author> Richard B. Kieburtz, Francoise Bellegarde, Jef Bell, James Hook, Jeffrey Lewis, Dino Oliva, Tim Sheard, Lisa Walton, and Tong Zhou. </author> <title> Calculating software generators from solution specifications. </title> <booktitle> In TAPSOFT'95, volume 915 of LNCS, </booktitle> <pages> pages 546-560. </pages> <publisher> Springer-Verlag, </publisher> <year> 1995. </year>
Reference-contexts: This capture of a problem family rather than a single problem increases programmer productivity. Program generators let experts capture their knowledge in a clear (and hence reusable) notation that can then be used for synthesising the desired software component <ref> [21, 17, 18] </ref>. Reliability and quality. The greatest source of errors in code maintenance is human intervention. When less human intervention is needed to modify a software product, there are proportionately fewer opportunities for error insertion and less rework of code is necessary.
Reference: [18] <author> Richard B. Kieburtz, Laura McKinney, Jeffrey Bell, James Hook, Alex Kotov, Jeffrey Lewis, Dino Oliva, Tim Sheard, Ira Smith, and Lisa Walton. </author> <title> A software engineering experiment in software component generation. </title> <booktitle> In 18th International Conference in Software Engineering, </booktitle> <month> March </month> <year> 1996. </year>
Reference-contexts: This capture of a problem family rather than a single problem increases programmer productivity. Program generators let experts capture their knowledge in a clear (and hence reusable) notation that can then be used for synthesising the desired software component <ref> [21, 17, 18] </ref>. Reliability and quality. The greatest source of errors in code maintenance is human intervention. When less human intervention is needed to modify a software product, there are proportionately fewer opportunities for error insertion and less rework of code is necessary.
Reference: [19] <author> John Launchbury and Amr Sabry. </author> <title> Monadic state: Axiomatization and type safety. </title> <booktitle> In Proceedings of the Symposium on Partial Evaluation and Semantics-Based Program Manipulation, </booktitle> <address> Amster-dam, </address> <month> June </month> <year> 1997. </year>
Reference-contexts: Sheard and Shields [29] investigate a dynamic type systems for multi-staged programs where some type obligations of staged computations can be put off till run-time. The type rule for run presented in this paper is motivated by the type system for runST <ref> [19] </ref>. The back and forth functions are similar to multilevel -expansion [5].
Reference: [20] <author> Mark Leone and Peter Lee. </author> <title> Deferred compilation: The automation of run-time code generation. </title> <type> Technical Report CMU-CS-93-225, </type> <institution> Carnegie Mel-lon University, </institution> <month> Dec. </month> <year> 1993. </year>
Reference-contexts: This is exactly the case when computing the multiplication of 2 matrixes. For each row in the first matrix, the dot product of that row will be taken for each column of the second. This example has appeared in several other works <ref> [9, 20] </ref> and we give our version below: Below we give three versions of the inner product function. One (iprod) with no staging annotations, the second (iprod2) with two levels of annotations, and the third (iprod3) with two levels of annotations but constructed with the back2 function.
Reference: [21] <author> Michael Lowry, Andrew Philpot, Thomas Press-burger, and Ian Underwood. Amphion: </author> <title> Automatic programming for scientific subroutine libraries. </title> <journal> NASA Science Information Systems Newsletter, </journal> <volume> 31 </volume> <pages> 22-25, </pages> <year> 1994. </year>
Reference-contexts: This capture of a problem family rather than a single problem increases programmer productivity. Program generators let experts capture their knowledge in a clear (and hence reusable) notation that can then be used for synthesising the desired software component <ref> [21, 17, 18] </ref>. Reliability and quality. The greatest source of errors in code maintenance is human intervention. When less human intervention is needed to modify a software product, there are proportionately fewer opportunities for error insertion and less rework of code is necessary.
Reference: [22] <author> Robin Milner. </author> <title> A theory of type polymorphism in programming. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 17 </volume> <pages> 348-375, </pages> <year> 1978. </year>
Reference-contexts: We introduce MetaML, a statically-typed multi-stage programming language extending Nielson and Nielson's two-level notation to an arbitrary number of stages (similar to their B-level language). MetaML is an extension of a Hindley-Milner polymorphically-typed <ref> [22] </ref> call-by-value -calculus [13] with support for sums, products, recursion, polymorphism, primitive datatypes and static type-inference. <p> first stage, while the value of b will be available only in the second stage! Therefore, MetaML's type system was designed to ensure that "well-typed programs won't go wrong", where going wrong now includes the violation of the cross-stage safety condition, as well as the standard notions of "going wrong" <ref> [22] </ref> in statically-typed languages.
Reference: [23] <author> Torben . Mogensen. </author> <title> Efficient self-interpretation in lambda calculus. </title> <booktitle> Functional Programming, </booktitle> <volume> 2(3) </volume> <pages> 345-364, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: We note that back and forth coorespond to 2-level eta-expansion which Danvy finds to be an important element in partial evaluation [5]. This isomorphism can also be viewed as a formalization of the intuitive equivalence of a symbolic evaluator <ref> [23] </ref> &lt;A,'c&gt; -&gt; &lt;B,'c&gt; and the syntactic representation of a function &lt;A -&gt; B,'c&gt;. It seems that this isomorphism, which MetaML has allowed us to make concrete, is at the heart of concise reduction systems, such as Danvy's type-directed partial evaluator [4] and its extensions [27].
Reference: [24] <author> F. Nielson. </author> <title> Correctness of code generation from a two-level meta-language. </title> <editor> In B. Robinet and R. Wil-helm, editors, </editor> <booktitle> Proceedings of the European Symposium on Programming (ESOP 86), volume 213 of LNCS, </booktitle> <pages> pages 30-40, </pages> <address> Saarbrucken, FRG, March 1986. </address> <publisher> Springer. </publisher>
Reference-contexts: Type checking is done once and for all before the first stage (Section 10.1). * Variables of any stage are available in all future stages. This feature, in a language which also contains run 1 makes MetaML's annotations strictly more expressive than the languages of Nielsen & Nielsen <ref> [25, 24] </ref>, Davies & Pfenning [7], and Davies [6]. <p> The loss of this ability is the price paid for cross stage persistence. In what follows is an historical perspective of the work highlighted in the table: * NN: Nielson and Nielson pioneered the investigation of staged languages with their two-level functional language <ref> [25, 24] </ref>. They presented rules for the well-formedness of the binding-times of expressions in the language, from which MetaML's type rules are derived. They also sketched guidelines for a multi-stage ("B-level") language.
Reference: [25] <author> F. Nielson and H. R. Nielson. </author> <title> Two-Level Functional Languages. </title> <booktitle> Number 34 in Cambridge Tracts in Theoretical Computer Science. </booktitle> <publisher> Cambridge University Press, </publisher> <year> 1992. </year>
Reference-contexts: 1 Introduction Multi-stage languages have recently been proposed as intermediate representations for partial evaluation [12] and runtime code generation [7]. These languages generalize the well-known two-level notation of Nielson & Nielson <ref> [25] </ref> to an arbitrary number of levels. A major thesis of this paper is that multi-stage languages are useful not only as intermediate representations, but also as programming languages in their own right. <p> It provides the following extensions not found in previous work on multi-stage systems: * Four distinct staging annotations, which we believe are necessary and sufficient for all multi-stage programming. (Section 5) These annotations generalize and safely combine those published previ ously <ref> [25, 12, 7, 6] </ref>. * A type system ensuring the well-formedness of acceptable multi-stage programs. Type checking is done once and for all before the first stage (Section 10.1). * Variables of any stage are available in all future stages. <p> Type checking is done once and for all before the first stage (Section 10.1). * Variables of any stage are available in all future stages. This feature, in a language which also contains run 1 makes MetaML's annotations strictly more expressive than the languages of Nielsen & Nielsen <ref> [25, 24] </ref>, Davies & Pfenning [7], and Davies [6]. <p> It is also easier to verify the correctness of both the generators and the programs they generate, as the issues of representation are hidden away from the programmer. 5 MetaML's Multi-Stage Programming An notations The two-level notation of Nielson & Nielson <ref> [25] </ref> features two annotations: over-bars to mark computations of the first stage, and under-bars to mark those of the second stage. Although quite powerful, this is only a subset of the annotations needed for generic multi-stage programming. <p> This is part of what we mean by having an integrated system. Cross-Stage Persistence can be relaxed by allowing variables to be available at exactly one stage. This seems to have been the case in all multi-stage languages known to us to date <ref> [25, 12, 7, 6] </ref>. The primary difficulty in implementing persistence is the proper hygienic treatment of free variables. We will show how this problem can be solved, thus allowing the user to stage significantly more expressions than was previously possible. <p> Similar type systems have been identified and used by Gomard and Jones [11], Davies & Pfenning [6] and Davies [7]. An important difference between these type systems and the one in Figure 1 is that in all previous statically-typed multi-stage languages <ref> [25, 7, 6] </ref>, only the following monolithic type rule is used for variables: Var (Monolithic): ( x) = t m n when m = n Whereas we allow the more general condition m n. <p> This optimization is safe since there are no variables in a rebuilt term. So rebuilding it more than once performs no useful work. This correctness of this optimization follows from the fact that under our semantics ~ &lt;e&gt; is always equal to e. Facility Example NN <ref> [25] </ref> GA [11] GB [9] Th [31] HG [12] 2 [7] fl [6] M Staging &lt;x.x&gt; 2 2 + 2 + + + + Strong Typing Y 1 N N N Y Y Y Monolithic Variables &lt;x.~(f &lt;x&gt;)&gt; Y Y Y Y Y N Y Y Reflection run or eval N <p> The loss of this ability is the price paid for cross stage persistence. In what follows is an historical perspective of the work highlighted in the table: * NN: Nielson and Nielson pioneered the investigation of staged languages with their two-level functional language <ref> [25, 24] </ref>. They presented rules for the well-formedness of the binding-times of expressions in the language, from which MetaML's type rules are derived. They also sketched guidelines for a multi-stage ("B-level") language.
Reference: [26] <author> G. D. Plotkin. </author> <title> Call-by-name, call-by-value- and the lambda-calculus. </title> <journal> Theoretical Computer Science, </journal> <volume> 1 </volume> <pages> 125-159, </pages> <year> 1975. </year>
Reference-contexts: For this reason, our implementation performs automatic safe-beta reduction on constants and variables. A beta reduction is safe if it does not change evaluation order, or effect termination properties. There is one safe case which is particularly easy to recognize, namely, Plotkin's fi v rule <ref> [26] </ref>. Whenever an application is constructed where the function part is an explicit lambda abstraction, and the argument part is a value, then that application can be symbolically beta reduced.
Reference: [27] <author> Tim Sheard. </author> <title> A type-directed, on-line partial evaluator for a polymorphic language. </title> <booktitle> In Proceedings of the Symposium on Partial Evaluation and Semantics-Based Program Manipulation, </booktitle> <address> Amster-dam, </address> <month> June </month> <year> 1997. </year>
Reference-contexts: It seems that this isomorphism, which MetaML has allowed us to make concrete, is at the heart of concise reduction systems, such as Danvy's type-directed partial evaluator [4] and its extensions <ref> [27] </ref>. Under MetaML's semantics, we can switch between the two types without needing to worry about substitution or variable capture. This has profound implications for the writing of staged functions.
Reference: [28] <author> Tim Sheard and Neal Nelson. </author> <title> Type safe abstractions using program generators. </title> <type> Technical Report OGI-TR-95-013, </type> <institution> Oregon Graduate Institute of Science and Technology, </institution> <year> 1995. </year>
Reference-contexts: While Davies shows how lift can be defined in terms of next and prev for a Succ/Zero representation for naturals, it must be explicitly programmed. Sheard has also investigated richer type systems for multi-staged programming. Sheard and Nelson investigated a two-stage language for the purpose of program generation <ref> [28] </ref>. The base language was statically typed, and dependent types were used to generate a wider class of programs than is possible by MetaML restricted to two stages.
Reference: [29] <author> Tim Sheard and Mark Shields. </author> <title> Dynamic typing through staged type inference. </title> <booktitle> In Proceedings of the Second ACM International Conference on Functional Programming, </booktitle> <month> jun </month> <year> 1997. </year> <note> (submitted). </note>
Reference-contexts: Sheard and Nelson investigated a two-stage language for the purpose of program generation [28]. The base language was statically typed, and dependent types were used to generate a wider class of programs than is possible by MetaML restricted to two stages. Sheard and Shields <ref> [29] </ref> investigate a dynamic type systems for multi-staged programs where some type obligations of staged computations can be put off till run-time. The type rule for run presented in this paper is motivated by the type system for runST [19].
Reference: [30] <author> Brian C. Smith. </author> <title> Reflection and Semantics in a Procedural Language. </title> <type> PhD thesis, </type> <institution> Massachusetts Institute of Technology, </institution> <month> January </month> <year> 1982. </year>
Reference-contexts: It is the only way a computation "frozen" using meta-brackets can be computed (or "forced") in the current stage. The argument to run must be of code type. Having run in the language implies introducing a kind of reflection <ref> [30] </ref>, and allows a future-stage computation to be performed now. To illustrate, consider the expression: let val a = &lt;50-10&gt; in 2+(run a) end This expression has type int and returns the value 42 when computed.
Reference: [31] <author> Peter Thiemann. </author> <title> Towards partial evaluation of full Scheme. </title> <editor> In Gregor Kiczales, editor, </editor> <volume> Reflection 96, </volume> <pages> pages 95-106, </pages> <address> San Francisco, CA, USA, </address> <month> April </month> <year> 1996. </year>
Reference-contexts: So rebuilding it more than once performs no useful work. This correctness of this optimization follows from the fact that under our semantics ~ &lt;e&gt; is always equal to e. Facility Example NN [25] GA [11] GB [9] Th <ref> [31] </ref> HG [12] 2 [7] fl [6] M Staging &lt;x.x&gt; 2 2 + 2 + + + + Strong Typing Y 1 N N N Y Y Y Monolithic Variables &lt;x.~(f &lt;x&gt;)&gt; Y Y Y Y Y N Y Y Reflection run or eval N N N Y N Y N <p> For example, we can't use [9]'s "Generic Code Generation functions" to define the language. A latter paper [10] demonstrates the impressive efficiency of MBTA, and the use of constraints-solving methods to perform the analysis. The MBTA is type-based, but underlying language is dynamically typed. * Th: Thiemann <ref> [31] </ref> studies a two-level language with eval, apply, and call/cc, in the context of studying the partial evaluation of a greater subset of scheme than was done previously. A BTA based on constraint-solving is presented.
Reference: [32] <author> Wright and Felleisen. </author> <title> A syntactic approach to type soundness. </title> <journal> Information and Computation (formerly Information and Control), </journal> <volume> 115, </volume> <year> 1994. </year>
Reference-contexts: We are currently extending this implementation to include all the features in core-ML. We are also actively pursuing a subject reduction theorem for M . The multi-level syntax makes the syntactic approaches to type soundness <ref> [32] </ref> difficult to apply, because reduction contexts may appear inside lambda expressions at levels greater than zero. We have also found that the non-Hindley-Milner type judgement for the run annotation complicates matters considerably.
References-found: 32

