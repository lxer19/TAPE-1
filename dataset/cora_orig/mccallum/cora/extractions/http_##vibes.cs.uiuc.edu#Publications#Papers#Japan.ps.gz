URL: http://vibes.cs.uiuc.edu/Publications/Papers/Japan.ps.gz
Refering-URL: http://vibes.cs.uiuc.edu/Publications/publications.htm
Root-URL: http://www.cs.uiuc.edu
Title: Performance Analysis of Parallel Systems: Approaches and Open Problems  
Author: Daniel A. Reed Ruth A. Aydt Luiz DeRose Celso L. Mendes Randy L. Ribler Eric Shaffer Huseyin Simitci Jeffrey S. Vetter Daniel R. Wells Shannon Whitmore Ying Zhang 
Address: Urbana, Illinois 61801 USA  
Affiliation: Department of Computer Science University of Illinois  
Abstract: Parallel computing is rapidly evolving to include heterogeneous collections of distributed and parallel systems. Concurrently, applications are becoming increasingly multidisciplinary with code libraries implemented using diverse programming models. To optimize the behavior of complex applications on heterogeneous systems, performance analysis software must also evolve, replacing post-mortem analysis with real-time, adaptive optimization, tightly integrating compile-time analysis with performance measurement and prediction, and supporting high-modality visualization and software manipulation. In this paper, we briefly survey the state of the art in each of these areas and sketch a series of open research problems. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Adve, V., Mellor-Crummey, J., Wang, J.- C., and Reed, D. </author> <title> Integrating Compilation and Performance Analysis for Data-Parallel Programs. </title> <booktitle> In Proceedings of Supercomputing'95 (November 1995). </booktitle>
Reference-contexts: Second, increasing software complexity, high-level programming models (e.g., data parallel and parallel object) and heterogeneous, wide area computing have all exacerbated performance analysis problems. No longer can measured data be related to user code without tight integration of performance measurement systems with compilers and runtime systems <ref> [1] </ref>. Third, repeated experience has shown that scientific application software developers will eschew powerful, but complex tools in favor of inferior, but easily understood tools. <p> To support source-level performance analysis of programs in data parallel languages, we believe compilers and performance tools must cooperate to integrate information about the program's dynamic behavior with compiler knowledge of the mapping from the low-level, explicitly parallel code to the high-level source <ref> [1] </ref>. <p> Concomitantly, the compiler must synthesize instrumentation during code generation. In an ongoing, collaborative effort with the Rice Fortran D group, we have explored performance data correlation techniques that can invert a wide range of compiler transformations, including loop interchange, code motion, and communication synthesis <ref> [1, 2] </ref>. During compilation, the Fortran D compiler emits data on the sequence of source code transformations, tying each synthesized code fragment to a portion of the original data parallel source code. During subsequent program execution, dynamic performance data is obtained from an instrumented version of the compiler-synthesized code.
Reference: [2] <author> Adve, V. S., Mellor-Crummey, J., Ander-son, M., Kennedy, K., Wang, J., and Reed, 14 D. A. </author> <title> Integrating Compilation and Performance Analysis for Data-Parallel Programs. In Proceedings of the Workshop on Debugging and Performance Tuning for Parallel Computing Systems, </title> <editor> M. L. Simmons, A. H. Hayes, D. A. Reed, and J. Brown, Eds. </editor> <publisher> IEEE Computer Society Press, </publisher> <year> 1994. </year>
Reference-contexts: Concomitantly, the compiler must synthesize instrumentation during code generation. In an ongoing, collaborative effort with the Rice Fortran D group, we have explored performance data correlation techniques that can invert a wide range of compiler transformations, including loop interchange, code motion, and communication synthesis <ref> [1, 2] </ref>. During compilation, the Fortran D compiler emits data on the sequence of source code transformations, tying each synthesized code fragment to a portion of the original data parallel source code. During subsequent program execution, dynamic performance data is obtained from an instrumented version of the compiler-synthesized code.
Reference: [3] <author> Blume, W., Doallo, R., Eigenmann, R., Grout, J., Hoeflinger, J., Lawrence, T., Lee, J., Padua, D., Paek, Y., Pottenger, W., Rauchwerger, L., and Tu, P. </author> <title> Parallel Programming with Polaris. </title> <institution> IEEE Computer (Dec. </institution> <year> 1996). </year>
Reference-contexts: Building on these observations, we are extending our symbolic models and integrating them with the SvPablo toolkit. In addition, we are incorporating analytic and high-level simulation models for esti 5 6 mating the behavior of caches and memory hierar-chies, all based on the Polaris parallelizing compiler <ref> [3] </ref>.
Reference: [4] <author> Corbett, P. F., Prost, J.-P., Demetriou, C., Gibson, G., Riedel, E., Zelenka, J., Chen, Y., Felten, E., Li, K., Hartman, J., Peterson, L., Bershad, B., Wolman, A., and Aydt, R. </author> <title> Proposal for a Common Parallel System Programming Interface Version 1.0. </title> <address> http://www.cs.arizona.edu/sio/api1.0.ps, Nov. </address> <year> 1996. </year>
Reference-contexts: Even seemingly small variations have potentially profound performance implications. This insight motivated the development of input/output systems, described in x3.4, that can adapt to changing input/output patterns as well as creation of APIs for parallel input/output <ref> [4] </ref> that allows users and high-level libraries to specify future access patterns via hints. 3.3.2 Multilevel I/O Libraries Although the emergence of new parallel input/output APIs like the SIO API and MPI-IO promise to provide a standard interface for parallel input/output, most application developers prefer to manage data on secondary storage
Reference: [5] <author> Couch, A. </author> <title> Graphical Representations of Program Performance on Hypercube Message-Passing Multiprocessors. </title> <type> PhD thesis, </type> <institution> Tufts University, Department of Computer Science, </institution> <year> 1988. </year>
Reference-contexts: Exem--plars of this work include Couch's seminal Seecube system <ref> [5] </ref>, ParaGraph [12], and our own Hyperview and Pablo toolkits [21, 28]. Although widely used to develop applications on early parallel systems, the increasingly complexity of parallel systems exposed several limitations of these toolkits. Perhaps the most obvious constraint was their limited scalability. <p> Performance data visualization has a long and storied history, though the explosion of interest in visualization of parallel system behavior can be traced to Seecube <ref> [5] </ref>, Pablo [28] and ParaGraph [12].
Reference: [6] <author> Crandall, P. E., Aydt, R. A., Chien, A. A., and Reed, D. A. </author> <title> Characterization of a Suite of Input/Output Intensive Applications. </title> <booktitle> In Proceedings of Supercomputing '95 (Dec. </booktitle> <year> 1995). </year>
Reference-contexts: As part of the SIO Initiative, we have extended the Pablo performance analysis toolkit to capture parallel application input/output patterns and file system responses and to compute I/O-specific performance metrics. The most significant observation from studies using this instrumentation <ref> [6, 34, 29, 30, 34, 33] </ref> is that scientific applications have input/output patterns and requirements more complex than simple stereotypes. <p> Driven by the output of decision procedures, actuators have many of the same properties as sensors, including local computation and distributed activation. 3.4.2 Adaptive Parallel File Systems As our extensive analysis of input/output dynamics <ref> [6, 35, 32] </ref> has shown, the parallel input/output patterns in emerging applications are both irregular and dynamic.
Reference: [7] <author> Cruz-Neira, C., D.J.Sandin, and DeFanti, T. </author> <title> Surround-Screen Projection-Based Virtual Reality: </title> <booktitle> The Design and Implementation of the CAVE. In SIGGRAPH '93 Proceedings (Aug. </booktitle> <year> 1993), </year> <institution> Association for Computing Machinery. </institution>
Reference-contexts: Below, we describe the design of Virtue, a collaborative environment for immersive performance analysis that embodies these design components. At present, a prototype of Virtue is operational, supporting three-dimensional visualization in the CAVE <ref> [7] </ref>, but much work remains to complete implementation of all design components. 12 Hierarchy and Abstraction. As we noted in x2, the key limitation of extant performance visualization tools is their lack of scalability. To address this problem, Virtue realizes abstract data as a hierarchy of embedded, three-dimensional graphs.
Reference: [8] <author> DeRose, L., Zhang, Y., and Aydt, R. Sv-pablo: </author> <title> A Multi-Language Performance Analysis System. </title> <note> In submitted for publication (Mar. </note> <year> 1998). </year>
Reference-contexts: These met-rics include both execution times and array reference data locality. The latter relies on identifying each compiler-synthesized message transmission as carrying specific array segments. 3.1.2 SvPablo: Portable Analysis Building on the insights obtained from our Rice collaboration, we have developed SvPablo <ref> [8] </ref>, a graphical environment for instrumenting application source code and browsing dynamic performance data. Sv-Pablo supports performance data capture, analysis, and presentation for applications written in a variety of languages and executing on both sequential and parallel systems.
Reference: [9] <author> Eisenhauer, G., Gu, W., Schwan, K., and Mallavarupu, N. </author> <title> Falcon | Toward Interactive Parallel Programs: the Online Steering of a Molecular Dynamic Program. </title> <booktitle> In Proceedings of the Third International Symposium on High-Performance Distributed Computing (Aug. </booktitle> <year> 1994). </year>
Reference-contexts: Notable examples include Leblanc's [16] creation of an adaptive real-time system for robotic control that consists of a multiprocessor executing a group of adaptive cognitive tasks and Schwan et al's <ref> [9] </ref> development of adaptive control mechanisms based on a sensor/actuator model. Performance data visualization has a long and storied history, though the explosion of interest in visualization of parallel system behavior can be traced to Seecube [5], Pablo [28] and ParaGraph [12].
Reference: [10] <author> Fahringer, T. </author> <title> Estimating and Optimizing Performance for Parallel programs. </title> <booktitle> IEEE Computer 28, </booktitle> <month> 11 (November </month> <year> 1995), </year> <pages> 47-56. </pages>
Reference-contexts: Notable examples include P 3 T <ref> [10] </ref> for performance prediction, together with Paradyn [25] and AIMS [36] for performance measurement. Each has exposed key research issues in performance measurement and analysis.
Reference: [11] <author> Graham, S., Kessler, P., and McKusick, M. </author> <title> gprof: A Call Graph Execution Profiler. </title> <booktitle> In Proceedings of the SIGPLAN '82 Symposium on Compiler Construction (Boston, </booktitle> <address> MA, </address> <month> June </month> <year> 1982), </year> <journal> Association for Computing Machinery, </journal> <pages> pp. 120-126. </pages>
Reference-contexts: By far the most common method of performance instrumentation is program counter sampling. The widely used UNIX prof and gprof <ref> [11] </ref> utilities periodically sample the program counter and compute a histogram of program counter locations. Because the histogram bins correspond to procedure code fragments and sampling occurs at known intervals, histogram bin height is an estimator of the amount of time spent in a particular procedure.
Reference: [12] <author> Heath, M. T., and Etheridge, J. A. </author> <title> Visualizing the Performance of Parallel Programs. </title> <booktitle> IEEE Software (Sept. </booktitle> <year> 1991), </year> <pages> 29-39. </pages>
Reference-contexts: Exem--plars of this work include Couch's seminal Seecube system [5], ParaGraph <ref> [12] </ref>, and our own Hyperview and Pablo toolkits [21, 28]. Although widely used to develop applications on early parallel systems, the increasingly complexity of parallel systems exposed several limitations of these toolkits. Perhaps the most obvious constraint was their limited scalability. <p> Performance data visualization has a long and storied history, though the explosion of interest in visualization of parallel system behavior can be traced to Seecube [5], Pablo [28] and ParaGraph <ref> [12] </ref>.
Reference: [13] <author> Hurley, C., and Buja, A. </author> <title> Analyzing High-dimensional Data with Motion Graphics. </title> <journal> SIAM Journal of Scientific and Statistical Computing 11, </journal> <volume> 6 (Nov. </volume> <year> 1990), </year> <pages> 1193-1211. </pages>
Reference-contexts: As an example, when analyzing the performance of WWW servers [15], we found it necessary to capture nearly fifty metrics on request types, processor, network, and memory usage to reliably identify performance problems. Principal component analysis and its statistical variant, projection pursuit <ref> [13] </ref>, seek to identify a subset of the metrics that captures most of the statistical variation. Intuitively, at any time t, many of the n metrics are highly correlated; principal component analysis and projection pursuit identify least correlated metrics. <p> The most important (i.e., least correlated) metrics are represented as the largest components of the projection vectors Clearly, the number of possible two or three-dimensional projections of an n-dimensional space can be large. Hence, projection pursuit minimizes an index describing the projection (e.g., in the Friedman-Tukey model <ref> [13] </ref>, the index measures clot-tedness and the algorithm uses a general hill climbing technique to generate new views of the subspace). Typically, the dimensionality k of the projection is two or three, one can visualize the projected metric space using standard visualization techniques.
Reference: [14] <author> Kasabov, N. K. </author> <title> Foundations of Neural Networks, Fuzzy Systems, and Knowledge Engineering. </title> <publisher> The MIT Press, </publisher> <year> 1996. </year>
Reference-contexts: However, the dynamic behavior of heterogeneous distributed systems and irregular multidisciplinary applications are too poorly understood to be amenable to either of these control techniques. In contrast, fuzzy logic targets precisely the attributes of the resource management problem that challenge classic techniques <ref> [14] </ref>, namely conflicting goals and poorly understood optimization spaces. Autopilot builds on this observation by coupling a configurable fuzzy logic rule base for distributed decision making with wide area performance sensors 10 and policy control actuators.
Reference: [15] <author> Kwan, T. T., McGrath, R. E., and Reed, D. A. </author> <title> NCSA's World Wide Web Server: Design and Performance. </title> <journal> IEEE Computer (Nov. </journal> <year> 1995), </year> <pages> 68-74. </pages>
Reference-contexts: Even after clustering identifies a small number of processor representatives, the total data volume may remain high. As an example, when analyzing the performance of WWW servers <ref> [15] </ref>, we found it necessary to capture nearly fifty metrics on request types, processor, network, and memory usage to reliably identify performance problems. Principal component analysis and its statistical variant, projection pursuit [13], seek to identify a subset of the metrics that captures most of the statistical variation.
Reference: [16] <author> LeBlanc, T. J., and Markatos, E. P. </author> <title> Operating System Support for Adaptive Real-time Systems. </title> <booktitle> In Proceedings of the Seventh IEEE Workshop on Real-Time Operating Systems and Software (May 1990), </booktitle> <pages> pp. 1-10. </pages>
Reference-contexts: Each has exposed key research issues in performance measurement and analysis. Similarly, several systems have been built that support application behavior steering (i.e., guiding a computation toward interesting phenomena), though there have been fewer efforts to interactively steer or adaptively control application performance. Notable examples include Leblanc's <ref> [16] </ref> creation of an adaptive real-time system for robotic control that consists of a multiprocessor executing a group of adaptive cognitive tasks and Schwan et al's [9] development of adaptive control mechanisms based on a sensor/actuator model.
Reference: [17] <author> Leigh, J., Johnson, A., and DeFanti, T. CAVERN: </author> <title> Distributed Architecture for Supporting Persistence and Interoperability in Collaborative Virtual Environments. Virtual Reality Research, </title> <booktitle> Development and Applications 2, </booktitle> <month> 2 (Dec. </month> <year> 1997), </year> <pages> 217-237. </pages>
Reference-contexts: Performance data visualization has a long and storied history, though the explosion of interest in visualization of parallel system behavior can be traced to Seecube [5], Pablo [28] and ParaGraph [12]. Virtual environments for performance analysis [27] are less common, though emerging immersive systems for distributed collaboration <ref> [17] </ref> target many of the same problems. 5 Conclusions As parallel computing evolves from homogeneous parallel platforms and applications dominated by single algorithms to heterogeneous collections of parallel systems and multidisciplinary applications, performance measurement, analysis, and optimization problems continue to increase.
Reference: [18] <author> Loveman, D. B. </author> <title> High Performance Fortran. </title> <booktitle> IEEE Parallel & Distributed Technology 1, </booktitle> <month> 1 (February </month> <year> 1993), </year> <pages> 25-42. </pages>
Reference-contexts: Below, we describe the challenges implicit in such an approach and outline possible solutions. 3.1 Aggressive Optimization Performance variability and the effort required to write explicitly parallel code have long limited the widespread use of parallel systems. Data parallel languages, like High Performance Fortran (HPF) <ref> [18] </ref> and object-parallel models like parallel C ++ , have been proposed to lessen the parallel programming burden. Although higher level programming models can reduce programming effort and increase code portability, they guarantee neither performance portability across parallel architectures nor scalability across problem sizes or number of processors.
Reference: [19] <author> Madhyastha, T. M., and Reed, D. A. </author> <title> Exploiting Global Input/Output Access Pattern Classification. </title> <booktitle> In Proceedings of SC '97: High Performance Computing and Networking (San Jose, </booktitle> <address> Nov. 1997), </address> <publisher> IEEE Computer Society Press. </publisher>
Reference-contexts: Because the interactions between these applications and the file system software change during and across application executions <ref> [19] </ref>, it is difficult or impossible to determine a globally optimal input/output configuration or to statically configure runtime systems and resource management policies for parallel input/output. Hence, parallel input/output optimization provides an excellent test of an adaptive, closed loop control system like Autopilot. <p> PPFS II is designed to work atop either parallel systems or PC and workstation clusters, providing a flexible testbed for high-performance input/output experiments. To explore automatic, qualitative classification of resource use, we have developed a suite of trained artificial neural networks (ANNs) <ref> [19] </ref> and hidden Markov models (HMMs) [20] that are implemented as Autopilot sensors. ANNs can efficiently classify access streams in real-time. In contrast, HMMs build a probabilistic model of the access pattern using prior execution training. This generality allows HMMs to classify arbitrary access patterns.
Reference: [20] <author> Madhyastha, T. M., and Reed, D. A. </author> <title> Input/Output Access Pattern Classification Using Hidden Markov Models. </title> <booktitle> In Proceedings of the 15 Fifth Workshop on Input/Output in Parallel and Distributed Systems (San Jose, </booktitle> <address> CA, Nov. 1997), </address> <publisher> ACM Press, </publisher> <pages> pp. 57-67. </pages>
Reference-contexts: Experience has shown that matching resource policies to time varying application behavior can greatly increase application performance (e.g., tuning input/output policies for caching and prefetching can reduce application input/output costs by an order of magnitude <ref> [20] </ref>). Based on these observations, we believe the historical model of post-mortem performance analysis and optimization must be subsumed by a new model of real-time analysis and adaptive optimization. <p> PPFS II is designed to work atop either parallel systems or PC and workstation clusters, providing a flexible testbed for high-performance input/output experiments. To explore automatic, qualitative classification of resource use, we have developed a suite of trained artificial neural networks (ANNs) [19] and hidden Markov models (HMMs) <ref> [20] </ref> that are implemented as Autopilot sensors. ANNs can efficiently classify access streams in real-time. In contrast, HMMs build a probabilistic model of the access pattern using prior execution training. This generality allows HMMs to classify arbitrary access patterns. <p> Fuzzy logic seems promising, but new methods, such as neural networks and genetic algorithms, can also be used to learn control rules and select membership functions [24] Finally, while neural networks and hidden Markov models have proven useful for input/output characterization <ref> [20] </ref>, other application resource characterizations remain to be explored.
Reference: [21] <author> Malony, A. D., Reed, D. A., Arendt, J. W., Aydt, R. A., Grabas, D., and Totty, B. K. </author> <title> An Integrated Performance Data Collection Analysis, and Visualization System. </title> <booktitle> In Proceedings of the Fourth Conference on Hypercube Concurrent Computers and Applications (Monterey, </booktitle> <address> CA, </address> <month> Mar. </month> <year> 1989), </year> <institution> Association for Computing Machinery. </institution>
Reference-contexts: Exem--plars of this work include Couch's seminal Seecube system [5], ParaGraph [12], and our own Hyperview and Pablo toolkits <ref> [21, 28] </ref>. Although widely used to develop applications on early parallel systems, the increasingly complexity of parallel systems exposed several limitations of these toolkits. Perhaps the most obvious constraint was their limited scalability.
Reference: [22] <author> Mendes, C. L. </author> <title> Performance Scalability Prediction on Multicomputers. </title> <type> PhD thesis, </type> <institution> University of Illinois at Urbana-Champaign, </institution> <month> May </month> <year> 1997. </year>
Reference-contexts: Based on this observation, we have extended the Rice Fortran D95 compiler to emit performance scalability predictions <ref> [23, 22] </ref> for data parallel code. In this approach, the data parallel compiler translates data parallel code and generates a symbolic cost model for program execution time, representing the scalability of each fragment in the original data parallel source.
Reference: [23] <author> Mendes, C. L., Wang, J.-C., and Reed, D. A. </author> <title> Automatic Performance Prediction and Scalability Analysis for Data Parallel Programs. </title> <booktitle> In Proceedings of the CRPC Workshop on Data Layout and Performance Prediction (Houston, </booktitle> <month> April </month> <year> 1995). </year>
Reference-contexts: Based on this observation, we have extended the Rice Fortran D95 compiler to emit performance scalability predictions <ref> [23, 22] </ref> for data parallel code. In this approach, the data parallel compiler translates data parallel code and generates a symbolic cost model for program execution time, representing the scalability of each fragment in the original data parallel source.
Reference: [24] <author> Meredith, D. L., Karr, C. L., and Kamur, K. K. </author> <title> The Use of Genetic Algorithms in the Design of Fuzzy Logic Controllers. </title> <booktitle> 3rd Workshop on Neural Networks WNN'92 (1992), </booktitle> <pages> 549-545. </pages>
Reference-contexts: Currently, there are no formal methods or useful tools that support creation and validation of rule sets for adaptive control. Fuzzy logic seems promising, but new methods, such as neural networks and genetic algorithms, can also be used to learn control rules and select membership functions <ref> [24] </ref> Finally, while neural networks and hidden Markov models have proven useful for input/output characterization [20], other application resource characterizations remain to be explored.
Reference: [25] <author> Miller, B. P., Callaghan, M. D., Cargille, J. M., Hollingsworth, J. K., Irvin, R. B., Karavanic, K. L., Kunchitha-padam, K., and Newhall, T. </author> <title> The Paradyn Parallel Performance Measurement Tools. </title> <booktitle> IEEE Computer 28, </booktitle> <month> 11 (November </month> <year> 1995), </year> <pages> 37-46. </pages>
Reference-contexts: Notable examples include P 3 T [10] for performance prediction, together with Paradyn <ref> [25] </ref> and AIMS [36] for performance measurement. Each has exposed key research issues in performance measurement and analysis. Similarly, several systems have been built that support application behavior steering (i.e., guiding a computation toward interesting phenomena), though there have been fewer efforts to interactively steer or adaptively control application performance.
Reference: [26] <author> Nickolayev, O. Y., Roth, P. C., and Reed, D. A. </author> <title> Real-time Statistical Clustering for Event Trace Reduction. </title> <booktitle> International Journal of Supercomputer Applications and High Performance Computing (1997). </booktitle>
Reference-contexts: Following <ref> [26] </ref>, if R i denotes the range of metric m i (t), we call the Cartesian product M = R 1 fi R 2 fi ::: fi R n a performance metric space. <p> By periodically computing cluster membership using performance metrics from each processor, an event tracing system can capture and extract traces only from representative members of each cluster, dramatically reducing the total data volume <ref> [26] </ref>. As an example of the possible data reduction due to statistical clustering, consider an SPMD code that relies on a master task to read initialization data and allocate work to a set of N worker tasks. <p> is similar, clustering identifies two clusters, one with cardinality one (the master) and a second with cardinality N (the workers), yielding a total data reduction of nearly N . to event traces from a 128 processor execution of a Hartree Fock quantum chemistry code on the In-tel Paragon XP/S; see <ref> [26] </ref> for details.
Reference: [27] <author> Osawa, N. </author> <title> An Enhanced 3-D Animation Tool for Performance Tuning of Parallel Programs based on Dynamic Models. </title> <booktitle> In Proceedings of the Symposium on Parallel and Distributed Tools (July 1998). </booktitle>
Reference-contexts: Performance data visualization has a long and storied history, though the explosion of interest in visualization of parallel system behavior can be traced to Seecube [5], Pablo [28] and ParaGraph [12]. Virtual environments for performance analysis <ref> [27] </ref> are less common, though emerging immersive systems for distributed collaboration [17] target many of the same problems. 5 Conclusions As parallel computing evolves from homogeneous parallel platforms and applications dominated by single algorithms to heterogeneous collections of parallel systems and multidisciplinary applications, performance measurement, analysis, and optimization problems continue to
Reference: [28] <author> Reed, D. A., Aydt, R. A., Noe, R. J., Roth, P. C., Shields, K. A., Schwartz, B., and Tavera, L. F. </author> <title> Scalable Performance Analysis: The Pablo Performance Analysis Environment. </title> <booktitle> In Proceedings of the Scalable Parallel Libraries Conference (1993), </booktitle> <editor> A. Skjellum, Ed., </editor> <publisher> IEEE Computer Society. </publisher>
Reference-contexts: Exem--plars of this work include Couch's seminal Seecube system [5], ParaGraph [12], and our own Hyperview and Pablo toolkits <ref> [21, 28] </ref>. Although widely used to develop applications on early parallel systems, the increasingly complexity of parallel systems exposed several limitations of these toolkits. Perhaps the most obvious constraint was their limited scalability. <p> Following execution, performance data from each processor is integrated, additional statistics are computed, and the resulting metrics are correlated with application source code, creating a performance file that is represented via the Pablo self-describing data format (SDDF) <ref> [28] </ref>. This performance file is the specification used by the SvPablo browser to display application source code and correlated performance metrics. Using the Pablo SDDF metaformat has enabled us to develop a user interface that is both portable and language independent. <p> Performance data visualization has a long and storied history, though the explosion of interest in visualization of parallel system behavior can be traced to Seecube [5], Pablo <ref> [28] </ref> and ParaGraph [12].
Reference: [29] <author> Reed, D. A., Elford, C. L., Madhyastha, T., Scullin, W. H., Aydt, R. A., and Smirni, E. </author> <title> I/O, Performance Analysis, and Performance Data Immersion. </title> <booktitle> In Proceedings of MASCOTS '96 (Feb. </booktitle> <year> 1996), </year> <pages> pp. 1-12. </pages>
Reference-contexts: As part of the SIO Initiative, we have extended the Pablo performance analysis toolkit to capture parallel application input/output patterns and file system responses and to compute I/O-specific performance metrics. The most significant observation from studies using this instrumentation <ref> [6, 34, 29, 30, 34, 33] </ref> is that scientific applications have input/output patterns and requirements more complex than simple stereotypes.
Reference: [30] <author> Reed, D. A., Gardner, M. J., and Smirni, E. </author> <title> Performance Visualization: 2-D, 3-D, and Beyond. </title> <booktitle> In Proceedings of the IEEE International Computer Performance and Dependability Symposium (Sept. </booktitle> <year> 1996). </year>
Reference-contexts: As part of the SIO Initiative, we have extended the Pablo performance analysis toolkit to capture parallel application input/output patterns and file system responses and to compute I/O-specific performance metrics. The most significant observation from studies using this instrumentation <ref> [6, 34, 29, 30, 34, 33] </ref> is that scientific applications have input/output patterns and requirements more complex than simple stereotypes.
Reference: [31] <author> Reed, D. A., Shields, K. A., Tavera, L. F., Scullin, W. H., and Elford, C. L. </author> <title> Virtual Reality and Parallel Systems Performance Analysis. </title> <journal> IEEE Computer (Nov. </journal> <year> 1995), </year> <pages> 57-67. </pages>
Reference-contexts: These beliefs are buttressed by our experience with virtual environment visualization of WWW traffic and parallel input/output <ref> [31] </ref>. Below, we describe the design of Virtue, a collaborative environment for immersive performance analysis that embodies these design components. At present, a prototype of Virtue is operational, supporting three-dimensional visualization in the CAVE [7], but much work remains to complete implementation of all design components. 12 Hierarchy and Abstraction.
Reference: [32] <author> Simitci, H., and Reed, D. A. </author> <title> A Comparison of Logical and Physical Parallel I/O Patterns. International Journal of Supercomputer Applications and High Performance Computing (to appear 1998). </title>
Reference-contexts: Driven by the output of decision procedures, actuators have many of the same properties as sensors, including local computation and distributed activation. 3.4.2 Adaptive Parallel File Systems As our extensive analysis of input/output dynamics <ref> [6, 35, 32] </ref> has shown, the parallel input/output patterns in emerging applications are both irregular and dynamic.
Reference: [33] <author> Smirni, E., Elford, C. L., and Reed, D. A. </author> <title> Performance Modeling of a Parallel I/O System: An Application Driven Approach. </title> <booktitle> In Proceedings of the Eighth SIAM Conference on Parallel Processing for Scientific Computing (Mar. </booktitle> <year> 1997). </year>
Reference-contexts: As part of the SIO Initiative, we have extended the Pablo performance analysis toolkit to capture parallel application input/output patterns and file system responses and to compute I/O-specific performance metrics. The most significant observation from studies using this instrumentation <ref> [6, 34, 29, 30, 34, 33] </ref> is that scientific applications have input/output patterns and requirements more complex than simple stereotypes.
Reference: [34] <author> Smirni, E., and Reed, D. A. </author> <title> I/O Requirements of Scientific Applications: An Evolutionary View. </title> <booktitle> In Proceedings of the Fifth IEEE International Symposium on High-Performance Distributed Computing (Aug. </booktitle> <year> 1996), </year> <pages> pp. 49-59. </pages>
Reference-contexts: As part of the SIO Initiative, we have extended the Pablo performance analysis toolkit to capture parallel application input/output patterns and file system responses and to compute I/O-specific performance metrics. The most significant observation from studies using this instrumentation <ref> [6, 34, 29, 30, 34, 33] </ref> is that scientific applications have input/output patterns and requirements more complex than simple stereotypes.
Reference: [35] <author> Smirni, E., and Reed, D. A. </author> <title> Workload Characterization of Input/Output Intensive Parallel Applications. </title> <booktitle> In Proceedings of the 9th International Conference on Modelling Techniques and Tools for Computer Performance Evaluation (June 1997). </booktitle>
Reference-contexts: Driven by the output of decision procedures, actuators have many of the same properties as sensors, including local computation and distributed activation. 3.4.2 Adaptive Parallel File Systems As our extensive analysis of input/output dynamics <ref> [6, 35, 32] </ref> has shown, the parallel input/output patterns in emerging applications are both irregular and dynamic.
Reference: [36] <author> Yan, J. C., Sarukkai, S. R., and Mehra, P. </author> <title> Performance Measurement, Visualization and Modeling of Parallel and Distributed Programs using the AIMS Toolkit. </title> <journal> Software Practice & Experience 25, </journal> <month> 4 (April </month> <year> 1995), </year> <pages> 429-461. </pages>
Reference-contexts: Notable examples include P 3 T [10] for performance prediction, together with Paradyn [25] and AIMS <ref> [36] </ref> for performance measurement. Each has exposed key research issues in performance measurement and analysis. Similarly, several systems have been built that support application behavior steering (i.e., guiding a computation toward interesting phenomena), though there have been fewer efforts to interactively steer or adaptively control application performance.
Reference: [37] <author> Zagha, M., Larson, B., Turner, S., and Itzkowitz, M. </author> <title> Performance Analysis Using the MIPS R10000 Performance Counters. </title> <booktitle> In Proceedings of Supercomputing'96 (November 1996). </booktitle>
Reference-contexts: Sv-Pablo supports performance data capture, analysis, and presentation for applications written in a variety of languages and executing on both sequential and parallel systems. In addition, SvPablo integrates data from the hardware performance counters <ref> [37] </ref> on the MIPS R10000 and SGI Origin 2000. The SvPablo implementation relies on a single user interface for performance instrumentation and visualization.
References-found: 37

