URL: ftp://ftp.cs.dartmouth.edu/TR/TR94-235.ps.Z
Refering-URL: http://www.cs.dartmouth.edu/reports/abstracts/TR94-235/
Root-URL: http://www.cs.dartmouth.edu
Author: David Kotz 
Date: 7, 1994  
Note: November  
Abstract: Available at URL ftp://ftp.cs.dartmouth.edu/pub/CS-techreports/TR94-235.ps.Z A DAta-Parallel Programming Library for Education (DAPPLE) Technical Report PCS-TR94-235 Department of Computer Science Dartmouth College Hanover, NH 03755-3510 dfk@cs.dartmouth.edu Abstract In the context of our overall goal to bring the concepts of parallel computing into the undergraduate curriculum, we set out to find a parallel-programming language for student use. To make it accessible to students at all levels, and to be independent of any particular hardware platform, we chose to design our own language, based on a data-parallel model and on C++. The result, DAPPLE, is a C++ class library designed to provide the illusion of a data-parallel programming language on conventional hardware and with conventional compilers. DAPPLE defines Vectors and Matrices as basic classes, with all the usual C++ operators overloaded to provide elementwise arithmetic. In addition, DAPPLE provides typical data-parallel operations like scans, permutations, and reductions. Finally, DAPPLE provides a parallel if-then-else statement to restrict the scope of the above operations to partial vectors or matrices.
Abstract-found: 1
Intro-found: 1
Reference: [BBG + 93] <author> Fran~cois Bodin, Peter Beckman, Denis Gannon, Srinivas Narayana, and Shelby X. Yang. </author> <title> Distributed pC++: basic ideas for an object parallel language. </title> <journal> Scientific Programming, </journal> <volume> 2(3), </volume> <month> Fall </month> <year> 1993. </year>
Reference-contexts: We found many research projects designing parallel C++ variants. C** [LRV92] is perhaps the closest candidate, in that it supports a data-parallel model, but it requires a new compiler and is not yet available. pC++ <ref> [BBG + 93] </ref> can also provide a data-parallel model, using only a preprocessor and library, but its syntax is a little complicated for beginners. Other data-parallel options like Presto++ [Kil92] and Compositional C++ [CK92] are also rather complex for beginners.
Reference: [Ble93] <author> Guy E. Blelloch. NESL: </author> <title> a nested data-parallel language. </title> <type> Technical Report CMU-CS-93-129, </type> <institution> Carnegie Mellon University, </institution> <month> April </month> <year> 1993. </year>
Reference-contexts: Although many data-parallel languages exist, including C*, Fortran90, NESL <ref> [Ble93] </ref>, and HPF [Lov93], they are difficult to use, are not similar to C++, or are not easily portable to student computers. We found many research projects designing parallel C++ variants. <p> It restricts the context to the left partition and recurses, and then restricts the context to the right partition and recurses. The quicksort example demonstrates one weakness of DAPPLE, its inability to support nested data parallelism <ref> [Ble93] </ref>. The two recursive calls to quicksort () must be done sequentially, each with only a small subset of the virtual processors active. Given this model, other sorting algorithms would be more appropriate.
Reference: [CGH94] <author> Rohit Chandra, Anoop Gupta, and John L. Hennessey. </author> <title> COOL: an object-based language for parallel programming. </title> <journal> IEEE Computer, </journal> <volume> 27(8) </volume> <pages> 14-26, </pages> <month> August </month> <year> 1994. </year>
Reference-contexts: Other data-parallel options like Presto++ [Kil92] and Compositional C++ [CK92] are also rather complex for beginners. Others, like Mentat [Gri93], CHARM++ [KK93], and COOL <ref> [CGH94] </ref>, are more task-parallel than data-parallel. Finding no suitable existing language, we decided to design and implement our own language as a set of macros and classes that extended C++. The result is DAPPLE, a DAta-Parallel Programming Library for Education.
Reference: [CK92] <author> K. Mani Chandy and Carl Kesselman. </author> <title> Compositional C++: Compositional parallel programming. </title> <type> Technical Report CS-TR-92-13, </type> <institution> California Institute of Technology, </institution> <year> 1992. </year>
Reference-contexts: Other data-parallel options like Presto++ [Kil92] and Compositional C++ <ref> [CK92] </ref> are also rather complex for beginners. Others, like Mentat [Gri93], CHARM++ [KK93], and COOL [CGH94], are more task-parallel than data-parallel. Finding no suitable existing language, we decided to design and implement our own language as a set of macros and classes that extended C++.
Reference: [ES90] <author> Margaret A. Ellis and Bjarne Stroustrup. </author> <title> The Annotated C++ Reference Manual. </title> <publisher> Addison-Wesley, </publisher> <year> 1990. </year> <title> Ninth printing. </title>
Reference-contexts: The functional style makes it easier to compose operations, e.g., B = shift (B,1) + B + shift (B,-1), than if shift () modified B. Recommended by the ARM <ref> [ES90, page 249] </ref>, the functional syntax shift (B,1) makes it clear that the operand B is not modified, while in B.shift (1) it is not as clear.
Reference: [Gri93] <author> Andrew S. Grimshaw. </author> <title> Easy-to-use object-oriented parallel processing with Mentat. </title> <journal> IEEE Computer, </journal> <volume> 26(5) </volume> <pages> 39-51, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: Other data-parallel options like Presto++ [Kil92] and Compositional C++ [CK92] are also rather complex for beginners. Others, like Mentat <ref> [Gri93] </ref>, CHARM++ [KK93], and COOL [CGH94], are more task-parallel than data-parallel. Finding no suitable existing language, we decided to design and implement our own language as a set of macros and classes that extended C++. The result is DAPPLE, a DAta-Parallel Programming Library for Education.
Reference: [JKM94] <author> Donald Johnson, David Kotz, and Fillia Makedon. </author> <title> Teaching parallel computing to freshmen. </title> <booktitle> In Conference on Parallel Computing for Undergraduates. </booktitle> <address> Colgate University, </address> <month> June </month> <year> 1994. </year>
Reference-contexts: We believe parallelism should be introduced early in the curriculum, before the habits of sequential thinking are ingrained. Indeed, we are preparing to teach it to freshmen in CS2 <ref> [JKM94] </ref>. <p> We are fine-tuning the language and implementation for use in a parallel-computing course later this year <ref> [JKM94] </ref>. DAPPLE should be useful beyond that course, however, in other courses and in other institutions. DAPPLE currently runs on DECstation 5000 workstations with Ultrix and the g++ compiler, and we are porting it to other Unix workstations (Sun, SGI, and DEC Alpha) and to the Macintosh (using Symantec C++).
Reference: [Kil92] <author> Michael F. Kilian. </author> <title> Parallel Sets: An Object-oriented Methodology for Massively Parallel Programming. </title> <type> PhD thesis, </type> <institution> Harvard University, </institution> <year> 1992. </year>
Reference-contexts: Other data-parallel options like Presto++ <ref> [Kil92] </ref> and Compositional C++ [CK92] are also rather complex for beginners. Others, like Mentat [Gri93], CHARM++ [KK93], and COOL [CGH94], are more task-parallel than data-parallel. Finding no suitable existing language, we decided to design and implement our own language as a set of macros and classes that extended C++.
Reference: [KK93] <author> L.V. Kale and Sanjeev Krishnan. CHARM++: </author> <title> A portable concurrent object oriented system based on C++. </title> <booktitle> In Proceedings of the Conference on Object Oriented Programming Systems, Languages and Applications, </booktitle> <year> 1993. </year>
Reference-contexts: Other data-parallel options like Presto++ [Kil92] and Compositional C++ [CK92] are also rather complex for beginners. Others, like Mentat [Gri93], CHARM++ <ref> [KK93] </ref>, and COOL [CGH94], are more task-parallel than data-parallel. Finding no suitable existing language, we decided to design and implement our own language as a set of macros and classes that extended C++. The result is DAPPLE, a DAta-Parallel Programming Library for Education.

Reference: [LRV92] <author> James R. Larus, Brad Richards, and Guhan Viswanathan. </author> <title> C**: A large-grain, object-oriented, data-parallel programming language. </title> <type> Technical Report #1126, </type> <institution> University of Wisconsin-Madison, </institution> <month> November </month> <year> 1992. </year>
Reference-contexts: Although many data-parallel languages exist, including C*, Fortran90, NESL [Ble93], and HPF [Lov93], they are difficult to use, are not similar to C++, or are not easily portable to student computers. We found many research projects designing parallel C++ variants. C** <ref> [LRV92] </ref> is perhaps the closest candidate, in that it supports a data-parallel model, but it requires a new compiler and is not yet available. pC++ [BBG + 93] can also provide a data-parallel model, using only a preprocessor and library, but its syntax is a little complicated for beginners. <p> P; r++) C [r][c] = inner (A [r][_], B [_][c]); cout &lt;< C; intMatrix D (P,R); // D is what C should be cin &gt;> D; cout &lt;< "The answers are different!" &lt;< endl; else cout &lt;< "The answers are the same." &lt;< endl; 5 to work with matrix slices <ref> [LRV92] </ref>. Here, A [r][_] is a row slice, representing row r of matrix A, and B [_][c] is a column slice, representing column c of matrix B. Slices may be used anywhere vectors may be used, including on the left-hand side of an assignment operator.
Reference: [Mil94] <editor> Russ Miller. </editor> <booktitle> The status of parallel processing education. IEEE Computer, </booktitle> <pages> pages 40-43, </pages> <month> August </month> <year> 1994. </year>
Reference-contexts: 1 Introduction Parallel computing, having been considered an advanced topic suitable only for graduate students, is slowly migrating into the undergraduate curriculum <ref> [Mil94] </ref>. We believe parallelism should be introduced early in the curriculum, before the habits of sequential thinking are ingrained. Indeed, we are preparing to teach it to freshmen in CS2 [JKM94].
References-found: 11

