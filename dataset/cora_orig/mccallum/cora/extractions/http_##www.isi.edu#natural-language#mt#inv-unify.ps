URL: http://www.isi.edu/natural-language/mt/inv-unify.ps
Refering-URL: http://www.isi.edu/natural-language/GAZELLE.html
Root-URL: 
Email: knight@isi.edu  
Title: Learning Word Meanings by Instruction  
Author: Kevin Knight 
Address: 4676 Admiralty Way Marina del Rey, CA 90292  
Affiliation: Information Sciences Institute and Computer Science Department University of Southern California  
Abstract: We develop techniques for learning the meanings of unknown words in context. Working within a compositional semantics framework, we write down equations in which a sentence's meaning is some combination function of the meaning of its words. When one of the words is unknown, we ask for a paraphrase of the sentence. We then compute the meaning of the unknown word by inverting parts of the semantic combination function. This technique can be used to learn word-concept mappings, decomposed meanings, and mappings between syntactic and semantic roles. It works for all parts of speech. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Ait-Kaci, H. </author> <year> 1984. </year> <title> A Lattice Theoretic Approach to Computation Based on a Calculus of Partially Ordered Type Structures. </title> <type> Ph.D. Thesis, </type> <institution> University of Pennsylvania. </institution>
Reference: <author> Anderson, J. R. </author> <year> 1977. </year> <title> Induction of augmented transition networks. </title> <booktitle> Cognitive Science 1. </booktitle>
Reference: <author> Bresnan, J., and Kaplan, R. </author> <year> 1982. </year> <title> Lexical-Functional Grammar: a formal system for grammatical representation. </title> <editor> In Bresnan, J., ed., </editor> <title> The Mental Representation of Grammatical Relations. </title> <publisher> MIT Press (Cam-bridge, </publisher> <address> MA). </address>
Reference: <author> Carbonell, J. </author> <year> 1979. </year> <title> Towards a self-extending parser. </title> <booktitle> In Proc. ACL. </booktitle>
Reference-contexts: Another approach is Explanation-Based Learning (EBL), which might also be called Expectation-Based Learning. If a system has very strong expectations (scriptal or semantic) about what will be uttered to it, then it can figure out the meanings of unknown words. One example of this approach is <ref> (Carbonell 1979) </ref>. This system parses a sentence like Russia sent massive arms shipments to the MPLA in Angola with unknown word MPLA. Using its script-based knowledge of international relations, the system concludes that the MPLA is an Angolan communist political faction| or else a location inside Angola.
Reference: <author> Carpenter, B. </author> <year> 1992. </year> <title> The Logic of Typed Feature Structures, </title> <booktitle> volume 32 of Tracts in Theoretical Computer Science. </booktitle> <address> Cambridge: </address> <publisher> Cambridge University Press. </publisher>
Reference: <author> Chierchia, G., and McConnell-Ginet, S. </author> <year> 1990. </year> <title> Meaning and Grammar: An Introduction to Semantics. </title> <publisher> The MIT Press. </publisher>
Reference-contexts: So we need a database of word meanings and a set of functions to combine word and phrase meanings. These functions can be specified declaratively and applied with a handful of meta-operators. The lambda calculus is commonly used for representing semantic functions and data <ref> (Chierchia & McConnell-Ginet 1990) </ref>. A flexible implementation popular in computational circles is via graphs and graph unification. (Moore 1989) gives descriptions of these notational systems. We will assume that word meanings and combination functions are all represented as labeled, directed acyclic graphs.
Reference: <author> Dalrymple, M.; Shieber, S.; and Periera, F. </author> <year> 1991. </year> <title> Ellipsis and higher-order unification. </title> <booktitle> Linguistics and Philosophy 14(4). </booktitle>
Reference-contexts: Other related work includes that on unification-based generation (Shieber et al. 1989) and on higher-order unification. Higher-order unification has been used to encode equations that provide solutions to the interpretation of ellipsis <ref> (Dalrymple, Shieber, & Periera 1991) </ref>, and it would be useful to explore how this relates to our inversion algorithm. Formal analysis of complexity and completeness would also be valuable.
Reference: <author> Dowding, J.; Gawron, J.; Appelt, D.; Bear, J.; Cherny, L.; Moore, R.; and Moran, D. </author> <year> 1993. </year> <title> Gem-ini: A natural language system for spoken-language understanding. </title> <booktitle> In Human Language Technology: Proc. ARPA Human Language Technology Workshop. Plainsboro, NJ: ARPA. </booktitle>
Reference-contexts: Semantic Framework This section lays out the framework for semantic interpretation that we will assume. The framework is well known, simple, and concrete, allowing us to specify new algorithms in detail. It is also one that is used in practical natural language systems like <ref> (Dowding et al. 1993) </ref> and (Knight et al. 1995). In the tradition of Montague (Dowty, Wall, & Peters 1981), we adopt a compositional semantics, in which the meaning of a sentence is a function of the meanings of its parts. Those parts are phrases and, ultimately, words.
Reference: <author> Dowty, D. R.; Wall, R.; and Peters, S. </author> <year> 1981. </year> <title> Introduction to Montague Semantics. </title> <publisher> Dordrecht: Reidel. </publisher>
Reference-contexts: The framework is well known, simple, and concrete, allowing us to specify new algorithms in detail. It is also one that is used in practical natural language systems like (Dowding et al. 1993) and (Knight et al. 1995). In the tradition of Montague <ref> (Dowty, Wall, & Peters 1981) </ref>, we adopt a compositional semantics, in which the meaning of a sentence is a function of the meanings of its parts. Those parts are phrases and, ultimately, words.
Reference: <author> Granger, R. </author> <year> 1977. </year> <title> Foulup: A program that figures out meanings of words from context. </title> <booktitle> In Proc. IJCAI. </booktitle>
Reference-contexts: Using its script-based knowledge of international relations, the system concludes that the MPLA is an Angolan communist political faction| or else a location inside Angola. Carbonell considers using IL to gradually converge on a single meaning, but opts instead for a guess-and-recover strategy. <ref> (Granger 1977) </ref> is another piece of work in this area. He considers sentences like I woke up yesterday, turned off my alarm clock, took a shower, and cooked myself two grimps for breakfast. Again, EBL can help us find a rough meaning for the unknown word grimp.
Reference: <author> Haas, J., and Jayaraman, B. </author> <year> 1993. </year> <title> From context-free to definite-clause grammars: A type-theoretic approach. </title> <journal> Journal of Logic Programming 12(1). </journal>
Reference: <author> Hatzivassiloglou, V., and McKeown, K. </author> <year> 1993. </year> <title> Towards the automatic identification of adjectival scales: Clustering adjectives according to meaning. </title> <booktitle> In Proc. ACL. </booktitle>
Reference: <author> Jacobs, P., and Zernik, U. </author> <year> 1988. </year> <title> Acquiring lexical knowledge from text: A case study. </title> <booktitle> In Proc. </booktitle> <publisher> AAAI. </publisher>
Reference: <author> Karttunen, L. </author> <year> 1986. </year> <title> Radical lexicalism. </title> <type> Tech. Report CSLI-86-68, </type> <institution> Center for the Study of Language and Information. </institution>
Reference: <author> Kasper. </author> <year> 1987. </year> <title> Feature Structures: A Logical Theory with Application to Language Analysis. </title> <type> Ph.D. Thesis, </type> <institution> University of Michigan. </institution>
Reference: <author> Knight, K.; Chander, I.; Haines, M.; Hatzivassiloglou, V.; Hovy, E.; Iida, M.; Luk, S. K.; Whitney, R.; and Yamada, K. </author> <year> 1995. </year> <title> Filling knowledge gaps in a broad-coverage MT system. </title> <booktitle> In Proc. IJCAI. </booktitle>
Reference-contexts: Semantic Framework This section lays out the framework for semantic interpretation that we will assume. The framework is well known, simple, and concrete, allowing us to specify new algorithms in detail. It is also one that is used in practical natural language systems like (Dowding et al. 1993) and <ref> (Knight et al. 1995) </ref>. In the tradition of Montague (Dowty, Wall, & Peters 1981), we adopt a compositional semantics, in which the meaning of a sentence is a function of the meanings of its parts. Those parts are phrases and, ultimately, words.
Reference: <author> Langley, P. </author> <year> 1982. </year> <title> Language acquisition through error recovery. </title> <journal> Cognition and Brain Theory 5(3). </journal>
Reference: <author> Moore, R. </author> <year> 1989. </year> <title> Unification-based semantic interpretation. </title> <booktitle> In Proc. ACL. </booktitle>
Reference-contexts: These functions can be specified declaratively and applied with a handful of meta-operators. The lambda calculus is commonly used for representing semantic functions and data (Chierchia & McConnell-Ginet 1990). A flexible implementation popular in computational circles is via graphs and graph unification. <ref> (Moore 1989) </ref> gives descriptions of these notational systems. We will assume that word meanings and combination functions are all represented as labeled, directed acyclic graphs. We also assume that a syntactic analysis precedes semantic processing.
Reference: <author> Pereira, F. C. N.; Tishby, N. Z.; and Lee, L. </author> <year> 1993. </year> <title> Distributional clustering of English words. </title> <booktitle> In Proc. ACL. </booktitle> <address> Harriman, New York: </address> <publisher> Morgan Kaufman. </publisher>
Reference: <author> Pollard, C., and Sag, I. </author> <year> 1994. </year> <title> Head Driven Phrase Structure Grammar. </title> <publisher> University of Chicago Press. </publisher>
Reference-contexts: There are other analyses. In particular, our method of discharging verb-argument features is not the best; see <ref> (Pollard & Sag 1994) </ref> for another treatment. Also note that we handle the subject-control facts of the verb wants during semantic interpretation; however, our role-filling takes the key syntactic processes into account.
Reference: <author> Reeker, L. H. </author> <year> 1976. </year> <title> The computational study of language acquisition. </title> <booktitle> Advances in Computers 15. </booktitle>
Reference: <author> Robinson, J. A. </author> <year> 1965. </year> <title> A machine-oriented logic based on the resolution principle. </title> <journal> Journal of the ACM 12(1). </journal>
Reference: <author> Shieber, S. M.; van Noord, G.; Moore, R. C.; and Pereira, F. C. N. </author> <year> 1989. </year> <title> A semantic-head-driven generation algorithm for unification based formalisms. </title> <booktitle> In Proc. ACL. </booktitle>
Reference-contexts: Combining inductive and instructive approaches to language learning is an open and potentially very interesting area of research. Other related work includes that on unification-based generation <ref> (Shieber et al. 1989) </ref> and on higher-order unification. Higher-order unification has been used to encode equations that provide solutions to the interpretation of ellipsis (Dalrymple, Shieber, & Periera 1991), and it would be useful to explore how this relates to our inversion algorithm.
Reference: <author> Shieber, S. </author> <year> 1986. </year> <title> An Introduction to Unification-Based Approaches to Grammar. </title> <institution> University of Chicago. </institution> <note> Also, CSLI Lecture Notes Series. </note>
Reference: <author> Thompson, C. </author> <year> 1995. </year> <title> Acquisition of a lexicon from semantic representations of sentences. </title> <booktitle> In Proc. ACL, Student Session. </booktitle>
Reference-contexts: Previous work in this vein includes (Reeker 1976; Anderson 1977; Langley 1982). We have attempted to strip away the assumptions and heuristics used by these systems, and to provide a simple algorithm suited to modern computational linguistic methods, both practical and theoretical. More recent work by <ref> (Thompson 1995) </ref> is also aimed at learning lexical semantics; it works by induction rather than instruction, and it does not yet deal with case-role mappings. Combining inductive and instructive approaches to language learning is an open and potentially very interesting area of research.
Reference: <author> Zernik, U. </author> <year> 1987. </year> <title> Language acquisition: Learning a hierarchy of phrases. </title> <booktitle> In Proc. IJCAI. </booktitle>
References-found: 26

