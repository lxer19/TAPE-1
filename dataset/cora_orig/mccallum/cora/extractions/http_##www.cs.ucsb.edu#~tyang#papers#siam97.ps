URL: http://www.cs.ucsb.edu/~tyang/papers/siam97.ps
Refering-URL: http://www.cs.ucsb.edu/Research/rapid_sweb/RAPID.html
Root-URL: http://www.cs.ucsb.edu
Title: A Comparison of 1-D and 2-D Data Mapping for Sparse LU Factorization with Partial Pivoting  
Author: Cong Fu Xiangmin Jiao Tao Yang 
Abstract: This paper presents a comparative study of two data mapping schemes for parallel sparse LU factorization with partial pivoting on distributed memory machines. Our previous work has developed an approach that incorporates static symbolic factorization, nonsymmetric L/U supernode partitioning and graph scheduling for this problem with 1-D column-block mapping. The 2-D mapping is commonly considered more scalable for general matrix computation but is difficult to be efficiently incorporated with sparse LU because partial pivoting and row interchanges require frequent synchronized inter-processor communication. We have developed an asynchronous sparse LU algorithm using 2-D block mapping, and obtained competitive performance on Cray-T3D. We report our preliminary studies on speedups, scalability, communication cost and memory requirement of this algorithm and compare it with the 1-D approach.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> C. Ashcraft, R. Grimes, J. Lewis, B. Peyton, and H. Simon, </author> <title> Progress in Sparse Matrix Methods for Large Sparse Linear Systems on Vector Supercomputers, </title> <journal> International Journal of Supercomputer Applications, </journal> <volume> 1 (1987), </volume> <pages> pp. 10-30. </pages>
Reference-contexts: In the literature 2-D mapping has been shown more scalable than 1-D for dense LU factorization and sparse Cholesky [13, 14]. In [10] a sparse solver with element-wise 2-D mapping is presented. For better cache performance, block partitioning is preferred <ref> [1] </ref>. However there are several difficulties to apply the 2-D block-oriented mapping to the case of sparse LU factorization even the static structure is predicted in advance.
Reference: [2] <author> J. Demmel, </author> <title> Numerical Linear Algebra on Parallel Processors. </title> <booktitle> Lecture Notes for NSF-CBMS Regional Conference in the Mathematical Sciences, </booktitle> <month> June </month> <year> 1995. </year>
Reference-contexts: The pivoting sequence is held until the factorization of the k-th panel is completed. Then the pivoting sequence is applied to the rest of the matrix. This is called "delayed pivoting" <ref> [2] </ref>. The F actor () tasks mainly use BLAS-1 and BLAS-2 subroutines. 2) Task U pdate (k; j) is to use panel k to modify panel j.
Reference: [3] <author> C. Fu and T. Yang, </author> <title> Run-time Compilation for Parallel Sparse Matrix Computations, </title> <booktitle> in Proceedings of ACM Inter. Conf. on Supercomputing, </booktitle> <address> Philadelphia, </address> <month> May </month> <year> 1996, </year> <pages> pp. </pages> <month> 237-244. </month> <title> [4] , Sparse LU Factorization with Partial Pivoting on Distributed Memory Machines, </title> <booktitle> in Proceedings of Supercomputing'96, </booktitle> <address> Pittsburgh, </address> <month> Nov. </month> <year> 1996. </year> <title> [5] , Space and Time Efficient Execution of Parallel Irregular Computation, </title> <note> 1997. In preparation. </note>
Reference-contexts: 1 Introduction Efficient parallelization for sparse LU factorization with pivoting is important to many scientific applications. Different from sparse Cholesky factorization, for which the parallelization problem has been relatively well solved <ref> [3, 8, 12, 13] </ref>, the sparse LU factorization is much harder to be parallelized due to its dynamic nature caused by pivoting operations. The previous work has addressed parallelization issues using shared memory platforms or restricted pivoting [6, 7, 9]. <p> [7] to eliminate the data structure variation caused by dynamic pivoting; 2)identify data regularity from the sparse structure obtained by the symbolic factorization so that efficient dense operations can be used to perform most of the computation; 3) make use of graph scheduling techniques and efficient run-time support called RAPID <ref> [3] </ref> to exploit irregular parallelism. The preliminary experiments are encouraging and good performance results are obtained with 1-D data mapping [4]. In the literature 2-D mapping has been shown more scalable than 1-D for dense LU factorization and sparse Cholesky [13, 14]. <p> The CA schedule tries to execute the pivoting tasks as early as possible since they are normally in the critical path of the computation. 4 * The 1-D RAPID code. This code uses a DAG to model irregular parallelism and the RAPID system <ref> [3] </ref> to schedule the tasks. Then RAPID will execute the DAG on a distributed memory machines using a low-overhead communication scheme. In [4], we show that the 1-D RAPID code outperforms the CA code because graph scheduling exploits the parallelism more aggressively. <p> In the CA algorithm, the extra memory requirement for communication is about Zb 2 (1 1=p). The 2-D algorithm needs about 2N b 2 buffer space. Thus the 2D algorithm is capable of solving large problem instances. The implementation of RAPID in <ref> [3] </ref> also requires that each processor have about Zb 2 (1 1=p) space for holding messages. * Communication volume. Assume at each stage, the probability for swapping rows (due to pivoting) across processors is q.
Reference: [6] <author> K. Gallivan, B. Marsolf, and H. Wijshoff, </author> <title> The Parallel Solution of Nonsymmetric Sparse Linear Systems using H* Reordering and an Assoicated Factorization, </title> <booktitle> in Proc. of ACM International Conference on Supercomputing, </booktitle> <address> Manchester, </address> <month> July </month> <year> 1994, </year> <pages> pp. 419-430. </pages>
Reference-contexts: The previous work has addressed parallelization issues using shared memory platforms or restricted pivoting <ref> [6, 7, 9] </ref>.
Reference: [7] <author> A. George and E. Ng, </author> <title> Parallel Sparse Gaussian Elimination with Partial Pivoting, </title> <journal> Annals of Operations Research, </journal> <volume> 22 (1990), </volume> <pages> pp. 219-240. </pages>
Reference-contexts: The previous work has addressed parallelization issues using shared memory platforms or restricted pivoting <ref> [6, 7, 9] </ref>. <p> The previous work has addressed parallelization issues using shared memory platforms or restricted pivoting [6, 7, 9]. In [4] we proposed a novel approach that integrates three key strategies together in parallelizing this algorithm on distributed memory machines: 1) adopt a static symbolic factorization scheme <ref> [7] </ref> to eliminate the data structure variation caused by dynamic pivoting; 2)identify data regularity from the sparse structure obtained by the symbolic factorization so that efficient dense operations can be used to perform most of the computation; 3) make use of graph scheduling techniques and efficient run-time support called RAPID [3] <p> In this section, we briefly discuss some techniques used in our S fl parallel sparse LU algorithm [4]. Static symbolic factorization. Static symbolic factorization is proposed in <ref> [7] </ref> to identify the worst case nonzero patterns. The basic idea is to statically consider all the possible pivoting choices at each step. And then the space is allocated for all the possible nonzeros that would be introduced by any pivoting sequence that could occur during the numerical factorization.
Reference: [8] <author> A. Gupta and V. Kumar, </author> <title> Optimally Scalable Parallel Sparse Cholesky Factorization, </title> <booktitle> in Proc. of 7th SIAM Conf. on Parallel Processing for Scientific Computing, </booktitle> <month> Feb. </month> <year> 1995, </year> <pages> pp. 442-447. </pages>
Reference-contexts: 1 Introduction Efficient parallelization for sparse LU factorization with pivoting is important to many scientific applications. Different from sparse Cholesky factorization, for which the parallelization problem has been relatively well solved <ref> [3, 8, 12, 13] </ref>, the sparse LU factorization is much harder to be parallelized due to its dynamic nature caused by pivoting operations. The previous work has addressed parallelization issues using shared memory platforms or restricted pivoting [6, 7, 9].
Reference: [9] <author> S. Hadfield and T. Davis, </author> <title> A Parallel Unsymmetric-pattern Multifrontal Method, </title> <type> Tech. Rep. </type> <institution> TR-94-028, CIS Departmenmt, University of Florida, </institution> <month> Aug. </month> <year> 1994. </year>
Reference-contexts: The previous work has addressed parallelization issues using shared memory platforms or restricted pivoting <ref> [6, 7, 9] </ref>.
Reference: [10] <author> S. C. Kothari and S. Mitra, </author> <title> A Scalable 2-D Parallel Sparse Solver , in Proc. </title> <booktitle> of Seventh SIAM Conference on Parallel Processing for Scientific Computing, </booktitle> <month> Feb. </month> <year> 1995, </year> <pages> pp. 424-429. </pages>
Reference-contexts: The preliminary experiments are encouraging and good performance results are obtained with 1-D data mapping [4]. In the literature 2-D mapping has been shown more scalable than 1-D for dense LU factorization and sparse Cholesky [13, 14]. In <ref> [10] </ref> a sparse solver with element-wise 2-D mapping is presented. For better cache performance, block partitioning is preferred [1]. However there are several difficulties to apply the 2-D block-oriented mapping to the case of sparse LU factorization even the static structure is predicted in advance.
Reference: [11] <author> X. Li, </author> <title> Sparse Gaussian Elimination on High Performance Computers , PhD thesis, </title> <type> CS, </type> <institution> UC Berkeley, </institution> <year> 1996. </year>
Reference-contexts: And then the space is allocated for all the possible nonzeros that would be introduced by any pivoting sequence that could occur during the numerical factorization. The static approach avoids data structure expansions during the numerical factorization. The dynamic factorization, which is used in an efficient sequential code SuperLU <ref> [11] </ref>, provides more accurate data structure prediction on the fly, but it is challenging to parallelize SuperLU on distributed memory machines. Currently the SuperLU group has been working on shared memory parallelizations [11]. L/U supernode partitioning. <p> The dynamic factorization, which is used in an efficient sequential code SuperLU <ref> [11] </ref>, provides more accurate data structure prediction on the fly, but it is challenging to parallelize SuperLU on distributed memory machines. Currently the SuperLU group has been working on shared memory parallelizations [11]. L/U supernode partitioning. After the nonzero fill-in patterns of a matrix is predicted, the matrix is further partitioned using a supernode approach to improve the cache performance. In [11], a nonsymmetric supernode is defined as a group of consecutive columns in which the corresponding L factor has a dense lower <p> Currently the SuperLU group has been working on shared memory parallelizations <ref> [11] </ref>. L/U supernode partitioning. After the nonzero fill-in patterns of a matrix is predicted, the matrix is further partitioned using a supernode approach to improve the cache performance. In [11], a nonsymmetric supernode is defined as a group of consecutive columns in which the corresponding L factor has a dense lower triangular block on the diagonal and the same nonzero pattern below the diagonal. Based on this definition, in each column block the L part only contains dense subrows.
Reference: [12] <author> E. Rothberg, </author> <title> Exploiting the Memory Hierarchy in Sequential and Parallel Sparse Cholesky Factorization , PhD thesis, </title> <institution> Dept. of Computer Science, Stanford, </institution> <month> Dec. </month> <year> 1992. </year>
Reference-contexts: 1 Introduction Efficient parallelization for sparse LU factorization with pivoting is important to many scientific applications. Different from sparse Cholesky factorization, for which the parallelization problem has been relatively well solved <ref> [3, 8, 12, 13] </ref>, the sparse LU factorization is much harder to be parallelized due to its dynamic nature caused by pivoting operations. The previous work has addressed parallelization issues using shared memory platforms or restricted pivoting [6, 7, 9]. <p> In 1-D column-block cyclic mapping, as illustrated in Figure 1 (b), a column-block A :;j is assigned to the same processor P j mod p , where p is the number of the processors. Each column-block is called a panel in <ref> [12] </ref>. A 2-D block cyclic mapping views the processors as a 2-D r fi s grid, and a block is the minimum unit for data mapping. A nonzero submatrix block A i;j is assigned to the processor P i mod r;j mod s as illustrated in Figure 1 (c).
Reference: [13] <author> E. Rothberg and R. Schreiber, </author> <title> Improved Load Distribution in Parallel Sparse Cholesky Factorization, </title> <booktitle> in Proc. of Supercomputing'94, </booktitle> <month> Nov. </month> <year> 1994, </year> <pages> pp. 783-792. </pages>
Reference-contexts: 1 Introduction Efficient parallelization for sparse LU factorization with pivoting is important to many scientific applications. Different from sparse Cholesky factorization, for which the parallelization problem has been relatively well solved <ref> [3, 8, 12, 13] </ref>, the sparse LU factorization is much harder to be parallelized due to its dynamic nature caused by pivoting operations. The previous work has addressed parallelization issues using shared memory platforms or restricted pivoting [6, 7, 9]. <p> The preliminary experiments are encouraging and good performance results are obtained with 1-D data mapping [4]. In the literature 2-D mapping has been shown more scalable than 1-D for dense LU factorization and sparse Cholesky <ref> [13, 14] </ref>. In [10] a sparse solver with element-wise 2-D mapping is presented. For better cache performance, block partitioning is preferred [1]. However there are several difficulties to apply the 2-D block-oriented mapping to the case of sparse LU factorization even the static structure is predicted in advance. <p> But on 64 processors the 2-D algorithm achieves 533.68 MFLOPS, better than the RAPID code which achieves 519.3 MFLOPS. We analyze the load balancing factor in Figure 3 (b). The load balance factor is defined as work total =(P work max ) <ref> [13] </ref>. Here we only count the work from the updating part 7 because it is the major part of the computation. The 2-D code has the best load balance, which can make up for the impact of lacking of efficient task scheduling.
Reference: [14] <author> R. Schreiber, </author> <title> Scalability of Sparse Direct Solvers, vol. 56 of Graph Theory and Sparse Matrix Computation (Edited by Alan George and John R. </title> <editor> Gilbert and Joseph W.H. Liu), </editor> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1993, </year> <pages> pp. 191-209. </pages>
Reference-contexts: The preliminary experiments are encouraging and good performance results are obtained with 1-D data mapping [4]. In the literature 2-D mapping has been shown more scalable than 1-D for dense LU factorization and sparse Cholesky <ref> [13, 14] </ref>. In [10] a sparse solver with element-wise 2-D mapping is presented. For better cache performance, block partitioning is preferred [1]. However there are several difficulties to apply the 2-D block-oriented mapping to the case of sparse LU factorization even the static structure is predicted in advance.
References-found: 12

