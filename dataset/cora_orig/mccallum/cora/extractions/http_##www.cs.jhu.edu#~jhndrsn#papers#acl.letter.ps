URL: http://www.cs.jhu.edu/~jhndrsn/papers/acl.letter.ps
Refering-URL: http://www.cs.jhu.edu/~jhndrsn/research.html
Root-URL: http://www.cs.jhu.edu
Email: satta@dei.unipd.it  jhndrsn@cs.jhu.edu  
Title: String Transformation Learning  
Author: Giorgio Satta John C. Henderson 
Address: via Gradenigo, 6/A I-35131 Padova, Italy  Baltimore, MD 21218-2694  
Affiliation: Dipartimento di Elettronica e Informatica Universita di Padova  Department of Computer Science Johns Hopkins University  
Abstract: String transformation systems have been introduced in (Brill, 1995) and have several applications in natural language processing. In this work we consider the computational problem of automatically learning from a given corpus the set of transformations presenting the best evidence. We introduce an original data structure and efficient algorithms that learn some families of transformations that are relevant for part-of-speech tagging and phonological rule systems. We also show that the same learning problem becomes NP-hard in cases of an unbounded use of don't care symbols in a transformation.
Abstract-found: 1
Intro-found: 1
Reference: <author> Apostolico, A. </author> <year> 1985. </year> <title> The myriad virtues of suffix trees. </title> <editor> In A. Apostolico and Z. Galil, editors, </editor> <booktitle> Combinatorial Algorithms on Words, </booktitle> <volume> volume 12. </volume> <publisher> Springer-Verlag, </publisher> <address> Berlin, Germany, </address> <pages> pages 85-96. </pages>
Reference-contexts: Data Structures This section introduces two data structures that are basic to the development of the algorithms presented in this paper. 3.1 Suffix trees We briefly present here a data structure that is well known in the text processing literature; the reader is referred to (Crochemore and Rytter, 1994) and <ref> (Apostolico, 1985) </ref> for definitions and further references. Let w be some non-null string. Throughout the paper we assume that the rightmost symbol of w is an end-marker not found at any other position in the string.
Reference: <institution> NATO Advanced Science Institutes, Seires F. </institution>
Reference: <author> Blumer, A., J. Blumer, D. Haussler, A. Ehrenfeucht, M. Chen, and J. Seiferas. </author> <year> 1985. </year> <title> The smallest automaton recognizing the subwords of a text. </title> <journal> Theoretical Computer Science, </journal> <volume> 40 </volume> <pages> 31-55. </pages>
Reference-contexts: An alternative data structure to suffix trees for the representations of string factors, called DAWG, has been presented in <ref> (Blumer et al., 1985) </ref>. We point out here that, because a DAWG is an acyclic graph rather than a tree, straightforward ways of defining alignment between two DAWGs results in a quadratic number of a-links, making DAWGs much less attractive than suffix trees for factor alignment.
Reference: <author> Brill, E. </author> <year> 1995. </year> <title> Transformation-based error-driven learning and natural language processing: A case study in part of speech tagging. </title> <note> Computational Linguistics. </note>
Reference-contexts: 1 Introduction Ordered sequences of rewriting rules are used in several applications in natural language processing, including phonological and morphological systems (Kaplan and Kay, 1994), morphological disambiguation, part-of-speech tagging and shallow syntactic parsing <ref> (Brill, 1995) </ref>, (Karlsson et al., 1995). In (Brill, 1995) a learning paradigm, called error-driven learning, has been introduced for automatic induction of a specific kind of rewriting rules called transformations, and it has been shown that the achieved accuracy of the resulting transformation systems is competitive with that of existing systems. <p> 1 Introduction Ordered sequences of rewriting rules are used in several applications in natural language processing, including phonological and morphological systems (Kaplan and Kay, 1994), morphological disambiguation, part-of-speech tagging and shallow syntactic parsing <ref> (Brill, 1995) </ref>, (Karlsson et al., 1995). In (Brill, 1995) a learning paradigm, called error-driven learning, has been introduced for automatic induction of a specific kind of rewriting rules called transformations, and it has been shown that the achieved accuracy of the resulting transformation systems is competitive with that of existing systems. <p> Then we say that ' is the statistic of factor x in w. 2 The learning paradigm The learning paradigm we adopt is called error-driven learning and has been originally proposed in <ref> (Brill, 1995) </ref> for part of speech tagging applications. We briefly introduce here the basic assumptions of the approach. A string transformation is a rewriting rule denoted as u ! v, where u and v are strings such that juj = jvj. <p> We have been concerned with learning the best transformations that should be applied at a given step. An ordered sequence of transformations can be learned by iteratively learning a single transformation and by processing the aligned corpus with the transformation just learned <ref> (Brill, 1995) </ref>. Dynamic techniques for processing the aligned corpus were first proposed in (Ramshaw and Marcus, 1996) to re-edit the corpus only where needed. <p> <ref> (Brill, 1995) </ref>. Dynamic techniques for processing the aligned corpus were first proposed in (Ramshaw and Marcus, 1996) to re-edit the corpus only where needed. Those authors report that this is not space efficient if transformation learning is done by independently testing all possible transformations in the search space (as in (Brill, 1995)). The suffix tree alignment data structure allows simultaneous scoring for all transformations. We can now take advantage of this and design dynamical algorithms that re-edit a suffix tree alignment only where needed, on the line of a similar method for suffix trees in (McCreight, 1976).
Reference: <author> Crochemore, M. and W. Rytter. </author> <year> 1994. </year> <title> Text Algorithms. </title> <publisher> Oxford University Press, Oxford, </publisher> <address> UK. </address>
Reference-contexts: in the next sections. 3 Data Structures This section introduces two data structures that are basic to the development of the algorithms presented in this paper. 3.1 Suffix trees We briefly present here a data structure that is well known in the text processing literature; the reader is referred to <ref> (Crochemore and Rytter, 1994) </ref> and (Apostolico, 1985) for definitions and further references. Let w be some non-null string. Throughout the paper we assume that the rightmost symbol of w is an end-marker not found at any other position in the string.
Reference: <author> Garey, M. R. and D. S. Johnson. </author> <year> 1979. </year> <title> Computers and Intractability. </title> <publisher> Freeman and Co., </publisher> <address> New York, NY. </address>
Reference-contexts: L? Membership in NP is easy to establish for TS. To show NP-hardness, we consider the CLIQUE decision problem for undirected, simple, connected graphs and transform such a problem to the TS problem. (The NP-completeness for the used restriction of the CLIQUE problem <ref> (Garey and Johnson, 1979) </ref> is easy to establish.) Let hG; K 0 i be an instance of the CLIQUE problem as above, G = (V; E) and K 0 &gt; 0. Without loss of generality, we assume that V = f1; 2; : : :; qg.
Reference: <author> Kaplan, R. M. and M. Kay. </author> <year> 1994. </year> <title> Regular models of phonological rule sistems. </title> <journal> Computational Linguistics, </journal> <volume> 20(3) </volume> <pages> 331-378. </pages>
Reference-contexts: 1 Introduction Ordered sequences of rewriting rules are used in several applications in natural language processing, including phonological and morphological systems <ref> (Kaplan and Kay, 1994) </ref>, morphological disambiguation, part-of-speech tagging and shallow syntactic parsing (Brill, 1995), (Karlsson et al., 1995). <p> Other than transformation based systems the methods presented in this paper can be used for learning rules of constraint grammars (Karlsson et al., 1995), phonological rule systems as in <ref> (Kaplan and Kay, 1994) </ref>, and in general those grammatical systems using constraints represented by means of rewriting rules. This is the case whenever we can encode the alphabet of the corpus in such a way that alignment is possible.
Reference: <author> Karlsson, F., A. Voutilainen, J. Heikkila, and A. Anttila. </author> <year> 1995. </year> <title> Constraint Grammar. A Language Independent System for Parsing Unrestricted Text. </title> <publisher> Mouton de Gruyter. </publisher>
Reference-contexts: 1 Introduction Ordered sequences of rewriting rules are used in several applications in natural language processing, including phonological and morphological systems (Kaplan and Kay, 1994), morphological disambiguation, part-of-speech tagging and shallow syntactic parsing (Brill, 1995), <ref> (Karlsson et al., 1995) </ref>. In (Brill, 1995) a learning paradigm, called error-driven learning, has been introduced for automatic induction of a specific kind of rewriting rules called transformations, and it has been shown that the achieved accuracy of the resulting transformation systems is competitive with that of existing systems. <p> Other than transformation based systems the methods presented in this paper can be used for learning rules of constraint grammars <ref> (Karlsson et al., 1995) </ref>, phonological rule systems as in (Kaplan and Kay, 1994), and in general those grammatical systems using constraints represented by means of rewriting rules. This is the case whenever we can encode the alphabet of the corpus in such a way that alignment is possible.
Reference: <author> McCreight, E. M. </author> <year> 1976. </year> <title> A space-economical suffix tree construction algorithm. </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> 23(2) </volume> <pages> 262-272. </pages>
Reference-contexts: The suffix tree and the statistics of all factors of w can be constructed/computed in time O (jwj), as reported in (Weiner, 1973) and <ref> (McCreight, 1976) </ref>. McCreight algorithm uses two basic functions to scan paths in the suffix tree under construction. These functions are briefly introduced here and will be exploited in the next subsection. <p> The suffix tree alignment data structure allows simultaneous scoring for all transformations. We can now take advantage of this and design dynamical algorithms that re-edit a suffix tree alignment only where needed, on the line of a similar method for suffix trees in <ref> (McCreight, 1976) </ref>. An alternative data structure to suffix trees for the representations of string factors, called DAWG, has been presented in (Blumer et al., 1985).
Reference: <author> Ramshaw, L. and M. P. Marcus. </author> <year> 1996. </year> <title> Exploring the nature of transformation-based learning. </title>
Reference-contexts: An ordered sequence of transformations can be learned by iteratively learning a single transformation and by processing the aligned corpus with the transformation just learned (Brill, 1995). Dynamic techniques for processing the aligned corpus were first proposed in <ref> (Ramshaw and Marcus, 1996) </ref> to re-edit the corpus only where needed. Those authors report that this is not space efficient if transformation learning is done by independently testing all possible transformations in the search space (as in (Brill, 1995)).
Reference: <editor> In J. Klavans and P. Resnik, editors, </editor> <title> The Balancing Act|Combining Symbolic and Statistical Approaches to Language. </title> <publisher> The MIT Press, </publisher> <address> Cam-bridge, MA, </address> <pages> pages 135-156. </pages>
Reference: <author> Weiner, P. </author> <year> 1973. </year> <title> Linear pattern-matching algorithms. </title> <booktitle> In Proceedings of the 14th IEEE Annual Symposium on Switching and Automata Theory, </booktitle> <pages> pages 1-11, </pages> <address> New York, NY. </address> <publisher> Institute of Electrical and Electronics Engineers. </publisher>
Reference-contexts: The suffix tree and the statistics of all factors of w can be constructed/computed in time O (jwj), as reported in <ref> (Weiner, 1973) </ref> and (McCreight, 1976). McCreight algorithm uses two basic functions to scan paths in the suffix tree under construction. These functions are briefly introduced here and will be exploited in the next subsection.
References-found: 12

