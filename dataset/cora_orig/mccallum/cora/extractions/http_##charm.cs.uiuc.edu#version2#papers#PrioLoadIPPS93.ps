URL: http://charm.cs.uiuc.edu/version2/papers/PrioLoadIPPS93.ps
Refering-URL: http://charm.cs.uiuc.edu/version2/papers/PrioLoadIPPS93.html
Root-URL: http://www.cs.uiuc.edu
Email: email: sinha@cs.uiuc.edu email: kale@cs.uiuc.edu  
Title: A Load Balancing Strategy For Prioritized Execution of Tasks  
Author: Amitabh B. Sinha Laxmikant V. Kale 
Address: Urbana, IL 61801 Urbana, IL 61801  
Affiliation: Department of Computer Science Department of Computer Science University of Illinois University of Illinois  
Abstract: Load balancing is a critical factor in achieving optimal performance in parallel applications where tasks are created in a dynamic fashion. In many computations, such as state space search problems, tasks have priorities, and solutions to the computation may be achieved more efficiently if these priorities are adhered to in the parallel execution of the tasks. For such tasks, a load balancing scheme that only seeks to balance load, without balancing high priority tasks over the entire system, might result in the concentration of high priority tasks (even in a balanced-load environment) on a few processors, thereby leading to low priority work being done. In such situations a load balancing scheme is desired which would balance both load and high priority tasks over the system. In this paper, we describe the development of a more efficient prioritized load balancing strategy. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> L. V. Kale. </author> <title> The Chare Kernel Parallel Programming System. </title> <booktitle> In International Conference on Parallel Processing, </booktitle> <month> August </month> <year> 1990. </year>
Reference-contexts: In Section 5, we describe the evolution of the load balancing strategy along with the results of performance evaluation experiments. Finally in Section 6, we review previous work on prioritized load balancing strategies and discuss future improvements to our load balancing strategy. 2 Programming Environment Charm <ref> [1] </ref> is a machine independent parallel programming language. Programs written in Charm run unchanged on shared memory machines including Encore Multimax and Sequent Symmetry, nonshared memory machines including Intel i860 and NCUBE/2, UNIX based networks of workstations including a network of IBM RISC workstations, and any UNIX based uniprocessor machine. <p> Thus Charm provides a good test-bed for different load balancing and queuing strategies. Charm also provides a type of replicated process called a branch-office chare, and five efficient data sharing abstractions called read-only, write-once, accumulator, monotonic and dynamic tables. We refer the interested user to <ref> [1, 2] </ref> for details of Charm. 3 Application: Traveling Salesman Problem The Traveling Salesman Problem (TSP) [3] is a typical example of an optimization problem solved using branch&bound techniques.
Reference: [2] <author> L. V. Kale et. al. </author> <title> The Chare Kernel Programming Language Manual (Internal Report). </title>
Reference-contexts: Thus Charm provides a good test-bed for different load balancing and queuing strategies. Charm also provides a type of replicated process called a branch-office chare, and five efficient data sharing abstractions called read-only, write-once, accumulator, monotonic and dynamic tables. We refer the interested user to <ref> [1, 2] </ref> for details of Charm. 3 Application: Traveling Salesman Problem The Traveling Salesman Problem (TSP) [3] is a typical example of an optimization problem solved using branch&bound techniques.
Reference: [3] <author> Edward W. Reingold, Jurg Nievergelt, and Nars-ingh Deo. </author> <title> Combinatorial Algorithms: Theory and Practice. </title> <publisher> Prentice-Hall, Inc., </publisher> <address> Englewood Cliffs, New Jersey, </address> <year> 1977. </year>
Reference-contexts: Charm also provides a type of replicated process called a branch-office chare, and five efficient data sharing abstractions called read-only, write-once, accumulator, monotonic and dynamic tables. We refer the interested user to [1, 2] for details of Charm. 3 Application: Traveling Salesman Problem The Traveling Salesman Problem (TSP) <ref> [3] </ref> is a typical example of an optimization problem solved using branch&bound techniques. In this problem a salesman must visit n cities, returning to the starting point, and is required to minimize the total cost of the trip.
Reference: [4] <author> J. D. C. Little, K. G. Murty, D. W. Sweeney, and C. Karel. </author> <title> An algorithm for the traveling salesman problem. </title> <journal> Operations Research, </journal> <volume> 11 </volume> <pages> 972-989, </pages> <year> 1963. </year>
Reference-contexts: Every pair of cities i and j has a cost C ij associated with them (if i = j, then C ij is assumed to be of infinite cost). We have implemented the branch&bound scheme proposed by Little, et. al. <ref> [4] </ref>. More sophisticated branch&bound schemes are available; since our focus is not on the best branch&bound scheme, but rather on an efficient prioritized load balancing strategy, Little's scheme is sufficient for our purpose.
Reference: [5] <author> M. Bellmore and G. Nemhauser. </author> <title> The traveling salesman problem: a survey. </title> <journal> Operations Research, </journal> <volume> 16 </volume> <pages> 538-558, </pages> <year> 1968. </year>
Reference-contexts: More sophisticated branch&bound schemes are available; since our focus is not on the best branch&bound scheme, but rather on an efficient prioritized load balancing strategy, Little's scheme is sufficient for our purpose. For a thorough discussion on branch&bound schemes and their parallelizations we refer you to <ref> [5, 6, 7, 8] </ref>. In Little's approach one starts with an initial partial solution, a cost function (C) and an infinite upper bound.

Reference: [7] <author> B. W. Wah, G. Li, and C. Yu. </author> <title> Multiprocessing of combinatorial search problems. </title> <editor> In V. Kumar, P. S. Gopalakrishnan, and L. N. Kamal, editors, </editor> <booktitle> Parallel Algorithms for Machine Intelligence and Vision. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1990. </year>
Reference-contexts: More sophisticated branch&bound schemes are available; since our focus is not on the best branch&bound scheme, but rather on an efficient prioritized load balancing strategy, Little's scheme is sufficient for our purpose. For a thorough discussion on branch&bound schemes and their parallelizations we refer you to <ref> [5, 6, 7, 8] </ref>. In Little's approach one starts with an initial partial solution, a cost function (C) and an infinite upper bound.
Reference: [8] <author> B. Monien and O. Vornberger. </author> <title> Parallel processing of combinatorial search trees. </title> <booktitle> Proceedings International Workshop on Parallel Algorithms and Architectures, </booktitle> <publisher> Math. Research Nr. </publisher> <address> 38, Akadmie-Verlag, Berlin, </address> <year> 1987. </year>
Reference-contexts: More sophisticated branch&bound schemes are available; since our focus is not on the best branch&bound scheme, but rather on an efficient prioritized load balancing strategy, Little's scheme is sufficient for our purpose. For a thorough discussion on branch&bound schemes and their parallelizations we refer you to <ref> [5, 6, 7, 8] </ref>. In Little's approach one starts with an initial partial solution, a cost function (C) and an infinite upper bound.
Reference: [9] <author> W. Shu and L. V. Kale. </author> <title> Dynamic scheduling of medium-grained processes on multicomputers. </title> <type> Technical report, </type> <institution> University of Illinois, Urbana, </institution> <year> 1989. </year>
Reference-contexts: We have examined two existing load balancing strategies, ACWN (adaptive contracting within a neighborhood) and Random, to measure and understand performance of fully distributed strategies for prioritized execution of tasks. In the random load balancing strategy, new work is sent out to a random processor. In the ACWN strategy <ref> [9] </ref>, newly generated work is required to travel between a minimum distance, minHops, and a maximum distance, max-Hops. Work always travels to topologically adjacent neighbors with the least load, but only if the difference in loads between the two neighbors is more than some predefined quantity, loadDelta.
Reference: [10] <author> L. V. Kale and A. B. Sinha. </author> <title> Projections: a scalable performance tool. </title> <booktitle> In International Parallel Processing Symposium, </booktitle> <month> April </month> <year> 1993. </year>
Reference-contexts: Notice that we get nearly linear speedups in the case of the shared memory machine runs, while in the case of the nonshared memory machine runs (with either load balancing strategy) the speedups seem to saturate after 8 processors. With the aid of Projections <ref> [10] </ref>, a performance tool developed for Charm, we were able to determine that the average busy time for each processor was 95% in the shared memory runs and 80% in the nonshared memory runs.
Reference: [11] <author> M. Furuichi, K. Taki, and N. Ichiyoshi. </author> <title> A multilevel load balancing scheme for or-parallel exhaustive search programs on the multi-psi. </title> <booktitle> Second ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, </booktitle> <year> 1990. </year>
Reference-contexts: Multi-level strategies have been studied before. Furuichi et. al. <ref> [11] </ref> present a strategy to partition the search of an OR-parallel graph in a distributed and hierarchical fashion among various processors | some processors function as subtask generators and distribute the tasks among the remaining processors. <p> One critical issue in their strategy is the generation of sub-tasks of reasonable granularity | if the grainsize is small, then the overheads of distributing would be substantial, if the grainsize is too large, then there might not be enough work to distribute. The model of computation in <ref> [11] </ref> is different from ours: in their model tasks are generated at and divided by only the task-generators, while in ours tasks can be generated at any managee.
Reference: [12] <author> I. Ahmad and A. Ghafoor. </author> <title> A semi distributed allocation strategy for large hypercube supercomputers. </title> <booktitle> Supercomputing, </booktitle> <year> 1990. </year>
Reference-contexts: The model of computation in [11] is different from ours: in their model tasks are generated at and divided by only the task-generators, while in ours tasks can be generated at any managee. Ahmad and Ghafoor <ref> [12] </ref> have presented a semi-distributed strategy for task allocation for regular topologies, e.g., hy-percubes as an alternative to completely centralized and completely distributed task allocation strategies.
Reference: [13] <author> A. B. Sinha and L. V. Kale. </author> <title> A load balancing strategy for prioritized execution of tasks. In Workshop on Dynamic Object Placement and Load Balancing in Parallel and Distributed Systems (in co-operation with ECOOP '92), </title> <month> June </month> <year> 1992. </year>
Reference-contexts: The work in this paper is an extension of a paper presented at a workshop on dynamic object placement and load balancing at ECOOP'92 <ref> [13] </ref>. A recent paper by Saletore [14] present strategies similar to the manager and the multiple manager strategies presented in this paper. However they present results for upto 32 processors only, for which we have found the manager scheme to be sufficient. Prioritized ACWN schemes have been discussed in [15].
Reference: [14] <author> Vikram A. Saletore and Mannan A. Mohammed. </author> <title> Hierarchical load balancing schemes for branch-and-bound computations on distributed memory machines. </title> <booktitle> In Hawaii International Conference on System Software, </booktitle> <month> January </month> <year> 1993. </year>
Reference-contexts: The work in this paper is an extension of a paper presented at a workshop on dynamic object placement and load balancing at ECOOP'92 [13]. A recent paper by Saletore <ref> [14] </ref> present strategies similar to the manager and the multiple manager strategies presented in this paper. However they present results for upto 32 processors only, for which we have found the manager scheme to be sufficient. Prioritized ACWN schemes have been discussed in [15].
Reference: [15] <author> V. </author> <title> Saletore . Machine Independent Parallel Execution of Speculative Computations. </title> <type> PhD thesis, </type> <institution> University of Illinois, Urbana, </institution> <month> September, </month> <year> 1990. </year>
Reference-contexts: A recent paper by Saletore [14] present strategies similar to the manager and the multiple manager strategies presented in this paper. However they present results for upto 32 processors only, for which we have found the manager scheme to be sufficient. Prioritized ACWN schemes have been discussed in <ref> [15] </ref>. However the results are available only till 16 processors, and hence a comparison with our strategy was not possible. In Section 5.3 we saw that the multiple managers strategy out-performs the token strategy for certain problems.
References-found: 14

