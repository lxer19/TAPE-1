URL: http://www.cs.huji.ac.il/papers/IP/IUW97/general-mosaics.ps.gz
Refering-URL: http://www.cs.huji.ac.il/papers/IP/index.html
Root-URL: 
Title: Mosaicing with Generalized Strips  
Author: Benny Rousso Shmuel Peleg Ilan Finci 
Address: 91904 Jerusalem, ISRAEL  
Affiliation: Inst. of Computer Science The Hebrew University of Jerusalem  
Abstract: To overcome most restrictions, mosaicing is presented in this paper as a process of collecting strips. Strips which are perpendicular to the optical flow are cut out of the images, and are warped so that within each strip the optical flow will be parallel. These strips are then pasted into the mosaic. This approach enables to define mosaicing even for cases of forward motion and for zoom. View interpolation, generating dense intermediate views, is used to overcome parallax effects. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S.E. Chen and L. Williams. </author> <title> View interpolation for image synthesis. In SIGGRAPH, pages 279-288, a c (a) Two original images. A map is seen on a wall parallel to the optical axis. (b) Reconstructed panoramic mosaic, which is similar to a real frontal view of the map (c). </title> <address> Anahiem, California, </address> <month> August </month> <year> 1993. </year> <note> ACM. </note>
Reference-contexts: For example, we can take a collection of L strips, each with a width of one pixel, from interpolated camera views in between the original camera positions. In order to synthesize new views we can use various methods, such as optical flow interpolation <ref> [1, 9] </ref>, trilinear tensor methods [7], and others. In most cases approximate methods will give good results. The creation of the intermediate views can involve only view interpolation, as in most of the applications view extrapolation is not needed.
Reference: [2] <author> R. Hartley and R. Gupta. </author> <title> Linear pushbroom cameras. </title> <editor> In J.O. Eklundh, editor, </editor> <booktitle> Third European Conference on Computer Vision, </booktitle> <pages> pages 555-566, </pages> <address> Stockholm, Sweden, May 1994. </address> <publisher> Springer. </publisher>
Reference-contexts: The strip collection process allows the introduction of a mechanism to overcome the effects of parallax by generating dense intermediate views. In some cases mosaics generated in this manner can be considered at linear pushbroom cameras <ref> [2] </ref>. 2 Mosaicing Using Strips Construction of panoramic mosaics includes the collection of sections from each image and pasting these sections next to each other to become the mosaic.
Reference: [3] <author> M. Irani, P. Anandan, and S. Hsu. </author> <title> Mosaic based representations of video sequences and their applications. </title> <booktitle> In Fifth International Conference on Computer Vision, </booktitle> <pages> pages 605-611, </pages> <address> Cambridge, MA, </address> <month> June </month> <year> 1995. </year> <pages> IEEE-CS. </pages>
Reference-contexts: Other methods use a camera which is rotating around the y axis passing through it's optical center without any translation. The resulting mosaic corresponds to a projection onto a cylinder [5]. Most methods select one frame to be a reference frame, towards which all other frames are warped <ref> [8, 3] </ref>. This approach uses 2D analysis to find motion based on an affine model or a general planar surface model, and allows somewhat more general camera motion.
Reference: [4] <author> M. Irani, B. Rousso, and S. Peleg. </author> <title> Detecting and tracking multiple moving objects using temporal integration. </title> <editor> In G. Sandini, editor, </editor> <booktitle> Second Euro-pean Conference on Computer Vision, </booktitle> <pages> pages 282-287, </pages> <address> Santa Margherita, Italy, May 1992. </address> <publisher> Springer. </publisher>
Reference-contexts: Many methods exist to recover the parameters of an affine transformation <ref> [4] </ref>.
Reference: [5] <author> Leonard McMillan and Gary Bishop. </author> <title> Plenop-tic modeling: An image-based rendering system. </title> <booktitle> In SIGGRAPH, </booktitle> <address> Los Angeles, California, </address> <month> August </month> <year> 1995. </year> <note> ACM. </note>
Reference-contexts: Other methods use a camera which is rotating around the y axis passing through it's optical center without any translation. The resulting mosaic corresponds to a projection onto a cylinder <ref> [5] </ref>. Most methods select one frame to be a reference frame, towards which all other frames are warped [8, 3]. This approach uses 2D analysis to find motion based on an affine model or a general planar surface model, and allows somewhat more general camera motion.
Reference: [6] <author> S. Peleg and J. Herman. </author> <title> Panoramic mosaics with VideoBrush. </title> <booktitle> In IUW-97, </booktitle> <address> New Orleans, Louisiana, </address> <month> May </month> <year> 1997. </year> <title> Morgan Kaufmann. a c (a) Two original images. (b) Mosaicing without view interpolation. Distant objects are duplicated, and close objects are truncated. (c) Using view interpolation reduces the distortions. </title>
Reference-contexts: These results are still preliminary, but indicate the potential of this approach. Simple cases can be seen in <ref> [6] </ref>. 5.1 Zoom During zoom, the resolution of the image increases while the field of view becomes smaller, causing the loss of the outside periphery from the next frame. Our process collects these circular peripheral strips, that disappear from one frame to the next, to construct the mosaic.
Reference: [7] <author> B. Rousso, S. Avidan, A. Shashua, and S. Pe-leg. </author> <title> Robust recovery of camera rotation from three frames. </title> <booktitle> In IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 796-802, </pages> <address> San Fran-sisco, California, </address> <month> June </month> <year> 1996. </year>
Reference-contexts: For example, we can take a collection of L strips, each with a width of one pixel, from interpolated camera views in between the original camera positions. In order to synthesize new views we can use various methods, such as optical flow interpolation [1, 9], trilinear tensor methods <ref> [7] </ref>, and others. In most cases approximate methods will give good results. The creation of the intermediate views can involve only view interpolation, as in most of the applications view extrapolation is not needed.
Reference: [8] <author> H.S. Sawhney, S. Ayer, and M. Gorkani. </author> <title> Model-based 2D & 3D dominant motion estimation for mosaicing and video representation. </title> <booktitle> In Fifth International Conference on Computer Vision, </booktitle> <pages> pages 583-590, </pages> <address> Cambridge, MA, </address> <month> June </month> <year> 1995. </year> <pages> IEEE-CS. </pages>
Reference-contexts: Other methods use a camera which is rotating around the y axis passing through it's optical center without any translation. The resulting mosaic corresponds to a projection onto a cylinder [5]. Most methods select one frame to be a reference frame, towards which all other frames are warped <ref> [8, 3] </ref>. This approach uses 2D analysis to find motion based on an affine model or a general planar surface model, and allows somewhat more general camera motion.
Reference: [9] <author> S. Seitz and C. Dyer. </author> <title> Physically valid view synthesis by image interpolation. </title> <booktitle> In Proc. IEEE Workshop on Representation of Visual Scenes, </booktitle> <address> Cam-bridge, MA, </address> <month> June </month> <year> 1995. </year> <pages> IEEE-CS. </pages>
Reference-contexts: For example, we can take a collection of L strips, each with a width of one pixel, from interpolated camera views in between the original camera positions. In order to synthesize new views we can use various methods, such as optical flow interpolation <ref> [1, 9] </ref>, trilinear tensor methods [7], and others. In most cases approximate methods will give good results. The creation of the intermediate views can involve only view interpolation, as in most of the applications view extrapolation is not needed.
References-found: 9

