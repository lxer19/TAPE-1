URL: ftp://softlib.rice.edu/pub/CRPC-TRs/reports/CRPC-TR93440.ps.gz
Refering-URL: http://www.crpc.rice.edu/CRPC/softlib/TRs_online.html
Root-URL: 
Email: e-mail: btouranc@lip.ens-lyon.fr  
Title: Trace2au Audio Monitoring Tools for Parallel Programs  
Author: Jean-Yves Peterschmitt Bernard Tourancheau yz 
Keyword: Monitoring, Parallelism, Sound on a workstation, Sonification  
Date: August 1993  
Address: 46, allee d'Italie 69364 Lyon Cedex 07 France  Knoxville, TN 37996-1301 USA  
Affiliation: LIP Unite de Recherche Associee 1398 du CNRS Ecole Normale Superieure de Lyon  University of Tennessee Computer Science Department  
Abstract: It is not easy to reach the best performances you can expect of a parallel computer. We therefore have to use monitoring programs to study the performances of parallel programs. We introduce here a way to generate sound in real-time on a workstation, with no additional hardware, and we apply it to such monitoring programs. 
Abstract-found: 1
Intro-found: 1
Reference: [Ass88] <author> MIDI Manufacturers Association. </author> <title> MIDI Musical Instrument Digital Interface, Specification 1.0. </title> <booktitle> International MIDI Association, </booktitle> <address> Los Angeles, CA, </address> <year> 1988. </year>
Reference-contexts: This tool allows the user to switch easily between using MIDI or sound on a Sun's SPARCstation. 2 Musical Instrument Digital Interface, a communication protocol that allows sound synthesizers to be interconnected and computer controlled <ref> [Ass88] </ref>. 2 What is maybe most important is the fact that the first set of dimensions described above relies on seeing, whereas the sound related dimensions rely on hearing.
Reference: [BDG + 92] <author> A. Beguelin, J. Dongarra, A. Geist, R. Manchek, K. Moore, and V. Sunderman. </author> <title> PVM and HeNCE : Tools for heterogeneous network computing. </title> <editor> In J. Dongarra and B. Tourancheau, editors, </editor> <booktitle> Environments and tools for parallel scientific Computing, volume 6 of Advances in parallel computing, </booktitle> <pages> pages 139-154, </pages> <address> Saint Hilaire du Touvet - France, </address> <month> September </month> <year> 1992. </year> <title> CNRS - NSF, </title> <publisher> Elsevier Sciences Publisher. </publisher>
Reference-contexts: In the future, we will try to add our sound procedures to existing mute programs 19 , such as HeNCE <ref> [BDG + 92] </ref> or ParaGraph [HE91]. We will also add a graphical user interface to our sound programs and start using them on top of PIMSY [PTV92, vRTV92], our scalable monitoring system.
Reference: [BH92] <author> Marc H. Brown and John Hershberger. </author> <title> Color and sound in algorithm animation. </title> <booktitle> Computer, </booktitle> <month> December </month> <year> 1992. </year>
Reference-contexts: Color is an additional dimension, time (animation) is yet another dimension, and so on. Therefore, using sound in a scientific visualization application will add another (set of) dimension (s) to the existing ones. Several papers have already studied this subject (see for example <ref> [BH92, FJA91, Mad92, RAM + 92, ZT92] </ref>). Using sound in such a context has been coined sonifica-tion or auralization. <p> Note that for obvious technical reasons, we can not achieve all these sound effects on a standard workstation. We will talk about this in the next section. As it is emphasized in <ref> [BH92] </ref>, sound can be used for four different reasons in a scientific application: reinforcing existing visual displays, conveying distinctive patterns or signatures (that are not obvious with mere displays), replacing displays or signaling exceptional conditions.
Reference: [Env92] <institution> Volvox Machines Programming Environment. </institution> <note> VolTms User's Guide. </note> <institution> ARCHIPEL SA, </institution> <address> 74940 Annecy-le-vieux, France, </address> <year> 1992. </year>
Reference-contexts: The content of the supplied trace data is sorted according to increasing timestamps. We decided to use the same kind of trace file we were using with vol tmspg (our customized version of ParaGraph for the ARCHIPEL Volvox machine <ref> [HE91, Env92, vRT92] </ref>): ASCII ".trf" files. The kind of trace file used can be easily modified. All we need is a way to know when the interesting events (SENDs and RECEIVEs in our current tools) take place. * the output is a ".au" sound 13 .
Reference: [FJA91] <author> Joan M. Francioni, Jay Alan Jackson, and Larry Albright. </author> <title> The sounds of parallel programs. </title> <publisher> In IEEE Computer Society Press, </publisher> <editor> editor, </editor> <booktitle> The Sixth Distributed Memory Computing Conference Proceedings, </booktitle> <year> 1991. </year>
Reference-contexts: Color is an additional dimension, time (animation) is yet another dimension, and so on. Therefore, using sound in a scientific visualization application will add another (set of) dimension (s) to the existing ones. Several papers have already studied this subject (see for example <ref> [BH92, FJA91, Mad92, RAM + 92, ZT92] </ref>). Using sound in such a context has been coined sonifica-tion or auralization. <p> Several papers have already studied this subject (see for example [BH92, FJA91, Mad92, RAM + 92, ZT92]). Using sound in such a context has been coined sonifica-tion or auralization. Concerning monitoring, <ref> [FJA91] </ref> focuses on the mapping of events to the MIDI format 2 , and uses the resulting sounds in parallel with ParaGraph ([HE91]). [Mad92] introduces a more general purpose sonification tool, and uses it in the Pablo monitoring environment (see also [RAM + 92]).
Reference: [HE91] <author> M. Heath and J. Etheridge. </author> <title> Visualizing the performance of parallel programs. </title> <journal> IEEE Software, </journal> <volume> 8 </volume> <pages> 29-39, </pages> <month> September </month> <year> 1991. </year>
Reference-contexts: The content of the supplied trace data is sorted according to increasing timestamps. We decided to use the same kind of trace file we were using with vol tmspg (our customized version of ParaGraph for the ARCHIPEL Volvox machine <ref> [HE91, Env92, vRT92] </ref>): ASCII ".trf" files. The kind of trace file used can be easily modified. All we need is a way to know when the interesting events (SENDs and RECEIVEs in our current tools) take place. * the output is a ".au" sound 13 . <p> In the future, we will try to add our sound procedures to existing mute programs 19 , such as HeNCE [BDG + 92] or ParaGraph <ref> [HE91] </ref>. We will also add a graphical user interface to our sound programs and start using them on top of PIMSY [PTV92, vRTV92], our scalable monitoring system.
Reference: [Hor85] <author> Bill Horne. </author> <title> The sound of music. </title> <booktitle> Computing Today, </booktitle> <month> April </month> <year> 1985. </year>
Reference: [Mad92] <author> Tara Maja Madhyastha. </author> <title> A portable system for data sonification. </title> <type> Master's thesis, </type> <institution> University of Illinois at Urbana-Champaign, </institution> <year> 1992. </year>
Reference-contexts: Color is an additional dimension, time (animation) is yet another dimension, and so on. Therefore, using sound in a scientific visualization application will add another (set of) dimension (s) to the existing ones. Several papers have already studied this subject (see for example <ref> [BH92, FJA91, Mad92, RAM + 92, ZT92] </ref>). Using sound in such a context has been coined sonifica-tion or auralization. <p> Using sound in such a context has been coined sonifica-tion or auralization. Concerning monitoring, [FJA91] focuses on the mapping of events to the MIDI format 2 , and uses the resulting sounds in parallel with ParaGraph ([HE91]). <ref> [Mad92] </ref> introduces a more general purpose sonification tool, and uses it in the Pablo monitoring environment (see also [RAM + 92]).
Reference: [PTV92] <author> S. Poinson, B. Tourancheau, and X. Vigouroux. </author> <title> Distributed monitoring for scalable massively parallel machines. </title> <editor> In J. Dongarra and B. Tourancheau, editors, </editor> <booktitle> Environment and Tools for Parallel Scientific Computing, volume 6 of Advances in parallel computing, </booktitle> <pages> pages 85-101, </pages> <address> Saint Hilaire du Touvet France, </address> <month> September </month> <year> 1992. </year> <title> CNRS - NSF, </title> <publisher> Elsevier Sciences Publisher. </publisher>
Reference-contexts: In the future, we will try to add our sound procedures to existing mute programs 19 , such as HeNCE [BDG + 92] or ParaGraph [HE91]. We will also add a graphical user interface to our sound programs and start using them on top of PIMSY <ref> [PTV92, vRTV92] </ref>, our scalable monitoring system.
Reference: [RAM + 92] <author> Daniel A. Reed, Ruth A. Aydt, Tara M. Madhyastha, Roger J Noe, Keith A. Shields, and Schwartz Bradley W. </author> <title> An overview of the pablo performance analysis environment. </title> <type> Technical report, </type> <institution> University of Illinois at Urbana-Champaign, </institution> <month> November </month> <year> 1992. </year>
Reference-contexts: Color is an additional dimension, time (animation) is yet another dimension, and so on. Therefore, using sound in a scientific visualization application will add another (set of) dimension (s) to the existing ones. Several papers have already studied this subject (see for example <ref> [BH92, FJA91, Mad92, RAM + 92, ZT92] </ref>). Using sound in such a context has been coined sonifica-tion or auralization. <p> Concerning monitoring, [FJA91] focuses on the mapping of events to the MIDI format 2 , and uses the resulting sounds in parallel with ParaGraph ([HE91]). [Mad92] introduces a more general purpose sonification tool, and uses it in the Pablo monitoring environment (see also <ref> [RAM + 92] </ref>).
Reference: [Rem86] <author> Claire Remy. Le compositeur et l'ordinateur. Micro-Systemes, </author> <month> June </month> <year> 1986. </year>
Reference: [Sun91] <author> Sun Microsystems. </author> <booktitle> SPARCstation Audio Programming, </booktitle> <month> July </month> <year> 1991. </year> <note> Part No : FE318-0. </note>
Reference-contexts: Now that we have the technical details (see also <ref> [Sun91, Sun92a, VR93] </ref>), let us see what kind of sound we can have on Sun's SPARCstations, with regard to the parameters discussed in the previous section.
Reference: [Sun92a] <author> Sun Microsystems. </author> <title> Multimedia Primer, </title> <month> February </month> <year> 1992. </year> <note> Part No : FE328-0. </note>
Reference-contexts: Now that we have the technical details (see also <ref> [Sun91, Sun92a, VR93] </ref>), let us see what kind of sound we can have on Sun's SPARCstations, with regard to the parameters discussed in the previous section.
Reference: [Sun92b] <author> Sun Microsystems. </author> <booktitle> SPARCstation 10 System Architecture, </booktitle> <month> May </month> <year> 1992. </year> <note> Part No : 4/92 FE-0/30K. </note>
Reference-contexts: produce sound in real-time 6 . * according to the Nyquist theorem 7 , the highest pitch we will be able to get will be of 4 KHz. 4 With the sound program running on the first one, and xplayer running on the other one. 5 Sun has announced in <ref> [Sun92b] </ref> that the SPARCstation 10 would be capable of simultaneous input and output of 16-bit stereo audio at rates up to 48 KHz.
Reference: [VR93] <author> Guido Van Rossum. </author> <title> Faq: Audio file formats. Usenet News, </title> <month> May </month> <year> 1993. </year>
Reference-contexts: According to <ref> [VR93] </ref>, the following manufacturers sell workstations with built-in sound capabilities: DEC, Hewlett-Packard, NeXT, SGI, Sony and Sun. We have worked with the Sun's SPARCstations that were available in our laboratory, but our programs could be easily modified to run on other workstations. <p> Now that we have the technical details (see also <ref> [Sun91, Sun92a, VR93] </ref>), let us see what kind of sound we can have on Sun's SPARCstations, with regard to the parameters discussed in the previous section. <p> We will however soon add a user interface to our programs, to make their use more intuitive. 13 Audio files that can be played on a Sun's SPARCstation usually have the ".au" extension. For more details about the file structure and the file header, see <ref> [VR93] </ref>. 9 * the programs are fast. This allows us to generate and play the created sound on the fly.
Reference: [vRT92] <author> M. van Riek and B. Tourancheau. </author> <title> The design of the general parallel monitoring system. </title> <editor> In N. Topham, R. Ibbett, and T. Bemmerl, editors, </editor> <booktitle> Programming Environments for Parallel Computing, volume A-11 of IFIP, </booktitle> <pages> pages 127-137, </pages> <address> Edinburgh, Scotland, April 1992. </address> <publisher> IFIP, North-Holland. </publisher>
Reference-contexts: The content of the supplied trace data is sorted according to increasing timestamps. We decided to use the same kind of trace file we were using with vol tmspg (our customized version of ParaGraph for the ARCHIPEL Volvox machine <ref> [HE91, Env92, vRT92] </ref>): ASCII ".trf" files. The kind of trace file used can be easily modified. All we need is a way to know when the interesting events (SENDs and RECEIVEs in our current tools) take place. * the output is a ".au" sound 13 .
Reference: [vRTV92] <author> M. van Riek, B. Tourancheau, and X. Vigouroux. </author> <title> The massively parallel monitoring system (a truly scalable approach to parallel monitoring). </title> <editor> In G. Haring, editor, </editor> <booktitle> Performance Measurement and Visualization of Parallel Systems, </booktitle> <address> Moravany, CZ, October 1992. </address> <publisher> Elsevier Sciences Publisher. </publisher>
Reference-contexts: In the future, we will try to add our sound procedures to existing mute programs 19 , such as HeNCE [BDG + 92] or ParaGraph [HE91]. We will also add a graphical user interface to our sound programs and start using them on top of PIMSY <ref> [PTV92, vRTV92] </ref>, our scalable monitoring system.
Reference: [ZT92] <author> Eugenio Zabala and Richard Taylor. </author> <title> Process and processor interaction : Architecture independent visualization schema. </title> <editor> In J. J. Dongarra and B. Tourancheau, editors, </editor> <booktitle> Environments and Tools for Parallel Scientific Computing, volume 6 of Advances in parallel computing, </booktitle> <address> Saint Hilaire du Touvet France, </address> <month> September </month> <year> 1992. </year> <title> CNRS - NSF, </title> <publisher> Elsevier Sciences Publisher. </publisher> <pages> 14 </pages>
Reference-contexts: Color is an additional dimension, time (animation) is yet another dimension, and so on. Therefore, using sound in a scientific visualization application will add another (set of) dimension (s) to the existing ones. Several papers have already studied this subject (see for example <ref> [BH92, FJA91, Mad92, RAM + 92, ZT92] </ref>). Using sound in such a context has been coined sonifica-tion or auralization. <p> Moreover, one of the advantages of sound is that we can process part of the information in a passive manner (i.e. without intently listening to it). This advantage has been detailed in <ref> [ZT92] </ref>. To convey information, using sound, we can play with the basic parameters of sound, and have them change over time: The pitch is related to the frequency, and can be used to convey a numerical value. The human ear can theoretically hear frequencies in the range [20...20,000] Hz.
References-found: 18

