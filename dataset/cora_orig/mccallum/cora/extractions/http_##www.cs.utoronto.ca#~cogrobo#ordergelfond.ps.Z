URL: http://www.cs.utoronto.ca/~cogrobo/ordergelfond.ps.Z
Refering-URL: http://www.cs.utoronto.ca/~cogrobo/
Root-URL: 
Email: @cs.ust.hk  
Title: An Ordering on Subgoals for Planning  
Author: Fangzhen Lin 
Address: Hong Kong  
Affiliation: Department of Computer Science The Hong Kong University of Science and Technology Clear Water Bay, Kowloon,  
Abstract: Subgoal ordering is a type of control information that has received much attention in AI planning community. In this paper we formulate precisely a subgoal ordering in the situation calculus. We show how information about this subgoal ordering can be deduced from the background action theory. We also show for both linear and nonlinear planners how knowledge about this ordering can be used in a provably correct way to avoid unnecessary backtracking.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> F. Bacchus and F. Kabanza. </author> <title> Planning for temporally extended goals. </title> <booktitle> In Proceedings of the 13th National Conference on Artificial Intelligence (AAAI-96), </booktitle> <publisher> AAAI Press, </publisher> <address> Menlo Park, CA., </address> <pages> pages 1215-1222, </pages> <year> 1996. </year>
Reference-contexts: However, our goal ordering has the advantage that it is planner independent. As we have shown, it is applicable to both linear and nonlinear planners. This work is also related to the work of Bacchus and Kabanza <ref> [1] </ref>. While we use the situation calculus, Bacchus and Kabanza use a temporal logic for expressing control information in planning.
Reference: [2] <author> A. Barrett and D. S. Weld. </author> <title> Characterizing subgoal interactions for planning. </title> <booktitle> In Proceedings of the Thirteenth International Joint Conference on Artificial Intelligence (IJCAI-93), </booktitle> <publisher> IJCAI Inc. Distributed by Morgan Kaufmann, </publisher> <address> San Mateo, CA., </address> <pages> pages 1388-1393, </pages> <year> 1993. </year>
Reference-contexts: The problem of subgoal ordering is important for AI planning. Korf [9] first shows that the complexity of a planning problem is closely related to the question of whether there is an effective ordering on subgoals (see also Barrett and Weld <ref> [2] </ref> and Joslin and Roach [8]). In this paper we formulate a subgoal ordering in the situation calculus. We show how information about this subgoal ordering can be deduced from the background action theory.
Reference: [3] <author> D. Chapman. </author> <title> Planning for conjunctive goals. </title> <journal> Artificial Intelligence, </journal> <volume> 32 </volume> <pages> 333-377, </pages> <year> 1987. </year>
Reference-contexts: 1 Introduction In a typical AI planning problem (cf. Chapman <ref> [3] </ref>), a goal is represented as a conjunction of simpler subgoals. The problem of subgoal ordering is about in which order a planner should attempt to achieve these subgoals.
Reference: [4] <author> J. Cheng and K. B. Irani. </author> <title> Ordering problem subgoals. </title> <booktitle> In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence (IJCAI-89), </booktitle> <pages> pages 931-936, </pages> <year> 1989. </year>
Reference-contexts: Instead of the space of all possible plans, we can consider some smaller classes of plans. For instance, similar to (Cheng and Irani <ref> [4] </ref>), we can consider only those plans that also achieve some additional goals: P recedence (g 1 ; g 2 ; G) 4 = (8s):S 0 &lt; s ^ H (g 1 & g 2 ; s) ^ H (G; s) P recedence (g 1 ; g 2 ; s): 19 <p> Although developed independently, it turned out that our ordering relation is closely related to but subtly different from that in (Etzioni [5]) and that in (Cheng and Irani <ref> [4] </ref>). Although we consider only the space of legal situations, Cheng and Irani ([4]) consider the space of all possible situations. 8 This difference is important.
Reference: [5] <author> O. Etzioni. </author> <title> Acquiring search-control knowledge via static analysis. </title> <journal> Artificial Intelligence, </journal> <volume> 62 </volume> <pages> 255-301, </pages> <year> 1993. </year>
Reference-contexts: However, to the best of our knowledge, this paper is the first attempt in using the situation calculus to formalize control knowledge in planning. Although developed independently, it turned out that our ordering relation is closely related to but subtly different from that in (Etzioni <ref> [5] </ref>) and that in (Cheng and Irani [4]). Although we consider only the space of legal situations, Cheng and Irani ([4]) consider the space of all possible situations. 8 This difference is important.
Reference: [6] <author> M. R. Genesereth and N. J. Nilsson. </author> <booktitle> The Logical Foundations of Artificial Intelligence. </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> Los Altos, CA., </address> <year> 1987. </year>
Reference-contexts: But on (B; C) has precedence over on (A; B) according to our definition. 6 Using the Subgoal Ordering in Planning We now show how knowledge about can be used effectively in planning. We consider two planners. One is a linear regression planner adapted from (Genesereth and Nilsson <ref> [6] </ref>). The other is the nonlinear planner SNLP of McAllester and Rosenblitt [13]. For ease of presentation, we shall consider only context-free actions. In the situation calculus, these actions are specified by a context-free action theory D (cf. <p> Let G 0 be a goal. A naive version of our linear regression planner adapted from (Nilsson [16] and Genesereth and Nilsson <ref> [6] </ref>) can be described as follows: 1. Initialize (for partial plans) to ;, G (for outstanding goals) to G 0 , and E (for equality constraints) to true. 2.
Reference: [7] <author> C. C. Green. </author> <title> Application of theorem proving to problem solving. </title> <booktitle> In Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI-69), </booktitle> <pages> pages 219-239, </pages> <year> 1969. </year>
Reference-contexts: = (8s):S 0 &lt; s ^ H (g 1 & g 2 ; s) ^ H (G; s) P recedence (g 1 ; g 2 ; s): 19 8 Related Work The situation calculus has been used for planning ever since it's introduced (McCarthy [14], McCarthy and Hayes [15], Green <ref> [7] </ref>). However, to the best of our knowledge, this paper is the first attempt in using the situation calculus to formalize control knowledge in planning.
Reference: [8] <author> D. Joslin and J. Roach. </author> <title> A theoretical analysis of conjunctive-goal problems. </title> <journal> Artificial Intelligence, </journal> <volume> 41 </volume> <pages> 97-106, </pages> <year> 1989. </year> <month> 21 </month>
Reference-contexts: The problem of subgoal ordering is important for AI planning. Korf [9] first shows that the complexity of a planning problem is closely related to the question of whether there is an effective ordering on subgoals (see also Barrett and Weld [2] and Joslin and Roach <ref> [8] </ref>). In this paper we formulate a subgoal ordering in the situation calculus. We show how information about this subgoal ordering can be deduced from the background action theory.
Reference: [9] <author> R. E. Korf. </author> <title> Planning as search: A quantitative approach. </title> <journal> Artificial Intelligence, </journal> <volume> 33 </volume> <pages> 65-88, </pages> <year> 1987. </year>
Reference-contexts: The problem of subgoal ordering is important for AI planning. Korf <ref> [9] </ref> first shows that the complexity of a planning problem is closely related to the question of whether there is an effective ordering on subgoals (see also Barrett and Weld [2] and Joslin and Roach [8]). In this paper we formulate a subgoal ordering in the situation calculus. <p> As Korf <ref> [9] </ref> noted, in Sussman's anomaly, the set fon (A; B); on (B; C)g of subgoals is not serializable according to his definition.
Reference: [10] <author> F. Lin. </author> <title> Applications of the situation calculus to formalizing control and strategic information: the prolog cut operator. </title> <note> http://www.cs.ust.hk/~flin/, Submitted. </note>
Reference-contexts: We have also applied the situation calculus to formalizing control information in logic programming by giving a logical semantics to the cut operator, the chief search control operator in Prolog. For details, see Lin <ref> [10] </ref> Acknowledgements Much of this work was done while the author was with the Department of Computer Science at the University of Toronto, where the research was supported in part by grants to Hector Levesque and Raymond Reiter from the Government of Canada Institute for Robotics and Intelligent Systems, and from
Reference: [11] <author> F. Lin and R. Reiter. </author> <title> State constraints revisited. </title> <journal> Journal of Logic and Computation, Special Issue on Actions and Processes, </journal> <volume> 4(5) </volume> <pages> 655-678, </pages> <year> 1994. </year>
Reference-contexts: As usual, s s 0 will be a shorthand for s &lt; s 0 _ s = s 0 . In this paper, we assume the following foundational axioms (Lin and Reiter <ref> [11] </ref>): 2 S 0 6= do (a; s); (8P )[P (S 0 ) ^ (8a; s)(P (s) P (do (a; s))) (8s)P (s)]; s &lt; do (a; s 0 ) (P oss (a; s 0 ) ^ s s 0 ): The first two axioms are unique names assumptions. <p> However, unlike Peano arithmetic which has a unique successor function, we have a class of successor functions here represented by the function do. The following proposition summarizes some simple consequences of . Proofs can be found in (Lin and Reiter <ref> [11] </ref>). <p> Reiter [21] and Lin and Reiter <ref> [11] </ref>): D = [ D ss [ D ap [ D una [ D S 0 ; where * is the set of the foundational axioms for situations as given in Section 2. * D ss is a set of successor state axioms, one for each fluent F , of the
Reference: [12] <author> F. Lin and R. Reiter. </author> <title> How to progress a database. </title> <journal> Artificial Intelligence, </journal> <note> 1997. To appear. </note>
Reference-contexts: Example 5.1 Consider the following blocks world (Lin and Reiter <ref> [12] </ref>): Actions 4 * move (x; y; z): Move block x from block y onto block z, provided both x and z are clear and block x is on top of block y. * movef romtable (x; y): Move block x from the table onto block y, provided x is clear <p> The other is the nonlinear planner SNLP of McAllester and Rosenblitt [13]. For ease of presentation, we shall consider only context-free actions. In the situation calculus, these actions are specified by a context-free action theory D (cf. Lin and Reiter <ref> [12] </ref>) of the following form: D = [ D ss [ D ap [ D una [ D S 0 ; where * is the set of the foundational axioms in Section 2. * D ss is a set of context free successor state axioms, one for each fluent F ,
Reference: [13] <author> D. McAllester and D. Rosenblitt. </author> <title> Systematic nonlinear planning. </title> <booktitle> In Proceedings of the Ninth National Conference on Artificial Intelligence (AAAI-91), </booktitle> <pages> pages 634-639, </pages> <year> 1991. </year>
Reference-contexts: We consider two planners. One is a linear regression planner adapted from (Genesereth and Nilsson [6]). The other is the nonlinear planner SNLP of McAllester and Rosenblitt <ref> [13] </ref>. For ease of presentation, we shall consider only context-free actions. In the situation calculus, these actions are specified by a context-free action theory D (cf.
Reference: [14] <author> J. McCarthy. </author> <title> Situations, actions and causal laws. </title> <editor> In M. Minsky, editor, </editor> <booktitle> Semantic Information Processing, </booktitle> <pages> pages 410-417. </pages> <publisher> MIT Press, </publisher> <address> Cambridge, Mass., </address> <year> 1968. </year>
Reference-contexts: ; g 2 ; G) 4 = (8s):S 0 &lt; s ^ H (g 1 & g 2 ; s) ^ H (G; s) P recedence (g 1 ; g 2 ; s): 19 8 Related Work The situation calculus has been used for planning ever since it's introduced (McCarthy <ref> [14] </ref>, McCarthy and Hayes [15], Green [7]). However, to the best of our knowledge, this paper is the first attempt in using the situation calculus to formalize control knowledge in planning.
Reference: [15] <author> J. McCarthy and P. Hayes. </author> <title> Some philosophical problems from the standpoint of artificial intelligence. </title> <editor> In B. Meltzer and D. Michie, editors, </editor> <booktitle> Machine Intelligence 4, </booktitle> <pages> pages 463-502. </pages> <publisher> Edinburgh University Press, Edinburgh, </publisher> <year> 1969. </year>
Reference-contexts: In section 9 we discuss some related work. Finally in section 9 we conclude this paper and point out some other control information that can be effectively formalized in the situation calculus. 2 The Situation Calculus The situation calculus (McCarthy and Hayes <ref> [15] </ref>) is a formalism for representing and reasoning about actions in dynamic domains. It is a many-sorted predicate calculus with some reserved predicate and function symbols. <p> G) 4 = (8s):S 0 &lt; s ^ H (g 1 & g 2 ; s) ^ H (G; s) P recedence (g 1 ; g 2 ; s): 19 8 Related Work The situation calculus has been used for planning ever since it's introduced (McCarthy [14], McCarthy and Hayes <ref> [15] </ref>, Green [7]). However, to the best of our knowledge, this paper is the first attempt in using the situation calculus to formalize control knowledge in planning.
Reference: [16] <author> N. J. Nilsson. </author> <booktitle> Principles of Articifial Intelligence. </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> Los Altos, CA., </address> <year> 1980. </year>
Reference-contexts: Let G 0 be a goal. A naive version of our linear regression planner adapted from (Nilsson <ref> [16] </ref> and Genesereth and Nilsson [6]) can be described as follows: 1. Initialize (for partial plans) to ;, G (for outstanding goals) to G 0 , and E (for equality constraints) to true. 2.
Reference: [17] <author> E. P. Pednault. </author> <title> Synthesizing plans that contain actions with context-dependent effects. </title> <journal> Computational Intelligence, </journal> <volume> 4 </volume> <pages> 356-372, </pages> <year> 1988. </year>
Reference-contexts: To formulate our theorem for computing g 1 g 2 in basic action theories, we need to introduce the notion of regression (cf. Waldinger [23], Pednault <ref> [17] </ref>, and Reiter [19]) and state constraints. Definition 5.1 Let D be a basic action theory, and (s) a formula that does not mention any other situation term except s. Let (do (ff; s)) be (s) with s replaced by do (ff; s).
Reference: [18] <author> J. Pinto and R. Reiter. </author> <title> Extending the situation calculus with event occurrences. </title> <booktitle> In Second Symposium on Logical Formalizations of Commonsense Reasoning, </booktitle> <year> 1993. </year>
Reference-contexts: Similar axioms are used in (Pinto and Reiter <ref> [18] </ref>). 3 For a detailed discussion of the use of induction in the situation calculus, see (Reiter [20]). 3 3 Simple Goals, Goals, and Plans We now define some basic concepts of classical planning.
Reference: [19] <author> R. Reiter. </author> <title> The frame problem in the situation calculus: a simple solution (sometimes) and a completeness result for goal regression. </title> <editor> In V. Lifschitz, editor, </editor> <booktitle> Artificial Intelligence and Mathematical Theory of Computation: Papers in Honor of John McCarthy, </booktitle> <pages> pages 418-420. </pages> <publisher> Academic Press, </publisher> <address> San Diego, CA, </address> <year> 1991. </year>
Reference-contexts: To formulate our theorem for computing g 1 g 2 in basic action theories, we need to introduce the notion of regression (cf. Waldinger [23], Pednault [17], and Reiter <ref> [19] </ref>) and state constraints. Definition 5.1 Let D be a basic action theory, and (s) a formula that does not mention any other situation term except s. Let (do (ff; s)) be (s) with s replaced by do (ff; s).
Reference: [20] <author> R. Reiter. </author> <title> Proving properties of states in the situation calculus. </title> <journal> Artificial Intelligence, </journal> <volume> 64 </volume> <pages> 337-351, </pages> <year> 1993. </year>
Reference-contexts: :s &lt; s: Unique names: s 1 &lt; s 2 s 1 6= s 2 : Induction on &lt;: (8P )[P (S 0 ) ^ (8a; s)(P (s) ^ P oss (a; s) P (do (a; s))) (8s)(S 0 s P (s))]: 2 These axioms have their origin in (Reiter <ref> [20] </ref>). Similar axioms are used in (Pinto and Reiter [18]). 3 For a detailed discussion of the use of induction in the situation calculus, see (Reiter [20]). 3 3 Simple Goals, Goals, and Plans We now define some basic concepts of classical planning. <p> s)(P (s) ^ P oss (a; s) P (do (a; s))) (8s)(S 0 s P (s))]: 2 These axioms have their origin in (Reiter <ref> [20] </ref>). Similar axioms are used in (Pinto and Reiter [18]). 3 For a detailed discussion of the use of induction in the situation calculus, see (Reiter [20]). 3 3 Simple Goals, Goals, and Plans We now define some basic concepts of classical planning. <p> To prove that (8s):s S 0 C (s) is a state constraint, we normally need to appeal to the principle of induction on &lt; in Proposition 2.1 (Reiter <ref> [20] </ref>). Example 5.3 Continuing our discussion of the blocks world Example 5.1. Consider the sentence (8s):s S 0 C (s), where C (s) is (8x):H (clear (x); s) :(9y)H (on (y; x); s): We claim that (8s):s S 0 C (s) is a state constraint.
Reference: [21] <author> R. Reiter. </author> <title> On specifying database updates. </title> <journal> Journal of Logic Programming, </journal> <volume> 25(1) </volume> <pages> 53-91, </pages> <year> 1995. </year>
Reference-contexts: In the following, we show how to use it to compute for a special class of action theories. 5 Computing the Subgoal Ordering in Action Theo ries with Successor State Axioms A basic action theory D is one that has the following form (cf. Reiter <ref> [21] </ref> and Lin and Reiter [11]): D = [ D ss [ D ap [ D una [ D S 0 ; where * is the set of the foundational axioms for situations as given in Section 2. * D ss is a set of successor state axioms, one for each
Reference: [22] <author> D. E. Smith and M. A. Peot. </author> <title> Postponing threats in partial-order planning. </title> <booktitle> In Proceedings of the Eleventh National Conference on Artificial Intelligence (AAAI-93), </booktitle> <publisher> AAAI Press, </publisher> <address> Menlo Park, CA., </address> <pages> pages 500-506, </pages> <year> 1993. </year>
Reference-contexts: It can be shown that this planner inherits many properties of SNLP. For instance, it is also sound and complete for ground goals. Example 6.1 Let us now illustrate this planner using a machine shop scheduling domain adapted from (Smith and Peot <ref> [22] </ref>). Fluents: * shaped (x): x is shaped. * drilled (x): x is drilled. * f astened (x; y): x is fastened to y. * f ree (x): x is not fastened to any other object. <p> When this is done, it has a complete, order consistent nonlinear plan. Notice that for this example, as long as the planner makes use of knowledge about , no threat removal strategies are needed. For SNLP, as shown in (Smith and Peot <ref> [22] </ref>), some non-trivial threat removal strategies are needed in order to avoid backtracking. 7 Some General Considerations In general, computing requires induction, thus is intractable. However, since is defined context independently, the computation does not need to be done at run time. <p> Our subgoal ordering is also related to various threat removal and conflict resolution strategies in nonlinear planning (Smith and Peot <ref> [22] </ref>, Yang [24], and others). It is possible that some provably correct threat removal strategies can be derived from our goal ordering, and vice versa. However, our goal ordering has the advantage that it is planner independent. As we have shown, it is applicable to both linear and nonlinear planners.
Reference: [23] <author> R. Waldinger. </author> <title> Achieving several goals simultaneously. </title> <editor> In E. Elcock and D. Michie, editors, </editor> <booktitle> Machine Intelligence, </booktitle> <pages> pages 94-136. </pages> <publisher> Ellis Horwood, Edinburgh, </publisher> <address> Scotland, </address> <year> 1977. </year>
Reference-contexts: To formulate our theorem for computing g 1 g 2 in basic action theories, we need to introduce the notion of regression (cf. Waldinger <ref> [23] </ref>, Pednault [17], and Reiter [19]) and state constraints. Definition 5.1 Let D be a basic action theory, and (s) a formula that does not mention any other situation term except s. Let (do (ff; s)) be (s) with s replaced by do (ff; s).
Reference: [24] <author> Q. Yang. </author> <title> A theory of conflict resolution in planning. </title> <journal> Artificial Intelligence, </journal> <volume> 58 </volume> <pages> 361-392, </pages> <year> 1992. </year> <month> 22 </month>
Reference-contexts: Our subgoal ordering is also related to various threat removal and conflict resolution strategies in nonlinear planning (Smith and Peot [22], Yang <ref> [24] </ref>, and others). It is possible that some provably correct threat removal strategies can be derived from our goal ordering, and vice versa. However, our goal ordering has the advantage that it is planner independent. As we have shown, it is applicable to both linear and nonlinear planners.
References-found: 24

