URL: ftp://ftp.eecs.umich.edu/people/jaeho/cirffss94-2.ps
Refering-URL: http://ai.eecs.umich.edu/people/jaeho/jaeho.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: AIAA/NASA Conference on Intelligent Robots in Field, Factory, Service, and Space (CIRFFSS '94) MOBILE ROBOT
Author: David Kortenkamp Marcus Huber, Frank Koss, William Belding, Jaeho Lee, Annie Wu, Clint Bidlack and Seth Rodgers 
Address: Ann Arbor, MI 48109  
Affiliation: Artificial Intelligence Laboratory The University of Michigan  
Abstract: Autonomous mobile robots need to integrate many different skills in order to perform complex tasks. In particular, they need to explore, sense, map and navigate in unknown or partially known environments. This paper describes a robot system that is designed to perform a find-and-deliver task in an office-building-like environment. The robot's initial orientation and location within the environment are not known, but the robot does have an a-priori map of the environment. We describe a sensor-based map representation that the robot uses while exploring its environment. We also describe how the robot determines its initial position and orientation within the environment, how it explores the environment for a visually-tagged object, how it recognizes the object and how it delivers the object. The robot also updates its map to reflect changes in the environment. While the entire robot system has not yet been integrated, each subsystem described in this paper has been implemented and tested. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Kenneth Basye, Thomas Dean, and Jeffrey Scott Vitter. </author> <title> Coping with uncertainty in map learning. </title> <booktitle> In Proceedings of the International Joint Conferences on Artificial Intelligence, </booktitle> <year> 1989. </year>
Reference-contexts: The first issue when creating such a representation is to decide on an appropriate sonar signature that will distinguish between different regions. Detecting region boundaries There have been many approaches to using sonar sensors to define distinctive places in an environment, including <ref> [10, 1, 6, 7, 9, 8] </ref>. In our approach, a region in the environment is characterized by having a common sonar signature throughout its extent, where the tectable by CARMEL. signature is the pattern of free or blocked space to the front, back and sides of the robot.
Reference: [2] <author> Johann Borenstein and Yoram Koren. </author> <title> His-togramic in-motion mapping for mobile robot obstacle avoidance. </title> <journal> IEEE Journal of Robotics and Automation, </journal> <volume> 7(4), </volume> <year> 1991. </year>
Reference-contexts: Three computers are on-board CARMEL, one computer each for the motors and sonar sensors and a 486-PC for high-level processing. The 486-PC has a framegrabber and performs all image processing. CARMEL has a basic obstacle avoidance competence provided by an algorithm called VFH <ref> [2, 3, 4] </ref>. VFH constructs a certainty grid of sonar hits and uses it to continually compute a new direction that will take the robot towards its target while avoiding obstacles. Overview We first present the robot's representation of its environment.
Reference: [3] <author> Johann Borenstein and Yoram Koren. </author> <title> The Vector Field Histogram for fast obstacle-avoidance for mobile robots. </title> <journal> IEEE Journal of Robotics and Automation, </journal> <volume> 7(3), </volume> <year> 1991. </year>
Reference-contexts: Three computers are on-board CARMEL, one computer each for the motors and sonar sensors and a 486-PC for high-level processing. The 486-PC has a framegrabber and performs all image processing. CARMEL has a basic obstacle avoidance competence provided by an algorithm called VFH <ref> [2, 3, 4] </ref>. VFH constructs a certainty grid of sonar hits and uses it to continually compute a new direction that will take the robot towards its target while avoiding obstacles. Overview We first present the robot's representation of its environment.
Reference: [4] <author> Johann Borenstein and Yorem Koren. </author> <title> Real-time obstacle avoidance for fast mobile robots. </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics, </journal> <volume> 19(5), </volume> <year> 1989. </year>
Reference-contexts: Three computers are on-board CARMEL, one computer each for the motors and sonar sensors and a 486-PC for high-level processing. The 486-PC has a framegrabber and performs all image processing. CARMEL has a basic obstacle avoidance competence provided by an algorithm called VFH <ref> [2, 3, 4] </ref>. VFH constructs a certainty grid of sonar hits and uses it to continually compute a new direction that will take the robot towards its target while avoiding obstacles. Overview We first present the robot's representation of its environment. <p> Thus, there are 16 unique sonar signatures in a rectilinear environment (see Figure 3 for a complete listing of the 16 sonar signatures). Our approach is unique in that it is directly tied to an obstacle avoidance algorithm|the Vector Field Histogram (VFH) <ref> [4] </ref>. The VFH algorithm first creates a histogram grid, which is a certainty grid representation of the objects surrounding the robot as detected using the robot's sonar sensors. VFH then takes a local window of the certainty grid and converts it into a polar representation called the polar histogram.
Reference: [5] <author> Eugene Charniak. </author> <title> Bayesian networks without tears. </title> <journal> AI Magazine, </journal> <month> Winter, </month> <year> 1991. </year>
Reference-contexts: Belief Network Approach In the second localization approach, the dependence of the sensed features on the world map, the robot's initial orientation, and the direction of travel of the robot as it attempts to localize itself, is modeled using a belief network <ref> [5, 11] </ref>. As the robot moves about and sees new features, the belief network accumulates a history of the features observed and the movements that the robot has made.
Reference: [6] <author> Thomas Dean, Kenneth Basye, Robert Chekaluk, Seungseok Hyun, Moises Lejter, and Margaret Randazza. </author> <title> Coping with uncertainty in a control system for navigation and exploration. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence (AAAI), </booktitle> <year> 1990. </year>
Reference-contexts: The first issue when creating such a representation is to decide on an appropriate sonar signature that will distinguish between different regions. Detecting region boundaries There have been many approaches to using sonar sensors to define distinctive places in an environment, including <ref> [10, 1, 6, 7, 9, 8] </ref>. In our approach, a region in the environment is characterized by having a common sonar signature throughout its extent, where the tectable by CARMEL. signature is the pattern of free or blocked space to the front, back and sides of the robot.
Reference: [7] <author> David Kortenkamp, L. Douglas Baker, and Terry Weymouth. </author> <title> Using gateways to build a route map. </title> <booktitle> In Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems, </booktitle> <year> 1992. </year>
Reference-contexts: The first issue when creating such a representation is to decide on an appropriate sonar signature that will distinguish between different regions. Detecting region boundaries There have been many approaches to using sonar sensors to define distinctive places in an environment, including <ref> [10, 1, 6, 7, 9, 8] </ref>. In our approach, a region in the environment is characterized by having a common sonar signature throughout its extent, where the tectable by CARMEL. signature is the pattern of free or blocked space to the front, back and sides of the robot.
Reference: [8] <author> Benjamin J. Kuipers and Yung-Tai Byun. </author> <title> A robot exploration and mapping strategy based on a semantic hierarchy of spatial representations. </title> <booktitle> Robotics and Autonomous Systems, </booktitle> <volume> 8, </volume> <year> 1991. </year>
Reference-contexts: The first issue when creating such a representation is to decide on an appropriate sonar signature that will distinguish between different regions. Detecting region boundaries There have been many approaches to using sonar sensors to define distinctive places in an environment, including <ref> [10, 1, 6, 7, 9, 8] </ref>. In our approach, a region in the environment is characterized by having a common sonar signature throughout its extent, where the tectable by CARMEL. signature is the pattern of free or blocked space to the front, back and sides of the robot.
Reference: [9] <author> Maja K. Mataric. </author> <title> Integration of representation into goal-driven behavior-based robots. </title> <journal> IEEE Transactions on Robotics and Automation, </journal> <volume> 8(3), </volume> <year> 1992. </year>
Reference-contexts: The first issue when creating such a representation is to decide on an appropriate sonar signature that will distinguish between different regions. Detecting region boundaries There have been many approaches to using sonar sensors to define distinctive places in an environment, including <ref> [10, 1, 6, 7, 9, 8] </ref>. In our approach, a region in the environment is characterized by having a common sonar signature throughout its extent, where the tectable by CARMEL. signature is the pattern of free or blocked space to the front, back and sides of the robot.
Reference: [10] <author> David P. Miller. </author> <title> A Spatial Representation System for Mobile Robots. </title> <booktitle> In Proceedings IEEE International Conference on Robotics and Automation, </booktitle> <address> St. Louis, </address> <year> 1985. </year>
Reference-contexts: The first issue when creating such a representation is to decide on an appropriate sonar signature that will distinguish between different regions. Detecting region boundaries There have been many approaches to using sonar sensors to define distinctive places in an environment, including <ref> [10, 1, 6, 7, 9, 8] </ref>. In our approach, a region in the environment is characterized by having a common sonar signature throughout its extent, where the tectable by CARMEL. signature is the pattern of free or blocked space to the front, back and sides of the robot.
Reference: [11] <author> Judea Pearl. </author> <title> Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1988. </year>
Reference-contexts: Belief Network Approach In the second localization approach, the dependence of the sensed features on the world map, the robot's initial orientation, and the direction of travel of the robot as it attempts to localize itself, is modeled using a belief network <ref> [5, 11] </ref>. As the robot moves about and sees new features, the belief network accumulates a history of the features observed and the movements that the robot has made.
Reference: [12] <author> Annie Wu, Clint Bidlack, Arun Katkere, Roy Feague, and Terry Weymouth. </author> <title> Vision-based object pose estimation for mobile robots. </title> <booktitle> In Proceedings of the AIAA/NASA Conference on Intelligent Robots in Field, Factory, Service, and Space (CIRFFSS '94), </booktitle> <year> 1994. </year> <month> 11 </month>
Reference-contexts: We will describe the algorithm for detecting the `X' here. The algorithm for determining the pose of the `X' is described in <ref> [12] </ref>. Marker detection The marker detection phase is composed of two main routines: the connected components routine and the marker identification routine. The detection phase must be both fast and accurate for the pose estimation algorithm to be useful for real-time tasks.
References-found: 12

