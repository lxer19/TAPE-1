URL: ftp://ftp-pubs.lcs.mit.edu/pub/lcs-pubs/tr.outbox/MIT-LCS-TR-488.ps.gz
Refering-URL: ftp://ftp-pubs.lcs.mit.edu/pub/lcs-pubs/listings/trlow.html
Root-URL: 
Title: An Incremental Type Inference System for the Programming Language Id  
Author: Shail Aditya Gupta 
Address: Technology,  
Affiliation: Dept. of Electrical Engineering and Computer Science, Massachusetts Institute of  
Note: Originally published as Master's thesis,  
Date: November 1990  September 1990.  
Pubnum: MIT LCS TR-488  
Abstract: This report describes research done at the Laboratory of Computer Science of the Massachusetts Institute of Technology. Funding for the Laboratory is provided in part by the Advanced Research Projects Agency of the Department of Defense under Office of Naval Research contract N00014-84-K-0099. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Alfred V. Aho, John E. Hopcroft, and Jeffrey D. Ullman. </author> <title> The Design and Analysis of Computer Algorithms. </title> <publisher> Addison-Wesley, </publisher> <year> 1974. </year>
Reference-contexts: This can be accomplished using the standard graph algorithm for finding the strongly connected components in a directed graph <ref> [1] </ref>. Each binding is assumed to be a node in the graph. <p> Considering each group as one supernode (using the fixpoint tuple binding transformation as described above), the graph becomes a directed acyclic graph (DAG) which can then be topologically sorted <ref> [1] </ref> bottom up. This numbers the set of nodes so that the nodes being used by other nodes appear earlier in the numbering than those using them. <p> Or else, the compiler can do that once in the beginning using the SCC algorithm described in <ref> [1] </ref>, which also identifies the correct topological ordering of the definitions. <p> Our implementation 102 leans more towards pragmatic simplicity than asymptotic efficiency, and is a variation of Huet's algorithm [28] based on the almost linear Union-Find algorithm <ref> [1] </ref>. Again, the choice of an implementation is independent of our incremental book-keeping mechanism so we will not discuss this aspect any further. 3. <p> But the above pair of expressions have different meanings as shown by their use in the following simple context. def context (x,y) = f x <ref> [1] </ref> = 1 in context e1 =) Undefined! context e2 =) 1 Referencial transparency is a very useful property for compiler optimizations, so we would like to preserve it for the rest of the program even if some parts of it are non-functional. Therefore our goal is two-fold, 1.
Reference: [2] <author> Andrew W. Appel and David B. MacQueen. </author> <title> A Standard ML Compiler. Distributed along with the Standard ML of New Jersey Compiler, </title> <year> 1989. </year>
Reference-contexts: ML, in most of its implementations <ref> [2, 3, 51, 24, 10] </ref>, has an interactive session to which definitions can be incrementally added, but it still requires a complete program to be specified bottom-up before any of its parts can be tested. <p> We will briefly describe the solution presented by Tofte, his description of the solution by Damas in [19] and subsequent refinements by David MacQueen as implemented in Standard ML of New Jersey <ref> [2, 3] </ref>. Finally, we will present the approach taken in Id, which is a refinement of these earlier works. 153 5.1 Non-Functional Constructs in Id Id has two classes of non-functional objects, I-Structures and mutex objects [9, 48]. <p> Following an idea due to David MacQueen that is currently used in Standard ML of New Jersey <ref> [2, 3] </ref>, we may add this flexibility to Damas' system as follows. Each type variable inside a type expression is associated with a natural number called its rank. This identifies the depth of -nesting of the given type variable after which it will enter the set of immediate store types.
Reference: [3] <author> Andrew W. Appel and David B. MacQueen. </author> <title> Standard ML Reference Manual. </title> <institution> Princeton University and AT&T Bell Laboratories, </institution> <note> Preliminary edition, </note> <year> 1989. </year> <title> Distributed along with the Standard ML of New Jersey Compiler. </title>
Reference-contexts: ML, in most of its implementations <ref> [2, 3, 51, 24, 10] </ref>, has an interactive session to which definitions can be incrementally added, but it still requires a complete program to be specified bottom-up before any of its parts can be tested. <p> We will briefly describe the solution presented by Tofte, his description of the solution by Damas in [19] and subsequent refinements by David MacQueen as implemented in Standard ML of New Jersey <ref> [2, 3] </ref>. Finally, we will present the approach taken in Id, which is a refinement of these earlier works. 153 5.1 Non-Functional Constructs in Id Id has two classes of non-functional objects, I-Structures and mutex objects [9, 48]. <p> Following an idea due to David MacQueen that is currently used in Standard ML of New Jersey <ref> [2, 3] </ref>, we may add this flexibility to Damas' system as follows. Each type variable inside a type expression is associated with a natural number called its rank. This identifies the depth of -nesting of the given type variable after which it will enter the set of immediate store types.
Reference: [4] <author> Zena M. Ariola and Arvind. P-TAC: </author> <title> A Parallel Intermediate Language. </title> <booktitle> In Proceedings of the Conference on Functional Programming Languages and Computer Architectures, </booktitle> <address> London, UK, </address> <pages> pages 230-242, </pages> <month> September </month> <year> 1989. </year> <note> Also: CSG Memo 295, </note> <institution> MIT Laboratory for Computer Science 545 Technology Square, </institution> <address> Cambridge, MA 02139, USA. </address>
Reference-contexts: For a concrete treatment of the Id syntax, the reader is referred to [46, 48]. A preliminary discussion of Id dynamic semantics is found in [8], while a more recent and revised version appears in <ref> [4] </ref>. We will present examples from Id, explaining their semantics informally. For the most part, the meaning should be fairly clear and we will rely on the reader's intuition in this matter. Consider the two programs in figure 2.1. <p> Literature has standard techniques to translate pattern matching into nested conditionals [10, 11, 15] as well. Thus, our task of static type analysis is greatly simplified after these transformations 12 . The kernel language description has been revised extensively by Ariola and Arvind in <ref> [4] </ref>. There the reader will find precise operational dynamic semantics and proofs of confluence etc. We will not go into those details since we are concerned with static semantics only, but we will draw from their description of the Id kernel syntax. <p> We will explore the issue of polymorphic type inferencing in presence of such assignable structures in chapter 5. 2.4.1 Mini-Language vs Id Kernel Language The kernel language P-TAC as shown in <ref> [4] </ref> and [9] is reproduced here in figure 2.7. The start symbol is Program. The superscripts on constants and identifiers denote their syntactic arity. We will restrict ourselves to the functional subset of P-TAC which simply amounts to ignoring the I-structure manipulation functions, namely, allocate, I select, and I set.
Reference: [5] <author> Arvind and David E. Culler. </author> <title> Dataflow Architectures. </title> <booktitle> In Annual Reviews in Computer Science, </booktitle> <volume> volume 1, </volume> <pages> pages 225-253. </pages> <publisher> Annual Reviews Inc., </publisher> <address> Palo Alto, CA, </address> <year> 1986. </year>
Reference-contexts: In either case, the top-level definitions do not have to be processed in any particular order. The user may edit and compile definitions interactively in arbitrary order. 3. The compiler is smoothly integrated with the editor and an emulator for the Tagged-token Dataflow Architecture <ref> [5, 7] </ref> into "Id-World" [50], a friendly, interactive, parallel programming environment. Each top-level compilation unit may be compiled, loaded, and linked with other similar units and then executed via commands given to the interactive 4 "Miranda" is a trademark of Research Software Ltd. 14 emulator. 4.
Reference: [6] <author> Arvind, Steve Heller, and Rishiyur S. Nikhil. </author> <title> Programming Generality and Parallel Computers. </title> <booktitle> In Fourth International Symposium on Biological and Artificial Intelligence Systems, </booktitle> <address> Trento, Italy, </address> <month> September </month> <year> 1988. </year> <note> Also: CSG Memo 287, </note> <institution> MIT Laboratory for Computer Science, 545 Technology Square, </institution> <address> Cambridge, MA 02139. </address>
Reference-contexts: The idea here is to be able to grow a list at its end rather than at its front. There is no functional way to do this. Using open lists, we can efficiently copy the 5 Refer <ref> [6, 48] </ref> for details and more examples of this technique. 155 first list as we traverse it down in a loop and stick the second list at its end in order to close it and make it into a valid functional list 6 .
Reference: [7] <author> Arvind and Rishiyur S. Nikhil. </author> <title> Executing a Program on the MIT Tagged-Token Dataflow Architecture. </title> <type> Technical Report CSG Memo 271, </type> <institution> MIT Laboratory for Computer Science, 545 Technology Square, </institution> <address> Cambridge, MA 02139, </address> <month> June </month> <year> 1988. </year> <note> An earlier version appeared in Proceedings of the PARLE Conference, </note> <institution> Eindhoven, </institution> <address> The Netherlands, </address> <publisher> Springer-Verlag LNCS Volume 259, </publisher> <month> June 15-19, </month> <year> 1987. </year>
Reference-contexts: In either case, the top-level definitions do not have to be processed in any particular order. The user may edit and compile definitions interactively in arbitrary order. 3. The compiler is smoothly integrated with the editor and an emulator for the Tagged-token Dataflow Architecture <ref> [5, 7] </ref> into "Id-World" [50], a friendly, interactive, parallel programming environment. Each top-level compilation unit may be compiled, loaded, and linked with other similar units and then executed via commands given to the interactive 4 "Miranda" is a trademark of Research Software Ltd. 14 emulator. 4.
Reference: [8] <author> Arvind, Rishiyur S. Nikhil, and Keshav K. Pingali. </author> <title> Id Nouveau Reference Manual, Part II: Operational Semantics. </title> <type> Technical report, </type> <institution> Computation Structures Group, MIT Laboratory for Computer Science, 545 Technology Square, </institution> <address> Cambridge, MA 02139, </address> <month> April </month> <year> 1987. </year>
Reference-contexts: For a concrete treatment of the Id syntax, the reader is referred to [46, 48]. A preliminary discussion of Id dynamic semantics is found in <ref> [8] </ref>, while a more recent and revised version appears in [4]. We will present examples from Id, explaining their semantics informally. For the most part, the meaning should be fairly clear and we will rely on the reader's intuition in this matter. Consider the two programs in figure 2.1. <p> Id is an evolving language [45, 46, 48]. But most of its important syntactic features can be expressed in a small subset of the full language. <ref> [8] </ref> discusses standard techniques for such "kernelization"; converting for -loops to while-loops and while-loops to tail-recursive procedure 40 calls, infix operators to function applications, n-tuple manipulations (making and selection) into family of primitive functions, removing n-tuples from function arguments and block bindings etc.
Reference: [9] <author> Arvind, Rishiyur S. Nikhil, and Keshav K. Pingali. I-Structures: </author> <title> Data Structures for Parallel Computing. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 11(4) </volume> <pages> 598-632, </pages> <year> 1989. </year>
Reference-contexts: We will not go into those details since we are concerned with static semantics only, but we will draw from their description of the Id kernel syntax. We also draw heavily from the description of I-structures by Arvind et al. in <ref> [9] </ref> which are assignable data structures used to extend the functional programming paradigm to provide efficient synchronisation and storage without losing useful properties such as confluence. <p> We will explore the issue of polymorphic type inferencing in presence of such assignable structures in chapter 5. 2.4.1 Mini-Language vs Id Kernel Language The kernel language P-TAC as shown in [4] and <ref> [9] </ref> is reproduced here in figure 2.7. The start symbol is Program. The superscripts on constants and identifiers denote their syntactic arity. We will restrict ourselves to the functional subset of P-TAC which simply amounts to ignoring the I-structure manipulation functions, namely, allocate, I select, and I set. <p> Finally, we will present the approach taken in Id, which is a refinement of these earlier works. 153 5.1 Non-Functional Constructs in Id Id has two classes of non-functional objects, I-Structures and mutex objects <ref> [9, 48] </ref>. We will not concern ourselves with the run-time dynamic semantics of these objects except for the fact that they behave like storage locations, in that they can be allocated without specifying their contents, be assigned to, or be queried for their contents 1 . <p> We will informally describe the use of some non-functional constructs in Id and the associated requirements they place on the type-checker 2 . Consider the following Id example called wavefront 3 taken from <ref> [9] </ref>, f A = I matrix ((1,m),(1,n)); fFor i &lt;- 1 to m do A [i,1] = 1 g; fFor j &lt;- 2 to n do A [1,j] = 1 g; fFor i &lt;- 2 to m do fFor j &lt;- 2 to n do A [i,j] = A [i-1,j] +
Reference: [10] <author> Lennart Augustsson. </author> <title> A Compiler for Lazy ML. </title> <booktitle> In Proceedings of the 1984 ACM Conference on Lisp and Functional Programming, </booktitle> <address> Austin, Texas, </address> <pages> pages 218-227, </pages> <month> August </month> <year> 1984. </year> <month> 171 </month>
Reference-contexts: ML, in most of its implementations <ref> [2, 3, 51, 24, 10] </ref>, has an interactive session to which definitions can be incrementally added, but it still requires a complete program to be specified bottom-up before any of its parts can be tested. <p> Literature has standard techniques to translate pattern matching into nested conditionals <ref> [10, 11, 15] </ref> as well. Thus, our task of static type analysis is greatly simplified after these transformations 12 . The kernel language description has been revised extensively by Ariola and Arvind in [4]. There the reader will find precise operational dynamic semantics and proofs of confluence etc.
Reference: [11] <author> Lennart Augustsson. </author> <title> Compiling Pattern Matching. </title> <booktitle> In Proceedings of the 1985 Workshop on Implementations of Functional Languages, </booktitle> <institution> Goteborg, Sweden. Chalmers University of Technology, </institution> <month> February </month> <year> 1985. </year>
Reference-contexts: Literature has standard techniques to translate pattern matching into nested conditionals <ref> [10, 11, 15] </ref> as well. Thus, our task of static type analysis is greatly simplified after these transformations 12 . The kernel language description has been revised extensively by Ariola and Arvind in [4]. There the reader will find precise operational dynamic semantics and proofs of confluence etc.
Reference: [12] <author> H. P. Barendregt. </author> <title> The Lambda Calculus: Its Syntax and Semantics. </title> <publisher> North-Holland, </publisher> <address> Amsterdam, </address> <year> 1984. </year>
Reference-contexts: The literature is filled with the discussion of semantics of Lambda Calculus, both operational and denotational. A complete theoretical treatment can be found in <ref> [12] </ref>. A very good discussion on Scott domains and denotational semantics can be found in [56]. The semantics of the type expressions is also fairly simple.
Reference: [13] <author> Kim B. Bruce, Albert R. Meyer, and John C. Mitchell. </author> <title> The Semantics of Second-Order Lambda Calculus. </title> <journal> Information and Computation, </journal> <volume> 85 </volume> <pages> 76-134, </pages> <year> 1990. </year>
Reference-contexts: The lists to the right of the arrow (=)) are the results of the computation shown at the left. While polymorphic, higher-order functions are useful and compact, they pose some theoretical problems for type inferencing. Such functions, in their full generality, are usually modelled using second-order typed Lambda Calculus <ref> [13, 23, 53] </ref>. The question of decidability of type inference in this model is still open. Some recent work in this field attempts to identify subsets of the full polymorphic model where this question can still be answered [30]. There are two ways out of this problem. <p> In fact, the second-order typed Lambda Calculus provides a much cleaner and easier to understand framework for a more general and richer class of functions <ref> [13, 23, 53] </ref>. Historically, though, only recently has there been an attempt to understand the various levels of type inference possible in that model, so as to keep it decidable [30]. <p> The interested reader is refered to <ref> [13] </ref> for further discussion in this regard. 2.3.5 The Type Inference Algorithm Given a set of inference rules, it is possible to implement them in various direct or indirect ways, addressing issues such as efficiency and correctness. <p> So there is no active or dynamic polymorphism in this system in the sense of Girard-Reynolds second-order polymorphic Lambda Calculus <ref> [13, 23, 53] </ref> and indeed the class of programs accepted by this system is exactly the same as that of simply typed first-order Lambda Calculus. But this system offers it in a package that gives the appearance of (static) polymorphism.
Reference: [14] <author> Rod M. Burstall, David B. MacQueen, and Don Sanella. </author> <title> Hope: an Experimental Applicative Language. </title> <booktitle> In Proceedings of the Lisp Conference, Stanford, </booktitle> <pages> pages 136-143. </pages> <publisher> ACM, </publisher> <month> August </month> <year> 1980. </year>
Reference-contexts: It supports higher-order functions, algebraic types, abstract data types, and overloading of identifiers, and in some of these respects it is similar to one or more of its contemporaries in the realm of functional langauges, namely, ML, Hope <ref> [14] </ref>, Miranda, Haskell [27] etc. But the programming environment for Id is different from that of these other languages in the following important ways. 1. The Id compiler [59] is incremental in nature. <p> We can restrict the polymorphism of arguments and results of functions in certain ways so that we are still able to decidably infer their type using known algorithms. The most popular approach, taken by many modern languages such as ML [24, 25, 41, 42], Miranda [60, 61], Hope <ref> [14] </ref>, Haskell [27] and Id, is to use a special polymorphic type inference system now commonly referred to as the Hindley/Milner type system [20, 26, 40]. Other, more recent efforts to strengthen this inference system have met with only partial success [30, 32, 43].
Reference: [15] <author> L. Cardelli. </author> <title> Compiling a Functional Language. </title> <booktitle> In Proceedings of the ACM Symposium on LISP and Functional Programming, </booktitle> <pages> pages 208-217, </pages> <month> August </month> <year> 1984. </year>
Reference-contexts: Literature has standard techniques to translate pattern matching into nested conditionals <ref> [10, 11, 15] </ref> as well. Thus, our task of static type analysis is greatly simplified after these transformations 12 . The kernel language description has been revised extensively by Ariola and Arvind in [4]. There the reader will find precise operational dynamic semantics and proofs of confluence etc.
Reference: [16] <author> L. Cardelli. </author> <title> Basic Polymorphic Typechecking. </title> <booktitle> Science of Computer Programming, </booktitle> <volume> 8(2) </volume> <pages> 147-172, </pages> <year> 1987. </year>
Reference-contexts: In chapter 2 we carefully examine the problem of polymorphic type inference for a functional language in the light of the Hindley/Milner type system <ref> [16, 20] </ref> and establish facts and notation used in the rest of the thesis. We describe the basic Hindley/Milner type inference system using an abstract syntax. This forms the basis for extension and reasoning for the subsequent chapters.
Reference: [17] <author> L. Cardelli and P. Wegner. </author> <title> On Understanding Types, Data Abstraction and Polymor-phism. </title> <journal> Computing Surveys, </journal> <volume> 17(4), </volume> <month> December </month> <year> 1985. </year>
Reference-contexts: Id is a strongly typed programming language. Furthermore, it supports type inferencing and polymorphism. We motivate these features below and present a basic type inferencing system for Id. An excellent introduction and survey of these concepts is found in <ref> [17] </ref>. We assume no previous knowledge on the part of the reader regarding the basic concepts of type inferencing, polymorphism, Hindley/Milner type system, its associated theoretical basis or the Id language. <p> Thus, we see that polymorphism and static type inferencing are useful features that help to combine the reliability obtained from strong typing with ease and efficiency of coding seen in untyped languages. 2.2.1 Kinds of Polymorphism Cardelli and Wegner describe various kinds of polymorphism in <ref> [17] </ref>. We have already seen Parametric Polymorphism exhibited by id length, which essentially means that the polymorphic functions have an explicit or implicit type parameter which determines the type of the argument for each application of that function.
Reference: [18] <author> D. Clement, J. Despeyroux, T. Despeyroux, and G. Kahn. </author> <title> A Simple Applicative Language: </title> <booktitle> Mini-ML. In Proceedings of the ACM Symposium on LISP and Functional Programming, </booktitle> <pages> pages 13-27, </pages> <month> August </month> <year> 1986. </year>
Reference-contexts: But it can be shown that these two systems admit exactly the same expressions and are thus equivalent in this sense. The equivalence of DM and DM 0 is captured in the following theorem proved in <ref> [18] </ref>. 33 Theorem 2.1 The system DM 0 is equivalent to system DM in the following sense: TE ` e : t =) TE ` e : t DM DM 0 ` e : t ^ close (TE; t ) - This means that every typing derivable in this DM 0
Reference: [19] <author> L. Damas. </author> <title> Type Assignment in Programming Languages. </title> <type> PhD thesis, </type> <institution> University of Edin-burgh, Department of Computer Science, </institution> <year> 1985. </year>
Reference-contexts: The basic inferencing mechanism was first devised by Hindley [26], which was later independently rediscovered and extended by Milner [40] to allow polymorphic functions. The theoretical basis was firmly established in Denotational Semantics by Damas <ref> [20, 19] </ref> and in Operational Semantics by Tofte [57]. Since then, several expositions have appeared in the literature, either in context of the languages that use this system or those that extend the richness or power of the system in some way (typing polymorphic references, type-containment, type-coercion etc.). <p> This is a fundamental property necessary for any inference mechanism to 36 establish its validity with respect to the associated operational or denotational computation model. In his original paper [40], Milner showed the semantic soundness of well-typed expressions. In the framework of Damas-Milner system DM as described in <ref> [20, 19] </ref>, Damas proved the soundness of his system using Denotational Semantics. Due to theorem 2.1, that system and the system presented here are equivalent. Therefore, intuitively it should be clear that the soundness theorem extends to this system as well. <p> Basically, this says that all typings of an expression can be obtained as instantiations of the closed version of the type returned by W in the final type environment. The proof of these results appears in [57]. The corresponding results for the DM system are proved in <ref> [19] </ref>. This completes our discussion of the Hindley/Milner type inference system. 2.4 Id Kernel Language In this section, we present the kernel language for Id. We will discuss how it fits with our mini-language described above and show how to perform basic type inferencing for programs written in it. <p> Then, we will discuss some theoretical and pragmatic issues involved in their polymorphic typing, taking examples from both Id and ML. We will briefly describe the solution presented by Tofte, his description of the solution by Damas in <ref> [19] </ref> and subsequent refinements by David MacQueen as implemented in Standard ML of New Jersey [2, 3]. <p> Therefore, the first statement will unify the type of the location r to be (int ! int ) ref and the system will detect the type error in the second expression while applying the contents of r to a bool. 159 Approximation II Damas, in his thesis <ref> [19] </ref>, takes a slightly different position 7 . He generates typings of the form, TE ` e : fl (5:1) where, is a type-scheme and is the set of types of all objects to which new references may be created as a side effect of evaluating e.
Reference: [20] <author> L. Damas and R. Milner. </author> <title> Principle Type Schemes for Functional Programs. </title> <booktitle> In Proceedings of the 9th ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 207-212, </pages> <year> 1982. </year>
Reference-contexts: In chapter 2 we carefully examine the problem of polymorphic type inference for a functional language in the light of the Hindley/Milner type system <ref> [16, 20] </ref> and establish facts and notation used in the rest of the thesis. We describe the basic Hindley/Milner type inference system using an abstract syntax. This forms the basis for extension and reasoning for the subsequent chapters. <p> The most popular approach, taken by many modern languages such as ML [24, 25, 41, 42], Miranda [60, 61], Hope [14], Haskell [27] and Id, is to use a special polymorphic type inference system now commonly referred to as the Hindley/Milner type system <ref> [20, 26, 40] </ref>. Other, more recent efforts to strengthen this inference system have met with only partial success [30, 32, 43]. The other way out is to help the type inference system by giving explicit type declarations in the program while still retaining polymorphic functions as first class objects. <p> The basic inferencing mechanism was first devised by Hindley [26], which was later independently rediscovered and extended by Milner [40] to allow polymorphic functions. The theoretical basis was firmly established in Denotational Semantics by Damas <ref> [20, 19] </ref> and in Operational Semantics by Tofte [57]. Since then, several expositions have appeared in the literature, either in context of the languages that use this system or those that extend the richness or power of the system in some way (typing polymorphic references, type-containment, type-coercion etc.). <p> Our notation is the same as used by Tofte in [57] and the description is primarily derived from the work of Damas <ref> [20] </ref>, Tofte [57], and Clement et al.[18]. 25 2.3.1 A Mini-Language Expressions We start with a set of basic constants and identifiers in the language as shown below. <p> of the following equivalent conditions hold, * For all types t 1 , 0 t 1 implies t 1 . * t 0 and no fi j is free in . * t 0 and FV () FV ( 0 ). 8 We differ slightly from the terminology used in <ref> [20] </ref> where these are called Instantiations and Generic Instantiations. 29 3. Similarly, by extension, instantiation of a type environment TE yields a generic instance TE 0 , written as TE - TE 0 , obtained by pointwise instantiation of the type-schemes in its range. <p> Readers familiar with the original Damas-Milner (DM ) inference system as described in <ref> [20] </ref> (refer to figure 2.5) will recognize the following differences in the system presented here (DM 0 ): 1. There are no separate rules for generalization of types or instantiation of type schemes. <p> Finally, we note the following lemmas which are proved in [57] for the DM 0 system. Their corresponding versions for the DM system are proved in <ref> [20] </ref>. Lemma 2.2 If t 0 then for all substitutions S, S St 0 . Lemma 2.3 If S is a substitution then, TE ` e : t =) S (TE ) ` e : St Another lemma from [20] relates typings with instantiated environments. <p> Their corresponding versions for the DM system are proved in <ref> [20] </ref>. Lemma 2.2 If t 0 then for all substitutions S, S St 0 . Lemma 2.3 If S is a substitution then, TE ` e : t =) S (TE ) ` e : St Another lemma from [20] relates typings with instantiated environments. <p> This is a fundamental property necessary for any inference mechanism to 36 establish its validity with respect to the associated operational or denotational computation model. In his original paper [40], Milner showed the semantic soundness of well-typed expressions. In the framework of Damas-Milner system DM as described in <ref> [20, 19] </ref>, Damas proved the soundness of his system using Denotational Semantics. Due to theorem 2.1, that system and the system presented here are equivalent. Therefore, intuitively it should be clear that the soundness theorem extends to this system as well.
Reference: [21] <author> S. I. Feldman. </author> <title> Make A Program for Maintaining Computer Programs. In Unix Programmer's Manual Supplementary Documents Volume 1. 4.3 Berkeley Software Distribution, </title> <month> April </month> <year> 1986. </year>
Reference-contexts: System designers have approached this problem in various ways. Some systems support separate compilation of physical partitions (such as files) of a large program that allows them to maintain consistency among the various components automatically, given some inter-partition dependency information; the UNIX 1 make facility <ref> [21] </ref> is an example. But then, it is the user's responsibility to setup the inter-dependence explicitly and the system has no automatic knowledge of the actual dependency among the partitions. The partitioning itself is artificial and has no default logical relationship with the actual code dependencies in the program.
Reference: [22] <author> David K. Gifford, Pierre Jouvelot, John M. Lucassen, and Mark A. Sheldon. </author> <title> FX-87 Reference Manual. </title> <type> Technical Report MIT/LCS/TR-407, </type> <institution> MIT Laboratory for Computer Science, </institution> <month> September </month> <year> 1987. </year>
Reference-contexts: Moreover, it is not clear that the additional expressive power gained by this approach would outweigh the loss in ease of programming and the increase in complexity of the compiler. There are experimental 24 systems based on this approach <ref> [22] </ref> and only future research may shed further light on the advantages of one over the other.
Reference: [23] <author> J. Y. Girard. </author> <title> Interpretation fonctionelle et elimination des coupures de l'arithmetique d'ordre superieur. </title> <institution> These D'Etat, Universite de Paris VII, </institution> <year> 1972. </year>
Reference-contexts: The lists to the right of the arrow (=)) are the results of the computation shown at the left. While polymorphic, higher-order functions are useful and compact, they pose some theoretical problems for type inferencing. Such functions, in their full generality, are usually modelled using second-order typed Lambda Calculus <ref> [13, 23, 53] </ref>. The question of decidability of type inference in this model is still open. Some recent work in this field attempts to identify subsets of the full polymorphic model where this question can still be answered [30]. There are two ways out of this problem. <p> In fact, the second-order typed Lambda Calculus provides a much cleaner and easier to understand framework for a more general and richer class of functions <ref> [13, 23, 53] </ref>. Historically, though, only recently has there been an attempt to understand the various levels of type inference possible in that model, so as to keep it decidable [30]. <p> So there is no active or dynamic polymorphism in this system in the sense of Girard-Reynolds second-order polymorphic Lambda Calculus <ref> [13, 23, 53] </ref> and indeed the class of programs accepted by this system is exactly the same as that of simply typed first-order Lambda Calculus. But this system offers it in a package that gives the appearance of (static) polymorphism.
Reference: [24] <author> Michael J. Gordon, Arthur J. Milner, and Christopher P. Wadsworth. </author> <title> Edinburgh LCF, </title> <booktitle> volume 78 of Lecture Notes in Computer Science, chapter 2. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1979. </year>
Reference-contexts: 2 Permitting the use of the same program code under multiple type contexts. 3 Inferring the type of every fragment of a program at compile time with very little or no help from the programmer. 13 Some recent efforts in the context of strongly typed functional languages such as ML <ref> [24, 25, 41, 42] </ref> and Miranda 4 [60, 61] have tried to come up with a workable solution for the interactive user, but their approach is not entirely satisfactory. <p> ML, in most of its implementations <ref> [2, 3, 51, 24, 10] </ref>, has an interactive session to which definitions can be incrementally added, but it still requires a complete program to be specified bottom-up before any of its parts can be tested. <p> In chapter 5, we extend the basic type inferencing mechanism for functional programs to incorporate non-functional language constructs. Specifically, the problem is to correctly type-check a polymorphic reference to a shared assignable location. The problem has been examined before in context of ML in <ref> [24] </ref> and semantically analysed recently by Tofte in [57]. Our proposal, developed independently, is a slight extension of the latter. <p> There are two ways out of this problem. We can restrict the polymorphism of arguments and results of functions in certain ways so that we are still able to decidably infer their type using known algorithms. The most popular approach, taken by many modern languages such as ML <ref> [24, 25, 41, 42] </ref>, Miranda [60, 61], Hope [14], Haskell [27] and Id, is to use a special polymorphic type inference system now commonly referred to as the Hindley/Milner type system [20, 26, 40].
Reference: [25] <author> Robert Harper, Robin Milner, and Mads Tofte. </author> <title> The Definition of Standard ML Version 2. </title> <type> Technical Report ECS-LFCS-88-62, </type> <institution> Laboratory for Foundations of Computer Science, Department of Computer Science, University of Edinburgh, </institution> <month> August </month> <year> 1988. </year> <note> (also published as CSR-274-88). </note>
Reference-contexts: 2 Permitting the use of the same program code under multiple type contexts. 3 Inferring the type of every fragment of a program at compile time with very little or no help from the programmer. 13 Some recent efforts in the context of strongly typed functional languages such as ML <ref> [24, 25, 41, 42] </ref> and Miranda 4 [60, 61] have tried to come up with a workable solution for the interactive user, but their approach is not entirely satisfactory. <p> There are two ways out of this problem. We can restrict the polymorphism of arguments and results of functions in certain ways so that we are still able to decidably infer their type using known algorithms. The most popular approach, taken by many modern languages such as ML <ref> [24, 25, 41, 42] </ref>, Miranda [60, 61], Hope [14], Haskell [27] and Id, is to use a special polymorphic type inference system now commonly referred to as the Hindley/Milner type system [20, 26, 40]. <p> Other structured programming languages like ML or CLU provide independent language constructs for logical partitioning of large programs into modules <ref> [37, 25] </ref> or clusters [36] respectively. But such partitioning is not geared towards fast, interactive and incremental program development.
Reference: [26] <author> R. Hindley. </author> <title> The Principle Type Scheme of an Object in Combinatory Logic. </title> <journal> Transactions of the American Mathematical Society, </journal> <volume> 146 </volume> <pages> 29-60, </pages> <month> December </month> <year> 1969. </year> <month> 172 </month>
Reference-contexts: It has a large purely functional subset with a few non-functional and non-deterministic extensions catering to areas where functional languages are either inadequate or are inefficient. It is strongly typed and employs the Hindley/Milner polymorphic type system <ref> [26, 40] </ref> to perform type inferencing. It supports higher-order functions, algebraic types, abstract data types, and overloading of identifiers, and in some of these respects it is similar to one or more of its contemporaries in the realm of functional langauges, namely, ML, Hope [14], Miranda, Haskell [27] etc. <p> The most popular approach, taken by many modern languages such as ML [24, 25, 41, 42], Miranda [60, 61], Hope [14], Haskell [27] and Id, is to use a special polymorphic type inference system now commonly referred to as the Hindley/Milner type system <ref> [20, 26, 40] </ref>. Other, more recent efforts to strengthen this inference system have met with only partial success [30, 32, 43]. The other way out is to help the type inference system by giving explicit type declarations in the program while still retaining polymorphic functions as first class objects. <p> Finally, we discuss an algorithm which uses these rules to derive a type for every expression in the given program and show its semantic properties. The basic inferencing mechanism was first devised by Hindley <ref> [26] </ref>, which was later independently rediscovered and extended by Milner [40] to allow polymorphic functions. The theoretical basis was firmly established in Denotational Semantics by Damas [20, 19] and in Operational Semantics by Tofte [57].
Reference: [27] <editor> P. Hudak and P. Wadler (editors). </editor> <title> Report on the programming language Haskell, a non--strict purely functional language (Version 1.0). </title> <type> Technical Report YALEU/DCS/RR777, </type> <institution> Yale University, Department of Computer Science, </institution> <month> April </month> <year> 1990. </year>
Reference-contexts: It supports higher-order functions, algebraic types, abstract data types, and overloading of identifiers, and in some of these respects it is similar to one or more of its contemporaries in the realm of functional langauges, namely, ML, Hope [14], Miranda, Haskell <ref> [27] </ref> etc. But the programming environment for Id is different from that of these other languages in the following important ways. 1. The Id compiler [59] is incremental in nature. <p> This is the major result of this thesis and to the author's knowledge, this is the first time such a proof has appeared in the literature. In chapter 4, we discuss the issues involved in overloading of identifiers. The original proposal as adopted in the language Haskell <ref> [27] </ref> defines type classes and translates overloading into parameterized function calls. Our system 5 is a slight simplification of that proposal. Every operator has its own class which makes it easier to allow either parameterization or specialization on demand in order to make the program more efficient. <p> The most popular approach, taken by many modern languages such as ML [24, 25, 41, 42], Miranda [60, 61], Hope [14], Haskell <ref> [27] </ref> and Id, is to use a special polymorphic type inference system now commonly referred to as the Hindley/Milner type system [20, 26, 40]. Other, more recent efforts to strengthen this inference system have met with only partial success [30, 32, 43]. <p> Only recently has there been some attempt to systematize the mechanism involved in this name sharing and to extend it to allow explicit user-defined overloading of identifiers in context of strongly typed, functional languages <ref> [27, 63] </ref>. In Id, we take a position close to that proposed by Wadler and Blott in [63]. In this chapter, we describe our proposal for explicit, user-defined overloading of identifiers and a systematic mechanism for the compiler to resolve and then translate such programs into appropriate code. <p> in the current version of Id [48] as a preliminary solution until the more general schemes described earlier are implemented. 4.4 Comparison with the Proposal of Wadler and Blott Our overloading scheme is based on the proposal by Wadler and Blott described in [63] and used in the language Haskell <ref> [27] </ref>. In this section we will compare the mechanisms for overloading resolution and translation in the two systems, their expressive power, and the different objectives they achieve. Both systems have the notion of a predicated type, which is the standard Hindley/Milner Type augmented with a set of overloading predicate clauses. <p> The interpretation of the instance 15 These examples are in Haskell. The syntax is mostly self explanatory. Early alphabets like a, b, etc. denote type variables, data is an algebraic type declaration, and function definitions appear as equations. For details, the reader is referred to <ref> [63, 27] </ref>. 150 declaration is to define a dictionary object numDInt that carries the method implementing definitions for that instance.
Reference: [28] <author> G. Huet. </author> <title> Resolution d'equations dans les langages d'ordre 1,2,...,!. </title> <type> PhD thesis, </type> <institution> Universite de Paris VII, </institution> <year> 1976. </year>
Reference-contexts: There are many algorithms for unification in the literature (see [35] for a survey), with computational complexity varying from linear to exponential in the size of the expressions being unified. Our implementation 102 leans more towards pragmatic simplicity than asymptotic efficiency, and is a variation of Huet's algorithm <ref> [28] </ref> based on the almost linear Union-Find algorithm [1]. Again, the choice of an implementation is independent of our incremental book-keeping mechanism so we will not discuss this aspect any further. 3.
Reference: [29] <author> Paris C. Kanellakis and John C. Mitchell. </author> <title> Polymorphic Unification and ML Typing. </title> <booktitle> In Proceedings of the 16th ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 105-115, </pages> <month> January </month> <year> 1989. </year>
Reference-contexts: There are very recent results in the literature to show that the Hindley/Milner type inference system is DEXPTIME-complete [31, 38]. This gives a tight bound over the previous lower bound result of PSPACE-hard by Mitchell <ref> [29] </ref>. These results are contrary to the common folklore that this system is fairly efficient in practice, and came as a surprise to the programming language community. <p> We identify four distinct levels of computational complexity. 1. We mentioned in section 2.5 that the Milner's type inference algorithm has an intrinsic exponential complexity. This is not only because of the potentially exponential size of the final type of a given program (see examples in <ref> [29] </ref>) but also due to the intrinsic complexity of simply determining whether the program is type correct or not. This complexity is completely independent of whether we compute the type incrementally or not, so we will disregard this aspect in further discussion. 2.
Reference: [30] <author> A.J. Kfoury and J. Tiuryn. </author> <title> Type Reconstruction in Finite Rank Fragments of the Second-Order -Calculus. </title> <type> Technical Report 89-011, </type> <institution> Boston University, </institution> <month> October </month> <year> 1989. </year>
Reference-contexts: The question of decidability of type inference in this model is still open. Some recent work in this field attempts to identify subsets of the full polymorphic model where this question can still be answered <ref> [30] </ref>. There are two ways out of this problem. We can restrict the polymorphism of arguments and results of functions in certain ways so that we are still able to decidably infer their type using known algorithms. <p> Other, more recent efforts to strengthen this inference system have met with only partial success <ref> [30, 32, 43] </ref>. The other way out is to help the type inference system by giving explicit type declarations in the program while still retaining polymorphic functions as first class objects. It is a non-trivial problem to figure out just where such type declarations need to be inserted. <p> Historically, though, only recently has there been an attempt to understand the various levels of type inference possible in that model, so as to keep it decidable <ref> [30] </ref>. It is possible to fit this system in that model by restricting the polymorphism of its typed terms to outermost quantification only. <p> But recently, there have been further advancements that strengthen this system non-trivially by permitting a limited amount of polymorphism even for -bound variables <ref> [30] </ref>. It may be worthwhile to examine and evaluate the benefits of upgrading the type system to this level. On another dimension, we would like to suggest extensions to the already rich repertoire of types and data-structures in Id.
Reference: [31] <author> A.J. Kfoury, J. Tiuryn, and P. Urzyczyn. </author> <title> An Analysis of ML Typability. </title> <type> Technical Report 89-009, </type> <institution> Boston University, </institution> <month> October </month> <year> 1989. </year>
Reference-contexts: The down side of this succinct representation of polymorphic programs is that the worst-case running complexity of this type inferencing mechanism is provably exponential. There are very recent results in the literature to show that the Hindley/Milner type inference system is DEXPTIME-complete <ref> [31, 38] </ref>. This gives a tight bound over the previous lower bound result of PSPACE-hard by Mitchell [29]. These results are contrary to the common folklore that this system is fairly efficient in practice, and came as a surprise to the programming language community.
Reference: [32] <author> A.J. Kfoury, J. Tiuryn, and P. Urzyczyn. </author> <title> Type-checking in the presence of polymorphic recursion. </title> <type> Technical report, </type> <institution> Boston University, </institution> <year> 1989. </year>
Reference-contexts: Other, more recent efforts to strengthen this inference system have met with only partial success <ref> [30, 32, 43] </ref>. The other way out is to help the type inference system by giving explicit type declarations in the program while still retaining polymorphic functions as first class objects. It is a non-trivial problem to figure out just where such type declarations need to be inserted.
Reference: [33] <author> J.W. Klop. </author> <title> Term Rewriting Systems. </title> <type> Technical report, </type> <institution> Center for Mathematics and Computer Science, </institution> <address> Amsterdam, The Netherlands, </address> <month> September </month> <year> 1985. </year>
Reference-contexts: We describe this in terms of a rewrite rule operational semantics. This, combined with the high level overloading processing algorithm described above, forms the complete overloading resolution mechanism of the compiler. Readers unfamiliar with the notation of Term Rewriting Systems should refer to <ref> [33, 34] </ref> for an excellent treatment. Our term rewriting system consists of the type predicate terms as specified syntactically in figure 4.2 and rewrite rules over them.
Reference: [34] <author> J.W. Klop. </author> <title> Term Rewriting Systems: A Tutorial. </title> <type> Technical report, </type> <institution> Center for Mathematics and Computer Science, </institution> <address> Amsterdam, The Netherlands, </address> <year> 1987. </year> <note> Also published in the Bulletin of the European Association for Theoretical Computer Science, 32, </note> <year> 1987. </year>
Reference-contexts: We describe this in terms of a rewrite rule operational semantics. This, combined with the high level overloading processing algorithm described above, forms the complete overloading resolution mechanism of the compiler. Readers unfamiliar with the notation of Term Rewriting Systems should refer to <ref> [33, 34] </ref> for an excellent treatment. Our term rewriting system consists of the type predicate terms as specified syntactically in figure 4.2 and rewrite rules over them.
Reference: [35] <author> Kevin Knight. </author> <title> Unification: A Multidisciplinary Survey. </title> <journal> ACM Computing Surveys, </journal> <volume> 21(1), </volume> <month> March </month> <year> 1989. </year>
Reference-contexts: This complexity is completely independent of whether we compute the type incrementally or not, so we will disregard this aspect in further discussion. 2. The basic computation vehicle is the unification algorithm. There are many algorithms for unification in the literature (see <ref> [35] </ref> for a survey), with computational complexity varying from linear to exponential in the size of the expressions being unified. Our implementation 102 leans more towards pragmatic simplicity than asymptotic efficiency, and is a variation of Huet's algorithm [28] based on the almost linear Union-Find algorithm [1].
Reference: [36] <author> Barbara Liskov and John Guttag. </author> <title> Abstraction and Specification in Program Development. </title> <publisher> MIT Press, </publisher> <year> 1986. </year>
Reference-contexts: Other structured programming languages like ML or CLU provide independent language constructs for logical partitioning of large programs into modules [37, 25] or clusters <ref> [36] </ref> respectively. But such partitioning is not geared towards fast, interactive and incremental program development.
Reference: [37] <author> David MacQueen. </author> <title> Modules for Standard ML. </title> <booktitle> In Proceedings of the ACM Symposium on LISP and Functional Programming, </booktitle> <pages> pages 198-207, </pages> <month> August </month> <year> 1984. </year>
Reference-contexts: Other structured programming languages like ML or CLU provide independent language constructs for logical partitioning of large programs into modules <ref> [37, 25] </ref> or clusters [36] respectively. But such partitioning is not geared towards fast, interactive and incremental program development. <p> On another dimension, we would like to suggest extensions to the already rich repertoire of types and data-structures in Id. One possible direction for extension is to introduce modules, functors, and structures in Id like those in ML <ref> [37] </ref>. Id already has abstract data types and an associated notion of information hiding, but structures and parameterized modules (functors) are more powerful features geared towards programming in the large and disciplined code sharing.
Reference: [38] <author> Harry G. Mairson. </author> <title> Deciding ML Typability is Complete for Deterministic Exponential Time. </title> <booktitle> In Proceedings of the 17th ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 382-401, </pages> <month> January </month> <year> 1990. </year>
Reference-contexts: The down side of this succinct representation of polymorphic programs is that the worst-case running complexity of this type inferencing mechanism is provably exponential. There are very recent results in the literature to show that the Hindley/Milner type inference system is DEXPTIME-complete <ref> [31, 38] </ref>. This gives a tight bound over the previous lower bound result of PSPACE-hard by Mitchell [29]. These results are contrary to the common folklore that this system is fairly efficient in practice, and came as a surprise to the programming language community.
Reference: [39] <author> Lambert Meertens. </author> <title> Incremental Polymorphic Type Checking in B. </title> <booktitle> In Proceedings of the 10th ACM Symposium on Principles of Programming Languages, </booktitle> <month> January </month> <year> 1983. </year>
Reference-contexts: In this way, our system can tolerate temporary type inconsistencies among definitions and reduce the number of recompilations by intelligent scheduling 29 , while still guaranteeing the correctness of inferred types before run-time. There are few other programming environments in the literature that have attempted to incorporate incrementality. In <ref> [39] </ref>, Meertens describes an incremental polymorphic type inference scheme for the language B. Even though the language specific issues are quite different, his system incrementally maintains fine-grain type constraints like those in the GLIDE system.
Reference: [40] <author> Robin Milner. </author> <title> A Theory of Type Polymorphism in Programming. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 17 </volume> <pages> 348-375, </pages> <year> 1978. </year>
Reference-contexts: It has a large purely functional subset with a few non-functional and non-deterministic extensions catering to areas where functional languages are either inadequate or are inefficient. It is strongly typed and employs the Hindley/Milner polymorphic type system <ref> [26, 40] </ref> to perform type inferencing. It supports higher-order functions, algebraic types, abstract data types, and overloading of identifiers, and in some of these respects it is similar to one or more of its contemporaries in the realm of functional langauges, namely, ML, Hope [14], Miranda, Haskell [27] etc. <p> The most popular approach, taken by many modern languages such as ML [24, 25, 41, 42], Miranda [60, 61], Hope [14], Haskell [27] and Id, is to use a special polymorphic type inference system now commonly referred to as the Hindley/Milner type system <ref> [20, 26, 40] </ref>. Other, more recent efforts to strengthen this inference system have met with only partial success [30, 32, 43]. The other way out is to help the type inference system by giving explicit type declarations in the program while still retaining polymorphic functions as first class objects. <p> Finally, we discuss an algorithm which uses these rules to derive a type for every expression in the given program and show its semantic properties. The basic inferencing mechanism was first devised by Hindley [26], which was later independently rediscovered and extended by Milner <ref> [40] </ref> to allow polymorphic functions. The theoretical basis was firmly established in Denotational Semantics by Damas [20, 19] and in Operational Semantics by Tofte [57]. <p> The model that we present here is that of untyped Lambda Calculus. This is the position taken in the original paper by Milner <ref> [40] </ref>. For the most part, the dynamic semantics is fairly intuitive; constants represent themselves as elements of a Scott Domain [55, 56] and lambda abstractions create domains containing continuous functions over these domains. <p> Further, the values they denote or evaluate to, have the corresponding inferred types. This is a fundamental property necessary for any inference mechanism to 36 establish its validity with respect to the associated operational or denotational computation model. In his original paper <ref> [40] </ref>, Milner showed the semantic soundness of well-typed expressions. In the framework of Damas-Milner system DM as described in [20, 19], Damas proved the soundness of his system using Denotational Semantics. Due to theorem 2.1, that system and the system presented here are equivalent.
Reference: [41] <author> Robin Milner. </author> <title> A Proposal for Standard ML. </title> <booktitle> In Proceedings of the ACM Symposium on Lisp and Functional Programming, </booktitle> <pages> pages 184-197, </pages> <month> August </month> <year> 1984. </year>
Reference-contexts: 2 Permitting the use of the same program code under multiple type contexts. 3 Inferring the type of every fragment of a program at compile time with very little or no help from the programmer. 13 Some recent efforts in the context of strongly typed functional languages such as ML <ref> [24, 25, 41, 42] </ref> and Miranda 4 [60, 61] have tried to come up with a workable solution for the interactive user, but their approach is not entirely satisfactory. <p> There are two ways out of this problem. We can restrict the polymorphism of arguments and results of functions in certain ways so that we are still able to decidably infer their type using known algorithms. The most popular approach, taken by many modern languages such as ML <ref> [24, 25, 41, 42] </ref>, Miranda [60, 61], Hope [14], Haskell [27] and Id, is to use a special polymorphic type inference system now commonly referred to as the Hindley/Milner type system [20, 26, 40].
Reference: [42] <author> Robin Milner. </author> <title> The Standard ML Core Language. Polymorphism, </title> <address> II(2), </address> <month> October </month> <year> 1985. </year>
Reference-contexts: 2 Permitting the use of the same program code under multiple type contexts. 3 Inferring the type of every fragment of a program at compile time with very little or no help from the programmer. 13 Some recent efforts in the context of strongly typed functional languages such as ML <ref> [24, 25, 41, 42] </ref> and Miranda 4 [60, 61] have tried to come up with a workable solution for the interactive user, but their approach is not entirely satisfactory. <p> There are two ways out of this problem. We can restrict the polymorphism of arguments and results of functions in certain ways so that we are still able to decidably infer their type using known algorithms. The most popular approach, taken by many modern languages such as ML <ref> [24, 25, 41, 42] </ref>, Miranda [60, 61], Hope [14], Haskell [27] and Id, is to use a special polymorphic type inference system now commonly referred to as the Hindley/Milner type system [20, 26, 40].
Reference: [43] <author> A. Mycroft. </author> <title> Polymorphic Type Schemes and Recursive Definitions. </title> <booktitle> In International Symposium on Programming, volume 167 of Lecture Notes in Computer Science, </booktitle> <pages> pages 217-228. </pages> <publisher> Springer-Verlag, </publisher> <year> 1984. </year> <month> 173 </month>
Reference-contexts: Other, more recent efforts to strengthen this inference system have met with only partial success <ref> [30, 32, 43] </ref>. The other way out is to help the type inference system by giving explicit type declarations in the program while still retaining polymorphic functions as first class objects. It is a non-trivial problem to figure out just where such type declarations need to be inserted.
Reference: [44] <author> Rishiyur S. Nikhil. </author> <title> Practical Polymorphism. </title> <booktitle> In Proceedings of the Conference on Func--tional Programming Languages and Computer Architectures, Nancy, FRANCE, volume 201 of Lecture notes in Computer Science. </booktitle> <publisher> Springer-Verlag, </publisher> <month> September </month> <year> 1985. </year>
Reference-contexts: It is our intention in this thesis to incorporate LISP-like programming incrementality within the framework of Hindley/Milner static type inference mechanism. Nikhil <ref> [44] </ref> raised this problem in the context of ML programming environment and outlined a scheme for incremental polymorphic type inference that we have concretized and implemented here for the programming environment of Id. <p> This is useful, for example, in developing large systems where the user may want to exercise localized parts of the system using appropriate test data without bothering about the whole system. See <ref> [44] </ref> for description of such a strategy. <p> completeness of incremental property inference is closely tied to the peculiarities of the property domain, the actual strategy used in computing and verifying the property, and the inter-relationship among the various properties being collected. 111 3.9.4 Related Work Our work has grown out of the ideas presented by Nikhil in <ref> [44] </ref>. Subsequently, Toyn et al.[58] used some of those ideas in their GLIDE system. Even though their incremental type inference system is based on the same principles as ours, it is very different in detail. The GLIDE system maintains much more fine-grain type information than our definition based book-keeping.
Reference: [45] <author> Rishiyur S. Nikhil. </author> <title> Id Nouveau Reference Manual, Part I: Syntax. </title> <type> Technical report, </type> <institution> Computation Structures Group, MIT Laboratory for Computer Science, 545 Technology Square, </institution> <address> Cambridge, MA 02139, </address> <month> April </month> <year> 1987. </year>
Reference-contexts: We will discuss how it fits with our mini-language described above and show how to perform basic type inferencing for programs written in it. Id is an evolving language <ref> [45, 46, 48] </ref>.
Reference: [46] <author> Rishiyur S. Nikhil. </author> <title> Id (Version 88.1) Reference Manual. </title> <type> Technical Report CSG Memo 284, </type> <institution> MIT Laboratory for Computer Science, 545 Technology Square, </institution> <address> Cambridge, MA 02139, </address> <month> August </month> <year> 1988. </year>
Reference-contexts: As an aside, we will not attempt to give a complete description of Id language syntax and semantics, though we do present the abstract syntax of the Id Kernel language at the end of this chapter. For a concrete treatment of the Id syntax, the reader is referred to <ref> [46, 48] </ref>. A preliminary discussion of Id dynamic semantics is found in [8], while a more recent and revised version appears in [4]. We will present examples from Id, explaining their semantics informally. <p> We will discuss how it fits with our mini-language described above and show how to perform basic type inferencing for programs written in it. Id is an evolving language <ref> [45, 46, 48] </ref>. <p> We intend to implement it using a slight variation of our make i array function above. def make array bounds f = f (l,u) = bounds in farray bounds 9 List Comprehensions are similar to array comprehensions in structure and mechanism but generate lists instead. See <ref> [46, 48] </ref> for details. 164 | [i] = f i || i &lt;- l to u gg; is implemented as def make array bounds f = f (l,u) = bounds; in f a = i array bounds; ffor i &lt;- l to u do a [i] = f i g; (read
Reference: [47] <author> Rishiyur S. Nikhil. </author> <title> Overloading. For internal circulation in the Computation Structures Group, </title> <institution> MIT Laboratory for Computer Science, </institution> <address> Cambridge, MA 02139, </address> <month> May </month> <year> 1988. </year>
Reference-contexts: Finally, in chapter 6, we present a summary of the results and conclude with future directions for research. 5 A preliminary version of the system described in this thesis was presented by Nikhil in <ref> [47] </ref> for internal circulation. 16 Chapter 2 Basic Type Inferencing The classical notion of Type is that of a set containing semantically similar values. <p> In this chapter, we describe our proposal for explicit, user-defined overloading of identifiers and a systematic mechanism for the compiler to resolve and then translate such programs into appropriate code. A preliminary version of this proposal was described by Nikhil in <ref> [47] </ref> for internal circulation. 115 This chapeter is organized as follows. In section 4.1, we discuss the desirable features of an overloading scheme and its relationship to parametric polymorphism.
Reference: [48] <author> Rishiyur S. Nikhil. </author> <title> Id Version 90.0 Reference Manual. </title> <type> Technical Report CSG Memo 284-1, </type> <institution> MIT Laboratory for Computer Science, 545 Technology Square, </institution> <address> Cambridge, MA 02139, </address> <month> July </month> <year> 1990. </year>
Reference-contexts: Id is a high-level language proposed by the Computation Structures Group at the Laboratory for Computer Science, MIT, for fine-grain dataflow parallel computation <ref> [48, 49] </ref>. It has a large purely functional subset with a few non-functional and non-deterministic extensions catering to areas where functional languages are either inadequate or are inefficient. It is strongly typed and employs the Hindley/Milner polymorphic type system [26, 40] to perform type inferencing. <p> As an aside, we will not attempt to give a complete description of Id language syntax and semantics, though we do present the abstract syntax of the Id Kernel language at the end of this chapter. For a concrete treatment of the Id syntax, the reader is referred to <ref> [46, 48] </ref>. A preliminary discussion of Id dynamic semantics is found in [8], while a more recent and revised version appears in [4]. We will present examples from Id, explaining their semantics informally. <p> We will discuss how it fits with our mini-language described above and show how to perform basic type inferencing for programs written in it. Id is an evolving language <ref> [45, 46, 48] </ref>. <p> The value and the subscript expression are evaluated at each of the values generated by a generator, which could be a nested combination of list producing expressions filterable through predicates. See <ref> [48] </ref> for details. 119 | [i] = X [i]+Y [i] || i &lt;- l to ugg; overload (+) :: (Vector *0) -&gt; (Vector *0) -&gt; (Vector *0) = vadd; The challange here is to allow vadd as a resolution instance of "+". <p> A detailed description of this strategy is beyond the scope of this thesis, but we should mention that due to its efficiency, this scheme is used in the current version of Id <ref> [48] </ref> as a preliminary solution until the more general schemes described earlier are implemented. 4.4 Comparison with the Proposal of Wadler and Blott Our overloading scheme is based on the proposal by Wadler and Blott described in [63] and used in the language Haskell [27]. <p> Finally, we will present the approach taken in Id, which is a refinement of these earlier works. 153 5.1 Non-Functional Constructs in Id Id has two classes of non-functional objects, I-Structures and mutex objects <ref> [9, 48] </ref>. We will not concern ourselves with the run-time dynamic semantics of these objects except for the fact that they behave like storage locations, in that they can be allocated without specifying their contents, be assigned to, or be queried for their contents 1 . <p> The idea here is to be able to grow a list at its end rather than at its front. There is no functional way to do this. Using open lists, we can efficiently copy the 5 Refer <ref> [6, 48] </ref> for details and more examples of this technique. 155 first list as we traverse it down in a loop and stick the second list at its end in order to close it and make it into a valid functional list 6 . <p> its implementation, and to our knowledge, an in-depth theoretical analysis has not been carried out yet. 5.3 Our Approach in Id 5.3.1 Typing Open Structures Id, with non-functional arrays and open lists (and indeed other open constructs such as algebraic types and tuples as proposed in its latest extension in <ref> [48] </ref>) has exactly the same flavor of typing complexity as ML's ref construct. The currently implemented mechanism in the Id Compiler was developed independently by the author under the guidance of Prof. R.S. Nikhil and was later found to be similar to Damas' system described in the last section. <p> We intend to implement it using a slight variation of our make i array function above. def make array bounds f = f (l,u) = bounds in farray bounds 9 List Comprehensions are similar to array comprehensions in structure and mechanism but generate lists instead. See <ref> [46, 48] </ref> for details. 164 | [i] = f i || i &lt;- l to u gg; is implemented as def make array bounds f = f (l,u) = bounds; in f a = i array bounds; ffor i &lt;- l to u do a [i] = f i g; (read
Reference: [49] <author> Rishiyur S. Nikhil and Arvind. </author> <title> Programming in Id: A Parallel Programming Language. </title> <note> Book in preparation, </note> <year> 1990. </year>
Reference-contexts: Id is a high-level language proposed by the Computation Structures Group at the Laboratory for Computer Science, MIT, for fine-grain dataflow parallel computation <ref> [48, 49] </ref>. It has a large purely functional subset with a few non-functional and non-deterministic extensions catering to areas where functional languages are either inadequate or are inefficient. It is strongly typed and employs the Hindley/Milner polymorphic type system [26, 40] to perform type inferencing.
Reference: [50] <author> Rishiyur S. Nikhil, P. R. Fenstermacher, J. E. Hicks, and R. P. Johnson. </author> <title> Id World Reference Manual. Computation Structures Group, </title> <institution> MIT Laboratory for Computer Science, 545 Technology Square, </institution> <address> Cambridge, MA 02139, </address> <note> revised edition, </note> <month> November </month> <year> 1989. </year>
Reference-contexts: In either case, the top-level definitions do not have to be processed in any particular order. The user may edit and compile definitions interactively in arbitrary order. 3. The compiler is smoothly integrated with the editor and an emulator for the Tagged-token Dataflow Architecture [5, 7] into "Id-World" <ref> [50] </ref>, a friendly, interactive, parallel programming environment. Each top-level compilation unit may be compiled, loaded, and linked with other similar units and then executed via commands given to the interactive 4 "Miranda" is a trademark of Research Software Ltd. 14 emulator. 4. <p> the user as well as validating efficient non-functional implementations of functional data-structures. 6.3 Concluding Remarks Finally, we would like to point out that our work on incremental type inferencing has grown out of a need for a rich type system for interactive program development environments such as that for Id <ref> [50] </ref>. A rich type system is a valuable tool in developing large, robust, and reliable software. But in association with interactive environments, it requires careful engineering, so as not to inhibit their interactive and incremental nature.
Reference: [51] <author> J. Ophel. AIMLESS: </author> <title> A Programming Environment for ML. </title> <type> Technical Report TR-CS-88-20, </type> <institution> Australian National University, </institution> <year> 1988. </year>
Reference-contexts: ML, in most of its implementations <ref> [2, 3, 51, 24, 10] </ref>, has an interactive session to which definitions can be incrementally added, but it still requires a complete program to be specified bottom-up before any of its parts can be tested. <p> Even though the language specific issues are quite different, his system incrementally maintains fine-grain type constraints like those in the GLIDE system. The AIMLESS system developed at the Australian National University as part of the programming environment of ANU ML <ref> [51] </ref> takes a completely different approach.
Reference: [52] <author> G. D. Plotkin. </author> <title> A Structural Approach to Operational Semantics. </title> <type> Technical Report DAIMI FN-19, </type> <institution> Computer Science Department, Aarhus University, Aarhus, Denmark, </institution> <month> September </month> <year> 1981. </year>
Reference-contexts: This is an important point that makes this system sound. 2.3.3 Operational Semantics of the Mini-Language Now we are ready to present the operational semantics of the mini-language. Both dynamic and static semantics are presented as a set of inference rules <ref> [52] </ref> operating on the expressions of the mini-language. The static semantic rules constitute the basic Hindley/Milner type inference rules, from which valid assertions about the type of the expressions can be inferred. Dynamic Semantics Dynamic operational semantics tells us how to evaluate the expressions of the language.
Reference: [53] <author> J. C. Reynolds. </author> <title> Towards a Theory of Type Structure. </title> <booktitle> In Paris Colloquium on Programming, volume 19 of Lecture Notes in Computer Science, </booktitle> <pages> pages 408-425. </pages> <publisher> Springer-Verlag, </publisher> <year> 1974. </year>
Reference-contexts: The lists to the right of the arrow (=)) are the results of the computation shown at the left. While polymorphic, higher-order functions are useful and compact, they pose some theoretical problems for type inferencing. Such functions, in their full generality, are usually modelled using second-order typed Lambda Calculus <ref> [13, 23, 53] </ref>. The question of decidability of type inference in this model is still open. Some recent work in this field attempts to identify subsets of the full polymorphic model where this question can still be answered [30]. There are two ways out of this problem. <p> In fact, the second-order typed Lambda Calculus provides a much cleaner and easier to understand framework for a more general and richer class of functions <ref> [13, 23, 53] </ref>. Historically, though, only recently has there been an attempt to understand the various levels of type inference possible in that model, so as to keep it decidable [30]. <p> So there is no active or dynamic polymorphism in this system in the sense of Girard-Reynolds second-order polymorphic Lambda Calculus <ref> [13, 23, 53] </ref> and indeed the class of programs accepted by this system is exactly the same as that of simply typed first-order Lambda Calculus. But this system offers it in a package that gives the appearance of (static) polymorphism.
Reference: [54] <author> J. A. Robinson. </author> <title> A Machine-Oriented Logic Based on the Resolution Principle. </title> <journal> Journal of the ACM, </journal> <volume> 12(1) </volume> <pages> 23-41, </pages> <year> 1965. </year>
Reference-contexts: This is precisely the information explicitly declared in the PASCAL program. The inference mechanism is governed by the unification algorithm of Robinson <ref> [54] </ref>. The known type of an identifier or an operator is unified with the type expected in the context where it is used. <p> Our inference algorithm uses the Unification algorithm of Robinson <ref> [54] </ref> which we state below as a theorem. Theorem 2.6 (Robinson) There is an algorithm U which, given a pair of types, either returns a substitution S or fails. Further, 1.
Reference: [55] <author> D. Scott. </author> <title> Data types as lattices. </title> <journal> Siam Journal of Computing, </journal> <volume> 5(3) </volume> <pages> 522-587, </pages> <year> 1976. </year>
Reference-contexts: The model that we present here is that of untyped Lambda Calculus. This is the position taken in the original paper by Milner [40]. For the most part, the dynamic semantics is fairly intuitive; constants represent themselves as elements of a Scott Domain <ref> [55, 56] </ref> and lambda abstractions create domains containing continuous functions over these domains. The syntactic categories we intro duced in section 2.3.3 can thus be easily understood in terms of these domains. Environments would then become partial functions from identifiers to elements of these domains.
Reference: [56] <author> J. E. Stoy. </author> <title> Denotational Semantics. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1977. </year>
Reference-contexts: The model that we present here is that of untyped Lambda Calculus. This is the position taken in the original paper by Milner [40]. For the most part, the dynamic semantics is fairly intuitive; constants represent themselves as elements of a Scott Domain <ref> [55, 56] </ref> and lambda abstractions create domains containing continuous functions over these domains. The syntactic categories we intro duced in section 2.3.3 can thus be easily understood in terms of these domains. Environments would then become partial functions from identifiers to elements of these domains. <p> The literature is filled with the discussion of semantics of Lambda Calculus, both operational and denotational. A complete theoretical treatment can be found in [12]. A very good discussion on Scott domains and denotational semantics can be found in <ref> [56] </ref>. The semantics of the type expressions is also fairly simple.
Reference: [57] <author> Mads Tofte. </author> <title> Operational Semantics and Polymorphic Type Inference. </title> <type> PhD thesis, </type> <institution> University of Edinburgh, Department of Computer Science, </institution> <year> 1988. </year> <note> Also published as ECS-LFCS-88-54. </note>
Reference-contexts: The type system must also provide support for sound type inference of polymorphic, non-functional, referential data-structures (a la Tofte <ref> [57] </ref>). 1.1 Thesis Outline The outline of this thesis is as follows. In chapter 2 we carefully examine the problem of polymorphic type inference for a functional language in the light of the Hindley/Milner type system [16, 20] and establish facts and notation used in the rest of the thesis. <p> Specifically, the problem is to correctly type-check a polymorphic reference to a shared assignable location. The problem has been examined before in context of ML in [24] and semantically analysed recently by Tofte in <ref> [57] </ref>. Our proposal, developed independently, is a slight extension of the latter. We not only type-check polymorphic references, but also allow the programmer to delineate functional and non-functional boundaries in the program, so that the compiler is able to perform functional optimizations in most parts of the program. <p> The basic inferencing mechanism was first devised by Hindley [26], which was later independently rediscovered and extended by Milner [40] to allow polymorphic functions. The theoretical basis was firmly established in Denotational Semantics by Damas [20, 19] and in Operational Semantics by Tofte <ref> [57] </ref>. Since then, several expositions have appeared in the literature, either in context of the languages that use this system or those that extend the richness or power of the system in some way (typing polymorphic references, type-containment, type-coercion etc.). Our notation is the same as used by Tofte in [57] <p> <ref> [57] </ref>. Since then, several expositions have appeared in the literature, either in context of the languages that use this system or those that extend the richness or power of the system in some way (typing polymorphic references, type-containment, type-coercion etc.). Our notation is the same as used by Tofte in [57] and the description is primarily derived from the work of Damas [20], Tofte [57], and Clement et al.[18]. 25 2.3.1 A Mini-Language Expressions We start with a set of basic constants and identifiers in the language as shown below. <p> Our notation is the same as used by Tofte in <ref> [57] </ref> and the description is primarily derived from the work of Damas [20], Tofte [57], and Clement et al.[18]. 25 2.3.1 A Mini-Language Expressions We start with a set of basic constants and identifiers in the language as shown below. <p> Finally, we note the following lemmas which are proved in <ref> [57] </ref> for the DM 0 system. Their corresponding versions for the DM system are proved in [20]. Lemma 2.2 If t 0 then for all substitutions S, S St 0 . <p> Due to theorem 2.1, that system and the system presented here are equivalent. Therefore, intuitively it should be clear that the soundness theorem extends to this system as well. Indeed, Tofte in <ref> [57] </ref> showed a similar consistency result for our system in an Operational Semantics setting. So, henceforth we shall assume that the semantic properties proved for one system naturally extend to the other and we may only state the results for one of them. <p> Basically, this says that all typings of an expression can be obtained as instantiations of the closed version of the type returned by W in the final type environment. The proof of these results appears in <ref> [57] </ref>. The corresponding results for the DM system are proved in [19]. This completes our discussion of the Hindley/Milner type inference system. 2.4 Id Kernel Language In this section, we present the kernel language for Id. <p> S 0 t 1 TE 0 + fx 7! close (TE 0 ; S 0 t 1 )g ` e 2 : St 2 TE 0 ` let x = e 1 in e 2 : St 2 18 For a proof of how these antecedents were arrived at, see <ref> [57] </ref>, pages 18-20. 75 where, TE 0 = S (TE ) = S 0 (TE) and S 0 = S # tyvars (TE) =) S (close (TE; t 1 )) = close (TE 0 ; S 0 t 1 ) We are given that the substitution S does not involve any <p> The problem of type-checking non-functional constructs has been studied in depth for the ML language by Tofte <ref> [57] </ref> and our discussion is based on that research. We will not go into the details of how to extend the Hindley/Milner type system to incorporate these constructs since that has been excellently dealt with in Tofte's thesis. <p> Otherwise, we may easily generate unsound typings and run into run-time type errors. The following example from Tofte's thesis <ref> [57] </ref> chapter 3, page 31, illustrates this problem. let r = ref (x.x) in (r := x.x+1; (!r) true) ref creates an assignable storage location that is initialized to the identity function, but is later overwritten with the successor function. <p> Again, we will have to make a conservative approximation of the actual run-time behaviour of the expression. Different authors have taken different positions in this matter. We will outline three schemes by means of examples and describe our position in the next section. Approximation I Tofte <ref> [57] </ref> makes a broad syntactic classification of expressions into two categories, applications and let-expressions termed as expansive, and identifiers and -abstractions termed as non-expansive. The idea is that only expansive expressions can ever lead to allocation of an object, which in turn implies an expansion of the store typing. <p> Damas' system makes finer distinctions among expressions in deciding which expressions allocate objects and when that allocation occurs, than Tofte's system which uses a simple 7 Our account of Damas' solution is based on its lucid exposition by Tofte in <ref> [57] </ref>, chapter 6. 160 syntactic classification to achieve that. So it should not surprise us if Damas' system admits programs that Tofte's system rejects.
Reference: [58] <author> Ian Toyn, Alan Dix, and Colin Runciman. </author> <title> Performance Polymorphism. </title> <booktitle> In Functional Programming Languages and Computer Architecture, volume 274 of Lecture Notes in Computer Science, </booktitle> <pages> pages 325-346. </pages> <publisher> Springer-Verlag, </publisher> <year> 1987. </year> <booktitle> Proceedings of the FPCA Conference held in Portland, </booktitle> <address> Oregon, </address> <year> 1987. </year> <month> 174 </month>
Reference: [59] <author> Kenneth R. Traub. </author> <title> A Compiler for the MIT Tagged-Token Dataflow Architecture. </title> <type> Tech--nical Report LCS TR-370, </type> <institution> MIT Laboratory for Computer Science, 545 Technology Square, </institution> <address> Cambridge, MA 02139, </address> <month> August </month> <year> 1986. </year>
Reference-contexts: But the programming environment for Id is different from that of these other languages in the following important ways. 1. The Id compiler <ref> [59] </ref> is incremental in nature. Each top-level phrase, which may be a constant binding, a function, a type definition, or a type annotation, is treated as a single individual compilation unit. 2. The compiler accepts input interactively from an editor or in batch-mode from a file. <p> The predicate 6 This is adapted from the ML interactive runtime environment where the last expression evaluated is referred to as "it". 7 A variation of the mechanism described here was first implemented (without formal characterization) as part of the Id Compiler by Traub <ref> [59] </ref>. 55 (a): A Property Domain D. CHECK: C : D fi D ! fpass; failg (b): Assumptions and Assumption Checks. 56 actually defines the structure of the domain according to whatever notion of consistency we want to impart to the desired property. <p> The incremental book-keeping mechanism we described in section 3.1.2 is general enough to capture almost all interesting incremental compilation properties. Indeed, this system, first implemented by Traub <ref> [59] </ref>, forms the backbone of all the incremental book-keeping done inside the Id Compiler developed at the Laboratory for Computer Science, MIT. But this system only specifies a basic mechanism for incremental property maintenance. It does not guarantee correctness for an arbitrary property.
Reference: [60] <author> David A. Turner. Miranda: </author> <title> A non-strict functional language with polymorphic types. </title> <booktitle> In Proceedings of the Conference on Functional Programming Languages and Computer Architectures, Nancy, FRANCE, volume 201 of Lecture Notes in Computer Science. </booktitle> <publisher> Springer-Verlag, </publisher> <month> September </month> <year> 1985. </year>
Reference-contexts: program code under multiple type contexts. 3 Inferring the type of every fragment of a program at compile time with very little or no help from the programmer. 13 Some recent efforts in the context of strongly typed functional languages such as ML [24, 25, 41, 42] and Miranda 4 <ref> [60, 61] </ref> have tried to come up with a workable solution for the interactive user, but their approach is not entirely satisfactory. <p> We can restrict the polymorphism of arguments and results of functions in certain ways so that we are still able to decidably infer their type using known algorithms. The most popular approach, taken by many modern languages such as ML [24, 25, 41, 42], Miranda <ref> [60, 61] </ref>, Hope [14], Haskell [27] and Id, is to use a special polymorphic type inference system now commonly referred to as the Hindley/Milner type system [20, 26, 40]. Other, more recent efforts to strengthen this inference system have met with only partial success [30, 32, 43]. <p> Thus, even a simple operation such as reading a file and writing it back may cause a violation of its dependencies and trigger a recompilation of the entire application. Some programming environments such as that for Miranda 2 <ref> [60, 61] </ref> ensure that each physical file partition (called a Miranda-script ) also represents an independent logical partition of the 1 "UNIX" is a trademark of Bell Laboratories. 2 "Miranda" is the trademark of Research Software Ltd. 51 complete system by requiring the user to explicitly declare its logical interface: the
Reference: [61] <author> David A. Turner. </author> <title> An Overview of Miranda. </title> <journal> SIGPLAN Notices, </journal> <volume> 21(12) </volume> <pages> 158-166, </pages> <month> December </month> <year> 1986. </year>
Reference-contexts: program code under multiple type contexts. 3 Inferring the type of every fragment of a program at compile time with very little or no help from the programmer. 13 Some recent efforts in the context of strongly typed functional languages such as ML [24, 25, 41, 42] and Miranda 4 <ref> [60, 61] </ref> have tried to come up with a workable solution for the interactive user, but their approach is not entirely satisfactory. <p> We can restrict the polymorphism of arguments and results of functions in certain ways so that we are still able to decidably infer their type using known algorithms. The most popular approach, taken by many modern languages such as ML [24, 25, 41, 42], Miranda <ref> [60, 61] </ref>, Hope [14], Haskell [27] and Id, is to use a special polymorphic type inference system now commonly referred to as the Hindley/Milner type system [20, 26, 40]. Other, more recent efforts to strengthen this inference system have met with only partial success [30, 32, 43]. <p> Thus, even a simple operation such as reading a file and writing it back may cause a violation of its dependencies and trigger a recompilation of the entire application. Some programming environments such as that for Miranda 2 <ref> [60, 61] </ref> ensure that each physical file partition (called a Miranda-script ) also represents an independent logical partition of the 1 "UNIX" is a trademark of Bell Laboratories. 2 "Miranda" is the trademark of Research Software Ltd. 51 complete system by requiring the user to explicitly declare its logical interface: the
Reference: [62] <author> Kevin S. Van Horn. </author> <title> Functional Language Implementations Survey, </title> <month> March </month> <year> 1990. </year> <title> Message on the Functional Programming Mailing List. </title>
Reference-contexts: After the editing, they are moved back to the script, being recompiled in the process, and any discrepencies found are reported. It is possible to minimize the recompilation cost by saving some previous information. The POPLOG <ref> [62] </ref> system is an umbrella for a variety of languages, including ML, Pro-log, and LISP and it permits incremental compilation of functions.
Reference: [63] <author> Philip Wadler and Stephen Blott. </author> <title> How to make ad-hoc polymorphism less ad hoc. </title> <booktitle> In Proceedings of the 16th ACM Symposium on Principles of Programming Languages, </booktitle> <address> Austin, Texas, </address> <pages> pages 60-76, </pages> <month> January </month> <year> 1989. </year> <month> 175 </month>
Reference-contexts: The type system is required to provide support for resolving and compiling overloaded identifier definitions and blend it with its existing system of polymorphism (a la Wadler and Blott <ref> [63] </ref>). 4. The type system must also provide support for sound type inference of polymorphic, non-functional, referential data-structures (a la Tofte [57]). 1.1 Thesis Outline The outline of this thesis is as follows. <p> Only recently has there been some attempt to systematize the mechanism involved in this name sharing and to extend it to allow explicit user-defined overloading of identifiers in context of strongly typed, functional languages <ref> [27, 63] </ref>. In Id, we take a position close to that proposed by Wadler and Blott in [63]. In this chapter, we describe our proposal for explicit, user-defined overloading of identifiers and a systematic mechanism for the compiler to resolve and then translate such programs into appropriate code. <p> In Id, we take a position close to that proposed by Wadler and Blott in <ref> [63] </ref>. In this chapter, we describe our proposal for explicit, user-defined overloading of identifiers and a systematic mechanism for the compiler to resolve and then translate such programs into appropriate code. <p> Subsequently in section 4.3, we show two mechanisms of translation, parameterization and specialization and debate the advantages of one over the other. Finally in section 4.4, we investigate the relationship between our proposal and that of Wadler and Blott in <ref> [63] </ref>. 4.1 Issues in Overloading There are several issues to consider in a possible scheme for overloading. The following discussion is geared towards the static, compile-time type analysis that we have chosen to follow. <p> It is conceivable that a smart compiler will be able to generate the parameterized forms by looking at the type of the variables involved and the declaration of the various instances. Indeed, this is precisely the approach taken by Wadler and Blott in <ref> [63] </ref>. There the authors offer a general mechanism to systematically convert overloaded expressions into parameterized functions applying them to suitably resolved arguments. It is possible to split this process into two parts. <p> to its efficiency, this scheme is used in the current version of Id [48] as a preliminary solution until the more general schemes described earlier are implemented. 4.4 Comparison with the Proposal of Wadler and Blott Our overloading scheme is based on the proposal by Wadler and Blott described in <ref> [63] </ref> and used in the language Haskell [27]. In this section we will compare the mechanisms for overloading resolution and translation in the two systems, their expressive power, and the different objectives they achieve. <p> Apart from differences in the mechanisms, our system is an overall simplification of the system proposed by Wadler and Blott. An important aspect of their system is the notion of a "class" with a set of operations (also called a method dictionary in <ref> [63] </ref>) defined for it. Each instance of that class defines its own method dictionary that can be passed around as an object and identifies the actual functions that implement the methods of that class. <p> The interpretation of the instance 15 These examples are in Haskell. The syntax is mostly self explanatory. Early alphabets like a, b, etc. denote type variables, data is an algebraic type declaration, and function definitions appear as equations. For details, the reader is referred to <ref> [63, 27] </ref>. 150 declaration is to define a dictionary object numDInt that carries the method implementing definitions for that instance.
References-found: 63

