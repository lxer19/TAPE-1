URL: http://www.cs.brandeis.edu/~liuba/pos8.ps.gz
Refering-URL: http://www.cs.brandeis.edu/~liuba/papers.html
Root-URL: http://www.cs.brandeis.edu
Email: e-mail: liuba@cs.brandeis.edu  
Title: Trust but Check: Mutable Objects in Untrusted Cooperative Caches  
Author: Liuba Shrira Ben Yoder 
Affiliation: Computer Science Department Brandeis University and Laboratory for Computer Science MIT  
Abstract: Cooperative caching is known to be an effective technique for improving the performance of large scale distributed storage systems [5, 6, 7, 11, 1]. Nevertheless, current cooperative caching techniques work only in environments when machines trust one other, a requirement that is likely to become more and more difficult to satisfy. We describe a novel technique for managing cooperative caches in an untrusted environment. Our principal innovation is a new way to update objects on pages in untrusted caches while guaranteeing page integrity. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Adya, M. Castro, B. Liskov, U. Maheshwari, and L. Shrira. </author> <title> Fragment Reconstruction: Providing Global Cache Coherence in a Trans-acti onal Storage System. </title> <booktitle> In ICDCS, </booktitle> <year> 1997. </year>
Reference-contexts: 1 Introduction Cooperative caching is known to be an effective technique for improving the performance of large scale distributed storage systems <ref> [5, 6, 7, 11, 1] </ref>. Nevertheless, current cooperative caching techniques work only in environments when machines trust one other, a requirement that is likely to become more and more difficult to satisfy. We describe a novel technique for managing cooperative caches in an untrusted environment. <p> the disease: namely, even with 1 the integrity checks, the latency of fetching a page from an untrusted cooperative cache is still less than the latency of fetching a page from a trusted server. 2 Base System Architecture Our work is done in the context of the cooperative caching system <ref> [1] </ref> in the Thor client/server object-oriented database [10]. This section describes the cooperative caching architecture before we extended it to support page protection. Thor servers provide persistent storage for objects and clients cache copies of these objects. <p> Note, that we do not attempt to show the benefits of cooperative caching since that has been shown by others [5, 6, 7, 11], nor we attempt to show the benefits of support for fine-grain updates since that has been shown by our earlier study <ref> [1] </ref>. The performance benefits of cooperative caching include reducing the latency of fetches and installation fetches. The performance overheads of the integrity verification include, as discussed in section 3, additional client and server processing and additional network communication.
Reference: [2] <author> A. Adya, R. Gruber, B. Liskov, and U. Maheshwari. </author> <title> Efficient Optimistic Concurrency Control Using Loosely Synchronized Clocks. </title> <booktitle> In SIGMOD, </booktitle> <year> 1995. </year>
Reference-contexts: The directory keeps track of which pages are cached by which clients. The mcache holds recently modified objects that have not yet been written back to their pages on disk. 2.1 Transactions and Cache Coherence Transactions are serialized using optimistic concurrency control <ref> [2, 8] </ref>. The client keeps track of objects that are read and modified by its transaction; it sends this information, along with new copies of modified objects, to the servers when it tries to commit the transaction.
Reference: [3] <author> M. Bellare and D. Micciancio. </author> <title> A New Paradigm for Collision-free Hashing: Incrementality at Reduced Cost. </title> <booktitle> In Advances in Cryptology - Eurocrypt 97, Lecture Notes in Computer Science Vol. </booktitle> <volume> 1233, </volume> <editor> W.Fumy ed., </editor> <publisher> Springer-Verlag, </publisher> <year> 1997, 1997. </year>
Reference-contexts: another client requests the page from an untrusted cache, the server can provide a hash to assure the client of the page's integrity. 3.1 Incremental Hashing To support protected partial updates, we have experimented with a number of techniques similar to the independently proposed AdHASH incremental hashing technique by Bellare-Micciancio <ref> [3] </ref>. Since AdHASH is provably secure we follow the AdHASH definition. The protection scheme is based on the MD5 cryptographic hash function [12].
Reference: [4] <author> M. Carey et al. </author> <title> A Status Report on the OO7 OODBMS Benchmarking Effort. </title> <booktitle> In OOPSLA Proceedings, </booktitle> <year> 1994. </year>
Reference-contexts: The measured times given below are averages computed over 20000 runs. The workload-dependent parameters including average reconstruction message size and the percentage of the swizzled objects on a page were determined running the multi-user OO7 benchmark <ref> [4] </ref>. The MD5 hashing and verification of a page with 128 byte objects takes 2.2 milliseconds. Updating the hash assuming up to four object updates takes 0.05 milliseconds. Page reconstruction assuming reconstruction messages with up to four modified objects takes 0.014 milliseconds.
Reference: [5] <author> M. Dahlin, R. Wang, T. Anderson, and D. Patterson. </author> <title> Cooperative Caching: Using Remote Client Memory to Improve File System Performance. </title> <booktitle> In OSDI, </booktitle> <year> 1994. </year>
Reference-contexts: 1 Introduction Cooperative caching is known to be an effective technique for improving the performance of large scale distributed storage systems <ref> [5, 6, 7, 11, 1] </ref>. Nevertheless, current cooperative caching techniques work only in environments when machines trust one other, a requirement that is likely to become more and more difficult to satisfy. We describe a novel technique for managing cooperative caches in an untrusted environment. <p> Integrity verification eliminates the risk but incurs performance overhead. The key question is whether the overhead of the integrity verification outweighs the performance benefits of cooperative caching. Note, that we do not attempt to show the benefits of cooperative caching since that has been shown by others <ref> [5, 6, 7, 11] </ref>, nor we attempt to show the benefits of support for fine-grain updates since that has been shown by our earlier study [1]. The performance benefits of cooperative caching include reducing the latency of fetches and installation fetches.
Reference: [6] <author> M. Feeley, W. Morgan, F. Pighin, A. Karlin, H. Levy, and C. Thekkath. </author> <title> Implementing Global Memory Management in a Workstation Cluster. </title> <booktitle> In SOSP, </booktitle> <year> 1995. </year>
Reference-contexts: 1 Introduction Cooperative caching is known to be an effective technique for improving the performance of large scale distributed storage systems <ref> [5, 6, 7, 11, 1] </ref>. Nevertheless, current cooperative caching techniques work only in environments when machines trust one other, a requirement that is likely to become more and more difficult to satisfy. We describe a novel technique for managing cooperative caches in an untrusted environment. <p> Integrity verification eliminates the risk but incurs performance overhead. The key question is whether the overhead of the integrity verification outweighs the performance benefits of cooperative caching. Note, that we do not attempt to show the benefits of cooperative caching since that has been shown by others <ref> [5, 6, 7, 11] </ref>, nor we attempt to show the benefits of support for fine-grain updates since that has been shown by our earlier study [1]. The performance benefits of cooperative caching include reducing the latency of fetches and installation fetches.
Reference: [7] <author> M. Franklin, M. Carey, and M. Livny. </author> <title> Global Memory Management in Client-Server DBMS Architectures. </title> <booktitle> In VLDB, </booktitle> <year> 1992. </year>
Reference-contexts: 1 Introduction Cooperative caching is known to be an effective technique for improving the performance of large scale distributed storage systems <ref> [5, 6, 7, 11, 1] </ref>. Nevertheless, current cooperative caching techniques work only in environments when machines trust one other, a requirement that is likely to become more and more difficult to satisfy. We describe a novel technique for managing cooperative caches in an untrusted environment. <p> Integrity verification eliminates the risk but incurs performance overhead. The key question is whether the overhead of the integrity verification outweighs the performance benefits of cooperative caching. Note, that we do not attempt to show the benefits of cooperative caching since that has been shown by others <ref> [5, 6, 7, 11] </ref>, nor we attempt to show the benefits of support for fine-grain updates since that has been shown by our earlier study [1]. The performance benefits of cooperative caching include reducing the latency of fetches and installation fetches.
Reference: [8] <author> R. Gruber. </author> <title> Optimism vs. Locking: A Study of Concurrency Control for Client-Server Object-Oriented Databases. </title> <type> PhD thesis, </type> <institution> Mas-sachusetts Institute of Technology, </institution> <year> 1997. </year>
Reference-contexts: The directory keeps track of which pages are cached by which clients. The mcache holds recently modified objects that have not yet been written back to their pages on disk. 2.1 Transactions and Cache Coherence Transactions are serialized using optimistic concurrency control <ref> [2, 8] </ref>. The client keeps track of objects that are read and modified by its transaction; it sends this information, along with new copies of modified objects, to the servers when it tries to commit the transaction.
Reference: [9] <author> John H. Howard, Michael L. Kazar, Sherri G. Menees, David A. Nichols, M. Satyanarayanan, Robert N. Sidebotham, and Michael J. West. </author> <title> Scale and performance in a distributed file system. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 6(1) </volume> <pages> 51-81, </pages> <month> February </month> <year> 1988. </year>
Reference-contexts: Without cooperative caching, the protection problem for shared storage systems is well understood. For example, in the Andrew file system <ref> [9] </ref>, clients are protected against one another. A malicious client cannot corrupt another client's pages. A client machine can observe or modify any pages entrusted to it.
Reference: [10] <author> B. Liskov, A. Adya, M. Castro, M. Day, S. Ghemawat, R. Gruber, U. Maheshwari, A. Myers, and L. Shrira. </author> <title> Safe and Efficient Sharing of Persistent Objects in Thor. </title> <booktitle> In SIGMOD, </booktitle> <year> 1996. </year>
Reference-contexts: integrity checks, the latency of fetching a page from an untrusted cooperative cache is still less than the latency of fetching a page from a trusted server. 2 Base System Architecture Our work is done in the context of the cooperative caching system [1] in the Thor client/server object-oriented database <ref> [10] </ref>. This section describes the cooperative caching architecture before we extended it to support page protection. Thor servers provide persistent storage for objects and clients cache copies of these objects. Applications run at the clients and interact with the system by making calls on methods of cached objects. <p> P (unswiz) is the cost of unswizzling. P (verify) is the cost of hashing and verifying a page. Like many other object-oriented databases, Thor uses pointer swizzling <ref> [10] </ref> to make code at clients run faster: persistent references stored in cached copies of objects are replaced by virtual memory pointers before they are used. Swizzled references in a page must be unswizzled into persistent references before the page can be shipped to another client.
Reference: [11] <author> P. Sarkar and J. Hartman. </author> <title> Efficient Cooperative Caching Using Hints. </title> <booktitle> In OSDI, </booktitle> <year> 1996. </year>
Reference-contexts: 1 Introduction Cooperative caching is known to be an effective technique for improving the performance of large scale distributed storage systems <ref> [5, 6, 7, 11, 1] </ref>. Nevertheless, current cooperative caching techniques work only in environments when machines trust one other, a requirement that is likely to become more and more difficult to satisfy. We describe a novel technique for managing cooperative caches in an untrusted environment. <p> Integrity verification eliminates the risk but incurs performance overhead. The key question is whether the overhead of the integrity verification outweighs the performance benefits of cooperative caching. Note, that we do not attempt to show the benefits of cooperative caching since that has been shown by others <ref> [5, 6, 7, 11] </ref>, nor we attempt to show the benefits of support for fine-grain updates since that has been shown by our earlier study [1]. The performance benefits of cooperative caching include reducing the latency of fetches and installation fetches.
Reference: [12] <author> Bruce Schneier. </author> <title> Applied Cryptography. </title> <publisher> John Wiley, </publisher> <year> 1996. </year>
Reference-contexts: Cooperative caching techniques in the literature typically permit any client to cache any page, so any client can corrupt any page, regardless of any authorization structure. A variety of cryptographic techniques exist for protecting the integrity (authenticity) of immutable data <ref> [12] </ref>. Unfortunately, traditional techniques are ill-equipped to handle partial updates to pages, but support for partial updates is critical in objecs systems to avoid the well-known penalties associated with false sharing. <p> Since AdHASH is provably secure we follow the AdHASH definition. The protection scheme is based on the MD5 cryptographic hash function <ref> [12] </ref>. MD5 maps a value to a short 128 bit value (hash) in such a way that with high probability no-one should be able to come up with two strings having the same hash value. We have also considered other strong cryptographic functions e.g. SHA [12] that provide comparable security, and <p> the MD5 cryptographic hash function <ref> [12] </ref>. MD5 maps a value to a short 128 bit value (hash) in such a way that with high probability no-one should be able to come up with two strings having the same hash value. We have also considered other strong cryptographic functions e.g. SHA [12] that provide comparable security, and selected MD5 because in our implementation it offered better performance for pages with small objects.
Reference: [13] <institution> Seagate Technology. </institution> <address> http://www.seagate.com, March 1997. </address>
Reference-contexts: The experiments were run on an unloaded DEC Alpha 3000/400, 133 MHz, workstation running DEC/OSF1; we used a page size of 8 KB. The network times are for a fast implementation of TCP over ATM, U-Net [14], and the disk times are for a modern disk, Barracuda 4 <ref> [13] </ref>. The measured times given below are averages computed over 20000 runs. The workload-dependent parameters including average reconstruction message size and the percentage of the swizzled objects on a page were determined running the multi-user OO7 benchmark [4].
Reference: [14] <author> T. von Eicken, A. Basu, V. Buch, and W. Vogels. U-Net: </author> <title> A User-Level Network Interface for Parallel and Distributed Computing. </title> <booktitle> In SOSP, </booktitle> <year> 1996. </year>
Reference-contexts: The experiments were run on an unloaded DEC Alpha 3000/400, 133 MHz, workstation running DEC/OSF1; we used a page size of 8 KB. The network times are for a fast implementation of TCP over ATM, U-Net <ref> [14] </ref>, and the disk times are for a modern disk, Barracuda 4 [13]. The measured times given below are averages computed over 20000 runs. The workload-dependent parameters including average reconstruction message size and the percentage of the swizzled objects on a page were determined running the multi-user OO7 benchmark [4].
References-found: 14

