URL: http://http.cs.berkeley.edu/~soumen/spaa96.ps
Refering-URL: http://http.cs.berkeley.edu/~soumen/restmt.html
Root-URL: http://www.cs.berkeley.edu
Title: Resource scheduling for parallel database and scientific applications  
Author: Soumen Chakrabarti S. Muthukrishnan 
Abstract: We initiate a study of resource scheduling problems in parallel database and scientific applications. Based on this study we formulate a problem. In our formulation, jobs specify their running times and amounts of a fixed number of other resources (like memory, IO) they need. The resource-time trade-off may be fundamentally different for different resource types. The processor resource is malleable, meaning we can trade processors for time gracefully. Other resources may not be malleable. One way to model them is to assume no malleability: the entire requirement of those resources has to be reserved for a job to begin execution, and no smaller quantity is acceptable. The jobs also have precedences amongst them; in our applications, the precedence structure may be restricted to being a collection of trees or series-parallel graphs. Not much is known about considering precedence and non-malleable resource constraints together. For many other problems, it has been possible to find schedules whose length match to a constant factor the sum of two obvious lower bounds: the total resource-time product of jobs, denoted V , and the critical path in the precedence graph, denoted . We show that there are instances when the optimal makespan is (V + log T ) in our model. Here T is the ratio between longest and shortest job execution times, where typically T t n, the number of jobs. We then give a polynomial time makespan algorithm that produces a schedule of length O(V + log T ), which is therefore an O(log T ) approximation. This contrasts with most existing solutions for this problem, which are greedy, list-based strategies. These fail under heavy load and that is provably unavoidable since theoretical results have established various adversaries for them that force (T ) or (n) approximations. The makespan algorithm can be extended to minimize the weighted average completion time over all the jobs to the same approximation factor of O(log T ). 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> N. Alon. </author> <title> Eigenvalues and expanders. </title> <journal> Combinatorica, </journal> <volume> 6(2) </volume> <pages> 83-96, </pages> <year> 1986. </year>
Reference-contexts: In what follows, consider the `th interval in time, namely, (t `1 ; t ` ]; other intervals are processed similarly. Step 1. Let J ` be the set of jobs that have arrived within time <ref> [1; t ` ] </ref> but have not already been scheduled. We remove from consideration any job which cannot be scheduled within the `-th interval because of critical path constraints. Compute the earliest possible finish time j of each job j based on critical path (assuming unlimited resource and pro cessors). <p> Arbitrary DAGs. While we have handled hierarchical job graphs such as forests or series-parallel graphs, the general DAG case is open. It is known that precedence-constrained knapsack with general precedence is strongly N P-hard [16], unlike forests. We show that settling the approximability issue will be challenging <ref> [1] </ref>.
Reference: [2] <author> K. Brown et al. </author> <title> Resource allocation and scheduling for mixed database workloads. </title> <type> Technical Report 1095, </type> <institution> University of Wisconsin at Madison, </institution> <month> July </month> <year> 1992. </year>
Reference-contexts: In x3 and x4 we give the makespan lower and upper bounds. In x5 and x6 we show how to extend the makespan algorithm to a WACT algorithm. In x7 we pose unresolved problems. 2 Model Databases. Query scheduling in parallel databases is a topic of active research <ref> [2, 19, 28, 13, 10] </ref>. Queries arrive from many users to a front-end manager process.
Reference: [3] <author> S. Chakrabarti, C. Phillips, A. Schulz, D. Shmoys, C. Stein, and J. Wein. </author> <title> Improved scheduling algorithms for minsum criteria. </title> <booktitle> In Automata, Languages and Programming (ICALP), LNCS, Paderborn, </booktitle> <address> Germany, July 1996. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: Mall Mall off-line / WACT Garey et al [9] N/A N/A fi p ; on makespan Feldmann et al [8] m par p fi any on makespan Hall et al [14] 1; m seq fi fi any off both 1; m seq fi fi ; on both Chakrabarti et al <ref> [3] </ref> m par p fi any on both m par fi ; on both This paper m par p p any on makespan m par any off WACT m par forest/SPG on both Table 1: Comparison of results. <p> For instance, our algorithms do not use powerful primitives such as linear programming algorithms, and indeed we could not improve the quality of our solution using them. Finally we remark that although our problem is different from existing theoretical settings, our solution borrows from various existing techniques <ref> [9, 23, 3, 14] </ref>. Outline. In x2 we study database and scientific computing scenarios to justify our model. In x3 and x4 we give the makespan lower and upper bounds. In x5 and x6 we show how to extend the makespan algorithm to a WACT algorithm. <p> If = ;, the above analysis (with a trivial Step 3) gives a schedule of length O (V s + T ). 5 Weighted average completion time In this section we will describe how to extend the makespan algorithm developed earlier to the WACT metric, by applying techniques similar to <ref> [14, 3] </ref>. First we divide time into geometrically increasing intervals. That is, define t 0 = 1, t ` = 2 `1 , ` = 1; : : :. In what follows, consider the `th interval in time, namely, (t `1 ; t ` ]; other intervals are processed similarly. <p> That completes the description of the processing for the `th interval. The steps at the high level are standard, for example, see <ref> [14, 3] </ref>. The technical crux is the design of the two subroutines DualPack and Makespan. Theorem 7 The above algorithm is polynomial in T and n and, for s = O (1), is an O (log T ) approximation for both makespan and WACT with on-line job arrival. <p> We defer the details to the final version. Imperfect malleability. In reality the processor resource is not perfectly malleable, neither are other resources perfectly nonmalleable. How important is it to model and optimize for complicated intermediate forms of malleability? For imperfect malleability in the processor dimension <ref> [3] </ref> gives an WACT algorithm. Persistent resources. A job may allocate memory mid-way through execution. We cannot model this by a chain of two jobs, since the memory the job was already holding is not released. How can jobs with such persistent resource needs be scheduled? Non-clairvoyance and preemption.
Reference: [4] <author> C. Chekuri, R. Motwani, and B. Natarajan. </author> <title> Scheduling to minimize weighted completion time. </title> <type> Manuscript, </type> <year> 1995. </year>
Reference-contexts: Note that the fat jobs need to be only over 1 1= log T wide in the resource dimension. This implies that a recent elegant constant factor WACT approximation technique due to Chekuri et al, which converts uniprocessor schedules to multiprocessor schedules <ref> [4] </ref>, will not generalize to handle non-malleable resources. Their technique is to start with a uniprocessor schedule where job j completes at time C 1 j and derive an m-machine schedule with C m j = O (C 1 j =m + j ).
Reference: [5] <author> M. E. Dyer and L. A. Wolsey. </author> <title> Formulating the single machine sequencing problem with release dates as a mixed integer program. </title> <journal> Discrete Applied Mathematics, </journal> <volume> 26 </volume> <pages> 255-270, </pages> <year> 1990. </year>
Reference-contexts: On the other hand, the (V; ; T ) characterization may not be entirely unreasonable since more sophisticated lower bounds based on relaxing integer linear programs appear to have a large integrality gap. Specifically, consider the two formulations below. The first one is adapted from Dyer and Wolsey <ref> [5] </ref>. Here y jt = 1 if job j is running at time t , and zero otherwise.
Reference: [6] <author> K. Ekanadham, J. E. Moreira, and V. K. Naik. </author> <title> Application oriented resource management on large scale parallel systems. </title> <type> Technical Report RC 20151, </type> <institution> IBM Research, Yorktown Heights, </institution> <month> Aug. </month> <year> 1995. </year>
Reference-contexts: To improve utilization, system support has been designed to express jobs at a finer level inside an application and convey the information to the resource manager by annotating the parallel executable <ref> [12, 6, 20] </ref>. Note that the common precedence graphs are chains for scripts, series-parallel graphs for structured programs, forests for database queries, and for divide-and-conquer and branch-and-bound. Fidelity. The most general representation of a job is its running time as a function of the resource allocated to it.
Reference: [7] <author> D. G. Feitelson and L. Rudolph, </author> <title> editors. Job Scheduling Strategies for Parallel Processing, </title> <booktitle> number 949 in LNCS. </booktitle> <publisher> Springer-Verlag, </publisher> <month> Apr. </month> <year> 1995. </year> <booktitle> Workshop at International Parallel Processing Symposium. </booktitle>
Reference-contexts: First, preemption is not allowed. Time-slicing and preemption of space-shared resources is very expensive because (1) the state has to be evicted to slower layers of the memory hierarchy, (2) processes have to synchronize and switch across protection domains, and (3) in-flight messages have to be flushed and reinjected <ref> [7, page 6] </ref>. Anecdotal evidence suggests that many practitioners switch off time sharing for production runs on parallel machines that do not permit creating dedicated space partitions. <p> Thus the goal is to find approximations for the worst case and heuristics in practical settings. All known practical solutions use some variant of greedy list- or queue-type scheduling <ref> [7, 10, 19] </ref>. Jobs on arrival are placed in a list ordered by some heuristic (often FIFO). The scheduler dispatches the first ready job on the list when enough resources become available. List scheduling and its variants are appealingly simple to implement; however they can be notoriously bad.
Reference: [8] <author> A. Feldmann, M.-Y. Kao, J. Sgall, and S.-H. Teng. </author> <title> Optimal online scheduling of parallel jobs with dependencies. </title> <booktitle> In Symposium on the Theory of Computing (STOC), </booktitle> <pages> pages 642-651. </pages> <publisher> ACM, </publisher> <year> 1993. </year>
Reference-contexts: Only malleable resource. If there were no non-malleable resources, (i.e., there is only a malleable resource), then precedence can be handled (in the sense of approximating makespan) even by a scheduler that does not know t j before a job finishes <ref> [8] </ref>. But we must also schedule non-malleable resources. Small resource demand. Another possible restriction is to allow non-malleable resources, but require each job to reserve no more than fraction of the nonmalleable resources, where is small. That is, the maximum fraction requested by an job is at most . <p> Specifically, we give instances of our prob 2 Reference # Job Non- Prec On-line/ Makespan procs type Mall Mall off-line / WACT Garey et al [9] N/A N/A fi p ; on makespan Feldmann et al <ref> [8] </ref> m par p fi any on makespan Hall et al [14] 1; m seq fi fi any off both 1; m seq fi fi ; on both Chakrabarti et al [3] m par p fi any on both m par fi ; on both This paper m par p p <p> In all occasions without nonmalleable resources, this lower bound can be achieved to a constant factor: + 1 m j t j = + V for sequential jobs [11], and + ( p 3 5 ) 1 P for malleable jobs <ref> [8] </ref>. These depend on arguments of the form: "if a critical path is being ignored, most of the resources are being utilized." In this section, we show that O (V + ) makespan is not always possible with both non-malleable resources and precedence constraints. <p> Thus this differentiates our problem from all list-type approaches [11, 9, 14] and malleable job scheduling <ref> [8] </ref>. Our formulation is very different in flavor because jobs may have to wait even when resource utilization is very low because their specific requirement of the non-malleable resources are not met. In contrast, jobs can proceed with a smaller amount of a malleable resource with proportionate slowdown. <p> Also let j be the critical path length from a root through job j, and = max j f j g. The makespan algorithm first invokes a malleable list-type scheduling algorithm <ref> [8] </ref> to allocate processors to jobs in J , and to assign (infeasible) preliminary execution intervals to these jobs. Then we partition the jobs into a sequence of layers with jobs within a layer being independent of each other. Finally we schedule these layers one by one using bin-packing. <p> Compute a greedy schedule for J ignoring all non-malleable resource requirements, as follows. Whenever there are more than flm free processors, schedule any job j in J (whose predecessors have all completed) on the minimum of m j and the number of free processors. This step is similar to <ref> [8] </ref>. Denote by j the number of processors allocated to job j. After processor allocation let the modified job times be t 0 j = t j m j = j , and modified critical path lengths be 0 j . <p> Picking fl such that (1 fl)(1 + 1 fl ) = 1, the length of the (invalid) schedule is at most + 1 mfl j m j t j , similar to <ref> [8] </ref>. Lemma 3 Jobs assigned to a particular layer I are independent; the layer ordering is consistent with job precedence and in any layer I, P Proof.
Reference: [9] <author> M. R. Garey and R. L. Graham. </author> <title> Bounds for multiprocessor scheduling with resource constraints. </title> <journal> SIAM Journal on Computing, </journal> <volume> 4(2) </volume> <pages> 187-200, </pages> <month> June </month> <year> 1975. </year>
Reference-contexts: Even if t j is known upon arrival, any greedy schedule has worst case makespan performance ratio at least nT =(n + T ), which is roughly T when T t n and n when T n, both of which are achieved trivially <ref> [9, Theorem 1] </ref>. On the other hand, all positive algorithmic results we tried to adapt fall short of our goal in some respect or another, unless we abandon some requirement. In what follows we show examples of this. No precedence. <p> In what follows we show examples of this. No precedence. If the precedence graph were empty, (i.e., independent jobs) then a number of approaches are known to get approximation bounds, even with additional restrictions like sub-linear speedup <ref> [9, 18, 27, 26, 25] </ref>. In the database scenario, it is possible to collapse each query (consisting of several jobs with a precedence relation amongst them) into one job (allocating maximum resources over all the jobs in the query) and then apply the results for independent jobs [28]. <p> We show that our formulation is very different in flavor, in that some parameter other than V and is at work. Specifically, we give instances of our prob 2 Reference # Job Non- Prec On-line/ Makespan procs type Mall Mall off-line / WACT Garey et al <ref> [9] </ref> N/A N/A fi p ; on makespan Feldmann et al [8] m par p fi any on makespan Hall et al [14] 1; m seq fi fi any off both 1; m seq fi fi ; on both Chakrabarti et al [3] m par p fi any on both m <p> For instance, our algorithms do not use powerful primitives such as linear programming algorithms, and indeed we could not improve the quality of our solution using them. Finally we remark that although our problem is different from existing theoretical settings, our solution borrows from various existing techniques <ref> [9, 23, 3, 14] </ref>. Outline. In x2 we study database and scientific computing scenarios to justify our model. In x3 and x4 we give the makespan lower and upper bounds. In x5 and x6 we show how to extend the makespan algorithm to a WACT algorithm. <p> Thus this differentiates our problem from all list-type approaches <ref> [11, 9, 14] </ref> and malleable job scheduling [8]. Our formulation is very different in flavor because jobs may have to wait even when resource utilization is very low because their specific requirement of the non-malleable resources are not met. <p> The total length of the invalid schedule will be O ( log T ). Step 4. Schedule each layer separately in time order. Consider each layer to be an instance of a generalized s-dimensional bin-packing problem 2 <ref> [9] </ref>. A first-fit (FF) bin packing of each layer, considering job j in the layer to be an item of "size" ~r j and bins of "size" ~ 1, suffices for our purpose. <p> Observe that the makespan routine is polynomial in n, T , and s, and works for any precedence. The above method also gives an alternative algorithm and much simpler anal ysis (weaker only in a constant) for the (s + 1)-approximate resource constrained scheduling result of <ref> [9] </ref>. Their (s + 1)- approximation is for = ;. In this case = T , and we allocate log T layers with t (I) 2 f1; 2; 4; : : : ; T g. Then P I t (I) &lt; 2T , giving an O (s) approximation.
Reference: [10] <author> M. Garofalakis and Y. Ioannidis. </author> <title> Multidimensional resource scheduling for parallel queries. </title> <booktitle> In ACM SIGMOD Conference on the Management of Data. ACM, </booktitle> <month> May </month> <year> 1996. </year>
Reference-contexts: Thus the goal is to find approximations for the worst case and heuristics in practical settings. All known practical solutions use some variant of greedy list- or queue-type scheduling <ref> [7, 10, 19] </ref>. Jobs on arrival are placed in a list ordered by some heuristic (often FIFO). The scheduler dispatches the first ready job on the list when enough resources become available. List scheduling and its variants are appealingly simple to implement; however they can be notoriously bad. <p> In x3 and x4 we give the makespan lower and upper bounds. In x5 and x6 we show how to extend the makespan algorithm to a WACT algorithm. In x7 we pose unresolved problems. 2 Model Databases. Query scheduling in parallel databases is a topic of active research <ref> [2, 19, 28, 13, 10] </ref>. Queries arrive from many users to a front-end manager process. <p> Fidelity. The most general representation of a job is its running time as a function of the resource allocated to it. It is difficult to find this function <ref> [10] </ref>, and unclear if it is simple enough to be used by the optimizer. We propose grouping the resources into two types: malleable and nonmalleable. It may be of interest to evaluate more elaborate alternatives.
Reference: [11] <author> R. L. Graham. </author> <title> Bounds on multiprocessor timing anomalies. </title> <journal> SIAM Journal of Applied Mathematics, </journal> <volume> 17(2) </volume> <pages> 416-429, </pages> <month> March </month> <year> 1969. </year>
Reference-contexts: In all occasions without nonmalleable resources, this lower bound can be achieved to a constant factor: + 1 m j t j = + V for sequential jobs <ref> [11] </ref>, and + ( p 3 5 ) 1 P for malleable jobs [8]. <p> Thus this differentiates our problem from all list-type approaches <ref> [11, 9, 14] </ref> and malleable job scheduling [8]. Our formulation is very different in flavor because jobs may have to wait even when resource utilization is very low because their specific requirement of the non-malleable resources are not met.
Reference: [12] <author> S. L. Graham, S. Lucco, and O. Sharp. </author> <title> Orchestrating interactions among parallel computations. </title> <booktitle> In Programming Language Design and Implementation (PLDI), </booktitle> <pages> pages 100-111, </pages> <address> Albuquerque, NM, </address> <month> June </month> <year> 1993. </year> <note> ACM. </note>
Reference-contexts: To improve utilization, system support has been designed to express jobs at a finer level inside an application and convey the information to the resource manager by annotating the parallel executable <ref> [12, 6, 20] </ref>. Note that the common precedence graphs are chains for scripts, series-parallel graphs for structured programs, forests for database queries, and for divide-and-conquer and branch-and-bound. Fidelity. The most general representation of a job is its running time as a function of the resource allocated to it.
Reference: [13] <author> J. Gray. </author> <title> A survey of parallel database techniques and systems, September 1995. </title> <booktitle> Tutorial at VLDB. </booktitle>
Reference-contexts: In x3 and x4 we give the makespan lower and upper bounds. In x5 and x6 we show how to extend the makespan algorithm to a WACT algorithm. In x7 we pose unresolved problems. 2 Model Databases. Query scheduling in parallel databases is a topic of active research <ref> [2, 19, 28, 13, 10] </ref>. Queries arrive from many users to a front-end manager process. <p> This model is best suited to shared memory databases running on symmetric bus-based multiprocessors (SMP) with shared access to disk [15]. They currently scale to 30-40 processors. There is consensus that SMP's and scalable multiprocessors will converge to networked clusters of SMP nodes <ref> [13] </ref>. Since communication costs across clusters is much more expensive than shared access within a cluster, the expectation is that most queries will be parallelized within an SMP node. Scientific applications. Multiprocessor installations are shared by many users submitting programs to manager processes running on the front-end that schedules them.
Reference: [14] <author> L. Hall, D. Shmoys, and J. Wein. </author> <title> Scheduling to minimize average completion time: Off-line and online algorithms. </title> <booktitle> In Symposium on Discrete Algorithms (SODA). ACM-SIAM, </booktitle> <year> 1996. </year>
Reference-contexts: Specifically, we give instances of our prob 2 Reference # Job Non- Prec On-line/ Makespan procs type Mall Mall off-line / WACT Garey et al [9] N/A N/A fi p ; on makespan Feldmann et al [8] m par p fi any on makespan Hall et al <ref> [14] </ref> 1; m seq fi fi any off both 1; m seq fi fi ; on both Chakrabarti et al [3] m par p fi any on both m par fi ; on both This paper m par p p any on makespan m par any off WACT m par forest/SPG <p> For instance, our algorithms do not use powerful primitives such as linear programming algorithms, and indeed we could not improve the quality of our solution using them. Finally we remark that although our problem is different from existing theoretical settings, our solution borrows from various existing techniques <ref> [9, 23, 3, 14] </ref>. Outline. In x2 we study database and scientific computing scenarios to justify our model. In x3 and x4 we give the makespan lower and upper bounds. In x5 and x6 we show how to extend the makespan algorithm to a WACT algorithm. <p> Thus this differentiates our problem from all list-type approaches <ref> [11, 9, 14] </ref> and malleable job scheduling [8]. Our formulation is very different in flavor because jobs may have to wait even when resource utilization is very low because their specific requirement of the non-malleable resources are not met. <p> If = ;, the above analysis (with a trivial Step 3) gives a schedule of length O (V s + T ). 5 Weighted average completion time In this section we will describe how to extend the makespan algorithm developed earlier to the WACT metric, by applying techniques similar to <ref> [14, 3] </ref>. First we divide time into geometrically increasing intervals. That is, define t 0 = 1, t ` = 2 `1 , ` = 1; : : :. In what follows, consider the `th interval in time, namely, (t `1 ; t ` ]; other intervals are processed similarly. <p> That completes the description of the processing for the `th interval. The steps at the high level are standard, for example, see <ref> [14, 3] </ref>. The technical crux is the design of the two subroutines DualPack and Makespan. Theorem 7 The above algorithm is polynomial in T and n and, for s = O (1), is an O (log T ) approximation for both makespan and WACT with on-line job arrival. <p> Also, note that if we had an approximation algorithm for the Makespan routine, we would have an O () approximation for minimizing WACT. If we are only interested in offline schedules, we can compute J 0 ` via rounding an integer program similar to <ref> [14] </ref>, obviating the need for the DualPack routine. We omit the details of the following claim. <p> Minimize P j w j C j subject to Resource: P Complete: P Couple: C j = t j t j t t + 1 Precedence: C j 1 C j 2 t j 2 8j 1 j 2 The second one is adapted from Hall et al <ref> [14] </ref>. Here y jt = 1 if job j completes at time t , and zero otherwise. <p> It is known that precedence-constrained knapsack with general precedence is strongly N P-hard [16], unlike forests. We show that settling the approximability issue will be challenging [1]. This shows that the framework of <ref> [14] </ref> may need modification to handle DAG's, not necessarily that the scheduling problem is difficult. 6 Claim 9 There is an approximation preserving reduction from Expansion, the problem of estimating the vertex expansion of a bipartite graph, to P.O.K., the partial order knapsack problem, even when all item costs and profits
Reference: [15] <author> W. Hong and M. Stonebraker. </author> <title> Optimization of parallel query execution plans in XPRS. </title> <booktitle> Distributed and Parallel Databases, </booktitle> <volume> 1(1) </volume> <pages> 9-32, </pages> <month> Jan. </month> <year> 1993. </year> <title> Also see Parallel Query Processing using Shared Memory Multiprocessing and Disk Arrays by W. </title> <type> Hong, PhD thesis, </type> <institution> UCB/ERL M93-28. </institution>
Reference-contexts: This has a serious drawback in that some obvious, critical coscheduling may be lost. For example, a CPU-bound job from one query and the IO-bound job of another can be co-scheduled and it is highly desirable to do so <ref> [15] </ref>; this cannot be done after the collapse. Only malleable resource. If there were no non-malleable resources, (i.e., there is only a malleable resource), then precedence can be handled (in the sense of approximating makespan) even by a scheduler that does not know t j before a job finishes [8]. <p> The tools are standard in database literature [22]. For parallel databases, one can also estimate for each operation up to how many processors can be employed at near-linear speedup <ref> [15] </ref>. Thus t j and m j can be estimated when a job arrives. Estimates of sizes of intermediate results can be used to estimate the memory and disk bandwidth resource vector ~r j . <p> Once processor and memory allocation are fixed, the disk bandwidth needed can be estimated from the total IO volume and job running time. This model is best suited to shared memory databases running on symmetric bus-based multiprocessors (SMP) with shared access to disk <ref> [15] </ref>. They currently scale to 30-40 processors. There is consensus that SMP's and scalable multiprocessors will converge to networked clusters of SMP nodes [13].
Reference: [16] <author> D. S. Johnson and K. A. Niemi. </author> <title> On knapsacks, partitions, and a new dynamic programming technique for trees. </title> <journal> Mathematics of Operations Research, </journal> <volume> 8(1) </volume> <pages> 1-14, </pages> <month> February </month> <year> 1983. </year>
Reference-contexts: The dynamic program can be extended to work on hierarchical graphs such as in-trees, out-trees, and series-parallel graphs, by using a technique of Johnson and Niemi <ref> [16] </ref>. (A series-parallel graph (SPG) can be represented hierarchically using the grammar: a SPG G is a vertex j (which is both the source and the sink), two SPG's G up and G down in se ries, or G left and G right in parallel.) We finally note that at the <p> Arbitrary DAGs. While we have handled hierarchical job graphs such as forests or series-parallel graphs, the general DAG case is open. It is known that precedence-constrained knapsack with general precedence is strongly N P-hard <ref> [16] </ref>, unlike forests. We show that settling the approximability issue will be challenging [1].
Reference: [17] <author> H. Kellerer, T. Tautenhahn, and G. J. Woeginger. </author> <title> Approx-imability and non-approximability results for minimizing total flow time on a single machine. </title> <booktitle> In Symposium on the Theory of Computing (STOC). ACM, </booktitle> <month> May </month> <year> 1996. </year>
Reference-contexts: Unfortunately, even with a single machine, off-line problem instance, and no resource or precedence constraints, it is N P-hard to approximate non-preemptive flowtime better than about a factor of ( p n) <ref> [17] </ref>. In a practical implementation of our algorithm, one might artificially increase w j for jobs waiting for a long time. Acknowledgments. Thanks to Joel Wein for introducing us to the area, and to Yaoguang Wang for helpful discussions.
Reference: [18] <author> W. Ludwig and P. Tiwari. </author> <title> Scheduling malleable and nonmalleable parallel tasks. </title> <booktitle> In Symposium on Discrete Algorithms (SODA), </booktitle> <pages> pages 167-176. ACM-SIAM, </pages> <year> 1994. </year>
Reference-contexts: In what follows we show examples of this. No precedence. If the precedence graph were empty, (i.e., independent jobs) then a number of approaches are known to get approximation bounds, even with additional restrictions like sub-linear speedup <ref> [9, 18, 27, 26, 25] </ref>. In the database scenario, it is possible to collapse each query (consisting of several jobs with a precedence relation amongst them) into one job (allocating maximum resources over all the jobs in the query) and then apply the results for independent jobs [28].
Reference: [19] <author> M. Mehta and D. Dewitt. </author> <title> Dynamic memory allocation for multiple-query workloads. </title> <booktitle> In Very Large Databases (VLDB), </booktitle> <pages> pages 354-367, </pages> <year> 1993. </year>
Reference-contexts: Thus the goal is to find approximations for the worst case and heuristics in practical settings. All known practical solutions use some variant of greedy list- or queue-type scheduling <ref> [7, 10, 19] </ref>. Jobs on arrival are placed in a list ordered by some heuristic (often FIFO). The scheduler dispatches the first ready job on the list when enough resources become available. List scheduling and its variants are appealingly simple to implement; however they can be notoriously bad. <p> In x3 and x4 we give the makespan lower and upper bounds. In x5 and x6 we show how to extend the makespan algorithm to a WACT algorithm. In x7 we pose unresolved problems. 2 Model Databases. Query scheduling in parallel databases is a topic of active research <ref> [2, 19, 28, 13, 10] </ref>. Queries arrive from many users to a front-end manager process. <p> relations R 1 and R 2 with, say, R 1 being smaller, takes time roughly proportional to dlog r jR 1 je, where r is the memory allocated; typically the query planner picks r = jR 1 j or r = jR 1 j 1=2 , independent of other queries <ref> [19] </ref>. Once processor and memory allocation are fixed, the disk bandwidth needed can be estimated from the total IO volume and job running time. This model is best suited to shared memory databases running on symmetric bus-based multiprocessors (SMP) with shared access to disk [15].
Reference: [20] <author> J. E. Moreira, V. K. Naik, and R. B. Konuru. </author> <title> A system for dynamic resource allocation and data distribution. </title> <type> Technical Report RC 20257, </type> <institution> IBM Research, Yorktown Heights, </institution> <month> Oct. </month> <year> 1995. </year>
Reference-contexts: To improve utilization, system support has been designed to express jobs at a finer level inside an application and convey the information to the resource manager by annotating the parallel executable <ref> [12, 6, 20] </ref>. Note that the common precedence graphs are chains for scripts, series-parallel graphs for structured programs, forests for database queries, and for divide-and-conquer and branch-and-bound. Fidelity. The most general representation of a job is its running time as a function of the resource allocated to it.
Reference: [21] <author> R. Motwani, S. Phillips, and E. Torng. </author> <title> Non-clairvoyant scheduling. </title> <journal> Theoretical Computer Science, </journal> <volume> 130 </volume> <pages> 17-47, </pages> <month> August </month> <year> 1994. </year> <note> Preliminary version in SODA 1993, pp 422-431. </note>
Reference-contexts: No deterministic scheduler that does not know t j until job j has finished 1 has WACT 1 Such a scheduler is called "non-clairvoyant". performance ratio bounded away from T <ref> [21, Theorem 5.4] </ref>. Even if t j is known upon arrival, any greedy schedule has worst case makespan performance ratio at least nT =(n + T ), which is roughly T when T t n and n when T n, both of which are achieved trivially [9, Theorem 1]. <p> How can jobs with such persistent resource needs be scheduled? Non-clairvoyance and preemption. For the motivating ap plications, reasonable estimates of job running time are possible. More general purpose schedulers must be non-clairvoyant, i.e., work without knowledge of t j before j completes <ref> [24, 21] </ref>. To handle this, recourse to job preemption or cancellation is needed, whose large cost has to be factored into the algorithm. Arbitrary DAGs. While we have handled hierarchical job graphs such as forests or series-parallel graphs, the general DAG case is open.
Reference: [22] <author> P. G. Selinger, M. M. Astrahan, D. D. Chamberlin, R. A. Lorie, and T. G. Price. </author> <title> Access path selection in a relational database management system. </title> <booktitle> In ACM SIGMOD Conference on the Management of Data, </booktitle> <pages> pages 23-34, </pages> <year> 1979. </year>
Reference-contexts: Databases keep certain access statistics along with the relations that are used to predict the sizes of results of joins and selects, and how many CPU instructions will be required to compute these results. The tools are standard in database literature <ref> [22] </ref>. For parallel databases, one can also estimate for each operation up to how many processors can be employed at near-linear speedup [15]. Thus t j and m j can be estimated when a job arrives.
Reference: [23] <author> D. Shmoys, C. Stein, and J. Wein. </author> <title> Improved approximation algorithms for shop scheduling problems. </title> <journal> SIAM Journal on Computing, </journal> <volume> 23 </volume> <pages> 617-632, </pages> <year> 1994. </year> <note> Preliminary version in SODA 1991. </note>
Reference-contexts: For instance, our algorithms do not use powerful primitives such as linear programming algorithms, and indeed we could not improve the quality of our solution using them. Finally we remark that although our problem is different from existing theoretical settings, our solution borrows from various existing techniques <ref> [9, 23, 3, 14] </ref>. Outline. In x2 we study database and scientific computing scenarios to justify our model. In x3 and x4 we give the makespan lower and upper bounds. In x5 and x6 we show how to extend the makespan algorithm to a WACT algorithm. <p> This is the last layer. Divide [t T; (t + 1)T ) into [t T; (t + 1 2 )T; (t + 1)T ) and recurse, placing the generated layers in pre-order <ref> [23] </ref>. The total length of the invalid schedule will be O ( log T ). Step 4. Schedule each layer separately in time order. Consider each layer to be an instance of a generalized s-dimensional bin-packing problem 2 [9].
Reference: [24] <author> D. B. Shmoys, J. Wein, and D. P. Williamson. </author> <title> Scheduling parallel machines online. </title> <booktitle> In Foundations of Computer Science (FOCS), </booktitle> <pages> pages 131-140, </pages> <year> 1991. </year>
Reference-contexts: How can jobs with such persistent resource needs be scheduled? Non-clairvoyance and preemption. For the motivating ap plications, reasonable estimates of job running time are possible. More general purpose schedulers must be non-clairvoyant, i.e., work without knowledge of t j before j completes <ref> [24, 21] </ref>. To handle this, recourse to job preemption or cancellation is needed, whose large cost has to be factored into the algorithm. Arbitrary DAGs. While we have handled hierarchical job graphs such as forests or series-parallel graphs, the general DAG case is open.
Reference: [25] <author> J. Turek, W. Ludwig, J. Wolf, L. Fleischer, P. Tiwari, J. Glasgow, U. Schweigelshohn, and P. S. Yu. </author> <title> Scheduling par-allelizable tasks to minimize average response time. </title> <booktitle> In Symposium on Parallel Algorithms and Architectures (SPAA). ACM, </booktitle> <year> 1994. </year>
Reference-contexts: In what follows we show examples of this. No precedence. If the precedence graph were empty, (i.e., independent jobs) then a number of approaches are known to get approximation bounds, even with additional restrictions like sub-linear speedup <ref> [9, 18, 27, 26, 25] </ref>. In the database scenario, it is possible to collapse each query (consisting of several jobs with a precedence relation amongst them) into one job (allocating maximum resources over all the jobs in the query) and then apply the results for independent jobs [28].
Reference: [26] <author> J. Turek, U. Schwiegelshohn, J. Wolf, and P. Yu. </author> <title> Scheduling parallel tasks to minimize average response time. </title> <booktitle> In Symposium on Discrete Algorithms (SODA), </booktitle> <pages> pages 112-121. ACM-SIAM, </pages> <year> 1994. </year>
Reference-contexts: In what follows we show examples of this. No precedence. If the precedence graph were empty, (i.e., independent jobs) then a number of approaches are known to get approximation bounds, even with additional restrictions like sub-linear speedup <ref> [9, 18, 27, 26, 25] </ref>. In the database scenario, it is possible to collapse each query (consisting of several jobs with a precedence relation amongst them) into one job (allocating maximum resources over all the jobs in the query) and then apply the results for independent jobs [28].
Reference: [27] <author> J. Turek, J. L. Wolf, and P. S. Yu. </author> <title> Approximate algorithms for scheduling parallelizable tasks. </title> <booktitle> In Symposium on Parallel Algorithms and Architectures (SPAA), </booktitle> <pages> pages 323-332, </pages> <year> 1992. </year>
Reference-contexts: In what follows we show examples of this. No precedence. If the precedence graph were empty, (i.e., independent jobs) then a number of approaches are known to get approximation bounds, even with additional restrictions like sub-linear speedup <ref> [9, 18, 27, 26, 25] </ref>. In the database scenario, it is possible to collapse each query (consisting of several jobs with a precedence relation amongst them) into one job (allocating maximum resources over all the jobs in the query) and then apply the results for independent jobs [28].
Reference: [28] <author> J. Wolf, J. Turek, M. Chen, and P. Yu. </author> <title> The optimal scheduling of multiple queries in a parallel database machine. </title> <type> Technical Report RC 18595 (81362) 12/17/92, </type> <institution> IBM, </institution> <year> 1992. </year> <month> 7 </month>
Reference-contexts: In the database scenario, it is possible to collapse each query (consisting of several jobs with a precedence relation amongst them) into one job (allocating maximum resources over all the jobs in the query) and then apply the results for independent jobs <ref> [28] </ref>. This has a serious drawback in that some obvious, critical coscheduling may be lost. For example, a CPU-bound job from one query and the IO-bound job of another can be co-scheduled and it is highly desirable to do so [15]; this cannot be done after the collapse. <p> In x3 and x4 we give the makespan lower and upper bounds. In x5 and x6 we show how to extend the makespan algorithm to a WACT algorithm. In x7 we pose unresolved problems. 2 Model Databases. Query scheduling in parallel databases is a topic of active research <ref> [2, 19, 28, 13, 10] </ref>. Queries arrive from many users to a front-end manager process.
References-found: 28

