URL: ftp://ftp.cs.virginia.edu/pub/dissertations/9404.ps.Z
Refering-URL: ftp://ftp.cs.virginia.edu/pub/dissertations/README.html
Root-URL: http://www.cs.virginia.edu
Title: Register Allocation and Phase Interactions in Retargetable Optimizing Compilers  
Author: Manuel Enrique Benitez 
Degree: A Dissertation Presented to the Faculty of the School of Engineering and Applied Science at the University of Virginia In Partial Fulfillment of the Requirements for the Degree Doctor of Philosophy (Computer Science) by  
Abstract-found: 0
Intro-found: 1
Reference: [AHO86] <author> A. V. Aho, R.Sethi and J.D. Ullman, CompilersPrinciples, </author> <title> Techniques, and Tools, </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1986. </year>
Reference-contexts: These limitations apply not only to code improvements like peephole optimization [MCKE65] and instruction scheduling [HENN83], which exploit specific architectural features, but also to code improvements like loop-invariant code motion <ref> [AHO86] </ref> and evaluation order determination [SETH70], whose broad applicability has fueled the myth that they can be effectively performed on high-level representations. The fallacy of this assumption is illustrated with a few simple examples. <p> complex expressions that generate simple arithmetic sequences within a loop with simpler expressions that are less expensive to compute, 1 A basic block consists of a sequence of straight-line code that can only be executed starting with the first instruction in the sequence and exited only through the last instruction <ref> [AHO86] </ref>. 9 induction variable elimination, which removes unneeded induction values from a loop, dead code elimination, which deletes code that will never be executed, branch chain elimination, which changes any branch that transfers control to another branch to branch directly to the destination of the second branch and jump minimization, which <p> Figure 6 shows the structure of vpo. The first phase of the back-end builds a control-ow graph (CFG) by partitioning the code into basic blocks <ref> [AHO86] </ref> in order to perform branch chain elimination, jump minimization and dead code elimination. Because the instruction selection phase attempts to combine logically adjacent rather that physically adjacent instructions, local and global links are inserted to connect groups of instructions that can potentially merge into a singleton. <p> if A then C = common_subexpression_elimination () live_variable_dataow_analysis () C = C dead_variable_elimination () C = C loop_optimizations () C = C instruction_selection () endif until C control_ow_optimizations () insert_function_prologue_and_epilogue () instruction_scheduling () fill_branch_delay_slots () endproc 73 vectors that reserve a single bit position for each instruction in the function <ref> [AHO86] </ref>. <p> Ordering code motion based on loop nesting level also exploits the fact that code moved out of an inner loop is often loop-invariant in the enclosing loop and can be moved repeatedly until it eventually propagates entirely outside the loops. the algorithm presented by Aho, Sethi and Ullman <ref> [AHO86] </ref> to find loop-invariant expressions in high-level intermediate code. This algorithm examines the loop whose information structure is passed to it as an argument and locates the two different types of loop-invariant registers which may be exist in a loop. <p> the basic induction variable is incremented by x 3 , the value of the induced expression changes from scalei+displacement to 1 In many cases, a block that qualifies as a preheader will already exist in the CFG, and a new basic block will not have to be created. 2 In <ref> [AHO86] </ref> these values are called cee and dee, respectively.
Reference: [AUSL82] <author> M. A. Auslander and M. E. Hopkins, </author> <title> An Overview of the PL.8 Compiler, </title> <booktitle> Proceedings of the SIGPLAN Notices 1982 Symposium on Programming Language Design and Implementation, </booktitle> <address> Boston, MA, </address> <month> June </month> <year> 1982, </year> <pages> 22-31. </pages>
Reference-contexts: Furthermore, this register allocation strategy does not prevent code improvement transformations from over-committing registers and producing code whose quality is worse than that of the original, unimproved code. The term, over-optimization, has been used to describe this situation <ref> [AUSL82] </ref>. To prevent over-optimization, the compiler can abstain from using pseudo-registers by requiring code improvements transformations to obtain actual target machine registers. <p> This representation provides more accurate cost and benefit estimates than 41 high-level representation do and result in better register packing decisions. Leveretts work suggests that low-level representations can be used to make highly machine-specific tasks like register allocation retargetable without sacrificing their quality. 3.4.4 PL.8 The PL.8 compiler <ref> [AUSL82] </ref> pioneered the use of graph coloring register allocation. This compiler rigorously adheres to the strategy of dividing the compilation process into a series of simpler, independent problems. To support this strategy, register consuming transformations request pseudo-register values from a gatekeeper that always allows their creation.
Reference: [BAAS78] <author> S. Baase, </author> <title> Computer Algorithms: Introduction to Design and Analysis, </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <month> June </month> <year> 1978. </year>
Reference-contexts: Because finding an optimal packing is an NP-complete problem <ref> [BAAS78] </ref>, algorithms that can optimally pack a non-trivial set of pseudo-register values require unacceptable amounts of execution time. <p> Determining the coloring (or assignment) of an interference graph that requires the fewest number of registers is an NP-complete problem <ref> [BAAS78] </ref>. Like compilers that perform sophisticated register packing, those that use coloring register allocators employ heuristics to obtain a good coloring of the interference graph instead of an optimal one.
Reference: [BELA66] <author> L. A. Belady, </author> <title> A Study of Replacement Algorithms for a Virtual-Storage Computer, </title> <journal> IBM Systems Journal, </journal> <volume> 5(2), </volume> <month> April </month> <year> 1966, </year> <pages> 78-101. </pages>
Reference-contexts: The following sections describe simpler optimal and near-optimal algorithms. 31 3.3.1.2 Page replacement Beladys optimal page replacement algorithm, developed for operating systems, can also be used to perform optimal local register allocation <ref> [BELA66] </ref>. The strategy is simple: when a value must be loaded into a register and all of the registers contain live values, displace the register value with the most distant next use. This approach works because it displaces the value that is most likely to end up being displaced, anyway.
Reference: [BELL71] <author> C. G. Bell and A. Newell, </author> <title> Computer Structures: Readings and Examples, </title> <publisher> McGraw-Hill, </publisher> <year> 1971. </year>
Reference-contexts: Unlike their high-level counterparts, low-level representations encode the semantics of a wide range of machine instructions. One of the most commonly used notations used to represent low-level code is the register transfer <ref> [BELL71] </ref>. Register transfers have been successfully used in a number retargetable optimizing compilers including PO [DAVI81], 6 YC [DAVI84b], vpo [BENI89] and gcc [STAL89]. <p> The low-level intermediate language used by llef is the register transfer notation, which is based on the Instruction Set Processor (ISP) notation developed by Bell and Newell <ref> [BELL71] </ref>. Register transfers represent machine instructions by describing the effects that the instructions have on architectures storage 70 calls. While assembly syntax varies from machine to machine, the register transfer specification of an operation is identical across machines. <p> Register transfers have their origins in the Instruction Set Processor (ISP) notation developed by Bell and Newell <ref> [BELL71] </ref>. The original notation was altered slightly to facilitate its use as a low-level intermediate language. The register transfer notation described here is similar to that presented by Davidson for PO [DAVI84b]. A register transfer describes the effect of a machine instruction.
Reference: [BENI88] <author> M. E. Benitez and J. W. Davidson, </author> <title> A Portable Global Optimizer and Linker, </title> <booktitle> Proceedings of the SIGPLAN Notices 1988 Symposium on Programming Language Design and Implementation, </booktitle> <address> Atlanta, GA, </address> <month> June </month> <year> 1988, </year> <pages> 329-338. </pages>
Reference-contexts: This strategy ensures that all of the opportunities created by each transformation to perform additional improvements are automatically exploited. Phase iteration is facilitated by the fact that all code improvement phases operate on the same representation of the code <ref> [BENI88] </ref>. Each phase indicates whether it applied transformations to the code so that vpo can determine which phases should be re-invoked. The global code improvements performed by vpo include dead variable elimination, local variable promotion and common subexpression elimination.
Reference: [BENI89] <author> M. E. Benitez, </author> <title> A Global Object Code Optimizer, </title> <type> MS Thesis, </type> <institution> University of Virginia, </institution> <address> Charlottesville, VA, </address> <month> January </month> <year> 1989. </year>
Reference-contexts: One of the most commonly used notations used to represent low-level code is the register transfer [BELL71]. Register transfers have been successfully used in a number retargetable optimizing compilers including PO [DAVI81], 6 YC [DAVI84b], vpo <ref> [BENI89] </ref> and gcc [STAL89]. Regardless of the underlying notation, low-level representations allow the code improvement algorithms to operate at the machine level where all of the target machine nuances are exposed and all transformations, including those that exploit specific architectural features, can be performed effectively. <p> This is a substantial accomplishment, considering that the front-ends already produce good code. These results suggest that performing code improvement transformations on low-level code is an effective way to produce high-quality machine code. 2.5.4 VPO The experience gained from the PO compiler was used to develop vpo <ref> [BENI89] </ref>, which differs from its predecessor the following significant areas: it uses a C [KERN78] front end, the instruction recognizer uses a yacc-produced parser [JOHN78a], it performs global-scope register allocation and code improvements and register allocation precedes most code improvements. <p> For the sake of brevity, this chapter does not discuss the portions of llef that were taken from vpo and remain relatively unchanged. Details concerning the instruction selection and common subexpression elimination code improvement phases are omitted because they were described in a previous document <ref> [BENI89] </ref>. 5.1 Overview The front-end of llef consists of a pcc-based [JOHN78b] retargetable front-end which transforms traditional C [KERN78] into a high-level, stack-based intermediate representation and a machine-specific code generator which transforms this high-level code into same low-level, register transfer-based representation used by vpo. <p> transformations were performed on the code and that there may be new opportunities to apply additional transformations. 72 5.2 Global-scope instruction selection The global-scope instruction selection algorithm used by vpo calculates the reaching definitions dataow information for each function in order to properly link logically adjacent instructions across basic blocks <ref> [BENI89] </ref>. <p> If the assignment is an instruction, then a global combiner link is set provided that the reference is the only possible use of the value. These two conditions satisfy all of the requirements for setting safe global combiner links <ref> [BENI89] </ref>. The SSA variant of the global combiner link phase was compared against the traditional reaching definition version using two large functions. The first function was a 1500 line parser for a compiler front-end.
Reference: [BENI91a] <author> M. E. Benitez, </author> <title> Register Transfer Standard, </title> <institution> Research Memorandum, University of Virginia, </institution> <address> Charlottesville, VA, </address> <month> March </month> <year> 1991. </year>
Reference-contexts: A standard encoding notation has been defined for this purpose which encodes register, local identifiers and global identifiers into two character tokens using an extended 8-bit ASCII field <ref> [BENI91a] </ref>. 195
Reference: [BENI91b] <author> M. E. Benitez and J. W. Davidson, </author> <title> Code Generation for Streaming: an Access/Execute Mechanism, </title> <booktitle> Proceedings of the Fourth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <address> Santa Clara, CA, </address> <month> April </month> <year> 1991, </year> <pages> 132-141. </pages>
Reference-contexts: In addition, recurrence optimization <ref> [BENI91b] </ref>, which eliminates memory references by keeping values that will be used in subsequent loop iterations in registers, is included even though it is an application-specific improvement usually performed only by compilers specializing in compiling either scientific or digital processing codes.
Reference: [BENI94] <author> M. E. Benitez and J. W. Davidson, </author> <title> The Advantages of Machine-Dependent Global Optimization, </title> <booktitle> Proceedings of the International Conference on Programming Languages and System Architectures, </booktitle> <address> Zurich, Switzerland, </address> <month> March </month> <year> 1994, </year> <pages> 105-124. </pages>
Reference-contexts: Together, these two factors account for much of the retargetability that high-level representations provide. Unfortunately, high-level representations provide the code improvement algorithms with little control over all but the most common architectural features, thereby limiting the effectiveness of code improvement transformations <ref> [BENI94] </ref>.
Reference: [BERN86] <author> R. Bernstein, </author> <title> Multiplication by Integer Constants, </title> <journal> SoftwarePractice and Experience, </journal> <volume> 16(7), </volume> <month> July </month> <year> 1986, </year> <pages> 641-652. </pages>
Reference: [BRAD91] <author> D. G. Bradlee, R. R. Henry and S. J. Eggers, </author> <title> The Marion System for Retargetable Instruction Scheduling, </title> <booktitle> Proceedings of the SIGPLAN Notices 1989 Symposium on Programming Language Design and Implementation, </booktitle> <address> Toronto, Ontario, </address> <month> June </month> <year> 1991, </year> <pages> 229-240. </pages>
Reference-contexts: This suggests that the techniques used to provide target machine information and handle unique architectural features in gcc may not be as general or as retargetable as they could be. 2.5.6 Marion Marion is a code generation system for pipelined RISC architectures that require quality instruction scheduling <ref> [BRAD91] </ref>. Marion integrates instruction scheduling, code generation and register allocation into a single phase. The instruction scheduler performs two separate instruction scheduling passes: the first to obtain schedule cost estimates and a second to produce a final schedule.
Reference: [BRIG89] <author> P. Briggs, K. D. Cooper, K. Kennedy and L. Torczon, </author> <title> Coloring Heuristics for Register Allocation, </title> <booktitle> Proceedings of the SIGPLAN Notices 1989 Symposium on Programming Language Design and Implementation, </booktitle> <address> Portland, OR, </address> <month> June </month> <year> 1989, </year> <pages> 275-284. </pages>
Reference-contexts: Because this process can create spill code, it is essential to provide the allocator with a suitable strategy for coloring and demoting interference graph nodes. The popularity of coloring paradigms has produced a plethora of coloring heuristics and spill strategies <ref> [CHAI81, CHOW83, BRIG89, GUPT89, CALL91] </ref>. One useful aspect of register coloring is that architecture-specific register requirements can be incorporated into the interference graph. For example, if a pseudo-register value is live across an external function call, it can be connected to nodes representing the volatile registers. <p> Since the development of the PL.8 compiler, much effort has been devoted to improving spill mechanisms. Some of the latest advances have been reported by Gupta, Soffa and Steele [GUPT89], by Briggs et al. <ref> [BRIG89] </ref> and by Callahan and Koblenz [CALL91].
Reference: [CALL91] <author> D. Callahan and B. Koblenz, </author> <title> Register Allocation via Hierarchical Graph Coloring, </title> <booktitle> Proceedings of the SIGPLAN Notices 1991 Symposium on Programming Language Design and Implementation, </booktitle> <address> Toronto, Ontario, </address> <month> June </month> <year> 1991, </year> <pages> 192-203. </pages>
Reference-contexts: Because this process can create spill code, it is essential to provide the allocator with a suitable strategy for coloring and demoting interference graph nodes. The popularity of coloring paradigms has produced a plethora of coloring heuristics and spill strategies <ref> [CHAI81, CHOW83, BRIG89, GUPT89, CALL91] </ref>. One useful aspect of register coloring is that architecture-specific register requirements can be incorporated into the interference graph. For example, if a pseudo-register value is live across an external function call, it can be connected to nodes representing the volatile registers. <p> Since the development of the PL.8 compiler, much effort has been devoted to improving spill mechanisms. Some of the latest advances have been reported by Gupta, Soffa and Steele [GUPT89], by Briggs et al. [BRIG89] and by Callahan and Koblenz <ref> [CALL91] </ref>. Neither improved spill mechanisms or coloring heuristics, however, can fully compensate for the over-optimization which prevents PL.8 style register allocation from producing high-quality code on machines with few registers. 3.4.5 UOPT UOPT is a U-code optimizer developed by Chow which uses a priority-based coloring register assigner [CHOW83].
Reference: [CHAI81] <author> G. J. Chaitin, M. A. Auslander, A. K. Chandra, J. Cocke, M. E. Hopkins and P. W. Markstein, </author> <title> Register allocation via Coloring, </title> <journal> Computer Languages, </journal> <volume> 6(1), </volume> <month> January </month> <year> 1981, </year> <pages> 47-57. </pages>
Reference-contexts: These registers are specified by the calling convention. Length of function (in instructions) Allocable registers v 1 v 3 v 5 v 2 v 4 34 3.3.2.2 Coloring Register assignment can be reduced to a graph coloring problem <ref> [CHAI81] </ref>. To perform register assignment via coloring, the assigner builds an interference graph where the nodes represent pseudo-register values and the edges connect values whose lifetimes overlap. An interference graph is shown in Figure 10. interference graph for this packing is given in Figure 10 (b). <p> Because this process can create spill code, it is essential to provide the allocator with a suitable strategy for coloring and demoting interference graph nodes. The popularity of coloring paradigms has produced a plethora of coloring heuristics and spill strategies <ref> [CHAI81, CHOW83, BRIG89, GUPT89, CALL91] </ref>. One useful aspect of register coloring is that architecture-specific register requirements can be incorporated into the interference graph. For example, if a pseudo-register value is live across an external function call, it can be connected to nodes representing the volatile registers.
Reference: [CHOW83] <author> F. C. Chow, </author> <title> A Portable Machine-Independent Global OptimizerDesign and Measurements, </title> <type> Ph.D. Dissertation, </type> <institution> Stanford University, Stanford, </institution> <address> CA, </address> <month> December </month> <year> 1983. </year> <month> 196 </month>
Reference-contexts: The choice of an intermediate representation seriously affects the retargetability of an optimizing compiler <ref> [CHOW83] </ref>. The types of intermediate representations have been used in optimizing compilers are fixed, high-level intermediate representations and low-level representations. Because fixed, high-level representations are independent of the target architecture, they require no modification to retarget. <p> Because this process can create spill code, it is essential to provide the allocator with a suitable strategy for coloring and demoting interference graph nodes. The popularity of coloring paradigms has produced a plethora of coloring heuristics and spill strategies <ref> [CHAI81, CHOW83, BRIG89, GUPT89, CALL91] </ref>. One useful aspect of register coloring is that architecture-specific register requirements can be incorporated into the interference graph. For example, if a pseudo-register value is live across an external function call, it can be connected to nodes representing the volatile registers. <p> Neither improved spill mechanisms or coloring heuristics, however, can fully compensate for the over-optimization which prevents PL.8 style register allocation from producing high-quality code on machines with few registers. 3.4.5 UOPT UOPT is a U-code optimizer developed by Chow which uses a priority-based coloring register assigner <ref> [CHOW83] </ref>. Like Sites storage allocator, UOPTs register allocator is invoked just prior to code generation. Unlike the PL.8 compiler, UOPTs code improvement phases create pseudo-variables instead or pseudo-registers so that code can be generated even if the allocator is bypassed.
Reference: [CHOW88] <author> F. C. Chow, </author> <title> Minimizing Register Usage Penalty at Procedure Calls, </title> <booktitle> Proceedings of the SIGPLAN Notices 1988 Symposium on Programming Language Design and Implementation, </booktitle> <address> Atlanta, GA, </address> <month> June </month> <year> 1988, </year> <pages> 85-94. </pages>
Reference-contexts: live_at_block_exit: TRUE used_first: FALSE is_set: TRUE range_start: 7 range_end: register_conflicts: w [14],w [30] node_conflicts: benefit: b 93 the function, a register might needlessly be reserved to contain the value of the argument over a large portion of the function. llef uses an approach is similar to Chows shrink wrapping technique <ref> [CHOW88] </ref> to determine the where the value of the argument can be loaded in order to reduce the lifetime of the argument as much as possible.
Reference: [CYTR91] <author> R. Cytron, J. Ferrante, B. K. Rosen, M. N. Wegman and F. K. Zadeck, </author> <title> Efficiently Computing Static Single Assignment Form and the Control Dependence Graph, </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 13(4), </volume> <month> October </month> <year> 1991, </year> <pages> 451-490. </pages>
Reference-contexts: The purpose for calculating the reaching definition information is to determine how many different assignments can possibly reach each register reference. A recent development in data structures called the Static Single Assignment (SSA) form, can also be used to determine if how many different definitions reach a particular reference <ref> [CYTR91] </ref>. Although the algorithms used to construct the SSA form are more difficult to implement and understand than the iterative algorithm used to calculate reaching definitions, their storage space and execution time complexities are practically linear with respect to the size of the function.
Reference: [DAVI80] <author> J. W. Davidson and C. W. Fraser, </author> <title> The Design and Application of a Retargetable Peephole Optimizer, </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 2(2), </volume> <month> April </month> <year> 1980, </year> <pages> 191-202. </pages>
Reference-contexts: This strategy complicates the compiler, the intermediate language and the retargeting process. Furthermore, in spite of these measures, ACK-based compilers are unable to produce high-quality RISC code. 2.5.2 PO Davidson and Fraser developed a technique to performs peephole optimization via instruction selection in a retargetable mechanism <ref> [DAVI80] </ref>. This a peephole optimizer based on this technique, along with a common subexpression eliminator and a local-scope register allocator, comprise the retargetable PO optimizing compiler [DAVI84b]. The structure of the PO compiler is shown in Figure 5.
Reference: [DAVI81] <author> J. W. Davidson, </author> <title> Simplifying Code Generation through Peephole Optimization, </title> <type> Ph.D. Dissertation, </type> <institution> University of Arizona, </institution> <address> Tucson, AZ, </address> <month> December </month> <year> 1981. </year>
Reference-contexts: Unlike their high-level counterparts, low-level representations encode the semantics of a wide range of machine instructions. One of the most commonly used notations used to represent low-level code is the register transfer [BELL71]. Register transfers have been successfully used in a number retargetable optimizing compilers including PO <ref> [DAVI81] </ref>, 6 YC [DAVI84b], vpo [BENI89] and gcc [STAL89]. Regardless of the underlying notation, low-level representations allow the code improvement algorithms to operate at the machine level where all of the target machine nuances are exposed and all transformations, including those that exploit specific architectural features, can be performed effectively.
Reference: [DAVI84a] <author> J. W. Davidson and C. W. Fraser, </author> <title> Register Allocation and Exhaustive Peephole Optimization, </title> <journal> SoftwarePractice and Experience, </journal> <volume> 14(9), </volume> <month> September </month> <year> 1984, </year> <pages> 857-865. </pages>
Reference-contexts: POs cacher phase performs local-scope, machine-independent common subexpression elimination. Because all values, including those computed in address calculations, are exposed at the machine-level and assigned to pseudo-register values that are never re-assigned, cacher detects and eliminates all local common subexpressions <ref> [DAVI84a] </ref>. The combiner phase performs instruction selection by merging adjacent register transfers into singletons and consulting a machine description to determine if some instruction on the target machine has the effect described by the combination.
Reference: [DAVI84b] <author> J. W. Davidson and C. W. Fraser, </author> <title> Code Selection through Object Code Optimization, </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 6(4), </volume> <month> October </month> <year> 1984, </year> <pages> 505-526. </pages>
Reference-contexts: One of the most commonly used notations used to represent low-level code is the register transfer [BELL71]. Register transfers have been successfully used in a number retargetable optimizing compilers including PO [DAVI81], 6 YC <ref> [DAVI84b] </ref>, vpo [BENI89] and gcc [STAL89]. Regardless of the underlying notation, low-level representations allow the code improvement algorithms to operate at the machine level where all of the target machine nuances are exposed and all transformations, including those that exploit specific architectural features, can be performed effectively. <p> This a peephole optimizer based on this technique, along with a common subexpression eliminator and a local-scope register allocator, comprise the retargetable PO optimizing compiler <ref> [DAVI84b] </ref>. The structure of the PO compiler is shown in Figure 5. Y Front End Code Expander Cacher Combiner Register Assigner 19 PO was one of the first optimizing compilers to apply code improvement transformations exclusively on a low-level representation of the code. <p> of these opportunities and present the register deprivation measurements taken to gauge the effectiveness of these enhancements. 6.1.1 Common subexpression elimination Code sequences often contain redundant expressions that can be removed by performing common subexpression elimination. llef uses a global variant of the common subexpression elimination technique used in PO <ref> [DAVI84b] </ref>. Unlike PO, however, llef performs local register assignment before common subexpression 139 elimination. The advantage of this approach is that it avoids over-optimization. Its disadvantage is that it fails to eliminate all local common subexpressions. Consider the unassigned code shown in Figure 88. <p> Register transfers have their origins in the Instruction Set Processor (ISP) notation developed by Bell and Newell [BELL71]. The original notation was altered slightly to facilitate its use as a low-level intermediate language. The register transfer notation described here is similar to that presented by Davidson for PO <ref> [DAVI84b] </ref>. A register transfer describes the effect of a machine instruction. Most machine operations can be defined in terms of the data movement that they effect. For this reason, the register transfer notation is particularly suited to describing data transfers between registers and memory locations.
Reference: [DAVI85] <author> J. W. Davidson, </author> <title> Simple Machine Description Grammars, </title> <institution> Computer Science Technical Report 85-22, University of Virginia, </institution> <address> Charlottesville, VA, </address> <month> November </month> <year> 1985. </year>
Reference: [DAVI86] <author> J. W. Davidson, </author> <title> A Retargetable Instruction Reorganizer, </title> <booktitle> Proceedings of the SIGPLAN Notices 1986 Symposium on Programming Language Design and Implementation, </booktitle> <address> Palo Alto, CA, </address> <month> June </month> <year> 1986, </year> <pages> 234-241. </pages>
Reference-contexts: Similarly, optimal evaluation orders cannot be produced on representations that obscure the register requirements of the machine code <ref> [MCKU84, DAVI86] </ref>. The factors that limit the effectiveness of code improvements transformations that operate on high-level representations can be avoided by using low-level representations. Unlike their high-level counterparts, low-level representations encode the semantics of a wide range of machine instructions. <p> The technique, however, was modified by Davidson to work on, PO <ref> [DAVI86] </ref>, and has been further extended to operate within llef. The following expression is used to illustrate the algorithm that determines and produces optimal evaluation orders in llef: a = (a + b) * (c * d + e * f) prior to local register allocation.
Reference: [DAVI88] <author> J. W. Davidson and A. M. Holler, </author> <title> A Study of a C Function Inliner, </title> <journal> SoftwarePractice and Experience, </journal> <volume> 18(8), </volume> <month> August </month> <year> 1988, </year> <pages> 775-790. </pages>
Reference: [DAVI91] <author> J. W. Davidson and D. B. Whalley, </author> <title> Methods for Saving and Restoring Register Values across Function Calls, </title> <journal> SoftwarePractice and Experience, </journal> <volume> 21(2), </volume> <month> February </month> <year> 1991, </year> <pages> 149-165. </pages>
Reference-contexts: effects of register deprivation in general, the integer to oating-point register ratio is maintained as close to its original value as possible. 4.5.3 Calling convention Because the relative size of the volatile register partition prescribed by the calling convention has a significant impact on the quality of the object code <ref> [DAVI91] </ref>, the register deprivation measurements strive to maintain a volatile to non-volatile register ratio that is as close to the original ratio as possible. Many calling conventions pass actual parameter values in a subset of the volatile register set.
Reference: [DUNL78] <author> D. D. Dunlop and J. C. Knight, </author> <title> Register Allocation in the SL/1 Compiler, </title> <booktitle> Proceedings of the 1978 LASL Workshop on Vector and Parallel Processors, </booktitle> <address> Los Alamos, New Mexico, </address> <month> September </month> <year> 1978, </year> <pages> 205-211. </pages>
Reference-contexts: insight into the register allocation problem. 3.4.1 SL/1 The SL/1 compiler was developed for the 256 general-purpose register CDC STAR-100 architecture and features a global-scope register allocation algorithm that uses cost values based on the estimated benefits of assigning values to registers as the basis for making register allocation decisions <ref> [DUNL78] </ref>. Costs are determined by estimating the difference in machine cycles between executing the program with a value assigned to a memory variable and with the value in a register. All values with a positive cost are candidates for register allocation.
Reference: [FRAS92] <author> C. W. Fraser and D. R. Hanson, </author> <title> Simple Register Spilling in a Retargetable Compiler, </title> <journal> SoftwarePractice and Experience, </journal> <volume> 22(1), </volume> <month> January </month> <year> 1992, </year> <pages> 85-99. </pages>
Reference-contexts: Except for cases where all of the registers in a register class are volatile, spills are extremely rare if the target machine provides three or more registers in each register class. Fraser and Hanson show that, with sufficient registers, even simple spill techniques produce good results <ref> [FRAS92] </ref>. The sophistication of the spill mechanism used by llefs local scope register assigner is motivated by the desire to generate high quality code on architectures that provide very few registers.
Reference: [FREI74] <author> R. A. </author> <title> Freiburghouse, Register Allocation Via Usage Counts, </title> <journal> Communications of the Association for Computing Machinery, </journal> <volume> 17(11), </volume> <month> November </month> <year> 1974, </year> <pages> 638-642. </pages>
Reference-contexts: x 2 x 4 7 x 3 x 4 8 x 4 x 6 9 0 0 1 0 0 32 3.3.1.3 Use counts Freiburghouse developed a system for performing local register allocation based on keeping track of the number of times each pseudo-register will be referenced in the future <ref> [FREI74] </ref>. This algorithm requires the first occurrence of each pseudo-register value to indicate how many times the value will be used. This count serves two purposes.
Reference: [GRAH82] <author> S. L. Graham, R. R. Henry, R. A. Schulman, </author> <title> An Experiment in Table Driven Code Generation, </title> <booktitle> Proceedings of the SIGPLAN Notices 1982 Symposium on Compiler Construction, </booktitle> <address> Boston, MA, </address> <month> June </month> <year> 1982, </year> <pages> 32-42. </pages>
Reference-contexts: This allocator is used in a Graham-Glanville-based <ref> [GRAH82] </ref> optimizing compiler. McKusicks framework separates the register set into a dedicated partition and a temporary partition. The dedicated partition is managed exclusively by the global-scope allocator. These registers are used to hold values created by the user and the code improvement transformations.
Reference: [GOOD88] <author> J. R. Goodman and W. C. Hsu, </author> <title> Code Scheduling and Register Allocation in Large Basic Blocks, </title> <booktitle> Proceedings of the 1988 International Conference on Supercomputing, </booktitle> <month> July </month> <year> 1988, </year> <pages> 442-452. </pages>
Reference-contexts: First, the register assignment decisions made by each code improvement algorithms constrain the allocation choices available to subsequent transformations. In compilers that perform code improvements using an infinite set of registers, this problem only occurs while applying low-level code improvements like instruction scheduling <ref> [GOOD88] </ref>. Second, the need to reuse registers complicates the task of determining which values have been previously computed since each individual expression value is no longer associated with a unique pseudo-register. <p> Their results show that the round-robin strategy usually allows better schedules to be produced, although there are cases where the schedules produced while using a traditional allocator outperform those produced with the round-robin allocator <ref> [GOOD88] </ref>. To illustrate how round-robin register allocation enhances the ability of the common subexpression eliminator to improve the code, consider the unassigned fragment of code shown in Figure 106. Instruction 4 of this code fragment computes a redundant subexpression that should be removed by the common subexpression eliminator.
Reference: [GUPT89] <author> R. Gupta, M. L. Soffa and T. Steele, </author> <title> Register Allocation via Clique Separators, </title> <booktitle> Proceedings of the SIGPLAN Notices 1989 Symposium on Programming Language Design and Implementation, </booktitle> <address> Portland, OR, </address> <month> June </month> <year> 1989, </year> <pages> 264-274. </pages>
Reference-contexts: Because this process can create spill code, it is essential to provide the allocator with a suitable strategy for coloring and demoting interference graph nodes. The popularity of coloring paradigms has produced a plethora of coloring heuristics and spill strategies <ref> [CHAI81, CHOW83, BRIG89, GUPT89, CALL91] </ref>. One useful aspect of register coloring is that architecture-specific register requirements can be incorporated into the interference graph. For example, if a pseudo-register value is live across an external function call, it can be connected to nodes representing the volatile registers. <p> Since the development of the PL.8 compiler, much effort has been devoted to improving spill mechanisms. Some of the latest advances have been reported by Gupta, Soffa and Steele <ref> [GUPT89] </ref>, by Briggs et al. [BRIG89] and by Callahan and Koblenz [CALL91].
Reference: [HENN83] <author> J. L. Hennessy and T. R. Gross, </author> <title> Postpass Code Optimization of Pipeline Constraints, </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 5(3), </volume> <month> July </month> <year> 1983, </year> <pages> 422-448. 197 </pages>
Reference-contexts: Unfortunately, high-level representations provide the code improvement algorithms with little control over all but the most common architectural features, thereby limiting the effectiveness of code improvement transformations [BENI94]. These limitations apply not only to code improvements like peephole optimization [MCKE65] and instruction scheduling <ref> [HENN83] </ref>, which exploit specific architectural features, but also to code improvements like loop-invariant code motion [AHO86] and evaluation order determination [SETH70], whose broad applicability has fueled the myth that they can be effectively performed on high-level representations. The fallacy of this assumption is illustrated with a few simple examples. <p> Finally, the architecture-specific code improvements called peephole optimization [MCKE65], instruction scheduling <ref> [HENN83] </ref> and delay slot filling [HENN90] are also included. This dissertation presents newly-developed retargetable algorithms for performing evaluation order determination, loop-invariant code motion, loop strength reduction, induction variable elimination, recurrence optimization, instruction scheduling and delay slot filling on low-level code. <p> One such strategy, suggested by Hennesy and Gross, uses a round-robin allocation technique to cycle through the allocable registers and increase the distance between register reuses <ref> [HENN83] </ref>. Goodman and Hsu compared this approach against a traditional allocator to measure its impact on post-pass instruction scheduling.
Reference: [HENN90] <author> J. L. Hennessy and D. A. Patterson, </author> <title> Computer Architecture, A Quantitative Approach, </title> <publisher> Morgan Kaufmann Publishers, </publisher> <address> San Mateo, CA, </address> <year> 1990. </year>
Reference-contexts: Finally, the architecture-specific code improvements called peephole optimization [MCKE65], instruction scheduling [HENN83] and delay slot filling <ref> [HENN90] </ref> are also included. This dissertation presents newly-developed retargetable algorithms for performing evaluation order determination, loop-invariant code motion, loop strength reduction, induction variable elimination, recurrence optimization, instruction scheduling and delay slot filling on low-level code. <p> Good register allocation is essential to producing high-quality code because the allocator affects the ability of the code generator to produce efficient code and of the code improvements to perform effective transformations. While register allocation has often been considered a code improvement <ref> [HENN90] </ref>, it is presented here not as a code improvement, but as a task whose importance in an optimizing compiler rivals that of code generation and actual code improvements. 3.1 The allocation process Register allocation is one of the most studied yet least understood compilation tasks. <p> This process eliminates the impact that the size of the allocable register set has on the components that are not being measured, regardless of whether it is beneficial or detrimental. The following formula, taken from Hennessy and Patterson <ref> [HENN90] </ref>, is used to obtain the percent improvement of the initial optimized trial over the base trial: sample trials. These improvement values indicate that code improvements produce only a slight reduction in the number of instructions executed by the benchmark programs when the minimum number of allocable registers is used. <p> This condition is called a data hazard, and is just one of the various types of hazards that a pipelined processor can encounter <ref> [HENN90] </ref>. Some pipeline processors contain hardware to detect data hazards and stall the processor until all of the requested operands are available. This action is called a pipeline stall. <p> The reason that these locations are less desirable is that they only improve the performance of the code if the branch is taken or not taken, depending on the source of the instruction. These techniques have been presented in the literature <ref> [HENN90] </ref>, and their corresponding implementations in llef are simple extensions of the techniques presented in this section.
Reference: [HORW66] <author> L.P. Horwitz, R. M. Karp, R. E. Miller and S. Winograd, </author> <title> Index Register Allocation, </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> 13(1), </volume> <month> January </month> <year> 1966, </year> <pages> 44-61. </pages>
Reference-contexts: The following sections survey the most commonly used local register allocation techniques. 3.3.1.1 Minimal cost path The register allocation strategy developed for the pioneering FORTRAN I compiler <ref> [HORW66] </ref> is based on finding the minimal cost path in a directed acyclic graph (DAG).
Reference: [JOHN78a] <author> S. C. Johnson, </author> <title> Yacc: Yet Another Compiler-Compiler, Unix Programmers Manual, </title> <journal> 2B, </journal> <volume> 19, </volume> <month> July </month> <year> 1978, </year> <pages> 1-34. </pages>
Reference-contexts: on low-level code is an effective way to produce high-quality machine code. 2.5.4 VPO The experience gained from the PO compiler was used to develop vpo [BENI89], which differs from its predecessor the following significant areas: it uses a C [KERN78] front end, the instruction recognizer uses a yacc-produced parser <ref> [JOHN78a] </ref>, it performs global-scope register allocation and code improvements and register allocation precedes most code improvements. Like PO, vpo uses a code expander to generate naive object code in the form of register transfers (RTLs) from the abstract intersection machine code emitted by the semantic analysis phase of the front-end.
Reference: [JOHN78b] <author> S. C. Johnson, </author> <title> A Portable Compiler: Theory and Practice, </title> <booktitle> Proceedings of the Fifth Association for Computing Machinery Symposium on Principles of Programming Language, </booktitle> <address> Tucson, AZ, </address> <month> January </month> <year> 1978, </year> <pages> 97-104. </pages>
Reference-contexts: Details concerning the instruction selection and common subexpression elimination code improvement phases are omitted because they were described in a previous document [BENI89]. 5.1 Overview The front-end of llef consists of a pcc-based <ref> [JOHN78b] </ref> retargetable front-end which transforms traditional C [KERN78] into a high-level, stack-based intermediate representation and a machine-specific code generator which transforms this high-level code into same low-level, register transfer-based representation used by vpo.
Reference: [JOHN86] <author> M. S. Johnson and T. C. Miller, </author> <title> Effectiveness of a Machine-Level, Global Optimizer, </title> <booktitle> Proceedings of the SIGPLAN Notices 1986 Symposium on Programming Language Design and Implementation, </booktitle> <address> Palo Alto, CA, </address> <month> June </month> <year> 1986, </year> <pages> 99-108. </pages>
Reference-contexts: by performing even a few simple code improvements at the machine level, and that it is possible to structure such a system so that it is highly retargetable. 2.5.3 HP Precision Architecture Shortly after the development of PO, a low-level, global-scope optimizing compiler was developed for the HP Precision Architecture <ref> [JOHN86] </ref>. One of the most notable features of this compiler is that most code improvement transformations are performed after code generation to fully exploit the processor pipeline, addressing modes and loop control instructions provided by the target architecture.
Reference: [KANE87] <author> G. Kane, </author> <title> MIPS RISC Architecture, </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1987. </year>
Reference-contexts: Figure 18 shows how the number of allocable registers affects the number of instructions executed by the object code produced by the vpo system presented in Section 2.5.4 for the Motorola 68020 [MOTO85] and the MIPS R3000 <ref> [KANE87] </ref> processors. These results show that vpo reduces the number of instructions executed by only a modest amount even when many registers are available. The reason for this is that vpo performs few global-scope code improvements. <p> Since the process of collecting register deprivation measurements can be lengthy and repetitive, it is most useful if it can be automated. The following sections describe how register deprivation mechanism was implemented in llef. The compilers for the MIPS R3000 <ref> [KANE87] </ref> and the Motorola 68020 [MOTO85] processors were instrumented in order to measure their performance.
Reference: [KERN78] <author> B. W. Kernighan and D. M. Ritchie, </author> <title> The C Programming Language, </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1978. </year>
Reference-contexts: These results suggest that performing code improvement transformations on low-level code is an effective way to produce high-quality machine code. 2.5.4 VPO The experience gained from the PO compiler was used to develop vpo [BENI89], which differs from its predecessor the following significant areas: it uses a C <ref> [KERN78] </ref> front end, the instruction recognizer uses a yacc-produced parser [JOHN78a], it performs global-scope register allocation and code improvements and register allocation precedes most code improvements. <p> Details concerning the instruction selection and common subexpression elimination code improvement phases are omitted because they were described in a previous document [BENI89]. 5.1 Overview The front-end of llef consists of a pcc-based [JOHN78b] retargetable front-end which transforms traditional C <ref> [KERN78] </ref> into a high-level, stack-based intermediate representation and a machine-specific code generator which transforms this high-level code into same low-level, register transfer-based representation used by vpo.
Reference: [LAM88] <author> M. S. Lam, </author> <title> Software Pipelining: An Effective Scheduling Technique for VLIW Machines, </title> <booktitle> Proceedings of the SIGPLAN Notices 1988 Symposium on Programming Language Design and Implementation, </booktitle> <address> Atlanta, GA, </address> <month> June </month> <year> 1988, </year> <pages> 318-328. </pages>
Reference: [LEVE80] <author> B. W. Leverett, R. G. Cattell, S. O. Hobbs, J. M. Newcomer, A. H. Reiner, B. R. Schatz and W. A. Wulf, </author> <title> An Overview of the Production-Quality Compiler-Compiler Project, </title> <journal> IEEE Computer, </journal> <volume> 13(8), </volume> <month> August </month> <year> 1980, </year> <pages> 38-49. </pages>
Reference-contexts: Since packing priorities are based on U-code references, these discrepancies may cause the storage allocator to make poor decisions. 3.4.3 PQCC Unlike the U-code storage allocator, the retargetable register allocator developed by Bruce Leverett for the Production-Quality Compiler-Compiler project <ref> [LEVE80] </ref> operates on a low-level representation and does not require the register set to be partitioned between the optimizer and the code generator [LEVE81].
Reference: [LEVE81] <author> B. W. Leverett, </author> <title> Register Allocation in Optimizing Compilers, </title> <type> Ph.D. Dissertation, </type> <institution> Carnegie-Mellon University, Pittsburg, </institution> <address> PA, </address> <month> February </month> <year> 1981. </year>
Reference-contexts: the storage allocator to make poor decisions. 3.4.3 PQCC Unlike the U-code storage allocator, the retargetable register allocator developed by Bruce Leverett for the Production-Quality Compiler-Compiler project [LEVE80] operates on a low-level representation and does not require the register set to be partitioned between the optimizer and the code generator <ref> [LEVE81] </ref>. Leveretts allocator integrates the task of assigning registers to the temporary values created by the code generator and the longer-lived values created by the user and the code improvement transformations.
Reference: [MCKE65] <author> W. M. McKeeman, </author> <title> Peephole Optimization, </title> <journal> Communications of the Association for Computing Machinery, </journal> <volume> 8(7), </volume> <month> July </month> <year> 1965, </year> <pages> 443-444. </pages>
Reference-contexts: Unfortunately, high-level representations provide the code improvement algorithms with little control over all but the most common architectural features, thereby limiting the effectiveness of code improvement transformations [BENI94]. These limitations apply not only to code improvements like peephole optimization <ref> [MCKE65] </ref> and instruction scheduling [HENN83], which exploit specific architectural features, but also to code improvements like loop-invariant code motion [AHO86] and evaluation order determination [SETH70], whose broad applicability has fueled the myth that they can be effectively performed on high-level representations. <p> Finally, the architecture-specific code improvements called peephole optimization <ref> [MCKE65] </ref>, instruction scheduling [HENN83] and delay slot filling [HENN90] are also included. This dissertation presents newly-developed retargetable algorithms for performing evaluation order determination, loop-invariant code motion, loop strength reduction, induction variable elimination, recurrence optimization, instruction scheduling and delay slot filling on low-level code.
Reference: [MCKU84] <author> M. K. McKusick, </author> <title> Register Allocation and Data Conversion in Machine Independent Code Generators, </title> <type> Ph.D. Dissertation, </type> <institution> University of California, Berkeley, </institution> <address> CA, </address> <month> December </month> <year> 1984. </year>
Reference-contexts: Similarly, optimal evaluation orders cannot be produced on representations that obscure the register requirements of the machine code <ref> [MCKU84, DAVI86] </ref>. The factors that limit the effectiveness of code improvements transformations that operate on high-level representations can be avoided by using low-level representations. Unlike their high-level counterparts, low-level representations encode the semantics of a wide range of machine instructions. <p> for code generation and from the significant differences between the high-level U-code and the target machine code. 3.4.6 Split allocation McKusick developed a split register allocation approach where global-scope allocation is performed by the code improvement phases of the compiler and local-scope allocation is handled by the code generator 43 <ref> [MCKU84] </ref>. This allocator is used in a Graham-Glanville-based [GRAH82] optimizing compiler. McKusicks framework separates the register set into a dedicated partition and a temporary partition. The dedicated partition is managed exclusively by the global-scope allocator.
Reference: [MOTO85] <author> Motorola, </author> <title> MC68020 32-Bit Microprocessor Users Manual, </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1985. </year>
Reference-contexts: This allocator works on a high-level intermediate representation called U-code <ref> [MOTO85] </ref>. Each pseudo-variable in the intermediate representation is annotated with information describing its type, size and storage requirements. For each pseudo-variable, the storage allocator calculates a priority proportional to the number of references and inversely proportional to the length of it life. <p> Figure 18 shows how the number of allocable registers affects the number of instructions executed by the object code produced by the vpo system presented in Section 2.5.4 for the Motorola 68020 <ref> [MOTO85] </ref> and the MIPS R3000 [KANE87] processors. These results show that vpo reduces the number of instructions executed by only a modest amount even when many registers are available. The reason for this is that vpo performs few global-scope code improvements. <p> Since the process of collecting register deprivation measurements can be lengthy and repetitive, it is most useful if it can be automated. The following sections describe how register deprivation mechanism was implemented in llef. The compilers for the MIPS R3000 [KANE87] and the Motorola 68020 <ref> [MOTO85] </ref> processors were instrumented in order to measure their performance.
Reference: [PERK79] <author> D. R. Perkins and R. L. </author> <title> Sites, Machine-Independent Pascal Code Optimization, </title> <booktitle> Proceedings of the SIGPLAN Notices 1979 Symposium on Programming Language Design and Implementation, </booktitle> <address> Denver, CO, </address> <month> August </month> <year> 1979, </year> <pages> 201-207. </pages>
Reference: [PROE92] <author> T. A. Proebsting and C. N. Fischer, </author> <title> Probabilistic Register Allocation, </title> <booktitle> Proceedings of the SIGPLAN 1992 Symposium on Programming Language Design and Implementation, </booktitle> <address> San Francisco, CA, </address> <month> June </month> <year> 1992, </year> <pages> 300-310. </pages>
Reference-contexts: For example, if a pseudo-register value is live across an external function call, it can be connected to nodes representing the volatile registers. The coloring process will then automatically avoid assigning the pseudo-register to any of the volatile registers. 3.3.2.3 Probabilistic Probabilistic register allocation, developed by Proebsting and Fischer <ref> [PROE92] </ref>, is a hybrid strategy that performs both local and global scope allocation. The local allocation phase computes a set of D probabilities for all of the pseudo-variable uses in a basic block. The global allocation phase uses these D probabilities to direct the allocation process.
Reference: [SETH70] <author> R. Sethi and J. D. Ullman, </author> <title> The Generation of Optimal Code for Arithmetic Expressions, </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> 17(4), </volume> <month> October </month> <year> 1970, </year> <pages> 715-728. </pages>
Reference-contexts: These limitations apply not only to code improvements like peephole optimization [MCKE65] and instruction scheduling [HENN83], which exploit specific architectural features, but also to code improvements like loop-invariant code motion [AHO86] and evaluation order determination <ref> [SETH70] </ref>, whose broad applicability has fueled the myth that they can be effectively performed on high-level representations. The fallacy of this assumption is illustrated with a few simple examples. <p> A well-known technique for minimizing the number of temporary values required to compute an arbitrary arithmetic expression is presented in the Sethi and Ullman text <ref> [SETH70] </ref>.
Reference: [SITE79] <author> R. L. </author> <title> Sites, Machine-Independent Register Allocation, </title> <booktitle> Proceedings of the SIGPLAN Notices 1979 Symposium on Programming Language Design and Implementation, </booktitle> <address> Denver, CO, </address> <month> August </month> <year> 1979, </year> <pages> 221-225. </pages>
Reference-contexts: Finally, they noted that interactions between register allocation, code generation and instruction scheduling complicate the process of finding optimal instruction schedules. 3.4.2 U-code Sites developed a retargetable compiler incorporating a register and storage allocator that uses an abstract definition of the storage hierarchy on the target architecture <ref> [SITE79] </ref>. This allocator works on a high-level intermediate representation called U-code [MOTO85]. Each pseudo-variable in the intermediate representation is annotated with information describing its type, size and storage requirements.
Reference: [STAL89] <author> R. M. Stallman, </author> <title> Using and Porting GNU CC, Free Software Foundation, </title> <address> Cambridge, MA, </address> <year> 1989. </year> <month> 198 </month>
Reference-contexts: For this strategy to work, however, it is essential for the compiler to compare favorably against the other compilers available for that architecture. The current popularity of gcc <ref> [STAL89] </ref>, for example, is due not only to the large number of systems for which it can produce code, but also to its low cost and the reasonable quality of the code that it produces. <p> One of the most commonly used notations used to represent low-level code is the register transfer [BELL71]. Register transfers have been successfully used in a number retargetable optimizing compilers including PO [DAVI81], 6 YC [DAVI84b], vpo [BENI89] and gcc <ref> [STAL89] </ref>. Regardless of the underlying notation, low-level representations allow the code improvement algorithms to operate at the machine level where all of the target machine nuances are exposed and all transformations, including those that exploit specific architectural features, can be performed effectively. <p> The amount of time required to retarget vpo depends on the complexity of the target architecture and can range from two weeks to a month. 2.5.5 GCC Like vpo, the GNU C compiler (gcc) <ref> [STAL89] </ref>, performs code improvements exclusively on machine code represented using register transfers. Currently, gcc provides front-ends for C, C++ and Objective C and its back-end supports 23 different target architectures. Register transfers are generated from the front-ends abstract expression trees using machine-specific templates.
Reference: [STEE61] <author> T. B. Steel, </author> <title> A first version of UNCOL, </title> <booktitle> Western Joint Computer Conference Proceedings, </booktitle> <month> May </month> <year> 1961, </year> <pages> 371-378. </pages>
Reference-contexts: Like many modern retargetable compilers, ACK is based on the principle that a single, universal intermediate language, called an UNCOL <ref> [STEE61] </ref>, allows N languages to be made available on M different architectures with only N front-ends plus M back-ends instead of MN separate compilers.
Reference: [SUNM87] <author> Sun Microsystems, </author> <title> The SPARC Architecture Manual, </title> <type> Version 7, </type> <institution> Sun Microsystems Corporation, Mountain View, </institution> <address> CA, </address> <year> 1987. </year>
Reference-contexts: the register description is that it replaces roughly 300 lines of complex, architecture-dependent C source code with about 40 lines of register description text. 76 This approach simplifies the retargeting process and encourages experimentation with the calling convention and the order in which the target machines registers should be assigned. <ref> [SUNM87] </ref>. The first line of the description declares the basic assignment types. These types are used to denote the order in which registers are assigned and the constraints that govern their use. <p> For example, the save instruction on the SUN SPARC <ref> [SUNM87] </ref>, which makes a new register window available, is represented by: w [14]=SV [w [14]+128]; In this example, the actual impact of the save instruction on the target machine is not clearly defined, but the register transfer is unique enough to distinguish it from any other instruction on the SPARC.
Reference: [TANE83] <author> A. S. Tanebaum, H. V. Staveren, E. G. Keizer and J. W. Stevenson, </author> <title> A Practical Tool Kit for Making Portable Compilers, </title> <journal> Communications of the Association for Computing Machinery, </journal> <volume> 26(9), </volume> <month> September </month> <year> 1983, </year> <pages> 654-660. </pages>
Reference-contexts: These sections focus primarily on the overall structure of each compiler, the nature of the intermediate language on which the bulk of the code improvements are applied and the techniques used to minimize the interactions between the various code improvement phases. 2.5.1 Amsterdam Compiler Kit The Amsterdam Compiler Kit (ACK) <ref> [TANE83] </ref> is a set of programs that simplify the task of developing a compiler.
Reference: [WALL86] <author> D. W. Wall, </author> <title> Global Register Allocation at Link Time, </title> <booktitle> Proceedings of the SIGPLAN Notices 1986 Symposium on Programming Language Design and Implementation, </booktitle> <address> Palo Alto, CA, </address> <month> June </month> <year> 1986, </year> <pages> 264-275. </pages>
Reference: [WHAL90] <author> D. B. Whalley, </author> <title> Ease: An Environment for Architecture Study and Experimentation, </title> <type> Ph.D. Dissertation, </type> <institution> University of Virginia, </institution> <address> Charlottesville, VA, </address> <month> May </month> <year> 1990. </year>
Reference-contexts: These processors were chosen to ensure that both RISC and CISC systems, which place significantly different demands on the compiler, are represented. 4.5.1 Measurements The object code produced by llef is instrumented to determine the number of instructions and memory references executed using ease <ref> [WHAL90] </ref>. When ease is employed, the object code produced by the compiler is instrumented with execution counters. After the instrumented code executes, the values of these counters are written to a file along with instruction information for each basic block.
Reference: [WOLF91] <author> M. E. Wolf and M. S. Lam, </author> <title> A Data Locality Optimizing Algorithm, </title> <booktitle> Proceedings of the SIGPLAN Notices 1991 Symposium on Programming Language Design and Implementation, </booktitle> <address> Toronto, Ontario, </address> <month> June </month> <year> 1991, </year> <pages> 30-44. </pages>
References-found: 57

