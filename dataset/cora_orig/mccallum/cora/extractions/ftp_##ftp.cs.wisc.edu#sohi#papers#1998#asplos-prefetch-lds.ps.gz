URL: ftp://ftp.cs.wisc.edu/sohi/papers/1998/asplos-prefetch-lds.ps.gz
Refering-URL: http://www.cs.wisc.edu/mscalar/publications.html
Root-URL: http://www.cs.wisc.edu
Email: -amir, moshovos, sohi-@cs.wisc.edu  
Title: Dependence Based Prefetching for Linked Data Structures  
Author: Amir Roth, Andreas Moshovos and Gurindar S. Sohi 
Address: 1210 W. Dayton St. Madison, WI 53706  
Affiliation: Computer Sciences Department University of Wisconsin, Madison  
Abstract: We introduce a dynamic scheme that captures the access patterns of linked data structures and can be used to predict future accesses with high accuracy. Our technique exploits the dependence relationships that exist between loads that produce addresses and loads that consume these addresses. By identifying producer-consumer pairs, we construct a compact internal representation for the associated structure and its traversal. To achieve a prefetching effect, a small prefetch engine speculatively traverses this representation ahead of the executing program. Dependence-based prefetching achieves speedups of up to 25% on a suite of pointer-intensive programs. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Baer and T. Chen. </author> <title> An effective on-chip preloading scheme to reduce data access penalty. </title> <booktitle> In Proceedings of the 1991 Conference on Supercomputing, </booktitle> <pages> pages 176186, </pages> <year> 1991. </year>
Reference: [2] <author> D. Burger, T. Austin, and S. Bennett. </author> <title> Evaluating future microprocessors: The simplescalar toolset. </title> <type> Technical Report CS-TR-96-1308, </type> <institution> University of Wisconsin-Madison, </institution> <month> Jul. </month> <year> 1996. </year>
Reference-contexts: Finally, the suggested input sets for some benchmarks were changed to produce longer execution samples. For our simulations, we use the SimpleScalar simulator <ref> [2] </ref>. We model a 4-way superscalar, out-of-order processor with a conventional five stage pipeline that allows a maximum of 32 in-ight instructions.
Reference: [3] <author> T. Chen and J. Baer. </author> <title> A performance study of software and hardware prefetching techniques. </title> <booktitle> In Proceedings of the 21st Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 223232, </pages> <month> Apr. </month> <year> 1994. </year>
Reference-contexts: Finally, they require knowledge of the cache parameters. Dependence-based prefetch-ing will mask capacity misses when other work is available, and incurs no explicit overhead. A similar volume of research has been done in hardware prefetch-ing <ref> [3] </ref>, and dynamic techniques for address prediction [7]. Most of these, such as stream buffers [9], reference prediction table (RPT)[4] and the subsequent Tango [19] analyze address sequences for single instructions arithmetically, and are designed to deal primarily with strided access patterns.
Reference: [4] <author> T. Chen and J. Baer. </author> <title> Effective hardware based data prefetch-ing for high performance processors. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 44:609623, </volume> <month> May. </month> <year> 1995. </year>
Reference: [5] <author> T. Chilimbi, J. Larus, and M. Hill. </author> <title> Improving pointer-based codes through cache-concious data placement. </title> <type> Technical Report CS-TR-98-1365, </type> <institution> University of Wisconsin, Madison, </institution> <month> Mar. </month> <year> 1998. </year>
Reference-contexts: bar) and all loads (right bar). (b) Normalized average latency for pointer loads (left, gray) and all loads (right, black). usage increases: first level data cache (lt gray), second level cache (dk gray) and main memory (black). (a) Another class of software solutions to this problem utilizes cache--conscious data placement <ref> [5] </ref>, the runtime allocation or reorganization of LDS nodes. Clustering techniques pack adjacent LDS nodes into a single (if possible) or consecutive cache lines and improve the spatial locality and arithmetic regularity of LDS access. Coloring techniques eliminate conicts that occur in common traversals.
Reference: [6] <author> G. Chrysos and J. Emer. </author> <title> Memory dependence prediction using store sets. </title> <booktitle> In Proceedings of the 25th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 142153, </pages> <month> Jun. </month> <year> 1998. </year>
Reference-contexts: Dependence-based prefetching can capture and prefetch all pointer loads. However, it has a potentially higher implementation cost. The use of data dependence between instructions as an information primitive and unit of prediction was introduced by Moshovos, Breach, Vijaykumar and Sohi [15], and later refined by Chrysos and Emer <ref> [6] </ref>. In the initial work, dependence prediction was used to synchronize loads, avoiding misspeculation due to unresolved dependences. Tyson and Austin [23] and Moshovos and Sohi [16] broadened the scope of use of dependence information.
Reference: [7] <author> J. Gonzalez and A. Gonzalez. </author> <title> Speculative execution via address prediction and data prefetching. </title> <booktitle> In Proceedings of the 11th International Conference on Supercomputing, </booktitle> <pages> pages 196203, </pages> <month> Jun. </month> <year> 1997. </year>
Reference-contexts: Finally, they require knowledge of the cache parameters. Dependence-based prefetch-ing will mask capacity misses when other work is available, and incurs no explicit overhead. A similar volume of research has been done in hardware prefetch-ing [3], and dynamic techniques for address prediction <ref> [7] </ref>. Most of these, such as stream buffers [9], reference prediction table (RPT)[4] and the subsequent Tango [19] analyze address sequences for single instructions arithmetically, and are designed to deal primarily with strided access patterns.
Reference: [8] <author> D. Joseph and D. Grunwald. </author> <title> Prefetching using markov predictors. </title> <booktitle> In Proceedings of the 24th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 252263, </pages> <month> Jun. </month> <year> 1997. </year>
Reference-contexts: Most of these, such as stream buffers [9], reference prediction table (RPT)[4] and the subsequent Tango [19] analyze address sequences for single instructions arithmetically, and are designed to deal primarily with strided access patterns. Joseph and Grun-wald <ref> [8] </ref> describe Markov predictors which represent cache miss sequences in the form of a probabilistic transition table. Markov predictors are capable of capturing complex patterns, but are nonetheless address based, and require storage proportional to the number of distinct entries in the miss stream.
Reference: [9] <author> N. Jouppi. </author> <title> Improving direct-mapped cache performance by the addition of a small fully-associative cache and prefetch buffers. </title> <booktitle> In Proceedings of the 17th International Symposium on Computer Architecture, </booktitle> <pages> pages 364373, </pages> <month> Jul. </month> <year> 1990. </year>
Reference-contexts: Dependence-based prefetch-ing will mask capacity misses when other work is available, and incurs no explicit overhead. A similar volume of research has been done in hardware prefetch-ing [3], and dynamic techniques for address prediction [7]. Most of these, such as stream buffers <ref> [9] </ref>, reference prediction table (RPT)[4] and the subsequent Tango [19] analyze address sequences for single instructions arithmetically, and are designed to deal primarily with strided access patterns. Joseph and Grun-wald [8] describe Markov predictors which represent cache miss sequences in the form of a probabilistic transition table.
Reference: [10] <author> M. Lam. </author> <title> Software pipelining: an efficient scheduling technique for vliw machines. </title> <booktitle> In Proceedings of the SIGPLAN88 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 318328, </pages> <month> Jun. </month> <year> 1988. </year>
Reference-contexts: However, these fundamentally rely on compile-time knowledge of the data set layout and its interaction with the cache. Linked structures are not often laid out by the compiler, and are incompatible with these optimizations. Software pipelining <ref> [10] </ref> tolerates high latency loads in loops by increasing the distance between the load and instructions that use its value. While not requiring specific layout information, software pipelin-ing relies on the ability to quickly generate addresses for arbitrary structure elements. LDS access undermines this critical requirement.
Reference: [11] <author> M. Lipasti, W. Schmidt, S. Kunkel, and R. Roediger. Spaid: </author> <title> Software prefetching in pointer and call intensive environments. </title> <booktitle> In Proceedings of the 28th Annual International Symposium on Microarchitecture, </booktitle> <pages> pages 231236, </pages> <month> Nov. </month> <year> 1995. </year>
Reference: [12] <author> C.-K. Luk and T. Mowry. </author> <title> Compiler based prefetching for recursive data structures. </title> <booktitle> In Proceedings of the 7th International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 222233, </pages> <month> Oct. </month> <year> 1996. </year>
Reference-contexts: We use this set of programs as it had been previously used to evaluate compiler prefetching algorithms <ref> [12] </ref>. A summary of the benchmarks, the sizes and types of linked data structures used, input parameters and dynamic instruction counts is shown in Table 1. <p> The critical path of this chain and its relationship to the original load greatly limits the scheduling scope of the prefetch, and consequently, the amount of latency that can be hidden. Luk and Mowry <ref> [12] </ref> proposed and evaluated a greedy compiler algorithm for scheduling software prefetches for linked data structures. They showed this scheme to be effective for certain programs, citing instruction overhead and the generation of useless prefetches as performance degradation factors for others. <p> In addition, it provides dynamic detection and suppression of unnecessary prefetches. We expect that this same mechanism can be integrated with a compiler-based prefetch-generation scheme to improve resource consumption. Luk and Mowry <ref> [12] </ref> presented a case for history-pointer prefetch-ing, which augments linked structure nodes with prefetching pointer fields, and data-linearization, in which LDS are programmatically laid out at runtime to allow sequential prefetch machinery to capture their traversal.
Reference: [13] <author> K. McKinley, S. Carr, and C.-W. Tseng. </author> <title> Improving data locality with loop transformations. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 18(4):424453, </volume> <month> Jul. </month> <year> 1996. </year>
Reference-contexts: These figures show that even in the case of serialized latencies, memory bandwidth can be readily traded off for latency. 6 Related Work Much work has been done in the area of data prefetching, both in software and hardware. Compiler optimizations that improve data locality <ref> [13] </ref> like blocking and loop interchange can greatly reduce the need for prefetching. However, these fundamentally rely on compile-time knowledge of the data set layout and its interaction with the cache. Linked structures are not often laid out by the compiler, and are incompatible with these optimizations.
Reference: [14] <author> S. Mehrotra and L. Harrison. </author> <title> Examination of a memory access classification scheme for pointer-intensive and numeric program. </title> <booktitle> In Proceedings of the 10th International Conference on Supercomputing, </booktitle> <pages> pages 133139, </pages> <month> May </month> <year> 1996. </year>
Reference-contexts: Markov predictors are capable of capturing complex patterns, but are nonetheless address based, and require storage proportional to the number of distinct entries in the miss stream. Mehrotra and Harrison <ref> [14] </ref> proposed simple extensions to the RPT aimed at capturing recurrent access patterns. They augmented the RPT with a Recurrence Recognition Unit (RRU), a finite state machine able to recognize single level recurrences, such as the ones used in list traversal.
Reference: [15] <author> A. Moshovos, S. Breach, T. Vijaykumar, and G. Sohi. </author> <title> Dynamic speculation and synchronization of data dependences. </title> <booktitle> In Proceedings of the 24th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 181193, </pages> <month> Jun. </month> <year> 1997. </year>
Reference-contexts: Dependence-based prefetching can capture and prefetch all pointer loads. However, it has a potentially higher implementation cost. The use of data dependence between instructions as an information primitive and unit of prediction was introduced by Moshovos, Breach, Vijaykumar and Sohi <ref> [15] </ref>, and later refined by Chrysos and Emer [6]. In the initial work, dependence prediction was used to synchronize loads, avoiding misspeculation due to unresolved dependences. Tyson and Austin [23] and Moshovos and Sohi [16] broadened the scope of use of dependence information.
Reference: [16] <author> A. Moshovos and G. Sohi. </author> <title> Streamlining inter-operation communication via data dependence prediction. </title> <booktitle> In Proceeding of the 30th Annual Internation Symposium on Microarchitec-ture, </booktitle> <pages> pages 235245, </pages> <month> Dec. </month> <year> 1997. </year>
Reference-contexts: In the initial work, dependence prediction was used to synchronize loads, avoiding misspeculation due to unresolved dependences. Tyson and Austin [23] and Moshovos and Sohi <ref> [16] </ref> broadened the scope of use of dependence information. They propose to dynamically and transparently convert address-based activity to dependence-based activity, to reduce memory communication latency. We are not aware of any work that uses instruction dependence speculation to prefetch.
Reference: [17] <author> T. Mowry, M. Lam, and A. Gupta. </author> <title> Design and evaluation of a compiler algorithm for prefetching. </title> <booktitle> In Proceedings of the 5th International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 62 73, </pages> <month> Oct. </month> <year> 1992. </year>
Reference: [18] <author> S. Palacharla and J. Smith. </author> <title> Complexity-effective superscalar processors. </title> <booktitle> In Proceedings of the 24th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 206218, </pages> <month> Jul. </month> <year> 1997. </year>
Reference-contexts: They propose to dynamically and transparently convert address-based activity to dependence-based activity, to reduce memory communication latency. We are not aware of any work that uses instruction dependence speculation to prefetch. Other related works include the static access/execute decoupling proposed by Smith [22] and subsequent dynamic dependence-based decoupling <ref> [18] </ref>.
Reference: [19] <author> S. Pinter and A. Yoaz. </author> <title> Tango: A hardware-based data prefetching technique for superscalar processors. </title> <booktitle> In Proceedings of the 29th Annual International Symposium on Mi-croarchitecture, </booktitle> <pages> pages 214225, </pages> <month> Dec. </month> <year> 1996. </year>
Reference-contexts: A similar volume of research has been done in hardware prefetch-ing [3], and dynamic techniques for address prediction [7]. Most of these, such as stream buffers [9], reference prediction table (RPT)[4] and the subsequent Tango <ref> [19] </ref> analyze address sequences for single instructions arithmetically, and are designed to deal primarily with strided access patterns. Joseph and Grun-wald [8] describe Markov predictors which represent cache miss sequences in the form of a probabilistic transition table.
Reference: [20] <author> A. Rogers, M. Carlisle, J. Reppy, and L. Hendren. </author> <title> Supporting dynamic data structures on distributed memory machines. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <month> Mar. </month> <year> 1995. </year>
Reference-contexts: In this section, we attempt to quantify the first two parameters by presenting a characterization of LDS access behavior for programs from the Olden pointer-intensive benchmark suite <ref> [20] </ref>. The Olden benchmarks are a collection of programs that includes small and medium sized scientific codes (bh and em3d), process simulations (health and power), graph optimization routines (mst and tsp), graphics utilities (perimeter and voronoi), a sorting routine (bisort) and a toy tree benchmark (treeadd). <p> Finally, in sections 5.4 and 5.5, we take a closer look at prefetching itself, and try to gain insight into our performance numbers by measuring its efficiency, overhead, and interaction with the memory system. 5.1 Experimental Framework Our experiments were performed using the Olden pointer-intensive benchmark suite <ref> [20] </ref>. The benchmarks were modified by hand to execute on a single processor, and all CM-5 specific code was removed. We compiled the programs for the MIPS-I architecture using the GNU GCC 2.7.2 compiler with optimization ags -O2 and -funroll-loops.
Reference: [21] <author> A. Rogers and K. Li. </author> <title> Software support for speculative loads. </title> <booktitle> In Proceedings of the 5th International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 3250, </pages> <month> Oct. </month> <year> 1992. </year>
Reference-contexts: While not requiring specific layout information, software pipelin-ing relies on the ability to quickly generate addresses for arbitrary structure elements. LDS access undermines this critical requirement. General purpose software prefetching [17][11] tolerates load latency by scheduling a matching speculative non-faulting load <ref> [21] </ref> far in advance. Pointer chasing requires that the address for a speculative LDS load be generated using a chain of dependent loads.
Reference: [22] <author> J. Smith. </author> <title> Decoupled access/execute computer architecture. </title> <booktitle> In Proceedings of the 9th Annual International Symposium on Computer Architecture, </booktitle> <month> Jul. </month> <year> 1982. </year>
Reference-contexts: They propose to dynamically and transparently convert address-based activity to dependence-based activity, to reduce memory communication latency. We are not aware of any work that uses instruction dependence speculation to prefetch. Other related works include the static access/execute decoupling proposed by Smith <ref> [22] </ref> and subsequent dynamic dependence-based decoupling [18].
Reference: [23] <author> G. Tyson and T. Austin. </author> <title> Improving the accuracy and performance of memory communication through renaming. </title> <booktitle> In Proceeding of the 30th Annual Internation Symposium on Microarchitecture, </booktitle> <pages> pages 218227, </pages> <month> Dec. </month> <year> 1997. </year>
Reference-contexts: In the initial work, dependence prediction was used to synchronize loads, avoiding misspeculation due to unresolved dependences. Tyson and Austin <ref> [23] </ref> and Moshovos and Sohi [16] broadened the scope of use of dependence information. They propose to dynamically and transparently convert address-based activity to dependence-based activity, to reduce memory communication latency. We are not aware of any work that uses instruction dependence speculation to prefetch.
References-found: 23

