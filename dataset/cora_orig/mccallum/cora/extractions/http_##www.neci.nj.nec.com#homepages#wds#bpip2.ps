URL: http://www.neci.nj.nec.com/homepages/wds/bpip2.ps
Refering-URL: http://www.neci.nj.nec.com/homepages/wds/works.html
Root-URL: 
Note: 15  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Foreman S. Acton: </author> <title> Numerical methods that work, </title> <note> MAA 1990 (updated from 1970 edition). </note>
Reference-contexts: This quantity was truncated to lie in <ref> [0; 1] </ref> and 12 if 16 stones remained in play the exact game value (from an endgame table) was used instead. Gamestarts are all 190 positions reachable in 3 ply. Players are identical at depth 1.
Reference: [2] <author> Alan Agresti: </author> <title> Categorical data analysis, </title> <publisher> Wiley 1990 </publisher>
Reference: [3] <author> Louis Victor Allis: </author> <title> Searching for solutions in games and artificial intelligence, </title> <journal> CIP-Gegevens Koninklijke Bibliotheek, </journal> <note> Den Haag 1994; ISBN=90-9007488-0 </note>
Reference-contexts: Some preliminary experiments in Othello suggest that this might boost BPIP's strength substantially. 4 W1 achieves node rates over 10 times faster than Lithidion and has a significantly higher quality evaluation function. The only feature Lithidion has which w1 does not, is the use of "proof number search" <ref> [3] </ref> on the opponent's thinking time in an attempt to solve certain moves. 5 These allow one to avoid re-searching positions which have been searched before, and in iteratively deepened alpha beta search can help with move ordering. 6 Multistage or lazy evaluators have a controllable tradeoff between statistical accuracy and <p> This game is similar to the game sold by Milton-Bradley and played on a 6 fi 7 noncylindrical board, but that game has been solved (win for the first player by moving into the center column) by James Allen and L.V. Allis in 1989 <ref> [3, 53] </ref>.
Reference: [4] <author> T. Anantharaman, M. Campbell, F. Hsu: </author> <title> Singular extensions; adding selectivity to brute force searching, </title> <booktitle> Artificial Intelligence 43 (1990) 99-109 </booktitle>
Reference-contexts: We have ignored this idea elsewhere in the paper. 5 Engineering tricks Soon after the first alpha-beta chess players appeared, so did various engineering improvements upon them, including "quiescence" and [50] "iterative deepening." Although the rate has slowed, such improvements continue to appear even 40 years later <ref> [4, 10] </ref>. We similarly conjecture that there are many engineering tricks to be had in BPIP search. 5.1 The multispike trick There is a tradeoff in BPIP between using staircase CDF's with many steps, which can approximate well arbitrary density functions, and using few steps, saving memory and time.
Reference: [5] <author> Thomas S. Anantharaman: </author> <title> A Statistical Study of Selective Min-Max Search in Computer Chess, </title> <type> (PhD thesis, </type> <institution> Carnegie Mellon University, Computer Science Dept.) </institution> <month> May </month> <year> 1990, </year> <month> CMU-CS-90-173 </month>
Reference: [6] <author> Thomas S. Anantharaman: </author> <title> Extension heuristics, </title> <note> ICCA Journal 14,2 (June 1991) 47-65. </note>
Reference-contexts: NPU, BPIP, and AB play identically at depth 1 throughout. 7 The best combination of search extensions found for the Deep Thought chess machine (after a huge amount of experimentation <ref> [6] </ref>) was estimated to be worth only 86 USCF rating points. 59 of these were due to threat extensions, 7 to singular extensions, and 5 to PV extensions.
Reference: [7] <author> Eric B. Baum and Warren D. Smith: </author> <title> Best Play for Imperfect Players and Game Tree Search; part I - theory. </title>
Reference: [8] <author> D.F. Beal: </author> <title> A generalized quiescence search algorithm, </title> <booktitle> Artificial Intelligence 43 (1990) 85-98 </booktitle>
Reference: [9] <author> Leo Breiman, J.H. Friedman, R.A.Olshen, C.J. Stone: </author> <title> Classification and regression trees, </title> <publisher> Wadsworth 1984 </publisher>
Reference: [10] <author> Michael Buro: </author> <title> Techniken fur die Bewertung von Spielsituationen anhand von Beispielen, </title> <type> Ph.D thesis, </type> <institution> at University of Paderborn, Germany, </institution> <month> December </month> <year> 1994. </year>
Reference-contexts: Giles and C. Springer , and Bugs by J-C. Weill. The main weaknesses of our Othello programs as tournament players are: 1. Speed: Evaluation function slow compared to Logistello. No transposition table. No thinking on opponent's time. 2. No opening book. 3. No top-quality endgame solver (the best programs <ref> [10, 55] </ref> find game theoretic value with 24 empty squares.) Logistello searches about 25 times as many nodes as Obogon. The biggest reason for our slow speed was our desire to keep the code comparatively simple and understandable. We believe our Othello evaluator is quite accurate. <p> had been consumed. (The AB player's time control was adjusted too, to equalize time used.) As table 4 shows, this lowered the performance of the BPIP player by about 1 disc per game, although it was still much stronger than the AB player 16 4.1.5 AB with "probcut" Michael Buro <ref> [10] </ref> invented a simple but (at least in Othello) effective heuristic for selective extension in AB. Buro's Othello program Logistello, at 30 minutes/side/game would normally search to about 11-12 ply doing a nonselective iterated deepening alpha-beta search. <p> We have ignored this idea elsewhere in the paper. 5 Engineering tricks Soon after the first alpha-beta chess players appeared, so did various engineering improvements upon them, including "quiescence" and [50] "iterative deepening." Although the rate has slowed, such improvements continue to appear even 40 years later <ref> [4, 10] </ref>. We similarly conjecture that there are many engineering tricks to be had in BPIP search. 5.1 The multispike trick There is a tradeoff in BPIP between using staircase CDF's with many steps, which can approximate well arbitrary density functions, and using few steps, saving memory and time. <p> Many-valued y i 's gain more information and a better fit in games with multivalued final score. However, in games whose result is binary (y i 2 f0; 1g) Buro <ref> [10] </ref> has suggested use of "logistic regression" instead of linear regression.
Reference: [11] <author> Michael Buro: ProbCut: </author> <title> an effective selective extension of the fffi algorithm, </title> <note> ICCA Journal 18,2 (1995) 71-76. </note>
Reference-contexts: The depths "8", and "4" and the optimum value X = 1:50 were found empirically. Probcut allows Logistello to search deeper in the selected lines. Its winning percentage against the nonselective version was 64:7% even in a tournament with 2:1 time odds. Also, Buro found <ref> [11] </ref> that 12 ply searches with selectivity turned on would make the same move, 93% of the time, as full width 12-ply searches, but run 4-6 times faster. Probcut is easy to implement. We implemented a probcut version of our AB Othello player.
Reference: [12] <author> David B. Chamberlin: </author> <title> How to play Warri, privately printed 1984. (Available from author, </title> <address> 2101 Birch-wood Road, Lancaster PA 17603, </address> <note> for $7.) </note>
Reference-contexts: requirement for the two sides to be the same, * and in other cases, simply every position reachable from gamestart in a certain number of ply. 2.2 Games, languages, hardware We have studied the abilities of full game playing programs on three games, Slagle kalah [48], Othello [24], and Warri <ref> [12] </ref>. Kalah was chosen as a simple game to begin on; Othello as a more complex game on which alpha-beta performs well; and then Warri was chosen as a more complex relative of Kalah. <p> The most important of the rule variants, and the one that is adopted in Antiguan league play (and in the annual tournaments held there in Decembers and televised in recent years) is called Warri. These are extracted from pages 15-17 of [39] and from <ref> [12] </ref>. 1. Warri is played on a 2fi6 board. 2. Four seeds per hole at gamestart (i.e. 48 total). South moves first. 3.
Reference: [13] <author> I. Chernev: </author> <title> The compleat Draughts player, </title> <publisher> Oxford University Press 1981. </publisher>
Reference: [14] <author> P-C. Chi & D. S. Nau: </author> <title> Comparison of the Minimax and Product Back-up Rules in a Variety of Games, </title> <booktitle> in Search in Artificial Intelligence, </booktitle> <editor> eds. L. Kanal and V. Kumar, </editor> <publisher> Springer Verlag, </publisher> <address> New York,(1989) pp 451-471. </address>
Reference-contexts: NPU does this well because Slagle Kalah exhibits few recognizable features which last for longer than a few ply (and even these are invisible to the crude evaluation function we are using here), so that all positions are fairly "independent" of all other positions. Chi and Nau <ref> [14] </ref> showed that NPU was superior to AB at certain search depths when a reduced version of Slagle Kalah. They argued that NPU tends to do better against AB, if the evaluator used has a large "rate of heuristic flaw" as do all known evaluators in Slagle kalah. <p> seeds evenly between the players, so that whoever was ahead before the cycle started, wins. 32 7.3 Slagle Kalah Slagle kalah was introduced in papers by Slagle et al. [48, 49], who used it as a vehicle for studying game tree search, and studied by other AI researchers (see eg <ref> [14] </ref>). See [48, 49] for the rules. We call this game "Slagle Kalah" because, as far as we are able to determine, the particular Mancala rule variant used here was invented by Slagle.
Reference: [15] <author> A. Delcher, S. Kasif: </author> <title> Improved Decision Making in Game Trees: Recovering from Pathology, </title> <booktitle> Proceedings of the National Conference on Artificial Intelligence (July 1992) 513-518. </booktitle>
Reference: [16] <editor> A.Deledicq and A.Popova: Wari et Solo, le jeu de calculs Africain, </editor> <address> CEDIC (93 avenue d'Italie 75013 Paris) 1977 </address>
Reference-contexts: Many of them are listed in [39] and <ref> [16] </ref>. The most important of the rule variants, and the one that is adopted in Antiguan league play (and in the annual tournaments held there in Decembers and televised in recent years) is called Warri. These are extracted from pages 15-17 of [39] and from [12]. 1.
Reference: [17] <author> R.M.Goodman and P. Smyth: </author> <title> Decision tree design from a communication theory standpoint, </title> <journal> IEEE Trans. Info. </journal> <note> Theory 34,5 (1988) 979-994. </note>
Reference-contexts: Recall the learning experiments from x6.1.3. The `B' player in tourney 0 had been trained on positions from AB searches. 30 This idea is well known <ref> [17, 34] </ref>, but we believe our growth termination condition is novel. 30 regarded as a probability distribution.
Reference: [18] <author> G.H. Golub and J.H. Welsch: </author> <title> Calculation of Gauss quadrature rules, </title> <journal> Math. </journal> <note> of Computation 23 (1969) 221-230 and microfiche. </note>
Reference-contexts: We have relied on the following method. We choose the locations and heights of the k spikes so that the first 2k nontrivial moments of the two distributions agree. Such a compression exists and is unique, and may be found using a slick numerical method of Golub and Welsch <ref> [18] </ref>. This compression method suffers from at least two flaws.
Reference: [19] <author> R. Floyd and R. Rivest: </author> <title> Expected time bounds for selection, </title> <journal> Commun. </journal> <note> ACM 18,3 (March 1975) 165-173 </note>
Reference: [20] <author> Louis C. Ginsberg: </author> <title> Principles of strategy in the game of checkers, privately printed 1931. Reprinted by Don Goodwin, </title> <address> 51 Tefly Road, Willowdale, Ontario Canada M2M-1C5. </address>
Reference: [21] <author> E.T.Jaynes: </author> <title> Concentration of distributions, pp 315-336 in E.T. Jaynes: papers on probability, </title> <journal> statistics, and statistical physics, Kluwer 1989. </journal> <volume> 35 </volume>
Reference-contexts: This termination condition is the one which naturally arises from the large-N asymptotics of E.T. Jayne's "entropy concentration theorem" <ref> [21] </ref> combined with the notion that the prior among models of description length B is proportional to 2 B . The philosophy is that an increase in model complexity of B bits is justified by improving the description of N samples by entropy change S bits, where (EQ 16) holds.
Reference: [22] <author> Robert L. Jennrich: </author> <title> Stepwise regression, pp. 58-75 in: Statistical Methods for Digital Computers, </title> <editor> (Editors: Kurt Enslein, Anthony Ralston, Herbert S. </editor> <publisher> Wilf) Wiley 1977 </publisher>
Reference-contexts: Let y i represent the final game result in the game in which position i arose. We wish to find weights ! 1::n so that y ~x ~!. The least squares choice of ~! is ~! = (X T X) 1 X T ~y. Of course <ref> [22] </ref>, one wishes to find X T X and X T ~y (total storage O (n 2 ) numbers) without ever storing the much larger N fi n matrix X. Many-valued y i 's gain more information and a better fit in games with multivalued final score. <p> First, each feature's weight had to have absolute value at least 10 times its standard error. (Our least squares fitter, which is based on a procedure by Jennrich <ref> [22] </ref>, calculates these standard errors and automatically refuses to incorporate features into the fit if they do not pass such "F-tests.") Features which often were thrown out of fits were suspect. Third, features with small "importance" (weight times standard deviation) were suspect.
Reference: [23] <author> Alexander Kotov: </author> <title> Think like a grandmaster, </title> <month> Batsford </month> <year> 1971 </year>
Reference: [24] <author> Ted Landau: </author> <title> Othello, brief and basic (1984), sold by US Othello Association, </title> <address> 920 Northgate Ave. Waynesboro VA 22980-3425. </address>
Reference-contexts: we remove the requirement for the two sides to be the same, * and in other cases, simply every position reachable from gamestart in a certain number of ply. 2.2 Games, languages, hardware We have studied the abilities of full game playing programs on three games, Slagle kalah [48], Othello <ref> [24] </ref>, and Warri [12]. Kalah was chosen as a simple game to begin on; Othello as a more complex game on which alpha-beta performs well; and then Warri was chosen as a more complex relative of Kalah. <p> feel we have made in the study of that particular game, and a discussion of "the hall of fame" of the strongest gameplaying entities for each game and estimates of how our programs compare to them, see our lengthy Tech Report [52]. 7.1 Othello For the rules of Othello, see <ref> [24] </ref> or [38]. An important rule not mentioned by these sources is the scoring of games which terminate before the board is filled. In these games, the winner gets the empties.
Reference: [25] <author> Han La Poutre and Warren D. Smith: </author> <title> Approximation of staircases by staircases, </title> <type> Technical report, </type> <address> NECI, 4 Independence Way, Princeton NJ 08540. </address>
Reference: [26] <author> Kai-Fu Lee and Sanjoy Mahajan: </author> <title> The development of a world class Othello program, </title> <booktitle> Artificial Intelligence 43 (1990) 21-36 </booktitle>
Reference-contexts: AB and BPIP are using the same evaluation function (AB is using the mean of the BPIP function, since AB requires a scalar) and AB is using response killer history tables and iterative deepening to do move ordering (similar to BILL <ref> [26] </ref>). The evaluator used a combination of linear regression and Kolmogorov-Smirnov trees (x6.1.1). In the timed games, AB did iterative deepening until cumulative time consumption exceeded a fixed fraction of the time budgeted for that move (except that on forced moves, which are rare, it plays instantly). <p> Slate's program is based on a comparatively fancy, full width alpha-beta type search with transposition table and quiescence, and it has a node rate 5fi higher than our programs. On the other hand, its evaluation function is comparatively simple. Slate's program had lost an earlier match with BILL <ref> [26] </ref> by a small margin. program wins mean discs sec/game consumed AB 94 36.35 217.22 (19) Slate 44 27.65 227.78 (18) (4 draws) (stddev 7.58) (disc conf. 6.83) program wins mean discs sec/game consumed BPIP 131 41.88 226.99 (23) Slate 10 22.12 239.26 (41) (1 draw) (stddev 6.51) (disc conf. 18.09)
Reference: [27] <author> R. Levinson & R. Snyder: </author> <title> DISTANCE: Toward the unification of chess knowledge, </title> <journal> ICCA (Int'l Computer Chess Assoc.) </journal> <note> Journal 16,3 (Sept. </note> <year> 1993) </year> <month> 123-136. </month>
Reference: [28] <author> T.A. Marsland: </author> <title> A review of game tree pruning, </title> <note> ICCA Journal 9,1 (March 1986) 3-19 </note>
Reference: [29] <author> F.J. Massey: </author> <title> Distribution table for the deviation between two sample cumulatives, </title> <journal> Ann. Math. Statist. </journal> <month> 23 </month> <year> (1952) </year> <month> 435-441. </month>
Reference-contexts: We regard each such subset as a (large sample from a) univariate probability density on . Choose that question maximizing the confidence that its two induced probability distributions are different. This confidence is computed by means of the "Kolmogorov-Smirnov two sample test," <ref> [51, 29] </ref> applied to uniquified 27 data. We cease to split further when (1 c)=s becomes smaller than some constant (we often used 0:001). Here c is the KS confidence that the two distributions really are different, and s is the number of candidate split-questions.
Reference: [30] <author> D.A. McAllester: </author> <title> Conspiracy numbers for min max search, </title> <booktitle> Artificial Intelligence 35 (1988) 287-310. </booktitle>
Reference-contexts: Rivest compared an algorithm of his devising to alpha-beta on the game of Connect 4, finding that he could beat it at equal nodes, but lost at equal time [37]. Schaeffer [44] implemented the conspiracy number algorithm of McAllester <ref> [30] </ref> and compared it to alpha-beta in chess, finding that it worked well in tactical middlegame situations, but was not competitive overall. Palay compared his algorithm to Belle on tactical positions in chess [32].
Reference: [31] <author> Dana S. Nau: </author> <title> Pathology on game trees revisited, and an alternative to minimaxing, </title> <address> AI 21 (1983) 224-244. </address>
Reference-contexts: We would like to see experiments on chess, but have abandoned these for the present paper as requiring too much programming work. In addition to the above games, we have studied different evaluation methods on fixed sized trees on the games "mod-9 connect-4," and Pearl's P-game [33] <ref> [31] </ref>. Pearl's P-game was included in this list because it was crafted to be "pathological" and thus seemed likely to lead to insight. For a description of the games except the P-game, see x7. The P-game is described in x3.1. <p> to a 62:38 win ratio (where a draw is 1=2 a win), which is smaller than the advantage BPIP enjoyed over AB in our Othello experiments, but comparable to BPIP's advantage in our Warri experiments. 7 3.1 Pearl's "P-game" This game was designed by Pearl [33] and studied by Nau <ref> [31] </ref> as an example of a theoretically "pathological" game 8 , i.e. a game where searching deeper can be shown to give smaller probability of making the correct move in some positions. <p> results were as follows. player depth 2 3 4 5 6 7 8 9 wins for AB 196178 196763 184547 186982 172071 180741 172815 187157 " " NPU 199926 197412 203727 202399 211349 207292 211538 203939 " " BPIP 203896 205825 211726 210619 216580 211967 215647 208904 This confirms Nau's <ref> [31] </ref> results that NPU is a superior decision procedure to minimax, searching to fixed depth in the P-game. BPIP is found to be superior to NPU with 4-9 standard deviations of confidence, depending on which depth.
Reference: [32] <author> A.J. Palay: </author> <title> Searching with probabilities, </title> <publisher> Pitman 1985 </publisher>
Reference-contexts: Schaeffer [44] implemented the conspiracy number algorithm of McAllester [30] and compared it to alpha-beta in chess, finding that it worked well in tactical middlegame situations, but was not competitive overall. Palay compared his algorithm to Belle on tactical positions in chess <ref> [32] </ref>. Russell and Wefald reported beating alpha-beta at Othello [40], but their implementation of alpha beta used no move ordering heuristic [41]. Our results are the first of which we are aware where an alternative approach was able to beat alpha-beta programs incorporating move ordering heuristics.
Reference: [33] <author> Judea Pearl: </author> <title> Heuristics, </title> <publisher> Addison-Wesley 1985. </publisher>
Reference-contexts: In some games, BPIP's advantage over minimax is comparable to that gained by an additional ply of search. We also compare both alpha-beta and BPIP to a previously proposed probablistic scheme that we call Naive Probability Update or NPU. By NPU we mean the proposal <ref> [33] </ref> to use an evaluation function estimating probability of winning, and to compute the value of a node as the probability it is winning given the (assumed independent) estimates for its children. <p> We would like to see experiments on chess, but have abandoned these for the present paper as requiring too much programming work. In addition to the above games, we have studied different evaluation methods on fixed sized trees on the games "mod-9 connect-4," and Pearl's P-game <ref> [33] </ref> [31]. Pearl's P-game was included in this list because it was crafted to be "pathological" and thus seemed likely to lead to insight. For a description of the games except the P-game, see x7. The P-game is described in x3.1. <p> This translates to a 62:38 win ratio (where a draw is 1=2 a win), which is smaller than the advantage BPIP enjoyed over AB in our Othello experiments, but comparable to BPIP's advantage in our Warri experiments. 7 3.1 Pearl's "P-game" This game was designed by Pearl <ref> [33] </ref> and studied by Nau [31] as an example of a theoretically "pathological" game 8 , i.e. a game where searching deeper can be shown to give smaller probability of making the correct move in some positions.
Reference: [34] <author> J. Ross Quinlan and R. L. Rivest: </author> <title> Inferring Decision Trees Using the Minimum Description Length Principle, </title> <booktitle> Information and Computation 80,3 (March 1989), </booktitle> <pages> 227-248. </pages>
Reference-contexts: Recall the learning experiments from x6.1.3. The `B' player in tourney 0 had been trained on positions from AB searches. 30 This idea is well known <ref> [17, 34] </ref>, but we believe our growth termination condition is novel. 30 regarded as a probability distribution.
Reference: [35] <author> A. Reinefeld: </author> <title> An improvement of the scout tree search algorithm, </title> <note> ICCA Journal 6,4 (Dec 1983) 4-14 </note>
Reference-contexts: We also implemented and 5 report results against an alpha-beta Othello program incorporating Buro's Probcut tree shaping heuristic. In general, however, we have stuck to simple versions of alpha-beta. We believe that fancy modifications of alpha beta, e.g. negascout <ref> [35] </ref>, buy little advantage in practice. See [46] for a comparative study of such modifications. We will describe in section 6 how we trained up evaluation functions. Generally our alpha-beta Program used as evaluation function the mean of the BPIP distributions. This allows a direct comparison. <p> Because this evaluator is so simple, we can obtain rates of 70000 evaluations/second during searches enormous rates. Starting from a set of tables with all entries zero, we conducted learning negascout <ref> [35] </ref> searches with transposition table.
Reference: [36] <author> Arthur Reisman: </author> <title> Checkers made easy, Key publ. </title> <publisher> co. </publisher> <year> 1959 </year>
Reference: [37] <author> R.L. Rivest: </author> <title> Game tree searching by min max approximation, </title> <booktitle> Artificial Intelligence 34 (1988) 77-96 </booktitle>
Reference-contexts: A number of authors have previously compared tree growth algorithms to alpha-beta. Rivest compared an algorithm of his devising to alpha-beta on the game of Connect 4, finding that he could beat it at equal nodes, but lost at equal time <ref> [37] </ref>. Schaeffer [44] implemented the conspiracy number algorithm of McAllester [30] and compared it to alpha-beta in chess, finding that it worked well in tactical middlegame situations, but was not competitive overall. Palay compared his algorithm to Belle on tactical positions in chess [32].
Reference: [38] <author> Paul S. Rosenbloom: </author> <title> A world-championship level Othello program, </title> <booktitle> Artificial Intelligence 19 (1982) 279-320 </booktitle>
Reference-contexts: have made in the study of that particular game, and a discussion of "the hall of fame" of the strongest gameplaying entities for each game and estimates of how our programs compare to them, see our lengthy Tech Report [52]. 7.1 Othello For the rules of Othello, see [24] or <ref> [38] </ref>. An important rule not mentioned by these sources is the scoring of games which terminate before the board is filled. In these games, the winner gets the empties.
Reference: [39] <author> Laurence Russ: </author> <title> Mancala Games, </title> <publisher> Reference Publications Inc (218 St. </publisher> <address> Clair River Drive, Box 344, Algonac MI 48001) 1984 </address>
Reference-contexts: Many of them are listed in <ref> [39] </ref> and [16]. The most important of the rule variants, and the one that is adopted in Antiguan league play (and in the annual tournaments held there in Decembers and televised in recent years) is called Warri. These are extracted from pages 15-17 of [39] and from [12]. 1. <p> Many of them are listed in <ref> [39] </ref> and [16]. The most important of the rule variants, and the one that is adopted in Antiguan league play (and in the annual tournaments held there in Decembers and televised in recent years) is called Warri. These are extracted from pages 15-17 of [39] and from [12]. 1. Warri is played on a 2fi6 board. 2. Four seeds per hole at gamestart (i.e. 48 total). South moves first. 3.
Reference: [40] <author> S. Russell and E. Wefald: </author> <title> Do the Right Thing, </title> <note> MIT Press 1991 (see especially chapter 4) </note>
Reference-contexts: Palay compared his algorithm to Belle on tactical positions in chess [32]. Russell and Wefald reported beating alpha-beta at Othello <ref> [40] </ref>, but their implementation of alpha beta used no move ordering heuristic [41]. Our results are the first of which we are aware where an alternative approach was able to beat alpha-beta programs incorporating move ordering heuristics.
Reference: [41] <author> S. Russell, </author> <type> personal communication. </type>
Reference-contexts: Palay compared his algorithm to Belle on tactical positions in chess [32]. Russell and Wefald reported beating alpha-beta at Othello [40], but their implementation of alpha beta used no move ordering heuristic <ref> [41] </ref>. Our results are the first of which we are aware where an alternative approach was able to beat alpha-beta programs incorporating move ordering heuristics. This previous work and some additional is discussed in more depth in Part 1.
Reference: [42] <author> A.L. Samuel: </author> <title> Some studies in machine learning using the game of checkers, </title> <institution> IBM J. Res. & Devel. </institution> <month> 3,3 </month> <year> (1959) </year> <month> 210-229. </month>
Reference: [43] <author> A.L. Samuel: </author> <title> Some studies in machine learning using the game of checkers II recent progress, </title> <institution> IBM J. Res. & Devel. </institution> <month> 11,6 </month> <year> (1967) </year> <month> 601-617. </month>
Reference: [44] <author> J. Schaeffer: </author> <title> Conspiracy numbers, </title> <booktitle> Artificial Intelligence 43 (1990) 67-84 36 </booktitle>
Reference-contexts: A number of authors have previously compared tree growth algorithms to alpha-beta. Rivest compared an algorithm of his devising to alpha-beta on the game of Connect 4, finding that he could beat it at equal nodes, but lost at equal time [37]. Schaeffer <ref> [44] </ref> implemented the conspiracy number algorithm of McAllester [30] and compared it to alpha-beta in chess, finding that it worked well in tactical middlegame situations, but was not competitive overall. Palay compared his algorithm to Belle on tactical positions in chess [32].
Reference: [45] <author> J. Schaeffer, J. Culberson, N. Treloar, B. Knight, P. Lu, D. Szafron: </author> <title> A world championship calibre checkers program, </title> <booktitle> Artificial Intelligence 53 (1992) 273-289. </booktitle>
Reference: [46] <author> J. Schaeffer: </author> <title> Experiments in search and knowledge, </title> <type> TR 86-12, </type> <institution> Department of Computer Science, University of Alberta, Edmonton, Alberta, Canada. </institution> <type> (His PhD thesis from U. </type> <institution> Waterloo, </institution> <month> May </month> <year> 1986.) </year>
Reference-contexts: We also implemented and 5 report results against an alpha-beta Othello program incorporating Buro's Probcut tree shaping heuristic. In general, however, we have stuck to simple versions of alpha-beta. We believe that fancy modifications of alpha beta, e.g. negascout [35], buy little advantage in practice. See <ref> [46] </ref> for a comparative study of such modifications. We will describe in section 6 how we trained up evaluation functions. Generally our alpha-beta Program used as evaluation function the mean of the BPIP distributions. This allows a direct comparison.
Reference: [47] <author> C.E. Shannon: </author> <title> Programming a computer for playing chess, </title> <journal> Philos. </journal> <note> Magazine 41,7 (1950) 256-275 </note>
Reference-contexts: These trends may portend substantial edges for Bayesian search techniques, which attempt to explore the most relevant directions, as opposed to simple Branch and Bound in a variety of problems. Shannon <ref> [47] </ref> proposed that computers select their move according to the minimax value of a full width subtree, with numerical leaf values assigned by some readily computed, heuristic evaluation function. The alpha-beta procedure speeds up this search.
Reference: [48] <author> J.R. Slagle and J.K. Dixon: </author> <title> Experiments with some programs that search game trees, </title> <journal> Commun. </journal> <note> ACM 16,2 (1969) 189-207 </note>
Reference-contexts: above, except we remove the requirement for the two sides to be the same, * and in other cases, simply every position reachable from gamestart in a certain number of ply. 2.2 Games, languages, hardware We have studied the abilities of full game playing programs on three games, Slagle kalah <ref> [48] </ref>, Othello [24], and Warri [12]. Kalah was chosen as a simple game to begin on; Othello as a more complex game on which alpha-beta performs well; and then Warri was chosen as a more complex relative of Kalah. <p> For comparison we played our AB player against AB with an extra ply. depth 2 3 4 5 6 7 8 9 10 total 10 This evaluation is the exact probability of winning given the current score difference (what <ref> [48] </ref> called Kalah difference) under the assumption that you will win the seeds on your side with probability G and those on your opponent's side with probability 1 G, the probabilities for each seed being assumed to be independent. 9 wins for AB 528 688 631 724 713 722 705 718 <p> In this case (detected by a 3-time repetition) the simplest scoring method is to divide the cycling seeds evenly between the players, so that whoever was ahead before the cycle started, wins. 32 7.3 Slagle Kalah Slagle kalah was introduced in papers by Slagle et al. <ref> [48, 49] </ref>, who used it as a vehicle for studying game tree search, and studied by other AI researchers (see eg [14]). See [48, 49] for the rules. <p> between the players, so that whoever was ahead before the cycle started, wins. 32 7.3 Slagle Kalah Slagle kalah was introduced in papers by Slagle et al. <ref> [48, 49] </ref>, who used it as a vehicle for studying game tree search, and studied by other AI researchers (see eg [14]). See [48, 49] for the rules. We call this game "Slagle Kalah" because, as far as we are able to determine, the particular Mancala rule variant used here was invented by Slagle.
Reference: [49] <author> J.R. Slagle and J.K. Dixon: </author> <title> Experiments with the M & N tree searching program, </title> <journal> Commun. </journal> <note> ACM 13,3 (March 1970) 147-153 </note>
Reference-contexts: In this case (detected by a 3-time repetition) the simplest scoring method is to divide the cycling seeds evenly between the players, so that whoever was ahead before the cycle started, wins. 32 7.3 Slagle Kalah Slagle kalah was introduced in papers by Slagle et al. <ref> [48, 49] </ref>, who used it as a vehicle for studying game tree search, and studied by other AI researchers (see eg [14]). See [48, 49] for the rules. <p> between the players, so that whoever was ahead before the cycle started, wins. 32 7.3 Slagle Kalah Slagle kalah was introduced in papers by Slagle et al. <ref> [48, 49] </ref>, who used it as a vehicle for studying game tree search, and studied by other AI researchers (see eg [14]). See [48, 49] for the rules. We call this game "Slagle Kalah" because, as far as we are able to determine, the particular Mancala rule variant used here was invented by Slagle.
Reference: [50] <author> D.J. Slate & L.R.Atkin: </author> <title> Chess 4.5: The Northwestern University chess program, </title> <editor> in P.Frey (ed.) </editor> <booktitle> Chess skill in man and machine, </booktitle> <publisher> Springer-Verlag 1983 </publisher>
Reference-contexts: We have ignored this idea elsewhere in the paper. 5 Engineering tricks Soon after the first alpha-beta chess players appeared, so did various engineering improvements upon them, including "quiescence" and <ref> [50] </ref> "iterative deepening." Although the rate has slowed, such improvements continue to appear even 40 years later [4, 10].
Reference: [51] <author> N. Smirnov: </author> <title> Tables for estimating the goodness of fit of empirical distributions, </title> <journal> Annals Math. Statist. </journal> <month> 19 </month> <year> (1948) </year> <month> 280-281 </month>
Reference-contexts: We regard each such subset as a (large sample from a) univariate probability density on . Choose that question maximizing the confidence that its two induced probability distributions are different. This confidence is computed by means of the "Kolmogorov-Smirnov two sample test," <ref> [51, 29] </ref> applied to uniquified 27 data. We cease to split further when (1 c)=s becomes smaller than some constant (we often used 0:001). Here c is the KS confidence that the two distributions really are different, and s is the number of candidate split-questions.
Reference: [52] <author> Smith, W. D., E. B. Baum, C. Garrett, R. Tudor: </author> <title> Best Play for Imperfect Players and Game Tree Search; part II- experiments; Monster Unedited Version; http://www.neci.nj.nec.com:80/homepages/eric/monster.ps. </title>
Reference-contexts: We hope to provide some insight into the engineering work that has gone into our current implementations and what avenues might lead to further improvement. The reader interested in replicating or extending our results will find gritty details of our experiments in our (completely unpolished) Technical report <ref> [52] </ref>. 2 Experimental methods, general discussion 2.1 Tournaments Most of our experiments consisted of multigame matches between two gameplaying entities. Our tournaments were "color balanced" e.g. each player would play each gamestart position from each side. <p> Presumably this incredible depth is due to the speed of basic operations in Slagle kalah, the presence of a simple but effective move ordering <ref> [52] </ref>, and the presence of a large number of cutoffs from early win detections. Note that AB's node rate is about 8 times quicker than BPIP's, and all known evaluation functions for Slagle kalah are rather poor quality. All these conditions favor AB over BPIP. <p> We also played the BPIP (c) programs versus Slate's program with unequal thinking times. The results <ref> [52] </ref> neither confirm nor disprove Seidler's theory, but do make it clear that any Othello benefit from Seidler's strategy is small. <p> We feel this was the right choice for a first implementation of BPIP, and it was good enough to beat alpha-beta. The long TR version <ref> [52] </ref> lists several improvements in memory management we know of, but mostly did not yet choose to implement. 6 Learning methods to make evaluators 6.1 Linear regression and significance tests Before constructing an evaluation function that returns probability distributions, we first construct one that simply returns a number approximating the expected <p> In our later Warri program, we used a self-learned table-based evaluator (which may be thought of as a linear evaluator with about 30000 weights). See x6.1.3. For details about our features and evaluation functions, see our long TM <ref> [52] </ref>. 6.1.1 Kolmogorov-Smirnov decision trees Once one has a good-quality scalar evaluator, one can semi-automatically construct an evaluator which returns a probability distribution. We call the method we invented "Kolmogorov-Smirnov trees." First we acquire a large set of positions arising during BPIP searches. <p> Therefore, although obaby's learning feats were impressive, its learned table-based evaluator was still weak in an absolute sense. Therefore, we decided to abort obaby and stick with an evaluator based on handmade features and linear regressions. In Warri, we had more success with the table learning technique (see <ref> [52] </ref>) than in Othello, and hence we used it in our final Warri program. <p> used in our evaluation functions, any new contributions we feel we have made in the study of that particular game, and a discussion of "the hall of fame" of the strongest gameplaying entities for each game and estimates of how our programs compare to them, see our lengthy Tech Report <ref> [52] </ref>. 7.1 Othello For the rules of Othello, see [24] or [38]. An important rule not mentioned by these sources is the scoring of games which terminate before the board is filled. In these games, the winner gets the empties.
Reference: [53] <editor> J.W. Uiterwijk, J.J. van den Herik, L.V. Allis: </editor> <title> A knowledge-based approach to connect-four, </title> <booktitle> in: Heuristic programming and artificial intelligence, the first computer olympiad, </booktitle> <publisher> Ellis Horwood Ltd 1989 </publisher>
Reference-contexts: This game is similar to the game sold by Milton-Bradley and played on a 6 fi 7 noncylindrical board, but that game has been solved (win for the first player by moving into the center column) by James Allen and L.V. Allis in 1989 <ref> [3, 53] </ref>.
Reference: [54] <author> S.H. Walker & D.B. Duncan: </author> <title> Estimation of the probability of an event as a function of several independent variables, </title> <note> Biometrika 54 (1967) 167-179. </note>
Reference-contexts: The maximumum likelihood statistical religion then proposes choosing ~! to maximize Q wins p i Q losses (1 p i ). <ref> [54] </ref> gives an iterative reweighted least squares process which converges to this ~!. We will now derive and describe a (presumably) equivalent algorithm.
Reference: [55] <author> J-C. Weill: </author> <title> The NegaC* search, </title> <note> ICCA Journal 15,1 (March 1992) 3-7 </note>
Reference-contexts: Giles and C. Springer , and Bugs by J-C. Weill. The main weaknesses of our Othello programs as tournament players are: 1. Speed: Evaluation function slow compared to Logistello. No transposition table. No thinking on opponent's time. 2. No opening book. 3. No top-quality endgame solver (the best programs <ref> [10, 55] </ref> find game theoretic value with 24 empty squares.) Logistello searches about 25 times as many nodes as Obogon. The biggest reason for our slow speed was our desire to keep the code comparatively simple and understandable. We believe our Othello evaluator is quite accurate.
Reference: [56] <author> Tom Wiswell: </author> <title> The science of checkers and draughts, </title> <note> A.S. Barnes 1973. </note>
Reference: [57] <author> Tom Wiswell: </author> <title> The complete guide to checkers, </title> <publisher> Macmillan 1970 </publisher>
Reference: [58] <author> Tom Wiswell and Jules Leopold: </author> <title> The wonderful world of checkers and draughts, </title> <note> A.S. Barnes 1980. </note> *********************** 
Reference: [59] <author> Brian W. Kernighan, Dennis M. Ritchie: </author> <title> The C programming language, second edition, </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs NJ 1988 </address>
Reference-contexts: Pearl's P-game was included in this list because it was crafted to be "pathological" and thus seemed likely to lead to insight. For a description of the games except the P-game, see x7. The P-game is described in x3.1. The guts of all our programs are written in C <ref> [59] </ref> and C++ [63],although we have also used the following languages in various places: UNIX (TM) shell, sed, and awk [60], TCL [62], perl [64], and matlab [61].
Reference: [60] <author> Brian W. Kernighan, Rob Pike: </author> <title> The UNIX programming environment, </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs NJ 1984 </address>
Reference-contexts: For a description of the games except the P-game, see x7. The P-game is described in x3.1. The guts of all our programs are written in C [59] and C++ [63],although we have also used the following languages in various places: UNIX (TM) shell, sed, and awk <ref> [60] </ref>, TCL [62], perl [64], and matlab [61]. All our timed experiments were run on a SGI machine based on a 150 MHz IP19 processor (MIPS R4400 processor with R4010 floating point chip) with data and instruction cache sizes of 16 Kbytes each, and a secondary unified 1 Mbyte cache.
Reference: [61] <author> Cleve B. Moler: </author> <title> MATLAB User's Guide, The MathWorks, </title> <publisher> Inc. </publisher> <address> Cochituate Place 24 Prime Park Way Natick, MA 01760. </address>
Reference-contexts: The P-game is described in x3.1. The guts of all our programs are written in C [59] and C++ [63],although we have also used the following languages in various places: UNIX (TM) shell, sed, and awk [60], TCL [62], perl [64], and matlab <ref> [61] </ref>. All our timed experiments were run on a SGI machine based on a 150 MHz IP19 processor (MIPS R4400 processor with R4010 floating point chip) with data and instruction cache sizes of 16 Kbytes each, and a secondary unified 1 Mbyte cache.
Reference: [62] <author> John K. Ousterhout: </author> <title> Tcl and the Tk toolkit, </title> <publisher> Addison-Wesley, </publisher> <address> Reading MA 1994 </address>
Reference-contexts: For a description of the games except the P-game, see x7. The P-game is described in x3.1. The guts of all our programs are written in C [59] and C++ [63],although we have also used the following languages in various places: UNIX (TM) shell, sed, and awk [60], TCL <ref> [62] </ref>, perl [64], and matlab [61]. All our timed experiments were run on a SGI machine based on a 150 MHz IP19 processor (MIPS R4400 processor with R4010 floating point chip) with data and instruction cache sizes of 16 Kbytes each, and a secondary unified 1 Mbyte cache.
Reference: [63] <author> Bjarne Stroustrup: </author> <title> The C++ programming language, </title> <publisher> Addison-Wesley, </publisher> <address> Reading MA 1991 </address>
Reference: [64] <author> Larry Wall and Randal L. Schwartz: </author> <title> Programming perl, O'Reilly & Associates, Sebastopol CA 1990 37 based on time odds tourney table ; readers may conjure up their own error bars...) in Othello, versus BPIP thinking time per game (seconds; BPIP evaluated 1350 nodes/sec as compared with AB's 2300). 38 compression of opinion change data at depth 5-6. </title> <type> 39 </type>
Reference-contexts: The P-game is described in x3.1. The guts of all our programs are written in C [59] and C++ [63],although we have also used the following languages in various places: UNIX (TM) shell, sed, and awk [60], TCL [62], perl <ref> [64] </ref>, and matlab [61]. All our timed experiments were run on a SGI machine based on a 150 MHz IP19 processor (MIPS R4400 processor with R4010 floating point chip) with data and instruction cache sizes of 16 Kbytes each, and a secondary unified 1 Mbyte cache.
References-found: 64

