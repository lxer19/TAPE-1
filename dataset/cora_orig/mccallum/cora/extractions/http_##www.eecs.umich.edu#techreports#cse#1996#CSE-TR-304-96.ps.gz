URL: http://www.eecs.umich.edu/techreports/cse/1996/CSE-TR-304-96.ps.gz
Refering-URL: http://www.eecs.umich.edu/home/techreports/cse96.html
Root-URL: http://www.eecs.umich.edu
Email: email: fnelsonr,aprakashg@eecs.umich.edu  
Title: Design Issues on the Support of Tools and Media in Replayable  
Author: Workspaces Nelson R. Manohar and Atul Prakash 
Address: Ann Arbor, MI 48109-2122 USA.  
Affiliation: Department of Electrical Engineering and Computer Science University of Michigan,  
Abstract: This paper presents flexible support for asynchronous sharing (later-time use) of computer-supported workspaces (CSWs), or simply replayable workspaces. Through the interactive replay of a previously recorded CSW session, it is possible to reuse valuable collaborative information. The session is represented through heterogeneous media streams each containing state and inputs to a CSW tool. We present here an architecture and tool/media interfaces for the support of tools as "plug-in" components of our replayable workspaces. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> H. Abdel-Wahab, S. Guan, and J. Nievergelt. </author> <title> Shared workspaces for group collaboration: An experiment using Internet and Unix inter-process communication. </title> <journal> IEEE Comm. Magazine, </journal> <pages> pages 10-16, </pages> <month> November </month> <year> 1988. </year>
Reference-contexts: Related work X-Window-aware systems, such as <ref> [1, 6] </ref>, in principle, allow playback of unmodified applications. However, these systems lack media integration and interacting with the underlying CSW is not possible. In media authoring, synchronization relationships are explicit, (i.e., manually crafted via scripts or flowcharts so as to balance media processing).
Reference: [2] <author> D. Anderson and R. Kuivila. </author> <title> A system for music performance. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 8(1) </volume> <pages> 56-82, </pages> <month> February </month> <year> 1990. </year>
Reference-contexts: Flexible tool coordination Next, we show how the tool coordination abstract machine supports the specification of the features of session objects. These primitives for tool coordination are specified in Appendix A. For brevity, we focus only on browsing features. Previous research in temporal access control (Tac) <ref> [2, 12, 18, 20] </ref>, show modeling of "Vcr-like" 6 | e.g., assuming (A V W ), at the end of an audio frame. 7 | e.g., on both the window and video streams. 6 browsing features as temporal transformations over a logical time system.
Reference: [3] <author> D. Bulterman, G. van Rossum, and R. van Liere. </author> <title> A structure for transportable, dynamic multimedia documents. </title> <booktitle> In Proc. of the Summer 1991 USENIX Conference, </booktitle> <pages> pages 137-154, </pages> <address> Nashville, TN, USA., </address> <month> June </month> <year> 1991. </year>
Reference-contexts: In our artifact generation (i.e., the capture of interactive CSW sessions), synchronization relationships are implicit, (i.e., a user-transparent process). Although our research then seems similar to interactive multimedia presentation research 5 <ref> [3, 4] </ref>, we focus on fine-grain integration of heterogeneous media streams as opposed to orchestration of heterogeneous document parts. Transportable active objects are also found in Java. Our architecture represents a framework that will allow such program capsules to replay platform-independent CSWs. We are currently pursuing this research.
Reference: [4] <author> M. Cecelia-Buchanan and P. Zellweger. </author> <title> Scheduling multimedia documents using temporal constraints. </title> <booktitle> In Proc. of the 3rd Int'l Workshop on Network and Operating System Support for Digital Audio and Video, </booktitle> <pages> pages 237-249, </pages> <address> La Jolla, CA, USA, </address> <month> November </month> <year> 1992. </year>
Reference-contexts: In our artifact generation (i.e., the capture of interactive CSW sessions), synchronization relationships are implicit, (i.e., a user-transparent process). Although our research then seems similar to interactive multimedia presentation research 5 <ref> [3, 4] </ref>, we focus on fine-grain integration of heterogeneous media streams as opposed to orchestration of heterogeneous document parts. Transportable active objects are also found in Java. Our architecture represents a framework that will allow such program capsules to replay platform-independent CSWs. We are currently pursuing this research.
Reference: [5] <author> C. Clauer, J. Kelly, T. Rosenberg, C. Rasmussen, P. Stauning, E. Friis-Christensen, R. Niciejewski, T. Killeen, S. Mende, Y. Zambre, T. Weymouth, A. Prakash, G. O. S.E. McDaniel, T. Finholt, and D. Atkins. </author> <title> A new project to support scientific collaboration electronically. </title> <journal> EOS Transactions on American Geophysical Union, </journal> <volume> 75, </volume> <month> June 28 </month> <year> 1994. </year>
Reference-contexts: Such asynchronously-shared CSWs are referred herein as replayable workspaces 1 . Our long-term research focuses on the development of toolkits to support collaboration paradigms such as the asynchronous sharing of CSWs. This research is partially motivated by the needs of two projects at the University of Michigan: Uarc <ref> [5] </ref> and the Medical Collab (Mdc). Specifically, in the Mdc, our goal is the asynchronous sharing of the CSW of a radiologist. To demonstrate our replayable workspace concepts, we used the University Hospital of Geneva's Osiris II tool 2 .
Reference: [6] <author> E. Craighill, R. Lang, M. Fong, and K. Skinner. CECED: </author> <title> A system for informal multimedia collaboration. </title> <booktitle> In Proc. of ACM Multimedia '93, </booktitle> <pages> pages 436-446, </pages> <address> CA, USA, </address> <month> August </month> <year> 1993. </year>
Reference-contexts: Related work X-Window-aware systems, such as <ref> [1, 6] </ref>, in principle, allow playback of unmodified applications. However, these systems lack media integration and interacting with the underlying CSW is not possible. In media authoring, synchronization relationships are explicit, (i.e., manually crafted via scripts or flowcharts so as to balance media processing).
Reference: [7] <author> R. Dannenberg, T. Neuendorffer, J. Newcomer, D. Rubine, and D. Anderson. Tactus: </author> <title> toolkit-level support for syn chronized interactive multimedia. </title> <journal> Multimedia Systems, </journal> <volume> 1(1) </volume> <pages> 77-86, </pages> <month> 1 </month> <year> 1993. </year>
Reference-contexts: Through reliance on a re-executable input model, our media-oriented QoS requirements relaxes into a range such as needed by voice-annotated window events | i.e., a less QoS-restricted range ([250 1000]ms) [23], feasible for application-level support [13]. Media servers rely on a tighly-coupled media/synchronization server <ref> [7, 20] </ref> for fine-grained synchronization and processing of pre-selected continuous media. Such coupling can be inflexible | through media-integration that is dependent on the media types being handled.
Reference: [8] <author> J. Herlocker and J. Konstan. </author> <title> Commands as media: design and implementation of a command stream. </title> <booktitle> In Proc. of ACM Multimedia '95, </booktitle> <pages> pages 155-166, </pages> <address> San Francisco, CA, </address> <month> November </month> <year> 1995. </year>
Reference-contexts: Although a sporadic server can be used for integration of discrete/continuous media with hard guarantees [9, 22], this assumes that any discrete event can execute within the time bound provided. For some tms, (e.g., a command stream <ref> [8] </ref>), a feasible time bound for LDU re-execution may not be practical. We focus on application-level integration of heterogeneous media and show how it is designed to statistically support a range of media-oriented QoS requirements. 4. Architecture overview A CSW is composed of multiple tools.
Reference: [9] <author> K. Jeffay. </author> <title> On latency management in time-shared operating systems. </title> <booktitle> In Proc. of the 11th IEEE Workshop on Real-Time Operating Systems and Software, </booktitle> <pages> pages 86-90, </pages> <address> Seattle, WA, USA, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: Our research on abstract machines for media-independent tool coordination would then become central to support "plug-in" compliance of tools to this kernel extension. Although a sporadic server can be used for integration of discrete/continuous media with hard guarantees <ref> [9, 22] </ref>, this assumes that any discrete event can execute within the time bound provided. For some tms, (e.g., a command stream [8]), a feasible time bound for LDU re-execution may not be practical.
Reference: [10] <author> K. Jeffay, D. Stone, and F. Donelson. </author> <title> Kernel support for live digital audio and video. </title> <journal> Computer Communications, </journal> <volume> 15(6) </volume> <pages> 388-395, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: The playback of stored media requires addressing three basic overheads: (1) fetch, (2) processing, and (3) presentation. Research on management of fetch overheads [19, 20] and scheduling overheads <ref> [10, 17] </ref> focuses on (low-level) system extensions to meet media requirements for continuous media. Our work focuses on application-level management and can be built on top of such extensions. Kernel-level management of additive overheads between competing processes is approached in [16].
Reference: [11] <author> L. Li, A. Karmouch, and N. Georganas. </author> <title> Multimedia teleorchestra with independent sources: Part 1 | temporal modeling of collaborative multimedia scenarios. </title> <journal> Multimedia Systems, </journal> <volume> 1(2) </volume> <pages> 143-153, </pages> <year> 1994. </year>
Reference-contexts: Our architecture uses the session manager as a centralized resource to address media integration between stream controllers. To ameliorate inter-process communication (IPC) overheads, the synchronization infrastructure uses flexible intervals coupled with relative scheduling to handle integration of asynchronous tms, as in <ref> [11, 13] </ref>. An interval is a sequence of consecutive tms events that is delimit at each end by a synchronization event. For example, the i th such interval is (s i ; e 1 ; e n ; s i+1 ).
Reference: [12] <author> T. Little. </author> <title> A framework for synchronous delivery of time-dependent multimedia systems. </title> <journal> Multimedia Systems, </journal> <volume> 1(1):87 94, </volume> <year> 1993. </year>
Reference-contexts: Flexible tool coordination Next, we show how the tool coordination abstract machine supports the specification of the features of session objects. These primitives for tool coordination are specified in Appendix A. For brevity, we focus only on browsing features. Previous research in temporal access control (Tac) <ref> [2, 12, 18, 20] </ref>, show modeling of "Vcr-like" 6 | e.g., assuming (A V W ), at the end of an audio frame. 7 | e.g., on both the window and video streams. 6 browsing features as temporal transformations over a logical time system.
Reference: [13] <author> N. Manohar and A. Prakash. </author> <title> Dealing with synchronization and timing variability in the playback of interactive session recordings. </title> <booktitle> In Proc. of ACM Multimedia '95, </booktitle> <pages> pages 45-56, </pages> <address> San Francisco, CA, </address> <month> November </month> <year> 1995. </year>
Reference-contexts: There are two basic approaches. In the first approach, the services of multiple tools are integrated into a monolithic-application | using carefully orchestrated, cooperating threads. Our previous prototype followed this approach <ref> [13] </ref>. This approach delivers complete control over tool coordination and media integration since, at the thread level, fine-grained scheduling and synchronization control is possible. Unfortunately, this low-level control also limits the flexibility of the resulting infrastructure. In the second approach, each tool remains a user-level process in the replayable workspace. <p> In general, application-level media integration can not meet the full QoS requirements spectrum. Through reliance on a re-executable input model, our media-oriented QoS requirements relaxes into a range such as needed by voice-annotated window events | i.e., a less QoS-restricted range ([250 1000]ms) [23], feasible for application-level support <ref> [13] </ref>. Media servers rely on a tighly-coupled media/synchronization server [7, 20] for fine-grained synchronization and processing of pre-selected continuous media. Such coupling can be inflexible | through media-integration that is dependent on the media types being handled. <p> Each continuity/synchronization tradeoff level is supported by a protocol and its associated synchronization treatment. When a stream controller falls "out-of-synch" wrt its master, several remedial treatments are possible. The various synchronization treatments supported are summarized in Table 3 (also in <ref> [13] </ref>). In the next section, will show how various treatments relate to continuity/synchronization tradeoff levels. Here, we describe the synchronization infrastructure that supports the various protocols of Table 3. Our architecture uses the session manager as a centralized resource to address media integration between stream controllers. <p> Our architecture uses the session manager as a centralized resource to address media integration between stream controllers. To ameliorate inter-process communication (IPC) overheads, the synchronization infrastructure uses flexible intervals coupled with relative scheduling to handle integration of asynchronous tms, as in <ref> [11, 13] </ref>. An interval is a sequence of consecutive tms events that is delimit at each end by a synchronization event. For example, the i th such interval is (s i ; e 1 ; e n ; s i+1 ). <p> be specified over which stream controller (i.e., lhs or an rhs) is to be notified first. 11 | Although assumes bounded delay, reliable Fifo delivery, our Ipc is limited to intra-workstation messages. 12 | For example, under protocol P3, the average time f (T ) is close to T =2 <ref> [13] </ref>. 10 We are also interest in the duration in real time (RT) of a scheduling interval (T fl ), measured as: T fl = RT (s i ) RT (s i1 ) (7) but when blocking protocols are used, we approximate T fl as: T fl T + t sync <p> In particular, in our case, t latency becomes negligible wrt T . Since f (T ) is a function of the protocol, T , and the load conditions <ref> [13] </ref>, this results in relatively large f (T ) values. <p> Good continuity calls constant and small q. The efficiency metric q depends, primarily, on the synchronization effort f (T ) | (applied to the inter-stream asynchrony). We can design synchronization protocols to perform at various f (T ) values by allocating effort on detection and treatment of asynchrony conditions <ref> [13] </ref>. Consequently, we can obtain various tradeoff levels between synchronization and continuity. 8. Experience We have preliminary experience on the use of the framework outlined in this paper in the context of the medical collaboratory project. <p> Our architecture uses loosely-coupled applications, in order to provide more flexibility in integrating various independent tools. Synchronization overheads due to inter-process communication between the session manager and the tools are higher than they would be in a monolithic application, such as that described in <ref> [13] </ref>. Those overheads basically depend on the value of t latency as compared to the value of T , the synchronization interval. The values of t latency on most workstations is variable but usually less than 10ms. <p> Since t latency is small compared to T , it contributes little to the value of q or variations in q. The results of the various synchronization protocols for one frhs; lhsg pair in a tightly-coupled application were reported in <ref> [13] </ref>. There, we showed that, it is important to choose the appropriate synchronization treatments between the streams, taking into account the nature of the streams. <p> For instance, in the case of audio and window streams, it is better to make audio a master stream (for continuity) and window a slave stream (for synchronization). Given the synchronization relationships between the streams, the use of adaptive protocols such as P3 or P5, as shown in <ref> [13] </ref> can reduce both the value and variations in asynchrony, and thus f (T ). Thus, use of adaptive protocols can help in reducing the value of q and the variations in q. 9.
Reference: [14] <author> N. Manohar and A. Prakash. </author> <title> The Session Capture and Replay Paradigm for Asynchronous Collaboration. </title> <booktitle> In Proc. of European Conference on Computer Supported Cooperative Work (ECSCW)'95, </booktitle> <pages> pages 161-177, </pages> <address> Stockholm, Sweden, </address> <month> September </month> <year> 1995. </year>
Reference-contexts: Our approach addresses the above goals by supporting the asynchronous sharing of interactive CSWs | through the use of session objects <ref> [14] </ref>. Such asynchronously-shared CSWs are referred herein as replayable workspaces 1 . Our long-term research focuses on the development of toolkits to support collaboration paradigms such as the asynchronous sharing of CSWs. <p> State data provides the basis for a restartable process formulation that allows re-execution of events at an arbitrary time-index. Finally, session objects are transportable objects, rooted as a file hierarchy of media directories <ref> [14] </ref>. The session manager remains unaware of stream-dependent details such as naming scheme, data locality, re-execution device, or layout of stream controller repositories. The data of a stream controller is currently represented using standard Unix filesystem support (i.e., byte-stream files and directories).
Reference: [15] <author> N. Manohar and A. Prakash. </author> <title> A flexible architecture for heterogeneous media integration on replayable workspaces. </title> <booktitle> In Proc. Third IEEE Int'l Conf on Multimedia Computing and Systems, to appear, </booktitle> <address> Hiroshima, Japan, </address> <month> June </month> <year> 1996. </year>
Reference-contexts: A user-level process, referred to as a session manager, coordinates these temporally-aware tools (stream controllers). Fig. 5 illustrates our replayable workspace architecture (see <ref> [15] </ref>). The session manager manipulates these stream controllers through simple "VCR-like" commands | regardless of the services provided by the tools. <p> By complying with these interfaces, a stream controller delivers temporal-awareness to services from its respective CSW tool to the collective replayable workspace. To support tool coordination and media integration, every stream controller must comply with three inter-process interfaces wrt the session manager (Fig. 8) <ref> [15] </ref>: functional interface (F): supports tool coordination | its primitives provide abstract machines that build the features of session objects. synchronization interface (S,D): supports media integration | its primitives support fine-grained inter-media relation ships between tms. feedback interface (M): supports the evaluation of the efficiency of the above interfaces.
Reference: [16] <author> C. Mercer, S. Savage, and H. Tokuda. </author> <title> Processor Capacity Reserves for Multimedia Operating Systems. </title> <booktitle> In Proceedings of the IEEE ICMCS, </booktitle> <month> May </month> <year> 1994. </year>
Reference-contexts: Our work focuses on application-level management and can be built on top of such extensions. Kernel-level management of additive overheads between competing processes is approached in <ref> [16] </ref>. One could visualize our session manager as a kernel process for support of replayable workspaces on future multimedia operating systems. Our research on abstract machines for media-independent tool coordination would then become central to support "plug-in" compliance of tools to this kernel extension.
Reference: [17] <author> J. Nakajima, M. Yazaki, and H. Matsumoto. </author> <title> Multimedia/realtime extensions for the Mach operating system. </title> <booktitle> In Proc. of the Summer USENIX Conference, </booktitle> <pages> pages 183-196, </pages> <address> Nashville, TN, USA, </address> <month> Summer </month> <year> 1991. </year>
Reference-contexts: The playback of stored media requires addressing three basic overheads: (1) fetch, (2) processing, and (3) presentation. Research on management of fetch overheads [19, 20] and scheduling overheads <ref> [10, 17] </ref> focuses on (low-level) system extensions to meet media requirements for continuous media. Our work focuses on application-level management and can be built on top of such extensions. Kernel-level management of additive overheads between competing processes is approached in [16].
Reference: [18] <author> S. Ramanathan and P. V. Rangan. </author> <title> Continuous media synchronization in distributed multimedia systems. </title> <booktitle> In Proc. of the 3rd Int'l Workshop on Network and Operating System Support for Digital Audio and Video, </booktitle> <pages> pages 328-335, </pages> <address> La Jolla, CA, USA, </address> <month> November </month> <year> 1992. </year>
Reference-contexts: Flexible tool coordination Next, we show how the tool coordination abstract machine supports the specification of the features of session objects. These primitives for tool coordination are specified in Appendix A. For brevity, we focus only on browsing features. Previous research in temporal access control (Tac) <ref> [2, 12, 18, 20] </ref>, show modeling of "Vcr-like" 6 | e.g., assuming (A V W ), at the end of an audio frame. 7 | e.g., on both the window and video streams. 6 browsing features as temporal transformations over a logical time system.
Reference: [19] <author> P. V. Rangan and H. M. Vin. </author> <title> Designing file systems for digital video and audio. </title> <journal> ACM Transactions of Computer Systems, </journal> <volume> 18(2) </volume> <pages> 197-222, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: The playback of stored media requires addressing three basic overheads: (1) fetch, (2) processing, and (3) presentation. Research on management of fetch overheads <ref> [19, 20] </ref> and scheduling overheads [10, 17] focuses on (low-level) system extensions to meet media requirements for continuous media. Our work focuses on application-level management and can be built on top of such extensions. Kernel-level management of additive overheads between competing processes is approached in [16].
Reference: [20] <author> L. Rowe and B. Smith. </author> <title> A Continuous Media Player. </title> <booktitle> In Proc. of the 3rd Int'l Workshop on Network and Operating System Support for Digital Audio and Video, </booktitle> <pages> pages 376-386, </pages> <address> La Jolla, CA, USA, </address> <month> November </month> <year> 1992. </year>
Reference-contexts: Through reliance on a re-executable input model, our media-oriented QoS requirements relaxes into a range such as needed by voice-annotated window events | i.e., a less QoS-restricted range ([250 1000]ms) [23], feasible for application-level support [13]. Media servers rely on a tighly-coupled media/synchronization server <ref> [7, 20] </ref> for fine-grained synchronization and processing of pre-selected continuous media. Such coupling can be inflexible | through media-integration that is dependent on the media types being handled. <p> The playback of stored media requires addressing three basic overheads: (1) fetch, (2) processing, and (3) presentation. Research on management of fetch overheads <ref> [19, 20] </ref> and scheduling overheads [10, 17] focuses on (low-level) system extensions to meet media requirements for continuous media. Our work focuses on application-level management and can be built on top of such extensions. Kernel-level management of additive overheads between competing processes is approached in [16]. <p> Flexible tool coordination Next, we show how the tool coordination abstract machine supports the specification of the features of session objects. These primitives for tool coordination are specified in Appendix A. For brevity, we focus only on browsing features. Previous research in temporal access control (Tac) <ref> [2, 12, 18, 20] </ref>, show modeling of "Vcr-like" 6 | e.g., assuming (A V W ), at the end of an audio frame. 7 | e.g., on both the window and video streams. 6 browsing features as temporal transformations over a logical time system.
Reference: [21] <author> R. Steinmetz. </author> <title> Synchronization properties in multimedia systems. </title> <journal> IEEE Journal of Selected Areas of Communication, </journal> <volume> 8(3) </volume> <pages> 401-411, </pages> <month> April </month> <year> 1990. </year>
Reference-contexts: Table 4. Adaptive mechanisms for inter-stream synchronization. 5. Media model Our media integration model is based on synchronization events coupled with a master/slave model | both widely accepted in the synchronization literature <ref> [21] </ref>. Our contribution focuses on flexible, application-level support for heterogeneous media integration. Based on individual tms tolerances and requirements, a relative tradeoff between synchronization and continuity can be associated with each master/slave relationship. Each continuity/synchronization tradeoff level is supported by a protocol and its associated synchronization treatment.
Reference: [22] <author> R. Steinmetz. </author> <title> Analyzing the multimedia operating system. </title> <journal> IEEE MultiMedia, </journal> <volume> 2(1) </volume> <pages> 68-84, </pages> <month> Spring </month> <year> 1995. </year>
Reference-contexts: Our research on abstract machines for media-independent tool coordination would then become central to support "plug-in" compliance of tools to this kernel extension. Although a sporadic server can be used for integration of discrete/continuous media with hard guarantees <ref> [9, 22] </ref>, this assumes that any discrete event can execute within the time bound provided. For some tms, (e.g., a command stream [8]), a feasible time bound for LDU re-execution may not be practical.
Reference: [23] <author> R. Steinmetz and K. Nahrstedt. </author> <title> Chapter 15: </title> <booktitle> Synchronization, </booktitle> <pages> pages 585-595. </pages> <publisher> Prentice Hall, </publisher> <year> 1995. </year> <month> 15 </month>
Reference-contexts: Transportable active objects are also found in Java. Our architecture represents a framework that will allow such program capsules to replay platform-independent CSWs. We are currently pursuing this research. Steinmetz characterized media-oriented QoS (e.g., synchronization and continuity) requirements in <ref> [23] </ref>. In general, application-level media integration can not meet the full QoS requirements spectrum. Through reliance on a re-executable input model, our media-oriented QoS requirements relaxes into a range such as needed by voice-annotated window events | i.e., a less QoS-restricted range ([250 1000]ms) [23], feasible for application-level support [13]. <p> (e.g., synchronization and continuity) requirements in <ref> [23] </ref>. In general, application-level media integration can not meet the full QoS requirements spectrum. Through reliance on a re-executable input model, our media-oriented QoS requirements relaxes into a range such as needed by voice-annotated window events | i.e., a less QoS-restricted range ([250 1000]ms) [23], feasible for application-level support [13]. Media servers rely on a tighly-coupled media/synchronization server [7, 20] for fine-grained synchronization and processing of pre-selected continuous media. Such coupling can be inflexible | through media-integration that is dependent on the media types being handled.
References-found: 23

