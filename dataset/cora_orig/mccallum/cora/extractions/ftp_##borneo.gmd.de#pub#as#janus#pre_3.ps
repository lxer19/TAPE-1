URL: ftp://borneo.gmd.de/pub/as/janus/pre_3.ps
Refering-URL: http://borneo.gmd.de/AS/janus/publi/publi.html
Root-URL: 
Email: smieja@gmdzi.uucp  muehlen@gmdzi.uucp  
Author: H. Muhlenbein 
Keyword: Reflective Modular Neural Network Systems  Keywords: Reflective architecture, Pandemonium, task decomposition, confidence, reliability.  
Date: March 13, 1992  
Address: Schlo Birlinghoven, 5205 St. Augustin 1, Germany.  
Affiliation: German National Research Centre for Computer Science (GMD),  
Note: F.J. Smieja  
Abstract: GMD Report #633 Abstract Many of the current artificial neural network systems have serious limitations, concerning accessibility, flexibility, scaling and reliability. In order to go some way to removing these we suggest a reflective neural network architecture. In such an architecture, the modular structure is the most important element. The building-block elements are called "minos' modules. They perform self-observation and inform on the current level of development, or scope of expertise, within the module. A Pandemonium system integrates such submodules so that they work together to handle mapping tasks. Network complexity limitations are attacked in this way with the Pandemonium problem decomposition paradigm, and both static and dynamic unreliability of the whole Pandemonium system is effectively eliminated through the generation and interpretation of confidence and ambiguity measures at every moment during the development of the system. Two problem domains are used to test and demonstrate various aspects of our architecture. Reliability and quality measures are defined for systems that only answer part of the time. Our system achieves better quality values than single networks of larger size for a handwritten digit problem. When both second and third best answers are accepted, our system is left with only 5% error on the test set, 2.1% better than the best single net. It is also shown how the system can elegantly learn to handle garbage patterns. With the parity problem it is demonstrated how complexity of problems may be decomposed automatically by the system, through solving it with networks of size smaller than a single net is required to be. Even when the system does not find a solution to the parity problem, because networks of too small a size are used, the reliability remains around 99-100%. Our Pandemonium architecture gives more power and flexibility to the higher levels of a large hybrid system than a single net system can, offering useful information for higher-level feedback loops, through which reliability of answers may be intelligently traded for less reliable but important "intuitional" answers. In providing weighted alternatives and possible generalizations, this architecture gives the best possible service to the larger system of which it will form part. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> L. Bochereau, P. Bourgine, and H. E. Priso. </author> <title> Generalist vs. specialist neural networks. </title> <type> Technical report, </type> <institution> CEMAGREF, France, </institution> <year> 1991. </year>
Reference-contexts: of parallel experts, how do we recombine the results to form a full answer? One may solve this using adaptive sub-module weighting methods [21, 8], individual sub-module reference vectors [9], pre-determined sub-module functionality followed by "connectionist gluing" of the functionalities together [36, 19], or dynamically determined and tabulated sub-module specialities <ref> [1] </ref>. In hierarchical sub-tasking it is observed that the global task can be usefully split up in a vertical manner, as a number of quasi-independent sub-tasks, that may simultaneously, or sequentially, influence the overall output. <p> the specialized modules is likely to give the correct answer, at any time (figure 2)? Other modular techniques get around the first question either by explicitly deciding how the problem will be decomposed, or deciding at a certain point in learning to form a new expert to resolve some conflict <ref> [21, 1] </ref>. Some approaches to the second question were discussed in section 2. The problem was considered in depth in [9], in which it was eventually decided to use a reference linear vector quantizer (LVQ) method to label regions of expertness.
Reference: [2] <author> V. Ruiz de Angulo and C. Torras. </author> <title> Minimally disturbing learning. </title> <editor> In A. Prieto, editor, </editor> <booktitle> Proceedings of the IWANN 91. </booktitle> <publisher> Springer Verlag, </publisher> <year> 1991. </year>
Reference-contexts: By dealing with the shape of the output, rather than the simple squared-error measure, we can more effectively find the network that can learn the pattern with the least amount of destructive learning <ref> [30, 5, 2] </ref>. Theoretically, the argument is that the generalization properties of a network are determined by its set of hyperplanes in pattern-space (input ! hidden) and in hidden-space (hidden ! output). These hyperplanes are constructed during the learning, through the mapping of the training set patterns.
Reference: [3] <author> S. Eberlein. </author> <title> Developing a decision-making network for a rover. </title> <journal> Journal of Neural Computation, </journal> <volume> 1(2), </volume> <year> 1989. </year>
Reference-contexts: Simultaneous sub-tasking is demonstrated in [25, 17, 4], while strictly hierarchical decomposition has been tried in <ref> [3, 4] </ref> and numerous hybrid neural methods, where the problem is separated into a number of distinct and consecutive sub-tasks. Indeed hierarchical systematic decomposition is always borne in mind when one intends (as we do) to develop general flexible and autonomous systems.
Reference: [4] <author> G.M. Edelman. </author> <title> Neural Darwinism. The theory of neuronal group selection. </title> <publisher> Basic Books, </publisher> <address> New York, </address> <year> 1987. </year>
Reference-contexts: In hierarchical sub-tasking it is observed that the global task can be usefully split up in a vertical manner, as a number of quasi-independent sub-tasks, that may simultaneously, or sequentially, influence the overall output. Simultaneous sub-tasking is demonstrated in <ref> [25, 17, 4] </ref>, while strictly hierarchical decomposition has been tried in [3, 4] and numerous hybrid neural methods, where the problem is separated into a number of distinct and consecutive sub-tasks. <p> Simultaneous sub-tasking is demonstrated in [25, 17, 4], while strictly hierarchical decomposition has been tried in <ref> [3, 4] </ref> and numerous hybrid neural methods, where the problem is separated into a number of distinct and consecutive sub-tasks. Indeed hierarchical systematic decomposition is always borne in mind when one intends (as we do) to develop general flexible and autonomous systems.
Reference: [5] <author> R. M. </author> <title> French. Using semi-distributed representations to overcome catastrophic forgetting in connectionist networks. </title> <type> Technical Report CRCC-51-1991, </type> <institution> Indiana University, Bloomington, Indiana, </institution> <year> 1991. </year>
Reference-contexts: Thus without some fixed point on the optimization of the current association, the subtleties of learning this generalization among the previous ones will be lost, and the previous ones unavoidably "catastrophically unlearned" <ref> [5] </ref> in order to accommodate the current one most easily. Such drawbacks must also be dealt with, before a neural network system can be claimed to be robust to changing environments. With our reflective architecture we propose to deal with the above points in the following way. <p> By dealing with the shape of the output, rather than the simple squared-error measure, we can more effectively find the network that can learn the pattern with the least amount of destructive learning <ref> [30, 5, 2] </ref>. Theoretically, the argument is that the generalization properties of a network are determined by its set of hyperplanes in pattern-space (input ! hidden) and in hidden-space (hidden ! output). These hyperplanes are constructed during the learning, through the mapping of the training set patterns.
Reference: [6] <author> I. Guyon. </author> <title> Applications of neural networks to character recognition. </title> <journal> International Journal of Pattern Recognition and Artificial Intelligence, </journal> <volume> 5(1-2):353-382, </volume> <year> 1991. </year>
Reference-contexts: Tolerance for all learning was set at tol = 0:2. The Pandemonium systems consisted of 3 minos modules. A "clean-peak" filter was also used at the output of the net systems. This is commonly used (in varying forms) in digit and character recognition experiments <ref> [10, 6] </ref>. It disallowed answers that do not consist of a clear peak at just one node. Our criterion was that the peak was to be 0:7, AND the other positions 0:3. This is reasonable, when one considers the learn tolerance was set at 0.2.
Reference: [7] <author> S. Hubrig-Schaumburg. </author> <title> Handwritten character recognition using a reflective modular neural network system. </title> <type> Master's thesis, </type> <institution> Bonn University, Germany, </institution> <year> 1992. </year>
Reference-contexts: Such things were however not of utmost importance at this stage, since the objective is to study the relative performances of the single net and a Pandemonium. Further experiments are currently being performed, with larger digits (pixel size 16x24) and with 3000 original exemplars <ref> [7] </ref>), and these results will be published elsewhere. 280 digits were written by 2 people (14 exemplars of the 10 digit classes each), and 250 were written by the third person (a further 25 exemplars for each class).
Reference: [8] <author> R. A. Jacobs and M. I. Jordan. </author> <title> Adaptive mixtures of local experts. </title> <journal> Neural Computation, </journal> <volume> 3(1), </volume> <year> 1991. </year>
Reference-contexts: With such techniques there always exists the "integration problem": having broken up the tasks over a number of parallel experts, how do we recombine the results to form a full answer? One may solve this using adaptive sub-module weighting methods <ref> [21, 8] </ref>, individual sub-module reference vectors [9], pre-determined sub-module functionality followed by "connectionist gluing" of the functionalities together [36, 19], or dynamically determined and tabulated sub-module specialities [1].
Reference: [9] <author> K. Joe, Y. Mori, and S. Miyake. </author> <title> Construction of a large-scale neural network: simulation of handwritten Japanese character recognition on NCUBE. </title> <journal> Concurrency, Practice and Experience, </journal> <volume> 2(2) </volume> <pages> 79-107, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: With such techniques there always exists the "integration problem": having broken up the tasks over a number of parallel experts, how do we recombine the results to form a full answer? One may solve this using adaptive sub-module weighting methods [21, 8], individual sub-module reference vectors <ref> [9] </ref>, pre-determined sub-module functionality followed by "connectionist gluing" of the functionalities together [36, 19], or dynamically determined and tabulated sub-module specialities [1]. <p> The question is, how might the sets be decomposed in order to achieve such useful problem breakdown? And what are the side-effects. The first question was tackled using external and static knowledge of the pattern classification problem domain, using reference vectors in <ref> [9] </ref>, phoneme sets in [36, 19], and a Kohonen net clustering method in [18]. Our method of reflective modular neural network division is different to the methods used by other researchers mainly because we try to retain the independence and self-sufficiency properties of the sub-modules. <p> Some approaches to the second question were discussed in section 2. The problem was considered in depth in <ref> [9] </ref>, in which it was eventually decided to use a reference linear vector quantizer (LVQ) method to label regions of expertness.
Reference: [10] <author> Y. LeCun, B. Boser, J. S. Denker, D. Henderson, R. E. Howard, W. Hubbard, and L. D. Jackel. </author> <title> Backpropagation applied to handwritten zip code recognition. </title> <journal> Neural Computation, </journal> <volume> 1 </volume> <pages> 541-551, </pages> <year> 1989. </year>
Reference-contexts: Other types of quality functions may be defined. For example, Nestor Applied Systems (personal communication, Feb. 1992) use the following definition: Q Nestor := P (a) 10P (wja) 10 Q Nestor 1 (16) for their NestorReader character and digit recognizer. Le Cun et al <ref> [10] </ref> also considered the question of quality ("accuracy" and rejection), but instead of defining a general quantity, they focused on the rejection rate required when the reliability (performance on the answered questions) was to be at least 99% (i.e. the fraction of patterns that need to be rejected in order to <p> Tolerance for all learning was set at tol = 0:2. The Pandemonium systems consisted of 3 minos modules. A "clean-peak" filter was also used at the output of the net systems. This is commonly used (in varying forms) in digit and character recognition experiments <ref> [10, 6] </ref>. It disallowed answers that do not consist of a clear peak at just one node. Our criterion was that the peak was to be 0:7, AND the other positions 0:3. This is reasonable, when one considers the learn tolerance was set at 0.2.
Reference: [11] <author> A. Linden and J. Kindermann. </author> <title> Inversion of multilayer nets. </title> <booktitle> In Proceedings of the IJCNN-89, </booktitle> <address> Washington, 1989. </address> <publisher> IEEE. </publisher>
Reference-contexts: Such responses by the network are only to be expected, when one considers what in fact the network learns during its training session <ref> [11] </ref>. When it is desired to learn new patterns the progressive learning property may allow it to be done fairly easily, but it may also be found that the generalization the association represents is at odds with a number of previous associations. <p> The task of the machine was always to distinguish between classification possibilities, and not to determine whether or not the input question was a member of the super-set of all possible classifications for which it is responsible. It was shown in <ref> [11] </ref> how the essential elements of a class|its "template" pattern|that the network itself learns, may be very different from what we consider to be a typical exemplar.
Reference: [12] <author> G. F. Marcus, M. Ullman, S. Pinker, M. Hollander, T. J. Rosen, and F. Xu. Overregularization. </author> <type> Technical Report Occasional paper 41, </type> <institution> MIT Center for Cognitive Science, </institution> <month> November </month> <year> 1990. </year>
Reference-contexts: This may be likened to a crude form of an overregularization problem in language learning by children: add "-ed" to every verb to form the past tense <ref> [12] </ref>, since the great majority of cases require it. The problem then of forming hyperplanes between possibilities, and sectioning off this kind of answer, is completely up to the system's discriminator (the Monitor networks).
Reference: [13] <author> M. Minsky. </author> <title> The Society of Mind. </title> <publisher> Simon and Schuster, </publisher> <address> New York, </address> <year> 1985. </year>
Reference-contexts: When the development of the Worker net has reached a certain level, it is permitted to introduce new modules if necessary. Our reflective modular neural network architecture is similar in spirit to Minsky's "Society of Mind" <ref> [13] </ref>. The notion was put forward as a way of releasing the would-be brain designer from the headaches and prohibitiveness of scaling and control complexity.
Reference: [14] <author> M. Minsky and S. Papert. </author> <title> Perceptrons. </title> <publisher> MIT Press, </publisher> <year> 1988. </year> <note> See particularly the Epilogue. </note>
Reference-contexts: Missing however was the method and architecture with which to do this. Muhlenbein [15], and once again Minsky <ref> [14] </ref>, remark that the next generation of neural network systems will require much more of a directed evolution in their construction, so that specialization and modular society structures can be developed.
Reference: [15] <author> H. Muhlenbein. </author> <title> Limitations of multilayer perceptrons steps towards genetic neural networks. </title> <journal> Parallel Computing, </journal> <volume> 14(3) </volume> <pages> 249-260, </pages> <year> 1990. </year>
Reference-contexts: With this measure a purely random mapping has a complexity of M c 0:5, since about half the nearest neighbour points are foreign, the parity problem has the maximum complexity M c = 1 (all nearest neighbour points are foreign), and for the "=1" problem <ref> [15] </ref>, the maximum value, for N I = 3, is M c = 0:56. Easy problems such as separating a single pattern from all others, has intrinsic M c that diminishes to zero with N I very quickly, actually given by M c = 2 (N I 1) . <p> What we need to prevent in decomposing the problem domain, is that we lose hope of generalization, which is one of the most important aspects of using neural networks at all <ref> [29, 15] </ref>. Random allocation of tasks is unlikely to provide us with generalization benefits from the Pandemonium system. <p> This is for the same reasons that a single network finds it more improbable to solve higher dimensional parity problems [33]. It is not that it is not possible (as shown in <ref> [15] </ref>), when the minimal number of hidden units are present, but that it is harder to find the solution. For the Pandemonium case of the last section it is also more unlikely that the sub-networks arrange themselves in the ideal configuration, as S and/or H scale. <p> He insisted that the large-scale advances could only be handled through some sort of modular paradigm, that involved employment of many experts, or little "minds", all working together to solve problems at a decomposed level. Missing however was the method and architecture with which to do this. Muhlenbein <ref> [15] </ref>, and once again Minsky [14], remark that the next generation of neural network systems will require much more of a directed evolution in their construction, so that specialization and modular society structures can be developed.
Reference: [16] <author> H. Muhlenbein and J. Kindermann. </author> <title> The dynamics of evolution and learning towards genetic neural networks. </title> <editor> In R. Pfeifer, Z. Schreter, F. Fogelman, and L. Steels, editors, </editor> <booktitle> Connectionism in Perspective, </booktitle> <address> Amsterdam, </address> <year> 1989. </year> <title> Elsevier. </title> <booktitle> Proceedings of the International Conference Connectionism in Perspective, </booktitle> <institution> University of Zurich, </institution> <month> 10-13 October </month> <year> 1988. </year>
Reference-contexts: The larger and more horrendously complicated a net becomes, the less we understand and can control what is or may be occurring in it. Even apart from complexity and capacity difficulties, which might be dealt with through some particular "divide-and-conquer" technique <ref> [16] </ref>, there are other problems related to most neural network models. One is confronted with them when it is desired that the system really does operate in an adaptable and "malleable" way. This belongs to the general notion of progressive learning.
Reference: [17] <author> J. M. Murre, R. H. Pfaf, and G. Wolters. </author> <title> CALM networks: A modular approach to supervised and unsupervised learning. </title> <booktitle> In Proceedings of the IJCNN-89. IEEE, </booktitle> <year> 1989. </year>
Reference-contexts: In hierarchical sub-tasking it is observed that the global task can be usefully split up in a vertical manner, as a number of quasi-independent sub-tasks, that may simultaneously, or sequentially, influence the overall output. Simultaneous sub-tasking is demonstrated in <ref> [25, 17, 4] </ref>, while strictly hierarchical decomposition has been tried in [3, 4] and numerous hybrid neural methods, where the problem is separated into a number of distinct and consecutive sub-tasks.
Reference: [18] <author> Y. Nishikawa, H. Kita, and A. Kawamura. NN/I: </author> <title> a neural network which divides and learns environments. </title> <booktitle> In Proceedings of the IJCNN-90, </booktitle> <address> Washington D.C., </address> <year> 1990. </year> <journal> IEEE. </journal> <volume> 30 </volume>
Reference-contexts: The first question was tackled using external and static knowledge of the pattern classification problem domain, using reference vectors in [9], phoneme sets in [36, 19], and a Kohonen net clustering method in <ref> [18] </ref>. Our method of reflective modular neural network division is different to the methods used by other researchers mainly because we try to retain the independence and self-sufficiency properties of the sub-modules. This will become clearer later when we describe the modules themselves (section 5).
Reference: [19] <author> L. Y. Pratt and C. A. Kamm. </author> <title> Improving a phoneme classification neural network through problem decomposition. </title> <booktitle> In Proceedings of the IJCNN-91. IEEE, </booktitle> <year> 1991. </year>
Reference-contexts: problem": having broken up the tasks over a number of parallel experts, how do we recombine the results to form a full answer? One may solve this using adaptive sub-module weighting methods [21, 8], individual sub-module reference vectors [9], pre-determined sub-module functionality followed by "connectionist gluing" of the functionalities together <ref> [36, 19] </ref>, or dynamically determined and tabulated sub-module specialities [1]. In hierarchical sub-tasking it is observed that the global task can be usefully split up in a vertical manner, as a number of quasi-independent sub-tasks, that may simultaneously, or sequentially, influence the overall output. <p> The question is, how might the sets be decomposed in order to achieve such useful problem breakdown? And what are the side-effects. The first question was tackled using external and static knowledge of the pattern classification problem domain, using reference vectors in [9], phoneme sets in <ref> [36, 19] </ref>, and a Kohonen net clustering method in [18]. Our method of reflective modular neural network division is different to the methods used by other researchers mainly because we try to retain the independence and self-sufficiency properties of the sub-modules.
Reference: [20] <author> T. L. D. Regulinski. </author> <title> On reliability of expert systems. </title> <journal> IEEE Transactions on Reliability, </journal> <note> 40(4):401, 1991. Editorial. </note>
Reference-contexts: That is, the value P (a) may turn out to be very low. The problem of reliability in real-world applications is not a new one, and has been considered in depth in relation to expert systems <ref> [20] </ref>, where the issue of usefulness vs. trustworthyness is relevant. It becomes clear that in order fairly to estimate the use of any system, both the quantities P (a) and P (cja) need to be taken account of.
Reference: [21] <author> D. L. Reilly, C. Scofield, C. Elbaum, and L. N. Cooper. </author> <title> Learning system archictectures composed of multiple learning modules. </title> <booktitle> In IEEE First International Conference on Neural Networks, </booktitle> <pages> pages 495-503, </pages> <year> 1987. </year>
Reference-contexts: With such techniques there always exists the "integration problem": having broken up the tasks over a number of parallel experts, how do we recombine the results to form a full answer? One may solve this using adaptive sub-module weighting methods <ref> [21, 8] </ref>, individual sub-module reference vectors [9], pre-determined sub-module functionality followed by "connectionist gluing" of the functionalities together [36, 19], or dynamically determined and tabulated sub-module specialities [1]. <p> the specialized modules is likely to give the correct answer, at any time (figure 2)? Other modular techniques get around the first question either by explicitly deciding how the problem will be decomposed, or deciding at a certain point in learning to form a new expert to resolve some conflict <ref> [21, 1] </ref>. Some approaches to the second question were discussed in section 2. The problem was considered in depth in [9], in which it was eventually decided to use a reference linear vector quantizer (LVQ) method to label regions of expertness.
Reference: [22] <author> D. E. Rumelhart, G. E. Hinton, and R. J. Williams. </author> <title> Learning internal representations by error propagation. </title> <journal> Nature, </journal> <volume> 323(533), </volume> <year> 1986. </year>
Reference-contexts: network should depend on the type of Worker network chosen, since part of our philosophy is also to have similar positive and negative aspects of learning in both the networks in a minos We choose the Worker net to be a feed-forward neural network, trained using the Back-Propagation learning procedure <ref> [22] </ref>. With the Monitor network it is wished that the module may comment on its ability to provide a reliable answer to the question being posed.
Reference: [23] <editor> D. E. Rumelhart and J. L. McClelland, editors. </editor> <title> Parallel Distributed Processing. Explorations in the Microstructure of Cognition, volume I, II. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1986. </year>
Reference-contexts: It may seem logical that one should strive to create modular systems of networks, but relatively few neural network programs actually actively pursue this goal. It is maybe because the message received from the first wave of the Parallel Distributed Processing (pdp) movement was one of "distributedness" of information <ref> [23] </ref>. The idea was to pull as far away as possible from standard symbol-pushing methods of information processing, that tended to concentrate on local representation of knowledge. The drawback of symbolic methods was that they required explicit specifications of interrelatedness among concepts.
Reference: [24] <author> J. H. Schmidhuber. </author> <title> Adaptive confidence and adaptive curiosity. </title> <type> Technical Report FKI-149-91, </type> <institution> Institut fur Informatik, Technische Universitat Munchen, Munich, Germany, </institution> <year> 1991. </year>
Reference-contexts: During learning, the whole system adapts, so that the confidence changes dynamically as well as the output. This idea of using one network to monitor the progress of another has also been employed in exploration [34] and control <ref> [24] </ref>. In these approaches it was attempted to reproduce the current error of the other network with respect to its target mapping (so that robot configurations of 7 high error might be explored and better learned).
Reference: [25] <author> M. Sekiguchi, S. Nagata, and K. Asakawa. </author> <title> Behaviour control for a mobile robot by multi-hierarchical neural network. </title> <booktitle> In Proceedings of the IEEE international conference on robotics and automation, </booktitle> <year> 1989. </year>
Reference-contexts: In hierarchical sub-tasking it is observed that the global task can be usefully split up in a vertical manner, as a number of quasi-independent sub-tasks, that may simultaneously, or sequentially, influence the overall output. Simultaneous sub-tasking is demonstrated in <ref> [25, 17, 4] </ref>, while strictly hierarchical decomposition has been tried in [3, 4] and numerous hybrid neural methods, where the problem is separated into a number of distinct and consecutive sub-tasks.
Reference: [26] <author> O. G. Selfridge. Pandemonium: </author> <title> a paradigm for learning. </title> <booktitle> In The Mechanisation of Thought Processes: Proceedings of a Symposium Held at the National Physical Laboratory, </booktitle> <month> November </month> <year> 1958, </year> <pages> pages 511-527, </pages> <address> London: HMSO, </address> <year> 1958. </year>
Reference-contexts: The question of side-effects of the overlapping regions of specialization results in the modular decomposition-recomposition problem (section 4. We return to it once more with respect to the decomposition afforded in the Pandemonium system in section 13. 3 Pandemonium The Pandemonium architecture was originally proposed in 1958 by Selfridge <ref> [26] </ref>. The idea is basically one of dividing and conquering a complex problem domain, through use of a number of specialized agents working in parallel. All these agents, or demons, process the same signal, or question, in parallel, and each provides a possible answer.
Reference: [27] <author> O. G. Selfridge and U. Neisser. </author> <title> Pattern recognition by machine. </title> <journal> Scientific American, </journal> 203(2) 60-68, August 1960. 
Reference-contexts: Equivalently, if the neural network modules are concerned with storing memories, each will be concerned with (specialized on) memorizing a certain set of memories. With this extension we retain the divide-and-conquer specialization problem-solving strategy, but where Selfridge's division resulted in local knowledge distribution (GC), or in his later applications <ref> [27] </ref> distributions of a number of non-adaptive filters, our method has knowledge partly distributed, in the neural network modules themselves.
Reference: [28] <author> F. J. Smieja. </author> <title> Evolution of intelligent systems in a changing environment: I. First steps with a structured brain. </title> <type> Technical Report 623, </type> <institution> Gesellschaft fur Mathematik und Datenverarbeitung, </institution> <address> St Augustin, Germany, </address> <month> August </month> <year> 1988. </year>
Reference-contexts: We replace each of the demons in figure 1 with a neural network module, and run the system using the divide-and-conquer principle <ref> [28, 31] </ref>. Each module will become specialized to a greater or lesser degree to a 5 particular aspect of the task. Equivalently, if the neural network modules are concerned with storing memories, each will be concerned with (specialized on) memorizing a certain set of memories.
Reference: [29] <author> F. J. Smieja. </author> <title> Learning and generalization in feed-forward neural networks. </title> <type> PhD thesis, </type> <institution> Edinburgh University, Department of Physics, </institution> <month> September </month> <year> 1989. </year> <note> Unpublished. </note>
Reference-contexts: What we need to prevent in decomposing the problem domain, is that we lose hope of generalization, which is one of the most important aspects of using neural networks at all <ref> [29, 15] </ref>. Random allocation of tasks is unlikely to provide us with generalization benefits from the Pandemonium system. <p> These hyperplanes are constructed during the learning, through the mapping of the training set patterns. If any regularities exist in the task domain <ref> [29] </ref>, then the hyperplane configurations set up in the network will be sufficient to give good estimates for the mappings of unseen patterns from the same domain. Our choice method allows us to probe the current set of relative hyperplane biases for a particular pattern, in the hidden-space.
Reference: [30] <author> F. J. Smieja. </author> <title> Hyperplane "spin" dynamics, network plasticity and back-propagation learning. </title> <type> Technical Report 634, </type> <institution> Gesellschaft fur Mathematik und Datenverarbeitung, St Augustin, Ger-many, </institution> <month> November </month> <year> 1991. </year>
Reference-contexts: By dealing with the shape of the output, rather than the simple squared-error measure, we can more effectively find the network that can learn the pattern with the least amount of destructive learning <ref> [30, 5, 2] </ref>. Theoretically, the argument is that the generalization properties of a network are determined by its set of hyperplanes in pattern-space (input ! hidden) and in hidden-space (hidden ! output). These hyperplanes are constructed during the learning, through the mapping of the training set patterns. <p> In this way a module may become an expert automatically. It would be even better if the input-space hyperplanes were used as well, in the determination of module appropriateness, and ways of doing this are being investigated. In <ref> [30] </ref> it was suggested that the maximum effort required to move an input-space hyperplane could be used directly to discover the "destructiveness" of a pattern. Note that this method does not confine itself to a particular form of the target (in figure 6 a simple classification was chosen for clarity). <p> The minos modules start off with their networks randomly initialized. The form of the initialization is as described in <ref> [30] </ref>, with the "mass" of the hyperplanes somewhat larger than usual, so that the nets may start off with a certain degree of "direction" in their specialization, given by the initial random hyperplane divisions. <p> An epoch is defined as the period in which the system sees the whole training set once. All runs were halted after 33 epochs. All nets in the Pandemonium were initialized differently, and all nets were initialized after the method described in <ref> [30] </ref>. Tolerance for all learning was set at tol = 0:2. The Pandemonium systems consisted of 3 minos modules. A "clean-peak" filter was also used at the output of the net systems. This is commonly used (in varying forms) in digit and character recognition experiments [10, 6].
Reference: [31] <author> F. J. Smieja. </author> <title> Multiple network systems (MINOS) modules: Task division and module discrimination. </title> <booktitle> In Proceedings of the 8th AISB conference on Artificial Intelligence, </booktitle> <address> Leeds, </address> <month> 16-19 April, </month> <year> 1991, 1991. </year> <note> Also available as GMD technical report 638. </note>
Reference-contexts: We replace each of the demons in figure 1 with a neural network module, and run the system using the divide-and-conquer principle <ref> [28, 31] </ref>. Each module will become specialized to a greater or lesser degree to a 5 particular aspect of the task. Equivalently, if the neural network modules are concerned with storing memories, each will be concerned with (specialized on) memorizing a certain set of memories. <p> With the Monitor network it is wished that the module may comment on its ability to provide a reliable answer to the question being posed. We noted in our forerunner of this paper <ref> [31] </ref> that there are various possibilities for this, ranging from table-lookup to error-estimation techniques, such as mentioned above.
Reference: [32] <author> F. J. Smieja. </author> <title> Neural network constructive algorithms: Trading generalization for learning efficiency? Circuits, </title> <journal> Systems and Signal Processing, </journal> <volume> 12(2) </volume> <pages> 331-374, </pages> <year> 1993. </year>
Reference-contexts: In order to explain how this might be possible, we define a simple mathematical measure of mapping complexity, for the special case of a 2-class mapping problem. This complexity measure, M c , was suggested in <ref> [33, 32] </ref>.
Reference: [33] <author> F. J. Smieja and H. Muhlenbein. </author> <title> The geometry of multilayer perceptron solutions. </title> <journal> Parallel Computing, </journal> <volume> 14(3) </volume> <pages> 261-276, </pages> <year> 1990. </year>
Reference-contexts: In order to explain how this might be possible, we define a simple mathematical measure of mapping complexity, for the special case of a 2-class mapping problem. This complexity measure, M c , was suggested in <ref> [33, 32] </ref>. <p> Hyperplane i (i 2 f1; 2; 3; : : :; ng) separates n patterns of one class from n patterns of the other class <ref> [33] </ref>. When S = 2 the minimal solution for each sub-module will involve n=2 + (n mod 2) hyperplanes each, Then each module will separate in total, n P n patterns from the rest. But this value is less than 2 n1 , when n is even. <p> This is for the same reasons that a single network finds it more improbable to solve higher dimensional parity problems <ref> [33] </ref>. It is not that it is not possible (as shown in [15]), when the minimal number of hidden units are present, but that it is harder to find the solution.
Reference: [34] <author> S. Thrun and K. Moller. </author> <title> Active exploration in dynamic environments. </title> <booktitle> In Proceedings of NIPS-4, </booktitle> <address> Denver, Colorado, </address> <year> 1992. </year> <note> to appear. </note>
Reference-contexts: During learning, the whole system adapts, so that the confidence changes dynamically as well as the output. This idea of using one network to monitor the progress of another has also been employed in exploration <ref> [34] </ref> and control [24]. In these approaches it was attempted to reproduce the current error of the other network with respect to its target mapping (so that robot configurations of 7 high error might be explored and better learned).
Reference: [35] <author> C. Tietz, P. Hendricks, A. Linden, and H. Muhlenbein. </author> <title> Object-oriented simulation of complex neural architectures on parallel computers. </title> <editor> In T. Kohonen, editor, </editor> <booktitle> Proceedings of COGNITIVA 90, </booktitle> <pages> pages 387-400, </pages> <address> Paris, </address> <year> 1990. </year> <pages> AFCET. </pages>
Reference-contexts: Our simulator is called SESAME (Software Environment for the Simulation of Adaptive Modular systEms) <ref> [35] </ref>, and employs the C++ object-oriented language. We want particularly to thank Jorg Kindermann, Alexander Linden and Christoph Tietz for their support and for helping with our extensions to the simulator.
Reference: [36] <author> A. Waibel. </author> <title> Modular construction of time-delay neural networks for speech recognition. </title> <journal> Neural Computation, </journal> <volume> 1, </volume> <year> 1989. </year> <month> 31 </month>
Reference-contexts: problem": having broken up the tasks over a number of parallel experts, how do we recombine the results to form a full answer? One may solve this using adaptive sub-module weighting methods [21, 8], individual sub-module reference vectors [9], pre-determined sub-module functionality followed by "connectionist gluing" of the functionalities together <ref> [36, 19] </ref>, or dynamically determined and tabulated sub-module specialities [1]. In hierarchical sub-tasking it is observed that the global task can be usefully split up in a vertical manner, as a number of quasi-independent sub-tasks, that may simultaneously, or sequentially, influence the overall output. <p> The question is, how might the sets be decomposed in order to achieve such useful problem breakdown? And what are the side-effects. The first question was tackled using external and static knowledge of the pattern classification problem domain, using reference vectors in [9], phoneme sets in <ref> [36, 19] </ref>, and a Kohonen net clustering method in [18]. Our method of reflective modular neural network division is different to the methods used by other researchers mainly because we try to retain the independence and self-sufficiency properties of the sub-modules.
References-found: 36

