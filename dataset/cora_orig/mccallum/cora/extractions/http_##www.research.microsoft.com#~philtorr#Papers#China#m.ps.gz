URL: http://www.research.microsoft.com/~philtorr/Papers/China/m.ps.gz
Refering-URL: http://www.research.microsoft.com/~philtorr/paper.html
Root-URL: http://www.research.microsoft.com
Title: Motion Clustering using the Trilinear Constraint over Three Views  
Author: P. H. S. Torr, A. Zisserman and D. W. Murray 
Address: Oxford University Parks Road, Oxford, OX1 3PJ, UK  
Affiliation: Robotics Research Group Department of Engineering Science  
Abstract: A new method for motion segmentation is presented for clustering features that belong to independently moving objects. It is based on the geometric constraints imposed on the image positions of points and lines arising from rigidly moving objects in the world. The motion of points and lines in the image over three views are linked by the trilinear (or trifocal) constraint, which plays a similar role in three views to that played by the fundamental matrix in two. The fundamental matrix only imposes a one dimensional constraint on the location of features in the second image given its location in the first, whereas the trilinear constraint gives the exact location of a feature in a third image given its location in the other two. The trilinear constraint discriminates a wider range of motion than the epipolar geometry. Furthermore the trilinear constraint has the advantage that it constrains the location of lines as well as points. The segmentation problem is transformed into that of grouping the features in the image consistent with different trilinear constraints. Feasible clusters are generated using robust techniques. It is essential that the method be robust due to the prevalence of mismatches generated by state of the art feature matchers. Degenerate cases are explored, with specific emphasis on the three view constraint on points and lines imposed by the affine camera. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> O.D. Faugeras. </author> <title> What can be seen in three dimensions with an uncalibrated stereo rig? In G. </title> <editor> Sandini, editor, </editor> <booktitle> Proc. 2nd European Conference on Computer Vision , LNCS 588, </booktitle> <pages> pages 563-578, </pages> <year> 1992. </year>
Reference-contexts: Rather than adopting heuristics it is observed that the projections of a rigid set of points in the scene are linked over two views by a 3 fi 3 fundamental matrix [F] <ref> [1, 4] </ref>. This encapsulates all the information on camera motion, camera parameters and epipolar geometry available from a given set of point correspondences. In particular neither knowledge concerning camera calibration nor the relative motion between camera and object is required to estimate [F].
Reference: [2] <author> M. A. Fischler and R. C. Bolles. </author> <title> Random sample consensus: a paradigm for model fitting with application to image analysis and automated cartography. </title> <journal> Commun. Assoc. Comp. Mach., </journal> <volume> vol. 24 </volume> <pages> 381-95, </pages> <year> 1981. </year>
Reference-contexts: Outliers have obstructed previous attempts to effect a segmentation process and the use of robust estimators proved a necessity. This lead to Torr and Murray [14] developing a random sampling approach to motion segmentation using the fundamental matrix and RANSAC <ref> [2] </ref>. Putative fundamental matrices are estimated using samples of seven point correspondences (yielding one or three solutions). The distance of each point from its epipolar line, defined by the fundamental matrix, is calculated, and if it is below a threshold, that correspondence is deemed to support that fundamental matrix. <p> For lines, the root mean square of the distances of the end points of the actual line to the predicted line is used as the error criterion. How many samples are required? Fischler and Bolles <ref> [2] </ref> and Rousseeuw [9] propose slightly different means of calculation, but both give broadly similar numbers. In this paper the method of calculation given in [9] is employed.
Reference: [3] <author> C. Harris and M.. Stephens. </author> <title> A combined corner and edge detector. </title> <booktitle> In Proc. Alvey Conf., </booktitle> <pages> pages 189-192, </pages> <year> 1987. </year>
Reference-contexts: Results The corner detector we use is that suggested by Harris and Stephens <ref> [3] </ref> which calculates an interest operator defined according to an auto-correlation of Gaussian smoothed images. The initial matching is done on the basis of cross correlation. All processing is automatic.
Reference: [4] <author> R. I. </author> <title> Hartley. Estimation of relative camera positions for uncalibrated cameras. </title> <editor> In G. Sandini, editor, </editor> <booktitle> Proc. 2nd European Conference on Computer Vision , LNCS 588, </booktitle> <pages> pages 579-87. </pages> <publisher> Springer-Verlag, </publisher> <year> 1992. </year>
Reference-contexts: Rather than adopting heuristics it is observed that the projections of a rigid set of points in the scene are linked over two views by a 3 fi 3 fundamental matrix [F] <ref> [1, 4] </ref>. This encapsulates all the information on camera motion, camera parameters and epipolar geometry available from a given set of point correspondences. In particular neither knowledge concerning camera calibration nor the relative motion between camera and object is required to estimate [F].
Reference: [5] <author> R. I. </author> <title> Hartley. Lines and points in three views a unified approach. </title> <booktitle> In ARPA Image Understanding Workshop, </booktitle> <address> Monterey, </address> <year> 1994. </year>
Reference-contexts: Unfortunately there are cases when the fundamental matrices, and hence epipolar geometries, for two objects are the same and yet their motion in the world is different e.g. two objects moving with different magnitudes of translations in the same direction. This is not the case for the trifocal constraint <ref> [5, 11] </ref>, which plays a similar role in three views to that played by the fundamental matrix in two. Rigidly connected point sets observed from three views exhibit a trilinear constraint governed by the relative disposition of object and cameras, and the calibration of the camera. <p> As the trifocal constraint intrinsically encodes the exact position of observed features relative to the camera; the object and background would exhibit differing constraints. Thus all the features may be clustered according to their indigenous constraint. The Trilinear Constraint In a key paper Hartley <ref> [5] </ref> elegantly links Shashua's [11] constraint on points with Weng, Ahuja and Huang's [17] constraint on lines over three views. The projected motion of points and lines in the image over three views are linked by a trilinear constraint. <p> The trifocal constraint constrains the positions of each feature (points and lines) over the three images: given the corresponding locations of a feature in two images and the constraint, its location in the third can be computed. Following the notation in <ref> [5] </ref> the trilinear constraint may be represented by a tensor, the coefficients of which are represented by the triply indexed quantity T ijk . <p> Let the image of a world point X be x, x and x in each of three images, where x = (x 1 ; x 2 ; x 3 ) &gt; is the noise free homogeneous coordinate in the image plane. It can be shown <ref> [5, 11] </ref> that x l = x i k=1 0 k=3 X x k T kil ; (1) for all i; j = 1 : : : 3. Hence there is a constraint linking rigid motion in the world to homogeneous image coordinates in image one, two, and three.
Reference: [6] <author> R. I. </author> <title> Hartley. Projective reconstruction from line correspondences. </title> <booktitle> In Proc. IEEE Conf. on Computer Vision and Pattern Recognition, </booktitle> <year> 1994. </year>
Reference-contexts: To solve for T a 27 fi 27 moment matrix is formed and the solution obtained from the eigenvector corresponding to the smallest eigenvalue in the usual way. A similar constraint may be obtained for lines <ref> [6] </ref>.
Reference: [7] <author> J. Mundy and A. Zisserman. </author> <title> Geometric Invariance in Computer Vision. </title> <publisher> MIT press, </publisher> <year> 1992. </year>
Reference-contexts: The rest of this section briefly details these models. For the modelling of independently moving objects which are typically distant and subtend a small field of view the affine camera <ref> [7, 10] </ref> is appropriate. The equivalent trifocal relations for the affine camera are as follows.
Reference: [8] <author> L. Quan. </author> <title> Invariants of 6 points from 3 uncalibrated images. </title> <editor> In J. O. Eckland, editor, </editor> <booktitle> Proc. 3rd European Conference on Computer Vision, </booktitle> <volume> LNCS 800/801, </volume> <pages> pages 459-469. </pages> <publisher> Springer-Verlag, </publisher> <year> 1994. </year>
Reference-contexts: Degeneracy also occurs either when two of the camera centres are coincident or upon observing a planar surface. If degeneracy is ignored then over fitting might occur, in this instance the 1 Using non-linear methods T ijk may be recovered given six points. (e.g. <ref> [8] </ref>). -3 estimated parameters are highly unstable and acutely influenced by noise and outliers. As a result features might be mis-clustered and the segmentation process as a whole might break down. This is demonstrated in Torr [12, 15].
Reference: [9] <author> P. J. Rousseeuw. </author> <title> Robust Regression and Outlier Detection. </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1987. </year>
Reference-contexts: For lines, the root mean square of the distances of the end points of the actual line to the predicted line is used as the error criterion. How many samples are required? Fischler and Bolles [2] and Rousseeuw <ref> [9] </ref> propose slightly different means of calculation, but both give broadly similar numbers. In this paper the method of calculation given in [9] is employed. <p> How many samples are required? Fischler and Bolles [2] and Rousseeuw <ref> [9] </ref> propose slightly different means of calculation, but both give broadly similar numbers. In this paper the method of calculation given in [9] is employed.
Reference: [10] <author> L. S. Shapiro, A. Zisserman, and M. Brady. </author> <title> Motion from point matches using affine epipolar geometry. </title> <editor> In J. O. Eckland, editor, </editor> <booktitle> Proc. 3rd European Conference on Computer Vision, </booktitle> <volume> LNCS 800/801, </volume> <pages> pages 161-166. </pages> <publisher> Springer-Verlag, </publisher> <year> 1994. </year>
Reference-contexts: The rest of this section briefly details these models. For the modelling of independently moving objects which are typically distant and subtend a small field of view the affine camera <ref> [7, 10] </ref> is appropriate. The equivalent trifocal relations for the affine camera are as follows.
Reference: [11] <author> A. Shashua. </author> <title> Trilinearity in visual recognition by alignment. </title> <booktitle> In Proc. 3rd European Conference on Computer Vision, </booktitle> <volume> LNCS 800/801, volume 1, </volume> <pages> pages 479-484, </pages> <month> May </month> <year> 1994. </year>
Reference-contexts: Unfortunately there are cases when the fundamental matrices, and hence epipolar geometries, for two objects are the same and yet their motion in the world is different e.g. two objects moving with different magnitudes of translations in the same direction. This is not the case for the trifocal constraint <ref> [5, 11] </ref>, which plays a similar role in three views to that played by the fundamental matrix in two. Rigidly connected point sets observed from three views exhibit a trilinear constraint governed by the relative disposition of object and cameras, and the calibration of the camera. <p> As the trifocal constraint intrinsically encodes the exact position of observed features relative to the camera; the object and background would exhibit differing constraints. Thus all the features may be clustered according to their indigenous constraint. The Trilinear Constraint In a key paper Hartley [5] elegantly links Shashua's <ref> [11] </ref> constraint on points with Weng, Ahuja and Huang's [17] constraint on lines over three views. The projected motion of points and lines in the image over three views are linked by a trilinear constraint. <p> Let the image of a world point X be x, x and x in each of three images, where x = (x 1 ; x 2 ; x 3 ) &gt; is the noise free homogeneous coordinate in the image plane. It can be shown <ref> [5, 11] </ref> that x l = x i k=1 0 k=3 X x k T kil ; (1) for all i; j = 1 : : : 3. Hence there is a constraint linking rigid motion in the world to homogeneous image coordinates in image one, two, and three.
Reference: [12] <author> P. H. S. Torr. </author> <title> Outlier Detection and Motion Segmentation. </title> <type> PhD thesis, </type> <institution> University of Oxford, </institution> <year> 1995. </year> <note> In preparation. </note>
Reference-contexts: Detection of independently moving objects is an essential but often neglected precursor to problems in robotics. In robotic vision, motion segmentation turns out to be a most demanding problem and has received considerable attention over the years, a review of which may be found in <ref> [12] </ref>. Previous approaches to motion clustering have failed because the motion models that they employ are too restrictive. <p> A full study and presentation of the problem of estimating degeneracy, in the presence of outliers, is given in <ref> [12, 15] </ref>, a robust estimator is developed that simultaneously flushes outliers and selects the correct model. A drawback with the two view approach is that the fundamental matrix defines only a one dimensional -2 constraint on the correspondence of an image point. <p> An attempt to recover structure would lead to a spurious positioning of the independently moving object. The introduction of a third view can resolve this ambiguity <ref> [12] </ref>. As the trifocal constraint intrinsically encodes the exact position of observed features relative to the camera; the object and background would exhibit differing constraints. Thus all the features may be clustered according to their indigenous constraint. <p> As a result features might be mis-clustered and the segmentation process as a whole might break down. This is demonstrated in Torr <ref> [12, 15] </ref>. To avoid this, each cluster in the segmentation is described by one of the following models: full trifocal (undegenerate) constraint, or the following degenerate models: the affine camera constraint, image-image projectivity, image-image affinity, image-image translation, or no motion. The rest of this section briefly details these models. <p> Proof in Torr <ref> [12] </ref>. If the camera motion is pure rotation, or a plane is observed, then the line and point correspondences are determined by image-image projectivities.
Reference: [13] <author> P. H. S. Torr and D. W. Murray. </author> <title> Outlier detection and motion segmentation. </title> <editor> In P. S. Schenker, editor, </editor> <booktitle> Sensor Fusion VI, </booktitle> <pages> pages 432-443. </pages> <booktitle> SPIE volume 2059, 1993. </booktitle> <address> Boston. </address>
Reference-contexts: The segmentation algorithm is based on two and three view constraints and as such represents an initialization or bootstrap of the segmentation process. It is envisaged that other processes would be used to augment the segmentation over multiple frames. The Fundamental Matrix Torr and Murray <ref> [13] </ref> first demonstrated that random sampling algorithm could be used to gain highly robust estimates of the fundamental matrix. Outliers have obstructed previous attempts to effect a segmentation process and the use of robust estimators proved a necessity.
Reference: [14] <author> P. H. S. Torr and D. W. Murray. </author> <title> Stochastic motion segmentation. </title> <editor> In J. O. Eckland, editor, </editor> <booktitle> Proc. 3rd European Conference on Computer Vision, </booktitle> <volume> LNCS 800/801, </volume> <pages> pages 328-338. </pages> <publisher> Springer-Verlag, </publisher> <year> 1994. </year>
Reference-contexts: Outliers have obstructed previous attempts to effect a segmentation process and the use of robust estimators proved a necessity. This lead to Torr and Murray <ref> [14] </ref> developing a random sampling approach to motion segmentation using the fundamental matrix and RANSAC [2]. Putative fundamental matrices are estimated using samples of seven point correspondences (yielding one or three solutions). <p> Epipolar geometry alone proved insufficient to segment this scene, application of the algorithm in Torr and Murray <ref> [14] </ref> gave rise to only one object. This is because, within the vicinity of the observed objects, the epipolar geometry of the lorry and background are locally similar. The use of the trifocal constraint gives much better results.
Reference: [15] <author> P. H. S. Torr, A. Zisserman, and S. Maybank. </author> <title> Robust detection of degeneracy. </title> <note> to appear in ICCV95, </note> <year> 1995. </year>
Reference-contexts: A full study and presentation of the problem of estimating degeneracy, in the presence of outliers, is given in <ref> [12, 15] </ref>, a robust estimator is developed that simultaneously flushes outliers and selects the correct model. A drawback with the two view approach is that the fundamental matrix defines only a one dimensional -2 constraint on the correspondence of an image point. <p> As a result features might be mis-clustered and the segmentation process as a whole might break down. This is demonstrated in Torr <ref> [12, 15] </ref>. To avoid this, each cluster in the segmentation is described by one of the following models: full trifocal (undegenerate) constraint, or the following degenerate models: the affine camera constraint, image-image projectivity, image-image affinity, image-image translation, or no motion. The rest of this section briefly details these models. <p> Generally, a projectivity models distant data. Segmentation Algorithm The segmentation algorithm has its basis in a robust estimator, dubbed PLUNDER <ref> [15] </ref>, which extracts models recursively from the set of correspondences. The algorithm is quite detailed and only a brief description is given here. PLUNDER is founded on a highly robust fitting algorithm the random sample consensus paradigm (RANSAC).
Reference: [16] <author> S. Ullman and R. Basri. </author> <title> Recognition by linear combination of models. </title> <journal> PAMI, </journal> <volume> vol.13(10):992-1006, </volume> <year> 1991. </year>
Reference-contexts: + p 5 x + p 9 y + p 3 x + p 13 = 0 00 0 p 1 y + p 6 x + p 10 y + p 4 x + p 15 = 0 00 0 This is the extension of the result of Ullman <ref> [16] </ref> for orthography to the affine camera.

References-found: 16

