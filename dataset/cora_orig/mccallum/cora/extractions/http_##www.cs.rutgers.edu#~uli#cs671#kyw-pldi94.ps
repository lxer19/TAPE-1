URL: http://www.cs.rutgers.edu/~uli/cs671/kyw-pldi94.ps
Refering-URL: http://www.cs.rutgers.edu/~uli/cs671/index.html
Root-URL: http://www.cs.rutgers.edu
Title: Precise Compile-Time Performance Prediction for Superscalar-Based Computers  
Author: Ko-Yang Wang 
Address: P.O. Box 704, Yorktown Heights, NY 10598, USA  
Affiliation: IBM T. J. Watson Research Center,  
Abstract: Optimizing compilers (particularly parallel compilers) are constrained by their ability to predict performance consequences of the transformations they apply. Many factors, such as unknowns in control structures, dynamic behavior of programs, and complexity of the underlying hardware, make it very difficult for compilers to estimate the performance of the transformations accurately and efficiently. In this paper, we present a performance prediction framework that combines several innovative approaches to solve this problem. First, the framework employs a detailed, architecture-specific, but portable, cost model that can be used to estimate the cost of straight line code efficiently. Second, aggregated costs of loops and conditional statements are computed and represented symbolically. This avoids unnecessary, premature guesses and preserves the precision of the prediction. Third, symbolic comparison allows compilers to choose the best transformation dynamically and systematically. Some methodologies for applying the framework to optimizing parallel compilers to support automatic, performance-guided program restructuring are discussed. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Andrews and C. D. Polychronopoulos. </author> <title> An Analytical Approach to Performance/Cost Modeling of Parallel Computers. </title> <type> PhD thesis, </type> <institution> University of Illinois at Urbana-Champaign, Ctr. Supercomputing Res. & Dev., </institution> <month> April </month> <year> 1991. </year> <note> CSRD Report No. 1110. </note>
Reference: [2] <author> V. Balasundaram, G. Fox, K. Kennedy, and U. Kremer. </author> <title> A static performance estimator to guide data partitioning decisions. </title> <booktitle> In Proceeding of the Third ACM Sigplan Symposium on Principles and practice of parallel programming (PPOPP), </booktitle> <month> April </month> <year> 1991. </year>
Reference-contexts: The symbolic performance analysis we introduced here allows the compiler to rely less on profiling and, at the mean time, preserves the accuracy of the estimation. V. Balasundaram et al. <ref> [2] </ref> presented a performance estimator for evaluating the relative efficiency of data partitioning schemes by computing cost of message passing statically. They assumed constant loop bounds and guessed for values of unknowns in programs. T. Fahringer and H.
Reference: [3] <author> D. Bernstein, D. Cohen, Y. Lavon, and V. Rainish. </author> <title> Performance evaluation of instruction scheduling on the ibm risc system/6000. </title> <booktitle> In Proceedings of MICRO-25, </booktitle> <pages> pages 226-235, </pages> <year> 1992. </year>
Reference-contexts: It is possible that one can use an existing module in the compiler the back-end code generator to generate low level code for performance estimation purposes. In fact, the IBM xlf and xlc compilers provide such a facility for estimating the cost of assembly instructions <ref> [3] </ref>. However, since the compiler needs the cost estimate during the program restructuring process (before back-end is invoked); it is impractical at this stage to do code generation for every intermediate step. Therefore, an efficient substitute is needed. <p> Speculative scheduling and code motion are handled naturally by the base model. * Branch optimizations. IBM xlf and xlc compilers are capable of branch optimizations, such as code replication, gluing, branch swapping, etc. to minimize the cost of branches <ref> [3] </ref>. The cost model handles the branch optimization by matching shapes of the cost blocks to decide whether the branching cost needs to be in cluded. * Loop unrolling. <p> It is also possible for the compiler to change expressions to simpler expressions by dropping some terms. For example, if the range of x is <ref> [3; 100] </ref>, then the equation 4x 4 + 2x 3 4x + 1=x 3 can be changed into 4x 4 + 2x 3 4x. 3.2 Automatic Program Transforma tion Based on Performance Estima tion One importance feature of the proposed framework is that it supports automatic program optimization.
Reference: [4] <author> D. Bernstein and M. Rodeh. </author> <title> Global instruction scheduling for superscalar machines. </title> <booktitle> In Proceedings of the ACM SIGPLAN'91 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 241-255, </pages> <address> Toronto, Ontario, Canada, </address> <month> June </month> <year> 1991. </year>
Reference-contexts: These transformations include operation overlapping (see Section 2.1), code motion to move loop invariant or inductive expressions out of loops, common sub-expression optimization, dead code elimination, branch prediction, speculative scheduling, etc. Most of these optimizations are done by the compiler back end <ref> [4] </ref> (or are more convenient to be left to the back-end to do). However, the performance estimation is used by program restructurer which is several phases before the code generation phase. This implies that the cost model needs to imitate these optimizations to get accurate estimates.
Reference: [5] <author> F. Bodin, D. Windheiser, W. Jalby, D. Atapattu, M. Lee, and D Gannon. </author> <title> Performance evaluation and prediction for parallel algorithms on the bbn gp1000. </title> <booktitle> In Proceedings of the 1990 International Conference on Supercomputing, </booktitle> <pages> pages 401-413, </pages> <month> August </month> <year> 1990. </year>
Reference-contexts: The performance expressions are parameterized with the formal parameters. Actual parameters are substituted at the call site to get more specific performance expressions. 4 Related Work The "load/store" modeling method used in <ref> [9, 5] </ref> characterizes the performance of shared memory architectures by a set of templates of vector load, store, and "nop" instructions. This works at the assembly level and only reflects the cost of memory hierarchy. D. At-apattu and D.
Reference: [6] <author> T. Fahringer, R. Blasko, and H. P. Zima. </author> <title> Automatic performance prediction to support paral-lelization of fortran programs for massively parallel systems. </title> <booktitle> In Proc. 6th ACM International Conference on Supercomputing, </booktitle> <pages> pages 347-356, </pages> <address> Wash-ington D.C., </address> <month> July </month> <year> 1992. </year>
Reference: [7] <author> T. Fahringer and H. Zima. </author> <title> A static parameter based performance prediction tool for parallel programs. </title> <booktitle> In Proceedings of the 7th International Conference on Supercomputing, </booktitle> <pages> pages 207-219, </pages> <address> Tokyo, Japan, </address> <month> July </month> <year> 1993. </year>
Reference-contexts: V. Balasundaram et al. [2] presented a performance estimator for evaluating the relative efficiency of data partitioning schemes by computing cost of message passing statically. They assumed constant loop bounds and guessed for values of unknowns in programs. T. Fahringer and H. Zima <ref> [7] </ref> discussed a static performance prediction tool which uses a combination of a parameter-based performance tool and a profiler.
Reference: [8] <author> J. Ferrante, V. Sarkar, and W. Thrash. </author> <title> On estimating and enhancing cache effectiveness. </title> <booktitle> In Proceedings of the 4th International Workshop on Languages and Compilers for Parallel Computing, </booktitle> <pages> pages 328-343, </pages> <address> Santa Clara, California, USA, </address> <month> August </month> <year> 1991. </year>
Reference-contexts: Many methodologies for estimating cache cost were proposed <ref> [8, 14, 10] </ref>. We adopt an algorithm that was introduced in [8]. <p> Many methodologies for estimating cache cost were proposed [8, 14, 10]. We adopt an algorithm that was introduced in <ref> [8] </ref>.
Reference: [9] <author> K. Gallivan, W. Jalby, A. Malony, and H. Wi-jshoff. </author> <title> Performance prediction of loop constructs on multiprocessor hierarchical-memory systems. </title> <booktitle> In Proceedings of the ACM International Conference on Supercomputing, </booktitle> <year> 1989. </year>
Reference-contexts: The performance expressions are parameterized with the formal parameters. Actual parameters are substituted at the call site to get more specific performance expressions. 4 Related Work The "load/store" modeling method used in <ref> [9, 5] </ref> characterizes the performance of shared memory architectures by a set of templates of vector load, store, and "nop" instructions. This works at the assembly level and only reflects the cost of memory hierarchy. D. At-apattu and D.
Reference: [10] <author> D. Gannon, W. Jalby, and K. Gallivan. </author> <title> Strategies for cache and local memory management by global program transformation. </title> <booktitle> In Proceedings of the 1987 International Conference on Supercomputing, </booktitle> <pages> pages 229-254, </pages> <year> 1987. </year>
Reference-contexts: Many methodologies for estimating cache cost were proposed <ref> [8, 14, 10] </ref>. We adopt an algorithm that was introduced in [8].
Reference: [11] <author> M. Gupta and P. Banerjee. </author> <title> Compile-time esti-mation of communication costs on multicomput-ers. </title> <booktitle> In Proc. 6th International Parallel Processing Symposium, </booktitle> <address> Beverly Hills, California, </address> <month> March </month> <year> 1992. </year>
Reference: [12] <author> M. Gupta, S. Midkiff, E. Schonberg, P. Sweeney, K.Y. Wang, and M. Burke. </author> <title> Ptran ii a compiler for high performance fortran. </title> <booktitle> In Proceedings of 4th Workshop on Compilers for Parallel Computers, </booktitle> <month> Dec </month> <year> 1993. </year>
Reference-contexts: The framework is implemented and is an integrated module of the PTRAN II compiler which is a prototype HPF compiler <ref> [12] </ref>. Preliminary results show that the predictions are fairly accurate for straight-line code on the RS6000 based machines. Work is underway on communication cost for distributed memory computers.
Reference: [13] <author> S. Hiranandani, K. Kennedy, and C. Tseng. </author> <title> Evaluation of compiler optimizations for Fortran D on MIMD distributed-memory machines. </title> <booktitle> In Proceedings of the 6th ACM International Conference on Supercomputing, </booktitle> <pages> pages 1-14, </pages> <month> July </month> <year> 1992. </year>
Reference: [14] <author> M. Lam, E. Rothberg, and M. Wolf. </author> <title> The cache performance and optimizations of blocked algorithms. </title> <booktitle> In Proceedings of the 4th International Conference on Architectural Support for Programming Languages and Operation Systems, </booktitle> <address> Santa Clara, CA, </address> <month> April </month> <year> 1991. </year>
Reference-contexts: Many methodologies for estimating cache cost were proposed <ref> [8, 14, 10] </ref>. We adopt an algorithm that was introduced in [8].
Reference: [15] <author> V. Sarkar. </author> <title> Partitioning and Scheduling Parallel Programs for Multiprocessors. </title> <publisher> Pitman, </publisher> <address> London, </address> <year> 1989. </year>
Reference-contexts: k fl C (B t ) + (n k) fl C (B f ) and if C (B t ) ' C (B f ) then the cost expression can be further simplified to be: C (L) = n fl C (B t ) 3.4 Profiling and Run-Time Tests Profiling <ref> [15] </ref> can be used to eliminate some variables that result from unknown values in the control structures (such as the branching probabilities of conditional statements). This is useful when the program behavior is relatively independent of the input data. <p> This works at the assembly level and only reflects the cost of memory hierarchy. D. At-apattu and D. Gannon [AtGa89] built an interactive tool that used a similar analytical machine model to predict performance for Alliant FX/8. V. Sarkar <ref> [15] </ref> computes at compile time a set of performance parameters and estimates execution time based on profiling data for single assignment languages. The symbolic performance analysis we introduced here allows the compiler to rely less on profiling and, at the mean time, preserves the accuracy of the estimation. V.
Reference: [16] <author> B. Stramm and F. Berman. </author> <title> Predicting the performance of large programs on scalable multicom-puters. </title> <booktitle> In Proceedings of the Scalable High Performance Computing Conference, </booktitle> <address> Williamsburg, VA, </address> <month> April </month> <year> 1992. </year>
Reference: [17] <author> A. J. C. van Gemund. </author> <title> Performance prediction of parallel processing systems: the pamela methodology. </title> <booktitle> In Proceedings of the 7th International Conference on Supercomputing, </booktitle> <pages> pages 318-327, </pages> <address> Tokyo, Japan, </address> <month> July </month> <year> 1993. </year>
Reference-contexts: Their system attempts to correlate statically computed parameters and the actual measurements, while our model actually derives a precise mathematical expression based on a set of implicit parameters to represent the run-time cost of the program. A. Gemund <ref> [17] </ref> defines a modeling language to model the serialization effects of parallel computer systems. Our code-model for message-passing is based on [19] which is a parameterized, static, performance prediction tool that supports different types of architectures.
Reference: [18] <author> K. Wang and D. Gannon. </author> <title> Applying ai techniques to program optimization for parallel computers. </title> <booktitle> In Parallel Processing for Supercomputers and Artificial Intelligence, </booktitle> <pages> pages 441-486. </pages> <publisher> McGraw-Hill, </publisher> <address> New York, New York, </address> <year> 1989. </year>
Reference: [19] <author> K. Wang and E. Houstis. </author> <title> A performance prediction model for parallel compilers. </title> <type> Technical Report CSD-TR-1041, </type> <institution> Department of Computer Sciences, Purdue University, </institution> <month> November </month> <year> 1990. </year>
Reference-contexts: A. Gemund [17] defines a modeling language to model the serialization effects of parallel computer systems. Our code-model for message-passing is based on <ref> [19] </ref> which is a parameterized, static, performance prediction tool that supports different types of architectures. This tools characterized program performance into a set of cost categories that includes instructions, cache, message passing, synchronization, and hot spot contentions, etc.
References-found: 19

