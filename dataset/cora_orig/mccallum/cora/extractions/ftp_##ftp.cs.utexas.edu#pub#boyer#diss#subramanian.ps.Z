URL: ftp://ftp.cs.utexas.edu/pub/boyer/diss/subramanian.ps.Z
Refering-URL: http://www.cs.utexas.edu/users/boyer/students.html
Root-URL: http://www.cs.utexas.edu
Title: A MECHANIZED FRAMEWORK FOR SPECIFYING PROBLEM DOMAINS AND VERIFYING PLANS  
Degree: APPROVED BY DISSERTATION COMMITTEE:  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> W. W. </author> <title> Agresti, editor. New Paradigms for Software Development. </title> <publisher> IEEE Computer Society Press, </publisher> <year> 1986. </year>
Reference-contexts: It is now known that the most expensive errors are caused by errors in the requirements specification stemming from a misunderstanding by the designer of the customer's needs <ref> [20, 40, 64, 46, 1] </ref>. Formal validation, the technique of formalizing the requirements specification, proving general properties that follow from the formal requirements specification and then comparing those with the informal requirements specification, has been proposed [40, 46, 33] to minimize such errors. <p> Formal validation, the technique of formalizing the requirements specification, proving general properties that follow from the formal requirements specification and then comparing those with the informal requirements specification, has been proposed [40, 46, 33] to minimize such errors. However, in many cases <ref> [20, 1] </ref>, a customer cannot be expected to know exactly what she wants before a prototype of the product is built nor be expected to not change the requirements after interacting with the prototype. <p> However, in many cases [20, 1], a customer cannot be expected to know exactly what she wants before a prototype of the product is built nor be expected to not change the requirements after interacting with the prototype. Rapid prototyping <ref> [57, 1] </ref> has been proposed to minimize the cost incurred when dealing with a changing requirements specification. Here the system designer takes a best guess at a requirements 5 specification and produces a prototype that the customer can interact with. <p> From the standpoint of rapid prototyping, our approach has the advantage that we can execute requirements specifications a la Lisp programs as well as prove general properties about them as in formal validation <ref> [33, 46, 1] </ref>. Similarly, whether a particular prototype (plan) satisfies a specification or not can be ascertained by either direct execution on test cases or "scenarios" [64, pages 257-262] or by mechanical verification. The former has the advantage of getting simple bugs out of the way. 28 6.
Reference: [2] <editor> James Allen, James Hendler, and Austin Tate, editors. </editor> <booktitle> Readings in Planning. </booktitle> <publisher> Morgan-Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1990. </year>
Reference-contexts: Commonsense reasoning is concerned with the construction of robots that can plan and act to achieve their goals in the physical world. Problem domains in commonsense reasoning and traditional robot planning <ref> [30, 2] </ref> consist of a robot with preprogrammed action routines that it can execute sequentially to manipulate objects in its physical environment. Consider the well-known example of a robot in a blocks world [37]. <p> We call such Lisp programs plan generators since they are similar to the planning algorithms for generating straightline plans <ref> [2, 113] </ref> used in AI. For example, the sequence of actions needed to clear a block in various states according to our plan is computed by the following plan generating program makeclear-gen. <p> In fact, a major portion of research in planning in AI is concerned with the construction of more efficient planners of this sort <ref> [113, 2] </ref>. However, because it is a function in a logic and because we have all possible domains as terms in the logic, it can be proved correct once and used to generate solutions to problems when a domain is modified.
Reference: [3] <author> James F. Allen. </author> <title> Towards a general theory of action and time, pages 464-479. </title> <editor> In Allen et al. </editor> <volume> [2], </volume> <year> 1990. </year>
Reference-contexts: The main disadvantage of these systems is that general problems such as the problem of clearing a block cannot be specified as input. Some temporal logics have also been proposed in AI <ref> [3, 89, 87] </ref> but it is unclear how effective they are in practice. Constraints on execution sequences generated by the actions of an agent also arise when specifying the behavior of reactive systems [44, 67].
Reference: [4] <author> Andrew Baker. </author> <title> Nonmonotonic reasoning in the framework of situation calculus. </title> <journal> Artificial Intelligence, </journal> <volume> 49 </volume> <pages> 5-23, </pages> <year> 1991. </year>
Reference-contexts: In a circumscription based formalism similar to <ref> [4] </ref>, (a relevant part of ) the Switch Domain may be formalized as follows. :noninertial (p; a) ! (holds (p; s) holds (p; result (a; s))) noninertial (Light1; Switch1) holds (Light1; result (Switch1; s)) Here variables p, s, and a are universally quantified from the outside over fluents, situations and actions <p> In a circumscription based formalism similar to <ref> [4] </ref>, (a relevant part of) the Switch Domain may be formalized as follows. :noninertial (p; a) ! (holds (p; s) holds (p; result (a; s))) noninertial (Light1; Switch1) holds (Light1; result (Switch1; s)) Here variables p, s, and a are universally quantified from the outside over fluents, situations and actions respectively. <p> The fluent names are Loaded and Alive; the action names are Load, Shoot and Wait . The domain is characterized by the propositions initially :Loaded; initially Alive; Load causes Loaded; Shoot causes :Alive if Loaded; Shoot causes :Loaded: Example 3. The Murder Mystery domain, motivated by an example from <ref> [4] </ref>, is obtained from the Yale Shooting domain by substituting :Alive after Shoot ; Wait (6:3) for the proposition initially :Loaded. Example 4.
Reference: [5] <author> William Bevier, Warren Hunt, J Strother Moore, and William Young. </author> <title> Special issue on system verification. </title> <journal> Journal of Automated Reasoning, </journal> <volume> 5(4), </volume> <year> 1989. </year>
Reference-contexts: The work most relevant to this dissertation seems to be the research on formalizing the semantics of individual von Neumann machines such as a microprocessor [11], an assembly language machine [95], a Micro-Gypsy (a Pascal-like language) machine [122] and various other machines <ref> [5] </ref> in the Boyer-Moore logic for the purpose of verifying programs and systems mechanically. The semantics of these various machines have been formalized by defining Lisp interpreters for various programming languages in the Boyer-Moore logic. <p> Because we can formalize arbitrary machines within our framework, we hope 17 that this dissertation would enable us to make progress towards the "ideal system verification tool" described by Moore <ref> [5, page 410] </ref> as follows. The ideal system verification tool is nothing more than a general-purpose automated reasoning system: it must be possible to define virtually arbitrary abstract machines and to derive their properties. <p> Since A Computational Logic [9] was published in 1979, Nqthm has been used by several dozen users to check proofs of over 16,000 theorems from many areas of number theory, proof theory, and computer science. An extensive partial listing may be found in [10, pages 5-9]. See also <ref> [5] </ref>. For a thorough and precise description of the Nqthm logic, we refer the reader to the rigorous treatment in [10], especially Chapter 4, in which the logic is precisely defined.
Reference: [6] <editor> D. Bjorner, C. A. R. Hoare, and H. Langmaack, editors. VDM'90: </editor> <title> VDM and Z | Formal Methods in Software Development, </title> <booktitle> volume 428 of Lecture Notes in Computer Science. </booktitle> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1990. </year>
Reference-contexts: In any case, mechanical support for developing programs using these formalisms is still at a rudimentary stage [53, 33]. VDM and Z are more notations for humans to use when developing software rather than languages with a precise formal semantics <ref> [6] </ref>. The Larch Shared Language, however, has been used for expressing and validating some state-independent properties of a specification such as consistency using the Larch Prover [33, 41]. A related approach for developing software is the use of program transformations [105, pages 97-192].
Reference: [7] <author> A. Borgida, J. Mylopoulos, and R. Reiter. </author> <title> "...And Nothing Else Changes": The frame problem in procedure specifications. </title> <booktitle> In Proc. Fifteenth Int'l Conf. on Software Engineering, </booktitle> <year> 1993. </year>
Reference-contexts: Operations on states are described in terms of the pre- and post-conditions. Unfortunately, the specification of actions with side-effects has been a problem using this approach [63]. A recent paper <ref> [7] </ref> also explains why the frame problem must be addressed by these specification languages. In any case, mechanical support for developing programs using these formalisms is still at a rudimentary stage [53, 33].
Reference: [8] <author> Robert S. Boyer, David M. Goldschlag, Matt Kaufmann, and J. Strother Moore. </author> <title> Functional instantiation in first-order logic. </title> <editor> In Vladimir Lifschitz, editor, </editor> <booktitle> Artificial Intelligence and Mathematical Theory of Computation: Papers in Honor of John McCarthy, </booktitle> <pages> pages 7-26. </pages> <publisher> Academic Press, </publisher> <year> 1991. </year>
Reference-contexts: In such a case, it would not be possible to define an interpreter for the domain as we have been doing since actions cannot be modeled by programs. We show in Chapter 5 how we may use the CONSTRAIN event <ref> [8] </ref> of Nqthm to specify partial actions. Obviously, we would lose the benefit of executability if actions are specified this way. 1.5.2 Formalizing "Non-monotonic" Reasoning How do we succeed in formalizing "non-monotonic" reasoning in classical first-order logic? The answer is simple. <p> We represent error states of this machine by lists whose car is 'failed. We propose to tackle the problem of specifying partial actions in the Boyer-Moore logic by specifying them using axioms introduced via the CONSTRAIN event <ref> [8] </ref>. The CONSTRAIN event allows us to add an axiom involving new function symbols using as "witnesses" or "models" previously defined functions. <p> Therefore, it would not be possible for us to define an interpreter for the system and reason about it as we have been doing so far. Fortunately, we do not need a different logic for dealing with partial actions. The CONSTRAIN event <ref> [8] </ref> of Nqthm allows us to add axioms that constrain function symbols without completely characterizing them. To ensure consistency, we are required to provide an already defined "witness" function that satisfies the proposed axiom about a new function symbol. <p> To ensure consistency, we are required to provide an already defined "witness" function that satisfies the proposed axiom about a new function symbol. The defined "witness" function is a model of the new function symbol. In <ref> [8] </ref>, the intuition behind the CONSTRAIN event is explained as follows: Intuitively, a good way to think about a CONSTRAIN event is to imagine defining a new function symbol, proving a theorem about that function symbol, and then forgetting about the defining equation while remember ing the theorem.: : : It
Reference: [9] <author> Robert S. Boyer and J Strother Moore. </author> <title> A Computational Logic. </title> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1979. </year>
Reference-contexts: So much for relevant research in artificial intelligence. Since von Neumann machines are also problem domains and since plans resemble programs, it behooves us to look carefully into research in mechanical program verification <ref> [9, 10, 18] </ref>. <p> Nqthm is a Common Lisp program for proving mathematical theorems. Since A Computational Logic <ref> [9] </ref> was published in 1979, Nqthm has been used by several dozen users to check proofs of over 16,000 theorems from many areas of number theory, proof theory, and computer science. An extensive partial listing may be found in [10, pages 5-9]. See also [5].
Reference: [10] <author> Robert S. Boyer and J Strother Moore. </author> <title> A Computational Logic Handbook. </title> <publisher> Academic Press, </publisher> <year> 1988. </year>
Reference-contexts: So much for relevant research in artificial intelligence. Since von Neumann machines are also problem domains and since plans resemble programs, it behooves us to look carefully into research in mechanical program verification <ref> [9, 10, 18] </ref>. <p> Since A Computational Logic [9] was published in 1979, Nqthm has been used by several dozen users to check proofs of over 16,000 theorems from many areas of number theory, proof theory, and computer science. An extensive partial listing may be found in <ref> [10, pages 5-9] </ref>. See also [5]. For a thorough and precise description of the Nqthm logic, we refer the reader to the rigorous treatment in [10], especially Chapter 4, in which the logic is precisely defined. <p> An extensive partial listing may be found in [10, pages 5-9]. See also [5]. For a thorough and precise description of the Nqthm logic, we refer the reader to the rigorous treatment in <ref> [10] </ref>, especially Chapter 4, in which the logic is precisely defined. In the body of this dissertation, we have been using a conventional syntax rather than the official Lisp-like syntax of Nqthm. <p> hand proof, identifies the key steps in the proof, formulates them as a sequence of lemmas, and gets each checked by the prover. 1.7.3 Syntax Summary Here is a summary of the conventional syntax used in this report in terms of the official syntax of the Nqthm logic described in <ref> [10] </ref>. (`cond' and `let' are recent extensions not described in [10].) 1. Variables. x , y, z , etc. are printed in italics. 34 2. Function application. <p> them as a sequence of lemmas, and gets each checked by the prover. 1.7.3 Syntax Summary Here is a summary of the conventional syntax used in this report in terms of the official syntax of the Nqthm logic described in <ref> [10] </ref>. (`cond' and `let' are recent extensions not described in [10].) 1. Variables. x , y, z , etc. are printed in italics. 34 2. Function application. <p> Then we will present our general framework. 5.1.1 Definition of eval$ For a fuller description of the concepts presented in this section, the reader must consult <ref> [10] </ref>. The quotations of terms in the logic are formed as follows. Variables like x and function symbols like fn are encoded by the corresponding litatoms such as 'x and 'fn. <p> One way to get around this problem may be to augment the CONSTRAIN event so that a user can declare some of the newly introduced function symbols as SU BRP s, primitive function symbols <ref> [10, page 134] </ref>. If functions specifying partial actions are introduced as SU BRP s and SU BRP axioms [10, page 134] corresponding to these function symbols are added to the logic by the CONSTRAIN event then we could perform lambda evaluation of partially specified actions using eval$ because APPLY-SUBR would then <p> to get around this problem may be to augment the CONSTRAIN event so that a user can declare some of the newly introduced function symbols as SU BRP s, primitive function symbols <ref> [10, page 134] </ref>. If functions specifying partial actions are introduced as SU BRP s and SU BRP axioms [10, page 134] corresponding to these function symbols are added to the logic by the CONSTRAIN event then we could perform lambda evaluation of partially specified actions using eval$ because APPLY-SUBR would then return the desired term.
Reference: [11] <author> Robert S. Boyer and Yuan Yu. </author> <title> Automated correctness proofs of machine code programs for a commercial microprocessor. </title> <booktitle> In Proceedings of the Eleventh Conference on Automated Deduction. </booktitle> <publisher> LNCS 607, Springer-Verlag, </publisher> <year> 1992. </year>
Reference-contexts: The work most relevant to this dissertation seems to be the research on formalizing the semantics of individual von Neumann machines such as a microprocessor <ref> [11] </ref>, an assembly language machine [95], a Micro-Gypsy (a Pascal-like language) machine [122] and various other machines [5] in the Boyer-Moore logic for the purpose of verifying programs and systems mechanically. <p> We have also explained the difficulties we experienced in getting the theorem prover to check some of the proofs. We conclude the introduction with a brief review of the automated reasoning system Nqthm, also known as `the Boyer-Moore Theorem Prover' reproduced with minor alterations from <ref> [11] </ref>. 1.7 The Automated Reasoning System Nqthm Detailed knowledge of Nqthm is unnecessary for those who are happy enough with the informal paraphrases of the formulas in the remainder of this dissertation. Nqthm is a Common Lisp program for proving mathematical theorems.
Reference: [12] <author> Robert S. Boyer and Yuan Yu. </author> <title> A formal specification of some user mode instructions for the Motorola 68020. </title> <type> Technical Report TR-92-04, </type> <institution> Computer Sciences Department, University of Texas at Austin, </institution> <year> 1992. </year> <pages> 217 218 </pages>
Reference-contexts: In the body of this dissertation, we have been using a conventional syntax rather than the official Lisp-like syntax of Nqthm. The translation between the conventional syntax and the official Lisp-like syntax is reproduced from <ref> [12] </ref> in Section 1.7.3. 1.7.1 The Logic The logic of Nqthm is a quantifier-free first order logic with equality.
Reference: [13] <editor> R. Brachman and H. Levesque, editors. </editor> <booktitle> Readings in Knowledge Representation. </booktitle> <publisher> Morgan Kaufmann Publishers, Inc., </publisher> <address> San Mateo, Calif., </address> <year> 1985. </year>
Reference: [14] <author> R. M. Burstall and J. A. Goguen. </author> <title> An Informal Introduction to Specifications using CLEAR, </title> <booktitle> pages 363-390. In Gehani and McGettrick [34], </booktitle> <year> 1986. </year>
Reference-contexts: Because we have a single framework within which all problem domains are formalized, we have the advantage of reusability; work done about one domain can be reused in another. Also, specifications are parameterized and can be composed <ref> [14, 33] </ref> because they are in a programming language. Since plans are parameterized and can be composed, we allow parameterized and composable designs as well. Both promote reusability. 7.
Reference: [15] <author> E.M. Clark, M. C. Browne, E. A. Emerson, and A. P. Sistla. </author> <title> Using temporal logic for automatic verification of finite state systems. </title> <editor> In K. R. Apt, editor, </editor> <booktitle> Logics and Models of Concurrent Systems, </booktitle> <pages> pages 3-26. </pages> <publisher> Springer-Verlag Berlin Heidelberg, </publisher> <year> 1985. </year>
Reference-contexts: Instead temporal operators are used to describe properties of states that are reachable from a given state. At present, mechanization of temporal logic has mostly been confined to propositional temporal logic [26]. Propositional temporal logic is suitable for verifying properties of finite state systems <ref> [15] </ref> but not for specifying general problems. One other disadvantage of temporal logic is the inability to express time durations. 4.2 Our Approach In this section, we describe how various constraints on solutions may be expressed as Lisp predicates on plans in the logic.
Reference: [16] <author> B Cohen. </author> <title> Justification of formal methods for system specification. </title> <journal> Software Engineering Journal, </journal> <pages> pages 26-35, </pages> <month> January </month> <year> 1989. </year>
Reference-contexts: The output state must have the same set of blocks as the input state. Such a program specification is called a requirements specification <ref> [63, 64, 16, 20] </ref> and is usually the starting point of the software life cycle [64, 16]. <p> The output state must have the same set of blocks as the input state. Such a program specification is called a requirements specification [63, 64, 16, 20] and is usually the starting point of the software life cycle <ref> [64, 16] </ref>.
Reference: [17] <author> R. L. Constable et al. </author> <title> Implementing Mathematics with the Nuprl Proof Development System. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, New Jersey, </address> <year> 1986. </year>
Reference-contexts: Rather, correctness-preserving transformations are used to synthesize efficient programs from inefficient algorithms that can be easily specified in a very high-level programming language. Yet another approach to program synthesis that is being tried is theorem proving in a constructive logic <ref> [17] </ref>. So far, this approach has been used primarily for constructing applicative programs [71] rather than imperative programs. Artificial intelligence techniques have also been applied to software engineering [105, 65].
Reference: [18] <author> D. Good, et al. </author> <title> Report on the language GYPSY version 2.0. </title> <type> Technical Report ICSCA-CMP-10, </type> <institution> Institute for Computing Science and Computer Applications, University of Texas at Austin, </institution> <year> 1978. </year>
Reference-contexts: So much for relevant research in artificial intelligence. Since von Neumann machines are also problem domains and since plans resemble programs, it behooves us to look carefully into research in mechanical program verification <ref> [9, 10, 18] </ref>.
Reference: [19] <author> O-J. Dahl, E. W. Dijkstra, and C. A. R. Hoare. </author> <title> Structured Programming. </title> <publisher> Academic Press, </publisher> <address> Orlando, Fla., </address> <year> 1972. </year>
Reference: [20] <author> A. M. Davis. </author> <title> Software Requirements: Analysis and Specification. </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1990. </year>
Reference-contexts: The output state must have the same set of blocks as the input state. Such a program specification is called a requirements specification <ref> [63, 64, 16, 20] </ref> and is usually the starting point of the software life cycle [64, 16]. <p> It is now known that the most expensive errors are caused by errors in the requirements specification stemming from a misunderstanding by the designer of the customer's needs <ref> [20, 40, 64, 46, 1] </ref>. Formal validation, the technique of formalizing the requirements specification, proving general properties that follow from the formal requirements specification and then comparing those with the informal requirements specification, has been proposed [40, 46, 33] to minimize such errors. <p> Formal validation, the technique of formalizing the requirements specification, proving general properties that follow from the formal requirements specification and then comparing those with the informal requirements specification, has been proposed [40, 46, 33] to minimize such errors. However, in many cases <ref> [20, 1] </ref>, a customer cannot be expected to know exactly what she wants before a prototype of the product is built nor be expected to not change the requirements after interacting with the prototype.
Reference: [21] <editor> J. De Kleer. </editor> <booktitle> An Assumption-based TMS, </booktitle> <pages> pages 280-298. </pages> <note> In Ginsberg [38], </note> <year> 1987. </year>
Reference-contexts: Such solutions are applicable to a class of domains. 3. Since proofs of theorems about one domain do not interfere with proofs of theorems about another, we do not need a "truth maintenance" mechanism <ref> [25, 21] </ref> for deleting proofs that no longer hold simply because the domain has changed. 4. Since domains are represented as data structures in Lisp, we can consider modifications other than addition of new information to a domain.
Reference: [22] <author> E. W. Dijkstra. </author> <booktitle> Notes on Structured Programming, </booktitle> <pages> pages 1-82. </pages> <note> In [19], </note> <year> 1972. </year>
Reference-contexts: In fact, the problem of combining primitive actions into programs that satisfy an input-output specification arises in practically all stages of top-down, stepwise program development <ref> [22, 64, 54] </ref>. Jones [54, page 75] describes the process of stepwise program development as follows: At each intermediate step of development the given specification is being realized in terms of sub-units. <p> When designing a program, we may have to take into consideration the available hardware on which the program is going to be ultimately executed to choose our solution. As Dijkstra <ref> [22, page 23] </ref> puts it: It is a programmer's everyday experience that for a given problem to be solved by a given algorithm, the program for a given machine is far from uniquely determined.
Reference: [23] <author> E. W. Dijkstra. </author> <title> Why correctness must be a mathematical concern. </title> <editor> In R. S. Boyer and J S. Moore, editors, </editor> <booktitle> The Correctness Problem in Computer Science. </booktitle> <publisher> Academic Press, </publisher> <address> London, </address> <year> 1981. </year>
Reference-contexts: We are quite used to sharing code|in the form of procedural abstractions in libraries|but here we are talking about 6 specifications sharing parts, proofs sharing arguments, theories sharing abstractions, even problems sharing common aspects. Similar sentiments are also expressed in <ref> [23, pages 7-8] </ref> and [53, pages 9-12]. Even when there are reusable design histories, the burden of figuring out what to redesign and what to reuse rests with the designer.
Reference: [24] <author> E.W. Dijkstra. </author> <title> A Discipline of Programming. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1976. </year>
Reference-contexts: execution of the plan is executable. 1.3 Experimental Requirements The purpose of this section is to outline precisely the experimental requirements of the mechanized theory we are attempting to construct and to discuss some 2 The use of "precondition" here is somewhat different from preconditions in the program verification literature <ref> [24, 54] </ref>. In program verification, we usually do not care how the program executes in a state that does not satisfy a precondition but here an action cannot be executed in a state that does not satisfy its preconditions. 8 of the obstacles we must overcome to achieve our goal. <p> Both actions and plans are programs that use add and delete operations. Actions do not terminate when executed in states that do not meet their preconditions. Non-termination is modeled using a special instruction abort as in <ref> [24, 39] </ref>.
Reference: [25] <author> J. Doyle. </author> <booktitle> A truth maintenance system, </booktitle> <pages> pages 259-279. </pages> <note> In Ginsberg [38], </note> <year> 1987. </year>
Reference-contexts: Such solutions are applicable to a class of domains. 3. Since proofs of theorems about one domain do not interfere with proofs of theorems about another, we do not need a "truth maintenance" mechanism <ref> [25, 21] </ref> for deleting proofs that no longer hold simply because the domain has changed. 4. Since domains are represented as data structures in Lisp, we can consider modifications other than addition of new information to a domain.
Reference: [26] <author> E. A. Emerson. </author> <title> Temporal and modal logic. </title> <editor> In J. van Leeuwen, editor, </editor> <booktitle> Handbook of Theoretical Computer Science, volume B. </booktitle> <publisher> North-Holland Publishing Company,Amsterdam, </publisher> <year> 1990. </year>
Reference-contexts: A reactive system is one whose role is to maintain an ongoing, usually non-terminating, interaction with its environment. Examples of such systems are digital watches, vending machines, and microwave ovens. Most reactive systems involve concurrent actions. Temporal logic <ref> [67, 66, 26] </ref> based on modal logic has often been advocated as a formalism for specifying the behavior of reactive systems. In a temporal logic, explicit mention of states is avoided, i.e., there are no terms that stand for states. <p> Instead temporal operators are used to describe properties of states that are reachable from a given state. At present, mechanization of temporal logic has mostly been confined to propositional temporal logic <ref> [26] </ref>. Propositional temporal logic is suitable for verifying properties of finite state systems [15] but not for specifying general problems.
Reference: [27] <author> H Enderton. </author> <title> A Mathematical Introduction To Logic. </title> <publisher> Academic Press, Inc., </publisher> <address> Orlando, FL, </address> <year> 1972. </year> <month> 219 </month>
Reference-contexts: For instance, a 1 It seems unlikely that a problem solving system can generate correct plans to solve general problems automatically since practically any formal system <ref> [27] </ref> such as set theory can be posed as a problem domain with formulas or sequences of formulas as states and inference rules as actions. 4 design that solves our programming exercise may consist of two procedures: a primitive procedure to unstack a block whenever the block is clear and another
Reference: [28] <author> S Fahlman. </author> <title> A planning system for robot construction tasks. </title> <journal> Artificial Intelligence, </journal> <volume> 5 </volume> <pages> 1-49, </pages> <year> 1974. </year>
Reference-contexts: These examples demonstrate how a single domain theory can be reused to verify plans for solving multiple problems within the domain. We also show how a variation of the blocks world (originally used by Fahlman <ref> [28] </ref> and suggested to us by Richard Waldinger) in which the move action has the side-effect of moving the blocks on top of it can be modeled using our approach. We give an example of a plan to form a single tower using all the blocks in the initial state. <p> The blocks world has been used as an example problem domain in AI for a long time <ref> [118, 112, 28] </ref> and at present there is some controversy over whether or not it is a "solved" problem. <p> In Section 2.3, we specify a variation of the blocks world that shows more clearly how our method is applicable to domains in which actions have side-effects. This blocks world <ref> [28] </ref> includes exactly one move 36 37 action which has the side-effect of moving all the blocks above the block that is moved along with it. We present an example of a plan to form a single tower using all the blocks in the initial state. <p> ), set-of-blocks (s2 ))) ! (resultlist (transform (s1 , s2 ), s1 ) = s2 ) 2.3 Specification of Actions with Side-effects To further clarify how our method can be used to specify domains involving actions that produce side-effects, we will specify a variation of the blocks world given in <ref> [28] </ref>. The set of states is the same as before. We are allowed only one action, move a block to the top of another block. This action has the side-effect of moving all the blocks above the block being moved along with it to the new location.
Reference: [29] <author> R. E. Fikes, P. E. Hart, and N. J. Nilsson. </author> <title> Learning and executing generalized robot plans. </title> <journal> Artificial Intelligence, </journal> <volume> 3(4) </volume> <pages> 251-288, </pages> <year> 1972. </year>
Reference-contexts: A recent theoretical proposal that also treats plans as programs is reported in [111]. The authors propose a logical framework for specifying consistent axiom-atizations of planning domains in Dynamic Logic [45] using a STRIPS-like <ref> [30, 29] </ref> representation of actions. Unlike the situation calculus, states are not explicitly represented as terms in dynamic logic but are instead referred to using modal operators.
Reference: [30] <author> R. E. Fikes and N. J. Nilsson. </author> <title> STRIPS: A new approach to the application of theorem proving to problem solving. </title> <journal> Artificial Intelligence, </journal> <volume> 2 </volume> <pages> 189-208, </pages> <year> 1971. </year>
Reference-contexts: Commonsense reasoning is concerned with the construction of robots that can plan and act to achieve their goals in the physical world. Problem domains in commonsense reasoning and traditional robot planning <ref> [30, 2] </ref> consist of a robot with preprogrammed action routines that it can execute sequentially to manipulate objects in its physical environment. Consider the well-known example of a robot in a blocks world [37]. <p> A recent theoretical proposal that also treats plans as programs is reported in [111]. The authors propose a logical framework for specifying consistent axiom-atizations of planning domains in Dynamic Logic [45] using a STRIPS-like <ref> [30, 29] </ref> representation of actions. Unlike the situation calculus, states are not explicitly represented as terms in dynamic logic but are instead referred to using modal operators.
Reference: [31] <author> Art Flatau. </author> <title> A Verified Implementation of an Applicative Language with Dynamic Storage Allocation. </title> <type> PhD thesis, </type> <institution> University of Texas at Austin, </institution> <year> 1992. </year>
Reference-contexts: Such constraints may also be phrased in terms of properties of states that ensue during the execution of the plan. For instance, Flatau <ref> [31] </ref> discusses the mechanical verification of a compiler that takes into account the resource constraints of the target machine when generating code.
Reference: [32] <author> Mark S. Fox and Stephen F. Smith. </author> <title> A Knowledge-based System for Factory Scheduling, pages 336-360. </title> <editor> In Allen et al. </editor> <volume> [2], </volume> <year> 1990. </year>
Reference-contexts: Vere [114] describes a planning system that accepts problems in propositional STRIPS [113] as input and generates a "partially ordered network of activities" as output. Fox <ref> [32] </ref> describes an expert system to plan and schedule tasks required for manufacturing products. More recently, Penberthy and Weld [103] describe a planner based on propositional STRIPS to generate plans that satisfy some temporal constraints.
Reference: [33] <author> S. J. Garland, J. V. Guttag, and J. J. Horning. </author> <title> Debugging Larch Shared Language specifications. </title> <journal> IEEE Transactions on Software Engineering, </journal> <pages> pages 1044-1057, </pages> <month> September </month> <year> 1990. </year>
Reference-contexts: Formal validation, the technique of formalizing the requirements specification, proving general properties that follow from the formal requirements specification and then comparing those with the informal requirements specification, has been proposed <ref> [40, 46, 33] </ref> to minimize such errors. However, in many cases [20, 1], a customer cannot be expected to know exactly what she wants before a prototype of the product is built nor be expected to not change the requirements after interacting with the prototype. <p> Unfortunately, the specification of actions with side-effects has been a problem using this approach [63]. A recent paper [7] also explains why the frame problem must be addressed by these specification languages. In any case, mechanical support for developing programs using these formalisms is still at a rudimentary stage <ref> [53, 33] </ref>. VDM and Z are more notations for humans to use when developing software rather than languages with a precise formal semantics [6]. <p> VDM and Z are more notations for humans to use when developing software rather than languages with a precise formal semantics [6]. The Larch Shared Language, however, has been used for expressing and validating some state-independent properties of a specification such as consistency using the Larch Prover <ref> [33, 41] </ref>. A related approach for developing software is the use of program transformations [105, pages 97-192]. However, this approach does not take the problem specification as the starting point of program synthesis. <p> From the standpoint of rapid prototyping, our approach has the advantage that we can execute requirements specifications a la Lisp programs as well as prove general properties about them as in formal validation <ref> [33, 46, 1] </ref>. Similarly, whether a particular prototype (plan) satisfies a specification or not can be ascertained by either direct execution on test cases or "scenarios" [64, pages 257-262] or by mechanical verification. The former has the advantage of getting simple bugs out of the way. 28 6. <p> Because we have a single framework within which all problem domains are formalized, we have the advantage of reusability; work done about one domain can be reused in another. Also, specifications are parameterized and can be composed <ref> [14, 33] </ref> because they are in a programming language. Since plans are parameterized and can be composed, we allow parameterized and composable designs as well. Both promote reusability. 7.
Reference: [34] <author> N. Gehani and A.D. McGettrick, </author> <title> editors. Software Specification Techniques. </title> <publisher> Addison-Wesley, </publisher> <year> 1986. </year>
Reference-contexts: Such use severely stresses the automated reasoning system because the semantics of interesting machines is extraordinarily complicated. Another group of researchers <ref> [40, 54, 34, 110] </ref> in software engineering have proposed formal specification languages and techniques for verifying designs of programs with respect to specifications. Three typical specification formalisms [117] are Larch [41], VDM [54] and Z (pronounced "zed") [110].
Reference: [35] <author> Michael Gelfond and Vladimir Lifschitz. </author> <title> Representing actions in extended logic programming. </title> <editor> In Krzysztof Apt, editor, </editor> <booktitle> Proc. Joint Int'l Conf. and Symp. on Logic Programming, </booktitle> <pages> pages 559-573, </pages> <year> 1992. </year>
Reference-contexts: Non-monotonic reasoning [38] has been found necessary for dealing with this problem in AI but has proven extremely difficult to formalize [84]. Gelfond and Lifschitz <ref> [35] </ref> identified a simple class of domains, a class of finite state systems, which they describe using a language called A for testing various approaches to formalizing non-monotonic reasoning. <p> The ideas behind the problem of specification modification and the need for non-monotonic reasoning are best illustrated using the class of domains (finite state systems) proposed by Gelfond and Lifschitz <ref> [35] </ref> for testing non-monotonic formalisms. The class of domains under consideration have the following properties: 1. The states of the system are given by the propositional values of a finite number of boolean variables or fluents. 2. Actions are not parameterized and are assumed to be executable in all states. <p> Thus, it is felt that a non-monotonic formalism| usually first-order logic augmented by non-monotonic rules such as circumscription [77, 80, 61]|is needed to express changes to domain specifications, as the following quotation from Gelfond and Lifschitz <ref> [35] </ref> indicates. <p> This also avoids the need for non-monotonic reasoning. The example class of domains in this chapter is the class of finite state machines that can described in the language A <ref> [35] </ref>. The list of events for formalizing this class of domains and proving typical theorems is included in Appendix D. In Chapter 7, we summarize the dissertation and suggest directions for future work. Throughout this dissertation we follow the following style of presentation. <p> In fact, most work in commonsense reasoning <ref> [86, 61, 35] </ref> and imperative program synthesis [105, 65, 70, 72] deals only with such problems. However, as explained in Chapter 1, problems that specify many more constraints on solutions arise in many contexts particularly during program development. <p> Non-monotonic reasoning [38] has been found necessary for dealing with this problem in AI but has proven extremely difficult to formalize [84]. Gelfond and Lifschitz <ref> [35] </ref> identified a simple class of domains, a class of finite state systems, which they describe using a language called A for testing various approaches to formalizing non-monotonic reasoning. <p> Thus, it is felt that a non-monotonic formalism| usually first-order logic augmented by non-monotonic rules such as circumscription [77, 80, 61]|is needed to express changes to domain specifications, as the following quotation from Gelfond and Lifschitz <ref> [35] </ref> indicates. <p> The rest of the chapter is organized as follows. In Section 6.3, we reproduce almost verbatim the rigorous definition of the syntax and semantics of A along with 108 the examples in <ref> [35] </ref>. These examples have been used by researchers in commonsense reasoning as tests or counterexamples to non-monotonic formalisms at various times. In Section 6.4, we describe our formalization of the class of domains that can be specified in A.
Reference: [36] <author> Michael Gelfond, Vladimir Lifschitz, and Arkady Rabinov. </author> <title> What are the limitations of the situation calculus? In Robert Boyer, editor, Automated Reasoning: </title> <booktitle> Essays in Honor of Woody Bledsoe, </booktitle> <pages> pages 167-179. </pages> <publisher> Kluwer Academic, </publisher> <address> Dordrecht, </address> <year> 1991. </year>
Reference-contexts: There is one action Switch1 which causes Light1 to become true when executed in any state. Since the semantics of A incorporates the default rule known as the "commonsense law of inertia" <ref> [61, 36] </ref> that an action does not affect a fluent unless otherwise mentioned in a domain description, the execution of Switch1 in any state is assumed by default to leave the value of Light2 unchanged. <p> There is one action Switch1 which causes Light1 to become true when executed in any state. Since the semantics of A incorporates the default rule known as the "commonsense law of inertia" <ref> [61, 36] </ref> that an action does not affect a fluent unless otherwise mentioned in a domain description, the execution of Switch1 in any state is assumed by default to leave the value of Light2 unchanged.
Reference: [37] <author> M. R. Genesereth and N. J. Nilsson. </author> <booktitle> Logical Foundations of Artificial Intelligence. </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> Los Altos, CA, </address> <year> 1987. </year>
Reference-contexts: Problem domains in commonsense reasoning and traditional robot planning [30, 2] consist of a robot with preprogrammed action routines that it can execute sequentially to manipulate objects in its physical environment. Consider the well-known example of a robot in a blocks world <ref> [37] </ref>. There is a table on which there are an arbitrary number of cubical blocks stacked one on top of another. Every block can be either on top of exactly one other block or on the table. <p> Thus, we are left with point 1. Fortunately, a rigorous state-transition model of problem domains is already available and, by now, well-understood in AI 7 <ref> [37, 101] </ref>. It is also well-known that a fairly large number of problems fit this model [100, 37, 99]. <p> Thus, we are left with point 1. Fortunately, a rigorous state-transition model of problem domains is already available and, by now, well-understood in AI 7 [37, 101]. It is also well-known that a fairly large number of problems fit this model <ref> [100, 37, 99] </ref>. A problem domain is given by a set of possible states of a physical world and a set of actions that can be executed sequentially to change the state of the world. Actions are deterministic and terminating. <p> This fact does not follow from the axioms that describe the direct effects including side-effects of the put action or the frame axioms. The usual solution to deduce indirect effects is to include state constraints <ref> [37, pages 263-283] </ref> as part of the problem specification. For instance, a state constraint that, in every state a block is either on top of another block or on the table but not both, would allow us to conclude that a is not on top of b after being unstacked.
Reference: [38] <editor> Mathew L. Ginsberg, editor. </editor> <booktitle> Readings in Nonmonotonic Reasoning. </booktitle> <publisher> Morgan-Kaufmann, </publisher> <address> Los Altos, CA, </address> <year> 1987. </year>
Reference-contexts: For this we need a formalism in which not only all possible domains but also facts describing changes to a domain specification can be expressed. Non-monotonic reasoning <ref> [38] </ref> has been found necessary for dealing with this problem in AI but has proven extremely difficult to formalize [84]. <p> For this we need a formalism in which not only all possible domains but also facts describing changes to a domain specification can be expressed. Non-monotonic reasoning <ref> [38] </ref> has been found necessary for dealing with this problem in AI but has proven extremely difficult to formalize [84].
Reference: [39] <editor> David Gries. </editor> <booktitle> The Science of Programming. </booktitle> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1981. </year>
Reference-contexts: Both actions and plans are programs that use add and delete operations. Actions do not terminate when executed in states that do not meet their preconditions. Non-termination is modeled using a special instruction abort as in <ref> [24, 39] </ref>.
Reference: [40] <author> J. V. Guttag and J. J. Horning. </author> <title> Formal Specification as a Design Tool, </title> <booktitle> pages 187-209. In Gehani and McGettrick [34], </booktitle> <year> 1986. </year>
Reference-contexts: It is now known that the most expensive errors are caused by errors in the requirements specification stemming from a misunderstanding by the designer of the customer's needs <ref> [20, 40, 64, 46, 1] </ref>. Formal validation, the technique of formalizing the requirements specification, proving general properties that follow from the formal requirements specification and then comparing those with the informal requirements specification, has been proposed [40, 46, 33] to minimize such errors. <p> Formal validation, the technique of formalizing the requirements specification, proving general properties that follow from the formal requirements specification and then comparing those with the informal requirements specification, has been proposed <ref> [40, 46, 33] </ref> to minimize such errors. However, in many cases [20, 1], a customer cannot be expected to know exactly what she wants before a prototype of the product is built nor be expected to not change the requirements after interacting with the prototype. <p> Such use severely stresses the automated reasoning system because the semantics of interesting machines is extraordinarily complicated. Another group of researchers <ref> [40, 54, 34, 110] </ref> in software engineering have proposed formal specification languages and techniques for verifying designs of programs with respect to specifications. Three typical specification formalisms [117] are Larch [41], VDM [54] and Z (pronounced "zed") [110].
Reference: [41] <author> J. V. Guttag, J. J. Horning, and J. M. Wing. </author> <title> Larch in five easy pieces. </title> <type> Technical Report 5, </type> <institution> DEC Systems Research Center, </institution> <month> July </month> <year> 1985. </year>
Reference-contexts: Another group of researchers [40, 54, 34, 110] in software engineering have proposed formal specification languages and techniques for verifying designs of programs with respect to specifications. Three typical specification formalisms [117] are Larch <ref> [41] </ref>, VDM [54] and Z (pronounced "zed") [110]. In all three formalisms, a system (problem domain) to be constructed is typically formalized as a set of states and a set of operations or procedures to change state. <p> VDM and Z are more notations for humans to use when developing software rather than languages with a precise formal semantics [6]. The Larch Shared Language, however, has been used for expressing and validating some state-independent properties of a specification such as consistency using the Larch Prover <ref> [33, 41] </ref>. A related approach for developing software is the use of program transformations [105, pages 97-192]. However, this approach does not take the problem specification as the starting point of program synthesis.
Reference: [42] <author> S. Hanks and D. McDermont. </author> <title> Default reasoning, nonmonotonic logics and the frame problem. </title> <booktitle> In Proc. AAAI-86, </booktitle> <volume> volume 1, </volume> <pages> pages 328-333, </pages> <year> 1986. </year> <month> 220 </month>
Reference-contexts: But as McCarthy [84] explains: : : : unfortunately the most obvious and apparently natural axiomati-zations tend to have unintended models, and this has been observed in several examples, especially the Yale Shooting Problem <ref> [42] </ref>. This has led to revised formalizations which work but don't seem so natural. It isn't clear whether there is a problem with the systems of nonmonotonic reasoning or whether we simply don't have the right axiom sets.
Reference: [43] <author> Steve Hanks and Drew McDermott. </author> <title> Nonmonotonic logic and temporal projection. </title> <journal> Artificial Intelligence, </journal> <volume> 33(3) </volume> <pages> 379-412, </pages> <year> 1987. </year>
Reference-contexts: The Fragile Object domain, motivated by an example from [108], has the fluent names Holding, Fragile and Broken, and the action Drop. It consists of two e-propositions: Drop causes :Holding if Holding; Drop causes Broken if Holding; Fragile: Example 2. The Yale Shooting domain, motivated by the example from <ref> [43] </ref>, is defined as follows. The fluent names are Loaded and Alive; the action names are Load, Shoot and Wait . The domain is characterized by the propositions initially :Loaded; initially Alive; Load causes Loaded; Shoot causes :Alive if Loaded; Shoot causes :Loaded: Example 3.
Reference: [44] <author> D. Harel and A. Pnueli. </author> <title> On the development of reactive systems. </title> <editor> In K. R. Apt, editor, </editor> <booktitle> Logics and Models of Concurrent Systems, </booktitle> <pages> pages 477-498. </pages> <publisher> Springer-Verlag Berlin Heidelberg, </publisher> <year> 1985. </year>
Reference-contexts: Some temporal logics have also been proposed in AI [3, 89, 87] but it is unclear how effective they are in practice. Constraints on execution sequences generated by the actions of an agent also arise when specifying the behavior of reactive systems <ref> [44, 67] </ref>. A reactive system is one whose role is to maintain an ongoing, usually non-terminating, interaction with its environment. Examples of such systems are digital watches, vending machines, and microwave ovens. Most reactive systems involve concurrent actions.
Reference: [45] <author> David Harel. </author> <title> First-Order Dynamic Logic, </title> <booktitle> volume 68 of Lecture Notes in Computer Science. </booktitle> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1979. </year>
Reference-contexts: A recent theoretical proposal that also treats plans as programs is reported in [111]. The authors propose a logical framework for specifying consistent axiom-atizations of planning domains in Dynamic Logic <ref> [45] </ref> using a STRIPS-like [30, 29] representation of actions. Unlike the situation calculus, states are not explicitly represented as terms in dynamic logic but are instead referred to using modal operators.
Reference: [46] <author> I. J. Hayes and C. B. Jones. </author> <title> Specifications are not (necessarily) executable. </title> <journal> Software Engineering Journal, </journal> <pages> pages 330-338, </pages> <month> November </month> <year> 1989. </year>
Reference-contexts: It is now known that the most expensive errors are caused by errors in the requirements specification stemming from a misunderstanding by the designer of the customer's needs <ref> [20, 40, 64, 46, 1] </ref>. Formal validation, the technique of formalizing the requirements specification, proving general properties that follow from the formal requirements specification and then comparing those with the informal requirements specification, has been proposed [40, 46, 33] to minimize such errors. <p> Formal validation, the technique of formalizing the requirements specification, proving general properties that follow from the formal requirements specification and then comparing those with the informal requirements specification, has been proposed <ref> [40, 46, 33] </ref> to minimize such errors. However, in many cases [20, 1], a customer cannot be expected to know exactly what she wants before a prototype of the product is built nor be expected to not change the requirements after interacting with the prototype. <p> There are two main problems in using constructs from a language like ALGOL or PASCAL to model actions. One is the problem of modeling preconditions since actions are partial functions executable only in those states that satisfy their preconditions <ref> [86, 46] </ref>. The other is the problem of specifying actions with side-effects [47]. One of the first attempts to automatically generate recursive plans to solve general problems is that of Manna and Waldinger [69, 72]. <p> From the standpoint of rapid prototyping, our approach has the advantage that we can execute requirements specifications a la Lisp programs as well as prove general properties about them as in formal validation <ref> [33, 46, 1] </ref>. Similarly, whether a particular prototype (plan) satisfies a specification or not can be ascertained by either direct execution on test cases or "scenarios" [64, pages 257-262] or by mechanical verification. The former has the advantage of getting simple bugs out of the way. 28 6. <p> It is perhaps for this reason that it is sometimes argued that specification languages for programs must not be executable <ref> [46] </ref>. When actions are partially specified, they cannot be modeled as programs. Therefore, it would not be possible for us to define an interpreter for the system and reason about it as we have been doing so far.
Reference: [47] <author> P. J Hayes. </author> <title> A logic of actions. </title> <editor> In D Michie and B Meltzer, editors, </editor> <booktitle> Machine Intelligence, </booktitle> <volume> volume 6, </volume> <pages> pages 495-520. </pages> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1971. </year>
Reference-contexts: One is the problem of modeling preconditions since actions are partial functions executable only in those states that satisfy their preconditions [86, 46]. The other is the problem of specifying actions with side-effects <ref> [47] </ref>. One of the first attempts to automatically generate recursive plans to solve general problems is that of Manna and Waldinger [69, 72]. <p> What makes the frame problem a problem is that, in domains of realistic complexity, there are many more actions and fluents and so many more frame axioms, thus making it practically impossible to obtain economical problem specifications. A related problem is the problem of side-effects <ref> [47, 102, 115] </ref>. This precludes the use of the "programming convention" that all fluents other than those explicitly asserted to change in the problem specification are left unchanged by an action. Side-effects are the changes caused by an action in objects other than its arguments.
Reference: [48] <author> Pat Hayes, </author> <month> January </month> <year> 1993. </year> <booktitle> In the Second Symposium on Logical Formalizations of Commonsense Reasoning. </booktitle>
Reference-contexts: While many blocks world implementations exist, very few of them can express general problems and verify plans such as the plan for clearing a block [72] that require mathematical induction. It is perhaps for this reason that Hayes <ref> [48] </ref> remarked recently that "we do not know how to do the blocks world very well". McCarthy [74] lists the blocks world as an "open problem" and Minsky [93, page 29] justifies the use of the blocks world as follows.
Reference: [49] <author> C. A. R. </author> <title> Hoare. </title> <booktitle> Notes on Data Structuring, </booktitle> <pages> pages 83-174. </pages> <note> In [19], </note> <year> 1972. </year>
Reference-contexts: A requirements specification is an informal but precise specification of the program to be constructed couched in the vocabulary of the customer, the person who wants the program built. Frequently, a requirements specification involves objects of the physical world <ref> [105, 68, 49, 56] </ref> as in the blocks world programming exercise.
Reference: [50] <author> J. R. Hobbs and R. C. Moore, </author> <title> editors. Formal Theories of the Commonsense World. </title> <publisher> Ablex, </publisher> <address> Norwood, NJ, </address> <year> 1985. </year>
Reference: [51] <editor> IEEE. </editor> <booktitle> Proceedings of the Fifth International Workshop on Software Specification and Design, </booktitle> <year> 1989. </year>
Reference-contexts: Some work on building automated systems that can take into account changes to problem specifications and programs is currently underway [96, 97, 106], particularly in the area of requirements acquisition <ref> [51] </ref>. The idea of constructing a program that can accept as input declarative facts that describe modifications to domain specifications so that the necessary changes to specifications are carried out automatically by the program is being pursued by many researchers in artificial intelligence [76, 79, 77, 81].
Reference: [52] <author> C. B. Jones and P. A. Lindsay. </author> <title> A support system for formal reasoning: Requirements and status. </title> <editor> In R. Bloomfield, L. Marshall, and R. Jones, editors, VDM'88: </editor> <title> VDM | The Way Ahead, </title> <booktitle> Lecture Notes in Computer Science, </booktitle> <pages> pages 139-152. </pages> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1988. </year>
Reference-contexts: At present, the importance of mechanizing all phases of the software life cycle and the utility of interactive mechanical verification of designs with respect to a specification during the software development process are well understood <ref> [52, 105, 65, 53] </ref>. The idea is to eliminate errors in the product as early as possible in the software life cycle, preferably well before the program is coded in a programming language. <p> Thus, reusable theories and libraries <ref> [52, 65, 53] </ref> have been identified as an important requirement for automated software design. As Woodcock [120] puts it: Re-usability is vital to the successful application of formal methods: it allows us to remain flexible by sharing descriptions at every stage of the development process.
Reference: [53] <author> C.B. Jones, K.D. Jones, P.A. Lindsay, and R. Moore. </author> <title> Mural: A Formal Development Support System. </title> <publisher> Springer-Verlag, </publisher> <address> London, U.K., </address> <year> 1991. </year>
Reference-contexts: At present, the importance of mechanizing all phases of the software life cycle and the utility of interactive mechanical verification of designs with respect to a specification during the software development process are well understood <ref> [52, 105, 65, 53] </ref>. The idea is to eliminate errors in the product as early as possible in the software life cycle, preferably well before the program is coded in a programming language. <p> Thus, reusable theories and libraries <ref> [52, 65, 53] </ref> have been identified as an important requirement for automated software design. As Woodcock [120] puts it: Re-usability is vital to the successful application of formal methods: it allows us to remain flexible by sharing descriptions at every stage of the development process. <p> We are quite used to sharing code|in the form of procedural abstractions in libraries|but here we are talking about 6 specifications sharing parts, proofs sharing arguments, theories sharing abstractions, even problems sharing common aspects. Similar sentiments are also expressed in [23, pages 7-8] and <ref> [53, pages 9-12] </ref>. Even when there are reusable design histories, the burden of figuring out what to redesign and what to reuse rests with the designer. Some work on building automated systems that can take into account changes to problem specifications and programs is currently underway [96, 97]. <p> Unfortunately, the specification of actions with side-effects has been a problem using this approach [63]. A recent paper [7] also explains why the frame problem must be addressed by these specification languages. In any case, mechanical support for developing programs using these formalisms is still at a rudimentary stage <ref> [53, 33] </ref>. VDM and Z are more notations for humans to use when developing software rather than languages with a precise formal semantics [6].
Reference: [54] <author> Cliff B. Jones. </author> <title> Software Development: A Rigorous Approach. </title> <publisher> Prentice-Hall International, Inc., </publisher> <address> London, </address> <year> 1980. </year>
Reference-contexts: In fact, the problem of combining primitive actions into programs that satisfy an input-output specification arises in practically all stages of top-down, stepwise program development <ref> [22, 64, 54] </ref>. Jones [54, page 75] describes the process of stepwise program development as follows: At each intermediate step of development the given specification is being realized in terms of sub-units. <p> In fact, the problem of combining primitive actions into programs that satisfy an input-output specification arises in practically all stages of top-down, stepwise program development [22, 64, 54]. Jones <ref> [54, page 75] </ref> describes the process of stepwise program development as follows: At each intermediate step of development the given specification is being realized in terms of sub-units. Such a realization is a way of achieving the given specification (documented with pre-/post-conditions) in terms of more basic objects. <p> To develop correct programs, we need proofs to show that "given any set of modules which satisfy the specifications of the sub-units, combining such modules in the way specified forms a unit which satisfies the given specification" <ref> [54, page 76] </ref>. At present, the importance of mechanizing all phases of the software life cycle and the utility of interactive mechanical verification of designs with respect to a specification during the software development process are well understood [52, 105, 65, 53]. <p> execution of the plan is executable. 1.3 Experimental Requirements The purpose of this section is to outline precisely the experimental requirements of the mechanized theory we are attempting to construct and to discuss some 2 The use of "precondition" here is somewhat different from preconditions in the program verification literature <ref> [24, 54] </ref>. In program verification, we usually do not care how the program executes in a state that does not satisfy a precondition but here an action cannot be executed in a state that does not satisfy its preconditions. 8 of the obstacles we must overcome to achieve our goal. <p> Such use severely stresses the automated reasoning system because the semantics of interesting machines is extraordinarily complicated. Another group of researchers <ref> [40, 54, 34, 110] </ref> in software engineering have proposed formal specification languages and techniques for verifying designs of programs with respect to specifications. Three typical specification formalisms [117] are Larch [41], VDM [54] and Z (pronounced "zed") [110]. <p> Another group of researchers [40, 54, 34, 110] in software engineering have proposed formal specification languages and techniques for verifying designs of programs with respect to specifications. Three typical specification formalisms [117] are Larch [41], VDM <ref> [54] </ref> and Z (pronounced "zed") [110]. In all three formalisms, a system (problem domain) to be constructed is typically formalized as a set of states and a set of operations or procedures to change state.
Reference: [55] <author> Henry Kautz. </author> <title> The logic of persistence. </title> <booktitle> In Proc. of AAAI-86, </booktitle> <pages> pages 401-405, </pages> <year> 1986. </year>
Reference-contexts: The Murder Mystery domain, motivated by an example from [4], is obtained from the Yale Shooting domain by substituting :Alive after Shoot ; Wait (6:3) for the proposition initially :Loaded. Example 4. The Stolen Car domain, motivated by an example from <ref> [55] </ref>, has one fluent name Stolen and one action name Wait , and is characterized by two propositions: initially :Stolen; Stolen after Wait ; Wait; Wait: The Stolen Car domain shows that inconsistent constraints may be specified about a domain.
Reference: [56] <author> R. A. Kemmerer. </author> <title> Testing formal specifications to detect design errors. </title> <journal> IEEE Transactions on Software Engineering, </journal> <pages> pages 32-43, </pages> <month> January </month> <year> 1985. </year>
Reference-contexts: A requirements specification is an informal but precise specification of the program to be constructed couched in the vocabulary of the customer, the person who wants the program built. Frequently, a requirements specification involves objects of the physical world <ref> [105, 68, 49, 56] </ref> as in the blocks world programming exercise. <p> We have chosen this example for three reasons. First, proofs that show that a plan or a class of plans does not satisfy a requirements specification seem to be needed during software development <ref> [56] </ref>. Therefore, a mechanical system for program development must be able to carry out such proofs even when they involve concepts not directly mentioned in the problem statement.
Reference: [57] <author> A. Klausner and T. E. Konchan. </author> <title> Rapid Prototyping and Requirements Specification Using PDS, </title> <booktitle> pages 441-454. In Gehani and McGettrick [34], </booktitle> <year> 1986. </year>
Reference-contexts: However, in many cases [20, 1], a customer cannot be expected to know exactly what she wants before a prototype of the product is built nor be expected to not change the requirements after interacting with the prototype. Rapid prototyping <ref> [57, 1] </ref> has been proposed to minimize the cost incurred when dealing with a changing requirements specification. Here the system designer takes a best guess at a requirements 5 specification and produces a prototype that the customer can interact with.
Reference: [58] <author> F. Kluzniak and S. Szpakowicz. </author> <title> Extract from Prolog for Programmers, pages 140-153. </title> <editor> In Allen et al. </editor> <volume> [2], </volume> <year> 1990. </year> <month> 221 </month>
Reference-contexts: Our first representation of blocks world states is as a list of terms that stand for primitive relations between blocks in a state such as On (A; B), Ontable (D) and Clear (C). This representation has been used in AI programs written in PLANNER [118] and Prolog <ref> [58] </ref>, and is used currently by many existing planning programs [113]. The representation turns out to be inconvenient for specifying the predicate on the set of possible states because it forces us to specify a number of state constraints explicitly.
Reference: [59] <author> R. A. Kowalski. </author> <title> Logic for Problem Solving. </title> <publisher> North-Holland, </publisher> <address> New York, </address> <year> 1979. </year>
Reference-contexts: We can use lambda expressions to also represent other kinds of fluents such as propositional fluents that are predicates on states as in [76, 72] and define the celebrated holds predicate <ref> [59, 61] </ref> in the same way we defined result. For instance, corresponding to predicates find-stack-of-block and on from Chapter 2, we can form fluent terms s: find-stack-of-block (b, s) and s: on (b1 b2 s).
Reference: [60] <author> C. Lafontaine, Y. Ledru, and P.-Y. Schobbens. </author> <title> An experiment in formal software development. </title> <journal> Communications of the ACM, </journal> <volume> 34(5) </volume> <pages> 62-71, </pages> <year> 1991. </year>
Reference-contexts: Plans for solving problems such as the problem of clearing a block are nothing but prototypes that can be verified against a formal requirements specification given by the initial and goal condition. And this is true whether we are developing programs for computers or for robots (cf. <ref> [60] </ref>). Another issue in software development is program modification [64, page 252], the changes that must be made to a program perhaps many years after it is written due to changes in the customer's requirements.
Reference: [61] <author> V. Lifschitz. </author> <title> Formal theories of action. </title> <booktitle> In The Frame Problem in Artificial Intelligence: Proceedings of the 1987 Workshop, </booktitle> <address> Los Angeles, CA, </address> <year> 1987. </year>
Reference-contexts: a sentence asserting the loss of a ticket is added, then the original plan can no longer be shown to work and a revised plan involving buying a replacement ticket can be shown to work. 19 Non-monotonic reasoning has been found necessary for this purpose and rules such as circumscription <ref> [77, 80, 61] </ref> have been proposed for formalizing the needed non-monotonic reasoning. The ideas behind the problem of specification modification and the need for non-monotonic reasoning are best illustrated using the class of domains (finite state systems) proposed by Gelfond and Lifschitz [35] for testing non-monotonic formalisms. <p> There is one action Switch1 which causes Light1 to become true when executed in any state. Since the semantics of A incorporates the default rule known as the "commonsense law of inertia" <ref> [61, 36] </ref> that an action does not affect a fluent unless otherwise mentioned in a domain description, the execution of Switch1 in any state is assumed by default to leave the value of Light2 unchanged. <p> Thus, it is felt that a non-monotonic formalism| usually first-order logic augmented by non-monotonic rules such as circumscription <ref> [77, 80, 61] </ref>|is needed to express changes to domain specifications, as the following quotation from Gelfond and Lifschitz [35] indicates. <p> In fact, most work in commonsense reasoning <ref> [86, 61, 35] </ref> and imperative program synthesis [105, 65, 70, 72] deals only with such problems. However, as explained in Chapter 1, problems that specify many more constraints on solutions arise in many contexts particularly during program development. <p> We can use lambda expressions to also represent other kinds of fluents such as propositional fluents that are predicates on states as in [76, 72] and define the celebrated holds predicate <ref> [59, 61] </ref> in the same way we defined result. For instance, corresponding to predicates find-stack-of-block and on from Chapter 2, we can form fluent terms s: find-stack-of-block (b, s) and s: on (b1 b2 s). <p> There is one action Switch1 which causes Light1 to become true when executed in any state. Since the semantics of A incorporates the default rule known as the "commonsense law of inertia" <ref> [61, 36] </ref> that an action does not affect a fluent unless otherwise mentioned in a domain description, the execution of Switch1 in any state is assumed by default to leave the value of Light2 unchanged. <p> Thus, it is felt that a non-monotonic formalism| usually first-order logic augmented by non-monotonic rules such as circumscription <ref> [77, 80, 61] </ref>|is needed to express changes to domain specifications, as the following quotation from Gelfond and Lifschitz [35] indicates.
Reference: [62] <author> T. A. Linden. </author> <title> Representing Software Designs as Partially Developed Plans, </title> <booktitle> pages 603-626. In Lowry and McCartney [65], </booktitle> <year> 1991. </year>
Reference-contexts: domain, involving array assignments, destructive list operations, and other alterations of data structures. 3 While they have observed that imperative programs may also be regarded as plans, we have shown that many problems in the initial stages of the software development process can also be regarded as planning problems (cf. <ref> [62] </ref>). 12 They formalize the problem of clearing a block in plan theory, a first-order logic based on the situation calculus, and describe the task of mechanically synthesizing a recursive program to solve the problem using their deductive tableau theorem prover.
Reference: [63] <author> B. H. Liskov and V. Berzins. </author> <title> An Appraisal of Program Specifications, </title> <booktitle> pages 3-25. In Gehani and McGettrick [34], </booktitle> <year> 1986. </year>
Reference-contexts: The output state must have the same set of blocks as the input state. Such a program specification is called a requirements specification <ref> [63, 64, 16, 20] </ref> and is usually the starting point of the software life cycle [64, 16]. <p> are two kinds of specifications usually distinguished during program development, the specification of a program to be constructed before a particular programming language is chosen and the specification of a program to be written in a particular programming language given in terms of the data structures of the programming language <ref> [63] </ref>. A requirements specification is an informal but precise specification of the program to be constructed couched in the vocabulary of the customer, the person who wants the program built. <p> The essence of the proposal is to view states as sets of positive ground literals such as on (A; B) and actions and plans as programs that modify states by adding and deleting literals. States are supposed to be axiomatized as abstract data types <ref> [63] </ref> using two operations, an add operation and a delete operation. The add operation adds a literal to a state. The delete operation removes a literal from a state if the literal belongs to the state, otherwise it leaves the state unchanged. <p> The variables are allowed to take on values of abstract data types that may not be directly available in a programming language. Operations on states are described in terms of the pre- and post-conditions. Unfortunately, the specification of actions with side-effects has been a problem using this approach <ref> [63] </ref>. A recent paper [7] also explains why the frame problem must be addressed by these specification languages. In any case, mechanical support for developing programs using these formalisms is still at a rudimentary stage [53, 33]. <p> For instance, 5 The concepts of actions and specifications of actions are respectively similar in spirit to the concepts of interface specification and behavior specification used in program specification <ref> [63] </ref>. 23 the specification of the move action may be defined by a Lisp program res-move (b1 , b2 , s) that returns an error state (which we normally represent as a list whose car is 'failed) if the input state s does not satisfy the preconditions.
Reference: [64] <author> B.H. Liskov and J.V. Guttag. </author> <title> Abstraction and Specification in Program Development. </title> <publisher> MIT press, </publisher> <address> Cambridge, MA, </address> <year> 1986. </year>
Reference-contexts: The output state must have the same set of blocks as the input state. Such a program specification is called a requirements specification <ref> [63, 64, 16, 20] </ref> and is usually the starting point of the software life cycle [64, 16]. <p> The output state must have the same set of blocks as the input state. Such a program specification is called a requirements specification [63, 64, 16, 20] and is usually the starting point of the software life cycle <ref> [64, 16] </ref>. <p> In fact, the problem of combining primitive actions into programs that satisfy an input-output specification arises in practically all stages of top-down, stepwise program development <ref> [22, 64, 54] </ref>. Jones [54, page 75] describes the process of stepwise program development as follows: At each intermediate step of development the given specification is being realized in terms of sub-units. <p> It is now known that the most expensive errors are caused by errors in the requirements specification stemming from a misunderstanding by the designer of the customer's needs <ref> [20, 40, 64, 46, 1] </ref>. Formal validation, the technique of formalizing the requirements specification, proving general properties that follow from the formal requirements specification and then comparing those with the informal requirements specification, has been proposed [40, 46, 33] to minimize such errors. <p> And this is true whether we are developing programs for computers or for robots (cf. [60]). Another issue in software development is program modification <ref> [64, page 252] </ref>, the changes that must be made to a program perhaps many years after it is written due to changes in the customer's requirements. In such a case, it is useful to minimize the amount of work needed to redesign the program and prove it correct. <p> Apart from the initial condition and goal condition, a specification may also include other kinds of constraints on solutions such as constraints on efficiency 10 and resource utilization <ref> [64] </ref>. Normally, we want not just some program that solves a problem but an efficient one. For instance, the plan to clear a block is optimal in the number of steps because every block above the block being cleared must be moved. <p> Similarly, whether a particular prototype (plan) satisfies a specification or not can be ascertained by either direct execution on test cases or "scenarios" <ref> [64, pages 257-262] </ref> or by mechanical verification. The former has the advantage of getting simple bugs out of the way. 28 6. <p> The ability to "test" plans or program designs in specific situations is particularly useful for rapid prototyping because prototypes can be subject to acceptance tests <ref> [64] </ref> using particular scenarios that a customer is familiar with. This removes errors early in the software life cycle and reduces costs. We will now explain briefly how the theorem prover was guided interactively to the proof of the theorem make-clear-works1.
Reference: [65] <author> Michael R. Lowry and Robert D. </author> <title> McCartney, editors. Automating Software Design. </title> <publisher> AAAI Press, </publisher> <address> Menlo Park, CA, </address> <year> 1991. </year>
Reference-contexts: machines that can be described in the language A, a language designed primarily for testing non-monotonic formalisms. 1.1 Motivation The problem of verifying whether or not a plan can bring about a goal state when executed in an initial state arises in both commonsense reasoning [76, 86] and software development <ref> [105, 65, 72, 70] </ref>. Commonsense reasoning is concerned with the construction of robots that can plan and act to achieve their goals in the physical world. <p> Of course, such problems of program construction using atomic actions arise in various stages of software development. While robot planning involves synthesis of abstract programs from problem specifications for execution by a robot in the external world, program synthesis <ref> [72, 70, 105, 65] </ref>, both interactive and automatic, is concerned with the construction of imperative programs from problem specifications for execution by a computer. To see the analogy with planning, consider the following programming exercise. <p> At present, the importance of mechanizing all phases of the software life cycle and the utility of interactive mechanical verification of designs with respect to a specification during the software development process are well understood <ref> [52, 105, 65, 53] </ref>. The idea is to eliminate errors in the product as early as possible in the software life cycle, preferably well before the program is coded in a programming language. <p> Thus, reusable theories and libraries <ref> [52, 65, 53] </ref> have been identified as an important requirement for automated software design. As Woodcock [120] puts it: Re-usability is vital to the successful application of formal methods: it allows us to remain flexible by sharing descriptions at every stage of the development process. <p> Yet another approach to program synthesis that is being tried is theorem proving in a constructive logic [17]. So far, this approach has been used primarily for constructing applicative programs [71] rather than imperative programs. Artificial intelligence techniques have also been applied to software engineering <ref> [105, 65] </ref>. However, most systems (e.g. [106, 109]) are of the program transformation kind and do not address the issue of formalizing problem domain specifications. <p> Artificial intelligence techniques have also been applied to software engineering [105, 65]. However, most systems (e.g. [106, 109]) are of the program transformation kind and do not address the issue of formalizing problem domain specifications. Further, many of the knowledge-based methods <ref> [65] </ref> do not have facilities for carrying out induction proofs so vital for proving correctness of plans such as the plan to clear a block. 18 1.4.2 Dealing with Specification Modification As mentioned before, the most popular approach used by computer scientists in software engineering for dealing with the problem of <p> In fact, most work in commonsense reasoning [86, 61, 35] and imperative program synthesis <ref> [105, 65, 70, 72] </ref> deals only with such problems. However, as explained in Chapter 1, problems that specify many more constraints on solutions arise in many contexts particularly during program development. The additional constraints in a problem specification may be categorized as follows: 1. Time requirements.
Reference: [66] <author> Z. Manna and A. Pnueli. </author> <title> Verification of concurrent programs: the temporal framework. </title> <editor> In R. S. Boyer and J S. Moore, editors, </editor> <booktitle> The Correctness Problem in Computer Science. </booktitle> <publisher> Academic Press, </publisher> <address> London, </address> <year> 1981. </year>
Reference-contexts: A reactive system is one whose role is to maintain an ongoing, usually non-terminating, interaction with its environment. Examples of such systems are digital watches, vending machines, and microwave ovens. Most reactive systems involve concurrent actions. Temporal logic <ref> [67, 66, 26] </ref> based on modal logic has often been advocated as a formalism for specifying the behavior of reactive systems. In a temporal logic, explicit mention of states is avoided, i.e., there are no terms that stand for states.
Reference: [67] <author> Z. Manna and A. Pnueli. </author> <title> The Temporal Logic of Reactive and Concurrent Systems. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1992. </year>
Reference-contexts: Some temporal logics have also been proposed in AI [3, 89, 87] but it is unclear how effective they are in practice. Constraints on execution sequences generated by the actions of an agent also arise when specifying the behavior of reactive systems <ref> [44, 67] </ref>. A reactive system is one whose role is to maintain an ongoing, usually non-terminating, interaction with its environment. Examples of such systems are digital watches, vending machines, and microwave ovens. Most reactive systems involve concurrent actions. <p> A reactive system is one whose role is to maintain an ongoing, usually non-terminating, interaction with its environment. Examples of such systems are digital watches, vending machines, and microwave ovens. Most reactive systems involve concurrent actions. Temporal logic <ref> [67, 66, 26] </ref> based on modal logic has often been advocated as a formalism for specifying the behavior of reactive systems. In a temporal logic, explicit mention of states is avoided, i.e., there are no terms that stand for states.
Reference: [68] <author> Z. Manna and R. Waldinger. </author> <title> Studies in Automatic Programming Logic. </title> <publisher> North-Holland, </publisher> <address> New York, </address> <year> 1977. </year>
Reference-contexts: A requirements specification is an informal but precise specification of the program to be constructed couched in the vocabulary of the customer, the person who wants the program built. Frequently, a requirements specification involves objects of the physical world <ref> [105, 68, 49, 56] </ref> as in the blocks world programming exercise.
Reference: [69] <author> Z. Manna and R. Waldinger. </author> <title> How to clear a block: plan formation in situational logic. </title> <booktitle> In Proceedings of the Eighth Conference on Automated Deduction. </booktitle> <publisher> LNCS 230, Springer-Verlag, </publisher> <year> 1986. </year>
Reference-contexts: The other is the problem of specifying actions with side-effects [47]. One of the first attempts to automatically generate recursive plans to solve general problems is that of Manna and Waldinger <ref> [69, 72] </ref>. The analogy between plans and programs is explained by them as follows 3 : Plans are closely analogous to imperative programs in that actions may be regarded as computer instructions, tests as conditional branches and the world as a huge data structure. <p> From the standpoint of plan verification, plan theory shares some of the disadvantages commonly associated with the situation calculus 4 style of formalization. First, there is the frame problem <ref> [86, 69] </ref>. In addition to saying what fluents are changed by an action, it is also necessary to provide frame axioms which state explicitly what fluents are left unchanged.
Reference: [70] <author> Z. Manna and R. Waldinger. </author> <title> The deductive synthesis of Imperative LISP programs. </title> <booktitle> In Proc. of AAAI-87, </booktitle> <pages> pages 155-160, </pages> <year> 1987. </year>
Reference-contexts: machines that can be described in the language A, a language designed primarily for testing non-monotonic formalisms. 1.1 Motivation The problem of verifying whether or not a plan can bring about a goal state when executed in an initial state arises in both commonsense reasoning [76, 86] and software development <ref> [105, 65, 72, 70] </ref>. Commonsense reasoning is concerned with the construction of robots that can plan and act to achieve their goals in the physical world. <p> Of course, such problems of program construction using atomic actions arise in various stages of software development. While robot planning involves synthesis of abstract programs from problem specifications for execution by a robot in the external world, program synthesis <ref> [72, 70, 105, 65] </ref>, both interactive and automatic, is concerned with the construction of imperative programs from problem specifications for execution by a computer. To see the analogy with planning, consider the following programming exercise. <p> In fact, most work in commonsense reasoning [86, 61, 35] and imperative program synthesis <ref> [105, 65, 70, 72] </ref> deals only with such problems. However, as explained in Chapter 1, problems that specify many more constraints on solutions arise in many contexts particularly during program development. The additional constraints in a problem specification may be categorized as follows: 1. Time requirements.
Reference: [71] <author> Z. Manna and R. Waldinger. </author> <title> Fundamentals of deductive program synthesis. </title> <type> Technical Report STAN-CS-92-1404, </type> <institution> Department of Computer Science, Stan-ford University, </institution> <month> January </month> <year> 1992. </year>
Reference-contexts: Yet another approach to program synthesis that is being tried is theorem proving in a constructive logic [17]. So far, this approach has been used primarily for constructing applicative programs <ref> [71] </ref> rather than imperative programs. Artificial intelligence techniques have also been applied to software engineering [105, 65]. However, most systems (e.g. [106, 109]) are of the program transformation kind and do not address the issue of formalizing problem domain specifications.
Reference: [72] <author> Zohar Manna and Richard Waldinger. </author> <title> How to clear a block: A theory of plans. </title> <journal> Journal of Automated Reasoning, </journal> <volume> 3 </volume> <pages> 343-377, </pages> <year> 1987. </year>
Reference-contexts: machines that can be described in the language A, a language designed primarily for testing non-monotonic formalisms. 1.1 Motivation The problem of verifying whether or not a plan can bring about a goal state when executed in an initial state arises in both commonsense reasoning [76, 86] and software development <ref> [105, 65, 72, 70] </ref>. Commonsense reasoning is concerned with the construction of robots that can plan and act to achieve their goals in the physical world. <p> When a robot is given general problems, it faces the task of automatically constructing programs. Consider, for example, the problem of clearing a block where we are not told whether the block is already clear or, if not, how many blocks are above it <ref> [72] </ref>. One plan to solve the problem is to unstack repeatedly the blocks on top of the given block until the latter is clear. <p> Of course, such problems of program construction using atomic actions arise in various stages of software development. While robot planning involves synthesis of abstract programs from problem specifications for execution by a robot in the external world, program synthesis <ref> [72, 70, 105, 65] </ref>, both interactive and automatic, is concerned with the construction of imperative programs from problem specifications for execution by a computer. To see the analogy with planning, consider the following programming exercise. <p> The other is the problem of specifying actions with side-effects [47]. One of the first attempts to automatically generate recursive plans to solve general problems is that of Manna and Waldinger <ref> [69, 72] </ref>. The analogy between plans and programs is explained by them as follows 3 : Plans are closely analogous to imperative programs in that actions may be regarded as computer instructions, tests as conditional branches and the world as a huge data structure. <p> Unfortunately, the representation of plans as programs without any restriction leads to certain semantic difficulties. To see this, consider the monkey, banana and bomb problem given in <ref> [72] </ref>. There is a monkey some distance away from two boxes a and b. The monkey is informed that one box contains a banana and the other a bomb but is not told which. His goal is to get the banana without being killed by the bomb. <p> The need for a large number of axioms also makes it a problem to create consistent axiomatizations of problem domains. Further, mechanical theorem proving becomes difficult in the presence of a large number of axioms as the following quotation from <ref> [72] </ref> indicates. 15 The reader may have been struck by the complexity of the reasoning required by the makeclear derivation, as constrasted with the apparent simplicity of the original planning problem. <p> While many blocks world implementations exist, very few of them can express general problems and verify plans such as the plan for clearing a block <ref> [72] </ref> that require mathematical induction. It is perhaps for this reason that Hayes [48] remarked recently that "we do not know how to do the blocks world very well". <p> Our plan (given in <ref> [72] </ref>) to clear the block was to unstack repeatedly the blocks above it one by one until it became clear. We also showed that the same problem could also be posed as the following requirements specification for which we can use our plan as an initial program design or prototype. <p> In fact, most work in commonsense reasoning [86, 61, 35] and imperative program synthesis <ref> [105, 65, 70, 72] </ref> deals only with such problems. However, as explained in Chapter 1, problems that specify many more constraints on solutions arise in many contexts particularly during program development. The additional constraints in a problem specification may be categorized as follows: 1. Time requirements. <p> We can use lambda expressions to also represent other kinds of fluents such as propositional fluents that are predicates on states as in <ref> [76, 72] </ref> and define the celebrated holds predicate [59, 61] in the same way we defined result. For instance, corresponding to predicates find-stack-of-block and on from Chapter 2, we can form fluent terms s: find-stack-of-block (b, s) and s: on (b1 b2 s).
Reference: [73] <author> D. McAllester and D. Rosenblitt. </author> <title> Systematic nonlinear planning. </title> <booktitle> In Proc. of AAAI-91, </booktitle> <pages> pages 634-639, </pages> <year> 1991. </year>
Reference-contexts: By choosing a different representation that allows state constraints to be directly deduced from the semantics of Lisp data structures a more tractable formalization is obtained. 2.1.1 A First Attempt In many contemporary planners <ref> [73, 94] </ref>, states are represented by a list of terms that stand for primitive relations between blocks such as On (A; B), Ontable (D) and Clear (C). Let us see what it takes to define a predicate on blocks world states using this representation.
Reference: [74] <author> John McCarthy. </author> <title> Open problems in the epistemology of common sense. In the collection of papers given in his AI course at UT, </title> <address> Austin, </address> <month> Fall </month> <year> 1987. </year> <month> 222 </month>
Reference-contexts: It is perhaps for this reason that Hayes [48] remarked recently that "we do not know how to do the blocks world very well". McCarthy <ref> [74] </ref> lists the blocks world as an "open problem" and Minsky [93, page 29] justifies the use of the blocks world as follows.
Reference: [75] <author> John McCarthy. </author> <title> A tough nut for proof procedures. </title> <institution> Stanford University A.I. </institution> <note> memo no. 16, </note> <year> 1964. </year>
Reference-contexts: Second, the problem domain|two-dimensional space and actions that change properties of points in space|is realistic and of interest in both AI applications such as robot motion planning and programming applications such as graphics. Finally, although the proof has been repeatedly posed as a challenge for automatic discovery by machines <ref> [98, 75, 78, 107] </ref>, McCarthy [83] informs us that he knows of "no work on making a computer do it, interactively or otherwise". Apart from the proof, some plans for solving general problems in this domain are also given along with theorems that must be proved to verify them. <p> The sequence of events to the Boyer-Moore theorem prover for formalizing the checkerboard problem domain and proving the impossibility of covering a mutilated checkerboard is included in Appendix B. 3.1 The Mutilated Checkerboard Problem The mutilated checkerboard problem has been used frequently <ref> [98, 75, 78, 107] </ref> to demonstrate the limitations of representations used by problem solving programs and theorem provers. The problem is usually stated for an ordinary 8 fi 8 checkerboard as follows [107, 121]: 60 61 An ordinary chess board has had two squares|one at each end of a diagonal|removed.
Reference: [76] <author> John McCarthy. </author> <title> Programs with Common Sense, </title> <note> chapter 7. In Minsky [91], </note> <year> 1968. </year>
Reference-contexts: the class of finite state machines that can be described in the language A, a language designed primarily for testing non-monotonic formalisms. 1.1 Motivation The problem of verifying whether or not a plan can bring about a goal state when executed in an initial state arises in both commonsense reasoning <ref> [76, 86] </ref> and software development [105, 65, 72, 70]. Commonsense reasoning is concerned with the construction of robots that can plan and act to achieve their goals in the physical world. <p> Thus, since the action of moving block x to the top of block y is specified by the function res-move (x , y, s), it is represented by a data structure that stands for s: res-move (x , y, s) as in <ref> [76] </ref>. Such terms are called fluents by McCarthy [76, 86]. The data structures that represent such lambda expressions are chosen so that result can evaluate lambda expressions on particular states using the Lisp interpreter eval$ available as a function in the logic. <p> Such terms are called fluents by McCarthy <ref> [76, 86] </ref>. The data structures that represent such lambda expressions are chosen so that result can evaluate lambda expressions on particular states using the Lisp interpreter eval$ available as a function in the logic. <p> Because we specify problem domains by programming, our approach makes it possible to formalize complex domains while retaining the power of logic to prove general properties. Thus, it combines the benefits of procedural and declarative specifications <ref> [76, 92, 119] </ref>. The frame problem does not arise any more than when programming a simulator for a domain in Lisp because all changes brought about by the execution of an action are specified using a program. <p> Thus, if the action of moving block x to the top of block y is specified by the function res-move (x , y, s), then the action is represented by a data structure that stands for s: res-move (x , y, s) as in <ref> [76] </ref>. Such terms are called fluents by McCarthy [76, 86]. The data structures that represent such lambda expressions are chosen so that result can evaluate lambda expressions on particular states using the Lisp interpreter eval$ available as a function in the logic. <p> Such terms are called fluents by McCarthy <ref> [76, 86] </ref>. The data structures that represent such lambda expressions are chosen so that result can evaluate lambda expressions on particular states using the Lisp interpreter eval$ available as a function in the logic. <p> We can use lambda expressions to also represent other kinds of fluents such as propositional fluents that are predicates on states as in <ref> [76, 72] </ref> and define the celebrated holds predicate [59, 61] in the same way we defined result. For instance, corresponding to predicates find-stack-of-block and on from Chapter 2, we can form fluent terms s: find-stack-of-block (b, s) and s: on (b1 b2 s). <p> The idea of constructing a program that can accept as input declarative facts that describe modifications to domain specifications so that the necessary changes to specifications are carried out automatically by the program is being pursued by many researchers in artificial intelligence <ref> [76, 79, 77, 81] </ref>. For this we need a formalism in which not only all possible domains but also facts describing changes to a domain specification can be expressed.
Reference: [77] <author> John McCarthy. </author> <title> Circumscription-a form of non-monotonic reasoning. </title> <journal> Artificial Intelligence, </journal> <volume> 13(1-2):27-39, </volume> <year> 1980. </year>
Reference-contexts: The idea of constructing a program that can accept as input, declarative facts that describe modifications to problem specifications so that the necessary changes to specifications can be carried out automatically is being pursued by many researchers in commonsense reasoning <ref> [79, 77, 81] </ref>. For this we need a formalism in which not only all possible domains but also facts describing changes to a domain specification can be expressed. Non-monotonic reasoning [38] has been found necessary for dealing with this problem in AI but has proven extremely difficult to formalize [84]. <p> A more ambitious approach, that of building a program that can accept as input declarative facts that describe changes to be made to problem specifications is being pursued by many researchers in AI. The problem was first mentioned by McCarthy <ref> [79, 77] </ref> and was called the qualification problem. One way to think of the qualification problem (in its broadest sense) is as the "robot modification" problem. Normally, when we build a robot like the blocks world robot, we would identify its problem domain constituting its specification and construct it accordingly. <p> a sentence asserting the loss of a ticket is added, then the original plan can no longer be shown to work and a revised plan involving buying a replacement ticket can be shown to work. 19 Non-monotonic reasoning has been found necessary for this purpose and rules such as circumscription <ref> [77, 80, 61] </ref> have been proposed for formalizing the needed non-monotonic reasoning. The ideas behind the problem of specification modification and the need for non-monotonic reasoning are best illustrated using the class of domains (finite state systems) proposed by Gelfond and Lifschitz [35] for testing non-monotonic formalisms. <p> Thus, it is felt that a non-monotonic formalism| usually first-order logic augmented by non-monotonic rules such as circumscription <ref> [77, 80, 61] </ref>|is needed to express changes to domain specifications, as the following quotation from Gelfond and Lifschitz [35] indicates. <p> The idea of constructing a program that can accept as input declarative facts that describe modifications to domain specifications so that the necessary changes to specifications are carried out automatically by the program is being pursued by many researchers in artificial intelligence <ref> [76, 79, 77, 81] </ref>. For this we need a formalism in which not only all possible domains but also facts describing changes to a domain specification can be expressed. <p> Thus, it is felt that a non-monotonic formalism| usually first-order logic augmented by non-monotonic rules such as circumscription <ref> [77, 80, 61] </ref>|is needed to express changes to domain specifications, as the following quotation from Gelfond and Lifschitz [35] indicates.
Reference: [78] <author> John McCarthy. </author> <title> Invited commentary. </title> <editor> In Jorg Siekmann and Graham Wright-son, editors, </editor> <booktitle> Automation of Reasoning 2: Classical Papers on Computational Logic 1967-1970, </booktitle> <pages> pages 157-158. </pages> <publisher> Springer Verlag, </publisher> <address> Berlin Heidelberg, </address> <year> 1983. </year>
Reference-contexts: Second, the problem domain|two-dimensional space and actions that change properties of points in space|is realistic and of interest in both AI applications such as robot motion planning and programming applications such as graphics. Finally, although the proof has been repeatedly posed as a challenge for automatic discovery by machines <ref> [98, 75, 78, 107] </ref>, McCarthy [83] informs us that he knows of "no work on making a computer do it, interactively or otherwise". Apart from the proof, some plans for solving general problems in this domain are also given along with theorems that must be proved to verify them. <p> The sequence of events to the Boyer-Moore theorem prover for formalizing the checkerboard problem domain and proving the impossibility of covering a mutilated checkerboard is included in Appendix B. 3.1 The Mutilated Checkerboard Problem The mutilated checkerboard problem has been used frequently <ref> [98, 75, 78, 107] </ref> to demonstrate the limitations of representations used by problem solving programs and theorem provers. The problem is usually stated for an ordinary 8 fi 8 checkerboard as follows [107, 121]: 60 61 An ordinary chess board has had two squares|one at each end of a diagonal|removed.
Reference: [79] <editor> John McCarthy. </editor> <booktitle> Epistemological Problems of Artificial Intelligence, </booktitle> <pages> pages 23-30. </pages> <note> In Brachman and Levesque [13], </note> <year> 1985. </year>
Reference-contexts: The idea of constructing a program that can accept as input, declarative facts that describe modifications to problem specifications so that the necessary changes to specifications can be carried out automatically is being pursued by many researchers in commonsense reasoning <ref> [79, 77, 81] </ref>. For this we need a formalism in which not only all possible domains but also facts describing changes to a domain specification can be expressed. Non-monotonic reasoning [38] has been found necessary for dealing with this problem in AI but has proven extremely difficult to formalize [84]. <p> A more ambitious approach, that of building a program that can accept as input declarative facts that describe changes to be made to problem specifications is being pursued by many researchers in AI. The problem was first mentioned by McCarthy <ref> [79, 77] </ref> and was called the qualification problem. One way to think of the qualification problem (in its broadest sense) is as the "robot modification" problem. Normally, when we build a robot like the blocks world robot, we would identify its problem domain constituting its specification and construct it accordingly. <p> The idea of constructing a program that can accept as input declarative facts that describe modifications to domain specifications so that the necessary changes to specifications are carried out automatically by the program is being pursued by many researchers in artificial intelligence <ref> [76, 79, 77, 81] </ref>. For this we need a formalism in which not only all possible domains but also facts describing changes to a domain specification can be expressed.
Reference: [80] <author> John McCarthy. </author> <title> Applications of circumscription to non-monotonic reasoning. </title> <journal> Artificial Intelligence, </journal> <volume> 28(1) </volume> <pages> 89-116, </pages> <year> 1986. </year>
Reference-contexts: a sentence asserting the loss of a ticket is added, then the original plan can no longer be shown to work and a revised plan involving buying a replacement ticket can be shown to work. 19 Non-monotonic reasoning has been found necessary for this purpose and rules such as circumscription <ref> [77, 80, 61] </ref> have been proposed for formalizing the needed non-monotonic reasoning. The ideas behind the problem of specification modification and the need for non-monotonic reasoning are best illustrated using the class of domains (finite state systems) proposed by Gelfond and Lifschitz [35] for testing non-monotonic formalisms. <p> Thus, it is felt that a non-monotonic formalism| usually first-order logic augmented by non-monotonic rules such as circumscription <ref> [77, 80, 61] </ref>|is needed to express changes to domain specifications, as the following quotation from Gelfond and Lifschitz [35] indicates. <p> Thus, it is felt that a non-monotonic formalism| usually first-order logic augmented by non-monotonic rules such as circumscription <ref> [77, 80, 61] </ref>|is needed to express changes to domain specifications, as the following quotation from Gelfond and Lifschitz [35] indicates.
Reference: [81] <editor> John McCarthy. </editor> <booktitle> Generality in artificial intelligence. </booktitle> <editor> In Robert L. Ashenhurst, editor, </editor> <booktitle> ACM Turing Award Lectures: The First Twenty Years. </booktitle> <publisher> ACM Press, </publisher> <address> New York, New York, </address> <year> 1987. </year>
Reference-contexts: The idea of constructing a program that can accept as input, declarative facts that describe modifications to problem specifications so that the necessary changes to specifications can be carried out automatically is being pursued by many researchers in commonsense reasoning <ref> [79, 77, 81] </ref>. For this we need a formalism in which not only all possible domains but also facts describing changes to a domain specification can be expressed. Non-monotonic reasoning [38] has been found necessary for dealing with this problem in AI but has proven extremely difficult to formalize [84]. <p> So we have terms such as result ('switch1, s0 , switch-dom1) which stands for the result of executing Switch1 in state s0 of the Switch Domain and prove theorems such as the following: 6 The connection between this and the proposal to include contexts as objects of <ref> [81, 85] </ref> is unclear. <p> The idea of constructing a program that can accept as input declarative facts that describe modifications to domain specifications so that the necessary changes to specifications are carried out automatically by the program is being pursued by many researchers in artificial intelligence <ref> [76, 79, 77, 81] </ref>. For this we need a formalism in which not only all possible domains but also facts describing changes to a domain specification can be expressed.
Reference: [82] <author> John McCarthy. </author> <title> Overcoming an unexpected obstacle. </title> <year> 1992. </year>
Reference-contexts: Theorem: always-broken holds ('(broken . 1), s) ! always-holds ('(broken . 1), p, '(drop), s, fo-domain) McCarthy <ref> [82] </ref> describes how non-monotonic reasoning might be required if a system must take into account a previously unknown action to infer that a previously unachievable goal can now be achieved using the new action.
Reference: [83] <author> John McCarthy, </author> <month> March </month> <year> 1993. </year> <type> Personal communication. </type>
Reference-contexts: Finally, although the proof has been repeatedly posed as a challenge for automatic discovery by machines [98, 75, 78, 107], McCarthy <ref> [83] </ref> informs us that he knows of "no work on making a computer do it, interactively or otherwise". Apart from the proof, some plans for solving general problems in this domain are also given along with theorems that must be proved to verify them.
Reference: [84] <author> John McCarthy. </author> <title> History of circumscription. </title> <journal> Artificial Intelligence, </journal> <volume> 59 </volume> <pages> 23-26, </pages> <year> 1993. </year>
Reference-contexts: For this we need a formalism in which not only all possible domains but also facts describing changes to a domain specification can be expressed. Non-monotonic reasoning [38] has been found necessary for dealing with this problem in AI but has proven extremely difficult to formalize <ref> [84] </ref>. Gelfond and Lifschitz [35] identified a simple class of domains, a class of finite state systems, which they describe using a language called A for testing various approaches to formalizing non-monotonic reasoning. <p> Rather than change an existing domain specification, they want a program to accept facts describing the changes to be made as input and carry out the necessary changes. McCarthy <ref> [84] </ref> explains this as follows: : : : the existing formalizations don't have enough of what I call elaboration tolerance. The idea is that formalizations should follow human fact representation in being modifiable primarily by extension rather than by replacement of axioms. <p> These clearly invalidate the above inference. noninertial (Light2; Switch1) holds (Light2; result (Switch1; s)) Thus, we have succeeded in suppressing some of the inferences that are not true in the new domain, i.e., in formalizing non-monotonic reasoning. But as McCarthy <ref> [84] </ref> explains: : : : unfortunately the most obvious and apparently natural axiomati-zations tend to have unintended models, and this has been observed in several examples, especially the Yale Shooting Problem [42]. This has led to revised formalizations which work but don't seem so natural. <p> For this we need a formalism in which not only all possible domains but also facts describing changes to a domain specification can be expressed. Non-monotonic reasoning [38] has been found necessary for dealing with this problem in AI but has proven extremely difficult to formalize <ref> [84] </ref>. Gelfond and Lifschitz [35] identified a simple class of domains, a class of finite state systems, which they describe using a language called A for testing various approaches to formalizing non-monotonic reasoning. <p> These clearly invalidate the above inference. noninertial (Light2; Switch1) holds (Light2; result (Switch1; s)) Thus, we have succeeded in suppressing some of the inferences that are not true in the new domain, i.e., in formalizing non-monotonic reasoning. But as McCarthy <ref> [84] </ref> explains "the most obvious and apparently natural axiomatizations tend to have unintended models". At present, the formalization of non-monotonic reasoning is a subject of continuing research [84]. 6.2 Our Approach Our approach to mechanize the "non-monotonic" reasoning needed for dealing with modifications to domain specifications in classical first-order logic is <p> But as McCarthy <ref> [84] </ref> explains "the most obvious and apparently natural axiomatizations tend to have unintended models". At present, the formalization of non-monotonic reasoning is a subject of continuing research [84]. 6.2 Our Approach Our approach to mechanize the "non-monotonic" reasoning needed for dealing with modifications to domain specifications in classical first-order logic is to include all possible domains as terms in the logic.
Reference: [85] <author> John McCarthy. </author> <title> Notes on formalizing context. </title> <booktitle> In Working Papers of the Second Symposium on Logical Formalizations of Commonsense Reasoning, </booktitle> <year> 1993. </year>
Reference-contexts: So we have terms such as result ('switch1, s0 , switch-dom1) which stands for the result of executing Switch1 in state s0 of the Switch Domain and prove theorems such as the following: 6 The connection between this and the proposal to include contexts as objects of <ref> [81, 85] </ref> is unclear.
Reference: [86] <author> John McCarthy and P. Hayes. </author> <title> Some philosophical problems from the standpoint of artificial intelligence. </title> <editor> In D. Michie and B. Meltzer, editors, </editor> <booktitle> Machine Intelligence, </booktitle> <volume> volume 4. </volume> <publisher> Edinburgh University Press, Edinburgh, </publisher> <address> Scotland, </address> <year> 1969. </year>
Reference-contexts: the class of finite state machines that can be described in the language A, a language designed primarily for testing non-monotonic formalisms. 1.1 Motivation The problem of verifying whether or not a plan can bring about a goal state when executed in an initial state arises in both commonsense reasoning <ref> [76, 86] </ref> and software development [105, 65, 72, 70]. Commonsense reasoning is concerned with the construction of robots that can plan and act to achieve their goals in the physical world. <p> The identical programming problem must be solved by designing a suitable procedure. Recognizing the difficulty of generating plans for solving general problems completely automatically, McCarthy and Hayes <ref> [86] </ref> proposed the construction of a program that can verify plans interactively as a first step towards artificial intelligence 1 . Of course, such problems of program construction using atomic actions arise in various stages of software development. <p> The first part relates work done in mechanically generating or verifying program-like plans for solving general problems. We will deal with work done in both artificial intelligence and software engineering. The second part relates work done in dealing with changes to problem specifications. 1.4.1 Plan Verification McCarthy and Hayes <ref> [86] </ref> proposed the construction of a proof-checker that can verify interactively whether or not a plan achieves a goal as a first step towards the construction of intelligent robots. <p> There are two main problems in using constructs from a language like ALGOL or PASCAL to model actions. One is the problem of modeling preconditions since actions are partial functions executable only in those states that satisfy their preconditions <ref> [86, 46] </ref>. The other is the problem of specifying actions with side-effects [47]. One of the first attempts to automatically generate recursive plans to solve general problems is that of Manna and Waldinger [69, 72]. <p> From the standpoint of plan verification, plan theory shares some of the disadvantages commonly associated with the situation calculus 4 style of formalization. First, there is the frame problem <ref> [86, 69] </ref>. In addition to saying what fluents are changed by an action, it is also necessary to provide frame axioms which state explicitly what fluents are left unchanged. <p> Such terms are called fluents by McCarthy <ref> [76, 86] </ref>. The data structures that represent such lambda expressions are chosen so that result can evaluate lambda expressions on particular states using the Lisp interpreter eval$ available as a function in the logic. <p> In fact, most work in commonsense reasoning <ref> [86, 61, 35] </ref> and imperative program synthesis [105, 65, 70, 72] deals only with such problems. However, as explained in Chapter 1, problems that specify many more constraints on solutions arise in many contexts particularly during program development. <p> Such terms are called fluents by McCarthy <ref> [76, 86] </ref>. The data structures that represent such lambda expressions are chosen so that result can evaluate lambda expressions on particular states using the Lisp interpreter eval$ available as a function in the logic.
Reference: [87] <author> Drew McDermont. </author> <booktitle> Reasoning about plans, </booktitle> <pages> pages 269-318. </pages> <note> In Hobbs and Moore [50], </note> <year> 1985. </year>
Reference-contexts: The main disadvantage of these systems is that general problems such as the problem of clearing a block cannot be specified as input. Some temporal logics have also been proposed in AI <ref> [3, 89, 87] </ref> but it is unclear how effective they are in practice. Constraints on execution sequences generated by the actions of an agent also arise when specifying the behavior of reactive systems [44, 67].
Reference: [88] <author> Drew McDermott. </author> <title> A critique of pure reason. </title> <journal> Computational Intelligence, </journal> <volume> 3 </volume> <pages> 151-160, </pages> <year> 1987. </year>
Reference-contexts: This difficulty arises because we have not taken into account that the monkey cannot test the initial state of the world to determine whether the banana is in a box or not. A similar situation arises with the "bomb in the toilet problem" <ref> [88, 116] </ref>. To prevent the construction of both forms of non-executable plans as solutions, Manna and Waldinger restrict plans to contain only primitive symbols which are described as those symbols "which we know how to execute".
Reference: [89] <author> Drew McDermott. </author> <title> A Temporal Logic for Reasoning about Processes and Plans, pages 436-463. </title> <editor> In Allen et al. </editor> <volume> [2], </volume> <year> 1990. </year>
Reference-contexts: The main disadvantage of these systems is that general problems such as the problem of clearing a block cannot be specified as input. Some temporal logics have also been proposed in AI <ref> [3, 89, 87] </ref> but it is unclear how effective they are in practice. Constraints on execution sequences generated by the actions of an agent also arise when specifying the behavior of reactive systems [44, 67].
Reference: [90] <author> Drew McDermott. </author> <title> Robot planning. </title> <journal> AI Magazine, </journal> <volume> 13(2) </volume> <pages> 55-79, </pages> <year> 1992. </year> <month> 223 </month>
Reference-contexts: While it is recognized that plans are essentially programs that produce a sequence of actions when executed in a state, at present there seems to be no agreement on a precise representation for plans <ref> [90] </ref>. Plans for solving general problems must generate distinct sequences of actions depending on the state in which they are executed.
Reference: [91] <editor> M. Minsky, editor. </editor> <booktitle> Semantic Information Processing. </booktitle> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1968. </year>
Reference: [92] <author> M. Minsky. </author> <title> A framework for representing knowledge. </title> <booktitle> In Brachman and Levesque [13], </booktitle> <pages> pages 245-262. </pages>
Reference-contexts: Because we specify problem domains by programming, our approach makes it possible to formalize complex domains while retaining the power of logic to prove general properties. Thus, it combines the benefits of procedural and declarative specifications <ref> [76, 92, 119] </ref>. The frame problem does not arise any more than when programming a simulator for a domain in Lisp because all changes brought about by the execution of an action are specified using a program.
Reference: [93] <author> M. Minsky. </author> <title> The Society of Mind. </title> <publisher> Simon and Schuster, Inc., </publisher> <address> New York, </address> <year> 1985. </year>
Reference-contexts: It is perhaps for this reason that Hayes [48] remarked recently that "we do not know how to do the blocks world very well". McCarthy [74] lists the blocks world as an "open problem" and Minsky <ref> [93, page 29] </ref> justifies the use of the blocks world as follows. In attempting to make our robot work, we found that many everyday problems were much more complicated than the sorts of problems, puzzles and games adults consider hard.
Reference: [94] <author> Steve Minton, Craig A. Knoblock, Daniel R. Kuokka, Yolanda Gil, Robert L. Joseph, and Jaime G. Carbonell. </author> <title> Prodigy 2.0: The manual and tutorial. </title> <type> Technical Report CMU-CS-89-146, </type> <institution> School of Computer Science, Carnegie Mellon University, </institution> <month> May </month> <year> 1989. </year>
Reference-contexts: By choosing a different representation that allows state constraints to be directly deduced from the semantics of Lisp data structures a more tractable formalization is obtained. 2.1.1 A First Attempt In many contemporary planners <ref> [73, 94] </ref>, states are represented by a list of terms that stand for primitive relations between blocks such as On (A; B), Ontable (D) and Clear (C). Let us see what it takes to define a predicate on blocks world states using this representation.
Reference: [95] <author> J Strother Moore. Piton: </author> <title> A verified assembly-level language. </title> <type> Technical Report CLI-22, </type> <institution> Computational Logic, Inc., Austin, Tx, </institution> <month> June </month> <year> 1988. </year>
Reference-contexts: The work most relevant to this dissertation seems to be the research on formalizing the semantics of individual von Neumann machines such as a microprocessor [11], an assembly language machine <ref> [95] </ref>, a Micro-Gypsy (a Pascal-like language) machine [122] and various other machines [5] in the Boyer-Moore logic for the purpose of verifying programs and systems mechanically. The semantics of these various machines have been formalized by defining Lisp interpreters for various programming languages in the Boyer-Moore logic.
Reference: [96] <author> M. </author> <title> Moriconi. </title> <booktitle> A Designer/Verifier Assistant, </booktitle> <pages> pages 335-350. </pages> <note> In Rich and Waters [105], </note> <year> 1986. </year>
Reference-contexts: Even when there are reusable design histories, the burden of figuring out what to redesign and what to reuse rests with the designer. Some work on building automated systems that can take into account changes to problem specifications and programs is currently underway <ref> [96, 97] </ref>. The idea of constructing a program that can accept as input, declarative facts that describe modifications to problem specifications so that the necessary changes to specifications can be carried out automatically is being pursued by many researchers in commonsense reasoning [79, 77, 81]. <p> Some work on building automated systems that can reason about the effects of incremental changes made to specifications and programs is currently underway <ref> [96, 97] </ref>. A more ambitious approach, that of building a program that can accept as input declarative facts that describe changes to be made to problem specifications is being pursued by many researchers in AI. The problem was first mentioned by McCarthy [79, 77] and was called the qualification problem. <p> However, even when there are reusable design histories available, the burden of figuring out what to redesign and what to reuse rests with the human designer. Some work on building automated systems that can take into account changes to problem specifications and programs is currently underway <ref> [96, 97, 106] </ref>, particularly in the area of requirements acquisition [51].
Reference: [97] <author> M. Moriconi and T. C. Winkler. </author> <title> Approximate reasoning about the semantic effects of program changes. </title> <journal> IEEE Transactions on Software Engineering, </journal> <pages> pages 980-992, </pages> <month> September </month> <year> 1990. </year>
Reference-contexts: Even when there are reusable design histories, the burden of figuring out what to redesign and what to reuse rests with the designer. Some work on building automated systems that can take into account changes to problem specifications and programs is currently underway <ref> [96, 97] </ref>. The idea of constructing a program that can accept as input, declarative facts that describe modifications to problem specifications so that the necessary changes to specifications can be carried out automatically is being pursued by many researchers in commonsense reasoning [79, 77, 81]. <p> Some work on building automated systems that can reason about the effects of incremental changes made to specifications and programs is currently underway <ref> [96, 97] </ref>. A more ambitious approach, that of building a program that can accept as input declarative facts that describe changes to be made to problem specifications is being pursued by many researchers in AI. The problem was first mentioned by McCarthy [79, 77] and was called the qualification problem. <p> However, even when there are reusable design histories available, the burden of figuring out what to redesign and what to reuse rests with the human designer. Some work on building automated systems that can take into account changes to problem specifications and programs is currently underway <ref> [96, 97, 106] </ref>, particularly in the area of requirements acquisition [51].
Reference: [98] <author> A. Newell. </author> <title> Limitations of the current stock of ideas about problem-solving. </title> <booktitle> In Proceedings of a Conference on Electronic Information Handling, </booktitle> <pages> pages 195-208, </pages> <year> 1965. </year>
Reference-contexts: Second, the problem domain|two-dimensional space and actions that change properties of points in space|is realistic and of interest in both AI applications such as robot motion planning and programming applications such as graphics. Finally, although the proof has been repeatedly posed as a challenge for automatic discovery by machines <ref> [98, 75, 78, 107] </ref>, McCarthy [83] informs us that he knows of "no work on making a computer do it, interactively or otherwise". Apart from the proof, some plans for solving general problems in this domain are also given along with theorems that must be proved to verify them. <p> The sequence of events to the Boyer-Moore theorem prover for formalizing the checkerboard problem domain and proving the impossibility of covering a mutilated checkerboard is included in Appendix B. 3.1 The Mutilated Checkerboard Problem The mutilated checkerboard problem has been used frequently <ref> [98, 75, 78, 107] </ref> to demonstrate the limitations of representations used by problem solving programs and theorem provers. The problem is usually stated for an ordinary 8 fi 8 checkerboard as follows [107, 121]: 60 61 An ordinary chess board has had two squares|one at each end of a diagonal|removed. <p> Thus, removing two squares of the same color would still make the number of white and black squares on the mutilated board unequal. Newell <ref> [98] </ref> observed that the argument can be formalized as a proof by induction on the number of domino placement actions done starting with an empty board assuming that the colors of the squares on the board are given.
Reference: [99] <author> A. Newell and H. A. Simon. </author> <title> Human Problem Solving. </title> <publisher> Prentice-Hall, </publisher> <year> 1972. </year>
Reference-contexts: Thus, we are left with point 1. Fortunately, a rigorous state-transition model of problem domains is already available and, by now, well-understood in AI 7 [37, 101]. It is also well-known that a fairly large number of problems fit this model <ref> [100, 37, 99] </ref>. A problem domain is given by a set of possible states of a physical world and a set of actions that can be executed sequentially to change the state of the world. Actions are deterministic and terminating.
Reference: [100] <author> N. J. Nilsson. </author> <booktitle> Problem-Solving Methods in Artificial Intelligence. </booktitle> <publisher> McGraw-Hill, </publisher> <address> New York, </address> <year> 1971. </year>
Reference-contexts: Thus, we are left with point 1. Fortunately, a rigorous state-transition model of problem domains is already available and, by now, well-understood in AI 7 [37, 101]. It is also well-known that a fairly large number of problems fit this model <ref> [100, 37, 99] </ref>. A problem domain is given by a set of possible states of a physical world and a set of actions that can be executed sequentially to change the state of the world. Actions are deterministic and terminating.
Reference: [101] <author> E. P. D. Pednault. </author> <title> Toward a mathematical theory of plan synthesis. </title> <type> PhD thesis, </type> <institution> Stanford University, Department of Electrical Engineering, </institution> <year> 1986. </year>
Reference-contexts: Thus, we are left with point 1. Fortunately, a rigorous state-transition model of problem domains is already available and, by now, well-understood in AI 7 <ref> [37, 101] </ref>. It is also well-known that a fairly large number of problems fit this model [100, 37, 99].
Reference: [102] <author> E. P. D. Pednault. </author> <title> Synthesizing plans that contain actions with context-dependent effects. </title> <journal> Computational Intelligence, </journal> <volume> 4 </volume> <pages> 356-372, </pages> <year> 1988. </year>
Reference-contexts: What makes the frame problem a problem is that, in domains of realistic complexity, there are many more actions and fluents and so many more frame axioms, thus making it practically impossible to obtain economical problem specifications. A related problem is the problem of side-effects <ref> [47, 102, 115] </ref>. This precludes the use of the "programming convention" that all fluents other than those explicitly asserted to change in the problem specification are left unchanged by an action. Side-effects are the changes caused by an action in objects other than its arguments. <p> Additional axioms are needed because, in general, an action may produce distinct side-effects depending on the properties of the state in which it is executed. The usual approach to tackle side-effects is to include additional axioms such as the put-table-on axiom with additional secondary preconditions <ref> [102] </ref>. Yet another difficulty with the situation calculus style of formalization is the problem of determining the indirect effects of an action, the so-called ramification problem.
Reference: [103] <author> J. Scott Penberthy and Daniel S. Weld. </author> <title> Temporal planning with constraints. </title> <booktitle> In Proceedings of the Spring Symposium on Planning, </booktitle> <address> Stanford, CA., </address> <year> 1993. </year>
Reference-contexts: Vere [114] describes a planning system that accepts problems in propositional STRIPS [113] as input and generates a "partially ordered network of activities" as output. Fox [32] describes an expert system to plan and schedule tasks required for manufacturing products. More recently, Penberthy and Weld <ref> [103] </ref> describe a planner based on propositional STRIPS to generate plans that satisfy some temporal constraints. The main disadvantage of these systems is that general problems such as the problem of clearing a block cannot be specified as input.
Reference: [104] <author> R. Reiter. </author> <title> Proving properties of states in the situation calculus. </title> <journal> Artificial Intelligence, </journal> <year> 1992. </year>
Reference-contexts: We show how the needed "non-monotonic" reasoning is formalized in our theory using the Switch Domain example described above. Section 6.6 deals with a class of theorems motivated by <ref> [104] </ref> about properties true of all states of a domain reachable from an initial state. Section 6.7 describes a plan generating program that outputs distinct solutions depending on the domain passed to it as a parameter. <p> Theorem: l-th4 holds ('(light2 . 0), s) ! holds ('(light2 . 1), result ('switch1, s, cons ('(switch1 (light2 . 1)), switch-dom1))) 121 6.6 Proving Properties of States Reiter <ref> [104] </ref> motivates the need to prove that certain properties are true in all states of a domain accessible from the initial state. Such theorems are typical of many domains. In fact, we have already proved a fair number of them in the preceding chapters.
Reference: [105] <editor> Charles Rich and Richard C. Waters, editors. </editor> <booktitle> Readings in Artificial Intelligence and Software Engineering. </booktitle> <publisher> Morgan-Kaufmann, </publisher> <address> Los Altos, CA, </address> <year> 1986. </year>
Reference-contexts: machines that can be described in the language A, a language designed primarily for testing non-monotonic formalisms. 1.1 Motivation The problem of verifying whether or not a plan can bring about a goal state when executed in an initial state arises in both commonsense reasoning [76, 86] and software development <ref> [105, 65, 72, 70] </ref>. Commonsense reasoning is concerned with the construction of robots that can plan and act to achieve their goals in the physical world. <p> Of course, such problems of program construction using atomic actions arise in various stages of software development. While robot planning involves synthesis of abstract programs from problem specifications for execution by a robot in the external world, program synthesis <ref> [72, 70, 105, 65] </ref>, both interactive and automatic, is concerned with the construction of imperative programs from problem specifications for execution by a computer. To see the analogy with planning, consider the following programming exercise. <p> A requirements specification is an informal but precise specification of the program to be constructed couched in the vocabulary of the customer, the person who wants the program built. Frequently, a requirements specification involves objects of the physical world <ref> [105, 68, 49, 56] </ref> as in the blocks world programming exercise. <p> At present, the importance of mechanizing all phases of the software life cycle and the utility of interactive mechanical verification of designs with respect to a specification during the software development process are well understood <ref> [52, 105, 65, 53] </ref>. The idea is to eliminate errors in the product as early as possible in the software life cycle, preferably well before the program is coded in a programming language. <p> The Larch Shared Language, however, has been used for expressing and validating some state-independent properties of a specification such as consistency using the Larch Prover [33, 41]. A related approach for developing software is the use of program transformations <ref> [105, pages 97-192] </ref>. However, this approach does not take the problem specification as the starting point of program synthesis. Rather, correctness-preserving transformations are used to synthesize efficient programs from inefficient algorithms that can be easily specified in a very high-level programming language. <p> Yet another approach to program synthesis that is being tried is theorem proving in a constructive logic [17]. So far, this approach has been used primarily for constructing applicative programs [71] rather than imperative programs. Artificial intelligence techniques have also been applied to software engineering <ref> [105, 65] </ref>. However, most systems (e.g. [106, 109]) are of the program transformation kind and do not address the issue of formalizing problem domain specifications. <p> In fact, most work in commonsense reasoning [86, 61, 35] and imperative program synthesis <ref> [105, 65, 70, 72] </ref> deals only with such problems. However, as explained in Chapter 1, problems that specify many more constraints on solutions arise in many contexts particularly during program development. The additional constraints in a problem specification may be categorized as follows: 1. Time requirements.
Reference: [106] <author> Charles Rich and Richard C. Waters. </author> <title> The Programmer's Apprentice. </title> <publisher> ACM Press, </publisher> <address> Reading, MA, </address> <year> 1990. </year> <month> 224 </month>
Reference-contexts: So far, this approach has been used primarily for constructing applicative programs [71] rather than imperative programs. Artificial intelligence techniques have also been applied to software engineering [105, 65]. However, most systems (e.g. <ref> [106, 109] </ref>) are of the program transformation kind and do not address the issue of formalizing problem domain specifications. <p> However, even when there are reusable design histories available, the burden of figuring out what to redesign and what to reuse rests with the human designer. Some work on building automated systems that can take into account changes to problem specifications and programs is currently underway <ref> [96, 97, 106] </ref>, particularly in the area of requirements acquisition [51].
Reference: [107] <author> J. A. Robinson. </author> <title> Formal and informal proofs. </title> <editor> In Robert Boyer, editor, </editor> <booktitle> Automated Reasoning: Essays in Honor of Woody Bledsoe, </booktitle> <pages> pages 267-282. </pages> <publisher> Kluwer Academic, </publisher> <address> Dordrecht, </address> <year> 1991. </year>
Reference-contexts: Since placing dominoes results in an even number of covered squares, the mutilated board cannot be covered completely with dominoes. When n is even, there is the following interesting argument <ref> [107] </ref> involving the use of colors. Let us color the squares alternately white and black (as on the usual chess board). The two missing squares have the same color. Thus, the mutilated board has an unequal number of white and black squares. <p> Second, the problem domain|two-dimensional space and actions that change properties of points in space|is realistic and of interest in both AI applications such as robot motion planning and programming applications such as graphics. Finally, although the proof has been repeatedly posed as a challenge for automatic discovery by machines <ref> [98, 75, 78, 107] </ref>, McCarthy [83] informs us that he knows of "no work on making a computer do it, interactively or otherwise". Apart from the proof, some plans for solving general problems in this domain are also given along with theorems that must be proved to verify them. <p> The sequence of events to the Boyer-Moore theorem prover for formalizing the checkerboard problem domain and proving the impossibility of covering a mutilated checkerboard is included in Appendix B. 3.1 The Mutilated Checkerboard Problem The mutilated checkerboard problem has been used frequently <ref> [98, 75, 78, 107] </ref> to demonstrate the limitations of representations used by problem solving programs and theorem provers. The problem is usually stated for an ordinary 8 fi 8 checkerboard as follows [107, 121]: 60 61 An ordinary chess board has had two squares|one at each end of a diagonal|removed. <p> The problem is usually stated for an ordinary 8 fi 8 checkerboard as follows <ref> [107, 121] </ref>: 60 61 An ordinary chess board has had two squares|one at each end of a diagonal|removed. There is on hand an unlimited supply of dominoes, each of which is large enough to cover exactly two adjacent squares of the board. <p> Is it possible to lay the dominoes on the mutilated chess board in such a manner as to cover it completely? In the more difficult version of the problem, the squares on the board are assumed to be indistinguishable by color. A solution <ref> [107] </ref> to the problem which researchers have wanted problem solving programs to discover is the following convincing argument that such a tiling is impossible. Let us color the squares alternately white and black (as on the usual chess board). The two missing squares have the same color.
Reference: [108] <author> Lenhart Schubert. </author> <title> Monotonic solution of the frame problem in the situation calculus: an efficient method for worlds with fully specified actions. In H.E. </title> <editor> Kyburg, R. Loui, and G. Carlson, editors, </editor> <booktitle> Knowledge Representation and De-feasible Reasoning, </booktitle> <pages> pages 23-67. </pages> <publisher> Kluwer, </publisher> <year> 1990. </year>
Reference-contexts: Lifschitz (private 109 communication) adds that "strictly speaking, a domain description includes, in addition to its value and effect propositions, the lists of its fluent names and of its action names." Example 1. The Fragile Object domain, motivated by an example from <ref> [108] </ref>, has the fluent names Holding, Fragile and Broken, and the action Drop. It consists of two e-propositions: Drop causes :Holding if Holding; Drop causes Broken if Holding; Fragile: Example 2. The Yale Shooting domain, motivated by the example from [43], is defined as follows. <p> These theorems are distinctly simpler than the theorems shown in the previous chapters because they have been used so far for testing non-monotonic formalisms. From the description of the Fragile Object Domain, the following theorems similar to those given in <ref> [108] </ref> about the effects of the drop action follow. Below we state the theorem that if Holding, F ragile and :Broken are true in state s in the Fragile Object Domain, then executing Drop in s results in a state in which :Holding, F ragile and Broken are true.
Reference: [109] <author> Douglas R. Smith. </author> <booktitle> KIDS|A Knowledge-Based Software Development System, </booktitle> <pages> pages 483-514. </pages> <note> In Lowry and McCartney [65], </note> <year> 1991. </year>
Reference-contexts: So far, this approach has been used primarily for constructing applicative programs [71] rather than imperative programs. Artificial intelligence techniques have also been applied to software engineering [105, 65]. However, most systems (e.g. <ref> [106, 109] </ref>) are of the program transformation kind and do not address the issue of formalizing problem domain specifications.
Reference: [110] <author> J. M. Spivey. </author> <title> Understanding Z. </title> <publisher> Cambridge University Press, </publisher> <address> Cambridge, </address> <year> 1988. </year>
Reference-contexts: Such use severely stresses the automated reasoning system because the semantics of interesting machines is extraordinarily complicated. Another group of researchers <ref> [40, 54, 34, 110] </ref> in software engineering have proposed formal specification languages and techniques for verifying designs of programs with respect to specifications. Three typical specification formalisms [117] are Larch [41], VDM [54] and Z (pronounced "zed") [110]. <p> Another group of researchers [40, 54, 34, 110] in software engineering have proposed formal specification languages and techniques for verifying designs of programs with respect to specifications. Three typical specification formalisms [117] are Larch [41], VDM [54] and Z (pronounced "zed") <ref> [110] </ref>. In all three formalisms, a system (problem domain) to be constructed is typically formalized as a set of states and a set of operations or procedures to change state.
Reference: [111] <author> Werner Stephan and Susanne Biundo. </author> <title> A new logical framework for deductive planning. </title> <booktitle> In Proc. of IJCAI-93. </booktitle>
Reference-contexts: In fact, the most difficult parts of the proof are involved not with generating the plan itself, but with proving that it meets the specified conditions successfully. A recent theoretical proposal that also treats plans as programs is reported in <ref> [111] </ref>. The authors propose a logical framework for specifying consistent axiom-atizations of planning domains in Dynamic Logic [45] using a STRIPS-like [30, 29] representation of actions. Unlike the situation calculus, states are not explicitly represented as terms in dynamic logic but are instead referred to using modal operators.
Reference: [112] <author> G. J. Sussman. </author> <title> A Computational Model of Skill Acquisition. </title> <publisher> American Else-vier, </publisher> <address> New York, </address> <year> 1975. </year>
Reference-contexts: The blocks world has been used as an example problem domain in AI for a long time <ref> [118, 112, 28] </ref> and at present there is some controversy over whether or not it is a "solved" problem.
Reference: [113] <author> Austin Tate, James Hendler, and Mark Drummond. </author> <title> A review of AI planning techniques. </title> <editor> In James Allen, James Hendler, and Austin Tate, editors, </editor> <booktitle> Readings in Planning, </booktitle> <pages> pages 26-50. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mate, CA, </address> <year> 1990. </year>
Reference-contexts: We call such Lisp programs plan generators since they are similar to the planning algorithms for generating straightline plans <ref> [2, 113] </ref> used in AI. For example, the sequence of actions needed to clear a block in various states according to our plan is computed by the following plan generating program makeclear-gen. <p> This representation has been used in AI programs written in PLANNER [118] and Prolog [58], and is used currently by many existing planning programs <ref> [113] </ref>. The representation turns out to be inconvenient for specifying the predicate on the set of possible states because it forces us to specify a number of state constraints explicitly. <p> Vere [114] describes a planning system that accepts problems in propositional STRIPS <ref> [113] </ref> as input and generates a "partially ordered network of activities" as output. Fox [32] describes an expert system to plan and schedule tasks required for manufacturing products. More recently, Penberthy and Weld [103] describe a planner based on propositional STRIPS to generate plans that satisfy some temporal constraints. <p> In fact, a major portion of research in planning in AI is concerned with the construction of more efficient planners of this sort <ref> [113, 2] </ref>. However, because it is a function in a logic and because we have all possible domains as terms in the logic, it can be proved correct once and used to generate solutions to problems when a domain is modified.
Reference: [114] <author> Steven A. Vere. </author> <title> Planning in Time: Windows and Durations for Activities and Goals, pages 297-318. </title> <editor> In Allen et al. </editor> <volume> [2], </volume> <year> 1990. </year>
Reference-contexts: Vere <ref> [114] </ref> describes a planning system that accepts problems in propositional STRIPS [113] as input and generates a "partially ordered network of activities" as output. Fox [32] describes an expert system to plan and schedule tasks required for manufacturing products.
Reference: [115] <author> R. J. Waldinger. </author> <title> Achieving several goals simultaneously. </title> <editor> In B. L. Webber and N. J. Nilsson, editors, </editor> <booktitle> Readings in Artificial Intelligence. </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> Los Altos, CA, </address> <year> 1981. </year>
Reference-contexts: What makes the frame problem a problem is that, in domains of realistic complexity, there are many more actions and fluents and so many more frame axioms, thus making it practically impossible to obtain economical problem specifications. A related problem is the problem of side-effects <ref> [47, 102, 115] </ref>. This precludes the use of the "programming convention" that all fluents other than those explicitly asserted to change in the problem specification are left unchanged by an action. Side-effects are the changes caused by an action in objects other than its arguments. <p> However, the derivation of frame axioms is not straightforward when the non-deterministic choose construct is employed. The main disadvantage of this approach is the difficulty of expressing actions with side-effects using this STRIPS-like representation of actions <ref> [115] </ref>. Also, state constraints must be formulated by the user and introduced explicitly as part of the domain specification. In general, it is difficult to formulate constraints in a way consistent with the underlying action semantics.
Reference: [116] <author> Richard Waldinger. </author> <title> The bomb in the toilet. </title> <journal> Computational Intelligence, </journal> <volume> 3 </volume> <pages> 220-221, </pages> <year> 1987. </year>
Reference-contexts: This difficulty arises because we have not taken into account that the monkey cannot test the initial state of the world to determine whether the banana is in a box or not. A similar situation arises with the "bomb in the toilet problem" <ref> [88, 116] </ref>. To prevent the construction of both forms of non-executable plans as solutions, Manna and Waldinger restrict plans to contain only primitive symbols which are described as those symbols "which we know how to execute".
Reference: [117] <author> Jeanette M. Wing. </author> <title> A specifier's introduction to formal methods. </title> <booktitle> IEEE Computer, </booktitle> <month> Septermber </month> <year> 1990. </year>
Reference-contexts: Such use severely stresses the automated reasoning system because the semantics of interesting machines is extraordinarily complicated. Another group of researchers [40, 54, 34, 110] in software engineering have proposed formal specification languages and techniques for verifying designs of programs with respect to specifications. Three typical specification formalisms <ref> [117] </ref> are Larch [41], VDM [54] and Z (pronounced "zed") [110]. In all three formalisms, a system (problem domain) to be constructed is typically formalized as a set of states and a set of operations or procedures to change state.
Reference: [118] <author> T. Winograd. </author> <title> A procedural model of language understanding. </title> <editor> In R. Schank and K. Colby, editors, </editor> <booktitle> Computer Models of Thought and Language. </booktitle> <editor> W. H. </editor> <publisher> Freeman, </publisher> <address> San Francisco, </address> <year> 1973. </year>
Reference-contexts: The blocks world has been used as an example problem domain in AI for a long time <ref> [118, 112, 28] </ref> and at present there is some controversy over whether or not it is a "solved" problem. <p> Our first representation of blocks world states is as a list of terms that stand for primitive relations between blocks in a state such as On (A; B), Ontable (D) and Clear (C). This representation has been used in AI programs written in PLANNER <ref> [118] </ref> and Prolog [58], and is used currently by many existing planning programs [113]. The representation turns out to be inconvenient for specifying the predicate on the set of possible states because it forces us to specify a number of state constraints explicitly.
Reference: [119] <author> T. </author> <title> Winograd. </title> <booktitle> Frame Representations and the Declarative/Procedural Controversy, </booktitle> <pages> pages 357-370. </pages> <note> In Brachman and Levesque [13], </note> <year> 1985. </year>
Reference-contexts: Because we specify problem domains by programming, our approach makes it possible to formalize complex domains while retaining the power of logic to prove general properties. Thus, it combines the benefits of procedural and declarative specifications <ref> [76, 92, 119] </ref>. The frame problem does not arise any more than when programming a simulator for a domain in Lisp because all changes brought about by the execution of an action are specified using a program.
Reference: [120] <author> J. C. P. Woodcock. </author> <title> Structuring specifications in Z. </title> <journal> Software Engineering Journal, </journal> <pages> pages 51-66, </pages> <month> January </month> <year> 1989. </year> <month> 225 </month>
Reference-contexts: Thus, reusable theories and libraries [52, 65, 53] have been identified as an important requirement for automated software design. As Woodcock <ref> [120] </ref> puts it: Re-usability is vital to the successful application of formal methods: it allows us to remain flexible by sharing descriptions at every stage of the development process.
Reference: [121] <author> Larry Wos, Ross Overbeek, Ewing Lusk, and Jim Boyle. </author> <title> Automated Reasoning: Introduction and Applications. </title> <publisher> Prentice Hall, Inc., </publisher> <year> 1984. </year>
Reference-contexts: The problem is usually stated for an ordinary 8 fi 8 checkerboard as follows <ref> [107, 121] </ref>: 60 61 An ordinary chess board has had two squares|one at each end of a diagonal|removed. There is on hand an unlimited supply of dominoes, each of which is large enough to cover exactly two adjacent squares of the board. <p> Using mathematical induction, we can exhaustively "test" the infinite number of possible sequences of actions and show that none of them can be used to cover a mutilated n fi n board. One previous attempt to mechanize the checkerboard solution was given by Wos et al. <ref> [121] </ref>. However, their effort differs from what we want in two respects. First, they propose a solution to the 8 fi 8 checkerboard problem and not the n fi n problem as in our case.

References-found: 121

