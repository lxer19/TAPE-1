URL: http://www.statslab.cam.ac.uk/~gareth/storage7.ps
Refering-URL: http://www.stats.bris.ac.uk/MCMC/pages/list.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Rates of convergence of stochastically monotone and continuous time Markov models  
Author: G. O. Roberts and R. L. Tweedie 
Keyword: 0 Keywords: Stochastic monotonicity, rates of convergence, Markov chain, Markov process SHORT TITLE: Stochatic monotonicity and rate bounds  
Address: DPMMS, 16 Mill Lane, Cambridge CB2 1SB, UK Postal Address:  Fort Collins CO 80523, USA  
Affiliation: Statistical Laboratory,  Department of Statistics, Colorado State University,  
Note: Work supported in part by NSF Grant DMS 9504561 and EPSRC grant GR/J19900 Postal Address:  
Date: March 17, 1998  
Abstract: In this paper we give bounds on the total variation distance from convergence of a continuous time positive recurrent Markov process on an arbitrary state space, based on Foster-Lyapunov drift and minorisation conditions. Considerably improved bounds are given in the stochastically monotone case, for both discrete and continuous time models, even in the absence of a reachable minimal element. These results are applied to storage models and to diffusion processes. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. Asmussen. </author> <title> Applied Probability and Queues. </title> <publisher> John Wiley & Sons, </publisher> <address> New York, </address> <year> 1987. </year>
Reference-contexts: Let ~ be the stochastic majorant of and , that is (e:major) P ~ (Y y) = <ref> [1; y] </ref> ^ [1; y] (10) Analogous to (5), we define (e:xitdef) ~ ~ = log 1 1 (e:boundinit1) (11) the inequality follows since (V ) b=(1 ), as in [5] or [11] for example. t:disccouple Theorem 2.2 Suppose that X is a stochastically monotone Markov chain satisfying (2) and (3) <p> Let ~ be the stochastic majorant of and , that is (e:major) P ~ (Y y) = <ref> [1; y] </ref> ^ [1; y] (10) Analogous to (5), we define (e:xitdef) ~ ~ = log 1 1 (e:boundinit1) (11) the inequality follows since (V ) b=(1 ), as in [5] or [11] for example. t:disccouple Theorem 2.2 Suppose that X is a stochastically monotone Markov chain satisfying (2) and (3) and started from <p> Suppose also that C takes the form <ref> [1; c] </ref> for some c 2 X. <p> By stochastic monotonicity, we can jointly run the two processes so that their initial order is preserved for all time. We let _ denote the stochastic minorant of and : that is (e:minor) P _ (Y y) = <ref> [1; y] </ref> _ [1; y] (13) and let ~ F and _ F be the distribution functions of ~ and _. For any distribution function F on X, and for u 2 [0; 1], set F (u) = inffx : F (x) ug. <p> By stochastic monotonicity, we can jointly run the two processes so that their initial order is preserved for all time. We let _ denote the stochastic minorant of and : that is (e:minor) P _ (Y y) = <ref> [1; y] </ref> _ [1; y] (13) and let ~ F and _ F be the distribution functions of ~ and _. For any distribution function F on X, and for u 2 [0; 1], set F (u) = inffx : F (x) ug. <p> For any distribution function F on X, and for u 2 <ref> [0; 1] </ref>, set F (u) = inffx : F (x) ug. <p> T is exactly analogous to that spelled out in Theorem 2.2, so the details are omitted. 5 A storage model example As our first example of the use of Theorem 4.3, we consider the Markov chain X on (0; 1) which describes a storage model with output proportional to content <ref> [1] </ref>. That is, X decays at an exponential rate fi, but at the times of input to the storage, which form a Poisson process of rate ff, there are positive jumps given by independent Exponential (1) random variables.
Reference: [2] <author> T. Lindvall. </author> <title> Lectures on the Coupling Method. </title> <publisher> John Wiley & Sons, </publisher> <address> New York, </address> <year> 1992. </year>
Reference-contexts: The bound (12) now follows immediately from Theorem 2.1 and the coupling inequality <ref> [2] </ref> applied to (1). <p> Proof We use the usual coupling construction with two processes marginally consistent with the dynamics of P , and generated on a bivariate space (see for example <ref> [2] </ref>). One process begins at x, the other at the stationary distribution . The processes will proceed independently until such time that they are both in C, when they are coupled with the minorisation probability ". <p> Then (e:contmon) kP (X t 2 ) ()k r (t; ffi; "; fl; ~) (37) where ~ is given by (10). Proof Since X is stochastically monotone, there is a probability space supporting two processes marginally faithful to P , started at different distributions, which preserves their order (see <ref> [2] </ref>).
Reference: [3] <author> Jun Liu. </author> <title> Eigenanalysis for a Metropolis sampling scheme with comparisons to rejection sampling and importance resampling. </title> <institution> Research Report R-427, Department of Statistics, Harvard University, </institution> <year> 1992. </year>
Reference-contexts: This means that we can take b = 1 and arbitrarily small. Taking the limit as ! 0 in (7) implies that (1 "). This is exactly the coupling bound (see for example [6, Theorem 16.2.4]), which is known to be exact for certain MCMC models <ref> [3, 14] </ref>.
Reference: [4] <author> R.B. Lund, </author> <title> S.P. Meyn, and R.L. Tweedie. Computable exponential convergence rates for stochastically ordered Markov processes. </title> <journal> Ann. Appl. Probab., </journal> <volume> 6 </volume> <pages> 218-237, </pages> <year> 1996. </year>
Reference-contexts: Suppose now that X is a stochastically monotone continuous time Markov process; that is, for all a 2 X, t 0, P t (; (1; a)) is non-increasing. Our next result is the continuous analogue of Theorem 2.2, generalising <ref> [4] </ref>, where only the case where 0 inffa; a 2 Xg is attainable was considered. t:cont2 Theorem 4.3 Suppose that X is stochastically monotone and positive recurrent, and that there exists a 2 X; t fl ; " &gt; 0 such that C = (1; a] is (t fl ; ")-small, <p> That is, X decays at an exponential rate fi, but at the times of input to the storage, which form a Poisson process of rate ff, there are positive jumps given by independent Exponential (1) random variables. This is similar to the models which are analysed in <ref> [4] </ref>, but the exponential decay in this model means that the empty state f0g is not achievable. In order to use our results, we first show that (0; a) is (t fl ; e a (1 e fft fl ))-small for all choices of a; t fl &gt; 0.
Reference: [5] <author> R.B. Lund and R.L. Tweedie. </author> <title> Geometric convergence rates for stochastically ordered Markov chains. </title> <journal> Math. Operations Res., </journal> <volume> 21 </volume> <pages> 182-194, </pages> <year> 1996. </year>
Reference-contexts: Lund and Tweedie <ref> [5] </ref> showed that if the chain has a stochastic 2 Discrete time bounds and stochastic monotonicity 4 monotonicity property, then one can avoid this bivariate structure. We now consider this context using Theorem 2.2. <p> We note that stochastic monotonicity is implied by this statement for just n = 1. Only the case where 0 inffa : a 2 Xg is attainable, in the sense that 0 2 X and (f0g) &gt; 0, was considered in <ref> [5] </ref>. We now show that we can exploit the monotonicity without this constraint, using the bounds from [10] in Theorem 2.1 directly to get tighter results. Our results are substantially more applicable than those of [5], since we consider models for which we can attain an arbitrary small set at the <p> attainable, in the sense that 0 2 X and (f0g) &gt; 0, was considered in <ref> [5] </ref>. We now show that we can exploit the monotonicity without this constraint, using the bounds from [10] in Theorem 2.1 directly to get tighter results. Our results are substantially more applicable than those of [5], since we consider models for which we can attain an arbitrary small set at the "bottom" of the space; and we do not require the drift condition (3) for C = f0g. <p> Let ~ be the stochastic majorant of and , that is (e:major) P ~ (Y y) = [1; y] ^ [1; y] (10) Analogous to (5), we define (e:xitdef) ~ ~ = log 1 1 (e:boundinit1) (11) the inequality follows since (V ) b=(1 ), as in <ref> [5] </ref> or [11] for example. t:disccouple Theorem 2.2 Suppose that X is a stochastically monotone Markov chain satisfying (2) and (3) and started from x. Suppose also that C takes the form [1; c] for some c 2 X. <p> We take p &gt; 1=2 so that the chain is irreducible and geometrically ergodic. As is obvious, this chain is stochastically monotone. Rather artificially, we take C = f0; 1g, and essentially as in <ref> [5, 13] </ref> we take V (x) = [p=q] x=2 ; x = 0; 1; : : : ; which leads to = 4pq; b = p pq; " = p; d = p=q: Here, the best rate of convergence is in fact = p 4pq: this follows using the methods in <p> 13] we take V (x) = [p=q] x=2 ; x = 0; 1; : : : ; which leads to = 4pq; b = p pq; " = p; d = p=q: Here, the best rate of convergence is in fact = p 4pq: this follows using the methods in <ref> [5] </ref> with f0g as the small set. <p> This last bound is known [10] to be poorer than that in Theorem 2.2. Bounds on the Rate of Convergence for Random Walk p 0.51 0.56 0.61 0.66 0.71 0.76 0.81 0.86 0.91 0.96 Optimal <ref> [5] </ref> 0.9998 0.993 0.976 0.947 0.908 0.85 0.78 0.69 0. 57 0.39 Theorem 2.2 0.9998 0.993 0.976 0.947 0.912 0.87 0.83 0.76 0.67 0.53 ST [13] 0.9999 0.996 0.988 0.974 0.954 0.93 0.89 0.85 0.79 0.70 Table 2.1. <p> This interpretation of the results is shown in Figure 2.1, where approximate log convergence times are given for the range of p values in Table 2.1. walk. The solid line represents the optimal bound (from <ref> [5] </ref>), the dotted and joined line is the bound from Theorem 2.2, and the dotted line is that from [13]. 3 Continuous time regeneration bounds In this section we extend the ideas of the previous section to continuous time, and this also gives results for bounds on total variation distance from
Reference: [6] <author> S. P. Meyn and R. L. Tweedie. </author> <title> Markov Chains and Stochastic Stability. </title> <publisher> Springer-Verlag, </publisher> <address> London, </address> <year> 1993. </year>
Reference-contexts: 1 = P as usual; and for any -finite measure and any non-negative function f we write (f ) = R We will assume that P is an aperiodic positive Harris recurrent chain, with invariant probability measure , and that P is -irreducible and geometrically ergodic: that is, as in <ref> [6, Chapter 15] </ref>, kP n (x; ) k V (x) n (1) for some function V : X ! [0; 1) and some constant &lt; 1. <p> We set J = d + 1 (b "); (e:etadef) = log 1 : (4) If is the initial measure, we set (e:dxidef) ~ = log 1 : (5) The following result is from [10, Theorem 5.1], and gives bounds on the times of the Nummelin splitting <ref> [6, Chapter 5] </ref> within C which will be crucial to our approach. t:disc Theorem 2.1 Suppose that (2) and (3) hold for the set C and some drift function V . <p> This means that we can take b = 1 and arbitrarily small. Taking the limit as ! 0 in (7) implies that (1 "). This is exactly the coupling bound (see for example <ref> [6, Theorem 16.2.4] </ref>), which is known to be exact for certain MCMC models [3, 14].
Reference: [7] <author> S. P. Meyn and R. L. Tweedie. </author> <title> Stability of Markovian processes III: Foster-Lyapunov criteria for continuous time processes. </title> <journal> Adv. Appl. Probab., </journal> <volume> 25 </volume> <pages> 518-548, </pages> <year> 1993. </year>
Reference-contexts: positive time t fl and " &gt; 0, if (C) &gt; 0 and there exists a probability measure '() on X satisfying the minorisation condition P t fl (e:1) In this context we utilise drift conditions which are based on the generator of P (for background and discussion see, e.g., <ref> [7] </ref>). <p> satisfy the one-sided Dynkin's formula (e:Dynk) E x (W (X t )) E x 0 This formula holds with equality if W is in the domain of the strong generator; furthermore, it holds at least with inequality if W is in the domains of certain stopped versions of the process <ref> [7] </ref>.
Reference: [8] <author> S. P. Meyn and R. L. Tweedie. </author> <title> Computable bounds for convergence rates of Markov chains. </title> <journal> Ann. Appl. Probab., </journal> <volume> 4 </volume> <pages> 981-1011, </pages> <year> 1994. </year>
Reference-contexts: 1 Introduction There has been considerable recent work on the problem of determining, in some computable way, the rate of convergence of Markov chains and processes. Recently, Meyn and Tweedie <ref> [8] </ref>, Rosenthal [11], and Roberts and Tweedie [10] have given bounds on total variation distance from stationarity of positive recurrent Markov chains, in terms of Lyapunov-Foster type drift conditions. Such results are extended to continuous time models by Roberts and Rosenthal [9].
Reference: [9] <author> G.O. Roberts and J.S. Rosenthal. </author> <note> A note on rescaled langevin algorithms. (In preparation). </note>
Reference-contexts: Recently, Meyn and Tweedie [8], Rosenthal [11], and Roberts and Tweedie [10] have given bounds on total variation distance from stationarity of positive recurrent Markov chains, in terms of Lyapunov-Foster type drift conditions. Such results are extended to continuous time models by Roberts and Rosenthal <ref> [9] </ref>. These results have the advantage of being applicable to any Markov chain (or process) on a completely general state space. <p> The purpose of this paper is twofold. Firstly, we develop continuous time results which are analogues of those of [10]. This often leads to considerable improvements in convergence time estimates, and is considerably easier to apply than existing approaches, such as those in <ref> [9] </ref> Secondly, we produce much sharper bounds in a specific class of models where Lyapunov-Foster techniques are particularly effective, namely when the Markov chain or process is stochastically monotone. <p> The set C fi C is clearly (t fl ; ")small, so we can directly apply Theorem 4.1. Since the regeneration time is t + t fl , the result 5 A storage model example 12 follows. Again, bounds on fl (V ) are readily available. From <ref> [9] </ref>, (V ) fl=ffi, so that (e:boundinit2) fl (V ) ffi providing a practical bound for use in (34). <p> In the diffusion examples considered in <ref> [9] </ref>, it was necessary to introduce `medium' and `pseudo-small' sets to bound ". The medium set construction of [9] can be used to provide parameters for rather general one-dimensional diffusions. <p> In the diffusion examples considered in <ref> [9] </ref>, it was necessary to introduce `medium' and `pseudo-small' sets to bound ". The medium set construction of [9] can be used to provide parameters for rather general one-dimensional diffusions. We will not carry out such general calculations, but rather concentrate on a simple but frequently used special case where the results have a particularly accessible form. <p> Proof That [c; a] is small follows from a simple comparison argument on the difference between two processes X a and X c started at a and c respectively, using anti-correlated Brownian motions. The final expression for the minorising constant comes from the Bachelier-Levy formula, as used in <ref> [9] </ref>. Many one-dimensional positive recurrent diffusions satisfy the conditions of this general lemma. In each specific case we also need to verify the existence of V satisfying (16), and this depends on the specific function . To illustrate the results in this context, we consider the following example.
Reference: [10] <author> G.O. Roberts and R.L. Tweedie. </author> <title> Bounds on regeneration times and convergence rates of markov chains. </title> <note> 1998. (submitted for publication). </note>
Reference-contexts: 1 Introduction There has been considerable recent work on the problem of determining, in some computable way, the rate of convergence of Markov chains and processes. Recently, Meyn and Tweedie [8], Rosenthal [11], and Roberts and Tweedie <ref> [10] </ref> have given bounds on total variation distance from stationarity of positive recurrent Markov chains, in terms of Lyapunov-Foster type drift conditions. Such results are extended to continuous time models by Roberts and Rosenthal [9]. <p> The purpose of this paper is twofold. Firstly, we develop continuous time results which are analogues of those of <ref> [10] </ref>. <p> Section 2 gives such 2 Discrete time bounds and stochastic monotonicity 2 bounds, using the regeneration time bounds of <ref> [10] </ref> and then specialising these for stochastically monotone Markov chains. In Section 3 we find a continuous time version of the regeneration time bounds in [10]. <p> Section 2 gives such 2 Discrete time bounds and stochastic monotonicity 2 bounds, using the regeneration time bounds of <ref> [10] </ref> and then specialising these for stochastically monotone Markov chains. In Section 3 we find a continuous time version of the regeneration time bounds in [10]. These results are interesting in their own right, and are also applied in Section 4 to give bounds on total variation distance from stationarity for continuous time general state space Markov processes. It is shown that in the stochastically monotone case these convergence time bounds are again much sharper. <p> 6 deal with examples, the former considering storage models and the latter dealing with a one dimensional diffusion example which can also be used to give rates of convergence of certain spherically symmetric three-dimensional diffusions. 2 Discrete time bounds and stochastic monotonicity There are two ingredients to the bounds in <ref> [10] </ref> that we shall use: a small set condition and a Foster-Lyapunov drift condition. <p> We set J = d + 1 (b "); (e:etadef) = log 1 : (4) If is the initial measure, we set (e:dxidef) ~ = log 1 : (5) The following result is from <ref> [10, Theorem 5.1] </ref>, and gives bounds on the times of the Nummelin splitting [6, Chapter 5] within C which will be crucial to our approach. t:disc Theorem 2.1 Suppose that (2) and (3) hold for the set C and some drift function V . <p> Thus our method provides the optimal rate in these circumstances, and the approximations used have lost us noth ing. s:monoMC In order to use the bounds in Theorem 2.1 to develop bounds in (1), a coupling of a bivariate Markov chain was used in <ref> [10] </ref>, and this bivariate structure leads to poor bounds in many cases. Lund and Tweedie [5] showed that if the chain has a stochastic 2 Discrete time bounds and stochastic monotonicity 4 monotonicity property, then one can avoid this bivariate structure. We now consider this context using Theorem 2.2. <p> Only the case where 0 inffa : a 2 Xg is attainable, in the sense that 0 2 X and (f0g) &gt; 0, was considered in [5]. We now show that we can exploit the monotonicity without this constraint, using the bounds from <ref> [10] </ref> in Theorem 2.1 directly to get tighter results. <p> This last bound is known <ref> [10] </ref> to be poorer than that in Theorem 2.2. <p> a small set C and a function V 2 D, such that for positive constants d; ffi and fl, V 1; sup x2C V (x) = d; AV (x) ffiV (x) + fl1 C (x) : (e:drift) (16) In order to construct a geometric trials argument similar to that in <ref> [10] </ref>, we let 0 = infft 0 : X t 2 Cg, and let t i ; i = 1; 2; : : : be defined by t 1 = infft 0 + t fl : X t 2 Cg ; and t i = infft t i1 + t fl <p> of the first regeneration time, and G (fi) be the moment generating function of 0 , started from the initial distribution ; and set (e:gstar) G fl (fi) = e fit fl y2C R (y; dw) E w (e fi 0 ) : (17) Emulating the discrete time results in <ref> [10] </ref> we have t:mgf Theorem 3.1 For any 0 &lt; fi ffi such that (1 ")G fl (fi) &lt; 1, and V satisfying (16), (e:firsteq) H (fi) G (fi) (18) "e fit fl 1 (1 ") i fi=ffi (e:secondeq) (19) where = ( fl ffi ")e ffit fl + d fl <p> The second set of inequalities involve minimising expression (24) in fi, as in <ref> [10] </ref>. <p> The processes will proceed independently until such time that they are both in C, when they are coupled with the minorisation probability ". Let (X; Y ) be the joint process, with couplings of X and Y corresponding to regenerations of this joint processes. Emulating <ref> [10] </ref>, let h (x; y) = (V (x) + V (y))=2 so that by (33), h satisfies a Lyapunov drift condition for the joint processes with generator A fl : (e:jointdrift) A fl h ffi fl h + fl fl 1 CfiC (35) where ffi fl = ffi fl=(d + 1)
Reference: [11] <author> J.S. Rosenthal. </author> <title> Minorization conditions and convergence rates for Markov chain Monte Carlo. </title> <journal> J. Amer. Statist. Assoc., </journal> <volume> 90 </volume> <pages> 558-566, </pages> <year> 1995. </year>
Reference-contexts: 1 Introduction There has been considerable recent work on the problem of determining, in some computable way, the rate of convergence of Markov chains and processes. Recently, Meyn and Tweedie [8], Rosenthal <ref> [11] </ref>, and Roberts and Tweedie [10] have given bounds on total variation distance from stationarity of positive recurrent Markov chains, in terms of Lyapunov-Foster type drift conditions. Such results are extended to continuous time models by Roberts and Rosenthal [9]. <p> Let ~ be the stochastic majorant of and , that is (e:major) P ~ (Y y) = [1; y] ^ [1; y] (10) Analogous to (5), we define (e:xitdef) ~ ~ = log 1 1 (e:boundinit1) (11) the inequality follows since (V ) b=(1 ), as in [5] or <ref> [11] </ref> for example. t:disccouple Theorem 2.2 Suppose that X is a stochastically monotone Markov chain satisfying (2) and (3) and started from x. Suppose also that C takes the form [1; c] for some c 2 X.
Reference: [12] <author> J.S. Rosenthal. </author> <title> Convergence of Gibbs sampler for a model related to James-Stein estimators. </title> <journal> Stat. and Comput., </journal> <volume> 6 </volume> <pages> 269-275, </pages> <year> 1996. </year>
Reference-contexts: Unfortunately, the generality of the results also leads to the bounds produced being too poor to be of practical value in many examples, particularly some of those from Markov chain Monte Carlo (MCMC) models, the application which inspired much of this work (though see <ref> [12] </ref>). The purpose of this paper is twofold. Firstly, we develop continuous time results which are analogues of those of [10].
Reference: [13] <author> D.J. Scott and R.L. Tweedie. </author> <title> Explicit rates of convergence of stochastically ordered Markov chains. </title> <booktitle> In Proc. Athens Conference on Applied Probability and Time Series Analysis: Papers in Honour of J.M. Gani and E.J. Hannan, </booktitle> <pages> pages 176-191, </pages> <address> New York, 1996. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: Although of course are results are not as sharp as when the minimal element is assumed to be attainable, they are still a great improvement on the use of the bivariate chain; and they also improve on those in <ref> [13] </ref>, where an ad hoc adjustment to use drift conditions to an arbitrary small set was introduced. <p> We take p &gt; 1=2 so that the chain is irreducible and geometrically ergodic. As is obvious, this chain is stochastically monotone. Rather artificially, we take C = f0; 1g, and essentially as in <ref> [5, 13] </ref> we take V (x) = [p=q] x=2 ; x = 0; 1; : : : ; which leads to = 4pq; b = p pq; " = p; d = p=q: Here, the best rate of convergence is in fact = p 4pq: this follows using the methods in <p> The table below gives the values of this best rate and that given by Theorem 2.2 for various values of p: we also give the bound ST = 2=( 4pq + 1) from <ref> [13] </ref>, which also uses drift to the set C = f0; 1g. This last bound is known [10] to be poorer than that in Theorem 2.2. <p> Bounds on the Rate of Convergence for Random Walk p 0.51 0.56 0.61 0.66 0.71 0.76 0.81 0.86 0.91 0.96 Optimal [5] 0.9998 0.993 0.976 0.947 0.908 0.85 0.78 0.69 0. 57 0.39 Theorem 2.2 0.9998 0.993 0.976 0.947 0.912 0.87 0.83 0.76 0.67 0.53 ST <ref> [13] </ref> 0.9999 0.996 0.988 0.974 0.954 0.93 0.89 0.85 0.79 0.70 Table 2.1. <p> different values of p in the Bernoulli random walk example. 3 Continuous time regeneration bounds 6 Note that until p &gt; 0:66, the regeneration bounds give the optimal result, since in this range J &lt; 1; for lighter traffic the bounds from Theorem 2.2 are considerably better than those in <ref> [13] </ref>. Inverting (6) gives an easy approximation to convergence time by assuming that it is proportional to (log ) 1 . This interpretation of the results is shown in Figure 2.1, where approximate log convergence times are given for the range of p values in Table 2.1. walk. <p> The solid line represents the optimal bound (from [5]), the dotted and joined line is the bound from Theorem 2.2, and the dotted line is that from <ref> [13] </ref>. 3 Continuous time regeneration bounds In this section we extend the ideas of the previous section to continuous time, and this also gives results for bounds on total variation distance from the stationary distribution of a general state space Markov process.
Reference: [14] <author> R.L. Smith and L. Tierney. </author> <title> Exact transition probabilities for the independence Metropolis sampler. </title> <note> 1997. (Preprint at http://www.stats.bris.ac.uk/MCMC/). </note>
Reference-contexts: This means that we can take b = 1 and arbitrarily small. Taking the limit as ! 0 in (7) implies that (1 "). This is exactly the coupling bound (see for example [6, Theorem 16.2.4]), which is known to be exact for certain MCMC models <ref> [3, 14] </ref>.
References-found: 14

