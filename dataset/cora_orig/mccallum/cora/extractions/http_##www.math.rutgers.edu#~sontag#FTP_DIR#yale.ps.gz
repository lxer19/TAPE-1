URL: http://www.math.rutgers.edu/~sontag/FTP_DIR/yale.ps.gz
Refering-URL: http://www.math.rutgers.edu/~sontag/papers.html
Root-URL: 
Email: E-mail: sontag@hilbert.rutgers.edu  
Title: NEURAL NETS AS SYSTEMS MODELS AND CONTROLLERS suitability of "neural nets" as models for dynamical
Author: Eduardo D. Sontag 
Note: to the  
Address: New Brunswick, NJ 08903  
Affiliation: Dept. of Mathematics, SYCON Rutgers Center for Systems and Control Rutgers University,  
Abstract: This paper briefly surveys some recent results relevant 
Abstract-found: 1
Intro-found: 1
Reference: [1] <editor> Albertini, F., and E.D. Sontag, </editor> <title> "For neural networks, function determines form," </title> <note> submitted. </note>
Reference-contexts: For instance, polynomial-time computation by -systems with real coefficients |a form of analog computing| is equivalent to a notion of computability (nonuniform polysize circuits) that appeared in abstract computation theory. Even the "P=?NP" problem has a version for -systems; see [9]. 3.8. Identifiability In <ref> [1] </ref>, with Francesca Albertini, we were interested in studying the following issue: To what extent does the function of a -system, that is to say, the "black box" behavior mapping external inputs to outputs, uniquely determine the coefficients of the matrices A, B, C? A precise formulation, for continuous-time, is as <p> Conversely, any such T gives rise to another system with the same i/o behavior. These classical facts apply only when is linear, as we discuss in <ref> [1] </ref>. There we show that for nonlinear activations |under very mild assumptions| the natural group of symmetries is far smaller than that of arbitrary nonsingular matrices, being instead just a finite group. We prove in [1] that if two nets give rise to the same i/o behavior, then (again, as for <p> These classical facts apply only when is linear, as we discuss in <ref> [1] </ref>. There we show that for nonlinear activations |under very mild assumptions| the natural group of symmetries is far smaller than that of arbitrary nonsingular matrices, being instead just a finite group. We prove in [1] that if two nets give rise to the same i/o behavior, then (again, as for linear systems, generically,) a matrix T will exist, providing the above interlacing equations, but having the special form of a permutation matrix composed with a diagonal matrix performing at most a sign reversal at each
Reference: [2] <author> Cybenko, G., </author> <title> "Approximation by superpositions of a sigmoidal function," Math. Control, Signals, </title> <booktitle> and Systems 2(1989): </booktitle> <pages> 303-314. </pages>
Reference-contexts: But most nonlinear functions are universal. Indeed, Hornik proved in [3] that any which is continuous, nonconstant, and bounded is universal (see also <ref> [2] </ref> for related results). Moreover, he also proved there (The <p>- orem 3 in the paper) that if in addition to the above, is of class C k , then it is also k-universal, for each positive integer k. (M.
Reference: [3] <author> Hornik, K., </author> <title> "Approximation capabilities of multilayer feedforward networks," </title> <booktitle> Neural Networks 4(1991): </booktitle> <pages> 251257. </pages>
Reference-contexts: But most nonlinear functions are universal. Indeed, Hornik proved in <ref> [3] </ref> that any which is continuous, nonconstant, and bounded is universal (see also [2] for related results).
Reference: [4] <author> Maass, W., G. Schnitger, and E.D. Sontag, </author> <title> "On the computational power of sigmoid versus boolean thresh-old circuits," </title> <booktitle> Proc. of the 32nd Annual Symp. on Foundations of Computer Science, </booktitle> <year> 1991: </year> <pages> 767-776. </pages>
Reference-contexts: In the multi-input case, it is interesting to study the particular case of binary inputs and the scaling with respect to input size, for natural Boolean functions; this gives a connection with theoretical computer science issues in the area of "circuit complexity" as discussed in <ref> [4] </ref>. 2.5.
Reference: [5] <author> Matthews, M., </author> <title> "On the uniform approximation of non-linear discrete-time fading-memory systems using neu-ral network models," </title> <type> Ph.D. Thesis, </type> <institution> E.T.H. Zurich, Diss. ETH No. </institution> <month> 9635, </month> <year> 1992. </year>
Reference-contexts: Some variations of this result were given earlier and independently in [6] and <ref> [5] </ref>, under more restrictive assumptions and with somewhat different definitions. As we haven't found it in this manner in the literature, we next sketch a proof. The final maps ff and fi will be built up out of several elementary maps. <p> For applications of these approximations to signal processing see <ref> [5] </ref>, and [6] for applications to control and identification. 2.4. Number of Units As discussed earlier, pattern recognition is involved in the use of nets as selectors of lower-level controllers.
Reference: [6] <author> Polycarpou, </author> <title> M.M., and P.A. Ioannou, "Identification and control of nonlinear systems using neural network models: Design and stability analysis," </title> <type> Report 91-09-01, </type> <month> Sept. </month> <year> 1991, </year> <institution> Dept. of EE/Systems, USC, </institution> <address> Los Angeles. </address>
Reference-contexts: Some variations of this result were given earlier and independently in <ref> [6] </ref> and [5], under more restrictive assumptions and with somewhat different definitions. As we haven't found it in this manner in the literature, we next sketch a proof. The final maps ff and fi will be built up out of several elementary maps. <p> For applications of these approximations to signal processing see [5], and <ref> [6] </ref> for applications to control and identification. 2.4. Number of Units As discussed earlier, pattern recognition is involved in the use of nets as selectors of lower-level controllers.
Reference: [7] <author> Romanik, K., </author> <title> "Approximate testing and learnability," </title> <booktitle> in Proc. Fifth ACM Workshop on Computational Learning Theory, </booktitle> <address> Pittsburgh, </address> <month> July </month> <year> 1992. </year>
Reference-contexts: The sample S is loadable into F iff inf ~w2IR r E (F ~w ; S) = 0: The capacity c (F) of F is defined by requiring that c (F ) k iff every jSj = k is loadable. (This was called the "testing dimension" in <ref> [7] </ref>.) That is, c (F )=1 means that all finite S are loadable, and c (F )=k &lt;1 means that each S of cardinality k is loadable but some S of cardinality k + 1 is not.
Reference: [8] <editor> Siegelmann, H.T., and E.D. Sontag, </editor> <booktitle> "On the computa-tional power of neural nets," in Proc. Fifth ACM Workshop on Computational Learning Theory, </booktitle> <address> Pittsburgh, </address> <note> July 1992; see also SYCON Report 91-11, </note> <institution> Rutgers Center for Systems and Control, </institution> <month> November </month> <year> 1991. </year>
Reference-contexts: An alternative way of character <p>- izing the power of a class of models is in terms of the computations that they can perform. Another natural question deals with parameter (weights) identification from i/o data. We now offer some remarks on these two topics. 3.7. Computability In the paper <ref> [8] </ref> with Hava Siegelmann, and related work, we investigated the computational capabilities of -systems, seen from the point of view of formal language theory. There we studied discrete-time - systems with = . <p> There we studied discrete-time - systems with = . When restricted to binary inputs and outputs, the computations carried out by such sys <p>- tems can be viewed as transformations on languages, and hence can be compared with other, more classical, models of computation. Our main results in <ref> [8] </ref> are: (a) with rational matrices A, B, and C, (and rational initial state), such systems are equivalent, up to polynomial time, to Turing machines; (b) with real matrices, all possible binary functions, recursive or not, are "computable".
Reference: [9] <author> Siegelmann, H.T., and E.D. Sontag, </author> <title> "Analog compu-tation, neural networks, and circuits," </title> <note> submitted. </note>
Reference-contexts: For instance, polynomial-time computation by -systems with real coefficients |a form of analog computing| is equivalent to a notion of computability (nonuniform polysize circuits) that appeared in abstract computation theory. Even the "P=?NP" problem has a version for -systems; see <ref> [9] </ref>. 3.8.
Reference: [10] <author> Sontag, E.D., </author> <title> "Nonlinear regulation: The piecewise linear approach," </title> <journal> IEEE Trans. Autom. Control AC26(1981): </journal> <pages> 346-358. </pages>
Reference-contexts: Sometimes, however, new issues arise, as discussed in the paper <ref> [10] </ref> which dealt with piecewise linear regulation, an area which is very closely related to the one of using dynamic nets as controllers. 1.2. Some Definitions To fix terminology, we provide some definitions and notations. The symbol will always denote a fixed function : IR ! IR.
Reference: [11] <author> Sontag, E.D., </author> <title> "Feedforward nets for interpolation and classification," </title> <journal> J. Comp. Syst. </journal> <note> Sci., to appear, </note> <year> 1992. </year>
Reference-contexts: In <ref> [11] </ref>, we studied the relation between capacity and number of neurons, for nets with one hidden layer and Heaviside or sigmoidal activations; note that large capacity memorization, so this is especially relevant for learning issues. Next we review some results from [11]. <p> In <ref> [11] </ref>, we studied the relation between capacity and number of neurons, for nets with one hidden layer and Heaviside or sigmoidal activations; note that large capacity memorization, so this is especially relevant for learning issues. Next we review some results from [11]. Consider first the case of input dimension m=1, that is, nets with one input, and k hidden units of type in one layer. <p> Furthermore, the inequality INTP () 1=3 holds for any universal nonlinearity. The paper <ref> [11] </ref> includes also results when the number of inputs m &gt; 1.
Reference: [12] <author> Sontag, E.D., </author> <title> "Feedback Stabilization Using TwoHidden-Layer Nets," </title> <booktitle> in Proc. Amer. Automatic Control Conference, </booktitle> <address> Boston, </address> <month> June </month> <year> 1991, </year> <pages> pp. 815-820. </pages> <note> To appear in IEEE Trans. Neural Networks. </note>
Reference-contexts: It is trivial to see that in general discontinuous functions are needed, so continuous cannot be used. However, and this is the interesting part, <ref> [12] </ref> establishes that nets with just one hidden layer, even if discontinuous is allowed, are not enough to guarantee the solution of all such problems. <p> More surprisingly, 1HLN feedback laws, even with H activations, are not in general enough |intuitively, one is again trying to solve inverse problems| but two hidden layer nets using H (and having direct i/o connections) are always sufficient. More precisely, <ref> [12] </ref> shows that the weakest possible type of open-loop asymptotic controllability is sufficient to imply the existence of (sampled) controllers built using such two-hidden layer nets, which stabilize on compact subsets of the state space. 3.
Reference: [13] <author> Sontag, E.D., </author> <title> Mathematical Control Theory: Deterministic Finite Dimensional Systems, </title> <publisher> Springer, </publisher> <address> New York, </address> <year> 1990. </year>
Reference-contexts: describing the model |in other words, the weights| uniquely determined by the input/output behavior to be matched? Dynamic nets also arise as controllers, in the case in which direct state feedback is impossible and only partial measurements are available. (A general introduction to dynamic feedback is given in the textbook <ref> [13] </ref>, which should also be consulted for all undefined terms from control theory.) Often dynamic controllers may be viewed as static controllers for augmented systems: adding parallel integrators, or delay lines, to the plant P and then controlling the enlarged system by static feedback can be interpreted in this fashion. <p> Next one finds a 1HLN function as in equation (1) that uniformly approximates f (x; u) (for the extended system) close enough on K 1 fi K 2 ; this will imply the desired approximation of solutions, by any standard well-posedness result, as discussed e.g. in <ref> [13] </ref>, Theo-- rem 37. <p> Now, the proof of Theorem 12 in <ref> [13] </ref> shows that there is a neighborhood V of zero, independent of n, where exponential stability will hold, for all n sufficiently large, because f (x; k n (x))=A n x + g n (x), with A n ! A and with g n (x) being o (x) uniformly on x. <p> Now continuity of solutions on the right-hand side gives the result globally on K. In general, continuous stabilizers fail to exist, as discussed for instance in <ref> [13] </ref>, Section 4.8. Thus 1HLN feedback laws, with continuous , do not provide a rich enough class of controllers.
References-found: 13

