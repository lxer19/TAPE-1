URL: ftp://ftp.icsi.berkeley.edu/pub/techreports/1993/tr-93-020.ps.gz
Refering-URL: http://www.icsi.berkeley.edu/techreports/1993.html
Root-URL: http://www.icsi.berkeley.edu
Title: Design Principles of Parallel Operating Systems |A Peace Case Study|  
Author: Wolfgang Schroder-Preikschat 
Note: On leave from the German National Research  
Address: I 1947 Center Street Suite 600 Berkeley, California 94704  FIRST, Rudower Chaussee 5, D-1199 Berlin, Germany,  
Affiliation: INTERNATIONAL COMPUTER SCIENCE INSTITUTE  Center for Computer Science, GMD  
Pubnum: TR-93-020  
Email: wosch@first.gmd.de  
Phone: 1-510-642-4274 FAX 1-510-643-7684  
Date: April 1993  
Abstract: Forthcoming massively parallel systems are distributed memory architectures. They consist of several hundreds to thousands of autonomous processing nodes interconnected by a high-speed network. A major challenge in operating system design for massively parallel architectures is to design a structure that reduces system bootstrap time, avoids bottlenecks in serving system calls, promotes fault tolerance, is dynamically alterable, and application-oriented. In addition to that, system-wide message passing is demanded to be of very low latency and very high efficiency. State of the art parallel operating systems design must obey the maxim not to punish an application by unneeded system functions. This requires to design a parallel operating system as a family of program modules, with parallel applications being an integral part of that family, and motivates object orientation to achieve an efficient implementation. fl This report is a condensed version of the author's habilitation and will also appear in the proceedings of the "International Summer Institut on Parallel Architectures, Languages, and Algorithms", Prague, Czech Republic, July 5-10, 1993 (Lecture Notes in Computer Science, Springer-Verlag). 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Backus. </author> <title> Can Programming Be Liberated from the von Neumann Style? A Functional Style and Its Algebra of Programs. </title> <journal> Communications of the ACM, </journal> <volume> 21(8) </volume> <pages> 613-641, </pages> <year> 1978. </year>
Reference-contexts: Another important factor is the complexity and, thus, immense difficulty of programming massively parallel systems. This calls for new programming models and still involves large efforts in theory, language design, and compilation techniques. It is well known, that programming theses systems must be "liberated from the von Neumann style" <ref> [1] </ref>, but there still are no satisfying programming models available.
Reference: [2] <author> R. Bryant, Hung-Yang Chang, and B. Rosenburg. </author> <title> Experience Developing the RP3 Operating System. </title> <journal> Computing Systems, The Journal of USENIX Association, </journal> <volume> 4(3) </volume> <pages> 183-216, </pages> <year> 1991. </year>
Reference-contexts: This understanding was also a dominating issue in operating systems development over the past decade. Multiprocessor operating systems such as Mach [33] emerged. But even with these specifically designed operating systems scalability problems arose when the number of processors significantly increased <ref> [2] </ref>. In many cases these problems were due to an inappropriate kernel structure. In shared memory systems, the granularity of program units that can be executed in parallel is determined by the performance of the process model.
Reference: [3] <author> D. D. Clark. </author> <title> The Structuring of Systems Using Upcalls. </title> <journal> Operating Systems Review, </journal> <volume> 19(5) </volume> <pages> 171-180, </pages> <year> 1985. </year>
Reference-contexts: A communication system emerges that exhibits three problem-oriented protocol layers (Figure 4). 16 Interactions between the layers happen via downcalls and upcalls <ref> [3] </ref>. Queues are used where possible to decouple the different flows of control. Calls in either direction are virtually asynchronous, since it depends on the actual load and on the nucleus configuration of whether message transfer requests must be queued or can be immediately carried out.
Reference: [4] <author> J. Cordsen and W. Schroder-Preikschat. </author> <title> Object-Oriented Operating System Design and the Revival of Program Families. </title> <booktitle> In Proceedings of the Second International Workshop on Object Orientation in Operating Systems (I-WOOOS '91), </booktitle> <pages> pages 24-28, </pages> <address> Palo Alto, CA, </address> <month> October 17-18, </month> <year> 1991. </year> <note> IEEE 91TH392-1. </note>
Reference-contexts: New system features are added to a given subset of system functions. Because of the 3 The term "minimal basis" is used as synonym too. 6 strong analogy between the notions "program family" and "object orientation", it is almost natural to construct program families by using an object-oriented framework <ref> [4] </ref>. Both approaches are in a certain sense dual to each other. The minimal subset of system functions in the program family concept has its counterpart in the superclass of the object-oriented approach. Minimal system extensions then are introduced by means of subclassing.
Reference: [5] <institution> Thinking Machines Corp. </institution> <note> The Connection Machine CM-5 Technical Summary. System Referance Manual, </note> <month> October </month> <year> 1991. </year>
Reference-contexts: In particular, for performance reasons, this view can (and should) be implemented without relying on paging but on compiler and runtime system support. 3 its 128 nodes is controlled by NX/2, a parallel operating system providing virtual shared memory [20]. The operating system for the CM-5 <ref> [5] </ref>, called CMost, is a SunOS variant. This variant, however, is only executed on the control processors. Processing nodes are run by a runtime executive and, normally, will be subjected to single-tasking mode of operation. Nevertheless, there is also support for multi-tasking. <p> It depends on the network architecture whether both parts will accumulate to the same delay. Note that the network may be tuned to specifically support the transfer of small and fixed size packets <ref> [5] </ref>. Node latency is the sum of sender latency and receiver latency. The former is due to the header and trailer setup procedure, referred to as header latency and trailer latency, respectively.
Reference: [6] <author> H. Custer. </author> <title> Inside WINDOWS-NT. </title> <publisher> Microsoft Press, </publisher> <address> ISBN 1-55615-481-X, </address> <year> 1993. </year>
Reference-contexts: Conclusions are presented in Section 5. 1 2 Parallel Operating Systems Almost any new (commercial) operating system that appears at the market is based on the microkernel architecture [10]. The most recent example of this fact is Windows-NT T M <ref> [6] </ref>. At first sight, this seems to suggest exploiting a microkernel as the common platform on top of which the parallel operating system should be built.
Reference: [7] <author> R. S. Fabry. </author> <title> Capability-Based Addressing. </title> <journal> Communications of the ACM, </journal> <volume> 17(7) </volume> <pages> 403-412, </pages> <month> July </month> <year> 1974. </year>
Reference-contexts: This is the purpose of the minimal extension to kernel isolation, namely network integrity. In order to model and enforce protection domains, a capability-based approach <ref> [7] </ref> is used. This approach grants object access only if a thread (i.e., subject) is in the possession of that object or one of its proxies. An object must be created and bound to a system-wide unique identifier before it can be used.
Reference: [8] <institution> Feasibility Study Committee of the Real-World Computing Program. The Master Plan for the Real-World Computing Program, </institution> <month> March 2, </month> <year> 1992. </year> <note> Draft. 30 </note>
Reference-contexts: In the nineties, it will be even more important in the realm of massively parallel systems. Massively parallel systems consist of hundreds or thousands of processing nodes. Recent studies <ref> [8] </ref> already present the vision of millions of cooperating nodes. The preferred paradigm to construct parallel machines of that scale relies on distributed memory. At the hardware level, the view of a common global memory is sacrificed.
Reference: [9] <author> D. Ferrari. </author> <title> Real-Time Communication in an Internetwork. </title> <type> Technical Report TR-92--001, </type> <institution> International Computer Science Institute, Berkeley, </institution> <address> CA, </address> <year> 1992. </year>
Reference-contexts: This calls for real-time capabilities of all nucleus instances involved in network-wide high-volume data transfer. In particular, it requires N C 2 to implement a (scaled-down) real-time communication protocol <ref> [9] </ref>. In addition to that, the network hardware must provide guarantees for the allocation of packet transfer slots. There must be a fixed and known (worst-case) delay from which the occurrence of the remote communication interrupt due to a transmitted header packet can be deduced.
Reference: [10] <author> M. Gien. </author> <title> Micro-kernel Architecture Key to Modern Operating System Design. </title> <type> Technical Report CS/TR-90-42.1, </type> <institution> Chorus systemes, Paris, </institution> <year> 1990. </year>
Reference-contexts: Following that, Section 4 explains various system configurations emerging from problem-oriented arrangements of the Peace building blocks. Conclusions are presented in Section 5. 1 2 Parallel Operating Systems Almost any new (commercial) operating system that appears at the market is based on the microkernel architecture <ref> [10] </ref>. The most recent example of this fact is Windows-NT T M [6]. At first sight, this seems to suggest exploiting a microkernel as the common platform on top of which the parallel operating system should be built.
Reference: [11] <author> W. K. </author> <title> Giloi. </title> <booktitle> The SUPRENUM Architecture. In Proceedings of CONPAR 88, </booktitle> <pages> pages 10-17, </pages> <address> Manchester, UK, September 12-16, 1988. </address> <publisher> Cambridge University Press. </publisher>
Reference-contexts: The Peace system is running as Unix guest level on a cluster of workstations and as native operating system on a 16 node (32 processor, i860) Manna system [12], 64 node (T800) Transputer system, and 320 node (mc68020) Suprenum system <ref> [11] </ref>. It provides a common, object-oriented and scalable "software backplane" for parallel computing [17]. Acknowledgement I would like to thank Joachim Beer for his helpful comments on the manuscript of this report.
Reference: [12] <author> W. K. Giloi and U. Bruning. </author> <booktitle> Architectural Trends in Parallel Supercomputers. In Proceedings of the Second NEC International Symposium on Systems and Computer Architectures, </booktitle> <address> Tokyo, </address> <month> August </month> <year> 1991. </year> <institution> Nippon Electric Corp. </institution> <note> appears as book. </note>
Reference-contexts: Peace was used as a case study system to exemplify the design concepts. The Peace system is running as Unix guest level on a cluster of workstations and as native operating system on a 16 node (32 processor, i860) Manna system <ref> [12] </ref>, 64 node (T800) Transputer system, and 320 node (mc68020) Suprenum system [11]. It provides a common, object-oriented and scalable "software backplane" for parallel computing [17]. Acknowledgement I would like to thank Joachim Beer for his helpful comments on the manuscript of this report.
Reference: [13] <author> A. N. Habermann, L. Flon, and L. Cooprider. </author> <title> Modularization and Hierarchy in a Family of Operating Systems. </title> <journal> Communications of the ACM, </journal> <volume> 19(5) </volume> <pages> 266-272, </pages> <year> 1976. </year>
Reference-contexts: It does not prescribe any particular implementation technique. The minimal subset of system functions defines a platform of fundamental abstractions serving to implement minimal system extensions. These extensions then are made on the basis of an incremental system design <ref> [13] </ref>, with each new level being a new minimal basis, i.e., virtual machine, for additional higher-level system extensions. A true application-oriented system evolves, since extensions are only made on demand, namely when needed to implement a specific system feature that supports a specific application.
Reference: [14] <author> A. J. Herbert and J. Monk. </author> <title> ANSA Reference Manual. Advanced Network Systems Architecture, </title> <address> Cambridge, UK, </address> <year> 1987. </year>
Reference-contexts: While in the past shared memory architectures did play the major role, it is very well accepted now that innovative parallel computers will be tightly-coupled distributed systems. In order to improve programmability and, thus, not only user acceptance but also maintainability and applicability, transparency <ref> [14] </ref> cannot be sacrificed. Transparency, however, can be achieved only at the cost of efficiency. Transparency in the context discussed here means to hide from parallel applications problems coming up with distributed systems. Efficiency means to reduce the message startup time for a given application to an absolute minimum.
Reference: [15] <author> J. Kramer and J. Magee. </author> <title> Dynamic Configuration for Distributed Systems. </title> <journal> Transactions of Software Engineering, </journal> <volume> SE-11(4), </volume> <year> 1985. </year>
Reference-contexts: This is true for both the user application and the parallel operating system. In order to ease configuration, an object model must found the basis of programming. In this sense, massively parallel systems and distributed systems share a very common basis. Approaches stemming from the distributed systems area <ref> [15] </ref> become transferable to the area of massively parallel systems to aid the mapping of at least the operating system. Thus, the least minimum requirement in the development of parallel operating systems is to design a structure that eases configuration.
Reference: [16] <author> H. C. Lauer and R. M. Needham. </author> <title> On the Duality of Operating System Structures. </title> <journal> Operating Systems Review, </journal> <volume> 13(2) </volume> <pages> 3-19, </pages> <month> April </month> <year> 1979. </year> <booktitle> Reprint of Proceedings of the 2nd International Symposium on Operating Systems Structures, IRIA, </booktitle> <month> October, </month> <year> 1978. </year>
Reference-contexts: It merely is a question of how these calling principles are carried out by an actual system representation. The duality of process-oriented and procedure-oriented operating system structures <ref> [16] </ref> makes possible to present a design that can be implemented either way. However, having a process-oriented implementation (by means of active objects) in mind is the right approach in order to prevent possible performance bottlenecks.
Reference: [17] <author> J. Lennon. </author> <title> Give Peace a Chance. The Plastic Ono Band Live Peace in Toronto, Apple Records, </title> <year> 1969. </year>
Reference-contexts: It provides a common, object-oriented and scalable "software backplane" for parallel computing <ref> [17] </ref>. Acknowledgement I would like to thank Joachim Beer for his helpful comments on the manuscript of this report.
Reference: [18] <author> H. M. Levy. </author> <booktitle> Proceedings of the Thirteenth ACM Symposium on Operating Systems Principles, </booktitle> <month> Oct. </month> <pages> 13-16, 91, </pages> <booktitle> Asilomar Conference Center, </booktitle> <address> Pacific Grove, CA, USA. </address> <booktitle> ACM Operating Systems Review, </booktitle> <volume> Vol. 25, No. </volume> <pages> 2, </pages> <note> Special Issue, </note> <year> 1991. </year>
Reference-contexts: These interactions are extremely heavyweight when compared to local program activities. Most recently, approaches have been made aimed at reducing kernel interactions in the course of context switches to an absolute minimum <ref> [18] </ref>. However, completely bypassing the kernel is not feasible. Both, monolithic and microkernel-based operating system architectures have in common that user and kernel space are physically isolated from each other. The separation is necessary in traditional multi-tasking and timesharing systems.
Reference: [19] <author> K. Li. </author> <title> Shared Virtual Memory on Loosely Coupled Multiprocessors. </title> <type> PhD thesis, </type> <institution> Yale University, </institution> <year> 1986. </year>
Reference-contexts: Moreover, an "unlimited" local address space is in contradiction to the Mimd principle, namely to avoid the von Neumann bottleneck to the memory. Note that traditional virtual memory has only little in common with virtual shared memory <ref> [19] </ref>. The latter was not introduced to solve the problem of memory over-allocation, but rather to present a view of a global, common address space that is physically distributed.
Reference: [20] <author> K. Li and R. Schaefer. </author> <title> A Hypercube Shared Virtual Memory System. </title> <booktitle> In Proceedings of the 1989 International Conference on Parallel Processing, </booktitle> <volume> volume 1, </volume> <pages> pages 125-132, </pages> <year> 1989. </year>
Reference-contexts: In particular, for performance reasons, this view can (and should) be implemented without relying on paging but on compiler and runtime system support. 3 its 128 nodes is controlled by NX/2, a parallel operating system providing virtual shared memory <ref> [20] </ref>. The operating system for the CM-5 [5], called CMost, is a SunOS variant. This variant, however, is only executed on the control processors. Processing nodes are run by a runtime executive and, normally, will be subjected to single-tasking mode of operation. Nevertheless, there is also support for multi-tasking.
Reference: [21] <institution> Meiko Ltd., Bristol, UK. CS/Tools Programmer's Manual, </institution> <year> 1990. </year>
Reference-contexts: These platforms, however, cannot always be regarded as operating system but rather runtime environment. They were specifically developed for a certain distributed memory parallel computer, having a certain set of applications in mind. Examples are CS/Tools <ref> [21] </ref>, PARIX [26], and UBIK [30]. Except the former mentioned one, these all are systems developed for Transputer-based architectures. The iPSC/2 hypercube with 1 Virtual memory on the processing nodes is in almost every case sacrificed, not only for technical reasons.
Reference: [22] <author> H. Mierendorff. </author> <title> Bounds on the Startup Time for the Genesis Node. </title> <type> Technical report, </type> <institution> GMD F2.G1, Bonn, Germany, </institution> <year> 1989. </year> <title> ESPRIT Project No. </title> <type> 2447. </type>
Reference-contexts: With the scalar performance of a 40 Mips processor (Risc technology) in mind, communication latency must be below 10 sec. As discussed in <ref> [22] </ref>, only then a balanced ratio between the per-node computing power and network performance is achieved. 2.2.2 System Complexity Programming and management of thousands of interconnected nodes is a non-trivial task| and it does not get better with millions of nodes.
Reference: [23] <author> S. J. Mullender and A. S. Tanenbaum. </author> <title> The Design of a Capability-Based Distributed Operating System. </title> <journal> The Computer Journal, </journal> <volume> 29(4) </volume> <pages> 289-299, </pages> <year> 1986. </year>
Reference-contexts: An object must be created and bound to a system-wide unique identifier before it can be used. It is assumed that a unique identifier cannot be deduced <ref> [23] </ref>. In order to achieve this, the nucleus generates a random number which, combined with a global hash key, is used to make identifiers system-wide unique. Note that this procedure works autonomously and needs not be controlled by a central system component.
Reference: [24] <author> J. Nolte. </author> <title> Language Level Support for Remote Object Invocation. </title> <institution> Arbeitspapiere der GMD 654, Gesellschaft fur Mathematik und Datenverarbeitung, </institution> <address> St. Augustin, Germany, </address> <month> June </month> <year> 1992. </year> <month> 31 </month>
Reference-contexts: Since kernel and nucleus together reside in the same address space, the kernel performs Local Object Invocation (Loi) to request nucleus services. Kernel services are made available via Remote Object Invocation (Roi). The Roi scheme always implies context switching, but not necessarily address space switching <ref> [24] </ref>. A separate thread of control is used to execute the requested method (i.e., service). In contrast to that, Noi logically implies the activation/deactivation of the nucleus address space via local system call traps. <p> By that means, kernel service processing works independently from the processing of the application task. It ensures that remotely requested services are processed latest when the thread scheduler gains control and selects a clerk <ref> [24] </ref> for execution|provided that the application task sharing with the kernel entity the same address space is "well-behaved" 4 . The next nucleus instance does not really introduce additional functionality, but provides the platform for multi-tasking and/or multi-user mode of operations. These operation modes call for isolation and protection measures. <p> The creator implicitly possesses the newly created object and henceforth acts as its owner. It is the autonomous decision of the owner to make the object either globally known, by exporting its unique identifier, or even accessible, by exporting its proxy object <ref> [24] </ref>. Thus, the access domain of an object may be extended only through the owner.
Reference: [25] <author> D. L. Parnas. </author> <title> Designing Software for Ease of Extension and Contraction. </title> <journal> Transaction on Software Engineering, </journal> <volume> SE-5(2), </volume> <year> 1979. </year>
Reference-contexts: A "vicious circle" parallel operating systems are assigned to break up. As a solution to this problem, two major aspects will be discussed in the following investigations. Firstly, the design of a parallel operating system should lead to a program family <ref> [25] </ref> and, secondly, the implementation should follow the paradigm of object orientation [32]. The goal is to try to answer the question of whether distributed (microkernel-based) operating systems are suited for distributed memory parallel computers or specific system software structures are required. <p> Code reuse is significantly enhanced, increasing the commonalities of different family members: "We consider a set of programs to be a program family if they have so much in common that it pays to study their common aspects before looking at the aspects that differentiate them" <ref> [25] </ref>. For the development of parallel operating systems it is sensible to chose, above all, the program family concept as fundamental design principle. Object orientation should primarily be used as implementation and not as design instrument.
Reference: [26] <institution> Parsytec Computer GmbH, Aachen, Germany. </institution> <note> PARIX Programmer's Manual, </note> <year> 1991. </year>
Reference-contexts: These platforms, however, cannot always be regarded as operating system but rather runtime environment. They were specifically developed for a certain distributed memory parallel computer, having a certain set of applications in mind. Examples are CS/Tools [21], PARIX <ref> [26] </ref>, and UBIK [30]. Except the former mentioned one, these all are systems developed for Transputer-based architectures. The iPSC/2 hypercube with 1 Virtual memory on the processing nodes is in almost every case sacrificed, not only for technical reasons.
Reference: [27] <author> J. L. Peterson and A. Silberschatz. </author> <title> Operating System Concepts. </title> <publisher> Addison-Wesley Publishing Company, </publisher> <address> ISBN 0-201-06079-5, </address> <note> second edition, </note> <year> 1985. </year>
Reference-contexts: Each of them implement the purest form of a unit of execution, without consideration of any protection and security measures. Thread preemption is the minimal extension to network communication. This means thread scheduling on a timer basis, actually introducing a second scheduling level. This level implements Cpu protection <ref> [27] </ref>, since a single thread (or task) is no longer able to seize the processor. The additional level knows the bundle as scheduling unit. A bundle consists of one or more threads, with non-preemptive scheduling of threads of the same bundle. Preemptive scheduling only happens between bundles.
Reference: [28] <author> W. Schroder-Preikschat. </author> <title> Overcoming the Startup Time Problem in Distributed Memory Architectures. </title> <editor> In Veljko Milutiniovic and Bruce D. Shriver, editors, </editor> <booktitle> Architecture and Emerging Technologies Tracks, volume 1 of Proceedings of the Twenty-Fourth Annual Hawaii International Conference on System Sciences, </booktitle> <pages> pages 551-559, </pages> <address> Kauai, Hawaii, </address> <month> January 8-11, </month> <title> 1991. </title> <publisher> IEEE Society Press, IEEE 91TH0350-9. </publisher>
Reference-contexts: In particular, this also holds for microkernel-based systems. However, all the microkernels presently available at the market fail to efficiently support the above mentioned type of parallel application <ref> [28] </ref>. The main problem is the artificial boundary between user and kernel. This boundary is due to the microkernel approach and not necessarily demanded by the parallel application. <p> The loss of "number crunching" power caused thereby is not only due to the communication protocol overhead but also a question of the actual operating mode of the node <ref> [28] </ref>. A single-tasking mode of operation, e.g., does not imply any form of address space isolation. <p> Experiences show that this overhead takes up to 74 % of the message startup time when executing a user-level send-receive-reply sequence <ref> [28] </ref>. Note, a 12 state of the art microkernel however supports only multi-tasking and, thus, unnecessarily drains computing power from a single-tasking application. The minimal subset of system functions is represented by a kernel family that implements four different operation modes (Figure 3).
Reference: [29] <author> W. Schroder-Preikschat. </author> <title> P E ACE|The Logical Design of Parallel Operating Systems. </title> <note> 1993. In preparation. </note>
Reference-contexts: The outline of the paper is as follows. Section 2 briefly discusses the characteristics of parallel operating systems. In Section 3 the functional decomposition made in design process of the Peace <ref> [29] </ref> parallel operating system is considered. Peace will serve as a case study system. Following that, Section 4 explains various system configurations emerging from problem-oriented arrangements of the Peace building blocks.
Reference: [30] <institution> Telmat, France. UBIK Programmer's Manual, </institution> <year> 1990. </year>
Reference-contexts: These platforms, however, cannot always be regarded as operating system but rather runtime environment. They were specifically developed for a certain distributed memory parallel computer, having a certain set of applications in mind. Examples are CS/Tools [21], PARIX [26], and UBIK <ref> [30] </ref>. Except the former mentioned one, these all are systems developed for Transputer-based architectures. The iPSC/2 hypercube with 1 Virtual memory on the processing nodes is in almost every case sacrificed, not only for technical reasons.
Reference: [31] <author> T. von Eicken, D. E. Culler, S. C. Goldstein, and K. E. Schauser. </author> <title> Active Messages: a Mechanism for Integrated Communication and Computation. </title> <type> Technical Report UCB/CSD 92/675, </type> <institution> University of California, Berkeley, </institution> <address> CA, </address> <year> 1992. </year>
Reference-contexts: A message object that is going to be transmitted by means of Club encodes the upcall handler (i.e., method) to be used for the delivery of that object to the peer Cosy entity|a Club message is some sort of "Active Message" <ref> [31] </ref>. 3.7 Communication Latency The most crucial aspect of Mimd systems is the message passing performance, in particular the message startup time. As was mentioned earlier, the message startup time depends on the communication latency of a network-wide message transaction.
Reference: [32] <author> P. Wegner. </author> <title> Classification in Object-Oriented Systems. </title> <journal> SIGPLAN Notices, </journal> <volume> 21(10) </volume> <pages> 173-182, </pages> <year> 1986. </year>
Reference-contexts: As a solution to this problem, two major aspects will be discussed in the following investigations. Firstly, the design of a parallel operating system should lead to a program family [25] and, secondly, the implementation should follow the paradigm of object orientation <ref> [32] </ref>. The goal is to try to answer the question of whether distributed (microkernel-based) operating systems are suited for distributed memory parallel computers or specific system software structures are required.
Reference: [33] <author> M. Young, A. Tevanian, R. Rashid, D. Golub, J. Eppinger, J. Chew, W. Bolosky, D. Black, and R. Baron. </author> <title> The Duality of Memory and Communication in the Implementation of a Multiprocessor Operating System. </title> <booktitle> In Proceedings of the Eleventh ACM Symposium on Operating System Principles, volume 21 of Operating Systems Review, </booktitle> <pages> pages 63-76, </pages> <address> Austin, Texas, CA, 1987. </address> <publisher> ACM. </publisher>
Reference-contexts: This understanding was also a dominating issue in operating systems development over the past decade. Multiprocessor operating systems such as Mach <ref> [33] </ref> emerged. But even with these specifically designed operating systems scalability problems arose when the number of processors significantly increased [2]. In many cases these problems were due to an inappropriate kernel structure.
Reference: [34] <author> R. Zajcew, Paul Roy, David Black, Chris Peak, Paulo Guedes, Bradford Kemp, John LoVerso, Michael Leibensperger, Michael Barnett, Faramarz Rabii, and Durriya Net-terwala. </author> <title> An OSF/1 UNIX for Massively Parallel Multicomputers. </title> <booktitle> In Proceedings of the USENIX Winter Technical Conference, </booktitle> <pages> pages 449-468, </pages> <address> San Diego, CA, USA, </address> <month> January 25-29, </month> <year> 1993. </year>
Reference-contexts: At first sight, this seems to suggest exploiting a microkernel as the common platform on top of which the parallel operating system should be built. It is quite feasible to even port microkernel-based Unix T M systems onto distributed memory parallel computers <ref> [34] </ref>, with every node executing the microkernel, a subset of system servers, and at least one application task. But the question comes up whether this really is the right approach.
References-found: 34

