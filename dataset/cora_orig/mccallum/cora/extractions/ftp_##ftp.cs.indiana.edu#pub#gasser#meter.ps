URL: ftp://ftp.cs.indiana.edu/pub/gasser/meter.ps
Refering-URL: http://www.cs.indiana.edu/ai/Gasser/Rhythm/home.html
Root-URL: http://www.cs.indiana.edu
Title: Meter as Mechanism: A Neural Network that Learns Metrical Patterns  
Author: Michael Gasser, Douglas Eck and Robert Port 
Keyword: Meter in Music and Speech  
Affiliation: Cognitive Science Program Indiana University  
Abstract: One kind of prosodic structure that apparently underlies both music and some examples of speech production is meter. Yet detailed measurements of the timing of both music and speech show that the nested periodicities that define metrical structure can be quite noisy in time. What kind of system could produce or perceive such variable metrical timing patterns? And what would it take to be able to store and reproduce particular metrical patterns from long-term memory? We have developed a network of coupled oscillators that both produces and perceives patterns of pulses that conform to particular meters. In addition, beginning with an initial state with no biases, it can learn to prefer the particular meter that it has been previously exposed to. Meter is an abstract structure in time based on the periodic recurrence of pulses, that is, on equal time intervals between distinct phase zeros. From this point of view, the simplest meter is a regular metronome pulse. But often there appear meters with two or three (or rarely even more) nested periodicities with integral frequency ratios. A hierarchy of such metrical structures is implied in standard Western musical notation, where different levels of the metrical hierarchy are indicated by kinds of notes (quarter notes, half notes, etc.) and by the bars separating measures with an equal number of beats. For example, in a basic waltz-time meter, there are individual beats, all with the same spacing, grouped into sets of three, with every third one receiving a stronger accent at its onset. In this meter there is a hierarchy consisting of both a faster periodic cycle (at the beat level) and a slower one (at the measure level) that is 1/3 as fast, with its onset (or zero phase angle) coinciding with the zero phase angle of every third beat. This essentially temporal view of meter contrasts with the traditional symbol-string theories (such as Hayes, 1981 for speech and Lerdahl and Jackendoff, 1983 for music). Metrical systems, however they are defined, seem to underlie most of what we call music. Indeed, an expanded version of European musical notation is found to be practical for transcribing most music from around the world. That is, most forms of music employ nested periodic temporal patterns (Titon, Fujie, & Locke, 1996). Musical notation has 
Abstract-found: 1
Intro-found: 1
Reference: <author> Abraham, R., & Shaw, C. </author> <year> (1983). </year> <title> Dynamics, </title> <booktitle> the geometry of behavior, part 1. </booktitle> <address> Santa Cruz, California: </address> <publisher> Aerial Press. </publisher>
Reference: <author> Amit, D. J. </author> <year> (1989). </year> <title> Modeling brain function: The world of attractor neural networks. </title> <publisher> Cambridge: Cambridge University Press. </publisher>
Reference-contexts: Thus it belongs to the family of attractor neural networks first studied by Hopfield (1982). While such networks grossly oversimplify real neural networks, for example, in their requirement that all weights be symmetric, they appear to be good candidates for investigating some of the abstract global properties of brains <ref> (Amit, 1989) </ref>. A SONOR network is designed to respond to input sequences of pulses when it is in perception mode and to produce output sequences of pulses when it is in production mode. The network has a single input-output (IO) unit representing its simple interface to the world.
Reference: <author> Baldi, P., & Meir, R. </author> <year> (1990). </year> <title> Computing with arrays of coupled oscillators: An application to preattentive texture discrimination. </title> <journal> Neural Computation, </journal> <volume> 2, </volume> <pages> 458-471. </pages>
Reference-contexts: In our simulations thus far we do not, however, incorporate the property of frequency adaptation. There is also a significant body of work on the properties of networks of coupled oscillators, which have been used to model both rhythmic behavior and feature binding <ref> (see Baldi & Meir, 1990) </ref>. Two types of systems have been studied. One type consists of oscillators similar to (but generally simpler than) the adaptive oscillators studied by Large & Kolen (1994) and McAuley (1995).
Reference: <author> Campbell, S. R., & Wang, D. </author> <year> (1996). </year> <title> Synchronization and desynchronization in a network of locally coupled wilson-cowan oscillators. </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> 7, </volume> <pages> 541-554. </pages>
Reference: <author> Cummins, F., & Port, R. F. </author> <year> (1998). </year> <title> Rhythmic constraints on stress timing in English. </title> <journal> Journal of Phonetics, </journal> <volume> 26, </volume> <pages> 145-171. </pages>
Reference-contexts: 1. Underlying the temporal patterns that make up music and speech are sequences of discrete pulses or beats. 2 Thus not all points in time are equally important; it is usually only the phase zeros whose locations matter. <ref> (See Cummins & Port, 1998 and Tajima, 1998 for further discussion.) </ref> Furthermore, the phase zeros are normally aligned with energy onsets, for speech, especially vowel onsets. 2.
Reference: <author> Dauer, R. </author> <year> (1983). </year> <journal> Stress-timing and syllable-timing reanalyzed. Journal of Phonetics, </journal> <volume> 11, </volume> <month> 51-62. </month> <title> METER AS MECHANISM 30 training, the IO unit is driven by an input pattern with duple meter, then allowed to vary. The output of the IO unit at this point is shown. </title>
Reference: <author> Delgutte, B. </author> <year> (1982). </year> <title> Some correlates of phonetic distinctions at the level of the auditory nerve. </title>
Reference: <editor> In R. Carlson & B. Granstrom (Eds.), </editor> <booktitle> The representation of speech in the peripheral auditory system (pp. </booktitle> <pages> 131-149). </pages> <publisher> Elsevier Biomedical Press. </publisher>
Reference: <author> FitzHugh, R. </author> <year> (1961). </year> <title> Impulses and physiological states in models of nerve membrane. </title> <journal> Biophysical Journal, </journal> <volume> 1, </volume> <pages> 445-466. </pages>
Reference: <author> Gasser, M., & Eck, D. </author> <year> (1996). </year> <title> Representing rhythmic patterns in a network of oscillators. </title> <booktitle> In Proceedings of the 4th International Conference on Music Perception and Cognition (pp. </booktitle> <pages> 361-366). </pages>
Reference-contexts: Others have to do with learning. We need to establish that the model is capable of acquiring more complex rhythms, for example, meters with three levels, patterns with alternating meters, or periodic patterns containing rests <ref> (Gasser & Eck, 1996) </ref>. We also need a principled way of &lt;determining when the network has "settled" in its response to a periodic pattern.
Reference: <author> Handel, S. </author> <year> (1989). </year> <title> Listening: An introduction to the perception of auditory events. </title> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference-contexts: Initially we will try metrically constrained speech such as verse, chants, or "over-rehearsed" speech, such as group prayers. 8 Note that in real biological systems, the tendency to prefer particular frequencies may also depend on built-in preferences of one sort or another <ref> (Handel, 1989) </ref>. METER AS MECHANISM 28 initial weights of 1.0 on connections to and from the IO unit and 0.0 elsewhere. The IO unit is driven by a duple input pattern, then allowed to vary freely. The output of the unit at this point is shown.
Reference: <author> Hinton, G., & Sejnowski, T. </author> <year> (1986). </year> <title> Learning and unlearning in Boltzmann machines. </title> <editor> In D. Rumel-hart & J. McClelland (Eds.), </editor> <booktitle> Parallel distributed processing, </booktitle> <volume> volume 1 (p. </volume> <pages> 282-317). </pages> <address> Cambridge, MA: </address> <publisher> The MIT Press. </publisher>
Reference-contexts: SONOR Connectivity With respect to the overall architecture, a SONOR network belongs to the family of settling networks, including Hopfield networks (Hopfield, 1982) and Boltzmann machines <ref> (Hinton & Sejnowski, 1986) </ref>, in which all processing units are joined by symmetrically weighted connections. Oscillators may be connected to other units in one of two ways. A "simple" connection implements a relationship much like that in conventional settling networks.
Reference: <author> Hopfield, J. J. </author> <year> (1982). </year> <title> Neural networks and physical systems with emergent collective computational abilities. </title> <booktitle> Proceedings of the National Academy of Sciences, </booktitle> <volume> 79, </volume> <pages> 2554-2558. </pages>
Reference-contexts: The minimum and resting activations are negative so that oscillators which are not aligned with the pulse of the IO unit are inhibited by it. SONOR Connectivity With respect to the overall architecture, a SONOR network belongs to the family of settling networks, including Hopfield networks <ref> (Hopfield, 1982) </ref> and Boltzmann machines (Hinton & Sejnowski, 1986), in which all processing units are joined by symmetrically weighted connections. Oscillators may be connected to other units in one of two ways. A "simple" connection implements a relationship much like that in conventional settling networks.
Reference: <author> Jones, D. </author> <year> (1932). </year> <title> An outline of English phonetics (3rd ed.). </title> <institution> Cambridge University Press. </institution> <note> (1st edition published 1918) Jones, </note> <author> M. R., & Boltz, M. </author> <year> (1989). </year> <title> Dynamic attending and responses to time. </title> <journal> Psychological Review, </journal> <volume> 96, </volume> <month> 459-491. </month> <title> METER AS MECHANISM 31 training, the IO unit is driven by an input pattern with triple meter, then allowed to vary. The output of the IO unit at this point is shown. </title>
Reference: <author> Kelso, J. A. S. </author> <year> (1995). </year> <title> Dynamic patterns: The self-organization of brain and behavior. </title> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference-contexts: The perception and the production of any real temporal patterns are governed by a single underlying system <ref> (Kelso, 1995) </ref>. This system consists of many coupled oscillators that may involve multiple internal oscillators plus various cyclic external visual or auditory events.
Reference: <author> Large, E., & Jones, M. </author> <title> (in press). The dynamics of attending: How we track events. </title> <journal> Psychological Review. </journal>
Reference: <author> Large, E. W., & Kolen, J. F. </author> <year> (1994). </year> <title> Resonance and the perception of musical meter. </title> <journal> Connection Science, </journal> <volume> 6, </volume> <pages> 177-208. </pages>
Reference-contexts: They are relatively robust to temporal noise in the input. 2. Single oscillators model the performance of subjects in tempo discrimination tasks (McAuley, 1995; McAuley & Kidd, in press). 3. Banks of adaptive oscillators with different preferred frequencies can discover metrical structure in music <ref> (Large & Kolen, 1994) </ref>. What the adaptive oscillator models lack is a mechanism for learning specific rhythmic patterns from the world. In SONOR we build on the adaptive oscillator models by combining oscillators in a network in which the connections between the oscillators are trainable. <p> In most ways the oscillators in SONOR resemble the oscillatory units in two other recent models of rhythm processing, those of McAuley (McAuley, 1995) and Large and Kolen <ref> (Large & Kolen, 1994) </ref>.
Reference: <author> Lehiste, I. </author> <year> (1977). </year> <title> Isochrony reconsidered. </title> <journal> Journal of Phonetics, </journal> <volume> 5, </volume> <pages> 253-263. </pages>
Reference: <author> Lerdahl, F., & Jackendoff, R. </author> <year> (1983). </year> <title> A generative theory of tonal music. </title> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference: <author> Martin, J. G. </author> <year> (1972). </year> <title> Rhythmic (hierarchical) versus serial structure in speech and other behavior. </title> <journal> Psychological Review, </journal> <volume> 79 (6), </volume> <pages> 487-509. </pages>
Reference: <author> McAuley, J. D. </author> <year> (1995). </year> <title> On the perception of time as phase: Toward an adaptive-oscillator model of rhythm. </title> <type> Unpublished doctoral dissertation, </type> <institution> Indiana University, Bloomington, </institution> <note> IN. </note>
Reference-contexts: We first consider the behavior of a single oscillator responding to other units in the network (either the IO unit or other oscillators). In most ways the oscillators in SONOR resemble the oscillatory units in two other recent models of rhythm processing, those of McAuley <ref> (McAuley, 1995) </ref> and Large and Kolen (Large & Kolen, 1994).
Reference: <author> McAuley, J. D., & Kidd, G. </author> <title> (in press). Effect of deviations from temporal expectations on tempo discrimination of isochronous tone sequences. </title> <journal> Journal of Experimental Psychology: Human Perception and Performance. </journal>
Reference: <author> McClelland, J., & Rumelhart, D. </author> <year> (1981). </year> <title> An interactive activation model of context effects in letter perception: Part 1. An account of basic findings. </title> <journal> Psychological Review, </journal> <volume> 88, </volume> <pages> 375-107. </pages> <note> METER AS MECHANISM 32 Miller, </note> <author> B. O., Scarborough, D. L., & Jones, J. A. </author> <year> (1992). </year> <title> On the perception of meter. </title> <editor> In M. Balaban, K. Ebcioglu, & O. Laske (Eds.), </editor> <title> Understanding music with ai: </title> <journal> Perspectives on music cognition (pp. </journal> <pages> 429-447). </pages> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference-contexts: In SONOR, matching the current input means synchronizing with the pulses which are output by the other units in the network. The activation function for oscillators is a slightly modified version of the familiar activation update rule of the Interactive Activation and Competition model <ref> (McClelland & Rumelhart, 1981) </ref>. In this rule, activation is adjusted at each update as a function of the input to the unit and of decay back to the unit's preferred frequency.
Reference: <author> Movellan, J. </author> <year> (1990). </year> <title> Contrastive Hebbian learning in the continuous Hopfield model. </title> <editor> In D. Touretzky, J. Elman, T. Sejnowski, & G. Hinton (Eds.), </editor> <booktitle> Proceedings of the 1990 Connectionist Models Summer School (pp. </booktitle> <pages> 10-17). </pages> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: The network has successfully auto-associated the pattern if the sequence of activations in the network, including the IO unit itself, does not change significantly when the IO unit is unclamped. Learning in SONOR is based on the Contrastive Hebbian Learning (CHL) algorithm <ref> (Movellan, 1990) </ref>, a learning algorithm for symmetric settling networks with continuous activation functions. CHL is designed for supervised learning: for each input pattern, the system is also provided with an associated target pattern. As we will see, however, it is straightforward to implement auto-association with CHL. <p> As in the standard CHL algorithm, the weights are not actually updated until the values are accumulated for both the positive and negative phases. The changes are proportional to the sum of these two values for each weight. As in standard Contrastive Hebbian Learning <ref> (Movellan, 1990) </ref>, the weight changes are W i;j = L (W + i;j ); (9) where L is a learning rate constant and W + i;j and W i;j are the weight change values accumulated during the positive and negative phases.
Reference: <author> Nagumo, J., Arimoto, S., & Yoshizawa, S. </author> <year> (1962). </year> <title> An active pulse transmission line simulating nerve axon. </title> <booktitle> Proceedings Institute of Radio Engineers, </booktitle> <volume> 50, </volume> <pages> 2061-2070. </pages>
Reference: <author> Port, R., Cummins, F., & Gasser, M. </author> <year> (1996). </year> <title> A dynamic approach to rhythm in language: Toward a temporal phonology. </title> <editor> In B. Luka & B. Need (Eds.), </editor> <booktitle> Proceedings of the chicago linguistics society (pp. </booktitle> <pages> 375-397). </pages> <institution> Department of Linguistics, University of Chicago. </institution>
Reference: <author> Port, R., Dalby, J., & O'Dell, M. </author> <year> (1987). </year> <title> Evidence for mora timing in japanese. </title> <journal> Journal of the Acoustical Society of America, </journal> <volume> 81, </volume> <pages> 1574-1585. </pages>
Reference: <author> Port, R. F. </author> <year> (1998). </year> <title> The dynamical approach to cognition: Inferences from language. (Available on the World Wide Web at http://www./cs.indiana.edu/~port/pap/brazil/text.html) Scott, </title> <editor> S. K. </editor> <year> (1993). </year> <title> P-centers in speech: An acoustic analysis. </title> <type> Unpublished doctoral dissertation, </type> <institution> University College London. </institution>
Reference-contexts: 1. Underlying the temporal patterns that make up music and speech are sequences of discrete pulses or beats. 2 Thus not all points in time are equally important; it is usually only the phase zeros whose locations matter. <ref> (See Cummins & Port, 1998 and Tajima, 1998 for further discussion.) </ref> Furthermore, the phase zeros are normally aligned with energy onsets, for speech, especially vowel onsets. 2.
Reference: <author> Somers, D., & Kopell, N. </author> <year> (1993). </year> <title> Rapid synchronization through fast threshold modulation. </title> <journal> Biological Cybernetics, </journal> <volume> 68, </volume> <pages> 393-407. </pages>
Reference: <author> Strogatz, S. H. </author> <year> (1994). </year> <title> Nonlinear dynamics and chaos. </title> <address> Reading, MA: </address> <publisher> Addison-Wesley. </publisher>
Reference: <author> Tajima, K. </author> <year> (1998). </year> <title> Speech rhythm in English and Japanese: Experiments in speech cycling. </title> <type> Unpublished doctoral dissertation, </type> <institution> Indiana University, Bloomington, </institution> <note> IN. </note>
Reference-contexts: 1. Underlying the temporal patterns that make up music and speech are sequences of discrete pulses or beats. 2 Thus not all points in time are equally important; it is usually only the phase zeros whose locations matter. <ref> (See Cummins & Port, 1998 and Tajima, 1998 for further discussion.) </ref> Furthermore, the phase zeros are normally aligned with energy onsets, for speech, especially vowel onsets. 2. <p> Sensitivity to Particular Period Ranges If there is a degree of periodicity in language, it probably occurs at different mean frequencies in different languages. For example, in Japanese, the mora and the bimora (with periods of roughly 230 and 460 ms) are the best candidates <ref> (Tajima, 1998) </ref> while in English, the foot or phrase (with periods of at least 500 ms) is a more likely level for periodicity. It also seems possible that nested metrical patterns, that is, those with more than one level, may be more or less dominated by the higher (slower) level.
Reference: <author> Tajima, K., & Port, R. F. </author> <year> (1999). </year> <title> Speech rhythm in english and japanese. </title> <editor> In J. Local (Ed.), </editor> <booktitle> Papers in laboratory phonology VI. </booktitle> <address> Cambridge: </address> <publisher> Cambridge University Press. </publisher>
Reference: <editor> Titon, J., Fujie, L., & Locke, D. (Eds.). </editor> <year> (1996). </year> <title> Worlds of music: An introduction to the music of the world's peoples. </title> <address> New York, NY: </address> <publisher> Macmillan. </publisher>
Reference: <author> Todd, N. </author> <year> (1985). </year> <title> A model of expressive timing in tonal music. </title> <journal> Music Perception, </journal> <volume> 3, </volume> <pages> 33-58. </pages> <editor> van Gelder, T., & Port, R. </editor> <year> (1995). </year> <title> It's about time: Overview of the dynamical approach to cognition. </title>
Reference: <editor> In R. Port & T. van Gelder (Eds.), </editor> <title> Mind as motion: </title> <journal> Explorations in the dynamics of cognition (pp. </journal> <pages> 1-43). </pages> <publisher> Bradford Books/MIT Press. </publisher> <editor> van Santen, J. </editor> <year> (1996). </year> <title> Segmental duration and speech timing. </title> <editor> In Y. Sagisaka, W. N. Campbell, & N. Higuchi (Eds.), </editor> <booktitle> Computing prosody. </booktitle> <address> New York: </address> <publisher> Springer Verlag. </publisher>
References-found: 35

