URL: ftp://ftp.cs.uu.nl/pub/RUU/CS/techreps/CS-1998/1998-17.ps.gz
Refering-URL: http://www.cs.ruu.nl/docs/research/publication/TechList1.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: Email: gerard@cs.uu.nl  
Title: Distributed Control for AI  
Author: Gerard Tel 
Date: July 1998  
Address: P.O. Box 80.089, 3508 TB Utrecht, The Netherlands  
Affiliation: Dept of Computer Science, Utrecht University  
Abstract: This paper discusses a number of elementary problems in distributed computing and a couple of well-known algorithmic "building blocks", which are used as procedures in distributed applications. We shall not strive for completeness, as an enumeration of the many known distributed algorithms would be pointless and endless. We do not even try to touch all relevant sub-areas and problems studied in distributed computing, because they are not all relevant to Distributed AI. Rather than an algorithm catalogue, the paper aims to be an eye-opener for the possibilities of the distributed computing model, an introduction to designing and reasoning about the algorithms, and a pointer to some literature. The paper introduces the distributed model and illustrates the various possibilities and difficulties with algorithms to compute spanning trees in a network. We show how the communication and time complexities of the algorithms are evaluated. Then a more complicated, but relevant control problem is studied, namely termination detection. This study reveals how intricate it is to make information about a distributed global state available to a node locally. Termination detection occurs in distributed applications of all areas and is not specific for Distributed AI. Application of some distributed control techniques is exemplified in the later sections in distributed computations for Artificial Intelligence problems. We discuss a distributed implementation of Arc Consistency and Constraint Satisfaction and observe how termination detection and distributed evaluation of functions play a role. The paper finally presents a distributed graph algorithm, illustrating another termination detection princi ple, and providing an example of broadcast/convergecast and controller movement.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Yehuda Afek and Moty Ricklin. Sparser: </author> <title> A paradigm for running distributed algorithms. </title> <editor> In Adrian Segall and Shmuel Zaks, editors, </editor> <booktitle> 6th Int. Workshop on Distributed Algorithms, volume 647 of Lecture Notes in Computer Science, </booktitle> <pages> pages 1-10, </pages> <address> Haifa, November 1992. </address> <publisher> Springer Verlag. </publisher>
Reference-contexts: In addition the distributed solution contains communication actions for the exchange of intermediate results and coordination; our goal is to minimise communication and computation cost. Afek and Ricklin <ref> [1] </ref> observe cost benefits of an intermediate strategy where computation is concentrated in several computing centres.
Reference: [2] <author> Baruch Awerbuch. </author> <title> A new distributed depth-first search algorithm. </title> <journal> Information Processing Letters, </journal> <volume> 20 </volume> <pages> 147-150, </pages> <year> 1985. </year>
Reference-contexts: These calls do not construct edges of the dfs tree; so if node u could be aware of its neighbour v being visited already, the call to v could be skipped without affecting the outcome, and the time complexity would be reduced significantly. This is exploited in Awerbuch's algorithm <ref> [2] </ref>; each node informs its neighbors when it is visited for the first time, before forwarding any recursive calls. Of course we still communicate through each edge, but informing the neighbors can be parallelised and we save on time.
Reference: [3] <author> Baruch Awerbuch. </author> <title> Optimal distributed algorithms for minimum weight spanning tree, counting, leader election and related problems. </title> <booktitle> In Symp. on Theory of Computing, </booktitle> <pages> pages 230-240, </pages> <month> May </month> <year> 1987. </year>
Reference-contexts: The message complexity of the fast solution is large (unknown though), while message optimal solutions (exchanging O (n log n + m) messages) exist with linear time complexity <ref> [3, 10] </ref>. We shall discuss a distributed depth-first search algorithm whose time is proportional to the depth of the DFS tree, while again message complexity rises sky-high.
Reference: [4] <author> Baruch Awerbuch and David Peleg. </author> <title> Routing with polynomial communication-space trade-off. </title> <journal> SIAM J. Discr. Math., </journal> <volume> 5(2) </volume> <pages> 151-162, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: In addition the distributed solution contains communication actions for the exchange of intermediate results and coordination; our goal is to minimise communication and computation cost. Afek and Ricklin [1] observe cost benefits of an intermediate strategy where computation is concentrated in several computing centres. Awerbuch and Peleg <ref> [4] </ref> reach similar conclusions, but a discussion of such solutions, though we would still consider them as distributed, is not possible in this chapter. 1.1 Model of Computation The distributed model is characterised by a collection of autonomous processing elements, called nodes.
Reference: [5] <author> K. Mani Chandy and Leslie Lamport. </author> <title> Distributed snapshots: Determining global states of distributed systems. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 3(1) </volume> <pages> 63-75, </pages> <month> February </month> <year> 1985. </year>
Reference-contexts: Taking the status reports can be coordinated so as to prevent any message from crossing the probe backwards, which would render the algorithm safe; the status reports would then form a consistent snapshot cf. <ref> [5] </ref>.
Reference: [6] <author> Israel Cidon. </author> <title> Yet another distributed depth-first search algorithm. </title> <journal> Information Processing Letters, </journal> <volume> 26 </volume> <pages> 301-305, </pages> <month> January </month> <year> 1988. </year>
Reference-contexts: Each time a node is visited for the first time the flow of [dfs] messages is interrupted for exchanging [visit] and [ack] messages, which takes two time units. Hence the time complexity is bounded by 4n 2. A slightly better result was obtained by Cidon <ref> [6] </ref>. Linear-message solution. Calls and returns through non-tree edges can be avoided without sending additional messages; see Helary et al. [12].
Reference: [7] <author> Edsger W. Dijkstra, Wim H. J. Feijen, and A. J. M. van Gasteren. </author> <title> Derivation of a termination detection algorithm for distributed computations. </title> <journal> Information Processing Letters, </journal> <volume> 16(5) </volume> <pages> 217-219, </pages> <month> June </month> <year> 1983. </year>
Reference-contexts: exchanged messages is relatively small (linear in n or m, say), the Dijkstra-Scholten algorithm is the termination detector of choice. 3.3 Probe Algorithms Probe algorithms repeatedly scan the entire network for active nodes and computation messages; they are based on the principle laid out by Dijkstra, Feijen, and Van Gasteren <ref> [7] </ref>. For simplicity of explanation we shall assume a special node (the controller) to coordinate detection; the controller exchanges status reports with all nodes.
Reference: [8] <author> Edsger W. Dijkstra and Carel S. Scholten. </author> <title> Termination detection for diffusing computations. </title> <journal> Information Processing Letters, </journal> <volume> 11(1) </volume> <pages> 1-4, </pages> <month> August </month> <year> 1980. </year>
Reference-contexts: Dijkstra and Scholten's algorithm <ref> [8] </ref> assumes that initially exactly one node is active; we call this node the root node. Global description: Computation tree.
Reference: [9] <author> Shimon Even, Gene Itkis, and Sergio Rajsbaum. </author> <title> On mixed connectivity certificates. </title> <editor> In Paul Spirakis, editor, </editor> <booktitle> European Symposium on Algorithms, volume 979 of Lecture Notes in Computer Science, </booktitle> <pages> pages 1-16. </pages> <publisher> Springer Verlag, </publisher> <year> 1995. </year>
Reference-contexts: Distributed Certificate Algorithm. At first sight the centralised data structure frustrates a distributed implementation, just as it is the case for breadth-first search. However, Evens et al. <ref> [9] </ref> showed that the central data structure can be replaced by a recursive search for unvisited nodes through the branches of the tree of the highest active level.
Reference: [10] <author> Robert G. Gallager, Pierre A. Humblet, and P. M. Spira. </author> <title> A distributed algorithm for minimum weight spanning trees. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 5 </volume> <pages> 67-77, </pages> <year> 1983. </year>
Reference-contexts: The message complexity of the fast solution is large (unknown though), while message optimal solutions (exchanging O (n log n + m) messages) exist with linear time complexity <ref> [3, 10] </ref>. We shall discuss a distributed depth-first search algorithm whose time is proportional to the depth of the DFS tree, while again message complexity rises sky-high. <p> At the end no node will see the entire tree, but only the status of its own links (tree or non-tree). The problem of computing weight-minimal trees has received attention in the literature <ref> [10] </ref>, but where unit-cost links are assumed all trees are weight-minimal and we shall not address this problem. We illustrate the algorithms by giving pseudocode with Pascal-like (mostly self-explanatory) syntax set in typewriter font. <p> Our example of a distributed graph processing algorithm was taken from the Artificial Intelligence domain, namely loop cutset computation. Other graph algorithms can be treated in a similar way to yield distributed versions; known examples include Shortest Path [27, Sec. 4.2], Minimum Spanning Tree <ref> [10] </ref>, Maximum Flow [32], Connectivity problems [14]. 6 Conclusions This chapter gives an overview of the most important techniques of distributed algorithm design for Distributed Artificial Intelligence applications. Important issues in this domain are the distributed control of computations, and the distributed processing of the network graph.
Reference: [11] <author> Juan A. Garay, Shay Kutten, and David Peleg. </author> <title> A sub-linear time distributed algorithm for minimum-weight spanning trees. </title> <booktitle> In Symp. on Theory of Computing, </booktitle> <pages> pages 659-668, </pages> <year> 1993. </year>
Reference-contexts: A fast algorithm is one that uses sub-linear (i.e., o (n)) time. Fast computing is not easy; Garay et al. <ref> [11] </ref> present an algorithm for Minimal Spanning Tree that runs in O (D + n 0:614 ) time, but the solution appears a bit artificial.
Reference: [12] <author> Jean-Michel Helary, Aomar Maddi, and Michel Raynal. </author> <title> Calcul distribue d'un extremum et du routage associe dans un reseau quelconque. </title> <type> Technical Report 516, </type> <institution> INRIA, Rennes, </institution> <month> April </month> <year> 1986. </year>
Reference-contexts: Hence the time complexity is bounded by 4n 2. A slightly better result was obtained by Cidon [6]. Linear-message solution. Calls and returns through non-tree edges can be avoided without sending additional messages; see Helary et al. <ref> [12] </ref>. In these solutions a node is not informed about a neighbour being visited by receiving from that neighbour, but instead the call and return messages include a complete list of nodes already visited.
Reference: [13] <author> Lisa Higham and Teresa Przytycka. </author> <title> A simple, efficient algorithm for maximum finding on rings. </title> <editor> In Andre Schiper, editor, </editor> <booktitle> 7th Int. Workshop on Distributed Algorithms, volume 725 of Lecture Notes in Computer Science, </booktitle> <pages> pages 249-263. </pages> <publisher> Springer Verlag, </publisher> <month> September </month> <year> 1993. </year>
Reference-contexts: If only identities are given, we may use an election program to choose one node as an initiator; such a program should of course not rely on the existence of an initiator, and would output, for example, the largest identity <ref> [13, 29] </ref>. If no initial identifiers are known while an initiator is distinguished, it may start a network traversal to assign unique names.
Reference: [14] <author> Esther Jennings. </author> <title> Distributed Graph Connectivity Algorithms. </title> <type> PhD thesis, </type> <institution> Dept of Elec. Eng., Lule-a Un. (Sw.), </institution> <month> Sept. 22, </month> <year> 1997. </year>
Reference-contexts: Testing global connectivity. Algorithms for computing 2- or 3-connected components may profit from execution on a 2- or 3-connectivity certificate <ref> [14] </ref>. The certificate can be computed in O (m) time and messages, and guarantees that the subsequent connectivity algorithm has to consider only O (n) edges. 3 Termination Detection A distributed algorithm terminates when it reaches a global state (configuration) in which no event of the algorithm is applicable. <p> Other graph algorithms can be treated in a similar way to yield distributed versions; known examples include Shortest Path [27, Sec. 4.2], Minimum Spanning Tree [10], Maximum Flow [32], Connectivity problems <ref> [14] </ref>. 6 Conclusions This chapter gives an overview of the most important techniques of distributed algorithm design for Distributed Artificial Intelligence applications. Important issues in this domain are the distributed control of computations, and the distributed processing of the network graph. We have seen two important control paradigms.
Reference: [15] <author> Nathan Linial. </author> <title> Distributive graph algorithms: Global solutions from local data. </title> <booktitle> In Foundations of Computer Science, </booktitle> <pages> pages 331-335. </pages> <publisher> IEEE, </publisher> <year> 1987. </year>
Reference-contexts: The network diameter serves as a time lower bound for all tasks that require coordination between all nodes (including every task that requires consensus in the output), because no information can be communicated across the network in o (D) time. Linial <ref> [15] </ref> gives examples of tasks (Maximal Independent Set, Colouring) that can be solved by local computations, i.e., in sub-diameter time, and Litovsky et al. [16] have further investigated the power of local computations. 1.3 Examples of Distributed Architectures in AI Distribution may be driven by several factors, such as the wish
Reference: [16] <author> Igor Litovsky, Yves Metivier, and Wies law Zielonka. </author> <title> On the recognition of families of graphs with local computations. </title> <journal> Information and Computation, </journal> <volume> 118(1) </volume> <pages> 110-119, </pages> <month> April </month> <year> 1995. </year>
Reference-contexts: Linial [15] gives examples of tasks (Maximal Independent Set, Colouring) that can be solved by local computations, i.e., in sub-diameter time, and Litovsky et al. <ref> [16] </ref> have further investigated the power of local computations. 1.3 Examples of Distributed Architectures in AI Distribution may be driven by several factors, such as the wish to speed up computations by using more hardware, or the availability of resources. Multiprocessor computers.
Reference: [17] <author> Virginia Mary Lo. </author> <title> Heuristic algorithms for task assignment in distributed systems. </title> <journal> IEEE Trans. on Computers, </journal> <volume> 37(11) </volume> <pages> 1384-1397, </pages> <month> November </month> <year> 1988. </year>
Reference-contexts: Minimising load and communication (over all allocations) is NP-hard, so an approximation algorithm is needed; see for example the work by Lo <ref> [17] </ref>. 4.6 Distributed Constraint Satisfaction Algorithm We shall now briefly discuss how Distributed Arc Consistency can be used in distributed solutions for Constraint Satisfaction Problems. A CSP is usually solved by backtracking, where parts of the solution space are eliminated from search by hypothesis generation.
Reference: [18] <author> R. Mohr and T. C. Henderson. </author> <title> Arc and path consistency revisited. </title> <journal> Artif. Intell., </journal> <volume> 28 </volume> <pages> 225-233, </pages> <year> 1986. </year>
Reference-contexts: Let Succ i denote the successors and Pred i the predecessors of i in this graph and m the number of edges. 4.2 The AC4 Algorithm Mohr and Henderson <ref> [18] </ref> proposed the following data structures and algorithm for detecting redundant values; see Alg. 16. <p> Initialisation of the data structures costs m:a 2 time, the initial check for redundant values takes m:a time, and the main loop may again take m:a 2 time. The resulting O (m:a 2 ) time complexity is optimal for Arc Consistency <ref> [18] </ref>. 4.3 The Distributed AC4 Algorithm In this subsection we shall describe a distributed implementation of the AC4 algorithm, first assuming that there is one computing node for each variable.
Reference: [19] <author> Hiroshi Nagamochi and Toshihide Ibaraki. </author> <title> A linear-time algorithm for finding a sparse k-connected spanning subgraph of a k-connected graph. </title> <journal> Algorithmica, </journal> <volume> 7 </volume> <pages> 583-596, </pages> <year> 1992. </year>
Reference: [20] <author> Thang Nguyen and Yves Deville. </author> <title> A distributed arc-consistency algorithm. </title> <type> Technical report, </type> <institution> Dept Informatique, Univ. Cath. de Louvain, </institution> <address> 1348 Louvain-la-Neuve, Belgium, </address> <month> September </month> <year> 1995. </year>
Reference-contexts: The reason is that probe algorithms exchange a fixed number of control messages per probe, independent of the number of basic messages. A good balance between detection overhead and detection delay can be achieved by starting probes under the control of a timer (as in <ref> [20] </ref>.) Assume a fixed delay of is introduced between the end of an unsuccessful probe and the start of the next one, and that the duration of the probe is small compared to . <p> next probe finds all nodes with rec = false and thus termination is detected after at most 2 delay. 4 Distributed Arc Consistency and CSP To demonstrate the application of the distributed algorithm techniques to distributed AI problems, we shall now study the distributed Arc Consistency algorithm DisAC4; see also <ref> [20] </ref>. The Constraint Satisfaction Problem and consistency filters were also discussed in Chapter 4. The Constraint Satisfaction Problem (CSP) and Arc Consistency (AC) are defined in Sec. 4.1, and the sequential AC4 algorithm is outlined in Sec. 4.2. <p> When node j eliminates w it will inform node i with a single message, and on receipt of this message node i must consider all its pairs of Supp [j; w]. This possibility is chosen in <ref> [20] </ref>. However, we observe that the support structure can be eliminated completely without significantly increasing the computational complexity of the algorithm. Indeed, for each j; w the set Supp [j; w] is read just at most once, namely, when j is eliminated from D j .
Reference: [21] <author> Pierre Rosenstiehl, J. R. Fiksel, and A. Holliger. </author> <title> Intelligent graphs: Networks of finite automata capable of solving graph problems. </title> <editor> In R. C. Read, editor, </editor> <booktitle> Graph Theory and Computing, </booktitle> <pages> pages 219-265. </pages> <publisher> Academic Press, </publisher> <year> 1972. </year>
Reference-contexts: If no initial identifiers are known while an initiator is distinguished, it may start a network traversal to assign unique names. A different situation arises in anonymous networks, where neither identities nor initiator are given; Rosenstiehl et al. <ref> [21] </ref> established 25 years ago that these networks can compute fewer functions. No function that requires to break symmetry can be computed deterministically; with randomised algorithms, naming and election can be performed, but only if the nodes initially know the size of the network [27, Chap. 9]. Communication.
Reference: [22] <author> Nir Shavit and Nissim Francez. </author> <title> A new approach to the detection of locally indicative stability. </title> <editor> In Laurent Kott, editor, </editor> <booktitle> Int. Colloq. on Automata, Languages, and Programming, volume 226 of Lecture Notes in Computer Science, </booktitle> <pages> pages 344-358. </pages> <publisher> Springer Verlag, </publisher> <year> 1986. </year>
Reference-contexts: The algorithm can be applied to computations like Alg. 7, where the active state is not explicit. The resulting fast DFS algorithm with termination detection is shown as Alg. 12. The requirement that only one node initiates the computation was relaxed by Shavit and Francez <ref> [22] </ref>; in their algorithm each initiator of the computation traces a subset of the activity, and one round of global communication is used to determine that all traced activity has ceased.
Reference: [23] <author> H. J. Suermondt and G. F. Cooper. </author> <title> Probabilistic inference in multiply connected belief networks using loop cutsets. </title> <journal> Int. J. of Approximate Reasoning, </journal> <volume> 4 </volume> <pages> 283-306, </pages> <year> 1990. </year>
Reference-contexts: The example worked out is the computation of a loop cutset in a Belief Network, which is a necessary preprocessing stage for the application of loop cutset conditioning in these networks. The aim of this section is to show how a sequential algorithm (by Suermondt and Cooper <ref> [23] </ref>) can be modified for distributed execution. 5.1 The Problem: Loop Cutset A Belief Network is a directed acyclic graph in which the nodes represent various hypotheses and the arcs represent known statistical dependencies. <p> Algorithm of Suermondt and Cooper. For efficiency reasons, the cutset should be small, but computation of an optimal cutset is NP hard. The best-known heuristic for computing small cutsets (Suermondt and Cooper <ref> [23] </ref>) includes vertices in C one by one, trying to choose vertices that cut as many loops as possible. This is done by choosing a vertex with maximal degree, but to avoid cutting a cycle by removal of a pit, the chosen node must have in-degree zero or one.
Reference: [24] <author> Andrew S. Tanenbaum. </author> <title> Computer Networks. </title> <publisher> Prentice Hall, 3rd edition, </publisher> <year> 1996. </year>
Reference-contexts: The flagrant waste of computing resources can be economically justified only if the output data (which is not transported here) far exceeds the input data in size. Duplicated computation is used to compute routing tables in the Internet <ref> [24, Sec. 5.5] </ref>. This chapter concerns distributed solutions, where the processing steps of the application are divided among the participating nodes. Even when not explicitly based on a sequential algorithm, each distributed solution can be seen as containing a sequential one consisting of the combined computation steps of the participants.
Reference: [25] <author> Gerard Tel. </author> <title> Distributed infimum approximation. </title> <type> Technical Report RUU-CS-86-12, </type> <institution> Dept of Computer Science, Utrecht Univ., </institution> <year> 1986. </year> <note> URL http://www.cs.ruu.nl/~gerard/liter/dia.dvi. </note>
Reference-contexts: Variations, complexity, discussion. The various probe based algorithms differ considerably, mainly in their treatment of in-transit messages, and the collection of the status reports <ref> [25, 26] </ref>. Instead of counting messages as we have shown, acknowledgements or time-outs can be used. Instead of direct communication with the controller as in Alg. 14, probe propagation through a Hamiltonian Cycle, or the Echo algorithm can be used for status communication.
Reference: [26] <author> Gerard Tel. </author> <title> Total algorithms. </title> <journal> Algorithms Review, </journal> <volume> 1(1) </volume> <pages> 13-42, </pages> <month> January </month> <year> 1990. </year> <month> 38 </month>
Reference-contexts: Variations, complexity, discussion. The various probe based algorithms differ considerably, mainly in their treatment of in-transit messages, and the collection of the status reports <ref> [25, 26] </ref>. Instead of counting messages as we have shown, acknowledgements or time-outs can be used. Instead of direct communication with the controller as in Alg. 14, probe propagation through a Hamiltonian Cycle, or the Echo algorithm can be used for status communication.
Reference: [27] <author> Gerard Tel. </author> <title> Introduction to Distributed Algorithms. </title> <publisher> Cambridge University Press, </publisher> <address> Cam--bridge, U.K., </address> <year> 1994. </year>
Reference-contexts: No function that requires to break symmetry can be computed deterministically; with randomised algorithms, naming and election can be performed, but only if the nodes initially know the size of the network <ref> [27, Chap. 9] </ref>. Communication. In this chapter, the communication between nodes is by message passing and has two operations, send and receive. <p> It is usually observed that the communication complexity for processing the network topology is at least linear in m, which is the input size for topological problems. For graph exploration, for example, this can be shown formally <ref> [27, Chap. 6] </ref> because each link must carry at least one message. Task that require processing a constant amount of information for each node (such as a sum of distributed inputs, see Alg. 14) can be performed with O (n) messages using spanning trees or cycles. <p> Consequently, lmsp (u) &lt; lmsp (v) lmsp (u) v, which implies that lmsp (u) is a prefix of lmsp (v), and u is an ancestor of v. 2 As a consequence, a dfs tree can be constructed with a variation of Chandy and Misra's algorithm <ref> [27, p. 120] </ref> for shortest path computation; see Alg. 7. Variable la u is node u's approximation of its lmsp; the approximations are initialised to 1, a string exceeding all other strings, and remain conservative in the sense that la u lmsp (u). <p> It is easy to show that the time consumption is O (D) under very weak additional assumptions about the timing of messages, and this explains why the algorithm is empirically fast. Unfortunately, our theoretical model allows for worse executions <ref> [27, p. 217] </ref>. The O (D) 13 construction time of the tree does not imply that its depth is O (D) because exploration messages over a long path may bypass messages over shorter paths. <p> It is far from trivial to firmly establish that the algorithm is correct and operates as described above, even under the most exotic scenarios of the computation and its timing. The basic techniques (invariant properties and variant functions) and their application to this algorithm are discussed in <ref> [27, Sec. 8.1] </ref> but are outside the scope of this chapter. <p> Our example of a distributed graph processing algorithm was taken from the Artificial Intelligence domain, namely loop cutset computation. Other graph algorithms can be treated in a similar way to yield distributed versions; known examples include Shortest Path <ref> [27, Sec. 4.2] </ref>, Minimum Spanning Tree [10], Maximum Flow [32], Connectivity problems [14]. 6 Conclusions This chapter gives an overview of the most important techniques of distributed algorithm design for Distributed Artificial Intelligence applications. <p> All these techniques were used in Suermondt and Cooper's algorithm, and are applicable to the distributed CSP algorithm outlined in Section 4.6. The interested reader is referred to <ref> [27] </ref> to read about more paradigms, such as leader election, control for anonymous networks, snapshots, synchronous algorithms; I consider them of lesser importance for the AI community. Distributed graph processing is based on sequential techniques for the same problem, and 36 distributed graph exploration is an important step.
Reference: [28] <author> Gerard Tel. </author> <title> Network orientation. </title> <journal> Int. Journal on Foundations of Computer Science, </journal> <volume> 5(1) </volume> <pages> 23-57, </pages> <month> March </month> <year> 1994. </year>
Reference-contexts: These assumptions are natural because they can be met at low cost when implementing a distributed system; distributed algorithms research has investigated their influence on the power of the model. In terms of network computing power, one of these assumptions suffices and they are equivalent <ref> [28] </ref>. If only identities are given, we may use an election program to choose one node as an initiator; such a program should of course not rely on the existence of an initiator, and would output, for example, the largest identity [13, 29].
Reference: [29] <author> Gerard Tel. </author> <title> Linear election in hypercubes. </title> <journal> Parallel Processing Letters, </journal> <volume> 5(3) </volume> <pages> 357-366, </pages> <year> 1995. </year>
Reference-contexts: If only identities are given, we may use an election program to choose one node as an initiator; such a program should of course not rely on the existence of an initiator, and would output, for example, the largest identity <ref> [13, 29] </ref>. If no initial identifiers are known while an initiator is distinguished, it may start a network traversal to assign unique names.
Reference: [30] <author> Gerard Tel and Friedemann Mattern. </author> <title> The derivation of termination detection algorithms from garbage collection schemes. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 15(1) </volume> <pages> 1-35, </pages> <month> January </month> <year> 1993. </year>
Reference-contexts: Probe algorithms rely on global (coordinated) scans of the network state and call termination when no activity is found. The distinction can be compared to that between reference counting and mark-and-sweep type garbage collectors <ref> [30] </ref>. 18 var state : (act, pas) init if u=u0 then act else pas ; cc : integer init 0 ; fat : node init if u=u0 then u else undef ; Su: state= act - send [mes] ; cc := cc + 1 Ru: A message [mes] from v arrives
Reference: [31] <author> Linda C. van der Gaag. </author> <title> Bayesian belief networks: Odds and ends. </title> <journal> The Computer Journal, </journal> <volume> 39(2) </volume> <pages> 97-113, </pages> <year> 1996. </year>
Reference-contexts: The neighbour relation can be defined by the hardware, for example in processor networks where the neighbors are those processors to which the node is physically connected. Alternatively, the application can define this relation, for example, in Belief Networks <ref> [31] </ref>, where each node stores information about a stochastic variable and communicates with nodes storing some related variables. Symmetry.
Reference: [32] <author> Bram Verweij. </author> <title> Distributed edge depletion for maximum flows. </title> <type> Master's thesis, </type> <institution> Dept of Computer Science, Utrecht Univ., </institution> <month> July </month> <year> 1996. </year> <month> 39 </month>
Reference-contexts: In Algorithm 9, node u stores the rank of its adjacent edge uv in rank u [v] (0 if the edge is unranked), and the flag search u [v] indicates if the search must still be forwarded to v. Verweij <ref> [32] </ref> shows that this search procedure indeed visits at each time the unvisited node of highest label. <p> Our example of a distributed graph processing algorithm was taken from the Artificial Intelligence domain, namely loop cutset computation. Other graph algorithms can be treated in a similar way to yield distributed versions; known examples include Shortest Path [27, Sec. 4.2], Minimum Spanning Tree [10], Maximum Flow <ref> [32] </ref>, Connectivity problems [14]. 6 Conclusions This chapter gives an overview of the most important techniques of distributed algorithm design for Distributed Artificial Intelligence applications. Important issues in this domain are the distributed control of computations, and the distributed processing of the network graph.
References-found: 32

