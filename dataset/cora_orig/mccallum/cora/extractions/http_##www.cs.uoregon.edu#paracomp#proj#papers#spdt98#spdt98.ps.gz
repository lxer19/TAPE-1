URL: http://www.cs.uoregon.edu/paracomp/proj/papers/spdt98/spdt98.ps.gz
Refering-URL: http://www.cs.uoregon.edu/paracomp/proj/tau/papers.html
Root-URL: http://www.cs.uoregon.edu
Email: klindlan-@cs.uoregon.edu  -beckman,karmesin-@acl.lanl.gov  
Title: Portable Profiling and Tracing for Parallel, Scientific Applications using C++  
Author: Sameer Shende, Allen D. Malony, Janice Cuny, Kathleen Lindlan -sameer, malony, cuny, Peter Beckman and Steve Karmesin 
Address: OR 97403  Los Alamos, NM 87545  
Affiliation: Department of Computer and Information Science University of Oregon, Eugene,  Advanced Computing Laboratory Los Alamos National Laboratory  
Abstract: 1. Abstract 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Advanced Computing Laboratory (LANL), </author> <title> Scientific Template Library - Part of the DOE 2000 ACTS Tool kit, </title> <year> 1998. </year> <month> URL:http://www.acl.lanl.gov/SciTL/. </month>
Reference-contexts: Approaches include the creation of OO interfaces to existing numerical libraries [5], the rewriting of libraries completely in OO form [4], and the building of applications from a multi-layered, hierarchical OO component framework <ref> [1] </ref>. Critics cite the inefficiencies of OO methods and language compilers, whereas proponents praise the ease of software construction, maintenance, and reusability. Here, we leave these arguments aside, and consider the nature of the tools that might support the development and analysis of parallel OO programs. <p> Such an SPMD model, with multiple contexts and multiple threads within contexts, supports a range of applications with multi-level parallelism, such as adaptive grid methods for large scale simulation. 4. Profiling C++ Scientific Applications Our application target was the ACTS C++ toolkit <ref> [1] </ref> which imposed a number of requirements on our profiling and tracing tools. The ACTS toolkit is a group of parallel class libraries and scientific software frameworks. It provides a rich set of data parallel abstractions, exploiting advanced features of C++.
Reference: [2] <institution> Advanced Computing Laboratory(LANL), TAU Porta ble Profiling, </institution> <year> 1998. </year> <month> URL:http://www.acl.lanl.gov/tau. </month>
Reference-contexts: Instrumentation can be done at the source code level, or at the binary executable code level [13][19]. We chose the source code level because of efficiency and portability concerns. Currently, our instrumentation is inserted manually using a profiling API <ref> [2] </ref>. To instrument, the user must specify the signature of each function to be profiled, and associate logically-related functions into profile groups. A function can belong to one or more profile groups. Once the groups have been identified, instrumentation macros are inserted into the code.
Reference: [3] <author> V.S. Adve, J.M. Crummey, M. Anderson, K. Kennedy, J. C. Wang, and D. A. Reed, </author> <title> Integrating Compilation and Performance Analysis for Data-Parallel Programs, </title> <booktitle> Proc. of the Workshop on Debugging and Performance Tuning for Parallel Computing Systems, </booktitle> <month> Jan. </month> <year> 1996. </year>
Reference-contexts: Certainly, similar questions over the need for new analysis techniques and tools have arisen in other contexts (e.g., in different parallel programming paradigms, in the use of high-level parallel languages <ref> [3] </ref>, or in the transition to metacomputing systems [6]). These questions have, in fact, driven much of the evolution of parallel and distributed tools. <p> For instance, the profiling data generated is fairly standard, modeled after the classic Unix prof and gprof facilities, but extended here across nodes, contexts, and threads of the HPC++ parallel execution model. Similarly, the recording of event traces is commonly found in tools for parallel performance analysis, notably Pablo <ref> [3] </ref> and AIMS [22]. The primary contributions of this work come from solving problems associated with the C++ language and its use in parallel scientific applications and frameworks. <p> Overcoming the obstacles to understanding program performance requires close integration between the performance measurement and analysis tools and the language compiler, as is demonstrated in the Pablo / Fortran D effort <ref> [3] </ref>. We regard many of the difficulties encountered for C++ performance measurement as overcoming the semantic problems of relating program execution information to program source representation and user-level framework abstractions.
Reference: [4] <author> F. Bassetti, K. Davis, and D. Quinlan, </author> <title> A Comparison of Performance-Enhancing Strategies for Parallel Numerical Object-Oriented Frameworks, </title> <booktitle> Proc. </booktitle> <volume> ISCOPE 97, LNCS Vol. 1343, </volume> <publisher> Springer, </publisher> <month> Dec. </month> <year> 1997. </year>
Reference-contexts: Introduction In recent years, there has been a trend towards building high-performance, large-scale applications using object-oriented (OO) techniques and languages (primarily C++ and Java) [9]. Approaches include the creation of OO interfaces to existing numerical libraries [5], the rewriting of libraries completely in OO form <ref> [4] </ref>, and the building of applications from a multi-layered, hierarchical OO component framework [1]. Critics cite the inefficiencies of OO methods and language compilers, whereas proponents praise the ease of software construction, maintenance, and reusability.
Reference: [5] <editor> J. Dongarra and L.S. Blackford, ScaLAPACK tuto rial, </editor> <booktitle> Proc. of Applied Parallel Computing, Industrial Computation and Optimization, Third International Workshop, PARA 96, </booktitle> <month> Aug. </month> <year> 1996. </year>
Reference-contexts: Introduction In recent years, there has been a trend towards building high-performance, large-scale applications using object-oriented (OO) techniques and languages (primarily C++ and Java) [9]. Approaches include the creation of OO interfaces to existing numerical libraries <ref> [5] </ref>, the rewriting of libraries completely in OO form [4], and the building of applications from a multi-layered, hierarchical OO component framework [1]. Critics cite the inefficiencies of OO methods and language compilers, whereas proponents praise the ease of software construction, maintenance, and reusability.
Reference: [6] <author> I. Foster and C. Kesselman, Globus: </author> <title> A Metacomput ing Infrastructure Toolkit, </title> <booktitle> Proc. of the Workshop on Environments and Tools for Parallel Scientific Comput ing, </booktitle> <month> Aug. </month> <year> 1996. </year>
Reference-contexts: Certainly, similar questions over the need for new analysis techniques and tools have arisen in other contexts (e.g., in different parallel programming paradigms, in the use of high-level parallel languages [3], or in the transition to metacomputing systems <ref> [6] </ref>). These questions have, in fact, driven much of the evolution of parallel and distributed tools. With the widespread use of C++, however, one might assume that all such interesting issues have already been resolved, but this is not true for two reasons.
Reference: [7] <author> S.L. Graham, P.B. Kessler, </author> <title> and M.K. McKusik, An Execution Profiling for Modular Programs, </title> <journal> Software -- Practice and Experience, </journal> <volume> Vol. 13, </volume> <pages> pp. 671-85, </pages> <year> 1983. </year>
Reference: [8] <author> J.K. Hollingsworth, B.P. Miller, M. J. R. Gonalves, O. Naim, Z. Xu and L. Zheng, </author> <title> MDL: A Language and Compiler for Dynamic Program Instrumentation, </title> <booktitle> Proc. 1997 International Conference on Parallel Architectures and Compilation Techniques, </booktitle> <pages> pp. 201-12, </pages> <month> Nov. </month> <year> 1997. </year>
Reference-contexts: These capabilities will be a significant aid to users in maintaining a meaningful correspondence between the program and its performance. We also intend to explore the use of dynamic instrumentation <ref> [8] </ref> to select and enable instrumentation at runtime. It is unlikely that all of the nuances of C++ instrumentation can be handled dynamically, but extending the API and its implementation to allow external instrumentation interaction could provide important runtime adaptive control.
Reference: [9] <author> Y. Ishikawa, </author> <title> R.R. Oldehoeft, </title> <editor> J.V.W. Reynders, and M. Tholburn (Eds.), </editor> <booktitle> Scientific Computing in Object-Ori ented Parallel Environments, Proc. ISCOPE97, </booktitle> <volume> LNCS Vol. 1343, </volume> <publisher> Springer, </publisher> <month> Dec. </month> <year> 1997. </year>
Reference-contexts: Introduction In recent years, there has been a trend towards building high-performance, large-scale applications using object-oriented (OO) techniques and languages (primarily C++ and Java) <ref> [9] </ref>. Approaches include the creation of OO interfaces to existing numerical libraries [5], the rewriting of libraries completely in OO form [4], and the building of applications from a multi-layered, hierarchical OO component framework [1].
Reference: [10] <author> E. Johnson, D. Gannon, and P. Beckman, </author> <title> HPC++: Experiments with the Parallel Standard Template Library, </title> <booktitle> Proc. International Conference on Supercom puting, </booktitle> <month> July </month> <year> 1997. </year>
Reference-contexts: In Section 6, we present examples from its application to several different computational science codes. Finally, in Section 7, we state conclusions and outline future work. 3. Model of Computation Our parallel C++ model of computation is based on that of HPC++Lib <ref> [10] </ref>, an object-oriented library that supports both task- and data-parallel programming paradigms. 1 HPC++Lib features a Java-style thread class for shared memory architectures, a template library that supports synchronization, collective parallel operations, and remote memory references, and a remote invocation facility for member function calls on objects in remote address spaces.
Reference: [11] <author> D. Lange and Y. Nakamura, </author> <title> Object-Oriented Program Tracing and Visualization, </title> <journal> IEEE Computer, </journal> <volume> Vol. 30, No. 5, </volume> <pages> pp. 63-70, </pages> <month> May </month> <year> 1997 </year>
Reference-contexts: This view also supported by research on object-oriented program analysis which indicates that conventional approaches are insufficient for dealing with OO semantics <ref> [11] </ref>. In comparison, then, with other tools that are available for use with C++, TAUs approach provides a more complete relationship of the C++ program to the measured performance information.
Reference: [12] <author> S.R. Lee, J.C. Cummings, </author> <title> S.D. Nolen, N.D. Keen, MC++ and a Transport Physics Framework. </title> <booktitle> Proc. </booktitle> <volume> ISCOPE 97, LNCS Vol. 1343, </volume> <publisher> Springer, </publisher> <month> Dec. </month> <year> 1997. </year>
Reference-contexts: User Experiences 6.1 MC++ MC++ <ref> [12] </ref> is a parallel Monte Carlo neutron transport code written in C++ using the POOMA Framework. The MC++ code inputs information describing a set of materials, some of which may be fissile (capable of generating neutrons), and the interfaces between materials.
Reference: [13] <author> B. Miller, M. Callaghan, J. Cargille, J. Hollingsworth, R. Irvin, K. Karavanic, K. Kunchithapadam, and T. Newhall, </author> <title> The Paradyne Parallel Performance Mea surement Tools, </title> <journal> IEEE Computer, </journal> <volume> Vol. 28, No. 11, pp.37-46, </volume> <month> November </month> <year> 1995. </year>
Reference: [14] <author> B. Mohr, A. Malony, and J. Cuny, </author> <title> TAU, </title> <editor> in G.V. Wil-son and P. Lu (Eds.), </editor> <title> Parallel Programming using C++, </title> <publisher> MIT Press, </publisher> <year> 1996. </year>
Reference-contexts: The TAU Portable Profiling and Tracing Package A number of profiling methods exist: statistical sampling of the program counter or call stack; hardware counter sampling; instruction counting; and timer instrumentation. We use the last of these in TAU (Tuning and Analysis Utilities) <ref> [14] </ref>. The architecture of the TAU profiling package is shown in Figure 1. <p> We are pursuing two avenues in this regard. We are working with Edison Design Group (EDG) and Kuck and Associates (KAI) to implement compile-time instrumentation capabilities. A by-product of this effort will be program information that will enable TAUs static analysis tools <ref> [14] </ref> to select, via structured program views (e.g., a class browser), what code will be instrumented. The instrumentation can then be generated automatically. The static tools are also linked with profile or trace displays where functions can be selected and the corresponding program code shown.
Reference: [15] <author> Pallas GmbH, </author> <title> VAMPIR - Visualization and Analysis of MPI Resources, </title> <booktitle> 1998. </booktitle> <address> URL:http://www.pallas.de/ pages/vampir.html. </address>
Reference-contexts: The application is compiled and run as before, but now traces are generated. These are merged and converted to one of several trace formats, including the binary Vampir 1 <ref> [15] </ref> data format. Although a function can belong to one or more profile groups, it has a distinguished, primary group. Vampir displays the traces and the functions based on the primary group for each function.
Reference: [16] <author> D. Pase, </author> <title> MPP Apprentice: A Non-Event Trace Perfor mance Tool for the Cray T3D, Workshop on Debug ging and Performance Tuning for Parallel Computing Systems, </title> <address> Oct. </address> <year> 1994. </year>
Reference-contexts: In the parallelizing compiler case, the problem is one of associating performance measurement with source location in the presence of code optimization. For example, Crays MPP Apprentice <ref> [16] </ref> supports source-level performance analysis for highly-optimized, parallel programs written C, Fortran, and Fortran90. In the case of parallel libraries, the performance model must be extended to reect the parallel programming model used, message passing or shared memory.
Reference: [17] <editor> J.V.W. Reynders et. al., Pooma: </editor> <title> A Framework for Sci entific Simulation on Parallel Architectures, </title> <editor> in G.V. Wilson and P. Lu (Eds.), </editor> <booktitle> Parallel Programming using C++, </booktitle> <pages> pp. 553-594, </pages> <publisher> MIT Press, </publisher> <year> 1996. </year>
Reference-contexts: The ACTS toolkit is a group of parallel class libraries and scientific software frameworks. It provides a rich set of data parallel abstractions, exploiting advanced features of C++. Most significantly, one of its central components -- the POOMA framework <ref> [17] </ref> -- makes extensive use of templates [18] to hide the mechanics of message passing behind data-parallel arrays. Our first two requirements are thus Abstraction. Our tools must handle data-parallel abstractions, providing access to individual instantiation as well as aggregate behavior. Completeness.
Reference: [18] <author> B. Stroustrup, </author> <title> The C++ Programming Language, Third Edition, </title> <publisher> Addison-Wesley, </publisher> <address> Massachusetts, </address> <month> June </month> <year> 1997. </year>
Reference-contexts: The ACTS toolkit is a group of parallel class libraries and scientific software frameworks. It provides a rich set of data parallel abstractions, exploiting advanced features of C++. Most significantly, one of its central components -- the POOMA framework [17] -- makes extensive use of templates <ref> [18] </ref> to hide the mechanics of message passing behind data-parallel arrays. Our first two requirements are thus Abstraction. Our tools must handle data-parallel abstractions, providing access to individual instantiation as well as aggregate behavior. Completeness.
Reference: [19] <institution> Silicon Graphics, Inc., </institution> <note> Speed Shop Users Guide, 1997. URL:http://techpubs.sgi.com. </note>
Reference: [20] <author> T. Veldhuizen, </author> <title> Expression Templates, C++ Report, </title> <booktitle> 7(5) </booktitle> <pages> 26-31, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: Some profiling data for Conejos template instantiations is shown in Figure 9. 6.3 Profiling Expression Templates in Blitz++ Another advantage of the TAU profiler is its ability to profile expression templates and to present the related performance information in a high-level form. Expression templates <ref> [20] </ref> allow logical and algebraic expressions to be passed to functions as arguments that are inlined in the function body. Traditionally, operator overloading in C++ permits a natural notation for building expressions with arrays using pairwise arithmetic overloaded operators.
Reference: [21] <author> T. Veldhuizen and M.E. Jernigan, </author> <title> Will C++ be Faster than Fortran, </title> <booktitle> Proc. </booktitle> <volume> ISCOPE 97, LNCS Vol. 1343, </volume> <publisher> Springer, </publisher> <month> Dec. </month> <year> 1997. </year>
Reference: [22] <author> J. Yan, </author> <title> Performance Tuning with AIMS---An Auto mated Instrumentation and Monitoring System for Mul ticomputers, </title> <booktitle> Proc. 27th Hawaii Int. Conf. on System Sciences, Hawaii, </booktitle> <month> Jan. </month> <year> 1994. </year>
Reference-contexts: Similarly, the recording of event traces is commonly found in tools for parallel performance analysis, notably Pablo [3] and AIMS <ref> [22] </ref>. The primary contributions of this work come from solving problems associated with the C++ language and its use in parallel scientific applications and frameworks. In this respect, we comment on related efforts for language-directed instrumentation and performance analysis, and discuss other profiling tools available for use with C++.
Reference: [23] <author> M. Zagha, B. Larson, S. Turner, and M. Itzkowitz, </author> <title> Per formance Analysis Using the MIPS R10000 Perfor mance Counters, </title> <booktitle> Proc. Supercomputing 96, IEEE Computer Society, </booktitle> <month> November </month> <year> 1996. </year>
Reference-contexts: We might, for example, need to track secondary data cache miss behavior. To do this, TAU provides access to hardware performance counters in the CPU. On an SGI/Cray Origin 2000, we accessed the performance counters on the R10000 CPU via the Perfex API <ref> [23] </ref>. The TAU profiling library was configured to use hardware counters, rather than the clock, and the results displayed as before with pprof and Racy tools.
References-found: 23

