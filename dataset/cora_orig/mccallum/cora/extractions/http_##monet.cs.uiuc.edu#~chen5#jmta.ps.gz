URL: http://monet.cs.uiuc.edu/~chen5/jmta.ps.gz
Refering-URL: http://monet.cs.uiuc.edu/~chen5/
Root-URL: http://www.cs.uiuc.edu
Email: klarag@cs.uiuc.edu  
Title: Adaptive versus Reservation-based Synchronization Protocols Analysis and Comparison  
Author: Hung-Shiun Alex Chen, Lintian Qiao, Klara Nahrstedt 
Address: fchen5, l-qiao,  
Affiliation: Department of Computer Science University of Illinois at Urbana-Champaign  
Abstract: With the expansion of distributed multimedia applications, such as video-phone, video-conference, and video-on-demand, synchronization among various media (time-dependent, time-independent) becomes an integral part of various protocols, mechanisms and services in the underlying computing and communication systems. The current systems allow and provide two different resource management environments where synchronization will be considered: (1) best effort resource management, and (2) reservation-based resource management with differentiation of service classes. Under these two resource management environments, our goal is to analyze and compare the design, implementation, and performance of synchronization protocols and services. Our approach to accomplish this complex analysis is inductive, because we select a representative protocol from each group, and consider an adaptive synchronization protocol on top of the best effort resource management and a reservation-based synchronization protocol on top of the reservation-based resource management. We believe that both protocols include a rich set of known synchronization algorithms and mechanisms, hence our resulting analysis and comparison show: (1) trade-offs/difference in design complexity of the synchronization protocols (space and time), (2) trade-offs/difference in implementation complexity of the synchronization protocols (space and time), and (3) magnitude of performance changes. 
Abstract-found: 1
Intro-found: 1
Reference: [AFKN95] <author> R. T. Apteker, J. A. Fisher, V. S. Kisimov, and H. Neishlos. </author> <title> Video Acceptability and Frame Rate. </title> <booktitle> IEEE Multimedia, </booktitle> <address> FALL:32-40, </address> <year> 1995. </year>
Reference-contexts: In both systems, we do not assume global synchronized clocks. 3.1.2 Lip Synchronization Specification To address the lip synchronization problem within an adaptive application there are two important observations to note: First, human perception of changing sampling rate depends on the media. According to the experimental results in <ref> [AFKN95] </ref>, reducing video frame rate from the normal rate 30 fps to even 10 fps is acceptable, especially in a multitasking window-based environment. However, we cannot decrease audio streams by this factor since the human ear is much more sensitive to the perceptual medium quality than the human eye.
Reference: [AH91] <author> D.P. Anderson and G. Homsy. </author> <title> A Continuous Media I/O Server and its Synchronization Mechanism. </title> <journal> IEEE Computer, </journal> <volume> 24(10) </volume> <pages> 51-57, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: From the synchronization specification, the internal system derives presentation sched-ulers and local synchronizers. Examples of systems which include this type of schedulers are MODE [Bla93], multimedia teleorchestra [LKG94], continuous media I/O server <ref> [AH91] </ref> or ACME [AH91] systems. These 1 The objective was not to come up with new synchronization mechanisms/algorithms, but to take existing algorithms and do a thorough trade-off analysis in different environments. <p> From the synchronization specification, the internal system derives presentation sched-ulers and local synchronizers. Examples of systems which include this type of schedulers are MODE [Bla93], multimedia teleorchestra [LKG94], continuous media I/O server <ref> [AH91] </ref> or ACME [AH91] systems. These 1 The objective was not to come up with new synchronization mechanisms/algorithms, but to take existing algorithms and do a thorough trade-off analysis in different environments.
Reference: [Bla93] <author> G. Blakowski. </author> <title> Development and Runtime Support for Distributed Multimedia Applications. </title> <publisher> Verlag Shaker, </publisher> <address> German edition, </address> <year> 1993. </year>
Reference-contexts: Known synchronization specifications are time-axis based specification, timed petri nets, interval-based specification, or time flow graphs ([SN95, Lit93, LKG94, WR94, PLL96], etc.). From the synchronization specification, the internal system derives presentation sched-ulers and local synchronizers. Examples of systems which include this type of schedulers are MODE <ref> [Bla93] </ref>, multimedia teleorchestra [LKG94], continuous media I/O server [AH91] or ACME [AH91] systems. These 1 The objective was not to come up with new synchronization mechanisms/algorithms, but to take existing algorithms and do a thorough trade-off analysis in different environments.
Reference: [CN97] <author> H-H. Chu and K. Nahrstedt. </author> <title> Memory Management for Soft Real-Time Multimedia Applications. </title> <type> Technical report, CS, </type> <institution> University of Illinois, Urbana, IL, </institution> <month> October </month> <year> 1997. </year>
Reference-contexts: We have such a solution <ref> [CN97, CN98] </ref> and we use it in this paper together with underlying ATM reservation approach to generate an end-to-end reservation-based environment. Without the CPU (OS) reservation, one gets only reservation-based service at the network level (using RSVP or ATM), which does not provide an end-to-end reservation-based solution.
Reference: [CN98] <author> H-H. Chu and K. Nahrstedt. </author> <title> CPU Service Classes for Multimedia Applications. </title> <type> Technical Report UIUCDCS-R-98-2068, CS, </type> <institution> University of Illinois, Urbana, IL, </institution> <month> August </month> <year> 1998. </year>
Reference-contexts: We have such a solution <ref> [CN97, CN98] </ref> and we use it in this paper together with underlying ATM reservation approach to generate an end-to-end reservation-based environment. Without the CPU (OS) reservation, one gets only reservation-based service at the network level (using RSVP or ATM), which does not provide an end-to-end reservation-based solution.
Reference: [CTCL95] <author> Z. Chen, S-M. Tan, R.H. Campbell, and Y. Li. </author> <title> Real Time Video and Audio in the World Wide Web. </title> <note> In WWW 95, </note> <year> 1995. </year>
Reference-contexts: With the compression of video streams, the intra-stream synchronization must be controlled closer. Ran-gan [RKR96] discusses the continuity and synchronization issues in MPEG compressed video streams. There exist services/protocols for support of video or audio communication such as vat, nv, vic, VDP <ref> [Moo94, CTCL95, RRV93] </ref>, and others. However, these protocols do not yet support lip synchronization. <p> An example of the best-effort environment is the Internet network with Unix OS support at the end-points. Various adaptive transmission protocols are deployed on top of the type of environment such as the VDP (Video Datagram Protocol) <ref> [CTCL95] </ref>, vat (adaptive video/audio protocol) [JM92], and others. * Reservation-based Environment In the reservation-based environment the network and OS use reservation, admission and enforcement algorithms to provide end-to-end QoS guarantees. In this case, the application does minimal work in QoS provision and relies heavily on the underlying QoS provision.
Reference: [EDP92] <author> J. Escobar, D. Deutsch, and C. Partridge. </author> <title> Flow Synchronization Protocol. </title> <booktitle> In Proceedings of IEEE Globecom, </booktitle> <pages> pages 1381-1387, </pages> <year> 1992. </year> <note> vol. 3. 30 </note>
Reference-contexts: SDS performs the synchronization recovery at the multimedia receiver before the playback and employs the synchronization parameters to guarantee the control for the different types of data streams. The protocol-based synchronization techniques must deal with system changes such as network delays. Escobar's flow synchronization protocol <ref> [EDP92] </ref> takes into account the dynamic changes in network delays by monitoring the jitter and re-synchronizing at the receiver if necessary. However, it assumes the presence of global clock in a distributed environment at all time. Similar approach is taken in the Rothemel's adaptive synchronization protocol [RH97].
Reference: [JM92] <author> V. Jacobson and S. McCanne. vat, </author> <title> Video Audio Tool. UNIX manual page, </title> <year> 1992. </year>
Reference-contexts: An example of the best-effort environment is the Internet network with Unix OS support at the end-points. Various adaptive transmission protocols are deployed on top of the type of environment such as the VDP (Video Datagram Protocol) [CTCL95], vat (adaptive video/audio protocol) <ref> [JM92] </ref>, and others. * Reservation-based Environment In the reservation-based environment the network and OS use reservation, admission and enforcement algorithms to provide end-to-end QoS guarantees. In this case, the application does minimal work in QoS provision and relies heavily on the underlying QoS provision.
Reference: [Lit93] <author> T. D. C. Little. </author> <title> A Framework for Synchronous Delivery of Time-Dependent Multimedia Data. </title> <journal> Multimedia Systems, </journal> <volume> 1(2) </volume> <pages> 87-94, </pages> <year> 1993. </year>
Reference: [LKG94] <author> L. Li, A. Karmouch, and N. Georganas. </author> <title> Multimedia Tele-orchestra with Independent Sources: Part 2 Synchronization Algorithm. </title> <journal> Multimedia Systems, </journal> <volume> 1(4) </volume> <pages> 154-165, </pages> <year> 1994. </year>
Reference-contexts: Known synchronization specifications are time-axis based specification, timed petri nets, interval-based specification, or time flow graphs ([SN95, Lit93, LKG94, WR94, PLL96], etc.). From the synchronization specification, the internal system derives presentation sched-ulers and local synchronizers. Examples of systems which include this type of schedulers are MODE [Bla93], multimedia teleorchestra <ref> [LKG94] </ref>, continuous media I/O server [AH91] or ACME [AH91] systems. These 1 The objective was not to come up with new synchronization mechanisms/algorithms, but to take existing algorithms and do a thorough trade-off analysis in different environments. <p> Nicolaou's scheme [Nic90] identifies two levels of data elements for defining synchronization points. The logical synchronization frames (LSF) are defined as the unit of synchronization for the control application while physical synchronization frames (PSF) are for the communication subsystem. Li <ref> [LKG94] </ref> presents a multimedia segment delivery scheme (SDS) for the simultaneous delivery of multimedia streams belonging to the same time interval. SDS performs the synchronization recovery at the multimedia receiver before the playback and employs the synchronization parameters to guarantee the control for the different types of data streams.
Reference: [Moo94] <author> G. Moon. </author> <title> New video and multimedia products. Internet Electronic Mail, </title> <month> February </month> <year> 1994. </year> <title> from rem-conf&.es.net news group. </title>
Reference-contexts: With the compression of video streams, the intra-stream synchronization must be controlled closer. Ran-gan [RKR96] discusses the continuity and synchronization issues in MPEG compressed video streams. There exist services/protocols for support of video or audio communication such as vat, nv, vic, VDP <ref> [Moo94, CTCL95, RRV93] </ref>, and others. However, these protocols do not yet support lip synchronization.
Reference: [NCN98] <author> K. Nahrstedt, H. Chu, and S. Narayan. </author> <title> QoS-aware Resource Management for Distributed Multimedia Applications. </title> <note> to appear in IOS Journal on High-Speed Networking, </note> <year> 1998. </year>
Reference-contexts: One protocol is the adaptive synchronization protocol which works in the best effort Internet/UNIX environment. The second protocol is the reservation-based synchronization protocol which works on top of the QualMan environment, comprising a QoS-aware resource management with provision of reservation for CPU, memory and bandwidth resources <ref> [NCN98] </ref>. The results of this paper show and experimentally validate the difficult spots and the intuitive properties of synchronization behavior in both environments. The paper is divided as follows: Section 2 presents extensive related work in the area of synchronization, and Section 3 discusses the design of both protocols. <p> An example of this kind of environment is the ATM network with QoS-aware resource management in the OS kernel (e.g., Mach OS) [RJMO98] or in the middleware using real-time extension of an OS kernel (e.g., QualMan System) 3 <ref> [NCN98] </ref>. Various experimental transmission protocols are deployed in this type of system such as the native ATM transport protocol in QualMan [NCN98]. <p> ATM network with QoS-aware resource management in the OS kernel (e.g., Mach OS) [RJMO98] or in the middleware using real-time extension of an OS kernel (e.g., QualMan System) 3 <ref> [NCN98] </ref>. Various experimental transmission protocols are deployed in this type of system such as the native ATM transport protocol in QualMan [NCN98]. <p> In Section 3.1. we present the design of our adaptive synchronization protocol in the best-effort environment. In Section 3.2. we discuss the design of the reservation-based synchronization protocol which runs on top of the ATM high-speed network and the QoS-aware resource management, called QualMan <ref> [NCN98] </ref>, developed at University of Illinois, Urbana-Champaign. <p> The CPU server provides a scheme for real-time multimedia applications to reserve their CPU usage in the form of (period, CPU usage in percentage). A profile of the CPU usage percentage for various video/audio average frame sizes and frame rates is created o*ine using probing <ref> [NCN98] </ref> and is used as the seed. In addition, QoS-aware memory allocation is introduced to minimize the frequency of the page fault for continuous media to provide predictable CPU execution times.
Reference: [Nic90] <author> C. Nicolaou. </author> <title> An Architecture for Real-Time Multimedia Communication Systems. </title> <journal> IEEE JSAC, </journal> <volume> 8 </volume> <pages> 391-400, </pages> <month> April </month> <year> 1990. </year>
Reference-contexts: Within a distributed environment, protocol-based techniques are applied. Shepherd's scheme [SS90] suggests two different techniques for inter-stream synchronization, the synchronization marker (SM) for indication of synchronization points and the synchronization channel. The synchronization markers are transmitted over a separate synchronization channel. Nicolaou's scheme <ref> [Nic90] </ref> identifies two levels of data elements for defining synchronization points. The logical synchronization frames (LSF) are defined as the unit of synchronization for the control application while physical synchronization frames (PSF) are for the communication subsystem.
Reference: [NQ96] <author> K. Nahrstedt and L. Qiao. </author> <title> A Tuning System for Distributed Multimedia Applications. </title> <type> Technical Report UIUCDCS-R-96-1958, CS, </type> <institution> University of Illinois, Urbana, IL, </institution> <month> May </month> <year> 1996. </year>
Reference-contexts: This rate is important because of synchronization between audio and video streams. (2) The system rate is the rate that the system can actually provide. It is initially determined during the call establishment phase where we use probe-based algorithm <ref> [NQ96] </ref>. This algorithm uses a probe a continuous clip from the beginning of the stream to determine what is the possible system rate at the client side. <p> If it's not sufficient, we apply the same strategy to P frames and then I frames. This also implies a B, P, I priority in increasing order. The algorithm's details and experimental validation in UNIX/Internet environment are described in <ref> [NQ96] </ref>. 3.2.3 Lip Synchronization Specification As described in Section 3.1.2, we set as a policy that no intentional adaptation of MPEG-1 compressed audio data will be considered in our scheme. When less system resources are available, only MPEG-1 compressed video data are to be dropped. <p> The monitoring and adaptation services at the server and client side are tightly coupled in a tuning system and create a complex adaptive/feedback control loop to adapt against changes introduced by the user, by the network/OS, or between application resources available during recording and playback phases <ref> [NQ96] </ref>. 4.2.2 Experimental Setup The underline network for testing our adaptive synchronization scheme is our departmental network which is 10 Mbps Ethernet with about 200 machines on. The tests are conducted in the later evening hours when the network is lightly loaded. <p> Extensive tests and results are shown in <ref> [NQ96] </ref>. The second clip (lect-iso.mpg and lect-iso.mp2) is played in black-and-white color.
Reference: [NQ97] <author> K. Nahrstedt and L. Qiao. </author> <title> Stability and Adaptation Control for Lip Synchronization Skews. </title> <note> Submitted to Journal of Multimedia Systems, </note> <year> 1997. </year>
Reference-contexts: With the adaptive control theory, we can show that the jitter is bounded <ref> [NQ97] </ref>. Furthermore, the synchronization skew s (t) between audio and video is also bounded. In fact, it can be showed [NQ97] that s (t) = j (t) = r s (t) 1 (2) Intuitively, the skew of current frame can be expressed as the skew of previously displayed frame plus the <p> With the adaptive control theory, we can show that the jitter is bounded <ref> [NQ97] </ref>. Furthermore, the synchronization skew s (t) between audio and video is also bounded. In fact, it can be showed [NQ97] that s (t) = j (t) = r s (t) 1 (2) Intuitively, the skew of current frame can be expressed as the skew of previously displayed frame plus the jitter that the system introduces by processing the current frame.
Reference: [Org93] <author> International Standards Organization. </author> <title> Information technology Coding of Moving Pictures and Associated Audio for Digital Storage Media at up to about 1.5 mbit/s Part 1: </title> <journal> Systems. </journal> <note> International Standard ISO/IEC IS 11172-1, </note> <year> 1993. </year>
Reference-contexts: When less system resources are available, only MPEG-1 compressed video data are to be dropped. MPEG-1 system standard ISO/IEC 11172-1 <ref> [Org93] </ref> specifies synchronization relations between audio and video objects, but it cannot be used in our approach.
Reference: [PLL96] <author> M. J. Perez-Luque and T. D. C. Little. </author> <title> A Temporal Reference Framework for Multimedia Synchronization. </title> <journal> Journal on Selected Areas in Communication, </journal> <volume> 14(1) </volume> <pages> 36-51, </pages> <month> January </month> <year> 1996. </year>
Reference: [RH97] <author> K. Rothemel and T. Helbig. </author> <title> An Adaptive Protocol for Synchronizing Media Streams. </title> <journal> Proc. of the IEEE, </journal> <volume> 5(5) </volume> <pages> 324-336, </pages> <year> 1997. </year>
Reference-contexts: However, it assumes the presence of global clock in a distributed environment at all time. Similar approach is taken in the Rothemel's adaptive synchronization protocol <ref> [RH97] </ref>. Another approach to re-synchronize is to send feedback. An example is Ramanathan's feedback technique [RVR92]. The multimedia server provides distribution of video streams over BISDN to mediaphones which are devices that have minimum capability to playback media and lack the sophistication to run any type of synchronization mechanism. <p> This is not necessary in our case, because our algorithm sends back rate change information only when the network or computer load change. Rothermel and Helbig's "Adaptive Protocol for Synchronization Media Streams" <ref> [RH97] </ref> is also interesting, and we compare it with our adaptive scheme. We refer to their protocol as R&H Protocol.
Reference: [RJMO98] <author> R. Rajkumar, K. Juvva, A. Molano, and S. Oikawa. </author> <title> Resource kernels: A resource-centric approach to real-time systems. </title> <booktitle> In Proceedings of the SPIE/ACM Conference on Multimedia Computing and Networking, </booktitle> <month> January </month> <year> 1998. </year>
Reference-contexts: In this case, the application does minimal work in QoS provision and relies heavily on the underlying QoS provision. An example of this kind of environment is the ATM network with QoS-aware resource management in the OS kernel (e.g., Mach OS) <ref> [RJMO98] </ref> or in the middleware using real-time extension of an OS kernel (e.g., QualMan System) 3 [NCN98]. Various experimental transmission protocols are deployed in this type of system such as the native ATM transport protocol in QualMan [NCN98].
Reference: [RKR96] <author> P. V. Rangan, S. S. Kumar, , and S. Rajan. </author> <title> Continuity and Synchronization in Mpeg. </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> 14(1) </volume> <pages> 52-60, </pages> <month> January </month> <year> 1996. </year>
Reference-contexts: The intra-stream and inter-stream synchronization are maintained by mediaphone's sending feedback units (lightweight messages) to the server. Bounded buffering and feedback from all devices are used for inter-media synchronization. With the compression of video streams, the intra-stream synchronization must be controlled closer. Ran-gan <ref> [RKR96] </ref> discusses the continuity and synchronization issues in MPEG compressed video streams. There exist services/protocols for support of video or audio communication such as vat, nv, vic, VDP [Moo94, CTCL95, RRV93], and others. However, these protocols do not yet support lip synchronization. <p> MPEG-1 system standard ISO/IEC 11172-1 [Org93] specifies synchronization relations between audio and video objects, but it cannot be used in our approach. The reason is that our adaptive scheme manipulates video streams at their frame level, and the interleaving and packetizing structure <ref> [RKR96] </ref> of MPEG-1 system standard would require that we introduce too much overhead to access individual video frames.
Reference: [RRV93] <author> S. Ramanathan, P. V. Rangan, and H.M. Vin. </author> <title> Frame-Induced Packet Discarding: An Efficient Strategy for Video Networking. </title> <booktitle> In Proceedings of 4th NOSSDAV, </booktitle> <address> Lancaster, England, </address> <month> Nov </month> <year> 1993. </year>
Reference-contexts: With the compression of video streams, the intra-stream synchronization must be controlled closer. Ran-gan [RKR96] discusses the continuity and synchronization issues in MPEG compressed video streams. There exist services/protocols for support of video or audio communication such as vat, nv, vic, VDP <ref> [Moo94, CTCL95, RRV93] </ref>, and others. However, these protocols do not yet support lip synchronization.
Reference: [RS92] <author> L. A. Rowe and B. C. Smith. </author> <title> Continuous Media Player. </title> <booktitle> In Proceedings of 3rd NOSSDAV, </booktitle> <address> San Diego, CA, </address> <month> November </month> <year> 1992. </year>
Reference-contexts: The OS load includes the existing load of the shared UNIX workstation and the additional video transmission load. 4.1 MPEG Audio and Video Benchmarks We have selected two representative movies to show our results. MPEG-1 video stream is decoded using software-based MPEG decoder based on Berkeley's MPEG-Player <ref> [RS92] </ref>. The decoded MPEG-1 audio stream is sent to audio device which then fully controls the playback of audio data in its buffer (audio device buffer, different from the client audio ring buffer).
Reference: [RVR92] <author> P. V. Rangan, H.M. Vin, and S. Ramanathan. </author> <title> Designing an On-Demand Multimedia Service. </title> <journal> IEEE Communications Magazine, </journal> <volume> 30(7) </volume> <pages> 56-65, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: However, it assumes the presence of global clock in a distributed environment at all time. Similar approach is taken in the Rothemel's adaptive synchronization protocol [RH97]. Another approach to re-synchronize is to send feedback. An example is Ramanathan's feedback technique <ref> [RVR92] </ref>. The multimedia server provides distribution of video streams over BISDN to mediaphones which are devices that have minimum capability to playback media and lack the sophistication to run any type of synchronization mechanism.
Reference: [SCFJ94] <author> H. Schulzrinne, S. Casner, R. Frederick, and V. Jacobson. RTP: </author> <title> A Transport Protocol for Real-Time Applications. Internet Draft of IETF Working Draft, </title> <month> July 18 </month> <year> 1994. </year>
Reference-contexts: The skew frequency probabilities during the playback are shown in Figure 14. 4.2.4 Discussion There exist some protocols today suitable for distributed real-time video/audio applications, such as RTP and RTCP. RTP <ref> [SCFJ94] </ref> is an end-to-end protocol based on UDP/IP to deliver the multimedia data and is primarily designed to satisfy the needs of multi-party multimedia conferences. A header containing a timestamp and sequence number is added to each UDP packet. It also has functions of payload type, framing, and source identification.
Reference: [SN95] <author> R. Steinmetz and K. Nahrstedt. Multimedia:Computing, </author> <title> Communications, and Applications. </title> <publisher> Prentice Hall, Inc., </publisher> <year> 1995. </year>
Reference-contexts: We will also compare some reported protocols with our schemes. The major requirements for audio/video synchronization in multimedia systems are bounded jitters within a continuous stream, and minimal and acceptable skews among dependent streams. Steinmetz's experiments <ref> [SN95] </ref> measured audio-visual skews within an analog environment that are perceived as "out-of-sync". A desired lip synchronization skew should be 80 ms. Between 80 ms and 160 ms the skew was found acceptable. However, beyond 160 ms skew is perceived as annoying. <p> For specification of the synchronization relation we use the time-axes-based specification. It is a simple but effective way to provide good synchronization abstraction for media contents. All single medium objects are attached to a time axis that presents an abstraction of real-time <ref> [SN95] </ref>. During the recording phase, each audio and video LDU (Logical Data Unit) is time-stamped 2 with the starting playout time within the stream. Due to the audio loss sensitivity, audio stream is used as the time-axis divider and the master stream to control the playout. <p> For the waiting operation, we follow the concept of Restricted Blocking which was introduced by Steinmetz <ref> [SN95] </ref>.
Reference: [SS90] <author> M. Salmony and D. Shepherd. </author> <title> Extending OSI to Support Synchronization Required by Multimedia Applications. </title> <journal> Computer Communication, </journal> <volume> 13 </volume> <pages> 399-406, </pages> <month> September </month> <year> 1990. </year> <month> 31 </month>
Reference-contexts: Within a distributed environment, protocol-based techniques are applied. Shepherd's scheme <ref> [SS90] </ref> suggests two different techniques for inter-stream synchronization, the synchronization marker (SM) for indication of synchronization points and the synchronization channel. The synchronization markers are transmitted over a separate synchronization channel. Nicolaou's scheme [Nic90] identifies two levels of data elements for defining synchronization points.
Reference: [WR94] <author> T. Wahl and K. Rothermel. </author> <title> Representing Time in Multimedia Systems. </title> <booktitle> In Proceedings of Multi--media Computing and Systems, </booktitle> <pages> pages 538-543, </pages> <address> Boston,MA, </address> <month> May </month> <year> 1994. </year>
Reference: [ZF94] <author> H. Zhang and D. Ferrari. </author> <title> Improving Utilization for Deterministic Service In Multimedia Communication. </title> <booktitle> In International Conference on Multimedia Computing and Systems, </booktitle> <address> Boston MA, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: We do not discuss schedulers on the switches because our focus is on the end system design. The service discipline operating on the ATM switches may range from a simple FCFS (First Come First Serve) to a more complex one with an algorithmically defined priority-based service. <ref> [ZF94] </ref> showed that even for a simple service discipline like FCFS, deterministic delay bounds can be obtained with provision of resource 5 The CPU reservation can be made for arbitrary units of scheduling.
References-found: 28

