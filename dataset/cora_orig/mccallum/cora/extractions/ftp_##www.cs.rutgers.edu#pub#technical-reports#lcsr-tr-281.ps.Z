URL: ftp://www.cs.rutgers.edu/pub/technical-reports/lcsr-tr-281.ps.Z
Refering-URL: http://www.cs.rutgers.edu/pub/technical-reports/
Root-URL: 
Title: Integrating Qualitative and Quantitative Object Representations in the Recovery and Tracking of 3-D Shape Psychophysical
Author: Sven J. Dickinson Dimitri Metaxas 
Note: To appear in: L. Harris and M. Jenkin (eds.), Computational and  
Address: New Brunswick, NJ 08903  Philadelphia, PA 19104-6389  Press, New York, NY.  
Affiliation: Department of Computer Science and Rutgers Center for Cognitive Science (RuCCS) Rutgers University  Department of Computer and Information Science University of Pennsylvania  Cambridge University  
Abstract: Data-driven models such as active contours in 2-D and deformable surfaces in 3-D have become prevalent in the computer vision community, particularly in the areas of shape tracking and shape recovery. They provide an important alternative to typical model-based recognition and tracking approaches that assume knowledge of the exact geometry of the object. Despite the power of these approaches, data-driven models often encode too little model information. As a consequence, active 3-D model recovery schemes often require manual segmentation or good model initialization, and active contour trackers have been able to track only an object's translation in the image. To overcome these problems requires bridging the representational gap between overconstrained geometric models and underconstrained active models. In previous work, we introduced a qualitative object representation integrating object-centered and viewer-centered models. In this paper, we first show how this representation provides the missing constraints on the recovery of quantitative 3-D deformable models from 2-D images. We then show how this same representation provides the missing constraints needed to quali tatively track an object's rotation in depth or to quantitatively track an object's pose. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Barr. </author> <title> Superquadrics and angle-preserving transformations. </title> <journal> IEEE Computer Graphics and Applications, </journal> <volume> 1 </volume> <pages> 11-23, </pages> <year> 1981. </year>
Reference-contexts: We first consider the case of superquadric ellipsoids <ref> [1] </ref>, which are given by the following formula: e = a B a 1 C u * 2 * 1 S v a 3 S u 1 A ; (6) where =2 u =2 and v &lt; , and where S w * = sgn (sin w)j sin wj * and
Reference: [2] <author> I. Biederman. </author> <title> Human image understanding: Recent research and a theory. Computer Vision, </title> <journal> Graphics, and Image Processing, </journal> <volume> 32 </volume> <pages> 29-73, </pages> <year> 1985. </year>
Reference-contexts: Their choice was inspired by a set of 5 volumetric shapes (called geons) proposed by the psychologist, Biederman, as a set of shapes which the human visual system could quickly recover from a 2-D image, and which were rich enough to describe a large number of everyday objects <ref> [2] </ref>. Unlike Biederman, however, we do not restrict our representation to geons; we borrow only the notion of a finite set of qualitatively-defined volumetric parts used to build objects. It is at the volumetric part modeling level, that we invoke the concept of viewer-centered modeling. <p> The probabilities are estimated from a frequency analysis of features viewed over a sampled viewing sphere centered on each of the volumetric classes. To demonstrate our techniques for shape recovery, object recognition, and tracking, we have selected an object representation similar to that used by Biederman <ref> [2] </ref>, in which the Cartesian product of contrastive shape properties gives rise to a set of volumetric primitives called geons. For our investigation, we have chosen three properties including cross-section shape, axis shape, and cross-section size variation [14].
Reference: [3] <author> T. J. Broida, S. Chandrashekhar, and R. Chellappa. </author> <title> Recursive 3-D motion estimation from a monocular image sequence. </title> <journal> IEEE Transactions on Aerospace and Electronic Systems, </journal> <volume> 26(4) </volume> <pages> 639-656, </pages> <year> 1990. </year>
Reference-contexts: from stereo images are sufficient to update the positions, orientations, and shapes of the models in 3-D; no costly feature extraction or correspondence is necessary. 4.2.1 Tracking and Prediction Kalman filtering techniques have been applied in the vision literature for the estimation of dynamic features [8] and rigid motion parameters <ref> [17, 3] </ref> of objects from image sequences. We use a Kalman filter to estimate the object's shape and motion in a sequence of images.
Reference: [4] <author> M. Chan, D. Metaxas, and S. Dickinson. </author> <title> A new approach to tracking 3-D objects in 2-D image sequences. </title> <booktitle> In Proceedings, AAAI '94, </booktitle> <address> Seattle, WA, </address> <month> August </month> <year> 1994. </year>
Reference-contexts: We are currently investigating the use of repulsion forces that would more effectively prevent network contours from converging. 4.2 Quantitative Object Tracking Our approach to quantitative tracking <ref> [4, 5] </ref> makes use of our frameworks for qualitative and quantitative shape recovery described in previous sections, as well as a physics-based framework for quantitative motion estimation [30].
Reference: [5] <author> M. Chan, D. Metaxas, and S. Dickinson. </author> <title> Physics-based tracking of 3-D objects in 2-D image sequences. </title> <booktitle> In Proceedings, 12 International Conference on Pattern Recognition, </booktitle> <pages> pages 326-330, </pages> <address> Jerusalem, Israel, </address> <month> October </month> <year> 1994. </year>
Reference-contexts: We are currently investigating the use of repulsion forces that would more effectively prevent network contours from converging. 4.2 Quantitative Object Tracking Our approach to quantitative tracking <ref> [4, 5] </ref> makes use of our frameworks for qualitative and quantitative shape recovery described in previous sections, as well as a physics-based framework for quantitative motion estimation [30].
Reference: [6] <author> R. Cipolla and A. Blake. </author> <title> Motion planning using image divergence and deformation. </title> <editor> In A. Blake and A. Yuille, editors, </editor> <booktitle> Active Vision, </booktitle> <pages> pages 189-201. </pages> <publisher> MIT Press, </publisher> <year> 1992. </year>
Reference-contexts: For example, if the dimensions or curvature of an object part changes, a new object model must be added. In the tracking domain, a similar continuum exists. Purely data-driven approaches, as shown in 2-D translation can be recovered and, in some cases, translation in depth (e.g., <ref> [6] </ref>), lack of any model information prevents the recovery of rotation in depth. At the other extreme, as shown in but require an exact specification of the object's geometry, and cannot support non-rigid object tracking, e.g., [27, 18, 39, 40].
Reference: [7] <author> R. Curven, A. Blake, and R. Cipolla. </author> <title> Parallel implementation of Lagrangian dynamics for real-time snakes. </title> <booktitle> In Proceedings, British Machine Vision Conference (BMVC '91), </booktitle> <pages> pages 27-35, </pages> <month> September </month> <year> 1991. </year>
Reference: [8] <author> R. Deriche and O. Faugeras. </author> <title> Tracking line segments. </title> <journal> Image and Vision Computing, </journal> <volume> 8(4) </volume> <pages> 261-270, </pages> <year> 1990. </year> <title> (a) (b) (e) (f) image potentials of an intermediate frame (both occlusions and visual events have occurred), (c-f) each object part correctly tracked with part models overlaid on the image potentials. Note that only the active model nodes are marked. </title>
Reference-contexts: between frames, local forces derived from stereo images are sufficient to update the positions, orientations, and shapes of the models in 3-D; no costly feature extraction or correspondence is necessary. 4.2.1 Tracking and Prediction Kalman filtering techniques have been applied in the vision literature for the estimation of dynamic features <ref> [8] </ref> and rigid motion parameters [17, 3] of objects from image sequences. We use a Kalman filter to estimate the object's shape and motion in a sequence of images.
Reference: [9] <author> S. Dickinson. </author> <title> The recovery and recognition of three-dimensional objects using part-based aspect matching. </title> <type> Technical Report CAR-TR-572, </type> <institution> Center for Automation Research, University of Maryland, </institution> <year> 1991. </year>
Reference-contexts: The ambiguous mappings between the levels of the aspect hierarchy are captured in a set of upward and downward conditional probabilities, mapping boundary groups to faces, faces to aspects, and aspects to volumes <ref> [9] </ref>. The probabilities are estimated from a frequency analysis of features viewed over a sampled viewing sphere centered on each of the volumetric classes.
Reference: [10] <author> S. Dickinson, H. Christensen, J. Tsotsos, and G. Olofsson. </author> <title> Active object recognition integrating attention and viewpoint control. </title> <booktitle> In Proceedings, </booktitle> <address> ECCV '94, Stockholm, Sweden, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: However, if we need to recover a more accurate, quantitative shape description for subclass recognition or for grasping, then a qualitative description is insufficient. In the following two subsections, we first outline an approach to qualitative shape recovery using the aspect hierarchy <ref> [16, 15, 10] </ref>. <p> Next, we show how the recovered aspects, along with the recovered qualitative shape, can be used to constrain a physics-based deformable model recovery process that will yield the quantitative shapes of the object's parts [12, 13]. 3.1 Qualitative Shape Recovery An analysis of the conditional probabilities in the aspect hierarchy <ref> [16, 10] </ref> suggests that for 3-D modeling primitives which resemble the commonly used generalized cylinders, superquadrics, or geons, the most appropriate image features for recognition appear to be image regions, or faces. <p> When such an event is detected, a signal describing the event is sent to the symbolic tracker. 4.1.2 Symbolic Tracker The symbolic tracker tracks movement from one node to another in a representation called the aspect prediction graph <ref> [10] </ref>. Each of the nodes in this representation, derived from an aspect graph [22] and the aspect hierarchy, represents a topologically different viewpoint of the object, while arcs between nodes specify the visual events or changes in image topology between nodes. The role of the symbolic tracker is to: 1. <p> Our goal has been to explore a number of closely-related object recognition behaviors that must be addressed by an active agent in a dynamic environment. Our object representation has so far provided a common framework for novel algorithms for these and other behaviors (e.g., active object recognition <ref> [10] </ref>). We continue to refine these algorithms while at the same time attempting to work with more complex scenes containing more realistic objects. 6 Acknowledgements The support of the National Science Foundation (Sven Dickinson: NSF CAREER IRI-9623913; Dimitri Metaxas: NSF IRI-93-09917, NSF CAREER IRI-9624604) is gratefully acknowledged.
Reference: [11] <author> S. Dickinson, P. Jasiobedzki, H. Christensen, and G. Olofsson. </author> <title> Qualitative tracking of 3-D objects using active contour networks. </title> <booktitle> In Proceedings, IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <address> Seattle, </address> <month> June </month> <year> 1994. </year>
Reference-contexts: In the following subsections, we outline our approach to each of these problems. 4.1 A Qualitative Tracker Our approach to qualitative object tracking, as shown in Figure 12, combines a symbolic tracker and an image tracker <ref> [11] </ref>. Just as we used a qualitative shape model to govern a data-driven shape recovery process, we will use the same qualitative shape model to govern a data-driven shape tracking process. 4.1.1 Image Tracker The image tracker employs a representation called an adaptive adjacency graph, or AAG.
Reference: [12] <author> S. Dickinson and D. Metaxas. </author> <title> Integrating qualitative and quantitative shape recovery. </title> <journal> International Journal of Computer Vision, </journal> <volume> 13(3) </volume> <pages> 1-20, </pages> <year> 1994. </year>
Reference-contexts: Geometrically, these quantitative shape models are closed surfaces in space whose intrinsic (material) coordinates are u = (u; v), defined on a domain <ref> [35, 12] </ref>. <p> Next, we show how the recovered aspects, along with the recovered qualitative shape, can be used to constrain a physics-based deformable model recovery process that will yield the quantitative shapes of the object's parts <ref> [12, 13] </ref>. 3.1 Qualitative Shape Recovery An analysis of the conditional probabilities in the aspect hierarchy [16, 10] suggests that for 3-D modeling primitives which resemble the commonly used generalized cylinders, superquadrics, or geons, the most appropriate image features for recognition appear to be image regions, or faces. <p> Details of the algorithm can be found in <ref> [29, 12] </ref>, while an extension of the technique to shape recovery from range data can be found in [13]. 3.2.1 Simplified Numerical Simulation When fitting the quantitative model to visual data, our goal is to recover q = (q &gt; c ; q &gt; s ; q &gt; vector of degrees
Reference: [13] <author> S. Dickinson, D. Metaxas, and A. Pentland. </author> <title> Constrained recovery of deformable models from range data. </title> <booktitle> In Proceedings, 2nd International Workshop on Visual Form, </booktitle> <address> Capri, Italy, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: Next, we show how the recovered aspects, along with the recovered qualitative shape, can be used to constrain a physics-based deformable model recovery process that will yield the quantitative shapes of the object's parts <ref> [12, 13] </ref>. 3.1 Qualitative Shape Recovery An analysis of the conditional probabilities in the aspect hierarchy [16, 10] suggests that for 3-D modeling primitives which resemble the commonly used generalized cylinders, superquadrics, or geons, the most appropriate image features for recognition appear to be image regions, or faces. <p> This technique was applied to the top-down recognition of multipart objects in <ref> [13] </ref>. Moving down the aspect hierarchy and guided by a Bayesian utility measure, target objects map to target volumes which, in turn, map to target aspect predictions which, in turn, map to target face predictions. <p> If the mapping from a verified aspect to a target volume is ambiguous, this attention mechanism can be used to drive an active recognition system which moves the camera to obtain a less ambiguous view of the volume <ref> [13] </ref>. <p> Details of the algorithm can be found in [29, 12], while an extension of the technique to shape recovery from range data can be found in <ref> [13] </ref>. 3.2.1 Simplified Numerical Simulation When fitting the quantitative model to visual data, our goal is to recover q = (q &gt; c ; q &gt; s ; q &gt; vector of degrees of freedom of the model.
Reference: [14] <author> S. Dickinson, A. Pentland, and A. Rosenfeld. </author> <title> A representation for qualitative 3-D object recognition integrating object-centered and viewer-centered models. </title> <editor> In K. Leibovic, editor, </editor> <title> Vision: A Convergence of Disciplines. </title> <publisher> Springer Verlag, </publisher> <address> New York, </address> <year> 1990. </year>
Reference-contexts: In order to meet the goals of qualitative object modeling and matching, we first model objects as object-centered constructions of qualitatively-defined volumetric parts chosen from some arbitrary, finite set <ref> [14] </ref>. The part classes are qualitative in the sense that they are invariant to degree of curvature, relative dimensions, degree of tapering, etc. <p> For our investigation, we have chosen three properties including cross-section shape, axis shape, and cross-section size variation <ref> [14] </ref>. The values of these properties give rise to a set of ten primitives (a subset of Biederman's geons), modeled using Pentland's SuperSketch 3-D modeling tool [31], and illustrated in Figure 5. Figure 6 illustrates a portion of the corresponding aspect hierarchy.
Reference: [15] <author> S. Dickinson, A. Pentland, and A. Rosenfeld. </author> <title> From volumes to views: An approach to 3-D object recognition. CVGIP: </title> <booktitle> Image Understanding, </booktitle> <volume> 55(2) </volume> <pages> 130-154, </pages> <year> 1992. </year>
Reference-contexts: However, if we need to recover a more accurate, quantitative shape description for subclass recognition or for grasping, then a qualitative description is insufficient. In the following two subsections, we first outline an approach to qualitative shape recovery using the aspect hierarchy <ref> [16, 15, 10] </ref>. <p> A search through the space of aspect hypotheses for a covering of the regions of the image is guided by a heuristic based on the conditional probabilities in the aspect hierarchy <ref> [16, 15] </ref>. During the search process, aspect verification, like face matching, is accomplished through the use of an interpretation tree search [19]. <p> This time, we search through the space of volume hypotheses until we find a set of volumes that is consistent with the objects in the database <ref> [16, 15] </ref>. 2 See Dickinson et al. [16] for a discussion on how parallelism and symmetry are computed. 10 3.1.2 Expected Object Recognition In an expected or top-down object recognition domain, in which we are searching for a particular object or part, we use the aspect hierarchy as an attention mechanism
Reference: [16] <author> S. Dickinson, A. Pentland, and A. Rosenfeld. </author> <title> 3-D shape recovery using distributed aspect matching. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 14(2) </volume> <pages> 174-198, </pages> <year> 1992. </year>
Reference-contexts: However, if we need to recover a more accurate, quantitative shape description for subclass recognition or for grasping, then a qualitative description is insufficient. In the following two subsections, we first outline an approach to qualitative shape recovery using the aspect hierarchy <ref> [16, 15, 10] </ref>. <p> Next, we show how the recovered aspects, along with the recovered qualitative shape, can be used to constrain a physics-based deformable model recovery process that will yield the quantitative shapes of the object's parts [12, 13]. 3.1 Qualitative Shape Recovery An analysis of the conditional probabilities in the aspect hierarchy <ref> [16, 10] </ref> suggests that for 3-D modeling primitives which resemble the commonly used generalized cylinders, superquadrics, or geons, the most appropriate image features for recognition appear to be image regions, or faces. <p> A search through the space of aspect hypotheses for a covering of the regions of the image is guided by a heuristic based on the conditional probabilities in the aspect hierarchy <ref> [16, 15] </ref>. During the search process, aspect verification, like face matching, is accomplished through the use of an interpretation tree search [19]. <p> This time, we search through the space of volume hypotheses until we find a set of volumes that is consistent with the objects in the database <ref> [16, 15] </ref>. 2 See Dickinson et al. [16] for a discussion on how parallelism and symmetry are computed. 10 3.1.2 Expected Object Recognition In an expected or top-down object recognition domain, in which we are searching for a particular object or part, we use the aspect hierarchy as an attention mechanism <p> This time, we search through the space of volume hypotheses until we find a set of volumes that is consistent with the objects in the database [16, 15]. 2 See Dickinson et al. <ref> [16] </ref> for a discussion on how parallelism and symmetry are computed. 10 3.1.2 Expected Object Recognition In an expected or top-down object recognition domain, in which we are searching for a particular object or part, we use the aspect hierarchy as an attention mechanism to focus the search for an aspect <p> The mnemonics, PN, PL, and PP, refer to primitive number (simply an enumeration of the primitives in the covering), primitive label (see Figure 5), and primitive probability, respectively. The mnemonics AN, AL, AP, and AS refer to the aspect number (an enumeration), aspect label (see <ref> [16] </ref>), aspect probability, and aspect score (how well aspect was verified), respectively. The mnemonics FN, FL, FP, and PS refer to face number (in image window), face label (see [16]), face probability, and corresponding primitive attachment surface (see [16]), respectively, for each component face of the aspect. <p> The mnemonics AN, AL, AP, and AS refer to the aspect number (an enumeration), aspect label (see <ref> [16] </ref>), aspect probability, and aspect score (how well aspect was verified), respectively. The mnemonics FN, FL, FP, and PS refer to face number (in image window), face label (see [16]), face probability, and corresponding primitive attachment surface (see [16]), respectively, for each component face of the aspect. The search window indicates the status of the aspect and primitive covering searches, along with the recognized object (table lamp) and a goodness of fit. <p> and AS refer to the aspect number (an enumeration), aspect label (see <ref> [16] </ref>), aspect probability, and aspect score (how well aspect was verified), respectively. The mnemonics FN, FL, FP, and PS refer to face number (in image window), face label (see [16]), face probability, and corresponding primitive attachment surface (see [16]), respectively, for each component face of the aspect. The search window indicates the status of the aspect and primitive covering searches, along with the recognized object (table lamp) and a goodness of fit.
Reference: [17] <author> E. D. Dickmanns and V. Graefe. </author> <title> Applications of dynamic monocular machine vision. </title> <journal> Machine Vision and Applications, </journal> <volume> 1 </volume> <pages> 241-261, </pages> <year> 1988. </year>
Reference-contexts: from stereo images are sufficient to update the positions, orientations, and shapes of the models in 3-D; no costly feature extraction or correspondence is necessary. 4.2.1 Tracking and Prediction Kalman filtering techniques have been applied in the vision literature for the estimation of dynamic features [8] and rigid motion parameters <ref> [17, 3] </ref> of objects from image sequences. We use a Kalman filter to estimate the object's shape and motion in a sequence of images.
Reference: [18] <author> D. Gennery. </author> <title> Visual tracking of known three-dimensional objects. </title> <journal> International Journal of Computer Vision, </journal> <volume> 7(3), </volume> <year> 1990. </year>
Reference-contexts: At the other extreme, as shown in but require an exact specification of the object's geometry, and cannot support non-rigid object tracking, e.g., <ref> [27, 18, 39, 40] </ref>. In this paper, we describe both shape recovery and shape tracking paradigms that attempt to close the gap between underconstrained data-driven approaches and overconstrained model-driven approaches. The critical component of our approach is a parts-based object representation that combines both object-centered and viewer-centered models.
Reference: [19] <author> W. Grimson and T. Lozano-Perez. </author> <title> Model-based recognition and localization from sparse range or tactile data. </title> <journal> International Journal of Robotics Research, </journal> <volume> 3(3) </volume> <pages> 3-35, </pages> <year> 1984. </year>
Reference-contexts: region, in which nodes represent bounding contours, and arcs represent relations between the contours, including cotermination, parallelism, and symmetry. 2 Once we have established a description for each image region, the next step is to match that description against the faces in the aspect hierarchy using an interpretation tree search <ref> [19] </ref>. Descriptions that exactly match a face in the aspect hierarchy will be given a single label with probability 1.0. <p> During the search process, aspect verification, like face matching, is accomplished through the use of an interpretation tree search <ref> [19] </ref>. Once a set of aspects has been recovered, each aspect is used to infer one or more volume hypotheses based on the non-zero conditional probabilities mapping aspects to volumes in the aspect hierarchy.
Reference: [20] <author> D. Huttenlocher and S. Ullman. </author> <title> Recognizing solid objects by alignment with an image. </title> <journal> International Journal of Computer Vision, </journal> <volume> 5(2) </volume> <pages> 195-212, </pages> <year> 1990. </year>
Reference-contexts: These limitations are a consequence of using such unconstrained models. At the other extreme lie the purely model-driven approaches to shape recovery, in which the exact geometry of the object is captured in a model, e.g., <ref> [26, 20, 24, 38] </ref>. As shown in Figure 2, simple image features such as corners or changes in curvature are paired with similar features on a 3-D model to yield a set of hypothesized correspondences.
Reference: [21] <author> M. Kass, A. Witkin, and D. Terzopolous. Snakes: </author> <title> Active contour models. </title> <journal> Internation Journal of Computer Vision, </journal> <volume> 1(4) </volume> <pages> 321-331, </pages> <year> 1988. </year>
Reference-contexts: The purely data-driven approaches to shape recovery are exemplified by the class of deformable or active model recovery techniques, in which a model contour (in 2-D) or surface (in 3-D) adapts itself to the image data under the influence of "forces" exerted by the image data <ref> [21, 36, 37, 35] </ref>. As shown in Figure 1, points on the model are "pulled" towards corresponding (e.g., closest) data points in the image, with the integrity of the model often maintained by giving the model physical properties such as mass, stiffness, and damping. <p> The AAG is initially created from a recovered aspect, and consists of a network of active contours (snakes) <ref> [21] </ref>. In addition, the AAG encodes the topology of the network's regions, as defined by minimal cycles of contours. Contours in the AAG can deform subject to both internal and external (image) forces while retaining their connectivity at nodes.
Reference: [22] <author> J. Koenderink and A. van Doorn. </author> <title> The internal representation of solid shape with respect to vision. </title> <journal> Biological Cybernetics, </journal> <volume> 32 </volume> <pages> 211-216, </pages> <year> 1979. </year>
Reference-contexts: It is at the volumetric part modeling level, that we invoke the concept of viewer-centered modeling. Traditional aspect graph representations of 3-D objects model an entire object with a set of aspects (or views), each defining a topologically distinct view of an object in terms of its visible surfaces <ref> [22] </ref>. Our approach differs in that we use aspects to represent a (typically small) set of volumetric parts from which objects appearing in our image database are constructed, rather than representing the entire object directly. <p> Each of the nodes in this representation, derived from an aspect graph <ref> [22] </ref> and the aspect hierarchy, represents a topologically different viewpoint of the object, while arcs between nodes specify the visual events or changes in image topology between nodes. The role of the symbolic tracker is to: 1.
Reference: [23] <author> S. Kristensen and H. Nielsen. </author> <title> 3d scene modeling for robot navigation. M.SC. </title> <type> Thesis, </type> <month> October </month> <year> 1992. </year>
Reference-contexts: The first step in recovering a set of faces is a region segmentation of the input image. We begin by applying Saint-Marc, Chen, and Medioni's edge-preserving adaptive smoothing filter to 9 the image [33]. Next, we apply a fast region segmentation algorithm due to Kristensen and Nielsen <ref> [23] </ref>, resulting in a region label image. In this method, a queue-based technique is used to merge pixels which differ by less than a similarity threshold. The comparison is based on simple pooled statistics for the regions.
Reference: [24] <author> Y. Lamdan, J. Schwartz, and H. Wolfson. </author> <title> On recognition of 3-D objects from 2-D images. </title> <booktitle> In Proceedings, IEEE International Conference on Robotics and Automation, </booktitle> <pages> pages 1407-1413, </pages> <address> Philadelphia, PA, </address> <year> 1988. </year>
Reference-contexts: These limitations are a consequence of using such unconstrained models. At the other extreme lie the purely model-driven approaches to shape recovery, in which the exact geometry of the object is captured in a model, e.g., <ref> [26, 20, 24, 38] </ref>. As shown in Figure 2, simple image features such as corners or changes in curvature are paired with similar features on a 3-D model to yield a set of hypothesized correspondences.
Reference: [25] <author> M. Li. </author> <title> Minimum description length based 2-D shape description. </title> <type> Technical Report CVAP114, </type> <institution> Computational Vision and Active Perception Lab, Royal Institute of Technology, Stockholm, Sweden, </institution> <month> October </month> <year> 1992. </year>
Reference-contexts: From the region topology graph, each region is characterized according to the qualitative shapes of its bounding contours. The steps of partitioning the bounding contour and classifying the resulting contours are performed simultaneously using a minimal description length algorithm <ref> [25] </ref>. From a set of initial candidate contour breakpoints (derived from a polygonal approximation), the algorithm considers all possible groupings of the inter-breakpoint contours.
Reference: [26] <author> D. Lowe. </author> <title> Perceptual Organization and Visual Recognition. </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Nor-well, MA, </address> <year> 1985. </year>
Reference-contexts: These limitations are a consequence of using such unconstrained models. At the other extreme lie the purely model-driven approaches to shape recovery, in which the exact geometry of the object is captured in a model, e.g., <ref> [26, 20, 24, 38] </ref>. As shown in Figure 2, simple image features such as corners or changes in curvature are paired with similar features on a 3-D model to yield a set of hypothesized correspondences.
Reference: [27] <author> D. Lowe. </author> <title> Fitting parameterized three-dimensional models to images. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 13(5) </volume> <pages> 441-450, </pages> <year> 1991. </year>
Reference-contexts: At the other extreme, as shown in but require an exact specification of the object's geometry, and cannot support non-rigid object tracking, e.g., <ref> [27, 18, 39, 40] </ref>. In this paper, we describe both shape recovery and shape tracking paradigms that attempt to close the gap between underconstrained data-driven approaches and overconstrained model-driven approaches. The critical component of our approach is a parts-based object representation that combines both object-centered and viewer-centered models.
Reference: [28] <author> D. Metaxas. </author> <title> Physics-based modeling of nonrigid objects for vision and graphics. </title> <type> Ph.D. thesis, </type> <institution> Dept. of Computer Science, Univ. of Toronto, </institution> <year> 1992. </year> <month> 25 </month>
Reference-contexts: We set up a noninertial, model-centered reference frame <ref> [28] </ref>, and express these positions as: x = c + Rp; (2) where c (t) is the origin of at the center of the model, and the orientation of is given by the rotation matrix R (t). <p> theory and express the local deformations as d = Sq d ; (9) 1 These coincide with the model frame axes x; y and z respectively. 8 where S is the shape matrix whose entries are the finite element shape functions, and q d are the model's nodal local displacements <ref> [28] </ref>. 3 Recovering 3-D Shape Identifying or recognizing the object's class may require only that we recover the coarse shape of the object. However, if we need to recover a more accurate, quantitative shape description for subclass recognition or for grasping, then a qualitative description is insufficient.
Reference: [29] <author> D. Metaxas and S. Dickinson. </author> <title> Integration of quantitative and qualitative techniques for de--formable model fitting from orthographic, perspective, and stereo projections. </title> <booktitle> In Proceedings, Fourth International Conference on Computer Vision, </booktitle> <address> Berlin, Germany, </address> <month> May </month> <year> 1993. </year>
Reference-contexts: Details of the algorithm can be found in <ref> [29, 12] </ref>, while an extension of the technique to shape recovery from range data can be found in [13]. 3.2.1 Simplified Numerical Simulation When fitting the quantitative model to visual data, our goal is to recover q = (q &gt; c ; q &gt; s ; q &gt; vector of degrees
Reference: [30] <author> D. Metaxas and D. Terzopoulos. </author> <title> Shape and nonrigid motion estimation through physics-based synthesis. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 15(6) </volume> <pages> 580-591, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: the use of repulsion forces that would more effectively prevent network contours from converging. 4.2 Quantitative Object Tracking Our approach to quantitative tracking [4, 5] makes use of our frameworks for qualitative and quantitative shape recovery described in previous sections, as well as a physics-based framework for quantitative motion estimation <ref> [30] </ref>. To be able to track multiple objects, initialization of the models is performed in the first frame of the sequence based on our quantitative shape recovery 19 process. <p> u + g + PH &gt; V 1 (z h ( ^ u)); (11) where u = ( _ q &gt; ; q &gt; ) &gt; and matrices F; H; g; P; V are associated with the model dynamics, the error in the given data, and the measurement noise statistics <ref> [30] </ref>. Since we are measuring local short range forces directly from the image potential, the term z h ( ^ u) represents the 2-D image forces.
Reference: [31] <author> A. Pentland. </author> <title> Perceptual organization and the representation of natural form. </title> <journal> Artificial Intelligence, </journal> <volume> 28 </volume> <pages> 293-331, </pages> <year> 1986. </year>
Reference-contexts: For our investigation, we have chosen three properties including cross-section shape, axis shape, and cross-section size variation [14]. The values of these properties give rise to a set of ten primitives (a subset of Biederman's geons), modeled using Pentland's SuperSketch 3-D modeling tool <ref> [31] </ref>, and illustrated in Figure 5. Figure 6 illustrates a portion of the corresponding aspect hierarchy.
Reference: [32] <author> A. Pentland and S. Sclaroff. </author> <title> Closed-form solutions for physically based shape modeling and recognition. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 13(7) </volume> <pages> 715-729, </pages> <year> 1991. </year>
Reference-contexts: In addition, such techniques often require a manual segmentation of an object into parts to which models are fitted, e.g., [36]. If the models are not properly initialized, a canonical fit may not be possible, e.g., <ref> [32] </ref>. These limitations are a consequence of using such unconstrained models. At the other extreme lie the purely model-driven approaches to shape recovery, in which the exact geometry of the object is captured in a model, e.g., [26, 20, 24, 38]. <p> both occluded aspects and occluded faces, only those portions (boundary groups) of the regions used to infer the faces exert external global deformation forces on the model. 3.2.3 Model Initialization One of the major limitations of previous deformable model fitting approaches is their dependence on model initialization and prior segmentation <ref> [37, 35, 32] </ref>. Using the qualitative shape recovery process as a front end, we first segment the data into parts, and for each part, we identify the relevant non-occluded data belonging to the part.
Reference: [33] <author> P. Saint-Marc, J.-S. Chen, and G. Medioni. </author> <title> Adaptive smoothing: A general tool for early vision. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 13(6) </volume> <pages> 514-529, </pages> <year> 1991. </year>
Reference-contexts: Finally, we map the aspects to primitives and extract primitive connectivity. The first step in recovering a set of faces is a region segmentation of the input image. We begin by applying Saint-Marc, Chen, and Medioni's edge-preserving adaptive smoothing filter to 9 the image <ref> [33] </ref>. Next, we apply a fast region segmentation algorithm due to Kristensen and Nielsen [23], resulting in a region label image. In this method, a queue-based technique is used to merge pixels which differ by less than a similarity threshold.
Reference: [34] <author> D. Terzopolous and R. Szeliski. </author> <title> Tracking with kalman snakes. </title> <editor> In A. Blake and A. Yuille, editors, </editor> <booktitle> Active Vision, </booktitle> <pages> pages 3-21. </pages> <publisher> MIT Press, </publisher> <year> 1992. </year>
Reference: [35] <author> D. Terzopoulos and D. Metaxas. </author> <title> Dynamic 3D models with local and global deformations: Deformable superquadrics. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 13(7) </volume> <pages> 703-714, </pages> <year> 1991. </year>
Reference-contexts: The purely data-driven approaches to shape recovery are exemplified by the class of deformable or active model recovery techniques, in which a model contour (in 2-D) or surface (in 3-D) adapts itself to the image data under the influence of "forces" exerted by the image data <ref> [21, 36, 37, 35] </ref>. As shown in Figure 1, points on the model are "pulled" towards corresponding (e.g., closest) data points in the image, with the integrity of the model often maintained by giving the model physical properties such as mass, stiffness, and damping. <p> For example, such techniques often assume that the bounding contour of a region belongs to the object, a problem when the object is occluded. Furthermore, focusing only on an object's silhouette assumes 3-D models with rotational symmetry, i.e., no surface discontinuities, e.g., <ref> [35] </ref>. In addition, such techniques often require a manual segmentation of an object into parts to which models are fitted, e.g., [36]. If the models are not properly initialized, a canonical fit may not be possible, e.g., [32]. These limitations are a consequence of using such unconstrained models. <p> Geometrically, these quantitative shape models are closed surfaces in space whose intrinsic (material) coordinates are u = (u; v), defined on a domain <ref> [35, 12] </ref>. <p> This allows us, through the apparatus of Lagrangian dynamics, to arrive at a set of equations of motion governing the behavior of our model under the action of externally applied forces. The Lagrange equations of motion take the form <ref> [35] </ref>: M q + D _ q + Kq = g q + f q ; (10) where M, D, and K are the mass, damping, and stiffness matrices, respectively, where g q are inertial (centrifugal and Coriolis) forces arising from the dynamic coupling between the local and 13 global degrees <p> We convert the external forces to generalized forces f q which act on the generalized coordinates of the model <ref> [35] </ref>. We apply forces to the model based on differences between the model's projected points and points on the recovered aspect's contours. <p> both occluded aspects and occluded faces, only those portions (boundary groups) of the regions used to infer the faces exert external global deformation forces on the model. 3.2.3 Model Initialization One of the major limitations of previous deformable model fitting approaches is their dependence on model initialization and prior segmentation <ref> [37, 35, 32] </ref>. Using the qualitative shape recovery process as a front end, we first segment the data into parts, and for each part, we identify the relevant non-occluded data belonging to the part.
Reference: [36] <author> D. Terzopoulos, A. Witkin, and M. Kass. </author> <title> Symmetry-seeking models and 3D object recovery. </title> <journal> International Journal of Computer Vision, </journal> <volume> 1 </volume> <pages> 211-221, </pages> <year> 1987. </year>
Reference-contexts: The purely data-driven approaches to shape recovery are exemplified by the class of deformable or active model recovery techniques, in which a model contour (in 2-D) or surface (in 3-D) adapts itself to the image data under the influence of "forces" exerted by the image data <ref> [21, 36, 37, 35] </ref>. As shown in Figure 1, points on the model are "pulled" towards corresponding (e.g., closest) data points in the image, with the integrity of the model often maintained by giving the model physical properties such as mass, stiffness, and damping. <p> Furthermore, focusing only on an object's silhouette assumes 3-D models with rotational symmetry, i.e., no surface discontinuities, e.g., [35]. In addition, such techniques often require a manual segmentation of an object into parts to which models are fitted, e.g., <ref> [36] </ref>. If the models are not properly initialized, a canonical fit may not be possible, e.g., [32]. These limitations are a consequence of using such unconstrained models.
Reference: [37] <author> D. Terzopoulos, A. Witkin, and M. Kass. </author> <title> Constraints on deformable models: Recovering 3D shape and nonrigid motion. </title> <journal> Artificial Intelligence, </journal> <volume> 36 </volume> <pages> 91-123, </pages> <year> 1988. </year>
Reference-contexts: The purely data-driven approaches to shape recovery are exemplified by the class of deformable or active model recovery techniques, in which a model contour (in 2-D) or surface (in 3-D) adapts itself to the image data under the influence of "forces" exerted by the image data <ref> [21, 36, 37, 35] </ref>. As shown in Figure 1, points on the model are "pulled" towards corresponding (e.g., closest) data points in the image, with the integrity of the model often maintained by giving the model physical properties such as mass, stiffness, and damping. <p> both occluded aspects and occluded faces, only those portions (boundary groups) of the regions used to infer the faces exert external global deformation forces on the model. 3.2.3 Model Initialization One of the major limitations of previous deformable model fitting approaches is their dependence on model initialization and prior segmentation <ref> [37, 35, 32] </ref>. Using the qualitative shape recovery process as a front end, we first segment the data into parts, and for each part, we identify the relevant non-occluded data belonging to the part. <p> A modal node is made active if: 1) it lies on the occluding contour of the model from that viewpoint <ref> [37] </ref>, or 2) the local surface curvature at the node is sufficiently large and the node is visible. Visibility of the nodes can be determined in two ways.
Reference: [38] <author> D. Thompson and J. Mundy. </author> <title> Model-directed object recognition on the connection machine. </title> <booktitle> In Proceedings, DARPA Image Understanding Workshop, </booktitle> <pages> pages 93-106, </pages> <address> Los Angeles, CA, </address> <year> 1987. </year>
Reference-contexts: These limitations are a consequence of using such unconstrained models. At the other extreme lie the purely model-driven approaches to shape recovery, in which the exact geometry of the object is captured in a model, e.g., <ref> [26, 20, 24, 38] </ref>. As shown in Figure 2, simple image features such as corners or changes in curvature are paired with similar features on a 3-D model to yield a set of hypothesized correspondences.
Reference: [39] <author> G. Verghese, K. Gale, and C. Dyer. </author> <title> Real-time, parallel tracking of three-dimensional objects from spatiotemporal sequences. </title> <editor> In V. Kumar, P.S. Gopalakrishnan, and L.N. Kanal, editors, </editor> <booktitle> Parallel Algorithms for Machine Intelligence and Vision. </booktitle> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1990. </year>
Reference-contexts: At the other extreme, as shown in but require an exact specification of the object's geometry, and cannot support non-rigid object tracking, e.g., <ref> [27, 18, 39, 40] </ref>. In this paper, we describe both shape recovery and shape tracking paradigms that attempt to close the gap between underconstrained data-driven approaches and overconstrained model-driven approaches. The critical component of our approach is a parts-based object representation that combines both object-centered and viewer-centered models.
Reference: [40] <author> J. Wu, R. Rink, T. Caelli, and V. Gourishankar. </author> <title> Recovery of the 3D location and motion of a rigid object through camera image (an extended kalman filter approach). </title> <journal> In International Journal of Computer Vision, </journal> <volume> volume 3, </volume> <pages> pages 373-394, </pages> <year> 1989. </year> <month> 26 </month>
Reference-contexts: At the other extreme, as shown in but require an exact specification of the object's geometry, and cannot support non-rigid object tracking, e.g., <ref> [27, 18, 39, 40] </ref>. In this paper, we describe both shape recovery and shape tracking paradigms that attempt to close the gap between underconstrained data-driven approaches and overconstrained model-driven approaches. The critical component of our approach is a parts-based object representation that combines both object-centered and viewer-centered models.
References-found: 40

