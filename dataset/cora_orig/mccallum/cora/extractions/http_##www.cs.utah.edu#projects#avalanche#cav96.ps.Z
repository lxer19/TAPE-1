URL: http://www.cs.utah.edu/projects/avalanche/cav96.ps.Z
Refering-URL: http://www.cs.utah.edu/projects/avalanche/avalanche-publications.html
Root-URL: 
Email: fratan,ganeshg@cs.utah.edu  
Title: An Improvement to Partial Order Reductions  
Author: Ratan Nalumasu Ganesh Gopalakrishnan 
Address: Salt Lake City, UT 84112  
Affiliation: Department of Computer Science University of Utah,  
Abstract: In this paper, we present a new partial order reduction algorithm that can help reduce both space and time requirements of automatic verifiers. The partial order reduction algorithms described in [God95, Hol94] (both incorporated in SPIN [Hol91]) were observed to yield very little savings in many practical cases due to the proviso in them. Our algorithm, called the two-phase algorith, is different from these algorithms in that it avoids the proviso, and follows a new execution strategy consisting of alternating phases of depth-first-search and partial order reduction. The two-phase algorithm is shown to preserve safety properties. It has been implemented in a new verifier which, like SPIN, takes Promela as input. Comparisons between these algorithms and the two-phase algorithm are provided for a significant number of examples, including directory based protocols of a new multiprocessor where significant performance gains are obtained. 
Abstract-found: 1
Intro-found: 1
Reference: [Ava] <institution> See http://www.cs.utah.edu/projects/avalanche for details. </institution>
Reference-contexts: If the process ordering is not as good, then the number of states saved in the hash table will be linear in the number of processes. 5.4 DSM Protocols Several realistic directory-based distributed shared memory protocols from the Avalanche multiprocessor project underway at the University of Utah <ref> [Ava] </ref> were experimented with. Directory based protocols to implement shared memory in multiprocessors are gaining popularity due to the scalable nature of the protocols. In a directory based system, every cache line has a designated home node|a processor responsible for maintaining the coherency of that line.
Reference: [CP95] <author> Ching-Tsun Chou and Doron Peled. </author> <title> Formal verification of a partial-order reduction technique for model-checking. </title> <address> ftp://ftp.cs.ucla.edu/pub/chou/por.ps, </address> <month> November </month> <year> 1995. </year>
Reference-contexts: 1 Introduction Partial order reductions has been a topic of considerable interest during the past few years <ref> [CP95, Pel93, GP93, God90, Val90] </ref>. Partial order reductions are based on the idea that when using interleaving to model concurrency, many permutations of the interleaving actions yield the same truth value for the properties being verified, and hence considering any one of the permutations is sufficient.

Reference: [God95] <author> Patrice Godefroid. </author> <title> Partial-Order Methods for the Verification of Concurrent Systems: An approach to the State-Explosion Problem. </title> <type> PhD thesis, </type> <institution> Univerite De Liege, </institution> <year> 1994-95. </year>
Reference-contexts: This, as we point out later, is directly attributable to the proviso used in it. A more general version of the same algorithm that may generate fewer states using sleepsets [GHP92] and the proviso is described in <ref> [God95] </ref>. However, this algorithm also generates many unnecessary configurations of states due to the proviso. In this paper, we present an alternative algorithm to perform partial order reductions that does not state-explode in this manner. <p> However, this algorithm also generates many unnecessary configurations of states due to the proviso. In this paper, we present an alternative algorithm to perform partial order reductions that does not state-explode in this manner. Our algorithm is different from the algorithms described in <ref> [God95, Hol94] </ref> in that it avoids the proviso and follows a new execution strategy consisting of alternating phases of depth-first-search and partial order reduction. It has been shown to preserve safety properties. The two-phase algorithm has been implemented in a new verifier which, like SPIN, takes Promela 1 as input. <p> It has been shown to preserve safety properties. The two-phase algorithm has been implemented in a new verifier which, like SPIN, takes Promela 1 as input. Comparisons between [Hol94] algo-rithm, <ref> [God95] </ref> algorithm, and the two-phase algorithm are provided for a significant number of examples. In those examples in which [Hol94] and [God95] algorithms state-explode due to the proviso, our algorithm performs significantly better in terms of runtime as well as memory requirements. <p> The two-phase algorithm has been implemented in a new verifier which, like SPIN, takes Promela 1 as input. Comparisons between [Hol94] algo-rithm, <ref> [God95] </ref> algorithm, and the two-phase algorithm are provided for a significant number of examples. In those examples in which [Hol94] and [God95] algorithms state-explode due to the proviso, our algorithm performs significantly better in terms of runtime as well as memory requirements. In a few cases, however, the two-phase algorithm generates more states than the algorithm in [Hol94] algorithm or [God95] algorithm. <p> In those examples in which [Hol94] and <ref> [God95] </ref> algorithms state-explode due to the proviso, our algorithm performs significantly better in terms of runtime as well as memory requirements. In a few cases, however, the two-phase algorithm generates more states than the algorithm in [Hol94] algorithm or [God95] algorithm. The overall performance of the two-phase algorithm is respectable on most practical examples. The rest of the paper is organized as follows: In Section 2, we provide basic definitions. <p> Note that if the execution is in a state S with process P in internal control state I, and all possible transitions of process P from I are safe, then those transitions constitute a persistent set in S in the sense described in <ref> [God95] </ref>. A program accepted by our verifier is well-formed if there is no cyclic execution that contains only deterministic states with respect to any process. Note that it is trivial to convert any non well-formed program into a well-formed program. <p> all enabled transitions from s nxt := successors of s obtained by executing transitions in tr for each succ in nxt do f if succ not in cache then enter succ in cache push (succ, stack) dfs1 () pop (stack) g Algorithm 1: Partial order reduction with pro viso In <ref> [God95] </ref>, an algorithm to implement partial order reductions that uses sleep sets, the pro viso, and a more generalized version of Choose () is presented. However, the proviso affects this algorithm in much the same way as it affects Al gorithm 1. <p> However, the proviso affects this algorithm in much the same way as it affects Al gorithm 1. Moreover, the computation of sleep sets may cause the total execution time to in crease. Storing the sleep set information may also increase memory requirements. In practice, the algorithm in <ref> [God95] </ref> generates fewer config urations than Algorithm 1. The two-phase algorithm presented in Al gorithm 2 implements partial order reductions without using the proviso. This algorithm runs every process in sequence until a non deterministic state with respect to that process is reached. <p> that would be considered by dfs2 () but not by dfs3 () would be considered by dfs3 () in its first-phase during the subsequent recursive call. 5 Case studies In this section, we present the results of running the three algorithms presented in Section 3 and the algorithm presented in <ref> [God95] </ref> on two toy protocols and four realistic protocols. In all the realistic protocols, the two-phase algorithms outperform the other algorithms. A brief explanation for this is as follows. In most reactive systems, a transaction typically involves a subset of processes. <p> In fact, in certain toy examples, dfs1 () generates all the reachable configurations of the systems. In realistic systems also the number of extra states generated due to the proviso can be high. <ref> [God95] </ref> algorithm also uses the proviso, thus exhibiting similar behavior. The two-phase algorithms do not use proviso. Instead they alternate a step of partial order reduction step with a step of complete DFS. <p> It can also be observed that the total number of transitions taken by the two-phase algorithms is less than the number of states saved in the cache by either the [Hol94] algorithm or <ref> [God95] </ref> algorithm. Hence, even if the first phase of the two-phase algorithms are modified to save every state into the cache, the two-phase algorithms would still generate fewer states 2 . [God95] algorithm did not run for N=12, probably because of some hard wired parameters. 5.2 Worst case runs better with <p> two-phase algorithms is less than the number of states saved in the cache by either the [Hol94] algorithm or <ref> [God95] </ref> algorithm. Hence, even if the first phase of the two-phase algorithms are modified to save every state into the cache, the two-phase algorithms would still generate fewer states 2 . [God95] algorithm did not run for N=12, probably because of some hard wired parameters. 5.2 Worst case runs better with the algorithm in [Hol94] than the two-phase algorithms. <p> This protocol has a 2 Actually, on this particular protocol such a modification will not result in any more states being entered into the cache. 7 N [Hol94] Algorithm <ref> [God95] </ref> Algorithm First two-phase Algorithm Second two-phase Algorithm 4 81/272/0.25 70/113/0.35 9/16/0.34 9/16/0.34 6 729/3221/0.32 683/1062/0.64 13/24/0.36 13/24/0.36 8 6561/21668/1.10 6422/9877/4.34 17/32/0.36 17/32/0.36 Table 1: Number of states saved in the hash table, number of transitions traversed and time taken by different algorithms on Best Case. runs more efficiently with the <p> In a directory based system, every cache line has a designated home node|a processor responsible for maintaining the coherency of that line. Whenever a node tries to access a cache line for reading or writing, if the line is not present in 8 N [Hol94] Algorithm <ref> [God95] </ref> Algorithm First two-phase Algorithm Second two-phase Algorithm 5 63/63/0.29 64/136/0.37 243/810/0.44 243/810/0.44 7 255/255/0.27 256/524/0.51 2187/10206/0.65 2187/10206/0.65 9 1023/1023/0.35 1024/2064/1.21 19683/118098/4.03 19683/118098/4.03 Table 2: Number of states saved in the hash table, number of transitions traversed and time taken by different algorithms on Worst Case. <p> The algorithm presented in [Hol94] did not finish the search in a total of 64 Megabytes of memory when the protocol consists of 4 servers and 4 clients. On this protocol also, both two-phase algorithms traverse fewer transitions than the number of states generated by [Hol94] or <ref> [God95] </ref> algorithm. 5.6 Leader Election Protocol This is a protocol to elect a leader in a unidirectional ring of processes, and is provided with the SPIN distribution. In this protocol, the proviso will never be invoked in dfs1 (). <p> The practical significance of the two-phase algorithm is its efficiency. In all realistic examples, we have found that the two-phase algorithm outperforms previous algorithms such as the ones in [Hol94] and <ref> [God95] </ref>. This efficiency is despite its use of an extremely simple criterion to determine when a transition may be postponed. The two-phase algorithm is shown to preserve safety properties. Algorithms 2 and 3 are implemented in a verifier that accepts a subset of Promela as input.
Reference: [God90] <author> Patrice Godefroid. </author> <title> Using partial orders to improve automatic verification methods. </title> <booktitle> In Computer Aided Verification, </booktitle> <pages> pages 176-185, </pages> <address> New Brunswick, NJ, USA, </address> <month> June </month> <year> 1990. </year>
Reference-contexts: 1 Introduction Partial order reductions has been a topic of considerable interest during the past few years <ref> [CP95, Pel93, GP93, God90, Val90] </ref>. Partial order reductions are based on the idea that when using interleaving to model concurrency, many permutations of the interleaving actions yield the same truth value for the properties being verified, and hence considering any one of the permutations is sufficient.
Reference: [Gop94] <author> Ganesh Gopalakrishnan. </author> <title> Developing micropipeline wavefront arbiters using lockable C-elements. </title> <journal> IEEE Design & Test of Computers, </journal> <volume> 11(4) </volume> <pages> 55-64, </pages> <month> Winter </month> <year> 1994. </year>
Reference-contexts: The reason for the bad performance of two-phase algorithms is that none of the reachable states is deterministic with respect to any process. Hence, the two-phase algorithms degenerate to classical DFS. 5.3 Wavefront Arbiter A cross-bar arbiter that operates by sweeping diagonally propagating "wavefronts" within a circuit array <ref> [Gop94] </ref> is shown in Figure 6. To request a cross-bar connection at location i,j, a request is placed at the "lockable" C-element [Gop94] at this location. The request attempts to "pin down" the wavefront at this location. When this succeeds, an acknowledgment is produced. <p> Hence, the two-phase algorithms degenerate to classical DFS. 5.3 Wavefront Arbiter A cross-bar arbiter that operates by sweeping diagonally propagating "wavefronts" within a circuit array <ref> [Gop94] </ref> is shown in Figure 6. To request a cross-bar connection at location i,j, a request is placed at the "lockable" C-element [Gop94] at this location. The request attempts to "pin down" the wavefront at this location. When this succeeds, an acknowledgment is produced. A property maintained by this arbiter is that no two C-elements on any row or a column can support a wavefront concurrently.
Reference: [GP93] <author> Patrice Godefroid and Didier Pirot-tin. </author> <title> Refining dependencies improves partial-order verification methods. </title> <booktitle> In Computer Aided Verification, </booktitle> <pages> pages 438-450, </pages> <address> Elounda, Greece, </address> <month> June </month> <year> 1993. </year>
Reference-contexts: 1 Introduction Partial order reductions has been a topic of considerable interest during the past few years <ref> [CP95, Pel93, GP93, God90, Val90] </ref>. Partial order reductions are based on the idea that when using interleaving to model concurrency, many permutations of the interleaving actions yield the same truth value for the properties being verified, and hence considering any one of the permutations is sufficient.
Reference: [HGP92] <author> Gerard Holzmann, Patrice Godefroid, and Didier Pirottin. </author> <title> Coverage preserving reduction strategies for reachabil-ity analysis. In International Symposium on Protocol Specification, Testing, and Verification, </title> <address> Lake Buena Vista, Florida, USA, </address> <month> June </month> <year> 1992. </year>
Reference-contexts: The second part of the condition is referred to as proviso <ref> [HGP92] </ref>. Without the proviso, some transitions might never be executed. If Choose () fails (i.e., if no process satisfying the condition can be found) all enabled transitions in that state are executed in depth first order.
Reference: [Hol91] <author> Gerard Holzmann. </author> <title> Design and Validation of Computer Protocols. </title> <publisher> Prentice Hall, </publisher> <year> 1991. </year>
Reference-contexts: An efficient implementation of partial order reductions to perform linear temporal logic model checking is described in [Hol94]. This algorithm is implemented in SPIN <ref> [Hol91] </ref>, a widely used verification tool for protocols written in Promela, a concurrent programming language. The algorithm divides all transitions in the system into two disjoint sets: local transitions and global transitions. Informally, a local transition of process is one that commutes with transitions of every other process.
Reference: [Hol94] <author> Gerard Holzmann. </author> <title> An improvement in formal verification. </title> <booktitle> In FORTE, </booktitle> <address> Bern, Switzerland, </address> <month> October </month> <year> 1994. </year>
Reference-contexts: An efficient implementation of partial order reductions to perform linear temporal logic model checking is described in <ref> [Hol94] </ref>. This algorithm is implemented in SPIN [Hol91], a widely used verification tool for protocols written in Promela, a concurrent programming language. The algorithm divides all transitions in the system into two disjoint sets: local transitions and global transitions. <p> However, this algorithm also generates many unnecessary configurations of states due to the proviso. In this paper, we present an alternative algorithm to perform partial order reductions that does not state-explode in this manner. Our algorithm is different from the algorithms described in <ref> [God95, Hol94] </ref> in that it avoids the proviso and follows a new execution strategy consisting of alternating phases of depth-first-search and partial order reduction. It has been shown to preserve safety properties. The two-phase algorithm has been implemented in a new verifier which, like SPIN, takes Promela 1 as input. <p> It has been shown to preserve safety properties. The two-phase algorithm has been implemented in a new verifier which, like SPIN, takes Promela 1 as input. Comparisons between <ref> [Hol94] </ref> algo-rithm, [God95] algorithm, and the two-phase algorithm are provided for a significant number of examples. In those examples in which [Hol94] and [God95] algorithms state-explode due to the proviso, our algorithm performs significantly better in terms of runtime as well as memory requirements. <p> It has been shown to preserve safety properties. The two-phase algorithm has been implemented in a new verifier which, like SPIN, takes Promela 1 as input. Comparisons between <ref> [Hol94] </ref> algo-rithm, [God95] algorithm, and the two-phase algorithm are provided for a significant number of examples. In those examples in which [Hol94] and [God95] algorithms state-explode due to the proviso, our algorithm performs significantly better in terms of runtime as well as memory requirements. In a few cases, however, the two-phase algorithm generates more states than the algorithm in [Hol94] algorithm or [God95] algorithm. <p> In those examples in which <ref> [Hol94] </ref> and [God95] algorithms state-explode due to the proviso, our algorithm performs significantly better in terms of runtime as well as memory requirements. In a few cases, however, the two-phase algorithm generates more states than the algorithm in [Hol94] algorithm or [God95] algorithm. The overall performance of the two-phase algorithm is respectable on most practical examples. The rest of the paper is organized as follows: In Section 2, we provide basic definitions. In Section 3, we present the algorithm of [Hol94] followed by the two-phase algorithm (actually we present <p> algorithm generates more states than the algorithm in <ref> [Hol94] </ref> algorithm or [God95] algorithm. The overall performance of the two-phase algorithm is respectable on most practical examples. The rest of the paper is organized as follows: In Section 2, we provide basic definitions. In Section 3, we present the algorithm of [Hol94] followed by the two-phase algorithm (actually we present two closely related two-phase algorithms; however, we often refer to both these algorithms collectively as " the two-phase algorithm"). In Section 4 the proof of the two-phase algorithms is presented. In Section 5, we provide case studies comparing different algorithms. <p> In practice, most programs do not contain such loops. 3 Algorithms This section provides an overview of the algorithm presented in <ref> [Hol94] </ref> (Algorithm 1) and the two-phase algorithm (Algorithm 2). The algorithm presented in [Hol94] attempts to find a process in an internal state such that all transitions of that process from that state are safe and that at least one of the transitions results in a state that is not contained <p> In practice, most programs do not contain such loops. 3 Algorithms This section provides an overview of the algorithm presented in <ref> [Hol94] </ref> (Algorithm 1) and the two-phase algorithm (Algorithm 2). The algorithm presented in [Hol94] attempts to find a process in an internal state such that all transitions of that process from that state are safe and that at least one of the transitions results in a state that is not contained in the stack (function Choose () in Algorithm 1). <p> Table 1 shows the results of running the algorithms on this protocol. On a system comprising of n processes, both two-phase algorithms generates 2n + 1 states while the algorithm described in <ref> [Hol94] </ref> generates 3 n states. It can also be observed that the total number of transitions taken by the two-phase algorithms is less than the number of states saved in the cache by either the [Hol94] algorithm or [God95] algorithm. <p> n processes, both two-phase algorithms generates 2n + 1 states while the algorithm described in <ref> [Hol94] </ref> generates 3 n states. It can also be observed that the total number of transitions taken by the two-phase algorithms is less than the number of states saved in the cache by either the [Hol94] algorithm or [God95] algorithm. <p> if the first phase of the two-phase algorithms are modified to save every state into the cache, the two-phase algorithms would still generate fewer states 2 . [God95] algorithm did not run for N=12, probably because of some hard wired parameters. 5.2 Worst case runs better with the algorithm in <ref> [Hol94] </ref> than the two-phase algorithms. This protocol has a 2 Actually, on this particular protocol such a modification will not result in any more states being entered into the cache. 7 N [Hol94] Algorithm [God95] Algorithm First two-phase Algorithm Second two-phase Algorithm 4 81/272/0.25 70/113/0.35 9/16/0.34 9/16/0.34 6 729/3221/0.32 683/1062/0.64 13/24/0.36 <p> for N=12, probably because of some hard wired parameters. 5.2 Worst case runs better with the algorithm in <ref> [Hol94] </ref> than the two-phase algorithms. This protocol has a 2 Actually, on this particular protocol such a modification will not result in any more states being entered into the cache. 7 N [Hol94] Algorithm [God95] Algorithm First two-phase Algorithm Second two-phase Algorithm 4 81/272/0.25 70/113/0.35 9/16/0.34 9/16/0.34 6 729/3221/0.32 683/1062/0.64 13/24/0.36 13/24/0.36 8 6561/21668/1.10 6422/9877/4.34 17/32/0.36 17/32/0.36 Table 1: Number of states saved in the hash table, number of transitions traversed and time taken by different algorithms on Best Case. runs more efficiently <p> Algorithm Second two-phase Algorithm 4 81/272/0.25 70/113/0.35 9/16/0.34 9/16/0.34 6 729/3221/0.32 683/1062/0.64 13/24/0.36 13/24/0.36 8 6561/21668/1.10 6422/9877/4.34 17/32/0.36 17/32/0.36 Table 1: Number of states saved in the hash table, number of transitions traversed and time taken by different algorithms on Best Case. runs more efficiently with the algorithm described in <ref> [Hol94] </ref>. Statistics for this protocol are in Table 2. total of 3 n states where n is the number of processes in the system. <p> In a directory based system, every cache line has a designated home node|a processor responsible for maintaining the coherency of that line. Whenever a node tries to access a cache line for reading or writing, if the line is not present in 8 N <ref> [Hol94] </ref> Algorithm [God95] Algorithm First two-phase Algorithm Second two-phase Algorithm 5 63/63/0.29 64/136/0.37 243/810/0.44 243/810/0.44 7 255/255/0.27 256/524/0.51 2187/10206/0.65 2187/10206/0.65 9 1023/1023/0.35 1024/2064/1.21 19683/118098/4.03 19683/118098/4.03 Table 2: Number of states saved in the hash table, number of transitions traversed and time taken by different algorithms on Worst Case. N [Hol94] Algorithm <p> N <ref> [Hol94] </ref> Algorithm [God95] Algorithm First two-phase Algorithm Second two-phase Algorithm 5 63/63/0.29 64/136/0.37 243/810/0.44 243/810/0.44 7 255/255/0.27 256/524/0.51 2187/10206/0.65 2187/10206/0.65 9 1023/1023/0.35 1024/2064/1.21 19683/118098/4.03 19683/118098/4.03 Table 2: Number of states saved in the hash table, number of transitions traversed and time taken by different algorithms on Worst Case. N [Hol94] Algorithm First two-phase Algorithm Second two-phase Algorithm 6 161/163/0.39 11/1155/0.40 3/300/0.37 8 295/297/0.75 13/2565/0.36 3/528/0.33 10 469/471/1.40 15/4807/0.41 3/820/0.36 Table 3: Number of states saved in the hash table, number of transition traversed and time taken for the reachability analysis of the wavefront arbiter by Algorithms 1, 2, and 3. <p> A service consists of doing a simple local calculation, sending a message to the client being served, waiting for another message from the client, and then responding with another message. The results of running such a hypothetical protocol is presented in Table 5. The algorithm presented in <ref> [Hol94] </ref> did not finish the search in a total of 64 Megabytes of memory when the protocol consists of 4 servers and 4 clients. On this protocol also, both two-phase algorithms traverse fewer transitions than the number of states generated by [Hol94] or [God95] algorithm. 5.6 Leader Election Protocol This is <p> The algorithm presented in <ref> [Hol94] </ref> did not finish the search in a total of 64 Megabytes of memory when the protocol consists of 4 servers and 4 clients. On this protocol also, both two-phase algorithms traverse fewer transitions than the number of states generated by [Hol94] or [God95] algorithm. 5.6 Leader Election Protocol This is a protocol to elect a leader in a unidirectional ring of processes, and is provided with the SPIN distribution. In this protocol, the proviso will never be invoked in dfs1 (). <p> The practical significance of the two-phase algorithm is its efficiency. In all realistic examples, we have found that the two-phase algorithm outperforms previous algorithms such as the ones in <ref> [Hol94] </ref> and [God95]. This efficiency is despite its use of an extremely simple criterion to determine when a transition may be postponed. The two-phase algorithm is shown to preserve safety properties. Algorithms 2 and 3 are implemented in a verifier that accepts a subset of Promela as input.
Reference: [Pel93] <author> Doron Peled. </author> <title> All from one, one for all: On model checking using representatives. </title> <booktitle> In Computer Aided Verification, </booktitle> <pages> pages 409-423, </pages> <address> Elounda, Greece, </address> <month> June </month> <year> 1993. </year>
Reference-contexts: 1 Introduction Partial order reductions has been a topic of considerable interest during the past few years <ref> [CP95, Pel93, GP93, God90, Val90] </ref>. Partial order reductions are based on the idea that when using interleaving to model concurrency, many permutations of the interleaving actions yield the same truth value for the properties being verified, and hence considering any one of the permutations is sufficient.
Reference: [Val90] <author> Antti Valmari. </author> <title> A stubborn attack on state explosion. </title> <booktitle> In Computer Aided Verification, </booktitle> <pages> pages 156-165, </pages> <address> New Brunswick, NJ, USA, </address> <month> June </month> <year> 1990. </year>
Reference-contexts: 1 Introduction Partial order reductions has been a topic of considerable interest during the past few years <ref> [CP95, Pel93, GP93, God90, Val90] </ref>. Partial order reductions are based on the idea that when using interleaving to model concurrency, many permutations of the interleaving actions yield the same truth value for the properties being verified, and hence considering any one of the permutations is sufficient.
References-found: 11

