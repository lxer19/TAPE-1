URL: http://www.cs.bu.edu/techreports/95-002-web-client-caching.ps.Z
Refering-URL: http://cs-www.bu.edu/techreports/Home.html
Root-URL: 
Email: fbest,carter,crovella,carro,heddaya,mirdadg@cs.bu.edu  
Title: Application-Level Document Caching in the Internet  
Author: Azer Bestavros Robert L. Carter Mark E. Crovella Carlos R. Cunha Abdelsalam Heddaya Sulaiman A. Mirdad 
Note: A slightly shorter version of this TR will appear in Proc. SDNE '95 (2nd Intl. Workshop on Services in Distributed and Networked Environments), Whistler, Canada,  This work has been partially supported by NSF (grant CCR-9308344). Document Internet URL is ``ftp://cs-ftp.bu.edu/techreports/95-002-web-client-caching.ps.Z''.  
Date: January 15, 1995 (Revised March 23, 1995)  June 5-6, 1995.  
Pubnum: BU-CS-95-002  
Abstract: With the increasing demand for document transfer services such as the World Wide Web comes a need for better resource management to reduce the latency of documents in these systems. To address this need, we analyze the potential for document caching at the application level in document transfer services. We have collected traces of actual executions of Mosaic, reflecting over half a million user requests for WWW documents. Using those traces, we study the tradeoffs between caching at three levels in the system, and the potential for use of application-level information in the caching system. Our traces show that while a high hit rate in terms of URLs is achievable, a much lower hit rate is possible in terms of bytes, because most profitably-cached documents are small. We consider the performance of caching when applied at the level of individual user sessions, at the level of individual hosts, and at the level of a collection of hosts on a single LAN. We show that the performance gain achievable by caching at the session level (which is straightforward to implement) is nearly all of that achievable at the LAN level (where caching is more difficult to implement). However, when resource requirements are considered, LAN level caching becomes much more desirable, since it can achieve a given level of caching performance using a much smaller amount of cache space. Finally, we consider the use of organizational boundary information as an example of the potential for use of application-level information in caching. Our results suggest that distinguishing between documents produced locally and those produced remotely can provide useful leverage in designing caching policies, because of differences in the potential for sharing these two document types among multiple users. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Swarup Acharya and Stanley B. Zdonik. </author> <title> An efficient scheme for dynamic data replication. </title> <type> Technical Report CS-93-43, </type> <institution> Brown University, </institution> <address> Providence, Rhode Island 02912, </address> <month> September </month> <year> 1993. </year>
Reference-contexts: Although we did not report on network bandwidth reduction, we have performed preliminary studies that show a significant potential for network bandwidth reduction by application-level caching. The reduction of network traffic due to intelligent data placement and replication is also studied in <ref> [1] </ref>. They present a distributed dynamic replication scheme, which uses a finite state automaton-based technique to learn file access patterns. In contrast, our focus is on data caching rather than replication and placement techniques. In [12] the authors approximate an optimal caching schedule based on fixed network and storage costs.
Reference: [2] <author> Azer Bestavros. </author> <title> Demand-based document dissemination for the World Wide Web. </title> <type> Technical Report TR-95-003, </type> <institution> Boston U., CS Dept, </institution> <address> Boston, MA 02215, </address> <month> Feb. </month> <year> 1995. </year>
Reference-contexts: There are three problems to be tackled for such an approach, namely what, how far, and in which direction (s) to disseminate. The work in <ref> [2] </ref> addresses the first two aspects, whereas the work in [8] investigates the third.
Reference: [3] <author> Matthew Addison Blaze. </author> <title> Caching in Large Scale Distributed File Systems. </title> <type> PhD thesis, </type> <institution> Prince-ton University, </institution> <year> 1993. </year> <month> 17 </month>
Reference-contexts: Although the intermediate cache reduces both the peak load at upstream servers and network load, the average hit rate at the intermediate cache is not significant. We further extend their work showing the improvements in latency due to application caching. In <ref> [3] </ref> Blaze presents a dynamic hierarchical file system. Each client can service requests issued by other clients from the local disk cache. The focus of that work was to reduce server load.
Reference: [4] <author> Michael D. Dahlin, Randolph Y. Wang, Thomas E. Anderson, and David A. Patterson. </author> <title> Co--operative caching: Using remote client memory to improve file system performance. </title> <booktitle> In Proc. of the 1st Symposium on Operating Systems Design and Implementation, </booktitle> <pages> pages 267-280, </pages> <month> Nov. </month> <year> 1994. </year>
Reference-contexts: Host caches could be implemented by a local server, or by periodically synchronizing each application's memory-based cache with a disk buffer. LAN caches consist of a cache managed by the clients on a single LAN, as in <ref> [4] </ref>. LAN caches require cooperation among the participating clients; host and session caches do not. Our work is unique in a number of ways. First, we base it on the large amount of user trace data we have collected. <p> The focus of that work was to reduce server load. Here we focus on reducing latency through the use of application-level caching; we plan future work to explore the potential for reduction in server load possible via application-level caching. Performance benefits of cooperative caching have been studied in <ref> [4] </ref>. Through the use of trace driven simulations a range of caching algorithms were studied. Their results show that an improvement of 73% in file read performance can be achieved.
Reference: [5] <author> Peter Danzig, Richard Hall, and Michael Schwartz. </author> <title> A case for caching file objects inside internetworks. </title> <type> Technical Report CU-CS-642-93, </type> <institution> University of Colorado at Boulder, Boulder, Colorado 80309-430, </institution> <month> March </month> <year> 1993. </year>
Reference-contexts: In contrast to these studies, the material presented in this paper focuses mainly on reducing response time through caching at the application level, rather than caching at the file system level. Danzig et al. <ref> [5] </ref> propose a hierarchical caching system that caches files at Core Nodal Switching Subsystems within the NSFNET. The main goal of their research is to reduce the bandwidth used by the system; their study shows that the NSFNET backbone traffic can be reduced by as much as 21%.
Reference: [6] <institution> National Center for Supercomputing Applications. Mosaic software and documentation. </institution>
Reference-contexts: We employed a trace-driven simulation approach to studying the document caching problem. First, we collected logs of users accessing the World Wide Web. We instrumented a version of NCSA Mosaic <ref> [6] </ref> to keep a record of all documents (named by their Uniform Resource Locators | URLs) accessed by the user during an execution of Mosaic. (We refer to each execution of Mosaic 1 as a session, and we call the log of each session a trace.) The results in this paper
Reference: [7] <author> Steven Glassman. </author> <title> A Caching Relay for the World Wide Web. </title> <booktitle> In First International Conference on the World-Wide Web, CERN, </booktitle> <address> Geneva (Switzerland), May 1994. </address> <publisher> Elsevier Science. </publisher>
Reference-contexts: data and the collection process; next, the results of our simulations for various caching policies using that data; next, a comparison of our work with related research; and, finally, our conclusions. 2 Reference Patterns 2.1 Data Collection Methods Prior studies of WWW traffic have been based on logs from proxies <ref> [7, 16] </ref>, or logs from the HTTP server daemon [13]. Our study required knowledge of individual user's access patterns, and we did not wish our data to be influenced by the caching behavior built in to the client application (Mosaic).
Reference: [8] <author> James Gwertzman and Margo Seltzer. </author> <title> The case for geographical push-caching. </title> <type> Technical Report HU TR-34-94 (excerpt), </type> <institution> Harvard U., DAS, </institution> <address> Cambridge, MA 02138, </address> <year> 1994. </year>
Reference-contexts: There are three problems to be tackled for such an approach, namely what, how far, and in which direction (s) to disseminate. The work in [2] addresses the first two aspects, whereas the work in <ref> [8] </ref> investigates the third.
Reference: [9] <institution> Merit Network Incorporated. NSFNet performance statistics. </institution>
Reference-contexts: We refer to these systems as document transfer systems and to the files involved as documents since each file has essentially been electronically "published." An increasingly large fraction of available bandwidth on the Internet is being used to transfer documents <ref> [9] </ref>. Strategies for reducing the latency of document access, the network bandwidth demand of document transfers, and the demand on document servers are becoming increasingly important. Techniques that could reduce document latency, network bandwidth demand, and server demand include data caching and replication.
Reference: [10] <author> D. Muntz and P. Honeyman. </author> <title> Multi-level caching in distributed file systems or your cache ain't nuthing but trash. </title> <booktitle> In Proceedings of the Winter 1992 USENIX, </booktitle> <pages> pages 305-313, </pages> <month> January </month> <year> 1992. </year>
Reference-contexts: In the worst-case the 15 algorithm produces a schedule that is no worse than twice the optimal one. Their theoretical work is an off-line algorithm in comparison to the work presented here in which trace data from user accesses is used to study on-line algorithms. Muntz and Honeyman <ref> [10] </ref> performed simulations on a two level caching system, intermediate servers and clients. Although the intermediate cache reduces both the peak load at upstream servers and network load, the average hit rate at the intermediate cache is not significant.
Reference: [11] <author> John K. Ousterhout, Herve Da Costa, David Harrison, John A. Kunze, Michael Kupfer, and James G. Thompson. </author> <title> A trace-driven analysis of the UNIX 4.2BSD file system. </title> <type> Technical Report CSD-85-230, </type> <institution> Dept. of Computer Science, University of California at Berkeley, </institution> <year> 1985. </year>
Reference-contexts: The upper histograms plot the distribution of documents, while the lower histograms plot the distribution of references to documents. Previous studies of user filesystem requests have shown a strong preference for small files <ref> [11, ?] </ref>. Our data shows a similar pattern; the most popular document size is between 256 and 768 bytes.
Reference: [12] <author> Christos H. Papadimitriou, Srinivas Ramanathan, and P. Venkat Rangan. </author> <title> Information caching for delivery of personalized video programs on home entertainment channels. </title> <booktitle> In Proceedings of the International Confrence on Multimedia Computing and Systems, </booktitle> <pages> pages 214-223, </pages> <month> May </month> <year> 1994. </year>
Reference-contexts: They present a distributed dynamic replication scheme, which uses a finite state automaton-based technique to learn file access patterns. In contrast, our focus is on data caching rather than replication and placement techniques. In <ref> [12] </ref> the authors approximate an optimal caching schedule based on fixed network and storage costs. This schedule indicates where and when a file should be cached. In the worst-case the 15 algorithm produces a schedule that is no worse than twice the optimal one.
Reference: [13] <author> James E. Pitkow and Margaret M. Recker. </author> <title> A Simple Yet Robust Caching Algorithm Based on Dynamic Access Patterns. </title> <booktitle> In Electronic Proc. of the 2nd WWW Conference, </booktitle> <year> 1994. </year>
Reference-contexts: our simulations for various caching policies using that data; next, a comparison of our work with related research; and, finally, our conclusions. 2 Reference Patterns 2.1 Data Collection Methods Prior studies of WWW traffic have been based on logs from proxies [7, 16], or logs from the HTTP server daemon <ref> [13] </ref>. Our study required knowledge of individual user's access patterns, and we did not wish our data to be influenced by the caching behavior built in to the client application (Mosaic). For these reasons, we instrumented Mosaic directly and captured logs of all accesses performed by the user.
Reference: [14] <author> R. Sandber, D. Goldberg, S. Kleiman, D. Walsh, and B. Lyon. </author> <title> Design and implementation of the Sun network file system. </title> <booktitle> In Proc. USENIX Summer Conference, </booktitle> <year> 1985. </year> <month> 18 </month>
Reference-contexts: session on each host improves the byte-hit rate to 36% and a cooperatively shared cache at the LAN provides further improvement to 48%, the performance of an infinite cache. 4 Related Work A great deal of research on caching and replication in distributed file systems has been conducted previously (e.g., <ref> [14, 15] </ref>). In such research the main goal has been to improve the overall perfor 14 mance of the system.
Reference: [15] <author> M. Satyanarayanan, J. Kistler, P. Kumar, M. Okasaki, E. Siegel, and D. Streere. Coda: </author> <title> A highly available file system for distributed workstation environments. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 39(4), </volume> <month> April </month> <year> 1990. </year>
Reference-contexts: session on each host improves the byte-hit rate to 36% and a cooperatively shared cache at the LAN provides further improvement to 48%, the performance of an infinite cache. 4 Related Work A great deal of research on caching and replication in distributed file systems has been conducted previously (e.g., <ref> [14, 15] </ref>). In such research the main goal has been to improve the overall perfor 14 mance of the system.
Reference: [16] <author> Jeff Sedayao. </author> <title> "Mosaic Will Kill My Network!" Studying Network Traffic Patterns of Mosaic Use. </title> <booktitle> In Electronic Proc. of the 2nd WWW Conference, </booktitle> <address> Chicago, Illinois, </address> <month> October </month> <year> 1994. </year> <month> 19 </month>
Reference-contexts: data and the collection process; next, the results of our simulations for various caching policies using that data; next, a comparison of our work with related research; and, finally, our conclusions. 2 Reference Patterns 2.1 Data Collection Methods Prior studies of WWW traffic have been based on logs from proxies <ref> [7, 16] </ref>, or logs from the HTTP server daemon [13]. Our study required knowledge of individual user's access patterns, and we did not wish our data to be influenced by the caching behavior built in to the client application (Mosaic).
References-found: 16

