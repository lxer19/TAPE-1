URL: ftp://ftp.cs.ucsd.edu/pub/team/groupMajorityAndStrictAgreement.ps.Z
Refering-URL: http://www.cs.ucsd.edu/users/flaviu/publications.html
Root-URL: http://www.cs.ucsd.edu
Email: flaviu@cs.ucsd.edu  
Title: Group, Majority, and Strict Agreement in Timed Asynchronous Distributed Systems  
Author: Flaviu Cristian 
Address: San Diego  
Affiliation: Computer Science and Engineering University of California,  
Abstract: Atomic broadcast is a group communication service that enables a team of distributed processes to keep replicated data `consistent', despite concurrency, communication uncertainty, failures and recoveries. We investigate possible meanings for replicated data `consistency' in timed asynchronous systems, subject to crash/performance process failures and omission/performance communication failures which may partition correct team members into isolated parallel groups. We propose three different replica consistency specifications: group agreement, majority agreement and strict agreement and give examples of atomic broadcast protocols that implement these specifications. The interface issues between the underlying membership services and the broadcast protocols that provide the above semantics are also addressed. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> G. Alvarez, F. Cristian, and S. Mishra. </author> <title> On-demand asynchronous atomic broadcast. </title> <booktitle> In 5th IFIP Working Conference on Dependable Computing for Critical Applications, </booktitle> <address> Urbana, Illinois, </address> <month> Sept. </month> <year> 1995. </year>
Reference-contexts: For example a fixed member, say l can act as a sequencer [8, 19], or the role of sequencer can rotate among g members cyclically [10, 2, 14] or on demand <ref> [25, 1] </ref>. A second way of achieving agreement on message delivery order is for each g member to infer it in a decentralized way from message precedence information piggy-backed on each broadcast message [21, 20, 16]. <p> Since they do not take into account the possibility that conflicting updates may be generated in parallel groups, they have to be classified as protocols that (tacitly) aim at achieving majority agreement. Other protocols have specifically been designed to achieve majority agreement, for example <ref> [10, 14, 1] </ref>. A variant of majority agreement, called `primary partition' agreement, is achieved by the protocol described in [7]. `Primary partition' groups are descendents of an original `primary partition' group. They differ from majority groups because they do not have to contain a numeric majority of team members.
Reference: [2] <author> Y. Amir, L. Moser, M. Melliar-Smith, D. Agar-wal, and P. Ciarfella. </author> <title> Fast message ordering and membership using a logical token-pasing ring. </title> <booktitle> In Proceedings of the 13th International IEEE Conference on Distributed Computing Systems, </booktitle> <pages> pages 551-560, </pages> <address> Pittsburgh, PA, </address> <month> May </month> <year> 1993. </year>
Reference-contexts: Agreement on the order in which these updates are to be applied by each g member can be achieved in many different ways. For example a fixed member, say l can act as a sequencer [8, 19], or the role of sequencer can rotate among g members cyclically <ref> [10, 2, 14] </ref> or on demand [25, 1]. A second way of achieving agreement on message delivery order is for each g member to infer it in a decentralized way from message precedence information piggy-backed on each broadcast message [21, 20, 16].
Reference: [3] <author> Y. Amir, L. Moser, P. Melliar-Smith, D. Agar-wal, and P. Ciarfella. </author> <title> Fast message ordering and membership using a logical token-passing ring. </title> <booktitle> In Proceedings of Thirteenth International Conference on Distributed Computing Systems, </booktitle> <pages> pages 551-560, </pages> <address> Pittsburgh, PA, </address> <month> May </month> <year> 1993. </year>
Reference-contexts: such as: 1) what to do if the current `primary partition' group contains only a minority of team members and the majority is outside this `primary partition' ? 2) if the replicated team state is persistent (e.g. stored on disks) how must total system failures be handled? The protocols of <ref> [20, 3, 16] </ref> provide group agreement, while that of [5] provides a reliable (unordered) group broadcast with properties similar to group agreement. The protocol described in [25] has a `primary bit' that allows it to be configured to provide either group or `primary partition' agreement.
Reference: [4] <author> E. Anceaume, B. Charron-Bost, P. Minet, and S. Toueg. </author> <title> On the formal specification of group membership services. </title> <type> Technical Report 95-1534, </type> <institution> Computer Science Department, Cornell University, </institution> <address> Ithaca, New York 14853, </address> <month> August </month> <year> 1995. </year>
Reference-contexts: Absence of such "good reason" requirements for new group creations would allow processes to always isolate themselves following instability periods into singleton groups that would generate trivial exe cutions that are of no practical interest <ref> [4] </ref>. (M s a ) Justification of additions.
Reference: [5] <author> O. Babaoglu, M. Baker, R. Davoli, and L. Gia-chini. Relacs: </author> <title> a communication infrastructure for constructing reliable applications. </title> <type> Technical Report CS94-15, </type> <institution> Laboratory for Computer Science, The University of Bologna, </institution> <year> 1994. </year>
Reference-contexts: `primary partition' group contains only a minority of team members and the majority is outside this `primary partition' ? 2) if the replicated team state is persistent (e.g. stored on disks) how must total system failures be handled? The protocols of [20, 3, 16] provide group agreement, while that of <ref> [5] </ref> provides a reliable (unordered) group broadcast with properties similar to group agreement. The protocol described in [25] has a `primary bit' that allows it to be configured to provide either group or `primary partition' agreement.
Reference: [6] <author> P. A. Bernstein, V. Hadzilacos, and N. Goodman. </author> <title> Concurrency Control and Recovery in Database Systems. </title> <publisher> Addison-Wesley Publishing Company, </publisher> <year> 1987. </year>
Reference-contexts: For example if team members are transaction commit managers, the specification of atomic commit forbids the existence of points in time at which some managers believe that a transaction is committed while others believe that it is aborted <ref> [6] </ref>. Such applications need a stronger form of agreement, namely strict agreement. Strict agreement guarantees that all team members agree at any time on a unique history of updates.
Reference: [7] <author> K. Birman, A. Schiper, and P. Stephenson. </author> <title> Lightweight causal and atomic group multi-cast. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 9(3) </volume> <pages> 272-314, </pages> <month> Aug </month> <year> 1991. </year>
Reference-contexts: Other protocols have specifically been designed to achieve majority agreement, for example [10, 14, 1]. A variant of majority agreement, called `primary partition' agreement, is achieved by the protocol described in <ref> [7] </ref>. `Primary partition' groups are descendents of an original `primary partition' group. They differ from majority groups because they do not have to contain a numeric majority of team members.
Reference: [8] <author> R. Carr. </author> <title> The Tandem global update protocol. </title> <journal> Tandem Systems Review, </journal> <month> Jun </month> <year> 1985. </year>
Reference-contexts: Agreement on the order in which these updates are to be applied by each g member can be achieved in many different ways. For example a fixed member, say l can act as a sequencer <ref> [8, 19] </ref>, or the role of sequencer can rotate among g members cyclically [10, 2, 14] or on demand [25, 1]. <p> Some of the published atomic broadcast protocol, for example <ref> [8, 19, 21] </ref>, do not consider the possibility that processes can be partitioned. Since they do not take into account the possibility that conflicting updates may be generated in parallel groups, they have to be classified as protocols that (tacitly) aim at achieving majority agreement.
Reference: [9] <author> D. Chandra, V. Hadzilacos, S. Toueg, and B. Charron-Bost. </author> <title> On the impossibility of group membership. </title> <type> Technical Report 95-1548, </type> <institution> Com--puter Science Department, Cornell University, </institution> <address> Ithaca, New York 14853, </address> <month> October </month> <year> 1995. </year>
Reference-contexts: A consequence of this very weak definition of correctness is the impossibility of implementing fundamental fault-tolerant services such as consensus and membership in time-free asynchronous systems <ref> [18, 9] </ref>. These services are, however, implementable in timed asynchronous systems in which certain stability conditions hold [15, 17]. Practical systems are often required to be fault-tolerant, so they are naturally timed and make use of timeouts 2 . Thus, most existing distributed systems are timed asynchronous.
Reference: [10] <author> J. Chang and N. Maxemchuk. </author> <title> Reliable broadcast protocols. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 2(3) </volume> <pages> 251-273, </pages> <month> Aug </month> <year> 1984. </year>
Reference-contexts: Agreement on the order in which these updates are to be applied by each g member can be achieved in many different ways. For example a fixed member, say l can act as a sequencer [8, 19], or the role of sequencer can rotate among g members cyclically <ref> [10, 2, 14] </ref> or on demand [25, 1]. A second way of achieving agreement on message delivery order is for each g member to infer it in a decentralized way from message precedence information piggy-backed on each broadcast message [21, 20, 16]. <p> Since they do not take into account the possibility that conflicting updates may be generated in parallel groups, they have to be classified as protocols that (tacitly) aim at achieving majority agreement. Other protocols have specifically been designed to achieve majority agreement, for example <ref> [10, 14, 1] </ref>. A variant of majority agreement, called `primary partition' agreement, is achieved by the protocol described in [7]. `Primary partition' groups are descendents of an original `primary partition' group. They differ from majority groups because they do not have to contain a numeric majority of team members.
Reference: [11] <author> F. Cristian. </author> <title> Asynchronous atomic broadcast. </title> <journal> IBM Technical Disclosure Bulletin, </journal> <volume> 33(9) </volume> <pages> 115-116, </pages> <month> Feb </month> <year> 1991. </year> <booktitle> Presented at the First IEEE Workshop on Management of Replicated Data, </booktitle> <address> Houston, TX, </address> <month> (Nov </month> <year> 1990). </year>
Reference-contexts: A second way of achieving agreement on message delivery order is for each g member to infer it in a decentralized way from message precedence information piggy-backed on each broadcast message [21, 20, 16]. A third possibility <ref> [11] </ref> is to use a train to totally order all updates applied by group members. All the above approaches have relative advantages and drawbacks [13]. In what follows we choose to use train protocols to illustrate how one can achieve group, majority and strict agreement.
Reference: [12] <author> F. Cristian. </author> <title> Understanding fault-tolerant distributed systems. </title> <journal> Communications of ACM, </journal> <volume> 34(2) </volume> <pages> 56-78, </pages> <month> Feb </month> <year> 1991. </year>
Reference-contexts: Processes exchange messages via a datagram communication service. Messages can get lost and communication delays are unbounded, however most 1 messages arrive at their destination within a known timeout delay constant d. Thus, datagram communication has omission/performance failure semantics <ref> [12] </ref>. Processes have access to stable storage and hardware clocks. Clocks measure time with a known accuracy by running within a linear envelope of real-time. Clocks are not required to be synchronized. Stable storage is used to store S-state replicas. <p> Servers are scheduled to run on processors in response to trigger events such as message arrivals or timeouts. Scheduling delays are unbounded; however, most actual scheduling delays are shorter than a known constant s. When scheduling delays exceed s, servers suffer performance failures <ref> [12] </ref>. Processors and servers 1 For a discussion on how to decide what "most" means in order to achieve a certain failure semantics, the interested reader is referred to the section "Choosing a Failure Semantics" of [12]. use self-checking mechanisms so that it is very unlikely that they produce functionally erroneous <p> When scheduling delays exceed s, servers suffer performance failures <ref> [12] </ref>. Processors and servers 1 For a discussion on how to decide what "most" means in order to achieve a certain failure semantics, the interested reader is referred to the section "Choosing a Failure Semantics" of [12]. use self-checking mechanisms so that it is very unlikely that they produce functionally erroneous outputs. Thus, servers have crash/performance failure semantics. We assume that any crashed server eventually restarts (or recovers). <p> Indeed, our introduction of the d and s likely time bounds makes processor and communication service specifications timed: they prescribe not only which state transitions/outputs should occur in response to trigger events, such as message arrivals or timeouts, but also the real-time intervals within which they are expected to occur <ref> [12] </ref>. In contrast, the specifications considered in [18] are time-free: they specify, for each state and input, only the next state/output, without imposing any constraint on the real-time it takes a state transition/output to occur.
Reference: [13] <author> F. Cristian, R. de Beijer, and S. Mishra. </author> <title> A performance comparison of asynchronous atomic broadcast protocols. </title> <journal> Distributed Systems Engineering, </journal> <volume> 1(4) </volume> <pages> 177-201, </pages> <month> Jun </month> <year> 1994. </year>
Reference-contexts: A third possibility [11] is to use a train to totally order all updates applied by group members. All the above approaches have relative advantages and drawbacks <ref> [13] </ref>. In what follows we choose to use train protocols to illustrate how one can achieve group, majority and strict agreement. A train message consists of a header (the locomotive) and a (possibly empty) sequence of proposed updates (the wagons).
Reference: [14] <author> F. Cristian and S. Mishra. </author> <title> The Pinwheel asynchronous atomic broadcast protocols. </title> <booktitle> In Proceedings of the Second International Symposium on Autonomous Decentralized Systems, </booktitle> <address> Phoenix, AZ, </address> <month> Mar </month> <year> 1995. </year>
Reference-contexts: Agreement on the order in which these updates are to be applied by each g member can be achieved in many different ways. For example a fixed member, say l can act as a sequencer [8, 19], or the role of sequencer can rotate among g members cyclically <ref> [10, 2, 14] </ref> or on demand [25, 1]. A second way of achieving agreement on message delivery order is for each g member to infer it in a decentralized way from message precedence information piggy-backed on each broadcast message [21, 20, 16]. <p> Since they do not take into account the possibility that conflicting updates may be generated in parallel groups, they have to be classified as protocols that (tacitly) aim at achieving majority agreement. Other protocols have specifically been designed to achieve majority agreement, for example <ref> [10, 14, 1] </ref>. A variant of majority agreement, called `primary partition' agreement, is achieved by the protocol described in [7]. `Primary partition' groups are descendents of an original `primary partition' group. They differ from majority groups because they do not have to contain a numeric majority of team members.
Reference: [15] <author> F. Cristian, F. Schmuck. </author> <title> Agreeing on processor-group membership in asynchronous distributed systems. </title> <type> Technical Report CSE95-428, UCSD, </type> <year> 1995. </year> <note> Available via anonymous ftp at cs.ucsd.edu as /pub/team/asyncmembership.ps.Z. </note>
Reference-contexts: A consequence of this very weak definition of correctness is the impossibility of implementing fundamental fault-tolerant services such as consensus and membership in time-free asynchronous systems [18, 9]. These services are, however, implementable in timed asynchronous systems in which certain stability conditions hold <ref> [15, 17] </ref>. Practical systems are often required to be fault-tolerant, so they are naturally timed and make use of timeouts 2 . Thus, most existing distributed systems are timed asynchronous. Since this paper only examines timed asynchronous systems, we will refer to them simply as asynchronous in the following text. <p> To maximize service availability, an underlying membership service groups those team members that can communicate among themselves in a timely manner into groups whose membership consists of subsets of P <ref> [15] </ref>. To efficiently handle queries and updates while maintaining the consistency of their replicas of the service state, the members of these groups agree to limit communication for the purpose of providing S to group members only. <p> of g, where the predecessor pred (q; g) of g relative to q is the previous group to which q was joined before joining g. (Initially, all team members are joined by definition to the predecessor group (0,0) with initial state s 0 and membership P , see for details <ref> [15] </ref>.) We say that processes p and q are (logically) partitioned at time t if they are joined to different parallel groups at t. Such partitioning can be a consequence of (physical) network instability or disconnectedness. <p> Membership protocols that satisfy the requirements for group agreement, and majority and strict agreement, respectively, are described and proven correct in <ref> [15] </ref>. 7 Discussion We have proposed three different specifications for what it means to keep replicated state consistent: group agreement, majority agreement and strict agreement.
Reference: [16] <author> P. Ezhilchelvan, R. Macedo, and S. Shrivastava. Newtop: </author> <title> a fault-tolerant group communication protocol. </title> <booktitle> In Proceedings of the 15th International Conference on Distributed Systems, </booktitle> <address> Vancouver, Canada., </address> <month> May </month> <year> 1995. </year>
Reference-contexts: A second way of achieving agreement on message delivery order is for each g member to infer it in a decentralized way from message precedence information piggy-backed on each broadcast message <ref> [21, 20, 16] </ref>. A third possibility [11] is to use a train to totally order all updates applied by group members. All the above approaches have relative advantages and drawbacks [13]. <p> such as: 1) what to do if the current `primary partition' group contains only a minority of team members and the majority is outside this `primary partition' ? 2) if the replicated team state is persistent (e.g. stored on disks) how must total system failures be handled? The protocols of <ref> [20, 3, 16] </ref> provide group agreement, while that of [5] provides a reliable (unordered) group broadcast with properties similar to group agreement. The protocol described in [25] has a `primary bit' that allows it to be configured to provide either group or `primary partition' agreement.
Reference: [17] <author> C. Fetzer and F. Cristian. </author> <title> On the possibility of consensus in asynchronous systems. </title> <booktitle> In 1995 Pacific Rim International Symposium on Fault-Tolerant Systems, </booktitle> <address> Newport Beach, CA, </address> <month> Dec </month> <year> 1995. </year>
Reference-contexts: A consequence of this very weak definition of correctness is the impossibility of implementing fundamental fault-tolerant services such as consensus and membership in time-free asynchronous systems [18, 9]. These services are, however, implementable in timed asynchronous systems in which certain stability conditions hold <ref> [15, 17] </ref>. Practical systems are often required to be fault-tolerant, so they are naturally timed and make use of timeouts 2 . Thus, most existing distributed systems are timed asynchronous. Since this paper only examines timed asynchronous systems, we will refer to them simply as asynchronous in the following text. <p> A correct value for the B constant for the two-round strict agreement train protocol is (2n 1)ffi, where n is the number of g members. 6 This progress assumption, which we believe to be quite reasonable in practice for any well-tuned asynchronous system, is similar to the majority-stability assumption of <ref> [17] </ref>. 7 For example, joined (p) is false between the moment p leaves a group pred (g; p) and the moment it joins the next group g. when joined (p) is true, group (p) yields the identifier of the group joined by p and mem (p) yields p's local view of
Reference: [18] <author> M. J. Fischer, N. A. Lynch, and M. S. Paterson. </author> <title> Impossibility of distributed consensus with one faulty process. </title> <journal> Journal of the ACM, </journal> <volume> 32(2) </volume> <pages> 374-382, </pages> <month> Apr </month> <year> 1985. </year>
Reference-contexts: We call a distributed system that satisfies the above hypotheses on processors, servers and communications a timed asynchronous system. Note that timed asynchronous systems are quite different from the time-free asynchronous systems discussed in <ref> [18] </ref>. The difference comes from the fact that the services of interest to us are timed, while those investigated in [18] are time-free. <p> Note that timed asynchronous systems are quite different from the time-free asynchronous systems discussed in <ref> [18] </ref>. The difference comes from the fact that the services of interest to us are timed, while those investigated in [18] are time-free. <p> In contrast, the specifications considered in <ref> [18] </ref> are time-free: they specify, for each state and input, only the next state/output, without imposing any constraint on the real-time it takes a state transition/output to occur. <p> A consequence of this very weak definition of correctness is the impossibility of implementing fundamental fault-tolerant services such as consensus and membership in time-free asynchronous systems <ref> [18, 9] </ref>. These services are, however, implementable in timed asynchronous systems in which certain stability conditions hold [15, 17]. Practical systems are often required to be fault-tolerant, so they are naturally timed and make use of timeouts 2 . Thus, most existing distributed systems are timed asynchronous.
Reference: [19] <author> F. Kaashoek and A. Tanenbaum. </author> <title> Group communication in the Amoeba distributed system. </title> <booktitle> In Proc. 11th Int. Conf. on Distributed Computing Systems, </booktitle> <pages> pages 222-230, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: Agreement on the order in which these updates are to be applied by each g member can be achieved in many different ways. For example a fixed member, say l can act as a sequencer <ref> [8, 19] </ref>, or the role of sequencer can rotate among g members cyclically [10, 2, 14] or on demand [25, 1]. <p> Some of the published atomic broadcast protocol, for example <ref> [8, 19, 21] </ref>, do not consider the possibility that processes can be partitioned. Since they do not take into account the possibility that conflicting updates may be generated in parallel groups, they have to be classified as protocols that (tacitly) aim at achieving majority agreement.
Reference: [20] <author> D. Malki, Y. Amir, D. Dolev, and S. Kramer. </author> <title> The Transis approach to high availability cluster communication. </title> <type> Technical Report CS94-14, </type> <institution> Computer Science Department, The Hebrew University of Jerusalem, Israel, </institution> <year> 1994. </year>
Reference-contexts: A second way of achieving agreement on message delivery order is for each g member to infer it in a decentralized way from message precedence information piggy-backed on each broadcast message <ref> [21, 20, 16] </ref>. A third possibility [11] is to use a train to totally order all updates applied by group members. All the above approaches have relative advantages and drawbacks [13]. <p> such as: 1) what to do if the current `primary partition' group contains only a minority of team members and the majority is outside this `primary partition' ? 2) if the replicated team state is persistent (e.g. stored on disks) how must total system failures be handled? The protocols of <ref> [20, 3, 16] </ref> provide group agreement, while that of [5] provides a reliable (unordered) group broadcast with properties similar to group agreement. The protocol described in [25] has a `primary bit' that allows it to be configured to provide either group or `primary partition' agreement.
Reference: [21] <author> S. Mishra, L. Peterson, and R. Schlichting. </author> <title> Consul: A communication substrate for fault-tolerant distributed programs. </title> <journal> Distributed Systems Engineering Journal, </journal> <year> 1993. </year>
Reference-contexts: A second way of achieving agreement on message delivery order is for each g member to infer it in a decentralized way from message precedence information piggy-backed on each broadcast message <ref> [21, 20, 16] </ref>. A third possibility [11] is to use a train to totally order all updates applied by group members. All the above approaches have relative advantages and drawbacks [13]. <p> Some of the published atomic broadcast protocol, for example <ref> [8, 19, 21] </ref>, do not consider the possibility that processes can be partitioned. Since they do not take into account the possibility that conflicting updates may be generated in parallel groups, they have to be classified as protocols that (tacitly) aim at achieving majority agreement.
Reference: [22] <author> M. Satyanarayanan, J. Kistler, P. Kumar, M. Okasaki, E. Siegel, and D. Steere. Coda: </author> <title> A highly available file system for a distributed workstation environment. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 39(4), </volume> <month> Apr </month> <year> 1990. </year>
Reference-contexts: At the other extreme, reconciliation for certain applications can be so hard as to require human intervention <ref> [22] </ref>. In all the above cases, we postulate the existence of an associative state merge function f that reconciles any conflicting updates applied to states s' and s" to produce a reconciled (or merged) state s. Examples of such merge functions are given in [24, 22]. <p> In all the above cases, we postulate the existence of an associative state merge function f that reconciles any conflicting updates applied to states s' and s" to produce a reconciled (or merged) state s. Examples of such merge functions are given in <ref> [24, 22] </ref>. We give below an example of an asynchronous atomic broadcast protocol that achieves group agreement. This protocol should provide enough intuition to make the formal properties for group agreement broadcast that we give next more easily understandable. <p> Little is known about how to define in general the reconciliation functions needed for group agreement. Ex amples of reconciliation functions that require human intervention are given in <ref> [22] </ref>, while [24] gives several example of automatic reconciliation procedures.
Reference: [23] <author> A. Schiper and A. Sandoz. </author> <title> Uniform reliable mul-ticast in a virtually synchronous environment. </title> <booktitle> In Proceedings of the Thirteenth International Conference on Distributed Computing Systems, </booktitle> <pages> pages 561-568, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: Given the importance of strict agreement in practice, we expect that more future protocols will be able to provide this strongest asynchronous consistency guarantee. Strict agreement is stronger than uniform agreement <ref> [23] </ref>, since the former ensures that "if a process delivers u then all processes deliver u", while the latter only ensures that "if a process delivers u then all correct processes deliver u".
Reference: [24] <author> R. Strong, D. Skeen, F. Cristian, and H. Aghili. </author> <title> Handshake protocols. </title> <booktitle> In Proceedings of the Seventh International Conference on Distributed Computing Systems, </booktitle> <pages> pages 521-528, </pages> <address> Berlin, </address> <month> Sep </month> <year> 1987. </year>
Reference-contexts: In all the above cases, we postulate the existence of an associative state merge function f that reconciles any conflicting updates applied to states s' and s" to produce a reconciled (or merged) state s. Examples of such merge functions are given in <ref> [24, 22] </ref>. We give below an example of an asynchronous atomic broadcast protocol that achieves group agreement. This protocol should provide enough intuition to make the formal properties for group agreement broadcast that we give next more easily understandable. <p> Little is known about how to define in general the reconciliation functions needed for group agreement. Ex amples of reconciliation functions that require human intervention are given in [22], while <ref> [24] </ref> gives several example of automatic reconciliation procedures.
Reference: [25] <author> R. van Renesse, K. Birman, and T. Hickey. </author> <title> Design and performance of Horus: a lightweight group communication system. </title> <type> TR 94-1442, </type> <institution> Cor-nell Univ, dept. of Computer Science, </institution> <month> Aug </month> <year> 1994. </year>
Reference-contexts: For example a fixed member, say l can act as a sequencer [8, 19], or the role of sequencer can rotate among g members cyclically [10, 2, 14] or on demand <ref> [25, 1] </ref>. A second way of achieving agreement on message delivery order is for each g member to infer it in a decentralized way from message precedence information piggy-backed on each broadcast message [21, 20, 16]. <p> The protocol described in <ref> [25] </ref> has a `primary bit' that allows it to be configured to provide either group or `primary partition' agreement. Little is known about how to define in general the reconciliation functions needed for group agreement.
References-found: 25

