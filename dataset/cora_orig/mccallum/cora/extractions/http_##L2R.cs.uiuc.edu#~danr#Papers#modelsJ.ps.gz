URL: http://L2R.cs.uiuc.edu/~danr/Papers/modelsJ.ps.gz
Refering-URL: http://L2R.cs.uiuc.edu/~danr/publications.html
Root-URL: http://www.cs.uiuc.edu
Title: Reasoning with Models  
Author: Roni Khardon Dan Roth 
Keyword: knowledge representation, common sense reasoning, automated reasoning.  
Address: Cambridge, MA 02138.  Rehovot 76100, ISRAEL  
Affiliation: Aiken Computation Laboratory, Harvard University,  Dept. of Appl. Math. CS, Weizmann Institute of Science,  
Note: Artificial Intelligence  An earlier version of the paper appears in the Proceedings of the National Conference on Artificial Intelligence, AAAI-94. Research supported by grant DAAL03-92-G-0115 (Center for Intelligent Control Systems). Research supported by NSF grant CCR-92-00884 and by DARPA AFOSR-F4962-92-J-0466. Current address:  
Email: froni,danrg@das.harvard.edu  e-mail: danr@wisdom.weizmann.ac.il  
Date: 87 (1996) 187-213  
Abstract: We develop a model-based approach to reasoning, in which the knowledge base is represented as a set of models (satisfying assignments) rather than a logical formula, and the set of queries is restricted. We show that for every propositional knowledge base (KB) there exists a set of characteristic models with the property that a query is true in KB if and only if it is satisfied by the models in this set. We characterize a set of functions for which the model-based representation is compact and provides efficient reasoning. These include cases where the formula-based representation does not support efficient reasoning. In addition, we consider the model-based approach to abductive reasoning and show that for any propositional KB, reasoning with its model-based representation yields an abductive explanation in time that is polynomial in its size. Some of our technical results make use of the Monotone Theory, a new characterization of Boolean functions recently introduced. The notion of restricted queries is inherent in our approach. This is a wide class of queries for which reasoning is efficient and exact, even when the model-based representation KB provides only an approximate representation of the domain in question. Moreover, we show that the theory developed here generalizes the model-based approach to reasoning with Horn expressions and captures even the notion of reasoning with Horn-approximations. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> N. Alon, J. Bruck, J. Naor, M. Naor, and R. Roth. </author> <title> Construction of asymptotically good low-rate error-correcting codes through pseudo-random graphs. </title> <journal> IEEE Transactions on information theory, </journal> <volume> 38(2) </volume> <pages> 509-516, </pages> <year> 1992. </year>
Reference-contexts: An (n; k)-universal set is a set of assignments fd 1 ; : : : d t g f0; 1g n such that every subset of k variables assumes all of its 2 k possible assignments in the d i 's. It is known <ref> [1] </ref> that for k = log n one can construct (n; k)-universal sets of polynomial size. Claim 8.2 ([4]) Let B be an (n; k)-universal set. Then B is a basis for any k-CNF KB.
Reference: [2] <author> C. Beeri, M. Dowd, R. Fagin, and R. Statman. </author> <title> On the structure of Armstorng relations for functional dependencies. </title> <journal> Journal of the ACM, </journal> <volume> 31(1) </volume> <pages> 30-46, </pages> <year> 1984. </year>
Reference-contexts: We also give other examples of expressive families of propositional expressions, for which our approach is useful. We note that characteristic models were studied independently in the Relational Data Base community (where they are called "generators") <ref> [2, 25] </ref>, for the special case of definite Horn expressions. The results in this paper have immediate implications in this domain (e.g., bounding the size of Armstrong relations), which are described elsewhere [18]. <p> cases. 6 Horn Expressions In this section we consider in detail the case of Horn formulas and show that in this case our notion of characteristic models coincides with the notion introduced in [14]. (Characteristic models for Horn expressions also coincide with the notion of generators in relational database theory <ref> [2, 18] </ref>.) We then discuss the issue of using a fixed model-based representation for answering unrestricted queries. We show that this extension, discussed in [14], relies on a special property of Horn formulas and does not generalize to other propositional languages. An example that explains this phenomenon is given.
Reference: [3] <author> R. Brachman and H. Levesque. </author> <title> The tractability of subsumption in framebased description languages. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pages 34-37, </pages> <year> 1984. </year>
Reference-contexts: Thus, this line of research aims at identifying classes of limited expressiveness, with which one can perform theorem proving efficiently <ref> [3, 24, 30, 31] </ref>. None of these works, however, meets the strong tractability requirements required for common-sense reasoning (e.g. see [35]), even though the limited expressiveness of classes discussed there has been argued to be implausible [7].
Reference: [4] <author> N. H. Bshouty. </author> <title> Exact learning via the monotone theory. </title> <booktitle> In Proceedings of the IEEE Symp. on Foundation of Computer Science, </booktitle> <pages> pages 302-311, </pages> <address> Palo Alto, CA., </address> <year> 1993. </year>
Reference-contexts: Some of our technical results make use of a new characterization of Boolean functions, called the Monotone Theory, introduced recently by Bshouty <ref> [4] </ref>. Recently, some more results on reasoning with models have been derived, exhibiting the usefulness of this approach. These include algorithms that use model-based representations to handle some fragments of Reiter's default logic as well as some cases of circuit diagnosis [20]. <p> While in this paper we also take this point of view, we are interested in studying the entire process of learning a knowledge base representation and reasoning with it. In particular, Bshouty <ref> [4] </ref> gives an algorithm that learns the model-based representation we consider here when given access to a Membership Oracle and an Equivalence Oracle. <p> in which f is represented as a propositional CNF expression, remains co-NP-Hard even when the set of queries is restricted to be a set of monotone functions. 4 Monotone Theory In this section we introduce the notation, definitions and results of the Monotone Theory of Boolean functions, introduced by Bshouty <ref> [4] </ref>. 1 An element of f0; 1g n denotes an assignment to the variables x 1 ; : : : ; x n (i.e., 0011 means x 1 = x 2 = 0, and x 3 = x 4 = 1).
Reference: [5] <author> M. Cadoli. </author> <title> Semantical and computational aspects of Horn approximations. </title> <booktitle> In Proceedings of the International Joint Conference of Artificial Intelligence, </booktitle> <pages> pages 39-44, </pages> <month> August </month> <year> 1993. </year>
Reference-contexts: Of course, computing the approximations is a hard computational problem, and this is why it is suggested as a compilation process. The computational problems of computing Horn approximations and reasoning with them are studied also in <ref> [5, 10, 30] </ref>. To facilitate the presentation we first define the notion of an approximation of KB. <p> On the other hand, since B KB KB, if for some u 2 B KB ; ff (u) = 0, then KB 6j= ff. A result similar to the corollary that follows, for the case in which G is the class of Horn expressions, is discussed in <ref> [15, 5, 6] </ref>. Corollary 5.5 Model-based Reasoning with KB lub (with respect to the language G) is correct for all queries in G. Example: (continued) The Horn basis for our example is: B H = f1111; 1110; 1101; 1011; 0111g (see Claim 6.1).
Reference: [6] <author> R. Dechter and J. Pearl. </author> <title> Structure identification in relational data. </title> <journal> Artificial Intelligence, </journal> <volume> 58 </volume> <pages> 237-270, </pages> <year> 1992. </year>
Reference-contexts: On the other hand, since B KB KB, if for some u 2 B KB ; ff (u) = 0, then KB 6j= ff. A result similar to the corollary that follows, for the case in which G is the class of Horn expressions, is discussed in <ref> [15, 5, 6] </ref>. Corollary 5.5 Model-based Reasoning with KB lub (with respect to the language G) is correct for all queries in G. Example: (continued) The Horn basis for our example is: B H = f1111; 1110; 1101; 1011; 0111g (see Claim 6.1). <p> The claim in [27] is given in the context of first order equational expressions, and the notation used there is substantially different. To facilitate the discussion, we give an adaption of the proof to the current terminology. (A different proof of this property, for the propositional domain, appears in <ref> [6] </ref>.) Claim 6.2 ([27]) A Boolean function can be represented using a Horn expression if and only if its set of models is closed under intersection. Proof: A proof that the models of Horn expressions are closed under intersection is given in [37].
Reference: [7] <author> J. Doyle and R. Patil. </author> <title> Two theses of knowledge representation: language restrictions, taxonomic classification, and the utility of representation services. </title> <journal> Artificial Intelligence, </journal> <volume> 48 </volume> <pages> 261-297, </pages> <year> 1991. </year>
Reference-contexts: None of these works, however, meets the strong tractability requirements required for common-sense reasoning (e.g. see [35]), even though the limited expressiveness of classes discussed there has been argued to be implausible <ref> [7] </ref>. Levesque argues [23, 24] that reasoning with a more direct representation is easier and better suits common-sense reasoning. He suggests to represent the knowledge base KB in a vivid form, which bears a strong and direct relationship to the real world.
Reference: [8] <author> D. Etherington, A. Borgida, R. Brachman, and H. Kautz. </author> <title> Vivid knowledge and tractable reasoning: Preliminary report. </title> <booktitle> In Proceedings of the International Joint Conference of Artificial Intelligence, </booktitle> <year> 1989. </year>
Reference-contexts: Levesque argues [23, 24] that reasoning with a more direct representation is easier and better suits common-sense reasoning. He suggests to represent the knowledge base KB in a vivid form, which bears a strong and direct relationship to the real world. This might be just a model of KB <ref> [8, 28] </ref> on which one can evaluate the truth value of the query ff. It is not clear, however, how one might derive a vivid form of the knowledge base.
Reference: [9] <author> R. Fagin. </author> <title> Horn clauses and database dependencies. </title> <journal> Journal of the ACM, </journal> <volume> 29(4) </volume> <pages> 952-985, </pages> <year> 1982. </year>
Reference-contexts: In the general case, though, even the size of the models may be infinite and it is not clear how one can overcome this problem. On the positive side, we note that Fagin <ref> [9] </ref> has shown that for a certain class of (Horn related) first order logic expressions, a single (infinite) model suffices to answer all queries in the language. Another line of research concerns the problem of planning.
Reference: [10] <author> R. Greiner and D. Schuurmans. </author> <title> Learning useful Horn approximations. </title> <booktitle> In Proceedings of the International Conference on the Principles of Knowledge Representation and Reasoning, </booktitle> <pages> pages 383-392, </pages> <year> 1992. </year>
Reference-contexts: Of course, computing the approximations is a hard computational problem, and this is why it is suggested as a compilation process. The computational problems of computing Horn approximations and reasoning with them are studied also in <ref> [5, 10, 30] </ref>. To facilitate the presentation we first define the notion of an approximation of KB.
Reference: [11] <author> A. Horn. </author> <title> On sentences which are true on direct unions of algebras. </title> <journal> Journal of Symbolic Logic, </journal> <volume> 16(1) </volume> <pages> 14-21, </pages> <year> 1951. </year>
Reference-contexts: Formally, char H (KB) = fu 2 KB j u 62 closure (KB n fug) g: (5) 12 The following claim is due to McKinsey [27], and has also been discussed by Horn <ref> [11] </ref>. The claim in [27] is given in the context of first order equational expressions, and the notation used there is substantially different.
Reference: [12] <author> P. N. Johnson-Laird. </author> <title> Mental Models. </title> <publisher> Harvard Press, </publisher> <year> 1983. </year>
Reference-contexts: It is not hard to motivate a model-based approach to reasoning from a cognitive point of view and indeed, many of the proponents of this approach to reasoning have been cognitive psychologists <ref> [12, 13, 22] </ref>. In the AI community this approach can be seen as an example of Levesque's notion of "vivid" reasoning and has already been studied in [14]. The deduction problem KB j= ff can be approached using the following model-based strategy: Test Set: A set S of possible assignments.
Reference: [13] <author> P. N. Johnson-Laird and R. M. J. Byrne. </author> <title> Deduction. </title> <publisher> Lawrence Erlbaum Associates, </publisher> <year> 1991. </year>
Reference-contexts: It is not hard to motivate a model-based approach to reasoning from a cognitive point of view and indeed, many of the proponents of this approach to reasoning have been cognitive psychologists <ref> [12, 13, 22] </ref>. In the AI community this approach can be seen as an example of Levesque's notion of "vivid" reasoning and has already been studied in [14]. The deduction problem KB j= ff can be approached using the following model-based strategy: Test Set: A set S of possible assignments.
Reference: [14] <author> H. Kautz, M. Kearns, and B. Selman. </author> <title> Reasoning with characteristic models. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pages 34-39, </pages> <year> 1993. </year>
Reference-contexts: In the AI community this approach can be seen as an example of Levesque's notion of "vivid" reasoning and has already been studied in <ref> [14] </ref>. The deduction problem KB j= ff can be approached using the following model-based strategy: Test Set: A set S of possible assignments. <p> For a wide class of queries we show that exact reasoning can be done efficiently, even when the reasoner keeps in KB an "approximate" representation of the "world". We show that the theory developed here generalizes the model-based approach to reasoning with Horn expressions, suggested in <ref> [14] </ref>, and captures even the notion of reasoning with theory approximations [33]. In particular, our results characterize the Horn expressions for which the approach suggested in [14] is useful and explain the phenomena observed there, regarding the relative sizes of the logical formula representation and the model-based representation of KB. <p> We show that the theory developed here generalizes the model-based approach to reasoning with Horn expressions, suggested in <ref> [14] </ref>, and captures even the notion of reasoning with theory approximations [33]. In particular, our results characterize the Horn expressions for which the approach suggested in [14] is useful and explain the phenomena observed there, regarding the relative sizes of the logical formula representation and the model-based representation of KB. We also give other examples of expressive families of propositional expressions, for which our approach is useful. <p> In Section 5 we consider the deduction problem. We introduce the set of characteristic models, and analyze the correctness and efficiency of model-based deduction with this set. In Section 6 we show that in the case of Horn expressions our theory reduces to the work in <ref> [14] </ref>. Section 7 discusses the size of model-based representations. Section 8 describes applications of the our theory to particular propositional languages. <p> Therefore, Theorem 5.6 holds for these cases. 6 Horn Expressions In this section we consider in detail the case of Horn formulas and show that in this case our notion of characteristic models coincides with the notion introduced in <ref> [14] </ref>. (Characteristic models for Horn expressions also coincide with the notion of generators in relational database theory [2, 18].) We then discuss the issue of using a fixed model-based representation for answering unrestricted queries. We show that this extension, discussed in [14], relies on a special property of Horn formulas and <p> of characteristic models coincides with the notion introduced in <ref> [14] </ref>. (Characteristic models for Horn expressions also coincide with the notion of generators in relational database theory [2, 18].) We then discuss the issue of using a fixed model-based representation for answering unrestricted queries. We show that this extension, discussed in [14], relies on a special property of Horn formulas and does not generalize to other propositional languages. An example that explains this phenomenon is given. We start by showing that Horn formulas have a small basis. <p> If x k is the only variable that appears un-negated in C then C is falsified by b (k) . 6.1 Characteristic Models In order to relate to the results from <ref> [14] </ref> we need a few definitions presented there. <p> Therefore, C can be re-written as a Horn expression. (Since C j= V V where the intersection is over all the clauses c in C.) Let c be any clause implied by C, and assume that it has m positive literals. Define m Horn strengthening <ref> [14] </ref> clauses of c, as follows: c i includes all the negative literals of c, and the ith positive literal of c. Thus, each of the clauses c i is a Horn disjunction, and c i j= c. <p> Based on this characterization of Horn expressions, it is clear that if KB is a Horn expression and M KB any subset of its models, then closure (M ) closure (KB) = KB. In <ref> [14] </ref> it is shown that if we take M = char H (KB), then we get closure (char H (KB)) = closure (KB) = KB: In particular, Equation (5) implies that char H (KB) is the smallest subset of KB with that property. <p> But since x 2 min b (k) (KB), this contradicts the assumption that x 6= y; z, and completes the proof. 6.2 General Queries In <ref> [14] </ref> it is shown that when the "world" can be described as a Horn expression one can answer any CNF query without re-computing the characteristic models. While we have shown that our general model-based representation coincides with that of [14] for the case of Horn expressions, it turns out that the <p> 6= y; z, and completes the proof. 6.2 General Queries In <ref> [14] </ref> it is shown that when the "world" can be described as a Horn expression one can answer any CNF query without re-computing the characteristic models. While we have shown that our general model-based representation coincides with that of [14] for the case of Horn expressions, it turns out that the ability to answer any query relies on a special property of Horn expressions, and does not generalize to other propositional languages. We next give a counterexample that exemplifies this. The deduction scheme in [14] when ff is a general <p> representation coincides with that of <ref> [14] </ref> for the case of Horn expressions, it turns out that the ability to answer any query relies on a special property of Horn expressions, and does not generalize to other propositional languages. We next give a counterexample that exemplifies this. The deduction scheme in [14] when ff is a general CN F expression, utilizes the following observations: 1. Every disjunction ff can be represented as ff = fi 1 _: : :_fi k , where the fi i are Horn disjunctions. 2. <p> Let KB be a Horn expression and ff any disjunction. If KB j= ff then there is a Horn disjunction fi such that KB j= fi and fi j= ff. Notice that observation (3) uses McKinsey's proof of Claim 6.2. (In <ref> [14] </ref> it is derived in a different way, using a completeness theorem for resolution given in [36].) Observation (2) implies that it is enough to consider queries that are disjunctions. Given ff, the deduction scheme in [14] decomposes it into the Horn disjunctions fi i s and tests deduction against the <p> Notice that observation (3) uses McKinsey's proof of Claim 6.2. (In <ref> [14] </ref> it is derived in a different way, using a completeness theorem for resolution given in [36].) Observation (2) implies that it is enough to consider queries that are disjunctions. Given ff, the deduction scheme in [14] decomposes it into the Horn disjunctions fi i s and tests deduction against the fi i s. By (3) at least one of the fi i s is implied by KB. <p> It is therefore important to compare this size with the size of other representations of the same function. In the previous section we have shown that our model-based representation is the same as that in <ref> [14] </ref> when the function is Horn. In [14] examples are given for large Horn expressions with a small set of characteristic models and vice versa, but it was not yet understood when and why it happens. <p> It is therefore important to compare this size with the size of other representations of the same function. In the previous section we have shown that our model-based representation is the same as that in <ref> [14] </ref> when the function is Horn. In [14] examples are given for large Horn expressions with a small set of characteristic models and vice versa, but it was not yet understood when and why it happens. <p> The same arguments hold for any b-monotone function with respect to the order relation b (one can simply rename the variables) and therefore jmin b (f )j = jDN F (f )j. Claim 7.2 explains the two examples in <ref> [14] </ref>. Both examples are 1 n -monotone Horn functions, one has a small DNF and the other has an exponentially large DNF. <p> In particular, consider the function f = ^ x i 2fp i ;q i g (x 1 _ x 2 _ : : : _ x n ) 15 defined on the 2n variables fp i ; q i g n i=1 in <ref> [14] </ref>. <p> On the other hand <ref> [14] </ref>, the function f = ^ i (p i _ q i ) has a linear size CNF expression, but its DNF , and therefore the set of characteristic models are of size O (2 n ). <p> These observations imply that our results hold for these restricted first order logic formalizations, where the polynomial bounds are relative to the number of variables in the propositional domain. 9 Abduction with Models In this section we consider the question of performing abduction using a model-based representation. In <ref> [14] </ref> it is shown that for a Horn expression KB, Abduction can be done in polynomial time using characteristic models. This is contrasted with the fact that using formula based representation the problem is NP-Hard [34]. In this section we show that the algorithm presented in [14] works for non-Horn expressions <p> In <ref> [14] </ref> it is shown that for a Horn expression KB, Abduction can be done in polynomial time using characteristic models. This is contrasted with the fact that using formula based representation the problem is NP-Hard [34]. In this section we show that the algorithm presented in [14] works for non-Horn expressions as well. 3 We note that the CNF formula size grows exponentially with the number of quantifiers. <p> KB ^ (^ x2E x) j= q and Thus, abduction involves tests for entailment (1) and consistency (2), but also a search for an explanation that passes both tests. We now show how one can use the algorithm from <ref> [14] </ref> for any propositional expression KB. Theorem 9.1 Let KB be a background propositional theory with a basis B, let A be an assumption set and q be a query. Let B H = fx 2 f0; 1g n jweight (x) n 1g. <p> Let B H = fx 2 f0; 1g n jweight (x) n 1g. Then, using the set of characteristic models = B [B H KB one can find an abductive explanation of q in time polynomial in jj and jAj. Proof: We use the algorithm Explain suggested in <ref> [14] </ref> for the case of a Horn knowledge base. For a Horn expression KB the algorithm uses the set char H (KB) = B H KB defined in Section 6. <p> The usefulness of the approach developed here is exemplified by the fact that it explains, generalizes and unifies many previous investigations, and in particular the fundamental works on reasoning with Horn models <ref> [14] </ref> and Horn approximations [33, 15, 16]. Recently, some more positive results for reasoning with characteristic models have been obtained, exhibiting the usefulness of this approach. In particular, efficient algorithms for reasoning within context and for default reasoning have been developed [20].
Reference: [15] <author> H. Kautz and B. Selman. </author> <title> A general framework for knowledge compilation. </title> <booktitle> In Proceedings of the International Workshop on Processing Declarative Knowledge, </booktitle> <address> Kaiserlautern, Germany, </address> <month> July </month> <year> 1991. </year> <month> 22 </month>
Reference-contexts: The significance of this, 9 as proved in Theorem 5.4, is that for queries with basis B reasoning with models yields correct deduction. A theory of knowledge compilation using Horn approximation was developed by Selman and Kautz in a series of papers <ref> [33, 15, 16] </ref>. Their goal is to speed up inference by replacing the original expression by two Horn approximations of it, one that implies the original expression (a lower bound) and one that is implied by it (an upper bound). <p> In this case, reasoning with models yields correct deduction for all queries in the approximation language. In particular, since there is a small fixed basis for all Horn expressions (see Claim 6.1) we can construct a Horn LUB and reason with it, generalizing the concept defined and discussed in <ref> [33, 15, 16] </ref>. Definition 5.2 (Least Upper-bound) Let F ; G be families of propositional languages. <p> On the other hand, since B KB KB, if for some u 2 B KB ; ff (u) = 0, then KB 6j= ff. A result similar to the corollary that follows, for the case in which G is the class of Horn expressions, is discussed in <ref> [15, 5, 6] </ref>. Corollary 5.5 Model-based Reasoning with KB lub (with respect to the language G) is correct for all queries in G. Example: (continued) The Horn basis for our example is: B H = f1111; 1110; 1101; 1011; 0111g (see Claim 6.1). <p> The usefulness of the approach developed here is exemplified by the fact that it explains, generalizes and unifies many previous investigations, and in particular the fundamental works on reasoning with Horn models [14] and Horn approximations <ref> [33, 15, 16] </ref>. Recently, some more positive results for reasoning with characteristic models have been obtained, exhibiting the usefulness of this approach. In particular, efficient algorithms for reasoning within context and for default reasoning have been developed [20].
Reference: [16] <author> H. Kautz and B. Selman. </author> <title> Forming concepts for fast inference. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pages 786-793, </pages> <year> 1992. </year>
Reference-contexts: The significance of this, 9 as proved in Theorem 5.4, is that for queries with basis B reasoning with models yields correct deduction. A theory of knowledge compilation using Horn approximation was developed by Selman and Kautz in a series of papers <ref> [33, 15, 16] </ref>. Their goal is to speed up inference by replacing the original expression by two Horn approximations of it, one that implies the original expression (a lower bound) and one that is implied by it (an upper bound). <p> In this case, reasoning with models yields correct deduction for all queries in the approximation language. In particular, since there is a small fixed basis for all Horn expressions (see Claim 6.1) we can construct a Horn LUB and reason with it, generalizing the concept defined and discussed in <ref> [33, 15, 16] </ref>. Definition 5.2 (Least Upper-bound) Let F ; G be families of propositional languages. <p> Nevertheless, one might hope that there is a basis for which the least upper bound will always have small representations in some (maybe other) form that admits fast reasoning. Kautz and Selman <ref> [16] </ref> show that for Horn representations this is not the case. In particular, they show that unless NP non-uniform P there is a function whose Horn LUB does not have a short representation that allows for efficient reasoning. <p> The usefulness of the approach developed here is exemplified by the fact that it explains, generalizes and unifies many previous investigations, and in particular the fundamental works on reasoning with Horn models [14] and Horn approximations <ref> [33, 15, 16] </ref>. Recently, some more positive results for reasoning with characteristic models have been obtained, exhibiting the usefulness of this approach. In particular, efficient algorithms for reasoning within context and for default reasoning have been developed [20].
Reference: [17] <author> R. Khardon. </author> <title> Translating between Horn representations and their characteristic models. </title> <journal> Journal of AI Research, </journal> <volume> 3 </volume> <pages> 349-372, </pages> <year> 1995. </year>
Reference-contexts: The question of translating between characteristic models and propositional expressions (which is relevant in database theory as well) has also been studied. Some results on the complexity of this and related questions are described in <ref> [17] </ref>. Most of the work on reasoning assumes that the knowledge base is given in some form, and the question of how this knowledge might be acquired is not considered.
Reference: [18] <author> R. Khardon, H. Mannila, and D. Roth. </author> <title> Reasoning with examples: Propositional formulae and database dependencies. </title> <type> Technical Report TR-15-95, </type> <institution> Aiken Computation Lab., Harvard University, </institution> <month> February </month> <year> 1995. </year>
Reference-contexts: The results in this paper have immediate implications in this domain (e.g., bounding the size of Armstrong relations), which are described elsewhere <ref> [18] </ref>. In addition, we consider the problem of performing abduction using a model-based approach and show that for any propositional knowledge base, using a model-based representation yields an abductive explanation in time that is polynomial in the size of the model-based representation. <p> cases. 6 Horn Expressions In this section we consider in detail the case of Horn formulas and show that in this case our notion of characteristic models coincides with the notion introduced in [14]. (Characteristic models for Horn expressions also coincide with the notion of generators in relational database theory <ref> [2, 18] </ref>.) We then discuss the issue of using a fixed model-based representation for answering unrestricted queries. We show that this extension, discussed in [14], relies on a special property of Horn formulas and does not generalize to other propositional languages. An example that explains this phenomenon is given.
Reference: [19] <author> R. Khardon and D. Roth. </author> <title> Learning to reason. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pages 682-687, </pages> <year> 1994. </year> <note> Full version: </note> <institution> TR-02-94, Aiken Computation Lab., Harvard University, </institution> <month> January </month> <year> 1994. </year>
Reference-contexts: In particular, Bshouty [4] gives an algorithm that learns the model-based representation we consider here when given access to a Membership Oracle and an Equivalence Oracle. In <ref> [19] </ref> we discuss the issue of "learning to reason" and illustrate the importance of the model-based approach for this problem. 2 Summary of Results We now briefly describe the main contributions of the model-based approach developed in this paper. <p> The previous discussion indicates that in some sense, the DNF representation of a Boolean function and the characteristic models representation introduced here are incomparable. While we do not consider here the question of how to get this knowledge representation, the following fact, shown in <ref> [19] </ref>, points to one more advantage of model-based representations. Let f be a function 16 with a polynomial size DNF representation. <p> We believe that some of the difficulties in constructing an adequate computational theory to reasoning result from the fact that these two tasks are viewed as separate. The "learning to reason" framework, which emphasizes this view, is developed and investigated in <ref> [19] </ref>. In particular, the results there illustrates the importance of the model-based approach to reasoning. Several directions for future research are possible. As mentioned in the paper, our results hold for restricted cases of first order logic, where the number of objects, and therefore the size of models is bounded.
Reference: [20] <author> R. Khardon and D. Roth. </author> <title> Default-reasoning with models. </title> <booktitle> In Proceedings of the International Joint Conference of Artificial Intelligence, </booktitle> <pages> pages 319-325, </pages> <month> August </month> <year> 1995. </year>
Reference-contexts: Recently, some more results on reasoning with models have been derived, exhibiting the usefulness of this approach. These include algorithms that use model-based representations to handle some fragments of Reiter's default logic as well as some cases of circuit diagnosis <ref> [20] </ref>. A theory of reasoning with partial models and the learnability of such representations is studied in [21]. The question of translating between characteristic models and propositional expressions (which is relevant in database theory as well) has also been studied. <p> Recently, some more positive results for reasoning with characteristic models have been obtained, exhibiting the usefulness of this approach. In particular, efficient algorithms for reasoning within context and for default reasoning have been developed <ref> [20] </ref>. An extension of the theory presented here, that applies in the case where only partial assignments are given in the knowledge base, is described in [21]. This work is part of a more general framework which views learning as an integral part of the reasoning process.
Reference: [21] <author> R. Khardon and D. Roth. </author> <title> Learning to reason with a restricted view. </title> <booktitle> In Workshop on Computational Learning Theory, </booktitle> <pages> pages 301-310, </pages> <month> July </month> <year> 1995. </year>
Reference-contexts: These include algorithms that use model-based representations to handle some fragments of Reiter's default logic as well as some cases of circuit diagnosis [20]. A theory of reasoning with partial models and the learnability of such representations is studied in <ref> [21] </ref>. The question of translating between characteristic models and propositional expressions (which is relevant in database theory as well) has also been studied. Some results on the complexity of this and related questions are described in [17]. <p> In particular, efficient algorithms for reasoning within context and for default reasoning have been developed [20]. An extension of the theory presented here, that applies in the case where only partial assignments are given in the knowledge base, is described in <ref> [21] </ref>. This work is part of a more general framework which views learning as an integral part of the reasoning process. We believe that some of the difficulties in constructing an adequate computational theory to reasoning result from the fact that these two tasks are viewed as separate.
Reference: [22] <author> S. M. Kosslyn. </author> <title> Image and Mind. </title> <publisher> Harvard Press, </publisher> <year> 1983. </year>
Reference-contexts: It is not hard to motivate a model-based approach to reasoning from a cognitive point of view and indeed, many of the proponents of this approach to reasoning have been cognitive psychologists <ref> [12, 13, 22] </ref>. In the AI community this approach can be seen as an example of Levesque's notion of "vivid" reasoning and has already been studied in [14]. The deduction problem KB j= ff can be approached using the following model-based strategy: Test Set: A set S of possible assignments.
Reference: [23] <author> H. Levesque. </author> <title> Making believers out of computers. </title> <journal> Artificial Intelligence, </journal> <volume> 30 </volume> <pages> 81-108, </pages> <year> 1986. </year>
Reference-contexts: Many other forms of reasoning which have been developed at least partly to avoid these computational difficulties, were also shown to be hard to compute [31, 30]. A significant amount of recent work on reasoning is influenced by convincing arguments of Levesque <ref> [23] </ref> who argued that common-sense reasoning is a distinct mode of reasoning and that we should give a computational theory that accounts for both its speed and flexibility. <p> None of these works, however, meets the strong tractability requirements required for common-sense reasoning (e.g. see [35]), even though the limited expressiveness of classes discussed there has been argued to be implausible [7]. Levesque argues <ref> [23, 24] </ref> that reasoning with a more direct representation is easier and better suits common-sense reasoning. He suggests to represent the knowledge base KB in a vivid form, which bears a strong and direct relationship to the real world.
Reference: [24] <author> H. Levesque. </author> <title> Is reasoning too hard ? In Proceeding of the 3rd NEC research Symposium. </title> <year> 1992. </year>
Reference-contexts: Thus, this line of research aims at identifying classes of limited expressiveness, with which one can perform theorem proving efficiently <ref> [3, 24, 30, 31] </ref>. None of these works, however, meets the strong tractability requirements required for common-sense reasoning (e.g. see [35]), even though the limited expressiveness of classes discussed there has been argued to be implausible [7]. <p> None of these works, however, meets the strong tractability requirements required for common-sense reasoning (e.g. see [35]), even though the limited expressiveness of classes discussed there has been argued to be implausible [7]. Levesque argues <ref> [23, 24] </ref> that reasoning with a more direct representation is easier and better suits common-sense reasoning. He suggests to represent the knowledge base KB in a vivid form, which bears a strong and direct relationship to the real world.
Reference: [25] <author> H. Mannila and K. J. Raiha. </author> <title> Design by example: An application of Armstrong relations. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 33(2) </volume> <pages> 126-141, </pages> <year> 1986. </year>
Reference-contexts: We also give other examples of expressive families of propositional expressions, for which our approach is useful. We note that characteristic models were studied independently in the Relational Data Base community (where they are called "generators") <ref> [2, 25] </ref>, for the special case of definite Horn expressions. The results in this paper have immediate implications in this domain (e.g., bounding the size of Armstrong relations), which are described elsewhere [18].
Reference: [26] <author> J. McCarthy. </author> <title> Programs with common sense. </title> <booktitle> In Proceedings of the Symposium on the Mechanization of Thought Processes, </booktitle> <volume> volume 1, </volume> <pages> pages 77-84. </pages> <institution> National Physical Laboratory, </institution> <year> 1958. </year> <editor> Reprinted in Minsky`s (ed.) </editor> <booktitle> Semantic Information Processing, </booktitle> <publisher> MIT Press(1968), </publisher> <pages> 403-409. </pages> <note> Also in R. </note> <editor> Brachman and H. Levesque, </editor> <booktitle> Readings in Knowledge Representation, </booktitle> <year> 1985. </year>
Reference-contexts: 1 Introduction A widely accepted framework for reasoning in intelligent systems is the knowledge-based system approach <ref> [26] </ref>. The idea is to keep the knowledge in some representation language with a well defined meaning assigned to those sentences. The sentences are stored in a Knowledge Base (KB) which is combined with a reasoning mechanism, used to determine what can be inferred from the sentences in the KB.
Reference: [27] <author> J. C. C McKinsey. </author> <title> The decision problem for some classes of sentences without quantifier. </title> <journal> Journal of Symbolic Logic, </journal> <volume> 8(3) </volume> <pages> 61-76, </pages> <year> 1943. </year>
Reference-contexts: Formally, char H (KB) = fu 2 KB j u 62 closure (KB n fug) g: (5) 12 The following claim is due to McKinsey <ref> [27] </ref>, and has also been discussed by Horn [11]. The claim in [27] is given in the context of first order equational expressions, and the notation used there is substantially different. <p> Formally, char H (KB) = fu 2 KB j u 62 closure (KB n fug) g: (5) 12 The following claim is due to McKinsey <ref> [27] </ref>, and has also been discussed by Horn [11]. The claim in [27] is given in the context of first order equational expressions, and the notation used there is substantially different. To facilitate the discussion, we give an adaption of the proof to the current terminology. (A different proof of this property, for the propositional domain, appears in [6].) Claim 6.2 ([27]) A
Reference: [28] <author> C. H. Papadimitriou. </author> <title> On selecting a satisfying truth assignment. </title> <booktitle> In Proc. 32nd Ann. IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 163-169, </pages> <year> 1991. </year>
Reference-contexts: Levesque argues [23, 24] that reasoning with a more direct representation is easier and better suits common-sense reasoning. He suggests to represent the knowledge base KB in a vivid form, which bears a strong and direct relationship to the real world. This might be just a model of KB <ref> [8, 28] </ref> on which one can evaluate the truth value of the query ff. It is not clear, however, how one might derive a vivid form of the knowledge base. <p> It is not clear, however, how one might derive a vivid form of the knowledge base. Moreover, selecting a model which is the most likely model of the real world, under various reasonable criteria, is computationally hard <ref> [28, 32] </ref>.
Reference: [29] <author> R. Reiter and J. De Kleer. </author> <title> Foundations of assumption-based truth maintenance systems. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pages 183-188, </pages> <year> 1987. </year>
Reference-contexts: This, however, does not affect our results which depend on the size of the basis and the size of the DNF formula. 19 Abduction is the task of finding a minimal explanation for some observation. Formally <ref> [29] </ref>, the reasoner is given a knowledge base KB (the background theory), a set of propositional letters 4 A (the assumption set), and a query letter q. An explanation of q is a minimal subset E A such that 1. <p> For Horn expressions explanations turn out to be composed of positive literals (this can be concluded from Corollary 4 in <ref> [29] </ref>). Here we restrict ourselves to explanations composed of positive literals (by allowing only positive literals in the assumption set) when using general expressions. One may therefore talk about "positive explanations" instead of explanations.
Reference: [30] <author> D. Roth. </author> <title> On the hardness of approximate reasoning. </title> <booktitle> In Proceedings of the International Joint Conference of Artificial Intelligence, </booktitle> <pages> pages 613-618, </pages> <month> August </month> <year> 1993. </year> <note> To Appear in Artificial Intelligence Journal. </note>
Reference-contexts: Many other forms of reasoning which have been developed at least partly to avoid these computational difficulties, were also shown to be hard to compute <ref> [31, 30] </ref>. A significant amount of recent work on reasoning is influenced by convincing arguments of Levesque [23] who argued that common-sense reasoning is a distinct mode of reasoning and that we should give a computational theory that accounts for both its speed and flexibility. <p> Thus, this line of research aims at identifying classes of limited expressiveness, with which one can perform theorem proving efficiently <ref> [3, 24, 30, 31] </ref>. None of these works, however, meets the strong tractability requirements required for common-sense reasoning (e.g. see [35]), even though the limited expressiveness of classes discussed there has been argued to be implausible [7]. <p> Of course, computing the approximations is a hard computational problem, and this is why it is suggested as a compilation process. The computational problems of computing Horn approximations and reasoning with them are studied also in <ref> [5, 10, 30] </ref>. To facilitate the presentation we first define the notion of an approximation of KB.
Reference: [31] <author> B. Selman. </author> <title> Tractable Default Reasoning. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, University of Toronto, </institution> <year> 1990. </year>
Reference-contexts: Many other forms of reasoning which have been developed at least partly to avoid these computational difficulties, were also shown to be hard to compute <ref> [31, 30] </ref>. A significant amount of recent work on reasoning is influenced by convincing arguments of Levesque [23] who argued that common-sense reasoning is a distinct mode of reasoning and that we should give a computational theory that accounts for both its speed and flexibility. <p> Thus, this line of research aims at identifying classes of limited expressiveness, with which one can perform theorem proving efficiently <ref> [3, 24, 30, 31] </ref>. None of these works, however, meets the strong tractability requirements required for common-sense reasoning (e.g. see [35]), even though the limited expressiveness of classes discussed there has been argued to be implausible [7].
Reference: [32] <author> B. Selman and H. Kautz. </author> <title> Model-preference default theories. </title> <journal> Artificial Intelligence, </journal> <volume> 45 </volume> <pages> 287-322, </pages> <year> 1990. </year>
Reference-contexts: It is not clear, however, how one might derive a vivid form of the knowledge base. Moreover, selecting a model which is the most likely model of the real world, under various reasonable criteria, is computationally hard <ref> [28, 32] </ref>.
Reference: [33] <author> B. Selman and H. Kautz. </author> <title> Knowledge compilation using Horn approximations. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pages 904-909, </pages> <year> 1991. </year>
Reference-contexts: We show that the theory developed here generalizes the model-based approach to reasoning with Horn expressions, suggested in [14], and captures even the notion of reasoning with theory approximations <ref> [33] </ref>. In particular, our results characterize the Horn expressions for which the approach suggested in [14] is useful and explain the phenomena observed there, regarding the relative sizes of the logical formula representation and the model-based representation of KB. <p> We show that even in this case we can perform exact deduction. As we show, reasoning with characteristic models of KB with respect to a basis B is equivalent to reasoning with the least upper bound (LUB) <ref> [33] </ref> of KB in the class of functions with basis B. The significance of this, 9 as proved in Theorem 5.4, is that for queries with basis B reasoning with models yields correct deduction. <p> The significance of this, 9 as proved in Theorem 5.4, is that for queries with basis B reasoning with models yields correct deduction. A theory of knowledge compilation using Horn approximation was developed by Selman and Kautz in a series of papers <ref> [33, 15, 16] </ref>. Their goal is to speed up inference by replacing the original expression by two Horn approximations of it, one that implies the original expression (a lower bound) and one that is implied by it (an upper bound). <p> In this case, reasoning with models yields correct deduction for all queries in the approximation language. In particular, since there is a small fixed basis for all Horn expressions (see Claim 6.1) we can construct a Horn LUB and reason with it, generalizing the concept defined and discussed in <ref> [33, 15, 16] </ref>. Definition 5.2 (Least Upper-bound) Let F ; G be families of propositional languages. <p> The usefulness of the approach developed here is exemplified by the fact that it explains, generalizes and unifies many previous investigations, and in particular the fundamental works on reasoning with Horn models [14] and Horn approximations <ref> [33, 15, 16] </ref>. Recently, some more positive results for reasoning with characteristic models have been obtained, exhibiting the usefulness of this approach. In particular, efficient algorithms for reasoning within context and for default reasoning have been developed [20].
Reference: [34] <author> B. Selman and H. Levesque. </author> <title> Abductive and default reasoning: A computational core. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pages 343-348, </pages> <year> 1990. </year>
Reference-contexts: In [14] it is shown that for a Horn expression KB, Abduction can be done in polynomial time using characteristic models. This is contrasted with the fact that using formula based representation the problem is NP-Hard <ref> [34] </ref>. In this section we show that the algorithm presented in [14] works for non-Horn expressions as well. 3 We note that the CNF formula size grows exponentially with the number of quantifiers.
Reference: [35] <author> L. Shastri. </author> <title> A computational model of tractable reasoning taking inspiration from cognition. </title> <booktitle> In Proceedings of the International Joint Conference of Artificial Intelligence, </booktitle> <pages> pages 202-207, </pages> <month> August </month> <year> 1993. </year>
Reference-contexts: Thus, this line of research aims at identifying classes of limited expressiveness, with which one can perform theorem proving efficiently [3, 24, 30, 31]. None of these works, however, meets the strong tractability requirements required for common-sense reasoning (e.g. see <ref> [35] </ref>), even though the limited expressiveness of classes discussed there has been argued to be implausible [7]. Levesque argues [23, 24] that reasoning with a more direct representation is easier and better suits common-sense reasoning.
Reference: [36] <author> J.R. Slage, C.L. Chang, and R.C.T. Lee. </author> <title> Completeness theorems for semantic resolution in consequence finding. </title> <booktitle> In Proceedings of the International Joint Conference of Artificial Intelligence, </booktitle> <pages> pages 281-285, </pages> <month> August </month> <year> 1969. </year>
Reference-contexts: If KB j= ff then there is a Horn disjunction fi such that KB j= fi and fi j= ff. Notice that observation (3) uses McKinsey's proof of Claim 6.2. (In [14] it is derived in a different way, using a completeness theorem for resolution given in <ref> [36] </ref>.) Observation (2) implies that it is enough to consider queries that are disjunctions. Given ff, the deduction scheme in [14] decomposes it into the Horn disjunctions fi i s and tests deduction against the fi i s.
Reference: [37] <author> M. H. Van-Emden and R. A. Kowalski. </author> <title> The semantics of predicate logic as a programming language. </title> <journal> Journal of the ACM, </journal> <volume> 23(4) </volume> <pages> 733-742, </pages> <year> 1976. </year> <month> 24 </month>
Reference-contexts: Proof: A proof that the models of Horn expressions are closed under intersection is given in <ref> [37] </ref>. For the other direction, let C be a CNF expression such that its models are closed under intersection. We claim that every clause c in C can be replaced with a Horn clause c H such that C j= c H j= c.
References-found: 37

