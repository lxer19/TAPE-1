URL: ftp://ftp.cs.ucla.edu/pub/stat_ser/R203-L.ps
Refering-URL: http://singapore.cs.ucla.edu/csl_papers.html
Root-URL: http://www.cs.ucla.edu
Email: judea@cs.ucla.edu  
Phone: Phone: (310) 825-3243 Fax: (310) 825-2273  
Title: Causal Inference from Indirect Experiments  
Author: Judea Pearl 
Keyword: Causal reasoning, treatment evaluation, noncompliance, graph ical models  
Address: Los Angeles, CA 90024  
Affiliation: Cognitive Systems Laboratory Computer Science Department University of California,  
Abstract: Indirect experiments are studies in which randomized control is replaced by randomized encouragement, that is, subjects are encouraged, rather than forced to receive treatment programs. The purpose of this paper is to bring to the attention of experimental researchers simple mathematical results that enable us to assess, from indirect experiments, the strength with which causal influences operate among variables of interest. The results reveal that despite the laxity of the encouraging instrument, indirect experimentation can yield significant and sometimes accurate information on the impact of a program on the population as a whole, as well as on the particular individuals who participated in the program. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J.D. Angrist and G.W. Imbens, </author> <title> Source of identifying information in evaluation models, </title> <type> Discussion Paper 1568, </type> <institution> Department of Economics, Harvard University, </institution> <address> Cambridge, MA, </address> <year> 1991. </year>
Reference-contexts: More remarkably, under conditions of no intrusion (namely, P (d 1 jz 0 ) = 0, as in most clinical trials), ff fl can be identified precisely <ref> [1] </ref>.
Reference: [2] <author> A.A. Balke and J. Pearl, </author> <title> Nonparametric bounds on causal effects from partial compliance data, </title> <type> Technical Report No. 199, </type> <institution> Cognitive Systems Laboratory, 15 UCLA Computer Science Department, </institution> <address> Los Angeles, CA, </address> <month> September </month> <year> 1993. </year> <note> Sub--mitted for publication. </note>
Reference-contexts: ff P (y 1 jz 1 ) P (y 1 jz 0 ) P (y 1 ; d 0 jz 1 ) P (y 0 ; d 1 jz 0 ) Due to their simplicity and wide range of applicability, the bounds of Eq. (5) were named the natural bounds <ref> [2] </ref>. <p> The width of the natural bounds, not surprisingly, is given by the rate of noncompliance, P (d 1 jz 0 ) + P (d 0 jz 1 ). This width can be narrowed further using linear programming <ref> [2] </ref>, which shows that, even under conditions of imperfect compliance, some experimental data (i.e., P (x; yjz)) can permit the precise evaluation of ff. <p> Under this assumption, the inequalities in Eq. (11) can be tightened <ref> [2] </ref> to give P (y; d 1 jz 1 ) P (y; d 0 jz 0 ) for all y 2 fy 0 ; y 1 g. <p> can be written in close mathematical form as E [P (y 1 jx; u)] = z X P (yjx 0 ; z 0 )P (x 0 ) - U @ @ @R u u u - Acknowledgment This investigation owes much to the results of Alex Balke, as reported in <ref> [2, 3] </ref>; Alex's encounter with Dr. Pearson was not entirely fantastical. I value the encouragement of James Robins, who probably is the only public health researcher who currently appreciates the usefulness of these results.
Reference: [3] <author> A.A. Balke and J. Pearl, </author> <title> Counterfactual probabilities: Computational methods, bounds, and applications, </title> <editor> in: R. Lopez de Mantaras and D. Poole, eds., </editor> <booktitle> Proceedings of the Tenth Conference on Uncertainty in Artificial Intelligence (Morgan Kaufmann, </booktitle> <address> San Mateo, CA, </address> <year> 1994) </year> <month> 46-54. </month>
Reference-contexts: can be written in close mathematical form as E [P (y 1 jx; u)] = z X P (yjx 0 ; z 0 )P (x 0 ) - U @ @ @R u u u - Acknowledgment This investigation owes much to the results of Alex Balke, as reported in <ref> [2, 3] </ref>; Alex's encounter with Dr. Pearson was not entirely fantastical. I value the encouragement of James Robins, who probably is the only public health researcher who currently appreciates the usefulness of these results.
Reference: [4] <author> R.J. Bowden and D.A. </author> <title> Turkington, </title> <publisher> Instrumental Variables (Cambridge University Press, </publisher> <address> Cambridge, UK, </address> <year> 1984). </year>
Reference-contexts: These two assumptions are equivalent to stating that Z is independent of U , a condition that economists call exogeneity, and which qualifies Z as an instrumental variable <ref> [4] </ref> relative to the relation between D and Y . 5 For a long time, it has been thought that it is impossible to verify experimentally whether a variable Z is exogenous, since the definition involves unobservable factors (or disturbances, as they are usually called) such as those represented by U
Reference: [5] <author> D.R. Cox, </author> <title> The Planning of Experiments (John Wiley and Sons, </title> <address> New York, </address> <year> 1958). </year>
Reference-contexts: This stands contrary to most of the literature on statistical experimentation, which considers the measurement of intermediate variables affected by the action to be useless, if not harmful, for causal inference <ref> [5, 18] </ref>.
Reference: [6] <author> J.T. Cushing and E. </author> <title> McMullin, </title> <type> eds., </type> <institution> Philosophical Consequences of Quantum Theory (University of Notre Dame Press, South Bend, IA, </institution> <year> 1989). </year>
Reference-contexts: Although such changes could in principle be explained by strong correlations between U , D, and Y (since D does not screen off Z from Y ), the instrumental inequality sets a limit on the magnitude of the changes. The similarity to Bell's inequality in quantum physics <ref> [6, 20] </ref> is not accidental; both inequalities delineate a class of observed correlations that cannot be explained by hypothesizing latent common causes.
Reference: [7] <author> B. Efron and D. Feldman, </author> <title> Compliance as an explanatory variable in clinical trials, </title> <journal> Journal of the American Statistical Association, </journal> <volume> Vol. 86, No. </volume> <month> 413 </month> <year> (1991) </year> <month> 9-26. </month>
Reference-contexts: For example, subjects experiencing adverse reactions to an experimental drug may decide to reduce the assigned dosage. Such imperfect compliance introduces appreciable bias into the conclusions that researchers draw from data, and this bias cannot be corrected unless detailed models of compliance are con structed <ref> [7] </ref>. 2. Denying subjects assigned to certain control groups the benefits of the best available treatment has moral and legal ramifications. <p> A portion of this data consisting of 337 subjects was analyzed in <ref> [7] </ref> and is the focus of this example. Subjects were randomized into two treatments groups of roughly equal size; in one group, all subjects were prescribed cholestyramine (z 1 ), while the subjects in the other group were prescribed a placebo (z 0 ).
Reference: [8] <author> A.S. Goldberger, </author> <title> Structural equation methods in the social sciences, </title> <journal> Economet-rica, </journal> <volume> Vol. </volume> <month> 40 </month> <year> (1972) </year> <month> 979-1001. </month>
Reference-contexts: from A to B is the same as those switching from B to A and (b) the success rate in one treatment arm is either zero or 100%. 5 Instrumental variables is a technique invented by the geneticist Sewal Wright (1928) to help economists identify elasticities of supply and demand <ref> [8] </ref>. The key idea is that the coefficient b in the (causal) equation Y = bX + U cannot be identified if X and U are correlated.
Reference: [9] <author> J.J. Heckman, </author> <title> Randomization and social policy evaluation, </title> <editor> in: C. Manski and I. Garfinkle, eds., </editor> <publisher> Evaluations of Welfare and Training Programs (Harvard University Press, </publisher> <year> 1992) </year> <month> 201-230. </month>
Reference-contexts: For example, it is difficult to justify placebo programs in AIDS research because those patients assigned to the placebo group would be denied access to potentially life saving treatment [13]. 3. Randomization, by its very presence, may influence participation as well as behavior <ref> [9] </ref>. For example, eligible candidates may be wary of applying to a school once they discover that it deliberately randomizes its admission criteria. <p> the treated: ff fl = E [P (y 1 jd 1 ; u) P (y 1 jd 0 ; u)jD = d 1 ] (4) namely, the change of the mean response of the treated subjects compared to the mean response of these same subjects had they not been treated <ref> [9] </ref>.
Reference: [10] <author> M.S. Kramer and S. Shapiro, </author> <title> Scientific Challenges in the Application of Randomized Trials, </title> <journal> Journal of the American Medical Association Vol. </journal> <month> 252 </month> <year> (1984) </year> <month> 2739-2745. </month>
Reference-contexts: Randomization, by its very presence, may influence participation as well as behavior [9]. For example, eligible candidates may be wary of applying to a school once they discover that it deliberately randomizes its admission criteria. Likewise, as Kramer and Shapiro <ref> [10] </ref> note, subjects in drug trials were less likely to participate in randomized trials than in nonexperimental studies, even when the treatments were equally nonthreatening.
Reference: [11] <editor> The Lipid Research Clinics Coronary Primary Prevention Trial results, </editor> <title> parts I and II, </title> <journal> Journal of the American Medical Association, </journal> <volume> Vol. 251, No. </volume> <month> 3 </month> <year> (1984) </year> <month> 351-374. </month>
Reference-contexts: populations, divided by the rate of participation P (d 1 jz 1 ). 4 Example 1: The Effects of Cholestyramine To demonstrate by example how the bounds for ff can be used to provide meaningful information about causal effects, consider the Lipid Research Clinics Coronary Primary Prevention Trial data (see <ref> [11] </ref>). A portion of this data consisting of 337 subjects was analyzed in [7] and is the focus of this example.
Reference: [12] <author> C.F. Manski, </author> <title> Nonparametric bounds on treatment effects, </title> <journal> American Economic Review, Papers and Proceedings, </journal> <volume> Vol. </volume> <month> 80 </month> <year> (1990) </year> <month> 319-323. </month>
Reference-contexts: The formulas reported in this paper provide assessments for both ff and ff fl . 5 3 Summary of Results Analysis shows <ref> [19, 12, 14] </ref> that the expression for ff (Eq. (2)) can be bounded by two simple formulas, each made up of observed parameters of P (y; djz) (see Appendix): ff P (y 1 jz 1 ) P (y 1 jz 0 ) P (y 1 ; d 0 jz 1 )
Reference: [13] <author> J. Palca, </author> <title> AIDS drug trials enter new age, </title> <note> Science Magazine (1989) 19-21. </note>
Reference-contexts: Denying subjects assigned to certain control groups the benefits of the best available treatment has moral and legal ramifications. For example, it is difficult to justify placebo programs in AIDS research because those patients assigned to the placebo group would be denied access to potentially life saving treatment <ref> [13] </ref>. 3. Randomization, by its very presence, may influence participation as well as behavior [9]. For example, eligible candidates may be wary of applying to a school once they discover that it deliberately randomizes its admission criteria.
Reference: [14] <author> J. Pearl, </author> <title> From Bayesian networks to causal networks, </title> <booktitle> in: Proceedings of the Adaptive Computing and Information Processing Seminar, Brunel Conference Centre, </booktitle> <address> London, </address> <month> January 25-27, </month> <year> 1994. </year> <note> See also Statistical Science, Vol. 8, No. 3 (1993) 266-269. </note>
Reference-contexts: The formulas reported in this paper provide assessments for both ff and ff fl . 5 3 Summary of Results Analysis shows <ref> [19, 12, 14] </ref> that the expression for ff (Eq. (2)) can be bounded by two simple formulas, each made up of observed parameters of P (y; djz) (see Appendix): ff P (y 1 jz 1 ) P (y 1 jz 0 ) P (y 1 ; d 0 jz 1 )
Reference: [15] <author> J. Pearl, </author> <title> A note on testing exogeneity of instrumental variables, </title> <type> Technical Report R-211-S, </type> <institution> Cognitive Systems Laboratory, UCLA Computer Science Department, </institution> <address> Los Angeles, CA, </address> <month> December </month> <year> 1993. </year>
Reference-contexts: The inequalities in Eq. (11), when generalized to multivalued variables, assume the form max X [max P (y; djz)] 1 (12) which was called the instrumental inequality in <ref> [15] </ref>. We see that the instrumental inequality is violated when the controlling instrument Z manages to produce significant changes in the response variable Y while the treatment D remains constant.
Reference: [16] <author> J. Pearl, </author> <title> Causal diagrams for experimental research, </title> <type> Technical Report R-218-L, </type> <institution> Cognitive Systems Laboratory, UCLA Computer Science Department, </institution> <address> Los Angeles, CA, </address> <month> May </month> <year> 1993. </year> <note> To appear in Biometrika. </note>
Reference-contexts: Given an arbitrary causal graph of the type described in Figure 1, only some of whose nodes are observable, it is now possible to determine by graphical techniques whether the causal effect of one variable on another can be computed from nonexperimental data over the observables <ref> [16, 17] </ref>. If the answer is yes, then randomized experiments are not necessary and one can predict the effect of interventions by symbolic manipulation of graphs and probabilities.
Reference: [17] <author> J. Pearl, </author> <title> A probabilistic calculus of actions, </title> <editor> in: R. Lopez de Mantaras and D. Poole, eds., </editor> <booktitle> Proceedings of the Tenth Conference on Uncertainty in Artificial Intelligence (Morgan Kaufman, </booktitle> <address> San Mateo, CA, </address> <year> 1994) </year> <month> 454-462. </month>
Reference-contexts: Given an arbitrary causal graph of the type described in Figure 1, only some of whose nodes are observable, it is now possible to determine by graphical techniques whether the causal effect of one variable on another can be computed from nonexperimental data over the observables <ref> [16, 17] </ref>. If the answer is yes, then randomized experiments are not necessary and one can predict the effect of interventions by symbolic manipulation of graphs and probabilities.
Reference: [18] <author> J.W. Pratt and R. Schlaifer, </author> <title> On the interpretation and observation of laws, </title> <journal> Journal of Econometrics, </journal> <volume> Vol. </volume> <month> 39 </month> <year> (1988) </year> <month> 23-52. </month>
Reference-contexts: This stands contrary to most of the literature on statistical experimentation, which considers the measurement of intermediate variables affected by the action to be useless, if not harmful, for causal inference <ref> [5, 18] </ref>.
Reference: [19] <author> J.M. Robins, </author> <title> The analysis of randomized and non-randomized AIDS treatment trials using a new approach to causal inference in longitudinal studies, </title> <editor> in: L. Sechrest, H. Freeman, and A. Mulley, eds., </editor> <title> Health Service Research Methodology: A Focus on AIDS (NCHSR, </title> <type> U.S. </type> <institution> Public Health Service, </institution> <year> 1989) </year> <month> 113-159. </month>
Reference-contexts: The formulas reported in this paper provide assessments for both ff and ff fl . 5 3 Summary of Results Analysis shows <ref> [19, 12, 14] </ref> that the expression for ff (Eq. (2)) can be bounded by two simple formulas, each made up of observed parameters of P (y; djz) (see Appendix): ff P (y 1 jz 1 ) P (y 1 jz 0 ) P (y 1 ; d 0 jz 1 )
Reference: [20] <author> P. Suppes, </author> <title> Probabilistic causality in space and time, </title> <editor> in: B. Skyrms and W.L. Harper, eds., Causation, Chance, </editor> <publisher> and Credence (Kluwer Academic Publishers, </publisher> <address> Dordrecht, The Netherlands, </address> <year> 1988) </year> <month> 135-151. </month>
Reference-contexts: Although such changes could in principle be explained by strong correlations between U , D, and Y (since D does not screen off Z from Y ), the instrumental inequality sets a limit on the magnitude of the changes. The similarity to Bell's inequality in quantum physics <ref> [6, 20] </ref> is not accidental; both inequalities delineate a class of observed correlations that cannot be explained by hypothesizing latent common causes.
Reference: [21] <author> S. Wright, </author> <title> Appendix, </title> <editor> in: P.G. Wright, </editor> <booktitle> The Tariff on Animal and Vegetable Oils (Macmillan, </booktitle> <address> New York, </address> <year> 1928) </year> <month> PAGES. 17 </month>
References-found: 21

