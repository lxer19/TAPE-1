URL: http://www.cs.purdue.edu/homes/spaf/tech-reps/9383.ps
Refering-URL: http://www.cs.purdue.edu/coast/coast-library.html
Root-URL: http://www.cs.purdue.edu
Email: sjc@cs.kent.edu spaf@cs.purdue.edu  
Title: Constructing Distributed Schedulers Using the messiahs Interface Language  
Author: Steve J. Chapin Eugene H. Spafford 
Address: OH 44242-0001 West Lafayette, IN 47907-1398  
Affiliation: Dept. of Math. Computer Science Dept. of Computer Sciences Kent State University Purdue University Kent,  
Abstract: As part of this work, we have constructed an interface layer to the underlying mechanisms. This includes the messiahs Interface Language (MIL) for constructing distributed schedulers. This paper gives an overview of messiahs, describes a sample interface layer in detail, and gives example implementations of well-known algorithms from the literature built using this layer. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. V. Aho, J. E. Hopcroft, and J. D. Ullman. </author> <title> The Design and Analysis of Computer Algorithms. </title> <publisher> Addison-Wesley Publishing Company, </publisher> <year> 1974. </year> <note> ISBN 0-201-00029-6. </note>
Reference-contexts: Individual systems enjoy execution autonomy, communication autonomy, design autonomy, and administrative autonomy as defined in [11, 16, 14]. Execution autonomy means that each system decides whether it 2 These correspond to the formal definitions of father, son, and brother found in <ref> [1] </ref>. will honor a request to execute a task; each system also has the right to revoke a task that it had previously accepted. Communication autonomy means that each system decides the content and frequency of state advertisements, and what other messages it sends.
Reference: [2] <author> G. J. Bergmann and J. M. Jagadeesh. </author> <title> An MIMD Parallel Processing Programming System with Automatic Resource Allocation. </title> <booktitle> In Proceedings of the ISMM International Workshop on Parallel Computing, </booktitle> <pages> pages 301-304, </pages> <address> Trani, Italy, </address> <month> September 10-13 </month> <year> 1991. </year>
Reference: [3] <author> B. A. Blake. </author> <title> Assignment of Independent Tasks to Minimize Completion Time. </title> <journal> Software-Practice and Experience, </journal> <volume> 22(9) </volume> <pages> 723-734, </pages> <month> September </month> <year> 1992. </year>
Reference: [4] <author> F. Bonomi. </author> <title> On Job Assignment for a Parallel System of Processor Sharing Queues. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 39(7) </volume> <pages> 858-869, </pages> <month> July </month> <year> 1990. </year>
Reference: [5] <author> F. Bonomi and A. Kumar. </author> <title> Adaptive Optimal Load Balancing in a Nonhomogeneous Multiserver System with a Central Job Scheduler. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 39(10) </volume> <pages> 1232-1250, </pages> <month> October </month> <year> 1990. </year>
Reference: [6] <author> M. Bowman, L. L. Peterson, and A. Yeatts. Univers: </author> <title> An Attribute-Based Name Server. </title> <journal> Software-Practice and Experience, </journal> <volume> 20(4) </volume> <pages> 403-424, </pages> <month> April </month> <year> 1990. </year>
Reference-contexts: We have chosen to provide a simple programming language as our interface, similar to that used in Univers <ref> [6] </ref>. Other interfaces are possible, such as a library of high-level language functions (see [9]). The messiahs Interface Language (MIL) contains direct support for dynamic scheduling algorithms, without precluding support for static algorithms. Static algorithms consider only the system topography, not the state, when calculating the mapping.
Reference: [7] <author> A. Bricker, M. Litzkow, and M. Livny. </author> <title> Condor Technical Summary. </title> <type> Technical Report 1069, </type> <institution> Department of Computer Science, University of Wisconsin-Madison, </institution> <month> January </month> <year> 1992. </year>
Reference-contexts: This approach is distinct from that taken in distributed programming systems such as PVM [18] in which the program distribution is visible, and even forced upon, the programmer. The messiahs approach more closely reflects that taken in Condor <ref> [7] </ref>, which schedules processes invisibly for the programmer. Program distribution is under the control of the autonomous system, and therefore the administrators, rather than the programmer. 2 The MESSIAHS Architecture messiahs supports task placement in distributed systems with hierarchical structure based on administrative domains, modeled by directed acyclic graphs. <p> In particular, a local system can run in a manner counterproductive to a global optimum. In the usual case, scheduling modules will cooperate, but administrators must be free to set their local policies or they will not participate in the distributed system. Both <ref> [7] </ref> and [17] note that users are willing to execute remote jobs on their workstations if the scheduling policy places higher priority on local jobs. scheduling module. <p> system to take on new tasks loadave an estimate of the load aver age for the entire system Procclass information on the different classes of processors in the system To determine the basis for the fixed portion of the description vector, we reviewed 18 algorithms from the existing scheduling literature <ref> [2-5, 7, 13, 17-20, 22-24, 26-28, 30, 31] </ref>. Table 1 depicts the resulting data set. We found that only two characteristics| processor speed and inter-processor communication time estimates|were used by more than four algorithms. <p> The first demonstrates the task revocation facility as used by a general-purpose distributed batch system. The second implements a load-balancing algorithm. 5.1 Distributed Batch The mitre distributed batch [17], Condor <ref> [7] </ref>, and Remote Unix [23] systems support general-purpose distributed processing for machines running the Unix operating system. Figure 5 lists a short specification file for a SPARC IPC participating in a distributed batching system.
Reference: [8] <author> T. L. Casavant and J. G. Kuhl. </author> <title> A Taxonomy of Scheduling in General-Purpose Distributed Computing Systems. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 14(2) </volume> <pages> 141-154, </pages> <month> February </month> <year> 1988. </year>
Reference-contexts: A central element of effective utilization of such systems is task scheduling. Task scheduling has two components: macro-scheduling (also defined as global scheduling <ref> [8] </ref> and task assignment [24]) and micro-scheduling (or local scheduling [8]). Macro-scheduling chooses where to run a process, while micro-scheduling selects which eligible process to execute next on a particular processor. All further uses of the term scheduling in this paper refer to macro-scheduling. <p> A central element of effective utilization of such systems is task scheduling. Task scheduling has two components: macro-scheduling (also defined as global scheduling <ref> [8] </ref> and task assignment [24]) and micro-scheduling (or local scheduling [8]). Macro-scheduling chooses where to run a process, while micro-scheduling selects which eligible process to execute next on a particular processor. All further uses of the term scheduling in this paper refer to macro-scheduling. <p> Static algorithms consider only the system topography, not the state, when calculating the mapping. Dynamic algorithms take the current system state as input, therefore the resultant mapping depends on the state (see <ref> [8] </ref>). Figure 3 depicts the structure of an MIL program.
Reference: [9] <author> S. J. Chapin. </author> <title> Scheduling Support Mechanisms for Autonomous, Heterogeneous, Distributed Systems. </title> <type> Ph.D. Dissertation, </type> <institution> Purdue University, </institution> <year> 1993. </year>
Reference-contexts: Macro-scheduling chooses where to run a process, while micro-scheduling selects which eligible process to execute next on a particular processor. All further uses of the term scheduling in this paper refer to macro-scheduling. The messiahs 1 system <ref> [9, 10, 11] </ref> provides a set of mechanisms that facilitate scheduling in distributed, heterogeneous, autonomous systems. For our purposes, distributed, or loosely-coupled, systems communicate via message passing rather than a shared memory bus. Heterogeneous systems may have different instruction set architectures, data formats, and attached devices. <p> The address and module fields uniquely identify a scheduling module: the address specifies a machine, and the module indicates which module on that machine. messiahs allows multiple modules to run on a single machine (see <ref> [9] </ref>). The nsys field indicates how many systems the vector represents; just as a distributed system encapsulates multiple subordinate systems, the description vector for a system contains information describing its component systems. <p> We have chosen to provide a simple programming language as our interface, similar to that used in Univers [6]. Other interfaces are possible, such as a library of high-level language functions (see <ref> [9] </ref>). The messiahs Interface Language (MIL) contains direct support for dynamic scheduling algorithms, without precluding support for static algorithms. Static algorithms consider only the system topography, not the state, when calculating the mapping. <p> MIL also assumes that neighbors can be trusted to tell the truth in their SDV advertisements, and depends on a model of timely information exchange. A more complex approach that addresses these limitations, implemented as a set of library calls for ligh-level languages, appears in <ref> [9] </ref>. In summary, messiahs embodies mechanisms supporting task placement in distributed, heterogeneous, autonomous systems. This support includes extensi ble mechanisms for implementing the local scheduling policy.
Reference: [10] <author> S. J. Chapin and E. H. Spafford. </author> <title> Scheduling Support for an Internetwork of Heterogeneous, Autonomous Processors. </title> <type> Technical Report TR-92-006, </type> <institution> Purdue University, </institution> <month> January </month> <year> 1992. </year>
Reference-contexts: Macro-scheduling chooses where to run a process, while micro-scheduling selects which eligible process to execute next on a particular processor. All further uses of the term scheduling in this paper refer to macro-scheduling. The messiahs 1 system <ref> [9, 10, 11] </ref> provides a set of mechanisms that facilitate scheduling in distributed, heterogeneous, autonomous systems. For our purposes, distributed, or loosely-coupled, systems communicate via message passing rather than a shared memory bus. Heterogeneous systems may have different instruction set architectures, data formats, and attached devices.
Reference: [11] <author> S. J. Chapin and E. H. Spafford. </author> <title> An Overview of the MESSIAHS Distributed Scheduling Support System. </title> <type> Technical Report TR-93-011 (supercedes TR-93-004), </type> <institution> Department of Computer Sciences, Purdue University, </institution> <month> January </month> <year> 1993. </year>
Reference-contexts: Macro-scheduling chooses where to run a process, while micro-scheduling selects which eligible process to execute next on a particular processor. All further uses of the term scheduling in this paper refer to macro-scheduling. The messiahs 1 system <ref> [9, 10, 11] </ref> provides a set of mechanisms that facilitate scheduling in distributed, heterogeneous, autonomous systems. For our purposes, distributed, or loosely-coupled, systems communicate via message passing rather than a shared memory bus. Heterogeneous systems may have different instruction set architectures, data formats, and attached devices. <p> The capabilities of Bredbeddle and Percival are subsumed and combined within General's SDV. Individual systems enjoy execution autonomy, communication autonomy, design autonomy, and administrative autonomy as defined in <ref> [11, 16, 14] </ref>. Execution autonomy means that each system decides whether it 2 These correspond to the formal definitions of father, son, and brother found in [1]. will honor a request to execute a task; each system also has the right to revoke a task that it had previously accepted.
Reference: [12] <author> S. Chowdhury. </author> <title> The Greedy Load Sharing Algorithm. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 9 </volume> <pages> 93-99, </pages> <year> 1990. </year>
Reference-contexts: The true guard in the revocation filter rule (line 10) matches any available task, and the value portion of the rule assigns an equal priority to all tasks under consideration. 5.2 Load Balancing Several researchers have investigated load balancing and sharing policies for distributed systems, such as those described in <ref> [12] </ref>, [15], and [26]. The greedy load-sharing algorithm [12], makes decisions based on a local optimum. When a user submits a task for execution, the receiving system attempts to place the task with a less busy neighbor, according to a weighting function. <p> (line 10) matches any available task, and the value portion of the rule assigns an equal priority to all tasks under consideration. 5.2 Load Balancing Several researchers have investigated load balancing and sharing policies for distributed systems, such as those described in <ref> [12] </ref>, [15], and [26]. The greedy load-sharing algorithm [12], makes decisions based on a local optimum. When a user submits a task for execution, the receiving system attempts to place the task with a less busy neighbor, according to a weighting function. If no suitable neighbor is found, the task is accepted for local execution.
Reference: [13] <author> A. Drexl. </author> <title> Job-Prozessor-Scheduling fur heterogene Computernetzwerke (Job-Processor Scheduling for Heterogeneous Computer Networks). </title> <journal> Wirtschaftsin-formatik, </journal> <volume> 31(4) </volume> <pages> 345-351, </pages> <month> August </month> <year> 1990. </year>
Reference-contexts: system to take on new tasks loadave an estimate of the load aver age for the entire system Procclass information on the different classes of processors in the system To determine the basis for the fixed portion of the description vector, we reviewed 18 algorithms from the existing scheduling literature <ref> [2-5, 7, 13, 17-20, 22-24, 26-28, 30, 31] </ref>. Table 1 depicts the resulting data set. We found that only two characteristics| processor speed and inter-processor communication time estimates|were used by more than four algorithms.
Reference: [14] <author> W. Du, A. K. Elmagarmid, Y. Leu, and S. D. Oster-mann. </author> <title> Effects of Local Autonomy on Global Concur-rency Control in Heterogeneous Distributed Database Systems. </title> <booktitle> In Second International Conference on Data and Knowledge Systems for Manufacturing and Engineering, </booktitle> <pages> pages 113-120. </pages> <publisher> IEEE, </publisher> <year> 1989. </year>
Reference-contexts: The capabilities of Bredbeddle and Percival are subsumed and combined within General's SDV. Individual systems enjoy execution autonomy, communication autonomy, design autonomy, and administrative autonomy as defined in <ref> [11, 16, 14] </ref>. Execution autonomy means that each system decides whether it 2 These correspond to the formal definitions of father, son, and brother found in [1]. will honor a request to execute a task; each system also has the right to revoke a task that it had previously accepted.
Reference: [15] <author> D. L. Eager, E. D. Lazowska, and J. </author> <note> Zahorjan. </note>
Reference-contexts: true guard in the revocation filter rule (line 10) matches any available task, and the value portion of the rule assigns an equal priority to all tasks under consideration. 5.2 Load Balancing Several researchers have investigated load balancing and sharing policies for distributed systems, such as those described in [12], <ref> [15] </ref>, and [26]. The greedy load-sharing algorithm [12], makes decisions based on a local optimum. When a user submits a task for execution, the receiving system attempts to place the task with a less busy neighbor, according to a weighting function.
References-found: 15

