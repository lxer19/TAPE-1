URL: ftp://ftp.cs.rochester.edu/pub/u/nelson/1997_ijcv.ps.gz
Refering-URL: http://www.cs.rochester.edu/u/nelson/papers.html
Root-URL: 
Email: Email: polana@cs.rochester.edu and nelson@cs.rochester.edu  
Title: Detection and Recognition of Periodic, Nonrigid Motion  
Author: Ramprasad Polana and Randal Nelson 
Address: Rochester, New York 14627  
Affiliation: Department of Computer Science University of Rochester  
Abstract: The recognition of nonrigid motion, particularly that arising from human movement (and by extension from the locomotory activity of animals) has typically made use of high-level parametric models representing the various body parts (legs, arms, trunk, head etc.) and their connections to each other. Such model-based recognition has been successful in some cases; however, the methods are often difficult to apply to real-world scenes, and are severely limited in their generalizability. The first problem arises from the difficulty of acquiring and tracking the requisite model parts, usually specific joints such as knees, elbows or ankles. This generally requires some prior high-level understanding and segmentation of the scene, or initialization by a human operator. The second problem, with generalization, is due to the fact that the human model is not much good for dogs or birds, and for each new type of motion, a new model must be hand-crafted. In this paper, we show that the recognition of human or animal locomotion, and, in fact, any repetitive activity can be done using low-level, non-parametric representations. Such an approach has the advantage that the same underlying representation is used for all examples, and no individual tailoring of models or prior scene understanding is required. We show in particular, that repetitive motion is such a strong cue, that the moving actor can be segmented, normalized spatially and temporally, and recognized by matching against a spatio-temporal template of motion features. We have implemented a real-time system that can recognize and classify repetitive motion activities in normal gray-scale image sequences. Results on a number of real-world sequences are described. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. Allmen and C.R. Dyer. </author> <title> Cyclic motion detection using spatiotemporal surface and curves. </title> <booktitle> In Proc. Int. Conf. on Pattern Recognition, </booktitle> <pages> pages 365-370, </pages> <year> 1990. </year>
Reference-contexts: The use of the resulting trajectory primal sketch in a motion recognition system is demonstrated by Gould et al. in [12]. The curvature features of trajectories have been used to detect cyclic motion by Allman and Dyer <ref> [1] </ref> and by Tsai et al. [34]. Recently, Seitz and Dyer [28] describe an algorithm for detecting periodic motion under arbitrary affine transformations of the object. Koller, Heinze and Nagel [19] developed a system that tracks moving vehicles and characterizes their trajectory segments in terms of natural language concepts.
Reference: [2] <author> C. H. Anderson, P. J. Burt, and G. S. van der Wal. </author> <title> Change detection and tracking using pyramid transform techniques. </title> <booktitle> In Proc. SPIE Conference on Intelligent Robots and Computer Vision, </booktitle> <pages> pages 300-305, </pages> <year> 1985. </year>
Reference-contexts: The trajectories are obtained by tracking features, which are centroids of blobs generated by the monotonicity operator. Very few researchers have addressed motion recognition directly using purely low-level features of retinal motion information. Anderson et al. <ref> [2] </ref> describe a method of change detection for surveillance applications based on the spectral energy in a temporal difference image. This has the flavor of the temporal texture analysis described here, but was not generalized to other motion features or more sophisticated recognition.
Reference: [3] <author> N.I. Badler. </author> <title> Temporal Scene Analysis: Conceptual Descriptions of Object Movements. </title> <type> PhD thesis, </type> <institution> Univ of Toronto, </institution> <year> 1975. </year>
Reference-contexts: A few researchers have worked towards obtaining higher-level descriptions, usually employing a linguistic approach for representing motion concepts <ref> [3] </ref>, [19]. Badler provides a computational methodology for the description of events based on object movements. Trajectories of idealized point features through successive image frames are associated with different motion verbs such as dropping, throwing, approaching etc.
Reference: [4] <author> H.W. Chun. </author> <title> A representation for temporal sequence and duration in massively parallel networks: Exploiting link connections. </title> <booktitle> In Proc. AAAI, </booktitle> <year> 1986. </year>
Reference-contexts: A modest amount of this work addresses more complicated motion recognition issues [16; 5; 15; 14], but the models and descriptions have typically not been implemented. Various computational models of temporal structure, have been proposed (e.g. <ref> [4; 10] </ref>) but much of this work is at a fairly high level of abstraction, and has not actually been applied to visual motion recognition except in rather artificial tests. A few researchers have worked towards obtaining higher-level descriptions, usually employing a linguistic approach for representing motion concepts [3], [19].
Reference: [5] <author> J.E. </author> <title> Cutting. Six tenets for event perception. </title> <journal> Cognition, </journal> <pages> pages 71-78, </pages> <year> 1981. </year>
Reference-contexts: Most computational motion work, as mentioned previously, has been concerned with various aspects of the structure-from-motion problem. There is a large body of psychophysical literature addressing the perception of motion, most of it concerned with primitive percepts. A modest amount of this work addresses more complicated motion recognition issues <ref> [16; 5; 15; 14] </ref>, but the models and descriptions have typically not been implemented.
Reference: [6] <author> Virginia R. de Sa. </author> <title> Unsupervised Classification Learning from Cross-Modality Structure in the Environment. </title> <type> PhD thesis, </type> <institution> Computer Science Department, Univ of Rochester, </institution> <year> 1994. </year>
Reference-contexts: Lip-reading systems based on motion recognition can be used for improving the recognition rate of utterances, by characterizing motion of the lips and motion surrounding the mouth area for different utterances. For instance, employing the feature vectors computed by the algorithms described here alone, Virginia de Sa <ref> [6] </ref> obtained a recognition rate of approximately 70 percent in this application. Recognition of hand gestures can aid in designing better man-machine interfaces. Rhyne and Wolf [27] study the use of gestures for editing operations and menu-oriented operations of pointing, selecting etc. <p> It remains to be seen whether the additional classes can be added without adversely affecting the recognition rate. 6.1 Lip-reading The feature vectors used in activity recognition proved useful in the case of lip-reading as well. Virginia de Sa <ref> [6] </ref> digitized image sequences of the mouth area during various utterances, and used the motion vectors computed by the method described here to classify the utterance. This information was used in conjunction with acoustic signals to improve the recognition rate of utterances.
Reference: [7] <author> Virginia R. de Sa and Dana H. Ballard. </author> <title> Self-teaching through correlated input. </title> <booktitle> In Computation and Neural Systems 1992, </booktitle> <pages> pages 437|441. </pages> <publisher> Kluwer Academic, </publisher> <year> 1993. </year>
Reference-contexts: A sample image sequence of an utterance is illustrated in 13. Ten frames of motion information around the utterance are used to compute a 5x5x5 spatiotemporal motion template of the utterance. Using a modified version of Kohonen's learning vector quantization 2.1 (LVQ2.1) <ref> [7] </ref>, [18], with 60 code book vectors, the recognition rate of reference vectors was 85 percent and the recognition rate of test vectors was 69 percent. 6.2 Gesture Recognition The use of spatiotemporal motion template to recognize activities can be extended to the case of gesture recognition as well.
Reference: [8] <author> J.E. Elman. </author> <title> Finding structure in time. </title> <type> Technical Report 8801, </type> <institution> Center for Research in Language, Univ. of California, </institution> <address> San Diego, </address> <year> 1988. </year>
Reference-contexts: A few studies have considered highly specific aspects of motion recognition computationally. Some temporal pattern recognition work has been done in the context of speech processing <ref> [17; 32; 8] </ref>, but the applicability of the techniques to motion recognition has not been considered. However, a few studies in speech recognition using visual cues (lip-reading) are relevant to motion recognition.
Reference: [9] <author> J.P. Ewart. </author> <title> Neuroethology of releasing mechanisms: </title> <journal> Prey-catching in toads. Behavioral and Brian Sciences, </journal> <volume> 10 </volume> <pages> 337-405, </pages> <year> 1987. </year>
Reference-contexts: A simple example occurs in the case of the common toad Bufo bufo , where any elongated object of a certain size exhibiting motion along the longitudinal axis, is identified as a potential food item, and elicits an orienting response <ref> [9] </ref>. Another example is the recognition of the female grayling butterflies by males. Tinbergen [33] reported that male butterflies fly towards crude paper models moving overhead, and that their response was not affected by the color or shape of the model.
Reference: [10] <author> J.E. Feldman. </author> <title> Time, space and form in vision. </title> <type> Technical Report 244, </type> <institution> University of Rochester, Computer Science Department, </institution> <year> 1988. </year>
Reference-contexts: A modest amount of this work addresses more complicated motion recognition issues [16; 5; 15; 14], but the models and descriptions have typically not been implemented. Various computational models of temporal structure, have been proposed (e.g. <ref> [4; 10] </ref>) but much of this work is at a fairly high level of abstraction, and has not actually been applied to visual motion recognition except in rather artificial tests. A few researchers have worked towards obtaining higher-level descriptions, usually employing a linguistic approach for representing motion concepts [3], [19].
Reference: [11] <author> K.E. Finn and A.A. Montgomery. </author> <title> Automatic optically-based recognition of speech. </title> <journal> Pattern Recognition Letters, </journal> <volume> 8 </volume> <pages> 159-164, </pages> <year> 1988. </year>
Reference-contexts: However, a few studies in speech recognition using visual cues (lip-reading) are relevant to motion recognition. Petajan et al. [23] use images of mouth opening over time while Finn and Montgomery <ref> [11] </ref> and Mase and Pentland [22] track points around the mouth and use features of specific points to characterize the spoken words. The system described by Pentland recognizes spoken digits with 70%-90% accuracy over 5 speakers.
Reference: [12] <author> K. Gould, K. Rangarajan, and M.A. Shah. </author> <title> Detection and representation of events in motion trajectories. </title> <editor> In Gonzalez and Mahdavieh, editors, </editor> <booktitle> Advances in Image Processing and Analysis. </booktitle> <publisher> SPIE Optical Engineering Press, </publisher> <year> 1992. </year>
Reference-contexts: Gould and Shah [13] represent motion characteristics of moving objects by recording the important events in their trajectory. The use of the resulting trajectory primal sketch in a motion recognition system is demonstrated by Gould et al. in <ref> [12] </ref>. The curvature features of trajectories have been used to detect cyclic motion by Allman and Dyer [1] and by Tsai et al. [34]. Recently, Seitz and Dyer [28] describe an algorithm for detecting periodic motion under arbitrary affine transformations of the object.
Reference: [13] <author> K. Gould and M. Shah. </author> <title> The trajectory primal sketch: A multi-scale scheme for representing motion characterestics. </title> <booktitle> In IEEE Conf. Computer Vision and Pattern Recognition, </booktitle> <pages> pages 79-85, </pages> <year> 1989. </year>
Reference-contexts: This severely limits the general applicability of the method. Trajectories of specific points belonging to an object have been used for motion recognition in contexts other than MLDs as well. Gould and Shah <ref> [13] </ref> represent motion characteristics of moving objects by recording the important events in their trajectory. The use of the resulting trajectory primal sketch in a motion recognition system is demonstrated by Gould et al. in [12].
Reference: [14] <author> E.C. Hildreth and C. Koch. </author> <title> The analysis of visual motion from computational theory to neural mechanisms. </title> <journal> Annual Review of Neuroscience, </journal> <year> 1987. </year> <month> 29 </month>
Reference-contexts: Most computational motion work, as mentioned previously, has been concerned with various aspects of the structure-from-motion problem. There is a large body of psychophysical literature addressing the perception of motion, most of it concerned with primitive percepts. A modest amount of this work addresses more complicated motion recognition issues <ref> [16; 5; 15; 14] </ref>, but the models and descriptions have typically not been implemented.
Reference: [15] <author> D.D. Hoffman and B.E. Flinchbuagh. </author> <title> The interpretation of biological motion. </title> <booktitle> Biological Cybernatics, </booktitle> <pages> pages 195-204, </pages> <year> 1982. </year>
Reference-contexts: Most computational motion work, as mentioned previously, has been concerned with various aspects of the structure-from-motion problem. There is a large body of psychophysical literature addressing the perception of motion, most of it concerned with primitive percepts. A modest amount of this work addresses more complicated motion recognition issues <ref> [16; 5; 15; 14] </ref>, but the models and descriptions have typically not been implemented. <p> The object behavior as given by its observed trajectory is associated with corresponding motion verbs. The trajectories are obtained by tracking features, which are centroids of blobs generated by a monotonicity operator in the image frame. Human motion, specifically walking, has been studied extensively using model-based approaches [21], <ref> [15] </ref>. O' Rourke and Badler show how human motion can be tracked using a detailed model of the human figure and a top-down approach for prediction and constraint propagation. Low-level image analysis is limited to searching specified image areas for certain body features employing various feature detectors or locators.
Reference: [16] <author> G. Johansson. </author> <title> Visual perception of biological motion and a model for its analysis. </title> <journal> Perception and Psychophysics, </journal> <volume> 14 </volume> <pages> 201-211, </pages> <year> 1973. </year>
Reference-contexts: The classic demonstration of pure motion recognition by humans is provided by Moving Light Display (MLD) experiments <ref> [16] </ref>, where human subjects are able to distinguish activities such as walking, running or stair climbing, from lights attached to the joints of an actor. More subtle movement characteristics can be distinguished as well. <p> Most computational motion work, as mentioned previously, has been concerned with various aspects of the structure-from-motion problem. There is a large body of psychophysical literature addressing the perception of motion, most of it concerned with primitive percepts. A modest amount of this work addresses more complicated motion recognition issues <ref> [16; 5; 15; 14] </ref>, but the models and descriptions have typically not been implemented.
Reference: [17] <author> B.H. Juang and L.R. Rabiner. </author> <title> Mixture autoregressive hidden markov models for speech signals. </title> <journal> IEEE Trans. Acoustics, Speech and Signal Processing, </journal> <volume> 6 </volume> <pages> 1404-1413, </pages> <year> 1985. </year>
Reference-contexts: A few studies have considered highly specific aspects of motion recognition computationally. Some temporal pattern recognition work has been done in the context of speech processing <ref> [17; 32; 8] </ref>, but the applicability of the techniques to motion recognition has not been considered. However, a few studies in speech recognition using visual cues (lip-reading) are relevant to motion recognition.
Reference: [18] <author> Teuvo Kohonen. </author> <title> Improved versions of learning vector quantization. </title> <booktitle> In IJCNN International Joint Conference on Neural Networks, </booktitle> <volume> volume 1, </volume> <pages> pages I-545-I-550, </pages> <year> 1990. </year>
Reference-contexts: A sample image sequence of an utterance is illustrated in 13. Ten frames of motion information around the utterance are used to compute a 5x5x5 spatiotemporal motion template of the utterance. Using a modified version of Kohonen's learning vector quantization 2.1 (LVQ2.1) [7], <ref> [18] </ref>, with 60 code book vectors, the recognition rate of reference vectors was 85 percent and the recognition rate of test vectors was 69 percent. 6.2 Gesture Recognition The use of spatiotemporal motion template to recognize activities can be extended to the case of gesture recognition as well.
Reference: [19] <author> D. Koller, N. Heinze, and H.-H. Nagel. </author> <title> Algorithmic characterization of vehicle trajectories from image sequences of motion verbs. </title> <booktitle> In Proc. of IEEE Computer Vision and Pattern Recognition, </booktitle> <pages> pages 90-95, </pages> <year> 1991. </year>
Reference-contexts: A few researchers have worked towards obtaining higher-level descriptions, usually employing a linguistic approach for representing motion concepts [3], <ref> [19] </ref>. Badler provides a computational methodology for the description of events based on object movements. Trajectories of idealized point features through successive image frames are associated with different motion verbs such as dropping, throwing, approaching etc. <p> The curvature features of trajectories have been used to detect cyclic motion by Allman and Dyer [1] and by Tsai et al. [34]. Recently, Seitz and Dyer [28] describe an algorithm for detecting periodic motion under arbitrary affine transformations of the object. Koller, Heinze and Nagel <ref> [19] </ref> developed a system that tracks moving vehicles and characterizes their trajectory segments in terms of natural language concepts. The trajectories are obtained by tracking features, which are centroids of blobs generated by the monotonicity operator.
Reference: [20] <author> R.C. Nelson. </author> <title> Qualitative detection of motion by a moving observer. </title> <booktitle> In Proc. of IEEE CVPR, </booktitle> <pages> pages 173-178, </pages> <year> 1991. </year>
Reference-contexts: For this, it is important to initially detect each actor in the scene and spatially isolate them. Fortunately, independent motion provides an exceptionally strong segmentation cue. Nelson <ref> [20] </ref> has demonstrated a real-time method of detecting independently moving objects even in the case that the observer is itself moving.
Reference: [21] <author> J. O'Rourke and N.I. Badler. </author> <title> Model-based image analysis of human motion using constraint propagation. </title> <journal> PAMI, </journal> <volume> 3(4) </volume> <pages> 522-537, </pages> <year> 1980. </year>
Reference-contexts: The object behavior as given by its observed trajectory is associated with corresponding motion verbs. The trajectories are obtained by tracking features, which are centroids of blobs generated by a monotonicity operator in the image frame. Human motion, specifically walking, has been studied extensively using model-based approaches <ref> [21] </ref>, [15]. O' Rourke and Badler show how human motion can be tracked using a detailed model of the human figure and a top-down approach for prediction and constraint propagation. Low-level image analysis is limited to searching specified image areas for certain body features employing various feature detectors or locators. <p> A challenging part in computing these invariants is to recover the connectivity of the individual dots (by body parts) in the MLD images. A domain independent approach to this problem is given by Rashid. Rashid <ref> [26; 21] </ref> 4 considered the computational interpretation of moving light displays, particularly in the context of gait determination. This work emphasized rather high-level symbolic models of temporal sequences, an approach made possible by the discrete nature of the moving light displays.
Reference: [22] <author> A. Pentland and K. Mase. </author> <title> Lip reading: Automatic visual recognition of spoken words. </title> <type> Technical Report 117, </type> <institution> M.I.T. Media Lab Vision Science, </institution> <year> 1989. </year>
Reference-contexts: However, a few studies in speech recognition using visual cues (lip-reading) are relevant to motion recognition. Petajan et al. [23] use images of mouth opening over time while Finn and Montgomery [11] and Mase and Pentland <ref> [22] </ref> track points around the mouth and use features of specific points to characterize the spoken words. The system described by Pentland recognizes spoken digits with 70%-90% accuracy over 5 speakers.
Reference: [23] <editor> E.D. Petajan, B. Bischoff, and N.M. </editor> <title> Brooke. An improved automatic lipreading system to enhance speech recognition. </title> <booktitle> In SIGCHI'88: Human Factors in Computing Systems, </booktitle> <pages> pages 19-25, </pages> <year> 1988. </year>
Reference-contexts: Some temporal pattern recognition work has been done in the context of speech processing [17; 32; 8], but the applicability of the techniques to motion recognition has not been considered. However, a few studies in speech recognition using visual cues (lip-reading) are relevant to motion recognition. Petajan et al. <ref> [23] </ref> use images of mouth opening over time while Finn and Montgomery [11] and Mase and Pentland [22] track points around the mouth and use features of specific points to characterize the spoken words. The system described by Pentland recognizes spoken digits with 70%-90% accuracy over 5 speakers.
Reference: [24] <author> R. Polana and R.C. Nelson. </author> <title> Temporal texture recognition. </title> <booktitle> In Proc. of CVPR, </booktitle> <pages> pages 129-134, </pages> <year> 1992. </year>
Reference-contexts: We answer this question affirmatively, and provide specific demonstrations of motion recognition using such an approach. In an earlier paper, we demonstrated the utility of our approach in the context of temporal textures <ref> [24] </ref>. In this paper we concentrate on recognition of periodic activities such as walking, though we have also performed experiments with non-periodic, but temporally segmentable movements.
Reference: [25] <author> R. Polana and R.C. Nelson. </author> <title> Detecting activities. </title> <journal> Journal of Visual Communication and Image Representation, </journal> <volume> 5(2) </volume> <pages> 172-180, </pages> <year> 1994. </year>
Reference-contexts: This applies to any object undergoing constant velocity locomotion. 3.2 Periodicity Detection A periodic motion detection algorithm under arbitrary affine transformations of the object was reported in [28]. In this section, we briefly describe the periodic activity detection algorithm used in our experiments and reported in <ref> [25] </ref>. We use Fourier methods to determine periodicity in an image sequence. Non-stationary objects are tracked and then the periodicity measure for the activity is computed. From Fourier theory we know that any periodic signal can be decomposed into a fundamental and harmonics. <p> Compute the dominant frequency w and the periodicity measure P w for each individual signal extracted. * Step 4. Compute overall periodicity measure P for the image sequence using the formula described above. The effectiveness of the algorithm was demonstrated through experiments using real-world image sequences in <ref> [25] </ref>. The periodicity measures computed using the above algorithm are plotted for 20 periodic and all 8 non-periodic sequences in Figure 1. As is evident from the graphs and the projected scatter plot, the technique separates complex periodic from non-periodic motion cleanly.
Reference: [26] <author> R.F. Rashid. LIGHTS: </author> <title> A System for Interpretation of Moving Light Displays. </title> <type> PhD thesis, </type> <institution> Computer Science Dept, University of Rochester, </institution> <year> 1980. </year>
Reference-contexts: A challenging part in computing these invariants is to recover the connectivity of the individual dots (by body parts) in the MLD images. A domain independent approach to this problem is given by Rashid. Rashid <ref> [26; 21] </ref> 4 considered the computational interpretation of moving light displays, particularly in the context of gait determination. This work emphasized rather high-level symbolic models of temporal sequences, an approach made possible by the discrete nature of the moving light displays.
Reference: [27] <author> J.R. Rhyne and C.G. Wolf. </author> <title> Gestural interfaces for information processing applications. </title> <type> Technical Report 12179, </type> <institution> IBM Research Report, </institution> <year> 1986. </year>
Reference-contexts: For instance, employing the feature vectors computed by the algorithms described here alone, Virginia de Sa [6] obtained a recognition rate of approximately 70 percent in this application. Recognition of hand gestures can aid in designing better man-machine interfaces. Rhyne and Wolf <ref> [27] </ref> study the use of gestures for editing operations and menu-oriented operations of pointing, selecting etc. On-line handwritten character recognition can be made easier by recognizing the motion trajectories of the hand for different characters. 3 The following section discusses the related literature concerning motion recognition.
Reference: [28] <author> S.M. Seitz and C.R. Dyer. </author> <title> Affine invariant detection of periodic motion. </title> <booktitle> In Proceedings of CVPR, </booktitle> <year> 1994. </year>
Reference-contexts: The use of the resulting trajectory primal sketch in a motion recognition system is demonstrated by Gould et al. in [12]. The curvature features of trajectories have been used to detect cyclic motion by Allman and Dyer [1] and by Tsai et al. [34]. Recently, Seitz and Dyer <ref> [28] </ref> describe an algorithm for detecting periodic motion under arbitrary affine transformations of the object. Koller, Heinze and Nagel [19] developed a system that tracks moving vehicles and characterizes their trajectory segments in terms of natural language concepts. <p> This applies to any object undergoing constant velocity locomotion. 3.2 Periodicity Detection A periodic motion detection algorithm under arbitrary affine transformations of the object was reported in <ref> [28] </ref>. In this section, we briefly describe the periodic activity detection algorithm used in our experiments and reported in [25]. We use Fourier methods to determine periodicity in an image sequence. Non-stationary objects are tracked and then the periodicity measure for the activity is computed.
Reference: [29] <author> R.H. Smythe. </author> <title> Vision in the Animal World. </title> <address> St. </address> <publisher> Martin's Press, </publisher> <address> NY, </address> <year> 1975. </year>
Reference-contexts: Birds pay no attention to leaves and branches moving in the breeze, or during a storm, but they immediately observe the movement of a living person or animal in the midst of such an environment <ref> [29] </ref>. In general, a moving object is distinguished better than a motionless one. Such abilities suggest that, in the case of machine vision, it might be possible to use motion as 2 a means of recognition directly, rather than indirectly through a geometric reconstruction.
Reference: [30] <author> K. Takahashi, S. Seki, H. Kojima, and R. Oka. </author> <title> Recognition of dextrous manipulations from time-varying images. </title> <booktitle> In Proc. IEEE Workshop on Moation of Non-rigid and Articulated Objects, </booktitle> <address> Austin TX, </address> <month> November, </month> <pages> pages 23-28, </pages> <year> 1994. </year> <month> 30 </month>
Reference-contexts: This has the flavor of the temporal texture analysis described here, but was not generalized to other motion features or more sophisticated recognition. More recently Takahashi et al. <ref> [31; 30] </ref> have used a model based on spatiotemporal edges to recognize gestures. A warping technique based on dynamic programing is used to match the motion in time. This work is similar to ours in that it uses a non-parametric, spatiotemporal representation.
Reference: [31] <author> K. Takahashi, S. Seki, and R. Oka. </author> <title> Spotting recognition of human gestures from motion images. </title> <editor> In V. Cappellini, editor, </editor> <booktitle> Time-Varying Image Processing and Motion Objects Recognition 3, </booktitle> <pages> pages 65-72. </pages> <publisher> Elsevier, </publisher> <year> 1994. </year>
Reference-contexts: This has the flavor of the temporal texture analysis described here, but was not generalized to other motion features or more sophisticated recognition. More recently Takahashi et al. <ref> [31; 30] </ref> have used a model based on spatiotemporal edges to recognize gestures. A warping technique based on dynamic programing is used to match the motion in time. This work is similar to ours in that it uses a non-parametric, spatiotemporal representation.
Reference: [32] <author> D. W. Tank and J. J. </author> <title> Hopfield. Concentrating information in time: analog neural networks with applications to speech recognition problems. </title> <booktitle> In Proceedings of the First International Conference on Neural Networks, </booktitle> <pages> pages 455-468, </pages> <year> 1987. </year>
Reference-contexts: A few studies have considered highly specific aspects of motion recognition computationally. Some temporal pattern recognition work has been done in the context of speech processing <ref> [17; 32; 8] </ref>, but the applicability of the techniques to motion recognition has not been considered. However, a few studies in speech recognition using visual cues (lip-reading) are relevant to motion recognition.
Reference: [33] <author> N. Tinbergen. </author> <title> The Study of Instinct. </title> <publisher> Oxford: Clarendon Press, </publisher> <year> 1951. </year>
Reference-contexts: Another example is the recognition of the female grayling butterflies by males. Tinbergen <ref> [33] </ref> reported that male butterflies fly towards crude paper models moving overhead, and that their response was not affected by the color or shape of the model.
Reference: [34] <author> R. Y. Tsai and T. S. Huang. </author> <title> Estimating 3-d motion parameters of a rigid planar patch i. </title> <journal> IEEE ASSP, </journal> <volume> 30 </volume> <pages> 525-534, </pages> <year> 1981. </year>
Reference-contexts: The use of the resulting trajectory primal sketch in a motion recognition system is demonstrated by Gould et al. in [12]. The curvature features of trajectories have been used to detect cyclic motion by Allman and Dyer [1] and by Tsai et al. <ref> [34] </ref>. Recently, Seitz and Dyer [28] describe an algorithm for detecting periodic motion under arbitrary affine transformations of the object. Koller, Heinze and Nagel [19] developed a system that tracks moving vehicles and characterizes their trajectory segments in terms of natural language concepts.
Reference: [35] <author> K. 'Frisch von'. Bees: </author> <title> Their Vision, Taste, Smell and Language. </title> <address> Moscow,IL, </address> <year> 1955. </year>
Reference-contexts: Scout bees notify other bees of the direction of a feeding place they have discovered by means of a 'waggling dance', and the other bees recognize the dance and fly directly toward the food without deviating <ref> [35] </ref>. It has also been noted that bees approach oscillating flowers almost twice as fast as they do motionless ones [36]. Many organisms have elaborate courting ceremonies in which recognition of the type of movement or dance of the opposite sex, is crucial.
Reference: [36] <author> E. Wolf and G. Zerrahn-Wolf. </author> <title> Flicker and the reactions of bees to flowers. </title> <journal> Journal of Gen. Physiol., </journal> <volume> 20 </volume> <pages> 511-518, </pages> <year> 1936. </year> <month> 31 </month>
Reference-contexts: It has also been noted that bees approach oscillating flowers almost twice as fast as they do motionless ones <ref> [36] </ref>. Many organisms have elaborate courting ceremonies in which recognition of the type of movement or dance of the opposite sex, is crucial.
References-found: 36

