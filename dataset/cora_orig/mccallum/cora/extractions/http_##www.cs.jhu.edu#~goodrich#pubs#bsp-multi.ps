URL: http://www.cs.jhu.edu/~goodrich/pubs/bsp-multi.ps
Refering-URL: http://www.cs.jhu.edu/~goodrich/pubs/index.html
Root-URL: http://www.cs.jhu.edu
Email: goodrich@cs.jhu.edu  
Title: Randomized Fully-Scalable BSP Techniques for Multi-Searching and Convex Hull Construction (Preliminary Version) ility. Both of
Author: Michael T. Goodrich 
Note: log(h+1) with high probab  
Address: Baltimore, MD 21218  
Affiliation: Center for Geometric Computing Dept. of Computer Science Johns Hopkins Univ.  
Abstract: We study randomized techniques for designing efficient algorithms on a p-processor bulk-synchronous parallel (BSP) computer, which is a parallel multicomputer that allows for general processor-to-processor communication rounds provided each processor is guaranteed to send and receive at most h items in any round. The measure of efficiency we use is in terms of the internal computation time of the processors and the number of communication rounds needed to solve the problem at hand. We present techniques that achieve optimal efficiency in these bounds over all possible values for p, and we call such techniques fully-scalable for this reason. In particular, we address two fundamental problems: multi-searching and convex hull construction. Our methods result in algorithms that use internal time that is O( n log n p ) and, for h = fi(n=p), a number of communication rounds that is O( log n
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Aggarwal, A. K. Chandra, and M. Snir. </author> <title> Communication complexity of PRAMs. </title> <journal> Theoretical Computer Science, </journal> <volume> 71 </volume> <pages> 3-28, </pages> <year> 1990. </year>
Reference-contexts: But, as more and more parallel computer systems are being built, researchers are realizing that processor-to-processor communication is a prime bottleneck in parallel computing (e.g., see Aggarwal et al. <ref> [1] </ref>, Bilardi and Preparata [13], Culler et al. [15], Kruskal et al. [30], Mansour et al. [31], Mehlhorn and Vishkin [33], Papadimitriou and Yannakakis [37], and Valiant [45, 44]). <p> The method we use in this paper is an adaptation of a strategy due to Reif [40] (see also Hagerup [27]): 1. For each element s i in S we select a random integer key s 0 i in the range <ref> [1; n 2 ] </ref>, and we sort these random keys using the comparison-based optimal bulk-synchronous sorting algorithm of the author [26]. This takes O (log h n) communication steps and O ((n log n)=p) internal com putation time. 2.
Reference: [2] <author> A. Aggarwal, B. Chazelle, L. Guibas, C. O'Dunlaing, and C. Yap. </author> <title> Parallel computational geometry. </title> <journal> Al-gorithmica, </journal> <volume> 3 </volume> <pages> 293-327, </pages> <year> 1988. </year>
Reference-contexts: 1 Introduction. Most of the research on parallel computational geometry in the past decade has focused on fine-grain massively-parallel models of computation (e.g., see <ref> [2, 3, 6, 28, 41] </ref>), where the ratio of memory to processors is fairly small (typically O (1)), and this focus has been independent of whether the model of computation was a parallel random-access machine (PRAM) or a network model, such as the hypercube. <p> There has been a significant amount of previous work on parallel computational geometry (e.g., see <ref> [2, 3, 6, 28, 41] </ref>).
Reference: [3] <author> S. G. Akl and K. A. Lyons. </author> <title> Parallel Computational Geometry. </title> <publisher> Prentice-Hall, </publisher> <year> 1993. </year>
Reference-contexts: 1 Introduction. Most of the research on parallel computational geometry in the past decade has focused on fine-grain massively-parallel models of computation (e.g., see <ref> [2, 3, 6, 28, 41] </ref>), where the ratio of memory to processors is fairly small (typically O (1)), and this focus has been independent of whether the model of computation was a parallel random-access machine (PRAM) or a network model, such as the hypercube. <p> There has been a significant amount of previous work on parallel computational geometry (e.g., see <ref> [2, 3, 6, 28, 41] </ref>).
Reference: [4] <author> N. M. Amato, M. T. Goodrich, and E. A. Ramos. </author> <title> Parallel algorithms for higher-dimensional convex hulls. </title> <booktitle> In Proc. 35th Annu. IEEE Sympos. Found. Comput. Sci., </booktitle> <pages> pages 683-694, </pages> <year> 1994. </year>
Reference-contexts: The current best fine-grain parallel solutions for convex hulls in IR 2 run in O (log n) time using n processors in the EREW PRAM model 1 [34] and in IR 3 run in O (log 2 n) time using n= log n processors in the EREW PRAM model <ref> [4] </ref> or, alternatively, in O (log n) time, with high probability, using n processors in the CREW PRAM model [39, 42]. Perhaps counter-intuitive to the notion of PRAM algorithms as extractors of maximum parallelism, these PRAM methods do not translate into efficient BSP algorithms. <p> Our method for 3-dimensional convex hulls is based upon using our multi-searching method to adapt the EREW PRAM algorithm of Amato et al. <ref> [4] </ref> to the BSP model. An outline of our algorithm is as follows: 1. <p> For each tetrahedron t in the geode, find the 2-dimensional contour of the intersection between the boundary of t and the final intersection polytope P using our 2-dimensional convex hull algorithm. 7. Use the "pruning" strategy of Amato et al. <ref> [4] </ref> to eliminate from each subproblem determined by a tetrahedron t those halfspaces that cannot contribute any vertex to P inside t , using the 2-dimensional contours on the boundary of t . This also reduces the total problem size to be O (n). 8. <p> Incidentally, when p = n=2 this result implies the first O (log n)-time optimal-work EREW PRAM method for 3-dimensional convex hulls, which, with high probability, improves the time bounds, work bounds, or model assumptions of several previous methods <ref> [4, 5, 39, 42] </ref>. 5 Conclusion. We have given a general algorithm for multi-searching in the BSP framework and given examples of how this method can be used to derive fully-scalable work-optimal parallel methods for several computational geometry problems, including 3-dimensional convex hull construction.
Reference: [5] <author> N. M. Amato and F. P. Preparata. </author> <title> The parallel 3D convex hull problem revisited. </title> <journal> Internat. J. Comput. Geom. Appl., </journal> <volume> 2(2) </volume> <pages> 163-173, </pages> <year> 1992. </year>
Reference-contexts: Incidentally, when p = n=2 this result implies the first O (log n)-time optimal-work EREW PRAM method for 3-dimensional convex hulls, which, with high probability, improves the time bounds, work bounds, or model assumptions of several previous methods <ref> [4, 5, 39, 42] </ref>. 5 Conclusion. We have given a general algorithm for multi-searching in the BSP framework and given examples of how this method can be used to derive fully-scalable work-optimal parallel methods for several computational geometry problems, including 3-dimensional convex hull construction.
Reference: [6] <author> M. J. Atallah. </author> <title> Parallel techniques for computational geometry. </title> <journal> Proc. IEEE, </journal> <volume> 80(9) </volume> <pages> 1435-1448, </pages> <month> Sept. </month> <year> 1992. </year>
Reference-contexts: 1 Introduction. Most of the research on parallel computational geometry in the past decade has focused on fine-grain massively-parallel models of computation (e.g., see <ref> [2, 3, 6, 28, 41] </ref>), where the ratio of memory to processors is fairly small (typically O (1)), and this focus has been independent of whether the model of computation was a parallel random-access machine (PRAM) or a network model, such as the hypercube. <p> There has been a significant amount of previous work on parallel computational geometry (e.g., see <ref> [2, 3, 6, 28, 41] </ref>).
Reference: [7] <author> M. J. Atallah, R. Cole, and M. T. Goodrich. </author> <title> Cascading divide-and-conquer: A technique for designing parallel algorithms. </title> <journal> SIAM J. Comput., </journal> <volume> 18 </volume> <pages> 499-532, </pages> <year> 1989. </year>
Reference-contexts: CREW version allowing concurrent reads, and the CRCW allowing for concurrent reads and writes (assuming some reasonable conflict resolution protocol). "self-contained" problem that is often studied in parallel computational geometry, a general problem that often arises as a subproblem in solutions to other problems is the multi-searching problem (e.g., see <ref> [7, 8, 9, 11, 12, 23] </ref>). In this problem one is given a collection S of "generic" searches that need to simultaneously access a data structure T (which in the context of this paper will always be a binary tree) to solve the problem at hand.
Reference: [8] <author> M. J. Atallah, F. Dehne, R. Miller, A. Rau-Chaplin, and J.-J. Tsay. </author> <title> Multisearch techniques for implementing data structures on a mesh-connected computer. </title> <booktitle> In Proc. ACM Sympos. Parallel Algorithms Architect. (SPAA), </booktitle> <pages> pages 204-214, </pages> <year> 1991. </year>
Reference-contexts: CREW version allowing concurrent reads, and the CRCW allowing for concurrent reads and writes (assuming some reasonable conflict resolution protocol). "self-contained" problem that is often studied in parallel computational geometry, a general problem that often arises as a subproblem in solutions to other problems is the multi-searching problem (e.g., see <ref> [7, 8, 9, 11, 12, 23] </ref>). In this problem one is given a collection S of "generic" searches that need to simultaneously access a data structure T (which in the context of this paper will always be a binary tree) to solve the problem at hand. <p> Our framework is based upon satisfying a set of searches defined for a binary search tree T . There are a number of additional applications in parallel computational geometry that depend upon multi-searching directed acyclic search graphs (e.g., see <ref> [8, 23] </ref>). Thus, a possible direction for future work would be to extend our results to search dags. Acknowledgements.
Reference: [9] <author> M. J. Atallah and A. Fabri. </author> <title> On the multisearching problem for hypercubes. </title> <note> Research Report 1990, INRIA, BP93, 06902 Sophia-Antipolis, </note> <institution> France, </institution> <month> June </month> <year> 1993. </year>
Reference-contexts: CREW version allowing concurrent reads, and the CRCW allowing for concurrent reads and writes (assuming some reasonable conflict resolution protocol). "self-contained" problem that is often studied in parallel computational geometry, a general problem that often arises as a subproblem in solutions to other problems is the multi-searching problem (e.g., see <ref> [7, 8, 9, 11, 12, 23] </ref>). In this problem one is given a collection S of "generic" searches that need to simultaneously access a data structure T (which in the context of this paper will always be a binary tree) to solve the problem at hand.
Reference: [10] <author> M. J. Atallah and M. T. Goodrich. </author> <title> Parallel algorithms for some functions of two convex polygons. </title> <journal> Algorithmica, </journal> <volume> 3 </volume> <pages> 535-548, </pages> <year> 1988. </year>
Reference-contexts: Let us therefore assume for the remainder of this algorithm that n &gt; h. 2. Divide the input into O (n 1=4 ) contiguous groups of size O (n 3=4 ) each, and recursively find the upper hull of each set. 3. Atallah and Goodrich <ref> [10] </ref> and Dadoun and Kirk-patrick [16] describe CREW PRAM methods for finding upper common tangents between two upper hulls in O (1) time using O (n * ) processors, for any constant * &gt; 0.
Reference: [11] <editor> A. Baumker, W. Dittrich, and F. Meyer auf der Heide. </editor> <title> Truly efficient parallel algorithms: 1-optimal multisearch for an extension of the BSP model. </title> <booktitle> In Proc. 3rd European Symposium on Algorithms (ESA), </booktitle> <pages> pages 17-30, </pages> <year> 1995. </year>
Reference-contexts: CREW version allowing concurrent reads, and the CRCW allowing for concurrent reads and writes (assuming some reasonable conflict resolution protocol). "self-contained" problem that is often studied in parallel computational geometry, a general problem that often arises as a subproblem in solutions to other problems is the multi-searching problem (e.g., see <ref> [7, 8, 9, 11, 12, 23] </ref>). In this problem one is given a collection S of "generic" searches that need to simultaneously access a data structure T (which in the context of this paper will always be a binary tree) to solve the problem at hand. <p> There is also some work by Baumker et al. <ref> [11, 12] </ref> on multi-searching for another variant of the BSP that allows for very long messages, and methods by Gerbessiotis and Siniola-kis for multi-searching level graphs. These methods do not translate into communication-optimal BSP algorithms for any range of values of p, however.
Reference: [12] <author> A. Baumker, W. Dittrich, and A. Pietracaprina. </author> <title> The deterministic complexity of parallel multisearch. </title> <note> In Proc. 1996 Scadanavian Workshop on Algorithmic Theory, page to appear, </note> <year> 1996. </year>
Reference-contexts: CREW version allowing concurrent reads, and the CRCW allowing for concurrent reads and writes (assuming some reasonable conflict resolution protocol). "self-contained" problem that is often studied in parallel computational geometry, a general problem that often arises as a subproblem in solutions to other problems is the multi-searching problem (e.g., see <ref> [7, 8, 9, 11, 12, 23] </ref>). In this problem one is given a collection S of "generic" searches that need to simultaneously access a data structure T (which in the context of this paper will always be a binary tree) to solve the problem at hand. <p> There is also some work by Baumker et al. <ref> [11, 12] </ref> on multi-searching for another variant of the BSP that allows for very long messages, and methods by Gerbessiotis and Siniola-kis for multi-searching level graphs. These methods do not translate into communication-optimal BSP algorithms for any range of values of p, however.
Reference: [13] <author> G. Bilardi and F. P. Preparata. </author> <title> Lower bounds to processor-time tradeoffs under bounded-speed message propagation. </title> <booktitle> In Proc. 4th International Workshop on Algorithms and Data Structures (WADS), </booktitle> <volume> LNCS 955, </volume> <pages> pages 1-12. </pages> <publisher> Springer-Verlag, </publisher> <year> 1995. </year>
Reference-contexts: But, as more and more parallel computer systems are being built, researchers are realizing that processor-to-processor communication is a prime bottleneck in parallel computing (e.g., see Aggarwal et al. [1], Bilardi and Preparata <ref> [13] </ref>, Culler et al. [15], Kruskal et al. [30], Mansour et al. [31], Mehlhorn and Vishkin [33], Papadimitriou and Yannakakis [37], and Valiant [45, 44]).
Reference: [14] <author> B. Chazelle. </author> <title> An optimal convex hull algorithm in any fixed dimension. </title> <journal> Discrete Comput. Geom., </journal> <volume> 10 </volume> <pages> 377-409, </pages> <year> 1993. </year>
Reference-contexts: Triangulate the faces of P 0 and form a triangular "cones" for each using the origin as apex (thereby constructing a simplicial cell complex Chazelle refers to as the geode <ref> [14] </ref>). 4. Construct a search tree T for this geode such that each leaf of T identifies for a plane h all the cells of the geode that h crosses. 5. Perform the multi-search of T using all the planes dual to points in S as queries. 6.
Reference: [15] <author> D. E. Culler, R. M. Karp, D. A. Patterson, A. Sahay, K. E. Schauser, E. Santos, R. Subramonian, and T. von Eicken. </author> <title> LogP: Towards a realistic model of parallel computation. </title> <booktitle> In Proc. 4th ACM SIGPLAN Symp. on Princ. and Practice of Parallel Programming, </booktitle> <pages> pages 1-12, </pages> <year> 1993. </year>
Reference-contexts: But, as more and more parallel computer systems are being built, researchers are realizing that processor-to-processor communication is a prime bottleneck in parallel computing (e.g., see Aggarwal et al. [1], Bilardi and Preparata [13], Culler et al. <ref> [15] </ref>, Kruskal et al. [30], Mansour et al. [31], Mehlhorn and Vishkin [33], Papadimitriou and Yannakakis [37], and Valiant [45, 44]). <p> processor-to-processor message| and we let g denote the time "gap" between consecutive messages received by a processor in a communication round, then we can characterize the total running time of a BSP computation as O (T I + (L + gh)T C ) [44] (similarly for the related LogP model <ref> [15, 29] </ref>). The goal of this paper is to further the study of bulk-synchronous parallel algorithms by addressing two fundamental problems in parallel computational geometry: multi-searching and convex hull construction. 1.1 Previous related work in parallel com-putational geometry.
Reference: [16] <author> N. Dadoun and D. G. Kirkpatrick. </author> <title> Optimal parallel algorithms for convex polygon separation. </title> <type> Technical Report 89-21, </type> <institution> Dept. of Computer Science, Univ. of British Columbia, </institution> <year> 1989. </year>
Reference-contexts: Divide the input into O (n 1=4 ) contiguous groups of size O (n 3=4 ) each, and recursively find the upper hull of each set. 3. Atallah and Goodrich [10] and Dadoun and Kirk-patrick <ref> [16] </ref> describe CREW PRAM methods for finding upper common tangents between two upper hulls in O (1) time using O (n * ) processors, for any constant * &gt; 0.
Reference: [17] <author> F. Dehne, X. Deng, P. Dymond, A. Fabri, and A. A. Khokhar. </author> <title> A randomized parallel 3D convex hull algorithm for course grained multicomputers. </title> <booktitle> In Proc. 7th ACM Symp. on Parallel Algorithms and Architectures, </booktitle> <pages> pages 27-33, </pages> <year> 1995. </year>
Reference-contexts: This is because simulating a PRAM algorithm in the BSP framework requires at least a constant number of communication rounds for each PRAM step (and even this is often quite difficult to achieve), whereas there are several known BSP solutions <ref> [17, 18, 21, 19, 20] </ref> to a number of computational geometry problems that use only O (1) communication rounds in total, albeit assuming that p, the number of processors, is fairly small relative to n, the problem size. <p> The best previous BSP algorithm for 3-dimensional convex hull construction is a method by Dehne et al. <ref> [17] </ref> that completes in O (1) communication rounds, with high probability, assuming that p n 1=(3+*) , for any fixed constant * &gt; 0.
Reference: [18] <author> F. Dehne, A. Fabri, and A. Rau-Chaplin. </author> <title> Scalable parallel geometric algorithms for coarse grained mul-ticomputers. </title> <booktitle> In Proc. 9th Annu. ACM Sympos. Com-put. Geom., </booktitle> <pages> pages 298-307, </pages> <year> 1993. </year>
Reference-contexts: The real potential of parallel computational geometry, therefore, probably lies in fl This research supported by the NSF under Grants CCR-9300079 and CCR-9625289, and by ARO under Grant DAAH04-96-1-0013. algorithm design for coarse-to-medium-grain parallel environments <ref> [18, 21] </ref>, where the ratio of memory to processors is non-constant, for such systems allow an algorithm designer to balance communication latency with internal computation time. Indeed, this realization has given rise to a powerful algorithmic model, which Valiant [44] calls "bulk synchronous" processing (BSP). <p> This is because simulating a PRAM algorithm in the BSP framework requires at least a constant number of communication rounds for each PRAM step (and even this is often quite difficult to achieve), whereas there are several known BSP solutions <ref> [17, 18, 21, 19, 20] </ref> to a number of computational geometry problems that use only O (1) communication rounds in total, albeit assuming that p, the number of processors, is fairly small relative to n, the problem size. <p> The best previous BSP algorithm for 3-dimensional convex hull construction is a method by Dehne et al. [17] that completes in O (1) communication rounds, with high probability, assuming that p n 1=(3+*) , for any fixed constant * &gt; 0. Such algorithms are scalable <ref> [18, 21] </ref> in the sense that they are efficient over a range of values of p, but they are not fully scalable, in that there is a limit placed on this range of values (which in the case of 3-dimensional convex hull construction is fairly restrictive).
Reference: [19] <author> F. Dehne, C. Kenyon, and A. Fabri. </author> <title> Scalable and architecture independent parallel geometric algorithms with high probability optimal time. </title> <booktitle> In Proc. 6th IEEE Symp. on Parallel and Distributed Processing (SPDP), </booktitle> <pages> pages 586-593, </pages> <year> 1994. </year>
Reference-contexts: This is because simulating a PRAM algorithm in the BSP framework requires at least a constant number of communication rounds for each PRAM step (and even this is often quite difficult to achieve), whereas there are several known BSP solutions <ref> [17, 18, 21, 19, 20] </ref> to a number of computational geometry problems that use only O (1) communication rounds in total, albeit assuming that p, the number of processors, is fairly small relative to n, the problem size.
Reference: [20] <author> X. Deng. </author> <title> A convex hull algorithm on course-grained multicomputer. </title> <booktitle> In Proc. 5th Annu. Internat. Sympos. Algorithms Comput. (ISAAC 94), </booktitle> <pages> pages 634-642, </pages> <year> 1994. </year>
Reference-contexts: This is because simulating a PRAM algorithm in the BSP framework requires at least a constant number of communication rounds for each PRAM step (and even this is often quite difficult to achieve), whereas there are several known BSP solutions <ref> [17, 18, 21, 19, 20] </ref> to a number of computational geometry problems that use only O (1) communication rounds in total, albeit assuming that p, the number of processors, is fairly small relative to n, the problem size.
Reference: [21] <author> O. Devillers and A. Fabri. </author> <title> Scalable algorithms for bichromatic line segment intersection problems on coarse grained multicomputers. </title> <booktitle> In Proc. 3rd Workshop Algorithms Data Struct., volume 709 of Lecture Notes in Computer Science, </booktitle> <pages> pages 277-288, </pages> <year> 1993. </year>
Reference-contexts: The real potential of parallel computational geometry, therefore, probably lies in fl This research supported by the NSF under Grants CCR-9300079 and CCR-9625289, and by ARO under Grant DAAH04-96-1-0013. algorithm design for coarse-to-medium-grain parallel environments <ref> [18, 21] </ref>, where the ratio of memory to processors is non-constant, for such systems allow an algorithm designer to balance communication latency with internal computation time. Indeed, this realization has given rise to a powerful algorithmic model, which Valiant [44] calls "bulk synchronous" processing (BSP). <p> This is because simulating a PRAM algorithm in the BSP framework requires at least a constant number of communication rounds for each PRAM step (and even this is often quite difficult to achieve), whereas there are several known BSP solutions <ref> [17, 18, 21, 19, 20] </ref> to a number of computational geometry problems that use only O (1) communication rounds in total, albeit assuming that p, the number of processors, is fairly small relative to n, the problem size. <p> The best previous BSP algorithm for 3-dimensional convex hull construction is a method by Dehne et al. [17] that completes in O (1) communication rounds, with high probability, assuming that p n 1=(3+*) , for any fixed constant * &gt; 0. Such algorithms are scalable <ref> [18, 21] </ref> in the sense that they are efficient over a range of values of p, but they are not fully scalable, in that there is a limit placed on this range of values (which in the case of 3-dimensional convex hull construction is fairly restrictive). <p> What makes this problem interesting is that comparing searches to each other yields no useful information (so, for example, the searches cannot be sorted by any "key" value). The only previous efficient BSP we know of for this problem is a method of Devillers and Fabri <ref> [21] </ref> that uses O (1) communication rounds if p n 1=2 and the communication network allows for segmented broadcasts to be performed in one round, where n = jSj + jT j.
Reference: [22] <author> H. Edelsbrunner. </author> <title> Algorithms in Combinatorial Geometry, </title> <booktitle> volume 10 of EATCS Monographs on Theoretical Computer Science. </booktitle> <publisher> Springer-Verlag, </publisher> <address> Heidelberg, West Germany, </address> <year> 1987. </year>
Reference-contexts: We proceed as follows: 1. If all the input points are contained on a single processor, compute the upper hull using any efficient sequential method (e.g., see <ref> [22, 36, 38] </ref>). Let us therefore assume for the remainder of this algorithm that n &gt; h. 2. Divide the input into O (n 1=4 ) contiguous groups of size O (n 3=4 ) each, and recursively find the upper hull of each set. 3.
Reference: [23] <author> A. Gerbessiotis and C. Siniolakis. </author> <title> Communication efficient data structures on the bsp model with applications in computational geometry. </title> <booktitle> In Proceedings of EUROPAR'96, </booktitle> <month> August </month> <year> 1996. </year>
Reference-contexts: CREW version allowing concurrent reads, and the CRCW allowing for concurrent reads and writes (assuming some reasonable conflict resolution protocol). "self-contained" problem that is often studied in parallel computational geometry, a general problem that often arises as a subproblem in solutions to other problems is the multi-searching problem (e.g., see <ref> [7, 8, 9, 11, 12, 23] </ref>). In this problem one is given a collection S of "generic" searches that need to simultaneously access a data structure T (which in the context of this paper will always be a binary tree) to solve the problem at hand. <p> Our framework is based upon satisfying a set of searches defined for a binary search tree T . There are a number of additional applications in parallel computational geometry that depend upon multi-searching directed acyclic search graphs (e.g., see <ref> [8, 23] </ref>). Thus, a possible direction for future work would be to extend our results to search dags. Acknowledgements.
Reference: [24] <author> A. V. Gerbessiotis and L. G. Valiant. </author> <title> Direct bulk-synchronous parallel algorithms. </title> <journal> J. of Parallel and Distributed Computing, </journal> <volume> 22 </volume> <pages> 251-267, </pages> <year> 1994. </year>
Reference-contexts: Thus, before we give our methods for multi-searching and convex hull construction, let us discuss a few basic BSP primitives. The primitives we discuss have been studied by others in bulk-synchronous contexts (e.g., see <ref> [24, 44] </ref>), but we describe them here in the fully-scalable framework for the sake of completeness. 2.1 Generalized Broadcast and Combine. Let S be a set of m items stored on a single processor. The generalized broadcasting problem is to distribute these items to all the other processors.
Reference: [25] <author> M. Ghouse and M. T. Goodrich. </author> <title> In-place techniques for parallel convex hull algorithms. </title> <booktitle> In Proc. 3rd ACM Sympos. Parallel Algorithms Architect., </booktitle> <pages> pages 192-203, </pages> <year> 1991. </year>
Reference-contexts: This strategy alone is not sufficient, however, to achieve the high-probability bound in the typical case when h n * , for some constant * &gt; 0. To achieve a high probability bound for all values of h we augment our strategy with a failure sweeping technique <ref> [25, 32] </ref>. In the first phase we build a layered network C from T and in the second phase we route the searches in S through C using a simple BSP packet routing protocol. <p> Fortunately, there is a simple way to boost this probability back to a high probability bound. 3.5 Improving the Success Probability via Failure Sweeping. In the full version we show how to apply a generalized version of the failure sweeping paradigm <ref> [25, 32] </ref> to improve the probability of success for routing all the searches in S through T in O (log h n) communication rounds to be at least 1 1=n c for any constant c 1.
Reference: [26] <author> M. T. Goodrich. </author> <title> Communication-efficient parallel sorting. </title> <type> Technical Report, </type> <institution> Dept. of Computer Science, Johns Hopkins Univeristy, </institution> <year> 1995. </year>
Reference-contexts: In fact, the only fully-scalable BSP algorithm we are familiar with is a sorting algorithm of the author <ref> [26] </ref>, which runs in O (log h n) communication rounds, for h = fi (n=p). <p> We refer to this version of the BSP model that allows for segmented broadcasts as the weak-CREW BSP model <ref> [26] </ref>); we call the (standard) version of the BSP model, which requires that each communication packet have a unique destination, the EREW BSP model. <p> For each element s i in S we select a random integer key s 0 i in the range [1; n 2 ], and we sort these random keys using the comparison-based optimal bulk-synchronous sorting algorithm of the author <ref> [26] </ref>. This takes O (log h n) communication steps and O ((n log n)=p) internal com putation time. 2. Sequentially, we perform a random permutation for each group of s 0 i elements that are given the same key. <p> We begin by sorting the input points by their x-coordinates. This can be done in O (log h n) communication rounds and combined running time of O ((n log n)=p + (L + gh) log h n), using the BSP sorting algorithm of the author <ref> [26] </ref>. Without loss of generality, we concentrate on the problem of computing an upper hull, i.e., those edges whose normals have positive second components. We proceed as follows: 1.
Reference: [27] <author> T. Hagerup. </author> <title> Fast parallel generation of random permutations. </title> <booktitle> In Annual International Colloquium on Automata, Languages and Programming, </booktitle> <volume> LNCS 510, </volume> <pages> pages 405-416. </pages> <publisher> Springer-Verlag, </publisher> <year> 1991. </year>
Reference-contexts: An important primitive-level computation that must often be performed in randomized parallel algorithms is to produce a random permutation of the elements of S. The method we use in this paper is an adaptation of a strategy due to Reif [40] (see also Hagerup <ref> [27] </ref>): 1. For each element s i in S we select a random integer key s 0 i in the range [1; n 2 ], and we sort these random keys using the comparison-based optimal bulk-synchronous sorting algorithm of the author [26].
Reference: [28] <author> J. JaJa. </author> <title> An Introduction to Parallel Algorithms. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Mass., </address> <year> 1992. </year>
Reference-contexts: 1 Introduction. Most of the research on parallel computational geometry in the past decade has focused on fine-grain massively-parallel models of computation (e.g., see <ref> [2, 3, 6, 28, 41] </ref>), where the ratio of memory to processors is fairly small (typically O (1)), and this focus has been independent of whether the model of computation was a parallel random-access machine (PRAM) or a network model, such as the hypercube. <p> There has been a significant amount of previous work on parallel computational geometry (e.g., see <ref> [2, 3, 6, 28, 41] </ref>).
Reference: [29] <author> R. M. Karp, A. Sahay, E. Santos, and K. E. Schauser. </author> <title> Optimal broadcast and summation in the LogP model. </title> <booktitle> In Proc. 5th ACM Symp. on Parallel Algorithms and Architectures, </booktitle> <pages> pages 142-153, </pages> <year> 1993. </year>
Reference-contexts: processor-to-processor message| and we let g denote the time "gap" between consecutive messages received by a processor in a communication round, then we can characterize the total running time of a BSP computation as O (T I + (L + gh)T C ) [44] (similarly for the related LogP model <ref> [15, 29] </ref>). The goal of this paper is to further the study of bulk-synchronous parallel algorithms by addressing two fundamental problems in parallel computational geometry: multi-searching and convex hull construction. 1.1 Previous related work in parallel com-putational geometry.
Reference: [30] <author> C. Kruskal, L. Rudolph, and M. Snir. </author> <title> A complexity theory of efficient parallel algorithms. </title> <journal> Theoretical Computer Science, </journal> <volume> 71 </volume> <pages> 95-132, </pages> <year> 1990. </year>
Reference-contexts: But, as more and more parallel computer systems are being built, researchers are realizing that processor-to-processor communication is a prime bottleneck in parallel computing (e.g., see Aggarwal et al. [1], Bilardi and Preparata [13], Culler et al. [15], Kruskal et al. <ref> [30] </ref>, Mansour et al. [31], Mehlhorn and Vishkin [33], Papadimitriou and Yannakakis [37], and Valiant [45, 44]).
Reference: [31] <author> Y. Mansour, N. Nisan, and U. Vishkin. </author> <title> Tradeoffs between communication throughput and parallel time. </title> <booktitle> In Proc. 26th ACM Symposium on Theory of Computing (STOC), </booktitle> <pages> pages 372-381, </pages> <year> 1994. </year>
Reference-contexts: But, as more and more parallel computer systems are being built, researchers are realizing that processor-to-processor communication is a prime bottleneck in parallel computing (e.g., see Aggarwal et al. [1], Bilardi and Preparata [13], Culler et al. [15], Kruskal et al. [30], Mansour et al. <ref> [31] </ref>, Mehlhorn and Vishkin [33], Papadimitriou and Yannakakis [37], and Valiant [45, 44]).
Reference: [32] <author> Y. Matias and U. Vishkin. </author> <title> Converting high probability into nearly-constant time|with applications to parallel hashing. </title> <booktitle> In 23rd ACM Symp. on Theory of Computing, </booktitle> <pages> pages 307-316, </pages> <year> 1991. </year>
Reference-contexts: This strategy alone is not sufficient, however, to achieve the high-probability bound in the typical case when h n * , for some constant * &gt; 0. To achieve a high probability bound for all values of h we augment our strategy with a failure sweeping technique <ref> [25, 32] </ref>. In the first phase we build a layered network C from T and in the second phase we route the searches in S through C using a simple BSP packet routing protocol. <p> Fortunately, there is a simple way to boost this probability back to a high probability bound. 3.5 Improving the Success Probability via Failure Sweeping. In the full version we show how to apply a generalized version of the failure sweeping paradigm <ref> [25, 32] </ref> to improve the probability of success for routing all the searches in S through T in O (log h n) communication rounds to be at least 1 1=n c for any constant c 1.
Reference: [33] <author> K. Mehlhorn and U. Vishkin. </author> <title> Randomized and deterministic simulations of PRAMs by parallel machines with restricted granularity of parallel memories. </title> <journal> Acta Informatica, </journal> <volume> 9(1) </volume> <pages> 29-59, </pages> <year> 1984. </year>
Reference-contexts: But, as more and more parallel computer systems are being built, researchers are realizing that processor-to-processor communication is a prime bottleneck in parallel computing (e.g., see Aggarwal et al. [1], Bilardi and Preparata [13], Culler et al. [15], Kruskal et al. [30], Mansour et al. [31], Mehlhorn and Vishkin <ref> [33] </ref>, Papadimitriou and Yannakakis [37], and Valiant [45, 44]).
Reference: [34] <author> R. Miller and Q. F. Stout. </author> <title> Efficient parallel convex hull algorithms. </title> <journal> IEEE Trans. Comput., </journal> <volume> C-37(12):1605-1618, </volume> <year> 1988. </year>
Reference-contexts: The current best fine-grain parallel solutions for convex hulls in IR 2 run in O (log n) time using n processors in the EREW PRAM model 1 <ref> [34] </ref> and in IR 3 run in O (log 2 n) time using n= log n processors in the EREW PRAM model [4] or, alternatively, in O (log n) time, with high probability, using n processors in the CREW PRAM model [39, 42]. <p> Our method is a BSP adaptation of the EREW PRAM algorithm of Miller and Stout <ref> [34] </ref>. We begin by sorting the input points by their x-coordinates. This can be done in O (log h n) communication rounds and combined running time of O ((n log n)=p + (L + gh) log h n), using the BSP sorting algorithm of the author [26].
Reference: [35] <author> R. Motwani and P. Raghavan. </author> <title> Randomized Algorithms. </title> <publisher> Cambridge University Press, </publisher> <address> New York, </address> <year> 1995. </year>
Reference-contexts: Lemma 2.3: If c 3, then the probability that the above random permutation algorithm will not terminate in a given iteration is at most 1=n c2 . Proof: We prove this by an application of a Chernoff bound (see <ref> [35] </ref>, p. 68). Let X i;j be an indicator random variable that is 1 if processor i chooses value j. Clearly, Pr (X i;j = 1) = 1=n 2 . <p> Proof: Our proof is an adaptation of arguments used to justify hypercube packet routing strategies <ref> [35] </ref> to our BSP protocol on the search network C. Let ^ C denote the compression of C implicitly defined by the assignment of nodes in C to processors. <p> This implies that E 4 j=1 3 kh : Thus, we can apply a Chernoff bound (e.g., see <ref> [35] </ref>, p. 72) to derive the following bound: Pr (d i &gt; c log h n) Pr (jS i j &gt; ch log h n) 0 n X H i;j &gt; 4c (kh=4) A 2 ch (log h n)=4 = n ch=4 log 2 h ; provided c 2.
Reference: [36] <author> J. O'Rourke. </author> <title> Computational Geometry in C. </title> <publisher> Cam-bridge University Press, </publisher> <year> 1994. </year>
Reference-contexts: We proceed as follows: 1. If all the input points are contained on a single processor, compute the upper hull using any efficient sequential method (e.g., see <ref> [22, 36, 38] </ref>). Let us therefore assume for the remainder of this algorithm that n &gt; h. 2. Divide the input into O (n 1=4 ) contiguous groups of size O (n 3=4 ) each, and recursively find the upper hull of each set. 3.
Reference: [37] <author> C. Papadimitriou and M. Yannakakis. </author> <title> Towards an architecture-independent analysis of parallel algorithms. </title> <booktitle> Proc. 20th ACM Symp. Theory Comp. (STOC), </booktitle> <pages> pages 510-513, </pages> <year> 1988. </year>
Reference-contexts: and more parallel computer systems are being built, researchers are realizing that processor-to-processor communication is a prime bottleneck in parallel computing (e.g., see Aggarwal et al. [1], Bilardi and Preparata [13], Culler et al. [15], Kruskal et al. [30], Mansour et al. [31], Mehlhorn and Vishkin [33], Papadimitriou and Yannakakis <ref> [37] </ref>, and Valiant [45, 44]).
Reference: [38] <author> F. P. Preparata and M. I. Shamos. </author> <title> Computational Geometry: An Introduction. </title> <publisher> Springer-Verlag, </publisher> <address> New York, NY, </address> <year> 1985. </year>
Reference-contexts: We proceed as follows: 1. If all the input points are contained on a single processor, compute the upper hull using any efficient sequential method (e.g., see <ref> [22, 36, 38] </ref>). Let us therefore assume for the remainder of this algorithm that n &gt; h. 2. Divide the input into O (n 1=4 ) contiguous groups of size O (n 3=4 ) each, and recursively find the upper hull of each set. 3.
Reference: [39] <author> J. Reif and S. Sen. </author> <title> Optimal parallel randomized algorithms for three-dimensional convex hulls and related problems. </title> <journal> SIAM J. Comput., </journal> <volume> 21(3) </volume> <pages> 466-485, </pages> <year> 1992. </year>
Reference-contexts: using n processors in the EREW PRAM model 1 [34] and in IR 3 run in O (log 2 n) time using n= log n processors in the EREW PRAM model [4] or, alternatively, in O (log n) time, with high probability, using n processors in the CREW PRAM model <ref> [39, 42] </ref>. Perhaps counter-intuitive to the notion of PRAM algorithms as extractors of maximum parallelism, these PRAM methods do not translate into efficient BSP algorithms. <p> Our approach in this case is based upon a randomized two-phase strategy for searching in such a tree T , which is in turn based upon randomized searching techniques of Reif and Sen <ref> [39, 42, 43] </ref>. This strategy alone is not sufficient, however, to achieve the high-probability bound in the typical case when h n * , for some constant * &gt; 0. <p> Incidentally, when p = n=2 this result implies the first O (log n)-time optimal-work EREW PRAM method for 3-dimensional convex hulls, which, with high probability, improves the time bounds, work bounds, or model assumptions of several previous methods <ref> [4, 5, 39, 42] </ref>. 5 Conclusion. We have given a general algorithm for multi-searching in the BSP framework and given examples of how this method can be used to derive fully-scalable work-optimal parallel methods for several computational geometry problems, including 3-dimensional convex hull construction.
Reference: [40] <author> J. H. Reif. </author> <title> An optimal parallel algorithm for integer sorting. </title> <booktitle> In Proc. 26th Annu. IEEE Sympos. Found. Comput. Sci., </booktitle> <pages> pages 496-504, </pages> <year> 1985. </year>
Reference-contexts: An important primitive-level computation that must often be performed in randomized parallel algorithms is to produce a random permutation of the elements of S. The method we use in this paper is an adaptation of a strategy due to Reif <ref> [40] </ref> (see also Hagerup [27]): 1. For each element s i in S we select a random integer key s 0 i in the range [1; n 2 ], and we sort these random keys using the comparison-based optimal bulk-synchronous sorting algorithm of the author [26].
Reference: [41] <author> J. H. Reif. </author> <title> Synthesis of Parallel Algorithms. </title> <publisher> Morgan Kaufmann Publishers, Inc., </publisher> <address> San Mateo, CA, </address> <year> 1993. </year>
Reference-contexts: 1 Introduction. Most of the research on parallel computational geometry in the past decade has focused on fine-grain massively-parallel models of computation (e.g., see <ref> [2, 3, 6, 28, 41] </ref>), where the ratio of memory to processors is fairly small (typically O (1)), and this focus has been independent of whether the model of computation was a parallel random-access machine (PRAM) or a network model, such as the hypercube. <p> There has been a significant amount of previous work on parallel computational geometry (e.g., see <ref> [2, 3, 6, 28, 41] </ref>).
Reference: [42] <author> J. H. Reif and S. Sen. </author> <title> Erratum: Optimal parallel randomized algorithms for three-dimensional convex hulls and related problems. </title> <journal> SIAM J. Computing, </journal> <volume> 23(2) </volume> <pages> 447-448, </pages> <year> 1994. </year>
Reference-contexts: using n processors in the EREW PRAM model 1 [34] and in IR 3 run in O (log 2 n) time using n= log n processors in the EREW PRAM model [4] or, alternatively, in O (log n) time, with high probability, using n processors in the CREW PRAM model <ref> [39, 42] </ref>. Perhaps counter-intuitive to the notion of PRAM algorithms as extractors of maximum parallelism, these PRAM methods do not translate into efficient BSP algorithms. <p> Our approach in this case is based upon a randomized two-phase strategy for searching in such a tree T , which is in turn based upon randomized searching techniques of Reif and Sen <ref> [39, 42, 43] </ref>. This strategy alone is not sufficient, however, to achieve the high-probability bound in the typical case when h n * , for some constant * &gt; 0. <p> Incidentally, when p = n=2 this result implies the first O (log n)-time optimal-work EREW PRAM method for 3-dimensional convex hulls, which, with high probability, improves the time bounds, work bounds, or model assumptions of several previous methods <ref> [4, 5, 39, 42] </ref>. 5 Conclusion. We have given a general algorithm for multi-searching in the BSP framework and given examples of how this method can be used to derive fully-scalable work-optimal parallel methods for several computational geometry problems, including 3-dimensional convex hull construction.
Reference: [43] <author> J. H. Reif and S. Sen. </author> <title> Randomized algorithms for binary search and load balancing on fixed connection networks with geometric applications. </title> <journal> SIAM J. Computing, </journal> <volume> 23(3) </volume> <pages> 633-651, </pages> <year> 1994. </year>
Reference-contexts: Our approach in this case is based upon a randomized two-phase strategy for searching in such a tree T , which is in turn based upon randomized searching techniques of Reif and Sen <ref> [39, 42, 43] </ref>. This strategy alone is not sufficient, however, to achieve the high-probability bound in the typical case when h n * , for some constant * &gt; 0.
Reference: [44] <author> L. G. Valiant. </author> <title> A bridging model for parallel computation. </title> <journal> Comm. ACM, </journal> <volume> 33 </volume> <pages> 103-111, </pages> <year> 1990. </year>
Reference-contexts: computer systems are being built, researchers are realizing that processor-to-processor communication is a prime bottleneck in parallel computing (e.g., see Aggarwal et al. [1], Bilardi and Preparata [13], Culler et al. [15], Kruskal et al. [30], Mansour et al. [31], Mehlhorn and Vishkin [33], Papadimitriou and Yannakakis [37], and Valiant <ref> [45, 44] </ref>). <p> Indeed, this realization has given rise to a powerful algorithmic model, which Valiant <ref> [44] </ref> calls "bulk synchronous" processing (BSP). In such a model an input of size n is distributed evenly across a p-processor parallel computer, with p &lt; n. <p> the worst-case time needed to send one processor-to-processor message| and we let g denote the time "gap" between consecutive messages received by a processor in a communication round, then we can characterize the total running time of a BSP computation as O (T I + (L + gh)T C ) <ref> [44] </ref> (similarly for the related LogP model [15, 29]). The goal of this paper is to further the study of bulk-synchronous parallel algorithms by addressing two fundamental problems in parallel computational geometry: multi-searching and convex hull construction. 1.1 Previous related work in parallel com-putational geometry. <p> Thus, before we give our methods for multi-searching and convex hull construction, let us discuss a few basic BSP primitives. The primitives we discuss have been studied by others in bulk-synchronous contexts (e.g., see <ref> [24, 44] </ref>), but we describe them here in the fully-scalable framework for the sake of completeness. 2.1 Generalized Broadcast and Combine. Let S be a set of m items stored on a single processor. The generalized broadcasting problem is to distribute these items to all the other processors.
Reference: [45] <author> L. G. Valiant. </author> <title> General purpose parallel architectures. </title> <editor> In J. van Leeuwen, editor, </editor> <booktitle> Handbook of Theoretical Computer Science, </booktitle> <pages> pages 943-972. </pages> <publisher> Elsevier/The MIT Press, </publisher> <address> Amsterdam, </address> <year> 1990. </year>
Reference-contexts: computer systems are being built, researchers are realizing that processor-to-processor communication is a prime bottleneck in parallel computing (e.g., see Aggarwal et al. [1], Bilardi and Preparata [13], Culler et al. [15], Kruskal et al. [30], Mansour et al. [31], Mehlhorn and Vishkin [33], Papadimitriou and Yannakakis [37], and Valiant <ref> [45, 44] </ref>).
References-found: 45

