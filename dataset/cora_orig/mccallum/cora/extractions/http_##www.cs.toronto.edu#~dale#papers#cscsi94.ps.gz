URL: http://www.cs.toronto.edu/~dale/papers/cscsi94.ps.gz
Refering-URL: http://www.cs.toronto.edu/~dale/
Root-URL: 
Email: dale@cs.toronto.edu  greiner@learning.siemens.com  
Title: Learning Default Concepts  
Author: Dale Schuurmans Russell Greiner 
Date: May 1994.  
Note: Appears in Proceedings of the Tenth Canadian Conference on Artificial Intelligence (CSCSI-94), Banff,  
Address: Toronto, Toronto, ON M5S 1A4  Princeton, NJ 08540  
Affiliation: Department of Computer Science University of  Siemens Corporate Research  
Abstract: Classical concepts, based on necessary and sufficient defining conditions, cannot classify logically insufficient object descriptions. Many reasoning systems avoid this limitation by using "default concepts" to classify incompletely described objects. We address the task of learning such default concepts from observational data. We model the underlying performance task | classifying incomplete examples | by a probabilistic process where random test examples are passed through a "blocker" that can hide object attributes from the classifier. We then address the task of learning accurate default concepts from random training examples. We survey the learning techniques that have been proposed for this task in the machine learning and knowledge representation literatures, investigate the relative merits of each, and show that a superior learning technique can be developed from well known statistical principles. Finally, we extend Valiant's pac-learning framework to this context and obtain a number of useful learnability results. 
Abstract-found: 1
Intro-found: 1
Reference: [Bac90] <author> F. Bacchus. </author> <title> Representing and Reasoning with Probabilistic Knowledge. </title> <publisher> MIT Press, </publisher> <year> 1990. </year>
Reference-contexts: learning efficiency, and determining the difficulty of learning under different conditions. 1 We first close this introduction by tying this research to existing work: Notice first that, while there is a voluminous literature on default and nonmonotonic reasoning [Rei87], and even a recent trend towards probabilistic interpretations of default logics <ref> [Pea88, Bac90] </ref>, the issue of learning defaults has scarcely been raised. <p> Existing default logics based on *-semantics (e.g., [Pea89]) all satisfy the consistent inheritance axiom and so tacitly assume independent blocking fi I . Here however the meaning of a default rule x fl !c can be given a "majority" semantics under fi I akin to that of <ref> [Bac90] </ref>. 3.2 Arbitrary blocking While fi I is a simple and convenient model, it does not capture every practical situation; in particular, it cannot deal with circumstances where our knowledge of an attribute is correlated with its value; e.g., felons are unlikely to answer questions of the form "have you ever <p> Furthermore, this approach has not backed up by any empirical data to support its efficacy. It is often stated that the crux of this type of statistical reasoning is the problem of "choosing the right reference class" <ref> [Bac90, BGHK92] </ref>. However, this premise might actually be leading us away from the most effective learning approaches here. Fundamentally, our goal should be to preserve all available statistical information, rather than throwing away statistics from one class in favor of those from another. <p> of the following simulation study: Each of the four techniques was implemented and tested in the simple domain where domain objects are described by a single bit (as before). 8 Philosophical discussions often mention the difficulty in choosing the candidate reference classes to participate in any conflict resolution procedure (cf., <ref> [Bac90, Chapter 5] </ref>). Ky-burg simply adopts the reference classes considered here, and ignores other "disjunctive" classes (cf., Section 2) by fiat.
Reference: [BE89] <author> A. Borgida and D. Etherington. </author> <title> Hierarchical knowledge bases and efficient disjunctive reasoning. </title> <booktitle> In KR-89, </booktitle> <year> 1989. </year>
Reference-contexts: 2 's antecedent will also match n 1 's. 4 Also observe that the blocking process fi introduces only a restricted form of ambiguity: fi may produce descriptions corresponding to disjunctions like 0fl 00 _ 01, but cannot produce a description corresponding to 01 _ 10 (this is reminiscent of <ref> [BE89] </ref>) | i.e., it cannot express the claim that an object is "either a non-green plant or a green non-plant".
Reference: [BEHW89] <author> A. Blumer, A. Ehrenfeucht, D. Haussler, and M. K. Warmuth. </author> <title> Learnability and the Vapnik-Chervonenkis dimension. </title> <journal> J. of ACM, </journal> <volume> 36(4), </volume> <year> 1989. </year>
Reference-contexts: Notice also that we are only addressing the sample complexity of learning, not computational complexity. 11 This is the same measure used when learning ccds. See <ref> [BEHW89] </ref> for a precise definition of VCdim and its application to determining the difficulty of learning sets of ccds.
Reference: [BFOS84] <author> L. Breiman, J. H. Friedman, R. A. Olshen, and C. J. Stone. </author> <title> Classification and Regression Trees. </title> <publisher> Wadsworth, </publisher> <address> Belmont, CA, </address> <year> 1984. </year>
Reference-contexts: Unfortunately, the challenge of learning default concept definitionshas received relatively little attention compared to the vast literature on the subject of learning to classify complete object descriptions. To date, only a few empirical studies have been published <ref> [PBH90, Qui89, BFOS84] </ref>, and the problem has yet to receive an adequate theoretical treatment in the machine learning literature; cf., [Riv87]. Consequently, there is no supporting theory that specifies when proposed techniques can be expected to perform well, or even why they work when they do. <p> The difficulty of learning a set of dcds D is then measured 9 thv and mli are particularly well suited to incorporating background knowledge; as demonstrated for thv in many decision-tree applications <ref> [Qui89, BFOS84] </ref>, and for mli by applications of the EM algorithm to parameterized domain distributions [LR87]. by the number of training examples needed to reliably guarantee a near optimal hypothesis, in the worst case over all possible example distributions satisfying some dcd d 2 D.
Reference: [BGHK92] <author> F. Bacchus, A. Grove, J. Halpern, and D. Koller. </author> <title> From statistics to beliefs. </title> <booktitle> In AAAI-92, </booktitle> <year> 1992. </year>
Reference-contexts: Furthermore, this approach has not backed up by any empirical data to support its efficacy. It is often stated that the crux of this type of statistical reasoning is the problem of "choosing the right reference class" <ref> [Bac90, BGHK92] </ref>. However, this premise might actually be leading us away from the most effective learning approaches here. Fundamentally, our goal should be to preserve all available statistical information, rather than throwing away statistics from one class in favor of those from another.
Reference: [Cla85] <author> W. Clancey. </author> <title> Heuristic classification. </title> <journal> Artificial Intelligence, </journal> <volume> 27, </volume> <year> 1985. </year>
Reference-contexts: 1 Introduction The task of most expert systems is to "classify" objects from some application domain <ref> [Cla85] </ref>, i.e., determine whether a particular object belongs to a specified class, given a description of that object. <p> There are, however, formalisms that can classify partial object descriptions. Such default concept definitions (dcds) are a natural generalization of ccds, which avoid this limitation by using default classification rules. These classifiers play an important role in many expert systems <ref> [Cla85, PBH90] </ref>. Of course these dcds must somehow be acquired for such applications. As it is often quite difficult to explicitly extract the knowledge of domain experts, it makes sense to use machine learning techniques to automatically acquire the appropriate default concept based on existing "solved" cases; cf., [PBH90].
Reference: [DH73] <author> R. O. Duda and P. Hart. </author> <title> Pattern Classification and Scene Analysis. </title> <publisher> Wiley, </publisher> <year> 1973. </year>
Reference-contexts: rates hp 1 ; p 2 ; : : : ; p n i: Lemma 2 Under fi I , for any domain distribution P XC , the optimally accurate dcd d makes maximum conditional likelihood (mcl) classifications under P XC , given the observed attributes of an object (cf., <ref> [DH73] </ref>).
Reference: [GHR94] <author> R. Greiner, T. Hancock, and R. B. Rao. </author> <title> Knowing what doesn't matter. </title> <type> Technical report, </type> <institution> Siemens Corporate Research, </institution> <year> 1994. </year>
Reference-contexts: Notice that fi I is overly restrictive and fi A is too underconstrained to adequately model such tasks; <ref> [GHR94] </ref> provides an initial analysis of this situation. We are currently investigating other intermediate blocking models that can more accurately model such domains and (we hope) lead to better empirical learning performance.
Reference: [Gin87] <editor> M. Ginsberg, editor. </editor> <booktitle> Readings in Nonmonotonic Reasoning. </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> Los Altos, </address> <year> 1987. </year>
Reference-contexts: Our acceptance conditions (rules of the form x fl !1) correspond to Reiter's "default" sufficient conditions (a.k.a. frame selectors). However our rejection conditions (rules of the form x fl ! 0) and Reiter's "default" necessary conditions (frame instantiations) are contra-positives, and so do not serve precisely the same function <ref> [Gin87] </ref>. Still, the similarities are striking given the far different motivations behind these formalizations. 3 Model: Random Test Examples We assume there is a "natural" source of random test examples against which we can evaluate the accuracy of any classifier.
Reference: [KS90] <author> M. J. Kearns and R. E. Shapire. </author> <title> Efficient distribution-free learning of probabilistic concepts. </title> <booktitle> In FOCS-90, </booktitle> <year> 1990. </year>
Reference-contexts: Also, a system that learns a probabilistic concept <ref> [KS90] </ref> will produce a mapping c i : X n 7! [0; 1] from the space of complete object descriptions X n to probability values; such a mapping does not directly handle missing attribute values. 2 Default Concepts Following standard practice, we consider a set of domain objects X n =
Reference: [Kyb83] <author> H. Kyburg. </author> <title> The reference class. </title> <journal> Philosophy of Science, </journal> <volume> 50, </volume> <year> 1983. </year>
Reference-contexts: A learning technique that attempts to do just this has been proposed in the philosophy of statistics literature | namely Kyburg's proposals for choosing the best ref erence class on which to base statistical judgements. ref (Reference class) <ref> [Kyb83, Kyb91] </ref> For description x fl , first select a "reference-class" description x fl r (either x fl itself, or possibly a more general description), then predict the most likely classification given all training descriptions that match the reference class description x fl r .
Reference: [Kyb91] <author> H. Kyburg. </author> <title> Evidential probability. </title> <booktitle> In IJCAI-91, </booktitle> <year> 1991. </year>
Reference-contexts: A learning technique that attempts to do just this has been proposed in the philosophy of statistics literature | namely Kyburg's proposals for choosing the best ref erence class on which to base statistical judgements. ref (Reference class) <ref> [Kyb83, Kyb91] </ref> For description x fl , first select a "reference-class" description x fl r (either x fl itself, or possibly a more general description), then predict the most likely classification given all training descriptions that match the reference class description x fl r . <p> Then employ a conflict resolution strategy (which trades-off interval bias and width) to decide whether to adopt successively more general reference classes <ref> [Kyb91] </ref>. 8 Although the ref strategy can override the predictions from specific descriptions with those from more general descriptions, it is not clear that it does so in the best conceivable way.
Reference: [LR87] <author> J. A. Little and D. B. Rubin. </author> <title> Statistical Analysis with Missing Data. </title> <publisher> Wiley, </publisher> <year> 1987. </year>
Reference-contexts: The best approach should involve combining all of the available statistics in a principled way. Here we note that a well known idea from theoretical statistics is applicable: namely, first determine the maximum likelihood distribution that accounts for all the data, then perform inferences according to this distribution <ref> [LR87] </ref>. This approach yields an effective method for determining the most likely classifications given incomplete training examples. mli (Maximum likelihood) [LR87] First, determine the domain distribution P fl XC that maximizes the likelihood of the observed training examples. <p> that a well known idea from theoretical statistics is applicable: namely, first determine the maximum likelihood distribution that accounts for all the data, then perform inferences according to this distribution <ref> [LR87] </ref>. This approach yields an effective method for determining the most likely classifications given incomplete training examples. mli (Maximum likelihood) [LR87] First, determine the domain distribution P fl XC that maximizes the likelihood of the observed training examples. Then, for description x fl , predict the most probable classifi cation according to P fl XC , given x fl 's observed at tributes. <p> The difficulty of learning a set of dcds D is then measured 9 thv and mli are particularly well suited to incorporating background knowledge; as demonstrated for thv in many decision-tree applications [Qui89, BFOS84], and for mli by applications of the EM algorithm to parameterized domain distributions <ref> [LR87] </ref>. by the number of training examples needed to reliably guarantee a near optimal hypothesis, in the worst case over all possible example distributions satisfying some dcd d 2 D.
Reference: [Min75] <author> M. Minsky. </author> <title> A framework for representing knowledge. </title> <booktitle> In The Psychology of Computer Vision. </booktitle> <publisher> McGraw-Hill, </publisher> <year> 1975. </year>
Reference-contexts: He argues that these concepts can be better characterized by specifying "default" necessary and sufficient conditions, and shows that this idea is similar to Minsky's concept of frames <ref> [Min75] </ref>: frame selectors can be viewed as "default" sufficient conditions for the frame concept, and frame instantiations can be viewed as "default" necessary conditions. These notions of non-classical concepts appear quite similar to the account of dcds developed here.
Reference: [PBH90] <author> B. Porter, R. Bareiss, and R. Holte. </author> <title> Concept learning and heuristic classification in weak-theory domains. </title> <journal> Artificial Intelligence, </journal> <volume> 45, </volume> <year> 1990. </year>
Reference-contexts: There are, however, formalisms that can classify partial object descriptions. Such default concept definitions (dcds) are a natural generalization of ccds, which avoid this limitation by using default classification rules. These classifiers play an important role in many expert systems <ref> [Cla85, PBH90] </ref>. Of course these dcds must somehow be acquired for such applications. As it is often quite difficult to explicitly extract the knowledge of domain experts, it makes sense to use machine learning techniques to automatically acquire the appropriate default concept based on existing "solved" cases; cf., [PBH90]. <p> Of course these dcds must somehow be acquired for such applications. As it is often quite difficult to explicitly extract the knowledge of domain experts, it makes sense to use machine learning techniques to automatically acquire the appropriate default concept based on existing "solved" cases; cf., <ref> [PBH90] </ref>. Unfortunately, the challenge of learning default concept definitionshas received relatively little attention compared to the vast literature on the subject of learning to classify complete object descriptions. <p> Unfortunately, the challenge of learning default concept definitionshas received relatively little attention compared to the vast literature on the subject of learning to classify complete object descriptions. To date, only a few empirical studies have been published <ref> [PBH90, Qui89, BFOS84] </ref>, and the problem has yet to receive an adequate theoretical treatment in the machine learning literature; cf., [Riv87]. Consequently, there is no supporting theory that specifies when proposed techniques can be expected to perform well, or even why they work when they do. <p> We are also beginning to examine many extensions to better cope with practical problems. For example, many application domains like medical diagnosis have the property that missing attribute values actually give useful information | namely that the missing attributes are irrelevant to the classification, given the known attribute values <ref> [PBH90] </ref>. Notice that fi I is overly restrictive and fi A is too underconstrained to adequately model such tasks; [GHR94] provides an initial analysis of this situation.
Reference: [Pea88] <author> J. Pearl. </author> <title> Probabilistic Reasoning in Intelligent Systems. </title> <publisher> Morgan Kaufmann, </publisher> <year> 1988. </year>
Reference-contexts: learning efficiency, and determining the difficulty of learning under different conditions. 1 We first close this introduction by tying this research to existing work: Notice first that, while there is a voluminous literature on default and nonmonotonic reasoning [Rei87], and even a recent trend towards probabilistic interpretations of default logics <ref> [Pea88, Bac90] </ref>, the issue of learning defaults has scarcely been raised.
Reference: [Pea89] <author> J. Pearl. </author> <title> Probabilistic semantics for nonmono-tonic reasoning: A survey. </title> <booktitle> In KR-89, </booktitle> <year> 1989. </year>
Reference-contexts: Existing default logics based on *-semantics (e.g., <ref> [Pea89] </ref>) all satisfy the consistent inheritance axiom and so tacitly assume independent blocking fi I .
Reference: [Qui89] <author> J. R. Quinlan. </author> <title> Unknown attribute values in induction. </title> <booktitle> In ML-89, </booktitle> <year> 1989. </year>
Reference-contexts: Unfortunately, the challenge of learning default concept definitionshas received relatively little attention compared to the vast literature on the subject of learning to classify complete object descriptions. To date, only a few empirical studies have been published <ref> [PBH90, Qui89, BFOS84] </ref>, and the problem has yet to receive an adequate theoretical treatment in the machine learning literature; cf., [Riv87]. Consequently, there is no supporting theory that specifies when proposed techniques can be expected to perform well, or even why they work when they do. <p> Notice that otherwise mlc always outperforms random guessing. of complete descriptions, and simply gathers separate statistics for each description x fl ; effectively treating fl as a third attribute value. thv (Three-valued) <ref> [Qui89] </ref> For description x fl , predict the most frequent classification among training ex amples of the form hx fl ; ci. thv clearly does not make the most effective use of the available training data, given that attributes are blocked independently of their values. <p> The difficulty of learning a set of dcds D is then measured 9 thv and mli are particularly well suited to incorporating background knowledge; as demonstrated for thv in many decision-tree applications <ref> [Qui89, BFOS84] </ref>, and for mli by applications of the EM algorithm to parameterized domain distributions [LR87]. by the number of training examples needed to reliably guarantee a near optimal hypothesis, in the worst case over all possible example distributions satisfying some dcd d 2 D. <p> In contrast, thv is the only provably effective technique for learning under fi A , given incomplete training examples, and so clearly dominates in this case. These theoretical observations can actually help explain some of the results obtained by recent empirical studies: Quinlan <ref> [Qui89] </ref> compared applications of the lem and thv techniques (along with some other ad hoc approaches) to decision-tree learning, and found that no single technique dominated the others over the set of test problem he considered.
Reference: [Rei87] <author> R. Reiter. </author> <title> Nonmonotonic reasoning. </title> <booktitle> Annual Review of Computer Science, </booktitle> <year> 1987. </year>
Reference-contexts: framework to the present case: assessing the effects of prior knowledge on learning efficiency, and determining the difficulty of learning under different conditions. 1 We first close this introduction by tying this research to existing work: Notice first that, while there is a voluminous literature on default and nonmonotonic reasoning <ref> [Rei87] </ref>, and even a recent trend towards probabilistic interpretations of default logics [Pea88, Bac90], the issue of learning defaults has scarcely been raised. <p> For example, even though non-green-plants plants things, the predicted photosynthesis properties are 0, 1, 0, respectively. Such a classifier cannot be specified by a classical concept. 4 There are many unexpected similarities between dcds and existing nonmonotonic knowledge representation formalisms. For example, Reiter <ref> [Rei87] </ref> considers com-monsense concepts like "bird", "chair", and "game" and 2 Thus there are 2 3 n distinct dcds possible on n boolean attributes, only some of which apparently have "reasonable" structures, see Lemma 1 below. 3 Each node in the graph represents a rule; e.g., "fl1 ! 1" encodes the
Reference: [Riv87] <author> R. Rivest. </author> <title> Learning decision lists. </title> <journal> Machine Learning, </journal> <volume> 2(3), </volume> <year> 1987. </year>
Reference-contexts: To date, only a few empirical studies have been published [PBH90, Qui89, BFOS84], and the problem has yet to receive an adequate theoretical treatment in the machine learning literature; cf., <ref> [Riv87] </ref>. Consequently, there is no supporting theory that specifies when proposed techniques can be expected to perform well, or even why they work when they do. We attempt to fill this void by studying the problem of learning accurate default concepts from examples within a precise mathematical framework.
Reference: [RS88] <author> R. Rivest and R. Sloan. </author> <title> Learning complicated concepts reliably and usefully. </title> <booktitle> In AAAI-88, </booktitle> <year> 1988. </year>
Reference-contexts: Other interesting research directions involve alternative generalizations of standard classification learning: This work has assumed that default definitions classify every description, no matter how incomplete. An interesting direction is to consider partial default definitions that sometimes say "I don't know" a la <ref> [RS88] </ref>. Such classifiers could prove useful in domains where the consequences of an incorrect classification sometimes outweigh those of remaining silent. Another interesting generalization is to consider active classifiers. That is, we have assumed that classifiers passively observe test examples and play no role in determining which attributes are observed.
Reference: [Sch94] <author> D. Schuurmans. </author> <title> Efficient, Accurate, and Reliable Machine Learning. </title> <type> PhD thesis, </type> <institution> University of Toronto, Department of Computer Science, </institution> <year> 1994. </year> <month> Forthcoming. </month>
Reference-contexts: We let X fl n = f0; 1; flg n denote the set of possible object descriptions. A test example hx fl ; ci consists 1 Unfortunately, space constraints preclude presenting proofs of the results stated in this abstract; see <ref> [Sch94] </ref>. of a (partial) description x fl of some domain object x, along with x's true classification c 2 f0; 1g. The space of possible examples is denoted X fl n fi f0; 1g.
Reference: [SV88] <author> G. Shackelford and D. Volper. </author> <title> Learning k-DNF with noise in the attributes. </title> <booktitle> In COLT-88, </booktitle> <year> 1988. </year>
Reference-contexts: Second, to avoid possible confusions, it is worth explicitly contrasting our "missing attribute" framework from other models of learning in the learnability community: A system that learns with attribute noise <ref> [SV88] </ref> will not know which attribute values have been corrupted; by contrast, we know explicitly which values are missing.
Reference: [Val84] <author> L. G. Valiant. </author> <title> A theory of the learnable. </title> <journal> Communications of the ACM, </journal> <volume> 27(11), </volume> <year> 1984. </year>
Reference-contexts: This points to the necessity of bias. In any successful application, the learning system must be constrained to search a restricted space of appropriate classifiers (here dcds). 9 Following the methodology pioneered by Valiant <ref> [Val84] </ref>, we consider how learning performance scales as a function of prior knowledge. Here we quantify bias by its measurable effects on the quality of learning that can be guaranteed.
References-found: 24

