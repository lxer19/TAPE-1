URL: ftp://synapse.cs.byu.edu/pub/papers/cgc_diss.ps
Refering-URL: ftp://synapse.cs.byu.edu/pub/papers/details.html
Root-URL: 
Title: On Integrating Inductive Learning with Prior Knowledge and Reasoning  
Author: Christophe G. Giraud-Carrier by Christophe G. Giraud-Carrier 
Degree: A Dissertation Presented to the  in Partial Fulfillment of the Requirements for the Degree Doctor of Philosophy  
Date: December 1994  
Affiliation: Department of Computer Science Brigham Young University  
Abstract-found: 0
Intro-found: 1
Reference: [AHA91a] <author> Aha, D.W. </author> <year> (1991). </year> <title> A Study of Instance-Based Algorithms for Supervised Learning Tasks. </title> <type> Technical Report, </type> <institution> University of California, Irvine. </institution>
Reference: [AHA91b] <author> Aha, D.W., Kibler, D., and Albert, M.K. </author> <year> (1991). </year> <title> Instance-Based Learning Algorithms. </title> <journal> Machine Learning, </journal> <volume> 6, </volume> <pages> 37-66. </pages>
Reference: [BER94] <author> Bertelsen, R. </author> <year> (1994). </year> <title> Extending ID3 Through Discretization of Continuous Inputs. </title> <booktitle> In Proceedings of the Seventh Florida AI Research Symposium (FLAIRS'94), </booktitle> <pages> 122-125. </pages>
Reference-contexts: A more adaptive mechanism, such as an incremental standard deviation, could be used instead of the range for purposes of normalization. Though ILA and FLARE handle continuous-valued attributes directly, a better treatment of such attributes is still necessary. As pointed out in <ref> [BER94] </ref>, actual continuous-valued attributes appear to be rarely used directly in human decision making. Rather, they are translated into a coarse set of discrete values, and it is those discrete values that are used in the learning system. The proposal in [BER94] provides a good starting point, particularly as it is <p> As pointed out in <ref> [BER94] </ref>, actual continuous-valued attributes appear to be rarely used directly in human decision making. Rather, they are translated into a coarse set of discrete values, and it is those discrete values that are used in the learning system. The proposal in [BER94] provides a good starting point, particularly as it is context-dependent, rather than solely driven by statistical considerations. Discretization of ordered (e.g., continuous) values does not affect ordering so that the metric we designed is still useful.
Reference: [BLU87] <author> Blumer, A., Ehrenfeucht, A., Haussler, D., and Warmuth, M.K. </author> <year> (1987). </year> <title> Occam's Razor. </title> <journal> Information Processing Letters, </journal> <volume> 24, </volume> <pages> 377-380. </pages>
Reference: [BRE91] <author> Brewka, G. </author> <year> (1991). </year> <title> Nonmonotonic Reasoning: Logical Foundations of Commonsense. </title> <publisher> Cambridge University Press. </publisher>
Reference-contexts: Precepts can be viewed as some instantiation of commonsense knowledge to a particular domain. Hence, if some commonsense knowledge is available, it may potentially be used to generate precepts. Several attempts have been made at formalizing commonsense knowledge <ref> [BRE91, LUK90] </ref>, and a huge database of commonsense facts, 117 called Cyc, is currently being compiled [LEN90].
Reference: [BUN90] <author> Buntine, W.L. </author> <year> (1990). </year> <title> A Theory of Learning Classification Rules. </title> <type> Ph.D. Dissertation, </type> <institution> University of Technology, School of Computing Science, Sydney. </institution>
Reference-contexts: Moreover, ASOCS and PDLA are limited to nominal domains. FLARE, like ScNets, handles both nominal and linear (including continuous) domains. Prior knowledge may take a variety of forms, some of 99 which are discussed in <ref> [BUN90] </ref>. FLARE uses either preencoded defaults or deducible domain knowledge. FLARE's prior knowledge is often used as a learning bias to prune and constrain the search in the input space. A formal discussion on the need for such biases is in [MIT80].
Reference: [CAI90] <author> Cai, Y., Cercone, N., and Han, J. </author> <year> (1990). </year> <title> An Attribute-Oriented Approach for Learning Classification Rules from Relational Databases. </title> <booktitle> In Proceedings of the Sixth International Conference on Data Engineering, </booktitle> <pages> 281-288. </pages>
Reference-contexts: Provision could be made to support some extensional learning, by for example recording instances of relationships between objects. If sufficiently many relationships exist, a relationship set may be "induced" between the corresponding classes of objects. One 131 interesting learning model from relational databases is in <ref> [CAI90] </ref>. Another incremental learning algorithms based on Galois lattices is in [GOD91]. A further advantage is the support for arbitrary relationships as well as, in particular, generalization. The problem of inheritance becomes one of graph traversal and conflicting defaults can be handled by choosing the path of shortest length.
Reference: [CAR83] <author> Carbonell, J.G. </author> <year> (1983). </year> <title> Learning by Analogy: Formulating and Generalizing Plans from Past Experience. </title> <editor> In Michalski, R.S., Carbonell, J.G., and Mitchell, T.M., (Eds.). </editor> <booktitle> Machine Learning: An Artificial Intelligence Approach. </booktitle> <publisher> Tioga Publishing Company, </publisher> <address> Palo Alto, CA, </address> <note> Chapter 5. </note>
Reference: [CHE91] <author> Cheng, Y. </author> <year> (1991). </year> <title> Context-Dependent Similarity. </title> <booktitle> Uncertainty in Artificial Intelligence, </booktitle> <volume> 6, </volume> <pages> 41-47. </pages>
Reference: [CLB84] <author> Clancey, B.C., and Shortliffe, E.H. </author> <year> (1984), </year> <editor> Editors. </editor> <booktitle> Readings in Medical Artificial Intelligence: The First Decade. </booktitle> <address> Reading, MA: </address> <publisher> Addison-Wesley Publishing Company. </publisher>
Reference-contexts: The inference engine carries out the deductive process using the rules in the rule base and the facts it is provided. Several of these systems have been successfully used in various domains, such as medical diagnosis <ref> [CLB84] </ref> and geology [DUD84]. One of the greatest challenges of current deductive systems is knowledge elicitation, that is the construction of the rule base. Typically, rules are obtained from human experts. Elicitation is a tedious task that presents many difficulties both practically and theoretically.
Reference: [CLK78] <author> Clark, K.L. </author> <year> (1978). </year> <title> Negation As Failure. </title> <editor> In Gallaire, H., and Minker, J., (Eds.). </editor> <title> Logic and Databases. </title> <publisher> Plenum Press, </publisher> <pages> 293-322. </pages>
Reference-contexts: Such rules typically capture some domain knowledge, or may be generated by reasoning about the current knowledge base. Definitions may be viewed as "if and only if" statements, while implications cannot. Induction, which produces definitions, lends itself naturally to the completion principle proposed in <ref> [CLK78] </ref>. That is, given a definition, if the knowledge base is instantiated at the conceptual level (i.e., q is known), then it is appropriate to assert p. However, the same does not hold for implications.
Reference: [CLP89] <author> Clark, P., and Niblett, T. </author> <year> (1989). </year> <title> The CN2 Induction Algorithm. </title> <journal> Machine Learning, </journal> <volume> 3, </volume> <pages> 261-283. </pages>
Reference-contexts: Inductive learning has been the subject of much research leading to the design of a variety of algorithms <ref> [CLP89, MIC83a, QUI86, SAL91] </ref>. In general, inductive learning * Submitted to Journal of Artificial Intelligence Research. 2 The philosopher Pierce actually identified three basic forms of reasoning: inductive, deductive and abductive. See Hartshorn et al. (Eds.), Collected Papers of Charles Sanders Pierce, Harvard University Press, Vol. 2, pp. 1931-1958. <p> Where IBL considers them to be complete mismatches, FLARE chooses a more middle-ground approach that may better capture the inherent notion of missing or "don't-know" attributes. Learning in FLARE contrasts with algorithms such as CN2 <ref> [CLP89] </ref>, where all training examples must be available a priori. Rather, it follows an incremental approach similar to that of [ELM91], except that it is the knowledge itself that is evolved, rather than the system's structure. Moreover, learning in FLARE can be effected continually. <p> Despite these limitations, FLARE effectively handles a wide range of applications. Moreover, AVL accounts for simple, efficient matching mechanisms, and lends itself naturally to many inductive learning problems. Indeed, many successful learning systems use AVL <ref> [CLP89, MIC83a, QUI86] </ref>. FOL statements of the aforementioned form are translated in a straightforward way into an equivalent symbolic-valued AVL representation, as follows. 1. Each predicate (e.g., on_table (x)) becomes a Boolean attribute. 2.
Reference: [COL89] <author> Collins, A., and Michalski, R.S. </author> <year> (1989). </year> <title> The Logic of Plausible Reasoning: </title>
Reference-contexts: If we now assert that q (x), then, using the completion principle and subsequently asserting p (x), we may be able to derive q'(x) based on the amount of overlap between p and p'. A new "conceptual" implication may thus be generated. Consider an example from <ref> [COL89] </ref>. Assume it is known that west Texas is cattle country, and the question is whether the Chaco is also cattle country.
References-found: 13

