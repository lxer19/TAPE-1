URL: http://vismod.www.media.mit.edu/vismod/publications/techdir/TR-371.ps.Z
Refering-URL: http://vismod.www.media.mit.edu/vismod/demos/facerec/index.html
Root-URL: 
Title: Bayesian Face Recognition using Deformable Intensity Surfaces  
Author: Baback Moghaddam, Chahab Nastar and Alex Pentland 
Address: 20 Ames Street, Cambridge MA 02139, U.S.A.  
Affiliation: The Media Laboratory, Massachusetts Institute of Technology  
Pubnum: Perceptual Computing Section,  
Abstract: M.I.T Media Laboratory Perceptual Computing Section Technical Report No. 371 Appears in: IEEE Conference on Computer Vision & Pattern Recognition, San Francisco, CA, June 1996. Abstract We describe a novel technique for face recognition based on deformable intensity surfaces which incorporates both the shape and texture components of the 2D image. The intensity surface of the facial image is modeled as a de- formable 3D mesh in (x; y; I(x; y)) space. Using an efficient technique for matching two surfaces (in terms of the analytic modes of vibration), we obtain a dense correspondence field (or 3D warp) between two images. The probability distributions of two classes of warps are then estimated from training data: interpersonal and ex- trapersonal variations. These densities are then used in a Bayesian framework for image matching and recognition. Experimental results with facial data from the US Army FERET database demonstrate an increased recognition rate over the previous best methods.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> K. J. Bathe. </author> <title> Finite Element Procedures in Engineering Analysis. </title> <publisher> Prentice-Hall, </publisher> <year> 1982. </year>
Reference-contexts: In this section we briefly review the mathematics of this approach (for further details the reader is referred to [11, 13, 12]). The intensity surface is modeled as a deformable mesh and is governed by Lagrangian dynamics <ref> [1] </ref> : M U + C _ U + KU = F (t) (1) where U = [: : : ; x i ; y i ; z i ; : : :] T is a vector storing nodal displacements, M, C and K are respectively the mass, damping and stiffness <p> Solving the governing equations in the modal basis leads to scalar equations where the unknown ~u (i) is the amplitude of mode i <ref> [1] </ref> The closed-form expression of the displacement field is then given by U i=1 with P t 3N , which means that only P scalar equations of the type of (4) need to be solved.
Reference: [2] <author> David Beymer. </author> <title> Vectorizing face images by interleaving shape and texture computations. </title> <journal> A.I. </journal> <volume> Memo No. </volume> <pages> 1537, </pages> <institution> Artificial Intelligence Laboratory, Massachusetts Institute of Technology, </institution> <year> 1995. </year>
Reference-contexts: Their system detects canonical points on the face and uses these landmarks to warp faces to a shape-free representation prior to implementing an eigenface technique for characterizing grayscale variations (face texture). Similarly, the face vectorizer system of Beymer & Poggio <ref> [2] </ref> uses optical flow to obtain a shape representation decou- pled from that of texture (in the form of a 2D correspondence field between a given face and a canonical model).
Reference: [3] <author> I. Craw and P. Cameron. </author> <title> Face recognition by com-puter. </title> <editor> In D. Hogg and R. Boyle, editors, </editor> <booktitle> Proc. British Machine Vision Conference, </booktitle> <pages> pages 498-507. </pages> <address> SpringerVerlag, </address> <year> 1992. </year>
Reference-contexts: 1 Introduction Current work in the area of image-based object modeling and visual recognition treats the shape and texture components of an object in a separate and often independent manner. The technique of extracting shape and forming a shape-normalized or "shape-free" grayscale component was suggested by Craw & Cameron <ref> [3] </ref>, which used an eigenface technique on shape-free faces for matching and recognition. Recently Craw et al. [4] have done a study which combines these two independently derived components (a manually- extracted shape component plus a shape-free texture) for enhanced recognition performance.
Reference: [4] <author> I. Craw and et al. </author> <title> Automatic face recognition: Combining configuration and texture. </title> <editor> In Martin Bichsel, editor, </editor> <booktitle> Proc. Int'l Workshop on Automatic Face and Gesture Recognition, </booktitle> <address> Zurich, </address> <year> 1995. </year>
Reference-contexts: The technique of extracting shape and forming a shape-normalized or "shape-free" grayscale component was suggested by Craw & Cameron [3], which used an eigenface technique on shape-free faces for matching and recognition. Recently Craw et al. <ref> [4] </ref> have done a study which combines these two independently derived components (a manually- extracted shape component plus a shape-free texture) for enhanced recognition performance. Similarly, Lanitis et al. [7] have developed an automatic face-processing system which is capable of combining the shape and texture components for recognition, albeit independently.
Reference: [5] <author> B.K.P. Horn and G. Schunck. </author> <title> Determining optical flow. </title> <journal> Artificial Intelligence, </journal> <volume> 17 </volume> <pages> 185-203, </pages> <year> 1981. </year>
Reference-contexts: The elasticity of the surface provides an intrinsic smoothness constraint for computing the final displacement field. We note that this formulation provides an interesting alternative to optical flow methods for obtaining correspondence, without the classical brightness constraint <ref> [5] </ref>. Indeed, the brightness constraint corresponds to a specific case of our formulation where the closest point P i has to have the same intensity as M i | i.e., ! M i P i is parallel to the XY plane. We do not make that assumption here.
Reference: [6] <author> I.T. Jolliffe. </author> <title> Principal Component Analysis. </title> <address> SpringerVerlag, New York, </address> <year> 1986. </year>
Reference-contexts: Recently, an efficient density estimation method was proposed by Moghaddam & Pentland [9] which divides the vector space R N into two complementary subspaces using an eigenspace decomposition. This method relies on a Principal Components Analysis (PCA) <ref> [6] </ref> to form a low- dimensional estimate of the complete likelihood which can be evaluated using only the first M principal components, where M &lt;< N .
Reference: [7] <author> A. Lanitis, C. J. Taylor, and T. F. Cootes. </author> <title> A uni-fied approach to coding and interpreting face images. </title> <booktitle> In IEEE Proceedings of the Fifth International Conference on Computer Vision (ICCV'95), </booktitle> <address> Cambridge, MA, </address> <month> June </month> <year> 1995. </year>
Reference-contexts: Recently Craw et al. [4] have done a study which combines these two independently derived components (a manually- extracted shape component plus a shape-free texture) for enhanced recognition performance. Similarly, Lanitis et al. <ref> [7] </ref> have developed an automatic face-processing system which is capable of combining the shape and texture components for recognition, albeit independently.
Reference: [8] <author> B. Moghaddam and A. Pentland. </author> <title> Face recognition us-ing view-based and modular eigenspaces. Automatic Systems for the Identification and Inspection of Humans, </title> <type> 2277, </type> <year> 1994. </year>
Reference-contexts: Note that this performance is better than or similar to recognition rates obtained by any algorithm tested on this database, and that it is lower (by about 10%) than 4 (a) (b) the typical rates that we have obtained with the FERET database <ref> [8] </ref>. We attribute this lower performance to the fact that these images were selected to be particularly challenging.
Reference: [9] <author> B. Moghaddam and A. Pentland. </author> <title> Probabilistic visual learning for object detection. </title> <booktitle> In IEEE Proceedings of the Fifth International Conference on Computer Vision (ICCV'95), </booktitle> <address> Cambridge, USA, </address> <month> June </month> <year> 1995. </year>
Reference-contexts: This final classification is performed using the a posteriori probabilities computed from the two class-conditional likelihoods which are themselves estimated from training data using an efficient subspace method for density estimation of high-dimensional Gaussian data <ref> [9] </ref>. 2 Deformable Intensity Surfaces In previous work [13, 12], we formulated a novel image matching technique based on a 3D surface representation of an image I (x; y) | i.e., as the surface (x; y; I (x; y)) as shown, for example, in Figure 1 | and developed an efficient <p> Furthermore, this computation would be highly inefficient since the intrinsic dimensionality or major degrees-of-freedom of ~ U for each class is likely to be significantly smaller than N . Recently, an efficient density estimation method was proposed by Moghaddam & Pentland <ref> [9] </ref> which divides the vector space R N into two complementary subspaces using an eigenspace decomposition. <p> The component of ~ U which lies in the feature space F is referred to as the "distance-in- feature-space" (DIFS) and is a Mahalanobis distance for Gaussian densities. As derived in <ref> [9] </ref>, the complete likelihood estimate can be written as the product of two independent marginal Gaus- sian densities (or equivalently as an appropriately weighted sum of the DIFS and DFFS) ^ P ( ~ Uj) = 6 6 4 2 i=1 i ! M Y 1=2 3 7 7 6 4 <p> These images are shown in These images were subsequently aligned with an automatic face-processing system which extracts faces from the input image and normalizes for translation, scale as well as slight rotations (both in-plane and out-of-plane). This system is described in detail in Moghaddam & Pentland <ref> [9] </ref> and uses the same PCA-based density estimation technique described earlier to obtain maximum-likelihood (ML) estimates of object location (in this case the position and scale (a) (b) the Gallery set (training) and (b) the Probe set (testing). of a face and the location of individual facial features).
Reference: [10] <author> C. Nastar. </author> <title> Vibration modes for nonrigid motion anal-ysis in 3D images. </title> <booktitle> In Proceedings of the Third European Conference on Computer Vision (ECCV '94), </booktitle> <address> Stockholm, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: These image manifolds are modeled as physically- based deformable surfaces which undergo deformations in accordance with a specified force field. The physical dynamics of the system are efficiently solved for using a formulation in terms of the analytic modes of vibration <ref> [10] </ref>. This manifold matching technique can be viewed as a more general formulation for image correspondence which, unlike optical flow, does not require a constant brightness assumption. <p> We do not make that assumption here. Solutions of the governing equation are typically obtained using an eigenvector-based modal decomposition <ref> [14, 11, 10] </ref>. In particular, the vibration modes (i) of the previous deformable surface are the vector solutions of the eigenproblem : K = ! 2 M (3) where !(i) is the i-th eigenfrequency of the system. <p> The modal superposition equation (5) can be seen as a Fourier expansion with high- frequencies neglected <ref> [10] </ref>. <p> The modal superposition equation (5) can be seen as a Fourier expansion with high- frequencies neglected [10]. In our formulation, however, we make use of the analytic modes <ref> [10, 13] </ref>, which are known sine and cosine functions for specific surface topologies (p; p 0 ) = [: : : ; cos 2n p 0 (2j 1) These analytic expressions avoid costly eigenvector decompositions and furthermore allow the total number of modes to be easily adjusted for the application.
Reference: [11] <author> C. Nastar and N. Ayache. </author> <title> Fast segmentation, track-ing, and analysis of deformable objects. </title> <booktitle> In IEEE Proceedings of the Third International Conference on Computer Vision (ICCV'93), </booktitle> <address> Berlin, </address> <month> May </month> <year> 1993. </year>
Reference-contexts: In this section we briefly review the mathematics of this approach (for further details the reader is referred to <ref> [11, 13, 12] </ref>). <p> We do not make that assumption here. Solutions of the governing equation are typically obtained using an eigenvector-based modal decomposition <ref> [14, 11, 10] </ref>. In particular, the vibration modes (i) of the previous deformable surface are the vector solutions of the eigenproblem : K = ! 2 M (3) where !(i) is the i-th eigenfrequency of the system.
Reference: [12] <author> C. Nastar, B. Moghaddam, and A. Pentland. </author> <title> Generalized image matching: Statistical learning of physically-based deformations. </title> <booktitle> In Proceedings of the Fourth European Conference on Computer Vision (ECCV'96), </booktitle> <address> Cambridge, UK, </address> <month> April </month> <year> 1996. </year>
Reference-contexts: This final classification is performed using the a posteriori probabilities computed from the two class-conditional likelihoods which are themselves estimated from training data using an efficient subspace method for density estimation of high-dimensional Gaussian data [9]. 2 Deformable Intensity Surfaces In previous work <ref> [13, 12] </ref>, we formulated a novel image matching technique based on a 3D surface representation of an image I (x; y) | i.e., as the surface (x; y; I (x; y)) as shown, for example, in Figure 1 | and developed an efficient method to warp one image onto another using <p> In this section we briefly review the mathematics of this approach (for further details the reader is referred to <ref> [11, 13, 12] </ref>).
Reference: [13] <author> C. Nastar and A. Pentland. </author> <title> Matching and recognition using deformable intensity surfaces. </title> <booktitle> In IEEE International Symposium on Computer Vision, Coral Gables, </booktitle> <address> USA, </address> <month> November </month> <year> 1995. </year>
Reference-contexts: This final classification is performed using the a posteriori probabilities computed from the two class-conditional likelihoods which are themselves estimated from training data using an efficient subspace method for density estimation of high-dimensional Gaussian data [9]. 2 Deformable Intensity Surfaces In previous work <ref> [13, 12] </ref>, we formulated a novel image matching technique based on a 3D surface representation of an image I (x; y) | i.e., as the surface (x; y; I (x; y)) as shown, for example, in Figure 1 | and developed an efficient method to warp one image onto another using <p> In this section we briefly review the mathematics of this approach (for further details the reader is referred to <ref> [11, 13, 12] </ref>). <p> The modal superposition equation (5) can be seen as a Fourier expansion with high- frequencies neglected [10]. In our formulation, however, we make use of the analytic modes <ref> [10, 13] </ref>, which are known sine and cosine functions for specific surface topologies (p; p 0 ) = [: : : ; cos 2n p 0 (2j 1) These analytic expressions avoid costly eigenvector decompositions and furthermore allow the total number of modes to be easily adjusted for the application.
Reference: [14] <author> A. Pentland and S. Sclaroff. </author> <title> Closed-form solutions for physically based shape modelling and recognition. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> PAMI-13(7):715-729, </volume> <month> July </month> <year> 1991. </year> <month> 7 </month>
Reference-contexts: We do not make that assumption here. Solutions of the governing equation are typically obtained using an eigenvector-based modal decomposition <ref> [14, 11, 10] </ref>. In particular, the vibration modes (i) of the previous deformable surface are the vector solutions of the eigenproblem : K = ! 2 M (3) where !(i) is the i-th eigenfrequency of the system.
References-found: 14

