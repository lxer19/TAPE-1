URL: http://www.icsi.berkeley.edu/~konig/papers/tr-94-012.ps
Refering-URL: http://www.icsi.berkeley.edu/~konig/papers/welcome.html
Root-URL: http://www.icsi.berkeley.edu
Note: Contents  
Abstract-found: 0
Intro-found: 1
Reference: [Bau72] <author> L. E. Baum. </author> <title> An inequality and associated maximization technique in statistical estimation for probabilistic functions of Markov processes. </title> <journal> Inequalities, </journal> <volume> 3 </volume> <pages> 1-8, </pages> <year> 1972. </year>
Reference-contexts: Viterbi approximation, i.e., the sum becomes a max as shown below: P (SjM ) = max P (q l 1 ; q l 2 ; : : : ; q l N jM ) (14) The probability P (XjM; S) is calculated using the forward recursion of the Forward-Backward algorithm <ref> [Bau72] </ref> as described in chapter 3 in [BM94] with the following set of assumptions: * H1: The transition probabilities are independent of the observation vectors as de scribed in the following equation: P (q n k ; X n1 l jq n1 Note that in the case of the phone models
Reference: [BM94] <author> H. Bourlard and N. Morgan. </author> <title> Connectionist Speech Recognition: A Hybrid Approach. </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1994. </year>
Reference-contexts: One solution would be to assume a parametric form for the trajectory, as was done by Deng. In our case, we have chosen to use a multi-layer perceptron (MLP) approach, which in our previous work at ICSI has proved useful for such estimates <ref> [BM94] </ref>. 4 The Time Index Model Implementation and Experiments We present here a specific implementation of the time index model and discuss initial experiments with the Resource Management Task [PFBP88]. 8 4.1 An Implementation of the Time Index Model In section 2, we described the emission probability of a state as <p> With the exception of this final input feature, this net was the same as the hybrid HMM/MLP system as described in <ref> [BM94] </ref>. For the preliminary tests, we assumed knowledge of the boundaries between the phones as produced by an automatic alignment (Viterbi) procedure on the known word string. <p> Find the N-best sentence hypotheses with a relatively simple and fast system. 2. Rescore the sentences with a more powerful system. 3. Combine the scores of the two systems, and output the sentence with the best score. See [ea91] for more details. Chapter 3 in <ref> [BM94] </ref> describes statistical speech recognition in terms of a series of assumptions that lead to the standard HMM formulation. <p> max as shown below: P (SjM ) = max P (q l 1 ; q l 2 ; : : : ; q l N jM ) (14) The probability P (XjM; S) is calculated using the forward recursion of the Forward-Backward algorithm [Bau72] as described in chapter 3 in <ref> [BM94] </ref> with the following set of assumptions: * H1: The transition probabilities are independent of the observation vectors as de scribed in the following equation: P (q n k ; X n1 l jq n1 Note that in the case of the phone models as described above, using single pronunciation word
Reference: [Den92] <author> L. Deng. </author> <title> A generalized hidden markov model with state-conditioned trend functions of time for the speech signal. </title> <booktitle> Signal Processing, </booktitle> <volume> 27 </volume> <pages> 65-78, </pages> <year> 1992. </year>
Reference-contexts: Deng has coined his model the trended HMM <ref> [Den92] </ref>.
Reference: [Dig92] <author> V.V. Digialakis. </author> <title> Segment-Based Stochastic Models of Spectral Dynamics for Continuous Speech Recognition. </title> <type> PhD thesis, </type> <institution> Boston University, </institution> <year> 1992. </year>
Reference-contexts: The production of the acoustic vectors in a segment may be described as a three step procedure <ref> [Dig92] </ref>: 1. Select the length of the segment according to P (Ljs k ), where L is the random variable that denotes the length of the segment, and s k is a particular speech unit. 2. <p> He uses up to five invariant regions for each model. The models based on the correlation invariance assumption outperformed the models based on the trajectory invariance assumption for the task of phone classification. For more details see <ref> [Dig92, DRO93] </ref>. The stochastic dynamic system approach appears to have more modeling power than an HMM, and can potentially capture the dynamics of acoustic vectors within a segment of speech.
Reference: [DRO93] <author> V.V. Digalakis, J.R. Rohlicek, and M. Ostendorf. </author> <title> Segment-based stochastic models of spectral dynamics for continuous speech recognition. </title> <journal> IEEE trans. on Speech and Audio Processing, </journal> <volume> 1(4) </volume> <pages> 431-442, </pages> <month> October </month> <year> 1993. </year>
Reference-contexts: He uses up to five invariant regions for each model. The models based on the correlation invariance assumption outperformed the models based on the trajectory invariance assumption for the task of phone classification. For more details see <ref> [Dig92, DRO93] </ref>. The stochastic dynamic system approach appears to have more modeling power than an HMM, and can potentially capture the dynamics of acoustic vectors within a segment of speech.
Reference: [ea91] <author> M. Ostendorf et al. </author> <title> Integraration of diverse recognition methodologies through reevaluation of n-best sentence hypotheses. </title> <booktitle> In Proceedings DARPA Speech and Natural Language Workshop, </booktitle> <year> 1991. </year> <month> 16 </month>
Reference-contexts: Typically the N-Best paradigm is used in the following way: 1. Find the N-best sentence hypotheses with a relatively simple and fast system. 2. Rescore the sentences with a more powerful system. 3. Combine the scores of the two systems, and output the sentence with the best score. See <ref> [ea91] </ref> for more details. Chapter 3 in [BM94] describes statistical speech recognition in terms of a series of assumptions that lead to the standard HMM formulation.
Reference: [Gla88] <author> J.R. Glass. </author> <title> Finding Acoustic Regularities in Speech Applications to Phonetic Recognition. </title> <type> PhD thesis, </type> <institution> M.I.T, </institution> <month> May </month> <year> 1988. </year>
Reference-contexts: However, this problem does not have an easy solution, see for example <ref> [Gla88] </ref>.
Reference: [GS93] <author> O. Ghitza and M.M. Sondhi. </author> <title> Hidden markov models with templates as non-stationarystates: an application to speech recognition. </title> <booktitle> Computer Speech and Language, </booktitle> <volume> 2 </volume> <pages> 101-119, </pages> <year> 1993. </year>
Reference-contexts: Their specific implementation had ten 14-dimensional vectors of cepstral coefficients. They used a multivariate Gaussian to represent the entire segment, which can require a 140 by 140 full covariance matrix for each phone (assuming that feature dependence is accounted for). Ghitza and Sondhi developed a model <ref> [GS93] </ref> that can also be viewed as a stochastic segment model with the following distinctions: * Their warping procedure is a dynamic time warping technique, instead of the linear time warping method used by Ostendorf and Roukos. * They used diphones as their sub word units, as opposed to to the
Reference: [JR85] <author> B. H. Juang and L.R. Rabiner. </author> <title> Mixture autoregressive hidden markov models for speech signals. </title> <journal> IEEE ASSP Magazine, </journal> <volume> 6(33) </volume> <pages> 1404-1413, </pages> <year> 1985. </year>
Reference-contexts: Several extensions to the basic HMM have been proposed in order to overcome some of these deficiencies. For example, autoregressive HMMs condition the emission probability of a given state on previous observations <ref> [JR85] </ref>. However, none of these extensions have explicitly modeled the emission in a given phone as a non-stationary process. In general this is too difficult to handle with a practical number of parameters.
Reference: [LCG93] <author> H.C. Leung, B. Chigier, and J.R. Glass. </author> <title> A comparative study of signal representations and classification techniques for speech recognition. </title> <booktitle> In Proceedings Int'l Conference on Acoustics Speech and Signal Processing, </booktitle> <address> Minnesota, USA, </address> <year> 1993. </year>
Reference-contexts: A critical issue here is the features used for this discrimination, both in terms of the signal analysis chosen and the frame rate and window size used. In a comparative study of signal representations <ref> [LCG93] </ref> it has been found that Bark auditory cepstral coefficients (BASC) achieved the lowest deletion error rate (the percentage of the transcription boundaries not found by a boundary detector) when used with a frame rate of 5ms and the size of the analysis window of 28.5 ms.
Reference: [Lee89] <author> K. F. Lee. </author> <title> Automatic Speech Recognition: The Development of the SPHINX System. </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1989. </year>
Reference-contexts: For a more detailed description see <ref> [Lee89, XH90] </ref>. By using standard HMMs, we assume that the possible values for the state process at every time step are the basic speech units, usually phones.
Reference: [Lev93] <author> E. Levin. </author> <title> Hidden control neural architecture modeling of nonlinear time varying and its applications. </title> <journal> IEEE trans. on Neural Networks, </journal> <volume> 4(1) </volume> <pages> 109-116, </pages> <month> January </month> <year> 1993. </year>
Reference-contexts: We have incorporated this idea in a connectionist context. 2.3.2 Hidden Control Neural Architecture Esther Levin suggested the idea of changing the mapping that is implemented by a multi-layered neural network as a function of additional control signals <ref> [Lev93] </ref>. Her model is called a Hidden Control Neural Network (HCNN). The advantage of the HCNN over a static neural network is that it can model signals generated by nonlinear dynamic systems with time variability, i.e., the mapping is a function of the state of the system.
Reference: [LHZ91] <author> H.C. Leung, I.L. Hetherington, and V.W. Zue. </author> <title> Speech recognition using stochastic explict-segment modeling. </title> <booktitle> In Proceedings European Conf. on Speech Communication and Technology. (EUROSPEECH), </booktitle> <address> Genova, Italy, </address> <year> 1991. </year>
Reference-contexts: Another idea currently being considered is the use of broad phone categories for estimating quantities like P (tijphone j ; x), since the temporal effects are likely to be fairly similar for broad classes of phones, such as the one used by Leung and colleagues <ref> [LHZ91] </ref> to find transitions between vowels, nasals, liquids, fricatives, stops, and silence.
Reference: [OR89] <author> M. Ostendorf and S. Roukos. </author> <title> A stochastic segment model for phoneme-based continuous speech recognition. </title> <journal> IEEE ASSP trans., </journal> <volume> 37(12) </volume> <pages> 1857-1869, </pages> <month> Decem-ber </month> <year> 1989. </year>
Reference-contexts: These models differ in the form of the distribution (Y js k ) and in the time-warping transformation T L . Ostendorf and Roukos <ref> [OR89] </ref> have used (among a number of methods) linear time sampling in their study, i.e., sampling Y in equal intervals along the time axis as their time warping procedure. Their specific implementation had ten 14-dimensional vectors of cepstral coefficients. <p> segment model with the following distinctions: * Their warping procedure is a dynamic time warping technique, instead of the linear time warping method used by Ostendorf and Roukos. * They used diphones as their sub word units, as opposed to to the phones in Ostendorf and Roukos' stochastic segment model <ref> [OR89] </ref>. * They maintained the HMM framework and assumed a semi-hidden Markov chain, i.e., each state has an explicit duration distribution. 4 These stochastic segment models are not inherently subject to the constraints of the i.i.d. assumptions discussed earlier. However, there are some practical difficulties: 1.
Reference: [PFBP88] <author> P. Price, W. Fisher, J. Bernstein, and D. </author> <title> Pallet. The darpa 1000-word resource management database for continuous spee ch recognition. </title> <booktitle> In Proceedings IEEE Intl. Conf. on Acoustics, Speech, and Signal Processing, </booktitle> <volume> volume 1, </volume> <pages> pages 651-654, </pages> <address> New York, 1988. </address> <publisher> IEEE. </publisher>
Reference-contexts: chosen to use a multi-layer perceptron (MLP) approach, which in our previous work at ICSI has proved useful for such estimates [BM94]. 4 The Time Index Model Implementation and Experiments We present here a specific implementation of the time index model and discuss initial experiments with the Resource Management Task <ref> [PFBP88] </ref>. 8 4.1 An Implementation of the Time Index Model In section 2, we described the emission probability of a state as P (xjphone j ; ti) . While such a quantity can always be defined, the important question is how to estimate it. <p> However, practical use of the time-index 9 10 model will require good estimates of the probabilities of boundary positions. Some possible solutions are discussed later in this report (section 5 ). 4.1.1 Experiments We used the Resource Management speaker independent task <ref> [PFBP88] </ref> for initial experiments. Training data consisted of 3990 read continuous sentences, and the 300 sentence Feb89 test set for development and cross-validation for the network training. The time index net (as shown in Figure 4) had 1000 hidden units, 61 outputs (the size of phone set).
Reference: [SA91] <author> R. Schwartz and S. Austin. </author> <title> A comparison of several approximate algorithms for finding multiple (n-best) sentnce hypotheses. </title> <booktitle> In Proceedings Int'l Conference on Acoustics Speech and Signal Processing, </booktitle> <address> Toronto, Canada, </address> <year> 1991. </year>
Reference-contexts: An approximation of this algorithm is to keep only the previous word as the history of the path (as described in <ref> [SA91] </ref>). Typically the N-Best paradigm is used in the following way: 1. Find the N-best sentence hypotheses with a relatively simple and fast system. 2. Rescore the sentences with a more powerful system. 3. Combine the scores of the two systems, and output the sentence with the best score.
Reference: [SC90] <author> R. Schwartz and Y. Chow. </author> <title> The n-best algorithm: An efficient and exact procedure for finding the n most likely sentence hyoptheses. </title> <booktitle> In Proceedings Int'l Conference on Acoustics Speech and Signal Processing, </booktitle> <address> New Mexico, USA, </address> <year> 1990. </year>
Reference-contexts: The goal of the N-best search is to generate a list of N candidate hypotheses, as well as the segmentations, i.e., the boundaries between the phones for each hypothesis. R. Schwartz and Y. Chow describe an exact algorithm for finding the N mostly likely sentence hypotheses in <ref> [SC90] </ref>. The main idea was to keep separate records for paths with different word sequences histories, adding the probabilities for multiple paths with the same history that transition into the same state.
Reference: [XH90] <author> M.A. Jack X.D. Huang, Y. Ariki. </author> <title> Hidden Markov Models For Speech Recognition. </title> <publisher> Edinburgh University Press, </publisher> <year> 1990. </year> <month> 17 </month>
Reference-contexts: For a more detailed description see <ref> [Lee89, XH90] </ref>. By using standard HMMs, we assume that the possible values for the state process at every time step are the basic speech units, usually phones.
References-found: 18

