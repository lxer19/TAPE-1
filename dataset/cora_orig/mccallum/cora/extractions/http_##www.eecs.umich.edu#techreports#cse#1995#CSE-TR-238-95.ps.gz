URL: http://www.eecs.umich.edu/techreports/cse/1995/CSE-TR-238-95.ps.gz
Refering-URL: http://www.eecs.umich.edu/home/techreports/cse95.html
Root-URL: http://www.eecs.umich.edu
Email: fatri,ashish,kgshing@eecs.umich.edu  
Title: Design Tradeoffs in Implementing Real-Time Channels on Bus-Based Multiprocessor Hosts  
Author: Atri Indiresan Ashish Mehra Kang G. Shin 
Keyword: Key Words Real-time communication, bus-based multiprocessors, network adapter, protocol process ing, CPU and link scheduling  
Address: Ann Arbor, Michigan 48109-2122  
Affiliation: Real-time Computing Laboratory Department of Electrical Engineering and Computer Science The University of Michigan  
Abstract: There are a growing number of real-time applications (e.g., real-time controls, and audio/video conferencing) that require certain quality-of-service (QoS) from the underlying communication subsystem. The communication subsystem must support real-time communication services that can be used to provide the required QoS of these applications, while providing reasonably good performance for best-effort traffic. In this paper we explore the design tradeoffs involved in supporting real-time communication on bus-based multiprocessor hosts using standard network hardware. These tradeoffs are examined by implementing the concept of real-time channel, a paradigm for real-time communication services in packet-switched networks. We first present a hardware and software architecture facilitating real-time communication on bus-based multiprocessor hosts. The main features of this architecture include a dedicated protocol processor, a split-architecture for accessing real-time communication services, and decoupling of data transfer and control in the communication protocol stack. The implications of network adapter characteristics for real-time communication are considered and desirable adapter features derived. Techniques to circumvent limitations in adapters not providing explicit support for real-time communication are presented. Support for real-time communication necessitates that shared host resources such as bus bandwidth, protocol processing bandwidth, and link bandwidth are consumed in a global order determined by the traffic characteristics of the active real-time channels. We present data transfer optimizations, mechanisms to schedule protocol processing, and link scheduling mechanisms that together achieve this goal. The effectiveness of our real-time channel implementation is demonstrated through experiments while varying traffic characteristics. The work reported in this paper was supported in part by the National Science Foundation under grant MIP-9203895 and the Office of Naval Research under grant N00014-94-1-0229. Any opinions, findings, and conclusions or recommendations expressed in this paper are those of the authors and do not necessarily reflect the views of NSF or ONR. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D. Ferrari and D. C. Verma, </author> <title> "A scheme for real-time channel establishment in wide-area networks," </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> vol. SAC-8, no. 3, </volume> <pages> pp. 368-379, </pages> <month> April </month> <year> 1990. </year>
Reference-contexts: Though no guarantees are made about the performance delivered to best-effort traffic, it is desirable to avoid unduly penalizing its performance in the presence of real-time traffic. The real-time channel model <ref> [1, 2] </ref> provides a paradigm for real-time communication services in packet-switched networks. In this model, an application requesting service must specify its traffic characteristics, including the rate at which data is generated, and QoS requirements to the network.
Reference: [2] <author> D. D. Kandlur, K. G. Shin, and D. Ferrari, </author> <title> "Real-time communication in multihop networks," </title> <journal> IEEE Trans. Parallel and Distributed Systems, </journal> <volume> vol. 5, no. 10, </volume> <pages> pp. 1044-1056, </pages> <month> October </month> <year> 1994. </year> <note> An earlier version appeared in the Proc. of the Int. Conf. on Distr. Comp. Sys., </note> <year> 1991. </year>
Reference-contexts: Though no guarantees are made about the performance delivered to best-effort traffic, it is desirable to avoid unduly penalizing its performance in the presence of real-time traffic. The real-time channel model <ref> [1, 2] </ref> provides a paradigm for real-time communication services in packet-switched networks. In this model, an application requesting service must specify its traffic characteristics, including the rate at which data is generated, and QoS requirements to the network. <p> Figure 3 outlines the forward phase of the channel establishment procedure. Given a particular source-destination route, channel establishment is performed using a fixed-priority scheme (algorithm D Order in <ref> [2] </ref>). We only consider static routes for real-time channels since it is very difficult to provide any message-delivery delay guarantees for a channel based on dynamic routing. Channel teardown is triggered by an rtc close call. <p> The NMP sends a teardown request containing the channel identifier along the path of the channel. At each node along the path, all reserved resources are freed and made available for other channels. 6 1. Select the next link along the source-destination route. 2. Use algorithm D Order <ref> [2] </ref> to compute the worst-case delay at this link. Assign the channel the highest possible priority that does not violate guarantees of existing channels. Also compute and reserve adequate buffer and processing resources. 3. Check if the link delay is less than the end-to-end delay. <p> Situation (ii) is handled by registering an event with the x-kernel to wake up the scheduler at the correct time. The link scheduler maintains three queues, namely, Queue 1, Queue 2, and Queue 3, in which outbound packets are inserted by protocol threads <ref> [2] </ref>. Queue 1 contains current real-time packets (whose logical arrival time is less than the current clock time), while Queue 3 contains real-time packets which have arrived early, either because of bursty message generation or because they encountered smaller delays at upstream nodes. <p> All the experiments were performed with a packet size of 2 KB and a pipeline depth of 2, while the message length was fixed at 8KB, i.e., messages consist of 4 packets. The deadline for each real-time channel is set at 50 ms and the link horizon <ref> [2] </ref>, which controls the degree to which the scheduler is work-conserving, is set at 0 ms. Figure 6 (a) shows that with a fragment size of 2 KB, the throughput for a single unconstrained source saturates at 1 MB/second, or 500 pps.
Reference: [3] <institution> CXT 250 16 Port Switch Installer's/User's Manual, ANCOR Communications, Inc., </institution> <year> 1993. </year>
Reference-contexts: Second, we explore three aspects pertaining to the performance of real-time and best-effort traffic on our hardware and software architecture. For this we use a VME bus-based multiprocessor as the end host, with hosts connected by a network constructed from the Ancor CXT 250 crossbar switch <ref> [3] </ref> and CIM 250 network adapters [4]. We highlight the performance implications of the design features and interface characteristics of the network adapter, especially for real-time communication. These observations are used to motivate desirable features in the network adapter that support real-time communication, and hence the implementation of real-time channels. <p> Each processor is an Ironics IV-3207 card with a Motorola MC68040 CPU; the NP has 16 MB of DRAM while the APs have 4 MB of DRAM. In the current configuration, the HARTS interconnection network is constructed from the Ancor CXT 250 crossbar switch <ref> [3] </ref> and Ancor VME CIM 250 network adaptors [4], which implement the ANSI Fibre Channel 3.0 standard [6]. We use the CXT 250 crossbar switch to embed various partially-connected point-to-point topologies for studying multi-hop communication.
Reference: [4] <institution> VME CIM 250 Reference/User's Manual, ANCOR Communications, Inc., </institution> <year> 1992. </year>
Reference-contexts: For this we use a VME bus-based multiprocessor as the end host, with hosts connected by a network constructed from the Ancor CXT 250 crossbar switch [3] and CIM 250 network adapters <ref> [4] </ref>. We highlight the performance implications of the design features and interface characteristics of the network adapter, especially for real-time communication. These observations are used to motivate desirable features in the network adapter that support real-time communication, and hence the implementation of real-time channels. <p> In the current configuration, the HARTS interconnection network is constructed from the Ancor CXT 250 crossbar switch [3] and Ancor VME CIM 250 network adaptors <ref> [4] </ref>, which implement the ANSI Fibre Channel 3.0 standard [6]. We use the CXT 250 crossbar switch to embed various partially-connected point-to-point topologies for studying multi-hop communication.
Reference: [5] <author> K. G. Shin, </author> <title> "HARTS: A distributed real-time architecture," </title> <journal> IEEE Computer, </journal> <volume> vol. 24, no. 5, </volume> <pages> pp. 25-35, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: We conclude in Section 8 with an analysis of the results and suggest directions for future work. 2 The Experimentation Platform In this section we describe the hardware and software architecture of our experimentation platform, which is being developed as a part of HARTS <ref> [5] </ref>. The primary goal of HARTS is to investigate architectural and operating system issues in distributed real-time computing. 2.1 Hardware Each HARTS node (also referred to as end host) is a VME bus-based multiprocessor with 2-4 processors, as shown in Figure 1.
Reference: [6] <institution> Fibre Channel Physical and Signalling Interface (FC-PH), American National Standards Institute, </institution> <note> rev. 3.0 edition, June 1992. Working draft. </note>
Reference-contexts: In the current configuration, the HARTS interconnection network is constructed from the Ancor CXT 250 crossbar switch [3] and Ancor VME CIM 250 network adaptors [4], which implement the ANSI Fibre Channel 3.0 standard <ref> [6] </ref>. We use the CXT 250 crossbar switch to embed various partially-connected point-to-point topologies for studying multi-hop communication. In addition to communication interface hardware, the CIM has 8MB DRAM, independent DMA controllers for data movement, and an input/output processor that provides support for Fibre Channel operations.
Reference: [7] <author> J. Dolter, S. Daniel, A. Mehra, J. Rexford, W. Feng, and K. Shin, "SPIDER: </author> <title> Flexible and efficient communication support for point-to-point distributed systems," </title> <booktitle> in Proc. Int'l Conf. on Distributed Computing Systems, </booktitle> <pages> pp. 574-580, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: Though the CIM has a general-purpose I/O processor, the on-board firmware is controlled by the manufacturer; the NP exercises control over the CIM only through command/response FIFOs. The native interconnection network between HARTS nodes will be provided by SPIDER <ref> [7] </ref>, a custom VME bus-based network adapter now in the final stages of development.
Reference: [8] <author> D. D. Kandlur, D. L. Kiskis, and K. G. Shin, "HARTOS: </author> <title> A distributed real-time operating system," </title> <journal> ACM SIGOPS Operating Systems Review, </journal> <volume> vol. 23, no. 3, </volume> <pages> pp. 72-89, </pages> <month> July </month> <year> 1989. </year> <month> 19 </month>
Reference-contexts: The native interconnection network between HARTS nodes will be provided by SPIDER [7], a custom VME bus-based network adapter now in the final stages of development. SPIDER would allow construction of partially-connected point-to-point topologies with node degrees up to 4. 2.2 Software HARTOS <ref> [8, 9] </ref>, the operating system running at each HARTS node, provides a uniform interface for application programs to access kernel and network services, and supports real-time applications in a distributed environment. Figure 1 highlights the main HARTOS components.
Reference: [9] <author> K. G. Shin, D. D. Kandlur, D. L. Kiskis, P. S. Dodd, H. A. Rosenberg, and A. Indiresan, </author> <title> "A distributed real-time operating system," </title> <journal> IEEE Software, </journal> <pages> pp. 58-68, </pages> <month> September </month> <year> 1992. </year> <note> [10] pSOS + /68K User's Manual, </note> <institution> Integrated Systems Inc., </institution> <note> version 1.2 edition, September 1992. Document No. KX68K-MAN. </note>
Reference-contexts: The native interconnection network between HARTS nodes will be provided by SPIDER [7], a custom VME bus-based network adapter now in the final stages of development. SPIDER would allow construction of partially-connected point-to-point topologies with node degrees up to 4. 2.2 Software HARTOS <ref> [8, 9] </ref>, the operating system running at each HARTS node, provides a uniform interface for application programs to access kernel and network services, and supports real-time applications in a distributed environment. Figure 1 highlights the main HARTOS components.
Reference: [11] <author> N. C. Hutchinson and L. L. Peterson, </author> <title> "The x-Kernel: An architecture for implementing network protocols," </title> <journal> IEEE Trans. Software Engineering, </journal> <volume> vol. 17, no. 1, </volume> <pages> pp. 1-13, </pages> <month> January </month> <year> 1991. </year>
Reference-contexts: Figure 1 highlights the main HARTOS components. The APs run the pSOS +m kernel [10] while the NP runs a protocol stack based on the x-kernel <ref> [11] </ref>. Communication between the APs and the NP is provided via the HARTOS API, a command/response interface that permits pSOS +m and x-kernel to provide network services to applications. AP Kernel: pSOS +m is a real-time multiprocessor OS kernel and serves as the executive for each AP. <p> NP Kernel: The NP employs a derivative of the x-kernel <ref> [11] </ref> as the (communication) executive. It employs a process-per-message model for protocol processing, in which a process or thread shepherds a message through the protocol stack; this eliminates extraneous context switches encountered in the process-per-protocol model [13].
Reference: [12] <author> A. Banerjea, D. Ferrari, B. Mah, M. Moran, D. C. Verma, and H. Zhang, </author> <title> "The Tenet real-time protocol suite: Design, implementation, and experiences," </title> <type> Technical Report TR-94-059, </type> <institution> International Computer Science Institute, Berkeley, </institution> <address> CA, </address> <month> November </month> <year> 1994. </year>
Reference-contexts: We could have implemented our real-time protocols in pSOS +m using pSOS +m sockets as the real-time channel API, similar to the approach adopted by the Tenet group <ref> [12] </ref>. However, we would then be forced to limit ourselves to uniprocessor configurations, with the accompanying process scheduling interference effects, and the semantics and associated overheads of the socket API. More importantly, an expensive coordination amongst the APs may be necessitated to determine the (node-wide) global transmission order. <p> The Tenet real-time protocol suite <ref> [12] </ref> is an advanced implementation of real-time communication on wide-area networks (WANs). This protocol suite comprises the RCAP channel administration protocol and the RTMP/RTIP transport and network layer protocols, which implement unicast real-time channels in UNIX 6 .
Reference: [13] <author> D. C. Schmidt and T. Suda, </author> <title> "Transport system architecture services for high-performance communications systems," </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> vol. 11, no. 4, </volume> <pages> pp. 489-506, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: NP Kernel: The NP employs a derivative of the x-kernel [11] as the (communication) executive. It employs a process-per-message model for protocol processing, in which a process or thread shepherds a message through the protocol stack; this eliminates extraneous context switches encountered in the process-per-protocol model <ref> [13] </ref>.
Reference: [14] <author> S. J. Le*er, M. K. McKusick, M. J. Karels, and J. S. Quarterman, </author> <title> The Design and Implementation of the 4.3BSD Unix Operating System, </title> <publisher> Addison Wesley, </publisher> <month> May </month> <year> 1989. </year>
Reference-contexts: A process-per-message model also allows protocol processing for each message to be independently scheduled on the processor based on a variety of scheduling policies, as opposed to the software-interrupt level processing in BSD 4.3 <ref> [14] </ref>; this improves the traffic insulation between different real-time channels. protocol interfaces with the HARTOS device driver on the APs to implement the HARTOS API. The Name Service protocol provides facilities to register a name locally, and look up a name globally.
Reference: [15] <author> F. Cristian, </author> <title> "Probabilistic clock synchronization," </title> <journal> Distributed Computing, </journal> <volume> vol. 4, no. 3, </volume> <pages> pp. 146-158, </pages> <year> 1989. </year>
Reference-contexts: Communication protocols include standard support like remote procedure call (RPC), reliable datagrams and fragmentation. The RPC and fragmentation protocols are modified versions of x-kernel's CHAN and BLAST protocols, respectively. Our implementation of the Clock Synchronization protocol uses Cristian's probabilistic clock synchronization algorithm <ref> [15] </ref>, while the Network Manager protocol is the resource reservation protocol for real-time channels; these two protocols together support real-time communication services. The HNET protocol is an unreliable datagram service with addressing support for the underlying network. <p> For example, an upper bound on pipeline depth is essential for jitter-sensitive applications like clock synchronization <ref> [15] </ref> and real-time audio/video. Since the CIM does not distinguish best-effort traffic from real-time traffic, the same pipeline depth and packet size must be used for both.
Reference: [16] <author> M. Lin, J. Hsieh, D. H. C. Du, and J. A. MacDonald, </author> <title> "Performance of high-speed network I/O subsystems: Case study of a fibre channel network," </title> <type> Technical Report TR-94-25, </type> <institution> Department of Computer Science, University of Minnesota, </institution> <year> 1994. </year>
Reference-contexts: The memory bandwidth was measured using the bcopy 2 operation, both within the NP and across the VME bus. The CIM has been shown to deliver a maximum throughput of 6 MB/second only for very large ( 3 MB) DMA transfers <ref> [16] </ref>; while the throughput we obtained for smaller packet sizes ( 16 KB) was similar to that obtained in [16], we could only obtain a data transfer bandwidth of 3 MB/second with 3 MB DMA transfers. 2 bcopy performs the transfer a word at a time, using programmed I/O. <p> The CIM has been shown to deliver a maximum throughput of 6 MB/second only for very large ( 3 MB) DMA transfers <ref> [16] </ref>; while the throughput we obtained for smaller packet sizes ( 16 KB) was similar to that obtained in [16], we could only obtain a data transfer bandwidth of 3 MB/second with 3 MB DMA transfers. 2 bcopy performs the transfer a word at a time, using programmed I/O.
Reference: [17] <author> R. L. Cruz, </author> <title> A Calculus for Network Delay and a Note on Topologies of Interconnection Networks, </title> <type> PhD thesis, </type> <institution> University of Illinois at Urbana-Champaign, </institution> <month> July </month> <year> 1987. </year> <note> available as technical report UILU-ENG-87-2246. </note>
Reference-contexts: The sending task establishes a real-time channel by invoking rtc create, specifying the traffic parameters for the message generation process and the end-to-end delay bound desired on this channel. The traffic generation model is based on a linear bounded arrival process <ref> [17, 18] </ref>, in which the arrival process has the following parameters: maximum message size (S max bytes), maximum message rate (R max messages/second), and maximum burst size (B max messages).
Reference: [18] <author> D. P. Anderson, S. Y. Tzou, R. Wahbe, R. Govindan, and M. Andrews, </author> <title> "Support for continuous media in the DASH system," </title> <booktitle> in Proc. Int'l Conf. on Distributed Computing Systems, </booktitle> <pages> pp. 54-61, </pages> <year> 1990. </year>
Reference-contexts: The sending task establishes a real-time channel by invoking rtc create, specifying the traffic parameters for the message generation process and the end-to-end delay bound desired on this channel. The traffic generation model is based on a linear bounded arrival process <ref> [17, 18] </ref>, in which the arrival process has the following parameters: maximum message size (S max bytes), maximum message rate (R max messages/second), and maximum burst size (B max messages). <p> Other protocols for resource reservation include the Session Reservation Protocol (SRP) and resource ReSerVation Protocol (RSVP). The SRP [34] was proposed as a (compound) session establishment protocol for IP networks as part of the DASH project <ref> [18, 35] </ref>. Recently, the RSVP has been proposed for use in the Internet [36]. While SRP is geared toward unicast sessions with performance guarantees, and is similar in flavor to NMP, RSVP is geared more towards multi-point multiparty communication.
Reference: [19] <author> C. Maeda and B. N. Bershad, </author> <title> "Protocol service decomposition for high-performance networking," </title> <booktitle> in Proc. ACM Symp. on Operating Systems Principles, </booktitle> <pages> pp. 244-255, </pages> <month> December </month> <year> 1993. </year>
Reference-contexts: The need for scheduling protocol processing at priority levels consistent with those of the communicating application was highlighted in [37] and some implementation strategies demonstrated in [38]. More recently, processor capacity reserves in Real-Time Mach [39] have been combined with user-level protocol processing <ref> [19] </ref> to make protocol processing inside hosts predictable [40]. Since we dedicate a processor for communication processing, only protocol threads compete with each other for processing resources.
Reference: [20] <author> P. Druschel and L. L. Peterson, "Fbufs: </author> <title> A high-bandwidth cross-domain transfer facility," </title> <booktitle> in Proc. ACM Symp. on Operating Systems Principles, </booktitle> <pages> pp. 189-202, </pages> <month> December </month> <year> 1993. </year>
Reference: [21] <author> P. Druschel, L. L. Peterson, and B. S. Davie, </author> <title> "Experiences with a high-speed network adaptor: A software perspective," </title> <booktitle> in Proc. of ACM SIGCOMM, </booktitle> <pages> pp. 2-13, </pages> <address> London, UK, </address> <month> October </month> <year> 1994. </year>
Reference: [22] <author> A. Edwards, G. Watson, J. Lumley, D. Banks, C. Calamvokis, and C. Dalton, </author> <title> "User-space protocols deliver high performance to applications on a low-cost Gb/s LAN," </title> <booktitle> in Proc. of ACM SIGCOMM, </booktitle> <pages> pp. 14-23, </pages> <address> London, UK, </address> <month> October </month> <year> 1994. </year>
Reference: [23] <author> C. M. Aras, J. F. Kurose, D. S. Reeves, and H. Schulzrinne, </author> <title> "Real-time communication in packet-switched networks," </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> vol. 82, no. 1, </volume> <pages> pp. 122-139, </pages> <month> January </month> <year> 1994. </year>
Reference-contexts: Our implementation methodology is applicable to other proposals for supporting guaranteed real-time communication in packet-switched networks. A detailed survey of the proposed techniques can be found in <ref> [23] </ref>. The most notable proposals are Weighted Fair Queueing [24], also known as Packet-by-Packet Generalized Processor Sharing [25], Stop-and-Go [26], Hierarchical Round-Robin [27], and Rate-Controlled Static-Priority Queueing [28]. Proposals for predicted (or best-effort) real-time communication include FIFO+ [29] and Hop-Laxity [30].
Reference: [24] <author> A. Demers, S. Keshav, and S. Shenker, </author> <title> "Analysis and simulation of a fair queueing algorthm," </title> <booktitle> Proc. of ACM SIGCOMM, </booktitle> <pages> pp. 3-12, </pages> <year> 1989. </year>
Reference-contexts: Our implementation methodology is applicable to other proposals for supporting guaranteed real-time communication in packet-switched networks. A detailed survey of the proposed techniques can be found in [23]. The most notable proposals are Weighted Fair Queueing <ref> [24] </ref>, also known as Packet-by-Packet Generalized Processor Sharing [25], Stop-and-Go [26], Hierarchical Round-Robin [27], and Rate-Controlled Static-Priority Queueing [28]. Proposals for predicted (or best-effort) real-time communication include FIFO+ [29] and Hop-Laxity [30].
Reference: [25] <author> A. K. Parekh and R. G. Gallager, </author> <title> "A generalized processor sharing approach to flow control in integrated services networks the single node case," </title> <booktitle> in IEEE INFOCOM, </booktitle> <pages> pp. 915-924, </pages> <year> 1992. </year>
Reference-contexts: Our implementation methodology is applicable to other proposals for supporting guaranteed real-time communication in packet-switched networks. A detailed survey of the proposed techniques can be found in [23]. The most notable proposals are Weighted Fair Queueing [24], also known as Packet-by-Packet Generalized Processor Sharing <ref> [25] </ref>, Stop-and-Go [26], Hierarchical Round-Robin [27], and Rate-Controlled Static-Priority Queueing [28]. Proposals for predicted (or best-effort) real-time communication include FIFO+ [29] and Hop-Laxity [30].
Reference: [26] <author> S. J. Golestani, </author> <title> "A stop-and-go queueing framework for congestion management," </title> <booktitle> in Proc. SIGCOMM Symposium, </booktitle> <pages> pp. 8-18. </pages> <publisher> ACM, </publisher> <month> September </month> <year> 1990. </year>
Reference-contexts: Our implementation methodology is applicable to other proposals for supporting guaranteed real-time communication in packet-switched networks. A detailed survey of the proposed techniques can be found in [23]. The most notable proposals are Weighted Fair Queueing [24], also known as Packet-by-Packet Generalized Processor Sharing [25], Stop-and-Go <ref> [26] </ref>, Hierarchical Round-Robin [27], and Rate-Controlled Static-Priority Queueing [28]. Proposals for predicted (or best-effort) real-time communication include FIFO+ [29] and Hop-Laxity [30].
Reference: [27] <author> C. R. Kalmanek, H. Kanakia, and S. Keshav, </author> <title> "Rate controlled servers for very high-speed networks," </title> <booktitle> in Proc. GLOBECOM, </booktitle> <month> December </month> <year> 1990. </year>
Reference-contexts: Our implementation methodology is applicable to other proposals for supporting guaranteed real-time communication in packet-switched networks. A detailed survey of the proposed techniques can be found in [23]. The most notable proposals are Weighted Fair Queueing [24], also known as Packet-by-Packet Generalized Processor Sharing [25], Stop-and-Go [26], Hierarchical Round-Robin <ref> [27] </ref>, and Rate-Controlled Static-Priority Queueing [28]. Proposals for predicted (or best-effort) real-time communication include FIFO+ [29] and Hop-Laxity [30].
Reference: [28] <author> H. Zhang and D. Ferrari, </author> <title> "Rate-controlled static-priority queueing," </title> <booktitle> in Proc. of IEEE INFOCOM, </booktitle> <pages> pp. 227-236, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: A detailed survey of the proposed techniques can be found in [23]. The most notable proposals are Weighted Fair Queueing [24], also known as Packet-by-Packet Generalized Processor Sharing [25], Stop-and-Go [26], Hierarchical Round-Robin [27], and Rate-Controlled Static-Priority Queueing <ref> [28] </ref>. Proposals for predicted (or best-effort) real-time communication include FIFO+ [29] and Hop-Laxity [30].
Reference: [29] <author> D. D. Clark, S. Shenker, and L. Zhang, </author> <title> "Supporting real-time applications in an integrated services packet network: Architecture and mechanism," </title> <booktitle> in Proc. of ACM SIGCOMM, </booktitle> <pages> pp. 14-26, </pages> <year> 1992. </year>
Reference-contexts: A detailed survey of the proposed techniques can be found in [23]. The most notable proposals are Weighted Fair Queueing [24], also known as Packet-by-Packet Generalized Processor Sharing [25], Stop-and-Go [26], Hierarchical Round-Robin [27], and Rate-Controlled Static-Priority Queueing [28]. Proposals for predicted (or best-effort) real-time communication include FIFO+ <ref> [29] </ref> and Hop-Laxity [30].
Reference: [30] <author> H. Schulzrinne, J. Kurose, and D. Towsley, </author> <title> "An evaluation of scheduling mechanisms for providing best-effort, real-time communication in wide-area networks," </title> <booktitle> in IEEE INFOCOM, </booktitle> <month> June </month> <year> 1994. </year>
Reference-contexts: The most notable proposals are Weighted Fair Queueing [24], also known as Packet-by-Packet Generalized Processor Sharing [25], Stop-and-Go [26], Hierarchical Round-Robin [27], and Rate-Controlled Static-Priority Queueing [28]. Proposals for predicted (or best-effort) real-time communication include FIFO+ [29] and Hop-Laxity <ref> [30] </ref>.
Reference: [31] <author> S. Shenker, D. D. Clark, and L. Zhang. </author> <title> A Service Model for an Integrated Services Internet. </title> <type> IETF working draft, </type> <month> October </month> <year> 1993. </year>
Reference-contexts: | 4194304 | 16777216 | | | | | | | offered load (packets/sec) latency (microseconds) fi fi fi fi fi fi fi fi fi fi ffi ffi (a) Message latency (b) Slot occupancy (queueing delay) is examining these issues in the context of providing integrated services on the Internet <ref> [31, 32] </ref>. The Tenet real-time protocol suite [12] is an advanced implementation of real-time communication on wide-area networks (WANs). This protocol suite comprises the RCAP channel administration protocol and the RTMP/RTIP transport and network layer protocols, which implement unicast real-time channels in UNIX 6 .
Reference: [32] <author> B. Braden, D. Clark, and S. Shenker. </author> <title> Integrated Services in the Internet Architecture: an Overview. </title> <type> IETF working draft, </type> <month> October </month> <year> 1993. </year> <month> 20 </month>
Reference-contexts: | 4194304 | 16777216 | | | | | | | offered load (packets/sec) latency (microseconds) fi fi fi fi fi fi fi fi fi fi ffi ffi (a) Message latency (b) Slot occupancy (queueing delay) is examining these issues in the context of providing integrated services on the Internet <ref> [31, 32] </ref>. The Tenet real-time protocol suite [12] is an advanced implementation of real-time communication on wide-area networks (WANs). This protocol suite comprises the RCAP channel administration protocol and the RTMP/RTIP transport and network layer protocols, which implement unicast real-time channels in UNIX 6 .
Reference: [33] <author> A. Banerjea, E. W. Knightly, F. L. Templin, and H. Zhang, </author> <title> "Experiments with the Tenet real-time protocol suite on the Sequoia 2000 wide area network," </title> <booktitle> in Proc. ACM Multimedia '94, </booktitle> <pages> pp. 183-192, </pages> <address> San Francisco, CA, </address> <month> October </month> <year> 1994. </year> <note> Also Tech. </note> <institution> Rept. TR-94-020, International Computer Science Institute, Berkeley, </institution> <address> CA, </address> <month> April </month> <year> 1994. </year>
Reference-contexts: This protocol suite comprises the RCAP channel administration protocol and the RTMP/RTIP transport and network layer protocols, which implement unicast real-time channels in UNIX 6 . The effectiveness of these protocols in providing and maintaining QoS guarantees has also been demonstrated <ref> [33] </ref>. Since UNIX-based uniprocessor workstations is the implementation platform, the Tenet approach uses the socket API (hence incurring data copying costs) and does not consider issues arising in a multiprocessor configuration. The problem of making protocol processing inside the host more predictable is also not addressed.
Reference: [34] <author> D. P. Anderson, R. G. Herrtwich, and C. Schaefer, "SRP: </author> <title> A resource reservation protocol for guaranteed performance communication in the internet," </title> <type> Technical Report TR-90-006, </type> <institution> International Computer Science Institute, Berkeley, </institution> <month> February </month> <year> 1990. </year>
Reference-contexts: While their implementation uses standard network adapters, they do not consider the impact of adapter characteristics on the ability to support real-time communication effectively. Other protocols for resource reservation include the Session Reservation Protocol (SRP) and resource ReSerVation Protocol (RSVP). The SRP <ref> [34] </ref> was proposed as a (compound) session establishment protocol for IP networks as part of the DASH project [18, 35]. Recently, the RSVP has been proposed for use in the Internet [36].
Reference: [35] <author> D. P. Anderson, </author> <title> "Metascheduling for continuous media," </title> <journal> ACM Trans. Computer Systems, </journal> <volume> vol. 11, no. 3, </volume> <pages> pp. 226-252, </pages> <month> August </month> <year> 1993. </year>
Reference-contexts: Other protocols for resource reservation include the Session Reservation Protocol (SRP) and resource ReSerVation Protocol (RSVP). The SRP [34] was proposed as a (compound) session establishment protocol for IP networks as part of the DASH project <ref> [18, 35] </ref>. Recently, the RSVP has been proposed for use in the Internet [36]. While SRP is geared toward unicast sessions with performance guarantees, and is similar in flavor to NMP, RSVP is geared more towards multi-point multiparty communication.
Reference: [36] <author> L. Zhang, S. Deering, D. Estrin, S. Shenker, and D. Zappala, "RSVP: </author> <title> A new resource ReSerVation Protocol," </title> <journal> IEEE Network Magazine, </journal> <pages> pp. 8-18, </pages> <month> September </month> <year> 1993. </year>
Reference-contexts: Other protocols for resource reservation include the Session Reservation Protocol (SRP) and resource ReSerVation Protocol (RSVP). The SRP [34] was proposed as a (compound) session establishment protocol for IP networks as part of the DASH project [18, 35]. Recently, the RSVP has been proposed for use in the Internet <ref> [36] </ref>. While SRP is geared toward unicast sessions with performance guarantees, and is similar in flavor to NMP, RSVP is geared more towards multi-point multiparty communication. The issue of making protocol processing predictable within (uniprocessor) hosts has received attention recently.
Reference: [37] <author> D. P. Anderson, L. Delgrossi, and R. G. Herrtwich, </author> <title> "Structure and scheduling in real-time protocol implementations," </title> <type> Technical Report TR-90-021, </type> <institution> International Computer Science Institute, Berkeley, </institution> <month> June </month> <year> 1990. </year>
Reference-contexts: The issue of making protocol processing predictable within (uniprocessor) hosts has received attention recently. The need for scheduling protocol processing at priority levels consistent with those of the communicating application was highlighted in <ref> [37] </ref> and some implementation strategies demonstrated in [38]. More recently, processor capacity reserves in Real-Time Mach [39] have been combined with user-level protocol processing [19] to make protocol processing inside hosts predictable [40].
Reference: [38] <author> R. Govindan and D. P. Anderson, </author> <title> "Scheduling and IPC mechanisms for continuous media," </title> <booktitle> in Proc. ACM Symp. on Operating Systems Principles, </booktitle> <pages> pp. 68-80, </pages> <year> 1991. </year>
Reference-contexts: The issue of making protocol processing predictable within (uniprocessor) hosts has received attention recently. The need for scheduling protocol processing at priority levels consistent with those of the communicating application was highlighted in [37] and some implementation strategies demonstrated in <ref> [38] </ref>. More recently, processor capacity reserves in Real-Time Mach [39] have been combined with user-level protocol processing [19] to make protocol processing inside hosts predictable [40]. Since we dedicate a processor for communication processing, only protocol threads compete with each other for processing resources.
Reference: [39] <author> C. W. Mercer, S. Savage, and H. Tokuda, </author> <title> "Processor capacity reserves for multimedia operating systems," </title> <institution> Computer Science Technical Report CMU-CS-93-157, Carnegie Mellon University, </institution> <month> May </month> <year> 1993. </year>
Reference-contexts: The issue of making protocol processing predictable within (uniprocessor) hosts has received attention recently. The need for scheduling protocol processing at priority levels consistent with those of the communicating application was highlighted in [37] and some implementation strategies demonstrated in [38]. More recently, processor capacity reserves in Real-Time Mach <ref> [39] </ref> have been combined with user-level protocol processing [19] to make protocol processing inside hosts predictable [40]. Since we dedicate a processor for communication processing, only protocol threads compete with each other for processing resources.
Reference: [40] <author> C. W. Mercer, J. Zelenka, and R. Rajkumar, </author> <title> "On predictable operating system protocol processing," </title> <type> Technical Report CMU-CS-94-165, </type> <institution> Carnegie Mellon University, </institution> <month> May </month> <year> 1994. </year> <month> 21 </month>
Reference-contexts: More recently, processor capacity reserves in Real-Time Mach [39] have been combined with user-level protocol processing [19] to make protocol processing inside hosts predictable <ref> [40] </ref>. Since we dedicate a processor for communication processing, only protocol threads compete with each other for processing resources.
References-found: 39

