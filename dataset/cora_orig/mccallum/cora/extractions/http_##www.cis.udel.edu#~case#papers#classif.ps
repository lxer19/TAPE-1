URL: http://www.cis.udel.edu/~case/papers/classif.ps
Refering-URL: http://www.cis.udel.edu/~case/colt.html
Root-URL: http://www.cis.udel.edu
Title: On the Classification of Computable Languages  
Author: John Case Efim Kinber Arun Sharma Frank Stephan 
Address: Heidelberg  
Affiliation: University of Delaware  Sacred Heart University  University of New South Wales  University of  
Abstract: A one-sided classifier converges to 1 on every set inside a given class and outputs infinitely often a 0 on every set outside the class. A two-sided classifier converges in the first case to 1 and in the second to 0. This paper considers one-sided and two-sided classifiers dealing with computable sets as input. It provides theorems from which the classifiability of natural examples can be assessed and investigates the relations of the types of classification to inductive learning theory and structural complexity theory in terms of Turing degrees. Furthermore, it deals with the special cases of classification from positive data only and of inferring trial-and-error classifier programs.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Leonard Adleman and Manuel Blum: </author> <title> Inductive Inference and Unsolvability. </title> <note> Journal of Symbolic Logic 56 (1991) 891-900. </note>
Reference-contexts: An alternative characterization is that there is a function u computable relative to U which dominates every recursive function, i.e., which satisfies (8 1 x) [u (x) &gt; f (x)] for all f 2 REC. Adleman and Blum <ref> [1] </ref> showed that high oracles play a significant role in inductive inference: REC can be Ex-identifiable relative to U iff U is high. Theorems 5.1 and 5.4 show that the high oracles play a similar special role in classification.
Reference: [2] <author> Dana Angluin: </author> <title> Inductive Inference of Formal Languages from Positive Data, </title> <note> Information and Control 45 (1980) 117-135. </note>
Reference-contexts: Given a computable function A (x; y), let A x = fy : A (x; y) = 1g and A = fA 0 ; A 1 ; . . .g. Such an A is called a uniformly recursive family. Angluin <ref> [2] </ref> initiated the study of learning uniformly recursive families from texts and after the introduction of monotonicity constraints many papers have considered the learnability of these families from texts and informants [17, 33, 34].
Reference: [3] <author> Ganesh Baliga and John Case: </author> <title> Learning with Higher Order Additional Information. </title> <booktitle> Proceedings of the Fifth International Workshop on Algorithmic Learning Theory, </booktitle> <address> Reinhardsbrunn, </address> <year> (1994) </year> <month> 64-75. </month>
Reference-contexts: Since the classification of only computable sets is more well-behaved, the following problem might still have a positive solution. Problem Does every infinite one-sided class have an infinite two-sided subclass? 6 Classification By Finding Trial-And-Error Programs Baliga, Case, Jain, Sharma and Suraj studied in several papers <ref> [3, 4, 11] </ref> the concept of learning (or using) limiting or mind-changing programs (equivalently, K-recursive programs) instead of ordinary programs for 10 classes of computable functions.
Reference: [4] <author> Ganesh Baliga, John Case, Sanjay Jain and Mandayam Suraj: </author> <title> Machine Learning of Higher Order Programs. </title> <journal> Journal of Symbolic Logic, </journal> <month> 59 </month> <year> (1994) </year> <month> 486-500. </month>
Reference-contexts: Since the classification of only computable sets is more well-behaved, the following problem might still have a positive solution. Problem Does every infinite one-sided class have an infinite two-sided subclass? 6 Classification By Finding Trial-And-Error Programs Baliga, Case, Jain, Sharma and Suraj studied in several papers <ref> [3, 4, 11] </ref> the concept of learning (or using) limiting or mind-changing programs (equivalently, K-recursive programs) instead of ordinary programs for 10 classes of computable functions.
Reference: [5] <author> Shai Ben-David: </author> <booktitle> Can Finite Samples Detect Singularities of Read-Valued Functions? Proceedings of the 24th Annual ACM Symposium on the Theory of Computer Science, </booktitle> <address> Victoria, B.C., </address> <year> (1992) </year> <month> 390-399. </month>
Reference-contexts: These guesses are supposed to converge, for each set A 2 A 1 ; A 2 ; . . . ; A k , to a value h such that A 2 A h . Smith, Wiehagen and Zeugmann [31] extended this study in various ways. Ben-David <ref> [5] </ref> and Kelly [18] also interestingly studied classification. They call a class classifiable iff there exists a (not-necessarily-computable) functional that indicates in the limit for every A whether or not it belongs to a given class A. They obtained topological conditions for classifiable classes.
Reference: [6] <author> Janis Barzdins and Rusi~ns Freivalds: </author> <title> Prediction and Limiting Synthesis of Recursively Enumerable Classes of Functions. In: Theory of Algorithms and Programs, </title> <type> Vol. </type> <institution> 1 (Latvian State University, </institution> <note> edited by J. M. Barzdins, Riga 1974) 112-128 (in Russian). 11 </note>
Reference-contexts: Note that Ex = Ex 0 . 5 infinitely many 0s which induce infinitely many mind changes on the modified learner; so this modified learner diverges and the modified learner is reliable, i.e., it converges on a computable A if and only if it learns A. Barzdins and Freivalds <ref> [6] </ref> introduced the notion of bounded mind changes where a machine has the right to output only a fixed finite number of guesses such that the last one of them is correct. This notion was more generally considered by Case and Smith [12].
Reference: [7] <author> Lenore Blum and Manuel Blum: </author> <title> Toward a mathematical Theory of Inductive Inference. </title> <journal> Information and Control, </journal> <month> 28 </month> <year> (1975) </year> <month> 125-155. </month>
Reference: [8] <author> J. Richard Buchi: </author> <title> On a decision method in restricted second order arithmetic. </title> <booktitle> In Proceedings of the International Congress on Logic, Methodology and Philosophy of Science, </booktitle> <publisher> Standford University Press, Standford, </publisher> <address> California, </address> <year> 1960. </year>
Reference-contexts: We briefly discuss the various approaches to the study of classification in the literature. One of the earliest attempts was the design of finite automata to decide whether an infinite string (representing the characteristic function of a language) belongs to a given !-language or not <ref> [8, 21, 23, 32] </ref>. But the restrictive computational ability of these finite automata led Buchi [8] and his successors to consider non-deterministic automata. The present paper takes the alternate approach of choosing Turing machines as classifiers. In fact this approach had already been begun by Buchi and Landweber [9, 20]. <p> One of the earliest attempts was the design of finite automata to decide whether an infinite string (representing the characteristic function of a language) belongs to a given !-language or not [8, 21, 23, 32]. But the restrictive computational ability of these finite automata led Buchi <ref> [8] </ref> and his successors to consider non-deterministic automata. The present paper takes the alternate approach of choosing Turing machines as classifiers. In fact this approach had already been begun by Buchi and Landweber [9, 20].
Reference: [9] <author> J. Richard Buchi and Lawrence H. </author> <title> Landweber: Definability in the Monadic Second Order Theory of Successor. </title> <note> Journal of Symbolic Logic 34 (1969) 166-170. </note>
Reference-contexts: But the restrictive computational ability of these finite automata led Buchi [8] and his successors to consider non-deterministic automata. The present paper takes the alternate approach of choosing Turing machines as classifiers. In fact this approach had already been begun by Buchi and Landweber <ref> [9, 20] </ref>. Smith and Wiehagen [30] introduced a model of classification analogous to the Gold model of learning [16].
Reference: [10] <author> John Case, Sanjay Jain and Suzanne Ngo Manguelle: </author> <title> Refinements of Inductive Inference by Popperian and Reliable Machines. </title> <type> Kybernetika, </type> <month> 30 </month> <year> (1994) </year> <month> 23-52. </month>
Reference-contexts: So one would like to look for a more general sufficient condition. The next theorem replaces, then, reliable inference by Popperian Explanatory-identification (PEx), i.e., Ex-identification where every conjecture ever issued by the learner is an index for a total function <ref> [10, 12] </ref>. Theorem 3.3 If A can be PEx-identified with a well-bounded number of mind changes, then A is two-sided classifiable.
Reference: [11] <author> John Case, Sanjay Jain and Arun Sharma: </author> <title> On Learning Limiting Programs. </title> <booktitle> International Journal of Foundations of Computer Science, </booktitle> <month> 3 </month> <year> (1992) </year> <month> 93-115. </month>
Reference-contexts: Since the classification of only computable sets is more well-behaved, the following problem might still have a positive solution. Problem Does every infinite one-sided class have an infinite two-sided subclass? 6 Classification By Finding Trial-And-Error Programs Baliga, Case, Jain, Sharma and Suraj studied in several papers <ref> [3, 4, 11] </ref> the concept of learning (or using) limiting or mind-changing programs (equivalently, K-recursive programs) instead of ordinary programs for 10 classes of computable functions.
Reference: [12] <author> John Case and Carl H. Smith: </author> <title> Comparison of Identification Criteria for Machine Inductive Inference. </title> <note> Theoretical Computer Science 25 (1983) 193-220. </note>
Reference-contexts: This does not effect convergence on A 2 A since there these new mind changes are inserted only finitely often. But if A =2 A, then the classifier outputs 2 Ex a -identification <ref> [12] </ref> requires that a final program p be output and that that p compute the input characteristic function with not more than a mistakes. <p> Barzdins and Freivalds [6] introduced the notion of bounded mind changes where a machine has the right to output only a fixed finite number of guesses such that the last one of them is correct. This notion was more generally considered by Case and Smith <ref> [12] </ref>. Freivalds and Smith [13] generalized this concept further by using constructive ordinal [26] bounds. Their more general version of bounded mind changes is equivalent to the following notion of well-bounded mind changes. <p> So one would like to look for a more general sufficient condition. The next theorem replaces, then, reliable inference by Popperian Explanatory-identification (PEx), i.e., Ex-identification where every conjecture ever issued by the learner is an index for a total function <ref> [10, 12] </ref>. Theorem 3.3 If A can be PEx-identified with a well-bounded number of mind changes, then A is two-sided classifiable.
Reference: [13] <author> Rusi~ns Freivalds and Carl H. Smith: </author> <title> On the Role of Procrastination for Machine Learning", </title> <note> Information and Computation 107 (1993) 237-271. </note>
Reference-contexts: Barzdins and Freivalds [6] introduced the notion of bounded mind changes where a machine has the right to output only a fixed finite number of guesses such that the last one of them is correct. This notion was more generally considered by Case and Smith [12]. Freivalds and Smith <ref> [13] </ref> generalized this concept further by using constructive ordinal [26] bounds. Their more general version of bounded mind changes is equivalent to the following notion of well-bounded mind changes.
Reference: [14] <author> William Gasarch, Mark Pleszkoch, Frank Stephan and Mahendran Velauthapillai: </author> <title> Classification Using Information. </title> <note> To appear in: Annals of Mathematics and Artificial Intelligence. </note>
Reference-contexts: They call a class classifiable iff there exists a (not-necessarily-computable) functional that indicates in the limit for every A whether or not it belongs to a given class A. They obtained topological conditions for classifiable classes. Gasarch, Pleszkoch, Stephan and Velauthapillai <ref> [14] </ref> extended this study and obtained relations between the Borel hierarchy on classes which is induced by the space f0; 1g 1 with product topology and the query hierarchy obtained by allowing a certain number of quantifier-alternations during querying a teacher on the target set A.
Reference: [15] <author> William Gasarch, Mark Pleszkoch and Mahendran Velauthapillai: </author> <title> Classification Using Information Conference Version. </title> <booktitle> Proceedings of the Fifth International Workshop on Algorithmic Learning Theory, Reinhardsbrunn, (1994) 290-300, Lecture Notes in Artificial Intelligence, </booktitle> <volume> 872, </volume> <publisher> Springer Verlag, </publisher> <address> Heidelberg, </address> <year> 1994. </year>
Reference: [16] <author> E. Mark Gold: </author> <title> Language Identification in the Limit. </title> <journal> Information and Control, </journal> <month> 10 </month> <year> (1967) </year> <month> 447-474. </month>
Reference-contexts: The present paper takes the alternate approach of choosing Turing machines as classifiers. In fact this approach had already been begun by Buchi and Landweber [9, 20]. Smith and Wiehagen [30] introduced a model of classification analogous to the Gold model of learning <ref> [16] </ref>. <p> Theorem 3.5 needs the well-bound on the mind changes. In the unbounded case the class of all cofinite sets is one-sided and Ex-identifiable, but not two-sided. So there is an Ex-identifiable class without one-sided classifiable complement. 4 Classification From Only Positive Data Gold <ref> [16] </ref> introduced the notion of identification from text. A text is a form of input where every set is presented as an sequence of numbers and the symbol "#", which contains each element of A at least once and which contains no numbers outside A.
Reference: [17] <author> Klaus Peter Jantke: </author> <title> Monotonic and Non-Monotonic Inductive Inference. </title> <booktitle> New Generation Computing 8 (1991) 349-360. </booktitle>
Reference-contexts: Such an A is called a uniformly recursive family. Angluin [2] initiated the study of learning uniformly recursive families from texts and after the introduction of monotonicity constraints many papers have considered the learnability of these families from texts and informants <ref> [17, 33, 34] </ref>. A class A is closed iff for each A =2 A there is a A such that no B 2 A extends . Theorem 2.3 Every uniformly computable family is one-sided. If it is also closed, then it is two-sided.
Reference: [18] <author> Kevin Kelly: </author> <title> The Logic of Reliable Inquiry. </title> <publisher> Oxford University Press, </publisher> <address> Oxford, </address> <note> to appear. </note>
Reference-contexts: Smith, Wiehagen and Zeugmann [31] extended this study in various ways. Ben-David [5] and Kelly <ref> [18] </ref> also interestingly studied classification. They call a class classifiable iff there exists a (not-necessarily-computable) functional that indicates in the limit for every A whether or not it belongs to a given class A. They obtained topological conditions for classifiable classes.
Reference: [19] <author> Ker-I Ko: </author> <title> Complexity Theory of Real Functions. </title> <publisher> Birkhauser, </publisher> <address> Boston, </address> <year> 1991. </year>
Reference: [20] <author> Lawrence H. </author> <title> Landweber: Decision Problems for !-Automata. </title> <journal> Mathematical Systems Theory, </journal> <month> 3 </month> <year> (1969) </year> <month> 376-384. </month>
Reference-contexts: But the restrictive computational ability of these finite automata led Buchi [8] and his successors to consider non-deterministic automata. The present paper takes the alternate approach of choosing Turing machines as classifiers. In fact this approach had already been begun by Buchi and Landweber <ref> [9, 20] </ref>. Smith and Wiehagen [30] introduced a model of classification analogous to the Gold model of learning [16].
Reference: [21] <author> Robert McNaughton: </author> <title> Testing and Generating Infinite Sequences by a Finite Automaton. </title> <note> Information and Control 9 (1966) 434-448. </note>
Reference-contexts: We briefly discuss the various approaches to the study of classification in the literature. One of the earliest attempts was the design of finite automata to decide whether an infinite string (representing the characteristic function of a language) belongs to a given !-language or not <ref> [8, 21, 23, 32] </ref>. But the restrictive computational ability of these finite automata led Buchi [8] and his successors to consider non-deterministic automata. The present paper takes the alternate approach of choosing Turing machines as classifiers. In fact this approach had already been begun by Buchi and Landweber [9, 20].
Reference: [22] <author> Eliana Minicozzi: </author> <title> Some Natural Properties of Strong Identification in Inductive Inference. </title> <note> Theoretical Computer Science 2 (1976) 345-360. </note>
Reference-contexts: This is due to the fact that the class of the pattern languages is both closed and uniformly recursive. * R = fA : A is regularg is one-sided, but not two-sided. 3 Links Between Learning and Classification Reliable identification in the limit <ref> [22] </ref> means that the learner either diverges or converges to a correct index, but it never converges to a false one. So, the inferred class is also in some sense classified since convergence indicates membership in the class and divergence indicates membership in its complement.
Reference: [23] <author> Maurice Nivat and Dominique Perrin (editors): </author> <title> Automata on Infinite Words. </title> <booktitle> Lecture Notes to Computer Science 192, </booktitle> <publisher> Springer-Verlag, </publisher> <address> Heidelberg, </address> <year> 1984. </year>
Reference-contexts: We briefly discuss the various approaches to the study of classification in the literature. One of the earliest attempts was the design of finite automata to decide whether an infinite string (representing the characteristic function of a language) belongs to a given !-language or not <ref> [8, 21, 23, 32] </ref>. But the restrictive computational ability of these finite automata led Buchi [8] and his successors to consider non-deterministic automata. The present paper takes the alternate approach of choosing Turing machines as classifiers. In fact this approach had already been begun by Buchi and Landweber [9, 20].
Reference: [24] <author> Piergiorgio Odifreddi: </author> <title> Classical recursion theory. </title> <publisher> North-Holland, </publisher> <address> Amsterdam, </address> <year> 1989. </year>
Reference: [25] <author> Daniel N. Osherson, Michael Stob and Scott Weinstein: </author> <title> Systems that learn. </title> <publisher> Bradford / MIT Press, </publisher> <address> London, </address> <year> 1986. </year>
Reference: [26] <author> Gerald E. Sacks: </author> <title> Higher Recursion Theory, Perspectives in Mathematical Logic, </title> <publisher> Springer-Verlag, </publisher> <address> Heidelberg, </address> <year> 1990. </year>
Reference-contexts: This notion was more generally considered by Case and Smith [12]. Freivalds and Smith [13] generalized this concept further by using constructive ordinal <ref> [26] </ref> bounds. Their more general version of bounded mind changes is equivalent to the following notion of well-bounded mind changes.
Reference: [27] <author> Robert I. Soare: </author> <title> Recursively enumerable sets and degrees. </title> <publisher> Springer-Verlag, </publisher> <address> Heidelberg, </address> <year> 1987. </year>
Reference-contexts: Theorem 3.4 There is a two-sided classifiable class A 2 Ex which cannot be Ex-learned with a well-bounded number of mind changes. Proof A simple set <ref> [27] </ref> is one which is recursively enumerable and whose infinite complement does not contain any infinite recursive set. Let S = fa 0 ; a 1 ; . . .g be a simple set and A = fA : jAj is finite and even and A Sg. <p> Furthermore, all classes F (from Example 2.4) can be partially classified since they are two-sided classifiable from text. Theorem 4.6 If A is one-sided classifiable from informant, then A is partially classifiable from text. The converse does not hold. 5 Structural Properties of Classification Soare <ref> [27] </ref> contains an extensive study on the relation between recursively enumerable and computable sets. As Stephan [28] has already noted, the situation of one-sided versus two-sided classification is similar of that of recursively enumerable versus computable sets. <p> So M converges on every computable set outside A to 0 and M is two-sided. A recursively enumerable set E is called creative <ref> [27, Definition II.4.3] </ref> iff there is an effective procedure which disproves for every e the hypothesis "W e = E" by a counterexample f (e), i.e., either f (e) 2 E W e or f (e) 2 W e E. <p> This can be achieved 3 ' U e is the e-th partial recursive in U function. 4 This differs slightly from Soare's definition <ref> [27, Definition IV.4.2] </ref>: Soare defined "K 0 T U 0 " instead of "K 0 T U 0 " since he considers only oracles U T K. 9 easily by H s (e) () = 0 if W e;jj+1 6= W e;jj ; 1 otherwise, i.e., if W e;jj+1 = W
Reference: [28] <author> Frank Stephan: </author> <title> On One-Sided Versus Two-Sided Classification. </title> <type> Manuscript. </type>
Reference-contexts: Later Stephan <ref> [28] </ref> investigated the limits of (computable) classifiers. He considered classification of languages w.r.t. one single class A and introduced two models of classification. <p> Two-sided classification may be considered to be a too strong requirement. In some applications it is sufficient if the classifier is able to signal the inclusion of a language in a given class, but only provides a weaker signal if the language is not in the class. Stephan <ref> [28] </ref> introduced the notion of one-sided classification to model this idea. One-Sided Classification: For all languages A: if A 2 A, then M () = 1 for almost all A; if A =2 A, then M () = 0 for infinitely many A. <p> Hence, in the sequel, the statement "for all languages A" in the above two definitions is replaced by "for all computable languages A". 1 The present paper may also be seen as closing the gap between Stephan's abstract work <ref> [28] </ref> and the more concrete approach of Smith, Wiehagen and Zeugmann [30, 31]. Before we begin a formal presentation of the results, we give an informal tour of the various sections in the paper. <p> We give examples of creative classes and show that a creative class is two-sided only relative to a high oracle. We discuss some interesting results about one-sided classifiable classes of intermediate complexity and compare our results with the more abstract study of classification by Stephan <ref> [28] </ref> in which a classifier has to behave correctly on noncomputable languages, too. Finally, in Section 6, we consider classifiers that, instead of guessing 0 or 1, output programs that converge in the limit to 0 or 1. <p> Theorem 4.6 If A is one-sided classifiable from informant, then A is partially classifiable from text. The converse does not hold. 5 Structural Properties of Classification Soare [27] contains an extensive study on the relation between recursively enumerable and computable sets. As Stephan <ref> [28] </ref> has already noted, the situation of one-sided versus two-sided classification is similar of that of recursively enumerable versus computable sets. This relationship does not only hold in the setting of classifying all sets but also in setting of the present paper of classifying computable sets. <p> Turing degrees, an important tool for studying recursively enumerable sets, are also found to be useful in analyzing the complexity of one-sided classification. The next result shows that similarly to Stephan's general setting <ref> [28] </ref> every one-sided class is two-sided 8 relative to a sufficiently complex oracle. An oracle U is Turing reducible to V (written: U T V ) iff U can be computed by a machine which has access to a database containing V by the membership-queries "Is x 2 V ?". <p> Now the class fA : A " U 6= ;g has an infinite complement but is not disjoint from any infinite two-sided class. It is well-known that every infinite recursively enumerable set has an infinite computable subset. Stephan <ref> [28] </ref> showed that this easy observation does not generalize to one-sided classification versus two-sided in his model which requires correct classification of non-computable sets. Since the classification of only computable sets is more well-behaved, the following problem might still have a positive solution.
Reference: [29] <author> Alan M. </author> <title> Turing: On Computable Numbers with an Application to the Entscheidungsproblem. </title> <booktitle> Proc. </booktitle> <address> London Math. Society 42 (1936) 230-265. </address>
Reference: [30] <author> Rolf Wiehagen and Carl H. Smith: </author> <title> Generalization versus Classification. </title> <journal> Journal of Experimental and Theoretical Artificial Intelligence, </journal> <volume> 7, </volume> <booktitle> 1995. Shorter version in Proceedings 5th Annual Workshop on Computational Learning Theory, </booktitle> <address> (1992) 224-230. </address> <publisher> ACM Press, </publisher> <address> New York. </address>
Reference-contexts: But the restrictive computational ability of these finite automata led Buchi [8] and his successors to consider non-deterministic automata. The present paper takes the alternate approach of choosing Turing machines as classifiers. In fact this approach had already been begun by Buchi and Landweber [9, 20]. Smith and Wiehagen <ref> [30] </ref> introduced a model of classification analogous to the Gold model of learning [16]. <p> Hence, in the sequel, the statement "for all languages A" in the above two definitions is replaced by "for all computable languages A". 1 The present paper may also be seen as closing the gap between Stephan's abstract work [28] and the more concrete approach of Smith, Wiehagen and Zeugmann <ref> [30, 31] </ref>. Before we begin a formal presentation of the results, we give an informal tour of the various sections in the paper. In Section 2, we introduce the basic definitions and give preliminary results about two-sided and one-sided classification for classes of computable languages. <p> Additionally, if the family is discrete, then it is also two-sided classifiable. As a consequence of this result, the class of pattern languages is two-sided classifiable. As a contrast, however, the class of regular languages is only one-sided classifiable. Although, from <ref> [30] </ref> we already know that learning and classification are, in general, incomparable, in Section 3, we provide some pleasant links between learning and classification. We show that for classes identifiable in the limit from informant that they can be reliably identified iff they are one-sided classifiable.
Reference: [31] <author> Carl H. Smith, Rolf Wiehagen and Thomas Zeugmann: </author> <title> Classifying Predicates and Languages. </title> <note> To appear in: International Journal of Foundations of Computer Science. </note>
Reference-contexts: These guesses are supposed to converge, for each set A 2 A 1 ; A 2 ; . . . ; A k , to a value h such that A 2 A h . Smith, Wiehagen and Zeugmann <ref> [31] </ref> extended this study in various ways. Ben-David [5] and Kelly [18] also interestingly studied classification. They call a class classifiable iff there exists a (not-necessarily-computable) functional that indicates in the limit for every A whether or not it belongs to a given class A. <p> Hence, in the sequel, the statement "for all languages A" in the above two definitions is replaced by "for all computable languages A". 1 The present paper may also be seen as closing the gap between Stephan's abstract work [28] and the more concrete approach of Smith, Wiehagen and Zeugmann <ref> [30, 31] </ref>. Before we begin a formal presentation of the results, we give an informal tour of the various sections in the paper. In Section 2, we introduce the basic definitions and give preliminary results about two-sided and one-sided classification for classes of computable languages.
Reference: [32] <author> Boris A. Trakhtenbrot: </author> <title> Finite Automata and the Logic of One Place Predicates. </title> <note> Sibirian Mathematical Journal 3 (1962) 103-131 [in Russian]. </note>
Reference-contexts: We briefly discuss the various approaches to the study of classification in the literature. One of the earliest attempts was the design of finite automata to decide whether an infinite string (representing the characteristic function of a language) belongs to a given !-language or not <ref> [8, 21, 23, 32] </ref>. But the restrictive computational ability of these finite automata led Buchi [8] and his successors to consider non-deterministic automata. The present paper takes the alternate approach of choosing Turing machines as classifiers. In fact this approach had already been begun by Buchi and Landweber [9, 20].
Reference: [33] <author> Thomas Zeugmann: </author> <title> Characterizations of Monotonic and Dual Monotonic Language Learning, </title> <note> Information and Computation 120 (1995) 155-173. </note>
Reference-contexts: Such an A is called a uniformly recursive family. Angluin [2] initiated the study of learning uniformly recursive families from texts and after the introduction of monotonicity constraints many papers have considered the learnability of these families from texts and informants <ref> [17, 33, 34] </ref>. A class A is closed iff for each A =2 A there is a A such that no B 2 A extends . Theorem 2.3 Every uniformly computable family is one-sided. If it is also closed, then it is two-sided.
Reference: [34] <author> Thomas Zeugmann and Steffen Lange: </author> <title> A Guided Tour Across the Boundaries of Learning Recursive Languages. Algorithmic Learning for Knowledge-Based Systems (K. </title> <editor> P. Jantke and S. Lange, Eds.), </editor> <booktitle> Lecture Notes in Computer Science 961 (1995) 193-262. </booktitle> <pages> 12 </pages>
Reference-contexts: Such an A is called a uniformly recursive family. Angluin [2] initiated the study of learning uniformly recursive families from texts and after the introduction of monotonicity constraints many papers have considered the learnability of these families from texts and informants <ref> [17, 33, 34] </ref>. A class A is closed iff for each A =2 A there is a A such that no B 2 A extends . Theorem 2.3 Every uniformly computable family is one-sided. If it is also closed, then it is two-sided.
References-found: 34

