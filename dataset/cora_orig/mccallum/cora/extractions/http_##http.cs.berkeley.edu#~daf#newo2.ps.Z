URL: http://http.cs.berkeley.edu/~daf/newo2.ps.Z
Refering-URL: http://http.cs.berkeley.edu/~daf/
Root-URL: 
Title: Finding Naked People system demonstrates excellent performance on a test set of 565 uncontrolled images
Author: David A. Forsyth and Margaret Fleck 
Note: The  
Abstract: This paper demonstrates an automatic system for telling whether there are naked people present in an image. The approach combines color and texture properties to obtain a mask for skin regions, which is shown to be effective for a wide range of shades and colors of skin. These skin regions are then fed to a specialized grouper, which attempts to group a human figure using geometric constraints on human structure. This approach introduces a new view of object recognition, where an object model is an organized collection of grouping hints obtained from a combination of constraints on color and texture and constraints on geometric properties such as the structure of individual parts and the relationships between parts. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Ahmad S., </author> <title> (1995) "A Usable Real-Time 3D Hand Tracker, </title> " <booktitle> 28th Asilomar Conference on Signals, Systems and Computers, </booktitle> <publisher> IEEE Computer Society Press. </publisher>
Reference-contexts: Face finding based on affine covariant geometric constraints is presented by [29]. Hands have been segmented using color <ref> [1] </ref> and tracked using on a kinematic model [45]. Color information is used in [50] to segment skin regions for face identification. 2.5 Summary Coding the appearance of individual regions is not a satisfactory notion of content.
Reference: [2] <author> Akita, K., </author> <title> "Image sequence analysis of real world human motion," </title> <journal> Pattern Recognition, </journal> <volume> 17, 1, </volume> <pages> 73-83, </pages> <year> 1984. </year>
Reference-contexts: It is usual to deal with images where segmentation is essentially trivial, or where the background is known in advance (as in PFind [62]). Typical systems group regions into stick figures by combining reasoning about gravity [28] or knowledge about background material <ref> [2] </ref> with motion cues, to form and fuse image ribbons. A good survey of related approaches that deal primarily with motion features and recognition of gestures, gaits, and other high level categories appears in [11].
Reference: [3] <author> Ashley, J., Barber, R., Flickner, M.D., Hafner, J.L., Lee, D., Niblack, W. and Petkovich, D. </author> <title> "Automatic and semiautomatic methods for image annotation and retrieval in QBIC," </title> <booktitle> SPIE Proc. Storage and Retrieval for Image and Video Databases III, </booktitle> <pages> 24-35, </pages> <year> 1995. </year>
Reference-contexts: The system then displays a selection of potential matches to those criteria, sorted by a score of the appropriateness of the match. The operator 3 can adjust the scoring function. Region segmentation is largely manual, but the most recent versions of QBIC <ref> [3] </ref> contain simple automated segmentation facilities. The representations constructed are a hierarchy of oriented rectangles of fixed internal color and a set of tiles on a fixed grid, which are described by internal color and texture properties.
Reference: [4] <editor> Bajcsy, </editor> <title> Ruzena (1973) "Computer Identification of Visual Surfaces," Comp. Vis. Im. </title> <booktitle> Proc. </booktitle> <volume> 2/2, </volume> <pages> pp. 118-130 </pages>
Reference: [5] <author> Connell, Jonathan H. and J. </author> <title> Michael Brady "Generating and Generalizing Models of Visual Objects," </title> <booktitle> Artificial Intelligence 31/2, </booktitle> <pages> pp. 159-183, </pages> <year> 1987 </year>
Reference-contexts: None is competent to perform abstract classification; this emphasis appears to be related to the underlying notion of model, rather than to the relative difficulty of the classification vs. identification. Notable exceptions appear in <ref> [7, 5, 35, 64] </ref>, which attempt to code relationships between various forms of volumetric primitive, where the description is in terms of the nature of the primitives involved and of their geometric relationship.
Reference: [6] <author> Brady, J. </author> <title> Michael and Haruo Asada (1984) "Smoothed Local Symmetries and Their Implementation," </title> <journal> Int. J. Robotics Res. </journal> <volume> 3/3, </volume> <pages> 36-61. </pages>
Reference-contexts: Sheffield's version of Canny's [9] edge detector, with relatively high smoothing and contrast thresholds, is applied to these skin areas to obtain a set of connected edge curves. Pairs of edge points with a near-parallel local symmetry <ref> [6] </ref> are found by a straightforward algorithm. Sets of points forming regions with roughly straight axes ("ribbons" [7]) are found using an algorithm based on the Hough transformation.
Reference: [7] <author> Brooks, Rodney A. </author> <title> (1981) "Symbolic Reasoning among 3-D Models and 2-D Images," </title> <booktitle> Artificial Intelligence 17, </booktitle> <pages> pp. 285-348. </pages>
Reference-contexts: None is competent to perform abstract classification; this emphasis appears to be related to the underlying notion of model, rather than to the relative difficulty of the classification vs. identification. Notable exceptions appear in <ref> [7, 5, 35, 64] </ref>, which attempt to code relationships between various forms of volumetric primitive, where the description is in terms of the nature of the primitives involved and of their geometric relationship. <p> Pairs of edge points with a near-parallel local symmetry [6] are found by a straightforward algorithm. Sets of points forming regions with roughly straight axes ("ribbons" <ref> [7] </ref>) are found using an algorithm based on the Hough transformation. The number of irrelevant symmetries recorded is notably reduced by an assumption that humans in test images will appear at a relatively small range of scales; this assumption works fairly well in practice 1 but appears to limit performance.
Reference: [8] <author> Burel G., Carel D., </author> <title> (1994) "Detecting and localization of face on digital images" Pattern Recognition Letters 15 pp 963-967. </title>
Reference-contexts: Face and hand finding/tracking is a related problem where textural, color, and structural constraints are exploited. The main features on a human face appear in much the same form in most images, enabling techniques based on principal component analysis or neural networks proposed by, for example, <ref> [41, 53, 49, 8] </ref>. Face finding based on affine covariant geometric constraints is presented by [29]. Hands have been segmented using color [1] and tracked using on a kinematic model [45].
Reference: [9] <author> Canny, John F. </author> <title> (1986) "A Computational Approach to Edge Detection," </title> <journal> IEEE Patt. Anal. Mach. Int. </journal> <volume> 8/6, </volume> <pages> pp. 679-698. </pages>
Reference-contexts: The input to the geometric grouping algorithm is a set of images, in which the skin filter has marked areas identified as human skin. Sheffield's version of Canny's <ref> [9] </ref> edge detector, with relatively high smoothing and contrast thresholds, is applied to these skin areas to obtain a set of connected edge curves. Pairs of edge points with a near-parallel local symmetry [6] are found by a straightforward algorithm.
Reference: [10] <institution> Candid home page at http://www.c3.lanl.gov/ kelly/CANDID/main.shtml </institution>
Reference-contexts: However, the approach does not adequately address the range of variation in object shape and appears to require images that depict single objects on a uniform background. Further examples of systems that identify materials using low-level image properties include Virage [59], Candid <ref> [10, 23] </ref> and Chabot [37]. None of these systems code spatial organisation in a way that supports object queries.
Reference: [11] <author> Cedras C., Shah M., </author> <title> (1994) "A Survey of Motion Analysis from Moving Light Displays" Computer Vision and Pattern Recognition pp 214-221. </title>
Reference-contexts: A good survey of related approaches that deal primarily with motion features and recognition of gestures, gaits, and other high level categories appears in <ref> [11] </ref>. Face and hand finding/tracking is a related problem where textural, color, and structural constraints are exploited.
Reference: [12] <author> Fleck,Margaret M. </author> <title> (1994) "Practical edge finding with a robust estimator," </title> <booktitle> Proc. of the IEEE Conf. on Computer Vision and Pattern Recognition, </booktitle> <pages> pp. 649-653. </pages>
Reference-contexts: To compute texture amplitude, the intensity image is smoothed with a median filter, and the result subtracted from the original image. The absolute values of these differences are run through a second median filter. These operations use a fast multi-ring approximation to the median filter <ref> [12] </ref>. The texture amplitude and the smoothed R g and B y values are then passed to a tightly-tuned skin filter.
Reference: [13] <author> Fleck, Margaret M. </author> <title> (1996) "The Topology of Boundaries," in press, </title> <journal> Artificial Intelligence. </journal>
Reference-contexts: An object (e.g. a ring) has a specific size and shape. This distinction and a similar distinction for actions, are well-known in linguistics and philosophy (dating back at least to [61]) where they are used to predict differences in the behavior of nouns and verbs (e.g. <ref> [13, 55, 56] </ref>). To a first approximation, 3D materials appear as distinctive colors and textures in 2D images, whereas objects appear as regions with distinctive shapes.
Reference: [14] <author> Forsyth, D.A., J.L. Mundy, A.P. Zisserman, A. Heller, C. Coehlo and C.A. Rothwell, </author> <title> "Invariant Descriptors for 3D Recognition and Pose," </title> <journal> IEEE Trans. Patt. Anal. and Mach. Intelligence, </journal> <volume> 13, 10, </volume> <year> 1991. </year>
Reference-contexts: Alternatively, one can define equivalence classes of features, each large enough to have distinctive properties (invariants) preserved under the imaging transformation. These invariants can then be used as an index for a model library (examples of various combinations of geometry, imaging transformations, and indexing strategies include <ref> [14, 26, 48, 52, 54, 60, 30, 24] </ref>). Each case described so far models object geometry exactly. Systems that recognize an object by matching a view to a collection of images of an object proceed in one of two ways.
Reference: [15] <author> Gershon, Ron, Allan D. Jepson, and John K. </author> <title> Tsotsos (1986) "Ambient Illumination and the Determination of Material Changes," </title> <journal> J. Opt. Soc. America A 3/10, </journal> <pages> pp. 1700-1707. </pages>
Reference-contexts: The input R, G, and B values are then transformed into log-opponent values I, R g , and B y (cf. e.g. <ref> [15] </ref>) as follows: 6 L (x) = 105 log 10 (x + 1 + n) R g = L (R) L (G) L (G) + L (R) The green channel is used to represent intensity because the red and blue channels from some cameras have poor spatial resolution.
Reference: [16] <author> Gong, </author> <title> Yihong and Masao Sakauchi (1995) "Detection of Regions Matching Specified Chromatic Features," Comp. Vis. Im. </title> <journal> Underst. </journal> <volume> 61/2, </volume> <pages> pp. 263-269. </pages>
Reference: [17] <author> Grimson, W.E.L. and Lozano-Perez, T., </author> <title> "Localising overlapping parts by searching the interpretation tree", </title> <journal> PAMI, </journal> <volume> 9, </volume> <pages> 469-482, </pages> <year> 1987. </year>
Reference-contexts: Comparisons can be scored by using a feature correspondence either to backproject object features into an image or to determine a new view of the object and overlay that on the 2 image. Appropriate feature correspondences can be obtained by various forms of search (for example, <ref> [19, 17] </ref>). Alternatively, one can define equivalence classes of features, each large enough to have distinctive properties (invariants) preserved under the imaging transformation.
Reference: [18] <author> Hogg, D., </author> <title> "Model-based vision: a program to see a walking person," </title> <journal> Image and Vision Computing, </journal> <volume> 1, 1, </volume> <pages> 5-19, </pages> <year> 1983. </year> <month> 23 </month>
Reference-contexts: Most previous work emphasizes motion, though [27] shows that structural constraints on humans yield pose, if a stick-figure group is available. The constraints on human dynamics can be exploited to locate moving people in images [43] or to track them <ref> [46, 18] </ref> The resulting figures can then be labelled to various degrees of granularity, leading to inferences 4 about what the person being tracked is doing. Typically, such systems are engineered to simplify segmentation, by, for example, constraining the contrast or the appearance of the background.
Reference: [19] <author> Huttenlocher, D.P. and Ullman, S., </author> <title> "Object recognition using alignment," </title> <booktitle> Proc. ICCV--1, </booktitle> <pages> 102-111, </pages> <year> 1986. </year>
Reference-contexts: Comparisons can be scored by using a feature correspondence either to backproject object features into an image or to determine a new view of the object and overlay that on the 2 image. Appropriate feature correspondences can be obtained by various forms of search (for example, <ref> [19, 17] </ref>). Alternatively, one can define equivalence classes of features, each large enough to have distinctive properties (invariants) preserved under the imaging transformation.
Reference: [20] <institution> Iowa City Press Citizen, "White House `couples' set off indecency program," </institution> <month> 24 Feb. </month> <year> 1996. </year>
Reference-contexts: As a result, seekers miss pictures, and avoiders miss 1 sites containing information they would like to have. Such incongruities occasionally receive media attention; in a recent incident, a commercial package for avoiders refused to allow access to the White House childrens' page <ref> [20] </ref>. 2 Background Determining which of a large set of pictures contain naked people can be seen as a problem in object recognition or in content based retrieval.
Reference: [21] <author> Jacobs, C.E., Finkelstein, A., and Salesin, D.H., </author> <title> "Fast Multiresolution Image Querying," </title> <booktitle> Proc SIGGRAPH-95, </booktitle> <pages> 277-285, </pages> <year> 1995. </year>
Reference-contexts: A third query mode looks for images that are near iconic matches of a given image (for example, <ref> [21] </ref>); this is clearly not relevant to the task in hand, and such systems will not be reviewed here. This application highlights the problems created by attempting to identify objects primarily on the basis of material properties.
Reference: [22] <author> Jacobs, Gerald H. </author> <title> (1981) Comparative Color Vision, </title> <publisher> Academic Press, </publisher> <address> New York. </address>
Reference: [23] <author> Kelly, P.M., Cannon, M., Hush, </author> <title> D.R., "Query by image example: the comparison algorithm for navigating digital image databases (CANDID) approach," </title> <booktitle> SPIE Proc. Storage and Retrieval for Image and Video Databases III, </booktitle> <pages> 238-249, </pages> <year> 1995. </year>
Reference-contexts: However, the approach does not adequately address the range of variation in object shape and appears to require images that depict single objects on a uniform background. Further examples of systems that identify materials using low-level image properties include Virage [59], Candid <ref> [10, 23] </ref> and Chabot [37]. None of these systems code spatial organisation in a way that supports object queries.
Reference: [24] <author> Kriegman, D. and Ponce, J., </author> <title> "Representations for recognising complex curved 3D objects," </title> <booktitle> Proc. International NSF-ARPA workshop on object representation in computer vision, LNCS-994, </booktitle> <pages> 89-100, </pages> <year> 1994. </year>
Reference-contexts: Alternatively, one can define equivalence classes of features, each large enough to have distinctive properties (invariants) preserved under the imaging transformation. These invariants can then be used as an index for a model library (examples of various combinations of geometry, imaging transformations, and indexing strategies include <ref> [14, 26, 48, 52, 54, 60, 30, 24] </ref>). Each case described so far models object geometry exactly. Systems that recognize an object by matching a view to a collection of images of an object proceed in one of two ways.
Reference: [25] <author> Layne, S.S., </author> <title> "Some issues in the indexing of images," </title> <journal> J. Am. Soc. Information Science, </journal> <volume> 45, 8, </volume> <pages> 583-588, </pages> <year> 1994. </year>
Reference-contexts: as complex, categorisations as abstract, or datasets as large as those required by this problem; and current content based retrieval systems must exploit internal database structure or textual information to make abstract queries. 2.1 Objects and materials Many notions of image content have been used to organize collections of images <ref> [25] </ref>. Relevant here are notions centered on objects; the distinction between materials and objects is particularly important. A material (e.g. skin) is defined by a homogeneous or repetitive pattern of fine-scale properties, but has no specific spatial extent or shape.
Reference: [26] <author> Lamdan, Y., Schwartz, J.T. and Wolfson, H.J. </author> <title> "Object Recognition by Affine Invariant Matching," </title> <booktitle> Proceedings CVPR, </booktitle> <address> p.335-344, </address> <year> 1988. </year>
Reference-contexts: Alternatively, one can define equivalence classes of features, each large enough to have distinctive properties (invariants) preserved under the imaging transformation. These invariants can then be used as an index for a model library (examples of various combinations of geometry, imaging transformations, and indexing strategies include <ref> [14, 26, 48, 52, 54, 60, 30, 24] </ref>). Each case described so far models object geometry exactly. Systems that recognize an object by matching a view to a collection of images of an object proceed in one of two ways.
Reference: [27] <author> Lee, H.-J. and Chen, Z. </author> <title> "Determination of 3D human body postures from a single view," </title> <journal> CVGIP, </journal> <volume> 30, </volume> <pages> 148-168, </pages> <year> 1985 </year>
Reference-contexts: There are several domain specific constraints in recognizing human bodies: humans are made out of parts whose shape is relatively simple; there are few ways to assemble these parts; and, when one can measure motion, the dynamics of these parts are limited, too. Most previous work emphasizes motion, though <ref> [27] </ref> shows that structural constraints on humans yield pose, if a stick-figure group is available.
Reference: [28] <author> Leung, M.K., and Yang, Y.-H., </author> <title> "First sight: a human body labelling system," </title> <journal> PAMI, </journal> <volume> 17, 4, </volume> <pages> 359-377, </pages> <year> 1995. </year>
Reference-contexts: It is usual to deal with images where segmentation is essentially trivial, or where the background is known in advance (as in PFind [62]). Typical systems group regions into stick figures by combining reasoning about gravity <ref> [28] </ref> or knowledge about background material [2] with motion cues, to form and fuse image ribbons. A good survey of related approaches that deal primarily with motion features and recognition of gestures, gaits, and other high level categories appears in [11].
Reference: [29] <author> Leung, T.K., Burl M.C., Perona P. </author> <title> (1995) "Finding faces in cluttered scenes using random labelled graph matching, </title> " <booktitle> International Conference on Computer Vision pp 637-644. </booktitle>
Reference-contexts: The main features on a human face appear in much the same form in most images, enabling techniques based on principal component analysis or neural networks proposed by, for example, [41, 53, 49, 8]. Face finding based on affine covariant geometric constraints is presented by <ref> [29] </ref>. Hands have been segmented using color [1] and tracked using on a kinematic model [45]. Color information is used in [50] to segment skin regions for face identification. 2.5 Summary Coding the appearance of individual regions is not a satisfactory notion of content.
Reference: [30] <author> J. Liu, J.L. Mundy, D.A. Forsyth, </author> <title> A.P. Zisserman and C.A. Rothwell, "Efficient Recognition of rotationally symmetric surfaces and straight homogenous generalized cylinders," </title> <booktitle> IEEE conference on Computer Vision and Pattern Recognition '93, </booktitle> <year> 1993. </year>
Reference-contexts: Alternatively, one can define equivalence classes of features, each large enough to have distinctive properties (invariants) preserved under the imaging transformation. These invariants can then be used as an index for a model library (examples of various combinations of geometry, imaging transformations, and indexing strategies include <ref> [14, 26, 48, 52, 54, 60, 30, 24] </ref>). Each case described so far models object geometry exactly. Systems that recognize an object by matching a view to a collection of images of an object proceed in one of two ways.
Reference: [31] <author> Lowe, David G. </author> <title> (1987) "The Viewpoint Consistency Constraint," </title> <journal> Intern. J. of Comp. Vis, </journal> <volume> 1/1, </volume> <pages> pp. 57-72. </pages>
Reference: [32] <author> MacFormat, </author> <note> issue no. 28 with CD-Rom, </note> <month> September, </month> <year> 1995. </year>
Reference-contexts: 58 images of clothed people, a mixture of Caucasians, Blacks, Asians, and Indians, largely showing their faces, 3 re-photographed from a book and the rest photographed from live models at the University of Iowa, * 44 assorted images from a photo CD that came with a copy of a magazine <ref> [32] </ref>, * 11 assorted personal photos, re-photographed with our CCD camera, and * 47 pictures of objects and textures taken in our laboratory for other purposes. * 1241 pictures, consisting of the complete contents of CD-ROM's 10000 (Air shows), 113000 (Arabian horses), 123000 (Backyard wildlife), 130000 (African speciality animals), 132000 (Annuals
Reference: [33] <author> Minka, T., </author> <title> "An image database browser that learns from user interaction," </title> <type> MIT media lab TR 365, </type> <year> 1995. </year>
Reference-contexts: Further examples of systems that identify materials using low-level image properties include Virage [59], Candid [10, 23] and Chabot [37]. None of these systems code spatial organisation in a way that supports object queries. Variations on photobook <ref> [42, 33] </ref> use a form of supervised learning known in the information retrieval community as "relevance feedback" to adjust segmentation and classification parameters for various forms of textured region. When a user is available to tune queries, supervised learning algorithms can clearly improve performance given appropriate object and image representations.
Reference: [34] <author> Murase, H. and Nayar, </author> <title> S.K., "Visual learning and recognition of 3D objects from appearance," </title> <note> to appear, Int. J. Computer Vision, 1995. 24 </note>
Reference-contexts: An alternative approach computes a feature vector from a compressed version of the image and uses a minimum distance classifier to match this feature vector to feature vectors computed from images of objects in a range of positions under various lighting conditions <ref> [34] </ref>. All of the approaches described rely heavily on specific, detailed geometry, known (or easily determined) correspondences, and either the existence of a single object on a uniform, known background (in the case of [34]) or the prospect of relatively clear segmentation. <p> feature vectors computed from images of objects in a range of positions under various lighting conditions <ref> [34] </ref>. All of the approaches described rely heavily on specific, detailed geometry, known (or easily determined) correspondences, and either the existence of a single object on a uniform, known background (in the case of [34]) or the prospect of relatively clear segmentation. None is competent to perform abstract classification; this emphasis appears to be related to the underlying notion of model, rather than to the relative difficulty of the classification vs. identification.
Reference: [35] <author> Nevatia, R. and Binford, </author> <title> T.O., "Description and recognition of curved objects," </title> <journal> Artifi--cial Intelligence, </journal> <volume> 8, </volume> <pages> 77-98, </pages> <year> 1977 </year>
Reference-contexts: None is competent to perform abstract classification; this emphasis appears to be related to the underlying notion of model, rather than to the relative difficulty of the classification vs. identification. Notable exceptions appear in <ref> [7, 5, 35, 64] </ref>, which attempt to code relationships between various forms of volumetric primitive, where the description is in terms of the nature of the primitives involved and of their geometric relationship.
Reference: [36] <author> Niblack, W., Barber, R, Equitz, W., Flickner, M., Glasman, E., Petkovic, D., and Yanker, P. </author> <title> (1993) "The QBIC project: querying images by content using colour, texture and shape," </title> <booktitle> IS and T/SPIE 1993 Intern. Symp. Electr. Imaging: Science and Technology, Conference 1908, Storage and Retrieval for Image and Video Databases. </booktitle>
Reference-contexts: As the results below show, it is insufficient to search for naked people by looking for skin alone; the skin needs to be in pieces of the right shape, which are attached to one another in the right ways. The best-known image database system is QBIC <ref> [36] </ref>, which allows an operator to specify various properties of a desired image. The system then displays a selection of potential matches to those criteria, sorted by a score of the appropriateness of the match. The operator 3 can adjust the scoring function.
Reference: [37] <author> Ogle, Virginia E. and Michael Stonebraker (1995) "Chabot: </author> <title> Retrieval from a Relational Database of Images," </title> <booktitle> Computer 28/9, </booktitle> <pages> pp. 40-48. </pages>
Reference-contexts: However, the approach does not adequately address the range of variation in object shape and appears to require images that depict single objects on a uniform background. Further examples of systems that identify materials using low-level image properties include Virage [59], Candid [10, 23] and Chabot <ref> [37] </ref>. None of these systems code spatial organisation in a way that supports object queries. Variations on photobook [42, 33] use a form of supervised learning known in the information retrieval community as "relevance feedback" to adjust segmentation and classification parameters for various forms of textured region.
Reference: [38] <author> O'Rourke, J. and Badler, N., </author> <title> "Model-based image analysis of human motion using constraint propagation," </title> <journal> PAMI, </journal> <volume> 2, 6, </volume> <pages> 522-536, </pages> <year> 1980. </year>
Reference: [39] <author> Pentland, A., Picard, R.W., and Sclaroff, S. "Photobook: </author> <title> content-based manipulation of image databases," MIT Media Lab Perceptual Computing TR No. </title> <type> 255, </type> <month> Nov. </month> <year> 1993. </year>
Reference-contexts: However, neither representation allows reasoning about the shape of individual regions, about the relative positioning of regions of given colors or about the cogency of geometric coocurrence information, and so there is little reason to believe that either representation can support object queries. Photobook <ref> [39] </ref> largely shares QBIC's model of an image as a collage of flat, homogenous frontally presented regions, but incorporates more sophisticated representations of texture and a degree of automatic segmentation. A version of Photobook ([39], p. 10) incorporates a simple notion of object queries, using plane object matching by an energy
Reference: [40] <author> Perez, </author> <title> Frank and Christof Koch (1994) "Towards Color Image Segmentation in Analog VLSI: Algorithm and Hardware," </title> <journal> Intern. J. of Comp. Vis. </journal> <volume> 12/1, </volume> <pages> pp. 17-42. </pages>
Reference: [41] <author> Pentland A., Moghaddam, B., Starner T., </author> <title> (1994) "View-based and modular eigenspaces for face recognition," </title> <booktitle> in Computer Vision and Pattern Recognition, </booktitle> <pages> pp 84-91. </pages>
Reference-contexts: Face and hand finding/tracking is a related problem where textural, color, and structural constraints are exploited. The main features on a human face appear in much the same form in most images, enabling techniques based on principal component analysis or neural networks proposed by, for example, <ref> [41, 53, 49, 8] </ref>. Face finding based on affine covariant geometric constraints is presented by [29]. Hands have been segmented using color [1] and tracked using on a kinematic model [45].
Reference: [42] <author> Picard, R.W. and Minka, T. </author> <title> "Vision texture for annotation," </title> <journal> J. Multimedia systems, </journal> <volume> 3, </volume> <pages> 3-14, </pages> <year> 1995. </year> <title> [43] "Detecting Activities" (1993) Polana R., </title> <journal> Nelon R., in Computer Vision and Pattern Recognition pp 2-13. </journal>
Reference-contexts: Object-oriented queries search for images that contain particular objects; such queries can be seen either as constructs on material queries <ref> [42] </ref>, as essentially textual matters [44], or as the proper domain of object recognition. <p> Further examples of systems that identify materials using low-level image properties include Virage [59], Candid [10, 23] and Chabot [37]. None of these systems code spatial organisation in a way that supports object queries. Variations on photobook <ref> [42, 33] </ref> use a form of supervised learning known in the information retrieval community as "relevance feedback" to adjust segmentation and classification parameters for various forms of textured region. When a user is available to tune queries, supervised learning algorithms can clearly improve performance given appropriate object and image representations.
Reference: [44] <author> Price, R., Chua, T.-S., Al-Hawamdeh, S., </author> <title> "Applying relevance feedback to a photo-archival system," </title> <journal> J. Information Sci., </journal> <volume> 18, </volume> <pages> 203-215, </pages> <year> 1992. </year>
Reference-contexts: Object-oriented queries search for images that contain particular objects; such queries can be seen either as constructs on material queries [42], as essentially textual matters <ref> [44] </ref>, or as the proper domain of object recognition. A third query mode looks for images that are near iconic matches of a given image (for example, [21]); this is clearly not relevant to the task in hand, and such systems will not be reviewed here.
Reference: [45] <author> Rehg, J.M, Kanade, T., </author> <title> (1995) "Model-based tracking of self-occluding articulated objects," </title> <booktitle> International Conference on Computer Vision pp 612-617. </booktitle>
Reference-contexts: Face finding based on affine covariant geometric constraints is presented by [29]. Hands have been segmented using color [1] and tracked using on a kinematic model <ref> [45] </ref>. Color information is used in [50] to segment skin regions for face identification. 2.5 Summary Coding the appearance of individual regions is not a satisfactory notion of content. To identify 3D objects, or even materials, requires representing shape properties of regions, and the relative spatial disposition of regions.
Reference: [46] <author> Rohr, K., </author> <title> "Towards model-based recognition of human movements in image sequences," </title> <journal> CVGIP-IU, </journal> <volume> 59, 1, </volume> <pages> 94-115, </pages> <year> 1994 </year>
Reference-contexts: Most previous work emphasizes motion, though [27] shows that structural constraints on humans yield pose, if a stick-figure group is available. The constraints on human dynamics can be exploited to locate moving people in images [43] or to track them <ref> [46, 18] </ref> The resulting figures can then be labelled to various degrees of granularity, leading to inferences 4 about what the person being tracked is doing. Typically, such systems are engineered to simplify segmentation, by, for example, constraining the contrast or the appearance of the background.
Reference: [47] <author> Rossotti, </author> <title> Hazel (1983) Colour: Why the World isn't Grey, </title> <publisher> Princeton University Press, </publisher> <address> Princeton, NJ. </address>
Reference-contexts: Skin can be identified as regions that have no texture and satisfy a collection of color constraints, as the appearance of skin is tightly constrained. The color of a human's skin is created by a combination of blood (red) and melanin (yellow, brown) <ref> [47] </ref>. Therefore, human skin has a restricted range of hues and is somewhat saturated, but not deeply saturated. Because more deeply colored skin is created by adding melanin, one would expect the saturation to increase as the skin becomes more yellow, and this is reflected in our data set.
Reference: [48] <author> Rothwell, C.A., A. Zisserman, J.L. Mundy and D.A. Forsyth, </author> <title> "Efficient Model Library Access by Projectively Invariant Indexing Functions," </title> <booktitle> Computer Vision and Pattern Recognition 92, </booktitle> <pages> 109-114, </pages> <year> 1992. </year>
Reference-contexts: Alternatively, one can define equivalence classes of features, each large enough to have distinctive properties (invariants) preserved under the imaging transformation. These invariants can then be used as an index for a model library (examples of various combinations of geometry, imaging transformations, and indexing strategies include <ref> [14, 26, 48, 52, 54, 60, 30, 24] </ref>). Each case described so far models object geometry exactly. Systems that recognize an object by matching a view to a collection of images of an object proceed in one of two ways.
Reference: [49] <author> Rowley, H., Baluja, S., Kanade, T. </author> <title> (1996) "Human Face Detection in Visual Scenes" To Appear in: </title> <booktitle> Neural Information Processing Systems 8. </booktitle> <pages> 25 </pages>
Reference-contexts: Face and hand finding/tracking is a related problem where textural, color, and structural constraints are exploited. The main features on a human face appear in much the same form in most images, enabling techniques based on principal component analysis or neural networks proposed by, for example, <ref> [41, 53, 49, 8] </ref>. Face finding based on affine covariant geometric constraints is presented by [29]. Hands have been segmented using color [1] and tracked using on a kinematic model [45].
Reference: [50] <author> Sanger, D., Haneishi, H. and Miyake, Y., </author> <title> "Method for light source discrimination and facial pattern detection from negative colour film," </title> <journal> J. Imaging Science and Technology, </journal> <volume> 39, 2, </volume> <pages> 166-175, </pages> <year> 1995. </year>
Reference-contexts: Face finding based on affine covariant geometric constraints is presented by [29]. Hands have been segmented using color [1] and tracked using on a kinematic model [45]. Color information is used in <ref> [50] </ref> to segment skin regions for face identification. 2.5 Summary Coding the appearance of individual regions is not a satisfactory notion of content. To identify 3D objects, or even materials, requires representing shape properties of regions, and the relative spatial disposition of regions.
Reference: [51] <author> Sclaroff, S. </author> <title> "World wide web image search engines," </title> <institution> Boston University Computer Science Dept TR95-016, </institution> <year> 1995. </year>
Reference-contexts: The existence of internet sites that sell images of naked people suggests that some people seek them, and would welcome a program that could find them automatically, perhaps by attaching an image content assessment program to a web robot (along the lines suggested by <ref> [51] </ref>). Equally, sales of programs such as "NetNanny" suggest that another significant group of people would prefer to prevent images of this form arriving on their computers. At present, each class seeks or avoids images based purely on the origin of the image, rather than on its content.
Reference: [52] <author> Stein, F. and Medioni, G., </author> <title> "Structural indexing: efficient 3D object recognition," </title> <booktitle> PAMI-14, </booktitle> <pages> 125-145, </pages> <year> 1992. </year>
Reference-contexts: Alternatively, one can define equivalence classes of features, each large enough to have distinctive properties (invariants) preserved under the imaging transformation. These invariants can then be used as an index for a model library (examples of various combinations of geometry, imaging transformations, and indexing strategies include <ref> [14, 26, 48, 52, 54, 60, 30, 24] </ref>). Each case described so far models object geometry exactly. Systems that recognize an object by matching a view to a collection of images of an object proceed in one of two ways.
Reference: [53] <author> Sung, K.K, Poggio, T., </author> <title> (1994) "Example-based Learning from View-based Human Face Detection" MIT A.I. Lab Memo No. </title> <type> 1521. </type>
Reference-contexts: Face and hand finding/tracking is a related problem where textural, color, and structural constraints are exploited. The main features on a human face appear in much the same form in most images, enabling techniques based on principal component analysis or neural networks proposed by, for example, <ref> [41, 53, 49, 8] </ref>. Face finding based on affine covariant geometric constraints is presented by [29]. Hands have been segmented using color [1] and tracked using on a kinematic model [45].
Reference: [54] <author> Taubin, G. and Cooper, </author> <title> D.B., "Object recognition based on moment (or algebraic) invariants," in J.L. Mundy and A.P. Zisserman (ed.s) Geometric Invariance in Computer Vision, </title> <publisher> MIT Press, </publisher> <year> 1992. </year>
Reference-contexts: Alternatively, one can define equivalence classes of features, each large enough to have distinctive properties (invariants) preserved under the imaging transformation. These invariants can then be used as an index for a model library (examples of various combinations of geometry, imaging transformations, and indexing strategies include <ref> [14, 26, 48, 52, 54, 60, 30, 24] </ref>). Each case described so far models object geometry exactly. Systems that recognize an object by matching a view to a collection of images of an object proceed in one of two ways.
Reference: [55] <author> B. Taylor, </author> <title> Tense and Continuity, </title> <note> Linguistics and Philosophy 1 (1977) 199-220. </note>
Reference-contexts: An object (e.g. a ring) has a specific size and shape. This distinction and a similar distinction for actions, are well-known in linguistics and philosophy (dating back at least to [61]) where they are used to predict differences in the behavior of nouns and verbs (e.g. <ref> [13, 55, 56] </ref>). To a first approximation, 3D materials appear as distinctive colors and textures in 2D images, whereas objects appear as regions with distinctive shapes.
Reference: [56] <author> C. L. Tenny, </author> <title> Grammaticalizing Aspect and Affectedness, </title> <type> Ph.D. thesis, </type> <institution> Linguistics and Philosophy, Massachusetts Inst. of Techn. </institution> <year> (1987). </year>
Reference-contexts: An object (e.g. a ring) has a specific size and shape. This distinction and a similar distinction for actions, are well-known in linguistics and philosophy (dating back at least to [61]) where they are used to predict differences in the behavior of nouns and verbs (e.g. <ref> [13, 55, 56] </ref>). To a first approximation, 3D materials appear as distinctive colors and textures in 2D images, whereas objects appear as regions with distinctive shapes.
Reference: [57] <author> Treisman, </author> <title> Anne (1985) "Preattentive Processing in Vision," Com. Vis. Grap. Im. </title> <booktitle> Proc. </booktitle> <volume> 31/2, </volume> <pages> pp. 156-177. </pages>
Reference: [58] <author> Ullman, S. and Basri, R. </author> <year> (1991). </year> <title> Recognition by linear combination of models, </title> <journal> IEEE PAMI, </journal> <volume> 13, 10, </volume> <pages> 992-1007. </pages>
Reference-contexts: An estimate of the appearance in the image of that object is then constructed from the correspondences. The hypothesis that the object is present is then verified using the estimate of appearance <ref> [58] </ref>. An alternative approach computes a feature vector from a compressed version of the image and uses a minimum distance classifier to match this feature vector to feature vectors computed from images of objects in a range of positions under various lighting conditions [34].
Reference: [59] <institution> Virage home page at http://www.virage.com/ </institution>
Reference-contexts: However, the approach does not adequately address the range of variation in object shape and appears to require images that depict single objects on a uniform background. Further examples of systems that identify materials using low-level image properties include Virage <ref> [59] </ref>, Candid [10, 23] and Chabot [37]. None of these systems code spatial organisation in a way that supports object queries.
Reference: [60] <author> Weiss, I. </author> <title> "Projective Invariants of Shapes," </title> <booktitle> Proceeding DARPA Image Understanding Workshop, </booktitle> <address> p.1125-1134, </address> <month> April </month> <year> 1988. </year>
Reference-contexts: Alternatively, one can define equivalence classes of features, each large enough to have distinctive properties (invariants) preserved under the imaging transformation. These invariants can then be used as an index for a model library (examples of various combinations of geometry, imaging transformations, and indexing strategies include <ref> [14, 26, 48, 52, 54, 60, 30, 24] </ref>). Each case described so far models object geometry exactly. Systems that recognize an object by matching a view to a collection of images of an object proceed in one of two ways.
Reference: [61] <author> Whorf, </author> <title> Benjamin Lee (1941) "The Relation of Habitual Thought and Behavior to Language," in Leslie Spier, ed., Language, culture, and personality, essays in memory of Edward Sapir, </title> <note> Sapir Memorial Publication Fund, Menasha, WI. </note>
Reference-contexts: An object (e.g. a ring) has a specific size and shape. This distinction and a similar distinction for actions, are well-known in linguistics and philosophy (dating back at least to <ref> [61] </ref>) where they are used to predict differences in the behavior of nouns and verbs (e.g. [13, 55, 56]). To a first approximation, 3D materials appear as distinctive colors and textures in 2D images, whereas objects appear as regions with distinctive shapes.
Reference: [62] <author> Wren, C., Azabayejani, A., Darrell, T. and Pentland, A., "Pfinder: </author> <title> real-time tracking of the human body," MIT Media Lab Perceptual Computing Section TR 353, </title> <year> 1995. </year>
Reference-contexts: It is usual to deal with images where segmentation is essentially trivial, or where the background is known in advance (as in PFind <ref> [62] </ref>). Typical systems group regions into stick figures by combining reasoning about gravity [28] or knowledge about background material [2] with motion cues, to form and fuse image ribbons.
Reference: [63] <author> Zisserman, A., Mundy, J.L., Forsyth, D.A., Liu, J.S., Pillow, N., Rothwell, C.A. and Utcke, S. </author> <title> (1995) "Class-based grouping in perspective images",Intern. </title> <booktitle> Conf. on Comp. </booktitle> <pages> Vis. </pages>
Reference: [64] <author> Zerroug, M. and Nevatia, R. </author> <title> "From an intensity image to 3D segmented descriptions," </title> <address> ICPR, </address> <year> 1994. </year> <month> 26 </month>
Reference-contexts: None is competent to perform abstract classification; this emphasis appears to be related to the underlying notion of model, rather than to the relative difficulty of the classification vs. identification. Notable exceptions appear in <ref> [7, 5, 35, 64] </ref>, which attempt to code relationships between various forms of volumetric primitive, where the description is in terms of the nature of the primitives involved and of their geometric relationship.
References-found: 63

