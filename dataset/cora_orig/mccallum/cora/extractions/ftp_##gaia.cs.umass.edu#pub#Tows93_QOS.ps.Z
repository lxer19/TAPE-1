URL: ftp://gaia.cs.umass.edu/pub/Tows93:QOS.ps.Z
Refering-URL: http://www-net.cs.umass.edu/papers/papers.html
Root-URL: 
Title: Providing Quality of Service in Packet Switched Networks  
Author: Don TOWSLEY 
Keyword: quality of service, call admission, real-time services, link scheduling.  
Note: Appeared in Performance Evaluation of Computer and Communication Systems (ed. L. Donatiello, R. Nelson), pp. 560-586, Springer Verlag, 1993. This work was supported in part by the National Science Foundation under grant NCR-9116183.  
Date: July 1993  
Address: Amherst, MA 01003 U.S.A.  
Affiliation: Dept. of Computer Science University of Massachusetts  
Abstract: Increases in bandwidths and processing capabilities of future packet switched networks will give rise to a dramatic increase in the types of applications using them. Many of these applications will require guaranteed quality of service (QOS) such as a bound on the maximum end-to-end packet delay and/or on the probability of packet loss. This poses exciting challenges to network designers. In this paper we discuss the QOS requirements of different applications and survey recent developments in the areas of call admission, link scheduling, and the interaction between the provision of QOS and call routing and traffic monitoring and policing. We identify what some of the important issues are in these areas and point out important directions for future research efforts. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. Akhtar. </author> <title> Congestion control in a fast packet switching network. </title> <type> Master's thesis, </type> <institution> Was hington University, St. Louis, Missouri, </institution> <year> 1987. </year>
Reference-contexts: They are based on the following approach for a given loss requirement, determine the maximum number of sources, n max , that can share a link so that they all satisfy their requirements. Then ^c = r=n max . This can be obtained either through analysis, <ref> [1] </ref>, or simulation, [16]. Observe that the test for call admission can be stated in the following equivalent form, is n + 1 n max ? Here n denotes the number of sessions currently using the link.
Reference: [2] <author> J.-T. Amenyo, A.A. Lazar, and G. </author> <title> Pacific. Cooperative distributed scheduling for ats-based broadband networks. </title> <booktitle> In INFOCOM'92, </booktitle> <pages> pages 333-342, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: being characterized by a high value of R peak but the network determines through measurements that it is considerably lower, can the network take advantage of it? Several proposed algorithms allow the network to modify network resource allocations to sessions in order to account for changes in traffic characteristics, see <ref> [2] </ref>. 7 Summary and Future Work In this paper we have presented the state of the art of provision of QOS in integrated digital services networks.
Reference: [3] <author> D. Anick, D. Mitra, and M. M. Sondhi. </author> <title> Stochastic theory of a data-handling system with multiple sources. </title> <journal> Bell System Technical Journal, </journal> <volume> 61 </volume> <pages> 1871-1894, </pages> <year> 1982. </year>
Reference-contexts: These applications produce bursty, highly correlated packet streams. Current traffic source models include Markov modulated arrival processes (e.g., [24]) and Markov modulated fluid processes, (e.g., <ref> [3] </ref>). In numerous cases, voice, medical images, and file transfers, they can be modeled by two state on-off models. If the process is in an off state, no packet is generated and if it is in an on state, packets are generated with at constant intervals of time. <p> This expression was derived from a fluid model of an off-on source, <ref> [3] </ref>, and developed to be 1) simple to compute, depending on only three parameters and 2) generally pessimistic. One problem with this approach is that it ignores the possible multiplexing gains achieved by sharing the link among a number of sources.
Reference: [4] <author> Caglan M. Aras, Jim Kurose, Douglas Reeves, and Henning Schulzrinne. </author> <title> Real-time com munication in packet-switched networks. </title> <note> To Appear in Proceedings of the IEEE, </note> <month> January </month> <year> 1994. </year>
Reference-contexts: In this section, we describe some of the issues that arise in designing multiclass scheduling policies and how they have been treated by network designers. The reader is referred to <ref> [23, 4] </ref> for additional details regarding the link scheduling policies described here as well as others. We assume that the scheduling policy must deal with at least three classes of applications which differ according to the type of QOS that they require, i) deterministic, ii) statistical, and iii) best effort.
Reference: [5] <author> Ernst Biersack. </author> <title> Error recovery in high-speed networks. </title> <booktitle> In Second International Workshop on Network and Operating System Support for Digital Audio and Video, </booktitle> <pages> page 222, </pages> <year> 1991. </year>
Reference-contexts: Although, these are the QOS metrics typically considered in the literature on provision of QOS, they may not be the most appropriate metrics, <ref> [39, 40, 6, 43, 30, 5, 37] </ref>. For example, consider the requirement that packet loss not exceed 1% for a voice application. <p> Thus a number of papers propose QOS requirements based on intervals of time, e.g., 1% loss over a talkspurt in audio applications [40, 6], over a frame in video <ref> [43, 30, 5, 37] </ref>. Recent work [36] indicates that replacing interval QOS measures with stationary QOS measures can produce very poor results if, in fact interval measures are of interest. There has been little work performed to include these types of metrics as part of call admission algorithms.
Reference: [6] <author> Hugh S. Bradlow. </author> <title> Performance measures for real-time continuous bit-stream oriented services: Application to packet reassembly. </title> <journal> Computer Networks and ISDN systems, </journal> <volume> 20:15 26, </volume> <year> 1990. </year>
Reference-contexts: Although, these are the QOS metrics typically considered in the literature on provision of QOS, they may not be the most appropriate metrics, <ref> [39, 40, 6, 43, 30, 5, 37] </ref>. For example, consider the requirement that packet loss not exceed 1% for a voice application. <p> Thus a number of papers propose QOS requirements based on intervals of time, e.g., 1% loss over a talkspurt in audio applications <ref> [40, 6] </ref>, over a frame in video [43, 30, 5, 37]. Recent work [36] indicates that replacing interval QOS measures with stationary QOS measures can produce very poor results if, in fact interval measures are of interest.
Reference: [7] <author> CCITT. </author> <booktitle> Rec. I.121: Recommendation on broadband aspects of ISDN. </booktitle> <year> 1988. </year>
Reference-contexts: We will describe these later in this section. It is worth pointing out that the ATM standard provides for virtual paths <ref> [7, 8] </ref> between source-destination pairs. Briefly, a virtual path can be viewed as a dedicated bandwidth channel between a pair of nodes. Hence, it is a mechanism that can be used to isolate different classes of service from each other.
Reference: [8] <author> CCITT. </author> <title> Rec. I.371: Recommendation on traffic control and congestion control in B-ISDN. </title> <year> 1992. </year>
Reference-contexts: We will describe these later in this section. It is worth pointing out that the ATM standard provides for virtual paths <ref> [7, 8] </ref> between source-destination pairs. Briefly, a virtual path can be viewed as a dedicated bandwidth channel between a pair of nodes. Hence, it is a mechanism that can be used to isolate different classes of service from each other.
Reference: [9] <author> C.-S. Chang. </author> <title> Stability, queue length and delay, part ii:stochastic queueing networks. </title> <type> Tech nical Report RC 17709, </type> <institution> IBM. </institution>
Reference-contexts: Kurose [33] provides tail bounds for the same network as Cruz under the assumption that busy periods at each node are finite and bounded in duration. Inherent in the model is the asumption that sources are described by LBAP's. Yaron and Sidi [50] and Chang <ref> [9] </ref> consider more general arrival processes for which the peak rate is unbounded and, based on Chernoff's bound, develop bounds on the end-to-end delay distribution.
Reference: [10] <author> R. Chipalkatti, J.F. Kurose, and D. Towsley. </author> <title> Scheduling policies for real-time and non real-time traffic in a statistical multiplexer. </title> <booktitle> In IEEE INFOCOM'89, </booktitle> <pages> pages 774-783, </pages> <month> April </month> <year> 1989. </year>
Reference-contexts: Instead, it may be possible to provide better performance to the other classes of service packets by delaying the packet's transmission for awhile and allocating the link instead to these other classes of service. These have been illustrated in <ref> [10] </ref>. It is important to point out that most proposed algorithms provide higher priority to packets generated by deterministic and statistical applications than to best effort packets. <p> Recently, several policies have been proposed that attempt to deal with the QOS requirements of two or more distinct classes of applications in a complementary manner. One of the earliest such policies, Minimum Laxity with Threshold (MLT), introduced by Chipalkatti, et al. <ref> [10] </ref> deals with an application in which the QOS metric is the fraction of packets whose delay exceeds a deadline D and another application whose QOS metric is expected delay.
Reference: [11] <author> D.D. Clark, S. Shenker, and L. Zhang. </author> <title> Supporting real-time applications in an integrated services packet network: architecture and mechanism. </title> <booktitle> In ACM SIGCOMM'92, </booktitle> <pages> pages 14 26, </pages> <year> 1992. </year>
Reference-contexts: A second reason for monitoring the traffic of a connection would be to provide adaptivity. If the traffic characteristics of a connection change, then the network could note these changes and make use of them when setting up additional calls. This approach is taken in <ref> [22, 11] </ref>. Most of the work in this area is based on the underlying assumption that bursts generated by sources are typically small compared to the buffer capacity of each node in the network. <p> The theory exhibits the folllowing important properties. * Networks can be non-feed-forward, * In the case that k = s for j k 2 s , the delay bound is given by T s + propagation delay (2) which is independent of the path length. Clarke, et al., <ref> [11] </ref> have proposed WFQ as the scheduler in their architecture for providing 15 deterministic QOS.
Reference: [12] <author> Rene Cruz. </author> <title> A calculus for network delay, part II: Network analysis. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> 37 </volume> <pages> 132-141, </pages> <year> 1991. </year>
Reference-contexts: In a very interesting series of papers, Cruz <ref> [12] </ref> shows that delays are bounded for a set of (possibly non-identical) sessions under any set of non-idling policies traversing a feed forward network provided that 1) each session (i) is described by a LBAP with parameters ( i ; i ) and for each link k, r k &gt; P
Reference: [13] <author> A. Demers, S. Keshav, and S. Shenker. </author> <title> Analysis and simulation of a fair queueing algorithm. </title> <journal> Internetworking:Research and Experience, </journal> <volume> 1 </volume> <pages> 3-26. </pages>
Reference-contexts: See [20] for further details and [19] for a description of how it can be integrated with other traffic classes Weighted Fair Queuing: This policy was first introduced as a mechanism to ensure fairness between different sessions in traditional data networks <ref> [13] </ref>. It is most easily described under the assumption that workloads generated by sessions can be treated as infinitely divisible fluids. Let S sessions labelled i = 1; : : :; S share a link with capacity r. <p> If r denotes the rate of the server and L max the maximum packet length, then it has been shown ([38]) that T i ^ T i L max =r . This policy was originally proposed and studied in <ref> [13] </ref> with i = 1=S for the purposes of providing fair service to traditional data traffic in the internet.
Reference: [14] <author> Anwar Elwalid and Debasis Mitra. </author> <title> Effective bandwidth of general Markovian traffic sources and admission control of high-speed networks. </title> <note> Submitted to ACM-IEEE Transactions on Networking, </note> <month> July </month> <year> 1992. </year>
Reference-contexts: Last, the work of Guerin, et al., which first proposed and developed the theory of effective bandwidths through simple heuristic arguments has been placed on a solid mathematical basis by several recent papers, <ref> [17, 14, 31] </ref>. This work has resulted in two types of results. The first is the derivation of the effective bandwidth of a single source for a large class of queueing systems and traffic models.
Reference: [15] <author> Domenico Ferrari and Dinesh Verma. </author> <title> A scheme for real-time channel establishment in wide-area networks. </title> <journal> IEEE J.Select.Areas Commun., </journal> <volume> 8 </volume> <pages> 368-379, </pages> <month> April </month> <year> 1990. </year>
Reference-contexts: At the time that the server becomes available, it is assigned the packet with the smallest (earliest) due date to transmit. Ferrari and Verma <ref> [15] </ref> propose this policy as part of a QOS provision mechanism where the due-date associated with a session is negotiated at the time that a call is admitted. It is also a component of the MARS approach [27]. <p> Examples of such calculations along with their computaional costs can be found in <ref> [15, 48] </ref>. Let d k denote this minimum local deadline at node j k . <p> Several ways of allocating end-to-end deadline to local deadlines are described in <ref> [15] </ref>. This approach can produce provable guarantees using EDD and J-EDD as the local schedulers. The latter provides lower jitter guarantees than the former. <p> This brings us to the approach most prevalent in the literature, namely to develop call admission policies that approximately provide statistical guarantees. Two approaches have been 17 taken in this direction. The first is to develop heuristic models for estimating the tails of delay distributions <ref> [15, 28] </ref>. The latter approach actually measures current network behavior and uses this to parameterize the model. <p> These ibclude * allocation of end-to-end QOS requirements to nodal QOS requirement, * adaptivity to changes in link loads, and * adaptivity to changes in session characteristics. Although several proposed call admission algorithms require the allocation of end-to-end QOS requirements to nodal requirements, e.g., <ref> [15, 22] </ref>, the problem has not been thoroughly addressed. One exception is the work of Nagarajan [36] which compares an optimal allocation to the simple heuristic of equal allocation.
Reference: [16] <author> G. Gallassi, G. Rigolio, and L. Fratta. </author> <title> ATM:bandwidth assignment and bandwidth enfor cement policies. </title> <booktitle> In GLOBECOM'89, </booktitle> <pages> pages 1788-1793, </pages> <month> December </month> <year> 1989. </year>
Reference-contexts: However, if the packet arrives to find an insufficient number of tokens, it is marked before being released. Coupling this with a link scheduling policy that is allowed to drop marked packets in the case of congestion, can yield performance improvements over the standard leaky bucket, <ref> [16] </ref> 6 A source is said to be a (; ; C) linearly bounded arrival process (LBAP) if, when fed through a leaky bucket with parameters , , and C, none of the packets ever incur a delay. <p> They are based on the following approach for a given loss requirement, determine the maximum number of sources, n max , that can share a link so that they all satisfy their requirements. Then ^c = r=n max . This can be obtained either through analysis, [1], or simulation, <ref> [16] </ref>. Observe that the test for call admission can be stated in the following equivalent form, is n + 1 n max ? Here n denotes the number of sessions currently using the link.
Reference: [17] <author> R. J. Gibbens and P. J. Hunt. </author> <title> Effective bandwidths for multi-type uas channel. </title> <journal> QUESTA, </journal> <volume> 9 </volume> <pages> 17-28, </pages> <year> 1991. </year>
Reference-contexts: Last, the work of Guerin, et al., which first proposed and developed the theory of effective bandwidths through simple heuristic arguments has been placed on a solid mathematical basis by several recent papers, <ref> [17, 14, 31] </ref>. This work has resulted in two types of results. The first is the derivation of the effective bandwidth of a single source for a large class of queueing systems and traffic models.
Reference: [18] <author> Andre Girard. </author> <title> Routing and Dimensioning in Circuit-Switched Networks. </title> <publisher> Addison Wesley, </publisher> <year> 1990. </year>
Reference-contexts: Various aspects of the routing problem and its relationship to the provision of QOS can be found in [26]. Solutions to the routing problem will undoubtedly borrow from routing in circuit-switched networks, <ref> [18] </ref>. Consider the problem of answering the question whether or not the QOS requirements of a new call can be satisfied while continuing to provide the QOS of other calls.
Reference: [19] <author> S. J. Golestani. </author> <title> A stop-and-go queueing framework for congestion management. </title> <booktitle> In Proc. 1990 SIGCOMM, </booktitle> <pages> pages 8-18. </pages>
Reference-contexts: Here F i is assumed to be a multiple of F i+1 . Thus, an application having a delay bound of D at the node would be assigned to level J = arg minfi : 2F i1 &lt; D 2F i g. See [20] for further details and <ref> [19] </ref> for a description of how it can be integrated with other traffic classes Weighted Fair Queuing: This policy was first introduced as a mechanism to ensure fairness between different sessions in traditional data networks [13].
Reference: [20] <author> S. J. Golestani. </author> <title> Congestion-free transmission of real-time traffic in packet networks. </title> <booktitle> In IEEE INFOCOM'90, </booktitle> <pages> pages 527-536, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: Here F i is assumed to be a multiple of F i+1 . Thus, an application having a delay bound of D at the node would be assigned to level J = arg minfi : 2F i1 &lt; D 2F i g. See <ref> [20] </ref> for further details and [19] for a description of how it can be integrated with other traffic classes Weighted Fair Queuing: This policy was first introduced as a mechanism to ensure fairness between different sessions in traditional data networks [13].
Reference: [21] <author> Roch Guerin et al. </author> <title> Equivalent capacity and its application to bandwidth allocation in high-speed networks. </title> <journal> IEEE J.Select.Areas Commun., </journal> <volume> 9(7) </volume> <pages> 968-981, </pages> <year> 1991. </year>
Reference-contexts: Then, the problem of call admission is simplified tremendously. The decision to accept a new call s requires the following test, is r P This approach was first proposed in <ref> [21] </ref> where the following heuristic expression was given to 19 compute the effective bandwidth of an on-off source, ^c = R peak x [ffb (1 u)R peak K] 2 + 4Kffbu (1 u)R peak 2ffb (1 u) where ff = ln (1=*). <p> One problem with this approach is that it ignores the possible multiplexing gains achieved by sharing the link among a number of sources. Hence, the following expression in <ref> [21] </ref> was proposed for the effective bandwidth of a collection of sources S, ^ C = min m + ff 0 ; i2S ) where m is the average aggregate rate of the sources in S, is the standard deviation in the aggregate rate, and ff 0 = p 2 ln
Reference: [22] <author> Roch Guerin and Levent Gun. </author> <title> A unified approach to bandwidth allocation and access control in fast packet-switched networks. </title> <booktitle> In INFOCOM'92, </booktitle> <pages> pages 01-12, </pages> <year> 1992. </year>
Reference-contexts: A second reason for monitoring the traffic of a connection would be to provide adaptivity. If the traffic characteristics of a connection change, then the network could note these changes and make use of them when setting up additional calls. This approach is taken in <ref> [22, 11] </ref>. Most of the work in this area is based on the underlying assumption that bursts generated by sources are typically small compared to the buffer capacity of each node in the network. <p> The first expression in the min is based on a Gaussian approximation of the aggregate bit rate. Such approximations have been shown to accurately model the stationary bit rate when the number of sources is sufficiently large ( &gt;10 is suggested in <ref> [22] </ref>). This has been extended to a network setting by assuming that the source traffic charac teristics are relatively unaffected much when passing through a link (see [22] for evidence for the validity of this assumption) and through an application of the principle of nodal isolation, i.e., allocating the end-to-end packet <p> have been shown to accurately model the stationary bit rate when the number of sources is sufficiently large ( &gt;10 is suggested in <ref> [22] </ref>). This has been extended to a network setting by assuming that the source traffic charac teristics are relatively unaffected much when passing through a link (see [22] for evidence for the validity of this assumption) and through an application of the principle of nodal isolation, i.e., allocating the end-to-end packet loss requirement among the nodes on a path. See [22] for details of this approach. <p> assuming that the source traffic charac teristics are relatively unaffected much when passing through a link (see <ref> [22] </ref> for evidence for the validity of this assumption) and through an application of the principle of nodal isolation, i.e., allocating the end-to-end packet loss requirement among the nodes on a path. See [22] for details of this approach. There is currently insufficient experience with this approach to determine how well it will work. As mentioned earlier, the guarantees are approximate. In order to compensate for this, they have been chosen to be very conservative. <p> These ibclude * allocation of end-to-end QOS requirements to nodal QOS requirement, * adaptivity to changes in link loads, and * adaptivity to changes in session characteristics. Although several proposed call admission algorithms require the allocation of end-to-end QOS requirements to nodal requirements, e.g., <ref> [15, 22] </ref>, the problem has not been thoroughly addressed. One exception is the work of Nagarajan [36] which compares an optimal allocation to the simple heuristic of equal allocation.
Reference: [23] <author> S. Keshav H. Zhang. </author> <title> Comparison of rate-based service disciplines. </title> <booktitle> In SIGCOMM. </booktitle>
Reference-contexts: In this section, we describe some of the issues that arise in designing multiclass scheduling policies and how they have been treated by network designers. The reader is referred to <ref> [23, 4] </ref> for additional details regarding the link scheduling policies described here as well as others. We assume that the scheduling policy must deal with at least three classes of applications which differ according to the type of QOS that they require, i) deterministic, ii) statistical, and iii) best effort.
Reference: [24] <author> Harry Heffes and David Lucantoni. </author> <title> A markov modulated characterization of voice and data traffic and related statistical multiplexer performance. </title> <journal> IEEE J.Select.Areas Commun., </journal> <volume> SAC-4:856-867, </volume> <month> September </month> <year> 1986. </year>
Reference-contexts: Although a number of applications are characterized by a continuous bit rate (CBR, e.g., voice without silence detection), most applications use compression techniques in order to reduce their average bandwidth requirements. These applications produce bursty, highly correlated packet streams. Current traffic source models include Markov modulated arrival processes (e.g., <ref> [24] </ref>) and Markov modulated fluid processes, (e.g., [3]). In numerous cases, voice, medical images, and file transfers, they can be modeled by two state on-off models.
Reference: [25] <author> Joseph Y. Hui. </author> <title> Resource allocation for broadband networks. </title> <journal> IEEE J.Select.Areas Com mun., </journal> <volume> 6(9) </volume> <pages> 1598-1608, </pages> <month> December </month> <year> 1988. </year>
Reference-contexts: Again, a call can be admitted if the combined populations fall within the feasible region. Such an approach has been sggested and studied in <ref> [25] </ref>. in the context of loss requirements and in the context of different types of QOS requirements [27].
Reference: [26] <author> Ren-Hung Hwang. </author> <title> Routing in high-speed networks. </title> <type> PhD thesis, </type> <institution> University of Massachu setts, Amherst, </institution> <year> 1993. </year>
Reference-contexts: Various aspects of the routing problem and its relationship to the provision of QOS can be found in <ref> [26] </ref>. Solutions to the routing problem will undoubtedly borrow from routing in circuit-switched networks, [18]. Consider the problem of answering the question whether or not the QOS requirements of a new call can be satisfied while continuing to provide the QOS of other calls.
Reference: [27] <author> Jay M. Hyman et al. </author> <title> Real-time scheduling with quality of service constraints. </title> <journal> IEEE J.Select.Areas Commun., </journal> <volume> 9(7) </volume> <pages> 1052-1063, </pages> <month> September </month> <year> 1991. </year>
Reference-contexts: There have been some attempts to develop high level scheduling policies that attempt to share the link cooperatively between different classes of service rather than to isolate them, <ref> [27] </ref>. We will survey these policies later in this section. Last, a scheduler has to be chosen to schedule packets belonging to the same class of service on the link. Clearly, any policy that provides class isolation can be used to provide session isolation. <p> Ferrari and Verma [15] propose this policy as part of a QOS provision mechanism where the due-date associated with a session is negotiated at the time that a call is admitted. It is also a component of the MARS approach <ref> [27] </ref>. A problem inherent in FIFO and EDD is that end-to-end jitter tends to grow as a function of the path length in networks. <p> Their preliminary results show that a threshold can be chosen that tradeoffs the QOS of both classes thus yielding better performance than what mght be achieved by either a static priority scheme or FIFO. 12 More recently, Lazar, et al. <ref> [27] </ref>, have proposed a more sophisticated variation of MLT that interleaves the transmission of deterministic and statistical packets in such a way that statistical packets are given priority so long as no deterministic packet is allowed to miss its deadline [27]. 5.4 Buffer management policies So far no mention has been <p> priority scheme or FIFO. 12 More recently, Lazar, et al. <ref> [27] </ref>, have proposed a more sophisticated variation of MLT that interleaves the transmission of deterministic and statistical packets in such a way that statistical packets are given priority so long as no deterministic packet is allowed to miss its deadline [27]. 5.4 Buffer management policies So far no mention has been made of the fact that buffer capacity at the link is finite in capacity, much less the impact that this has on link scheduling (if any). <p> This is exemplified in the work described in <ref> [27] </ref>. 6.2.2 Statistical loss guarantees We begin the discussion of how to provide statistical loss guarantees by first noting that a solution to this problem often automatically solves the problem of providing statistical deadline guarantees in many high speed networks. Consider a network with links having bandwidths of 150Mbs. <p> Again, a call can be admitted if the combined populations fall within the feasible region. Such an approach has been sggested and studied in [25]. in the context of loss requirements and in the context of different types of QOS requirements <ref> [27] </ref>. Last, the work of Guerin, et al., which first proposed and developed the theory of effective bandwidths through simple heuristic arguments has been placed on a solid mathematical basis by several recent papers, [17, 14, 31]. This work has resulted in two types of results.
Reference: [28] <author> S. Jamin, S. Shenker, L. Zhang, and D.D Clark. </author> <title> An admission control algorithm for pre dictive real-time service(extended abstract). </title> <booktitle> In Third International Workshop on network and operating system support for digital audio and video, </booktitle> <pages> pages 308-315, </pages> <month> November </month> <year> 1992. </year>
Reference-contexts: This brings us to the approach most prevalent in the literature, namely to develop call admission policies that approximately provide statistical guarantees. Two approaches have been 17 taken in this direction. The first is to develop heuristic models for estimating the tails of delay distributions <ref> [15, 28] </ref>. The latter approach actually measures current network behavior and uses this to parameterize the model. <p> This is an area worth investigating. Another area worth investigating is the application of some of the approximate guarantee techniques developed for delays <ref> [28] </ref> to the problem of packet loss. Another fruitful area of research is that of either developing call admission algorithms based on interval QOS metrics or trelating such metrics more closely to stationary metrics such as Q2 and Q4 so as to use existing approaches for dealing with interval metrics.
Reference: [29] <author> C.R. Kalmanek, H. Kanakia, and S. Keshav. </author> <title> Rate controlled servers for very high-speed networks. </title> <booktitle> In Globecom'90, </booktitle> <month> December </month> <year> 1990. </year>
Reference-contexts: In particular, best effort packets can use slots that would normally go idle. Last, This policy is easy to implement. See <ref> [29] </ref> for further details on its implementation and performance. Stop and Go Queueing (SG): This policy is similar to HRR with one important distinction. In addition to associating a frame to the outgoing link, a frame of the same length is also associated with each incoming link.
Reference: [30] <author> Gunnar Karlsson and Martin Vetterli. </author> <title> Packet video and its integration into the network architecture. </title> <journal> IEEE J.Select.Areas Commun., </journal> <volume> 7(5) </volume> <pages> 739-751, </pages> <month> June </month> <year> 1989. </year>
Reference-contexts: Although, these are the QOS metrics typically considered in the literature on provision of QOS, they may not be the most appropriate metrics, <ref> [39, 40, 6, 43, 30, 5, 37] </ref>. For example, consider the requirement that packet loss not exceed 1% for a voice application. <p> Thus a number of papers propose QOS requirements based on intervals of time, e.g., 1% loss over a talkspurt in audio applications [40, 6], over a frame in video <ref> [43, 30, 5, 37] </ref>. Recent work [36] indicates that replacing interval QOS measures with stationary QOS measures can produce very poor results if, in fact interval measures are of interest. There has been little work performed to include these types of metrics as part of call admission algorithms.
Reference: [31] <author> F. P. Kelly. </author> <title> Effective bandwidths at multi-class queues. </title> <journal> QUESTA, </journal> <volume> 9 </volume> <pages> 5-16, </pages> <year> 1991. </year>
Reference-contexts: Last, the work of Guerin, et al., which first proposed and developed the theory of effective bandwidths through simple heuristic arguments has been placed on a solid mathematical basis by several recent papers, <ref> [17, 14, 31] </ref>. This work has resulted in two types of results. The first is the derivation of the effective bandwidth of a single source for a large class of queueing systems and traffic models.
Reference: [32] <author> S. Keshav. </author> <title> On the efficient implementation of fair queueing. </title> <journal> Internetworking:Research and Experience, </journal> <volume> 2 </volume> <pages> 157-173. </pages>
Reference: [33] <author> Jim Kurose. </author> <title> On computing per-session performance bounds in high-speed multi-hop com puter networks. </title> <booktitle> In ACM SIGMETRICS'92, </booktitle> <pages> pages 128-139, </pages> <month> June </month> <year> 1992. </year> <month> 25 </month>
Reference-contexts: These include 16 * provable guarantees, * and approximate guarantees. The first approach is an extension of the work of Cruz for bounding maximum end-to-end delay to bounding the tail of the end-to-end delay distribution. Kurose <ref> [33] </ref> provides tail bounds for the same network as Cruz under the assumption that busy periods at each node are finite and bounded in duration. Inherent in the model is the asumption that sources are described by LBAP's.
Reference: [34] <author> Z. Liu and D. Towsley. </author> <title> Burst reduction properties of the token bank in ATM networks. </title> <booktitle> In IFIP workshop on modeling and performance evaluation of ATM technology. </booktitle>
Reference-contexts: More recent work has focussed on formally stating and proving a number of burst reduction properties exhibited by this mechanism. These include burstiness exhibited by the departure process, or by its effects on delays and/or losses at downstream queues <ref> [35, 34] </ref>. 5 Link Scheduling Policies In a high speed network setting, link scheduling policies must allow different classes of applica tions having different quality of service requirements to share a link.
Reference: [35] <author> Zhen Liu and Don Towsley. </author> <title> Burst reduction properties of rate-control throttles:departure process. </title> <note> To Appear in Annals of Operations Research. </note>
Reference-contexts: More recent work has focussed on formally stating and proving a number of burst reduction properties exhibited by this mechanism. These include burstiness exhibited by the departure process, or by its effects on delays and/or losses at downstream queues <ref> [35, 34] </ref>. 5 Link Scheduling Policies In a high speed network setting, link scheduling policies must allow different classes of applica tions having different quality of service requirements to share a link.
Reference: [36] <author> Ramesh Nagarajan. </author> <title> Quality-of-service issues in high-speed networks. </title> <type> PhD thesis, </type> <institution> Univer sity of Massachusetts, Amherst, </institution> <year> 1993. </year>
Reference-contexts: Thus a number of papers propose QOS requirements based on intervals of time, e.g., 1% loss over a talkspurt in audio applications [40, 6], over a frame in video [43, 30, 5, 37]. Recent work <ref> [36] </ref> indicates that replacing interval QOS measures with stationary QOS measures can produce very poor results if, in fact interval measures are of interest. There has been little work performed to include these types of metrics as part of call admission algorithms. <p> Although several proposed call admission algorithms require the allocation of end-to-end QOS requirements to nodal requirements, e.g., [15, 22], the problem has not been thoroughly addressed. One exception is the work of Nagarajan <ref> [36] </ref> which compares an optimal allocation to the simple heuristic of equal allocation. This study shows that, if the QOS requirement is low loss, then little is gained in using the optimal allocation over the equal allocation.
Reference: [37] <author> Pramod Pancha and Magda El Zarki. </author> <title> Bandwidth requirements of variable bit rate MPEG sources in ATM networks. </title> <booktitle> In IFIP workshop on modeling and performance evaluation of ATM technology, </booktitle> <pages> pages 5.2.1-5.2.25, </pages> <month> January </month> <year> 1993. </year>
Reference-contexts: Although, these are the QOS metrics typically considered in the literature on provision of QOS, they may not be the most appropriate metrics, <ref> [39, 40, 6, 43, 30, 5, 37] </ref>. For example, consider the requirement that packet loss not exceed 1% for a voice application. <p> Thus a number of papers propose QOS requirements based on intervals of time, e.g., 1% loss over a talkspurt in audio applications [40, 6], over a frame in video <ref> [43, 30, 5, 37] </ref>. Recent work [36] indicates that replacing interval QOS measures with stationary QOS measures can produce very poor results if, in fact interval measures are of interest. There has been little work performed to include these types of metrics as part of call admission algorithms.
Reference: [38] <author> Abhay Parekh and Robert Gallager. </author> <title> A generalized processor sharing approach to flow control in integrated services networks the single node case. </title> <booktitle> In INFOCOM'92, </booktitle> <pages> pages 915-924, </pages> <year> 1992. </year>
Reference-contexts: However, it has recently been shown that, if a source is a (; ) LBAP, it is possible to choose values for so that the maximum delay at the server is bounded <ref> [38] </ref>. In particular, if i = i , then T i i It is unnecessary for other sessions to behave as LBAP's. Thus this policy can be used to share the server among applications requiring hard real time guarantees, statistical guarantees, and no guarantees.
Reference: [39] <author> V. Ramaswamy. </author> <title> Traffic performance modeling for packet communication whence, where and wither. </title> <booktitle> In Third Australian Teletraffic Seminar, </booktitle> <month> November </month> <year> 1988. </year> <title> Keynote Address. </title>
Reference-contexts: Although, these are the QOS metrics typically considered in the literature on provision of QOS, they may not be the most appropriate metrics, <ref> [39, 40, 6, 43, 30, 5, 37] </ref>. For example, consider the requirement that packet loss not exceed 1% for a voice application.
Reference: [40] <author> V. Ramaswamy and Walter Willinger. </author> <title> Efficient traffic performance strategies for packet multiplexers. </title> <journal> Computer Networks and ISDN systems, </journal> <volume> 20 </volume> <pages> 401-407, </pages> <year> 1990. </year>
Reference-contexts: Although, these are the QOS metrics typically considered in the literature on provision of QOS, they may not be the most appropriate metrics, <ref> [39, 40, 6, 43, 30, 5, 37] </ref>. For example, consider the requirement that packet loss not exceed 1% for a voice application. <p> Thus a number of papers propose QOS requirements based on intervals of time, e.g., 1% loss over a talkspurt in audio applications <ref> [40, 6] </ref>, over a frame in video [43, 30, 5, 37]. Recent work [36] indicates that replacing interval QOS measures with stationary QOS measures can produce very poor results if, in fact interval measures are of interest.
Reference: [41] <author> J.-F. Ren, J.W. Mark, and J.W. Wong. </author> <title> Performance analysis of a leaky-bucket controlled ATM multiplexer. To Appear in Performance Evaluation. </title>
Reference-contexts: Before ending this section, we mention that the leaky bucket has been the subject of many studies. Most have focussed on evaluating its performance, either in isolation, e.g., [44], or feeding one or more downstream queues, e.g., <ref> [41] </ref>. More recent work has focussed on formally stating and proving a number of burst reduction properties exhibited by this mechanism.
Reference: [42] <author> H. Saito. </author> <title> Call admission control in an ATM network using upper bound of cell loss proba bility. </title> <journal> IEEE Transactions on Communications, </journal> <volume> 40(9) </volume> <pages> 1512-1521, </pages> <month> September </month> <year> 1992. </year>
Reference-contexts: Hence, the event T &gt; D corresponds to the event of a packet that is lost due to buffer overflow in this case. Unlike deadlines, there is no general method for obtaining provable bounds on packet loss probabilities except in the case of a single link. Saito <ref> [42] </ref> provides bounds on cell loss probabi lities for an ATM switch using a FIFO scheduler. The bounds require the average rate and the peak rate for each source over an interval of length K=2 where K is the buffer capacity.
Reference: [43] <author> Nachum Shacham. </author> <title> Packet recovery in high-speed networks using coding and buffer mana gement. </title> <booktitle> In INFOCOM, </booktitle> <pages> pages 124-131, </pages> <year> 1990. </year>
Reference-contexts: Although, these are the QOS metrics typically considered in the literature on provision of QOS, they may not be the most appropriate metrics, <ref> [39, 40, 6, 43, 30, 5, 37] </ref>. For example, consider the requirement that packet loss not exceed 1% for a voice application. <p> Thus a number of papers propose QOS requirements based on intervals of time, e.g., 1% loss over a talkspurt in audio applications [40, 6], over a frame in video <ref> [43, 30, 5, 37] </ref>. Recent work [36] indicates that replacing interval QOS measures with stationary QOS measures can produce very poor results if, in fact interval measures are of interest. There has been little work performed to include these types of metrics as part of call admission algorithms.
Reference: [44] <author> M. Sidi, W. Liu, I.Cidon, and I. Gopal. </author> <title> Congestion control through input rate regulation. </title> <booktitle> In GLOBECOM'89. </booktitle>
Reference-contexts: In that case the peak rate parameter will be omitted, e.g., (; ) LBAP instead of (; ; 1) LBAP. Before ending this section, we mention that the leaky bucket has been the subject of many studies. Most have focussed on evaluating its performance, either in isolation, e.g., <ref> [44] </ref>, or feeding one or more downstream queues, e.g., [41]. More recent work has focussed on formally stating and proving a number of burst reduction properties exhibited by this mechanism.
Reference: [45] <author> D. Towsley and F. Baccelli. </author> <title> Comparisons of service disciplines in a tandem queueing network with real-time constraints. </title> <journal> OR Letters, </journal> <volume> 10. </volume>
Reference-contexts: This is due to several reasons. First, it is extremely easy to implement. Second, it exhibits a number of important properties. For example, it is known to minimize the variance in the delay through a node and, in certain cases, the end-to-end delays through a tandem network <ref> [45] </ref>. It is also known to stochastically minimize the maximum end-to-end delay. These two features make it the policy of choice within a session and an option to consider for scheduling packets from different sessions belonging to the same class of service.
Reference: [46] <author> J. Turner. </author> <title> New directions in communications (or which way to the information age). </title> <journal> IEEE Communications Magazine, </journal> <volume> 24 </volume> <pages> 8-15, </pages> <year> 1986. </year>
Reference-contexts: An example of such a mechanism is the leaky bucket <ref> [46] </ref>. Further details are found in section 4. A second reason for monitoring the traffic of a connection would be to provide adaptivity. If the traffic characteristics of a connection change, then the network could note these changes and make use of them when setting up additional calls. <p> Traffic shaping mechanisms come in many different flavors. However, they are mostly variations of the leaky bucket rate control mechanism originally proposed by Turner, <ref> [46] </ref>. We briefly describe one variation which is used by a number of different proposed bandwidth allocation policies. Briefly, a leaky bucket consists of a data buffer and a finite capacity token buffer. Packets enter the data buffer from the source.
Reference: [47] <author> J.S. Turner. </author> <title> Managing bandwidth in ATM networks with bursty traffic. </title> <journal> IEEE Network, </journal> <volume> 6(5) </volume> <pages> 50-59, </pages> <month> September </month> <year> 1992. </year> <month> 26 </month>
Reference-contexts: If the buffer size is much smaller than the burst size, then the only solution may be to perform fast circuit switching at a burst level. An example of this approach is found in <ref> [47] </ref>. 5 4 Traffic Shaping and Monitoring As we have observed in section 3, a traffic shaping mechanism may be necessary to ensure that a source behaves according to the characterization that it provides the network at the time that it establishes its session.
Reference: [48] <author> Dinesh Verma, Hui Zhang, and Domenico Ferrari. </author> <title> Delay jitter control for real-time com munication in a packet switching network. </title> <booktitle> In IEEE Tricomm'91, </booktitle> <month> April </month> <year> 1991. </year>
Reference-contexts: It is also a component of the MARS approach [27]. A problem inherent in FIFO and EDD is that end-to-end jitter tends to grow as a function of the path length in networks. As a consequence, Verma and Ferrari <ref> [48] </ref> proposed an idling version of EDD, Jitter-EDD (J-EDD) which has the provable property that end to end jitter never exceeds that for a single node, regardless of path length. <p> Examples of such calculations along with their computaional costs can be found in <ref> [15, 48] </ref>. Let d k denote this minimum local deadline at node j k .
Reference: [49] <author> G.M. Woodruff and R. Kositpaiboon. </author> <title> Multimedia traffic management principles for gua ranteed ATM network performance. </title> <journal> IEEE J.Select.Areas Commun., </journal> <volume> 8. </volume>
Reference-contexts: We shall refer to the former as the principle of connection isolation and will examine approaches based on both as well as a hybrid. The reader is referred to <ref> [49] </ref> for further design principles for call admission algorithms. In order to answer "the question", a connection must provide workload descriptors along with its QOS requirements. The previous section described some proposed descriptors and requirements. A successful call setup corresponds to a contract between the application and network.
Reference: [50] <author> Opher Yaron and Moshe Sidi. </author> <title> Calculating performance bounds in communication networks. </title> <booktitle> In IEEE INFOCOM'93, </booktitle> <pages> pages 539-546, </pages> <month> April </month> <year> 1993. </year>
Reference-contexts: Kurose [33] provides tail bounds for the same network as Cruz under the assumption that busy periods at each node are finite and bounded in duration. Inherent in the model is the asumption that sources are described by LBAP's. Yaron and Sidi <ref> [50] </ref> and Chang [9] consider more general arrival processes for which the peak rate is unbounded and, based on Chernoff's bound, develop bounds on the end-to-end delay distribution.
Reference: [51] <editor> David Yates et al. </editor> <title> On per-session end-to-end delay and the call admission problem for real-time applications with qos requirements. </title> <note> To appear in SIGCOMM'93. 27 </note>
Reference-contexts: However, there is considerable evidence that such an approach will result in extremely poor performance, i.e., the number of sessions permitted to use the network will be considerably lower than necessary. We illustrate this with an example taken from <ref> [51] </ref>. The network has been configured so that each communication link carries 48 32Kbs voice calls where each voice call generates a packet every 16ms during a talkspurt.
References-found: 51

