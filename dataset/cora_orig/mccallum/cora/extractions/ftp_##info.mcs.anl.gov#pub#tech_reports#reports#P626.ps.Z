URL: ftp://info.mcs.anl.gov/pub/tech_reports/reports/P626.ps.Z
Refering-URL: http://www.mcs.anl.gov/adic/
Root-URL: http://www.mcs.anl.gov
Email: fbischof,rohg@mcs.anl.gov  mauer@math.uiuc.edu  
Title: ADIC: An Extensible Automatic Differentiation Tool for ANSI-C  
Author: Christian Bischof and Lucas Roh Andrew Mauer-Oats 
Date: (revised May 1997)  
Note: Argonne Preprint ANL/MCS-P626-1196  To appear in Software: Practice and Experience This work was supported by the Mathematical, Information, and Computational Sciences Division subprogram of the Office of Computational and Technology Research, U.S. Department of Energy, under Contract W-31-109-Eng-38, by the National Aerospace Agency under Purchase Orders L25935D and L64948D, and by the National Science Foundation, through the Center for Research on Parallel Computation, under Cooperative Agreement No. CCR-9120008. The work of this author was performed while he was a student research associate with  
Address: Argonne, IL 60439 USA  Urbana, IL 61802  
Affiliation: Mathematics and Computer Science Division Argonne National Laboratory  Department of Mathematics University of Illinois at Urbana-Champaign  Argonne National Laboratory.  
Abstract-found: 0
Intro-found: 1
Reference: [1] <institution> Proceedings of the 5th AIAA/NASA/USAF/ISSMO Symposium on Multidisciplinary Analysis and Optimization, Panama City, Florida, American Association of Aeronautics and Aerospace Engineers, </institution> <year> 1994. </year>
Reference-contexts: Derivatives are also essential in other areas of nonlinear modeling, for example in nonlinear equation solving and design optimization <ref> [1, 4, 26] </ref>. In general, given a code C that computes a function f : x 2 R n 7! y 2 R m with n inputs and m outputs, we may then require the derivatives of some of the outputs y with respect to some of the inputs x.
Reference: [2] <author> Jason Abate, Christian Bischof, Alan Carle, and Lucas Roh. </author> <title> Algorithms and design for a second-order automatic differentiation module. </title> <type> Preprint ANL/MCS-636-0197, </type> <institution> Mathematics and Computer Science Division, Argonne National Laboratory, </institution> <year> 1997. </year> <note> To appear in Proc. Int. Symposium on Symbolic and Algebraic Computing (ISSAC) '97. </note>
Reference-contexts: f fl r x b; (1) and a familiar incarnation is the product rule g = a fl b ) r x g = b fl r x a + a fl r x b: (2) Note that this approach can easily be generalized to compute derivatives of arbitrary order <ref> [2, 7, 15] </ref>. The chain rule is associative. <p> Generally, the larger the code fragment, the more sophisticated the AD algorithms that are potentially applicable. The mechanism just described is used by ADIC to perform the derivative augmentation. We have built a gradient module for first-order derivatives, and we are working on a hessian module for second-order derivatives <ref> [2] </ref>. These modules process one statement fragment at a time. Each derivative module is a separate executable program that communicates with the host via files. <p> In fact, a given module may perform context-sensitive transformations rather than the same transformation algorithm to every statement, but the change of algorithms is transparent to the surrounding tool layers (see, for example, <ref> [2] </ref>). To assist developers in writing AIF modules, we have created a toolkit that provides a library of C++ classes insulating the developer from various interfacing issues and provides the AST node definitions, the attribute mechanism, and a set of tree manipulation routines in additon to various utilities.
Reference: [3] <author> Frederick A. Adkins and Edward J. Haug. </author> <title> Operational envelope of a Spatial stewart platform. </title> <note> To appear as Technical Brief in ASME J. </note> <institution> of Mechanical Design, </institution> <month> May </month> <year> 1996. </year>
Reference-contexts: In the context of such work, we were presented with a model for the so-called Stewart platform (the model derivation is described in <ref> [3] </ref>). The Stewart platform consisted of 763 lines of code and the unmodified code took 1.7 seconds to complete.
Reference: [4] <editor> N. Alexandrow and M. Hussaini, editors. </editor> <title> Multidisciplinary Design Optimization. </title> <publisher> SIAM, </publisher> <address> Philadelphia, </address> <year> 1997. </year>
Reference-contexts: Derivatives are also essential in other areas of nonlinear modeling, for example in nonlinear equation solving and design optimization <ref> [1, 4, 26] </ref>. In general, given a code C that computes a function f : x 2 R n 7! y 2 R m with n inputs and m outputs, we may then require the derivatives of some of the outputs y with respect to some of the inputs x.
Reference: [5] <author> M. Bartholomew-Biggs. </author> <title> OPFAD a users guide to the OPtima Forward Automatic Differentiation tool. </title> <type> Technical report, </type> <institution> Numerical Optimization Centre, University of Hertfordsshire, </institution> <year> 1995. </year> <month> 35 </month>
Reference-contexts: In addition, some overhead is associated with the operator overloading itself. Examples of this approach are ADOL-C [34], ADOL-F [49], ADO1 [45], FADBAD [6], and OPTIMA <ref> [5, 24] </ref>. Source-to-source transformation: This approach employs compiler techniques to transform a program source code into a new source code that explicitly carries out the derivative computation; hence, it is applicable to any language.
Reference: [6] <author> Claus Bendtsen and Ole Stauning. FADBAD, </author> <title> A Flexible C++ Package for Auto--matic Differentiation, Using the Forward and Backward Methods. </title> <type> Technical Report IMM-REP-1996-17, </type> <institution> Department of Mathematical Modelling, Technical University of Denmark, </institution> <month> August </month> <year> 1996. </year>
Reference-contexts: In addition, some overhead is associated with the operator overloading itself. Examples of this approach are ADOL-C [34], ADOL-F [49], ADO1 [45], FADBAD <ref> [6] </ref>, and OPTIMA [5, 24]. Source-to-source transformation: This approach employs compiler techniques to transform a program source code into a new source code that explicitly carries out the derivative computation; hence, it is applicable to any language.
Reference: [7] <author> M. Berz. </author> <title> High-Order Computation and Normal Form Analysis of Repetitive Systems, </title> <type> volume AIP 249, </type> <institution> page 456. American Institute of Physics, </institution> <address> Woodbury, NY, </address> <year> 1991. </year>
Reference-contexts: f fl r x b; (1) and a familiar incarnation is the product rule g = a fl b ) r x g = b fl r x a + a fl r x b: (2) Note that this approach can easily be generalized to compute derivatives of arbitrary order <ref> [2, 7, 15] </ref>. The chain rule is associative.
Reference: [8] <author> Martin Berz, Christian Bischof, George Corliss, and Andreas Griewank. </author> <title> Computational Differentiation: Techniques, Applications, and Tools. </title> <publisher> SIAM, </publisher> <address> Philadelphia, </address> <year> 1996. </year>
Reference-contexts: Also, if C changes, which is often the case during code development, an up-to-date C 0 is produced by simply rerunning the tools. An overview of currently available AD tools can be found at http://www.mcs.anl.gov/Projects/autodiff/AD Tools, as well as in the articles in <ref> [8] </ref>. AD technology is still in its infancy; the development of better algorithms for exploiting chain rule associativity and their incorporation into AD tools promise significant improvement in the performance of generated derivative codes.
Reference: [9] <author> Christian Bischof. </author> <title> Automatic differentiation and numerical software design. </title> <editor> In Ronald Boisvert, editor, </editor> <booktitle> The Quality of Numerical Software: Assessment and Enhancement, </booktitle> <pages> pages 287-299, </pages> <address> London, 1997. </address> <publisher> Chapman & Hall. </publisher>
Reference-contexts: These functions are part of an ANSI-C instantiation of the ADIntrinsics subsystem [13]. While most of the time the evaluation of an intrinsic at a point of nondifferentiability does not compromise the overall result, subtle issues may arise whose satisfactory solution does depend on the particular application context <ref> [9, 14] </ref>. 2.2 The ADIC Process In this subsection, we explain in more detail how the ADIC process relates to the generic anatomy of an AD tool briefly outlined in subsection 1.3. The automatic differentiation process with ADIC is shown in Figure 8.
Reference: [10] <author> Christian Bischof, Ali Bouaricha, Peyvand Khademi, and Jorge More. </author> <title> Computing gradients in large-scale optimization using automatic differentiation. </title> <type> Preprint MCS-P488-0195, </type> <institution> Mathematics and Computer Science Division, Argonne National Laboratory, </institution> <year> 1995. </year> <note> To appear in INFORMS Journal of Computing. </note>
Reference-contexts: In this case, SparsLinC provides a much more suitable implementation than the dense loops shown in Figures 6 and 7. SparsLinC, which is written in ANSI-C, was originally developed in the context of the ADIFOR project and has been successfully employed in large-scale nonlinear modeling <ref> [10, 16, 21, 18] </ref>.
Reference: [11] <author> Christian Bischof, Alan Carle, George Corliss, Andreas Griewank, and Paul Hovland. ADIFOR: </author> <title> Generating derivative codes from Fortran programs. </title> <journal> Scientific Programming, </journal> <volume> 1(1) </volume> <pages> 11-29, </pages> <year> 1992. </year>
Reference-contexts: In addition, the computation of n partial derivatives requires n + 1 function evaluations. Recently, automatic differentiation (AD) has been gaining popularity with the emergence of software tools such as ADIFOR <ref> [11, 12] </ref>, ODYSSEE [48], or ADOL-C [34]. Given a code C, these tools can automatically produce an accurate and reasonably fast derivative code C 0 . <p> The advantages of this approach are that the entire program context is available at compile time to exploit chain rule associativity and to gather information that could tighten conservative assumptions underlying AD algorithms. The disadvantage is the major effort required in implementing such a tool. ADIC, ADIFOR <ref> [11, 12] </ref>, ODYSSEE [48], and TAMC [29] are examples of this approach. 1.3 What's New in ADIC Our goal was to build an efficient AD tool for ANSI-C geared primarily toward the computation of first- and second-order derivatives. <p> Derivative Code Generation. Conceptually, the strategy for computing first-order derivatives as shown is the same one that currently underlies ADIFOR <ref> [11, 12] </ref> and thus allows the same flexibility with respect to "derivative seeding" to compute selected derivatives, chain derivatives, or exploit derivative sparsity that is described in these references. <p> Writing and Linking the Driver. The user provides a driver that specifies, at runtime, the input variables with respect to which derivatives actually need to be computed. In fact, with proper initialization, we can compute directional derivatives (this process is termed "derivative seeding;" see <ref> [11, 12] </ref>). We show a simple driver for func.ad.c (from Figures 3 and 4) in Figure 9. Variables that used to be of type double are now declared to be of type DERIV TYPE, and their values are referred to via the DERIV val macro. <p> If x and y are aliases of each other, we also alias g x and g y. Such an approach is taken by ADIFOR <ref> [11, 12] </ref>. This approach is generally not feasible for C, however, because of the unrestricted use of pointers. Nevertheless, since an lvalue expression evaluates to a unique address, we can use the address as the basis of an association scheme.
Reference: [12] <author> Christian Bischof, Alan Carle, Peyvand Khademi, and Andrew Mauer. ADIFOR 2.0: </author> <title> Automatic differentiation of Fortran 77 programs. </title> <journal> IEEE Computational Science & Engineering, </journal> <volume> 3(3) </volume> <pages> 18-32, </pages> <year> 1996. </year>
Reference-contexts: In addition, the computation of n partial derivatives requires n + 1 function evaluations. Recently, automatic differentiation (AD) has been gaining popularity with the emergence of software tools such as ADIFOR <ref> [11, 12] </ref>, ODYSSEE [48], or ADOL-C [34]. Given a code C, these tools can automatically produce an accurate and reasonably fast derivative code C 0 . <p> This approach works with languages that support operator overloading such as C++ or Fortran 90. z Despite the elegance of this approach, its major disadvantage is the inability to exploit chain rule associativity because of the lack of context inherent in operator overloading <ref> [12, 19] </ref>. In addition, some overhead is associated with the operator overloading itself. Examples of this approach are ADOL-C [34], ADOL-F [49], ADO1 [45], FADBAD [6], and OPTIMA [5, 24]. <p> The advantages of this approach are that the entire program context is available at compile time to exploit chain rule associativity and to gather information that could tighten conservative assumptions underlying AD algorithms. The disadvantage is the major effort required in implementing such a tool. ADIC, ADIFOR <ref> [11, 12] </ref>, ODYSSEE [48], and TAMC [29] are examples of this approach. 1.3 What's New in ADIC Our goal was to build an efficient AD tool for ANSI-C geared primarily toward the computation of first- and second-order derivatives. <p> Derivative Code Generation. Conceptually, the strategy for computing first-order derivatives as shown is the same one that currently underlies ADIFOR <ref> [11, 12] </ref> and thus allows the same flexibility with respect to "derivative seeding" to compute selected derivatives, chain derivatives, or exploit derivative sparsity that is described in these references. <p> Writing and Linking the Driver. The user provides a driver that specifies, at runtime, the input variables with respect to which derivatives actually need to be computed. In fact, with proper initialization, we can compute directional derivatives (this process is termed "derivative seeding;" see <ref> [11, 12] </ref>). We show a simple driver for func.ad.c (from Figures 3 and 4) in Figure 9. Variables that used to be of type double are now declared to be of type DERIV TYPE, and their values are referred to via the DERIV val macro. <p> If x and y are aliases of each other, we also alias g x and g y. Such an approach is taken by ADIFOR <ref> [11, 12] </ref>. This approach is generally not feasible for C, however, because of the unrestricted use of pointers. Nevertheless, since an lvalue expression evaluates to a unique address, we can use the address as the basis of an association scheme. <p> Automatic differentiation tools also offer promising avenues for the application of research typically done in the compiler and runtime system communities, for instance, in flow analysis and performance prediction. As mentioned, for example, in <ref> [12, 21] </ref>, AD provides ample opportunities for exploiting parallelism, from threads in shared-memory programming models (e.g., [41]) to the typically coarser-grained communication paradigms (e.g., MPI [37]) used in distributed-memory paradigms.
Reference: [13] <author> Christian Bischof, Alan Carle, Peyvand Khademi, Andrew Mauer, and Paul Hovland. </author> <title> ADIFOR 2.0 user's guide (Revision C). </title> <type> Technical Memorandum ANL/MCS-TM-192, </type> <institution> Mathematics and Computer Science Division, Argonne National Laboratory, </institution> <year> 1995. </year> <note> (also CRPC Technical Report CRPC-95516-S). </note>
Reference-contexts: The latter function also provides a reasonable default value for the local partial derivatives (e.g., ad adji 0) so that the execution can proceed. These functions are part of an ANSI-C instantiation of the ADIntrinsics subsystem <ref> [13] </ref>.
Reference: [14] <author> Christian Bischof, George Corliss, and Andreas Griewank. </author> <title> ADIFOR exception handling. </title> <type> Technical Report ANL/MCS-TM-159, </type> <institution> Mathematics and Computer Science Division, Argonne National Laboratory, </institution> <year> 1991. </year>
Reference-contexts: These functions are part of an ANSI-C instantiation of the ADIntrinsics subsystem [13]. While most of the time the evaluation of an intrinsic at a point of nondifferentiability does not compromise the overall result, subtle issues may arise whose satisfactory solution does depend on the particular application context <ref> [9, 14] </ref>. 2.2 The ADIC Process In this subsection, we explain in more detail how the ADIC process relates to the generic anatomy of an AD tool briefly outlined in subsection 1.3. The automatic differentiation process with ADIC is shown in Figure 8.
Reference: [15] <author> Christian Bischof, George Corliss, and Andreas Griewank. </author> <title> Structured second- and higher-order derivatives through univariate Taylor series. </title> <journal> Optimization Methods and Software, </journal> <volume> 2 </volume> <pages> 211-232, </pages> <year> 1993. </year>
Reference-contexts: f fl r x b; (1) and a familiar incarnation is the product rule g = a fl b ) r x g = b fl r x a + a fl r x b: (2) Note that this approach can easily be generalized to compute derivatives of arbitrary order <ref> [2, 7, 15] </ref>. The chain rule is associative.
Reference: [16] <author> Christian Bischof, Peyvand Khademi, Ali Bouaricha, and Alan Carle. </author> <title> Efficient computation of gradients and Jacobians by transparent exploitation of sparsity in automatic differentiation. </title> <journal> Optimization Methods and Software, </journal> <volume> 7(1) </volume> <pages> 1-39, </pages> <month> July </month> <year> 1996. </year> <month> 36 </month>
Reference-contexts: In this case, SparsLinC provides a much more suitable implementation than the dense loops shown in Figures 6 and 7. SparsLinC, which is written in ANSI-C, was originally developed in the context of the ADIFOR project and has been successfully employed in large-scale nonlinear modeling <ref> [10, 16, 21, 18] </ref>.
Reference: [17] <author> Christian Bischof and Lucas Roh. </author> <title> ADIC user guide. </title> <type> Technical Memorandum ANL/MCS-TM-225, </type> <institution> Mathematics and Computer Science Division, Argonne National Laboratory, </institution> <year> 1997. </year>
Reference-contexts: For more details, see <ref> [17] </ref>. Transforming Using ADIC. The ADIC translator generates the derivative code from the code submitted by the user and consists of four components: * Preprocessor: The preprocessor processes the C preprocessor directives and expands macros embedded in the source code. <p> ADIC allows the user to specify macros that should not be expanded through its control file mechanism. This facility can also be used to handle function-like macros and type definitions. These preprocessor issues are discussed in more detail in <ref> [17] </ref>. 4 AIF The Automatic Differentiation Intermediate Form The preceding sections discussed how to prepare an ANSI-C code for derivative augmentation. In this section, we discuss the mechanism for achieving this augmentation. As mentioned previously, automatic differentiation is a field in its infancy.
Reference: [18] <author> Christian Bischof and Po-Ting Wu. </author> <title> Time-parallel computation of pseudo-adjoints for a leapfrog scheme. </title> <type> Preprint ANL/MCS-P639-0197, </type> <institution> Mathematics and Computer Science Division, Argonne National Laboratory, </institution> <year> 1997. </year>
Reference-contexts: The development of heuristics to exploit algorithmic and program structure, and hence to better exploit chain rule associativity, is the subject of current research (see, for example, <ref> [18, 19, 21, 27, 33, 36] </ref>). 1.2 Implementation Strategies for Automatic Differentiation Tools Unlike compilers or most program transformation systems, AD tools modify the semantics of the underlying program by inserting, in a rule-based fashion, code for computing derivatives. <p> In this case, SparsLinC provides a much more suitable implementation than the dense loops shown in Figures 6 and 7. SparsLinC, which is written in ANSI-C, was originally developed in the context of the ADIFOR project and has been successfully employed in large-scale nonlinear modeling <ref> [10, 16, 21, 18] </ref>.
Reference: [19] <author> Christian H. Bischof and Mohammad R. Haghighat. </author> <title> On hierarchical differentiation. </title> <editor> In Martin Berz, Christian Bischof, George Corliss, and Andreas Griewank, editors, </editor> <title> Computational Differentiation: Techniques, </title> <booktitle> Applications, and Tools, </booktitle> <pages> pages 83-94. </pages> <publisher> SIAM, </publisher> <address> Philadelphia, </address> <year> 1996. </year>
Reference-contexts: The development of heuristics to exploit algorithmic and program structure, and hence to better exploit chain rule associativity, is the subject of current research (see, for example, <ref> [18, 19, 21, 27, 33, 36] </ref>). 1.2 Implementation Strategies for Automatic Differentiation Tools Unlike compilers or most program transformation systems, AD tools modify the semantics of the underlying program by inserting, in a rule-based fashion, code for computing derivatives. <p> This approach works with languages that support operator overloading such as C++ or Fortran 90. z Despite the elegance of this approach, its major disadvantage is the inability to exploit chain rule associativity because of the lack of context inherent in operator overloading <ref> [12, 19] </ref>. In addition, some overhead is associated with the operator overloading itself. Examples of this approach are ADOL-C [34], ADOL-F [49], ADO1 [45], FADBAD [6], and OPTIMA [5, 24]. <p> However, as shown in <ref> [19, 21, 38] </ref>, considerable improvements can be obtained by varying strategies at lower levels within a code. To enable this, we identify code fragments that can be mapped to the simple language underlying the AIF abstraction.
Reference: [20] <author> Christian H. Bischof, William T. Jones, Andrew Mauer, and Jamshid Samareh. </author> <title> Experiences with the application of the ADIC automatic differentiation tool to the CSCMDO 3-D volume grid generation code. </title> <booktitle> In Proceedings of the 34th AIAA Aerospace Sciences Meeting, </booktitle> <institution> AIAA Paper 96-0716. American Institute of Aeronautics and Astronomics, </institution> <year> 1996. </year>
Reference-contexts: ADIC (Automatic Differentiation of C) is our AD tool that addresses these design issues. A prototype of ADIC was successfully applied to CSCMDO <ref> [20] </ref>, a 3-D volume grid generator specifically designed for use in multidisciplinary design optimization. The current ADIC has been employed to generate derivative-enhanced versions of semiconductor device simulators, a 3-D motion control simulator, and a neural network model.
Reference: [21] <author> Christian H. Bischof and Po-Ting Wu. </author> <title> Exploiting intermediate sparsity in computing derivatives of a leapfrog scheme. </title> <type> Preprint ANL/MCS-P572-0396, </type> <institution> Mathematics and Computer Science Division, Argonne National Laboratory, </institution> <year> 1996. </year>
Reference-contexts: The development of heuristics to exploit algorithmic and program structure, and hence to better exploit chain rule associativity, is the subject of current research (see, for example, <ref> [18, 19, 21, 27, 33, 36] </ref>). 1.2 Implementation Strategies for Automatic Differentiation Tools Unlike compilers or most program transformation systems, AD tools modify the semantics of the underlying program by inserting, in a rule-based fashion, code for computing derivatives. <p> However, as shown in <ref> [19, 21, 38] </ref>, considerable improvements can be obtained by varying strategies at lower levels within a code. To enable this, we identify code fragments that can be mapped to the simple language underlying the AIF abstraction. <p> In this case, SparsLinC provides a much more suitable implementation than the dense loops shown in Figures 6 and 7. SparsLinC, which is written in ANSI-C, was originally developed in the context of the ADIFOR project and has been successfully employed in large-scale nonlinear modeling <ref> [10, 16, 21, 18] </ref>. <p> Automatic differentiation tools also offer promising avenues for the application of research typically done in the compiler and runtime system communities, for instance, in flow analysis and performance prediction. As mentioned, for example, in <ref> [12, 21] </ref>, AD provides ample opportunities for exploiting parallelism, from threads in shared-memory programming models (e.g., [41]) to the typically coarser-grained communication paradigms (e.g., MPI [37]) used in distributed-memory paradigms.
Reference: [22] <author> Francois Bodin, Peter Beckman, Dennis Gannon, Jacob Goutwals, Srinivas Narayana, Suresh Srinivas, and Beata Winnicka. Sage++: </author> <title> An object-oriented toolkit and class library for building Fortran and C++ restructuring tools. </title> <booktitle> In Proceedings of the Second Annual Object-Oriented Numerics Conference. IEEE, </booktitle> <year> 1994. </year>
Reference-contexts: Another postprocessor that is routinely used is purse-c, a component of the ADIntrinsics system. The ADIC main processor and the AIF modules perform the following functions: * Parsing: The marked-up source files are parsed into an intermediate form. To this end, we employ the Sage++ <ref> [22] </ref> parser. * Canonicalization: At this stage, we canonicalize the intermediate form by addressing ANSI-C-specific issues such as side-effects and pointers. The subtle issues arising in this context are described in Section 3. * Analysis: ADIC currently does not employ data flow or dependence analysis for improving derivative generation.
Reference: [23] <author> H.-J. Boehm. </author> <title> Space efficient conservative garbage collection. </title> <journal> SIGPLAN Notices, </journal> <volume> 28(6) </volume> <pages> 197-206, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: We are developing a mechanism for dealing with potential memory leaks via user directives. In this context, garbage collection mechanisms such as the one described in <ref> [23] </ref> may play a useful role. This approach of redefining double in the derivative code cannot be used, however, in the following circumstances: * We cannot statically determine that a particular memory location will be used to house a double.
Reference: [24] <author> S. Brown. </author> <title> OPRAD a users guide to the OPtima Reverse Automatic Differentiation tool. </title> <type> Technical report, </type> <institution> Numerical Optimization Centre, University of Hertfordsshire, </institution> <year> 1995. </year>
Reference-contexts: In addition, some overhead is associated with the operator overloading itself. Examples of this approach are ADOL-C [34], ADOL-F [49], ADO1 [45], FADBAD [6], and OPTIMA <ref> [5, 24] </ref>. Source-to-source transformation: This approach employs compiler techniques to transform a program source code into a new source code that explicitly carries out the derivative computation; hence, it is applicable to any language.
Reference: [25] <author> K. M. Cham, S.-Y. Oh, D. Chin, J. Moll, K.Lee, and P. V. Voorde. </author> <booktitle> Parasitic Elements Simulation, </booktitle> <pages> pages 129-140. </pages> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, 2nd edition, </address> <year> 1988. </year>
Reference-contexts: time (rf) time (f) 2.4 3.1 4.0 5.2 6.3 7.4 time (CD) time (AD) 1.3 1.6 1.7 1.7 1.7 1.7 Table 1: Timing Results for CSCMDO 5.2 The FCAP2 Circuit Interconnect Simulator The FCAP (Fast Capacitance Extraction) suite of codes has been under development by Hewlett-Packard Laboratory since the 1980's <ref> [25] </ref>. These codes are used in the context of simulating capacitance and thermal properties of devices as well as on-chip/off-chip interconnects. They were also incorporated into the Raphael TM capacitance extraction software that is marketed by TMA (Technology Modeling Associate) Inc. FCAP2 consists of 7,680 lines of ANSI-C code.
Reference: [26] <author> H. Engl and J. McLaughlin. </author> <title> Proceedings of the Symposium on Inverse Problems and Optimal Design in Industry, </title> <publisher> Teubner Verlag, Stuttgart, </publisher> <year> 1994. </year>
Reference-contexts: Derivatives are also essential in other areas of nonlinear modeling, for example in nonlinear equation solving and design optimization <ref> [1, 4, 26] </ref>. In general, given a code C that computes a function f : x 2 R n 7! y 2 R m with n inputs and m outputs, we may then require the derivatives of some of the outputs y with respect to some of the inputs x.
Reference: [27] <author> Christele Faure. </author> <title> Splitting of algebraic expressions for automatic differentiation. </title> <editor> In Martin Berz, Christian Bischof, George Corliss, and Andreas Griewank, editors, </editor> <title> Com 37 putational Differentiation: Techniques, </title> <booktitle> Applications, and Tools, </booktitle> <pages> pages 117-128. </pages> <publisher> SIAM, </publisher> <address> Philadelphia, </address> <year> 1996. </year>
Reference-contexts: The development of heuristics to exploit algorithmic and program structure, and hence to better exploit chain rule associativity, is the subject of current research (see, for example, <ref> [18, 19, 21, 27, 33, 36] </ref>). 1.2 Implementation Strategies for Automatic Differentiation Tools Unlike compilers or most program transformation systems, AD tools modify the semantics of the underlying program by inserting, in a rule-based fashion, code for computing derivatives.
Reference: [28] <author> Daniel P. Friedman and Matthias Felleisen. </author> <title> The Little Schemer. </title> <publisher> MIT Press, </publisher> <address> Cam-bridge, 4th edition, </address> <year> 1996. </year>
Reference-contexts: In our 30 project, the file-based AIF toolkit interface provided considerable stability to developers of transformation tools, even though the AIF representation itself changed several times. We are doubtful that such development stability could have been achieved if a program representation representation had been directly manipulated in Scheme <ref> [28] </ref> or CAML [52]. In summary, AIF allows us to decouple the world of the language-dependent AD fron-tend and the world of the AD transformation developer (which sees a simple, language-independent representation of program fragments).
Reference: [29] <author> Ralf Giering. </author> <title> Tangent linear and adjoint model compiler, users manual. Unpublished Information, </title> <institution> Max-Planck Institut fur Meteorologie, Hamburg, Germany, </institution> <year> 1996. </year>
Reference-contexts: The disadvantage is the major effort required in implementing such a tool. ADIC, ADIFOR [11, 12], ODYSSEE [48], and TAMC <ref> [29] </ref> are examples of this approach. 1.3 What's New in ADIC Our goal was to build an efficient AD tool for ANSI-C geared primarily toward the computation of first- and second-order derivatives.
Reference: [30] <author> Phillip E. Gill, Walter Murray, and Margaret H. Wright. </author> <title> Practical Optimization. </title> <publisher> Academic Press, </publisher> <address> London, </address> <year> 1981. </year>
Reference-contexts: For the simplest case, one-sided differences, the derivative of f with respect to the ith input x i is approximated by @ f x i The main drawback of the divided differences technique is that inherent errors make it difficult to determine the accuracy of the approximation <ref> [30, 44] </ref>. In addition, the computation of n partial derivatives requires n + 1 function evaluations. Recently, automatic differentiation (AD) has been gaining popularity with the emergence of software tools such as ADIFOR [11, 12], ODYSSEE [48], or ADOL-C [34].
Reference: [31] <author> Victor V. Goldman and Gerard Cats. </author> <title> Automatic adjoint modeling within a program generation framework: A case study for a weather forecasting grid-point model. </title> <editor> In Martin Berz, Christian Bischof, George Corliss, and Andreas Griewank, editors, </editor> <title> Computational Differentiation: Techniques, </title> <booktitle> Applications, and Tools, </booktitle> <pages> pages 185-194. </pages> <publisher> SIAM, </publisher> <address> Philadelphia, </address> <year> 1996. </year>
Reference-contexts: C 0 can also be developed with the help of a symbolic mathematics package such as Mathematica, Maple, or Reduce. While this approach works well for domain-specific languages (see, e.g., <ref> [31, 42] </ref>), it is not directly applicable to large computer codes in languages such as Fortran 77 or C. Another alternative, divided differences, does not directly produce a derivative code but rather approximates the derivatives by evaluating f at multiple input points.
Reference: [32] <author> Andreas Griewank. </author> <title> On automatic differentiation. </title> <booktitle> In Mathematical Programming: Recent Developments and Applications, </booktitle> <pages> pages 83-108, </pages> <address> Amsterdam, 1989. </address> <publisher> Kluwer Academic Publishers. </publisher>
Reference-contexts: The reverse mode requires a reversal of the order of the original program execution, but is attractive when one desires the computation of the derivatives of few output values with respect to many input values. These issues are discussed in more detail in <ref> [32, 35, 46] </ref>. For general problems, the choice of a good strategy depends on the time and memory constraints as well as the particular program structure.
Reference: [33] <author> Andreas Griewank. </author> <title> Achieving logarithmic growth of temporal and spatial complexity in reverse automatic differentiation. </title> <journal> Optimization Methods and Software, </journal> <volume> 1(1) </volume> <pages> 35-54, </pages> <year> 1992. </year>
Reference-contexts: The development of heuristics to exploit algorithmic and program structure, and hence to better exploit chain rule associativity, is the subject of current research (see, for example, <ref> [18, 19, 21, 27, 33, 36] </ref>). 1.2 Implementation Strategies for Automatic Differentiation Tools Unlike compilers or most program transformation systems, AD tools modify the semantics of the underlying program by inserting, in a rule-based fashion, code for computing derivatives.
Reference: [34] <author> Andreas Griewank, David Juedes, and Jean Utke. ADOL-C, </author> <title> a package for the automatic differentiation of algorithms written in C/C++. </title> <journal> ACM Transactions on Mathematical Software, </journal> <volume> 22(2) </volume> <pages> 131-167, </pages> <year> 1996. </year>
Reference-contexts: In addition, the computation of n partial derivatives requires n + 1 function evaluations. Recently, automatic differentiation (AD) has been gaining popularity with the emergence of software tools such as ADIFOR [11, 12], ODYSSEE [48], or ADOL-C <ref> [34] </ref>. Given a code C, these tools can automatically produce an accurate and reasonably fast derivative code C 0 . AD works by systematically applying the chain rule of differential calculus at the elementary operator level and thus does not incur the errors inherent in divided difference 3 approximations. <p> In addition, some overhead is associated with the operator overloading itself. Examples of this approach are ADOL-C <ref> [34] </ref>, ADOL-F [49], ADO1 [45], FADBAD [6], and OPTIMA [5, 24]. Source-to-source transformation: This approach employs compiler techniques to transform a program source code into a new source code that explicitly carries out the derivative computation; hence, it is applicable to any language.
Reference: [35] <author> Andreas Griewank and Shawn Reese. </author> <title> On the calculation of Jacobian matrices by the Markowitz rule. </title> <editor> In Andreas Griewank and George F. Corliss, editors, </editor> <title> Automatic Differentiation of Algorithms: Theory, </title> <booktitle> Implementation, and Application, </booktitle> <pages> pages 126-135. </pages> <publisher> SIAM, </publisher> <address> Philadelphia, </address> <year> 1991. </year>
Reference-contexts: The reverse mode requires a reversal of the order of the original program execution, but is attractive when one desires the computation of the derivatives of few output values with respect to many input values. These issues are discussed in more detail in <ref> [32, 35, 46] </ref>. For general problems, the choice of a good strategy depends on the time and memory constraints as well as the particular program structure.
Reference: [36] <author> Jose Grimm, Loc Pottier, and Nicole Rostaing-Schmidt. </author> <title> Optimal time and minimum space time product for reversing a certain class of programs. </title> <editor> In Martin Berz, Christian Bischof, George Corliss, and Andreas Griewank, editors, </editor> <title> Computational Differentiation, Techniques, </title> <booktitle> Applications, and Tools, </booktitle> <pages> pages 95-106. </pages> <publisher> SIAM, </publisher> <address> Philadelphia, </address> <year> 1996. </year>
Reference-contexts: The development of heuristics to exploit algorithmic and program structure, and hence to better exploit chain rule associativity, is the subject of current research (see, for example, <ref> [18, 19, 21, 27, 33, 36] </ref>). 1.2 Implementation Strategies for Automatic Differentiation Tools Unlike compilers or most program transformation systems, AD tools modify the semantics of the underlying program by inserting, in a rule-based fashion, code for computing derivatives.
Reference: [37] <author> William Gropp, Ewing Lusk, and Anthony Skjellum. </author> <title> Using MPI Portable Parallel Programming with the Message Passing Interface. </title> <publisher> MIT Press, </publisher> <address> Cambridge, </address> <year> 1994. </year> <month> 38 </month>
Reference-contexts: As mentioned, for example, in [12, 21], AD provides ample opportunities for exploiting parallelism, from threads in shared-memory programming models (e.g., [41]) to the typically coarser-grained communication paradigms (e.g., MPI <ref> [37] </ref>) used in distributed-memory paradigms. Acknowledgments We thank Jason Abate of the University of Texas at Austin and Alan Carle of Rice University for their insightful comments and Po-Ting Wu of Argonne National Laboratory for his help in debugging ADIC.
Reference: [38] <author> Paul Hovland, Christian Bischof, Donna Spiegelman, and Mario Casella. </author> <title> Efficient derivative codes through automatic differentiation and interface contraction: An application in biostatistics. </title> <type> Preprint MCS-P491-0195, </type> <institution> Mathematics and Computer Science Division, Argonne National Laboratory, </institution> <year> 1995. </year> <note> To appear in SIAM J. Scientific Computing, </note> <month> 18(4) (July </month> <year> 1997). </year>
Reference-contexts: However, as shown in <ref> [19, 21, 38] </ref>, considerable improvements can be obtained by varying strategies at lower levels within a code. To enable this, we identify code fragments that can be mapped to the simple language underlying the AIF abstraction.
Reference: [39] <author> William T. Jones and Jamshid Samareh-Abolhassani. </author> <title> A grid generation system for multidisciplinary design optimization. </title> <booktitle> In Proceedings of the Workshop on Surface Modeling, Grid Generation, and Related Issues in CFD Solutions, </booktitle> <pages> pages 11-21, </pages> <year> 1995. </year> <month> NASA-CP3291. </month>
Reference-contexts: all double variables with an array for the gradient object, memory requirements of the ADIC-generated code scale linearly with p. 5.1 The CSCMDO 3-D Volume Grid Generator CSCMDO is a general-purpose, multi-block, three-dimensional, structured volume grid generator with specialized features for grid modifications that occur in multidisciplinary design optimization contexts <ref> [39] </ref>. It has been used, for example, with the RAPID 2-D surface grid generator [50] and the TLNS3D 3-D CFD solver [51] in design optimization studies at NASA for the high-speed planes. CSCMDO consists of 16,500 lines of ANSI-C; the unmodified code runs for 49 seconds.
Reference: [40] <author> David W. Juedes and Karthik Balakrishnan. </author> <title> Generalized neural networks, computational differentiation, and evolution. </title> <editor> In Martin Berz, Christian Bischof, George Corliss, and Andreas Griewank, editors, </editor> <title> Computational Differentiation: Techniques, </title> <booktitle> Applications, and Tools, </booktitle> <pages> pages 273-286. </pages> <publisher> SIAM, </publisher> <address> Philadelphia, </address> <year> 1996. </year>
Reference-contexts: 22.8 28.3 time (CD) time (AD) 2.0 2.1 2.2 2.1 2.2 2.1 Table 3: Timing Results for Stewart Platform 5.4 Neural Network Model Our last example is a generic neural network with n inputs, k hidden layers, a single output, and sigmoidal activation functions (as described on p. 279 in <ref> [40] </ref>). The model consists of 73 lines of ANSI-C. The training of these networks gives rise to an optimization problem that requires a gradient of the model for its solution. The data in Table 4 are based on the time for 1000 executions of the model.
Reference: [41] <author> Bil Lewis and Daniel J. Berg. </author> <title> Threads Primer. </title> <publisher> SunSoft Press, </publisher> <year> 1996. </year>
Reference-contexts: As mentioned, for example, in [12, 21], AD provides ample opportunities for exploiting parallelism, from threads in shared-memory programming models (e.g., <ref> [41] </ref>) to the typically coarser-grained communication paradigms (e.g., MPI [37]) used in distributed-memory paradigms. Acknowledgments We thank Jason Abate of the University of Texas at Austin and Alan Carle of Rice University for their insightful comments and Po-Ting Wu of Argonne National Laboratory for his help in debugging ADIC.
Reference: [42] <author> Michael Monagan and Rene R. Rodoni. </author> <title> An implementation of the forward and reverse mode of automatic differentiation in Maple. </title> <editor> In Martin Berz, Christian Bischof, George Corliss, and Andreas Griewank, editors, </editor> <title> Computational Differentiation: Techniques, </title> <booktitle> Applications, and Tools, </booktitle> <pages> pages 353-362. </pages> <publisher> SIAM, </publisher> <address> Philadelphia, </address> <year> 1996. </year>
Reference-contexts: C 0 can also be developed with the help of a symbolic mathematics package such as Mathematica, Maple, or Reduce. While this approach works well for domain-specific languages (see, e.g., <ref> [31, 42] </ref>), it is not directly applicable to large computer codes in languages such as Fortran 77 or C. Another alternative, divided differences, does not directly produce a derivative code but rather approximates the derivatives by evaluating f at multiple input points.
Reference: [43] <author> Heman Pande. </author> <title> Compile-Time Analysis of C and C++ Systems. </title> <type> PhD thesis, </type> <institution> Dept. of Computer Science, Rutgers University, </institution> <year> 1996. </year> <note> Technical Report LCSR-TR-260. </note>
Reference-contexts: In particular, unlike ADIFOR, ADIC does not perform an interprocedural data flow analysis to determine which variables need to be active, but makes the conservative assumption that all variables are active. Pointer analysis of ANSI-C programs remains an active research area (see, e.g., <ref> [43, 47, 53] </ref>); in the future we hope to able to assimilate emerging tools from the compiler community to provide some of these capabilities. * Derivative Augmentation: ADIC's current default strategy is the forward mode.
Reference: [44] <author> William H. Press and Saul A. Teukolsky. </author> <title> Numerical calculation of derivatives. </title> <journal> Computers in Physics, </journal> <volume> 5(1) </volume> <pages> 88-89, </pages> <address> Jan./Feb. </address> <year> 1991. </year>
Reference-contexts: For the simplest case, one-sided differences, the derivative of f with respect to the ith input x i is approximated by @ f x i The main drawback of the divided differences technique is that inherent errors make it difficult to determine the accuracy of the approximation <ref> [30, 44] </ref>. In addition, the computation of n partial derivatives requires n + 1 function evaluations. Recently, automatic differentiation (AD) has been gaining popularity with the emergence of software tools such as ADIFOR [11, 12], ODYSSEE [48], or ADOL-C [34].
Reference: [45] <author> J. D. Pryce and J. K. Reid. </author> <title> AD01 a Fortran 90 code for automatic differentiation. Unpublished information, </title> <institution> Rutherford Appleton Laboratory, Oxon, U.K., </institution> <year> 1996. </year>
Reference-contexts: In addition, some overhead is associated with the operator overloading itself. Examples of this approach are ADOL-C [34], ADOL-F [49], ADO1 <ref> [45] </ref>, FADBAD [6], and OPTIMA [5, 24]. Source-to-source transformation: This approach employs compiler techniques to transform a program source code into a new source code that explicitly carries out the derivative computation; hence, it is applicable to any language.
Reference: [46] <author> Louis B. Rall. </author> <title> Automatic Differentiation: Techniques and Applications, </title> <booktitle> volume 120 of Lecture Notes in Computer Science. </booktitle> <publisher> Springer Verlag, </publisher> <address> Berlin, </address> <year> 1981. </year>
Reference-contexts: The reverse mode requires a reversal of the order of the original program execution, but is attractive when one desires the computation of the derivatives of few output values with respect to many input values. These issues are discussed in more detail in <ref> [32, 35, 46] </ref>. For general problems, the choice of a good strategy depends on the time and memory constraints as well as the particular program structure.
Reference: [47] <author> Martin Rinard and Pedro Diniz. </author> <title> Commutativity analysis: A new analysis framework for parallelizing compilers. </title> <booktitle> In Proceedings ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI'96), </booktitle> <pages> pages 54-67, </pages> <address> New York, 1996. </address> <publisher> ACM. </publisher>
Reference-contexts: In particular, unlike ADIFOR, ADIC does not perform an interprocedural data flow analysis to determine which variables need to be active, but makes the conservative assumption that all variables are active. Pointer analysis of ANSI-C programs remains an active research area (see, e.g., <ref> [43, 47, 53] </ref>); in the future we hope to able to assimilate emerging tools from the compiler community to provide some of these capabilities. * Derivative Augmentation: ADIC's current default strategy is the forward mode.
Reference: [48] <author> Nicole Rostaing, Stephane Dalmas, and Andre Galligo. </author> <title> Automatic differentiation in Odyssee. </title> <address> Tellus, 45a(5):558-568, </address> <month> October </month> <year> 1993. </year> <month> 39 </month>
Reference-contexts: In addition, the computation of n partial derivatives requires n + 1 function evaluations. Recently, automatic differentiation (AD) has been gaining popularity with the emergence of software tools such as ADIFOR [11, 12], ODYSSEE <ref> [48] </ref>, or ADOL-C [34]. Given a code C, these tools can automatically produce an accurate and reasonably fast derivative code C 0 . <p> The disadvantage is the major effort required in implementing such a tool. ADIC, ADIFOR [11, 12], ODYSSEE <ref> [48] </ref>, and TAMC [29] are examples of this approach. 1.3 What's New in ADIC Our goal was to build an efficient AD tool for ANSI-C geared primarily toward the computation of first- and second-order derivatives.
Reference: [49] <author> Dimitri Shiriaev and Andreas Griewank. ADOL-F: </author> <title> Automatic differentiation of For--tran codes. </title> <editor> In Martin Berz, Christian Bischof, George Corliss, and Andreas Griewank, editors, </editor> <title> Computational Differentiation: Techniques, </title> <booktitle> Applications, and Tools, </booktitle> <pages> pages 375-384. </pages> <publisher> SIAM, </publisher> <address> Philadelphia, </address> <year> 1996. </year>
Reference-contexts: In addition, some overhead is associated with the operator overloading itself. Examples of this approach are ADOL-C [34], ADOL-F <ref> [49] </ref>, ADO1 [45], FADBAD [6], and OPTIMA [5, 24]. Source-to-source transformation: This approach employs compiler techniques to transform a program source code into a new source code that explicitly carries out the derivative computation; hence, it is applicable to any language.
Reference: [50] <author> Robert E. Smith, Malcolm G. I. Bloor, Michael Wilson, and Almuttil M. Thomas. </author> <title> Rapid airplane parametric input design (RAPID). </title> <booktitle> In Proceedings of the 12th AIAA Computational Fluid Dynamics Conference, </booktitle> <address> San Diego, </address> <institution> AIAA 95-1687. American Institute of Aeronautics and Astronautics, </institution> <year> 1995. </year>
Reference-contexts: It has been used, for example, with the RAPID 2-D surface grid generator <ref> [50] </ref> and the TLNS3D 3-D CFD solver [51] in design optimization studies at NASA for the high-speed planes. CSCMDO consists of 16,500 lines of ANSI-C; the unmodified code runs for 49 seconds.
Reference: [51] <author> V. N. Vatsa, M. D. Sanetrik, and E. B. Parlette. </author> <title> Development of a flexible and efficient multigrid-based multiblock flow solver. </title> <booktitle> In Proceedings of the 31st AIAA Aerospace Sciences Meeting, </booktitle> <pages> AIAA 93-0677. </pages> <institution> American Institute of Aeronautics and Astronautics, </institution> <year> 1993. </year>
Reference-contexts: It has been used, for example, with the RAPID 2-D surface grid generator [50] and the TLNS3D 3-D CFD solver <ref> [51] </ref> in design optimization studies at NASA for the high-speed planes. CSCMDO consists of 16,500 lines of ANSI-C; the unmodified code runs for 49 seconds. As shown in Table 1, ADIC-generated code is faster than central differences, and its advantage improves as the number of derivatives increases.
Reference: [52] <author> P. Weis, M. Mauny, A. Laville, and A. </author> <title> Suarez. The CAML Reference Manual, </title> <note> 1990. See also http://pauillac.inria.fr/caml. </note>
Reference-contexts: We are doubtful that such development stability could have been achieved if a program representation representation had been directly manipulated in Scheme [28] or CAML <ref> [52] </ref>. In summary, AIF allows us to decouple the world of the language-dependent AD fron-tend and the world of the AD transformation developer (which sees a simple, language-independent representation of program fragments).
Reference: [53] <author> Robert P. Wilson and Monica S. Lam. </author> <title> Efficient context-sensitivity pointer analysis for C programs. </title> <booktitle> In Proceedings of the ACM SIGPLAN'95 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 1-12, </pages> <address> New York, 1995. </address> <publisher> ACM Press. </publisher> <pages> 40 </pages>
Reference-contexts: In particular, unlike ADIFOR, ADIC does not perform an interprocedural data flow analysis to determine which variables need to be active, but makes the conservative assumption that all variables are active. Pointer analysis of ANSI-C programs remains an active research area (see, e.g., <ref> [43, 47, 53] </ref>); in the future we hope to able to assimilate emerging tools from the compiler community to provide some of these capabilities. * Derivative Augmentation: ADIC's current default strategy is the forward mode.
References-found: 53

