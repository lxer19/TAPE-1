URL: http://www.ai.mit.edu/~cdp/scaz-3heads.ps.Z
Refering-URL: http://www.ai.mit.edu/people/scaz/scaz.html
Root-URL: 
Email: scaz@ai.mit.edu  
Title: A Binocular, Foveated Active Vision System  
Author: Brian Scassellati 
Address: Square Room NE43-813 Cambridge, MA 02139  
Affiliation: 545 Technology  
Abstract: This report documents the design and implementation of a binocular, foveated active vision system as part of the Cog project at the MIT Artificial Intelligence Laboratory. The active vision system features a 3 degree of freedom mechanical platform that supports four color cameras, a motion control system, and a parallel network of digital signal processors for image processing. To demonstrate the capabilities of the system, we present re sults from four sample visual-motor tasks.
Abstract-found: 1
Intro-found: 1
Reference: <author> Ballard, D. </author> <year> (1989), </year> <title> `Behavioral Constraints on Animate Vision', </title> <booktitle> Image and Vision Computing 7:1, </booktitle> <pages> 3-9. </pages>
Reference-contexts: Although significantly heavier and larger than their human counterpart, they are smaller and more lightweight than other active vision systems <ref> (Ballard 1989, Reid, Bradshow, McLauch-lan, Sharkey, & Murray 1993) </ref>. The mechanical design and machining of the vision systems were done by Cynthia Ferrell, Elmer Lee, and Milton Wong.
Reference: <author> Banks, B. S. & Scassellati, B. </author> <year> (1997), </year> <title> Research Abstracts, MIT Artificial Intelligence Laboratory, chapter Learning Visual-Motor Tasks: A Comparison Study. </title>
Reference-contexts: The example described here uses a 17 fi 17 interpolated lookup table to estimate the saccade function. We are currently completing a comparative study between various machine learning techniques on this task <ref> (Banks & Scassellati 1997) </ref>. Saccade map training begins with a linear estimate based on the range of the encoder limits (determined during self-calibration).
Reference: <author> Brooks, R. & Stein, L. A. </author> <year> (1994), </year> <title> `Building Brains for Bodies', </title> <booktitle> Autonomous Robots 1:1, </booktitle> <pages> 7-25. </pages>
Reference-contexts: 1 Introduction The Cog Project at the MIT Artificial Intelligence Laboratory has focused on the construction of an upper torso humanoid robot, called Cog, to explore the hypothesis that human-like intelligence requires human-like interactions with the world <ref> (Brooks & Stein 1994) </ref>. Cog has sensory and motor systems that mimic human capabilities, including over twenty-one degrees of freedom and a variety of sensory systems, including visual, auditory, proprioceptive, tactile, and vestibular senses. This paper documents the design and implementation of a binocular, foveated active vision system for Cog.
Reference: <author> Ferrell, C. </author> <year> (1997), </year> <title> Research Abstracts, MIT Artificial Intelligence Laboratory, chapter Learning Social Behaviors in an Altricial Context. </title>
Reference: <author> Graham, C. H. </author> <year> (1965), </year> <title> Vision and Visual Perception, </title> <publisher> John Wiley and Sons, Inc. </publisher>
Reference-contexts: Smooth pursuit movements maintain the fovea, a very small area at the center of the visual field. A discontinuity occurs where axons that form the optic nerve crowd out photoreceptor cell bodies, resulting in a blind spot. From <ref> (Graham 1965) </ref>. image of a moving object on the fovea at speeds below 100 ffi per second. Vergence movements adjust the eyes for viewing objects at varying depth.
Reference: <author> Irie, R. </author> <year> (1997), </year> <title> Research Abstracts, MIT Artificial Intelligence Laboratory, chapter Multimodal Sensory Integration for a Humanoid Robot. </title>
Reference: <author> Kandel, E. R., Schwartz, J. H. & Jessell, T. M., </author> <booktitle> eds (1992), Principles of Neural Science, </booktitle> <institution> Appleton and Lange, </institution> <note> chapter chapter title. </note>
Reference-contexts: On average, the human eye performs 3 to 4 full range saccades per second <ref> (Kandel et al. 1992) </ref>. Given this goal, Cog's eye motor system is designed to perform three 120 ffi pan saccades per second and three 60 ffi tilt saccades per second (with 250 ms of stability in between saccades).
Reference: <author> Kemp, C. </author> <year> (1997), </year> <title> Research Abstracts, MIT Artificial Intelligence Laboratory, chapter A Platform for Visual Learning. </title>
Reference: <author> Kuniyoshi, Y., Kita, N., Sugimoto, K., Nakamura, S. & Suehiro, T. </author> <year> (1995), </year> <title> A Foveated Wide Angle Lens for Active Vision, </title> <booktitle> in `Proc. IEEE Int. Conf. Robotics and Automation'. </booktitle>
Reference: <author> Marjanovic, M., Scassellati, B. & Williamson, M. </author> <year> (1996), </year> <title> Self-Taught Visually-Guided Pointing for a Humanoid Robot, </title> <booktitle> in `Society of Adaptive Behavior'. </booktitle>
Reference: <author> Peskin, J. & Scassellati, B. </author> <year> (1997), </year> <title> Research Abstracts, MIT Artificial Intelligence Laboratory, chapter Image Stabilization through Vestibular and Retinal Feedback. </title>
Reference-contexts: The optokinetic response places the least demanding requirements on our system; it requires only basic image processing techniques and slow compensatory movements. 1 With this set of requirements, we can begin to 1 Implementations of these two reflexes are currently in progress for Cog <ref> (Peskin & Scassellati 1997) </ref>. The desktop development platforms have no head motion, and no vestibular system, and thus do not require these reflexes. describe the design decisions that lead to our cur-rent implementation. We begin in Section 3 with the choice of the camera system.
Reference: <author> Reid, I., Bradshow, K., McLauchlan, P., Sharkey, P., & Murray, D. </author> <year> (1993), </year> <title> From Saccades to Smooth Pursuit: Real-Time Gaze Control using Motion Feedback, </title> <booktitle> in `International Conference on Intelligent Robots and Systems', Yokahama, Japan, </booktitle> <pages> pp. 1013-1020. </pages>
Reference: <author> Scassellati, B. </author> <year> (1997), </year> <title> Research Abstracts, MIT Artificial Intelligence Laboratory, chapter Mechanisms of Shared Attention for a Humanoid Robot. </title> <editor> van der Spiegel, J., Kreider, G., Claeys, C., Debuss-chere, I., Sandini, G., Dario, P., Fantini, F., Bel-luti, P. & Soncini, G. </editor> <year> (1989), </year> <title> A foveated retina-like sensor using CCD technology, </title> <publisher> Kluwer Academic Publishers. </publisher>
Reference-contexts: The optokinetic response places the least demanding requirements on our system; it requires only basic image processing techniques and slow compensatory movements. 1 With this set of requirements, we can begin to 1 Implementations of these two reflexes are currently in progress for Cog <ref> (Peskin & Scassellati 1997) </ref>. The desktop development platforms have no head motion, and no vestibular system, and thus do not require these reflexes. describe the design decisions that lead to our cur-rent implementation. We begin in Section 3 with the choice of the camera system. <p> The example described here uses a 17 fi 17 interpolated lookup table to estimate the saccade function. We are currently completing a comparative study between various machine learning techniques on this task <ref> (Banks & Scassellati 1997) </ref>. Saccade map training begins with a linear estimate based on the range of the encoder limits (determined during self-calibration).
Reference: <author> Yamato, J. </author> <year> (1997), </year> <title> Research Abstracts, MIT Artificial Intelligence Laboratory, chapter Learning Pointing Action in 3D space using depth information from stereo cameras. </title>
References-found: 14

