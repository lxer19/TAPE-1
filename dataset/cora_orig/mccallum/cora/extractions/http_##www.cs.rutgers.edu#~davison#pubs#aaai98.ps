URL: http://www.cs.rutgers.edu/~davison/pubs/aaai98.ps
Refering-URL: http://www.cs.rutgers.edu/~davison/pubs/aaai98.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: flou,davisong@cs.rutgers.edu  
Title: Highest Utility First Search Across Multiple Levels of Stochastic Design  
Author: Louis Steinberg J. Storrs Hall Brian D. Davison 
Address: New Brunswick, NJ 08903  
Affiliation: Department of Computer Science, Rutgers University  
Abstract: Many design problems are solved using multiple levels of abstraction, where a design at one level has combi-natorially many children at the next level. A stochastic optimization methods, such as simulated annealing, genetic algorithms and multi-start hill climbing, is often used in such cases to generate the children of a design. This gives rise to a search tree for the overall problem characterized by a large branching factor, objects at different levels that are hard to compare, and a child-generator that is too expensive to run more than a few times at each level. We present the Highest Utility First Search (HUFS) control algorithm for searching such trees. HUFS is based on an estimate we derive for the expected utility of starting the design process from any given design alternative, where utility reflects both the intrinsic value of the final result and the cost in computing resources it will take to get that result. We also present an empirical study applying HUFS to the problem of VLSI module placement, in which HUFS demonstrates significantly better performance than the common "waterfall" control method. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Boddy, M., and Dean, T. </author> <year> 1994. </year> <title> Deliberation scheduling for problem solving in time-constrained environments. </title> <booktitle> Artificial Intelligence 67 </booktitle> <pages> 245-285. </pages>
Reference-contexts: Hansen and Zilberstein (Hansen & Zilberstein 1996a), (Hansen & Zilberstein 1996b) are concerned with anytime algorithms <ref> (Boddy & Dean 1994) </ref>. An anytime algorithm is one that can be stopped after working for a variable amount of time. If it is stopped after working for a short time, it will give lower quality results than if it is stopped after working for a longer time.
Reference: <author> Etzioni, O. </author> <year> 1991. </year> <title> Embedding decision-analytic control in a learning architecture. </title> <booktitle> Artificial Intelligence 49 </booktitle> <pages> 129-159. </pages>
Reference-contexts: Another relevant paper is <ref> (Etzioni 1991) </ref>. <p> If it is stopped before any ground-level design is produced, then it gives no answer at all. It would be interesting to see if HUFS could be turned into an anytime algorithm. Etzioni <ref> (Etzioni 1991) </ref> describes an approach to a planning problem that is quite different from our problem here, but he uses a notion called "marginal utility".
Reference: <author> Goldberg, D. E. </author> <year> 1989. </year> <title> Genetic Algorithms in Search, Optimization, </title> <booktitle> and Machine Learning. </booktitle> <address> Reading, Mass.: </address> <publisher> Addison-Wesley. </publisher>
Reference: <author> Hansen, E., and Zilberstein, S. </author> <year> 1996a. </year> <title> Monitoring anytime algorithms. </title> <journal> SIGART Bulletin Special Issue on Anytime Algorithms and Deliberation Scheduling 7(2) </journal> <pages> 28-33. </pages>
Reference-contexts: However, these problems do not have the large branching factors and different types of objects at each level of the search tree, and the specific methods they use do not apply to our problem here. Hansen and Zilberstein <ref> (Hansen & Zilberstein 1996a) </ref>, (Hansen & Zilberstein 1996b) are concerned with anytime algorithms (Boddy & Dean 1994). An anytime algorithm is one that can be stopped after working for a variable amount of time. <p> i.e. repeated execution of one stochastic optimizer, is thus an anytime algorithm | if there is more time, more runs can be done and the average quality of the result will be better, and if there is less time fewer runs can be done and the quality will be worse. <ref> (Hansen & Zilberstein 1996a) </ref> defines the "myopic expected value of computation" (myopic EVC) which is equivalent in our terms to EIV c, and their rule for stopping, stop when myopic EVC is negative, is equivalent to our rule, stop when EIV &lt; c.
Reference: <author> Hansen, E., and Zilberstein, S. </author> <year> 1996b. </year> <title> Monitoring the progress of anytime problem-solving. </title> <booktitle> In Proceedings of the 13th National Conference on Artificial Intelligence, </booktitle> <pages> 1229-1234. </pages>
Reference-contexts: However, these problems do not have the large branching factors and different types of objects at each level of the search tree, and the specific methods they use do not apply to our problem here. Hansen and Zilberstein (Hansen & Zilberstein 1996a), <ref> (Hansen & Zilberstein 1996b) </ref> are concerned with anytime algorithms (Boddy & Dean 1994). An anytime algorithm is one that can be stopped after working for a variable amount of time.
Reference: <author> Ingber, L. </author> <year> 1996. </year> <title> Adaptive simulated annealing (ASA): Lessons learned. </title> <journal> Control and Cybernetics 25(1) </journal> <pages> 33-54. </pages>
Reference-contexts: Recently, a number of techniques for stochastic optimization have been shown to be useful for specific levels of such problems. These techniques include simulated annealing <ref> (Ingber 1996) </ref>, genetic algorithms (Michalewicz 1996; Goldberg 1989), and random-restart hill climbing (Zha et al. 1996). A design at one level is translated into a correct but poor design at the next level, and a stochastic optimizer is used to improve this design.
Reference: <author> Michalewicz, Z. </author> <year> 1996. </year> <title> Genetic Algorithms + Data Structures = Evolution Programs. </title> <address> New York: </address> <publisher> Springer-Verlag. </publisher>
Reference: <author> Russell, S., and Wefald, E. </author> <year> 1991. </year> <title> Do the Right Thing. </title> <publisher> MIT Press. </publisher>
Reference-contexts: I.e., the utility of d is the expected difference between the value of the final design we will get if we use d as our starting point and the cost of the computation it will take to get this design. (This formulation of utility was taken from <ref> (Russell & Wefald 1991) </ref>.) The basic idea of HUFS is very simple: Find the design alternative d opt with the highest Udesign, among all the design alternatives you currently have on all the levels, and generate one child from d opt , that is, run the appropriate level's optimizer with d <p> most relevant to our work on HUFS are the work on utility-based meta c HUFS HUFS Waterfall HUFS/WF Score Runs Runs Runs 1600 92523. 15.6 26.0 0.60 6400 99978. 5.6 8.0 0.70 Table 2: Optimizer runs vs. average score for HUFS and waterfall reasoning by Russell and Wefald reported in <ref> (Russell & Wefald 1991) </ref> and the work on monitoring anytime algorithms by Zilberstein and colleagues. Another relevant paper is (Etzioni 1991).
Reference: <author> Steinberg, L.; Hall, J. S.; and Davison, B. </author> <year> 1998. </year> <title> Highest utility first search: a control method for multilevel stochastic design. </title> <type> Technical Report HPCD-TR-59, </type> <institution> High Perfomance Computing and Design Project, Department of Computer Science, Rutgers University, </institution> <address> New Brunswick, NJ. </address>
Reference-contexts: to combine the two single-level analyses (one for generating trees from netlists and one for generating placements from trees) to show that Udesign (L) is not only the utility of generating trees from L, it is also the utility of the whole multi-level process of generating placements from L. (See <ref> (Steinberg, Hall, & Davison 1998) </ref> for this proof.) Thus, in general, for level i &gt; 0, U i (s) = U i1 (s t (G (s i1 js))); U i1 ; c i1 )) The HUFS Algorithm The HUFS algorithm is a best first search where "best" means "largest Udesign". <p> We rather arbitrarily set U placement (s) = 10 6 s. The score functions were all simple heuristics based on the information available in a design at each level. See <ref> (Steinberg, Hall, & Davison 1998) </ref> for more details. <p> We presented HUFS and its implementation for a two-level system that solves the problem of placing circuit modules on a VLSI chip, and showed that HUFS performed significantly better than the waterfall approach of working in a strict top-down, level by level manner. See <ref> (Steinberg, Hall, & Davison 1998) </ref> for further details and discussions of such issues as the scalability of HUFS and problems with the models of value and time cost used in HUFS.
Reference: <author> Tribus, M. </author> <year> 1969. </year> <title> Rational Descriptions, Decisions and Designs. </title> <address> New York: </address> <publisher> Pergamon Press. </publisher>
Reference-contexts: This paper presents an alternative to the waterfall control method, called "Highest Utility First Search" (HUFS). HUFS applies ideas from the decision theory <ref> (Tribus 1969) </ref> to explore the tree of alternatives in a much more flexible manner than waterfall. We will describe HUFS and present empirical data from one example design task showing that HUFS can be a significant improvement over waterfall search. <p> When we generate children from d, we update our estimate of H (rjd) by using H (rjS (d)) (that is, H (rjs) where s = S (d)) as our prior estimate and H (rjd) as our posteriori estimate, and the standard Bayesian formula <ref> (Tribus 1969) </ref>, sP (R (d ) = r jchild scores = s 1 : : : s n ) = P (R (d ) = r)P (child scores = s 1 : : : s n jR (d ) = r ) P (child scores = s 1 : : :
Reference: <author> Zha, G.-C.; Smith, D.; Schwabacher, M.; Rasheed, K.; Gelsey, A.; and Knight, D. </author> <year> 1996. </year> <title> High performance supersonic missile inlet design using automated optimization. </title> <booktitle> In AIAA Symposium on Multidisciplinary Analysis and Optimization '96. </booktitle>
Reference-contexts: Recently, a number of techniques for stochastic optimization have been shown to be useful for specific levels of such problems. These techniques include simulated annealing (Ingber 1996), genetic algorithms (Michalewicz 1996; Goldberg 1989), and random-restart hill climbing <ref> (Zha et al. 1996) </ref>. A design at one level is translated into a correct but poor design at the next level, and a stochastic optimizer is used to improve this design.
Reference: <author> Zilberstein, S., and Russell, S. </author> <year> 1996. </year> <title> Optimal composition of real-time systems. </title> <journal> Artificial Intelligence 82(1-2):181-213. </journal>
Reference-contexts: However, Hansen and Zilberstein are concerned with the general case of anytime algorithms (and also with the cost of the monitoring, which we do not consider), and thus do not derive any more specific formula for myopic EVC. They also do not consider multi-level systems. (Zilberstein 1993) and <ref> (Zilberstein & Russell 1996) </ref> also define a stopping rule similar to ours and prove that, under conditions similar to those that hold in our single-level case, it is optimal.
Reference: <author> Zilberstein, S. </author> <year> 1993. </year> <title> Operational Rationality Through Compilation of Anytime Algorithms. </title> <type> Ph.D. Dissertation, </type> <institution> University of California at Berkeley. </institution>
Reference-contexts: However, Hansen and Zilberstein are concerned with the general case of anytime algorithms (and also with the cost of the monitoring, which we do not consider), and thus do not derive any more specific formula for myopic EVC. They also do not consider multi-level systems. <ref> (Zilberstein 1993) </ref> and (Zilberstein & Russell 1996) also define a stopping rule similar to ours and prove that, under conditions similar to those that hold in our single-level case, it is optimal.
References-found: 13

