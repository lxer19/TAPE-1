URL: ftp://ftp.cs.rochester.edu/pub/u/michael/JPDC98.ps.gz
Refering-URL: http://www.cs.rochester.edu/u/michael/
Root-URL: 
Email: fmichael,scottg@cs.rochester.edu  
Title: Non-Blocking Algorithms and Preemption-Safe Locking on Multiprogrammed Shared Memory Multiprocessors  
Author: Maged M. Michael Michael L. Scott 
Note: This work was supported in part by NSF grants nos. CDA-94-01142 and CCR-93-19445, and by ONR research grant no. N00014-92J-1801 (in conjunction with the DARPA Research in Information Science and TechnologyHigh Performance Computing, Software Science and Technology program, ARPA Order no. 8930).  
Date: March 1997  
Address: Rochester, NY 14627-0226  
Affiliation: Department of Computer Science University of Rochester  
Abstract: Most multiprocessors are multiprogrammed in order to achieve acceptable response time and to increase their utilization. Unfortunately, inopportune preemption may significantly degrade the performance of synchronized parallel applications. To address this problem, researchers have developed two principal strategies for concurrent, atomic update of shared data structures: (1) preemption-safe locking and (2) non-blocking (lock-free) algorithms. Preemption-safe locking requires kernel support. Non-blocking algorithms generally require a universal atomic primitive such as compare-and-swap or load-linked/store-conditional, and are widely regarded as inefficient. We evaluate the performance of preemption-safe lock-based and non-blocking implementations of important data structuresqueues, stacks, heaps, and countersincluding non-blocking and lock-based queue algorithms of our own, in micro-benchmarks and real applications on a 12-processor SGI Challenge multiprocessor. Our results indicate that our non-blocking queue consistently outperforms the best known alternatives, and that data-structure-specific non-blocking algorithms, which exist for queues, stacks, and counters, can work extremely well. Not only do they outperform preemption-safe lock-based algorithms on multiprogrammed machines, they also outperform ordinary locks on dedicated machines. At the same time, since general-purpose non-blocking techniques do not yet appear to be practical, preemption-safe locks remain the preferred alternative for complex data structures: they outperform conventional locks by significant margins on multiprogrammed systems. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Alemany and E. W. Felten. </author> <title> Performance Issues in Non-blocking Synchronization on Shared-Memory Multiprocessors. </title> <booktitle> In Proceedings of the Eleventh ACM Symposium on Principles of Distributed Computing, </booktitle> <address> Vancouver, BC, Canada, </address> <month> August </month> <year> 1992. </year>
Reference-contexts: The basic methodology requires copying the entire data structure on every update. Herlihy also proposed an optimization by which the programmer can avoid some fraction of the copying for certain data structures; he illustrated this optimization in a non-blocking implementation of a skew-heap-based priority queue. Alemany and Felten <ref> [1] </ref> and LaMarca [20] proposed techniques to reduce unnecessary copying and useless parallelism associated with Herlihy's methodologies using extra communication between the operating system kernel and application processes.
Reference: [2] <author> T. E. Anderson. </author> <title> The Performance of Spin Lock Alternatives for Shared-Memory Multiprocessors. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 1(1) </volume> <pages> 6-16, </pages> <month> January </month> <year> 1990. </year>
Reference-contexts: All non-blocking algorithms also use bounded exponential backoff. The effectiveness of backoff in reducing contention on locks and synchronization data is demonstrated in the literature <ref> [2, 25] </ref>. The backoff was chosen to yield good overall performance for all algorithms, and not to exceed 30 s. We emulate both test and-set and compare-and-swap, using load-linked and store-conditional instructions, as shown in Figure 5.
Reference: [3] <author> R. J. Anderson and H. Woll. </author> <title> Wait-Free Parallel Algorithms for the Union-Find Problem. </title> <booktitle> In Proceedings of the Twenty-Third ACM Symposium on Theory of Computing, </booktitle> <pages> pages 370-380, </pages> <month> May </month> <year> 1991. </year> <month> 28 </month>
Reference-contexts: We also observe that a stack derived from Herlihy's general methodology, with unnecessary copying removed, seems to be simple enough to compete with lock-based algorithms. Valois [43] proposed a non-blocking implementation of linked lists. Anderson and Woll <ref> [3] </ref> proposed a non blocking solution to the union-find problem. Simple non-blocking centralized counters can be implemented trivially using a fetch-and-add atomic primitive (if supported by hardware), or a read-modify-check-write cycle us ing compare-and-swap or load-linked/store-conditional.
Reference: [4] <author> T. E. Anderson, B. N. Bershad, E. D. Lazowska, and H. M. Levy. </author> <title> Scheduler Activations: Effective Kernel Support for the User-Level Management of Parallelism. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 10(1) </volume> <pages> 53-79, </pages> <month> February </month> <year> 1992. </year>
Reference-contexts: Black's work on Mach [7] introduced another recovery technique: a process may suggest to the kernel that it be descheduled in favor of some specific other process (presumably the one that is holding a desired lock). The scheduler activations of Anderson et al. <ref> [4] </ref> also support recovery: when a processor is taken from an application, another processor belonging to the same application is informed via software interrupt.
Reference: [5] <author> J. H. Anderson and M. Moir. </author> <title> Universal Constructions for Multi-Object Operations. </title> <booktitle> In Proceedings of the Fourteenth ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pages 184-194, </pages> <address> Ottawa, Ontario, Canada, </address> <month> August </month> <year> 1995. </year>
Reference-contexts: Barnes [6] presented a general methodology in which processes record and timestamp their modifications to the shared object, and cooperate whenever conflicts arise. Shavit and Touitou [33] presented software transactional memory, which implements a k-word compare-and-swap using load-linked/store-conditional. Also, Anderson and Moir <ref> [5] </ref> presented non-blocking methodologies for large objects that rely on techniques for implementing multiple-word compare-and-swap using load-linked/store-conditional and vice versa. Turek et al. [40] and Prakash et al. [31] presented methodologies for transforming multiple lock concurrent objects into lock-free concurrent objects.
Reference: [6] <author> G. Barnes. </author> <title> A Method for Implementing Lock-Free Data Structures. </title> <booktitle> In Proceedings of the Fifth Annual ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 261-270, </pages> <address> Velen, Germany, </address> <month> June - July </month> <year> 1993. </year>
Reference-contexts: Alemany and Felten [1] and LaMarca [20] proposed techniques to reduce unnecessary copying and useless parallelism associated with Herlihy's methodologies using extra communication between the operating system kernel and application processes. Barnes <ref> [6] </ref> presented a general methodology in which processes record and timestamp their modifications to the shared object, and cooperate whenever conflicts arise. Shavit and Touitou [33] presented software transactional memory, which implements a k-word compare-and-swap using load-linked/store-conditional.
Reference: [7] <author> D. L. Black. </author> <title> Scheduling Support for Concurrency and Parallelism in the Mach Operating System. </title> <journal> Computer, </journal> <volume> 23(5) </volume> <pages> 35-43, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: Karlin et al. [17] present 4 a set of spin-then-block alternatives that adjust the spin time based on past experience. Black's work on Mach <ref> [7] </ref> introduced another recovery technique: a process may suggest to the kernel that it be descheduled in favor of some specific other process (presumably the one that is holding a desired lock).
Reference: [8] <author> J. Edler, J. Lipkis, and E. Schonberg. </author> <title> Process Management for Highly Parallel UNIX Systems. </title> <booktitle> In Proceedings of the USENIX Workshop on Unix and Supercomputers, </booktitle> <address> Pittsburgh, PA, </address> <month> September </month> <year> 1988. </year>
Reference-contexts: Finally, we summarize our conclusions and recommendations in Section 6. 2 Preemption-Safe Locking For simple mutual exclusion locks (e.g. test-and-set), preemption-safe locking techniques allow the system either to avoid or to recover from the adverse effect of the preemption of processes holding locks. Edler et al.'s Symunix system <ref> [8] </ref> employs an avoidance technique: a process may set a flag requesting that the kernel not preempt it because it is holding a lock. <p> For the designers of future systems, we recommend (1) that hardware always include a universal atomic primitive, and (2) that kernel interfaces provide a mechanism for preemption-safe locking. For small-scale machines, the Synunix interface <ref> [8] </ref> appears to work well. For larger machines, a more elaborate interface may be appropriate [18]. We have presented a concurrent queue algorithm that is simple, non-blocking, practical, and fast. It appears to be the algorithm of choice for any queue-based application on a multiprocessor with a universal atomic primitive.
Reference: [9] <author> A. Gottlieb, B. D. Lubachevsky, and L. Rudolph. </author> <title> Basic Techniques for the Efficient Coordination of Very Large Numbers of Cooperating Sequential Processors. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 5(2) </volume> <pages> 164-189, </pages> <month> April </month> <year> 1983. </year>
Reference-contexts: These algorithms are incompletely specified; they omit important details such as the handling of empty or single-item queues, or concurrent enqueues and dequeues. Lamport [21] presented a wait-free algorithm that allows only a single enqueuer and a single dequeuer. 4 Gottlieb et al. <ref> [9] </ref> and Mellor-Crummey [24] presented algorithms that are lock-free but not non-blocking: they do not use locking mechanisms, but they allow a slow process to delay faster processes indefinitely.
Reference: [10] <author> M. P. Herlihy and J. M. Wing. </author> <title> Axioms for Concurrent Objects. </title> <booktitle> In Proceedings of the Fourteenth ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 13-26, </pages> <month> January </month> <year> 1987. </year>
Reference-contexts: As mentioned above, Massalin and Pu [23] presented a non-blocking array-based algorithm based on double-compare-and-swap, a primitive available only on later members of the Motorola 68000 family of processors. Herlihy and Wing <ref> [10] </ref> presented an array-based algorithm that requires infinite arrays.
Reference: [11] <author> M. P. Herlihy and J. M. Wing. </author> <title> Linearizability: A Correctness Condition for Concurrent Objects. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 12(3) </volume> <pages> 463-492, </pages> <month> July </month> <year> 1990. </year>
Reference-contexts: A node is 5 An implementation of a data structure is linearizable if it can always give an external observer, observing only the abstract data structure operations, the illusion that each of these operations takes effect instantaneously at some point between its invocation and its response <ref> [11] </ref>. 9 freed only when no pointers in the data structure or temporary variables point to it. We discovered and corrected [26] race conditions in the memory management mechanism and the associated non-blocking queue algorithm.
Reference: [12] <author> M. Herlihy. </author> <title> Wait-Free Synchronization. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 13(1) </volume> <pages> 124-149, </pages> <month> January </month> <year> 1991. </year>
Reference-contexts: Our contributions include: * A simple, fast, and practical non-blocking queue algorithm that outperforms all known alternatives, and should be the algorithm of choice for multiprocessors that support universal atomic primitives. 1 Herlihy <ref> [12] </ref> presented a hierarchy of non-blocking objects that also applies to atomic primitives. A primitive is at level n of the hierarchy if it can provide a non-blocking solution to a consensus problem for up to n processors.
Reference: [13] <author> M. Herlihy. </author> <title> A Methodology for Implementing Highly Concurrent Data Objects. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 15(5) </volume> <pages> 745-770, </pages> <month> November </month> <year> 1993. </year>
Reference-contexts: These implementations and methodologies 5 were motivated in large part by the performance degradation of mutual exclusion locks as a result of arbitrary process delays, particularly those due to preemption on a multiprogrammed system. 3.1 General Non-Blocking Methodologies Herlihy <ref> [13] </ref> presented a general methodology for transforming sequential implementations of data structures into concurrent non-blocking implementations using compare-and-swap or load-linked/store-conditional. The basic methodology requires copying the entire data structure on every update. <p> Turek et al. [40] and Prakash et al. [31] presented methodologies for transforming multiple lock concurrent objects into lock-free concurrent objects. Unfortunately, the performance of non-blocking algorithms resulting from general methodologies is acknowledged to be significantly inferior to that of the corresponding lock-based algorithms <ref> [13, 20, 33] </ref>. Two proposals for hardware support for general non-blocking data structures have been presented: transactional memory by Herlihy and Moss [14] and the Oklahoma update by Stone et al. [38]. Neither of these techniques has been implemented on a real machine. <p> Table 2 shows performance on a dedicated processorthe left-most points in the top-most graph. The four stack implementations are: the usual single lock algorithm using ordinary and preemption-safe locks, Treiber's non-blocking stack algorithm [39], and an optimized non-blocking algorithm based on Herlihy's general methodology <ref> [13] </ref>. Like Treiber's non-blocking stack algorithm, the optimized algorithm based on Herlihy's methodology uses a singly-linked list to represent the stack with a Top pointer. <p> Accordingly, Treiber's algorithm yields the best performance even with no contention. 5.3 Heaps three implementations are: the usual single-lock algorithm using ordinary and preemption-safe locks, and an optimized non-blocking algorithm due to Herlihy <ref> [13] </ref>. The optimized non-blocking algorithm due to Herlihy uses a binary tree to represent the heap with a Root pointer. Every process has its own copy of Root.
Reference: [14] <author> M. Herlihy and J. E. Moss. </author> <title> Transactional Memory: Architectural Support for Lock-Free Data Structures. </title> <booktitle> In Proceedings of the Twentieth International Symposium on Computer Architecture, </booktitle> <pages> pages 289-300, </pages> <address> San 29 Diego, CA, </address> <month> May </month> <year> 1993. </year> <note> Expanded version available as CRL 92/07, </note> <institution> December Cambridge Research Laboratory, </institution> <month> December </month> <year> 1992. </year>
Reference-contexts: Unfortunately, the performance of non-blocking algorithms resulting from general methodologies is acknowledged to be significantly inferior to that of the corresponding lock-based algorithms [13, 20, 33]. Two proposals for hardware support for general non-blocking data structures have been presented: transactional memory by Herlihy and Moss <ref> [14] </ref> and the Oklahoma update by Stone et al. [38]. Neither of these techniques has been implemented on a real machine. The simulation-based experimental results of Herlihy and Moss show performance significantly inferior to that of spin locks.
Reference: [15] <author> K. Hwang and F. A. Briggs. </author> <title> Computer Architecture and Parallel Processing. </title> <publisher> McGraw-Hill, </publisher> <year> 1984. </year>
Reference-contexts: Our presentation includes two new concurrent queue algorithms. One is non-blocking; the other uses a pair of mutual exclusion locks. 4 Concurrent Queue Algorithms 4.1 Discussion of Previous Work Many researchers have proposed lock-free algorithms for concurrent queues. Hwang and Briggs <ref> [15] </ref>, Sites [34], and Stone [37] presented lock-free algorithms based on compare-and-swap. These algorithms are incompletely specified; they omit important details such as the handling of empty or single-item queues, or concurrent enqueues and dequeues.
Reference: [16] <author> E. H. Jensen, G. W. Hagensen, and J. M. Broughton. </author> <title> A New Approach to Exclusive Data Access in Shared Memory Multiprocessors. </title> <type> Technical Report UCRL-97663, </type> <institution> Lawrence Livermore National Laboratory, </institution> <month> November </month> <year> 1987. </year>
Reference-contexts: If the shared location currently holds the expected value, it is assigned the new value atomically. A Boolean return value indicates whether the replacement occurred. Compare-and-swap is supported on the Intel Pentium Pro and Sparc V9 architectures. 3 Load-linked and store-conditional, proposed by Jensen et al. <ref> [16] </ref>, must be used together to read, modify, and write a shared location. Load-linked returns the value stored at the shared location. Store-conditional checks if any other processor has since written to that location. If not then the location is updated and the operation returns success, otherwise it returns failure.
Reference: [17] <author> A. R. Karlin, K. Li, M. S. Manasse, and S. Owicki. </author> <title> Empirical Studies of Competitive Spinning for a Shared-Memory Multiprocessor. </title> <booktitle> In Proceedings of the Thirteenth ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 41-55, </pages> <address> Pacific Grove, CA, </address> <month> October </month> <year> 1991. </year>
Reference-contexts: Recovery-based preemption-safe locking techniques include the spin-then-block locks of Ousterhout [30] which let a waiting process spin for a certain period of time and thenif unsuccessful in entering the critical sectionblock, thus minimizing the adverse effect of waiting for a lock held by a descheduled process. Karlin et al. <ref> [17] </ref> present 4 a set of spin-then-block alternatives that adjust the spin time based on past experience.
Reference: [18] <author> L. I. Kontothanassis, R. W. Wisniewski, and M. L. Scott. </author> <title> Scheduler-Conscious Synchronization. </title> <journal> In ACM Transactions on Computer Systems, </journal> <month> February </month> <year> 1997. </year>
Reference-contexts: Preempting and scheduling processes in an order inconsistent with their order in the lock's queue can degrade performance dramatically. Kontothanassis et al. <ref> [18] </ref> present preemption-safe (or scheduler-conscious) versions of the ticket lock, the MCS lock [25], and Krieger et al.'s reader-writer lock [19]. These algorithms detect the descheduling of critical processes using handshaking and/or a widened kernel-user interface, and use this information to avoid handing the lock to a preempted process. <p> For the designers of future systems, we recommend (1) that hardware always include a universal atomic primitive, and (2) that kernel interfaces provide a mechanism for preemption-safe locking. For small-scale machines, the Synunix interface [8] appears to work well. For larger machines, a more elaborate interface may be appropriate <ref> [18] </ref>. We have presented a concurrent queue algorithm that is simple, non-blocking, practical, and fast. It appears to be the algorithm of choice for any queue-based application on a multiprocessor with a universal atomic primitive. Also, we have presented a two-lock queue algorithm.
Reference: [19] <author> O. Krieger, M. Stumm, and R. Unrau. </author> <title> A Fair Fast Scalable Reader-Writer Lock. </title> <booktitle> In Proceedings of the 1993 International Conference on Parallel Processing, pages II:201-204, </booktitle> <address> St. Charles, IL, August 1993. </address> <publisher> CRC Press. </publisher>
Reference-contexts: Preempting and scheduling processes in an order inconsistent with their order in the lock's queue can degrade performance dramatically. Kontothanassis et al. [18] present preemption-safe (or scheduler-conscious) versions of the ticket lock, the MCS lock [25], and Krieger et al.'s reader-writer lock <ref> [19] </ref>. These algorithms detect the descheduling of critical processes using handshaking and/or a widened kernel-user interface, and use this information to avoid handing the lock to a preempted process.
Reference: [20] <author> A. LaMarca. </author> <title> A Performance Evaluation of Lock-free Synchronization Protocols. </title> <booktitle> In Proceedings of the Thirteenth ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pages 130-140, </pages> <address> Los Angeles, CA, </address> <month> August </month> <year> 1994. </year>
Reference-contexts: Herlihy also proposed an optimization by which the programmer can avoid some fraction of the copying for certain data structures; he illustrated this optimization in a non-blocking implementation of a skew-heap-based priority queue. Alemany and Felten [1] and LaMarca <ref> [20] </ref> proposed techniques to reduce unnecessary copying and useless parallelism associated with Herlihy's methodologies using extra communication between the operating system kernel and application processes. Barnes [6] presented a general methodology in which processes record and timestamp their modifications to the shared object, and cooperate whenever conflicts arise. <p> Turek et al. [40] and Prakash et al. [31] presented methodologies for transforming multiple lock concurrent objects into lock-free concurrent objects. Unfortunately, the performance of non-blocking algorithms resulting from general methodologies is acknowledged to be significantly inferior to that of the corresponding lock-based algorithms <ref> [13, 20, 33] </ref>. Two proposals for hardware support for general non-blocking data structures have been presented: transactional memory by Herlihy and Moss [14] and the Oklahoma update by Stone et al. [38]. Neither of these techniques has been implemented on a real machine.
Reference: [21] <author> L. Lamport. </author> <title> Specifying Concurrent Program Modules. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 5(2) </volume> <pages> 190-222, </pages> <month> April </month> <year> 1983. </year>
Reference-contexts: Hwang and Briggs [15], Sites [34], and Stone [37] presented lock-free algorithms based on compare-and-swap. These algorithms are incompletely specified; they omit important details such as the handling of empty or single-item queues, or concurrent enqueues and dequeues. Lamport <ref> [21] </ref> presented a wait-free algorithm that allows only a single enqueuer and a single dequeuer. 4 Gottlieb et al. [9] and Mellor-Crummey [24] presented algorithms that are lock-free but not non-blocking: they do not use locking mechanisms, but they allow a slow process to delay faster processes indefinitely.
Reference: [22] <author> B. D. Marsh, M. L. Scott, T. J. LeBlanc, and E. P. Markatos. </author> <title> First-Class User-Level Threads. </title> <booktitle> In Proceedings of the Thirteenth ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 110-121, </pages> <address> Pacific Grove, CA, </address> <month> October </month> <year> 1991. </year>
Reference-contexts: A process should yield the processor if it finds, upon leaving a critical section, that it was granted an extension. The first-class threads of Marsh et al.'s Psyche system <ref> [22] </ref> employ a different avoidance technique: they require the kernel to warn an application process a fixed amount of time in advance of preemption, by setting a flag that is visible in user space.
Reference: [23] <author> H. Massalin and C. Pu. </author> <title> A Lock-Free Multiprocessor OS Kernel. </title> <type> Technical Report CUCS-005-91, </type> <institution> Computer Science Department, Columbia University, </institution> <year> 1991. </year>
Reference-contexts: Simple non-blocking centralized counters can be implemented trivially using a fetch-and-add atomic primitive (if supported by hardware), or a read-modify-check-write cycle us ing compare-and-swap or load-linked/store-conditional. Figure 2 shows a non-blocking counter implementation using load-linked/store-conditional. 7 Massalin and Pu <ref> [23] </ref> presented non-blocking algorithms for array-based stacks, array-based queues, and linked lists. Unfortunately, their algorithms require double-compare-and-swap, a primitive that operates on two arbitrary memory locations simultaneously, and that appears to be available only on the Motorola 68020 processor and its direct descendants. <p> Treiber [39] presented an algorithm that is non-blocking but inefficient: a dequeue operation takes time proportional to the number of the elements in the queue. As mentioned above, Massalin and Pu <ref> [23] </ref> presented a non-blocking array-based algorithm based on double-compare-and-swap, a primitive available only on later members of the Motorola 68000 family of processors. Herlihy and Wing [10] presented an array-based algorithm that requires infinite arrays.
Reference: [24] <author> J. M. Mellor-Crummey. </author> <title> Concurrent Queues: Practical Fetch-and-F Algorithms. </title> <type> TR 229, </type> <institution> Computer Science Department, University of Rochester, </institution> <month> November </month> <year> 1987. </year> <month> 30 </month>
Reference-contexts: These algorithms are incompletely specified; they omit important details such as the handling of empty or single-item queues, or concurrent enqueues and dequeues. Lamport [21] presented a wait-free algorithm that allows only a single enqueuer and a single dequeuer. 4 Gottlieb et al. [9] and Mellor-Crummey <ref> [24] </ref> presented algorithms that are lock-free but not non-blocking: they do not use locking mechanisms, but they allow a slow process to delay faster processes indefinitely. <p> Valois's reference counting technique guarantees preventing the ABA problem without the need for modification counters or the double-word compare-and-swap. Mellor-Crummey's lock-free queue <ref> [24] </ref> requires no special precautions to avoid the ABA problem because it uses compare-and-swap in a fetch-and-store-modify-compare-and-swap sequence rather than the usual read-modifycompare-and-swap sequence. However, this same feature makes the algorithm blocking. 4.2 New Algorithms We present two concurrent queue algorithms inspired by ideas in the work described above. <p> preemption-safe locks (single ordinary lock and single safe lock); our two-lock algorithm, again using both ordinary and preemption-safe locks (two ordinary locks and two safe locks); our non-blocking algorithm (MS non-blocking) and those due to Prakash et al. [32] (PLJ non-blocking) and Valois [41] (Valois non-blocking); and Mellor-Crummey's blocking algorithm <ref> [24] </ref> (MC blocking). We include the algorithm of Prakash et al. because it appears to be the best of the known non-blocking alternatives.
Reference: [25] <author> J. M. Mellor-Crummey and M. L. Scott. </author> <title> Algorithms for Scalable Synchronization on Shared-Memory Multi--processors. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 9(1) </volume> <pages> 21-65, </pages> <month> February </month> <year> 1991. </year>
Reference-contexts: Preempting and scheduling processes in an order inconsistent with their order in the lock's queue can degrade performance dramatically. Kontothanassis et al. [18] present preemption-safe (or scheduler-conscious) versions of the ticket lock, the MCS lock <ref> [25] </ref>, and Krieger et al.'s reader-writer lock [19]. These algorithms detect the descheduling of critical processes using handshaking and/or a widened kernel-user interface, and use this information to avoid handing the lock to a preempted process. <p> All non-blocking algorithms also use bounded exponential backoff. The effectiveness of backoff in reducing contention on locks and synchronization data is demonstrated in the literature <ref> [2, 25] </ref>. The backoff was chosen to yield good overall performance for all algorithms, and not to exceed 30 s. We emulate both test and-set and compare-and-swap, using load-linked and store-conditional instructions, as shown in Figure 5.
Reference: [26] <author> M. M. Michael and M. L. Scott. </author> <title> Correction of a Memory Management Method for Lock-Free Data Structures. </title> <type> TR 599, </type> <institution> Computer Science Department, University of Rochester, </institution> <month> December </month> <year> 1995. </year>
Reference-contexts: We discovered and corrected <ref> [26] </ref> race conditions in the memory management mechanism and the associated non-blocking queue algorithm.
Reference: [27] <author> M. M. Michael and M. L. Scott. </author> <title> Implementation of General-Purpose Atomic Primitives for Distributed Shared-Memory Multiprocessors. </title> <booktitle> In Proceedings of the First International Symposium on High Performance Computer Architecture, </booktitle> <pages> pages 222-231, </pages> <address> Raleigh, NC, </address> <month> January </month> <year> 1995. </year>
Reference-contexts: The results are similar to those observed for queues and stacks, but are even more pronounced. The non-blocking algorithm outperforms the preemption-safe lock-based counter by more than 55% on 11 processors with various levels of multiprogramming. The performance of a fetch-and-add atomic primitive would be even better <ref> [27] </ref>. 5.5 Quicksort Application We performed experiments on two versions of a parallel quicksort application, one that uses a link-based queue, and another that uses a link-based stack for distributing items to be sorted among the cooperating processes.
Reference: [28] <author> M. M. Michael and M. L. Scott. </author> <title> Simple, Fast, and Practical Non-Blocking and Blocking Concurrent Queue Algorithms. </title> <booktitle> In Proceedings of the Fifteenth ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pages 267-275, </pages> <address> Philadelphia, PA, </address> <month> May </month> <year> 1996. </year>
Reference-contexts: We evaluate the relative performance of preemption-safe and non-blocking atomic update techniques on multiprogrammed (time-sliced) as well as dedicated multiprocessor systems. We focus on four important data structures: queues, stacks, heaps, and counters. For queues, we present fast new non-blocking and lock-based algorithms <ref> [28] </ref>. Our experimental results, employing both micro-benchmarks and real applications, on a 12-processor Silicon Graphics Challenge multiprocessor, indicate that our non-blocking queue algorithm outperforms existing algorithms under almost all circumstances.
Reference: [29] <author> M. M. Michael and M. L. Scott. </author> <title> Relative Performance of Preemption-Safe Locking and Non-Blocking Synchronization on Multiprogrammed Shared Memory Multiprocessors. </title> <booktitle> In Proceedings of the Eleventh International Parallel Processing Symposium, </booktitle> <address> Geneva, Switzerland, </address> <month> April </month> <year> 1997. </year>
Reference-contexts: In general, efficient data-structure-specific non-blocking algorithms outperform both ordinary and preemption-safe lock-based alternatives, not only on time-sliced systems, but on dedicated machines as well <ref> [29] </ref>. At the same time, preemption-safe algorithms outperform ordinary locks on time-sliced systems, and should therefore be supported by multiprocessor operating systems. We do not examine general-purpose non-blocking techniques in detail; previous work indicates that they are highly inefficient, though they provide a level of fault tolerance unavailable with locks.
Reference: [30] <author> J. K. Ousterhout. </author> <title> Scheduling Techniques for Concurrent Systems. </title> <booktitle> In Proceedings of the Third International Conference on Distributed Computing Systems, </booktitle> <pages> pages 22-30, </pages> <address> Miami/Ft. Lauderdale, FL, </address> <month> October </month> <year> 1982. </year>
Reference-contexts: Alternative multiprogramming schemes to time-slicing have been proposed in order to avoid the adverse effect of time-slicing on the performance of synchronization operations. However, each has limited applicability and/or reduces the utilization of the multiprocessor. Coscheduling <ref> [30] </ref>, ensures that all processes of an application run together. It has the disadvantage of reducing the utilization of the multiprocessor if applications have a variable amount of parallelism, or if processes cannot be evenly assigned to time-slices of the multiprocessor. <p> If it finds the flag is set, it can voluntarily yield the processor. Recovery-based preemption-safe locking techniques include the spin-then-block locks of Ousterhout <ref> [30] </ref> which let a waiting process spin for a certain period of time and thenif unsuccessful in entering the critical sectionblock, thus minimizing the adverse effect of waiting for a lock held by a descheduled process.
Reference: [31] <author> S. Prakash, Y. H. Lee, and T. Johnson. </author> <title> Non-Blocking Algorithms for Concurrent Data Structures. </title> <type> Technical Report 91-002, </type> <institution> Department of Computer and Information Sciences, University of Florida, </institution> <year> 1991. </year>
Reference-contexts: Shavit and Touitou [33] presented software transactional memory, which implements a k-word compare-and-swap using load-linked/store-conditional. Also, Anderson and Moir [5] presented non-blocking methodologies for large objects that rely on techniques for implementing multiple-word compare-and-swap using load-linked/store-conditional and vice versa. Turek et al. [40] and Prakash et al. <ref> [31] </ref> presented methodologies for transforming multiple lock concurrent objects into lock-free concurrent objects. Unfortunately, the performance of non-blocking algorithms resulting from general methodologies is acknowledged to be significantly inferior to that of the corresponding lock-based algorithms [13, 20, 33].
Reference: [32] <author> S. Prakash, Y. H. Lee, and T. Johnson. </author> <title> A Nonblocking Algorithm for Shared Queues Using Compare-and-Swap. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 43(5) </volume> <pages> 548-559, </pages> <month> May </month> <year> 1994. </year>
Reference-contexts: The algorithm uses one anchor pointer to manage the queue instead of the usual head and tail. Our experiments revealed a race condition in which a slow dequeuer can cause an enqueued item to be lost permanently. Prakash, Lee, and Johnson <ref> [32] </ref> presented a linearizable non-blocking algorithm that uses a singly-linked list to represent the queue with Head and Tail pointers. It uses compare-and-swap to enqueue and dequeue nodes at the tail and the head of the list, respectively. <p> The eight implementations are: the usual single-lock algorithm using both ordinary and preemption-safe locks (single ordinary lock and single safe lock); our two-lock algorithm, again using both ordinary and preemption-safe locks (two ordinary locks and two safe locks); our non-blocking algorithm (MS non-blocking) and those due to Prakash et al. <ref> [32] </ref> (PLJ non-blocking) and Valois [41] (Valois non-blocking); and Mellor-Crummey's blocking algorithm [24] (MC blocking). We include the algorithm of Prakash et al. because it appears to be the best of the known non-blocking alternatives.
Reference: [33] <author> N. Shavit and D. Touitou. </author> <title> Software Transactional Memory. </title> <booktitle> In Proceedings of the Fourteenth ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pages 204-213, </pages> <address> Ottawa, Ontario, Canada, </address> <month> August </month> <year> 1995. </year>
Reference-contexts: Barnes [6] presented a general methodology in which processes record and timestamp their modifications to the shared object, and cooperate whenever conflicts arise. Shavit and Touitou <ref> [33] </ref> presented software transactional memory, which implements a k-word compare-and-swap using load-linked/store-conditional. Also, Anderson and Moir [5] presented non-blocking methodologies for large objects that rely on techniques for implementing multiple-word compare-and-swap using load-linked/store-conditional and vice versa. <p> Turek et al. [40] and Prakash et al. [31] presented methodologies for transforming multiple lock concurrent objects into lock-free concurrent objects. Unfortunately, the performance of non-blocking algorithms resulting from general methodologies is acknowledged to be significantly inferior to that of the corresponding lock-based algorithms <ref> [13, 20, 33] </ref>. Two proposals for hardware support for general non-blocking data structures have been presented: transactional memory by Herlihy and Moss [14] and the Oklahoma update by Stone et al. [38]. Neither of these techniques has been implemented on a real machine.
Reference: [34] <author> R. </author> <title> Sites. Operating Systems and Computer Architecture. </title> <editor> In H. Stone, editor, </editor> <title> Introduction to Computer Architecture, </title> <note> page chapter 12. Science Research Associates, second edition, </note> <year> 1980. </year>
Reference-contexts: Our presentation includes two new concurrent queue algorithms. One is non-blocking; the other uses a pair of mutual exclusion locks. 4 Concurrent Queue Algorithms 4.1 Discussion of Previous Work Many researchers have proposed lock-free algorithms for concurrent queues. Hwang and Briggs [15], Sites <ref> [34] </ref>, and Stone [37] presented lock-free algorithms based on compare-and-swap. These algorithms are incompletely specified; they omit important details such as the handling of empty or single-item queues, or concurrent enqueues and dequeues. <p> non-blocking queue algorithm that avoids the contention caused by the snapshots of Prakash et al.'s algorithm and allows more concurrency by keeping a dummy node at the head (dequeue end) of a singly-linked list, thus simplifying the special cases associated with empty and single-item queues (a technique suggested by Sites <ref> [34] </ref>). Unfortunately, the algorithm allows the tail pointer to lag behind the head pointer, thus preventing dequeuing processes from safely freeing or re-using dequeued nodes.
Reference: [35] <author> J. M. Stone. </author> <title> A Simple and Correct Shared-Queue Algorithm Using Compare-and-Swap. </title> <booktitle> In Proceedings, Supercomputing '90, </booktitle> <address> New York, NY, </address> <month> November </month> <year> 1990. </year> <month> 31 </month>
Reference-contexts: Valois [41] presented an array-based algorithm that requires either an unaligned compare-and-swap (not supported on any architecture) or a Motorola-like double-compare-and-swap. 4 A wait-free algorithm is both non-blocking and starvation free: it guarantees that every active process will make progress within a bounded number of time steps. 8 Stone <ref> [35] </ref> presented a queue that is lock-free but non-linearizable 5 and not non-blocking. It is non-linearizable because a slow enqueuer may cause a faster process to enqueue an item and subsequently observe an empty queue, even though the enqueued item has never been dequeued.
Reference: [36] <author> J. M. Stone. </author> <title> A Non-Blocking Compare-and-Swap Algorithm for a Shared Circular Queue. </title> <editor> In S. Txafestas and others, editors, </editor> <booktitle> Parallel and Distributed Computing in Engineering Systems, </booktitle> <pages> pages 147-152. </pages> <publisher> Elsevier Science Publishers, </publisher> <year> 1992. </year>
Reference-contexts: Our experiments also revealed a race condition in which a certain interleaving of a slow dequeue with faster enqueues and dequeues by other process (es) can cause an enqueued item to be lost permanently. Stone also presented <ref> [36] </ref> a non-blocking queue based on a circular singly-linked list. The algorithm uses one anchor pointer to manage the queue instead of the usual head and tail. Our experiments revealed a race condition in which a slow dequeuer can cause an enqueued item to be lost permanently.
Reference: [37] <author> H. S. Stone. </author> <title> High Performance Computer Architecture. </title> <publisher> Addison-Wesley, </publisher> <year> 1993. </year>
Reference-contexts: Our presentation includes two new concurrent queue algorithms. One is non-blocking; the other uses a pair of mutual exclusion locks. 4 Concurrent Queue Algorithms 4.1 Discussion of Previous Work Many researchers have proposed lock-free algorithms for concurrent queues. Hwang and Briggs [15], Sites [34], and Stone <ref> [37] </ref> presented lock-free algorithms based on compare-and-swap. These algorithms are incompletely specified; they omit important details such as the handling of empty or single-item queues, or concurrent enqueues and dequeues.
Reference: [38] <author> J. M. Stone, H. S. Stone, P. Heidelberger, and J. Turek. </author> <title> Multiple Reservations and the Oklahoma Update. </title> <journal> IEEE Parallel and Distributed Technology, </journal> <volume> 1(5) </volume> <pages> 58-71, </pages> <month> November </month> <year> 1993. </year>
Reference-contexts: Two proposals for hardware support for general non-blocking data structures have been presented: transactional memory by Herlihy and Moss [14] and the Oklahoma update by Stone et al. <ref> [38] </ref>. Neither of these techniques has been implemented on a real machine. The simulation-based experimental results of Herlihy and Moss show performance significantly inferior to that of spin locks.
Reference: [39] <author> R. K. Treiber. </author> <title> Systems Programming: Coping with Parallelism. </title> <type> RJ 5118, </type> <institution> IBM Almaden Research Center, </institution> <month> April </month> <year> 1986. </year>
Reference-contexts: Neither of these techniques has been implemented on a real machine. The simulation-based experimental results of Herlihy and Moss show performance significantly inferior to that of spin locks. Stone et al. did not present experimental results. 3.2 Data-Structure-Specific Non-Blocking Algorithms Treiber <ref> [39] </ref> proposed a non-blocking implementation of concurrent link-based stacks. It represents the stack as a singly-linked list with a Top pointer. It uses compare-and-swap to modify the value of Top atomically. Commented pseudo-code of Treiber's non-blocking stack algorithm is presented in Figure 1. <p> Treiber <ref> [39] </ref> presented an algorithm that is non-blocking but inefficient: a dequeue operation takes time proportional to the number of the elements in the queue. <p> A similar technique can be used to prevent the race condition 10 in Stone's blocking algorithm. A simple and efficient non-blocking stack algorithm due to Treiber <ref> [39] </ref> can be used to implement a non-blocking free list. employs separate Head and Tail locks, to allow complete concurrency between enqueues and dequeues. As in the non-blocking queue, we keep a dummy node at the beginning of the list. <p> Table 2 shows performance on a dedicated processorthe left-most points in the top-most graph. The four stack implementations are: the usual single lock algorithm using ordinary and preemption-safe locks, Treiber's non-blocking stack algorithm <ref> [39] </ref>, and an optimized non-blocking algorithm based on Herlihy's general methodology [13]. Like Treiber's non-blocking stack algorithm, the optimized algorithm based on Herlihy's methodology uses a singly-linked list to represent the stack with a Top pointer.
Reference: [40] <author> J. Turek, D. Shasha, and S. Prakash. </author> <title> Locking Without Blocking: Making Lock Based Concurrent Data Structure Algorithms Nonblocking. </title> <booktitle> In Proceedings of the Eleventh ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems, </booktitle> <pages> pages 212-222, </pages> <address> Vancouver, BC, Canada, </address> <month> August </month> <year> 1992. </year>
Reference-contexts: Shavit and Touitou [33] presented software transactional memory, which implements a k-word compare-and-swap using load-linked/store-conditional. Also, Anderson and Moir [5] presented non-blocking methodologies for large objects that rely on techniques for implementing multiple-word compare-and-swap using load-linked/store-conditional and vice versa. Turek et al. <ref> [40] </ref> and Prakash et al. [31] presented methodologies for transforming multiple lock concurrent objects into lock-free concurrent objects. Unfortunately, the performance of non-blocking algorithms resulting from general methodologies is acknowledged to be significantly inferior to that of the corresponding lock-based algorithms [13, 20, 33].
Reference: [41] <author> J. D. Valois. </author> <title> Implementing Lock-Free Queues. </title> <booktitle> In Proceedings of the Seventh International Conference on Parallel and Distributed Computing Systems, </booktitle> <address> Las Vegas, NV, </address> <month> October </month> <year> 1994. </year>
Reference-contexts: As mentioned above, Massalin and Pu [23] presented a non-blocking array-based algorithm based on double-compare-and-swap, a primitive available only on later members of the Motorola 68000 family of processors. Herlihy and Wing [10] presented an array-based algorithm that requires infinite arrays. Valois <ref> [41] </ref> presented an array-based algorithm that requires either an unaligned compare-and-swap (not supported on any architecture) or a Motorola-like double-compare-and-swap. 4 A wait-free algorithm is both non-blocking and starvation free: it guarantees that every active process will make progress within a bounded number of time steps. 8 Stone [35] presented a <p> If so it tries to complete the ongoing operation and then takes another snapshot of the data structure. Otherwise it tries to complete its own operation. The process keeps trying until it completes its operation. Valois <ref> [41, 42] </ref> presented a list-based non-blocking queue algorithm that avoids the contention caused by the snapshots of Prakash et al.'s algorithm and allows more concurrency by keeping a dummy node at the head (dequeue end) of a singly-linked list, thus simplifying the special cases associated with empty and single-item queues (a <p> usual single-lock algorithm using both ordinary and preemption-safe locks (single ordinary lock and single safe lock); our two-lock algorithm, again using both ordinary and preemption-safe locks (two ordinary locks and two safe locks); our non-blocking algorithm (MS non-blocking) and those due to Prakash et al. [32] (PLJ non-blocking) and Valois <ref> [41] </ref> (Valois non-blocking); and Mellor-Crummey's blocking algorithm [24] (MC blocking). We include the algorithm of Prakash et al. because it appears to be the best of the known non-blocking alternatives.
Reference: [42] <author> J. D. Valois. </author> <title> Lock-Free Data Structures. </title> <publisher> Ph. </publisher> <address> D. </address> <institution> dissertation, Rensselaer Polytechnic Institute, </institution> <month> May </month> <year> 1995. </year>
Reference-contexts: If so it tries to complete the ongoing operation and then takes another snapshot of the data structure. Otherwise it tries to complete its own operation. The process keeps trying until it completes its operation. Valois <ref> [41, 42] </ref> presented a list-based non-blocking queue algorithm that avoids the contention caused by the snapshots of Prakash et al.'s algorithm and allows more concurrency by keeping a dummy node at the head (dequeue end) of a singly-linked list, thus simplifying the special cases associated with empty and single-item queues (a
Reference: [43] <author> J. D. Valois. </author> <title> Lock-Free Linked Lists Using Compare-and-Swap. </title> <booktitle> In Proceedings of the Fourteenth ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pages 214-222, </pages> <address> Ottawa, Ontario, Canada, </address> <month> August </month> <year> 1995. </year>
Reference-contexts: However, Treiber's stack is very simple and can be expected to be quite efficient. We also observe that a stack derived from Herlihy's general methodology, with unnecessary copying removed, seems to be simple enough to compete with lock-based algorithms. Valois <ref> [43] </ref> proposed a non-blocking implementation of linked lists. Anderson and Woll [3] proposed a non blocking solution to the union-find problem. Simple non-blocking centralized counters can be implemented trivially using a fetch-and-add atomic primitive (if supported by hardware), or a read-modify-check-write cycle us ing compare-and-swap or load-linked/store-conditional.
Reference: [44] <author> J. Zahorjan, E. D. Lazowska, and D. L. Eager. </author> <title> The Effect of Scheduling Discipline on Spin Overhead in Shared Memory Parallel Systems. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 2(2) </volume> <pages> 180-198, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: In order to achieve acceptable response time and high utilization, most multiprocessors are multiprogrammed by time-slicing processors among processes. The performance of mutual exclusion locks in parallel applications degrades significantly on time-slicing multiprogrammed systems <ref> [44] </ref> due to the preemption of processes holding locks. Any other processes busy-waiting on the lock are then unable to perform useful work until the preempted process is rescheduled and subsequently releases the lock.
References-found: 44

