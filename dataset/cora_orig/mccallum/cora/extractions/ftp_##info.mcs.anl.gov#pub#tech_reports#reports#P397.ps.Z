URL: ftp://info.mcs.anl.gov/pub/tech_reports/reports/P397.ps.Z
Refering-URL: http://www.mcs.anl.gov/publications/abstracts/abstracts93.htm
Root-URL: http://www.mcs.anl.gov
Title: Parallel language constructs for paradigm integration and deterministic computations  
Author: K. M. Chandy a and I. T. Foster b 
Date: January 1994.  
Address: Argonne, Ill.,  256-80, Pasadena, California 91125, U.S.A.  Illinois 60439, U.S.A.  
Affiliation: Mathematics and Computer Science Division, Argonne National Laboratory,  a Department of Computer Science, California Institute of Technology,  b Mathematics and Computer Science Division, Argonne National Laboratory, Argonne,  
Note: Preprint MCS-P397-1193,  
Abstract: We describe parallel extensions of sequential programming languages for writing programs that integrate different programming paradigms and that execute in heterogeneous environments comprising both distributed and shared memory. The extensions can be used to write programs with dynamic process and communication structures. Programs can use shared-memory, message passing, and data parallel programming paradigms, and can be written in a way that permits the compiler and run-time system to verify that they are deterministic. The extensions also provide the programmer with control over how data and processes are mapped to processors, and hence how computational resources are allocated to different parts of a program. A subset of these ideas has been incorporated in an extension to Fortran called Fortran M. However, the underlying sequential notation is not central to the ideas. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Boyle, J., R. Butler, T. Disz, B. Glickfield, E. Lusk, R. Overbeek, J. Patterson, and R. Stevens, </author> <title> Portable Programs for Parallel Processors, </title> <publisher> Holt, Rinehart and Winston, </publisher> <year> 1987. </year>
Reference-contexts: Since Fortran M compiles to Fortran, powerful Fortran optimizing compilers available on most platforms can be used to advantage. Furthermore, the central ideas of this paper can be used with other sequential imperative languages. A comparison of Fortran M with parallel programs using message-passing libraries such as P4 <ref> [1] </ref> or PVM [14] is also instructive. A focus of Fortran M is the development of reliable programs by (i) separating deterministic and nondeterministic components (and allowing simpler reasoning and debugging for the deterministic parts) and (ii) type-checking messages (since channels are typed).
Reference: [2] <author> Cann, D. C., J. T. Feo, and T. M. DeBoni, </author> <title> Sisal 1,2: High Performance Applicative Computing, </title> <booktitle> Proc. Symp. Parallel and Distributed Processing, </booktitle> <publisher> IEEE CS Press, Los Alamitos, </publisher> <address> Calif., </address> <year> 1990, </year> <pages> 612-616. </pages>
Reference-contexts: Nondeterministic constructs can be included, if required. A comparison of Fortran M with data-parallel languages [15, 10] and high-level languages <ref> [2] </ref> highlights some of the weaknesses and strengths of our approach. Fortran M employs processes explicitly, and uses explicit exchange of tokens between processes. Care must be taken by the Fortran M programmer to avoid starvation: processes waiting for tokens that never arrive. <p> Some of this work could be handled automatically by a compiler using data-flow technology. Data-parallel languages [15, 10] and applicative languages <ref> [2] </ref> do not require the programmer to deal with processes, messages or tokens. A weakness of Fortran M is that it is a small extension of Fortran, a sequential imperative language, whereas high-level languages such as Id and Sisal are designed from the outset to be functional.
Reference: [3] <author> Chandy, K. M. and I. Foster, </author> <title> A Deterministic Notation for Cooperating Processes, </title> <type> Preprint MCS-P346-0193, </type> <institution> Mathematics and Computer Science Division, Argonne National Laboratory, Argonne, Ill. </institution> <month> 60439, </month> <year> 1993. </year>
Reference-contexts: FORTRAN M For concreteness, we outline how channels, deterministic shared variables, and data parallelism are incorporated into a sequential programming language (Fortran). The presentation is necessarily somewhat simplified; for details, see <ref> [8, 3] </ref>.
Reference: [4] <author> Chandy, K. M., I. Foster, K. Kennedy, C. Koelbel, and C.-W. Tseng, </author> <title> Integrated Support for Task and Data Parallelism, </title> <note> Intl J. Supercomputer Applications (to appear). </note>
Reference-contexts: Hence, operations on a distributed array may require communication. Data-distribution statements allow FM programs to specify certain classes of data-parallel computations. A complimentary approach to the integration of data parallelism is to allow Fortran M programs to call data parallel programs, written for example in Fortran D <ref> [4] </ref>. 4.4. Resource management Resource management constructs allow the programmer to specify how processes and distributed data are to be mapped to processors and hence how computational resources are to be allocated to different parts of a program [9]. These constructs influence performance but not the result computed.
Reference: [5] <author> Church, A. and J. B. Rosser, </author> <title> Some Properties of Conversion, </title> <journal> Trans. American Math. Soc., </journal> <volume> 39, </volume> <year> 1936, </year> <pages> 472-482. </pages>
Reference-contexts: DETERMINISM Our approach to achieving determinism is based on the diamond property and the Church-Rosser theorem <ref> [5, 13] </ref>, well-known in functional programming. 2.1 Theory Let G be a labeled directed graph, where each edge of the graph has a single label, and for each vertex v and each label l there is at most one edge directed from v with label l. <p> If there are edges from a vertex v with distinct labels l and r, then there are paths l; r and r; l from v, and both paths end at the same vertex; see Figure 1. The 2 following theorem is proved in <ref> [5, 13] </ref>. <p> EARLIER WORK The work described in this paper integrates well-known ideas about the Church-Rosser theorem <ref> [5, 13] </ref>, capabilities [7, 6], channels [11], and distributed shared memory [12]. An implementation in a widely-used sequential language (Fortran) provides a parallel notation that supports (i) dynamic process structures, (ii) paradigm integration and (iii) compiler verification of determinism, and that runs on multicomputer networks or (weakly-coherent) shared-memory systems.
Reference: [6] <author> Cohen, E. and D. Jefferson, </author> <title> Protection in the Hydra Operating System, </title> <booktitle> Proc. 5th Symp. Operating Systems Principles, ACM, </booktitle> <year> 1975, </year> <pages> 141-150. </pages>
Reference-contexts: Likewise, a process can receive a message from a channel if and only if it holds the receiver token for the channel. Thus the sender and receiver tokens are capabilities that confer certain rights to the holder of the tokens <ref> [7, 6] </ref>. The send command is nonblocking, and the receive command is blocking. The state of a channel is a queue of messages. Sending a message m on a channel appends m to the tail of the queue of messages in the channel. <p> EARLIER WORK The work described in this paper integrates well-known ideas about the Church-Rosser theorem [5, 13], capabilities <ref> [7, 6] </ref>, channels [11], and distributed shared memory [12]. An implementation in a widely-used sequential language (Fortran) provides a parallel notation that supports (i) dynamic process structures, (ii) paradigm integration and (iii) compiler verification of determinism, and that runs on multicomputer networks or (weakly-coherent) shared-memory systems.
Reference: [7] <author> Dennis, J. B., and E. C. Van Horn, </author> <title> Programming Semantics for Multiprogrammed Computations, </title> <journal> Comm. ACM, </journal> <volume> 9, </volume> <year> 1966, </year> <pages> 143-155. </pages>
Reference-contexts: Likewise, a process can receive a message from a channel if and only if it holds the receiver token for the channel. Thus the sender and receiver tokens are capabilities that confer certain rights to the holder of the tokens <ref> [7, 6] </ref>. The send command is nonblocking, and the receive command is blocking. The state of a channel is a queue of messages. Sending a message m on a channel appends m to the tail of the queue of messages in the channel. <p> EARLIER WORK The work described in this paper integrates well-known ideas about the Church-Rosser theorem [5, 13], capabilities <ref> [7, 6] </ref>, channels [11], and distributed shared memory [12]. An implementation in a widely-used sequential language (Fortran) provides a parallel notation that supports (i) dynamic process structures, (ii) paradigm integration and (iii) compiler verification of determinism, and that runs on multicomputer networks or (weakly-coherent) shared-memory systems.
Reference: [8] <author> Foster, I. and K. M. Chandy, </author> <title> Fortran M: A Language for Modular Parallel Programming, </title> <type> Preprint MCS-P327-0992, </type> <institution> Argonne National Laboratory, Argonne Ill. </institution> <month> 60439, </month> <year> 1992. </year>
Reference-contexts: FORTRAN M For concreteness, we outline how channels, deterministic shared variables, and data parallelism are incorporated into a sequential programming language (Fortran). The presentation is necessarily somewhat simplified; for details, see <ref> [8, 3] </ref>. <p> The PROCESSORS declaration specifies the shape and dimension of a processor array, the LOCATION annotation maps processes to specified elements of this array and the SUBMACHINE annotation specifies that a process should execute in a subset of the array <ref> [8] </ref>. 8 5. EARLIER WORK The work described in this paper integrates well-known ideas about the Church-Rosser theorem [5, 13], capabilities [7, 6], channels [11], and distributed shared memory [12].
Reference: [9] <author> Foster, I., R. Olson, and S. Tuecke, </author> <title> Productive Parallel Programming: The PCN Approach, </title> <journal> Scientific Programming, </journal> <volume> 1(1), </volume> <year> 1992. </year>
Reference-contexts: Resource management Resource management constructs allow the programmer to specify how processes and distributed data are to be mapped to processors and hence how computational resources are to be allocated to different parts of a program <ref> [9] </ref>. These constructs influence performance but not the result computed. Hence, a program can be developed on a uniprocessor and then tuned on a parallel computer by changing only mapping constructs.
Reference: [10] <author> Fox, G., S. Hiranandani, K. Kennedy, C. Koelbel, U. Kremer, C. Tseng, M.Wu, </author> <title> Fortran D Language Specification, </title> <type> Technical Report TR90-141, </type> <institution> Computer Science, Rice Univ., Houston, TX, </institution> <year> 1990. </year>
Reference-contexts: Data parallel programming languages often allow the programmer to specify (a) how data is distributed over processors, and (b) the computation that is to be performed on each data item; the compiler then determines what computation and communication should be performed at each processor <ref> [15, 10] </ref>. We allow individual processes to execute programs written in a data-parallel notation. These programs may create distributed data structures which are local to that process. They may interact with other (data or task parallel) computations by operating on arrays of channels or deterministic shared variables. <p> If y is NULL before the receive, then after the receive y references the same data item as MSG, and the number of tokens corresponding to y held by the receiver is the number of tokens in the message. 4.3 Data parallelism Programs can use data distribution statements <ref> [10] </ref> to create distributed arrays. Semantically, distributed arrays are indistinguishable from nondistributed arrays. That is, they are accessible only to the process in which they are declared and are passed by value to subprocesses. <p> Nondeterministic constructs can be included, if required. A comparison of Fortran M with data-parallel languages <ref> [15, 10] </ref> and high-level languages [2] highlights some of the weaknesses and strengths of our approach. Fortran M employs processes explicitly, and uses explicit exchange of tokens between processes. Care must be taken by the Fortran M programmer to avoid starvation: processes waiting for tokens that never arrive. <p> Some of this work could be handled automatically by a compiler using data-flow technology. Data-parallel languages <ref> [15, 10] </ref> and applicative languages [2] do not require the programmer to deal with processes, messages or tokens.
Reference: [11] <author> Hoare, C. A. R., </author> <title> Communicating Sequential Processes, </title> <journal> Comm. ACM, </journal> <volume> 21(8), </volume> <year> 1969, </year> <pages> 666-677. </pages>
Reference-contexts: EARLIER WORK The work described in this paper integrates well-known ideas about the Church-Rosser theorem [5, 13], capabilities [7, 6], channels <ref> [11] </ref>, and distributed shared memory [12]. An implementation in a widely-used sequential language (Fortran) provides a parallel notation that supports (i) dynamic process structures, (ii) paradigm integration and (iii) compiler verification of determinism, and that runs on multicomputer networks or (weakly-coherent) shared-memory systems. Nondeterministic constructs can be included, if required.
Reference: [12] <author> Li, K., and P. Hudak, </author> <title> Memory Coherence in Shared Virtual Memory Systems, </title> <journal> ACM Trans. Comp. Systems, </journal> <volume> 7(4), </volume> <year> 1989, </year> <pages> 321-359. </pages>
Reference-contexts: EARLIER WORK The work described in this paper integrates well-known ideas about the Church-Rosser theorem [5, 13], capabilities [7, 6], channels [11], and distributed shared memory <ref> [12] </ref>. An implementation in a widely-used sequential language (Fortran) provides a parallel notation that supports (i) dynamic process structures, (ii) paradigm integration and (iii) compiler verification of determinism, and that runs on multicomputer networks or (weakly-coherent) shared-memory systems. Nondeterministic constructs can be included, if required.
Reference: [13] <author> McLennan, B. J., </author> <title> Functional Programming: Practice and Theory, </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Mass. </address> <year> 1990 </year>
Reference-contexts: DETERMINISM Our approach to achieving determinism is based on the diamond property and the Church-Rosser theorem <ref> [5, 13] </ref>, well-known in functional programming. 2.1 Theory Let G be a labeled directed graph, where each edge of the graph has a single label, and for each vertex v and each label l there is at most one edge directed from v with label l. <p> If there are edges from a vertex v with distinct labels l and r, then there are paths l; r and r; l from v, and both paths end at the same vertex; see Figure 1. The 2 following theorem is proved in <ref> [5, 13] </ref>. <p> EARLIER WORK The work described in this paper integrates well-known ideas about the Church-Rosser theorem <ref> [5, 13] </ref>, capabilities [7, 6], channels [11], and distributed shared memory [12]. An implementation in a widely-used sequential language (Fortran) provides a parallel notation that supports (i) dynamic process structures, (ii) paradigm integration and (iii) compiler verification of determinism, and that runs on multicomputer networks or (weakly-coherent) shared-memory systems.
Reference: [14] <author> Sunderam, V., </author> <title> PVM: A Framework for Parallel Distributed Computing, </title> <journal> Concurrency Practice and Experience, </journal> <volume> 2, </volume> <year> 1990, </year> <pages> 315-339. </pages>
Reference-contexts: Furthermore, the central ideas of this paper can be used with other sequential imperative languages. A comparison of Fortran M with parallel programs using message-passing libraries such as P4 [1] or PVM <ref> [14] </ref> is also instructive. A focus of Fortran M is the development of reliable programs by (i) separating deterministic and nondeterministic components (and allowing simpler reasoning and debugging for the deterministic parts) and (ii) type-checking messages (since channels are typed).
Reference: [15] <author> Thinking Machines Corporation, </author> <title> CM Fortran Reference Manual, Thinking Machines, </title> <address> Cambridge, Mass., </address> <year> 1989. </year> <month> 10 </month>
Reference-contexts: Data parallel programming languages often allow the programmer to specify (a) how data is distributed over processors, and (b) the computation that is to be performed on each data item; the compiler then determines what computation and communication should be performed at each processor <ref> [15, 10] </ref>. We allow individual processes to execute programs written in a data-parallel notation. These programs may create distributed data structures which are local to that process. They may interact with other (data or task parallel) computations by operating on arrays of channels or deterministic shared variables. <p> Nondeterministic constructs can be included, if required. A comparison of Fortran M with data-parallel languages <ref> [15, 10] </ref> and high-level languages [2] highlights some of the weaknesses and strengths of our approach. Fortran M employs processes explicitly, and uses explicit exchange of tokens between processes. Care must be taken by the Fortran M programmer to avoid starvation: processes waiting for tokens that never arrive. <p> Some of this work could be handled automatically by a compiler using data-flow technology. Data-parallel languages <ref> [15, 10] </ref> and applicative languages [2] do not require the programmer to deal with processes, messages or tokens.
References-found: 15

