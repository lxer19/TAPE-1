URL: http://www.cs.umn.edu/Users/dept/users/du/papers/pvm-hippi.ps
Refering-URL: http://www.cs.umn.edu/Users/dept/users/du/papers/
Root-URL: http://www.cs.umn.edu
Title: Enhanced PVM Communications over a HIPPI Local Area Network  
Author: Jenwei Hsieh, David H.C. Du, Norman J. Troullier Mengjou Lin 
Affiliation: Distributed Multimedia Research Center 2 and Computer Science Department, University of Minnesota  Advanced Technology Group, Apple Computer, Inc.  
Abstract: With the emergence of switch-based high-speed local area networks (such as HIPPI, ATM, and Fibre Channel) and powerful workstations, distributed network computing becomes more feasible for large-scale scientific and engineering applications. Most of the distributed algorithms are implemented based on the message passing model. In a local area network environment, fast message passing can be achieved by employing high-speed networks and reducing the overhead of protocol processing. In this paper, we present a study of improving Parallel Virtual Machine's (PVM) communication performance over a HIPPI local area network. After a detailed examination of PVM's communication subsystem, we re-implemented PVM using the Hewlett Packard's Link Level Access (LLA) interface instead of the BSD socket interface which was originally used by PVM. From the experimental results of the performance evaluation, our study demonstrates the potential and feasibility of high-performance network computing over a high-speed switch-based local area network. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Beguelin, A., Dongarra, J., Geist, A., Manchek,R., Sunderam, V., </author> <title> "A User's Guide to PVM (Parallel Virtual Machine)", </title> <type> Technical Report ORNL/TM-11826, </type> <institution> Oak Ridge National Laboratory, Oak Ridge, TN, </institution> <month> July </month> <year> 1991. </year>
Reference-contexts: Distributed applications utilize the computational power and communication facility of the cluster by using special libraries provided by the software framework. Those libraries usually support process management, synchronization, and message passing based on standard network protocols. Examples of such software framework are PVM <ref> [1, 5, 14] </ref>, P4 [2], Express [11], Linda [3], and MPI [15]. <p> The performance of the enhanced communications of PVM over a HIPPI network is discussed in Section 5. Finally, Section 6 concludes this paper and discusses future work. 2 An Overview of the PVM and HIPPI Networks 3 2.1 PVM: A Parallel Programming Environment PVM <ref> [1, 5, 14] </ref> is a software system for the development and execution of parallel applications. It allows an interconnected collection of independent heterogeneous computers to appear as a single virtual computational resource or a single parallel machine. The independent machines may be ordinary workstations, multiprocessors, supercomputers, or specialized processors.
Reference: [2] <author> Bulter, R. and Lusk, E., </author> <title> "User's Guide to the P4 Programming System", </title> <type> Technical Report ANL-92/17, </type> <institution> Argonne National Laboratory, </institution> <year> 1992. </year>
Reference-contexts: Distributed applications utilize the computational power and communication facility of the cluster by using special libraries provided by the software framework. Those libraries usually support process management, synchronization, and message passing based on standard network protocols. Examples of such software framework are PVM [1, 5, 14], P4 <ref> [2] </ref>, Express [11], Linda [3], and MPI [15].
Reference: [3] <author> Carriero, N. and Gelernter, D., </author> <title> "Linda in Context", </title> <journal> Communications of the ACM, </journal> <volume> 32(4), </volume> <pages> pp. 444-458, </pages> <month> April </month> <year> 1989. </year> <month> 19 </month>
Reference-contexts: Those libraries usually support process management, synchronization, and message passing based on standard network protocols. Examples of such software framework are PVM [1, 5, 14], P4 [2], Express [11], Linda <ref> [3] </ref>, and MPI [15].
Reference: [4] <author> Sheue-Ling Chang, David H.C. Du, Jenwei Hsieh, Mengjou Lin, Rose P. Tsang, </author> <title> "Enhanced PVM Communications over a High-Speed Local Area Network", </title> <booktitle> IEEE Parallel and Distributed Technology, </booktitle> <month> Fall </month> <year> 1995. </year>
Reference-contexts: For portability reason, PVM only assumes that the underlying network has point-to-point communication mechanism. The multicast function was implemented by invoking a sequential series of send primitives. A previous study has demonstrated that PVM can be re-implemented to take advantage of the inherent multicast nature of ATM networks <ref> [4] </ref>. PVM's implementation of mul-ticast communications replies on both Task-Daemon protocol and Daemon-Daemon protocol. We will use Figure 4 to explain the two-phase implementation of multicasting communications. * Phase I: Set up a multicasting connection.
Reference: [5] <author> Geist, G.A., Sunderam, </author> <title> V.S., "Network-Based Concurrent Computing on the PVM System", </title> <journal> Concur-rency: Practice and Experience, </journal> <volume> 4 </volume> (4):293-311, June 1992. 
Reference-contexts: Distributed applications utilize the computational power and communication facility of the cluster by using special libraries provided by the software framework. Those libraries usually support process management, synchronization, and message passing based on standard network protocols. Examples of such software framework are PVM <ref> [1, 5, 14] </ref>, P4 [2], Express [11], Linda [3], and MPI [15]. <p> The performance of the enhanced communications of PVM over a HIPPI network is discussed in Section 5. Finally, Section 6 concludes this paper and discusses future work. 2 An Overview of the PVM and HIPPI Networks 3 2.1 PVM: A Parallel Programming Environment PVM <ref> [1, 5, 14] </ref> is a software system for the development and execution of parallel applications. It allows an interconnected collection of independent heterogeneous computers to appear as a single virtual computational resource or a single parallel machine. The independent machines may be ordinary workstations, multiprocessors, supercomputers, or specialized processors.
Reference: [6] <author> ANSI X3.183-1991. </author> <title> "High-Performance Parallel Interface: Mechanical, Electrical, and Signaling Protocol Specification (HIPPI-PH)". </title> <publisher> American National Standard Institute, Inc., </publisher> <month> June </month> <year> 1991. </year>
Reference-contexts: The second approach is discussed in much greater detail throughout the rest of this paper. In this study, we utilized both approaches to demonstrate the potential and feasibility of distributed network computing over a high-speed switch-based local area network. For the underlying high-speed network, we used the HIPPI <ref> [6, 7, 8, 9] </ref> as the switch-based network platform. HIPPI offers a connection-oriented service with peak data transmission rates of 800 or 1600 Mbits/sec. HIPPI is a mature technology, which is widely used in most supercomputers and many high-end workstations. <p> Also, in general, there do not exist interesting algorithms which can make use of hundreds of relatively fast processors interconnected by a low-speed network. The growing availability of high-speed networks may make very large virtual machines more likely and feasible. 2.2 HIPPI Networks The High-Performance Parallel Interface (HIPPI) <ref> [6, 7, 8, 9] </ref> is one of the high-speed network or channel solutions commercially available. HIPPI is a simplex point-to-point interface for transferring data at peak rates of 800 or 1600 Mbits/sec over distances of up to 25 meters.
Reference: [7] <author> ANSI X3.210-1992. </author> <title> "High-Performance Parallel Interface: Framing Protocol (HIPPI-FP)". </title> <publisher> American National Standard Institute, Inc., </publisher> <month> Feb. </month> <year> 1992. </year>
Reference-contexts: The second approach is discussed in much greater detail throughout the rest of this paper. In this study, we utilized both approaches to demonstrate the potential and feasibility of distributed network computing over a high-speed switch-based local area network. For the underlying high-speed network, we used the HIPPI <ref> [6, 7, 8, 9] </ref> as the switch-based network platform. HIPPI offers a connection-oriented service with peak data transmission rates of 800 or 1600 Mbits/sec. HIPPI is a mature technology, which is widely used in most supercomputers and many high-end workstations. <p> Also, in general, there do not exist interesting algorithms which can make use of hundreds of relatively fast processors interconnected by a low-speed network. The growing availability of high-speed networks may make very large virtual machines more likely and feasible. 2.2 HIPPI Networks The High-Performance Parallel Interface (HIPPI) <ref> [6, 7, 8, 9] </ref> is one of the high-speed network or channel solutions commercially available. HIPPI is a simplex point-to-point interface for transferring data at peak rates of 800 or 1600 Mbits/sec over distances of up to 25 meters.
Reference: [8] <author> ANSI X3.218-1993. </author> <title> "High-Performance Parallel Interface: Encapsulation of ISO 8802-2 (IEEE Std 802.2) Logical Link Control Protocol Data Unit (802.2 Link Encapsulation), </title> <publisher> (HIPPI-LE)". American National Standard Institute, Inc., </publisher> <month> June </month> <year> 1993. </year>
Reference-contexts: The second approach is discussed in much greater detail throughout the rest of this paper. In this study, we utilized both approaches to demonstrate the potential and feasibility of distributed network computing over a high-speed switch-based local area network. For the underlying high-speed network, we used the HIPPI <ref> [6, 7, 8, 9] </ref> as the switch-based network platform. HIPPI offers a connection-oriented service with peak data transmission rates of 800 or 1600 Mbits/sec. HIPPI is a mature technology, which is widely used in most supercomputers and many high-end workstations. <p> Also, in general, there do not exist interesting algorithms which can make use of hundreds of relatively fast processors interconnected by a low-speed network. The growing availability of high-speed networks may make very large virtual machines more likely and feasible. 2.2 HIPPI Networks The High-Performance Parallel Interface (HIPPI) <ref> [6, 7, 8, 9] </ref> is one of the high-speed network or channel solutions commercially available. HIPPI is a simplex point-to-point interface for transferring data at peak rates of 800 or 1600 Mbits/sec over distances of up to 25 meters. <p> HIPPI is a simplex point-to-point interface for transferring data at peak rates of 800 or 1600 Mbits/sec over distances of up to 25 meters. A related standard defines the usage of a crossbar switch to support multiple interconnections between HIPPI interfaces on different hosts [9]. Standards <ref> [8, 16] </ref> were also defined for running standard network protocols, such as TCP/IP and UDP/IP, over HIPPI. To extend HIPPI's connectivity, an implementor's agreement (the Serial-HIPPI [18]) specifies how the HIPPI packets are to be carried over a pair of fiber optical cables.
Reference: [9] <author> ANSI X3.222-1993. </author> <title> "High-Performance Parallel Interface: Physical Switch Control (HIPPI-SC)". </title> <publisher> American National Standard Institute, Inc., </publisher> <month> July </month> <year> 1993. </year>
Reference-contexts: The second approach is discussed in much greater detail throughout the rest of this paper. In this study, we utilized both approaches to demonstrate the potential and feasibility of distributed network computing over a high-speed switch-based local area network. For the underlying high-speed network, we used the HIPPI <ref> [6, 7, 8, 9] </ref> as the switch-based network platform. HIPPI offers a connection-oriented service with peak data transmission rates of 800 or 1600 Mbits/sec. HIPPI is a mature technology, which is widely used in most supercomputers and many high-end workstations. <p> Also, in general, there do not exist interesting algorithms which can make use of hundreds of relatively fast processors interconnected by a low-speed network. The growing availability of high-speed networks may make very large virtual machines more likely and feasible. 2.2 HIPPI Networks The High-Performance Parallel Interface (HIPPI) <ref> [6, 7, 8, 9] </ref> is one of the high-speed network or channel solutions commercially available. HIPPI is a simplex point-to-point interface for transferring data at peak rates of 800 or 1600 Mbits/sec over distances of up to 25 meters. <p> HIPPI is a simplex point-to-point interface for transferring data at peak rates of 800 or 1600 Mbits/sec over distances of up to 25 meters. A related standard defines the usage of a crossbar switch to support multiple interconnections between HIPPI interfaces on different hosts <ref> [9] </ref>. Standards [8, 16] were also defined for running standard network protocols, such as TCP/IP and UDP/IP, over HIPPI. To extend HIPPI's connectivity, an implementor's agreement (the Serial-HIPPI [18]) specifies how the HIPPI packets are to be carried over a pair of fiber optical cables.
Reference: [10] <author> Elisabeth Wechsler, </author> <title> "Industry Harnesses Clustered Workstations To Squeeze Extra Cycles". </title> <journal> NAS News, </journal> <volume> Vol 2, No. 9, </volume> <month> March/April </month> <year> 1995. </year>
Reference-contexts: The advantages of network computing have already attracted many companies to use it as an alternative form of high-performance computing. A recent report shows that several companies in aeronautics industry utilize clusters of workstations for computational fluid dynamics processing and propulsion applications during off hours and weekends 3 <ref> [10] </ref>. 3 Three case studies of recent aeronautics industry experience show how workstation clusters are being used as alternative forms of high-performance computing: (1) McDonnell Douglas has as many as 400 workstations (with an average of 200 per session) divided into clusters of 20 workstations per parallel job doing CFD (computational
Reference: [11] <author> Kolawa, A., </author> <title> "The Express Programming Environment", </title> <booktitle> Workshop on Heterogeneous Network-Based Concurrent Computing", </booktitle> <address> Tallahassee, </address> <month> Oct. </month> <year> 1991. </year>
Reference-contexts: Distributed applications utilize the computational power and communication facility of the cluster by using special libraries provided by the software framework. Those libraries usually support process management, synchronization, and message passing based on standard network protocols. Examples of such software framework are PVM [1, 5, 14], P4 [2], Express <ref> [11] </ref>, Linda [3], and MPI [15].
Reference: [12] <author> Lin, M., Hsieh, J., Du, D., Thomas, J., MacDonald, J., </author> <title> "Distributed Network Computing Over Local ATM Networks", </title> <journal> IEEE Journal on Selected Areas in Communications: Special Issue on ATM LAN Implementation and Experiences with an Emerging Technology, </journal> <volume> Vol 13, No. 4, </volume> <month> May </month> <year> 1995. </year>
Reference-contexts: The overhead incurred by the high-level protocols and the delay caused by the interactions with the host operating system can be varied by using different Application Programming Interfaces (APIs) which are available on different protocol layers <ref> [12] </ref>. <p> Figure 3 depicts these two communication modes. The advantage of the Direct Routing mode is that it provides a more efficient communication path than the Normal Routing mode. A previous report observed more than a twofold increase in communication performance when using Direct Routing mode <ref> [12] </ref>. The main reason PVM provides 8 the Normal Routing mode, despite its lower performance, is because of the limited number of file descriptors some Unix systems provide. Each open Unix domain or TCP connection consumes a file descriptor. <p> Figure 6 illustrates that PVM/LLA improves the achievable throughput for PVM Direct mode. Table III summarizes the performance of PVM and PVM/LLA over 10 Mbits/sec Ethernet network with the following three performance metrics <ref> [12] </ref>: * r max (maximum achievable throughput) : the maximum achievable throughput which is ob tained from experiments by transmitting very large messages. * n 1=2 (half performance message length) : the message size needed to achieve half of the maximum achievable throughput.
Reference: [13] <author> Lin, M., Hsieh, J., Du, D.H.C., MacDonald, J., </author> <title> "Performance of High-Speed Network I/O Subsystems: Case Study of a Fibre Channel Network", </title> <booktitle> IEEE Proceedings of Supercomputing 1994, </booktitle> <address> Washington D.C., </address> <month> Nov. </month> <year> 1994. </year>
Reference-contexts: It will speed up the transmission of data across the SGC I/O bus because of the reduction of the overhead from the per-packet processing. This approach is similar to one solution used to improve the Direct Memory Access (DMA) performance of a network I/O subsystem <ref> [13] </ref>. In their quantitative analysis of the network operations, they found that the per-page processing is the biggest bottleneck of the DMA operations. They increased the page size for each DMA operation to reduce the total overhead.
Reference: [14] <author> Manchek, </author> <title> R.J., "Design and Implementation of PVM Version 3", </title> <type> Master Thesis, </type> <institution> University of Ten-nessee, Knoxville, </institution> <month> May, </month> <year> 1994. </year>
Reference-contexts: Distributed applications utilize the computational power and communication facility of the cluster by using special libraries provided by the software framework. Those libraries usually support process management, synchronization, and message passing based on standard network protocols. Examples of such software framework are PVM <ref> [1, 5, 14] </ref>, P4 [2], Express [11], Linda [3], and MPI [15]. <p> The performance of the enhanced communications of PVM over a HIPPI network is discussed in Section 5. Finally, Section 6 concludes this paper and discusses future work. 2 An Overview of the PVM and HIPPI Networks 3 2.1 PVM: A Parallel Programming Environment PVM <ref> [1, 5, 14] </ref> is a software system for the development and execution of parallel applications. It allows an interconnected collection of independent heterogeneous computers to appear as a single virtual computational resource or a single parallel machine. The independent machines may be ordinary workstations, multiprocessors, supercomputers, or specialized processors. <p> The network of independent PVM pvmds forms the basis for support of important features for a network-based computing environment. These features include dynamic reconfigurability, fault tolerance and scalability. PVM provides dynamic reconfigurability by allowing hosts to enter and exit the virtual machine via notification messages <ref> [14] </ref>. PVM version 3 also supports the notion of dynamic process groups. Processes can belong to multiple named groups, and groups can be changed dynamically at any time during a computation. <p> This dynamic reconfigurability also provides support for scalability and fault tolerance. Since management is decentralized and localized, a PVM virtual machine may potentially scale up to hundreds of hosts executing thousands of tasks. However, the largest reported virtual machines consist of approximately 100 hosts <ref> [14] </ref>. This is due to, in part, the lack of availability of 4 high-speed networks. Also, in general, there do not exist interesting algorithms which can make use of hundreds of relatively fast processors interconnected by a low-speed network. <p> Some operating systems limit the number of open files to as few as 32. If a virtual machine consists of N hosts, each machine must have N 1 connections to the other hosts. Thus the drawback of the Direct Routing mode is its limited scalability <ref> [14] </ref>. 3.4.3 Multicasting Efficient support for multicasting is important because multicast data flow patterns are often found in parallel programming applications.
Reference: [15] <author> Message Passing Interface Forum, </author> <title> "MPI: A Message-Passing Interface Standard", </title> <note> Version 1.1: </note> <month> June, </month> <year> 1995. </year>
Reference-contexts: Those libraries usually support process management, synchronization, and message passing based on standard network protocols. Examples of such software framework are PVM [1, 5, 14], P4 [2], Express [11], Linda [3], and MPI <ref> [15] </ref>.
Reference: [16] <author> J. Renwick and A. Nicholson. </author> <title> "IP and ARP on HIPPI", </title> <type> RFC 1374, </type> <month> Oct. </month> <year> 1992. </year>
Reference-contexts: HIPPI is a simplex point-to-point interface for transferring data at peak rates of 800 or 1600 Mbits/sec over distances of up to 25 meters. A related standard defines the usage of a crossbar switch to support multiple interconnections between HIPPI interfaces on different hosts [9]. Standards <ref> [8, 16] </ref> were also defined for running standard network protocols, such as TCP/IP and UDP/IP, over HIPPI. To extend HIPPI's connectivity, an implementor's agreement (the Serial-HIPPI [18]) specifies how the HIPPI packets are to be carried over a pair of fiber optical cables.
Reference: [17] <author> Rami el Sebeiti, </author> <title> Hewlett-Packard France, </title> <type> Personal communications, </type> <year> 1995. </year>
Reference-contexts: The theoretical throughput of the SGC bus is 60 MB/sec for outbound writing and 38 MB/sec for inbound reading. A recently performance measurement 5 shows that the the LLA interface provided by the HIPPI interface card can achieve up to 55 MB/sec throughput for outbound transmission <ref> [17] </ref>. However, the LLA interface can only achieve around 24 MB/sec throughput for inbound reception. 5.2 PVM and PVM/LLA on Ethernet The preliminary tests of PVM/LLA were conducted on HP's Ethernet driver which also support LLA application programming interface.
Reference: [18] <author> Serial HIPPI Implementors Group. </author> <title> "Serial HIPPI Specification, Revision 1.0", </title> <month> May </month> <year> 1991. </year>
Reference-contexts: A related standard defines the usage of a crossbar switch to support multiple interconnections between HIPPI interfaces on different hosts [9]. Standards [8, 16] were also defined for running standard network protocols, such as TCP/IP and UDP/IP, over HIPPI. To extend HIPPI's connectivity, an implementor's agreement (the Serial-HIPPI <ref> [18] </ref>) specifies how the HIPPI packets are to be carried over a pair of fiber optical cables. The HIPPI can be extended up to 10 km on single-mode fiber. HIPPI provides connection-oriented service and reliable communications between hosts. With the crossbar switch, HIPPI can be used as a high-speed LAN.
Reference: [19] <author> Snir, M., Hochschild, P., Frye, D.D., and Gildea, K.J., </author> <title> "The Communication Software and Parallel Environment of the IBM SP2", </title> <journal> IBM Systems Journal, </journal> <volume> Vol. 34, No. 2, </volume> <month> Feb. </month> <year> 1995 </year>
Reference-contexts: The experimental environment consists of two HP 9000 series 735 workstations equipped with HP's HIPPI interface boards. The experimental measurement shows that our PVM/LLA on a HIPPI LAN can achieve comparable performance as the Message Passing Library (MPL) in IBM's scalable POWERparallel system SP2 <ref> [19] </ref>. The performance measurement also demonstrates that clusters of workstations inter-connected with switch-based high-speed LANs can be used for high-performance computing. The organization of the remainder of this paper is as follows. Section 2 provides an overview of the PVM distributed programming environment and HIPPI networks. <p> 3.3.4 3.506 3086 1922 9.679 4717 758 un-tuned PVM/LLA 3.390 1989 1855 11.763 4050 528 tuned PVM/LLA 3.390 1989 1855 16.103 7551 540 The experimental measurement shows that our PVM/LLA on a HIPPI LAN can achieve comparable performance as the Message Passing Library (MPL) in IBM's scalable POWERparallel system SP2 <ref> [19] </ref>. The IP version of the MPL provides user-to-user latency of 277.0 sec and point-to-point throughput of 10.8 Mbytes/sec. 17 6 Conclusion and Future Work The communication subsystem of PVM is primarily based upon the BSD socket interface.
Reference: [20] <author> D. Tolmie and J. Renwick. </author> <title> "HIPPI: Simplicity Yields Success". </title> <journal> IEEE Network, </journal> <pages> page 28, </pages> <month> Jan. </month> <year> 1993. </year> <month> 20 </month>
Reference-contexts: The flow control is performed at the physical layer. HIPPI is a mature technology, most supercomputers and many high-end workstations are equipped with HIPPI interfaces for high-throughput data connections. The success and widespread use of HIPPI is due to its KISS (Keep It Sweet and Simple) design 5 philosophy <ref> [20] </ref>. 3 The Communication Subsystem of PVM As shown in Figure 1, the three main components of PVM are the pvmd daemon program, libpvm programming library, and the applications which are running as PVM tasks.
References-found: 20

