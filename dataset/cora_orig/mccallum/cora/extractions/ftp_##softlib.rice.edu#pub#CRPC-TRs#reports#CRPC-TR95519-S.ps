URL: ftp://softlib.rice.edu/pub/CRPC-TRs/reports/CRPC-TR95519-S.ps
Refering-URL: http://www.cs.rice.edu/~ken/kennedy-vita.html
Root-URL: 
Title: An Empirical Study of Cross-loop Reuse in the NAS benchmarks  
Author: Keith Cooper Ken Kennedy Nathaniel McIntosh 
Address: Houston, Texas, USA  
Affiliation: Department of Computer Science Rice University  
Abstract: This paper describes an empirical study designed to quantify the level of cross-loop reuse occurring in a set of scientific Fortran programs, the NAS Benchmarks. Cross-loop reuse takes place when a set of data items or cache lines are accessed in a given loop nest and then accessed again within some subsequent portion of the program (usually another outer loop nest). In contrast to intra-loop reuse, which takes place during the execution of a single loop nest, cross-loop reuse is not always detectable by traditional compile-time reuse analysis techniques. In this study, the benchmark programs are instrumented and run through a cache simulator. The simulator gathers statistics on cross-loop reuse using a novel classification scheme that clearly identifies the different types of reuse. According to the simulation data, the level of cross-loop reuse varies widely from program to program, and depends greatly on the problem size and cache size. Some programs exhibit almost no cross-loop reuse, however other programs have significant levels of cross-loop reuse even for fairly small cache sizes. The data from this study suggest that cross-loop reuse information would be quite beneficial for compilers that attempt certain optimizations. 
Abstract-found: 1
Intro-found: 1
Reference: [AC72] <author> F. Allen and J. Cocke. </author> <title> A catalogue of optimizing transformations. </title> <editor> In J. Rustin, </editor> <booktitle> 14 editor, Design and Optimization of Compilers. </booktitle> <publisher> Prentice-Hall, </publisher> <year> 1972. </year>
Reference-contexts: Within the compiler community, researchers have developed a number of techniques to help programs exploit their locality of reference in order to improve cache utilization. For example, loop interchange <ref> [AC72] </ref> can be applied to help a program take advantage of inherent spatial locality. Other methods of this sort include loop tiling and unroll-and-jam [CCK90, WL91]. <p> As with all studies of this nature, much depends on the optimization techniques employed by the compiler used to compile the programs being simulated. Certain compiler transformations have the potential to change the way data items are reused. One such transformation is loop fusion <ref> [Wol89, AC72] </ref>. Fusing two adjacent loops may bring successive uses of a given location closer together, increasing the likelihood that the reused location will be found in cache, but also potentially converting cross-loop reuse into intra-loop reuse.
Reference: [AL93] <author> B. Appelbe and B. Lakshmanan. </author> <title> Optimizing parallel programs using affinity regions. </title> <booktitle> In Proceedings of the 1993 International Conference on Parallel Processing, pages II-246-II-249, </booktitle> <address> St. Charles, IL, </address> <month> August </month> <year> 1993. </year>
Reference-contexts: These studies tend to focus on examining the effects of various architectural features (line size, associativity, etc) on cache performance, however, and do not try to classify or categorize the various sources of reuse. A number of researchers have developed compiler techniques useful for improving cache behavior <ref> [CMT94, AL93, WL91, CCK90] </ref>. Most of these techniques apply to individual loop nests, however, and are not designed to exploit cross-loop reuse. Two exceptions are loop fusion and affinity regions. McKinley et al have proposed using loop fusion to improving locality and cache behavior [KM93]. <p> Affinity regions are a technique that allows a compiler to give locality-improving hints to the loop scheduler for a parallel program running on a shared-memory multiprocessor. Compile-time identification of affinity regions was proposed by Appelbe et al <ref> [AL93] </ref>.
Reference: [BBLS91a] <author> D. Bailey, J. Barton, T. Lasinski, and H. Simon. </author> <title> The NAS parallel benchmarks. </title> <type> Technical Report RNR-91-002, </type> <institution> NASA Ames Research Center, </institution> <month> August </month> <year> 1991. </year>
Reference-contexts: Our primary goal for this paper will be to describe a set of experiments that address the third concern above: quantifying the cross-loop reuse that exists in typical scientific programs. Our experiments are based on a simulation study of the NAS benchmarks <ref> [BBLS91a, BBLS91b] </ref>. In addition, we will explore possible applications of cross-loop reuse analysis. An outline of the rest of this paper is as follows. Section 2 provides some motivation for our study by giving an example of a latency-hiding technique that might benefit from cross-loop reuse information. <p> could detect the set of references that result in cross-loop initial hits, it would be able to reduce the overhead for prefetching, since prefetches for these references could be eliminated. 4 Experimental framework 4.1 Programs For our experiments, we used the entire collection of programs from the NAS benchmark suite <ref> [BBLS91a, BBLS91b] </ref>, plus a single program (Ocean) from the PERFECT benchmark suite [CKPK90].
Reference: [BBLS91b] <author> D. Bailey, J. Barton, T. Lasinski, and H. Simon. </author> <title> The NAS parallel benchmarks. </title> <journal> International Journal of Supercomputing Applications, </journal> <volume> 5(3) </volume> <pages> 63-73, </pages> <month> Fall </month> <year> 1991. </year>
Reference-contexts: Our primary goal for this paper will be to describe a set of experiments that address the third concern above: quantifying the cross-loop reuse that exists in typical scientific programs. Our experiments are based on a simulation study of the NAS benchmarks <ref> [BBLS91a, BBLS91b] </ref>. In addition, we will explore possible applications of cross-loop reuse analysis. An outline of the rest of this paper is as follows. Section 2 provides some motivation for our study by giving an example of a latency-hiding technique that might benefit from cross-loop reuse information. <p> could detect the set of references that result in cross-loop initial hits, it would be able to reduce the overhead for prefetching, since prefetches for these references could be eliminated. 4 Experimental framework 4.1 Programs For our experiments, we used the entire collection of programs from the NAS benchmark suite <ref> [BBLS91a, BBLS91b] </ref>, plus a single program (Ocean) from the PERFECT benchmark suite [CKPK90].
Reference: [CCK90] <author> D. Callahan, S. Carr, and K. Kennedy. </author> <title> Improving register allocation for subscripted variables. </title> <booktitle> In Proceedings of the SIGPLAN '90 Conference on Programming Language Design and Implementation, </booktitle> <address> White Plains, NY, </address> <month> June </month> <year> 1990. </year>
Reference-contexts: For example, loop interchange [AC72] can be applied to help a program take advantage of inherent spatial locality. Other methods of this sort include loop tiling and unroll-and-jam <ref> [CCK90, WL91] </ref>. These techniques are driven by various forms of loop level analysis they focus on identifying locations that are reused within a single loop nest ("intra-loop reuse"). Although intra-loop reuse is important, it is not the only type of reuse that occurs in practice. <p> These studies tend to focus on examining the effects of various architectural features (line size, associativity, etc) on cache performance, however, and do not try to classify or categorize the various sources of reuse. A number of researchers have developed compiler techniques useful for improving cache behavior <ref> [CMT94, AL93, WL91, CCK90] </ref>. Most of these techniques apply to individual loop nests, however, and are not designed to exploit cross-loop reuse. Two exceptions are loop fusion and affinity regions. McKinley et al have proposed using loop fusion to improving locality and cache behavior [KM93].
Reference: [CK93] <author> R. Cmelik and D. Keppel. Shade: </author> <title> A fast instruction-set simulator for execution profiling. </title> <type> Technical Report SMLI 93-12; UWCSE 93-06-06, </type> <institution> Sun Microsystems Laboratories, Inc. and University of Washington, </institution> <year> 1993. </year>
Reference-contexts: The available data indicates that fusion would not substantially alter our results [CMT94]. 4.3 Simulation framework Our cache simulator was built using the Sparc Performance Analysis Toolkit; it is layered on top of the tool shade <ref> [CK93] </ref>. Shade provides an extensible mechanism for writing execution-driven simulators; it operates by interpreting a Sparc executable and passing a trace of the instructions to a user-written trace analyzer. In our case, the trace analyzer simulates a particular cache configuration.
Reference: [CKPK90] <author> G. Cybenko, L. Kipp, L. Pointer, and D. Kuck. </author> <title> Supercomputer performance evaluation and the Perfect benchmarks. </title> <booktitle> In Proceedings of the 1990 ACM International Conference on Supercomputing, </booktitle> <address> Amsterdam, The Netherlands, </address> <month> June </month> <year> 1990. </year>
Reference-contexts: it would be able to reduce the overhead for prefetching, since prefetches for these references could be eliminated. 4 Experimental framework 4.1 Programs For our experiments, we used the entire collection of programs from the NAS benchmark suite [BBLS91a, BBLS91b], plus a single program (Ocean) from the PERFECT benchmark suite <ref> [CKPK90] </ref>.
Reference: [CMT94] <author> S. Carr, K. S. M c Kinley, and C.-W. Tseng. </author> <title> Compiler optimizations for improving data locality. </title> <booktitle> In Proceedings of the Sixth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS-VI), </booktitle> <address> San Jose, CA, </address> <month> October </month> <year> 1994. </year>
Reference-contexts: Previous studies, however, have shown that fusion is less widely applicable than most other locality-enhancing transformations. The available data indicates that fusion would not substantially alter our results <ref> [CMT94] </ref>. 4.3 Simulation framework Our cache simulator was built using the Sparc Performance Analysis Toolkit; it is layered on top of the tool shade [CK93]. <p> These studies tend to focus on examining the effects of various architectural features (line size, associativity, etc) on cache performance, however, and do not try to classify or categorize the various sources of reuse. A number of researchers have developed compiler techniques useful for improving cache behavior <ref> [CMT94, AL93, WL91, CCK90] </ref>. Most of these techniques apply to individual loop nests, however, and are not designed to exploit cross-loop reuse. Two exceptions are loop fusion and affinity regions. McKinley et al have proposed using loop fusion to improving locality and cache behavior [KM93].
Reference: [CP90] <author> D. Callahan and A. Porterfield. </author> <title> Data cache performance of supercomputer applications. </title> <booktitle> In Proceedings of Supercomputing '90, </booktitle> <address> New York, NY, </address> <month> November </month> <year> 1990. </year>
Reference-contexts: For certain programs, the use of cross-loop reuse information has the potential to reduce useless prefetches by a factor of 2, which is fairly significant. 13 6 Related work There is an extensive body of previous research on memory reference behavior and cache performance of various benchmark applications <ref> [GHPS91, CP90, SZ88, Smi82] </ref>. These studies tend to focus on examining the effects of various architectural features (line size, associativity, etc) on cache performance, however, and do not try to classify or categorize the various sources of reuse.
Reference: [GHPS91] <author> J. D. Gee, M. D. Hill, D. N. Pnevmatikatos, and A. J. Smith. </author> <title> Cache performance of the SPEC benchmark suite. </title> <type> Technical Report TR 1049, </type> <institution> University of Wisconsin, </institution> <month> September </month> <year> 1991. </year>
Reference-contexts: 0.73 0.75 1.22 6.06 17.93 17.92 CG 0.36 0.34 0.22 0.09 0.09 0.09 0.09 0.16 FT 2.62 0.36 0.19 0.11 0.06 0.04 0.02 0.02 ocean 0.94 0.68 0.67 1.34 1.25 0.82 1.04 11.91 the floating point programs in the SPEC benchmarks, when run using the same cache size and configuration <ref> [GHPS91] </ref>. The miss rates for the NAS programs appear to be somewhat lower for the smaller cache sizes (8K - 32K), but the disparity is less evident for cache sizes above 32K. <p> For certain programs, the use of cross-loop reuse information has the potential to reduce useless prefetches by a factor of 2, which is fairly significant. 13 6 Related work There is an extensive body of previous research on memory reference behavior and cache performance of various benchmark applications <ref> [GHPS91, CP90, SZ88, Smi82] </ref>. These studies tend to focus on examining the effects of various architectural features (line size, associativity, etc) on cache performance, however, and do not try to classify or categorize the various sources of reuse.
Reference: [KM93] <author> K. Kennedy and K. S. M c Kinley. </author> <title> Maximizing loop parallelism and improving data locality via loop fusion and distribution. </title> <booktitle> In Proceedings of the Sixth Workshop on Languages and Compilers for Parallel Computing, </booktitle> <address> Portland, OR, </address> <month> August </month> <year> 1993. </year>
Reference-contexts: Most of these techniques apply to individual loop nests, however, and are not designed to exploit cross-loop reuse. Two exceptions are loop fusion and affinity regions. McKinley et al have proposed using loop fusion to improving locality and cache behavior <ref> [KM93] </ref>. Affinity regions are a technique that allows a compiler to give locality-improving hints to the loop scheduler for a parallel program running on a shared-memory multiprocessor. Compile-time identification of affinity regions was proposed by Appelbe et al [AL93].
Reference: [MLG92] <author> T. Mowry, M. Lam, and A. Gupta. </author> <title> Design and evaluation of a compiler algorithm for prefetching. </title> <booktitle> In Proceedings of the Fifth International Conference 15 on Architectural Support for Programming Languages and Operating Systems (ASPLOS-V), </booktitle> <pages> pages 62-73, </pages> <address> Boston, MA, </address> <month> October </month> <year> 1992. </year>
Reference-contexts: In Section 5, we present and interpret the results of the experiments. Section 6 summarizes some of the previous research that relates to this work. Finally, in Section 7 we give our conclusions. 2 2 Motivating example: software prefetching Compiler-directed software prefetching <ref> [MLG92] </ref> is a good example of a cache-management technique that could potentially benefit from cross-loop reuse information. Software prefetching is a two-phase process. In the first phase, the compiler analyzes the program and seeks to determine the set of variable references that are likely to cause cache misses at run-time.
Reference: [Smi82] <author> A. J. Smith. </author> <title> Cache memories. </title> <journal> ACM Computing Surveys, </journal> <volume> 13(3) </volume> <pages> 473-530, </pages> <month> September </month> <year> 1982. </year>
Reference-contexts: For certain programs, the use of cross-loop reuse information has the potential to reduce useless prefetches by a factor of 2, which is fairly significant. 13 6 Related work There is an extensive body of previous research on memory reference behavior and cache performance of various benchmark applications <ref> [GHPS91, CP90, SZ88, Smi82] </ref>. These studies tend to focus on examining the effects of various architectural features (line size, associativity, etc) on cache performance, however, and do not try to classify or categorize the various sources of reuse.
Reference: [SZ88] <author> K. So and V. Zecca. </author> <title> Cache performance of vector processors. </title> <booktitle> In Proceedings of the 15th International Symposium on Computer Architecture, </booktitle> <year> 1988. </year>
Reference-contexts: For certain programs, the use of cross-loop reuse information has the potential to reduce useless prefetches by a factor of 2, which is fairly significant. 13 6 Related work There is an extensive body of previous research on memory reference behavior and cache performance of various benchmark applications <ref> [GHPS91, CP90, SZ88, Smi82] </ref>. These studies tend to focus on examining the effects of various architectural features (line size, associativity, etc) on cache performance, however, and do not try to classify or categorize the various sources of reuse.
Reference: [WL91] <author> M. E. Wolf and M. Lam. </author> <title> A data locality optimizing algorithm. </title> <booktitle> In Proceedings of the SIGPLAN '91 Conference on Programming Language Design and Implementation, </booktitle> <address> Toronto, Canada, </address> <month> June </month> <year> 1991. </year>
Reference-contexts: For example, loop interchange [AC72] can be applied to help a program take advantage of inherent spatial locality. Other methods of this sort include loop tiling and unroll-and-jam <ref> [CCK90, WL91] </ref>. These techniques are driven by various forms of loop level analysis they focus on identifying locations that are reused within a single loop nest ("intra-loop reuse"). Although intra-loop reuse is important, it is not the only type of reuse that occurs in practice. <p> These studies tend to focus on examining the effects of various architectural features (line size, associativity, etc) on cache performance, however, and do not try to classify or categorize the various sources of reuse. A number of researchers have developed compiler techniques useful for improving cache behavior <ref> [CMT94, AL93, WL91, CCK90] </ref>. Most of these techniques apply to individual loop nests, however, and are not designed to exploit cross-loop reuse. Two exceptions are loop fusion and affinity regions. McKinley et al have proposed using loop fusion to improving locality and cache behavior [KM93].
Reference: [Wol89] <author> M. J. Wolfe. </author> <title> Optimizing Supercompilers for Supercomputers. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1989. </year> <month> 16 </month>
Reference-contexts: As with all studies of this nature, much depends on the optimization techniques employed by the compiler used to compile the programs being simulated. Certain compiler transformations have the potential to change the way data items are reused. One such transformation is loop fusion <ref> [Wol89, AC72] </ref>. Fusing two adjacent loops may bring successive uses of a given location closer together, increasing the likelihood that the reused location will be found in cache, but also potentially converting cross-loop reuse into intra-loop reuse.
References-found: 16

