URL: http://www.cc.gatech.edu/fac/Mustaque.Ahamad/pubs/scalable.ps
Refering-URL: http://www.cs.gatech.edu/fac/Mustaque.Ahamad/pubs.html
Root-URL: 
Title: Scalable Consistency Protocols for Distributed Services  
Author: Mustaque Ahamad Rammohan Kordale 
Keyword: Scalable Services, Distributed Objects, Replication, Caching, Consistency Pro tocols.  
Date: August 1997  
Address: Atlanta, GA 30332  Mountain View, CA 94087  
Affiliation: College of Computing Georgia Institute of Technology  Scalable Information Systems Silicon Graphics Inc.  
Abstract: A common way to address scalability requirements of distributed services is to employ server replication and client caching of objects that encapsulate the service state. The performance of such a system could depend very much on the protocol implemented by the system to maintain consistency among object copies. We explore scalable consistency protocols that never require synchronization and communication between all nodes that have copies of related objects. We achieve this by developing a novel approach called local consistency (LC). LC based protocols can provide increased flexibility and efficiency by allowing nodes control over how and when they become aware of updates to cached objects. We develop two protocols for implementing strong consistency using this approach and demonstrate that they scale better than a traditional invalidation based consistency protocol along the system load and geographic distribution dimensions of scale. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. V. Adve and M. H. Hill. </author> <title> Implementing sequential consistency in cache-based systems. </title> <booktitle> In Proc. of Intl. Conf. on Parallel Processing, </booktitle> <year> 1990. </year>
Reference-contexts: Other protocols that share a similar approach include the dynamic self-invalidation protocol [27] and the implementation of sequentially consistent memory described in <ref> [1] </ref>. The invalidation-set protocol maintains consistent node views by receiving information about what object copies stored at the node have been overwritten since it last communicated with the server. In the case of a single server, such information can be maintained efficiently by the server node.
Reference: [2] <author> M. Ahamad, G. Neiger, P. Hutto, P. Kohli and J. Burns. </author> <title> Causal Memory: Definitions and Implementations. </title> <booktitle> Distributed Computing, </booktitle> <year> 1995. </year>
Reference-contexts: Another way in which correctness can be demonstrated is by using an argument that is inspired by work in scalable or weakly ordered memory systems <ref> [2, 12, 35] </ref>. These systems assume two types of operations: synchronization or labeled operations and ordinary operations. Synchronization operations order the ordinary operations so the resulting executions are ones that can also be obtained in a strongly consistent system.
Reference: [3] <author> M. Baker, J. H. Hartman, M. D. Kupfer, K. W. Shirriff, J. K. Ousterhout. </author> <title> Measurements of a distributed file system. </title> <booktitle> In Proc. of the 13th Symp. on Oper. Sys. Principles, </booktitle> <year> 1991. </year>
Reference-contexts: This study was conducted by researchers at the University of Toronto. We call this workload as the Toronto workload and it was used to evaluate protocols along the geographic distribution aspect of scalability. Apart from the above two workloads, we also use information from the Sprite <ref> [3] </ref> and the xFS [8, 9] traces. We chose to implement a synthetic workload generator because neither usable live loads nor the traces of the Toronto workload (which was uniquely useful for evaluating geographic scalability) were available. Our synthetic workload generator can be described by the following parameters. <p> We also chose a cache that was half the size of a full cache. The full cache size in our case is smaller compared to the full cache of 512 files in the Princeton study [4], and 1024 files in <ref> [3, 8] </ref>. This is because the total number of objects in the workload is much smaller (about 1500 objects) due to the fact that all the objects created in our workload are active. The study by Bodnarchuk and Bunt [5] also supports the use of a small number of objects.
Reference: [4] <author> M. </author> <title> Blaze. Caching in large-scale distributed file systems. </title> <type> PhD Thesis, </type> <institution> Princeton, </institution> <year> 1992. </year> <month> 26 </month>
Reference-contexts: The first workload is taken from Matt Blaze's thesis on "Caching in large scale distributed systems" <ref> [4] </ref>. We call this the Princeton workload and it documents file accesses of approximately 250 users collected over a week in the Princeton University Computer Science department. This workload was used to evaluate protocols along the system load aspect of scalability. <p> In previous studies <ref> [4, 8] </ref>, a cache size that is half the size of a full cache is chosen. We also chose a cache that was half the size of a full cache. <p> We also chose a cache that was half the size of a full cache. The full cache size in our case is smaller compared to the full cache of 512 files in the Princeton study <ref> [4] </ref>, and 1024 files in [3, 8]. This is because the total number of objects in the workload is much smaller (about 1500 objects) due to the fact that all the objects created in our workload are active.
Reference: [5] <author> R. R. Bodnarchuk and F. B. Bunt. </author> <title> A synthetic workload model for a distributed system file server. </title> <booktitle> ACM SIGMETRICS 1991. </booktitle>
Reference-contexts: Reducing inter-access times arbitrarily can have an effect on the accuracy of the results. We will discuss this in the next section. Creation: Every time an object access is generated, the probability that an object would be created was taken to be 0.5% <ref> [5] </ref>. 4 There exist workloads from Web servers that support access to dynamic content (available from the URL http://ita.ee.lbl.gov/html/traces.html). Such workloads represent a single writer and multiple reader access patterns. We wanted to explore consistency with distributed servers and when the objects can be updated at multiple nodes. <p> This is because the total number of objects in the workload is much smaller (about 1500 objects) due to the fact that all the objects created in our workload are active. The study by Bodnarchuk and Bunt <ref> [5] </ref> also supports the use of a small number of objects. We implemented the LRU cache replacement policy. * Server cache and disk delay: We emulate an object server by using statistics from previous studies [8].
Reference: [6] <author> V. Cate. </author> <title> Alex a global file system. </title> <booktitle> In Proc. of 1992 USENIX File System Workshop, </booktitle> <year> 1992. </year>
Reference-contexts: This will ensure that clock times in various views will correctly reflect the order between the views. Object lifetimes may appear similar to time-to-live (TTL) fields (e.g., the Alex protocol <ref> [6] </ref>) or leases [15] which have been explored to reduce consistency related messages. However, there are many differences. We use logical time to define lifetimes and use them to ensure consistency across related but different objects.
Reference: [7] <author> A, Chankhunthod, P. Danzig, C. Neerdaels, M. Schwartz and K. Worrel. </author> <title> A hierarchical internet object cache. </title> <booktitle> 1996 Usenix Technical Conference, </booktitle> <month> Jan. </month> <year> 1996. </year>
Reference: [8] <author> M. D. Dahlin, R. Y. Wang, T. E. Anderson, and D. A. Patterson. </author> <title> Cooperative caching: using remote client memory to improve file system performance. </title> <booktitle> In Proc. of OSDI, </booktitle> <year> 1994. </year>
Reference-contexts: We call this workload as the Toronto workload and it was used to evaluate protocols along the geographic distribution aspect of scalability. Apart from the above two workloads, we also use information from the Sprite [3] and the xFS <ref> [8, 9] </ref> traces. We chose to implement a synthetic workload generator because neither usable live loads nor the traces of the Toronto workload (which was uniquely useful for evaluating geographic scalability) were available. Our synthetic workload generator can be described by the following parameters. <p> In previous studies <ref> [4, 8] </ref>, a cache size that is half the size of a full cache is chosen. We also chose a cache that was half the size of a full cache. <p> We also chose a cache that was half the size of a full cache. The full cache size in our case is smaller compared to the full cache of 512 files in the Princeton study [4], and 1024 files in <ref> [3, 8] </ref>. This is because the total number of objects in the workload is much smaller (about 1500 objects) due to the fact that all the objects created in our workload are active. The study by Bodnarchuk and Bunt [5] also supports the use of a small number of objects. <p> The study by Bodnarchuk and Bunt [5] also supports the use of a small number of objects. We implemented the LRU cache replacement policy. * Server cache and disk delay: We emulate an object server by using statistics from previous studies <ref> [8] </ref>. We assume 20% server cache hit ratio and 14 ms. average disk access time. 9.2 Results We now present the results of our experiments that evaluate the protocols along the two dimensions of scale system load and geographic distribution. <p> In the evaluation we have done, SC lc provides better performance than the invalidation based protocol SC inv when an application can tolerate some lag in node views and the current global view. Distributed file systems also employ caching to employ performance. The xFS <ref> [8] </ref> system makes use of an invalidation based protocol to ensure cache consistency. The call-backs of AFS [19] also have a similar effect. The Bayou [37] and Coda [22] systems address replication, caching and consistency in mobile environments. Bayou addresses several levels of consistency (e.g., session guarantees [36]).
Reference: [9] <author> M. D. Dahlin, C. J. Mather, R. Y. Wang, T. E. Anderson, and D. A. Patterson. </author> <title> A quantitative analysis of cache policies for scalable network file systems. </title> <booktitle> In Proc. of ACM SIG-METRICS, </booktitle> <year> 1994. </year>
Reference-contexts: We call this workload as the Toronto workload and it was used to evaluate protocols along the geographic distribution aspect of scalability. Apart from the above two workloads, we also use information from the Sprite [3] and the xFS <ref> [8, 9] </ref> traces. We chose to implement a synthetic workload generator because neither usable live loads nor the traces of the Toronto workload (which was uniquely useful for evaluating geographic scalability) were available. Our synthetic workload generator can be described by the following parameters. <p> However, with increasing network bandwidths, it may be more desirable to reduce server load rather than the number of messages <ref> [9] </ref>. In Figure 9, we plot server load per client as a product of cache misses experienced by one client and the time spent at the server to service a cache miss. SC inv imposes 12% more load on the server per client than SC lc . <p> In this case, all messages carrying data were assumed to take the time it takes for a 16KB message and all control messages were assumed to take the time it takes for a 12 byte message. Finally, <ref> [9] </ref> suggests that even if wide-area link bandwidths are no longer a factor and wide-area latencies decrease, the best case scenario would be where the latency is equal to disk access time (we used 14 ms in our studies).
Reference: [10] <author> K. Eswaran, J. N. Gray, R. A. Lorie and I. L. Traiger. </author> <title> The notions of consistency and predicate locks in dtabase systems. </title> <journal> Communications of the ACM, </journal> <month> 19,11 (Nov. </month> <year> 1976). </year>
Reference-contexts: Thus, all nodes agree on the order of updates to an object and conflicting updates are not possible. Strong consistency can be formulated in a number of different ways. Sequential consistency [25] and serializability <ref> [10] </ref>, used in shared memory systems and in databases, respectively, are two consistency models that require that execution of operations on shared objects should be serializable. However, these consistency conditions do not consider the time at which operations are executed.
Reference: [11] <author> C. Fidge. </author> <title> Timestamps in message-passing systems that preserve the partial ordering. </title> <booktitle> Australian Computer Science Conf., </booktitle> <year> 1988. </year>
Reference-contexts: In large scale distributed systems, it is not reasonable to assume the existence of such a clock. We develop a consistency protocol that does not require synchronized clocks. Instead, logical clocks are used to record object lifetimes. In particular, we use vector clocks <ref> [32, 11] </ref>. Vector times have been used to order writes and to detect conflicting updates in replicated data systems such as Bayou [36] and Coda [22].
Reference: [12] <author> K. Gharachorloo, D. Lenoski, J. Laudon, P. Gibbons, A. Gupta, and J. Hennessy. </author> <title> Memory consistency and event ordering in scalable shared-memory multiprocessors. </title> <booktitle> In ISCA 1990. </booktitle>
Reference-contexts: Several approaches have been explored for developing scalable consistency protocols. In the context of distributed shared memory systems, synchronization information (e.g., lock operations) is exploited to reduce the cost of consistency maintenance <ref> [12, 21] </ref>. Because of the system scale and the varying degrees of coupling between application components, we do not assume that all accesses to service state are controlled via synchronization operations. <p> update (V T server , V T 0 x:rt = update (x:rt, V T 0 x:vt = update (x:vt, V T server ) if (mode = read) x:rt = update (x:rt, V T ) x.owner = self return (x) else x.owner = P i return (x) increment (update ([01],[11],[10])) = <ref> [12] </ref> (y:rt is V T 1 when y was read by P 1 ). No copies need to be invalidated locally since y is the only copy at node P 2 . Also, V T 2 is advanced to [12]. <p> else x.owner = P i return (x) increment (update ([01],[11],[10])) = <ref> [12] </ref> (y:rt is V T 1 when y was read by P 1 ). No copies need to be invalidated locally since y is the only copy at node P 2 . Also, V T 2 is advanced to [12]. Suppose now node P 2 caches a read-only copy of x and then P 1 wants to update x. It assigns the write-time using the same rules and hence x:wt = [22 ]. In addition, the local copy of y is invalidated because y:vt &lt; x:wt. <p> Another way in which correctness can be demonstrated is by using an argument that is inspired by work in scalable or weakly ordered memory systems <ref> [2, 12, 35] </ref>. These systems assume two types of operations: synchronization or labeled operations and ordinary operations. Synchronization operations order the ordinary operations so the resulting executions are ones that can also be obtained in a strongly consistent system. <p> Also, we only address consistency at the level of object accesses whereas Thor supports transactions that can include a sequence of accesses. In scalable shared memory systems (e.g, Stanford DASH <ref> [12] </ref>) and software implementations of distributed shared memory [21], consistency actions are delayed until certain synchronization operations complete.
Reference: [13] <author> D. S. Gill, S. Zhou, and H. S. Sandhu. </author> <title> A case study of file system workload in a large-scale distributed environment. </title> <institution> University of Toronto Technical Report, </institution> <year> 1994. </year>
Reference-contexts: We call this the Princeton workload and it documents file accesses of approximately 250 users collected over a week in the Princeton University Computer Science department. This workload was used to evaluate protocols along the system load aspect of scalability. The second workload <ref> [13, 14] </ref> is taken from a large industrial distributed file system supporting several thousand users organized into project oriented workgroups and connected together by a hierarchy of local area and wide area networks and spread across several metropolitan areas. This study was conducted by researchers at the University of Toronto.
Reference: [14] <author> D. S. Gill, S. Zhou, and H. S. Sandhu. </author> <title> A case study of file system workload in a large-scale distributed environment. </title> <booktitle> In Proc. of ACM Sigmetrics, </booktitle> <month> May </month> <year> 1994. </year>
Reference-contexts: We call this the Princeton workload and it documents file accesses of approximately 250 users collected over a week in the Princeton University Computer Science department. This workload was used to evaluate protocols along the system load aspect of scalability. The second workload <ref> [13, 14] </ref> is taken from a large industrial distributed file system supporting several thousand users organized into project oriented workgroups and connected together by a hierarchy of local area and wide area networks and spread across several metropolitan areas. This study was conducted by researchers at the University of Toronto.
Reference: [15] <author> C. G. Gray and D. R. Cheriton. Leases: </author> <title> An efficient fault-tolerant mechanism for distributed file cache consistency. </title> <booktitle> In Proc. of 12th ACM Symposium on Operating Systems Principles (SOSP), </booktitle> <year> 1989. </year>
Reference-contexts: This will ensure that clock times in various views will correctly reflect the order between the views. Object lifetimes may appear similar to time-to-live (TTL) fields (e.g., the Alex protocol [6]) or leases <ref> [15] </ref> which have been explored to reduce consistency related messages. However, there are many differences. We use logical time to define lifetimes and use them to ensure consistency across related but different objects.
Reference: [16] <author> R. G. Guy, J. S. Heidemann, W. Mak, T. W. Page Jr., G. J. Popek, and D. Rothmeier. </author> <title> Implementation of the Ficus replicated file system. </title> <booktitle> In USENIX Conf., </booktitle> <month> June </month> <year> 1990. </year>
Reference: [17] <author> J. Gwerzman and M. Seltzer. </author> <title> World-wide web cache consistency. </title> <booktitle> 1996 Usenix Technical Conference, </booktitle> <month> January </month> <year> 1996.. </year>
Reference-contexts: We enumerate some of the related systems (detailed comparisons are not included due to space constraints). Consistency issues in the context of the Web have been discussed in <ref> [17, 29, 40] </ref>. The protocols studied include ones based on time-to-live (TTL), which only provides weak consistency, and invalidation and polling based protocols for strong consistency.
Reference: [18] <author> Maurice P. Herlihy and Jeannette M. Wing. </author> <title> Linearizability: A correctness condition for concurrent objects. </title> <journal> ACM Transactions on Programming Languages, </journal> <volume> 12(3) </volume> <pages> 463-492, </pages> <month> July </month> <year> 1990. </year>
Reference-contexts: In interactive applications, timely dissemination of an update is required. Such timeliness is provided by strong consistency models such as atomic memory [30] and linearizability <ref> [18] </ref>. These consistency models require that serializations of operations respect the time at which the operations are executed. Clearly, protocols that implement such strong consistency are more expensive and do not permit any "lag" that may be acceptable in disseminating the effects of update operations.
Reference: [19] <author> J. H. Howard et. al., </author> <title> Scale and performance in distributed file systems. </title> <journal> ACM Trans. on Computer Systems, </journal> <month> Feb., </month> <year> 1988. </year>
Reference-contexts: Distributed file systems also employ caching to employ performance. The xFS [8] system makes use of an invalidation based protocol to ensure cache consistency. The call-backs of AFS <ref> [19] </ref> also have a similar effect. The Bayou [37] and Coda [22] systems address replication, caching and consistency in mobile environments. Bayou addresses several levels of consistency (e.g., session guarantees [36]).
Reference: [20] <author> A. D. Joseph, A. F. de Lespinasse, J. A. Tauber, D. K. Gifford, and M. F. Kaashoek. </author> <title> Rover: A toolkit for mobile information access. </title> <booktitle> In Proc. of 15th SOSP, </booktitle> <year> 1995. </year> <month> 27 </month>
Reference-contexts: Since we guarantee serialization of all object accesses, our protocol does not allow conflicting updates. The advancing of views in our protocol when a client communicates with a server is similar to reconciliation in Coda. Thor [28] and Rover <ref> [20] </ref> employ object caching and strive to provide strong consistency. Conflicting accesses in Rover could lead to consistency violation (the user must repair the effects of such violations).
Reference: [21] <author> P. Keleher, A. L. Cox, and W. Zwaenepoel. </author> <title> Lazy release consistency for software distributed shared memory. </title> <booktitle> In Proc. of the 19th International Symposium of Computer Architecture, </booktitle> <year> 1992. </year>
Reference-contexts: Several approaches have been explored for developing scalable consistency protocols. In the context of distributed shared memory systems, synchronization information (e.g., lock operations) is exploited to reduce the cost of consistency maintenance <ref> [12, 21] </ref>. Because of the system scale and the varying degrees of coupling between application components, we do not assume that all accesses to service state are controlled via synchronization operations. <p> Also, we only address consistency at the level of object accesses whereas Thor supports transactions that can include a sequence of accesses. In scalable shared memory systems (e.g, Stanford DASH [12]) and software implementations of distributed shared memory <ref> [21] </ref>, consistency actions are delayed until certain synchronization operations complete.
Reference: [22] <author> J. Kistler and M. Satyanarayanan. </author> <title> Disconnected operation in the Coda file system. </title> <booktitle> In ACM Symp. on Oper. Sys. Principles, </booktitle> <year> 1991. </year>
Reference-contexts: Instead, logical clocks are used to record object lifetimes. In particular, we use vector clocks [32, 11]. Vector times have been used to order writes and to detect conflicting updates in replicated data systems such as Bayou [36] and Coda <ref> [22] </ref>. In our system, a vector clock is a vector of integers with a component for each update node 3 , where an update node is defined as a node on which an object can be updated. We denote the clock at node P i by V T i . <p> Also, V T 2 is advanced to [12]. Suppose now node P 2 caches a read-only copy of x and then P 1 wants to update x. It assigns the write-time using the same rules and hence x:wt = <ref> [22 ] </ref>. In addition, the local copy of y is invalidated because y:vt &lt; x:wt. <p> Distributed file systems also employ caching to employ performance. The xFS [8] system makes use of an invalidation based protocol to ensure cache consistency. The call-backs of AFS [19] also have a similar effect. The Bayou [37] and Coda <ref> [22] </ref> systems address replication, caching and consistency in mobile environments. Bayou addresses several levels of consistency (e.g., session guarantees [36]). Although weaker consistency levels do permit more scalable implementation, we focus on scalable implementations of strong consistency that avoid conflicting updates to an object.
Reference: [23] <author> R. Kordale. </author> <title> System support for scalable services. </title> <type> PhD Thesis, </type> <institution> Georgia Inst. of Technology, </institution> <year> 1997. </year>
Reference-contexts: Such a serialization can be constructed even when one client reads values from an older view while the object is updated at another node. A more detailed proof can be found in <ref> [23] </ref>. 5 Ob ject Lifetime based Protocol If consistency is required across related objects that are stored at several servers, an invalidation-set for a node can not be maintained at a single server without incurring additional communication overhead. We now develop a protocol that allows distributed servers. <p> In the absence of explicit synchronization, orderings induced between operations by the clock rules in our approach result in implicit synchronization which allows us to demonstrate that all accesses can be serialized. A proof that demonstrates correctness can be found in <ref> [23] </ref>. 6 A Hybrid Protocol The object lifetime based protocol can sometimes be more conservative than required. For example, assume that in Figure 4, the second write of P 2 is to another related object z instead of w (y)1.
Reference: [24] <author> R. Kordale and M. Ahamad. </author> <title> Object Caching in a CORBA Copliant System. </title> <journal> Usenix Systems Journal, </journal> <year> 1996. </year>
Reference-contexts: Although the caching architecture at client nodes could impact object invocation performance, our focus in this paper is on the comparative evaluation of the consistency protocols. Thus, we omit the details of the prototype, which can be found in <ref> [24] </ref>, and focus on its evaluation. 8 Workload In the absence of traces from interactive applications deployed in a wide-area environment, we considered synthetic workloads to evaluate the consistency protocols.
Reference: [25] <author> L. Lamport. </author> <title> How to make a multiprocessor computer that correctly executes multiprocess programs. </title> <journal> IEEE Trans. on Computers, </journal> <month> Sep </month> <year> 1979. </year>
Reference-contexts: Thus, all nodes agree on the order of updates to an object and conflicting updates are not possible. Strong consistency can be formulated in a number of different ways. Sequential consistency <ref> [25] </ref> and serializability [10], used in shared memory systems and in databases, respectively, are two consistency models that require that execution of operations on shared objects should be serializable. However, these consistency conditions do not consider the time at which operations are executed.
Reference: [26] <author> S. Landis, and S. Maffeis. </author> <title> Building reliable distributed systems with CORBA. </title> <booktitle> In Proc. of USENIX Conference on Object-Oriented Technologies and Systems(COOTS), </booktitle> <year> 1995. </year>
Reference-contexts: Other systems that address scalable access to objects also exist. The ITV [34] system supports a video-on-demand application and makes use of objects to implement communication between clients and servers. However, caching and consistency issues are not addressed in this system. The Electra system <ref> [26] </ref> implements replicated objects using group communication. Group communication with atomic ordering is required for strong consistency which is costly.
Reference: [27] <author> A. R. Lebeck, and D. A. Wood. </author> <title> Dynamic self-invalidation: Reducing coherence overhead in shared-memory multiprocessors. </title> <booktitle> In Proceedings of the 22nd Annual International Symposium on Computer Architecture, </booktitle> <year> 1995. </year>
Reference-contexts: For example, our protocol is similar to the one presented in [31] but we do not require that a client communicate with the server on each write operation. Other protocols that share a similar approach include the dynamic self-invalidation protocol <ref> [27] </ref> and the implementation of sequentially consistent memory described in [1]. The invalidation-set protocol maintains consistent node views by receiving information about what object copies stored at the node have been overwritten since it last communicated with the server.
Reference: [28] <author> B. Liskov, A. Adya, M. Castro, M. Day, S. Ghemawat, R. Gruber., U. Maheshwari and L. Shrira. </author> <title> Safe and Efficient Sharing of Persistent Objects in Thor. </title> <booktitle> ACM SIGMOD, </booktitle> <year> 1996. </year>
Reference-contexts: Since we guarantee serialization of all object accesses, our protocol does not allow conflicting updates. The advancing of views in our protocol when a client communicates with a server is similar to reconciliation in Coda. Thor <ref> [28] </ref> and Rover [20] employ object caching and strive to provide strong consistency. Conflicting accesses in Rover could lead to consistency violation (the user must repair the effects of such violations).
Reference: [29] <author> C. Liu and P. Cao. </author> <title> Maintaining strong consistency in the World-wide Web. </title> <booktitle> Proc. of International Conference on Distributed Computing, </booktitle> <month> May </month> <year> 1997. </year>
Reference-contexts: We enumerate some of the related systems (detailed comparisons are not included due to space constraints). Consistency issues in the context of the Web have been discussed in <ref> [17, 29, 40] </ref>. The protocols studied include ones based on time-to-live (TTL), which only provides weak consistency, and invalidation and polling based protocols for strong consistency. <p> Consistency issues in the context of the Web have been discussed in [17, 29, 40]. The protocols studied include ones based on time-to-live (TTL), which only provides weak consistency, and invalidation and polling based protocols for strong consistency. Although it is argued in <ref> [29] </ref> that strong consistency can be provided using 6 Reads can return older values when writes do not result in synchronous invalidation of cached copies. The number of cache misses is not significantly different in the two protocols for many of the data points in the experiments.
Reference: [30] <author> J. Misra. </author> <title> Axioms for memory access in asynchronous hardware systems. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 8(1) </volume> <pages> 142-153, </pages> <month> January </month> <year> 1986. </year>
Reference-contexts: In interactive applications, timely dissemination of an update is required. Such timeliness is provided by strong consistency models such as atomic memory <ref> [30] </ref> and linearizability [18]. These consistency models require that serializations of operations respect the time at which the operations are executed. Clearly, protocols that implement such strong consistency are more expensive and do not permit any "lag" that may be acceptable in disseminating the effects of update operations.
Reference: [31] <author> M. Mizuno, M. Raynal, and J. Z. Zhou. </author> <title> Sequential Consistency in distributed systems. </title> <booktitle> Proc. Intl. Workshop on "Unifying Theory and Practice in Dist. Systems. </booktitle>
Reference-contexts: This protocol is based on efficient sequential consistency protocols that have been developed for shared memory systems. For example, our protocol is similar to the one presented in <ref> [31] </ref> but we do not require that a client communicate with the server on each write operation. Other protocols that share a similar approach include the dynamic self-invalidation protocol [27] and the implementation of sequentially consistent memory described in [1].
Reference: [32] <author> F. Mattern. </author> <title> Time and global states of distributed systems. </title> <booktitle> In Proceedings of the International Workshop on Parallel and Distributed Algorithms, </booktitle> <year> 1989. </year>
Reference-contexts: In large scale distributed systems, it is not reasonable to assume the existence of such a clock. We develop a consistency protocol that does not require synchronized clocks. Instead, logical clocks are used to record object lifetimes. In particular, we use vector clocks <ref> [32, 11] </ref>. Vector times have been used to order writes and to detect conflicting updates in replicated data systems such as Bayou [36] and Coda [22].
Reference: [33] <author> J. Mogul. </author> <title> Hinted caching in the Web. </title> <booktitle> ACM SIGOPS Workshop, </booktitle> <year> 1996. </year>
Reference: [34] <author> M. N. Nelson, M. Linton and S. Owicki. </author> <title> A highly available, scalable ITV system. </title> <booktitle> In Proc. of 15th SOSP, </booktitle> <year> 1995. </year>
Reference-contexts: Other systems that address scalable access to objects also exist. The ITV <ref> [34] </ref> system supports a video-on-demand application and makes use of objects to implement communication between clients and servers. However, caching and consistency issues are not addressed in this system. The Electra system [26] implements replicated objects using group communication.
Reference: [35] <author> M. Raynal, and A. Schiper. </author> <title> From causal consistency to sequential consistency in shared memory systems. </title> <type> IRISA TR#: 926. </type>
Reference-contexts: Another way in which correctness can be demonstrated is by using an argument that is inspired by work in scalable or weakly ordered memory systems <ref> [2, 12, 35] </ref>. These systems assume two types of operations: synchronization or labeled operations and ordinary operations. Synchronization operations order the ordinary operations so the resulting executions are ones that can also be obtained in a strongly consistent system.
Reference: [36] <author> D. B. Terry, A. J. Demers, K. Petersen, M. J. Spreitzer, M. M. Theimer, and B. B. Welch. </author> <title> Session guarantees for weakly consistent replicated data. </title> <booktitle> In IEEE Symp. on Parallel and Dist. Information Sys., </booktitle> <year> 1994. </year> <month> 28 </month>
Reference-contexts: We develop a consistency protocol that does not require synchronized clocks. Instead, logical clocks are used to record object lifetimes. In particular, we use vector clocks [32, 11]. Vector times have been used to order writes and to detect conflicting updates in replicated data systems such as Bayou <ref> [36] </ref> and Coda [22]. In our system, a vector clock is a vector of integers with a component for each update node 3 , where an update node is defined as a node on which an object can be updated. <p> The xFS [8] system makes use of an invalidation based protocol to ensure cache consistency. The call-backs of AFS [19] also have a similar effect. The Bayou [37] and Coda [22] systems address replication, caching and consistency in mobile environments. Bayou addresses several levels of consistency (e.g., session guarantees <ref> [36] </ref>). Although weaker consistency levels do permit more scalable implementation, we focus on scalable implementations of strong consistency that avoid conflicting updates to an object.
Reference: [37] <author> D. B. Terry, M. M. Theimer, K. Petersen, A. J. Demers, M. J. Spreitzer, and C. H.Hauser. </author> <title> Managing update conflicts in Bayou, a weakly connected replicated storage system. </title> <booktitle> In ACM SOSP, </booktitle> <year> 1995. </year>
Reference-contexts: Distributed file systems also employ caching to employ performance. The xFS [8] system makes use of an invalidation based protocol to ensure cache consistency. The call-backs of AFS [19] also have a similar effect. The Bayou <ref> [37] </ref> and Coda [22] systems address replication, caching and consistency in mobile environments. Bayou addresses several levels of consistency (e.g., session guarantees [36]). Although weaker consistency levels do permit more scalable implementation, we focus on scalable implementations of strong consistency that avoid conflicting updates to an object.
Reference: [38] <author> F. J. Torres-Rojas and M. Ahamad. </author> <title> Plausible Clocks: Constant size logical clocks for distributed systems. </title> <booktitle> In Proceedings of the 10th Workshop on Distributed Algorithms (WDAG), </booktitle> <address> Italy, </address> <month> October </month> <year> 1996. </year>
Reference-contexts: If this is not true, the scalability of the vector clock could become an issue. We do not strictly need a component for each update node and more compact logical clocks can be used in place of vector clocks <ref> [38] </ref>. 10 to be valid. 5.1 Clock Rules Since we want to order views by logical clock times, clocks need to be advanced to reflect view changes.
Reference: [39] <author> R. Y. Wang and T. E. Anderson. xFS: </author> <title> A wide area mass storage file system. </title> <booktitle> In Proceedings of the 4th Workshop on Workstation Operating Systems, </booktitle> <month> Oct </month> <year> 1993. </year>
Reference: [40] <author> K. Worrell. </author> <title> Invalidation in large scale network object caches. </title> <type> Master's thesis. </type> <institution> University of Colorado, </institution> <year> 1994. </year> <month> 29 </month>
Reference-contexts: We enumerate some of the related systems (detailed comparisons are not included due to space constraints). Consistency issues in the context of the Web have been discussed in <ref> [17, 29, 40] </ref>. The protocols studied include ones based on time-to-live (TTL), which only provides weak consistency, and invalidation and polling based protocols for strong consistency.
References-found: 40

