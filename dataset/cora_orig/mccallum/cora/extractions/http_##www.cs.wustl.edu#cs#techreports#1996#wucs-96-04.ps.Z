URL: http://www.cs.wustl.edu/cs/techreports/1996/wucs-96-04.ps.Z
Refering-URL: http://www.cs.wustl.edu/cs/cs/publications.html
Root-URL: 
Email: gopal@dworkin.wustl.edu guru@flora.wustl.edu  
Title: Bringing Real-time Scheduling Theory and Practice Closer for Multimedia Computing  
Author: R. Gopalakrishnan Gurudatta M. Parulkar 
Address: in St.Louis  
Affiliation: Department of Computer Science Washington University  
Abstract: This paper seeks to bridge the gap between theory and practice of real-time scheduling in the domain of multimedia computer systems. We show that scheduling algorithms that are good in theory, often have practical limitations. However when these algorithms are modified based on practical considerations, existing theoretical results cannot be used as they are. In this paper we motivate the need for new scheduling schemes for multimedia protocol processing, and demonstrate their real-time performance in our prototype implementation. We then explain the observed results by analysis and measurement. More specifically, we show that using strict preemption can introduce overheads in protocol processing such as more context switching and extra system calls. We present our scheduling scheme called rate-monotonic with delayed preemption (rmdp) and show how it reduces both these overheads. We then develop the analytical framework to analyze rmdp and other scheduling schemes that lie in the region between strict (immediate) preemption and no preemption. Byproducts of our analysis include simpler schedulability tests for non-preemptive scheduling, and a variant of rate-monotonic scheduling that has fewer preemptions. Finally, we measure the overhead due to context switching on Pentium and Sparc-1 machines and its impact on real-time performance. We show that when scheduling clock interrupts occur every 1 millisecond, rmdp can lessen the overhead of context switching leading to an increase in utilization of as much as 8%. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Chen, J.B., et. al., </author> <title> "The Measured Performance of Personal Computer Operating Systems," </title> <booktitle> 15 th ACM SOSP, </booktitle> <month> Dec. </month> <year> 1995. </year>
Reference-contexts: A system call involves crossing the user-kernel boundary. For our Pentium machine running netbsd, this overhead is about 770 processor cycles (or 280 instructions) <ref> [1] </ref>. <p> We are currently looking into ways to do this. Estimating gains from saving system calls The measurements presented earlier only consider gains due to reduction in preemptions. We can also model the gains due to saving on locking system calls in a simple manner. If we assume from <ref> [1] </ref> that each system calls is 770 cycles, then one pair of lock set/release operations should take (assuming cycle time is 10 nanoseconds) 770 fl 2 fl 10 = 0:015 msec.
Reference: [2] <author> Gopalakrishnan R., Parulkar G.M., </author> <title> "Real-time Upcalls: A Mechanism to Provide Real-time Processing guarantees," </title> <type> Tech. Rep. </type> <institution> WUCS-95-06, Washington University, St.Louis, </institution> <year> 1995. </year>
Reference-contexts: Also we show by experiment that rmdp reduces the number of involuntary context switches thus increasing useful cpu utilization. Full details of the rtu implementation including security issues, system call interface, other efficiency benefits, and protocol performance measurements can be found in <ref> [2, 4] </ref>. Other research groups have used periodic real-time threads [15, 9] to implement protocol processing. However these solutions do not cater to the special needs of protocol processing, leading to overheads caused by locking and context switching.
Reference: [3] <author> Gopalakrishnan R., Parulkar G.M., </author> <title> "A Generalized Preemption Model for Real-time Scheduling," </title> <type> Tech. Rep. </type> <institution> WUCS-96-04, Washington University, St.Louis, </institution> <year> 1996. </year>
Reference: [4] <author> Gopalakrishnan R., Parulkar G.M., </author> <title> "A Real-time Upcall Facility for Protocol Processing with QoS Guarantees," </title> <booktitle> (Poster) 15 th ACM SOSP, </booktitle> <month> Dec. </month> <year> 1995. </year>
Reference-contexts: Also we show by experiment that rmdp reduces the number of involuntary context switches thus increasing useful cpu utilization. Full details of the rtu implementation including security issues, system call interface, other efficiency benefits, and protocol performance measurements can be found in <ref> [2, 4] </ref>. Other research groups have used periodic real-time threads [15, 9] to implement protocol processing. However these solutions do not cater to the special needs of protocol processing, leading to overheads caused by locking and context switching.
Reference: [5] <author> Jeffay, K., Stanat, D.F., Martel, C.U., </author> <title> "On Non-Preemptive Scheduling of Periodic and Sporadic Tasks," </title> <booktitle> 12 th IEEE Real-Time Systems Symposium, </booktitle> <month> Dec </month> <year> 1991. </year>
Reference-contexts: Non-preemptive scheduling schemes have many practical advantages from the implementation standpoint. As stated in <ref> [5] </ref>, they are easier to implement, and their overheads are easier to characterize. A necessary and sufficient condition is also derived in [5] to determine if a task set is schedulable under a non-preemptive edf scheduling scheme. <p> Non-preemptive scheduling schemes have many practical advantages from the implementation standpoint. As stated in <ref> [5] </ref>, they are easier to implement, and their overheads are easier to characterize. A necessary and sufficient condition is also derived in [5] to determine if a task set is schedulable under a non-preemptive edf scheduling scheme. <p> The problem with the above test is that the time complexity of evaluating the second condition is polynomial in the maximum task period <ref> [5] </ref>. This is because the test has to consider all task arrivals for a duration equal to the maximum task period. We have obtained a much simpler test for non-preemptive edf by considering it as a special case of the threshold and delayed preemption schemes. <p> U 1 max C r (1=T 1 1=T r ) (5) Equation 5 has a time complexity of O (n) which is a vast improvement over the test in <ref> [5] </ref>. However our test only gives a sufficient condition for schedulability whereas the test in [5] provides a necessary and sufficient condition. In the next section we simulate task sets of different characteristics to see how close our sufficient condition is to the optimal condition given in [5]. 7.1 Comparing the <p> U 1 max C r (1=T 1 1=T r ) (5) Equation 5 has a time complexity of O (n) which is a vast improvement over the test in <ref> [5] </ref>. However our test only gives a sufficient condition for schedulability whereas the test in [5] provides a necessary and sufficient condition. In the next section we simulate task sets of different characteristics to see how close our sufficient condition is to the optimal condition given in [5]. 7.1 Comparing the Sufficient and Optimal Conditions We compare the simple utilization based sufficiency condition (Equation 5) to <p> the test in <ref> [5] </ref>. However our test only gives a sufficient condition for schedulability whereas the test in [5] provides a necessary and sufficient condition. In the next section we simulate task sets of different characteristics to see how close our sufficient condition is to the optimal condition given in [5]. 7.1 Comparing the Sufficient and Optimal Conditions We compare the simple utilization based sufficiency condition (Equation 5) to the optimal, but more complex necessary and sufficient conditions derived in [5]. <p> simulate task sets of different characteristics to see how close our sufficient condition is to the optimal condition given in <ref> [5] </ref>. 7.1 Comparing the Sufficient and Optimal Conditions We compare the simple utilization based sufficiency condition (Equation 5) to the optimal, but more complex necessary and sufficient conditions derived in [5]. We make the comparison by generating task sets based on some criteria, and determining the breakdown utilization [7] predicted by the two tests. Breakdown utilization is defined as follows. The execution time for each task is multiplied by a constant scaling factor ff while the periods remain fixed. <p> The difference between the breakdown utilizations for the two tests is a measure of the amount by which the simple sufficiency condition underestimates the scheduling capacity. For evaluating the conditions in <ref> [5] </ref> we used a simplified method suggested in [6]. We vary two parameters while generating a task set-the number of tasks per task set, and the range of periods of tasks in a given task set. <p> When the number of tasks per set is 50 and above, the error is within 10% for all task sets. We therefore conclude that the sufficiency bound is very useful for larger task sets. It must be noted that the complexity of evaluating the necessary condition in <ref> [5] </ref> increases with the number of tasks, which makes our simpler test even more preferable. 8 Mixed Scheduling-A Modification to RM In this section we use our earlier results to analyze a simple variation of the rate monotonic scheme.
Reference: [6] <author> Jeffay, K., Stone, </author> <title> D.L., "Accounting for Interrupt Handling Costs in Dynamic Priority Task Systems," </title> <booktitle> 14 th IEEE Real-Time Systems Symposium, </booktitle> <month> Dec </month> <year> 1993. </year>
Reference-contexts: The difference between the breakdown utilizations for the two tests is a measure of the amount by which the simple sufficiency condition underestimates the scheduling capacity. For evaluating the conditions in [5] we used a simplified method suggested in <ref> [6] </ref>. We vary two parameters while generating a task set-the number of tasks per task set, and the range of periods of tasks in a given task set.
Reference: [7] <author> Katcher et. al., </author> <title> "Engineering and Analysis of Fixed Priority Schedulers," </title> <journal> IEEE Transactions on Software Engineering, </journal> <month> Sep </month> <year> 1993. </year>
Reference-contexts: The reduction is equal to the maximum value of B i =T i over all tasks, where B i is the time for which task i can be blocked, and T i is its period. Blocking due to other system events such as periodic timer interrupts is considered in <ref> [7] </ref>. 3.1 Inadequacy of Existing Results None of the results in Table 2 can be directly used to model delayed preemption. The fully preemptive test does not hold because it assumes tasks cannot be blocked. <p> An advantage of delayed preemption is that it can save involuntary context switches an example of which is P 1 . The results in <ref> [7] </ref> only account for timer handling and exit times, and makes a simplified assumption that every arrival causes a preemption. On the other hand, our work studies policy blocking in a systematic manner. It also measures preemption costs with greater precision and shows how it can be reduced. <p> We make the comparison by generating task sets based on some criteria, and determining the breakdown utilization <ref> [7] </ref> predicted by the two tests. Breakdown utilization is defined as follows. The execution time for each task is multiplied by a constant scaling factor ff while the periods remain fixed.
Reference: [8] <author> Katcher, D.I., </author> <title> "Engineering and Analysis of Real-time Operating Systems," </title> <type> PhD Thesis, </type> <institution> Carnegie Mellon University, </institution> <year> 1994. </year>
Reference-contexts: This shows that it is important to distinguish between blocking caused due to overhead and blocking due to other tasks. Borrowing terminology in <ref> [8] </ref> we characterize existing results as analyses of mechanism blocking i.e., concerned with overheads caused due to system activities.
Reference: [9] <author> Khanna, S., et. al., </author> <title> "Realtime Scheduling in SunOS5.0," </title> <booktitle> USENIX, Winter 1992, </booktitle> <address> pp.375-390. </address>
Reference-contexts: Full details of the rtu implementation including security issues, system call interface, other efficiency benefits, and protocol performance measurements can be found in [2, 4]. Other research groups have used periodic real-time threads <ref> [15, 9] </ref> to implement protocol processing. However these solutions do not cater to the special needs of protocol processing, leading to overheads caused by locking and context switching.
Reference: [10] <author> Lehoczky, J.P., Sha, L., </author> <title> "Performance of Real-Time Bus Scheduling Algorithms," ACM Performance Evaluation Review, </title> <address> Vol.14, No.1, </address> <month> May </month> <year> 1986. </year>
Reference: [11] <author> Liu, C.L. and Layland, J.W., </author> <title> "Scheduling Algorithms for Multiprogramming in a Hard-Real-Time Environment," </title> <journal> JACM, </journal> <volume> Vol. 20,No. 1, </volume> <month> January </month> <year> 1973. </year>
Reference-contexts: A task has a period T and a computation requirement C. The utilization of a task is C=T , and the total utilization U of a set of tasks is the sum of their individual utilizations. We start with the well known rm and edf scheduling algorithms introduced in <ref> [11] </ref>. rm gives higher priorities to tasks with smaller periods, and edf gives higher priorities to tasks with earlier deadlines. The analysis in [11] assumed a uniprocessor system where tasks are independent, and deadlines are equal to the periods. <p> We start with the well known rm and edf scheduling algorithms introduced in <ref> [11] </ref>. rm gives higher priorities to tasks with smaller periods, and edf gives higher priorities to tasks with earlier deadlines. The analysis in [11] assumed a uniprocessor system where tasks are independent, and deadlines are equal to the periods. It also assumes that preemption is immediate i.e, a running task is preempted as soon as a higher priority task becomes runnable and the context switch time is zero. <p> The schedulability test can therefore be written as U = i=1 1rn It can be easily seen that for K r = 1 the test reduces to the standard result in <ref> [11] </ref>. It must be noted that the above result holds for any combination of task periods.
Reference: [12] <author> Pingali, S., </author> <title> "Protocol and Real Time Scheduling Issues for Multimedia Applications," </title> <type> PhD Thesis, </type> <institution> University of Massachusetts, Amherst, </institution> <month> Sep </month> <year> 1994. </year>
Reference-contexts: We show that any set of tasks that are schedulable by the rm policy, are schedulable by the mixed policy. An interesting feature of the mixed policy is that it has fewer context switches compared to rm. In fact it is shown in <ref> [12] </ref> that edf has fewer context switches than the rm for periodic tasks.
Reference: [13] <author> Sha, L. et. al., </author> <title> "Priority Inheritance Protocols: An Approach to Real-Time Synchronization," </title> <journal> IEEE Transactions on Computers, Vol.39, </journal> <volume> No.9, </volume> <month> Sep </month> <year> 1990. </year>
Reference-contexts: Strict preemption requires that distinct protocol tasks that share data (such as buffer lists and packet queues) lock them before access. In a real-time scheduling environment lock operations must be mediated by the os to prevent unbounded priority inversion <ref> [13] </ref>. Thus system calls for locking increase per packet processing costs, counteracting efforts that have gone into speeding up packet processing. Likewise, involuntary context switches due to strict preemption causes cpu cycles to be wasted and reduces useful utilization. <p> Blocking occurs when a task is prevented from running by a lower priority task. Blocking that occurs when a lower priority task is in a critical section of code is considered in <ref> [13] </ref>. It can be seen that blocking reduces the utilization bound compared to the idealized case. <p> U n (2 1=n 1) max c r (1=T 1 1=T r ) (1) 1rn The above results give an increased utilization bound compared to <ref> [13] </ref> where the reduction in utilization due to blocking would be c max =T 1 . 6.2 Threshold Preemption In this scheme a task J r can block another task for a maximum time C r . Thus r C r . <p> The schedulability test can therefore be written as U = i=1 1rn 9 6.2.1 Improvement over Existing Results For both rm and edf scheduling, the improvement in utilization compared to the result given in <ref> [13] </ref> is equal to u r . As K r approaches 1:0, the unavailable utilization given by [13] approaches u r whereas in our case it approaches 0. <p> schedulability test can therefore be written as U = i=1 1rn 9 6.2.1 Improvement over Existing Results For both rm and edf scheduling, the improvement in utilization compared to the result given in <ref> [13] </ref> is equal to u r . As K r approaches 1:0, the unavailable utilization given by [13] approaches u r whereas in our case it approaches 0.
Reference: [14] <author> Sha, L., Lehoczky, J.P., Rajkumar, R., </author> <title> "Solutions for Some Practical Problems in Prioritized Preemptive Scheduling," </title> <booktitle> IEEE Real-Time Systems Symposium, </booktitle> <month> Dec </month> <year> 1986. </year>
Reference: [15] <author> Tokuda, H., Nakajima, T., Rao, P., </author> <title> "Real-Time Mach: Towards Predictable Real-time Systems," </title> <booktitle> USENIX Mach Workshop, </booktitle> <month> Oct </month> <year> 1990. </year>
Reference-contexts: Full details of the rtu implementation including security issues, system call interface, other efficiency benefits, and protocol performance measurements can be found in [2, 4]. Other research groups have used periodic real-time threads <ref> [15, 9] </ref> to implement protocol processing. However these solutions do not cater to the special needs of protocol processing, leading to overheads caused by locking and context switching.
References-found: 15

