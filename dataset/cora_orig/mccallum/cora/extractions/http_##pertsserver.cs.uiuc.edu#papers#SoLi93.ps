URL: http://pertsserver.cs.uiuc.edu/papers/SoLi93.ps
Refering-URL: http://pertsserver.cs.uiuc.edu/papers/
Root-URL: http://www.cs.uiuc.edu
Title: Maintaining Temporal Consistency: Pessimistic vs. Optimistic Concurrency Control  
Keyword: Index terms Data temporal consistency, periodic job model, real-time scheduling, multiversion concurrency control, performance evaluation.  
Abstract: We study the performance of concurrency control algorithms in maintaining temporal consistency of shared data in hard real-time systems. In our model, a hard real-time system consists of periodic tasks which are either write-only, read-only or update transactions. Transactions may share data. Data objects are temporally inconsistent when their ages and dispersions are greater than the absolute and relative thresholds allowed by the application. Real-time transactions must read temporally consistent data in order to deliver correct results. Based on this model, we have evaluated the performance of two well-known classes of concurrency control algorithms that handle multiversion data: the two-phase locking and the optimistic algorithms, as well as the rate-monotonic and earliest-deadline-first scheduling algorithms. The effects of using the priority inheritance and stack-based protocols with lock-based concurrency control are also studied. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. W.-S. Liu, K.-J. Lin, and X. Song. </author> <title> A position paper on scheduling hard real-time transactions. </title> <booktitle> In Proceedings of IEEE Workshop on Real-Time Operating Systems and Software, </booktitle> <month> May </month> <year> 1988. </year>
Reference-contexts: These dimensions are the transaction parameters discussed below. Phases and Periods | We experimented with both in-phase and random-phase transactions in order to determine whether temporal consistency is sensitive to the phases of transactions that share data. Each period is uniformly distributed over the interval <ref> [1; B] </ref>, where B is the period ratio, the ratio of the longest period to the shortest period in a workload. Utilization distribution | We varied the execution times of transactions by using different utilization distributions.
Reference: [2] <author> X. Song and J. W.-S. Liu. </author> <title> Performance of multiversion concurrency control algorithms in maintaining temporal consistency. </title> <booktitle> In Proceedings of IEEE 14th Annual International Computer Software & Applications Conference, </booktitle> <pages> pages 132-139, </pages> <month> October </month> <year> 1990. </year>
Reference: [3] <author> X. Song and J. W.-S. Liu. </author> <title> How well can data temporal consistency be maintained? In Proceedings of 1992 IEEE Symposium on Computer-Aided Control System Design, </title> <month> March </month> <year> 1992. </year>
Reference-contexts: Hereafter, we refer to a periodic sequence of transactions as a periodic transaction. When it is unnecessary to distinguish them, we refer to both a periodic transaction and an individual transaction in a sequence as a transaction. Transactions read and/or write data objects as they execute <ref> [3] </ref>. Some data objects are models of real-world objects, for example, the altitude and velocity of an aircraft. The real-world objects are monitored by sensors, and their values are sampled periodically. An instant at which the value of a real-world object is sampled is called a sampling time. <p> This computation is an update transaction; it reads the inertial data, wind speed and direction, etc., and computes the desired position toward the planned destination. Temporal Consistency We define the temporal consistency of data in terms of the age and dispersion (of ages) of the data <ref> [3] </ref>. To define age and dispersion, we note again that an image x is updated periodically by the write-only transaction for the corresponding real-world object X . As a new value of an image is written, an old value of the image read by other transactions ages.
Reference: [4] <author> K. Vidyasankar. </author> <title> Generalized theory of serializability. </title> <journal> Acta Informatica, </journal> <volume> 24 </volume> <pages> 105-119, </pages> <year> 1987. </year>
Reference: [5] <author> A. K. Mok. </author> <title> Fundamental design problems of distributed systems for the hard real-time environment. </title> <type> Ph.D. dissertation, </type> <institution> Massachusetts Institute of Technology, </institution> <month> May </month> <year> 1983. </year> <month> 20 </month>
Reference: [6] <author> L. Sha, R. Rajkumar, and J. P. Lehoczky. </author> <title> Concurrency control for distributed real-time databases. </title> <journal> Sigmod Records, </journal> <volume> 17(1) </volume> <pages> 82-97, </pages> <month> March </month> <year> 1988. </year>
Reference: [7] <author> S. H. Son and R. P. Cook. </author> <title> Scheduling and consistency in real-time database systems. </title> <booktitle> In Proceedings of the 6th IEEE Workshop on Real-Time Operating Systems and Software, </booktitle> <pages> pages 42-45, </pages> <month> May </month> <year> 1989. </year>
Reference: [8] <author> C. L. Liu and J. W. Layland. </author> <title> Scheduling algorithms for multiprogramming in a hard real-time environment. </title> <journal> Journal of ACM, </journal> <volume> 20(1) </volume> <pages> 46-61, </pages> <month> January </month> <year> 1979. </year>
Reference-contexts: They may read temporally inconsistent data or may simply not be able to produce their results on time. This paper studies the time characteristics of data for a class of hard real-time applications that can be characterized by the periodic-job model <ref> [8] </ref>. We extend this model by considering the time properties of the data accessed by each task. <p> Based on this extended model, we evaluated the performance of two well-known classes of concurrency control algorithms the pessimistic and optimistic [4,5,6,7] and two well-known priority-based preemptive scheduling algorithms the rate-monotonic and earliest-deadline-first algorithms <ref> [8] </ref> in maintaining temporal consistency of data. Contrary to our intuition, we found that the optimistic concurrency control algorithm is generally poorer in their ability to maintain temporal consistency of data than pessimistic algorithms, even though the former allows more tasks to meet their deadlines. <p> Section 4 discusses the performance metrics and workload characteristics. Section 5 presents the results of our simulation experiments. Section 6 summarizes the conclusions drawn from the results of this study. 2 Model and Temporal Consistency In the traditional periodic-job model <ref> [8] </ref>, the workload to be scheduled on a processor is a set J = fJ 1 ; J 2 ; : : : ; J m g of m periodic jobs; each job J i is a periodic sequence of tasks that carry out the same computation. <p> The rate-monotonic and earliest-deadline-first algorithms, the best known algorithms of this type <ref> [8] </ref>, are studied here. These algorithms assign priorities to tasks. Scheduling decisions are made when a new task becomes ready and when a task is completed. At each decision point, the ready task with the highest priority is executed. The rate-monotonic algorithm assigns priorities to jobs according to their periods. <p> The worst-case feasible utilizations of the rate-monotonic algorithm and the earliest-deadline-first algorithm are m (2 1=m 1) and 1, respectively, when the jobs are independent <ref> [8] </ref>. 3 The Extended Model Our model of a hard real-time system is an extension of this periodic-job model. In the extended model, every task in a periodic job is either a read-only, write-only or update (read and write) transaction.
Reference: [9] <author> L. Sha, R. Rajkumar, and J. P. Lehoczky. </author> <title> Priority inheritance protocols. </title> <type> Technical Report CMU-CS-87-181, </type> <institution> Carnegie Mellon University, </institution> <month> November </month> <year> 1987. </year>
Reference: [10] <author> M.-I. Chen and K.-J. Lin. </author> <title> Dynamic priority ceilings: A concurrency control protocol for real-time systems. </title> <type> Technical Report No. </type> <institution> UIUCDCS-R-89-1511, Department of Computer Science, University of Illinois, </institution> <month> April </month> <year> 1989. </year>
Reference: [11] <author> T. P. Baker. </author> <title> A stack-based resource allocation policy for realtime processes. </title> <booktitle> In Proceedings of IEEE 11th Real-Time Systems Symposium, </booktitle> <pages> pages 191-200, </pages> <month> December </month> <year> 1990. </year>
Reference-contexts: These results can be used to guide the design of applications: we can make it easier to maintain temporal consistency by avoiding undesirable parameters. Previous work on scheduling periodic jobs that share data includes the priority inheritance protocols [9,10] and stack-based protocol <ref> [11] </ref>. These protocols can be used to control the duration of priority inversion, that is, the duration when a higher priority task is blocked by a lower priority task. We evaluate here the improvement in temporal consistency when these protocols are used to control priority inversion.
Reference: [12] <author> R. Abbott and H. Garcia-Molina. </author> <title> Scheduling real-time transactions: A performance evaluation. </title> <booktitle> In Proceedings of the 14th International Conference on Very Large Data Bases, </booktitle> <pages> pages 1-12, </pages> <month> August </month> <year> 1988. </year>
Reference: [13] <author> J. Huang, J. A. Stankovic, D. Towsley, and K. Ramamritham. </author> <title> Experimental evaluation of real-time transaction processing. </title> <booktitle> In Proceedings of IEEE 10th Real-Time Systems Symposium, </booktitle> <pages> pages 144-153, </pages> <month> December </month> <year> 1989. </year>
Reference: [14] <author> J. R. Haritsa, M. J. Carey, and M. Livny. </author> <title> On being optimistic about real-time constraints. </title> <booktitle> In Proceedings of the 1990 ACM PODS Symposium, </booktitle> <month> April </month> <year> 1990. </year>
Reference-contexts: This is again due to preemptions of transactions. Optimistic concurrency control was shown to outperform lock-based concurrency control in real-time databases <ref> [14] </ref> where transactions have random parameters. We found that the performance of the optimistic algorithm is poor in maintaining temporal consistency in real-time systems that consist of periodic activities.
Reference: [15] <author> R. Snodgrass and I. Ahn. </author> <title> Temporal databases. </title> <journal> IEEE Computer, </journal> <volume> 19(9) </volume> <pages> 35-42, </pages> <month> September </month> <year> 1986. </year>
Reference-contexts: Each image x is dated by the sampling time of the corresponding real-world object X . The latest sampling time of X is the valid time <ref> [15] </ref> of its image x. In addition to images, other data objects in the system are either derived objects or invariant objects. The value of a derived object is computed from the values of a set of images and/or other objects.
Reference: [16] <author> B. T. Blaustein, H. Garcia-Molina, D. R. Ries, R. M. Chilenskas, and C. W. Kaufman. </author> <title> Maintaining replicated databases even in the presence of network partitions. </title> <booktitle> In Proceedings of the 16th Annual Electronics & Aerospace Conference and Exposition, </booktitle> <pages> pages 353-360, </pages> <month> September </month> <year> 1983. </year>
Reference-contexts: The value of a derived object is computed from the values of a set of images and/or other objects. It is dated by the time at which the oldest object in the set is dated. (The notion of derived objects is similar to that of computed attributes in <ref> [16] </ref>.) For example, in an autopilot system, the wind speed is sensed, sampled and recorded every 2 seconds. The flight control task reads the wind speed and other parameters and computes the projected heading of the aircraft. In our model, the wind speed is an image.
Reference: [17] <author> C. L. Liu and J. W.-S. Liu. </author> <title> Linear Systems Analysis. </title> <publisher> McGraw Hill, </publisher> <year> 1975. </year>
Reference-contexts: Typically, the faster the value of a real-world object changes, the shorter is the period of the write-only transaction to update the corresponding image. (The period is determined by the Nquist sampling theorem <ref> [17] </ref>.) Therefore, this definition of age captures the fact that the faster the value of an image changes, the faster its versions age. The age of an image is the age of its most recent version. In the absence of any failure, the age of an image is always zero.
Reference: [18] <author> M. Carey and W. A. Muhanna. </author> <title> The preformance of multiversion concurrency control algorithms. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 4(4) </volume> <pages> 338-378, </pages> <month> November </month> <year> 1985. </year>
Reference-contexts: be for the results of computations based on them to be considered correct. 3 Multiversion Concurrency Control The concurrency control algorithms evaluated here support multiple versions, which has been shown to improve data availability and transaction throughput despite of the additional overhead in locating and accessing older versions of data <ref> [18] </ref>. These algorithms are based on the well-known version pool algorithm [19] and the broadcast commit algorithm [20,21]. They maintain weak consistency [19]. They guarantee that update transactions execute in a serial-izable manner among themselves, and each read-only transaction sees a consistent view of the database.
Reference: [19] <author> A. Chan and R. Gray. </author> <title> Implementing distributed real-only transactions. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-11(2):205-212, </volume> <month> February </month> <year> 1985. </year>
Reference-contexts: These algorithms are based on the well-known version pool algorithm <ref> [19] </ref> and the broadcast commit algorithm [20,21]. They maintain weak consistency [19]. They guarantee that update transactions execute in a serial-izable manner among themselves, and each read-only transaction sees a consistent view of the database. Write-only transactions do not read any data. <p> These algorithms are based on the well-known version pool algorithm <ref> [19] </ref> and the broadcast commit algorithm [20,21]. They maintain weak consistency [19]. They guarantee that update transactions execute in a serial-izable manner among themselves, and each read-only transaction sees a consistent view of the database. Write-only transactions do not read any data. Their write sets are disjoint from each other and from the write sets of update transactions. <p> Their write sets are disjoint from each other and from the write sets of update transactions. When a write-only transaction writes an image in each period, it creates a new version of the image. We simulated four variations of the well-known version pool algorithm <ref> [19] </ref>. All of them assume that the data objects accessed by every transaction are known a priori; predeclaration of data access [22] is required. The results presented in Section 5 are primarily on the simplest variation: 2PL algorithm with pre-locking.
Reference: [20] <author> D. Menasce and T. Nakanishi. </author> <title> Optimistic versus pessimistic concurrency control mechanisms in database management systems. </title> <journal> Information Systems, </journal> <volume> 7(1), </volume> <year> 1982. </year>
Reference: [21] <author> J. Robinson. </author> <title> Design of concurrency controls for transaction processing systems. </title> <type> Ph.D. dissertation, </type> <institution> Carnegie Mellow University, </institution> <year> 1982. </year>
Reference: [22] <author> P. A. Bernstein and N. Goodman. </author> <title> Concurrency control in distributed databases. </title> <journal> Computing Surveys, </journal> <volume> 13(2) </volume> <pages> 185-221, </pages> <month> June </month> <year> 1981. </year>
Reference-contexts: When a write-only transaction writes an image in each period, it creates a new version of the image. We simulated four variations of the well-known version pool algorithm [19]. All of them assume that the data objects accessed by every transaction are known a priori; predeclaration of data access <ref> [22] </ref> is required. The results presented in Section 5 are primarily on the simplest variation: 2PL algorithm with pre-locking. Like the version pool algorithm, each transaction is assigned a startup timestamp when it begins execution and a commit timestamp when it commits.
Reference: [23] <author> X. Song. </author> <title> Data Temporal Consistency in Hard Real-Time Systems. </title> <type> Ph.D. dissertation, </type> <institution> University of Illinois at Urbana-Champaign, </institution> <month> May </month> <year> 1992. </year>
Reference-contexts: The other three variations of the version pool algorithms simulated are 2PL-PI algorithm, 2PL-SB with pre-locking, and 2PL-SB without pre-locking. They are described in the appendix. We will compare their performance with that of the 2PL-with pre-locking algorithm in Section 5. Details on their performance can be found in <ref> [23] </ref>. We simulated an extended version of the broadcast commit algorithm [20,21], an optimistic concurrency control known to work well in real-time databases, especially when conflicts between transactions are infrequent [14,24,25]. The extended algorithm accommodates multiver-sion data and periodic transactions. <p> In this case, the age is greater than the dispersion. In our simulations, we give A and R the same value of 1. We expected the percentage of inconsistent transactions to be smaller as the value of A and R increased. Our simulation results confirmed this conjecture <ref> [23] </ref>. We will not include the results for larger values of A and R in this paper due to space limitations. 5 Simulation Results In this section, we present the simulation results. Due to space limitation, many details are omitted; they can be found in [23]. <p> simulation results confirmed this conjecture <ref> [23] </ref>. We will not include the results for larger values of A and R in this paper due to space limitations. 5 Simulation Results In this section, we present the simulation results. Due to space limitation, many details are omitted; they can be found in [23]. In each series of experiments, we started with a baseline workload and varied the conflict pattern, read-only percentage, period ratio, transaction phases, utilization distribution, and the number of transactions. In the baseline workload, there is no read-only transaction, and all the update transactions conflict with each other. <p> When the rate-monotonic algorithm fails to schedule some periodic transactions to meet their deadlines, many individual transactions miss their deadlines in a row. Consequently, the maximum age of data is also older when no concurrency control is used <ref> [23] </ref>. Effects of Conflict Patterns We expect the inconsistency percentage to improve when the workload consists of transactions with fewer conflicts. <p> When the period ratio is greater, e.g., B = 50, the optimistic algorithm produces much worse inconsistency than the 2PL algorithm, as shown in the fact that the aborted transactions cause a much higher miss percentage for the optimistic algorithm <ref> [23] </ref>. Effects of Read-only Transactions We expect the performance of both the 2PL algorithm and the optimistic algorithm to improve as the percentage of read-only transactions increases and, hence, data access conflicts decrease. <p> In this case, some read-only transactions may prevent some update transactions from updating their data on time, resulting in a higher miss percentage. Details on this result can be found in <ref> [23] </ref>. workloads in which read-only transactions have longer periods than update transactions. We see a significant improvement in the inconsistency percentage as the read-only percentage increases. <p> However, the maximum age of data is older for the mixed workloads because of preemptions. As in the case of the locking algorithm, the inconsistency percentage is larger when some read-only transactions have shorter periods than some update transactions <ref> [23] </ref>. The results of this series of experiment also tell us how inconsistency percentage depends on period ratio and the concurrency control algorithms used. <p> When B is 200, the breakdown utilization is less than 0.2, and the other performance metrics have significantly worse values than when B = 50 <ref> [23] </ref>. <p> For example, when B = 10 and U = 0:7 (and U = 0:8), the inconsistency percentage for random-phase transactions is almost four times (twice) that of in-phase transactions. We also observed a higher miss percentage for the random-phase transactions <ref> [23] </ref>. This is caused by the higher abort rate of these transactions. We then varied the utilizations of transactions according to the EQ, SH and LH distributions described earlier. <p> However, the inconsistency percentage becomes worse for the SH distribution when U is close to 1. The exact behavior of this and other performance metrics, and explanation of the behavior can be found in <ref> [23] </ref>. We also simulated workloads consisting of different numbers of update transactions. The inconsistency percentage is consistently larger when the optimistic algorithm is used than when the 2PL algorithm is used. Details on this simulation experiment and the results can be found in [23]. 5.4 Effects of Scheduling Algorithms We found <p> of the behavior can be found in <ref> [23] </ref>. We also simulated workloads consisting of different numbers of update transactions. The inconsistency percentage is consistently larger when the optimistic algorithm is used than when the 2PL algorithm is used. Details on this simulation experiment and the results can be found in [23]. 5.4 Effects of Scheduling Algorithms We found that the two scheduling algorithms, rate-monotonic and earliest-deadline-first, exhibit similar behaviors in many cases in terms of maintaining temporal consistency [23]. <p> Details on this simulation experiment and the results can be found in <ref> [23] </ref>. 5.4 Effects of Scheduling Algorithms We found that the two scheduling algorithms, rate-monotonic and earliest-deadline-first, exhibit similar behaviors in many cases in terms of maintaining temporal consistency [23]. For example, the percentage of inconsistent transactions increases as the period ratio becomes greater but decreases when there are fewer conflicts among transactions and when the transaction conflict pattern exhibits locality. <p> The inconsistency percentage and age of data become larger as there are more transactions. The inconsistency becomes worse especially when more shorter period transactions are added to the workload <ref> [23] </ref>. * Temporal consistency of data is highly affected by the transaction conflict pattern. When all transactions conflict, the inconsistency percentage is the worst. On the average, the inconsistency percentage decreases when the amount of transaction conflicts reduces.
Reference: [24] <author> J. R. Haritsa, M. J. Carey, and M. Livny. </author> <title> Dynamic real-time optimistic concurrency control. </title> <booktitle> In Proceedings of IEEE 11th Real-Time Systems Symposium, </booktitle> <pages> pages 94-103, </pages> <month> December </month> <year> 1990. </year>
Reference: [25] <author> J. Huang and J. A. Stankovic. </author> <title> Concurrency control in real-time database systems: Optimistic scheme vs. two-phase locking. </title> <type> Technical Report No. 90-66, </type> <institution> University of Massachusetts, Amherst, </institution> <month> July </month> <year> 1990. </year>
Reference: [26] <author> J. P. Lehoczky, L. Sha, and Y. Ding. </author> <title> The rate monotone scheduling algorithm: Exact characterization and average case behavior. </title> <booktitle> In Proceedings of IEEE 10th Real-Time Systems Symposium, </booktitle> <pages> pages 166-171, </pages> <month> December </month> <year> 1989. </year> <month> 21 </month>
Reference-contexts: We can see in Figure 7 (b) that the age of data is the oldest for the 2PL-SB algorithm without pre-locking. 5.3 Effects of Other Workload Parameters Lehoczky et al. pointed out in <ref> [26] </ref> that schedulability of a set of independent periodic jobs is strongly dependent upon the relative lengths of their periods. In particular, the breakdown utilization increases and converges to 1 as the period ratio B increases.
References-found: 26

