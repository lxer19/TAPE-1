URL: http://www.dai.ed.ac.uk/students/ianf/Research/Papers/smith-nau-stratplanning.ps
Refering-URL: http://www.dai.ed.ac.uk/students/ianf/Research/
Root-URL: 
Email: nau@cs.umd.edu  
Title: Games: Planning and Learning,  Strategic Planning for Imperfect-Information Games  
Author: Stephen J. J. Smith Dana S. Nau 
Address: College Park, MD 20742 USA  sjsmith@cs.umd.edu College Park, MD 20742 USA  
Affiliation: Computer Science Department Computer Science Department and University of Maryland Institute for Systems Research  University of Maryland  
Note: Papers from the 1993 Fall Symposium, AAAI Press, 1993.  This work supported in part by an AT&T Ph.D. scholarship to Stephen J. J. Smith, Maryland Industrial Partnerships (MIPS) grant 501.15, Great Game Products, and NSF grants IRI-8907890, NSFD CDR-88003012, and IRI-9306580.  
Abstract: Although game-tree search works well in perfect-information games, there are problems in trying to use it for imperfect-information games such as bridge. The lack of knowledge about the opponents' possible moves gives the game tree a very large branching factor, making the tree so immense that game-tree searching is infeasible. In this paper, we describe our approach for overcoming this problem. We develop a model of imperfect-information games, and describe how to represent information about the game using a modified version of a task network that is extended to represent multi-agency and uncertainty. We present a game-playing procedure that uses this approach to generate game trees in which the set of alternative choices is determined not by the set of possible actions, but by the set of available tactical and strategic schemes. In our tests of this approach on the game of bridge, we found that it generated trees having a much smaller branching factor than would have been generated by conventional game-tree search techniques. Thus, even in the worst case, the game tree contained only about 1300 nodes, as opposed to the approximately 6:01fi10 44 nodes that would have been produced by a brute-force game tree search in the worst case. Furthermore, our approach successfully solved typical bridge problems that matched situations in its knowledge base. These preliminary tests suggest that our approach has the potential to yield bridge-playing programs much better than existing ones|and thus we have begun to build a full implementation. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Ballard, B. W. </author> <year> 1983. </year> <title> Non-minimax search strategies for minimax trees: Theoretical foundations and empirical studies. </title> <type> Technical report, </type> <institution> Duke University, Durham, NC. </institution>
Reference-contexts: Some work has been done on extending game-tree search to deal with uncertainty, including Horacek's work on chess (Horacek, 1990), and Ballard's work on backgammon <ref> (Ballard, 1983) </ref>. However, these works do not deal with the kind of uncertainty that we discussed in the introduction, and thus it does not appear to us that these approaches would be sufficient to accomplish our objectives.
Reference: <author> Berliner, H. J.; Goetsch, G.; Campbell, M. S.; and Ebeling, C. </author> <year> 1990. </year> <title> Measuring the performance potential of chess programs. </title> <booktitle> Artificial Intelligence 43 </booktitle> <pages> 7-20. </pages>
Reference: <author> Biermann, A. W. </author> <year> 1978. </year> <title> Theoretical issues related to computer game playing programs. </title> <type> Personal Computing 86-88. </type>
Reference: <author> Cormen, T. H.; Leiserson, C. E.; and Rivest, R. L. </author> <year> 1990. </year> <title> Introduction to Algorithms. </title> <publisher> MIT Press/McGraw Hill. </publisher>
Reference-contexts: We are not employing decision trees (also, and less ambiguously, referred to as comparison trees (Knuth, 1973)) as they are defined in the sorting literature <ref> (Cormen et al., 1990, p. 173) </ref>. We apologize for the confusion, but it is inescapable. 4 In the decision theory literature, what we call external-agent nodes are usually called chance nodes, because decision theorists usually assume that the external agent is random.
Reference: <author> Erol, K.; Nau, D. S.; and Subrahmanian, V. S. </author> <year> 1992. </year> <title> Complexity, decidability and undecidability results for domain-independent planning. </title> <journal> (CS-TR-2797, </journal> <note> UMIACS-TR-91-154, SRC-TR-91-96). Submitted for journal publication. </note>
Reference: <author> Erol, K.; Nau, D. S.; and Hendler, J. </author> <year> 1993. </year> <title> Toward a general framework for hierarchical task-network planning. </title> <booktitle> In AAAI Spring Symposium. </booktitle>
Reference: <author> Feldman, J. A. and Sproull, R. F. </author> <year> 1977. </year> <booktitle> Decision theory and artificial intelligence ii: The hungry monkey. Cognitive Science 1 </booktitle> <pages> 158-192. </pages>
Reference: <author> Feldman, J. A. and Yakimovsky, Y. </author> <year> 1974. </year> <title> Decision theory and artificial intelligence i. a semantics-based region analyzer. </title> <booktitle> Artificial Intelligence 5 </booktitle> <pages> 349-371. </pages>
Reference: <author> French, S. </author> <year> 1986. </year> <title> Decision Theory: An Introduction to the Mathematics of Rationality. </title> <publisher> Wiley. </publisher>
Reference-contexts: Some will make use of the belief 5 This definition of external-agent criterion is somewhat different from the usual definition of decision criterion in decision theory (e.g. <ref> (French, 1986) </ref>, p. 28), which essentially defines decision criteria on a two-level structure of decision nodes and chance nodes, without the belief function p.
Reference: <author> Gamback, B.; Rayner, M.; and Pell, B. </author> <year> 1990. </year> <title> An architecture for a sophisticated mechanical bridge player. </title> <editor> In Beal, D. F. and Levy, D.N.L., editors 1990, </editor> <booktitle> Heuristic Programming in Artificial Intelligence| The Second Computer Olympiad. </booktitle> <publisher> Ellis Horwood. </publisher>
Reference: <author> Gamback, B.; Rayner, M.; and Pell, B. </author> <year> 1993. </year> <title> Pragmatic reasoning in bridge. </title> <type> Technical Report 299, </type> <institution> Computer Laboratory, University of Cambridge. </institution>
Reference: <author> Horacek, H. </author> <year> 1990. </year> <title> Reasoning with uncertainty in computer chess. </title> <booktitle> Artificial Intelligence 43 </booktitle> <pages> 37-56. </pages>
Reference-contexts: Some work has been done on extending game-tree search to deal with uncertainty, including Horacek's work on chess <ref> (Horacek, 1990) </ref>, and Ballard's work on backgammon (Ballard, 1983). However, these works do not deal with the kind of uncertainty that we discussed in the introduction, and thus it does not appear to us that these approaches would be sufficient to accomplish our objectives.
Reference: <author> Knuth, D. E. </author> <year> 1973. </year> <booktitle> The Art of Computer Programming, </booktitle> <volume> Vol. </volume> <month> 3: </month> <title> Sorting and Searching. </title> <publisher> Addison-Wesley Publ. Co. </publisher>
Reference-contexts: We are not employing decision trees (also, and less ambiguously, referred to as comparison trees <ref> (Knuth, 1973) </ref>) as they are defined in the sorting literature (Cormen et al., 1990, p. 173).
Reference: <author> Lee, K.-F. and Mahajan, S. </author> <year> 1990. </year> <title> The development of a world class othello program. </title> <booktitle> Artificial Intelligence 43 </booktitle> <pages> 21-36. </pages>
Reference-contexts: Introduction Although game-tree search works well in perfect-information games (such as chess (Berliner et al., 1990; Levy and Newborn, 1982), checkers (Samuel, 1967), and othello <ref> (Lee and Mahajan, 1990) </ref>), it does not always work so well in other games. One example is the game of bridge. Bridge is an imperfect-information game, in which no player has complete knowledge about the state of the world, the possible actions, and their effects.
Reference: <author> Levy, D. and Newborn, M. </author> <year> 1982. </year> <title> All About Chess and Computers. </title> <publisher> Computer Science Press. </publisher>
Reference: <author> Sacerdoti, E. D. </author> <year> 1974. </year> <title> Planning in a hierarchy of abstraction spaces. </title> <booktitle> Artificial Intelligence 5 </booktitle> <pages> 115-135. </pages>
Reference: <author> Sacerdoti, E. D. </author> <year> 1977. </year> <title> A Structure for Plans and Behavior. </title> <publisher> American Elsevier Publishing Company. </publisher>
Reference-contexts: To represent the tactical and strategic schemes of card-playing in bridge, we use instances of multi-agent methods|structures similar to the task decompositions used in hierarchical single-agent planning systems such as Nonlin (Tate, 1976; Tate, 1977), NOAH <ref> (Sacerdoti, 1977) </ref>, and MOLGEN (Stefik, 1981), but modified to represent multi-agency and uncertainty. To generate game trees, we use a procedure similar to task-network decomposition.
Reference: <author> Sacerdoti, E. D. </author> <year> 1990. </year> <title> The nonlinear nature of plans. </title> <editor> In Allen, J.; Hendler, J.; and Tate, A., editors 1990, </editor> <booktitle> Readings in Planning. </booktitle> <publisher> Morgan Kaufman. </publisher> <pages> 162-170. </pages> <booktitle> Originally appeared in Proc. IJCAI-75, </booktitle> <pages> pp. 206-214. </pages>
Reference: <author> Samuel, A. L. </author> <year> 1967. </year> <title> Some studies in machine learning using the game of checkers. </title> <journal> ii-recent progress. IBM Journal of Research and Development 2 </journal> <pages> 601-617. </pages>
Reference-contexts: Introduction Although game-tree search works well in perfect-information games (such as chess (Berliner et al., 1990; Levy and Newborn, 1982), checkers <ref> (Samuel, 1967) </ref>, and othello (Lee and Mahajan, 1990)), it does not always work so well in other games. One example is the game of bridge. Bridge is an imperfect-information game, in which no player has complete knowledge about the state of the world, the possible actions, and their effects.
Reference: <author> Smith, S. J. J. and Nau, D. S. </author> <year> 1993. </year> <title> Toward an analysis of forward pruning. </title> <booktitle> In AAAI Fall Symposium on Games: Planning and Learning. </booktitle>
Reference-contexts: Since our approach avoids generating all possible moves for all agents, it is in essence a type of forward pruning. Although forward pruning has not worked very well in games such as chess (Biermann, 1978; Truscott, 1981), our study of forward pruning <ref> (Smith and Nau, 1993) </ref> suggests that forward pruning works best in situations where there is a high correlation among the minimax values of sibling nodes. We believe that bridge has this characteristic.
Reference: <author> Stefik, M. </author> <year> 1981. </year> <title> Planning with constraints (MOL-GEN: </title> <booktitle> Part 1). Artificial Intelligence 16 </booktitle> <pages> 111-140. </pages>
Reference-contexts: To represent the tactical and strategic schemes of card-playing in bridge, we use instances of multi-agent methods|structures similar to the task decompositions used in hierarchical single-agent planning systems such as Nonlin (Tate, 1976; Tate, 1977), NOAH (Sacerdoti, 1977), and MOLGEN <ref> (Stefik, 1981) </ref>, but modified to represent multi-agency and uncertainty. To generate game trees, we use a procedure similar to task-network decomposition.
Reference: <author> Tate, A. </author> <year> 1976. </year> <title> Project planning using a hierarchic non-linear planner. </title> <type> Technical Report 25, </type> <institution> Department of Artificial Intelligence, University of Edinburgh. </institution>
Reference: <author> Tate, A. </author> <year> 1977. </year> <title> Generating project networks. </title> <booktitle> In Proc. 5th International Joint Conf. Artificial Intelligence. </booktitle>
Reference: <author> Truscott, T. R. </author> <year> 1981. </year> <title> Techniques used in minimax game-playing programs. </title> <type> Master's thesis, </type> <institution> Duke University, Durham, NC. </institution>
Reference: <author> Wilkins, D. E. </author> <year> 1980. </year> <title> Using patterns and plans in chess. </title> <booktitle> Artificial Intelligence 14 </booktitle> <pages> 165-203. </pages>
Reference: <author> Wilkins, D. E. </author> <year> 1982. </year> <title> Using knowledge to control tree searching. </title> <booktitle> Artificial Intelligence 18 </booktitle> <pages> 1-51. </pages>
References-found: 26

