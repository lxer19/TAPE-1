URL: http://www.cs.berkeley.edu/~kozyraki/papers/1996.TR172.QueueManagement.ps
Refering-URL: http://www.cs.berkeley.edu/~kozyraki/papers/papers.html
Root-URL: 
Title: The Architecture, Operation and Design of the Queue Management Block in the ATLAS I ATM Switch  
Author: Christoforos E. Kozyrakis 
Date: July 1996  
Pubnum: FORTH-ICS TR-172  
Abstract: Among the various switch buffer architectures, output queueing implemented in a completely shared buffer is the one that achieves the highest possible utilization of both output bandwidth and buffer space. The high link throughput, small cell size and additional features of ATM switching, such as multiple classes of service, multicasting and flow control, enforce further extensions to the above scheme and demand pure hardware implementations. In this work we present the hardware block maintaining output queues per priority class in the ATLAS I single chip ATM switch. It also provides support for multicasting and multi-lane credit-based flow control. Techniques such as pipelined and superscalar processing, usually employed in processors' design, are used in order to accommodate for the amount and high speed of operation required. This also modifies the approach to the timing of operations, the control design and the calculation of the hardware complexity. The block was extensively simulated to ensure the correctness of its operation. Although the hardware implementation is currently in progress, the circuits already laid out are presented, while the VLSI design of the remaining blocks is analyzed. In addition, the Priority Enforcer circuit and its full-custom layout is thoroughly described. 
Abstract-found: 1
Intro-found: 1
Reference: [CoST88] <author> J. Coudreuse, W. Sincoskie, J.S. Turner: </author> <title> Guest Editorial in Broadband Packet Communications, </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> vol. 6(8), </volume> <month> December </month> <year> 1988, </year> <pages> pp. 1452-1454. </pages>
Reference-contexts: In order to meet these demands, switches must use flexible buffer architectures and implement high performance data structures for cells stored in them, which were not essential before <ref> [CoST88] </ref>. Since these structures must be updated in rates similar to those of cell arrivals and departures, they must be implemented in hardware [Toba90].
Reference: [Gros92] <author> K. Grosspietsch: </author> <title> Associative Processors and Memories: A survey, </title> <booktitle> IEEE Micro, </booktitle> <month> June </month> <year> 1992, </year> <pages> pp. 12-19. </pages>
Reference-contexts: In this section, we present the two-ported memories and their peripheral circuits already laid out in full-custom CMOS, and also describe the VLSI implementation of the remaining static memory blocks. 9.1 Content-Addressable Memory Cells The VPout and OutMask memory blocks have to be content-addressable (CAM) <ref> [Gros92] </ref> in order to accommodate for the search action in the first stage of credit arrival operations. There are two basic alternatives in the layout of static CAM cells [TroS92], presented in figure 11.
Reference: [HaMa88] <author> M. Haskard, I. </author> <month> May: </month> <title> Analog VLSI Design, nMOS and CMOS, </title> <publisher> Prentice Hall, </publisher> <address> ISBN 0-13-032640-2, </address> <year> 1988. </year>
Reference-contexts: The sense amplifier circuit laid out for these to memory blocks is a typical CMOS single-output operational amplifier <ref> [HaMa88] </ref>, presented in figure 15. The amplifier consists of a four-transistor current mirror, connected to a current source. The output of the amplifier drives an inverter, designed to have a 1.5V threshold voltage. Its output feeds the output latch.
Reference: [HlKa88] <author> M. Hluchyj, M. Karol: </author> <title> Queueing in High-Performance Packet Switching, </title> <journal> IEEE Journal on Sel. Areas in Communications, </journal> <volume> vol. 6, no. 9, </volume> <month> December </month> <year> 1988, </year> <pages> pp. 1587-1597. </pages>
Reference: [KaSS96] <author> M. Katevenis, D. Serpanos, E. Spyridakis: </author> <title> Credit-Flow-Controlled ATM versus Wormohole Routing, </title> <type> Technical Report FORTH-ICS/TR-171, "ICS, </type> <institution> FORTH, </institution> <address> Heraklio, Crete, Greece, </address> <month> July </month> <year> 1996. </year> <note> URL: file://ftp.ics.forth.gr/tech-reports/1996/1996.TR171.ATM vs Wormhole.ps.gz </note>
Reference-contexts: Its aggregate throughput reaches 20 Gigabits/second. It provides shared buffer for 256 ATM cells, using the pipeline memory architecture [KaVE95]. ATLAS also supports configurable VP and VP-VC switching (by using a translation table), both rate and optional credit-based multi-lane back-pressure flow control <ref> [KaSS96] </ref>, load monitoring, link bundling and merging of flow groups. Multicasting is also supported, as long as all the copies of the cell transmitted to different links use the same VP/VC identifier. Internally, the switch has an additional input and output. Thus, it functions as a 17x17 switch.
Reference: [KaSV96] <author> M. Katevenis, D. Serpanos, P Vatsolaki: </author> <title> ATLAS I: A General-Purpose, Single-Chip ATM Switch with Credit-Based Flow Control, Hot Interconnects IV Symposium, </title> <publisher> Stanford Univ., </publisher> <address> CA, USA, </address> <month> Aug. </month> <year> 1996. </year> <note> URL: file://ftp.ics.forth.gr/tech-reports/1996/1996.HOTI.ATLAS I ATMswitchChip.ps.gz </note>
Reference: [KaVE95] <author> M. Katevenis, P. Vatsolaki, A. Efthymiou: </author> <title> Pipelined Memory Shared Buffer for VLSI Switches, </title> <booktitle> Proceedings of the ACM SIGCOMM'95 Conference, </booktitle> <address> Cambridge, Ma., USA, </address> <month> 30 August - 1 Sep. </month> <year> 1995, </year> <note> pp.39-48. URL: file://ftp.ics.forth.gr/tech-reports/1995/1995.SIGCOMM95.PipeMemoryShBuf.ps.gz </note>
Reference-contexts: ATLAS has 16 input and 16 output point-to-point links, each running at 622 Mbits/s. Its aggregate throughput reaches 20 Gigabits/second. It provides shared buffer for 256 ATM cells, using the pipeline memory architecture <ref> [KaVE95] </ref>. ATLAS also supports configurable VP and VP-VC switching (by using a translation table), both rate and optional credit-based multi-lane back-pressure flow control [KaSS96], load monitoring, link bundling and merging of flow groups. <p> The Queue Management block (just as the whole switch) must have enough resources to be able to serve all normal events within one cell-time from their appearance. This is so in order to ensure that the correct data is written/read to/from the shared data buffer <ref> [KaVE95] </ref> and the size of FIFO memories in the credit/cell serialization blocks is kept small . Hence , each memory block must have enough throughput to accommodate for all the accesses that may be performed during the corresponding operations. <p> This imposes the restriction that only one operation, either for cell arrival or cell departure, may start on every clock cycle, but this complies with the operation of the shared data buffer <ref> [KaVE95] </ref> (either a read or a write operation may start on a single cycle). A closer look at table 2 also reveals that the two operations perform accesses to the same memory block in corresponding stages.
Reference: [KSVMC96] <author> M. Katevenis, D. Serpanos, P Vatsolaki, E. Markatos, K. Courcoubetis: </author> <title> ATLAS I Architecture: Architecture of the ATM Switch Chip of ASICCOM, version 1.1, ASICCOM Consortium Internal Document, </title> <month> March </month> <year> 1996. </year>
Reference-contexts: The switch will be fabricated in a 0:5m CMOS technology and its clock frequency will be 50 MHz. 1.2 The Queue Management Block The Queue Management 2 block is the part of the ATLAS I switch responsible for implementing the appropriate data structures for cells within its shared data buffer <ref> [KSVMC96] </ref>. These structures are used in order to keep record of both cells blocked by the flow control protocol and cells ready to be transmitted to their destination, and to be able to serve them in the way defined by the flow control scheme and the priority rules. <p> Size: 54 x 17 bits. The VPout, OutMask and CreditMask memories comprise the CreditLess Cell List sublock, while the LinkList memory with its peripheral circuits form the Ready Queues sublock <ref> [KSVMC96] </ref>. 2. Block Organization Architecture, Operation and Design of the Queue Management Block 5 2. Block Organization 6 Architecture, Operation and Design of the Queue Management Block Another important part of the block is the control logic. <p> These events are cell arrivals, cell departures and credit arrivals. All cell and credit events are served by the QM block, and the switch in general, in a pipelined fashion <ref> [KSVMC96] </ref>. One can imagine the block as a two way superscalar pipelined CPU, where the first processing unit is used for credit arrival operations, while the second one is shared by cell arrivals and departures. <p> Since, ATLAS is a 16 x 16 switch, the maximum number of events per cell-time is 16 cell arrivals, 16 cell departures and 32 credit arrivals <ref> [KSVMC96] </ref>. There is also the case of an additional event per cell-time, e.g. an extra cell arrival caused by a small difference in the clock periods of two neighboring switches, the injection/delivery of a cell through/to the Switch Control and Monitoring block or the execution of a management command. <p> By using these commands, we must be able to read and write every memory entry in the block. The purpose of their existence is to enable testing of the functionality of the block, proper initialization of the memories and the execution of the algorithm for lost cells/credits detection <ref> [KSVMC96] </ref>. All blocks exchange data and addresses for management commands through two busses that run across the whole switch, and connect the various blocks with the Switch Control and Monitoring block.
Reference: [LeBo92] <author> J. LeBoudec, </author> <title> The Asynchronous Transfer Mode : A Tutorial, </title> <journal> Computer Networks and ISDN Systems, </journal> <volume> vol. 24, no. 4, </volume> <month> May </month> <year> 1992. </year>
Reference-contexts: 1. Introduction Asynchronous Transfer Mode (ATM) <ref> [LeBo92] </ref> puts additional requirements both on the speed and the complexity of switches (routers), used as building blocks in networks.
Reference: [OYT89] <author> T. Ogura, J. Yamada, S. Yamada, M. Tan-No: </author> <title> A 20-kbit Associative Memory LSI for Artificial Intelligence Machine, </title> <journal> IEEE Journal of Solid-State Circuits, </journal> <volume> vol. 24, no. 4, </volume> <month> August </month> <year> 1989, </year> <pages> pp. 1014-1020. </pages>
Reference-contexts: Since the search access of CAM memories is usually twice as slow as the read-write accesses, especially in the case where the match-line is discharged by a single memory cell, some care must be taken in order to accelerate it. The match accelerator circuit <ref> [OYT89] </ref>, depicted in figure 13, could be used in order to achieve high-speed search access. This circuit detects if the match-line is being discharged. In this case, it cuts off the match-line from the output line, and the latter is discharged faster, since it has smaller stray capacitance.
Reference: [PaHe95] <author> D. Patterson, J. Hennessy: </author> <title> Computer Architecture : a quantitative approach, </title> <publisher> Morgan Kaufman Publishers, </publisher> <address> ISBN 1-55860-329-8, </address> <year> 1995. </year> <month> 51 </month>
Reference: [PaHe93] <author> D. Patterson, J. Hennessy: </author> <title> Computer Organization : the hardwaresofware interface, </title> <publisher> Mor--gan Kaufman Publishers, </publisher> <address> ISBN 1-55860-281-X, </address> <year> 1993. </year>
Reference-contexts: Since, the credits pipeline has four stages and the cells pipeline has 3, each one operating on either a cell arrival or departure, a single FSM would have 432 (!) different states. The method employed for the QM control unit is the one used for pipelined and superscalar CPUs <ref> [PaHe93] </ref>. Once a pipeline is initiated, all the necessary control signals are calculated on the first stage. They are transferred to the following stages through pipeline registers, until they are "consumed" by the proper stage. <p> In order to confront with this problem, one must first locate the sources of data hazards and the conditions under which they arise, and then provide for a stable solution. Two methods for solving this problem are usually employed <ref> [PaHe93] </ref>. The first one, stalling a pipeline whenever a data hazard occurs, is unacceptable for the ATLAS I switch, since stalling would result to either dropping incoming cells and credits, or underutilizing the output throughput.
Reference: [Sidi91] <author> S. Sidiropoulos: </author> <title> Fast Packet Switches for Asynchronous Transfer Mode, </title> <type> Technical Report FORTH-ICS/TR-25, ICS, </type> <institution> FORTH, Heraklio, Crete, GR, </institution> <month> August </month> <year> 1991, </year> <pages> 69 pages. </pages>
Reference-contexts: First of all it is a three-ported cell, with one CAM and two RAM ports. Furthermore, a variation of the normal CAM port is employed, for which a single bit-line (match enable) is used to search the memory only for logic one and don't care values <ref> [Sidi91] </ref>.
Reference: [ST96] <author> ST-SPICE User Manual, SGS-Thomson, </author> <month> July </month> <year> 1996. </year>
Reference-contexts: The circuit was tested with the STSPICE transistor-level simulator <ref> [ST96] </ref>, provided by SGS-Thomson, under all possible process and environment conditions. 10.5 Cyclic Priority Enforcers As mentioned in section 9, the Priority Enforcer may have to be a cyclic one, in order to guarantee randomness and fairness in the distribution of incoming credits in the case of merging flow-groups.
Reference: [Syn94] <institution> HDL Compiler for Verilog Reference Manual, Synopsys Inc, </institution> <month> March </month> <year> 1994. </year>
Reference-contexts: They all are static memories. On the other hand, control logic and the rest of the block logic will be designed with semi-custom layout techniques. Semi-custom gate-level layout can be produced automatically from functional or behavioral descriptions by using synthesis tools, such as Synopsys <ref> [Syn94] </ref>.
Reference: [TaFr88] <author> Y. Tamir, G. Frazier: </author> <title> High-Performance Multi-Queue Buffers for VLSI Communication Switches, </title> <booktitle> Proc. of the 15th Int. Symp. on Computer Architecture, ACM SIGARCH vol. </booktitle> <volume> 16, no. 2, </volume> <month> May </month> <year> 1988, </year> <pages> pp. 343-354. </pages>
Reference: [Toba90] <author> F.A. Tobagi: </author> <title> Fast Packet Switch Architectures for Broadband Integrated Services Digital Networks, </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> vol. 78, </volume> <month> January </month> <year> 1990, </year> <pages> pp. 133-167. </pages>
Reference-contexts: Since these structures must be updated in rates similar to those of cell arrivals and departures, they must be implemented in hardware <ref> [Toba90] </ref>. Output queues, implemented as linked lists in a completely shared buffer, have been identified as the combination of data structure and buffer architecture that results in high utilization of both available throughput and buffer space [HlKa88][TaFr88].
Reference: [TroS92] <author> N. Troullinos, C. Stormon: </author> <title> Design Issues in Static Content-Addressable Memory Cells, CASE Center Technical Report No. </title> <type> 9208, </type> <institution> CASE Center, Syracuse University, </institution> <month> August </month> <year> 1992. </year>
Reference-contexts: There are two basic alternatives in the layout of static CAM cells <ref> [TroS92] </ref>, presented in figure 11. The left one, 9 transistor cell, consists of a traditional SRAM cell, plus a two-transistor exclusive-OR comparator and a pull-down transistor for the match-line.
Reference: [Uyem92] <author> John P. Uyemura: </author> <title> Circuit design for CMOS VLSI, </title> <publisher> Kluwer Academic Publishers, </publisher> <address> ISBN 0-7923-9184-5, </address> <year> 1992. </year>
Reference-contexts: are usually sensitive to noise and unstable voltage supply, and since the correctness of the search access is crucial for the operation of the credit-based flow control protocol, we believe it is safer to use a plain inverter with properly raised threshold voltage in order to achieve the desired speedup <ref> [Uyem92] </ref>. 9.2 Random-Access Memory Cells The CreditMask and LinkList memories, along with the Head-Tail register file are static random-access blocks. The memory cell for the first two, shown in figure 14, can be the same : a two-ported static RAM cell. <p> Static CMOS NOR gates with large fan-in are slow, because of the pmos transistors connected in series, and occupy a large area, since they need a pmos and a nmos transistor per input. In order to avoid both negative effects we can use precharged NOR gates with domino timing <ref> [Uyem92] </ref>. A precharged NOR gate is presented in figure 23. While the PHI clock signal is low, node OUT is precharged. When PHI is set, the gate is evaluated and, if one or more inputs are high, node OUT is discharged and node OU T is set.
Reference: [Veri94] <author> Verilog-XL Reference Manual, Cadence Design Systems Inc., v. 2.1, </author> <month> Decmber </month> <year> 1994. </year>
Reference-contexts: The organization used for the simulation is presented in figure 10. The QM block functional model, written in Verilog-XL <ref> [Veri94] </ref> as all the rest of the code for this simulation, implements all the operations and functions described in the previous sections, with a clock cycle precision.
Reference: [WeEs93] <author> N. Weste, K. Eshraghian: </author> <title> Principles of CMOS VLSI Design a Systems Perspective, second edition, </title> <publisher> Addison-Wesley, </publisher> <address> ISBN 0-201-53376-6, </address> <year> 1993. </year> <month> 52 </month>
Reference-contexts: The five memories included in the block are multi-ported and have critical timing requirements and, therefore, need to be designed with full-custom mask-level layout techniques <ref> [WeEs93] </ref>. They all are static memories. On the other hand, control logic and the rest of the block logic will be designed with semi-custom layout techniques. Semi-custom gate-level layout can be produced automatically from functional or behavioral descriptions by using synthesis tools, such as Synopsys [Syn94]. <p> up the operation of the PE, we can take advantage of the similarity of the NEH signal calculation to the carry propagation problem, and use techniques similar to carry lookahead and 10.2 Design Alternatives for the Priority Enforcer 40 Architecture, Operation and Design of the Queue Management Block carry prediction <ref> [WeEs93] </ref>. The NEH vector can be calculated by the dual tree structure presented in figure 22. The role of the upper tree is to reduce the number of input signals to a ripple structure, so that its fast evaluation is feasible. <p> The first one would have a single input (inverter), the second one two and so on. In order to avoid that one can merge multiple NOR gates into a Manchester chain circuit <ref> [WeEs93] </ref>, presented in figure 24. A Manchester chain is a dynamic circuit that can be used for evaluation of multiple OR-type results. During the low phase of the clock signal PHI, all nodes I N T i are precharged.
References-found: 21

