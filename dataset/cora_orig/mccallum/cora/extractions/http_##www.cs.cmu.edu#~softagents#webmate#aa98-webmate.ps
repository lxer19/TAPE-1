URL: http://www.cs.cmu.edu/~softagents/webmate/aa98-webmate.ps
Refering-URL: http://www.cs.cmu.edu/~softagents/webmate/
Root-URL: 
Email: lchen@cs.cmu.edu, katia@cs.cmu.edu  
Title: WebMate A Personal Agent for Browsing and Searching  
Author: Liren Chen and Katia Sycara 
Keyword: Area: Software Agents Keywords: Information Agents, Instructability, Knowledge acquisition and accumula tion, long-term adaptation and learning, user modeling  
Note: This research has been supported in part by ARPA contract F33615-93-1-1330, and by ONR Grant N00014-96-1222.  
Date: September 30, 1997  
Address: Pittsburgh, PA. 15213  
Affiliation: The Robotics Institute Carnegie Mellon University  
Abstract: The World-Wide Web is developing very fast. Currently, finding useful information on the Web is a time consuming process. In this paper, we present WebMate, an agent that helps users to effectively browse and search the Web. WebMate extends the state of the art in Web-based information retrieval in many ways. First, it uses multiple TF-IDF vectors to keep track of user interests in different domains. These domains are automatically learned by WebMate. Second, WebMate uses the Trigger Pair Model to automatically extract keywords for refining document search. Third, during search, the user can provide multiple pages as similarity/relevance guidance for the search. The system extracts and combines relevant keywords from these relevant pages and uses them for keyword refinement. Using these techniques, WebMate provides effective browsing and searching help and also compiles and sends to users personal newspaper by automatically spiding news sources. We have experimentally evaluated the performance of the system. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Katia Sycara, Anandeep Pannu, Mike Williamson, Dajun Zeng, Keih Decker. </author> <year> 1996, </year> <title> Distributed Intelligent Agents. </title> <booktitle> Published in IEEE Expert, Intelligent Systems & their applications, </booktitle> <month> Dec, </month> <year> 1996 </year>
Reference-contexts: Intelligent software agents are being developed to deal with these issues. Intelligent agents are programs that act on behalf of their human users to perform laborious information-gathering tasks <ref> [1] </ref> and they are one of the "hot" topics in Information Systems R&D at the moment. The last ten years have seen a marked interest in agent-oriented technology, spanning applications as diverse as information retrieval, user interface design and network management.
Reference: [2] <author> Shaw Green, Leon Hurst, Brenda Nangle, Padraig Cunninggham, Fergal Somers, Richard Evans. </author> <year> 1997, </year> <title> Software Agents: A review. </title> <address> http://www.cs.tcd.id/Brenda.Nangle/iag.html </address>
Reference: [3] <author> Marko Balabanovic, Yoav Shaham. </author> <year> 1995, </year> <title> Learning Information Retrieval Agents: Experiments with Automated Web Browsing. </title> <booktitle> Proceedings of the AAAI Spring Symposium Series on Information Gathering from Heterogeneous, Distributed Environments: </booktitle> <pages> 13-18. </pages>
Reference-contexts: In section 2, we describe the architecture of the system. The WebMate acts as a proxy and monitors a user's actions. In section 3, we describe the user profile representation and learning algorithm <ref> [3, 4] </ref>. In addition, we provide experimental results of compiling a personal newspaper. In section 4, we discuss how to use the Trigger Pairs Model to extract relevant words to use as keyword refinements to improve search. <p> It learns from experiences of multiple users to improve its advice-giving skills. Letizia [17] can recommend nearby pages by doing lookahead search. Syskill & Webert [4] is a software agent that learns to rate pages on the Web, deciding which pages might interest a user. Lira <ref> [3] </ref> works o*ine and returns a set of pages that match the user's interest. Daily Briefing 11 allows you to use Autonomy Intelligent Agents as Newshounds to sniff out stories and compile a personal daily newspaper with stories, features and articles selected from the Internet to match your requirements.
Reference: [4] <author> M. Pazzani, J. Muramatsu, D. Billsus. </author> <year> 1996, </year> <title> Syskill & webert: Identifying interesting web sites. </title> <booktitle> In AAAI conference, </booktitle> <address> Portland, </address> <year> 1996 </year>
Reference-contexts: In section 2, we describe the architecture of the system. The WebMate acts as a proxy and monitors a user's actions. In section 3, we describe the user profile representation and learning algorithm <ref> [3, 4] </ref>. In addition, we provide experimental results of compiling a personal newspaper. In section 4, we discuss how to use the Trigger Pairs Model to extract relevant words to use as keyword refinements to improve search. <p> the applet controller, the user receives intelligent help from WebMate. 3 Learning profile to compile personal newspaper 3.1 Profile Representation and Learning Algorithm There are several machine learning approaches that can be used to learn a user profile, such as Bayesian classifier, Nearest Neighbor, PEBLS, Decision Trees, TF-IDF, Neural Nets <ref> [4, 5] </ref>. In order for a particular technique to be effective, it should match the characteristics of the task and the user. <p> In the morning, the user can read the recommended personal newspaper. If the user does not provide any URLs that he would like to be the information sources, WebMate constructs a query <ref> [4] </ref> using the top several words in the current profile and sends it to popular search engines (e.g. Altavista, Yahoo). If the result is needed immediately, the results returned by the search engines are directly used as the recommended web pages. <p> It learns from experiences of multiple users to improve its advice-giving skills. Letizia [17] can recommend nearby pages by doing lookahead search. Syskill & Webert <ref> [4] </ref> is a software agent that learns to rate pages on the Web, deciding which pages might interest a user. Lira [3] works o*ine and returns a set of pages that match the user's interest.
Reference: [5] <author> Pannu, A. and Sycara, K. </author> <year> 1996, </year> <title> A Personal Text Filtering Agent. </title> <booktitle> Proceedings of the AAAI Stanford Spring Symposium on Machine Learning and Information Access, </booktitle> <address> Stanford, CA, March 25-27, </address> <year> 1996. </year>
Reference-contexts: the applet controller, the user receives intelligent help from WebMate. 3 Learning profile to compile personal newspaper 3.1 Profile Representation and Learning Algorithm There are several machine learning approaches that can be used to learn a user profile, such as Bayesian classifier, Nearest Neighbor, PEBLS, Decision Trees, TF-IDF, Neural Nets <ref> [4, 5] </ref>. In order for a particular technique to be effective, it should match the characteristics of the task and the user.
Reference: [6] <author> K.Lang. </author> <year> 1995, </year> <title> NewsWeeder: Learning to filter Netnews. </title> <booktitle> Proceedings of Machine Learning, </booktitle> <publisher> Morgan Kaufman, </publisher> <address> San Francisco, </address> <year> 1995 </year> <month> 15 </month>
Reference: [7] <author> G.Salton and M.J.McGill. </author> <year> 1983, </year> <title> Introduction to Modern Information Retrieval. </title> <publisher> McGraw-Hill, </publisher> <address> New York, </address> <year> 1983 </year>
Reference-contexts: In order to save on storage space, the system doesn't keep any of the previous positive example documents. It only keeps the profile learned from those positive examples. In this way, the system will adapt to the user's evolving and recent interests. WebMate utilizes TF-IDF method <ref> [7] </ref> with multiple vectors representation. The basic idea of the algorithm is to represent each document as a vector in a vector space so that documents with similar content have similar vectors. Each dimension of the vector space represents a word and its weight.
Reference: [8] <author> Gerard Salton, Chris Buckley. </author> <year> 1988, </year> <title> Improving Retrieval Performance by Relevance Feedback. </title> <publisher> Cornell University, </publisher> <pages> 88-898 </pages>
Reference-contexts: In addition, we provide experimental results of compiling a personal newspaper. In section 4, we discuss how to use the Trigger Pairs Model to extract relevant words to use as keyword refinements to improve search. We also present utilizing relevance feedback <ref> [8] </ref> during search to dynamically enhance the search for relevant documents. <p> The central problems in relevance feedback are selecting "features" (words, phrases) from relevant documents and calculating weights for these features in the context of a new query <ref> [8] </ref>.
Reference: [9] <author> Marbo Balabonovic, Yoav Shoham. </author> <year> 1997, </year> <title> Combining Content-Based and Collaborative Recommendation. </title> <journal> Communications of the ACM, </journal> <month> March, </month> <year> 1997 </year>
Reference-contexts: This algorithm is run whenever a user marks a document as "I like it". Thus, the user profile is incrementally, unobtrusively and continuously updated. 3.2 Compiling personal newspaper We utilize the approach of learning user profile to compile a personal newspaper <ref> [9, 10, 11] </ref>. We do this in two ways. One way is to automatically spide a list of URLs that the user wants monitored. An example of such a URL is one that consists of many news headlines like the home page of the NewsLinx Company 3 .
Reference: [10] <author> Peter W. Foltz, Susan T. Dumais. </author> <year> 1992, </year> <title> Personalized Information Delivery: An Analysis of Information Filtering Methods. </title> <booktitle> Published in Comminucations of the ACM, </booktitle> <volume> 35(12), </volume> <pages> 51-60, </pages> <year> 1992 </year>
Reference-contexts: This algorithm is run whenever a user marks a document as "I like it". Thus, the user profile is incrementally, unobtrusively and continuously updated. 3.2 Compiling personal newspaper We utilize the approach of learning user profile to compile a personal newspaper <ref> [9, 10, 11] </ref>. We do this in two ways. One way is to automatically spide a list of URLs that the user wants monitored. An example of such a URL is one that consists of many news headlines like the home page of the NewsLinx Company 3 .
Reference: [11] <author> Paul Resnick. </author> <year> 1997, </year> <title> Filtering Information on the Internet. </title> <address> http://www.sciam.com/0397issue/0397resnick.html </address>
Reference-contexts: This algorithm is run whenever a user marks a document as "I like it". Thus, the user profile is incrementally, unobtrusively and continuously updated. 3.2 Compiling personal newspaper We utilize the approach of learning user profile to compile a personal newspaper <ref> [9, 10, 11] </ref>. We do this in two ways. One way is to automatically spide a list of URLs that the user wants monitored. An example of such a URL is one that consists of many news headlines like the home page of the NewsLinx Company 3 .
Reference: [12] <author> Chengfeng Han, Hideo Fujii, W. Bruce Croft. </author> <title> 1994 Automatic Query Expansion for Japanese Text Retrieval. </title> <type> UMass Technical Report </type>
Reference-contexts: There are three ways to expand the query: manual query expansion, semi-manual query expansion, and automatic query expansion <ref> [12] </ref>. No matter which method is used, the key point is to get the best refinement words. <p> business, bank, dow, earning, composite, cent, analyst, big, chrysler, investor, cash, 8 In the Trigger Pairs Model, (S; T ) is different from (T; S), so the Trigger Pairs Model is different from the method of using co-occurrence of two words that is generally used in other keywords expansion experiments <ref> [12] </ref> 8 average, economy, close, capital, chip, ...g.
Reference: [13] <author> Ronald Rosenfeld. </author> <year> 1994, </year> <title> Adaptive Statistical Language Modeling: A Maximum Entropy Approach. </title> <institution> Carnegie Mellon University, </institution> <type> Ph.D. Thesis </type>
Reference-contexts: In other words, one of the characteristics of good refinement words is that they be domain specific. In this section we present the method for automatically finding appropriate keywords to constrain and refine search for relevant documents. 7 http://www.cogsci.princeton.edu/~wn/ 7 We use the Trigger Pairs Model <ref> [13, 14] </ref>. If a word S is significantly correlated with another word T, then (S, T) is considered a "trigger pair", with S being the trigger and T the triggered word. When S occurs in the document, it triggers T, causing its probability estimate to change. <p> Currently in WebMate, only words are used to represent a user's profile. We feel that new machine learning algothrims for classifying the new web pages are necessary to improve the accuracy of the recommendation. We are currently implementing phrases, bigram <ref> [13] </ref> of words and plan to explore the trigger pairs or relevant words to improve the learning. In addition, we are implementing heuristics to filter out advertisements and irrelevant content around web pages comtaining news.
Reference: [14] <author> Susan Gauch, Robert P. Futrelle. </author> <title> Experiments in Automatic Word Class and Word Sense Identification for Information Retrieval. </title> <booktitle> Proceedings of the Third Annual Symposium on Document Analysis and Information Retrieval </booktitle>
Reference-contexts: In other words, one of the characteristics of good refinement words is that they be domain specific. In this section we present the method for automatically finding appropriate keywords to constrain and refine search for relevant documents. 7 http://www.cogsci.princeton.edu/~wn/ 7 We use the Trigger Pairs Model <ref> [13, 14] </ref>. If a word S is significantly correlated with another word T, then (S, T) is considered a "trigger pair", with S being the trigger and T the triggered word. When S occurs in the document, it triggers T, causing its probability estimate to change. <p> Relevance feedback is a process where users identify relevant documents in an initial list of retrieved documents, and the system then creates a new query based on those sample relevant documents <ref> [14] </ref>. The idea is that since the newly formed query is based on documents that are similar to the desired relevant documents, the returned documents will indeed be similar.
Reference: [15] <author> Kathleen Webster, Kathryn Paul. </author> <year> 1996, </year> <title> Beyond Surfing: Tools and Techniques for Searching the Web. </title> <month> Jan. </month> <year> 1996, </year> <note> Information Technology </note>
Reference: [16] <author> Thorsten Joachims, Dayne Freitag, Tom Mitchell. </author> <year> 1997, </year> <title> WebWatcher: A Tour Guide for the World Wide Web. </title> <booktitle> Proceedings of IJCAI97, </booktitle> <month> August </month> <year> 1997. </year>
Reference-contexts: Cooperative (http://www.ie.utoronto.ca/EIL/ABS-page/ABS-intro.h) *8) Special Issue AI in Medicine Editorial Special Issue Artificial Intelligence in Medicine "Architectures for Intelligent Systems Based on Reusable Components" (http://www.swi.psy.uva.nl/usr/Schreiber/papers/Mu) *9) CS 791A Agent Architectures for Information Gathering (http://centaurus.cs.umass.edu/ig-seminar.html) *10) Interaction Protocols for Software Agents on the World Wide Web (http://rbse.jsc.nasa.gov/eichmann/www-s96/interact) 5 Related work WebWatcher 10 <ref> [16] </ref> is a tour guide for the web. It learns from experiences of multiple users to improve its advice-giving skills. Letizia [17] can recommend nearby pages by doing lookahead search.
Reference: [17] <author> H.Lieberman. </author> <year> 1995, </year> <title> Letizia: An agent that assists web browsing. </title> <booktitle> In International Joint Conference of Artificial Intelligence, </booktitle> <address> Montreal, </address> <month> Aug. </month> <year> 1995 </year>
Reference-contexts: It learns from experiences of multiple users to improve its advice-giving skills. Letizia <ref> [17] </ref> can recommend nearby pages by doing lookahead search. Syskill & Webert [4] is a software agent that learns to rate pages on the Web, deciding which pages might interest a user. Lira [3] works o*ine and returns a set of pages that match the user's interest.
Reference: [18] <author> Bernardo A. Huberman, Michael Kaminsky. </author> <year> 1996, </year> <title> Beehive: A System for Cooperative Filtering and Sharing of Information </title>
Reference-contexts: Metabot 13 is a Java-based, client-server application for searching the web by performing a simultaneous query on multiple web search services. CoolURL 14 is an exploratory technology that enables users to use agent technology to recommend cool URLs to a community of users. Beehive <ref> [18] </ref> is a distributed system for social sharing and filtering of information. Firefly 15 uses software agents that automate the process of retrieving data from the Web based on what they know about their owner's tastes and interests. Their core technology is the social filtering (or colaborative filtering).
Reference: [19] <author> URL: </author> <title> Collection of Bots in the Web, </title> <note> http://www.botspot.com/ 16 </note>
References-found: 19

