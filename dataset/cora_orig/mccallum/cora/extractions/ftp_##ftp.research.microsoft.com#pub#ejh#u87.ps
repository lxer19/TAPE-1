URL: ftp://ftp.research.microsoft.com/pub/ejh/u87.ps
Refering-URL: http://www.research.microsoft.com/users/horvitz/bo.htm
Root-URL: http://www.research.microsoft.com
Title: Reasoning about Beliefs and Actions under Computational Resource Constraints 1  
Author: Eric J. Horvitz 
Address: Stanford, California 94305-5479  
Affiliation: Medical Computer Science Group Knowledge Systems Laboratory Stanford University  
Abstract: Although many investigators affirm a desire to build reasoning systems that behave consistently with the axiomatic basis defined by probability theory and utility theory, limited resources for engineering and computation can make a complete normative analysis impossible. We attempt to move discussion beyond the debate over the scope of problems that can be handled effectively to cases where it is clear that there are insufficient computational resources to perform an analysis deemed as complete. Under these conditions, we stress the importance of considering the expected costs and benefits of applying alternative approximation procedures and heuristics for computation and knowledge acquisition. We discuss how knowledge about the structure of user utility can be used to control value tradeoffs for tailoring inference to alternative contexts. We address the notion of real-time rationality, focusing on the application of knowledge about the expected timewise-refinement abilities of reasoning strategies to balance the benefits of additional computation with the costs of acting with a partial result. We discuss the benefits of applying decision theory to control the solution of difficult problems given limitations and uncertainty in reasoning resources. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A.V. Aho, J.E. Hopcroft, and J.D. Ullman. </author> <title> Data Structures and Algorithms. </title> <publisher> Addison-Wesley, </publisher> <address> Menlo Park, California, </address> <year> 1983. </year>
Reference-contexts: The classical interest in calculating final answers permeates computer science. Complexity theorists have focused almost exclusively on proving results about the time and space resources that must be expended to run algorithms to termination <ref> [8, 1, 25] </ref>. In the real world, strict limitations and variations on the time available for problem solving suggest that the focus on time complexity for algorithmic termination is limited; analyses centering on how good a solution can be found in the time available for computation are of importance.
Reference: [2] <author> B.G. Buchanan and E.H. Shortliffe, </author> <title> editors. Rule-Based Expert Systems: The MYCIN Experiments of the Stanford Heuristic Programming Project. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1984. </year>
Reference-contexts: In most schemes, the degree of truth or belief in the presence of a hypothesis can range continuously between complete truth and complete falsity. Such belief-entailment schemes include probability theory [18, 27], fuzzy logic [38], Dempster-Shafer theory [30], and MYCIN certainty factors <ref> [2] </ref>. Finally, decision making is the process of selecting the best action to take. A decision or action is an irrevocable allocation of valuable resources. The classical decision-theoretic basis defines rational beliefs and actions with the axioms of prob ability theory and utility theory.
Reference: [3] <author> P. Cheeseman. </author> <title> In defense of probability. </title> <booktitle> In Proceedings of the Ninth International Joint Conference on Artificial Intelligence, </booktitle> <address> Los Angeles, CA, </address> <booktitle> page ?? Internation Joint Conference on Artificial Intelligence, </booktitle> ?? <year> 1985. </year>
Reference-contexts: Numerous investigators interested in the automation of uncertain reasoning have converged on the theoretical adequacy of the decision-theoretic basis for rational action <ref> [11, 3, 17] </ref>. Recent discussions about computational approaches to reasoning with uncertainty have centered on the degree to which probability and utility theory can handle inference problems of realistic complexity.
Reference: [4] <author> H.L. Chin and G.F. Cooper. </author> <title> Bayesian belief network inference using simulation. In L.N. </title> <editor> Kanal, J.F. Lemmer, and T.S. Levitt, editors, </editor> <booktitle> Uncertainty in Artificial Intelligence 3, </booktitle> <pages> pages 129-148. </pages> <publisher> North Holland, </publisher> <address> New York, </address> <year> 1989. </year>
Reference-contexts: The variance with which the distribution converges on a probability with additional computation depends on the topology of the network, and on the nature of the probabilistic dependencies within the network. Recent work has shown current simulation algorithms to have intolerably slow convergence rates in many realistic cases <ref> [4] </ref> . Stochastic simulation is nevertheless a promising class of inference for the derivation of useful bounded-resource computation strategies. * Completeness Modulation Completeness-modulation strategies center on techniques for reasoning about attributes of the uncertain-reasoning model to include in an analysis.
Reference: [5] <author> G.F. Cooper. NESTOR: </author> <title> A Computer-based Medical Diagnostic Aid that Integrates Causal and Probabilistic Knowledge. </title> <type> PhD thesis, </type> <institution> Computer Science Department, Stanford University, Stanford, </institution> <address> CA, </address> <month> November </month> <year> 1984. </year> <type> Rep. </type> <note> No. STAN-CS-84-48. Also numbered HPP-84-48. </note>
Reference-contexts: Recent research has focused on the computational complexity of probabilistic reasoning. The research has been based on analyses of uncertain-reasoning problems represented with graphs. The most popular representation uses directed graphs to represent explicitly conditional dependencies and independencies among beliefs in propositions <ref> [28, 5, 27] </ref>. Many researchers have ascribed a common semantics to the directed graphs. The representation is often called a belief network. <p> that are oriented to human preferences. 7.1 Promising Probabilistic Inference Approaches Several classes of approximation methods and heuristics are promising sources of useful strategies for bounded-resource computation. * Bound Calculation and Propagation There has been ongoing interest in the calculation of upper and lower bounds on point probabilities of interest <ref> [5] </ref>. Probabilistic bounding techniques determine bounds on probabilities through a logical analysis of constraints acquired from a partial analysis. Bounds become tighter as additional constraints are brought into consideration. <p> Bounds become tighter as additional constraints are brought into consideration. Cooper has applied a best-first search algorithm to focus attention on the most relevant aspects of the problem in calculating bounds on the hypotheses <ref> [5] </ref>. * Stochastic Simulation Simulation techniques are approximation strategies that report a probability distribution or partial characterization of a distribution over probabilities of interest through a process of weighted random sampling [13, 26]. In many cases, the distribution over the probabilities is approximated by the binomial distribution.
Reference: [6] <author> G.F. Cooper. </author> <title> Probabilistic inference using belief networks is NP-hard. </title> <journal> Artificial Intelligence, </journal> <volume> 42 </volume> <pages> 393-405, </pages> <year> 1990. </year>
Reference-contexts: Although the directed-graph representations allow the expression of inference problems that can be solved efficiently, many topologies have resisted tractable algorithmic solution. A troubling topology is the multiply connected network [27]. Such inference problems belong to a class of difficult problems that have been shown to be N P-hard <ref> [6] </ref>. Problems in complex areas such as medicine often require representation with multiply connected networks. Thus, in the worst case, rational beliefs and actions demand computation that is exponential in the size of the problem.
Reference: [7] <author> R. Cox. </author> <title> Probability, frequency and reasonable expectation. </title> <journal> American Journal of Physics, </journal> <volume> 14 </volume> <pages> 1-13, </pages> <year> 1946. </year>
Reference-contexts: Probability theory dictates that the assignment and entailment of belief in the truth of propositions should be consistent with a parsimonious set of axioms. The logical equivalence of these axioms with a small set of intuitive properties desired in a measure of belief has been demonstrated <ref> [7, 18] </ref>. Utility theory [36] dictates the consistent assignment and updating of the value of alternative actions given the values of alternative outcomes and the degrees of belief in the outcomes. Measures of value consistent with the axioms of utility theory are called utilities.
Reference: [8] <author> M.R. Garey and D.S. Johnson. </author> <title> Computers and Intractability: A Guide to the Theory of NP-Completeness. W.H. </title> <publisher> Freeman and Company, </publisher> <address> New York, </address> <year> 1979. </year>
Reference-contexts: The classical interest in calculating final answers permeates computer science. Complexity theorists have focused almost exclusively on proving results about the time and space resources that must be expended to run algorithms to termination <ref> [8, 1, 25] </ref>. In the real world, strict limitations and variations on the time available for problem solving suggest that the focus on time complexity for algorithmic termination is limited; analyses centering on how good a solution can be found in the time available for computation are of importance.
Reference: [9] <author> I.J. </author> <title> Good. Rational decisions. </title> <journal> J. R. Statist. Soc. B, </journal> <volume> 14 </volume> <pages> 107-114, </pages> <year> 1952. </year>
Reference-contexts: Previous research in decision science has touched on the formal integration of the costs of reasoning into decision-making inference. The earliest discussion of the explicit integration of the costs of inference within the framework of normative rationality was introduced by Good <ref> [9] </ref>, who made the distinction between what he referred to as type I and type II rationality. Good defined type I rationality as inference that is consistent with the axioms of decision theory without regard to the cost of inference.
Reference: [10] <author> G.A. Gorry. </author> <title> Computer-assisted clinical decision making. </title> <booktitle> Methods of Information in Medicine, </booktitle> <volume> 12 </volume> <pages> 45-51, </pages> <year> 1973. </year>
Reference-contexts: Such an assumption greatly reduces the resources required for knowledge assessment and computation. Assumptions of global independence have been made in many reasoning systems that have been deemed to perform adequately (e.g., the MYCIN certainty-factor model [11, 17] and the early probabilistic diagnostic programs <ref> [10, 33] </ref>). The actual costs and benefits of defaulting to conditional independence among evidence in many real-world problems have not been determined.
Reference: [11] <author> D.E. Heckerman. </author> <title> Probabilistic interpretations for MYCIN's certainty factors. In L.N. </title> <editor> Kanal and J.F. Lemmer, editors, </editor> <booktitle> Uncertainty in Artificial Intelligence, </booktitle> <pages> pages 167-196. </pages> <publisher> North Holland, </publisher> <address> New York, </address> <year> 1986. </year>
Reference-contexts: Numerous investigators interested in the automation of uncertain reasoning have converged on the theoretical adequacy of the decision-theoretic basis for rational action <ref> [11, 3, 17] </ref>. Recent discussions about computational approaches to reasoning with uncertainty have centered on the degree to which probability and utility theory can handle inference problems of realistic complexity. <p> Specific dependencies are included in an overwhelming independent model when they become salient. Such an assumption greatly reduces the resources required for knowledge assessment and computation. Assumptions of global independence have been made in many reasoning systems that have been deemed to perform adequately (e.g., the MYCIN certainty-factor model <ref> [11, 17] </ref> and the early probabilistic diagnostic programs [10, 33]). The actual costs and benefits of defaulting to conditional independence among evidence in many real-world problems have not been determined.
Reference: [12] <author> D.E. Heckerman and E.J. Horvitz. </author> <title> On the expressiveness of rule-based systems for reasoning under uncertainty. </title> <booktitle> In Proceedings AAAI-87 Sixth National Conference on Artificial Intelligence, </booktitle> <address> Seattle, WA, </address> <pages> pages 121-126. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <month> July </month> <year> 1987. </year>
Reference-contexts: If there is no arc from A to B, the probability distribution for B is not directly dependent on the values of A. Less expressive representations commonly employed in artificial-intelligence research have not allowed specific independencies to be represented efficiently <ref> [12] </ref>. 1 Belief networks are special cases of more general graphical representations that can represent available actions and the utility of alternative outcomes in addition to beliefs [21, 29]. These graphs have been called influence diagrams and decision networks.
Reference: [13] <author> M. Henrion. </author> <title> Propagation of uncertainty by probabilistic logic sampling in Bayes' networks. </title> <editor> In J.F. Lemmer and L.N. Kanal, editors, </editor> <booktitle> Uncertainty in Artificial Intelligence 2, </booktitle> <pages> pages 149-164. </pages> <publisher> North Holland, </publisher> <address> New York, </address> <year> 1988. </year>
Reference-contexts: This work was supported by Grant NCC 2-220-51 from the NASA-Ames Research Center and Grant RO1LM04529 from the National Library of Medicine. Computer facilities were provided by the SUMEX-AIM Resource under Grant RR-00785 from the National Institutes of Health. relatively complex real-world problems <ref> [29, 13] </ref>. In this paper, we move beyond discussions of the degree to which the theories of probability and utility are able to solve real-world problems. We focus on situations where it is clear that insufficient resources prohibit the use of the normative basis for a complete analysis. <p> search algorithm to focus attention on the most relevant aspects of the problem in calculating bounds on the hypotheses [5]. * Stochastic Simulation Simulation techniques are approximation strategies that report a probability distribution or partial characterization of a distribution over probabilities of interest through a process of weighted random sampling <ref> [13, 26] </ref>. In many cases, the distribution over the probabilities is approximated by the binomial distribution. The variance with which the distribution converges on a probability with additional computation depends on the topology of the network, and on the nature of the probabilistic dependencies within the network.
Reference: [14] <author> E.J. Horvitz. </author> <title> Reasoning about inference tradeoffs in a world of bounded resources. </title> <type> Tech--nical Report KSL-86-55, </type> <institution> Medical Computer Science Group, Section on Medical Informatics, Stanford University, Stanford, </institution> <address> CA, </address> <month> March </month> <year> 1986. </year>
Reference-contexts: We are concerned with rational strategies for handling such resource insufficiencies. We have been exploring resource constraints and the feasibility of normative approaches to knowledge assessment, computation, and explanation under scarce resources <ref> [15, 14] </ref>. That is, we have sought to apply the principles of normative rationality to reason about the solution of a base-level decision problem. We focus our attention on real-time decision making. Resource-constraint issues can be especially salient in the context of real-time requirements. <p> For example, we could consider the value of different types of partially sorted files instead of dwelling on our inability to always complete a sort under uncertain and varying time limitations <ref> [14] </ref>. An approach to developing techniques for optimizing the value of uncertain reasoning under ranging resource limitations is the development of problem reformulation and inference schemes that allow the generation and efficient manipulation of partial results. <p> We focus on the use of knowledge about multiple components of value at the metalevel to tailor inference to the appropriate context. The example reflects ongoing work on inference under bounded resources <ref> [14] </ref>. Although the results can be derived formally, we shall describe the sample problem with a set of qualitative curves for clarity. The curves capture important functional relationships among components of computational value in alternative contexts.
Reference: [15] <author> E.J. Horvitz. </author> <title> Toward a science of expert systems. </title> <booktitle> Proceedings of the 18th Symposium on the Interface of Computer Science and Statistics, </booktitle> <pages> pages 45-52, </pages> <month> March </month> <year> 1986. </year>
Reference-contexts: We are concerned with rational strategies for handling such resource insufficiencies. We have been exploring resource constraints and the feasibility of normative approaches to knowledge assessment, computation, and explanation under scarce resources <ref> [15, 14] </ref>. That is, we have sought to apply the principles of normative rationality to reason about the solution of a base-level decision problem. We focus our attention on real-time decision making. Resource-constraint issues can be especially salient in the context of real-time requirements.
Reference: [16] <author> E.J. Horvitz. </author> <title> A multiattribute utility approach to inference understandability and explanation. </title> <type> Technical Report KSL-28-87, </type> <institution> Medical Computer Science Group, Section on Medical Informatics, Stanford University, Stanford, </institution> <address> CA, </address> <month> March </month> <year> 1987. </year>
Reference-contexts: The node Clarity indicates that the transparency and explainability of inference may be another important dimension of inference-related cost in the context of an expert system <ref> [19, 16] </ref>. 5.2 Multiple Attributes of Inference and Outcome As indicated in Figure 2, the costs of reasoning may have several components. Multiple dimensions of utility can be ascertained through consideration of attributes of outcomes and problem solving that are important to a computational agent or system user.
Reference: [17] <author> E.J. Horvitz and D.E. Heckerman. </author> <title> The inconsistent use of measures of certainty in artificial intelligence research. In L.N. </title> <editor> Kanal and J.F. Lemmer, editors, </editor> <booktitle> Uncertainty in Artificial Intelligence, </booktitle> <pages> pages 137-151. </pages> <publisher> North Holland, </publisher> <address> New York, </address> <year> 1986. </year>
Reference-contexts: Numerous investigators interested in the automation of uncertain reasoning have converged on the theoretical adequacy of the decision-theoretic basis for rational action <ref> [11, 3, 17] </ref>. Recent discussions about computational approaches to reasoning with uncertainty have centered on the degree to which probability and utility theory can handle inference problems of realistic complexity. <p> Specific dependencies are included in an overwhelming independent model when they become salient. Such an assumption greatly reduces the resources required for knowledge assessment and computation. Assumptions of global independence have been made in many reasoning systems that have been deemed to perform adequately (e.g., the MYCIN certainty-factor model <ref> [11, 17] </ref> and the early probabilistic diagnostic programs [10, 33]). The actual costs and benefits of defaulting to conditional independence among evidence in many real-world problems have not been determined.
Reference: [18] <author> E.J. Horvitz, D.E. Heckerman, </author> <title> and C.P. Langlotz. A framework for comparing alternative formalisms for plausible reasoning. </title> <booktitle> In Proceedings AAAI-86 Fifth National Conference on Artificial Intelligence, </booktitle> <address> Philadelphia, PA, </address> <pages> pages 210-214. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <month> August </month> <year> 1986. </year>
Reference-contexts: Investigators have answered criticism about the inadequate expressiveness of probability theory by pointing out that the normative basis addresses consistent inference with measures of belief and preference, not issues surrounding the formulation of problems <ref> [18] </ref>. Other researchers have shown that probability theory and utility theory are logically equivalent to the satisfaction of a small set of intuitive properties [35, 18]. <p> Other researchers have shown that probability theory and utility theory are logically equivalent to the satisfaction of a small set of intuitive properties <ref> [35, 18] </ref>. Still others have responded to complaints of intractability by demonstrating techniques that can solve 1 This article appeared originally in the Proceedings of the Third Workshop on Uncertainty in Artificial Intelligence, Seattle WA, July 1987. AAAI and Association for Uncertainty in Artificial Intelligence, Mountain View, CA, pp. 429-444. <p> In most schemes, the degree of truth or belief in the presence of a hypothesis can range continuously between complete truth and complete falsity. Such belief-entailment schemes include probability theory <ref> [18, 27] </ref>, fuzzy logic [38], Dempster-Shafer theory [30], and MYCIN certainty factors [2]. Finally, decision making is the process of selecting the best action to take. A decision or action is an irrevocable allocation of valuable resources. <p> Probability theory dictates that the assignment and entailment of belief in the truth of propositions should be consistent with a parsimonious set of axioms. The logical equivalence of these axioms with a small set of intuitive properties desired in a measure of belief has been demonstrated <ref> [7, 18] </ref>. Utility theory [36] dictates the consistent assignment and updating of the value of alternative actions given the values of alternative outcomes and the degrees of belief in the outcomes. Measures of value consistent with the axioms of utility theory are called utilities.
Reference: [19] <author> E.J. Horvitz, D.E. Heckerman, B.N. Nathwani, and L.M. Fagan. </author> <title> The use of a heuristic problem-solving hierarchy to facilitate the explanation of hypothesis-directed reasoning. </title> <booktitle> In Proceedings of Medinfo, </booktitle> <address> Washington, DC, </address> <pages> pages 27-31. </pages> <publisher> North Holland, </publisher> <address> New York, </address> <month> October </month> <year> 1986. </year>
Reference-contexts: The node Clarity indicates that the transparency and explainability of inference may be another important dimension of inference-related cost in the context of an expert system <ref> [19, 16] </ref>. 5.2 Multiple Attributes of Inference and Outcome As indicated in Figure 2, the costs of reasoning may have several components. Multiple dimensions of utility can be ascertained through consideration of attributes of outcomes and problem solving that are important to a computational agent or system user.
Reference: [20] <author> R.A. Howard. </author> <title> Value of information lotteries. </title> <journal> IEEE Transactions of Systems Science and Cybernetics, </journal> <volume> SSC-3(1):54-60, </volume> <year> 1967. </year>
Reference-contexts: Other related work in decision science centered on the value of analysis. These studies have explored the likely benefit of doing a decision analysis or continuing to refine a decision. Matheson [24] explored the value of spending additional effort to analyze a bidding problem proposed by Howard <ref> [20] </ref>.
Reference: [21] <editor> R.A. Howard and J.E. Matheson, editors. </editor> <booktitle> Readings on the Principles and Applications of Decision Analysis. Strategic Decisions Group, </booktitle> <address> Menlo Park, Ca., </address> <year> 1984. </year>
Reference-contexts: Less expressive representations commonly employed in artificial-intelligence research have not allowed specific independencies to be represented efficiently [12]. 1 Belief networks are special cases of more general graphical representations that can represent available actions and the utility of alternative outcomes in addition to beliefs <ref> [21, 29] </ref>. These graphs have been called influence diagrams and decision networks. An example of a portion of a simple decision problem for medical diagnosis is shown in Figure 1. The node labeled E obs represents the current state of the observed evidence.
Reference: [22] <author> D.V. Lindley. </author> <title> Reconciliation of decision analyses. </title> <journal> Operations Research, </journal> <volume> 34 </volume> <pages> 289-295, </pages> <year> 1986. </year>
Reference-contexts: These studies have explored the likely benefit of doing a decision analysis or continuing to refine a decision. Matheson [24] explored the value of spending additional effort to analyze a bidding problem proposed by Howard [20]. Watson and Brown [37] and Lindley <ref> [22] </ref> describe issues surrounding the application of a preliminary decision analysis to assist in the decision as to whether an individual should embark on a more costly decision analysis of the base problem at hand. 6 Toward a Timewise-Refinement Paradigm Classical approaches to normative inference have pursued the determination of point
Reference: [23] <author> J.G. </author> <month> March. </month> <title> Bounded rationality, ambiguity, and the engineering of choice. </title> <journal> Bell Journal of Economics, </journal> <pages> pages 587-608, </pages> <year> 1978. </year>
Reference-contexts: The intent of our research is to develop coherent approaches to generating and selecting the most promising strategy for particular problem-solving challenges. Notions of bounded rationality that have been exercised in earlier discussion of intelligent systems faced with complex problems shun a formal perspective as too costly <ref> [31, 23] </ref>. Most research on reasoning and acting under resource constraints has focused on the discovery of relatively simple satisficing approaches to problem solving. These approaches may stray far from the levels of utility that might be achieved through the pursuit of more sophisticated normative analyses.
Reference: [24] <author> J.E. Matheson. </author> <title> The value of analysis and computation. </title> <journal> IEEE Transactions on Systems Science, and Cybernetics, </journal> <volume> 4 </volume> <pages> 211-219, </pages> <year> 1968. </year>
Reference-contexts: Other related work in decision science centered on the value of analysis. These studies have explored the likely benefit of doing a decision analysis or continuing to refine a decision. Matheson <ref> [24] </ref> explored the value of spending additional effort to analyze a bidding problem proposed by Howard [20].
Reference: [25] <author> C.H. Papadimitriou and K. Steiglitz. </author> <title> Combinatorial Optimization: Algorithms and Complexity. </title> <publisher> Prentice-Hall, Inc., </publisher> <address> Englewood Cliffs, New Jersey, </address> <year> 1982. </year>
Reference-contexts: The classical interest in calculating final answers permeates computer science. Complexity theorists have focused almost exclusively on proving results about the time and space resources that must be expended to run algorithms to termination <ref> [8, 1, 25] </ref>. In the real world, strict limitations and variations on the time available for problem solving suggest that the focus on time complexity for algorithmic termination is limited; analyses centering on how good a solution can be found in the time available for computation are of importance.
Reference: [26] <author> J. Pearl. </author> <title> Evidential reasoning using stochastic simulation of causal models. </title> <type> Technical Report R-68, </type> <institution> CSD-8600, Cognitive Systems Laboratory, UCLA Computer Science Department, </institution> <month> September </month> <year> 1986. </year>
Reference-contexts: search algorithm to focus attention on the most relevant aspects of the problem in calculating bounds on the hypotheses [5]. * Stochastic Simulation Simulation techniques are approximation strategies that report a probability distribution or partial characterization of a distribution over probabilities of interest through a process of weighted random sampling <ref> [13, 26] </ref>. In many cases, the distribution over the probabilities is approximated by the binomial distribution. The variance with which the distribution converges on a probability with additional computation depends on the topology of the network, and on the nature of the probabilistic dependencies within the network.
Reference: [27] <author> J. Pearl. </author> <title> Fusion, propagation, and structuring in belief networks. </title> <journal> Artificial Intelligence, </journal> <volume> 29 </volume> <pages> 241-288, </pages> <year> 1986. </year>
Reference-contexts: In most schemes, the degree of truth or belief in the presence of a hypothesis can range continuously between complete truth and complete falsity. Such belief-entailment schemes include probability theory <ref> [18, 27] </ref>, fuzzy logic [38], Dempster-Shafer theory [30], and MYCIN certainty factors [2]. Finally, decision making is the process of selecting the best action to take. A decision or action is an irrevocable allocation of valuable resources. <p> Recent research has focused on the computational complexity of probabilistic reasoning. The research has been based on analyses of uncertain-reasoning problems represented with graphs. The most popular representation uses directed graphs to represent explicitly conditional dependencies and independencies among beliefs in propositions <ref> [28, 5, 27] </ref>. Many researchers have ascribed a common semantics to the directed graphs. The representation is often called a belief network. <p> Although the directed-graph representations allow the expression of inference problems that can be solved efficiently, many topologies have resisted tractable algorithmic solution. A troubling topology is the multiply connected network <ref> [27] </ref>. Such inference problems belong to a class of difficult problems that have been shown to be N P-hard [6]. Problems in complex areas such as medicine often require representation with multiply connected networks. <p> Such strategies might be best applied at knowledge-encoding time. An example of a potentially useful local reformulation is the use of tractable prototypical dependency structures, such as the noisy-OR structure <ref> [27] </ref>.
Reference: [28] <author> W.F. Rousseau. </author> <title> A method for computing probabilities in complex situations. </title> <type> Technical Report 6252-2, </type> <institution> Center for Systems Research, Stanford University, Stanford, </institution> <address> CA, </address> <month> May </month> <year> 1968. </year>
Reference-contexts: Recent research has focused on the computational complexity of probabilistic reasoning. The research has been based on analyses of uncertain-reasoning problems represented with graphs. The most popular representation uses directed graphs to represent explicitly conditional dependencies and independencies among beliefs in propositions <ref> [28, 5, 27] </ref>. Many researchers have ascribed a common semantics to the directed graphs. The representation is often called a belief network.
Reference: [29] <author> R.D. Shachter. </author> <title> Evaluating influence diagrams. </title> <journal> Operations Research, </journal> <volume> 34 </volume> <pages> 871-882, </pages> <year> 1986. </year>
Reference-contexts: This work was supported by Grant NCC 2-220-51 from the NASA-Ames Research Center and Grant RO1LM04529 from the National Library of Medicine. Computer facilities were provided by the SUMEX-AIM Resource under Grant RR-00785 from the National Institutes of Health. relatively complex real-world problems <ref> [29, 13] </ref>. In this paper, we move beyond discussions of the degree to which the theories of probability and utility are able to solve real-world problems. We focus on situations where it is clear that insufficient resources prohibit the use of the normative basis for a complete analysis. <p> Less expressive representations commonly employed in artificial-intelligence research have not allowed specific independencies to be represented efficiently [12]. 1 Belief networks are special cases of more general graphical representations that can represent available actions and the utility of alternative outcomes in addition to beliefs <ref> [21, 29] </ref>. These graphs have been called influence diagrams and decision networks. An example of a portion of a simple decision problem for medical diagnosis is shown in Figure 1. The node labeled E obs represents the current state of the observed evidence.
Reference: [30] <author> G. Shafer. </author> <title> A Mathematical Theory of Evidence. </title> <publisher> Princeton University Press, </publisher> <address> Princeton, NJ, </address> <year> 1976. </year>
Reference-contexts: In most schemes, the degree of truth or belief in the presence of a hypothesis can range continuously between complete truth and complete falsity. Such belief-entailment schemes include probability theory [18, 27], fuzzy logic [38], Dempster-Shafer theory <ref> [30] </ref>, and MYCIN certainty factors [2]. Finally, decision making is the process of selecting the best action to take. A decision or action is an irrevocable allocation of valuable resources. The classical decision-theoretic basis defines rational beliefs and actions with the axioms of prob ability theory and utility theory.
Reference: [31] <author> H.A. Simon. </author> <title> A behavioral model of rational choice. </title> <journal> Quarterly Journal of Economics, </journal> <volume> 69 </volume> <pages> 99-118, </pages> <year> 1955. </year>
Reference-contexts: The intent of our research is to develop coherent approaches to generating and selecting the most promising strategy for particular problem-solving challenges. Notions of bounded rationality that have been exercised in earlier discussion of intelligent systems faced with complex problems shun a formal perspective as too costly <ref> [31, 23] </ref>. Most research on reasoning and acting under resource constraints has focused on the discovery of relatively simple satisficing approaches to problem solving. These approaches may stray far from the levels of utility that might be achieved through the pursuit of more sophisticated normative analyses.
Reference: [32] <author> D.E. Smith. </author> <title> Controlling inference. </title> <type> Technical Report STAN-CS-86-1107, </type> <institution> Computer Science Department, Stanford University, </institution> <month> April </month> <year> 1986. </year>
Reference-contexts: Related machine-intelligence research on the control of reasoning by Smith, and by Treitel and Genesereth, has explored the usefulness of applying utility theory in the selection of alternative logical reasoning strategies <ref> [32, 34] </ref>. Our work differs from the logic theorem-proving work in its pursuit of theoretical tools for the control of computation under scarce resources, of decision-theoretic inference under resource constraints, and of the structure of partial results and multiple dimensions of utility.
Reference: [33] <author> P. Szolovits and S.G. Pauker. </author> <title> Categorical and probabilistic reasoning in medical diagnosis. </title> <journal> Artificial Intelligence, </journal> <volume> 11 </volume> <pages> 115-144, </pages> <year> 1978. </year>
Reference-contexts: Such an assumption greatly reduces the resources required for knowledge assessment and computation. Assumptions of global independence have been made in many reasoning systems that have been deemed to perform adequately (e.g., the MYCIN certainty-factor model [11, 17] and the early probabilistic diagnostic programs <ref> [10, 33] </ref>). The actual costs and benefits of defaulting to conditional independence among evidence in many real-world problems have not been determined.
Reference: [34] <author> R. </author> <title> Treitel and M.R. Genesereth. Choosing directions for rules. </title> <booktitle> In Proceedings AAAI-86 Fifth National Conference on Artificial Intelligence, </booktitle> <address> Philadelphia, PA, </address> <pages> pages 153-157. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <month> August </month> <year> 1986. </year>
Reference-contexts: Related machine-intelligence research on the control of reasoning by Smith, and by Treitel and Genesereth, has explored the usefulness of applying utility theory in the selection of alternative logical reasoning strategies <ref> [32, 34] </ref>. Our work differs from the logic theorem-proving work in its pursuit of theoretical tools for the control of computation under scarce resources, of decision-theoretic inference under resource constraints, and of the structure of partial results and multiple dimensions of utility.
Reference: [35] <author> M. </author> <title> Tribus. Rational Descriptions, Decisions, and Designs. </title> <publisher> Pergamon Press, </publisher> <address> New York, </address> <year> 1969. </year>
Reference-contexts: Other researchers have shown that probability theory and utility theory are logically equivalent to the satisfaction of a small set of intuitive properties <ref> [35, 18] </ref>. Still others have responded to complaints of intractability by demonstrating techniques that can solve 1 This article appeared originally in the Proceedings of the Third Workshop on Uncertainty in Artificial Intelligence, Seattle WA, July 1987. AAAI and Association for Uncertainty in Artificial Intelligence, Mountain View, CA, pp. 429-444.
Reference: [36] <author> J. von Neumann and O. Morgenstern. </author> <title> Theory of Games and Economic Behavior. </title> <publisher> Princeton University Press, </publisher> <address> Princeton, NJ, </address> <year> 1947. </year>
Reference-contexts: The logical equivalence of these axioms with a small set of intuitive properties desired in a measure of belief has been demonstrated [7, 18]. Utility theory <ref> [36] </ref> dictates the consistent assignment and updating of the value of alternative actions given the values of alternative outcomes and the degrees of belief in the outcomes. Measures of value consistent with the axioms of utility theory are called utilities. <p> Von Neumann and Morgenstern, the authors of utility theory, proved that agents making decisions consistent with the axioms of utility would behave as though they associate utility values with alternative outcomes and would act to maximize their expected utility <ref> [36] </ref>. The application of probability theory for belief assignment and utility theory for decision making defines a normative basis for reasoning under uncertainty.
Reference: [37] <author> S.R. Watson and R.V. Brown. </author> <title> The valuation of decision analysis. J.R. </title> <journal> Statist. Soc. A., </journal> <volume> 141(1) </volume> <pages> 69-78, </pages> <year> 1978. </year>
Reference-contexts: These studies have explored the likely benefit of doing a decision analysis or continuing to refine a decision. Matheson [24] explored the value of spending additional effort to analyze a bidding problem proposed by Howard [20]. Watson and Brown <ref> [37] </ref> and Lindley [22] describe issues surrounding the application of a preliminary decision analysis to assist in the decision as to whether an individual should embark on a more costly decision analysis of the base problem at hand. 6 Toward a Timewise-Refinement Paradigm Classical approaches to normative inference have pursued the
Reference: [38] <author> L.A. Zadeh. </author> <title> The role of fuzzy logic in the management of uncertainty in expert systems. </title> <journal> Fuzzy Sets and Systems, </journal> <volume> 11 </volume> <pages> 199-227, </pages> <year> 1983. </year>
Reference-contexts: In most schemes, the degree of truth or belief in the presence of a hypothesis can range continuously between complete truth and complete falsity. Such belief-entailment schemes include probability theory [18, 27], fuzzy logic <ref> [38] </ref>, Dempster-Shafer theory [30], and MYCIN certainty factors [2]. Finally, decision making is the process of selecting the best action to take. A decision or action is an irrevocable allocation of valuable resources.
References-found: 38

