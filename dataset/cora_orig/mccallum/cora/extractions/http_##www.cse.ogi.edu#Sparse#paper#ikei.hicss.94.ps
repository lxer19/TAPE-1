URL: http://www.cse.ogi.edu/Sparse/paper/ikei.hicss.94.ps
Refering-URL: http://www.cse.ogi.edu/Sparse/sparse.papers.html
Root-URL: http://www.cse.ogi.edu
Title: Automatic Array Alignment for Distributed Memory Multicomputers  
Author: M. Wolfe M. Ikei 
Address: Portland, OR 97124 Ibaraki, 308 JAPAN  
Affiliation: Oregon Graduate Institute Hitachi Chemical Company, Ltd.  
Abstract: Languages such as Fortran-D and High Performance Fortran use explicit virtual processor arrays (Templates or Decompositions) to which the programmer explicitly aligns the arrays of the program. We explore a technique to automate this process. In particular, we are interested in imperative languages, similar to Fortran, and scientific computations using indexed data structures (arrays). We have implemented automatic alignment in our imperative language using techniques similar to those used for the functional language Crystal. Here we show what changes we made to the procedure to take into account the imperative nature of our source language. In particular, a functional language has a single-assignment attribute; each array element is defined only once. An imperative language allows array elements to be redefined; this allows the imperative program to use arrays with fewer dimensions, as we show. Our compiler technique "resurrects" the lost dimensions of the data arrays to successfully apply automatic data alignment. 
Abstract-found: 1
Intro-found: 1
Reference: [FHK + 90] <author> Geoffrey Fox, Seema Hiranandani, Ken Kennedy, Charles Koelbel, Uli Kremer, Chau-Wen Tseng, and Min-You Wu. </author> <title> Fortran D language specification. </title> <type> Technical Report TR90-141, </type> <institution> Rice Univ., </institution> <month> December </month> <year> 1990. </year> <note> Revised April,1991. </note>
Reference-contexts: We can consider this as a two-phase process: selecting how to decompose the data, and distributing the work to match the data decomposition. Languages like Fortran D and High Performance Fortran have constructs with which programmers manually decompose the data <ref> [FHK + 90, HPF92] </ref>. In this case, the main role of the compiler is to derive the SPMD node program with explicit communication from the global program and the given data decomposition [HKT92]. Our main focus of this paper is to automate the data decomposition step.
Reference: [HKT92] <author> Seema Hiranandani, Ken Kennedy, and Chau-Wen Tseng. </author> <title> Compiling Fortran D for MIMD distributed memory machines. </title> <journal> Communication of the ACM, </journal> <volume> 35(8) </volume> <pages> 66-88, </pages> <month> August </month> <year> 1992. </year>
Reference-contexts: Languages like Fortran D and High Performance Fortran have constructs with which programmers manually decompose the data [FHK + 90, HPF92]. In this case, the main role of the compiler is to derive the SPMD node program with explicit communication from the global program and the given data decomposition <ref> [HKT92] </ref>. Our main focus of this paper is to automate the data decomposition step. Recent work on the functional language Crystal has produced a compiler which automatically converts Crystal programs into executable data-parallel SPMD programs for Distributed Memory Multicom-puters [Li91].
Reference: [HPF92] <author> HPFF. </author> <title> High Performance Fortran Specification, </title> <type> draft ver. </type> <address> 0.4 edition, </address> <month> November </month> <year> 1992. </year>
Reference-contexts: We can consider this as a two-phase process: selecting how to decompose the data, and distributing the work to match the data decomposition. Languages like Fortran D and High Performance Fortran have constructs with which programmers manually decompose the data <ref> [FHK + 90, HPF92] </ref>. In this case, the main role of the compiler is to derive the SPMD node program with explicit communication from the global program and the given data decomposition [HKT92]. Our main focus of this paper is to automate the data decomposition step.
Reference: [Ike92] <author> Mitsuru Ikei. </author> <title> Automatic program restruc-turing for distributed memory multicom-puters. M.S. </title> <type> thesis, </type> <institution> Oregon Graduate Institute, Dept. of Computer Science and Engineering, </institution> <month> April </month> <year> 1992. </year>
Reference-contexts: Our research examines how to apply these compiler steps to an imperative language; in particular, we have implemented analogs of Control Structure Synthesis and Domain Alignment in our Tiny program restructuring research tool <ref> [Wol91, Ike92] </ref>. In this paper we discuss mainly these two steps. The rest of this paper is organized as follows. In Section 2, we show a simple example of how a program can be converted for mul-ticomputers. Sections 3 and 4 discuss Control Structure Synthesis and Domain Alignment respectively.
Reference: [Li91] <author> Jingke Li. </author> <title> Compiling Crystal for distributed-memory machines. </title> <type> PhD dissertation, </type> <institution> Yale Univ., Dept. Computer Science, </institution> <month> October </month> <year> 1991. </year>
Reference-contexts: Our main focus of this paper is to automate the data decomposition step. Recent work on the functional language Crystal has produced a compiler which automatically converts Crystal programs into executable data-parallel SPMD programs for Distributed Memory Multicom-puters <ref> [Li91] </ref>. The compiler uses three steps to transform the functional program to executable SPMD form: (1) Control Structure Synthesis, (2) Domain Alignment and (3) Communication Synthesis.
Reference: [Wol90] <author> Michael Wolfe. </author> <title> Loop rotation. </title> <editor> In David Gelernter, Alexandru Nicolau, and David A. Padua, editors, </editor> <booktitle> Languages and Compilers for Parallel Computing, Research Monographs in Parallel and Distributed Computing, </booktitle> <pages> pages 531-553. </pages> <publisher> MIT Press, </publisher> <address> Boston, </address> <year> 1990. </year>
Reference-contexts: But sometimes it is better to move chunks of data among processors along with their ownerships. Using this strategy, the mm program can be converted as shown in Figure 15, using a data rotation strategy <ref> [Wol90] </ref>. Arrays c () and a () are decomposed row-wise and distributed statically among all processors. Although array b () is decomposed column-wise and distributed among all processors similarly, we redistribute it by the dorotate construct.
Reference: [Wol91] <author> Michael Wolfe. </author> <title> The Tiny loop restructuring research tool. </title> <booktitle> In Proc. 1991 International Conf. on Parallel Processing, </booktitle> <volume> volume II, </volume> <pages> pages 46-53, </pages> <address> St. Charles, IL, </address> <month> August </month> <year> 1991. </year> <institution> Penn State Press. </institution>
Reference-contexts: Our research examines how to apply these compiler steps to an imperative language; in particular, we have implemented analogs of Control Structure Synthesis and Domain Alignment in our Tiny program restructuring research tool <ref> [Wol91, Ike92] </ref>. In this paper we discuss mainly these two steps. The rest of this paper is organized as follows. In Section 2, we show a simple example of how a program can be converted for mul-ticomputers. Sections 3 and 4 discuss Control Structure Synthesis and Domain Alignment respectively.
References-found: 7

