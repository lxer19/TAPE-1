URL: http://www.cs.duke.edu/~large/Papers/wads.ps
Refering-URL: http://www.cs.duke.edu/~large/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: A General Lower Bound on the I/O-Complexity of Comparison-based Algorithms  
Author: Lars Arge, Mikael Knudsen and Kirsten Larsen 
Address: Ny Munkegade, DK-8000 Aarhus C.  
Affiliation: Aarhus University, Computer Science Department  
Abstract: We show a general relationship between the number of comparisons and the number of I/O-operations needed to solve a given problem. This relationship enables one to show lower bounds on the number of I/O-operations needed to solve a problem whenever a lower bound on the number of comparisons is known. We use the result to show lower bounds on the I/O-complexity on a number of problems where known techniques only give trivial bounds. Among these are the problems of removing duplicates from a multiset, a problem of great importance in e.g. relational data-base systems, and the problem of determining the mode the most frequently occurring element of a multiset. We develop algorithms for these problems in order to show that the lower bounds are tight.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Aggarwal, A., Vitter, J.S.: </author> <title> The I/O Complexity of Sorting and Related Problems. </title> <booktitle> Proceedings of 14th ICALP (1987), Lecture Notes in Computer Science 267, </booktitle> <publisher> Springer Verlag, </publisher> <month> 467-478, </month> <title> and: The Input/Output Complexity of Sorting and Related Problems. </title> <journal> Communications of the ACM, </journal> <volume> Vol 31 (9) (1988) 1116-1127. </volume>
Reference-contexts: In this paper we work in a model introduced by Aggarwal and Vitter <ref> [1] </ref> where an I/O-operation swaps B records between external storage and the internal memory, capable of holding M records. An algorithm for this model is called an I/O-algorithm. Aggarwal and Vitter [1] consider the I/O-complexity of a number of specific sorting-related problems, namely sorting, fast Fourier transformation, permutation networks, permuting and <p> In this paper we work in a model introduced by Aggarwal and Vitter <ref> [1] </ref> where an I/O-operation swaps B records between external storage and the internal memory, capable of holding M records. An algorithm for this model is called an I/O-algorithm. Aggarwal and Vitter [1] consider the I/O-complexity of a number of specific sorting-related problems, namely sorting, fast Fourier transformation, permutation networks, permuting and matrix fl This paper was presented at the third Workshop on Algorithms and Data Structures (WADS'93) y This work was partially supported by the ESPRIT II Basic Research Actions Program of <p> T merge (n; m) denotes the number of comparisons needed to merge two sorted lists, of size n and m respectively. While <ref> [1] </ref> shows lower bounds for a number of specific problems, our result enables one to show lower bounds on the number of I/O-operations needed to solve a problem for any problem where a lower bound on the number of comparisons needed is known. <p> Among these is sorting where we obtain the same lower bound as in <ref> [1] </ref>. We use the result to show lower bounds on a number of problems not formerly considered with respect to I/O-complexity. <p> We develop algorithms for these problems in order to show that the lower bounds are tight. The basic idea in the lower bound proofs in <ref> [1] </ref> is to count how many permutations can be generated with a given number of I/O-operations and to compare this to the number of permutations needed to solve a problem. This technique, however, is not generally applicable. <p> The first M locations in the extended memory constitute the internal memory we denote these s <ref> [1] </ref>; s [2]; : : : ; s [M ] and the rest of the extended memory constitute secondary storage. <p> This is because such manipulations cannot save any comparisons. The differences between our model and the model presented in <ref> [1] </ref> are, apart from ours being restricted to a comparison model, mainly three things. Firstly, Aggarwal and Vitter only assume that a transfer involves B contiguous records in secondary storage, whereas we assume that the B records constitute a track. <p> Further more note that and fi can be defined similarly and that an extension of the definition to more variables describing the problem (other than n), is made by combining the above definition with the ordinary definition of big-oh in more variables. Aggarwal and Vitter <ref> [1] </ref> show the following lower bound on the I/O-complexity of sorting: n log n B log M ! They also give two algorithms based on mergesort and bucketsort that are asymptotically optimal. As mentioned earlier our result provides the same lower bound. <p> This is done with a slightly modified version of an algorithm described by Aggarwal and Vitter <ref> [1] </ref>. Details of these algorithms will appear in a full paper. As the number of I/O-operations at each level is proportional to n=B, the analysis reduces to bounding the number of levels. <p> This gives us the matching upper bound of O aB B . 6 Remarks and Open Problems In the previous section we showed tight bounds on the problems of removing duplicates from a multiset, and determining the mode of a multiset. As mentioned in the introduction, previously known techniques <ref> [1] </ref> give only trivial lower bounds on these problems. On the other hand our theorem is also limited in the sense that there are problems for which it is useless. One example is the problem of permuting n records according to a given permutation . <p> An interesting and important problem "lying between" duplicate removal and permuting is multiset sorting. This problem is analyzed in [4], and lower bounds are given, both using our theorem and a (reduction-) variant of the technique from <ref> [1] </ref>. The obtained lower bounds are quite good, but we believe there is room for improvement. Another interesting problem is to extend the model in which the lower bounds apply. Especially it would be interesting to extend our theorem to an I/O version of algebraic decision trees thus allowing arithmetic.
Reference: [2] <author> Ben-Or, M.: </author> <title> Lower bounds for algebraic computation trees. </title> <booktitle> Proceedings of 15th STOC (1983), </booktitle> <pages> 80-86. </pages>
Reference-contexts: The first M locations in the extended memory constitute the internal memory we denote these s [1]; s <ref> [2] </ref>; : : : ; s [M ] and the rest of the extended memory constitute secondary storage. <p> It can easily be shown (see e.g. <ref> [2] </ref>) that a lower bound on the number of comparisons for each of these problems is n log n O (n). An optimal algorithm is, therefore, to sort the two sets independently, and then solving the problem by "merging" them.
Reference: [3] <author> Blum, M., Floyd, R.W, Pratt, V.R, Rivest, R.L, Tarjan, R.E.: </author> <title> Time bounds for selection. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 7(4) (1972), </volume> <pages> 448-461. </pages>
Reference: [4] <author> Knudsen, M., Larsen, K.: </author> <title> I/O-complexity of comparison and permutation problems. M.Sc. </title> <type> Thesis, </type> <institution> Aarhus University, </institution> <month> November </month> <year> 1992. </year> <month> 11 </month>
Reference-contexts: One example is the problem of permuting n records according to a given permutation . An interesting and important problem "lying between" duplicate removal and permuting is multiset sorting. This problem is analyzed in <ref> [4] </ref>, and lower bounds are given, both using our theorem and a (reduction-) variant of the technique from [1]. The obtained lower bounds are quite good, but we believe there is room for improvement. Another interesting problem is to extend the model in which the lower bounds apply.
Reference: [5] <author> Knuth, D.E.: </author> <title> The Art of Computer Programming, Vol 3: Sorting and Searching, </title> <publisher> Addison-Wesley (1973) (p. </publisher> <pages> 205-206). </pages>
Reference-contexts: Finally, we get the desired result: jpath T c (x)j n B B log B + I=O T (x) T merge (M B; B) 2 Two lists of length n and m (where n &gt; m) can be merged using binary merging <ref> [5] </ref> in m + b n 2 t c 1 + t m comparisons where t = blog n m c.
Reference: [6] <author> Misra, J., Gries, D.: </author> <title> Finding Repeated Elements. </title> <booktitle> Science of Computer Programming 2 (1982), </booktitle> <pages> 143-152, </pages> <publisher> North-Holland Publishing. </publisher>
Reference-contexts: If not, we continue the process on each of the segments as described above. Both the division into segments and the determination of B-majorants can be done in a constant number of sequential runs through each segment. To determine B-majorants we use an algorithm due to Misra and Gries <ref> [6] </ref>. The division of a segment (of n records) into c disjoint new segments can be done so that either 3n p M B is a bound on the number of elements in a new segment or else all the records in the new segment are equal.
Reference: [7] <author> Munro, J.I., Raman, V.: </author> <title> Sorting Multisets and Vectors In-Place. </title> <booktitle> Proceedings of 2nd WADS, Lecture Notes in Computer Science 519, </booktitle> <publisher> Springer Verlag (1991), </publisher> <pages> 473-479. </pages>
Reference-contexts: Any other record (i.e. one of the duplicates) equals one in the set. As the total order is known, the number of comparisons made must be at least the number needed to sort the initial multiset. A lower bound on this has been shown <ref> [7] </ref> to be n log n i=1 n i log n i O (n). <p> In a start configuration, the n records reside at the beginning of the secondary storage. The goal is to have an instance of the most frequently occurring record residing first in secondary storage and all other records immediately after. Munro and Raman <ref> [7] </ref> showed that n log n a O (n) is a lower bound on the number of ternary comparisons needed to determine the mode, where a denotes the frequency of the mode.
Reference: [8] <author> Munro, I., Spira, </author> <title> P.M.: Sorting and Searching in Multisets. </title> <journal> SIAM Journal of Computing, </journal> <note> 5 (1) (1976) 1-8. </note>
Reference-contexts: thus, our theorem, again combined with a trivial lower bound of n B , gives the following lower bound on the number of I/O-operations: I=O mode 2 ( aB B n )! The algorithm that matches this bound is inspired by the distribution sort algorithm presented by Munro and Spira <ref> [8] </ref>. First, we divide the multiset into c disjoint segments of roughly equal size (a segment is a sub-multiset which contains all elements within a given range).
Reference: [9] <author> Nodine, M.H., Vitter, J.S.: </author> <title> Optimal Deterministic Sorting on Parallel Disks. </title> <institution> Brown University, CS-92-08, </institution> <month> August </month> <year> 1992. </year>
Reference-contexts: Of course lower bounds in the Aggarwal and Vitter model also apply in 7 the more realistic model. As using multiple disks is a very popular way of speeding up e.g. external sorting, extensive research has recently been done in this area <ref> [9] </ref> [10]. 5 Optimal Algorithms The common notion of g (n; M; B) 2 O (f (n; M; B)) is that there exists a constant c, such that when n; M and B get sufficiently large, g is bounded by c f .
Reference: [10] <author> Vitter, J.S: </author> <title> Efficient Memory Access in Large-Scale Computation (invited paper). </title> <booktitle> Proceedings of 8th STACS (1991), </booktitle> <pages> 26-41. </pages>
Reference-contexts: Of course lower bounds in the Aggarwal and Vitter model also apply in 7 the more realistic model. As using multiple disks is a very popular way of speeding up e.g. external sorting, extensive research has recently been done in this area [9] <ref> [10] </ref>. 5 Optimal Algorithms The common notion of g (n; M; B) 2 O (f (n; M; B)) is that there exists a constant c, such that when n; M and B get sufficiently large, g is bounded by c f .
Reference: [11] <author> Vitter, J.S., Shriver, E.A.M.: </author> <title> Optimal Disk I/O with Parallel Block Transfer. </title> <booktitle> Proceedings of 22nd STOC (1990), </booktitle> <pages> 159-169. 12 </pages>
Reference-contexts: It should be clear that we can get lower bounds in the same model by dividing lower bounds proved in our model by P . It is worth noting that this parallel model is not especially realistic. A more realistic model was considered in <ref> [11] </ref> in which the secondary storage is partitioned into P distinct disk drives. In each I/O-operation, each of the P disks can simultaneously transfer one block. Thus, P blocks can be transferred per I/O, but only if no two blocks come from the same disk.
References-found: 11

