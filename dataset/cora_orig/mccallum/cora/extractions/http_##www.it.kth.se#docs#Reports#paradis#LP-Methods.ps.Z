URL: http://www.it.kth.se/docs/Reports/paradis/LP-Methods.ps.Z
Refering-URL: http://www.it.kth.se/docs/Reports/paradis/
Root-URL: http://www.it.kth.se
Title: Linear Programming Methods for Minimizing Execution Time of Indexed Computations  
Author: Bjorn Lisper 
Address: P.O. Box 70043  S-100 44 Stockholm, SWEDEN  
Affiliation: Department of Telecommunication and Computer Systems  The Royal Institute of Technology  
Abstract: Systolic implementations of regular, static algorithms can be found by scheduling methods. A class of schedules that has proved to be particularly useful for this purpose is affine mappings from index vectors, enumerating the atomic computations in the algorithm, to a discrete space-time, describing the events in a regular, synchronous system. Affine mappings have the advantage of preserving the regularity of the algorithm into the supporting hardware. They also allow for powerful optimization procedures. We describe how linear programming methods can be applied to find affine schedules with minimal execution time for a given indexed algorithm. We review the work done in the field and present some recent results. We also hint at the possibility to use these methods for code generation for massively parallel, mesh-connected machines. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> W. B. Ackerman. </author> <title> Data flow languages. </title> <journal> Computer, </journal> <volume> 15(2) </volume> <pages> 15-25, </pages> <month> Feb. </month> <year> 1982. </year>
Reference-contexts: A pair hx; oe (x)i can be interpreted as an assignment x oe (x), where x is assigned the value of oe (x). Because the left-hand side variables are distinct, a variable is assigned at most once, so causal substitutions adhere to the single-assignment rule, well-known from definitional languages <ref> [1] </ref>. The evaluation of oe (x) requires the values of the variables in varset (oe (x)), i.e. the variables y for which y OE oe x.
Reference: [2] <author> M. Annaratone, E. Arnould, T. Gross, H. T. Kung, M. Lam, O. Menzilcioglu, and J. A. Webb. </author> <title> The Warp computer: Architecture, implementation and performance. </title> <journal> IEEE Trans. Comput., </journal> <volume> C-36(12):1523-1538, </volume> <month> Dec. </month> <year> 1987. </year>
Reference-contexts: See, for instance, [10]. An interesting possiblility is to apply these methods also to code generation for parallel computers close to systolic arrays, like regular SIMD processor arrays or the Warp <ref> [2] </ref>. The rest of this paper is organized as follows: in sections 2, 3 and 4 we develop the essentials of a general theory for indexed static algorithms and space-time mappings.
Reference: [3] <author> M. C. Chen. </author> <title> A parallel language and its compilation to multiprocessor machines or VLSI. </title> <booktitle> In Proc. Principles of Programming Languages, </booktitle> <pages> pages 131-139, </pages> <month> Jan. </month> <year> 1986. </year>
Reference-contexts: URE:s have been used extensively as a starting point for synthesis of systolic arrays [5, 27, 35]. Extensions of URE:s have also been considered [4, 28], as well as the closely related Regular Iterative Algorithms (RIA) [9, 30]. Crystal <ref> [3] </ref> is a general language for recursion equations. It is proposed as a programming language to be used in conjunction with space-time mapping methods, in order to find efficient parallel implementations.
Reference: [4] <author> J.-M. Delosme and I. Ipsen. </author> <title> Efficient systolic arrays for the solution of Toeplitz systems: an illustration of a methodology for the construction of systolic architectures in VLSI. </title> <editor> In W. Moore, A. McCabe, and R. Urquhart, editors, </editor> <booktitle> Systolic Arrays, </booktitle> <pages> pages 37-46, </pages> <address> Bristol, UK, </address> <year> 1987. </year> <note> Adam Hilger. </note>
Reference-contexts: The origin is the paper by Karp, Miller and Winograd on Uniform Recurrence Equations (URE) [11]. URE:s have been used extensively as a starting point for synthesis of systolic arrays [5, 27, 35]. Extensions of URE:s have also been considered <ref> [4, 28] </ref>, as well as the closely related Regular Iterative Algorithms (RIA) [9, 30]. Crystal [3] is a general language for recursion equations. It is proposed as a programming language to be used in conjunction with space-time mapping methods, in order to find efficient parallel implementations. <p> In an early paper [6] Fortes and Parisi-Presicce give an algorithm, that finds a time-minimal linear schedule when the index set is the cartesian product of sets of consecutive integers. Later, their result was extended to URE:s in general [32]. Delosme and Ipsen <ref> [4] </ref> observed that the execution time optimization problem, for recurrences with affine dependencies, can be cast as an integer linear programming problem. Kothari, Oh and Gannett [13] propose a heuristic that works for nested loop programs with linear dependencies, under certain assumptions on the character of the resulting hardware.
Reference: [5] <author> B. R. Engstrom and P. L. Cappello. </author> <title> The SDEF programming system. </title> <journal> J. Parallel Distrib. Comput., </journal> <volume> 7 </volume> <pages> 201-231, </pages> <year> 1989. </year>
Reference-contexts: In this way, the imperative overspecification is avoided and the steps in the recurrence can be scheduled directly. The origin is the paper by Karp, Miller and Winograd on Uniform Recurrence Equations (URE) [11]. URE:s have been used extensively as a starting point for synthesis of systolic arrays <ref> [5, 27, 35] </ref>. Extensions of URE:s have also been considered [4, 28], as well as the closely related Regular Iterative Algorithms (RIA) [9, 30]. Crystal [3] is a general language for recursion equations.
Reference: [6] <author> J. A. B. Fortes and F. Parisi-Presicce. </author> <title> Optimal linear schedules for the parallel execution of algorithms. </title> <booktitle> In Proc. IEEE Int. Conf. on Parallel Processing, </booktitle> <pages> pages 322-329, </pages> <year> 1984. </year>
Reference-contexts: Besides a close correspondence with data dependence graphs, they have very simple semantics [20]. The problem of minimizing the execution time for affinely scheduled computations has been studied for limited cases before. In an early paper <ref> [6] </ref> Fortes and Parisi-Presicce give an algorithm, that finds a time-minimal linear schedule when the index set is the cartesian product of sets of consecutive integers. Later, their result was extended to URE:s in general [32].
Reference: [7] <author> G. Gratzer. </author> <title> Universal Algebra. </title> <publisher> Springer-Verlag, </publisher> <address> New York, NY, </address> <year> 1979. </year>
Reference-contexts: In section 7 we briefly review some related work. Section 8, finally, provides a discussion and suggestions for future research. 2 Preliminaries A mathematical model of static algorithms can be based on universal algebra and formal expressions <ref> [7] </ref>. Let varset (p) be the set of variables in the expression p, e.g. varset (x + 2 y z) = fx; y; zg. A substitution oe is a partial function from variables to expressions.
Reference: [8] <author> C.-H. Huang and C. Lengauer. </author> <title> The derivation of systolic implementations of programs. </title> <journal> Acta Inform., </journal> <volume> 24 </volume> <pages> 595-632, </pages> <year> 1987. </year>
Reference-contexts: In the setting of imperative languages, restricted loops with static loop bodies <ref> [8, 23, 24] </ref> or simple conditionals [13] have been considered. Actually, the linear space-time mapping methods are descendants of the wave-front method [17, 25, 34] for scheduling Fortran DO loops on the Illiac-IV.
Reference: [9] <author> H. V. Jagadish, S. K. Rao, and T. Kailath. </author> <title> Array architectures for iterative algorithms. </title> <journal> Proc. IEEE, </journal> <volume> 75(9) </volume> <pages> 1304-1321, </pages> <month> Sept. </month> <year> 1987. </year>
Reference-contexts: URE:s have been used extensively as a starting point for synthesis of systolic arrays [5, 27, 35]. Extensions of URE:s have also been considered [4, 28], as well as the closely related Regular Iterative Algorithms (RIA) <ref> [9, 30] </ref>. Crystal [3] is a general language for recursion equations. It is proposed as a programming language to be used in conjunction with space-time mapping methods, in order to find efficient parallel implementations.
Reference: [10] <author> R. Kannan. </author> <title> A polynomial algorithm for the two-variable integer programming problem. </title> <journal> J. Assoc. Comput. Mach., </journal> <volume> 27(1) </volume> <pages> 118-122, </pages> <month> Jan. </month> <year> 1980. </year>
Reference-contexts: While NP-complete in general, there exists a polynomial time ILP algorithm for each fixed number of variables [31]. Most algorithms of interest for systolic implementations have natural two- or three-dimensional indexings, so it is likely that there are practical polynomial time minimization techniques. See, for instance, <ref> [10] </ref>. An interesting possiblility is to apply these methods also to code generation for parallel computers close to systolic arrays, like regular SIMD processor arrays or the Warp [2].
Reference: [11] <author> R. M. Karp, R. E. Miller, and S. Winograd. </author> <title> The organization of computations for uniform recurrence equations. </title> <journal> J. Assoc. Comput. Mach., </journal> <volume> 14(3) </volume> <pages> 563-590, </pages> <month> July </month> <year> 1967. </year>
Reference-contexts: Another approach is to use simple recurrences to express the class of static algorithms under consideration. In this way, the imperative overspecification is avoided and the steps in the recurrence can be scheduled directly. The origin is the paper by Karp, Miller and Winograd on Uniform Recurrence Equations (URE) <ref> [11] </ref>. URE:s have been used extensively as a starting point for synthesis of systolic arrays [5, 27, 35]. Extensions of URE:s have also been considered [4, 28], as well as the closely related Regular Iterative Algorithms (RIA) [9, 30]. Crystal [3] is a general language for recursion equations.
Reference: [12] <author> T. Kaufl. </author> <title> Reasoning about systems of linear inequalities. </title> <editor> In E. Lusk and R. Overbeek, editors, </editor> <booktitle> Proc. 9th Int. Conf. on Automated Deduction, </booktitle> <pages> pages 563-572. </pages> <booktitle> Volume 310 of Lecture Notes in Comput. </booktitle> <publisher> Sci., Springer-Verlag, </publisher> <month> May </month> <year> 1988. </year>
Reference-contexts: A crucial point is that the number of inequalities must be kept within a reasonable limit. Fast methods are known that eliminate dominated inequalities and detect when a system of inequalities has no solution <ref> [12, 33] </ref>. A naive generation of constraints according to the theory developed here will, however, yield O (jIj 2 linear constraints in the worst case for many of the interesting properties.
Reference: [13] <author> S. C. Kothari, H. Oh, and E. Gannett. </author> <title> Optimal designs of linear flow systolic architectures. </title> <booktitle> In Proc. of the 1989 Int. Conf. on Parallel Processing, </booktitle> <volume> Vol. I: Architecture, </volume> <pages> pages 247-256, </pages> <month> Aug. </month> <year> 1989. </year>
Reference-contexts: In the setting of imperative languages, restricted loops with static loop bodies [8, 23, 24] or simple conditionals <ref> [13] </ref> have been considered. Actually, the linear space-time mapping methods are descendants of the wave-front method [17, 25, 34] for scheduling Fortran DO loops on the Illiac-IV. <p> Later, their result was extended to URE:s in general [32]. Delosme and Ipsen [4] observed that the execution time optimization problem, for recurrences with affine dependencies, can be cast as an integer linear programming problem. Kothari, Oh and Gannett <ref> [13] </ref> propose a heuristic that works for nested loop programs with linear dependencies, under certain assumptions on the character of the resulting hardware.
Reference: [14] <author> H. T. Kung. </author> <title> Why systolic architectures? Computer, </title> <booktitle> 15 </booktitle> <pages> 37-46, </pages> <month> Jan. </month> <year> 1982. </year> <month> 10 </month>
Reference-contexts: For static algorithms, code generation for given parallel systems and synthesis of special-purpose architectures are merely two sides of the same coin. In both cases, solutions can be found by scheduling methods. Regular VLSI structures like systolic arrays <ref> [14, 16] </ref> can be derived by a space-time mapping followed by a projection. Algorithms that are readily implementable on such structures have a certain regularity themselves. Typically, this regularity can be captured by a sometimes multidimensional enumeration, that yields a compact representation of the algorithm.
Reference: [15] <author> H. T. Kung and M. S. Lam. </author> <title> Wafer-scale integration and two-level pipelined implementations of systolic arrays. </title> <journal> J. Parallel Distrib. Comput., </journal> <volume> 1(1) </volume> <pages> 32-63, </pages> <month> Aug. </month> <year> 1984. </year>
Reference-contexts: The use of "internal" pipelining of operations in systolic arrays is sometimes called two-level pipelining <ref> [15] </ref>. Systolic arrays with two-level pipelining can thus be derived by affine space-time mappings. Define, for all x and y in dom (oe) such that x OE oe y, the data dependence vector from x to y, d xy , to be G (y) G (x).
Reference: [16] <author> H. T. Kung and C. E. Leiserson. In C. Mead and L. Conway: </author> <title> Introduction to VLSI systems, chapter 8.3. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1980. </year>
Reference-contexts: For static algorithms, code generation for given parallel systems and synthesis of special-purpose architectures are merely two sides of the same coin. In both cases, solutions can be found by scheduling methods. Regular VLSI structures like systolic arrays <ref> [14, 16] </ref> can be derived by a space-time mapping followed by a projection. Algorithms that are readily implementable on such structures have a certain regularity themselves. Typically, this regularity can be captured by a sometimes multidimensional enumeration, that yields a compact representation of the algorithm.
Reference: [17] <author> L. Lamport. </author> <title> The parallel execution of DO loops. </title> <journal> Comm. ACM, </journal> <volume> 17 </volume> <pages> 83-93, </pages> <month> Feb. </month> <year> 1974. </year>
Reference-contexts: In the setting of imperative languages, restricted loops with static loop bodies [8, 23, 24] or simple conditionals [13] have been considered. Actually, the linear space-time mapping methods are descendants of the wave-front method <ref> [17, 25, 34] </ref> for scheduling Fortran DO loops on the Illiac-IV. In order to schedule loops by space-time mappings, however, the loop body must first be transformed to remove the overspecification of the imperative formulation.
Reference: [18] <author> B. Lisper. </author> <title> Time-optimal synthesis of systolic arrays with pipelined cells. Res. </title> <type> Rep. </type> <institution> YALEU/DCS/RR-560, Dept. Comput. Sci., Yale University, </institution> <month> Sept. </month> <year> 1987. </year>
Reference-contexts: An on-line system should then use the inputs in the same order, in order to minimize response time and buffer space. This can be expressed as linear constraints, <ref> [18] </ref>. 6.6 Pipeline causality constraints The causality constraint (1) is based on the view that an indexed computation is atomic and can be carried out in one time-step, without overlap. <p> For examples of time-optimal systolic arrays with two-level pipelining, derived with linear programming methods, see <ref> [18, 22] </ref>. 6.7 Computations that need more than one time unit to complete Another extension is to allow operations to use more than one time unit, without being internally pipelined. For each index vector i we then assume a positive integer computation time c (i).
Reference: [19] <author> B. Lisper. </author> <title> Single assignment semantics for imperative programs. </title> <editor> In E. Odjik, M. Rem, and J.-C. Syre, editors, </editor> <booktitle> Proc. PARLE'89 vol. II: Parallel Languages, </booktitle> <pages> pages 321-334, </pages> <address> Berlin, </address> <month> June </month> <year> 1989. </year> <booktitle> Volume 366 of Lecture Notes in Comput. </booktitle> <publisher> Sci., Springer-Verlag. </publisher>
Reference-contexts: Define the ordering OE oe on variables by: x OE oe y iff x 2 varset (oe (y)). oe is causal if OE + oe is well-founded (a strict partial order and no infinite decreasing chains exist). For more detail, see <ref> [19, 20] </ref>. 3 Indexed static algorithms A causal substitution oe is a partial function: thus, it is a set of pairs f hx; oe (x)i j x 2 dom (oe) g where each x is distinct.
Reference: [20] <author> B. Lisper. </author> <title> Synthesis of Synchronous Systems by Static Scheduling in Space-Time, </title> <booktitle> volume 362 of Lecture Notes in Comput. </booktitle> <publisher> Sci. Springer-Verlag, </publisher> <address> Heidelberg, </address> <month> May </month> <year> 1989. </year>
Reference-contexts: 1 Introduction Special purpose parallel systems for static algorithms can be found by so-called space-time mapping methods <ref> [20] </ref>. <p> Define the ordering OE oe on variables by: x OE oe y iff x 2 varset (oe (y)). oe is causal if OE + oe is well-founded (a strict partial order and no infinite decreasing chains exist). For more detail, see <ref> [19, 20] </ref>. 3 Indexed static algorithms A causal substitution oe is a partial function: thus, it is a set of pairs f hx; oe (x)i j x 2 dom (oe) g where each x is distinct. <p> space-time mapping F from the index vector structure hI; OEi is usually required to fulfil the following two requirements: If i OE i 0 ; then F t (i) &lt; F t (i 0 ): (Causality) (1) F is injective. (2) Under some circumstances, these requirements can be somewhat relaxed, <ref> [20] </ref>. When a schedule is determined, the mapped dependence graph can be projected to yield a system of interconnected, synchronous processes supporting the schedule. <p> This turns the task to find an optimal L i t into a pure ILP problem. There are, however, interesting algorithms, suitable for systolic implementation, with natural indexings which allow non-integer affine mappings <ref> [20, 21] </ref>. Figure 1 shows such an index set I. For instance, the following space-time mapping from I is allowed: y = 1=2 1=2 k 1=2 It will map any index vector of I to integer coordinates despite its non-integer coefficients. <p> Note that an attempt to find a time-optimal solution with pure ILP methods will not catch this solution, which actually is optimal w.r.t. execution time <ref> [20] </ref>. Index sets allowing non-integer affine time functions can, however, always be affinely transformed into a new ones that only allow integer affine time functions. Such a transformation is called a preconditioning index set transformation. See [21]. <p> If this condition is fulfilled, then the value of x can always be used by one computation at a time and then passed on to the next, <ref> [20, theorems 8.1, 8.2] </ref>. In the linear case we obtain L t (G (y)) 6= L t (G (y 0 )), that is: L t (G (y 0 ) G (y)) 6= 0 for all y, y 0 in succ (x). <p> Indexed regular dependence graphs [26, 29] is an example of this. The causal substitutions described here also provide a language-independent, general model of static algorithms. Besides a close correspondence with data dependence graphs, they have very simple semantics <ref> [20] </ref>. The problem of minimizing the execution time for affinely scheduled computations has been studied for limited cases before. In an early paper [6] Fortes and Parisi-Presicce give an algorithm, that finds a time-minimal linear schedule when the index set is the cartesian product of sets of consecutive integers.
Reference: [21] <author> B. Lisper. </author> <title> Preconditioning index set transformations for time-optimal affine scheduling. </title> <booktitle> In Proc. 2nd Ann. Symp. on Parallel Algorithms and Architectures, </booktitle> <pages> pages 360-366. </pages> <publisher> ACM, </publisher> <month> July </month> <year> 1990. </year>
Reference-contexts: This turns the task to find an optimal L i t into a pure ILP problem. There are, however, interesting algorithms, suitable for systolic implementation, with natural indexings which allow non-integer affine mappings <ref> [20, 21] </ref>. Figure 1 shows such an index set I. For instance, the following space-time mapping from I is allowed: y = 1=2 1=2 k 1=2 It will map any index vector of I to integer coordinates despite its non-integer coefficients. <p> Index sets allowing non-integer affine time functions can, however, always be affinely transformed into a new ones that only allow integer affine time functions. Such a transformation is called a preconditioning index set transformation. See <ref> [21] </ref>.
Reference: [22] <author> B. Lisper. </author> <title> Synthesis of time-optimal systolic arrays with cells with inner structure. </title> <journal> J. Parallel Distrib. Comput., </journal> <volume> 10(2) </volume> <pages> 182-187, </pages> <month> Oct. </month> <year> 1990. </year>
Reference-contexts: Step 4 requires solving a linear programming problem for each P jk , with the additional requirement that L t i 2 Z for all i 2 I. See <ref> [22] </ref>. (Note that since we consider affine time functions, we do not have to require L t i 2 N . <p> For space-time mappings between index space and space-time of equal dimension, i.e. when L is square, the condition is equivalent to non-singularity of L. Then it can be obtained from the non-singularity condition det (L) 6= 0 simply by expanding det (L) after the L t -row <ref> [22] </ref>. 6 6.3 Locality of communications Let d be a metric on the space Z k , i.e. d (r; r 0 ) is the distance between r and r 0 . <p> Such a causality constraint requires information about the inner structure of computations. This information is captured by a pipeline description, according to the following definition from <ref> [22] </ref>: Definition 2 Let oe be a causal substitution. <p> Then, the pipeline causality constraints yield the following linear inequalities for the linear part of the time function <ref> [22, theorem 1] </ref>: * L t d xy p (x) i (x; y) for all variables x and y in dom (oe) such that x OE oe y. <p> For examples of time-optimal systolic arrays with two-level pipelining, derived with linear programming methods, see <ref> [18, 22] </ref>. 6.7 Computations that need more than one time unit to complete Another extension is to allow operations to use more than one time unit, without being internally pipelined. For each index vector i we then assume a positive integer computation time c (i).
Reference: [23] <author> W. L. Miranker and A. Winkler. </author> <title> Spacetime representations of computational structures. </title> <journal> Computing, </journal> <volume> 32 </volume> <pages> 93-114, </pages> <year> 1984. </year>
Reference-contexts: In the setting of imperative languages, restricted loops with static loop bodies <ref> [8, 23, 24] </ref> or simple conditionals [13] have been considered. Actually, the linear space-time mapping methods are descendants of the wave-front method [17, 25, 34] for scheduling Fortran DO loops on the Illiac-IV.
Reference: [24] <author> D. I. Moldovan. </author> <title> On the analysis and synthesis of VLSI algorithms. </title> <journal> IEEE Trans. Comput., </journal> <volume> C-31:1121-1126, </volume> <month> Oct. </month> <year> 1982. </year>
Reference-contexts: 6.1 Causality The causality constraint (1) immediately gives the following linear constraints: whenever i OE i 0 , it must hold that L t (i 0 i) &gt; 0: (6) Commonly, the set f i 0 i j i OE i 0 g of data dependence vectors (ddv's) is formed <ref> [24, 27, 28] </ref>. With these, condition (6) becomes L t d &gt; 0 for all ddv's d. Typically, a regular algorithm considered for systolic implementation will have only a few distinct ddv's. <p> In the setting of imperative languages, restricted loops with static loop bodies <ref> [8, 23, 24] </ref> or simple conditionals [13] have been considered. Actually, the linear space-time mapping methods are descendants of the wave-front method [17, 25, 34] for scheduling Fortran DO loops on the Illiac-IV.
Reference: [25] <author> Y. Muraoka. </author> <title> Parallelism Exposure and Exploitation in Programs. </title> <type> PhD thesis, </type> <institution> Dept. Comput. Sci., University of Illinois at Urbana-Champaign, </institution> <year> 1971. </year>
Reference-contexts: In the setting of imperative languages, restricted loops with static loop bodies [8, 23, 24] or simple conditionals [13] have been considered. Actually, the linear space-time mapping methods are descendants of the wave-front method <ref> [17, 25, 34] </ref> for scheduling Fortran DO loops on the Illiac-IV. In order to schedule loops by space-time mappings, however, the loop body must first be transformed to remove the overspecification of the imperative formulation.
Reference: [26] <author> H. Nelis and E. F. Deprettere. </author> <title> A systematic method for mapping algorithms of arbitrarily large dimensions onto fixed size systolic arrays. </title> <booktitle> In Proc. IEEE Int. Symp. on Circuits and Systems, </booktitle> <volume> vol. 2, </volume> <pages> pages 559-563, </pages> <month> May </month> <year> 1987. </year>
Reference-contexts: A third approach is to develop theories free from language issues. For instance, a description of static algorithms could be based directly on DAG:s where the nodes are labeled with the particular computations they stand for. Indexed regular dependence graphs <ref> [26, 29] </ref> is an example of this. The causal substitutions described here also provide a language-independent, general model of static algorithms. Besides a close correspondence with data dependence graphs, they have very simple semantics [20].
Reference: [27] <author> P. </author> <title> Quinton. Automatic synthesis of systolic arrays from uniform recurrent equations. </title> <booktitle> In Proc. 11th Annual Int. Symp. on Comput. Arch., </booktitle> <pages> pages 208-214, </pages> <month> June </month> <year> 1984. </year>
Reference-contexts: 6.1 Causality The causality constraint (1) immediately gives the following linear constraints: whenever i OE i 0 , it must hold that L t (i 0 i) &gt; 0: (6) Commonly, the set f i 0 i j i OE i 0 g of data dependence vectors (ddv's) is formed <ref> [24, 27, 28] </ref>. With these, condition (6) becomes L t d &gt; 0 for all ddv's d. Typically, a regular algorithm considered for systolic implementation will have only a few distinct ddv's. <p> In this way, the imperative overspecification is avoided and the steps in the recurrence can be scheduled directly. The origin is the paper by Karp, Miller and Winograd on Uniform Recurrence Equations (URE) [11]. URE:s have been used extensively as a starting point for synthesis of systolic arrays <ref> [5, 27, 35] </ref>. Extensions of URE:s have also been considered [4, 28], as well as the closely related Regular Iterative Algorithms (RIA) [9, 30]. Crystal [3] is a general language for recursion equations.
Reference: [28] <author> S. V. Rajopadye. </author> <title> Synthesizing systolic arrays with control signals from recurrence equations. Distrib. </title> <journal> Comput., </journal> <volume> 3 </volume> <pages> 88-105, </pages> <year> 1989. </year>
Reference-contexts: 6.1 Causality The causality constraint (1) immediately gives the following linear constraints: whenever i OE i 0 , it must hold that L t (i 0 i) &gt; 0: (6) Commonly, the set f i 0 i j i OE i 0 g of data dependence vectors (ddv's) is formed <ref> [24, 27, 28] </ref>. With these, condition (6) becomes L t d &gt; 0 for all ddv's d. Typically, a regular algorithm considered for systolic implementation will have only a few distinct ddv's. <p> The origin is the paper by Karp, Miller and Winograd on Uniform Recurrence Equations (URE) [11]. URE:s have been used extensively as a starting point for synthesis of systolic arrays [5, 27, 35]. Extensions of URE:s have also been considered <ref> [4, 28] </ref>, as well as the closely related Regular Iterative Algorithms (RIA) [9, 30]. Crystal [3] is a general language for recursion equations. It is proposed as a programming language to be used in conjunction with space-time mapping methods, in order to find efficient parallel implementations.
Reference: [29] <author> I. V. Ramakrishnan, D. S. Fussell, and A. Silberschatz. </author> <title> Mapping homogeneous graphs on linear arrays. </title> <journal> IEEE Trans. Comput., </journal> <volume> C-35(3):189-209, </volume> <month> Mar. </month> <year> 1986. </year>
Reference-contexts: A third approach is to develop theories free from language issues. For instance, a description of static algorithms could be based directly on DAG:s where the nodes are labeled with the particular computations they stand for. Indexed regular dependence graphs <ref> [26, 29] </ref> is an example of this. The causal substitutions described here also provide a language-independent, general model of static algorithms. Besides a close correspondence with data dependence graphs, they have very simple semantics [20].
Reference: [30] <author> S. K. Rao and T. Kailath. </author> <title> Regular iterative algorithms and their implementation on processor arrays. </title> <journal> Proc. IEEE, </journal> <volume> 76(3) </volume> <pages> 259-269, </pages> <month> Mar. </month> <year> 1988. </year>
Reference-contexts: URE:s have been used extensively as a starting point for synthesis of systolic arrays [5, 27, 35]. Extensions of URE:s have also been considered [4, 28], as well as the closely related Regular Iterative Algorithms (RIA) <ref> [9, 30] </ref>. Crystal [3] is a general language for recursion equations. It is proposed as a programming language to be used in conjunction with space-time mapping methods, in order to find efficient parallel implementations.
Reference: [31] <author> A. Schrijver. </author> <title> Theory of Linear and Integer Programming. </title> <publisher> Wiley, </publisher> <year> 1986. </year>
Reference-contexts: Many desirable properties for regular VLSI structures turn into linear constraints on the time part of the space-time mapping. While NP-complete in general, there exists a polynomial time ILP algorithm for each fixed number of variables <ref> [31] </ref>. Most algorithms of interest for systolic implementations have natural two- or three-dimensional indexings, so it is likely that there are practical polynomial time minimization techniques. See, for instance, [10].
Reference: [32] <author> W. Shang and J. A. B. Fortes. </author> <title> On the optimality of linear schedules. </title> <journal> J. VLSI Signal Processing, </journal> <volume> 1 </volume> <pages> 209-220, </pages> <year> 1989. </year>
Reference-contexts: In an early paper [6] Fortes and Parisi-Presicce give an algorithm, that finds a time-minimal linear schedule when the index set is the cartesian product of sets of consecutive integers. Later, their result was extended to URE:s in general <ref> [32] </ref>. Delosme and Ipsen [4] observed that the execution time optimization problem, for recurrences with affine dependencies, can be cast as an integer linear programming problem.
Reference: [33] <author> R. Shostak. </author> <title> Deciding linear equalities by computing loop residues. </title> <journal> J. Assoc. Comput. Mach., </journal> <volume> 28(4) </volume> <pages> 769-779, </pages> <month> Oct. </month> <year> 1981. </year>
Reference-contexts: A crucial point is that the number of inequalities must be kept within a reasonable limit. Fast methods are known that eliminate dominated inequalities and detect when a system of inequalities has no solution <ref> [12, 33] </ref>. A naive generation of constraints according to the theory developed here will, however, yield O (jIj 2 linear constraints in the worst case for many of the interesting properties.
Reference: [34] <author> R. A. Towle. </author> <title> Control and data dependence for program transformations. </title> <type> PhD thesis, </type> <institution> Dept. Comput. Sci., University of Illinois at Urbana-Champaign, </institution> <month> Mar. </month> <year> 1976. </year>
Reference-contexts: In the setting of imperative languages, restricted loops with static loop bodies [8, 23, 24] or simple conditionals [13] have been considered. Actually, the linear space-time mapping methods are descendants of the wave-front method <ref> [17, 25, 34] </ref> for scheduling Fortran DO loops on the Illiac-IV. In order to schedule loops by space-time mappings, however, the loop body must first be transformed to remove the overspecification of the imperative formulation.
Reference: [35] <author> V. Van Dongen and M. Petit. PRESAGE: </author> <title> A tool for the parallellization of nested loop programs. </title> <booktitle> In Proc. IMEC-IFIP Workshop on Formal Methods for Correct VLSI Design, </booktitle> <pages> pages 443-461, </pages> <year> 1989. </year> <month> 11 </month>
Reference-contexts: In this way, the imperative overspecification is avoided and the steps in the recurrence can be scheduled directly. The origin is the paper by Karp, Miller and Winograd on Uniform Recurrence Equations (URE) [11]. URE:s have been used extensively as a starting point for synthesis of systolic arrays <ref> [5, 27, 35] </ref>. Extensions of URE:s have also been considered [4, 28], as well as the closely related Regular Iterative Algorithms (RIA) [9, 30]. Crystal [3] is a general language for recursion equations.
Reference: [36] <author> Y. Wong and J.-M. Delosme. </author> <title> Optimization of computation time for systolic arrays. </title> <booktitle> In Proc. 26th Allerton Conf. on Communication, Control and Computing, </booktitle> <pages> pages 1104-1113, </pages> <month> Sept. </month> <year> 1988. </year> <month> 12 </month>
Reference-contexts: Kothari, Oh and Gannett [13] propose a heuristic that works for nested loop programs with linear dependencies, under certain assumptions on the character of the resulting hardware. Wong and Delosme <ref> [36] </ref>, finally, describe a branch-and-bound algorithm to find time-optimal linear schedules for URE:s when the cycle time for atomic steps (i.e. nodes in the data dependence graph) is taken into account.
References-found: 36

