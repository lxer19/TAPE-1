URL: http://cse.ogi.edu/~sheard/papers/PepmMulStg97.ps
Refering-URL: http://www.cse.ogi.edu/~sheard/sheard.html
Root-URL: http://www.cse.ogi.edu
Email: fwalidt,sheardg@cse.ogi.edu  
Title: Multi-Stage Programming with Explicit Annotations  
Author: Walid Taha Tim Sheard 
Affiliation: Oregon Graduate Institute of Science Technology  
Abstract: We introduce MetaML, a statically-typed multi-stage programming language extending Nielson and Nielson's two stage notation to an arbitrary number of stages. MetaML extends previous work by introducing four distinct staging annotations which generalize those published previously [25, 12, 7, 6] We give a static semantics in which type checking is done once and for all before the first stage, and a dynamic semantics which introduces a new concept of cross-stage persistence, which requires that variables available in any stage are also available in all future stages. We illustrate that staging is a manual form of binding time analysis. We explain why, even in the presence of automatic binding time analysis, explicit annotations are useful, especially for programs with more than two stages. A thesis of this paper is that multi-stage languages are useful as programming languages in their own right, and should support features that make it possible for programmers to write staged computations without significantly changing their normal programming style. To illustrate this we provide a simple three stage example, and an extended two-stage example elaborating a number of practical issues. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> C. Consel and O. Danvy. </author> <title> For a better support of static data flow. </title> <editor> In J. Hughes, editor, </editor> <booktitle> Functional Programming Languages and Computer Architecture, </booktitle> <address> Cambridge, Massachusetts, </address> <booktitle> August 1991 (Lecture Notes in Computer Science, </booktitle> <volume> vol. 523), </volume> <pages> pages 496-519. </pages> <address> New York: </address> <publisher> ACM, Berlin: Springer-Verlag, </publisher> <year> 1991. </year>
Reference: [2] <author> Charles Consel and Olivier Danvy. </author> <title> Tutorial notes on partial evaluation. </title> <booktitle> In ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 493-501, </pages> <month> January </month> <year> 1993. </year>
Reference-contexts: Following the annotations, the specializer either performs a computation, or produces text for inclusion in the output (residual) program. The relationship between partial-evaluation and multistage programming is that the intermediate data structure between the two steps is a two-stage annotated program <ref> [2] </ref>, and that the specialization phase is (the first stage in) the execution of the two-stage annotated program produced by BTA. Recently, Gluck and Jtrgensen proposed multi-level BTA and showed that it is an efficient alternative to multiple specialization [9, 10].
Reference: [3] <author> Roberto Di Cosmo. </author> <title> Isomorphisms of Types: from - calculus to information retrieval and language design. </title> <booktitle> Progress in Theoretical Computer Science. </booktitle> <publisher> Birkhauser, </publisher> <year> 1995. </year>
Reference-contexts: Under this proviso (and disregarding termination issues) the composition of these two functions is identity under MetaML's semantics (see Section 10). They define an isomorphism between values of type &lt;A,'c&gt; -&gt; &lt;B,'c&gt; and &lt;A -&gt; B,'c&gt;. <ref> [3] </ref>. The back and forth functions are similar to two-level -expansion [5]. In MetaML, however, back and forth are not only meta-level concepts or optimizations, but rather, first class functions in the language, and the user can apply them directly to values of the appropriate type.
Reference: [4] <author> Olivier Danvy. </author> <title> Type-directed partial evaluation. </title> <booktitle> In ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 242-257, </pages> <address> Florida, January 1996. New York: </address> <publisher> ACM. </publisher>
Reference-contexts: It seems that this isomorphism, which MetaML has allowed us to make concrete, is at the heart of concise reduction systems, such as Danvy's type-directed partial evaluator <ref> [4] </ref> and its extensions [27]. Under MetaML's semantics, we can switch between the two types without needing to worry about substitution or variable capture. This has profound implications for the writing of staged functions.
Reference: [5] <author> Olivier Danvy, Karoline Malmkjaer, and Jens Pals-berg. </author> <title> The essence of eta-expansion in partial evaluation. </title> <journal> LISP and Symbolic Computation, </journal> <volume> 1(19), </volume> <year> 1995. </year>
Reference-contexts: Under this proviso (and disregarding termination issues) the composition of these two functions is identity under MetaML's semantics (see Section 10). They define an isomorphism between values of type &lt;A,'c&gt; -&gt; &lt;B,'c&gt; and &lt;A -&gt; B,'c&gt;. [3]. The back and forth functions are similar to two-level -expansion <ref> [5] </ref>. In MetaML, however, back and forth are not only meta-level concepts or optimizations, but rather, first class functions in the language, and the user can apply them directly to values of the appropriate type.
Reference: [6] <author> Rowan Davies. </author> <title> A temporal-logic approach to binding time analysis. </title> <booktitle> In Proceedings, 11 th Annual IEEE Symposium on Logic in Computer Science, </booktitle> <pages> pages 184-195, </pages> <address> New Brunswick, New Jersey, 27-30 July 1996. </address> <publisher> IEEE Computer Society Press. </publisher>
Reference-contexts: It provides the following extensions not found in previous work on multi-stage systems: * Four distinct staging annotations, which we believe are necessary and sufficient for all multi-stage programming. (Section 5) These annotations generalize and safely combine those published previously <ref> [25, 12, 7, 6] </ref>. The formal proof of safety is ongoing work. * A type system ensuring the well-formedness of acceptable multi-stage programs. Type checking is done once and for all before the first stage (Section 10.1). * Variables of any stage are available in all future stages. <p> This feature, in a language which also contains run 1 makes MetaML's annotations strictly more expressive than the languages of Nielsen & Nielsen [25, 24], Davies & Pfenning [7], and Davies <ref> [6] </ref>. We also deal with the interesting technical problem of ensuring the hygienic binding of free variables (Section 10.2) in code expres sions. * A non-Hindley-Milner, second-order type judgement for the run annotation to ensure that no code is ever run in a context in which it is undefined. <p> This is part of what we mean by having an integrated system. Cross-Stage Persistence can be relaxed by allowing variables to be available at exactly one stage. This seems to have been the case in all multi-stage languages known to us to date <ref> [25, 12, 9, 10, 7, 6] </ref>. The primary difficulty in implementing persistence is the proper hygienic treatment of free variables. We will show how this problem can be solved, thus allowing the user to stage significantly more expressions than was previously possible. <p> Because we are more used to reasoning about functions, this leads us to avoid creating functions of the latter kind except when we need to inspect the code. The type of back is one of the axioms of the logic system motivating the type system of Davies <ref> [6] </ref>. MetaML's type system was motivated purely by operational reasons. At the same time, it is important for the programmer to have both coercions, thereby being able to switch back and forth between the two isomorphic types as the need arises. <p> For the standard part of the language, code (now denoted by h i for conciseness) is a normal type constructor that needs no special treatment and the level n is never changed. Similar type systems have been identified and used by Go-mard and Jones [11], Davies & Pfenning <ref> [6] </ref> and Davies [7]. <p> Similar type systems have been identified and used by Go-mard and Jones [11], Davies & Pfenning [6] and Davies [7]. An important difference between these type systems and the one in Figure 1 is that in all previous statically-typed multi-stage languages <ref> [25, 7, 6] </ref>, only the following mono lithic type rule is used for variables: Var (Monolithic): ( x) = t m n when m = n Whereas we allow the more general condition m n. <p> In particular, not all the language allow reflection in the form of a run or eval function. Most notably, even in the most recent work of Davies, it was not known how eval could be included in the language <ref> [6] </ref>. * Cross-Stage Persistence: This is the most distinguishing feature of MetaML, and has been discussed in detail in this paper. To our knowledge, this feature has not been proposed or incorporated into any multi-stage programming language. <p> They presented rules for the well-formedness of the binding-times of expressions in the Facility Example NN [25] GA [11] GB [9] Th [31] HG [12] 2 [7] fl <ref> [6] </ref> M Staging &lt;x.x&gt; 2 2 + 2 + + + + Strong Typing Y 1 N N N Y Y Y Monolithic Variables &lt;x.~(f &lt;x&gt;)&gt; Y Y Y Y Y N Y Y Reflection run or eval N N N Y N Y N Y X-Stage Persistance f.&lt;x.f x&gt; N <p> In their work, Hatcliff & Gluck identified language-independence of the internal representation of "code" as an important characteris tic of any multi-stage language. * 2 : Davies & Pfenning presented the first statically-typed multi-stage language Mini-ML 2 <ref> [6] </ref>. The type system is motivated by constructive modal logic, and a formal proof is presented for the equivalence of binding-time correctness and modal correctness. In contrast, the MetaML type-system was motivated primarily by operational considerations. <p> Also, while Mini-ML 2 can simulate persistence for code values, a stage-zero function, for example, cannot be made persistent. Finally, Mini-ML 2 allows expressing functions like back are not expressible in the language. * fl : The multi-stage language Mini-ML fl <ref> [6] </ref> is motivated by a linear-time constructive modal logic. The language allows staged expressions to contain monolithic free variables. The two constructs of Mini-ML fl ; next and prev, correspond quite closely to MetaML's meta-brackets and escape. The type constructor fl also corresponds (roughly) to code.
Reference: [7] <author> Rowan Davies and Frank Pfenning. </author> <title> A modal analysis of staged computation. </title> <booktitle> In 23rd Annual ACM Symposium on Principles of Programming Languages (POPL'96), </booktitle> <address> St.Petersburg Beach, Florida, </address> <month> January </month> <year> 1996. </year>
Reference-contexts: 1 Introduction Multi-stage languages have recently been proposed as intermediate representations for partial evaluation [12, 9, 10] and runtime code generation <ref> [7] </ref>. These languages generalize the well-known two-level notation of Nielson & Nielson [25] to an arbitrary number of levels. A major thesis of this paper is that multi-stage languages are useful not only as intermediate representations, but also as programming languages in their own right. <p> It provides the following extensions not found in previous work on multi-stage systems: * Four distinct staging annotations, which we believe are necessary and sufficient for all multi-stage programming. (Section 5) These annotations generalize and safely combine those published previously <ref> [25, 12, 7, 6] </ref>. The formal proof of safety is ongoing work. * A type system ensuring the well-formedness of acceptable multi-stage programs. Type checking is done once and for all before the first stage (Section 10.1). * Variables of any stage are available in all future stages. <p> This feature, in a language which also contains run 1 makes MetaML's annotations strictly more expressive than the languages of Nielsen & Nielsen [25, 24], Davies & Pfenning <ref> [7] </ref>, and Davies [6]. <p> This is part of what we mean by having an integrated system. Cross-Stage Persistence can be relaxed by allowing variables to be available at exactly one stage. This seems to have been the case in all multi-stage languages known to us to date <ref> [25, 12, 9, 10, 7, 6] </ref>. The primary difficulty in implementing persistence is the proper hygienic treatment of free variables. We will show how this problem can be solved, thus allowing the user to stage significantly more expressions than was previously possible. <p> Similar type systems have been identified and used by Go-mard and Jones [11], Davies & Pfenning [6] and Davies <ref> [7] </ref>. <p> Similar type systems have been identified and used by Go-mard and Jones [11], Davies & Pfenning [6] and Davies [7]. An important difference between these type systems and the one in Figure 1 is that in all previous statically-typed multi-stage languages <ref> [25, 7, 6] </ref>, only the following mono lithic type rule is used for variables: Var (Monolithic): ( x) = t m n when m = n Whereas we allow the more general condition m n. <p> They presented rules for the well-formedness of the binding-times of expressions in the Facility Example NN [25] GA [11] GB [9] Th [31] HG [12] 2 <ref> [7] </ref> fl [6] M Staging &lt;x.x&gt; 2 2 + 2 + + + + Strong Typing Y 1 N N N Y Y Y Monolithic Variables &lt;x.~(f &lt;x&gt;)&gt; Y Y Y Y Y N Y Y Reflection run or eval N N N Y N Y N Y X-Stage Persistance f.&lt;x.f
Reference: [8] <author> Nachum Dershowitz. </author> <title> Computing with rewrite systems. </title> <journal> Information and Control, </journal> <volume> 65 </volume> <pages> 122-157, </pages> <year> 1985. </year>
Reference: [9] <author> Robert Gluck and Jesper Jtrgensen. </author> <title> Efficient multilevel generating extensions for program specialization. </title> <booktitle> In Programming Languages, Implementations, Logics and Programs (PLILP'95), volume 982 of Lecture Notes in Computer Science. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1995. </year>
Reference-contexts: 1 Introduction Multi-stage languages have recently been proposed as intermediate representations for partial evaluation <ref> [12, 9, 10] </ref> and runtime code generation [7]. These languages generalize the well-known two-level notation of Nielson & Nielson [25] to an arbitrary number of levels. <p> Recently, Gluck and Jtrgensen proposed multi-level BTA and showed that it is an efficient alternative to multiple specialization <ref> [9, 10] </ref>. Their underlying annotated language is closely related to MetaML. 4 Why Explicit Annotations? If BTA performs staging automatically, why should programmers stage programs manually? They shouldn't have to, but there are several important reasons why they may want to: Pragmatic. <p> This is part of what we mean by having an integrated system. Cross-Stage Persistence can be relaxed by allowing variables to be available at exactly one stage. This seems to have been the case in all multi-stage languages known to us to date <ref> [25, 12, 9, 10, 7, 6] </ref>. The primary difficulty in implementing persistence is the proper hygienic treatment of free variables. We will show how this problem can be solved, thus allowing the user to stage significantly more expressions than was previously possible. <p> This is exactly the case when computing the multiplication of 2 matrixes. For each row in the first matrix, the dot product of that row will be taken for each column of the second. This example has appeared in several other works <ref> [9, 20] </ref> and we give our version below. We give three versions of the inner product function. One (iprod) with no staging annotations, the second (iprod2) with two levels of annotations, and the third (iprod3) with two levels of annotations but constructed with the back2 function. <p> They presented rules for the well-formedness of the binding-times of expressions in the Facility Example NN [25] GA [11] GB <ref> [9] </ref> Th [31] HG [12] 2 [7] fl [6] M Staging &lt;x.x&gt; 2 2 + 2 + + + + Strong Typing Y 1 N N N Y Y Y Monolithic Variables &lt;x.~(f &lt;x&gt;)&gt; Y Y Y Y Y N Y Y Reflection run or eval N N N Y N <p> The language allows the treatment of expressions containing monolithic free variables. They use a "const" construct only for constants of ground type. Our treatment of variables in the formal seman tics is inspired by their work. * GB: Gluck and Jtrgensen <ref> [9] </ref> present the novel idea of multi-level BTA, as a very efficient and effective alternate to multiple self-application. An untyped multilevel language based on Scheme is used for the presentation. Our study of MetaML is at a more basic level: MetaML is an abstract calculus.
Reference: [10] <author> Robert Gluck and Jesper Jtrgensen. </author> <title> Fast binding-time analysis for multi-level specialization. </title> <booktitle> In PSI-96: An-drei Ershov Second International Memorial Conference, Perspectives of System Informatics, volume 1181 of Lecture Notes in Computer Science. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1996. </year>
Reference-contexts: 1 Introduction Multi-stage languages have recently been proposed as intermediate representations for partial evaluation <ref> [12, 9, 10] </ref> and runtime code generation [7]. These languages generalize the well-known two-level notation of Nielson & Nielson [25] to an arbitrary number of levels. <p> Recently, Gluck and Jtrgensen proposed multi-level BTA and showed that it is an efficient alternative to multiple specialization <ref> [9, 10] </ref>. Their underlying annotated language is closely related to MetaML. 4 Why Explicit Annotations? If BTA performs staging automatically, why should programmers stage programs manually? They shouldn't have to, but there are several important reasons why they may want to: Pragmatic. <p> This is part of what we mean by having an integrated system. Cross-Stage Persistence can be relaxed by allowing variables to be available at exactly one stage. This seems to have been the case in all multi-stage languages known to us to date <ref> [25, 12, 9, 10, 7, 6] </ref>. The primary difficulty in implementing persistence is the proper hygienic treatment of free variables. We will show how this problem can be solved, thus allowing the user to stage significantly more expressions than was previously possible. <p> While this is very convenient for run-time code generation, it makes the proper specification of MetaML more difficult. For example, we can't use [9]'s "Generic Code Generation functions" to define the language. A second paper by Gluck and Jtrgensen <ref> [10] </ref> demonstrates the impressive efficiency of MBTA, and the use of constraints-solving methods to perform the analysis.
Reference: [11] <author> Carsten K. Gomard and Neil D. Jones. </author> <title> A partial evaluator for untyped lambda calculus. </title> <journal> Journal of Functional Programming, </journal> <volume> 1(1) </volume> <pages> 21-69, </pages> <year> 1991. </year>
Reference-contexts: For the standard part of the language, code (now denoted by h i for conciseness) is a normal type constructor that needs no special treatment and the level n is never changed. Similar type systems have been identified and used by Go-mard and Jones <ref> [11] </ref>, Davies & Pfenning [6] and Davies [7]. <p> They presented rules for the well-formedness of the binding-times of expressions in the Facility Example NN [25] GA <ref> [11] </ref> GB [9] Th [31] HG [12] 2 [7] fl [6] M Staging &lt;x.x&gt; 2 2 + 2 + + + + Strong Typing Y 1 N N N Y Y Y Monolithic Variables &lt;x.~(f &lt;x&gt;)&gt; Y Y Y Y Y N Y Y Reflection run or eval N N N <p> They also sketched guidelines for a multi-stage ("B-level") language. The two-level language is widely used to describe binding-time annotations in the par tial evaluation literature. * GA: Gomard and Jones use a statically-typed two-stage language for partial evaluation of the untyped -calculus <ref> [11] </ref>. The language allows the treatment of expressions containing monolithic free variables. They use a "const" construct only for constants of ground type.
Reference: [12] <author> John Hatcliff and Robert Gluck. </author> <title> Reasoning about hierarchies of online specialization systems. </title> <editor> In Olivier Danvy, Robert Gluck, and Peter Thiemann, editors, </editor> <title> Partial Evaluation, </title> <booktitle> volume 1110 of Lecture Notes in Computer Science, </booktitle> <pages> pages 161-182. </pages> <publisher> Springer-Verlag, </publisher> <year> 1996. </year>
Reference-contexts: 1 Introduction Multi-stage languages have recently been proposed as intermediate representations for partial evaluation <ref> [12, 9, 10] </ref> and runtime code generation [7]. These languages generalize the well-known two-level notation of Nielson & Nielson [25] to an arbitrary number of levels. <p> It provides the following extensions not found in previous work on multi-stage systems: * Four distinct staging annotations, which we believe are necessary and sufficient for all multi-stage programming. (Section 5) These annotations generalize and safely combine those published previously <ref> [25, 12, 7, 6] </ref>. The formal proof of safety is ongoing work. * A type system ensuring the well-formedness of acceptable multi-stage programs. Type checking is done once and for all before the first stage (Section 10.1). * Variables of any stage are available in all future stages. <p> This is part of what we mean by having an integrated system. Cross-Stage Persistence can be relaxed by allowing variables to be available at exactly one stage. This seems to have been the case in all multi-stage languages known to us to date <ref> [25, 12, 9, 10, 7, 6] </ref>. The primary difficulty in implementing persistence is the proper hygienic treatment of free variables. We will show how this problem can be solved, thus allowing the user to stage significantly more expressions than was previously possible. <p> They presented rules for the well-formedness of the binding-times of expressions in the Facility Example NN [25] GA [11] GB [9] Th [31] HG <ref> [12] </ref> 2 [7] fl [6] M Staging &lt;x.x&gt; 2 2 + 2 + + + + Strong Typing Y 1 N N N Y Y Y Monolithic Variables &lt;x.~(f &lt;x&gt;)&gt; Y Y Y Y Y N Y Y Reflection run or eval N N N Y N Y N Y X-Stage <p> Thiemann also deals with the issue of variable-arity functions, which is a practical problem when dealing with eval in Scheme. * HG: Hatcliff & Gluck studied a multi-stage flow-chart language called S-Graph-n, and thoroughly investigated the issues involved in the implementation of such a language <ref> [12] </ref>. The syntax of S-Graph-n explicitly captures all the information necessary for specifying the staging of a computation: each construct is annotated with a number indicating the stage during which it is to be executed, and all variables are annotated with a number indicating the stage of their availability.
Reference: [13] <author> J. Roger Hindley and Jonathan P. Seldin. </author> <title> Introduction to Cobminators and -Calculus. Number 1 in London Mathematical Society Student Texts. </title> <publisher> Cambridge University Press, </publisher> <year> 1986. </year>
Reference-contexts: We introduce MetaML, a statically-typed multi-stage programming language extending Nielson and Nielson's two-level notation to an arbitrary number of stages (similar to their B-level language). MetaML is an extension of a Hindley-Milner polymorphically-typed [22] call-by-value -calculus <ref> [13] </ref> with support for sums, products, recursion, polymor-phism, primitive datatypes and static type-inference.
Reference: [14] <author> Neil D. Jones. </author> <title> Mix ten years later. In Partial Evaluation and Semantics-Based Program Manipulation, New Haven, </title> <journal> Connecticut (Sigplan Notices, </journal> <volume> vol. 26, no. 9, </volume> <month> September </month> <year> 1991), </year> <pages> pages 24-38. </pages> <address> New York: </address> <publisher> ACM, </publisher> <address> New York: </address> <publisher> ACM, </publisher> <month> June </month> <year> 1995. </year>
Reference-contexts: Pedagogical tool. It has been observed that it is sometimes hard for users to understand the workings of partial evaluation systems <ref> [14] </ref>. New users often lack a good mental model of how partial evaluation systems work. Although BTA is an involved process, requiring special expertise, the annotations it produces are relatively simple and easy to understand.
Reference: [15] <author> Neil D. Jones, Carsten K Gomard, and Peter Sestoft. </author> <title> Partial Evaluation and Automatic Program Generation. </title> <publisher> Prentice-Hall, </publisher> <year> 1993. </year>
Reference-contexts: It provides an approach radically different from, and superior to, the classic "programs-as-strings" view that seems to predominate in many ad-hoc software generation systems. MetaML is tightly integrated in this sense. 3 Relationship to Partial Evaluation Today, the most sophisticated automatic staging techniques are found in partial evaluation systems <ref> [15] </ref>. Partial evaluation optimizes a program using a priori information about some of that program's inputs. The goal is to identify and perform as many computations as possible in a program before run-time. O*ine partial evaluation has two distinct steps, binding-time analysis (BTA) and specialization. <p> Having a programming language with explicit staging annotations would help users of partial evaluation understand more of the issues involved in staged computation, and, hopefully, reduce the steep learning curve currently associated with learning to use a partial evaluator effectively <ref> [15] </ref>. Nielson & Niel-son's two-stage notation is the only widely accepted notation for expressing staged computation. But Nielson & Nielson's notation is not widely viewed as a programming language, perhaps because over-bars and under-bars do not appear on the standard keyboard and no implementation of it is in widespread use.
Reference: [16] <author> Simon L. Peyton Jones and John Launchbury. </author> <title> Unboxed values as first class citizens in a non-strict functional language. </title> <booktitle> In Functional Programming and Computer Architecture, </booktitle> <month> September 91. </month>
Reference-contexts: We believe that MetaML can have positive implications for understanding and communicating ideas about multi-stage programs, partial evaluation and the complex process of binding-time analysis in much the same way that the boxed / unboxed (#) distinction provides a language for understanding boxing optimizations as source-to-source transformations <ref> [16] </ref>. 1 An eval-like operator. 2 Why Multi-stage Programs? The concept of a stage arises naturally in a wide variety of situations. For a compiled language, there are two distinct stages: compile-time, and run-time. But three distinct stages appear in the context of program generation: generation, compilation, and execution.
Reference: [17] <author> Richard B. Kieburtz, Francoise Bellegarde, Jef Bell, James Hook, Jeffrey Lewis, Dino Oliva, Tim Sheard, Lisa Walton, and Tong Zhou. </author> <title> Calculating software generators from solution specifications. </title> <booktitle> In TAPSOFT'95, volume 915 of LNCS, </booktitle> <pages> pages 546-560. </pages> <publisher> Springer-Verlag, </publisher> <year> 1995. </year>
Reference-contexts: This capture of a problem family rather than a single problem increases programmer productivity. Program generators let experts capture their knowledge in a clear (and hence reusable) notation that can then be used for synthe-sising the desired software component <ref> [21, 17, 18] </ref>. Reliability and quality. The greatest source of errors in code maintenance is human intervention. When less human intervention is needed to modify a software product, there are proportionately fewer opportunities for error insertion and less rework of code is necessary.
Reference: [18] <author> Richard B. Kieburtz, Laura McKinney, Jeffrey Bell, James Hook, Alex Kotov, Jeffrey Lewis, Dino Oliva, Tim Sheard, Ira Smith, and Lisa Walton. </author> <title> A software engineering experiment in software component generation. </title> <booktitle> In 18th International Conference in Software Engineering, </booktitle> <month> March </month> <year> 1996. </year>
Reference-contexts: This capture of a problem family rather than a single problem increases programmer productivity. Program generators let experts capture their knowledge in a clear (and hence reusable) notation that can then be used for synthe-sising the desired software component <ref> [21, 17, 18] </ref>. Reliability and quality. The greatest source of errors in code maintenance is human intervention. When less human intervention is needed to modify a software product, there are proportionately fewer opportunities for error insertion and less rework of code is necessary.
Reference: [19] <author> John Launchbury and Amr Sabry. </author> <title> Monadic state: Axiomatization and type safety. </title> <booktitle> In Proceedings of the International Conference on Functional Programming, </booktitle> <address> Amsterdam, </address> <month> June </month> <year> 1997. </year>
Reference-contexts: Sheard and Shields [29] investigate a dynamic type systems for multi-staged programs where some type obligations of staged computations can be put off till run-time. The type rule for run presented in this paper is motivated by the type system for runST <ref> [19] </ref>. 13 Conclusion We have described an n-stage multi-stage programming language which we call MetaML. MetaML was designed as a programming language. Our primary purpose was to support the writing of multi-stage programs. Because of this our design choices where different from those of other multistage systems.
Reference: [20] <author> Mark Leone and Peter Lee. </author> <title> Deferred compilation: The automation of run-time code generation. </title> <type> Technical Report CMU-CS-93-225, </type> <institution> Carnegie Mellon University, </institution> <month> Dec. </month> <year> 1993. </year>
Reference-contexts: This is exactly the case when computing the multiplication of 2 matrixes. For each row in the first matrix, the dot product of that row will be taken for each column of the second. This example has appeared in several other works <ref> [9, 20] </ref> and we give our version below. We give three versions of the inner product function. One (iprod) with no staging annotations, the second (iprod2) with two levels of annotations, and the third (iprod3) with two levels of annotations but constructed with the back2 function.
Reference: [21] <author> Michael Lowry, Andrew Philpot, Thomas Pressburger, and Ian Underwood. Amphion: </author> <title> Automatic programming for scientific subroutine libraries. </title> <journal> NASA Science Information Systems Newsletter, </journal> <volume> 31 </volume> <pages> 22-25, </pages> <year> 1994. </year>
Reference-contexts: This capture of a problem family rather than a single problem increases programmer productivity. Program generators let experts capture their knowledge in a clear (and hence reusable) notation that can then be used for synthe-sising the desired software component <ref> [21, 17, 18] </ref>. Reliability and quality. The greatest source of errors in code maintenance is human intervention. When less human intervention is needed to modify a software product, there are proportionately fewer opportunities for error insertion and less rework of code is necessary.
Reference: [22] <author> Robin Milner. </author> <title> A theory of type polymorphism in programming. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 17 </volume> <pages> 348-375, </pages> <year> 1978. </year>
Reference-contexts: We introduce MetaML, a statically-typed multi-stage programming language extending Nielson and Nielson's two-level notation to an arbitrary number of stages (similar to their B-level language). MetaML is an extension of a Hindley-Milner polymorphically-typed <ref> [22] </ref> call-by-value -calculus [13] with support for sums, products, recursion, polymor-phism, primitive datatypes and static type-inference. <p> first stage, while the value of b will be available only in the second stage! Therefore, MetaML's type system was designed to ensure that "well-typed programs won't go wrong", where going wrong now includes the violation of the cross-stage safety condition, as well as the standard no-tions of "going wrong" <ref> [22] </ref> in statically-typed languages. A formal proof of this property is ongoing work.
Reference: [23] <author> Torben . Mogensen. </author> <title> Efficient self-interpretation in lambda calculus. </title> <booktitle> Functional Programming, </booktitle> <volume> 2(3) </volume> <pages> 345-364, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: This isomorphism can also be viewed as a formalization of the intuitive equivalence of a symbolic evaluator <ref> [23] </ref> &lt;A,'c&gt; -&gt; &lt;B,'c&gt; and the syntactic representation of a function &lt;A -&gt; B,'c&gt;. It seems that this isomorphism, which MetaML has allowed us to make concrete, is at the heart of concise reduction systems, such as Danvy's type-directed partial evaluator [4] and its extensions [27].
Reference: [24] <author> F. Nielson. </author> <title> Correctness of code generation from a two-level meta-language. </title> <editor> In B. Robinet and R. Wilhelm, editors, </editor> <booktitle> Proceedings of the European Symposium on Programming (ESOP 86), volume 213 of LNCS, </booktitle> <pages> pages 30-40, </pages> <address> Saarbrucken, FRG, March 1986. </address> <publisher> Springer. </publisher>
Reference-contexts: Type checking is done once and for all before the first stage (Section 10.1). * Variables of any stage are available in all future stages. This feature, in a language which also contains run 1 makes MetaML's annotations strictly more expressive than the languages of Nielsen & Nielsen <ref> [25, 24] </ref>, Davies & Pfenning [7], and Davies [6]. <p> The loss of this ability is the price paid for cross stage persistence. In what follows is an historical perspective of the work highlighted in the table: * NN: Nielson and Nielson pioneered the investigation of staged languages with their two-level functional language <ref> [25, 24] </ref>.
Reference: [25] <author> F. Nielson and H. R. Nielson. </author> <title> Two-Level Functional Languages. </title> <booktitle> Number 34 in Cambridge Tracts in Theoretical Computer Science. </booktitle> <publisher> Cambridge University Press, </publisher> <year> 1992. </year>
Reference-contexts: 1 Introduction Multi-stage languages have recently been proposed as intermediate representations for partial evaluation [12, 9, 10] and runtime code generation [7]. These languages generalize the well-known two-level notation of Nielson & Nielson <ref> [25] </ref> to an arbitrary number of levels. A major thesis of this paper is that multi-stage languages are useful not only as intermediate representations, but also as programming languages in their own right. <p> It provides the following extensions not found in previous work on multi-stage systems: * Four distinct staging annotations, which we believe are necessary and sufficient for all multi-stage programming. (Section 5) These annotations generalize and safely combine those published previously <ref> [25, 12, 7, 6] </ref>. The formal proof of safety is ongoing work. * A type system ensuring the well-formedness of acceptable multi-stage programs. Type checking is done once and for all before the first stage (Section 10.1). * Variables of any stage are available in all future stages. <p> Type checking is done once and for all before the first stage (Section 10.1). * Variables of any stage are available in all future stages. This feature, in a language which also contains run 1 makes MetaML's annotations strictly more expressive than the languages of Nielsen & Nielsen <ref> [25, 24] </ref>, Davies & Pfenning [7], and Davies [6]. <p> It is also easier to verify the correctness of both the generators and the programs they generate, as the issues of representation are hidden away from the programmer. 5 MetaML's Multi-Stage Programming Annotations The two-level notation of Nielson & Nielson <ref> [25] </ref> features two annotations: over-bars to mark computations of the first stage, and under-bars to mark those of the second stage. Although quite powerful, this is only a subset of the annotations needed for pragmatic multi-stage programming. <p> This is part of what we mean by having an integrated system. Cross-Stage Persistence can be relaxed by allowing variables to be available at exactly one stage. This seems to have been the case in all multi-stage languages known to us to date <ref> [25, 12, 9, 10, 7, 6] </ref>. The primary difficulty in implementing persistence is the proper hygienic treatment of free variables. We will show how this problem can be solved, thus allowing the user to stage significantly more expressions than was previously possible. <p> Similar type systems have been identified and used by Go-mard and Jones [11], Davies & Pfenning [6] and Davies [7]. An important difference between these type systems and the one in Figure 1 is that in all previous statically-typed multi-stage languages <ref> [25, 7, 6] </ref>, only the following mono lithic type rule is used for variables: Var (Monolithic): ( x) = t m n when m = n Whereas we allow the more general condition m n. <p> The loss of this ability is the price paid for cross stage persistence. In what follows is an historical perspective of the work highlighted in the table: * NN: Nielson and Nielson pioneered the investigation of staged languages with their two-level functional language <ref> [25, 24] </ref>. <p> In what follows is an historical perspective of the work highlighted in the table: * NN: Nielson and Nielson pioneered the investigation of staged languages with their two-level functional language [25, 24]. They presented rules for the well-formedness of the binding-times of expressions in the Facility Example NN <ref> [25] </ref> GA [11] GB [9] Th [31] HG [12] 2 [7] fl [6] M Staging &lt;x.x&gt; 2 2 + 2 + + + + Strong Typing Y 1 N N N Y Y Y Monolithic Variables &lt;x.~(f &lt;x&gt;)&gt; Y Y Y Y Y N Y Y Reflection run or eval N
Reference: [26] <author> G. D. Plotkin. </author> <title> Call-by-name, call-by-value- and the lambda-calculus. </title> <journal> Theoretical Computer Science, </journal> <volume> 1 </volume> <pages> 125-159, </pages> <year> 1975. </year>
Reference-contexts: For this reason, our implementation performs automatic safe-beta reduction on constants and variables. A beta reduction is safe if it does not change evaluation order, or effect termination properties. There is one safe case which is particularly easy to recognize, namely, Plotkin's fi v rule <ref> [26] </ref>. Whenever an application is constructed where the function part is an explicit lambda abstraction, and the argument part is a value, then that application can be symbolically beta reduced.
Reference: [27] <author> Tim Sheard. </author> <title> A type-directed, on-line partial evaluator for a polymorphic language. </title> <booktitle> In Proceedings of the Symposium on Partial Evaluation and Semantics-Based Program Manipulation, </booktitle> <address> Amsterdam, </address> <month> June </month> <year> 1997. </year>
Reference-contexts: It seems that this isomorphism, which MetaML has allowed us to make concrete, is at the heart of concise reduction systems, such as Danvy's type-directed partial evaluator [4] and its extensions <ref> [27] </ref>. Under MetaML's semantics, we can switch between the two types without needing to worry about substitution or variable capture. This has profound implications for the writing of staged functions.
Reference: [28] <author> Tim Sheard and Neal Nelson. </author> <title> Type safe abstractions using program generators. </title> <type> Technical Report OGI-TR-95-013, </type> <institution> Oregon Graduate Institute of Science and Technology, </institution> <year> 1995. </year>
Reference-contexts: The type constructor fl also corresponds (roughly) to code. Unfortunately, eval is no longer expressible in the language. Sheard has also investigated richer type systems for multi-staged programming. Sheard and Nelson investigated a two-stage language for the purpose of program generation <ref> [28] </ref>. The base language was statically typed, and dependent types were used to generate a wider class of programs than is possible by MetaML restricted to two stages.
Reference: [29] <author> Mark Shields, Tim Sheard, and Simon Peyton Jones. </author> <title> Dynamic typing through staged type inference. </title> <booktitle> In Proceedings of the 25th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, </booktitle> <month> jan </month> <year> 1998. </year> <note> (to appear). </note>
Reference-contexts: Sheard and Nelson investigated a two-stage language for the purpose of program generation [28]. The base language was statically typed, and dependent types were used to generate a wider class of programs than is possible by MetaML restricted to two stages. Sheard and Shields <ref> [29] </ref> investigate a dynamic type systems for multi-staged programs where some type obligations of staged computations can be put off till run-time.
Reference: [30] <author> Brian C. Smith. </author> <title> Reflection and Semantics in a Procedural Language. </title> <type> PhD thesis, </type> <institution> Massachusetts Institute of Technology, </institution> <month> January </month> <year> 1982. </year>
Reference-contexts: It is the only way a computation "frozen" using meta-brackets can be computed (or "forced") in the current stage. The argument to run must be of code type. Having run in the language implies introducing a kind of reflection <ref> [30] </ref>, and allows a future-stage computation to be performed now. To illustrate, consider the expression: let val a = &lt;50-10&gt; in 2+(run a) end This expression has type int and returns the value 42 when computed.
Reference: [31] <author> Peter Thiemann. </author> <title> Towards partial evaluation of full Scheme. </title> <editor> In Gregor Kiczales, editor, </editor> <volume> Reflection 96, </volume> <pages> pages 95-106, </pages> <address> San Francisco, CA, USA, </address> <month> April </month> <year> 1996. </year>
Reference-contexts: They presented rules for the well-formedness of the binding-times of expressions in the Facility Example NN [25] GA [11] GB [9] Th <ref> [31] </ref> HG [12] 2 [7] fl [6] M Staging &lt;x.x&gt; 2 2 + 2 + + + + Strong Typing Y 1 N N N Y Y Y Monolithic Variables &lt;x.~(f &lt;x&gt;)&gt; Y Y Y Y Y N Y Y Reflection run or eval N N N Y N Y N <p> A second paper by Gluck and Jtrgensen [10] demonstrates the impressive efficiency of MBTA, and the use of constraints-solving methods to perform the analysis. The MBTA is type-based, but underlying language is dynamically typed. * Th: Thiemann <ref> [31] </ref> studies a two-level language with eval, apply, and call/cc, in the context of studying the partial evaluation of a greater subset of scheme than was done previously. A BTA based on constraint-solving is presented.
Reference: [32] <author> Wright and Felleisen. </author> <title> A syntactic approach to type soundness. </title> <journal> Information and Computation (formerly Information and Control), </journal> <volume> 115, </volume> <year> 1994. </year>
Reference-contexts: We are currently extending this implementation to include all the features in core-ML. We are also actively pursuing a subject reduction theorem for M . The multi-level syntax makes the syntactic approaches to type soundness <ref> [32] </ref> difficult to apply, because reduction contexts may appear inside lambda expressions at levels greater than zero. We have also found that the non-Hindley-Milner type judgement for the run annotation complicates matters considerably.
References-found: 32

