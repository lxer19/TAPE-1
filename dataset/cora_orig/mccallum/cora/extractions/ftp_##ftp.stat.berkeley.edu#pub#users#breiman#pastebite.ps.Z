URL: ftp://ftp.stat.berkeley.edu/pub/users/breiman/pastebite.ps.Z
Refering-URL: http://www.cs.su.oz.au/~thierry/ckdd.html
Root-URL: 
Email: leo@stat.berkeley.edu  
Title: PASTING BITES TOGETHER FOR PREDICTION IN LARGE DATA SETS AND ONLINE  
Author: Leo Breiman* 
Note: *Partially supported by NSF Grant 1-444063-21445  
Address: Berkeley, CA. 94708  
Affiliation: Statistics Department University of California  
Abstract: The size of many data bases have grown to the point where they cannot fit into the fast memory of even large memory machines, to say nothing of current workstations. If what we want to do is to use these data bases to construct predictions of various characteristics, then since the usual methods require that all data be held in fast memory, various workarounds have to be used. This paper studies one such class of methods which give accuracy comparable to that which could have been obtained if all data could have been held in core and which are computationally fast. The procedure takes small bites of the data, grows a predictor on each small bite and then pastes these predictors together. The methods are also applicable to online learning. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Quinlan, J.R.[1996] Bagging, </author> <title> Boosting, </title> <booktitle> and C4.5, Proceedings of AAAI'96 National Conference, on Artificial Intelligence 10 Tibshirani, </booktitle> <editor> R.[1996] Bias, </editor> <title> Variance, and Prediction Error for Classification Rules, </title> <type> Technical Report, </type> <institution> Statistics Department, University of Toronto Wolpert, </institution> <month> D.H. </month> <title> and Macready, W.G.[1996] An Efficient Method to Estimate Bagging's Generalization Error </title>
References-found: 1

