URL: http://www.cs.berkeley.edu/~vahdat/publications/sigmetrics95/sigmetrics.ps
Refering-URL: http://now.cs.berkeley.edu/Glunix/glunix.html
Root-URL: 
Title: The Interaction of Parallel and Sequential Workloads on a Network of Workstations  
Author: Remzi H. Arpaci, Andrea C. Dusseau, Amin M. Vahdat, Lok T. Liu, Thomas E. Anderson, and David A. Patterson 
Address: Berkeley, CA 94720  
Affiliation: Computer Science Division University of California, Berkeley  
Abstract: This paper examines the plausibility of using a network of workstations (NOW) for a mixture of parallel and sequential jobs. Through simulations, our study examines issues that arise when combining these two workloads on a single platform. Start- ing from a dedicated NOW just for parallel programs, we incrementally relax uniprogramming restrictions until we have a multi-programmed, multi-user NOW for both interactive sequential users and parallel programs. We show that a number of issues associated with the distributed NOW environment (e.g., daemon activity, coscheduling skew) can have a small but noticeable effect on parallel program performance. We also find that efficient migration to idle workstations is necessary to maintain acceptable parallel application performance. Furthermore, we present a methodology for deriving an optimal delay time for recruiting idle machines for use by parallel programs; this recruitment threshold was just 3 minutes for the research cluster we measured. Finally, we quantify the effects of the additional parallel load upon interactive users by keeping track of the potential number of user delays in our simulations. When we limit the maximum number of delays per user, we can still maintain acceptable parallel program performance. In summary, we find that for our workloads a 2:1 rule applies: a NOW cluster of approximately 60 machines can sustain a 32-node parallel workload in addition to the sequential load placed upon it by interactive users. 
Abstract-found: 1
Intro-found: 1
Reference: [Anderson et al. 1993] <author> Anderson, T., Owicki, S., Saxe, J., and Thacker, C. </author> <title> High Speed Switch Scheduling for Local Area Networks. </title> <journal> In ACM Transactions on Computer Systems, </journal> <pages> pp. 319-352, </pages> <year> 1993. </year>
Reference-contexts: In the last few years massively parallel processors (MPPs) and NOWs have become more alike. MPPs are using the same processors, memory, and even operating systems found in workstations, while NOWs have started to use switches in their local-area networks (LANs) similar to MPP-style networks <ref> [Anderson et al. 1993, Boden et al. 1995] </ref>. Thus, MPPs are trying to take advantage of the workstation price- performance curve, while the disparity between LAN and MPP network performance is being addressed by recent LAN developments. <p> For this reason, NOWs have historically only run coarse-grained parallel programs. The recent introduction of switch-based LANs, such as ATM [Biagioni et al. 1993], switched Ethernet, AN- 2 <ref> [Anderson et al. 1993] </ref>, and Myrinet [Boden et al. 1995], increases the feasibility of running general-purpose parallel applications on NOWs. For example, the delivered bandwidth on today's SynOptics, Fore, and Cisco ATM equipment is comparable to the delivered 10 MB/s bandwidth of Thinking Machines CM-5.
Reference: [Ashok & Zahorjan 1992] <author> Ashok, I. and Zahorjan, J. </author> <title> Scheduling a Mixed Interactive and Batch Workload on a Parallel, Shared-Memory Supercomputer. </title> <booktitle> In Proceedings of Supercomputing '92, </booktitle> <pages> pp. 616-625, </pages> <month> November </month> <year> 1992. </year>
Reference-contexts: The idea of recruiting remote memory as a fast backing store could also be of help [Dahlin et al. 1994, Felten & Zahorjan 1991]. Having a fixed-memory partition between parallel and sequential jobs <ref> [Ashok & Zahorjan 1992] </ref> may also help, but this may not be possible without kernel modifications. <p> Finally, we do not assume a priori knowledge of the available parallelism in the programs we schedule. The impact of memory management has also been scrutinized in a multiprocessor environment [Chandra et al. 1994]. Ashok and Zahorjan <ref> [Ashok & Zahorjan 1992] </ref> studied mixing an interactive and batch workload onto a parallel, shared- memory supercomputer. They found that partitioning memory statically between batch and interactive jobs performs better than policies that can vary dynamically. Our study differs in that batch and interactive jobs never share the same node.
Reference: [Biagioni et al. 1993] <author> Biagioni, E., Cooper, E., and Sansom, R. </author> <title> Designing a Practical ATM LAN. </title> <journal> IEEE Network, </journal> <volume> 7(2) </volume> <pages> 32-39, </pages> <month> March </month> <year> 1993. </year>
Reference-contexts: For this reason, NOWs have historically only run coarse-grained parallel programs. The recent introduction of switch-based LANs, such as ATM <ref> [Biagioni et al. 1993] </ref>, switched Ethernet, AN- 2 [Anderson et al. 1993], and Myrinet [Boden et al. 1995], increases the feasibility of running general-purpose parallel applications on NOWs.
Reference: [Blelloch et al. 1991] <author> Blelloch, G., Leiserson, C., </author> <title> and Maggs, </title> <publisher> B. </publisher>
Reference-contexts: Column is an implementation of the column-sort algorithm [Leighton 1985]; a description of the implementation can be found in [Culler et al. 1994]. The program em3d simulates the propagation of electro-magnetic waves through objects in three dimensions [Culler et al. 1993a]. A version of the sample sort algorithm <ref> [Blelloch et al. 1991] </ref> is implemented by sample. Finally, connect uses a randomized algorithm to find the connected components of an arbitrary graph [Krishnamurthy et al. 1994]. These benchmarks represent a cross-section of parallel applications with different message sizes, and with different communication and synchronization frequencies.
References-found: 4

