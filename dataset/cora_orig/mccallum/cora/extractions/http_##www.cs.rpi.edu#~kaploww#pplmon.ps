URL: http://www.cs.rpi.edu/~kaploww/pplmon.ps
Refering-URL: http://www.cs.rpi.edu/~kaploww/research.html
Root-URL: http://www.cs.rpi.edu
Title: Program Optimization Based on Compile-Time Cache Performance Prediction  
Author: Wesley K. Kaplow Boleslaw K. Szymanski 
Keyword: Cache Simulation, Performance Prediction, Loop Optimization  
Address: Troy, N.Y. 12180-3590, USA  
Affiliation: Department of Computer Science Rensselaer Polytechnic Institute,  
Note: Parallel Processing Letters c World Scientific Publishing Company  Received (received date) Revised (revised date) Communicated by (Name of Editor)  
Abstract: We present a novel, compile-time method for determining the cache performance of the loop nests in a program. The cache-miss rates are produced by applying the program's reference string of a loop nest, determined during compilation, to an architecturally parameterized cache simulator. The obtained cache-miss rates correlate well with the performance of the loop nests on actual target machines. We describe also a heuristic that uses this method for compile-time optimization of loop ranges in iteration-space blocking. The results of the loop program optimizations are presented for different processor architectures, namely IBM SP1 RS/6000, the SuperSPARC, and the Intel i860. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> M. S. Lam, E. E. Rotherberg, and M. Wolf, </author> <title> The Cache Performance and Optimizations of Blocked Algorithms, </title> <booktitle> in ACM Architectural Support for Programming Languages and Operating Systems, </booktitle> <address> Santa Clara, CA, </address> <month> April, </month> <year> 1991, </year> <pages> 63-74. </pages>
Reference-contexts: The function G (v s ; i) defined for any v 2 R (p) returns the statement pointed out by the first i elements of v s : G (v s ; i) = S (p; v s <ref> [1] </ref>) if i = 1 S (G (v s ; i 1); v s [i]) otherwise statements at different levels. The last element of v s refers to a variable reference. <p> We show that the heuritic can be used to quickly determine the iteration-space blocking factor. Some results for loop interchange are given in Table 1 and Figure 6 (see also [11]). Blocking or tiling <ref> [1] </ref> is used to increase the locality of data references during the loop execution by adding additional levels of loops so that inner loops iterate over blocks of the original iteration space. The results of this optimization are shown in Figure 7.
Reference: 2. <author> S. Carr, K. S. McKinley, and C. W. Tseng, </author> <title> Compiler Optimizations for Improving Data Locality, </title> <booktitle> in ACM Architectural Support for Programming Languages and Operating Systems, </booktitle> <address> San Jose, CA, </address> <month> October, </month> <year> 1994, </year> <pages> 252-262. </pages>
Reference: 3. <author> D. Gannon, W. Jalby, and K. Gallican, </author> <title> Strategies for Cache and Local Memory Management by Global Program Transformation, </title> <journal> Journal of Parallel and Distributed Computing, </journal> <month> October, </month> <year> 1988. </year>
Reference: 4. <author> A. Gerasoulis and T. Yang, </author> <title> On the Granularity and Clustering of Directed Acyclic Task Graphs, </title> <booktitle> IEEE Transaction on Parallel and Distributed Systems 4(6)(1993) 686-701. </booktitle>
Reference-contexts: The processor performance on a code section is a key parameter in parallel task partitioning and scheduling (c.f., [4,5]). For example, in <ref> [4] </ref> the task granularity, defined as a function of the ratio of task communication to its computation, is the basis for determining optimal parallel schedules. In this paper we describe a compile-time method for determining cache performance on a generalized loop range.
Reference: 5. <author> A. Gerasoulis and T. Yang, </author> <title> Comparison of Clustering Heuristics for Scheduling Directed Acyclic Graphs on Multiprocessors, </title> <journal> Journal of Parallel and Distributed Computing 16(1992) 276-291. </journal>
Reference-contexts: When the code is blocked, the reference pattern generated by the blocked traversal will not follow a traversal of a contiguously allocated array. Static prediction methods, such as proposed by <ref> [5] </ref> or [7], do not take this into consideration, and therefore they may not correctly choose the proper blocking factor for a loop.
Reference: 6. <author> D. A. Paterson and J. L. Hennessy, </author> <title> Computer Organization and Design: The Hardware/Software Interface, </title> <publisher> (Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1993). </year>
Reference-contexts: The relationships among these classes are shown in Figure 1. Exact Methods generate the reference string by creating a synthetic mix or abbreviated form of the application code, executing it, and running it through the real cache (cf. <ref> [6] </ref>). Although actions of the cache over the string are very fast (they are taken by the actual hardware), the method requires repetitive compilations and executions of the application codes; therefore it is too time-consuming to be used at compile-time. <p> The successor of v therefore points to first variable of the first statement of the I 1 loop, with I 1 incremented by one. 2.2. Cache Model As defined in <ref> [6] </ref>, a cache is the first level of memory closest to a processor. Cache is a fast memory that at any execution instance represents some subset of the address space of a processor.
Reference: 7. <author> T. Fahringer, </author> <title> Automatic Cache Performance Prediction in a Parallelizing Compiler, </title> <booktitle> in Proceedings of AICA, </booktitle> <address> Lecee, Italy, </address> <month> September, </month> <year> 1993. </year>
Reference-contexts: Analytical models approximate both the reference string and the actions of the cache. Instead of looking at individual references, these methods determine the number of distinct cache lines referenced in a loop nest based on the number of reference classes [1,2] or array classes <ref> [7] </ref>. This number combined with the number of cache lines and loop ranges yields a crude approximation of cache misses. The method cannot accurately account for effects of different replacement algorithms, context switches, set-associative cache mappings, or translation of virtual to physical addresses. <p> The upper bound of i h is estimated by an analytical method similar to the one presented in <ref> [7] </ref> using the formula: i h = N fi K fi L i=1 size (i) where n acs is the number of array access classes (see [7] for their definition) in the innermost loop, size (i) is the data size of references in the i th reference class in bytes, and <p> The upper bound of i h is estimated by an analytical method similar to the one presented in <ref> [7] </ref> using the formula: i h = N fi K fi L i=1 size (i) where n acs is the number of array access classes (see [7] for their definition) in the innermost loop, size (i) is the data size of references in the i th reference class in bytes, and K; L; N are parameters of the cache described in the previous section. <p> When the code is blocked, the reference pattern generated by the blocked traversal will not follow a traversal of a contiguously allocated array. Static prediction methods, such as proposed by [5] or <ref> [7] </ref>, do not take this into consideration, and therefore they may not correctly choose the proper blocking factor for a loop.
Reference: 8. <author> A.J. Goldberg and J. Hennessy, </author> <title> Performance Debugging Shared-Memory Multiprocessor Programs with Mtool, </title> <booktitle> in Proceedings Supercomputing 91, </booktitle> <publisher> (IEEE Computer Science Press, Los Alamitos, </publisher> <address> CA) 481-490. </address>
Reference: 9. <author> A. Gupta, M. Martonosi, and T. Anderson, MemSpy: </author> <title> Analyzing Memory System Bottlenecks in Programs, Performance Analysis Review, </title> <publisher> 20(1)(1992). </publisher>
Reference: 10. <author> A. R. Lebeck and D. Wood, </author> <title> Cache Profiling and the SPEC Benchmarks: A Case Study, </title> <booktitle> IEEE Computer, </booktitle> <month> October, </month> <year> 1994. </year>
Reference-contexts: Context-switch effects can be approximated by the periodic clearing of the current contents of the cache. Instead of physical addresses, both models use compile-time addresses that are changed during loading. However, as shown in <ref> [10] </ref>, the probability of additional cache misses caused by loading is low, so the effect of this approximation on the miss-rates is negligible.
Reference: 11. <author> W. Kaplow, W. Maniatty, B. Szymanski, </author> <title> Impact of Memory Hierarchy on Program Partitioning and Scheduling, </title> <booktitle> in Proceedings of the 28 th Hawaii International Conference on System Sciences, </booktitle> <address> Maui, Hawaii, </address> <month> January, </month> <year> 1995. </year> <month> 12 </month>
Reference-contexts: We show that the heuritic can be used to quickly determine the iteration-space blocking factor. Some results for loop interchange are given in Table 1 and Figure 6 (see also <ref> [11] </ref>). Blocking or tiling [1] is used to increase the locality of data references during the loop execution by adding additional levels of loops so that inner loops iterate over blocks of the original iteration space. The results of this optimization are shown in Figure 7.
References-found: 11

