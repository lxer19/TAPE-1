URL: http://www.math.tau.ac.il/~mansour/papers/96stoc.ps.gz
Refering-URL: 
Root-URL: 
Email: mkearns@research.att.com  mansour@math.tau.ac.il  
Title: On the Boosting Ability of Top-Down Decision Tree Learning Algorithms is obtained. The differing bounds
Author: Michael Kearns Yishay Mansour 
Note: much stronger bound of (1=*) O(1= 2 (which is polynomial in 1=*)  The primary contribution of this work is in  
Affiliation: AT&T Research  Tel-Aviv University  
Abstract: We analyze the performance of top-down algorithms for decision tree learning, such as those employed by the widely used C4.5 and CART software packages. Our main result is a proof that such algorithms are boosting algorithms. By this we mean that if the functions that label the internal nodes of the decision tree can weakly approximate the unknown target function, then the top-down algorithms we study will amplify this weak advantage to build a tree achieving any desired level of accuracy. The bounds we obtain for this amplification show an interesting dependence on the splitting criterion used by the top-down algorithm. More precisely, if the functions used to label the internal nodes have error 1=2 fl as approximations to the target function, then for the splitting criteria used by CART and C4.5, trees of size (1=*) O(1=fl 2 * 2 ) and (1=*) O(log(1=*)=fl 2 ) (respectively) suffice to drive the error below *. Thus (for example), small constant advantage over random guessing is amplified to constant error with trees of constant size. For a new splitting criterion suggested by our analysis, the 
Abstract-found: 1
Intro-found: 1
Reference: [1] <editor> In Machine Learning: </editor> <booktitle> Proceedings of the International Con ference. </booktitle> <publisher> Morgan Kaufmann, </publisher> <pages> 1982-1995. </pages>
Reference-contexts: See Figure 4 for a diagram summarizing the split parameters. We are now in position to make some simple but central insights regarding how the split at ` reduces the quantity G t . Note that since q = (1t )p+t r and t 2 <ref> [0; 1] </ref>, one of p and r is less than or equal to q and the other is greater than or equal to q. Without loss of generality, let p q r. Now before the split, the contribution of the leaf ` to G t was w G (q). <p> Towards this goal, we first fix t and ffi and lower bound D G (q; t; ffi) by an algebraic expression of its parameters. Lemma 5.2 Let G (q) be one of 4q (1 q); H (q) and 2 p Then for any fixed values for t; ffi 2 <ref> [0; 1] </ref>, D G (q; t; ffi) 2 00 t (1 t )(1 2t )ffi 3 G (q): Proof: With t and ffi fixed, we perform a Taylor expansion of G (q) at q, and replace the occurrences of G (q), G (q t ffi) and G (q + (1 t <p> We begin by substituting for ffi under the given constraint t (1 t )ffi flq (1 q). It is clear from Equation 11 and Figure 5 that for any fixed values q; t 2 <ref> [0; 1] </ref>, D G (q; t; ffi) is minimized by choosing ffi as small as possible. <p> This will allow us to replace occurrences of t with constant values. Lemma 5.3 Let G (q) be one of 4q (1 q); H (q) and 2 p Let fl 2 <ref> [0; 1] </ref> be any fixed value, and let D G (q; t ) be as defined in Equation 16. Then for any fixed q 2 [0; 1], D G (q; t ) is minimized by a value of t falling in the interval [0:4; 0:6]. <p> Lemma 5.3 Let G (q) be one of 4q (1 q); H (q) and 2 p Let fl 2 <ref> [0; 1] </ref> be any fixed value, and let D G (q; t ) be as defined in Equation 16. Then for any fixed q 2 [0; 1], D G (q; t ) is minimized by a value of t falling in the interval [0:4; 0:6]. <p> We would like to show that for some particular choices for G, any minimizing value of t is always (for all q; 2 <ref> [0; 1] </ref>, fl 2 (0; 1=2], and ffi = flq (1 q)=(t (1 t )) bounded away from 0 and 1. For the choice G (q) = 2 p can be seen in Figures 8 and 9 that for all q; 2 [0; 1], if t 0:4 then @D G (q; <p> of t is always (for all q; 2 <ref> [0; 1] </ref>, fl 2 (0; 1=2], and ffi = flq (1 q)=(t (1 t )) bounded away from 0 and 1. For the choice G (q) = 2 p can be seen in Figures 8 and 9 that for all q; 2 [0; 1], if t 0:4 then @D G (q; t )=@t 0, and if t 0:6 then @D G (q; t )=@t 0. (Formal proof for this choice of G is given in Lemma 5.8 of the Appendix, and for the other choices for G in the full version of the <p> We now apply these general results to obtain lower bounds for specific choices of G (). Lemma 5.4 Under the constraint t (1 t )ffi flq (1 q) given by Lemma 5.1, if G (q) = 4q (1 q) then for any q 2 <ref> [0; 1] </ref> D G (q; t; ffi) 16fl (q (1 q)) : (18) Proof: Here we have derivatives G 00 (q) = 8 and G 000 (q) = 0. <p> t ) 16fl (q (1 q)) : (20) Here we have used the fact that t (1 t ) 1=4. 2 (Lemma 5.4) Lemma 5.5 Under the constraint t (1 t )ffi flq (1 q) given by Lemma 5.1, if G (q) = H (q) then for any q 2 <ref> [0; 1] </ref> D G (q; t; ffi) fl q (1 q): (21) Proof: Using the fact that for G (q) = H (q) we have derivatives G 00 (q) = (1=(1 q) + 1=q) and G 000 (q) = (1=(1 q) 2 1=q 2 ), application of Lemma 5.2 yields D <p> which states that the minimizing value of t lies in the interval [0:4; 0:6] for all q. 2 (Lemma 5.5) Lemma 5.6 Under the constraint t (1 t )ffi flq (1 q) given by Lemma 5.1, if G (q) = 2 p q (1 q) then for any q 2 <ref> [0; 1] </ref> D G (q; t; ffi) 2 2 3=2 Proof: Here we have derivatives G (q) = 2 (q (1 q)) 3=2 (q (1 q)) 1=2 (28) G (q) = 4 (q (1 q)) 5=2 + (q (1 q)) 3=2 : (29) Plugging these derivatives into Lemma 5.2 yields D <p> We will now see the strong effect that these drops have on our final bounds, beginning with the choice G (q) = 2 p Theorem 5.7 Let G (q) = 2 p defined in Equations 1 and 2. Then under the Weak Hypothesis Assumption, for any * 2 <ref> [0; 1] </ref>, to obtain * t * it suffices to make t 1 32=fl 2 splits. Proof: By the definition of G t , there must exist a leaf ` such that 2w (`)(q (`)(1 q (`))) 1=2 G t =t.
Reference: [2] <author> A. Blum, M. Furst, J. Jackson, M. Kearns, Y. Mansour, and S. Rudich. </author> <title> Weakly learning DNF and characterizing statistical query learning using Fourier analysis. </title> <booktitle> In Proceedings of the 26th ACM Symposium on the Theory of Computing. </booktitle> <publisher> ACM Press, </publisher> <address> New York, NY, </address> <year> 1994. </year>
Reference: [3] <author> L. Breiman, J. H. Friedman, R. A. Olshen, and C. J. Stone. </author> <title> Classification and Regression Trees. </title> <booktitle> Wadsworth International Group, </booktitle> <year> 1984. </year>
Reference: [4] <author> N. Bshouty and Y. Mansour. </author> <title> Simple learning algorithms for decision trees and multivariate polynomials. </title> <booktitle> In Proceedings of the 36th IEEE Symposium on the Foundations of Computer Science, </booktitle> <pages> pages 304-311. </pages> <publisher> IEEE Computer Society Press, Los Alamitos, </publisher> <address> CA, </address> <year> 1995. </year>
Reference: [5] <author> N. H. Bshouty. </author> <title> Exact learning via the monotone theory. </title> <booktitle> In Proceedings of the 34th IEEE Symposium on the Foundations of Computer Science, </booktitle> <pages> pages 302-311. </pages> <publisher> IEEE Computer Society Press, Los Alamitos, </publisher> <address> CA, </address> <year> 1993. </year>
Reference: [6] <author> W. Buntine and T. Niblett. </author> <title> A further comparison of splitting rules for decision-tree induction. </title> <journal> Machine Learning, </journal> <volume> 8 </volume> <pages> 75-86, </pages> <year> 1992. </year>
Reference: [7] <author> T. Dietterich, M. Kearns, and Y. Mansour. </author> <title> Applying the weak learning framework to understand and improve C4.5. </title> <type> Unpublished manuscript, </type> <year> 1996. </year>
Reference-contexts: It is worth noting here that despite the fact that existing boosting algorithms enjoy significantly better bounds than those given here for top-down heuristics, the algorithms are actually fairly comparable in practice <ref> [8, 7] </ref>. <p> recent experimental paper investigating some of the theoretical issues raised here, we argue that this disparity between theory and experiment can largely be explained by regarding the advantage fl as an algorithm-dependent quantity that varies according to the relative difficulty of the filtered distributions generated by the algorithm in question <ref> [7] </ref>. It is reasonable to ask whether some assumption other than the Weak Hypothesis Assumption might permit even more favorable analyses of top-down decision tree algorithms.
Reference: [8] <author> Y. Freund and R. Schapire. </author> <title> Some experiments with a new boosting algorithm. </title> <type> Unpublished manuscript, </type> <year> 1996. </year>
Reference-contexts: It is worth noting here that despite the fact that existing boosting algorithms enjoy significantly better bounds than those given here for top-down heuristics, the algorithms are actually fairly comparable in practice <ref> [8, 7] </ref>.
Reference: [9] <author> Yoav Freund. </author> <title> Boosting a weak learning algorithm by major ity. </title> <journal> Information and Computation, </journal> <volume> 121(2) </volume> <pages> 256-285, </pages> <month> September </month> <year> 1995. </year>
Reference-contexts: several previous papers have proposed boosting algorithms that combine many different functions from F , each with a small predictive advantage over random guessing on a different filtered distribution, to obtain a single hybrid function whose generalization error on the target distribution P is less than any desired value * <ref> [16, 9, 10] </ref>. The central question examined for such algorithms is: As a function of the advantage fl and the desired error *, how many functions must be combined, and how many random examples drawn? Several boosting algorithms enjoy very strong upper bounds on these quantities [16, 9, 10]: the number <p> any desired value * <ref> [16, 9, 10] </ref>. The central question examined for such algorithms is: As a function of the advantage fl and the desired error *, how many functions must be combined, and how many random examples drawn? Several boosting algorithms enjoy very strong upper bounds on these quantities [16, 9, 10]: the number of functions that must be combined is polynomial in 1=fl and log (1=*), and the number of examples required is polynomial in 1=fl and 1=*. <p> We will show that for appropriately chosen G, algorithm TopDown F;G (t) in fact achieves tree size bounds that are exponential in 1=fl but polynomial in 1=* 3 . In contrast, the recent boosting methods specifically designed for the weak learning model <ref> [9, 10] </ref> represent their hypothesis as a thresholded linear combination of functions from F , a choice that is obviously well-suited to the Weak Hypothesis Assumption in light of the remarks above. <p> Thus, the resulting class of filtered distributions is in some sense simpler than those generated by other boosting algorithms <ref> [16, 9, 10] </ref>. Our goal now is to obtain for each G a lower bound on the local drop G (q) (1 t )G (p) t G (r) to G t under the condition t (1 t )ffi flq (1 q) given by Lemma 5.1.
Reference: [10] <author> Yoav Freund and Robert E. Schapire. </author> <title> A decision-theoretic gen eralization of on-line learning and an application to boosting. </title> <booktitle> In Second European Conference on Computational Learning Theory, </booktitle> <pages> pages 23-37. </pages> <publisher> Springer-Verlag, </publisher> <year> 1995. </year>
Reference-contexts: several previous papers have proposed boosting algorithms that combine many different functions from F , each with a small predictive advantage over random guessing on a different filtered distribution, to obtain a single hybrid function whose generalization error on the target distribution P is less than any desired value * <ref> [16, 9, 10] </ref>. The central question examined for such algorithms is: As a function of the advantage fl and the desired error *, how many functions must be combined, and how many random examples drawn? Several boosting algorithms enjoy very strong upper bounds on these quantities [16, 9, 10]: the number <p> any desired value * <ref> [16, 9, 10] </ref>. The central question examined for such algorithms is: As a function of the advantage fl and the desired error *, how many functions must be combined, and how many random examples drawn? Several boosting algorithms enjoy very strong upper bounds on these quantities [16, 9, 10]: the number of functions that must be combined is polynomial in 1=fl and log (1=*), and the number of examples required is polynomial in 1=fl and 1=*. <p> We will show that for appropriately chosen G, algorithm TopDown F;G (t) in fact achieves tree size bounds that are exponential in 1=fl but polynomial in 1=* 3 . In contrast, the recent boosting methods specifically designed for the weak learning model <ref> [9, 10] </ref> represent their hypothesis as a thresholded linear combination of functions from F , a choice that is obviously well-suited to the Weak Hypothesis Assumption in light of the remarks above. <p> Thus, the resulting class of filtered distributions is in some sense simpler than those generated by other boosting algorithms <ref> [16, 9, 10] </ref>. Our goal now is to obtain for each G a lower bound on the local drop G (q) (1 t )G (p) t G (r) to G t under the condition t (1 t )ffi flq (1 q) given by Lemma 5.1.
Reference: [11] <author> J. Jackson. </author> <title> An efficient membership query algorithm for learn ing DNF with respect to the uniform distribution. </title> <booktitle> In Proceedings of the 35th IEEE Symposium on the Foundations of Computer Science. </booktitle> <publisher> IEEE Computer Society Press, Los Alamitos, </publisher> <address> CA, </address> <year> 1994. </year>
Reference: [12] <author> M. Kearns and L. G. Valiant. </author> <title> Cryptographic limitations on learning boolean formulae and finite automata. </title> <journal> Journal of the ACM, </journal> <volume> 41(1) </volume> <pages> 67-95, </pages> <year> 1994. </year>
Reference: [13] <author> E. Kushilevitz and Y. Mansour. </author> <title> Learning decision trees using the Fourier spectrum. </title> <booktitle> In Proc. of the 23rd Symposium on Theory of Computing, </booktitle> <pages> pages 455-464. </pages> <publisher> ACM Press, </publisher> <address> New York, NY, </address> <year> 1991. </year>
Reference: [14] <author> J. Mingers. </author> <title> An empirical comparison of selection measures for decision-tree induction. </title> <journal> Machine Learning, </journal> <volume> 3 </volume> <pages> 319-342, </pages> <year> 1989. </year>
Reference: [15] <author> J.R. Quinlan. C4.5: </author> <title> Programs for Machine Learning. </title> <publisher> Morgan Kaufmann, </publisher> <year> 1993. </year>
Reference: [16] <author> R. E. Schapire. </author> <title> The strength of weak learnability. </title> <journal> Machine Learning, </journal> <volume> 5(2) </volume> <pages> 197-227, </pages> <year> 1990. </year>
Reference-contexts: several previous papers have proposed boosting algorithms that combine many different functions from F , each with a small predictive advantage over random guessing on a different filtered distribution, to obtain a single hybrid function whose generalization error on the target distribution P is less than any desired value * <ref> [16, 9, 10] </ref>. The central question examined for such algorithms is: As a function of the advantage fl and the desired error *, how many functions must be combined, and how many random examples drawn? Several boosting algorithms enjoy very strong upper bounds on these quantities [16, 9, 10]: the number <p> any desired value * <ref> [16, 9, 10] </ref>. The central question examined for such algorithms is: As a function of the advantage fl and the desired error *, how many functions must be combined, and how many random examples drawn? Several boosting algorithms enjoy very strong upper bounds on these quantities [16, 9, 10]: the number of functions that must be combined is polynomial in 1=fl and log (1=*), and the number of examples required is polynomial in 1=fl and 1=*. <p> Thus, the resulting class of filtered distributions is in some sense simpler than those generated by other boosting algorithms <ref> [16, 9, 10] </ref>. Our goal now is to obtain for each G a lower bound on the local drop G (q) (1 t )G (p) t G (r) to G t under the condition t (1 t )ffi flq (1 q) given by Lemma 5.1.
Reference: [17] <author> L. G. Valiant. </author> <title> A theory of the learnable. </title> <journal> Communications of the ACM, </journal> <volume> 27(11) </volume> <pages> 1134-1142, </pages> <year> 1984. </year>
References-found: 17

