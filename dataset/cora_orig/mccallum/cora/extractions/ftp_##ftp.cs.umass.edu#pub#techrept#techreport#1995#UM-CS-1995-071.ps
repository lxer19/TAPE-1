URL: ftp://ftp.cs.umass.edu/pub/techrept/techreport/1995/UM-CS-1995-071.ps
Refering-URL: http://dis.cs.umass.edu/research/negotiation.html
Root-URL: 
Title: Coalition Formation among Bounded Rational Agents  
Author: Tuomas W. Sandholm and Victor R. Lesser 
Abstract: Computer Science Department University of Massachusetts at Amherst CMPSCI Technical Report 95-71 September 7, 1995 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. Aumann. </author> <title> Acceptable points in general cooperative n-person games. volume IV of Contributions to the Theory of Games. </title> <publisher> Princeton University Press, </publisher> <year> 1959. </year>
Reference-contexts: Often this solution concept is too weak because subgroups of agents can deviate in a coordinated manner. The Strong Nash equilibrium <ref> [1] </ref> is a solution concept that guarantees more stability in the sense that it requires that there is no subgroup that can deviate in a manner that increases the payoff of all of its members given that nonmembers do not deviate from the original solution. <p> Again, other solution concepts are necessary, e.g. the Nash equilibrium or some of its refinements. This is part of our current research. 6 Related DAI research on collusion Coalition formation has been widely studied in game theory <ref> [12, 2, 3, 1, 27, 18] </ref>; only the most relevant concepts were presented here. This section compares our work to other recent DAI research on coalition formation. Zlotkin and Rosenschein [30] analyze rational agents that cannot make side payments, while our agents do.
Reference: [2] <author> B. D. Bernheim, B. Peleg, and M. D. Whinston. </author> <title> Coalition-proof nash equilibria: 1. concepts. </title> <journal> Journal of Economic Theory, </journal> <volume> 42(1) </volume> <pages> 1-12, </pages> <month> June </month> <year> 1987. </year>
Reference-contexts: The Strong Nash equilibrium is often too strong a solution concept because in many games no such equilibria exist. Recently, the Coalition-Proof Nash equilibrium <ref> [2, 3] </ref> has been suggested to remedy this problem. This solution concept requires that there is no subgroup that can make a mutually beneficial deviation (keeping the strategies of nonmembers fixed) in a way that the deviation itself is stable according to the same criterion. <p> Again, other solution concepts are necessary, e.g. the Nash equilibrium or some of its refinements. This is part of our current research. 6 Related DAI research on collusion Coalition formation has been widely studied in game theory <ref> [12, 2, 3, 1, 27, 18] </ref>; only the most relevant concepts were presented here. This section compares our work to other recent DAI research on coalition formation. Zlotkin and Rosenschein [30] analyze rational agents that cannot make side payments, while our agents do.
Reference: [3] <author> B. D. Bernheim and M. D. Whinston. </author> <title> Coalition-proof nash equilibria: 2. </title> <journal> applications. Journal of Economic Theory, </journal> <volume> 42(1) </volume> <pages> 13-29, </pages> <month> June </month> <year> 1987. </year>
Reference-contexts: The Strong Nash equilibrium is often too strong a solution concept because in many games no such equilibria exist. Recently, the Coalition-Proof Nash equilibrium <ref> [2, 3] </ref> has been suggested to remedy this problem. This solution concept requires that there is no subgroup that can make a mutually beneficial deviation (keeping the strategies of nonmembers fixed) in a way that the deviation itself is stable according to the same criterion. <p> Again, other solution concepts are necessary, e.g. the Nash equilibrium or some of its refinements. This is part of our current research. 6 Related DAI research on collusion Coalition formation has been widely studied in game theory <ref> [12, 2, 3, 1, 27, 18] </ref>; only the most relevant concepts were presented here. This section compares our work to other recent DAI research on coalition formation. Zlotkin and Rosenschein [30] analyze rational agents that cannot make side payments, while our agents do.
Reference: [4] <author> M. Boddy and T. Dean. </author> <title> Solving time-dependent planning problems. </title> <booktitle> In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 979-984, </pages> <address> Detroit, MI, </address> <month> Aug. </month> <year> 1989. </year>
Reference-contexts: The design-to-time framework is used instead of the anytime framework <ref> [21, 6, 4, 11, 29] </ref> because to devise a theory of self-interested agents, the possibility that they design their algorithms to time has to be accounted for.
Reference: [5] <author> A. Charnes and K. O. Kortanek. </author> <title> On balanced sets, cores, and linear programming. </title> <type> Technical Report 12, </type> <institution> Cornell Univ., Dept. of Industrial Eng. and Operations Res., </institution> <address> Ithaca, NY, </address> <year> 1966. </year>
Reference-contexts: The condition C 6= ; can be converted into necessary and sufficient conditions on the v R S 's in games where the grand coalition maximizes social welfare <ref> [24, 5] </ref>. We convert the condition BRC (c comp ) 6= ; into conditions on the v S (c comp )'s analogously. Let B 1 ; :::; B p be distinct, nonempty, proper subsets of A. <p> Proof. Shapley [24] proved the following fact (his Theorem 3) for rational agents. In a superadditive game, C 6= ; iff for every proper minimal balanced set B = fB 1 ; :::; B p g; j=1 j v R A . Charnes and Kortanek <ref> [5] </ref> proved that this set of inequalities is minimal. Theorem 3.3 follows by analogy. 2 Example.
Reference: [6] <author> T. Dean and M. Boddy. </author> <title> An analysis of time-dependent planning. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pages 49-54, </pages> <address> St. Paul, MN, </address> <month> Aug. </month> <year> 1988. </year>
Reference-contexts: The design-to-time framework is used instead of the anytime framework <ref> [21, 6, 4, 11, 29] </ref> because to devise a theory of self-interested agents, the possibility that they design their algorithms to time has to be accounted for.
Reference: [7] <author> A. Garvey and V. Lesser. </author> <title> Design-to-time real-time scheduling. </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics, </journal> <volume> 23(6), </volume> <year> 1993. </year>
Reference-contexts: The curves become flat at a c comp that is so high that it is not worth to take any iterative refinement steps: the initial solutions are used (their computation requirements are assumed negligible). Conceptually the agents use design-to-time algorithms <ref> [7, 29, 8] </ref>: once an agent has decided how much CPU time r S it will allocate to a computation, it can design an algorithm that will find a solution of cost c S (r S ).
Reference: [8] <author> A. Garvey and V. Lesser. </author> <booktitle> A survey of research in deliberative real-time artificial intelligence. Real-Time Systems, </booktitle> <volume> 6 </volume> <pages> 317-347, </pages> <year> 1994. </year>
Reference-contexts: The curves become flat at a c comp that is so high that it is not worth to take any iterative refinement steps: the initial solutions are used (their computation requirements are assumed negligible). Conceptually the agents use design-to-time algorithms <ref> [7, 29, 8] </ref>: once an agent has decided how much CPU time r S it will allocate to a computation, it can design an algorithm that will find a solution of cost c S (r S ).
Reference: [9] <author> General Magic, Inc. </author> <title> Telescript technology: The foundation for the elec-tronic marketplace, </title> <note> 1994. White paper. </note>
Reference-contexts: In all, the bounded rational value of a coalition is determined by three factors: 3 In practice, CPU time can already be bought on supercomputers. Similarly, the developing infrastructure for remotely executing agents provides an equivalent setting. For example in Telescript <ref> [9] </ref>, the remotely executing agents pay Teleclicks for CPU time to the owner of the host machine. In this paper, the market for CPU time is assumed to be so large that the demand of the agents we are studying does not impact the price of a CPU time unit.
Reference: [10] <author> I. </author> <title> Good. Twenty-seven principles of rationality. </title> <editor> In V. Godambe and D. Sprott, editors, </editor> <title> Foundations of Statistical Inference. </title> <publisher> Toronto: Holt, Rinehart, Winston, </publisher> <year> 1971. </year>
Reference-contexts: If the problem is hard and the instance is large, it is unrealistic to assume that it can be solved without deliberation costs. This paper adopts a model of bounded rationality <ref> [26, 10] </ref>, where each agent has to pay for the computational resources (CPU cycles) that it uses for deliberation.
Reference: [11] <author> E. J. Horvitz. </author> <title> Reasoning about beliefs and actions under computational resource constraints. </title> <editor> In L. Kanal, T. Levitt, and J. Lemmer, editors, </editor> <booktitle> Uncertainty in Artificial Intelligence, </booktitle> <volume> volume 3, </volume> <pages> pages 301-324. </pages> <year> 1989. </year> <month> 30 </month>
Reference-contexts: The design-to-time framework is used instead of the anytime framework <ref> [21, 6, 4, 11, 29] </ref> because to devise a theory of self-interested agents, the possibility that they design their algorithms to time has to be accounted for.
Reference: [12] <author> J. P. Kahan and A. Rapoport. </author> <title> Theories of Coalition Formation. </title> <publisher> Lawrence Erlbaum Associates Publishers, </publisher> <year> 1984. </year>
Reference-contexts: These activities interact. For example, the coalition that an agent wants to join depends on the portion of the value that the agent would be allocated in each potential coalition. Coalition formation has been widely studied <ref> [12, 27, 18, 25, 30, 13] </ref>, but to our knowledge, only among rational agents. Let us call the entire set of agents A. Say, that the lowest cost achievable by agents S A working together, but without any other agents, is c R S . <p> agent is motivated to stay with CS Rfl (individual rationality)? Furthermore, can it be distributed so that every subgroup of agents is better off with CS Rfl than by forming a coalition of their own (coalition rationality)? The core (C) is the solution concept that satisfies both of these conditions <ref> [12, 27, 18] </ref>. <p> It is often too strong: in many cases it is empty, i.e. the social good cannot be divided so that the individual and coalition rationality conditions are satisfied <ref> [12, 27, 18] </ref>. A lesser problem is that the core may include multiple ~x's and the agents have to agree on one of them. An often used solution is to pick the nucleolus which is, intuitively speaking, the center of the core [12, 27, 18]. <p> the individual and coalition rationality conditions are satisfied <ref> [12, 27, 18] </ref>. A lesser problem is that the core may include multiple ~x's and the agents have to agree on one of them. An often used solution is to pick the nucleolus which is, intuitively speaking, the center of the core [12, 27, 18]. Games with non-empty cores are called weak, Fig. 2. Now we introduce the analog of the core for BR agents. <p> Again, other solution concepts are necessary, e.g. the Nash equilibrium or some of its refinements. This is part of our current research. 6 Related DAI research on collusion Coalition formation has been widely studied in game theory <ref> [12, 2, 3, 1, 27, 18] </ref>; only the most relevant concepts were presented here. This section compares our work to other recent DAI research on coalition formation. Zlotkin and Rosenschein [30] analyze rational agents that cannot make side payments, while our agents do. <p> We do not assume that one agent can take care of all the agents' tasks. Unlike our work, they also assume that all agents have the same capabilities (symmetric cost functions for task sets). Their method guarantees each agent an expected value that equals its Shapley value <ref> [12, 18] </ref>. The Shapley value motivates individual agents to stay with the coalition structure (individual rationality) and the group of all agents to stay (group rationality). Unlike the core, the Shapley value does not in general motivate every subgroup of agents to stay with the coalition structure (coalition rationality).
Reference: [13] <author> S. Ketchpel. </author> <title> Forming coalitions in the face of uncertain rewards. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pages 414-419, </pages> <address> Seattle, WA, </address> <month> July </month> <year> 1994. </year>
Reference-contexts: These activities interact. For example, the coalition that an agent wants to join depends on the portion of the value that the agent would be allocated in each potential coalition. Coalition formation has been widely studied <ref> [12, 27, 18, 25, 30, 13] </ref>, but to our knowledge, only among rational agents. Let us call the entire set of agents A. Say, that the lowest cost achievable by agents S A working together, but without any other agents, is c R S . <p> In combinatorial problems such as the vehicle routing problem of this paper (and the Postmen Domain of Zlotkin and Rosenschein for that matter), this is clearly intractable if the problem instances are large. Ketchpel <ref> [13] </ref> presents a coalition formation method for rational agents which have different expectations of coalition values. The (computational) origin of these expectations is not addressed. His assumption of imperfect information differs from our setting, where the agents have perfect information, but cannot perfectly deduce.
Reference: [14] <author> D. M. Kreps. </author> <title> A course in microeconomic theory. </title> <publisher> Princeton University Press, </publisher> <year> 1990. </year>
Reference-contexts: Yet if the agents had different PPs or computation unit costs, the problem would not necessarily be within BRCFG. In non-CFGs, superadditivity, subadditivity, and the core are undefined, Fig. 2. Thus, other solution concepts are necessary. One alternative is the Nash equilibrium <ref> [17, 14] </ref>, which guarantees stability in the sense that no agent alone is motivated to deviate from the solution given that others in the game do not deviate. Often this solution concept is too weak because subgroups of agents can deviate in a coordinated manner.
Reference: [15] <author> S. Lin and B. W. Kernighan. </author> <title> An effective heuristic procedure for the traveling salesman problem. </title> <journal> Operations Research, </journal> <volume> 21 </volume> <pages> 498-516, </pages> <year> 1971. </year>
Reference-contexts: One example is completing an iterative refinement algorithm by running an exhaustive complete algorithm after the refinement phase. Another example is switching from using one refinement operator (e.g. 2- swap in TSP <ref> [15, 20] </ref>) to using another refinement operator (e.g. 3-swap in TSP). Furthermore, refinements often decrease solution cost in a stepwise, noncontinuous manner rendering the PPs locally nonconvex|as in our experiments (Fig. 1 left).
Reference: [16] <author> M. G. Lundgren, K. Jornsten, and P. Varbrand. </author> <title> On the nucleolus of the basic vehicle routing game. </title> <type> Technical Report 1992-26, </type> <institution> Linkoping Univ., Dept. of Mathematics, Sweden, </institution> <year> 1992. </year>
Reference-contexts: Thus, the problem is NP-complete. Moreover, the problem instances in our example are so large that even the smallest ones are too hard to solve optimally. Therefore, rational coalition formation algorithms for the vehicle routing problem <ref> [16] </ref> are unusable. The rational value (v R S ) of each coalition S is defined by the tasks and the resources (vehicles, depots) of the agents in the coalition. Specifically, v R S is independent of how nonmembers solve their optimization problems.
Reference: [17] <author> J. Nash. </author> <title> Equilibrium points in n-person games. </title> <booktitle> Proc. of the National Academy of Sciences, </booktitle> <volume> 36 </volume> <pages> 48-49, </pages> <year> 1950. </year>
Reference-contexts: Yet if the agents had different PPs or computation unit costs, the problem would not necessarily be within BRCFG. In non-CFGs, superadditivity, subadditivity, and the core are undefined, Fig. 2. Thus, other solution concepts are necessary. One alternative is the Nash equilibrium <ref> [17, 14] </ref>, which guarantees stability in the sense that no agent alone is motivated to deviate from the solution given that others in the game do not deviate. Often this solution concept is too weak because subgroups of agents can deviate in a coordinated manner.
Reference: [18] <author> H. Raiffa. </author> <title> The Art and Science of Negotiation. </title> <publisher> Harvard Univ. Press, </publisher> <address> Cambridge, Mass., </address> <year> 1982. </year>
Reference-contexts: These activities interact. For example, the coalition that an agent wants to join depends on the portion of the value that the agent would be allocated in each potential coalition. Coalition formation has been widely studied <ref> [12, 27, 18, 25, 30, 13] </ref>, but to our knowledge, only among rational agents. Let us call the entire set of agents A. Say, that the lowest cost achievable by agents S A working together, but without any other agents, is c R S . <p> agent is motivated to stay with CS Rfl (individual rationality)? Furthermore, can it be distributed so that every subgroup of agents is better off with CS Rfl than by forming a coalition of their own (coalition rationality)? The core (C) is the solution concept that satisfies both of these conditions <ref> [12, 27, 18] </ref>. <p> It is often too strong: in many cases it is empty, i.e. the social good cannot be divided so that the individual and coalition rationality conditions are satisfied <ref> [12, 27, 18] </ref>. A lesser problem is that the core may include multiple ~x's and the agents have to agree on one of them. An often used solution is to pick the nucleolus which is, intuitively speaking, the center of the core [12, 27, 18]. <p> the individual and coalition rationality conditions are satisfied <ref> [12, 27, 18] </ref>. A lesser problem is that the core may include multiple ~x's and the agents have to agree on one of them. An often used solution is to pick the nucleolus which is, intuitively speaking, the center of the core [12, 27, 18]. Games with non-empty cores are called weak, Fig. 2. Now we introduce the analog of the core for BR agents. <p> Again, other solution concepts are necessary, e.g. the Nash equilibrium or some of its refinements. This is part of our current research. 6 Related DAI research on collusion Coalition formation has been widely studied in game theory <ref> [12, 2, 3, 1, 27, 18] </ref>; only the most relevant concepts were presented here. This section compares our work to other recent DAI research on coalition formation. Zlotkin and Rosenschein [30] analyze rational agents that cannot make side payments, while our agents do. <p> We do not assume that one agent can take care of all the agents' tasks. Unlike our work, they also assume that all agents have the same capabilities (symmetric cost functions for task sets). Their method guarantees each agent an expected value that equals its Shapley value <ref> [12, 18] </ref>. The Shapley value motivates individual agents to stay with the coalition structure (individual rationality) and the group of all agents to stay (group rationality). Unlike the core, the Shapley value does not in general motivate every subgroup of agents to stay with the coalition structure (coalition rationality).
Reference: [19] <author> J. S. Rosenschein and G. Zlotkin. </author> <title> Rules of Encounter. </title> <publisher> MIT Press, </publisher> <year> 1994. </year>
Reference-contexts: In practice it is often necessary to learn the other agents' characteristics from previous encounters. Alternatively, the agents can be made to explicitly declare their tasks and resources, but they may lie in order to gain monetarily. Rosenschein and Zlotkin <ref> [19] </ref> analyze when rational agents are motivated to declare truthfully. Unfortunately that work assumes only two agents and that they can optimally solve exponentially many NP-complete problems without computation costs. Even under these assumptions, in most cases, truth-telling is not achieved. <p> For example, in some domains it is possible to restrict oneself to using algorithms 6 agents, and how it relates to the rational case. Dotted lines show the rational agent domain classification of Rosenschein and Zlotkin <ref> [19] </ref>. They use "Subadditive" to mean that an agent's cost for handling tasks is subadditive in tasks. We use subadditive to refer to coalition value functions that are subadditive in agents. <p> Specifically, v R S is independent of how nonmembers solve their optimization problems. Therefore our problem is a characteristic function game (CFG), Fig. 2. 20 Our problem is outside the domain classification of Rosenschein and Zlotkin <ref> [19] </ref>, Fig. 2, because agents do not have symmetric capabilities due to heterogeneous fleets. If their definition were extended to allow asymmetric capabilities, our domain would be in SOD n TOD. <p> Negative interactions can also be caused by conflicting goals. In satisfying their goals, nonmembers may actually move the world further from the coalition's goal state (s) <ref> [19] </ref>. Positive interactions are often caused by partially overlapping goals. In satisfying their goals, non- members may actually move the world closer to the coalition's goal state (s), from where the coalition can reach its goals less expensively than it could have without the actions of nonmembers.
Reference: [20] <author> T. W. Sandholm. </author> <title> An implementation of the contract net protocol based on marginal cost calculations. </title> <booktitle> In Proc. 11th National Conference on Artificial Intelligence (AAAI-93), </booktitle> <pages> pages 256-262, </pages> <month> July </month> <year> 1993. </year>
Reference-contexts: One example is completing an iterative refinement algorithm by running an exhaustive complete algorithm after the refinement phase. Another example is switching from using one refinement operator (e.g. 2- swap in TSP <ref> [15, 20] </ref>) to using another refinement operator (e.g. 3-swap in TSP). Furthermore, refinements often decrease solution cost in a stepwise, noncontinuous manner rendering the PPs locally nonconvex|as in our experiments (Fig. 1 left). <p> Finally, his 2-agent auction is manipulable and compu- tationally inefficient. He approaches the coalition formation and the payoff division problems simultaneously. This is closely related to the contracting protocol of Sandholm <ref> [20] </ref> (TRA- CONET), where agents construct the global solution by contracting a small number of tasks at a time, and payments are made regarding each contract before new contracts take place. An agent updates its approximate solution after each task transfer.
Reference: [21] <author> T. W. Sandholm and V. R. Lesser. </author> <title> Utility-based termination of any-time algorithms. </title> <booktitle> In ECAI Workshop on Decision Theory for DAI Applications, </booktitle> <pages> pages 88-99, </pages> <address> Amsterdam, The Netherlands, </address> <year> 1994. </year> <note> Extended version: </note> <institution> Univ. of Mass. at Amherst, Comp. Sci. </institution> <type> Tech. Report 94-54. </type>
Reference-contexts: The design-to-time framework is used instead of the anytime framework <ref> [21, 6, 4, 11, 29] </ref> because to devise a theory of self-interested agents, the possibility that they design their algorithms to time has to be accounted for. <p> In practice there is uncertainty in each PP: the meta-level is not exact. 5 Secondly, the PP depends on several features of the problem instance, and computing the mapping from the instance to the PP <ref> [21] </ref> may take considerable time, thus making the meta-level itself costly. In the limit, the base algorithm would be run at the meta-level to determine what it would achieve for a given time setting. <p> In general, for optimal meta-reasoning, the remaining part of a probabilistic PP should be conditioned on the algorithm's performance on that problem instance on previous CPU time steps <ref> [21, 29] </ref>. Such conditioning, anytime algorithms, and their integration to coalition formation are part of our current research. 5 knowledge. For any coalition's problem and for any setting of CPU time, the cost of the solution potentially generated by each agent is the same. <p> The models are equivalent if the domain cost increases linearly with real time and distribution does not speed up computation. Extensions include generalizing these methods to agents with different PPs, probabilistic PPs, and anytime algorithms where PPs are conditioned on execution so far <ref> [21, 29] </ref>. Agents with probabilistic PPs may want to rese- lect a coalition if the value of their original coalition is lower than expected| but sunk computation cost has already been incurred. Future research also includes agents that can refine solutions generated by others.
Reference: [22] <author> T. W. Sandholm and V. R. Lesser. </author> <title> Coalition formation among bounded rational agents. </title> <booktitle> In Proc. 14th International Joint Conference on Artificial Intelligence (IJCAI-95), </booktitle> <pages> pages 662-669, </pages> <address> Montreal, Canada, </address> <month> Aug. </month> <year> 1995. </year>
Reference: [23] <author> T. W. Sandholm and V. R. Lesser. </author> <title> Issues in automated negotiation and electronic commerce: Extending the contract net framework. </title> <booktitle> In Proc. First International Conference on Multiagent Systems (ICMAS95), </booktitle> <pages> pages 328-335, </pages> <address> San Francisco, </address> <month> June </month> <year> 1995. </year>
Reference-contexts: Future research also includes agents that can refine solutions generated by others. Finally, we are in the process of developing interaction protocols <ref> [23] </ref> that efficiently guide self-interested agents towards the optimal and stable (whenever possible) coalition structures|as determined by the theory developed in this paper. 29
Reference: [24] <author> L. S. Shapley. </author> <title> On balanced sets and cores. </title> <journal> Naval Research Logistics Quarterly, </journal> <volume> 14 </volume> <pages> 453-460, </pages> <year> 1967. </year>
Reference-contexts: The condition C 6= ; can be converted into necessary and sufficient conditions on the v R S 's in games where the grand coalition maximizes social welfare <ref> [24, 5] </ref>. We convert the condition BRC (c comp ) 6= ; into conditions on the v S (c comp )'s analogously. Let B 1 ; :::; B p be distinct, nonempty, proper subsets of A. <p> Proof. Shapley <ref> [24] </ref> proved the following fact (his Theorem 2) for rational agents. In games where CS Rfl = fAg, C 6= ; iff for every minimal balanced set B = fB 1 ; :::; B p g; j=1 j v R A . Theorem 3.2 follows by analogy. 2 Example. <p> B = fB 1 ; :::; B p g; j=1 j v B j (c comp ) v A (c comp ). Furthermore, this set of inequalities is minimal: no smaller set is sufficient. Proof. Shapley <ref> [24] </ref> proved the following fact (his Theorem 3) for rational agents. In a superadditive game, C 6= ; iff for every proper minimal balanced set B = fB 1 ; :::; B p g; j=1 j v R A .
Reference: [25] <author> O. Shechory and S. Kraus. </author> <title> Feasible formation of stable coalitions among autonomous agents in general environments. </title> <journal> Computational Intelligence Journal, </journal> <note> 1995. Submitted. </note>
Reference-contexts: These activities interact. For example, the coalition that an agent wants to join depends on the portion of the value that the agent would be allocated in each potential coalition. Coalition formation has been widely studied <ref> [12, 27, 18, 25, 30, 13] </ref>, but to our knowledge, only among rational agents. Let us call the entire set of agents A. Say, that the lowest cost achievable by agents S A working together, but without any other agents, is c R S . <p> An agent updates its approximate solution after each task transfer. In general equilibrium approaches such as WAL- RAS [28], non-manipulative agents iterate over the allocation of resources 27 and tasks, and payments are made only after a final solution is reached. Shechory and Kraus <ref> [25] </ref> analyze coalition formation among rational agents with perfect information in domains that are not necessarily superadditive. Their protocol guarantees that if agents follow it, a certain stability criterion (K-stability) is met. This requires the solution of an exponential number of optimization problems.
Reference: [26] <author> H. A. Simon. </author> <title> Models of bounded rationality, volume 2. </title> <publisher> MIT Press, </publisher> <year> 1982. </year>
Reference-contexts: If the problem is hard and the instance is large, it is unrealistic to assume that it can be solved without deliberation costs. This paper adopts a model of bounded rationality <ref> [26, 10] </ref>, where each agent has to pay for the computational resources (CPU cycles) that it uses for deliberation.
Reference: [27] <author> W. J. van der Linden and A. </author> <title> Verbeek. Coalition formation: a gametheoretic approach. </title> <editor> In H. A. M. Wilke, editor, </editor> <booktitle> Coalition Formation, volume 24 of Advances in Psychology. </booktitle> <publisher> North Holland, </publisher> <year> 1985. </year>
Reference-contexts: These activities interact. For example, the coalition that an agent wants to join depends on the portion of the value that the agent would be allocated in each potential coalition. Coalition formation has been widely studied <ref> [12, 27, 18, 25, 30, 13] </ref>, but to our knowledge, only among rational agents. Let us call the entire set of agents A. Say, that the lowest cost achievable by agents S A working together, but without any other agents, is c R S . <p> CFGs are a strict subset of NFGs. The two are equivalent in constant-sum games with unrestricted side-payments and perfect communication. In such games, the characteristic function value of a coalition is its minimax value from the normal form game <ref> [27] </ref>. The equivalent of CFGs among BR agents are BRCFGs (Fig. 2) where the value of each coalition S is defined by v S (c comp ). This paper mainly studies BRCFGs. Non-BRCFGs are addressed in Section 5. There exist BRCFGs that are not CFGs. <p> agent is motivated to stay with CS Rfl (individual rationality)? Furthermore, can it be distributed so that every subgroup of agents is better off with CS Rfl than by forming a coalition of their own (coalition rationality)? The core (C) is the solution concept that satisfies both of these conditions <ref> [12, 27, 18] </ref>. <p> It is often too strong: in many cases it is empty, i.e. the social good cannot be divided so that the individual and coalition rationality conditions are satisfied <ref> [12, 27, 18] </ref>. A lesser problem is that the core may include multiple ~x's and the agents have to agree on one of them. An often used solution is to pick the nucleolus which is, intuitively speaking, the center of the core [12, 27, 18]. <p> the individual and coalition rationality conditions are satisfied <ref> [12, 27, 18] </ref>. A lesser problem is that the core may include multiple ~x's and the agents have to agree on one of them. An often used solution is to pick the nucleolus which is, intuitively speaking, the center of the core [12, 27, 18]. Games with non-empty cores are called weak, Fig. 2. Now we introduce the analog of the core for BR agents. <p> Again, other solution concepts are necessary, e.g. the Nash equilibrium or some of its refinements. This is part of our current research. 6 Related DAI research on collusion Coalition formation has been widely studied in game theory <ref> [12, 2, 3, 1, 27, 18] </ref>; only the most relevant concepts were presented here. This section compares our work to other recent DAI research on coalition formation. Zlotkin and Rosenschein [30] analyze rational agents that cannot make side payments, while our agents do.
Reference: [28] <author> M. Wellman. </author> <title> A general- equilibrium approach to distributed transporta-tion planning. </title> <booktitle> In Proc. 10th National Conference on Artificial Intelligence (AAAI-92), </booktitle> <pages> pages 282-289, </pages> <address> San Jose, CA, </address> <month> July </month> <year> 1992. </year>
Reference-contexts: An agent updates its approximate solution after each task transfer. In general equilibrium approaches such as WAL- RAS <ref> [28] </ref>, non-manipulative agents iterate over the allocation of resources 27 and tasks, and payments are made only after a final solution is reached. Shechory and Kraus [25] analyze coalition formation among rational agents with perfect information in domains that are not necessarily superadditive.
Reference: [29] <author> S. Zilberstein. </author> <title> Operational rationality through compilation of anytime algorithms. </title> <type> PhD thesis, </type> <institution> University of California, Berkeley, </institution> <year> 1993. </year>
Reference-contexts: The curves become flat at a c comp that is so high that it is not worth to take any iterative refinement steps: the initial solutions are used (their computation requirements are assumed negligible). Conceptually the agents use design-to-time algorithms <ref> [7, 29, 8] </ref>: once an agent has decided how much CPU time r S it will allocate to a computation, it can design an algorithm that will find a solution of cost c S (r S ). <p> The design-to-time framework is used instead of the anytime framework <ref> [21, 6, 4, 11, 29] </ref> because to devise a theory of self-interested agents, the possibility that they design their algorithms to time has to be accounted for. <p> In general, for optimal meta-reasoning, the remaining part of a probabilistic PP should be conditioned on the algorithm's performance on that problem instance on previous CPU time steps <ref> [21, 29] </ref>. Such conditioning, anytime algorithms, and their integration to coalition formation are part of our current research. 5 knowledge. For any coalition's problem and for any setting of CPU time, the cost of the solution potentially generated by each agent is the same. <p> The models are equivalent if the domain cost increases linearly with real time and distribution does not speed up computation. Extensions include generalizing these methods to agents with different PPs, probabilistic PPs, and anytime algorithms where PPs are conditioned on execution so far <ref> [21, 29] </ref>. Agents with probabilistic PPs may want to rese- lect a coalition if the value of their original coalition is lower than expected| but sunk computation cost has already been incurred. Future research also includes agents that can refine solutions generated by others.
Reference: [30] <author> G. Zlotkin and J. S. Rosenschein. </author> <title> Coalition, cryptography and stabil-ity: Mechanisms for coalition formation in task oriented domains. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pages 432-437, </pages> <address> Seattle, WA, </address> <month> July </month> <year> 1994. </year> <month> 32 </month>
Reference-contexts: These activities interact. For example, the coalition that an agent wants to join depends on the portion of the value that the agent would be allocated in each potential coalition. Coalition formation has been widely studied <ref> [12, 27, 18, 25, 30, 13] </ref>, but to our knowledge, only among rational agents. Let us call the entire set of agents A. Say, that the lowest cost achievable by agents S A working together, but without any other agents, is c R S . <p> This section compares our work to other recent DAI research on coalition formation. Zlotkin and Rosenschein <ref> [30] </ref> analyze rational agents that cannot make side payments, while our agents do. Their analysis is limited to "Subadditive Task Oriented Domains" (STODs), which are a strict subset of CFGs, Fig. 2. In their solution concept, one agent handles all the tasks.
References-found: 30

