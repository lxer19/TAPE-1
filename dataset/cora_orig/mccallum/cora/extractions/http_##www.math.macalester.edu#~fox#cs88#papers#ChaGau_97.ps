URL: http://www.math.macalester.edu/~fox/cs88/papers/ChaGau_97.ps
Refering-URL: http://www.math.macalester.edu/~fox/cs88/readings.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Neural competitive maps for reactive and adaptive navigation  
Author: Carolina Chang and Paolo Gaudiano 
Address: 677 Beacon Street, Boston, MA 02215  
Affiliation: Boston University Neurobotics Lab Dept. of Cognitive and Neural Systems  
Abstract: We have recently introduced a neural network for reactive obstacle avoidance based on a model of classical and operant conditioning. In this article we describe the success of this model when implemented on two real autonomous robots. Our results show the promise of self-organizing neural networks in the domain of intelligent robotics. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A.A. Baloch and A.M. Waxman. </author> <title> Visual learning, adaptive expectations, and behavioral conditioning of the mobile robot MAVIN. Neural Networks, </title> <address> 4:271302, </address> <year> 1991. </year>
Reference-contexts: For instance, the right sensor nodes learn to generate a behavior of turn left, and so on. In contrast, our approach obviates the need for this sort of knowledge by adding the inhibitory operant learning. Another model worthy of mention is that of Baloch and Waxman <ref> [1] </ref>. Their work, which was done on the robot MAVIN, includes a much richer and more complex model than the one presented here, and its focus is on visual navigation. However, they too used a variant of Grossberg's conditioning circuit as part of their overall control scheme.
Reference: [2] <author> R.A. Brooks. </author> <title> A robust layered control system for a mobile robot. </title> <journal> IEEE Journal of Robotics and Automation, </journal> <volume> RA-2(1):1423, </volume> <year> 1986. </year>
Reference-contexts: The traditional world modeling approach of AI is being supplanted by more flexible approaches emphasizing the importance of local interactions between low-level components <ref> [2, 3] </ref>. Furthermore, interesting complex behaviors can be observed when simple robots operate in a situated environment, interacting with unknown objects or other robots [8, 9]. Research in our group has focused on neural networks that were originally developed to explain various aspects of biological function.
Reference: [3] <author> R.A. Brooks. </author> <title> Intelligence without representation. </title> <journal> Artificial Intelligence, </journal> <volume> 139160:47, </volume> <year> 1991. </year>
Reference-contexts: The traditional world modeling approach of AI is being supplanted by more flexible approaches emphasizing the importance of local interactions between low-level components <ref> [2, 3] </ref>. Furthermore, interesting complex behaviors can be observed when simple robots operate in a situated environment, interacting with unknown objects or other robots [8, 9]. Research in our group has focused on neural networks that were originally developed to explain various aspects of biological function.
Reference: [4] <author> Paolo Gaudiano, Eduardo Zalama, Carolina Chang, and Juan L opez Coronado. </author> <title> A model of operant conditioning for adaptive obstacle avoidance. </title> <editor> In P. Maes, M. J. Mataric, J. Meyer, J. Pollack, and S. W. Wilson, editors, </editor> <booktitle> From Animals to Animats 4, </booktitle> <pages> pages 373381, </pages> <address> Cambridge, MA, 1996. </address> <publisher> MIT Press. </publisher>
Reference-contexts: In particular, our neural network tries to learn to avoid obstacles reactively with only minimal information about its structure and its environment. A preliminary version of this work focusing on computer simulations was presented at a recent meeting <ref> [4] </ref>. In this article we summarize the proposed neural network and report our successful attempts to implement the neural network on two different real autonomous robots. <p> Hence, the presence of an obstacle to the right causes the robot to shift to the left, and vice versa. Further details on this operation can be found elsewhere <ref> [4] </ref>. Experimental results We now present some results based on implementation of the model just described on two real robots. Our earlier simulations had been based on a model of a differential-drive wheeled mobile robot.
Reference: [5] <author> Paolo Gaudiano, Eduardo Zalama, and Juan L opez Coronado. </author> <title> An unsupervised neural network for real-time, low-level control of a mobile robot: noise resistance, stability, and hardware implementation. </title> <journal> IEEE SMC, </journal> <volume> 26:485496, </volume> <year> 1996. </year>
Reference-contexts: A gain term can be used to specify the maximum possible velocity. As an alternative, the transformation from the angular velocity population to actual wheel velocities can be done adaptively with another neural network <ref> [5] </ref>. The design of fig. 1 satisfies a number of fundamental constraints. <p> An excitatory component, which is generated directly by the sensory system, reflects the angular velocity required to reach a given target in the absence of obstacles. We have shown previously how this signal could be derived from the sensors <ref> [5] </ref>; for simplicity here we assume that the angular velocity is proportional to the angle between the robot's heading and the target.
Reference: [6] <author> S. Grossberg. </author> <title> On the dynamics of operant conditioning. </title> <journal> Journal of Theoretical Biology, </journal> <volume> 33:225 255, </volume> <year> 1971. </year>
Reference-contexts: Recently we in fl E-mail: fcchang,gaudianog@cns.bu.edu. Supported by the Office of Naval Research (ONR N00014-96-1-0772 and N00014-95-1-0409) and by the mediaCenter Verwaltungs, GmbH, in Friedrichshafen, Germany. troduced a neural network for obstacle avoidance that is based on a model of classical and operant conditioning first proposed by Grossberg <ref> [6] </ref>. The goal of our work is to begin to replicate the kind of autonomy that is observed in biological organisms. In particular, our neural network tries to learn to avoid obstacles reactively with only minimal information about its structure and its environment. <p> In this article we summarize the proposed neural network and report our successful attempts to implement the neural network on two different real autonomous robots. Classical and Operant Conditioning Models of classical and operant conditioning <ref> [11, 12, 6] </ref> have emerged from the field of psychology in order to try to explain how an organism can achieve autonomous behavior in a constantly changing environment.
Reference: [7] <author> S. Grossberg and D.S. Levine. </author> <title> Neural dynamics of attentionally modulated Pavlovian conditioning: blocking, interstimulus interval, and secondary reinforcement. </title> <journal> Applied Optics, </journal> <volume> 26:50155030, </volume> <year> 1987. </year>
Reference-contexts: This kind of learning is related to reinforcement learning [12]. Conditioning and obstacle avoidance In 1971, Grossberg proposed a model of classical and operant conditioning, which was designed to account for a variety of behavioral data. The model was refined in several subsequent publications. In 1987, Grossberg & Levine <ref> [7] </ref> described a computer simulation of the main components of the conditioning circuit. This model was used to explain a number of phenomena from classical conditioning. Our implementation of Grossberg's conditioning circuit, which follows closely that of [7], is shown in fig. 1. <p> In 1987, Grossberg & Levine <ref> [7] </ref> described a computer simulation of the main components of the conditioning circuit. This model was used to explain a number of phenomena from classical conditioning. Our implementation of Grossberg's conditioning circuit, which follows closely that of [7], is shown in fig. 1.
Reference: [8] <editor> Maja J. Mataric. </editor> <booktitle> Issues and approaches in the design of collective autonomous agents. Robotics and Autonomous Systems, </booktitle> <address> 16:321331, </address> <year> 1995. </year>
Reference-contexts: The traditional world modeling approach of AI is being supplanted by more flexible approaches emphasizing the importance of local interactions between low-level components [2, 3]. Furthermore, interesting complex behaviors can be observed when simple robots operate in a situated environment, interacting with unknown objects or other robots <ref> [8, 9] </ref>. Research in our group has focused on neural networks that were originally developed to explain various aspects of biological function. Recently we in fl E-mail: fcchang,gaudianog@cns.bu.edu.
Reference: [9] <author> Rolf Pfeifer. </author> <title> Teaching powerful ideas with autonomous mobile robots. </title> <journal> Journal of Computer Science Education, pages xxxxxx, </journal> <note> 1997. (in press). </note>
Reference-contexts: The traditional world modeling approach of AI is being supplanted by more flexible approaches emphasizing the importance of local interactions between low-level components [2, 3]. Furthermore, interesting complex behaviors can be observed when simple robots operate in a situated environment, interacting with unknown objects or other robots <ref> [8, 9] </ref>. Research in our group has focused on neural networks that were originally developed to explain various aspects of biological function. Recently we in fl E-mail: fcchang,gaudianog@cns.bu.edu.
Reference: [10] <author> Rolf Pfeifer and Paul Verschure. </author> <title> Distributed adaptive control: a paradigm for designing autonomous agents. </title> <editor> In F. J. Varela and P. Bourgine, editors, </editor> <booktitle> Toward a practice of autonomous systems, </booktitle> <pages> pages 2130. </pages> <publisher> MIT Press, </publisher> <address> Cam-bridge, MA, </address> <year> 1992. </year>
Reference-contexts: It is interesting to compare briefly our approach to some similar results published in recent years. A recent model of Pfeifer and Verschure <ref> [10] </ref> also utilizes a form of associative learning to learn avoidance behavior (and also approach but under special conditions). One main difference is that their model presumes the existence of an avoidance behavior, 4 the success of which depends on built-in knowledge about the sensors.
Reference: [11] <author> Robert A. Rescorla and Allan R. Wagner. </author> <title> A theory of pavlovian conditioning: variations in the effectiveness of reinforcement and nonrein-forcement. </title> <editor> In A. H. Black and W. F. Prokasy, editors, </editor> <title> Classical Conditioning II, </title> <booktitle> chapter 3, </booktitle> <pages> pages 6499. </pages> <address> Appleton, New York, </address> <year> 1972. </year>
Reference-contexts: In this article we summarize the proposed neural network and report our successful attempts to implement the neural network on two different real autonomous robots. Classical and Operant Conditioning Models of classical and operant conditioning <ref> [11, 12, 6] </ref> have emerged from the field of psychology in order to try to explain how an organism can achieve autonomous behavior in a constantly changing environment.
Reference: [12] <author> Richard S. Sutton and Andrew G. Barto. </author> <title> Toward a modern theory of adaptive networks: Expectation and prediction. </title> <journal> Psychological Review, </journal> <volume> 88:135170, </volume> <year> 1981. </year> <month> 5 </month>
Reference-contexts: In this article we summarize the proposed neural network and report our successful attempts to implement the neural network on two different real autonomous robots. Classical and Operant Conditioning Models of classical and operant conditioning <ref> [11, 12, 6] </ref> have emerged from the field of psychology in order to try to explain how an organism can achieve autonomous behavior in a constantly changing environment. <p> This kind of learning is related to reinforcement learning <ref> [12] </ref>. Conditioning and obstacle avoidance In 1971, Grossberg proposed a model of classical and operant conditioning, which was designed to account for a variety of behavioral data. The model was refined in several subsequent publications.
References-found: 12

