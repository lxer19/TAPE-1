URL: http://www.eecs.umich.edu/~zuberi/research/thesis.ps
Refering-URL: http://www.eecs.umich.edu/~zuberi/
Root-URL: http://www.cs.umich.edu
Title: ABSTRACT REAL-TIME OPERATING SYSTEM SERVICES FOR NETWORKED EMBEDDED SYSTEMS  
Author: by Khawar M. Zuberi Chair: Kang G. Shin 
Abstract: This dissertation examines issues related to the design and implementation of real-time operating system (RTOS) services for consumer item embedded systems such as cars, webTVs, and cellular phones. Since these devices are mass-produced, keeping production costs low is all important, meaning that RTOS services must be highly efficient to enable use of low-cost hardware in these devices. This dissertation explores optimization techniques for basic RTOS services (task scheduling, synchronization, and communication) to meet the requirements of embedded systems. First, dynamic schedulers like earliest-deadline first (EDF) give high processor utilization but incur high run-time overhead while the opposite is true for static schedulers like rate-monotonic (RM). We design the combined static/dynamic (CSD) scheduler which employs both EDF and RM to deliver run-time overhead comparable to RM and utilization comparable to EDF. Second, increasing use of OO programming has made efficient synchronization important for embedded systems. In an OO multitasking environment, accesses to objects have to be protected through semaphores to ensure mutual exclusion. We present a new semaphore implementation scheme which saves one context switch per lock operation in most circumstances by rescheduling threads to minimize blocking. Third, embedded devices with Internet connectivity require efficient processing of network data. We present a protocol architecture for reducing receive overhead for audio and video messages. The architecture reduces I-cache misses by safely bypassing multiple protocol layers (benefiting short audio messages) and real-time message data is copied only once 
Abstract-found: 1
Intro-found: 1
Reference: <institution> 131 BIBLIOGRAPHY </institution>
Reference: [1] <author> T. Abdelzaher, A. Shaikh, F. Jahanian, and K. Shin, "RTCAST: </author> <title> Lightweight multi-cast for real-time process groups," </title> <booktitle> in Proc. Real-Time Technology and Applications Symposium, </booktitle> <pages> pp. 250-259, </pages> <month> June </month> <year> 1996. </year>
Reference-contexts: Middleware services are implemented on top of the OS (e.g., in the form of daemon processes) and they provide services needed by specialized applications usually running on large-scale parallel or distributed platforms. Examples of middleware services include reliable/atomic multicast <ref> [1, 37] </ref>, consistent event ordering [12, 59, 123], and task allocation in a parallel/distributed environment [107]. At present, embedded systems used in consumer items are not complex enough to require middleware services.
Reference: [2] <author> T. Abdelzaher and K. G. Shin, </author> <title> "Optimal combined task and message scheduling in distributed real-time systems," </title> <booktitle> in Proc. Real-Time Systems Symposium, </booktitle> <pages> pp. 162-171, </pages> <year> 1995. </year>
Reference-contexts: This has led to the development of well-known scheduling schemes such as rate-monotonic (RM) [76], earliest-deadline-first (EDF) [76], and deadline-monotonic [69]. But in recent years, the focus of research has shifted from uniprocessor task scheduling to scheduling tasks and messages in multiprocessors and distributed systems <ref> [2, 54, 117] </ref>. Uniprocessor task scheduling is treated as a "solved" problem and research in this area has tapered off.
Reference: [3] <author> F. Adelstein and M. Singhal, </author> <title> "Real-time causal message ordering in multimedia systems," </title> <booktitle> in Proc. Int'l Conf. on Distributed Computing Systems, </booktitle> <pages> pp. 36-43, </pages> <year> 1995. </year>
Reference-contexts: This results in embedded systems programmers often attempting to improve performance through hand-crafted | thus ad hoc | techniques which not only increases design-time but also tends to be error-prone. Researchers in the past have focused on large-scale applications <ref> [3, 17, 51, 72] </ref> and with good reason: smaller applications used either mechanical or analog electronic control (as in automobiles) or, if using digital control, had a simplistic design where the controller performed only very basic functions (as in various home appliances).
Reference: [4] <institution> Am79C90 CMOS Local Area Network Controller for Ethernet (C-LANCE), Advanced Micro Devices, Inc., </institution> <year> 1994. </year>
Reference-contexts: For both transmission and reception, it has two queues of in-use and free buffers, so it can continue operating as long as some free buffers are available. This is a more complicated and expensive NA design than common NAs such as LANCE <ref> [4] </ref>. LANCE 1 uses circular queues of buffers. For transmission, it transmits messages from the ring until it reaches a free buffer at which point it stops. For reception, it fills buffers in the receive ring until it reaches a filled buffer at which point it starts dropping packets. <p> Accurate modeling of network traffic is not our intent. All we want is to show that receiving even 10-20 non-real-time packets within time interval T is highly improbable, and get some idea of how improbable that is. Since network adapters usually have 128-256 receive buffers <ref> [4, 15] </ref> | and this is likely to increase even further as memory densities increase and cost decreases | receiving even 10-20 packets within T seconds is not enough to disrupt the handling of real-time packets. <p> But for networks such as FDDI and Ethernet which have large packet data units in the kilobytes, it would appear that preemption is infeasible, but in reality that is not the case. Most network adapters (such as LANCE <ref> [4] </ref> for Ethernet) do not keep message data in network adapter memory. Instead, data is kept in host memory and the network adapter is provided with pointers to this data and it uses DMA to transfer data as needed.
Reference: [5] <editor> Appliance war could make web less open. </editor> <title> News Briefs, </title> <journal> IEEE Computer, </journal> <volume> vol. 30, no. 10, </volume> <pages> pp. 20-25, </pages> <month> October </month> <year> 1997. </year>
Reference-contexts: Annual production volumes of IAs (including cellular phones with Internet connectivity) are expected to reach 48 million units by year 2001 <ref> [5] </ref>. At these volumes, extra costs of even a few dollars per unit translate into a loss of millions of dollars overall. <p> The future of IAs is already evident in new devices such as web video phones which use the Internet for audio/video communication. With annual production volume of IAs expected to reach 48 million units by year 2001 <ref> [5] </ref>, IAs are becoming an important class of embedded devices. IAs differ from other embedded devices (such as automotive controllers) in that they communicate directly over the Internet. This means that IAs must run a full communication protocol stack.
Reference: [6] <author> A. C. Audsley, A. Burns, and A. J. Wellings, </author> <title> "Deadline monotonic scheduling theorey and application," </title> <journal> Control Engineering Practice, </journal> <volume> vol. 1, no. 1, </volume> <pages> pp. 71-78, </pages> <year> 1993. </year>
Reference-contexts: This predictability is ensured by system-level services, most important among them being the task scheduler in the RTOS. Real-time task scheduling has been focus of active research for several decades <ref> [6, 69, 76, 106] </ref>. This has led to the development of well-known scheduling schemes such as rate-monotonic (RM) [76], earliest-deadline-first (EDF) [76], and deadline-monotonic [69].
Reference: [7] <author> B. Bershad, S. Savage, P. Pardyak, E. Sirer, M. Fiuczynski, D. Becker, C. Chambers, and S. Eggers, </author> <title> "Extensibility, safety and performance in the SPIN operating system," </title> <booktitle> in Proc. Symp. Operating Systems Principles, </booktitle> <pages> pp. 267-284, </pages> <year> 1995. </year>
Reference-contexts: This deals with the OS providing mechanisms which allow the OS to be extended to provide new functionality. Extensibility falls into three broad categories: the microkernel approach [38, 75], the grafting approach <ref> [7, 100] </ref>, and library OSs based on a thin kernel layer which securely exports hardware resources [22, 53].
Reference: [8] <author> T. Blackwell, </author> <title> "Speeding up protocols for small messages," </title> <booktitle> in Proc. SIGCOMM, </booktitle> <pages> pp. 85-95, </pages> <month> August </month> <year> 1996. </year>
Reference-contexts: Other protocol architecture optimizations have been proposed, such as giving applications direct (but controlled) access to the NA [21], but these schemes usually require hardware support from the NA. Regarding non-data-touching overheads, a batch processing technique was proposed in <ref> [8] </ref>. The idea is to wait till several small messages have been received; then process them as a batch, thereby reducing I-cache misses. This scheme is useful for handling bursts of short messages but is not effective for live audio messages because they are spaced at regular intervals in time.
Reference: [9] <author> J. Brignell and N. White, </author> <title> Intelligent Sensor Systems, </title> <address> Bristol, Philadelphia, </address> <year> 1994. </year>
Reference-contexts: In fact, maximum interval between two such events is unbounded (event may never occur again). In such cases, using periodic messages is a waste of network bandwidth and CPU cycles because 99 there is nothing to say most of the time. Smart sensors <ref> [9] </ref> are most suitable for detecting such events. These sensors have DSP capabilities to recognize events on their own, so they signal the controller only when required.
Reference: [10] <author> G. Cena, L. Durante, and A. Valenzano, </author> <title> "Standard field bus networks for industrial applications," </title> <journal> Computer Standards and Interfaces, </journal> <volume> vol. 17, no. 2, </volume> <pages> pp. 155-167, </pages> <month> January </month> <year> 1995. </year>
Reference-contexts: Another factor contributing to this rapidly increasing complexity is networking. More and more embedded devices are connected to the Internet (such as web TVs and cellular phones). Also, applications which have multiple controllers (such as automobiles) now have these controllers interconnected by a field bus <ref> [10, 91] </ref> (local area networks (LANs) specially designed for real-time control applications) to allow the controllers to coordinate their activities, thus providing new features and better performance. The increased complexity of today's embedded systems 1 necessitates that an RTOS be used to manage various resources (Figure 1.2-b).
Reference: [11] <author> R. S. Chin and S. T. Chanson, </author> <title> "Distributed object-based programming systems," </title> <journal> ACM Computing Surveys, </journal> <volume> vol. 23, no. 1, </volume> <pages> pp. 91-124, </pages> <month> March </month> <year> 1991. </year>
Reference-contexts: Under the active object model <ref> [11] </ref>, one or more server threads are permanently bound to an object. When a client thread invokes a method, a server thread executes the method on behalf of the client. With the passive object model [11], objects do not have threads of their own. <p> Under the active object model <ref> [11] </ref>, one or more server threads are permanently bound to an object. When a client thread invokes a method, a server thread executes the method on behalf of the client. With the passive object model [11], objects do not have threads of their own. To invoke a method, a thread will enter the object, execute the method, and then exit the object. From the point of view of synchronization, the active object model has an advantage if only one thread is assigned per object.
Reference: [12] <author> F. Cristian, H. Aghili, R. Strong, and D. Dolev, </author> <title> "Atomic broadcast: From simple message diffusion to byzantine agreement," </title> <booktitle> in Proc. Int'l Symposium on Fault-Tolerant Computing, </booktitle> <pages> pp. 200-206, </pages> <month> June </month> <year> 1985. </year>
Reference-contexts: Middleware services are implemented on top of the OS (e.g., in the form of daemon processes) and they provide services needed by specialized applications usually running on large-scale parallel or distributed platforms. Examples of middleware services include reliable/atomic multicast [1, 37], consistent event ordering <ref> [12, 59, 123] </ref>, and task allocation in a parallel/distributed environment [107]. At present, embedded systems used in consumer items are not complex enough to require middleware services.
Reference: [13] <author> M. Crovella and A. Bestavros, </author> <title> "Self-similarity in world wide web traffic evidence and possible causes," </title> <booktitle> in Proc. SIGMETRICS, </booktitle> <pages> pp. 160-169, </pages> <month> May </month> <year> 1996. </year> <month> 132 </month>
Reference-contexts: However, various studies have shown that wide-area network traffic is too bursty to be correctly modeled by a Poisson process [16, 90]. Telnet arrivals have been modeled by a Pareto distribution [90], but only empirical models exist for FTP [16] and web browsing <ref> [13, 14] </ref>. This precludes any closed-form derivation of non-real-time packet arrival distributions. Added to this is yet another difficulty that network traffic characteristics may change from time to time or place to place. These characteristics depend on factors such as network congestion, speed at which servers can transmit data, etc.
Reference: [14] <author> C. Cunha, A. Bestavros, and M. Crovella, </author> <title> "Characteristics of WWW client-based traces," </title> <type> Technical Report BU-CS-95-010, </type> <institution> Boston University, Computer Science Department, </institution> <year> 1995. </year>
Reference-contexts: However, various studies have shown that wide-area network traffic is too bursty to be correctly modeled by a Poisson process [16, 90]. Telnet arrivals have been modeled by a Pareto distribution [90], but only empirical models exist for FTP [16] and web browsing <ref> [13, 14] </ref>. This precludes any closed-form derivation of non-real-time packet arrival distributions. Added to this is yet another difficulty that network traffic characteristics may change from time to time or place to place. These characteristics depend on factors such as network congestion, speed at which servers can transmit data, etc. <p> For evaluation purposes, we chose to use web browsing as a representative non-real-time application. Measurements of web traffic have shown that retrieval of even small web pages 85 take more than 2 seconds <ref> [14] </ref>. This is the time needed to look up the remote host's DNS entry and establish TCP connections. After this initial phase data transfer begins at the rate of 1 byte per 90-100s [14]. Most web pages are relatively small-sized. Measurements in [14] show most pages to be 256-512 bytes, but <p> web traffic have shown that retrieval of even small web pages 85 take more than 2 seconds <ref> [14] </ref>. This is the time needed to look up the remote host's DNS entry and establish TCP connections. After this initial phase data transfer begins at the rate of 1 byte per 90-100s [14]. Most web pages are relatively small-sized. Measurements in [14] show most pages to be 256-512 bytes, but with the increasing use of in-line images, this is likely to increase. Even then, the trend of favoring small-sized pages will persist, especially considering the small display screens that IAs have. <p> web pages 85 take more than 2 seconds <ref> [14] </ref>. This is the time needed to look up the remote host's DNS entry and establish TCP connections. After this initial phase data transfer begins at the rate of 1 byte per 90-100s [14]. Most web pages are relatively small-sized. Measurements in [14] show most pages to be 256-512 bytes, but with the increasing use of in-line images, this is likely to increase. Even then, the trend of favoring small-sized pages will persist, especially considering the small display screens that IAs have. As such, we assume a 10kbyte page size.
Reference: [15] <author> C. Dalton, G. Watson, D. Banks, C. Calamvokis, A. Edwards, and J. Lumley, </author> <title> "Afterburner," </title> <journal> IEEE Network, </journal> <volume> vol. 7, no. 4, </volume> <pages> pp. 36-43, </pages> <month> July </month> <year> 1993. </year>
Reference-contexts: We show that this layer bypass can be easily applied to live voice messages, resulting in considerable reduction in non-data-touching overheads. Regarding data-touching overheads (which affect long messages), we exploit the periodic nature of video applications. We show that the single-copy scheme presented for non-real-time systems in <ref> [15] </ref> | which requires specialized network adapter hardware to be feasible for non-real-time systems | works well without any hardware support for multimedia applications because of their periodic nature. <p> This indicates a need to develop an easier-to-use scheme to reduce I-cache misses; a scheme which does not require low-level fine-tuning of protocol code yet avoids all unnecessary I-cache misses. 6.2.2 Single-Copy Architectures The single-copy network architecture was proposed by network adapter (NA) designers <ref> [15] </ref> to reduce data-touching overheads. <p> In case NA buffers fill up, data has to be buffered within the kernel, leading to two data copies. This architecture was proposed for general-purpose computing, and to be effective for such applications, the NA not only needs "enough" buffers, it also needs "flexible" buffers. 77 The Afterburner NA <ref> [15] </ref> uses linked lists to manage NA buffers. For both transmission and reception, it has two queues of in-use and free buffers, so it can continue operating as long as some free buffers are available. <p> Accurate modeling of network traffic is not our intent. All we want is to show that receiving even 10-20 non-real-time packets within time interval T is highly improbable, and get some idea of how improbable that is. Since network adapters usually have 128-256 receive buffers <ref> [4, 15] </ref> | and this is likely to increase even further as memory densities increase and cost decreases | receiving even 10-20 packets within T seconds is not enough to disrupt the handling of real-time packets. <p> This way, I-cache misses associated with protocol processing are minimized, which re-duces overhead by 14-20% for short messages. To reduce data-touching overheads, we used the single-copy scheme <ref> [15] </ref>, showing that for real-time messages, it can be used effectively without any hardware support from the NA, and improves overhead by 15-22%. 94 CHAPTER 7 MESSAGE SCHEDULING FOR CONTROLLER AREA NETWORK (CAN) The previous chapter dealt with communication requirements of embedded devices connected to the Internet.
Reference: [16] <author> P. B. Danzig, S. Jamin, R. Caceres, D. Mitzel, and D. Estrin, </author> <title> "An empirical workload model for driving wide-area TCP/IP network simulations," </title> <journal> Journal of Internetwork-ing, </journal> <volume> vol. 3, no. 1, </volume> <pages> pp. 1-26, </pages> <month> March </month> <year> 1992. </year>
Reference-contexts: This reduces the complexity of network traffic analysis because of the simplicity of Poisson processes. However, various studies have shown that wide-area network traffic is too bursty to be correctly modeled by a Poisson process <ref> [16, 90] </ref>. Telnet arrivals have been modeled by a Pareto distribution [90], but only empirical models exist for FTP [16] and web browsing [13, 14]. This precludes any closed-form derivation of non-real-time packet arrival distributions. <p> However, various studies have shown that wide-area network traffic is too bursty to be correctly modeled by a Poisson process [16, 90]. Telnet arrivals have been modeled by a Pareto distribution [90], but only empirical models exist for FTP <ref> [16] </ref> and web browsing [13, 14]. This precludes any closed-form derivation of non-real-time packet arrival distributions. Added to this is yet another difficulty that network traffic characteristics may change from time to time or place to place.
Reference: [17] <author> A. S. Debelack, J. D. Dehn, L. L. Muchinsky, and D. M. Smith, </author> <title> "Next generation air traffic control automation," </title> <journal> IBM Systems Journal, </journal> <volume> vol. 34, no. 1, </volume> <pages> pp. 63-77, </pages> <year> 1995. </year>
Reference-contexts: This results in embedded systems programmers often attempting to improve performance through hand-crafted | thus ad hoc | techniques which not only increases design-time but also tends to be error-prone. Researchers in the past have focused on large-scale applications <ref> [3, 17, 51, 72] </ref> and with good reason: smaller applications used either mechanical or analog electronic control (as in automobiles) or, if using digital control, had a simplistic design where the controller performed only very basic functions (as in various home appliances).
Reference: [18] <author> E. W. Dijkstra, </author> <title> "Cooperating sequential processes," </title> <type> Technical Report EWD-123, </type> <institution> Technical University, Eindhoven, </institution> <address> the Netherlands, </address> <year> 1965. </year>
Reference-contexts: OO design gives benefits such as reduced software design time and software re-use [83]. But with these benefits comes the extra cost of ensuring mutual exclusion when an object's internal state is updated. Semaphores 1 <ref> [18, 36] </ref> are typically used to provide this mutual exclusion. <p> Moreover, each object invocation requires a context switch from the client thread to the server thread, so this model is time-inefficient as well. With the passive object model, multiple threads can be inside the same object at one time, so they must synchronize their activities. Semaphores <ref> [18, 36] </ref> are commonly used for this purpose (e.g., to provide the monitor construct [40]).
Reference: [19] <author> P. Druschel and G. Banga, </author> <title> "Lazy receiver processing (LRP): A network subsystem architecture for server systems," </title> <booktitle> in Proc. Operating Systems Design and Implementation, </booktitle> <month> October </month> <year> 1996. </year>
Reference-contexts: The send-side architecture is simpler than the receive-side because processing can occur as part of the send system call (as done in <ref> [19, 65, 79] </ref>) and this is the scheme we use as well. However, on the receive-side, protocol processing in general cannot occur at the time of the receive system call since the message may not have arrived yet. <p> The next subsection describes the basic structure we chose for our protocol architecture, followed by a description of our protocol processing optimizations in subsections 6.3.2-6.3.3. 6.3.1 Basic Structure We chose lazy receiver processing (LRP) <ref> [19] </ref> (Figure 6.2) as our basic protocol architecture. In this scheme, the send-side processing is done by the application threads. When a send system call is made, the application thread enters the kernel, executes all relevant protocol and device driver code, and transfers the data to the NA for transmission.
Reference: [20] <author> P. Druschel and L. L. Peterson, "Fbufs: </author> <title> A high-bandwidth cross-domain transfer facility," </title> <booktitle> in Proc. Symp. Operating Systems Principles, </booktitle> <pages> pp. 189-202, </pages> <month> December </month> <year> 1993. </year>
Reference-contexts: These measurements justify our choice of LRP for ensuring predictability. 6.5 Related Work Many researchers attempted to reduce data-touching overheads in various ways. Virtual memory page re-mapping is commonly used to reduce data-copying costs when crossing protection boundaries <ref> [20] </ref>. This technique works well to a certain extent, especially when combined with the mbuf mechanism of BSD [66]. Mbufs are linked lists of buffers. <p> This is not the case with the BSD socket interface, where the location for incoming messages is specified by the user, not by the kernel, resulting in two data copies. Yet another problem with memory remapping is the cost of remapping pages from one domain to another. In <ref> [20] </ref> an optimization is presented in which mappings are cached to reduce overhead significantly. This works reasonably well for transmission, but works for reception only if the network protocol allows packet-level demultiplexing at the device driver level.
Reference: [21] <author> P. Druschel, L. L. Peterson, and B. Davie, </author> <title> "Experiences with a high-speed network adaptor: A software perspective," </title> <booktitle> in Proc. SIGCOMM, </booktitle> <pages> pp. 2-13, </pages> <month> August </month> <year> 1994. </year>
Reference-contexts: In short, caching page 92 mappings cannot work over connectionless networks such as Ethernet. Other protocol architecture optimizations have been proposed, such as giving applications direct (but controlled) access to the NA <ref> [21] </ref>, but these schemes usually require hardware support from the NA. Regarding non-data-touching overheads, a batch processing technique was proposed in [8]. The idea is to wait till several small messages have been received; then process them as a batch, thereby reducing I-cache misses.
Reference: [22] <author> D. Engler, M. F. Kaashoek, and J. O'Toole Jr., </author> <title> "Extensibility, safety and performance in the SPIN operating system," </title> <booktitle> in Proc. Symp. Operating Systems Principles, </booktitle> <pages> pp. 251-266, </pages> <month> December </month> <year> 1995. </year>
Reference-contexts: This deals with the OS providing mechanisms which allow the OS to be extended to provide new functionality. Extensibility falls into three broad categories: the microkernel approach [38, 75], the grafting approach [7, 100], and library OSs based on a thin kernel layer which securely exports hardware resources <ref> [22, 53] </ref>. The microkernel approach envisions a small kernel implementing address spaces, interprocess communication, and other minimal core OS functionality while all other services (such as network communication and file systems) are provided by privileged user-level servers.
Reference: [23] <author> D. Engler and M. F. Kaashoek, "DPF: </author> <title> Fast, flexible message demultiplexing using dynamic code generation," </title> <booktitle> in Proc. SIGCOMM, </booktitle> <pages> pp. 53-59, </pages> <month> August </month> <year> 1996. </year>
Reference-contexts: This is similar to the send-side schemes used in [65, 79]. The main advantage of LRP is for the receive-side processing. Under LRP, incoming 79 packets trigger interrupts which cause the device driver to execute and it passes packets on to the packet filter <ref> [23, 84] </ref>. (The packet filter is a small piece of code which is dynamically installed in the kernel by individual applications to detect packets belonging to those applications and take appropriate actions.) The filter tries to forward packets directly to queues associated with the destination thread where packets stay unprocessed until <p> We also added our own packet filter rather than using the high-overhead BSD packet filter. For simplicity, we implemented a UDP/IP-specific filter. Interested readers are referred to <ref> [23] </ref> for more generalized high-performance packet filters. 6.4.2 Performance Improvements We sent datagram messages from one processor to another and measured the total overhead of receive-side protocol processing including interrupt handling and all relevant context switches.
Reference: [24] <author> Wu-chang Feng, D. Kandlur, D. Saha, and K. Shin, </author> <title> "On providing minimum rate guarantees over the internet," </title> <type> Technical report, </type> <institution> IBM Research report RC 20618, </institution> <note> version 2, </note> <month> November </month> <year> 1997. </year>
Reference-contexts: Since WAN scheduling deals mostly with router issues, it does not affect the design of OS services for embedded systems and is beyond the scope of this thesis. Interested readers are referred to <ref> [24, 119] </ref>. 11 Since a field bus is contained entirely within an embedded system, scheduling messages on a field bus is the responsibility of the embedded systems designer.
Reference: [25] <author> Wu-chi Feng and F. Jahanian, </author> <title> "Providing VCR functionality in a constant quality video-on-demand transportation service," </title> <type> Technical Report CSE-TR 271-95, </type> <institution> University of Michigan, EECS Dept., </institution> <month> December </month> <year> 1995. </year>
Reference-contexts: Handling short messages efficiently is important for applications such as Internet telephony where live voice packets are usually just 30-50 bytes (as in the GSM audio encoding scheme [99] used in various Internet phones). On the other hand, video applications exchange long messages (10-15 kbytes <ref> [25] </ref>) and these must be handled efficiently as well. <p> Handling short messages efficiently is important for applications such as Internet telephony where live voice packets are usually just 30-50 bytes (as in the GSM audio encoding scheme [99] used in various Internet phones). On the other hand, video applications exchange long messages (10-15 kbytes <ref> [25] </ref>) and these too must be handled efficiently. Different overheads come into play depending on whether short or long messages are being processed. Data-touching overheads (which include data copying and checksum overheads) tend to dominate when dealing with long messages.
Reference: [26] <author> D. Ferrari and D. Verma, </author> <title> "A scheme for real-time channel establishment in wide-area networks," </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> vol. 8, no. 3, </volume> <pages> pp. 368-379, </pages> <month> April </month> <year> 1990. </year>
Reference-contexts: The ERCOS task scheduler [92] uses separate queues for preemptive and non-preemptive tasks. Multiple queues are used in network scheduling to combine different types of traffic on the same link in a switched network <ref> [26, 27, 54] </ref>. But in all these cases, multiple queues are used to share a single resource (CPU or network link) between tasks/messages with different quality of service (QoS) requirements. What is novel about CSD is the use of multiple queues to improve performance. <p> However, the authors of [120] showed that EDF performs better than other simple heuristics. This is why several researchers have used EDF for network scheduling <ref> [26, 54, 121] </ref>. This motivates us to use EDF to schedule messages on CAN, but EDF incurs high overhead (as discussed later) which makes it impractical for CAN.
Reference: [27] <author> S. Floyd and V. Jacobson, </author> <title> "Link-sharing and resource management models for packet networks," </title> <journal> IEEE/ACM Trans. Networking, </journal> <volume> vol. 3, no. 4, </volume> <pages> pp. 365-386, </pages> <month> August </month> <year> 1995. </year>
Reference-contexts: The ERCOS task scheduler [92] uses separate queues for preemptive and non-preemptive tasks. Multiple queues are used in network scheduling to combine different types of traffic on the same link in a switched network <ref> [26, 27, 54] </ref>. But in all these cases, multiple queues are used to share a single resource (CPU or network link) between tasks/messages with different quality of service (QoS) requirements. What is novel about CSD is the use of multiple queues to improve performance.
Reference: [28] <institution> FIP bus for exchange of information between transmitters, actuators, and programmable controllers, NF C46 601-607, French Association for Standardization, </institution> <year> 1990. </year>
Reference-contexts: These issues are discussed next. Field Bus Scheduling: The recent proliferation of embedded systems has resulted in many network protocols being designed specifically to satisfy the real-time control requirements of embedded systems. These protocols include the Controller Area Network (CAN) [47], Profibus [32], FIP <ref> [28] </ref>, SP-50 [44], MAP/TOP [80], SERCOS [46], and TTP [61]. All these protocols are known by the general name of field bus because they are meant to control the so-called field devices (sensors and actuators) and all of them have a bus topology.
Reference: [29] <author> V. Frost and B. Melamed, </author> <title> "Traffic modeling for telecommunications networks," </title> <journal> IEEE Communications Mag., </journal> <volume> vol. 33, </volume> <pages> pp. 70-80, </pages> <month> March </month> <year> 1994. </year>
Reference-contexts: Following is an analysis of how frequently this might happen when both real-time and non-real-time packets are being received through the NA. Estimating Non-Real-Time Packet Arrivals: In the past, Poisson processes have been used to model packet arrivals <ref> [29] </ref>. This reduces the complexity of network traffic analysis because of the simplicity of Poisson processes. However, various studies have shown that wide-area network traffic is too bursty to be correctly modeled by a Poisson process [16, 90].
Reference: [30] <author> J. G. Ganssle, </author> <title> The Art of Programming Embedded Systems, </title> <publisher> Academic Press, </publisher> <year> 1992. </year>
Reference-contexts: The sharp drop in microprocessor prices over the past several years has resulted in digital control being used in much smaller and simpler embedded applications <ref> [30] </ref> such as automotive controllers, cellular phones, and home electronic appliances. Also, the increasing popularity of the Internet has led to a new class of computing/communication devices called information appliances (IAs) [71]. IAs are specialized devices with Internet connectivity. <p> the schemes for large-scale systems, these new schemes must provide correct functionality, but beyond that, they must also satisfy the efficiency requirements of emerging real-time embedded applications. 1.1 Embedded Systems All digital systems contained in a larger environment and controlling that environment in some way can be called embedded systems <ref> [30, 35] </ref>. In most of these systems, the environment being controlled imposes response time restrictions on the embedded system in which case it is referred to as a real-time embedded system [30, 35]. <p> digital systems contained in a larger environment and controlling that environment in some way can be called embedded systems <ref> [30, 35] </ref>. In most of these systems, the environment being controlled imposes response time restrictions on the embedded system in which case it is referred to as a real-time embedded system [30, 35]. The on-board navigation system of an aircraft is a real-time embedded system as is the engine controller of an automobile and the digital signal processing (DSP) controller in a cellular phone. We are interested in consumer item embedded systems.
Reference: [31] <author> M. Gergeleit and H. Streich, </author> <title> "Implementing a distributed high-resolution real-time clock using the CAN-bus," </title> <booktitle> in 1st International CAN Conference, </booktitle> <month> September </month> <year> 1994. </year>
Reference-contexts: Then, the deadline field for message i will be the logical inverse of d i SOE = d i ` `, where d i is the absolute deadline of message i and t is the current time (it is assumed that all nodes have synchronized clocks <ref> [31] </ref>). Value of ` depends on what fraction of CPU-time the designer is willing to allow for ID updates. Let this fraction be x. Let M be the MIPS of the CPU and n be the number of instructions required to do the update. <p> To avoid this problem, we must use an agreement protocol to trigger the ID update on all nodes. The CAN clock synchronization algorithm <ref> [31] </ref> synchronizes clocks to within 20s, so that the ID update processes on various nodes will wake up within 20s of each other. A simple agreement protocol can be that one process is designated to broadcast a message on the CAN bus.
Reference: [32] <institution> PROFIBUS standard part 1 and 2, </institution> <type> DIN 19 245, </type> <institution> German Institute of Normalization, </institution> <month> April </month> <year> 1991. </year>
Reference-contexts: These issues are discussed next. Field Bus Scheduling: The recent proliferation of embedded systems has resulted in many network protocols being designed specifically to satisfy the real-time control requirements of embedded systems. These protocols include the Controller Area Network (CAN) [47], Profibus <ref> [32] </ref>, FIP [28], SP-50 [44], MAP/TOP [80], SERCOS [46], and TTP [61]. All these protocols are known by the general name of field bus because they are meant to control the so-called field devices (sensors and actuators) and all of them have a bus topology.
Reference: [33] <author> R. Gopalakrishnan and G. Parulkar, </author> <title> "Bringing real-time theory and practice closer for multimedia computing," </title> <booktitle> in SIGMETRICS, </booktitle> <pages> pp. 1-12, </pages> <month> May </month> <year> 1996. </year>
Reference-contexts: In practice, neither EDF nor RM deliver good performance. In fact, for many real workloads, performance of both these schedulers is about the same [58]. The recent popularity of multimedia applications has led to renewed interest in making uniprocessor task scheduling efficient. In <ref> [33] </ref>, a delayed preemption scheme is presented 37 in which a running task is preempted only at quantized time boundaries. This scheme is useful for protocol data processing since it allows relatively short packet-handling tasks to execute to completion before being preempted.
Reference: [34] <author> P. Goyal, X. Guo, and H. Vin, </author> <title> "A hierarchical CPU scheduler for multimedia operating systems," </title> <booktitle> in Proc. Operating Systems Design and Implementation (OSDI), </booktitle> <month> October </month> <year> 1996. </year>
Reference-contexts: When all scheduling is done in software, it makes much more sense to use dynamic scheduling for short-period tasks and fixed-priority scheduling for the rest of the workload as is done by CSD. The start-time fair queuing (SFQ) algorithm <ref> [34] </ref> was proposed as a framework to enable use to different schedulers for different classes of applications. Conceivably, SFQ can be used to combine EDF and RM.
Reference: [35] <author> R. K. Gupta, </author> <title> Co-Sysnthesis of Hardware and Software for Digital Embedded Systems, </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1995. </year>
Reference-contexts: the schemes for large-scale systems, these new schemes must provide correct functionality, but beyond that, they must also satisfy the efficiency requirements of emerging real-time embedded applications. 1.1 Embedded Systems All digital systems contained in a larger environment and controlling that environment in some way can be called embedded systems <ref> [30, 35] </ref>. In most of these systems, the environment being controlled imposes response time restrictions on the embedded system in which case it is referred to as a real-time embedded system [30, 35]. <p> digital systems contained in a larger environment and controlling that environment in some way can be called embedded systems <ref> [30, 35] </ref>. In most of these systems, the environment being controlled imposes response time restrictions on the embedded system in which case it is referred to as a real-time embedded system [30, 35]. The on-board navigation system of an aircraft is a real-time embedded system as is the engine controller of an automobile and the digital signal processing (DSP) controller in a cellular phone. We are interested in consumer item embedded systems.
Reference: [36] <author> A. N. Habermann, </author> <title> "Synchronization of communicating processes," </title> <journal> Communications of the ACM, </journal> <volume> vol. 15, no. 3, </volume> <pages> pp. 171-176, </pages> <month> March </month> <year> 1972. </year>
Reference-contexts: OO design gives benefits such as reduced software design time and software re-use [83]. But with these benefits comes the extra cost of ensuring mutual exclusion when an object's internal state is updated. Semaphores 1 <ref> [18, 36] </ref> are typically used to provide this mutual exclusion. <p> Moreover, each object invocation requires a context switch from the client thread to the server thread, so this model is time-inefficient as well. With the passive object model, multiple threads can be inside the same object at one time, so they must synchronize their activities. Semaphores <ref> [18, 36] </ref> are commonly used for this purpose (e.g., to provide the monitor construct [40]).
Reference: [37] <author> V. Hadzilacos and S. Toueg, </author> <title> "Fault-tolerant broadcasts and related problems," in Distributed Systems, </title> <editor> S. Mullender, </editor> <booktitle> editor, </booktitle> <pages> pp. 97-145, </pages> <publisher> Addison Wesley, </publisher> <address> New York, </address> <note> second edition, </note> <year> 1993. </year>
Reference-contexts: Middleware services are implemented on top of the OS (e.g., in the form of daemon processes) and they provide services needed by specialized applications usually running on large-scale parallel or distributed platforms. Examples of middleware services include reliable/atomic multicast <ref> [1, 37] </ref>, consistent event ordering [12, 59, 123], and task allocation in a parallel/distributed environment [107]. At present, embedded systems used in consumer items are not complex enough to require middleware services.
Reference: [38] <author> H. Haertig, M. Hohmuth, J. Liedtke, S. Schoenberg, and J. Wolter, </author> <title> "The performance of -kernel-based systems," </title> <booktitle> in Proc. Symp. Operating Systems Principles, </booktitle> <pages> pp. 66-77, </pages> <month> October </month> <year> 1997. </year>
Reference-contexts: This deals with the OS providing mechanisms which allow the OS to be extended to provide new functionality. Extensibility falls into three broad categories: the microkernel approach <ref> [38, 75] </ref>, the grafting approach [7, 100], and library OSs based on a thin kernel layer which securely exports hardware resources [22, 53].
Reference: [39] <author> D. Hildebrand, </author> <title> "An architectural overview of QNX," </title> <booktitle> in Proc. Usenix Workshop on Micro-Kernels and Other Kernel Architectures, </booktitle> <month> April </month> <year> 1992. </year>
Reference-contexts: Comparing this to other major RTOSs for embedded applications (Table 3.4), we see that our goal of a small-sized RTOS has been achieved. RTOS Size (kbytes) QNX 101 VxWorks 5.1 286 EMERALDS 13 Table 3.4: Sizes of various RTOSs (uniprocessor versions). Size of QNX is from <ref> [39] </ref> and includes the "kernel," Proc, and Dev modules which is the minimal configuration with device driver support. VxWorks' size is from a compiled stand-alone version.
Reference: [40] <author> C. A. R. Hoare, </author> <title> "Monitors: An operating system structuring concept," </title> <journal> Communications of the ACM, </journal> <volume> vol. 17, no. 10, </volume> <pages> pp. 549-557, </pages> <month> October </month> <year> 1974. </year>
Reference-contexts: With the passive object model, multiple threads can be inside the same object at one time, so they must synchronize their activities. Semaphores [18, 36] are commonly used for this purpose (e.g., to provide the monitor construct <ref> [40] </ref>). Even though locking based on semaphores incurs time overhead, it is decidedly much more memory-efficient than the active object model. 58 5.2.2 OO Design Under EMERALDS For the above stated reasons, we advocate the passive object model for embedded software design.
Reference: [41] <author> N. C. Hutchinson and L. L. Peterson, </author> <title> "The x-kernel: An architecture for implementing network protocols," </title> <journal> IEEE Trans. Software Engineering, </journal> <volume> vol. 17, no. 1, </volume> <pages> pp. 1-13, </pages> <month> January </month> <year> 1991. </year>
Reference-contexts: The protocol code was taken from FreeBSD 4.4 and minor modifications were made to make it work with our protocol architecture. 6.2 Protocol Architecture Issues Network protocol architecture has been an active area of research for many years <ref> [41, 97] </ref> and various techniques have been proposed to make protocol processing efficient.
Reference: [42] <author> A. Indiresan, A. Mehra, , and K. G. Shin, </author> <title> "The END: An emulated network device for evaluating adapter design," </title> <booktitle> in Proc. 3rd Intl. Workshop on Performability Modeling of Computer and Communication Systems, </booktitle> <year> 1996. </year>
Reference-contexts: To implement MTS within EMERALDS on TouCAN, we would first have to port EMERALDS to the MC68376 microcontroller. To avoid this, we instead used device emulation <ref> [42] </ref> under which a general-purpose microcontroller is made to emulate a network adapter. This emulator interfaces to the host CPU through an I/O bus. The emulator presents the host CPU the same interface that the actual network adapter would.
Reference: [43] <author> A. Indiresan, </author> <title> Exploring Quality-of-Service Issues in Network Interface Design, </title> <type> PhD thesis, </type> <institution> University of Michigan, </institution> <year> 1997. </year>
Reference-contexts: If a high-priority message arrives at this point, it has to be buffered in software to wait for one or more messages already in the adapter to be sent. But this priority inversion is bounded by the token rotation time and number of buffers in the adapter <ref> [43] </ref>. In CAN, priority inversion can be unbounded. If the adapter buffers contain low-priority messages, these messages will not be sent as long as there are higher-priority messages anywhere else in the network. <p> If this is the case, preemption can be used to address the priority inversion problem in these networks as well. Previous solutions to reduce priority inversion for such networks include schemes which limit the number of FIFO buffers used for transmission <ref> [43] </ref>. This reduces priority inversion but also increases the frequency of interrupts.
Reference: [44] <institution> Industrial Automation Systems | Systems Integration and Communication | Field-bus (draft) (ISA/SP50-93), Instrument Society of America, </institution> <address> 1st edition, </address> <year> 1993. </year> <title> [45] 82527 Serial Communications Controller Architectural Overview, </title> <publisher> Intel Corporation, </publisher> <year> 1993. </year>
Reference-contexts: These issues are discussed next. Field Bus Scheduling: The recent proliferation of embedded systems has resulted in many network protocols being designed specifically to satisfy the real-time control requirements of embedded systems. These protocols include the Controller Area Network (CAN) [47], Profibus [32], FIP [28], SP-50 <ref> [44] </ref>, MAP/TOP [80], SERCOS [46], and TTP [61]. All these protocols are known by the general name of field bus because they are meant to control the so-called field devices (sensors and actuators) and all of them have a bus topology. <p> Message-passing in EMERALDS has been designed with efficiency and flexibility in mind. Most communication networks designed for embedded, real-time systems such as CAN [47], TTP [61], SERCOS [46], SP50 <ref> [44] </ref>, etc., provide the bottom two layers of the ISO OSI reference stack (the physical and data-link layers) which is sufficient for exchanging simple messages (all that the sender has to do is talk directly to the network device driver). <p> These systems consist of multiple computational nodes, sensors, and actuators interconnected by a low-speed LAN called a field bus [94]. Of the multiple field bus protocols available for such use (including SP-50 FieldBus <ref> [44] </ref>, MAP [80], TTP [61], etc.), the Controller Area Network (CAN) [49, 104] has gained wide-spread acceptance in the industry [118]. CAN is a contention-based multi-master network which has the potential to efficiently handle both periodic as well as sporadic messages.
Reference: [46] <institution> Electrical Equipment of Industrial Machines | Serial Data Link for Real-Time Com--munication between Controls and Drives, International Electrotechnical Commission, </institution> <year> 1994. </year> <note> Revision 8. </note>
Reference-contexts: Field Bus Scheduling: The recent proliferation of embedded systems has resulted in many network protocols being designed specifically to satisfy the real-time control requirements of embedded systems. These protocols include the Controller Area Network (CAN) [47], Profibus [32], FIP [28], SP-50 [44], MAP/TOP [80], SERCOS <ref> [46] </ref>, and TTP [61]. All these protocols are known by the general name of field bus because they are meant to control the so-called field devices (sensors and actuators) and all of them have a bus topology. <p> Message-passing in EMERALDS has been designed with efficiency and flexibility in mind. Most communication networks designed for embedded, real-time systems such as CAN [47], TTP [61], SERCOS <ref> [46] </ref>, SP50 [44], etc., provide the bottom two layers of the ISO OSI reference stack (the physical and data-link layers) which is sufficient for exchanging simple messages (all that the sender has to do is talk directly to the network device driver).
Reference: [47] <institution> Road vehicles | Interchange of digital information | Controller area network (CAN) for high-speed communication. ISO 11898, International Standards Organization, </institution> <address> 1st edition, </address> <year> 1993. </year>
Reference-contexts: These issues are discussed next. Field Bus Scheduling: The recent proliferation of embedded systems has resulted in many network protocols being designed specifically to satisfy the real-time control requirements of embedded systems. These protocols include the Controller Area Network (CAN) <ref> [47] </ref>, Profibus [32], FIP [28], SP-50 [44], MAP/TOP [80], SERCOS [46], and TTP [61]. All these protocols are known by the general name of field bus because they are meant to control the so-called field devices (sensors and actuators) and all of them have a bus topology. <p> Message-passing in EMERALDS has been designed with efficiency and flexibility in mind. Most communication networks designed for embedded, real-time systems such as CAN <ref> [47] </ref>, TTP [61], SERCOS [46], SP50 [44], etc., provide the bottom two layers of the ISO OSI reference stack (the physical and data-link layers) which is sufficient for exchanging simple messages (all that the sender has to do is talk directly to the network device driver).
Reference: [48] <author> Y. Ishikawa, H. Tokuda, and C. W. Mercer, </author> <title> "An object-oriented real-time programming language," </title> <journal> IEEE Computer, </journal> <volume> vol. 25, no. 10, </volume> <pages> pp. 66-73, </pages> <month> October </month> <year> 1992. </year>
Reference-contexts: These notions of encapsulation and modularity greatly help the software design process because various system components such as sensors, actuators, and controllers can be modeled by objects. Then, under the OO paradigm, real-time software is just a collection of threads of execution, each invoking various methods of various objects <ref> [48] </ref>. 57 Conceptually, this OO paradigm is very appealing and gives benefits such as reduced software design time and software re-use. But practically speaking, these benefits come at a cost. The methods of an object must synchronize their access to the object's data to ensure mutual exclusion.
Reference: [49] <institution> Road vehicles | Interchange of digital information | Controller area network (CAN) for high-speed communication, ISO 11898, </institution> <year> 1993. </year>
Reference-contexts: These systems consist of multiple computational nodes, sensors, and actuators interconnected by a low-speed LAN called a field bus [94]. Of the multiple field bus protocols available for such use (including SP-50 FieldBus [44], MAP [80], TTP [61], etc.), the Controller Area Network (CAN) <ref> [49, 104] </ref> has gained wide-spread acceptance in the industry [118]. CAN is a contention-based multi-master network which has the potential to efficiently handle both periodic as well as sporadic messages. <p> Section 7.4 discusses issues related to implementation of MTS, focusing on the priority inversion problem. Section 7.5 evaluates the network schedulability performance of MTS (compared to EDF and DM) and presents implementation overhead measurements. The chapter concludes with Section 7.6. 7.1 Controller Area Network (CAN) CAN <ref> [49, 104] </ref> is an advanced serial communication protocol for distributed real-time control systems. It is a contention-based multi-master network whose timeliness properties come from its collision resolution algorithm.
Reference: [50] <author> K. Jeffay, D. F. Stanat, and C. U. Martel, </author> <title> "On non-preemptive scheduling of periodic and sporadic tasks," </title> <booktitle> in Proc. Real-Time Systems Symposium, </booktitle> <pages> pp. 129-139, </pages> <year> 1991. </year>
Reference-contexts: Each message will have a unique priority which will form its ID. However, in general, fixed-priority schemes give lower utilization than other schemes such as non-preemptive EDF. Non-preemptive scheduling under release time constraints is NP-hard in the strong sense <ref> [50] </ref>, meaning that there is no polynomial time scheduler which will always give the maximum schedulable utilization. However, the authors of [120] showed that EDF performs better than other simple heuristics. This is why several researchers have used EDF for network scheduling [26, 54, 121].
Reference: [51] <author> E. D. Jensen and J. D. Northcutt, </author> <title> "Alpha: a non-proprietary operating system for large, complex, distributed real-time systems," </title> <booktitle> in Proc. IEEE Workshop on Experimental Distributed Systems, </booktitle> <pages> pp. 35-41, </pages> <year> 1990. </year>
Reference-contexts: This results in embedded systems programmers often attempting to improve performance through hand-crafted | thus ad hoc | techniques which not only increases design-time but also tends to be error-prone. Researchers in the past have focused on large-scale applications <ref> [3, 17, 51, 72] </ref> and with good reason: smaller applications used either mechanical or analog electronic control (as in automobiles) or, if using digital control, had a simplistic design where the controller performed only very basic functions (as in various home appliances). <p> For example, a multitude of RTOSs have been designed to date which provide a predictable platform for task execution and inter-process 1 From here on, we use the term embedded system to mean consumer item embedded system, unless stated otherwise. 4 communication, but most of these RTOSs like Alpha <ref> [51] </ref> and the Spring Kernel [109] were designed for large parallel and distributed systems with powerful processors and fast interconnection networks.
Reference: [52] <author> M. B. Jones, D. Rosu, and M.-C. Rosu, </author> <title> "CPU reservations and time constraints: Efficient, predictable scheduling of independet activities," </title> <booktitle> in Proc. Symp. Operating Systems Principles, </booktitle> <pages> pp. 198-211, </pages> <month> October </month> <year> 1997. </year>
Reference-contexts: This scheme is useful for protocol data processing since it allows relatively short packet-handling tasks to execute to completion before being preempted. However, utility of such delayed preemption schedulers in handling application task workloads is yet to be demonstrated. The Rialto scheduler <ref> [52] </ref> uses time-slice scheduling to reduce run-time overhead to a minimum, but it employs heuristics for constructing the schedule, resulting in non-optimal solutions. In embedded systems, scheduler inefficiencies become a major concern because of relatively slow CPUs. This led us to investigate ways to reduce scheduler overhead and improve performance.
Reference: [53] <author> M. F. Kaashoek and et. al, </author> <title> "Application performance and flexibility on Exokernel systems," </title> <booktitle> in Proc. Symp. Operating Systems Principles, </booktitle> <pages> pp. 52-65, </pages> <month> October </month> <year> 1997. </year>
Reference-contexts: This deals with the OS providing mechanisms which allow the OS to be extended to provide new functionality. Extensibility falls into three broad categories: the microkernel approach [38, 75], the grafting approach [7, 100], and library OSs based on a thin kernel layer which securely exports hardware resources <ref> [22, 53] </ref>. The microkernel approach envisions a small kernel implementing address spaces, interprocess communication, and other minimal core OS functionality while all other services (such as network communication and file systems) are provided by privileged user-level servers.
Reference: [54] <author> D. D. Kandlur, K. G. Shin, and D. Ferrari, </author> <title> "Real-time communication in multi-hop networks," </title> <journal> IEEE Trans. on Parallel and Distributed Systems, </journal> <volume> vol. 5, no. 10, </volume> <pages> pp. 1044-1056, </pages> <month> October </month> <year> 1994. </year>
Reference-contexts: This has led to the development of well-known scheduling schemes such as rate-monotonic (RM) [76], earliest-deadline-first (EDF) [76], and deadline-monotonic [69]. But in recent years, the focus of research has shifted from uniprocessor task scheduling to scheduling tasks and messages in multiprocessors and distributed systems <ref> [2, 54, 117] </ref>. Uniprocessor task scheduling is treated as a "solved" problem and research in this area has tapered off. <p> The ERCOS task scheduler [92] uses separate queues for preemptive and non-preemptive tasks. Multiple queues are used in network scheduling to combine different types of traffic on the same link in a switched network <ref> [26, 27, 54] </ref>. But in all these cases, multiple queues are used to share a single resource (CPU or network link) between tasks/messages with different quality of service (QoS) requirements. What is novel about CSD is the use of multiple queues to improve performance. <p> However, the authors of [120] showed that EDF performs better than other simple heuristics. This is why several researchers have used EDF for network scheduling <ref> [26, 54, 121] </ref>. This motivates us to use EDF to schedule messages on CAN, but EDF incurs high overhead (as discussed later) which makes it impractical for CAN. <p> If messages are numbered according to their priority with j = 1 being the highest-priority message, then i is schedulable <ref> [54] </ref> if: 9t 2 S; j=1 dt=T j eC j + C p t; where S =fset of all release times of messages 1; 2; ; i 1 through time D i C i g [fD i C i g; T j , C j , and D j are the
Reference: [55] <author> D. Kandlur, D. Saha, and M. Willebeek-LeMair, </author> <title> "Protocol architecture for multimedia applications over ATM networks," </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> vol. 14, no. 7, </volume> <pages> pp. 1349-1359, </pages> <month> September </month> <year> 1996. </year>
Reference-contexts: The architecture must be able to efficiently handle not only long messages (such as video) but also short, frequent ones (such as live audio). Also, studies have shown that receive-side protocol processing overhead is higher than send-side overhead <ref> [55, 57, 79] </ref> and this is what limits throughput; so, we focus on improving receive-side overhead while ensuring predictability. Local Message-Passing The traditional mechanism for exchange of information between tasks is message-passing using mailboxes. <p> With messages arriving with such high frequency, non-data-touching overheads (context switching, interrupt handling, I-cache miss overheads, etc.) become an important part of protocol processing. Studies have shown that receive-side protocol processing is more complicated and has higher overhead than the send-side <ref> [55, 57, 79] </ref> and this is what limits throughput; so, here we focus on improving receive-side overhead.
Reference: [56] <author> D. Katcher, H. Arakawa, and J. Strosnider, </author> <title> "Engineering and analysis of fixed priority schedulers," </title> <journal> IEEE Trans. Software Engineering, </journal> <volume> vol. 19, no. 9, </volume> <pages> pp. 920-934, </pages> <month> September </month> <year> 1993. </year>
Reference-contexts: Our test procedure involves generating random task workloads, then for each workload, scaling the execution times of tasks until the workload is no longer feasible for a given scheduler. The utilization at which the workload becomes infeasible is called the breakdown utilization <ref> [56] </ref>. We expect that with scheduling overheads considered, CSD will have the highest breakdown utilization. 50 4.4.1 Results Because scheduling overheads are a function of the number of tasks (n) in the workload, we tested all schedulers for workloads ranging from n = 5 to n = 50. <p> The well-known avionics task workload [77, 78] is accepted as typifying real-time control 117 applications and also has been used by others for research on real-time scheduling <ref> [56] </ref>. The workload is reproduced in Table 7.2. It has 6 tasks with deadlines in the 5-50ms range (i.e., high-speed tasks) and 11 tasks with deadlines in the 59-1000ms range (low-speed tasks).
Reference: [57] <author> J. Kay and J. Pasquale, </author> <title> "Measurement, analysis, and improvement of UDP/IP throughput for the DECstation 5000," </title> <booktitle> in Proc. Winter USENIX, </booktitle> <pages> pp. 249-258, </pages> <month> Jan-uary </month> <year> 1993. </year>
Reference-contexts: The architecture must be able to efficiently handle not only long messages (such as video) but also short, frequent ones (such as live audio). Also, studies have shown that receive-side protocol processing overhead is higher than send-side overhead <ref> [55, 57, 79] </ref> and this is what limits throughput; so, we focus on improving receive-side overhead while ensuring predictability. Local Message-Passing The traditional mechanism for exchange of information between tasks is message-passing using mailboxes. <p> With messages arriving with such high frequency, non-data-touching overheads (context switching, interrupt handling, I-cache miss overheads, etc.) become an important part of protocol processing. Studies have shown that receive-side protocol processing is more complicated and has higher overhead than the send-side <ref> [55, 57, 79] </ref> and this is what limits throughput; so, here we focus on improving receive-side overhead. <p> In all cases, the UDP checksum is turned off. From the figure, we see the benefit of bypassing IP and UDP layers. Performance is improved 20% (beyond that of LRP). Note that the sharper variations in the plots are a result of BSD's mbuf allocation scheme <ref> [57] </ref> and are not related to the protocol architecture. 88 The above measurements were for a relatively slow processor typical of CPUs used in IAs. As already mentioned, layer bypass can also be applied to web servers which use much faster processors.
Reference: [58] <author> K. Kettler, D. Katcher, and J. Strosnider, </author> <title> "A modeling methodology for real-time/multimedia operating systems," </title> <booktitle> in Proc. Real-Time Technology and Applications Symposium, </booktitle> <pages> pp. 15-26, </pages> <year> 1996. </year>
Reference-contexts: The static RM scheduler has much lower run-time overhead but its average-case schedulable utilization is only 88% [67] | well below that for EDF. In practice, neither EDF nor RM deliver good performance. In fact, for many real workloads, performance of both these schedulers is about the same <ref> [58] </ref>. The recent popularity of multimedia applications has led to renewed interest in making uniprocessor task scheduling efficient. In [33], a delayed preemption scheme is presented 37 in which a running task is preempted only at quantized time boundaries.
Reference: [59] <author> H. Kopetz, </author> <title> "Sparse time versus dense time in distributed real-time systems," </title> <booktitle> in Proc. Int'l Conf. on Distributed Computing Systems, </booktitle> <pages> pp. 460-467, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: Middleware services are implemented on top of the OS (e.g., in the form of daemon processes) and they provide services needed by specialized applications usually running on large-scale parallel or distributed platforms. Examples of middleware services include reliable/atomic multicast [1, 37], consistent event ordering <ref> [12, 59, 123] </ref>, and task allocation in a parallel/distributed environment [107]. At present, embedded systems used in consumer items are not complex enough to require middleware services.
Reference: [60] <author> H. Kopetz, A. Damm, C. Koza, M. Mulazzani, W. Schwabl, C. Senft, and R. Zain-linger, </author> <title> "Distributed fault-tolerant real-time systems: the MARS approach," </title> <journal> IEEE Micro, </journal> <volume> vol. 9, no. 1, </volume> <pages> pp. 25-40, </pages> <month> February </month> <year> 1989. </year> <month> 135 </month>
Reference-contexts: State messages <ref> [60] </ref> use global variables to pass messages between tasks, but these variables are managed by code generated automatically by a software tool, not by the application designer. <p> Then, traditional message-passing and/or semaphores must be used. Hence, state messages do not replace traditional message passing for all situations, but they do replace it for most inter-task communication requirements in embedded applications. Previous Work State messages were first used in the MARS OS <ref> [60] </ref> and have also been implemented in ERCOS [92]. The state message implementation used in these systems as described in [62] is as follows.
Reference: [61] <author> H. Kopetz and G. Grunsteidl, </author> <title> "TTP a protocol for fault-tolerant real-time systems," </title> <journal> IEEE Computer, </journal> <volume> vol. 27, no. 1, </volume> <pages> pp. 14-23, </pages> <month> January </month> <year> 1994. </year>
Reference-contexts: Field Bus Scheduling: The recent proliferation of embedded systems has resulted in many network protocols being designed specifically to satisfy the real-time control requirements of embedded systems. These protocols include the Controller Area Network (CAN) [47], Profibus [32], FIP [28], SP-50 [44], MAP/TOP [80], SERCOS [46], and TTP <ref> [61] </ref>. All these protocols are known by the general name of field bus because they are meant to control the so-called field devices (sensors and actuators) and all of them have a bus topology. <p> Message-passing in EMERALDS has been designed with efficiency and flexibility in mind. Most communication networks designed for embedded, real-time systems such as CAN [47], TTP <ref> [61] </ref>, SERCOS [46], SP50 [44], etc., provide the bottom two layers of the ISO OSI reference stack (the physical and data-link layers) which is sufficient for exchanging simple messages (all that the sender has to do is talk directly to the network device driver). <p> These systems consist of multiple computational nodes, sensors, and actuators interconnected by a low-speed LAN called a field bus [94]. Of the multiple field bus protocols available for such use (including SP-50 FieldBus [44], MAP [80], TTP <ref> [61] </ref>, etc.), the Controller Area Network (CAN) [49, 104] has gained wide-spread acceptance in the industry [118]. CAN is a contention-based multi-master network which has the potential to efficiently handle both periodic as well as sporadic messages.
Reference: [62] <author> H. Kopetz and J. Reisinger, </author> <title> "The non-blocking write protocol NBW: a solution to a real-time synchronization problem," </title> <booktitle> in Proc. Real-Time Systems Symposium, </booktitle> <pages> pp. 131-137, </pages> <year> 1993. </year>
Reference-contexts: Previous Work State messages were first used in the MARS OS [60] and have also been implemented in ERCOS [92]. The state message implementation used in these systems as described in <ref> [62] </ref> is as follows. The problem with using global variables for passing messages is that a reader may read a half-written message since there is no synchronization between readers and writers. This problem is solved by using an N -deep circular buffer for each state message. <p> With a deep enough buffer, the scheme can guarantee that data will not be corrupted while it is being read by a reader, but a large N can make state messages infeasible for our limited-memory target applications. 27 The solution presented in <ref> [62] </ref> limits N by having readers repeat the read operation until they get uncorrupted data. This saves memory at the cost of increasing the read time by as much as several hundred microseconds, even under the assumption that writers and readers run on separate processors with shared memory.
Reference: [63] <author> C. M. Krishna and K. G. Shin, </author> <title> Real-Time Systems, </title> <publisher> McGraw-Hill, </publisher> <year> 1997. </year>
Reference-contexts: The workload is feasible under RM if [67] 8i; 1 i n; min 0 i X c j + t (RM ) & P j A 1: In practice, this equation need only be evaluated for a finite number of t values as described in <ref> [63] </ref>. Schedulability under CSD is tested as follows.
Reference: [64] <author> G. Lawton, </author> <title> "Dawn of the Internet appliance," </title> <journal> IEEE Computer, </journal> <volume> vol. 30, no. 10, </volume> <pages> pp. 16-18, </pages> <month> October </month> <year> 1997. </year>
Reference-contexts: Also, in this chapter we focused only on improving the semaphore lock operation. In the future, we plan to investigate optimizations related to the release operation to get further improvements in synchronization overheads. 73 CHAPTER 6 END-HOST PROTOCOL PROCESSING ARCHITECTURE Information appliances (IAs) <ref> [64, 71] </ref> are single-user devices with Internet connectivity, used for specialized communication and information retrieval purposes. Currently, IAs exist as webTVs, smart cellular phones with e-mail and web browsing, PDAs, and web phones.
Reference: [65] <author> C. Lee, K. Yoshida, C. Mercer, and R. Rajkumar, </author> <title> "Predictable communication protocol processing in Real-Time Mach," </title> <booktitle> in Proc. Real-Time Technology and Applications Symposium, </booktitle> <pages> pp. 220-229, </pages> <month> June </month> <year> 1996. </year>
Reference-contexts: The send-side architecture is simpler than the receive-side because processing can occur as part of the send system call (as done in <ref> [19, 65, 79] </ref>) and this is the scheme we use as well. However, on the receive-side, protocol processing in general cannot occur at the time of the receive system call since the message may not have arrived yet. <p> When a send system call is made, the application thread enters the kernel, executes all relevant protocol and device driver code, and transfers the data to the NA for transmission. This is similar to the send-side schemes used in <ref> [65, 79] </ref>. The main advantage of LRP is for the receive-side processing. <p> In fact, the need to send timely acknowledgments in protocols such as TCP is the primary reason for having a separate network thread. LRP provides more predictable message handling than other protocol architectures such as the user-level architecture presented in <ref> [65] </ref> which always relies on special network threads for protocol processing. This can lead to priority inversion [82], i.e., handling of a high-priority real-time message (such as live voice) being unnecessarily delayed by the processing of lower-priority or non-real-time messages.
Reference: [66] <author> S. Le*er, M. McKusick, M. Karels, and J. Quarterman, </author> <title> The Design and Implementation of the 4.3BSD UNIX Operating System, </title> <publisher> Addison-Wesley Publishing Company, Inc., </publisher> <year> 1989. </year>
Reference-contexts: In our scheme, packet arrivals trigger interrupts. The device driver executes and forms an mbuf chain of the packets. Mbufs are linked lists of buffers which allow easy addition and removal of headers (see <ref> [66] </ref> for details). Data is left in the NA and the mbufs are made to point to that data. The packet filter then enqueues the mbuf chain in the appropriate socket, and the associated user thread is signaled. <p> Virtual memory page re-mapping is commonly used to reduce data-copying costs when crossing protection boundaries [20]. This technique works well to a certain extent, especially when combined with the mbuf mechanism of BSD <ref> [66] </ref>. Mbufs are linked lists of buffers. To add a header, all that needs to be done is allocate a memory buffer (anywhere in the address space), put the header data in it, and link this buffer at the head of the mbuf chain.
Reference: [67] <author> J. Lehoczky, L. Sha, and Y. Ding, </author> <title> "The rate monotonic scheduling algorithm: exact characterization and average case behavior," </title> <booktitle> in Proc. Real-Time Systems Symposium, </booktitle> <year> 1989. </year>
Reference-contexts: On the other hand, the rate-monotonic (RM) [76] scheme has a much lower run-time overhead since it does not have to repeatedly re-sort the tasks, but on average, it delivers a schedulable utilization of only 88% <ref> [67] </ref>. <p> EDF incurs high run-time overhead in keeping tasks sorted by their (changing) deadlines. When this overhead is taken into consideration, the CPU capacity left for workload tasks is well below 100%. The static RM scheduler has much lower run-time overhead but its average-case schedulable utilization is only 88% <ref> [67] </ref> | well below that for EDF. In practice, neither EDF nor RM deliver good performance. In fact, for many real workloads, performance of both these schedulers is about the same [58]. The recent popularity of multimedia applications has led to renewed interest in making uniprocessor task scheduling efficient. <p> Previous work has shown that on average, U fl = 0:88 for RM <ref> [67] </ref>. To see why U fl for RM is less than that for EDF, consider the workload shown in Table 4.1. Each task t i has deadline d i = P i . <p> The workload is feasible under RM if <ref> [67] </ref> 8i; 1 i n; min 0 i X c j + t (RM ) & P j A 1: In practice, this equation need only be evaluated for a finite number of t values as described in [63]. Schedulability under CSD is tested as follows.
Reference: [68] <author> G. W. Lenhart, </author> <title> "A field bus approach to local control networks," </title> <booktitle> Advances in Instru-mentaion and Control, </booktitle> <volume> vol. 48, no. 1, </volume> <pages> pp. 357-365, </pages> <year> 1993. </year>
Reference-contexts: Buses are preferable to rings, stars, or other point-to-point topologies because they require the least amount of wiring <ref> [68] </ref> which keeps production costs down. Scheduling messages on a field bus is made difficult by the fact that these messages are usually just 5-10 bytes long (which is all that's needed to exchange sensor readings and actuator commands).
Reference: [69] <author> J. Y.-T. Leung and J. Whitehead, </author> <title> "On the complexity of fixed-priority scheduling of periodic, real-time tasks," </title> <journal> Performance Evaluation, </journal> <volume> vol. 2, no. 4, </volume> <pages> pp. 237-250, </pages> <month> December </month> <year> 1982. </year>
Reference-contexts: This predictability is ensured by system-level services, most important among them being the task scheduler in the RTOS. Real-time task scheduling has been focus of active research for several decades <ref> [6, 69, 76, 106] </ref>. This has led to the development of well-known scheduling schemes such as rate-monotonic (RM) [76], earliest-deadline-first (EDF) [76], and deadline-monotonic [69]. <p> Real-time task scheduling has been focus of active research for several decades [6, 69, 76, 106]. This has led to the development of well-known scheduling schemes such as rate-monotonic (RM) [76], earliest-deadline-first (EDF) [76], and deadline-monotonic <ref> [69] </ref>. But in recent years, the focus of research has shifted from uniprocessor task scheduling to scheduling tasks and messages in multiprocessors and distributed systems [2, 54, 117]. Uniprocessor task scheduling is treated as a "solved" problem and research in this area has tapered off. <p> The CSD scheduler maintains two queues of tasks. The first queue is the dynamic-priority (DP) queue which contains tasks to be scheduled by EDF. The second queue is the fixed-priority (FP) queue which contains tasks to be scheduled by RM (or any other fixed-priority scheduler such as deadline-monotonic <ref> [69] </ref>, but for simplicity, we assume RM is the policy used for the FP queue). <p> In this scheme, messages with a shorter period get higher priority than those with longer periods. RM assumes that deadline equals period, which is not always true in reality. Instead of RM, we can use its close relative, deadline monotonic (DM) scheduling <ref> [69] </ref>. With DM, messages with tighter relative deadlines are assigned higher priorities and these priorities form the ID for each message [112, 113]. DM is a simple scheme and is easily implementable on CAN.
Reference: [70] <author> H. Levy and R. Eckhouse, Jr., </author> <title> Computer Programming and Architecture: The VAX-11, </title> <publisher> Digital Press, </publisher> <year> 1980. </year>
Reference-contexts: All but three entries in the first-level page table are null, so only three second-level page 1 Some OSs such as Linux use segment registers present in x86 processors to distinguish unmapped and swapped out pages. The VAX-11 provided a page table length register to achieve the same goal <ref> [70] </ref>. However, such hardware support is not available on many popular processors used in embedded systems such as 680x0, so an alternate scheme is needed in these CPUs. 21 reduce the size of the page table. tables exist.
Reference: [71] <author> T. Lewis, </author> <title> "Information appliances: </title> <journal> Gadget netopia," IEEE Computer, </journal> <volume> vol. 31, no. 1, </volume> <pages> pp. 59-70, </pages> <month> January </month> <year> 1998. </year>
Reference-contexts: Also, the increasing popularity of the Internet has led to a new class of computing/communication devices called information appliances (IAs) <ref> [71] </ref>. IAs are specialized devices with Internet connectivity. Examples include web televisions (webTVs), personal digital assistants (PDAs), web video phones, and digital cellular phones with e-mail and web browsing capabilities. All of these devices (cars, IAs, and home appliances) are consumer products. <p> Also, in this chapter we focused only on improving the semaphore lock operation. In the future, we plan to investigate optimizations related to the release operation to get further improvements in synchronization overheads. 73 CHAPTER 6 END-HOST PROTOCOL PROCESSING ARCHITECTURE Information appliances (IAs) <ref> [64, 71] </ref> are single-user devices with Internet connectivity, used for specialized communication and information retrieval purposes. Currently, IAs exist as webTVs, smart cellular phones with e-mail and web browsing, PDAs, and web phones. <p> First, IAs are specialized devices which perform specific functions and are not meant for general-purpose computing. Second, IAs use simple, low-cost hardware to keep production costs low. For example, the current generation of personal information managers (PIMs) typically use processors running at 16-44 MHz <ref> [71] </ref>. These CPUs are sufficient for the specialized functions supported by IAs. Moreover, low-speed processors consume less power, thus providing longer operation with lighter batteries; both being key requirements for portable IAs.
Reference: [72] <author> J.-P. Li and M. W. </author> <title> Mutka, "Priority based real-time communication for large scale wormhole networks," </title> <booktitle> in Proc. International Parallel Processing Symposium, </booktitle> <pages> pp. 433-438, </pages> <month> April </month> <year> 1994. </year>
Reference-contexts: This results in embedded systems programmers often attempting to improve performance through hand-crafted | thus ad hoc | techniques which not only increases design-time but also tends to be error-prone. Researchers in the past have focused on large-scale applications <ref> [3, 17, 51, 72] </ref> and with good reason: smaller applications used either mechanical or analog electronic control (as in automobiles) or, if using digital control, had a simplistic design where the controller performed only very basic functions (as in various home appliances).
Reference: [73] <author> J. Liebeherr and D. E. Wrege, </author> <title> "Versatile packet multiplexer for quality-of-service networks," </title> <booktitle> in Proc. IEEE International Symposium on High Performance Distributed Computing, </booktitle> <pages> pp. 148-155, </pages> <year> 1995. </year>
Reference-contexts: As such, our scheme is orthogonal to scheduling schemes which handle varying QoS requirements. The two can be combined by using CSD to schedule one or more queues of a QoS scheduler. The rotating-priority-queues (RPQ) scheme <ref> [73, 74] </ref> was also proposed for network scheduling and like CSD, it too attempts to find a middle ground between EDF and static priority schedulers by using multiple queues. Packets within a queue use FIFO ordering but the relative priorities between queues rotate in a fixed way.
Reference: [74] <author> J. Liebeherr, D. E. Wrege, and D. Ferrari, </author> <title> "Exact admission control for networks with a bounded delay service," </title> <journal> IEEE/ACM Trans. Networking, </journal> <volume> vol. 4, no. 6, </volume> <pages> pp. 885-901, </pages> <month> December </month> <year> 1996. </year>
Reference-contexts: As such, our scheme is orthogonal to scheduling schemes which handle varying QoS requirements. The two can be combined by using CSD to schedule one or more queues of a QoS scheduler. The rotating-priority-queues (RPQ) scheme <ref> [73, 74] </ref> was also proposed for network scheduling and like CSD, it too attempts to find a middle ground between EDF and static priority schedulers by using multiple queues. Packets within a queue use FIFO ordering but the relative priorities between queues rotate in a fixed way.
Reference: [75] <editor> J. Liedtke, </editor> <booktitle> "On -kernel construction," in Proc. Symp. Operating Systems Principles, </booktitle> <pages> pp. 237-250, </pages> <month> December </month> <year> 1995. </year>
Reference-contexts: This deals with the OS providing mechanisms which allow the OS to be extended to provide new functionality. Extensibility falls into three broad categories: the microkernel approach <ref> [38, 75] </ref>, the grafting approach [7, 100], and library OSs based on a thin kernel layer which securely exports hardware resources [22, 53].
Reference: [76] <author> C. L. Liu and J. W. Layland, </author> <title> "Scheduling algorithms for multiprogramming in a hard real-time environment," </title> <journal> Journal of the ACM, </journal> <volume> vol. 20, no. 1, </volume> <pages> pp. 46-61, </pages> <month> January </month> <year> 1973. </year> <month> 136 </month>
Reference-contexts: Listed below are brief overviews of the approaches we took to optimize these services and our primary contributions. 14 * Task scheduling: The earliest-deadline-first (EDF) <ref> [76] </ref> scheduling scheme ideally sched-ules workloads with utilizations of up to 100%. But this is a theoretical limit which is not achieved in practice because of the high run-time overhead incurred by EDF in sorting tasks according to deadlines. On the other hand, the rate-monotonic (RM) [76] scheme has a much <p> scheduling: The earliest-deadline-first (EDF) <ref> [76] </ref> scheduling scheme ideally sched-ules workloads with utilizations of up to 100%. But this is a theoretical limit which is not achieved in practice because of the high run-time overhead incurred by EDF in sorting tasks according to deadlines. On the other hand, the rate-monotonic (RM) [76] scheme has a much lower run-time overhead since it does not have to repeatedly re-sort the tasks, but on average, it delivers a schedulable utilization of only 88% [67]. <p> This predictability is ensured by system-level services, most important among them being the task scheduler in the RTOS. Real-time task scheduling has been focus of active research for several decades <ref> [6, 69, 76, 106] </ref>. This has led to the development of well-known scheduling schemes such as rate-monotonic (RM) [76], earliest-deadline-first (EDF) [76], and deadline-monotonic [69]. <p> This predictability is ensured by system-level services, most important among them being the task scheduler in the RTOS. Real-time task scheduling has been focus of active research for several decades [6, 69, 76, 106]. This has led to the development of well-known scheduling schemes such as rate-monotonic (RM) <ref> [76] </ref>, earliest-deadline-first (EDF) [76], and deadline-monotonic [69]. But in recent years, the focus of research has shifted from uniprocessor task scheduling to scheduling tasks and messages in multiprocessors and distributed systems [2, 54, 117]. <p> Real-time task scheduling has been focus of active research for several decades [6, 69, 76, 106]. This has led to the development of well-known scheduling schemes such as rate-monotonic (RM) <ref> [76] </ref>, earliest-deadline-first (EDF) [76], and deadline-monotonic [69]. But in recent years, the focus of research has shifted from uniprocessor task scheduling to scheduling tasks and messages in multiprocessors and distributed systems [2, 54, 117]. Uniprocessor task scheduling is treated as a "solved" problem and research in this area has tapered off. <p> Each task t i has a period P i , execution time c i , and deadline d i . Then this workload has utilization U = P n i=1 c i =P i . EDF is a dynamic-priority scheduler which gives highest priority to the earliest-deadline task <ref> [76] </ref>, and can schedule all workloads with U 1 under the ideal condition that EDF's run-time overhead is ignored. We say that U fl = 1 for EDF. Other schedulers such as RM (which schedules tasks according to fixed priorities based on the tightness of their P i [76]) can have <p> earliest-deadline task <ref> [76] </ref>, and can schedule all workloads with U 1 under the ideal condition that EDF's run-time overhead is ignored. We say that U fl = 1 for EDF. Other schedulers such as RM (which schedules tasks according to fixed priorities based on the tightness of their P i [76]) can have U fl &lt; 1. For example, a workload with U = 0:90 may be schedulable under RM, but if some c i is slightly increased so that U becomes 0:91, the workload may no longer be schedulable even under ideal conditions. <p> Considering that CSD has no schedulability overhead, it easily outperforms both EDF and RM. 4.2.5 Schedulability Test A task set ft i : i = 1; 2; : : :; ng with tasks sorted by their RM-priority (tasks with shorter periods have lower index i) is feasible under EDF if <ref> [76] </ref> U = i=1 P i where t (EDF ) is t for EDF. <p> A 1; where the function dxe fl excludes the last invocation of j released before time t if its deadline exceeds d i : ~ P k = &lt; l P k t m l P k 1 otherwise This test for DP2 tasks uses the critical time zone assumption <ref> [76] </ref> which is valid only if all DP1 and DP2 tasks have utilization 1 ( P r c i +t (X) DP1 or DP2 task, respectively). Note that because of the check for deadlines, the critical time zone assumption is not automatically valid here as it is under rate-monotonic analysis. <p> RPQ achieves this by coarse-grained deadline quantization and using FIFO ordering for all packets with the same quantized deadline. This lowers hardware costs but can degrade schedulability significantly. Liu and Layland in their seminal paper <ref> [76] </ref> also proposed combining EDF and RM. Their motivation was to exploit fixed CPU interrupt priorities to schedule short-period tasks while using a software EDF scheduler for long-period tasks. High-priority tasks get scheduled by fixed-priority scheduling (using hardware mechanisms) while low-priority tasks are scheduled using software deadline-driven scheduling. <p> The most popular form of fixed-priority real-time scheduling is rate monotonic (RM) <ref> [76] </ref>. In this scheme, messages with a shorter period get higher priority than those with longer periods. RM assumes that deadline equals period, which is not always true in reality. Instead of RM, we can use its close relative, deadline monotonic (DM) scheduling [69]. <p> MTS's performance also drops but not as much as that of DM. This affirms that deadline-based schemes are more capable of handling sporadic messages. Increasing the number of sporadic messages increases the load at the critical instant (using Liu and Layland's terminology <ref> [76] </ref>), even though overall workload utilization is almost unchanged.
Reference: [77] <author> C. D. Locke, D. Vogel, L. Lucas, and J. Goodenough, </author> <title> "Generic avionics software spec-ification," </title> <type> Technical Report CMU/SEI-90-TR-8, </type> <institution> Carnegie Mellon University, </institution> <year> 1990. </year>
Reference-contexts: When we look at workloads of typical real-time control applications, we find that there is indeed a great variation between periods of various tasks (and a corresponding variation in periods/deadlines of messages sent by these tasks). The well-known avionics task workload <ref> [77, 78] </ref> is accepted as typifying real-time control 117 applications and also has been used by others for research on real-time scheduling [56]. The workload is reproduced in Table 7.2.
Reference: [78] <author> C. D. Locke, D. Vogel, and T. Mesler, </author> <title> "Building a predictable avionics plarform in Ada: A case study," </title> <booktitle> in Proc. Real-Time Systems Symposium, </booktitle> <pages> pp. 181-189, </pages> <year> 1991. </year>
Reference-contexts: When we look at workloads of typical real-time control applications, we find that there is indeed a great variation between periods of various tasks (and a corresponding variation in periods/deadlines of messages sent by these tasks). The well-known avionics task workload <ref> [77, 78] </ref> is accepted as typifying real-time control 117 applications and also has been used by others for research on real-time scheduling [56]. The workload is reproduced in Table 7.2.
Reference: [79] <author> C. Maeda and B. Bershad, </author> <title> "Protocol service decomposition for high-performance networking," </title> <booktitle> in Proc. Symp. Operating Systems Principles, </booktitle> <pages> pp. 244-255, </pages> <month> December </month> <year> 1993. </year>
Reference-contexts: The architecture must be able to efficiently handle not only long messages (such as video) but also short, frequent ones (such as live audio). Also, studies have shown that receive-side protocol processing overhead is higher than send-side overhead <ref> [55, 57, 79] </ref> and this is what limits throughput; so, we focus on improving receive-side overhead while ensuring predictability. Local Message-Passing The traditional mechanism for exchange of information between tasks is message-passing using mailboxes. <p> With messages arriving with such high frequency, non-data-touching overheads (context switching, interrupt handling, I-cache miss overheads, etc.) become an important part of protocol processing. Studies have shown that receive-side protocol processing is more complicated and has higher overhead than the send-side <ref> [55, 57, 79] </ref> and this is what limits throughput; so, here we focus on improving receive-side overhead. <p> The send-side architecture is simpler than the receive-side because processing can occur as part of the send system call (as done in <ref> [19, 65, 79] </ref>) and this is the scheme we use as well. However, on the receive-side, protocol processing in general cannot occur at the time of the receive system call since the message may not have arrived yet. <p> When a send system call is made, the application thread enters the kernel, executes all relevant protocol and device driver code, and transfers the data to the NA for transmission. This is similar to the send-side schemes used in <ref> [65, 79] </ref>. The main advantage of LRP is for the receive-side processing.
Reference: [80] <institution> Manufacturing Automation Protocol (MAP) 3.0 Implementation Release, MAP/TOP Users Group, </institution> <year> 1987. </year>
Reference-contexts: These issues are discussed next. Field Bus Scheduling: The recent proliferation of embedded systems has resulted in many network protocols being designed specifically to satisfy the real-time control requirements of embedded systems. These protocols include the Controller Area Network (CAN) [47], Profibus [32], FIP [28], SP-50 [44], MAP/TOP <ref> [80] </ref>, SERCOS [46], and TTP [61]. All these protocols are known by the general name of field bus because they are meant to control the so-called field devices (sensors and actuators) and all of them have a bus topology. <p> These systems consist of multiple computational nodes, sensors, and actuators interconnected by a low-speed LAN called a field bus [94]. Of the multiple field bus protocols available for such use (including SP-50 FieldBus [44], MAP <ref> [80] </ref>, TTP [61], etc.), the Controller Area Network (CAN) [49, 104] has gained wide-spread acceptance in the industry [118]. CAN is a contention-based multi-master network which has the potential to efficiently handle both periodic as well as sporadic messages.
Reference: [81] <author> J. Mellor-Crummey and M. Scott, </author> <title> "Algorithms for scalable synchronization on shared-memory multiprocessors," </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> vol. 9, no. 1, </volume> <pages> pp. 21-65, </pages> <month> February </month> <year> 1991. </year>
Reference-contexts: However, for simplicity, we concern ourselves only with semaphores in this chapter. 56 Most research in the area of reducing task synchronization overhead has focused on multiprocessors <ref> [81, 116] </ref>. But our target architectures are either uniprocessor (as in home appliances) or very loosely-coupled distributed systems (as in automotive applications). Even with the latter, threads typically do not need to access remote objects, so our concern is only with improving task synchronization performance for a single processor.
Reference: [82] <author> C. Mercer and H. Tokuda, </author> <title> "An evaluation of priority consistency in protocol architectures," </title> <booktitle> in Proc. IEEE Conf. Local Computer Networks, </booktitle> <pages> pp. 386-398, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: End-Host Protocol Processing: Because of their web-centric nature, an efficient communication subsystem is an important part of an IA OS. The communication subsystem must efficiently and predictably handle both audio as well as video communication. Predictability is needed to ensure timely processing of incoming and outgoing messages <ref> [82] </ref>. The protocol architecture must provide mechanisms to guarantee that high-priority real-time messages (such as live voice) do not get unnecessarily delayed by the processing of lower-priority or non-real-time messages. At the same time, the protocol architecture must provide for efficient execution of protocol code. <p> LRP provides more predictable message handling than other protocol architectures such as the user-level architecture presented in [65] which always relies on special network threads for protocol processing. This can lead to priority inversion <ref> [82] </ref>, i.e., handling of a high-priority real-time message (such as live voice) being unnecessarily delayed by the processing of lower-priority or non-real-time messages.
Reference: [83] <author> B. Meyer, </author> <title> Object-Oriented Software Construction, </title> <publisher> Prentice-Hall, </publisher> <year> 1988. </year>
Reference-contexts: The advent of Java and increasing use of C++ has made OO programming important for embedded systems. OO design gives benefits such as reduced software design time and software re-use <ref> [83] </ref>. But with these benefits comes the extra cost of ensuring mutual exclusion when an object's internal state is updated. Semaphores 1 [18, 36] are typically used to provide this mutual exclusion.
Reference: [84] <author> J. Mogul, R. Rashid, and M. Accetta, </author> <title> "The packet filter: An efficient mechanism for user-level network code," </title> <booktitle> in Proc. Symp. Operating Systems Principles, </booktitle> <pages> pp. 39-51, </pages> <month> November </month> <year> 1987. </year>
Reference-contexts: This is similar to the send-side schemes used in [65, 79]. The main advantage of LRP is for the receive-side processing. Under LRP, incoming 79 packets trigger interrupts which cause the device driver to execute and it passes packets on to the packet filter <ref> [23, 84] </ref>. (The packet filter is a small piece of code which is dynamically installed in the kernel by individual applications to detect packets belonging to those applications and take appropriate actions.) The filter tries to forward packets directly to queues associated with the destination thread where packets stay unprocessed until <p> In [20] an optimization is presented in which mappings are cached to reduce overhead significantly. This works reasonably well for transmission, but works for reception only if the network protocol allows packet-level demultiplexing at the device driver level. Low-level message demultiplexing is quite common by means of packet filters <ref> [84] </ref> but it requires the first packet of a message to arrive before the message's final destination can be determined. If packets get re-ordered, then packet-level demultiplexing is possible only if the network is connection-based such as ATM.
Reference: [85] <author> A. K. Mok, </author> <title> "Fundamental design problems of distributed systems for the hard real-time environment," </title> <type> Ph.D thesis, </type> <year> 1983. </year>
Reference-contexts: This corresponds to a minimum interarrival time (MIT) for such messages. Such aperiodic messages which have a MIT are called sporadic messages <ref> [85] </ref>. Knowing the MIT of a sporadic message makes it possible to guarantee its delivery even under the worst possible situation. 7.2.3 Non-Real-Time Messages In automotive systems, a monitoring process needs to collect status information from various controllers for on-board diagnostic purposes.
Reference: [86] <author> D. Mosberger, L. L. Peterson, P. G. Bridges, and S. O'Malley, </author> <title> "Analysis of techniques to improve protocol processing latency," </title> <booktitle> in Proc. SIGCOMM, </booktitle> <pages> pp. 73-84, </pages> <month> August </month> <year> 1996. </year>
Reference-contexts: As a result, 76 if (check1) - ... if (check2) - ... if (check3) - ... researchers attempted to minimize such overheads by various means. In <ref> [86] </ref>, techniques called outlining and cloning are presented in which frequently-executed paths through the protocol stack are identified (by studying the protocol code), and this information is passed to the compiler which places code in memory to minimize I-cache misses for these paths.
Reference: [87] <author> M68040 User's Manual, Motorola Inc., </author> <year> 1992. </year>
Reference-contexts: In particular, we want to know which is the best scheduler when all scheduling overheads (run-time and schedulability) are considered. The EDF and RM run-time overheads for EMERALDS measured on a 25MHz Motorola 68040 processor <ref> [87] </ref> with separate 4kbytes instruction and data caches are in Table 4.3. The run-time overhead of CSD is derived from these values as already discussed in Sections 4.2.4 and 4.3.2. <p> behave just like standard implementation semaphores, but we do not believe this will be needed very often, if at all. 5.5 Performance Evaluation To measure the improvement in performance resulting from our new semaphore scheme, we implemented it under EMERALDS and measured performance on a 25 MHz Motorola 68040 processor <ref> [87] </ref>. When a thread enters an object, it first acquires the semaphore protecting the object, and when it exits the object, it releases the semaphore. The cumulative time spent in these two operations represents the overhead associated with synchronizing thread access to objects.
Reference: [88] <author> MC68336/376 User's Manual, Motorola Inc., </author> <year> 1996. </year>
Reference-contexts: Since high-speed messages have shorter deadlines than low-speed ones, they will automatically have higher DM priority (which is exactly what we want). 7.4 Implementation In this section, we present schemes to implement MTS on Motorola's TouCAN module <ref> [88] </ref> which features 16 message buffers and internal arbitration between transmission buffers based on message ID. As such, TouCAN is representative of modern CAN NAs. <p> TouCAN lies on the same chip as the CPU and is interconnected to the CPU (and other on-chip modules) through Motorola's intermodule bus. Motorola is currently marketing the MC68376 <ref> [88] </ref> microcontroller which incorporates TouCAN with a CPU32 core. TouCAN has 16 message buffers. Each buffer can be configured to either transmit or receive messages.
Reference: [89] <institution> OSEK/VDX Operating System Specification 2.0, OSEK Group, </institution> <year> 1997. </year> <note> Revision 1. </note>
Reference-contexts: Ford evaluated performance of EMERALDS on these microcontrollers and compared it to several commercial small RTOSs. Results of these evaluations showed EMERALDS to have superior performance (see Chapter 3). Moreover, EMERALDS was also modified to conform to the OSEK automotive OS standard <ref> [89] </ref> and ported to the Hitachi SH-2 processor in a joint project with Hitachi Research Lab. 1.3 Outline of the Dissertation The remainder of this dissertation is organized as follows. <p> Previous work in improving semaphore performance has focused on either relaxing the semaphore semantics to get better performance [111], coming up with new semantics and new synchronization policies [114], or putting restrictions on the application programmer to disallow certain actions (such as making blocking system calls) while holding a semaphore <ref> [89] </ref>. The problem with these approaches is that these new/modified semantics may be suit 15 able for some particular applications but usually they do not have wide applicability. <p> Previous work in this area has focused on either relaxing the semaphore semantics to get better performance [111], coming up with new semantics and new synchronization policies [114], or putting restrictions on the application programmer to disallow certain operations (such as making blocking system calls) while holding a semaphore <ref> [89] </ref>. The problem with this approach is that these new/modified semantics may be suitable for some particular applications but usually they do not have wide applicability.
Reference: [90] <author> V. Paxson and S. Floyd, </author> <title> "Wide area traffic: The failure of poisson modeling," </title> <journal> IEEE/ACM Trans. Networking, </journal> <volume> vol. 3, no. 3, </volume> <pages> pp. 226-244, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: This reduces the complexity of network traffic analysis because of the simplicity of Poisson processes. However, various studies have shown that wide-area network traffic is too bursty to be correctly modeled by a Poisson process <ref> [16, 90] </ref>. Telnet arrivals have been modeled by a Pareto distribution [90], but only empirical models exist for FTP [16] and web browsing [13, 14]. This precludes any closed-form derivation of non-real-time packet arrival distributions. <p> This reduces the complexity of network traffic analysis because of the simplicity of Poisson processes. However, various studies have shown that wide-area network traffic is too bursty to be correctly modeled by a Poisson process [16, 90]. Telnet arrivals have been modeled by a Pareto distribution <ref> [90] </ref>, but only empirical models exist for FTP [16] and web browsing [13, 14]. This precludes any closed-form derivation of non-real-time packet arrival distributions. Added to this is yet another difficulty that network traffic characteristics may change from time to time or place to place.
Reference: [91] <author> P. Pleinevaux and J. D. Decotignie, </author> <title> "Time critical communication networks: field buses," </title> <journal> IEEE Network, </journal> <volume> vol. 2, no. 3, </volume> , <month> May </month> <year> 1988. </year>
Reference-contexts: Another factor contributing to this rapidly increasing complexity is networking. More and more embedded devices are connected to the Internet (such as web TVs and cellular phones). Also, applications which have multiple controllers (such as automobiles) now have these controllers interconnected by a field bus <ref> [10, 91] </ref> (local area networks (LANs) specially designed for real-time control applications) to allow the controllers to coordinate their activities, thus providing new features and better performance. The increased complexity of today's embedded systems 1 necessitates that an RTOS be used to manage various resources (Figure 1.2-b).
Reference: [92] <author> S. Poledna, T. Mocken, and J. Schiemann, "ERCOS: </author> <title> an operating system for automotive applications," </title> <booktitle> in SAE International Congress and Exposition, </booktitle> <pages> pp. 55-65, </pages> <month> February </month> <year> 1996. </year> <type> SAE Technical Paper Series 960623. </type>
Reference-contexts: Hence, state messages do not replace traditional message passing for all situations, but they do replace it for most inter-task communication requirements in embedded applications. Previous Work State messages were first used in the MARS OS [60] and have also been implemented in ERCOS <ref> [92] </ref>. The state message implementation used in these systems as described in [62] is as follows. The problem with using global variables for passing messages is that a reader may read a half-written message since there is no synchronization between readers and writers. <p> Increasing the number of queues gives some further improvement in performance, but the schedulability overhead starts increasing rapidly so that using more than three queues yields only a minimal improvement in performance. 53 4.5 Related Work Using multiple scheduling queues is not a new idea. The ERCOS task scheduler <ref> [92] </ref> uses separate queues for preemptive and non-preemptive tasks. Multiple queues are used in network scheduling to combine different types of traffic on the same link in a switched network [26, 27, 54].
Reference: [93] <author> C. Pu, T. Autrey, A. Black, C. Consel, C. Cowan, J. Inouye, L. Kethana, J. Walpole, and K. Zhang, </author> <title> "Optimistic incremental specialization: Streamlining a commercial operating system," </title> <booktitle> in Proc. Symp. Operating Systems Principles, </booktitle> <pages> pp. 314-324, </pages> <month> December </month> <year> 1995. </year>
Reference-contexts: In [86], techniques called outlining and cloning are presented in which frequently-executed paths through the protocol stack are identified (by studying the protocol code), and this information is passed to the compiler which places code in memory to minimize I-cache misses for these paths. In <ref> [93] </ref>, incremental specialization is presented in which special code optimized for the common case is used whenever possible. The system includes a number of checks which cause a switch to the code which handles the fully general case if the special case no longer applies.
Reference: [94] <author> R. S. Raji, </author> <title> "Smart networks for control," </title> <journal> IEEE Spectrum, </journal> <volume> vol. 31, no. 6, </volume> <pages> pp. 49-55, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: IAs communicate through wireless networks or over phone lines, so the network bandwidth available to them is much less than that available to desktop workstations. Similarly, the field bus networks are of low bandwidth, usually 1-3 Mbits/s <ref> [94] </ref>: on one hand this keeps costs down and on the other, this is all the bandwidth that is really needed to exchange short messages of sensor readings and actuator commands. This gives embedded systems a very different "flavor" than larger applications with faster processors and networks. <p> In this chapter, we address communication issues related to another important class of embedded systems which are fieldbus-based such as automotive and factory automation systems. These systems consist of multiple computational nodes, sensors, and actuators interconnected by a low-speed LAN called a field bus <ref> [94] </ref>. Of the multiple field bus protocols available for such use (including SP-50 FieldBus [44], MAP [80], TTP [61], etc.), the Controller Area Network (CAN) [49, 104] has gained wide-spread acceptance in the industry [118].
Reference: [95] <author> K. Ramamritham and J. A. Stankovic, </author> <title> "Scheduling algorithms and operating systems support for real-time systems," </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> vol. 82, no. 1, </volume> <pages> pp. 55-67, </pages> <month> January </month> <year> 1994. </year>
Reference-contexts: But the embedded systems of today (Figure 1.1) tend to be networked, run application code written in object-oriented (OO) languages such as Java, execute an increasing number of complex tasks, and need real-time operating system (RTOS) <ref> [95] </ref> support | either to handle audio/video or to interact with the environment. The challenge is to provide a functionally-rich operating system (OS) able to support these new applications while keeping OS overheads to a minimum.
Reference: [96] <author> A. Reibman and A. Berger, </author> <title> "Traffic descriptions for VBR video teleconferencing over ATM networks," </title> <journal> IEEE/ACM Trans. Networking, </journal> <volume> vol. 3, no. 3, </volume> <pages> pp. 329-339, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: T for audio is quite short, usually 10-30ms [98], so audio is not a problem. Video applications usually run at 30 frames/s <ref> [96] </ref> but to conserve CPU and network bandwidth | which is important in IAs | some may run at a slower rate of 20 or even 10 frames/s, giving a T as large as 0.1s.
Reference: [97] <author> D. C. Schmidt and T. Suda, </author> <title> "Transport system architecture services for high-performance communications systems," </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> vol. 11, no. 4, </volume> <pages> pp. 489-506, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: The protocol code was taken from FreeBSD 4.4 and minor modifications were made to make it work with our protocol architecture. 6.2 Protocol Architecture Issues Network protocol architecture has been an active area of research for many years <ref> [41, 97] </ref> and various techniques have been proposed to make protocol processing efficient.
Reference: [98] <author> H. Schulzrinne, </author> <title> "RTP profile for audio and video conferences with minimal control," </title> <type> RFC 1890, </type> <month> January </month> <year> 1996. </year>
Reference-contexts: Data-touching overheads (which include data copying and checksum overheads) tend to dominate when dealing with long messages. For short (audio) messages, the message size is just tens of bytes (so copying overheads are not important), but messages are sent once every 10-30ms <ref> [98] </ref>. With messages arriving with such high frequency, non-data-touching overheads (context switching, interrupt handling, I-cache miss overheads, etc.) become an important part of protocol processing. <p> T for audio is quite short, usually 10-30ms <ref> [98] </ref>, so audio is not a problem. Video applications usually run at 30 frames/s [96] but to conserve CPU and network bandwidth | which is important in IAs | some may run at a slower rate of 20 or even 10 frames/s, giving a T as large as 0.1s.
Reference: [99] <author> J. Scourias, </author> <title> "Overview of the Global System for Mobile Communications," </title> <address> http://ccnga.uwaterloo.ca/~jscouria/GSM/gsmreport.html. </address>
Reference-contexts: The subsystem must be structured to handle both short as well as long messages with minimal overhead. Handling short messages efficiently is important for applications such as Internet telephony where live voice packets are usually just 30-50 bytes (as in the GSM audio encoding scheme <ref> [99] </ref> used in various Internet phones). On the other hand, video applications exchange long messages (10-15 kbytes [25]) and these must be handled efficiently as well. <p> The subsystem must be structured to handle both short as well as long messages with minimal overhead. Handling short messages efficiently is important for applications such as Internet telephony where live voice packets are usually just 30-50 bytes (as in the GSM audio encoding scheme <ref> [99] </ref> used in various Internet phones). On the other hand, video applications exchange long messages (10-15 kbytes [25]) and these too must be handled efficiently. Different overheads come into play depending on whether short or long messages are being processed.
Reference: [100] <author> M. Seltzer, Y. Endo, C. Small, and K. Smith, </author> <title> "Dealing with disaster: Surviving misbehaving kernel extensions," </title> <booktitle> in Proc. Operating System Design and Implementation, </booktitle> <month> October </month> <year> 1996. </year>
Reference-contexts: This deals with the OS providing mechanisms which allow the OS to be extended to provide new functionality. Extensibility falls into three broad categories: the microkernel approach [38, 75], the grafting approach <ref> [7, 100] </ref>, and library OSs based on a thin kernel layer which securely exports hardware resources [22, 53].
Reference: [101] <author> L. Sha, R. Rajkumar, and J. Lehoczky, </author> <title> "Priority inheritance protocols: An approach to real-time synchronization," </title> <journal> IEEE Trans. on Computers, </journal> <volume> vol. 39, no. 3, </volume> <pages> pp. 1175-1198, </pages> <year> 1990. </year>
Reference-contexts: The problem with these approaches is that these new/modified semantics may be suit 15 able for some particular applications but usually they do not have wide applicability. We took the approach of providing full semaphore semantics (with priority inheritance <ref> [101] </ref>), but optimizing the implementation of these semaphores by exploiting certain features of embedded applications [126]. We rely on the fact that the order in which embedded applications access objects (which is the same as the order in which semaphores are used) can be determined at compile-time. <p> The problem with this approach is that these new/modified semantics may be suitable for some particular applications but usually they do not have wide applicability. We took the approach of providing full semaphore semantics (with priority inheritance <ref> [101] </ref>), but optimizing the implementation of these semaphores by exploiting certain features of embedded applications [126]. As a result, our semaphore scheme has wide applicability within the domain of embedded applications, while significantly improving performance over standard implementation methods for semaphores. <p> will use characteristics common to embedded applications. 5.3.1 Standard Semaphore Implementation The standard procedure to lock a semaphore can be summarized as follows: if (sem locked) - do priority inheritance; add caller thread to wait queue; block; /* wait for sem to be released */ - lock sem; Priority inheritance <ref> [101] </ref> is needed in real-time systems to avoid unbounded priority inversion [114]. If a high-priority thread T h calls sem lock () on a semaphore already locked by a low-priority thread T l , the latter's priority is temporarily increased to that of the former. <p> Other than that, implementing DM on TouCAN is no different than implementing MTS. 7.4.5 Preemption as a Mechanism for Controlling Priority Inversion In CPU scheduling, priority inheritance <ref> [101] </ref> is a well-known mechanism for handling priority inversion between threads of execution. If a low-priority thread holds a resource needed by a high-priority thread, the former's priority is temporarily increased to that of the latter until the resource is released.
Reference: [102] <author> K. G. Shin, </author> <title> "Real-time communications in a computer-controlled workcell," </title> <journal> IEEE Trans. Robotics and Automation, </journal> <volume> vol. 7, no. 1, </volume> <pages> pp. 105-113, </pages> <month> February </month> <year> 1991. </year>
Reference-contexts: Previous work regarding scheduling such messages on CAN includes [112, 113], but they focused on fixed-priority scheduling. Shin <ref> [102] </ref> considered earliest-deadline first (EDF) scheduling, but did not consider its high overhead which makes 95 EDF impractical for CAN. <p> Our goal is therefore to make the IDs reflect the deadlines of messages. Moreover, each message must have a unique ID (which is a requirement of CAN). This can be done by dividing the ID into three fields <ref> [102] </ref>, as shown in Figure 7.2. The deadline field is derived from the deadline of the message. Actually, it is the logical inverse of the deadline because we want the shortest deadline to have the highest priority. <p> If two messages have the same deadline, the one with the higher uniqueness code will win. This uniqueness code also serves to identify the message for reception purposes. For EDF scheduling, messages may be assigned codes arbitrarily as long as they are unique for each message <ref> [102] </ref>. However, as we will see later, the question of assigning uniqueness codes will be critical in MTS. In Figure 7.2, the priority field is a single bit used to distinguish real-time and non-real-time messages. It is 1 for real-time messages and 0 otherwise. <p> As time progresses, absolute message deadlines (i.e., logical inverse of the actual deadlines) get larger and larger. Eventually, they will require more bits than are available in the CAN ID field. The obvious solution is to use slack time <ref> [102] </ref> (time to deadline) instead of 102 the deadline itself, but this introduces two other problems: P1. Remaining slack time of a message changes with every clock tick. This will require IDs of all messages to be updated continually (at the start of each arbitration round).
Reference: [103] <author> K. G. Shin and P. Ramanathan, </author> <title> "Real-time computing: a new discipline of computer science and engineering," </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> vol. 82, no. 1, </volume> <pages> pp. 6-24, </pages> <month> January </month> <year> 1994. </year>
Reference-contexts: INTRODUCTION Real-time computing <ref> [103, 108] </ref> deals with predictable and timely execution of tasks to meet application-specific timing constraints. In the past, real-time computing focused almost exclusively on large and expensive projects related to avionics, space, and defense applications. <p> goal, we made use of several features of embedded systems which allowed us to increase the efficiency of system calls and keep the size of EMERALDS to just 13 kbytes (uniprocessor version). 36 CHAPTER 4 COMBINED EDF AND RM SCHEDULING Real-time computing systems must behave predictably even in unpredictable environments <ref> [103] </ref>. This predictability is ensured by system-level services, most important among them being the task scheduler in the RTOS. Real-time task scheduling has been focus of active research for several decades [6, 69, 76, 106].
Reference: [104] <editor> SAE Handbook, </editor> <booktitle> Society of Automotive Engineers, </booktitle> <year> 1995. </year> <pages> pp. </pages> <month> 23.560-23.573. </month>
Reference-contexts: These systems consist of multiple computational nodes, sensors, and actuators interconnected by a low-speed LAN called a field bus [94]. Of the multiple field bus protocols available for such use (including SP-50 FieldBus [44], MAP [80], TTP [61], etc.), the Controller Area Network (CAN) <ref> [49, 104] </ref> has gained wide-spread acceptance in the industry [118]. CAN is a contention-based multi-master network which has the potential to efficiently handle both periodic as well as sporadic messages. <p> Section 7.4 discusses issues related to implementation of MTS, focusing on the priority inversion problem. Section 7.5 evaluates the network schedulability performance of MTS (compared to EDF and DM) and presents implementation overhead measurements. The chapter concludes with Section 7.6. 7.1 Controller Area Network (CAN) CAN <ref> [49, 104] </ref> is an advanced serial communication protocol for distributed real-time control systems. It is a contention-based multi-master network whose timeliness properties come from its collision resolution algorithm.
Reference: [105] <author> J. D. Solomon, </author> <title> Mobile IP, the Internet Unplugged, </title> <publisher> Prentice Hall, </publisher> <year> 1998. </year>
Reference-contexts: Communication support for portable devices: The current paradigm for a portable device (such as a PDA) to connect to the Internet is to use a cellular phone to connect to a fixed Internet host which provides access to the rest of the Internet. Even mobile IP <ref> [105] </ref> relies on a home agent (which is an IP host residing on the home subnetwork of the mobile host) to forward IP packets to the mobile host. These extra hops increase network traffic.
Reference: [106] <author> B. Sprunt, L. Sha, and J. Lehoczky, </author> <title> "Aperiodic task scheduling for hard-real-time systems," </title> <booktitle> Real-Time Systems, </booktitle> <volume> vol. 1, no. 1, </volume> <pages> pp. 27-60, </pages> <month> June </month> <year> 1989. </year>
Reference-contexts: This predictability is ensured by system-level services, most important among them being the task scheduler in the RTOS. Real-time task scheduling has been focus of active research for several decades <ref> [6, 69, 76, 106] </ref>. This has led to the development of well-known scheduling schemes such as rate-monotonic (RM) [76], earliest-deadline-first (EDF) [76], and deadline-monotonic [69]. <p> These schedulers do not require any costly off-line analysis, can easily handle changes in the workload during the design process, and can handle aperiodic tasks as well using, for example, a sporadic server <ref> [106] </ref>. However, since priority-driven schedulers make run-time scheduling decisions, they incur overhead which 39 can be 5-15% of CPU time.
Reference: [107] <author> J. Stankovic, K. Ramamritham, and S. Cheng, </author> <title> "Evaluation of a bidding algorithm for real-time distributed systems," </title> <journal> IEEE Trans. on Computers, </journal> <volume> vol. C.34, no. 12, </volume> , <month> December </month> <year> 1985. </year>
Reference-contexts: Examples of middleware services include reliable/atomic multicast [1, 37], consistent event ordering [12, 59, 123], and task allocation in a parallel/distributed environment <ref> [107] </ref>. At present, embedded systems used in consumer items are not complex enough to require middleware services.
Reference: [108] <author> J. Stankovic, </author> <title> "Misconceptions about real-time computing," </title> <journal> IEEE Computer, </journal> <volume> vol. 21, no. 10, </volume> <pages> pp. 10-19, </pages> <month> October </month> <year> 1988. </year>
Reference-contexts: INTRODUCTION Real-time computing <ref> [103, 108] </ref> deals with predictable and timely execution of tasks to meet application-specific timing constraints. In the past, real-time computing focused almost exclusively on large and expensive projects related to avionics, space, and defense applications.
Reference: [109] <author> J. Stankovic and K. Ramamritham, </author> <title> "The Spring Kernel: a new paradigm for real-time operating systems," </title> <journal> ACM Operating Systems Review, </journal> <volume> vol. 23, no. 3, </volume> <pages> pp. 54-71, </pages> <month> July </month> <year> 1989. </year> <month> 138 </month>
Reference-contexts: of RTOSs have been designed to date which provide a predictable platform for task execution and inter-process 1 From here on, we use the term embedded system to mean consumer item embedded system, unless stated otherwise. 4 communication, but most of these RTOSs like Alpha [51] and the Spring Kernel <ref> [109] </ref> were designed for large parallel and distributed systems with powerful processors and fast interconnection networks. <p> for (;;) - obj_1.method // protected by sem S1 obj_2.method // protected by sem S2 ... obj_n.method // protected by sem Sn block (..., S1, S2, ..., Sn); - This is somewhat similar to the Spring kernel's notion of reserving all resources a task needs before letting the task execute <ref> [109] </ref>, but with an important difference: the Spring kernel executes tasks non-preemptively while under our proposal, threads execute preemptively.
Reference: [110] <author> W. R. Stevens, </author> <title> Advanced Programming in the UNIX Environment, </title> <publisher> Addison-Wesley, </publisher> <year> 1992. </year>
Reference-contexts: When processes no longer need a segment, they call shm detach (). These calls unmap the segment from their address space, except the last call which also frees up the physical memory. These semantics are easier to use than, for example, UNIX <ref> [110] </ref> semantics where shared memory must be explicitly created before mapping it into an address space, and must be explicitly deleted after unmapping it from each address space. 3.5 Miscellaneous OS Services 3.5.1 Semaphores Threads often need to ensure mutual exclusion when accessing critical regions of code dealing with shared resources.
Reference: [111] <author> H. Takada and K. Sakamura, </author> <title> "Experimental implementations of priority inheritance semaphore on ITRON-specification kernel," </title> <booktitle> in 11th TRON Project International Symposium, </booktitle> <pages> pp. 106-113, </pages> <year> 1994. </year>
Reference-contexts: Note that an efficient semaphore scheme is useful not only for OO programming but for any application requiring synchronization between multiple threads of execution. Previous work in improving semaphore performance has focused on either relaxing the semaphore semantics to get better performance <ref> [111] </ref>, coming up with new semantics and new synchronization policies [114], or putting restrictions on the application programmer to disallow certain actions (such as making blocking system calls) while holding a semaphore [89]. <p> Even with the latter, threads typically do not need to access remote objects, so our concern is only with improving task synchronization performance for a single processor. Previous work in this area has focused on either relaxing the semaphore semantics to get better performance <ref> [111] </ref>, coming up with new semantics and new synchronization policies [114], or putting restrictions on the application programmer to disallow certain operations (such as making blocking system calls) while holding a semaphore [89].
Reference: [112] <author> K. Tindell, A. Burns, and A. J. Wellings, </author> <title> "Calculating Controller Area Network (CAN) message response times," </title> <journal> Control Engineering Practice, </journal> <volume> vol. 3, no. 8, </volume> <pages> pp. 1163-1169, </pages> <year> 1995. </year>
Reference-contexts: Previous work regarding scheduling such messages on CAN includes <ref> [112, 113] </ref>, but they focused on fixed-priority scheduling. Shin [102] considered earliest-deadline first (EDF) scheduling, but did not consider its high overhead which makes 95 EDF impractical for CAN. <p> RM assumes that deadline equals period, which is not always true in reality. Instead of RM, we can use its close relative, deadline monotonic (DM) scheduling [69]. With DM, messages with tighter relative deadlines are assigned higher priorities and these priorities form the ID for each message <ref> [112, 113] </ref>. DM is a simple scheme and is easily implementable on CAN.
Reference: [113] <author> K. W. Tindell, H. Hansson, and A. J. Wellings, </author> <title> "Analyzing real-time communications: Controller Area Network (CAN)," </title> <booktitle> in Proc. Real-Time Systems Symposium, </booktitle> <pages> pp. 259-263, </pages> <month> December </month> <year> 1994. </year>
Reference-contexts: Previous work regarding scheduling such messages on CAN includes <ref> [112, 113] </ref>, but they focused on fixed-priority scheduling. Shin [102] considered earliest-deadline first (EDF) scheduling, but did not consider its high overhead which makes 95 EDF impractical for CAN. <p> RM assumes that deadline equals period, which is not always true in reality. Instead of RM, we can use its close relative, deadline monotonic (DM) scheduling [69]. With DM, messages with tighter relative deadlines are assigned higher priorities and these priorities form the ID for each message <ref> [112, 113] </ref>. DM is a simple scheme and is easily implementable on CAN.
Reference: [114] <author> H. Tokuda and T. Nakajima, </author> <title> "Evaluation of real-time synchronization in Real-Time Mach," </title> <booktitle> in Second Mach Symposium, </booktitle> <pages> pp. 213-221. </pages> <publisher> Usenix, </publisher> <year> 1991. </year>
Reference-contexts: Previous work in improving semaphore performance has focused on either relaxing the semaphore semantics to get better performance [111], coming up with new semantics and new synchronization policies <ref> [114] </ref>, or putting restrictions on the application programmer to disallow certain actions (such as making blocking system calls) while holding a semaphore [89]. The problem with these approaches is that these new/modified semantics may be suit 15 able for some particular applications but usually they do not have wide applicability. <p> Previous work in this area has focused on either relaxing the semaphore semantics to get better performance [111], coming up with new semantics and new synchronization policies <ref> [114] </ref>, or putting restrictions on the application programmer to disallow certain operations (such as making blocking system calls) while holding a semaphore [89]. The problem with this approach is that these new/modified semantics may be suitable for some particular applications but usually they do not have wide applicability. <p> The standard procedure to lock a semaphore can be summarized as follows: if (sem locked) - do priority inheritance; add caller thread to wait queue; block; /* wait for sem to be released */ - lock sem; Priority inheritance [101] is needed in real-time systems to avoid unbounded priority inversion <ref> [114] </ref>. If a high-priority thread T h calls sem lock () on a semaphore already locked by a low-priority thread T l , the latter's priority is temporarily increased to that of the former. <p> But for network message transmission, a message holds the resource under contention (i.e., the network adapter buffer) until it completes transmission. Using priority inheritance in this situation can lead to a significant schedulability degradation (see Section 7.5.5). Another technique for tackling priority inversion in CPU scheduling is preempt-and-restart <ref> [114] </ref> in which the resource holder is preempted and forced to restart later from the beginning of the critical section. The disadvantage of this scheme is that once a thread is preempted, all CPU work it had done since entering the critical section is lost.
Reference: [115] <author> Robbert van Renesse, </author> <title> "Masking the overhead of protocol layering," </title> <booktitle> in Proc. SIG-COMM, </booktitle> <pages> pp. 96-104, </pages> <month> August </month> <year> 1996. </year>
Reference-contexts: This scheme is useful for handling bursts of short messages but is not effective for live audio messages because they are spaced at regular intervals in time. An innovative protocol architecture was presented in <ref> [115] </ref> which also aims to optimize the fast path. The packet filter compares headers of incoming packets against pre-computed expected values. In case of a match, the packet is forwarded immediately to the application, thereby reducing the latency of processing.
Reference: [116] <author> C.-D. Wang, H. Takada, and K. Sakamura, </author> <title> "Priority inheritance spin locks for multiprocessor real-time systems," </title> <booktitle> in 2nd International Symposium on Parallel Architectures, Algorithms, and Networks, </booktitle> <pages> pp. 70-76, </pages> <year> 1996. </year>
Reference-contexts: However, for simplicity, we concern ourselves only with semaphores in this chapter. 56 Most research in the area of reducing task synchronization overhead has focused on multiprocessors <ref> [81, 116] </ref>. But our target architectures are either uniprocessor (as in home appliances) or very loosely-coupled distributed systems (as in automotive applications). Even with the latter, threads typically do not need to access remote objects, so our concern is only with improving task synchronization performance for a single processor.
Reference: [117] <author> J. Xu, </author> <title> "Multiprocessor scheduling of processes with release times, deadlines, precedence, and exclusion relations," </title> <journal> IEEE Trans. Software Engineering, </journal> <volume> vol. 19, no. 2, </volume> <pages> pp. 139-154, </pages> <year> 1993. </year>
Reference-contexts: This has led to the development of well-known scheduling schemes such as rate-monotonic (RM) [76], earliest-deadline-first (EDF) [76], and deadline-monotonic [69]. But in recent years, the focus of research has shifted from uniprocessor task scheduling to scheduling tasks and messages in multiprocessors and distributed systems <ref> [2, 54, 117] </ref>. Uniprocessor task scheduling is treated as a "solved" problem and research in this area has tapered off.
Reference: [118] <author> H. Zeltwanger, </author> <title> "An inside look at the fundamentals of CAN," </title> <journal> Control Engineering, </journal> <volume> vol. 42, no. 1, </volume> <pages> pp. 81-87, </pages> <month> January </month> <year> 1995. </year>
Reference-contexts: any hardware support from the network adapter or any restrictions on the network API) which benefits long messages such as video and streaming data. * CAN scheduling and host support: The Controller Area Network (CAN) is being widely used in real-time control applications such as automobiles, aircraft, and automated factories <ref> [118] </ref>. <p> Of the multiple field bus protocols available for such use (including SP-50 FieldBus [44], MAP [80], TTP [61], etc.), the Controller Area Network (CAN) [49, 104] has gained wide-spread acceptance in the industry <ref> [118] </ref>. CAN is a contention-based multi-master network which has the potential to efficiently handle both periodic as well as sporadic messages. It is currently being used in a wide range of embedded real-time control applications [118] including automotive control, industrial automation, and medical monitoring. <p> etc.), the Controller Area Network (CAN) [49, 104] has gained wide-spread acceptance in the industry <ref> [118] </ref>. CAN is a contention-based multi-master network which has the potential to efficiently handle both periodic as well as sporadic messages. It is currently being used in a wide range of embedded real-time control applications [118] including automotive control, industrial automation, and medical monitoring. Its main attraction is its low cost (a CAN interface chip costs about $5) and reliability features like atomic multicasts and fault confinement.
Reference: [119] <author> L. Zhang, S. Deering, D. Estrin, S. Shenker, and D. Zappala, "RSVP: </author> <title> A new Resource ReSerVation Protocol," </title> <journal> IEEE Network, </journal> <volume> vol. 7, no. 9, </volume> <pages> pp. 8-18, </pages> <month> September </month> <year> 1993. </year>
Reference-contexts: Since WAN scheduling deals mostly with router issues, it does not affect the design of OS services for embedded systems and is beyond the scope of this thesis. Interested readers are referred to <ref> [24, 119] </ref>. 11 Since a field bus is contained entirely within an embedded system, scheduling messages on a field bus is the responsibility of the embedded systems designer.
Reference: [120] <author> W. Zhao and K. Ramamritham, </author> <title> "Simple and integrated heuristic algorithms for scheduling tasks with time and resource constraints," </title> <journal> Jounal of Systems and Software, </journal> <volume> vol. 7, </volume> <pages> pp. 195-205, </pages> <year> 1987. </year>
Reference-contexts: However, in general, fixed-priority schemes give lower utilization than other schemes such as non-preemptive EDF. Non-preemptive scheduling under release time constraints is NP-hard in the strong sense [50], meaning that there is no polynomial time scheduler which will always give the maximum schedulable utilization. However, the authors of <ref> [120] </ref> showed that EDF performs better than other simple heuristics. This is why several researchers have used EDF for network scheduling [26, 54, 121]. This motivates us to use EDF to schedule messages on CAN, but EDF incurs high overhead (as discussed later) which makes it impractical for CAN.
Reference: [121] <author> Q. Zheng and K. G. Shin, </author> <title> "On the ability of establishing real-time channels in point-to-point packet-switched networks," </title> <journal> IEEE Trans. Communications, </journal> <volume> vol. 24, no. 2/3/4, </volume> <pages> pp. 1096-1105, </pages> <month> February/March/April </month> <year> 1994. </year>
Reference-contexts: However, the authors of [120] showed that EDF performs better than other simple heuristics. This is why several researchers have used EDF for network scheduling <ref> [26, 54, 121] </ref>. This motivates us to use EDF to schedule messages on CAN, but EDF incurs high overhead (as discussed later) which makes it impractical for CAN. <p> ED* is an imaginary scheduling policy which works the same as EDF but requires only an 11-bit ID. We would expect MTS's performance to lie between those of ED* and DM. To check schedulability under ED*, we use the schedulability check for non-preemptive EDF in <ref> [121] </ref>. 114 Our measurements show that performance of MTS depends upon various workload char-acteristics. We identify the conditions under which MTS performs well and show that these conditions are typical of control applications.
Reference: [122] <author> K. M. Zuberi and K. G. Shin, </author> <title> "Non-preemptive scheduling of messages on Controller Area Network for real-time control applications," </title> <booktitle> in Proc. Real-Time Technology and Applications Symposium, </booktitle> <pages> pp. 240-249, </pages> <month> May </month> <year> 1995. </year>
Reference-contexts: Fixed-priority deadline-monotonic (DM) scheduling needs fewer bits to express priorities but yields relatively low utilization. We designed a scheduler called the mixed traffic scheduler (MTS) which combines EDF and DM by using quantized deadlines <ref> [122, 125, 127] </ref>. Packets are scheduled based on deadlines if deadlines are distinguishable after quantization; otherwise, they are scheduled using DM priorities. <p> Shin [102] considered earliest-deadline first (EDF) scheduling, but did not consider its high overhead which makes 95 EDF impractical for CAN. In this chapter, we present a scheduling scheme for CAN called the mixed traffic scheduler (MTS) <ref> [122, 125, 127] </ref> which increases schedulable utilization and performs better than fixed-priority schemes while incurring less overhead than EDF. We also describe how MTS can be implemented on existing CAN network adapters.
Reference: [123] <author> K. M. Zuberi and K. G. Shin, </author> <title> "A causal message ordering scheme for distributed embedded real-time systems," </title> <booktitle> in Proc. Symposium on Reliable and Distributed Systems, </booktitle> <pages> pp. 210-219, </pages> <month> October </month> <year> 1996. </year>
Reference-contexts: Middleware services are implemented on top of the OS (e.g., in the form of daemon processes) and they provide services needed by specialized applications usually running on large-scale parallel or distributed platforms. Examples of middleware services include reliable/atomic multicast [1, 37], consistent event ordering <ref> [12, 59, 123] </ref>, and task allocation in a parallel/distributed environment [107]. At present, embedded systems used in consumer items are not complex enough to require middleware services.
Reference: [124] <author> K. M. Zuberi and K. G. Shin, "EMERALDS: </author> <title> A microkernel for embedded real-time systems," </title> <booktitle> in Proc. Real-Time Technology and Applications Symposium, </booktitle> <pages> pp. 241-249, </pages> <month> June </month> <year> 1996. </year> <month> 139 </month>
Reference-contexts: (as demonstrated by its implementation within EMERALDS), it also delivers higher network utilization than DM. 2 The following chapters discuss these scheduling, synchronization, and communication issues in detail. 17 CHAPTER 3 EMERALDS: A REAL-TIME OPERATING SYSTEM EMERALDS is a small, fast kernel we have designed for use in embedded devices <ref> [124] </ref>. It features efficient context switches, interrupt handling, and memory usage. It provides full memory protection between processes, features an efficient system call mechanism, and has a low-overhead intra-node inter-process communication (IPC) scheme. <p> In fact, for this case, only one counter 2 This is especially true in EMERALDS where system call overhead is comparable to subroutine call overhead even with full memory protection between processes <ref> [124] </ref>. 59 held by thread T 1 . T x is an unrelated thread which was executing while T 2 was blocked. <p> For long messages, we compare the single-copy and standard two-copy schemes. 6.4.1 Platform We implemented our protocol architecture within EMERALDS on a 25MHz Motorola 68040 processor with separate 4kbyte data and instruction caches. EMERALDS features highly optimized context switching, interrupt handling, and memory usage <ref> [124] </ref>. The 68040 is typical of CPUs used in many IAs today. (We will later discuss the results on a faster processor.) We use two processors in our experiments, connected by a 10Mb/s private Ethernet using the LANCE network adapter.
Reference: [125] <author> K. M. Zuberi and K. G. Shin, </author> <title> "Real-time decentralized control with CAN," </title> <booktitle> in Proc. IEEE Conference on Emerging Technologies and Factory Automation, </booktitle> <pages> pp. 93-99, </pages> <month> November </month> <year> 1996. </year>
Reference-contexts: Fixed-priority deadline-monotonic (DM) scheduling needs fewer bits to express priorities but yields relatively low utilization. We designed a scheduler called the mixed traffic scheduler (MTS) which combines EDF and DM by using quantized deadlines <ref> [122, 125, 127] </ref>. Packets are scheduled based on deadlines if deadlines are distinguishable after quantization; otherwise, they are scheduled using DM priorities. <p> Shin [102] considered earliest-deadline first (EDF) scheduling, but did not consider its high overhead which makes 95 EDF impractical for CAN. In this chapter, we present a scheduling scheme for CAN called the mixed traffic scheduler (MTS) <ref> [122, 125, 127] </ref> which increases schedulable utilization and performs better than fixed-priority schemes while incurring less overhead than EDF. We also describe how MTS can be implemented on existing CAN network adapters.
Reference: [126] <author> K. M. Zuberi and K. G. Shin, </author> <title> "An efficient semaphore implementation scheme for small-memory embedded systems," </title> <booktitle> in Proc. Real-Time Technology and Applications Symposium, </booktitle> <pages> pp. 25-34, </pages> <month> June </month> <year> 1997. </year>
Reference-contexts: We took the approach of providing full semaphore semantics (with priority inheritance [101]), but optimizing the implementation of these semaphores by exploiting certain features of embedded applications <ref> [126] </ref>. We rely on the fact that the order in which embedded applications access objects (which is the same as the order in which semaphores are used) can be determined at compile-time. This is true because of the sensor-controller-actuator loop executed by typical embedded applications. <p> We took the approach of providing full semaphore semantics (with priority inheritance [101]), but optimizing the implementation of these semaphores by exploiting certain features of embedded applications <ref> [126] </ref>. As a result, our semaphore scheme has wide applicability within the domain of embedded applications, while significantly improving performance over standard implementation methods for semaphores.
Reference: [127] <author> K. M. Zuberi and K. G. Shin, </author> <title> "Scheduling messages on Controller Area Network for real-time CIM applications," </title> <journal> IEEE Trans. Robotics and Automation, </journal> <pages> pp. 310-314, </pages> <month> April </month> <year> 1997. </year>
Reference-contexts: Fixed-priority deadline-monotonic (DM) scheduling needs fewer bits to express priorities but yields relatively low utilization. We designed a scheduler called the mixed traffic scheduler (MTS) which combines EDF and DM by using quantized deadlines <ref> [122, 125, 127] </ref>. Packets are scheduled based on deadlines if deadlines are distinguishable after quantization; otherwise, they are scheduled using DM priorities. <p> Shin [102] considered earliest-deadline first (EDF) scheduling, but did not consider its high overhead which makes 95 EDF impractical for CAN. In this chapter, we present a scheduling scheme for CAN called the mixed traffic scheduler (MTS) <ref> [122, 125, 127] </ref> which increases schedulable utilization and performs better than fixed-priority schemes while incurring less overhead than EDF. We also describe how MTS can be implemented on existing CAN network adapters. <p> First, we give high-speed messages priority over low-speed and non-real-time ones by setting the most significant bit to 1 in the ID for high-speed messages (Figure 7.3a). This protects high-speed messages from all other types of traffic. If the uniqueness field is to be 5 bits <ref> [127] </ref> (allowing 32 high-speed messages), and the priority field is 1 bit, then the remaining 5 bits are still not enough to encode the deadlines (relative to the latest SOE). Our solution is to quantize time into regions and encode deadlines according to which region they fall in.
Reference: [128] <author> K. M. Zuberi and K. G. Shin, </author> <title> "An efficient end-host protocol processing architecture for real-time audio and video traffic," to appear in Proc. Network and Operating System Support for Digital Audio and Video (NOSSDAV), </title> <month> July </month> <year> 1998. </year> <month> 140 </month>
Reference-contexts: On the other hand, video applications exchange long messages (10-15 kbytes [25]) and these must be handled efficiently as well. We devised optimizations for reducing receive-side network protocol processing overhead thus enabling efficient handling of real-time audio and video messages <ref> [128] </ref>. (We focus on receive-side overhead since it usually exceeds send-side overhead.) In our scheme, I-cache miss overheads are minimized by safely bypassing multiple protocol layers, benefiting short messages such as live audio.
References-found: 128

