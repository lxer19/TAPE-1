URL: http://www.cs.cmu.edu/afs/cs.cmu.edu/user/chao-hu/personal/paper/spie951.ps
Refering-URL: http://www.cs.cmu.edu/afs/cs.cmu.edu/user/chao-hu/personal/home.html
Root-URL: 
Title: A general neural computer architecture and its ANN-based task assignment method for parallel distributed processing  
Author: Hu Chao Sylvian.R.Ray Nanning Zheng 
Keyword: 1.INTRODUCTION  
Address: Urbana,IL 61801 Xi'an,Shaanxi,710049 USA PRC  
Affiliation: Department of Computer Science Inst. of AI and Robotics University of Illinois Xi'an Jiaotong University  
Abstract: A new DSP-based neural simulating computer architecture and its ANN-based task assignment method for parallel distributed processing are proposed. The hardware of the proposed neural simulating computer can be reconfigured in terms of a variety of research interests and requirements of pattern recognition. The software programming environment utilizes an intelligent compiler to perform static task assignment in the both cases of single-task multi-processor and multi-task multi-processor. An improved Hopfield neural network which can converge to global optimal solution is employed by the complier to map different tasks or neurons to their corresponding real processors. An approach of introducing hidden layer to increase the computation ability of the neural simulating computer is also developed. Finally, a proof is given which shows that the use of improved Hopfield algorithm and the modification to network structure don't change the intrinsic properties of the original network. In recent years many progress has been made in natural scene understanding and continuous speech recognition in artificial intelligence and pattern recognition research fields 1;2;3 . Because of the computation ability and connective mechanism of conventional Von-Neumann computer, people have still not achieved perfect upshots in solving many issues associated with pattern recognition, although these problems are pretty easy for human being. The reason for this is that the natural environment is very sophisticated and uncertain, which make us very difficult to construct very large software to summarize and describe domain expert knowledge of various fields on conventional serial computer. Therefore, it is a promising and urgent project to develop a new computer architecture different from a single CPU structure. The fault tolerance ability and associative function of human brain make it possible to make correct decision and judgement when there is only partial information available. The human brain also has very strong self-organization and self-adaptation abilities so that it can learn from facts ans examples. Neural computer can partially imitate the information processing function of human brain by using parallel distributed processing and self-organization architecture which consists of large number of basic processing units. Compared with conventional computer, the most important feature of neural computer is that each processing unit is not only a place for information processing and storing but also a place for interconnecting with surrounding processing units. In this paper we develop a new architecture of general neural simulating computer based on multiple digital signal processor(DSP) and propose an artificial neural network(ANN) based task assignment method for parallel distributed processing. The hardware of the presented architecture can be reconfig-ured in terms of a variety of research interests and requirements of the pattern recognition. The software 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> Y.H.Pao, </author> <title> Adaptive pattern recognition and neural network, </title> <publisher> Addison-Wesley Pub, Inc., </publisher> <year> 1989. </year>
Reference: 2. <author> D.W.Tank and J.J.Hopfield, </author> <title> Simple neural optimization networks: an A/D converter, signal decision circuit, and a linear programming circuit, </title> <journal> IEEE Trans. on Circuits and System, </journal> <month> May </month> <year> 1986. </year>
Reference: 3. <author> D.Psaltis, </author> <title> Optical information processing based on an associative memory model of neural nets with threshold and feedback. </title> <journal> Opt.Lett., </journal> <volume> Vol. 10, </volume> <year> 1985 </year>
Reference: 4. <author> Y.Gao, N.Zheng and C.Hu, </author> <title> A neural computer architecture based on multi-DSP, </title> <address> ICSPAT'94, USA. </address>
Reference-contexts: More details about the hardware architecture can be found in literature <ref> [4] </ref>. It is faster for each processor to access local memory than to access shared memory because this process must be serial while the former is parallel.
Reference: 5. <author> T.Kohonen, </author> <title> Adaptive associative and self-organizing functions in neural computing, </title> <journal> Applied Optics, </journal> <volume> Vol.26, </volume> <month> Nov. </month> <year> 1987 </year>
Reference: 6. <author> G.V.Wilson and G.S Pawley, </author> <title> On stability of the traveling salesman problem algorithm of Hopfield and Tank, </title> <journal> Biol., Cybern., </journal> <year> 1985 </year>
Reference: 7. <author> J.J.Hopfield and D.W.Tank, </author> <title> Neural computation of decision in optimization problems, </title> <publisher> Biol,Cybern, Vol.52 </publisher>
Reference: 8. <editor> Kung.H.T, </editor> <booktitle> The structure of parallel algorithms in advances in computing, </booktitle> <publisher> Academic Press, </publisher> <address> NY, </address> <year> 1980 </year>
Reference: 9. <author> Yoshiyahu Takefuji, </author> <title> Neural network parallel computing, </title> <publisher> Kluwer Academic Pub., </publisher> <year> 1992 </year>
Reference: 10. <author> Chao Hu, N.Zheng, Y.Gao, </author> <title> Neuron design and stability of neural network for TSP, </title> <publisher> IEEE IC-SMC'94, </publisher> <address> USA. </address>
References-found: 10

