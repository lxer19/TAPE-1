URL: http://www.cse.ucsc.edu/research/concurrent/papers/iopads97.ps
Refering-URL: http://www.cse.ucsc.edu/research/concurrent/reports/
Root-URL: http://www.cse.ucsc.edu
Email: randal@almaden.ibm.com darrell@cs.ucsc.edu  
Title: Efficient Distributed Backup with Delta Compression  
Author: Randal C. Burns Darrell D. E. Long 
Address: Santa Cruz  
Affiliation: Department of Computer Science Department of Computer Science IBM Almaden Research Center University of California,  
Abstract: Inexpensive storage and more powerful processors have resulted in a proliferation of data that needs to be reliably backed up. Network resource limitations make it increasingly difficult to backup a distributed file system on a nightly or even weekly basis. By using delta compression algorithms, which minimally encode a version of a file using only the bytes that have changed, a backup system can compress the data sent to a server. With the delta backup technique, we can achieve significant savings in network transmission time over previous techniques. Our measurements indicate that file system data may, on average, be compressed to within 10% of its original size with this method and that approximately 45% of all changed files have also been backed up in the previous week. Based on our measurements, we conclude that a small file store on the client that contains copies of previously backed up files can be used to retain versions in order to generate delta files. To reduce the load on the backup server, we implement a modified version storage architecture, version jumping, that allows us to restore delta encoded file versions with at most two accesses to tertiary storage. This minimizes server workload and network transmission time on file restore. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Miklos Ajtai, Randal Burns, Ronald Fagin, and Larry Stockmeyer. </author> <title> Efficient differential compression of binary sources. </title> <journal> IBM Research: </journal> <note> In Preparation, </note> <year> 1997. </year>
Reference-contexts: Consequently, if only a few bytes are modified in a large file, the backup system saves the expense of transmitting the large file in favor of transmitting only the changed bytes. Recent advances in differencing algorithms <ref> [1, 4] </ref>, allow nearly optimally compressed encodings of binary inputs in linear time. We use such an algorithm to generate delta encodings of versions. <p> Furthermore, both uncompressed files and delta encoded files still realize benefits from the standard file compression methods that ADSM already utilizes <ref> [1] </ref>. We integrate delta backup into ADSM and have a backwardly compatible system with optimizations to transmit and store a reduced amount of data at the server. <p> An ideal differencing algorithm can create a delta file, (V i ;V i+1 ) , with maximum size ffjV i j. The symbols encoded in a delta file can either replace existing symbols or add data to the file, as all reasonable encodings do not mark deleted symbols <ref> [1] </ref>.
Reference: [2] <author> Albert Alderson. </author> <title> A space-efficient technique for recording versions of data. </title> <journal> Software Engineering Journal, </journal> <volume> 3(6):240246, </volume> <month> June </month> <year> 1988. </year>
Reference-contexts: Previous efforts in the efficient restoration of file versions have provided restoration execution times independent of the number of intermediate versions. These include methods based on AVL Dags [7], linked data structures <ref> [19, 2] </ref>, or string libraries [3]. However, these require all delta versions of a given file to be present at restore time and are consequently infeasible for a backup system.
Reference: [3] <author> Andrew P. Black and Charles H. Burris, Jr. </author> <title> A compact representation for file versions: A preliminary report. </title> <booktitle> In Proceedings of the 5th International Conference on Data Engineering, </booktitle> <pages> pages 321329. </pages> <publisher> IEEE, </publisher> <year> 1989. </year>
Reference-contexts: Previous efforts in the efficient restoration of file versions have provided restoration execution times independent of the number of intermediate versions. These include methods based on AVL Dags [7], linked data structures [19, 2], or string libraries <ref> [3] </ref>. However, these require all delta versions of a given file to be present at restore time and are consequently infeasible for a backup system. Such a backup system would require all prior versions of a file to be recalled from long term storage for that file to be reconstructed.
Reference: [4] <author> Randal Burns and Darrell D. E. </author> <title> Long. A linear time, constant space differencing algorithm. </title> <booktitle> In Proceedings of the 1997 International Performance, Computing and Communications Conference (IPCCC'97), </booktitle> <month> Feb. </month> <pages> 5-7, </pages> <address> Tempe/Phoenix, Arizona, USA, </address> <month> February </month> <year> 1997. </year>
Reference-contexts: Consequently, if only a few bytes are modified in a large file, the backup system saves the expense of transmitting the large file in favor of transmitting only the changed bytes. Recent advances in differencing algorithms <ref> [1, 4] </ref>, allow nearly optimally compressed encodings of binary inputs in linear time. We use such an algorithm to generate delta encodings of versions. <p> For an extremely active page, the log will likely exceed the page size. Differential compression also has the guarantee that a log of modifications to a file will be no smaller than the corresponding delta <ref> [4] </ref>. Recently, several commercial systems have appeared on the marketplace that claim to perform delta backup [11, 6, 18]. <p> Based on experimental results <ref> [4] </ref>, we chose ff = 0:01 and ff = 0:1 as a low and a high value for the compressibility of file system data. We note that the version jumping and delta chain storage curves are nearly identical for small values of n.
Reference: [5] <author> Luis-Felipe Cabrera, Robert Rees, Stefan Steiner, Michael Penner, and Wayne Hineman. ADSM: </author> <title> A multi-platform, scalable, backup and archive mass storage system. </title> <booktitle> In IEEE Compcon, </booktitle> <address> San Francisco, CA March 5-9, </address> <year> 1995, </year> <pages> pages 420427. </pages> <publisher> IEEE, </publisher> <year> 1995. </year>
Reference-contexts: We enhanced the client/server architecture of the AdStar Distributed Storage Manager (ADSM) backup system <ref> [5] </ref> to transmit delta files when a backup client has retained two versions of the same file. Furthermore, both uncompressed files and delta encoded files still realize benefits from the standard file compression methods that ADSM already utilizes [1].
Reference: [6] <author> Connected Corp. </author> <title> The Importance of Backup in Small Business. </title> <note> http://www.connected.com/wtpaper.html, 1996. </note>
Reference-contexts: Differential compression also has the guarantee that a log of modifications to a file will be no smaller than the corresponding delta [4]. Recently, several commercial systems have appeared on the marketplace that claim to perform delta backup <ref> [11, 6, 18] </ref>. While the exact methods these systems use have not been disclosed, the product literature implies that they either perform logging [11] or difference at the granularity of a file block [18, 6]. We perform delta backup at the granularity of a byte. <p> Recently, several commercial systems have appeared on the marketplace that claim to perform delta backup [11, 6, 18]. While the exact methods these systems use have not been disclosed, the product literature implies that they either perform logging [11] or difference at the granularity of a file block <ref> [18, 6] </ref>. We perform delta backup at the granularity of a byte.
Reference: [7] <author> Christopher W. Fraser and Eugene W. Myers. </author> <title> An editor for revision control. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 9(2):277295, </volume> <month> April </month> <year> 1987. </year>
Reference-contexts: An important goal of our system is to minimize the number of deltas participating in any given restore operation. Previous efforts in the efficient restoration of file versions have provided restoration execution times independent of the number of intermediate versions. These include methods based on AVL Dags <ref> [7] </ref>, linked data structures [19, 2], or string libraries [3]. However, these require all delta versions of a given file to be present at restore time and are consequently infeasible for a backup system.
Reference: [8] <institution> International Business Machines. </institution> <note> Publication No. G221-2426: 3490 Magnetic Tape Subsystem Family, </note> <year> 1996. </year>
Reference-contexts: A backup system has the additional limitation that any given delta file may reside on a physically distinct media device and device access can be slow, generally several seconds to load a tape in a tape robot <ref> [8] </ref>. Consequently, having many distinct deltas participate in the restoration of a single file becomes costly in device latency. An important goal of our system is to minimize the number of deltas participating in any given restore operation.
Reference: [9] <author> L.A. Bjork, Jr. </author> <title> Generalized audit trail requirements and concepts for database applications. </title> <journal> IBM Systems Journal, </journal> <volume> 14(3):229245, </volume> <year> 1975. </year>
Reference-contexts: For file systems, there are no guarantees that modifications have page alignment. While dirty bits are effective for databases, they may not apply well to file system backup. To improve on the granularity of backup, logging methods have been used to record the changes to a database <ref> [9, 14] </ref> and a file system [16]. A logging system records every write during an epoch to a log file. This can be used to recover the version as it existed at the start of an epoch into its current state.
Reference: [10] <author> Raymond A. Lorie. </author> <title> Physical integrity in a large segmented database. </title> <journal> IBM Transactions on Database Systems, </journal> <volume> 2(1):91104, </volume> <month> March </month> <year> 1977. </year>
Reference-contexts: In x6 potential future work is discussed and we present our conclusions in x7. 2 Origins of Delta Backup Delta backup emerged from many applications, the first instance appearing in database technology. The database pages that are written between backup epochs are marked as dirty using a single bit <ref> [10, 17] </ref>. At the end of an epoch, only the dirty pages need to be backed up. This concept parallels delta backup but operates only at page granularity. For file systems, there are no guarantees that modifications have page alignment.
Reference: [11] <author> Peter B. Malcolm. </author> <title> United States Patent No. 5,086,502: Method of Operating a Data Processing System. </title> <booktitle> Intelligence Quotient International, </booktitle> <month> February </month> <year> 1992. </year>
Reference-contexts: Differential compression also has the guarantee that a log of modifications to a file will be no smaller than the corresponding delta [4]. Recently, several commercial systems have appeared on the marketplace that claim to perform delta backup <ref> [11, 6, 18] </ref>. While the exact methods these systems use have not been disclosed, the product literature implies that they either perform logging [11] or difference at the granularity of a file block [18, 6]. We perform delta backup at the granularity of a byte. <p> Recently, several commercial systems have appeared on the marketplace that claim to perform delta backup [11, 6, 18]. While the exact methods these systems use have not been disclosed, the product literature implies that they either perform logging <ref> [11] </ref> or difference at the granularity of a file block [18, 6]. We perform delta backup at the granularity of a byte.
Reference: [12] <author> Robert Morris. </author> <title> United States Patent No. 5,574,906: System and method for reducing storage requirements in backup subsystems utilizing segmented compression and differencing. </title> <booktitle> International Business Machines, </booktitle> <year> 1996. </year>
Reference-contexts: While incremental backup only detects changes at the granularity of a file, delta backup refines this concept, transmitting only the altered bytes in the files to be incrementally backed up <ref> [12] </ref>. Consequently, if only a few bytes are modified in a large file, the backup system saves the expense of transmitting the large file in favor of transmitting only the changed bytes. Recent advances in differencing algorithms [1, 4], allow nearly optimally compressed encodings of binary inputs in linear time.
Reference: [13] <author> Marc J. Rochkind. </author> <title> The source code control system. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-1(4):364370, </volume> <month> December </month> <year> 1975. </year>
Reference-contexts: Restoring files that have been stored using delta backup generates additional concerns in delta file management. Traditional methods for storing deltas require the decompression agent to examine either all of the versions of a given file <ref> [13] </ref> or all versions in between the first version and the version being restored [15]. In either case, the time to reconstruct a given file grows at least linearly (see x4.1) with respect to the number of versions involved. <p> ; V i1 ; V i ; V i+1 ; : : : : The traditional way to store this version chain as a series of deltas is, for two adjacent versions V i and V i+1 , to store the difference between these two files, V i ;V i+1 <ref> [13] </ref>.
Reference: [14] <author> Dennis G. Severance and Guy M. Lohman. </author> <title> Differential files: Their application to the maintenance of large databases. </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 1(2):256267, </volume> <month> September </month> <year> 1976. </year>
Reference-contexts: For file systems, there are no guarantees that modifications have page alignment. While dirty bits are effective for databases, they may not apply well to file system backup. To improve on the granularity of backup, logging methods have been used to record the changes to a database <ref> [9, 14] </ref> and a file system [16]. A logging system records every write during an epoch to a log file. This can be used to recover the version as it existed at the start of an epoch into its current state.
Reference: [15] <author> Walter F. Tichy. </author> <title> RCS A system for version control. </title> <journal> Software Practice and Experience, </journal> <volume> 15(7):637654, </volume> <month> July </month> <year> 1985. </year>
Reference-contexts: Traditional methods for storing deltas require the decompression agent to examine either all of the versions of a given file [13] or all versions in between the first version and the version being restored <ref> [15] </ref>. In either case, the time to reconstruct a given file grows at least linearly (see x4.1) with respect to the number of versions involved. <p> This linear sequence of versions forms a history of modifications to a file which we call a version chain. We now develop a notation for delta storage and analyze a linear version chain stored using traditional methods <ref> [15] </ref>. Linear delta chains are the most compact version storage scheme as the inter-version modification are smallest when differencing between consecutive versions. We will use the optimality of linear delta chains later as a basis to compare the compression of the version jumping scheme. <p> In a system that retains multiple versions, the cost of restoring the most remote version quickly becomes exorbitant. 4.2 Reverse Delta Chains Some version control systems solve the problem of long delta chains with reverse delta chain storage <ref> [15] </ref>. A reverse delta chain keeps the most recent version of a file present and uncompressed. The version chain is then stored as a set of backward deltas.
Reference: [16] <author> V. P. Turnburke, Jr. </author> <title> Sequential data processing design. </title> <journal> IBM Systems Journal, </journal> <volume> 2:3748, </volume> <month> March </month> <year> 1963. </year>
Reference-contexts: While dirty bits are effective for databases, they may not apply well to file system backup. To improve on the granularity of backup, logging methods have been used to record the changes to a database [9, 14] and a file system <ref> [16] </ref>. A logging system records every write during an epoch to a log file. This can be used to recover the version as it existed at the start of an epoch into its current state.
Reference: [17] <author> Joost M. Verhofstad. </author> <title> Recovery techniques for database systems. </title> <journal> ACM Computing Surveys, </journal> <volume> 10(2):167195, </volume> <month> June </month> <year> 1978. </year>
Reference-contexts: In x6 potential future work is discussed and we present our conclusions in x7. 2 Origins of Delta Backup Delta backup emerged from many applications, the first instance appearing in database technology. The database pages that are written between backup epochs are marked as dirty using a single bit <ref> [10, 17] </ref>. At the end of an epoch, only the dirty pages need to be backed up. This concept parallels delta backup but operates only at page granularity. For file systems, there are no guarantees that modifications have page alignment.
Reference: [18] <author> VytalVault, Inc. </author> <title> VytalVault Product Information. </title> <note> http://www.vytalnet.com/vytalvlt/product.htm, 1996. </note>
Reference-contexts: Differential compression also has the guarantee that a log of modifications to a file will be no smaller than the corresponding delta [4]. Recently, several commercial systems have appeared on the marketplace that claim to perform delta backup <ref> [11, 6, 18] </ref>. While the exact methods these systems use have not been disclosed, the product literature implies that they either perform logging [11] or difference at the granularity of a file block [18, 6]. We perform delta backup at the granularity of a byte. <p> Recently, several commercial systems have appeared on the marketplace that claim to perform delta backup [11, 6, 18]. While the exact methods these systems use have not been disclosed, the product literature implies that they either perform logging [11] or difference at the granularity of a file block <ref> [18, 6] </ref>. We perform delta backup at the granularity of a byte.
Reference: [19] <author> Lin Yu and Daniel J. Rosenkrantz. </author> <title> A linear time scheme for version reconstruction. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 16(3):775 797, </volume> <month> May </month> <year> 1994. </year>
Reference-contexts: Previous efforts in the efficient restoration of file versions have provided restoration execution times independent of the number of intermediate versions. These include methods based on AVL Dags [7], linked data structures <ref> [19, 2] </ref>, or string libraries [3]. However, these require all delta versions of a given file to be present at restore time and are consequently infeasible for a backup system.
References-found: 19

