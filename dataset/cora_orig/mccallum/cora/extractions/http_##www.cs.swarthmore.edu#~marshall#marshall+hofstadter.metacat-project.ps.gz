URL: http://www.cs.swarthmore.edu/~marshall/marshall+hofstadter.metacat-project.ps.gz
Refering-URL: http://www.cs.swarthmore.edu/~marshall/vita.html
Root-URL: 
Email: fmarshall,dughofg@cogsci.indiana.edu  
Title: The Metacat Project: A Self-Watching Model of Analogy-Making  
Author: James B. Marshall Douglas R. Hofstadter 
Keyword: analogy, perception, fluid-concepts, self-watching, explanation  
Address: Bloomington, Indiana 47408 USA  
Affiliation: Department of Computer Science Indiana University  
Note: Center for Research on Concepts and Cognition  
Abstract: This paper presents a broad overview of the Metacat project, an extension of the Copycat computer model of fluid concepts, high-level perception, and analogy-making. Copycat models the complex, subconscious interplay between concepts and perception that gives rise to the flexible human ability to perceive apparently-dissimilar situations as being "the same". A key feature of the architecture is the emergence of statistically-robust, high-level behavior from the interactions of many small, low-level, nondeterministic processing agents. All processing occurs through the collective actions of many agents working in parallel on different aspects of an analogy problem, without any higher-level executive process controlling the course of events. Current work on Metacat is focused on extending the Copycat model in a way that permits it to create much richer representations of the analogies it makes. This involves incorporating a long-term memory into the architecture, along with a "self-watching" ability, so that the program can recognize, remember, and recall important patterns that occur in its own processing as it solves analogy problems. Using this higher-order "meta-level" information, analogies can be compared and contrasted in an insightful way, allowing Metacat to understand and explain its answers in a way that Copycat cannot. Metacat's relationship to other work in AI and cognitive science is also examined, in particular work on case-based reasoning and derivational analogy.
Abstract-found: 1
Intro-found: 1
Reference: [Blank et al., 1992] <author> Blank, D., Meeden, L., and Marshall, J. </author> <year> (1992). </year> <title> Exploring the symbolic/subsymbolic continuum: A case study of RAAM. </title> <editor> In Dinsmore, J., editor, </editor> <booktitle> The Symbolic and Connectionist Paradigms: Closing the Gap, </booktitle> <pages> pages 113-148. </pages> <publisher> Lawrence Erlbaum Associates, </publisher> <address> Hillsdale, NJ. </address>
Reference-contexts: At the same time, however, it incorporates many ideas from the more traditional paradigm of symbolic AI, staking out a kind of middle ground between these two opposites. Some further perspectives on the emergent-symbolic spectrum and Copycat's relationship to it can be found in <ref> [Blank et al., 1992] </ref>. For many problems, Copycat's behavior agrees well with human behavior, in terms of the range and frequencies of the answers it finds, as well as its ratings of their quality.
Reference: [Carbonell, 1986] <author> Carbonell, J. </author> <year> (1986). </year> <title> Derivational analogy: A theory of reconstructive problem solving and expertise acquisition. </title> <editor> In Michalski, R., Carbonell, J., and Mitchell, T., editors, </editor> <booktitle> Machine Learning: An Artificial Intelligence Approach, </booktitle> <volume> Volume II, </volume> <pages> pages 371-392. </pages> <publisher> Morgan Kauf-mann, </publisher> <address> Palo Alto, CA. </address>
Reference-contexts: This information is stored, along with the answer's other supporting Workspace structures, in Metacat's memory, forming a high-level characterization of the answer. In some ways, this idea is similar in flavor to work on derivational analogy <ref> [Carbonell, 1986, Veloso, 1994] </ref>, in which a system stores temporal traces of a problem-solving session in memory for use in analogous situations that may arise later, so as to improve the system's level of performance. <p> In derivational analogy, an entire trace of a problem-solving session is stored for future reference, not just the solution produced in the end, along with a series of annotations describing the conditions under which each step in the solution was taken <ref> [Carbonell, 1986, Veloso, 1994] </ref>. In Metacat, the thematic information stored with an answer summarizes the important concepts and events that together contributed to the discovery of the answer, much like the temporal problem-solving trace of derivational analogy.
Reference: [Chi et al., 1989] <author> Chi, M., Bassok, M., Lewis, M., Reimann, P., and Glaser, R. </author> <year> (1989). </year> <title> Self-explanations: How students study and use examples in learning to solve problems. </title> <journal> Cognitive Science, </journal> <volume> 13 </volume> <pages> 145-182. </pages>
Reference-contexts: For example, an interesting psychological phenomenon related to self-watching, dubbed the self-explanation effect, has been described and studied in the context of students learning to solve physics problems from examples <ref> [Chi et al., 1989, VanLehn et al., 1992] </ref>. In this series of studies, students monitored their own understanding or misunderstanding as they studied worked-out textbook examples of mechanics problems, generating verbal explanations of the example solutions in the process.
Reference: [Hofstadter, 1984] <author> Hofstadter, D. R. </author> <year> (1984). </year> <title> The Copycat project: An experiment in nondetermin-ism and creative analogies. </title> <type> AI Memo 755, </type> <institution> MIT Artificial Intelligence Laboratory. </institution>
Reference-contexts: 1 Introduction This paper describes the Metacat project, an extension of the Copycat computer model of fluid concepts, high-level perception, and analogy-making that simulates the complex, subconscious interplay between perception and concepts underlying human creativity <ref> [Hofstadter, 1984, Mitchell, 1993, Hofstadter and FARG, 1995] </ref>. Copycat operates in an abstract, idealized microworld of analogy problems that exhibits a surprising degree of subtlety and richness.
Reference: [Hofstadter and FARG, 1995] <author> Hofstadter, D. R. </author> <title> and FARG (1995). Fluid Concepts and Creative Analogies: Computer Models of the Fundamental Mechanisms of Thought. </title> <publisher> Basic Books, </publisher> <address> New York. </address>
Reference-contexts: 1 Introduction This paper describes the Metacat project, an extension of the Copycat computer model of fluid concepts, high-level perception, and analogy-making that simulates the complex, subconscious interplay between perception and concepts underlying human creativity <ref> [Hofstadter, 1984, Mitchell, 1993, Hofstadter and FARG, 1995] </ref>. Copycat operates in an abstract, idealized microworld of analogy problems that exhibits a surprising degree of subtlety and richness. <p> We believe that realizing such a program would go a long way toward a genuine understanding of the powerful yet subtle conceptual machinery underlying human cognition. 3 A Sketch of Copycat's Architecture A detailed exposition of the Copycat model can be found in [Mitchell, 1993] and <ref> [Hofstadter and FARG, 1995] </ref>. Here we shall give just a brief overview. Copycat perceives analogies between short strings of letters, which can be thought of as representing abstract, idealized situations. <p> This problem has been discussed at length elsewhere <ref> [Mitchell, 1993, Hofstadter and FARG, 1995] </ref>, so we summarize briefly here. In Copycat's letter-string domain, a has no predecessor and z has no successor.
Reference: [Leake, 1996] <author> Leake, D. B., </author> <title> editor (1996). Case-Based Reasoning: Experiences, Lessons, & Future Directions. </title> <publisher> MIT Press/AAAI Press, </publisher> <address> Cambridge, MA. </address>
Reference-contexts: Other concepts clearly lie very far away from the core: penguins, say, or rollerskates, or computer software. Or do they? Consider the following humorous quip seen recently on the World Wide Web <ref> [Leake, 1996] </ref>: "Windows-95: Microsoft's Vietnam?" Regardless of whether or not one agrees with its sentiment, its meaning is readily understood. Windows-95, a computer operating system, can be perceived as an instance of the concept Vietnam. <p> characterize and actively guide Metacat's processing, allowing the program first to detect and then to avoid the kind of senseless looping behavior so problematic in Copycat. 5 Relation to Other Work As the previous discussion may suggest, Metacat touches on many of the issues underlying research in case-based reasoning (CBR) <ref> [Leake, 1996] </ref>. Metacat's memory may be thought of as storing "cases", representing either successes (i.e., the discovery of a new answer) or failures (i.e., hitting a snag). These cases form a corpus of experience on which the program can draw when faced with new situations.
Reference: [Mitchell, 1993] <author> Mitchell, M. </author> <year> (1993). </year> <title> Analogy-making as Perception. </title> <publisher> MIT Press/Bradford Books, </publisher> <address> Cambridge, MA. </address>
Reference-contexts: 1 Introduction This paper describes the Metacat project, an extension of the Copycat computer model of fluid concepts, high-level perception, and analogy-making that simulates the complex, subconscious interplay between perception and concepts underlying human creativity <ref> [Hofstadter, 1984, Mitchell, 1993, Hofstadter and FARG, 1995] </ref>. Copycat operates in an abstract, idealized microworld of analogy problems that exhibits a surprising degree of subtlety and richness. <p> We believe that realizing such a program would go a long way toward a genuine understanding of the powerful yet subtle conceptual machinery underlying human cognition. 3 A Sketch of Copycat's Architecture A detailed exposition of the Copycat model can be found in <ref> [Mitchell, 1993] </ref> and [Hofstadter and FARG, 1995]. Here we shall give just a brief overview. Copycat perceives analogies between short strings of letters, which can be thought of as representing abstract, idealized situations. <p> This problem has been discussed at length elsewhere <ref> [Mitchell, 1993, Hofstadter and FARG, 1995] </ref>, so we summarize briefly here. In Copycat's letter-string domain, a has no predecessor and z has no successor.
Reference: [VanLehn et al., 1992] <author> VanLehn, K., Jones, R., and Chi, M. </author> <year> (1992). </year> <title> A model of the self-explanation effect. </title> <journal> The Journal of the Learning Sciences, </journal> <volume> 2(1) </volume> <pages> 1-59. </pages>
Reference-contexts: For example, an interesting psychological phenomenon related to self-watching, dubbed the self-explanation effect, has been described and studied in the context of students learning to solve physics problems from examples <ref> [Chi et al., 1989, VanLehn et al., 1992] </ref>. In this series of studies, students monitored their own understanding or misunderstanding as they studied worked-out textbook examples of mechanics problems, generating verbal explanations of the example solutions in the process.

References-found: 8

