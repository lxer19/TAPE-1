URL: http://csg-www.lcs.mit.edu:8001/Users/vivek/ps/MeSa97.ps
Refering-URL: http://csg-www.lcs.mit.edu:8001/Users/vivek/sark_pub.html
Root-URL: 
Email: Email: megiddo@almaden.ibm.com Email: vivek@lcs.mit.edu  
Title: Optimal Weighted Loop Fusion for Parallel Programs  
Author: Nimrod Megiddo Vivek Sarkar 
Affiliation: IBM Almaden Research Center MIT Laboratory for Computer Science and Tel Aviv University and IBM Software Solutions Division  
Abstract: Much of the computation involved in parallel programs occurs within loops, either nested loops as in parallel scientific applications or collections of loops as in stream-based applications. Loop fusion is a well-known program transformation that has shown to be effective in improving data locality in parallel programs by reducing inter-processor communication and improving register and cache locality. Weighted loop fusion is the problem of finding a legal partition of loop nests into fusible clusters so as to minimize the total inter-cluster weights. The loop nests may contain parallel or sequential loops; care is taken to ensure that a parallel loop does not get serialized after fusion. It has been shown in past work that the weighted loop fusion problem is NP-hard. Despite the NP-hardness property, we show how optimal solutions can be found efficiently (i.e., within the compile-time constraints of a product-quality optimizing compiler) for weighted loop fusion problem sizes that occur in practice. In this paper, we present an integer programming formulation for weighted loop fusion with size (number of variables and constraints) that is linearly proportional to the size of the input weighted loop fusion problem. The linear-sized formulation is key to making the execution time small enough for use in a product-quality optimizing compiler, since the natural integer programming formulation for this problem has cubic size for which the execution time would be too large to be practical. The linear-sized integer programming formulation can be solved efficiently using any standard optimization package but we also present a custom branch-and-bound algorithm that can be used if greater efficiency is desired. A prototype implementation of this approach has been completed, and preliminary compile-time measurements are included in the paper as validation of the practicality of this approach. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> John R. Allen. </author> <title> Dependence Analysis for Subscripted Variables and its Application to Program Transformation. </title> <type> PhD thesis, </type> <institution> Rice University, Houston, TX, </institution> <year> 1983. </year>
Reference-contexts: An edge in the LDG represents a loop-independent data dependence <ref> [1] </ref> from the source loop nest to the destination loop nest i.e., if there is an LDG edge from loop nest L to loop nest M , then loop nest M must be executed after loop nest L. <p> (Use L ; Def M ) 2.3. /* Test for illegal array data dependence. */ if V contains a lexicographically negative dependence vector then return false 2.4. /* Test for serialization due to creation of loop-carried dependence vector after fusion. */ if V contains a dependence vector that is carried <ref> [1] </ref> at the same level as a parallel loop in loop nest L or loop nest M then return false end for 3. return true end 3.1 A Simple Integer Programming For- mulation In this subsection, we develop a simple integer programming formulation that follows naturally from the the weighted loop
Reference: [2] <author> R. Allen and K. Kennedy. </author> <title> Automatic translation of FORTRAN programs to vector form. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 9 </volume> <pages> 491-542, </pages> <year> 1987. </year>
Reference-contexts: As a result, being able to handle loops efficiently is of fundamental importance. A lot of the past work in optimizing the performance of loops has focused on individual loop nests rather than on collections of loop nests <ref> [2, 11, 3, 24, 22, 23, 20] </ref>. This paper examines the weighted loop fusion problem. Each pair of loop nests has an associated non-negative weight which is the cost savings that would be obtained if the two loop nests were fused. <p> A node in the LDG represents a perfect loop nest i.e., a set of perfectly nested loops [24]. We assume that, prior to loop fusion, suitable iteration-reordering loop transformations have been performed on the individual loop nests <ref> [2, 11, 3, 24, 22, 23, 20, 19] </ref> and that individual loops have been identified as being parallel or serial (either by programmer input or by automatic parallelization).
Reference: [3] <author> U. Banerjee. </author> <title> Dependence Analysis for Supercomputing. </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, MA, </address> <year> 1988. </year>
Reference-contexts: As a result, being able to handle loops efficiently is of fundamental importance. A lot of the past work in optimizing the performance of loops has focused on individual loop nests rather than on collections of loop nests <ref> [2, 11, 3, 24, 22, 23, 20] </ref>. This paper examines the weighted loop fusion problem. Each pair of loop nests has an associated non-negative weight which is the cost savings that would be obtained if the two loop nests were fused. <p> A node in the LDG represents a perfect loop nest i.e., a set of perfectly nested loops [24]. We assume that, prior to loop fusion, suitable iteration-reordering loop transformations have been performed on the individual loop nests <ref> [2, 11, 3, 24, 22, 23, 20, 19] </ref> and that individual loops have been identified as being parallel or serial (either by programmer input or by automatic parallelization).
Reference: [4] <author> David Callahan. </author> <title> A Global Approach to Detection of Parallelism. </title> <type> PhD thesis, </type> <institution> Rice University, </institution> <month> April </month> <year> 1987. </year> <institution> Rice COMP TR87-50. </institution>
Reference-contexts: We now mention some past work related to unweighted loop fusion i.e., the problem of finding a legal fusion partition that minimizes the number of fusion clusters (there are no edge weights in this problem statement and hence no consideration of locality savings for pairs of loops). In <ref> [4] </ref>, Callahan presented a greedy partitioning algorithm for unweighted loop fusion and proved its optimality.
Reference: [5] <author> Jyh-Herng Chow, Leonard E. Lyon, and Vivek Sarkar. </author> <title> Automatic Parallelization for Symmetric Shared-Memory Multiprocessors. </title> <booktitle> CASCON '96 conference, </booktitle> <month> November </month> <year> 1996. </year>
Reference-contexts: The problem instances were obtained from loop dependence graphs built by the IBM ASTI high-level optimizer, which provides the foundation for high-order transformations [19] and automatic shared-memory parallelization <ref> [5] </ref> in the latest IBM xl fortran (xlf) compilers for RS/6000 and PowerPC unipro-cessors and symmetric multiprocessors (SMP's), and for automatic distributed-memory parallelization in the IBM xl high performance fortran (xlhpf) compiler for the SP-2 distributed-memory multiprocessor [21]. The rest of the paper is organized as follows. <p> We present preliminary measurements of the execution time taken by the IBM Optimization Subroutine Library (OSL) package to solve integer-programming problem instances obtained from loop dependence graphs built by the IBM ASTI high-level optimizer, which provides the foundation for high-order transformations [19] and automatic shared-memory parallelization <ref> [5] </ref> in the latest IBM xl fortran (xlf) compilers for RS/6000 and PowerPC unipro-cessors and symmetric multiprocessors (SMP's), and for automatic distributed-memory parallelization in the IBM xl high performance fortran (xlhpf) compiler for the SP-2 distributed-memory multiprocessor [21]. <p> As future work, we plan to use our prototype implemen tation to measure the runtime improvements delivered by using the optimal weighted fusion algorithm in the ASTI high-level optimizer to automatically parallelize programs for execution on symmetric multiprocessors <ref> [5] </ref>. In addition, we will explore the possibility of developing integer programming solutions for other compiler-related NP-hard graph partitioning problems such as those introduced in [17, 18].
Reference: [6] <author> J. Ferrante, K. J. Ottenstein, and J. D. Warren. </author> <title> The program dependence graph and its use in optimization. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 9(3) </volume> <pages> 319-349, </pages> <month> July </month> <year> 1987. </year>
Reference-contexts: Two loop nests are said to be conformable if their corresponding loops have the same type (parallel or serial) and identical iteration lengths (loop bounds). Two loop nests (or, more generally, statements) are said to be identically control dependent if they have the same set of control conditions <ref> [6] </ref>, i.e., the same set of (node, label) pairs as control dependence predecessors.
Reference: [7] <author> Jeanne Ferrante, Vivek Sarkar, and Wendy Thrash. </author> <title> On Estimating and Enhancing Cache Effectiveness. </title> <booktitle> Lecture Notes in Computer Science, </booktitle> (589):328-343, 1991. Proceedings of the Fourth International Workshop on Languages and Compilers for Parallel Computing, Santa Clara, California, USA, August 1991. Edited by U. Banerjee, D. Gelernter, A. Nicolau, D. Padua. 
Reference-contexts: We used this simple cost measure for the sake of illustration though it does capture register locality and cache locality. We would recommend using a more sophisticated locality cost model, such as the cost models in <ref> [7, 22, 19] </ref>, when computing weights for use in a real compiler. Thus, in the cost model for this example, w 12 = 1 because the load of A (I) would be saved in loop 20 if it is fused with loop 10 (see program text in Figure 1).
Reference: [8] <author> G. R. Gao, R. Olsen, V. Sarkar, and R. Thekkath. </author> <title> Collective loop fusion for array contraction. </title> <booktitle> Springer-Verlag Lecture Notes in Computer Science, 757. Proceedings of the Fifth Workshop on Languages and Compilers for Parallel Computing, </booktitle> <institution> Yale University, </institution> <month> August </month> <year> 1992. </year>
Reference-contexts: For parallel programs, an additional contractabil-ity constraint imposed by Algorithm Contractable is to mark an edge (i; j) as noncontractable if i and j are parallel loops but fusing them together would result in a sequential loop. version of the example from <ref> [8] </ref>). The LDG for the program in Figure 1 is shown in Figure 2, where the noncontractable edges are marked with X. For convenience, LDG edges in Figure 2 are also labeled with the name of the variable associated with the dependence. <p> Maximal distribution also yields a larger number of perfect loop nests that can be subject to iteration-reordering loop transformations (e.g., interchange, tiling) before loop fusion. The problem of selecting a fusion/distribution configuration thus becomes equivalent to an optimal weighted loop fusion problem after maximal distribution. In <ref> [8] </ref>, Gao et al studied the weighted loop fusion problem in the context of array contraction, and presented a polynomial-time algorithm based on the max-flow/min-cut algorithm as a heuristic solution.
Reference: [9] <author> A. Goldberg and R. Paige. </author> <title> Stream processing. </title> <booktitle> 1984 ACM Symposium on Lisp and Functional Programming, </booktitle> <pages> pages 53-62, </pages> <month> August </month> <year> 1984. </year> <institution> Austin, TX. </institution>
Reference-contexts: Second, the inter-cluster dependence graph defined by the fusion partition must be acyclic. This general definition of a fusion partition subsumes restricted definitions of "horizontal" and "vertical" loop fusion that have been considered in past work (see <ref> [9] </ref> for a brief summary). Weighted loop fusion is the problem of finding a legal fusion partition of loop nests into fusible clusters so as to minimize the total inter-cluster node-pair weights. It has been shown in past work that the weighted loop fusion problem is NP-hard [12]. <p> The authors proved that the unordered typed fusion problem can be solved optimally in polynomial time for two types, but is NP-hard in general. In <ref> [9] </ref>, Goldberg and Paige studied the problem of stream processing, an optimization technique that is related to loop fusion. They showed how stream processing and loop fusion techniques can be used to avoid intermediate storage in database queries and thus reduce the execution time of the queries.
Reference: [10] <author> IBM. </author> <title> IBM Optimization Subroutine Library (OSL) User Guide and Reference, Version 1, Release 2.1. </title> <type> Technical report, </type> <institution> International Business Machines, </institution> <year> 1995. </year> <note> Pub. No. SC23-0519-04 (also see http://www.research.ibm.com/osl/osl). </note>
Reference-contexts: A prototype implementation of this approach has been completed. Since the integer programming formulation is provably optimal, the focus of our initial experimental results is on measuring the compile-time complexity of this approach. We present preliminary measurements of the execution time taken by the IBM Optimization Subroutine Library (OSL) <ref> [10] </ref> to solve integer-programming instances of the weighted loop fusion problem.
Reference: [11] <author> Francois Irigoin and Remi Triolet. </author> <title> Supernode Partitioning. </title> <booktitle> Conference Record of Fifteenth ACM Symposium on Principles of Programming Languages, </booktitle> <year> 1988. </year>
Reference-contexts: As a result, being able to handle loops efficiently is of fundamental importance. A lot of the past work in optimizing the performance of loops has focused on individual loop nests rather than on collections of loop nests <ref> [2, 11, 3, 24, 22, 23, 20] </ref>. This paper examines the weighted loop fusion problem. Each pair of loop nests has an associated non-negative weight which is the cost savings that would be obtained if the two loop nests were fused. <p> A node in the LDG represents a perfect loop nest i.e., a set of perfectly nested loops [24]. We assume that, prior to loop fusion, suitable iteration-reordering loop transformations have been performed on the individual loop nests <ref> [2, 11, 3, 24, 22, 23, 20, 19] </ref> and that individual loops have been identified as being parallel or serial (either by programmer input or by automatic parallelization).
Reference: [12] <author> Ken Kennedy and Kathryn S. McKinley. </author> <title> Maximizing loop parallelism and improving data locality via loop fusion and distribution. </title> <booktitle> Springer-Verlag Lecture Notes in Computer Science, 768. Proceedings of the Sixth Workshop on Languages and Compilers for Parallel Computing, </booktitle> <address> Portland, Oregon, </address> <month> August </month> <year> 1993. </year>
Reference-contexts: Weighted loop fusion is the problem of finding a legal fusion partition of loop nests into fusible clusters so as to minimize the total inter-cluster node-pair weights. It has been shown in past work that the weighted loop fusion problem is NP-hard <ref> [12] </ref>. Hence greedy algorithms are used in practice to obtain heuristic solutions to the weighted loop fusion problem with no proven performance bounds on how the heuristic solutions compare to optimal solutions. <p> In [8], Gao et al studied the weighted loop fusion problem in the context of array contraction, and presented a polynomial-time algorithm based on the max-flow/min-cut algorithm as a heuristic solution. In <ref> [12] </ref>, Kennedy and McKinley proved that the weighted loop fusion problem is NP-hard and presented two polynomial-time algorithms as heuristic solutions, a simple greedy algorithm and a more powerful algorithm based on the max-flow/min-cut algo-rithm.
Reference: [13] <author> Ken Kennedy and Kathryn S. McKinley. </author> <title> Typed Fusion with Applications to Parallel and Sequential Code Generation. </title> <type> Technical report, </type> <institution> Department of Computer Science, Rice University, </institution> <year> 1993. </year> <month> TR93-208. </month>
Reference-contexts: In [4], Callahan presented a greedy partitioning algorithm for unweighted loop fusion and proved its optimality. In <ref> [13] </ref>, Kennedy and McKinley extended Callahan's result by addressing the problem of (unweighted) typed fusion, an extension to unweighted loop fusion in which each loop has an assigned type and only loops of the same type can be fused together.
Reference: [14] <author> M. Metcalfe and J. Reid. </author> <title> Fortran 90 Explained. </title> <publisher> Oxford Science Publishers, </publisher> <year> 1990. </year>
Reference-contexts: This suggests that the weighted loop fusion problem instances are likely to be small (&lt; 20 loop nests) for Fortran 77 programs, which certainly makes them ideal candidates for our integer programming solutions. In the future, we expect to see larger LDG's when optimizing Fortran 90 <ref> [14] </ref> programs with array language constructs, because they get compiled to code that typically contains a larger number of conformable loop nests than are found in Fortran 77 programs. 6 A Branch-And-Bound Method The preliminary experimental results in Section 5 suggest that the instances of the integer programming formulation in Problem
Reference: [15] <author> George L. Nemhauser and Laurence A. Wolsey. </author> <title> Integer and Combinatorial Optimization. </title> <publisher> John Wiley & Sons, </publisher> <year> 1988. </year> <note> Wiley Interscience Series in Discrete Mathematics and Optimization. </note>
Reference-contexts: The second condition in the above corollary statement ensures that if x ij = 1 and (i; j) 2 A then necessarily j &gt; i . The weighted loop fusion problem can now be modeled as the following mixed integer programming problem (see <ref> [15] </ref>, for example, as a reference for mixed integer programming): Problem 3.5.
Reference: [16] <author> Vivek Sarkar. </author> <title> Determining Average Program Execution Times and their Variance. </title> <booktitle> Proceedings of the 1989 SIGPLAN Conference on Programming Language Design and Implementation, </booktitle> <volume> 24(7) </volume> <pages> 298-312, </pages> <month> July </month> <year> 1989. </year>
Reference-contexts: Weights may also take into account execution probabilities for conditionals in the loop bodies <ref> [16] </ref>. An undirected weight graph can be used as a sparse representation of the weights such that there is an edge connecting nodes i and j if and only if the weight w ij = w ji is nonzero.
Reference: [17] <author> Vivek Sarkar. </author> <title> Partitioning and Scheduling Parallel Programs for Multiprocessors. </title> <publisher> Pitman, London and The MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1989. </year> <booktitle> In the series, Research Monographs in Parallel and Distributed Computing. </booktitle>
Reference-contexts: In addition, we will explore the possibility of developing integer programming solutions for other compiler-related NP-hard graph partitioning problems such as those introduced in <ref> [17, 18] </ref>.
Reference: [18] <author> Vivek Sarkar. </author> <title> Automatic Partitioning of a Program Dependence Graph into Parallel Tasks. </title> <journal> IBM Journal of Research and Development, </journal> <volume> 35(5/6), </volume> <year> 1991. </year>
Reference-contexts: In addition, we will explore the possibility of developing integer programming solutions for other compiler-related NP-hard graph partitioning problems such as those introduced in <ref> [17, 18] </ref>.
Reference: [19] <author> Vivek Sarkar. </author> <title> Automatic Selection of High Order Transformations in the IBM XL Fortran Compilers. </title> <journal> IBM Journal of Research and Development, </journal> <volume> 41(3), </volume> <month> May </month> <year> 1997. </year>
Reference-contexts: The problem instances were obtained from loop dependence graphs built by the IBM ASTI high-level optimizer, which provides the foundation for high-order transformations <ref> [19] </ref> and automatic shared-memory parallelization [5] in the latest IBM xl fortran (xlf) compilers for RS/6000 and PowerPC unipro-cessors and symmetric multiprocessors (SMP's), and for automatic distributed-memory parallelization in the IBM xl high performance fortran (xlhpf) compiler for the SP-2 distributed-memory multiprocessor [21]. <p> A node in the LDG represents a perfect loop nest i.e., a set of perfectly nested loops [24]. We assume that, prior to loop fusion, suitable iteration-reordering loop transformations have been performed on the individual loop nests <ref> [2, 11, 3, 24, 22, 23, 20, 19] </ref> and that individual loops have been identified as being parallel or serial (either by programmer input or by automatic parallelization). <p> We used this simple cost measure for the sake of illustration though it does capture register locality and cache locality. We would recommend using a more sophisticated locality cost model, such as the cost models in <ref> [7, 22, 19] </ref>, when computing weights for use in a real compiler. Thus, in the cost model for this example, w 12 = 1 because the load of A (I) would be saved in loop 20 if it is fused with loop 10 (see program text in Figure 1). <p> We present preliminary measurements of the execution time taken by the IBM Optimization Subroutine Library (OSL) package to solve integer-programming problem instances obtained from loop dependence graphs built by the IBM ASTI high-level optimizer, which provides the foundation for high-order transformations <ref> [19] </ref> and automatic shared-memory parallelization [5] in the latest IBM xl fortran (xlf) compilers for RS/6000 and PowerPC unipro-cessors and symmetric multiprocessors (SMP's), and for automatic distributed-memory parallelization in the IBM xl high performance fortran (xlhpf) compiler for the SP-2 distributed-memory multiprocessor [21].
Reference: [20] <author> Vivek Sarkar and Radhika Thekkath. </author> <title> A General Framework for Iteration-Reordering Loop Transformations. </title> <booktitle> Proceedings of the ACM SIGPLAN '92 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 175-187, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: As a result, being able to handle loops efficiently is of fundamental importance. A lot of the past work in optimizing the performance of loops has focused on individual loop nests rather than on collections of loop nests <ref> [2, 11, 3, 24, 22, 23, 20] </ref>. This paper examines the weighted loop fusion problem. Each pair of loop nests has an associated non-negative weight which is the cost savings that would be obtained if the two loop nests were fused. <p> A node in the LDG represents a perfect loop nest i.e., a set of perfectly nested loops [24]. We assume that, prior to loop fusion, suitable iteration-reordering loop transformations have been performed on the individual loop nests <ref> [2, 11, 3, 24, 22, 23, 20, 19] </ref> and that individual loops have been identified as being parallel or serial (either by programmer input or by automatic parallelization).
Reference: [21] <author> Ko-Yang Wang, Wei-Min Ching, Manish Gupta, Sam Midkiff, Edith Schonberg, and Dave Shields. </author> <title> Improving the Performance of HPF Compilers. </title> <booktitle> Proceedings of the Fifth Workshop on Compilers for Parallel Computers (CPC '95), Malaga, </booktitle> <address> Spain, </address> <month> June </month> <year> 1995. </year>
Reference-contexts: optimizer, which provides the foundation for high-order transformations [19] and automatic shared-memory parallelization [5] in the latest IBM xl fortran (xlf) compilers for RS/6000 and PowerPC unipro-cessors and symmetric multiprocessors (SMP's), and for automatic distributed-memory parallelization in the IBM xl high performance fortran (xlhpf) compiler for the SP-2 distributed-memory multiprocessor <ref> [21] </ref>. The rest of the paper is organized as follows. Section 2 describes the program representation assumed and also defines the weighted loop fusion optimization problem. The integer programming formulation is then developed in Section 3. <p> optimizer, which provides the foundation for high-order transformations [19] and automatic shared-memory parallelization [5] in the latest IBM xl fortran (xlf) compilers for RS/6000 and PowerPC unipro-cessors and symmetric multiprocessors (SMP's), and for automatic distributed-memory parallelization in the IBM xl high performance fortran (xlhpf) compiler for the SP-2 distributed-memory multiprocessor <ref> [21] </ref>. To test out the solution provided in this paper, the ASTI optimizer was extended to compute load-reuse weights (as in Section 4) for each LDG encountered in the loop fusion phase, and to print out the weighted LDG's. LDG's taken from a small set of test programs.
Reference: [22] <author> Michael E. Wolf and Monica S. Lam. </author> <title> A Data Locality Optimization Algorithm. </title> <booktitle> Proceedings of the ACM SIG-PLAN Symposium on Programming Language Design and Implementation, </booktitle> <pages> pages 30-44, </pages> <month> June </month> <year> 1991. </year>
Reference-contexts: As a result, being able to handle loops efficiently is of fundamental importance. A lot of the past work in optimizing the performance of loops has focused on individual loop nests rather than on collections of loop nests <ref> [2, 11, 3, 24, 22, 23, 20] </ref>. This paper examines the weighted loop fusion problem. Each pair of loop nests has an associated non-negative weight which is the cost savings that would be obtained if the two loop nests were fused. <p> A node in the LDG represents a perfect loop nest i.e., a set of perfectly nested loops [24]. We assume that, prior to loop fusion, suitable iteration-reordering loop transformations have been performed on the individual loop nests <ref> [2, 11, 3, 24, 22, 23, 20, 19] </ref> and that individual loops have been identified as being parallel or serial (either by programmer input or by automatic parallelization). <p> We used this simple cost measure for the sake of illustration though it does capture register locality and cache locality. We would recommend using a more sophisticated locality cost model, such as the cost models in <ref> [7, 22, 19] </ref>, when computing weights for use in a real compiler. Thus, in the cost model for this example, w 12 = 1 because the load of A (I) would be saved in loop 20 if it is fused with loop 10 (see program text in Figure 1).
Reference: [23] <author> Michael E. Wolf and Monica S. Lam. </author> <title> A Loop Transformation Theory and an Algorithm to Maximize Parallelism. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 2(4) </volume> <pages> 452-471, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: As a result, being able to handle loops efficiently is of fundamental importance. A lot of the past work in optimizing the performance of loops has focused on individual loop nests rather than on collections of loop nests <ref> [2, 11, 3, 24, 22, 23, 20] </ref>. This paper examines the weighted loop fusion problem. Each pair of loop nests has an associated non-negative weight which is the cost savings that would be obtained if the two loop nests were fused. <p> A node in the LDG represents a perfect loop nest i.e., a set of perfectly nested loops [24]. We assume that, prior to loop fusion, suitable iteration-reordering loop transformations have been performed on the individual loop nests <ref> [2, 11, 3, 24, 22, 23, 20, 19] </ref> and that individual loops have been identified as being parallel or serial (either by programmer input or by automatic parallelization).
Reference: [24] <author> Michael J. Wolfe. </author> <title> Optimizing Supercompilers for Supercomputers. </title> <publisher> Pitman, London and The MIT Press, </publisher> <address> Cam-bridge, Massachusetts, </address> <year> 1989. </year> <booktitle> In the series, Research Monographs in Parallel and Distributed Computing. </booktitle>
Reference-contexts: As a result, being able to handle loops efficiently is of fundamental importance. A lot of the past work in optimizing the performance of loops has focused on individual loop nests rather than on collections of loop nests <ref> [2, 11, 3, 24, 22, 23, 20] </ref>. This paper examines the weighted loop fusion problem. Each pair of loop nests has an associated non-negative weight which is the cost savings that would be obtained if the two loop nests were fused. <p> A node in the LDG represents a perfect loop nest i.e., a set of perfectly nested loops <ref> [24] </ref>. We assume that, prior to loop fusion, suitable iteration-reordering loop transformations have been performed on the individual loop nests [2, 11, 3, 24, 22, 23, 20, 19] and that individual loops have been identified as being parallel or serial (either by programmer input or by automatic parallelization). <p> A node in the LDG represents a perfect loop nest i.e., a set of perfectly nested loops [24]. We assume that, prior to loop fusion, suitable iteration-reordering loop transformations have been performed on the individual loop nests <ref> [2, 11, 3, 24, 22, 23, 20, 19] </ref> and that individual loops have been identified as being parallel or serial (either by programmer input or by automatic parallelization). <p> Each edge in the LDG is marked as being contractable or noncontractable. An LDG edge is marked as noncon-tractable if its source and destination loop nests cannot be fused because doing so would violate the data dependence test for loop fusion <ref> [24] </ref>. Algorithm Contractable (L; M ) in Figure 3 outlines the contractability test for nodes (loop nests) L and M assuming that there is at least one LDG edge from L to M . <p> This gives us the upper bound, V 1 (C 0 ; O) V 2 (C 0 ; O) + (i;j)2O 7 Related Work Loop distribution <ref> [24] </ref> is a well known loop transformation that separates a single loop nest into multiple conformable loop nests and is thus the inverse of loop fusion. Loop distribution is effective in controlling register pressure and in creating a larger number of loop nests to feed into loop fusion. <p> The goal of combining distribution and fusion is to automatically select an optimized fusion/distribution configuration i.e., an optimized regrouping of statements. Therefore, without any loss of generality, we can assume that all loop nests are maximally distributed <ref> [24] </ref> before any fusion transformation is applied. Maximal distribution also yields a larger number of perfect loop nests that can be subject to iteration-reordering loop transformations (e.g., interchange, tiling) before loop fusion.
References-found: 24

