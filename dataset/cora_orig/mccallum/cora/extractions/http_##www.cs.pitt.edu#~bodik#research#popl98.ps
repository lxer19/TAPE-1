URL: http://www.cs.pitt.edu/~bodik/research/popl98.ps
Refering-URL: http://www.cs.pitt.edu/~bodik/research/popl98.html
Root-URL: 
Email: bodik@cs.pitt.edu  anik@hpl.hp.com  
Title: Path-Sensitive Value-Flow Analysis  
Author: Rastislav Bodk Sadun Anik 
Keyword: data-flow analysis frameworks, path-sensitive value numbering, partial redundancy elimination, interpro-cedural constant propagation.  
Address: Pittsburgh Pittsburgh, PA 15260  1501 Page Mill Road Palo Alto, CA 94304  
Affiliation: Dept. of Computer Science University of  Hewlett-Packard Laboratories  
Abstract: When analyzing programs for value recomputation, one faces the problem of naming the value that flows between equivalent computations with different lexical names. This paper presents a data-flow analysis framework that overcomes this problem by synthesizing a name space tailored for tracing the values whose flow is of interest to a given data-flow problem. Furthermore, to exploit recomputation of a value with multiple, synonymous names, path-sensitive value numbering on the synthetic name space is developed. Optimizations that rely on value flow to detect redundant computations, such as partial redundancy elimination and constant propagation, become more powerful when phrased in our framework. The framework is built on a new program representation called Value Name Graph (VNG) which gains its power from integrating three orthogonal techniques: symbolic back-substitution, value numbering, and data-flow analysis. Our experiments with the implementation show that analysis on the VNG is practical in both time and space. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> G. Agrawal, J. Saltz, and R. Das. </author> <title> Interprocedural partial redundancy elimination and its application to distributed memory compilation. </title> <booktitle> In ACM SIGPLAN '95 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 258-269, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: At the first line, A [min] is loaded under the lexical name A [0]. Commonly used techniques fail to optimize the program because common subexpression elimination [2], or partial redundancy elimination <ref> [1, 17, 18, 31, 33] </ref> based on data-flow problems that are solved over a space of lexical names can only detect value reuse between the consecutive loads of A [min]. <p> In this section, VNG is used to develop a transformation that removes from the program (some of) these redundant computations. This optimization is known as Partial Redundancy Elimination (PRE) [33], most commonly performed on the name space of lexical names using code motion <ref> [1, 17, 18, 19, 31, 32, 33] </ref>. Solving the data-flow problems constituting the optimization on the VNG results in a PRE algorithm that is strictly more powerful than the optimal lexical algorithm in [32]. <p> Last, we propose an efficient implementation and empirically confirm the practicality of the approach. The VNG framework generalizes the lexical expression names used in partial redundancy elimination (which is based on data-flow analysis alone) <ref> [1, 17, 18, 31, 33] </ref> by using symbolic back-substitution and relating the names with the power of value numbering techniques [4, 37]. We refer the reader to Section 2 for a comparison of these techniques.
Reference: [2] <author> Alfred V. Aho, Ravi Sethi, and Jeffrey D. Ullman. </author> <booktitle> Compilers Principles, Techniques, and Tools. </booktitle> <publisher> Addison Wesley, </publisher> <year> 1986. </year>
Reference-contexts: At the first line, A [min] is loaded under the lexical name A [0]. Commonly used techniques fail to optimize the program because common subexpression elimination <ref> [2] </ref>, or partial redundancy elimination [1, 17, 18, 31, 33] based on data-flow problems that are solved over a space of lexical names can only detect value reuse between the consecutive loads of A [min]. <p> The first three benchmarks come from spec92, grep is a Unix utility, and the mm's are simple matrix multiplies, with static and dynamic memory allocation, respectively. Before the VNG analysis was applied, all classical optimizations <ref> [2] </ref> were applied on these procedures. In a majority of procedures in Table 1, the growth rate of S is linear; in a few, the rate only slightly exceeds a linear curve.
Reference: [3] <author> F. Allen, B.K. Rosen, and K. Zadeck. </author> <title> Optimization in Compilers, Chapter 6, Value Numbering (unpublished). </title> <publisher> ACM Press/Addison Wesley, </publisher> <year> 1992. </year>
Reference-contexts: These techniques can be used independently to eliminate redundant computations, but none is strictly superior to the others <ref> [3] </ref>. Symbolic back-substitution with value numbering. In the example below, the two computations refer to the same value. Neither global value numbering [37] nor symbolic back-substitution can detect this relationship, unless they work in concert. We propose the following method for combining them.
Reference: [4] <author> Bowen Alpern, Mark N. Wegman, and F. Kenneth Zadeck. </author> <title> Detecting equalities of variables in programs. </title> <booktitle> In 15th Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 1-11, </pages> <address> San Diego, California, </address> <month> January </month> <year> 1988. </year>
Reference-contexts: Class partitioning is optimistic: the algorithm initially assumes that all names at each node belong to the 1 Unless the symbolic pattern P is a single program variable. 2 By transforming the names into the SSA form <ref> [4, 37] </ref>, the value numbers for the name space can be computed globally (cf. Section 6). Input: value transfer functions: VT [n; e], names live on exit of node n: S out [n]. <p> Computing the equivalence of symbolic names separately at each CFG node consumes excessive memory. Because a name e typically refers to the same value over many neighboring nodes, the C [n; e] array stores greatly redundant information which can be removed if names are transformed to the SSA form <ref> [4, 37] </ref>, similar to the SSA form of expressions defined in [12]. <p> The VNG framework generalizes the lexical expression names used in partial redundancy elimination (which is based on data-flow analysis alone) [1, 17, 18, 31, 33] by using symbolic back-substitution and relating the names with the power of value numbering techniques <ref> [4, 37] </ref>. We refer the reader to Section 2 for a comparison of these techniques.
Reference: [5] <author> R. A. Ballance, A. B. Maccabe, and K. J. Ottenstein. </author> <title> The program dependence web: a representation supporting control-, data-, and demand-driven interpretation of imperative programs. </title> <booktitle> In Proceedings of the ACM SIGPLAN '90 Conference on Programming Language Design and Implementation, </booktitle> <volume> volume 25, </volume> <pages> pages 257-271, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: Symbolic back-substitution have been used to determine properties of computed values. Reif and Lewis provide a formalism for using back-substituted symbolic expression names on the program CFG for determining constant values [36]. More recently, a symbolic back-substitution technique based on the Gated SSA (GSA) representation <ref> [5] </ref> is presented by Tu and Padua in [41]. Rather than projecting symbolic expressions on to the CFG points, they assign path predicates to symbolic expressions using the gating functions of GSA.
Reference: [6] <author> Rastislav Bodik and Rajiv Gupta. </author> <title> Array data flow analysis for load-store optimizations in fine-grain architectures. </title> <journal> International Journal of Parallel Programming, </journal> <volume> 24(6) </volume> <pages> 481-512, </pages> <month> December </month> <year> 1996. </year>
Reference-contexts: This issue arises also in binary program translation or run-time optimizations. The VNG is able to reconstruct sufficient relationships among address computations to remove recurrent memory accesses <ref> [6, 9, 11, 20] </ref>. Finally, the scope of the VNG can be a single loop or a trace, making it attractive to just-in-time compilation. <p> Expression reassociation is orthogonal to the methodology presented in this paper. By using our framework on a reassociated program, one can benefit from the combined power of the two approaches. Finally, there are data-flow frameworks for array value-flow analysis, intended primarily for load/store elimination <ref> [6, 20] </ref>. Their application domains are limited to single loops in which loop indices are incremented unconditionally and address expressions of interest for load/store operations are affine functions of such loop indices.
Reference: [7] <author> Rastislav Bodik, Rajiv Gupta, and Mary Lou Soffa. </author> <title> In-terprocedural conditional branch elimination. </title> <booktitle> In Proceedings of the ACM SIGPLAN '97 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 146-158, </pages> <month> June </month> <year> 1997. </year>
Reference-contexts: If some symbolic patterns P permit dramatic name space growth in practice, the size of S can be restricted during its demand-driven construction by terminating the back-substitution as soon as a predetermined number of names has been created. Such approach was successfully used in the demand-driven analysis in <ref> [7] </ref>. Table 1 also reports other VNG characteristics relevant to efficient implementation. The column N gives the number of CFG nodes in each procedure. Each node contains a single intermediate statement.
Reference: [8] <author> Preston Briggs and Keith D. Cooper. </author> <title> Effective partial redundancy elimination. </title> <booktitle> In Proceedings of the Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 159-170, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: Note that the necessary name 2a b neither lexically appears in the program text, nor can be reassociated <ref> [8] </ref> from any lexical expression by reordering of operands. Therefore, to carry out a more powerful analysis, a customized name space must be built. This paper makes the following main contributions: Analysis framework for value-flow problems. <p> Johnson and Schlansker describe how such a system can be constructed and utilized in solving predicated flow problems [27]. Briggs and Cooper show that by careful reassociation of program expressions, one can expose more redundancies in a program <ref> [8] </ref>. Our framework is not strictly more powerful than theirs because their reassociated program may compute values that were not computed in the original program, which means that these values will not be in our name space, thus escaping our analysis.
Reference: [9] <author> David Callahan, Steve Carr, and Ken Kennedy. </author> <title> Improving register allocation for subscripted variables. </title> <booktitle> In Proceedings of the ACM SIGPLAN '90 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 53-65, </pages> <month> June </month> <year> 1990. </year> <month> 14 </month>
Reference-contexts: This issue arises also in binary program translation or run-time optimizations. The VNG is able to reconstruct sufficient relationships among address computations to remove recurrent memory accesses <ref> [6, 9, 11, 20] </ref>. Finally, the scope of the VNG can be a single loop or a trace, making it attractive to just-in-time compilation.
Reference: [10] <author> David Callahan, Keith D. Cooper, Ken Kennedy, and Linda Torczon. </author> <title> Interprocedural constant propagation. </title> <booktitle> In Proceedings of the SIGPLAN '86 Symposium on Compiler Construction, </booktitle> <pages> pages 152-161, </pages> <month> July </month> <year> 1986. </year>
Reference-contexts: Finally, all original computation are replaced with temporaries. 8 Application 2: Precise Interprocedural Non linear Constant Propagation The traditional formulation of Constant Propagation (CP) does not distribute across the meet operator, therefore, in-terprocedural algorithms for this data-flow problem need to trade precision for effectiveness <ref> [10, 25] </ref>. Recently, a distributive formulation of a linear version of CP was presented [38]. The linear version is restricted in that only assignments with at most one variable in the right-hand side (e.g., x:=2*y+3) are interpreted.
Reference: [11] <author> Steve Carr and Ken Kennedy. </author> <title> Scalar replacement in the presence of conditional control flow. </title> <journal> Software Practice and Experience, </journal> <volume> 24(1) </volume> <pages> 51-77, </pages> <month> January </month> <year> 1994. </year>
Reference-contexts: VNG is also being used to carry out PRE of load/store operations; it is worth noting that the popular (cf. [26]) algorithm in <ref> [11] </ref> computes 11 data-flow problems, while the VNG is able to subsume this optimization by solving only three problems. We are currently considering the use of VNG for array bound check optimizations and for synthesizing run-time memory disambiguation. Distributive formulations of non-distributive problems. <p> This issue arises also in binary program translation or run-time optimizations. The VNG is able to reconstruct sufficient relationships among address computations to remove recurrent memory accesses <ref> [6, 9, 11, 20] </ref>. Finally, the scope of the VNG can be a single loop or a trace, making it attractive to just-in-time compilation.
Reference: [12] <author> Fred Chow, Sun Chan, Robert Kennedy, Shin-Ming Liu, Raymond Lo, and Peng Tu. </author> <title> A new algorithm for partial redundancy elimination based on SSA form. </title> <booktitle> In Proceedings of the ACM SIGPLAN '97 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 273-286, </pages> <address> Las Vegas, Necada, </address> <month> June 15-18, </month> <year> 1997. </year>
Reference-contexts: Because a name e typically refers to the same value over many neighboring nodes, the C [n; e] array stores greatly redundant information which can be removed if names are transformed to the SSA form [4, 37], similar to the SSA form of expressions defined in <ref> [12] </ref>.
Reference: [13] <author> Cliff Click. </author> <title> Global code motion/global value numbering. </title> <booktitle> In Proceedings of the ACM SIGPLAN '95 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 246-257, </pages> <address> La Jolla, California, </address> <month> June 18-21, </month> <year> 1995. </year>
Reference-contexts: We refer the reader to Section 2 for a comparison of these techniques. Instead of using lexical names, the redundancy elimination approach in <ref> [13] </ref> solves data-flow problems on the name space of global value numbers [37], which is insufficient to detect the redundancy in Figure 1 because neither A [min] nor A [i] from a given iteration has the same value number as A [min] in the subsequent iteration along each execution path.
Reference: [14] <author> P. Cousot and R. Cousot. </author> <title> Abstract intrepretation: a unified lattice model for static analysis of programs by construction or approximation of fixpoints. </title> <booktitle> In Conference Record of the 4th ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 238-252, </pages> <address> Los Angeles, CA, </address> <month> January </month> <year> 1977. </year>
Reference-contexts: Keywords: data-flow analysis frameworks, path-sensitive value numbering, partial redundancy elimination, interpro-cedural constant propagation. 1 Motivation The goal of global data-flow analysis is to collect facts that characterize point-wise properties of a program. Significant research effort has been invested in designing lattices of data-flow facts <ref> [14, 39] </ref>, which serve as the domain and range of data-flow functions. The orthogonal task of properly choosing the name space of data-flow functions can also greatly influence the precision of data-flow analysis. <p> To terminate the process, we restrict the back 3 substitution by allowing it at most W visits of a CFG node. This termination is similar to widening <ref> [14] </ref>. The VNG thus models the flow of a value along any W consecutive loop iterations, which provides sufficient scope for optimizations in the instruction-level parallelism domain. We present in Section 4.3 an extension of value numbering for capturing the value flow along infinitely long control flow paths. <p> By applying the inductive proof from Section 4.3, one can verify that the output of the following program is always 5. The lexical approaches we are aware of consider variables separately and will hence fail here because the widening operator <ref> [14] </ref> will determine that neither a nor b are constants at the output. <p> The power of the analysis is obtained through integration of symbolic back-substitution, value numbering, and data-flow analysis. Our work was inspired by the conceptual framework described by Rau [35] in the spirit of abstract interpretation <ref> [14] </ref>. He describes how repeated back-substitution of names along loop back-edges can detect loop-carried value equivalences on a path-per-path basis. The paper presents the problems that arise in naming and comparing symbolic ex 13 pression originating in different loop iterations. Our frame-work offers a practical solution to these problems.
Reference: [15] <author> Ron K. Cytron and Jeanne Ferrante. </author> <title> Efficiently computing -nodes on-the-fly. </title> <booktitle> In Proceedings of the 6th International Workshop on Languages and Compilers for Parallel Computing, </booktitle> <publisher> LNCS, </publisher> <pages> pages 461-476, </pages> <address> Oregon, </address> <month> August </month> <year> 1993. </year> <note> Springer-Verlag. </note>
Reference-contexts: If we define the static definition of a name e to be each VNG node (n; e) out where e was back-substituted into a different name, VT [n; e] 6= e, then a scalar SSA algorithm <ref> [15] </ref> can be easily adapted to treat these definitions as scalar definitions. The resulting -nodes will represent the desired effect.
Reference: [16] <author> Alain Deutsch. </author> <title> Interprocedural May-Alias analysis for pointers: Beyond k-limiting. </title> <journal> SIGPLAN Notices, </journal> <volume> 29(6) </volume> <pages> 230-241, </pages> <month> June </month> <year> 1994. </year> <booktitle> Proceedings of the ACM SIGPLAN '94 Conference on Programming Language Design and Implementation. </booktitle>
Reference-contexts: The back-substitution is simple and its use is restricted to the preprocessing stage of the analysis. A similar approach to custom name-space design is also applied in heap pointer alias analysis <ref> [16, 23] </ref>, where sufficiently expressive names for memory objects cannot be derived from any lexical names. The VNG for the loop example is shown in Figure 1.
Reference: [17] <author> Dhanajay M. Dhamdhere, Barry K. Rosen, and Kenneth F. Zadeck. </author> <title> How to analyze large programs efficiently and informatively. </title> <booktitle> In Proceedings of the Conference on Programming Language Design and Implementation (PLDI), </booktitle> <volume> volume 27, </volume> <pages> pages 212-223, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: At the first line, A [min] is loaded under the lexical name A [0]. Commonly used techniques fail to optimize the program because common subexpression elimination [2], or partial redundancy elimination <ref> [1, 17, 18, 31, 33] </ref> based on data-flow problems that are solved over a space of lexical names can only detect value reuse between the consecutive loads of A [min]. <p> In this section, VNG is used to develop a transformation that removes from the program (some of) these redundant computations. This optimization is known as Partial Redundancy Elimination (PRE) [33], most commonly performed on the name space of lexical names using code motion <ref> [1, 17, 18, 19, 31, 32, 33] </ref>. Solving the data-flow problems constituting the optimization on the VNG results in a PRE algorithm that is strictly more powerful than the optimal lexical algorithm in [32]. <p> Last, we propose an efficient implementation and empirically confirm the practicality of the approach. The VNG framework generalizes the lexical expression names used in partial redundancy elimination (which is based on data-flow analysis alone) <ref> [1, 17, 18, 31, 33] </ref> by using symbolic back-substitution and relating the names with the power of value numbering techniques [4, 37]. We refer the reader to Section 2 for a comparison of these techniques.
Reference: [18] <author> Dhananjay M. Dhamdhere. </author> <title> Practical adaptation of the global optimization algorithm of Morel and Renvoise. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 13(2) </volume> <pages> 291-294, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: At the first line, A [min] is loaded under the lexical name A [0]. Commonly used techniques fail to optimize the program because common subexpression elimination [2], or partial redundancy elimination <ref> [1, 17, 18, 31, 33] </ref> based on data-flow problems that are solved over a space of lexical names can only detect value reuse between the consecutive loads of A [min]. <p> In this section, VNG is used to develop a transformation that removes from the program (some of) these redundant computations. This optimization is known as Partial Redundancy Elimination (PRE) [33], most commonly performed on the name space of lexical names using code motion <ref> [1, 17, 18, 19, 31, 32, 33] </ref>. Solving the data-flow problems constituting the optimization on the VNG results in a PRE algorithm that is strictly more powerful than the optimal lexical algorithm in [32]. <p> Last, we propose an efficient implementation and empirically confirm the practicality of the approach. The VNG framework generalizes the lexical expression names used in partial redundancy elimination (which is based on data-flow analysis alone) <ref> [1, 17, 18, 31, 33] </ref> by using symbolic back-substitution and relating the names with the power of value numbering techniques [4, 37]. We refer the reader to Section 2 for a comparison of these techniques.
Reference: [19] <author> K. Drechsler and M. Stadel. </author> <title> A solution to a problem with Morel and Renvoise's "global optimization by suppression of partial redundancies". </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 10(4) </volume> <pages> 635-640, </pages> <month> October </month> <year> 1988. </year>
Reference-contexts: In this section, VNG is used to develop a transformation that removes from the program (some of) these redundant computations. This optimization is known as Partial Redundancy Elimination (PRE) [33], most commonly performed on the name space of lexical names using code motion <ref> [1, 17, 18, 19, 31, 32, 33] </ref>. Solving the data-flow problems constituting the optimization on the VNG results in a PRE algorithm that is strictly more powerful than the optimal lexical algorithm in [32].
Reference: [20] <author> E. Duesterwald, R. Gupta, and M. L. Soffa. </author> <title> A practical data flow framework for array reference analysis and its use in optimizations. </title> <booktitle> In Proceedings of the ACM SIGPLAN '93 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 68-77, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: This issue arises also in binary program translation or run-time optimizations. The VNG is able to reconstruct sufficient relationships among address computations to remove recurrent memory accesses <ref> [6, 9, 11, 20] </ref>. Finally, the scope of the VNG can be a single loop or a trace, making it attractive to just-in-time compilation. <p> Expression reassociation is orthogonal to the methodology presented in this paper. By using our framework on a reassociated program, one can benefit from the combined power of the two approaches. Finally, there are data-flow frameworks for array value-flow analysis, intended primarily for load/store elimination <ref> [6, 20] </ref>. Their application domains are limited to single loops in which loop indices are incremented unconditionally and address expressions of interest for load/store operations are affine functions of such loop indices.
Reference: [21] <author> Evelyn Duesterwald, Rajiv Gupta, and Mary Lou Soffa. </author> <title> Demand-driven computation of interprocedural data flow. </title> <booktitle> In Conference Record of the 22nd ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 37-48, </pages> <month> January </month> <year> 1995. </year>
Reference-contexts: OUT [n; e] = &gt; we compute the fixed point iteratively: IN [n] = m2pred (n) OUT [n] OUT [n] i = f n (IN [n] i ) An effective alternative to an iterative algorithm can be a demand-driven analyzer <ref> [21, 38] </ref>. Examples of VNG data-flow equations for specific problems are in Section 7. 5.1 Backward problems In backward problems, data-flow facts may merge not only at control flow confluence points, but also at each VNG node (n; e) in that has multiple successors due to the VT function.
Reference: [22] <author> Michael P. Gerlek, Eric Stoltz, and Michael Wolfe. </author> <title> Beyond induction variables: Detecting and classifying sequences using a demand-driven SSA form. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 17(1) </volume> <pages> 85-122, </pages> <month> January </month> <year> 1995. </year>
Reference-contexts: Implementation and experiments. We have implemented the framework in a VLIW backend compiler with the goal of supporting aggressive, path-sensitive elimination of redundant load/store operations. The emphasis was on handling loops with complicated control flow and conditional increments of induction variables <ref> [22] </ref> like min in Figure 1. The VNG is especially beneficial in a backend compiler because the limited symbol table information is not sufficient to map an array load back to the original index expression, e.g. to A [2 fl i + 3].
Reference: [23] <author> Rakesh Ghiya and Laurie J. Hendren. </author> <title> Connection analysis: A practical interprocedural heap analysis for C. </title> <journal> International Journal of Parallel Programming, </journal> <volume> 24(6) </volume> <pages> 547-578, </pages> <year> 1996. </year>
Reference-contexts: The back-substitution is simple and its use is restricted to the preprocessing stage of the analysis. A similar approach to custom name-space design is also applied in heap pointer alias analysis <ref> [16, 23] </ref>, where sufficiently expressive names for memory objects cannot be derived from any lexical names. The VNG for the loop example is shown in Figure 1.
Reference: [24] <author> G. Goff, K. Kennedy, and C.-W. Tseng. </author> <title> Practical Dependency Testing. </title> <booktitle> In Proceedings Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 15-29, </pages> <address> Ot-tawa, CDN, </address> <month> June </month> <year> 1991. </year> <journal> ACM SIGPLAN. SIGPLAN Notices, </journal> <volume> 26(6). </volume>
Reference-contexts: We have chosen these two values because they are most likely to be used in practice; there are few opportunities for loop carried value reuse beyond an iteration distance of two <ref> [24] </ref>. Surprisingly, the name space is much smaller that the set V .
Reference: [25] <author> Dan Grove and Linda Torczon. </author> <title> Interprocedural constant propagation: A study of jump function implementations. </title> <booktitle> In Proceedings of the ACM SIGPLAN '93 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 90-99, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: Finally, all original computation are replaced with temporaries. 8 Application 2: Precise Interprocedural Non linear Constant Propagation The traditional formulation of Constant Propagation (CP) does not distribute across the meet operator, therefore, in-terprocedural algorithms for this data-flow problem need to trade precision for effectiveness <ref> [10, 25] </ref>. Recently, a distributive formulation of a linear version of CP was presented [38]. The linear version is restricted in that only assignments with at most one variable in the right-hand side (e.g., x:=2*y+3) are interpreted.
Reference: [26] <author> Anne M. Holler. </author> <title> Optimization for a superscalar out-of-order machine. </title> <booktitle> In Proceedings of the 29th Annual International Symposium on Microarchitecture, </booktitle> <pages> pages 336-348, </pages> <month> December </month> <year> 1996. </year>
Reference-contexts: By using names created through back-substitution across multiple loop iterations, VNGPRE subsumes predictive commoning, an optimization aimed at removing common subexpressions recurring across loop iterations <ref> [26, 34] </ref>. VNG is also being used to carry out PRE of load/store operations; it is worth noting that the popular (cf. [26]) algorithm in [11] computes 11 data-flow problems, while the VNG is able to subsume this optimization by solving only three problems. <p> By using names created through back-substitution across multiple loop iterations, VNGPRE subsumes predictive commoning, an optimization aimed at removing common subexpressions recurring across loop iterations [26, 34]. VNG is also being used to carry out PRE of load/store operations; it is worth noting that the popular (cf. <ref> [26] </ref>) algorithm in [11] computes 11 data-flow problems, while the VNG is able to subsume this optimization by solving only three problems. We are currently considering the use of VNG for array bound check optimizations and for synthesizing run-time memory disambiguation. Distributive formulations of non-distributive problems.
Reference: [27] <author> Richard Johnson and Michael Schlansker. </author> <title> Analysis techniques for predicated code. </title> <booktitle> In Proceedings of the 29th Annual International Symposium on Microprogramming, </booktitle> <pages> pages 100-113, </pages> <month> December </month> <year> 1996. </year>
Reference-contexts: In order to use this representation for data-flow analysis, a powerful boolean symbolic evaluation system may be needed. Johnson and Schlansker describe how such a system can be constructed and utilized in solving predicated flow problems <ref> [27] </ref>. Briggs and Cooper show that by careful reassociation of program expressions, one can expose more redundancies in a program [8].
Reference: [28] <author> J. B. Kam and J. D. Ullman. </author> <title> Monotone data flow analysis frameworks. </title> <journal> Acta Informatica, </journal> <volume> 7 </volume> <pages> 305-317, </pages> <year> 1977. </year>
Reference-contexts: The approach in this paper is to transform a given data-flow problem defined on a lexical name space within a framework such as <ref> [28] </ref> or [29] into a problem on the VNG. The transformed problem uses the original lattice, however, its data-flow transfer functions are extended to direct data-flow facts between elements of the synthesized name space according to the value flow. <p> The data-flow problem performs a meet operation ^ at the confluence of these edges. 5 Data-flow Analysis Framework This section describes at an abstract level how data-flow problems are solved on the VNG. Given a data-flow problem defined within a framework such as <ref> [28] </ref> or [29], we transform it into a VNG data-flow problem.
Reference: [29] <author> G. A. Kildall. </author> <title> A unified approach to global program optimization. </title> <booktitle> In Conference Record of the Fifth Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 194-206, </pages> <year> 1973. </year>
Reference-contexts: The approach in this paper is to transform a given data-flow problem defined on a lexical name space within a framework such as [28] or <ref> [29] </ref> into a problem on the VNG. The transformed problem uses the original lattice, however, its data-flow transfer functions are extended to direct data-flow facts between elements of the synthesized name space according to the value flow. <p> The data-flow problem performs a meet operation ^ at the confluence of these edges. 5 Data-flow Analysis Framework This section describes at an abstract level how data-flow problems are solved on the VNG. Given a data-flow problem defined within a framework such as [28] or <ref> [29] </ref>, we transform it into a VNG data-flow problem.
Reference: [30] <author> Jens Knoop, O. Ruthing, and Bernhard Steffen. </author> <title> Code motion and code placement: </title> <type> Just synonyms? Technical Report MIP-9716, </type> <institution> Fakultat fur Mathematik und Informatik, University of Passau, </institution> <year> 1997. </year>
Reference-contexts: By phrasing data-flow problems constituting the optimization on the VNG, more redundant computations can be removed than when we rely on a lexical analysis. Furthermore, a new technique called path-sensitive value numbering allows us to develop a version of PRE that is more powerful than the best existing algorithms <ref> [30, 40] </ref>. By using names created through back-substitution across multiple loop iterations, VNGPRE subsumes predictive commoning, an optimization aimed at removing common subexpressions recurring across loop iterations [26, 34]. <p> VNG-PRE is a code-motion transformation: each original computation is moved upwards to its Earliest points, where it is removed if it is redundant. Knoop et al characterized in <ref> [30] </ref> a capability frontier beyond which code-motion transformations fail to eliminate redundancies detected in the class of 11 value-flow graphs like the VNG. Consider the example from [30], shown in Figure 11 (a). <p> Knoop et al characterized in <ref> [30] </ref> a capability frontier beyond which code-motion transformations fail to eliminate redundancies detected in the class of 11 value-flow graphs like the VNG. Consider the example from [30], shown in Figure 11 (a). While the computations in the nodes 5 and 6 are redundant and can be removed as shown in because placing either (or both) to the node 4 would not be compensated by removals along all paths. <p> The node 4 presents a barrier for the code motion because the two computations are not equal at the node, which prevents the code motion from considering them in concert. We present here an algorithm going beyond this frontier, subsuming the best known code-motion algorithms in <ref> [30, 40] </ref>. First, the program is optimized with the code-motion VNGPRE presented above. Next, we optimize the program further using a more aggressive Earliest notion. <p> The final earliest points compute values that are guaranteed to be used in a replacement along each path. 4 Therefore, this transformation cannot be characterized as a code motion, but rather as a code placement <ref> [30] </ref>. 12 Example 3. We illustrate the aggressive algorithm through the example in Figure 11. VNGPRE fails to remove the redundancy because no original computation can be hoisted. In fact, we are aware of no previous algorithm that can optimize this program. <p> The prior work can be best compared with our framework by examining what subset of the three underlying mechanisms it exploits. Knoop, Ruthing, and Steffen developed independently from us a representation called Value Flow Graph (VFG) which combines all three underlying mechanisms <ref> [30, 40] </ref>. Recently, they developed a VFG-based PRE algorithm that has identical power to our code-motion VNGPRE [30]. In comparison, our work offers the following benefits. First, their name space is based on a graph representation of a computation and has, therefore, very limited algebraic simplification capabilities. <p> Knoop, Ruthing, and Steffen developed independently from us a representation called Value Flow Graph (VFG) which combines all three underlying mechanisms [30, 40]. Recently, they developed a VFG-based PRE algorithm that has identical power to our code-motion VNGPRE <ref> [30] </ref>. In comparison, our work offers the following benefits. First, their name space is based on a graph representation of a computation and has, therefore, very limited algebraic simplification capabilities. As a result, the VFG discovers a smaller class of name equivalences that the VNG. <p> Third, the path-sensitive value numbering defined in Section 4.2 enables us to formulate a code placement PRE algorithm that is more powerful than theirs <ref> [30] </ref>. Furthermore, we specify how to minimize live ranges of temporary variables used in the PRE. Fourth, the distributive formulation of value numbering together with the inductive value numbering enables a novel interprocedural constant propagation. Last, we propose an efficient implementation and empirically confirm the practicality of the approach.
Reference: [31] <author> Jens Knoop, Oliver Ruthing, and Bernhard Steffen. </author> <title> Lazy code motion. </title> <journal> SIGPLAN Notices, </journal> <volume> 27(7) </volume> <pages> 224-234, </pages> <month> July </month> <year> 1992. </year> <booktitle> Proceedings of the ACM SIGPLAN '92 Conference on Programming Language Design and Implementation. </booktitle>
Reference-contexts: At the first line, A [min] is loaded under the lexical name A [0]. Commonly used techniques fail to optimize the program because common subexpression elimination [2], or partial redundancy elimination <ref> [1, 17, 18, 31, 33] </ref> based on data-flow problems that are solved over a space of lexical names can only detect value reuse between the consecutive loads of A [min]. <p> In this section, VNG is used to develop a transformation that removes from the program (some of) these redundant computations. This optimization is known as Partial Redundancy Elimination (PRE) [33], most commonly performed on the name space of lexical names using code motion <ref> [1, 17, 18, 19, 31, 32, 33] </ref>. Solving the data-flow problems constituting the optimization on the VNG results in a PRE algorithm that is strictly more powerful than the optimal lexical algorithm in [32]. <p> Also, all predicates in this section are defined to be false for each (n; ?), (n; &gt;), and for each dead VNG node. We develop VNGPRE as an adaptation of the lexical code-motion PRE in <ref> [31] </ref> in which optimization candidates are hoisted along each control flow path, in order to enable removal of the candidates in some hoisted points. First, we compute the global data-flow predicate AN which characterizes anticipability of a computation. <p> Last, we propose an efficient implementation and empirically confirm the practicality of the approach. The VNG framework generalizes the lexical expression names used in partial redundancy elimination (which is based on data-flow analysis alone) <ref> [1, 17, 18, 31, 33] </ref> by using symbolic back-substitution and relating the names with the power of value numbering techniques [4, 37]. We refer the reader to Section 2 for a comparison of these techniques.
Reference: [32] <author> Jens Knoop, Oliver Ruthing, and Bernhard Steffen. </author> <title> Optimal code motion: </title> <journal> Theory and practice. ACM Transactions on Programming Languages and Systems, </journal> <volume> 16(4) </volume> <pages> 1117-1155, </pages> <month> July </month> <year> 1994. </year>
Reference-contexts: In this section, VNG is used to develop a transformation that removes from the program (some of) these redundant computations. This optimization is known as Partial Redundancy Elimination (PRE) [33], most commonly performed on the name space of lexical names using code motion <ref> [1, 17, 18, 19, 31, 32, 33] </ref>. Solving the data-flow problems constituting the optimization on the VNG results in a PRE algorithm that is strictly more powerful than the optimal lexical algorithm in [32]. <p> Solving the data-flow problems constituting the optimization on the VNG results in a PRE algorithm that is strictly more powerful than the optimal lexical algorithm in <ref> [32] </ref>. The transformation, called VNGPRE, accomplishes PRE through a replacement of redundant computations with temporary variables and an insertion of equivalent computations into appropriate CFG edges, to initialize the temporaries. <p> Insertion of computations at earliest points unnecessarily increases register pressure. We now describe how the insertion points determined by VNGPRE can be moved forward as much as possible without increasing the number of computations along any path. This step is an adaptation of delayability from <ref> [32] </ref>. By computing the global predicate Delayed, earliest insertions are delayed until they reach a) some original computation, b) a node whose predecessor does not contain a delayed insertion, or c) an edge across which the delayed computation would have to be replicated.
Reference: [33] <author> E. Morel and C. Renviose. </author> <title> Global optimization by supres-sion of partial redundancies. </title> <journal> CACM, </journal> <volume> 22(2) </volume> <pages> 96-103, </pages> <month> February </month> <year> 1979. </year>
Reference-contexts: At the first line, A [min] is loaded under the lexical name A [0]. Commonly used techniques fail to optimize the program because common subexpression elimination [2], or partial redundancy elimination <ref> [1, 17, 18, 31, 33] </ref> based on data-flow problems that are solved over a space of lexical names can only detect value reuse between the consecutive loads of A [min]. <p> In this section, VNG is used to develop a transformation that removes from the program (some of) these redundant computations. This optimization is known as Partial Redundancy Elimination (PRE) <ref> [33] </ref>, most commonly performed on the name space of lexical names using code motion [1, 17, 18, 19, 31, 32, 33]. Solving the data-flow problems constituting the optimization on the VNG results in a PRE algorithm that is strictly more powerful than the optimal lexical algorithm in [32]. <p> In this section, VNG is used to develop a transformation that removes from the program (some of) these redundant computations. This optimization is known as Partial Redundancy Elimination (PRE) [33], most commonly performed on the name space of lexical names using code motion <ref> [1, 17, 18, 19, 31, 32, 33] </ref>. Solving the data-flow problems constituting the optimization on the VNG results in a PRE algorithm that is strictly more powerful than the optimal lexical algorithm in [32]. <p> Last, we propose an efficient implementation and empirically confirm the practicality of the approach. The VNG framework generalizes the lexical expression names used in partial redundancy elimination (which is based on data-flow analysis alone) <ref> [1, 17, 18, 31, 33] </ref> by using symbolic back-substitution and relating the names with the power of value numbering techniques [4, 37]. We refer the reader to Section 2 for a comparison of these techniques.
Reference: [34] <author> K. O'Brien, B. Hay, J. Minish, H. Schaffer, B. Schloss, A. Shepherd, and M. Zaleski. </author> <title> Advanced Compiler Technology for the RISC System/6000 Architecture. </title> <institution> IBM Corporation, </institution> <year> 1991. </year>
Reference-contexts: By using names created through back-substitution across multiple loop iterations, VNGPRE subsumes predictive commoning, an optimization aimed at removing common subexpressions recurring across loop iterations <ref> [26, 34] </ref>. VNG is also being used to carry out PRE of load/store operations; it is worth noting that the popular (cf. [26]) algorithm in [11] computes 11 data-flow problems, while the VNG is able to subsume this optimization by solving only three problems.
Reference: [35] <author> B. R. Rau. </author> <title> Data flow and dependence analysis for instruction level parallelism. </title> <booktitle> In Proceedings of the Fourth International Workshop on Languages and Compilers for Parallel Computing, </booktitle> <publisher> LNCS, </publisher> <pages> pages 236-250. </pages> <publisher> Springer-Verlag, </publisher> <year> 1991. </year>
Reference-contexts: The VNG enables formulation of algorithms for partial redundancy elimination and constant propagation that are more powerful than existing techniques. The power of the analysis is obtained through integration of symbolic back-substitution, value numbering, and data-flow analysis. Our work was inspired by the conceptual framework described by Rau <ref> [35] </ref> in the spirit of abstract interpretation [14]. He describes how repeated back-substitution of names along loop back-edges can detect loop-carried value equivalences on a path-per-path basis. The paper presents the problems that arise in naming and comparing symbolic ex 13 pression originating in different loop iterations.
Reference: [36] <author> J. H. Reif and H. R. Lewis. </author> <title> Symbolic evaluation and the global value graph. </title> <booktitle> In Conference Record of the Fourth annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 104-118. </pages> <publisher> ACM, ACM, </publisher> <month> January </month> <year> 1977. </year>
Reference-contexts: Symbolic back-substitution have been used to determine properties of computed values. Reif and Lewis provide a formalism for using back-substituted symbolic expression names on the program CFG for determining constant values <ref> [36] </ref>. More recently, a symbolic back-substitution technique based on the Gated SSA (GSA) representation [5] is presented by Tu and Padua in [41]. Rather than projecting symbolic expressions on to the CFG points, they assign path predicates to symbolic expressions using the gating functions of GSA.
Reference: [37] <author> Barry K. Rosen, Mark N. Wegman, and F. Kenneth Zadeck. </author> <title> Global value numbers and redundant computations. </title> <booktitle> In 15th Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 12-27, </pages> <address> San Diego, California, </address> <month> Jan-uary </month> <year> 1988. </year>
Reference-contexts: The equivalence of A [i] and A [min] along the then path is left undiscovered because these two computations are analyzed separately, having been partitioned according to their lexical names. Global value numbering <ref> [37] </ref> (1) x:=a+b names (v) = fx; a + bg t:=a+b (2) b:=2*a-x names (v) = fx; 2a bg ) b:=2*a-t (3) x:=a-b names (v) = fa + x; 2a bg x:=a-b (4) z:=a+x names (v) = fz; a + x; 2a bg z:=t is a method for determining which lexically <p> These techniques can be used independently to eliminate redundant computations, but none is strictly superior to the others [3]. Symbolic back-substitution with value numbering. In the example below, the two computations refer to the same value. Neither global value numbering <ref> [37] </ref> nor symbolic back-substitution can detect this relationship, unless they work in concert. We propose the following method for combining them. In the first step, back-substitution starting from both computations propagates backwards the corresponding symbolic names and creates the VNG. <p> Since the two names are derived from the names of the two computations, the computations must refer to the same value regardless of the taken path. In comparison with global value numbering <ref> [37] </ref>, our value numbering does not build equivalence classes over the definitions of program variables, but instead over the symbolic names created during the back-substitution step. Furthermore, the equivalence classes are built on each node in the program graph, rather than globally. The figure connects equivalent names with dotted lines. <p> The goal of VNG value numbering is to find for each node a partitioning of the name space into equivalence classes such that all names from a class denote the same value, along any path leading to the node. The process mimics the Global Value Numbering (GVN) <ref> [37] </ref> but differs from it in three respects. First, the equivalence relation is computed on the synthesized name space, rather than on the set of program variables. Second, the information about equivalence of names is propagated across value transfer functions VT obtained by symbolic back-substitution. <p> Class partitioning is optimistic: the algorithm initially assumes that all names at each node belong to the 1 Unless the symbolic pattern P is a single program variable. 2 By transforming the names into the SSA form <ref> [4, 37] </ref>, the value numbers for the name space can be computed globally (cf. Section 6). Input: value transfer functions: VT [n; e], names live on exit of node n: S out [n]. <p> The distributive version of value numbering is used in Section 8 to perform an interprocedural non-linear constant propagation and also in Section 4.3 to develop a more general value numbering algorithm. 4.2 Path-sensitive Value Numbering Both global value numbering <ref> [37] </ref> and the algorithm in Figure 6 find equivalences that are guaranteed to hold under any program input. When multiple equations define a particular data-flow problem, some of the equations may only be concerned with a subgraph of the VNG. <p> Computing the equivalence of symbolic names separately at each CFG node consumes excessive memory. Because a name e typically refers to the same value over many neighboring nodes, the C [n; e] array stores greatly redundant information which can be removed if names are transformed to the SSA form <ref> [4, 37] </ref>, similar to the SSA form of expressions defined in [12]. <p> The resulting -nodes will represent the desired effect. After such transformation, it is possible to record the results of value numbering in a single global table of size equal to the number of SSA names, as is done in global value numbering <ref> [37] </ref>. 7 Application 1: Partial Redundancy Elimination So far in this paper, the VNG has been presented as an analysis tool aimed at detecting computations that are redundant along some incoming paths due to prior, equivalent computations. <p> The VNG framework generalizes the lexical expression names used in partial redundancy elimination (which is based on data-flow analysis alone) [1, 17, 18, 31, 33] by using symbolic back-substitution and relating the names with the power of value numbering techniques <ref> [4, 37] </ref>. We refer the reader to Section 2 for a comparison of these techniques. <p> We refer the reader to Section 2 for a comparison of these techniques. Instead of using lexical names, the redundancy elimination approach in [13] solves data-flow problems on the name space of global value numbers <ref> [37] </ref>, which is insufficient to detect the redundancy in Figure 1 because neither A [min] nor A [i] from a given iteration has the same value number as A [min] in the subsequent iteration along each execution path. Symbolic back-substitution have been used to determine properties of computed values.
Reference: [38] <author> Mooly Sagiv, Thomas Reps, and Susan Horwitz. </author> <title> Precise in-terprocedural dataflow analysis with applications to constant propagation. </title> <booktitle> Theoretical Computer Science, </booktitle> <address> 167(1-2):131-170, </address> <month> 30 October </month> <year> 1996. </year>
Reference-contexts: OUT [n; e] = &gt; we compute the fixed point iteratively: IN [n] = m2pred (n) OUT [n] OUT [n] i = f n (IN [n] i ) An effective alternative to an iterative algorithm can be a demand-driven analyzer <ref> [21, 38] </ref>. Examples of VNG data-flow equations for specific problems are in Section 7. 5.1 Backward problems In backward problems, data-flow facts may merge not only at control flow confluence points, but also at each VNG node (n; e) in that has multiple successors due to the VT function. <p> Recently, a distributive formulation of a linear version of CP was presented <ref> [38] </ref>. The linear version is restricted in that only assignments with at most one variable in the right-hand side (e.g., x:=2*y+3) are interpreted. Using VNG, we are able to formulate a distributive, non-linear CP algorithm which can handle arbitrary assignments (within the domain of the symbolic pattern P ).
Reference: [39] <author> D. Scott. </author> <title> Lattice theory, data types, and semantics. </title> <publisher> Prentice-Hall, </publisher> <year> 1972. </year>
Reference-contexts: Keywords: data-flow analysis frameworks, path-sensitive value numbering, partial redundancy elimination, interpro-cedural constant propagation. 1 Motivation The goal of global data-flow analysis is to collect facts that characterize point-wise properties of a program. Significant research effort has been invested in designing lattices of data-flow facts <ref> [14, 39] </ref>, which serve as the domain and range of data-flow functions. The orthogonal task of properly choosing the name space of data-flow functions can also greatly influence the precision of data-flow analysis.
Reference: [40] <author> Bernhard Steffen, Jens Knoop, and O. Ruthing. </author> <title> The value flow graph: A program representation for optimal program transformations. </title> <booktitle> In Proceedings of the 3rd European Symposium on Programming (ESOP'90), </booktitle> <volume> volume 432, </volume> <pages> pages 389-405, </pages> <address> Kopenhagen (Denmark), </address> <month> May </month> <year> 1990. </year>
Reference-contexts: By phrasing data-flow problems constituting the optimization on the VNG, more redundant computations can be removed than when we rely on a lexical analysis. Furthermore, a new technique called path-sensitive value numbering allows us to develop a version of PRE that is more powerful than the best existing algorithms <ref> [30, 40] </ref>. By using names created through back-substitution across multiple loop iterations, VNGPRE subsumes predictive commoning, an optimization aimed at removing common subexpressions recurring across loop iterations [26, 34]. <p> The node 4 presents a barrier for the code motion because the two computations are not equal at the node, which prevents the code motion from considering them in concert. We present here an algorithm going beyond this frontier, subsuming the best known code-motion algorithms in <ref> [30, 40] </ref>. First, the program is optimized with the code-motion VNGPRE presented above. Next, we optimize the program further using a more aggressive Earliest notion. <p> The prior work can be best compared with our framework by examining what subset of the three underlying mechanisms it exploits. Knoop, Ruthing, and Steffen developed independently from us a representation called Value Flow Graph (VFG) which combines all three underlying mechanisms <ref> [30, 40] </ref>. Recently, they developed a VFG-based PRE algorithm that has identical power to our code-motion VNGPRE [30]. In comparison, our work offers the following benefits. First, their name space is based on a graph representation of a computation and has, therefore, very limited algebraic simplification capabilities.
Reference: [41] <author> P. Tu and D. Padua. </author> <title> Gated SSA-Based demand-driven symbolic analysis for parallelizing compilers. </title> <booktitle> In Conference proceedings of the 1995 International Conference on Supercomputing, </booktitle> <address> Barcelona, Spain, </address> <month> July 3-7, </month> <year> 1995, </year> <pages> pages 414-423, </pages> <year> 1995. </year>
Reference-contexts: Reif and Lewis provide a formalism for using back-substituted symbolic expression names on the program CFG for determining constant values [36]. More recently, a symbolic back-substitution technique based on the Gated SSA (GSA) representation [5] is presented by Tu and Padua in <ref> [41] </ref>. Rather than projecting symbolic expressions on to the CFG points, they assign path predicates to symbolic expressions using the gating functions of GSA. This approach can be effective in answering queries on pairs of symbolic expressions, especially when the resulting symbolic expressions have simple gating functions.
References-found: 41

