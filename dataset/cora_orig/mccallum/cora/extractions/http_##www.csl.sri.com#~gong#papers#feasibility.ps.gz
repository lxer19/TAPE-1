URL: http://www.csl.sri.com/~gong/papers/feasibility.ps.gz
Refering-URL: http://www.csl.sri.com/~gong/papers/pubs92.html
Root-URL: 
Title: Handling Infeasible Specifications of Cryptographic Protocols  
Author: Li Gong 
Address: 301A Dates Drive  Ithaca, NY 14850 Ithaca, NY 14853  
Affiliation: ORA Corporation Cornell University  Dept. of Computer Science  
Abstract: In the verification of cryptographic protocols along the approach of the logic for authentication by Burrows, Abadi, and Needham, it is possible to write a specification which does not faithfully represent the real world situation. Such a specification, though impossible or unreasonable to implement, can go undetected and be verified to be correct. It can also lead to logical statements that do not preserve causality, which in turn can have undesirable consequences. Such a specification, called an infeasible specification here, can be subtle and hard to locate. This note shows how the logic of cryptographic protocols by Gong, Needham, and Yahalom can be enhanced with a notion of eligibility to preserve causality of beliefs and detect infeasible specifications. It is conceivable that this technique can be adopted in other similar logics. 
Abstract-found: 1
Intro-found: 1
Reference: [Burrows 89] <author> M. Burrows, M. Abadi, R.M. Needham, </author> <title> "A Logic for Authentication", </title> <journal> in Proceedings of the Royal Society of London, </journal> <note> A 426, 1989, pp.233-271. </note>
Reference-contexts: As in the case of any algorithm, proving a protocol's (maybe only partial) correctness is desirable. Burrows, Abadi, and Needham devised a logic for authentication <ref> [Burrows 89] </ref> (subsequently referred to as the BAN logic), which opened a new direction in the specification and verification of cryptographic protocols. <p> Such advances of states are often viewed and treated as evolution of belief and knowledge [Halpern 84]. Burrows, Abadi, and Needham took a similar point of view and devised a logic for authentication <ref> [Burrows 89] </ref>. <p> Usually, a message of the form P ! Q : X stating that P sends message X (possibly including message enten-sions in the GNY logic) to Q is automatically transformed into a logical statement Q &lt; X, representing that Q received X <ref> [Burrows 89, Gong 90b, Kailar 91] </ref>. This is the point where infeasible specifications may slip through. In the revised GNY logic, no such transformation is done.
Reference: [Gong 90a] <author> L. Gong, </author> <title> "Cryptographic Protocols for Distributed Systems", </title> <type> PhD dissertation, </type> <institution> University of Cambridge, </institution> <month> April, </month> <year> 1990. </year>
Reference-contexts: A protocol is considered infeasible if either of the two requirements is violated. In the revised GNY logic, a notion of eligibility is introduced so that the feasibility checks become an integral part of the logical analysis <ref> [Gong 90a] </ref>. The remaining of this section shows how the logic works in this aspect. Only a brief description is given, and irrelevant parts of the logic are omitted. <p> Each of the postulates as given above takes care to cover the two types of infeasible specifications that can be possibly specified in the GNY logic. There are more postulates including those for using public-key systems (see <ref> [Gong 90a] </ref>). The rules as given above also ensure that any statement of the form P j Q j C can only be derived if Q j C already holds. Thus they enforce a causal relation between beliefs.
Reference: [Gong 90b] <author> L. Gong, R. Needham, and R. Yahalom, </author> <title> "Reasoning about Belief in Cryptographic Protocols", </title> <booktitle> in Proceedings of the IEEE 1990 Symposium on Security and Privacy, </booktitle> <address> Oakland, California, </address> <month> May, </month> <year> 1990, </year> <month> pp.234-248. </month>
Reference-contexts: Non-causality is sometimes undesirable [Kailar 91]. This note first uses a few examples to point out the potential problems with infeasibility and non-causality. It then shows how a simple enhancement to a similar logic <ref> [Gong 90b] </ref> can handle these issues. Readers are assumed to be familiar with the related literature. 2 The BAN Logic, Feasibility, and Causality A protocol specifies the interactions between processes. A process can be viewed as a state machine. <p> This is especially useful because some errors can be very subtle and difficult to locate. 3 Handling Infeasible Specifications Gong, Needham, and Yahalom developed a logic for analyzing cryptographic protocols <ref> [Gong 90b] </ref> (referred to as the GNY logic) along the line of the BAN logic. The major difference is that the GNY logic works at a lower level of abstraction thus removing many restrictions (re quirements) in the BAN logic. <p> It also allows a principal to receive and make use of some formulas (e.g. ciphertexts) without knowing their contents (e.g. plain-texts). A more detailed description of the GNY logic and a summary of the differences between it and the BAN logic can be found in a earlier paper <ref> [Gong 90b] </ref>. Compared with the BAN logic, the GNY logic is easier and more natural to use, but is also more prone to writing infeasible specifications. Therefore, the GNY logic explicitly relied upon a mechanism external to the logic in dealing with them. <p> Usually, a message of the form P ! Q : X stating that P sends message X (possibly including message enten-sions in the GNY logic) to Q is automatically transformed into a logical statement Q &lt; X, representing that Q received X <ref> [Burrows 89, Gong 90b, Kailar 91] </ref>. This is the point where infeasible specifications may slip through. In the revised GNY logic, no such transformation is done. <p> When an expected message does not arrive, the recipient can block forever or timeout. The GNY logic, similar to other logics, can analyze the states of the principals in such a situation, but more attention should be paid to possessions than beliefs <ref> [Gong 90b] </ref>. This is because a principal may not have enough confidence in certain received formulas (such as a nonce or a piece of cipher-text) until a much later stage, for example, upon the completion of the protocol. Beliefs do not exhibit such problems.
Reference: [Halpern 84] <author> J.Y. Halpern and Y. Moses, </author> <title> "Knowledge and Common Knowledge in a Distributed Environment", </title> <booktitle> in Proceedings of the 3rd ACM Symposium on Principles of Distributed Computing, </booktitle> <address> Vancouver, British Columbia, </address> <month> August, </month> <year> 1984, </year> <month> pp.50-61. </month>
Reference-contexts: For example, process P may learn that its messages to process Q were received because it just received an acknowledgment message from Q. Such advances of states are often viewed and treated as evolution of belief and knowledge <ref> [Halpern 84] </ref>. Burrows, Abadi, and Needham took a similar point of view and devised a logic for authentication [Burrows 89].
Reference: [Kailar 91] <author> R. Kailar and V.D. Gligor, </author> <title> "On the Evolution of Beliefs in Authentication Protocols", </title> <booktitle> in Proceedings of the IEEE Computer Security Foundations Workshop IV, </booktitle> <address> Franconia, New Hampshire, </address> <month> June, </month> <year> 1991. </year>
Reference-contexts: Unfortunately, there have not been concrete guidelines for the idealization and the derivation procedures. Thus infeasible specifications may not be always detected. An infeasible specification can also lead to a subtle situation where causality of beliefs is not preserved. Non-causality is sometimes undesirable <ref> [Kailar 91] </ref>. This note first uses a few examples to point out the potential problems with infeasibility and non-causality. It then shows how a simple enhancement to a similar logic [Gong 90b] can handle these issues. <p> For ex ample, a chained belief may specify a trusted path. If there is no guarantee of causality, part of the path may be broken and the path may no longer be trusted (e.g. <ref> [Kailar 91] </ref>). The BAN logic is not concerned with dealing with infeasible protocol specifications. Thus its model simply requires that every principal believes what it says. <p> Usually, a message of the form P ! Q : X stating that P sends message X (possibly including message enten-sions in the GNY logic) to Q is automatically transformed into a logical statement Q &lt; X, representing that Q received X <ref> [Burrows 89, Gong 90b, Kailar 91] </ref>. This is the point where infeasible specifications may slip through. In the revised GNY logic, no such transformation is done. <p> Using the same paradigm, variations on the postulates can define different treatments once infeasible specifications are found. It is conceivable that similar measures can be taken in the BAN logic and others. For example, Kailar and Gligor used a kind of "eager belief" in their logic to preserve causality <ref> [Kailar 91] </ref>. However, they do not have the notion of possession and only handle infeasible or non-causal beliefs. Acknowledgments Virgil Gligor related to me a recent paper [Kailar 91], which inspired the writing of this note. Simon Foley and referees provided helpful comments. <p> For example, Kailar and Gligor used a kind of "eager belief" in their logic to preserve causality <ref> [Kailar 91] </ref>. However, they do not have the notion of possession and only handle infeasible or non-causal beliefs. Acknowledgments Virgil Gligor related to me a recent paper [Kailar 91], which inspired the writing of this note. Simon Foley and referees provided helpful comments.
References-found: 5

