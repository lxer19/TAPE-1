URL: ftp://ftp.cse.unsw.edu.au/pub/doc/papers/UNSW/9704.ps.Z
Refering-URL: http://www.cse.unsw.edu.au/school/research/tr.html
Root-URL: http://www.cse.unsw.edu.au
Email: E-mail: fgernot,kevine,jerry,smrg@cse.unsw.edu.au  E-mail: jochen@watson.ibm.com  
Title: Implementation and Performance of the Mungi Single-Address-Space Operating System  
Author: Gernot Heiser Kevin Elphinstone Jerry Vochteloo Stephen Russell Jochen Liedtke 
Date: June 1997  
Web: WWW: http://www.cse.unsw.edu.au/~disy  
Address: Sydney 2052, Australia  30 Saw Mill River Road, Hawthorne, NY 10532, USA  Sydney 2052, Australia  
Affiliation: Department of Computer Systems School of Computer Science and Engineering The University of New South Wales,  IBM T. J. Watson Research Center  School of Computer Science and Engineering The University of New South Wales  
Pubnum: UNSW-CSE-TR-9704  
Abstract-found: 0
Intro-found: 1
Reference: [AK85] <author> D. A. Abramson and J. L. Keedy. </author> <title> Implementing a large virtual memory in a distributed computing system. </title> <booktitle> In Proceedings of the 18th Hawaii International Conference on System Sciences, </booktitle> <volume> volume 2, </volume> <pages> pages 515-522, </pages> <year> 1985. </year>
Reference: [APW86] <author> M. Anderson, R. Pose, and C. S. Wallace. </author> <title> A password-capability system. </title> <journal> The Computer Journal, </journal> <volume> 29 </volume> <pages> 1-8, </pages> <year> 1986. </year>
Reference-contexts: Each valid capability grants the holder one or more of these rights to an object. 1 A capability granting RWXD rights is, by definition, an owner capability. Capabilities are user objects and can be stored and passed around freely. They are implemented as password capabilities <ref> [APW86] </ref>, protected from forgery by sparsity. Each capability consists essentially of two parts: the base (64-bit) address of the object the capability refers to (represented as the number of the object's first page), and a (64-bit) password. The password is chosen by the owner when the capability is registered.
Reference: [Ber80] <author> V. Berstis. </author> <title> Security and protection in the IBM System/38. </title> <booktitle> In Proceedings of the 7th Symposium on Computer Architecture, </booktitle> <pages> pages 245-250. </pages> <address> ACM/IEEE, </address> <month> May </month> <year> 1980. </year>
Reference-contexts: the owners' control over their objects, as access could not be reliably revoked. 8 2 OVERVIEW OF THE MUNGI SYSTEM Instead of encouraging the use of active objects and a client-server model, we are using a protected procedure call mechanism similar to the profile adoption mechanism of the IBM System/38 <ref> [Ber80] </ref>. Our mechanism, called protection domain extension (PDX), allows the caller of a PDX procedure to extend its protection domain, for the duration of the call, by the protection domain of the callee [VERH96]. Unlike System/38, our PDX mechanism does not require special hardware.
Reference: [CLFL94] <author> J. S. Chase, H. M. Levy, M. J. Feeley, and E. D. Lazowska. </author> <title> Sharing and protection in a single address space operating system. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 12 </volume> <pages> 271-307, </pages> <month> November </month> <year> 1994. </year> <note> REFERENCES 21 </note>
Reference-contexts: It has also been claimed [WM96] that the simplified model significantly reduces the complexity of the operating system, and leads to improved performance. A number of SASOS prototypes have been implemented to date, for example, Opal <ref> [CLFL94] </ref> and Angel [WM96]. These implementations were intended primarily as a proof-of-concept and have not been able to fully demonstrate the potential advantages of a SASOS. <p> Opal <ref> [CLFL94] </ref> is a recent SASOS targeted for 64-bit architectures. In Opal, memory segments, threads, protection domains, portals (protected procedure entry points) and resource groups (used for accounting) are all first-class objects, protected by capabilities. In contrast, Mungi only has capabilities for memory objects. <p> The cache-miss penalty is rather high on the Indy, 34 cycles (0.34 s) for the first item in a line. 16 5 PERFORMANCE Comparisons with SGI's operating systems used the identical platform running Irix 6.2. Comparisons with Opal are based on published data <ref> [CLFL94] </ref>. These timings had been obtained on a DEC 3000/400 AXP (133.3 MHz Alpha CPU). According to the SPEC ratings, this machine should be roughly as fast as our Indy (give or take 10-20 %). 5.1 Microbenchmarks Here we present timings obtained for basic Mungi system calls.
Reference: [CLLB92] <author> J. S. Chase, H. M. Levy, E. D. Lazowska, and M. Baker-Harvey. </author> <title> Lightweight shared objects in a 64-bit operating system. </title> <booktitle> In Conference on Object-Oriented Programming Systems, Languages, and Applications, </booktitle> <year> 1992. </year>
Reference-contexts: 1 Introduction Single-address-space operating systems (SASOS) have recently been proposed as an attractive model for making the best use of the wide address space provided by the latest generations of microprocessors <ref> [WSO + 92, CLLB92, RSE + 92] </ref>. The basic idea of these systems is that by removing address space boundaries, they encourage sharing of data between processes. In a SASOS, all processes share the same address space.
Reference: [CM88] <author> A. Chang and M. F. Mergen. </author> <title> 801 storage: Architecture and programming. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 6 </volume> <pages> 28-50, </pages> <year> 1988. </year>
Reference: [CMS90] <author> C. Chao, M. Mackey, and B. Sears. </author> <title> Mach on a virtually addressed cache architecture. </title> <booktitle> In USENIX Mach Workshop, </booktitle> <pages> pages 31-51, </pages> <year> 1990. </year>
Reference-contexts: Copy-on-write is supported by the default pager (and is really just a special case of a mapping operation). Further uses of these mapping operations are outlined in Sect. 2.5.2. 2.5.1 Implications of aliasing While copy-on-write introduces aliasing on read-only objects (and is thus harmless <ref> [CMS90] </ref>), mappings potentially introduce the same aliasing problems as in multi-address-space systems. This seems to defeat some of the advantages of a SASOS.
Reference: [CS92] <author> R. G. G. Cattell and J. Skeen. </author> <title> Object operations benchmark. </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 17 </volume> <pages> 1-31, </pages> <year> 1992. </year>
Reference-contexts: Mapping a further page of a previously validated object takes only 25 s. 5.2 OO1 As an approximation to a "real-life" application we implemented the object operations ("OO1") benchmark <ref> [CS92] </ref>. OO1 simulates typical operations in a simple object-oriented database system. Client code invokes a database system to perform lookup, traverse and insert operations on a database. <p> The project was supported by grant no ### under the Australian Research Council's Large Grants scheme. A OO1 Implementation Details For our benchmarks we used the "small" database (20,000 parts) defined in <ref> [CS92] </ref>. The lookup operation consists of searching 1000 random parts in the database; the database server is invoked once for each part. The insert operation creates 100 new parts in the database and connects each to 3 random parts. The total number of database server invocations is 400 in this case.
Reference: [DD68] <author> R. Daley and J. Dennis. </author> <title> Virtual memory, processes, and sharing in Multics. </title> <journal> Communications of the ACM, </journal> <volume> 11(5) </volume> <pages> 306-312, </pages> <month> May </month> <year> 1968. </year>
Reference-contexts: Alternatively, it would be possible to modify the L4 IPC code to directly enforce the restrictions required. 4 Related Work Systems using globally valid names for accessing objects have been, in one form or another, around for a relatively long time. The best known one is probably Multics <ref> [DD68] </ref>, which used a global name space of (segment-name,offset) pairs to identify data. However, individual processes executed in their own private address space. Segments were made accessible to processes by mapping them into the address space, where they could be accessed via a segment number.
Reference: [DVH66] <author> J. Dennis and E. Van Horn. </author> <title> Programming semantics for multiprogrammed computers. </title> <journal> Communications of the ACM, </journal> <volume> 9 </volume> <pages> 143-55, </pages> <year> 1966. </year>
Reference-contexts: In contrast, a SASOS guarantees that all processes can access a particular memory object via the same virtual address, and hence guarantees the validity of embedded pointers across processes. Capabilities, as introduced by Dennis and Van Horn <ref> [DVH66] </ref>, provide a true global naming space. Capabilities provide a segmented view of memory similar to that of Multics. Unlike Multics, pure capability systems use capabilities, together with segment offsets, as first class memory addresses.
Reference: [ERHL96] <author> K. Elphinstone, S. Russell, G. Heiser, and J. Liedtke. </author> <title> Supporting persistent object systems in a single address space. </title> <booktitle> In Proceedings of the 7th International Workshop on Persistent Object Systems, </booktitle> <pages> pages 111-119, </pages> <address> Cape May, NJ, USA, May 1996. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: As there is no I/O model in the system, a pager cannot use I/O operations to handle a residency fault. Instead, the pager uses another memory object as its backing store. To support forwarding of page faults, Mungi provides mapping operations between different regions of virtual memory <ref> [ERHL96] </ref>. Pages belonging to an object O 1 may be mapped to another object O 2 , which causes O 2 's pager to be invoked when necessary. Page faults may be forwarded several times until they reach the default pager. <p> The addition of virtual memory mapping operations has made it possible to incorporate into the single-address-space model user-level pagers and I/O, and leave, for example, the implementation of stability models to the user level <ref> [ERHL96] </ref>. This allowed us to build a "pure" SASOS, where virtual memory is the only communication medium between processes.
Reference: [GBY90] <author> G. Gonnet and R. Baeza-Yates. </author> <title> Handbook of Algorithms and Data Structures. </title> <publisher> Addison-Wesley, </publisher> <address> 2 nd edition, </address> <year> 1990. </year>
Reference-contexts: Objects Object creation (which, by itself, does not allocate any backing store) costs 60 s in Mungi. Less than one microsecond of that is for the OT update (on a 4-level B + -tree, which is sufficient to hold at least 32 million object descriptors <ref> [GBY90] </ref>). Segment creation in Opal using a recycled inode costs 315 s. Object deletion in Mungi takes 150 s, compared to 900 s in Opal. Neither operation can easily be compared to Irix, which does not seem to support a memory file system.
Reference: [HLM + 82] <author> P. M. Hansen, M. A. Linton, R. N. Mayo, M. Murphy, and D. A. Patterson. </author> <title> A performance evaluation of the Intel iAPX 432. </title> <journal> Computer Architecture News, </journal> <volume> 10(4) </volume> <pages> 17-26, </pages> <month> June </month> <year> 1982. </year>
Reference-contexts: Historically, there have been a significant number of systems following this approach: from the earliest commercial capability system, the Plessey 250 (see [Lev84]), via the Cambridge CAP computer [NW77], to the IBM System/38 [HSH81], the Intel iAXP 432 <ref> [HLM + 82] </ref> and the Monads system [RA85,AK85], the last probably being the first ever distributed shared memory system. System/38 and Monads in particular, share much of the philosophy of a SASOS, such as a single-level store, orthogonal persistence, object-based protection, and, in Monads' case, transparent distribution.
Reference: [HMRS96] <author> D. Hagimont, J. Mossiere, X. Rousset de Pina, and F. Saunier. </author> <title> Hidden software capabilities. </title> <booktitle> In Proceedings of the 16th International Conference on Distributed Computing Systems, </booktitle> <pages> pages 282-289, </pages> <address> Hong Kong, </address> <month> May </month> <year> 1996. </year> <note> IEEE. </note>
Reference-contexts: Objects in Nemesis export multiple interfaces, which are combined with closures to provide compile-time type checking. By contrast, object support in Mungi is seen to be largely a programming language issue, with PDX providing the basic support required. Hagimont et al. <ref> [HMRS96] </ref> argue that application code should not have to deal explicitly with capabilities. Their Arias SASOS, presently under development, hides capabilities from application code and describes all protection in an extended interface definition language.
Reference: [HSH81] <author> M. E. Houdek, F. G. Soltis, and R. L. Hoffman. </author> <title> IBM System/38 support for capability-based addressing. </title> <booktitle> In Proceedings of the 8th Symposium on Computer Architecture, </booktitle> <pages> pages 341-348. </pages> <address> ACM/IEEE, </address> <month> May </month> <year> 1981. </year>
Reference-contexts: Historically, there have been a significant number of systems following this approach: from the earliest commercial capability system, the Plessey 250 (see [Lev84]), via the Cambridge CAP computer [NW77], to the IBM System/38 <ref> [HSH81] </ref>, the Intel iAXP 432 [HLM + 82] and the Monads system [RA85,AK85], the last probably being the first ever distributed shared memory system.
Reference: [KC94] <author> D. Kotz and P. Crow. </author> <title> The expected lifetime of "single-address-space" operating systems. </title> <booktitle> In SIGMETRICS Conference on Measurement and Modeling of Computer Systems, </booktitle> <pages> pages 161-70, </pages> <address> Santa Clara, CA, USA, 1994. </address> <publisher> ACM. </publisher>
Reference-contexts: Hence dangling pointers and capabilities do not present a security problem. Address space reuse is important as otherwise even a 64-bit address space could conceivably be exhausted <ref> [KC94] </ref>.
Reference: [Lev84] <author> H. M. Levy. </author> <title> Capability-Based Computer Systems. </title> <publisher> Digital Press, </publisher> <year> 1984. </year>
Reference-contexts: Making capabilities (part of) the lowest level of addressing generally implies building special hardware to interpret the capabilities. Historically, there have been a significant number of systems following this approach: from the earliest commercial capability system, the Plessey 250 (see <ref> [Lev84] </ref>), via the Cambridge CAP computer [NW77], to the IBM System/38 [HSH81], the Intel iAXP 432 [HLM + 82] and the Monads system [RA85,AK85], the last probably being the first ever distributed shared memory system. <p> Hydra can be considered the first microkernel architecture, as it implemented at user level many services which were traditionally part of the kernel. Objects were the basic units of protection and encapsulation. However, the lack of an appropriate hardware base made objects and operations on them too expensive <ref> [Lev84] </ref>. The Xerox Cedar system [SZBH86] features a single address space to enhance sharing. Protection is not maintained by the operating system, but depends on the use of a type-safe programming language (also called Cedar).
Reference: [Lie92] <editor> J. Liedtke. Clans & chiefs. </editor> <booktitle> In 12. GI/ITG-Fachtagung Architektur von Rechensys-temen, </booktitle> <pages> pages 294-305, </pages> <address> Kiel, 1992. </address> <publisher> Springer Verlag. </publisher>
Reference-contexts: The only problem this is likely to cause is that it prevents confinement, as we cannot control IPC between user tasks. Ideally, all IPC should go through the Mungi server. L4 actually provides appropriate mechanisms to control IPC <ref> [Lie92] </ref>, but at the cost of doubling the number of IPCs required to implement Mungi system calls.
Reference: [Lie93] <author> J. Liedtke. </author> <title> A basis for huge fine-grained address spaces and user level mapping. </title> <booktitle> In Proceedings of the 7th European Conference on Object Oriented Programming (ECOOP) Workshop on Granularity of Objects in Distributed Systems (GODS'93), </booktitle> <address> Kaiserslautern, Germany, </address> <month> July </month> <year> 1993. </year> <note> 22 REFERENCES </note>
Reference-contexts: The TLB contains 48 entries, each mapping two neighboring 4kb virtual pages. We maintain a two-way associative TLB cache for fast TLB miss handling. On a cache miss, the mapping is obtained from a guarded page table (GPT) <ref> [Lie93, Lie96b] </ref>. The GPT is an efficient data structure well suited for large, sparse address spaces. The main advantage GPTs have over alternative data structures, such as inverted page tables (IPTs) [CM88,RA85], is that they efficiently support sharing of large areas of the address space.
Reference: [Lie95] <editor> J. Liedtke. </editor> <booktitle> On -kernel construction. In Proceedings of the 15th ACM Symposium on OS Principles, </booktitle> <pages> pages 237-250, </pages> <address> Copper Mountain, CO, USA, </address> <month> December </month> <year> 1995. </year>
Reference-contexts: The details of the implementation are given below, while performance figures are presented in Section 5. We decided to build Mungi on top of the L4 microkernel <ref> [Lie95] </ref>. The main reason for this approach was that it would make the Mungi system easier to port between different hardware architectures. <p> It is mostly written in assembler, and inherently unportable <ref> [Lie95] </ref>. Furthermore, there were no 64-bit implementations of L4 available at all. This meant that we had to implement L4 from scratch.
Reference: [Lie96a] <author> J. Liedtke. </author> <title> L4 Reference Manual. </title> <address> GMD/IBM, </address> <month> September </month> <year> 1996. </year> <note> Available from URL http://www.inf.tu-dresden.de/ mh1/l3/. </note>
Reference-contexts: For this model to be accepted as effective, it is also necessary to demonstrate that these abstractions can be implemented efficiently. Section 3 describes how we have built the Mungi model on top of our implementation of the L4 microkernel <ref> [Lie96a] </ref> for the MIPS R4600 processor. In Section 4 we review related work on capability systems and other global address space approaches, as well as recent implementations of SASOS.
Reference: [Lie96b] <author> J. Liedtke. </author> <title> On the Realization Of Huge Sparsely-Occupied and Fine-Grained Address Spaces. </title> <publisher> Oldenbourg, </publisher> <address> Munich, Germany, </address> <year> 1996. </year>
Reference-contexts: The TLB contains 48 entries, each mapping two neighboring 4kb virtual pages. We maintain a two-way associative TLB cache for fast TLB miss handling. On a cache miss, the mapping is obtained from a guarded page table (GPT) <ref> [Lie93, Lie96b] </ref>. The GPT is an efficient data structure well suited for large, sparse address spaces. The main advantage GPTs have over alternative data structures, such as inverted page tables (IPTs) [CM88,RA85], is that they efficiently support sharing of large areas of the address space.
Reference: [LRD95] <author> A. Lindstrom, J. Rosenberg, and A. Dearle. </author> <title> The grand unified theory of address spaces. </title> <booktitle> In Proceedings of the 5th Workshop on Hot Topics in Operating Systems (HotOS), </booktitle> <pages> pages 66-71, </pages> <address> Orcas Island, WA, USA, </address> <month> May </month> <year> 1995. </year> <note> IEEE. </note>
Reference-contexts: Its basic storage abstraction is called a container, which essentially constitutes an address space. Containers, or parts thereof, can be mapped into other containers. Grasshopper presents a generalized model of address spaces, which can emulate a traditional model, such as UNIX, as well as the SASOS model <ref> [LRD95] </ref>.
Reference: [MT86] <author> S. J. Mullender and A. S. Tanenbaum. </author> <title> The design of a capability-based distributed operating system. </title> <journal> The Computer Journal, </journal> <volume> 29 </volume> <pages> 289-99, </pages> <year> 1986. </year>
Reference-contexts: Such an approach is obviously unable to support legacy software, and seems to be too restrictive, as it will not work with many of the most popular programming languages. Amoeba <ref> [MT86] </ref> is a distributed system using sparse capabilities for naming and protecting objects. Capabilities are authenticated by an object's server, which therefore needs to be invoked for every operation on the object. Grasshopper [RDH + 96] is a system specifically designed to support persistence.
Reference: [NW77] <author> R. Needham and R. Walker. </author> <title> The Cambridge CAP computer and its protection system. </title> <booktitle> In Proceedings of the 6th ACM Symposium on OS Principles, </booktitle> <pages> pages 1-10. </pages> <publisher> ACM, </publisher> <month> November </month> <year> 1977. </year>
Reference-contexts: Making capabilities (part of) the lowest level of addressing generally implies building special hardware to interpret the capabilities. Historically, there have been a significant number of systems following this approach: from the earliest commercial capability system, the Plessey 250 (see [Lev84]), via the Cambridge CAP computer <ref> [NW77] </ref>, to the IBM System/38 [HSH81], the Intel iAXP 432 [HLM + 82] and the Monads system [RA85,AK85], the last probably being the first ever distributed shared memory system.
Reference: [RA85] <author> J. Rosenberg and D. Abramson. </author> <title> MONADS-PC|a capability-based workstation to support software engineering. </title> <booktitle> In Proceedings of the 18th Hawaii International Conference on System Sciences, </booktitle> <volume> volume 1, </volume> <pages> pages 222-31. </pages> <publisher> IEEE, </publisher> <year> 1985. </year>
Reference: [RDH + 96] <author> J. Rosenberg, A. Dearle, D. Hulse, A. Lindstrom, and S. Norris. </author> <title> Operating system support for persistent and recoverable computations. </title> <journal> Communications of the ACM, </journal> <volume> 39(9) </volume> <pages> 62-69, </pages> <month> September </month> <year> 1996. </year>
Reference-contexts: Amoeba [MT86] is a distributed system using sparse capabilities for naming and protecting objects. Capabilities are authenticated by an object's server, which therefore needs to be invoked for every operation on the object. Grasshopper <ref> [RDH + 96] </ref> is a system specifically designed to support persistence. Its basic storage abstraction is called a container, which essentially constitutes an address space. Containers, or parts thereof, can be mapped into other containers.
Reference: [Ros94] <author> T. Roscoe. </author> <title> Linkage in the Nemesis single address space operating system. </title> <journal> Operating Systems Review, </journal> <volume> 28(4) </volume> <pages> 48-55, </pages> <year> 1994. </year>
Reference-contexts: The Angel prototype is distributed, using distributed shared memory technology. The designers of Angel have studied fault tolerance issues [Wil93] and have demonstrated that full POSIX support, including the difficult fork operation, is possible in a SASOS [WMSS93]. Angel outperforms FreeBSD in some microbenchmarks. Nemesis <ref> [Ros94] </ref> is another recent SASOS. It differs from Opal and Angel in that the address space is not distributed, and persistence is handled at the user level. Objects in Nemesis export multiple interfaces, which are combined with closures to provide compile-time type checking.
Reference: [RSE + 92] <author> S. Russell, A. Skea, K. Elphinstone, G. Heiser, K. Burston, I. Gorton, and G. Hellestrand. </author> <title> Distribution + persistence = global virtual memory. </title> <booktitle> In Proceedings of the 2nd International Workshop on Object Orientation in Operating Systems, </booktitle> <pages> pages 96-99, </pages> <address> Dourdan, France, </address> <month> September </month> <year> 1992. </year> <note> IEEE. </note>
Reference-contexts: 1 Introduction Single-address-space operating systems (SASOS) have recently been proposed as an attractive model for making the best use of the wide address space provided by the latest generations of microprocessors <ref> [WSO + 92, CLLB92, RSE + 92] </ref>. The basic idea of these systems is that by removing address space boundaries, they encourage sharing of data between processes. In a SASOS, all processes share the same address space.
Reference: [SZBH86] <author> D. C. Swinehart, P. T. Zellweger, R. J. Beach, and R. B. Hagmann. </author> <title> A structural view of the Cedar programming environment. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 8 </volume> <pages> 419-490, </pages> <year> 1986. </year>
Reference-contexts: Objects were the basic units of protection and encapsulation. However, the lack of an appropriate hardware base made objects and operations on them too expensive [Lev84]. The Xerox Cedar system <ref> [SZBH86] </ref> features a single address space to enhance sharing. Protection is not maintained by the operating system, but depends on the use of a type-safe programming language (also called Cedar).
Reference: [THK95] <author> M. Talluri, M. D. Hill, and Y. A. Khalid. </author> <title> A new page table for 64-bit address spaces. </title> <booktitle> In Proceedings of the 15th ACM Symposium on OS Principles, </booktitle> <pages> pages 184-200, </pages> <address> Copper Mountain Resort, Co, USA, </address> <month> December </month> <year> 1995. </year> <note> ACM. </note>
Reference-contexts: In our implementation we use this for quickly mapping kernel data structures (e.g. a virtual array of thread control blocks) into the client's view of the address space for the duration of a system call. Using clustered page tables <ref> [THK95] </ref> would have been a possibility. However, we are doubtful as to whether clustered page tables can handle very sparse address spaces, with many single-page objects, as efficiently as GPTs.
Reference: [VERH96] <author> J. Vochteloo, K. Elphinstone, S. Russell, and G. Heiser. </author> <title> Protection domain extensions in Mungi. </title> <booktitle> In Proceedings of the 5th International Workshop on Object Orientation in Operating Systems, </booktitle> <pages> pages 161-165, </pages> <address> Seattle, WA, USA, </address> <month> October </month> <year> 1996. </year> <note> IEEE. </note>
Reference-contexts: Our mechanism, called protection domain extension (PDX), allows the caller of a PDX procedure to extend its protection domain, for the duration of the call, by the protection domain of the callee <ref> [VERH96] </ref>. Unlike System/38, our PDX mechanism does not require special hardware. More specifically, a PDX object's descriptor in the OT contains, for each PDX capability, a list of entry points, and a Clist capability.
Reference: [Wal90] <author> C. S. Wallace. </author> <title> Physically random generator. </title> <journal> Computer Systems Science & Engineering, </journal> <volume> 5 </volume> <pages> 82-88, </pages> <year> 1990. </year> <note> REFERENCES 23 </note>
Reference-contexts: The password is chosen by the owner when the capability is registered. It is normally obtained from a library routine. Presently, we use a DES-based encryption scheme for creating "random" passwords. However, in the future we plan to use a hardware device producing truly random bitstrings <ref> [Wal90] </ref>. The list of valid capabilities for each object is maintained by the system in a distributed system-wide directory, the object table (OT). As capabilities are user objects, it is not possible to determine the tasks and users who have access to a particular object.
Reference: [WCC + 74] <author> W. Wulf, E. Cohen, W. Corwin, A. Jones, R. Levin, C. Pierson, and F. Pollack. HYDRA: </author> <title> The kernel of a multiprocessor operating system. </title> <journal> Communications of the ACM, </journal> <volume> 17 </volume> <pages> 337-345, </pages> <year> 1974. </year>
Reference-contexts: At the very least, it requires a tagged memory. It is unclear whether such a system would be viable without the backing of IBM's market share in the traditional commercial computing sector. Furthermore, the AS/400 design does not seem to lend itself very well to distribution. Hydra <ref> [WCC + 74] </ref> was a software-based capability system supporting a large, flat name space for persistent objects. Hydra can be considered the first microkernel architecture, as it implemented at user level many services which were traditionally part of the kernel. Objects were the basic units of protection and encapsulation.
Reference: [Wil93] <author> T. Wilkinson. </author> <title> Implementing Fault Tolerance in a 64-Bit Distributed Operating System. </title> <type> PhD thesis, </type> <institution> Systems Architecture Research Centre, City University, </institution> <address> London, UK, </address> <month> July </month> <year> 1993. </year>
Reference-contexts: It therefore is not faced, and does not address, issues resulting from a huge, sparsely used address space. The Angel prototype is distributed, using distributed shared memory technology. The designers of Angel have studied fault tolerance issues <ref> [Wil93] </ref> and have demonstrated that full POSIX support, including the difficult fork operation, is possible in a SASOS [WMSS93]. Angel outperforms FreeBSD in some microbenchmarks. Nemesis [Ros94] is another recent SASOS.
Reference: [WM96] <author> T. Wilkinson and K. Murray. </author> <title> Evaluation of a distributed single address space operating system. </title> <booktitle> In Proceedings of the 16th International Conference on Distributed Computing Systems, </booktitle> <pages> pages 494-501, </pages> <address> Hong Kong, </address> <month> May </month> <year> 1996. </year> <note> IEEE. </note>
Reference-contexts: A SASOS avoids problems with virtual caches created by address aliasing in multi-address-space systems: as every datum is always accessed through the same address, different cache lines are guaranteed to refer to different data. It has also been claimed <ref> [WM96] </ref> that the simplified model significantly reduces the complexity of the operating system, and leads to improved performance. A number of SASOS prototypes have been implemented to date, for example, Opal [CLFL94] and Angel [WM96]. <p> It has also been claimed <ref> [WM96] </ref> that the simplified model significantly reduces the complexity of the operating system, and leads to improved performance. A number of SASOS prototypes have been implemented to date, for example, Opal [CLFL94] and Angel [WM96]. These implementations were intended primarily as a proof-of-concept and have not been able to fully demonstrate the potential advantages of a SASOS. <p> The prototype implementation emulates Opal on top of Mach's UNIX server. This approach naturally has a drastic impact on performance, as discussed in Sect. 5. For this reason, the emulated Opal prototype cannot demonstrate the inherent performance advantages of a SASOS. Angel <ref> [WM96] </ref> has very similar goals to Opal and Mungi. Contrary to most SASOS approaches, Angel does not use capability-based protection, nor does it have any explicit protection system built in.
Reference: [WMSS93] <author> T. Wilkinson, K. Murray, A. Saulsbury, and T. Stiemerling. </author> <title> Compiling for a 64-bit single address space architecture. </title> <type> Technical report TCU/SARC/1993/1, </type> <institution> Systems Architecture Research Centre, City University, </institution> <address> London, UK, </address> <month> March </month> <year> 1993. </year>
Reference-contexts: The Angel prototype is distributed, using distributed shared memory technology. The designers of Angel have studied fault tolerance issues [Wil93] and have demonstrated that full POSIX support, including the difficult fork operation, is possible in a SASOS <ref> [WMSS93] </ref>. Angel outperforms FreeBSD in some microbenchmarks. Nemesis [Ros94] is another recent SASOS. It differs from Opal and Angel in that the address space is not distributed, and persistence is handled at the user level.
Reference: [WSO + 92] <author> T. Wilkinson, T. Stiemerling, P. E. Osmon, A. Saulsbury, and P. Kelly. Angel: </author> <title> A proposed multiprocessor operating system kernel. </title> <booktitle> In European Workshop on Parallel Computing, </booktitle> <pages> pages 316-319, </pages> <address> Barcelona, Spain, </address> <year> 1992. </year>
Reference-contexts: 1 Introduction Single-address-space operating systems (SASOS) have recently been proposed as an attractive model for making the best use of the wide address space provided by the latest generations of microprocessors <ref> [WSO + 92, CLLB92, RSE + 92] </ref>. The basic idea of these systems is that by removing address space boundaries, they encourage sharing of data between processes. In a SASOS, all processes share the same address space.
References-found: 38

