URL: http://www.umiacs.umd.edu/users/yaser/iccv98-appearance.ps.Z
Refering-URL: http://www.umiacs.umd.edu/users/yaser/publications.html
Root-URL: 
Email: black@parc.xerox.com fleet@qucis.queensu.ca yaser@cs.umd.edu  
Title: A Framework for Modeling Appearance Change in Image Sequences  
Author: Michael J. Black David J. Fleet Yaser Yacoob 
Address: 3333 Coyote Hill Road, Palo Alto, CA 94304  College Park, MD 20742  
Affiliation: Xerox Palo Alto Research Center,  Dept. of Computing Information Science, Queen's University, Kingston, Ont.  Computer Vision Laboratory, University of Maryland,  
Pubnum: K7L 3N6  
Abstract: Image appearance may change over time due to a variety of causes such as 1) object or camera motion; 2) generic photometric events including variations in illumination (e.g. shadows) and specular reflections; and 3) iconic changes which are specific to the objects being viewed and include complex occlusion events and changes in the material properties of the objects. We propose a general framework for representing and recovering these appearance changes in an image sequence as a mixture of different causes. The approach generalizes previous work on optical flow to provide a richer description of image events and more reliable estimates of image motion. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. Ayer and H. Sawhney. </author> <title> Layered representation of motion video using robust maximum-likelihood estimation of mixture models and MDL encoding. </title> <booktitle> ICCV, </booktitle> <pages> pp. 777-784, </pages> <year> 1995. </year>
Reference-contexts: Unlike the approaches above, however, the mixture model framework factors appearance change into multiple causes and performs a soft assignment of pixels to the different models 3 Mixture Model of Appearance Change Mixture models [14] have been used previously in motion analysis for recovering multiple motions within an image region <ref> [1, 13, 19] </ref>. The basic goals are to estimate the parameters of a set of models given data generated by multiple causes and to assign data to the estimated models. Here we use this idea to account for co-occurring types of appearance change. <p> In this case we will need to estimate the number of instances of each appearance model that are required. There has been recent work on this topic in the area of multiple motion estimation <ref> [1, 20] </ref>. A related issue is the use of spatial smoothness in the modeling of appearance change. In place of the parameterized models we might substitute regularized models of appearance change with priors on their spatial smoothness.
Reference: [2] <author> D. Beymer and T. Poggio. </author> <title> Image representations for visual learning. </title> <journal> Science, </journal> <volume> Vol. 272, </volume> <pages> pp. 1905-1909, </pages> <month> June </month> <year> 1996. </year>
Reference-contexts: This allows for a general class of smooth deformations between frames, including both multiplicative and additive changes to intensity, as does the general constraint in (2). A number of authors have proposed more general linear models of image brightness <ref> [2, 10, 11, 18] </ref>. For example, Hager and Belhumeur [10] use principal component analysis (PCA) to find a set of orthogonal basis images, fB j (~x)g, that spans the ensemble of images of an object under a wide variety of illuminant directions.
Reference: [3] <author> M. J. Black and P. Anandan. </author> <title> The robust estimation of multiple motions: Parametric and piecewise-smooth flow fields. </title> <journal> CVIU, </journal> <volume> 63(1) </volume> <pages> 75-104, </pages> <month> Jan. </month> <year> 1996. </year>
Reference-contexts: One focus of recent work in motion estimation is to make it robust in the presence of these un-modeled changes in appearance (ie. violations of the brightness constancy assumption) <ref> [3] </ref>. The approach here is quite different in that we explicitly model many of these events and hence extend the notion of constancy to more complex types of appearance change. One motivation for this is our interest in recognizing complex non-rigid and articulated motions, such as human facial expressions. <p> We first compute image motion for each training sequence using the brightness constancy assumption and a robust optical flow algorithm <ref> [3] </ref>. The training set consists of a set of p optical flow fields. For images with s = nfim pixels, each flow field contains 2s quantities (i.e., the horizontal and vertical flow components at each pixel).
Reference: [4] <author> M. J. Black and A. D. Jepson. Eigentracking: </author> <title> Robust matching and tracking of articulated objects using a view-based representation. </title> <booktitle> ECCV, </booktitle> <pages> pp. 329-342, </pages> <year> 1996. </year>
Reference-contexts: Hal-linan [11] proposed a model that included both a model of illumination variation and a learned deformation model (EigenWarps). These approaches are also related to the eigentracking work of Black and Jepson <ref> [4] </ref> in which sub--space constraints are used to help account for iconic changes in appearance while an object is being tracked.
Reference: [5] <author> M. J. Black and Y. Yacoob. </author> <title> Tracking and recognizing rigid and non-rigid facial motions using local parametric models of image motions. </title> <booktitle> ICCV, </booktitle> <pages> pp. 374-381, </pages> <year> 1995. </year>
Reference-contexts: One motivation for this is our interest in recognizing complex non-rigid and articulated motions, such as human facial expressions. Previous work in this area has focused on image motion of face regions such as the mouth <ref> [5] </ref>. But image motion alone does not capture appearance changes such as the systematic appearance/disappearance of the teeth and tongue during speech and facial expressions. For machine recognition we would like to be able to model these intensity variations. <p> The training set included image sequences of a variety of different subjects performing the facial expressions joy, anger, and sadness. The faces of each subject were stabilized with respect to the first frame in the sequence using a planar motion model <ref> [5] </ref>. The mouth regions were extracted from the stabilized sequences and PCA was performed.
Reference: [6] <author> M. J. Black, Y. Yacoob, and D. J. </author> <title> Fleet. Modelling appearance change in image sequences. </title> <booktitle> 3rd Int. Workshop on Visual Form, </booktitle> <address> Capri, Italy, </address> <month> May </month> <year> 1997. </year>
Reference-contexts: By comparison, specular reflections (Figure 1, lower right) are typically local and can be modeled, in the simplest case, as a near saturation of image intensity. The fourth class of events considered in this paper is iconic change <ref> [6] </ref>. We use the word iconic to indicate changes that are pictorial. These are systematic changes in image appearance that are not readily explained by physical models of motion, illumination, or specularity. A simple example is the blinking of the eye in Figure 1 (lower left). <p> These approaches are also related to the eigentracking work of Black and Jepson [4] in which sub--space constraints are used to help account for iconic changes in appearance while an object is being tracked. In <ref> [6] </ref> we extended these general linear brightness models by allowing spatially varying explanations for pixels I (~x; t) = w 0 (~x)I Motion (~x) + w 1 (~x)I Iconic (~x): The terms w i (~x) are spatially varying weights between zero and one that indicate the extent to which a pixel
Reference: [7] <author> M. J. Black, Y. Yacoob, A. D. Jepson, and D. J. </author> <title> Fleet. Learning parameterized models of image motion. </title> <booktitle> CVPR, </booktitle> <pages> pp. 561-567, </pages> <year> 1997. </year>
Reference-contexts: shown in Figure 9. 1 2 3 4 A 8 (~x), for the facial expression experiment. 1 2 3 4 for the facial expression mouth motion. 6.2 Learned Deformations We learn a domain-specific model for the deformation component of the appearance change in much the same way using PCA (see <ref> [7] </ref>). We first compute image motion for each training sequence using the brightness constancy assumption and a robust optical flow algorithm [3]. The training set consists of a set of p optical flow fields. <p> Another outstanding research issue concerns the learning and use of domain-specific models when more than one domain of interest exists. When one has several domain-specific models the problems of estimation, indexing, and recognition become much more interesting (cf. <ref> [7] </ref>). 8 Conclusions Appearance changes in image sequences result from a complex combination of events and processes, including motion, illumination variations, specularities, changes in material properties, occlusions, and disocclusions. In this paper we propose a framework that models these variations as a mixture of causes.
Reference: [8] <author> T. Ezzat and T. Poggio. </author> <title> Facial analysis and synthesis using image-based models. </title> <booktitle> Int. Conf. on Auto. Face and Gesture Recog., </booktitle> <pages> pp. 116-121, </pages> <year> 1996. </year>
Reference: [9] <author> J. J. Gibson. </author> <title> The Ecological Approach to Visual Perception. </title> <publisher> Houghton Mifflin, </publisher> <address> Boston, MA, </address> <year> 1979. </year>
Reference-contexts: One could ask: Why model image deformation? While all image changes might be modeled by iconic change this does not reflect the natural properties of objects (their structural texture <ref> [9] </ref>) and how they change. Motion is a natural category of appearance change that is important to model and recover.
Reference: [10] <author> G. D. Hager and P. N. Belhumeur. </author> <title> Real-time tracking of image regions with changes in geometry and illumination. </title> <booktitle> CVPR, </booktitle> <pages> pp. 403-410, </pages> <year> 1996. </year>
Reference-contexts: This allows for a general class of smooth deformations between frames, including both multiplicative and additive changes to intensity, as does the general constraint in (2). A number of authors have proposed more general linear models of image brightness <ref> [2, 10, 11, 18] </ref>. For example, Hager and Belhumeur [10] use principal component analysis (PCA) to find a set of orthogonal basis images, fB j (~x)g, that spans the ensemble of images of an object under a wide variety of illuminant directions. <p> This allows for a general class of smooth deformations between frames, including both multiplicative and additive changes to intensity, as does the general constraint in (2). A number of authors have proposed more general linear models of image brightness [2, 10, 11, 18]. For example, Hager and Belhumeur <ref> [10] </ref> use principal component analysis (PCA) to find a set of orthogonal basis images, fB j (~x)g, that spans the ensemble of images of an object under a wide variety of illuminant directions.
Reference: [11] <author> P. Hallinan. </author> <title> A deformable model for the recognition of human faces under arbitrary illumination. </title> <type> PhD thesis, </type> <institution> Harvard Univ., </institution> <month> Aug. </month> <year> 1995. </year>
Reference-contexts: This allows for a general class of smooth deformations between frames, including both multiplicative and additive changes to intensity, as does the general constraint in (2). A number of authors have proposed more general linear models of image brightness <ref> [2, 10, 11, 18] </ref>. For example, Hager and Belhumeur [10] use principal component analysis (PCA) to find a set of orthogonal basis images, fB j (~x)g, that spans the ensemble of images of an object under a wide variety of illuminant directions. <p> The authors estimate the motion parameters ~m = [m 1 ; : : : ; m k ] and the subspace parameters b 1 :::b n . Hal-linan <ref> [11] </ref> proposed a model that included both a model of illumination variation and a learned deformation model (EigenWarps).
Reference: [12] <author> F. R. Hampel, E. M. Ronchetti, P. J. Rousseeuw, and W. A. Stahel. </author> <title> Robust Statistics: The Approach Based on Influence Functions. </title> <publisher> John Wiley and Sons, </publisher> <address> New York, NY, </address> <year> 1986. </year>
Reference-contexts: This reflects our expectation that the residuals I (~x; t) I C i (~x; t; ~ff i ) contain outliers <ref> [12] </ref>. Below we define the individual sources of appearance change. <p> i (~x; i ) @~ff i where @ log p i (I (~x; t)j~ff i ; i )=@~ff i = (I (~x; t) I C i (~x; t; ~ff i ); i ) @~ff i and where (r; ) = 2 + r 2 (10) is a robust influence function <ref> [12] </ref> (Figure 5) that reduces the effect of outliers on the maximum likelihood estimate. In the case of mixtures of Gaussian densities, the parameters can be computed in closed form. In the case of the robust likelihood function we incrementally compute the ~ff i satisfying (8).
Reference: [13] <author> A. Jepson and M. J. Black. </author> <title> Mixture models for optical flow computation. </title> <booktitle> CVPR, </booktitle> <pages> pp. 760-761, </pages> <year> 1993. </year>
Reference-contexts: Unlike the approaches above, however, the mixture model framework factors appearance change into multiple causes and performs a soft assignment of pixels to the different models 3 Mixture Model of Appearance Change Mixture models [14] have been used previously in motion analysis for recovering multiple motions within an image region <ref> [1, 13, 19] </ref>. The basic goals are to estimate the parameters of a set of models given data generated by multiple causes and to assign data to the estimated models. Here we use this idea to account for co-occurring types of appearance change. <p> These same values of were used for all the models. The algorithm is embedded within a coarse-to-fine process that first estimates parameters at a coarse spatial resolution and then updates them at successively finer resolutions. As in <ref> [13] </ref> we can add an explicit outlier layer with a fixed likelihood p 0 = ( 2 + (2:5) 2 ) 2 : a: I (t) b: I (t + 1) c: flow d: stable e: w 1 f: w 2 This term is used only in the normalization in Equation
Reference: [14] <author> G.J. McLachlan and K.E. Basford. </author> <title> Mixture Models: Inference and Applications to Clustering. </title> <publisher> Marcel Dekker Inc., </publisher> <address> N.Y., </address> <year> 1988. </year>
Reference-contexts: These different types of appearance change commonly occur together with natural objects; for example, with articulated human motion or the textural motion of plants, flags, water, etc. We employ a probabilistic mixture model formulation <ref> [14] </ref> to recover the various types of appearance change and to perform a soft assignment, or classification, of pixels to causes. This is illustrated in Figure 2. <p> While changes around the mouth can be modeled by a smooth deformation (image t+1 warped to approximate image t) the large disocclusions are best modeled as an iconic change (taken here to be a linear combination of learned basis images). We use the EM-algorithm <ref> [14] </ref> to iteratively compute maximum likelihood estimates for the deformation and iconic model parameters as well as the posterior probabilities that pixels at time t are explained by each of the causes. These probabilities are the weights in Figure 2 and they provide a soft assignment of pixels to causes. <p> Unlike the approaches above, however, the mixture model framework factors appearance change into multiple causes and performs a soft assignment of pixels to the different models 3 Mixture Model of Appearance Change Mixture models <ref> [14] </ref> have been used previously in motion analysis for recovering multiple motions within an image region [1, 13, 19]. The basic goals are to estimate the parameters of a set of models given data generated by multiple causes and to assign data to the estimated models. <p> Given these causes, the probability of observing the image I (~x; t) is then p (I (~x; t)j~ff 1 ; : : : ; ~ff n ; 1 ; : : : ; n ) = i=1 where the i are mixture proportions <ref> [14] </ref> which we take to be 1=n for each i indicating that each cause is equally likely. The ~ff i are parameters of model I C i for which we seek a maximum likelihood estimate and the i are scale parameters. <p> If the parameters of the models are known, then we can compute the posterior probability, w i (~x; i ), that pixel ~x belongs to cause i. This is given by <ref> [14] </ref> w i (~x; i ) = P n : (7) These ownership weights force every pixel to be explained by some combination of the different causes. <p> As the go to zero, the likelihood function approaches a delta function hence, for small values of , the weights will tend towards zero or one. The maximum likelihood estimate <ref> [14] </ref> of the parameters is defined in terms of these ownership weights and can be shown to satisfy X n X w i (~x; i ) @~ff i where @ log p i (I (~x; t)j~ff i ; i )=@~ff i = (I (~x; t) I C i (~x; t; ~ff
Reference: [15] <author> N. Mukawa. </author> <title> Estimation of shape, reflection coefficients and illuminant direction from image sequences. </title> <booktitle> ICCV, </booktitle> <pages> pp. 507-512, </pages> <year> 1990. </year>
Reference-contexts: For machine recognition we would like to be able to model these intensity variations. Our framework extends several previous approaches that generalize the brightness constancy assumption. Mukawa <ref> [15] </ref> extended the brightness constancy assumption to allow illumination changes that are a smoothly varying function of the image brightness.
Reference: [16] <author> C. Nastar, B. Moghaddam, and A. Pentland. </author> <title> Generalized image matching: </title> <journal> Statistical learning of physically-based deformations. </journal> <volume> ECCV, </volume> <pages> pp. 589-598, </pages> <year> 1996. </year>
Reference-contexts: Another generalization of brightness constancy was proposed by Nastar et al. <ref> [16] </ref>. Treating the image as a surface in 3D XYI-space, they proposed a physically-based approach for finding the deformation from an XYI surface at time t to the XYI surface at t + 1.
Reference: [17] <author> S. Negahdaripour and C. Yu. </author> <title> A generalized brightness change model for computing optical flow. </title> <booktitle> ICCV, </booktitle> <pages> pp. 2-11, </pages> <year> 1993. </year>
Reference-contexts: Our framework extends several previous approaches that generalize the brightness constancy assumption. Mukawa [15] extended the brightness constancy assumption to allow illumination changes that are a smoothly varying function of the image brightness. In a related paper, Negahdaripour and Yu <ref> [17] </ref> proposed a general linear brightness constraint I (~x; t) = m (~x; t) I (~x ~u (~x); t + 1) + c (~x; t) (2) where m (~x; t) and c (~x; t) are used to account for multiplicative and additive deviations from brightness constancy and are assumed to be
Reference: [18] <author> T. Vetter, M. J. Jones, and T. Poggio. </author> <title> A bootstrapping algorithm for learning linear models of object classes. </title> <booktitle> CVPR, </booktitle> <pages> pp. 40-47, </pages> <year> 1997. </year>
Reference-contexts: This allows for a general class of smooth deformations between frames, including both multiplicative and additive changes to intensity, as does the general constraint in (2). A number of authors have proposed more general linear models of image brightness <ref> [2, 10, 11, 18] </ref>. For example, Hager and Belhumeur [10] use principal component analysis (PCA) to find a set of orthogonal basis images, fB j (~x)g, that spans the ensemble of images of an object under a wide variety of illuminant directions.
Reference: [19] <author> Y. Weiss. </author> <title> Smoothness in layers: Motion segmentation using nonparametric mixture estimation. </title> <booktitle> CVPR, </booktitle> <pages> pp. 520-526, </pages> <year> 1997. </year>
Reference-contexts: Unlike the approaches above, however, the mixture model framework factors appearance change into multiple causes and performs a soft assignment of pixels to the different models 3 Mixture Model of Appearance Change Mixture models [14] have been used previously in motion analysis for recovering multiple motions within an image region <ref> [1, 13, 19] </ref>. The basic goals are to estimate the parameters of a set of models given data generated by multiple causes and to assign data to the estimated models. Here we use this idea to account for co-occurring types of appearance change. <p> The illumination model only accounts for a globally linear illumination change while the actual shadow fades smoothly at the edges of the hand. To account for local variations in illumination one could replace the linear model L with a regularized model of the illumination variation (see <ref> [19] </ref> for regularization in a mixture-model framework). 5.2 Specularities Consider the example in Figure 7 in which a stapler with a prominent specularity on the metal plate is moved. We model this situation using a mixture of motion (I C 1 ) and specularity (I C 3 ) models. <p> A related issue is the use of spatial smoothness in the modeling of appearance change. In place of the parameterized models we might substitute regularized models of appearance change with priors on their spatial smoothness. In a mixture model framework for motion estimation, Weiss <ref> [19, 20] </ref> has shown how to incorporate regularized models and smoothness priors on the ownership weights. Another outstanding research issue concerns the learning and use of domain-specific models when more than one domain of interest exists.
Reference: [20] <author> Y. Weiss and E. H. Adelson. </author> <title> A unified mixture framework for motion segmentation: Incorporating spatial coherence and estimating the number of models. </title> <booktitle> CVPR, </booktitle> <pages> pp. 321-326, </pages> <year> 1996. </year>
Reference-contexts: In this case we will need to estimate the number of instances of each appearance model that are required. There has been recent work on this topic in the area of multiple motion estimation <ref> [1, 20] </ref>. A related issue is the use of spatial smoothness in the modeling of appearance change. In place of the parameterized models we might substitute regularized models of appearance change with priors on their spatial smoothness. <p> A related issue is the use of spatial smoothness in the modeling of appearance change. In place of the parameterized models we might substitute regularized models of appearance change with priors on their spatial smoothness. In a mixture model framework for motion estimation, Weiss <ref> [19, 20] </ref> has shown how to incorporate regularized models and smoothness priors on the ownership weights. Another outstanding research issue concerns the learning and use of domain-specific models when more than one domain of interest exists.
References-found: 20

