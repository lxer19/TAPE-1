URL: http://www.cs.wisc.edu/~dewitt/papers/paralleldb/vldb93.ps
Refering-URL: http://www.cs.wisc.edu/~dewitt/paralleldb.html
Root-URL: 
Email: dewitt-@cs.wisc.edu  
Title: Dynamic Memory Allocation for Multiple-Query Workloads  
Author: Manish Mehta David J. DeWitt 
Address: -mmehta,  
Affiliation: Computer Science Department University of Wisconsin-Madison  
Abstract: This paper studies the problem of memory allocation and scheduling in a multiple query workload with widely varying resource requirements. Several memory allocation and scheduling schemes are presented and their performance is compared using a detailed simulation study. The results demonstrate the inadequacies of static schemes with fixed scheduling and memory allocation policies. A dynamic adaptive scheme which integrates scheduling and memory allocation is developed and is shown to perform effectively under widely varying workloads. 1. Introduction 
Abstract-found: 1
Intro-found: 1
Reference: [Chen92a] <author> Chen, Ming-Syan et. al., </author> <title> "Using Segmented Right-Deep Trees for the Execution of Pipelined Hash Joins", </title> <booktitle> Proc. 18th VLDB Conf., to appear, </booktitle> <address> Vancouver, Canada, </address> <month> August </month> <year> 1992. </year>
Reference-contexts: All these schemes use a first-come first-served policy to service the arriving queries. As will be shown later, this can lead to bad performance for a multi-query workload. -2 Query scheduling algorithms proposed in <ref> [Chen92a, Schn90] </ref> handle scheduling of only single complex join queries and do not consider multiple queries. The batch scheduling algorithms studied in [Meht93] cannot be directly applied as batch scheduling algorithms attempt only to maximize overall throughput and do not consider the impact on query response times.
Reference: [Chou85] <author> H. Chou, D. DeWitt, </author> <title> "An Evaluation of Buffer Management Strategies for Relational Database Systems", </title> <booktitle> Proc. 11th Int'l VLDB Conf., </booktitle> <address> Stockholm, Sweden, </address> <month> Aug. </month> <year> 1985. </year>
Reference-contexts: Another drawback is that the memory allocation policy is largely independent of the query scheduling policy. To the best of our knowledge each of these schemes schedules queries in a first-come, first-served manner, delaying the actual execution only until sufficient memory becomes available (e.g. DBMIN <ref> [Chou85] </ref>). As we will demonstrate, this decoupling of query scheduling from memory allocation can have disastrous effects on the overall performance of the system. The problem of processing multiple-query workloads becomes even more complex when the workload consists of different types of queries, each with widely varying memory requirements. <p> The hot set model [Sacc86] defines the notion of a hot set for nested-loop join operations and tries to pre-allocate a join's hot-set prior to its execution. The DBMIN algorithm <ref> [Chou85] </ref> extends the idea of a hot-set by estimating the buffer allocation per file based on the expected pattern of usage. The DBMIN algorithm was further extended in Marginal Gains allocation [Ng91] and later it was employed to perform predictive load control based on disk utilization [Falo91].
Reference: [Corn89] <author> D. Cornell, P. Yu, </author> <title> "Integration of Buffer Management and Query Optimization in a Relational Database Environment", </title> <booktitle> Proc. 15th Int'l VLDB Conf., </booktitle> <address> Amsterdam, The Netherlands, </address> <month> Aug, </month> <year> 1989. </year>
Reference-contexts: In addition, none of these algorithms handle the allocation of memory to hash joins. The only work, to our knowledge, that directly handles memory allocation among concurrently executing hash-join queries is <ref> [Corn89, Yu93] </ref>. The authors introduce the concepts of memory consumption and return on consumption which are used to study the overall reduction in response times due to additional memory allocation. A heuristic algorithm based on these ideas is proposed for memory allocation.
Reference: [DeWi84] <author> DeWitt, D., et al, </author> <title> "Implementation Techniques for Main Memory Database Systems," </title> <booktitle> Proc. ACM SIGMOD Conf., </booktitle> <address> Boston, MA, </address> <month> June </month> <year> 1984. </year>
Reference-contexts: Inclusion of indices and varying join selectivity changes only the overall response time of the query and not the memory requirements of the queries. As a result, ignoring these simplifications does not affect the results qualitatively. All joins were executed using the hybrid-hash join algorithm 2 <ref> [DeWi84, Shap86] </ref>. This algorithm operates in two phases. In the first phase, called the build phase, the inner relation is partitioned into n buckets I 1 1 n The tuples that hash into bucket I 1 are kept in an in-memory hash table. <p> Join Memory Allocation The amount of memory allocated to a hybrid hash join can range from the square root of the size of the inner relation to the actual size of the relation <ref> [DeWi84] </ref>. In a multi-query environment, allocating more memory to a join reduces not only the execution time of the operation but also disk and CPU contention as the query performs fewer I/O operations.
Reference: [DeWi90] <author> DeWitt, D., et al, </author> <title> "The Gamma Database Machine Project", </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <volume> 2(1), </volume> <month> March </month> <year> 1990. </year>
Reference-contexts: Including queries with multiple joins would have made it impossible to separate the effects of memory allocation from other query scheduling issues. In addition most database systems (with the exception of Gamma <ref> [DeWi90] </ref> and Volcano [Grae89b]), execute multiple-query joins as a series of binary joins and do not pipeline tuples between adjacent joins in the query tree. Such simplified workloads have also been used previously in [Falo91, Ng91, Yu93].
Reference: [Ferg 93] <author> Ferguson D., Nikolaou C., Geargiadis L., </author> <title> "Goal Oriented, Adaptive Transaction Routing for High Performance Transaction Processing Systems", </title> <booktitle> Proc. 2nd Int'l Conf. on Parallel and Distributed Systems, </booktitle> <address> San Diego CA, </address> <month> Jan. </month> <year> 1993. </year>
Reference: [Falo91] <author> C. Faloutsos, R. Ng, T. Sellis, </author> <title> "Predictive Load Control for Flexible Buffer Allocation", </title> <booktitle> Proc. 17th Int'l VLDB Conf., </booktitle> <address> Barcelona, Spain, </address> <month> Sept. </month> <year> 1991. </year>
Reference-contexts: The DBMIN algorithm [Chou85] extends the idea of a hot-set by estimating the buffer allocation per file based on the expected pattern of usage. The DBMIN algorithm was further extended in Marginal Gains allocation [Ng91] and later it was employed to perform predictive load control based on disk utilization <ref> [Falo91] </ref>. Each of these schemes, with the exception of [Falo91], ignore the effects of other concurrently executing queries and thus make localized decisions for each query. In addition, none of these algorithms handle the allocation of memory to hash joins. <p> The DBMIN algorithm was further extended in Marginal Gains allocation [Ng91] and later it was employed to perform predictive load control based on disk utilization <ref> [Falo91] </ref>. Each of these schemes, with the exception of [Falo91], ignore the effects of other concurrently executing queries and thus make localized decisions for each query. In addition, none of these algorithms handle the allocation of memory to hash joins. The only work, to our knowledge, that directly handles memory allocation among concurrently executing hash-join queries is [Corn89, Yu93]. <p> In addition most database systems (with the exception of Gamma [DeWi90] and Volcano [Grae89b]), execute multiple-query joins as a series of binary joins and do not pipeline tuples between adjacent joins in the query tree. Such simplified workloads have also been used previously in <ref> [Falo91, Ng91, Yu93] </ref>. Another simplification in the workload is that the selections were executed by scanning the data file and do not use indices.
Reference: [Grae89a] <author> G. Graefe, </author> <title> "Dynamic Query Evaluation Plans", </title> <booktitle> Proc. ACM SIGMOD '89 Conf., </booktitle> <address> Portland, Oregon, </address> <year> 1989. </year>
Reference-contexts: It is not very evident as to when taking memory from an executing query and giving it to some other query benefits the overall performance of the system. The same drawback lies in other schemes which dynamically change query plans at run-time <ref> [Grae89a] </ref>. 3. Workload Description In this study we consider only queries involving a single join and two selections. This simple workload allowed us to study the effects of memory allocation and load control without considering other complex query scheduling issues like pipelining and intra-query parallelism.
Reference: [Grae89b] <author> Gray, J., ed., "Volcano: </author> <title> An extensible and parallel dataflow query processing system.", </title> <institution> Computer Science Technical Report, Oregon Graduate Center, </institution> <address> Beavorton, OR, </address> <month> June </month> <year> 1989. </year>
Reference-contexts: Including queries with multiple joins would have made it impossible to separate the effects of memory allocation from other query scheduling issues. In addition most database systems (with the exception of Gamma [DeWi90] and Volcano <ref> [Grae89b] </ref>), execute multiple-query joins as a series of binary joins and do not pipeline tuples between adjacent joins in the query tree. Such simplified workloads have also been used previously in [Falo91, Ng91, Yu93].
Reference: [Haas90] <author> L. Haas et. al., </author> <title> "Starburst Mid-Flight: As the Dust Clears", </title> <journal> IEEE Trans. on Knowledge and Data Eng., </journal> <volume> 2(1), </volume> <month> March, </month> <year> 1990. </year>
Reference-contexts: The CPU uses a round-robin process scheduling policy. The buffer pool models a set of main memory page frames. Page replacement in the buffer pool is controlled via the LRU policy extended with "love/hate" hints (like those used in the Starburst buffer manager <ref> [Haas90] </ref>). These hints are provided by the various relational operators when fixed pages are unpinned. For example, "love" hints are given by the index scan operator to keep index pages in memory; "hate" hints are used by the sequential scan operator to prevent buffer pool flooding.
Reference: [Livn87] <author> Livny, M., S. Khoshafian, and H. Boral, </author> <title> "Multi-Disk Management Algorithms", </title> <booktitle> Proc. ACM SIGMETRICS Conf., </booktitle> <address> Alberta, Canada, </address> <month> May </month> <year> 1987. </year>
Reference-contexts: As queries arrive in the system they are first routed to a special scheduler task that controls the scheduling and execution of all transactions present in the system. The database is modeled as a set of relations that are declustered <ref> [Ries78, Livn87] </ref> over all the disk drives. The simulator models the database system as a closed queueing system [Reis80]. 7.1. Terminals The terminals model the external workload source for the system. Each terminal sequentially submits a stream of queries of a particular class.
Reference: [Meht93] <author> M. Mehta, V. Soloviev, D. DeWitt, </author> <title> "Batch Scheduling in Parallel Database Systems", </title> <booktitle> to appear 9th Int'l Conf. on Data Engineering, </booktitle> <address> Vienna, </address> <month> April </month> <year> 1993. </year>
Reference-contexts: As will be shown later, this can lead to bad performance for a multi-query workload. -2 Query scheduling algorithms proposed in [Chen92a, Schn90] handle scheduling of only single complex join queries and do not consider multiple queries. The batch scheduling algorithms studied in <ref> [Meht93] </ref> cannot be directly applied as batch scheduling algorithms attempt only to maximize overall throughput and do not consider the impact on query response times. Adaptive hash join algorithms, which can adapt to changing memory requirements have been proposed by [Zell90].
Reference: [Ng91] <author> R. Ng, C. Faloutsos, T. Sellis, </author> <title> "Flexible Buffer Allocation Based on Marginal Gains", </title> <booktitle> Proc. ACM SIGMOD '91 Conf., </booktitle> <address> Denver, CO, </address> <month> May </month> <year> 1991. </year>
Reference-contexts: The DBMIN algorithm [Chou85] extends the idea of a hot-set by estimating the buffer allocation per file based on the expected pattern of usage. The DBMIN algorithm was further extended in Marginal Gains allocation <ref> [Ng91] </ref> and later it was employed to perform predictive load control based on disk utilization [Falo91]. Each of these schemes, with the exception of [Falo91], ignore the effects of other concurrently executing queries and thus make localized decisions for each query. <p> In addition most database systems (with the exception of Gamma [DeWi90] and Volcano [Grae89b]), execute multiple-query joins as a series of binary joins and do not pipeline tuples between adjacent joins in the query tree. Such simplified workloads have also been used previously in <ref> [Falo91, Ng91, Yu93] </ref>. Another simplification in the workload is that the selections were executed by scanning the data file and do not use indices.
Reference: [Reis80] <author> M. Reiser, and S. Lavenberg, </author> <title> "Mean Value Analysis of Closed Multichain Queueing Networks", </title> <journal> JACM, </journal> <volume> 27(2), </volume> <month> April, </month> <year> 1980. </year>
Reference-contexts: The database is modeled as a set of relations that are declustered [Ries78, Livn87] over all the disk drives. The simulator models the database system as a closed queueing system <ref> [Reis80] </ref>. 7.1. Terminals The terminals model the external workload source for the system. Each terminal sequentially submits a stream of queries of a particular class.
Reference: [Ries78] <author> D. Ries, and R. Epstein, </author> <title> "Evaluation of Distribution Criteria for Distributed Database Systems", </title> <type> UCBERL Technical Report M78/22, </type> <institution> UC Berkeley, </institution> <month> May </month> <year> 1978. </year>
Reference-contexts: As queries arrive in the system they are first routed to a special scheduler task that controls the scheduling and execution of all transactions present in the system. The database is modeled as a set of relations that are declustered <ref> [Ries78, Livn87] </ref> over all the disk drives. The simulator models the database system as a closed queueing system [Reis80]. 7.1. Terminals The terminals model the external workload source for the system. Each terminal sequentially submits a stream of queries of a particular class.
Reference: [Sacc86] <author> G. Sacco, M. Schkolnick, </author> <title> "Buffer Management in Relational Database Systems", </title> <journal> ACM TODS, </journal> <volume> 11(4), </volume> <month> December </month> <year> 1986. </year>
Reference-contexts: Related Work The subject of memory allocation in database systems has been studied extensively. A significant portion of this work is related to allocating buffers to queries in order to minimize the number of disk accesses. The hot set model <ref> [Sacc86] </ref> defines the notion of a hot set for nested-loop join operations and tries to pre-allocate a join's hot-set prior to its execution. The DBMIN algorithm [Chou85] extends the idea of a hot-set by estimating the buffer allocation per file based on the expected pattern of usage.
Reference: [Schn90] <author> Schneider, D. and DeWitt, D., </author> <title> "Tradeoffs in Processing Complex Join Queries via Hashing in Multiprocessor Database Machines," </title> <booktitle> Proc. 16th VLDB Conf., </booktitle> <address> Melbourne, Australia, </address> <month> Aug. </month> <year> 1990. </year> <month> -27 </month>
Reference-contexts: All these schemes use a first-come first-served policy to service the arriving queries. As will be shown later, this can lead to bad performance for a multi-query workload. -2 Query scheduling algorithms proposed in <ref> [Chen92a, Schn90] </ref> handle scheduling of only single complex join queries and do not consider multiple queries. The batch scheduling algorithms studied in [Meht93] cannot be directly applied as batch scheduling algorithms attempt only to maximize overall throughput and do not consider the impact on query response times. <p> This simple workload allowed us to study the effects of memory allocation and load control without considering other complex query scheduling issues like pipelining and intra-query parallelism. For example, while there are several different execution strategies for complex queries such as left-deep, right-deep, and bushy scheduling <ref> [Schn90] </ref>, nothing is known about their relative performance in a multiuser environment. Including queries with multiple joins would have made it impossible to separate the effects of memory allocation from other query scheduling issues.
Reference: [Schw90] <author> H. Schwetman, </author> <title> CSIM Users' Guide, </title> <type> MCC Technical Report No. </type> <institution> ACT-126-90, Microelectronics and Computer Technology Corp., Austin, TX, </institution> <month> March </month> <year> 1990. </year>
Reference-contexts: Simulation Model The simulator used for this work was derived from a simulation model of the Gamma parallel database machine which had been validated against the actual Gamma implementation. The simulator is written in the CSIM/C++ process-oriented simulation language <ref> [Schw90] </ref>. The simulator models a centralized database system as shown in Figure 5. The system consists of a single processing node, composed of one CPU, memory, one or more disk drives, and a set of external terminals from -11 which queries are submitted.
Reference: [Shap86] <author> L. Shapiro, </author> <title> "Join Processing in Database Systems with Large Main Memories", </title> <journal> ACM TODS, </journal> <volume> 11(3), </volume> <month> Sept. </month> <year> 1986. </year>
Reference-contexts: Inclusion of indices and varying join selectivity changes only the overall response time of the query and not the memory requirements of the queries. As a result, ignoring these simplifications does not affect the results qualitatively. All joins were executed using the hybrid-hash join algorithm 2 <ref> [DeWi84, Shap86] </ref>. This algorithm operates in two phases. In the first phase, called the build phase, the inner relation is partitioned into n buckets I 1 1 n The tuples that hash into bucket I 1 are kept in an in-memory hash table.
Reference: [Yu93] <author> P. Yu, D. Cornell, </author> <title> "Buffer Management Based on Return on Consumption in a Multi-Query Environment", </title> <journal> The VLDB Journal, </journal> <volume> 2(1), </volume> <month> January </month> <year> 1993. </year>
Reference-contexts: In addition, none of these algorithms handle the allocation of memory to hash joins. The only work, to our knowledge, that directly handles memory allocation among concurrently executing hash-join queries is <ref> [Corn89, Yu93] </ref>. The authors introduce the concepts of memory consumption and return on consumption which are used to study the overall reduction in response times due to additional memory allocation. A heuristic algorithm based on these ideas is proposed for memory allocation. <p> In addition most database systems (with the exception of Gamma [DeWi90] and Volcano [Grae89b]), execute multiple-query joins as a series of binary joins and do not pipeline tuples between adjacent joins in the query tree. Such simplified workloads have also been used previously in <ref> [Falo91, Ng91, Yu93] </ref>. Another simplification in the workload is that the selections were executed by scanning the data file and do not use indices. <p> Medium query memory is divided equally among concurrent medium queries and ,in several cases, there is not much of an improvement in allocating memory between the minimum and maximum needed by the query. We plan to investigate the performance of the heuristic proposed in <ref> [Yu93] </ref> where a query gets either the maximum or the minimum memory required in the future. Even though it leads to high mean percentage changes at high loads (Fig. 20), Adaptive is the best algorithm for fairness followed by FCFS-Minimum, FCFS-Available and FCFS-Maximum as shown in Fig 19. 8.4.3.
Reference: [Zell90] <author> H. Zeller, J. Gray, </author> <title> "An Adaptive Hash Join Algorithm for Multiuser Environments", </title> <booktitle> Proc. 16th Int'l VLDB Conf., </booktitle> <address> Melbourne, Australia, </address> <month> Aug. </month> <year> 1990. </year> <month> -28 </month>
Reference-contexts: The batch scheduling algorithms studied in [Meht93] cannot be directly applied as batch scheduling algorithms attempt only to maximize overall throughput and do not consider the impact on query response times. Adaptive hash join algorithms, which can adapt to changing memory requirements have been proposed by <ref> [Zell90] </ref>. The implications of adapting to memory changes have not been investigated in the context of a multiple query workload. It is not very evident as to when taking memory from an executing query and giving it to some other query benefits the overall performance of the system.
References-found: 21

