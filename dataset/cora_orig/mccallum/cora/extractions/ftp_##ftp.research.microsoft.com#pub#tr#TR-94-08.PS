URL: ftp://ftp.research.microsoft.com/pub/tr/TR-94-08.PS
Refering-URL: http://www.research.microsoft.com/users/breese/TR-94-08.html
Root-URL: http://www.research.microsoft.com
Email: heckerma@microsoft.com,breese@microsoft.com  
Title: Causal Independence for Probability Assessment and Inference Using Bayesian Networks  
Author: David Heckerman John S. Breese 
Note: To appear in IEEE, Systems, Man, and Cybernetics  
Address: One Microsoft Way Redmond, WA 98052  
Affiliation: Microsoft Research Advanced Technology Division Microsoft Corporation  
Date: March 1994 (Revised October 1995)  
Abstract: Technical Report MSR-TR-94-08 
Abstract-found: 1
Intro-found: 1
Reference: [Buntine, 1994] <author> Buntine, W. </author> <year> (1994). </year> <title> Operations for learning with graphical models. </title> <journal> Journal of Artificial Intelligence Research, </journal> <volume> 2 </volume> <pages> 159-225. </pages>
Reference: [Cooper and Herskovits, 1992] <author> Cooper, G. and Herskovits, E. </author> <year> (1992). </year> <title> A Bayesian method for the induction of probabilistic networks from data. </title> <journal> Machine Learning, </journal> <volume> 9 </volume> <pages> 309-347. </pages>
Reference: [D'Ambrosio, 1991] <author> D'Ambrosio, B. </author> <year> (1991). </year> <title> Local expression languages for probabilistic dependence. </title> <booktitle> In Proceedings of Seventh Conference on Uncertainty in Artificial Intelligence, </booktitle> <address> Los An-geles, CA, </address> <pages> pages 95-102. </pages> <publisher> Morgan Kaufmann. </publisher>
Reference: [Diez, 1993] <author> Diez, F. </author> <year> (1993). </year> <title> Parameter adjustment in Bayes networks. the generalized noisy or-gate. </title> <booktitle> In Proceedings of Ninth Conference on Uncertainty in Artificial Intelligence, </booktitle> <address> Washington, DC, </address> <pages> pages 99-105. </pages> <publisher> Morgan Kaufmann. </publisher> <pages> 12 </pages>
Reference-contexts: Namely, whereas the unrestricted model requires 2 n probabilities, the noisy-OR model requires only n probabilities: one probability for each causal mechanism. Consequently, probability assessment is simplified, and learning algorithms are more accurate (assuming the model is correct). The noisy-OR model has been generalized in several ways <ref> [Srinivas, 1993, Diez, 1993, Heckerman, 1993, Heckerman and Breese, 1994] </ref>. In this paper, we describe these generalizations, which collectively we call causal independence, and show how these models are related to one another.
Reference: [Heckerman, 1993] <author> Heckerman, D. </author> <year> (1993). </year> <title> Causal independence for knowledge acquisition and in-ference. </title> <booktitle> In Proceedings of Ninth Conference on Uncertainty in Artificial Intelligence, </booktitle> <address> Washington, DC, </address> <pages> pages 122-127. </pages> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Namely, whereas the unrestricted model requires 2 n probabilities, the noisy-OR model requires only n probabilities: one probability for each causal mechanism. Consequently, probability assessment is simplified, and learning algorithms are more accurate (assuming the model is correct). The noisy-OR model has been generalized in several ways <ref> [Srinivas, 1993, Diez, 1993, Heckerman, 1993, Heckerman and Breese, 1994] </ref>. In this paper, we describe these generalizations, which collectively we call causal independence, and show how these models are related to one another. <p> The names of the models along with their relationships are depicted in Figure 4. After describing each model, we identify its benefits for probability assessment and/or probabilistic inference. As is to be expected, the more specific models have added benefits, but are less generally applicable. 2 <ref> [Heckerman, 1993] </ref> describes special cases of the noisy-MAX and noisy-addition models where all causes are binary. 6 relationships. 3.1 Amechanistic Causal Independence One problem with general causal independence is that it is sometimes difficult to identify specific causal mechanisms and intermediate nodes. <p> In Section 4, we examine inference speedups in more detail. 3.3 Temporal Causal Independence The last form of causal independence that we consider, called temporal causal independence <ref> [Heckerman, 1993] </ref>, is a special case of both amechanistic and decomposable causal independence. The model is depicted in Figure 8a. <p> In an application involving the effect of drugs on white blood cell counts, we found the temporal version of causal independence to be a more natural method for interacting with the expert <ref> [Heckerman, 1993] </ref>.
Reference: [Heckerman and Breese, 1994] <author> Heckerman, D. and Breese, J. </author> <year> (1994). </year> <title> A new look at causal independence. </title> <booktitle> In Proceedings of Tenth Conference on Uncertainty in Artificial Intelligence, </booktitle> <address> Seattle, WA, </address> <pages> pages 286-292. </pages> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Namely, whereas the unrestricted model requires 2 n probabilities, the noisy-OR model requires only n probabilities: one probability for each causal mechanism. Consequently, probability assessment is simplified, and learning algorithms are more accurate (assuming the model is correct). The noisy-OR model has been generalized in several ways <ref> [Srinivas, 1993, Diez, 1993, Heckerman, 1993, Heckerman and Breese, 1994] </ref>. In this paper, we describe these generalizations, which collectively we call causal independence, and show how these models are related to one another. <p> When this restriction is met, we say that the causal-independence model is decomposable <ref> [Heckerman and Breese, 1994] </ref>. An example of this form of causal independence is the noisy-OR model, where each g i (x; y) = OR (x; y), and e 0 = false. The noisy-MAX, noisy-addition, and linear-Gaussian models are also examples of decomposable causal independence.
Reference: [Heckerman et al., 1995a] <author> Heckerman, D., Breese, J., and Rommelse, K. </author> <year> (1995a). </year> <title> Decision-theoretic troubleshooting. </title> <journal> Communications of the ACM, </journal> <volume> 38 </volume> <pages> 49-57. </pages>
Reference-contexts: In an application involving the effect of drugs on white blood cell counts, we found the temporal version of causal independence to be a more natural method for interacting with the expert [Heckerman, 1993]. In contrast, in a number of hardware troubleshooting applications <ref> [Heckerman et al., 1995a] </ref>, we found the amechanistic form to be more effective. 10 4 Inference Improvement in Bayesian Networks In the previous section, we saw that there are two potential sources for gains in inference efficiency: (1) reduction in the size of parent sets afforded by (singly) decomposable causal independence,
Reference: [Heckerman et al., 1995b] <author> Heckerman, D., Geiger, D., and Chickering, D. </author> <year> (1995b). </year> <title> Learning Bayesian networks: The combination of knowledge and statistical data. </title> <journal> Machine Learning, </journal> <volume> 20 </volume> <pages> 197-243. </pages>
Reference: [Heckerman et al., 1995c] <author> Heckerman, D., Mamdani, A., and Wellman, M. </author> <year> (1995c). </year> <title> Real-world applications of Bayesian networks. </title> <journal> Communications of the ACM, </journal> <volume> 38. </volume>
Reference-contexts: The representation rigorously describes probabilistic relationships, yet includes a human-oriented qualitative structure that facilitates communication between the user and the probabilistic model. Consequently, the representation has proven to be useful for modeling many real-world problems including diagnosis, forecasting, automated vision, sensor fusion, manufacturing control, and information retrieval <ref> [Heckerman et al., 1995c] </ref>. To be more technical, a Bayesian network encodes a joint probability distribution over a set of random variables. A variable may be discrete, having a finite or countable number of states, or it may be continuous.
Reference: [Heckerman and Shachter, 1995] <author> Heckerman, D. and Shachter, R. </author> <year> (1995). </year> <title> A decision-based view of causality. </title> <type> Technical Report MSR-TR-94-10, </type> <institution> Microsoft, </institution> <address> Redmond, WA. </address>
Reference-contexts: For example, we used cause-and-effect considerations to construct the Bayesian-network structure shown in Figure 1. The network is used for troubleshooting printing problems within the Windows tm operating system. The connection between causation and conditional independence is discussed in detail in (e.g.) <ref> [Spirtes et al., 1993, Pearl, 1995, Heckerman and Shachter, 1995] </ref>. Statistical techniques for learning Bayesian-network structure from data or a combination of data and expert knowledge are also available [Cooper and Herskovits, 1992, Spiegelhalter et al., 1993, Buntine, 1994, Madigan and Raftery, 1994, Heckerman et al., 1995b]. <p> Philosophers call such an assumption a counterfactual [Lewis, 1973, Holland, 1986]|a statement that can not be verified by observation. Although this assumption may seem unusual, this and other counterfactual assumptions can be made rigorous in the context of a causal model <ref> [Rubin, 1978, Pearl, 1995, Heckerman and Shachter, 1995] </ref>. We note that amechanistic causal independence has several model restrictions. Namely, each intermediate node e i must have the same number of states as e. Also, let e 0 denote the state of e when all causes are in their distinguished state.
Reference: [Henrion, 1987] <author> Henrion, M. </author> <year> (1987). </year> <title> Some practical issues in constructing belief networks. </title> <booktitle> In Proceedings of the Third Workshop on Uncertainty in Artificial Intelligence, </booktitle> <address> Seattle, WA, </address> <pages> pages 132-139. </pages> <booktitle> Association for Uncertainty in Artificial Intelligence, </booktitle> <address> Mountain View, CA. </address> <note> Also in Kanal, </note> <editor> L., Levitt, T., and Lemmer, J., editors, </editor> <booktitle> Uncertainty in Artificial Intelligence 3, </booktitle> <pages> pages 161-174. </pages> <publisher> North-Holland, </publisher> <address> New York, </address> <year> 1989. </year>
Reference-contexts: Also, local disk space may be inadequate, but this cause of bad spooled output will be inhibited if the print job is small. Thus, we can use the 4 noisy-OR model to capture these relationships. <ref> [Henrion, 1987] </ref> extended the noisy-OR model to include situations where the effect can be true even when all described causes are false. In this extension, we include a dummy or leak cause, which is always set to true.
Reference: [Holland, 1986] <author> Holland, P. </author> <year> (1986). </year> <title> Statistics and causal inference. </title> <journal> Journal of the American Statistical Association, </journal> <volume> 81 </volume> <pages> 945-968. </pages>
Reference-contexts: Amechanistic causal independence has an interesting semantics. In particular, by definition of the intermediate nodes e i , these nodes can not be simultaneously observed. Nonetheless, the model includes the assumption that these nodes are mutually independent. Philosophers call such an assumption a counterfactual <ref> [Lewis, 1973, Holland, 1986] </ref>|a statement that can not be verified by observation. Although this assumption may seem unusual, this and other counterfactual assumptions can be made rigorous in the context of a causal model [Rubin, 1978, Pearl, 1995, Heckerman and Shachter, 1995].
Reference: [Howard and Matheson, 1981] <author> Howard, R. and Matheson, J. </author> <year> (1981). </year> <title> Influence diagrams. </title> <editor> In Howard, R. and Matheson, J., editors, </editor> <booktitle> Readings on the Principles and Applications of Decision Analysis, </booktitle> <volume> volume II, </volume> <pages> pages 721-762. </pages> <institution> Strategic Decisions Group, </institution> <address> Menlo Park, CA. </address>
Reference-contexts: 1 Introduction A Bayesian network is a modeling and inference tool for problems involving uncertainty <ref> [Howard and Matheson, 1981, Pearl, 1988] </ref>. The representation rigorously describes probabilistic relationships, yet includes a human-oriented qualitative structure that facilitates communication between the user and the probabilistic model.
Reference: [Jensen et al., 1990] <author> Jensen, F., Lauritzen, S., and Olesen, K. </author> <year> (1990). </year> <title> Bayesian updating in recursive graphical models by local computations. </title> <journal> Computational Statisticals Quarterly, </journal> <volume> 4 </volume> <pages> 269-282. </pages>
Reference-contexts: Each effect has four causes, and two of the causes are common causes of each effect. Each node in the BN2 (binary) and BN2 (5) models have two and five states, respectively. In our experiments, we used Jensen's junction-tree inference algorithm <ref> [Jensen et al., 1990] </ref>, an adaptation of Lauritzen-Spiegelhalter's algorithm [Lauritzen and Spiegelhalter, 1988]. In using this algorithm, we transform a given Bayesian network to an annotated undirected tree, where each node in the tree|sometimes called a clique|corresponds to a set of nodes in the original Bayesian network.
Reference: [Kim and Pearl, 1983] <author> Kim, J. and Pearl, J. </author> <year> (1983). </year> <title> A computational model for causal and diagnostic reasoning in inference engines. </title> <booktitle> In Proceedings Eighth International Joint Conference on Artificial Intelligence, </booktitle> <address> Karlsruhe, West Germany, </address> <pages> pages 190-193. </pages> <booktitle> International Joint Conference on Artificial Intelligence. </booktitle>
Reference-contexts: Furthermore, probabilistic inference (e.g., the computation of p (c 1 je)) has time complexity O (2 n ). To overcome this limitation of the representation, <ref> [Kim and Pearl, 1983] </ref> introduced the noisy-OR model. The model, which assumes that causes and effect are binary with states true and false, is shown in Figure 2b. The nodes m i represent inhibitory causal mechanisms, each of which have two states|true and false.
Reference: [Lauritzen and Spiegelhalter, 1988] <author> Lauritzen, S. and Spiegelhalter, D. </author> <year> (1988). </year> <title> Local computations with probabilities on graphical structures and their application to expert systems. </title> <journal> J. Royal Statistical Society B, </journal> <volume> 50 </volume> <pages> 157-224. 13 </pages>
Reference-contexts: Each node in the BN2 (binary) and BN2 (5) models have two and five states, respectively. In our experiments, we used Jensen's junction-tree inference algorithm [Jensen et al., 1990], an adaptation of Lauritzen-Spiegelhalter's algorithm <ref> [Lauritzen and Spiegelhalter, 1988] </ref>. In using this algorithm, we transform a given Bayesian network to an annotated undirected tree, where each node in the tree|sometimes called a clique|corresponds to a set of nodes in the original Bayesian network. Associated with each clique is its joint probability distribution.
Reference: [Lewis, 1973] <author> Lewis, D. </author> <year> (1973). </year> <title> Causation. </title> <journal> Journal of Philosophy, </journal> <pages> pages 556-572. </pages>
Reference-contexts: Amechanistic causal independence has an interesting semantics. In particular, by definition of the intermediate nodes e i , these nodes can not be simultaneously observed. Nonetheless, the model includes the assumption that these nodes are mutually independent. Philosophers call such an assumption a counterfactual <ref> [Lewis, 1973, Holland, 1986] </ref>|a statement that can not be verified by observation. Although this assumption may seem unusual, this and other counterfactual assumptions can be made rigorous in the context of a causal model [Rubin, 1978, Pearl, 1995, Heckerman and Shachter, 1995].
Reference: [Madigan and Raftery, 1994] <author> Madigan, D. and Raftery, A. </author> <year> (1994). </year> <title> Model selection and accounting for model uncertainty in graphical models using Occam's window. </title> <journal> Journal of the American Statistical Association, </journal> <volume> 89 </volume> <pages> 1535-1546. </pages>
Reference: [Neal, 1992] <author> Neal, R. </author> <year> (1992). </year> <title> Connectionist learning of belief networks. </title> <journal> Artificial Intelligence, </journal> <volume> 56 </volume> <pages> 71-113. </pages>
Reference-contexts: In addition, we show how the use of causal independence leads to simplifications in probability assessment and probabilistic inference. Use of the noisy-OR model to improve the learning of probabilities is discussed in <ref> [Neal, 1992] </ref>. 2 General Causal Independence Causal independence is a straightforward generalization of the noisy-OR model, and is depicted in the Bayesian network of Figure 3. In this model, the causes, effect, causal mechanisms, and intermediate nodes (x i ) may be discrete or continuous.
Reference: [Pearl, 1988] <author> Pearl, J. </author> <year> (1988). </year> <title> Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA. </address>
Reference-contexts: 1 Introduction A Bayesian network is a modeling and inference tool for problems involving uncertainty <ref> [Howard and Matheson, 1981, Pearl, 1988] </ref>. The representation rigorously describes probabilistic relationships, yet includes a human-oriented qualitative structure that facilitates communication between the user and the probabilistic model.
Reference: [Pearl, 1995] <author> Pearl, J. </author> <year> (1995). </year> <title> Causal diagrams for empirical research. </title> <journal> Biometrika, </journal> <note> to appear. </note>
Reference-contexts: For example, we used cause-and-effect considerations to construct the Bayesian-network structure shown in Figure 1. The network is used for troubleshooting printing problems within the Windows tm operating system. The connection between causation and conditional independence is discussed in detail in (e.g.) <ref> [Spirtes et al., 1993, Pearl, 1995, Heckerman and Shachter, 1995] </ref>. Statistical techniques for learning Bayesian-network structure from data or a combination of data and expert knowledge are also available [Cooper and Herskovits, 1992, Spiegelhalter et al., 1993, Buntine, 1994, Madigan and Raftery, 1994, Heckerman et al., 1995b]. <p> Philosophers call such an assumption a counterfactual [Lewis, 1973, Holland, 1986]|a statement that can not be verified by observation. Although this assumption may seem unusual, this and other counterfactual assumptions can be made rigorous in the context of a causal model <ref> [Rubin, 1978, Pearl, 1995, Heckerman and Shachter, 1995] </ref>. We note that amechanistic causal independence has several model restrictions. Namely, each intermediate node e i must have the same number of states as e. Also, let e 0 denote the state of e when all causes are in their distinguished state.
Reference: [Rubin, 1978] <author> Rubin, D. </author> <year> (1978). </year> <title> Bayesian inference for causal effects: The role of randomization. </title> <journal> Annals of Statistics, </journal> <volume> 6 </volume> <pages> 34-58. </pages>
Reference-contexts: Philosophers call such an assumption a counterfactual [Lewis, 1973, Holland, 1986]|a statement that can not be verified by observation. Although this assumption may seem unusual, this and other counterfactual assumptions can be made rigorous in the context of a causal model <ref> [Rubin, 1978, Pearl, 1995, Heckerman and Shachter, 1995] </ref>. We note that amechanistic causal independence has several model restrictions. Namely, each intermediate node e i must have the same number of states as e. Also, let e 0 denote the state of e when all causes are in their distinguished state.
Reference: [Shachter, 1986] <author> Shachter, R. </author> <year> (1986). </year> <title> Evaluating influence diagrams. </title> <journal> Operations Research, </journal> <volume> 34 </volume> <pages> 871-882. </pages>
Reference-contexts: The advantages are most significant for domains where variables are discrete. In these cases, the computational complexity of exact inference is at least exponential in the number of parents of the node with the most parents, and complexity is often discussed in <ref> [Shachter, 1986] </ref>. 4 We introduce the constant e 0 so that all functions g i have two arguments. 8 network in (a). The network in (c) has a smaller undirected cycle than that in (b). dominated by this factor.
Reference: [Shachter, 1988] <author> Shachter, R. </author> <year> (1988). </year> <title> Probabilistic inference and influence diagrams. </title> <journal> Operations Research, </journal> <volume> 36 </volume> <pages> 589-604. </pages>
Reference: [Spiegelhalter et al., 1993] <author> Spiegelhalter, D., Dawid, A., Lauritzen, S., and Cowell, R. </author> <year> (1993). </year> <title> Bayesian analysis in expert systems. </title> <journal> Statistical Science, </journal> <volume> 8 </volume> <pages> 219-282. </pages>
Reference: [Spiegelhalter and Lauritzen, 1990] <author> Spiegelhalter, D. and Lauritzen, S. </author> <year> (1990). </year> <title> Sequential updating of conditional probabilities on directed graphical structures. </title> <journal> Networks, </journal> <volume> 20 </volume> <pages> 579-605. </pages>
Reference-contexts: In a Bayesian network, each node x i is associated with the conditional probability distributions p (x i j i )|one distribution for each state of i . These distributions may be directly assessed, learned from data, or determined from a combination of prior knowledge and data <ref> [Spiegelhalter and Lauritzen, 1990] </ref>. From Equations 1 and 2, we see that any Bayesian network for fx 1 ; : : : ; x n g uniquely determines a joint probability distribution for those variables.
Reference: [Spirtes et al., 1993] <author> Spirtes, P., Glymour, C., and Scheines, R. </author> <year> (1993). </year> <title> Causation, Prediction, and Search. </title> <publisher> Springer-Verlag, </publisher> <address> New York. </address>
Reference-contexts: For example, we used cause-and-effect considerations to construct the Bayesian-network structure shown in Figure 1. The network is used for troubleshooting printing problems within the Windows tm operating system. The connection between causation and conditional independence is discussed in detail in (e.g.) <ref> [Spirtes et al., 1993, Pearl, 1995, Heckerman and Shachter, 1995] </ref>. Statistical techniques for learning Bayesian-network structure from data or a combination of data and expert knowledge are also available [Cooper and Herskovits, 1992, Spiegelhalter et al., 1993, Buntine, 1994, Madigan and Raftery, 1994, Heckerman et al., 1995b].
Reference: [Srinivas, 1993] <author> Srinivas, S. </author> <year> (1993). </year> <title> A generalization of the noisy-Or model. </title> <booktitle> In Proceedings of Ninth Conference on Uncertainty in Artificial Intelligence, </booktitle> <address> Washington, DC, </address> <pages> pages 208-215. </pages> <publisher> Morgan Kaufmann. </publisher> <pages> 14 </pages>
Reference-contexts: Namely, whereas the unrestricted model requires 2 n probabilities, the noisy-OR model requires only n probabilities: one probability for each causal mechanism. Consequently, probability assessment is simplified, and learning algorithms are more accurate (assuming the model is correct). The noisy-OR model has been generalized in several ways <ref> [Srinivas, 1993, Diez, 1993, Heckerman, 1993, Heckerman and Breese, 1994] </ref>. In this paper, we describe these generalizations, which collectively we call causal independence, and show how these models are related to one another. <p> Note that, because causes and the intermediate nodes are no longer restricted to two states, we should not interpret the causal mechanisms as necessarily inhibitory. Rather, the mechanisms represent a more general mapping from cause to effect. A slightly less general form of causal independence is described by <ref> [Srinivas, 1993] </ref>. As is true for the noisy-OR model, use of the causal-independence model simplifies the quantification of the cause-effect interaction, because the causal mechanisms are mutually independent.
References-found: 28

