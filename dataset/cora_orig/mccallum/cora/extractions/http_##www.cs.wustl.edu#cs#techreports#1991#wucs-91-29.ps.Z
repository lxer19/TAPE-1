URL: http://www.cs.wustl.edu/cs/techreports/1991/wucs-91-29.ps.Z
Refering-URL: http://www.cs.wustl.edu/cs/cs/publications.html
Root-URL: 
Title: The Difficulty of Random Attribute Noise  
Author: Sally A. Goldman Robert H. Sloan 
Note: Supported in part by a GE Foundation Junior Faculty Grant. Part of this research was conducted while the author was at the M.I.T. Laboratory for Computer Science and supported by NSF grant DCR-8607494 and a grant from the Siemens Corporation.  Part of this research was conducted while the author was at Harvard and supported by ARO grant DAAL 03-86-K-0171.  
Address: St. Louis, Missouri 63130  Chicago, IL 60680  
Affiliation: Department of Computer Science Washington University  Dept. of Electrical Engineering and Computer Science University of Illinois at Chicago  
Pubnum: WUCS-91-29  
Email: Net address: sg@cs.wustl.edu  Net address: sloan@ss1.eecs.uic.edu  
Date: June 6, 1991  
Abstract: This paper studies the robustness of pac learning algorithms when the instance space is f0; 1g n , and the examples are corrupted by purely random noise affecting only the instances (and not the labels). In the past, conflicting results on this subject have been obtained|the "best agreement" rule can only tolerate small amounts of noise, yet in some cases large amounts of noise can be tolerated. We show that the truth lies somewhere between these two alternatives. For uniform attribute noise, in which each attribute is flipped independently at random with the same probability, we present an algorithm that pac learns monomials for any (unknown) noise rate less than 1=2. Contrasting this positive result, we show that nonuniform random attribute noise, where each attribute i is flipped randomly and independently with its own probability p i , is nearly as harmful as malicious noise|no algorithm can tolerate more than a very small amount of such noise. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Dana Angluin and Philip Laird. </author> <title> Learning from noisy examples. </title> <journal> Machine Learning, </journal> <volume> 2(4) </volume> <pages> 343-370, </pages> <year> 1988. </year>
Reference-contexts: It has been shown that for both discrete <ref> [1] </ref> and continuous [8] instance spaces, the hypothesis that minimizes disagreements meets the pac criterion when the examples are modified by random labeling noise. Similarly, Kearns and Li [6] have shown that this method of minimizing disagreements can tolerate a small amount of malicious noise in discrete instance spaces. <p> The "desired," noiseless output of each oracle would thus be a correctly labeled example (x; s), where x is drawn according to D. We now describe the actual outputs from the following noise oracles: MAL - [13], RMC - <ref> [1] </ref>, MMC - [11], URA - [11], and NRA -. * When MAL is called, with probability 1 -, it does indeed return a correctly labeled (x; s) where x is drawn according to D.
Reference: [2] <author> Anselm Blumer, Andrzej Ehrenfeucht, David Haussler, and Manfred K. War-muth. </author> <title> Learnability and the Vapnik-Chervonenkis dimension. </title> <journal> Journal of the ACM, </journal> <volume> 36(4) </volume> <pages> 929-965, </pages> <year> 1989. </year>
Reference-contexts: Finally, as Blumer et al. mention <ref> [2] </ref>, their VC dimension methods can be used to prove that this minimal disagreement method also works for handling small amounts of malicious noise in continuous instance spaces.
Reference: [3] <author> David Haussler, Michael Kearns, Nick Littlestone, and Manfred K. Warmuth. </author> <title> Equivalence of models for polynomial learnability. </title> <journal> Information and Computation. </journal> <note> To appear. </note>
Reference-contexts: Good discussions of the details of the model are given by Kearns et al. and by Haussler et al. <ref> [7, 3] </ref>. Briefly, a concept is a subset of some instance space X, and a concept class is some subset of 2 X . An example of a concept c is a pair (x; s), where x 2 X, and s is 1 if x 2 c and 0 otherwise.
Reference: [4] <author> Wassily Hoeffding. </author> <title> Probability inequalities for sums of bounded random variables. </title> <journal> Journal of the American Statistical Association, </journal> <volume> 58(301) </volume> <pages> 13-30, </pages> <month> March </month> <year> 1963. </year>
Reference-contexts: Let p + denote the probability of drawing a positive example from URA -. (Note that since the noise process does not affect the labels, p + is also the probability of drawing a positive example directly from EX.) By applying Hoeffding's Inequality <ref> [4] </ref> it is easily shown that if p + * then with probability at least 1 ffi=2 the algorithm will obtain enough positive examples in step 2. Of course, if p + &lt; * then the hypothesis FALSE is *-good. <p> Of course, if p + &lt; * then the hypothesis FALSE is *-good. We now show that if enough positive examples are obtained in step 2, then the hypothesis output in step 5 is *-good with high probability. Again, by applying Ho-effding's Inequality <ref> [4] </ref>, it is easily shown that the probability that all of the estimates ^p i are within *(1 2-b )=8n of their true value p i is at least 1 ffi=2.
Reference: [5] <author> Michael Kearns. </author> <title> Thoughts on hypothesis boosting. </title> <type> (Unpublished), </type> <month> December </month> <year> 1988. </year>
Reference-contexts: We note that for arbitrary adversarial malicious noise, that is the maximum noise rate that any algorithm can tolerate <ref> [5] </ref>. Although the method of minimizing disagreements is not effective against random attribute noise, there are techniques for coping with uniform random attribute noise. In particular, Shackelford and Volper [10] have an algorithm that tolerates large amounts of random attribute noise for learning k-DNF formulas.
Reference: [6] <author> Michael Kearns and Ming Li. </author> <title> Learning in the presence of malicious errors. </title> <booktitle> In Proceedings of the Twentieth Annual ACM Symposium on Theory of Computing, </booktitle> <address> Chicago, Illinois, </address> <month> May </month> <year> 1988. </year>
Reference-contexts: It has been shown that for both discrete [1] and continuous [8] instance spaces, the hypothesis that minimizes disagreements meets the pac criterion when the examples are modified by random labeling noise. Similarly, Kearns and Li <ref> [6] </ref> have shown that this method of minimizing disagreements can tolerate a small amount of malicious noise in discrete instance spaces. <p> Kearns and Li <ref> [6] </ref> showed that for any nontrivial concept class, it is impossible to pac learn to accuracy * with examples from MAL - unless - &lt; *=(1 + *): Our result for nonuniform random attribute noise is similar, with a slightly weaker bound. 8 Labeled Instance D 1 D 2 (00; ) <p> It is possible to pac learn C to accuracy * with examples from NRA only if - &lt; 2*. Proof: We use the method of induced distributions <ref> [6] </ref>. Say C contains the concepts x 1 and x 2 . In what follows, we will put zero probability weight on instances containing 1's in positions 3 through n, and thus may assume that -k = 0 for 3 k n.
Reference: [7] <author> Michael Kearns, Ming Li, Leonard Pitt, and Leslie Valiant. </author> <title> On the learnability of boolean formulae. </title> <booktitle> In Proceedings of the Nineteenth Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 285-295, </pages> <address> New York, New York, </address> <month> May </month> <year> 1987. </year>
Reference-contexts: Good discussions of the details of the model are given by Kearns et al. and by Haussler et al. <ref> [7, 3] </ref>. Briefly, a concept is a subset of some instance space X, and a concept class is some subset of 2 X . An example of a concept c is a pair (x; s), where x 2 X, and s is 1 if x 2 c and 0 otherwise.
Reference: [8] <author> Philip D. Laird. </author> <title> Learning from Good and Bad Data. </title> <booktitle> Kluwer international series in engineering and computer science. </booktitle> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, </address> <year> 1988. </year> <month> 11 </month>
Reference-contexts: It has been shown that for both discrete [1] and continuous <ref> [8] </ref> instance spaces, the hypothesis that minimizes disagreements meets the pac criterion when the examples are modified by random labeling noise. Similarly, Kearns and Li [6] have shown that this method of minimizing disagreements can tolerate a small amount of malicious noise in discrete instance spaces.
Reference: [9] <author> J. Ross Quinlan. </author> <title> The effect of noise on concept learning. </title> <booktitle> In Machine Learning, An Artificial Intelligence Approach (Volume II), chapter 6, </booktitle> <pages> pages 149-166. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1986. </year>
Reference-contexts: Yet, one would expect that labeling noise would be worse than random attribute noise. Indeed, in one empirical test (of the ID-3 system), that is exactly what was found <ref> [9] </ref>. Yet, in spite of both these empirical results and our intuition, we have shown that in the pac model random attribute noise 10 (when it is nonuniform) is significantly more harmful than random labeling noise.
Reference: [10] <author> George Shackelford and Dennis Volper. </author> <title> Learning k-DNF with noise in the attributes. </title> <booktitle> In First Workshop on Computatinal Learning Theory, </booktitle> <pages> pages 97-103, </pages> <address> Cambridge, Mass. August 1988. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: On the one hand, Sloan [11] has show that the "best-agreement" rule can only tolerate very small amounts of random attribute noise|suggesting that random attribute noise may be difficult to overcome. However, by using a different strategy, Shackelford and Volper <ref> [10] </ref> have obtained an algorithm that tolerates a large amount of random attribute noise (at a known noise rate) for learning k-DNF formulas. Thus their result suggests that random attribute noise may be like random classification noise, where large amounts of noise can sometimes be tolerated. <p> We note that for arbitrary adversarial malicious noise, that is the maximum noise rate that any algorithm can tolerate [5]. Although the method of minimizing disagreements is not effective against random attribute noise, there are techniques for coping with uniform random attribute noise. In particular, Shackelford and Volper <ref> [10] </ref> have an algorithm that tolerates large amounts of random attribute noise for learning k-DNF formulas. That algorithm, however, has one very unpleasant requirement: it must be given the exact noise rate as an input.
Reference: [11] <author> Robert H. Sloan. </author> <title> Types of noise in data for concept learning. </title> <booktitle> In First Workshop on Computational Learning Theory, </booktitle> <pages> pages 91-96. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1988. </year>
Reference-contexts: We assume throughout that the classification of each instance is always correctly reported. In the past, conflicting results on handling random attribute noise have been obtained. On the one hand, Sloan <ref> [11] </ref> has show that the "best-agreement" rule can only tolerate very small amounts of random attribute noise|suggesting that random attribute noise may be difficult to overcome. <p> So these results specify the amount of noise that can be tolerated ignoring the issue of computation time. (Of course, if a hypothesis minimizing disagreements can be found in polynomial time then the above techniques produce efficient learning algorithms.) Sloan <ref> [11] </ref> has extended those results to the case of malicious labeling noise. Finally, as Blumer et al. mention [2], their VC dimension methods can be used to prove that this minimal disagreement method also works for handling small amounts of malicious noise in continuous instance spaces. <p> In the case of uniform random attribute noise, if one uses the minimal disagreement method, then the minimum error rate obtainable (i.e. the minimum "epsilon") is bounded below by the noise rate <ref> [11] </ref>. We note that for arbitrary adversarial malicious noise, that is the maximum noise rate that any algorithm can tolerate [5]. Although the method of minimizing disagreements is not effective against random attribute noise, there are techniques for coping with uniform random attribute noise. <p> The "desired," noiseless output of each oracle would thus be a correctly labeled example (x; s), where x is drawn according to D. We now describe the actual outputs from the following noise oracles: MAL - [13], RMC - [1], MMC - <ref> [11] </ref>, URA - [11], and NRA -. * When MAL is called, with probability 1 -, it does indeed return a correctly labeled (x; s) where x is drawn according to D. With probability it returns an example (x; s) about which no assumptions whatsoever may be made. <p> The "desired," noiseless output of each oracle would thus be a correctly labeled example (x; s), where x is drawn according to D. We now describe the actual outputs from the following noise oracles: MAL - [13], RMC - [1], MMC - <ref> [11] </ref>, URA - [11], and NRA -. * When MAL is called, with probability 1 -, it does indeed return a correctly labeled (x; s) where x is drawn according to D. With probability it returns an example (x; s) about which no assumptions whatsoever may be made. <p> In fact, nonuniform random attribute noise is significantly more harmful than malicious labeling noise generated by a powerful adversary <ref> [11] </ref>, and nearly as harmful as truly malicious noise. Acknowledgments We would like to thank Les Valiant for suggesting this line of research. We thank Dana Angluin for pointing out an error (and providing a correction to this error) in our original statement of Theorem 2.
Reference: [12] <author> Leslie G. Valiant. </author> <title> A theory of the learnable. </title> <journal> Communications of the ACM, </journal> <volume> 27(11) </volume> <pages> 1134-1142, </pages> <month> November </month> <year> 1984. </year>
Reference-contexts: that with nonuniform random attribute noise, the minimum error rate obtainable is bounded below by one-half of the noise rate, regardless of the technique (or computation time) of the learning algorithm. 2 3 Notation We assume that the reader is familiar with the model of pac learning introduced by Valiant <ref> [12] </ref>. Good discussions of the details of the model are given by Kearns et al. and by Haussler et al. [7, 3]. Briefly, a concept is a subset of some instance space X, and a concept class is some subset of 2 X .
Reference: [13] <author> Leslie G. Valiant. </author> <title> Learning disjunctions of conjunctions. </title> <booktitle> In Proceedings IJCAI-85, </booktitle> <pages> pages 560-566. </pages> <booktitle> International Joint Committee for Artificial Intelligence, </booktitle> <publisher> Mor-gan Kaufmann, </publisher> <month> August </month> <year> 1985. </year> <month> 12 </month>
Reference-contexts: The output from the noise process is all the learner can observe. The "desired," noiseless output of each oracle would thus be a correctly labeled example (x; s), where x is drawn according to D. We now describe the actual outputs from the following noise oracles: MAL - <ref> [13] </ref>, RMC - [1], MMC - [11], URA - [11], and NRA -. * When MAL is called, with probability 1 -, it does indeed return a correctly labeled (x; s) where x is drawn according to D.
References-found: 13

