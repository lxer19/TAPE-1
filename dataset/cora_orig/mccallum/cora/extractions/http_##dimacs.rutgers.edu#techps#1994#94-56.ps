URL: http://dimacs.rutgers.edu/techps/1994/94-56.ps
Refering-URL: http://dimacs.rutgers.edu/TechnicalReports/1994.html
Root-URL: http://www.cs.rutgers.edu
Title: Linear-Time Algorithm for Network Decomposition  
Author: by Lenore J. Cowen ; 
Address: Baltimore, MD 21218  
Affiliation: Department of Mathematical Sciences Johns Hopkins University  
Note: A  2 Visit supported by an NSF Postdoctoral Fellowship. DIMACS is a cooperative project of Rutgers University, Princeton University, AT&T Bell Laboratories and Bellcore. DIMACS is an NSF Science and Technology Center, funded under contract STC-91-19999; and also receives support from the New Jersey Commission on Science and Technology.  
Abstract: DIMACS Technical Report 94-56 December 1994 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Y. Afek and M. Riklin. Sparser: </author> <title> A paradigm for running distributed algorithms. </title> <editor> J. </editor> <booktitle> of Algorithms, </booktitle> <year> 1991. </year>
Reference-contexts: that the low-diameter condition was best possible: there exist families of graphs for which to minimize and d simultaneously, require ; d = O (log n).) Further work on network decomposition focused on the construction of low-diameter network decompositions, and applications, in the parallel and distributed models of computation (see <ref> [1, 2, 3, 5, 6, 7] </ref>.) In this note, it is shown how to modify the simple greedy construction in [6] to save a log n factor in running time. The new algorithm runs in O (E + n) time, which is optimal.
Reference: [2] <author> B. Awerbuch, B. Berger, L. Cowen, and D. Peleg. </author> <title> Fast distributed network decomposition. </title> <booktitle> In Proc. 11th ACM Symp. on Principles of Distributed Computing, </booktitle> <month> Aug. </month> <year> 1992. </year>
Reference-contexts: that the low-diameter condition was best possible: there exist families of graphs for which to minimize and d simultaneously, require ; d = O (log n).) Further work on network decomposition focused on the construction of low-diameter network decompositions, and applications, in the parallel and distributed models of computation (see <ref> [1, 2, 3, 5, 6, 7] </ref>.) In this note, it is shown how to modify the simple greedy construction in [6] to save a log n factor in running time. The new algorithm runs in O (E + n) time, which is optimal.
Reference: [3] <author> B. Awerbuch, B. Berger, L. Cowen, and D. Peleg. </author> <title> Low-diamter graph decomposition is in NC. </title> <booktitle> In Proc. 3'rd Scandinavian Workshop on Algorithm Theory, </booktitle> <month> July </month> <year> 1992. </year>
Reference-contexts: that the low-diameter condition was best possible: there exist families of graphs for which to minimize and d simultaneously, require ; d = O (log n).) Further work on network decomposition focused on the construction of low-diameter network decompositions, and applications, in the parallel and distributed models of computation (see <ref> [1, 2, 3, 5, 6, 7] </ref>.) In this note, it is shown how to modify the simple greedy construction in [6] to save a log n factor in running time. The new algorithm runs in O (E + n) time, which is optimal.
Reference: [4] <author> B. Awerbuch, A. Goldberg, M. Luby, and S. Plotkin. </author> <title> Network decomposition and locality in distributed computation. </title> <booktitle> In Proc. 30th IEEE Symp. on Foundations of Computer Science, </booktitle> <month> May </month> <year> 1989. </year>
Reference-contexts: A (; d)-decomposition is said to be low-diameter if and d are both O (log n). The (; d)- decomposition problem, most commonly called network decomposition was introduced in <ref> [4] </ref> as a means of partitioning a network into local regions, though they did not achieve clusters that were low-diameter by the standards of the above definition (They produced and d both O (n * ), for * = O ( p p In [5, 6] a simple greedy algorithm was
Reference: [5] <author> B. Awerbuch and D. Peleg. </author> <title> Sparse partitions. </title> <booktitle> In Proc. 31st IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 503-513, </pages> <year> 1990. </year>
Reference-contexts: called network decomposition was introduced in [4] as a means of partitioning a network into local regions, though they did not achieve clusters that were low-diameter by the standards of the above definition (They produced and d both O (n * ), for * = O ( p p In <ref> [5, 6] </ref> a simple greedy algorithm was presented that produced a low-diameter network decomposition in O (E log n + n) time. (In addition, [6] proved that the low-diameter condition was best possible: there exist families of graphs for which to minimize and d simultaneously, require ; d = O (log <p> that the low-diameter condition was best possible: there exist families of graphs for which to minimize and d simultaneously, require ; d = O (log n).) Further work on network decomposition focused on the construction of low-diameter network decompositions, and applications, in the parallel and distributed models of computation (see <ref> [1, 2, 3, 5, 6, 7] </ref>.) In this note, it is shown how to modify the simple greedy construction in [6] to save a log n factor in running time. The new algorithm runs in O (E + n) time, which is optimal.
Reference: [6] <author> N. Linial and M. Saks. </author> <title> Decomposing graphs into regions of small diameter. </title> <booktitle> In Proc. 2nd ACM-SIAM Symp. on Discrete Algorithms, </booktitle> <pages> pages 320-330. </pages> <address> ACM/SIAM, </address> <month> Jan. </month> <year> 1991. </year>
Reference-contexts: called network decomposition was introduced in [4] as a means of partitioning a network into local regions, though they did not achieve clusters that were low-diameter by the standards of the above definition (They produced and d both O (n * ), for * = O ( p p In <ref> [5, 6] </ref> a simple greedy algorithm was presented that produced a low-diameter network decomposition in O (E log n + n) time. (In addition, [6] proved that the low-diameter condition was best possible: there exist families of graphs for which to minimize and d simultaneously, require ; d = O (log <p> were low-diameter by the standards of the above definition (They produced and d both O (n * ), for * = O ( p p In [5, 6] a simple greedy algorithm was presented that produced a low-diameter network decomposition in O (E log n + n) time. (In addition, <ref> [6] </ref> proved that the low-diameter condition was best possible: there exist families of graphs for which to minimize and d simultaneously, require ; d = O (log n).) Further work on network decomposition focused on the construction of low-diameter network decompositions, and applications, in the parallel and distributed models of computation <p> that the low-diameter condition was best possible: there exist families of graphs for which to minimize and d simultaneously, require ; d = O (log n).) Further work on network decomposition focused on the construction of low-diameter network decompositions, and applications, in the parallel and distributed models of computation (see <ref> [1, 2, 3, 5, 6, 7] </ref>.) In this note, it is shown how to modify the simple greedy construction in [6] to save a log n factor in running time. The new algorithm runs in O (E + n) time, which is optimal. <p> ; d = O (log n).) Further work on network decomposition focused on the construction of low-diameter network decompositions, and applications, in the parallel and distributed models of computation (see [1, 2, 3, 5, 6, 7].) In this note, it is shown how to modify the simple greedy construction in <ref> [6] </ref> to save a log n factor in running time. The new algorithm runs in O (E + n) time, which is optimal. Note that the new construction will produce clusters whose diameter can be larger by a small constant factor than those in [6], so in some applications where network <p> modify the simple greedy construction in <ref> [6] </ref> to save a log n factor in running time. The new algorithm runs in O (E + n) time, which is optimal. Note that the new construction will produce clusters whose diameter can be larger by a small constant factor than those in [6], so in some applications where network decomposition is used as a data structure, the original algorithm might be preferable in practice, even though it is more costly. 2 The Algorithm The new algorithm works as follows. Pick a color. <p> the interior, (i.e. are also in the ball of radius r 1 around the center node), AND (b) at least half the edges which are adjacent to a vertex in the ball of radius r, have an endpoint within the ball of radius r 1. (This is the modification of <ref> [6] </ref>). The interior of the ball is put into the color class, and the entire ball is removed from the graph. (The border (those nodes whose distance from the center vertex is exactly r) will not be colored with the current color).
Reference: [7] <author> A. Panconesi and A. Srinivasan. </author> <title> Improved distributed algorithms for coloring and network decomposition problems. </title> <booktitle> In Proc. 24th ACM Symp. on Theory of Computing, </booktitle> <pages> pages 581-592, </pages> <year> 1992. </year>
Reference-contexts: that the low-diameter condition was best possible: there exist families of graphs for which to minimize and d simultaneously, require ; d = O (log n).) Further work on network decomposition focused on the construction of low-diameter network decompositions, and applications, in the parallel and distributed models of computation (see <ref> [1, 2, 3, 5, 6, 7] </ref>.) In this note, it is shown how to modify the simple greedy construction in [6] to save a log n factor in running time. The new algorithm runs in O (E + n) time, which is optimal.
References-found: 7

