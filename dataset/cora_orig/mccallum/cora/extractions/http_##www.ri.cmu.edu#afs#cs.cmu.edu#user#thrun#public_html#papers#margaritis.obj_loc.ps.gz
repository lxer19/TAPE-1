URL: http://www.ri.cmu.edu/afs/cs.cmu.edu/user/thrun/public_html/papers/margaritis.obj_loc.ps.gz
Refering-URL: http://www.ri.cmu.edu/afs/cs.cmu.edu/user/thrun/public_html/papers/full.html
Root-URL: 
Email: dmarg+@cs.cmu.edu  thrun+@cs.cmu.edu  
Title: Learning To Locate An Object in 3D Space From A Sequence Of Camera Images  
Author: Dimitris Margaritis Sebastian Thrun 
Keyword: Mobile Robotics, Decision Trees, Probabilistic Reasoning.  
Note: Contact author: Dimitris Margaritis office: (412) 2686767 lab: (412) 2683837  
Address: 5000 Forbes Ave. Pittsburgh, PA 15213  
Affiliation: Dept. of Computer Science Carnegie Mellon University  
Abstract: This paper addresses the problem of determining an object's 3D location from a stream of camera images recorded by mobile robot. The approach presented here allows people to train robots to recognize specific objects, by presenting it examples of the object to be recognized. A decision tree method is used to learn significant features of the target object from individual camera images. Individual estimates are integrated over time using Bayes rule, into a probabilistic 3D model of the robot's environment. Experimental results illustrate that the method enables a mobile robot to robustly estimate the 3D location of objects from multiple camera images. 
Abstract-found: 1
Intro-found: 1
Reference: [BBC + 95] <author> J. Buhmann, W. Burgard, A. B. Cremers, D. Fox, T. Hofmann, F. Schneider, J. Strikos, and S. Thrun. </author> <title> The mobile robot Rhino. </title> <journal> AI Magazine, </journal> <volume> 16(1), </volume> <year> 1995. </year>
Reference-contexts: Our approach can handle situations that contain a variable (unknown) number of target objects. Finally, the problem of finding and manipulating objects has received considerable attention within the AI community (see [Hor94] and various papers in [Sim95, KBM98]). For example, Buhmann et al. <ref> [BBC + 95] </ref> described an approach where a robot could be trained to recognize specific objects. Most existing approaches in the mobile robot community, however, make the assumption that the object is located in floor-height, in which case camera coordinates can directly be converted to real-world coordinates.
Reference: [BFHS96] <author> W. Burgard, D. Fox, D. Hennig, and T. Schmidt. </author> <title> Estimating the absolute position of a mobile robot using position probability grids. </title> <booktitle> In Proceedings of the Thirteenth National Conference on Artificial Intelligence, </booktitle> <address> Menlo Park, </address> <month> August </month> <year> 1996. </year> <booktitle> AAAI, </booktitle> <publisher> AAAI Press/MIT Press. </publisher>
Reference-contexts: The approach reported here estimates distance indirectly, through integrating multiple camera images recorded at different locations. Unfortunately, the approach in [MM94] is incapable of dealing with error in the robot's odometry. Our approach is similar to Markov localization <ref> [BFHS96, NPB95, SK95, Thr98a] </ref>, a method for probabilistically estimating the pose of a mobile robot in a (known) environment. Markov localization relies on the same statistical principles for integrating multiple sensor readings into a single belief. <p> Our approach is similar to Markov localization [BFHS96, NPB95, SK95, Thr98a], a method for probabilistically estimating the pose of a mobile robot in a (known) environment. Markov localization relies on the same statistical principles for integrating multiple sensor readings into a single belief. In fact, the approach in <ref> [BFHS96] </ref> uses the same basic representations as our approach: evenly spaced grids. Markov localization, however, rests on the assumption that there is exactly one object (i.e., the robot) whose location is to be estimated. Our approach can handle situations that contain a variable (unknown) number of target objects.
Reference: [CB90] <author> G.C. Casella and R.L. Berger. </author> <title> Statistical Inference. </title> <publisher> Wadsworth & Brooks, </publisher> <address> Pacific Grove, CA, </address> <year> 1990. </year>
Reference-contexts: Like the approaches presented in [FI93, MKS94], it partitions a real-valued high-dimensional input space into hypercubes. The output nodes, however, represent conditional densities, which are estimated using a frequentist approach <ref> [CB90] </ref>. This is related to results reported in [TLS89, Mac92, Mit97], which show that under appropriate assumptions, artificial neural networks approximate conditional probability density functions. The mathematical approach for integrating information is adopted from the statistical literature [CB90, Pea88]. <p> This is related to results reported in [TLS89, Mac92, Mit97], which show that under appropriate assumptions, artificial neural networks approximate conditional probability density functions. The mathematical approach for integrating information is adopted from the statistical literature <ref> [CB90, Pea88] </ref>. The approach presented in this paper also bears close resemblance to occupancy grids [Mor88, Elf89]. Occupancy grid approaches are popular techniques for learning models of mobile robot environments from sensor data. Just like the approach proposed here, they represent the environment using fine-grained, evenly spaced grids.
Reference: [Elf89] <author> A. Elfes. </author> <title> Occupancy Grids: A Probabilistic Framework for Robot Perception and Navigation. </title> <type> PhD thesis, </type> <institution> Department of Electrical and Computer Engineering, Carnegie Mellon University, </institution> <year> 1989. </year>
Reference-contexts: The mathematical approach for integrating information is adopted from the statistical literature [CB90, Pea88]. The approach presented in this paper also bears close resemblance to occupancy grids <ref> [Mor88, Elf89] </ref>. Occupancy grid approaches are popular techniques for learning models of mobile robot environments from sensor data. Just like the approach proposed here, they represent the environment using fine-grained, evenly spaced grids.
Reference: [FI93] <author> U.M. Fayyad and K.B. Irani. </author> <title> Multi-interval discretization of continuous-valued attributes for classification learning. </title> <booktitle> In Proceedings of IJCAI-93, </booktitle> <address> Chamberry, France, </address> <month> July </month> <year> 1993. </year> <title> IJCAI, </title> <publisher> Inc. </publisher>
Reference-contexts: The early algorithms were only applicable to problems with discrete input and output spaces. Decision tree learning algorithms for real-valued input spaces were proposed in <ref> [FI93, MKS94] </ref>. Tree-based regression methods for real-valued input and output spaces can be found in [Fri91, Moo90]. The work presented in this paper provides an example where a decision tree is used to learn a conditional probability density function. Like the approaches presented in [FI93, MKS94], it partitions a real-valued high-dimensional <p> real-valued input spaces were proposed in <ref> [FI93, MKS94] </ref>. Tree-based regression methods for real-valued input and output spaces can be found in [Fri91, Moo90]. The work presented in this paper provides an example where a decision tree is used to learn a conditional probability density function. Like the approaches presented in [FI93, MKS94], it partitions a real-valued high-dimensional input space into hypercubes. The output nodes, however, represent conditional densities, which are estimated using a frequentist approach [CB90]. This is related to results reported in [TLS89, Mac92, Mit97], which show that under appropriate assumptions, artificial neural networks approximate conditional probability density functions.
Reference: [Fri91] <author> J. H. Friedman. </author> <title> Multivariate adaptive regression splines. </title> <journal> Annals of Statistics, </journal> <volume> 19(1):1141, </volume> <month> March </month> <year> 1991. </year>
Reference-contexts: The early algorithms were only applicable to problems with discrete input and output spaces. Decision tree learning algorithms for real-valued input spaces were proposed in [FI93, MKS94]. Tree-based regression methods for real-valued input and output spaces can be found in <ref> [Fri91, Moo90] </ref>. The work presented in this paper provides an example where a decision tree is used to learn a conditional probability density function. Like the approaches presented in [FI93, MKS94], it partitions a real-valued high-dimensional input space into hypercubes.
Reference: [Hor94] <author> I. Horswill. </author> <title> Specialization of perceptual processes. </title> <type> Technical Report AI TR-1511, </type> <institution> MIT, AI Lab, </institution> <address> Cambridge, MA, </address> <month> September </month> <year> 1994. </year>
Reference-contexts: Our approach can handle situations that contain a variable (unknown) number of target objects. Finally, the problem of finding and manipulating objects has received considerable attention within the AI community (see <ref> [Hor94] </ref> and various papers in [Sim95, KBM98]). For example, Buhmann et al. [BBC + 95] described an approach where a robot could be trained to recognize specific objects.
Reference: [KBM98] <author> D. Kortenkamp, R.P. Bonassi, and R. Murphy, </author> <title> editors. AI-based Mobile Robots: Case studies of successful robot systems, </title> <address> Cambridge, MA, </address> <year> 1998. </year> <note> MIT Press. to appear. </note>
Reference-contexts: Our approach can handle situations that contain a variable (unknown) number of target objects. Finally, the problem of finding and manipulating objects has received considerable attention within the AI community (see [Hor94] and various papers in <ref> [Sim95, KBM98] </ref>). For example, Buhmann et al. [BBC + 95] described an approach where a robot could be trained to recognize specific objects.
Reference: [Mac92] <author> D. J. C. MacKay. </author> <title> Bayesian Methods for Adaptive Models. </title> <type> PhD thesis, </type> <institution> California Institute of Technology, Pasadena, California, </institution> <year> 1992. </year>
Reference-contexts: Like the approaches presented in [FI93, MKS94], it partitions a real-valued high-dimensional input space into hypercubes. The output nodes, however, represent conditional densities, which are estimated using a frequentist approach [CB90]. This is related to results reported in <ref> [TLS89, Mac92, Mit97] </ref>, which show that under appropriate assumptions, artificial neural networks approximate conditional probability density functions. The mathematical approach for integrating information is adopted from the statistical literature [CB90, Pea88]. The approach presented in this paper also bears close resemblance to occupancy grids [Mor88, Elf89].
Reference: [Mit97] <author> T.M. Mitchell. </author> <title> Machine Learning. </title> <publisher> McGraw-Hill, </publisher> <year> 1997. </year>
Reference-contexts: It is common practice to penalize complexity when inducing decision trees <ref> [Qui86, Mit97] </ref>. This is because large trees tend to overfit the data, which usually has a negative effect on the generalization accuracy. The literature has produced two different paradigms for penalizing complexity: restricting the growth of the tree, and post-pruning fully grown trees. <p> As these results demonstrate, our approach can accurately determine the location of the target object. It is also robust to errors in the robot's odometry. This robustness is a result of incorporating our probabilistic model of robot motion. 5 Related Work Decision trees <ref> [Qui86, Qui93, Mit97] </ref> are one of the most popular inductive machine learning method to date. The early algorithms were only applicable to problems with discrete input and output spaces. Decision tree learning algorithms for real-valued input spaces were proposed in [FI93, MKS94]. <p> Like the approaches presented in [FI93, MKS94], it partitions a real-valued high-dimensional input space into hypercubes. The output nodes, however, represent conditional densities, which are estimated using a frequentist approach [CB90]. This is related to results reported in <ref> [TLS89, Mac92, Mit97] </ref>, which show that under appropriate assumptions, artificial neural networks approximate conditional probability density functions. The mathematical approach for integrating information is adopted from the statistical literature [CB90, Pea88]. The approach presented in this paper also bears close resemblance to occupancy grids [Mor88, Elf89].
Reference: [MKS94] <author> S.K. Murthy, S. Kasif, and S. Salzberg. </author> <title> A system for induction of oblique decision trees. </title> <journal> Journal of Artificial Intelligence Research, </journal> <volume> 2:133, </volume> <year> 1994. </year>
Reference-contexts: The early algorithms were only applicable to problems with discrete input and output spaces. Decision tree learning algorithms for real-valued input spaces were proposed in <ref> [FI93, MKS94] </ref>. Tree-based regression methods for real-valued input and output spaces can be found in [Fri91, Moo90]. The work presented in this paper provides an example where a decision tree is used to learn a conditional probability density function. Like the approaches presented in [FI93, MKS94], it partitions a real-valued high-dimensional <p> real-valued input spaces were proposed in <ref> [FI93, MKS94] </ref>. Tree-based regression methods for real-valued input and output spaces can be found in [Fri91, Moo90]. The work presented in this paper provides an example where a decision tree is used to learn a conditional probability density function. Like the approaches presented in [FI93, MKS94], it partitions a real-valued high-dimensional input space into hypercubes. The output nodes, however, represent conditional densities, which are estimated using a frequentist approach [CB90]. This is related to results reported in [TLS89, Mac92, Mit97], which show that under appropriate assumptions, artificial neural networks approximate conditional probability density functions.
Reference: [MM94] <author> H.P. Moravec and M.C. Martin. </author> <title> Robot navigation by 3D spatial evidence grids. Mobile Robot Laboratory, </title> <institution> Robotics Institute, Carnegie Mellon University, </institution> <year> 1994. </year>
Reference-contexts: First, they model occupancy, not the location of a specific target object. Second they are usually constructed from range measurements (e.g., sonar, laser), not from camera images. Third, they are usually two-dimensional. There are, however, notable exceptions. The approaches described in <ref> [MM94, TBB + 98] </ref> construct occupancy grids from sequences of camera images. Moravec and Martin's approach [MM94] has probably been the first to construct 3D grids, instead of the commonly used 2D representations. Both approaches, however, used stereo vision to estimate the loca 13 tion of obstacles. <p> Second they are usually constructed from range measurements (e.g., sonar, laser), not from camera images. Third, they are usually two-dimensional. There are, however, notable exceptions. The approaches described in [MM94, TBB + 98] construct occupancy grids from sequences of camera images. Moravec and Martin's approach <ref> [MM94] </ref> has probably been the first to construct 3D grids, instead of the commonly used 2D representations. Both approaches, however, used stereo vision to estimate the loca 13 tion of obstacles. Stereo vision generates distance estimates, which greatly facilitates the construction of the maps. <p> Both approaches, however, used stereo vision to estimate the loca 13 tion of obstacles. Stereo vision generates distance estimates, which greatly facilitates the construction of the maps. The approach reported here estimates distance indirectly, through integrating multiple camera images recorded at different locations. Unfortunately, the approach in <ref> [MM94] </ref> is incapable of dealing with error in the robot's odometry. Our approach is similar to Markov localization [BFHS96, NPB95, SK95, Thr98a], a method for probabilistically estimating the pose of a mobile robot in a (known) environment.
Reference: [Moo90] <author> A. W. Moore. </author> <title> Efficient Memory-based Learning for Robot Control. </title> <type> PhD thesis, </type> <institution> Trinity Hall, University of Cambridge, </institution> <address> England, </address> <year> 1990. </year>
Reference-contexts: The early algorithms were only applicable to problems with discrete input and output spaces. Decision tree learning algorithms for real-valued input spaces were proposed in [FI93, MKS94]. Tree-based regression methods for real-valued input and output spaces can be found in <ref> [Fri91, Moo90] </ref>. The work presented in this paper provides an example where a decision tree is used to learn a conditional probability density function. Like the approaches presented in [FI93, MKS94], it partitions a real-valued high-dimensional input space into hypercubes. <p> Denser and larger grids are desirable, but unfortunately the computational cost of of updating the grid is cubic in the number of grid cells. An interesting extension of the current approach would be to use variable-resolution representations, such as oct-trees <ref> [Sam89b, Sam89a, Moo90] </ref>, for representing object location. Such representations could balance the computational and memory resources, by modeling regions coarsely that are unlikely to contain a target object.
Reference: [Mor88] <author> H. P. Moravec. </author> <title> Sensor fusion in certainty grids for mobile robots. </title> <journal> AI Magazine, </journal> <pages> pages 6174, </pages> <month> Summer </month> <year> 1988. </year>
Reference-contexts: The mathematical approach for integrating information is adopted from the statistical literature [CB90, Pea88]. The approach presented in this paper also bears close resemblance to occupancy grids <ref> [Mor88, Elf89] </ref>. Occupancy grid approaches are popular techniques for learning models of mobile robot environments from sensor data. Just like the approach proposed here, they represent the environment using fine-grained, evenly spaced grids.
Reference: [NPB95] <author> I. Nourbakhsh, R. Powers, and S. Birchfield. </author> <title> DERVISH an office-navigating robot. </title> <journal> AI Magazine, </journal> <volume> 16(2):53 60, </volume> <month> Summer </month> <year> 1995. </year>
Reference-contexts: The approach reported here estimates distance indirectly, through integrating multiple camera images recorded at different locations. Unfortunately, the approach in [MM94] is incapable of dealing with error in the robot's odometry. Our approach is similar to Markov localization <ref> [BFHS96, NPB95, SK95, Thr98a] </ref>, a method for probabilistically estimating the pose of a mobile robot in a (known) environment. Markov localization relies on the same statistical principles for integrating multiple sensor readings into a single belief.
Reference: [Pea88] <author> J. Pearl. </author> <title> Probabilistic reasoning in intelligent systems: networks of plausible inference. </title> <publisher> Morgan Kaufmann Publishers, </publisher> <address> San Mateo, CA, </address> <year> 1988. </year>
Reference-contexts: Here v ~ N (10; 1 2 ). Right image: This graph illustrates the outcome of specific motion commands projected along the z axis. Similar formulas for belief integration can be found in <ref> [Pea88, Thr98b] </ref>. 3.2 Robot Motion Each robot motion introduces uncertainty into the robot's estimate of the object's location because of imperfect actuators and measuring devices. <p> This is related to results reported in [TLS89, Mac92, Mit97], which show that under appropriate assumptions, artificial neural networks approximate conditional probability density functions. The mathematical approach for integrating information is adopted from the statistical literature <ref> [CB90, Pea88] </ref>. The approach presented in this paper also bears close resemblance to occupancy grids [Mor88, Elf89]. Occupancy grid approaches are popular techniques for learning models of mobile robot environments from sensor data. Just like the approach proposed here, they represent the environment using fine-grained, evenly spaced grids.
Reference: [Qui86] <author> J. R. Quinlan. </author> <title> Induction of decision trees. </title> <booktitle> Machine Learning, </booktitle> <address> 1:81106, </address> <year> 1986. </year>
Reference-contexts: It is common practice to penalize complexity when inducing decision trees <ref> [Qui86, Mit97] </ref>. This is because large trees tend to overfit the data, which usually has a negative effect on the generalization accuracy. The literature has produced two different paradigms for penalizing complexity: restricting the growth of the tree, and post-pruning fully grown trees. <p> As these results demonstrate, our approach can accurately determine the location of the target object. It is also robust to errors in the robot's odometry. This robustness is a result of incorporating our probabilistic model of robot motion. 5 Related Work Decision trees <ref> [Qui86, Qui93, Mit97] </ref> are one of the most popular inductive machine learning method to date. The early algorithms were only applicable to problems with discrete input and output spaces. Decision tree learning algorithms for real-valued input spaces were proposed in [FI93, MKS94].
Reference: [Qui93] <author> J. R. Quinlan. C4.5: </author> <title> Programs for Machine Learning. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1993. </year>
Reference-contexts: As these results demonstrate, our approach can accurately determine the location of the target object. It is also robust to errors in the robot's odometry. This robustness is a result of incorporating our probabilistic model of robot motion. 5 Related Work Decision trees <ref> [Qui86, Qui93, Mit97] </ref> are one of the most popular inductive machine learning method to date. The early algorithms were only applicable to problems with discrete input and output spaces. Decision tree learning algorithms for real-valued input spaces were proposed in [FI93, MKS94].
Reference: [Sam89a] <author> H. Samet. </author> <title> Applications of Spatial Data Structures. </title> <publisher> Addison-Wesley Publishing Inc., </publisher> <year> 1989. </year>
Reference-contexts: Denser and larger grids are desirable, but unfortunately the computational cost of of updating the grid is cubic in the number of grid cells. An interesting extension of the current approach would be to use variable-resolution representations, such as oct-trees <ref> [Sam89b, Sam89a, Moo90] </ref>, for representing object location. Such representations could balance the computational and memory resources, by modeling regions coarsely that are unlikely to contain a target object.
Reference: [Sam89b] <author> H. Samet. </author> <title> The Design and Analysis of Spatial Data Structures. </title> <publisher> Addison-Wesley Publishing Inc., </publisher> <year> 1989. </year>
Reference-contexts: Denser and larger grids are desirable, but unfortunately the computational cost of of updating the grid is cubic in the number of grid cells. An interesting extension of the current approach would be to use variable-resolution representations, such as oct-trees <ref> [Sam89b, Sam89a, Moo90] </ref>, for representing object location. Such representations could balance the computational and memory resources, by modeling regions coarsely that are unlikely to contain a target object.
Reference: [Sim95] <author> R. Simmons. </author> <title> The 1994 AAAI robot competition and exhibition. </title> <journal> AI Magazine, </journal> <volume> 16(1), </volume> <month> Spring </month> <year> 1995. </year>
Reference-contexts: Our approach can handle situations that contain a variable (unknown) number of target objects. Finally, the problem of finding and manipulating objects has received considerable attention within the AI community (see [Hor94] and various papers in <ref> [Sim95, KBM98] </ref>). For example, Buhmann et al. [BBC + 95] described an approach where a robot could be trained to recognize specific objects.
Reference: [SK95] <author> R. Simmons and S. Koenig. </author> <title> Probabilistic robot navigation in partially observable environments. </title> <booktitle> In Pro ceedings of IJCAI-95, </booktitle> <pages> pages 10801087, </pages> <address> Montreal, Canada, </address> <month> August </month> <year> 1995. </year> <title> IJCAI, </title> <publisher> Inc. </publisher>
Reference-contexts: The approach reported here estimates distance indirectly, through integrating multiple camera images recorded at different locations. Unfortunately, the approach in [MM94] is incapable of dealing with error in the robot's odometry. Our approach is similar to Markov localization <ref> [BFHS96, NPB95, SK95, Thr98a] </ref>, a method for probabilistically estimating the pose of a mobile robot in a (known) environment. Markov localization relies on the same statistical principles for integrating multiple sensor readings into a single belief.
Reference: [TBB + 98] <author> S. Thrun, A. Bucken, W. Burgard, D. Fox, T. Frohlinghaus, D. Hennig, T. Hofmann, M. Krell, and T. Schimdt. </author> <title> Map learning and high-speed navigation in RHINO. </title> <editor> In D. Kortenkamp, R.P. Bonasso, and R. Murphy, editors, </editor> <title> AI-based Mobile Robots: Case studies of successful robot systems. </title> <publisher> MIT Press, </publisher> <address> Cam-bridge, MA, </address> <year> 1998. </year> <note> to appear. </note>
Reference-contexts: First, they model occupancy, not the location of a specific target object. Second they are usually constructed from range measurements (e.g., sonar, laser), not from camera images. Third, they are usually two-dimensional. There are, however, notable exceptions. The approaches described in <ref> [MM94, TBB + 98] </ref> construct occupancy grids from sequences of camera images. Moravec and Martin's approach [MM94] has probably been the first to construct 3D grids, instead of the commonly used 2D representations. Both approaches, however, used stereo vision to estimate the loca 13 tion of obstacles.
Reference: [Thr98a] <author> S. Thrun. </author> <title> Bayesian landmark learning for mobile robot localization. </title> <booktitle> Machine Learning, </booktitle> <year> 1998. </year> <note> to appear. </note>
Reference-contexts: The approach reported here estimates distance indirectly, through integrating multiple camera images recorded at different locations. Unfortunately, the approach in [MM94] is incapable of dealing with error in the robot's odometry. Our approach is similar to Markov localization <ref> [BFHS96, NPB95, SK95, Thr98a] </ref>, a method for probabilistically estimating the pose of a mobile robot in a (known) environment. Markov localization relies on the same statistical principles for integrating multiple sensor readings into a single belief.
Reference: [Thr98b] <author> S. Thrun. </author> <title> Learning maps for indoor mobile robot navigation. </title> <journal> Artificial Intelligence, </journal> <note> 1998. to appear. </note>
Reference-contexts: Here v ~ N (10; 1 2 ). Right image: This graph illustrates the outcome of specific motion commands projected along the z axis. Similar formulas for belief integration can be found in <ref> [Pea88, Thr98b] </ref>. 3.2 Robot Motion Each robot motion introduces uncertainty into the robot's estimate of the object's location because of imperfect actuators and measuring devices. <p> Another promising extension of the current approach would be to devise methods that actively control the robot so as to maximize information gain. In the experiments presented here, a human manually positioned the robot. In our previous work <ref> [Thr98b] </ref>, however, we already developed successful methods for active information gathering, which were applied in the context of learning 2D occupancy grid maps.
Reference: [TLS89] <author> N. Thishby, E. Levin, and S. A. Solla. </author> <title> Consistent inference of probabilities in layered networks: </title> <booktitle> predic tions and generalizations. In Proceedings of the First International Joint Conference on Neural Networks, </booktitle> <address> Washington, DC, San Diego, </address> <year> 1989. </year> <journal> IEEE TAB Neural Network Committee. </journal> <volume> 16 </volume>
Reference-contexts: Like the approaches presented in [FI93, MKS94], it partitions a real-valued high-dimensional input space into hypercubes. The output nodes, however, represent conditional densities, which are estimated using a frequentist approach [CB90]. This is related to results reported in <ref> [TLS89, Mac92, Mit97] </ref>, which show that under appropriate assumptions, artificial neural networks approximate conditional probability density functions. The mathematical approach for integrating information is adopted from the statistical literature [CB90, Pea88]. The approach presented in this paper also bears close resemblance to occupancy grids [Mor88, Elf89].
References-found: 26

