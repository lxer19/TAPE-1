URL: http://csgrad.cs.vt.edu/~jxzhao/6704/project/document/sigir96revised.ps
Refering-URL: http://csgrad.cs.vt.edu/~jxzhao/6704/project/document/index.html
Root-URL: http://www.cs.vt.edu
Email: kraaij@tpd.tno.nl  Ren ee Pohlmann Renee.C.Pohlmann@let.ruu.nl  
Title: Viewing Stemming as Recall Enhancement  
Author: Wessel Kraaij 
Address: The Netherlands  The Netherlands  
Affiliation: Institute of Applied Physics Netherlands Organisation for Applied Scientific Research (TNO) Delft  Research Institute for Language and Speech (OTS/STT) Utrecht University Utrecht  
Abstract: Previous research on stemming has shown both positive and negative effects on retrieval performance. This paper describes an experiment in which several linguistic and non-linguistic stemmers are evaluated on a Dutch test collection. Experiments especially focus on the measurement of Recall. Results show that linguistic stemming restricted to inflection yields a significant improvement over full linguistic and non-linguistic stemming, both in average Precision and R-Recall. Best results are obtained with a linguistic stemmer which is enhanced with compound analysis. This version has a significantly better Recall than a system without stemming, without a significant deterioration of Precision. 
Abstract-found: 1
Intro-found: 1
Reference: [Aalbersberg et al., 1991] <author> Aalbersberg, Y. J., Brandsma, E., & Corthout, M. </author> <year> (1991). </year> <title> Full text document retrieval: from theory to applications. </title> <booktitle> Informatiewetenschap 1991, </booktitle> <address> Wetenschappelijke bijdragen aan de eerste STINFON-Conferentie. </address>
Reference-contexts: will continue with a discussion of a number of other key issues in the design and setup of our evaluation experiment: the test collection, evaluation measures and statistical validation. 3.1 System variants The retrieval engine used in the UPLIFT project is the TRU vector space engine developed by Philips Research <ref> [Aalbersberg et al., 1991] </ref>. A plain version of this system (i.e. without a stemming algorithm) was used as a baseline for our experiment. We started with the development of suffix stripping algorithm for Dutch based on the Porter algorithm.
Reference: [Baayen et al., 1993] <editor> Baayen, R. H., Piepenbrock, R., & van Rijn, H., editors (1993). </editor> <title> The CELEX Lexical Database (CD-ROM). Linguistic Data Consortium, </title> <institution> University of Pennsylvania, </institution> <address> Phil-adelphia (PA). </address>
Reference-contexts: Our version of the algorithm closely resembles its English original and consists of 98 rules which fully cover Dutch regular inflectional morphology and partly cover derivational morphology 7 We subsequently developed two linguistic stemmers (inflectional and derivational) using a computer readable dictionary, the CELEX lexical database <ref> [Baayen et al., 1993] </ref>. Using CELEX, two separate files were created which relate stems to their inflectional and derivational forms respectively. To avoid unnecessary overhead, not all possible forms were included in these files but only those forms which actually occurred in our test collection.
Reference: [Harman, 1991] <author> Harman, D. </author> <year> (1991). </year> <title> How effective is suffixing? Journal of the American Society for Information Science, </title> <publisher> 42(1),7-15. </publisher>
Reference-contexts: Instead of creating separate indexes for each stemming variant, we used a method which was also used by Harman in her evaluation experiment <ref> [Harman, 1991] </ref>. Before the actual execution of a query by the retrieval engine, query terms are `expanded' with related terms using the dictionary files.
Reference: [Harman, 1993a] <author> Harman, D., </author> <title> editor (1993a). </title> <booktitle> The First Text REtrieval Conference (TREC-1). </booktitle> <institution> National Institute for Standards and Technology. </institution> <note> Special Publication 500-207. </note>
Reference-contexts: He subsequently adapts these measures to normalize for query variance by averaging over within-query rank or score. Using these measures, he evaluates the performance of five different stemming algorithms (removes, Lovins, Porter, Xerox inflectional stemmer, Xerox derivational stemmer) using the TREC test collection <ref> [Harman, 1993a, 1994, 1995] </ref> . Statistical tests are applied and detailed, per-query analysis is carried out to identify probable causes for differences between stemmers.
Reference: [Harman, 1993b] <author> Harman, D. </author> <year> (1993b). </year> <title> Overview of the first text retrieval conference (TREC-1). </title> <booktitle> In The First Text REtrieval Conference (TREC-1), </booktitle> <pages> pp. 1-20. </pages> <institution> National Institute for Standards and Technology. </institution> <note> Special Publication 500-207. </note>
Reference-contexts: This last number is difficult to estimate for large databases, without doing relevance assessments for nearly the complete database [Tague, 1981]. For our experiment, we decided to use the 'Pooling method' which is also employed in TREC cf. <ref> [Harman, 1993b] </ref>. This method computes relative Recall values instead of absolute Recall. The method is based on the assumption that if one has a 'pool' of diverse IR systems, the probability that a relevant document will be retrieved by one of the systems is high.
Reference: [Harman, 1994] <author> Harman, D., </author> <title> editor (1994). </title> <booktitle> The Second Text REtrieval Conference (TREC-2). </booktitle> <institution> National Institute for Standards and Technology. </institution> <note> Special Publication 500-215. </note>
Reference: [Harman, 1995] <author> Harman, D., </author> <title> editor (1995). Overview of the Third Text REtrieval Conference (TREC-3). </title> <institution> National Institute for Standards and Technology. </institution> <note> Special Publication 500-225. </note>
Reference: [Hull, 1993] <author> Hull, D. </author> <year> (1993). </year> <title> Using statistical testing in the evaluation of retrieval experiments. </title> <booktitle> In Proceedings of ACM-SIGIR93, </booktitle> <pages> pp. 329-338. </pages>
Reference: [Hull, 1996] <author> Hull, D. </author> <year> (1996). </year> <title> Stemming algorithms a case study for detailed evaluation. </title> <journal> Journal of the American Society for Information Science, </journal> <volume> 47(1). </volume>
Reference-contexts: Furthermore, recent research <ref> [Hull, 1996] </ref> seems to indicate that a more detailed evaluation of stemming algorithms, focusing on Recall, does reveal significant improvement, even for English. <p> R-Recall Since the evaluation measures mentioned above focus on Precision values and stemming is mainly a Recall enhancement technique, we have also experimented with various Recall measures. Like Hull <ref> [Hull, 1996] </ref>, we started with measuring Recall at fixed document cutoff points (25,50,75,100,200,500 and 1000). A disadvantage of this method is that Recall at 25 does not seem to make much sense for queries with many relevant documents.
Reference: [Kraaij & Pohlmann, 1994] <author> Kraaij, W., & Pohlmann, R. </author> <year> (1994). </year> <title> Porter's stemming algorithm for Dutch. </title> <editor> In Noordman, L., & de Vroomen, W., editors, </editor> <booktitle> Informatiewetenschap 1994: Wetenschappelijke bijdragen aan de derde STINFON Confer-entie, </booktitle> <pages> pp. 167-180. </pages>
Reference-contexts: The use of syntactic information will be the subject of the next phase of our project. 7 For a more detailed description of the Dutch Porter algorithm we refer to <ref> [Kraaij & Pohlmann, 1994] </ref>. morphological variants of the same concept are treated as independ-ent base vectors. Harman corrected for this defect by modifying the similarity computation procedure: document frequencies for morphological variants of the same term are `grouped'.
Reference: [Kraaij & Pohlmann, 1996] <author> Kraaij, W., & Pohlmann, R. </author> <year> (1996). </year> <title> Using linguistic knowledge in information retrieval. </title> <note> OTS Working Paper OTS-WP-CL-96-001, </note> <institution> Research Institute for Language and Speech (OTS), Utrecht University. </institution>
Reference-contexts: The results of these experiments will not be reported here. For details on these experiments and for an in-depth description of the stemming experiment we refer to <ref> [Kraaij & Pohlmann, 1996] </ref>. The use of syntactic information will be the subject of the next phase of our project. 7 For a more detailed description of the Dutch Porter algorithm we refer to [Kraaij & Pohlmann, 1994]. morphological variants of the same concept are treated as independ-ent base vectors. <p> Besides Porter- and CELEX-based versions the pool also included versions with synonym expansion. For more details, the reader is referred to <ref> [Kraaij & Pohlmann, 1996] </ref>. order of the complete database which is generally cut off at a fixed number. In principle it is possible to compute Precision/Recall data at each point in a document ranking resulting in a Precision/Recall graph. A problem arises when a rank contains more than one document. <p> For details on these versions the reader is referred to <ref> [Kraaij & Pohlmann, 1996] </ref>. n c1f c1 c2 c4 sf porter 20% 13% 9% 8% 5% 40% 6% Table 1: Distribution of successful query terms over versions A more detailed investigation of the successful query terms revealed that the 'best' term for a particular query (i.e. the term that retrieves the
Reference: [Krovetz, 1993] <author> Krovetz, R. </author> <year> (1993). </year> <title> Viewing morphology as an inference process. </title> <booktitle> In Proceedings of ACM-SIGIR93, </booktitle> <pages> pp. 191-203. </pages>
Reference-contexts: Based on an evaluation experiment with several different suffix-stripping algorithms, Harman [1991] concluded that suffix stripping does not improve retrieval effectiveness, at least not for English. Other researchers, however, have reported favourable results using more linguistically motivated stemming algorithms for English <ref> [Krovetz, 1993] </ref> or morphologically more complex lan This paper is a slightly revised version of the paper which is to appear in the proceedings of SIGIR96 guages like Slovene [Popovi c & Willett, 1992].
Reference: [Lovins, 1968] <author> Lovins, J. B. </author> <year> (1968). </year> <title> Development of a stemming algorithm. Mechanical Translation and Computational Linguistics, </title> <publisher> 11,22-31. </publisher>
Reference-contexts: Several different techniques have been proposed to achieve this goal. One of the simplest techniques, suffix stripping, uses a list of frequent suffixes to reduce words to their base form or 'stem' e.g. <ref> [Lovins, 1968] </ref>, [Porter, 1980]. Based on an evaluation experiment with several different suffix-stripping algorithms, Harman [1991] concluded that suffix stripping does not improve retrieval effectiveness, at least not for English. <p> We will discuss some representative results here. Harman [1991] compared three well-known suffixing algorithms for English: the S-stemmer, the Lovins stemmer <ref> [Lovins, 1968] </ref> and the Porter stemmer [Porter, 1980]. Harman contrasted these suffixing algorithms with a baseline of no stemming at all. After a detailed evaluation 2 , Harman reached the conclusion that none of the stemming algorithms consistently improve performance.
Reference: [Popovi c & Willett, 1992] <author> Popovi c, M., & Willett, P. </author> <year> (1992). </year> <title> The effectiveness of stemming for natural-language access to Slovene textual data. </title> <journal> Journal of the American Society for Information Science, 43(5),384-390. </journal>
Reference-contexts: Other researchers, however, have reported favourable results using more linguistically motivated stemming algorithms for English [Krovetz, 1993] or morphologically more complex lan This paper is a slightly revised version of the paper which is to appear in the proceedings of SIGIR96 guages like Slovene <ref> [Popovi c & Willett, 1992] </ref>. Furthermore, recent research [Hull, 1996] seems to indicate that a more detailed evaluation of stemming algorithms, focusing on Recall, does reveal significant improvement, even for English.
Reference: [Porter, 1980] <author> Porter, M. F. </author> <year> (1980). </year> <title> An algorithm for suffix stripping. Program, </title> <publisher> 14(3),130-137. </publisher>
Reference-contexts: Several different techniques have been proposed to achieve this goal. One of the simplest techniques, suffix stripping, uses a list of frequent suffixes to reduce words to their base form or 'stem' e.g. [Lovins, 1968], <ref> [Porter, 1980] </ref>. Based on an evaluation experiment with several different suffix-stripping algorithms, Harman [1991] concluded that suffix stripping does not improve retrieval effectiveness, at least not for English. <p> We will discuss some representative results here. Harman [1991] compared three well-known suffixing algorithms for English: the S-stemmer, the Lovins stemmer [Lovins, 1968] and the Porter stemmer <ref> [Porter, 1980] </ref>. Harman contrasted these suffixing algorithms with a baseline of no stemming at all. After a detailed evaluation 2 , Harman reached the conclusion that none of the stemming algorithms consistently improve performance.
Reference: [Salton, 1989] <author> Salton, G. </author> <year> (1989). </year> <title> Automatic Text Processing The Transformation, Analysis, and Retrieval of Information by Computer. </title> <publisher> Addison-Wesley Publishing Company, </publisher> <address> Reading (MA). </address>
Reference-contexts: The expansion method has one drawback though. The Vector Space Model (VSM) relies on the assumption that the n concepts (i.e. index terms) spanning up an n-dimensional vector space are uncorrelated <ref> [Salton, 1989] </ref>. This simplification reduces the query-document similarity computation to the inner product of their corresponding term vectors. The query expansion method, however, is a less optimal approximation of this assumption because 6 Besides this experiment we have also investigated the use of synonyms in retrieval.
Reference: [Salton & McGill, 1983] <author> Salton, G., & McGill, M. </author> <year> (1983). </year> <title> Introduction to Modern Information Retrieval. </title> <publisher> McGraw-Hill Book Co., </publisher> <address> New York. </address>
Reference: [Tague, 1981] <author> Tague, J. M. </author> <year> (1981). </year> <title> The pragmatics of information retrieval experimentation. </title> <editor> In Sparck Jones, K., editor, </editor> <booktitle> Information Retrieval Experiment, </booktitle> <pages> pp. 59-102. </pages> <publisher> Butterworths. </publisher>
Reference-contexts: This last number is difficult to estimate for large databases, without doing relevance assessments for nearly the complete database <ref> [Tague, 1981] </ref>. For our experiment, we decided to use the 'Pooling method' which is also employed in TREC cf. [Harman, 1993b]. This method computes relative Recall values instead of absolute Recall.
Reference: [Tague-Sutcliffe, 1995a] <author> Tague-Sutcliffe, J. </author> <year> (1995a). </year> <title> Measuring Information, An Information Services Perspective. </title> <publisher> Academic Press, </publisher> <address> San Diego (CA). </address>
Reference-contexts: If not, arcsine transformations can be tried or non-parametric tests like the Sign test or Friedman test can be applied. We have set up an experimental design and analysis method along the lines of [Tague-Sutcliffe, 1995b] and <ref> [Tague-Sutcliffe, 1995a] </ref>. The chosen design is a repeated measures single factor design, sometimes also referred to as randomized block design.
Reference: [Tague-Sutcliffe, 1995b] <author> Tague-Sutcliffe, J. </author> <year> (1995b). </year> <title> A statistical analysis of the TREC-3 data. </title> <booktitle> In Overview of the Third Text REtrieval Conference (TREC-3), </booktitle> <pages> pp. 385-398. </pages> <institution> National Institute for Standards and Technology. </institution> <note> Special Publication 500-225. </note>
Reference-contexts: However, the interpolation approach has a number of drawbacks, especially when a certain query yields only a small amount of relevant documents. We have therefore also used a second measure: average Precision, from the collection of measures assessed in TREC3 <ref> [Tague-Sutcliffe, 1995b] </ref>. The average Precision for a certain query and a certain system version is computed by averaging all Precision values at relevant document positions in the relevance ranking. <p> If not, arcsine transformations can be tried or non-parametric tests like the Sign test or Friedman test can be applied. We have set up an experimental design and analysis method along the lines of <ref> [Tague-Sutcliffe, 1995b] </ref> and [Tague-Sutcliffe, 1995a]. The chosen design is a repeated measures single factor design, sometimes also referred to as randomized block design.
Reference: [Vosse, 1994] <author> Vosse, T. G. </author> <year> (1994). </year> <title> The Word Connection. </title> <type> PhD thesis, </type> <institution> Rijksuniversiteit Leiden, Neslia Paniculata Uitgeverij, Enschede. </institution> <month> 9 </month>
Reference-contexts: To handle this problem, some stemmer versions were extended with a compound analyser, the `word splitter' developed by Theo Vosse for the CORRie (grammar checker) project <ref> [Vosse, 1994] </ref>. The word splitter will try to split a compound into its components (stems) on the basis of word combination rules for Dutch and a lexicon. If the splitter is unsuccessful, the word is left unchanged.
References-found: 21

