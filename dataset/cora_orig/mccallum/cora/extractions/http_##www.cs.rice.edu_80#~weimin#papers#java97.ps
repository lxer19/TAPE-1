URL: http://www.cs.rice.edu:80/~weimin/papers/java97.ps
Refering-URL: http://www.cs.rice.edu:80/~weimin/
Root-URL: 
Email: fweimin, alcg@cs.rice.edu  
Title: Java/DSM: A Platform for Heterogeneous Computing  
Author: Weimin Yu and Alan Cox 
Date: July 31, 1997  
Address: Houston, TX 77251  
Affiliation: Department of Computer Science Rice University  
Abstract: In this paper we describe a system for programming heterogeneous computing environments based upon Java and software Distributed Shared Memory (DSM). Compared with existing approaches for heterogeneous computing, our system transparently handles both the hardware differences and the distributed nature of the system. It is therefore much easier to program. Java is a good candidate for heterogeneous programming because of its portability. Java provides the Remote Method Invocation (RM I) mechanism for distributed computing. However, our early experience with RMI showed that the programmer must spend significant effort on such problems as data replication and the optimization of the remote interface to improve communication efficiency. Furthermore, the need for reference marshaling is not completely eliminated by RMI's effort to facilitate the sharing of linked structures between machines. A DSM system provides a shared memory abstraction over a group of physically distributed machines. It automatically handles data communication between machines and eliminates the need for the programmer to write message-passing code. A multithreaded Java program written for a single machine will require fewer changes to run on a Java/DSM combination than with RMI. We have been implementing a JDK-1.0.2 based parallel Java Virtual Machine on the Tread-Marks DSM system. Our implementation includes a distributed garbage collector and supports the Java API with very few changes. In this paper we will describe our motivation and the implementation, and report our early experience with programming under both RMI and DSM. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D. I. Bevan. </author> <title> Distributed garbage collection using reference counting. In Parallel Arch. and Lang. </title> <booktitle> Europe, </booktitle> <pages> pages 117-187, </pages> <address> Eindhoven, The Netherlands, </address> <month> June </month> <year> 1987. </year> <note> Spring-Verlag Lecture Notes in Computer Science 259. </note>
Reference-contexts: During each garbage collection, the export list is treated as part of the root set of references, and there is no need to communicate with remote machines. Imported references that are not marked will be sent back to their owners. The owner uses weighted reference counting <ref> [10, 11, 1] </ref> to decide when a reference can be removed from the export list.
Reference: [2] <author> A.D. Birrell and B.J. Nelson. </author> <title> Implementing remote procedure calls. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 2(1) </volume> <pages> 39-59, </pages> <month> February </month> <year> 1984. </year>
Reference-contexts: It is up to the programmer to marshal them into a message and reconstruct the data structure on the remote machine. 2.3.2 Remote Procedure Call In the Remote Procedure Call (RPC) <ref> [2] </ref> model, servers export interfaces, making a specific set of operations available to clients that bind to the corresponding interface. Clients then invoke these server operations by making RPCs. To the client, the RPC is supposed to look like a normal procedure call.
Reference: [3] <author> R. Bisiani and A. Forin. </author> <title> Multilanguage parallel programming of heterogeneous machines. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 37(8), </volume> <month> August </month> <year> 1988. </year>
Reference-contexts: Furthermore, since pointers are usually meaningless across machine boundaries, the sharing of complex data structures usually requires first marshaling them into a byte stream, then reconstructing them on the remote machine. 2.2 Heterogeneous DSM Systems Several heterogeneous DSM systems have been designed in the past, including Mermaid [13] and Agora <ref> [3] </ref>. We take Mermaid as an example. Mermaid is implemented on the IVY DSM system and supports the C language. Because of the shared memory abstraction Mermaid provides, the distributed nature is hidden from the programmer.
Reference: [4] <author> G.A. Geist and V.S. Sunderam. </author> <title> Network-based concurrent computing on the PVM system. </title> <journal> Concurrency: Practice and Experience, </journal> <pages> pages 293-311, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: Message passing based platforms include message passing libraries and Remote Procedure Call (RP C). 2.3.1 Message Passing Libraries Message passing libraries such as PVM <ref> [4] </ref>, TCGMSG [5] and Express [9] have long been in use. A message passing standard MPI [8] has also been developed. PVM provides basic primitives such as send () and receive () as well as routines to convert basic data items between native formats and a standard format.
Reference: [5] <author> R.J. Harrison. </author> <title> Portable tools and applications for parallel computers. </title> <journal> In International Journal of Quantum Chemistry, </journal> <volume> volume 40, </volume> <pages> pages 847-863, </pages> <month> February </month> <year> 1990. </year>
Reference-contexts: Message passing based platforms include message passing libraries and Remote Procedure Call (RP C). 2.3.1 Message Passing Libraries Message passing libraries such as PVM [4], TCGMSG <ref> [5] </ref> and Express [9] have long been in use. A message passing standard MPI [8] has also been developed. PVM provides basic primitives such as send () and receive () as well as routines to convert basic data items between native formats and a standard format.
Reference: [6] <author> P. Keleher, S. Dwarkadas, A.L. Cox, and W. Zwaenepoel. Treadmarks: </author> <title> Distributed shared memory on standard workstations and operating systems. </title> <booktitle> In Proceedings of the 1994 Winter Usenix Conference, </booktitle> <pages> pages 115-131, </pages> <month> January </month> <year> 1994. </year>
Reference-contexts: With the coming of Java we have seen people who have never written a distributed application starting to do so. We believe it is highly desirable to provide them with a simpler programming platform. We are implementing a JDK-1.0.2 based parallel Java Virtual Machine on the TreadMarks DSM system <ref> [6] </ref>. Our implementation includes a distributed garbage collector and supports the Java API with very few changes. To program our our implementation is very much like writing a multi-threaded Java program on a single processor.
Reference: [7] <author> K. Li and P. Hudak. </author> <title> Memory coherence in shared virtual memory systems. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 7(4) </volume> <pages> 321-359, </pages> <month> November </month> <year> 1989. </year>
Reference-contexts: A DSM system handles the communication of data between machines, eliminating the need for the programmer to write message-passing code. Roughly speaking, a DSM system enables processes on different machines to share virtual memory, even though no physical memory is shared by the machines <ref> [7] </ref>. It is widely accepted that it is easier to program with shared memory than message passing: Instead of sending and receiving messages explicitly, programs can use ordinary loads and stores to access shared data.
Reference: [8] <author> Message Passing Interface Forum. </author> <title> MPI: A message-passing interface standard, </title> <note> version 1.0, </note> <month> May </month> <year> 1994. </year>
Reference-contexts: Message passing based platforms include message passing libraries and Remote Procedure Call (RP C). 2.3.1 Message Passing Libraries Message passing libraries such as PVM [4], TCGMSG [5] and Express [9] have long been in use. A message passing standard MPI <ref> [8] </ref> has also been developed. PVM provides basic primitives such as send () and receive () as well as routines to convert basic data items between native formats and a standard format.
Reference: [9] <institution> Parasoft Corporation, Pasadena, CA. </institution> <note> Express user's guide, version 3.2.5, </note> <year> 1992. </year>
Reference-contexts: Message passing based platforms include message passing libraries and Remote Procedure Call (RP C). 2.3.1 Message Passing Libraries Message passing libraries such as PVM [4], TCGMSG [5] and Express <ref> [9] </ref> have long been in use. A message passing standard MPI [8] has also been developed. PVM provides basic primitives such as send () and receive () as well as routines to convert basic data items between native formats and a standard format.
Reference: [10] <author> R. Thomas. </author> <title> A dataflow computer with improved asymptotic performance. </title> <type> Technical Report TR-265, </type> <institution> MIT Laboratory for Computer Science, </institution> <year> 1981. </year>
Reference-contexts: During each garbage collection, the export list is treated as part of the root set of references, and there is no need to communicate with remote machines. Imported references that are not marked will be sent back to their owners. The owner uses weighted reference counting <ref> [10, 11, 1] </ref> to decide when a reference can be removed from the export list.
Reference: [11] <author> P. Watson and I. Watson. </author> <title> An efficient garbage collection scheme for parallel computer architectures. </title> <booktitle> In PARLE'87|Parallel Architectures and Languages Europe, number 259 in Lecture Notes in Computer Science, </booktitle> <address> Eindhoven (the Netherlands), June 1987. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: During each garbage collection, the export list is treated as part of the root set of references, and there is no need to communicate with remote machines. Imported references that are not marked will be sent back to their owners. The owner uses weighted reference counting <ref> [10, 11, 1] </ref> to decide when a reference can be removed from the export list.
Reference: [12] <author> Weimin Yu and Alan Cox. </author> <title> Conservative garbage collection on distributed shared memory systems. </title> <booktitle> In Proceedings of the 16th International Conference on Distributed Computing Systems, </booktitle> <year> 1996. </year>
Reference-contexts: Here we give a brief introduction to our garbage collection algorithm. A detailed description can be found in <ref> [12] </ref>. The garbage collector on each machine maintains two lists: the export list, which contains remote references to locally created objects; and the import list, which contains references to remote objects. These two lists are not accurate. They are a conservative estimate of the real cross-machine reference set.
Reference: [13] <author> S. Zhou, M. Stumm, K. Li, and D. Wortman. </author> <title> Heterogeneous distributed shared memory. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 3(5), </volume> <month> September </month> <year> 1992. </year>
Reference-contexts: Furthermore, since pointers are usually meaningless across machine boundaries, the sharing of complex data structures usually requires first marshaling them into a byte stream, then reconstructing them on the remote machine. 2.2 Heterogeneous DSM Systems Several heterogeneous DSM systems have been designed in the past, including Mermaid <ref> [13] </ref> and Agora [3]. We take Mermaid as an example. Mermaid is implemented on the IVY DSM system and supports the C language. Because of the shared memory abstraction Mermaid provides, the distributed nature is hidden from the programmer.
References-found: 13

