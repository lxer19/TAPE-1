URL: ftp://ftp.cs.unimaas.nl/pub/papers/postma/jann95.ps.gz
Refering-URL: http://www.cs.unimaas.nl/~postma/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Activity-Conserving Dynamics for Optimisation Networks  
Author: Eric O. Postma H. Jaap van den Herik Patrick T.W. Hudson 
Address: Netherlands  
Affiliation: Department of Computer Science University of Limburg, Maastricht, The  
Abstract: A novel type of dynamics conserving activity in neural networks is presented. We distinguish stochastic and deterministic activity-conserving dynamics. As an example, deterministic (mean-field) activity-conserving dynamics is applied to the N-queens problem. The new dynamics are more succesful in finding valid solutions than the standard dynamics. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R.J. </author> <title> Glauber. Time-dependent statistics of the Ising model. </title> <journal> Journal of Physics, </journal> <volume> 4: </volume> <pages> 294-307, </pages> <year> 1963. </year>
Reference-contexts: In their optimi-sation network for solving the TSP problem, Hopfield and Tank [2] incorporated the following conservation term E c in the energy function: E c (a) = 2 X X a cs A ; (1) where a is the activation vector with elements a cs 2 <ref> [0; 1] </ref> (c; s 2 f1; 2; :::; Ag). An active neuron, a cs = 1, represents the assignment of city c to stop s. The positive parameter ff weights the conservation constraint relative to other constraints. 0 The authors thank Jos Uiterwijk for his help and discussions. <p> The results obtained with deterministic AC dynamics are succesfully compared with the results of standard dynamics as re ported in the literature. Finally, Section 5 concludes on dynamics and complexity. 2 STOCHASTIC ACTIVITY-CONSERVING DYNAMICS In stochastic Glauber updating <ref> [1] </ref>, a neuron's state is flipped (from 0 to 1 or vice versa) with a probability proportional to the associated decrease in energy. <p> In our case, the continuous variable a i is defined as a i = hn i i, where the brackets represent the average over time. For a standard neural network (e.g., [3]) with activation variables a i 2 <ref> [0; 1] </ref> and weights w ij = w ji and w ii = 0, for all i; j 2 K, mean-field AC dynamics are defined as (cf. [6]): d a i = 2 j 4 (2a i a j + a i + a j ) tanh 0 1 X (w
Reference: [2] <author> J.J. Hopfield and D.W. Tank. </author> <title> "Neural" computation of decisions in optimization problems. </title> <journal> Biological Cybernetics, </journal> <volume> 52: </volume> <pages> 141-152, </pages> <year> 1985. </year>
Reference-contexts: In optimi-sation neural networks, assignments may be represented by active neurons, so that conservation constraints translate into conservation of activation. In their optimi-sation network for solving the TSP problem, Hopfield and Tank <ref> [2] </ref> incorporated the following conservation term E c in the energy function: E c (a) = 2 X X a cs A ; (1) where a is the activation vector with elements a cs 2 [0; 1] (c; s 2 f1; 2; :::; Ag).
Reference: [3] <author> J.J. </author> <title> Hopfield. Neurons with graded response have collective computational properties like those of a two-state neuron. </title> <booktitle> Proceedings of the National Academy of Sciences, U.S.A., </booktitle> <volume> 81: </volume> <pages> 3088-3092, </pages> <year> 1984. </year>
Reference-contexts: The stochastic dynamics may be combined with simulated annealing [5] in order to solve optimisation problems. In applying this combination to a molecular-configuration problem, we obtained results competitive with traditional algorithmic approaches [8]. Analogous to the mean-field formulation of Glauber neural-network dynamics <ref> [3] </ref>, below we present a mean-field formulation of Kawasaki dynamics in neural networks. 3 DETERMINISTIC ACTIVITY-CONSERVING DYNAMICS Mean-field Kawasaki dynamics were derived by Penrose [6] in the context of mod-elling the dynamics of Ising spins. <p> In our case, the continuous variable a i is defined as a i = hn i i, where the brackets represent the average over time. For a standard neural network (e.g., <ref> [3] </ref>) with activation variables a i 2 [0; 1] and weights w ij = w ji and w ii = 0, for all i; j 2 K, mean-field AC dynamics are defined as (cf. [6]): d a i = 2 j 4 (2a i a j + a i + a
Reference: [4] <author> K. Kawasaki. </author> <title> Kinetics of Ising models. </title> <editor> In C. Domb and M.S. Green, editors, </editor> <title> Phase transitions and critical phenomena, </title> <booktitle> Volume 2, </booktitle> <pages> pages 443-501. </pages> <publisher> Academic Press, </publisher> <address> London, </address> <year> 1972. </year>
Reference-contexts: We present an alternative strong-enforcement method that does not suffer from such a limitation. Central to our method is the use of activity-conserving (AC) dynamics based on Kawasaki's updating scheme from statistical mechanics <ref> [4] </ref>. Under AC dynamics only transitions that leave the total activity in the network invariant are allowed. While the initial state of the network fixes the activity, our method allows for strong enforcement of the conservation constraint for any possible value of the total activity. <p> More specifically, given two neurons, i and j, one active and the other inactive, their states are exchanged with probability (cf. <ref> [4] </ref>) P (n i $ n j ) = 2 tanh T + 1 : (3) In this equation, n i 2 f0; 1g is the binary state variable of neuron i; and E (n i $ n j ) is the change in energy associated with the exchange of the
Reference: [5] <author> S. Kirkpatrick, C.D. Gelatt Jr., </author> <title> and M.P. Vecchi. Optimization by simulated annealing. </title> <journal> Science, </journal> <volume> 220: </volume> <pages> 671-680, </pages> <year> 1983. </year>
Reference-contexts: T is the temperature parameter (T &gt; 0). The stochastic dynamics may be combined with simulated annealing <ref> [5] </ref> in order to solve optimisation problems. In applying this combination to a molecular-configuration problem, we obtained results competitive with traditional algorithmic approaches [8].
Reference: [6] <author> O. Penrose. </author> <title> A mean-field equation of motion for the dynamic Ising model. </title> <journal> Journal of Statistical Physics, </journal> <volume> 63: </volume> <pages> 975-986, </pages> <year> 1991. </year>
Reference-contexts: Analogous to the mean-field formulation of Glauber neural-network dynamics [3], below we present a mean-field formulation of Kawasaki dynamics in neural networks. 3 DETERMINISTIC ACTIVITY-CONSERVING DYNAMICS Mean-field Kawasaki dynamics were derived by Penrose <ref> [6] </ref> in the context of mod-elling the dynamics of Ising spins. We reformulate his results in neural-network terms and then apply the mean-field equations so obtained to an optimisation task. In the mean-field approximation to stochastic dynamics, continuous activation variables are defined as the average values of stochastic variables. <p> For a standard neural network (e.g., [3]) with activation variables a i 2 [0; 1] and weights w ij = w ji and w ii = 0, for all i; j 2 K, mean-field AC dynamics are defined as (cf. <ref> [6] </ref>): d a i = 2 j 4 (2a i a j + a i + a j ) tanh 0 1 X (w ik w jk )a k A 5 : (4) For (4), Penrose formulated a Lyapunov function for the special case that all non-zero weights have the same
Reference: [7] <author> C. Peterson and B. Soderberg. </author> <title> A new method for mapping optimization problems onto neural networks. </title> <journal> International Journal of Neural Systems, </journal> <volume> 1: </volume> <pages> 3-22, </pages> <year> 1989. </year>
Reference-contexts: The conservation term (1) is meant to represent soft enforcement of the conservation constraint (cf. [10]). Network states violating the constraint are discouraged, but nevertheless possible. An alternative approach is to employ strong enforcement, i.e., only network states that obey the constraint are admitted. Peterson and Soderberg <ref> [7] </ref> defined dynamics for A-state (Potts) neurons which always satisfy the condition P A i a i = 1. <p> Consequently, the conservation term (1) is equal to zero and can be discarded from the energy function. Optimisation networks with Potts neurons have been shown to perform very well on TSP problems as well as on other problems involving a conservation constraint. Unfortunately, Peterson and Soderberg's method <ref> [7] </ref> can only be applied when the conservation constraint can be expressed as (2). We present an alternative strong-enforcement method that does not suffer from such a limitation. Central to our method is the use of activity-conserving (AC) dynamics based on Kawasaki's updating scheme from statistical mechanics [4].
Reference: [8] <author> E.O. Postma, H.J. Van den Herik, and P.T.W. Hudson. </author> <title> Activity-conserving dynamics for neural networks. </title> <editor> In S. Gielen and B. Kappen, editors, </editor> <booktitle> Proceedings of the International Conference on Artificial Neural Networks, </booktitle> <pages> ICANN'93 pages 539-544. </pages> <publisher> Springer-Verlag, </publisher> <address> London, </address> <year> 1993. </year>
Reference-contexts: T is the temperature parameter (T &gt; 0). The stochastic dynamics may be combined with simulated annealing [5] in order to solve optimisation problems. In applying this combination to a molecular-configuration problem, we obtained results competitive with traditional algorithmic approaches <ref> [8] </ref>. Analogous to the mean-field formulation of Glauber neural-network dynamics [3], below we present a mean-field formulation of Kawasaki dynamics in neural networks. 3 DETERMINISTIC ACTIVITY-CONSERVING DYNAMICS Mean-field Kawasaki dynamics were derived by Penrose [6] in the context of mod-elling the dynamics of Ising spins.
Reference: [9] <author> O. Shagrir. </author> <title> A neural net with self-inhibiting units for the N-queens problem. </title> <journal> International Journal of Neural Systems, </journal> <volume> 3: </volume> <pages> 249-252, </pages> <year> 1992. </year>
Reference-contexts: Below, we evaluate our deterministic AC dynamics using the N-queens problem. 4 APPLICATION TO THE N-QUEENS PROBLEM The N-queens problem entails the placement of N queens on an N fi N chess-board in a way that no two queens are placed on the same row, column, or diagonal. Shagrir <ref> [9] </ref> formulated the N -queens energy function E (a) = xy @ i6=x X a xy a xj + m6=0 X a xy a x+m;ym A xy ! 2 where a xy is the activation of the neuron at position (x; y) on the N fi N chessboard (x; y; i; <p> In table 1, the results are listed together with results obtained by standard deterministic dynamics in a Hopfield and Tank network (taken from <ref> [9] </ref>). (The total number of solutions is also listed. For N = 6, it can be seen that the performance drops because there are relatively few valid solutions.) It is observed that AC dynamics are more succesful in finding valid solutions than the standard dynamics.
Reference: [10] <author> P.D. Simic. </author> <title> Statistical mechanics as the underlying theory of `elastic' and `neural' optimisation. </title> <journal> Network, </journal> <volume> 1: </volume> <pages> 89-103, </pages> <year> 1990. </year>
Reference-contexts: Email: postma@cs.rulimburg.nl. 1 Minimisation of the conservation term leads to a network state in which the total activity ( P P s a cs ) is equal to A. The conservation term (1) is meant to represent soft enforcement of the conservation constraint (cf. <ref> [10] </ref>). Network states violating the constraint are discouraged, but nevertheless possible. An alternative approach is to employ strong enforcement, i.e., only network states that obey the constraint are admitted.
References-found: 10

