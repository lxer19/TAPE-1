URL: http://www.cs.colorado.edu/homes/cai/public_html/papers/ogd.ps.gz
Refering-URL: http://www.cs.colorado.edu/homes/cai/public_html/mypapers.html
Root-URL: http://www.cs.colorado.edu
Title: OVERLAPPING DOMAIN DECOMPOSITION ALGORITHMS FOR GENERAL SPARSE MATRICES  
Author: XIAO-CHUAN CAI AND YOUCEF SAAD 
Keyword: Key words. Sparse matrix, iterative methods, preconditioning, graph partitioning, domain decomposition.  
Abstract: Domain decomposition methods for Finite Element problems using a partition based on the underlying finite element mesh have been extensively studied. In this paper, we discuss algebraic extensions of the class of overlapping domain decomposition algorithms for general sparse matrices. The subproblems are created with an overlapping partition of the graph corresponding to the sparsity structure of the matrix. These algebraic domain decomposition methods are especially useful for unstructured mesh problems. We also discuss some difficulties encountered in the algebraic extension, particularly the issues related to the coarse solver. 1. Introduction. The aim of this paper is to develop parallel preconditioned iterative methods for solving general large sparse linear systems that arise from the dis-cretization of partial differential equations, more particularly on unstructured meshes. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> L. Adams and J. Ortega, </author> <title> A multi-color SOR method for parallel computers, </title> <booktitle> Proceedings of Int. Conf. Par. Proc., </booktitle> <year> 1982. </year> <pages> pp. 53-56. </pages>
Reference-contexts: Other preconditioned iterative methods can also be used to solve this class of sparse systems and the interested reader should refer to <ref> [1, 6, 13] </ref> for further references. In the practical implementation of the algebraic Schwarz algorithms, a crucial step resides in the non-numerical preprocessing of the problem, e.g., graph partitioning, graph coloring, etc..
Reference: [2] <author> X.- C. Cai, W. D. Gropp and D. E. Keyes, </author> <title> A comparison of some domain decomposition algorithms for nonsymmetric elliptic problems, </title> <journal> J. Numer. Lin. Alg. Appl. </journal> <year> 1993. </year>
Reference-contexts: There are quite a few different ways to construct preconditioners with the operators T i , see for example <ref> [2] </ref>. For simplicity, we discuss only the additive and the multiplicative Schwarz algorithms. <p> Both algorithms discussed above are one-level algorithms and the convergence rates deteriorate, linearly in the number of T i s, as the number of subdomains increases. A coarse solver is usually included to prevent the loss of optimal convergence. We refer to <ref> [2, 3, 4, 5] </ref> for further discussions of this issue. 3 3. Algebraic Schwarz Algorithms. We consider a linear system of the form, Au = f (7) where A is a sparse matrix, having a symmetric pattern. <p> We note that the most popularly used ILU (0) is not a good choice for this example. 6.2. Two-level algorithms. When the matrix A is obtained from the discretiza-tion, with a mesh parameter h, of a continuous differential equation, it has been shown, in <ref> [2, 8] </ref>, that a two-level method which utilizes a coarse mesh performs considerly better than the corresponding one-level method. The coarse mesh matrix is usually obtained by using the same discretization scheme but with a much larger mesh parameter H.
Reference: [3] <author> X. -C. Cai and O. B. Widlund, </author> <title> Domain decomposition algorithms for indefinite elliptic problems, </title> <journal> SIAM J. Sci. Stat. Comp. </journal> <volume> 13 (1992), </volume> <pages> pp. 243-258. </pages>
Reference-contexts: Review of Variational Schwarz Algorithms. Before presenting the algebraic formulation of the Schwarz algorithms, we give a brief review of the classic Schwarz algorithms, including the additive and multiplicative versions. Details of the classic versions can be found in <ref> [3, 4, 5] </ref>. To illustrate the ideas of Schwarz type algorithms, we consider a homogeneous Dirichlet boundary value problem: ( u = 0 on @; where is a two- or three-dimensional domain with boundary @. <p> Both algorithms discussed above are one-level algorithms and the convergence rates deteriorate, linearly in the number of T i s, as the number of subdomains increases. A coarse solver is usually included to prevent the loss of optimal convergence. We refer to <ref> [2, 3, 4, 5] </ref> for further discussions of this issue. 3 3. Algebraic Schwarz Algorithms. We consider a linear system of the form, Au = f (7) where A is a sparse matrix, having a symmetric pattern.
Reference: [4] <author> X. -C. Cai and O. B. Widlund, </author> <title> Multiplicative Schwarz algorithms for nonsymmetric and indefinite elliptic problems, </title> <journal> SIAM J. Numer. Anal. </journal> <volume> 30 (1993), </volume> <pages> pp. 936-952. </pages>
Reference-contexts: Review of Variational Schwarz Algorithms. Before presenting the algebraic formulation of the Schwarz algorithms, we give a brief review of the classic Schwarz algorithms, including the additive and multiplicative versions. Details of the classic versions can be found in <ref> [3, 4, 5] </ref>. To illustrate the ideas of Schwarz type algorithms, we consider a homogeneous Dirichlet boundary value problem: ( u = 0 on @; where is a two- or three-dimensional domain with boundary @. <p> Both algorithms discussed above are one-level algorithms and the convergence rates deteriorate, linearly in the number of T i s, as the number of subdomains increases. A coarse solver is usually included to prevent the loss of optimal convergence. We refer to <ref> [2, 3, 4, 5] </ref> for further discussions of this issue. 3 3. Algebraic Schwarz Algorithms. We consider a linear system of the form, Au = f (7) where A is a sparse matrix, having a symmetric pattern. <p> if the multiplicative Schwarz algorithm is used as in the form of (6), then it is a purely sequential algorithm, however, if we color and regroup the subgraphs such that each is a union of several disconnected subgraphs then a great deal of parallelism can be introduced (see discussion in <ref> [4] </ref>), i.e. the subproblems defined on the disconnected subgraphs can be solved independently in parallel. Simple greedy heuristic subgraph coloring algorithms have been discussed in the literature, see for example, [13]. For the completeness of this paper, we will give a description of one such coloring algorithm in Section 5. <p> In addition, we note that the convergence rate of the multiplicative Schwarz depends inversely on the number of colors, cf <ref> [4] </ref>. As a result, minimizing the number of colors will not only increase the parallelism but it will also improve the intrinsic convergence rate. We found that the greedy coloring algorithm just mentioned does give satisfactory results in practice. <p> In the case of multiplicative Schwarz preconditioning, a symmetrization technique has to be used in order to obtain an A-self-adjoint preconditioned system, we refer to <ref> [4] </ref> for further discussions.
Reference: [5] <author> M. Dryja and O. B. Widlund, </author> <title> Towards a unified theory of domain decomposition algorithms for elliptic problems, in Third International Symposium on Domain Decomposition Methods for Partial Differential Equations, </title> <editor> T. F. Chan, R. Glowinski, J. Periaux, and O. B. Widlund, eds., </editor> <publisher> SIAM, </publisher> <address> Philadelphia (1990). </address>
Reference-contexts: We are interested in the class of overlapping Schwarz domain decomposition precon-ditioners that were previously introduced in the context of variational solution of partial differential equations; see <ref> [5] </ref> and references therein. According to the divide-and-conquer philosophy underlying the domain decomposition approach, the domain of definition of the partial differential equation is partitioned into a set of subdomains whose union is the original domain and the partial differential equations are then discretized on each of the subdomains. <p> Review of Variational Schwarz Algorithms. Before presenting the algebraic formulation of the Schwarz algorithms, we give a brief review of the classic Schwarz algorithms, including the additive and multiplicative versions. Details of the classic versions can be found in <ref> [3, 4, 5] </ref>. To illustrate the ideas of Schwarz type algorithms, we consider a homogeneous Dirichlet boundary value problem: ( u = 0 on @; where is a two- or three-dimensional domain with boundary @. <p> Here V h is a finite dimensional subspace of the Sobolev space V = H 1 0 () and a (; ) is the usual bilinear form associated with the elliptic operator L. Following the Dryja-Widlund construction of the overlapping decomposition of V h (cf. <ref> [5] </ref>), the triangulation of is introduced as follows. The region is first divided into nonoverlap ping substructures i , i = 1; ; N: Then all the substructures i , which have diameter 2 of order H, are divided into elements of size h. <p> Therefore, a good preconditioner plays an essential role in the success of any iterative methods used to solve it. For Schwarz methods, cf. Dryja and Widlund <ref> [5] </ref>, the preconditioner is constructed by solving a sequence of subdomain problems of the form: Find T i e 2 V i , such that a (T i e; v) = b (e; v); 8v 2 V i : T i e is a projection of the error onto the subspace <p> Both algorithms discussed above are one-level algorithms and the convergence rates deteriorate, linearly in the number of T i s, as the number of subdomains increases. A coarse solver is usually included to prevent the loss of optimal convergence. We refer to <ref> [2, 3, 4, 5] </ref> for further discussions of this issue. 3 3. Algebraic Schwarz Algorithms. We consider a linear system of the form, Au = f (7) where A is a sparse matrix, having a symmetric pattern. <p> This problem is successfully handled for the cases of variational Schwarz algorithms by inserting a solve with an extra coarse mesh space to the preconditioner. This allows to incorporate the needed communication between the almost decoupled local subspaces and prevents deterioration in convergence rates, see <ref> [5] </ref> for a theoretically analysis. However, for the case of general sparse matrices, defining the analogue of a `coarse 7 problem' and whether a similar cure to the deterioration of convergence rates can be achieved, are still almost entirely open issues.
Reference: [6] <author> H. C. Elman and E. Agron, </author> <title> Ordering techniques for the preconditioning conjugate gradient method on parallel computers, UMIACS-TR-88-53, </title> <type> UMIACS, </type> <institution> Univ. of Maryland, </institution> <year> 1988. </year>
Reference-contexts: Other preconditioned iterative methods can also be used to solve this class of sparse systems and the interested reader should refer to <ref> [1, 6, 13] </ref> for further references. In the practical implementation of the algebraic Schwarz algorithms, a crucial step resides in the non-numerical preprocessing of the problem, e.g., graph partitioning, graph coloring, etc..
Reference: [7] <author> R. W. Freund G. H. and N. M. Nachtigal, </author> <title> Iterative solution of linear systems, </title> <booktitle> Acta Numerica 1991, </booktitle> <pages> pp. 57-100. </pages>
Reference-contexts: In the section, we only discuss those parameters that are of interest to us currently. For a fixed preconditioner, there are also many accelerators which can be used such as GMRES [15], BiCGSTAB [16], TFQMR <ref> [7] </ref>, etc.. However, we shall restrict ourselves to the use of the restarted GMRES algorithm. We consider the following two model problems. Problem 0. We consider the Poisson equation 4 u = f with Dirichlet boundary condition on the unit square in R 2 .
Reference: [8] <author> W. Gropp and B. Smith, </author> <title> Experiences with domain decomposition in three dimensions: Overlapping Schwarz methods in Sixth International Symposium on Domain Decomposition Methods for Partial Differential Equations, </title> <editor> A. Quarteroni, et al. eds., </editor> <publisher> AMS, </publisher> <year> (1993). </year> <note> To appear. </note>
Reference-contexts: We note that the most popularly used ILU (0) is not a good choice for this example. 6.2. Two-level algorithms. When the matrix A is obtained from the discretiza-tion, with a mesh parameter h, of a continuous differential equation, it has been shown, in <ref> [2, 8] </ref>, that a two-level method which utilizes a coarse mesh performs considerly better than the corresponding one-level method. The coarse mesh matrix is usually obtained by using the same discretization scheme but with a much larger mesh parameter H.
Reference: [9] <author> W. Gropp and B. Smith, </author> <title> Simplified linear equation solvers: User's manual, </title> <institution> Mathematics and Computer Science Division, Argonne National Laboratory, </institution> <year> 1993. </year>
Reference-contexts: The testing codes used in the experiments are developed with the help of two pieces of software, namely the SPARSKIT of Saad [12] and the package PETSc of W. Gropp and B. Smith <ref> [9] </ref>. 6.1. One-level algorithms. The first suit of tests are for the additive Schwarz algorithms, see Tables 1 and 2. In these two tables, all the subdomain problems are solved exactly with Gaussian elimination.
Reference: [10] <author> J. W. H. Liu, </author> <title> A graph partitioning algorithm by node separators, </title> <journal> ACM Transactions on Mathematical Software, </journal> <volume> 15, </volume> <year> (1989), </year> <pages> pp. 198-219. </pages>
Reference-contexts: Here n is the size of the matrix. Since we assume that the non-zero pattern is symmetric the adjacency graph G is indirected. There are several algorithms described in the literature for partitioning a graph into subgraphs <ref> [10, 11, 14] </ref>. The approach described in [10] is a form of nested dissection algorithm, and the author proposes a number of strategies to find good separators. In [11] a spectral analysis of Discrete Laplacian is exploited. <p> Here n is the size of the matrix. Since we assume that the non-zero pattern is symmetric the adjacency graph G is indirected. There are several algorithms described in the literature for partitioning a graph into subgraphs [10, 11, 14]. The approach described in <ref> [10] </ref> is a form of nested dissection algorithm, and the author proposes a number of strategies to find good separators. In [11] a spectral analysis of Discrete Laplacian is exploited. In section 5 we give a brief description of a technique presented in [14].
Reference: [11] <author> A. Pothen, H. D. Simon and K.-P. Liou, </author> <title> Partitioning sparse matrices with eigenvectors of graphs, </title> <journal> SIAM J. Matrix Anal. Appl. </journal> <volume> 11 (1990), </volume> <pages> pp. 430-452. </pages>
Reference-contexts: Here n is the size of the matrix. Since we assume that the non-zero pattern is symmetric the adjacency graph G is indirected. There are several algorithms described in the literature for partitioning a graph into subgraphs <ref> [10, 11, 14] </ref>. The approach described in [10] is a form of nested dissection algorithm, and the author proposes a number of strategies to find good separators. In [11] a spectral analysis of Discrete Laplacian is exploited. <p> There are several algorithms described in the literature for partitioning a graph into subgraphs [10, 11, 14]. The approach described in [10] is a form of nested dissection algorithm, and the author proposes a number of strategies to find good separators. In <ref> [11] </ref> a spectral analysis of Discrete Laplacian is exploited. In section 5 we give a brief description of a technique presented in [14]. In summary, the algorithm consists of two phases.
Reference: [12] <author> Y. Saad, SPARSKIT: </author> <title> A basic tool kit for sparse matrix computations, </title> <type> TR 90-20, </type> <institution> Research Institute for Advanced Computer Science, NASA Ames Research Center, Moffet Field, </institution> <address> CA, </address> <year> 1990. </year>
Reference-contexts: Of course, ^ b must also be modified. 5. Tools for Graph Decomposition Methods . In this section, we discuss several useful algorithms for the graph decomposition algorithm described in the previous section. Let (a, ja, ia) be the usual Compressed Sparse Row format (CSR), see <ref> [12] </ref>, of the sparse matrix A 1 The graph G = (W; E) of A is completely determined by the two one dimensional arrays ia and ja. <p> The number of overlapping level-sets is denoted by ovlp. m 0 is the initial seed for the number of subgraphs. The testing codes used in the experiments are developed with the help of two pieces of software, namely the SPARSKIT of Saad <ref> [12] </ref> and the package PETSc of W. Gropp and B. Smith [9]. 6.1. One-level algorithms. The first suit of tests are for the additive Schwarz algorithms, see Tables 1 and 2. In these two tables, all the subdomain problems are solved exactly with Gaussian elimination.
Reference: [13] <author> Y. Saad, </author> <title> Highly parallel preconditioners for general sparse matrices, </title> <type> Preprint 92-087, </type> <institution> Army High Performance Computing Research Center, University of Minnesota, </institution> <year> 1992. </year>
Reference-contexts: Other preconditioned iterative methods can also be used to solve this class of sparse systems and the interested reader should refer to <ref> [1, 6, 13] </ref> for further references. In the practical implementation of the algebraic Schwarz algorithms, a crucial step resides in the non-numerical preprocessing of the problem, e.g., graph partitioning, graph coloring, etc.. <p> Simple greedy heuristic subgraph coloring algorithms have been discussed in the literature, see for example, <ref> [13] </ref>. For the completeness of this paper, we will give a description of one such coloring algorithm in Section 5. Let us define the matrix ^ A i as the sum of all the matrices A i that share the same color. <p> An independent set is maximal if it cannot be augmented by elements in its complement to form a larger independent set. In what follows an independent set is always meant in the sense of a maximal independent set. Algorithms for finding such sets are described in <ref> [13] </ref>. The `coarsening' algorithm can be described as follows. Algorithm 3 (Coarsening algorithm:). Start: Select a threshold number nodes n w . Set ^ W = W; ^ E = E. <p> The subdomain problems are solved by Gaussian elimination. m 0 # of subgraphs ovlp = 0 ovlp = 1 ovlp = 2 2 2 9 8 7 8 9 21 18 18 also been reached in <ref> [13] </ref>, where global ILU (k) preconditioners, among others, were discussed. We note that the most popularly used ILU (0) is not a good choice for this example. 6.2. Two-level algorithms.
Reference: [14] <author> Y. Saad, </author> <title> Krylov subspace methods in distributed computing environments, </title> <type> Preprint 92-126, </type> <institution> Army High Performance Computing Research Center, University of Minnesota, </institution> <year> 1992. </year>
Reference-contexts: Here n is the size of the matrix. Since we assume that the non-zero pattern is symmetric the adjacency graph G is indirected. There are several algorithms described in the literature for partitioning a graph into subgraphs <ref> [10, 11, 14] </ref>. The approach described in [10] is a form of nested dissection algorithm, and the author proposes a number of strategies to find good separators. In [11] a spectral analysis of Discrete Laplacian is exploited. <p> The approach described in [10] is a form of nested dissection algorithm, and the author proposes a number of strategies to find good separators. In [11] a spectral analysis of Discrete Laplacian is exploited. In section 5 we give a brief description of a technique presented in <ref> [14] </ref>. In summary, the algorithm consists of two phases. The first phase finds a set of n 0 initial vertices that are reasonably well spread apart in the graph. <p> Graph Partitioning. The graph partitioning algorithm described in <ref> [14] </ref> consists of two phases. The purpose of the first phase is to provide a subset S 0 of W consisting of points that are at nearly equal distance to each other.
Reference: [15] <author> Y. Saad and M. H. Schultz, </author> <title> GMRES: A generalized minimal residual algorithm for solving nonsymmetric linear systems, </title> <journal> SIAM J. Sci. Stat. Comp. </journal> <volume> 7 (1986), </volume> <pages> pp. 865-869. 16 </pages>
Reference-contexts: The solution of the original PDE is obtained typically by a Krylov space type iterative method, such as the generalized minimal residual algorithm (GMRES) <ref> [15] </ref>, which is preconditioned by an operator which typically incorporates the solutions of the subproblems. Our goal in this paper is to extend the framework of the overlapping domain decomposition approach to general sparse linear systems. <p> In the section, we only discuss those parameters that are of interest to us currently. For a fixed preconditioner, there are also many accelerators which can be used such as GMRES <ref> [15] </ref>, BiCGSTAB [16], TFQMR [7], etc.. However, we shall restrict ourselves to the use of the restarted GMRES algorithm. We consider the following two model problems. Problem 0. We consider the Poisson equation 4 u = f with Dirichlet boundary condition on the unit square in R 2 .
Reference: [16] <author> H. A. Van der Vorst, </author> <title> Bi-CGSTAB: A more smoothly converging variant of CG-S for the solution of nonsymmetric linear systems, </title> <journal> SIAM J. Sci. Stat. Comp. </journal> <volume> 13 (1992), </volume> <pages> pp. 631-644. 17 </pages>
Reference-contexts: In the section, we only discuss those parameters that are of interest to us currently. For a fixed preconditioner, there are also many accelerators which can be used such as GMRES [15], BiCGSTAB <ref> [16] </ref>, TFQMR [7], etc.. However, we shall restrict ourselves to the use of the restarted GMRES algorithm. We consider the following two model problems. Problem 0. We consider the Poisson equation 4 u = f with Dirichlet boundary condition on the unit square in R 2 .
References-found: 16

