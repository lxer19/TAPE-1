URL: http://www.stat.cmu.edu/www/cmu-stats/tr/tr646/tr646.ps
Refering-URL: 
Root-URL: 
Title: Inference in Dynamic Error-in-Variable-Measurement Problems  
Author: Jo~ao S. Albuquerque Lorenz T. Biegler Robert E. Kass 
Address: Pittsburgh, PA 15213  Pittsburgh, PA 15213  Pittsburgh, PA 15213  
Affiliation: Department of Chemical Engineering, Carnegie Mellon University,  Department of Chemical Engineering, Carnegie Mellon University,  Department of Statistics, Carnegie Mellon University,  
Date: July 26, 1996  
Abstract: Efficient algorithms have been developed for estimating model parameters from measured data, even in the presence of gross errors. In addition to point estimates of parameters, however, assessments of uncertainty are needed. Linear approximations provide standard errors, but these can be misleading when applied to models that are substantially nonlinear. To overcome this difficulty, "profiling" methods have been developed for the case in which the regressor variables are error free. In this paper we extend profiling methods to Error-in-Variable-Measurement (EVM) models. We use Laplace's method to integrate out the incidental parameters associated with the measurement errors, and then apply profiling methods to obtain approximate confidence contours for the parameters. This approach is computationally efficient, requiring few function evaluations, and can be applied to large scale problems. It is useful when the certain measurement errors (e.g., input variables) are relatively small, but not so small that they can be ignored. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Albuquerque, J. S. , Biegler, L. T. </author> , <title> `Decomposition Algorithms for On-Line Estimation with Nonlinear DAE Models',accepted for publication in Comput. </title> <institution> Chem. Engng., </institution> <year> 1996. </year>
Reference-contexts: Then the posterior distribution density will become: p (u 1 ; ; u n ; jx; u) = p x (x n+1 jx n+1 ) i=1 We discretize the DAE system (1)-(2) using Implicit Runge Kutta or orthogonal collocation schemes at these sampling points <ref> [1, 13, 20] </ref> obtaining the following collocation and continuity equations: F i (x i ; _x i ; u i ; ) = 0 (9) i = 1; ; n where _x i are the collocation variables or stage derivatives. <p> Although the DAE does not have to be discretized only at the sampling points <ref> [1] </ref>, we assume that the sampling times provide a stable enough discretization grid for simplicity, keeping in mind that this assumption can be easily relaxed. <p> i ; _x i ) x 1 = x (t 1 ) Problem (10) grows in size both in the number of variables and degrees-of-freedom for optimization as the number of time steps or data sets increases, and can easily become too big to solve unless special measures are taken <ref> [1, 22, 5, 16] </ref>. Several efficient methods have been developed that allow for a fast solution of the large scale problems that arise in solving problem (10). <p> Several efficient methods have been developed that allow for a fast solution of the large scale problems that arise in solving problem (10). Some of these methods <ref> [1, 22, 16] </ref> are tailored to the structure of the first-order optimal conditions arising from problem (10) and their computational effort is linear with the number of time steps (or data sets). <p> We conclude that approximation (24) is reliable for large numbers of inputs as long as the measurement noise level remains small. As the noise increases, the approximation begins to break down. 5.3 Two connected tanks In this example, which we treated previously <ref> [1, 2] </ref> we have two tanks connected by a valve. The measured variables are the flows F 0 ; F 1 ; F 2 and the levels of liquid h 1 ; h 2 . <p> These problems are especially important in on-line applications in process control where measurement errors in the process outputs and inputs cannot be ignored. Efficient algorithms have recently been developed to solve nonlinear EVM problems <ref> [1, 2] </ref>, but without the capability for nonlinear inference of these parameters, questions of dependence among parameters and parametric sensitivity remain unanswered, and these considerations may even invalidate the results of the point estimation.
Reference: [2] <author> Albuquerque, J. S. ,Biegler, L. T. </author> , <title> `Data Reconciliation and Gross Error Detection for Dynamic Systems', </title> <note> accepted for publication in AIChE Journal, </note> <year> 1996. </year>
Reference-contexts: We conclude that approximation (24) is reliable for large numbers of inputs as long as the measurement noise level remains small. As the noise increases, the approximation begins to break down. 5.3 Two connected tanks In this example, which we treated previously <ref> [1, 2] </ref> we have two tanks connected by a valve. The measured variables are the flows F 0 ; F 1 ; F 2 and the levels of liquid h 1 ; h 2 . <p> These problems are especially important in on-line applications in process control where measurement errors in the process outputs and inputs cannot be ignored. Efficient algorithms have recently been developed to solve nonlinear EVM problems <ref> [1, 2] </ref>, but without the capability for nonlinear inference of these parameters, questions of dependence among parameters and parametric sensitivity remain unanswered, and these considerations may even invalidate the results of the point estimation.
Reference: [3] <author> Basu, A. , Paliwal, K. K. </author> <title> ,`Robust M-Estimates and Generalized M-Estimates for Au toregressive Parameter Estimation',TENCON 89, </title> <booktitle> Fourth IEEE Region 10 International Conference, </booktitle> <address> Bombay, India, </address> <year> 1989. </year>
Reference: [4] <author> Bates D. M. ,Watts D. G. </author> <title> ,`Nonlinear Regression Analysis and its Applications', </title> <publisher> Wiley, </publisher> <year> 1988. </year>
Reference-contexts: In problems that are approximately linear, standard errors may be obtained by applying standard least-squares theory to a linearized solution space for the system. As nonlinearity increases, however, alternative methods are needed. An effective approach involves "profiling" <ref> [4] </ref>, which is a technique based on the signed-square root of the loglikelihood function (or log posterior density) that produces improved confidence intervals [24]. The purpose of this paper is to extend the profiling methodology to EVM problems. <p> However, even when an efficient method is used, the problem may still be expensive. Consequently, any method of drawing inferences on the parameters must limit the number of times problem (10) is solved. 3 Profiling Methods Profiling methods were discussed by Bates and Watts <ref> [4] </ref> as an approximate and reasonably efficient method to obtain nonlinear inferences. Additional general discussion and theory has been provided by Sweeting [24]. In this section we review key elements of the methodology. <p> the profile t, also more informatively called the signed-square-root of the log posterior density, t ( q ) = sgn ( q ^ q ) 2 (`( q ; ^ q ) `( ^ )) (16) is asymptotically distributed as a standard Normal distribution to a high order of accuracy <ref> [4, 17, 24] </ref>. The term "profile" here refers to the use of the conditional maximum of the log posterior after fixing the value of the component q . <p> On the other hand, exact methods for nonlinear inference are expensive for process models even if only a handful of parameters are present. Instead, for this case, an efficient profiling approach <ref> [4] </ref> leads to a reasonably accurate approximation of confidence regions. However, when the number of parameters becomes large, as in the EVM problem, even this approach is prohibitively expensive.
Reference: [5] <author> Betts, J. T. </author> <title> ,`Experience with a Sparse Nonlinear Programming Algorithm', IMA Workshop on Large Scale Optimization, </title> <institution> University of Minnesota, </institution> <year> 1995. </year>
Reference-contexts: i ; _x i ) x 1 = x (t 1 ) Problem (10) grows in size both in the number of variables and degrees-of-freedom for optimization as the number of time steps or data sets increases, and can easily become too big to solve unless special measures are taken <ref> [1, 22, 5, 16] </ref>. Several efficient methods have been developed that allow for a fast solution of the large scale problems that arise in solving problem (10). <p> Some of these methods [1, 22, 16] are tailored to the structure of the first-order optimal conditions arising from problem (10) and their computational effort is linear with the number of time steps (or data sets). General large-scale optimization <ref> [5] </ref> algorithms, with sparse algebra reordering algorithms for the first order optimal conditions can also be used. However, even when an efficient method is used, the problem may still be expensive.
Reference: [6] <author> Crowe, C. M. </author> <title> ,`Observability and Redundancy of Process Data for Steady State Reconcili ation',Chem. </title> <institution> Eng. Sci. ,44 (12),pp. 2909-2917,1989. </institution>
Reference: [7] <author> Fariss, R. H. , Law, V. H. </author> <title> ,`An Efficient Computational Technique for Generalized Appli cation of Maximum Likelihood to Improve Correlation of Experimental Data', </title> <journal> Comput. Chem. Engng. </journal> , <volume> 3, </volume> <pages> pp. 95-104, </pages> <year> 1979, </year>
Reference: [8] <author> Forsythe, G. E. </author> , <title> `Computer Methods for Mathematical Computations', </title> <publisher> Prentice-Hall, En glewood Cliffs, </publisher> <editor> N. J. </editor> <publisher> ,1977. </publisher>
Reference-contexts: / i=1 exp 1 i x 1i ) 2 1 i x 2i ) 2 1 u i u i 2 (41) and the marginal density in becomes p (jx; u) = 1 Figures ??, ?? and ?? compare integral (42) obtained by numerical integration with a 8-panel Newton-Cotes rule <ref> [8] </ref> with the Laplace approximation for one point (N = 1), a small number of data sets (N = 10) and a large number of data sets (N = 150) for the case of a small measurement noise in the inputs ( = 0:01).
Reference: [9] <author> Kass, R. K. , Genz, A. </author> <title> ,`Subregion-Adaptive Integration of Functions having a Dominant Peak', </title> <note> to appear in Journal of Computational and Graphical Statistics, </note> <year> 1997 </year>
Reference-contexts: We turned to these approximations because of the computational burden inherent in dynamic systems; each evaluation of the likelihood function is very costly because a DAE system must be solved. As a result, Monte Carlo or quadrature methods (e.g., <ref> [9] </ref> and the references therein) can not be used in this setting.
Reference: [10] <author> Kass, R. K. ,Tierney, L. ,Kadane, J. B. </author> <booktitle> ,`Laplace's Method in Bayesian Analy sis',Contemporary Mathematics, </booktitle> <volume> 115, </volume> <pages> pp. </pages> <year> 89-99,1991. </year>
Reference-contexts: Because of the heavy computational burden involved in evaluating the posterior density (which requires solving equations (10) repeat 7 edly), we use an approximation known as Laplace's method <ref> [10, 15, 26] </ref>. A further justification of this approach is that the error associated with u i is small. 4.1 Laplace's method Let be the objective function in problem (10), (x 1 ; ; x n+1 ; u 1 ; ; u n ; ) = (19) i=1 .
Reference: [11] <author> Johnston, L. P. M. ,Kramer, A. M. </author> <title> ,`Maximum Likelihood Data Rectification: Steady State Systems', </title> <journal> AIChE Journal, </journal> <volume> 41 (11),pp. </volume> <pages> 2145-2426, </pages> <year> 1995. </year> <month> 20 </month>
Reference: [12] <author> Kretsovalis,A. ,Mah,R. S. H. </author> <title> ,`Observability and Redundancy Classification in Generalized Process Networks-I. </title> <journal> Theorems',Comput. Chem. Engng. </journal> <volume> ,12, </volume> <pages> pp. 671-687, </pages> <year> 1988. </year>
Reference: [13] <author> Liebman, M. J. ,Edgar, T. F. ,Lasdon, L. ,S. </author> <title> ,`Efficient Data Reconciliation and Estimation for Dynamic Processes using Nonlinear Programming Techniques', </title> <journal> Comp. Chem. Engng. </journal> , <volume> 16 (10/11),p. 963, </volume> <year> 1992 </year>
Reference-contexts: Then the posterior distribution density will become: p (u 1 ; ; u n ; jx; u) = p x (x n+1 jx n+1 ) i=1 We discretize the DAE system (1)-(2) using Implicit Runge Kutta or orthogonal collocation schemes at these sampling points <ref> [1, 13, 20] </ref> obtaining the following collocation and continuity equations: F i (x i ; _x i ; u i ; ) = 0 (9) i = 1; ; n where _x i are the collocation variables or stage derivatives.
Reference: [14] <author> Wolfram, S. </author> <title> ,`Mathematica. A System for Doing Mathematics by Computer', </title> <publisher> Addison Wesley, </publisher> <year> 1988. </year>
Reference-contexts: In this example we compare the unnormalized marginal density in obtained by computing the integral (35) numerically using Mathematica <ref> [14] </ref> with the Laplace approximation for several noise levels in u and with the linear approximation (37). Figures ??,??,?? and ?? show the comparisons for standard-deviation = 0:01; 0:5; 1:0 and 2:0 respectively.
Reference: [15] <author> Murray, J. D. </author> <title> ,`Asymptotic Analysis', </title> <publisher> Clarendon Press, </publisher> <year> 1974. </year>
Reference-contexts: Because of the heavy computational burden involved in evaluating the posterior density (which requires solving equations (10) repeat 7 edly), we use an approximation known as Laplace's method <ref> [10, 15, 26] </ref>. A further justification of this approach is that the error associated with u i is small. 4.1 Laplace's method Let be the objective function in problem (10), (x 1 ; ; x n+1 ; u 1 ; ; u n ; ) = (19) i=1 .
Reference: [16] <author> Schloder, J. P. , Ziee, M. W. , Bock, H. G. , Gallitzendorfer, J. V. </author> , <title> `Parameter Estimation in Multispecies Transport Reaction Systems using Parallel Algorithms', </title> <type> Preprint 95-26, </type> <institution> Interdisciplinares Zentrum Fu Wissenschaftliches Rechnen der Universitat Heidelberg, </institution> <year> 1995. </year>
Reference-contexts: i ; _x i ) x 1 = x (t 1 ) Problem (10) grows in size both in the number of variables and degrees-of-freedom for optimization as the number of time steps or data sets increases, and can easily become too big to solve unless special measures are taken <ref> [1, 22, 5, 16] </ref>. Several efficient methods have been developed that allow for a fast solution of the large scale problems that arise in solving problem (10). <p> Several efficient methods have been developed that allow for a fast solution of the large scale problems that arise in solving problem (10). Some of these methods <ref> [1, 22, 16] </ref> are tailored to the structure of the first-order optimal conditions arising from problem (10) and their computational effort is linear with the number of time steps (or data sets).
Reference: [17] <author> Seber, G. A. ,Wild C. J. </author> <title> ,`Nonlinear Regression', </title> <publisher> Wiley, </publisher> <year> 1989. </year>
Reference-contexts: the profile t, also more informatively called the signed-square-root of the log posterior density, t ( q ) = sgn ( q ^ q ) 2 (`( q ; ^ q ) `( ^ )) (16) is asymptotically distributed as a standard Normal distribution to a high order of accuracy <ref> [4, 17, 24] </ref>. The term "profile" here refers to the use of the conditional maximum of the log posterior after fixing the value of the component q .
Reference: [18] <author> Shun, Z. ,McCullagh, P. </author> <title> ,`Laplace Approximation of High-Dimensional Integrals', </title> <type> Technical Report no. 389, </type> <institution> Department of Statistics, The University of Chicago, </institution> <year> 1994. </year>
Reference-contexts: As a result, Monte Carlo or quadrature methods (e.g., [9] and the references therein) can not be used in this setting. Although Laplace's method can break down as the number of parameters being integrated (here, the incidental parameters) increases <ref> [18] </ref>, our examples demonstrate that the technique remains effective when the noise in the incidental parameters is small, even for a large number of control variables.
Reference: [19] <author> Narasimhan, S. , Mah, R. S. H. </author> , <title> `Generalized Likelihood Ratios for Gross Error Identifica tion in Dynamic Processes', </title> <journal> AIChE Journal, </journal> <volume> 34 (8), </volume> <pages> pp. 1321-1331, </pages> <year> 1988. </year>
Reference: [20] <author> Sistu, P. B. ,Gopinath, R. S. , Bequette, B. W. </author> <title> ,`Computation Issues in Nonlinear Predictive Control', </title> <journal> Comp. Chem. Engng. </journal> , <volume> 17 (4),p. 361, </volume> <year> 1993 </year>
Reference-contexts: Then the posterior distribution density will become: p (u 1 ; ; u n ; jx; u) = p x (x n+1 jx n+1 ) i=1 We discretize the DAE system (1)-(2) using Implicit Runge Kutta or orthogonal collocation schemes at these sampling points <ref> [1, 13, 20] </ref> obtaining the following collocation and continuity equations: F i (x i ; _x i ; u i ; ) = 0 (9) i = 1; ; n where _x i are the collocation variables or stage derivatives. <p> Each regression took 7.8 seconds of CPU time in a MicroVAX 3200 workstation. Computing the second derivatives and their determinant took 5.5 seconds. Total running time was 146 seconds. 5.4 Reactor problem In this problem, treated previously by Sistu et al. <ref> [20] </ref>, we consider a nonisothermal CSTR with an exothermal irreversible reaction.
Reference: [21] <author> Stanley, G. M. , Mah, R. S. H. </author> , <title> `Observability and Redundancy in Process Data Estima tion', </title> <journal> Chem. Engr. Sci. </journal> , <volume> 36, </volume> <pages> pp. 259, </pages> <year> 1981. </year>
Reference: [22] <author> Steinbach, M. </author> <title> ,`Fast Recursive SQP Methods for Large-Scale Optimal Control Problems', </title> <type> PhD Thesis, </type> <institution> Interdisciplinares Zentrum Fu Wissenschaftliches Rechnen der Universitat Heidelberg, </institution> <year> 1995. </year>
Reference-contexts: i ; _x i ) x 1 = x (t 1 ) Problem (10) grows in size both in the number of variables and degrees-of-freedom for optimization as the number of time steps or data sets increases, and can easily become too big to solve unless special measures are taken <ref> [1, 22, 5, 16] </ref>. Several efficient methods have been developed that allow for a fast solution of the large scale problems that arise in solving problem (10). <p> Several efficient methods have been developed that allow for a fast solution of the large scale problems that arise in solving problem (10). Some of these methods <ref> [1, 22, 16] </ref> are tailored to the structure of the first-order optimal conditions arising from problem (10) and their computational effort is linear with the number of time steps (or data sets).
Reference: [23] <author> Swartz, C. L. E. </author> , <title> `Data Reconciliation for Generalized Flowsheet Applications', </title> <booktitle> paper presented at the American Chemical Society National Meeting, </booktitle> <address> Dallas, Tx, </address> <month> April, </month> <year> 1989. </year> <month> 21 </month>
Reference: [24] <author> Sweeting, T. J. </author> <title> ,`A Framework for Bayesian and Likelihood Approximations in Statistics', </title> <journal> Biometrika, </journal> <volume> 82, </volume> <pages> pp. 1-24, </pages> <year> 1995. </year>
Reference-contexts: As nonlinearity increases, however, alternative methods are needed. An effective approach involves "profiling" [4], which is a technique based on the signed-square root of the loglikelihood function (or log posterior density) that produces improved confidence intervals <ref> [24] </ref>. The purpose of this paper is to extend the profiling methodology to EVM problems. <p> Additional general discussion and theory has been provided by Sweeting <ref> [24] </ref>. In this section we review key elements of the methodology. Consider the regression problem described in section 2 but without the input or control variables (incidental parameters) u (t) or assuming that these are error free, so that they become constants. <p> the profile t, also more informatively called the signed-square-root of the log posterior density, t ( q ) = sgn ( q ^ q ) 2 (`( q ; ^ q ) `( ^ )) (16) is asymptotically distributed as a standard Normal distribution to a high order of accuracy <ref> [4, 17, 24] </ref>. The term "profile" here refers to the use of the conditional maximum of the log posterior after fixing the value of the component q .
Reference: [25] <author> Tamhane, A. C. , Kao,C. , Mah, R. S. H. </author> <title> ,`Gross Error Detection in Serially Correlated Process Data. 2. Dynamic Systems', Ind. </title> <journal> Eng. Chem. Res., </journal> <volume> 31, </volume> <pages> pp. 254-262, </pages> <year> 1992. </year>
Reference: [26] <author> Tierney, L. and Kadane, J.B., </author> <title> `Accurate approximations for posterior moments and marginal densities', </title> <journal> J. Amer. Statist. Assoc., </journal> <volume> 81, </volume> <pages> pp. 82-6, </pages> <year> 1986. </year>
Reference-contexts: Because of the heavy computational burden involved in evaluating the posterior density (which requires solving equations (10) repeat 7 edly), we use an approximation known as Laplace's method <ref> [10, 15, 26] </ref>. A further justification of this approach is that the error associated with u i is small. 4.1 Laplace's method Let be the objective function in problem (10), (x 1 ; ; x n+1 ; u 1 ; ; u n ; ) = (19) i=1 .
Reference: [27] <author> Tjoa, I. B. , Biegler ,L. T. </author> , <title> `Simultaneous Strategies for Data Reconciliation and Gross Error Detection of Nonlinear Systems', </title> <journal> Comput. Chem. Engng. ,15 (10),pp. </journal> <pages> 679-90, </pages> <year> 1991. </year> <month> 22 </month>
References-found: 27

