URL: http://www.isi.edu/~berson/sigmod95.ps
Refering-URL: http://www.isi.edu/~berson/
Root-URL: http://www.isi.edu
Title: Fault Tolerant Design of Multimedia Servers  
Author: Steven Berson Leana Golubchik Richard R. Muntz 
Date: October 27, 1994  
Affiliation: UCLA Computer Science Department  
Abstract: Recent technological advances have made multimedia on-demand servers feasible. Two challenging tasks in such systems are: a) satisfying the real-time requirement for continuous delivery of objects at specified bandwidths and b) efficiently servicing multiple clients simultaneously. To accomplish these tasks and realize economies of scale associated with servicing a large user population, the multimedia server can require a large disk subsystem. Although a single disk is fairly reliable, a large disk farm can have an unacceptably high probability of disk failure. Further, due to the real-time constraint, the reliability and availability requirements of multimedia systems are very stringent. In this paper we investigate techniques for providing a high degree of reliability and availability, at low disk storage, bandwidth, and memory costs for on-demand multimedia servers.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Steven Berson, Shahram Ghandeharizadeh, Richard R. Muntz, and Xi-angyu Ju. </author> <title> Staggered Striping in Multimedia Information Systems. </title> <address> SIG-MOD, </address> <year> 1994. </year> <month> 25 </month>
Reference-contexts: Another challenging task in multimedia systems is to service multiple clients simultaneously. Both of these tasks are accomplished in <ref> [1] </ref> through a novel layout of the data on the disk drives, using a technique termed staggered striping. An example multimedia system is illustrated in Figure 1; it includes a multimedia server, a communication network, and a set of display stations.
Reference: [2] <author> Steven Berson, Leana Golubchik, and Richard R. Muntz. </author> <title> A Fault Tol--erant Design of a Multimedia Server. </title> <type> Technical Report CSD-940009, </type> <institution> UCLA, </institution> <year> 1994. </year>
Reference-contexts: that cost is a constraint in our system 5 , it is important to consider the size and cost of the 4 Non-buffering schemes, other than the ones that are limited to small parity groups, e.g., parity-per-subobject scheme, are not presented in this paper due to lack of space; see <ref> [2] </ref> for details. 5 Otherwise we could just buy more disks. 21 buffers and compare these against the savings in disk space. For the purpose of illustration we consider a simple system with a constant bandwidth requirement.
Reference: [3] <author> D. Bitton and J. Gray. </author> <title> Disk Shadowing. </title> <booktitle> VLDB, </booktitle> <pages> pages 331-338, </pages> <year> 1988. </year>
Reference-contexts: Therefore, without some form of fault tolerance, such a system is not likely to be acceptable. To improve the reliability and availability of the system we must use some fraction of the disk space to store redundant information. Typically, parity schemes [6] and mirroring schemes <ref> [3] </ref> have been used for this purpose. For instance, consider a storage subsystem (such as in Figure 2), where four out of every five disks are used to store "real" data and the fifth disk is used to store parity information, e.g., X0p0 = X0:0 X1:0 X2:0 X3:0.
Reference: [4] <author> P. Chen, E. Lee, G. Gibson, R. Katz, and D. Patterson. </author> <title> RAID: High-Performance, Reliable Secondary Storage. </title> <journal> ACM Computing Surveys, </journal> <pages> pages 145-186, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: The streaming RAID scheme can withstand up to one failure per disk cluster before a catastrophic failure occurs. If we assume that disks fail independently, then the mean time to failure (MTTF) of a 1000 disk system with clusters of 9 data disks and 1 parity disk is approximately <ref> [4] </ref>: M T T F = M T T F (disk) 2 N fl (C 1) fl M T T R (disk) where N is the total number of disks in the system, C is the cluster size including the parity disk, and MTTR (disk) is the mean time to repair
Reference: [5] <author> Richard R. Muntz and John C.S. Lui. </author> <title> Performance analysis of disk arrays under failure. </title> <booktitle> VLDB Conference, </booktitle> <pages> pages 162-173, </pages> <year> 1990. </year>
Reference-contexts: Therefore improvements in reliability must be balanced against degradation in performance and increased costs. There are three modes of operation for a disk subsystem <ref> [5] </ref>, as originally defined in the context of disk arrays: 1) normal mode, where all disks are operational, 2) degraded mode, where one (or more) disks have failed, and 3) rebuild mode, where the disks are still down, but the process of rebuilding the missing information on spare disks is in
Reference: [6] <author> David A. Patterson, Garth Gibson, and Randy H. Katz. </author> <title> A Case for Redundant Arrays of Inexpensive Disks (RAID). </title> <booktitle> ACM SIGMOD Conference, </booktitle> <pages> pages 109-116, </pages> <year> 1988. </year>
Reference-contexts: Therefore, without some form of fault tolerance, such a system is not likely to be acceptable. To improve the reliability and availability of the system we must use some fraction of the disk space to store redundant information. Typically, parity schemes <ref> [6] </ref> and mirroring schemes [3] have been used for this purpose.
Reference: [7] <author> F. Tobagi, J. Pang, R. Baird, and M. Gang. </author> <title> Streaming RAID A Disk Array Management System for Video Files. </title> <booktitle> ACM Multimedia '93, </booktitle> <pages> pages 393-400, </pages> <year> 1993. </year>
Reference-contexts: The rest of the paper is organized as follows. Section 2 presents background information on multimedia servers. In particular, in Section 2, we discuss the most straightforward use of RAID technology which although advocated in previous proposals <ref> [7] </ref> can be improved upon significantly. Sections 3 and 5 present our parity schemes, and Section 6 compares these schemes with respect to performance and reliability.
References-found: 7

