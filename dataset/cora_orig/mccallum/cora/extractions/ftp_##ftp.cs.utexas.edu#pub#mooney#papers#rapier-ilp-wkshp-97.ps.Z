URL: ftp://ftp.cs.utexas.edu/pub/mooney/papers/rapier-ilp-wkshp-97.ps.Z
Refering-URL: http://www.cs.utexas.edu/users/ml/nl.html
Root-URL: http://www.cs.utexas.edu
Email: fmecaliff,mooneyg@cs.utexas.edu  
Title: Applying ILP-based Techniques to Natural Language Information Extraction: An Experiment in Relational Learning  
Author: Mary Elaine Califf and Raymond J. Mooney 
Address: Austin, TX 78712  
Affiliation: Department of Computer Sciences University of Texas at Austin  
Note: To appear in Working Notes of the IJCAI-97 Workshop on Frontiers of ILP  
Abstract-found: 0
Intro-found: 1
Reference: [ ARPA, 1992 ] <editor> ARPA, editor. </editor> <booktitle> Proceedings of the Fourth DARPA Message Understanding Evaluation and Conference, </booktitle> <address> San Mateo, CA, 1992. </address> <publisher> Mor-gan Kaufman. </publisher>
Reference-contexts: Section 5 presents our conclusions. 2 Background 2.1 Information Extraction Information extraction is the task of locating specific pieces of data from a natural language document, and has been the focus of ARPA's Message Understanding Conferences (MUC) <ref> [ Lehnert and Sund-heim, 1991; ARPA, 1992; 1993 ] </ref> . Usually the data to be extracted is described by a template specifying a list of slots to be filled. For example, Figure 1 shows part of a job posting, and the corresponding slots of the filled computer-science job template. <p> Lower precision indicates that the system is producing spurious fillers: that its rules are overly general. Lower recall indicates that the system is failing to find correct fillers: that its rules are too specific. Recent MUC conferences have introduced an F-measure <ref> [ ARPA, 1992 ] </ref> , combining precision and recall in order to provide a single number measurement for IE systems. We report the precision, recall, and F-measure with precision and recall weighted equally. <p> At 90 training examples, the average precision was 83.7% and the average recall was 53.1%. These numbers look quite promising when compared to the measured performance of other IE systems on various domains <ref> [ Soderland et al., 1995; Riloff, 1996; ARPA, 1992; 1993 ] </ref> . These comparisons are general, since the tasks are different, but they do indicate that Rapier is doing relatively well. It should be noted that the precision is close to 80% even with only 15 example documents.
Reference: [ ARPA, 1993 ] <editor> ARPA, editor. </editor> <booktitle> Proceedings of the Fifth DARPA Message Understanding Evaluation and Conference, </booktitle> <address> San Mateo, CA, 1993. </address> <publisher> Morgan Kaufman. </publisher>
Reference: [ Blockeel and deRaedt, 1996 ] <author> Henrik Blockeel and Luc deRaedt. </author> <title> Relational knowledge discovery in databases. </title> <booktitle> In Proceedings of the Sixth International Workshop on Inductive Logic Programming", </booktitle> <pages> pages 1-13, </pages> <year> 1996. </year>
Reference-contexts: To actually use inductive logic programming to learn rules for this task, one would have to be able to robustly produce a first order representation of the original documents. However, relational learning does not have to limited to first order logic representations <ref> [ Blockeel and deRaedt, 1996 ] </ref> . Therefore, we have chosen instead to apply ILP-based techniques to a rule representa tion more suited to the task.
Reference: [ Brill, 1994 ] <author> Eric Brill. </author> <title> Some advances in rule-based part of speech tagging. </title> <booktitle> In Proceedings of the Twelfth National Conference on Artificial Intelligence, </booktitle> <year> 1994. </year>
Reference-contexts: This rule assumes that the document has been tagged with the POS tagger of <ref> [ Brill, 1994 ] </ref> . 3.2 The Learning Algorithm As noted above, Rapier's algorithm primarily consists of a specific to general (bottom-up) search. First, for each slot, most-specific patterns are created for each example, specifying word and tag for the filler and its complete context.
Reference: [ Cohen, 1995 ] <author> W. W. Cohen. </author> <title> Text categorization and relational learning. </title> <booktitle> In Proceedings of the Twelfth International Conference on Machine Learning, </booktitle> <pages> pages 124-132, </pages> <address> San Francisco, CA, 1995. </address> <publisher> Morgan Kaufman. </publisher>
Reference-contexts: One domain with the complexity to make relational learning preferable to feature-based learning is natural language processing (NLP). Detailed experimental comparisons of ILP and feature-based induction have demonstrated the advantages of relational representations in two language related tasks, text categorization <ref> [ Cohen, 1995 ] </ref> and generating the past tense of an English verb [ Mooney and Califf, 1995 ] . However, for some NLP tasks, first order logic representations may be very difficult to produce.
Reference: [ Cohen, 1996 ] <author> W. W. Cohen. </author> <title> Learning rules that classify e-mail. </title> <booktitle> In Papers from the AAAI Spring Symposium on Machine Learning in Information Access, </booktitle> <pages> pages 18-25. </pages> <publisher> AAAI Press, </publisher> <year> 1996. </year>
Reference-contexts: ILP also allows the use of background knowledge, and the resulting rules are often more comprehensible. The comprehensibility of symbolic rules makes it easier for the system developer to understand and verify the resulting system and perhaps even edit the learned knowledge <ref> [ Cohen, 1996 ] </ref> . One domain with the complexity to make relational learning preferable to feature-based learning is natural language processing (NLP).
Reference: [ Huffmann, 1996 ] <author> Scott B. Huffmann. </author> <title> Learning information extraction patterns from examples. </title> <editor> In Stefan Wermter, Ellen Riloff, and Gabriele Scheller, editors, </editor> <title> Connectionist, Statistical, and Symbolic Approaches to Learning for Natural Language Processing, </title> <booktitle> Lecture Notes in Artificial Intelligence, </booktitle> <pages> pages 246-260. </pages> <publisher> Springer, </publisher> <year> 1996. </year>
Reference-contexts: IE can be useful in a variety of domains. The various MUC's have focused on domains such as Latin American terrorism, joint ventures, microelectronics, and company management changes. Others have used IE to track medical patient records [ Soder-land et al., 1995 ] or company mergers <ref> [ Huffmann, 1996 ] </ref> . The general task considered in this paper is extracting information from postings to USENET newsgroups, such as job announcements. Posting from Newsgroup Telecommunications. SOLARIS Systems Administrator. 38-44K.
Reference: [ Lehnert and Sundheim, 1991 ] <editor> Wendy Lehnert and Beth Sundheim. </editor> <title> A performance evaluation of text-analysis technologies. </title> <journal> AI Magazine, </journal> <volume> 12(3) </volume> <pages> 81-94, </pages> <year> 1991. </year>
Reference: [ Miller et al., 1993 ] <author> G. Miller, R. Beckwith, C. Fell-baum, D. Gross, and K. Miller. </author> <title> Introduction to WordNet: An on-line lexical database. </title> <note> Available by ftp to clarity.princeton.edu, </note> <year> 1993. </year>
Reference-contexts: Induced patterns can also easily incorporate semantic class information, such as that provided by WordNet <ref> [ Miller et al., 1993 ] </ref> . The remainder of this paper is organized as follows. Section 2 presents background material on IE and describes the specific ILP systems which inspired our algorithm. Section 3 describes Rapier's rule representation and learning algorithm. <p> may allow the search to explode. 3 Rapier System 3.1 Rule Representation Rapier's rule representation uses patterns that make use of limited syntactic and semantic information, using freely available, robust knowledge sources such as a part-of-speech tagger and a lexicon with semantic classes, such as the hypernym links in Word-Net <ref> [ Miller et al., 1993 ] </ref> . The initial implementation does not use a parser, primarily because of the difficulty of producing a robust parser for unrestricted text and because simpler patterns of the type we propose can represent useful extraction rules for at least some domains.
Reference: [ Mooney and Califf, 1995 ] <author> R. J. Mooney and M. E. Califf. </author> <title> Induction of first-order decision lists: Results on learning the past tense of English verbs. </title> <journal> Journal of Artificial Intelligence Research, </journal> <volume> 3 </volume> <pages> 1-24, </pages> <year> 1995. </year>
Reference-contexts: Detailed experimental comparisons of ILP and feature-based induction have demonstrated the advantages of relational representations in two language related tasks, text categorization [ Cohen, 1995 ] and generating the past tense of an English verb <ref> [ Mooney and Califf, 1995 ] </ref> . However, for some NLP tasks, first order logic representations may be very difficult to produce. One such task is information extraction (IE), in which specific pieces of information are extracted from natural language documents.
Reference: [ Muggleton and Feng, 1992 ] <author> S. Muggleton and C. Feng. </author> <title> Efficient induction of logic programs. </title> <editor> In S. Muggleton, editor, </editor> <booktitle> Inductive Logic Programming, </booktitle> <pages> pages 281-297. </pages> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1992. </year>
Reference-contexts: Each of these are briefly described in order more clearly show how we use the learning techniques developed in ILP with an alternate representation. Golem <ref> [ Muggleton and Feng, 1992 ] </ref> employs a bottom-up algorithm based on the construction of relative least-general generalizations, rlggs [ Plotkin, 1970 ] .
Reference: [ Muggleton, 1995 ] <author> Steve Muggleton. </author> <title> Inverse entailment and Progol. </title> <journal> New Generation Computing Journal, </journal> <volume> 13 </volume> <pages> 245-286, </pages> <year> 1995. </year>
Reference-contexts: Chillin uses the notion of empirical subsumption, which means that as new, more general clauses are added, all of the clauses which are not needed to prove positive examples are removed from the definition. Progol <ref> [ Muggleton, 1995 ] </ref> also combines bottom-up and top-down search. Using mode declarations provided for both the background predicates and the predicate being learned, it constructs a most specific clause for a random seed example.
Reference: [ Plotkin, 1970 ] <author> G. D. Plotkin. </author> <title> A note on inductive generalization. </title> <editor> In B. Meltzer and D. Michie, editors, </editor> <booktitle> Machine Intelligence (Vol. </booktitle> <volume> 5). </volume> <publisher> Elsevier North-Holland, </publisher> <address> New York, </address> <year> 1970. </year>
Reference-contexts: Each of these are briefly described in order more clearly show how we use the learning techniques developed in ILP with an alternate representation. Golem [ Muggleton and Feng, 1992 ] employs a bottom-up algorithm based on the construction of relative least-general generalizations, rlggs <ref> [ Plotkin, 1970 ] </ref> . The algorithm operates by randomly selecting pairs of positive examples, computing the determinate rlggs of each pair, and selecting the resulting consistent clauses with the greatest coverage of positive examples.
Reference: [ Quinlan, 1990 ] <author> J.R. Quinlan. </author> <title> Learning logical definitions from relations. </title> <journal> Machine Learning, </journal> <volume> 5(3) </volume> <pages> 239-266, </pages> <year> 1990. </year>
Reference-contexts: If the resulting clause covers negative examples, it is specialized by adding antecedent literals in a top-down fashion. The search for new literals is carried out in a hill-climbing fash ion, using an information gain metric for evaluating literals. This is similar to the search employed by Foil <ref> [ Quinlan, 1990 ] </ref> . In cases where a correct clause cannot be learned with the existing background relations, Chillin attempts to construct new predicates which will distinguish the covered negative examples from the covered positives. <p> We maintain a list of the best n rules created and specialize the rules under consideration by adding pieces of the generalizations of the pre- and post-filler patterns of the two seed rules, working outward from the fillers. The rules are ordered using an information value metric <ref> [ Quinlan, 1990 ] </ref> weighted by the size of the rule (preferring smaller rules). When the best rule under consideration produces no negative examples, specialization ceases; that rule is added to the rule base, and all rules empirically subsumed by it are removed.
Reference: [ Riloff, 1996 ] <author> Ellen Riloff. </author> <title> Automatically generating extraction patterns from untagged text. </title> <booktitle> In Proceedings of the Thirteenth National Conference on Artificial Intelligence, </booktitle> <pages> pages 1044-1049, </pages> <year> 1996. </year>
Reference-contexts: At 90 training examples, the average precision was 83.7% and the average recall was 53.1%. These numbers look quite promising when compared to the measured performance of other IE systems on various domains <ref> [ Soderland et al., 1995; Riloff, 1996; ARPA, 1992; 1993 ] </ref> . These comparisons are general, since the tasks are different, but they do indicate that Rapier is doing relatively well. It should be noted that the precision is close to 80% even with only 15 example documents.
Reference: [ Soderland et al., 1995 ] <author> Stephen Soderland, D. Fisher, J. Aseltine, and W. Lehnert. </author> <title> Crystal: Inducing a conceptual dictionary. </title> <booktitle> In Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 1314-1319, </pages> <year> 1995. </year>
Reference-contexts: At 90 training examples, the average precision was 83.7% and the average recall was 53.1%. These numbers look quite promising when compared to the measured performance of other IE systems on various domains <ref> [ Soderland et al., 1995; Riloff, 1996; ARPA, 1992; 1993 ] </ref> . These comparisons are general, since the tasks are different, but they do indicate that Rapier is doing relatively well. It should be noted that the precision is close to 80% even with only 15 example documents.
Reference: [ Weizenbaum, 1966 ] <author> J. Weizenbaum. </author> <title> ELIZA A computer program for the study of natural language communications between men and machines. </title> <journal> Communications of the Association for Computing Machinery, </journal> <volume> 9 </volume> <pages> 36-45, </pages> <year> 1966. </year>
Reference-contexts: Therefore, we have chosen instead to apply ILP-based techniques to a rule representa tion more suited to the task. Using only a corpus of documents paired with filled templates, Rapier (Robust Automated Production of Information Extraction Rules) learns unbounded Eliza-like patterns <ref> [ Weizenbaum, 1966 ] </ref> that utilize limited syntactic information, such as the output of a part-of-speech tagger. Induced patterns can also easily incorporate semantic class information, such as that provided by WordNet [ Miller et al., 1993 ] . The remainder of this paper is organized as follows.
Reference: [ Zelle and Mooney, 1994 ] <author> J. M. Zelle and R. J. Mooney. </author> <title> Combining top-down and bottom-up methods in inductive logic programming. </title> <booktitle> In Proceedings of the Eleventh International Conference on Machine Learning, </booktitle> <pages> pages 343-351, </pages> <address> New Brunswick, NJ, </address> <month> July </month> <year> 1994. </year>
Reference-contexts: That clause is further generalized by computing the rlggs of the clause with new randomly selected positive examples, and generalization terminates when the coverage of the best consistent clause stops improving. The Chillin <ref> [ Zelle and Mooney, 1994 ] </ref> system combines top-down (general to specific) and bottom-up ILP techniques. The algorithm starts with a most specific definition (the set of positive examples) and introduces generalizations which make the definition more compact.
References-found: 18

