URL: http://www.cs.cmu.edu/afs/cs.cmu.edu/project/fox/member/petel/www/papers/trace.ps
Refering-URL: http://www.cs.cmu.edu/afs/cs.cmu.edu/project/fox/member/petel/www/papers/mess.html
Root-URL: 
Title: Trace-based Program Analysis  
Author: Christopher Colby Peter Lee 
Note: Also published as Fox Memorandum CMU-CS-FOX-95-04  
Address: Pittsburgh, PA 15213  
Affiliation: School of Computer Science Carnegie Mellon University  
Date: July 1995  
Pubnum: CMU-CS-95-179  
Abstract: We present trace-based program analysis, a semantics-based framework for statically analyzing and transforming programs with loops, assignments, and nested record structures. Trace-based analyses are based on transfer transition systems, which define the small-step operational semantics of programming languages. Intuitively, transfer transition systems provide direct support for reasoning about the possible execution traces of a program, instead of just individual program states. The traces in a transfer transition system have many uses, including the finite representation of all possible terminating executions of a loop. Also, traces may be systematically "pieced together", thus allowing the composition of separately analyzed program fragments. The utility of the approach is demonstrated by showing three applications: software pipelining, loop-invariant removal, and data alias detection. This research was sponsored in part by the Advanced Research Projects Agency CSTO under the title "The Fox Project: Advanced Languages for Systems Software", ARPA Order No. C533, issued by ESC/ENS under Contract No. F19628-95-C-0050, and in part by the National Science Foundation under PYI grant #CCR-9057567. y Work performed while on leave at Ecole Polytechnique, France.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Alfred V. Aho, Ravi Sethi, and Jeffrey D. Ullman. </author> <booktitle> Compilers: Principles, Techniques, and Tools. </booktitle> <publisher> Addison-Wesley, </publisher> <year> 1986. </year>
Reference-contexts: One might reasonably ask why trace-based analysis is necessary, since ad hoc techniques, many based on dataflow analysis, often work in practice, at least in simple cases <ref> [1] </ref>. Indeed, for the gcd example shown in Section 2, it is a simple matter to unroll the loop once and then perform standard optimizations such as constant propagation. One basic reason is that semantics-based approaches provide a way to reason about correctness and safety of analysis-based program transformations.
Reference: [2] <author> A. Aiken and A. Nicolau. </author> <title> Perfect pipelining: A new loop parallelization technique. </title> <booktitle> In Proceedings of the 1988 European Symposium on Programming, </booktitle> <publisher> LNCS. Springer-Verlag, </publisher> <month> March </month> <year> 1988. </year>
Reference-contexts: Determining precise information about loops, however, is often of critical importance for static optimization of code. One of the most striking examples is software pipelin-ing <ref> [2, 22] </ref>, a strategy for statically transforming the structure of a loop in order to take advantage of the potential instruction-level parallelism both within a single iteration and between adjacent iterations. <p> In this section, we demonstrate this by showing how a form of software pipelining can be developed using a transfer transition system. Software pipelining is a program transformation on loops that attempts to exploit instruction-level parallelism in superscalar and VLIW architectures <ref> [2, 22] </ref>. <p> Software pipelining is a program transformation on loops that attempts to exploit instruction-level parallelism in superscalar and VLIW architectures [2, 22]. As an example, consider the following code fragment taken from <ref> [2] </ref> (but with a conditional statement added so that the loop 16 exit can be expressed): l entry : i i + 1; l 1 : j i + h; l 3 : l j + 1; l 4 : test i &lt; n; l 5 : if test then l
Reference: [3] <author> D.R. Chase, M. Wegman, and F.K. Zadeck. </author> <title> Analysis of pointers and structures. </title> <booktitle> In Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 296-310, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: Examples of the kinds of properties that are useful in practice include: * The pairs of data objects that may or must be aliases at a given label <ref> [3, 14] </ref>. * Grammars giving all of the possible shapes of structured data at a given label [12, 20]. * Linear relationships amongst integer-valued variables (e.g., x = y z) at a given label [16, 21].
Reference: [4] <author> Christopher Colby. </author> <title> Analysis of synchronization and aliasing with abstract interpretation. </title> <note> Unpublished. </note>
Reference-contexts: There are a handful of "trace-based" analyses in the literature, such as Colby's analyses of concurrency <ref> [4, 5, 6] </ref> and Deutsch's online alias analysis [13, Sect. 4.4]. It is also common to use some notion of execution traces when reasoning about concurrent computations. But in the areas of static program analysis and program transformation the technique is little known. <p> Even further, it is difficult to imagine many of the more advanced alias and storage analyses (e.g., [14, 6]) without abstract interpretation, and nor is it likely that the analyses of concurrency in <ref> [5, 4] </ref> would have been found. The problem is that ad hoc techniques rarely generalize or shed any light on techniques that might be adapted for other problems, while the methodology of semantics-based approaches root analyses in the most general soil|a semantics of the language|from which other analyses may spring.
Reference: [5] <author> Christopher Colby. </author> <title> Analyzing the communication topology of concurrent programs. </title> <booktitle> In ACM SIGPLAN Symposium on Partial Evaluation and Semantics-Based Program Manupulation, </booktitle> <pages> pages 202-214, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: There are a handful of "trace-based" analyses in the literature, such as Colby's analyses of concurrency <ref> [4, 5, 6] </ref> and Deutsch's online alias analysis [13, Sect. 4.4]. It is also common to use some notion of execution traces when reasoning about concurrent computations. But in the areas of static program analysis and program transformation the technique is little known. <p> Even further, it is difficult to imagine many of the more advanced alias and storage analyses (e.g., [14, 6]) without abstract interpretation, and nor is it likely that the analyses of concurrency in <ref> [5, 4] </ref> would have been found. The problem is that ad hoc techniques rarely generalize or shed any light on techniques that might be adapted for other problems, while the methodology of semantics-based approaches root analyses in the most general soil|a semantics of the language|from which other analyses may spring.
Reference: [6] <author> Christopher Colby. </author> <title> Determining storage properties of sequential and concurrent programs with assignment and structured data. </title> <booktitle> In International Static Analysis Symposium, </booktitle> <year> 1995. </year> <note> To appear. </note>
Reference-contexts: There are a handful of "trace-based" analyses in the literature, such as Colby's analyses of concurrency <ref> [4, 5, 6] </ref> and Deutsch's online alias analysis [13, Sect. 4.4]. It is also common to use some notion of execution traces when reasoning about concurrent computations. But in the areas of static program analysis and program transformation the technique is little known. <p> Abstract interpretation, on the other hand, clearly aided the solution to control-flow analysis of higher-order functions [20, 27]. Even further, it is difficult to imagine many of the more advanced alias and storage analyses (e.g., <ref> [14, 6] </ref>) without abstract interpretation, and nor is it likely that the analyses of concurrency in [5, 4] would have been found.
Reference: [7] <author> Charles Consel. </author> <title> Polyvariant binding-time analysis for applicative languages. In Partial Evaluation and Semantics-Based Program Manipulation, New Haven, </title> <journal> Connecticut (SIGPLAN Notices, </journal> <volume> vol. 26, no. 9, </volume> <month> September </month> <year> 1991), </year> <pages> pages 66-77, </pages> <year> 1993. </year>
Reference-contexts: In the literature, this idea is sometimes informally referred to as polyvariance <ref> [7, 23] </ref> and is also closely related to the notion of cloning in dataflow analysis. A common form of polyvariance involves partitioning certain blocks of code, such as function bodies or loop bodies, by the label that preceded their entry.
Reference: [8] <author> P. Cousot and R. Cousot. </author> <title> Abstract interpretation: A unified lattice model for static analysis of programs by construction of approximations of fixpoints. </title> <booktitle> In Fourth Annual ACM Symposium on Principles of Programming Languages, </booktitle> <year> 1977. </year>
Reference-contexts: Also, the analysis (i.e., the computation of S) and the S function itself must be computable and, for practical reasons, efficient. Abstract interpretation <ref> [8] </ref> is a comprehensive mathematical theory for devising and reasoning about such relationships and decidability problems, and in addition it provides a semantics-based framework for devising the analysis algorithms.
Reference: [9] <author> P. Cousot and R. Cousot. </author> <title> Semantic design of program analysis frameworks. </title> <booktitle> In Sixth Annual ACM Symposium on Principles of Programming Languages, </booktitle> <address> San Antonio, Texas, </address> <pages> pages 269-282, </pages> <year> 1979. </year>
Reference-contexts: The idea of reasoning about traces instead of states is not new. The theoretical foundations go back to Cousot and Cousot <ref> [9] </ref>.
Reference: [10] <author> P. Cousot and R. Cousot. </author> <title> Inductive definitions, semantics and abstract interpretation. </title> <booktitle> In Conference Record of the 19th ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 83-94, </pages> <year> 1992. </year>
Reference-contexts: The idea of reasoning about traces instead of states is not new. The theoretical foundations go back to Cousot and Cousot [9]. Their work on G 1 SOS <ref> [10] </ref> is also related, but whereas the main focus of their system is to achieve a unified compositional operational model of non-termination, our motivation for transfer transition systems is ultimately a practical one: to provide a new framework not only for static analysis of programs, but also for developing complex program
Reference: [11] <author> P. Cousot and R. Cousot. </author> <title> Higher-order abstract interpretation (and application to comportment analysis generalizing strictness, termination, projection and PER analysis of functional languages). </title> <booktitle> In Proceedings of 1994 IEEE International Conference on Computer Languages (ICCL'94), Toulouse, France, </booktitle> <pages> pages 95-112, </pages> <month> May </month> <year> 1994. </year>
Reference-contexts: Typically, the construction of an analyzer begins with a so-called "concrete" or "collecting" semantics <ref> [11, 18] </ref> in which programs are assigned meanings of the form C 2 Label ! -(State ) where -(State) is the powerset of program states.
Reference: [12] <author> P. Cousot and R. Cousot. </author> <title> Formal language, grammar and set-constraint-based program analysis by abstract interpretation. </title> <booktitle> In Conference on Functional Programming and Computer Architecture, </booktitle> <year> 1995. </year>
Reference-contexts: Examples of the kinds of properties that are useful in practice include: * The pairs of data objects that may or must be aliases at a given label [3, 14]. * Grammars giving all of the possible shapes of structured data at a given label <ref> [12, 20] </ref>. * Linear relationships amongst integer-valued variables (e.g., x = y z) at a given label [16, 21].
Reference: [13] <author> Alain Deutsch. </author> <title> Operational Models of Programming Languages and Representations of Relations on Regular Languages with Application to the Static Determination of Dynamic Aliasing Properties of Data. </title> <type> PhD thesis, </type> <institution> LIX, Ecole Polytechnique, Palaiseau, France, </institution> <year> 1992. </year>
Reference-contexts: There are a handful of "trace-based" analyses in the literature, such as Colby's analyses of concurrency [4, 5, 6] and Deutsch's online alias analysis <ref> [13, Sect. 4.4] </ref>. It is also common to use some notion of execution traces when reasoning about concurrent computations. But in the areas of static program analysis and program transformation the technique is little known.
Reference: [14] <author> Alain Deutsch. </author> <title> A storeless model of aliasing and its abstractions using finite representations of right-regular equivalence relations. </title> <booktitle> In Proceedings of the IEEE 1992 International Conference on Computer Languages, </booktitle> <address> San Fransisco, California, </address> <pages> pages 2-13, </pages> <month> April </month> <year> 1992. </year>
Reference-contexts: Examples of the kinds of properties that are useful in practice include: * The pairs of data objects that may or must be aliases at a given label <ref> [3, 14] </ref>. * Grammars giving all of the possible shapes of structured data at a given label [12, 20]. * Linear relationships amongst integer-valued variables (e.g., x = y z) at a given label [16, 21]. <p> Abstract interpretation, on the other hand, clearly aided the solution to control-flow analysis of higher-order functions [20, 27]. Even further, it is difficult to imagine many of the more advanced alias and storage analyses (e.g., <ref> [14, 6] </ref>) without abstract interpretation, and nor is it likely that the analyses of concurrency in [5, 4] would have been found.
Reference: [15] <author> M. Felleisen and D.P. Friedman. </author> <title> Control operators, the secd-machine, and the lambda-calculus. </title> <booktitle> In 3rd Working Conference on the Formal Description of Programming Concepts, </booktitle> <month> August </month> <year> 1986. </year>
Reference-contexts: In a programming language with a looping construct, the semantic meaning is usually modeled by infinite structures. For example, denotational semantics [28] uses limits of infinite chains to model the meaning of recursive functions. In standard formulations of structural operational semantics [26] and small-step operational semantics <ref> [15] </ref>, the behavior of loops is modeled by unbounded sequences of transitions. An analysis based on any of these semantic models is thus forced to develop some method for reasoning finitely about these (potentially) infinite objects.
Reference: [16] <author> P. Granger. </author> <title> Static analysis on linear congruence equalities among variables of a program. </title> <booktitle> In TAPSOFT'91, volume 493 of Lecture Notes in Computer Science, </booktitle> <pages> pages 169-192. </pages> <publisher> Springer Verlag, </publisher> <year> 1991. </year>
Reference-contexts: * The pairs of data objects that may or must be aliases at a given label [3, 14]. * Grammars giving all of the possible shapes of structured data at a given label [12, 20]. * Linear relationships amongst integer-valued variables (e.g., x = y z) at a given label <ref> [16, 21] </ref>. Typically, the construction of an analyzer begins with a so-called "concrete" or "collecting" semantics [11, 18] in which programs are assigned meanings of the form C 2 Label ! -(State ) where -(State) is the powerset of program states.
Reference: [17] <author> Williams Ludwell Harrison. </author> <title> The interprocedural analysis and automatic parallelisation of scheme programs. </title> <journal> Lisp and Symbolic Computation, </journal> <volume> 2(3) </volume> <pages> 176-396, </pages> <month> October </month> <year> 1989. </year>
Reference-contexts: Indeed, there is quite a bit of room for creativity here, as the only real requirement on the set Point is that its elements must have finite descriptions. Some recent proposals have used fairly complex mechanisms such as procedure strings <ref> [17] </ref>. Unfortunately, the idea of polyvariance, and indeed any formulation of program analysis that involves only a refinement of the notion of "program point," is fundamentally limited.
Reference: [18] <author> Paul Hudak and Jonathan Young. </author> <title> Collecting interpretations of expressions. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 13(2) </volume> <pages> 269-190, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: Typically, the construction of an analyzer begins with a so-called "concrete" or "collecting" semantics <ref> [11, 18] </ref> in which programs are assigned meanings of the form C 2 Label ! -(State ) where -(State) is the powerset of program states.
Reference: [19] <author> Suresh Jagannathan and Stephen Weeks. </author> <title> A unified treatment of flow analysis in higher-order languages. </title> <booktitle> In Proceedings of the 22 nd ACM Symposium on Principles of Programming Languages, </booktitle> <year> 1995. </year>
Reference-contexts: Also appealing is the fact that it is straightforward to extend this idea and keep track of, say, the last two calling points instead of just the last one, or in general the last k for some finite k <ref> [19, 27] </ref>. Indeed, there is quite a bit of room for creativity here, as the only real requirement on the set Point is that its elements must have finite descriptions. Some recent proposals have used fairly complex mechanisms such as procedure strings [17].
Reference: [20] <author> N. D. Jones and S. S. Muchnick. </author> <title> Flow analysis and optimization of LISP-like structures. </title> <booktitle> In Sixth Annual ACM Symposium on Principles of Programming Languages, </booktitle> <address> San Antonio, Texas, </address> <pages> pages 244-256, </pages> <month> January </month> <year> 1979. </year>
Reference-contexts: Examples of the kinds of properties that are useful in practice include: * The pairs of data objects that may or must be aliases at a given label [3, 14]. * Grammars giving all of the possible shapes of structured data at a given label <ref> [12, 20] </ref>. * Linear relationships amongst integer-valued variables (e.g., x = y z) at a given label [16, 21]. <p> Indeed, it is easy to see that the technique of "unroll once and then do constant propagation" is not very general, and in fact does not work for the purpose of software pipelining. Abstract interpretation, on the other hand, clearly aided the solution to control-flow analysis of higher-order functions <ref> [20, 27] </ref>. Even further, it is difficult to imagine many of the more advanced alias and storage analyses (e.g., [14, 6]) without abstract interpretation, and nor is it likely that the analyses of concurrency in [5, 4] would have been found.
Reference: [21] <author> M. Karr. </author> <title> Affine relationships among variables of a program. </title> <journal> Acta Informatica, </journal> <volume> 6 </volume> <pages> 133-151, </pages> <year> 1976. </year>
Reference-contexts: * The pairs of data objects that may or must be aliases at a given label [3, 14]. * Grammars giving all of the possible shapes of structured data at a given label [12, 20]. * Linear relationships amongst integer-valued variables (e.g., x = y z) at a given label <ref> [16, 21] </ref>. Typically, the construction of an analyzer begins with a so-called "concrete" or "collecting" semantics [11, 18] in which programs are assigned meanings of the form C 2 Label ! -(State ) where -(State) is the powerset of program states.
Reference: [22] <author> Monica Lam. </author> <title> Software pipelining: An effective scheduling technique for VLIW machines. </title> <booktitle> In SIGPLAN'88 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 318-328, </pages> <month> June </month> <year> 1988. </year>
Reference-contexts: Determining precise information about loops, however, is often of critical importance for static optimization of code. One of the most striking examples is software pipelin-ing <ref> [2, 22] </ref>, a strategy for statically transforming the structure of a loop in order to take advantage of the potential instruction-level parallelism both within a single iteration and between adjacent iterations. <p> In this section, we demonstrate this by showing how a form of software pipelining can be developed using a transfer transition system. Software pipelining is a program transformation on loops that attempts to exploit instruction-level parallelism in superscalar and VLIW architectures <ref> [2, 22] </ref>.
Reference: [23] <author> Torben Mogensen. </author> <title> Binding time analysis for polymorphically typed higher order languages. </title> <editor> In J. Diaz and F. Orejas, editors, </editor> <booktitle> TAPSOFT '89. Proc. Int. Conf. Theory and Practice of Software Development, Barcelona, Spain, March 1989 (Lecture Notes in Computer Science, </booktitle> <volume> vol. 352), </volume> <pages> pages 298-312. </pages> <publisher> Springer-Verlag, </publisher> <year> 1989. </year> <month> 24 </month>
Reference-contexts: In the literature, this idea is sometimes informally referred to as polyvariance <ref> [7, 23] </ref> and is also closely related to the notion of cloning in dataflow analysis. A common form of polyvariance involves partitioning certain blocks of code, such as function bodies or loop bodies, by the label that preceded their entry.
Reference: [24] <author> Alan Mycroft. </author> <title> Abstract Interpretation and Optimising Transformations for Applicative Pro--grams. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, University of Edinburgh, </institution> <address> Scotland, </address> <year> 1981. </year>
Reference-contexts: Some special cases of program analyses, such as strictness analysis <ref> [24, 29] </ref>, can be formalized quite elegantly and compositionally using a denotational model, and a general framework for denotational-semantics-based analysis has been developed in [25].
Reference: [25] <author> Flemming Nielson. </author> <title> Strictness analysis and denotational abstract interpretation. </title> <journal> Information and Computation, </journal> <volume> 76(1) </volume> <pages> 29-92, </pages> <month> January </month> <year> 1988. </year>
Reference-contexts: Some special cases of program analyses, such as strictness analysis [24, 29], can be formalized quite elegantly and compositionally using a denotational model, and a general framework for denotational-semantics-based analysis has been developed in <ref> [25] </ref>. However, many program analyses are concerned with details of the actual computation process itself and thus must be based on an operational model, making it difficult to analyze a program compositionally. Again, this is a serious problem in practice.
Reference: [26] <author> Gordon Plotkin. </author> <title> A structural approach to operational semantics. </title> <type> Technical Report DAIMI-FN-19, </type> <institution> Computer Science Department, Aarhus University, </institution> <year> 1981. </year>
Reference-contexts: In a programming language with a looping construct, the semantic meaning is usually modeled by infinite structures. For example, denotational semantics [28] uses limits of infinite chains to model the meaning of recursive functions. In standard formulations of structural operational semantics <ref> [26] </ref> and small-step operational semantics [15], the behavior of loops is modeled by unbounded sequences of transitions. An analysis based on any of these semantic models is thus forced to develop some method for reasoning finitely about these (potentially) infinite objects.
Reference: [27] <author> Olin Shivers. </author> <title> Control-flow Analysis of Higher-Order Languages. </title> <type> PhD thesis, </type> <institution> Carnegie Mellon University, Pittsburgh, Pennsylvania, </institution> <month> May </month> <year> 1991. </year>
Reference-contexts: Also appealing is the fact that it is straightforward to extend this idea and keep track of, say, the last two calling points instead of just the last one, or in general the last k for some finite k <ref> [19, 27] </ref>. Indeed, there is quite a bit of room for creativity here, as the only real requirement on the set Point is that its elements must have finite descriptions. Some recent proposals have used fairly complex mechanisms such as procedure strings [17]. <p> Indeed, it is easy to see that the technique of "unroll once and then do constant propagation" is not very general, and in fact does not work for the purpose of software pipelining. Abstract interpretation, on the other hand, clearly aided the solution to control-flow analysis of higher-order functions <ref> [20, 27] </ref>. Even further, it is difficult to imagine many of the more advanced alias and storage analyses (e.g., [14, 6]) without abstract interpretation, and nor is it likely that the analyses of concurrency in [5, 4] would have been found.
Reference: [28] <author> Joseph E. Stoy. </author> <title> Denotational Semantics : The Scott-Strachey Approach to Programming Language Theory. </title> <publisher> MIT Press, </publisher> <year> 1977. </year>
Reference-contexts: Loops have long been the bane of semantics-based program analysis. In a programming language with a looping construct, the semantic meaning is usually modeled by infinite structures. For example, denotational semantics <ref> [28] </ref> uses limits of infinite chains to model the meaning of recursive functions. In standard formulations of structural operational semantics [26] and small-step operational semantics [15], the behavior of loops is modeled by unbounded sequences of transitions.
Reference: [29] <author> Philip Wadler and R. J. M. Hughes. </author> <title> Projections for strictness analysis. </title> <booktitle> In Third International Conference on Functional Programming and Computer Architecture, </booktitle> <year> 1987. </year> <month> 25 </month>
Reference-contexts: Some special cases of program analyses, such as strictness analysis <ref> [24, 29] </ref>, can be formalized quite elegantly and compositionally using a denotational model, and a general framework for denotational-semantics-based analysis has been developed in [25].
References-found: 29

