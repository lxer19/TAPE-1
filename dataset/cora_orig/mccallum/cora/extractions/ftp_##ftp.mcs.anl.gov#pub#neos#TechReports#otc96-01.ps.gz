URL: ftp://ftp.mcs.anl.gov/pub/neos/TechReports/otc96-01.ps.gz
Refering-URL: http://www.mcs.anl.gov/otc/Guide/TechReports/index.html
Root-URL: http://www.mcs.anl.gov
Title: OPTIMIZATION TECHNOLOGY CENTER PCx User Guide 1  
Author: by Joseph Czyzyk, Sanjay Mehrotra, and Stephen J. Wright 
Date: February 19, 1997  
Pubnum: Technical Report OTC 96/01  
Abstract: We describe the code PCx, a primal-dual interior-point code for linear programming. Information is given about problem formulation and the underlying algorithm, along with instructions for installing, invoking, and using the code. Computational results on standard test problems are tabulated. The current version number is 1.0. Key words: linear programming, interior-point methods, software. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> E. D. Andersen and K. D. Andersen, </author> <title> Presolving in linear programming, </title> <journal> Mathematical Programming, </journal> <volume> 71 (1995), </volume> <pages> pp. 221-245. </pages>
Reference-contexts: The scalar oe 2 <ref> [0; 1] </ref> in (12) is chosen by a complicated heuristic that is based on the ability of the pure affine-scaling step to attain large reductions in the duality measure before reaching the 4 boundary of the positive orthant for the (x; s; r; w) components. <p> Given the affine-scaling step, we calculate the maximum step to this boundary in primal and dual variables from the definitions ff aff;P = inffff 2 <ref> [0; 1] </ref> j (x; w) + ff (x aff ; w aff ) 0g; (14a) ff aff;D = inffff 2 [0; 1] j (s; r) + ff (s aff ; r aff ) 0g: (14b) We then compute the duality measure aff at this point as aff = 2n (x + <p> Given the affine-scaling step, we calculate the maximum step to this boundary in primal and dual variables from the definitions ff aff;P = inffff 2 <ref> [0; 1] </ref> j (x; w) + ff (x aff ; w aff ) 0g; (14a) ff aff;D = inffff 2 [0; 1] j (s; r) + ff (s aff ; r aff ) 0g: (14b) We then compute the duality measure aff at this point as aff = 2n (x + ff aff;P x) T (s + ff aff;D s) + (w + ff aff;P w) T (r + ff aff;D <p> Similarly to (14), we calculate ff max;P = inf fff 2 <ref> [0; 1] </ref> j (x; w) + ff (x; w) 0g; (18a) and set where fl P and fl D are two scaling factors obtained from Mehrotra's adaptive steplength heuristic [6, p. 588]. <p> Presolvers significantly enhance the efficiency and robustness of both simplex and interior-point codes. The presolver in PCx works with the formulation (1) stored in the LPtype data structure. It makes use of techniques described by Andersen and Andersen <ref> [1] </ref>, checking the data for the following features: Infeasibility. Check that u i 0 for each upper bound u i , i 2 U , and that a zero row of A has a corresponding zero in the right-hand side vector b. Empty Rows. <p> Forced Rows. Sometimes, the linear constraint represented by row i of A forces all its variables to either their upper or lower bounds. An example would be the constraint 10x 3 4x 10 + x 12 = 4 subject to the bounds x 3 2 <ref> [0; +1); x 10 2 [0; 1] </ref>; x 12 2 [0; +1): In this case, we must have x 3 = 0, x 10 = 1 and x 12 = 0, so these three variables (and the corresponding row of A) can be eliminated. <p> Sometimes, the linear constraint represented by row i of A forces all its variables to either their upper or lower bounds. An example would be the constraint 10x 3 4x 10 + x 12 = 4 subject to the bounds x 3 2 [0; +1); x 10 2 <ref> [0; 1] </ref>; x 12 2 [0; +1): In this case, we must have x 3 = 0, x 10 = 1 and x 12 = 0, so these three variables (and the corresponding row of A) can be eliminated.
Reference: [2] <author> J. R. Gilbert, E. Ng, and B. W. Peyton, </author> <title> An efficient algorithm to compute row and column counts for sparse cholesky factorization, </title> <journal> SIAM Journal on Matrix Analysis and Applications, </journal> <volume> 15 (1994), </volume> <pages> pp. 1075-1091. </pages>
Reference-contexts: Ng and Peyton's code uses a multiple minimum degree ordering strategy identical to the one in SPARSPAK. This strategy was introduced by Liu [4]. The scheme used for symbolic factorization is partly described by Liu [5] and Gilbert, Ng, and Peyton <ref> [2] </ref>. The numerical factorization is performed by a left-looking block sparse Cholesky algorithm, as described by Ng and Peyton [7].
Reference: [3] <author> J. Gondzio, </author> <title> Multiple centrality corrections in a primal-dual method for linear programming, </title> <journal> Computational Optimization and Applications, </journal> <volume> 6 (1996), </volume> <pages> pp. 137-156. 23 </pages>
Reference-contexts: 1 Introduction PCx is a linear programming solver developed at the Optimization Technology Center at Ar-gonne National Laboratory and Northwestern University. It implements a variant of Mehrotra's predictor-corrector algorithm [6] with the higher-order correction strategy of Gondzio <ref> [3] </ref>. This primal-dual approach has proved to be the most efficient interior-point method for general linear programs. The bulk of PCx is written in the C programming language. However, its main computational engine|the sparse Cholesky code of Ng and Peyton [7]|is coded in Fortran 77. <p> At the user's request, Gondzio's <ref> [3] </ref> higher-order correction strategy be used to enhance the search direction at each iteration. In this approach, additional centering/correction directions are computed by solving (9) for different right-hand sides. <p> Default: 3.0. dualfeastol fvalueg Specify a dual feasibility tolerance. Default: 10 8 . history fyesg/fnog Request that a history file be written (yes) or not written (no). If yes, the file probname.log is written to the working directory (see Section 8). HOCorrections fyesg/fnog Request that Gondzio's <ref> [3] </ref> higher-order corrections be used to en hance the search direction. Default: no. inputdirectory fnameg Give the directory here if PCx is to search for the MPS input files in some directory other than the working directory, give the directory here. Remember to include a trailing "/". <p> Part of the reason is that the factorization routine is more efficient relative to the solution routine than is the case in, for example, HOPDM (see Gondzio <ref> [3] </ref>). It follows that there is less to be gained by economizing on matrix factorizations. Significant improvements can however be observed on several problems, including dfl001, pds-10, NEMSemm1, and NEMSwrld.
Reference: [4] <author> J. W.-H. Liu, </author> <title> Modification of the minimum degree algorithm by multiple elimination, </title> <journal> ACM Transactions on Mathematical Software, </journal> <volume> 11 (1985), </volume> <pages> pp. </pages> <month> 141-153. </month> <title> [5] , The role of elimination trees in sparse factorization, </title> <journal> SIAM Journal on Matrix Analysis and Applications, </journal> <volume> 11 (1990), </volume> <pages> pp. 134-172. </pages>
Reference-contexts: Ng and Peyton's code uses a multiple minimum degree ordering strategy identical to the one in SPARSPAK. This strategy was introduced by Liu <ref> [4] </ref>. The scheme used for symbolic factorization is partly described by Liu [5] and Gilbert, Ng, and Peyton [2]. The numerical factorization is performed by a left-looking block sparse Cholesky algorithm, as described by Ng and Peyton [7].
Reference: [6] <author> S. Mehrotra, </author> <title> On the implementation of a primal-dual interior point method, </title> <journal> SIAM Journal on Optimization, </journal> <volume> 2 (1992), </volume> <pages> pp. 575-601. </pages>
Reference-contexts: 1 Introduction PCx is a linear programming solver developed at the Optimization Technology Center at Ar-gonne National Laboratory and Northwestern University. It implements a variant of Mehrotra's predictor-corrector algorithm <ref> [6] </ref> with the higher-order correction strategy of Gondzio [3]. This primal-dual approach has proved to be the most efficient interior-point method for general linear programs. The bulk of PCx is written in the C programming language. <p> 0; i = 1; 2; : : :; n; (8e) We stress that the PCx code actually works with the formulation (2); we use the simpler form (6) in our discussion solely to avoid creating a notational jungle in the next few sections. 3 3 The Algorithm Mehrotra's predictor-corrector algorithm <ref> [6] </ref> is based on Newton's method for the KKT conditions (4a)-(4e), modified to retain positivity of the (x; s; r; w) components, to incorporate a "centering" component in the search direction, and to improve the order of accuracy to which the search direction approximates the nonlinear equations (4d) and (4e). <p> Similarly to (14), we calculate ff max;P = inf fff 2 [0; 1] j (x; w) + ff (x; w) 0g; (18a) and set where fl P and fl D are two scaling factors obtained from Mehrotra's adaptive steplength heuristic <ref> [6, p. 588] </ref>. <p> If the solution file is written, it is named probname.out and is placed in the working directory (see Section 8). Default: yes. stepfactor fvalueg Specify a value in the range (0; 1) that is used in Mehrotra's adaptive steplength heuristic from <ref> [6, p. 118] </ref>. This value is a lower bound for fl P and fl D in (19). Default: 0:9. unrollinglevel fvalueg Specify the level of loop unrolling. Allowable values are 1, 2, 4, and 8. (This parameter is used only in the Ng-Peyton sparse Cholesky code.) Default: 4.
Reference: [7] <author> E. Ng and B. W. Peyton, </author> <title> Block sparse Cholesky algorithms on advanced uniprocessor computers, </title> <journal> SIAM Journal on Scientific Computing, </journal> <volume> 14 (1993), </volume> <pages> pp. 1034-1056. </pages>
Reference-contexts: Section 3 describes the algorithm, including details of termination and infeasibility detection. Section 4 discusses the major computational issue in the code|factorization of a sparse, positive definite matrix|including the modifications to the Ng-Peyton code <ref> [7] </ref> needed in this context. Presolver capabilities are outlined in Section 5. Section 7 contains instructions for installing the code in a Unix environment, while instructions for invoking PCx as a stand-alone solver are given in Section 8. <p> These factorizations and triangular substitutions dominate the computational cost of the algorithm. The factorization is carried out with the sparse Cholesky code of Ng and Peyton <ref> [7] </ref>, modified slightly to handle the small pivot elements that frequently arise during later iterations of the interior-point method. <p> This strategy was introduced by Liu [4]. The scheme used for symbolic factorization is partly described by Liu [5] and Gilbert, Ng, and Peyton [2]. The numerical factorization is performed by a left-looking block sparse Cholesky algorithm, as described by Ng and Peyton <ref> [7] </ref>. The code exploits hierarchical memory by splitting the supernodes into blocks that fit into available cache. (Cache size is passed to the code as a parameter.) Loop unrolling is used to make better use of registers.
Reference: [8] <author> S. J. Wright, </author> <title> The Cholesky factorization in interior-point and barrier methods, </title> <type> Preprint MCS-P600-0596, </type> <institution> Mathematics and Computer Science Division, Argonne National Laboratory, Argonne, Ill., </institution> <month> May </month> <year> 1996. </year> <title> [9] , Primal-Dual Interior-Point Methods, </title> <publisher> SIAM Publications, </publisher> <address> Philadelphia, Pa, </address> <year> 1996. </year> <note> To appear. </note>
Reference-contexts: This substitution causes the off-diagonal elements in the ith column of the Cholesky factor L to be extremely small (essentially zero) and causes the ith component of the solution vector to be extremely small. Analysis of this technique has been performed by Wright <ref> [8] </ref>. A similar pivot modification strategy is used by the MATLAB-based code LIPSOL (see Zhang [10],[11]), which also uses Ng and Peyton's code as its computational engine.
Reference: [10] <author> Y. Zhang, </author> <title> User's Guide to LIPSOL, </title> <institution> Department of Mathematics and Statistics, University of Maryland Baltimore County, Baltimore, Maryland, </institution> <month> July </month> <year> 1995. </year> <title> [11] , Solving large-scale linear programs by interior-point methods under the MATLAB en-viroment, </title> <type> Technical Report TR96-01, </type> <institution> Department of Mathematics and Statistics, University of Maryland Baltimore County, Baltimore, Md, </institution> <year> 1996. </year>
Reference: [12] <institution> Annual Energy Outlook 1996, Energy Information Administration, U. S. Department of Energy, </institution> <address> Washington, DC 20585, </address> <year> 1996. </year> <note> Document DOE/EIA-0383(96). 24 </note>
Reference-contexts: In two cases, infeasibility was detected by the preprocessor, so the interior-point solver did not need to be called at all. The NEMS problems are instances of models in the National Energy Modeling System (NEMS) of the Energy Information Administration of the United States Department of Energy <ref> [12] </ref>. These problems are taken from NEMS modules which are used to model electricity capacity planning, petroleum marketing, and coal marketing. PCx solved these problems efficiently, as shown in Tables 3 and 6 Note that the improvements obtained by using second-order corrections are not too dramatic.
References-found: 9

