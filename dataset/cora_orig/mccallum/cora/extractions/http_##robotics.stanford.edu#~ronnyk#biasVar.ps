URL: http://robotics.stanford.edu/~ronnyk/biasVar.ps
Refering-URL: http://robotics.stanford.edu/users/ronnyk/ronnyk-bib.html
Root-URL: 
Email: ronnyk@sgi.com  dhw@santafe.edu  
Title: Bias Plus Variance Decomposition for Zero-One Loss Functions  
Author: Ron Kohavi David H. Wolpert 
Address: 2011 N. Shoreline Blvd Mountain View, CA 94043-1389  1399 Hyde Park Rd. Santa Fe, NM 87501  
Affiliation: Data Mining and Visualization Silicon Graphics, Inc.  The Santa Fe Institute  
Date: 1996  
Note: To appear in Machine Learning: Proceedings of the Thirteenth International Conference,  
Abstract: We present a bias-variance decomposition of expected misclassification rate, the most commonly used loss function in supervised classification learning. The bias-variance decomposition for quadratic loss functions is well known and serves as an important tool for analyzing learning algorithms, yet no decomposition was offered for the more commonly used zero-one (misclassification) loss functions until the recent work of Kong & Dietterich (1995) and Breiman (1996). Their decomposition suffers from some major shortcomings though (e.g., potentially negative variance), which our decomposition avoids. We show that, in practice, the naive frequency-based estimation of the decomposition terms is by itself biased and show how to correct for this bias. We illustrate the decomposition on various algorithms and datasets from the UCI repository.
Abstract-found: 1
Intro-found: 1
Reference: <author> Ali, K. M. </author> <year> (1996), </year> <title> Learning Probabilistic Relational Concept Descriptions, </title> <type> PhD thesis, </type> <institution> University of California, </institution> <address> Irvine. http://www.ics.uci.edu/~ali. </address>
Reference: <author> Breiman, L. </author> <year> (1994a), </year> <institution> Bagging predictors, Technical Report Statistics Department, University of Cal-ifornia at Berkeley. </institution>
Reference: <author> Breiman, L. </author> <year> (1994b), </year> <title> Heuristics of instability in model selection, </title> <institution> Technical Report Statistics Department, University of California at Berkeley. </institution>
Reference-contexts: Minor variations in the training set may cause a different split, which might change the whole subtree. As a consequence, decision trees are very unstable, and therefore they usually gain by ag gregation techniques <ref> (Breiman 1994b) </ref>. Note also that the smaller the internal sample, the more bias we potentially add (Gordon & Olshen 1984) but the more different the classifiers will be, leading to a more stable average.
Reference: <author> Breiman, L. </author> <year> (1996), </year> <title> Bias, variance, and arcing classifiers, </title> <type> Technical report, </type> <institution> Statistics Department, University of California, Berkeley. </institution> <note> Available at: http://www.stat.Berkeley.EDU/users/breiman/. </note>
Reference: <author> Cover, T. M. & Thomas, J. A. </author> <year> (1991), </year> <title> Elements of Information Theory, </title> <publisher> John Wiley & Sons, Inc. </publisher>
Reference-contexts: the two ways of estimating the bias (estimating for each set of n training sets and then averaging, minus estimating based on the full set of N = 2n training sets): E 1 P 2 i=1;2 w i 1 P fi E T 1 P 2 : By Jensen's inequality <ref> (Cover & Thomas 1991) </ref>, the first term on the right hand side is larger or equal to the second term. This shows that when we average once (over 2n instances) rather than twice (over n instances) we get a smaller estimate for the bias 2 , which establishes the proposition.
Reference: <author> Dietterich, T. G. & Kong, E. B. </author> <year> (1995), </year> <title> Machine learning bias, statistical bias, and statistical variance of decision tree algorithms, </title> <type> Technical report, </type> <institution> Department of Computer Science, Oregon State University. </institution>
Reference: <author> Efron, B. & Tibshirani, R. </author> <year> (1993), </year> <title> An Introduction to the Bootstrap, </title> <publisher> Chapman & Hall. </publisher>
Reference: <author> Geman, S., Bienenstock, E. & Doursat, R. </author> <year> (1992), </year> <title> "Neural networks and the bias/variance dilemma", </title> <booktitle> Neural Computation 4, </booktitle> <pages> 1-48. </pages>
Reference-contexts: 1 Introduction The bias plus variance decomposition <ref> (Geman, Bi-enenstock & Doursat 1992) </ref> is a powerful tool from sampling theory statistics for analyzing supervised learning scenarios that have quadratic loss functions.
Reference: <author> Gordon, L. & Olshen, R. </author> <year> (1984), </year> <title> "Almost sure consistent nonparametric regression from recursive partitioning schemes", </title> <journal> Journal of Multivariate Analysis 15, </journal> <pages> 147-163. </pages>
Reference-contexts: As a consequence, decision trees are very unstable, and therefore they usually gain by ag gregation techniques (Breiman 1994b). Note also that the smaller the internal sample, the more bias we potentially add <ref> (Gordon & Olshen 1984) </ref> but the more different the classifiers will be, leading to a more stable average. Our results show that in this voting scheme, the reduction in error is almost solely due to the reduction in variance.
Reference: <author> Kong, E. B. & Dietterich, T. G. </author> <year> (1995), </year> <title> Error-correcting output coding corrects bias and variance, </title> <editor> in A. Prieditis & S. Russell, eds, </editor> <booktitle> "Machine Learning: Proceedings of the Twelfth International Conference", </booktitle> <publisher> Morgan Kaufmann Publishers, Inc., </publisher> <pages> pp. 313-321. </pages>
Reference: <author> Murphy, P. M. & Aha, D. W. </author> <year> (1996), </year> <note> UCI repository of machine learning databases, http://www.ics.uci.edu/~mlearn. </note>
Reference-contexts: with a description of our experimental methodology, and then discuss a problem with the naive estimation of the terms in our decomposition by using frequency counts. 4.1 Our frequency counts experiments To investigate the behavior of the terms in our decomposition, we ran a set of experiments on UCI repository <ref> (Murphy & Aha 1996) </ref>. In each of those experiments, for a given dataset and a given learning algorithm, we estimated (the x-average of) bias 2 , variance, intrinsic noise, and overall error as follows. 1. We randomly divided each dataset into two parts, D and E. <p> In practice though, we always had enough data so that negative bias 2 estimates never occurred. 4.3 The Experiments We now present experiments demonstrating the bias and variance of induction algorithms for datasets from the UCI repository <ref> (Murphy & Aha 1996) </ref>. The datasets were chosen so that they contain at least 500 instances (to ensure accurate estimates of error) and notation NN-k indicates vote among the k closest neighbors. Table 1: The Datasets and their characteristics Dataset No.
Reference: <author> Perrone, M. </author> <year> (1993), </year> <title> Improving regression estimation: averaging methods for variance reduction with extensions to general convex measure optimization, </title> <type> PhD thesis, </type> <institution> Brown University, Physics Dept. </institution>
Reference: <author> Quinlan, J. R. </author> <year> (1986), </year> <title> "Induction of decision trees", </title> <booktitle> Machine Learning 1, </booktitle> <pages> 81-106. </pages> <note> Reprinted in Shav-lik and Dietterich (eds.) Readings in Machine Learning. </note>
Reference-contexts: sets and estimated the terms in Equation 3 and 4 using the generated classifier for each point x in the evaluation set E. (Equation 4 was used to estimate p (y H jf; m; x).) At first, all these terms were estimated using frequency counts. values of N when ID3 <ref> (Quinlan 1986) </ref> was executed on three datasets from the UCI repository. It is clear that our estimate of bias 2 using frequency counts shrinks as we increase N .
Reference: <author> Wolpert, D. </author> <note> (submitted), On bias plus variance, SFI TR 95-08-074 in ftp.santafe.edu/pub/dhw ftp/bias.plus.ps. </note>
Reference: <author> Wolpert, D. H. </author> <year> (1992), </year> <title> "Stacked generalization", </title> <booktitle> Neural Networks 5, </booktitle> <pages> 241-259. </pages>
Reference-contexts: other goes down as a parameter of the induction algorithm is varied, we can see examples where both change in the same direction. 4.5 Combining Classifiers There has been a lot of work recently on combining classifiers, with the terms aggregation, averages, ensembles, classifier combinations, voting, and stacking commonly used <ref> (Wolpert 1992, Breiman 1994a, Perrone 1993, Ali 1996) </ref>. In the simplest scheme, multiple classifiers are generated and then vote for each test instance, with the majority prediction used as the final prediction. ID3.
Reference: <author> Wolpert, D. H. </author> <year> (1994), </year> <title> The relationship between PAC, the statistical physics framework, the Bayesian framework, and the VC framework, </title> <editor> in D. </editor> <publisher> H. </publisher>
Reference: <author> Wolpert, ed., </author> <title> "The Mathemtatics of Generalization", </title> <publisher> Addison Wesley. </publisher>
References-found: 17

