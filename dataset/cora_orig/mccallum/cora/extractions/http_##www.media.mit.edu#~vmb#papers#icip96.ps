URL: http://www.media.mit.edu/~vmb/papers/icip96.ps
Refering-URL: http://www.media.mit.edu/~vmb/
Root-URL: http://www.media.mit.edu
Email: fechalom,vmbg@media.mit.edu  
Title: SEGMENTATION OF AN IMAGE SEQUENCE USING MULTI-DIMENSIONAL IMAGE ATTRIBUTES (PROC. ICIP-96)  
Author: Edmond Chalom and V. Michael Bove, Jr. 
Address: 20 Ames St., Cambridge, MA 02139, USA  
Affiliation: MIT Media Laboratory,  
Abstract: Whether for purposes of compression efficiency, image editing, interactive multimedia authoring, or database search, it is often useful to be able to segment images or image sequences into regions corresponding to objects. In this paper we describe a segmentation scheme that takes account of multiple image characteristics, developing a multi-modal statistical model of regions based on a small amount of user-supplied training data. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. Kunt, A. Ikonomopoulos and M. Kocher, </author> <title> "Second-Generation Image-Coding Techniques," </title> <booktitle> Proc. IEEE 73(4), </booktitle> <pages> pp. 549-574, </pages> <year> 1985. </year>
Reference-contexts: 1. INTRODUCTION Researchers have shown the compression advantages of coding video as a set of regions that can be defined by motion or texture models. <ref> [1] </ref>, [2], [3] Segmentation of video can likewise enable special effects (e.g. placing actors into a synthetic set) or authoring of interactive or personalizable programming. [4] In cases where semantics are as important as compression, though, one finds that generally objects in the real world do not correspond to a simple
Reference: [2] <author> E. A. Adelson and J. Y. A. Wang, </author> <title> "Representing Moving Images with Layers," </title> <journal> IEEE Trans. on Image Processing, </journal> <volume> 3, </volume> <pages> pp. 625-638, </pages> <month> Sept. </month> <year> 1994. </year>
Reference-contexts: 1. INTRODUCTION Researchers have shown the compression advantages of coding video as a set of regions that can be defined by motion or texture models. [1], <ref> [2] </ref>, [3] Segmentation of video can likewise enable special effects (e.g. placing actors into a synthetic set) or authoring of interactive or personalizable programming. [4] In cases where semantics are as important as compression, though, one finds that generally objects in the real world do not correspond to a simple clustering <p> In particular, it is possible to estimate the motion at every pixel directly from the observation data using a dense optical flow technique [8], [9] (indeed, a further transformation which would produce a higher-level motion model might be applied <ref> [2] </ref>). It is also possible to estimate texture information using local statistics on luminance values or other techniques such as SAR, [10] or steer-able filters, [11] which depend only on the raw image data.
Reference: [3] <author> M. Irani, S. Hsu, and P. Anandan, </author> <title> "Mosaic-Based Video Compression," </title> <booktitle> Proc. SPIE Digital Video Compression: Algorithms and Technologies 1995, </booktitle> <volume> 2419, </volume> <pages> pp. 242-253, </pages> <year> 1995. </year>
Reference-contexts: 1. INTRODUCTION Researchers have shown the compression advantages of coding video as a set of regions that can be defined by motion or texture models. [1], [2], <ref> [3] </ref> Segmentation of video can likewise enable special effects (e.g. placing actors into a synthetic set) or authoring of interactive or personalizable programming. [4] In cases where semantics are as important as compression, though, one finds that generally objects in the real world do not correspond to a simple clustering model
Reference: [4] <author> V. M. Bove, Jr., </author> <title> "Object-Oriented Television," </title> <journal> SMPTE Journal, </journal> <volume> 104, </volume> <pages> pp. 803-807, </pages> <month> Dec. </month> <year> 1995. </year>
Reference-contexts: 1. INTRODUCTION Researchers have shown the compression advantages of coding video as a set of regions that can be defined by motion or texture models. [1], [2], [3] Segmentation of video can likewise enable special effects (e.g. placing actors into a synthetic set) or authoring of interactive or personalizable programming. <ref> [4] </ref> In cases where semantics are as important as compression, though, one finds that generally objects in the real world do not correspond to a simple clustering model of a single parameter like motion; it is also true that the desired segmentation is a function of the application formatting purposes it
Reference: [5] <author> E. Chalom and V. M. Bove, Jr., </author> <title> "Segmentation of Frames in a Video Sequence Using Motion and Other Attributes", </title> <booktitle> SPIE Digital Video Compression: Algorithms and Technologies, </booktitle> <volume> 2419, </volume> <pages> pp. 230-241, </pages> <year> 1995. </year>
Reference-contexts: In previous work we have demonstrated segmentation based on a collection of image attributes. <ref> [5] </ref> This research also showed that supervised methods generally perform better than unsupervised algorithms, while simultaneously offering greater flexibility by permitting the user to define in advance the desired segmentation by indicating a few representative points corresponding to each region.
Reference: [6] <author> S. Tanveer F. Mahmood, </author> <title> "Attentional Selection In Object Recognition", </title> <type> TR #1420, </type> <institution> MIT Artificial Intelligence Laboratory, </institution> <month> Feb., </month> <year> 1993. </year>
Reference-contexts: FEATURE SELECTION It is a natural, and almost unnoticed process for the human perceptual system adaptively to identify portions of a visual image as belonging to coherent objects in the world, based on a variety of static and dynamic image attributes. <ref> [6] </ref> Merely calculating some of these attributes remains a substantial task for machines, and even as increased computational power makes it easier, the greater task remains of intelligently assimilating the results (or "features") in order to perform higher level image processing tasks.
Reference: [7] <author> Charles W. Therrien, </author> <title> Decision Estimation And Classification, </title> <publisher> John Wiley and Sons, Inc., </publisher> <year> 1989. </year>
Reference-contexts: In this paper, the original raw image data is considered as a set of "observation" samples (or a vector of observations), and a "feature" vector is defined to be the result of a transformation or calculation applied to the observation vector. <ref> [7] </ref> The ideal feature space is one which simplifies the object segmentation process. <p> Similarly the optimal tri-modal mixture model will fit the data better than the optimal bi-modal. In fact it is clear from information theory [12], <ref> [7] </ref> that if an optimal N -modal mixture model is used, it will fit the training data precisely. The problem, however, is in determining the underlying PDF, for each feature, of all the data points (of a particular region) including both the "labeled" training data and the "unlabeled" data. <p> This type of problem is often referred to as maximum a posteriori or MAP hypothesis testing. <ref> [7] </ref> At each unlabeled sample point of the image we want to assign the sample to class or region R i that maximizes the a posteriori probability, P (R i jf ), where f is the feature vector, e.g. motion, color, texture, and position value at the corresponding location.
Reference: [8] <author> B.K.P. Horn, and B.G. Schunck, </author> <title> "Determining Optical Flow", AI Memo, AI Lab, </title> <publisher> MIT, </publisher> <month> April </month> <year> 1980. </year>
Reference-contexts: In a sense, there is more information embedded in the image sequence than meets the eye. In particular, it is possible to estimate the motion at every pixel directly from the observation data using a dense optical flow technique <ref> [8] </ref>, [9] (indeed, a further transformation which would produce a higher-level motion model might be applied [2]). It is also possible to estimate texture information using local statistics on luminance values or other techniques such as SAR, [10] or steer-able filters, [11] which depend only on the raw image data.
Reference: [9] <author> J.R. Bergen, P.J. Burt, R. Hingorani, and S. Peleg, </author> <title> "Computing two motions from three frames", </title> <type> Technical Report, </type> <institution> David Sarnoff Research Center, </institution> <year> 1990. </year>
Reference-contexts: In a sense, there is more information embedded in the image sequence than meets the eye. In particular, it is possible to estimate the motion at every pixel directly from the observation data using a dense optical flow technique [8], <ref> [9] </ref> (indeed, a further transformation which would produce a higher-level motion model might be applied [2]). It is also possible to estimate texture information using local statistics on luminance values or other techniques such as SAR, [10] or steer-able filters, [11] which depend only on the raw image data.
Reference: [10] <author> Jianchang Mao and Anil K. Jain, </author> <title> "Texture Classification And Segmentation Using Multiresolution Simultaneous Autoregressive Models", </title> <journal> Pattern Recognition, </journal> <volume> 25(2), </volume> <pages> pp. 173-188, </pages> <year> 1992. </year>
Reference-contexts: It is also possible to estimate texture information using local statistics on luminance values or other techniques such as SAR, <ref> [10] </ref> or steer-able filters, [11] which depend only on the raw image data. Color and luminance information, as well as row and column positions at each pixel, can also be used as features, and require no additional calculation since it is obtained directly from the image data.
Reference: [11] <author> William T. Freeman and Edward H. Adelson, </author> <title> "The Design and Use of Steerable Filters", </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 13(9), </volume> <pages> pp. 891-906, </pages> <month> September, </month> <year> 1991. </year>
Reference-contexts: It is also possible to estimate texture information using local statistics on luminance values or other techniques such as SAR, [10] or steer-able filters, <ref> [11] </ref> which depend only on the raw image data. Color and luminance information, as well as row and column positions at each pixel, can also be used as features, and require no additional calculation since it is obtained directly from the image data.
Reference: [12] <author> Thomas M. Cover and Joy A. Thomas, </author> <title> Elements of Information Theory, </title> <publisher> John Wiley and Sons, Inc., </publisher> <year> 1991. </year> <title> "Table Tennis" image sequence with user selected training data points from 5 regions superimposed. Top Right: Segmentation result of frames 1,3,6, and 10, shown at half resolution, using training data from first frame only. Above Left: First frame from original "Dance" sequence. Above Right: Location of user selected training data points from 4 regions (black points are unlabeled). Left: Segmentation result of frames 1, 21, 40, and 60, shown at half resolution, using training data from first frame only. </title>
Reference-contexts: Similarly the optimal tri-modal mixture model will fit the data better than the optimal bi-modal. In fact it is clear from information theory <ref> [12] </ref>, [7] that if an optimal N -modal mixture model is used, it will fit the training data precisely. The problem, however, is in determining the underlying PDF, for each feature, of all the data points (of a particular region) including both the "labeled" training data and the "unlabeled" data.
Reference: [13] <author> Richard Redner and Homer E. Walker, </author> <title> "Mixture Densities, Maximum Likelihood and the EM Algorithm", </title> <journal> SIAM Review, </journal> <volume> 26(2), </volume> <pages> pp. 195-239, </pages> <month> April, </month> <year> 1984. </year>
Reference-contexts: By limiting the potential number of modes, m, and varying m from 1 to 5, for example, it is straightforward to calculate the parameters of the best fit to the training data, for each m-modal mixture model, using an Expectation-Maximization (EM) algorithm. <ref> [13] </ref> Given a set of parametric distribution models, the next step is to measure the entropy distance, (a.k.a. the Kullback-Leibler distance) between each of the models and the training data.
Reference: [14] <author> Paul A. Viola, </author> <title> "Alignment by Maximization of Mutual Information", </title> <type> TR #1548, </type> <institution> MIT Artificial Intelligence Laboratory, </institution> <month> June, </month> <year> 1995. </year>
Reference-contexts: The probability that model i is the correct model (where model i corresponds with the PDF distribution having i modes) is estimated by normalizing the derivative of the difference of entropy distances of two successive modes, with respect to m the number of modes. <ref> [14] </ref> In other words, if the PDF mixture model corresponding to 2 modes brings us dramatically closer to the training data than the 1-mode model, then there is a proportionally dramatic increase in the likelihood that the 2-mode model is indeed the correct model for our purposes, even though the 3-mode
References-found: 14

