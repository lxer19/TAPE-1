URL: http://www.iscs.nus.sg/~liuh/symbol.ps
Refering-URL: 
Root-URL: 
Email: frudys,liuhg@iscs.nus.sg  
Title: Draft Symbolic Representation of Neural Networks  
Author: Rudy Setiono and Huan Liu 
Address: Ridge, Singapore 0511  
Affiliation: Department of Information Systems and Computer Science National University of Singapore Kent  
Abstract: An early and shorter version of this paper has been accepted for presenta tion at IJCAI'95. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Cheng, </author> <title> U.M. Fayyad, K.B. Irani, and Z Qian. Improved decision trees: A generalized version of id3. </title> <booktitle> In Proceedings of the Fifth International Conference on Machine Learning, </booktitle> <pages> pages 100-106. </pages> <publisher> Morgan Kaufman, </publisher> <year> 1988. </year>
Reference-contexts: Figure next to a connection indicates the weight of that connection. been randomly generated in the interval <ref> [1; 1] </ref>. Each of the trained networks was pruned until its accuracy on the training data dropped below 95%. The weights and topology of networks with the smallest number of connections and an accuracy rate of more than 97% were saved for possible rule extraction. <p> If necessary, the intermediate process can also be explicitly explained by rules R ih and R ho . C4.5 and C4.5rules [12] were run on the above three datasets to generate DT rules. Briefly, C4.5 generates a decision tree which C4.5rules generalizes to rules. Since researchers <ref> [1, 17, 20] </ref> observed that mapping many-valued variables to two-valued variables results in decision trees with higher classification accuracy 3 , the same binary coded data for neural networks were used for C4.5 and C4.5rules. Being explicable is only one aspect of understandability.
Reference: [2] <author> T.G. Dietterich, H. Hild, and G. Bakiri. </author> <title> A comparative study of id3 and backpropagation for english text-to-speech mapping. </title> <booktitle> In Machine Learning: Proceedings of the Seventh International Conference. </booktitle> <institution> University of Texas, Austin, Texas, </institution> <year> 1990. </year>
Reference-contexts: 1 Introduction Researchers <ref> [2, 3, 13, 17, 21] </ref> have compared experimentally the performance of learning algorithms of decision trees and neural networks (NNs). <p> In other words, a symbolic representation is obtained for the network. 4 Discussion Discussed here are other issues of interests: * The training time. As was mentioned in many papers <ref> [2, 3, 13, 17, 21] </ref> doing comparison between backpropagation and decision tree learning, it takes much longer time to train a neural network than to learn a decision tree. This is also true for NN rules and DT rules extraction.
Reference: [3] <author> D.H. Fisher and K.B. McKusick. </author> <title> An empirical comparison of id3 and back-propagation. </title> <booktitle> In Proceedings of 11th International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 788-793, </pages> <year> 1989. </year>
Reference-contexts: 1 Introduction Researchers <ref> [2, 3, 13, 17, 21] </ref> have compared experimentally the performance of learning algorithms of decision trees and neural networks (NNs). <p> In other words, a symbolic representation is obtained for the network. 4 Discussion Discussed here are other issues of interests: * The training time. As was mentioned in many papers <ref> [2, 3, 13, 17, 21] </ref> doing comparison between backpropagation and decision tree learning, it takes much longer time to train a neural network than to learn a decision tree. This is also true for NN rules and DT rules extraction.
Reference: [4] <author> R.A. Fisher. </author> <title> The use of multiple measurements in taxonomic problems. </title> <journal> Ann. Eugenics, </journal> <volume> 7(2) </volume> <pages> 179-188, </pages> <year> 1936. </year>
Reference-contexts: Iris a classic dataset introduced by R.A. Fisher <ref> [4] </ref>; 2. Breast Cancer a widely tested real-world dataset for the Wisconsin Breast Cancer diagnosis; and 3. Splice-junction a dataset used in splice-junction determination originally described by Noordewier et al [11].
Reference: [5] <author> L. Fu. </author> <booktitle> Neural Networks in Computer Intelligence. </booktitle> <publisher> McGraw-Hill, </publisher> <year> 1994. </year>
Reference-contexts: If we can extract rules from neural networks as generating rules from decision trees, we can certainly understand better how a prediction is made. In addition, rules are a form of knowledge that can be easily verified by experts, passed on and expanded. Some recent works <ref> [5, 15, 19] </ref> have shown that rules can be extracted from networks. These algorithms are search-based methods. In order to reduce their exponential complexity in search time, only subsets of incoming weights that exceed the bias on a unit are searched. Such sets are then rewritten as rules. <p> Examples in odd positions in the original dataset form the training set and the rest are for testing as was done in <ref> [5] </ref>. * Breast Cancer the dataset consists of 699 examples, of which 458 examples are classified as benign, and 241 are malignant. 50% examples of each class were randomly selected (i.e., 229 benign and 121 malignant examples) for training, the rest for testing in the experiments. <p> NN rules cover all the possible combinations of the connections with various input values and discrete activation values of hidden units. This is a significant improvement over search-based methods <ref> [19, 5] </ref> where all possible input combinations are searched for subsets that will exceed the bias on a unit. To reduce the cost of searching, they normally limit the number of antecedents in extracted rules. Our algorithm imposes no such limit. * Consistency between NN and DT rules.
Reference: [6] <author> B. Hassibi and D.G. Stork. </author> <title> Second order derivatives for network pruning: Optimal brain surgeon. </title> <booktitle> Neural Information Processing Systems, </booktitle> <volume> 5 </volume> <pages> 164-171, </pages> <year> 1993. </year>
Reference-contexts: error function: (w; v) = F (w; v) + P (w; v); (3) where F (w; v) is the cross entropy function: F (w; v) = i=1 p=1 t i p (1 t i p ) : (4) and P (w; v) is the penalty function used for weight decay <ref> [6, 8] </ref>: P (w; v) = * 1 @ m=1 `=1 ` ) 2 ` ) 2 + m=1 p=1 p ) 2 p ) 2 A + (5) 0 h X n X (w m 2 h X o X p 1 Using this penalty function, we have been able
Reference: [7] <author> R. Kerber. Chimerge: </author> <title> Discretization of numeric attributes. </title> <booktitle> In AAAI-92, Proceedings Ninth National Conference on Artificial Intelligence, </booktitle> <pages> pages 123-128. </pages> <publisher> AAAI Press/The MIT Press, </publisher> <year> 1992. </year>
Reference-contexts: Each example is described using four numeric attributes (A 1 , A 2 , A 3 and A4): sepal-length, and sepal-width, petal-length, petal-width. Since each attribute takes a continuous number, the Chi2 algorithm [10], a generalized version of ChiMerge by Kerber <ref> [7] </ref>, is applied to discretize attribute values.
Reference: [8] <author> Y. Le Cun, J.S. Denker, and S.A. Solla. </author> <title> Opptimal brain damage. </title> <booktitle> Neural Information Processing Systems, </booktitle> <volume> 2 </volume> <pages> 598-605, </pages> <year> 1990. </year>
Reference-contexts: error function: (w; v) = F (w; v) + P (w; v); (3) where F (w; v) is the cross entropy function: F (w; v) = i=1 p=1 t i p (1 t i p ) : (4) and P (w; v) is the penalty function used for weight decay <ref> [6, 8] </ref>: P (w; v) = * 1 @ m=1 `=1 ` ) 2 ` ) 2 + m=1 p=1 p ) 2 p ) 2 A + (5) 0 h X n X (w m 2 h X o X p 1 Using this penalty function, we have been able
Reference: [9] <author> H. Liu. </author> <title> Generating perfect rules. </title> <type> Technical report, </type> <institution> Department of Info Sys and Comp Sci, National University of Singapore, </institution> <month> February </month> <year> 1995. </year>
Reference-contexts: The rule generation algorithm RG produces perfect rules, i.e., the error rate of the rules is no worse than the inconsistency rate ffi in the data (refer to <ref> [9] </ref> for the details); in the context of this work, the clustered data does not have any inconsistency and ffi is 0, so its error rate is 0. 2.5 Recursive application of NNRE However, when there are still too many connections (e.g., more than 7) between a hidden unit and input
Reference: [10] <author> H. Liu and R. Setiono. Chi2: </author> <title> Discretization of ordinal variables and feature selection. </title> <type> Technical report, </type> <institution> Department of Info Sys and Comp Sci, National University of Singapore, </institution> <month> January </month> <year> 1995. </year>
Reference-contexts: Each example is described using four numeric attributes (A 1 , A 2 , A 3 and A4): sepal-length, and sepal-width, petal-length, petal-width. Since each attribute takes a continuous number, the Chi2 algorithm <ref> [10] </ref>, a generalized version of ChiMerge by Kerber [7], is applied to discretize attribute values.
Reference: [11] <author> M.O. Noordewieer, G.G. Towell, and J.W. Shavlik. </author> <title> Training knowledge-based neural networks to recognize genes in dna sequences. </title> <booktitle> In Advances in neural information processing systems, </booktitle> <volume> volume 3, </volume> <pages> pages 530-536. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1991. </year>
Reference-contexts: Iris a classic dataset introduced by R.A. Fisher [4]; 2. Breast Cancer a widely tested real-world dataset for the Wisconsin Breast Cancer diagnosis; and 3. Splice-junction a dataset used in splice-junction determination originally described by Noordewier et al <ref> [11] </ref>. The datasets are obtainable from the University of California Irvine data repository for machine learning (via anonymous ftp from ics.uci.edu).
Reference: [12] <author> J.R. Quinlan. C4.5: </author> <title> Programs for Machine Learning. </title> <publisher> Morgan Kaufmann, </publisher> <year> 1993. </year>
Reference-contexts: Understanding a neural network is achieved by having a symbolic representation that is able to explain, based on the rules, how each prediction is made, as in understanding a decision tree by having rules generated from it <ref> [12] </ref>. 3.1 Datasets and Representations Three datasets used are: 1. Iris a classic dataset introduced by R.A. Fisher [4]; 2. Breast Cancer a widely tested real-world dataset for the Wisconsin Breast Cancer diagnosis; and 3. Splice-junction a dataset used in splice-junction determination originally described by Noordewier et al [11]. <p> By examining the fired rule, it can be explained how the prediction is attained. If necessary, the intermediate process can also be explicitly explained by rules R ih and R ho . C4.5 and C4.5rules <ref> [12] </ref> were run on the above three datasets to generate DT rules. Briefly, C4.5 generates a decision tree which C4.5rules generalizes to rules.
Reference: [13] <author> J.R. Quinlan. </author> <title> Comparing connectionist and symbolic learning methods. </title> <editor> In S.J. Hanson, G.A. Drastall, and R.L. Rivest, editors, </editor> <booktitle> Computational Learning Therory and Natural Learning Systems, </booktitle> <volume> volume 1, </volume> <pages> pages 445-456. </pages> <publisher> A Bradford Book, The MIT Press, </publisher> <year> 1994. </year>
Reference-contexts: 1 Introduction Researchers <ref> [2, 3, 13, 17, 21] </ref> have compared experimentally the performance of learning algorithms of decision trees and neural networks (NNs). <p> A general picture of these comparisons is that: (1) Backpropagation (an NN learning method) usually requires a great deal more computation; (2) the predictive accuracy of both approaches is roughly the same, with backpropagation often slightly more accurate <ref> [13] </ref>; and (3) symbolic learning (decision trees induction) can produce interpretable rules while networks of weights are harder to interpret [17]. In effect, a neural network is widely regarded as a black box due to the fact that little is known about how its prediction is made. <p> In other words, a symbolic representation is obtained for the network. 4 Discussion Discussed here are other issues of interests: * The training time. As was mentioned in many papers <ref> [2, 3, 13, 17, 21] </ref> doing comparison between backpropagation and decision tree learning, it takes much longer time to train a neural network than to learn a decision tree. This is also true for NN rules and DT rules extraction. <p> This is also true for NN rules and DT rules extraction. Due to the existence of sequential and parallel data types, and decision trees and neural networks are best suited to one type only <ref> [13] </ref>, the two approaches are expected to coexist. When time is really scarce, 5 This runs counter to our intuition.
Reference: [14] <author> D.E. Rumelhart, McClelland J.L., </author> <title> and the PDP Rearch Group. </title> <booktitle> Parallel Distributed Processing, volume 1. </booktitle> <address> Cambridge, Mass. </address> <publisher> The MIT Press, </publisher> <year> 1986. </year>
Reference-contexts: m v m where ff m = ffi ( l=1 l w m The target output for an example x i that belongs to class C j is an o dimensional vector t i , where t i p = 0 if p 6= j and t i backpropagation algorithm <ref> [14] </ref> is applied to update the weights (w; v) and minimize the following error function: (w; v) = F (w; v) + P (w; v); (3) where F (w; v) is the cross entropy function: F (w; v) = i=1 p=1 t i p (1 t i p ) : (4)
Reference: [15] <author> K. Saito and R Nakano. </author> <title> Medical diagnostic expert system based on pdp model. </title> <booktitle> In Proceedings of IEEE International Conference on Neural Networks, </booktitle> <volume> volume 1, </volume> <pages> pages 255-262. </pages> <publisher> IEEE, </publisher> <year> 1988. </year>
Reference-contexts: If we can extract rules from neural networks as generating rules from decision trees, we can certainly understand better how a prediction is made. In addition, rules are a form of knowledge that can be easily verified by experts, passed on and expanded. Some recent works <ref> [5, 15, 19] </ref> have shown that rules can be extracted from networks. These algorithms are search-based methods. In order to reduce their exponential complexity in search time, only subsets of incoming weights that exceed the bias on a unit are searched. Such sets are then rewritten as rules.
Reference: [16] <author> R. Setiono. </author> <title> A penalty function approach for pruning feedforward neural networks. </title> <type> Technical Report, DISCS, </type> <institution> National University of Singapore, </institution> <year> 1995. </year>
Reference-contexts: Details of the comparison and the choice of the parameter values (* 1 , * 2 , and fi) are given in <ref> [16] </ref>. 2.2 Network Pruning A network pruning algorithm is briefly described below. This pruning algorithm removes the connections of the network according to the magnitudes of their weights (7 and 8). <p> At the same time, weights of irrelevant connections should be encouraged to converge to zero. The penalty function (5) is found to be particularly suitable for these purposes. The details of this pruning algorithm and experimental results obtained are described in <ref> [16] </ref>. Neural network pruning algorithm 1. Let 1 and 2 be positive scalars such that 1 + 2 &lt; 0:5. 2. Pick a fully connected network.
Reference: [17] <author> J.W. Shavlik, R.J. Mooney, and G.G. Towell. </author> <title> Symbolic and neural learning algorithms: An experimental comparison. </title> <journal> Machine Learning, </journal> <volume> 6(2) </volume> <pages> 111-143, </pages> <year> 1991. </year>
Reference-contexts: 1 Introduction Researchers <ref> [2, 3, 13, 17, 21] </ref> have compared experimentally the performance of learning algorithms of decision trees and neural networks (NNs). <p> (1) Backpropagation (an NN learning method) usually requires a great deal more computation; (2) the predictive accuracy of both approaches is roughly the same, with backpropagation often slightly more accurate [13]; and (3) symbolic learning (decision trees induction) can produce interpretable rules while networks of weights are harder to interpret <ref> [17] </ref>. In effect, a neural network is widely regarded as a black box due to the fact that little is known about how its prediction is made. <p> If necessary, the intermediate process can also be explicitly explained by rules R ih and R ho . C4.5 and C4.5rules [12] were run on the above three datasets to generate DT rules. Briefly, C4.5 generates a decision tree which C4.5rules generalizes to rules. Since researchers <ref> [1, 17, 20] </ref> observed that mapping many-valued variables to two-valued variables results in decision trees with higher classification accuracy 3 , the same binary coded data for neural networks were used for C4.5 and C4.5rules. Being explicable is only one aspect of understandability. <p> In other words, a symbolic representation is obtained for the network. 4 Discussion Discussed here are other issues of interests: * The training time. As was mentioned in many papers <ref> [2, 3, 13, 17, 21] </ref> doing comparison between backpropagation and decision tree learning, it takes much longer time to train a neural network than to learn a decision tree. This is also true for NN rules and DT rules extraction.
Reference: [18] <author> M. Smith. </author> <title> Neural networks for Statistical Modeling. </title> <publisher> Van Nostrand Rein-hold, </publisher> <year> 1993. </year>
Reference-contexts: Since each attribute takes a continuous number, the Chi2 algorithm [10], a generalized version of ChiMerge by Kerber [7], is applied to discretize attribute values. The thermometer code <ref> [18] </ref> is used to binarize the discretized values, 16, 9, 7, and 6 inputs (discrete values) for A 1 ,A 2 , A 3 , and A 4 , respectively. (Refer to the details in Tables 6-9 in Appendix.) With 1 input for bias, there are total 39 inputs and three
Reference: [19] <author> G.G. Towell and J.W. Shavlik. </author> <title> Extracting refined rules from knowledge-based neural networks. </title> <journal> Machine Learning, </journal> <volume> 13(1) </volume> <pages> 71-101, </pages> <year> 1993. </year> <month> 17 </month>
Reference-contexts: If we can extract rules from neural networks as generating rules from decision trees, we can certainly understand better how a prediction is made. In addition, rules are a form of knowledge that can be easily verified by experts, passed on and expanded. Some recent works <ref> [5, 15, 19] </ref> have shown that rules can be extracted from networks. These algorithms are search-based methods. In order to reduce their exponential complexity in search time, only subsets of incoming weights that exceed the bias on a unit are searched. Such sets are then rewritten as rules. <p> With one input for bias, there are total 241 inputs and three outputs for the original network. For the experiments presented here, 1006 examples were randomly chosen as training data from the 3175 examples following other researchers' way <ref> [19] </ref>, the rest used as testing data. 3.2 A Detailed Example Iris Data Classification This example shows in detail how rules are extracted from a pruned network. In the experiment, 100 fully connected neural networks were used as the starting networks. <p> Otherwise, it is worthwhile trying both because of backpropagation's other advantages (generalizing better on a smaller dataset, predicting better in general, etc. <ref> [19] </ref>). * Average performance of NN rules. Because of neural networks' nondeterministic nature, it is not uncommon that hundreds runs of networks are needed with different initial weights. As was shown in Table 1, the average performance for 100 pruned networks is very impressive (94.55%). <p> Unlike M-of-N rules <ref> [19] </ref>, NN rules here reflect precisely how the network works. NN rules given here are actually the merge of the two sets: 1. from the input layer to the hidden layer; and 2. from the hidden layer to the output layer. <p> NN rules cover all the possible combinations of the connections with various input values and discrete activation values of hidden units. This is a significant improvement over search-based methods <ref> [19, 5] </ref> where all possible input combinations are searched for subsets that will exceed the bias on a unit. To reduce the cost of searching, they normally limit the number of antecedents in extracted rules. Our algorithm imposes no such limit. * Consistency between NN and DT rules.
Reference: [20] <author> P.E. Utgoff and C.E. Brodley. </author> <title> An incremental method for finding mul--tivariate splits for decision trees. </title> <booktitle> In Machine Learning: Proceedings of the Seventh International Conference, </booktitle> <pages> pages 58-65. </pages> <institution> University of Texas, Austin, Texas, </institution> <year> 1990. </year>
Reference-contexts: If necessary, the intermediate process can also be explicitly explained by rules R ih and R ho . C4.5 and C4.5rules [12] were run on the above three datasets to generate DT rules. Briefly, C4.5 generates a decision tree which C4.5rules generalizes to rules. Since researchers <ref> [1, 17, 20] </ref> observed that mapping many-valued variables to two-valued variables results in decision trees with higher classification accuracy 3 , the same binary coded data for neural networks were used for C4.5 and C4.5rules. Being explicable is only one aspect of understandability.
Reference: [21] <author> S.M. Weiss and I. Kapouleas. </author> <title> An empirical comparison of pattern recognition, neural nets, </title> <booktitle> and machine learning classifcation methods. In Proceedings of 11th International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 781-787, </pages> <year> 1989. </year>
Reference-contexts: 1 Introduction Researchers <ref> [2, 3, 13, 17, 21] </ref> have compared experimentally the performance of learning algorithms of decision trees and neural networks (NNs). <p> In other words, a symbolic representation is obtained for the network. 4 Discussion Discussed here are other issues of interests: * The training time. As was mentioned in many papers <ref> [2, 3, 13, 17, 21] </ref> doing comparison between backpropagation and decision tree learning, it takes much longer time to train a neural network than to learn a decision tree. This is also true for NN rules and DT rules extraction.
References-found: 21

