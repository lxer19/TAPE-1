URL: ftp://ftp.cis.ohio-state.edu/pub/anish/papers/load-balancing.ps.gz
Refering-URL: http://www.cis.ohio-state.edu/~anish/pub.html
Root-URL: 
Title: On the Correctness Criteria of Load Balancing Programs  
Author: Anish Arora Mohamed G. Gouda 
Keyword: load balancing programs, verification, distribution, constraint, convergence  
Date: April 17, 1997  
Address: Columbus, OH 43210 Austin, TX 78712  
Affiliation: Computer Information Science Computer Sciences The Ohio State University The University of Texas  
Abstract: Load balancing programs are usually verified by analyzing and simulating simple performance models. In this paper, we argue that besides this verification the correctness of load balancing programs needs to be verified formally, in order to gain confidence in the use of these programs in practical situations where the simple models are not always respected. Towards this end, we propose a set of correctness conditions that need to be satisfied by load balancing programs. Moreover, we show that these correctness conditions are not unduly restrictive, by designing a rich family of load balancing programs that satisfy these conditions. The presented programs are distinguished by their properties of full distribution, scalability, adaptivity, fault-tolerance, and guaranteed progress irrespective of the speed at which the environment produces or consumes load. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Arora, M. G. Gouda: </author> <title> Distributed reset. </title> <note> IEEE Transactions on Computers 43(9) (1994) 1026-1038 </note>
Reference-contexts: It follows that to achieve fault-tolerance in ring and tree networks, additional programs are needed to reconfigure the virtual graph in the presence of failures and repairs. Several such programs have appeared in the literature; for example, <ref> [1, 2] </ref> present reconfiguration programs for trees and rings that tolerate any finite number of failures and repairs. We conclude this section with the remark that similar considerations occur when designing load balancing computations for arbitrary networks. <p> We conclude that constrained convergence is useful and merits further consideration. Convergence Span. Proofs of the convergence criterion that exhibit variant functions have the added advantage that they provide upper bounds on the convergence span. We measure these bounds in terms of rounds <ref> [1] </ref>. Intuitively, a round consists of a sequence of steps wherein each node makes some minimal progress.
Reference: [2] <author> A. Arora, A. Singhai: </author> <title> Fault-tolerant reconfiguration of trees and rings in networks. Journal of High Integrity Design 1(4) (1995) 375-384 </title>
Reference-contexts: It follows that to achieve fault-tolerance in ring and tree networks, additional programs are needed to reconfigure the virtual graph in the presence of failures and repairs. Several such programs have appeared in the literature; for example, <ref> [1, 2] </ref> present reconfiguration programs for trees and rings that tolerate any finite number of failures and repairs. We conclude this section with the remark that similar considerations occur when designing load balancing computations for arbitrary networks.
Reference: [3] <author> P. Gronning, T.Q. Nielsen, and H.H Lovengreen: </author> <title> Stepwise development of a distributed load balancing algorithm. </title> <booktitle> Proceedings of the Fifth International Workshop on Distributed Algorithms (1991) </booktitle>
Reference-contexts: An example refinement of a load balancing program has been presented by Gronning et al <ref> [3] </ref>. In this example, actions with same atomicity as ours are refined into actions that use message passing in hypercube of Transputers, while preserving local convergence. Our correctness criteria have been influenced by the notion of self-stabilization [5].
Reference: [4] <author> J. A. Stankovik: </author> <title> Stability and distributed scheduling algorithms. </title> <journal> IEEE Transactions on Software Engineering SE-11(10) (1985) 1141-1152 </journal>
Reference-contexts: And, if the environment perturbs the state at arbitrarily high speeds but the durations of such perturbations are finite, then the program starts to converge eventually (cf. <ref> [4] </ref>).
Reference: [5] <author> E. W. Dijkstra: </author> <title> Self-stabilizing systems in spite of distributed control. </title> <booktitle> Communications of the ACM 17(11) (1974) 643-644 </booktitle>
Reference-contexts: In this example, actions with same atomicity as ours are refined into actions that use message passing in hypercube of Transputers, while preserving local convergence. Our correctness criteria have been influenced by the notion of self-stabilization <ref> [5] </ref>. This notion enables programs to withstand perturbations, by guaranteeing recovery of the program to desired execution even after the program is placed in an arbitrary state. Generalizations of this notion have been found useful, for instance, in verifying adaptivity [6] and fault-tolerance [7].
Reference: [6] <author> M. G. Gouda, T. Herman: </author> <title> Adaptive programming. </title> <journal> IEEE Transactions on Software Engineering 17(9) (1991) 911-921 </journal>
Reference-contexts: This notion enables programs to withstand perturbations, by guaranteeing recovery of the program to desired execution even after the program is placed in an arbitrary state. Generalizations of this notion have been found useful, for instance, in verifying adaptivity <ref> [6] </ref> and fault-tolerance [7]. In this paper, we have considered a generalization of self-stabilization that we call constrained convergence. We conclude that constrained convergence is useful and merits further consideration. Convergence Span.
Reference: [7] <author> A. Arora, M. G. Gouda: </author> <title> Closure and convergence: A foundation of fault-tolerant computing. </title> <note> IEEE Transactions on Software Engineering 19(11) (1993) 1015-1027 20 </note>
Reference-contexts: This notion enables programs to withstand perturbations, by guaranteeing recovery of the program to desired execution even after the program is placed in an arbitrary state. Generalizations of this notion have been found useful, for instance, in verifying adaptivity [6] and fault-tolerance <ref> [7] </ref>. In this paper, we have considered a generalization of self-stabilization that we call constrained convergence. We conclude that constrained convergence is useful and merits further consideration. Convergence Span.

Reference: [9] <author> B.A. Shirazi, A.R. Hurson and K.M. Kavi: </author> <title> Scheduling and Load Balancing in Parallel and Distributed Systems. </title> <publisher> IEEE Computer Society Press (1995) 1-42 </publisher>
Reference: [10] <author> K. L. Burgess and K. M. Passino: </author> <title> Stability analysis of load balancing systems. </title> <journal> International Journal of Control, </journal> <month> 61(2) </month> <year> (1995) </year>
Reference: [11] <author> F. C. H. Lin, R. Keller: </author> <title> The gradient model load balancing method. </title> <journal> IEEE Transactions on Software Engineering 13(1) (1987) 32-38 </journal>

Reference: [14] <author> D. Ferrari and S. Zhou: </author> <title> A dynamic load balancing policy with a central job dispatcher (LBC). </title> <booktitle> Proceedings of Performance'87, Twelveth International Symposium on Computer Performance Modeling, Measurement, and Evaluation (1987) 515-528 </booktitle>
Reference: [15] <author> T. Kunz: </author> <title> The influence of different workload descriptions on a heuristic load balancing scheme. </title> <note> IEEE Transactions on Software Engineering 17(7) (1991) 725-730 23 </note>
Reference: [16] <author> H.-C. Lin and C.S. Raghavendra: </author> <title> A dynamic load balancing policy with a central job dispatcher (LBC). </title> <note> IEEE Transactions on Software Engineering 18(2) (1992) 148-158 24 </note>
References-found: 13

