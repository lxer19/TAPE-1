URL: http://cs.nyu.edu/~yap/visual/home/pub/eechien-thesis.ps.gz
Refering-URL: http://cs.nyu.edu/~yap/visual/home/pub.html
Root-URL: http://www.cs.nyu.edu
Title: Foveation Techniques and Scheduling Issues in Thinwire Visualization  
Author: by Ee-Chien Chang 
Degree: A dissertation submitted in partial fulfillment of the requirements for the degree of Doctor of Philosophy  Approved: Professor Chee Yap  
Note: Research Advisor  
Date: May, 1998  
Address: New York University  
Affiliation: Department of Computer Science  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> C.H. Anderson, P.J. Burt, and G.S. van der Wal. </author> <title> Change detection and tracking using pyramid transform techniques. </title> <booktitle> Proceedings of the DARPA Image Understanding Workshop, </booktitle> <pages> pages 72-78, </pages> <year> 1985. </year>
Reference-contexts: A more flexible approach first computes a hierarchical representation of the image, and the foveated image is then obtained by cut-and-paste from different scales of the image. The method proposed by Burt <ref> [6, 1, 5] </ref> which uses Gaussian pyramid as the hierarchical representation of the image belongs to this approach. Machine Vision A uniform image contains too much information and this is always a bottleneck in real-time vision systems. <p> In this case, however, a request is served at a rate. How a request q is served throughout its life span is defined by its rate function f q : R ! <ref> [0; 1] </ref>.
Reference: [2] <author> A. Basu, A. Sullivan, and K.J. Wiebe. </author> <title> Variable resolution teleconferencing. </title> <booktitle> In IEEE Systems, Man, and Cybernetics Conference, </booktitle> <pages> pages 170-175, </pages> <year> 1993. </year>
Reference-contexts: Foveation, in this case, helps to reduce the network workload. As opposes to the previous applications, the data here could be the simple array data, for example image or video. Using foveation or region of interests (ROI) to reduce network workload is an active area in video conferencing <ref> [31, 13, 2, 3] </ref>. Attention is also focused on the means to select ROI, for example in [31, 10]. Note that video and still images are very different in nature and have different requirements.
Reference: [3] <author> A. Basu and K.J. Wiebe. </author> <title> Videoconferencing using spatially varying sensing with multiple and moving fovea. </title> <booktitle> In Proceedings of the IEEE International Conference on Pattern Recognition, </booktitle> <volume> volume 3, </volume> <pages> pages 30-34, </pages> <year> 1994. </year>
Reference-contexts: Foveation, in this case, helps to reduce the network workload. As opposes to the previous applications, the data here could be the simple array data, for example image or video. Using foveation or region of interests (ROI) to reduce network workload is an active area in video conferencing <ref> [31, 13, 2, 3] </ref>. Attention is also focused on the means to select ROI, for example in [31, 10]. Note that video and still images are very different in nature and have different requirements.
Reference: [4] <author> B. Bederson, R.S. Wallace, and E.L. Schwartz. </author> <title> A miniaturized active vision system. </title> <booktitle> In 11th IAPR International Conference on Pattern Recognition, </booktitle> <pages> pages 58-62, </pages> <address> The Hague, Netherlands, </address> <year> 1992. </year> <booktitle> Specialty Conference on Pattern Recognition Hardware Architecture. </booktitle>
Reference-contexts: This methodology is also known as smart-sensing introduced by Burt [5]. Again, this dynamic nature is motivated by the human vision. An implementation of such a system is CORTEX-I <ref> [46, 4] </ref>. Another interesting property of foveation lies in the geometry of the logmap. Note that rotation and scaling in the retinal plane amounts to translation along the and axis in the visual cortex plane respectively.
Reference: [5] <author> P.J. Burt. </author> <title> Smart sensing within a pyramid vision machine. </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> 76(8) </volume> <pages> 1006-1015, </pages> <year> 1988. </year>
Reference-contexts: A more flexible approach first computes a hierarchical representation of the image, and the foveated image is then obtained by cut-and-paste from different scales of the image. The method proposed by Burt <ref> [6, 1, 5] </ref> which uses Gaussian pyramid as the hierarchical representation of the image belongs to this approach. Machine Vision A uniform image contains too much information and this is always a bottleneck in real-time vision systems. <p> Yeshurun and Schwartz [48] generalized the use of foveation in machine vision to space-variant vision. The performance of a space-variant vision system could be further enhanced by dynamically 11 moving the fovea so as to gather relevant information. This methodology is also known as smart-sensing introduced by Burt <ref> [5] </ref>. Again, this dynamic nature is motivated by the human vision. An implementation of such a system is CORTEX-I [46, 4]. Another interesting property of foveation lies in the geometry of the logmap. <p> Figure 2.14 (b) illustrates a self-similar 0-1 mask. This method of using a 0-1 mask to produce "foveated" image is essentially the well-known technique of Burt <ref> [5] </ref>. In a certain sense, we give a justification of this method by arguing that it is indeed an approximation of the foveation operator with standard weight function. The advantages of using the 0-1 mask, beside its simplicity, is the computational speedup in the reconstruction process.
Reference: [6] <author> P.J. Burt and Theodore Adelson. </author> <title> A laplacian pyramid for data com 150 pression. </title> <journal> IEEE Trans. Commun., </journal> <volume> C-8:1230-1245, </volume> <year> 1981. </year>
Reference-contexts: A more flexible approach first computes a hierarchical representation of the image, and the foveated image is then obtained by cut-and-paste from different scales of the image. The method proposed by Burt <ref> [6, 1, 5] </ref> which uses Gaussian pyramid as the hierarchical representation of the image belongs to this approach. Machine Vision A uniform image contains too much information and this is always a bottleneck in real-time vision systems.
Reference: [7] <author> B. Cabral, N. Cam, and J. Foran. </author> <title> Accelerated volume rendering and to-mographic reconstruction using texture mapping hardware. </title> <booktitle> 1994 Symp. on Volume Visualization, </booktitle> <pages> pages 91-97, </pages> <year> 1994. </year>
Reference-contexts: The advantages of using the 0-1 mask, beside its simplicity, is the computational speedup in the reconstruction process. As observed in the introduction of this chapter, foveation is also applied to speedup computation, which is achieved by ignoring most of the wavelet coefficients. For example, in <ref> [7] </ref>, the projection of the volume data onto a plane is computed by performing a texture mapping operation for each coefficient. Note that the original approximation scheme is not suitable. 58 using DAUB6 and Haar wavelet respectively. Summary. Let us summarize the methods described in this section. 1.
Reference: [8] <author> E.C. Chang and C. Yap. </author> <title> A wavelet approach to foveating images. </title> <booktitle> 13th ACM Symposium on Computational Geometry, </booktitle> <pages> pages 397-399, </pages> <year> 1997. </year>
Reference-contexts: We formulate this process as an operator and analyze its operator matrix with respect to some wavelet basis. The analysis suggests some approximation methods. Based on these methods, we propose an interactive progressive transmission scheme. Definition in one dimension. We begin with one dimensional functions. A foveation <ref> [8] </ref> of a function f : R ! R is determined by a weight function w : R ! R 0 and a scaling function g : R ! R. The weight function is non-negative and w (x) = 0 only for finitely many x.
Reference: [9] <author> Ingrid Daubechies. </author> <title> Ten Lectures on Wavelets. </title> <publisher> SIAM, </publisher> <year> 1992. </year>
Reference-contexts: Therefore, the restriction on can be relaxed to the followings: 49 1. has compact support, and 2. is uniformly Lipschitz q 5 4 and has at least two vanishing moments. Certainly, such wavelet exists. An example is DAU B6 <ref> [9] </ref>. Now, by straight forward application of Schur's lemma using Lemma 2.8 and Lemma 2.7, we have the boundedness of T fov .
Reference: [10] <author> A. Eleftheriadis and A. Jacquin. </author> <title> Automatic face location detection and tracking for model-assisted coding of video teleconferencing sequences at low bitrates. Signal Processing: </title> <journal> Image Communication, </journal> <volume> 7(3) </volume> <pages> 231-248, </pages> <year> 1995. </year>
Reference-contexts: Using foveation or region of interests (ROI) to reduce network workload is an active area in video conferencing [31, 13, 2, 3]. Attention is also focused on the means to select ROI, for example in <ref> [31, 10] </ref>. Note that video and still images are very different in nature and have different requirements. Video transmission stresses even more on real-time performance, but there is less requirement of progressive refinement since successive frames or images displayed are not the same.
Reference: [11] <author> R.A. Fisher and H.M. Tong. </author> <title> A full-field-of-view dome visual display for tactical combat training. </title> <booktitle> In Proc. Image Conference IV, </booktitle> <address> Phoenix, Arizona, </address> <month> June, </month> <year> 1987. </year>
Reference-contexts: A possible approach is by allowing the viewer walks through these objects interactively. Of course, this method is computationally intensive due to the size of the data and the real-time requirement. This is where foveation could play an active role. Examples are flight simulation systems designed by <ref> [42, 11] </ref>. Volume rendering, which could be viewed as a projection from a three dimensional data to a two dimensional image, is inherently computationally intensive due to the large size of volumetric data set.
Reference: [12] <author> M. Frazier and B. Jawerth. </author> <title> Applications of the and wavelet transforms to the theory of function spaces. </title> <booktitle> In Wavelets and Their Applications, </booktitle> <pages> pages 377-418. </pages> <publisher> Jones and Bartlett, </publisher> <year> 1992. </year>
Reference-contexts: Next, by using the self-similarity and fast decay property, we apply Schur's lemma (Lemma A.1) to show that T fov is bounded. This approach of proving the boundedness of an operator could also be found in <ref> [12] </ref> and [20]. We first show a few lemmas and present the proof of this theorem at the end of this section. In the rest of this section, we assume that the scaling 41 function g and weight function w satisfy the conditions stated in the theorem.
Reference: [13] <author> B. Girod. </author> <title> Eye movements and coding of video sequences. </title> <booktitle> SPIE Visual Communications and Image Processing, </booktitle> <volume> 1001 </volume> <pages> 398-405, </pages> <year> 1988. </year>
Reference-contexts: Foveation, in this case, helps to reduce the network workload. As opposes to the previous applications, the data here could be the simple array data, for example image or video. Using foveation or region of interests (ROI) to reduce network workload is an active area in video conferencing <ref> [31, 13, 2, 3] </ref>. Attention is also focused on the means to select ROI, for example in [31, 10]. Note that video and still images are very different in nature and have different requirements.
Reference: [14] <author> G.G. Holmes. </author> <title> The cortical localization of vision. </title> <type> Br. </type> <institution> Med. J, ii:193-199, </institution> <year> 1919. </year>
Reference-contexts: Studies of this space-variant structure in the visual cortex could be traced back to <ref> [26, 14, 30] </ref>, who suggest a well-defined map-like representation of visual field in the cortex. In the early 1940's, Talbot and Marshall [41] demonstrate and confirm this hypothesis.
Reference: [15] <author> Nuggehally S. Jayant and Peter Noll. </author> <title> Digital coding of waveforms: principles and applications to speech and video. </title> <address> Englewood Cliffs, New Jersey, </address> <year> 1984. </year> <month> 151 </month>
Reference-contexts: For a random source A and a quantizer Q, let e A := Q (A). If the number of bins is fixed, say N , to minimize the expected mean square error Ef (A Q (A)) 2 g, Lloyd-Max algorithm <ref> [24, 15] </ref> gives the optimal solution where smaller bins are "allocated" to more popular values.
Reference: [16] <author> Philip Kortum and Wilson S. Geisler. </author> <title> Implementation of a foveated image coding system for image bandwidth reduction. In Human Vision and Electronic Imaging, </title> <booktitle> SPIE Proceedings Vol. </booktitle> <volume> 2657, </volume> <pages> pages 350-360, </pages> <year> 1996. </year>
Reference-contexts: The real-time system designed by Kortum <ref> [16] </ref> and the real-time system CORTEX-I developed by Wallace et al. [46] use this approach. The partition is usually precomputed and stored in a lookup table, and thus, the 10 horizontal log-Cartesian arrangements. <p> Thus, to provide a foveated image that is indistinguishable to the viewer throughout the visualization process, it is necessary to track the viewer's gaze point and produce the corresponding foveated image. Example of systems using eye tracking are <ref> [17, 16] </ref>. We would like to clarify that in our thinwire application, we do not intend to track the viewer's gaze point. Instead, the viewer is to "cooperate" with the system by selecting his gaze point using the conventional pointing devices, for example mouse, joystick or even keyboard.
Reference: [17] <author> M. Levoy and R. Whitaker. </author> <title> Gaze-directed volume rendering. </title> <journal> Computer Graphics, </journal> <volume> 24(2) </volume> <pages> 217-223, </pages> <month> March </month> <year> 1990. </year>
Reference-contexts: Since volume data is a generalization of image data, techniques on image foveation could be extended to volume naturally, except that it poses more of a computational challenge. Levoy and Whitaker build a system that achieve real-time rending of volume data <ref> [17] </ref> using foveation. They perform volume rendering at different resolution 13 and the foveated image is obtained by pasting images of different resolutions using interpolation. <p> Thus, to provide a foveated image that is indistinguishable to the viewer throughout the visualization process, it is necessary to track the viewer's gaze point and produce the corresponding foveated image. Example of systems using eye tracking are <ref> [17, 16] </ref>. We would like to clarify that in our thinwire application, we do not intend to track the viewer's gaze point. Instead, the viewer is to "cooperate" with the system by selecting his gaze point using the conventional pointing devices, for example mouse, joystick or even keyboard.
Reference: [18] <author> Richard J. Lipton and Andrew Tomkins. </author> <title> Online interval scheduling. </title> <booktitle> Proceedings of the 5th annual ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <pages> pages 304-311, </pages> <year> 1994. </year>
Reference-contexts: An example is the on-line intervals packing problem 90 where the instance consists of open intervals and a schedule is a subset of non-overlapping intervals. Lipton and Tomkins <ref> [18] </ref> study a variant where the input intervals are sorted by their left endpoints, and the intervals are restricted to two types: intervals with unit size and intervals with size k. The goal is to cover the real line as much as possible.
Reference: [19] <author> S. Mallat. </author> <title> A theory for multiresolution signal decomposition: the wavelet representation. </title> <journal> IEEE Trans. Pattern Anal. Machine Intell., </journal> <volume> 11 </volume> <pages> 674-692, </pages> <year> 1989. </year>
Reference-contexts: j n;m jx 2 1 ! 1=2 142 Combine with (A.2), we have kT xk 2 1 X 1 X n;m x m n=0 (B ^w n ) m=0 m w m = m=0 x 2 w m n=0 B 2 n=0 n : A.2 Multiresolution analysis A multiresolution analysis <ref> [19] </ref> is given by a sequence fV j g j2Z of closed sub spaces of L 2 (R) satisfying the followings: 1. V j V j1 for all j 2 Z.
Reference: [20] <author> S. Mallat, Z. Zhang, and G. Papanicolaou. </author> <title> Adaptive covariance estimation of locally stationary processes. </title> <journal> Annals of Stat., </journal> <note> 1997 (To appear). </note>
Reference-contexts: Next, by using the self-similarity and fast decay property, we apply Schur's lemma (Lemma A.1) to show that T fov is bounded. This approach of proving the boundedness of an operator could also be found in [12] and <ref> [20] </ref>. We first show a few lemmas and present the proof of this theorem at the end of this section. In the rest of this section, we assume that the scaling 41 function g and weight function w satisfy the conditions stated in the theorem.
Reference: [21] <author> Stephane Mallat. </author> <title> A Wavelet Tour of Signal Processing. </title> <publisher> Academic Press, </publisher> <year> 1998. </year>
Reference-contexts: surprisingly, the uniform quantizer outperforms the quantizer obtained by Lloyd-Max algorithm; in fact it is near optimal for small D (or large number of bins) assuming A is well-behaved (for example, when A is Laplacian [47] or the quantizer and A satisfy the high bit rate assumption 69 described in <ref> [21] </ref>). Note that the entropy of e A is a lower bound for the average bit size needed to code e A [34]. In the context of progressive transmission, there are two types of scalar quantization: multiscale and embedded quantization. <p> Bits Allocation of Transform Code. Let us treat the three steps of transform code more formally but restrict the discussion to the cases where the base B is orthonormal, and where scalar quantization and entropy encoding are applied in the last two steps. We follow the approach in <ref> [21] </ref>. Let B = fg m g 0m&lt;N be an orthonormal basis. A function/image f is represented by its coefficients fa m g with respect to B where each a m = hf; g m i. <p> A proof of the above theorem and a discussion on regularity could be found in <ref> [21] </ref>. 146 Appendix B B.1 Sparse representation for 0-1 Mask Pyra mid The 0-1 mask pyramid stores the mask fc j [m; n]g j;m;n . We use a straightforward representation. The pyramid is represented as a list of sparse matrices.
Reference: [22] <author> M. Manasse, L.A. McGeoch, and D. Sleator. </author> <title> Competitive algorithms for server problems. </title> <booktitle> In Proc. 20th Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 322-333, </pages> <year> 1988. </year>
Reference-contexts: Sleator and Tarjan 89 [37] show that the LIFO (last in first out) and LRU (least recently used) strategies are k-competitive and the problem is no better than k-competitive. The paging problem is a special case of the k-server problem introduced by Manasse, MacGeoch, and Sleator <ref> [22] </ref>. There are a few variants on the computational models. One may consider randomized scheduler. A randomized scheduler S, as opposed to the deterministic scheduler, is allowed to toss coins randomly. Given an instance I, let S (I) to be the random variable of the schedule output by S.
Reference: [23] <author> David Marr. </author> <title> Vision: a computational Investigation into the Human Representation and Processing of Visual Information. W.H. </title> <publisher> Freeman, </publisher> <year> 1982. </year>
Reference-contexts: One would argue that the mean square error in (2.30) may not be the right measure. It is well known that the sensitivity of the human vision varies across different frequencies <ref> [23] </ref>. However, mean square error is still of much interests since it is easy to manipulate mathematically. Many compression schemes, for example JPEG, use a weighted mean square error as a guide for compression.
Reference: [24] <author> J. Max. </author> <title> Quantizing for minimum distortion. </title> <journal> IRE Transactions on Information Theory, </journal> <volume> IT-6(1):7-12, </volume> <year> 1960. </year> <month> 152 </month>
Reference-contexts: For a random source A and a quantizer Q, let e A := Q (A). If the number of bins is fixed, say N , to minimize the expected mean square error Ef (A Q (A)) 2 g, Lloyd-Max algorithm <ref> [24, 15] </ref> gives the optimal solution where smaller bins are "allocated" to more popular values.
Reference: [25] <author> B.H. McCormick, T.A. DeFanti, and M.D. Brown. </author> <title> Visualization in sci-entific computing. </title> <journal> ACM Computer Graphics (special issue), </journal> <volume> 21, </volume> <year> 1987. </year>
Reference-contexts: This observation could be confirmed by psychological experiment and has been exploited by some visualization systems. Since the landmark NSF Report in 1987 <ref> [25] </ref>, visualization is an active research area. Visualization is a process whereby the viewer gains insight into a large data set. An interesting issue in visualization concerns how to visualize a large geometric data set. A possible approach is by allowing the viewer walks through these objects interactively.
Reference: [26] <author> M. </author> <title> Minkowski. Experimentelle untersuchungen uber die beziehungen der grosshirninde. </title> <publisher> Arb. Hirnanat. Inst. </publisher> <address> Zurich, 7:259, </address> <year> 1913. </year>
Reference-contexts: Studies of this space-variant structure in the visual cortex could be traced back to <ref> [26, 14, 30] </ref>, who suggest a well-defined map-like representation of visual field in the cortex. In the early 1940's, Talbot and Marshall [41] demonstrate and confirm this hypothesis.
Reference: [27] <author> Alireza Moini. </author> <title> Vision chips or seeing silicon. </title> <note> www page at url:hhttp://www.eleceng.adelaide.edu.au/ groups/gaas/bugeye/visionchips/i, Last update April 1997. </note>
Reference-contexts: Therefore, the process is a non-uniform sampling process. A survey on some of the past and current technology of vision chip could be found in [28], which is also available in the web <ref> [27] </ref>. Another method for obtaining the value at the logmap pixels is from a two dimensional uniform resolution raster image, for example Figure 2.1 (a).
Reference: [28] <author> Alireza Moini. </author> <title> Vision chips or seeing silicon. </title> <type> Technical Report, </type> <institution> Center for High Performance Integrated Technologies and Systems, The University of Adelaide, </institution> <month> March </month> <year> 1997. </year>
Reference-contexts: Another interesting arrangement is the one obtained by blending two arrangements: the usual uniform arrangement within the fovea and the space 9 variant arrangement on the peripheral. Examples of this configuration are described in <ref> [28] </ref>. A disadvantage of this configuration is the difficulty in merging the two arrangements smoothly. The values at the logmap pixels can be obtained from a scene using a foveated vision chip (or seeing silicon) where the photoreceptors are organized in a way similar to the biological retina. <p> The width of a sampling function increases linearly as the distance of the photoreceptor from the center of the chip increases. Therefore, the process is a non-uniform sampling process. A survey on some of the past and current technology of vision chip could be found in <ref> [28] </ref>, which is also available in the web [27]. Another method for obtaining the value at the logmap pixels is from a two dimensional uniform resolution raster image, for example Figure 2.1 (a).
Reference: [29] <author> F. Panerai, C. Capurro, and G. </author> <title> Sandini. Space variant vision for an active camera mount. </title> <booktitle> In Proc. SPIE AeroSense95, </booktitle> <year> 1995. </year>
Reference-contexts: For example, Panerai et al. <ref> [29] </ref> use a logmap of the form, := k ln ( x 2 + y 2 + a); and 8 &gt; &gt; : x if x &gt; 0; x + otherwise. (2.2) They also study various arrangements of logmap pixels (in the retinal plane), namely log-Cartesian and horizontal log-Cartesian as illustrated <p> The real-time system designed by Kortum [16] and the real-time system CORTEX-I developed by Wallace et al. [46] use this approach. The partition is usually precomputed and stored in a lookup table, and thus, the 10 horizontal log-Cartesian arrangements. Image reproduced from <ref> [29] </ref>. "emulating" process is fast but lack flexibility in the sense that the arrangement of the logmap pixels is fixed. A more flexible approach first computes a hierarchical representation of the image, and the foveated image is then obtained by cut-and-paste from different scales of the image. <p> Note that rotation and scaling in the retinal plane amounts to translation along the and axis in the visual cortex plane respectively. Apparently, this is a desirable property in some vision tasks, for example, in corner detection. In addition, based on experimental results, Panerai et al. <ref> [29] </ref> report that computation in the visual cortex plane is more robust in finding correlation of two images I left and I right where both images are obtained from a binocular camera system. A lot of basic image processing operations depend on the neighborhood relationship of pixels.
Reference: [30] <author> S. Poliak. </author> <title> The main afferent fibre systems of the cerebral cortex in primates. </title> <journal> Univ. Calif. Publ. Anat., </journal> <volume> 2 </volume> <pages> 107-207, </pages> <year> 1932. </year>
Reference-contexts: Studies of this space-variant structure in the visual cortex could be traced back to <ref> [26, 14, 30] </ref>, who suggest a well-defined map-like representation of visual field in the cortex. In the early 1940's, Talbot and Marshall [41] demonstrate and confirm this hypothesis.
Reference: [31] <author> T.H. Reeves and J.A. Robinson. </author> <title> Adaptive foveation of mpeg video. </title> <booktitle> Proceedings, 4th ACM International Multimedia Conference, </booktitle> <year> 1996. </year>
Reference-contexts: Foveation, in this case, helps to reduce the network workload. As opposes to the previous applications, the data here could be the simple array data, for example image or video. Using foveation or region of interests (ROI) to reduce network workload is an active area in video conferencing <ref> [31, 13, 2, 3] </ref>. Attention is also focused on the means to select ROI, for example in [31, 10]. Note that video and still images are very different in nature and have different requirements. <p> Using foveation or region of interests (ROI) to reduce network workload is an active area in video conferencing [31, 13, 2, 3]. Attention is also focused on the means to select ROI, for example in <ref> [31, 10] </ref>. Note that video and still images are very different in nature and have different requirements. Video transmission stresses even more on real-time performance, but there is less requirement of progressive refinement since successive frames or images displayed are not the same.
Reference: [32] <author> E.L. Schwartz. </author> <title> Spatial mapping in primate sensory projection: Analytic structure and relevance to perception. </title> <journal> Biological Cybernetics, </journal> <volume> 25 </volume> <pages> 181-194, </pages> <year> 1977. </year>
Reference-contexts: Studies of this space-variant structure in the visual cortex could be traced back to [26, 14, 30], who suggest a well-defined map-like representation of visual field in the cortex. In the early 1940's, Talbot and Marshall [41] demonstrate and confirm this hypothesis. Subsequent studies by Schwartz <ref> [32] </ref> show that the complex logmap is a good model for the mapping of the visual field in the visual cortex. Schwartz gives a recent survey on this topic in [33].
Reference: [33] <author> Eric L. Schwartz. </author> <title> Topographic mapping in primate visual cortex: History, anatomy, and computation. </title> <editor> In D. H. Kelly, editor, </editor> <booktitle> Visual Science and Engineering: Models and Applications, </booktitle> <pages> pages 293-360. </pages> <publisher> Marcel Dekker, </publisher> <year> 1994. </year> <month> 153 </month>
Reference-contexts: In the early 1940's, Talbot and Marshall [41] demonstrate and confirm this hypothesis. Subsequent studies by Schwartz [32] show that the complex logmap is a good model for the mapping of the visual field in the visual cortex. Schwartz gives a recent survey on this topic in <ref> [33] </ref>.
Reference: [34] <author> C.E. Shannon. </author> <title> Communications in the presence of noise. </title> <booktitle> In Proceedings of the IRE, </booktitle> <volume> volume 37, </volume> <pages> pages 10-21, </pages> <month> January </month> <year> 1949. </year>
Reference-contexts: Note that the entropy of e A is a lower bound for the average bit size needed to code e A <ref> [34] </ref>. In the context of progressive transmission, there are two types of scalar quantization: multiscale and embedded quantization. In multiscale quantization, the data is first quantized by a coarse quantizer and the quantization error is then quantized by a finer quantizer.
Reference: [35] <author> J.M. Shapiro. </author> <title> Embedded image coding using zerotrees of wavelet coefficients. </title> <journal> IEEE Transactions on Signal Processing, </journal> <volume> 41(12) </volume> <pages> 3445-3462, </pages> <month> December </month> <year> 1993. </year>
Reference-contexts: Consider the wavelet coefficients of an image. By visual inspection, one could conclude that there is coherence across the scales. Methods that exploit this observation is the zero-tree developed by Shapiro <ref> [35] </ref> and the predictive method by Simoncelli and Buccigrossi [36]. Using transform code to generate foveated images. Most current image compression schemes are concerned with uniform progressive transmission. However, we could easily generalize them to to space-variant progressive transmission by using different bin size across the spatial domain.
Reference: [36] <author> E.P. Simoncelli and R.W. Buccigrossi. </author> <title> Embedded wavelet image compression based on a joint probability model. </title> <booktitle> In 4th IEEE International Conference on Image Processing, </booktitle> <address> Santa Barbara, </address> <year> 1997. </year>
Reference-contexts: Consider the wavelet coefficients of an image. By visual inspection, one could conclude that there is coherence across the scales. Methods that exploit this observation is the zero-tree developed by Shapiro [35] and the predictive method by Simoncelli and Buccigrossi <ref> [36] </ref>. Using transform code to generate foveated images. Most current image compression schemes are concerned with uniform progressive transmission. However, we could easily generalize them to to space-variant progressive transmission by using different bin size across the spatial domain.
Reference: [37] <author> D. Sleator and R. Tarjan. </author> <title> Amortized efficiency of list update and paging rules. </title> <journal> Communications of the ACM, </journal> <volume> 28(2) </volume> <pages> 202-208, </pages> <year> 1985. </year>
Reference-contexts: Performance of an on-line scheduler could be measured by its competitiveness, introduced by Sleator and Tarjan <ref> [37] </ref>. Suppose S is a scheduler and S (I) is the schedule produced by S on I, then S is c-competitive if for any instance I, merit (opt (I)) c : merit (S (I)) + b; where b is some constant and opt (I) is the optimal off-line schedule. <p> A classic example is the paging problem where the main memory can only holds at most k pages and the goal is to minimize the number of page faults. Sleator and Tarjan 89 <ref> [37] </ref> show that the LIFO (last in first out) and LRU (least recently used) strategies are k-competitive and the problem is no better than k-competitive. The paging problem is a special case of the k-server problem introduced by Manasse, MacGeoch, and Sleator [22].
Reference: [38] <author> K.R. Sloan and S.L. Tanimoto. </author> <title> Progressive refinement of raster images. </title> <journal> IEEE Trans. Comput., </journal> <volume> C-28(11):871-874, </volume> <year> 1979. </year>
Reference-contexts: One of the early papers on progressive transmission was by Sloan and Tanimoto <ref> [38] </ref>. Since then, it is an active research area and most current image compression schemes include features of progressive transmission. The popular graphic format GIF and JPEG [45] already have progressive transmission mode. A survey on progressive transmission could be found in [44].
Reference: [39] <institution> Wavelet technology and information access. www page at url:hhttp://www.summus.com/i, Summus, Ltd, Last update November 21,1997. </institution>
Reference-contexts: For still images, it is well known that by allowing the user specifies the area of interest could greatly improve compression rate. For example, the commercial Summus' Wavelet Image (WI) has the feature of multiple "region of interests focusing" <ref> [39] </ref>. Here, the role of the user is to select the region of interests before the image is compressed. The selected regions are then compressed with less distortion. However, the role of the viewer is passive in the sense that he is not allowed to choose the region of interests.
Reference: [40] <author> A. Tabernero, J. Portilla, and R. Navarro. </author> <title> Duality between the local spectrum of a signal and its inverse fourier transform, the local signal. </title> <type> Technical Report 53, </type> <institution> Instituto de Optica (CSIC), Spain, </institution> <year> 1997. </year>
Reference-contexts: This simple description is desirable in the thinwire applications. Tabernero et al. study a closely related foveatization operator <ref> [40] </ref>. We will address the differences between their operator and ours. Definition in two dimensions. <p> Note that the difference between these two formulations amounts to whether a modulo j j is applied to w (x) (the w (x) within the parameter of g) in the definition (2.3). The foveatization operator <ref> [40] </ref>, on the contrary, is equivalent to convolution in the visual cortex plane.
Reference: [41] <author> S.A. Talbot and W.H. Marshall. </author> <title> Physiological studies on neural mechanisms of visual localization and discrimination. </title> <journal> Am. J. Ophthalmol, </journal> <volume> 24 </volume> <pages> 1255-1263, </pages> <year> 1941. </year>
Reference-contexts: Studies of this space-variant structure in the visual cortex could be traced back to [26, 14, 30], who suggest a well-defined map-like representation of visual field in the cortex. In the early 1940's, Talbot and Marshall <ref> [41] </ref> demonstrate and confirm this hypothesis. Subsequent studies by Schwartz [32] show that the complex logmap is a good model for the mapping of the visual field in the visual cortex. Schwartz gives a recent survey on this topic in [33].
Reference: [42] <author> H.M. Tong and R.A. Fisher. </author> <title> Progress report on an eye-slaved area-of-interest visual display. </title> <booktitle> In Proc. Image Conference III, </booktitle> <address> Phoenix, Arizona, </address> <month> May, </month> <year> 1984. </year> <month> 154 </month>
Reference-contexts: A possible approach is by allowing the viewer walks through these objects interactively. Of course, this method is computationally intensive due to the size of the data and the real-time requirement. This is where foveation could play an active role. Examples are flight simulation systems designed by <ref> [42, 11] </ref>. Volume rendering, which could be viewed as a projection from a three dimensional data to a two dimensional image, is inherently computationally intensive due to the large size of volumetric data set.
Reference: [43] <author> K.H. Tzou. </author> <title> Embedded max quantization. </title> <booktitle> In Proc. IEEE Int. Conf. Acoust. Speech. Sig. Proc., </booktitle> <pages> pages 505-508. </pages> <address> ICASSP'86, </address> <year> 1986. </year>
Reference-contexts: In the context of progressive transmission, there are two types of scalar quantization: multiscale and embedded quantization. In multiscale quantization, the data is first quantized by a coarse quantizer and the quantization error is then quantized by a finer quantizer. In the embedded quantization <ref> [43] </ref>, the output of the coarse quantizer coincide with the output of the finer quantizer applied in the next step. As a result, for each refinement, the refined quantized values can be obtained by concatenation of the previous values with the additional bits. <p> On the other hand, in the case of multiscale quantization, an arithmetic addition is required for each coefficient. Therefore, embedded quantization is computationally more efficient. Furthermore it is also more efficient in achieving low distortion <ref> [43] </ref>. Lossless Compression. This step is also known as channel compression. After quantization, the image is represented as a sequence of bytes. Lossless compression applies an invertible transformation to remove redundancy. A major framework for lossless compression scheme is entropy encoding.
Reference: [44] <author> Kou-Hu Tzou. </author> <title> Progressive image transmission: a review and comparison of techniques. </title> <journal> Optical Engineering, </journal> <volume> 26(7) </volume> <pages> 581-589, </pages> <year> 1987. </year>
Reference-contexts: Since then, it is an active research area and most current image compression schemes include features of progressive transmission. The popular graphic format GIF and JPEG [45] already have progressive transmission mode. A survey on progressive transmission could be found in <ref> [44] </ref>. Under a progressive transmission scheme, an image I is first transformed and stored as a linear bit stream b 0 ; b 1 ; : : : ; b n .
Reference: [45] <author> G.K. Wallace. </author> <title> The jpeg still picture compression standard. </title> <journal> Communications of the ACM, </journal> <volume> 34(4) </volume> <pages> 30-44, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: One of the early papers on progressive transmission was by Sloan and Tanimoto [38]. Since then, it is an active research area and most current image compression schemes include features of progressive transmission. The popular graphic format GIF and JPEG <ref> [45] </ref> already have progressive transmission mode. A survey on progressive transmission could be found in [44]. Under a progressive transmission scheme, an image I is first transformed and stored as a linear bit stream b 0 ; b 1 ; : : : ; b n .
Reference: [46] <author> R.S. Wallace, P.-W. Ong, B. Bederson, and E.L. Schwartz. </author> <title> Space variant image processing. </title> <journal> Intl. J. of Computer Vision, </journal> <volume> 13(1) </volume> <pages> 71-90, </pages> <year> 1994. </year>
Reference-contexts: The real-time system designed by Kortum [16] and the real-time system CORTEX-I developed by Wallace et al. <ref> [46] </ref> use this approach. The partition is usually precomputed and stored in a lookup table, and thus, the 10 horizontal log-Cartesian arrangements. Image reproduced from [29]. "emulating" process is fast but lack flexibility in the sense that the arrangement of the logmap pixels is fixed. <p> This methodology is also known as smart-sensing introduced by Burt [5]. Again, this dynamic nature is motivated by the human vision. An implementation of such a system is CORTEX-I <ref> [46, 4] </ref>. Another interesting property of foveation lies in the geometry of the logmap. Note that rotation and scaling in the retinal plane amounts to translation along the and axis in the visual cortex plane respectively. <p> In the usual uniform image, this neighborhood is usually taken as the 4-neighbor or 8-neighbor depending on whether the four corners are to be included. It is not clear how the neighborhood relationship should be defined for the logmap pixels. Wallace et al. <ref> [46] </ref> study various configurations of connectivity graph for the logmap pixels, where the connectivity graph represents the neighborhood relationship of the logmap pixels: two pixels are adjacent if and only if there is an edge between them. 12 Visualization The existence of a space-variant nature in our visual sys-tem suggests that
Reference: [47] <author> R.C. Wood. </author> <title> On optimum quantization. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> IT-15(2):248-252, </volume> <year> 1969. </year>
Reference-contexts: mean square error, say D, and would like to minimize the entropy of e A, surprisingly, the uniform quantizer outperforms the quantizer obtained by Lloyd-Max algorithm; in fact it is near optimal for small D (or large number of bins) assuming A is well-behaved (for example, when A is Laplacian <ref> [47] </ref> or the quantizer and A satisfy the high bit rate assumption 69 described in [21]). Note that the entropy of e A is a lower bound for the average bit size needed to code e A [34].
Reference: [48] <author> Y. Yeshurun and E.L. Schwartz. </author> <title> Shape description with a space-variant sensor: Algorithms for scan-path, fusion and convergence over multiple scans. </title> <journal> IEEE Trans. Pattern Anal. Machine Intell., </journal> <volume> PAPMI-11:1217-1222, </volume> <year> 1989. </year>
Reference-contexts: Two straightforward ways to reduce information are by lowering the resolution uniformly or by reducing the size of the visual field. Foveation provides a simple and fast blending of both means of reduction. Yeshurun and Schwartz <ref> [48] </ref> generalized the use of foveation in machine vision to space-variant vision. The performance of a space-variant vision system could be further enhanced by dynamically 11 moving the fovea so as to gather relevant information. This methodology is also known as smart-sensing introduced by Burt [5].
References-found: 48

