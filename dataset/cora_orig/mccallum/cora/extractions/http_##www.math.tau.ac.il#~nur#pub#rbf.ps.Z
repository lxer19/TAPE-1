URL: http://www.math.tau.ac.il/~nur/pub/rbf.ps.Z
Refering-URL: http://www.cnl.salk.edu/~wiskott/Bibliographies/FaceProcessing.html
Root-URL: http://www.cnl.salk.edu/~wiskott/Bibliographies/FaceProcessing.html
Title: Image Warping by Radial Basis Functions: Application to Facial Expressions  
Author: Nur Arad Nira Dyn, Daniel Reisfeld Yehezkel Yeshurun 
Address: Tel-Aviv 69978, Israel.  
Affiliation: School of Mathematical Sciences Tel-Aviv University  
Abstract: The human face is an elastic object. A natural paradigm for representing facial expressions is to form a complete 3D model of facial muscles and tissues. However, determining the actual parameter values for synthesizing and animating facial expressions is tedious; evaluating these parameters for facial expression analysis out of grey-level images is ahead of the state of the art in computer vision. Using only 2D face images and a small number of anchor points, we show that the method of radial basis functions provides a powerful mechanism for processing facial expressions. Although constructed specifically for facial expressions, our method is applicable to other elastic objects as well. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> T. Beier and S. Neely. </author> <title> Feature-based image metamorphosis. </title> <journal> Computer Graphics, </journal> <volume> 26(2) </volume> <pages> 35-42, </pages> <year> 1992. </year>
Reference-contexts: The affine transformation can compensate for various viewing conditions, but is not effective if the facial expression is modified. A recent 2D approach <ref> [1] </ref>, which was impressively used in a video clip, ignores the affine aspects of the transformation. All these points have motivated us to look for a smooth 2D transformation, which can be used to compensate for changes in facial expressions, based on a relatively small number of anchor points. <p> Moreover, the position of the points may not coincide with the position of physical features that are to be manipulated. Another algorithm that has cumulated in an impressive Michael Jackson video is the feature based image metamorphosis algorithm <ref> [1] </ref>, where the position of each point is the weighted average of affine transformations determined by corresponding line segments in the source and target images.
Reference: [2] <author> F. L. Bookstein. </author> <title> Principal warps: Thin-plate splines and the decomposition of deformations. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 11 </volume> <pages> 567-585, </pages> <year> 1989. </year>
Reference-contexts: The computation of the coefficients in (5) involves the solution of two square linear systems of size N + 3 (with the same matrix in each case). An algebraic treatment of the mapping (5) is given in <ref> [2] </ref>.
Reference: [3] <author> C. De Boor. </author> <title> On calculating with B-splines. </title> <journal> Journal of Approximation Theory, </journal> <volume> 6 </volume> <pages> 50-62, </pages> <year> 1972. </year>
Reference-contexts: Another possibility is constructing a pair of R 2 ! R functions where each of these functions is constructed by a tensor product of univariate functions. Such an approach involves tessellations of the plane, and requires a relatively large number of points to be specified <ref> [3, 5, 12] </ref>. This drawback applies to other tessellation dependent techniques, such as an adaptive meshing technique [30] which uses a facial muscle control model defined on a mesh. Turning to the family of mappings defined in the present work, 2D radial basis function transformations overcome the drawbacks previously mentioned.
Reference: [4] <author> H. H. Bulthoff and S. Edelman. </author> <title> Psychophysical support for a 2D view interpolation theory of object recognition. </title> <booktitle> Proceedings of the National Academy of Sciences, </booktitle> <volume> 89 </volume> <pages> 60-64, </pages> <year> 1992. </year>
Reference-contexts: An alternative approach is not to rely on a 3D model of the face, but rather to use a limited set of anchor points in 2D face images. This approach is attractive from the computational complexity point of view and is supported by psychophysical findings <ref> [4] </ref>. We have recently demonstrated the applicability of such an approach to face recognition. We have developed a system that automatically detects the most important facial features (eyes and mouth) using generalized symmetry [25, 26].
Reference: [5] <author> W. Dahmen and C. A. Micchelli. </author> <title> On linear independence of B-splines I: Triangulations of simploids. </title> <journal> SIAM journal of Numerical Analysis, </journal> <volume> 19 </volume> <pages> 993-1012, </pages> <year> 1982. </year>
Reference-contexts: Another possibility is constructing a pair of R 2 ! R functions where each of these functions is constructed by a tensor product of univariate functions. Such an approach involves tessellations of the plane, and requires a relatively large number of points to be specified <ref> [3, 5, 12] </ref>. This drawback applies to other tessellation dependent techniques, such as an adaptive meshing technique [30] which uses a facial muscle control model defined on a mesh. Turning to the family of mappings defined in the present work, 2D radial basis function transformations overcome the drawbacks previously mentioned.
Reference: [6] <author> J. Duchon. </author> <title> Splines minimizing rotation-invariant semi-norms in Sobolev spaces. </title> <editor> In C. K. Chui, L. L. Schumaker, and J. D. Ward, editors, </editor> <booktitle> Multivariate Approximation Theory, </booktitle> <pages> pages 85-100. </pages> <publisher> Birkhauser, </publisher> <address> Basel, </address> <year> 1979. </year> <month> 20 </month>
Reference-contexts: continuously differentiable, it is customary to use the functional J (f ) = R 2 (f xx ) 2 + 2 (f xy ) 2 + (f yy ) 2 d (x; y) as a measure of the total amount of bending of the surface (x; y; f (x; y)) <ref> [6] </ref>. The functional J is rotation invariant, again reflecting the fact that the data has no preferred orientations. <p> With this formulation in mind, it is known that the choice g (t) = t 2 log t (with g (0) = 0) provides a uniquely solvable interpolation problem (3) - (4) with m = 1, the solution of which minimizes the functional J <ref> [6] </ref>.
Reference: [7] <author> N. Dyn. </author> <title> Interpolation and approximation by radial and related functions. </title> <editor> In C. K. Chui, L. L. Schumaker, and J. D. Ward, editors, </editor> <booktitle> Approximation Theory VI, </booktitle> <volume> volume 1, </volume> <pages> pages 211-234. </pages> <publisher> Academic Press, </publisher> <year> 1989. </year>
Reference-contexts: Some classes of functions for which a unique solution to (2) exists for any N distinct points x i 2 R d , and are well known in the literature <ref> [7] </ref> are: 1. g (t) = (t 2 + c 2 ) ff ; 0 &lt; ff &lt; 1 (multiquadrics). 2. g (t) = log (t 2 + c 2 ) 1=2 ; c 2 1 (shifted log). 3. g (t) = exp (t 2 =oe 2 ) ; oe &gt;
Reference: [8] <author> N. Dyn, D. Levin, and S. Rippa. </author> <title> Numerical procedures for global surface fitting of scattered data by radial functions. </title> <journal> SIAM Journal of Scientific and Statistical Computing, </journal> <volume> 7 </volume> <pages> 639-659, </pages> <year> 1986. </year>
Reference-contexts: When using thin-plate spline, an alternative to using look-up tables is to use certain linear combinations of the original basis functions that decay polynomially; i.e., another basis (not necessarily radial) can be constructed using functions f , satisfying f (t) = O (t k ) <ref> [8] </ref>, We, however, were satisfied with look-up tables, and thus did not further persue this approach. 16 5 Discussion 5.1 Comparison with other Works In the last several years a consirable amount of research has been directed towards image warping in general and animation of facial expressions in particular.
Reference: [9] <author> N. Dyn and G. Wahba. </author> <title> On the estimation of functions of several variables from aggregated data. </title> <journal> SIAM Journal Of Mathematical Analysis, </journal> <volume> 13(1) </volume> <pages> 134-152, </pages> <year> 1982. </year>
Reference-contexts: i = 1; : : : ; N (8) N X a i q (x i ) = 0 for q (x; y) = 1; x; y; (9) where G is defined in equation (2), and (G + I) i is the i'th row of the matrix G + I <ref> [9] </ref>. A similar solution exists for T V . The equations given in (8) are the generalization of the interpolation equations, while those given in (9) guarantee the reproduction of linear polynomials. Some special cases of the functionals (6)-(7) are listed below: * N = 3.
Reference: [10] <author> S. Edelman, D. Reisfeld, and Y. Yeshurun. </author> <title> Learning to recognize faces from examples. </title> <booktitle> In Proceedings of the 2nd European Conference on Computer Vision, </booktitle> <pages> pages 787-791, </pages> <address> Santa Margherita Ligure, Italy, </address> <month> May </month> <year> 1992. </year>
Reference-contexts: We have also shown that normalizing a 2D image of a face using an affine transformation determined by the location of the eyes and mouth is an effective step towards face recognition <ref> [10] </ref>. The affine transformation can compensate for various viewing conditions, but is not effective if the facial expression is modified. A recent 2D approach [1], which was impressively used in a video clip, ignores the affine aspects of the transformation. <p> Using the center of the mouth as the third anchor point improves the quality of the superposition of facial images and is instrumental for face recognition <ref> [10] </ref>. and scaling) is used. A generalization is obtained by using an affine transformation (similarity and shear). Notice that the matching at the chin leaves room for improvement. This is fine for recognition purposes, since Mona and Venus posses different types of chins. <p> We have held experiments with other base functions such as t ff ; 1 &lt; ff &lt; 2, with comparable success. 5.3 General remarks A major motivation for this work was the successful use of affine transformations in face normalization <ref> [10] </ref>. One feature of affine mappings is their group structure: The family of affine transformations is closed under composition and inversion. This structure is attractive in interactive systems, since the position of the anchor points can be successively tuned. Thus, the final outcome is memoryless.
Reference: [11] <author> J. D. Foley, A. van Dam, S. K. Feiner, and J. F. Hughes. </author> <title> Computer graphics: </title> <booktitle> principles and practice. </booktitle> <publisher> Addison-Wesley, </publisher> <year> 1990. </year>
Reference-contexts: Some try to simulate muscle action, skin complexion and so on [30, 19, 24, 28], while others employ texture mapping techniques, which transform 2D texture planes onto the manifold determined by the 3D mesh representing face geometry <ref> [11, 16, 32, 31, 21] </ref>. The two methods can be combined to enhance their respective performance. However, determining the actual parameter values for synthesizing and animating facial expressions is a task requiring tedious interactions with a human operator. In the case of facial expression analysis, the situation is even worse.
Reference: [12] <author> P. Fong and H. P. Seidel. </author> <title> Control points for multivariate B-spline surfaces over arbitrary triangulations. </title> <journal> Computer Graphics Forum, </journal> <volume> 10 </volume> <pages> 309-317, </pages> <year> 1991. </year>
Reference-contexts: Another possibility is constructing a pair of R 2 ! R functions where each of these functions is constructed by a tensor product of univariate functions. Such an approach involves tessellations of the plane, and requires a relatively large number of points to be specified <ref> [3, 5, 12] </ref>. This drawback applies to other tessellation dependent techniques, such as an adaptive meshing technique [30] which uses a facial muscle control model defined on a mesh. Turning to the family of mappings defined in the present work, 2D radial basis function transformations overcome the drawbacks previously mentioned.
Reference: [13] <author> C. Frederick and E. L. Schwartz. </author> <title> Conformal image warping. </title> <journal> IEEE Computer Graphics and Applications, March, </journal> 1990 54-61, 1990. 
Reference-contexts: These techniques may exhibit impressive results, but suffer from the fundamental drawback that they are object dependent, i.e. a different model is needed for different non-rigid objects. The second family of techniques model independent simulate deformations without using any information on the object being deformed <ref> [27, 17, 13] </ref>. Recently these two approaches have been combined [23], in the sense that an association between mathematical parameters defining the transformations and real-life facial expressions was established, giving rise to an expression editor. <p> These constraints should rely on the position of few anchor points that can be detected automatically. There are various alternatives for the construction of such a mapping. Functions of a complex variable have been suggested in such a setting <ref> [13] </ref> since R 2 is naturally incorporated into their structure. Analyticity is a primary attribute of such functions, meaning that they are conformal transformations. Therefore these functions cannot reproduce a general affine mapping, a requirement which is paramount in our case.
Reference: [14] <author> F. Galton. </author> <title> Composite portraits, made by combining those of many different persons, into a single, resultant figure. </title> <journal> Journal of the Anthropological Institute, </journal> <volume> 8 </volume> <pages> 132-144, 1879. </pages>
Reference-contexts: For the technique to succeed, he carefully aligned the different images so that the pupils of the eyes coincided. He superimposed photographs of faces of army personnel for a definite portrait of health; of tuberculosis victims for disease; and of convicted felons for criminality <ref> [14, 15] </ref>. Being a member of the Victorian elite, he was surprised to see that a superimposed photograph of people convicted of murder, manslaughter, or violent robbery tended to look more respectable than the individual ones used to make it.
Reference: [15] <author> F. Galton. </author> <title> Personal identification and description - ii. </title> <booktitle> Nature, </booktitle> <pages> pages 201-203, </pages> <month> 22 Jun 1899. </month>
Reference-contexts: For the technique to succeed, he carefully aligned the different images so that the pupils of the eyes coincided. He superimposed photographs of faces of army personnel for a definite portrait of health; of tuberculosis victims for disease; and of convicted felons for criminality <ref> [14, 15] </ref>. Being a member of the Victorian elite, he was surprised to see that a superimposed photograph of people convicted of murder, manslaughter, or violent robbery tended to look more respectable than the individual ones used to make it.
Reference: [16] <author> P. S. Heckbert. </author> <title> Survey of texture mapping. </title> <journal> IEEE Computer Graphics and applications, </journal> <volume> 6(11) </volume> <pages> 56-67, </pages> <month> November </month> <year> 1986. </year>
Reference-contexts: Some try to simulate muscle action, skin complexion and so on [30, 19, 24, 28], while others employ texture mapping techniques, which transform 2D texture planes onto the manifold determined by the 3D mesh representing face geometry <ref> [11, 16, 32, 31, 21] </ref>. The two methods can be combined to enhance their respective performance. However, determining the actual parameter values for synthesizing and animating facial expressions is a task requiring tedious interactions with a human operator. In the case of facial expression analysis, the situation is even worse. <p> In cases where two anchor points are mapped to the same or almost the same location, the backward transformation is ill-defined and the forward transformation must be used. Overcoming the resulting aliasing problem is also a standard procedure <ref> [16] </ref>. We have found that, in practice, the two directions are useful. Of the following examples Figures 6 and 7 were obtained using the forward transformation, and the rest were obtained using the backward transformation.
Reference: [17] <author> Z. C. Li, C. Y. Suen, T. D. Bui, and Q. L. Gu. </author> <title> Harmonic models of shape transformations in digital images and patterns. CVGIP: Graphical Models and Image Processing, </title> <booktitle> 54(3) </booktitle> <pages> 198-209, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: These techniques may exhibit impressive results, but suffer from the fundamental drawback that they are object dependent, i.e. a different model is needed for different non-rigid objects. The second family of techniques model independent simulate deformations without using any information on the object being deformed <ref> [27, 17, 13] </ref>. Recently these two approaches have been combined [23], in the sense that an association between mathematical parameters defining the transformations and real-life facial expressions was established, giving rise to an expression editor.
Reference: [18] <author> W. R. Madych and S. A. Nelson. </author> <title> Multivariate interpolation: a variational theory. </title>
Reference-contexts: and without a polynomial term) minimizes the functional (f; f ), where (f; h) is defined by (f; h) = R 2 ( ^ f is the fourier transform of f ), and the minimum is taken over all functions f for which the functional (f; f ) is defined <ref> [18] </ref>.
Reference: [19] <author> N. Magnenat-Thalmann, P. Primeau, and D. Thalmann. </author> <title> Abstract muscle action procedures for face animation. </title> <journal> The Visual Computer, </journal> <volume> 3 </volume> <pages> 290-297, </pages> <year> 1988. </year>
Reference-contexts: Such applications require realistic reproduction of faces, as opposed to computer vision face recognition and classification tasks that do not require full reconstruction. Current approaches for synthesizing facial expressions use 3D face models, which employ a 3D mesh. Some try to simulate muscle action, skin complexion and so on <ref> [30, 19, 24, 28] </ref>, while others employ texture mapping techniques, which transform 2D texture planes onto the manifold determined by the 3D mesh representing face geometry [11, 16, 32, 31, 21]. The two methods can be combined to enhance their respective performance.
Reference: [20] <author> G. A. Micchelli. </author> <title> Interpolation of scattered data: distance matrices and conditionally positive definite functions. Constructive Approximation, </title> <booktitle> 2 </booktitle> <pages> 11-22, </pages> <year> 1986. </year>
Reference-contexts: This method of interpolation reproduces polynomials in m whenever (4) is uniquely solvable. Conditions for the unique solvability of (4) can be found in <ref> [20] </ref>. A large class of radial functions for which (4) is solvable at distinct fx i g has the additional property that the interpolant satisfies some variational principle, namely the interpolant minimizes some functional defined on a relevant space of functions.
Reference: [21] <author> M. Oka, K. Tsutsui, A. Ohba, Y. Kurauchi, and T. Tago. </author> <title> Real-time manipulation of texture mapped surfaces. </title> <journal> Computer Graphics, </journal> <volume> 21(4) </volume> <pages> 181-188, </pages> <year> 1987. </year> <month> 21 </month>
Reference-contexts: Some try to simulate muscle action, skin complexion and so on [30, 19, 24, 28], while others employ texture mapping techniques, which transform 2D texture planes onto the manifold determined by the 3D mesh representing face geometry <ref> [11, 16, 32, 31, 21] </ref>. The two methods can be combined to enhance their respective performance. However, determining the actual parameter values for synthesizing and animating facial expressions is a task requiring tedious interactions with a human operator. In the case of facial expression analysis, the situation is even worse.
Reference: [22] <author> F. I. Parke. </author> <title> Parameterized models for facial animation. </title> <journal> IEEE Computer Graphics and Applications, </journal> <pages> pages 61-68, </pages> <month> November </month> <year> 1982. </year>
Reference-contexts: From our point of view models and procedures intended at facial animation may be classified into two families: The first model dependent, generates facial expressions by first constructing a mathematical model of the physical face, and then defining the dynamics which govern the non-rigid motion of the object, e.g. <ref> [22, 28] </ref>. These techniques may exhibit impressive results, but suffer from the fundamental drawback that they are object dependent, i.e. a different model is needed for different non-rigid objects. The second family of techniques model independent simulate deformations without using any information on the object being deformed [27, 17, 13].
Reference: [23] <author> P.Kalra, A.Magnili, N. Magnenat Thalmann, and D. Thalmann. </author> <title> Simulation of facial muscle actions based on rational free form deformations. </title> <address> CGF, 11(3):C-59 - C-69, </address> <year> 1992. </year>
Reference-contexts: The second family of techniques model independent simulate deformations without using any information on the object being deformed [27, 17, 13]. Recently these two approaches have been combined <ref> [23] </ref>, in the sense that an association between mathematical parameters defining the transformations and real-life facial expressions was established, giving rise to an expression editor. Ideally, model dependant warps mimic the real world realistically, however at the present they are much simpler than the real world.
Reference: [24] <author> S. Platt and N. I. Badler. </author> <title> Animating facial expression. </title> <journal> Computer Graphics, </journal> <volume> 15(3) </volume> <pages> 245-252, </pages> <year> 1981. </year>
Reference-contexts: Such applications require realistic reproduction of faces, as opposed to computer vision face recognition and classification tasks that do not require full reconstruction. Current approaches for synthesizing facial expressions use 3D face models, which employ a 3D mesh. Some try to simulate muscle action, skin complexion and so on <ref> [30, 19, 24, 28] </ref>, while others employ texture mapping techniques, which transform 2D texture planes onto the manifold determined by the 3D mesh representing face geometry [11, 16, 32, 31, 21]. The two methods can be combined to enhance their respective performance.
Reference: [25] <author> D. Reisfeld, H. Wolfson, and Y. Yeshurun. </author> <title> Detection of interest points using symmetry. </title> <booktitle> In Third International Conference on Computer Vision, </booktitle> <pages> pages 62-65, </pages> <address> Osaka, Japan, </address> <month> December </month> <year> 1990. </year>
Reference-contexts: We have recently demonstrated the applicability of such an approach to face recognition. We have developed a system that automatically detects the most important facial features (eyes and mouth) using generalized symmetry <ref> [25, 26] </ref>. We have also shown that normalizing a 2D image of a face using an affine transformation determined by the location of the eyes and mouth is an effective step towards face recognition [10].
Reference: [26] <author> D. Reisfeld and Y. Yeshurun. </author> <title> Robust detection of facial features by generalized symmetry. </title> <booktitle> In Proceedings of the 11th International Conference on Pattern Recognition, The Hague, </booktitle> <address> Netherlands, </address> <month> September </month> <year> 1992. </year>
Reference-contexts: We have recently demonstrated the applicability of such an approach to face recognition. We have developed a system that automatically detects the most important facial features (eyes and mouth) using generalized symmetry <ref> [25, 26] </ref>. We have also shown that normalizing a 2D image of a face using an affine transformation determined by the location of the eyes and mouth is an effective step towards face recognition [10].
Reference: [27] <author> T. W. Sederberg and S. R. Parry. </author> <title> Free-form deformation of solid geometric models. </title> <booktitle> In SIGGRAPH '86, </booktitle> <pages> pages 151-160, </pages> <year> 1986. </year>
Reference-contexts: These techniques may exhibit impressive results, but suffer from the fundamental drawback that they are object dependent, i.e. a different model is needed for different non-rigid objects. The second family of techniques model independent simulate deformations without using any information on the object being deformed <ref> [27, 17, 13] </ref>. Recently these two approaches have been combined [23], in the sense that an association between mathematical parameters defining the transformations and real-life facial expressions was established, giving rise to an expression editor. <p> Another model that defines a transformation by the position of anchor points is the free-form deformation model of Sederberg and Parry <ref> [27] </ref>. In this model the anchors (control points) must lie on a regular grid, thus imposing at least 4 control points in the planar case, but typically many more. Moreover, the position of the points may not coincide with the position of physical features that are to be manipulated.
Reference: [28] <author> D. Terzopolous and K. Waters. </author> <title> Physically based facial modeling, analysis, and animation. </title> <journal> Journal of Visualization and Animation, </journal> <volume> 1(2) </volume> <pages> 73-80, </pages> <year> 1990. </year>
Reference-contexts: Such applications require realistic reproduction of faces, as opposed to computer vision face recognition and classification tasks that do not require full reconstruction. Current approaches for synthesizing facial expressions use 3D face models, which employ a 3D mesh. Some try to simulate muscle action, skin complexion and so on <ref> [30, 19, 24, 28] </ref>, while others employ texture mapping techniques, which transform 2D texture planes onto the manifold determined by the 3D mesh representing face geometry [11, 16, 32, 31, 21]. The two methods can be combined to enhance their respective performance. <p> From our point of view models and procedures intended at facial animation may be classified into two families: The first model dependent, generates facial expressions by first constructing a mathematical model of the physical face, and then defining the dynamics which govern the non-rigid motion of the object, e.g. <ref> [22, 28] </ref>. These techniques may exhibit impressive results, but suffer from the fundamental drawback that they are object dependent, i.e. a different model is needed for different non-rigid objects. The second family of techniques model independent simulate deformations without using any information on the object being deformed [27, 17, 13].
Reference: [29] <author> C. W. A. M. van Overveld. </author> <title> Beyond bump maps: nonlinear mappings for the modeling of geometric details in computer graphics. </title> <booktitle> Computer Aided Design, </booktitle> <volume> 24(4) </volume> <pages> 201-209, </pages> <month> April </month> <year> 1992. </year>
Reference-contexts: A model-free warping algorithm driven by the position of source and target anchor points is the nonlinear mappings for modeling of geometric details of van Overveld <ref> [29] </ref>. Like our model, the warp is affine whenever possible. However, when more than three anchors are used, it is rare that affine warping is possible, and a definition of a generalization of affine warping is needed.
Reference: [30] <author> K. Waters and D. Terzopoulos. </author> <title> Modeling and animating faces using scanned data. </title> <journal> The Journal Of Visualization and Computer Animation, </journal> <volume> 2(4) </volume> <pages> 123-128, </pages> <year> 1991. </year>
Reference-contexts: Such applications require realistic reproduction of faces, as opposed to computer vision face recognition and classification tasks that do not require full reconstruction. Current approaches for synthesizing facial expressions use 3D face models, which employ a 3D mesh. Some try to simulate muscle action, skin complexion and so on <ref> [30, 19, 24, 28] </ref>, while others employ texture mapping techniques, which transform 2D texture planes onto the manifold determined by the 3D mesh representing face geometry [11, 16, 32, 31, 21]. The two methods can be combined to enhance their respective performance. <p> Such an approach involves tessellations of the plane, and requires a relatively large number of points to be specified [3, 5, 12]. This drawback applies to other tessellation dependent techniques, such as an adaptive meshing technique <ref> [30] </ref> which uses a facial muscle control model defined on a mesh. Turning to the family of mappings defined in the present work, 2D radial basis function transformations overcome the drawbacks previously mentioned.
Reference: [31] <author> L. Williams. </author> <title> Performance-driven facial animation. </title> <journal> Computer Graphics, </journal> <volume> 24(4) </volume> <pages> 235-242, </pages> <year> 1990. </year>
Reference-contexts: Some try to simulate muscle action, skin complexion and so on [30, 19, 24, 28], while others employ texture mapping techniques, which transform 2D texture planes onto the manifold determined by the 3D mesh representing face geometry <ref> [11, 16, 32, 31, 21] </ref>. The two methods can be combined to enhance their respective performance. However, determining the actual parameter values for synthesizing and animating facial expressions is a task requiring tedious interactions with a human operator. In the case of facial expression analysis, the situation is even worse.
Reference: [32] <author> J. F. S. Yau and A. D. Duffy. </author> <title> A texture mapping approach to 3-D facial image synthesis. </title> <journal> Computer Graphics Forum, </journal> <volume> 17 </volume> <pages> 129-143, </pages> <year> 1988. </year> <month> 22 </month>
Reference-contexts: Some try to simulate muscle action, skin complexion and so on [30, 19, 24, 28], while others employ texture mapping techniques, which transform 2D texture planes onto the manifold determined by the 3D mesh representing face geometry <ref> [11, 16, 32, 31, 21] </ref>. The two methods can be combined to enhance their respective performance. However, determining the actual parameter values for synthesizing and animating facial expressions is a task requiring tedious interactions with a human operator. In the case of facial expression analysis, the situation is even worse.
References-found: 32

