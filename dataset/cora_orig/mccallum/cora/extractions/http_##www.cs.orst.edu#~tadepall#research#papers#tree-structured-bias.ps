URL: http://www.cs.orst.edu/~tadepall/research/papers/tree-structured-bias.ps
Refering-URL: 
Root-URL: 
Email: (tadepalli@cs.orst.edu)  (russell@cs.berkeley.edu)  
Phone: (541)-737-5552  (510) 642-4964  
Title: Learning from Examples and Membership Queries with Structured Determinations  
Author: Prasad Tadepalli Stuart Russell 
Date: December 16, 1997  
Address: Corvallis, OR 97331  Berkeley, CA 94720  
Affiliation: Department of Computer Science Oregon State University  Computer Science Division University of California  
Abstract: It is well known that prior knowledge or bias can speed up learning, at least in theory. It has proved difficult to make constructive use of prior knowledge, so that approximately correct hypotheses can be learned efficiently. In this paper, we consider a particular form of bias which consists of a set of "determinations." A set of attributes is said to determine a given attribute if the latter is purely a function of the former. The bias is tree-structured if there is a tree of attributes such that the attribute at any node is determined by its children, where the leaves correspond to input attributes and the root corresponds to the target attribute for the learning problem. The set of allowed functions at each node is called the basis. The tree-structured bias restricts the target functions to those representable by a read-once formula (a Boolean formula in which each variable occurs at most once) of a given structure over the basis functions. We show that efficient learning using a given tree-structured bias from random examples and membership queries is possible if the basis class itself is learnable and obeys some mild closure conditions. The algorithm uses a form of controlled experimentation in order to learn each part of the overall function, fixing the inputs to the other parts of the function at appropriate values. We present empirical results that demonstrate that when a tree-structured bias is available, our method significantly improves upon knowledge-free induction. We also show that there are hard cryptographic limitations 
Abstract-found: 1
Intro-found: 1
Reference: [ Aizenstein and Pitt, 1991 ] <author> H. Aizenstein and L. Pitt. </author> <title> Exact learning of read-twice DNF formulas. </title> <booktitle> In Proceedings of the 32 nd Annual IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pages 170-179, </pages> <address> Washington, D.C., </address> <year> 1991, </year> <title> August 1991. </title> <publisher> IEEE Computer Society Press. </publisher>
Reference: [ Angluin and Kharitonov, 1995 ] <author> D. Angluin and M. </author> <title> Kharitonov. </title> <journal> When won't membership queries help? Journal of Computer and Systems Sciences, </journal> <volume> 50(2) </volume> <pages> 336-355, </pages> <year> 1995. </year>
Reference-contexts: In the framework of prediction-preserving reducibility with membership queries, we start with two representations of function spaces F and F 0 and define a reduction that will allow us to convert a polynomial-time pwm-prediction algorithm M 0 for F 0 into a polynomial-time pwm-prediction algorithm M for F <ref> [ Angluin and Kharitonov, 1995 ] </ref> . If F is known to be hard to predict, so is F 0 . <p> While h and r must be computable in polynomial time, g need not be, but we must ensure that it maps to functions whose representation sizes are bounded by a polynomial in the sizes of the original functions. The reader is referred to <ref> [ Angluin and Kharitonov, 1995 ] </ref> for a more formal description of prediction preserving reducibility. We now state our main theorem which is based on a prediction preserving transformation of learning arbitrary boolean functions to functions induced by fixed dags.
Reference: [ Angluin et al., 1993 ] <author> D. Angluin, L. Hellerstein, and M. Karpinski. </author> <title> Learning read-once formulas with queries. </title> <journal> Journal of the ACM, </journal> <volume> 40(1) </volume> <pages> 185-210, </pages> <year> 1993. </year>
Reference-contexts: The class of k-decision lists is closed under variable negation, pac-learnable, and properly includes k-DNF and k-CNF [ Kohavi and Benson, 1993 ] . Monotone DNF-formulas are pwm-predictable <ref> [ Angluin et al., 1993 ] </ref> , closed under projection, but not under variable negation; however, they do satisfy our condition because the closure of monotone DNF-formulas under variable negation, called unate formulas, are pwm-predictable [ Angluin et al., 1993 ] . <p> Monotone DNF-formulas are pwm-predictable <ref> [ Angluin et al., 1993 ] </ref> , closed under projection, but not under variable negation; however, they do satisfy our condition because the closure of monotone DNF-formulas under variable negation, called unate formulas, are pwm-predictable [ Angluin et al., 1993 ] . Similarly, we can use Bshouty's [ 1993 ] algorithm for learning decision trees. However, there are some interesting pwm-predictable classes such as conjunctions of Horn clauses for which the closure under variable negation does not hold, and hence our theorem does not apply.
Reference: [ Angluin, 1988 ] <author> D. Angluin. </author> <title> Queries and concept learning. </title> <journal> Machine Learning, </journal> <volume> 2(4) </volume> <pages> 319-342, </pages> <year> 1988. </year>
Reference-contexts: Bshouty, Hancock, and Hellerstein [ 1992 ] and Tadepalli [ 1993 ] showed that the use of membership queries <ref> [ Angluin, 1988 ] </ref> as well as random examples renders the learning problem with a k-TSB bias tractable. Tadepalli assumes that the determination tree is given, whereas Bshouty et al. infer the tree structure as well as the target function. <p> to be tree-structured in that even mild deviations from the tree-structure could make the learning problem computationally intractable. 3 Learning from Examples and Membership Queries In this paper, we will be using a version of Probably Approximately Correct (PAC) learning [ Valiant, 1984 ] , extended to include membership queries <ref> [ Angluin, 1988 ] </ref> . We restrict ourselves here to learning Boolean functions. An assignment is a mapping from attributes B 1 ; : : : ; B n to their values in = f0; 1g. n denotes the set of binary strings of length n. <p> The more theoretically inclined reader is referred to these excellent pieces of work, particularly the last one, which subsumes the other papers. All of this work is based on exact learning using equivalence queries as well as membership queries <ref> [ Angluin, 1988 ] </ref> . We call this model the "exact learning model" from now on. <p> The model of exact learning with equivalence and membership queries is theoretically attractive because it sidesteps the need for probability distributions. Positive results of this model directly yield positive results under the pwm-predictability model using standard transformations <ref> [ Angluin, 1988 ] </ref> . However, they are not equivalent because a negative result in the equivalence plus membership query model does not imply that pwm-learning is not possible. More specifically, Lemma 5 of [ Bshouty et al., 1995a ] is the exact-model counterpart of our Theorem 8.
Reference: [ Baffes and Mooney, 1993 ] <author> P.T. Baffes and R.J. Mooney. </author> <title> Extending theory refinement to m-of-n rules. </title> <journal> Informatica, </journal> <volume> 17 </volume> <pages> 387-397, </pages> <year> 1993. </year>
Reference-contexts: Work in theory refinement seeks to address the above issue by discouraging radical revisions of the theory and by requiring that the learning program makes only minimal changes to the input theory. We ran a theory revision program, called NEITHER <ref> [ Baffes and Mooney, 1993 ] </ref> , on our problem. NEITHER is a propositional theory refinement program that accepts theories described as Horn clauses, and refines them until all the training examples are correctly classified.
Reference: [ Blumer et al., 1989 ] <author> A. Blumer, A. Ehrenfeucht, D. Haussler, and M.K. Warmuth. </author> <title> Learn-ability and the Vapnik-Chervonenkis dimension. </title> <journal> Journal of the ACM, </journal> <volume> 36(4) </volume> <pages> 929-965, </pages> <year> 1989. </year>
Reference-contexts: More general definitions allow it to grow slowly with the number of examples, e.g., according to O (m ff ), where 0 ff &lt; 1 <ref> [ Blumer et al., 1989 ] </ref> . Thus, compression algorithms compress the training sample into a reasonably small hypothesis and are sometimes called "Ockham algorithms," named after William of Ockham, the original proponent of "Ockham's Razor." The next theorem follows from the results of [ Blumer et al., 1989 ] and <p> ), where 0 ff &lt; 1 <ref> [ Blumer et al., 1989 ] </ref> . Thus, compression algorithms compress the training sample into a reasonably small hypothesis and are sometimes called "Ockham algorithms," named after William of Ockham, the original proponent of "Ockham's Razor." The next theorem follows from the results of [ Blumer et al., 1989 ] and establishes that a compression algorithm can be easily converted into a prediction algorithm by making sure that it is called with a sufficiently large random sample.
Reference: [ Bshouty et al., 1992 ] <author> N.H. Bshouty, T.R. Hancock, and L. Hellerstein. </author> <title> Learning Boolean read-once formulas with arbitrary symmetric and constant fan-in gates. </title> <booktitle> In Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, </booktitle> <pages> pages 1-15, </pages> <address> Pittsburgh, PA, 1992. </address> <publisher> ACM Press. </publisher>
Reference-contexts: The fan-in of the tree is the maximum fan-in over all nodes. The fan-out of the tree is the maximum fan-out over all nodes, which is 1. To nontrivially constrain the set of allowed functions, the fan-in of the tree was originally restricted to a constant k <ref> [ Russell, 1989; Bshouty et al., 1992; Tadepalli, 1993 ] </ref> | the k-TSB bias. In this paper, we consider a generalized tree-structured bias in which the nodes have arbitrarily large fan-ins. <p> Equivalence queries are in the form of "is the target function the same as g?" If g is the target function, the teacher answers `yes'; otherwise the teacher responds with a counterexample, i.e., an example where g and the target function disagree. In <ref> [ Bshouty et al., 1992 ] </ref> and [ Bshouty et al., 1995a ] , the authors describe a learning algorithm that exactly identifies the determination tree (skeleton) and the target function from membership and equivalence queries for constant fan-in or symmetric internal functions.
Reference: [ Bshouty et al., 1995a ] <author> N. H. Bshouty, T.R. Hancock, and L. Hellerstein. </author> <title> Learning Boolean read-once formulas over generalized bases. </title> <journal> Journal of Computer and Systems Sciences, </journal> <volume> 50(3) </volume> <pages> 521-542, </pages> <year> 1995. </year>
Reference-contexts: In Section 8, we discuss the relationship of our work to the work on learning read-once formulas, especially to that of <ref> [ Bshouty et al., 1995a ] </ref> . Our algorithm can be interpreted to mean that the unobservability of the internal attribute values does not pose unsurmountable difficulties in learning functions consistent with a given determination tree. <p> Proof: Follows immediately from Theorem 9 and the result of Kearns and Valiant, which shows that learning Boolean functions is as hard as inverting certain one-way functions, e.g., breaking the RSA cryptosystem or factoring Blum integers [ Kearns and Valiant, 1994 ] . 2 It was shown in <ref> [ Bshouty et al., 1995a ] </ref> that exact learning of read-twice formulas with equivalence and membership queries is hard when the internal functions include f, OR, N OT , AN Dg. <p> In [ Bshouty et al., 1992 ] and <ref> [ Bshouty et al., 1995a ] </ref> , the authors describe a learning algorithm that exactly identifies the determination tree (skeleton) and the target function from membership and equivalence queries for constant fan-in or symmetric internal functions. A symmetric Boolean function gives the same output for any permutation of its inputs. <p> Hence, the main results of Bshouty et al. include learning the skeleton of the formulas, but are restricted to the union of symmetric and constant fan-in basis functions <ref> [ Bshouty et al., 1995a ] </ref> . For example, arbitrary k-decision lists cannot be represented as compositions of symmetric or constant fan-in functions, and hence their algorithm cannot be used when the basis includes k-decision lists. <p> However, they are not equivalent because a negative result in the equivalence plus membership query model does not imply that pwm-learning is not possible. More specifically, Lemma 5 of <ref> [ Bshouty et al., 1995a ] </ref> is the exact-model counterpart of our Theorem 8. Although our theorems are based on similar insights, neither of them implies the other. Their lemma assumes that the internal functions are exactly learnable, a strictly stronger assumption than ours that they are pwm-predictable. <p> We also provide empirical support for the work on read-once formulas by showing that our implementation achieves smaller error rates from the same data when compared to knowledge-free induction algorithms. Our results and those in <ref> [ Bshouty et al., 1995a ] </ref> suggest that the experimental learning community needs to pay attention to theoretical work on learning from membership queries; the performance of practical induction systems can perhaps be improved significantly compared to an approach based purely on random examples. 54 The ideas of Bshouty et al. <p> These assumptions impose a tree-structure on the network and constrain the basis functions to be linear threshold functions. Their algorithm learns the network structure using recursive partitioning of the input variables as in <ref> [ Bshouty et al., 1995a ] </ref> , and learns the linearly separable internal functions using Karmarkar's linear programming algorithm [ Karmarkar, 1994 ] . TSB-2 is a successor of TSB-1, which was restricted to constant fan-in determination trees [ Tadepalli, 1993 ] . <p> On the other hand, this problem should not arise with TSB-2 because of its ability to learn each of the internal functions locally. Schlimmer [ 1993 ] describes a program that learns determinations from data using a semi-exhaustive search [ Schlimmer, 1993 ] . The algorithms of <ref> [ Bshouty et al., 1995a ] </ref> for learning the skeletons of the read-once formulas have worst case complexities of the order of O (n k+1 ) for k-TSB and O (n 6 ) for TSB with symmetric basis functions. <p> On the theoretical side, the most interesting open problem is to learn the tree structure under the weakest possible assumptions about the internal (basis) functions. The positive results so far have been restricted to the union of constant fan-in and symmetric basis functions <ref> [ Bshouty et al., 1995a ] </ref> . The question of whether this class can be extended to include all learnable functions that obey our closure properties is still open. It is possible that there are basis functions for which learning the tree-structure is hard under the conditions of Theorem 8.
Reference: [ Bshouty et al., 1995b ] <author> N.H. Bshouty, T.R. Hancock, and L. Hellerstein. </author> <title> Learning arithmetic read-once formulas. </title> <journal> SIAM Journal on Computing, </journal> <volume> 24(4) </volume> <pages> 706-35, </pages> <year> 1995. </year> <month> 59 </month>
Reference-contexts: We also foresee that real-world learning might require the introduction of restricted classes of non-Boolean functions at the nodes of the tree. There has been some work in computational learning theory on learning arithmetic read-once formulas that may be useful here <ref> [ Bshouty et al., 1995b ] </ref> . We expect that the basic insights used in TSB-2, including distinguishing assignments, will carry over into the more 57 general setting.
Reference: [ Bshouty, 1993 ] <author> N.H. Bshouty. </author> <title> Exact learning via the monotone theory. </title> <booktitle> In Proceedings of the 34 th IEEE Symposium on the Foundations of Computer Science, </booktitle> <pages> pages 302-311, </pages> <address> Los Alamitos, CA, 1993. </address> <publisher> IEEE Computer Society Press. </publisher>
Reference: [ Cohen, 1991 ] <author> W.W. Cohen. </author> <title> The generality of overgenerality. </title> <booktitle> In Proceedings of the Eighth International Workshop on Machine Learning, </booktitle> <pages> pages 490-494, </pages> <address> Evanston, IL, 1991. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: For example, FOCL [ Pazzani and Kibler, 1992 ] , and Grendel [ Cohen, 1992 ] learn general relational concepts and are capable of making use of background knowledge expressed as first-order Horn clauses. As suggested by Cohen, determinations can be expressed as overgeneral Horn clauses <ref> [ Cohen, 1991 ] </ref> .
Reference: [ Cohen, 1992 ] <author> W.W. Cohen. </author> <title> Compiling prior knowledge into an explicit bias. </title> <booktitle> In Proceedings of the Ninth International Conference on Machine Learning, </booktitle> <pages> pages 102-110, </pages> <address> Austin, TX, 1992. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: In this way, the system need never consider hypotheses that are not consistent with the background knowledge. Implemented systems of this type include Odysseus [ Wilkins et al., 1987 ] , KBANN [ Shavlik and Towell, 1989 ] , and Grendel <ref> [ Cohen, 1992 ] </ref> , as well as the work of Getoor [ 1989 ] which we discuss below. <p> Such improved programs could be used in concert with ours to provide a more complete learning system. There has been considerable amount of research on using prior knowledge in learning. For example, FOCL [ Pazzani and Kibler, 1992 ] , and Grendel <ref> [ Cohen, 1992 ] </ref> learn general relational concepts and are capable of making use of background knowledge expressed as first-order Horn clauses. As suggested by Cohen, determinations can be expressed as overgeneral Horn clauses [ Cohen, 1991 ] .
Reference: [ Cooper and Herskovits, 1992 ] <author> G.F. Cooper and E. Herskovits. </author> <title> A Bayesian method for the induction of probabilistic networks from data. </title> <journal> Machine Learning, </journal> <volume> 9(4) </volume> <pages> 309-348, </pages> <month> October </month> <year> 1992. </year>
Reference-contexts: Although there are a few results in learning Bayesian networks from data when all the variables are observable <ref> [ Cooper and Herskovits, 1992 ] </ref> , learning with hidden variables is much harder (see [ Russell et al., 1995 ] and [ Friedman, 1997 ] for recent algorithms).
Reference: [ Darwiche and Pearl, 1994 ] <author> A. Darwiche and J. Pearl. </author> <title> Symbolic causal networks. </title> <booktitle> In Proceeding of the Twelfth National Conference on Artificial Intelligence, </booktitle> <pages> pages 238-244, </pages> <address> Seattle, WA, 1994. </address> <publisher> AAAI Press. </publisher>
Reference: [ Davies, 1985 ] <author> T. Davies. </author> <title> Analogy. Informal note IN-CSLI-85-4, </title> <publisher> CSLI, </publisher> <address> Stanford Unviersity, </address> <year> 1985. </year>
Reference-contexts: For example, we say that fA; B; Cg D, read the set fA; B; Cg determines D, if the values of A; B and C are sufficient to determine the value of D. Since determinations are a form of first-order knowledge <ref> [ Davies, 1985 ] </ref> , they can be derived using logical inference from suitable background knowledge, including other determinations. Thus, armed with an appropriate inference algorithm and a knowledge base, a learning system can derive a restricted hypothesis vocabulary for its current learning task.
Reference: [ Friedman, 1997 ] <author> N. Friedman. </author> <title> Learning belief networks in the presence of missing values and hidden variables. </title> <booktitle> In Proceedings of International Conference on Machine Learning, </booktitle> <pages> pages 125-133, </pages> <address> Nashville, TN, 1997. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Although there are a few results in learning Bayesian networks from data when all the variables are observable [ Cooper and Herskovits, 1992 ] , learning with hidden variables is much harder (see [ Russell et al., 1995 ] and <ref> [ Friedman, 1997 ] </ref> for recent algorithms). As yet, no work has been done on using membership queries in such algorithms, nor on ascertaining the computational complexity of the problem. It may be possible to extend our algorithms to efficiently learn tree-structured Bayesian networks with hidden variables.
Reference: [ Getoor, 1989 ] <author> L. Getoor. </author> <title> The instance description: How it can be derived and the use of its derivation. </title> <type> Unpublished ms report, </type> <institution> Computer Science Division, University of California, Berkeley, </institution> <address> CA, </address> <year> 1989. </year> <note> Later published as NASA Ames Research Center Technical Report IC-94-04. </note>
Reference-contexts: See [ Russell, 1989 ] and <ref> [ Getoor, 1989 ] </ref> for more examples.) By construction, the attributes at internal nodes of the derivation tree will be unobservable. <p> The example of this section is adapted from Getoor's work <ref> [ Getoor, 1989 ] </ref> . A credit card 6 company may be interested in predicting the expected profits from offering a credit to an individual. <p> TSB-2 is a successor of TSB-1, which was restricted to constant fan-in determination trees [ Tadepalli, 1993 ] . Other than TSB-1, there were two previous implementations of tree-structured bias <ref> [ Getoor, 1989 ] </ref> (see also [ Russell, 1989 ] ). However, both of them have only had limited success. One of them assumes that the Boolean functions at each node are monotone, yielding a very simple polytime algorithm with membership queries.
Reference: [ Hancock and Hellerstein, 1991 ] <author> T. Hancock and L. Hellerstein. </author> <title> Learning read-once formulas over fields and extended bases. </title> <booktitle> In Proceedings of the Fourth Annual Workshop on Computational Learning Theory, </booktitle> <pages> pages 326-336, </pages> <address> Santa Cruz, CA, 1991. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: [ Hancock et al., 1994 ] <author> T.R. Hancock, M. Golea, and M. Marchand. </author> <title> Learning nonoverlapping perceptron networks from examples and membership queries. </title> <journal> Machine Learning, </journal> <volume> 16(3) </volume> <pages> 161-183, </pages> <year> 1994. </year>
Reference: [ Hancock, 1991 ] <author> T. Hancock. </author> <title> Learning 2DNF formulas and k decision trees. </title> <booktitle> In Proceed--ings of the Fourth Annual Workshop on Computational Learning Theory, </booktitle> <pages> pages 199-209, </pages> <address> San Mateo, CA, 1991. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: [ Hirsh, 1990 ] <author> H. Hirsh. </author> <title> Knowledge as bias. In D.P. </title> <editor> Benjamin, editor, </editor> <booktitle> Change of Representation and Inductive Bias, </booktitle> <pages> pages 209-221. </pages> <publisher> Kluwer, Norwell, </publisher> <address> MA, </address> <year> 1990. </year>
Reference-contexts: This approach has proved effective in some cases. Implemented systems of this type include mEBG <ref> [ Hirsh, 1990 ] </ref> and GOLEM [ Muggleton and Feng, 1990 ] . A third approach is to use the background knowledge to generate a "template" for the hypothesis, which can be filled in using the observations to constrain the functions that make up the template.
Reference: [ Karmarkar, 1994 ] <author> N. Karmarkar. </author> <title> A new polynomial time algorithm for linear programming. </title> <journal> Combinatorica, </journal> <volume> 4 </volume> <pages> 373-395, </pages> <year> 1994. </year>
Reference-contexts: Their algorithm learns the network structure using recursive partitioning of the input variables as in [ Bshouty et al., 1995a ] , and learns the linearly separable internal functions using Karmarkar's linear programming algorithm <ref> [ Karmarkar, 1994 ] </ref> . TSB-2 is a successor of TSB-1, which was restricted to constant fan-in determination trees [ Tadepalli, 1993 ] . Other than TSB-1, there were two previous implementations of tree-structured bias [ Getoor, 1989 ] (see also [ Russell, 1989 ] ).
Reference: [ Kearns and Valiant, 1994 ] <author> M. Kearns and L.G. Valiant. </author> <title> Cryptographic limitations on learning Boolean formulae and finite automata. </title> <journal> Journal of the ACM, </journal> <volume> 41(1) </volume> <pages> 67-95, </pages> <year> 1994. </year>
Reference-contexts: Since learning arbitrary Boolean functions is as hard as inverting one-way functions <ref> [ Kearns and Valiant, 1994 ] </ref> , learning with tree-structured bias with random examples alone is believed to be intractable. <p> Since learning arbitrary Boolean functions is as hard as inverting one-way functions, learning with tree-structured bias with random examples alone is believed to be intractable <ref> [ Kearns and Valiant, 1994 ] </ref> . To see that tree-structured bias cannot be implemented with membership queries alone, consider the class of Boolean functions that output 1 on at most one input and output 0 on all others. <p> Proof: Follows immediately from Theorem 9 and the result of Kearns and Valiant, which shows that learning Boolean functions is as hard as inverting certain one-way functions, e.g., breaking the RSA cryptosystem or factoring Blum integers <ref> [ Kearns and Valiant, 1994 ] </ref> . 2 It was shown in [ Bshouty et al., 1995a ] that exact learning of read-twice formulas with equivalence and membership queries is hard when the internal functions include f, OR, N OT , AN Dg.
Reference: [ Kohavi and Benson, 1993 ] <author> R. Kohavi and S. Benson. </author> <title> Research note on decision lists. </title> <journal> Machine Learning, </journal> <volume> 13(1) </volume> <pages> 131-134, </pages> <year> 1993. </year>
Reference-contexts: The class of k-decision lists is closed under variable negation, pac-learnable, and properly includes k-DNF and k-CNF <ref> [ Kohavi and Benson, 1993 ] </ref> .
Reference: [ Mahadevan and Tadepalli, 1994 ] <author> S. Mahadevan and P. Tadepalli. </author> <title> Quantifying prior determination knowledge using PAC learning model. </title> <journal> Machine Learning, </journal> <volume> 17(1) </volume> <pages> 69-105, </pages> <year> 1994. </year>
Reference-contexts: Since this restricted vocabulary may be much smaller than the total set of features available, the learning system may be able to learn from many fewer examples in much less time <ref> [ Russell, 1989; Mahadevan and Tadepalli, 1994 ] </ref> .
Reference: [ Mitchell, 1980 ] <author> T. Mitchell. </author> <title> The need for biases in learning generalizations. </title> <editor> In J. Shav-lik and T.G. Dietterich, editors, </editor> <booktitle> Readings in Machine Learning, </booktitle> <pages> pages 184-191. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1980. </year> <note> Originally published as Rutgers University technical report. </note>
Reference-contexts: 1 Introduction Bias is the term used in machine learning to refer to any information, implicit or explicit, that a learning algorithm uses to select hypotheses, beyond mere consistency with the available observations. Without bias, inductive learning is impossible <ref> [ Mitchell, 1980 ] </ref> . Bias can take many forms, including restrictions on the space of hypotheses that the learning algorithm can consider.
Reference: [ Muggleton and Feng, 1990 ] <author> S. Muggleton and C. Feng. </author> <title> Efficient induction of logic programs. </title> <booktitle> In Proceedings of the First Conference on Algorithmic Learning Theory, </booktitle> <pages> pages 369-381, </pages> <address> Tokyo, Japan, 1990. </address> <publisher> Ohmsha. </publisher>
Reference-contexts: This approach has proved effective in some cases. Implemented systems of this type include mEBG [ Hirsh, 1990 ] and GOLEM <ref> [ Muggleton and Feng, 1990 ] </ref> . A third approach is to use the background knowledge to generate a "template" for the hypothesis, which can be filled in using the observations to constrain the functions that make up the template.
Reference: [ Pagallo and Haussler, 1990 ] <author> G. Pagallo and D. Haussler. </author> <title> Boolean feature discovery in empirical learning. </title> <journal> Machine Learning, </journal> <volume> 5 </volume> <pages> 71-99, </pages> <year> 1990. </year>
Reference-contexts: A decision tree representation may be even larger than the corresponding decision list representation since it suffers from the so called "replication problem," which is due to the fact that the decision tree can only test a single attribute at any node <ref> [ Pagallo and Haussler, 1990 ] </ref> . As a result, even ID3 performs poorly as the depth of the determination tree is increased.
Reference: [ Pazzani and Kibler, 1992 ] <author> M. Pazzani and D. Kibler. </author> <title> The utility of knowledge in inductive learning. </title> <journal> Machine Learning, </journal> <volume> 9(1) </volume> <pages> 57-94, </pages> <year> 1992. </year>
Reference-contexts: Improving the complexities of these algorithms is essential to yield practical implementations. Such improved programs could be used in concert with ours to provide a more complete learning system. There has been considerable amount of research on using prior knowledge in learning. For example, FOCL <ref> [ Pazzani and Kibler, 1992 ] </ref> , and Grendel [ Cohen, 1992 ] learn general relational concepts and are capable of making use of background knowledge expressed as first-order Horn clauses. As suggested by Cohen, determinations can be expressed as overgeneral Horn clauses [ Cohen, 1991 ] .
Reference: [ Pearl, 1988 ] <author> Judea Pearl. </author> <title> Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1988. </year>
Reference-contexts: We can generalize this to stochastic domains by assuming that the values of the input features only determine the probability of the output feature. A stochastic determination graph can thus be interpreted as the graph structure of a Bayesian network <ref> [ Pearl, 1988 ] </ref> . Deterministic versions of Bayesian networks, called "symbolic causal networks" by Darwiche and Pearl [ 1994 ] , are similar to determination graphs except that they allow some "exogenous" propositions to introduce noise into the functional relationship defined by the determination.
Reference: [ Pillaipakkamnatt and Raghavan, 1995 ] <author> K. Pillaipakkamnatt and V. Raghavan. </author> <title> Read-twice DNF formulas are properly learnable. </title> <journal> Information and Computation, </journal> <volume> 122(2) </volume> <pages> 236-267, </pages> <year> 1995. </year>
Reference: [ Pitt and Warmuth, 1990 ] <author> L. Pitt and M.K. Warmuth. </author> <title> Prediction preserving reducibility. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 41(3) </volume> <pages> 430-467, </pages> <year> 1990. </year>
Reference: [ Quinlan, 1986 ] <author> R. Quinlan. </author> <title> Induction of decision trees. </title> <journal> Machine Learning, </journal> <volume> 1(1) </volume> <pages> 81-106, </pages> <year> 1986. </year>
Reference-contexts: We present empirical results that show that our algorithm leads to fast and reliable convergence when two different induction programs are used to learn the internal functions: Quinlan's ID3 <ref> [ Quinlan, 1986 ] </ref> , and a program called k-DL that learns k-decision lists introduced by Rivest [ 1987 ] . <p> It selects that clause, removes all covered examples from the set and iterates to select the next clause. k-DL can be shown to be a consistent learning algorithm for k-decision lists. * TSB-2 ID3 uses ID3 to learn the internal functions as decision trees <ref> [ Quinlan, 1986 ] </ref> . A decision tree is a rooted binary tree in which each internal node in the tree tests for the value of a single input attribute of the input example. <p> ID3 is a top-down algorithm that uses information gain as a heuristic evaluation function to decide which attribute to select at a given point to split the example set into two depending on its value <ref> [ Quinlan, 1986 ] </ref> . It then recursively calls itself on the two mutually disjoint sets of examples thus created and builds the left and right subtrees. <p> Our experiments compare TSB-2 with a knowledge-free induction program on the same set of examples. We used ID3 <ref> [ Quinlan, 1986 ] </ref> and k-DL [ Rivest, 1987 ] as our knowledge-free induction systems, because of their simplicity and availability.
Reference: [ Quinlan, 1990 ] <author> R. Quinlan. </author> <title> Learning logical definitions from relations. </title> <journal> Machine Learning, </journal> <volume> 5 </volume> <pages> 239-266, </pages> <year> 1990. </year>
Reference-contexts: They also worked better than any other system we tried on this domain including a more sophisticated version of ID3 called C4.5 and a propositional version of FOIL <ref> [ Quinlan, 1990 ] </ref> .
Reference: [ Rivest, 1987 ] <author> R. Rivest. </author> <title> Learning decision lists. </title> <journal> Machine Learning, </journal> <volume> 2(3) </volume> <pages> 229-246, </pages> <year> 1987. </year>
Reference-contexts: In the next section, we apply our program to Rivest's k-decision lists or k-DL, i.e., lists of k-length clauses, each of which is an IF-THEN statement with 0 or 1 outcome <ref> [ Rivest, 1987 ] </ref> . The class of k-decision lists is closed under variable negation, pac-learnable, and properly includes k-DNF and k-CNF [ Kohavi and Benson, 1993 ] . <p> Our experiments compare TSB-2 with a knowledge-free induction program on the same set of examples. We used ID3 [ Quinlan, 1986 ] and k-DL <ref> [ Rivest, 1987 ] </ref> as our knowledge-free induction systems, because of their simplicity and availability. They also worked better than any other system we tried on this domain including a more sophisticated version of ID3 called C4.5 and a propositional version of FOIL [ Quinlan, 1990 ] .
Reference: [ Russell and Grosof, 1987 ] <author> S.J. Russell and B. Grosof. </author> <title> A declarative approach to bias in concept learning. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pages 505-510, </pages> <address> Seattle, WA, 1987. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: The idea of declarative bias <ref> [ Russell and Grosof, 1987; Russell and Grosof, 1990 ] </ref> is to replace the exogenous bias, which is often only implicit, with background domain knowledge possessed by the learning system. <p> of declarative bias was based on the observation that the vocabulary bias for a propositional hypothesis space|that is, the set of features from which hypotheses are to be constructed|can be expressed concisely as a determination whose left-hand side contains the relevant features and whose right-hand side contains the target concept <ref> [ Russell and Grosof, 1987 ] </ref> . For example, we say that fA; B; Cg D, read the set fA; B; Cg determines D, if the values of A; B and C are sufficient to determine the value of D.
Reference: [ Russell and Grosof, 1990 ] <author> S.J. Russell and B. Grosof. </author> <title> Declarative bias: An overview. In D.P. </title> <editor> Benjamin, editor, </editor> <booktitle> Change of Representation and Inductive Bias, </booktitle> <pages> pages 267-308. </pages> <publisher> Kluwer, Norwell, </publisher> <address> MA, </address> <year> 1990. </year>
Reference-contexts: The idea of declarative bias <ref> [ Russell and Grosof, 1987; Russell and Grosof, 1990 ] </ref> is to replace the exogenous bias, which is often only implicit, with background domain knowledge possessed by the learning system.
Reference: [ Russell et al., 1995 ] <author> S.J. Russell, J. Binder, D. Koller, and K. </author> <title> Kanazawa. Local learning in probabilistic networks with hidden variables. </title> <booktitle> In Proceedings of the 14 th International Conference on Artificial Intelligence, </booktitle> <pages> pages 1146-1152, </pages> <address> Montreal, Canada, 1995. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Although there are a few results in learning Bayesian networks from data when all the variables are observable [ Cooper and Herskovits, 1992 ] , learning with hidden variables is much harder (see <ref> [ Russell et al., 1995 ] </ref> and [ Friedman, 1997 ] for recent algorithms). As yet, no work has been done on using membership queries in such algorithms, nor on ascertaining the computational complexity of the problem.
Reference: [ Russell, 1988 ] <author> S.J. Russell. </author> <title> Tree-structured bias. </title> <booktitle> In Proceedings of the Seventh National Conference on Artificial Intelligence, </booktitle> <pages> pages 641-645, </pages> <address> Saint Paul, MN, 1988. </address> <publisher> Morgan Kauf-mann. </publisher>
Reference-contexts: For example, if the learner knows (or can deduce) that the model, make, optional extras, and year of a car determine its list price, then it need not worry about the color of the car, the day of the week, or the name of the current Pope. In <ref> [ Russell, 1988 ] </ref> , it was shown that the knowledge used in the derivation of a suitable determination bias can impose additional constraints on the hypothesis space, beyond those implied by the determination itself. <p> We call this 3 tree structure along with a labeling of the leaves of the tree with distinct input attributes a determination tree (see Figure 1). It was shown in <ref> [ Russell, 1988 ] </ref> that the number of examples required to learn a function consistent with a given determination tree is linear in the number of leaves, provided the tree has bounded degree.
Reference: [ Russell, 1989 ] <author> S. J. Russell. </author> <title> The Use of Knowledge in Analogy and Induction. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1989. </year>
Reference-contexts: Since this restricted vocabulary may be much smaller than the total set of features available, the learning system may be able to learn from many fewer examples in much less time <ref> [ Russell, 1989; Mahadevan and Tadepalli, 1994 ] </ref> . <p> See <ref> [ Russell, 1989 ] </ref> and [ Getoor, 1989 ] for more examples.) By construction, the attributes at internal nodes of the derivation tree will be unobservable. <p> The task is to predict the value of the output attribute A 0 for x. Out of the many types of determinations Russell defined, in this paper, we are concerned with what may be called a "functional" determination <ref> [ Russell, 1989 ] </ref> . This is defined as follows. <p> The fan-in of the tree is the maximum fan-in over all nodes. The fan-out of the tree is the maximum fan-out over all nodes, which is 1. To nontrivially constrain the set of allowed functions, the fan-in of the tree was originally restricted to a constant k <ref> [ Russell, 1989; Bshouty et al., 1992; Tadepalli, 1993 ] </ref> | the k-TSB bias. In this paper, we consider a generalized tree-structured bias in which the nodes have arbitrarily large fan-ins. <p> TSB-2 is a successor of TSB-1, which was restricted to constant fan-in determination trees [ Tadepalli, 1993 ] . Other than TSB-1, there were two previous implementations of tree-structured bias [ Getoor, 1989 ] (see also <ref> [ Russell, 1989 ] </ref> ). However, both of them have only had limited success. One of them assumes that the Boolean functions at each node are monotone, yielding a very simple polytime algorithm with membership queries.
Reference: [ Schapire, 1990 ] <author> R. E. Schapire. </author> <title> The strength of weak learnability. </title> <journal> Machine Learning, </journal> <volume> 5(2) </volume> <pages> 197-227, </pages> <year> 1990. </year>
Reference: [ Schlimmer, 1993 ] <author> J. Schlimmer. </author> <title> Efficiently inducing determinations: A complete and systematic search algorithm that uses optimal pruning. </title> <booktitle> In Proceedings of the Tenth International Conference on Machine Learning, </booktitle> <pages> pages 284-290, </pages> <address> Amherst, MA, 1993. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: On the other hand, this problem should not arise with TSB-2 because of its ability to learn each of the internal functions locally. Schlimmer [ 1993 ] describes a program that learns determinations from data using a semi-exhaustive search <ref> [ Schlimmer, 1993 ] </ref> . The algorithms of [ Bshouty et al., 1995a ] for learning the skeletons of the read-once formulas have worst case complexities of the order of O (n k+1 ) for k-TSB and O (n 6 ) for TSB with symmetric basis functions.
Reference: [ Shavlik and Towell, 1989 ] <author> J.W. Shavlik and G.G. Towell. </author> <title> An approach to combining explanation-based and neural learning algorithms. </title> <journal> Connection Science, </journal> <volume> 3(1) </volume> <pages> 231-53, </pages> <year> 1989. </year> <month> 62 </month>
Reference-contexts: In this way, the system need never consider hypotheses that are not consistent with the background knowledge. Implemented systems of this type include Odysseus [ Wilkins et al., 1987 ] , KBANN <ref> [ Shavlik and Towell, 1989 ] </ref> , and Grendel [ Cohen, 1992 ] , as well as the work of Getoor [ 1989 ] which we discuss below.
Reference: [ Tadepalli, 1993 ] <author> P. Tadepalli. </author> <title> Learning from queries and examples with tree-structured bias. </title> <booktitle> In Proceedings of the Tenth International Conference on Machine Learning, </booktitle> <pages> pages 322-329, </pages> <address> Amherst, MA, 1993. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: The fan-in of the tree is the maximum fan-in over all nodes. The fan-out of the tree is the maximum fan-out over all nodes, which is 1. To nontrivially constrain the set of allowed functions, the fan-in of the tree was originally restricted to a constant k <ref> [ Russell, 1989; Bshouty et al., 1992; Tadepalli, 1993 ] </ref> | the k-TSB bias. In this paper, we consider a generalized tree-structured bias in which the nodes have arbitrarily large fan-ins. <p> TSB-2 is a successor of TSB-1, which was restricted to constant fan-in determination trees <ref> [ Tadepalli, 1993 ] </ref> . Other than TSB-1, there were two previous implementations of tree-structured bias [ Getoor, 1989 ] (see also [ Russell, 1989 ] ). However, both of them have only had limited success.
Reference: [ Valiant, 1984 ] <author> L.G. Valiant. </author> <title> A theory of the learnable. </title> <journal> Communications of the ACM, </journal> <volume> 27(11) </volume> <pages> 1134-1142, </pages> <month> August </month> <year> 1984. </year>
Reference-contexts: The environment provides random examples, and answers the membership queries, i.e., gives the output for any input queried by the learner. Using the Probably Approximately Correct (PAC) learning framework <ref> [ Valiant, 1984 ] </ref> , extended with membership queries [ An 1 This assumption is fairly natural. <p> hand, it appears that it is necessary for the derivation to be tree-structured in that even mild deviations from the tree-structure could make the learning problem computationally intractable. 3 Learning from Examples and Membership Queries In this paper, we will be using a version of Probably Approximately Correct (PAC) learning <ref> [ Valiant, 1984 ] </ref> , extended to include membership queries [ Angluin, 1988 ] . We restrict ourselves here to learning Boolean functions. <p> minimal function space F fl which includes F and is closed under complement (variable negation or projection). 12 Consider the space of k-DNF functions, which is known to be learnable. k-DNF is the space of Boolean functions that can be expressed as disjunctions of conjunctions of at most k literals <ref> [ Valiant, 1984 ] </ref> . For example, AB + BC + DE is a 2-DNF formula. It is easy to see that k-DNF is closed under projection.
Reference: [ Wegener, 1987 ] <author> I. Wegener. </author> <title> The Complexity of Boolean Functions. </title> <publisher> John Wiley & Sons, </publisher> <address> New York, NY, </address> <year> 1987. </year>
Reference: [ Wilkins et al., 1987 ] <author> D.C. Wilkins, W.J. Clancey, and B.G. Buchanan. </author> <title> Knowledge base refinement by monitoring abstract control knowledge. </title> <journal> International Journal of Man-Machine Studies, </journal> <volume> 27(3) </volume> <pages> 281-293, </pages> <year> 1987. </year>
Reference-contexts: In this way, the system need never consider hypotheses that are not consistent with the background knowledge. Implemented systems of this type include Odysseus <ref> [ Wilkins et al., 1987 ] </ref> , KBANN [ Shavlik and Towell, 1989 ] , and Grendel [ Cohen, 1992 ] , as well as the work of Getoor [ 1989 ] which we discuss below.
References-found: 47

