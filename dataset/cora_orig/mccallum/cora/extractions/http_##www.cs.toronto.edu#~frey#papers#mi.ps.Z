URL: http://www.cs.toronto.edu/~frey/papers/mi.ps.Z
Refering-URL: http://www.cs.toronto.edu/~frey/papers/mi.abs.html
Root-URL: http://www.cs.toronto.edu
Email: bfrey@uiuc.edu  Neil.Lawrence@cl.cam.ac.uk  cmbishop@microsoft.com  
Title: Markovian Inference in Belief Networks  
Author: Brendan J. Frey Neil Lawrence Christopher M. Bishop 
Address: 405 N. Mathews Ave., Urbana, Illinois 61801  New Museums Site, Pembroke Street Cambridge UK CB2 3QG  St. George House, 1 Guildhall St. Cambridge, UK CB2 3NH  
Affiliation: Beckman Institute for Advanced Science and Technology University of Illinois at Urbana-Champaign  Computer Laboratory University of Cambridge  Microsoft Research Cambridge  
Abstract: Bayesian belief networks can represent the complicated probabilistic processes that form natural sensory inputs. Once the parameters of the network have been learned, nonlinear inferences about the input can be made by computing the posterior distribution over the hidden units (e.g., depth in stereo vision) given the input. Computing the posterior distribution exactly is not practical in richly-connected networks, but it turns out that by using a variational (a.k.a., mean field) method, it is easy to find a product-form distribution that approximates the true posterior distribution. This approximation assumes that the hidden variables are independent given the current input. In this paper, we explore a more powerful variational technique that models the posterior distribution using a Markov chain. We compare this method with inference using mean fields and mixtures of mean fields in randomly generated networks. Submitted to NIP98, Algorithms and Architectures, oral presentation. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Bishop, C. M., T. Jaakkola, M. I. Jordan, and N. </author> <title> Lawrence (1997). Approximating posterior distributions in belief networks using mixtures. </title> <type> Technical report, </type> <institution> Neural Computing Research Group, Aston University, Birmingham, UK. </institution> <note> To appear in Proceedings NIPS'97. </note>
Reference: <author> Frey, B. J. </author> <year> (1998). </year> <title> Graphical Models for Machine Learning and Digital Communication. </title> <address> Cambridge MA.: </address> <publisher> MIT Press. </publisher> <address> See http://www.cs.utoronto.ca/frey. </address>
Reference-contexts: In richly-connected networks such as layered networks, the time needed to compute the posterior distribution exactly grows exponen tially with the number of hidden units. So, we usually approximate inference using Markov chain Monte Carlo methods (Neal, 1992), recognition networks (Hinton et al., 1995), loopy probability propagation <ref> (Frey, 1998) </ref>, or variational techniques (Jordan et al., 1998). In a variational approximation we try to fit a parameterized distribution to the hidden units for the current input pattern.
Reference: <author> Hinton, G. E., P. Dayan, B. J. Frey, and R. M. </author> <title> Neal (1995). The wake-sleep algorithm for unsupervised neural networks. </title> <booktitle> Science 268, </booktitle> <pages> 11581161. </pages>
Reference-contexts: In richly-connected networks such as layered networks, the time needed to compute the posterior distribution exactly grows exponen tially with the number of hidden units. So, we usually approximate inference using Markov chain Monte Carlo methods (Neal, 1992), recognition networks <ref> (Hinton et al., 1995) </ref>, loopy probability propagation (Frey, 1998), or variational techniques (Jordan et al., 1998). In a variational approximation we try to fit a parameterized distribution to the hidden units for the current input pattern.
Reference: <author> Jaakkola, T. S. and M. I. </author> <title> Jordan (1998). Approximating posteriors via mixture models. </title>
Reference: <editor> In M. I. Jordan (Ed.), </editor> <title> Learning and Inference in Graphical Models. </title> <publisher> Norwell MA.: Kluwer Academic Publishers. </publisher>
Reference: <author> Jordan, M. I., Z. Ghahramani, T. S. Jaakkola, and L. K. </author> <title> Saul (1998). An introduction to variational methods for graphical models. </title> <editor> In M. I. Jordan (Ed.), </editor> <title> Learning and Inference in Graphical Models. </title> <publisher> Norwell MA.: Kluwer Academic Publishers. </publisher>
Reference-contexts: So, we usually approximate inference using Markov chain Monte Carlo methods (Neal, 1992), recognition networks (Hinton et al., 1995), loopy probability propagation (Frey, 1998), or variational techniques <ref> (Jordan et al., 1998) </ref>. In a variational approximation we try to fit a parameterized distribution to the hidden units for the current input pattern.
Reference: <author> Neal, R. M. </author> <year> (1992). </year> <title> Connectionist learning of belief networks. </title> <journal> Artificial Intelligence 56, </journal> <volume> 71113. </volume>
Reference-contexts: Taking A i as the set of indices for the parents of s i (those variables having edges directed to s i ), the joint distribution can be written P (s) j i=1 P (s i jfs j g j2A i ): (1) In the case of sigmoid belief networks <ref> (Neal, 1992) </ref>, the variables are binary and the param-eterized conditional probability that unit s i has the value 1 is given by the logistic sigmoid function of the net input: P (s i = 1jfs j g j2A i ; ) j 1=(1 + e n i ); n i j <p> In richly-connected networks such as layered networks, the time needed to compute the posterior distribution exactly grows exponen tially with the number of hidden units. So, we usually approximate inference using Markov chain Monte Carlo methods <ref> (Neal, 1992) </ref>, recognition networks (Hinton et al., 1995), loopy probability propagation (Frey, 1998), or variational techniques (Jordan et al., 1998). In a variational approximation we try to fit a parameterized distribution to the hidden units for the current input pattern.
Reference: <author> Neal, R. M. and G. E. </author> <title> Hinton (1993). A new view of the EM algorithm that justifies incremental and other variants. </title> <note> Unpublished manuscript available over the internet by ftp at ftp://ftp.cs.utoronto.ca/pub/radford/em.ps.Z. </note>
Reference-contexts: is always positive: L (; OE; ) F (OE; ) ln P (dj): (10) By setting some of the parameters in OE to account for the visible units d and then min imizing L (; OE; ) with respect to , OE and , we can perform generalized expectation maximization <ref> (Neal and Hinton, 1993) </ref>. 2 Markovian inference The mean field theory for sigmoid belief networks (Saul et al., 1996) uses a product-form variational distribution over the hidden units.
Reference: <author> Saul, L. K., T. Jaakkola, and M. I. </author> <title> Jordan (1996). Mean field theory for sigmoid belief networks. </title> <journal> Journal of Artificial Intelligence Research 4, </journal> <volume> 6176. </volume>
Reference-contexts: setting some of the parameters in OE to account for the visible units d and then min imizing L (; OE; ) with respect to , OE and , we can perform generalized expectation maximization (Neal and Hinton, 1993). 2 Markovian inference The mean field theory for sigmoid belief networks <ref> (Saul et al., 1996) </ref> uses a product-form variational distribution over the hidden units. <p> In this case the fan-out of the hidden units is n = 2. In this section, we summarize the performance of Markovian inference in randomly drawn networks and compare it with mean field theory <ref> (Saul et al., 1996) </ref> and mixtures of mean fields (Jaakkola and Jordan, 1998; Bishop et al., 1997). Figure 2 shows the connectivity of the networks we used for testing inference.
References-found: 9

