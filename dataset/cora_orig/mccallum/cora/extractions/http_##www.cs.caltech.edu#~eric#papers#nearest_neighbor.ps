URL: http://www.cs.caltech.edu/~eric/papers/nearest_neighbor.ps
Refering-URL: http://www.cs.caltech.edu/~eric/papers/papers.html
Root-URL: http://www.cs.caltech.edu
Email: eric@cs.caltech.edu  
Title: Validation of Nearest Neighbor Classifiers  
Author: Eric Bax 
Date: June 2, 1998  
Address: Pasadena, CA 91125  
Affiliation: Computer Science Dept. California Institute of Technology 256-80  
Abstract: We develop a probabilistic bound on the error rate of the nearest neighbor classifier formed from a set of labelled examples. The bound is computed using only the examples in the set. A subset of the examples is used as a validation set to bound the error rate of the classifier formed from the remaining examples. Then a bound is computed for the difference in error rates between the original classifier and the reduced classifier. This bound is computed by partitioning the validation set and using each subset to compute bounds for the error rate difference due to the other subsets. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Y. Abu-Mostafa, </author> <title> What you need to know about the VC inequality, Class notes from CS156, </title> <institution> California Institute of Technology, </institution> <year> 1996. </year>
Reference-contexts: By Hoeffd-ing's inequality [9], P rfL n k + *g e 2k* 2 2 This is a probabilistic upper bound on the underlying error rate. For more information on this approach to validation, refer to work by Vapnik and Chervonenkis [14], Vapnik [13], Abu-Mostafa <ref> [1] </ref>, and Bax [2]. 4 Reduced Classifier Now return to the basic framework, in which we have only the labelled in-sample examples. To employ Hoeffding's inequality, remove the last k examples from the in-sample set to form a validation set. <p> A challenge for the future is to extend the bounds for single classifiers to uniform bounds over multiple classifiers. For finite sets of classifiers, uniform bounds may be developed by summing the probabilities of bound failures for single classifiers to bound the probability of failure in the uniform bound <ref> [1] </ref>. For example, these bounds apply to sets of classifiers formed by eliminating different subsets of examples from the in-sample set. It may be possible to improve these bounds using methods of validation by inference based on rates of agreement among classifiers, as in [2].
Reference: [2] <author> E. Bax, </author> <title> Validation of voting committees, </title> <note> Neural Computation 10 (4) (1998) 975-986. </note>
Reference-contexts: By Hoeffd-ing's inequality [9], P rfL n k + *g e 2k* 2 2 This is a probabilistic upper bound on the underlying error rate. For more information on this approach to validation, refer to work by Vapnik and Chervonenkis [14], Vapnik [13], Abu-Mostafa [1], and Bax <ref> [2] </ref>. 4 Reduced Classifier Now return to the basic framework, in which we have only the labelled in-sample examples. To employ Hoeffding's inequality, remove the last k examples from the in-sample set to form a validation set. Let C nk be the classifier formed from the remaining examples. <p> For example, these bounds apply to sets of classifiers formed by eliminating different subsets of examples from the in-sample set. It may be possible to improve these bounds using methods of validation by inference based on rates of agreement among classifiers, as in <ref> [2] </ref>. For infinite classes of classifiers, it may be possible to develop bounds using the concept of VC dimension [14]. For example, these bounds would apply to all classifiers with a particular set of examples and a metric from some class of metrics.
Reference: [3] <author> T. M. </author> <title> Cover, Learning in pattern recognition, in Methodologies of Pattern Recognition, </title> <editor> S. Watanabe, Ed., </editor> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1969, </year> <pages> 111-132. </pages>
Reference-contexts: Cover and Hart [5] proved that under mild continuity assumptions R 1 is no more than twice the Bayes (optimal) error rate. Cover <ref> [3] </ref> showed that the average error rate of using the remaining examples to classify each example in the in-sample set is an unbiased estimate of R n1 . Cover [4] and Psaltis, Snapp, and Venkatesh [12] have investigated the convergence of R n to R 1 .
Reference: [4] <author> T. M. </author> <title> Cover, Rates of convergence of nearest neighbor decision procedures, </title> <booktitle> Proc. First Annual Hawaii Conf. on Systems Theory, </booktitle> <year> 1968, </year> <pages> 413-415. </pages>
Reference-contexts: Cover [3] showed that the average error rate of using the remaining examples to classify each example in the in-sample set is an unbiased estimate of R n1 . Cover <ref> [4] </ref> and Psaltis, Snapp, and Venkatesh [12] have investigated the convergence of R n to R 1 . Cover [4] worked with the case of a one-dimensional input space, and Psaltis, et. al., [12] extended the work, showing that dimensionality can have a strong effect on convergence. <p> Cover [3] showed that the average error rate of using the remaining examples to classify each example in the in-sample set is an unbiased estimate of R n1 . Cover <ref> [4] </ref> and Psaltis, Snapp, and Venkatesh [12] have investigated the convergence of R n to R 1 . Cover [4] worked with the case of a one-dimensional input space, and Psaltis, et. al., [12] extended the work, showing that dimensionality can have a strong effect on convergence. Wagner [15], Fritz [7], and Gyorfi [8] have studied the convergence of L n to R 1 .
Reference: [5] <author> T. M. Cover and P. E. Hart, </author> <title> Nearest neighbor pattern classification, </title> <journal> IEEE Trans. Inform. Theory, </journal> <note> IT-13 (1967) 21-27. 7 </note>
Reference-contexts: While this paper focuses on L n , the error rate of the classifier at hand, much work in the past has focused on R n , the average error rate over classifiers formed from randomly drawn examples. Cover and Hart <ref> [5] </ref> proved that under mild continuity assumptions R 1 is no more than twice the Bayes (optimal) error rate. Cover [3] showed that the average error rate of using the remaining examples to classify each example in the in-sample set is an unbiased estimate of R n1 .
Reference: [6] <author> J. Franklin, </author> <title> Methods of Mathematical Economics, </title> <publisher> Springer-Verlag New York, Inc., </publisher> <year> 1979, </year> <pages> 190-203. </pages>
Reference-contexts: This value can be found by gradient descent within the region indicated by the constraints. For the theory that motivates this method, consult Kuhn and Tucker [10] or Franklin <ref> [6] </ref>. (All feasible solutions are valid bounds.) In the bound 9, an implicit lower bound of zero is used for q. This need not be the case. Let q A be the probability that C A is correct and C nk is incorrect.
Reference: [7] <author> J. Fritz, </author> <title> Distribution-free exponential error bound for nearest neighbor classification, </title> <journal> IEEE Trans. Inform. Theory, </journal> <month> IT-21 </month> <year> (1975) </year> <month> 552-557. </month>
Reference-contexts: Cover [4] worked with the case of a one-dimensional input space, and Psaltis, et. al., [12] extended the work, showing that dimensionality can have a strong effect on convergence. Wagner [15], Fritz <ref> [7] </ref>, and Gyorfi [8] have studied the convergence of L n to R 1 . This paper develops the following method to bound L n . Some in-sample examples are removed from the in-sample set to form a validation set. The remaining in-sample examples form a reduced classifier.
Reference: [8] <author> L. Gyorfi, </author> <title> On the rate of convergence of nearest neighbor rules, </title> <journal> IEEE Trans. Inform. Theory, </journal> <note> IT-24 (1978) 509-512. </note>
Reference-contexts: Cover [4] worked with the case of a one-dimensional input space, and Psaltis, et. al., [12] extended the work, showing that dimensionality can have a strong effect on convergence. Wagner [15], Fritz [7], and Gyorfi <ref> [8] </ref> have studied the convergence of L n to R 1 . This paper develops the following method to bound L n . Some in-sample examples are removed from the in-sample set to form a validation set. The remaining in-sample examples form a reduced classifier.
Reference: [9] <author> W. Hoeffding, </author> <title> Probability inequalities for sums of bounded random variables, </title> <journal> Am. Stat. Assoc. J., </journal> <month> 58 </month> <year> (1963) </year> <month> 13-30. </month>
Reference-contexts: Let C n be the classifier formed from the in-sample examples. Let k be the error rate of C n over the validation examples. By Hoeffd-ing's inequality <ref> [9] </ref>, P rfL n k + *g e 2k* 2 2 This is a probabilistic upper bound on the underlying error rate.
Reference: [10] <author> H. W. Kuhn and J. W. Tucker, </author> <title> Nonlinear programming, </title> <booktitle> in Proceedings of the Second Berkeley Symposium on Mathematical Statistics and Probability Berkeley, </booktitle> <publisher> Univ. of California Press, </publisher> <year> 1950, </year> <pages> 481-492. </pages>
Reference-contexts: This value can be found by gradient descent within the region indicated by the constraints. For the theory that motivates this method, consult Kuhn and Tucker <ref> [10] </ref> or Franklin [6]. (All feasible solutions are valid bounds.) In the bound 9, an implicit lower bound of zero is used for q. This need not be the case. Let q A be the probability that C A is correct and C nk is incorrect.
Reference: [11] <author> N. Linial and N. Nisan, </author> <title> Approximate inclusion-exclusion, </title> <note> Combina-torica 10 (4) (1990) 349-365. </note>
Reference-contexts: The expected bias due to truncating the inclusion and exclusion formula decreases more slowly. For some ideas about how to estimate the inclusion and exclusion formula using fewer terms, refer to work by Linial and Nisan <ref> [11] </ref>. 7 Validation Set Size The choice of validation set size k mediates a tradeoff between confidence and robustness. Observe from the RHS of bound 9 that as k increases, the probability of bound failure decreases exponentially.
Reference: [12] <author> D. Psaltis, R. Snapp, and S. Venkatesh, </author> <title> On the finite sample performance of the nearest neighbor classifier, </title> <journal> IEEE Trans. Inform. Theory, </journal> <note> 40 (3) (1994) 820-837. </note>
Reference-contexts: Cover [3] showed that the average error rate of using the remaining examples to classify each example in the in-sample set is an unbiased estimate of R n1 . Cover [4] and Psaltis, Snapp, and Venkatesh <ref> [12] </ref> have investigated the convergence of R n to R 1 . Cover [4] worked with the case of a one-dimensional input space, and Psaltis, et. al., [12] extended the work, showing that dimensionality can have a strong effect on convergence. <p> Cover [4] and Psaltis, Snapp, and Venkatesh <ref> [12] </ref> have investigated the convergence of R n to R 1 . Cover [4] worked with the case of a one-dimensional input space, and Psaltis, et. al., [12] extended the work, showing that dimensionality can have a strong effect on convergence. Wagner [15], Fritz [7], and Gyorfi [8] have studied the convergence of L n to R 1 . This paper develops the following method to bound L n .
Reference: [13] <author> V. N. Vapnik, </author> <title> Estimation of Dependences Based on Empirical Data p.31, </title> <publisher> Springer-Verlag New York, Inc. </publisher> <year> 1982. </year>
Reference-contexts: By Hoeffd-ing's inequality [9], P rfL n k + *g e 2k* 2 2 This is a probabilistic upper bound on the underlying error rate. For more information on this approach to validation, refer to work by Vapnik and Chervonenkis [14], Vapnik <ref> [13] </ref>, Abu-Mostafa [1], and Bax [2]. 4 Reduced Classifier Now return to the basic framework, in which we have only the labelled in-sample examples. To employ Hoeffding's inequality, remove the last k examples from the in-sample set to form a validation set.
Reference: [14] <author> V. N. Vapnik and A. Chervonenkis, </author> <title> On the uniform convergence of relative frequencies of events to their probabilities, </title> <journal> Theory Prob. Appl., </journal> <volume> 16(1971) </volume> <pages> 264-280. </pages>
Reference-contexts: By Hoeffd-ing's inequality [9], P rfL n k + *g e 2k* 2 2 This is a probabilistic upper bound on the underlying error rate. For more information on this approach to validation, refer to work by Vapnik and Chervonenkis <ref> [14] </ref>, Vapnik [13], Abu-Mostafa [1], and Bax [2]. 4 Reduced Classifier Now return to the basic framework, in which we have only the labelled in-sample examples. To employ Hoeffding's inequality, remove the last k examples from the in-sample set to form a validation set. <p> It may be possible to improve these bounds using methods of validation by inference based on rates of agreement among classifiers, as in [2]. For infinite classes of classifiers, it may be possible to develop bounds using the concept of VC dimension <ref> [14] </ref>. For example, these bounds would apply to all classifiers with a particular set of examples and a metric from some class of metrics.
Reference: [15] <author> T. J. Wagner, </author> <title> Convergence of the nearest neighbor rule, </title> <journal> IEEE Trans. Inform. Theory, </journal> <note> IT-17 (1971) 566-571. 8 </note>
Reference-contexts: Cover [4] and Psaltis, Snapp, and Venkatesh [12] have investigated the convergence of R n to R 1 . Cover [4] worked with the case of a one-dimensional input space, and Psaltis, et. al., [12] extended the work, showing that dimensionality can have a strong effect on convergence. Wagner <ref> [15] </ref>, Fritz [7], and Gyorfi [8] have studied the convergence of L n to R 1 . This paper develops the following method to bound L n . Some in-sample examples are removed from the in-sample set to form a validation set. The remaining in-sample examples form a reduced classifier.
References-found: 15

