URL: http://www.cs.concordia.ca/~faculty/lata/PS/anne.ps.gz
Refering-URL: http://www.cs.concordia.ca/~faculty/lata/papers.html
Root-URL: http://www.cs.concordia.ca
Email: condon@cs.wisc.edu  lata@cs.concordia.ca  
Title: Upper and Lower Bounds for Selection on the Mesh  
Author: Anne Condon Ph: -- Lata Narayanan Ph: -- 
Keyword: Lower bound, selection, mesh, randomized algorithm, adaptiveness.  
Note: Condon's research supported by NSF grant numbers CCR-9100886 and CCR-9257241 and by awards from Digital Equipment Corporation and the AT&T Foundation. Narayanan's research supported in part by NSERC grant number OGP0155204.  
Date: May 31, 1996  
Address: Madison, WI 53706  Montreal, Canada H3G 1M8  
Affiliation: Department of Computer Science University of Wisconsin  Department of Computer Science Concordia University  
Abstract: A distance-optimal algorithm for selection on the mesh has proved to be elusive, although distance-optimal algorithms for the related problems of routing and sorting have recently been discovered. In this paper, we explain, using the notion of adaptiveness, why techniques used in the currently best selection algorithms cannot lead to a distance-optimal algorithm. For worst-case inputs, we apply new techniques to improve the previous best upper bound of 1:22n of Kaklamanis et al. [7] to 1:15n. This improvement is obtained in part by increasing the adaptiveness of previous algorithms. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Agarwal, B. Lim, D. Kranz, and J. Kubiatowicz. </author> <month> APRIL: </month> <title> A processor architecture for 20 multiprocessing. </title> <booktitle> In Proceedings of the 17th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 104-114, </pages> <year> 1990. </year>
Reference-contexts: At the end of the algorithm the selected element must be at the center processor of the mesh. Because of the simplicity of its architecture, the mesh model is a well-studied and popular model of parallel computation [12] and is the basis for several parallel machines <ref> [1, 14] </ref>. We consider a standard model [6, 7, 12, 13, 16] in which a processor is allowed to communicate one packet of information to each of its neighbors during a single time step and to queue a constant number of packets between time steps.
Reference: [2] <author> D. Angluin and L. Valiant. </author> <title> Fast probabilistic algorithms for hamiltonian circuits and matchings. </title> <journal> Journal of Computer and System Science, </journal> <volume> 18 </volume> <pages> 155-193, </pages> <year> 1979. </year>
Reference: [3] <author> H. Chernoff. </author> <title> A measure of asymptotic efficiency for tests of a hypothesis based on the sum of observations. </title> <journal> Annals of Mathematics and Statistics, </journal> <volume> 23 </volume> <pages> 493-507, </pages> <year> 1952. </year>
Reference: [4] <author> A. Condon and L. Narayanan. </author> <title> Upper Bounds for Sorting and Selection on Meshes. </title> <type> DI-MACS Technical Report Number 94-34, </type> <year> 1994. </year>
Reference: [5] <author> Y. Han, Y. Igarashi, and M. Truszczynski. </author> <title> Indexing schemes and lower bounds for sorting on a mesh-connected computer. </title> <type> Technical Report Number 114-88, </type> <institution> University of Kentucky, Lexington, </institution> <year> 1988. </year>
Reference-contexts: An algorithm is maximally adaptive if every step of the algorithm is a knowledge step. The maximally-adaptive model is similar to the lower bound model of Schnorr and Shamir [18], Kunde [10] and Han et al. <ref> [5] </ref>. However, our model allows replication of packets, which is not allowed in their model. On the other hand, their model is more general than our maximally adaptive model in that an algorithm may depend on the values of accessible packets, and not just on the outcomes of comparisons.
Reference: [6] <author> C. Kaklamanis and D. Krizanc. </author> <title> Optimal sorting on mesh-connected processor arrays. </title> <booktitle> In Proceedings of the 4th Annual ACM Symposium on Parallel Algorithms and Architecture, </booktitle> <pages> pages 50-59, </pages> <year> 1992. </year>
Reference-contexts: Because of the simplicity of its architecture, the mesh model is a well-studied and popular model of parallel computation [12] and is the basis for several parallel machines [1, 14]. We consider a standard model <ref> [6, 7, 12, 13, 16] </ref> in which a processor is allowed to communicate one packet of information to each of its neighbors during a single time step and to queue a constant number of packets between time steps. <p> This question is especially interesting in light of the fact that distance-optimal algorithms for the related problems of sorting and routing have recently been discovered <ref> [6, 8, 13] </ref>. We provide a partial answer for this question in this paper. Our main lower bound shows that the techniques used in the best previous selection algorithms cannot yield a distance-optimal algorithm. <p> Conclusions are presented in Section 5. 2 Upper and Lower Bound Models 2.1 Upper Bound Model Our upper bound model is a standard one for describing routing algorithms on the mesh <ref> [6, 7, 13, 16] </ref>. The n fi n mesh-connected array of processors (or two-dimensional mesh) contains N = n 2 processors arranged in a two-dimensional grid.
Reference: [7] <author> C. Kaklamanis, D. Krizanc, L. Narayanan, and A. Tsantilas. </author> <title> Randomized sorting and selection on mesh-connected processor arrays. </title> <booktitle> In Proceedings of the 3rd Annual ACM Symposium on Parallel Algorithms and Architecture, </booktitle> <pages> pages 17-28, </pages> <year> 1991. </year>
Reference-contexts: Because of the simplicity of its architecture, the mesh model is a well-studied and popular model of parallel computation [12] and is the basis for several parallel machines [1, 14]. We consider a standard model <ref> [6, 7, 12, 13, 16] </ref> in which a processor is allowed to communicate one packet of information to each of its neighbors during a single time step and to queue a constant number of packets between time steps. <p> This is the only known lower bound for selection on the standard model of the mesh (Kunde's lower bound of 2n o (n) steps [10] applies only to a very restricted model of the mesh). The previously best algorithm for this problem runs in 1:22n steps <ref> [7, 8, 15] </ref>. Thus, the complexity of selection on the mesh is well-known to be fi (n); the main open question is whether there exists a distance-optimal, or n + o (n)-time, algorithm for selection on the mesh. <p> Thus, the routes of packets are adapted at the filtering steps. The success of the filtering method depends on the routing scheme, the locations of the filters and the times that filtering is done. The previous best algorithm of Kaklamanis et al. <ref> [7] </ref> can also be viewed as a filtering algorithm, but filtering is only done once, based on a single sample which is collected at the center. Our scheme uses three filters, and uses a new distributed sampling method to enable the filtering processors to filter elements earlier in the algorithm. <p> Conclusions are presented in Section 5. 2 Upper and Lower Bound Models 2.1 Upper Bound Model Our upper bound model is a standard one for describing routing algorithms on the mesh <ref> [6, 7, 13, 16] </ref>. The n fi n mesh-connected array of processors (or two-dimensional mesh) contains N = n 2 processors arranged in a two-dimensional grid. <p> Thus, our lower bounds for maximally-adaptive algorithms are more general than previous results for such algorithms. The previous best algorithm for selection of Kaklamanis et al. <ref> [7] </ref> is a weakly adaptive algorithm. Roughly, a small sample of elements is routed close to the center of the mesh and sorted. From this sample, splitters are computed which are broadcast to all processors within a certain range of the center. <p> The proof of Theorem 3.3 can be found in Section A.4. 4 A Randomized Algorithm for Selection The high-level description of our algorithm is similar to previous algorithms of <ref> [7, 9] </ref>. However, we use several new techniques, including greater adaptiveness, in order to obtain gains in the running time. We start this section with an outline of the general scheme used in previous algorithms, and then describe our new techniques in detail. <p> It is now possible to give an overview of the running time of the algorithm. First, consider Step 2. The bracketing elements are selected by the center processor using sampling techniques (see <ref> [17, 7] </ref>); to get a sample of the entire input to the center requires n steps since this is the maximum distance of an element to the center. <p> Thus, the total time of Steps 2 through 5 must be at least n + 2g. In fact, they can be completed in time n + 2g + o (n) as shown in <ref> [7] </ref>. It remains to consider Step 1; we summarize the analysis here. <p> In the following sections, we describe Steps 1 and 4 of our algorithm in detail. We omit discussion of the remaining steps, since these are almost identical to previous work <ref> [7] </ref> and a complete description can be found there. <p> The proof of the running time is technically complicated and can be found in Section A.1. 2 13 4.2 Steps 1b and 1d: Selecting the Splitters Selection of the splitter elements is done using the following set sampling method of [17], which was also used in <ref> [7] </ref>. Each element in the set tosses a coin, which is heads with probability ffN 5ffi1 ln N , for some constants ff and ffi (ff = 18 and ffi = 1=6 is sufficient). The set of elements which toss heads is the sample. <p> Let rank (E) for any input element E be the rank of E in the entire input set I. Then it is easy to see that with high probability, rank (b 0 ) bN=2c + 3N 1ffi (for details see <ref> [7] </ref>). We claim that bN=2c rank (M )+da 2 1 =2e. To see this, note that the rank (M ) is minimized if all elements not in A (P ) are greater than all the elements in A (P ). In this case, rank (M ) = bjA (P )j=2c. <p> Step 1e requires an additional (n=48 + 1=8)n g + o (n) steps (Lemma 4.6). Steps 1 and 2 can be done simultaneously by giving priority to packets performing Step 2; this causes an additional delay of at most o (n) steps with high probability as in <ref> [7] </ref>. Step 2 can be done in n + g + o (n) steps, and Step 1 can be done in n (1 + 1=8 + n=48) g + o (n) steps. To minimize the running time, we equate the two to get g ' 0:07n steps. <p> Since there are at most o (n) such packets, they do not cause a delay of more than o (n) steps (Lemma 4.7). Therefore the entire algorithm can be finished in n + 2g + o (n) = 1:15n (see <ref> [7] </ref> for the analysis of Steps 3 and 4). 18 In the description above, the only steps that require non-constant size queues are Steps 1a, 1c, and 1e. To achieve constant size queues here, we use a redistribution technique described in [9].
Reference: [8] <author> M. Kaufmann and J. Sibeyn and T. Suel. </author> <title> Derandomizing algorithms for routing and sorting on meshes. processors. </title> <booktitle> In Proceedings of the Fifth Annual ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <pages> pages 669-679, </pages> <year> 1994. </year>
Reference-contexts: This is the only known lower bound for selection on the standard model of the mesh (Kunde's lower bound of 2n o (n) steps [10] applies only to a very restricted model of the mesh). The previously best algorithm for this problem runs in 1:22n steps <ref> [7, 8, 15] </ref>. Thus, the complexity of selection on the mesh is well-known to be fi (n); the main open question is whether there exists a distance-optimal, or n + o (n)-time, algorithm for selection on the mesh. <p> This question is especially interesting in light of the fact that distance-optimal algorithms for the related problems of sorting and routing have recently been discovered <ref> [6, 8, 13] </ref>. We provide a partial answer for this question in this paper. Our main lower bound shows that the techniques used in the best previous selection algorithms cannot yield a distance-optimal algorithm. <p> Analyzing or implementing an algorithm based on this approach would likely be difficult, however. Finally, we note that our upper bound result is a randomized algorithm. Are there deterministic algorithms that match these bounds? Recent work of Kaufmann et. al. <ref> [8] </ref> may yield a deterministic 1:15n algorithm.
Reference: [9] <author> D. Krizanc, L. Narayanan, and R. Raman. </author> <title> Fast deterministic selection on mesh-connected processor arrays. </title> <journal> Algorithmica, </journal> <volume> 15: </volume> <pages> 319-332, </pages> <year> 1996. </year>
Reference-contexts: The proof of Theorem 3.3 can be found in Section A.4. 4 A Randomized Algorithm for Selection The high-level description of our algorithm is similar to previous algorithms of <ref> [7, 9] </ref>. However, we use several new techniques, including greater adaptiveness, in order to obtain gains in the running time. We start this section with an outline of the general scheme used in previous algorithms, and then describe our new techniques in detail. <p> To achieve constant size queues here, we use a redistribution technique described in <ref> [9] </ref>. Essentially, packets that are moving along a row towards the perimeter of the diamond stop at the first node which has a non-full queue.
Reference: [10] <author> M. Kunde. </author> <title> l-selection and related problems on grids of processors. </title> <journal> Journal of New Generation Computer Systems, </journal> <volume> 2 </volume> <pages> 129-143, </pages> <year> 1989. </year>
Reference-contexts: Any selection algorithm requires n1 steps, since this is the distance from the corners to the center of the mesh. This is the only known lower bound for selection on the standard model of the mesh (Kunde's lower bound of 2n o (n) steps <ref> [10] </ref> applies only to a very restricted model of the mesh). The previously best algorithm for this problem runs in 1:22n steps [7, 8, 15]. <p> An algorithm is weakly-adaptive if it is O (1)-adaptive; otherwise we say it is 4 highly-adaptive. An algorithm is maximally adaptive if every step of the algorithm is a knowledge step. The maximally-adaptive model is similar to the lower bound model of Schnorr and Shamir [18], Kunde <ref> [10] </ref> and Han et al. [5]. However, our model allows replication of packets, which is not allowed in their model. <p> Our new algorithm in Section 4 is the first algorithm for selection which is not quadrant constrained. Parts (a) and (b) of Theorem 3.3 extend in different ways a previous result of Kunde <ref> [10] </ref>, who proved a lower bound of 2n o (n) steps for maximally-adaptive algorithms with queue size of 1, and the additional restriction that packets are not replicated. <p> The best previously known algorithm for selection, and also the algorithm in this paper, satisfy the restrictions of this model. Other lower bounds are also presented, which improve on previous work of Kunde <ref> [10] </ref>. In contrast to our negative results, we obtained a randomized algorithm for selection at the center processor that runs in 1:15n steps with high probability.
Reference: [11] <author> F. T. Leighton. </author> <title> Average case analysis of greedy routing algorithms on arrays. </title> <booktitle> In Proceedings of the 2nd Annual ACM Symposium on Parallel Algorithms and Architecture, </booktitle> <pages> pages 2-10, </pages> <year> 1990. </year>
Reference: [12] <author> T. Leighton. </author> <title> Introduction to Parallel Algorithms and Architectures: Arrays, Trees, Hyper-cubes. </title> <publisher> Morgan-Kaufmann, </publisher> <address> San Mateo, </address> <year> 1992. </year>
Reference-contexts: At the end of the algorithm the selected element must be at the center processor of the mesh. Because of the simplicity of its architecture, the mesh model is a well-studied and popular model of parallel computation <ref> [12] </ref> and is the basis for several parallel machines [1, 14]. <p> Because of the simplicity of its architecture, the mesh model is a well-studied and popular model of parallel computation [12] and is the basis for several parallel machines [1, 14]. We consider a standard model <ref> [6, 7, 12, 13, 16] </ref> in which a processor is allowed to communicate one packet of information to each of its neighbors during a single time step and to queue a constant number of packets between time steps.
Reference: [13] <author> F. Leighton, F. Makedon, and I. Tollis. </author> <title> A 2n 2 step algorithm for routing in an n fi n array with constant size queues. </title> <booktitle> In Proceedings of the 1989 ACM Symposium on Parallel Algorithms and Architecture, </booktitle> <pages> pages 328-335, </pages> <year> 1989. </year>
Reference-contexts: Because of the simplicity of its architecture, the mesh model is a well-studied and popular model of parallel computation [12] and is the basis for several parallel machines [1, 14]. We consider a standard model <ref> [6, 7, 12, 13, 16] </ref> in which a processor is allowed to communicate one packet of information to each of its neighbors during a single time step and to queue a constant number of packets between time steps. <p> This question is especially interesting in light of the fact that distance-optimal algorithms for the related problems of sorting and routing have recently been discovered <ref> [6, 8, 13] </ref>. We provide a partial answer for this question in this paper. Our main lower bound shows that the techniques used in the best previous selection algorithms cannot yield a distance-optimal algorithm. <p> Conclusions are presented in Section 5. 2 Upper and Lower Bound Models 2.1 Upper Bound Model Our upper bound model is a standard one for describing routing algorithms on the mesh <ref> [6, 7, 13, 16] </ref>. The n fi n mesh-connected array of processors (or two-dimensional mesh) contains N = n 2 processors arranged in a two-dimensional grid.
Reference: [14] <author> S. L. Lillevik. </author> <title> Touchstone program overview. </title> <booktitle> In Proceedings of the 5th Distributed Memory Computing Conference, </booktitle> <address> Charleston, SC, </address> <month> April 9-12 </month> <year> 1990. </year> <month> 21 </month>
Reference-contexts: At the end of the algorithm the selected element must be at the center processor of the mesh. Because of the simplicity of its architecture, the mesh model is a well-studied and popular model of parallel computation [12] and is the basis for several parallel machines <ref> [1, 14] </ref>. We consider a standard model [6, 7, 12, 13, 16] in which a processor is allowed to communicate one packet of information to each of its neighbors during a single time step and to queue a constant number of packets between time steps.
Reference: [15] <author> L. Narayanan. </author> <title> Selection, Sorting, and Routing on Mesh-Connected Processor Arrays. </title> <type> PhD thesis, </type> <institution> University of Rochester, </institution> <year> 1992. </year>
Reference-contexts: This is the only known lower bound for selection on the standard model of the mesh (Kunde's lower bound of 2n o (n) steps [10] applies only to a very restricted model of the mesh). The previously best algorithm for this problem runs in 1:22n steps <ref> [7, 8, 15] </ref>. Thus, the complexity of selection on the mesh is well-known to be fi (n); the main open question is whether there exists a distance-optimal, or n + o (n)-time, algorithm for selection on the mesh.
Reference: [16] <author> S. Rajasekaran and T. Tsantilas. </author> <title> Optimal algorithms for routing on the mesh. </title> <journal> Algorithmica, </journal> <volume> 8 </volume> <pages> 21-38, </pages> <year> 1992. </year>
Reference-contexts: Because of the simplicity of its architecture, the mesh model is a well-studied and popular model of parallel computation [12] and is the basis for several parallel machines [1, 14]. We consider a standard model <ref> [6, 7, 12, 13, 16] </ref> in which a processor is allowed to communicate one packet of information to each of its neighbors during a single time step and to queue a constant number of packets between time steps. <p> Conclusions are presented in Section 5. 2 Upper and Lower Bound Models 2.1 Upper Bound Model Our upper bound model is a standard one for describing routing algorithms on the mesh <ref> [6, 7, 13, 16] </ref>. The n fi n mesh-connected array of processors (or two-dimensional mesh) contains N = n 2 processors arranged in a two-dimensional grid.
Reference: [17] <author> R. Reischuk. </author> <title> Probabilistic parallel algorithms for sorting and selection. </title> <journal> SIAM Journal of Computing, </journal> <volume> 14(2) </volume> <pages> 396-411, </pages> <month> May </month> <year> 1985. </year>
Reference-contexts: It is now possible to give an overview of the running time of the algorithm. First, consider Step 2. The bracketing elements are selected by the center processor using sampling techniques (see <ref> [17, 7] </ref>); to get a sample of the entire input to the center requires n steps since this is the maximum distance of an element to the center. <p> The proof of the running time is technically complicated and can be found in Section A.1. 2 13 4.2 Steps 1b and 1d: Selecting the Splitters Selection of the splitter elements is done using the following set sampling method of <ref> [17] </ref>, which was also used in [7]. Each element in the set tosses a coin, which is heads with probability ffN 5ffi1 ln N , for some constants ff and ffi (ff = 18 and ffi = 1=6 is sufficient). The set of elements which toss heads is the sample. <p> The set of elements which toss heads is the sample. Every (ffN 4ffi ln N )-th element of the sample is called a divider. The following lemma is proved in <ref> [17] </ref>. Lemma 4.2 For sufficiently small constants ffi, given a set of m = fi (N ); m N elements, the above scheme produces mN ffi1 dividers which divide the elements into buckets of size N 1ffi (1 N 2ffi ).
Reference: [18] <author> C. Schnorr and A. Shamir. </author> <title> An optimal sorting algorithm for mesh-connected computers. </title> <booktitle> In Proceedings of the Eighteenth Annual ACM Symposium on the Theory of Computation, </booktitle> <pages> pages 255-263, </pages> <year> 1986. </year>
Reference-contexts: An algorithm is weakly-adaptive if it is O (1)-adaptive; otherwise we say it is 4 highly-adaptive. An algorithm is maximally adaptive if every step of the algorithm is a knowledge step. The maximally-adaptive model is similar to the lower bound model of Schnorr and Shamir <ref> [18] </ref>, Kunde [10] and Han et al. [5]. However, our model allows replication of packets, which is not allowed in their model. <p> If the algorithm fails to route the median to the center processor in the required time, then the center processor broadcasts a message to restart, and a naive O (n) algorithm can be executed (such as an algorithm based on sorting <ref> [18] </ref>). Since the probability of failure is O (N 3 ), the expected running time of the whole algorithm is still 1:15n. It is now possible to give an overview of the running time of the algorithm. First, consider Step 2.
References-found: 18

