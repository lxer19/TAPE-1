URL: http://www.cs.berkeley.edu/~nir/Papers/FrG3.ps
Refering-URL: http://http.cs.berkeley.edu/~nir/publications.html
Root-URL: 
Email: nir@cs.stanford.edu  moises@erg.sri.com  
Title: Learning Bayesian Networks with Local Structure  
Author: Nir Friedman Moises Goldszmidt 
Address: Gates Building 1A Stanford, CA 94305-9010  333 Ravenswood Way, EK329 Menlo Park, CA 94025  
Affiliation: Stanford University Dept. of Computer Science  SRI International  
Abstract: In this paper we examine a novel addition to the known methods for learning Bayesian networks from data that improves the quality of the learned networks. Our approach explicitly represents and learns the local structure in the conditional probability tables (CPTs), that quantify these networks. This increases the space of possible models, enabling the representation of CPTs with a variable number of parameters that depends on the learned local structures. The resulting learning procedure is capable of inducing models that better emulate the real complexity of the interactions present in the data. We describe the theoretical foundations and practical aspects of learning local structures, as well as an empirical evaluation of the proposed method. This evaluation indicates that learning curves characterizing the procedure that exploits the local structure converge faster than these of the standard procedure. Our results also show that networks learned with local structure tend to be more complex (in terms of arcs), yet require less parameters.
Abstract-found: 1
Intro-found: 1
Reference: <author> Beinlich, I., G. Suermondt, R. Chavez, and G. </author> <title> Cooper (1989). The ALARM monitoring system. </title> <booktitle> In Proc. 2'nd European Conf. on AI and Medicine. </booktitle>
Reference: <author> Boutilier, C., N. Friedman, M. Goldszmidt, and D. </author> <title> Koller (1996). Context-specific independence in Bayesian networks. </title> <booktitle> In UAI '96. </booktitle>
Reference: <author> Buntine, W. </author> <year> (1991a). </year> <title> A theory of learning classification rules. </title>
Reference: <author> Ph. D. </author> <type> thesis, </type> <institution> University of Technology, Sydney. </institution>
Reference: <author> Buntine, W. </author> <year> (1991b). </year> <title> Theory refinement on Bayesian networks. </title> <booktitle> In UAI '91, </booktitle> <pages> pp. 52-60. </pages>
Reference: <author> Buntine, W. </author> <year> (1993). </year> <title> Learning classification trees. </title> <booktitle> In Artificial Intelligence Frontiers in Statistics. </booktitle> <publisher> Chapman & Hall. </publisher>
Reference: <author> Cooper, G. F. and E. </author> <title> Herskovits (1992). A Bayesian method for the induction of probabilistic networks from data. </title> <booktitle> Machine Learning 9, </booktitle> <pages> 309-347. </pages>
Reference: <author> Cover, T. M. and J. A. </author> <title> Thomas (1991). Elements of Information Theory. </title> <publisher> Wiley. </publisher>
Reference: <author> Diez, F. J. </author> <year> (1993). </year> <title> Parameter adjustment in bayes networks. the generalized noisy or-gate. </title> <booktitle> In UAI '93, </booktitle> <pages> pp. 99-105. </pages>
Reference: <author> Friedman, N. and Z. </author> <month> Yakhini </month> <year> (1996). </year> <title> On the sample complexity of learning Bayesian networks. </title> <booktitle> In UAI '96. </booktitle>
Reference: <author> Heckerman, D. </author> <year> (1995). </year> <title> A tutorial on learning Bayesian networks. </title> <type> Technical Report MSR-TR-95-06, </type> <institution> Microsoft Research. </institution>
Reference: <author> Heckerman, D. and J. S. </author> <title> Breese (1994). A new look at causal independence. </title> <booktitle> In UAI '94, </booktitle> <pages> pp. 286-292. </pages>
Reference: <author> Heckerman, D., D. Geiger, and D. M. </author> <title> Chickering (1995). Learning Bayesian networks: The combination of knowl-ege and statistical data. </title> <booktitle> Machine Learning 20, </booktitle> <pages> 197-243. </pages>
Reference: <author> Lam, W. and F. </author> <title> Bacchus (1994). Learning Bayesian belief networks. An approach based on the MDL principle. </title> <booktitle> Computational Intelligence 10, </booktitle> <pages> 269-293. </pages>
Reference: <author> Musick, R. </author> <year> (1994). </year> <title> Belief Network Induction. </title> <editor> Ph. D. thesis, U. C. </editor> <address> Berkeley. </address>
Reference: <author> Neal, R. M. </author> <year> (1992). </year> <title> Connectionist learning of belief networks. </title> <booktitle> Artificial Intelligence 56, </booktitle> <pages> 71-113. </pages>
Reference: <author> Pearl, J. </author> <year> (1988). </year> <title> Probabilistic Reasoning in Intelligent Systems. </title> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Quinlan, J. R. </author> <year> (1993). </year> <title> C4.5: Programs for Machine Learning. </title> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Quinlan, J. R. and R. </author> <title> Rivest (1989). Inferring decision trees using the minimum description length principle. </title> <booktitle> Information and Computation 80, </booktitle> <pages> 227-248. </pages>
Reference: <author> Rissanen, J. </author> <year> (1989). </year> <title> Stochastic Complexity in Statistical Inquiry. </title> <publisher> World Scientific Publ. </publisher>
Reference: <author> Schwarz, G. </author> <year> (1978). </year> <title> Estimating the dimension of a model. </title> <journal> Annals of Statistics 6, </journal> <pages> 461-464. </pages>
Reference: <author> Spiegelhalter, D. J. and S. L. </author> <title> Lauritzen (1990). Sequential updating of conditional probabilities on directed graphical structures. </title> <booktitle> Networks 20, </booktitle> <pages> 579-605. </pages>
Reference: <author> Srinivas, S. </author> <year> (1993). </year> <title> A generalization of the noisy-or model. </title> <booktitle> In UAI '93, </booktitle> <pages> pp. 208-215. </pages>
Reference: <author> Wallace, C. and J. </author> <title> Patrick (1993). Coding decision trees. </title> <booktitle> Machine Learning 11, </booktitle> <pages> 7-22. </pages>
References-found: 24

