URL: http://www.cs.ucsb.edu/~acha/publications/sigmodrec98.ps.gz
Refering-URL: http://www.cs.ucsb.edu/~acha/publications/sigmod-rec98.html
Root-URL: http://www.cs.ucsb.edu
Email: chialin@cs.umd.edu, acha@cs.ucsb.edu, als@cs.umd.edu, saltz@cs.umd.edu  
Title: T2: A Customizable Parallel Database For Multi-dimensional Data  
Author: Chialin Chang Anurag Acharya Alan Sussman Joel Saltz 
Date: March 17, 1998  
Address: College Park, MD 20742  Santa Barbara, CA 93106  Baltimore, MD 21287  
Affiliation: Dept. of Computer Science University of Maryland  Dept. of Computer Science University of California  Dept. of Pathology Johns Hopkins Medical Institutions  
Pubnum: TRCS98-05  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> A. Acharya, M. Uysal, R. Bennett, A. Mendelson, M. Beynon, J. Hollingsworth, J. Saltz, and A. Suss-man. </author> <title> Tuning the performance of I/O-intensive parallel applications. </title> <booktitle> In Proceedings of the Fourth ACM Workshop on I/O in Parallel and Distributed Systems, </booktitle> <month> May </month> <year> 1996. </year>
Reference-contexts: Furthermore, every application developer has to implement complex support for managing and scheduling the processing. Over the past three years, we have been working with several scientific research groups to understand the processing requirements for such applications <ref> [1, 5, 6, 10, 12, 19, 24, 25, 31] </ref>. Our study of a large set of applications indicates that the processing for such datasets is often highly stylized and shares several important characteristics. Usually, both the input dataset as well as the result being computed have underlying multi-dimensional grids. <p> A typical analysis <ref> [1, 5, 12, 19] </ref> processes satellite data for ten days to a year and generates one or more composite images of the area under study.
Reference: [2] <author> P. Baumann, P. Furtado, R. Ritsch, and N. Wid-mann. </author> <booktitle> Geo/environmental and medical data management in the RasDaMan system. In Proceedings of the 23th VLDB Conference, </booktitle> <pages> pages 548-552, </pages> <address> Athens, Greece, </address> <month> Aug. </month> <year> 1997. </year>
Reference-contexts: These datasets are usually multi-dimensional. The data dimensions can be spatial coordinates, time, or varying experimental conditions such as temperature, velocity or magnetic field. The increasing importance of such datasets has been recognized by several database research groups and several systems have been developed for managing and/or visualizing them <ref> [2, 7, 15, 20, 30, 34] </ref>.
Reference: [3] <author> N. Beckmann, H.-P. Kriegel, R. Schneider, and B. Seeger. </author> <title> The R fl -tree: An efficient and robust access method for points and rectangles. </title> <booktitle> In Proceedings of the 1990 ACM-SIGMOD Conference, </booktitle> <pages> pages 322-331, </pages> <address> Atlantic City, NJ, </address> <month> May </month> <year> 1990. </year>
Reference-contexts: T2 uses multi-dimensional indices (e.g., R fl -trees <ref> [3, 14] </ref>, quad-trees [11]) to manage these datasets. For a given dataset, a separate index is created for every attribute space of interest.
Reference: [4] <author> C. F. Cerco and T. Cole. </author> <title> User's guide to the CE-QUAL-ICM three-dimensional eutrophica-tion model, release version 1.0. </title> <type> Technical Report EL-95-15, </type> <institution> US Army Corps of Engineers Water Experiment Station, Vicksburg, MS, </institution> <year> 1995. </year>
Reference-contexts: Typical examples of very large scientific datasets include long running simulations of time-dependent phenomena that periodically generate snapshots of their state (e.g. hydrodynamics and chemical transport simulation for estimating pollution impact on water bodies <ref> [4, 6, 21] </ref>, magne-tohydrodynamics simulation of planetary magneto-spheres [35], simulation of a flame sweeping through a volume [31], airplane wake simulations [22]), archives of raw and processed remote sensing data (e.g. <p> Water contamination studies: Environmental scientists study the water quality of bays and estuaries using long running hydrodynamics and chemical transport simulations <ref> [4, 6, 21] </ref>. The hydrodynamics simulation imposes an unstructured grid on the area of interest and determines circulation patterns and fluid velocities over time. The chemical transport simulation models reactions and transport of contaminants, using the fluid velocity data generated by the hydrodynamics simulation.
Reference: [5] <author> C. Chang, B. Moon, A. Acharya, C. Shock, A. Suss-man, and J. Saltz. </author> <title> Titan: A high performance remote-sensing database. </title> <booktitle> In Proceedings of the 1997 International Conference on Data Engineering, </booktitle> <pages> pages 375-384. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> Apr. </month> <year> 1997. </year>
Reference-contexts: Furthermore, every application developer has to implement complex support for managing and scheduling the processing. Over the past three years, we have been working with several scientific research groups to understand the processing requirements for such applications <ref> [1, 5, 6, 10, 12, 19, 24, 25, 31] </ref>. Our study of a large set of applications indicates that the processing for such datasets is often highly stylized and shares several important characteristics. Usually, both the input dataset as well as the result being computed have underlying multi-dimensional grids. <p> A typical analysis <ref> [1, 5, 12, 19] </ref> processes satellite data for ten days to a year and generates one or more composite images of the area under study. <p> This example is loosely based on Titan <ref> [5] </ref>, a prototype data server capable of producing composite images out of raw remotely-sensed data. The AVHRR dataset is partitioned into IFOV chunks based on the geometry of the IFOVs and the performance characteristics of the disks used to store the data.
Reference: [6] <author> S. Chippada, C. N. Dawson, M. L. Martnez, and M. F. Wheeler. </author> <title> A Godunov-type finite volume method for the system of shallow water equations. </title> <note> Computer Methods in Applied Mechanics and Engineering (to appear), 1997. Also a TICAM Report 96-57, </note> <institution> University of Texas, Austin, </institution> <address> TX 78712. </address>
Reference-contexts: Typical examples of very large scientific datasets include long running simulations of time-dependent phenomena that periodically generate snapshots of their state (e.g. hydrodynamics and chemical transport simulation for estimating pollution impact on water bodies <ref> [4, 6, 21] </ref>, magne-tohydrodynamics simulation of planetary magneto-spheres [35], simulation of a flame sweeping through a volume [31], airplane wake simulations [22]), archives of raw and processed remote sensing data (e.g. <p> Furthermore, every application developer has to implement complex support for managing and scheduling the processing. Over the past three years, we have been working with several scientific research groups to understand the processing requirements for such applications <ref> [1, 5, 6, 10, 12, 19, 24, 25, 31] </ref>. Our study of a large set of applications indicates that the processing for such datasets is often highly stylized and shares several important characteristics. Usually, both the input dataset as well as the result being computed have underlying multi-dimensional grids. <p> Water contamination studies: Environmental scientists study the water quality of bays and estuaries using long running hydrodynamics and chemical transport simulations <ref> [4, 6, 21] </ref>. The hydrodynamics simulation imposes an unstructured grid on the area of interest and determines circulation patterns and fluid velocities over time. The chemical transport simulation models reactions and transport of contaminants, using the fluid velocity data generated by the hydrodynamics simulation.
Reference: [7] <author> D. J. DeWitt, N. Kabra, J. Luo, J. M. Patel, and J.-B. Yu. </author> <title> Client-server Paradise. </title> <booktitle> In Proceedings of the 20th VLDB Conference, </booktitle> <pages> pages 558-569. </pages> <publisher> Morgan Kaufmann Publishers, Inc., </publisher> <year> 1994. </year>
Reference-contexts: These datasets are usually multi-dimensional. The data dimensions can be spatial coordinates, time, or varying experimental conditions such as temperature, velocity or magnetic field. The increasing importance of such datasets has been recognized by several database research groups and several systems have been developed for managing and/or visualizing them <ref> [2, 7, 15, 20, 30, 34] </ref>.
Reference: [8] <author> J. Dongarra, J. D. Croz, S. Hammarling, and I. S. Duff. </author> <title> A set of level 3 basic linear algebra subprograms. </title> <journal> ACM Transactions on Mathematical Software, </journal> <volume> 16(1) </volume> <pages> 1-17, </pages> <month> Mar. </month> <year> 1990. </year>
Reference-contexts: As a result, a data chunk has to be retrieved only once. This is similar to the strip-mining and/or blocking operations performed for optimizing cache usage for matrix operations <ref> [8, 17, 26] </ref>. The query execution service performs two kinds of synchronization. First, it enforces the synchronization indicated by the synchronization markers in the 7 list of chunks to be retrieved from every disk (com-puted by the planning service).
Reference: [9] <author> M. T. Fang, R. C. T. Lee, and C. C. Chang. </author> <title> The idea of de-clustering and its applications. </title> <booktitle> In Proceedings of the 12th VLDB Conference, </booktitle> <pages> pages 181-188, </pages> <address> Kyoto, Japan, </address> <year> 1986. </year>
Reference-contexts: As for mapping functions, T2 currently supports static linking; we plan to provide dynamic linking in the near future. By default, T2 uses the minimax algorithm [24, 25] for decluster-ing and the Short Spanning Path (SSP) algorithm <ref> [9] </ref> for clustering. In addition, T2 allows the data layout to be separately computed and provided in a file. This would be useful if the algorithms used to compute the placements were embedded in some other application that could not be structured to fit T2's interface requirements.
Reference: [10] <author> R. Ferreira, B. Moon, J. Humphries, A. Sussman, J. Saltz, R. Miller, and A. Demarzo. </author> <title> The Virtual Microscope. </title> <booktitle> In Proceedings of the 1997 AMIA Annual Fall Symposium, </booktitle> <pages> pages 449-453. </pages> <institution> American Medical Informatics Association, Hanley and Belfus, Inc., </institution> <month> Oct. </month> <year> 1997. </year> <note> Also available as University of Maryland Technical Report CS-TR-3777 and UMIACS-TR-97-35. </note>
Reference-contexts: Furthermore, every application developer has to implement complex support for managing and scheduling the processing. Over the past three years, we have been working with several scientific research groups to understand the processing requirements for such applications <ref> [1, 5, 6, 10, 12, 19, 24, 25, 31] </ref>. Our study of a large set of applications indicates that the processing for such datasets is often highly stylized and shares several important characteristics. Usually, both the input dataset as well as the result being computed have underlying multi-dimensional grids. <p> Sensor values are pre-processed to correct the effects of various distortions, such as instrument drift, atmospheric distortion and topographic effects, before they are used. Virtual Microscope and Analysis of Microscopy Data : The Virtual Microscope <ref> [10] </ref> is an application we have developed to support the need to interactively view and process digitized data aris 2 ing from tissue specimens. The Virtual Microscope provides a realistic digital emulation of a high power light microscope.
Reference: [11] <author> R. A. Finkel and J. L. Bentley. </author> <title> Quad-Trees a data structure for retrieval on composite keys. </title> <journal> Acta In-formatica, </journal> <volume> 4 </volume> <pages> 1-9, </pages> <year> 1974. </year>
Reference-contexts: T2 uses multi-dimensional indices (e.g., R fl -trees [3, 14], quad-trees <ref> [11] </ref>) to manage these datasets. For a given dataset, a separate index is created for every attribute space of interest. For example, the underlying attribute space for AVHRR satellite data has three axes latitude (in 1/128th of a degree), longitude (1/128th of a degree) and time (in seconds).
Reference: [12] <institution> NSF/ARPA Grand Challenge Project at the University of Maryland for Land Cover Dynamics, </institution> <year> 1995. </year> <note> http://www.umiacs.umd.edu:80/research/GC/. 9 </note>
Reference-contexts: Furthermore, every application developer has to implement complex support for managing and scheduling the processing. Over the past three years, we have been working with several scientific research groups to understand the processing requirements for such applications <ref> [1, 5, 6, 10, 12, 19, 24, 25, 31] </ref>. Our study of a large set of applications indicates that the processing for such datasets is often highly stylized and shares several important characteristics. Usually, both the input dataset as well as the result being computed have underlying multi-dimensional grids. <p> A typical analysis <ref> [1, 5, 12, 19] </ref> processes satellite data for ten days to a year and generates one or more composite images of the area under study.
Reference: [13] <author> J. Gray, A. Bosworth, A. Layman, and H. Pira--hesh. </author> <title> Data cube: A relational aggregation operator generalizing group-by, </title> <booktitle> cross-tab, and sub-totals. In Proceedings of the 1996 International Conference on Data Engineering, </booktitle> <pages> pages 152-159, </pages> <address> New Orleans, Louisiana, </address> <month> Feb. </month> <year> 1996. </year>
Reference-contexts: Aggregation functions are assumed to be commutative and associative and can be applied to individual data items in parallel and in any order. T2 is able to deal with both distributive and algebraic aggregation functions as defined by Gray et. al <ref> [13] </ref>. Currently, aggregation functions are statically linked. We plan to provide dynamic linking facilities in the near future. Functions are specified by a (function name, object file name) pair.
Reference: [14] <author> A. Guttman. R-Trees: </author> <title> A dynamic index structure for spatial searching. </title> <booktitle> In Proceedings of the 1984 ACM-SIGMOD Conference, </booktitle> <pages> pages 47-57, </pages> <address> Boston, MA, </address> <month> June </month> <year> 1984. </year>
Reference-contexts: T2 uses multi-dimensional indices (e.g., R fl -trees <ref> [3, 14] </ref>, quad-trees [11]) to manage these datasets. For a given dataset, a separate index is created for every attribute space of interest.
Reference: [15] <author> Y. Ioannidis, M. Livny, S. Gupta, and N. Ponnekanti. </author> <title> ZOO: A desktop experiment management environment. </title> <booktitle> In Proc. 22nd International VLDB Conference, </booktitle> <pages> pages 274-85, </pages> <year> 1996. </year>
Reference-contexts: These datasets are usually multi-dimensional. The data dimensions can be spatial coordinates, time, or varying experimental conditions such as temperature, velocity or magnetic field. The increasing importance of such datasets has been recognized by several database research groups and several systems have been developed for managing and/or visualizing them <ref> [2, 7, 15, 20, 30, 34] </ref>.
Reference: [16] <author> C. O. Justice, J. R. G. Townshend, B. N. Holben, and C. J. Tucker. </author> <title> Analysis of the phenology of global vegetation using meteorological satellite data. </title> <journal> International Journal of Remote Sensing, </journal> <pages> pages 1271-1318, </pages> <year> 1985. </year>
Reference-contexts: This derived spatial attribute space is used for the standard AVHRR data product. As described in Section 3, the transformation function registered with the data aggregation service performs a sequence of corrections to each IFOV. In addition, it also computes the Normalized Difference Vegetation Index (NDVI) <ref> [16] </ref> for each IFOV, using corrected values from the first two bands of each 8 IFOV.
Reference: [17] <author> I. Kodukula, N. Ahmed, and K. Pingali. </author> <title> Data-centric multi-level blocking. </title> <booktitle> In Proceedings of the SIGPLAN '97 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 346-357. </pages> <publisher> ACM Press, </publisher> <month> June </month> <year> 1997. </year> <journal> ACM SIGPLAN Notices, </journal> <volume> Vol. 32, No. </volume> <pages> 5. </pages>
Reference-contexts: As a result, a data chunk has to be retrieved only once. This is similar to the strip-mining and/or blocking operations performed for optimizing cache usage for matrix operations <ref> [8, 17, 26] </ref>. The query execution service performs two kinds of synchronization. First, it enforces the synchronization indicated by the synchronization markers in the 7 list of chunks to be retrieved from every disk (com-puted by the planning service).
Reference: [18] <institution> Land Satellite Thematic Mapper (TM). </institution> <note> http://edcwww.cr.usgs.gov/nsdi/html/landsat tm/ landsat tm. </note>
Reference-contexts: AVHRR [27], Thematic Mapper <ref> [18] </ref>, MODIS [23]), and archives of medical images (e.g. high resolution confocal light microscopy, CT imaging, MRI, sonog-raphy). These datasets are usually multi-dimensional. The data dimensions can be spatial coordinates, time, or varying experimental conditions such as temperature, velocity or magnetic field.
Reference: [19] <author> S. Liang, L. Davis, J. Townshend, R. Chellappa, R. Dubayah, S. Goward, J. JaJa, S. Krishnamachari, N. Roussopoulos, J. Saltz, H. Samet, T. Shock, and M. Srinivasan. </author> <title> Land cover dynamics investigation using parallel computers. </title> <booktitle> In Proceedings of the 1995 International Geoscience and Remote Sensing Symposium, Quantitative Remote Sensing for Science and Applications., </booktitle> <pages> pages 332-4, </pages> <month> July </month> <year> 1995. </year>
Reference-contexts: Furthermore, every application developer has to implement complex support for managing and scheduling the processing. Over the past three years, we have been working with several scientific research groups to understand the processing requirements for such applications <ref> [1, 5, 6, 10, 12, 19, 24, 25, 31] </ref>. Our study of a large set of applications indicates that the processing for such datasets is often highly stylized and shares several important characteristics. Usually, both the input dataset as well as the result being computed have underlying multi-dimensional grids. <p> A typical analysis <ref> [1, 5, 12, 19] </ref> processes satellite data for ten days to a year and generates one or more composite images of the area under study.
Reference: [20] <author> M. Livny, R. Ramakrishnan, K. Beyer, G. Chen, D. Donjerkovic, S. Lawande, J. Myllymaki, and K. Wenger. </author> <title> DEVise: integrated querying and visual exploration of large datasets. </title> <booktitle> In Proceedings of ACM SIGMOD, </booktitle> <pages> pages 301-12, </pages> <year> 1997. </year>
Reference-contexts: These datasets are usually multi-dimensional. The data dimensions can be spatial coordinates, time, or varying experimental conditions such as temperature, velocity or magnetic field. The increasing importance of such datasets has been recognized by several database research groups and several systems have been developed for managing and/or visualizing them <ref> [2, 7, 15, 20, 30, 34] </ref>.
Reference: [21] <author> R. A. Luettich, J. J. Westerink, and N. W. Scheffner. ADCIRC: </author> <title> An advanced three-dimensional circulation model for shelves, coasts, and estuaries. </title> <type> Technical Report 1, </type> <institution> Department of the Army, U.S. Army Corps of Engineers, </institution> <address> Washington, D.C. 20314-1000, </address> <month> December </month> <year> 1991. </year>
Reference-contexts: Typical examples of very large scientific datasets include long running simulations of time-dependent phenomena that periodically generate snapshots of their state (e.g. hydrodynamics and chemical transport simulation for estimating pollution impact on water bodies <ref> [4, 6, 21] </ref>, magne-tohydrodynamics simulation of planetary magneto-spheres [35], simulation of a flame sweeping through a volume [31], airplane wake simulations [22]), archives of raw and processed remote sensing data (e.g. <p> Water contamination studies: Environmental scientists study the water quality of bays and estuaries using long running hydrodynamics and chemical transport simulations <ref> [4, 6, 21] </ref>. The hydrodynamics simulation imposes an unstructured grid on the area of interest and determines circulation patterns and fluid velocities over time. The chemical transport simulation models reactions and transport of contaminants, using the fluid velocity data generated by the hydrodynamics simulation.
Reference: [22] <author> K.-L. Ma and Z. Zheng. </author> <title> 3D visualization of unsteady 2D airplane wake vortices. </title> <booktitle> In Proceedings of Visualization'94, </booktitle> <pages> pages 124-31, </pages> <month> Oct </month> <year> 1994. </year>
Reference-contexts: scientific datasets include long running simulations of time-dependent phenomena that periodically generate snapshots of their state (e.g. hydrodynamics and chemical transport simulation for estimating pollution impact on water bodies [4, 6, 21], magne-tohydrodynamics simulation of planetary magneto-spheres [35], simulation of a flame sweeping through a volume [31], airplane wake simulations <ref> [22] </ref>), archives of raw and processed remote sensing data (e.g. AVHRR [27], Thematic Mapper [18], MODIS [23]), and archives of medical images (e.g. high resolution confocal light microscopy, CT imaging, MRI, sonog-raphy). These datasets are usually multi-dimensional.
Reference: [23] <institution> The Moderate Resolution Imaging Spectrometer. </institution> <note> http://ltpwww.gsfc.nasa.gov/MODIS/MODIS.html. </note>
Reference-contexts: AVHRR [27], Thematic Mapper [18], MODIS <ref> [23] </ref>), and archives of medical images (e.g. high resolution confocal light microscopy, CT imaging, MRI, sonog-raphy). These datasets are usually multi-dimensional. The data dimensions can be spatial coordinates, time, or varying experimental conditions such as temperature, velocity or magnetic field.
Reference: [24] <author> B. Moon, A. Acharya, and J. Saltz. </author> <title> Study of scalable declustering algorithms for parallel grid files. </title> <booktitle> In Proceedings of the Tenth International Parallel Processing Symposium, </booktitle> <pages> pages 434-440. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> Apr. </month> <year> 1996. </year>
Reference-contexts: Furthermore, every application developer has to implement complex support for managing and scheduling the processing. Over the past three years, we have been working with several scientific research groups to understand the processing requirements for such applications <ref> [1, 5, 6, 10, 12, 19, 24, 25, 31] </ref>. Our study of a large set of applications indicates that the processing for such datasets is often highly stylized and shares several important characteristics. Usually, both the input dataset as well as the result being computed have underlying multi-dimensional grids. <p> Each algorithm is specified by name. Algorithms that have not been previously integrated into T2 have to be linked in. As for mapping functions, T2 currently supports static linking; we plan to provide dynamic linking in the near future. By default, T2 uses the minimax algorithm <ref> [24, 25] </ref> for decluster-ing and the Short Spanning Path (SSP) algorithm [9] for clustering. In addition, T2 allows the data layout to be separately computed and provided in a file.
Reference: [25] <author> B. Moon and J. H. Saltz. </author> <title> Scalability analysis of declustering methods for multidimensional range queries. </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <note> 1997. To appear. </note>
Reference-contexts: Furthermore, every application developer has to implement complex support for managing and scheduling the processing. Over the past three years, we have been working with several scientific research groups to understand the processing requirements for such applications <ref> [1, 5, 6, 10, 12, 19, 24, 25, 31] </ref>. Our study of a large set of applications indicates that the processing for such datasets is often highly stylized and shares several important characteristics. Usually, both the input dataset as well as the result being computed have underlying multi-dimensional grids. <p> Each algorithm is specified by name. Algorithms that have not been previously integrated into T2 have to be linked in. As for mapping functions, T2 currently supports static linking; we plan to provide dynamic linking in the near future. By default, T2 uses the minimax algorithm <ref> [24, 25] </ref> for decluster-ing and the Short Spanning Path (SSP) algorithm [9] for clustering. In addition, T2 allows the data layout to be separately computed and provided in a file.
Reference: [26] <author> T. C. Mowry, M. S. Lam, and A. Gupta. </author> <title> Design and evaluation of a compiler algorithm for prefetch-ing. </title> <booktitle> In Proceedings of the Fifth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS V), </booktitle> <pages> pages 62-73. </pages> <publisher> ACM Press, </publisher> <month> Oct. </month> <year> 1992. </year>
Reference-contexts: As a result, a data chunk has to be retrieved only once. This is similar to the strip-mining and/or blocking operations performed for optimizing cache usage for matrix operations <ref> [8, 17, 26] </ref>. The query execution service performs two kinds of synchronization. First, it enforces the synchronization indicated by the synchronization markers in the 7 list of chunks to be retrieved from every disk (com-puted by the planning service).
Reference: [27] <institution> NASA Goddard Distributed Active Archive Center (DAAC). Advanced Very High Resolution Radiometer Global Area Coverage (AVHRR GAC) data. </institution> <note> http://daac.gsfc.nasa.gov/CAMPAIGN DOCS/ LAND BIO/origins.html. </note>
Reference-contexts: AVHRR <ref> [27] </ref>, Thematic Mapper [18], MODIS [23]), and archives of medical images (e.g. high resolution confocal light microscopy, CT imaging, MRI, sonog-raphy). These datasets are usually multi-dimensional. The data dimensions can be spatial coordinates, time, or varying experimental conditions such as temperature, velocity or magnetic field.
Reference: [28] <author> S. Olsson and C. Busch. </author> <title> A national telepathology trial in Sweden: Feasibility and assessment. </title> <journal> Arch. Anat. Cytol. Pathol., </journal> <volume> 43 </volume> <pages> 234-241, </pages> <year> 1995. </year>
Reference-contexts: At the basic level, it can emulate the usual behavior of a physical microscope including continuously moving the stage and changing magnification and focus. Used in this manner, the Virtual Microscope can support completely digital dynamic telepathology <ref> [28, 37, 38] </ref>. In addition, it enables new modes of behavior that cannot be achieved with a physical microscope, such as simultaneous viewing and manipulation of a single slide by multiple users. Pathologists and biomedical researchers need to process as well as view microscopy data.
Reference: [29] <institution> The Oracle 8 spatial data cartridge, </institution> <year> 1997. </year> <note> http://www.oracle.com/st/cartridges/spatial/. </note>
Reference-contexts: Anurag Acharya is supported by a grant from the College of Engineering. the SpatialWare DataBlade Module [32] for the In-formix Universal Server and the Oracle 8 Spatial data cartridge <ref> [29] </ref>). These systems, however, focus on lineage management, retrieval and visualization of multi-dimensional datasets. They provide little or no support for analyzing or processing these datasets the assumption is that this is too application-specific to warrant common support.
Reference: [30] <author> J. Patel et al. </author> <title> Building a scaleable geo-spatial DBMS: technology, implementation, and evaluation. </title> <booktitle> In Proceedings of ACM SIGMOD, </booktitle> <pages> pages 336-47, </pages> <year> 1997. </year>
Reference-contexts: These datasets are usually multi-dimensional. The data dimensions can be spatial coordinates, time, or varying experimental conditions such as temperature, velocity or magnetic field. The increasing importance of such datasets has been recognized by several database research groups and several systems have been developed for managing and/or visualizing them <ref> [2, 7, 15, 20, 30, 34] </ref>.
Reference: [31] <author> G. Patnaik, K. Kailasnath, and E. Oran. </author> <title> Effect of gravity on flame instabilities in premixed gases. </title> <journal> AIAA Journal, </journal> <volume> 29(12) </volume> <pages> 2141-8, </pages> <month> Dec </month> <year> 1991. </year>
Reference-contexts: examples of very large scientific datasets include long running simulations of time-dependent phenomena that periodically generate snapshots of their state (e.g. hydrodynamics and chemical transport simulation for estimating pollution impact on water bodies [4, 6, 21], magne-tohydrodynamics simulation of planetary magneto-spheres [35], simulation of a flame sweeping through a volume <ref> [31] </ref>, airplane wake simulations [22]), archives of raw and processed remote sensing data (e.g. AVHRR [27], Thematic Mapper [18], MODIS [23]), and archives of medical images (e.g. high resolution confocal light microscopy, CT imaging, MRI, sonog-raphy). These datasets are usually multi-dimensional. <p> Furthermore, every application developer has to implement complex support for managing and scheduling the processing. Over the past three years, we have been working with several scientific research groups to understand the processing requirements for such applications <ref> [1, 5, 6, 10, 12, 19, 24, 25, 31] </ref>. Our study of a large set of applications indicates that the processing for such datasets is often highly stylized and shares several important characteristics. Usually, both the input dataset as well as the result being computed have underlying multi-dimensional grids.
Reference: [32] <institution> SpatialWare DataBlade Module (from MapInfo) Corp, </institution> <year> 1997. </year> <note> http://www.informix.com/informix/ bussol/iusdb/databld/dbtech/sheets/spware.htm. </note>
Reference-contexts: Anurag Acharya is supported by a grant from the College of Engineering. the SpatialWare DataBlade Module <ref> [32] </ref> for the In-formix Universal Server and the Oracle 8 Spatial data cartridge [29]). These systems, however, focus on lineage management, retrieval and visualization of multi-dimensional datasets.
Reference: [33] <author> D. R. Steinwand. </author> <title> Mapping raster imagery to the Interrupted Goodes Homolosine projection. </title> <address> http://edcwww.cr.usgs.gov/landdaac/1KM/goodesarticle.html. </address>
Reference-contexts: During processing, this attribute space is mapped to another attribute space, which is a grid in the Interrupted Goodes Homolosine map projection <ref> [33] </ref>. T2 allows users to index this dataset either on the underlying latitude-longitude-time attribute space or on the attribute space jointly defined by the Goodes map projection and time. Second, T2 leverages commonality in processing requirements to seamlessly integrate data retrieval and processing for a wide variety of applications.
Reference: [34] <author> M. Stonebraker. </author> <title> An overview of the Sequoia 2000 project. </title> <booktitle> In Proceedings of the 1992 COMPCON Conference, </booktitle> <pages> pages 383-388, </pages> <address> San Francisco, CA, </address> <year> 1992. </year>
Reference-contexts: These datasets are usually multi-dimensional. The data dimensions can be spatial coordinates, time, or varying experimental conditions such as temperature, velocity or magnetic field. The increasing importance of such datasets has been recognized by several database research groups and several systems have been developed for managing and/or visualizing them <ref> [2, 7, 15, 20, 30, 34] </ref>.
Reference: [35] <author> T. Tanaka. </author> <title> Configurations of the solar wind flow and magnetic field around the planets with no magnetic field: calculation by a new MHD. </title> <journal> Jounal of Geophysical Research, </journal> <volume> 98(A10):17251-62, </volume> <month> Oct </month> <year> 1993. </year>
Reference-contexts: Typical examples of very large scientific datasets include long running simulations of time-dependent phenomena that periodically generate snapshots of their state (e.g. hydrodynamics and chemical transport simulation for estimating pollution impact on water bodies [4, 6, 21], magne-tohydrodynamics simulation of planetary magneto-spheres <ref> [35] </ref>, simulation of a flame sweeping through a volume [31], airplane wake simulations [22]), archives of raw and processed remote sensing data (e.g. AVHRR [27], Thematic Mapper [18], MODIS [23]), and archives of medical images (e.g. high resolution confocal light microscopy, CT imaging, MRI, sonog-raphy). These datasets are usually multi-dimensional.
Reference: [36] <institution> The USGS General Cartographic Transformation Package, </institution> <note> version 2.0.2. ftp://mapping.usgs.gov/ pub/software/current software/gctp/, </note> <year> 1997. </year>
Reference-contexts: A variety of projections are used by earth scientists the USGS cartographic transformation package supports 24 different projections <ref> [36] </ref> . An earth scientist specifies the projection that best suits her needs, maps the sensor data using the chosen projection, and generates an image by compositing the projected data.
Reference: [37] <author> M. Weinstein and J. I. Epstein. </author> <title> Telepathology diagnosis of prostate needle biopsies. </title> <booktitle> Human Pathology, </booktitle> <volume> 28(1) </volume> <pages> 22-29, </pages> <month> Jan. </month> <year> 1997. </year>
Reference-contexts: At the basic level, it can emulate the usual behavior of a physical microscope including continuously moving the stage and changing magnification and focus. Used in this manner, the Virtual Microscope can support completely digital dynamic telepathology <ref> [28, 37, 38] </ref>. In addition, it enables new modes of behavior that cannot be achieved with a physical microscope, such as simultaneous viewing and manipulation of a single slide by multiple users. Pathologists and biomedical researchers need to process as well as view microscopy data.
Reference: [38] <author> R. S. Weinstein, A. Bhattacharyya, A. R. Graham, and J. R. Davis. Telepathology: </author> <title> A ten-year progress report. </title> <booktitle> Human Pathology, </booktitle> <volume> 28(1) </volume> <pages> 1-7, </pages> <month> Jan. </month> <year> 1997. </year> <month> 10 </month>
Reference-contexts: At the basic level, it can emulate the usual behavior of a physical microscope including continuously moving the stage and changing magnification and focus. Used in this manner, the Virtual Microscope can support completely digital dynamic telepathology <ref> [28, 37, 38] </ref>. In addition, it enables new modes of behavior that cannot be achieved with a physical microscope, such as simultaneous viewing and manipulation of a single slide by multiple users. Pathologists and biomedical researchers need to process as well as view microscopy data.
References-found: 38

