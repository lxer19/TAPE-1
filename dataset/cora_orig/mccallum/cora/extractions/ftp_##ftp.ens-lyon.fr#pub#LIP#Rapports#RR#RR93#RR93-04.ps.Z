URL: ftp://ftp.ens-lyon.fr/pub/LIP/Rapports/RR/RR93/RR93-04.ps.Z
Refering-URL: http://www.cs.cmu.edu/~rll/talks/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: The cellular developmental of neural networks: the interaction of learning and evolution  
Author: Frederic Gruau Darrell Whitley 
Note: Research Report N o 93-04  
Date: January 1993  
Abstract-found: 0
Intro-found: 0
Reference: <institution> References </institution>
Reference: [1] <author> D.H. Ackley, G.E. Hinton and T.J. Sejnowski, </author> <title> (1985) A learning algorithm for Boltzman machines. </title> <journal> Cognitive Science, </journal> <volume> 9 </volume> <pages> 147-169. </pages>
Reference-contexts: Note that this is somewhat different from perceptron learning in as much as we collect statistical information over all of the training patterns, not just those that result in errors. This learning also is similar to the local learning used in Boltzman machines <ref> [1] </ref>, however, in these experiments we are not concerned with escaping local minima and have no need for the simulated annealing component that is used in the Boltzman machine to achieve a global search of weight space.
Reference: [2] <author> D.H. Ackley and M. Littman, </author> <title> (1991) Interactions between learning and evolution. </title> <booktitle> In, Proc. of the 2nd Conf. on Artificial Life, </booktitle> <editor> C.G. Langton, ed., </editor> <publisher> Addison-Wesley, </publisher> <year> 1991. </year>
Reference-contexts: In this case, the effects on schemata and hyperplane sampling may be minimal. 3.1 The Baldwin Effect There are other ways that evolution and learning can interact that is not Lamarkian in nature. One method which has recently received new attention is the Baldwin effect [11] <ref> [2] </ref>. &gt;From an implementational point of view, exploitation of the Baldwin effect requires that individuals employ some form of learning, but the acquired behavior is not coded back to the genetic encoding as in Lamarkian learning.
Reference: [3] <author> J.M.Baldwin, </author> <title> (1896) A new factor in evolution. </title> <journal> American Naturalist, </journal> <volume> 30 </volume> <pages> 441-451, 1896. </pages>
Reference-contexts: The idea that learned behavior could influence evolution by creating selective pressure toward genetically encoding or genetic predisposing learned behavior was first proposed by J.M. Baldwin <ref> [3] </ref> almost a hundred years ago. Hinton and Nolan [11] offer the following simple example to illustrate the Baldwin effect. 11 Assume that the fitness landscape is flat, with a single spike representing a target solution.
Reference: [4] <author> R.K. Belew, </author> <title> (1989) When both individuals and populations search: Adding simple learning to the Genetic Algorithm. </title> <booktitle> In 3th Intern. Conf. on Genetic Algorithms, </booktitle> <editor> D. Schaffer, ed., </editor> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: The underspecification found by Hinton and Nolan might have occurred because the search was prematurely terminated.) Hinton and Nolan's work illustrates the Baldwin effect, but provides little insight about whether the Baldwin effect can be intentionally exploited to accelerate evolutionary learning. Belew <ref> [4] </ref> also offers a good critique of some of the assumptions underlying the Hinton and Nolan model. In particular, the number of learning trials allocated to the individual must be sufficient to occasionally locate the spike; otherwise, it remains a needle in a haystack.
Reference: [5] <author> R. K. Belew and J. McInerney and N. Schraudolf, </author> <title> (1990) Evolving Networks, Using the Genetic Algorithm with Connectionist Learning. </title> <institution> CSE-CS-90-174, Univ. Calif. </institution> <address> San Diego. </address>
Reference-contexts: A common fitness measurement is the training time. (Generalization would be an interesting fitness measure, but we know of no such study to date.) Miller and Todd have explored these ideas [15], as have Belew, McInerney and Schraudolf <ref> [5] </ref>. Whit-ley, Starkweather and Bogart [20] showed that the genetic algorithm could be used to find network topologies that consistently display improved learning speeds over the typical fully connected feed forward network.
Reference: [6] <author> R. Collins and D. Jefferson, </author> <title> (1991) Selection in massively parallel genetic algorithm. </title> <booktitle> In 4th Intern. Conf. on G. </booktitle> <editor> A., R. Belew and L. Booker, eds., </editor> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: The mother tree almost encodes a XOR, except the number of input nodes is incorrect. The dotted line indicates the subtree which is to be pruned and replaced. The resulting offspring encodes a general solution for the parity problem. isolation by distance <ref> [6] </ref>, such that different local regions on the grid may display local trends in terms of evolutionary development. Individuals are deleted by using an approximation of the scheme of genitor [19].
Reference: [7] <author> D. Sharp, B. Alpert and E. Mjolness, </author> <title> (1988) Scaling, machine learning and genetic neural nets. </title> <institution> La-ur-88-142, Los Alamos National Laboratory. </institution>
Reference-contexts: If the architecture is indeed complex (e.g. 500 connections or more) 9,000 evaluations is likely to be inadequate for genetic search. There are new directions being explored for optimizing neural network architectures. Grammar based architecture descriptions [12] <ref> [7] </ref> [9] [10] may display better scaling properties. By optimizing grammar trees that generate network architectures instead of directly optimizing architectures this research hopes to achieve better scalability, and in some sense, reusability of network architectures.
Reference: [8] <author> D.E. Goldberg, </author> <title> (1989) Genetic Algorithms in Search, Optimization and Machine Learning. </title> <publisher> Addison-Wesley. </publisher>
Reference-contexts: Consider the simple case in which chromosomes are bit strings instead of grammar trees. Changing the coding of offspring's bit string alters the statistical information about hyperplane subpartitions that is implicitly contained in the population <ref> [8] </ref>. Theoretically, applying local optimization to improve each offspring undermines the genetic algorithm's ability to search via hyperplane sampling. The objection to local optimization is that changing information in the offspring inherited from the parents results in a loss of inherited schemata, and a loss of hyperplane information.
Reference: [9] <author> F. Gruau, </author> <title> (1992) Genetic synthesis of Boolean neural networks with a cell rewriting developmental process. In, Combination of Genetic Algorithms and Neural Networks, </title> <editor> D. Whitley and J.D. Schaffer, eds, </editor> <publisher> IEEE Computer Society Press, </publisher> <year> 1992. </year>
Reference-contexts: If the architecture is indeed complex (e.g. 500 connections or more) 9,000 evaluations is likely to be inadequate for genetic search. There are new directions being explored for optimizing neural network architectures. Grammar based architecture descriptions [12] [7] <ref> [9] </ref> [10] may display better scaling properties. By optimizing grammar trees that generate network architectures instead of directly optimizing architectures this research hopes to achieve better scalability, and in some sense, reusability of network architectures. <p> A grammar tree is used 2 which is both more compact and more flexible than direct codings or previously developed grammatical representations. This representation, called cellular encoding has been described by Gruau <ref> [9] </ref> [10]. The grammar tree is used to encode a cellular developmental process that more closely resembles biological cell division than other neural network encodings. The research presented in the current study particularly focuses on the addition of learning to the development process and the evolution of grammar trees. <p> Section 2 of this paper reviews the literature on grammar based descriptions of neural networks and also presents the details of the cellular encoding and development scheme developed by Gruau <ref> [9] </ref>. It also describes the genetic algorithm used in these experiments, and the genetic programming paradigm developed by Koza [17] which is used to generate and recombine grammar trees. <p> Unlike Kitano, Mjolness is not restricted to only using matrices of size 2 k ; it is not clear, however, what is the range of possible sizes. Also, the size of the neural networks has to be determined by hand. Gruau <ref> [9] </ref> directly develops a family of neural nets and avoids the need to go through the matrix representation. Instead of a matrix, the object on which the development rules are applied is the cell of a network. Each cell has a copy of the chromosome. <p> The subtrees which are exchanged during recombination are randomly selected. Figure 3 gives an example of cross-over. 2.2.1 A Description of the genetic algorithm Gruau <ref> [9] </ref> has designed a sequential genetic algorithm that uses local selection and mating based on a geographical lay out of individuals. Individuals reside on a 2-D grid and mate with the best chromosome found during a random walk in the neighborhood. <p> The combined effect of these mutations strategies is to explore a large number of different placements for R. Gruau <ref> [9] </ref> has shown that this approach reliably generates solutions to the parity and symmetry problems.
Reference: [10] <author> F. </author> <title> Gruau (1992) Cellular encoding of genetic neural network. </title> <type> TR 92.21, </type> <institution> Laboratoire de l'Informatique pour le Parallelisme, Ecole Normale Superieure de Lyon, </institution> <year> 1992. </year>
Reference-contexts: If the architecture is indeed complex (e.g. 500 connections or more) 9,000 evaluations is likely to be inadequate for genetic search. There are new directions being explored for optimizing neural network architectures. Grammar based architecture descriptions [12] [7] [9] <ref> [10] </ref> may display better scaling properties. By optimizing grammar trees that generate network architectures instead of directly optimizing architectures this research hopes to achieve better scalability, and in some sense, reusability of network architectures. <p> A grammar tree is used 2 which is both more compact and more flexible than direct codings or previously developed grammatical representations. This representation, called cellular encoding has been described by Gruau [9] <ref> [10] </ref>. The grammar tree is used to encode a cellular developmental process that more closely resembles biological cell division than other neural network encodings. The research presented in the current study particularly focuses on the addition of learning to the development process and the evolution of grammar trees. <p> The resulting language can describe networks in a more elegant and compact way, and the representation can be readily recombined by the genetic algorithm. Various properties of cellular encoding have been formalized and proved by Gruau <ref> [10] </ref>. Gruau used a genetic algorithm to recombine grammar trees representing cellular encodings and showed that neural networks for the parity problem and symmetry problem could be found. Furthermore, the grammar trees are recursive encodings that generate whole families of networks that compute parity or symmetry.
Reference: [11] <author> G.E. Hinton and S.J. Nowlan, </author> <title> (1987) How learning can guide evolution. </title> <journal> Complex Systems, </journal> <volume> 1 </volume> <pages> 495-502. </pages>
Reference-contexts: In this case, the effects on schemata and hyperplane sampling may be minimal. 3.1 The Baldwin Effect There are other ways that evolution and learning can interact that is not Lamarkian in nature. One method which has recently received new attention is the Baldwin effect <ref> [11] </ref> [2]. &gt;From an implementational point of view, exploitation of the Baldwin effect requires that individuals employ some form of learning, but the acquired behavior is not coded back to the genetic encoding as in Lamarkian learning. <p> The idea that learned behavior could influence evolution by creating selective pressure toward genetically encoding or genetic predisposing learned behavior was first proposed by J.M. Baldwin [3] almost a hundred years ago. Hinton and Nolan <ref> [11] </ref> offer the following simple example to illustrate the Baldwin effect. 11 Assume that the fitness landscape is flat, with a single spike representing a target solution. Also assume that individuals can recognize when they are close to a solution and can alter their behavior to exploit the target solution.
Reference: [12] <author> H. Kitano, </author> <title> (1990) Designing neural network using genetic algorithm with graph generation system. </title> <journal> Complex Systems, </journal> <volume> 4 </volume> <pages> 461-476. 23 </pages>
Reference-contexts: If the architecture is indeed complex (e.g. 500 connections or more) 9,000 evaluations is likely to be inadequate for genetic search. There are new directions being explored for optimizing neural network architectures. Grammar based architecture descriptions <ref> [12] </ref> [7] [9] [10] may display better scaling properties. By optimizing grammar trees that generate network architectures instead of directly optimizing architectures this research hopes to achieve better scalability, and in some sense, reusability of network architectures. <p> When optimizing neural network architectures we would like to develop grammatical descriptions of neural networks that have some of the properties of L-systems. In particular, the same set of rules might be used to generate an entire family of related networks. Kitano <ref> [12] </ref> uses a grammar to generate a family of matrices of size 2 k . The element of the matrix are characters in a finite alphabet. In order to develop matrix M k+1 each character of the matrix M k is replaced by a 2 fi 2 matrix.
Reference: [13] <author> H. Kitano, </author> <title> (1992) Neurogenetic Learning An Integrated Method of designing and Training Neural Networks using Genetic Algorithms. </title> <institution> Technical report CMU-CMT-92-13 Carnegie Mellon University. </institution>
Reference-contexts: Using some predefined convention allows one to deduce a connectivity matrix from each matrix M k of the family. This connectivity 3 matrix describes the architecture of a neural net. In a more recent study, Kitano <ref> [13] </ref> shows that it is also possible to deduce weight values from M k . There are certain problems with Kitano's representation scheme. An m fi m matrix must be developed for a network of n neurons, where m is the smallest power of 2 bigger than n.
Reference: [14] <author> P. Prusinkiewicz and A. Lindenmayer, </author> <title> (1992) The algorithmic beauty of plants. </title> <publisher> Springer-Verlag. </publisher>
Reference-contexts: By applying the rewrite rules of an L-system grammar in different ways, or by stochastically applying rewrite rules, one can generate surprisingly complex structures that have a remarkable resemblance to different plant structures <ref> [14] </ref>. When optimizing neural network architectures we would like to develop grammatical descriptions of neural networks that have some of the properties of L-systems. In particular, the same set of rules might be used to generate an entire family of related networks.
Reference: [15] <author> G. Miller and P. Todd and S. Hedge, </author> <title> (1989) Designing Neural Networks using Genetic Algorithm, </title> <booktitle> In, 3rd Intern. Conf. on Genetic Algorithms, </booktitle> <editor> D.J. Schaffer, ed., </editor> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: These directly coded network architectures have usually been trained using back propagation. A common fitness measurement is the training time. (Generalization would be an interesting fitness measure, but we know of no such study to date.) Miller and Todd have explored these ideas <ref> [15] </ref>, as have Belew, McInerney and Schraudolf [5]. Whit-ley, Starkweather and Bogart [20] showed that the genetic algorithm could be used to find network topologies that consistently display improved learning speeds over the typical fully connected feed forward network.
Reference: [16] <author> H. Muhlenbein, </author> <title> (1990) Limitations of multi-layer perceptrons networks steps towards genetic neural networks. </title> <journal> Parallel Computing, </journal> <volume> 14 </volume> <pages> 249-260. </pages>
Reference-contexts: problems (parity or symmetry with over 100 inputs, for example) which cannot be learned with traditional gradient based training algorithms because it is not possible to iterate over a set of training examples which would be large enough to adequately represent the function spaces associated with these problems (c.f., Muhlenbein <ref> [16] </ref>). 3 Adding learning to cellular development One way to speed up the search for functional networks is to add some form of learning to the developmental process.
Reference: [17] <author> J. R. Koza and J. P. Rice, </author> <title> (1991) Genetic generation of both the weights and architecture for a neural network. </title> <booktitle> In Intern. Joint Conf. on Neural Networks, </booktitle> <address> Seattle 92. </address>
Reference-contexts: Section 2 of this paper reviews the literature on grammar based descriptions of neural networks and also presents the details of the cellular encoding and development scheme developed by Gruau [9]. It also describes the genetic algorithm used in these experiments, and the genetic programming paradigm developed by Koza <ref> [17] </ref> which is used to generate and recombine grammar trees. Section 3 discusses the role of learning in evolution and the various forms of learning and combined learning-evolutionary search strategies to be used in these experiments. <p> Genetic Programming has been defined by Koza as a way of evolving computer programs with a genetic algorithm <ref> [17] </ref>. In Koza's Genetic Programming paradigm the individuals in the population are lisp s-expressions which can be depicted graphically as rooted, point-labeled trees with ordered branches. Since our chromosmes (grammr-trees) have exactly the same structure, the same approach is used for generating and recombing grammar trees.
Reference: [18] <editor> J.D. Schaffer and , D. Whitley and L. Eshelman, </editor> <title> (1992) Introduction, to Combination of Genetic Algorithms and Neural Networks, </title> <publisher> IEEE Computer Society, </publisher> <year> 1992. </year>
Reference-contexts: 1 Combining genetic algorithms and neural networks. There is now a relatively large number of papers that deal with various combinations of genetic algorithms and neural networks. A survey of this work is given by Schaffer, Whitley and Eshelman <ref> [18] </ref> in an introduction to the proceeding of a workshop on Combinations of Genetic algorithms and Neural Networks. Genetic Algorithms have been used to do weight training for supervised learning and for reinforcement learning applications.
Reference: [19] <author> D. Whitley, </author> <title> (1989) The genitor algorithm and selection pressure why rank based allocation of reproductive trials is best. </title> <booktitle> 3rd Intern. Conf. on Genetic Algorithms, </booktitle> <editor> D.J. Schaffer, ed., </editor> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: The resulting offspring encodes a general solution for the parity problem. isolation by distance [6], such that different local regions on the grid may display local trends in terms of evolutionary development. Individuals are deleted by using an approximation of the scheme of genitor <ref> [19] </ref>. We select randomly 50 individuals among the population, and delete the worse individual in this sample, instead of deleting the worse individual in the whole population. The population size p and the number of generations g are not fixed.
Reference: [20] <author> D. Whitley, T. Starkweather and C. Bogart, </author> <title> (1990) Genetic algorithms and neural networks: optimizing connection and connectivity. </title> <journal> Parallel Computing, </journal> <volume> 14 </volume> <pages> 347-361, </pages> <year> 1990. </year> <pages> 24 25 </pages>
Reference-contexts: A common fitness measurement is the training time. (Generalization would be an interesting fitness measure, but we know of no such study to date.) Miller and Todd have explored these ideas [15], as have Belew, McInerney and Schraudolf [5]. Whit-ley, Starkweather and Bogart <ref> [20] </ref> showed that the genetic algorithm could be used to find network topologies that consistently display improved learning speeds over the typical fully connected feed forward network.
References-found: 21

