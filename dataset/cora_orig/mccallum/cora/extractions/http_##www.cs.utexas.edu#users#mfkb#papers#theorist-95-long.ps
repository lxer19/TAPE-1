URL: http://www.cs.utexas.edu/users/mfkb/papers/theorist-95-long.ps
Refering-URL: http://www.cs.utexas.edu/users/mfkb/papers/
Root-URL: 
Email: (theorist@cs.utexas.edu) (lester@adm.csc.ncsu.edu)  
Title: Robust Natural Language Generation from Large-Scale Knowledge Bases 1  
Author: Charles B. Callaway James C. Lester 
Keyword: Content areas: Natural Language Generation, Large-Scale Knowledge Bases  
Address: Austin, TX 78712-1188 Raleigh, NC 27695-8206  
Affiliation: Department of Computer Sciences Department of Computer Science The University of Texas at Austin North Carolina State University  
Abstract: In recent years, the natural language generation community has begun to mature rapidly and produce sophisticated off-the-shelf surface realizers. A parallel development in the knowledge representation community has been the emergence of large-scale knowledge bases that house tens of thousands of facts encoded in expressive representational languages. Because of the richness of their representations and the sheer volume of their formally encoded knowledge, these knowledge bases offer the promise of significantly improving the quality of natural language generation. However, the representational complexity, scale, and task-independence of these knowledge bases pose great challenges to natural language generators. We have designed, implemented, and empirically evaluated Fare, a functional realization system that exploits message specifications drawn from large-scale knowledge bases to create functional descriptions, which are expressions that encode both functional information (case assignment) and structural information (phrasal constituent embeddings). Given a message specification, Fare exploits lexical and grammatical annotations on knowledge base objects to construct functional descriptions, which are then converted to text by a surface generator. Two empirical studies|one with an explanation generator and one with a qualitative model builder|suggest that Fare is robust, efficient, expressive, and appropriate for a broad range of applications. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D. Appelt. </author> <title> Planning english referring expressions. </title> <journal> Artificial Intelligence, </journal> <volume> 26 </volume> <pages> 1-33, </pages> <year> 1985. </year>
Reference-contexts: Although work has also been done on integrating the tasks so that decisions made at realization time can affect planning decisions <ref> [3, 1, 8] </ref>, the two-task "pipeline" model has typically been adopted by work in multi-sentential natural language generation e.g., [15, 14, 16, 17, 18].
Reference: [2] <author> A. </author> <title> Cawsey. Explanation and Interaction: The Computer Generation of Explanatory Dialogues. </title> <publisher> MIT Press, </publisher> <year> 1992. </year>
Reference-contexts: With three significant exceptions ([8], <ref> [2] </ref>, and [19]), the field of natural language generation has not witnessed the development of an "empiricist evaluation" school. However, it is clear that empirical evaluations can yield very informative data.
Reference: [3] <author> L. Danlos. </author> <title> Conceptual and linguistic decisions in generation. </title> <booktitle> In Tenth International Conference on Computational Linguistics, </booktitle> <pages> pages 501-504, </pages> <institution> Stanford University, </institution> <month> July </month> <year> 1984. </year>
Reference-contexts: Although work has also been done on integrating the tasks so that decisions made at realization time can affect planning decisions <ref> [3, 1, 8] </ref>, the two-task "pipeline" model has typically been adopted by work in multi-sentential natural language generation e.g., [15, 14, 16, 17, 18].
Reference: [4] <author> M. Elhadad. FUF: </author> <title> The universal unifier user manual version 5.0. </title> <type> Technical Report CUCS-038-91, </type> <institution> Department of Computer Science, Columbia University, </institution> <year> 1991. </year>
Reference-contexts: 1 Introduction In recent years, the field of natural language generation has begun to mature very rapidly. In addition to encouraging results in the form of specific theories and mechanisms that address particular generation phenomena, the field has witnessed the appearance of very sophisticated off-the-shelf surface realization systems <ref> [14, 4] </ref>. A parallel development in the knowledge representation community has been the emergence of large-scale knowledge bases (LSKBs) that house tens of thousands of facts encoded in expressive representational languages [20, 10]. <p> To this end, we have designed, implemented, and empirically evaluated Fare, 2 a functional realization system that exploits message specifications drawn from large-scale knowledge bases to create functional descriptions <ref> [4, 5] </ref>, which are expressions that encode both functional information (case assignment) and structural information (phrasal constituent embeddings). Given a message specification, Fare exploits lexical and grammatical annotations on knowledge base objects to construct functional descriptions, which are then converted to text by the Fuf surface generator [4, 5]. <p> create functional descriptions <ref> [4, 5] </ref>, which are expressions that encode both functional information (case assignment) and structural information (phrasal constituent embeddings). Given a message specification, Fare exploits lexical and grammatical annotations on knowledge base objects to construct functional descriptions, which are then converted to text by the Fuf surface generator [4, 5]. We have conducted these investigations in the "laboratory" provided by the Biology Knowledge Base Project. <p> Given a message specification, Fare uses its knowledge of case mappings, syntax, and lexical information to construct a functional description. Fare then passes the functional description to Fuf, a unification-based surface generator <ref> [4, 5] </ref>. Fuf is accompanied by an extensive, portable English grammar, Surge, 5 which Elhadad describes as "the result of five years of intensive experimentation in grammar writing." Fuf's grammar borrows the notions of feature structures and unification from functional unification grammars [9].
Reference: [5] <author> M. Elhadad. </author> <title> Using Argumentation to Control Lexical Choice: A Functional Unification Implementation. </title> <type> PhD thesis, </type> <institution> Columbia University, </institution> <year> 1992. </year>
Reference-contexts: To this end, we have designed, implemented, and empirically evaluated Fare, 2 a functional realization system that exploits message specifications drawn from large-scale knowledge bases to create functional descriptions <ref> [4, 5] </ref>, which are expressions that encode both functional information (case assignment) and structural information (phrasal constituent embeddings). Given a message specification, Fare exploits lexical and grammatical annotations on knowledge base objects to construct functional descriptions, which are then converted to text by the Fuf surface generator [4, 5]. <p> create functional descriptions <ref> [4, 5] </ref>, which are expressions that encode both functional information (case assignment) and structural information (phrasal constituent embeddings). Given a message specification, Fare exploits lexical and grammatical annotations on knowledge base objects to construct functional descriptions, which are then converted to text by the Fuf surface generator [4, 5]. We have conducted these investigations in the "laboratory" provided by the Biology Knowledge Base Project. <p> Given a message specification, Fare uses its knowledge of case mappings, syntax, and lexical information to construct a functional description. Fare then passes the functional description to Fuf, a unification-based surface generator <ref> [4, 5] </ref>. Fuf is accompanied by an extensive, portable English grammar, Surge, 5 which Elhadad describes as "the result of five years of intensive experimentation in grammar writing." Fuf's grammar borrows the notions of feature structures and unification from functional unification grammars [9].
Reference: [6] <author> R. P. Gabriel. </author> <title> Deliberate writing. </title> <editor> In D. D. McDonald and L. Bolc, editors, </editor> <booktitle> Natural Language Generation Systems, </booktitle> <pages> pages 1-46. </pages> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1988. </year>
Reference-contexts: from the anther to the stigma." 6 Adverbs are typically encountered as slot annotations in message specifications. 7 Note that the template is merely one of two components of FD-Skeletons; Skeletons also include semantic tests for inclusion and modification of nested functional descriptions. 6 Following in the NLG "revision" tradition <ref> [24, 15, 22, 23, 6, 12] </ref>, the third knowledge source used by the functional realizer is a library of semantic transformations.
Reference: [7] <author> M. Halliday. </author> <title> System and Function in Language. </title> <publisher> Oxford University Press, Oxford, </publisher> <year> 1976. </year>
Reference-contexts: It also incorporates the notion of systems from systemic grammars <ref> [7] </ref>. Fuf frees a functional realizer from lower-level issues such as positioning and morphological manipulation. After discussing Fare's principal knowledge sources, we describe the algorithms that guide its operation. 3.1 Knowledge Sources Fare employs three principle knowledge sources: a lexicon, a library of FD-Skeletons, and a library of semantic transformations.
Reference: [8] <author> E. Hovy. </author> <title> Pragmatics and natural language generation. </title> <journal> Artificial Intelligence, </journal> <volume> 43 </volume> <pages> 153-197, </pages> <year> 1990. </year>
Reference-contexts: Although work has also been done on integrating the tasks so that decisions made at realization time can affect planning decisions <ref> [3, 1, 8] </ref>, the two-task "pipeline" model has typically been adopted by work in multi-sentential natural language generation e.g., [15, 14, 16, 17, 18].
Reference: [9] <author> M. Kay. </author> <title> Functional grammar. </title> <booktitle> In Proceedings of the Berkeley Linguistic Society, </booktitle> <year> 1979. </year>
Reference-contexts: Fuf is accompanied by an extensive, portable English grammar, Surge, 5 which Elhadad describes as "the result of five years of intensive experimentation in grammar writing." Fuf's grammar borrows the notions of feature structures and unification from functional unification grammars <ref> [9] </ref>. It also incorporates the notion of systems from systemic grammars [7]. Fuf frees a functional realizer from lower-level issues such as positioning and morphological manipulation.
Reference: [10] <author> D. Lenat and R. Guha. </author> <title> Building Large Knowledge Based Systems. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Massachusetts, </address> <year> 1990. </year>
Reference-contexts: A parallel development in the knowledge representation community has been the emergence of large-scale knowledge bases (LSKBs) that house tens of thousands of facts encoded in expressive representational languages <ref> [20, 10] </ref>. Because of the richness of their representations and the sheer volume of their formally encoded knowledge, LSKBs offer the promise of significantly improving the quality of natural language generation. However, the representational complexity, scale, and task-independence of LSKBs pose great challenges to natural language generators.
Reference: [11] <author> J. Lester. </author> <title> Generating Natural Language Explanations from Large-Scale Knowledge Bases. </title> <type> PhD thesis, </type> <institution> The University of Texas at Austin, Austin, Texas, </institution> <year> 1994. </year>
Reference-contexts: botanical anatomy and physiology. (Its deductive closure is of course significantly larger.) To study both the robustness and range of applicability of our approach, Fare was evaluated in the context of two very different, knowledge-based systems, both of which extract structures from the Biology Knowledge Base: an explanation generator, Knight <ref> [12, 13, 11] </ref>, and a qualitative model constructor Tripel [21]. 2 Functional Realization Classically, natural language generation has been decomposed into two subtasks: planning, determining the content and organization of a text, and realization, translating the content to natural language. <p> Fare is given a message specification produced by a text planner. We have employed two text planners: an explanation generator, Knight <ref> [12, 13, 11] </ref>, and a qualitative model constructor Tripel [21] that has been "linguistically augmented." Both Knight and Tripel employ the Biology Knowledge Base [20]. <p> To this end, we conducted a formal evaluation of Fare in conjunction with an explanation generator and an informal evaluation in conjunction with a qualitative model builder. 4.1 Robustness, Efficiency, and Expressiveness First, we evaluated Fare with Knight <ref> [12, 13, 11] </ref>, a robust explanation generator that constructs explanations about scientific phenomena. It extracts structures from a large-scale knowledge base and organizes them into hierarchical discourse plans. Working in conjunction, Knight, Fare, and Fuf have produced more than a thousand different sentences.
Reference: [12] <author> J. Lester and B. Porter. </author> <title> A revision-based model of instructional multi-paragraph discourse production. </title> <booktitle> In Proceedings of the Thirteenth Cognitive Science Society Conference, </booktitle> <pages> pages 796-800, </pages> <year> 1991. </year>
Reference-contexts: botanical anatomy and physiology. (Its deductive closure is of course significantly larger.) To study both the robustness and range of applicability of our approach, Fare was evaluated in the context of two very different, knowledge-based systems, both of which extract structures from the Biology Knowledge Base: an explanation generator, Knight <ref> [12, 13, 11] </ref>, and a qualitative model constructor Tripel [21]. 2 Functional Realization Classically, natural language generation has been decomposed into two subtasks: planning, determining the content and organization of a text, and realization, translating the content to natural language. <p> Fare is given a message specification produced by a text planner. We have employed two text planners: an explanation generator, Knight <ref> [12, 13, 11] </ref>, and a qualitative model constructor Tripel [21] that has been "linguistically augmented." Both Knight and Tripel employ the Biology Knowledge Base [20]. <p> from the anther to the stigma." 6 Adverbs are typically encountered as slot annotations in message specifications. 7 Note that the template is merely one of two components of FD-Skeletons; Skeletons also include semantic tests for inclusion and modification of nested functional descriptions. 6 Following in the NLG "revision" tradition <ref> [24, 15, 22, 23, 6, 12] </ref>, the third knowledge source used by the functional realizer is a library of semantic transformations. <p> To this end, we conducted a formal evaluation of Fare in conjunction with an explanation generator and an informal evaluation in conjunction with a qualitative model builder. 4.1 Robustness, Efficiency, and Expressiveness First, we evaluated Fare with Knight <ref> [12, 13, 11] </ref>, a robust explanation generator that constructs explanations about scientific phenomena. It extracts structures from a large-scale knowledge base and organizes them into hierarchical discourse plans. Working in conjunction, Knight, Fare, and Fuf have produced more than a thousand different sentences.
Reference: [13] <author> J. Lester and B. Porter. </author> <title> A student-sensitive discourse generator for intelligent tutoring systems. </title> <booktitle> In Proceedings of the International Conference on the Learning Sciences, </booktitle> <pages> pages 298-304, </pages> <month> August </month> <year> 1991. </year>
Reference-contexts: botanical anatomy and physiology. (Its deductive closure is of course significantly larger.) To study both the robustness and range of applicability of our approach, Fare was evaluated in the context of two very different, knowledge-based systems, both of which extract structures from the Biology Knowledge Base: an explanation generator, Knight <ref> [12, 13, 11] </ref>, and a qualitative model constructor Tripel [21]. 2 Functional Realization Classically, natural language generation has been decomposed into two subtasks: planning, determining the content and organization of a text, and realization, translating the content to natural language. <p> Fare is given a message specification produced by a text planner. We have employed two text planners: an explanation generator, Knight <ref> [12, 13, 11] </ref>, and a qualitative model constructor Tripel [21] that has been "linguistically augmented." Both Knight and Tripel employ the Biology Knowledge Base [20]. <p> To this end, we conducted a formal evaluation of Fare in conjunction with an explanation generator and an informal evaluation in conjunction with a qualitative model builder. 4.1 Robustness, Efficiency, and Expressiveness First, we evaluated Fare with Knight <ref> [12, 13, 11] </ref>, a robust explanation generator that constructs explanations about scientific phenomena. It extracts structures from a large-scale knowledge base and organizes them into hierarchical discourse plans. Working in conjunction, Knight, Fare, and Fuf have produced more than a thousand different sentences.
Reference: [14] <author> W. Mann. </author> <title> An overview of the Penman text generation system. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pages 261-265, </pages> <year> 1983. </year>
Reference-contexts: 1 Introduction In recent years, the field of natural language generation has begun to mature very rapidly. In addition to encouraging results in the form of specific theories and mechanisms that address particular generation phenomena, the field has witnessed the appearance of very sophisticated off-the-shelf surface realization systems <ref> [14, 4] </ref>. A parallel development in the knowledge representation community has been the emergence of large-scale knowledge bases (LSKBs) that house tens of thousands of facts encoded in expressive representational languages [20, 10]. <p> Although work has also been done on integrating the tasks so that decisions made at realization time can affect planning decisions [3, 1, 8], the two-task "pipeline" model has typically been adopted by work in multi-sentential natural language generation e.g., <ref> [15, 14, 16, 17, 18] </ref>. Realization itself can be 2 Functional Assigner of Role Embeddings. 1 decomposed into two subtasks: functional realization, constructing functional descriptions from mes-sage specifications supplied by a planner; and surface generation, translating functional descriptions to text.
Reference: [15] <author> W. Mann and J. Moore. </author> <title> Computer generation of multiparagraph english text. </title> <journal> American Journal of Computational Linguistics, </journal> <volume> 7(1) </volume> <pages> 17-29, </pages> <year> 1981. </year>
Reference-contexts: Although work has also been done on integrating the tasks so that decisions made at realization time can affect planning decisions [3, 1, 8], the two-task "pipeline" model has typically been adopted by work in multi-sentential natural language generation e.g., <ref> [15, 14, 16, 17, 18] </ref>. Realization itself can be 2 Functional Assigner of Role Embeddings. 1 decomposed into two subtasks: functional realization, constructing functional descriptions from mes-sage specifications supplied by a planner; and surface generation, translating functional descriptions to text. <p> from the anther to the stigma." 6 Adverbs are typically encountered as slot annotations in message specifications. 7 Note that the template is merely one of two components of FD-Skeletons; Skeletons also include semantic tests for inclusion and modification of nested functional descriptions. 6 Following in the NLG "revision" tradition <ref> [24, 15, 22, 23, 6, 12] </ref>, the third knowledge source used by the functional realizer is a library of semantic transformations.
Reference: [16] <author> D. McDonald. </author> <title> Description directed control: Its implications for natural language generation. </title> <journal> Computers and Mathematics, </journal> <volume> 9(1) </volume> <pages> 111-130, </pages> <year> 1983. </year>
Reference-contexts: Although work has also been done on integrating the tasks so that decisions made at realization time can affect planning decisions [3, 1, 8], the two-task "pipeline" model has typically been adopted by work in multi-sentential natural language generation e.g., <ref> [15, 14, 16, 17, 18] </ref>. Realization itself can be 2 Functional Assigner of Role Embeddings. 1 decomposed into two subtasks: functional realization, constructing functional descriptions from mes-sage specifications supplied by a planner; and surface generation, translating functional descriptions to text.
Reference: [17] <author> K. McKeown. </author> <title> Text Generation: Using Discourse Strategies and Focus Constraints to Generate Natural Language Text. </title> <publisher> Cambridge University Press, </publisher> <year> 1985. </year>
Reference-contexts: Although work has also been done on integrating the tasks so that decisions made at realization time can affect planning decisions [3, 1, 8], the two-task "pipeline" model has typically been adopted by work in multi-sentential natural language generation e.g., <ref> [15, 14, 16, 17, 18] </ref>. Realization itself can be 2 Functional Assigner of Role Embeddings. 1 decomposed into two subtasks: functional realization, constructing functional descriptions from mes-sage specifications supplied by a planner; and surface generation, translating functional descriptions to text.
Reference: [18] <author> M. Meteer. </author> <title> The Generation Gap: The Problem of Expressibility in Text Planning. </title> <type> PhD thesis, </type> <institution> University of Massachusetts, </institution> <month> February </month> <year> 1990. </year>
Reference-contexts: Although work has also been done on integrating the tasks so that decisions made at realization time can affect planning decisions [3, 1, 8], the two-task "pipeline" model has typically been adopted by work in multi-sentential natural language generation e.g., <ref> [15, 14, 16, 17, 18] </ref>. Realization itself can be 2 Functional Assigner of Role Embeddings. 1 decomposed into two subtasks: functional realization, constructing functional descriptions from mes-sage specifications supplied by a planner; and surface generation, translating functional descriptions to text.
Reference: [19] <author> V. Mittal. </author> <title> Generating Natural Language Descriptions with Integrated Text and Examples. </title> <type> PhD thesis, </type> <institution> University of Southern California, </institution> <month> September </month> <year> 1993. </year>
Reference-contexts: With three significant exceptions ([8], [2], and <ref> [19] </ref>), the field of natural language generation has not witnessed the development of an "empiricist evaluation" school. However, it is clear that empirical evaluations can yield very informative data.
Reference: [20] <author> B. Porter, J. Lester, K. Murray, K. Pittman, A. Souther, L. Acker, and T. Jones. </author> <title> AI research in the context of a multifunctional knowledge base: The botany knowledge base project. </title> <institution> Technical Report AI Laboratory AI88-88, University of Texas at Austin, Austin, Texas, </institution> <year> 1988. </year>
Reference-contexts: A parallel development in the knowledge representation community has been the emergence of large-scale knowledge bases (LSKBs) that house tens of thousands of facts encoded in expressive representational languages <ref> [20, 10] </ref>. Because of the richness of their representations and the sheer volume of their formally encoded knowledge, LSKBs offer the promise of significantly improving the quality of natural language generation. However, the representational complexity, scale, and task-independence of LSKBs pose great challenges to natural language generators. <p> We have conducted these investigations in the "laboratory" provided by the Biology Knowledge Base Project. The result of a seven year effort, the Biology Knowledge Base <ref> [20] </ref> is an immense, task-independent representation of more than 180,000 facts about botanical anatomy and physiology. (Its deductive closure is of course significantly larger.) To study both the robustness and range of applicability of our approach, Fare was evaluated in the context of two very different, knowledge-based systems, both of which <p> Fare is given a message specification produced by a text planner. We have employed two text planners: an explanation generator, Knight [12, 13, 11], and a qualitative model constructor Tripel [21] that has been "linguistically augmented." Both Knight and Tripel employ the Biology Knowledge Base <ref> [20] </ref>. This is a large-scale knowledge base 4 Fare's implementation consists of approximately 5,000 lines of Lucid Common Lisp. 4 whose hierarchy encodes information about biological objects (representing botanical anatomy) and biological processes (representing botanical physiology and development).
Reference: [21] <author> J. Rickel and B. Porter. </author> <title> Automated modeling for answering prediction questions: Selecting the time scale and system boundary. </title> <booktitle> In Proceedings of the Twelfth National Conference on Artificial Intelligence, </booktitle> <pages> pages 1191-1198, </pages> <year> 1994. </year>
Reference-contexts: course significantly larger.) To study both the robustness and range of applicability of our approach, Fare was evaluated in the context of two very different, knowledge-based systems, both of which extract structures from the Biology Knowledge Base: an explanation generator, Knight [12, 13, 11], and a qualitative model constructor Tripel <ref> [21] </ref>. 2 Functional Realization Classically, natural language generation has been decomposed into two subtasks: planning, determining the content and organization of a text, and realization, translating the content to natural language. <p> Fare is given a message specification produced by a text planner. We have employed two text planners: an explanation generator, Knight [12, 13, 11], and a qualitative model constructor Tripel <ref> [21] </ref> that has been "linguistically augmented." Both Knight and Tripel employ the Biology Knowledge Base [20]. <p> To investigate Fare's ability to realize message specifications that were generated for a significantly different kind of application, we obtained a qualitative model constructor, Tripel <ref> [21] </ref>. In collaboration with the designer of Tripel, we modified it to produce text planning commands in addition to its simulation data. 11 Next, we extended Fare's library of Functional Description Skeletons to address the new specification types.
Reference: [22] <author> M. M. Vaughan and D. D. McDonald. </author> <title> A model of revision in natural language generation. </title> <booktitle> In Proceedings of the 24th Annual Meeting, </booktitle> <pages> pages 90-96, </pages> <institution> Columbia University, 1986. Association for Computational Linguistics. </institution>
Reference-contexts: from the anther to the stigma." 6 Adverbs are typically encountered as slot annotations in message specifications. 7 Note that the template is merely one of two components of FD-Skeletons; Skeletons also include semantic tests for inclusion and modification of nested functional descriptions. 6 Following in the NLG "revision" tradition <ref> [24, 15, 22, 23, 6, 12] </ref>, the third knowledge source used by the functional realizer is a library of semantic transformations.
Reference: [23] <author> W.-K. C. Wong and R. F. Simmons. </author> <title> A blackboard model of text production with revision. </title> <booktitle> In Proceedings of the AAAI Workshop on Text Planning and Realization, </booktitle> <address> St. Paul, Minnesota, </address> <month> August </month> <year> 1988. </year>
Reference-contexts: from the anther to the stigma." 6 Adverbs are typically encountered as slot annotations in message specifications. 7 Note that the template is merely one of two components of FD-Skeletons; Skeletons also include semantic tests for inclusion and modification of nested functional descriptions. 6 Following in the NLG "revision" tradition <ref> [24, 15, 22, 23, 6, 12] </ref>, the third knowledge source used by the functional realizer is a library of semantic transformations.
Reference: [24] <author> M. Yazdani. </author> <title> Reviewing as a component of the text generation process. </title> <editor> In G. Kempen, editor, </editor> <booktitle> Natural Language Generation, </booktitle> <pages> pages 183-190. </pages> <publisher> Martinus Nijhoff, </publisher> <address> Dordrecht, The Netherlands, </address> <year> 1987. </year>
Reference-contexts: from the anther to the stigma." 6 Adverbs are typically encountered as slot annotations in message specifications. 7 Note that the template is merely one of two components of FD-Skeletons; Skeletons also include semantic tests for inclusion and modification of nested functional descriptions. 6 Following in the NLG "revision" tradition <ref> [24, 15, 22, 23, 6, 12] </ref>, the third knowledge source used by the functional realizer is a library of semantic transformations.
References-found: 24

