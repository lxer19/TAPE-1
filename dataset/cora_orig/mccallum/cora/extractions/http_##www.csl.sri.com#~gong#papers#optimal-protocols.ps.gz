URL: http://www.csl.sri.com/~gong/papers/optimal-protocols.ps.gz
Refering-URL: http://www.csl.sri.com/~gong/papers/pubs95.html
Root-URL: 
Title: Efficient Network Authentication Protocols: Lower Bounds and Optimal Implementations  
Author: Li Gong 
Keyword: Key Words: Authentication, key distribution, protocol metrics, lower bound, optimal protocol.  
Address: 333 Ravenswood Avenue Menlo Park, California 94025 U.S.A.  
Affiliation: SRI International Computer Science Laboratory  
Note: Published in Distributed Computing, Volume 9, Number  
Email: gong@csl.sri.com  
Date: 3, 1995  
Abstract: Research in authentication protocols has focused largely on developing and analyzing protocols that are secure against certain types of attacks. There is little and only scattered discussion on protocol efficiency. This paper presents results on the lower bounds on the numbers of messages, rounds, and encryptions required for network authentication. For each proven lower bound, an authentication protocol achieving the bound is also given, thus proving that the bound is a tight bound if the given optimal protocol is secure. Moreover, we give impossibility results of obtaining protocols that are simultaneously optimal with respect to the numbers of messages and rounds. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. Abadi and R.M. Needham. </author> <title> Prudent Engineering Practice for Cryptographic Protocols. </title> <booktitle> In Proceedings of the IEEE Symposium on Research in Security and Privacy, </booktitle> <pages> pages 122-136, </pages> <address> Oakland, California, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: We need to be more specific about the "secure fashion". Although we cannot locate a formal definition for this in the literature, we can nevertheless assemble the following minimum requirements for authentication from well-known attacks and acceptable practices in designing authentication protocols (see elsewhere <ref> [1] </ref> for more references). First, for a protocol to work in practice, it has to be reasonably efficient. Thus we have Requirement 1 S and A can easily compute the session key. Here, "easy" (or "hard") means computational easy (or difficult). <p> Because session keys can be shared or broken, one should not reuse them. Thus we have Requirement 4 It is hard to cheat S or A into reusing a session key. There are more desirable requirements <ref> [1] </ref>, but those listed above are enough for our proof. It is straightforward to translate Requirements 1-4 into the following: 1. Given K and z, it is easy to compute f (K; z); 2. Without knowing K, it is hard to compute f (K; z); 3.
Reference: [2] <author> B. Bird, I. Gopal, A. Herzberg, P. Janson, S. Kutten, R. Molva, and M. Yung. </author> <title> Systematic Design of a Family of Attack-Resistant Authentication Protocols. </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> 11(5) </volume> <pages> 679-693, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: Thus an authentication protocol is sometimes also called a key distribution protocol. Current research in authentication protocols has focused largely on the security of protocols, and there is only scattered published discussion on the issue of protocol efficiency (e.g., <ref> [2, 3, 7, 9, 17, 24] </ref>). The treatment of efficiency or performance is generally given a low priority and is often rather ad hoc. <p> His result of q + 4 is consistent with our result of 5 messages here (refer to Table 2) for a single domain, i.e., when q = 1. Apart from our own earlier work [10] and some scattered arguments on whether an individual protocol is optimal in some aspects <ref> [2, 13, 17] </ref>, we are not aware of any other general study on efficiency lower bounds of authentication protocols. It was conjectured that protecting passwords from guessing attacks would make a protocol inherently more expensive.
Reference: [3] <author> A.D. Birrell. </author> <title> Secure Communications Using Remote Procedure Calls. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 3(1) </volume> <pages> 1-14, </pages> <month> February </month> <year> 1985. </year>
Reference-contexts: Thus an authentication protocol is sometimes also called a key distribution protocol. Current research in authentication protocols has focused largely on the security of protocols, and there is only scattered published discussion on the issue of protocol efficiency (e.g., <ref> [2, 3, 7, 9, 17, 24] </ref>). The treatment of efficiency or performance is generally given a low priority and is often rather ad hoc.
Reference: [4] <author> M. Burrows, M. Abadi, and R.M. Needham. </author> <title> A Logic for Authentication. </title> <type> Technical Report 39, </type> <institution> DEC System Research Center, Palo Alto, California, </institution> <month> February </month> <year> 1989. </year> <note> Revised version of Febru-ary 22, </note> <year> 1990. </year>
Reference-contexts: A temporary key whose "goodness" remains unconfirmed until it is further used is called an "uncertified key" <ref> [4, p.32] </ref>. We discuss its usage in section 4.2. 2.2 Settings There are two important setting parameters to consider. The first parameter is the mechanism each participant uses to establish the freshness of messages. Broadly speaking, there are two well-known mechanisms. <p> However, in the case of using public-key systems, letting clients be involved in choosing the keys can improve security, because S no longer has to know all the secrets. 2.3 Goals The goals of authentication have been carefully studied, and a protocol usually falls in one of two levels <ref> [4] </ref>. A protocol at the first level can be viewed as authentication only. That is, after completing the protocol, each client will have received a key in a timely or fresh message, and the client believes that the key is suitable to be shared with the other client. <p> Moreover, it is insecure to let a client use an uncertified key solely generated by another client, because attacks replaying past messages may succeed. 4 However, when both clients participate in 4 The discussion on using uncertified keys was triggered apparently by the Yahalom protocol <ref> [4, p.30] </ref>. <p> Burrows, Abadi, and Needham then suggested modifications that removed the need for the superfluous assumptions by eliminating the use of uncertified keys altogether <ref> [4] </ref>. 5 It can be arranged so that one client can certify the key with four messages and three rounds. For example, in the above message-optimal protocol, A can detect replay attacks after receiving message 4 by checking if that handshake message contains N a . <p> One topic for future work is to investigate metrics or scenarios other than those already discussed. For example, there might be a sequence of messages optimal in the sense that more and/or higher order of beliefs <ref> [4] </ref> can be achieved with the same number of messages. Minimizing interactions with the server can also be beneficial. 22 Finally, we note that the efficiency of a protocol cannot be fully characterized independently of its implementation details.
Reference: [5] <author> D.E. Denning and G.M. Sacco. </author> <title> Timestamps in Key Distribution Protocols. </title> <journal> Communications of the ACM, </journal> <volume> 24(8) </volume> <pages> 533-536, </pages> <month> August </month> <year> 1981. </year>
Reference-contexts: We discuss its usage in section 4.2. 2.2 Settings There are two important setting parameters to consider. The first parameter is the mechanism each participant uses to establish the freshness of messages. Broadly speaking, there are two well-known mechanisms. One is based on synchronized clocks <ref> [5] </ref> 1 , the other uses nonces [15]. We discuss the 1 Clock synchronization mechanisms often do not address their own security problems. See elsewhere [8] for a more detailed discussion and more references on the risks of using clocks. 3 two cases separately. <p> Case 1: TB+AO+SO Messages. The originator has to notify S of starting the protocol. After that, it takes at least two more messages for the server-distributed temporary key to reach the two clients. Thus a lower bound is three messages. The Denning-Sacco protocol <ref> [5] </ref> achieves this lower bound. Rounds. Key distribution cannot happen before S is notified by the originator, thus two rounds is a lower bound.
Reference: [6] <author> W. Diffie and M.E. Hellman. </author> <title> New Directions in Cryptography. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> IT-22(6):644-65, </volume> <month> November </month> <year> 1976. </year>
Reference-contexts: In section 4.2, we discussed the use of uncertified keys in conventional cryptosystems. Diffie-Hellman key-exchange protocols also use uncertified keys, but in public-key systems. For the two clients to exchange their independently chosen random numbers <ref> [6] </ref>, clearly two messages and two rounds are optimal. Again, this is not equivalent to the case of authentication only (AO) because the temporary key is yet uncertified. To certify the temporary key, at least one 15 more message and one more round are needed. <p> We do not consider the use of public-key algorithms, which are one-way functions by definition. 18 6.1 Necessity Proof Even though authentication protocols can be direct authentication between two parties <ref> [6] </ref> or indirect authentication via a trusted third party [15], the essence of Needham-Schroeder authentication is to arrange a secret to be shared between two parties two clients, or a client and the server. (Group-oriented authentication is a generalization of two-party authentication.) Therefore, we can define Needham-Schroeder authentication to be the
Reference: [7] <author> L. Gong. </author> <title> Using One-Way Functions for Authentication. </title> <journal> ACM Computer Communication Review, </journal> <volume> 19(5) </volume> <pages> 8-11, </pages> <month> October </month> <year> 1989. </year>
Reference-contexts: Thus an authentication protocol is sometimes also called a key distribution protocol. Current research in authentication protocols has focused largely on the security of protocols, and there is only scattered published discussion on the issue of protocol efficiency (e.g., <ref> [2, 3, 7, 9, 17, 24] </ref>). The treatment of efficiency or performance is generally given a low priority and is often rather ad hoc.
Reference: [8] <author> L. Gong. </author> <title> A Security Risk of Depending on Synchronized Clocks. </title> <journal> ACM Operating Systems Review, </journal> <volume> 26(1) </volume> <pages> 49-53, </pages> <month> January </month> <year> 1992. </year>
Reference-contexts: Broadly speaking, there are two well-known mechanisms. One is based on synchronized clocks [5] 1 , the other uses nonces [15]. We discuss the 1 Clock synchronization mechanisms often do not address their own security problems. See elsewhere <ref> [8] </ref> for a more detailed discussion and more references on the risks of using clocks. 3 two cases separately.
Reference: [9] <author> L. Gong. </author> <title> Increasing Availability and Security of an Authentication Service. </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> 11(5) </volume> <pages> 657-662, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: Thus an authentication protocol is sometimes also called a key distribution protocol. Current research in authentication protocols has focused largely on the security of protocols, and there is only scattered published discussion on the issue of protocol efficiency (e.g., <ref> [2, 3, 7, 9, 17, 24] </ref>). The treatment of efficiency or performance is generally given a low priority and is often rather ad hoc. <p> Systems in which authentication servers are not wholly trustworthy can deploy distributed authentication protocols using multiple servers where it is necessary for a majority of servers to collude in order to compromise the availability or the security of the authentication service <ref> [9] </ref>. 4 still count this as one message. A message being forwarded explicitly that is, we do not consider implicit relays, such as when a message is forwarded by a network gateway counts as a new message sent by the intermediate party. <p> The server may still impersonate clients by giving false information about a client's public key, but cannot compromise the security of a connection that has been legitimately established. Distributed authentication protocols can deal with such dishonest servers <ref> [9] </ref>. The use of public-key systems does not obscure the need for traditional cryptosystems.
Reference: [10] <author> L. Gong. </author> <title> Lower Bounds on Messages and Rounds for Network Authentication Protocols. </title> <booktitle> In Proceedings of the 1st ACM Conference on Computer and Communications Security, </booktitle> <pages> pages 26-37, </pages> <address> Fairfax, Virginia, </address> <month> November </month> <year> 1993. </year> <month> 23 </month>
Reference-contexts: His result of q + 4 is consistent with our result of 5 messages here (refer to Table 2) for a single domain, i.e., when q = 1. Apart from our own earlier work <ref> [10] </ref> and some scattered arguments on whether an individual protocol is optimal in some aspects [2, 13, 17], we are not aware of any other general study on efficiency lower bounds of authentication protocols. It was conjectured that protecting passwords from guessing attacks would make a protocol inherently more expensive. <p> We have also given a proof that keyed one-way hash functions are necessary for authentication, thus proving that the NED protocol we proposed earlier <ref> [10] </ref> is optimal in that it uses only keyed one-way hash functions and not traditional encryptions. This aspect of a protocol is orthogonal to the lower bounds on messages and rounds.
Reference: [11] <author> L. Gong. </author> <title> New Protocols for Third-Party-Based Authentication and Secure Broadcast. </title> <booktitle> In Proceedings of the 2nd ACM Conference on Computer and Communications Security, </booktitle> <pages> pages 176-183, </pages> <address> Fairfax, Virginia, </address> <month> November </month> <year> 1994. </year>
Reference-contexts: This is because it must be hard for an attacker to either compute a legitimate handshake message without knowing the session key or compute the session key from the handshake messages. 6.2 The NED protocol The following protocol is taken from an earlier conference paper <ref> [11] </ref>, and please refer to that paper for detailed security argument. Suppose the server S shares a secret K as with client A, and a secret K bs with client B. Let N s denote the S's nonce. The NED protocol without handshake is as follows. 20 1.
Reference: [12] <author> L. Gong. </author> <title> Optimal Authentication Protocols Resistant to Password Guessing Attacks. </title> <booktitle> In Proceedings of the 8th IEEE Computer Security Foundations Workshop, </booktitle> <pages> pages 24-29, </pages> <address> County Kerry, Ireland, </address> <month> June </month> <year> 1995. </year>
Reference-contexts: It was conjectured that protecting passwords from guessing attacks would make a protocol inherently more expensive. Recently, protocols have been (independently) proposed <ref> [12, 22] </ref> that protect passwords against guessing attacks while being optimal in both messages and rounds. 8 Conclusion and Future Work We have conducted a systematic study of the optimality (in terms of the numbers of messages, rounds, and encryptions) of network authentication protocols.
Reference: [13] <author> A. Kehne, J. Schonwalder, and H. Langendorfer. </author> <title> A Nonce-Based Protocol for Multiple Authentications. </title> <journal> ACM Operating Systems Review, </journal> <volume> 26(4) </volume> <pages> 84-89, </pages> <month> October </month> <year> 1992. </year>
Reference-contexts: Case 8: NB+AH+SO Messages. Compared with Case 7, at least one more message is needed to complete the two-way handshake (after both clients have received the temporary key). Thus five messages is a lower bound, which is achieved in the protocol by Kehne et al. <ref> [13] </ref>, as well as the following protocol: 1. A ! B: A; B; N a 3. S ! B: fS; B; A; K; B; N b g K bs , fS; A; A; K; B; N a g K as 5. <p> His result of q + 4 is consistent with our result of 5 messages here (refer to Table 2) for a single domain, i.e., when q = 1. Apart from our own earlier work [10] and some scattered arguments on whether an individual protocol is optimal in some aspects <ref> [2, 13, 17] </ref>, we are not aware of any other general study on efficiency lower bounds of authentication protocols. It was conjectured that protecting passwords from guessing attacks would make a protocol inherently more expensive.
Reference: [14] <author> I. Lakatos. </author> <title> Proofs and Refutations. </title> <publisher> Cambridge University Press, </publisher> <year> 1976. </year>
Reference-contexts: If an example protocol is later shown to be insecure, 3 It is always debatable as to what constitutes a proof. The essays by Lakatos <ref> [14] </ref> provide excellent philosophical, logical, and historical perspectives of theorem proving. 6 the lower bound still stands, but a new protocol would be needed to demonstrate the achievability of the lower bound.
Reference: [15] <author> R.M. Needham and M.D. Schroeder. </author> <title> Using Encryption for Authentication in Large Networks of Computers. </title> <journal> Communications of the ACM, </journal> <volume> 21(12) </volume> <pages> 993-999, </pages> <month> December </month> <year> 1978. </year>
Reference-contexts: The model of authentication taken here is the common one often found in the literature (e.g., <ref> [15] </ref>). There are three participants: two clients, denoted by A and B, and an authentication server S via which A and B agree upon a temporary key. Both conventional cryptosystems (e.g., DES [23]) and public-key systems (e.g., RSA [21]) are useful in authentication protocols [15], though as we see in Section <p> often found in the literature (e.g., <ref> [15] </ref>). There are three participants: two clients, denoted by A and B, and an authentication server S via which A and B agree upon a temporary key. Both conventional cryptosystems (e.g., DES [23]) and public-key systems (e.g., RSA [21]) are useful in authentication protocols [15], though as we see in Section 6, they are not necessary. We first concentrate on the use of conventional cryptosystems and later analyze the use of public key or mixed-key systems. Similarly, we start with mutual authentication and discuss other variations later. <p> The first parameter is the mechanism each participant uses to establish the freshness of messages. Broadly speaking, there are two well-known mechanisms. One is based on synchronized clocks [5] 1 , the other uses nonces <ref> [15] </ref>. We discuss the 1 Clock synchronization mechanisms often do not address their own security problems. See elsewhere [8] for a more detailed discussion and more references on the risks of using clocks. 3 two cases separately. <p> The B cannot receive the key earlier than in round 4, and thus cannot complete the handshake in that round. The original Needham-Schroeder protocol <ref> [15] </ref> uses five messages in five rounds, and the revised protocol [16] uses seven messages in seven rounds. Cases 9 to 12 are in Appendix A. Table 2 summarizes the proven results about lower bounds on the numbers of messages and rounds. <p> For example, after initial authentication completes and the clients share a temporary key, the clients may want to perform handshake at a later stage, or perform handshake repeatedly over a period of time <ref> [15] </ref>. Therefore, it is worthwhile to examine the cost of such independent and possibly partial handshakes with regard to the use of timestamps and nonces, without the possibility of piggybacking handshake on earlier messages. <p> This is reminiscent of one-way authentication <ref> [15] </ref>, which cannot be done with only nonces. The case for half handshake using nonces needs a bit of explanation. If the protocol initiator wants to authenticate to the other party, then three messages (and three rounds) are needed. <p> The Needham-Schroeder public-key protocol <ref> [15] </ref> uses seven messages in seven rounds. With each other's public key, the clients may wish to establish a temporary key in the style of Diffie-Hellman. In section 4.2, we discussed the use of uncertified keys in conventional cryptosystems. Diffie-Hellman key-exchange protocols also use uncertified keys, but in public-key systems. <p> We do not consider the use of public-key algorithms, which are one-way functions by definition. 18 6.1 Necessity Proof Even though authentication protocols can be direct authentication between two parties [6] or indirect authentication via a trusted third party <ref> [15] </ref>, the essence of Needham-Schroeder authentication is to arrange a secret to be shared between two parties two clients, or a client and the server. (Group-oriented authentication is a generalization of two-party authentication.) Therefore, we can define Needham-Schroeder authentication to be the following abstract problem: assuming that parties S and A
Reference: [16] <author> R.M. Needham and M.D. Schroeder. </author> <title> Authentication Revisited. </title> <journal> ACM Operating Systems Review, </journal> <volume> 21(1):7, </volume> <month> January </month> <year> 1987. </year>
Reference-contexts: Cases 3 to 6 are in Appendix A. Case 7: NB+AO+SO All cases from this point on are nonce-based. We recall the principle that each party concerned with freshness needs to choose a nonce of its own <ref> [16] </ref>. Messages. Each client has to choose a nonce and send it out, and each expects to receive a message from the server containing its nonce as well as the temporary key; therefore four messages is a lower bound. <p> The B cannot receive the key earlier than in round 4, and thus cannot complete the handshake in that round. The original Needham-Schroeder protocol [15] uses five messages in five rounds, and the revised protocol <ref> [16] </ref> uses seven messages in seven rounds. Cases 9 to 12 are in Appendix A. Table 2 summarizes the proven results about lower bounds on the numbers of messages and rounds. There, when both lower bounds can be met simultaneously, we write "x msgs and y rounds".
Reference: [17] <author> B.C. Neuman and S.G. Stubblebine. </author> <title> A Note on the Use of Timestamps as Nonces. </title> <journal> ACM Operating Systems Review, </journal> <volume> 27(2) </volume> <pages> 10-14, </pages> <month> April </month> <year> 1993. </year>
Reference-contexts: Thus an authentication protocol is sometimes also called a key distribution protocol. Current research in authentication protocols has focused largely on the security of protocols, and there is only scattered published discussion on the issue of protocol efficiency (e.g., <ref> [2, 3, 7, 9, 17, 24] </ref>). The treatment of efficiency or performance is generally given a low priority and is often rather ad hoc. <p> discussed include use of a timestamp as a nonce or for dual purposes, or the setting in which one party has the option to use a timestamp or a nonce, depending on environmental restrictions, e.g., whether it is possible to piggyback a "challenge" in a previous message, as in Kerberos <ref> [17] </ref>. The second parameter is concerned with the question of who chooses the temporary key. We consider three possibilities. One is that the server chooses the key. The second is that any one client can choose the key. The third is that both clients participate in choosing the key. <p> For example, in Kerberos if the client's initial message contains a wrong timestamp, the server rejects the request but returns a current timestamp to the client for synchronizing the clock and preparing a subsequent request <ref> [17] </ref>. 4.2 Using Uncertified Keys We now examine the case we excluded earlier: the use of uncertified keys. It does not make sense to exchange uncertified keys when all parties have synchronized clocks, since all that is necessary is to include a timestamp in the key distribution message. <p> His result of q + 4 is consistent with our result of 5 messages here (refer to Table 2) for a single domain, i.e., when q = 1. Apart from our own earlier work [10] and some scattered arguments on whether an individual protocol is optimal in some aspects <ref> [2, 13, 17] </ref>, we are not aware of any other general study on efficiency lower bounds of authentication protocols. It was conjectured that protecting passwords from guessing attacks would make a protocol inherently more expensive. <p> There are other considerations that cannot be easily abstracted. For example, approaches using timestamp or verifier-issued timestamps (as nonces) reduce the server states per-connection and thus increase performance <ref> [17] </ref>. Also, a protocol that can piggyback its last message on the opening message of a subsequent communication may yield better overall performance than another protocol that cannot piggyback, even if both protocols use the same numbers of messages and rounds.
Reference: [18] <author> B.C. Neuman and T. Ts'o. </author> <title> Kerberos: An Authentication Service for Computer Networks. </title> <journal> IEEE Communications, </journal> <volume> 32(9) </volume> <pages> 33-38, </pages> <month> September </month> <year> 1994. </year>
Reference-contexts: The last handshake message cannot be sent out before both clients have received the key. Thus a lower bound is four messages. The following protocol, as does the Kerberos protocol with the optional fourth message <ref> [18] </ref>, achieves this lower bound. 1. A ! S: A; B 3. A ! B: fS; B; A; K; B; T s g K bs , fA; B; T a g K Rounds.
Reference: [19] <author> D. Otway and O. Rees. </author> <title> Efficient and Timely Mutual Authentication. </title> <journal> ACM Operating Systems Review, </journal> <volume> 21(1) </volume> <pages> 8-10, </pages> <month> January </month> <year> 1987. </year>
Reference-contexts: Messages. Each client has to choose a nonce and send it out, and each expects to receive a message from the server containing its nonce as well as the temporary key; therefore four messages is a lower bound. A protocol in the style of the Otway-Rees protocol <ref> [19] </ref> (i.e., 2 nested RPCs) achieves this lower bound: 8 1. A ! B: A; B; N a 3. S ! B: fS; B; A; K; B; N b g K bs , fS; A; A; K; B; N a g K as Rounds.
Reference: [20] <author> B. Preneel. </author> <title> Cryptographic Hash Functions. </title> <journal> European Transactions on Telecommunications, </journal> <volume> 5(4) </volume> <pages> 431-448, </pages> <month> July-August </month> <year> 1994. </year>
Reference-contexts: The above four requirement of f () obviously makes it a keyed one-way hash function, according to the definition (called Manipulation Detection Code) given in <ref> [20] </ref>, except that there hardness is interpreted specifically to be as hard as random guessing. Thus we have proven that keyed one-way functions are necessary for authentication.
Reference: [21] <author> R.L. Rivest, A. Shamir, and L. Adleman. </author> <title> A Method for Obtaining Digital Signatures and Public-Key Cryptosystems. </title> <journal> Communications of the ACM, </journal> <volume> 21(2) </volume> <pages> 120-126, </pages> <month> February </month> <year> 1978. </year>
Reference-contexts: There are three participants: two clients, denoted by A and B, and an authentication server S via which A and B agree upon a temporary key. Both conventional cryptosystems (e.g., DES [23]) and public-key systems (e.g., RSA <ref> [21] </ref>) are useful in authentication protocols [15], though as we see in Section 6, they are not necessary. We first concentrate on the use of conventional cryptosystems and later analyze the use of public key or mixed-key systems. Similarly, we start with mutual authentication and discuss other variations later.
Reference: [22] <author> K.Y. Siu and S. Keung. </author> <title> Efficient Protocols Secure Against Guessing and Replay Attacks. </title> <booktitle> In Proceedings of the 4th International Conference on Computer Communications and Networks, </booktitle> <address> Las Vegas, Nevada, </address> <month> September </month> <year> 1995. </year>
Reference-contexts: It was conjectured that protecting passwords from guessing attacks would make a protocol inherently more expensive. Recently, protocols have been (independently) proposed <ref> [12, 22] </ref> that protect passwords against guessing attacks while being optimal in both messages and rounds. 8 Conclusion and Future Work We have conducted a systematic study of the optimality (in terms of the numbers of messages, rounds, and encryptions) of network authentication protocols.
Reference: [23] <institution> Data Encryption Standard. (U.S.) National Bureau of Standards, </institution> <month> January </month> <year> 1977. </year> <type> (U.S.) </type> <note> Federal Information Processing Standards Publication, FIPS PUB 46. </note>
Reference-contexts: The model of authentication taken here is the common one often found in the literature (e.g., [15]). There are three participants: two clients, denoted by A and B, and an authentication server S via which A and B agree upon a temporary key. Both conventional cryptosystems (e.g., DES <ref> [23] </ref>) and public-key systems (e.g., RSA [21]) are useful in authentication protocols [15], though as we see in Section 6, they are not necessary. We first concentrate on the use of conventional cryptosystems and later analyze the use of public key or mixed-key systems.

References-found: 23

