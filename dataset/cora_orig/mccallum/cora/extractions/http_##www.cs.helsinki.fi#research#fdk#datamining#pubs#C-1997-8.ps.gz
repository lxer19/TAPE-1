URL: http://www.cs.helsinki.fi/research/fdk/datamining/pubs/C-1997-8.ps.gz
Refering-URL: http://www.cs.helsinki.fi/research/pmdm/datamining/publications.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: search and borders of theories in knowledge discovery  
Author: Heikki Mannila and Hannu Toivonen 
Address: Finland  
Affiliation: University of Helsinki  
Note: Levelwise  
Abstract: Department of Computer Science Series of Publications C Report C-1997-8 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. Agrawal, T. Imielinski, and A. Swami. </author> <title> Mining association rules between sets of items in large databases. </title> <booktitle> In Proceedings of ACM SIG-MOD Conference on Management of Data (SIGMOD'93), </booktitle> <pages> pages 207 216, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: The task is to tnd the theory of r with respect to L and q, i.e., the set Th (L; r; q) = f' 2 L j q (r; ') is trueg: Example 1 Given a relation r with n rows over binary-valued attributes R, an association rule <ref> [1] </ref> is an expression of the form X ) A, where X R and A 2 R. <p> A set X R is frequent, if fr (X) exceeds the given threshold. Several algorithms for tnding frequent sets have been presented <ref> [1, 2, 11, 14, 15, 16, 31, 35, 36, 37, 38] </ref>. The problem of tnding all frequent sets can be described in our framework as follows. The description language L consists of all subsets X of elements of R.
Reference: [2] <author> R. Agrawal, H. Mannila, R. Srikant, H. Toivonen, and A. I. Verkamo. </author> <title> Fast discovery of association rules. </title> <editor> In U. M. Fayyad, G. Piatetsky-Shapiro, P. Smyth, and R. Uthurusamy, editors, </editor> <booktitle> Advances in Knowledge Discovery and Data Mining, </booktitle> <pages> pages 307 328. </pages> <publisher> AAAI Press, </publisher> <address> Menlo Park, CA, </address> <year> 1996. </year>
Reference-contexts: A set X R is frequent, if fr (X) exceeds the given threshold. Several algorithms for tnding frequent sets have been presented <ref> [1, 2, 11, 14, 15, 16, 31, 35, 36, 37, 38] </ref>. The problem of tnding all frequent sets can be described in our framework as follows. The description language L consists of all subsets X of elements of R. <p> The roots of this approach are in the use of diagrams of models in model theory (see, e.g., [5]). The approach has been used in various forms, for example in <ref> [2, 6, 7, 18, 20, 23] </ref>. One should note that in contrast with, e.g., [6], our emphasis is on very simple representation languages. Obviously, if L is intnite and q (r; ') is satisted for intnitely many sentences, (an explicit representation of) Th (L; r; q) cannot be computed. <p> The central idea is to start from the most general sentences, and then to generate and evaluate more and more special sentences, but not to evaluate those sentences that cannot be interesting given all the information obtained in earlier iterations <ref> [2] </ref>; see also [22, 30]. The method is as follows. Algorithm 3 The levelwise algorithm for tnding all potentially interesting sentences. Input: A database r, a language L with specialization relation , and a selection predicate q. Output: The set Th (L; r; q). Method: 1. <p> Note that the computation to determine the candidate collection does not involve the database (Step 5). For example, in computations of frequent sets for association rules Step 5 uses only a negligible amount of time <ref> [2] </ref>. The following lemma is immediate. Lemma 4 Assume L is a language, r is a database, q is a selection predicate, and is a specialization relation. Then Algorithm 3 computes Th (L; r; q) correctly. For Algorithm 3 to be applicable, several conditions have to be fultlled. <p> The algorithm will perform at most k + 1 iterations of the outermost loop, i.e., read the database k + 1 times, where k is the size of the largest subset X such that fr (X) exceeds the given threshold. See <ref> [2, 14, 15, 31, 36, 38] </ref> for various implementation methods. Example 6 Strong rules [33] are database rules of the form if expression then expression, where the expressions are simple conditions on attribute values. <p> Theorem 13 Algorithm 3 uses jTh (L; r; q) [ Bd (Th (L; r; q))j evaluations 12 of the selection predicate q. The proof is again immediate. Some straightforward lower bounds for the problem of tnding all frequent sets are given in <ref> [2] </ref>. Now we consider the problem of lower bounds in more realistic models of computation. The main eort in tnding the theory Th (L; r; q) is in the evaluation of predicate q against the database. Thus we consider the following model of computation.
Reference: [3] <author> S. Bell. </author> <title> Discovery and maintenance of functional dependencies by independencies. </title> <booktitle> In Proceedings of the First International Conference on Knowledge Discovery and Data Mining (KDD'95), </booktitle> <pages> pages 27 32, </pages> <address> Montreal, Canada, </address> <month> Aug. </month> <year> 1995. </year>
Reference-contexts: Such a dependency is true in the relation r, if for all pairs of rows t; u 2 r we have: if t and u have the same value for all attributes in X, they have the same value for B. For various algorithms for tnding such dependencies, see <ref> [3, 24, 25, 26, 32] </ref>. Functional dependencies with a txed right-hand side B can be found using the levelwise algorithm by considering the set of sentences fX j X Rg; and the selection predicate q: q (r; X) is true if and only if X ! B holds in r.
Reference: [4] <author> C. Berge. </author> <title> Hypergraphs. Combinatorics of Finite Sets. </title> <publisher> North-Holland Publishing Company, </publisher> <address> Amsterdam, </address> <note> 3rd edition, </note> <year> 1973. </year>
Reference-contexts: Frequent sets, functional dependencies with a txed right-hand sides, and inclusion dependencies are easily representable as sets; the same holds for (monotone) DNF or CNF formulae. A collection H of subsets of R is a (simple) hypergraph <ref> [4] </ref>, if no element of H is empty and if X; Y 2 H and X Y imply X = Y . The elements of H are called the edges of the hypergraph, and the elements of R are the vertices of the hypergraph. <p> The advantage of Theorem 22 is that there is a wealth of material known about transversals of hypergraphs (see, e.g., <ref> [4] </ref>). The relevance of transversals to computing the theory of a model has long been known in the context of tnding functional dependencies [26]; see [8] for a variety of other problems where this concept turns up.
Reference: [5] <author> C. C. Chang and H. J. Keisler. </author> <title> Model Theory. </title> <publisher> North-Holland, </publisher> <address> Amster-dam, </address> <year> 1973. </year> <note> 3rd ed., </note> <year> 1990. </year>
Reference-contexts: For some applications, q (r; ') could mean that ' is true or almost true in r, or that ' detnes (in some way) an interesting subgroup of r. The roots of this approach are in the use of diagrams of models in model theory (see, e.g., <ref> [5] </ref>). The approach has been used in various forms, for example in [2, 6, 7, 18, 20, 23]. One should note that in contrast with, e.g., [6], our emphasis is on very simple representation languages.
Reference: [6] <author> L. De Raedt and M. Bruynooghe. </author> <title> A theory of clausal discovery. </title> <booktitle> In Proceedings of the Thirteenth International Joint Conference on Artitcial 22 Intelligence (IJCAI93), </booktitle> <pages> pages 1058 1053, </pages> <address> Chambry, France, 1993. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: The roots of this approach are in the use of diagrams of models in model theory (see, e.g., [5]). The approach has been used in various forms, for example in <ref> [2, 6, 7, 18, 20, 23] </ref>. One should note that in contrast with, e.g., [6], our emphasis is on very simple representation languages. Obviously, if L is intnite and q (r; ') is satisted for intnitely many sentences, (an explicit representation of) Th (L; r; q) cannot be computed. <p> The roots of this approach are in the use of diagrams of models in model theory (see, e.g., [5]). The approach has been used in various forms, for example in [2, 6, 7, 18, 20, 23]. One should note that in contrast with, e.g., <ref> [6] </ref>, our emphasis is on very simple representation languages. Obviously, if L is intnite and q (r; ') is satisted for intnitely many sentences, (an explicit representation of) Th (L; r; q) cannot be computed. For the above formulation to make sense, the language L has to be detned carefully.
Reference: [7] <author> L. De Raedt and S. Deroski. </author> <title> First-order jk-clausal theories are PAC-learnable. </title> <journal> Artitcial Intelligence, </journal> <volume> 70:375 392, </volume> <year> 1994. </year>
Reference-contexts: The roots of this approach are in the use of diagrams of models in model theory (see, e.g., [5]). The approach has been used in various forms, for example in <ref> [2, 6, 7, 18, 20, 23] </ref>. One should note that in contrast with, e.g., [6], our emphasis is on very simple representation languages. Obviously, if L is intnite and q (r; ') is satisted for intnitely many sentences, (an explicit representation of) Th (L; r; q) cannot be computed.
Reference: [8] <author> T. Eiter and G. Gottlob. </author> <title> Identifying the minimal transversals of a hyper-graph and related problems. </title> <journal> SIAM Journal on Computing, </journal> <volume> 24(6):1278 1304, </volume> <month> Dec. </month> <year> 1995. </year>
Reference-contexts: The advantage of Theorem 22 is that there is a wealth of material known about transversals of hypergraphs (see, e.g., [4]). The relevance of transversals to computing the theory of a model has long been known in the context of tnding functional dependencies [26]; see <ref> [8] </ref> for a variety of other problems where this concept turns up. The complexity of computing the transversal of a hypergraph has long been open: see [10, 13, 29] for recent breakthroughs. 7 Concluding remarks We studied a simple levelwise algorithm for the rule discovery stage in KDD.
Reference: [9] <editor> U. M. Fayyad, G. Piatetsky-Shapiro, P. Smyth, and R. Uthurusamy, editors. </editor> <booktitle> Advances in Knowledge Discovery and Data Mining. </booktitle> <publisher> AAAI Press, </publisher> <address> Menlo Park, CA, </address> <year> 1996. </year>
Reference-contexts: There are several attractive application areas for KDD, and it seems that techniques from machine learning, statistics, and databases can be prottably combined to obtain useful methods and systems for KDD. See, e.g., <ref> [9, 34] </ref> for general descriptions of the area. The KDD area is and should be largely guided by (successful) applications. Still, theoretical work in the area is needed. In this paper we take some steps towards theoretical KDD.
Reference: [10] <author> M. L. Fredman and L. Khachiyan. </author> <title> On the complexity of dualization of monotone disjunctive normal forms. </title> <journal> Journal of Algorithms, </journal> <volume> 21(3):618 628, </volume> <month> Nov. </month> <year> 1996. </year>
Reference-contexts: The complexity of computing the transversal of a hypergraph has long been open: see <ref> [10, 13, 29] </ref> for recent breakthroughs. 7 Concluding remarks We studied a simple levelwise algorithm for the rule discovery stage in KDD. We showed that this algorithm can be applied in various domains, including association rules, frequent episodes in sequences, and integrity constraints in relational databases.
Reference: [11] <author> T. Fukuda et al. </author> <title> Mining optimized association rules for numeric attributes. </title> <booktitle> In Proceedings of the Fifteenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems (PODS'96), </booktitle> <year> 1996. </year>
Reference-contexts: A set X R is frequent, if fr (X) exceeds the given threshold. Several algorithms for tnding frequent sets have been presented <ref> [1, 2, 11, 14, 15, 16, 31, 35, 36, 37, 38] </ref>. The problem of tnding all frequent sets can be described in our framework as follows. The description language L consists of all subsets X of elements of R.
Reference: [12] <author> D. Gunopulos, R. Khardon, H. Mannila, and H. Toivonen. </author> <title> Data mining, hypergraph transversals, and machine learning. </title> <type> Manuscript, </type> <year> 1996. </year>
Reference-contexts: Perhaps the most interesting question is investigating the sample-and-correct algorithm for various applications: the results with association rules indicate that this method can be very ecient. 2 This connection has recently been strengthened <ref> [12] </ref>. 21 Acknowledgements Discussions with and comments from Willi Klsgen, Katarina Morik, Arno Siebes, and Inkeri Verkamo have been most useful. Part of this work was done while Heikki Mannila was visiting Max Planck Institut fr Informatik, Saarbrcken, Germany.
Reference: [13] <author> V. Gurvich and L. Khachiyan. </author> <title> On generating the irredundant conjunctive and disjunctive normal forms of monotone boolean functions. </title> <type> Technical Report LCSR-TR-251, </type> <institution> Rutgers University, </institution> <year> 1995. </year>
Reference-contexts: The complexity of computing the transversal of a hypergraph has long been open: see <ref> [10, 13, 29] </ref> for recent breakthroughs. 7 Concluding remarks We studied a simple levelwise algorithm for the rule discovery stage in KDD. We showed that this algorithm can be applied in various domains, including association rules, frequent episodes in sequences, and integrity constraints in relational databases.
Reference: [14] <author> J. Han and Y. Fu. </author> <title> Discovery of multiple-level association rules from large databases. </title> <booktitle> In Proceedings of the 21st International Conference on Very Large Data Bases (VLDB'95), </booktitle> <pages> pages 420 431, </pages> <address> Zurich, Swizerland, </address> <year> 1995. </year>
Reference-contexts: A set X R is frequent, if fr (X) exceeds the given threshold. Several algorithms for tnding frequent sets have been presented <ref> [1, 2, 11, 14, 15, 16, 31, 35, 36, 37, 38] </ref>. The problem of tnding all frequent sets can be described in our framework as follows. The description language L consists of all subsets X of elements of R. <p> The algorithm will perform at most k + 1 iterations of the outermost loop, i.e., read the database k + 1 times, where k is the size of the largest subset X such that fr (X) exceeds the given threshold. See <ref> [2, 14, 15, 31, 36, 38] </ref> for various implementation methods. Example 6 Strong rules [33] are database rules of the form if expression then expression, where the expressions are simple conditions on attribute values.
Reference: [15] <author> M. Holsheimer, M. Kersten, H. Mannila, and H. Toivonen. </author> <title> A perspective on databases and data mining. </title> <booktitle> In Proceedings of the First International 23 Conference on Knowledge Discovery and Data Mining (KDD'95), </booktitle> <pages> pages 150 155, </pages> <address> Montreal, Canada, </address> <month> Aug. </month> <year> 1995. </year>
Reference-contexts: A set X R is frequent, if fr (X) exceeds the given threshold. Several algorithms for tnding frequent sets have been presented <ref> [1, 2, 11, 14, 15, 16, 31, 35, 36, 37, 38] </ref>. The problem of tnding all frequent sets can be described in our framework as follows. The description language L consists of all subsets X of elements of R. <p> The algorithm will perform at most k + 1 iterations of the outermost loop, i.e., read the database k + 1 times, where k is the size of the largest subset X such that fr (X) exceeds the given threshold. See <ref> [2, 14, 15, 31, 36, 38] </ref> for various implementation methods. Example 6 Strong rules [33] are database rules of the form if expression then expression, where the expressions are simple conditions on attribute values.
Reference: [16] <author> M. Houtsma and A. Swami. </author> <title> Set-oriented mining of association rules. </title> <type> Research Report RJ 9567, </type> <institution> IBM Almaden Research Center, </institution> <address> San Jose, California, </address> <month> October </month> <year> 1993. </year>
Reference-contexts: A set X R is frequent, if fr (X) exceeds the given threshold. Several algorithms for tnding frequent sets have been presented <ref> [1, 2, 11, 14, 15, 16, 31, 35, 36, 37, 38] </ref>. The problem of tnding all frequent sets can be described in our framework as follows. The description language L consists of all subsets X of elements of R.
Reference: [17] <author> M. Kantola, H. Mannila, K.-J. Rih, and H. Siirtola. </author> <title> Discovering functional and inclusion dependencies in relational databases. </title> <journal> International Journal of Intelligent Systems, </journal> <volume> 7(7):591 607, </volume> <month> Sept. </month> <year> 1992. </year>
Reference-contexts: Such rules can be found using the above algorithm. Several choices of the specialization relation are possible, and the number of iterations in the outermost loop of the algorithm depends on that choice. Example 7 Consider the discovery of all inclusion dependencies that hold in a given database instance <ref> [17, 21, 24] </ref>. Given a database schema R, an inclusion dependency over R is an expression R [X] S [Y ], where R and S are relation schemas of R, and X and Y are equal-length sequences of attributes of R and S, respectively, that do not contain duplicates.
Reference: [18] <author> J.-U. Kietz and S. Wrobel. </author> <title> Controlling the complexity of learning in logic through syntactic and task-oriented models. </title> <editor> In S. Muggleton, editor, </editor> <booktitle> Inductive Logic Programming, </booktitle> <pages> pages 335 359. </pages> <publisher> Academic Press, </publisher> <address> London, </address> <year> 1992. </year>
Reference-contexts: The roots of this approach are in the use of diagrams of models in model theory (see, e.g., [5]). The approach has been used in various forms, for example in <ref> [2, 6, 7, 18, 20, 23] </ref>. One should note that in contrast with, e.g., [6], our emphasis is on very simple representation languages. Obviously, if L is intnite and q (r; ') is satisted for intnitely many sentences, (an explicit representation of) Th (L; r; q) cannot be computed.
Reference: [19] <author> M. Klemettinen, H. Mannila, P. Ronkainen, H. Toivonen, and A. I. Verkamo. </author> <title> Finding interesting rules from large sets of discovered association rules. </title> <booktitle> In Proceedings of the Third International Conference on Information and Knowledge Management (CIKM'94), </booktitle> <pages> pages 401 407, </pages> <address> Gaithersburg, MD, </address> <month> Nov. </month> <year> 1994. </year> <note> ACM. </note>
Reference-contexts: Recall that all sentences in Th (L; r; q) are probably not interesting to the user: Th (L; r; q) will be pruned further using, e.g., statistical signitcance or other criteria <ref> [19] </ref>. But Th (L; r; q) should not contain hundreds of thousands of useless sentences. 3 Examples Next we look at the applicability of the algorithm by considering some ex amples of KDD problems. 5 Example 5 For association rules, the specialization relation was already given above.
Reference: [20] <author> W. Kloesgen. </author> <title> Ecient discovery of interesting statements in databases. </title> <journal> Journal of Intelligent Information Systems, </journal> <volume> 4(1):53 69, </volume> <year> 1995. </year>
Reference-contexts: The roots of this approach are in the use of diagrams of models in model theory (see, e.g., [5]). The approach has been used in various forms, for example in <ref> [2, 6, 7, 18, 20, 23] </ref>. One should note that in contrast with, e.g., [6], our emphasis is on very simple representation languages. Obviously, if L is intnite and q (r; ') is satisted for intnitely many sentences, (an explicit representation of) Th (L; r; q) cannot be computed.
Reference: [21] <author> A. J. Knobbe and P. W. Adriaans. </author> <title> Discovering foreign key relations in relational databases. </title> <booktitle> In Cybernetics and Systems, Volume II, The Thirteenth European Meeting on Cybernetics and Systems Research, </booktitle> <pages> pages 961 966, </pages> <address> Vienna, Austria, </address> <month> Apr. </month> <year> 1996. </year>
Reference-contexts: Such rules can be found using the above algorithm. Several choices of the specialization relation are possible, and the number of iterations in the outermost loop of the algorithm depends on that choice. Example 7 Consider the discovery of all inclusion dependencies that hold in a given database instance <ref> [17, 21, 24] </ref>. Given a database schema R, an inclusion dependency over R is an expression R [X] S [Y ], where R and S are relation schemas of R, and X and Y are equal-length sequences of attributes of R and S, respectively, that do not contain duplicates.
Reference: [22] <author> P. Langley. </author> <title> Elements of Machine Learning. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1996. </year> <month> 24 </month>
Reference-contexts: For the above formulation to make sense, the language L has to be detned carefully. In this paper we analyze a simple levelwise algorithm for computing the collection Th (L; r; q). As already done by Mitchell [30], we use a specialization/generalization relation between sentences. (See, e.g., <ref> [22] </ref> for an overview of approaches to related problems.) A specialization relation is a partial order on the sentences in L. We say that ' is more general than , if ' ; we also say that is more specitc than '. <p> The central idea is to start from the most general sentences, and then to generate and evaluate more and more special sentences, but not to evaluate those sentences that cannot be interesting given all the information obtained in earlier iterations [2]; see also <ref> [22, 30] </ref>. The method is as follows. Algorithm 3 The levelwise algorithm for tnding all potentially interesting sentences. Input: A database r, a language L with specialization relation , and a selection predicate q. Output: The set Th (L; r; q). Method: 1.
Reference: [23] <author> H. Mannila and K.-J. Rih. </author> <title> Design by example: An application of Arm--strong relations. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 33(2):126 141, </volume> <year> 1986. </year>
Reference-contexts: The roots of this approach are in the use of diagrams of models in model theory (see, e.g., [5]). The approach has been used in various forms, for example in <ref> [2, 6, 7, 18, 20, 23] </ref>. One should note that in contrast with, e.g., [6], our emphasis is on very simple representation languages. Obviously, if L is intnite and q (r; ') is satisted for intnitely many sentences, (an explicit representation of) Th (L; r; q) cannot be computed.
Reference: [24] <author> H. Mannila and K.-J. Rih. </author> <title> Design of Relational Databases. </title> <publisher> Addison-Wesley Publishing Company, </publisher> <address> Wokingham, UK, </address> <year> 1992. </year>
Reference-contexts: Such rules can be found using the above algorithm. Several choices of the specialization relation are possible, and the number of iterations in the outermost loop of the algorithm depends on that choice. Example 7 Consider the discovery of all inclusion dependencies that hold in a given database instance <ref> [17, 21, 24] </ref>. Given a database schema R, an inclusion dependency over R is an expression R [X] S [Y ], where R and S are relation schemas of R, and X and Y are equal-length sequences of attributes of R and S, respectively, that do not contain duplicates. <p> Such a dependency is true in the relation r, if for all pairs of rows t; u 2 r we have: if t and u have the same value for all attributes in X, they have the same value for B. For various algorithms for tnding such dependencies, see <ref> [3, 24, 25, 26, 32] </ref>. Functional dependencies with a txed right-hand side B can be found using the levelwise algorithm by considering the set of sentences fX j X Rg; and the selection predicate q: q (r; X) is true if and only if X ! B holds in r. <p> We prove later that jBd (Th (L; r; q))j queries are necessary already for the veritcation of the result. This result gives as a corollary a result about tnding functional dependencies that in the more specitc setting was not easy to tnd <ref> [24, 25] </ref>. For simplicity, we present the result here for the case of tnding keys of a relation. Given a relation r over schema R, a key of r is a subset X of R such that no two rows agree on X.
Reference: [25] <author> H. Mannila and K.-J. Rih. </author> <title> On the complexity of dependency inference. </title> <journal> Discrete Applied Mathematics, </journal> <volume> 40:237 243, </volume> <year> 1992. </year>
Reference-contexts: Such a dependency is true in the relation r, if for all pairs of rows t; u 2 r we have: if t and u have the same value for all attributes in X, they have the same value for B. For various algorithms for tnding such dependencies, see <ref> [3, 24, 25, 26, 32] </ref>. Functional dependencies with a txed right-hand side B can be found using the levelwise algorithm by considering the set of sentences fX j X Rg; and the selection predicate q: q (r; X) is true if and only if X ! B holds in r. <p> We prove later that jBd (Th (L; r; q))j queries are necessary already for the veritcation of the result. This result gives as a corollary a result about tnding functional dependencies that in the more specitc setting was not easy to tnd <ref> [24, 25] </ref>. For simplicity, we present the result here for the case of tnding keys of a relation. Given a relation r over schema R, a key of r is a subset X of R such that no two rows agree on X.
Reference: [26] <author> H. Mannila and K.-J. Rih. </author> <title> Algorithms for inferring functional dependencies. </title> <journal> Data & Knowledge Engineering, </journal> <volume> 12(1):83 99, </volume> <month> Feb. </month> <year> 1994. </year>
Reference-contexts: Such a dependency is true in the relation r, if for all pairs of rows t; u 2 r we have: if t and u have the same value for all attributes in X, they have the same value for B. For various algorithms for tnding such dependencies, see <ref> [3, 24, 25, 26, 32] </ref>. Functional dependencies with a txed right-hand side B can be found using the levelwise algorithm by considering the set of sentences fX j X Rg; and the selection predicate q: q (r; X) is true if and only if X ! B holds in r. <p> The advantage of Theorem 22 is that there is a wealth of material known about transversals of hypergraphs (see, e.g., [4]). The relevance of transversals to computing the theory of a model has long been known in the context of tnding functional dependencies <ref> [26] </ref>; see [8] for a variety of other problems where this concept turns up. The complexity of computing the transversal of a hypergraph has long been open: see [10, 13, 29] for recent breakthroughs. 7 Concluding remarks We studied a simple levelwise algorithm for the rule discovery stage in KDD.
Reference: [27] <author> H. Mannila and H. Toivonen. </author> <title> Discovering generalized episodes using minimal occurrences. </title> <booktitle> In Proceedings of the Second International Conference on Knowledge Discovery and Data Mining (KDD'96), </booktitle> <pages> pages 146 151, </pages> <address> Portland, Oregon, Aug. 1996. </address> <publisher> AAAI Press. </publisher>
Reference-contexts: Example 8 Consider the problem of recognizing frequent episodes in sequences of events <ref> [27, 28] </ref>. An episode is a collection of events that occur within a time interval of a given size in a given partial order. Once such episodes are known, one can also produce rules for describing or predicting the behavior of the sequence.
Reference: [28] <author> H. Mannila, H. Toivonen, and A. I. Verkamo. </author> <title> Discovering frequent episodes in sequences. </title> <booktitle> In Proceedings of the First International Conference on Knowledge Discovery and Data Mining (KDD'95), </booktitle> <pages> pages 210 215, </pages> <address> Montreal, Canada, </address> <month> Aug. </month> <year> 1995. </year>
Reference-contexts: Example 8 Consider the problem of recognizing frequent episodes in sequences of events <ref> [27, 28] </ref>. An episode is a collection of events that occur within a time interval of a given size in a given partial order. Once such episodes are known, one can also produce rules for describing or predicting the behavior of the sequence.
Reference: [29] <author> N. Mishra and L. Pitt. </author> <title> On bounded-degree hypergraph transversal. </title> <type> Manuscript, </type> <year> 1995. </year>
Reference-contexts: The complexity of computing the transversal of a hypergraph has long been open: see <ref> [10, 13, 29] </ref> for recent breakthroughs. 7 Concluding remarks We studied a simple levelwise algorithm for the rule discovery stage in KDD. We showed that this algorithm can be applied in various domains, including association rules, frequent episodes in sequences, and integrity constraints in relational databases.
Reference: [30] <author> T. M. Mitchell. </author> <title> Generalization as search. </title> <journal> Artitcial Intelligence, </journal> <volume> 18:203 226, </volume> <year> 1982. </year>
Reference-contexts: For the above formulation to make sense, the language L has to be detned carefully. In this paper we analyze a simple levelwise algorithm for computing the collection Th (L; r; q). As already done by Mitchell <ref> [30] </ref>, we use a specialization/generalization relation between sentences. (See, e.g., [22] for an overview of approaches to related problems.) A specialization relation is a partial order on the sentences in L. <p> The central idea is to start from the most general sentences, and then to generate and evaluate more and more special sentences, but not to evaluate those sentences that cannot be interesting given all the information obtained in earlier iterations [2]; see also <ref> [22, 30] </ref>. The method is as follows. Algorithm 3 The levelwise algorithm for tnding all potentially interesting sentences. Input: A database r, a language L with specialization relation , and a selection predicate q. Output: The set Th (L; r; q). Method: 1. <p> Consider, e.g., the negative border: no pattern such that ' for some ' in the negative border is in S, while all other patterns are in S. 1 I.e., the positive border corresponds to the set denoted by S in <ref> [30] </ref>. 9 A theory Th (L; r; q) is always closed downwards with respect to a spe-cialization relation, and the concept of border can be applied on the set of all patterns that satisfy q.
Reference: [31] <author> J. S. Park, M.-S. Chen, and P. S. Yu. </author> <title> An eective hash-based algorithm for mining association rules. </title> <booktitle> In Proceedings of ACM SIGMOD Conference on Management of Data (SIGMOD'95), </booktitle> <pages> pages 175 186, </pages> <address> San Jose, California, </address> <month> May </month> <year> 1995. </year>
Reference-contexts: A set X R is frequent, if fr (X) exceeds the given threshold. Several algorithms for tnding frequent sets have been presented <ref> [1, 2, 11, 14, 15, 16, 31, 35, 36, 37, 38] </ref>. The problem of tnding all frequent sets can be described in our framework as follows. The description language L consists of all subsets X of elements of R. <p> The algorithm will perform at most k + 1 iterations of the outermost loop, i.e., read the database k + 1 times, where k is the size of the largest subset X such that fr (X) exceeds the given threshold. See <ref> [2, 14, 15, 31, 36, 38] </ref> for various implementation methods. Example 6 Strong rules [33] are database rules of the form if expression then expression, where the expressions are simple conditions on attribute values.
Reference: [32] <author> B. Pfahringer and S. Kramer. </author> <title> Compression-based evaluation of partial determinations. </title> <booktitle> In Proceedings of the First International Conference 25 on Knowledge Discovery and Data Mining (KDD'95), </booktitle> <pages> pages 234 239, </pages> <address> Montreal, Canada, </address> <month> Aug. </month> <year> 1995. </year>
Reference-contexts: Such a dependency is true in the relation r, if for all pairs of rows t; u 2 r we have: if t and u have the same value for all attributes in X, they have the same value for B. For various algorithms for tnding such dependencies, see <ref> [3, 24, 25, 26, 32] </ref>. Functional dependencies with a txed right-hand side B can be found using the levelwise algorithm by considering the set of sentences fX j X Rg; and the selection predicate q: q (r; X) is true if and only if X ! B holds in r.
Reference: [33] <author> G. Piatetsky-Shapiro. </author> <title> Discovery, analysis, and presentation of strong rules. </title> <editor> In G. Piatetsky-Shapiro and W. J. Frawley, editors, </editor> <booktitle> Knowledge Discovery in Databases, </booktitle> <pages> pages 229 248. </pages> <publisher> AAAI Press, </publisher> <address> Menlo Park, CA, </address> <year> 1991. </year>
Reference-contexts: See [2, 14, 15, 31, 36, 38] for various implementation methods. Example 6 Strong rules <ref> [33] </ref> are database rules of the form if expression then expression, where the expressions are simple conditions on attribute values.
Reference: [34] <editor> G. Piatetsky-Shapiro and W. J. Frawley, editors. </editor> <title> Knowledge Discovery in Databases. </title> <publisher> AAAI Press, </publisher> <address> Menlo Park, CA, </address> <year> 1991. </year>
Reference-contexts: There are several attractive application areas for KDD, and it seems that techniques from machine learning, statistics, and databases can be prottably combined to obtain useful methods and systems for KDD. See, e.g., <ref> [9, 34] </ref> for general descriptions of the area. The KDD area is and should be largely guided by (successful) applications. Still, theoretical work in the area is needed. In this paper we take some steps towards theoretical KDD.
Reference: [35] <author> A. Savasere, E. Omiecinski, and S. Navathe. </author> <title> An ecient algorithm for mining association rules in large databases. </title> <booktitle> In Proceedings of the 21st International Conference on Very Large Data Bases (VLDB'95), </booktitle> <pages> pages 432 444, </pages> <address> Zurich, Swizerland, </address> <year> 1995. </year>
Reference-contexts: A set X R is frequent, if fr (X) exceeds the given threshold. Several algorithms for tnding frequent sets have been presented <ref> [1, 2, 11, 14, 15, 16, 31, 35, 36, 37, 38] </ref>. The problem of tnding all frequent sets can be described in our framework as follows. The description language L consists of all subsets X of elements of R. <p> Applied to association rules this method produces extremely good results [38]. Basically, with a high probability one can discover the association rules holding in a database using only a single pass through the database. Another method for computing an initial approximation can be derived from the algorithm of <ref> [35] </ref>. The idea is to divide r into small datasets r i which can be handled in main memory, and to compute S i = Th (L; r i ; q).
Reference: [36] <author> R. Srikant and R. Agrawal. </author> <title> Mining generalized association rules. </title> <booktitle> In Proceedings of the 21st International Conference on Very Large Data Bases (VLDB'95), </booktitle> <pages> pages 407 419, </pages> <address> Zurich, Swizerland, </address> <year> 1995. </year>
Reference-contexts: A set X R is frequent, if fr (X) exceeds the given threshold. Several algorithms for tnding frequent sets have been presented <ref> [1, 2, 11, 14, 15, 16, 31, 35, 36, 37, 38] </ref>. The problem of tnding all frequent sets can be described in our framework as follows. The description language L consists of all subsets X of elements of R. <p> The algorithm will perform at most k + 1 iterations of the outermost loop, i.e., read the database k + 1 times, where k is the size of the largest subset X such that fr (X) exceeds the given threshold. See <ref> [2, 14, 15, 31, 36, 38] </ref> for various implementation methods. Example 6 Strong rules [33] are database rules of the form if expression then expression, where the expressions are simple conditions on attribute values.
Reference: [37] <author> R. Srikant and R. Agrawal. </author> <title> Mining quantitative association rules in large relational tables. </title> <booktitle> In Proceedings of ACM SIGMOD Conference on Management of Data (SIGMOD'96), </booktitle> <pages> pages 112, </pages> <address> Montreal, Canada, </address> <year> 1996. </year>
Reference-contexts: A set X R is frequent, if fr (X) exceeds the given threshold. Several algorithms for tnding frequent sets have been presented <ref> [1, 2, 11, 14, 15, 16, 31, 35, 36, 37, 38] </ref>. The problem of tnding all frequent sets can be described in our framework as follows. The description language L consists of all subsets X of elements of R.
Reference: [38] <author> H. Toivonen. </author> <title> Sampling large databases for association rules. </title> <booktitle> In Proceedings of the 22nd International Conference on Very Large Data Bases (VLDB'96), </booktitle> <pages> pages 134 145, </pages> <address> Mumbay, India, Sept. 1996. </address> <publisher> Morgan Kaufmann. </publisher> <pages> 26 </pages>
Reference-contexts: A set X R is frequent, if fr (X) exceeds the given threshold. Several algorithms for tnding frequent sets have been presented <ref> [1, 2, 11, 14, 15, 16, 31, 35, 36, 37, 38] </ref>. The problem of tnding all frequent sets can be described in our framework as follows. The description language L consists of all subsets X of elements of R. <p> The algorithm will perform at most k + 1 iterations of the outermost loop, i.e., read the database k + 1 times, where k is the size of the largest subset X such that fr (X) exceeds the given threshold. See <ref> [2, 14, 15, 31, 36, 38] </ref> for various implementation methods. Example 6 Strong rules [33] are database rules of the form if expression then expression, where the expressions are simple conditions on attribute values. <p> How to obtain good original guesses S? One fairly widely applicable method is sampling. Take a small sample s from r, compute Th (L; s; q) and use it as S. Applied to association rules this method produces extremely good results <ref> [38] </ref>. Basically, with a high probability one can discover the association rules holding in a database using only a single pass through the database. Another method for computing an initial approximation can be derived from the algorithm of [35].
References-found: 38

