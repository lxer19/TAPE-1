URL: http://www.cs.twsu.edu/~haynes/random.ps
Refering-URL: http://adept.cs.twsu.edu/~thomas/publications.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: E-mail: haynes@cs.twsu.edu  
Title: A Comparison of Random Search versus Genetic Programming as Engines for Collective Adaptation  
Author: Thomas Haynes 
Address: Wichita, KS 67260  
Affiliation: Department of Computer Science Wichita State University  
Abstract: We have integrated the distributed search of genetic programming (GP) based systems with collective memory to form a collective adaptation search method. Such a system significantly improves search as problem complexity is increased. Since the pure GP approach does not scale well with problem complexity, a natural question is which of the two components is actually contributing to the search process. We investigate a collective memory search which utilizes a random search engine and find that it significantly outperforms the GP based search engine. We examine the solution space and show that as problem complexity and search space grow, a collective adaptive system will perform better than a collective memory search employing random search as an engine.
Abstract-found: 1
Intro-found: 1
Reference: [ Bron and Kerbosch, 1973 ] <author> Coen Bron and Joep Kerbosch. </author> <title> Finding all cliques of an undi-rected graph. </title> <journal> Communications of the ACM, </journal> <volume> 16(9) </volume> <pages> 575-577, </pages> <year> 1973. </year>
Reference-contexts: Given a graph G = (V; E), a clique of G is a complete subgraph of G. A clique is denoted by the set of vertices in the complete subgraph and the goal of clique covering is to find all cliques of G <ref> [ Bron and Kerbosch, 1973 ] </ref> . Since the subgraph of G induced by any subset of the vertices of a complete subgraph of G is also complete, it is sufficient to find all maximal complete subgraphs of G. A maximal complete subgraph of G is a maximal clique. <p> While the duplication of coding segments repair process is able to search such graphs, the plain GP system will prematurely converge. We now examine the hamming6-4.clq dataset from the DIMACS repository, which has 64 nodes, 704 edges, and a maximum clique size of 4. From the Bron-Kerbosch algorithm <ref> [ Bron and Kerbosch, 1973 ] </ref> , we know that there are 464 cliques, with a maximum fitness of 1,597,424.
Reference: [ Haynes et al., 1996 ] <author> Thomas Haynes, Dale Schoenefeld, and Roger Wainwright. </author> <title> Type inheritance in strongly typed genetic programming. </title> <editor> In Kenneth E. Kinnear, Jr. and Peter J. Angeline, editors, </editor> <booktitle> Advances in Genetic Programming 2, chapter 18. </booktitle> <publisher> MIT Press, </publisher> <year> 1996. </year>
Reference-contexts: The function and terminal sets are F = fExtCon, IntCong and T = f1,. . . ,#verticesg. ExtCon "separates" two candidate maximal cliques, while IntCon "joins" two candidate cliques to create a larger candidate. (Strong typing [ Montana, 1995 ] and type inheritance <ref> [ Haynes et al., 1996 ] </ref> are used to ensure the parent of an ExtCon node is either the root or another ExtCon node.) The fitness evaluation rewards for clique size and rewards for the number of cliques in the tree.
Reference: [ Haynes, 1996 ] <author> Thomas Haynes. </author> <title> Duplication of coding segments in genetic programming. </title> <booktitle> In Proceedings of the Thirteenth National Conference on Artificial Intelligence, </booktitle> <address> Portland, OR, </address> <month> August </month> <year> 1996. </year>
Reference-contexts: The example graph exhibits nice regularities which allows for the efficient comparison of results across different test runs. These regularities have been utilized to identify and enumerate the building blocks, i.e., the connected components <ref> [ Haynes, 1996 ] </ref> . Chromosomes 4 were repaired by stripping out all invalid candidate cliques. Various rates of return of repaired chromosomes into the population were investigated and it was found that by duplicating the coding segments the search process could be significantly improved 1 .
Reference: [ Haynes, 1997 ] <author> Thomas Haynes. </author> <title> Collective memory search. </title> <booktitle> In Proceedings of the 1997 ACM Symposium on Applied Computing. </booktitle> <publisher> ACM Press, </publisher> <year> 1997. </year>
Reference-contexts: The evaluation of one chromosome is independent of all others. It has been shown that collective adaptation, which is the addition of collective memory to a GP-based learning system, significantly improves the search process as problem complexity is increased <ref> [ Haynes, 1997 ] </ref> . We believe that this improvement is a direct result of the change of focus from strict competition to cooperation. <p> We found that such a repair strategy led to premature convergence in a non-optimal section of the search space. If we instead adopt a collective adaptation technique in this domain, the search process is greatly facilitated <ref> [ Haynes, 1997 ] </ref> . With the collective adaptation we do not repair chromosomes which have no valid candidate cliques. Instead the chromosomes gather candidate cliques into the collective memory and the process agent removes duplicates and candidates subsumed by larger candidates. <p> Instead the chromosomes gather candidate cliques into the collective memory and the process agent removes duplicates and candidates subsumed by larger candidates. The addition of collective adaptation to the search technique significantly improves the efficiency of the search process <ref> [ Haynes, 1997 ] </ref> . We want to leverage that improvement to allow clique cover in more realistic graphs. The simple graphs we use to illustrate the clique cover are contrived and thus facilitate the search process, i.e., a known optimal solution exists.
Reference: [ Holland, 1975 ] <author> John H. Holland. </author> <booktitle> Adpatation in Natural and Artificial Systems. </booktitle> <publisher> University of Michigan Press, </publisher> <address> Ann Arbor, MI, </address> <year> 1975. </year> <month> 11 </month>
Reference-contexts: 1 Introduction Genetic algorithms (GA) <ref> [ Holland, 1975 ] </ref> are a class of parallel search algorithms inspired by biological evolutionary adaptation. Genetic programming (GP) [ Koza, 1992 ] is an offshoot of the GA and is used in the automatic induction of programs. Both GA and GP represent search strategies in a population of chromosomes. <p> Also, the GP can effectively utilize C 7 to search for all candidate cliques of size 8 for which C 7 forms a core set of nodes. With random search, this potential to exploit exploration is lost. The belief in emergent selection and the schema theorem <ref> [ Holland, 1975 ] </ref> , i.e., the building over time of the solution piece by piece from the elementary blocks, shields us from the fact that for cliques of maximum size 4 and parse trees of maximum depth 10, random search will effectively generate candidate cliques.
Reference: [ Johnson and Trick, 1996 ] <editor> David S. Johnson and Michael A. Trick, editors. </editor> <title> Cliques, Color--ing, and Satisfiability, </title> <booktitle> volume 26 of DIMACS: Series in Discrete Mathematics and Theoretical Computer Science. </booktitle> <publisher> American Mathematical Society, </publisher> <year> 1996. </year>
Reference-contexts: The search for the optimal solution for this graph is not trivial for GP systems which do not employ collective memory. In the Second DIMACS Challenge <ref> [ Johnson and Trick, 1996 ] </ref> random graphs were generated as tests for the maximum clique problem 2 (ftp://dimacs.rutgers.edu/pub/challenge). While the duplication of coding segments repair process is able to search such graphs, the plain GP system will prematurely converge.
Reference: [ Koza, 1992 ] <author> John R. Koza. </author> <title> Genetic Programming: On the Programming of Computers by Natural Selection. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1992. </year>
Reference-contexts: 1 Introduction Genetic algorithms (GA) [ Holland, 1975 ] are a class of parallel search algorithms inspired by biological evolutionary adaptation. Genetic programming (GP) <ref> [ Koza, 1992 ] </ref> is an offshoot of the GA and is used in the automatic induction of programs. Both GA and GP represent search strategies in a population of chromosomes. <p> We then validate our argument by experimenting with a more difficult search space. 2 Genetic Programming Genetic programming is a machine learning technique used in the automatic induction of computer programs <ref> [ Koza, 1992 ] </ref> . A GP system is primarily comprised of three main parts: * a population of chromosomes * a chromosome evaluator * a selection and recombination mechanism.
Reference: [ Montana, 1995 ] <author> David J. Montana. </author> <title> Strongly typed genetic programming. </title> <journal> Evolutionary Computation, </journal> <volume> 3(2) </volume> <pages> 199-230, </pages> <year> 1995. </year> <month> 12 </month>
Reference-contexts: Each chromosome in a GP pool represents sets of candidate maximal cliques. The function and terminal sets are F = fExtCon, IntCong and T = f1,. . . ,#verticesg. ExtCon "separates" two candidate maximal cliques, while IntCon "joins" two candidate cliques to create a larger candidate. (Strong typing <ref> [ Montana, 1995 ] </ref> and type inheritance [ Haynes et al., 1996 ] are used to ensure the parent of an ExtCon node is either the root or another ExtCon node.) The fitness evaluation rewards for clique size and rewards for the number of cliques in the tree.
References-found: 8

