URL: ftp://ftp.ics.uci.edu/pub/machine-learning-papers/others/Domingos-TR94-RISE.ps.Z
Refering-URL: http://www.ics.uci.edu/AI/ML/MLAbstracts.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Abstract: Design and Evaluation of the RISE 1.0 Learning System Pedro Domingos pedrod@ics.uci.edu Technical Report 94-34 August 30, 1994 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D. W. Aha, D. Kibler, and M. K. Albert. </author> <title> Instance-based learning algorithms. </title> <journal> Machine Learning, </journal> <volume> 6 </volume> <pages> 37-66, </pages> <year> 1991. </year>
Reference-contexts: Antecedents of both types can take on the special value fl, which stands for "any," i.e. for a disjunction of all possible values in the case of a nominal attribute, or the range <ref> [1; 1] </ref> in the case of a numeric one. Setting an attribute's value to fl is equivalent to dropping it. <p> p (r) is the number of examples covered by the rule whose con-sequents are identical to the rule's ("positive" examples) , n (r) is the number of examples covered by the rule whose consequents are different from the rule's ("negative" ones), S is the sample (training set) size, and 2 <ref> [0; 1] </ref> is a noise tolerance coefficient. The idea behind is that in noisier domains rules should be allowed to cover a greater proportion of negative examples; in noiseless domains this proportion should be 0. <p> Perfect match is the special case where the highest match score is equal to the number of attributes. This is easily implemented and may improve accuracy, as well as forming a bridge to instance-based (IBL) algorithms <ref> [1] </ref>: with appropriate match metrics and voting weights, Rise will act like an IBL algorithm when the voting rules are ungeneralized examples. 4 With the current version of Rise and the domains used so far, however, no-match situations are extremely rare, so this feature has little or no impact on the
Reference: [2] <author> W. Buntine and T. Niblett. </author> <title> A further comparison of splitting rules for decision tree induction. </title> <journal> Machine Learning, </journal> <volume> 8 </volume> <pages> 75-86, </pages> <year> 1992. </year> <month> 11 </month>
Reference-contexts: The voting domain was tried in two forms: with and without the "physician fee freeze" attribute. Remov 8 50 60 70 80 90 100 Accuracy (%) No. examples RISE CN2 EABC, with 5 irrelevant attributes. ing this attribute causes the difficulty of the domain to increase substantially <ref> [2, 5] </ref>, making possible an evaluation of performance variation with difficulty while holding other factors constant. Ten-fold cross-validation was performed for Rise and CN2, using the same training and test sets for the two at each step.
Reference: [3] <author> P. Clark and R. Boswell. </author> <title> Rule induction with CN2: Some recent improvements. </title> <booktitle> In Proc. EWSL-91, </booktitle> <pages> pages 151-163, </pages> <year> 1991. </year>
Reference-contexts: CN2 [4] was chosen for this purpose because it is probably the most extensively evaluated noise-tolerant algorithm of this type. A recent, enhanced version was used <ref> [3] </ref>. All options were set so as to maximize similarity to Rise: unordered rules, star size 1, and 0 significance threshold. Results in [3] indicate that induction and use of unordered rules tend to significantly increase performance over decision lists. <p> CN2 [4] was chosen for this purpose because it is probably the most extensively evaluated noise-tolerant algorithm of this type. A recent, enhanced version was used <ref> [3] </ref>. All options were set so as to maximize similarity to Rise: unordered rules, star size 1, and 0 significance threshold. Results in [3] indicate that induction and use of unordered rules tend to significantly increase performance over decision lists. <p> In the new version of CN2 a significance threshold of 0 tends to produce the highest accuracies. Laplacian accuracy was chosen as the heuristic, since it is the one that yields the best results <ref> [3] </ref>.
Reference: [4] <author> P. Clark and T. Niblett. </author> <title> The CN2 induction algorithm. </title> <journal> Machine Learning, </journal> <volume> 3 </volume> <pages> 261-283, </pages> <year> 1989. </year>
Reference-contexts: This approach has often worked well in practice, but is plagued by the splintering of the sample that it causes, resulting in decisions being made with less and less statistical support as induction progresses. "Separate and conquer" methods <ref> [7, 4, 10] </ref> alleviate this problem somewhat by inducing instead a set of rules that covers all or most positive examples, while covering no or few negative examples. <p> The aim of the research described in this report is to begin elucidating this question. Another problem is that a typical rule induction system (e.g. CN2 <ref> [4] </ref>, or FOIL [12] in relational domains) would keep producing the same rule if each cycle started with the whole training set. One way to avoid this is to invert the direction of search: instead of general-to-specific search, use specific-to-general, starting one search from 1 each example. <p> The total complexity is therefore O (EA + EA fi EA fi A + EA fi E fi A) = O (E 2 A 3 ). This is competitive with e.g. CN2. (Note that the computations in <ref> [4] </ref> are only for the basic step of the algorithm, which is embedded in loops that may run O (EA) in the worst case.) In particular, Rise is quadratic in the number of examples, meaning it can be applied directly to all but very large databases. <p> The practical effect of this will depend on the domain. 4 Empirical evaluation With the goal of empirically evaluating the usefulness of the "conquering without separating" strategy, Rise was compared with a current "separate-and-conquer" rule induction algorithm on a number of natural and artificial domains. CN2 <ref> [4] </ref> was chosen for this purpose because it is probably the most extensively evaluated noise-tolerant algorithm of this type. A recent, enhanced version was used [3]. All options were set so as to maximize similarity to Rise: unordered rules, star size 1, and 0 significance threshold. <p> The other observation comes from the trio of medical domains (lymphography, breast cancer, and primary tumor) where CN2 was originally tested <ref> [4] </ref> and that is probably the most widely used in the machine learning literature: there is no significant difference in the "easier" domain (lymphography) or the intermediate one (breast cancer), but Rise is significantly better in the "harder" one (primary tumor).
Reference: [5] <author> R. C. Holte. </author> <title> Very simple classification rules perform well on most commonly used datasets. </title> <journal> Machine Learning, </journal> <volume> 11 </volume> <pages> 63-91, </pages> <year> 1993. </year>
Reference-contexts: The voting domain was tried in two forms: with and without the "physician fee freeze" attribute. Remov 8 50 60 70 80 90 100 Accuracy (%) No. examples RISE CN2 EABC, with 5 irrelevant attributes. ing this attribute causes the difficulty of the domain to increase substantially <ref> [2, 5] </ref>, making possible an evaluation of performance variation with difficulty while holding other factors constant. Ten-fold cross-validation was performed for Rise and CN2, using the same training and test sets for the two at each step.
Reference: [6] <author> R. C. Holte, L. E. Acker, and B. W. Porter. </author> <title> Concept learning and the problem of small disjuncts. </title> <booktitle> In Proc. IJCAI-89, </booktitle> <pages> pages 813-818, </pages> <year> 1989. </year>
Reference-contexts: As a result, it may not be possible to reliably induce some rules to their full length, causing either overly general or incorrect rules to be produced, negatively affecting accuracy. A related problem, first identified by Holte and coworkers <ref> [6, 13] </ref>, is that of small disjuncts. While covering relatively few examples, small disjuncts tend to be responsible for a disproportionate share of the classification errors committed. Many of these disjuncts undoubtedly represent actual small disjuncts in the domain.
Reference: [7] <author> R. S. Michalski. </author> <title> A theory and methodology of inductive learning. </title> <journal> Artificial Intelligence, </journal> <volume> 20 </volume> <pages> 111-161, </pages> <year> 1983. </year>
Reference-contexts: This approach has often worked well in practice, but is plagued by the splintering of the sample that it causes, resulting in decisions being made with less and less statistical support as induction progresses. "Separate and conquer" methods <ref> [7, 4, 10] </ref> alleviate this problem somewhat by inducing instead a set of rules that covers all or most positive examples, while covering no or few negative examples.
Reference: [8] <author> S. Muggleton and C. Feng. </author> <title> Efficient induction of logic programs. </title> <booktitle> In Proc. 1st Workshop on Algorithmic Learning Theory, </booktitle> <pages> pages 368-381, </pages> <year> 1990. </year>
Reference-contexts: After eliminating the more obvious sources of inefficiency in the code, speed may still be improvable without compromising accuracy by the use of sampling techniques, eg. as done by GOLEM <ref> [8] </ref>. In any case, if accuracy and speed are comparable, then conquering without separating is probably the strategy of choice, since it yields simpler algorithms.
Reference: [9] <author> P. M. Murphy and D. W. Aha. </author> <title> UCI repository of machine learning databases. Machine-readable data repository, </title> <institution> University of California, Department of Information and Computer Science, </institution> <address> Irvine, CA, </address> <year> 1992. </year>
Reference-contexts: The difference in performance between Rise and CN2 has again increased substantially, leading to the hypothesis that conquering without separating becomes more advantageous as domain difficulty increases. 4.2 Natural domains Tests were conducted in 16 domains from the UCI repository <ref> [9] </ref> to determine if this behavior is observable in practical situations. Selection of domains obeyed the following criteria: prefer widely used domains, provide a selection of symbolic, numeric and mixed domains, and provide a spectrum of difficulty.
Reference: [10] <author> G. Pagallo and D. Haussler. </author> <title> Boolean feature discovery in empirical learning. </title> <journal> Machine Learning, </journal> <volume> 3 </volume> <pages> 71-99, </pages> <year> 1990. </year>
Reference-contexts: This approach has often worked well in practice, but is plagued by the splintering of the sample that it causes, resulting in decisions being made with less and less statistical support as induction progresses. "Separate and conquer" methods <ref> [7, 4, 10] </ref> alleviate this problem somewhat by inducing instead a set of rules that covers all or most positive examples, while covering no or few negative examples.
Reference: [11] <author> J. R. Quinlan. </author> <title> Induction of decision trees. </title> <journal> Machine Learning, </journal> <volume> 1 </volume> <pages> 81-106, </pages> <year> 1986. </year>
Reference-contexts: 1 Introduction and motivation Current machine learning approaches to the induction of concept definitions from examples fall mainly into two categories: "divide and conquer" and "separate and conquer." "Divide and conquer" methods <ref> [11, 14] </ref> recursively partition the instance space until regions of roughly constant class membership are obtained.
Reference: [12] <author> J. R. Quinlan. </author> <title> Learning logical definitions from relations. </title> <journal> Machine Learning, </journal> <volume> 5 </volume> <pages> 239-266, </pages> <year> 1990. </year>
Reference-contexts: The aim of the research described in this report is to begin elucidating this question. Another problem is that a typical rule induction system (e.g. CN2 [4], or FOIL <ref> [12] </ref> in relational domains) would keep producing the same rule if each cycle started with the whole training set. One way to avoid this is to invert the direction of search: instead of general-to-specific search, use specific-to-general, starting one search from 1 each example.
Reference: [13] <author> J. R. Quinlan. </author> <title> Improved estimates for the accuracy of small disjuncts. </title> <journal> Machine Learning, </journal> <volume> 6 </volume> <pages> 93-98, </pages> <year> 1991. </year>
Reference-contexts: As a result, it may not be possible to reliably induce some rules to their full length, causing either overly general or incorrect rules to be produced, negatively affecting accuracy. A related problem, first identified by Holte and coworkers <ref> [6, 13] </ref>, is that of small disjuncts. While covering relatively few examples, small disjuncts tend to be responsible for a disproportionate share of the classification errors committed. Many of these disjuncts undoubtedly represent actual small disjuncts in the domain.
Reference: [14] <author> J. R. Quinlan. C4.5: </author> <title> Programs for Machine Learning. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1993. </year>
Reference-contexts: 1 Introduction and motivation Current machine learning approaches to the induction of concept definitions from examples fall mainly into two categories: "divide and conquer" and "separate and conquer." "Divide and conquer" methods <ref> [11, 14] </ref> recursively partition the instance space until regions of roughly constant class membership are obtained. <p> The approach taken is the following. Initially, for each numeric attribute, all occurring values are collected and sorted into ascending order. The midpoint of each pair of consecutive values is then computed, and an ordered list of these midpoints stored, as done in C4.5 <ref> [14] </ref>. At each generalization step, two generalizations of the attribute are considered: replacing its upper limit by the next higher point on the list (or 1 if there is none), and replacing its lower limit by the next lower point (or 1) .
Reference: [15] <author> H. Ragavan and L. Rendell. </author> <title> Lookahead feature construction for learning hard concepts. </title> <booktitle> In Proc. 10th Machine Learning Conf., </booktitle> <pages> pages 252-259, </pages> <year> 1993. </year> <month> 12 </month>
Reference-contexts: It will also be interesting to measure the size and accuracy of the individual disjuncts produced, and to relate performance to quantitative measures of concept difficulty, as done in e.g. <ref> [15] </ref>. The current, far from optimized version of Rise is somewhat slower than the C implementation of CN2, but still quite competitive.
References-found: 15

