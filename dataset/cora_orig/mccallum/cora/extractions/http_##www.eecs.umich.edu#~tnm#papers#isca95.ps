URL: http://www.eecs.umich.edu/~tnm/papers/isca95.ps
Refering-URL: http://www.eecs.umich.edu/~tnm/papers.html
Root-URL: http://www.cs.umich.edu
Title: Abstract  
Keyword: Key words: code bloat, address traces, caches, instruction fetching.  
Abstract: Previous research has shown that the SPEC benchmarks achieve low miss ratios in relatively small instruction caches. This paper presents evidence that current software-development practices produce applications that exhibit substantially higher instruction-cache miss ratios than do the SPEC benchmarks. To represent these trends, we have assembled a collection of applications, called the Instruction Benchmark Suite (IBS), that provides a better test of instruction-cache performance. We discuss the rationale behind the design of IBS and characterize its behavior relative to the SPEC benchmark suite. Our analysis is based on trace-driven and trap-driven simulations and takes into full account both the application and operating-system components of the workloads. This paper then reexamines a collection of previously-proposed hardware mechanisms for improving instruction-fetch performance in the context of the IBS workloads. We study the impact of cache organization, transfer bandwidth, prefetching, and pipelined memory systems on machines that rely on the use of relatively small primary caches to facilitate increased clock rates. We find that, although of little use for SPEC, the right combination of these techniques provides significant benefit for IBS. Even so, under IBS, a stubborn lower bound on the instruction-fetch CPI remains as an obstacle to improving overall processor performance. 
Abstract-found: 1
Intro-found: 1
Reference: [Alexander85] <author> Alexander, C. A., Keshlear, W. M. and Briggs, F. </author> <title> Translation buffer performance in a UNIX environment. </title> <booktitle> Computer Architecture News 13 (5): </booktitle> <pages> 2-14, </pages> <year> 1985. </year>
Reference: [Alexander86] <author> Alexander, C., Keshlear, W., Cooper, F. and Briggs, F. </author> <title> Cache memory performance in a UNIX environment. </title> <booktitle> Computer Architecture News 14: </booktitle> <pages> 14-70, </pages> <year> 1986. </year>
Reference: [Agarwal88] <author> Agarwal, A., Hennessy, J. and Horowitz, M. </author> <title> Cache performance of operating system and multiprogramming workloads. </title> <journal> ACM Transactions on Computer Systems 6 (Number 4): </journal> <pages> 393-431, </pages> <year> 1988. </year>
Reference: [Baer87] <author> Baer, J.-L. and Wang, W.-H. </author> <title> Architectural choices for multi-level cache hierarchies. </title> <booktitle> Proceedings of the 16th International Conference on Parallel Processing: </booktitle> <pages> 258-261, </pages> <year> 1987. </year>
Reference-contexts: Several hardware-based methods have been proposed to reduce the penalty of misses in small, direct-mapped primary I-caches. The most straightforward is to add a second level of cache, either on or off chip, to reduce time-consuming references to main memory <ref> [Short88, Baer87, Baer88, Przybylski89, Przybylski90, Happel92, Kessler91, Olukotun91, Jouppi94, Wang89] </ref>. Other methods focus on optimizing the interface from the primary I-cache to the next level in the memory hierarchy, whether it be a second-level cache, or main memory.
Reference: [Baer88] <author> Baer, J.-L. and Wang, W.-H. </author> <title> On the inclusion properties for multi-level cache hierarchies. </title> <booktitle> The 15th Annual International Symposium on Computer Architecture 16 (2): </booktitle> <pages> 73-80, </pages> <year> 1988. </year>
Reference-contexts: Several hardware-based methods have been proposed to reduce the penalty of misses in small, direct-mapped primary I-caches. The most straightforward is to add a second level of cache, either on or off chip, to reduce time-consuming references to main memory <ref> [Short88, Baer87, Baer88, Przybylski89, Przybylski90, Happel92, Kessler91, Olukotun91, Jouppi94, Wang89] </ref>. Other methods focus on optimizing the interface from the primary I-cache to the next level in the memory hierarchy, whether it be a second-level cache, or main memory.
Reference: [Bershad94] <author> Bershad, B., Lee, D., Romer, T. and Chen, B. </author> <title> Avoiding conict misses dynamically in large direct-mapped caches, </title> <booktitle> In The Sixth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <address> San Jose, CA, </address> <publisher> ACM Press (SIGOPS), </publisher> <pages> 158-170, </pages> <year> 1994. </year>
Reference-contexts: When a cache is physically-indexed and larger than the page size, operating systems can implement page-allocation algorithms that more evenly distribute pages in the cache to help prevent conict misses <ref> [Bray90, Kessler92, Bershad94] </ref>. Most previous studies of workloads with a significant operating system component have tended to consider simple memory systems. Most of the effort in these studies went into the collection of complete address traces that include multi-task and operating system references. <p> The plots also show that small amounts of associativity reduce variability by avoiding conict misses before they happen. This suggests that on-chip, associative L2 caches offer an attractive alternative to the recently-proposed cache miss lookaside (CML) buffers <ref> [Bershad94] </ref>. 1. The additional delay due to the associative lookup will increase the access time to the L2 cache, possibly increasing the L1-L2 latency by 1 full cycle. This would increase the L1 contribution to CPI instr from 0.34 to 0.38.
Reference: [Bomberger92] <author> Bomberger, A., Hardy, N., Frantz, A. P., Landau, C. R., Frantz, W. S., Shapiro, J. S. and Hardy, A. C. </author> <booktitle> The Key-KOS Nanokernel Architecture, In USENIX Micro-Kernels and Other Kernel Architectures, </booktitle> <address> Seattle, Washington, </address> <publisher> USENIX, </publisher> <pages> 95-112, </pages> <year> 1992. </year>
Reference-contexts: Porting an application to a different operating system requires that it be rewritten to use the application-procedure interfaces or APIs of the new host OS. To simplify this process, some operating systems, such as Windows NT [Custer93], Mach 3.0 [Accetta86], and others <ref> [Bomberger92, Cheriton84, Malan91, Rozier92, Wiecek92] </ref> have been designed to emulate multiple APIs. Overhead due to API emulation is represented in IBS through the use of a 4.3 BSD emulation library that is dynamically linked into the address space of each user application.
Reference: [Borg90] <author> Borg, A., Kessler, R. and Wall, D. </author> <title> Generation and analysis of very long address traces, </title> <booktitle> In The 17th Annual International Symposium on Computer Architecture, IEEE, </booktitle> <year> 1990. </year>
Reference: [Bray90] <author> Bray, B., Lynch, W. and Flynn, M. J. </author> <title> Page allocation to reduce access time of physical caches. </title> <institution> Stanford University, Computer Systems Laboratory. CSL-TR-90-454. </institution> <year> 1990. </year>
Reference-contexts: When a cache is physically-indexed and larger than the page size, operating systems can implement page-allocation algorithms that more evenly distribute pages in the cache to help prevent conict misses <ref> [Bray90, Kessler92, Bershad94] </ref>. Most previous studies of workloads with a significant operating system component have tended to consider simple memory systems. Most of the effort in these studies went into the collection of complete address traces that include multi-task and operating system references.
Reference: [Brunner91] <author> Brunner, R. A. </author> <title> VAX Architecture Reference Manual. </title> <publisher> Digital Press, </publisher> <year> 1991. </year>
Reference-contexts: The net effect of these trends is that primary caches have not grown in size during the past 10 years <ref> [Brunner91] </ref>. These hardware and software trends are particularly demanding of instruction caches because code bloat can increase the active instruction working-set sizes that CPU caches must retain close to the processor.
Reference: [Budd91] <author> Budd, T. </author> <title> An Introduction to Object-Oriented Programming. </title> <publisher> Addison-Wesley Publishing IBSN 0-201-54709-0, </publisher> <year> 1991. </year>
Reference-contexts: Windows NT also separates its different API servers (Win32, OS/2, POSIX, etc.) into independent modules or subsystems that are loaded into the system only as needed [Custer93]. The benefits of object-oriented and modular code are well-recognized <ref> [Budd91] </ref>, but because they incur a variety of overheads, these techniques come with a cost. The IBS benchmark suite represents these costs in two ways.
Reference: [Calder94] <author> Calder, B., Grunwald, D. and Zorn, B. </author> <title> Quantifying behavioral differences between C and C++ programs. </title> <institution> The Department of Computer Science, University of Colorado. CU-CS-698-94. </institution> <year> 1994. </year>
Reference-contexts: This assertion is supported by the recent work of Calder et al. who have performed a more detailed study of 10 C and 10 C++ programs in <ref> [Calder94] </ref>.
Reference: [Chen93c] <author> Chen, B. and Bershad, B. </author> <title> The impact of operating system structure on memory system performance, </title> <booktitle> In Proc. 14th Symposium on Operating System Principles, </booktitle> <year> 1993. </year>
Reference: [Chen94a] <author> Chen, B. </author> <title> Memory behavior of an X11 window system, </title> <booktitle> In USENIX Winter 1994 Technical Conference, </booktitle> <year> 1994. </year>
Reference: [Cheriton84] <author> Cheriton, D. R. </author> <title> The V kernel: A software base for distributed systems. </title> <booktitle> IEEE Software 1 (2): </booktitle> <pages> 19-42, </pages> <year> 1984. </year>
Reference-contexts: Porting an application to a different operating system requires that it be rewritten to use the application-procedure interfaces or APIs of the new host OS. To simplify this process, some operating systems, such as Windows NT [Custer93], Mach 3.0 [Accetta86], and others <ref> [Bomberger92, Cheriton84, Malan91, Rozier92, Wiecek92] </ref> have been designed to emulate multiple APIs. Overhead due to API emulation is represented in IBS through the use of a 4.3 BSD emulation library that is dynamically linked into the address space of each user application.
Reference: [Clark83] <author> Clark, D. </author> <title> Cache performance in the VAX-11/780. </title> <journal> ACM Transactions on Computer Systems 1: </journal> <pages> 24-37, </pages> <year> 1983. </year>
Reference: [Clark85a] <author> Clark, D. W. and Emer, J. S. </author> <title> Performance of the VAX-11/780 translation buffer: </title> <booktitle> Simulation and measurement. ACM Transactions on Computer Systems 3 (1): </booktitle> <pages> 31-62, </pages> <year> 1985. </year> <month> 12 </month>
Reference: [Clark85b] <author> Clark, D. W., Bannon, P. J. and Keller, J. B. </author> <title> Measuring VAX 8800 Performance with a Histogram Hardware Monitor, </title> <booktitle> In The 15th Annual International Symposium on Computer Architecture, Honolulu, Hawaii, IEEE, </booktitle> <pages> 176-185, </pages> <year> 1985. </year>
Reference: [Cmelik94] <author> Cmelik, B. and Keppel, D. Shade: </author> <title> A fast instruction-set simulator for execution profiling, </title> <booktitle> In SIGMET-RICS, </booktitle> <address> Nashville, TN, </address> <publisher> ACM, </publisher> <pages> 128-137, </pages> <year> 1994. </year>
Reference-contexts: For example, DEC implements ABI emulation by statically translating VAX and MIPS binaries into Alpha binaries [Sites92]. Apple uses a similar strategy to dynamically translate 68040 binaries to the PowerPC architecture [Koch94]. Several other examples of ABI emulators are given in <ref> [Cmelik94] </ref>. ABI emulation causes code bloat because several host instructions are usually required to emulate a single source instruction. An emulation environment typically also includes a large amount of additional execution state, such as translated instruction blocks or jump tables that lead to frequent indirect jumps [Cmelik94]. <p> emulators are given in <ref> [Cmelik94] </ref>. ABI emulation causes code bloat because several host instructions are usually required to emulate a single source instruction. An emulation environment typically also includes a large amount of additional execution state, such as translated instruction blocks or jump tables that lead to frequent indirect jumps [Cmelik94]. We represent ABI emulation in our benchmark suite with spim, which emulates the MIPS instruction set on a variety of other architectures including the SPARC, HP-PA, x86 and the MIPS itself [Larus91].
Reference: [Custer93] <author> Custer, H. </author> <title> Inside Windows NT. </title> <address> Redmond, Wash-ington, </address> <publisher> Microsoft Press, </publisher> <year> 1993. </year>
Reference-contexts: Porting an application to a different operating system requires that it be rewritten to use the application-procedure interfaces or APIs of the new host OS. To simplify this process, some operating systems, such as Windows NT <ref> [Custer93] </ref>, Mach 3.0 [Accetta86], and others [Bomberger92, Cheriton84, Malan91, Rozier92, Wiecek92] have been designed to emulate multiple APIs. Overhead due to API emulation is represented in IBS through the use of a 4.3 BSD emulation library that is dynamically linked into the address space of each user application. <p> To help manage this complexity, software developers rely on techniques such as object-oriented programming and the restructuring of code into independent and interchangeable modules. For example, the Windows NT Executive bases all of its system abstractions, such as processes, threads and files on an object-oriented model <ref> [Custer93] </ref>. Windows NT also separates its different API servers (Win32, OS/2, POSIX, etc.) into independent modules or subsystems that are loaded into the system only as needed [Custer93]. <p> For example, the Windows NT Executive bases all of its system abstractions, such as processes, threads and files on an object-oriented model <ref> [Custer93] </ref>. Windows NT also separates its different API servers (Win32, OS/2, POSIX, etc.) into independent modules or subsystems that are loaded into the system only as needed [Custer93]. The benefits of object-oriented and modular code are well-recognized [Budd91], but because they incur a variety of overheads, these techniques come with a cost. The IBS benchmark suite represents these costs in two ways.
Reference: [Cvetanovic94] <author> Cvetanovic, Z. and Bhandarkar, D. </author> <title> Characterization of Alpha AXP performance using TP and SPEC Work-loads, </title> <booktitle> In The 21st Annual International Symposium on Computer Architecture, </booktitle> <address> Chicago, Ill., </address> <publisher> IEEE, </publisher> <year> 1994. </year>
Reference: [Emer84] <author> Emer, J. and Clark, D. </author> <title> A characterization of processor performance in the VAX-11/780, </title> <booktitle> In The 11th Annual Symposium on Computer Architecture, </booktitle> <address> Ann Arbor, MI, </address> <publisher> IEEE, </publisher> <pages> 301-309, </pages> <year> 1984. </year>
Reference-contexts: To add an additional degree of confidence to our measurements and to take into account inherent variations in performance due to operating system effects, we use a trap-driven simulator called Tapeworm II [Uhlig94]. We adopt a simple performance model based on cycles-per-instruction (CPI) that focuses on instruction-fetching performance <ref> [Emer84, Hennessey90, Smith92] </ref>: where CPI instr is performance lost to I-cache misses and CPI other is determined by the instruction-issue rate and all other sources of processor stalls, such D-cache misses, TLB misses, CPU pipeline interlocks and issue constraints.
Reference: [Farrens89] <author> Farrens, M. and Pleszkun, A. </author> <title> Improving performance of small on-chip instruction caches, </title> <booktitle> In The 16th Annual International Symposium on Computer Architecture, ACM, </booktitle> <pages> 234-241, </pages> <year> 1989. </year>
Reference-contexts: Other methods focus on optimizing the interface from the primary I-cache to the next level in the memory hierarchy, whether it be a second-level cache, or main memory. These methods include the tuning of the cache line sizes [Przybylski90], prefetching <ref> [Farrens89, Hill87, Smith78, Smith92] </ref>, pipelining 1. During the past three ISCAs, over two thirds of the papers dealing with uniprocessor architecture issues used the SPEC benchmarks [ISCA92, ISCA93, ISCA94]. 3 [Jouppi90, Olukotun92, Palcharla94] and bypassing [Hennessy90]. There are also software-based methods for improving I-cache performance. <p> After arriving at an optimized L2 design, we consider how bandwidth, prefetching, bypassing and pipelining the L1-L2 interface can further improve performance. Throughout this section, we draw on the work of numerous researchers who have explored various instruction-fetching techniques, including multi-level caching, prefetching and pipelined-memory systems <ref> [Farrens89, Hill87, Kessler91, Jouppi90, Jouppi94, Olukotun92, Przybylski,89, Smith78, Smith82] </ref>. This work uses IBS to compare and evaluate these various architectural mechanisms under a more challenging workload. Throughout this analysis, we only consider instruction references.
Reference: [Flanagan93] <author> Flanagan, J. K., Nelson, B. E. and Archibald, J. K. </author> <title> The inaccuracy of trace-driven simulation using incomplete trace data. </title> <institution> Brigham Young University. </institution> <year> 1993. </year>
Reference: [Gee93] <author> Gee, J., Hill, M., Pnevmatikatos, D. and Smith, A. J. </author> <title> Cache Performance of the SPEC92 Benchmark Suite. </title> <journal> IEEE Micro (August): </journal> <pages> 17-27, </pages> <year> 1993. </year>
Reference-contexts: First, bloat in operating system code does not affect the SPEC suite because less than 2% of the entire execution time of the SPEC benchmarks is spent in system mode <ref> [Gee93] </ref>. Second, unlike real-world applications, the SPEC benchmarks are not regularly augmented with new features or restructured to enhance their portability and maintainability. <p> I-cache performance lost to IBS. 2 Related Work In recent years, much of the architecture research community has settled on using the SPEC benchmark suite as a measure of uniprocessor system performance 1 and considerable effort has been expended by commercial computer manufacturers to tune system performance on these workloads <ref> [Gee93] </ref>. Despite its popularity for evaluating a wide range of architectural structures, SPEC warns against the use of the SPEC89 or SPEC92 benchmarks for testing memory or I/O performance [SPEC93]. <p> In particular, the SPEC benchmark suite is not a good test of instruction-cache performance, a point made most persuasively by Gee et al. who have shown through exhaustive simulation that most of the SPEC benchmarks fit easily into relatively small I-caches over a range of associativities and line sizes <ref> [Gee93] </ref>. One reason that the SPEC benchmarks exhibit such good I-cache performance is due to their infrequent invocation of operating system services. <p> The I-cache component, CPI instr can be further factored into: where MPI is the I-cache miss ratio (misses per instruction) and CPM is the I-cache miss penalty (cycles per miss). Some of our comparisons with the SPEC92 benchmarks are based on miss ratios reported by Gee et al. in <ref> [Gee93] </ref>. Because Gee et al. performed their study on the same machine type (MIPS-based DECstations) and with the same type of compiler used in this study, meaningful comparisons can be made. <p> For the purposes of comparison, the average MPI for the IBS workloads running under Ultrix 3.1 and the SPEC92 benchmarks running under Ultrix 4.1 are also given. The SPEC92 results are based on miss ratios reported by Gee et al. in <ref> [Gee93] </ref>. Workload components include the user application task (s), the Mach 3.0 kernel, and the BSD and X display servers. The relative importance of each of these Workload Components is given as a fraction of total execution time.
Reference: [Happel92] <author> Happel, L. P. and Jayasumana, A. P. </author> <title> Performance of a RISC machine with two-level caches. </title> <booktitle> IEE Proceedings-E 139 (3): </booktitle> <pages> 221-229, </pages> <year> 1992. </year>
Reference-contexts: Several hardware-based methods have been proposed to reduce the penalty of misses in small, direct-mapped primary I-caches. The most straightforward is to add a second level of cache, either on or off chip, to reduce time-consuming references to main memory <ref> [Short88, Baer87, Baer88, Przybylski89, Przybylski90, Happel92, Kessler91, Olukotun91, Jouppi94, Wang89] </ref>. Other methods focus on optimizing the interface from the primary I-cache to the next level in the memory hierarchy, whether it be a second-level cache, or main memory.
Reference: [Hennessy90] <author> Hennessy, J. L. and Patterson, D. A. </author> <title> Computer Architecture A Quantitative Approach. </title> <address> San Mateo, </address> <publisher> Morgan Kaufmann, </publisher> <year> 1990. </year>
Reference-contexts: These methods include the tuning of the cache line sizes [Przybylski90], prefetching [Farrens89, Hill87, Smith78, Smith92], pipelining 1. During the past three ISCAs, over two thirds of the papers dealing with uniprocessor architecture issues used the SPEC benchmarks [ISCA92, ISCA93, ISCA94]. 3 [Jouppi90, Olukotun92, Palcharla94] and bypassing <ref> [Hennessy90] </ref>. There are also software-based methods for improving I-cache performance. Compilers can reduce conict misses by carefully placing procedures in memory with the assistance of execution-profile information and through call-graph analysis [Hwu89, McFarling89, Torrellas95].
Reference: [Hill87] <author> Hill, M. </author> <title> Aspects of cache memory and instruction buffer performance. </title> <institution> The University of California at Berke-ley. </institution> <year> 1987. </year>
Reference-contexts: Other methods focus on optimizing the interface from the primary I-cache to the next level in the memory hierarchy, whether it be a second-level cache, or main memory. These methods include the tuning of the cache line sizes [Przybylski90], prefetching <ref> [Farrens89, Hill87, Smith78, Smith92] </ref>, pipelining 1. During the past three ISCAs, over two thirds of the papers dealing with uniprocessor architecture issues used the SPEC benchmarks [ISCA92, ISCA93, ISCA94]. 3 [Jouppi90, Olukotun92, Palcharla94] and bypassing [Hennessy90]. There are also software-based methods for improving I-cache performance. <p> Following the Three-Cs model of cache performance <ref> [Hill87] </ref>, this graph is a stacked-bar chart that breaks the cause of misses into three components: capacity, conict and compulsory misses. 1 Capacity misses are removed by larger 1. I/O and paging activity can cause a significant number of compulsory D-cache misses. <p> After arriving at an optimized L2 design, we consider how bandwidth, prefetching, bypassing and pipelining the L1-L2 interface can further improve performance. Throughout this section, we draw on the work of numerous researchers who have explored various instruction-fetching techniques, including multi-level caching, prefetching and pipelined-memory systems <ref> [Farrens89, Hill87, Kessler91, Jouppi90, Jouppi94, Olukotun92, Przybylski,89, Smith78, Smith82] </ref>. This work uses IBS to compare and evaluate these various architectural mechanisms under a more challenging workload. Throughout this analysis, we only consider instruction references.
Reference: [Huck93] <author> Huck, J. and Hays, J. </author> <title> Architectural support for translation table management in large address space machines, </title> <booktitle> In The 20th Annual International Symposium on Computer Architecture, </booktitle> <address> San Diego, California, </address> <publisher> IEEE, </publisher> <pages> 39-50, </pages> <year> 1993. </year>
Reference: [Hwu89] <author> Hwu, W.-m. and Chang, P. </author> <title> Achieving high instruction cache performance with an optimizing compiler, </title> <booktitle> In The 16th International Symposium on Computer Architecture, </booktitle> <address> Jerusalem, Isreal, </address> <publisher> IEEE Computer Society Press (ACM SIGARCH), </publisher> <pages> 242-251, </pages> <year> 1989. </year>
Reference-contexts: There are also software-based methods for improving I-cache performance. Compilers can reduce conict misses by carefully placing procedures in memory with the assistance of execution-profile information and through call-graph analysis <ref> [Hwu89, McFarling89, Torrellas95] </ref>. When a cache is physically-indexed and larger than the page size, operating systems can implement page-allocation algorithms that more evenly distribute pages in the cache to help prevent conict misses [Bray90, Kessler92, Bershad94].
Reference: [ISCA92] <editor> ISCA92. </editor> <booktitle> The 19th Annual International Symposium on Computer Architecture, In ISCA, </booktitle> <address> Gold Coast, Austra-lia, </address> <publisher> ACM SIGARCH and IEEE Computer Society, </publisher> <pages> 1-424, </pages> <year> 1992. </year>
Reference-contexts: These methods include the tuning of the cache line sizes [Przybylski90], prefetching [Farrens89, Hill87, Smith78, Smith92], pipelining 1. During the past three ISCAs, over two thirds of the papers dealing with uniprocessor architecture issues used the SPEC benchmarks <ref> [ISCA92, ISCA93, ISCA94] </ref>. 3 [Jouppi90, Olukotun92, Palcharla94] and bypassing [Hennessy90]. There are also software-based methods for improving I-cache performance. Compilers can reduce conict misses by carefully placing procedures in memory with the assistance of execution-profile information and through call-graph analysis [Hwu89, McFarling89, Torrellas95].
Reference: [ISCA93] <editor> ISCA93. </editor> <booktitle> The 20th Annual International Symposium on Computer Architecture, In ISCA, </booktitle> <address> San Diego, Califor-nia, </address> <publisher> ACM SIGARCH and IEEE Computer Society, </publisher> <pages> 1-360, </pages> <year> 1993. </year>
Reference-contexts: These methods include the tuning of the cache line sizes [Przybylski90], prefetching [Farrens89, Hill87, Smith78, Smith92], pipelining 1. During the past three ISCAs, over two thirds of the papers dealing with uniprocessor architecture issues used the SPEC benchmarks <ref> [ISCA92, ISCA93, ISCA94] </ref>. 3 [Jouppi90, Olukotun92, Palcharla94] and bypassing [Hennessy90]. There are also software-based methods for improving I-cache performance. Compilers can reduce conict misses by carefully placing procedures in memory with the assistance of execution-profile information and through call-graph analysis [Hwu89, McFarling89, Torrellas95].
Reference: [ISCA94] <editor> ISCA94. </editor> <booktitle> The 21st Annual International Symposium on Computer Architecture, In ISCA, </booktitle> <address> Chicago, Illinois, </address> <publisher> ACM SIGARCH and IEEE Computer Society, </publisher> <pages> 1-394, </pages> <year> 1994. </year>
Reference-contexts: These methods include the tuning of the cache line sizes [Przybylski90], prefetching [Farrens89, Hill87, Smith78, Smith92], pipelining 1. During the past three ISCAs, over two thirds of the papers dealing with uniprocessor architecture issues used the SPEC benchmarks <ref> [ISCA92, ISCA93, ISCA94] </ref>. 3 [Jouppi90, Olukotun92, Palcharla94] and bypassing [Hennessy90]. There are also software-based methods for improving I-cache performance. Compilers can reduce conict misses by carefully placing procedures in memory with the assistance of execution-profile information and through call-graph analysis [Hwu89, McFarling89, Torrellas95].
Reference: [Jouppi90] <author> Jouppi, N. </author> <title> Improving direct-mapped cache performance by the addition of a small fully-associative cache and prefetch buffers, </title> <booktitle> In The 17th Annual International Symposium on Computer Architecture, </booktitle> <address> Seattle, WA, </address> <publisher> IEEE Computer Society Press (ACM SIGARCH), </publisher> <pages> 364-373, </pages> <year> 1990. </year>
Reference-contexts: These methods include the tuning of the cache line sizes [Przybylski90], prefetching [Farrens89, Hill87, Smith78, Smith92], pipelining 1. During the past three ISCAs, over two thirds of the papers dealing with uniprocessor architecture issues used the SPEC benchmarks [ISCA92, ISCA93, ISCA94]. 3 <ref> [Jouppi90, Olukotun92, Palcharla94] </ref> and bypassing [Hennessy90]. There are also software-based methods for improving I-cache performance. Compilers can reduce conict misses by carefully placing procedures in memory with the assistance of execution-profile information and through call-graph analysis [Hwu89, McFarling89, Torrellas95]. <p> After arriving at an optimized L2 design, we consider how bandwidth, prefetching, bypassing and pipelining the L1-L2 interface can further improve performance. Throughout this section, we draw on the work of numerous researchers who have explored various instruction-fetching techniques, including multi-level caching, prefetching and pipelined-memory systems <ref> [Farrens89, Hill87, Kessler91, Jouppi90, Jouppi94, Olukotun92, Przybylski,89, Smith78, Smith82] </ref>. This work uses IBS to compare and evaluate these various architectural mechanisms under a more challenging workload. Throughout this analysis, we only consider instruction references. <p> During cycles where the processor hits in the cache, the pipeline is kept busy with sequential prefetch requests 1 . Prefetches are stored in a special buffer, called a Stream Buffer <ref> [Jouppi90] </ref>. The stream buffer is a fully-associative memory with 1 or more lines and is very similar to a bypass buffer. The results (see Table 8) show that streams buffers effectively improve I-fetch performance until they reach sizes of about 6 lines, after which the improvements are marginal.
Reference: [Jouppi94] <author> Jouppi, N. and Wilton, S. </author> <title> Tradeoffs in two-level on-chip caching, </title> <booktitle> In The 21st Annual International Symposium on Computer Architecture, </booktitle> <address> Chicago, IL, </address> <publisher> IEEE Computer Society Press, </publisher> <pages> 34-45, </pages> <year> 1994. </year>
Reference-contexts: However, technology trends have resulted in more complex trade-offs in the case of TLBs and caches. Although continued advancements in integrated-circuit densities make it possible to allocate more die area to on-chip cache structures, reductions in cycle times constrain the maximum size and associativity of primary on-chip caches <ref> [Jouppi94] </ref>. This is true because for a given integrated-circuit technology, increasing cache size and associativity increases access times [Olukutun92, Wada92, Wilton94]. <p> This analysis confirms that code-bloat trends lead to increased I-cache capacity and associativity requirements. Then, starting with the assumption that future high-speed processors will have to limit their primary I-caches to small, direct-mapped memories <ref> [Jouppi94] </ref>, we evaluate various methods for reducing primary I-cache miss penalties. <p> Several hardware-based methods have been proposed to reduce the penalty of misses in small, direct-mapped primary I-caches. The most straightforward is to add a second level of cache, either on or off chip, to reduce time-consuming references to main memory <ref> [Short88, Baer87, Baer88, Przybylski89, Przybylski90, Happel92, Kessler91, Olukotun91, Jouppi94, Wang89] </ref>. Other methods focus on optimizing the interface from the primary I-cache to the next level in the memory hierarchy, whether it be a second-level cache, or main memory. <p> recover some of the performance lost to bloated code. 5 Instruction Fetch Support for IBS The IBS workloads require significantly larger I-caches to achieve the same miss rates as the SPEC benchmarks, but cycle-time constraints prevent level-1 (L1) caches from providing the size and/or associativity necessary to deliver good performance <ref> [Jouppi94] </ref>. However, integration levels have reached a point where small L1 caches can be supported by a variety of on-chip structures that reduce the L1 miss penalty. The remainder of this paper examines the effectiveness of some of these structures when supporting IBS. <p> After arriving at an optimized L2 design, we consider how bandwidth, prefetching, bypassing and pipelining the L1-L2 interface can further improve performance. Throughout this section, we draw on the work of numerous researchers who have explored various instruction-fetching techniques, including multi-level caching, prefetching and pipelined-memory systems <ref> [Farrens89, Hill87, Kessler91, Jouppi90, Jouppi94, Olukotun92, Przybylski,89, Smith78, Smith82] </ref>. This work uses IBS to compare and evaluate these various architectural mechanisms under a more challenging workload. Throughout this analysis, we only consider instruction references.
Reference: [Koch94] <author> Koch, P. </author> <title> Emulating the 68040 in the PowerPC Macintosh, In Microprocessor Forum, </title> <address> San Francisco, CA, </address> <year> 1994. </year>
Reference-contexts: ABI emulation is sometimes used to ease the transition from an older processor architecture to a newer one. For example, DEC implements ABI emulation by statically translating VAX and MIPS binaries into Alpha binaries [Sites92]. Apple uses a similar strategy to dynamically translate 68040 binaries to the PowerPC architecture <ref> [Koch94] </ref>. Several other examples of ABI emulators are given in [Cmelik94]. ABI emulation causes code bloat because several host instructions are usually required to emulate a single source instruction.
Reference: [Kessler91] <author> Kessler, R. </author> <title> Analysis of multi-megabyte secondary CPU cache memories. </title> <institution> University of Wisconsin-Madison. </institution> <year> 1991. </year>
Reference-contexts: Several hardware-based methods have been proposed to reduce the penalty of misses in small, direct-mapped primary I-caches. The most straightforward is to add a second level of cache, either on or off chip, to reduce time-consuming references to main memory <ref> [Short88, Baer87, Baer88, Przybylski89, Przybylski90, Happel92, Kessler91, Olukotun91, Jouppi94, Wang89] </ref>. Other methods focus on optimizing the interface from the primary I-cache to the next level in the memory hierarchy, whether it be a second-level cache, or main memory. <p> After arriving at an optimized L2 design, we consider how bandwidth, prefetching, bypassing and pipelining the L1-L2 interface can further improve performance. Throughout this section, we draw on the work of numerous researchers who have explored various instruction-fetching techniques, including multi-level caching, prefetching and pipelined-memory systems <ref> [Farrens89, Hill87, Kessler91, Jouppi90, Jouppi94, Olukotun92, Przybylski,89, Smith78, Smith82] </ref>. This work uses IBS to compare and evaluate these various architectural mechanisms under a more challenging workload. Throughout this analysis, we only consider instruction references. <p> Increased associativity improves miss rates by reducing con-ict misses. As a result, associativity also reduces variability in performance caused by OS page-mapping effects in a physically-indexed cache <ref> [Kessler91, Sites88] </ref>. Figure 5 shows that the amount of variability is a function of the workload, cache size and associativity.
Reference: [Kessler92] <author> Kessler, R. and Hill, M. </author> <title> Page placement algorithms for large real-indexed caches. </title> <booktitle> ACM Transaction on Computer Systems 10 (4): </booktitle> <pages> 338-359, </pages> <year> 1992. </year>
Reference-contexts: When a cache is physically-indexed and larger than the page size, operating systems can implement page-allocation algorithms that more evenly distribute pages in the cache to help prevent conict misses <ref> [Bray90, Kessler92, Bershad94] </ref>. Most previous studies of workloads with a significant operating system component have tended to consider simple memory systems. Most of the effort in these studies went into the collection of complete address traces that include multi-task and operating system references.
Reference: [Larus91] <author> Larus, J. SPIM S20: </author> <title> A MIPS R2000 Simulator. </title> <institution> University of Washington. Revision 9. </institution> <year> 1991. </year>
Reference-contexts: Renders and displays a single postscript page with text and graphics in an X win dow. verilog Verilog-XL (version 1.6b) simulating the logic design of an experimental microprocessor. gcc The GNU C compiler (version 2.6) spim The SPIM MIPS emulator written by James Larus <ref> [Larus91] </ref>. The input is the SPEC92 espresso program. sdet A multiprocess, system performance benchmark which includes programs that test CPU performance, OS performance and I/O performance. <p> We represent ABI emulation in our benchmark suite with spim, which emulates the MIPS instruction set on a variety of other architectures including the SPARC, HP-PA, x86 and the MIPS itself <ref> [Larus91] </ref>. The IBS spim workload emulates a MIPS binary of the espresso SPEC benchmark and exhibits an MPI that is approximately 3 times the normal MPI of espresso when not being emulated. Maintainability As it grows in size and complexity, application and system software becomes increasingly difficult to maintain.
Reference: [Malan91] <author> Malan, G., Rashid, R., Golub, D. and Baron, R. </author> <title> DOS as a Mach 3.0 application, </title> <booktitle> In USENIX Mach Symposium, USENIX, </booktitle> <pages> 27-40, </pages> <year> 1991. </year>
Reference-contexts: Porting an application to a different operating system requires that it be rewritten to use the application-procedure interfaces or APIs of the new host OS. To simplify this process, some operating systems, such as Windows NT [Custer93], Mach 3.0 [Accetta86], and others <ref> [Bomberger92, Cheriton84, Malan91, Rozier92, Wiecek92] </ref> have been designed to emulate multiple APIs. Overhead due to API emulation is represented in IBS through the use of a 4.3 BSD emulation library that is dynamically linked into the address space of each user application.
Reference: [Maynard94] <author> Maynard, A. M., Donnelly, C. and Olszewski, B. </author> <title> Contrasting characteristics and cache performance of technical and multi-user commercial workloads, </title> <booktitle> In The Sixth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <address> San Jose, CA, </address> <publisher> ACM Press (SIGOPS), </publisher> <pages> 145-156, </pages> <year> 1994. </year>
Reference: [McFarling89] <author> McFarling, S. </author> <title> Program optimization for instruction caches, </title> <booktitle> In The Third International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <address> Boston, MA, </address> <publisher> ACM (SIGARCH), </publisher> <pages> 183-191, </pages> <year> 1989. </year>
Reference-contexts: There are also software-based methods for improving I-cache performance. Compilers can reduce conict misses by carefully placing procedures in memory with the assistance of execution-profile information and through call-graph analysis <ref> [Hwu89, McFarling89, Torrellas95] </ref>. When a cache is physically-indexed and larger than the page size, operating systems can implement page-allocation algorithms that more evenly distribute pages in the cache to help prevent conict misses [Bray90, Kessler92, Bershad94].
Reference: [Mogul91] <author> Mogul, J. C. and Borg, A. </author> <title> The effect of context switches on cache performance, </title> <booktitle> In Fourth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <address> Santa Clara, California, </address> <publisher> ACM, </publisher> <pages> 75-84, </pages> <address> 1991. [MReport92-94]MReport. Sebastopol, CA, MicroDesign Resources, </address> <year> 1992, 1993 </year> <month> and </month> <year> 1994. </year>
Reference: [Mulder91] <author> Mulder, J., Quach, N. and Flynn, M. </author> <title> An area model for on-chip memories and its application. </title> <journal> IEEE Journal of Solid-State Circuits 26 (2): </journal> <pages> 98-106, </pages> <year> 1991. </year>
Reference-contexts: Second, the reduction in area reduces the cache access time. The Mulder area model predicts a 10% reduction in area when moving from a 16-byte to a 64-byte line (8-KB, direct-mapped cache) <ref> [Mulder91] </ref>, while the Wilton and Jouppi timing model shows a 6% decrease in access time [Wilton94]. The incremental improvements due to increasing bandwidth begin to diminish for rates greater than 16 bytes/cycle.
Reference: [Nagle92] <author> Nagle, D., Uhlig, R., Mudge, T., </author> <title> Monster: a tool for analyzing the interaction between operating systems and architectures. </title> <institution> CSE-TR147-92. University of Michigan, </institution> <year> 1992. </year>
Reference-contexts: Our analysis of IBS uses two different and complementary methods: trace-driven and trap-driven simulation. For trace-driven simulation, we gathered address traces complete with user and operating system references by using Monster, a hardware logic analyzer connected to the CPU pins of a DECstation 3100 <ref> [Nagle92] </ref>. Because the caches on this machine are implemented off chip, all memory references were captured using this technique. Long, continuous traces were obtained by stalling the DECstation while unloading the trace buffer in the logic analyzer 1. We do not examine the aforementioned software-based methods in this paper. 2.
Reference: [Nagle93] <author> Nagle, D., Uhlig, R., Stanley, T., Sechrest, S., Mudge, T. and Brown, R. </author> <title> Design tradeoffs for software-managed TLBs. </title> <booktitle> In the 20th Annual International Symposium on Computer Architecture, </booktitle> <address> San Diego, California, 27-38, </address> <month> May </month> <year> 1993. </year>
Reference: [Nagle94] <author> Nagle, D., Uhlig, R., Mudge, T. and Sechrest, S. </author> <title> Optimal allocation of on-chip memory for multiple-API operating systems, </title> <booktitle> In the 21st Annual International Symposium on Computer Architecture, </booktitle> <address> Chicago, Illinois, </address> <month> May </month> <year> 1994. </year> <month> 13 </month>
Reference-contexts: The ability to change cache sizes in smaller increments also helps to more optimally allocate chip die-area among various on-chip memory-system structures (I-cache, D-cache, TLB) <ref> [Nagle94] </ref>. 5.2 Tuning the L1-L2 Interface For both configurations, a 64-KB 8-way, set-associative L2 cache contributes less than one third to the total CPI instr , making the L1 I-cache the performance bottleneck.
Reference: [Olukotun91] <author> Olukotun, O. A., Mudge, T. N. and Brown, R. B. </author> <title> Implementing a cache for a high-performance GaAs microprocessor, </title> <booktitle> In Proc. 18th Annual International Symposium on Computer Architecture, </booktitle> <address> Toronto, Canada, 138-147, </address> <year> 1991. </year>
Reference-contexts: Several hardware-based methods have been proposed to reduce the penalty of misses in small, direct-mapped primary I-caches. The most straightforward is to add a second level of cache, either on or off chip, to reduce time-consuming references to main memory <ref> [Short88, Baer87, Baer88, Przybylski89, Przybylski90, Happel92, Kessler91, Olukotun91, Jouppi94, Wang89] </ref>. Other methods focus on optimizing the interface from the primary I-cache to the next level in the memory hierarchy, whether it be a second-level cache, or main memory.
Reference: [Olukotun92] <author> Olukotun, K., Mudge, T. and Brown, R. </author> <title> Performance optimization of pipelined primary caches, </title> <booktitle> In The 19th Annual International Symposium on Computer Architecture, </booktitle> <address> Gold Coast, Australia, </address> <publisher> IEEE, </publisher> <pages> 181-190, </pages> <year> 1992. </year>
Reference-contexts: These methods include the tuning of the cache line sizes [Przybylski90], prefetching [Farrens89, Hill87, Smith78, Smith92], pipelining 1. During the past three ISCAs, over two thirds of the papers dealing with uniprocessor architecture issues used the SPEC benchmarks [ISCA92, ISCA93, ISCA94]. 3 <ref> [Jouppi90, Olukotun92, Palcharla94] </ref> and bypassing [Hennessy90]. There are also software-based methods for improving I-cache performance. Compilers can reduce conict misses by carefully placing procedures in memory with the assistance of execution-profile information and through call-graph analysis [Hwu89, McFarling89, Torrellas95]. <p> After arriving at an optimized L2 design, we consider how bandwidth, prefetching, bypassing and pipelining the L1-L2 interface can further improve performance. Throughout this section, we draw on the work of numerous researchers who have explored various instruction-fetching techniques, including multi-level caching, prefetching and pipelined-memory systems <ref> [Farrens89, Hill87, Kessler91, Jouppi90, Jouppi94, Olukotun92, Przybylski,89, Smith78, Smith82] </ref>. This work uses IBS to compare and evaluate these various architectural mechanisms under a more challenging workload. Throughout this analysis, we only consider instruction references.
Reference: [Ousterhout94] <author> Ousterhout, J. K. </author> <title> Tcl and the Tk Toolkit. </title> <publisher> Addi-son-Wesley Publishing Company, </publisher> <year> 1994. </year>
Reference-contexts: The dominant window system in UNIX-based workstations is X11 [Scheier86], which includes an X display server, a window manager and a set of application-linked libraries that implement the core X calls and higher-level graphical objects such as the tk widget set <ref> [Ousterhout94] </ref>. The use of any X application implies that all of these layers of code will be activated, increasing instruction path lengths over workloads with simple textual user interfaces.
Reference: [Palcharla94] <author> Palcharla, S. and Kessler, R. E. </author> <title> Evaluating stream buffers as a secondary cache replacement, </title> <booktitle> In The 21st Annual International Symposium on Computer Architecture, </booktitle> <address> Chicago, Illinois, </address> <publisher> IEEE, </publisher> <pages> 24-33, </pages> <year> 1994. </year>
Reference-contexts: These methods include the tuning of the cache line sizes [Przybylski90], prefetching [Farrens89, Hill87, Smith78, Smith92], pipelining 1. During the past three ISCAs, over two thirds of the papers dealing with uniprocessor architecture issues used the SPEC benchmarks [ISCA92, ISCA93, ISCA94]. 3 <ref> [Jouppi90, Olukotun92, Palcharla94] </ref> and bypassing [Hennessy90]. There are also software-based methods for improving I-cache performance. Compilers can reduce conict misses by carefully placing procedures in memory with the assistance of execution-profile information and through call-graph analysis [Hwu89, McFarling89, Torrellas95].
Reference: [Patel92] <author> Patel, K., Smith, B. C. and Rowe, L. A. </author> <title> Performance of a Software MPEG Video Decoder. </title> <institution> University of Cali-fornia, Berkeley. </institution> <year> 1992. </year>
Reference-contexts: The Workload Description mpeg_play mpeg_play (version 2.0) from the Berkeley Plateau Research Group. Displays 85 frames from a com pressed video file <ref> [Patel92] </ref>. jpeg_play The xloadimage (version 3.0) program written by Jim Frost. Displays two JPEG images. gs Ghostscript (version 2.4.1) distributed by the Free Software Foundation.
Reference: [Przybylski89] <author> Przybylski, S., Horowitz, M. and Hennessy, J. </author> <title> Characteristics of performance-optimal multi-level cache hierarchies, </title> <booktitle> In Proc. 16th Annual International Symposium on Computer Architecture, Jerusalem, Israel, </booktitle> <pages> 114-121, </pages> <year> 1989. </year>
Reference-contexts: Several hardware-based methods have been proposed to reduce the penalty of misses in small, direct-mapped primary I-caches. The most straightforward is to add a second level of cache, either on or off chip, to reduce time-consuming references to main memory <ref> [Short88, Baer87, Baer88, Przybylski89, Przybylski90, Happel92, Kessler91, Olukotun91, Jouppi94, Wang89] </ref>. Other methods focus on optimizing the interface from the primary I-cache to the next level in the memory hierarchy, whether it be a second-level cache, or main memory.
Reference: [Przybylski90] <author> Przybylski, S. </author> <title> The performance impact of block sizes and fetching strategies, </title> <booktitle> In Proceedings of the 16th Annual International Symposium on Computer Architecture, </booktitle> <address> Seattle, WA, </address> <publisher> IEEE, </publisher> <pages> 160-169, </pages> <year> 1990. </year>
Reference-contexts: Several hardware-based methods have been proposed to reduce the penalty of misses in small, direct-mapped primary I-caches. The most straightforward is to add a second level of cache, either on or off chip, to reduce time-consuming references to main memory <ref> [Short88, Baer87, Baer88, Przybylski89, Przybylski90, Happel92, Kessler91, Olukotun91, Jouppi94, Wang89] </ref>. Other methods focus on optimizing the interface from the primary I-cache to the next level in the memory hierarchy, whether it be a second-level cache, or main memory. <p> Other methods focus on optimizing the interface from the primary I-cache to the next level in the memory hierarchy, whether it be a second-level cache, or main memory. These methods include the tuning of the cache line sizes <ref> [Przybylski90] </ref>, prefetching [Farrens89, Hill87, Smith78, Smith92], pipelining 1. During the past three ISCAs, over two thirds of the papers dealing with uniprocessor architecture issues used the SPEC benchmarks [ISCA92, ISCA93, ISCA94]. 3 [Jouppi90, Olukotun92, Palcharla94] and bypassing [Hennessy90]. There are also software-based methods for improving I-cache performance.
Reference: [Rozier92] <author> Rozier, M., Abrossimov, V., Armand, F., Boule, I., Gien, M., Guillemont, M., Herrman, F., Kaise, C., Langlois, S., Leonard, P. and Neuhauser, W. </author> <title> Overview of the Chorus distributed operating system, In Micro-kernels and Other Kernel Architectures, </title> <address> Seattle, Washington, </address> <publisher> USENIX, </publisher> <pages> 39-69, </pages> <year> 1992. </year>
Reference-contexts: Porting an application to a different operating system requires that it be rewritten to use the application-procedure interfaces or APIs of the new host OS. To simplify this process, some operating systems, such as Windows NT [Custer93], Mach 3.0 [Accetta86], and others <ref> [Bomberger92, Cheriton84, Malan91, Rozier92, Wiecek92] </ref> have been designed to emulate multiple APIs. Overhead due to API emulation is represented in IBS through the use of a 4.3 BSD emulation library that is dynamically linked into the address space of each user application.
Reference: [Scheier86] <author> Scheier, R. and Gettys, J. </author> <title> The X window system. </title> <journal> ACM Transactions on Graphics 5 (2): </journal> <pages> 79-109, </pages> <year> 1986. </year>
Reference-contexts: Such features are usually implemented with the help of multiple layers of system software that comprise a window system. The dominant window system in UNIX-based workstations is X11 <ref> [Scheier86] </ref>, which includes an X display server, a window manager and a set of application-linked libraries that implement the core X calls and higher-level graphical objects such as the tk widget set [Ousterhout94].
Reference: [Short88] <author> Short, R. and Levy, H. </author> <title> A simulation study of two-level caches, </title> <booktitle> In Proc. 15th Annual International Symposium on Computer Architecture, Honolulu, Hawaii, </booktitle> <pages> 81-88, </pages> <year> 1988. </year>
Reference-contexts: Several hardware-based methods have been proposed to reduce the penalty of misses in small, direct-mapped primary I-caches. The most straightforward is to add a second level of cache, either on or off chip, to reduce time-consuming references to main memory <ref> [Short88, Baer87, Baer88, Przybylski89, Przybylski90, Happel92, Kessler91, Olukotun91, Jouppi94, Wang89] </ref>. Other methods focus on optimizing the interface from the primary I-cache to the next level in the memory hierarchy, whether it be a second-level cache, or main memory.
Reference: [Sites88] <author> Sites, R. L. and Agarwal, A. </author> <title> Multiprocessor cache analysis with ATUM, </title> <booktitle> In The 15th Annual International Symposium on Computer Architecture, Honolulu, Hawaii, IEEE, </booktitle> <pages> 186-195, </pages> <year> 1988. </year>
Reference-contexts: Increased associativity improves miss rates by reducing con-ict misses. As a result, associativity also reduces variability in performance caused by OS page-mapping effects in a physically-indexed cache <ref> [Kessler91, Sites88] </ref>. Figure 5 shows that the amount of variability is a function of the workload, cache size and associativity.
Reference: [Sites92] <author> Sites, R., Chernoff, A., Kirk, M., Marks, M. and Robinson, S. </author> <title> Binary translation. </title> <journal> Digital Technical Journal 4 (4): </journal> <pages> 137-152, </pages> <year> 1992. </year>
Reference-contexts: ABI emulation is sometimes used to ease the transition from an older processor architecture to a newer one. For example, DEC implements ABI emulation by statically translating VAX and MIPS binaries into Alpha binaries <ref> [Sites92] </ref>. Apple uses a similar strategy to dynamically translate 68040 binaries to the PowerPC architecture [Koch94]. Several other examples of ABI emulators are given in [Cmelik94]. ABI emulation causes code bloat because several host instructions are usually required to emulate a single source instruction.
Reference: [Smith78] <author> Smith, A. J. </author> <title> Sequential program prefetching in memory hierarchies. </title> <booktitle> IEEE Computer 11 (12): </booktitle> <pages> 7-21, </pages> <year> 1978. </year>
Reference-contexts: Other methods focus on optimizing the interface from the primary I-cache to the next level in the memory hierarchy, whether it be a second-level cache, or main memory. These methods include the tuning of the cache line sizes [Przybylski90], prefetching <ref> [Farrens89, Hill87, Smith78, Smith92] </ref>, pipelining 1. During the past three ISCAs, over two thirds of the papers dealing with uniprocessor architecture issues used the SPEC benchmarks [ISCA92, ISCA93, ISCA94]. 3 [Jouppi90, Olukotun92, Palcharla94] and bypassing [Hennessy90]. There are also software-based methods for improving I-cache performance. <p> After arriving at an optimized L2 design, we consider how bandwidth, prefetching, bypassing and pipelining the L1-L2 interface can further improve performance. Throughout this section, we draw on the work of numerous researchers who have explored various instruction-fetching techniques, including multi-level caching, prefetching and pipelined-memory systems <ref> [Farrens89, Hill87, Kessler91, Jouppi90, Jouppi94, Olukotun92, Przybylski,89, Smith78, Smith82] </ref>. This work uses IBS to compare and evaluate these various architectural mechanisms under a more challenging workload. Throughout this analysis, we only consider instruction references. <p> However, stream-buffer performance might be further improved by implementing multiple stream buffers and switching between the stream buffers on subroutine jumps. This would be particularly useful for short leaf-node function calls. Another optimization would be to add a target prefetch table <ref> [Smith78] </ref>. This table would store the addresses of non-sequential pairs of lines. As 1. Pipelining the memory system also allows data references to be mixed with prefetch requests.
Reference: [Smith82] <author> Smith, A. J. </author> <title> Cache Memories. </title> <booktitle> Computing Surveys 14 (3): </booktitle> <pages> 473-530, </pages> <year> 1982. </year>
Reference-contexts: After arriving at an optimized L2 design, we consider how bandwidth, prefetching, bypassing and pipelining the L1-L2 interface can further improve performance. Throughout this section, we draw on the work of numerous researchers who have explored various instruction-fetching techniques, including multi-level caching, prefetching and pipelined-memory systems <ref> [Farrens89, Hill87, Kessler91, Jouppi90, Jouppi94, Olukotun92, Przybylski,89, Smith78, Smith82] </ref>. This work uses IBS to compare and evaluate these various architectural mechanisms under a more challenging workload. Throughout this analysis, we only consider instruction references. <p> Table 6 shows that for small line sizes, prefetching can significantly improve performance. The table also shows a result previously noted by Smith <ref> [Smith82] </ref>: prefetching over multiple small lines yields better performance than implementing a cache with longer lines. For example, the cache with the 64-byte line has a CPI instr of 0.297 while the cache with the 16-byte line and 3 prefetched lines has a lower CPI instr of 0.260.
Reference: [Smith85] <author> Smith, A. J. </author> <title> Cache evaluation and the impact on workload choice, </title> <booktitle> In 12th International Symposium on Computer Architecture, </booktitle> <address> Boston, Mass., </address> <publisher> IEEE, </publisher> <pages> 64-73, </pages> <year> 1985. </year>
Reference-contexts: 1 Introduction It has long been recognized that the best selection of memory-system parameters, such as cache size, associativity and line size, is highly dependent on the workload that a machine is expected to support <ref> [Smith85] </ref>. Because application and operating system code continually evolves over time to incorporate new functions, and because memory technologies are constantly changing in capability and cost, it follows that memory-system parameters must be periodically re-evaluated to achieve the best possible performance.
Reference: [Smith92] <author> Smith, J. E. and Hsu, W.-C. </author> <title> Prefetching in supercomputer instruction caches, </title> <booktitle> In Supercomputing 92, </booktitle> <pages> 588-597, </pages> <year> 1992. </year>
Reference-contexts: Other methods focus on optimizing the interface from the primary I-cache to the next level in the memory hierarchy, whether it be a second-level cache, or main memory. These methods include the tuning of the cache line sizes [Przybylski90], prefetching <ref> [Farrens89, Hill87, Smith78, Smith92] </ref>, pipelining 1. During the past three ISCAs, over two thirds of the papers dealing with uniprocessor architecture issues used the SPEC benchmarks [ISCA92, ISCA93, ISCA94]. 3 [Jouppi90, Olukotun92, Palcharla94] and bypassing [Hennessy90]. There are also software-based methods for improving I-cache performance. <p> To add an additional degree of confidence to our measurements and to take into account inherent variations in performance due to operating system effects, we use a trap-driven simulator called Tapeworm II [Uhlig94]. We adopt a simple performance model based on cycles-per-instruction (CPI) that focuses on instruction-fetching performance <ref> [Emer84, Hennessey90, Smith92] </ref>: where CPI instr is performance lost to I-cache misses and CPI other is determined by the instruction-issue rate and all other sources of processor stalls, such D-cache misses, TLB misses, CPU pipeline interlocks and issue constraints.
Reference: [SPEC91] <author> SPEC. </author> <title> The SPEC Benchmark Suite. </title> <journal> SPEC Newsletter. </journal> <volume> 3: </volume> <pages> 3-4, </pages> <year> 1991. </year>
Reference-contexts: These hardware and software trends are particularly demanding of instruction caches because code bloat can increase the active instruction working-set sizes that CPU caches must retain close to the processor. When CPU performance is reported in terms of SPECmarks <ref> [SPEC91] </ref>, the effects of code bloat on system performance in an actual work environment are not revealed for two reasons.
Reference: [SPEC93] <author> SPEC. </author> <title> SPEC: A five year retrospective. </title> <booktitle> The SPEC Newsletter 5 (4): </booktitle> <pages> 1-4, </pages> <year> 1993. </year>
Reference-contexts: Despite its popularity for evaluating a wide range of architectural structures, SPEC warns against the use of the SPEC89 or SPEC92 benchmarks for testing memory or I/O performance <ref> [SPEC93] </ref>.
Reference: [Taylor90] <author> Taylor, G., Davies, P. and Farmwald, M. </author> <title> The TLB slice A low-cost high-speed address translation mechanism, </title> <booktitle> In The 17th Annual International Symposium on Computer Architecture, </booktitle> <pages> 355-363, </pages> <year> 1990. </year>
Reference: [Torrellas92] <author> Torrellas, J., Gupta, A. and Hennessy, J. </author> <title> Characterizing the caching and synchronization performance of multiprocessor operating system, </title> <booktitle> In Fifth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <address> Boston, Massachusetts, </address> <publisher> ADM, </publisher> <pages> 162-174, </pages> <year> 1992. </year>
Reference: [Torrellas95] <author> Torrellas, J., Xia, C. and Daigle, R. </author> <title> Optimizing instruction cache performance for operating system intensive workloads, </title> <booktitle> In The 1st International Symposium on High-Performance Computer Architecture (HPCA), </booktitle> <address> Raleigh, North Carolina, </address> <note> to appear, </note> <year> 1995. </year>
Reference-contexts: There are also software-based methods for improving I-cache performance. Compilers can reduce conict misses by carefully placing procedures in memory with the assistance of execution-profile information and through call-graph analysis <ref> [Hwu89, McFarling89, Torrellas95] </ref>. When a cache is physically-indexed and larger than the page size, operating systems can implement page-allocation algorithms that more evenly distribute pages in the cache to help prevent conict misses [Bray90, Kessler92, Bershad94].
Reference: [Touma92] <author> Touma, W. R. </author> <title> The Dynamics of the Computer Industry. </title> <institution> University of Texas at Austin. </institution> <year> 1993. </year>
Reference-contexts: Improvements in memory technology can offset some of these trends. For example, main-memory DRAMs have quadrupled in size roughly every 2 to 3 years and their price has dropped steadily from about $800 per megabyte in 1986 to a current price of about $40 per megabyte <ref> [Touma92] </ref>. Magnetic disk drives have exhibited similar improvements in capacity and reduction in cost [Touma92]. However, technology trends have resulted in more complex trade-offs in the case of TLBs and caches. <p> For example, main-memory DRAMs have quadrupled in size roughly every 2 to 3 years and their price has dropped steadily from about $800 per megabyte in 1986 to a current price of about $40 per megabyte <ref> [Touma92] </ref>. Magnetic disk drives have exhibited similar improvements in capacity and reduction in cost [Touma92]. However, technology trends have resulted in more complex trade-offs in the case of TLBs and caches. Although continued advancements in integrated-circuit densities make it possible to allocate more die area to on-chip cache structures, reductions in cycle times constrain the maximum size and associativity of primary on-chip caches [Jouppi94].
Reference: [Uhlig94] <author> Uhlig, R., Nagle, D., Sechrest, S. and Mudge, T. </author> <title> Trap-driven simulation with tapeworm II. </title> <booktitle> In the 6th International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <address> San Jose, California, </address> <publisher> ACM Press (SIGARCH), </publisher> <pages> 132-144, </pages> <year> 1994. </year>
Reference-contexts: To add an additional degree of confidence to our measurements and to take into account inherent variations in performance due to operating system effects, we use a trap-driven simulator called Tapeworm II <ref> [Uhlig94] </ref>.
Reference: [Wada92] <author> Wada, T., Rajan, S. and Przybylski, S. </author> <title> An analytical access time model for on-chip cache memories. </title> <journal> IEEE Journal of Solid-State Circuits 27 (8): </journal> <pages> 1147-1156, </pages> <year> 1992. </year>
Reference-contexts: This is true because for a given integrated-circuit technology, increasing cache size and associativity increases access times <ref> [Olukutun92, Wada92, Wilton94] </ref>. As a result, the primary caches in processors that have targeted fast cycle times (100+ MHz) in recent years tend to have low associativity and are limited to 4KB to 16KB [MReport93, MReport94].
Reference: [Wang89] <author> Wang, W.-H., Baer, J.-L. and Levy, H. </author> <title> Organization and performance of a two-level virtual-real cache hierarchy, </title> <booktitle> In The 16th Annual International Symposium on Computer Architecture, </booktitle> <address> Jerusalem, Israel, </address> <publisher> IEEE Computer Society Press (ACM SIGARCH), </publisher> <pages> 140-148, </pages> <year> 1989. </year>
Reference-contexts: Several hardware-based methods have been proposed to reduce the penalty of misses in small, direct-mapped primary I-caches. The most straightforward is to add a second level of cache, either on or off chip, to reduce time-consuming references to main memory <ref> [Short88, Baer87, Baer88, Przybylski89, Przybylski90, Happel92, Kessler91, Olukotun91, Jouppi94, Wang89] </ref>. Other methods focus on optimizing the interface from the primary I-cache to the next level in the memory hierarchy, whether it be a second-level cache, or main memory.
Reference: [Wiecek92] <author> Wiecek, C. A., Kaler, C. G., Fiorelli, S., Davenport, W. C. and Chen, R. C. </author> <title> A Model and Prototype of VMS Using the Mach 3.0 Kernel, </title> <booktitle> In USENIX Micro-kernels and Other Kernel Architectures Workshop, </booktitle> <address> Seattle, Washington, </address> <publisher> USENIX, </publisher> <pages> 187-203, </pages> <year> 1992. </year>
Reference-contexts: Porting an application to a different operating system requires that it be rewritten to use the application-procedure interfaces or APIs of the new host OS. To simplify this process, some operating systems, such as Windows NT [Custer93], Mach 3.0 [Accetta86], and others <ref> [Bomberger92, Cheriton84, Malan91, Rozier92, Wiecek92] </ref> have been designed to emulate multiple APIs. Overhead due to API emulation is represented in IBS through the use of a 4.3 BSD emulation library that is dynamically linked into the address space of each user application.
Reference: [Wilton94] <author> Wilton, S. and Jouppi, N. </author> <title> An enhanced access and cycle time model for on-chip caches. </title> <institution> DEC Western Research Lab. </institution> <month> 93/5. </month> <year> 1994. </year>
Reference-contexts: This is true because for a given integrated-circuit technology, increasing cache size and associativity increases access times <ref> [Olukutun92, Wada92, Wilton94] </ref>. As a result, the primary caches in processors that have targeted fast cycle times (100+ MHz) in recent years tend to have low associativity and are limited to 4KB to 16KB [MReport93, MReport94]. <p> This would increase the L1 contribution to CPI instr from 0.34 to 0.38. It is also possible that the increase would be small enough so as not to impact the latency. Przybylski [Przybylski88] and Wilton <ref> [Wilton94] </ref> present detailed models that more accurately account for these effects. 9 A final advantage of associativity is that it allows designers to add cache memory in increments smaller than a power of two. <p> Second, the reduction in area reduces the cache access time. The Mulder area model predicts a 10% reduction in area when moving from a 16-byte to a 64-byte line (8-KB, direct-mapped cache) [Mulder91], while the Wilton and Jouppi timing model shows a 6% decrease in access time <ref> [Wilton94] </ref>. The incremental improvements due to increasing bandwidth begin to diminish for rates greater than 16 bytes/cycle. Moreover, building large cache busses (&gt; 128 bits) can consume a significant amount of chip area and possibly impact the overall cache size.
References-found: 74

