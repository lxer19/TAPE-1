URL: http://www.cs.ucsb.edu/~yfwang/courses/cs595j/98fall/papers/invariants.ps.gz
Refering-URL: http://www.cs.ucsb.edu/~yfwang/courses/cs595j/98fall/index.html
Root-URL: http://www.cs.ucsb.edu
Email: E-mail: fronald,yfwangg@cs.ucsb.edu  
Title: Geometric and Illumination Invariants for Object Recognition  
Author: Ronald Alferez and Yuan-Fang Wang 
Address: Santa Barbara, CA 93106  
Affiliation: Department of Computer Science University of California  
Abstract: We propose invariant formulations that can potentially be combined into a single system. In particular, we describe a framework for computing invariant features which are insensitive to rigid motion, affine transform, changes of parameterization and scene illumination, perspective transform, and view point change. This is unlike most current research on image invariants which concentrates on either geometric or illumination invariants exclusively. The formulations are widely applicable to many popular basis representations, such as wavelets [3, 4, 24, 25], short-time Fourier analysis [13, 35], and splines [2, 5, 37]. Exploiting formulations that examine information about shape and color at different resolution levels, the new approach is neither strictly global nor local. It enables a quasi-localized, hierarchical shape analysis which is rarely found in other known invariant techniques, such as global invariants. Furthermore, it does not require estimating high-order derivatives in computing invariants (unlike local invariants), whence is more robust. We provide results of numerous experiments on both synthetic and real data to demonstrate the validity and flexibility of the proposed framework.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> K. Arbter, W. E. Snyder, H. Burkhardt, and G. Hirzinger. </author> <title> Application of Affine-Invariant Fourier Descriptors to Recognition of 3-D Objects. </title> <journal> IEEE Trans. Pattern Analy. Machine Intell., </journal> <volume> 12 </volume> <pages> 640-647, </pages> <year> 1990. </year>
Reference-contexts: Similarly, many have focused their research on illumination invariants. A few have attempted to combine the two. Invariants under affine transformations have been studied by [20] using Hough-based methods, 2 (a) (b) (c) dimensions. by <ref> [1, 30] </ref> using Fourier descriptors, and by [43] using wavelets. In these cases, affine invariants were used to recognize planar objects in 3D space. Orthographic projection was used to approximate perspective projection, and the "shear" effect in affine transformations modeled perspective distortion. <p> Intrinsic arc length transforms linearly under any linear transformation. Translation and rotation do not affect the arc length, and scaling only scales the parameter accordingly. However, under affine transformation, the arc length parameter is nonlinearly transformed <ref> [1] </ref>. A more suitable parameterization is thus required. We describe two parameterizations which are linear under an affine transformation. <p> If the points along the curve is discretized (say into pixels), the curve becomes a polyline (or polygon if enclosed). The effect is a parameterization which is zero along the sides of the polyline, and infinite at the vertices. To avoid this, <ref> [1] </ref> using a first order form, defined a second parameter which some later called the enclosed area parameter: = 2 a The drawback here is that this parameter is not invariant to translation, and requires a closed contour.
Reference: [2] <author> W. Bohm, G. Farin, and J. Kahmann. </author> <title> A Survey of Curve and Surface Methods in CAGD. </title> <booktitle> Comput. Aided Geometric Des., </booktitle> <pages> pages 1-60, </pages> <year> 1984. </year>
Reference-contexts: Whence, the new method is more robust. 5.) We introduce the use of rational basis functions to facilitate the analysis of invariants under perspective transform. Rational basis functions, such as NURBS, have been widely used in the computer graphics community <ref> [2, 5, 10, 33, 44] </ref>. However, their usage in perspective invariants is novel. The remainder of this paper is organized as follows: Sec. 2 reviews related work done in the past, Sec. 3 presents the framework of image-derived invariants. <p> Hence, the transformed curve can be generated using the transformed wavelet coefficients and the same wavelet bases, instead of transforming the curve point-by-point. This is an observation which is commonly made in the computer graphics community about curves generated by the spline functions and associated control vertices <ref> [2, 5, 37] </ref>. <p> The projection process can be linearized using a tool which is well-established in computer graphics, the rational form of a basis function <ref> [2, 5, 10, 33, 44] </ref>. The most famous of such an expression is probably NURBS (Non-Uniform Rational B-Spline), which was adopted as a standard for IGES (Initial Graphics Exchange Specification) [18].
Reference: [3] <editor> J. M. Combes, A. Grossman, and Ph. Tchamitchian (Eds.). </editor> <title> Wavelets: Time-Frequency Methods and Phase Space, 2nd ed. </title> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1990. </year>
Reference-contexts: We propose to use the framework with wavelet, short-time Fourier analysis, and spline bases, which have been widely used in signal and speech processing, image analysis, computer vision, and computer graphics <ref> [3, 4, 5, 24, 25, 35, 37] </ref>. 4.) It ameliorates some difficulties encountered in computing global or local image invariants. We employ basis functions of a compact support (wavelets, short-time Fourier analysis, and splines).
Reference: [4] <author> I. Daubechies. </author> <title> Orthonormal Bases of Compactly Supported Wavelets. </title> <journal> Commun. Pure Appl. Math., </journal> <volume> 41 </volume> <pages> 909-960, </pages> <year> 1988. </year>
Reference-contexts: We propose to use the framework with wavelet, short-time Fourier analysis, and spline bases, which have been widely used in signal and speech processing, image analysis, computer vision, and computer graphics <ref> [3, 4, 5, 24, 25, 35, 37] </ref>. 4.) It ameliorates some difficulties encountered in computing global or local image invariants. We employ basis functions of a compact support (wavelets, short-time Fourier analysis, and splines). <p> Affine Transform Consider a 2D curve, where t denotes a parameterization which is invariant under affine transform (as described above), c (t) = x (t) # and its expansion onto the wavelet basis a;b = 1 p a g ( tb a ) (where g (t) is the mother wavelet <ref> [4] </ref>) as u a;b = c a;b dt : If the curve is allowed a general affine transform with the transformed curve denoted by: c 0 (t) = mc + t = m x (t) # where m is any nonsingular 2 fi 2 matrix and t represents the translational motion,
Reference: [5] <author> C. deBoor. </author> <title> A Practical Guide to Spline. </title> <publisher> Springer-Verlag, </publisher> <address> New York/Berlin, </address> <year> 1978. </year>
Reference-contexts: We propose to use the framework with wavelet, short-time Fourier analysis, and spline bases, which have been widely used in signal and speech processing, image analysis, computer vision, and computer graphics <ref> [3, 4, 5, 24, 25, 35, 37] </ref>. 4.) It ameliorates some difficulties encountered in computing global or local image invariants. We employ basis functions of a compact support (wavelets, short-time Fourier analysis, and splines). <p> Whence, the new method is more robust. 5.) We introduce the use of rational basis functions to facilitate the analysis of invariants under perspective transform. Rational basis functions, such as NURBS, have been widely used in the computer graphics community <ref> [2, 5, 10, 33, 44] </ref>. However, their usage in perspective invariants is novel. The remainder of this paper is organized as follows: Sec. 2 reviews related work done in the past, Sec. 3 presents the framework of image-derived invariants. <p> Hence, the transformed curve can be generated using the transformed wavelet coefficients and the same wavelet bases, instead of transforming the curve point-by-point. This is an observation which is commonly made in the computer graphics community about curves generated by the spline functions and associated control vertices <ref> [2, 5, 37] </ref>. <p> The projection process can be linearized using a tool which is well-established in computer graphics, the rational form of a basis function <ref> [2, 5, 10, 33, 44] </ref>. The most famous of such an expression is probably NURBS (Non-Uniform Rational B-Spline), which was adopted as a standard for IGES (Initial Graphics Exchange Specification) [18].
Reference: [6] <author> S. J. Dickinson, A. Pentland, and A. Rosenfeld. </author> <title> 3-D Shape Recovery Using Distributed Aspect Matching. </title> <journal> IEEE Trans. Pattern Analy. Machine Intell., </journal> <volume> 14(2) </volume> <pages> 174-198, </pages> <year> 1992. </year>
Reference-contexts: The need for invariant image descriptors has long been recognized in computer vision [36, 47]. Invariant features form a compact, intrinsic description of an object, and can be used to design recognition algorithms that are potentially more efficient than, say, aspect-based approaches <ref> [6, 8, 9] </ref>. Hence, it was even argued that object recognition is the search for invariants [47]. Image invariants can be designed to fit the needs of specific systems. Some require only that it be non-discriminating to an object's geometric pose or orientation.
Reference: [7] <author> L. E. Dickson. </author> <title> Algebraic Invariants. </title> <publisher> John-Wiley & Sons, </publisher> <year> 1914. </year>
Reference-contexts: 1 Introduction Image features and shape descriptors that capture the essential traits of an object and are insensitive to environmental changes are ideal for recognition. The search for invariants (e.g., algebraic and projective invariants) is a classical problem in mathematics dating back to the 18th century <ref> [7, 21, 36] </ref>. The need for invariant image descriptors has long been recognized in computer vision [36, 47]. Invariant features form a compact, intrinsic description of an object, and can be used to design recognition algorithms that are potentially more efficient than, say, aspect-based approaches [6, 8, 9].
Reference: [8] <author> D. Eggert and K. Bowyer. </author> <title> Computing the Perspective Projection Aspect Graph of Solids of Revolution. </title> <journal> IEEE Trans. Pattern Analy. Machine Intell., </journal> <volume> 15(2) </volume> <pages> 109-128, </pages> <year> 1993. </year>
Reference-contexts: The need for invariant image descriptors has long been recognized in computer vision [36, 47]. Invariant features form a compact, intrinsic description of an object, and can be used to design recognition algorithms that are potentially more efficient than, say, aspect-based approaches <ref> [6, 8, 9] </ref>. Hence, it was even argued that object recognition is the search for invariants [47]. Image invariants can be designed to fit the needs of specific systems. Some require only that it be non-discriminating to an object's geometric pose or orientation.
Reference: [9] <author> D. Eggert, K. Bowyer, C. R. Dyer, and H. I. Christensen. </author> <title> The Scale Space Aspect Graph. </title> <journal> IEEE Trans. Pattern Analy. Machine Intell., </journal> <volume> 15(11) </volume> <pages> 1114-1130, </pages> <year> 1993. </year>
Reference-contexts: The need for invariant image descriptors has long been recognized in computer vision [36, 47]. Invariant features form a compact, intrinsic description of an object, and can be used to design recognition algorithms that are potentially more efficient than, say, aspect-based approaches <ref> [6, 8, 9] </ref>. Hence, it was even argued that object recognition is the search for invariants [47]. Image invariants can be designed to fit the needs of specific systems. Some require only that it be non-discriminating to an object's geometric pose or orientation.
Reference: [10] <author> G. Farin. </author> <title> Algorithms for Rational Bezier Curves. </title> <journal> Comput. Aided Des., </journal> <volume> 15(2) </volume> <pages> 73-77, </pages> <month> Mar. </month> <year> 1983. </year>
Reference-contexts: Whence, the new method is more robust. 5.) We introduce the use of rational basis functions to facilitate the analysis of invariants under perspective transform. Rational basis functions, such as NURBS, have been widely used in the computer graphics community <ref> [2, 5, 10, 33, 44] </ref>. However, their usage in perspective invariants is novel. The remainder of this paper is organized as follows: Sec. 2 reviews related work done in the past, Sec. 3 presents the framework of image-derived invariants. <p> The projection process can be linearized using a tool which is well-established in computer graphics, the rational form of a basis function <ref> [2, 5, 10, 33, 44] </ref>. The most famous of such an expression is probably NURBS (Non-Uniform Rational B-Spline), which was adopted as a standard for IGES (Initial Graphics Exchange Specification) [18].
Reference: [11] <author> J. D. Foley, A. van Dam, S. K. Feiner, and J. F. Hughes. </author> <title> Computer Graphics: </title> <booktitle> Principles and Practice, 2nd ed. </booktitle> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1990. </year>
Reference-contexts: Illumination invariants have been applied to recognize textures [17], 3D objects [39], and 3D textures [19]. A physics-based approach is used in [29], to produce illumination invariants from infrared imagery. Many, including our proposed technique, assumes a Lambertian <ref> [11] </ref> surface model for simplicity. There has been limited success in combining geometric and illumination invariants. For instance, Slater and Healey [39] used local color invariants to recognize 3D objects. <p> Based on a Lambertian model <ref> [11] </ref>, s (; t) is s (; t) = ( i=1 where n is the number of light sources used to illuminate the scene, l i () the source luminance spectral distribution, N the surface normal, N i the incident direction for source i, (; t) the surface reflectivity, and a
Reference: [12] <author> D. Forsyth. </author> <title> A Novel Algorithm for Color Constancy. </title> <journal> Int. J. Comput. Vision, </journal> <volume> 5 </volume> <pages> 5-36, </pages> <year> 1990. </year>
Reference-contexts: Lei [22] demonstrated how cross ratios can be used to recognize planar objects in 3D space. In this case, "true" perspective invariants were formulated. However, objects were restricted to polygons and required accurate identification of vertex positions. Illumination invariants have also been studied extensively in <ref> [12, 16, 15, 27, 28, 29, 40, 41, 46] </ref>. These invariants allowed for changes that may include altering the position and number of light sources, the brightness and contrast, and even hue. Illumination invariants have been applied to recognize textures [17], 3D objects [39], and 3D textures [19].
Reference: [13] <author> D. </author> <title> Gabor. </title> <journal> Theory of Communication. J. Inst. Elec. Eng., </journal> <volume> 93 </volume> <pages> 429-457, </pages> <year> 1946. </year>
Reference: [14] <author> H. W. Guggenheimer. </author> <title> Differential Geometry. </title> <publisher> McGraw-Hill, </publisher> <address> New York, </address> <year> 1963. </year>
Reference-contexts: However, under affine transformation, the arc length parameter is nonlinearly transformed [1]. A more suitable parameterization is thus required. We describe two parameterizations which are linear under an affine transformation. The first, called affine arc length, is defined <ref> [14] </ref> as: t = a _xy x _y dt where _x; _y are the first and x; y are the second derivatives with respect to any parameter t (possibly the arc length), and (a; b) is the path along a segment of the curve.
Reference: [15] <author> G. Healey and A. Jain. </author> <title> Using Physics-Based Invariant Representations for the Recognition of Regions in Multi-spectral Images. </title> <journal> In Proc. IEEE Comput. Soc. Conf. Comput. Vision and Pattern Recognit., </journal> <pages> pages 750-755, </pages> <address> San Francisco, CA, </address> <month> Jun. 96. </month>
Reference-contexts: Lei [22] demonstrated how cross ratios can be used to recognize planar objects in 3D space. In this case, "true" perspective invariants were formulated. However, objects were restricted to polygons and required accurate identification of vertex positions. Illumination invariants have also been studied extensively in <ref> [12, 16, 15, 27, 28, 29, 40, 41, 46] </ref>. These invariants allowed for changes that may include altering the position and number of light sources, the brightness and contrast, and even hue. Illumination invariants have been applied to recognize textures [17], 3D objects [39], and 3D textures [19]. <p> k ] fi fi fi [ u c 1 ;d 1 u c 2 ;d 2 u c k ;d k ] [ u c 1 ;d 1 u c 2 ;d 2 u c k ;d k ] fi : This derivation is in spirit similar to that of <ref> [15, 17] </ref>. By using a ratio expression, we obtain a much simpler and computationally efficient form of invariants which does not require computing the color correlation matrix and the singular value decomposition of such a matrix [15, 17]. 4 Conclusion In this paper we present a new framework for computing image <p> ;d k ] fi : This derivation is in spirit similar to that of <ref> [15, 17] </ref>. By using a ratio expression, we obtain a much simpler and computationally efficient form of invariants which does not require computing the color correlation matrix and the singular value decomposition of such a matrix [15, 17]. 4 Conclusion In this paper we present a new framework for computing image invariants. The framework utilizes many desirable properties of wavelet and basis expansion techniques, including the ability to analyze the shape and color at different resolution levels.
Reference: [16] <author> G. Healey and D. Slater. </author> <title> Global Color Constancy: Recognition of Objects by Use of Illumination-Invariant Properties of Color Distributions. </title> <journal> Opt. Soc. Am. A, </journal> <volume> 11(11) </volume> <pages> 3003-3010, </pages> <month> Nov. </month> <year> 1994. </year>
Reference-contexts: Lei [22] demonstrated how cross ratios can be used to recognize planar objects in 3D space. In this case, "true" perspective invariants were formulated. However, objects were restricted to polygons and required accurate identification of vertex positions. Illumination invariants have also been studied extensively in <ref> [12, 16, 15, 27, 28, 29, 40, 41, 46] </ref>. These invariants allowed for changes that may include altering the position and number of light sources, the brightness and contrast, and even hue. Illumination invariants have been applied to recognize textures [17], 3D objects [39], and 3D textures [19].
Reference: [17] <author> G. Healey and L. Wang. </author> <title> Illumination-Invariant Recognition of Texture in Color Images. </title> <journal> Opt. Soc. Am. A, </journal> <volume> 12(9) </volume> <pages> 1877-1883, </pages> <month> Sep. </month> <year> 1995. </year>
Reference-contexts: Illumination invariants have also been studied extensively in [12, 16, 15, 27, 28, 29, 40, 41, 46]. These invariants allowed for changes that may include altering the position and number of light sources, the brightness and contrast, and even hue. Illumination invariants have been applied to recognize textures <ref> [17] </ref>, 3D objects [39], and 3D textures [19]. A physics-based approach is used in [29], to produce illumination invariants from infrared imagery. Many, including our proposed technique, assumes a Lambertian [11] surface model for simplicity. There has been limited success in combining geometric and illumination invariants. <p> Following a path similar to that adopted by several researchers <ref> [17, 27, 28, 39] </ref>, we assume that reflected radiance functions are modeled as a linear combination of a small number of basis functions s k (), whence, s (; t) = k where s k () denotes the k-th basis function for representing the reflected radiance properties, and ff k (t) <p> k ] fi fi fi [ u c 1 ;d 1 u c 2 ;d 2 u c k ;d k ] [ u c 1 ;d 1 u c 2 ;d 2 u c k ;d k ] fi : This derivation is in spirit similar to that of <ref> [15, 17] </ref>. By using a ratio expression, we obtain a much simpler and computationally efficient form of invariants which does not require computing the color correlation matrix and the singular value decomposition of such a matrix [15, 17]. 4 Conclusion In this paper we present a new framework for computing image <p> ;d k ] fi : This derivation is in spirit similar to that of <ref> [15, 17] </ref>. By using a ratio expression, we obtain a much simpler and computationally efficient form of invariants which does not require computing the color correlation matrix and the singular value decomposition of such a matrix [15, 17]. 4 Conclusion In this paper we present a new framework for computing image invariants. The framework utilizes many desirable properties of wavelet and basis expansion techniques, including the ability to analyze the shape and color at different resolution levels.
Reference: [18] <author> IGES. </author> <title> Initial Graphics Exchange Specifications, </title> <type> Ver. </type> <institution> 3.0. Nat. Bur. of Stds., Gaithersburg, MD, </institution> <year> 1986. </year>
Reference-contexts: The most famous of such an expression is probably NURBS (Non-Uniform Rational B-Spline), which was adopted as a standard for IGES (Initial Graphics Exchange Specification) <ref> [18] </ref>. By using a rational basis form, we will show that perspective invariance can be verified efficiently and in a linear manner. We will use NURBS for illustration. In a nutshell, a b-spline function is a polynomial of a finite support.
Reference: [19] <author> R. Kondepudy and G. Healey. </author> <title> Use of Invariants for Recognition of Three-Dimensional Color Textures. </title> <journal> Opt. Soc. Am. A, </journal> <volume> 11(11) </volume> <pages> 3037-3049, </pages> <month> Nov. </month> <year> 1994. </year>
Reference-contexts: These invariants allowed for changes that may include altering the position and number of light sources, the brightness and contrast, and even hue. Illumination invariants have been applied to recognize textures [17], 3D objects [39], and 3D textures <ref> [19] </ref>. A physics-based approach is used in [29], to produce illumination invariants from infrared imagery. Many, including our proposed technique, assumes a Lambertian [11] surface model for simplicity. There has been limited success in combining geometric and illumination invariants.
Reference: [20] <author> Yehezkel Lamdan, Jacob T. Schwartz, and Haim J. Wolfson. </author> <title> Affine Invariant Model-Based Object Recognition. </title> <journal> IEEE Trans. Robot. and Automat., </journal> <volume> 6(5) </volume> <pages> 578-589, </pages> <year> 1990. </year>
Reference-contexts: Similarly, many have focused their research on illumination invariants. A few have attempted to combine the two. Invariants under affine transformations have been studied by <ref> [20] </ref> using Hough-based methods, 2 (a) (b) (c) dimensions. by [1, 30] using Fourier descriptors, and by [43] using wavelets. In these cases, affine invariants were used to recognize planar objects in 3D space.
Reference: [21] <author> E. P. Lane. </author> <title> Projective Differential Geometry of Curves and Surfaces. </title> <publisher> Univ. of Chicago Press, </publisher> <address> Chicago, IL, </address> <year> 1932. </year>
Reference-contexts: 1 Introduction Image features and shape descriptors that capture the essential traits of an object and are insensitive to environmental changes are ideal for recognition. The search for invariants (e.g., algebraic and projective invariants) is a classical problem in mathematics dating back to the 18th century <ref> [7, 21, 36] </ref>. The need for invariant image descriptors has long been recognized in computer vision [36, 47]. Invariant features form a compact, intrinsic description of an object, and can be used to design recognition algorithms that are potentially more efficient than, say, aspect-based approaches [6, 8, 9].
Reference: [22] <author> Guo Lei. </author> <title> Recognition of Planar Objects in 3-D Space from Single Perspective Views Using Cross Ratio. </title> <journal> IEEE Trans. Robot. and Automat., </journal> <volume> 6(4) </volume> <pages> 432-437, </pages> <year> 1990. </year>
Reference-contexts: Hence, the assumption is that the size of the observed object is small relative to its distance from the camera, i:e:; a weak perspective. Under large perspective distortion, however, a more rigorous treatment of perspective invariants is needed. Lei <ref> [22] </ref> demonstrated how cross ratios can be used to recognize planar objects in 3D space. In this case, "true" perspective invariants were formulated. However, objects were restricted to polygons and required accurate identification of vertex positions.
Reference: [23] <author> Simon X. Liao and Miroslaw Pawlak. </author> <title> On Image Analysis by Moments. </title> <journal> IEEE Trans. Pattern Analy. Machine Intell., </journal> <volume> 3 </volume> <pages> 254-266, </pages> <year> 1996. </year>
Reference-contexts: Properties of the wavelet transform are discussed in [45]. A comprehensive survey on the subject of invariants in general is presented by [36]. A review of geometric invariants is presented in [31, 47]. Other approaches to invariants and recognition are discussed in <ref> [34, 31, 23] </ref>.
Reference: [24] <author> S. G. Mallat. </author> <title> A Theory for Multiresolution Signal Decomposition: The Wavelet Representation. </title> <journal> IEEE Trans. Pattern Analy. Machine Intell., </journal> <volume> 11(7) </volume> <pages> 674-693, </pages> <year> 1989. </year>
Reference-contexts: We propose to use the framework with wavelet, short-time Fourier analysis, and spline bases, which have been widely used in signal and speech processing, image analysis, computer vision, and computer graphics <ref> [3, 4, 5, 24, 25, 35, 37] </ref>. 4.) It ameliorates some difficulties encountered in computing global or local image invariants. We employ basis functions of a compact support (wavelets, short-time Fourier analysis, and splines).
Reference: [25] <author> S. G. Mallat. </author> <title> Multifrequency Channel Decompositions of Images and Wavelet Models. </title> <journal> IEEE Trans. Acoust. Speech Signal Processing, </journal> <volume> 37 </volume> <pages> 2091-2110, </pages> <year> 1989. </year>
Reference-contexts: We propose to use the framework with wavelet, short-time Fourier analysis, and spline bases, which have been widely used in signal and speech processing, image analysis, computer vision, and computer graphics <ref> [3, 4, 5, 24, 25, 35, 37] </ref>. 4.) It ameliorates some difficulties encountered in computing global or local image invariants. We employ basis functions of a compact support (wavelets, short-time Fourier analysis, and splines).
Reference: [26] <author> S. G. Mallat. </author> <title> Zero-Crossings of a Wavelet Transform. </title> <journal> IEEE Trans. on Information Theory, </journal> <volume> 37(4) </volume> <pages> 1019-1033, </pages> <year> 1991. </year>
Reference-contexts: They used a similar technique in [43] to formulate affine invariants to recognize planar objects in 3D space. However, only a weak perspective was assumed. Recently, it has become popular to use wavelets (or quadrature mirror filters QMF's) in decomposing and representing signals at multiple scales <ref> [38, 26] </ref>. Indeed, we use wavelets to achieve multi-resolution analysis in our invariant formulation. However, one caveat in doing this is that orthogonal wavelets are critically sampled. They achieve representation through scaling and translation. <p> One remedy was proposed by Simoncelli, et. al. [38], where they define a shiftable transform in which the information represented within a subband remains in the same subband as the signal is translated. Another approach is described by Mallat <ref> [26] </ref>, wherein a signal uses the local extreme in its wavelet transform domain to make it invariant to time shifts. Properties of the wavelet transform are discussed in [45]. A comprehensive survey on the subject of invariants in general is presented by [36].
Reference: [27] <author> L. Maloney. </author> <title> Evaluation of Linear Models of Surface Spectral Reflectance with Small Number of Parameters. </title> <journal> Opt. Soc. Am. A, </journal> <volume> 3 </volume> <pages> 1673-1683, </pages> <year> 1986. </year> <month> 17 </month>
Reference-contexts: Lei [22] demonstrated how cross ratios can be used to recognize planar objects in 3D space. In this case, "true" perspective invariants were formulated. However, objects were restricted to polygons and required accurate identification of vertex positions. Illumination invariants have also been studied extensively in <ref> [12, 16, 15, 27, 28, 29, 40, 41, 46] </ref>. These invariants allowed for changes that may include altering the position and number of light sources, the brightness and contrast, and even hue. Illumination invariants have been applied to recognize textures [17], 3D objects [39], and 3D textures [19]. <p> Following a path similar to that adopted by several researchers <ref> [17, 27, 28, 39] </ref>, we assume that reflected radiance functions are modeled as a linear combination of a small number of basis functions s k (), whence, s (; t) = k where s k () denotes the k-th basis function for representing the reflected radiance properties, and ff k (t)
Reference: [28] <author> L. Maloney and B. Wandell. </author> <title> Color Constancy: A Method for Recovering Surface Spectral Reflectance. </title> <journal> Opt. Soc. Am. A, </journal> <volume> 3 </volume> <pages> 29-33, </pages> <year> 1986. </year>
Reference-contexts: Lei [22] demonstrated how cross ratios can be used to recognize planar objects in 3D space. In this case, "true" perspective invariants were formulated. However, objects were restricted to polygons and required accurate identification of vertex positions. Illumination invariants have also been studied extensively in <ref> [12, 16, 15, 27, 28, 29, 40, 41, 46] </ref>. These invariants allowed for changes that may include altering the position and number of light sources, the brightness and contrast, and even hue. Illumination invariants have been applied to recognize textures [17], 3D objects [39], and 3D textures [19]. <p> Following a path similar to that adopted by several researchers <ref> [17, 27, 28, 39] </ref>, we assume that reflected radiance functions are modeled as a linear combination of a small number of basis functions s k (), whence, s (; t) = k where s k () denotes the k-th basis function for representing the reflected radiance properties, and ff k (t)
Reference: [29] <author> J. Michel, N. Nandhakumar, and V. Velten. </author> <title> Thermophysical Algebraic Invariants from Infrared Imagery for Object Recognition. </title> <journal> IEEE Trans. Pattern Analy. Machine Intell., </journal> <volume> 19 </volume> <pages> 41-51, </pages> <year> 1987. </year>
Reference-contexts: Lei [22] demonstrated how cross ratios can be used to recognize planar objects in 3D space. In this case, "true" perspective invariants were formulated. However, objects were restricted to polygons and required accurate identification of vertex positions. Illumination invariants have also been studied extensively in <ref> [12, 16, 15, 27, 28, 29, 40, 41, 46] </ref>. These invariants allowed for changes that may include altering the position and number of light sources, the brightness and contrast, and even hue. Illumination invariants have been applied to recognize textures [17], 3D objects [39], and 3D textures [19]. <p> These invariants allowed for changes that may include altering the position and number of light sources, the brightness and contrast, and even hue. Illumination invariants have been applied to recognize textures [17], 3D objects [39], and 3D textures [19]. A physics-based approach is used in <ref> [29] </ref>, to produce illumination invariants from infrared imagery. Many, including our proposed technique, assumes a Lambertian [11] surface model for simplicity. There has been limited success in combining geometric and illumination invariants. For instance, Slater and Healey [39] used local color invariants to recognize 3D objects.
Reference: [30] <author> T. Miyatake, T. Matsuyama, and M. Nagao. </author> <title> Affine Transform Invariant Curve Recognition Using Fourier Descriptors (original in Japanese). </title> <journal> Trans. Inform. Processing Soc. Japan, </journal> <volume> 24(1) </volume> <pages> 64-67, </pages> <year> 1983. </year>
Reference-contexts: Similarly, many have focused their research on illumination invariants. A few have attempted to combine the two. Invariants under affine transformations have been studied by [20] using Hough-based methods, 2 (a) (b) (c) dimensions. by <ref> [1, 30] </ref> using Fourier descriptors, and by [43] using wavelets. In these cases, affine invariants were used to recognize planar objects in 3D space. Orthographic projection was used to approximate perspective projection, and the "shear" effect in affine transformations modeled perspective distortion.
Reference: [31] <editor> J. Mundy and A. Zisserman (eds.). </editor> <booktitle> Geometric Invariance in Computer Vision. </booktitle> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1992. </year>
Reference-contexts: Properties of the wavelet transform are discussed in [45]. A comprehensive survey on the subject of invariants in general is presented by [36]. A review of geometric invariants is presented in <ref> [31, 47] </ref>. Other approaches to invariants and recognition are discussed in [34, 31, 23]. <p> Properties of the wavelet transform are discussed in [45]. A comprehensive survey on the subject of invariants in general is presented by [36]. A review of geometric invariants is presented in [31, 47]. Other approaches to invariants and recognition are discussed in <ref> [34, 31, 23] </ref>.
Reference: [32] <editor> Joseph L. Mundy, Andrew Zisserman, and David Forsyth (Eds.). </editor> <booktitle> Proc. Applications of Invariance in Computer Vision. In Proc. Second Joint European-US Workshop, </booktitle> <month> Oct. </month> <year> 1993. </year>
Reference-contexts: A review of geometric invariants is presented in [31, 47]. Other approaches to invariants and recognition are discussed in [34, 31, 23]. Numerous papers on invariance, with emphasis in their applications in computer vision, can be found in <ref> [32] </ref>. 3 Technical Rationale A word on the notational convention: matrices and vectors will be represented by bold-face characters, such as M and V, while scalar quantities by plain-face characters such as S. 2D quantities will be in small letters while 3D quantities in capital letters.
Reference: [33] <author> L. Peigl and W. Tiller. </author> <title> Curve and Surface Constructions using Rational B-Splines. </title> <journal> Comput. Aided Des., </journal> <volume> 19(9) </volume> <pages> 485-498, </pages> <year> 1987. </year>
Reference-contexts: Whence, the new method is more robust. 5.) We introduce the use of rational basis functions to facilitate the analysis of invariants under perspective transform. Rational basis functions, such as NURBS, have been widely used in the computer graphics community <ref> [2, 5, 10, 33, 44] </ref>. However, their usage in perspective invariants is novel. The remainder of this paper is organized as follows: Sec. 2 reviews related work done in the past, Sec. 3 presents the framework of image-derived invariants. <p> The projection process can be linearized using a tool which is well-established in computer graphics, the rational form of a basis function <ref> [2, 5, 10, 33, 44] </ref>. The most famous of such an expression is probably NURBS (Non-Uniform Rational B-Spline), which was adopted as a standard for IGES (Initial Graphics Exchange Specification) [18].
Reference: [34] <author> S.J. Perantonis and P.J. </author> <title> Lisboa. Translation, Rotation, and Scale Invariant Pattern Recognition by High-order Neural Networks and Moment Classifiers. </title> <journal> IEEE Trans. on Information Theory, </journal> <volume> 3 </volume> <pages> 241-251, </pages> <year> 1992. </year>
Reference-contexts: Properties of the wavelet transform are discussed in [45]. A comprehensive survey on the subject of invariants in general is presented by [36]. A review of geometric invariants is presented in [31, 47]. Other approaches to invariants and recognition are discussed in <ref> [34, 31, 23] </ref>.
Reference: [35] <author> L. R. Rabiner and D. W. Schafer. </author> <title> Digital Processing of Speech Signals. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1978. </year>
Reference-contexts: We propose to use the framework with wavelet, short-time Fourier analysis, and spline bases, which have been widely used in signal and speech processing, image analysis, computer vision, and computer graphics <ref> [3, 4, 5, 24, 25, 35, 37] </ref>. 4.) It ameliorates some difficulties encountered in computing global or local image invariants. We employ basis functions of a compact support (wavelets, short-time Fourier analysis, and splines).
Reference: [36] <author> T. H. Reiss. </author> <title> Recognizing Planar Objects Using Invariant Image Features. </title> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1993. </year>
Reference-contexts: 1 Introduction Image features and shape descriptors that capture the essential traits of an object and are insensitive to environmental changes are ideal for recognition. The search for invariants (e.g., algebraic and projective invariants) is a classical problem in mathematics dating back to the 18th century <ref> [7, 21, 36] </ref>. The need for invariant image descriptors has long been recognized in computer vision [36, 47]. Invariant features form a compact, intrinsic description of an object, and can be used to design recognition algorithms that are potentially more efficient than, say, aspect-based approaches [6, 8, 9]. <p> The search for invariants (e.g., algebraic and projective invariants) is a classical problem in mathematics dating back to the 18th century [7, 21, 36]. The need for invariant image descriptors has long been recognized in computer vision <ref> [36, 47] </ref>. Invariant features form a compact, intrinsic description of an object, and can be used to design recognition algorithms that are potentially more efficient than, say, aspect-based approaches [6, 8, 9]. Hence, it was even argued that object recognition is the search for invariants [47]. <p> Another approach is described by Mallat [26], wherein a signal uses the local extreme in its wavelet transform domain to make it invariant to time shifts. Properties of the wavelet transform are discussed in [45]. A comprehensive survey on the subject of invariants in general is presented by <ref> [36] </ref>. A review of geometric invariants is presented in [31, 47]. Other approaches to invariants and recognition are discussed in [34, 31, 23]. <p> One can interpret the enclosed area parameter as the area of the triangular region enclosed by the two lines from the centroid to a and b, respectively. Since the affine transform linearly changes area, a parameterization that sweeps a constant area will be an invariant of weight 1 <ref> [36, 47] </ref>. <p> For invariants under general affine transform, many forms using ratios, cross ratios, and ratios of ratios have already been derived <ref> [36, 47] </ref>. For example, it is known that the cross ratio of four collinear points are invariant under the affine transform, and the area of the triangle formed by any three u a;b changes linearly in an affine transform (an invariant of weight 1 [36, 47]). <p> of ratios have already been derived <ref> [36, 47] </ref>. For example, it is known that the cross ratio of four collinear points are invariant under the affine transform, and the area of the triangle formed by any three u a;b changes linearly in an affine transform (an invariant of weight 1 [36, 47]).
Reference: [37] <author> D. F. Rogers and J. A. Adams. </author> <title> Mathematical Elements for Computer Graphics, 2nd Ed. </title> <publisher> McGraw-Hill, </publisher> <address> New York, NY, </address> <year> 1990. </year>
Reference-contexts: We propose to use the framework with wavelet, short-time Fourier analysis, and spline bases, which have been widely used in signal and speech processing, image analysis, computer vision, and computer graphics <ref> [3, 4, 5, 24, 25, 35, 37] </ref>. 4.) It ameliorates some difficulties encountered in computing global or local image invariants. We employ basis functions of a compact support (wavelets, short-time Fourier analysis, and splines). <p> Hence, the transformed curve can be generated using the transformed wavelet coefficients and the same wavelet bases, instead of transforming the curve point-by-point. This is an observation which is commonly made in the computer graphics community about curves generated by the spline functions and associated control vertices <ref> [2, 5, 37] </ref>. <p> u 0 fi fi fi c;d fi = jmu c;d j ju a;b j : If the second term in Eq. 1 is not zero, but is a constant (e.g., for spline functions, the area under a spline basis integrates to a constant 1 for a uniformly spaced knot vector <ref> [37] </ref>), then invariant expressions can still be derived, albeit in a slightly more complicated form: fi fi u 0 c;d fi fi fi u 0 g;h fi = j (mu e;f + v) (mu g;h + v)j jm (u a;b u c;d )j = j (u e;f u g;h )j where <p> We will use NURBS for illustration. In a nutshell, a b-spline function is a polynomial of a finite support. Non-rational b-spline functions of order k (or a polynomial of degree k 1) are generated by the Cox-deBoor recursion formulas <ref> [37] </ref>: N i;1 (t) = 1 if x i t &lt; x i+1 0 otherwise ; and (t x i )N i;k1 (t) + x i+k x i+1 The values of x i are elements of a knot vector satisfying the relations x i x i+1 . <p> We assume the focal length of the camera is 1. To illustrate, Fig. 2 shows the rational b-spline bases of order four (third-degree polynomial) for an open knot vector [X] = [000012222] <ref> [37] </ref>. By varying the Z coordinates of the associated control vertices, the shape of the bases adapts accordingly. <p> When all the Z's are equal, the rational bases reduce to the non-rational bases as expected in Eq. 4. Fig. 3 shows sample b-spline curves using both periodical and open knot vectors <ref> [37] </ref>. Column (a) in Fig. 3 shows curves generated using non-rational spline bases in space. Columns (b) and (c) show the projections of the 3D curves using two different methods: One is generating points along the 3D curves in Fig. 3 (a), then projecting them one by one.
Reference: [38] <author> E.P. Simoncelli, E.H. Adelson W.T. Freeman, </author> <title> and D.J. Heeger. Shiftable Multiscale Transforms. </title> <journal> IEEE Trans. on Information Theory, </journal> <volume> 38 </volume> <pages> 587-607, </pages> <year> 1991. </year>
Reference-contexts: They used a similar technique in [43] to formulate affine invariants to recognize planar objects in 3D space. However, only a weak perspective was assumed. Recently, it has become popular to use wavelets (or quadrature mirror filters QMF's) in decomposing and representing signals at multiple scales <ref> [38, 26] </ref>. Indeed, we use wavelets to achieve multi-resolution analysis in our invariant formulation. However, one caveat in doing this is that orthogonal wavelets are critically sampled. They achieve representation through scaling and translation. <p> The result is that even though basis functions at a scale are translated versions of each other, it does not imply that the transform coefficients behave in the same way when the input signal undergoes a simple translation. One remedy was proposed by Simoncelli, et. al. <ref> [38] </ref>, where they define a shiftable transform in which the information represented within a subband remains in the same subband as the signal is translated.
Reference: [39] <author> D. Slater and G. Healey. </author> <title> The Illumination-Invariant Recognition of 3D Objects Using Local Color Invariants. </title> <journal> IEEE Trans. Pattern Analy. Machine Intell., </journal> <volume> 18(2) </volume> <pages> 206-210, </pages> <month> Feb. </month> <year> 1996. </year>
Reference-contexts: These invariants allowed for changes that may include altering the position and number of light sources, the brightness and contrast, and even hue. Illumination invariants have been applied to recognize textures [17], 3D objects <ref> [39] </ref>, and 3D textures [19]. A physics-based approach is used in [29], to produce illumination invariants from infrared imagery. Many, including our proposed technique, assumes a Lambertian [11] surface model for simplicity. There has been limited success in combining geometric and illumination invariants. For instance, Slater and Healey [39] used local <p> 3D objects <ref> [39] </ref>, and 3D textures [19]. A physics-based approach is used in [29], to produce illumination invariants from infrared imagery. Many, including our proposed technique, assumes a Lambertian [11] surface model for simplicity. There has been limited success in combining geometric and illumination invariants. For instance, Slater and Healey [39] used local color invariants to recognize 3D objects. In this study, they derived invariants of local color pixel distributions, which were independent of the position and orientation of an object's surface. <p> Following a path similar to that adopted by several researchers <ref> [17, 27, 28, 39] </ref>, we assume that reflected radiance functions are modeled as a linear combination of a small number of basis functions s k (), whence, s (; t) = k where s k () denotes the k-th basis function for representing the reflected radiance properties, and ff k (t)
Reference: [40] <author> D. Slater and G. Healey. </author> <title> Using a Spectral Reflectance Model for the Illumination-Invariant Recognition of Local Image Structure. </title> <journal> In Proc. IEEE Comput. Soc. Conf. Comput. Vision and Pattern Recognit., </journal> <pages> pages 770-775, </pages> <address> San Francisco, CA, </address> <month> Jun. </month> <year> 1996. </year>
Reference-contexts: Lei [22] demonstrated how cross ratios can be used to recognize planar objects in 3D space. In this case, "true" perspective invariants were formulated. However, objects were restricted to polygons and required accurate identification of vertex positions. Illumination invariants have also been studied extensively in <ref> [12, 16, 15, 27, 28, 29, 40, 41, 46] </ref>. These invariants allowed for changes that may include altering the position and number of light sources, the brightness and contrast, and even hue. Illumination invariants have been applied to recognize textures [17], 3D objects [39], and 3D textures [19].
Reference: [41] <author> D. Slater and G. Healey. </author> <title> The Illumination-Invariant Matching of Deterministic Local Structure in Color Images. </title> <journal> IEEE Trans. Pattern Analy. Machine Intell., </journal> 19(10) 1146-1151, 1997. 
Reference-contexts: Lei [22] demonstrated how cross ratios can be used to recognize planar objects in 3D space. In this case, "true" perspective invariants were formulated. However, objects were restricted to polygons and required accurate identification of vertex positions. Illumination invariants have also been studied extensively in <ref> [12, 16, 15, 27, 28, 29, 40, 41, 46] </ref>. These invariants allowed for changes that may include altering the position and number of light sources, the brightness and contrast, and even hue. Illumination invariants have been applied to recognize textures [17], 3D objects [39], and 3D textures [19]. <p> Computing invariants for each region in the image is necessary for recognition. Furthermore, the allowable range of the object's distance from the camera must be pre-determined, with each window size corresponding to one possible distance measure. This comes close to estimating geometric features by brute-force methods. Their later study <ref> [41] </ref> describes a recognition system invariant to illumination, rotation and scale. Scale invariance was limited to regions that were locally radially invariant, i:e:; the circular image region appears the same, regardless of radius. Another study [48] proposed an algorithm for classifying textures invariant to rotation and gray-scale transformation.
Reference: [42] <author> Q. M. Tieng and W. W. Boles. </author> <title> Recognition of 2D Object Contours Using the Wavelet Transform Zero-Crossing Representation. </title> <journal> IEEE Trans. Pattern Analy. Machine Intell., </journal> <volume> 19(8) </volume> <pages> 910-916, </pages> <month> Aug. </month> <year> 1997. </year>
Reference-contexts: Recent research has exploited the properties of wavelets to formulate invariants that allow analysis to be performed at different resolution levels. Dyadic wavelets were used in <ref> [42] </ref> to decompose object contours into several components at different resolution levels. The resolution levels that were to be used for matching were pre-determined, by selecting the levels where most of its energy was concentrated.
Reference: [43] <author> Q. M. Tieng and W. W. Boles. </author> <title> Wavelet-Based Affine Invariant Representation: A Tool for Recognizing Planar Objects in 3D Space. </title> <journal> IEEE Trans. Pattern Analy. Machine Intell., </journal> <volume> 19(8) </volume> <pages> 846-857, </pages> <month> Aug. </month> <year> 1997. </year>
Reference-contexts: Similarly, many have focused their research on illumination invariants. A few have attempted to combine the two. Invariants under affine transformations have been studied by [20] using Hough-based methods, 2 (a) (b) (c) dimensions. by [1, 30] using Fourier descriptors, and by <ref> [43] </ref> using wavelets. In these cases, affine invariants were used to recognize planar objects in 3D space. Orthographic projection was used to approximate perspective projection, and the "shear" effect in affine transformations modeled perspective distortion. <p> Hence, the advantages of spatial and frequency domain methods were combined. The result was a curve representation invariant to translation, rotation, and scaling. They used a similar technique in <ref> [43] </ref> to formulate affine invariants to recognize planar objects in 3D space. However, only a weak perspective was assumed. Recently, it has become popular to use wavelets (or quadrature mirror filters QMF's) in decomposing and representing signals at multiple scales [38, 26].
Reference: [44] <author> W. Tiller. </author> <title> Rational B-Splines for Curve and Surface Representation. </title> <journal> IEEE Comput. Graphics & App., </journal> <volume> 3(6) </volume> <pages> 61-69, </pages> <year> 1987. </year>
Reference-contexts: Whence, the new method is more robust. 5.) We introduce the use of rational basis functions to facilitate the analysis of invariants under perspective transform. Rational basis functions, such as NURBS, have been widely used in the computer graphics community <ref> [2, 5, 10, 33, 44] </ref>. However, their usage in perspective invariants is novel. The remainder of this paper is organized as follows: Sec. 2 reviews related work done in the past, Sec. 3 presents the framework of image-derived invariants. <p> The projection process can be linearized using a tool which is well-established in computer graphics, the rational form of a basis function <ref> [2, 5, 10, 33, 44] </ref>. The most famous of such an expression is probably NURBS (Non-Uniform Rational B-Spline), which was adopted as a standard for IGES (Initial Graphics Exchange Specification) [18].
Reference: [45] <author> M. Vetterli and J. Kovacevic. </author> <title> Wavelets and Subband Coding. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1995. </year>
Reference-contexts: Another approach is described by Mallat [26], wherein a signal uses the local extreme in its wavelet transform domain to make it invariant to time shifts. Properties of the wavelet transform are discussed in <ref> [45] </ref>. A comprehensive survey on the subject of invariants in general is presented by [36]. A review of geometric invariants is presented in [31, 47]. Other approaches to invariants and recognition are discussed in [34, 31, 23].
Reference: [46] <author> L. Wang and G. Healey. </author> <title> Illumination and Geometry Invariant Recognition of Texture in Color Images. </title> <journal> In Proc. IEEE Comput. Soc. Conf. Comput. Vision and Pattern Recognit., </journal> <pages> pages 419-424, </pages> <address> San Francisco, CA, </address> <month> Jun. </month> <year> 1996. </year>
Reference-contexts: Lei [22] demonstrated how cross ratios can be used to recognize planar objects in 3D space. In this case, "true" perspective invariants were formulated. However, objects were restricted to polygons and required accurate identification of vertex positions. Illumination invariants have also been studied extensively in <ref> [12, 16, 15, 27, 28, 29, 40, 41, 46] </ref>. These invariants allowed for changes that may include altering the position and number of light sources, the brightness and contrast, and even hue. Illumination invariants have been applied to recognize textures [17], 3D objects [39], and 3D textures [19].
Reference: [47] <author> I. Weiss. </author> <title> Geometric Invariants and Object Recognition. </title> <journal> Int. J. Comput. Vision, </journal> <volume> 10(3) </volume> <pages> 207-231, </pages> <year> 1993. </year>
Reference-contexts: The search for invariants (e.g., algebraic and projective invariants) is a classical problem in mathematics dating back to the 18th century [7, 21, 36]. The need for invariant image descriptors has long been recognized in computer vision <ref> [36, 47] </ref>. Invariant features form a compact, intrinsic description of an object, and can be used to design recognition algorithms that are potentially more efficient than, say, aspect-based approaches [6, 8, 9]. Hence, it was even argued that object recognition is the search for invariants [47]. <p> Invariant features form a compact, intrinsic description of an object, and can be used to design recognition algorithms that are potentially more efficient than, say, aspect-based approaches [6, 8, 9]. Hence, it was even argued that object recognition is the search for invariants <ref> [47] </ref>. Image invariants can be designed to fit the needs of specific systems. Some require only that it be non-discriminating to an object's geometric pose or orientation. Others may be only interested in it being insensitive to the change of illumination of the entire scene. <p> Properties of the wavelet transform are discussed in [45]. A comprehensive survey on the subject of invariants in general is presented by [36]. A review of geometric invariants is presented in <ref> [31, 47] </ref>. Other approaches to invariants and recognition are discussed in [34, 31, 23]. <p> One can interpret the enclosed area parameter as the area of the triangular region enclosed by the two lines from the centroid to a and b, respectively. Since the affine transform linearly changes area, a parameterization that sweeps a constant area will be an invariant of weight 1 <ref> [36, 47] </ref>. <p> For invariants under general affine transform, many forms using ratios, cross ratios, and ratios of ratios have already been derived <ref> [36, 47] </ref>. For example, it is known that the cross ratio of four collinear points are invariant under the affine transform, and the area of the triangle formed by any three u a;b changes linearly in an affine transform (an invariant of weight 1 [36, 47]). <p> of ratios have already been derived <ref> [36, 47] </ref>. For example, it is known that the cross ratio of four collinear points are invariant under the affine transform, and the area of the triangle formed by any three u a;b changes linearly in an affine transform (an invariant of weight 1 [36, 47]).
Reference: [48] <author> W-R Wu and S-C Wei. </author> <title> Rotation and Gray-Scale Transformation-Invariant Texture Classification Using Spiral Resampling, Subband Decomposition, and Hidden Markov Model. </title> <journal> IEEE Trans. Image Processing, </journal> <volume> 5(10) </volume> <pages> 1423-1434, </pages> <month> Oct. </month> <year> 1996. </year> <month> 18 </month>
Reference-contexts: This comes close to estimating geometric features by brute-force methods. Their later study [41] describes a recognition system invariant to illumination, rotation and scale. Scale invariance was limited to regions that were locally radially invariant, i:e:; the circular image region appears the same, regardless of radius. Another study <ref> [48] </ref> proposed an algorithm for classifying textures invariant to rotation and gray-scale transformation. It used spiral resampling, subband decomposition, and Hidden Markov Model. Two-dimensional texture images were converted to 1-D signals in a spiral fashion to achieve 3 rotation invariance.
References-found: 48

