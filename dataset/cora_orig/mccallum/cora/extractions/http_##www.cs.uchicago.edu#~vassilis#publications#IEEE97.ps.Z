URL: http://www.cs.uchicago.edu/~vassilis/publications/IEEE97.ps.Z
Refering-URL: http://infolab.cs.uchicago.edu/webseer/
Root-URL: 
Email: f vassilis, swain g@cs.uchicago.edu  
Title: Distinguishing Photographs and Graphics on the World Wide Web  
Author: Vassilis Athitsos and Michael J. Swain 
Address: Chicago, Illinois 60637  
Affiliation: Department of Computer Science The University of Chicago  
Abstract: When we search for images in multimedia documents, we often have in mind specific image types that we are interested in; examples are photographs, graphics, maps, cartoons, portraits of people, and so on. This paper describes an automated system that classifies Web images as photographs or graphics, based on their content. The system first submits the images into some tests, which look at the image content, and then feeds the results of those tests into a classifier. The classifier is built using learning techniques, which take advantage of the vast amount of training data that is available on the Web. Text associated with an image can be used to further improve the accuracy of the classification. The system is used as a part of WebSeer, an image search engine for the Web. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Y. Amit and D. </author> <title> Geman (1987). "Randomized Inquiries About Shape: an Application to Handwritten Digit Recognition" </title>
Reference-contexts: To make the final decision, we need a decision making module that will make the final classification based on those scores. We currently use multiple decision trees for that task. Our decision tree design is based on Yali Amit's work with decision trees <ref> [1] </ref>, with minor modifications, in order to adjust it to our domain. 6.1 Classification with Multiple Decision Trees Each decision tree is a binary tree. <p> We start at the root. If the images in S are all photographs or all graphics, we stop. Otherwise, we pick the optimal test for the root, with respect to our training set. We use the same criteria as <ref> [1] </ref> to determine what the optimal test in a given node is. [4] explains the intuition behind the notion of "information gain" that we and [1] use to evaluate the informational value of a given test at a given node. <p> Otherwise, we pick the optimal test for the root, with respect to our training set. We use the same criteria as <ref> [1] </ref> to determine what the optimal test in a given node is. [4] explains the intuition behind the notion of "information gain" that we and [1] use to evaluate the informational value of a given test at a given node. If the information gain from all tests is zero, we stop. Othewise, we recursively construct the left and right subtree under the root.
Reference: [2] <author> John R. Smith and Shih-Fu Chang (1996). </author> <title> "Searching for Images and Videos on the World Wide Web". </title> <type> Technical Report # 459-96-25. </type> <institution> Center for Telecommunications Research, Columbia University. </institution>
Reference-contexts: Preliminary results show that the document that contains the image is also a useful source of information. 2 Related Work Up to now there have been very few efforts to automate the classification of images as photographs and graphics. The WebSeek search engine <ref> [2] </ref> performs that classification based on information obtained from the color histograms of the images. The system described in [3] uses some information from the image content, as well as information from the image context, that is the HTML document in which the image is embedded. <p> In addition, the filename portion of the image URL is tested for the occurrence of words that are usually associated with only one of the two image types. The existence or not of such words is an additional feature that is considered in the classification. One problem with <ref> [2] </ref> and [3] is that it is hard to evaluate their accuracy. In [2] the authors claim a 1 recall rate of 0.914 for Web photographs and 0.923 for Web graphics. However, they don't specify exactly what they consider photographs and graphics. <p> The existence or not of such words is an additional feature that is considered in the classification. One problem with <ref> [2] </ref> and [3] is that it is hard to evaluate their accuracy. In [2] the authors claim a 1 recall rate of 0.914 for Web photographs and 0.923 for Web graphics. However, they don't specify exactly what they consider photographs and graphics.
Reference: [3] <author> Neil C. Rowe and Brian Frew (1997). </author> <title> "Automatic Caption Localization for Photographs on World Wide Web Pages". </title> <institution> Department of Computer Science, Naval Postgraduate School </institution>
Reference-contexts: The WebSeek search engine [2] performs that classification based on information obtained from the color histograms of the images. The system described in <ref> [3] </ref> uses some information from the image content, as well as information from the image context, that is the HTML document in which the image is embedded. <p> The existence or not of such words is an additional feature that is considered in the classification. One problem with [2] and <ref> [3] </ref> is that it is hard to evaluate their accuracy. In [2] the authors claim a 1 recall rate of 0.914 for Web photographs and 0.923 for Web graphics. However, they don't specify exactly what they consider photographs and graphics. <p> However, they don't specify exactly what they consider photographs and graphics. We see later in the paper that we can define those image types in different ways, and our definitions have a direct impact on the error rate. The authors of <ref> [3] </ref> also don't specify exactly what they consider photographs and graphics.
Reference: [4] <author> Tom Mitchell (1997). </author> <title> "Machine Learning". </title> <address> Mc-Graw Hill 7 </address>
Reference-contexts: If the images in S are all photographs or all graphics, we stop. Otherwise, we pick the optimal test for the root, with respect to our training set. We use the same criteria as [1] to determine what the optimal test in a given node is. <ref> [4] </ref> explains the intuition behind the notion of "information gain" that we and [1] use to evaluate the informational value of a given test at a given node. If the information gain from all tests is zero, we stop.
References-found: 4

