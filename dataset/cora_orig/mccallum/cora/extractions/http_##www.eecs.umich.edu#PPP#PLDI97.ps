URL: http://www.eecs.umich.edu/PPP/PLDI97.ps
Refering-URL: http://www.eecs.umich.edu/PPP/publist.html
Root-URL: http://www.cs.umich.edu
Email: alexe@eos.ncsu.edu davidson@eecs.umich.edu  
Title: Efficient Formulation for Optimal Modulo Schedulers  
Author: Alexandre E. Eichenberger Edward S. Davidson 
Address: Raleigh, NC 27695-7911 Ann Arbor, MI 48109-2122  
Affiliation: ECE Department EECS Department North Carolina State University University of Michigan  
Abstract: Modulo scheduling algorithms based on optimal solvers have been proposed to investigate and tune the performance of modulo scheduling heuristics. While recent advances have broadened the scope for which the optimal approach is applicable, this approach increasingly suffers from large execution times. In this paper, we propose a more efficient formulation of the modulo scheduling space that significantly decreases the execution time of solvers based on integer linear programs. For example, the total execution time is reduced by a factor of 8.6 when 782 loops from the Perfect Club, SPEC, and Livermore Fortran Kernels are scheduled for minimum register requirements using the more efficient formulation instead of the traditional formulation. Experimental evidence further indicates that significantly larger loops can be scheduled under realistic machine constraints. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> B. R. Rau and C. D. Glaeser. </author> <title> Some scheduling techniques and an easily schedulable horizontal architecture for high performance scientific computing. </title> <booktitle> Fourteenth Annual Workshop on Microprogramming, </booktitle> <pages> pages 183-198, </pages> <month> October </month> <year> 1981. </year>
Reference-contexts: For our target machine, the resource constraints allow up to 3 operations of any kind to be issued in each row of the MRT. The initiation interval is bounded by the minimum initiation interval (MII) <ref> [1] </ref>, which is a lower bound on the smallest feasible value of II for which a modulo schedule can be found. This lower bound is constrained either by critical resources being fully utilized or by critical loop-carried dependence cycles. <p> disjoint Relations (11) and (15) by formulating the following constraint: k f k u + z 0 (17) Inequality (17) is equivalent to the union of Relations (11) and (15) because when k u &gt; k f , Inequality (17) holds regardless of the value of z since z 2 <ref> [0; 1] </ref> and when k u = k f , Inequality (17) holds precisely when z = 0.
Reference: [2] <author> P. Y. Hsu. </author> <title> Highly Concurrent Scalar Processing. </title> <type> PhD thesis, </type> <institution> Department of Electrical and Computer Engineering, University of Illinois, Urbana, IL, </institution> <year> 1986. </year>
Reference: [3] <author> B. R. Rau. </author> <title> Iterative Modulo Scheduling: An algorithm for software pipelining loops. </title> <booktitle> Proceedings of the 27th Annual International Symposium on Microarchitecture, </booktitle> <pages> pages 63-74, </pages> <month> November </month> <year> 1994. </year>
Reference: [4] <author> A. E. Eichenberger, E. S. Davidson, and S. G. Abra-ham. </author> <title> Optimum modulo schedules for minimum register 11 requirements. </title> <booktitle> Proceedings of the International Confer--ence on Supercomputing, </booktitle> <pages> pages 31-40, </pages> <month> July </month> <year> 1995. </year>
Reference-contexts: Recent advances in optimal modulo scheduling algorithms have broadened the scope of the machines for which this approach is applicable: for example, machines with arbitrary patterns of resource usages can be handled using the formulation proposed in <ref> [4] </ref> or [5]. The formulation in [5] may also map each operation to a given instance of a resource (e.g. map a multiply op-eration to one of the multiply functional units). <p> Recent advances have also refined the secondary objectives that may be minimized; for example, the actual register requirements of a modulo schedule (i.e. the maximum number of live variables at any cycle of the schedule, referred to as MaxLive) may be minimized using the formulation proposed in <ref> [4] </ref>. <p> The formulation of the variables and the first two types of constraints (presented in Sections 3.1 and 3.2) were proposed by Govindarajan et al [7], and the last type of constraints (shown in Section 3.3) was proposed by us in <ref> [4] </ref>. <p> In this paper, we use the constraints derived in <ref> [4] </ref>: N1 X X a (rc)modII;i M q 8q 2 Q; r 2 [0; II) (5) where Q is the set of resource types, M q is the number of resources of type q, and c 2 Res i;q indicates that operation i uses a resource of type q exactly c <p> The formulation of the secondary objective function (for minimum register requirements) is based on the 0-1-structured formulation found in <ref> [4] </ref>. Recall that this algorithm achieves the minimum feasible register requirements for a given loop iteration, initiation interval, and set of machine constraints. 7 MinBuff Modulo Scheduler. This scheduler finds a schedule with minimum II, and the minimum buffer requirements among all such schedules.
Reference: [5] <author> E. R. Altman, R. Govindarajan, and G. R. Gao. </author> <title> Scheduling and mapping: Software pipelining in the presence of structural hazards. </title> <booktitle> In Proceedings of the ACM SIGPLAN'95 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 139-150, </pages> <year> 1995. </year>
Reference-contexts: Recent advances in optimal modulo scheduling algorithms have broadened the scope of the machines for which this approach is applicable: for example, machines with arbitrary patterns of resource usages can be handled using the formulation proposed in [4] or <ref> [5] </ref>. The formulation in [5] may also map each operation to a given instance of a resource (e.g. map a multiply op-eration to one of the multiply functional units). <p> Recent advances in optimal modulo scheduling algorithms have broadened the scope of the machines for which this approach is applicable: for example, machines with arbitrary patterns of resource usages can be handled using the formulation proposed in [4] or <ref> [5] </ref>. The formulation in [5] may also map each operation to a given instance of a resource (e.g. map a multiply op-eration to one of the multiply functional units). <p> Note that for machines where a mapping from each operation's resource usages to resource instances cannot be trivially found, the formulation proposed by Altman et al <ref> [5] </ref> should be used.
Reference: [6] <author> J. R. Ruttenberg, G. R. Gao, and A. Stoutchinin. </author> <title> Software pipelining showdown: Optimal vs. heuristic methods in a production compiler. </title> <booktitle> Proceedings of the ACM SIGPLAN'96 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 1-11, </pages> <month> May </month> <year> 1996. </year>
Reference-contexts: Unfortunately, the present state-of-the-art optimal modulo schedulers based on integer linear programming solvers has not yet reached this stage, when accounting for all the machine constraints, even when scheduling for traditional machines and without considering spill code generation or loop transformations. As recently illustrated by Ruttenberg et al <ref> [6] </ref>, a modulo scheduler that minimizes the register requirements among all minimum-II modulo schedules has difficulty finding solutions in reasonable time for medium-sized loops when precisely modeling the machine constraints. <p> This more efficient formulation addresses a major concern with modulo schedulers that are based on integer linear programming solvers <ref> [6] </ref>, which is their traditionally high execution time.
Reference: [7] <author> R. Govindarajan, E. R. Altman, and G. R. Gao. </author> <title> Minimizing register requirements under resource-constrained rate-optimal software pipelining. </title> <booktitle> Proceedings of the 27th Annual International Symposium on Microarchitecture, </booktitle> <pages> pages 85-94, </pages> <month> November </month> <year> 1994. </year>
Reference-contexts: The traditional formulation consists of three types of scheduling constraints: the assignment constraints, the dependence constraints, and the resource constraints. The formulation of the variables and the first two types of constraints (presented in Sections 3.1 and 3.2) were proposed by Govindarajan et al <ref> [7] </ref>, and the last type of constraints (shown in Section 3.3) was proposed by us in [4]. <p> Recall that unlike registers, buffers are reserved for integer multiples of II cycles. When considering the traditional formulation of the modulo scheduling space, we use Constraints (4), (1), and (5,) as well as the formulation of the minimum-buffer secondary objective function found in <ref> [7] </ref>. When evaluating the structured formulation, we use Constraints (1), (5), and (20); in addition, we reformulate the minimum-buffer objective function as proposed by Dupont de Dinechin [15] in order to obtain a 0-1-structured formulation 1 . <p> When considering the traditional formulation of the modulo scheduling space, we use Constraints (1), (5), and (4,) as well as the formulation of the minimum-lifetime secondary objective function found in [16]. When evaluating the structured formulation, we use Constraints (1), (5), and (20); we 1 As formulated in <ref> [7] </ref>, the minimum-buffer objective function uses additional variables that are defined by constraints which are not 0-1-structured. By transforming the problem using a technique proposed in [15], however, we may define these additional variables using constraints of the same type as Constraints (20).
Reference: [8] <author> B. R. Rau. </author> <title> Iterative Modulo Scheduling. </title> <journal> International Journal of Parallel Programming, </journal> <volume> 24(1) </volume> <pages> 2-64, </pages> <year> 1996. </year>
Reference-contexts: Note that the MII lower bound is not a tight lower bound as they may be no feasible modulo schedules that achieves MII, possibly due to the presence complex resource patterns or to the interference between resource and dependence constraints <ref> [8] </ref>. The virtual register lifetimes associated with this iteration are presented in Figure 1d. The register requirements can also be computed by collapsing Figure 1d to II rows, with wraparound, as shown in Figure 1e. <p> A traditional framework of optimal modulo sched-uler for minimum II based on IP solvers is thus defined as follows. First, the minimum initiation interval (MII) <ref> [8] </ref> is computed, and the tentative II is set to MII. Second, the integer linear programming system for the tentative II, given loop iteration, and given target machine is constructed. <p> In our third experiment, we use the NoObj Modulo Scheduler to investigate the performance of the Iterative Modulo Scheduler proposed by Rau <ref> [8] </ref>. Since the Iterative Modulo Scheduler results in schedules with optimal throughput for 1274 (or 96.0%) of the 1327 loops in the benchmark suite, we only need to investigate and compare the remaining 53 loops.
Reference: [9] <author> A. E. Eichenberger and E. S. Davidson. </author> <title> Stage scheduling: A technique to reduce the register requirements of a modulo schedule. </title> <booktitle> Proceedings of the 28th Annual International Symposium on Microarchitecture, </booktitle> <pages> pages 180-191, </pages> <month> November </month> <year> 1995. </year>
Reference: [10] <author> A. E. Eichenberger. </author> <title> Modulo Scheduling, Machine Representations, and Register-Sensitive Algorithms. </title> <type> PhD thesis, </type> <institution> University of Michigan, Department of Electrical Engineering and Computer Science, </institution> <address> Ann Arbor, MI, </address> <year> 1996. </year>
Reference-contexts: A derivation of Inequality (5) as well as a precise definition of the machines for which Inequality (5) is applicable is found in <ref> [10] </ref>. 3.4 Optimal Modulo Scheduling Framework The traditional formulation of the modulo scheduling space is based on the assignment, dependence, and resource constraints as defined by Constraints (1), (4), and (5), respectively. <p> This right hand side value is just large enough to ensure that this inequality is trivially satisfied. A detailed proof is provided in <ref> [10] </ref>. 4.3 Final Formulation of the Structured Depen dence Constraints While we may simply formulate structured dependence constraints for each dependence edge (i; j) 2 E sched using Inequality (19), we may further tighten the formulation of the scheduling space using an observation made by Chaudhuri et al [14] for dependent
Reference: [11] <author> A. E. Eichenberger, E. S. Davidson, and S. G. Abra-ham. </author> <title> Minimum register requirements for a modulo schedule. </title> <booktitle> Proceedings of the 27th Annual International Symposium on Microarchitecture, </booktitle> <pages> pages 75-84, </pages> <month> Novem-ber </month> <year> 1994. </year>
Reference-contexts: The memory latency and the add/sub latency is one cycle, and the mult latency is four cycles. We selected these values to obtain a concise example; however, our method works independently of the numbers of functional units, resource constraints, and latencies. Example 1 This example <ref> [11] </ref> illustrates the scheduling constraints and the register requirements of a modulo-scheduled loop.
Reference: [12] <author> R. A. Huff. </author> <title> Lifetime-sensitive modulo scheduling. </title> <booktitle> Proceedings of the ACM SIGPLAN'93 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 258-267, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: We see that exactly 7 virtual registers are live in the first row and 7 in the second. Thus the register requirements, which are determined by the row with the maximum number of live values, and referred to as MaxLive <ref> [12] </ref>, are thus 7 in this example. 3 Backgrounds on Optimal Modulo Scheduling In this section, we first present the traditional formulation that is used by optimal modulo schedulers based on integer linear programming solvers.
Reference: [13] <author> G. L. Nemhauser and L. A. Wolsey. </author> <title> Integer and Combinatorial Optimization. </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1988. </year>
Reference-contexts: optimal. 4 Structured Formulation of the Dependence Constraints Solving an integer linear programming system can be implemented by iteratively solving a linear programming model where additional constraints are introduced (and removed) to force each integer variable to an integer value without omitting from the solution space any optimal (integer) solution <ref> [13] </ref>. A branch-and-bound algorithm is used to determine which parts of the search space to consider, and each branch-and-bound node is evaluated by solving a linear programming model with the original constraints augmented by some additional constraints that force variables to integer values.
Reference: [14] <author> S. Chaudhuri, R. A. Walker, and J. E. Mitchell. </author> <title> Analyzing and exploiting the structure of the constraints in the ILP approach to the scheduling problem. </title> <journal> IEEE Transactions on Very Large Scale Integration Systems, </journal> <volume> 2(4) </volume> <pages> 456-471, </pages> <month> December </month> <year> 1994. </year>
Reference-contexts: Recent work by Chaudhuri et al <ref> [14] </ref> on the structure of the scheduling problem has shown techniques to formulate efficient integer linear program for scheduling straight-line (non-loop, nonbranching) code. <p> The basic idea for this reformulation is due to Chaudhuri et al <ref> [14] </ref> which has such a reformulation for straight line (nonloop, non-branching) code. The adaptation of this idea to modulo schedules for loop code is, however, not straightforward and substantially different in detail, as is the proof of the validity of this adaptation. <p> provided in [10]. 4.3 Final Formulation of the Structured Depen dence Constraints While we may simply formulate structured dependence constraints for each dependence edge (i; j) 2 E sched using Inequality (19), we may further tighten the formulation of the scheduling space using an observation made by Chaudhuri et al <ref> [14] </ref> for dependent operations in straight line (nonloop, nonbranching) code. Consider operation i, with latency l, that produces a value used by operation j. When operation i is assigned to cycle t, or any subsequent cycles [14], operation j must be assigned in a cycle t 0 t + l. <p> the formulation of the scheduling space using an observation made by Chaudhuri et al <ref> [14] </ref> for dependent operations in straight line (nonloop, nonbranching) code. Consider operation i, with latency l, that produces a value used by operation j. When operation i is assigned to cycle t, or any subsequent cycles [14], operation j must be assigned in a cycle t 0 t + l. Using a similar observation here, we may replace a r;i in the right hand side of Inequality (19) by the sum of the a x;i variables over x 2 [r; II).
Reference: [15] <author> B. Dupont de Dinechin. </author> <title> Parametric computation of margins and of minimum cumulative register lifetime dates. </title> <booktitle> Proceedings of the 9th International Workshop on Languages and Compilers for Parallel Computing, </booktitle> <year> 1996. </year>
Reference-contexts: When evaluating the structured formulation, we use Constraints (1), (5), and (20); in addition, we reformulate the minimum-buffer objective function as proposed by Dupont de Dinechin <ref> [15] </ref> in order to obtain a 0-1-structured formulation 1 . Although the MinBuff algorithm minimizes buffers, in our comparisons we always present the actual register requirements associated with these schedules. MinLife Modulo Scheduler. <p> When evaluating the structured formulation, we use Constraints (1), (5), and (20); we 1 As formulated in [7], the minimum-buffer objective function uses additional variables that are defined by constraints which are not 0-1-structured. By transforming the problem using a technique proposed in <ref> [15] </ref>, however, we may define these additional variables using constraints of the same type as Constraints (20).
Reference: [16] <author> B. Dupont de Dinechin. </author> <title> Simplex scheduling: More than lifetime-sensitive instruction scheduling. </title> <booktitle> Proceedings of the International Conference on Parallel Architecture and Compiler Techniques, </booktitle> <pages> pages 327-330, </pages> <year> 1994. </year>
Reference-contexts: When considering the traditional formulation of the modulo scheduling space, we use Constraints (1), (5), and (4,) as well as the formulation of the minimum-lifetime secondary objective function found in <ref> [16] </ref>. When evaluating the structured formulation, we use Constraints (1), (5), and (20); we 1 As formulated in [7], the minimum-buffer objective function uses additional variables that are defined by constraints which are not 0-1-structured.
Reference: [17] <author> M. Berry et al. </author> <title> The Perfect Club Benchmarks: Effective performance evaluation of supercomputers. </title> <journal> The International Journal of Supercomputer Applications, </journal> <volume> 3(3) </volume> <pages> 5-40, </pages> <month> Fall </month> <year> 1989. </year>
Reference-contexts: It uses the same formulation of the modulo scheduling space as the MinReg Modulo Scheduler, and simply returns the first schedule that it finds. In this study, we use a benchmark of 1327 loops obtained from the Perfect Club <ref> [17] </ref>, SPEC-89 [18], and the Livermore Fortran Kernels [19], as compiled by the Cydra 5 Fortran77 compiler [20] after load-store elimination, recurrence back-substitution, and IF-conversion. The resource requirements of the Cy-dra 5 [21] are precisely modeled, using the reduced machine description produced in [22].
Reference: [18] <author> J. Uniejewski. </author> <title> SPEC Benchmark Suite: Designed for today's advanced system. </title> <journal> SPEC Newsletter, </journal> <month> Fall </month> <year> 1989. </year>
Reference-contexts: It uses the same formulation of the modulo scheduling space as the MinReg Modulo Scheduler, and simply returns the first schedule that it finds. In this study, we use a benchmark of 1327 loops obtained from the Perfect Club [17], SPEC-89 <ref> [18] </ref>, and the Livermore Fortran Kernels [19], as compiled by the Cydra 5 Fortran77 compiler [20] after load-store elimination, recurrence back-substitution, and IF-conversion. The resource requirements of the Cy-dra 5 [21] are precisely modeled, using the reduced machine description produced in [22].
Reference: [19] <author> F. H. McMahon. </author> <title> The Livermore Fortran Kernels: A computer test of the numerical performance range. </title> <type> Technical Report UCRL-53745, </type> <institution> Lawrence Livermore National Laboratory, Livermore, California, </institution> <year> 1986. </year>
Reference-contexts: It uses the same formulation of the modulo scheduling space as the MinReg Modulo Scheduler, and simply returns the first schedule that it finds. In this study, we use a benchmark of 1327 loops obtained from the Perfect Club [17], SPEC-89 [18], and the Livermore Fortran Kernels <ref> [19] </ref>, as compiled by the Cydra 5 Fortran77 compiler [20] after load-store elimination, recurrence back-substitution, and IF-conversion. The resource requirements of the Cy-dra 5 [21] are precisely modeled, using the reduced machine description produced in [22].
Reference: [20] <author> J. C. Dehnert and R. A. Towle. </author> <title> Compiling for the Cydra 5. </title> <journal> In The Journal of Supercomputing, </journal> <volume> volume 7, </volume> <pages> pages 181-227, </pages> <year> 1993. </year>
Reference-contexts: In this study, we use a benchmark of 1327 loops obtained from the Perfect Club [17], SPEC-89 [18], and the Livermore Fortran Kernels [19], as compiled by the Cydra 5 Fortran77 compiler <ref> [20] </ref> after load-store elimination, recurrence back-substitution, and IF-conversion. The resource requirements of the Cy-dra 5 [21] are precisely modeled, using the reduced machine description produced in [22].
Reference: [21] <author> G. R. Beck, D. W. L. Yen, and T. L. Anderson. </author> <title> The Cydra 5 mini-supercomputer: Architecture and implementation. </title> <journal> In The Journal of Supercomputing, </journal> <volume> volume 7, </volume> <pages> pages 143-180, </pages> <year> 1993. </year>
Reference-contexts: In this study, we use a benchmark of 1327 loops obtained from the Perfect Club [17], SPEC-89 [18], and the Livermore Fortran Kernels [19], as compiled by the Cydra 5 Fortran77 compiler [20] after load-store elimination, recurrence back-substitution, and IF-conversion. The resource requirements of the Cy-dra 5 <ref> [21] </ref> are precisely modeled, using the reduced machine description produced in [22]. Note that we only model, for a given loop, the resources that are used by at least two operations, since the other resources, if any, pose no resource conflicts.
Reference: [22] <author> A. E. Eichenberger and E. S. Davidson. </author> <title> A reduced mul-tipipeline machine description that preserves scheduling constraints. </title> <booktitle> Proceedings of the ACM SIGPLAN'96 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 12-22, </pages> <month> May </month> <year> 1996. </year> <month> 12 </month>
Reference-contexts: The resource requirements of the Cy-dra 5 [21] are precisely modeled, using the reduced machine description produced in <ref> [22] </ref>. Note that we only model, for a given loop, the resources that are used by at least two operations, since the other resources, if any, pose no resource conflicts.
References-found: 22

