URL: ftp://ftp.csd.abdn.ac.uk/pub/pedwards/PUBS/byrnesv.ps.Z
Refering-URL: http://www.csd.abdn.ac.uk/~pedwards/res/drama.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: fbyrne, pedwardsg@csd.abdn.ac.uk  
Title: Refinement in Agent Groups  
Author: Ciara Byrne and Peter Edwards 
Address: King's College,  Aberdeen, Scotland AB9 2UE  
Affiliation: Department of Computing Science,  University of Aberdeen,  
Abstract: A group of intelligent agents may work together in order to solve a problem or achieve a common goal. If the group fails to achieve a goal, it may be able to adapt its behaviour so that such a goal can be achieved in the future. One of the ways in which the behaviour of the agent group can be changed is by refining the knowledge of individual agents. We are developing a distributed refinement system called DRAMA (Distributed Refinement Among Multiple Agents) to perform this task. The system makes use of a special type of agent called a refinement facilitator which coordinates the refinement process within the agent group.
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> A. H. Bond and L. Gasser, </author> <title> An Analysis of Problems and Research in DAI, </title> <booktitle> Readings in Distributed Artificial Intelligence (1988), </booktitle> <publisher> Morgan-Kaufmann, </publisher> <pages> 3-35. </pages>
Reference-contexts: Where the system consists of a number of interacting intelligent agents, performance may be evaluated by the coherence of the agent group or from the point of view of individual agents' success in achieving their goals. "Coherence will refer to how well the system behaves as a unit" <ref> [1] </ref>. Coherence may be measured along several dimensions including the quality of the solutions which the system produces, the efficiency with which solutions are produced and how gracefully performance degrades in the presence of failure or uncertainty.
Reference: 2. <author> D. Ourston and R.J. Mooney, </author> <title> Changing the Rules: A Comprehensive Approach to Theory Refinement, </title> <booktitle> Proceedings of the Eighth International Conference on Machine Learning (1991), </booktitle> <pages> 485-489. </pages>
Reference-contexts: The process of refining the knowledge of agents attempts to improve solution quality by allowing the agent group to avoid failures in the future. 2 The Refinement Problem Techniques for refining the knowledge held in a single knowledge base have already been extensively investigated <ref> [2] </ref> [3] [4] [5]. The process of refining the multiple related knowledge bases of a group of cooperating agents presents unique challenges. In addition to their domain knowledge, social agents have knowledge that allows them to interact with others. Agents may represent knowledge in different ways. <p> In this case, social knowledge may need to be refined in order to allow agents to interact in a more efficient manner. 3 Designing a Distributed Refinement System Refinement systems generally execute a cycle similar to the following (based on EITHER <ref> [2] </ref>): Recognise that a fault has occurred, locate the failure point (or postulate several possible failure points) and determine what refinements need to be made to the faulty knowledge.
Reference: 3. <author> G. Towell, J. Shavlik and M. Noordewier, </author> <title> Refinement of Approximate Domain Theories by Knowledge-Based Neural Networks, </title> <booktitle> Proceedings of the Eighth National Conference on Artificial Intelligence (1990), </booktitle> <pages> 861-866. </pages>
Reference-contexts: The process of refining the knowledge of agents attempts to improve solution quality by allowing the agent group to avoid failures in the future. 2 The Refinement Problem Techniques for refining the knowledge held in a single knowledge base have already been extensively investigated [2] <ref> [3] </ref> [4] [5]. The process of refining the multiple related knowledge bases of a group of cooperating agents presents unique challenges. In addition to their domain knowledge, social agents have knowledge that allows them to interact with others. Agents may represent knowledge in different ways.
Reference: 4. <author> B.L. Richards and R.J. Mooney, </author> <title> Learning Relations by Pathfinding, </title> <booktitle> Proceedings of the Tenth National Conference on Artificial Intelligence (1992), </booktitle> <pages> 723-738. </pages>
Reference-contexts: The process of refining the knowledge of agents attempts to improve solution quality by allowing the agent group to avoid failures in the future. 2 The Refinement Problem Techniques for refining the knowledge held in a single knowledge base have already been extensively investigated [2] [3] <ref> [4] </ref> [5]. The process of refining the multiple related knowledge bases of a group of cooperating agents presents unique challenges. In addition to their domain knowledge, social agents have knowledge that allows them to interact with others. Agents may represent knowledge in different ways.
Reference: 5. <author> S. Craw and D. Sleeman, </author> <title> The Flexibility of Speculative Refinement, </title> <booktitle> Machine Learn--ing: Proceedings of the Eighth International Workshop (1991), </booktitle> <pages> 28-32. </pages>
Reference-contexts: The process of refining the knowledge of agents attempts to improve solution quality by allowing the agent group to avoid failures in the future. 2 The Refinement Problem Techniques for refining the knowledge held in a single knowledge base have already been extensively investigated [2] [3] [4] <ref> [5] </ref>. The process of refining the multiple related knowledge bases of a group of cooperating agents presents unique challenges. In addition to their domain knowledge, social agents have knowledge that allows them to interact with others. Agents may represent knowledge in different ways.
Reference: 6. <author> R.G. Smith, </author> <title> The Contract Net Protocol: High-Level Communication and Control in a Distributed Problem Solver, </title> <journal> IEEE Transactions on Computers, </journal> <month> C-29:12 </month> <year> (1980), </year> <pages> 1104-1113. </pages>
Reference-contexts: Interaction: How to interact with other agents in order to procure services, perform tasks for others, etc. An agent may, for example, know how to use a cooperation strategy such as the Contract Net Protocol <ref> [6] </ref>). Agent Models: An agent can use these models to identify other agents with whom it is useful to interact, and to make this interaction more effective. For example, an agent may wish to determine which agents have the skills necessary to perform a particular task.
Reference: 7. <author> Y. Shoham, </author> <note> Agent-Oriented Programming, Technical Report STAN-CS-1335-90 (1990), </note> <institution> Department of Computer Science, Stanford University. </institution>
Reference-contexts: Agent-oriented programming <ref> [7] </ref> is a new programming paradigm which attempts to use mentalistic concepts such as beliefs, desires and intentions to formally describe the properties of agents. GOAL is based on Agent-K [8].
Reference: 8. <author> W. Davies and P. Edwards, Agent-K: </author> <title> An Integration of AOP and KQML, </title> <booktitle> CIKM Workshop on Intelligent Information Agents (1994), </booktitle> <editor> Y. Labrou and T. Finin (Eds), </editor> <booktitle> National Institute of Standards and Technology, </booktitle> <address> Gaithersburg, Maryland. </address>
Reference-contexts: Agent-oriented programming [7] is a new programming paradigm which attempts to use mentalistic concepts such as beliefs, desires and intentions to formally describe the properties of agents. GOAL is based on Agent-K <ref> [8] </ref>. An Agent-K agent is specified in terms of its capabilities, a set of initial beliefs and a number of commitment rules. An agent's capabilities are the actions which it can perform.
Reference: 9. <author> T. Finin, R. Fritzson, D. McKay et al, </author> <title> An Overview of KQML: A Knowledge Query and Manipulation Language, </title> <type> Technical Report (1992), </type> <institution> Department of Computer Science, University of Maryland. </institution>
Reference-contexts: A commitment rule's conditions are matched against incoming messages and the agent's current mental state. If the rule fires, then a commitment is formed to perform the action requested by the message sender. Agents use KQML (Knowledge Query and Manipulation Language) <ref> [9] </ref> messages for inter-agent communication. 4.1 The Test Domain We have implemented a simple hunter-prey scenario using agents programmed in GOAL. We chose this domain because it has previously been used in the DAI literature [10] and both agents and their environment can be defined at various levels of complexity. <p> The important thing from the point of view of the agent group is that refinements are generated and that they are presented in an appropriate manner to the refinement facilitator. 6 The Refinement Facilitator A facilitator coordinates interaction between agents. For example, KQML <ref> [9] </ref> communication facilitators are used to manage message traffic among other agents by routing messages to appropriate agents, providing buffering and translation facilities, etc.
Reference: 10. <author> M. Tan, </author> <title> Multi-Agent Reinforcement Learning: Independent vs. </title> <booktitle> Cooperative Agents, Machine Learning: Proceedings of the Tenth International Conference (1993), </booktitle> <month> 330-337. </month> <title> This article was processed using the L A T E X macro package with LLNCS style </title>
Reference-contexts: Agents use KQML (Knowledge Query and Manipulation Language) [9] messages for inter-agent communication. 4.1 The Test Domain We have implemented a simple hunter-prey scenario using agents programmed in GOAL. We chose this domain because it has previously been used in the DAI literature <ref> [10] </ref> and both agents and their environment can be defined at various levels of complexity. During experimentation, the environment may be made progressively more realistic and complex, thereby making it more difficult for agents to achieve their goals. The domain has the characteristics that it is dynamic, ongoing and unpredictable.
References-found: 10

