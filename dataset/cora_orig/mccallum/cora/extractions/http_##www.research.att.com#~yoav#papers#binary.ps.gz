URL: http://www.research.att.com/~yoav/papers/binary.ps.gz
Refering-URL: http://www.research.att.com/~yoav/publications.html
Root-URL: 
Email: yoav@research.att.com  
Title: Predicting a binary sequence almost as well as the optimal biased coin  
Author: Yoav Freund 
Date: April 3, 1996  
Web: http://www.research.att.com/orgs/ssr/people/yoav/  
Affiliation: AT&T Laboratories  
Abstract: We apply the exponential weight algorithm, introduced and Littlestone and Warmuth [17] and by Vovk [24] to the problem of predicting a binary sequence almost as well as the best biased coin. We first show that for the case of the logarithmic loss, the derived algorithm is equivalent to the Bayes algorithm with Jeffrey's prior, that was studied by Xie and Barron under probabilistic assumptions [26]. We derive a uniform bound on the regret which holds for any sequence. We also show that if the empirical distribution of the sequence is bounded away from 0 and from 1, then, as the length of the sequence increases to infinity, the difference between this bound and a corresponding bound on the average case regret of the same algorithm (which is asymptotically optimal in that case) is only 1=2. We show that this gap of 1=2 is necessary by calculating the regret of the min-max optimal algorithm for this problem and showing that the asymptotic upper bound is tight. We also study the application of this algorithm to the square loss and show that the algorithm that is derived in this case is different from the Bayes algorithm and is better than it for prediction in the worst-case.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Abramowitz and Stegun. </author> <title> Handbook of Mathematical Functions. </title> <institution> National Bureau of Standards, </institution> <year> 1970. </year>
Reference-contexts: You observe a sequence of bits x 1 ; x 2 ; : : : one bit at a time. Before observing each bit you have to predict its value. The prediction of the tth bit x t is given in terms of a number p t 2 <ref> [0; 1] </ref>. Outputting p t close to 1 corresponds to a confident prediction that x t = 1 while p t close to 0 corresponds to a confident prediction that x t = 0. <p> Outputting p t = 1=2 corresponds to making a vacuous prediction. 1 Formally, we define a loss function `(p; x) from <ref> [0; 1] </ref> fi f0; 1g to the non-negative real numbers R + . The value of `(p t ; x t ) is the loss we associate with making the prediction p t and then observing the bit x t . <p> Interestingly, if the number of trials T is fixed ahead of time then the min-max optimal strategy for the adversary who chooses the value of p is to choose it according to some fixed distribution, P worst (T) , over <ref> [0; 1] </ref> (see e.g. Blackwell [3] Ferguson [11] and Haussler [13]). The min-max optimal prediction strategy for this case is the Bayes prediction algorithm with the prior set to P worst (T) . <p> In the case of the biased coins, the assumption is that there exists some fixed value of p 2 <ref> [0; 1] </ref> for which the total loss P T t=1 `(p; x t ) is significantly smaller than T L. We do not define directly the concept of a significant difference. <p> We refer to it as the exponential weights algorithm and denote it by EW. We denote a class of models by P. In this section we assume that P is a finite set of values in <ref> [0; 1] </ref> whose element are p 1 ; : : : ; p N . We denote the cumulative loss of the model p i at time t by L (p i ; t) = t 0 =1 `(p i ; x t 0 ). The algorithm is simple. <p> The natural extension of the notion of the weights that are associated with each model in a finite class is to assume that there is a measure defined over the set of models P = <ref> [0; 1] </ref>, 7 and as the initial weights sum to one, the initial measure, denoted by 1 is a probability measure. We shall sometimes refer to this initial probability measure as the prior. <p> Similarly to the prediction rule given in Equation (14) the prediction at time t is any t 2 <ref> [0; 1] </ref> which satisfies l (0; t ) c ln 0 e (1=c)l (0;p) d t (p) 0 d t (p) (17) R 1 R 1 ! The bound that one is guaranteed in this case is T X l (x t ; t ) c ln 0 ! Interestingly, the <p> paper we develop a bound which is appropriate for the model class of the biased coins and is based on the method of Laplace integration. 7 A measure over a space W is a function from the set of measurable sets (in our case, the Borel sets in W = <ref> [0; 1] </ref>) to the real numbers in the range [0; 1]. <p> the model class of the biased coins and is based on the method of Laplace integration. 7 A measure over a space W is a function from the set of measurable sets (in our case, the Borel sets in W = <ref> [0; 1] </ref>) to the real numbers in the range [0; 1]. <p> From here on we use the symbol c to denote the minimal value that satisfies this criterion. 2. For all values of x, `(p; x) has a continuous second derivative as a function of p. 3. There exists a function p : <ref> [0; 1] </ref> ! [0; 1] such that the unique optimal model for any sequence x T whose empirical distribution is is p ( ). We use p to denote p ( ) when is clear from the context. <p> From here on we use the symbol c to denote the minimal value that satisfies this criterion. 2. For all values of x, `(p; x) has a continuous second derivative as a function of p. 3. There exists a function p : <ref> [0; 1] </ref> ! [0; 1] such that the unique optimal model for any sequence x T whose empirical distribution is is p ( ). We use p to denote p ( ) when is clear from the context. <p> More precisely, we want to choose ! so as to maximize the minimal value achieved over all choices of 2 <ref> [0; 1] </ref>. 11 As ! is a distribution, it is easy to see that the minimum of the first term 9 For a good description of the Laplace method, see chapter 2 of Murray's book [18]. 10 See the derivation of Equation (2.33) in [18]. 11 Actually, if we fix T <p> However, our goal is to choose a single distribution that will work well for all large T . We thus have to consider all rational , which, as the second derivative of h is continuous, is equivalent to considering all 2 <ref> [0; 1] </ref>. 10 in the bound is maximized if the value of this term is equal for all values of . We thus arrive at the choice of ! given in Equation (22) which exactly cancels the dependence on of the first term. <p> T 1 by R wc (EW; T; ) (29) 2 1 ln 2 1 2 + (T min ( ; 1 )) 1 1 which implies that R wc (EW; T ) 2 The last inequality shows that the regret of the exponential weights algorithm holds uniformly for all 2 <ref> [0; 1] </ref>, i.e., for all sequences. It is worthwhile to consider the more precise bound given in Inequality (29). <p> Similar observations and the same fix hold for the worst case regret. As we show at the end of the last section, the regret of algorithm BJ on the interior of <ref> [0; 1] </ref> is (1=2) ln T + (1=2) ln (=2), larger by 1=2 from the optimal performance with respect to the average regret. We now show that this small gap cannot be removed. <p> We conjecture that such an example exists also for the continuous model class P = <ref> [0; 1] </ref>. 8 Absolute Loss In this section we consider the absolute loss, which has very different properties than the log loss and the square loss. Haussler et al. [14] there is no finite value of c such that the bound (13) holds for = 1=c. <p> However, we do not need to use an infinite set of models in our analysis for this case. This is because in this case the optimal model in the class P = <ref> [0; 1] </ref> is always either p = 0 or p = 1.
Reference: [2] <author> J. M. Bernardo. </author> <title> Reference posterior distributions for bayesian inference. </title> <journal> J. Roy. Statistic. Soc. Ser. B., </journal> <volume> 41 </volume> <pages> 113-147, </pages> <year> 1979. </year>
Reference-contexts: However, these prior distributions are very peculiar (see e.g. [28]), calculating them is hard, and, most importantly, they are optimal only if T is known in advance. A more attractive option is to find an algorithm which does not need to know T in advance. Bernardo <ref> [2] </ref> suggested using the Bayes algorithm with Jeffrey's prior 3 (which we denote here by BJ), and Clarke and Barron [5] proved that this choice is asymptotically optimal for the models that are in the interior of the set.
Reference: [3] <author> David Blackwell and M.A. Girshick. </author> <title> Theory of Games and Statistical Decisions. </title> <publisher> Dover Publications, Inc, </publisher> <address> New York, </address> <year> 1954. </year> <month> 15 </month>
Reference-contexts: Interestingly, if the number of trials T is fixed ahead of time then the min-max optimal strategy for the adversary who chooses the value of p is to choose it according to some fixed distribution, P worst (T) , over [0; 1] (see e.g. Blackwell <ref> [3] </ref> Ferguson [11] and Haussler [13]). The min-max optimal prediction strategy for this case is the Bayes prediction algorithm with the prior set to P worst (T) .
Reference: [4] <author> Nicolo Cesa-Bianchi, Yoav Freund, David P. Helmbold, David Haussler, Robert E. Schapire, and Manfred K. Warmuth. </author> <title> How to use expert advice. </title> <booktitle> In Proceedings of the Twenty-Fifth Annual ACM Symposium on the Theory of Computing, </booktitle> <pages> pages 382-391, </pages> <year> 1993. </year> <note> To appear, Journal of the Association for Computing Machinery. </note>
Reference-contexts: We do this by calculating the regret of the min-max optimal algorithm for the worst-case regret with respect to the log loss. We use a rather well known lemma, stated for instance in Starkov [21, 22] and in Cesa-Bianchi et al. <ref> [4] </ref>. <p> Haussler et al. [14] there is no finite value of c such that the bound (13) holds for = 1=c. Moreover, as was shown by Cesa-Bianchi at 14 al. <ref> [4] </ref>, there is no prediction algorithm whose worst-case regret does not depend on the loss of the best model.
Reference: [5] <author> Bertrand S. Clarke and Andrew R. Barron. </author> <title> Jeffrey's prior is asymptotically least favorable under entropic risk. </title> <journal> J. Stat Planning and Inference, </journal> <volume> 41 </volume> <pages> 37-60, </pages> <year> 1994. </year>
Reference-contexts: A more attractive option is to find an algorithm which does not need to know T in advance. Bernardo [2] suggested using the Bayes algorithm with Jeffrey's prior 3 (which we denote here by BJ), and Clarke and Barron <ref> [5] </ref> proved that this choice is asymptotically optimal for the models that are in the interior of the set.
Reference: [6] <author> T. Cover and E. Ordentlich. </author> <title> Universal portfolios with side information. </title> <type> Unpublished Manuscript, </type> <year> 1995. </year>
Reference-contexts: This direction builds upon the ideas of prediction in the worst-case [12], on-line learning [7, 16, 17, 24], universal coding [9, 22, 20], universal portfolios <ref> [8, 6] </ref> and universal prediction [10]. We define trivial per-trial loss as the maximal loss incurred by the best prediction.
Reference: [7] <author> Thomas M. </author> <title> Cover. Behavior of sequential predictors of binary sequences. </title>
Reference-contexts: This direction builds upon the ideas of prediction in the worst-case [12], on-line learning <ref> [7, 16, 17, 24] </ref>, universal coding [9, 22, 20], universal portfolios [8, 6] and universal prediction [10]. We define trivial per-trial loss as the maximal loss incurred by the best prediction.
Reference: [8] <author> Thomas M. </author> <title> Cover. Universal portfolios. </title> <journal> Mathematical Finance, </journal> <volume> 1(1) </volume> <pages> 1-29, </pages> <month> Jan-uary </month> <year> 1991. </year>
Reference-contexts: This direction builds upon the ideas of prediction in the worst-case [12], on-line learning [7, 16, 17, 24], universal coding [9, 22, 20], universal portfolios <ref> [8, 6] </ref> and universal prediction [10]. We define trivial per-trial loss as the maximal loss incurred by the best prediction.
Reference: [9] <author> L. D. Davisson. </author> <title> Universal noiseless coding. </title> <journal> IEEE Trans. Inform. Theory, </journal> <volume> 19 </volume> <pages> 783-795, </pages> <year> 1973. </year>
Reference-contexts: This direction builds upon the ideas of prediction in the worst-case [12], on-line learning [7, 16, 17, 24], universal coding <ref> [9, 22, 20] </ref>, universal portfolios [8, 6] and universal prediction [10]. We define trivial per-trial loss as the maximal loss incurred by the best prediction.
Reference: [10] <author> M. Feder, N. Merhav, and M. Gutman. </author> <title> Universal prediction of individual sequences. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> 38 </volume> <pages> 1258-1270, </pages> <year> 1992. </year>
Reference-contexts: This direction builds upon the ideas of prediction in the worst-case [12], on-line learning [7, 16, 17, 24], universal coding [9, 22, 20], universal portfolios [8, 6] and universal prediction <ref> [10] </ref>. We define trivial per-trial loss as the maximal loss incurred by the best prediction.
Reference: [11] <author> Thomas S. Ferguson. </author> <title> Mathematical Statistics: A Decision Theoretic Approach. </title> <publisher> Academic Press, </publisher> <year> 1967. </year>
Reference-contexts: Interestingly, if the number of trials T is fixed ahead of time then the min-max optimal strategy for the adversary who chooses the value of p is to choose it according to some fixed distribution, P worst (T) , over [0; 1] (see e.g. Blackwell [3] Ferguson <ref> [11] </ref> and Haussler [13]). The min-max optimal prediction strategy for this case is the Bayes prediction algorithm with the prior set to P worst (T) .
Reference: [12] <author> Dean P. Foster. </author> <title> Prediction in the worst case. </title> <journal> The Annals of Statistics, </journal> <volume> 19(2) </volume> <pages> 1084-1090, </pages> <year> 1991. </year>
Reference-contexts: This direction builds upon the ideas of prediction in the worst-case <ref> [12] </ref>, on-line learning [7, 16, 17, 24], universal coding [9, 22, 20], universal portfolios [8, 6] and universal prediction [10]. We define trivial per-trial loss as the maximal loss incurred by the best prediction.
Reference: [13] <author> David Haussler. </author> <title> A general minimax result for relative entropy. </title> <type> Unpublished manuscript. </type>
Reference-contexts: Blackwell [3] Ferguson [11] and Haussler <ref> [13] </ref>). The min-max optimal prediction strategy for this case is the Bayes prediction algorithm with the prior set to P worst (T) . However, these prior distributions are very peculiar (see e.g. [28]), calculating them is hard, and, most importantly, they are optimal only if T is known in advance.
Reference: [14] <author> David Haussler, Jyrki Kivinen, and Manfred K. Warmuth. </author> <title> Tight worst-case loss bounds for predicting with expert advice. </title> <booktitle> In Computational Learning Theory: Second European Conference, </booktitle> <volume> EuroCOLT '95, </volume> <pages> pages 69-83. </pages> <publisher> Springer-Verlag, </publisher> <year> 1995. </year>
Reference-contexts: Haussler, Kivinen and Warmuth <ref> [14] </ref> studied the problem of combining models for predicting a binary sequence in detail. They give a formula for calculating the minimal 6 value of c for any loss function within a broad class such that the bound (13) holds for = 1=c. <p> It is easy to verify that the log loss and the square loss over the model class of biased coins have properties 2 and 3. The proof that property 1 holds for these loss functions can be found in Haussler et al <ref> [14] </ref>. 8 1. `(p; x) is (c; 1=c) achievable for some 0 &lt; x &lt; 1. From here on we use the symbol c to denote the minimal value that satisfies this criterion. 2. <p> We conjecture that such an example exists also for the continuous model class P = [0; 1]. 8 Absolute Loss In this section we consider the absolute loss, which has very different properties than the log loss and the square loss. Haussler et al. <ref> [14] </ref> there is no finite value of c such that the bound (13) holds for = 1=c. Moreover, as was shown by Cesa-Bianchi at 14 al. [4], there is no prediction algorithm whose worst-case regret does not depend on the loss of the best model.
Reference: [15] <author> Ming Li and Paul Vitanyi. </author> <title> An introduction to Kolmogorov complexity and its applications. </title> <booktitle> Texts and Monogaraphs in Computer Science. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1993. </year>
Reference: [16] <author> Nick Littlestone. </author> <title> Learning when irrelevant attributes abound. </title> <booktitle> In 28th Annual Symposium on Foundations of Computer Science, </booktitle> <pages> pages 68-77, </pages> <month> October </month> <year> 1987. </year>
Reference-contexts: This direction builds upon the ideas of prediction in the worst-case [12], on-line learning <ref> [7, 16, 17, 24] </ref>, universal coding [9, 22, 20], universal portfolios [8, 6] and universal prediction [10]. We define trivial per-trial loss as the maximal loss incurred by the best prediction.
Reference: [17] <author> Nick Littlestone and Manfred K. Warmuth. </author> <title> The weighted majority algorithm. </title> <journal> Information and Computation, </journal> <volume> 108 </volume> <pages> 212-261, </pages> <year> 1994. </year>
Reference-contexts: This direction builds upon the ideas of prediction in the worst-case [12], on-line learning <ref> [7, 16, 17, 24] </ref>, universal coding [9, 22, 20], universal portfolios [8, 6] and universal prediction [10]. We define trivial per-trial loss as the maximal loss incurred by the best prediction. <p> not suggest an interesting way for finding this distribution or for calculating the predictions that would be generated by using it. 5 2 The algorithm The algorithm we study is a direct generalization of the aggregating strategy of Vovk [24, 23], and the Weighted Majority algorithm of Littlestone and Warmuth <ref> [17] </ref>. We refer to it as the exponential weights algorithm and denote it by EW. We denote a class of models by P.
Reference: [18] <author> J.D. Murray. </author> <title> Asymptotic Analysis. </title> <publisher> Springer Verlag, </publisher> <year> 1973. </year> <month> 16 </month>
Reference-contexts: choose ! so as to maximize the minimal value achieved over all choices of 2 [0; 1]. 11 As ! is a distribution, it is easy to see that the minimum of the first term 9 For a good description of the Laplace method, see chapter 2 of Murray's book <ref> [18] </ref>. 10 See the derivation of Equation (2.33) in [18]. 11 Actually, if we fix T , we need to consider only values of of the form i=T . Indeed, we can find slightly better choices of ! for fixed values of T . <p> achieved over all choices of 2 [0; 1]. 11 As ! is a distribution, it is easy to see that the minimum of the first term 9 For a good description of the Laplace method, see chapter 2 of Murray's book <ref> [18] </ref>. 10 See the derivation of Equation (2.33) in [18]. 11 Actually, if we fix T , we need to consider only values of of the form i=T . Indeed, we can find slightly better choices of ! for fixed values of T .
Reference: [19] <author> Jorma Rissanen. </author> <title> Stochastic Complexity in Statistical Inquiry, </title> <booktitle> volume 15 of Series in Computer Science. World Scientific, </booktitle> <year> 1989. </year>
Reference-contexts: Thus the algorithm suggested by the logical Bayesian analysis is also (almost) optimal with respect to the worst-case regret. This result complements the results of Xie and Barron [26]. This result also merges nicely with the method of stochastic complexity advocated by Rissanen <ref> [19] </ref>.
Reference: [20] <author> Jorma Rissanen and Glen G. Langdon, Jr. </author> <title> Universal modeling and coding. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> IT-27(1):12-23, </volume> <month> January </month> <year> 1981. </year>
Reference-contexts: This direction builds upon the ideas of prediction in the worst-case [12], on-line learning [7, 16, 17, 24], universal coding <ref> [9, 22, 20] </ref>, universal portfolios [8, 6] and universal prediction [10]. We define trivial per-trial loss as the maximal loss incurred by the best prediction. <p> This result complements the results of Xie and Barron [26]. This result also merges nicely with the method of stochastic complexity advocated by Rissanen [19]. That is because any prediction algorithm can be translated into a coding algorithm and vice versa (for example, using arithmetic coding <ref> [20] </ref>.) The length of the code for a sequence x T is equal (within one bit) to the cumulative log loss of the corresponding prediction algorithm on the same sequence.
Reference: [21] <author> Yu. M. Shtarkov. </author> <title> Coding of descrete sources with unknown statistics. </title> <editor> In I. Csiszar and P. Elias, editors, </editor> <booktitle> Topics in Information Theory, </booktitle> <pages> pages 559-574. </pages> <publisher> North Holland, </publisher> <address> Amsterdam, </address> <year> 1975. </year>
Reference-contexts: We now show that this small gap cannot be removed. We do this by calculating the regret of the min-max optimal algorithm for the worst-case regret with respect to the log loss. We use a rather well known lemma, stated for instance in Starkov <ref> [21, 22] </ref> and in Cesa-Bianchi et al. [4].
Reference: [22] <author> Yu. M. Shtarkov. </author> <title> Universal sequential coding of single messages. </title> <journal> Problems of Information Transmission, </journal> <volume> 23 </volume> <pages> 175-186, </pages> <month> July-September </month> <year> 1987. </year>
Reference-contexts: This direction builds upon the ideas of prediction in the worst-case [12], on-line learning [7, 16, 17, 24], universal coding <ref> [9, 22, 20] </ref>, universal portfolios [8, 6] and universal prediction [10]. We define trivial per-trial loss as the maximal loss incurred by the best prediction. <p> We now show that this small gap cannot be removed. We do this by calculating the regret of the min-max optimal algorithm for the worst-case regret with respect to the log loss. We use a rather well known lemma, stated for instance in Starkov <ref> [21, 22] </ref> and in Cesa-Bianchi et al. [4]. <p> Using this we can explicitly calculate the worst-case regret of the min/max optimal algorithm (this result was previously shown by Starkov <ref> [22] </ref>).
Reference: [23] <author> V. G. Vovk. </author> <title> A game of prediction with expert advice. </title> <booktitle> In Proceedings of the Eighth Annual Conference on Computational Learning Theory, </booktitle> <year> 1995. </year>
Reference-contexts: However, this observation is of little value, because it does not suggest an interesting way for finding this distribution or for calculating the predictions that would be generated by using it. 5 2 The algorithm The algorithm we study is a direct generalization of the aggregating strategy of Vovk <ref> [24, 23] </ref>, and the Weighted Majority algorithm of Littlestone and Warmuth [17]. We refer to it as the exponential weights algorithm and denote it by EW. We denote a class of models by P.
Reference: [24] <author> Volodimir G. Vovk. </author> <title> Aggregating strategies. </title> <booktitle> In Proceedings of the Third Annual Workshop on Computational Learning Theory, </booktitle> <pages> pages 371-383, </pages> <year> 1990. </year>
Reference-contexts: This direction builds upon the ideas of prediction in the worst-case [12], on-line learning <ref> [7, 16, 17, 24] </ref>, universal coding [9, 22, 20], universal portfolios [8, 6] and universal prediction [10]. We define trivial per-trial loss as the maximal loss incurred by the best prediction. <p> However, this observation is of little value, because it does not suggest an interesting way for finding this distribution or for calculating the predictions that would be generated by using it. 5 2 The algorithm The algorithm we study is a direct generalization of the aggregating strategy of Vovk <ref> [24, 23] </ref>, and the Weighted Majority algorithm of Littlestone and Warmuth [17]. We refer to it as the exponential weights algorithm and denote it by EW. We denote a class of models by P. <p> As was shown by Vovk <ref> [24] </ref> and Haussler et al. the optimal parameters in this case are c = 1=2, = 2 and the optimal model is p = .
Reference: [25] <author> G. N. Watson. </author> <title> Theory of Bessel functions. </title> <publisher> Cambridge University Press, </publisher> <year> 1952. </year>
Reference-contexts: This is always the case if a &lt; t min &lt; b and might be the case if t = a or t = b. We concentrate on the first case. Laplace method, or, more formally, Watson's Lemma <ref> [25] </ref>, gives us the following asymptotic approximation for the integral in this case 10 Theorem 2 (Watson) Let f and h be functions from the segment [a; b] to the reals.
Reference: [26] <author> Qun Xie and Andrew Barron. </author> <title> Minimax redundancy for the class of memoryless sources. </title> <type> Unpublished Manuscript, </type> <year> 1995. </year>
Reference-contexts: Bernardo [2] suggested using the Bayes algorithm with Jeffrey's prior 3 (which we denote here by BJ), and Clarke and Barron [5] proved that this choice is asymptotically optimal for the models that are in the interior of the set. Finally, Xie and Barron <ref> [26] </ref> performed a detailed analysis of the BJ algorithm for the model class of biased coins and have shown that for any * &gt; 0 and any 0 &lt; ff &lt; 1: 4 lim *=T ff p1*=T ff 1 ln T = 2 (2) These two methodologies, and most prediction methodologies <p> Thus the algorithm suggested by the logical Bayesian analysis is also (almost) optimal with respect to the worst-case regret. This result complements the results of Xie and Barron <ref> [26] </ref>. This result also merges nicely with the method of stochastic complexity advocated by Rissanen [19]. <p> slightly larger bound of 1 2 ln T + 1 2 + 1 2 . 12 Finally, if = Q (1=T ) then we get an intermediate bound. 6 Comparison to other results regarding log-loss It is interesting to compare these bounds to the ones given by Xie and Barron <ref> [26] </ref>. They analyze the same algorithm on a very similar problem, but they consider the expected regret and not the worst-case regret. As was shown in the introduction, the worst-case regret upper bounds the average-case regret. <p> From the arguments given in the previous section we get that, Theorem 3 implies the bound given in Equation (10). The difference between this bound and the bound derived by Xie and Barron <ref> [26] </ref> described in Equation (2) is (1=2) ln (=2) (1=2) ln (=2e) = 0:5 nits = 0:721 bits .
Reference: [27] <author> Kenji Yamanishi. </author> <title> A decision-theoretic extension of stochastic complexity and its applications to learning. </title> <type> Unpublished Manuscript, </type> <year> 1995. </year>
Reference-contexts: The derivation given in this section was done independently, for a much more general scenario, by Yamanishi in <ref> [27] </ref>. However, as we shall see, this method, by itself, is not sufficient to prove a bound on the worst-case regret. Later in this paper we describe the additional steps required to do that. We require that the loss function `(p; x) has the following three properties.
Reference: [28] <author> Zhongxin Zhang. </author> <title> Discrete Noninformative Prioirs. </title> <type> PhD thesis, </type> <institution> Yale University, </institution> <year> 1994. </year>
Reference-contexts: Blackwell [3] Ferguson [11] and Haussler [13]). The min-max optimal prediction strategy for this case is the Bayes prediction algorithm with the prior set to P worst (T) . However, these prior distributions are very peculiar (see e.g. <ref> [28] </ref>), calculating them is hard, and, most importantly, they are optimal only if T is known in advance. A more attractive option is to find an algorithm which does not need to know T in advance.
References-found: 28

