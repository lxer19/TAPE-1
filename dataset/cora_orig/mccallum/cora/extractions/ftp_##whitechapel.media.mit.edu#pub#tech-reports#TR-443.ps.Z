URL: ftp://whitechapel.media.mit.edu/pub/tech-reports/TR-443.ps.Z
Refering-URL: http://www-white.media.mit.edu/cgi-bin/tr_pagemaker/
Root-URL: http://www.media.mit.edu
Email: Email: fbaback,wasi,sandyg@media.mit.edu  
Title: Probabilistic Matching for Face Recognition  
Author: Baback Moghaddam, Wasiuddin Wahid and Alex Pentland 
Address: 20 Ames St., Cambridge, MA 02139, USA.  
Affiliation: MIT Media Laboratory,  
Note: Beyond Eigenfaces:  
Abstract: M.I.T Media Laboratory Perceptual Computing Section Technical Report No. 443 Appears in: The 3rd IEEE Int'l Conference on Automatic Face & Gesture Recognition, Nara, Japan, April 1998 Abstract We propose a novel technique for direct visual matching of images for the purposes of face recognition and database search. Specifically, we argue in favor of a probabilistic measure of similarity, in contrast to simpler methods which are based on standard L 2 norms (e.g., template matching) or subspace-restricted norms (e.g., eigenspace matching). The proposed similarity measure is based on a Bayesian analysis of image differences: we model two mutually exclusive classes of variation between two facial images: intra-personal (variations in appearance of the same individual, due to different expressions or lighting) and extra-personal (variations in appearance due to a difference in identity). The high-dimensional probability density functions for each respective class are then obtained from training data using an eigenspace density estimation technique and subsequently used to compute a similarity measure based on the a posteriori probability of membership in the intra-personal class, which is used to rank matches in the database. The performance advantage of this probabilistic matching technique over standard nearest-neighbor eigenspace matching is demonstrated using results from ARPA's 1996 "FERET" face recognition competition, in which this algorithm was found to be the top performer.
Abstract-found: 1
Intro-found: 1
Reference: [1] <editor> V.I. Belhumeur, J.P. Hespanha, and D.J. Kriegman. Eigenfaces vs. fisherfaces: </editor> <title> Recognition using class specific linear projection. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> PAMI-19(7):711-720, </volume> <month> July </month> <year> 1997. </year>
Reference-contexts: This Bayesian (MAP) approach can also be viewed as a generalized nonlinear extension of Linear Discriminant Analysis (LDA) [8, 3] or "FisherFace" techniques <ref> [1] </ref> for face recognition. Moreover, our nonlinear generalization has distinct computational/storage advantages over these linear methods for large databases. 2 Analysis of Intensity Differences We now consider the problem of characterizing the type of differences which occur when matching two images in a face recognition task. <p> This aspect of our approach differs significantly from recent methods which use simple linear discriminant analysis techniques for recognition (e.g., [8, 3]). Our Bayesian (MAP) method can also be viewed as a generalized nonlinear (quadratic) version of Linear Discriminant Analysis (LDA) [3] or "FisherFace" techniques <ref> [1] </ref>. The computational advantage of our approach is that there is no need to compute and store an eigenspace for each individual in the gallery (as required with LDA).
Reference: [2] <author> R. Brunelli and T. Poggio. </author> <title> Face recognition : Features vs. templates. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 15(10), </volume> <month> October </month> <year> 1993. </year>
Reference-contexts: 1 Introduction Current approaches to image matching for visual object recognition and image database retrieval often make use of simple image similarity metrics such as Euclidean distance or normalized correlation, which correspond to a standard template-matching approach to recognition <ref> [2] </ref>. For example, in its simplest form, the similarity measure S (I 1 ; I 2 ) between two images I 1 and I 2 can be set to be inversely proportional to the norm jjI 1 I 2 jj. <p> Specifically, we have argued in favor of a probabilistic measure of similarity, in contrast Bayesian similarity metric. to simpler methods which are based on standard L 2 norms (e.g., template matching <ref> [2] </ref>) or subspace-restricted norms (e.g., eigenspace matching [9]). This technique is based on a Bayesian analysis of image differences which leads to a very useful measure of similarity.
Reference: [3] <author> K. Etemad and R. Chellappa. </author> <title> Discriminant analysis for recognition of human faces. </title> <booktitle> In Proc. of Int'l Conf. on Acoustics, Speech and Signal Processing, </booktitle> <pages> pages 2148-2151, </pages> <year> 1996. </year>
Reference-contexts: This Bayesian (MAP) approach can also be viewed as a generalized nonlinear extension of Linear Discriminant Analysis (LDA) <ref> [8, 3] </ref> or "FisherFace" techniques [1] for face recognition. <p> Furthermore, by equating similarity with the a posteriori probability we obtain an optimal non-linear decision rule for matching and recognition. This aspect of our approach differs significantly from recent methods which use simple linear discriminant analysis techniques for recognition (e.g., <ref> [8, 3] </ref>). Our Bayesian (MAP) method can also be viewed as a generalized nonlinear (quadratic) version of Linear Discriminant Analysis (LDA) [3] or "FisherFace" techniques [1]. <p> This aspect of our approach differs significantly from recent methods which use simple linear discriminant analysis techniques for recognition (e.g., [8, 3]). Our Bayesian (MAP) method can also be viewed as a generalized nonlinear (quadratic) version of Linear Discriminant Analysis (LDA) <ref> [3] </ref> or "FisherFace" techniques [1]. The computational advantage of our approach is that there is no need to compute and store an eigenspace for each individual in the gallery (as required with LDA).
Reference: [4] <author> I.T. Jolliffe. </author> <title> Principal Component Analysis. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1986. </year>
Reference-contexts: Recently, an efficient density estimation method was proposed by Moghaddam & Pentland [6] which divides the vector space R N into two complementary subspaces using an eigenspace decomposition. This method relies on a Principal Components Analysis (PCA) <ref> [4] </ref> to form a low-dimensional estimate of the complete likelihood which can be evaluated using only the first M principal components, where M &lt;< N .
Reference: [5] <author> B. Moghaddam and A. Pentland. </author> <title> Face recognition using view-based and modular eigenspaces. Automatic Systems for the Identification and Inspection of Humans, </title> <type> 2277, </type> <year> 1994. </year>
Reference-contexts: Note that this performance is better than or similar to recognition rates obtained by any algorithm tested on this database, and that it is lower (by about 10%) than the typical rates that we have obtained with the FERET database <ref> [5] </ref>. We attribute this lower performance to the fact that these images were selected to be particularly challenging.
Reference: [6] <author> B. Moghaddam and A. Pentland. </author> <title> Probabilistic visual learning for object representation. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> PAMI-19(7):696-710, </volume> <month> July </month> <year> 1997. </year>
Reference-contexts: P ( I j) (1) where P ( I j) is the a posteriori probability given by Bayes rule, using estimates of the likelihoods P (j I ) and P (j E ) which are derived from training data using an efficient subspace method for density estimation of high-dimensional data <ref> [6] </ref>. This Bayesian (MAP) approach can also be viewed as a generalized nonlinear extension of Linear Discriminant Analysis (LDA) [8, 3] or "FisherFace" techniques [1] for face recognition. <p> Furthermore, this computation would be highly inefficient since the intrinsic dimensionality or major degrees-of-freedom of for each class is likely to be significantly smaller than N . Recently, an efficient density estimation method was proposed by Moghaddam & Pentland <ref> [6] </ref> which divides the vector space R N into two complementary subspaces using an eigenspace decomposition. <p> The component in the orthogonal subspace F is the so-called "distance-from-feature-space" (DFFS), a Euclidean distance equivalent to the PCA residual error. The component of which lies in the feature space F is referred to as the "distance-in-feature-space" (DIFS) and is a Mahalanobis distance for Gaussian densities. As shown in <ref> [6] </ref>, the complete likelihood estimate can be written as the product of two independent marginal Gaussian densities ^ P (j) = 6 6 4 2 i=1 i ! M Y 1=2 3 7 7 4 2 (2) (NM)=2 5 (3) where P F (j) is the true marginal density in F <p> For this purpose we have used an automatic face-processing system which extracts faces from the input image and normalizes for translation, scale as well as slight rotations (both in-plane and out-of-plane). This system is described in detail in <ref> [6] </ref> and uses maximum-likelihood estimation of object location (in this case the position and scale of a face and the location of individual facial features) to geometrically align faces into standard normalized form as shown in Figure 3. 2 (a) (b) used for (a) the Gallery set (training) and (b) the
Reference: [7] <author> P. J. Phillips, H. Moon, P. Rauss, and S. Rizvi. </author> <title> The FERET evaluation methodology for face-recognition algorithms. </title> <booktitle> In IEEE Proceedings of Computer Vision and Pattern Recognition, </booktitle> <pages> pages 137-143, </pages> <month> June </month> <year> 1997. </year>
Reference-contexts: The probabilistic similarity measure was used in the September 1996 FERET competition (with subspace dimensionalities of M I = M E = 125) and was found to be the top-performing system by a typical margin of 10-20% over the other competing algorithms <ref> [7] </ref> (see Figure 7). Figure 8 shows the performance comparison between standard eigenfaces and the Bayesian method from this test. Note the 10% gain in performance afforded by the new Bayesian similarity measure.
Reference: [8] <author> D. Swets and J. Weng. </author> <title> Using discriminant eigenfeatures for image retrieval. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> PAMI-18(8):831-836, </volume> <month> August </month> <year> 1996. </year>
Reference-contexts: This Bayesian (MAP) approach can also be viewed as a generalized nonlinear extension of Linear Discriminant Analysis (LDA) <ref> [8, 3] </ref> or "FisherFace" techniques [1] for face recognition. <p> Furthermore, by equating similarity with the a posteriori probability we obtain an optimal non-linear decision rule for matching and recognition. This aspect of our approach differs significantly from recent methods which use simple linear discriminant analysis techniques for recognition (e.g., <ref> [8, 3] </ref>). Our Bayesian (MAP) method can also be viewed as a generalized nonlinear (quadratic) version of Linear Discriminant Analysis (LDA) [3] or "FisherFace" techniques [1].
Reference: [9] <author> M. Turk and A. Pentland. </author> <title> Eigenfaces for recognition. </title> <journal> Journal of Cognitive Neuroscience, </journal> <volume> 3(1), </volume> <year> 1991. </year> <month> 6 </month>
Reference-contexts: All the faces in our experiments were geometrically aligned and normalized in this manner prior to further analysis. 3.1 Eigenface Matching As a baseline comparison, we first used an eigenface matching technique for recognition <ref> [9] </ref>. The normalized images from the gallery and the probe sets were projected onto a 100-dimensional eigenspace and a nearest-neighbor rule based on a Euclidean distance measure was used to match each probe image to a gallery image. <p> Specifically, we have argued in favor of a probabilistic measure of similarity, in contrast Bayesian similarity metric. to simpler methods which are based on standard L 2 norms (e.g., template matching [2]) or subspace-restricted norms (e.g., eigenspace matching <ref> [9] </ref>). This technique is based on a Bayesian analysis of image differences which leads to a very useful measure of similarity.
References-found: 9

