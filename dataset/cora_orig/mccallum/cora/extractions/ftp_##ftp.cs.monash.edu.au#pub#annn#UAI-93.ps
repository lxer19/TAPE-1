URL: ftp://ftp.cs.monash.edu.au/pub/annn/UAI-93.ps
Refering-URL: http://www.cs.monash.edu.au/~annn/cv/pub.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Uncertainty in  Deliberation Scheduling for Time-Critical Sequential Decision Making  
Author: Thomas Dean, Leslie Pack Kaelbling, Jak Kirman, Ann Nicholson 
Address: Providence, RI 02912  
Affiliation: Department of Computer Science Brown University,  
Date: 1993  
Pubnum: AI,  
Abstract: We describe a method for time-critical decision making involving sequential tasks and stochastic processes. The method employs several iterative refinement routines for solving different aspects of the decision making problem. This paper concentrates on the meta-level control problem of deliberation scheduling, allocating computational resources to these routines. We provide different models corresponding to optimization problems that capture the different circumstances and computational strategies for decision making under time constraints. We consider precursor models in which all decision making is performed prior to execution and recurrent models in which decision making is performed in parallel with execution, accounting for the states observed during execution and anticipating future states. We describe algorithms for precursor and recurrent models and provide the results of our empirical investigations to date.
Abstract-found: 1
Intro-found: 1
Reference: [ Bellman, 1957 ] <author> Bellman, Richard 1957. </author> <title> Dynamic Programming. </title> <publisher> Princeton University Press. </publisher>
Reference-contexts: All of our current policy generation techniques are based on iterative algorithms such as value iteration <ref> [ Bellman, 1957 ] </ref> and policy iteration [ Howard, 1960 ] . In this paper, we use the latter. These techniques can be interrupted at any point to return a policy whose value improves in expectation on each iteration. <p> that we are still working in the comparatively small domain necessary to be able to compute the optimal policy over the whole domain; for larger domains, iter and whole are computationally infeasible. 5 Related Work and Conclusions Our primary interest is in applying the sequential decision making techniques of Bellman <ref> [ Bellman, 1957 ] </ref> and Howard [ Howard, 1960 ] in time-critical applications. Our initial motivation for this research arose in attempting to put the anytime synthetic projection work of Drummond and Bresina [ Drummond and Bresina, 1990 ] on more secure theoretical foundations.
Reference: [ Boddy, 1991 ] <author> Boddy, </author> <title> Mark 1991. Anytime problem solving using dynamic programming. </title> <booktitle> In Proceedings AAAI-91. AAAI. </booktitle> <pages> 738-743. </pages>
Reference-contexts: Hansson and Mayer's BPS (Bayesian Problem Solver) [ Hansson and Mayer, 1989 ] supports general state space search with decision theoretic control of inference; it may be that BPS could be used as the basis for envelope alteration. Boddy <ref> [ Boddy, 1991 ] </ref> describes solutions to related problems involving dynamic programming. For an overview of resource-bounded decision making methods, see chapter 8 of the text by Dean and Wellman [ Dean and Wellman, 1991 ] .
Reference: [ Dean and Boddy, 1988 ] <author> Dean, Thomas and Boddy, </author> <title> Mark 1988. An analysis of time-dependent planning. </title> <booktitle> In Proceedings AAAI-88. AAAI. </booktitle> <pages> 49-54. </pages>
Reference-contexts: Our initial motivation for this research arose in attempting to put the anytime synthetic projection work of Drummond and Bresina [ Drummond and Bresina, 1990 ] on more secure theoretical foundations. The approach described in this paper represents a particular instance of time-dependent planning <ref> [ Dean and Boddy, 1988 ] </ref> and borrows from, among others, Horvitz' [ Horvitz, 1988 ] approach to flexible computation.
Reference: [ Dean and Wellman, 1991 ] <author> Dean, Thomas and Well-man, </author> <title> Michael 1991. Planning and Control. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, California. </address>
Reference-contexts: Boddy [ Boddy, 1991 ] describes solutions to related problems involving dynamic programming. For an overview of resource-bounded decision making methods, see chapter 8 of the text by Dean and Wellman <ref> [ Dean and Wellman, 1991 ] </ref> . We have presented an approach to coping with uncertainty and time pressure in decision making. The approach lends itself to a variety of online computational strategies, a few of which are described in this paper.
Reference: [ Dean et al., 1993 ] <author> Dean, Thomas; Kaelbling, Leslie; Kirman, Jak; and Nicholson, </author> <title> Ann 1993. Planning with deadlines in stochastic domains. </title> <booktitle> In Proceedings AAAI-93. </booktitle> <publisher> AAAI. </publisher>
Reference-contexts: A companion paper <ref> [ Dean et al., 1993 ] </ref> provides additional details regarding algorithms for precursor-deliberation models. In this paper, we dispense with the mathematical preliminaries, and concentrate on conveying basic ideas and empirical results. <p> The data for Figure 4 was determined from one representative run of the three algorithms on a particular initial state and goal. In another paper <ref> [ Dean et al., 1993 ] </ref> we present results for the average improvement of the start state under the policy available at time t as a function of time. 4 Recurrent Deliberation 4.1 The Model In recurrent-deliberation models, the agent has to repeatedly decide how to allocate time to deliberation, taking
Reference: [ Drummond and Bresina, 1990 ] <author> Drummond, Mark and Bresina, </author> <title> John 1990. Anytime synthetic projection: Maximizing the probability of goal satisfaction. </title> <booktitle> In Proceedings AAAI-90. AAAI. </booktitle> <pages> 138-144. </pages>
Reference-contexts: At all times, the system maintains a restricted automaton. The restricted automaton and corresponding policy are improved as time permits by successive refinement. This approach was inspired by the work of Drummond and Bresina <ref> [ Drummond and Bresina, 1990 ] </ref> on anytime synthetic projection. <p> Our initial motivation for this research arose in attempting to put the anytime synthetic projection work of Drummond and Bresina <ref> [ Drummond and Bresina, 1990 ] </ref> on more secure theoretical foundations. The approach described in this paper represents a particular instance of time-dependent planning [ Dean and Boddy, 1988 ] and borrows from, among others, Horvitz' [ Horvitz, 1988 ] approach to flexible computation.
Reference: [ Hansson and Mayer, 1989 ] <author> Hansson, Othar and Mayer, </author> <title> Andrew 1989. Heuristic search as evidential reasoning. </title> <booktitle> In Proceedings of the Fifth Workshop on Uncertainty in AI. </booktitle> <pages> 152-161. </pages>
Reference-contexts: The approach described in this paper represents a particular instance of time-dependent planning [ Dean and Boddy, 1988 ] and borrows from, among others, Horvitz' [ Horvitz, 1988 ] approach to flexible computation. Hansson and Mayer's BPS (Bayesian Problem Solver) <ref> [ Hansson and Mayer, 1989 ] </ref> supports general state space search with decision theoretic control of inference; it may be that BPS could be used as the basis for envelope alteration. Boddy [ Boddy, 1991 ] describes solutions to related problems involving dynamic programming.
Reference: [ Horvitz, 1988 ] <author> Horvitz, Eric J. </author> <year> 1988. </year> <title> Reasoning under varying and uncertain resource constraints. </title> <booktitle> In Proceedings AAAI-88. AAAI. </booktitle> <pages> 111-116. </pages>
Reference-contexts: The approach described in this paper represents a particular instance of time-dependent planning [ Dean and Boddy, 1988 ] and borrows from, among others, Horvitz' <ref> [ Horvitz, 1988 ] </ref> approach to flexible computation. Hansson and Mayer's BPS (Bayesian Problem Solver) [ Hansson and Mayer, 1989 ] supports general state space search with decision theoretic control of inference; it may be that BPS could be used as the basis for envelope alteration.
Reference: [ Howard, 1960 ] <author> Howard, Ronald A. </author> <year> 1960. </year> <title> Dynamic Programming and Markov Processes. </title> <publisher> MIT Press, </publisher> <address> Cambridge, Massachusetts. </address>
Reference-contexts: All of our current policy generation techniques are based on iterative algorithms such as value iteration [ Bellman, 1957 ] and policy iteration <ref> [ Howard, 1960 ] </ref> . In this paper, we use the latter. These techniques can be interrupted at any point to return a policy whose value improves in expectation on each iteration. <p> the comparatively small domain necessary to be able to compute the optimal policy over the whole domain; for larger domains, iter and whole are computationally infeasible. 5 Related Work and Conclusions Our primary interest is in applying the sequential decision making techniques of Bellman [ Bellman, 1957 ] and Howard <ref> [ Howard, 1960 ] </ref> in time-critical applications. Our initial motivation for this research arose in attempting to put the anytime synthetic projection work of Drummond and Bresina [ Drummond and Bresina, 1990 ] on more secure theoretical foundations.
References-found: 9

