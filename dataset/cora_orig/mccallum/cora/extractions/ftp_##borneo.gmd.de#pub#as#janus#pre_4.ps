URL: ftp://borneo.gmd.de/pub/as/janus/pre_4.ps
Refering-URL: http://borneo.gmd.de/AS/janus/publi/publi.html
Root-URL: 
Title: Multiple Network Systems (Minos) Modules: Task Division and Module Discrimination 1  
Author: F.J. Smieja 
Address: Schlo Birlinghoven, 53754 Sankt Augustin, Germany.  
Affiliation: German National Research Center for Information Technology (GMD),  
Abstract: It is widely considered an ultimate connectionist objective to incorporate neural networks into intelligent systems. These systems are intended to possess a varied repertoire of functions enabling adaptable interaction with a non-static environment. The first step in this direction is to develop various neural network algorithms and models, the second step is to combine such networks into a modular structure that might be incorporated into a workable system. In this paper we consider one aspect of the second point, namely: processing reliability and hiding of wetware details. Pre- sented is an architecture for a type of neural expert module, named an Authority. An Authority consists of a number of Minos modules. Each of the Minos modules in an Authority has the same processing capabilities, but varies with respect to its particular specialization to aspects of the problem domain. The Authority employs the collection of Minoses like a panel of experts. The expert with the highest confidence is believed, and it is the answer and confidence quotient that are transmitted to other levels in a system hierarchy. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Denker, D. Schwartz, B. Wittner, S. Solla, R. Howard, L. Jackel, and J. </author> <title> Hopfield. Large automatic learning, rule extraction and generalization. </title> <journal> Complex Systems, </journal> <volume> 1(5), </volume> <year> 1987. </year>
Reference-contexts: Furthermore, the more difficult the mapping function to be learnt, the more training examples that will be necessary for decent generalization <ref> [18, 1] </ref>. Numbers explode with input space dimension size.
Reference: [2] <author> S. Grossberg. </author> <title> Adaptive pattern classification and universal recoding II: Feedback, expectation, olfaction and illusions. </title> <journal> Biological Cybernetics, </journal> <volume> 23 </volume> <pages> 187-202, </pages> <year> 1976. </year>
Reference-contexts: We may use the slow (but well generalizing) back-propagation algorithm in the worker net with a degree of confidence, since it is responsible for the monitor net learning too. One might however envisage other forms of monitor network, such as Kohonen net [4] or ART nets <ref> [2] </ref>. One might even come up with a recurrent form for use with recurrent worker networks. The simple confidence measure used in our initial implementations is identical to the output of the monitor net.
Reference: [3] <author> R. A. Jacobs and M. I. Jordan. </author> <title> Adaptive mixtures of local experts. </title> <journal> Neural Computation, </journal> <volume> 3(1), </volume> <year> 1991. </year>
Reference-contexts: Suggestion 3 is a reasonably good solution to this problem, that was employed in [10] using a Kohonen net [4] to separate pattern clusters for learning among a set of modules, and the gating idea has also been employed in <ref> [3] </ref>. Such gating is viewed here as placing too great a restriction on the system as a whole.
Reference: [4] <author> T Kohonen. </author> <title> Self-Organization and Associative Memory, </title> <booktitle> 2nd. </booktitle> <address> edition. SpringerVerlag, Berlin, </address> <year> 1988. </year>
Reference-contexts: Enforcing such unlearning at this level will degrade the expertness of the modules and the effective higher complexity of the problem will degrade the scaling prospects of the networks. Suggestion 3 is a reasonably good solution to this problem, that was employed in [10] using a Kohonen net <ref> [4] </ref> to separate pattern clusters for learning among a set of modules, and the gating idea has also been employed in [3]. Such gating is viewed here as placing too great a restriction on the system as a whole. <p> We may use the slow (but well generalizing) back-propagation algorithm in the worker net with a degree of confidence, since it is responsible for the monitor net learning too. One might however envisage other forms of monitor network, such as Kohonen net <ref> [4] </ref> or ART nets [2]. One might even come up with a recurrent form for use with recurrent worker networks. The simple confidence measure used in our initial implementations is identical to the output of the monitor net.
Reference: [5] <author> Y. le Cun. </author> <title> Medical diagnosis using neural networks. </title> <booktitle> In Proceedings of Cognitiva, </booktitle> <address> Paris, </address> <year> 1985. </year>
Reference-contexts: INTRODUCTION The great majority of work on neural networks so far has concentrated on developing different models and observing their performance either on so-called "toy-problems" [13, 11, 19], in an attempt to improve them, or on highly preprocessed and isolated examples of aspects of real-world human processing <ref> [14, 20, 5, 12] </ref>, in an attempt to demonstrate their potential. The ultimate objective is, with regard to Artificial Intel- ligence, to incorporate such networks into large hierarchical learning systems driven by centralized self-supervision and goal generators.
Reference: [6] <author> M. Minsky. </author> <title> The Society of Mind. </title> <publisher> Simon and Schuster, </publisher> <address> New York, </address> <year> 1985. </year>
Reference-contexts: By employing neural network module decomposition of problems, Authorities adopt the "divide and conquer" approach to solving difficult mapping problems. This is a way of attacking the neural network scaling problem <ref> [7, 6] </ref>: The more difficult a mapping problem (of a fixed input space size) the more hidden units that will be necessary in order to solve it [19, 17].
Reference: [7] <author> M. Minsky and S. Papert. </author> <title> Perceptrons. </title> <publisher> MIT Press, </publisher> <year> 1988. </year> <note> See particularly the Epilogue. </note>
Reference-contexts: By employing neural network module decomposition of problems, Authorities adopt the "divide and conquer" approach to solving difficult mapping problems. This is a way of attacking the neural network scaling problem <ref> [7, 6] </ref>: The more difficult a mapping problem (of a fixed input space size) the more hidden units that will be necessary in order to solve it [19, 17].
Reference: [8] <author> H. Muhlenbein. </author> <title> Limitations of multilayer perceptrons steps towards genetic neural networks. </title> <journal> Parallel Computing, </journal> <volume> 14(3) </volume> <pages> 249-260, </pages> <year> 1990. </year>
Reference-contexts: This is a modular as opposed to a neural soup technique of producing systems capable of solving problems of higher complexity <ref> [8] </ref>. Such division often might be rejected on generalization grounds. Indeed, if as many networks as patterns are available, then absolutely no generalization should perhaps be expected.
Reference: [9] <author> H. Muhlenbein and J. Kindermann. </author> <title> The dynamics of evolution and learning towards genetic neural networks. </title> <editor> In R. Pfeifer, Z. Schreter, F. Fogelman, and L. Steels, editors, </editor> <booktitle> Connectionism in Perspective, </booktitle> <address> Amsterdam, </address> <year> 1989. </year> <title> Elsevier. </title> <booktitle> Proceedings of the International Conference Connectionism in Perspective, </booktitle> <institution> University of Zurich, </institution> <month> 10-13 October </month> <year> 1988. </year>
Reference-contexts: An initial attempt at such an extension of Pandemonium was undertaken in [16] with the Pandemonium II system (see also <ref> [9] </ref>). Made available to the system was a number of feed-forward neural networks of identical structure, but different initiali- zations. Desired was to see the system use these networks to divide a problem up, resulting in each network being faced with an easier mapping task.
Reference: [10] <author> Y. Nishikawa, H. Kita, and A. Kawamura. NN/I: </author> <title> a neural network which divides and learns environments. </title> <booktitle> In Proceedings of the IJCNN-90, </booktitle> <address> Washington D.C., 1990. </address> <publisher> IEEE. </publisher>
Reference-contexts: Enforcing such unlearning at this level will degrade the expertness of the modules and the effective higher complexity of the problem will degrade the scaling prospects of the networks. Suggestion 3 is a reasonably good solution to this problem, that was employed in <ref> [10] </ref> using a Kohonen net [4] to separate pattern clusters for learning among a set of modules, and the gating idea has also been employed in [3]. Such gating is viewed here as placing too great a restriction on the system as a whole.
Reference: [11] <author> B.A. Pearlmutter. </author> <title> Learning state space trajectories in recurrent neural networks. </title> <journal> Neural Computation, </journal> <volume> 1(2) </volume> <pages> 263-269, </pages> <year> 1989. </year>
Reference-contexts: INTRODUCTION The great majority of work on neural networks so far has concentrated on developing different models and observing their performance either on so-called "toy-problems" <ref> [13, 11, 19] </ref>, in an attempt to improve them, or on highly preprocessed and isolated examples of aspects of real-world human processing [14, 20, 5, 12], in an attempt to demonstrate their potential.
Reference: [12] <author> N. Qian and T. J. Sejnowski. </author> <title> Predicting the secondary structure of globular proteins using neural network models. </title> <journal> Journal of Molecular Biology, </journal> <volume> 202:865884, </volume> <year> 1988. </year>
Reference-contexts: INTRODUCTION The great majority of work on neural networks so far has concentrated on developing different models and observing their performance either on so-called "toy-problems" [13, 11, 19], in an attempt to improve them, or on highly preprocessed and isolated examples of aspects of real-world human processing <ref> [14, 20, 5, 12] </ref>, in an attempt to demonstrate their potential. The ultimate objective is, with regard to Artificial Intel- ligence, to incorporate such networks into large hierarchical learning systems driven by centralized self-supervision and goal generators.
Reference: [13] <author> D. E. Rumelhart, G. E. Hinton, and R. J. Williams. </author> <title> Learning internal represen-tations by error propagation. </title> <journal> Nature, </journal> <volume> 323(533), </volume> <year> 1986. </year>
Reference-contexts: INTRODUCTION The great majority of work on neural networks so far has concentrated on developing different models and observing their performance either on so-called "toy-problems" <ref> [13, 11, 19] </ref>, in an attempt to improve them, or on highly preprocessed and isolated examples of aspects of real-world human processing [14, 20, 5, 12], in an attempt to demonstrate their potential. <p> The (feed-forward) net with its output nearest to the target output associated with the input pattern, as judged by the Taskmaster (loosely equivalent to Selfridge's "Decision Demon"), was allocated the learning of this pattern. Learning the pattern meant performing n back-propagation <ref> [13] </ref> steps. Thus the task domain was divided up in such a way that patterns were allocated to be learnt by those nets that were most suited to this aspect of the (possibly complicated) mapping problem, at this time.
Reference: [14] <author> T. J. Sejnowski and C. R. Rosenberg. NETtalk: </author> <title> A parallel network that learns to read aloud. </title> <journal> Complex Systems, </journal> <volume> 1(1), </volume> <year> 1987. </year>
Reference-contexts: INTRODUCTION The great majority of work on neural networks so far has concentrated on developing different models and observing their performance either on so-called "toy-problems" [13, 11, 19], in an attempt to improve them, or on highly preprocessed and isolated examples of aspects of real-world human processing <ref> [14, 20, 5, 12] </ref>, in an attempt to demonstrate their potential. The ultimate objective is, with regard to Artificial Intel- ligence, to incorporate such networks into large hierarchical learning systems driven by centralized self-supervision and goal generators.
Reference: [15] <author> O. G. Selfridge. Pandemonium: </author> <title> a paradigm for learning. </title> <booktitle> In The Mechanisation of Thought Processes: Proceedings of a Symposium Held at the National Physical Laboratory, </booktitle> <month> November </month> <year> 1958, </year> <pages> pages 511-527, </pages> <address> London: HMSO, </address> <year> 1958. </year>
Reference-contexts: The need for module reliability is discussed, then improvements are proposed in the form of the Minos module, and its inclusion in an Authority system. Finally further extensions to the Authority system are briefly outlined. PANDEMONIUM I AND II In Selfridge's 1959 paper <ref> [15] </ref> he describes the Pandemonium system, which achieves efficiency in learning recognition problem domains through the utilization of several "demons", each of which responds in a certain way to a particular input.
Reference: [16] <author> F. J. Smieja. </author> <title> Evolution of intelligent systems in a changing environment: I. First steps with a structured brain. </title> <type> Technical Report 623, </type> <institution> Gesellschaft fur Mathematik und Datenverarbeitung, </institution> <address> St Augustin, Germany, </address> <month> August </month> <year> 1988. </year>
Reference-contexts: An initial attempt at such an extension of Pandemonium was undertaken in <ref> [16] </ref> with the Pandemonium II system (see also [9]). Made available to the system was a number of feed-forward neural networks of identical structure, but different initiali- zations.
Reference: [17] <author> F. J. Smieja. </author> <title> The significance of underlying correlations in the training of a layered net. </title> <booktitle> In Abstracts of the First Annual Meeting of the INNS, supplement to Neural Networks, Vol 1, </booktitle> <address> Boston, Mass., </address> <month> September </month> <year> 1988. </year> <note> Available as Edinburgh University preprint 88/447. </note>
Reference-contexts: This is a way of attacking the neural network scaling problem [7, 6]: The more difficult a mapping problem (of a fixed input space size) the more hidden units that will be necessary in order to solve it <ref> [19, 17] </ref>. Furthermore, the more difficult the mapping function to be learnt, the more training examples that will be necessary for decent generalization [18, 1]. Numbers explode with input space dimension size.
Reference: [18] <author> F. J. Smieja and H. Muhlenbein. </author> <title> The geometry of multilayer perceptron soluti-ons. </title> <journal> Parallel Computing, </journal> <volume> 14 </volume> <pages> 261-275, </pages> <year> 1990. </year>
Reference-contexts: Furthermore, the more difficult the mapping function to be learnt, the more training examples that will be necessary for decent generalization <ref> [18, 1] </ref>. Numbers explode with input space dimension size.
Reference: [19] <author> G. Tesauro and B. Janssens. </author> <title> Scaling relationships in backpropagation learning. </title> <journal> Complex Systems, </journal> <volume> 2 </volume> <pages> 39-44, </pages> <year> 1988. </year>
Reference-contexts: INTRODUCTION The great majority of work on neural networks so far has concentrated on developing different models and observing their performance either on so-called "toy-problems" <ref> [13, 11, 19] </ref>, in an attempt to improve them, or on highly preprocessed and isolated examples of aspects of real-world human processing [14, 20, 5, 12], in an attempt to demonstrate their potential. <p> This is a way of attacking the neural network scaling problem [7, 6]: The more difficult a mapping problem (of a fixed input space size) the more hidden units that will be necessary in order to solve it <ref> [19, 17] </ref>. Furthermore, the more difficult the mapping function to be learnt, the more training examples that will be necessary for decent generalization [18, 1]. Numbers explode with input space dimension size.
Reference: [20] <author> G. Tesauro and T. Sejnowski. </author> <title> A parallel network that learns to play backgam-mon. </title> <journal> Artificial Intelligence, </journal> <note> 1988. in press. </note>
Reference-contexts: INTRODUCTION The great majority of work on neural networks so far has concentrated on developing different models and observing their performance either on so-called "toy-problems" [13, 11, 19], in an attempt to improve them, or on highly preprocessed and isolated examples of aspects of real-world human processing <ref> [14, 20, 5, 12] </ref>, in an attempt to demonstrate their potential. The ultimate objective is, with regard to Artificial Intel- ligence, to incorporate such networks into large hierarchical learning systems driven by centralized self-supervision and goal generators.
References-found: 20

