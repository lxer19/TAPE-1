URL: ftp://ftp.eecs.umich.edu/people/durfee/daiw94-vd.ps.Z
Refering-URL: http://ai.eecs.umich.edu/people/durfee/vita.html
Root-URL: http://www.cs.umich.edu
Email: fjmvidal,durfeeg@umich.edu  
Title: RMM's Solution Concept and the Equilibrium Point Solution.  
Author: Jose M. Vidal and Edmund H. Durfee 
Address: Ann Arbor, MI 48109-2122.  
Affiliation: Department of Electrical Engineering and Computer Science University of Michigan,  
Abstract: Research in distributed AI has dealt with the interactions of agents, both cooperative and self-interested. The Recursive Modeling Method (RMM) is one method used for modeling rational self-interested agents. It assumes that knowledge is nested to a finite depth. An expansion of RMM, using a sigmoid function, was proposed with the hope that the solution concept of the new RMM would approximate the Nash EP in cases where RMM S knowledge approximated the common knowledge that is assumed by game theory. In this paper, we present a mathematical analysis of RMM with the sigmoid function and prove that it indeed tries to converge to the Nash EP. However, we also show how and why it fails to do so for most cases. Using this analysis, we argue for abandoning the sigmoid function as an implicit representation of uncertainty about the depth of knowledge, in favor of an explicit representation of the uncertainty. We also suggest other avenues of research that might give us other more efficient solution concepts which would also take into consideration the cost of computation and the expected gains.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Ken Binmore. </author> <title> Modelling rational players, part 1. </title> <journal> Economics and Philosophy, </journal> <volume> 3 </volume> <pages> 179-214, </pages> <year> 1987. </year>
Reference-contexts: Recently, some game theorists have questioned the common knowledge assumption on the grounds that such an infinite nesting would be impossible to achieve in reality [5]. There have also been some computational tractability concerns which have lead to other solution concepts <ref> [1] </ref> which approximate the EP solution but only assume E k knowledge 1 . RMM has employed several different solution concepts through its history. Originally it would simply recurse down until it reached a known finite level and then propagate a solution back up.
Reference: [2] <author> Ken Binmore. </author> <title> Modelling rational players, part 2. </title> <journal> Economics and Philosophy, </journal> <volume> 4 </volume> <pages> 9-55, </pages> <year> 1988. </year>
Reference: [3] <author> Edmund H. Durfee, Jaeho Lee, and Piotr J. Gmytrasiewicz. </author> <title> Overeager reciprocal rationality and mixed strategy equilibria. </title> <booktitle> In Proceedings of the eleventh National Conference on Artificial Intelligence, </booktitle> <year> 1993. </year>
Reference-contexts: Durfee, Lee and Gmytrasiewicz <ref> [3] </ref> set about understanding the relationship between RMM and Nash EP for this particular case and discovered some differences. In an attempt to reconcile them, they considered a new solution concept, RMM with the use of a sigmoid function which we will refer to as RMM S . <p> We also address its stability problems and explain why these problems arise, with the conclusion that it would be impossible to reliably use this technique for all games. The paper starts by reviewing the aforementioned solution concepts. Section 4 presents a differentiation method, used in <ref> [3] </ref>, and proves that it sometimes finds a Nash EP solution for some games. We will later prove, in Section 6, that this is the same solution that RMM S attempts to converge to when it converges on a mixed strategy solution. <p> The problem was fixed by incorporating a sigmoid function whose role is to reduce the importance of the solutions close to the leaves of the tree. Details on this function can be found in <ref> [3] </ref>. We will call this version RMM S . The deeper levels of the hierarchy were multiplied by a sigmoid function with a very small exponent k. <p> The differentiation method used to find the EP solution in <ref> [3] </ref> is not guaranteed to always work. It might not find all the EPs. However, this method is fairly powerful and, as we shall see later, the solution it returns corresponds to the one RMM S sometimes tries to converge to.
Reference: [4] <author> Piotr J. Gmytrasiewicz, Edmund H. Durfee, and David K. Wehe. </author> <title> A decision-theoretic approach to coordinating multiagent interactions. </title> <booktitle> In Proceedings of the twelfth international joint conference on artificial intelligence, </booktitle> <year> 1991. </year>
Reference-contexts: If so, the agent should also model the other agents modeling him, and so on. This situation leads to a recursive nesting of models, which is the basic architecture of the Recursive Modeling Method (RMM), see <ref> [4] </ref>. The recursive nesting can be infinite in some situations, as would happen if common knowledge was assumed. <p> The reason is that RMM in its original form, has absolute certainty about which is the last level in the hierarchy. The sigmoid function was an attempt at reducing this certainty but, as we have shown, it is not a stable solution. The newest version of RMM <ref> [4] </ref> incorporates some of the lessons learned from this work. It does not have a sigmoid function and, instead, it chooses to explicitly represent the uncertainty about the depth of knowledge. This is accomplished with the use of probabilities.
Reference: [5] <author> Joseph Y. Halpern and Yoram Moses. </author> <title> Knowledge and common knowledge in a distributed environment. </title> <booktitle> In Proceedings of the 3rd ACM Conference on Principles of Distributed Computing, </booktitle> <year> 1984. </year>
Reference-contexts: Game theory has studied such cases extensively and has an agreed upon fixed point solution, the Nash Equilibrium Point (EP), for them. Recently, some game theorists have questioned the common knowledge assumption on the grounds that such an infinite nesting would be impossible to achieve in reality <ref> [5] </ref>. There have also been some computational tractability concerns which have lead to other solution concepts [1] which approximate the EP solution but only assume E k knowledge 1 . RMM has employed several different solution concepts through its history. <p> The complexity is especially troublesome for cases, like the ones we dealt with in this paper, where a cheap, game theoretic solution is a valid solution as long as we are willing to assume common knowledge. It is arguably impossible to achieve common knowledge <ref> [5] </ref>. However, we propose that there are cases where it might be of higher utility to assume common knowledge and arrive at an answer quickly and cheaply using some simple EP method, rather than use RMM.
Reference: [6] <author> Stuart Russell and Eric Wefald. </author> <title> Do The Right Thing. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, Mas-sachusetts, </address> <year> 1991. </year>
Reference-contexts: What we really want is for RMM to return the best answer it can get given a limited amount of time and processing power. We are currently using some of the work done on limited rationality <ref> [6] </ref> to expand RMM so that it will provide this functionality. The method involves the use of expectation functions which calculate the value of expanding a node in the hierarchy. A node will only be expanded if its value 12 is sufficiently large (i.e. we have something to gain).
Reference: [7] <author> Robert Savit. </author> <title> When random is not random: An introduction to chaos in market prices. </title> <journal> Journal of Futures Markets, </journal> <year> 1988. </year>
Reference-contexts: We also draw the line y = x. Since both opponents have the same payoffs, and therefore the same sigmoid function, we can map the behavior of the RMM S algorithm in much the same way as we would trace the behavior of a non-linear system <ref> [7] </ref>. We start with the value x = 1=2, our initial guess, and trace the progression of the solution, as seen in Figure 2. As can be seen, as the exponent k increases the sigmoid curve gets steeper around x = 1=3, the EP solution.
Reference: [8] <author> Martin Shubik. </author> <title> Game theory in the social sciences. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1985. </year>
References-found: 8

