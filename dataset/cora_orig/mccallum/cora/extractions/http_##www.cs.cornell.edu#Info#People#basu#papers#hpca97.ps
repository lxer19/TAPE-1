URL: http://www.cs.cornell.edu/Info/People/basu/papers/hpca97.ps
Refering-URL: http://www.cs.cornell.edu/Info/People/basu/papers.html
Root-URL: 
Email: -mdw,basu,tve-@cs.cornell.edu  
Title: ATM and Fast Ethernet Network Interfaces for User-level Communication  
Author: Matt Welsh, Anindya Basu, and Thorsten von Eicken 
Address: Ithaca, NY 14853, USA  
Affiliation: Department of Computer Science Cornell University,  
Abstract: Fast Ethernet and ATM are two attractive network technologies for interconnecting workstation clusters for parallel and distributed computing. This paper compares network interfaces with and without programmable coprocessors for the two types of networks using the U-Net communication architecture to provide low-latency and high-bandwidth communication. U-Net provides protected, user-level access to the network interface and offers application-level round-trip latencies as low as 60msec over Fast Ethernet and 90msec over ATM. The design of the network interface and the underlying network fabric have a large bearing on the U-Net design and performance. Network interfaces with programmable coprocessors can transfer data directly to and from user space while others require aid from the operating system kernel. The paper provides detailed performance analysis of U-Net for Fast Ethernet and ATM, including application-level performance on a set of Split-C parallel benchmarks. These results show that high-performance computing is possible on a network of PCs connected via Fast Ethernet. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> T.E. Anderson, D.E. Culler, D.A. Patterson, et. al. </author> <title> A Case for NOW (Networks of Workstations). </title> <booktitle> IEEE Micro, </booktitle> <month> Feb. </month> <year> 1995, </year> <pages> pages 54-64. </pages>
Reference-contexts: Each system consists of two Fast Ethernet controllers operating in a round-robin fashion to double the aggregate bandwidth per node. This project employs the same network hardware and operating system as U-Net/FE, however, all network access is through the kernel sockets interface. Similarly, the Berkeley Network-of-Workstations <ref> [1] </ref> project aims to form large-scale distributed and parallel computing systems out of off-the-shelf components, connected via FDDI or Myrinet. 3 U-Net communication architecture The U-Net architecture virtualizes the network interface in such a way that a combination of operating system and hardware mechanisms can provide every application the illusion of
Reference: [2] <author> D. Becker, T. Sterling, D. Savarese, B. Fryxell, and K. Olson. </author> <title> Communication Overhead for Space Science Applications on the Beowulf Parallel Workstation. </title> <booktitle> In Proc. of the 4th HPDC 95. </booktitle>
Reference-contexts: The ParaStation [18] system obtains small-message (4-byte) send and receive processor overheads of about 2.5msec using specialized hardware and user-level unprotected access to the network interface. The Beowulf <ref> [2] </ref> project has constructed a workstation cluster consisting of Pentium systems connected via Fast Ethernet. Each system consists of two Fast Ethernet controllers operating in a round-robin fashion to double the aggregate bandwidth per node.
Reference: [3] <author> M. Blumrich, C. Dubnicki, E. W. Felten and K. Li. </author> <title> Virtual-Memory-Mapped Network Interfaces . IEEE Micro, </title> <month> Feb. </month> <year> 1995, </year> <pages> pages 21-28. </pages>
Reference-contexts: 1 Introduction High-performance computing on clusters of workstations requires low-latency communication to efficiently implement parallel languages and distributed algorithms. Recent research <ref> [3, 8, 16] </ref> has demonstrated that direct application access to the network interface can provide both low-latency and high-bandwidth communication over commodity networks such as 155Mbps ATM and 100Base-TX Fast Ethernet. <p> The HP Hamlyn [20] network architecture also implements a user-level communication model similar to Active Messages but uses a custom network interface where message sends and receives are implemented in hardware. Shrimp <ref> [3] </ref> allows processes to connect virtual memory pages on two nodes through the use of custom network interfaces; memory accesses to such pages on one side are automatically mirrored on the other side.
Reference: [4] <author> D. Boggs, J. Mogul, and C. Kent. </author> <title> Measured Capacity of an Ethernet: Myths and Reality. </title> <note> WRL Research Report 88/4, </note> <institution> Western Research Laboratory, </institution> <month> September </month> <year> 1988. </year>
Reference: [5] <author> D. E. Culler, A. Dusseau, S. C. Goldstein, A. Krishnamur-thy, S. Lumetta, T. von Eicken, and K. Yelick. </author> <title> Introduction to Split-C. </title> <booktitle> In Proc. of Supercomputing '93. </booktitle>
Reference-contexts: A previous implementation of U-Net over ATM [16] demonstrated that this architecture is able to efficiently support low-latency communication protocols such as Active Messages [17] for use as a workstation cluster interconnect for parallel computing. Split-C <ref> [5] </ref>, a state-of-the-art parallel language, has been implemented using Active Messages over U-Net and, on a cluster of SPARCStations connected via ATM, shows performance comparable to MPPs such as the CM-5 and the Meiko CS-2. <p> One solution would be to use a simple IPv4 encapsulation for U-Net messages; however, this would add considerable communication overhead. U-Net/ATM does not suffer this problem as ATM virtual circuits are established network-wide. 5 Parallel Algorithm Benchmarks A set of parallel algorithm benchmarks written in the Split-C <ref> [5] </ref> language have been employed to compare high-level application performance of the two U-Net implementations. The Split-C language allows processes to transfer data through the use of global pointers a virtual address coupled with a process identifier. <p> The performance of this benchmark suite on a variety of multiprocessors is presented in <ref> [5] </ref>. The matrix multiply application was run twice, once using matrices of 8 by 8 blocks with 128 by 128 double oats in each block, and once using 16 by 16 blocks with 16 by 16 double oats in each block. The main loop in the 3.
Reference: [6] <author> D. E. Culler, A. Dusseau, R. Martin, K. E. Schauser. </author> <title> Fast Parallel Sorting: from LogP to Split-C. </title> <booktitle> In Proc. of WPPP '93, </booktitle> <month> July 93. </month>
Reference: [7] <author> D.E. Culler, et. al. </author> <title> Generic Active Message Interface Specification, </title> <note> version 1.1. http://now.cs.berkeley.edu/Papers/Papers/gam_spec.ps </note>
Reference: [8] <author> P. Druschel and L. Peterson. Fbufs: </author> <title> A High-Bandwidth Cross-Domain Transfer Facility. </title> <booktitle> In Proc. of the 14th SOSP. </booktitle> <pages> pages 189-202. </pages> <month> December </month> <year> 1993. </year>
Reference-contexts: 1 Introduction High-performance computing on clusters of workstations requires low-latency communication to efficiently implement parallel languages and distributed algorithms. Recent research <ref> [3, 8, 16] </ref> has demonstrated that direct application access to the network interface can provide both low-latency and high-bandwidth communication over commodity networks such as 155Mbps ATM and 100Base-TX Fast Ethernet.
Reference: [9] <author> P. Druschel, L. Peterson, and B.S. Davie. </author> <title> Experiences with a HighSpeed Network adapter: A Software Perspective. </title> <booktitle> In Proc. of SIGCOMM-94, </booktitle> <pages> pages 2-13, </pages> <month> Aug </month> <year> 1994. </year>
Reference: [10] <author> A. Edwards, G. Watson, J. Lumley, D. Banks, C. Calam-vokis and C.Dalton. </author> <title> Userspace protocols deliver high performance to applications on a low-cost Gb/s LAN. </title> <booktitle> In Proc. of SIGCOMM-94, </booktitle> <pages> pages 14-23, </pages> <month> Aug. </month> <year> 1994 </year>
Reference: [11] <author> J. Kay and J. Pasquale. </author> <title> The importance of Non-Data Touching Processing Overheads. </title> <booktitle> In Proc. of SIGCOMM-93, </booktitle> <pages> pages 259-269, </pages> <month> Aug. </month> <year> 1993 </year>
Reference: [12] <author> S. Pakin, M. Lauria, and A. Chien. </author> <title> High Performance Messaging on Workstations: Illinois Fast Messages (FM) for Myrinet. </title> <booktitle> In Proc. of Supercomputing '95, </booktitle> <address> San Diego, Cali-fornia. </address>
Reference-contexts: Several of these models propose to introduce special-purpose networking hardware. Thekkath [14] proposes to separate the control and data ow of network access using a shared-memory model; remote-memory operations are implemented as unused opcodes in the MIPS instruction set. The Illinois Fast Messages <ref> [12] </ref> achieve high performance on a Myrinet network using communication primitives similar to Active Messages. The network interface is accessed directly from userspace but does not provide support for simultaneous use by multiple applications.
Reference: [13] <author> R. Seifert. </author> <title> The Effect of Ethernet Behavior on Networks using High-Performance Workstations and Servers. </title> <address> http://wwwhost.ots.utexas.edu/ethernet/pdf/techrept13.pdf </address>
Reference: [14] <author> C. A. Thekkath, H. M. Levy, and E. D. Lazowska. </author> <title> Separating Data and Control Transfer in Distributed Operating Systems. </title> <booktitle> In Proc. of the 6th Intl Conf. on ASPLOS, </booktitle> <month> Oct </month> <year> 1994. </year>
Reference-contexts: Several of these models propose to introduce special-purpose networking hardware. Thekkath <ref> [14] </ref> proposes to separate the control and data ow of network access using a shared-memory model; remote-memory operations are implemented as unused opcodes in the MIPS instruction set. The Illinois Fast Messages [12] achieve high performance on a Myrinet network using communication primitives similar to Active Messages.
Reference: [15] <author> T. von Eicken, A.Basu and V.Buch. </author> <title> Low-Latency Communication Over ATM Networks Using Active Messages. </title> <booktitle> IEEE Micro, </booktitle> <month> Feb. </month> <year> 1995, </year> <pages> pages 46-53. </pages>
Reference: [16] <author> T. von Eicken, A. Basu, V. Buch, and W. Vogels. U-Net: </author> <title> A User-Level Network Interface for Parallel and Distributed Computing. </title> <booktitle> In Proc. of the 15th ACM SOSP, </booktitle> <pages> pages 40-53, </pages> <month> December </month> <year> 1995. </year>
Reference-contexts: 1 Introduction High-performance computing on clusters of workstations requires low-latency communication to efficiently implement parallel languages and distributed algorithms. Recent research <ref> [3, 8, 16] </ref> has demonstrated that direct application access to the network interface can provide both low-latency and high-bandwidth communication over commodity networks such as 155Mbps ATM and 100Base-TX Fast Ethernet. <p> This shifts most of the protocol processing to user-level where it can often be specialized and better integrated into the application thus yielding higher performance. Protection is ensured through the virtual memory system and through kernel control of connection setup and tear-down. A previous implementation of U-Net over ATM <ref> [16] </ref> demonstrated that this architecture is able to efficiently support low-latency communication protocols such as Active Messages [17] for use as a workstation cluster interconnect for parallel computing. <p> A Bay Networks 100BaseTX hub, a Bay Networks 28115 16-port switch and a Cabletron FN100 8-port switch were individually employed. 4.2 ATM Network Interface Operation The U-Net implementation for the PCA-200 uses custom firmware to implement U-Net directly and is largely identical to that of the Sbus-based SBA-200 described in <ref> [16] </ref>. The firmware allows multiple user processes to concurrently communicate with the onboard i960 which maintains a data structure that contains protection information for all open endpoints. <p> This sharp rise can be attributed to the fact that both transmit and receive on U-Net/ATM are optimized 2. U-Net over ATM on 140Mbps TAXI achieves 65ms round-trip latency <ref> [16] </ref>; the additional overhead here is incurred due to OC-3c SONET framing. for single cell sends and receives, in particular, a single cell receive does not involve the additional cost of receive buffer allocation. <p> Dereferenc-ing a global pointer allows a process to read or write data in the address space of other nodes cooperating in the parallel application. Split-C is implemented over Active Messages [17], a low-cost RPC mechanism, providing ow control and reliable transfer, which has been implemented over U-Net <ref> [16] </ref>.
Reference: [17] <author> T. von Eicken, D. E. Culler, S. C. Goldstein, and K. E. Schauser. </author> <title> Active Messages: A Mechanism for Integrated Communication and Computation. </title> <booktitle> In Proc. of the 19th ISCA, </booktitle> <pages> pages 256-266, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: Protection is ensured through the virtual memory system and through kernel control of connection setup and tear-down. A previous implementation of U-Net over ATM [16] demonstrated that this architecture is able to efficiently support low-latency communication protocols such as Active Messages <ref> [17] </ref> for use as a workstation cluster interconnect for parallel computing. Split-C [5], a state-of-the-art parallel language, has been implemented using Active Messages over U-Net and, on a cluster of SPARCStations connected via ATM, shows performance comparable to MPPs such as the CM-5 and the Meiko CS-2. <p> Dereferenc-ing a global pointer allows a process to read or write data in the address space of other nodes cooperating in the parallel application. Split-C is implemented over Active Messages <ref> [17] </ref>, a low-cost RPC mechanism, providing ow control and reliable transfer, which has been implemented over U-Net [16].
Reference: [18] <author> T. M. Warschko, W. F. Tichy, and C. H. Herter. </author> <title> Efficient Parallel Computing on Workstation Clusters. </title> <address> http://wwwipd.ira.uka.de/~warschko/parapc/sc95.html </address>
Reference-contexts: Shrimp [3] allows processes to connect virtual memory pages on two nodes through the use of custom network interfaces; memory accesses to such pages on one side are automatically mirrored on the other side. The ParaStation <ref> [18] </ref> system obtains small-message (4-byte) send and receive processor overheads of about 2.5msec using specialized hardware and user-level unprotected access to the network interface. The Beowulf [2] project has constructed a workstation cluster consisting of Pentium systems connected via Fast Ethernet.
Reference: [19] <author> M. Welsh, A. Basu, and T. von Eicken. </author> <title> Low-latency communication over Fast Ethernet. </title> <booktitle> In Proc. of EuroPar 96, </booktitle> <address> Lyon, France, </address> <month> August </month> <year> 1996. </year>
Reference-contexts: Split-C [5], a state-of-the-art parallel language, has been implemented using Active Messages over U-Net and, on a cluster of SPARCStations connected via ATM, shows performance comparable to MPPs such as the CM-5 and the Meiko CS-2. Recently a Fast Ethernet implementation <ref> [19] </ref> demonstrated that U-Net can be implemented efficiently over a network substrate other than ATM. U-Net over Fast Ethernet uses a substantially simpler network interface than the ATM implementation. <p> Two important outstanding questions were whether the U-Net model is only feasible over connection-oriented networks such as ATM and whether the use of a programmable coprocessor on the network adapter in the ATM implementation is a necessary part of the design. The implementation of U-Net over Fast Ethernet (U-Net/FE) <ref> [19] </ref> explores the use of Fast Ethernet as an alternative to ATM. It shows that the U-Net design itself does not depend upon specific features of ATM networks or on the use of a programmable coprocessor on the network interface.
Reference: [20] <author> J. Wilkes. </author> <title> An interface for sender-based communication. </title> <type> Tech. Rep. </type> <institution> HPL-OSR-92-13, Hewlett-Packard Research Laboratory, </institution> <month> Nov. </month> <year> 1992. </year>
Reference-contexts: The Illinois Fast Messages [12] achieve high performance on a Myrinet network using communication primitives similar to Active Messages. The network interface is accessed directly from userspace but does not provide support for simultaneous use by multiple applications. The HP Hamlyn <ref> [20] </ref> network architecture also implements a user-level communication model similar to Active Messages but uses a custom network interface where message sends and receives are implemented in hardware.
References-found: 20

