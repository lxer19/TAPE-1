URL: http://www.cs.msu.edu/~stockman/Papers/3D.freeform.indexing.ps.Z
Refering-URL: http://www.cs.msu.edu/~stockman/pubs.html
Root-URL: http://www.cs.msu.edu
Email: chenjj@pixel.cps.msu.edu, stockman@pixel.cps.msu.edu  
Phone: Phone: 517-355-5240 FAX 517-432-1061  
Title: 3D Free-form Object Recognition using Indexing by Contour Features  
Author: Jin-Long Chen and George C. Stockman 
Note: Corresponding Author: George Stockman  
Address: East Lansing, MI 48824-1027  
Affiliation: Department of Computer Science Michigan State University  
Abstract: We address the problem of recognizing free-form 3D objects from a single 2D intensity image. A model-based solution within the alignment paradigm is presented which involves three major schemes modeling, matching, and indexing. The modeling scheme constructs a set of model aspects which can predict the object contour as seen from any viewpoint. The matching scheme aligns the edgemap of a candidate model to the observed edgemap using an initial approximate pose. The major contribution of this paper involves the indexing scheme and its integration with modeling and matching to perform recognition. Indexing generates hypotheses specifying both candidate model aspects and approximate pose and scale. Hypotheses are ordered by likelyhood based on prior knowledge of pre-stored models and the visual evidence from the observed objects. A prototype implementation has been tested in recognition and localization experiments with a database containing 658 model aspects from 20 3D objects and 80 2D objects. Bench tests and simulations show that many kinds of objects can be handled accurately and efficiently even in cluttered scenes. We conclude that the proposed recognition-by-alignment paradigm is a viable approach to many 3D object recognition problems. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> N. Ayache and O. D. Faugeras. </author> <title> HYPER: A new approach for the recognition and positioning of two-dimensional objects. </title> <journal> IEEE Trans. on Pattern Analysis and Machine Intelligence, </journal> <volume> 8(1) </volume> <pages> 44-54, </pages> <year> 1986. </year>
Reference-contexts: Most successful recognition systems developed so far have used polyhedral object models and have relied on matching special features such as corners, lines, or holes. A commonly adopted strategy is recognition-by-alignment [24] or hypothesize-and-verify <ref> [1, 14, 16, 22, 29, 36] </ref>. Minimal sets of features are used to form hypothetical correspondences between an image and a pre-stored object model.
Reference: [2] <author> D. H. Ballard and C. H. Brown. </author> <title> Computer Vision. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, New Jersey, </address> <year> 1982. </year>
Reference-contexts: The quantity & has been shown to be invariant to translation, rotation, and scaling <ref> [2, 27] </ref>. Roundness: the roundness of C, t (C), is the sum of the absolute curvatures along C, i.e., i=0 j i j where i is the curvature at point p i . <p> We can rearrange Eq.(9) as j ( i 0 j )j * and quantize the difference of orientation using 2* as a unit into cells in the range of <ref> [2; 2] </ref>. H i and H j are said to be consistent if i 0 i and j 0 j fall into the same cell. In this way, hypotheses in the same cells are grouped together.
Reference: [3] <author> R. Basri. </author> <title> The alignment of objects with smooth surfaces: Error analysis of the curvature method. </title> <booktitle> In Proceedings IEEE Conf. on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 341-346, </pages> <address> Illinois, </address> <month> June </month> <year> 1992. </year>
Reference-contexts: Accurate predictions were achieved despite that (1) the object had complex 3D shape; (2) the light reflectance distorted some of the internal edges; and (3) only five images were used to create a crude approximation of the radii of curvature at the limbs. This replicates previous results of Basri <ref> [3] </ref>. (a) phone1 (b) swan2 (c) cup (d) face 24 7.2 Matching Results The matching algorithm has succeeded in deriving object pose by aligning only the silhouettes [12].
Reference: [4] <author> R. Basri and S. Ullman. </author> <title> The alignment of objects with smooth surfaces. </title> <booktitle> In Proceedings 2nd Int. Conf. on Computer Vision, </booktitle> <pages> pages 482-488, </pages> <address> Florida, </address> <month> December </month> <year> 1988. </year>
Reference-contexts: The modeling scheme is an extension of the curvature method of Basri and Ullman <ref> [4] </ref>. The matching scheme uses Newton's method with Levenberg-Marquart minimization and heuristics to handle occlusion and imperfect feature detection. The work presented in this paper adds two important contributions. <p> The object recognition system which we propose comprises three primary techniques: complex object modeling, probabilistic indexing, and robust matching. Complex Object Modeling: The modeling method is an extension of the curvature method of Basri and Ullman <ref> [4] </ref> extended for use with object aspects. The modeling scheme builds/learns 3D models from sets of 2D images taken at controlled viewpoints. The approach accounts for the changes in image contours due to small changes in viewpoint for 4 limbs, blades, and creases. <p> While CAD models may support this, a great deal of effort is needed to create a model of some free-form objects. Thus, we used a stereo-based algorithm which allows the model to be automatically learned from images. We briefly review the modeling method here; see <ref> [4, 11] </ref> for details. An object model is constructed from a set of 2D intensity images taken from controlled viewpoints of the viewsphere. <p> Two types of edges are used in modeling: silhouette and internal edges. The object silhouette is generated by the orthographic projection of the rim which is the set of all points on the object surface with surface normal perpendicular to the visual axis <ref> [4] </ref>. Internal edges of an aspect are those visible at any viewpoint within the aspect and are caused by known discontinuities in albedo or surface normal or by artifacts such as 8 illumination or shadows [11]. <p> The Z-axis is the visual axis, and the Y-axis points out of the paper. (b) The object is rotated about the Y-axis. p is the new rim point approximated by Eq. (1) (based on <ref> [4] </ref>). p 2 is the corresponding point of p 2 after rotation. Let X and Y be the main axes of the image plane, and let Z be the visual axis. Consider a smooth object under rotation R around the vertical axis Y. <p> t and p to be (x; y; z z c ) t , Eq. (1) can be changed into a simpler equation: p = R (p r) + r: (2) The relative depth z z c and the modified curvature vector r at p are derived from the model construction <ref> [4] </ref> and are stored as parts of the object model.
Reference: [5] <author> J. S. Beis and D. G. Lowe. </author> <title> Learning indexing functions for 3-D model-based object recognition. </title> <booktitle> In Proceedings IEEE Conf. on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 275-280, </pages> <address> Seattle, WA, </address> <year> 1994. </year>
Reference-contexts: In addition, researchers have studied indexing schemes for quickly recovering correspondence hypotheses without resorting to comparison of all pairs of model/image feature sets <ref> [5, 8, 13, 26, 32, 33] </ref>. The problem of pose estimation from feature correspondences has also been studied independent of other stages [12, 25, 30, 35].
Reference: [6] <author> R. C. Bolles and R. A. Cain. </author> <title> Recognizing and locating partially visible objects, the local-feature-focus method. </title> <journal> Int. Journal of Robotics Research, </journal> <volume> 1(3) </volume> <pages> 57-82, </pages> <year> 1982. </year>
Reference-contexts: Techniques have been developed to make the search for correspondences more efficient by applying geometric constraints [18, 19] or by using local feature focus methods <ref> [6, 7, 15] </ref>. In addition, researchers have studied indexing schemes for quickly recovering correspondence hypotheses without resorting to comparison of all pairs of model/image feature sets [5, 8, 13, 26, 32, 33].
Reference: [7] <author> R. C. Bolles and P. Horaud. 3DPO: </author> <title> A three-dimensional part orientation system. </title> <journal> Int. Journal of Robotics Research, </journal> <volume> 5(3) </volume> <pages> 3-26, </pages> <year> 1986. </year>
Reference-contexts: Techniques have been developed to make the search for correspondences more efficient by applying geometric constraints [18, 19] or by using local feature focus methods <ref> [6, 7, 15] </ref>. In addition, researchers have studied indexing schemes for quickly recovering correspondence hypotheses without resorting to comparison of all pairs of model/image feature sets [5, 8, 13, 26, 32, 33].
Reference: [8] <author> J. B. Burns, R. S. Weiss, and E. M. Riseman. </author> <title> View variation of point-set and line-segment features. </title> <journal> IEEE Trans. on Pattern Analysis and Machine Intelligence, </journal> <volume> 15(1) </volume> <pages> 51-68, </pages> <year> 1993. </year>
Reference-contexts: In addition, researchers have studied indexing schemes for quickly recovering correspondence hypotheses without resorting to comparison of all pairs of model/image feature sets <ref> [5, 8, 13, 26, 32, 33] </ref>. The problem of pose estimation from feature correspondences has also been studied independent of other stages [12, 25, 30, 35].
Reference: [9] <author> C.-C. Chen. </author> <title> Improved moment invariants for shape discrimination. </title> <journal> Pattern Recognition, </journal> <volume> 26(5) </volume> <pages> 683-686, </pages> <year> 1993. </year>
Reference-contexts: The skewness, of the part, (C) is defined as (C) = cos 1 ~ p 0 p N1 ~ p m p N=2 Moment invariants: Moment invariants are well known in pattern recognition [23]. Modified moments using only the curve boundary were defined in <ref> [9] </ref>. After experimenting with the use of several normalized moments, we settled on only one of them (denoted as 1 ) the sum of the two normalized second moments [10].
Reference: [10] <author> J.-L. Chen. </author> <title> On Recognizing and Tracking 3D Curved Objects From 2D Images. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, Michigan State University, </institution> <year> 1996. </year>
Reference-contexts: Modified moments using only the curve boundary were defined in [9]. After experimenting with the use of several normalized moments, we settled on only one of them (denoted as 1 ) the sum of the two normalized second moments <ref> [10] </ref>. Convexity: The codon representation is susceptible to spurious extrema resulting from noise, preventing it from being a reliable part descriptor by itself. <p> Here we include more results in addition to those reported in [11]. (a) blockB7 (b) can (c) zebra1 (d) mug26 The edgemap alignment algorithm was tested on a total of 60 aspect models. Figure 12 shows a few alignment examples (see <ref> [10] </ref> for more results). Test objects were partially occluded in several test scenes. As can be seen from the white contours in Figure 12, most of the observed objects are well fitted. Table 1 shows the goodness of the fit. <p> The last row of Figure 15 depicts the results of hand initialized model fitting, demonstrating that these four objects do have corresponding models in the database and that the matching stage can verify this. Additional examples can be found in <ref> [10] </ref>. The recognition system breaks if the indexing scheme fails to generate correct model hypotheses for verification and this occurs when all the parts of an observed object are occluded. 8 Concluding Discussion This paper describes two significant contributions toward the recognition of free-form 3D objects.
Reference: [11] <author> J.-L. Chen and G. C. Stockman. </author> <title> Determining pose of 3d objects with curved surfaces. </title> <journal> IEEE Trans. on Pattern Analysis and Machine Intelligence, </journal> <volume> 18(1) </volume> <pages> 52-57, </pages> <year> 1996. </year>
Reference-contexts: In previous work <ref> [11] </ref>, we have reported solutions to subproblems 1 and 4; that is, we have given a viable modeling method and have shown how to match a model to image edges assuming that an approximate pose is known. <p> We adopt a least-squares minimization approach | similar to the approach in [30] | to reliably estimate the object pose. This minimization technique uses heuristics to estimate pose and is relatively robust to outliers occurring due to partial occlusion <ref> [11] </ref> and imperfect image segmentation. We argue that the approach given in this paper overcomes the common problems and enables construction of practical machine vision systems for handling free-form objects. Our previous work [11] demonstrated the capability of modeling free-form objects and matching models to images; those results are briefly surveyed <p> technique uses heuristics to estimate pose and is relatively robust to outliers occurring due to partial occlusion <ref> [11] </ref> and imperfect image segmentation. We argue that the approach given in this paper overcomes the common problems and enables construction of practical machine vision systems for handling free-form objects. Our previous work [11] demonstrated the capability of modeling free-form objects and matching models to images; those results are briefly surveyed in Sections 3 and 4 after the general paradigm is given in Section 2. <p> While CAD models may support this, a great deal of effort is needed to create a model of some free-form objects. Thus, we used a stereo-based algorithm which allows the model to be automatically learned from images. We briefly review the modeling method here; see <ref> [4, 11] </ref> for details. An object model is constructed from a set of 2D intensity images taken from controlled viewpoints of the viewsphere. <p> Internal edges of an aspect are those visible at any viewpoint within the aspect and are caused by known discontinuities in albedo or surface normal or by artifacts such as 8 illumination or shadows <ref> [11] </ref>. Unlike silhouette edges, internal edges are not usually occluded by the object surface under a small rotation. Thus, corresponding points on internal edges before and after rotation usually exist in multiple images. <p> We use the Levenberg-Marquardt algorithm to solve the overall least-squares minimization problem. Two heuristics are used in the iterative matching process (see <ref> [11] </ref> for more detail). A heuristic is used to maintain a balance in the importance of silhouette and internal edge alignment as fitting progresses. <p> A detailed edgemap matching algorithm is given in <ref> [11] </ref>. The second heuristic would fail to synthesize good local point correspondences if the observed edgemap and the model edgemap were not approximately scaled so an approximate scale must be initially given. <p> Thus, rejecting false model-pose hypotheses at an early stage of the verification process can reduce the recognition time significantly. We incorporate a hierarchical verification strategy into the recognition system to expedite the alignment tests. 21 The NLM method (i.e., the edgemap matching algorithm as presented in <ref> [11] </ref>) uses two parameters: the maximum number of iterations allowed, I max , and the matching error threshold, E t , to determine when the algorithm should terminate. <p> This replicates previous results of Basri [3]. (a) phone1 (b) swan2 (c) cup (d) face 24 7.2 Matching Results The matching algorithm has succeeded in deriving object pose by aligning only the silhouettes [12]. In <ref> [11] </ref>, we have shown that (1) the algorithm can handle partially occluded objects and objects with internal edges; (2) the basin of the convergence is broad; (3) the accuracy of the derived object pose can be further improved by introducing internal object edges in the alignment process. <p> Here we include more results in addition to those reported in <ref> [11] </ref>. (a) blockB7 (b) can (c) zebra1 (d) mug26 The edgemap alignment algorithm was tested on a total of 60 aspect models. Figure 12 shows a few alignment examples (see [10] for more results). Test objects were partially occluded in several test scenes.
Reference: [12] <author> J.-L. Chen, G. C. Stockman, and K. Rao. </author> <title> Recovering and tracking pose of curved 3D objects from 2D images. </title> <booktitle> In Proceedings IEEE Conf. on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 233-239, </pages> <address> New York, </address> <month> June </month> <year> 1993. </year>
Reference-contexts: In addition, researchers have studied indexing schemes for quickly recovering correspondence hypotheses without resorting to comparison of all pairs of model/image feature sets [5, 8, 13, 26, 32, 33]. The problem of pose estimation from feature correspondences has also been studied independent of other stages <ref> [12, 25, 30, 35] </ref>. Our current work addresses remaining problems that need to be overcome in order to construct more general machine vision systems: first, we need to handle free-form objects and second we need to handle significant occlusion. <p> This replicates previous results of Basri [3]. (a) phone1 (b) swan2 (c) cup (d) face 24 7.2 Matching Results The matching algorithm has succeeded in deriving object pose by aligning only the silhouettes <ref> [12] </ref>. In [11], we have shown that (1) the algorithm can handle partially occluded objects and objects with internal edges; (2) the basin of the convergence is broad; (3) the accuracy of the derived object pose can be further improved by introducing internal object edges in the alignment process.
Reference: [13] <author> D. T. Clemens and D. W. Jacobs. </author> <title> Space and time bounds on indexing 3-D models from 2-D images. </title> <journal> IEEE Trans. on Pattern Analysis and Machine Intelligence, </journal> <volume> 13(10) </volume> <pages> 1007-1017, </pages> <year> 1991. </year> <month> 40 </month>
Reference-contexts: In addition, researchers have studied indexing schemes for quickly recovering correspondence hypotheses without resorting to comparison of all pairs of model/image feature sets <ref> [5, 8, 13, 26, 32, 33] </ref>. The problem of pose estimation from feature correspondences has also been studied independent of other stages [12, 25, 30, 35].
Reference: [14] <author> M. Dhome, M. Richetin, J.-T. Lapreste, and G. Rives. </author> <title> Determinination of the attitude of 3D objects from a single perspective view. </title> <journal> IEEE Trans. on Pattern Analysis and Machine Intelligence, </journal> <volume> 11(12) </volume> <pages> 1265-1278, </pages> <year> 1989. </year>
Reference-contexts: Most successful recognition systems developed so far have used polyhedral object models and have relied on matching special features such as corners, lines, or holes. A commonly adopted strategy is recognition-by-alignment [24] or hypothesize-and-verify <ref> [1, 14, 16, 22, 29, 36] </ref>. Minimal sets of features are used to form hypothetical correspondences between an image and a pre-stored object model.
Reference: [15] <author> O. Faugeras and M. Hebert. </author> <title> The representation, recognition, and locating of 3D objects. </title> <journal> Int. Journal of Robotics Research, </journal> <volume> 5(3) </volume> <pages> 27-52, </pages> <year> 1986. </year>
Reference-contexts: Techniques have been developed to make the search for correspondences more efficient by applying geometric constraints [18, 19] or by using local feature focus methods <ref> [6, 7, 15] </ref>. In addition, researchers have studied indexing schemes for quickly recovering correspondence hypotheses without resorting to comparison of all pairs of model/image feature sets [5, 8, 13, 26, 32, 33].
Reference: [16] <author> P. J. Flynn. </author> <title> CAD-Based Computer Vision: Modeling and Recognition Strategies. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, Michigan State University, </institution> <year> 1990. </year>
Reference-contexts: Most successful recognition systems developed so far have used polyhedral object models and have relied on matching special features such as corners, lines, or holes. A commonly adopted strategy is recognition-by-alignment [24] or hypothesize-and-verify <ref> [1, 14, 16, 22, 29, 36] </ref>. Minimal sets of features are used to form hypothetical correspondences between an image and a pre-stored object model.
Reference: [17] <author> P. J. Flynn and A. K. Jain. </author> <title> Bonsai: 3D object recognition using constrained search. </title> <journal> IEEE Trans. on Pattern Analysis and Machine Intelligence, </journal> <volume> 13(10) </volume> <pages> 1066-1075, </pages> <year> 1991. </year>
Reference-contexts: This indexing power is a decision-theoretic measure of saliency of a part for identifying a model under the Bayesian framework whereas a saliency measure based on population <ref> [17] </ref> is somewhat ad hoc.
Reference: [18] <author> W. E. L. </author> <title> Grimson. Object Recognition by Computer: The Role of Geometric Constraints. </title> <publisher> MIT Press, </publisher> <address> Cambridge MA, </address> <year> 1990. </year>
Reference-contexts: Techniques have been developed to make the search for correspondences more efficient by applying geometric constraints <ref> [18, 19] </ref> or by using local feature focus methods [6, 7, 15]. In addition, researchers have studied indexing schemes for quickly recovering correspondence hypotheses without resorting to comparison of all pairs of model/image feature sets [5, 8, 13, 26, 32, 33].
Reference: [19] <author> W. E. L. Grimson and T. Lozano-Perez. </author> <title> Localizing overlapping parts by searching the interpretation tree. </title> <journal> IEEE Trans. on Pattern Analysis and Machine Intelligence, </journal> <volume> 9(4) </volume> <pages> 469-482, </pages> <year> 1987. </year>
Reference-contexts: Techniques have been developed to make the search for correspondences more efficient by applying geometric constraints <ref> [18, 19] </ref> or by using local feature focus methods [6, 7, 15]. In addition, researchers have studied indexing schemes for quickly recovering correspondence hypotheses without resorting to comparison of all pairs of model/image feature sets [5, 8, 13, 26, 32, 33].
Reference: [20] <author> D. D. Hoffman and W. A. Richards. </author> <title> Codon constraints on closed 2d shapes. Computer Vision, </title> <journal> Graphics, and Image Processing, </journal> <volume> 31 </volume> <pages> 265-281, </pages> <year> 1985. </year>
Reference-contexts: Thus, we partition a 2D contour into parts using the Partitioning Rule: segment a curve at concave cusps (or minima of negative curvature) to break the shape into its parts. This partitioning rule leads to a representation of the shape boundary based on codons <ref> [20] </ref>. Codons are formed by partitioning curves at minima of curvature; the maxima and zeros of curvature are used to describe the shape of each segment, resulting in five types of codon. <p> Each sample of these three parameters, together with the translation parameters (t x ; t y ) and the scaling parameter s, formed the initial parameter estimates for the fitting. The translational parameters (t x ; t y ) were randomly selected within <ref> [20; 20] </ref> pixels and s within [0:9; 1:1]; 240 samples were generated for each viewing aspect. Six test objects, as shown fitted by their corresponding models in Figure 13, were used to conduct the experiments. Three of them are symmetric about some rotation axis.
Reference: [21] <author> D. D. Hoffman and W. A. Richards. </author> <title> Parts of recognition. </title> <journal> Cognition, </journal> <volume> 18 </volume> <pages> 65-96, </pages> <year> 1985. </year>
Reference-contexts: The following simple scheme worked well, although alternate or hybrid schemes might work even better. First, the partitioning rule, proposed by Hoffman and Richards <ref> [21] </ref>, is used to segment the 2D silhouette into parts. Second, part 12 invariant features are derived for indexing and the indexing is carried out via hashing. Third, parts stemming from the same model are integrated together to form groups of consistent hypotheses. <p> We have experimented with a simple partitioning rule for identifying parts from a complex object. The transversality principle, studied by Hoffman and Richards <ref> [21] </ref>, provides very general rules for segmenting either 2D or 3D objects into parts. Part boundaries are naturally delimited by the concavities. In the case of 2D plane curves or silhouettes, these concavities appear as cusps or occur at points of minima of negative curvature.
Reference: [22] <author> R. Horaud. </author> <title> New methods for matching 3D objects with single perspective views. </title> <journal> IEEE Trans. on Pattern Analysis and Machine Intelligence, </journal> <volume> 9(3) </volume> <pages> 401-412, </pages> <year> 1987. </year>
Reference-contexts: Most successful recognition systems developed so far have used polyhedral object models and have relied on matching special features such as corners, lines, or holes. A commonly adopted strategy is recognition-by-alignment [24] or hypothesize-and-verify <ref> [1, 14, 16, 22, 29, 36] </ref>. Minimal sets of features are used to form hypothetical correspondences between an image and a pre-stored object model.
Reference: [23] <author> M. K. Hu. </author> <title> Visual pattern recognition by moment invariants. </title> <journal> IEEE Trans. Information Theory, </journal> <volume> 12 </volume> <pages> 179-187, </pages> <year> 1962. </year>
Reference-contexts: The skewness, of the part, (C) is defined as (C) = cos 1 ~ p 0 p N1 ~ p m p N=2 Moment invariants: Moment invariants are well known in pattern recognition <ref> [23] </ref>. Modified moments using only the curve boundary were defined in [9]. After experimenting with the use of several normalized moments, we settled on only one of them (denoted as 1 ) the sum of the two normalized second moments [10].
Reference: [24] <author> D. P. Huttenlocher and S. Ullman. </author> <title> Object recognition using alignment. </title> <booktitle> In Proceedings 1st Int. Conf. on Computer Vision, </booktitle> <pages> pages 102-111, </pages> <address> London, </address> <year> 1987. </year>
Reference-contexts: Most successful recognition systems developed so far have used polyhedral object models and have relied on matching special features such as corners, lines, or holes. A commonly adopted strategy is recognition-by-alignment <ref> [24] </ref> or hypothesize-and-verify [1, 14, 16, 22, 29, 36]. Minimal sets of features are used to form hypothetical correspondences between an image and a pre-stored object model. <p> It is also assumed that objects are rigid. Under these assumptions, there are six unknown parameters for the image of an object under a rigid-body transformation: three for rotation, two for translation, and one 5 for scaling <ref> [24] </ref>. The recognition system has the four major components of an alignment system: (1) image processing, (2) model building, (3) indexing, and (4) determination of pose parameters by alignment. Feature Extraction: One prominent problem of vision is figure-ground separation.
Reference: [25] <author> D. J. Kriegman and J. Ponce. </author> <title> On recognizing and positioning curved 3D objects from image contours. </title> <journal> IEEE Trans. on Pattern Analysis and Machine Intelligence, </journal> <volume> 12 </volume> <pages> 1127-1137, </pages> <year> 1990. </year>
Reference-contexts: In addition, researchers have studied indexing schemes for quickly recovering correspondence hypotheses without resorting to comparison of all pairs of model/image feature sets [5, 8, 13, 26, 32, 33]. The problem of pose estimation from feature correspondences has also been studied independent of other stages <ref> [12, 25, 30, 35] </ref>. Our current work addresses remaining problems that need to be overcome in order to construct more general machine vision systems: first, we need to handle free-form objects and second we need to handle significant occlusion.
Reference: [26] <author> Y. Lamdan and H. J. Wolfson. </author> <title> Geometric hashing: A general and efficient model-based recognition scheme. </title> <booktitle> In Proceedings 2nd Int. Conf. on Computer Vision, </booktitle> <pages> pages 238-249, </pages> <year> 1988. </year>
Reference-contexts: In addition, researchers have studied indexing schemes for quickly recovering correspondence hypotheses without resorting to comparison of all pairs of model/image feature sets <ref> [5, 8, 13, 26, 32, 33] </ref>. The problem of pose estimation from feature correspondences has also been studied independent of other stages [12, 25, 30, 35].
Reference: [27] <author> C. C. Lin and R. Chellappa. </author> <title> Classification of partial 2-D shapes using fourier descriptors. </title> <journal> IEEE Trans. on Pattern Analysis and Machine Intelligence, </journal> <volume> 9(5) </volume> <pages> 686-673, </pages> <year> 1987. </year> <month> 41 </month>
Reference-contexts: The quantity & has been shown to be invariant to translation, rotation, and scaling <ref> [2, 27] </ref>. Roundness: the roundness of C, t (C), is the sum of the absolute curvatures along C, i.e., i=0 j i j where i is the curvature at point p i .
Reference: [28] <author> D. G. Lowe. </author> <title> Perceptual Organization and Visual Recognition. </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, </address> <year> 1985. </year>
Reference-contexts: We implemented the range search using a hashing scheme. 5.3 Hypothesis Grouping For indexing to be effective, it is important that some data-driven grouping mechanism produce sets of parts likely to come from a single object <ref> [28] </ref>. Multiple scene parts drawn from the same observed object should yield similar relative orientation with parts bound to the same model candidate (e.g., poses should cluster).
Reference: [29] <author> D. G. Lowe. </author> <title> Three-dimensional object recognition from single two-dimensional images. </title> <journal> Artificial Intelligence, </journal> <volume> 31(3) </volume> <pages> 355-395, </pages> <year> 1987. </year>
Reference-contexts: 1 Introduction We present results on recognition of free-form objects from a single intensity image under the alignment paradigm. Edges of models projected into 2D are matched against image edges from an observed scene in the manner proposed by David Lowe <ref> [29] </ref> and illustrated in based on alignment. 1) Free-form objects must be modeled in such a way that object contours in 2D can be efficiently generated. 2) Representative object contours must be extracted from an image. 3) Only a small number of model candidates should be hypothesized for testing. <p> Most successful recognition systems developed so far have used polyhedral object models and have relied on matching special features such as corners, lines, or holes. A commonly adopted strategy is recognition-by-alignment [24] or hypothesize-and-verify <ref> [1, 14, 16, 22, 29, 36] </ref>. Minimal sets of features are used to form hypothetical correspondences between an image and a pre-stored object model. <p> In one experiment with 60 test model aspects, alignment was achieved within 1.6 pixels mean-squared distance error within 10 iterations of the hill-climbing procedure. These results are consistent with those reported by Lowe <ref> [29] </ref>. Significant occlusion and scale change can be tolerated. The alignment results are not tied to the specific modeling scheme presented in Section 3. The matching algorithm can 38 work with a feature-based CAD model which can predict an object's edgemap when given a viewpoint.
Reference: [30] <author> D. G. Lowe. </author> <title> Fitting parameterized 3-D models to images. </title> <journal> IEEE Trans. on Pattern Analysis and Machine Intelligence, </journal> <volume> 13(5) </volume> <pages> 441-450, </pages> <year> 1991. </year>
Reference-contexts: In addition, researchers have studied indexing schemes for quickly recovering correspondence hypotheses without resorting to comparison of all pairs of model/image feature sets [5, 8, 13, 26, 32, 33]. The problem of pose estimation from feature correspondences has also been studied independent of other stages <ref> [12, 25, 30, 35] </ref>. Our current work addresses remaining problems that need to be overcome in order to construct more general machine vision systems: first, we need to handle free-form objects and second we need to handle significant occlusion. <p> Robust Matching: Our matching technique refines a pose estimate using hill-climbing to constrain the search for correspondences between model and image contours. We adopt a least-squares minimization approach | similar to the approach in <ref> [30] </ref> | to reliably estimate the object pose. This minimization technique uses heuristics to estimate pose and is relatively robust to outliers occurring due to partial occlusion [11] and imperfect image segmentation.
Reference: [31] <author> F. Mokhtarian and A. K. Mackworth. </author> <title> A theory of multi-scale, curvature-based shape representation for planar curves. </title> <journal> IEEE Trans. on Pattern Analysis and Machine Intelligence, </journal> <volume> 14 </volume> <pages> 789-805, </pages> <year> 1992. </year>
Reference-contexts: This codon representation is sensitive to noise resulting from the computation of curvature, which can cause many spurious curvature extrema. To suppress noise and keep gross shape, the curves should be smoothed when computing curvature <ref> [31] </ref>. The results of the segmentation scheme applied to the silhouettes of a 3D wood carving of a squirrel and a model car are shown in Figure 8.
Reference: [32] <author> J. T. Schwartz and M. Sharir. </author> <title> Identification of partially obscured objects in two and three dimensions by matching noisy characteristics curves. </title> <journal> Int. Journal of Robotics Research, </journal> <volume> 6(2) </volume> <pages> 29-44, </pages> <year> 1987. </year>
Reference-contexts: In addition, researchers have studied indexing schemes for quickly recovering correspondence hypotheses without resorting to comparison of all pairs of model/image feature sets <ref> [5, 8, 13, 26, 32, 33] </ref>. The problem of pose estimation from feature correspondences has also been studied independent of other stages [12, 25, 30, 35].
Reference: [33] <author> F. Stein and G. Medioni. </author> <title> Structural indexing: Efficient 2-D object recognition. </title> <journal> IEEE Trans. on Pattern Analysis and Machine Intelligence, </journal> <volume> 14(12) </volume> <pages> 1198-1204, </pages> <year> 1992. </year>
Reference-contexts: In addition, researchers have studied indexing schemes for quickly recovering correspondence hypotheses without resorting to comparison of all pairs of model/image feature sets <ref> [5, 8, 13, 26, 32, 33] </ref>. The problem of pose estimation from feature correspondences has also been studied independent of other stages [12, 25, 30, 35]. <p> We encode each part C using the quantized attributes. All encoded parts serve as indexing primitives to search a hash table for model hypotheses (similar to the hashing scheme in <ref> [33] </ref>). Invariant attributes of parts index to model aspects. The variant attributes of parts can be used to group consistent model aspect hypotheses into clusters and also to provide an approximate alignment between a sensed part and a model part.
Reference: [34] <author> G. C. Stockman. </author> <title> Object Recognition. </title> <editor> In Ramesh C. Jain and Anil K. Jain, editors, </editor> <booktitle> Analysis and Interpretation of Range Images, </booktitle> <pages> pages 225-253. </pages> <publisher> Springer-Verlag, </publisher> <year> 1990. </year>
Reference-contexts: Perhaps the most compelling support for this idea is based on recognition in the presence of occlusion. In higher level models, parts are represented to form relationships and are also related to object function <ref> [34] </ref>. Partial occlusion of the object renders global shape descriptors ineffective for indexing or recognition. Decomposition of a sensed shape into parts seems inevitable for this phase of object recognition.
Reference: [35] <author> S. Sullivan, L. Sandford, and J. Ponce. </author> <title> On using geometric distance fits to estimate 3D object shape, pose, and deformation from range, CT, and video images. </title> <booktitle> In Proceedings IEEE Conf. on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 110-115, </pages> <address> New York, </address> <month> June </month> <year> 1993. </year>
Reference-contexts: In addition, researchers have studied indexing schemes for quickly recovering correspondence hypotheses without resorting to comparison of all pairs of model/image feature sets [5, 8, 13, 26, 32, 33]. The problem of pose estimation from feature correspondences has also been studied independent of other stages <ref> [12, 25, 30, 35] </ref>. Our current work addresses remaining problems that need to be overcome in order to construct more general machine vision systems: first, we need to handle free-form objects and second we need to handle significant occlusion.
Reference: [36] <author> M. D. Wheeler and K. </author> <title> Ikeuchi. Sensor modeling, probabilistic hypothesis generation, and robust localization for object recognition. </title> <journal> IEEE Trans. on Pattern Analysis and Machine Intelligence, </journal> <volume> 17(3) </volume> <pages> 252-265, </pages> <year> 1995. </year>
Reference-contexts: Most successful recognition systems developed so far have used polyhedral object models and have relied on matching special features such as corners, lines, or holes. A commonly adopted strategy is recognition-by-alignment [24] or hypothesize-and-verify <ref> [1, 14, 16, 22, 29, 36] </ref>. Minimal sets of features are used to form hypothetical correspondences between an image and a pre-stored object model.
Reference: [37] <author> J. H. Yi and D. Chelberg. </author> <title> Rapid object recognition from a large model database. </title> <booktitle> In Proceedings IEEE 2nd CAD-Based Vision Workshop, </booktitle> <pages> pages 28-35, </pages> <address> Champion, PA, </address> <year> 1994. </year>
Reference-contexts: To achieve this goal, we adopt a decision-theoretic approach using a Bayesian framework where the measure of the discriminatory power of a part for a model is defined in terms of posterior probability (similar to the Bayesian framework in <ref> [37] </ref>). Let P (M k ) be the prior probability that model M k is observed. Let P (M k jp i ) be the posterior probability that reflects the updated belief that model M k appears in the scene after the part p i is observed.
References-found: 37

