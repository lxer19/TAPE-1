URL: http://www.cs.rutgers.edu/~davison/pubs/mltr41.ps
Refering-URL: http://www.cs.rutgers.edu/~davison/pubs/mltr41.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: fdavison,hirshg@cs.rutgers.edu  
Title: Experiments in UNIX Command Prediction  
Author: Brian D. Davison and Haym Hirsh 
Date: August 1997  
Address: New Jersey  
Affiliation: Department of Computer Science Rutgers, The State University of  
Abstract: A good user interface is central to the success of most products. Our research is concerned with improving an interface by making it adaptive | changing over time as it learns more about the user. In this paper we consider the task of modifying a UNIX shell to learn to predict the next command executed as one sample adaptive user interface. To this end, we have collected command histories (some extensive) from 77 people, and have calculated the predictive accuracy for each of five methods over this dataset. The algorithm with the highest performance produces an average online predictive accuracy of up to 38%.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Robert Armstrong, Dayne Freitag, Thorsten Joachims, and Tom Mitchell. WebWatcher: </author> <title> A learning apprentice for the world wide web. </title> <booktitle> In Proceedings of the AAAI Spring Symposium on Information Gathering from Distributed, Heterogeneous Environments, </booktitle> <month> March </month> <year> 1995. </year>
Reference-contexts: Finally, Lesh and Etzioni [9] also consider UNIX commands in plan recognition. Other examples of action prediction include interface agents that learn to provide assistance [11], the prediction of which link on a WWW page will be 2 traversed by a user <ref> [1] </ref>, the time and place for meetings for an on-line calendar system [6, 13], the values of fields in a form-filling system [7], the next thing a user will write on a pen-based computer [19, 18], and the next key a user will press on a calculator [20] or computer keyboard <p> degree of autonomy by having it begin execution of its prediction during the execution of the previous command (at least for those commands that are "nondestructive", or with a suitably designed "undo" function), much in the fashion that WebWatcher prefetches WWW pages that it predicts the user will next visit <ref> [1] </ref>.
Reference: [2] <author> Allen Cypher. Eager: </author> <title> Programming repetitive tasks by demonstration. </title> <booktitle> In Cypher [3], </booktitle> <pages> pages 204-217. </pages>
Reference-contexts: Also similar is work in programming by demonstration [3], such as Cypher's Eager <ref> [2] </ref>, which recognizes and automates simple loops in user actions in a graphical interface. Finally, Lesh and Etzioni [9] also consider UNIX commands in plan recognition.
Reference: [3] <author> Allen Cypher, </author> <title> editor. Watch What I Do: Programming by Demonstration. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1993. </year> <month> 13 </month>
Reference-contexts: One nice property of this approach is that data are collected passively, during a user's regular interactions with the shell, rather than requiring special data or training by the user as is the case, for example, with much of the work in programming by demonstration <ref> [3] </ref>. In our present research [8, 5], we focus exclusively on command prediction. This means that we do not attempt to predict command parameters, and so our methods do not completely specify a user's next action. This is discussed further at the end of the paper. <p> Motoda and Yoshida's [15, 22, 21] investigation of the use of machine learning to predict a user's next command is the most similar to the work reported here, but does not consider standard algorithms and has a small dataset. Also similar is work in programming by demonstration <ref> [3] </ref>, such as Cypher's Eager [2], which recognizes and automates simple loops in user actions in a graphical interface. Finally, Lesh and Etzioni [9] also consider UNIX commands in plan recognition.
Reference: [4] <author> J. J. Darragh, I. H. Witten, and M. L. James. </author> <title> The reactive keyboard: A predictive typing aid. </title> <journal> IEEE Computer, </journal> <volume> 23(11) </volume> <pages> 41-49, </pages> <month> November </month> <year> 1990. </year>
Reference-contexts: the time and place for meetings for an on-line calendar system [6, 13], the values of fields in a form-filling system [7], the next thing a user will write on a pen-based computer [19, 18], and the next key a user will press on a calculator [20] or computer keyboard <ref> [4, 12] </ref>. 3 Approach and Methodology 3.1 Who the test subjects were We captured command histories from a total of 77 people at Rutgers University.
Reference: [5] <author> Brian D. Davison and Haym Hirsh. </author> <title> Toward an adaptive command line interface. </title> <booktitle> In Proceedings of the Seventh International Conference on Human-Computer Interaction, </booktitle> <address> San Francisco, CA, August 1997. </address> <publisher> Elsevier Science Publishers. </publisher>
Reference-contexts: In our present research <ref> [8, 5] </ref>, we focus exclusively on command prediction. This means that we do not attempt to predict command parameters, and so our methods do not completely specify a user's next action. This is discussed further at the end of the paper.
Reference: [6] <author> Lisa Dent, J. Boticario, John McDermott, Tom Mitchell, and David Zabowski. </author> <title> A personal learning apprentice. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pages 96-103, </pages> <address> Menlo Park, CA, July 1992. </address> <publisher> AAAI Press. </publisher>
Reference-contexts: Other examples of action prediction include interface agents that learn to provide assistance [11], the prediction of which link on a WWW page will be 2 traversed by a user [1], the time and place for meetings for an on-line calendar system <ref> [6, 13] </ref>, the values of fields in a form-filling system [7], the next thing a user will write on a pen-based computer [19, 18], and the next key a user will press on a calculator [20] or computer keyboard [4, 12]. 3 Approach and Methodology 3.1 Who the test subjects were
Reference: [7] <author> Leonard A. Hermens and Jeffrey C. Schlimmer. </author> <title> A machine-learning apprentice for the completion of repetitive forms. </title> <booktitle> In Proceedings of the Ninth IEEE Conference on Artificial Intelligence Applications, </booktitle> <address> Los Alamitos, CA, March 1993. </address> <publisher> IEEE Computer Society Press. </publisher>
Reference-contexts: of action prediction include interface agents that learn to provide assistance [11], the prediction of which link on a WWW page will be 2 traversed by a user [1], the time and place for meetings for an on-line calendar system [6, 13], the values of fields in a form-filling system <ref> [7] </ref>, the next thing a user will write on a pen-based computer [19, 18], and the next key a user will press on a calculator [20] or computer keyboard [4, 12]. 3 Approach and Methodology 3.1 Who the test subjects were We captured command histories from a total of 77 people
Reference: [8] <author> Haym Hirsh and Brian D. Davison. </author> <title> An adaptive UNIX command-line assistant. </title> <booktitle> In Proceedings of the First International Conference on Autonomous Agents. </booktitle> <publisher> ACM Press, </publisher> <year> 1997. </year>
Reference-contexts: In our present research <ref> [8, 5] </ref>, we focus exclusively on command prediction. This means that we do not attempt to predict command parameters, and so our methods do not completely specify a user's next action. This is discussed further at the end of the paper. <p> Learning is performed by the decision-tree learner C4.5. It is described further in <ref> [8] </ref>. While this initial version of ilash incorporates a strong learner, it does make other tradeoffs. Decision trees are not created or updated online | a new decision tree must be built explicitly by the user, commonly just once a day.
Reference: [9] <author> Neal Lesh and Oren Etzioni. </author> <title> A sound and fast goal recognizer. </title> <booktitle> In Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence. </booktitle> <publisher> Morgan Kaufmann, </publisher> <year> 1995. </year>
Reference-contexts: Also similar is work in programming by demonstration [3], such as Cypher's Eager [2], which recognizes and automates simple loops in user actions in a graphical interface. Finally, Lesh and Etzioni <ref> [9] </ref> also consider UNIX commands in plan recognition.
Reference: [10] <author> Nicholas Littlestone and Manfred K. Warmuth. </author> <title> The weighted majority algorithm. </title> <journal> Information and Computation, </journal> <volume> 108 </volume> <pages> 212-261, </pages> <year> 1994. </year>
Reference-contexts: More sophisticated still would be to do a weighted vote of multiple matches from each of a number of distance metrics, with the weights of each match learned using recently developed "weighted-majority" learning algorithms <ref> [10] </ref>. Automatic adaptation in any user interface is a welcome improvement. This paper has demonstrated that adaptation is feasible for command line interfaces; there are likewise other aspects of most user interfaces that can take advantage of the regularities present in most human interactions.
Reference: [11] <editor> Pattie Maes and Robyn Kozierok. </editor> <booktitle> Learning interface agents. In Proceedings of the Eleventh National Conference on Artificial Intelligence, </booktitle> <pages> pages 459-465, </pages> <address> Menlo Park, CA, 1993. </address> <publisher> AAAI Press. </publisher>
Reference-contexts: Finally, Lesh and Etzioni [9] also consider UNIX commands in plan recognition. Other examples of action prediction include interface agents that learn to provide assistance <ref> [11] </ref>, the prediction of which link on a WWW page will be 2 traversed by a user [1], the time and place for meetings for an on-line calendar system [6, 13], the values of fields in a form-filling system [7], the next thing a user will write on a pen-based computer
Reference: [12] <author> T. Masui and K. Nakayama. </author> <title> Repeat and predict | two keys to efficient text editing. </title> <booktitle> In Proceedings of the Conference on Human Factors in Computing Systems, </booktitle> <pages> pages 118-123, </pages> <address> New York, April 1994. </address> <publisher> ACM Press. </publisher>
Reference-contexts: the time and place for meetings for an on-line calendar system [6, 13], the values of fields in a form-filling system [7], the next thing a user will write on a pen-based computer [19, 18], and the next key a user will press on a calculator [20] or computer keyboard <ref> [4, 12] </ref>. 3 Approach and Methodology 3.1 Who the test subjects were We captured command histories from a total of 77 people at Rutgers University.
Reference: [13] <author> Tom Mitchell, Rich Caruana, Dayne Freitag, John McDermott, and David Zabowski. </author> <title> Experience with a learning personal assistant. </title> <journal> Communications of the ACM, </journal> <volume> 37(7) </volume> <pages> 81-91, </pages> <month> July </month> <year> 1994. </year>
Reference-contexts: Other examples of action prediction include interface agents that learn to provide assistance [11], the prediction of which link on a WWW page will be 2 traversed by a user [1], the time and place for meetings for an on-line calendar system <ref> [6, 13] </ref>, the values of fields in a form-filling system [7], the next thing a user will write on a pen-based computer [19, 18], and the next key a user will press on a calculator [20] or computer keyboard [4, 12]. 3 Approach and Methodology 3.1 Who the test subjects were
Reference: [14] <author> Tom Michael Mitchell, Sridhar Mahadevan, and Louis I. Steinberg. </author> <title> LEAP: A learning apprentice for VLSI design. </title> <booktitle> In Proceedings of the Ninth International Joint Conference on Artificial Intelligence, </booktitle> <address> Los Angeles, CA, </address> <month> August </month> <year> 1985. </year>
Reference-contexts: The prediction of a user's next command by the shell requires some mechanism to consider the user's current session and from that generate a prediction 1 for the next command. We have used a "learning apprentice" approach <ref> [14] </ref> to gather data by recording the sequence of commands executed as well as any pertinent information about the state of the shell.
Reference: [15] <author> Hiroshi Motoda and Kenichi Yoshida. </author> <title> Machine learning techniques to make computers easier to use. </title> <booktitle> In Proceedings of the Fifteenth International Joint Conference on Artificial Intelligence, </booktitle> <month> August </month> <year> 1997. </year>
Reference-contexts: Motoda and Yoshida's <ref> [15, 22, 21] </ref> investigation of the use of machine learning to predict a user's next command is the most similar to the work reported here, but does not consider standard algorithms and has a small dataset. <p> As a result, it does not lend itself to the random partitioning or sampling necessary for traditional cross-validation performance evaluation. While we could forego cross-validation and just split a user's data, e.g. the first two thirds for training, and the last third for evaluation (as <ref> [15, 22] </ref> does), we would lose two-thirds of our data points, and likely perform substantially worse on the last third. 1 Intuitively, this also makes sense; the patterns of use over the past day or even the past hour are often useful in predicting the next command.
Reference: [16] <author> J. Ross Quinlan. </author> <title> Learning logical definitions from relations. </title> <journal> Machine Learning, </journal> <volume> 5(3) </volume> <pages> 239-266, </pages> <year> 1990. </year>
Reference-contexts: For example, it would be nice to have a shell that predicted "dvips foo" if the previous command was "latex foo". We are hopeful that recent learning methods developed in the area of inductive logic programming (e.g., <ref> [16] </ref>) may prove successful in making such predictions.
Reference: [17] <author> J. Ross Quinlan. C4.5: </author> <title> Programs for Machine Learning. </title> <publisher> Morgan Kauf-mann, </publisher> <address> San Mateo, CA, </address> <year> 1993. </year>
Reference-contexts: We chose to run multiple methods both for comparison and verification of performance. The first is a fairly complex algorithm; the others are simplistic baselines or methods constructed specifically for this problem. 4 * The first was C4.5 <ref> [17] </ref>, and was selected as a common, well-studied decision-tree learner with excellent performance over a variety of prob lems. * An Omniscient predictor was devised that would correctly predict every command, providing that the desired command was present in the current training set.
Reference: [18] <author> Jeffrey C. Schlimmer and Leonard A. Hermens. </author> <title> Software agents: Completing patterns and constructing user interfaces. </title> <journal> Journal of Artificial Intelligence Research, </journal> <volume> 1 </volume> <pages> 61-89, </pages> <year> 1993. </year>
Reference-contexts: the prediction of which link on a WWW page will be 2 traversed by a user [1], the time and place for meetings for an on-line calendar system [6, 13], the values of fields in a form-filling system [7], the next thing a user will write on a pen-based computer <ref> [19, 18] </ref>, and the next key a user will press on a calculator [20] or computer keyboard [4, 12]. 3 Approach and Methodology 3.1 Who the test subjects were We captured command histories from a total of 77 people at Rutgers University.
Reference: [19] <author> Jeffrey C. Schlimmer and Patricia Crane Wells. </author> <title> Quantitative results comparing three intelligent interfaces for information capture: A case study adding name information into an electronic personal organizer. </title> <journal> Journal of Artificial Intelligence Research, </journal> <volume> 5 </volume> <pages> 329-349, </pages> <year> 1996. </year>
Reference-contexts: the prediction of which link on a WWW page will be 2 traversed by a user [1], the time and place for meetings for an on-line calendar system [6, 13], the values of fields in a form-filling system [7], the next thing a user will write on a pen-based computer <ref> [19, 18] </ref>, and the next key a user will press on a calculator [20] or computer keyboard [4, 12]. 3 Approach and Methodology 3.1 Who the test subjects were We captured command histories from a total of 77 people at Rutgers University.
Reference: [20] <author> Ian H. Witten. </author> <title> A predictive calculator. </title> <booktitle> In Cypher [3], </booktitle> <pages> pages 66-76. </pages>
Reference-contexts: by a user [1], the time and place for meetings for an on-line calendar system [6, 13], the values of fields in a form-filling system [7], the next thing a user will write on a pen-based computer [19, 18], and the next key a user will press on a calculator <ref> [20] </ref> or computer keyboard [4, 12]. 3 Approach and Methodology 3.1 Who the test subjects were We captured command histories from a total of 77 people at Rutgers University.
Reference: [21] <author> Kenichi Yoshida. </author> <title> User command prediction by graph-based induction. </title> <booktitle> In Proceedings of the Sixth International Conference on Tools with Artificial Intelligence, </booktitle> <pages> pages 732-735, </pages> <address> Los Alamitos, CA, November 1994. </address> <publisher> IEEE Computer Society Press. </publisher>
Reference-contexts: Motoda and Yoshida's <ref> [15, 22, 21] </ref> investigation of the use of machine learning to predict a user's next command is the most similar to the work reported here, but does not consider standard algorithms and has a small dataset.
Reference: [22] <author> Kenichi Yoshida and Hiroshi Motoda. </author> <title> Automated user modeling for intelligent interface. </title> <journal> International Journal of Human-Computer Interaction, </journal> <volume> 8(3) </volume> <pages> 237-258, </pages> <year> 1996. </year>
Reference-contexts: Motoda and Yoshida's <ref> [15, 22, 21] </ref> investigation of the use of machine learning to predict a user's next command is the most similar to the work reported here, but does not consider standard algorithms and has a small dataset. <p> As a result, it does not lend itself to the random partitioning or sampling necessary for traditional cross-validation performance evaluation. While we could forego cross-validation and just split a user's data, e.g. the first two thirds for training, and the last third for evaluation (as <ref> [15, 22] </ref> does), we would lose two-thirds of our data points, and likely perform substantially worse on the last third. 1 Intuitively, this also makes sense; the patterns of use over the past day or even the past hour are often useful in predicting the next command.
References-found: 22

