URL: http://www.cs.purdue.edu/homes/edm/papers/aria2.ps.Z
Refering-URL: http://www.cs.purdue.edu/people/edm/
Root-URL: http://www.cs.purdue.edu
Title: Migrant Threads on Process Farms: Parallel Programming with Ariadne  
Author: Edward Mascarenhas Vernon Rego 
Note: Research supported in part by NATO-CRG900108, ONR-9310233, and ARO-93G0045.  
Address: West Lafayette, IN 47907  
Affiliation: Department of Computer Sciences Purdue University  
Abstract: We present a novel and portable threads-based system for the development of concurrent applications on shared and distributed memory environments. Implementing user-space threads, the Ariadne system is highly effective for medium to coarse grained applications. Sequential programs are readily converted into parallel programs for shared or distributed memory, with low development effort. We describe basic threads primitives, and constructs for synchronization and computation in concurrent applications. Ariadne flexibly caters to a variety of communication environments, through a simple interface. It supports the development of customized schedulers on shared memory multiprocessors, and offers a thread migration capability for distributed environments. Scheduling of computations at the thread level offers both task- and data-driven executions. Thread migration is a powerful feature which turns remote memory accesses into local accesses, enables load-balancing and simplifies program development. Ariadne currently runs on the SPARC (SunOS 4.x, SunOS 5.x), Sequent Symmetry, Intel Paragon, Silicon Graphics IRIX, and IBM RS/6000 environments. We present Ariadne's parallel programming capability through several examples, reporting on performance measurements obtained with each. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Aho, J. Hopcroft, and J. Ullman. </author> <title> The Design and Analysis of Computer Algorithms. </title> <publisher> Addison-Wesley, </publisher> <year> 1974. </year>
Reference-contexts: **argv, int nprocs) - int mytid; int done = FALSE; numprocs = nprocs; mytid = pvm_mytid (); /* pvm routine to get task id */ tids [0] = pvm_parent (); if (tids [0] &lt; 0) - /* the controller */ tids [0] = mytid; procid = 0; pvm_spawn ("progname", &argv <ref> [1] </ref>, 0, "", nprocs-1, &tids [1]); pvm_initsend, pvm_pkint; /* init and pack the tid array */ pvm_mcast (&tids [1], nprocs-1, 0); /* send to others */ set up data structures for termination since I am controller; while (!done) - recv FINISH messages from other processes; done = FALSE; if (all processes <p> mytid; int done = FALSE; numprocs = nprocs; mytid = pvm_mytid (); /* pvm routine to get task id */ tids [0] = pvm_parent (); if (tids [0] &lt; 0) - /* the controller */ tids [0] = mytid; procid = 0; pvm_spawn ("progname", &argv <ref> [1] </ref>, 0, "", nprocs-1, &tids [1]); pvm_initsend, pvm_pkint; /* init and pack the tid array */ pvm_mcast (&tids [1], nprocs-1, 0); /* send to others */ set up data structures for termination since I am controller; while (!done) - recv FINISH messages from other processes; done = FALSE; if (all processes have finished) done = TRUE; <p> pvm routine to get task id */ tids [0] = pvm_parent (); if (tids [0] &lt; 0) - /* the controller */ tids [0] = mytid; procid = 0; pvm_spawn ("progname", &argv <ref> [1] </ref>, 0, "", nprocs-1, &tids [1]); pvm_initsend, pvm_pkint; /* init and pack the tid array */ pvm_mcast (&tids [1], nprocs-1, 0); /* send to others */ set up data structures for termination since I am controller; while (!done) - recv FINISH messages from other processes; done = FALSE; if (all processes have finished) done = TRUE; - send EXIT message to all processes; pvm_exit (); - else - pvm_recv <p> In the adaptive quadrature example, threads run to completion upon obtaining control. Before relinquishing control on termination, each thread may create two new threads. Hence the context-switch count is in the order of the number of threads. 6.2 Quicksort The well-known quicksort algorithm <ref> [1] </ref> operates recursively, to sort a list S of n integers. A partition () procedure uses a pivot to split S and each recursively obtained subarray into three pieces. <p> The algorithm locates the j-th smallest array element through a scan which splits an N element array A in such as way that A [0]; A <ref> [1] </ref>; :::; A [j 2] A [j 1] A [j]; :::A [N 1]. FIND can be used to located the median and halve an array.
Reference: [2] <author> T. E. Anderson, B. N. Bershad, E. D. Lazowska, and H. M. Levy. </author> <title> Scheduler activations: Effective kernel support for the user-level management of parallelism. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 10(1) </volume> <pages> 53-79, </pages> <month> February </month> <year> 1992. </year> <month> 40 </month>
Reference-contexts: In contrast, user threads are both cheap and highly efficient. Finally, because not every OS provides kernel threads, applications based on kernel-space threads are not portable. Scheduler Activations <ref> [2] </ref> and Psyche [21] are examples of systems that attempt to combine the advantages of both user-space and kernel-space threads, through use of up-calls and software interrupts. Ariadne keeps thread information inside a thread shell. <p> Examples 2 and limitations of user-space implementations can be found in [25]. As evidenced by the growing number of operating systems promoting kernel-space threads (e.g., Solaris, Mach), efficient coupling of cheap user-space threads with kernel-level support can enhance development of concurrent applications <ref> [21, 2] </ref>. Because kernel-space thread implementations are OS specific, and tied to particular hardware, application portability is a serious concern. A possible solution is the use of the POSIX standard as a threads programming interface.
Reference: [3] <author> T. E. Anderson, E. D. Lazowska, and H. M. Levy. </author> <title> The performance implications of thread management alternatives for shared-memory multiprocessors. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 38(12) </volume> <pages> 1631-1644, </pages> <month> December </month> <year> 1989. </year>
Reference-contexts: In IVY, a network-wide virtual address space, shared among loosely coupled processors, permits computations to access remote objects. The shared virtual 2 For examples of threads systems see FastThreads <ref> [3] </ref>, C Threads [39], Solaris Threads [31], Filaments [13], System [6], Pthreads [27]. 38 memory allows threads and objects to migrate easily, since all processors have access to the same virtual address space. But in IVY, this requires maintaining coherence of copies of data resident on distinct processors.
Reference: [4] <author> B. N. Bershad, E. D. Lazowska, and H. M. Levy. </author> <title> Presto: A system for object-oriented parallel programming. </title> <journal> Software-Practice and Experience, </journal> <volume> 18(8) </volume> <pages> 713-732, </pages> <month> August </month> <year> 1988. </year>
Reference-contexts: It is left to be seen, however, whether particular implementations of the standard can circumvent operational and performance problems. Threads have been proposed as basic units for enabling concurrency in many systems. For example, on shared memory multiprocessors, Ariadne multiplexes user threads on top of multiple processes. The PRESTO <ref> [4] </ref> system and System [6] also use processes in this manner, though the implementations are less general and do not support distributed memory architectures. Examples of other systems providing threads or threads-like interfaces with distributed memory support include IVY [20], Amber [9], Clouds [11], and distributed Filaments [15].
Reference: [5] <author> A. D. Birrell and B. J. Nelson. </author> <title> Implementing remote procedure calls. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 2(1) </volume> <pages> 39-59, </pages> <month> February </month> <year> 1984. </year>
Reference-contexts: Thread migration overheads in Ariadne are small, compared to the total time required for migration. The time required to migrate a thread is only 1-3% larger than the time required to move a message of the same size. Details on thread migrations can be found in [25]. Each RPC-style <ref> [5, 9, 11] </ref> access requires two messages, a send and a receive. The former delivers parameters to a procedure, and the latter returns results. In the traditional process-oriented model the sender typically blocks on the send. With threads, the sending process is free to continue with other work.
Reference: [6] <author> P. A. Buhr and R. A. Stroobosscher. </author> <title> The System: Providing light-weight concurrency on shared-memory multiprocessor computers running unix. </title> <journal> Software-Practice and Experience, </journal> <volume> 20(9) </volume> <pages> 929-964, </pages> <month> September </month> <year> 1990. </year>
Reference-contexts: Threads have been proposed as basic units for enabling concurrency in many systems. For example, on shared memory multiprocessors, Ariadne multiplexes user threads on top of multiple processes. The PRESTO [4] system and System <ref> [6] </ref> also use processes in this manner, though the implementations are less general and do not support distributed memory architectures. Examples of other systems providing threads or threads-like interfaces with distributed memory support include IVY [20], Amber [9], Clouds [11], and distributed Filaments [15]. <p> In IVY, a network-wide virtual address space, shared among loosely coupled processors, permits computations to access remote objects. The shared virtual 2 For examples of threads systems see FastThreads [3], C Threads [39], Solaris Threads [31], Filaments [13], System <ref> [6] </ref>, Pthreads [27]. 38 memory allows threads and objects to migrate easily, since all processors have access to the same virtual address space. But in IVY, this requires maintaining coherence of copies of data resident on distinct processors. Such maintenance overheads and contention for multiple access to data degrades performance.
Reference: [7] <author> R. Butler and E. Lusk. </author> <title> User's Guide to the P4 programming System. </title> <type> Technical Report ANL-92/17, </type> <institution> Argonne National Laboratory, </institution> <year> 1992. </year>
Reference-contexts: Future environments will consist of a heterogeneous mix: multiprocessor desktops, specialized workstations and fast, multiprocessor servers. These will communicate over high-speed networks such as the 100-Mbps Ethernet, FDDI or ATM. Concurrency supporting environments [42] such as PVM [37] and P4/Parmacs <ref> [7] </ref> must also evolve, to exploit newer technologies and provide novel services. Though concurrent computing on loosely coupled machines has repeatedly proven to be both low-cost and effective [29, 37], metrics of performance and parallelization effort exhibit both a need and scope for improvement.
Reference: [8] <author> M. Carlisle and A. Rogers. </author> <title> Software caching and computation migration in olden. </title> <booktitle> In Proceedings of the Fifth ACM Symposium on Principles and Practice of Parallel Programming, </booktitle> <year> 1995. </year>
Reference-contexts: Complex object migration is nontrivial, given that internal objects and/or pointers to other objects require packing and unpacking at source and destination processes, respectively. Another alternative to the two schemes mentioned above is computation migration <ref> [18, 8] </ref>. Here, part of a computation (e.g., the topmost function in a sequence of nested calls) is moved to a process hosting required data. <p> Thus each migration requires a return. Computation migration is useful when thread stacks are large, enabling low migration costs because only necessary stack is migrated. A similar method is used for computation migration in Olden <ref> [8] </ref>. Here, the idea is to exploit compiler-based techniques to parallelize recursive C programs. During compilation, a remote access is resolved either by computation migration or page-level software caching.
Reference: [9] <author> J. S. Chase, F. G. Amador, E. D. Lazowska, H. M. Levy, and R. J. Littlefield. </author> <title> The Amber System: Parallel programming on a network of multiprocessors. </title> <booktitle> In Symposium on Operating System Principles, </booktitle> <pages> pages 147-158, </pages> <year> 1989. </year>
Reference-contexts: Thread migration overheads in Ariadne are small, compared to the total time required for migration. The time required to migrate a thread is only 1-3% larger than the time required to move a message of the same size. Details on thread migrations can be found in [25]. Each RPC-style <ref> [5, 9, 11] </ref> access requires two messages, a send and a receive. The former delivers parameters to a procedure, and the latter returns results. In the traditional process-oriented model the sender typically blocks on the send. With threads, the sending process is free to continue with other work. <p> The PRESTO [4] system and System [6] also use processes in this manner, though the implementations are less general and do not support distributed memory architectures. Examples of other systems providing threads or threads-like interfaces with distributed memory support include IVY [20], Amber <ref> [9] </ref>, Clouds [11], and distributed Filaments [15]. In IVY, a network-wide virtual address space, shared among loosely coupled processors, permits computations to access remote objects.
Reference: [10] <author> D. Clark and D. Tennenhouse. </author> <title> Architectural considerations for a new generation of protocols. </title> <booktitle> In SIGCOMM, </booktitle> <year> 1990. </year>
Reference-contexts: For example, employing the generic functionality of an OS for a message-passing processor task-based computation, as done in PVM and P4, poses problems of efficiency. Kernel-based process scheduling for layer invocation, combined with client insensitivity to critical timing in protocol functions, can effect significant though avoidable overheads <ref> [10, 43] </ref>. Typical distributed applications, such as those supported by PVM and P4, are typically limited to processor subroutine-based computation. Proposals for their redesign/extension, to include threads support, have begun to appear [14]. <p> For our experiments, g 1 (x) = x fl x + 1:0, g 2 (x) = sin (x), with x 2 <ref> [10; 10] </ref>, and ffi = 10 7 . All runs were made on a 4-processor SPARCstation 20. Measured execution time and speedup are shown in Figure 12. Measured time excludes initial-izations, and speedup is measured relative to sequential (single-threaded) execution.
Reference: [11] <author> P. Dasgupta, R. Ananthanarayanan, S. Menon, A. Mohindra, and R. Chen. </author> <title> Distributed programming with Objects and Threads in the Clouds System. </title> <type> Technical Report GIT-GC 91/26, </type> <institution> Georgia Institute of Technology, </institution> <year> 1991. </year>
Reference-contexts: Thread migration overheads in Ariadne are small, compared to the total time required for migration. The time required to migrate a thread is only 1-3% larger than the time required to move a message of the same size. Details on thread migrations can be found in [25]. Each RPC-style <ref> [5, 9, 11] </ref> access requires two messages, a send and a receive. The former delivers parameters to a procedure, and the latter returns results. In the traditional process-oriented model the sender typically blocks on the send. With threads, the sending process is free to continue with other work. <p> In the traditional process-oriented model the sender typically blocks on the send. With threads, the sending process is free to continue with other work. Data-shipping is a form of remote memory copy: remote data is moved to a computation or simply moved from one process to another <ref> [20, 11] </ref>. Shipping data to a computation requires copy coherency, an expensive proposition when changes are frequent. Moving data between processes to improve locality is beneficial when remote accesses are frequent, but is expensive for large data blocks or memory pages. <p> The PRESTO [4] system and System [6] also use processes in this manner, though the implementations are less general and do not support distributed memory architectures. Examples of other systems providing threads or threads-like interfaces with distributed memory support include IVY [20], Amber [9], Clouds <ref> [11] </ref>, and distributed Filaments [15]. In IVY, a network-wide virtual address space, shared among loosely coupled processors, permits computations to access remote objects.
Reference: [12] <author> D. L. Eager and J. Zahorjan. Chores: </author> <title> Enhanced run-time support for shared-memory parallel computing. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 11(1) </volume> <pages> 1-32, </pages> <month> February </month> <year> 1993. </year>
Reference-contexts: This helps prevent stack overflow and increases computation granularity. A related technique for increasing the granularity of fine-grained applications is found in Lazy Task Creation [26]. It is also possible to enhance stateful threads with support for low-cost fine-grained operations as in the Chores system <ref> [12] </ref>. An interesting feature of programming with Ariadne, as demonstrated above, is the relative ease with which one can move from sequential code to parallel code. This occurs because sequential and parallel versions of code do not differ much.
Reference: [13] <author> D. R. Engler, G. R. Andrews, and D. K. Lowenthal. Filaments: </author> <title> Efficient support for fine-grain parallelism. </title> <type> Technical Report TR 93-13a, </type> <institution> Department of Computer Science, The University of Arizona, </institution> <year> 1993. </year>
Reference-contexts: In IVY, a network-wide virtual address space, shared among loosely coupled processors, permits computations to access remote objects. The shared virtual 2 For examples of threads systems see FastThreads [3], C Threads [39], Solaris Threads [31], Filaments <ref> [13] </ref>, System [6], Pthreads [27]. 38 memory allows threads and objects to migrate easily, since all processors have access to the same virtual address space. But in IVY, this requires maintaining coherence of copies of data resident on distinct processors.
Reference: [14] <author> A. Ferrari and V. Sunderam. TPVM: </author> <title> Distributed concurrent computing with lightweight processes. </title> <booktitle> In Proceedings of the 4-th High Performance Distributed Computing Symposium, </booktitle> <address> Washington, D.C., </address> <pages> pages 211-218, </pages> <month> August </month> <year> 1985. </year>
Reference-contexts: Typical distributed applications, such as those supported by PVM and P4, are typically limited to processor subroutine-based computation. Proposals for their redesign/extension, to include threads support, have begun to appear <ref> [14] </ref>. While processes provide flexibility, their management and scheduling overheads tend to dominate potential gains, and application-specific distributed management is cumbersome. For simplicity, distributed applications often consist of communicating processes which compute using a subroutine structure.
Reference: [15] <author> V. W. Freeh, D. K. Lowenthal, and G. R. Andrews. </author> <title> Distributed filaments: Efficient fine-grain parallelism on a cluster of workstations. </title> <type> Technical Report TR 94-11a, </type> <institution> Department of Computer Science, The University of Arizona, </institution> <year> 1994. </year> <month> 41 </month>
Reference-contexts: In each case, an object's data may be large and sufficiently complicated by internal transient active objects to discourage frequent data migration. On the other hand, threads are generally small <ref> [15] </ref>, and thread migration is cheaper than data migration when locality of data access is an issue, or when thread state is small compared with data state [18]. <p> The PRESTO [4] system and System [6] also use processes in this manner, though the implementations are less general and do not support distributed memory architectures. Examples of other systems providing threads or threads-like interfaces with distributed memory support include IVY [20], Amber [9], Clouds [11], and distributed Filaments <ref> [15] </ref>. In IVY, a network-wide virtual address space, shared among loosely coupled processors, permits computations to access remote objects.
Reference: [16] <author> J. C. Gomez, V. Rego, and V. Sunderam. </author> <title> Tailoring Receive Threads to Suit Network Loads: Tech--niques and Experiments. </title> <type> Technical report, </type> <institution> Department of Computer Sciences, Purdue University, </institution> <month> December </month> <year> 1995. </year>
Reference-contexts: We found threads functionality highly useful in supporting multiple domains simultaneously. By encapsulating difficult domain functionality, users are relieved of the burden of recreating domain code. Experiments describing efficiency gains with such layering in protocol design can be found in <ref> [16] </ref>. Threads enable a direct and natural expression of concurrency in many applications. In particle-physics, for example, a thread models a molecule; in personal communication systems, a thread may represent a mobile phone; in queuing or teletraffic simulations, a thread may represent a request. <p> Support-layer software is an intrinsic part of the threads library, while the customization modules are meant to flexibly cater to application needs. The layered design enables the system to interface well with application-level software. The ParaSol system [22] is one example of this, and the Clam active-messaging system <ref> [16] </ref> is another. Consider, for example, threads support in ParaSol. Custom modules in ParaSol are mapped into Ariadne's kernel and support layers, as shown in Figure 1. The global object locator is an Object Manager that maps unique object identifiers onto logical process identifiers. <p> Issues of remote data access and synchronization are effectively addressed by thread migration and message passing. Migration and data redistribution also help in achieving reduced load-imbalance. Ariadne is highly effective with remote memory operations, active-messaging 8 and lightweight protocol design <ref> [16] </ref>. 3 Ariadne Threads on Shared Memory Since Ariadne does not require kernel-level support from an OS, true concurrency is achieved by multiplexing user-space threads on multiple processes. An alternative, currently being pursued, is to multiplex Ariadne threads on available kernel-space threads. <p> In the study of network design or mobile computing systems, threads may represent packets or dynamic computing units. Besides computational or modeling applications, distributed threads are valuable in support-level settings such as enhanced windowing, active-messaging and protocol design <ref> [16] </ref>. In general, distributed threads perform well when computation granularity is coarse. <p> In the ParaSol parallel process-oriented simulation environment [22], threads implement simulation processes and operate in conjunction with optimistic and adaptive simulation protocols. In the investigation of efficient user-space implementations of network protocols, threads offer support for dynamic adaptations to network loads and active messaging <ref> [16] </ref>.
Reference: [17] <author> C. A. R. Hoare. </author> <title> Proof of a program: Find. </title> <journal> Communications of the ACM, </journal> <volume> 14(1) </volume> <pages> 39-45, </pages> <month> January </month> <year> 1971. </year>
Reference-contexts: The uniprocessor, shared memory version of Ariadne takes about 12-15% longer than a sequential program, giving a rough indication of threads system overheads. 6.2.1 Quicksort with FIND In early work, Hoare <ref> [17] </ref> proposes a FIND algorithm for locating the order-statistics of an array.
Reference: [18] <author> W. C. Hsieh, P. Wang, and W. E. Weihl. </author> <title> Computation Migration: Enhancing Locality for Distributed-Memory Parallel Systems. </title> <booktitle> Proceedings of the Symposium on Principles and Practice of Parallel Programming, </booktitle> <pages> pages 239-248, </pages> <year> 1993. </year>
Reference-contexts: On the other hand, threads are generally small [15], and thread migration is cheaper than data migration when locality of data access is an issue, or when thread state is small compared with data state <ref> [18] </ref>. In our experience with parallel simulation applications, the cost of moving threads between processors is roughly the same as the cost of messaging the same event-related information [33]. The Ariadne system supports threads-based programming on shared- and distributed-memory environments. <p> Complex object migration is nontrivial, given that internal objects and/or pointers to other objects require packing and unpacking at source and destination processes, respectively. Another alternative to the two schemes mentioned above is computation migration <ref> [18, 8] </ref>. Here, part of a computation (e.g., the topmost function in a sequence of nested calls) is moved to a process hosting required data. <p> Another alternative to the two schemes mentioned above is computation migration [18, 8]. Here, part of a computation (e.g., the topmost function in a sequence of nested calls) is moved to a process hosting required data. Using compile-time transforms, the scheme described in <ref> [18] </ref> effects this by 16 transferring single activation frames between hosts; the function is forced to return to the sender, entailing a two-way transfer. <p> Because a migrant need never return to its sender, transfers are one-way instead of two-way; intermediate results are generally stored in an object within the thread. Thread migration is known to require the least number of messages for a typical series of remote access requests <ref> [18] </ref>. With potentially low consumption of network bandwidth, relative to other access schemes, thread migration offers good potential for improved performance. Choice of an appropriate access scheme depends, however, on the needs of the application and on the underlying environment. <p> Proposals for its application include load sharing, resource sharing, communication overhead reduction and failure robustness, among others [34, 35]. Dynamic migration is usually addressed in the context of distributed operating systems, for example V [40] and DEMOS/MP [32]. Another form of thread migration, called computation migration <ref> [18] </ref>, has been proposed as part of the Prelude language. This technique exploits compile-time transformations to migrate only the topmost frame of a stack. This frame may move from one node to another, repeatedly accessing objects, but must finally return to its source. Thus each migration requires a return.
Reference: [19] <author> J. M. Lemme and J. H. Rice. </author> <title> Adaptive quadrature algorithms for the ILLIAC IV. </title> <journal> International Journal of Computer and Information Sciences, </journal> <volume> 9(1) </volume> <pages> 63-72, </pages> <month> February </month> <year> 1980. </year>
Reference-contexts: Level 150 fi fi fi Recursion Maximum 4 4 4 0:5 1:5 2:5 3:5 Processors Speedup No recursion 3 3 3 Recursion Level 50 + + + Recursion Level 150 2 2 2 Recursion Maximum fi fi fi Performance We tested the adaptive threads-based quadrature on an integrand proposed in <ref> [19] </ref> to be a worthwhile test. The function f (x) = sign (g 1 (x); g 2 (x)) is defined as jg 1 (x)j if g 2 (x) 0, and as g 1 (x) if g 2 (x) &lt; 0.
Reference: [20] <author> K. Li. IVY: </author> <title> A shared virtual memory system for parallel computing. </title> <booktitle> In Proceedings of the International Conference on Parallel Processing, </booktitle> <pages> pages 94-101, </pages> <year> 1988. </year>
Reference-contexts: In the traditional process-oriented model the sender typically blocks on the send. With threads, the sending process is free to continue with other work. Data-shipping is a form of remote memory copy: remote data is moved to a computation or simply moved from one process to another <ref> [20, 11] </ref>. Shipping data to a computation requires copy coherency, an expensive proposition when changes are frequent. Moving data between processes to improve locality is beneficial when remote accesses are frequent, but is expensive for large data blocks or memory pages. <p> The PRESTO [4] system and System [6] also use processes in this manner, though the implementations are less general and do not support distributed memory architectures. Examples of other systems providing threads or threads-like interfaces with distributed memory support include IVY <ref> [20] </ref>, Amber [9], Clouds [11], and distributed Filaments [15]. In IVY, a network-wide virtual address space, shared among loosely coupled processors, permits computations to access remote objects.
Reference: [21] <author> B. D. Marsh, M. L. Scott, T. J. LeBlanc, and E. P. Markatos. </author> <title> First class user-level threads. </title> <booktitle> In Symposium on Operating System Principles, </booktitle> <pages> pages 110-121, </pages> <year> 1991. </year>
Reference-contexts: In contrast, user threads are both cheap and highly efficient. Finally, because not every OS provides kernel threads, applications based on kernel-space threads are not portable. Scheduler Activations [2] and Psyche <ref> [21] </ref> are examples of systems that attempt to combine the advantages of both user-space and kernel-space threads, through use of up-calls and software interrupts. Ariadne keeps thread information inside a thread shell. <p> Examples 2 and limitations of user-space implementations can be found in [25]. As evidenced by the growing number of operating systems promoting kernel-space threads (e.g., Solaris, Mach), efficient coupling of cheap user-space threads with kernel-level support can enhance development of concurrent applications <ref> [21, 2] </ref>. Because kernel-space thread implementations are OS specific, and tied to particular hardware, application portability is a serious concern. A possible solution is the use of the POSIX standard as a threads programming interface.
Reference: [22] <author> E. Mascarenhas, F. Knop, and V. Rego. ParaSol: </author> <title> A Multi-threaded System for Parallel Simulation Based on Mobile Threads. </title> <booktitle> In Proceedings of the Winter Simulation Conference, </booktitle> <pages> pages 690-697, </pages> <year> 1995. </year>
Reference-contexts: We propose a paradigm of domain-oriented computation, based on threads and events, to enable low-cost parallelization and rapid experimentation. Indeed, this motivated development of the Ariadne threads system [25] to support `process-oriented' parallel simulation <ref> [22] </ref>. The idea is to move domain functionality into a layer distinct from parallel simulation functionality. We found threads functionality highly useful in supporting multiple domains simultaneously. By encapsulating difficult domain functionality, users are relieved of the burden of recreating domain code. <p> This layering, along with layered support of the ParaSol parallel simulation system <ref> [22] </ref>, is shown in Figure 1. The kernel layer facilitates thread creation, initialization, destruction, and context-switching; it uses an internal priority-queue based scheduler. The support layer enables applications to use threads via supervised kernel access and allows customization. <p> Support-layer software is an intrinsic part of the threads library, while the customization modules are meant to flexibly cater to application needs. The layered design enables the system to interface well with application-level software. The ParaSol system <ref> [22] </ref> is one example of this, and the Clam active-messaging system [16] is another. Consider, for example, threads support in ParaSol. Custom modules in ParaSol are mapped into Ariadne's kernel and support layers, as shown in Figure 1. <p> Both rely on the underlying communications environment and may be generalized to envelop other computing models. Using message-passing, for example, Ariadne processes may support remote-memory copy; through data area broadcasts, remote processes are offered asynchronous read/write access. As another example, mobile threads in the ParaSol <ref> [22] </ref> parallel simulation system may communicate with other mobile threads through a mailbox facility. Such messaging enables threads to exchange and share data, update results, schedule computations and synchronize. Thread migration overheads in Ariadne are small, compared to the total time required for migration. <p> We intend to examine thread migration for load balancing in more detail. Finally, Ariadne is currently being used to support two related environments. In the ParaSol parallel process-oriented simulation environment <ref> [22] </ref>, threads implement simulation processes and operate in conjunction with optimistic and adaptive simulation protocols. In the investigation of efficient user-space implementations of network protocols, threads offer support for dynamic adaptations to network loads and active messaging [16].
Reference: [23] <author> E. Mascarenhas and V. Rego. </author> <title> Ariadne User Manual. </title> <type> Technical Report 94-081, </type> <institution> Computer Sciences Department, Purdue University, </institution> <year> 1994. </year>
Reference-contexts: User-defined functions typically create and manage an appropriate data structure for handling ready threads. This depends on how the application wants to schedule threads. Details of scheduler customization can be found in <ref> [23, 25] </ref>. Because threads are preemptable, all runnable threads at the highest priority have access to the CPU. This allows Ariadne threads to use fine time-slicing to share a host process's time-slice in round-robin fashion.
Reference: [24] <author> E. Mascarenhas and V. Rego. </author> <title> DISplay: A Visualization and User Interaction Interface for Parallel Simulation Environments. </title> <journal> Computer & Graphics, </journal> <volume> 19(5) </volume> <pages> 739-753, </pages> <year> 1995. </year>
Reference-contexts: We simulate the movement of the walker for T time-steps, and finally compute his mean square displacement (msd). The goal is to (empirically) determine msd as a function of q and T . Details on the model can be found in [28] and <ref> [24] </ref>. In this example, both thread migration and data transfer are used. The uniprocessor version of the application is simple to code. A 2-D grid is created to represent the lattice, and a set of sites is marked as inaccessible. <p> For simplicity, we do not implement cascading retractions. Pseudocode for a walker is shown in Figure 18. Synchronization is based on a decentralized protocol, with each processor synchronizing only with its neighbors <ref> [24] </ref>. Though the application is regular and well-suited to distribution, load imbalance is a certainty. Initially balanced process loads become unbalanced as walkers begin to migrate across slice boundaries. Redistributing grid slices to balance load is possible, but is not pursued here.
Reference: [25] <author> E. Mascarenhas and V. Rego. Ariadne: </author> <title> Architecture of a portable threads system supporting thread migration. </title> <journal> Software-Practice and Experience, </journal> <volume> 26(3) </volume> <pages> 327-356, </pages> <month> March </month> <year> 1996. </year>
Reference-contexts: For simplicity, distributed applications often consist of communicating processes which compute using a subroutine structure. But though subroutine calls are inexpensive, they lack flexibility in that they run only when invoked, and when invoked they run to completion. We propose the use of cheap, user-space threads <ref> [38, 25] </ref> as the unit of computation in shared- and distributed-memory environments. <p> Finally, because of flexibility in task schedules and simplicity of thread operations, programming with threads holds promise for reduced parallelization effort. We propose a paradigm of domain-oriented computation, based on threads and events, to enable low-cost parallelization and rapid experimentation. Indeed, this motivated development of the Ariadne threads system <ref> [25] </ref> to support `process-oriented' parallel simulation [22]. The idea is to move domain functionality into a layer distinct from parallel simulation functionality. We found threads functionality highly useful in supporting multiple domains simultaneously. By encapsulating difficult domain functionality, users are relieved of the burden of recreating domain code. <p> The system is written in C, and supports applications developed in Fortran, C and C++. 3 A brief overview of the uniprocessor system is provided in Section 2. Details on the system's internal mechanisms for thread migration and distributed support can be found in <ref> [25] </ref>. Shared- and distributed-memory models are presented in Sections 3 and 4, respectively. The customization interface, using PVM as an example, is described in Section 5. Four examples exemplifying Ariadne's use are detailed in Section 6, along with discussions on performance. <p> In the current system, use of multiple processes helps circumvent the problem of blocking. 5 SPARCstation 20. Details on context switching can be found in <ref> [25] </ref>. The approach is simple and effective, and has enabled ports to a number of different architectures, including SPARCs, SGI and IBM RS/6000 workstations, and Intel Paragon and Sequent Symmetry multiprocessors. Scheduling and Time-Slicing A built-in scheduler doles out portions of a process's time-slice to the process's threads. <p> User-defined functions typically create and manage an appropriate data structure for handling ready threads. This depends on how the application wants to schedule threads. Details of scheduler customization can be found in <ref> [23, 25] </ref>. Because threads are preemptable, all runnable threads at the highest priority have access to the CPU. This allows Ariadne threads to use fine time-slicing to share a host process's time-slice in round-robin fashion. <p> In distributed environments, message passing and thread migration are the primary synchronization mechanisms. A thread may migrate to a remote processor and signal a semaphore there. Details on basic kernel mechanisms, and benchmark comparisons of Ariadne primitives with primitives in commercial threads systems can be found in <ref> [25] </ref>. 2.3 Parallel Programming with Ariadne The basic threads system is augmented to provide programming support on shared and distributed memory environments. On shared memory multiprocessors, Ariadne exploits Unix's IPC facilities. <p> Shared Memory Schedulers The base system provides a scheduler customization facility for implementing specialized shared memory schedulers. These allow processes to access and schedule threads from a common pool of runnable threads. User-defined customization involves development of data structure with insert and delete operations, callable by Ariadne's context-switching routine <ref> [25] </ref>. When invoked, the function a_sched_register () installs user-defined scheduler functions in place of the kernel's built-in scheduler. Given a sufficient number of runnable threads to keep processors busy, this mechanism effects automatic load balancing. Examples of load balancing with shared memory schedulers are described in Section 6. <p> Thread migration overheads in Ariadne are small, compared to the total time required for migration. The time required to migrate a thread is only 1-3% larger than the time required to move a message of the same size. Details on thread migrations can be found in <ref> [25] </ref>. Each RPC-style [5, 9, 11] access requires two messages, a send and a receive. The former delivers parameters to a procedure, and the latter returns results. In the traditional process-oriented model the sender typically blocks on the send. <p> During initialization, the first process created turns into a control process which monitors progress of other processes; it determines when all processes are done with computation, and can trigger a shutdown of the system. Details on how this is accomplished can be found in <ref> [25] </ref>. Function a_dexit () effects cleanup on process termination, using primitives provided 19 by the underlying system for this purpose. For example, in Ariadne's PVM interface, a call is made to pvm_exit (). Pseudocode outlining this implementation is shown in Figure 6. <p> As in the previous example, the sequential algorithm readily lends itself to parallelization on shared memory using Ariadne's threads. As before, each recursive call that operates on a subarray of S is turned into a thread. Code describing the development of a parallel, multithreaded quicksort can be found in <ref> [25] </ref>. In the following section we show how pivoting to get balanced loads can enhance parallel execution performance, even though such pivoting requires more work. Using Ariadne to perform a quicksort helps illustrate its automatically balanced processor loads. <p> Examples 2 and limitations of user-space implementations can be found in <ref> [25] </ref>. As evidenced by the growing number of operating systems promoting kernel-space threads (e.g., Solaris, Mach), efficient coupling of cheap user-space threads with kernel-level support can enhance development of concurrent applications [21, 2].
Reference: [26] <author> E. Mohr, D. A. Kranz, and R. Halstead Jr. </author> <title> Lazy task creation: A technique for increasing the granularity of parallel programs. </title> <journal> IEEE transactions on Parallel and Distributed Systems, </journal> <volume> 2(3) </volume> <pages> 264-280, </pages> <month> July </month> <year> 1991. </year>
Reference-contexts: New threads are created only when the depth of recursion reaches or exceeds some user-set threshold RECURSE LEVEL. This helps prevent stack overflow and increases computation granularity. A related technique for increasing the granularity of fine-grained applications is found in Lazy Task Creation <ref> [26] </ref>. It is also possible to enhance stateful threads with support for low-cost fine-grained operations as in the Chores system [12]. An interesting feature of programming with Ariadne, as demonstrated above, is the relative ease with which one can move from sequential code to parallel code.
Reference: [27] <author> F. Mueller. </author> <title> A library implementation of POSIX threads under UNIX. </title> <booktitle> In Winter USENIX, </booktitle> <pages> pages 29-41, </pages> <month> January </month> <year> 1993. </year>
Reference-contexts: In IVY, a network-wide virtual address space, shared among loosely coupled processors, permits computations to access remote objects. The shared virtual 2 For examples of threads systems see FastThreads [3], C Threads [39], Solaris Threads [31], Filaments [13], System [6], Pthreads <ref> [27] </ref>. 38 memory allows threads and objects to migrate easily, since all processors have access to the same virtual address space. But in IVY, this requires maintaining coherence of copies of data resident on distinct processors. Such maintenance overheads and contention for multiple access to data degrades performance.
Reference: [28] <author> H. Nakanishi. </author> <title> Anomalous diffusion in disordered clusters. </title> <editor> In P. J. Reynolds, editor, </editor> <title> On clusters and Clustering, From Atoms to Fractals, </title> <booktitle> chapter 27, </booktitle> <pages> pages 373-382. </pages> <publisher> Elsevier Science Publishers B.V., </publisher> <year> 1993. </year>
Reference-contexts: These phenomena are sometimes modeled as random walks on disordered clusters. The model described below is known as the ant in the labyrinth and is attributed to deGennes <ref> [28] </ref>. <p> We simulate the movement of the walker for T time-steps, and finally compute his mean square displacement (msd). The goal is to (empirically) determine msd as a function of q and T . Details on the model can be found in <ref> [28] </ref> and [24]. In this example, both thread migration and data transfer are used. The uniprocessor version of the application is simple to code. A 2-D grid is created to represent the lattice, and a set of sites is marked as inaccessible.
Reference: [29] <author> H. Nakanishi, V. Rego, and V. Sunderam. </author> <title> On the Effectiveness of Superconcurrent Computations on Heterogeneous Networks. </title> <journal> Journal of Parallel & Distributed Computing, </journal> <volume> 24(2) </volume> <pages> 177-190, </pages> <month> March </month> <year> 1995. </year> <month> 42 </month>
Reference-contexts: Concurrency supporting environments [42] such as PVM [37] and P4/Parmacs [7] must also evolve, to exploit newer technologies and provide novel services. Though concurrent computing on loosely coupled machines has repeatedly proven to be both low-cost and effective <ref> [29, 37] </ref>, metrics of performance and parallelization effort exhibit both a need and scope for improvement. Execution performance of a distributed application invariably hinges on network latency and throughput. Computation speeds are orders of magnitude larger than communication speeds, and typical network environments are relatively slow.
Reference: [30] <author> J. M. Ortega and R. G. Voigt. </author> <title> Solution of Partial Differential Equations on Vector and Parallel Computers. </title> <publisher> SIAM, </publisher> <year> 1985. </year>
Reference-contexts: Such iteration occurs, for example, in determining steady state heat distribution over a thin square metal plate, given temperature on the boundary. The behavior of this system is governed by Laplace's equation with Dirichlet boundary conditions. It can be discretized using a five-point difference equation <ref> [30] </ref>, with the square replaced by a mesh. The problem is one of determining the values of heat distribution at mesh intersection points. Given a mesh with m 2 points, the finite differencing scheme yields a system of m 2 linear equations in m 2 unknowns.
Reference: [31] <author> M. L. Powell, S. R. Kleiman, S. Barton, D. Shah, D. Stein, and M. Weeks. </author> <title> SunOS Multi-thread Architecture. </title> <booktitle> In Proceedings of the 1991 USENIX Winter Conference, </booktitle> <pages> pages 65-79. </pages> <publisher> Sun Microsystems Inc., </publisher> <year> 1991. </year>
Reference-contexts: In IVY, a network-wide virtual address space, shared among loosely coupled processors, permits computations to access remote objects. The shared virtual 2 For examples of threads systems see FastThreads [3], C Threads [39], Solaris Threads <ref> [31] </ref>, Filaments [13], System [6], Pthreads [27]. 38 memory allows threads and objects to migrate easily, since all processors have access to the same virtual address space. But in IVY, this requires maintaining coherence of copies of data resident on distinct processors.
Reference: [32] <author> M. L. Powell and B. P. Miller. </author> <title> Process migration in DEMOS/MP. </title> <booktitle> In Proceedings of the Ninth ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 110-119, </pages> <month> October </month> <year> 1983. </year>
Reference-contexts: Despite this, process migration has received considerable attention from the research community. Proposals for its application include load sharing, resource sharing, communication overhead reduction and failure robustness, among others [34, 35]. Dynamic migration is usually addressed in the context of distributed operating systems, for example V [40] and DEMOS/MP <ref> [32] </ref>. Another form of thread migration, called computation migration [18], has been proposed as part of the Prelude language. This technique exploits compile-time transformations to migrate only the topmost frame of a stack.
Reference: [33] <author> J. Sang, E. Mascarenhas, and V. Rego. </author> <title> Mobile-Process-Based Parallel Simulation. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 33(1) </volume> <pages> 12-23, </pages> <month> February </month> <year> 1996. </year>
Reference-contexts: In our experience with parallel simulation applications, the cost of moving threads between processors is roughly the same as the cost of messaging the same event-related information <ref> [33] </ref>. The Ariadne system supports threads-based programming on shared- and distributed-memory environments. The system consists of a base library and a set of interface modules for applications and communication subsystems.
Reference: [34] <author> C. Shub. </author> <title> Native code process-originated migration in a heterogeneous environment. </title> <booktitle> In Proceedings of the ACM 18th Annual Computer Science Conference, </booktitle> <pages> pages 266-270, </pages> <year> 1990. </year>
Reference-contexts: Despite this, process migration has received considerable attention from the research community. Proposals for its application include load sharing, resource sharing, communication overhead reduction and failure robustness, among others <ref> [34, 35] </ref>. Dynamic migration is usually addressed in the context of distributed operating systems, for example V [40] and DEMOS/MP [32]. Another form of thread migration, called computation migration [18], has been proposed as part of the Prelude language.
Reference: [35] <author> J. M. Smith. </author> <title> A Survey of Process Migration Mechanisms. </title> <booktitle> ACM Operating System Review, </booktitle> <pages> pages 28-40, </pages> <month> July </month> <year> 1988. </year>
Reference-contexts: Despite this, process migration has received considerable attention from the research community. Proposals for its application include load sharing, resource sharing, communication overhead reduction and failure robustness, among others <ref> [34, 35] </ref>. Dynamic migration is usually addressed in the context of distributed operating systems, for example V [40] and DEMOS/MP [32]. Another form of thread migration, called computation migration [18], has been proposed as part of the Prelude language.
Reference: [36] <author> D. Stein and D. Shah. </author> <title> Implementing lightweight threads. </title> <booktitle> In Proceedings of the 1992 USENIX Summer Conference, </booktitle> <pages> pages 1-9. </pages> <publisher> SunSoft, Inc., </publisher> <year> 1992. </year>
Reference-contexts: The layering has been very useful in ParaSol's development. 4 2.1 Basic Mechanisms A Unix process supports threads in one of two ways: in user-space or in kernel-space. Ariadne is an example of a user-space threads system, while Solaris <ref> [36] </ref> is an example of an OS that provides kernel-space threads. With kernel support, an OS may schedule threads. If one kernel thread blocks, due to I/O, page faults, etc., an unblocked kernel thread can run.
Reference: [37] <author> V. Sunderam, G. Geist, J. Dongarra, and R. Manchek. </author> <title> The PVM Concurrent Computing System: Evolution, </title> <journal> Experiencs and Trends. Journal of Parallel & Distributed Computing, </journal> <volume> 20(4) </volume> <pages> 531-546, </pages> <month> March </month> <year> 1994. </year>
Reference-contexts: Future environments will consist of a heterogeneous mix: multiprocessor desktops, specialized workstations and fast, multiprocessor servers. These will communicate over high-speed networks such as the 100-Mbps Ethernet, FDDI or ATM. Concurrency supporting environments [42] such as PVM <ref> [37] </ref> and P4/Parmacs [7] must also evolve, to exploit newer technologies and provide novel services. Though concurrent computing on loosely coupled machines has repeatedly proven to be both low-cost and effective [29, 37], metrics of performance and parallelization effort exhibit both a need and scope for improvement. <p> Concurrency supporting environments [42] such as PVM [37] and P4/Parmacs [7] must also evolve, to exploit newer technologies and provide novel services. Though concurrent computing on loosely coupled machines has repeatedly proven to be both low-cost and effective <ref> [29, 37] </ref>, metrics of performance and parallelization effort exhibit both a need and scope for improvement. Execution performance of a distributed application invariably hinges on network latency and throughput. Computation speeds are orders of magnitude larger than communication speeds, and typical network environments are relatively slow. <p> Modules are available for the support of shared schedulers, and Ariadne currently provides an interface supporting the PVM <ref> [37] </ref> and Conch [41] communication libraries. The system is written in C, and supports applications developed in Fortran, C and C++. 3 A brief overview of the uniprocessor system is provided in Section 2.
Reference: [38] <author> A. Tanenbaum. </author> <title> Distributed Operating Systems. </title> <publisher> Prentice Hall, </publisher> <year> 1995. </year>
Reference-contexts: For simplicity, distributed applications often consist of communicating processes which compute using a subroutine structure. But though subroutine calls are inexpensive, they lack flexibility in that they run only when invoked, and when invoked they run to completion. We propose the use of cheap, user-space threads <ref> [38, 25] </ref> as the unit of computation in shared- and distributed-memory environments.
Reference: [39] <author> A. Tevanian, R. Rashid, D. Golub, D. Black, E. Cooper, and M. Young. </author> <title> Mach threads and the unix kernel: The battle for control. </title> <booktitle> In Proceedings of the 1987 USENIX Summer Conference, </booktitle> <pages> pages 185-197, </pages> <year> 1987. </year>
Reference-contexts: In IVY, a network-wide virtual address space, shared among loosely coupled processors, permits computations to access remote objects. The shared virtual 2 For examples of threads systems see FastThreads [3], C Threads <ref> [39] </ref>, Solaris Threads [31], Filaments [13], System [6], Pthreads [27]. 38 memory allows threads and objects to migrate easily, since all processors have access to the same virtual address space. But in IVY, this requires maintaining coherence of copies of data resident on distinct processors.
Reference: [40] <author> M. M. Theimer, K. A. Lantz, and D. R. Cheriton. </author> <title> Preemptable remote execution facilities for the V-system. </title> <booktitle> In Poceedings of the Tenth ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 2-12, </pages> <year> 1985. </year>
Reference-contexts: Despite this, process migration has received considerable attention from the research community. Proposals for its application include load sharing, resource sharing, communication overhead reduction and failure robustness, among others [34, 35]. Dynamic migration is usually addressed in the context of distributed operating systems, for example V <ref> [40] </ref> and DEMOS/MP [32]. Another form of thread migration, called computation migration [18], has been proposed as part of the Prelude language. This technique exploits compile-time transformations to migrate only the topmost frame of a stack.
Reference: [41] <author> B. Topol. Conch: </author> <title> Second generation heterogeneous computing. </title> <type> Technical report, </type> <institution> Department of Math and Computer Science, Emory University, </institution> <year> 1992. </year>
Reference-contexts: Modules are available for the support of shared schedulers, and Ariadne currently provides an interface supporting the PVM [37] and Conch <ref> [41] </ref> communication libraries. The system is written in C, and supports applications developed in Fortran, C and C++. 3 A brief overview of the uniprocessor system is provided in Section 2. Details on the system's internal mechanisms for thread migration and distributed support can be found in [25]. <p> Barrier synchronization is inherent to the algorithm. Iterative schemes exist (e.g., chaotic relaxation schemes) which are synchronization free. Performance The SOR application was run on a SPARCstation 5 (Ethernet) LAN, with each machine hosting 32MB of real memory. In this case, Ariadne's messaging support came from the Conch <ref> [41] </ref> distributed system, which allows processors to be configured in a ring. The uniprocessor version of the program is also threads-based, but does not incur distributed system overheads. The environment was not dedicated to the application, though experiments were conducted during off-peak hours.
Reference: [42] <author> L. Turcotte. </author> <title> A Survey of Software Environments for Exploiting Networked Computing Resources. </title> <type> Technical report, </type> <institution> Engineering Research Center for Computational Field Simulations, Mississippi State, </institution> <month> January </month> <year> 1993. </year>
Reference-contexts: Future environments will consist of a heterogeneous mix: multiprocessor desktops, specialized workstations and fast, multiprocessor servers. These will communicate over high-speed networks such as the 100-Mbps Ethernet, FDDI or ATM. Concurrency supporting environments <ref> [42] </ref> such as PVM [37] and P4/Parmacs [7] must also evolve, to exploit newer technologies and provide novel services.
Reference: [43] <author> T. von Eicken, D. Culler, S.GoldStein, and K. Schauser. </author> <title> Active messages: A mechanism for integrated communication and computation. </title> <booktitle> In International Symposium on Computer Architecture, </booktitle> <pages> pages 256-266, </pages> <month> May </month> <year> 1992. </year> <month> 43 </month>
Reference-contexts: For example, employing the generic functionality of an OS for a message-passing processor task-based computation, as done in PVM and P4, poses problems of efficiency. Kernel-based process scheduling for layer invocation, combined with client insensitivity to critical timing in protocol functions, can effect significant though avoidable overheads <ref> [10, 43] </ref>. Typical distributed applications, such as those supported by PVM and P4, are typically limited to processor subroutine-based computation. Proposals for their redesign/extension, to include threads support, have begun to appear [14].
References-found: 43

