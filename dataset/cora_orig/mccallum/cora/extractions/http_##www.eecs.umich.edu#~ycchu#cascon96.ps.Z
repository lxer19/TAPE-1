URL: http://www.eecs.umich.edu/~ycchu/cascon96.ps.Z
Refering-URL: http://www.eecs.umich.edu/~ycchu/
Root-URL: http://www.eecs.umich.edu
Title: Abstract  
Abstract: The performance of host communication subsystems is an important research topic in computer networks. 1 Performance metrics such as throughput, delay, and packet loss are important indices to observe the system behavior. Most research in this area is conducted by experimental measurement; far less attention is paid to the analytic modeling approach. The well-known complexity and dynamic nature of the Transmission Control Protocol/Internet Protocol (TCP/IP) make the performance modeling of communication subsystems extremely difficult. The purpose of this study is to analyze and model the overhead in Unix communication subsystems. The overhead is caused by protocol processing as well as kernel functions for fair allocation of system resources. Our approach is to build analytic models of communication overhead for sending and receiving a message. The analytic models can be applied to analyze the communication overhead for Internet information systems, such as the Internet web servers, or software servers built above midwares, such as the Distributed Computing Environment/Remote Procedure Call (DCE/RPC) servers, that require intensive network I/O. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> C. Chang, R. Flower, J. Forecast, H. Gray, W. Hawe, K. Ramakrishnan, A. Nadkarni, U. Shikarpur, and K. Wilde. </author> <title> High-performance TCP/IP and UDP/IP Networking in DEC OSF/ 1 for Alpha AXP. </title> <journal> Digital Technical Journal, </journal> <volume> Vol. 5, No. 1, </volume> <month> Winter </month> <year> 1993. </year>
Reference-contexts: Socket Layer Protocol Layer Network Interface Layer Application Layer socket send buffer interface send queue socket receive buffer protocol input queue socket receive buffer stream datagram socketsocket TCP/UDP 3 The specific communication subsystem we studied is a DEC Alpha AXP workstation running the OSF/1 1.0 <ref> [1] </ref>. The workstation is attached to a department LAN with an Ethernet adaptor.
Reference: [2] <author> D. D. Clark. </author> <title> Modularity and Efficiency in Protocol Implementation. </title> <type> RFC 817, </type> <institution> Internet Engineering Task Force, </institution> <month> July </month> <year> 1982. </year>
Reference-contexts: The network-interface layer is mainly concerned with the link-layer encapsulation/ decapsulation and driving the transmission media. The TCP/IP protocol specification puts no restriction on the layered structure of network software. Most implementations, however, put the code in the kernel with tightly integrated software layers for efficiency considerations <ref> [2] </ref>. Socket Layer Protocol Layer Network Interface Layer Application Layer socket send buffer interface send queue socket receive buffer protocol input queue socket receive buffer stream datagram socketsocket TCP/UDP 3 The specific communication subsystem we studied is a DEC Alpha AXP workstation running the OSF/1 1.0 [1].
Reference: [3] <author> D. D. Clark, V. Jacobson, J. Romkey, and H. Salwen. </author> <title> An Analysis of TCP Processing Overhead. </title> <journal> IEEE Communication Magazine, </journal> <volume> Vol. 27, No. 6, </volume> <pages> pp. 23-29, </pages> <month> June </month> <year> 1989. </year>
Reference: [4] <author> D. E. Comer. </author> <title> Internetworking with TCP/IP Volume I: Principles, Protocols, and Architecture, Third Edition, </title> <publisher> Prentice Hall, </publisher> <year> 1995. </year>
Reference: [5] <author> J. Kay and J. Pasquale. </author> <title> Measurement, Analysis, and Improvement of UDP/IP Throughput for the DECstation 5000. </title> <booktitle> Proceedings of the Winter 1993 USENIX Conference, </booktitle> <pages> pp. 249-258, </pages> <month> January </month> <year> 1993. </year>
Reference: [6] <author> J. Kay and J. Pasquale. </author> <title> The Importance of Non-Data Touching Processing Overheads in TCP/IP. </title> <booktitle> Proc. ACM SIGCOMM 93, </booktitle> <address> San Francisco, </address> <month> September </month> <year> 1993. </year>
Reference-contexts: Both checksum computation and data movement are data-touching operations; the overhead, hence, grows linearly with the data size to be processed. Protocol-specific Processing Protocol-specific processing contributes different overhead in each protocol layer. Measurement results show that the overhead tends to be fixed if the checksum computation is not included <ref> [6] </ref>. Therefore, we can use constants to represent the fixed part of overhead for protocol-specific processing in each layer, and we denote them separately as TCP in , TCP out , UDP in , UDP out , IP in , and IP out .
Reference: [7] <author> M. Khandker, P. Honeyman, and T. Teorey. </author> <title> Performance of DCE RPC. </title> <booktitle> Proc. 2nd International Conference on Services in Distributed and Networked Environments, </booktitle> <pages> pp. 2-10, </pages> <address> Whistler, BC, Canada, </address> <month> July </month> <year> 1995. </year>
Reference-contexts: DCE relies on the remote procedure call (RPC) as its communication paradigm to construct distributed applications based on client/server architecture. Detailed analysis of the DCE/RPC has shown the significant communication overhead for transporting request and reply messages between client and server machines <ref> [7] </ref>. In this subsection, we apply the analytic models to analyze the communication overhead of a null RPC. 1 A livelocked server spends most of its resources on non-productive operations, such as rejecting new con nections or aborting partially-completed ones [10].
Reference: [8] <author> S. J. Lefer, M. K. McKusick, M. J. Karels, and J. S. Quarterman. </author> <title> The Design and Implementation of the 4.3 BSD Unix Operating System, </title> <publisher> Addison-Wesley, </publisher> <year> 1989. </year>
Reference-contexts: Conclusions and future work are outlined in Section 5. 2 Unix Communication Subsystems The Unix communication subsystem is divided into three software layers: 1) the socket layer, 2) the protocol layer, and 3) the network-interface layer <ref> [8] </ref>. The software architecture is shown in The socket layer hides the complexity of network communication and provides an abstract interface similar to a generic I/O device. The protocol layer covers protocol-specific processing in the transport layer (TCP/UDP) and the network layer (IP). <p> The workstation is attached to a department LAN with an Ethernet adaptor. The implementation of the OSF/1 network software follows the design of the 4.3 BSD Reno release <ref> [8] </ref>. 2.1 The Processing Overhead In communication subsystems, processing overhead can be caused by data-touching operations, such as data movement and checksum computation, as well as non-data-touching operations, such as context switching and interrupt handling.
Reference: [9] <author> P. McKenney and K. Parulkar. </author> <title> Efficient Demultiplexing of Incoming TCP Packets. </title> <booktitle> Proc. ACM SIGCOMM 92, </booktitle> <pages> pp. 269-279, </pages> <address> Bal-timore, MD, </address> <month> August </month> <year> 1993. </year>
Reference-contexts: Demultiplexing Demultiplexing is a table-lookup operation in the transport layer. It searches protocol control blocks (PCBs) for the socket connection associated with an incoming packet. Most implementation derived from the BSD Unix uses a link-list structure with a one-entry cache 2 (for the latest lookup result) to improve performance <ref> [9] </ref>. The search cost depends on the number of socket connections in the system. Here we consider it as part of the fixed overhead in transport-layer input routines, TCP in and UDP in .
Reference: [10] <author> J. Mogul. </author> <title> Operating Systems Support for Busy Internet Servers. </title> <note> WRL Technical Note TN-49, </note> <month> May </month> <year> 1995. </year>
Reference-contexts: The overhead is caused by both protocol-specific processing and operating system (OS) activities such as data movement, context switching, and interrupt handling. Careful analysis of the overhead breakdown can improve the design of communication subsystems. However, it cannot reveal how server machines behave under heavy network traffic <ref> [10] </ref>. This question has received more attention recently because many distributed servers, such as the World-Wide Web (WWW) servers, have generally experienced performance problems in response time and service availability [11,12]. <p> Here we consider it as part of the fixed overhead in transport-layer input routines, TCP in and UDP in . However, it has been shown that the overhead can grow significantly in a busy Internet information server that has peak connections for more than a thousand <ref> [10] </ref>. Interrupt Handling Network communication generates two device hardware interrupts: the receiving interrupt and the transmission-complete interrupt. The overhead for interrupt handling receives less attention than other processing overhead. <p> Another important characteristic of communication subsystems is that the OS has no way to control the load offered to it because it has no control over the number of clients, or over their aggressiveness <ref> [10] </ref>. Although ow control can restrict the data that arrives over an existing connection, it cannot control the rate of requests for new connections. For an overloaded server, these two characteristics cause the OS to spend more time on incoming packet processing than on the rest of request services. <p> In this subsection, we apply the analytic models to analyze the communication overhead of a null RPC. 1 A livelocked server spends most of its resources on non-productive operations, such as rejecting new con nections or aborting partially-completed ones <ref> [10] </ref>.
Reference: [11] <author> J. Mogul. </author> <title> Network Behavior of a Busy Web Server and its Clients. </title> <note> WRL Research Report 95/5, </note> <month> May </month> <year> 1995. </year>
Reference-contexts: For busy Internet web servers, the general performance problems experienced are long response time and short-term service unavailability. A common solution for these problems is to off-load the enormous requests from a single machine to replicated servers <ref> [11] </ref>. Researches also identified the inefficiency in the HyperText Transfer Protocol (HTTP) 1 itself, which uses separate TCP connections for each request. An enhanced HTTP, which uses a single TCP connection for all data exchange, reduces the response time caused by the round-trip network latency [12]. <p> We estimate that it requires 15 hardware interrupts (8 I r and 7 I s ) to service this HTTP transaction. For a busy web server with a peak request rate of about 60 requests per second <ref> [11] </ref>, it will generate approximately 900 interrupts per second. Researches have shown the cost of interrupt service is not trivial in modern computer systems.
Reference: [12] <author> V. Padmanabhan and J. Mogul. </author> <title> Improving WWW Latency. </title> <booktitle> Proc. 2nd WWW Conference 94: Mosaic and the Web, </booktitle> <pages> pp. 995-1005, </pages> <address> Chicago, October1994. </address>
Reference-contexts: Researches also identified the inefficiency in the HyperText Transfer Protocol (HTTP) 1 itself, which uses separate TCP connections for each request. An enhanced HTTP, which uses a single TCP connection for all data exchange, reduces the response time caused by the round-trip network latency <ref> [12] </ref>. In this subsection, we apply the analytic models to examine the communication overhead caused by HTTP requests. HTTP relies on TCP to provide reliable message delivery.
Reference: [13] <author> C. Papadopoulos and G. M. Parulkar. </author> <title> Experimental Evaluation of SunOS IPC and TCP/ IP Protocol Implementation. </title> <journal> ACM/IEEE Transactions on Networking, </journal> <volume> Vol. 1, No. 2, </volume> <pages> pp. 199-216, </pages> <month> April </month> <year> 1993. </year>
Reference: [14] <author> K. Ramakrishnan. </author> <title> Performance Considerations in Designing Network Interfaces. </title> <journal> IEEE Journals on Selected Areas in Communications, </journal> <volume> Vol. 11, No. 2, </volume> <pages> pp. 203-219, </pages> <month> Feb-ruary </month> <year> 1993. </year>
Reference-contexts: This is probably 2 The one-entry cache is called 1-behind cache. 4 because of its asynchronous nature and the difficulty for measuring it. However, careful analysis of interrupt handling in the network device driver reveals how it critically affects the performance during heavy network traffic <ref> [14] </ref>. In the system we studied, the overhead of the receiving interrupt, denoted as I r , covers the entire link-layer processing. It does not include the data movement overhead from network adaptor to kernel, M ka (m) (which is done by DMA).
Reference: [15] <author> W. R. Stevens. </author> <title> TCP/IP Illustrated: Volume I, </title> <publisher> Addison-Wesley, </publisher> <year> 1994. </year>
References-found: 15

