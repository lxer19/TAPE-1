URL: ftp://theory.lcs.mit.edu/pub/people/oded/ceg.ps
Refering-URL: http://theory.lcs.mit.edu/~oded/complexity.html
Root-URL: 
Title: Lower Bounds for Sampling Algorithms for Estimating the Average  
Author: Ran Canetti Guy Even Oded Goldreich 
Keyword: Key words: Theory of computation, Sampling, Estimating, Randomness, Lower bounds.  
Date: October 6, 1994  
Abstract: We show lower bounds on the number of sample points and on the number of coin tosses used by general sampling algorithms for estimating the average value of functions over a large domain. The bounds depend on the desired precision and on the error probability of the estimate. Our lower bounds match upper bounds established by known algorithms, up to a multiplicative constant. Furthermore, we give a non-constructive proof of existence of an algorithm that improves the known upper bounds by a constant factor. 
Abstract-found: 1
Intro-found: 1
Reference: [BGG] <author> M. Bellare, O. Goldreich and S. Goldwasser, </author> <title> "Randomness in Interactive Proofs", </title> <booktitle> 31st FOCS, </booktitle> <year> 1990, </year> <month> pp.563-571. </month>
Reference-contexts: However, this sampler is very wasteful in randomness: it uses n t (n) coin tosses. Several more randomness-efficient samplers are known in the literature. We refer the reader to <ref> [BGG] </ref> for a survey. Of special interest is the sampler presented in [BGG]: this sampler is simultaneously tight with respect to both bounds (up to a multiplicative constant). <p> However, this sampler is very wasteful in randomness: it uses n t (n) coin tosses. Several more randomness-efficient samplers are known in the literature. We refer the reader to <ref> [BGG] </ref> for a survey. Of special interest is the sampler presented in [BGG]: this sampler is simultaneously tight with respect to both bounds (up to a multiplicative constant). <p> Finally, we give a non-constructive proof of existence of a sampler that is more efficient than the <ref> [BGG] </ref> sampler, both in the number of samples and in the number of coins tossed. 2 Namely, we show that given precision *, error probability ffi, and any number n 2 N, there exists an (*; ffi)-sampler (for functions f : f0; 1g n ! [0; 1]) that uses 2 * <p> Specifically, the <ref> [BGG] </ref> algorithm uses O ( 1 ffi ) samples, and tosses 2n + O (log 1 ffi ) coins.
Reference: [CEG] <author> R. Canetti, Guy Even and O. Goldreich, </author> <title> "Lower Bounds for Sampling Algorithms for Estimating the Average", </title> <type> Technical Report # 789, </type> <institution> Department of Computer Science, Technion, </institution> <month> Nov. </month> <year> 1993. </year>
Reference-contexts: For details see our Technical Report <ref> [CEG] </ref>).
Reference: [GW] <author> O. Goldreich and A. Wigderson, </author> <title> "Tiny Families of Functions with Random Properties: </title>
Reference-contexts: Recently, Goldreich and Wigderson have presented an explicit (and efficient) sampler that given *, ffi, and n as above uses O ( 1 * 2 log 1 ffi ) samples and tosses n + O (log 1 * ) + O (log 1 ffi ) coins <ref> [GW] </ref>. 2 The setting We use the following notational conventions. Let a 2 R A denote a random variable, a, uniformly distributed over the set A.
References-found: 3

