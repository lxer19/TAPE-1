URL: http://charm.cs.uiuc.edu/manuals/yaddes-ckpt-int.ps.gz
Refering-URL: http://charm.cs.uiuc.edu/manuals/
Root-URL: http://www.cs.uiuc.edu
Title: Effects of the Checkpoint Interval on Time and Space in Time Warp  
Author: Bruno R. Preiss Wayne M. Loucks Ian D. MacIntyre 
Address: Waterloo, Ontario, Canada, N2L 3G1  Drive, Kanata, Ontario, Canada, K2L 4B6.  
Affiliation: Department of Electrical and Computer Engineering University of Waterloo  
Note: Copyright (c) 1994 by The Association for Computing Machinery, Inc.  This work was supported in part by the Information Technology Research Centre (ITRC) of the Province of Ontario (Canada) and by the Natural Sciences and Engineering Research Council (NSERC) of Canada. Ian MacIntyre is currently at CARP Systems International, 600 Terry Fox  
Abstract: y An earlier version of a part of this paper appeared in the 1992 SCS/IEEE Workshop on Parallel and Distributed Simulation under the title "On the Trade-off between Time and Space in Optimistic Parallel Discrete-Event Simulation"[27]. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Bellenot, S. </author> <title> State skipping performance with the Time Warp Operating System. </title> <booktitle> In Proc. 1992 Workshop on Parallel and Distributed Simulation (Newport Beach, </booktitle> <address> Califor-nia, </address> <month> Jan. </month> <year> 1992), </year> <editor> M. Abrams and P. F. Reynolds Jr., Eds., </editor> <booktitle> Institute of Electrical and Electronics Engineers/Society for Computer Simulation, </booktitle> <pages> pp. 53-61. </pages>
Reference-contexts: An alternative to checkpointing on the basis of simulation events is to checkpoint on the basis of real CPU execution time. For example, in the original design of the Time Warp Operating System <ref> [1] </ref>, the state of an LP was checkpointed after that LP had consumed a save period amount of real CPU execution time. However, early tests showed that for unsaturated workloads using a save period of zero always resulted in the best execution times [1]. <p> design of the Time Warp Operating System <ref> [1] </ref>, the state of an LP was checkpointed after that LP had consumed a save period amount of real CPU execution time. However, early tests showed that for unsaturated workloads using a save period of zero always resulted in the best execution times [1]. The effect of T cp on the execution time of the simulation is not the same in all cases. <p> In fact, if a processor has no productive simulation work to be performed, then the cost (in CPU time) of checkpointing can be ignored. This is demonstrated in the work described by Bellenot <ref> [1] </ref> with regards to saturated and unsaturated simulation execution. <p> As the number of processors is increased, STF scheduling behaves less like a sequential simulation and the optimum checkpoint interval decreases. These effects are also consistent with those 24 Copyright (c) 1994 by The Association for Computing Machinery, Inc. described by Bellenot <ref> [1] </ref>. Effects of Scheduling Strategies The performance for the different strategies are shown in Figure 8. Tables 2 and 3 give the time-optimal values for the STF and SVTF scheduling algorithms.
Reference: [2] <author> Burdorf, C., and Marti, J. </author> <title> Non-preemptive Time Warp scheduling algorithms. </title> <booktitle> Operating Systems Review 24, </booktitle> <month> 2 (Apr. </month> <year> 1990), </year> <pages> 7-18. </pages>
Reference-contexts: As indicated above in Section 2.4.1, the benchmarks used in this simulation produce saturated workloads. I.e., processors rarely have idle time. In this paper we examine several different scheduling algorithms. For a more complete discussion of scheduling algorithms see <ref> [2] </ref> and [12]. In this paper we only consider non-preemptive scheduling algorithms. I.e., once an LP begins to process an input message, the processing of that message will proceed to completion before another LP (on the same processor) is permitted to execute.
Reference: [3] <author> Chandy, K. M., Browne, J. C., Dissly, C. W., and Uhrig, W. R. </author> <title> Analytic models for rollback and recovery strategies in data base systems. </title> <journal> IEEE Trans. on Software Engineering 1, </journal> <month> 1 (Mar. </month> <year> 1975), </year> <pages> 440-110. </pages>
Reference-contexts: a high degree of predictiveness to limit the negative impact of aggressive cancellation can also benefit from the use of checkpoint intervals larger than one. 4.4 Comparison of Theoretical Bounds and Experimental Results Selection of the optimal checkpoint interval has been extensively studied in the context of transaction-oriented database systems <ref> [3, 8, 9, 19, 29, 30] </ref>. In the context of transaction systems, the purpose of checkpointing and rollback recovery is to improve the reliability of the 26 Copyright (c) 1994 by The Association for Computing Machinery, Inc. system in the presence of failures.
Reference: [4] <author> Chandy, K. M., and Misra, J. </author> <title> Distributed simulation: A case study in design and verification of distributed programs. </title> <journal> IEEE Trans. on Software Engineering 5, </journal> <month> 5 (Sept. </month> <year> 1979), </year> <month> 440-452. </month> <title> Copyright (c) 1994 by The Association for Computing Machinery, </title> <publisher> Inc. </publisher>
Reference-contexts: In conservative methods, execution of an LP is halted until it can be determined with certainty that resumed execution will not violate causality. Conservative methods are prone to deadlock <ref> [4] </ref>. In optimistic methods, LPs always process input messages whenever they are available under the implicit assumption that the message sequence does not violate causality. When a causality violation occurs, the LP is returned to its state immediately prior to the violation (rollback), and execution resumes [11].
Reference: [5] <author> Fujimoto, R. M. </author> <title> Lookahead in parallel discrete event simulation. </title> <booktitle> In Proc. 1988 Int. Conf. on Parallel Processing (St Charles, </booktitle> <address> Illinois, </address> <month> Aug. </month> <year> 1988), </year> <title> vol. </title> <booktitle> III, </booktitle> <pages> pp. 34-41. </pages>
Reference-contexts: We have also conducted experiments in which we varied the lookahead of the node implementation|the lookahead is a measure of the node's predictiveness. (For a detailed discussion of lookahead see <ref> [5] </ref>.) These results, which are reported in [25], suggest that systems which exploit a high degree of predictiveness to limit the negative impact of aggressive cancellation can also benefit from the use of checkpoint intervals larger than one. 4.4 Comparison of Theoretical Bounds and Experimental Results Selection of the optimal checkpoint
Reference: [6] <author> Fujimoto, R. M. </author> <title> Optimistic approaches to parallel discrete event simulation. </title> <booktitle> Transactions of the Society for Computer Simulation 7, </booktitle> <month> 2 (June </month> <year> 1990), </year> <pages> 153-191. </pages>
Reference-contexts: The state is easily reconstructed by reprocessing input messages. However, output messages regenerated during state reconstruction must not be sent since they are an artifact of the state reconstruction process. An LP that is reconstructing a missing state is said to be coasting forward <ref> [6] </ref>. The reconstruction 1 Actually, in our implementation, all input messages having exactly the same timestamp are processed by an LP at once. A set of input messages having the same timestamp is called an input event combination. For a discussion on the importance of using event combinations, see [16].
Reference: [7] <author> Gafni, A. </author> <title> Space management and cancellation mechanisms for Time Warp. </title> <type> Tech. Rep. </type> <institution> TR-85-341, Univ. of Southern California, </institution> <address> Los Angeles, CA, </address> <month> Oct. </month> <year> 1985. </year>
Reference-contexts: When the LP resumes execution, it will generate output messages. In the event that an output message is the same as a message that would have been cancelled during the rollback, then the new output message and its antimessage will be discarded <ref> [7] </ref>. 6 Copyright (c) 1994 by The Association for Computing Machinery, Inc. The assumption is that after a rollback, an LP is likely to produce the same output messages.
Reference: [8] <author> Gelenbe, E. </author> <title> On the optimum checkpoint interval. </title> <journal> Journal of the Associating for Computing Machinery 26, </journal> <month> 2 (Apr. </month> <year> 1979), </year> <pages> 259-270. </pages>
Reference-contexts: a high degree of predictiveness to limit the negative impact of aggressive cancellation can also benefit from the use of checkpoint intervals larger than one. 4.4 Comparison of Theoretical Bounds and Experimental Results Selection of the optimal checkpoint interval has been extensively studied in the context of transaction-oriented database systems <ref> [3, 8, 9, 19, 29, 30] </ref>. In the context of transaction systems, the purpose of checkpointing and rollback recovery is to improve the reliability of the 26 Copyright (c) 1994 by The Association for Computing Machinery, Inc. system in the presence of failures.
Reference: [9] <author> Grassi, V., Donatiello, L., and Tucci, S. </author> <title> On the optimal checkpointing of critical tasks and transaction-oriented systems. </title> <journal> IEEE Trans. on Software Engineering 18, </journal> <month> 1 (Jan. </month> <year> 1992), </year> <pages> 72-77. </pages>
Reference-contexts: a high degree of predictiveness to limit the negative impact of aggressive cancellation can also benefit from the use of checkpoint intervals larger than one. 4.4 Comparison of Theoretical Bounds and Experimental Results Selection of the optimal checkpoint interval has been extensively studied in the context of transaction-oriented database systems <ref> [3, 8, 9, 19, 29, 30] </ref>. In the context of transaction systems, the purpose of checkpointing and rollback recovery is to improve the reliability of the 26 Copyright (c) 1994 by The Association for Computing Machinery, Inc. system in the presence of failures.
Reference: [10] <author> Jefferson, D., Beckman, B., Wieland, F., Blume, L., DiLoreto, M., Hon-talas, P., Laroche, P., Sturdevant, K., Tupman, J., Warren, V., Wedel, J., Younger, H., and Bellenot, S. </author> <title> Distributed simulation and the Time Warp Operating System. </title> <booktitle> In Proc. 12th SIGOPS|Symposium on Operating Systems Principles (1987), </booktitle> <pages> pp. 77-93. </pages>
Reference-contexts: When a causality violation occurs, the LP is returned to its state immediately prior to the violation (rollback), and execution resumes [11]. In this paper we focus on the most common optimistic synchronization method, namely Time-Warp <ref> [10] </ref>.
Reference: [11] <author> Jefferson, D. R. </author> <title> Virtual time. </title> <journal> ACM Trans. on Programming Languages and Systems 7, </journal> <month> 3 (July </month> <year> 1985), </year> <month> 404-425. </month> <title> 38 Copyright (c) 1994 by The Association for Computing Machinery, </title> <publisher> Inc. </publisher>
Reference-contexts: In optimistic methods, LPs always process input messages whenever they are available under the implicit assumption that the message sequence does not violate causality. When a causality violation occurs, the LP is returned to its state immediately prior to the violation (rollback), and execution resumes <ref> [11] </ref>. In this paper we focus on the most common optimistic synchronization method, namely Time-Warp [10].
Reference: [12] <author> Lin, Y.-B., and Lazowska, E. D. </author> <title> Processor scheduling for Time Warp parallel simulation. </title> <type> Tech. rep., </type> <institution> Dept. of Comp. Sci. and Eng., University of Washington, </institution> <address> Seattle, Washington, </address> <month> Mar. </month> <year> 1990. </year>
Reference-contexts: As indicated above in Section 2.4.1, the benchmarks used in this simulation produce saturated workloads. I.e., processors rarely have idle time. In this paper we examine several different scheduling algorithms. For a more complete discussion of scheduling algorithms see [2] and <ref> [12] </ref>. In this paper we only consider non-preemptive scheduling algorithms. I.e., once an LP begins to process an input message, the processing of that message will proceed to completion before another LP (on the same processor) is permitted to execute. <p> Furthermore, the arrival of an antimessage at an LP will not terminate the current processing cycle of that LP. 11 Copyright (c) 1994 by The Association for Computing Machinery, Inc. 2.5.1 Smallest-Timestamp-First Scheduling Smallest-timestamp-first (STF) scheduling is the most commonly used scheduling heuristic in optimistic simulation systems <ref> [12] </ref>. The STF scheduling algorithm gives higher priority to LPs having input messages with lower timestamps. This algorithm always chooses for execution the LP from among those having an input message to be processed the one having the message with the smallest timestamp.
Reference: [13] <author> Lin, Y.-B., and Lazowska, E. D. </author> <title> Reducing the state saving overhead for Time Warp parallel simulation. </title> <type> Tech. rep., </type> <institution> Dept. of Comp. Sci. and Eng., University of Washington, </institution> <address> Seattle, Washington, </address> <month> Feb. </month> <year> 1990. </year>
Reference-contexts: This confirms the observation originally made by Lin on the basis of simulations of parallel 18 Copyright (c) 1994 by The Association for Computing Machinery, Inc. simulation <ref> [13] </ref>, that when choosing a checkpoint interval, it is better to select an interval that is too large, rather than one that is too small. <p> Because of this, the arrival processes for rollback occurrences are fundamentally different and the results from transaction-oriented systems are not directly applicable to simulation. More recently, Lin and Lazowska have studied the selection of time-optimal checkpoint intervals specifically in the context of optimistically synchronized parallel simulation <ref> [13] </ref>. In this section we compare the experimentally determined time-optimal checkpoint intervals with the Lin-Lazowska interval and with the theoretical upper and lower bounds [14]. 4.4.1 Time-Optimal Checkpoint Intervals In [13], Lin and Lazowska first derived bounds for the state saving time overhead. <p> Lin and Lazowska have studied the selection of time-optimal checkpoint intervals specifically in the context of optimistically synchronized parallel simulation <ref> [13] </ref>. In this section we compare the experimentally determined time-optimal checkpoint intervals with the Lin-Lazowska interval and with the theoretical upper and lower bounds [14]. 4.4.1 Time-Optimal Checkpoint Intervals In [13], Lin and Lazowska first derived bounds for the state saving time overhead. Using these bounds, it is possible to select a checkpoint interval which minimizes the state-saving time overhead. In this paper we will briefly present the results of their derivation. We refer the interested reader to [13] and [14] <p> Intervals In <ref> [13] </ref>, Lin and Lazowska first derived bounds for the state saving time overhead. Using these bounds, it is possible to select a checkpoint interval which minimizes the state-saving time overhead. In this paper we will briefly present the results of their derivation. We refer the interested reader to [13] and [14] for the details of the derivation. To present their results, we first introduce some notation: I cp checkpoint interval : The number of input messages processed between two consecutive checkpoint operations. <p> Table 5 gives formulae for the lower, I l cp , and upper, I u cp , bounds on the checkpoint interval for each of the three cases. 4.4.2 Empirical Results In <ref> [13] </ref>, Lin and Lazowska argue that the optimal checkpoint interval (I optimal cp ) is likely to fall in the smaller interval [I cp ; I + cp ].
Reference: [14] <author> Lin, Y.-B., Preiss, B. R., Loucks, W. M., and Lazowska, E. D. </author> <title> Selecting the checkpoint interval in Time Warp parallel simulation. </title> <booktitle> In Proc. 1993 Workshop on Parallel and Distributed Simulation (San Diego, </booktitle> <address> CA, </address> <month> May </month> <year> 1993), </year> <booktitle> Institute of Electrical and Electronics Engineers/Society for Computer Simulation, </booktitle> <pages> pp. 3-10. </pages>
Reference-contexts: More recently, Lin and Lazowska have studied the selection of time-optimal checkpoint intervals specifically in the context of optimistically synchronized parallel simulation [13]. In this section we compare the experimentally determined time-optimal checkpoint intervals with the Lin-Lazowska interval and with the theoretical upper and lower bounds <ref> [14] </ref>. 4.4.1 Time-Optimal Checkpoint Intervals In [13], Lin and Lazowska first derived bounds for the state saving time overhead. Using these bounds, it is possible to select a checkpoint interval which minimizes the state-saving time overhead. In this paper we will briefly present the results of their derivation. <p> Using these bounds, it is possible to select a checkpoint interval which minimizes the state-saving time overhead. In this paper we will briefly present the results of their derivation. We refer the interested reader to [13] and <ref> [14] </ref> for the details of the derivation. To present their results, we first introduce some notation: I cp checkpoint interval : The number of input messages processed between two consecutive checkpoint operations. <p> In a more detailed theoretical analysis the bounds on the time-optimal checkpoint interval are linear in the number of rollback cycles <ref> [14] </ref>. As a result, since throttling decreases the number of rollback cycles, it would be expected that the (theoretical) time-optimal checkpoint interval estimated above would underestimate the true time-optimal checkpoint interval. 5 Space vs.
Reference: [15] <author> Loucks, W. M., and Preiss, B. R. </author> <title> The role of knowledge in distributed simulation. </title> <booktitle> In Proc. SCS Multiconf. on Distributed Simulation (San Diego, </booktitle> <address> CA, </address> <month> Jan. </month> <year> 1990), </year> <booktitle> Society for Computer Simulation, </booktitle> <pages> pp. 9-16. </pages>
Reference-contexts: The following is a very brief description of the benchmarks. For more detailed descriptions see <ref> [15, 22, 23, 24] </ref>. These simulations were coded and run on a Transputer system 13 Copyright (c) 1994 by The Association for Computing Machinery, Inc. (Section 3.3), and a number of experiments were performed on the system (Section 3.4). 3.1 Benchmarks The system simulated is a static network of nodes.
Reference: [16] <author> Manjikian, N., and Loucks, W. M. </author> <title> Using split event sets to form and schedule event combinations in discrete event simulation. </title> <booktitle> In Proc. 25th Ann. Simulation Symp. (Apr. 1992), Institute of Electrical and Electronics Engineers/Society for Computer Simulation, </booktitle> <pages> pp. 184-191. </pages>
Reference-contexts: The reconstruction 1 Actually, in our implementation, all input messages having exactly the same timestamp are processed by an LP at once. A set of input messages having the same timestamp is called an input event combination. For a discussion on the importance of using event combinations, see <ref> [16] </ref>. For the sake of clarity, in this paper we refer simply to input messages. We implicitly assume that should there be simultaneous input messages, all of these are processed by an LP at once.
Reference: [17] <author> Misra, J. </author> <title> Distributed discrete-event simulation. </title> <journal> ACM Computing Surveys 18, </journal> <month> 1 (Mar. </month> <year> 1986), </year> <month> 39-66. </month> <title> Copyright (c) 1994 by The Association for Computing Machinery, </title> <publisher> Inc. </publisher>
Reference-contexts: Each LP has its own notion of simulation time (local virtual time or LVT) and the LPs exchange timestamped messages <ref> [17] </ref>. Optimistic synchronization allows each LP to execute asynchronously. However, to ensure correct simulation results, certain causality constraints must be met.
Reference: [18] <author> Nicol, D. M. </author> <title> High performance parallelized discrete event simulation of stochastic queueing networks. </title> <booktitle> In Proc. 1988 Winter Simulation Conf. </booktitle> <address> (San Diego, California, </address> <month> Dec. </month> <year> 1988), </year> <editor> M. A. Abrams, P. L. Haigh, and J. C. Comfort, Eds., </editor> <booktitle> Society for Computer Simulation, </booktitle> <pages> pp. 306-314. </pages>
Reference-contexts: When a blocked LP receives an input message, the LP is placed at the end of the list of ready LPs. 3 Experimental Overview The results presented in this paper were obtained from parallel simulations of closed stochastic queueing network benchmarks based on those described in <ref> [18] </ref>. The following is a very brief description of the benchmarks. For more detailed descriptions see [15, 22, 23, 24].
Reference: [19] <author> Nicola, V. F., and Van Spanje, J. M. </author> <title> Comparative analysis of different models of checkpointing and recovery. </title> <journal> IEEE Trans. on Software Engineering 16, </journal> <month> 8 (Aug. </month> <year> 1990), </year> <pages> 807-821. </pages>
Reference-contexts: a high degree of predictiveness to limit the negative impact of aggressive cancellation can also benefit from the use of checkpoint intervals larger than one. 4.4 Comparison of Theoretical Bounds and Experimental Results Selection of the optimal checkpoint interval has been extensively studied in the context of transaction-oriented database systems <ref> [3, 8, 9, 19, 29, 30] </ref>. In the context of transaction systems, the purpose of checkpointing and rollback recovery is to improve the reliability of the 26 Copyright (c) 1994 by The Association for Computing Machinery, Inc. system in the presence of failures.
Reference: [20] <author> Preiss, B. R. </author> <title> The Yaddes distributed discrete event simulation specification language and execution environments. </title> <type> CCNG Technical Report E-181, </type> <institution> Department of Electrical Engineering and Computer Communications Networks Group, University of Waterloo, </institution> <year> 1989. </year>
Reference-contexts: The process of recovering storage allocated to fossils is called fossil collection. GVT introduces two further time penalties, the time to estimate GVT and the time perform the fossil collection algorithm. All the experiments described in this paper use the token-based GVT algorithm described in <ref> [20] </ref>. 2.5 Process Scheduling Algorithms In general, the number of LPs required for a simulation will not match the number of processors available to do the simulation. In particular when simulating large systems, it is likely that the number of LPs will exceed the number of processors. <p> For a load of one, T event was 2.2 ms, for a load of four, T event was 2.9 ms, and for a load of eight it was 3.5 ms. 3.3 Simulation Software and Hardware The simulations were implemented using the Yaddes distributed discrete event simulation language <ref> [20, 21, 26] </ref>. The simulations were performed on a Transputer multiprocessor with a total of eight processors. The connections between the processors form a cube. In all cases, the obvious LP to processor assignment was made. <p> In principle, such memory can be reclaimed by the fossil collection algorithm. However, all practical fossil collection algorithms lag the instan 31 Copyright (c) 1994 by The Association for Computing Machinery, Inc. taneous GVT. In the current implementation of Yaddes, a circulating token GVT algorithm is used <ref> [20] </ref>. It is difficult to obtain time-averaged memory utilization data without significantly perturbing the behaviour of the simulation. However, it is relatively simple to determine the maximum memory utilization for checkpointed state information and message buffers independently, as well as for total storage (state plus message buffers).
Reference: [21] <author> Preiss, B. R. </author> <title> The Yaddes distributed discrete event simulation specification language and execution environments. </title> <booktitle> In Proc. SCS Multiconf. on Distributed Simulation (Tampa, </booktitle> <address> FL, </address> <month> Mar. </month> <year> 1989), </year> <booktitle> Society for Computer Simulation, </booktitle> <pages> pp. 139-144. </pages>
Reference-contexts: For a load of one, T event was 2.2 ms, for a load of four, T event was 2.9 ms, and for a load of eight it was 3.5 ms. 3.3 Simulation Software and Hardware The simulations were implemented using the Yaddes distributed discrete event simulation language <ref> [20, 21, 26] </ref>. The simulations were performed on a Transputer multiprocessor with a total of eight processors. The connections between the processors form a cube. In all cases, the obvious LP to processor assignment was made.
Reference: [22] <author> Preiss, B. R. </author> <title> Performance of discrete event simulation on a multiprocessor using optimistic and conservative synchronization. </title> <booktitle> In Proc. 1990 Int. Conf. on Parallel Processing (St. </booktitle> <address> Charles, IL, </address> <month> Aug. </month> <year> 1990), </year> <title> Penn. </title> <publisher> State University, </publisher> <pages> pp. 218-222. </pages>
Reference-contexts: The following is a very brief description of the benchmarks. For more detailed descriptions see <ref> [15, 22, 23, 24] </ref>. These simulations were coded and run on a Transputer system 13 Copyright (c) 1994 by The Association for Computing Machinery, Inc. (Section 3.3), and a number of experiments were performed on the system (Section 3.4). 3.1 Benchmarks The system simulated is a static network of nodes.
Reference: [23] <author> Preiss, B. R., and Loucks, W. M. </author> <title> Prediction and lookahead in distributed simulation. </title> <type> CCNG Technical Report E-191, </type> <institution> Department of Electrical Engineering and 40 Copyright (c) 1994 by The Association for Computing Machinery, Inc. Computer Communications Networks Group, University of Waterloo, </institution> <year> 1989. </year>
Reference-contexts: The following is a very brief description of the benchmarks. For more detailed descriptions see <ref> [15, 22, 23, 24] </ref>. These simulations were coded and run on a Transputer system 13 Copyright (c) 1994 by The Association for Computing Machinery, Inc. (Section 3.3), and a number of experiments were performed on the system (Section 3.4). 3.1 Benchmarks The system simulated is a static network of nodes.
Reference: [24] <author> Preiss, B. R., and Loucks, W. M. </author> <title> The impact of lookahead on the performance of conservative distributed simulation. </title> <booktitle> In Proc. 1990 European Multiconference| Simulation Methodologies, Languages and Architectures (Nuremberg, </booktitle> <address> FRG, </address> <month> June </month> <year> 1990), </year> <booktitle> Society for Computer Simulation, </booktitle> <pages> pp. 204-209. </pages>
Reference-contexts: The following is a very brief description of the benchmarks. For more detailed descriptions see <ref> [15, 22, 23, 24] </ref>. These simulations were coded and run on a Transputer system 13 Copyright (c) 1994 by The Association for Computing Machinery, Inc. (Section 3.3), and a number of experiments were performed on the system (Section 3.4). 3.1 Benchmarks The system simulated is a static network of nodes.
Reference: [25] <author> Preiss, B. R., Loucks, W. M., and MacIntyre, I. D. </author> <title> Effects of the checkpoint interval on time and space in Time Warp. </title> <type> CCNG Technical Report E-230, </type> <institution> Department of Electrical and Computer Engineering and Computer Communications Networks Group, University of Waterloo, </institution> <month> June </month> <year> 1993. </year>
Reference-contexts: We have also conducted experiments in which we varied the lookahead of the node implementation|the lookahead is a measure of the node's predictiveness. (For a detailed discussion of lookahead see [5].) These results, which are reported in <ref> [25] </ref>, suggest that systems which exploit a high degree of predictiveness to limit the negative impact of aggressive cancellation can also benefit from the use of checkpoint intervals larger than one. 4.4 Comparison of Theoretical Bounds and Experimental Results Selection of the optimal checkpoint interval has been extensively studied in the
Reference: [26] <author> Preiss, B. R., and MacIntyre, I. D. </author> <title> YADDES|Yet Another Distributed Discrete Event Simulator: User manual. </title> <type> CCNG Technical Report E-197, </type> <institution> Department of Electrical and Computer Engineering and Computer Communications Networks Group, University of Waterloo, </institution> <year> 1990. </year>
Reference-contexts: For a load of one, T event was 2.2 ms, for a load of four, T event was 2.9 ms, and for a load of eight it was 3.5 ms. 3.3 Simulation Software and Hardware The simulations were implemented using the Yaddes distributed discrete event simulation language <ref> [20, 21, 26] </ref>. The simulations were performed on a Transputer multiprocessor with a total of eight processors. The connections between the processors form a cube. In all cases, the obvious LP to processor assignment was made.
Reference: [27] <author> Preiss, B. R., MacIntyre, I. D., and Loucks, W. M. </author> <title> On the trade-off between time and space in optimistic parallel discrete-event simulation. </title> <booktitle> In Proc. 1992 Workshop on Parallel and Distributed Simulation (Newport Beach, </booktitle> <address> CA, </address> <month> Jan. </month> <year> 1992), </year> <booktitle> Institute of Electrical and Electronics Engineers/Society for Computer Simulation, </booktitle> <pages> pp. 33-42. </pages>
Reference: [28] <author> Reynolds, P. F. </author> <title> A spectrum of options for parallel simulation. </title> <booktitle> In Proc. 1988 Winter Simulation Conf. </booktitle> <address> (San Diego, California, </address> <month> Dec. </month> <note> 1988), </note> <author> M. A. Abrams, P. L. Haigh, </author> <title> and 41 Copyright (c) 1994 by The Association for Computing Machinery, </title> <publisher> Inc. </publisher> <editor> J. C. Comfort, Eds., </editor> <booktitle> Society for Computer Simulation, </booktitle> <pages> pp. 325-332. </pages>
Reference-contexts: Synchronization methods 4 Copyright (c) 1994 by The Association for Computing Machinery, Inc. fall into two broad categories|conservative and optimistic <ref> [28] </ref>. In conservative methods, execution of an LP is halted until it can be determined with certainty that resumed execution will not violate causality. Conservative methods are prone to deadlock [4].
Reference: [29] <author> Shin, K. G., Lin, T.-H., and Lee, Y.-H. </author> <title> Optimal checkpointing of real-time tasks. </title> <journal> IEEE Trans. on Computers 36, </journal> <volume> 11 (Nov. </volume> <year> 1987), </year> <pages> 1328-1341. </pages>
Reference-contexts: a high degree of predictiveness to limit the negative impact of aggressive cancellation can also benefit from the use of checkpoint intervals larger than one. 4.4 Comparison of Theoretical Bounds and Experimental Results Selection of the optimal checkpoint interval has been extensively studied in the context of transaction-oriented database systems <ref> [3, 8, 9, 19, 29, 30] </ref>. In the context of transaction systems, the purpose of checkpointing and rollback recovery is to improve the reliability of the 26 Copyright (c) 1994 by The Association for Computing Machinery, Inc. system in the presence of failures.

References-found: 29

