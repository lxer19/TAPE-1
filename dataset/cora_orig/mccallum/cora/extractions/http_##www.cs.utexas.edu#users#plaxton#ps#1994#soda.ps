URL: http://www.cs.utexas.edu/users/plaxton/ps/1994/soda.ps
Refering-URL: http://www.cs.utexas.edu/users/plaxton/html/abc.html
Root-URL: 
Title: Optimal Parallel Sorting in Multi-Level Storage  
Author: Alok Aggarwal C. Greg Plaxton 
Abstract: We adapt the Sharesort algorithm of Cypher and Plax-ton to run on various parallel models of multi-level storage, and analyze its resulting performance. Sharesort was originally defined in the context of sorting n records on an n-processor hypercubic network. In that context, it is not known whether Sharesort is asymptotically optimal. Nonetheless, we find that Sharesort achieves optimal time bounds for parallel sorting in multi-level storage, under a variety of models that have been defined in the literature. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Aggarwal, B. Alpern, A. K. Chandra, and M. Snir. </author> <title> A model for hierarchical memory. </title> <booktitle> In Proceedings of the 19th Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 305-314, </pages> <month> May </month> <year> 1987. </year>
Reference-contexts: In an effort to properly capture this phenomenon, a variety of sequential models of multilevel storage (often referred to as memory hierarchy models) have been proposed <ref> [1, 2, 4, 5, 13] </ref>. <p> In an effort to properly capture this phenomenon, a variety of sequential models of multilevel storage (often referred to as memory hierarchy models) have been proposed [1, 2, 4, 5, 13]. For example, one simple model assumes that accessing memory location i costs lg i units of time <ref> [1] </ref>. (More elaborate models tend to allow special block operations, or to define discontinuous access functions [2, 5].) For each particular model of multi-level storage, it is natural to analyze the complexity of routing (permuting) and sorting data. <p> We have applied the preceding mechanical strategy to determine the running time of Sharesort on several specific models of multi-level storage that have been proposed in the literature: (i) the hierarchical memory model of Aggarwal, Alpern, Chandra and Snir <ref> [1] </ref>, (ii) the hierarchical memory model with block transfer of Aggarwal, Chandra, and Snir [2], (iii) the uniform memory hierarchy model of Alpern, Carter, and Feig [5] (as well as the random-access and sequential variants of this model defined by Nodine and Vitter [18]), (iv) the parallel disk model.
Reference: [2] <author> A. Aggarwal, A. K. Chandra, and M. Snir. </author> <title> Hierarchical memory with block transfer. </title> <booktitle> In Proceedings of the 28th Annual IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pages 204-216, </pages> <month> October </month> <year> 1987. </year>
Reference-contexts: In an effort to properly capture this phenomenon, a variety of sequential models of multilevel storage (often referred to as memory hierarchy models) have been proposed <ref> [1, 2, 4, 5, 13] </ref>. <p> For example, one simple model assumes that accessing memory location i costs lg i units of time [1]. (More elaborate models tend to allow special block operations, or to define discontinuous access functions <ref> [2, 5] </ref>.) For each particular model of multi-level storage, it is natural to analyze the complexity of routing (permuting) and sorting data. The complexity of these fundamental operations is intimately related to our notion of the "power" of the model. <p> the preceding mechanical strategy to determine the running time of Sharesort on several specific models of multi-level storage that have been proposed in the literature: (i) the hierarchical memory model of Aggarwal, Alpern, Chandra and Snir [1], (ii) the hierarchical memory model with block transfer of Aggarwal, Chandra, and Snir <ref> [2] </ref>, (iii) the uniform memory hierarchy model of Alpern, Carter, and Feig [5] (as well as the random-access and sequential variants of this model defined by Nodine and Vitter [18]), (iv) the parallel disk model.
Reference: [3] <author> A. Aggarwal and C. G. Plaxton. </author> <title> Optimal parallel sorting in multi-level storage. </title> <type> Technical Report TR-93-22, </type> <institution> University of Texas at Austin, Department of Computer Science, </institution> <month> November </month> <year> 1993. </year> <note> Available via anonymous ftp from ftp.cs.utexas.edu. </note>
Reference-contexts: Constant factor issues will not be addressed. (A number of practical considerations that one should take into account in an actual Sharesort implementation are discussed in <ref> [3] </ref>.) Readers familiar with the intricacies of the Share-sort implementation on hypercubic networks [11] may be skeptical about the claim made in Section 1 that our Sharesort-based algorithms for parallel models of multilevel storage are "conceptually simple". <p> Due to space limitations, we have omitted the mechanical details associated with evaluating the running time of Sharesort on each of the aforementioned models. The reader is referred to <ref> [3] </ref> for additional details. 8 Concluding Remarks Sharesort may be useful in other parallel sorting applications where some form regularity is enforced (e.g., in an environment where BPC permutations are less expensive than arbitrary permutations).
Reference: [4] <author> A. Aggarwal and J. S. Vitter. </author> <title> The input/output complexity of sorting and related problems. </title> <journal> CACM, </journal> <volume> 31 </volume> <pages> 1116-1127, </pages> <year> 1988. </year>
Reference-contexts: In an effort to properly capture this phenomenon, a variety of sequential models of multilevel storage (often referred to as memory hierarchy models) have been proposed <ref> [1, 2, 4, 5, 13] </ref>.
Reference: [5] <author> B. Alpern, L. Carter, and E. Feig. </author> <title> Uniform memory hierarchies. </title> <booktitle> In Proceedings of the 31st Annual IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pages 600-608, </pages> <month> Octo-ber </month> <year> 1990. </year>
Reference-contexts: In an effort to properly capture this phenomenon, a variety of sequential models of multilevel storage (often referred to as memory hierarchy models) have been proposed <ref> [1, 2, 4, 5, 13] </ref>. <p> For example, one simple model assumes that accessing memory location i costs lg i units of time [1]. (More elaborate models tend to allow special block operations, or to define discontinuous access functions <ref> [2, 5] </ref>.) For each particular model of multi-level storage, it is natural to analyze the complexity of routing (permuting) and sorting data. The complexity of these fundamental operations is intimately related to our notion of the "power" of the model. <p> several specific models of multi-level storage that have been proposed in the literature: (i) the hierarchical memory model of Aggarwal, Alpern, Chandra and Snir [1], (ii) the hierarchical memory model with block transfer of Aggarwal, Chandra, and Snir [2], (iii) the uniform memory hierarchy model of Alpern, Carter, and Feig <ref> [5] </ref> (as well as the random-access and sequential variants of this model defined by Nodine and Vitter [18]), (iv) the parallel disk model. Each of these models takes one or more parameters and so actually corresponds to a family of models.
Reference: [6] <author> K. E. Batcher. </author> <title> Sorting networks and their applications. </title> <booktitle> In Proceedings of the AFIPS Spring Joint Computer Conference, </booktitle> <volume> vol. 32, </volume> <pages> pages 307-314, </pages> <year> 1968. </year>
Reference-contexts: BPC route. This operation can be performed in O (d 0 ) time [16]. 3. Merge. This operation can be performed in O (d 0 ) time by reversing one of the two lists (using a BPC route) and then applying Batcher's bitonic merge algorithm <ref> [6] </ref>. 4. Monotone route. This operation can be per formed in O (d 0 ) time [17]. 5. Prefix. This operation can be performed in O (d 0 ) time (see [15], for example). 6. Row route. <p> Hence these algorithms can be implemented by making use of the subroutines cited above. For each of the following three sorting algorithms, this approach leads to efficient hypercube implementations. 1. Bitonic sort. This sorting algorithm, due to Batcher <ref> [6] </ref>, can be expressed in terms of the assignment, BPC route, and merge operations applied to a dimension-d cube containing 2 d keys. The corresponding hypercube algorithm runs in O (d 2 ) time.
Reference: [7] <author> G. Bell. </author> <title> Ultracomputers: A teraflop before its time. </title> <journal> Communications of the ACM, </journal> <volume> 35 </volume> <pages> 26-47, </pages> <year> 1992. </year>
Reference-contexts: The coming generation of tera-computers can be expected to consist of thousands of processors, each with its own multi-gigabyte storage <ref> [7] </ref>. Thus, an extension of sequential multi-level storage models to the parallel domain would seem to be well-motivated.
Reference: [8] <author> T. H. Cormen. </author> <title> Fast permuting on disk arrays. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 17 </volume> <pages> 41-57, </pages> <year> 1993. </year>
Reference-contexts: This seems to be a natural and appropriate approach. The so-called "parallel disk model" of Vitter and Shriver [21] has also been studied by Cormen <ref> [9, 8] </ref>, who provides an extremely tight complexity analysis for certain classes of routing operations. The sorting results presented in [18, 20, 21] are quite non-trivial; each of these papers provides tight sorting bounds for the specific family of computational models that it addresses.
Reference: [9] <author> T. H. Cormen and L. F. Wisniewski. </author> <title> Asymptotically tight bounds for performing BMMC permutations on parallel disk systems. </title> <booktitle> In Proceedings of the 5th Annual ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 130-139, </pages> <month> July </month> <year> 1993. </year>
Reference-contexts: This seems to be a natural and appropriate approach. The so-called "parallel disk model" of Vitter and Shriver [21] has also been studied by Cormen <ref> [9, 8] </ref>, who provides an extremely tight complexity analysis for certain classes of routing operations. The sorting results presented in [18, 20, 21] are quite non-trivial; each of these papers provides tight sorting bounds for the specific family of computational models that it addresses.
Reference: [10] <author> R. E. Cypher and C. G. Plaxton. </author> <title> Techniques for shared key sorting. </title> <type> Technical Report RJ 7347, </type> <institution> Computer Science Department, IBM Almaden Research Center, </institution> <month> March </month> <year> 1990. </year>
Reference-contexts: key sorting operation of Cypher and Plaxton [11]. (This claim follows from the optimal O (d 0 ) complexity of sparse enumeration sort, discussed below.) If exponential preprocessing time (to compute certain tables used by the algorithm) is allowed, an optimal O (d 0 ) running time can be achieved <ref> [10] </ref>. With polynomial preprocessing, O (d 0 lg fl d 0 ) is achievable [10]. With 4 no preprocessing, O (d 0 lg d 0 ) is currently the best bound known [11]. A number of sorting algorithms that have been proposed in the literature belong to the family A. <p> O (d 0 ) complexity of sparse enumeration sort, discussed below.) If exponential preprocessing time (to compute certain tables used by the algorithm) is allowed, an optimal O (d 0 ) running time can be achieved <ref> [10] </ref>. With polynomial preprocessing, O (d 0 lg fl d 0 ) is achievable [10]. With 4 no preprocessing, O (d 0 lg d 0 ) is currently the best bound known [11]. A number of sorting algorithms that have been proposed in the literature belong to the family A. Hence these algorithms can be implemented by making use of the subroutines cited above.
Reference: [11] <author> R. E. Cypher and C. G. Plaxton. </author> <title> Deterministic sorting in nearly logarithmic time on the hypercube and related computers. </title> <journal> JCSS, </journal> <volume> 47 </volume> <pages> 501-548, </pages> <year> 1993. </year>
Reference-contexts: Balance Sort is a deterministic sorting scheme that leads to optimal or best-known complexity bounds for virtually all parallel models of multi-level storage yet proposed. The main result of our paper is that the deterministic Sharesort algorithm of Cypher and Plaxton <ref> [11] </ref>, originally designed as a one-item-per-processor sorting algorithm for hypercubic networks, is readily adaptable to all known parallel models of multi-level storage, where in all cases it matches the asymptotic performance of Balance Sort. (In fact, in limited cases Sharesort provides technical improvements over Balance Sort by requiring a less powerful <p> Constant factor issues will not be addressed. (A number of practical considerations that one should take into account in an actual Sharesort implementation are discussed in [3].) Readers familiar with the intricacies of the Share-sort implementation on hypercubic networks <ref> [11] </ref> may be skeptical about the claim made in Section 1 that our Sharesort-based algorithms for parallel models of multilevel storage are "conceptually simple". <p> Row routing is not really a new operation either, as it is a minor variant of the shared key sorting operation used within the Sharesort algorithm of Cypher and Plaxton <ref> [11] </ref>. The set of six basic operations stated below may seem to have been somewhat arbitrarily chosen. <p> Prefix. This operation can be performed in O (d 0 ) time (see [15], for example). 6. Row route. The asymptotic complexity of this operation is known to be the same (to within a constant factor) as that of the shared key sorting operation of Cypher and Plaxton <ref> [11] </ref>. (This claim follows from the optimal O (d 0 ) complexity of sparse enumeration sort, discussed below.) If exponential preprocessing time (to compute certain tables used by the algorithm) is allowed, an optimal O (d 0 ) running time can be achieved [10]. <p> With polynomial preprocessing, O (d 0 lg fl d 0 ) is achievable [10]. With 4 no preprocessing, O (d 0 lg d 0 ) is currently the best bound known <ref> [11] </ref>. A number of sorting algorithms that have been proposed in the literature belong to the family A. Hence these algorithms can be implemented by making use of the subroutines cited above. For each of the following three sorting algorithms, this approach leads to efficient hypercube implementations. 1. Bitonic sort. <p> Upon termination, the key with rank i (ties can be broken in a stable fashion) is stored in processor i, 0 i &lt; 2 fld . 3. Sharesort. This algorithm, due to Cypher and Plaxton <ref> [11] </ref>, can be expressed in terms of the assignment, BPC route, merge, monotone route, prefix, and row route operations applied to a constant number of dimension-d cubes, one of which initially contains the set of 2 d input keys. (Sharesort also makes use of bitonic sort and sparse enumeration sort, but
Reference: [12] <author> R. E. Cypher and J. L. C. Sanz. Cubesort: </author> <title> A parallel algorithm for sorting N data items with S-sorters. </title> <journal> Journal of Algorithms, </journal> <volume> 13 </volume> <pages> 211-234, </pages> <year> 1992. </year>
Reference-contexts: The algorithm must produce the sorted output in the same par-cube C. 6.1 Cubesort If a = O (b) (i.e., if the number of keys is bounded by some polynomial in the number of processors) then Cubesort <ref> [12] </ref> provides a simple method for obtaining an efficient sorting algorithm. (Leighton's column sort [14] could also be used to obtain the bounds that follow. We prefer to make use of Cubesort only because the permutations performed by Cubesort can be implemented as BPC routes, one of our basic operations.
Reference: [13] <author> R. W. Floyd. </author> <title> Permuting information in idealized two-level storage. </title> <editor> In R. E. Miller and J. W. Thatcher, editors, </editor> <booktitle> Complexity of Computer Computations, </booktitle> <pages> pages 105-109. </pages> <publisher> Plenum Press, </publisher> <address> New York, </address> <year> 1972. </year>
Reference-contexts: In an effort to properly capture this phenomenon, a variety of sequential models of multilevel storage (often referred to as memory hierarchy models) have been proposed <ref> [1, 2, 4, 5, 13] </ref>.
Reference: [14] <author> F. T. Leighton. </author> <title> Tight bounds on the complexity of parallel sorting. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-34:344-354, </volume> <year> 1985. </year>
Reference-contexts: Such networks are known to exist <ref> [14] </ref>. Although the preceding paragraph gives a complete description of the model G, it will be useful to introduce some additional terminology. First, let us arbitrarily partition the p processors into c sh par-groups (parallel groups) of size 2 b . <p> algorithm must produce the sorted output in the same par-cube C. 6.1 Cubesort If a = O (b) (i.e., if the number of keys is bounded by some polynomial in the number of processors) then Cubesort [12] provides a simple method for obtaining an efficient sorting algorithm. (Leighton's column sort <ref> [14] </ref> could also be used to obtain the bounds that follow. We prefer to make use of Cubesort only because the permutations performed by Cubesort can be implemented as BPC routes, one of our basic operations.
Reference: [15] <author> F. T. Leighton. </author> <title> Introduction to Parallel Algorithms and Architectures: Arrays, Trees, and Hypercubes. </title> <publisher> Morgan-Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1991. </year>
Reference-contexts: Monotone route. This operation can be per formed in O (d 0 ) time [17]. 5. Prefix. This operation can be performed in O (d 0 ) time (see <ref> [15] </ref>, for example). 6. Row route.
Reference: [16] <author> D. Nassimi and S. Sahni. </author> <title> A self routing Benes network and parallel permutation algorithms. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-30:332-340, </volume> <year> 1981. </year>
Reference-contexts: Assignment. An assignment operation requires only O (1) time, as it can be implemented with a constant number of local operations at each processor (no inter-processor communication is required). 2. BPC route. This operation can be performed in O (d 0 ) time <ref> [16] </ref>. 3. Merge. This operation can be performed in O (d 0 ) time by reversing one of the two lists (using a BPC route) and then applying Batcher's bitonic merge algorithm [6]. 4. Monotone route. This operation can be per formed in O (d 0 ) time [17]. 5.
Reference: [17] <author> D. Nassimi and S. Sahni. </author> <title> Parallel permutation and sorting algorithms and a new generalized connection network. </title> <journal> JACM, </journal> <volume> 29 </volume> <pages> 642-667, </pages> <year> 1982. </year>
Reference-contexts: Merge. This operation can be performed in O (d 0 ) time by reversing one of the two lists (using a BPC route) and then applying Batcher's bitonic merge algorithm [6]. 4. Monotone route. This operation can be per formed in O (d 0 ) time <ref> [17] </ref>. 5. Prefix. This operation can be performed in O (d 0 ) time (see [15], for example). 6. Row route. <p> Sparse enumeration sort. This algorithm, due to Nassimi and Sahni <ref> [17] </ref>, can be expressed in terms of the assignment, BPC route, merge, monotone route, and prefix operations applied to a constant number of dimension-d cubes, one of which initially contains the set of input keys.
Reference: [18] <author> M. H. Nodine and J. S. Vitter. </author> <title> Large-scale sorting in parallel memories. </title> <booktitle> In Proceedings of the 3rd Annual ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 29-39, </pages> <month> July </month> <year> 1991. </year>
Reference-contexts: The coming generation of tera-computers can be expected to consist of thousands of processors, each with its own multi-gigabyte storage [7]. Thus, an extension of sequential multi-level storage models to the parallel domain would seem to be well-motivated. In fact, Vitter and Shriver [21], Nodine and Vitter <ref> [18] </ref>, and Vitter and No-dine [20] have proposed just such a series of extensions, and have examined the complexity of sorting in various parallel models of multi-level storage. <p> This seems to be a natural and appropriate approach. The so-called "parallel disk model" of Vitter and Shriver [21] has also been studied by Cormen [9, 8], who provides an extremely tight complexity analysis for certain classes of routing operations. The sorting results presented in <ref> [18, 20, 21] </ref> are quite non-trivial; each of these papers provides tight sorting bounds for the specific family of computational models that it addresses. <p> model of Aggarwal, Alpern, Chandra and Snir [1], (ii) the hierarchical memory model with block transfer of Aggarwal, Chandra, and Snir [2], (iii) the uniform memory hierarchy model of Alpern, Carter, and Feig [5] (as well as the random-access and sequential variants of this model defined by Nodine and Vitter <ref> [18] </ref>), (iv) the parallel disk model. Each of these models takes one or more parameters and so actually corresponds to a family of models. We have evaluated the running time of Share-sort for all parameter settings that have been considered in previous papers.
Reference: [19] <author> M. H. Nodine and J. S. Vitter. </author> <title> Deterministic distibution sort in shared and distributed memory multiprocessors. </title> <booktitle> In Proceedings of the 5th Annual ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 120-129, </pages> <month> July </month> <year> 1993. </year>
Reference-contexts: However, until recently, no single algorithm (or single paradigm) was known that could be used to obtain optimal time bounds for sorting on all models in these families. The question of existence of such an algorithm was largely resolved by the recent Balance Sort algorithm of Nodine and Vitter <ref> [19] </ref>. Balance Sort is a deterministic sorting scheme that leads to optimal or best-known complexity bounds for virtually all parallel models of multi-level storage yet proposed.
Reference: [20] <author> J. S. Vitter and M. H. Nodine. </author> <title> Large-scale sorting in uniform memory hierarchies. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 17 </volume> <pages> 41-57, </pages> <year> 1993. </year>
Reference-contexts: Thus, an extension of sequential multi-level storage models to the parallel domain would seem to be well-motivated. In fact, Vitter and Shriver [21], Nodine and Vitter [18], and Vitter and No-dine <ref> [20] </ref> have proposed just such a series of extensions, and have examined the complexity of sorting in various parallel models of multi-level storage. <p> This seems to be a natural and appropriate approach. The so-called "parallel disk model" of Vitter and Shriver [21] has also been studied by Cormen [9, 8], who provides an extremely tight complexity analysis for certain classes of routing operations. The sorting results presented in <ref> [18, 20, 21] </ref> are quite non-trivial; each of these papers provides tight sorting bounds for the specific family of computational models that it addresses.
Reference: [21] <author> J. S. Vitter and E. A. M. Shriver. </author> <title> Optimal disk I/O with parallel block transfer. </title> <booktitle> In Proceedings of the 22nd Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 159-169, </pages> <month> May </month> <year> 1990. </year> <note> To appear in Algorithmica. 10 </note>
Reference-contexts: The coming generation of tera-computers can be expected to consist of thousands of processors, each with its own multi-gigabyte storage [7]. Thus, an extension of sequential multi-level storage models to the parallel domain would seem to be well-motivated. In fact, Vitter and Shriver <ref> [21] </ref>, Nodine and Vitter [18], and Vitter and No-dine [20] have proposed just such a series of extensions, and have examined the complexity of sorting in various parallel models of multi-level storage. <p> This seems to be a natural and appropriate approach. The so-called "parallel disk model" of Vitter and Shriver <ref> [21] </ref> has also been studied by Cormen [9, 8], who provides an extremely tight complexity analysis for certain classes of routing operations. <p> This seems to be a natural and appropriate approach. The so-called "parallel disk model" of Vitter and Shriver [21] has also been studied by Cormen [9, 8], who provides an extremely tight complexity analysis for certain classes of routing operations. The sorting results presented in <ref> [18, 20, 21] </ref> are quite non-trivial; each of these papers provides tight sorting bounds for the specific family of computational models that it addresses.
References-found: 21

