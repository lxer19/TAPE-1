URL: http://www.cs.nyu.edu/cs/projects/proteus/sekine/papers/thesis_publish.ps.gz
Refering-URL: http://www.cs.nyu.edu/cs/projects/proteus/sekine/index.html
Root-URL: http://www.cs.nyu.edu
Title: Corpus-based Parsing and Sublanguage Studies  
Author: by Satoshi Sekine 
Degree: A dissertation submitted in partial fulfillment of the requirements for the degree of Doctor of Philosophy  
Date: May 1998  
Address: New York University  
Affiliation: Computer Science Department  
Abstract-found: 0
Intro-found: 0
Reference: [Biber 93] <author> Douglas Biber: </author> <title> "Using Register-Diversified Corpora for General Language Studies" Journal of Computer Linguistics Vol.19, </title> <type> Num 2, </type> <institution> pp219-241. </institution> <year> (1993) </year>
Reference-contexts: Most of them claim that the notion is important in processing natural language text, owning to lexical, syntactic or semantic restrictions, etc. A number of these studies have analyzed actual texts to try to verify the claim [Kittredge 82] [Grishman and Kittredge 86] [Slocum 86] <ref> [Biber 93] </ref>. Some of these studies and the definition of `sublanguage' will be discussed in Section 3.2. Several successful natural language processing systems have explicitly or implicitly addressed the sublanguage restrictions. <p> The brochure texts exhibited more syntactic phenomena than manual texts, although manual texts were not simply a subset of the other. The experiments suggest the possibilities of sublanguage identification and further the possibilities of sublanguage specific processing in order to maximize the performance of systems. Biber <ref> [Biber 93] </ref> referred to the sublanguages as `registers'. First, he compared the part-of-speech tags of grammatically ambiguous words between two different registers: fiction and exposition. Some examples are shown in Table 3.1.
Reference: [Black et al. 91] <author> E.Black, S.Abney, D Flickenger, C.Gdaniec, R.Grishman, P.Harrison, D.Hindle, R.Ingria, F.Jelinek, J.Klavans, M.Liberman, M.Marcus, S.Roukos, B.Santorini, T.Strzalkowski: </author> <title> "A Procedure for Quantitatively Comparing the Syntactic Coverage of English Grammars" Proceedings of the 4th DARPA Speech and Natural Language Workshop (1991) </title>
Reference-contexts: It is natural that the number of sentences which exhaust memory is larger for G-0 than for G-2, because of the larger number of rules. Next, the evaluation using Parseval method on parsed sentences is shown in Table 2.6. "Parseval" is the measurement of parsed result proposed by <ref> [Black et al. 91] </ref>. The result in the table is the result achieved by the G-0 grammar, supplemented by the result using the G-2 grammar, if the larger grammar can't generate a parse tree. <p> The grammars are trained on the PennTreeBank sections 02 - 21, and tested on section 23. The accuracy measure is slightly different from the accuracy measure used in the previous section. In the previous section, the Parseval method <ref> [Black et al. 91] </ref> was used. In that measure, multiple layers of unary trees are collapsed to a single layer of unary tree. Also, the labeling is not considered in the matching 5 .
Reference: [Black et al. 93] <author> Ezra Black, Fred Jelinek, John Lafferty, David Magerman, Robert Mercer and Salim Roukos: </author> <title> "Towards History-Based Grammars: </title> <booktitle> Using Richer Models for Probabilistic Parsing" Proceedings of the 31st Annual Meeting of the Association for Computational Linguistics (ACL) (1993) </booktitle>
Reference-contexts: Furthermore, experiments over the past few years have shown the benefits of using probabilistic information in parsing, and the large corpus allows us to train the probabilities of a grammar [Fujisaki 84] [Garside and Leech 85] [Chitrao and Grishman 90] [Magerman and Weir 92] <ref> [Black et al. 93] </ref> [Bod 93] [Magerman 95] [Collins 96]. A number of recent parsing experiments have also indicated that grammars whose production probabilities are dependent on the context can be more effective than context-free grammars in selecting a correct parse. <p> There have been several attempts to build context-dependent grammars based on large corpora [Chitrao and Grishman 90] [Simmons and Yu 91] [Magerman and Weir 92] [Schabes and Waters 93] <ref> [Black et al. 93] </ref> [Bod 93] [Magerman 95]. As is evident from the two lists of citations, there has been considerable research involving both probabilistic grammar based on syntactically-bracketed corpora and context-sensitivity. Some of these will be explained in the next section. <p> In other words, these are completely supervised methods. Some of them use the Wall Street Journal text of the PennTreeBank which will also be used in the experiments of this thesis. A group at IBM <ref> [Black et al. 93] </ref> built a parser which used context information, including the dominating production and the syntactic and semantic categories of words in the prior derivation.
Reference: [Black 93] <editor> Ezra Black "Parsing English By Computer: </editor> <booktitle> The State Of the Art" Proceedings of the ATR International Workshop on Speech Translation (1993) </booktitle>
Reference-contexts: Note that they used lexical information, while the parser described in this section uses almost no lexical information. Compared to so-called traditional, or hand-made grammars, roughly speaking, the performance is similar or better. For example, Black <ref> [Black 93] </ref> cited the best non-crossing score using traditional grammars as 41% and the average of several systems as 22%. 2.5 Five Non-terminal Grammar In the framework of the parser explained in the previous section, the two non-terminals were selected based on intuition.
Reference: [Bod 92] <institution> Rens Bod "Data Oriented Parsing (DOP)" Proceedings of the 14th Conference on Computational Linguistics (COLING) (1992) </institution>
Reference-contexts: The performance of the parser was outstanding. Its precision and recall for the sentences shorter than 40 words were 86.3% and 85.8%, respectively. This was the first parser to approach the current state-of-the-art performance on the task of parsing Wall Street Journal sentences. 10 2.2.6 Data Oriented Parsing Bod <ref> [Bod 92] </ref> [Bod 95] [Bod and Scha 96] explored the idea of Data Oriented Parsing. In this framework, all possible tree fragments in a hand annotated corpus are regarded as rules of a probabilistic grammar.
Reference: [Bod 93] <institution> Rens Bod "Using an Annotated Corpus as a Stochastic Grammar" Proceedings of the 6th Conference of the European Chapter of the Association for Computational Linguistics (EACL) (1993) </institution>
Reference-contexts: Furthermore, experiments over the past few years have shown the benefits of using probabilistic information in parsing, and the large corpus allows us to train the probabilities of a grammar [Fujisaki 84] [Garside and Leech 85] [Chitrao and Grishman 90] [Magerman and Weir 92] [Black et al. 93] <ref> [Bod 93] </ref> [Magerman 95] [Collins 96]. A number of recent parsing experiments have also indicated that grammars whose production probabilities are dependent on the context can be more effective than context-free grammars in selecting a correct parse. <p> There have been several attempts to build context-dependent grammars based on large corpora [Chitrao and Grishman 90] [Simmons and Yu 91] [Magerman and Weir 92] [Schabes and Waters 93] [Black et al. 93] <ref> [Bod 93] </ref> [Magerman 95]. As is evident from the two lists of citations, there has been considerable research involving both probabilistic grammar based on syntactically-bracketed corpora and context-sensitivity. Some of these will be explained in the next section.
Reference: [Bod 95] <editor> Rens Bod "Enriching Linguistics with Statistics: </editor> <booktitle> Performance Models of Natural Language" Doctoral thesis, </booktitle> <publisher> Universiteit van Amsterdam (1995) </publisher>
Reference-contexts: Its precision and recall for the sentences shorter than 40 words were 86.3% and 85.8%, respectively. This was the first parser to approach the current state-of-the-art performance on the task of parsing Wall Street Journal sentences. 10 2.2.6 Data Oriented Parsing Bod [Bod 92] <ref> [Bod 95] </ref> [Bod and Scha 96] explored the idea of Data Oriented Parsing. In this framework, all possible tree fragments in a hand annotated corpus are regarded as rules of a probabilistic grammar.
Reference: [Bod and Scha 96] <editor> Rens Bod and Remko Scha "Data-Oriented Language Processing: </editor> <title> An Overview" ftp://ftp.fwi.uva.nl/pub/theory/illc/researchreports/LP-96-13.text.ps.gz (1996) </title>
Reference-contexts: The parser and the evaluation program are available as public domain software from 2 [Sekine 96a] and [Sekine and Collins 97]. Also, the work was referenced in a book [Young and Bloothooft 97] and in a review <ref> [Bod and Scha 96] </ref>. Chapter 3 describes a study of the sublanguage notion based on corpora. First, statistical measures are used to find sublanguage from newspaper articles. Then multi-domain corpora are used for a study of sublanguage features in terms of lexical and syntactic characteristics. <p> Its precision and recall for the sentences shorter than 40 words were 86.3% and 85.8%, respectively. This was the first parser to approach the current state-of-the-art performance on the task of parsing Wall Street Journal sentences. 10 2.2.6 Data Oriented Parsing Bod [Bod 92] [Bod 95] <ref> [Bod and Scha 96] </ref> explored the idea of Data Oriented Parsing. In this framework, all possible tree fragments in a hand annotated corpus are regarded as rules of a probabilistic grammar.
Reference: [Brill et al. 90] <author> Eric Brill, David Magerman, </author> <title> Mitchell Marcus and Beatrice San-torini "Deducting Linguistic Structure from the Statistics of Large Corpora" Proceeding of the June DARPA Speech and Natural Language workshop. </title> <address> Hidden Valley, Pennsylvania. </address> <year> (1990) </year> <month> 129 </month>
Reference: [Brill 93] <editor> Eric Brill "Automatic Grammar Induction and Parsing Free Text: </editor> <booktitle> A Transformation-Based Approach" Proceedings of the 31st Annual Meeting of the Association for Computational Linguistics (ACL) (1993) </booktitle>
Reference: [Briscoe and Carroll 93] <institution> Ted Briscoe and John Carroll "Generalized Probabilistic LR Parsing of Natural Language (Corpora) with Unification-Based Grammars" Journal of Computational Linguistics Vol.19,No.1 (1993) </institution>
Reference-contexts: It produced a parse tree for 38 input sentences and 35 of them were equivalent to the correct parse tree produced by the augmented version of PUNDIT. They concluded that comparable performance was achieved without the painfully hand-crafted augmentation of the grammar. Briscoe and Carroll <ref> [Briscoe and Carroll 93] </ref> created a probabilistic LR parser with a unification-based grammar. As states of the LR table are related to the parse context, it becomes a context sensitive probabilistic model if the probability is calculated directly from the corpus, instead of derived from probabilistic CFG rules.
Reference: [Bross et al. 72] <author> I D J Bross and P A Shapiro and B B Anderson: </author> <title> "How information is carried in scientific sub-languages" Science", </title> <address> Vol.176, </address> <month> 1303-1307 </month> <year> (1972) </year>
Reference-contexts: From this definition, we can infer that a sublanguage can be defined empirically by observing language behavior. The other type of definition is exemplified by the following citation from Bross, Shapio and Anderson <ref> [Bross et al. 72] </ref>: Informally, we can define a sublanguage as the language used by a particular community of speakers, say, those concerned with a particular subject matter or those engaged in a specialized occupation.
Reference: [Carroll and Briscoe 96] <author> John Carroll and Ted Briscoe: </author> <title> "Apportioning development effort in a probabilistic LR parsing system through evaluation" Proceedings of the Conference on Empirical Methods in Natural Language Processing. </title> <year> (1996) </year>
Reference-contexts: When we try to parse a text in a particular domain, we should prepare a grammar which suits that domain. This idea naturally contrasts with the idea of robust broad-coverage parsing <ref> [Carroll and Briscoe 96] </ref>, in which a single grammar should be prepared for parsing any kind of text.
Reference: [Charniak 93] <author> Eugene Charniak: </author> <title> Statistical Language Learning The MIT Press (1993) </title>
Reference-contexts: There are several good textbook in natural language processing, for example, [Grishman 86]. Anyone who wants to know the basics of statistics used in this thesis should refer to <ref> [Charniak 93] </ref> or [Krenn and Samuelsson 97]. Chapter 2 describes a probabilistic parser whose grammar is obtained from a syntactically tagged corpus. The distinguishing characteristic of the grammar is that it has only a small number of non-terminals. Both a two non-terminal grammar and five non-terminal grammar will be described. <p> They use a hand crafted grammar as the base of the experiment. The core idea of the probability estimation is iterative training. The inside-outside algorithm, which is motivated by the forward-backward algorithm, was used to reduce the expensive computation. For an explanation of the inside-outside algorithm, see for example <ref> [Charniak 93] </ref>; only the iterative training will be explained here. The algorithm tried to assign a probability for each grammar rule, say P i (r j ) is the probability of rule r j after the i-th iteration. Each grammar rule has an initial probability P 0 (r). <p> This looks appealing, but as was described in <ref> [Charniak 93] </ref> there is a local minimum problem. Charniak reported an experiment with the inside-outside algorithm using a grammar of all possible fixed length rules. In the experiment, 300 different randomly-set initial probabilities were assigned for the grammar, and 300 different final sets of probabilities were generated by the algorithm. <p> This problem is the crucial issue for automatic sublanguage definition, because otherwise we need manual intervention or artificial thresholds. In order to explore this problem, the following statistics are proposed. Perplexity, more precisely `uni-gram perplexity' (P P ) is a notion from Information Theory (see <ref> [Charniak 93] </ref> or [Krenn and Samuelsson 97]). It can be formally defined based on unigram Entropy H: H = w P P = 2 (3.2) Here p (w) is the probability of a token w in the source. <p> CE (T; M ) = i The smaller the value, the more accurately the model represents the test set. If the model is identical to the test set, the value is equal to the entropy of the set itself (see <ref> [Charniak 93] </ref> for details). For each pair of the distributions, cross entropy is computed by taking the distribution as the probability. Figure 3.3 shows the cross entropy of syntactic structure across domains.
Reference: [Charniak 97] <author> Eugene Charniak: </author> <booktitle> "Statistical Parsing with a Context-free Grammar and Word Statistics" Proceedings of the 14th National Conference on Artificial Inteligence (1997) </booktitle>
Reference-contexts: Also [Ratnaparkhi 97] proposed a parser using similar information based on maximum entropy model. The parsing strategy is unique and it can generate multiple trees in linear observed time. The performance is 87.5% and 86.3% of recall and precision. <ref> [Charniak 97] </ref> reported a parser based on similar framework. 2.2.8 Explanation-based Learning This is an interesting framework for constructing grammars which is closely related to the framework presented in this thesis. <p> We can see that the lexical dependency information improves about 2% in recall and 1.5% in precision. This is an encouraging result for pursuing this line of the experiment. 2.8.5 Future Direction This is currently a very active research area in corpus based parsing. Recently, in [Collins 97] <ref> [Charniak 97] </ref> [Ratnaparkhi 97], very good parsing performances are reported using lexical dependencies on statistical parsers. The dependency information they used is relatively richer than that used in this experiment.
Reference: [Chitrao and Grishman 90] <author> Mahesh Chitrao, Ralph Grishman: </author> <title> "Statistical Parsing of Message" Proceeding of the June DARPA Speech and Natural Language workshop. </title> <address> Hidden Valley, Pennsylvania. </address> <year> (1990) </year>
Reference-contexts: Furthermore, experiments over the past few years have shown the benefits of using probabilistic information in parsing, and the large corpus allows us to train the probabilities of a grammar [Fujisaki 84] [Garside and Leech 85] <ref> [Chitrao and Grishman 90] </ref> [Magerman and Weir 92] [Black et al. 93] [Bod 93] [Magerman 95] [Collins 96]. A number of recent parsing experiments have also indicated that grammars whose production probabilities are dependent on the context can be more effective than context-free grammars in selecting a correct parse. <p> This context sensitivity can be acquired easily using a large corpus, whereas human ability to compute such information is obviously limited. There have been several attempts to build context-dependent grammars based on large corpora <ref> [Chitrao and Grishman 90] </ref> [Simmons and Yu 91] [Magerman and Weir 92] [Schabes and Waters 93] [Black et al. 93] [Bod 93] [Magerman 95]. As is evident from the two lists of citations, there has been considerable research involving both probabilistic grammar based on syntactically-bracketed corpora and context-sensitivity. <p> This demonstrates the importance of annotated training data. 2.2.2 Context Sensitive Parsing The previous parsers used the pure context free grammar formalism. The method described here tried to use context sensitivity in parsing. Chitrao and Grishman <ref> [Chitrao and Grishman 90] </ref>, [Chitrao 90] used the iterative processing using an unannotated corpus based on a hand crafted grammar. They used an unannotated corpus just like the Fujisaki's experiment.
Reference: [Chitrao 90] <institution> Mahesh Chitrao "Statistical Techniques for Parsing Messages" Doctoral thesis, </institution> <note> New York University (1990) [CL Special Issue I 93] "Special Issue on Using Large Corpora: I" Journal of Computational Linguistics Vol.19,Num.1 (1993) [CL Special Issue II 93] "Special Issue on Using Large Corpora: II" Journal of Computational Linguistics Vol.19,Num.2 (1993) </note>
Reference-contexts: This demonstrates the importance of annotated training data. 2.2.2 Context Sensitive Parsing The previous parsers used the pure context free grammar formalism. The method described here tried to use context sensitivity in parsing. Chitrao and Grishman [Chitrao and Grishman 90], <ref> [Chitrao 90] </ref> used the iterative processing using an unannotated corpus based on a hand crafted grammar. They used an unannotated corpus just like the Fujisaki's experiment. The specialties of the method were `fine grained statistics' and `heuristic penalties'. `Fine grained statistics' tried to capture some context sensitivities.
Reference: [Collins 96] <institution> Michael Collins "A New Statistical Parser Based on Bigram Lexical Dependencies" Proceedings of the 34th Annual Meeting of the Association for Computational Linguistics (ACL) (1996) </institution>
Reference-contexts: over the past few years have shown the benefits of using probabilistic information in parsing, and the large corpus allows us to train the probabilities of a grammar [Fujisaki 84] [Garside and Leech 85] [Chitrao and Grishman 90] [Magerman and Weir 92] [Black et al. 93] [Bod 93] [Magerman 95] <ref> [Collins 96] </ref>. A number of recent parsing experiments have also indicated that grammars whose production probabilities are dependent on the context can be more effective than context-free grammars in selecting a correct parse. <p> However, as they extracted all possible tree fragments, the number of possible derivations becomes enormous, so some technique to overcome the problem is needed [Sima'an 97]. 2.2.7 Parsing by Lexical Dependency This is another state-of-the-art parser, proposed by Collins <ref> [Collins 96] </ref>. It used an annotated corpus, Wall Street Journal of the PennTreeBank, like the method by Magerman. The difference is that this method heavily relies on the lexical information or lexical dependencies rather than context information. <p> The head is going to be the head of all dependencies to the other elements in the constituent. It is defined by heuristic rules introduced by [Magerman 95] and <ref> [Collins 96] </ref>. For example, in order to find the head of a prepositional phrase, the elements in the phrase are scanned from left to right, and the first preposition encountered in the scan is the head of the phrase. <p> If no item in the table is found, then the left or right-most item will be the head of the constituent. Appendix B shows the rules. This table is created based on the previous work by [Magerman 95] and <ref> [Collins 96] </ref>. 2.8.3 Acquire Data from Corpus From 96% of the PennTreeBank corpus (section 00, 01 and 03-24), 1,034,914 dependency relationships for 32,012 distinct head words are extracted. The dependency direction, i.e. if the argument is to the left or right of the head, is also recorded.
Reference: [Collins 97] <editor> Michael Collins "Three Generative, </editor> <booktitle> Lexicalised Models for Statistical Parsing" Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics (ACL) (1997) </booktitle>
Reference-contexts: The performance is comparable to the parser by Magerman. Its best labeled-recall was 85.3% and labeled-precision was 85.7%. The interesting comparative experiment reported was that if it ignores the lexical information but uses only parts-of-speech information, the performance decrease significantly to 76.1% recall and 76.6% precision. Recently <ref> [Collins 97] </ref> reported a new version of the parser. It includes a generative model of lexicalized context-free grammar and a probabilistic treatment of both subcategorization and wh-movement. The recall and precision of the new parser are 88.1% and 87.5%. <p> We can see that the lexical dependency information improves about 2% in recall and 1.5% in precision. This is an encouraging result for pursuing this line of the experiment. 2.8.5 Future Direction This is currently a very active research area in corpus based parsing. Recently, in <ref> [Collins 97] </ref> [Charniak 97] [Ratnaparkhi 97], very good parsing performances are reported using lexical dependencies on statistical parsers. The dependency information they used is relatively richer than that used in this experiment.
Reference: [Cormen et.al 90] <author> Thomas Cormen, Charles Leiserson and Ronald Rivest: </author> <title> Introduction to Algorithms The MIT Press (1990) 130 </title>
Reference-contexts: The time complexity of heap operations is logarithmic in the number of data in the heap. (The reader who is interested may find details in <ref> [Cormen et.al 90] </ref>).
Reference: [Francis and Kucera 64/79] <author> W. Nelson Francis and Henry Kucera: </author> <title> "Manual of in-formation to accompany A Standard Corpus of Present-Day Edited American English for use with Digital Computers" Brown University, </title> <institution> Department of Linguistics (1964/1979) </institution>
Reference-contexts: There are only 68 words which have frequencies over 1000. (The total number of distinct words is 39217 and the total number of articles is 2147). 3.4 Brown Corpus In the experiments in the remainder of the chapter and in the next chapter, the Brown corpus <ref> [Francis and Kucera 64/79] </ref> will be used. A brief review of the Brown corpus will be presented in this section. It is a syntactically tagged corpus consisting of several domains. One of the important features is that the way of tagging is uniform throughout the corpus.
Reference: [Fujisaki 84] <author> Tetsunosuke Fujisaki: </author> <booktitle> "A Stochastic Approach to Sentence Parsing" Proceedings of the 10th Conference on Computational Linguistics (COLING) (1984) </booktitle>
Reference-contexts: Furthermore, experiments over the past few years have shown the benefits of using probabilistic information in parsing, and the large corpus allows us to train the probabilities of a grammar <ref> [Fujisaki 84] </ref> [Garside and Leech 85] [Chitrao and Grishman 90] [Magerman and Weir 92] [Black et al. 93] [Bod 93] [Magerman 95] [Collins 96]. <p> The third column indicates if it uses lexical information. In the last row, the method proposed in this thesis is explained. It emphasizes context sensitivity and tries it with and without lexical information. 2.2.1 Iterative Learning Algorithm One of the earliest experiments on corpus-based parsing was conducted by Fujisaki <ref> [Fujisaki 84] </ref> [Fujisaki et al. 89]. It involved probabilities of pure CFG rules computed from an unannotated corpus using the inside-outside algorithm and unsupervised iterative training. They use a hand crafted grammar as the base of the experiment. The core idea of the probability estimation is iterative training.
Reference: [Fujisaki et al. 89] <author> Tetsunosuke Fujisaki, Fred Jelinek, J.Cocke, Ezra Black and T.Nishino: </author> <booktitle> "Probabilistic Parsing Method for Sentence Disambiguation" Proceedings of 1st International Workshop on Parsing Technologies (1989) </booktitle>
Reference-contexts: In the last row, the method proposed in this thesis is explained. It emphasizes context sensitivity and tries it with and without lexical information. 2.2.1 Iterative Learning Algorithm One of the earliest experiments on corpus-based parsing was conducted by Fujisaki [Fujisaki 84] <ref> [Fujisaki et al. 89] </ref>. It involved probabilities of pure CFG rules computed from an unannotated corpus using the inside-outside algorithm and unsupervised iterative training. They use a hand crafted grammar as the base of the experiment. The core idea of the probability estimation is iterative training.
Reference: [Fujio and Matsumoto 97] <author> Masakazu Fujio and Yuji Matsumoto: </author> <title> "Statistic Based Dependency Analysis" Natural Language group Information Processing Society of Japan (In Japanese) (1997) </title>
Reference-contexts: It has been well discussed that, in Japanese, lexical relationships are the most crucial information for analyzing syntactic structures, and there are probabilistic corpus based parser which use lexical information (for example, <ref> [Fujio and Matsumoto 97] </ref> [Shirai et al. 97]).
Reference: [Garside and Leech 85] <editor> Roger Garside, Fanny Leech: </editor> <booktitle> "A Probabilistic Parser" Proceedings of the 2nd Conference of the European Chapter of the Association for Computational Linguistics (EACL) (1985) </booktitle>
Reference-contexts: Furthermore, experiments over the past few years have shown the benefits of using probabilistic information in parsing, and the large corpus allows us to train the probabilities of a grammar [Fujisaki 84] <ref> [Garside and Leech 85] </ref> [Chitrao and Grishman 90] [Magerman and Weir 92] [Black et al. 93] [Bod 93] [Magerman 95] [Collins 96].
Reference: [Gnanadesikan 77] <author> R.Gnanadesikan: </author> <title> Methods for Statistical Data Analysis of Mul-tivariate Observations John Wiley & Sons, </title> <publisher> Inc (1977) </publisher>
Reference-contexts: M 8.58 8.36 8.34 8.26 8.68 8.53 8.76 8.81 8.98 8.17 8.18 6.67 8.16 8.26 7.98 P 8.39 8.26 8.24 8.21 8.47 8.31 8.36 8.90 8.90 7.84 7.86 7.77 7.92 6.88 7.89 70 3.5.3 Clustering First, a brief introduction of the standard clustering techniques using a distance matrix is mentioned <ref> [Gnanadesikan 77] </ref>. Given a set of items and a distance between each pair of items (not necessarily Euclidean distance), similar items are clustered based on the distance. Because there is no unique definition of grouping, the method of clustering is rather heuristic and several different methods have been proposed.
Reference: [Grishman et al. 84a] <author> Ralph Grishman, Ngo Than Nhan, Elaine Marsh and Lynette Hirschmann: </author> <booktitle> "Automated determination of sublanguage syntactic usage" Proceedings of the 10th Conference on Computational Linguistics (COLING) (1984) </booktitle>
Reference: [Grishman et al. 84b] <author> Ralph Grishman, Ngo Than Nhan and Elaine Marsh: </author> <title> "Tuning Natural Language Grammers for New Domains" Conference on Intelligent Systems and Machines, </title> <address> Rochester, Minnesota, </address> <month> pp342-346 </month> <year> (1984) </year>
Reference: [Grishman et al. 86] <author> Ralph Grishman, Lynette Hirschman and Ngo Than Nhan: </author> <title> "Discovery Procedures for Sublanguage Selectional Patterns: </title> <note> Initial Experiments" Journal of Computational Linguistics Vol.12 No.3 (1986) </note>
Reference: [Grishman 86] <author> Ralph Grishman: </author> <note> Computational Linguistics: An introduction Cam-bridge University Press (1986) </note>
Reference-contexts: It should be possible for anyone with sufficient knowledge of natural language processing and basic knowledge about statistics to work their way through this thesis, though this may require considerable effort for a total novice. There are several good textbook in natural language processing, for example, <ref> [Grishman 86] </ref>. Anyone who wants to know the basics of statistics used in this thesis should refer to [Charniak 93] or [Krenn and Samuelsson 97]. Chapter 2 describes a probabilistic parser whose grammar is obtained from a syntactically tagged corpus.
Reference: [Grishman and Kittredge 86] <editor> Ralph Grishman and Richard Kittredge (ed.): </editor> <title> Analyzing Language in Restricted Domains: </title> <publisher> Sublanguage Description and Processing Lawrence Erlbaum Associates, Publishers (1986) </publisher>
Reference-contexts: Most of them claim that the notion is important in processing natural language text, owning to lexical, syntactic or semantic restrictions, etc. A number of these studies have analyzed actual texts to try to verify the claim [Kittredge 82] <ref> [Grishman and Kittredge 86] </ref> [Slocum 86] [Biber 93]. Some of these studies and the definition of `sublanguage' will be discussed in Section 3.2. Several successful natural language processing systems have explicitly or implicitly addressed the sublanguage restrictions. <p> There are many other such studies, for example in [Kittredge 82] <ref> [Grishman and Kittredge 86] </ref>. Slocum [Slocum 86] reported the experiments which tried to identify sublan-guages on syntactic grounds. Four texts were prepared; two were extracted from operating and maintenance manuals, and the other two were sales brochures. These were parsed by their METAL parser.
Reference: [Grishman and Sterling 92] <editor> Ralph Grishman and John Sterling: </editor> <booktitle> "Acquisition of Se-lectional Patterns" Proceedings of the 14th Conference on Computational Linguistics (COLING) (1992) 131 </booktitle>
Reference-contexts: Among them, several studies have mentioned the importance of the sublanguage notion, for example <ref> [Grishman and Sterling 92] </ref> [Sekine 92]. Although these are still small experiments in terms of coverage, they addressed an important problem of knowledge acquisition for sublanguage.
Reference: [Grishman and Sterling 94] <editor> Ralph Grishman, John Sterling: </editor> <booktitle> "Generalizing Auto--matically Generated Selectional Patterns" Proceedings of the 15th Conference on Computational Linguistics (COLING) (1994) </booktitle>
Reference: [Grishman et al. 94] <author> Ralph Grishman, Catherine Macleod and Adam Meyers: </author> <title> "Comlex Syntax: </title> <booktitle> Building a Computational Lexicon" Proceedings of the 15th Conference on Computational Linguistics (COLING) (1994) </booktitle>
Reference-contexts: So one plausible idea is to build word clusters each of which has similar behavior. In order to build the cluster, there are two possibilities. One is to use an existing dictionary. For example, the COMLEX dictionary <ref> [Grishman et al. 94] </ref> has the class of "report-verb". We can use the verbs in this class for this particular instance. The other possibility is to use automatic clustering based on the data itself.
Reference: [Harris 68] <editor> Zellig Harris: </editor> <publisher> Mathematical Structures of Language John Wiley and Sons, </publisher> <address> New York (1968) </address>
Reference-contexts: We can find two kinds of definitions, although the difference has not received serious attention. One definition is inferable from Harris <ref> [Harris 68] </ref>: Certain proper subsets of the sentences of a language may be closed under some or all of the operations defined in the language, and thus constitute a sublanguage of it. From this definition, we can infer that a sublanguage can be defined empirically by observing language behavior.
Reference: [Hirshman et al. 75] <author> Lynette Hirschman, Ralph Grishman and Naomi Sager: </author> <title> "Grammatically based automatic word class formation" Information Processing and Management vol.11, </title> <address> pp.39-57. </address> <year> (1975) </year>
Reference: [Inui et al. 97] <author> Kentaro Inui, Virach Sornlertlamvanich, Hozumi Tanaka and Takenobu Tokunaga: </author> <booktitle> "A new Formalization of Probabilistic GLR Parsing" Proceedings of 5th International Workshop on Parsing Technologies (1997) </booktitle>
Reference-contexts: Out of 55 test sentences, 41 (74.5%) were parsed correctly with the highest ranked analysis, while in 6 cases, the correct analysis was the second or third most highly ranked. An interesting work on this line was reported in <ref> [Inui et al. 97] </ref>. 2.2.4 History Based Parsing All the approaches to grammar learning in this subsection and the subsections which follow used hand annotated corpora for their training. In other words, these are completely supervised methods.
Reference: [Isabelle 84] <author> P Isabelle: </author> <title> "Machine Translation at the TAUM group" in King,M. </title> <editor> (ed.) </editor> <booktitle> Machine Translation Today: The State of the Art, </booktitle> <publisher> Edinburgh University Press (1984) </publisher>
Reference-contexts: Some of these studies and the definition of `sublanguage' will be discussed in Section 3.2. Several successful natural language processing systems have explicitly or implicitly addressed the sublanguage restrictions. For example, TAUM-METEO <ref> [Isabelle 84] </ref> is a machine translation system in which only sentences in the weather forecast domain are dealt with. It works remarkably well and has been used commercially. It is believed that the system was successful because of the limitation of the task, including the size of vocabulary and grammar.
Reference: [Jelinek 91] <author> Fred Jelinek, B Merialdo, S Roukos, and M Strauss: </author> <title> "A Dynamic Language Model for Speech Recognition" Proceedings of DARPA Speech and Natural Language Workshop (1991) </title>
Reference-contexts: Table 3.5 shows some of the recent work which use topic coherence techniques, including cache model and topic clustering methods. Because the evaluations were made on different test sets and Site Description Improvement References (Year) (word error rate) IBM (91) cache model <ref> [Jelinek 91] </ref> CMU (94) trigger model 19.9 ! 17.8 [Rosenfeld 94] BU (93-94) clustering 11.3 ! 11.2 [Ostendorf et al. 95] (4 topic LM) CMU (96) hand clustering 0.1,0.6% improve. [Seymore 97] (5883 topic) in 2 story SRI (96) clustering 33.1 ! 33.0 [Weng 97] (4 topic LM) CU (96) cache
Reference: [Jones and Somers 97] <editor> Daniel Jones and Harold Somers (ed.): </editor> <title> New Methods in Language Processing UCL Press (1982) </title>
Reference-contexts: Also the work was referenced in a book [McEnery and Wilson 96] and appeared in a chapter of a book <ref> [Jones and Somers 97] </ref>. Chapter 4 describes experiments with the parser based on the sublanguage notion. This combines the approaches described in the previous two chapters. Several sublanguage grammars are acquired from different domain corpora, and the performance of parsing texts from different domain with different grammars is observed.
Reference: [Joshi et al. 75] <author> Aravind Joshi, Leon Levy and M Takahashi: </author> <title> "Tree Adjunct grammars" Journal of the Computer and System Sciences, </title> <month> 10 </month> <year> (1975) </year>
Reference-contexts: The formalism of Tree Adjoining Grammar (TAG) and Lexical Tree Adjoining Grammar (LTAG) were proposed by Joshi and Schabes <ref> [Joshi et al. 75] </ref> [Joshi 87]. [Schabes et al. 88] [Schabes 90]. The idea behind TAG formalism is very similar to the idea of the parser described in this thesis and LTAG is actually a motivation of the modification towards lexicalized probabilistic parser explained in Section 2.9.
Reference: [Joshi 87] <author> Aravind Joshi: </author> <title> "An introduction to Tree Adjoining Grammars" In A.Manaster-Ramer (ed.), Mathematics of Language, </title> <publisher> John Benjamins, </publisher> <month> Am-sterdam </month> <year> (1987) </year>
Reference-contexts: The formalism of Tree Adjoining Grammar (TAG) and Lexical Tree Adjoining Grammar (LTAG) were proposed by Joshi and Schabes [Joshi et al. 75] <ref> [Joshi 87] </ref>. [Schabes et al. 88] [Schabes 90]. The idea behind TAG formalism is very similar to the idea of the parser described in this thesis and LTAG is actually a motivation of the modification towards lexicalized probabilistic parser explained in Section 2.9.
Reference: [Joshi 94] <author> Aravind Joshi and B Srinivas: </author> <title> "Disambiguation of Super Parts of Speech (or Supertags): </title> <booktitle> Almost Parsing" Proceedings of the 15th Conference on Computational Linguistics (COLING) (1994) </booktitle>
Reference-contexts: Several frameworks of probabilistic LTAG have been proposed [Resnik 92] [Schabes 92]. However, these seem to have difficulty to define the initial grammar rules. It is not straightforward to assign probabilities to the rules. The recent work by Joshi 13 <ref> [Joshi 94] </ref> tries to use n-gram statistics in order to find an elemental structure for each lexical item, which is called supertag. As a supertag contains structural information, assigning supertags for all the words in a sentence almost results in a parse of the sentence.
Reference: [Joshi 96] <editor> Aravind Joshi: </editor> <booktitle> "NLP Research at UPenn" JSPS workshop; Tokyo (1996) </booktitle>
Reference: [Karlgren and Cutting 94] <author> Jussi Karlgren and Douglass Cutting: </author> <title> "Recognizing Text Genres with Simple Metrics Using Discriminant Analysis" Proceedings of the 15th Conference on Computational Linguistics (COLING) (1994) 132 </title>
Reference: [Katz 87] <author> Slava M. </author> <title> Katz "Estimation of Probabilities from Sparse Data for the Language Model Component of a Speech Recognizer" IEEE Transactions on Acoustics, Speech, </title> <booktitle> and Signal Processing (1987) </booktitle>
Reference: [Kittredge 82] <editor> Richard Kittredge, John Lehrberger (ed.): </editor> <title> Sublanguage: Studies of Language in Restricted Semantic domains Walter de Gruyter, </title> <address> Berlin (1982) </address>
Reference-contexts: Most of them claim that the notion is important in processing natural language text, owning to lexical, syntactic or semantic restrictions, etc. A number of these studies have analyzed actual texts to try to verify the claim <ref> [Kittredge 82] </ref> [Grishman and Kittredge 86] [Slocum 86] [Biber 93]. Some of these studies and the definition of `sublanguage' will be discussed in Section 3.2. Several successful natural language processing systems have explicitly or implicitly addressed the sublanguage restrictions. <p> There are many other such studies, for example in <ref> [Kittredge 82] </ref> [Grishman and Kittredge 86]. Slocum [Slocum 86] reported the experiments which tried to identify sublan-guages on syntactic grounds. Four texts were prepared; two were extracted from operating and maintenance manuals, and the other two were sales brochures. These were parsed by their METAL parser.
Reference: [Krenn and Samuelsson 97] <author> Brigitte Krenn and Christer Samuelsson: </author> <note> "The Linguist's Guide to Statistics" http://www.coli.uni-sb.de/ ~ krenn/stat nlp.ps (1997) </note>
Reference-contexts: There are several good textbook in natural language processing, for example, [Grishman 86]. Anyone who wants to know the basics of statistics used in this thesis should refer to [Charniak 93] or <ref> [Krenn and Samuelsson 97] </ref>. Chapter 2 describes a probabilistic parser whose grammar is obtained from a syntactically tagged corpus. The distinguishing characteristic of the grammar is that it has only a small number of non-terminals. Both a two non-terminal grammar and five non-terminal grammar will be described. <p> This problem is the crucial issue for automatic sublanguage definition, because otherwise we need manual intervention or artificial thresholds. In order to explore this problem, the following statistics are proposed. Perplexity, more precisely `uni-gram perplexity' (P P ) is a notion from Information Theory (see [Charniak 93] or <ref> [Krenn and Samuelsson 97] </ref>). It can be formally defined based on unigram Entropy H: H = w P P = 2 (3.2) Here p (w) is the probability of a token w in the source.
Reference: [Kurohashi and Nagao 97] <author> Sadao Kurohashi and Makoto Nagao: </author> <title> "Building a Japanese Parsed Corpus while Improving the Parsing System" Proceedings of the Natural Language Pacific Rim Symposium (1997) </title>
Reference-contexts: The difference is caused by the additional two words. In this section, a trial of acquiring a Japanese grammar which uses context information will be presented. 2.10.1 Corpus In this experiment, a Japanese annotated corpus developed at Kyoto University <ref> [Kurohashi and Nagao 97] </ref> is used. It has part-of-speech (POS) tagging and dependency information. They used an automatic part-of-speech tagger, JUMAN 41 [Matsumoto et al. 97] and a dependency analyzer, KN Parser [Kurohashi 96] to build initial structures and then trained annotators corrected the results.
Reference: [Kurohashi 96] <author> Sadao Kurohashi: </author> <title> "Japanese syntactic analyser: </title> <address> KNP" Kyoto University (1996) </address>
Reference-contexts: It has part-of-speech (POS) tagging and dependency information. They used an automatic part-of-speech tagger, JUMAN 41 [Matsumoto et al. 97] and a dependency analyzer, KN Parser <ref> [Kurohashi 96] </ref> to build initial structures and then trained annotators corrected the results. The size of the corpus is about 10,000 sentences, which is about a fifth of PennTreeBank at the moment. Their target size is 200,000. Each segment (BUNSETSU) is identified along with its dependency information.
Reference: [Leech et al. 83] <author> Geoffrey Leech, Roger Garside, E. Atwell: </author> <title> "The Automatic Grammatical Tagging of the LOB Corpus" ICAME News 7, </title> <month> pp13-33 </month> <year> (1983) </year>
Reference: [Leech et al. 87] <author> Geoffrey Leech, Roger Garside, G. Sampson: </author> <title> The computational analysis of English; A corpus based approach London, </title> <publisher> Longman (1987) </publisher>
Reference: [Lehrberger 82] <author> John Lehrberger: </author> <title> "Automatic Translation and the Concept of Sublanguage" in Sublanguage: Study of Language in Restricted Semantic Domains (1982) </title>
Reference-contexts: However, the deductive definition is not always possible and sometimes it may be wrong, as was discussed earlier. The inductive definition is related to quantitative analyses, since it is empirical. This will be described later. 3.2.2 Qualitative Analyses of Sublanguage Lehrberger <ref> [Lehrberger 82] </ref> summarized qualitatively the characteristics of sublanguage into six categories. This analysis is also interesting in terms of quantitative 57 analyses.
Reference: [Magerman and Marcus 91a] <author> David Margerman and Mitchell Marcus: "Pearl: </author> <booktitle> A Probabilistic Chart Parser" Proceedings of the 5th Conference of the European Chapter of the Association for Computational Linguistics (EACL) (1991) </booktitle>
Reference-contexts: When the two experiments were conducted, large annotated corpora were not available. The first approach used an existing parser to create training data, and the other also used an existing parser along with human intervention to choose the appropriate analysis. Magerman <ref> [Magerman and Marcus 91a] </ref> proposed a probabilistic parser, Pearl. It did not use an iterative training process; instead, probabilities were defined just by counting the usage of rules in a corpus.
Reference: [Magerman and Marcus 91b] <author> David Margerman and Mitchell Marcus: </author> <title> "Parsing the Voyager domain using Pearl" Proceedings of Speech and Natural Language Workshop, </title> <note> pp 231-236 (1991) </note>
Reference: [Magerman and Weir 92] <author> David Magerman and C.Weir: </author> <title> "Efficiency, </title> <booktitle> Robustness and Accuracy in Picky Chart Parsing" Proceedings of the 30th Annual Meeting of the Association for Computational Linguistics (ACL) (1992) </booktitle>
Reference-contexts: Furthermore, experiments over the past few years have shown the benefits of using probabilistic information in parsing, and the large corpus allows us to train the probabilities of a grammar [Fujisaki 84] [Garside and Leech 85] [Chitrao and Grishman 90] <ref> [Magerman and Weir 92] </ref> [Black et al. 93] [Bod 93] [Magerman 95] [Collins 96]. A number of recent parsing experiments have also indicated that grammars whose production probabilities are dependent on the context can be more effective than context-free grammars in selecting a correct parse. <p> This context sensitivity can be acquired easily using a large corpus, whereas human ability to compute such information is obviously limited. There have been several attempts to build context-dependent grammars based on large corpora [Chitrao and Grishman 90] [Simmons and Yu 91] <ref> [Magerman and Weir 92] </ref> [Schabes and Waters 93] [Black et al. 93] [Bod 93] [Magerman 95]. As is evident from the two lists of citations, there has been considerable research involving both probabilistic grammar based on syntactically-bracketed corpora and context-sensitivity. Some of these will be explained in the next section.
Reference: [Magerman 95] <editor> David Magerman: </editor> <booktitle> "Statistical Decision-Tree Models for Parsing" Proceedings of the 33rd Annual Meeting of the Association for Computational Linguistics (ACL) (1995) </booktitle>
Reference-contexts: Furthermore, experiments over the past few years have shown the benefits of using probabilistic information in parsing, and the large corpus allows us to train the probabilities of a grammar [Fujisaki 84] [Garside and Leech 85] [Chitrao and Grishman 90] [Magerman and Weir 92] [Black et al. 93] [Bod 93] <ref> [Magerman 95] </ref> [Collins 96]. A number of recent parsing experiments have also indicated that grammars whose production probabilities are dependent on the context can be more effective than context-free grammars in selecting a correct parse. <p> There have been several attempts to build context-dependent grammars based on large corpora [Chitrao and Grishman 90] [Simmons and Yu 91] [Magerman and Weir 92] [Schabes and Waters 93] [Black et al. 93] [Bod 93] <ref> [Magerman 95] </ref>. As is evident from the two lists of citations, there has been considerable research involving both probabilistic grammar based on syntactically-bracketed corpora and context-sensitivity. Some of these will be explained in the next section. <p> feature among several different kinds of features. (A good explanation of the decision tree method can be found in [Russell and Norvig 95].) 2.2.5 Decision Tree Parsing Magerman, who was a member of the project explained in the previous subsection, tried to make more extensive use of the decision tree <ref> [Magerman 95] </ref>. It used Wall Street Journal of the PennTreeBank in the experiment. The parser had three decision tree models which take context into account. The three models are a part-of-speech tagging model, a node-expansion model, and a node-labeling model. <p> The head is going to be the head of all dependencies to the other elements in the constituent. It is defined by heuristic rules introduced by <ref> [Magerman 95] </ref> and [Collins 96]. For example, in order to find the head of a prepositional phrase, the elements in the phrase are scanned from left to right, and the first preposition encountered in the scan is the head of the phrase. <p> If no item in the table is found, then the left or right-most item will be the head of the constituent. Appendix B shows the rules. This table is created based on the previous work by <ref> [Magerman 95] </ref> and [Collins 96]. 2.8.3 Acquire Data from Corpus From 96% of the PennTreeBank corpus (section 00, 01 and 03-24), 1,034,914 dependency relationships for 32,012 distinct head words are extracted. The dependency direction, i.e. if the argument is to the left or right of the head, is also recorded.
Reference: [Marcus 90] <author> Mitchell Marcus: </author> <booktitle> "Tutorial on Tagging and Processing Large Textual Corpora" Presented at the 28th Annual Meeting of the Association for Computational Linguistics (ACL) (1990) 133 </booktitle>
Reference: [Marcus 93] <author> Mitchell Marcus, Beatrice Santorini and Mary Marcinkiewicz: </author> <title> "Build--ing a Large Annotated Corpus of English: </title> <journal> The Penn TreeBank" Journal of Computational Linguistics, Vol.19 No.1, </journal> <volume> pp313-330. </volume> <year> (1993) </year>
Reference-contexts: When examining these methods, we can distinguish two different kinds of corpus, unannotated corpus and annotated corpus. Prior to the University of Pennsylvania Tree Bank (PennTreeBank), an annotated corpus [Marcus 96], <ref> [Marcus 93] </ref>, the majority of the research in the field had been done using unannotated corpora in combination with some existing grammar. This was mainly because there had been no widely-known, publically and easily available syntactically annotated corpora. In this section, four projects which used unannotated corpora are described. <p> One of the important features is that the way of tagging is uniform throughout the corpus. This is the crucial feature for the purpose of the sublanguage 66 studies because otherwise the different sublanguages could not be easily compared. Actually, the PennTreeBank version of the Brown corpus <ref> [Marcus 93] </ref> is used in the experiments. The following description is quoted from the manual. This Standard Corpus of Present-Day Americana English consists of 1,014,312 words of running text of edited English prose printed in the United States during the calendar year 1961.
Reference: [Marcus 96] <author> Mitchell Marcus, Beatrice Santorini and Mary Marcinkiewicz: </author> <title> "Building a large annotated corpus of English: the Penn Treebank" in the distributed Penn Tree Bank Project II CD-ROM, Linguistic Data Consortium, </title> <institution> University of Pennsylvania. </institution> <year> (1996) </year>
Reference-contexts: Finally, in Chapter 5, closing discussions and possible future work will be presented. 3 Chapter 2 Corpus-based Parser 2.1 Introduction The availability of large, syntactically-bracketed corpora such as the University of Pennsylvania Tree Bank (PennTreeBank) <ref> [Marcus 96] </ref> affords us the opportunity to automatically build or train broad-coverage grammars. Although it is inevitable that an annotated corpus would contain errors, statistical methods and the size of the corpus may be able to ameliorate the effect of individual errors. <p> When examining these methods, we can distinguish two different kinds of corpus, unannotated corpus and annotated corpus. Prior to the University of Pennsylvania Tree Bank (PennTreeBank), an annotated corpus <ref> [Marcus 96] </ref>, [Marcus 93], the majority of the research in the field had been done using unannotated corpora in combination with some existing grammar. This was mainly because there had been no widely-known, publically and easily available syntactically annotated corpora. <p> This modification also works to reduce the number of grammar rules. Finally, some new categories are introduced. This is because the PennTreeBank project tried to reduce the number of part-of-speech categories in order to ease the tagging effort. The PennTreeBank manual <ref> [Marcus 96] </ref> says that they combined categories, in cases where finer distinctions can be recovered based on lexical information.
Reference: [Matsumoto et al. 97] <author> Yuuji Matsumoto, Sadao Kurohashi, Osamu Yamaji, Yuu Taeki and Makoto Nagao: </author> <title> "Japanese morphological analyzing System: </title> <institution> JU-MAN" Kyoto University and Nara Institute of Science and Technology (1997) </institution>
Reference-contexts: It has part-of-speech (POS) tagging and dependency information. They used an automatic part-of-speech tagger, JUMAN 41 <ref> [Matsumoto et al. 97] </ref> and a dependency analyzer, KN Parser [Kurohashi 96] to build initial structures and then trained annotators corrected the results. The size of the corpus is about 10,000 sentences, which is about a fifth of PennTreeBank at the moment. Their target size is 200,000.
Reference: [McEnery and Wilson 96] <author> Tony McEnery and Andrew Wilson: </author> <note> Corpus Linguistics Edinburgh University Press (1996) </note>
Reference-contexts: Some parts of the work reported in this chapter were previously published in [Sekine 94a], [Sekine 94b], [Sekine 95], [Sekine et al. 95], [Sekine and Grishman 96], [Sekine et al. 97a], [Sekine and Grishman 97] and [Sekine 97]. Also the work was referenced in a book <ref> [McEnery and Wilson 96] </ref> and appeared in a chapter of a book [Jones and Somers 97]. Chapter 4 describes experiments with the parser based on the sublanguage notion. This combines the approaches described in the previous two chapters.
Reference: [Ostendorf et al. 95] <author> Mari Ostendorf, Fred Richardson, Rukemini Iyer, Ashvin Kan-nan, Orith Ronen and Rebecca Bates: </author> <booktitle> "The 1994 BU NAB News Benchmark System" Proceedings of the ARPA Spoken Language Systems Technology Workshop (1995) </booktitle>
Reference-contexts: Because the evaluations were made on different test sets and Site Description Improvement References (Year) (word error rate) IBM (91) cache model [Jelinek 91] CMU (94) trigger model 19.9 ! 17.8 [Rosenfeld 94] BU (93-94) clustering 11.3 ! 11.2 <ref> [Ostendorf et al. 95] </ref> (4 topic LM) CMU (96) hand clustering 0.1,0.6% improve. [Seymore 97] (5883 topic) in 2 story SRI (96) clustering 33.1 ! 33.0 [Weng 97] (4 topic LM) CU (96) cache model 27.7 ! 27.5 [Woodland et al. 97] Sekine sublanguage and 24.6 ! 24.0 cache model 9.7
Reference: [Pereira and Schabes 92] <author> Fernando Pereira and Yves Schabes: </author> <booktitle> "Inside-Outside Reestimation from Partially Bracketed Corpora" Proceedings of the 30th Annual Meeting of the Association for Computational Linguistics (ACL) (1992) </booktitle>
Reference-contexts: An interesting way to force the initial probabilities into the correct part of the parameter space was proposed by <ref> [Pereira and Schabes 92] </ref>. They tried the inside-outside algorithm with partially annotated corpora. It starts with a grammar in Chomsky normal form containing all possible productions. They introduced a partially annotated corpus, in other words `seeds', which are known correct relationships.
Reference: [Ratnaparkhi 97] <author> Adwait Ratnaparkhi: </author> <title> "A Linear Observed Time Statistical Parser Based on Maximum Entropy Models" Proceedings of Empirical Method for Natural Language Processings (1997) </title>
Reference-contexts: Recently [Collins 97] reported a new version of the parser. It includes a generative model of lexicalized context-free grammar and a probabilistic treatment of both subcategorization and wh-movement. The recall and precision of the new parser are 88.1% and 87.5%. Also <ref> [Ratnaparkhi 97] </ref> proposed a parser using similar information based on maximum entropy model. The parsing strategy is unique and it can generate multiple trees in linear observed time. <p> This is an encouraging result for pursuing this line of the experiment. 2.8.5 Future Direction This is currently a very active research area in corpus based parsing. Recently, in [Collins 97] [Charniak 97] <ref> [Ratnaparkhi 97] </ref>, very good parsing performances are reported using lexical dependencies on statistical parsers. The dependency information they used is relatively richer than that used in this experiment.
Reference: [Rayner 88] <author> Manny Rayner: </author> <booktitle> "Applying Explanation-Based Generalization to Natural-Language Processing" Proceedings of the International Conference on Fifth Generation Computer Systems (1988) </booktitle>
Reference-contexts: It is based on Explanation-Based Learning (EBL) firstly introduced in Artificial Intelligence, and applied to parsing by <ref> [Rayner 88] </ref>, [Samuelsson 94a] and [Rayner 96]. The background idea is that grammar rules tend to combine frequently in some particular ways. Given a sufficiently large parsed corpus, it is possible to identify the common combinations of grammar rules and chunk them into "macro-rules".
Reference: [Rayner 96] <author> Manny Rayner and David Cater: </author> <booktitle> "Fast Parsing Using Pruning and Grammar Specialization" Proceedings of the 34th Annual Meeting of the Association for Computational Linguistics (ACL) (1996) </booktitle>
Reference-contexts: It is based on Explanation-Based Learning (EBL) firstly introduced in Artificial Intelligence, and applied to parsing by [Rayner 88], [Samuelsson 94a] and <ref> [Rayner 96] </ref>. The background idea is that grammar rules tend to combine frequently in some particular ways. Given a sufficiently large parsed corpus, it is possible to identify the common combinations of grammar rules and chunk them into "macro-rules". <p> The result is a "specialized" grammar, which has a larger number of rules, but a simpler structure, allowing it in practice to parse quickly. It gains speed in a trade-of for the coverage. In <ref> [Rayner 96] </ref>, they reported 3 to 4 times speed up at the price of about 5% loss of coverage, using 15,000 training data in the Air Travel Planning (ATIS) domain.
Reference: [Resnik 92] <author> Phillip Resnik: </author> <booktitle> "Probablistic Tree-Adjoining Grammar as a Framework for Statistical Natural Language Processing" Proceedings of the 14th Conference on Computational Linguistics (COLING) (1992) </booktitle>
Reference-contexts: It can be rephrased that each lexical item has associated with it a set of structures that characterize the contexts within which that item can appear. Several frameworks of probabilistic LTAG have been proposed <ref> [Resnik 92] </ref> [Schabes 92]. However, these seem to have difficulty to define the initial grammar rules. It is not straightforward to assign probabilities to the rules.
Reference: [Rosenfeld 94] <author> Ronald Rosenfeld: </author> <title> "A Hybrid Approach to Adaptive Statistical Language Modeling" Proceedings of Human Language Technology Workshop (1994) </title>
Reference-contexts: Because the evaluations were made on different test sets and Site Description Improvement References (Year) (word error rate) IBM (91) cache model [Jelinek 91] CMU (94) trigger model 19.9 ! 17.8 <ref> [Rosenfeld 94] </ref> BU (93-94) clustering 11.3 ! 11.2 [Ostendorf et al. 95] (4 topic LM) CMU (96) hand clustering 0.1,0.6% improve. [Seymore 97] (5883 topic) in 2 story SRI (96) clustering 33.1 ! 33.0 [Weng 97] (4 topic LM) CU (96) cache model 27.7 ! 27.5 [Woodland et al. 97] Sekine
Reference: [Russell and Norvig 95] <author> Stuart Russell and Peter Norvig: </author> <booktitle> "Artificial Intelligence: A Modern Approach" Prentice Hall Series in Artificial Intelligence (1995) 134 </booktitle>
Reference-contexts: The decision tree is a general tool in the sense that it can be trained so that it utilizes the most useful feature among several different kinds of features. (A good explanation of the decision tree method can be found in <ref> [Russell and Norvig 95] </ref>.) 2.2.5 Decision Tree Parsing Magerman, who was a member of the project explained in the previous subsection, tried to make more extensive use of the decision tree [Magerman 95]. It used Wall Street Journal of the PennTreeBank in the experiment. <p> The details of the experiments are omitted here. 25 2.6 Size of Training Corpus In this section, the issue of training corpus size will be discussed. This issue is very often discussed in corpus based methods, or data oriented learning in general <ref> [Russell and Norvig 95] </ref>. In order to assess the ability of the system, it is important to know the relationship between the training corpus size and the performance, or how much data is needed to achieve sufficient performance.
Reference: [Samuelsson 94a] <author> Christer Samuelsson: </author> <title> "Fast Natural-Language Parsing Using Explanation-Based Learning" doctoral thesis, </title> <institution> The Royal Institute of Technology and Stockholm University (1994) </institution>
Reference-contexts: It is based on Explanation-Based Learning (EBL) firstly introduced in Artificial Intelligence, and applied to parsing by [Rayner 88], <ref> [Samuelsson 94a] </ref> and [Rayner 96]. The background idea is that grammar rules tend to combine frequently in some particular ways. Given a sufficiently large parsed corpus, it is possible to identify the common combinations of grammar rules and chunk them into "macro-rules".
Reference: [Samuelsson 94b] <author> Christer Samuelsson: </author> <booktitle> "Grammar Specialization through Entropy Thresholds" Proceedings of the 32nd Annual Meeting of the Association for Computational Linguistics (ACL) (1994) </booktitle>
Reference-contexts: However, their experiments are done on a small and relatively homogeneous domain. The performance is not compatible, because they reported only the indirect performance produced by the parse output. <ref> [Samuelsson 94b] </ref> proposed entropy thresholds which automatically 12 derive the macro-rules, but no improvement over the previous work was found. 2.2.9 (Lexicalized) Tree Adjoining Grammar The relevance of this research to this thesis is not the method of grammar acquisition, but its formalism.
Reference: [Sankar et al. 96] <author> A.Sankar, A.Stolcke, T.Chung, L.Neumeyer, M.Weintraub, H.Franco and F.Beaufays: </author> <title> "Noise-Resistant Feature Extraction and Model Training for Robust Speech Recognition" DARPA Speech Recognition Workshop (1996) </title>
Reference-contexts: This is the motivation for the experiments in this section. 2.11.1 Structure SRI's speech recognition system was used as the source of transcription hypotheses <ref> [Sankar et al. 96] </ref>. The scheme of the experiment is shown in Figure 2.14. The n-best sentences, the most likely top n candidate sentences for an utterance, is the input data for the parser. The parser assigns its own score for each sentence.
Reference: [Schabes et al. 88] <author> Yves Schabes, Anne Abeille and Aravind Joshi: </author> <title> "Parsing strategies with lexicalized grammars: </title> <booktitle> Application to tree adjoining grammars" Proceedings of the 12th Conference on Computational Linguistics (COLING) (1988) </booktitle>
Reference-contexts: The formalism of Tree Adjoining Grammar (TAG) and Lexical Tree Adjoining Grammar (LTAG) were proposed by Joshi and Schabes [Joshi et al. 75] [Joshi 87]. <ref> [Schabes et al. 88] </ref> [Schabes 90]. The idea behind TAG formalism is very similar to the idea of the parser described in this thesis and LTAG is actually a motivation of the modification towards lexicalized probabilistic parser explained in Section 2.9.
Reference: [Schabes 90] <author> Yves Schabes: </author> <booktitle> "Mathematical and Computational Aspects of Lexical-ized Grammars" PhD thesis, </booktitle> <institution> University of Pennsylvania (1990) </institution>
Reference-contexts: The formalism of Tree Adjoining Grammar (TAG) and Lexical Tree Adjoining Grammar (LTAG) were proposed by Joshi and Schabes [Joshi et al. 75] [Joshi 87]. [Schabes et al. 88] <ref> [Schabes 90] </ref>. The idea behind TAG formalism is very similar to the idea of the parser described in this thesis and LTAG is actually a motivation of the modification towards lexicalized probabilistic parser explained in Section 2.9.
Reference: [Schabes 92] <author> Yves Schabes: </author> <booktitle> "Stochastic Lexicalized Tree-Adjoining Grammars" Proceedings of the 14th Conference on Computational Linguistics (COLING) (1992) </booktitle>
Reference-contexts: It can be rephrased that each lexical item has associated with it a set of structures that characterize the contexts within which that item can appear. Several frameworks of probabilistic LTAG have been proposed [Resnik 92] <ref> [Schabes 92] </ref>. However, these seem to have difficulty to define the initial grammar rules. It is not straightforward to assign probabilities to the rules.
Reference: [Schabes and Waters 93] <author> Yves Schabes, R.Waters: </author> <booktitle> "Lexicalized Context-Free Grammars" Proceedings of the 31st Annual Meeting of the Association for Computational Linguistics (ACL) (1993) </booktitle>
Reference-contexts: This context sensitivity can be acquired easily using a large corpus, whereas human ability to compute such information is obviously limited. There have been several attempts to build context-dependent grammars based on large corpora [Chitrao and Grishman 90] [Simmons and Yu 91] [Magerman and Weir 92] <ref> [Schabes and Waters 93] </ref> [Black et al. 93] [Bod 93] [Magerman 95]. As is evident from the two lists of citations, there has been considerable research involving both probabilistic grammar based on syntactically-bracketed corpora and context-sensitivity. Some of these will be explained in the next section.
Reference: [Sekine et al. 92a] <author> Satoshi Sekine, Jeremy Carroll, Sofia Ananiadou, Jun-ichi Tsu-jii: </author> <booktitle> "Automatic Learning for Semantic Collocation" Proceedings of the 3rd Conference on Applied Natural Language Processing (1992) </booktitle>
Reference: [Sekine et al. 92b] <author> Satoshi Sekine, Sofia Ananiadou, Jeremy Carroll, Jun-ichi Tsu-jii: </author> <booktitle> "Linguistic Knowledge Generator" Proceedings of the 14th Conference on Computational Linguistics (COLING) (1992) </booktitle>
Reference: [Sekine 92] <institution> Satoshi Sekine "Automatic Linguistic Knowledge Acquisition from Corpora" MSc thesis; University of Manchester Institute of Science and Technology (1992) </institution>
Reference-contexts: Among them, several studies have mentioned the importance of the sublanguage notion, for example [Grishman and Sterling 92] <ref> [Sekine 92] </ref>. Although these are still small experiments in terms of coverage, they addressed an important problem of knowledge acquisition for sublanguage.
Reference: [Sekine 93] <author> Satoshi Sekine: </author> <title> "Linguistic Knowledge Acquisition from Corpora using Dempster-Shafer Theory and Human Intervention" Shizen-Gengo-Syori-Kenkyuukai (Research Group on Natural Language Processing) Information Processing Society of Japan (In Japanese) (1993) </title>
Reference: [Sekine 94a] <author> Satoshi Sekine: </author> <booktitle> "Automatic Sublanguage Identification for a New Text" Proceedings of the 2nd Annual Workshop on Very Large Corpora (1994) 135 </booktitle>
Reference-contexts: Then multi-domain corpora are used for a study of sublanguage features in terms of lexical and syntactic characteristics. Finally, an application of sublanguage to continuous speech recognition will be described. Some parts of the work reported in this chapter were previously published in <ref> [Sekine 94a] </ref>, [Sekine 94b], [Sekine 95], [Sekine et al. 95], [Sekine and Grishman 96], [Sekine et al. 97a], [Sekine and Grishman 97] and [Sekine 97]. Also the work was referenced in a book [McEnery and Wilson 96] and appeared in a chapter of a book [Jones and Somers 97].
Reference: [Sekine 94b] <author> Satoshi Sekine: </author> <title> "A New Direction for Sublanguage NLP" Proceed--ings of the International Conference on New Methods in Language Processing (1994) </title>
Reference-contexts: Then multi-domain corpora are used for a study of sublanguage features in terms of lexical and syntactic characteristics. Finally, an application of sublanguage to continuous speech recognition will be described. Some parts of the work reported in this chapter were previously published in [Sekine 94a], <ref> [Sekine 94b] </ref>, [Sekine 95], [Sekine et al. 95], [Sekine and Grishman 96], [Sekine et al. 97a], [Sekine and Grishman 97] and [Sekine 97]. Also the work was referenced in a book [McEnery and Wilson 96] and appeared in a chapter of a book [Jones and Somers 97].
Reference: [Sekine 95] <author> Satoshi Sekine: </author> <title> "A New Direction for Sublanguage NLP" Journal of Gengo Syori Gakkai (Natural Language Processing) (1995) </title>
Reference-contexts: Then multi-domain corpora are used for a study of sublanguage features in terms of lexical and syntactic characteristics. Finally, an application of sublanguage to continuous speech recognition will be described. Some parts of the work reported in this chapter were previously published in [Sekine 94a], [Sekine 94b], <ref> [Sekine 95] </ref>, [Sekine et al. 95], [Sekine and Grishman 96], [Sekine et al. 97a], [Sekine and Grishman 97] and [Sekine 97]. Also the work was referenced in a book [McEnery and Wilson 96] and appeared in a chapter of a book [Jones and Somers 97].
Reference: [Sekine et al. 95] <author> Satoshi Sekine, John Sterling, Ralph Grishman: </author> <booktitle> "NYU/BBN 1994 CSR Evaluation" Proceedings of the Spoken Language Systems Technology Workshop (1995) </booktitle>
Reference-contexts: Then multi-domain corpora are used for a study of sublanguage features in terms of lexical and syntactic characteristics. Finally, an application of sublanguage to continuous speech recognition will be described. Some parts of the work reported in this chapter were previously published in [Sekine 94a], [Sekine 94b], [Sekine 95], <ref> [Sekine et al. 95] </ref>, [Sekine and Grishman 96], [Sekine et al. 97a], [Sekine and Grishman 97] and [Sekine 97]. Also the work was referenced in a book [McEnery and Wilson 96] and appeared in a chapter of a book [Jones and Somers 97].
Reference: [Sekine and Tsujii 95] <author> Satoshi Sekine, Jun-ichi Tsujii: </author> <title> "Automatic Linguistic Knowledge Acquisition from Corpora" Journal of Machine Translation (1995) </title>
Reference: [Sekine and Grishman 95] <author> Satoshi Sekine, Ralph Grishman: </author> <booktitle> "A Corpus-based Probabilistic Grammar with Only Two Non-terminals" Proceedings of the 4th International Workshop on Parsing Technology (1995) </booktitle>
Reference-contexts: A trial of this approach for Japanese and an application of the parser for continuous speech recognition will be presented. Some parts of the work reported in this chapter were previously published in <ref> [Sekine and Grishman 95] </ref>, [Sekine et al. 97a] and [Sekine et al. 97b]. The parser and the evaluation program are available as public domain software from 2 [Sekine 96a] and [Sekine and Collins 97].
Reference: [Sekine and Grishman 96] <author> Satoshi Sekine, Ralph Grishman: </author> <title> "NYU Language Modeling Experiments for 1995 CSR Evaluation" Proceedings of the Spoken Language Systems Technology Workshop (1996) </title>
Reference-contexts: Finally, an application of sublanguage to continuous speech recognition will be described. Some parts of the work reported in this chapter were previously published in [Sekine 94a], [Sekine 94b], [Sekine 95], [Sekine et al. 95], <ref> [Sekine and Grishman 96] </ref>, [Sekine et al. 97a], [Sekine and Grishman 97] and [Sekine 97]. Also the work was referenced in a book [McEnery and Wilson 96] and appeared in a chapter of a book [Jones and Somers 97].
Reference: [Sekine 96a] <author> Satoshi Sekine: </author> <note> "Apple Pie Parser Homepage" http://cs.nyu.edu/cs/projects/proteus/app </note>
Reference-contexts: Some parts of the work reported in this chapter were previously published in [Sekine and Grishman 95], [Sekine et al. 97a] and [Sekine et al. 97b]. The parser and the evaluation program are available as public domain software from 2 <ref> [Sekine 96a] </ref> and [Sekine and Collins 97]. Also, the work was referenced in a book [Young and Bloothooft 97] and in a review [Bod and Scha 96]. Chapter 3 describes a study of the sublanguage notion based on corpora. First, statistical measures are used to find sublanguage from newspaper articles.
Reference: [Sekine 96b] <author> Satoshi Sekine: </author> <booktitle> "Modeling Topic Coherence for Speech Recognition" Proceedings of the 16th Conference on Computational Linguistics (COLING) (1996) </booktitle>
Reference: [Sekine et al. 97a] <author> Satoshi Sekine, Andrew Borthwick and Ralph Grishman: </author> <title> "NYU language Modeling Experiment for 1996 CSR Evaluation" Proceedings of the DARPA Speech Recognition Workshop (1997) </title>
Reference-contexts: A trial of this approach for Japanese and an application of the parser for continuous speech recognition will be presented. Some parts of the work reported in this chapter were previously published in [Sekine and Grishman 95], <ref> [Sekine et al. 97a] </ref> and [Sekine et al. 97b]. The parser and the evaluation program are available as public domain software from 2 [Sekine 96a] and [Sekine and Collins 97]. Also, the work was referenced in a book [Young and Bloothooft 97] and in a review [Bod and Scha 96]. <p> Finally, an application of sublanguage to continuous speech recognition will be described. Some parts of the work reported in this chapter were previously published in [Sekine 94a], [Sekine 94b], [Sekine 95], [Sekine et al. 95], [Sekine and Grishman 96], <ref> [Sekine et al. 97a] </ref>, [Sekine and Grishman 97] and [Sekine 97]. Also the work was referenced in a book [McEnery and Wilson 96] and appeared in a chapter of a book [Jones and Somers 97]. Chapter 4 describes experiments with the parser based on the sublanguage notion.
Reference: [Sekine and Grishman 97] <author> Satoshi Sekine and Ralph Grishman: </author> <title> "Domain Project Report" Final Report of Domain project (1997) </title>
Reference-contexts: Finally, an application of sublanguage to continuous speech recognition will be described. Some parts of the work reported in this chapter were previously published in [Sekine 94a], [Sekine 94b], [Sekine 95], [Sekine et al. 95], [Sekine and Grishman 96], [Sekine et al. 97a], <ref> [Sekine and Grishman 97] </ref> and [Sekine 97]. Also the work was referenced in a book [McEnery and Wilson 96] and appeared in a chapter of a book [Jones and Somers 97]. Chapter 4 describes experiments with the parser based on the sublanguage notion. <p> This combines the approaches described in the previous two chapters. Several sublanguage grammars are acquired from different domain corpora, and the performance of parsing texts from different domain with different grammars is observed. Parts of the work reported in this chapter were previously published in <ref> [Sekine and Grishman 97] </ref> and [Sekine 97].
Reference: [Sekine 97] <author> Satoshi Sekine: </author> <booktitle> "The Domain Dependence of Parsing" Proceedings of the 5th Conference on Applied Natural Language Processing (1997) </booktitle>
Reference-contexts: Finally, an application of sublanguage to continuous speech recognition will be described. Some parts of the work reported in this chapter were previously published in [Sekine 94a], [Sekine 94b], [Sekine 95], [Sekine et al. 95], [Sekine and Grishman 96], [Sekine et al. 97a], [Sekine and Grishman 97] and <ref> [Sekine 97] </ref>. Also the work was referenced in a book [McEnery and Wilson 96] and appeared in a chapter of a book [Jones and Somers 97]. Chapter 4 describes experiments with the parser based on the sublanguage notion. This combines the approaches described in the previous two chapters. <p> Several sublanguage grammars are acquired from different domain corpora, and the performance of parsing texts from different domain with different grammars is observed. Parts of the work reported in this chapter were previously published in [Sekine and Grishman 97] and <ref> [Sekine 97] </ref>. Finally, in Chapter 5, closing discussions and possible future work will be presented. 3 Chapter 2 Corpus-based Parser 2.1 Introduction The availability of large, syntactically-bracketed corpora such as the University of Pennsylvania Tree Bank (PennTreeBank) [Marcus 96] affords us the opportunity to automatically build or train broad-coverage grammars.
Reference: [Sekine and Collins 97] <author> Satoshi Sekine and Micheal Collins: </author> <title> "Bracketing evaluation program" http://cs.nyu.edu/cs/projects/proteus/evalb </title>
Reference-contexts: Some parts of the work reported in this chapter were previously published in [Sekine and Grishman 95], [Sekine et al. 97a] and [Sekine et al. 97b]. The parser and the evaluation program are available as public domain software from 2 [Sekine 96a] and <ref> [Sekine and Collins 97] </ref>. Also, the work was referenced in a book [Young and Bloothooft 97] and in a review [Bod and Scha 96]. Chapter 3 describes a study of the sublanguage notion based on corpora. First, statistical measures are used to find sublanguage from newspaper articles. <p> In that measure, multiple layers of unary trees are collapsed to a single layer of unary tree. Also, the labeling is not considered in the matching 5 . However, the metric used in this section is the simple labeled bracketing precision and recall <ref> [Sekine and Collins 97] </ref>. From the experiments, the labeled bracketing metric generated about 1% to 3% worse result compared to the Parseval method.
Reference: [Sekine et al. 97b] <author> Satoshi Sekine, Kiyotaka Uchimoto and Hitoshi Isahara: </author> <title> "Corpus-based Japanese Parser Using Context Information" Proceedings of the Natural Language Pacific Rim Symposium (1997) </title>
Reference-contexts: A trial of this approach for Japanese and an application of the parser for continuous speech recognition will be presented. Some parts of the work reported in this chapter were previously published in [Sekine and Grishman 95], [Sekine et al. 97a] and <ref> [Sekine et al. 97b] </ref>. The parser and the evaluation program are available as public domain software from 2 [Sekine 96a] and [Sekine and Collins 97]. Also, the work was referenced in a book [Young and Bloothooft 97] and in a review [Bod and Scha 96].
Reference: [Seymore 97] <author> Kristie Seymore, Stanley Chen, Maxine Eskenazi and Roni Rosenfeld: </author> <booktitle> "Language and Pronunciation Modeling in the CMU 1996 Hub 4 Evaluation" Proceedings of the DARPA Speech Recognition Workshop (1997) 136 </booktitle>
Reference-contexts: evaluations were made on different test sets and Site Description Improvement References (Year) (word error rate) IBM (91) cache model [Jelinek 91] CMU (94) trigger model 19.9 ! 17.8 [Rosenfeld 94] BU (93-94) clustering 11.3 ! 11.2 [Ostendorf et al. 95] (4 topic LM) CMU (96) hand clustering 0.1,0.6% improve. <ref> [Seymore 97] </ref> (5883 topic) in 2 story SRI (96) clustering 33.1 ! 33.0 [Weng 97] (4 topic LM) CU (96) cache model 27.7 ! 27.5 [Woodland et al. 97] Sekine sublanguage and 24.6 ! 24.0 cache model 9.7 ! 9.4 Table 3.5: Approaches of topic coherent model in speech recognition on
Reference: [Shirai et al. 97] <author> Kiyoaki Shirai, Kentaro Inui, Hozumi Tanaka and Takenobu Toku--naga: </author> <title> "An Empirical Study on Statistical Disambiguation of Japanese Dependency Structures Using a Lexically Sensitive Language Model" Proceedings of the Natural Language Pacific Rim Symposium (1997) </title>
Reference-contexts: It has been well discussed that, in Japanese, lexical relationships are the most crucial information for analyzing syntactic structures, and there are probabilistic corpus based parser which use lexical information (for example, [Fujio and Matsumoto 97] <ref> [Shirai et al. 97] </ref>).
Reference: [Sima'an 97] <author> Khalil Sima'an: </author> <booktitle> "Explanation-Based Learning of Data Oriented Parsing" Proceedings of the Workshop on Computational Natural Language Learning (CoNLL) (1997) </booktitle>
Reference-contexts: However, as they extracted all possible tree fragments, the number of possible derivations becomes enormous, so some technique to overcome the problem is needed <ref> [Sima'an 97] </ref>. 2.2.7 Parsing by Lexical Dependency This is another state-of-the-art parser, proposed by Collins [Collins 96]. It used an annotated corpus, Wall Street Journal of the PennTreeBank, like the method by Magerman.
Reference: [Simmons and Yu 91] <author> Robert Simmons and Yeong-Ho Yu: </author> <booktitle> "The Acquisition and Application of Context Sensitive Grammar for English" Proceedings of the 29st Annual Meeting of the Association for Computational Linguistics (ACL) (1991) </booktitle>
Reference-contexts: This context sensitivity can be acquired easily using a large corpus, whereas human ability to compute such information is obviously limited. There have been several attempts to build context-dependent grammars based on large corpora [Chitrao and Grishman 90] <ref> [Simmons and Yu 91] </ref> [Magerman and Weir 92] [Schabes and Waters 93] [Black et al. 93] [Bod 93] [Magerman 95]. As is evident from the two lists of citations, there has been considerable research involving both probabilistic grammar based on syntactically-bracketed corpora and context-sensitivity.
Reference: [Slocum 86] <author> Jonathan Slocum: </author> <title> "How One Might Automatically Identify and Adapt to a Sublanguage: An Initial Exploration" in Analyzing Language in Restricted Domains (1986) </title>
Reference-contexts: Most of them claim that the notion is important in processing natural language text, owning to lexical, syntactic or semantic restrictions, etc. A number of these studies have analyzed actual texts to try to verify the claim [Kittredge 82] [Grishman and Kittredge 86] <ref> [Slocum 86] </ref> [Biber 93]. Some of these studies and the definition of `sublanguage' will be discussed in Section 3.2. Several successful natural language processing systems have explicitly or implicitly addressed the sublanguage restrictions. <p> There are many other such studies, for example in [Kittredge 82] [Grishman and Kittredge 86]. Slocum <ref> [Slocum 86] </ref> reported the experiments which tried to identify sublan-guages on syntactic grounds. Four texts were prepared; two were extracted from operating and maintenance manuals, and the other two were sales brochures. These were parsed by their METAL parser.
Reference: [Sparck-Jones 73] <author> K.Sparck-Jones: </author> <title> "Index Term Weighting" Information Storage and Retrieval, </title> <address> Vol.9, </address> <month> p619-633 </month> <year> (1973) </year>
Reference-contexts: This is a standard metric of information retrieval based on the assumption that the lower frequency words provide more information about topics <ref> [Sparck-Jones 73] </ref>. For each article, article scores (AScore) for all articles (target) in the large corpus are computed as the sum of the weighted scores of the selected keywords and are normalized by the log of the size of the target article.
Reference: [Speech Workshop 97] <institution> Proceedings of the Speech Recognition Workshop DARPA (1997) </institution>
Reference: [Speech Workshop 96] <institution> Proceedings of the Speech Recognition Workshop DARPA (1996) </institution>
Reference-contexts: The absolute improvement using the sublanguage component over SRI's system, for example, on P0 is 0.6%, from 24.6% to 24.0%, as shown in Table 3.6. The figures in the table was based on the formal evaluation conducted at NIST <ref> [Speech Workshop 96] </ref>. The absolute improvement looks tiny; however, there is a System P0 C0 C4A C4B SRI 24.6 % 9.7 % 24.6 % 9.7 % Table 3.6: Formal result of speech recognition limit to the improvement we can obtain, because the N-best sentences don't always contain the correct candidate.
Reference: [Speech Workshop 95] <institution> Proceedings of the Spoken Language Systems Technology Workshop ARPA (1995) </institution>
Reference: [Tanaka 89] <author> Hozumi Tanaka: </author> <title> Shizen Gengo Kaiseki no Kiso Introduction to Natural Language Analysis - (in Japanese) Sangyo Tosyo (1989) </title>
Reference: [Weng 97] <author> Fuliang Weng, Andreas Stolcke and Ananth Sankar: </author> <title> "Hub-4 Language Modeling using Domain Interpolation and Data Clustering" Proceedings of the DARPA Speech Recognition Workshop (1997) </title>
Reference-contexts: (word error rate) IBM (91) cache model [Jelinek 91] CMU (94) trigger model 19.9 ! 17.8 [Rosenfeld 94] BU (93-94) clustering 11.3 ! 11.2 [Ostendorf et al. 95] (4 topic LM) CMU (96) hand clustering 0.1,0.6% improve. [Seymore 97] (5883 topic) in 2 story SRI (96) clustering 33.1 ! 33.0 <ref> [Weng 97] </ref> (4 topic LM) CU (96) cache model 27.7 ! 27.5 [Woodland et al. 97] Sekine sublanguage and 24.6 ! 24.0 cache model 9.7 ! 9.4 Table 3.5: Approaches of topic coherent model in speech recognition on different conditions, a direct comparison is not possible.
Reference: [Willett 88] <author> Peter Willett: </author> <title> "Recent trends in hierarchic document clustering: a critical review" Information Processing and Management, </title> <address> vol.24 num.5, </address> <month> pp577-597 </month> <year> (1988) </year>
Reference-contexts: Each article in the corpus is regarded as a unit of data, and a sublanguage will be formed by gathering similar units in term of word appearance. This is almost identical to the text clustering technique, which has been well studied in the field of information retrieval <ref> [Willett 88] </ref>. However the aim of the text clustering in information retrieval is slightly different from that in this thesis. They try to make text clusters which are useful for human information retrieval purposes, so the linguistic features of the clusters are not so important.
Reference: [Woodland et al. 97] <author> P. Woodland, M. Gales, D. Pye and S. Young: </author> <title> "Broadcast News Transcription Using HTK" Proceedings of the DARPA Speech Recognition Workshop (1997) </title>
Reference-contexts: model 19.9 ! 17.8 [Rosenfeld 94] BU (93-94) clustering 11.3 ! 11.2 [Ostendorf et al. 95] (4 topic LM) CMU (96) hand clustering 0.1,0.6% improve. [Seymore 97] (5883 topic) in 2 story SRI (96) clustering 33.1 ! 33.0 [Weng 97] (4 topic LM) CU (96) cache model 27.7 ! 27.5 <ref> [Woodland et al. 97] </ref> Sekine sublanguage and 24.6 ! 24.0 cache model 9.7 ! 9.4 Table 3.5: Approaches of topic coherent model in speech recognition on different conditions, a direct comparison is not possible.
Reference: [Young and Bloothooft 97] <author> Steve Young and Gerrit Bloothooft (ed.): </author> <title> Corpus-based Methods in Language and Speech Recognition Kluwer Academic Publishers (1997) </title>
Reference-contexts: The parser and the evaluation program are available as public domain software from 2 [Sekine 96a] and [Sekine and Collins 97]. Also, the work was referenced in a book <ref> [Young and Bloothooft 97] </ref> and in a review [Bod and Scha 96]. Chapter 3 describes a study of the sublanguage notion based on corpora. First, statistical measures are used to find sublanguage from newspaper articles.
Reference: [Zipf 49] <author> G.Zipf: </author> <title> Human behaviour and the principle of least effort Addison-Wesley (1949) </title>
Reference-contexts: In other words, for 95.3% of input sentence, we can not make any output. A very rough estimation assuming Zipf's law <ref> [Zipf 49] </ref> [Zipf 65] in the distribution requires 10 70 to 10 140 sentences in order to get 80% of coverage. 1 In this approach, ambiguities caused by lexical information, for example, prepositional attachment, are ignored. 2 These are not the entire corpus but the 96% of the corpus which will
Reference: [Zipf 65] <author> G.Zipf: </author> <title> The psycho-biology of language: An introduction to dynamic philology MIT Press (1965) 138 </title>
Reference-contexts: In other words, for 95.3% of input sentence, we can not make any output. A very rough estimation assuming Zipf's law [Zipf 49] <ref> [Zipf 65] </ref> in the distribution requires 10 70 to 10 140 sentences in order to get 80% of coverage. 1 In this approach, ambiguities caused by lexical information, for example, prepositional attachment, are ignored. 2 These are not the entire corpus but the 96% of the corpus which will be used
References-found: 111

