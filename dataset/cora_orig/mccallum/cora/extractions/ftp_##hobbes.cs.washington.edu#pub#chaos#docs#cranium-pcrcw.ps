URL: ftp://hobbes.cs.washington.edu/pub/chaos/docs/cranium-pcrcw.ps
Refering-URL: http://www.cs.washington.edu/research/projects/lis/chaos/www/abstracts/cranium.html
Root-URL: http://www.cs.washington.edu
Title: Cranium: An Interface for Message Passing on Adaptive Packet Routing Networks  
Author: Neil R. McKenzie, Kevin Bolding, Carl Ebeling and Lawrence Snyder 
Address: FR-35 Seattle WA 98195, USA  
Affiliation: University of Washington Department of CSE,  
Abstract: Cranium is a processor-network interface for an interconnection network based on adaptive packet routing. Adaptive networks relax the restriction that packet order is preserved; packets may be delivered to their destinations in an arbitrary sequence. Cranium uses two mechanisms: an automatic-receive interface for packet serialization and high performance, and a processor-initiated interface for flexibility. To minimize software overhead, Cranium is directly accessible by user-level programs. Protection for user-level message passing is implemented by mapping user-level handles into physical node identifiers and buffer addresses. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> John Y. Ngai and Charles L. Seitz. </author> <title> A Framework for Adaptive Routing in Mul-ticomputer Networks. </title> <booktitle> Proc. of the Symposium on Parallel Architectures and Algorithms, </booktitle> <month> May </month> <year> 1989. </year>
Reference-contexts: Simulation studies show that at high network loads, adaptive routing offers higher bandwidth and lower latency than the standard dimension-order oblivious algorithm, for a given fixed network packet size <ref> [1, 2, 4] </ref>. Adaptive routing improves fault tolerance, the ability to operate in the pres ence of failed components [3]. It is feasible to construct fast, economically competitive adaptive routers, such as the Chaos router [4]. In the network architectures we consider in this article, network packets have bounded length.
Reference: 2. <author> Kevin Bolding and Lawrence Snyder. </author> <title> Mesh and Torus Chaotic Routing. </title> <booktitle> Advanced Research in VLSI and Parallel Systems; Proc. of the 1992 Brown/MIT Conference, </booktitle> <month> March </month> <year> 1992, </year> <pages> pp. 333-347. </pages>
Reference-contexts: Simulation studies show that at high network loads, adaptive routing offers higher bandwidth and lower latency than the standard dimension-order oblivious algorithm, for a given fixed network packet size <ref> [1, 2, 4] </ref>. Adaptive routing improves fault tolerance, the ability to operate in the pres ence of failed components [3]. It is feasible to construct fast, economically competitive adaptive routers, such as the Chaos router [4]. In the network architectures we consider in this article, network packets have bounded length.
Reference: 3. <author> Kevin Bolding and William Yost. </author> <title> Design of a Router for Fault-Tolerant Networks. </title> <booktitle> Proc. of the 1994 Parallel Computer Routing and Communication Workshop, </booktitle> <publisher> Springer-Verlag, </publisher> <address> Seattle WA, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: Simulation studies show that at high network loads, adaptive routing offers higher bandwidth and lower latency than the standard dimension-order oblivious algorithm, for a given fixed network packet size [1, 2, 4]. Adaptive routing improves fault tolerance, the ability to operate in the pres ence of failed components <ref> [3] </ref>. It is feasible to construct fast, economically competitive adaptive routers, such as the Chaos router [4]. In the network architectures we consider in this article, network packets have bounded length. <p> Either the tardy packets eventually arrive and computation can proceed, or network failure is detected. In the latter case, the interface issues a command to the network for self-diagnosis and possible reconfiguration. See Bolding and Yost <ref> [3] </ref> for further information on fault detection and recovery in the Chaos network. Here is the organization of the rest of this report. Section 2 introduces the architecture of Cranium. Section 3 discusses run-time issues and high-level message passing protocols. Section 4 discusses related work on network interface design.
Reference: 4. <author> Kevin Bolding. </author> <title> Chaotic Routing: Design and Implementation of an Adaptive Multicomputer Network Router. </title> <type> PhD dissertation, </type> <institution> University of Washington, Dept. of CSE, </institution> <address> Seattle WA, </address> <month> July </month> <year> 1993. </year>
Reference-contexts: Simulation studies show that at high network loads, adaptive routing offers higher bandwidth and lower latency than the standard dimension-order oblivious algorithm, for a given fixed network packet size <ref> [1, 2, 4] </ref>. Adaptive routing improves fault tolerance, the ability to operate in the pres ence of failed components [3]. It is feasible to construct fast, economically competitive adaptive routers, such as the Chaos router [4]. In the network architectures we consider in this article, network packets have bounded length. <p> Adaptive routing improves fault tolerance, the ability to operate in the pres ence of failed components [3]. It is feasible to construct fast, economically competitive adaptive routers, such as the Chaos router <ref> [4] </ref>. In the network architectures we consider in this article, network packets have bounded length.
Reference: 5. <author> Edward W. Felten. </author> <title> Protocol Compilation: High-Performance Communication for Parallel Programs. </title> <type> PhD dissertation, </type> <institution> University of Washington, Dept. of CSE, </institution> <month> Sept. </month> <year> 1993. </year> <note> Available as UW CSE technical report TR 93-09-09. </note>
Reference-contexts: Designers of the older generation of network interfaces considered message passing to be an operating system service. The latency of message passing on a system with direct user-level access to the network is reduced by one to two orders of magnitude compared with a similar system-level interface. Felten <ref> [5] </ref> outlines the basic strategy for safe user-level communication that Cranium supports system partitioning, hardware validation for message destinations, gang scheduling, saving and restoring the network state, and separate user and kernel level communication. The third requirement is the ability to detect faults in the network at two levels. <p> A higher-speed version may involve a semi-custom solution using sea-of-gates technology. The current design of Cranium uses the standard gang-scheduling model for safe user-level access <ref> [5, 13] </ref>. Recently, there has been interest in studying general processor scheduling on multicomputers that have user-level support for message passing [11, 14]. The idea is to let multiple user processes execute at the same time inside the same machine partition.
Reference: 6. <author> Thorsten von Eicken et al. </author> <title> Active Messages: A Mechanism for Integrated Communication and Computation. </title> <booktitle> 19th Annual International Symposium on Computer Architecture, </booktitle> <month> May </month> <year> 1992, </year> <pages> pp. 256-266. </pages>
Reference-contexts: The user queue is the proper mechanism for funneling packets that arrive without prior arrangement; it provides the best support for synchronization, small data transfers and active message handlers <ref> [6] </ref>. After two nodes synchronize, the auto-receive channels can be used for high bandwidth communication. The restriction with the auto-receive channels is that the processor on the receiving node must initiate an auto-receive channel transfer before the processor on the sending node initiates its corresponding send channel transfer.
Reference: 7. <author> Oliver A. McBryan. </author> <title> An Overview of Message Passing Environments. </title> <booktitle> Parallel Computing 20(4), </booktitle> <month> April </month> <year> 1994, </year> <pages> pp. 417-444. </pages>
Reference-contexts: NX-style message passing example Most parallel message-passing codes use a standard interface for message passing, such as NX, Express, PVM, and many others <ref> [7] </ref>. Standard interfaces improve program portability and readability, compared with using the specific message passing primitives provided by the architecture. We now show a simple example of run-time support for Cranium using the semantics of csend () and crecv (), the most basic method of communication under NX [8].
Reference: 8. <author> Paul Pierce. </author> <title> The NX Message Passing Interface. </title> <booktitle> Parallel Computing 20(4), </booktitle> <month> April </month> <year> 1994, </year> <pages> pp. 463-480. </pages>
Reference-contexts: Standard interfaces improve program portability and readability, compared with using the specific message passing primitives provided by the architecture. We now show a simple example of run-time support for Cranium using the semantics of csend () and crecv (), the most basic method of communication under NX <ref> [8] </ref>. Figure 4 illustrates how the NX commands are implemented in terms of Cranium commands, for the case of medium length messages (between 32 and 32K bytes). In the figure, italics represent pseudocode, and roman type represents NI commands.
Reference: 9. <author> Shekhar Borkar et al. </author> <title> Supporting Systolic and Memory Communication in iWarp. </title> <booktitle> Proc. of the 17th Annual International Symposium on Computer Architecture, </booktitle> <address> Seattle WA, </address> <month> May </month> <year> 1990, </year> <pages> pp. 70-81. </pages>
Reference-contexts: Examples include iWarp <ref> [9] </ref>, MDP (J-machine) [10], and *T [11]. The advantage of tightly-coupled systems is an order of magnitude lower message latency than a comparable bus-based interface. However, there are several disadvantages to this strategy. By placing the interface onto the processor chip, some other functionality must be eliminated or moved off-chip.
Reference: 10. <author> William J. Dally et al. </author> <title> The Message-Driven Processor: A Multicomputer Processing Node with Efficient Mechanisms. </title> <booktitle> IEEE Micro, </booktitle> <month> April </month> <year> 1992, </year> <pages> pp. 23-39. </pages>
Reference-contexts: Examples include iWarp [9], MDP (J-machine) <ref> [10] </ref>, and *T [11]. The advantage of tightly-coupled systems is an order of magnitude lower message latency than a comparable bus-based interface. However, there are several disadvantages to this strategy. By placing the interface onto the processor chip, some other functionality must be eliminated or moved off-chip.
Reference: 11. <author> Greg M. Papadopoulos et al. </author> <title> *T: Integrated Building Blocks for Parallel Computing. </title> <booktitle> Proc. of Supercomputing '93, </booktitle> <address> Portland OR, </address> <month> November </month> <year> 1993, </year> <pages> pp. 624-635. </pages>
Reference-contexts: Examples include iWarp [9], MDP (J-machine) [10], and *T <ref> [11] </ref>. The advantage of tightly-coupled systems is an order of magnitude lower message latency than a comparable bus-based interface. However, there are several disadvantages to this strategy. By placing the interface onto the processor chip, some other functionality must be eliminated or moved off-chip. <p> A higher-speed version may involve a semi-custom solution using sea-of-gates technology. The current design of Cranium uses the standard gang-scheduling model for safe user-level access [5, 13]. Recently, there has been interest in studying general processor scheduling on multicomputers that have user-level support for message passing <ref> [11, 14] </ref>. The idea is to let multiple user processes execute at the same time inside the same machine partition.
Reference: 12. <author> Greg M. Papadopoulos. </author> <title> Personal communication. </title> <booktitle> Supercomputing '93, </booktitle> <address> Portland OR, </address> <month> November </month> <year> 1993. </year>
Reference-contexts: However, there are several disadvantages to this strategy. By placing the interface onto the processor chip, some other functionality must be eliminated or moved off-chip. In the *T design, about 15 per cent of the processor's chip area is dedicated to the network interface <ref> [12] </ref>. The resulting single-processor performance is less than the fastest possible. Another disadvantage to the tight coupling is the extra amount of engineering effort needed to design and build the interface. Unlike the case for a bus-based interface, this effort cannot be easily amortized across a family of different processors.
Reference: 13. <author> Charles Leiserson et al. </author> <title> The Network Architecture of the CM-5. </title> <booktitle> Symposium on Parallel Algorithms and Architectures, </booktitle> <year> 1992, </year> <pages> pp. 272-285. </pages>
Reference-contexts: Continuing research in this area may eventually solve these problems. In the meantime, bus-based interfacing remains the most economically viable strategy for implementing multicomputers, using standard workstation processors and memories. Examples of systems using bus-based network interfaces with direct user-level access are CM-5 <ref> [13] </ref>, Shrimp [14], Hamlyn [15] and Cranium. 4.2 Comparison of Cranium with Shrimp and Hamlyn Cranium is highly similar to the Shrimp processor-network interface [14]. In both systems, messages are sent and received at the cost of only a few user-level instructions. <p> A higher-speed version may involve a semi-custom solution using sea-of-gates technology. The current design of Cranium uses the standard gang-scheduling model for safe user-level access <ref> [5, 13] </ref>. Recently, there has been interest in studying general processor scheduling on multicomputers that have user-level support for message passing [11, 14]. The idea is to let multiple user processes execute at the same time inside the same machine partition.
Reference: 14. <author> Mattias A. Blumrich et al. </author> <title> Virtual Memory-Mapped Network Interface for the SHRIMP Multicomputer. </title> <booktitle> Proc. of the 21st International Symposium on Computer Architecture, </booktitle> <address> Chicago IL, </address> <month> April </month> <year> 1994, </year> <pages> pp. 142-153. </pages>
Reference-contexts: Continuing research in this area may eventually solve these problems. In the meantime, bus-based interfacing remains the most economically viable strategy for implementing multicomputers, using standard workstation processors and memories. Examples of systems using bus-based network interfaces with direct user-level access are CM-5 [13], Shrimp <ref> [14] </ref>, Hamlyn [15] and Cranium. 4.2 Comparison of Cranium with Shrimp and Hamlyn Cranium is highly similar to the Shrimp processor-network interface [14]. In both systems, messages are sent and received at the cost of only a few user-level instructions. <p> Examples of systems using bus-based network interfaces with direct user-level access are CM-5 [13], Shrimp <ref> [14] </ref>, Hamlyn [15] and Cranium. 4.2 Comparison of Cranium with Shrimp and Hamlyn Cranium is highly similar to the Shrimp processor-network interface [14]. In both systems, messages are sent and received at the cost of only a few user-level instructions. Both systems use a separate phase to map user-space buffers with the operating system and the network interface. Both systems use DMA, rather than the programmed-I/O approach used by the CM-5 interface. <p> A higher-speed version may involve a semi-custom solution using sea-of-gates technology. The current design of Cranium uses the standard gang-scheduling model for safe user-level access [5, 13]. Recently, there has been interest in studying general processor scheduling on multicomputers that have user-level support for message passing <ref> [11, 14] </ref>. The idea is to let multiple user processes execute at the same time inside the same machine partition.
Reference: 15. <author> John Wilkes. </author> <title> Hamlyn an Interface for Sender-Based Communications. </title> <type> Technical Report HPL-OSR-92-13, </type> <institution> Hewlett-Packard Company, HP Labs, Operating System Research Dept., </institution> <month> November </month> <year> 1992. </year>
Reference-contexts: Continuing research in this area may eventually solve these problems. In the meantime, bus-based interfacing remains the most economically viable strategy for implementing multicomputers, using standard workstation processors and memories. Examples of systems using bus-based network interfaces with direct user-level access are CM-5 [13], Shrimp [14], Hamlyn <ref> [15] </ref> and Cranium. 4.2 Comparison of Cranium with Shrimp and Hamlyn Cranium is highly similar to the Shrimp processor-network interface [14]. In both systems, messages are sent and received at the cost of only a few user-level instructions. <p> Cranium can send the contents of a single buffer to a set of nodes without copying data or invoking the operating system, which is not possible under the current design of Shrimp. Cranium is also similar to Hamlyn <ref> [15] </ref>. Both interfaces are designed to work with a network that deliver packets out-of-order. Both interfaces make use of multiple DMA contexts, called mapping table slots in Hamlyn, similar to Cranium's channels.
Reference: 16. <author> Robert Bedichek. </author> <title> The Meerkat Multicomputer. </title> <type> PhD dissertation, </type> <institution> University of Washington, Dept. of CSE, </institution> <address> Seattle WA, </address> <month> June </month> <year> 1994. </year>
Reference-contexts: For simulation, we can take advantage of two existing behavioral simulation tools: a network simulator and a processor simulator. The Chaos network simulator is a very flexible tool for modeling a wide variety of routing algorithms, including chaotic routing, oblivious routing and minimal adaptive routing. The Meerkat processor simulator <ref> [16] </ref> is a functional simulator for multiprocessors, and is enhanced with timing models for caches, TLBs, register scoreboarding and other processor resources. The simulator is functionally equivalent to a physical multiprocessor prototype system that uses a grid of busses for its interconnect.
References-found: 16

