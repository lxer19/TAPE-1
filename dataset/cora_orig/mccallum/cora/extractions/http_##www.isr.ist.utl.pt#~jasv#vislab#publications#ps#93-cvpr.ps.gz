URL: http://www.isr.ist.utl.pt/~jasv/vislab/publications/ps/93-cvpr.ps.gz
Refering-URL: http://www.isr.ist.utl.pt/~jasv/vislab/publications/publications.html
Root-URL: 
Email: e-mail: jasv@kappa.ist.utl.pt e-mail:giulio@vision.dist.unige.it  
Title: Divergent Stereo for Robot Navigation Learning from Bees example of reflex-type control of motion, driven
Author: J. Santos-Victor G. Sandini, F. Curotto, S. Garibaldi 
Note: An  is presented. In particular it is shown  
Address: Portugal LIRA-Lab, Genoa Italy  
Affiliation: DEEC Instituto Superior Tecnico DIST University of Genova ISR, Lisboa  
Abstract: The approach is based on the use of two cameras mounted on a mobile robot and with the optical axis directed in opposite directions such that the two visual fields do not overlap (divergent stereo); Range computation is based on the computation of the apparent image speed on images acquired during robot's motion. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M.V. Srinivasan, M. Lehrer, W.H. Kirchner, and S.W. Zhang. </author> <title> Range perception through apparent image speed in freely flying honeybees. </title> <journal> Visual Neuroscience, </journal> <volume> 6 </volume> <pages> 519-535, </pages> <year> 1991. </year>
Reference-contexts: In spite of these limitations we will demonstrate a variety of navigation capabilities based upon very simple, direct estimation of "range" extracted from 2D (or even 1D) optical flow. The inspiration of the ideas presented here derives from some recent research results, on the behavior of honeybees <ref> [1] </ref> and, more generally, from the use some insects make, of flow field information [2] to control their flying trajectory in unconstrained, hostile envi-ronments [3]. <p> A simple example would suffice to explain the kind of simplifications that can be gained by solving apparently complex navigation problems using qualitative measures of optical flow. In the experiment of Srinivasan <ref> [1] </ref> honeybees were trained to navigate along corridors in order to reach a source of food. <p> What kind of information is used to maintain the bee in the middle of the corridor and how it is computed is, therefore, a non trivial question. The answer presented in <ref> [1] </ref>, is rather simple and it is based on the difference between the velocity information computed from the left and the right eye: if the bee is in the middle of the corridor the two velocities are the same, if the bee is closer to one wall, the velocity of the
Reference: [2] <author> G.A. Horridge. </author> <title> A theory of insect vision: velocity parallax. </title> <journal> Proceedings of the Royal Society of London, B, </journal> <volume> 229 </volume> <pages> 13-27, </pages> <year> 1986. </year>
Reference-contexts: The inspiration of the ideas presented here derives from some recent research results, on the behavior of honeybees [1] and, more generally, from the use some insects make, of flow field information <ref> [2] </ref> to control their flying trajectory in unconstrained, hostile envi-ronments [3]. From the computational view point the problems to be solved are far more complex than what we usually do in controlling a mobile robot moving on a flat surface.
Reference: [3] <author> N. Franceschini, J. Pichon, and C. Blanes. </author> <title> Real time visuomotor control: from flies to robots. </title> <booktitle> In Fifth Int. Conference on Advanced Robotics, </booktitle> <address> Pisa, Italy, </address> <month> June </month> <year> 1991. </year>
Reference-contexts: The inspiration of the ideas presented here derives from some recent research results, on the behavior of honeybees [1] and, more generally, from the use some insects make, of flow field information [2] to control their flying trajectory in unconstrained, hostile envi-ronments <ref> [3] </ref>. From the computational view point the problems to be solved are far more complex than what we usually do in controlling a mobile robot moving on a flat surface.
Reference: [4] <author> B. K. P. Horn and B. G. Schunck. </author> <title> Determining optical flow. </title> <journal> Artificial Intelligence, </journal> <volume> 17 No.1-3:185-204, </volume> <year> 1981. </year>
Reference-contexts: The optical flow V = (u; v), is usually obtained by using the fundamental optical flow constraint <ref> [4] </ref>, shown in equation (1), or by imposing second order stationarity constraints in the brightness function [5, 6], according to equation (2): @I u + @y @I = 0 (1) dt By using expression (2), one ends up with the following system of equations, which can be solved to obtain both
Reference: [5] <author> Nagel H. </author> <title> On the estimation of optical flow: Relations between different approaches and some new results. </title> <journal> Artificial Intelligence, </journal> <volume> 33 </volume> <pages> 299-323, </pages> <year> 1987. </year>
Reference-contexts: The optical flow V = (u; v), is usually obtained by using the fundamental optical flow constraint [4], shown in equation (1), or by imposing second order stationarity constraints in the brightness function <ref> [5, 6] </ref>, according to equation (2): @I u + @y @I = 0 (1) dt By using expression (2), one ends up with the following system of equations, which can be solved to obtain both components of the optical flow.
Reference: [6] <author> S. Uras, F. Girosi, A. Verri, and V. Torre. </author> <title> Computational approach to motion perception. </title> <journal> Biological Cybernetics, </journal> <volume> 60 </volume> <pages> 69-87, </pages> <year> 1988. </year>
Reference-contexts: The optical flow V = (u; v), is usually obtained by using the fundamental optical flow constraint [4], shown in equation (1), or by imposing second order stationarity constraints in the brightness function <ref> [5, 6] </ref>, according to equation (2): @I u + @y @I = 0 (1) dt By using expression (2), one ends up with the following system of equations, which can be solved to obtain both components of the optical flow.
Reference: [7] <author> J. Santos-Victor, G. Sandini, F. Curotto, and S. Garibaldi. </author> <title> Divergent stereo for robot navigation: A step forward to a robotic bee. </title> <note> Submitted for publication, </note> <year> 1993. </year>
Reference-contexts: In particular it is shown how a difficult task like navigating through a narrow funneled corridor while avoiding an obstacle is pos sible without the need for accurate depth or motion estimation. In a more extended paper <ref> [7] </ref> this kind of reactive control will be presented in more details and its extension to forward-velocity control and discontinuities in optical flow measures will be described. In this extended paper a comparison with a similar approach (which was published after our submission to CVPR) is also discussed [8]. 1
Reference: [8] <author> D. Coombs and K. Roberts. </author> <title> Centering behaviour using peripheral vision. In D.P. </title> <editor> Casasent, editor, </editor> <booktitle> Intelligent Robots and Computer Vision XI: Algorithms, Techniques a nd Active Vision, </booktitle> <pages> pages 714-21. </pages> <booktitle> SPIE, </booktitle> <volume> Vol. 1825, </volume> <month> Nov. </month> <year> 1992. </year> <note> 1 Acknowledgements: The research described in this paper has been supported by the Special Projects on Robotics of the Italian National Council of Research and bu the Esprit Project VAP-2 </note>
Reference-contexts: In this extended paper a comparison with a similar approach (which was published after our submission to CVPR) is also discussed <ref> [8] </ref>. 1
References-found: 8

