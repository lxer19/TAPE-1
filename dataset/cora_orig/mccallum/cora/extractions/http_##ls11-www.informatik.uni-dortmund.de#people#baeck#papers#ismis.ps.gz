URL: http://ls11-www.informatik.uni-dortmund.de/people/baeck/papers/ismis.ps.gz
Refering-URL: http://ls11-www.informatik.uni-dortmund.de/people/baeck/ea_general.html
Root-URL: http://ls11-www.informatik.uni-dortmund.de/people/baeck/ea_general.html
Phone: 2  
Title: Intelligent Mutation Rate Control in Canonical Genetic Algorithms  
Author: Thomas Back and Martin Schutz 
Address: Joseph-von-Fraunhofer-Str. 20, D-44227 Dortmund  XI, D-44221 Dortmund  
Affiliation: 1 Informatik Centrum Dortmund, Center for Applied Systems Analysis (CASA),  Universitat Dortmund, Fachbereich Informatik, LS  
Abstract: The role of the mutation rate in canonical genetic algorithms is investigated by comparing a constant setting, a deterministically varying, time-dependent mutation rate schedule, and a self-adaptation mechanism for individual mutation rates following the principle of self-adaptation as used in evolution strategies. The power of the self-adaptation mechanism is illustrated by a time-varying optimization problem, where mutation rates have to adapt continuously in order to follow the optimum. The strengths of the proposed deterministic schedule and the self-adaptation method are demonstrated by a comparison of their performance on difficult combinatorial optimization problems (multiple knapsack, maximum cut and maximum independent set in graphs). Both methods are shown to perform significantly better than the canonical genetic algorithm, and the deterministic schedule yields the best results of all control mechanisms compared. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> Th. </author> <title> Back. The interaction of mutation rate, selection, and self-adaptation within a genetic algorithm. </title> <editor> In R. Manner and B. Manderick, editors, </editor> <booktitle> Parallel Problem Solving from Nature, </booktitle> <volume> 2, </volume> <pages> pages 85-94. </pages> <publisher> Elsevier, </publisher> <address> Amsterdam, </address> <year> 1992. </year>
Reference-contexts: In contrast to these findings, however, practical applications of genetic algorithms often favor larger or non-constant settings of the mutation rate. Some recently developed theory regarding the optimal mutation rate schedule for a simple objective function provides a good confirmation of the usefulness of lar-ger, varying mutation rates <ref> [1, 19] </ref>. The theoretical result is used in section 2 to derive a general deterministic mutation rate control schedule for canonical genetic algorithms. <p> In section 3, we present a self-adaptation mechanism for individual mutation rates in genetic algorithms. Finally, section 4 presents experimental results regarding the performance of the mutation rate control mechanisms on some difficult combinatorial optimization problems. 2 Deterministic Mutation Rate Schedules Independently of each other, Muhlenbein [19] and Back <ref> [1] </ref> investigated the optimal mutation rate for a simple (1+1)-algorithm (a single parent generates an offspring by means of mutation and the better of both survives for the next generation) and the objective function f (x) = P n i=1 x i ("counting ones"). <p> An exact analytical expression for the improvement probability (for the counting ones function) as presented in <ref> [1] </ref>, however, clarifies that the optimal mutation probability depends strongly on the objective function value f (x) and follows a hyperbolic law of the form p = (2 (f (x) + 1) n) 1 (1) (see [3], chapter 6). <p> individual a 0 = (x 0 1 ; : : : ; x 0 where x 0 i = 1 x i if U (<ref> [0; 1] </ref>) &lt; p 0 (otherwise, x 0 i = x i ), and U ([0; 1]) denotes a uniform random number sampled from the interval [0; 1]. Crossover is presently applied only to the binary vector and has no impact on the mutation rate, but it is certainly worthwhile to investigate the effect of intermediary recombination on mutation rates [6].
Reference: 2. <author> Th. </author> <title> Back. Self-Adaptation in Genetic Algorithms. </title> <editor> In F. J. Varela and P. Bourgine, editors, </editor> <booktitle> Proceedings of the First European Conference on Artificial Life, </booktitle> <pages> pages 263-271. </pages> <publisher> The MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1992. </year>
Reference-contexts: Early efforts include the self-adaptation of a binary representation of the crossover operator [22] and a binary representation of the mutation probability for each individual <ref> [2] </ref>, but both were of limited success.
Reference: 3. <author> Th. </author> <title> Back. Evolutionary Algorithms in Theory and Practice. </title> <publisher> Oxford University Press, </publisher> <address> New York, </address> <year> 1996. </year>
Reference-contexts: analytical expression for the improvement probability (for the counting ones function) as presented in [1], however, clarifies that the optimal mutation probability depends strongly on the objective function value f (x) and follows a hyperbolic law of the form p = (2 (f (x) + 1) n) 1 (1) (see <ref> [3] </ref>, chapter 6). Notice that the resulting mutation probability decreases from a value of 1/2 to 1=n for f (x) 2 fn=2; : : :; n 1g, i.e., the optimal mutation rate control deviates strongly from the general assumption that genetic algorithms need a very small mutation rate. <p> Though the gain achieved by control schedule (1) regarding the time to ab-sorbtion is small for the counting ones problem (see <ref> [3] </ref>, chapter 6), we consider it interesting to test an analogue of equation (1) on more complex objective functions.
Reference: 4. <author> Th. Back and S. Khuri. </author> <title> An evolutionary heuristic for the maximum independent set problem. </title> <booktitle> In Proceedings of the First IEEE Conference on Evolutionary Computation, </booktitle> <pages> pages 531-535. </pages> <publisher> IEEE Press, </publisher> <year> 1994. </year>
Reference-contexts: This setting yields surprisingly good results for a variety of NP-hard combinatorial optimization problems such as the multiple knapsack problem [18], the minimum vertex cover problem [16], the maximum independent set problem <ref> [4] </ref>, and others [17]. <p> instances of combinatorial optimization problems that have been shown in previos work to be difficult for canonical genetic algorithms: A multiple 0/1 knapsack problem (n = 105) [18], a maximum cut problem for weighted graphs (n = 100) [17], and a maximum independent set problem for graphs (n = 100) <ref> [4] </ref>. <p> knapsack problem (called "weing7-105") stems from Weingartner and Ness [26], the graph for the maximum cut problem is a regular, scalable graph as described in [17], and the graph for the maximum independent set problem is a random graph with small edge density (0.1), obtained by a method described in <ref> [4] </ref>. It is relatively straightforward to represent potential solutions to these problems by binary strings. <p> All problems are maximization problems. For further details regarding the problem definitions and the objective functions, the reader is referred to <ref> [4, 17, 18] </ref>. A genetic algorithm with proportional selection (population size 100) and (15,100)-selection was applied to these three problems, using a constant mutation rate of 1=n, the self-adaptation of mutation rates (with fl = 0:22) as presented in section 3, and the deterministic schedule proposed in section 2.
Reference: 5. <author> Th. Back and M. Schutz. </author> <title> Evolution strategies for mixed-integer optimization of optical multilayer systems. </title> <editor> In J. R. McDonnell, R. G. Reynolds, and D. B. Fogel, editors, </editor> <booktitle> Evolutionary Programming IV: Proceedings of the Fourth Annual Conference on Evolutionary Programming, </booktitle> <pages> pages 33-51. </pages> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1995. </year>
Reference-contexts: Small changes are more likely than large ones. A modification by a factor c occurs with the same probability as a modific ation by 1=c. Based on these requirements, a logistic transformation of the form p 0 = 1 + p 1 can be derived <ref> [5, 20] </ref>, such that p 0 is distributed according to a logistic normal distribution with probability density function f p 0 (x) = p exp B ln x j 2 1 A ; (4) where i = ln p The learning rate fl in equation (3) allows for a control of
Reference: 6. <author> Th. Back and H.-P. Schwefel. </author> <title> An overview of evolutionary algorithms for parameter optimization. </title> <journal> Evolutionary Computation, </journal> <volume> 1(1) </volume> <pages> 1-23, </pages> <year> 1993. </year>
Reference-contexts: 1 Introduction Genetic Algorithms [11, 14] are the best known representative of a class of direct random search methods called evolutionary algorithms <ref> [6] </ref>, which are widely used with great success to solve complex optimization and adaptation problems. <p> An alternative mechanism for controlling the mutation rate consists in the on-line learning or self-adaptation of this parameter, which works with great success in evolution strategies and evolutionary programming <ref> [6] </ref>. In section 3, we present a self-adaptation mechanism for individual mutation rates in genetic algorithms. <p> It would probably be more desirable, however, if the algorithm could adapt its mutation rate according to the topology of the objective function, using the principle of strategy parameter self-adaptation as developed by Schwefel for evolution strategies <ref> [6] </ref>. 3 Two-Level Learning in Genetic Algorithms A fascinating alternative to the typical exogenous prescription of strategy parameters consists in the principle of strategy parameter self-adaptation or on-line learning as first implemented by Schwefel in the context of multimembered evolution strategies [23, 24, 25]. <p> Notice that the standard deviation is also subject to mutation (using a logarithmic normal distribution), and the mutated oe is used as the standard deviation for a modification of the x i . More general variants of this mechanism are described e.g. in <ref> [6] </ref>. The self-adaptation principle exploits the indirect link between favorable strategy parameters and objective function values and facilitates an adaptation on the level of the strategy parameters almost completely without exogenous control. Consequently, self-adapting strategies are able to adapt their parameters implicitly, according to the topology of the objective function. <p> Crossover is presently applied only to the binary vector and has no impact on the mutation rate, but it is certainly worthwhile to investigate the effect of intermediary recombination on mutation rates <ref> [6] </ref>.
Reference: 7. <editor> L. J. Eshelman, R. A. Caruna, and J. D. Schaffer. </editor> <title> Biases in the crossover landscape. </title> <editor> In J. D. Schaffer, editor, </editor> <booktitle> Proceedings of the 3rd International Conference on Genetic Algorithms, </booktitle> <pages> pages 10-19. </pages> <publisher> Morgan Kaufmann Publishers, </publisher> <address> San Mateo, CA, </address> <year> 1989. </year>
Reference-contexts: The crossover operator (applied with crossover probability p c ) exchanges information between different individuals according to a number of crossover points which are randomly chosen on the individual. A choice of two crossover points is recommended e.g. in <ref> [7] </ref>. This paper focuses on the mutation operator, which introduces innovation into the population by inverting bits with a probability p m per bit.
Reference: 8. <author> D. B. Fogel. </author> <title> Evolutionary Computation: Toward a New Philosophy of Machine Intelligence. </title> <publisher> IEEE Press, </publisher> <address> Piscataway, NJ, </address> <year> 1995. </year>
Reference-contexts: Independently of this, Fogel et al. [9] developed an almost identical procedure for evolutionary programming (see also <ref> [8] </ref>). The self-adaptation principle incorporates certain strategy parameters (such as variances and covariances of a generalized, n-dimensional normal distribution in case of evolution strategies) into the representation of each individual.
Reference: 9. <editor> D. B. Fogel, L. J. Fogel, and W. Atmar. </editor> <title> Meta-evolutionary programming. </title> <editor> In R. R. Chen, editor, </editor> <booktitle> Proc. 25th Asilomar Conference on Signals, Systems and Computers, </booktitle> <pages> pages 540-545. </pages> <address> Pacific Grove, CA, </address> <year> 1991. </year>
Reference-contexts: Independently of this, Fogel et al. <ref> [9] </ref> developed an almost identical procedure for evolutionary programming (see also [8]). The self-adaptation principle incorporates certain strategy parameters (such as variances and covariances of a generalized, n-dimensional normal distribution in case of evolution strategies) into the representation of each individual.
Reference: 10. <editor> L. Fogel, D. B. Fogel, and P. J. Angeline. </editor> <title> A preliminary investigation on extending evolutionary programming to include self-adaptation on finite state machines. </title> <journal> Informatica, </journal> <volume> 18 </volume> <pages> 387-398, </pages> <year> 1994. </year>
Reference-contexts: In the second case, the binary representation of mutation rates hampered their efficient fine-tuning by self-adaptation. Recently, Fogel et al. transferred the method from evolutionary programming to finite state machines by using an additive normally distributed modification of mutation rates <ref> [10] </ref>, but this mechanism suffers from the difficulty to guarantee that mutation rates have to stay in the interval ]0; 1 [.
Reference: 11. <author> D. E. Goldberg. </author> <title> Genetic algorithms in search, optimization and machine learning. </title> <publisher> Addison Wesley, </publisher> <address> Reading, MA, </address> <year> 1989. </year>
Reference-contexts: 1 Introduction Genetic Algorithms <ref> [11, 14] </ref> are the best known representative of a class of direct random search methods called evolutionary algorithms [6], which are widely used with great success to solve complex optimization and adaptation problems. <p> This operator is typically assessed as a secondary one which is of little importance in comparison to crossover (e.g., [14], p. 111), such that most canonical genetic algorithms work with small, constant settings of p m 2 [0:001; 0:01] (see e.g. <ref> [11, 12, 15, 21] </ref>). In contrast to these findings, however, practical applications of genetic algorithms often favor larger or non-constant settings of the mutation rate.
Reference: 12. <author> J. J. Grefenstette. </author> <title> Optimization of control parameters for genetic algorithms. </title> <journal> IEEE Transactions on Systems, Man and Cybernetics, </journal> <volume> SMC-16(1):122-128, </volume> <year> 1986. </year>
Reference-contexts: This operator is typically assessed as a secondary one which is of little importance in comparison to crossover (e.g., [14], p. 111), such that most canonical genetic algorithms work with small, constant settings of p m 2 [0:001; 0:01] (see e.g. <ref> [11, 12, 15, 21] </ref>). In contrast to these findings, however, practical applications of genetic algorithms often favor larger or non-constant settings of the mutation rate. <p> The results are shown in figure 1 for proportional selection (with linear dynamic scaling and a scaling window of 5 generations; see <ref> [12] </ref>) and figure 2 for (15,100)-selection.
Reference: 13. <author> F. Hoffmeister and Th. </author> <title> Back. Genetic self-learning. </title> <editor> In F. J. Varela and P. Bourgine, editors, </editor> <booktitle> Proceedings of the 1st European Conference on Artificial Life, </booktitle> <pages> pages 227-235. </pages> <publisher> The MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1992. </year>
Reference-contexts: The right plot shows the corresponding best objective function value in the population. The optimum location is inverted every 250 generations. In order to test the feasibility of the new mechanism, an experiment from evolution strategies (with a time-varying version of the sphere model; see <ref> [13] </ref>) is transferred to the self-adaptive genetic algorithm as follows: The counting ones problem f (x) = P n i=1 x i ! min is modified by switching between f and f 0 (x) = n f (x) ! min every g generations.
Reference: 14. <author> J. H. Holland. </author> <title> Adaptation in natural and artificial systems. </title> <publisher> The University of Michigan Press, </publisher> <address> Ann Arbor, MI, </address> <year> 1975. </year>
Reference-contexts: 1 Introduction Genetic Algorithms <ref> [11, 14] </ref> are the best known representative of a class of direct random search methods called evolutionary algorithms [6], which are widely used with great success to solve complex optimization and adaptation problems. <p> This paper focuses on the mutation operator, which introduces innovation into the population by inverting bits with a probability p m per bit. This operator is typically assessed as a secondary one which is of little importance in comparison to crossover (e.g., <ref> [14] </ref>, p. 111), such that most canonical genetic algorithms work with small, constant settings of p m 2 [0:001; 0:01] (see e.g. [11, 12, 15, 21]). In contrast to these findings, however, practical applications of genetic algorithms often favor larger or non-constant settings of the mutation rate.
Reference: 15. <author> K. A. De Jong. </author> <title> An analysis of the behaviour of a class of genetic adaptive systems. </title> <type> PhD thesis, </type> <institution> University of Michigan, </institution> <year> 1975. </year>
Reference-contexts: This operator is typically assessed as a secondary one which is of little importance in comparison to crossover (e.g., [14], p. 111), such that most canonical genetic algorithms work with small, constant settings of p m 2 [0:001; 0:01] (see e.g. <ref> [11, 12, 15, 21] </ref>). In contrast to these findings, however, practical applications of genetic algorithms often favor larger or non-constant settings of the mutation rate.
Reference: 16. <author> S. Khuri and Th. </author> <title> Back. An evolutionary heuristic for the minimum vertex cover problem. </title> <editor> In J. Kunze and H. Stoyan, editors, </editor> <booktitle> KI-94 Workshops (Extended Abstracts), </booktitle> <pages> pages 83-84. </pages> <institution> Gesellschaft fur Informatik e. V., Bonn, </institution> <year> 1994. </year>
Reference-contexts: This setting yields surprisingly good results for a variety of NP-hard combinatorial optimization problems such as the multiple knapsack problem [18], the minimum vertex cover problem <ref> [16] </ref>, the maximum independent set problem [4], and others [17].
Reference: 17. <author> S. Khuri, Th. Back, and J. Heitkotter. </author> <title> An evolutionary approach to combinatorial optimization problems. </title> <editor> In D. Cizmar, editor, </editor> <booktitle> Proceedings of the 22nd Annual ACM Computer Science Conference, </booktitle> <pages> pages 66-73. </pages> <publisher> ACM Press, </publisher> <address> New York, </address> <year> 1994. </year>
Reference-contexts: This setting yields surprisingly good results for a variety of NP-hard combinatorial optimization problems such as the multiple knapsack problem [18], the minimum vertex cover problem [16], the maximum independent set problem [4], and others <ref> [17] </ref>. <p> To test the global convergence behavior, we take three instances of combinatorial optimization problems that have been shown in previos work to be difficult for canonical genetic algorithms: A multiple 0/1 knapsack problem (n = 105) [18], a maximum cut problem for weighted graphs (n = 100) <ref> [17] </ref>, and a maximum independent set problem for graphs (n = 100) [4]. The knapsack problem (called "weing7-105") stems from Weingartner and Ness [26], the graph for the maximum cut problem is a regular, scalable graph as described in [17], and the graph for the maximum independent set problem is a <p> [18], a maximum cut problem for weighted graphs (n = 100) <ref> [17] </ref>, and a maximum independent set problem for graphs (n = 100) [4]. The knapsack problem (called "weing7-105") stems from Weingartner and Ness [26], the graph for the maximum cut problem is a regular, scalable graph as described in [17], and the graph for the maximum independent set problem is a random graph with small edge density (0.1), obtained by a method described in [4]. It is relatively straightforward to represent potential solutions to these problems by binary strings. <p> All problems are maximization problems. For further details regarding the problem definitions and the objective functions, the reader is referred to <ref> [4, 17, 18] </ref>. A genetic algorithm with proportional selection (population size 100) and (15,100)-selection was applied to these three problems, using a constant mutation rate of 1=n, the self-adaptation of mutation rates (with fl = 0:22) as presented in section 3, and the deterministic schedule proposed in section 2.
Reference: 18. <author> S. Khuri, Th. Back, and J. Heitkotter. </author> <title> The zero/one multiple knapsack problem and genetic algorithms. </title> <editor> In E. Deaton, D. Oppenheim, J. Urban, and H. Berghel, editors, </editor> <booktitle> Proceedings of the 1994 ACM Symposium on Applied Computing, </booktitle> <pages> pages 188-193. </pages> <publisher> ACM Press, </publisher> <address> New York, </address> <year> 1994. </year>
Reference-contexts: Using an approximation of the probability for improving the objective function value by mutation, Muhlenbein arrived at an optimal mutation rate p = 1=n. This setting yields surprisingly good results for a variety of NP-hard combinatorial optimization problems such as the multiple knapsack problem <ref> [18] </ref>, the minimum vertex cover problem [16], the maximum independent set problem [4], and others [17]. <p> To test the global convergence behavior, we take three instances of combinatorial optimization problems that have been shown in previos work to be difficult for canonical genetic algorithms: A multiple 0/1 knapsack problem (n = 105) <ref> [18] </ref>, a maximum cut problem for weighted graphs (n = 100) [17], and a maximum independent set problem for graphs (n = 100) [4]. <p> All problems are maximization problems. For further details regarding the problem definitions and the objective functions, the reader is referred to <ref> [4, 17, 18] </ref>. A genetic algorithm with proportional selection (population size 100) and (15,100)-selection was applied to these three problems, using a constant mutation rate of 1=n, the self-adaptation of mutation rates (with fl = 0:22) as presented in section 3, and the deterministic schedule proposed in section 2.
Reference: 19. <author> H. Muhlenbein. </author> <title> How genetic algorithms really work: </title> <editor> I. mutation and hillclimbing. In R. Manner and B. Manderick, editors, </editor> <booktitle> Parallel Problem Solving from Nature 2, </booktitle> <pages> pages 15-25. </pages> <publisher> Elsevier, </publisher> <address> Amsterdam, </address> <year> 1992. </year>
Reference-contexts: In contrast to these findings, however, practical applications of genetic algorithms often favor larger or non-constant settings of the mutation rate. Some recently developed theory regarding the optimal mutation rate schedule for a simple objective function provides a good confirmation of the usefulness of lar-ger, varying mutation rates <ref> [1, 19] </ref>. The theoretical result is used in section 2 to derive a general deterministic mutation rate control schedule for canonical genetic algorithms. <p> In section 3, we present a self-adaptation mechanism for individual mutation rates in genetic algorithms. Finally, section 4 presents experimental results regarding the performance of the mutation rate control mechanisms on some difficult combinatorial optimization problems. 2 Deterministic Mutation Rate Schedules Independently of each other, Muhlenbein <ref> [19] </ref> and Back [1] investigated the optimal mutation rate for a simple (1+1)-algorithm (a single parent generates an offspring by means of mutation and the better of both survives for the next generation) and the objective function f (x) = P n i=1 x i ("counting ones").
Reference: 20. <institution> J. Obalek. Rekombinationsoperatoren fur Evolutionsstrategien. Diplomarbeit, Universitat Dortmund, Fachbereich Informatik, </institution> <year> 1994. </year>
Reference-contexts: the first case, the limited success is due to the weak impact of a particular crossover operator on the fitness of an individual, such that no particular operator is clearly preferred (with the exception of specially de signed objective functions which strongly favor a particular kind of crossover operator; see <ref> [20] </ref>). In the second case, the binary representation of mutation rates hampered their efficient fine-tuning by self-adaptation. <p> Small changes are more likely than large ones. A modification by a factor c occurs with the same probability as a modific ation by 1=c. Based on these requirements, a logistic transformation of the form p 0 = 1 + p 1 can be derived <ref> [5, 20] </ref>, such that p 0 is distributed according to a logistic normal distribution with probability density function f p 0 (x) = p exp B ln x j 2 1 A ; (4) where i = ln p The learning rate fl in equation (3) allows for a control of
Reference: 21. <author> J. D. Schaffer, R. A. Caruana, L. J. Eshelman, and R. Das. </author> <title> A study of control parameters affecting online performance of genetic algorithms for function optimization. </title> <editor> In J. D. Schaffer, editor, </editor> <booktitle> Proceedings of the 3rd International Conference on Genetic Algorithms, </booktitle> <pages> pages 51-60. </pages> <publisher> Morgan Kaufmann Publishers, </publisher> <address> San Mateo, CA, </address> <year> 1989. </year>
Reference-contexts: This operator is typically assessed as a secondary one which is of little importance in comparison to crossover (e.g., [14], p. 111), such that most canonical genetic algorithms work with small, constant settings of p m 2 [0:001; 0:01] (see e.g. <ref> [11, 12, 15, 21] </ref>). In contrast to these findings, however, practical applications of genetic algorithms often favor larger or non-constant settings of the mutation rate.
Reference: 22. <author> J. D. Schaffer and A. Morishima. </author> <title> An adaptive crossover distribution mechanism for genetic algorithms. </title> <editor> In J. J. Grefenstette, editor, </editor> <booktitle> Proceedings of the 2nd International Conference on Genetic Algorithms and Their Applications, </booktitle> <pages> pages 36-40. </pages> <publisher> Lawrence Erlbaum Associates, </publisher> <address> Hillsdale, NJ, </address> <year> 1987. </year>
Reference-contexts: The great success of self-adapting strategy parameters in case of continuous optimization problems suggests a transfer of the general principle to genetic algorithms and discrete optimization problems. Early efforts include the self-adaptation of a binary representation of the crossover operator <ref> [22] </ref> and a binary representation of the mutation probability for each individual [2], but both were of limited success.
Reference: 23. <author> H.-P. Schwefel. </author> <title> Collective intelligence in evolving systems. </title> <editor> In W. Wolff, C.-J. Soeder, and F. R. Drepper, editors, Ecodynamics, </editor> <booktitle> Contributions to Theoretical Ecology, </booktitle> <pages> pages 95-100. </pages> <publisher> Springer, </publisher> <address> Berlin, </address> <year> 1987. </year>
Reference-contexts: parameter self-adaptation as developed by Schwefel for evolution strategies [6]. 3 Two-Level Learning in Genetic Algorithms A fascinating alternative to the typical exogenous prescription of strategy parameters consists in the principle of strategy parameter self-adaptation or on-line learning as first implemented by Schwefel in the context of multimembered evolution strategies <ref> [23, 24, 25] </ref>. Independently of this, Fogel et al. [9] developed an almost identical procedure for evolutionary programming (see also [8]). The self-adaptation principle incorporates certain strategy parameters (such as variances and covariances of a generalized, n-dimensional normal distribution in case of evolution strategies) into the representation of each individual. <p> For evolution strategies, Schwefel has demonstrated that a relatively strong selective pressure as e.g. provided by (,)-selection ( parent individuals create &gt; offspring individuals by recombination and mutation, and the best offspring individuals are selected as parents of the next generation) is mandatory for the self-adaptation principle to work <ref> [23, 24] </ref>. Consequently, we also incor porate (,)-selection into the self-adaptive genetic algorithm as an alternative to proportional selection. Fig. 1.: The self-adaptation mechanism is shown here for the counting ones function with n = 1000 and a genetic algorithm with proportional selection, without crossover.
Reference: 24. <author> H.-P. Schwefel. </author> <title> Imitating evolution: Collective, two-level learning processes. </title> <editor> In U. Witt, editor, </editor> <booktitle> Explaining Process and Change | Approaches to Evolutionary Economics, </booktitle> <pages> pages 49-63. </pages> <publisher> The University of Michigan Press, </publisher> <address> Ann Arbor, MI, </address> <year> 1992. </year>
Reference-contexts: parameter self-adaptation as developed by Schwefel for evolution strategies [6]. 3 Two-Level Learning in Genetic Algorithms A fascinating alternative to the typical exogenous prescription of strategy parameters consists in the principle of strategy parameter self-adaptation or on-line learning as first implemented by Schwefel in the context of multimembered evolution strategies <ref> [23, 24, 25] </ref>. Independently of this, Fogel et al. [9] developed an almost identical procedure for evolutionary programming (see also [8]). The self-adaptation principle incorporates certain strategy parameters (such as variances and covariances of a generalized, n-dimensional normal distribution in case of evolution strategies) into the representation of each individual. <p> For evolution strategies, Schwefel has demonstrated that a relatively strong selective pressure as e.g. provided by (,)-selection ( parent individuals create &gt; offspring individuals by recombination and mutation, and the best offspring individuals are selected as parents of the next generation) is mandatory for the self-adaptation principle to work <ref> [23, 24] </ref>. Consequently, we also incor porate (,)-selection into the self-adaptive genetic algorithm as an alternative to proportional selection. Fig. 1.: The self-adaptation mechanism is shown here for the counting ones function with n = 1000 and a genetic algorithm with proportional selection, without crossover.
Reference: 25. <author> H.-P. Schwefel. </author> <title> Evolution and Optimum Seeking. </title> <booktitle> Sixth-Generation Computer Technology Series. </booktitle> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1995. </year>
Reference-contexts: parameter self-adaptation as developed by Schwefel for evolution strategies [6]. 3 Two-Level Learning in Genetic Algorithms A fascinating alternative to the typical exogenous prescription of strategy parameters consists in the principle of strategy parameter self-adaptation or on-line learning as first implemented by Schwefel in the context of multimembered evolution strategies <ref> [23, 24, 25] </ref>. Independently of this, Fogel et al. [9] developed an almost identical procedure for evolutionary programming (see also [8]). The self-adaptation principle incorporates certain strategy parameters (such as variances and covariances of a generalized, n-dimensional normal distribution in case of evolution strategies) into the representation of each individual.

References-found: 25

