URL: http://www.cs.cmu.edu/afs/cs.cmu.edu/project/scandal/public/papers/ieee-scan.ps.gz
Refering-URL: http://www.cs.cmu.edu/afs/cs.cmu.edu/Web/People/blelloch/publications.html
Root-URL: 
Title: Scans as Primitive Parallel Operations  
Author: Guy E. Blelloch 
Date: November 1989  
Affiliation: Carnegie Mellon University  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> M. Ajtai, J. Komlos, and E. Szemeredi. </author> <title> An O(n lg n) sorting network. </title> <booktitle> In Proceedings ACM Symposium on Theory of Computing, </booktitle> <pages> pages 1-9, </pages> <month> April </month> <year> 1983. </year>
Reference-contexts: On a P-RAM, each element a i is placed in a separate processor, and the scan executes over a fixed order of the processors|the prefix operation on a linked list [48, 27], and the fetch-and-op type instructions [21, 20, 37] are not considered. 1 The AKS sorting network <ref> [1] </ref> takes O (lg n) time deterministically, but is not practical. 2 The appendix gives a short history of the scan operations. 1 Model Algorithm EREW CRCW Scan Graph Algorithms (n vertices, m edges, m processors) Minimum Spanning Tree O (lg 2 n) O (lg n) O (lg n) Connected Components <p> Some of the algorithms are probabilistic. 2 Memory Reference Scan Operation Theoretical VLSI models Time O (lg n) [29] O (lg n) [30] Area O (n 2 = lg n) O (n) Circuit models Depth O (lg n) <ref> [1] </ref> O (lg n) [15] Size O (n lg n) O (n) Actual 64K processor CM-2 Bit Cycles (Time) 600 550 Percent of Hardware 30 0 Table 2: Both in theory and in practice certain scan operations can execute in less time than references to a shared memory, and can be <p> If we assume for n keys that the keys are O (lg n) bits long, a common assumption in models of computation [45], then the algorithm has a step complexity of O (lg n). Although O (lg n) is the same asymptotic complexity as existing EREW and CRCW algorithms <ref> [1, 11] </ref>, the algorithm is much simpler and has a significantly smaller constant. Note that since integers, characters, and floating-point numbers can all be sorted with a radix sort, a radix sort suffices for almost all sorting of fixed-length keys required in practice.
Reference: [2] <author> D. C. Allen. </author> <title> The BBN multiprocessors: Butterfly and Monarch. </title> <booktitle> In Proceedings Prince-ton Conference on Supercomputers and Stellar Dynamics, </booktitle> <month> June </month> <year> 1986. </year>
Reference-contexts: This time is considerably faster than the routing time of existing parallel computers such as the BBN Butterfly or the Thinking Machines Connection Machine. With a more aggressive clock such as the 10 nanoseconds clock being looked at by BBN for the Monarch 9 <ref> [2] </ref>, this time would be reduced to .5 microseconds|twice as fast as the best case global access time expected on the Monarch. <p> In most existing and proposed tightly connected parallel computers <ref> [22, 36, 2, 41] </ref>, the cost of the communication network is between 1/3 and 1/2 the cost of the computer.
Reference: [3] <author> Baruch Awerbuch and Yossi Shiloach. </author> <title> New connectivity and MSF algorithms for Ultracomputer and PRAM. </title> <booktitle> In Proceedings ACM Symposium on Theory of Computing, </booktitle> <pages> pages 175-179, </pages> <year> 1985. </year>
Reference-contexts: For n vertices and m edges, it has a step complexity of O (lg n). The best algorithm known for 14 the EREW P-RAM model requires O (lg 2 n) time [23, 39]. The best algorithm known for the CRCW P-RAM model requires O (lg n) time <ref> [3] </ref>, but this algorithms requires that the generic CRCW P-RAM model be extended so that if several processors write to the same location, either the value from the lowest numbered processor is written, or the minimum value is written.
Reference: [4] <author> Kenneth E. Batcher. </author> <title> Sorting networks and their applications. </title> <booktitle> In AFIPS Spring Joint Computer Conference, </booktitle> <pages> pages 307-314, </pages> <year> 1968. </year>
Reference-contexts: The split radix sort is fast in the scan model, but is it fast in practice? After all, our architectural justification claimed that the scan primitives bring the P-RAM models closer to reality. Table 4 compares implementations of the split radix sort and Batcher's bitonic sort <ref> [4] </ref> on the Connection Machine. We choose the bitonic sort for comparison because it is commonly cited as the most practical parallel sorting algorithm. I have also looked into implementing Cole's sort [11], which is optimal on the P-RAM models, on the Connection Machine. <p> We wonder whether there might be other primitives that can be cheaply implemented on a parallel architecture. One such primitive might be a merge primitive that merges two sorted vectors. As shown by Batcher <ref> [4] </ref>, this can be executed in a single pass of an Omega network.
Reference: [5] <author> C. Berge and A. Ghouila-Houri. </author> <title> Programming, Games, and Transportation Networks. </title> <publisher> John Wiley, </publisher> <address> New York, </address> <year> 1965. </year>
Reference-contexts: All these algorithms are based on the algorithm of Sollin <ref> [5] </ref>, which is similar to the algorithm of Bor _uvka [9]. The algorithms start with a forest of trees in which each tree is a single vertex. These trees are merged during the algorithm, and the algorithm terminates when a single tree remains.
Reference: [6] <author> H. J. Berliner. </author> <title> A chronology of computer chess and its literature. </title> <journal> Artificial Intelligence, </journal> <volume> 10(2), </volume> <year> 1978. </year>
Reference-contexts: To distribute values from each position i to its segment, we permute the values to the beginning of the segments and use a segmented copy operation to copy the values across the segment. Allocation and 6 This is how many chess playing algorithms work <ref> [6] </ref>. The search is called an minimax search since it alternates moves between the two players, trying to minimize the benefit of one player and maximize the benefit of the other. 17 distribution each require O (1) steps on the scan model.
Reference: [7] <author> Guy E. Blelloch. </author> <title> Scan Primitives and Parallel Vector Models. </title> <type> PhD thesis, </type> <institution> Artificial Intelligence Laboratory, Massachusetts Institute of Technology, </institution> <address> Cambridge, MA, </address> <month> November </month> <year> 1988. </year>
Reference-contexts: These scan primitives improve the asymptotic running time of many algorithms by an O (lg n) factor. The algorithms not described in this paper are described elsewhere <ref> [7, 8] </ref>. <p> This version of quicksort has been implemented on the Connection Machine and executes in about twice the time as the split radix sort. 13 The technique of recursively breaking segments into subsegments and operating inde-pendently within each segment can be used for many other divide-and-conquer algorithms <ref> [7, 8] </ref>. 2.3.2 Graphs An undirected graph can be represented using a segment for each vertex and an element position within a segment for each edge of the vertex. Since each edge is incident on two vertices, it appears in two segments. <p> Such neighbor summing can be executed by distributing the value from each vertex over its edges using a segmented copy operation, permuting these values using the cross-pointers, and summing the values on the edges back into the vertices using a segmented +-distribute operation. Elsewhere <ref> [7] </ref> we show that by keeping trees in a particular form, we can similarly reduce the step complexity of many tree operations on trees with n vertices by O (lg n). <p> From a theoretical orientation, efficient circuits for implementing scan primitives have been discussed elsewhere [28, 15]. This section therefore concentrates on a practical implementation, described at the logic level, and discusses how this implementation could fit into an actual machine. Elsewhere we have shown <ref> [7] </ref> that some of the other scan operations, such as the segmented scan operations, can be implemented directly with little additional hardware. Although the discussion suggests a separate circuit (set of chips) to implement the scan operations, wires and chips of a scan circuit might be shared with other circuitry. <p> The or-scan and and-scan can be implemented with a 1-bit max-scan and min-scan respectively. The implementation of the floating-point +-scan is described elsewhere <ref> [7] </ref>. A segmented max-scan is implemented by first enumerating the segment bits, appending the result (plus 1 in positions where the flag is set) to the original numbers, executing an unsegmented max-scan, and removing the appended bits (see Figure 16).
Reference: [8] <author> Guy E. Blelloch and James J. Little. </author> <title> Parallel solutions to geometric problems on the Scan Model of computation. </title> <booktitle> In Proceedings International Conference on Parallel Processing, </booktitle> <volume> pages Vol 3: </volume> <pages> 218-222, </pages> <month> August </month> <year> 1988. </year>
Reference-contexts: These scan primitives improve the asymptotic running time of many algorithms by an O (lg n) factor. The algorithms not described in this paper are described elsewhere <ref> [7, 8] </ref>. <p> This version of quicksort has been implemented on the Connection Machine and executes in about twice the time as the split radix sort. 13 The technique of recursively breaking segments into subsegments and operating inde-pendently within each segment can be used for many other divide-and-conquer algorithms <ref> [7, 8] </ref>. 2.3.2 Graphs An undirected graph can be represented using a segment for each vertex and an element position within a segment for each edge of the vertex. Since each edge is incident on two vertices, it appears in two segments.
Reference: [9] <author> O. Bor _uvka. </author> <title> O jistem problen minimal im. </title> <journal> Praca Moravske Pr irodovedecke Spolecnosti, </journal> (3):37-58, 1926. (In Czech.). 
Reference-contexts: All these algorithms are based on the algorithm of Sollin [5], which is similar to the algorithm of Bor _uvka <ref> [9] </ref>. The algorithms start with a forest of trees in which each tree is a single vertex. These trees are merged during the algorithm, and the algorithm terminates when a single tree remains.
Reference: [10] <author> R. P. Brent and H. T. Kung. </author> <title> The chip complexity of binary arithmetic. </title> <booktitle> In Proceedings ACM Symposium on Theory of Computing, </booktitle> <pages> pages 190-200, </pages> <year> 1980. </year>
Reference: [11] <author> Richard Cole. </author> <title> Parallel merge sort. </title> <booktitle> In Proceedings Symposium on Foundations of Computer Science, </booktitle> <pages> pages 511-516, </pages> <month> October </month> <year> 1986. </year> <month> 34 </month>
Reference-contexts: If we assume for n keys that the keys are O (lg n) bits long, a common assumption in models of computation [45], then the algorithm has a step complexity of O (lg n). Although O (lg n) is the same asymptotic complexity as existing EREW and CRCW algorithms <ref> [1, 11] </ref>, the algorithm is much simpler and has a significantly smaller constant. Note that since integers, characters, and floating-point numbers can all be sorted with a radix sort, a radix sort suffices for almost all sorting of fixed-length keys required in practice. <p> Table 4 compares implementations of the split radix sort and Batcher's bitonic sort [4] on the Connection Machine. We choose the bitonic sort for comparison because it is commonly cited as the most practical parallel sorting algorithm. I have also looked into implementing Cole's sort <ref> [11] </ref>, which is optimal on the P-RAM models, on the Connection Machine.
Reference: [12] <author> Richard Cole and Uzi Vishkin. </author> <title> Approximate scheduling, exact scheduling, and appli-cations to parallel algorithms. </title> <booktitle> In Proceedings Symposium on Foundations of Computer Science, </booktitle> <pages> pages 478-491, </pages> <year> 1986. </year>
Reference-contexts: The segment-descriptor partitions the processors into vertices. Processors Steps Processor-Step Halving Merge O (n) O (lg n) O (n lg n) O (n= lg n) O (lg n) O (n) List Ranking <ref> [12] </ref> O (n) O (lg n) O (n lg n) O (n= lg n) O (lg n) O (n) Tree Contraction [18] O (n) O (lg n) O (n lg n) O (n= lg n) O (lg n) O (n) Table 5: The processor-step complexity of many algorithms can be reduced
Reference: [13] <author> Richard Cole and Uzi Vishkin. </author> <title> Faster Optimal Parallel Prefix Sums and List Ranking. </title> <type> Technical Report Ultracomputer Note 117, </type> <address> New York University, </address> <month> February </month> <year> 1987. </year>
Reference-contexts: Allocation requires O (lg n) steps on a EREW P-RAM and O (lg n= lg lg n) steps on a CREW P-RAM (this is based on the prefix sum routine of Cole and Vishkin <ref> [13] </ref>). When an algorithm allocates processors, the number of processors required is usually determined dynamically and will depend on the data.
Reference: [14] <author> C. C. Elgot and A. Robinson. </author> <title> Random access stored program machines. </title> <journal> Journal of the Association of Computer Machinery, </journal> <volume> 11(4) </volume> <pages> 365-399, </pages> <year> 1964. </year>
Reference-contexts: The assumption that primitives operate in unit time allows researchers to greatly simplify the analysis of algorithms, but is never strictly valid on real machines: primitives often execute in time dependent on machine and algorithm parameters. For example, in the serial random access machine (RAM) model <ref> [14] </ref>, memory references are assumed to take unit time even though the data must fan-in on any real hardware and therefore take time that increases with the memory size.
Reference: [15] <author> Faith E. Fich. </author> <title> New bounds for parallel prefix circuits. </title> <booktitle> In Proceedings ACM Symposium on Theory of Computing, </booktitle> <pages> pages 100-109, </pages> <month> April </month> <year> 1983. </year>
Reference-contexts: Some of the algorithms are probabilistic. 2 Memory Reference Scan Operation Theoretical VLSI models Time O (lg n) [29] O (lg n) [30] Area O (n 2 = lg n) O (n) Circuit models Depth O (lg n) [1] O (lg n) <ref> [15] </ref> Size O (n lg n) O (n) Actual 64K processor CM-2 Bit Cycles (Time) 600 550 Percent of Hardware 30 0 Table 2: Both in theory and in practice certain scan operations can execute in less time than references to a shared memory, and can be implemented with less hardware. <p> From a theoretical orientation, efficient circuits for implementing scan primitives have been discussed elsewhere <ref> [28, 15] </ref>. This section therefore concentrates on a practical implementation, described at the logic level, and discusses how this implementation could fit into an actual machine.
Reference: [16] <author> Steven Fortune and James Wyllie. </author> <title> Parallelism in random access machines. </title> <booktitle> In Proceedings ACM Symposium on Theory of Computing, </booktitle> <pages> pages 114-118, </pages> <year> 1978. </year>
Reference-contexts: In spite of this inaccuracy in the model, the unit-time assumption has served as an excellent basis for the analysis of algorithms. In the parallel random access machine (P-RAM) models <ref> [16, 40, 42, 19, 20] </ref>, memory references are again assumed to take unit time.
Reference: [17] <author> F. Gavril. </author> <title> Merging with parallel processors. </title> <journal> Communications of the ACM, </journal> <volume> 18(10) </volume> <pages> 588-591, </pages> <year> 1975. </year>
Reference-contexts: When the p &lt; n= lg n, the algorithm is optimal. Although the split radix sort and the quicksort algorithms are variations of well-known algorithms translated to a new model, the merging algorithm described here is original. The merging algorithm of Shiloach and Vishkin for the CRCW P-RAM model <ref> [17, 42] </ref> has the same complexity but is quite different. Their algorithm is not recursive.
Reference: [18] <author> Hillel Gazit, Gary L. Miller, and Shang-Hua Teng. </author> <title> Optimal Tree Contraction in the EREW Model, </title> <address> pages 139-156. </address> <publisher> Plenum Publishing Corporation, </publisher> <year> 1988. </year>
Reference-contexts: Processors Steps Processor-Step Halving Merge O (n) O (lg n) O (n lg n) O (n= lg n) O (lg n) O (n) List Ranking [12] O (n) O (lg n) O (n lg n) O (n= lg n) O (lg n) O (n) Tree Contraction <ref> [18] </ref> O (n) O (lg n) O (n lg n) O (n= lg n) O (lg n) O (n) Table 5: The processor-step complexity of many algorithms can be reduced by using fewer processors and assigning many elements to each processor. 20 Before Star-Merge Index = [0 1 2 3 4
Reference: [19] <author> L. M. Goldschlager. </author> <title> A universal interconnection pattern for parallel computers. </title> <journal> Journal of the Association of Computer Machinery, </journal> <volume> 29(3) </volume> <pages> 1073-1086, </pages> <year> 1982. </year>
Reference-contexts: In spite of this inaccuracy in the model, the unit-time assumption has served as an excellent basis for the analysis of algorithms. In the parallel random access machine (P-RAM) models <ref> [16, 40, 42, 19, 20] </ref>, memory references are again assumed to take unit time.
Reference: [20] <author> Allan Gottlieb, R. Grishman, Clyde P. Kruskal, Kevin P. McAuliffe, Larry Rudolph, and Marc Snir. </author> <title> The NYU Ultracomputer|designing a MIMD, shared-memory parallel machine. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-32:175-189, </volume> <year> 1983. </year>
Reference-contexts: In spite of this inaccuracy in the model, the unit-time assumption has served as an excellent basis for the analysis of algorithms. In the parallel random access machine (P-RAM) models <ref> [16, 40, 42, 19, 20] </ref>, memory references are again assumed to take unit time. <p> On a P-RAM, each element a i is placed in a separate processor, and the scan executes over a fixed order of the processors|the prefix operation on a linked list [48, 27], and the fetch-and-op type instructions <ref> [21, 20, 37] </ref> are not considered. 1 The AKS sorting network [1] takes O (lg n) time deterministically, but is not practical. 2 The appendix gives a short history of the scan operations. 1 Model Algorithm EREW CRCW Scan Graph Algorithms (n vertices, m edges, m processors) Minimum Spanning Tree O
Reference: [21] <author> Allan Gottlieb, B. D. Lubachevsky, and Larry Rudolph. </author> <title> Basic techniques for the efficient coordination of very large numbers of cooperating sequential processors. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 5(2), </volume> <month> April </month> <year> 1983. </year>
Reference-contexts: On a P-RAM, each element a i is placed in a separate processor, and the scan executes over a fixed order of the processors|the prefix operation on a linked list [48, 27], and the fetch-and-op type instructions <ref> [21, 20, 37] </ref> are not considered. 1 The AKS sorting network [1] takes O (lg n) time deterministically, but is not practical. 2 The appendix gives a short history of the scan operations. 1 Model Algorithm EREW CRCW Scan Graph Algorithms (n vertices, m edges, m processors) Minimum Spanning Tree O
Reference: [22] <author> W. Daniel Hillis. </author> <title> The Connection Machine. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1985. </year>
Reference-contexts: In most existing and proposed tightly connected parallel computers <ref> [22, 36, 2, 41] </ref>, the cost of the communication network is between 1/3 and 1/2 the cost of the computer.
Reference: [23] <author> D. S. Hirschberg, A. K. Chandra, and D. V. Sarwate. </author> <title> Computing connected components on parallel computers. </title> <journal> Communications of the ACM, </journal> <volume> 22(8) </volume> <pages> 461-464, </pages> <year> 1979. </year>
Reference-contexts: For n vertices and m edges, it has a step complexity of O (lg n). The best algorithm known for 14 the EREW P-RAM model requires O (lg 2 n) time <ref> [23, 39] </ref>.
Reference: [24] <author> C. A. R. Hoare. </author> <title> Quicksort. </title> <journal> Computer J., </journal> <volume> 5(1) </volume> <pages> 10-15, </pages> <year> 1962. </year> <month> 35 </month>
Reference-contexts: They can also be implemented directly as described by Schwartz [40]. 2.3.1 Example: Quicksort To illustrate the use of segments, we consider a parallel version of Quicksort. Similar to the standard serial version <ref> [24] </ref>, the parallel version picks one of the keys as a pivot value, splits the keys into three sets|keys lesser, equal and greater than the pivot|and recurses on each set. 4 The algorithm has an expected step complexity of O (lg n).
Reference: [25] <author> Kenneth E. Iverson. </author> <title> A Programming Language. </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1962. </year>
Reference: [26] <author> D.E. Knuth. </author> <title> Sorting and Searching. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1973. </year>
Reference-contexts: The algorithm is a parallel version of the standard serial radix sort <ref> [26] </ref>. The algorithm loops over the bits of the keys, starting at the lowest bit, executing a split operation on each iteration.
Reference: [27] <author> Clyde P. Kruskal, Larry Rudolph, and Marc Snir. </author> <title> The power of parallel prefix. </title> <booktitle> In Proceedings International Conference on Parallel Processing, </booktitle> <pages> pages 180-185, </pages> <month> August </month> <year> 1985. </year>
Reference-contexts: These have a particularly simple implementation and they can be used to implement many other useful scan operations. On a P-RAM, each element a i is placed in a separate processor, and the scan executes over a fixed order of the processors|the prefix operation on a linked list <ref> [48, 27] </ref>, and the fetch-and-op type instructions [21, 20, 37] are not considered. 1 The AKS sorting network [1] takes O (lg n) time deterministically, but is not practical. 2 The appendix gives a short history of the scan operations. 1 Model Algorithm EREW CRCW Scan Graph Algorithms (n vertices, m
Reference: [28] <author> Richard E. Ladner and Michael J. Fischer. </author> <title> Parallel prefix computation. </title> <journal> Journal of the Association of Computer Machinery, </journal> <volume> 27(4) </volume> <pages> 831-838, </pages> <month> October </month> <year> 1980. </year>
Reference-contexts: From a theoretical orientation, efficient circuits for implementing scan primitives have been discussed elsewhere <ref> [28, 15] </ref>. This section therefore concentrates on a practical implementation, described at the logic level, and discusses how this implementation could fit into an actual machine.
Reference: [29] <author> Frank Thomson Leighton. </author> <title> Tight bounds on the complexity of parallel sorting. </title> <booktitle> In Proceedings ACM Symposium on Theory of Computing, </booktitle> <pages> pages 71-80, </pages> <month> May </month> <year> 1984. </year>
Reference-contexts: These scan primitives improve the asymptotic running time of many algorithms by an O (lg n) factor. The algorithms not described in this paper are described elsewhere [7, 8]. Some of the algorithms are probabilistic. 2 Memory Reference Scan Operation Theoretical VLSI models Time O (lg n) <ref> [29] </ref> O (lg n) [30] Area O (n 2 = lg n) O (n) Circuit models Depth O (lg n) [1] O (lg n) [15] Size O (n lg n) O (n) Actual 64K processor CM-2 Bit Cycles (Time) 600 550 Percent of Hardware 30 0 Table 2: Both in theory
Reference: [30] <author> Charles E. Leiserson. </author> <title> Area-efficient layouts (for VLSI). </title> <booktitle> In Proceedings Symposium on Foundations of Computer Science, </booktitle> <year> 1980. </year>
Reference-contexts: The algorithms not described in this paper are described elsewhere [7, 8]. Some of the algorithms are probabilistic. 2 Memory Reference Scan Operation Theoretical VLSI models Time O (lg n) [29] O (lg n) <ref> [30] </ref> Area O (n 2 = lg n) O (n) Circuit models Depth O (lg n) [1] O (lg n) [15] Size O (n lg n) O (n) Actual 64K processor CM-2 Bit Cycles (Time) 600 550 Percent of Hardware 30 0 Table 2: Both in theory and in practice certain
Reference: [31] <author> Boris D. Lubachevsky and Albert G. Greenberg. </author> <title> Simple, efficient asynchronous parallel prefix algorithms. </title> <booktitle> In Proceedings International Conference on Parallel Processing, </booktitle> <pages> pages 66-69, </pages> <month> August </month> <year> 1987. </year>
Reference: [32] <author> G. A. Mago. </author> <title> A network of computers to execute reduction languages. </title> <journal> International Journal of Computer and Information Sciences, </journal> <year> 1979. </year>
Reference: [33] <author> Gary L. Miller and John H. Reif. </author> <title> Parallel tree contraction and its application. </title> <booktitle> In Proceedings Symposium on Foundations of Computer Science, </booktitle> <pages> pages 478-489, </pages> <month> October </month> <year> 1985. </year>
Reference-contexts: This random mate technique is similar to the method discussed by Miller and Reif <ref> [33] </ref>. Since on average 1/4 of the trees are deleted on each step, O (lg n) steps are required to reduce the forest to a single tree.
Reference: [34] <author> William M. Newman and Robert F. Sproull. </author> <title> Principles of Interactive Computer Graphics. </title> <publisher> McGraw-Hill, </publisher> <address> New York, </address> <year> 1979. </year>
Reference-contexts: Figure 9 illustrates an example. The routine we discuss returns a vector of (x; y) pairs that specify the position of each pixel along the line. It generates the same set of pixels as generated by the simple digital differential analyzer (DDA) serial technique <ref> [34] </ref>. The basic idea of the routine is for each line to allocate a processor for each pixel in the line, and then for each allocated pixel to determine, in parallel, its final position in the grid.
Reference: [35] <author> Yu Ofman. </author> <title> On the algorithmic complexity of discrete functions. </title> <journal> Cybernetics and Control Theory, Sov. Phys Dokl., </journal> <volume> 7(7) </volume> <pages> 589-591, </pages> <month> January </month> <year> 1963. </year>
Reference: [36] <author> G. F. Pfister and V. A. Norton. </author> <title> `Hot Spot' contention and combining in multistage interconnection networks. </title> <booktitle> In Proceedings International Conference on Parallel Processing, </booktitle> <pages> pages 790-797, </pages> <month> August </month> <year> 1985. </year> <month> 36 </month>
Reference-contexts: In most existing and proposed tightly connected parallel computers <ref> [22, 36, 2, 41] </ref>, the cost of the communication network is between 1/3 and 1/2 the cost of the computer.
Reference: [37] <author> Abhiram G. Ranade. </author> <title> Fluent Parallel Computation. </title> <type> PhD thesis, </type> <institution> Yale University, De--partment of Computer Science, </institution> <address> New Haven, CT, </address> <year> 1989. </year>
Reference-contexts: On a P-RAM, each element a i is placed in a separate processor, and the scan executes over a fixed order of the processors|the prefix operation on a linked list [48, 27], and the fetch-and-op type instructions <ref> [21, 20, 37] </ref> are not considered. 1 The AKS sorting network [1] takes O (lg n) time deterministically, but is not practical. 2 The appendix gives a short history of the scan operations. 1 Model Algorithm EREW CRCW Scan Graph Algorithms (n vertices, m edges, m processors) Minimum Spanning Tree O
Reference: [38] <author> James B. Salem. *Render: </author> <title> A Data Parallel Approach to Polygon Rendering. </title> <type> Technical Report VZ88-2, </type> <institution> Thinking Machines Corporation, </institution> <month> January </month> <year> 1988. </year>
Reference-contexts: This routine has a step complexity of O (1) and requires as many processors as pixels in the lines. The routine has been implemented on the Connection Machine, has been extended to render solid objects by Salem, and is part of a rendering package for the 18 Connection Machine <ref> [38] </ref>. 2.5 Load Balancing Up to now this paper has assumed that a P-RAM always has as many processors as elements in the data vectors. This section considers simulating multiple elements on each processor. Such simulation is important for two reasons.
Reference: [39] <author> Carla Savage and Joseph Ja'Ja'. </author> <title> Fast, efficient parallel algorithms for some graph problems. </title> <journal> Society for Industrial and Applied Mathematics, </journal> <volume> 10(4) </volume> <pages> 682-691, </pages> <year> 1981. </year>
Reference-contexts: For n vertices and m edges, it has a step complexity of O (lg n). The best algorithm known for 14 the EREW P-RAM model requires O (lg 2 n) time <ref> [23, 39] </ref>.
Reference: [40] <author> Jacob T. Schwartz. </author> <title> Ultracomputers. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 2(4) </volume> <pages> 484-521, </pages> <month> October </month> <year> 1980. </year>
Reference-contexts: In spite of this inaccuracy in the model, the unit-time assumption has served as an excellent basis for the analysis of algorithms. In the parallel random access machine (P-RAM) models <ref> [16, 40, 42, 19, 20] </ref>, memory references are again assumed to take unit time. <p> Segmented scans take two arguments: a set of values and a set of segment flags. Each flag in the segment flags specifies the start of a new segment (see Figure 4). Segmented scans were first suggested by Schwartz <ref> [40] </ref> and this paper shows some useful applications of these scans. The segmented scan operations are useful because they allow algorithms to execute the scans independently over the elements of many sets. <p> This graph representation is then used in a minimum-spanning-tree algorithm. The segmented scan operations can all be implemented with at most two calls to the two unsegmented primitive scans (see Section 3.4). They can also be implemented directly as described by Schwartz <ref> [40] </ref>. 2.3.1 Example: Quicksort To illustrate the use of segments, we consider a parallel version of Quicksort.
Reference: [41] <author> Charles L. Seitz. </author> <title> The Cosmic Cube. </title> <journal> Communications of the ACM, </journal> <volume> 28(1) </volume> <pages> 22-33, </pages> <month> Jan-uary </month> <year> 1985. </year>
Reference-contexts: In most existing and proposed tightly connected parallel computers <ref> [22, 36, 2, 41] </ref>, the cost of the communication network is between 1/3 and 1/2 the cost of the computer.
Reference: [42] <author> Y. Shiloach and U. Vishkin. </author> <title> Finding the maximum, merging and sorting in a parallel computation model. </title> <journal> Journal of Algorithms, </journal> <volume> 2(1) </volume> <pages> 88-102, </pages> <year> 1981. </year>
Reference-contexts: In spite of this inaccuracy in the model, the unit-time assumption has served as an excellent basis for the analysis of algorithms. In the parallel random access machine (P-RAM) models <ref> [16, 40, 42, 19, 20] </ref>, memory references are again assumed to take unit time. <p> When the p &lt; n= lg n, the algorithm is optimal. Although the split radix sort and the quicksort algorithms are variations of well-known algorithms translated to a new model, the merging algorithm described here is original. The merging algorithm of Shiloach and Vishkin for the CRCW P-RAM model <ref> [17, 42] </ref> has the same complexity but is quite different. Their algorithm is not recursive.
Reference: [43] <author> Yossi Shiloach and Uzi Vishkin. </author> <title> An O(log n) parallel connectivity algorithm. </title> <journal> Journal of Algorithms, </journal> <volume> 3 </volume> <pages> 57-67, </pages> <year> 1982. </year>
Reference-contexts: The only complication is maintaining the representation when merging stars. As with the Shiloach and Vishkin CRCW P-RAM algorithm <ref> [43] </ref>, trees are selected for merging by forming stars. We define a star as a set of vertices within a graph with one of the set marked as the parent, the others marked as children, and an edge that leads from each child vertex to its parent vertex 5 . <p> All children find their minimum edge (using a min-distribute), and all such edges that are connected to a parent are marked as star edges. Since, on average, half the trees are children 5 This definition of a star is slightly different from the definition of Shiloach and Vishkin <ref> [43] </ref>. 15 and half of the trees on the other end of the minimum edge of a child are parents, 1/4 of the trees are merged on each star-merge step. This random mate technique is similar to the method discussed by Miller and Reif [33].
Reference: [44] <author> Harold S. Stone. </author> <title> Parallel processsing with the perfect shu*e. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-20(2):153-161, </volume> <year> 1971. </year>
Reference-contexts: One solution is to use lower-level models based on a fixed connectivity of the processors, such as the shu*e-exchange networks <ref> [44] </ref> or grid networks [47]. This, however, gives up machine independence and greatly complicates the description of algorithms.
Reference: [45] <author> Robert E. Tarjan. </author> <title> Data Structures and Network Algorithms. </title> <institution> Society for Industrial and Applied Mathematics, </institution> <address> Philadelphia, Pennsylvania, </address> <year> 1983. </year>
Reference-contexts: The split operation has a step complexity of O (1); so for d-bit keys, the split radix sort has a step complexity of O (d). If we assume for n keys that the keys are O (lg n) bits long, a common assumption in models of computation <ref> [45] </ref>, then the algorithm has a step complexity of O (lg n). Although O (lg n) is the same asymptotic complexity as existing EREW and CRCW algorithms [1, 11], the algorithm is much simpler and has a significantly smaller constant.
Reference: [46] <author> Thinking Machines Corporation. </author> <title> Connection Machine parallel instruction set (PARIS). </title> <month> July </month> <year> 1986. </year>
Reference-contexts: The split radix sort is the sort currently supported by the parallel instruction set of the Connection Machine <ref> [46] </ref>. 2.3 Segments and Segmented Scans In many algorithms it is useful to break the linear ordering of the processors into segments and have a scan operation start again at the beginning of each segment; we call such scan operations, segmented scans.
Reference: [47] <author> C. D. Thompson and H. T. Kung. </author> <title> Sorting on a mesh-connected parallel computer. </title> <journal> Communications of the ACM, </journal> <volume> 20 </volume> <pages> 263-271, </pages> <year> 1977. </year>
Reference-contexts: One solution is to use lower-level models based on a fixed connectivity of the processors, such as the shu*e-exchange networks [44] or grid networks <ref> [47] </ref>. This, however, gives up machine independence and greatly complicates the description of algorithms.
Reference: [48] <author> James C. Wyllie. </author> <title> The Complexity of Parallel Computations. </title> <type> Technical Report TR-79-387, </type> <institution> Department of Computer Science, Cornell University, </institution> <address> Ithaca, NY, </address> <month> August </month> <year> 1979. </year> <month> 37 </month>
Reference-contexts: These have a particularly simple implementation and they can be used to implement many other useful scan operations. On a P-RAM, each element a i is placed in a separate processor, and the scan executes over a fixed order of the processors|the prefix operation on a linked list <ref> [48, 27] </ref>, and the fetch-and-op type instructions [21, 20, 37] are not considered. 1 The AKS sorting network [1] takes O (lg n) time deterministically, but is not practical. 2 The appendix gives a short history of the scan operations. 1 Model Algorithm EREW CRCW Scan Graph Algorithms (n vertices, m
References-found: 48

