URL: file://ftp.cis.ohio-state.edu/pub/tech-report/1992/TR26.ps.gz
Refering-URL: ftp://ftp.cis.ohio-state.edu/pub/tech-report/TRList.html
Root-URL: 
Title: Optimal Evaluation of Fortran-90 Array Expressions for Distributed Memory Machines  
Author: S.D. Kaushik, S.K.S. Gupta, C.-H. Huang, P. Sadayappan 
Keyword: Data distributions, Fortran-90, Array expressions, Arborescence, Bi nary expression trees.  
Address: Columbus, OH 43210  
Affiliation: Department of Computer and Information Science The Ohio State University  
Abstract: The owner-computes strategy has been used for evaluation of Fortran-90 array expressions on distributed memory machines. This strategy simplifies code generation but is often expensive in terms of the total communication cost and size of temporary memory required for its implementation. In this paper, we propose the relaxing of the owner computes strategy, to reduce the total communication and temporary storage cost. We develop cost metrics for measuring the communication and memory cost associated with the evaluation of Fortran-90 array expressions on distributed memory machines. The communication tree is introduced as a useful representation for array expressions involving associative and commutative operators of one kind. Procedures for estimating communication and temporary memory costs for a communication tree are described. An efficient polynomial-time algorithm to determine an evaluation order which minimizes the communication cost is presented. We also present an efficient polynomial-time algorithm to determine the evaluation order which minimizes the memory cost involved in the evaluation of such expressions. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> I. Ahmad, R. Bordawekar, Z. Bozkus, A. Choudhary, G. Fox, K. Parasuram, R. Ponnusamy, S. Ranka, and R. Thakur. </author> <title> Implementation and scalability of Fortan-90D intrinsic functions on distributed memory machines. </title> <type> Technical report, </type> <institution> Northeast Parallel Architectures Centre, </institution> <month> Jun. </month> <year> 1992. </year>
Reference-contexts: Extensions for Fortran-90 such as Fortran-90D <ref> [1] </ref>, Fortran-90 Yale Extension [4] and Distributed Fortran-90 [19] have been proposed. In Fortran-90D, parallelism is represented largely in terms of parallel constructs such as array operations, forall loops and intrinsic functions. Current compilers generate data parallel code based on the owner-computes philosophy [3, 7, 10, 11].
Reference: [2] <author> A. V. Aho, R. Sethi, and J.D. Ullman. </author> <title> Compilers P rinciples, techniques and tools. </title> <publisher> Addison-Wesley, </publisher> <month> Jun </month> <year> 1987. </year>
Reference-contexts: The algorithm is similar to the labeling algorithm used to find the minimum number of registers required to evaluate an arithmetic expression represented by a binary expression tree <ref> [2] </ref>. Some results follow directly from the algorithm. 13 Lemma 3.1 Let T = (V; E) be a communication tree representing the expression E.
Reference: [3] <author> B. M. Chapman, P. Mehrotra, and H. P. Zima. </author> <title> Vienna Fortran a Fortran language extension for distributed memory multiprocessors. </title> <editor> In J. Saltz and P. Mehrotra, editors, </editor> <booktitle> Language, Compilers and Runtime Environments for Distributed Memory Machines, </booktitle> <pages> pages 39-62. </pages> <publisher> North-Holland, </publisher> <address> Amsterdam, </address> <year> 1992. </year>
Reference-contexts: Extensions for Fortran-90 such as Fortran-90D [1], Fortran-90 Yale Extension [4] and Distributed Fortran-90 [19] have been proposed. In Fortran-90D, parallelism is represented largely in terms of parallel constructs such as array operations, forall loops and intrinsic functions. Current compilers generate data parallel code based on the owner-computes philosophy <ref> [3, 7, 10, 11] </ref>. Under the owner computes strategy, the owner of a data element, i.e the processor on which the data element is located, performs the computation that assigns a value to that data element.
Reference: [4] <author> M. Chen and J.-J. Wu. </author> <title> Optimizing Fortran-90 programs for data motion on massively parallel systems. </title> <type> Technical Report YALEU/DCS/TR-882, </type> <institution> Yale University, Dept. of Computer Science, </institution> <month> Jan. </month> <year> 1992. </year>
Reference-contexts: Extensions for Fortran-90 such as Fortran-90D [1], Fortran-90 Yale Extension <ref> [4] </ref> and Distributed Fortran-90 [19] have been proposed. In Fortran-90D, parallelism is represented largely in terms of parallel constructs such as array operations, forall loops and intrinsic functions. Current compilers generate data parallel code based on the owner-computes philosophy [3, 7, 10, 11]. <p> They provide an efficient algorithm to find the minimum cost evaluation procedure for an arbitrary expression for "robust metrics". Li and Chen [16] address the problem of aligning arrays on a data parallel architecture to minimize communication. Chen and Wu <ref> [4] </ref> describe a general algebraic compiler optimization technique that reduces communication overhead for Fortran-90 implementations on massively parallel machines. However, the evaluation on MIMD architectures, of array expressions consisting of array sections distributed using regular data distributions, has not been addressed in the literature.
Reference: [5] <author> Y.-J. Chu and T.-H. Liu. </author> <title> On the shortest arborescence of a directed graph. </title> <journal> Scientia Sinica, </journal> <volume> 14(10) </volume> <pages> 1396-1400, </pages> <year> 1965. </year>
Reference-contexts: Hence either C (T ) = C (T 0 ) and T is a communication tree with minimum communication cost or we have a contradiction. 2. There exist several efficient algorithms for finding the minimum spanning arborescences of a directed graph <ref> [5, 6, 21, 13] </ref>. The complexity for a dense graph with n vertices is O (n 2 ) [21].
Reference: [6] <author> N. Deo. </author> <title> Graph Theory with Applications to Engineering and Computer Science. </title> <publisher> Prentice Hall of India, </publisher> <year> 1987. </year>
Reference-contexts: This vertex R is the root of the arborescence. A spanning arborescence in a connected digraph is a spanning tree that is an arborescence. An arborescence has the following properties <ref> [6] </ref>. * An arborescence is a directed tree in which every vertex other that the root has an in-degree of exactly one. * In an arborescence, there is a directed path from the root R to every other vertex. <p> Hence either C (T ) = C (T 0 ) and T is a communication tree with minimum communication cost or we have a contradiction. 2. There exist several efficient algorithms for finding the minimum spanning arborescences of a directed graph <ref> [5, 6, 21, 13] </ref>. The complexity for a dense graph with n vertices is O (n 2 ) [21].
Reference: [7] <author> G. Fox, S. Hiranandani, K. Kennedy, C Koelbel, U. Kremer, C.-W. Tseng, and M-Y. Wu. </author> <title> Fortran-D Language Specification. </title> <type> Technical Report TR-91-170, </type> <institution> Dept. of Computer Science, Rice University, </institution> <month> Dec. </month> <year> 1991. </year>
Reference-contexts: Extensions for Fortran-90 such as Fortran-90D [1], Fortran-90 Yale Extension [4] and Distributed Fortran-90 [19] have been proposed. In Fortran-90D, parallelism is represented largely in terms of parallel constructs such as array operations, forall loops and intrinsic functions. Current compilers generate data parallel code based on the owner-computes philosophy <ref> [3, 7, 10, 11] </ref>. Under the owner computes strategy, the owner of a data element, i.e the processor on which the data element is located, performs the computation that assigns a value to that data element. <p> Consider two arrays A (0 : N t 1) and B (0 : N f 1) distributed over P t and P f processors respectively. The regular data distributions used are the block distribution, cyclic distribution and the block-cyclic distribution <ref> [7, 10] </ref>. Fig. 2 illustrates all the three types of data distributions for an array of size 16 distributed over 4 processors.
Reference: [8] <author> J.R. Gilbert and R. Schreiber. </author> <title> Optimal expression evaluation on data parallel architectures. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 13 </volume> <pages> 58-64, </pages> <year> 1991. </year>
Reference-contexts: Mace and Wagner [17, 18] determine globally optimal storage patterns for efficient access during vector operations. Knobe, Lukas and Steele [14, 15] have addressed the expression 3 evaluation problem for data parallel SIMD architectures. Techniques for automatic layout of ar-rays to reduce the communication are discussed. Gilbert and Schreiber <ref> [8] </ref> address the issue of evaluating expressions involving arrays of the same shape located at various positions in a SIMD multi-computer connected in a regular fashion. Using a metric that describes the cost of moving arrays, they determine the intermediate positions at which to carry out the individual operations.
Reference: [9] <author> S.K. Gupta, S.D. Kaushik, S. Mufti, S. Sharma, C.-H. Huang, and P. Sadayappan. </author> <title> On the generation of efficient data communication for distributed memory machines. </title> <type> Technical Report OSU-CIS-RC-5/92-TR15, </type> <institution> Dept. of Computer and Information Sciences, The Ohio State University, </institution> <month> Jun. </month> <year> 1992. </year>
Reference-contexts: In <ref> [9] </ref> closed form expressions for the exact data sets (sets of data values to be communicated) and processor sets (sets of processors to communicate to) for the Fortran-90 array statement have been derived.
Reference: [10] <author> S. Hiranandani, K. Kennedy, and C.-W. Tseng. </author> <title> Compiler optimizations for Fortran-D on mimd distributed memory machines. </title> <booktitle> In Supercomputing '91, </booktitle> <pages> pages 86-100, </pages> <month> Nov. </month> <year> 1991. </year>
Reference-contexts: Extensions for Fortran-90 such as Fortran-90D [1], Fortran-90 Yale Extension [4] and Distributed Fortran-90 [19] have been proposed. In Fortran-90D, parallelism is represented largely in terms of parallel constructs such as array operations, forall loops and intrinsic functions. Current compilers generate data parallel code based on the owner-computes philosophy <ref> [3, 7, 10, 11] </ref>. Under the owner computes strategy, the owner of a data element, i.e the processor on which the data element is located, performs the computation that assigns a value to that data element. <p> Consider two arrays A (0 : N t 1) and B (0 : N f 1) distributed over P t and P f processors respectively. The regular data distributions used are the block distribution, cyclic distribution and the block-cyclic distribution <ref> [7, 10] </ref>. Fig. 2 illustrates all the three types of data distributions for an array of size 16 distributed over 4 processors.
Reference: [11] <author> S. Hiranandani, K. Kennedy, and C.-W. Tseng. </author> <title> Compiler support for machine-independent parallel programming in Fortran D. </title> <editor> In J. Saltz and P. Mehrotra, editors, </editor> <booktitle> Language, Compilers and Runtime Environments for Distributed Memory Machines, </booktitle> <pages> pages 139-176. </pages> <publisher> North-Holland, </publisher> <address> Amsterdam, </address> <year> 1992. </year>
Reference-contexts: Extensions for Fortran-90 such as Fortran-90D [1], Fortran-90 Yale Extension [4] and Distributed Fortran-90 [19] have been proposed. In Fortran-90D, parallelism is represented largely in terms of parallel constructs such as array operations, forall loops and intrinsic functions. Current compilers generate data parallel code based on the owner-computes philosophy <ref> [3, 7, 10, 11] </ref>. Under the owner computes strategy, the owner of a data element, i.e the processor on which the data element is located, performs the computation that assigns a value to that data element.
Reference: [12] <author> American National Standards Institute. </author> <title> American Natioinal Standard for Information Systems Programming Language Fortran (Fortran 90), ANSI X3.198-1991 edition, </title> <month> Jan. </month> <year> 1990. </year>
Reference-contexts: of processors at appropriate points in the execution of the generated parallel program. 1 7) + a 2 fl X2 (4 : 11) + a 3 fl X3 (8 : 15) + a 4 fl X4 (12 : 19) This programming model has been incorporated in array-based languages like Fortran-90 <ref> [12, 20] </ref>. Extensions for Fortran-90 such as Fortran-90D [1], Fortran-90 Yale Extension [4] and Distributed Fortran-90 [19] have been proposed. In Fortran-90D, parallelism is represented largely in terms of parallel constructs such as array operations, forall loops and intrinsic functions.
Reference: [13] <author> R.M. Karp. </author> <title> A simple derivation of Edmonds' algorithm for optimum branchings. </title> <journal> Networks, </journal> <volume> 1(3) </volume> <pages> 265-272, </pages> <year> 1971. </year>
Reference-contexts: Hence either C (T ) = C (T 0 ) and T is a communication tree with minimum communication cost or we have a contradiction. 2. There exist several efficient algorithms for finding the minimum spanning arborescences of a directed graph <ref> [5, 6, 21, 13] </ref>. The complexity for a dense graph with n vertices is O (n 2 ) [21].
Reference: [14] <author> K. Knobe, J. D. Lukas, and G.L. Steele Jr. </author> <title> Massively parallel data optimization. </title> <booktitle> In Proc. Frontiers '88 : The Second Symposium on the Frontiers of Massively Parallel Computation, </booktitle> <address> George Mason University, </address> <pages> pages 551-558, </pages> <month> Oct. </month> <year> 1988. </year>
Reference-contexts: Work in the literature has been restricted to optimizing the evaluation of array expressions on vector machines and massively parallel SIMD architectures such as the Connection Machine, AMT DAP. Mace and Wagner [17, 18] determine globally optimal storage patterns for efficient access during vector operations. Knobe, Lukas and Steele <ref> [14, 15] </ref> have addressed the expression 3 evaluation problem for data parallel SIMD architectures. Techniques for automatic layout of ar-rays to reduce the communication are discussed.
Reference: [15] <author> K. Knobe, J.D. Lukas, and G.L. Steele Jr. </author> <title> Data optimization : Allocation of arrays to reduce communication on SIMD machines. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 8 </volume> <pages> 102-118, </pages> <year> 1990. </year>
Reference-contexts: Work in the literature has been restricted to optimizing the evaluation of array expressions on vector machines and massively parallel SIMD architectures such as the Connection Machine, AMT DAP. Mace and Wagner [17, 18] determine globally optimal storage patterns for efficient access during vector operations. Knobe, Lukas and Steele <ref> [14, 15] </ref> have addressed the expression 3 evaluation problem for data parallel SIMD architectures. Techniques for automatic layout of ar-rays to reduce the communication are discussed.
Reference: [16] <author> J. Li and M. Chen. </author> <title> The data alignment phase in compiling programs for distributed memory machine. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 13(2) </volume> <pages> 213-221, </pages> <month> Oct. </month> <year> 1991. </year>
Reference-contexts: Using a metric that describes the cost of moving arrays, they determine the intermediate positions at which to carry out the individual operations. They provide an efficient algorithm to find the minimum cost evaluation procedure for an arbitrary expression for "robust metrics". Li and Chen <ref> [16] </ref> address the problem of aligning arrays on a data parallel architecture to minimize communication. Chen and Wu [4] describe a general algebraic compiler optimization technique that reduces communication overhead for Fortran-90 implementations on massively parallel machines.
Reference: [17] <author> M. Mace. </author> <title> Memory Storage Patterns in Parallel Processing. </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, Massachusetts, </address> <year> 1987. </year>
Reference-contexts: Work in the literature has been restricted to optimizing the evaluation of array expressions on vector machines and massively parallel SIMD architectures such as the Connection Machine, AMT DAP. Mace and Wagner <ref> [17, 18] </ref> determine globally optimal storage patterns for efficient access during vector operations. Knobe, Lukas and Steele [14, 15] have addressed the expression 3 evaluation problem for data parallel SIMD architectures. Techniques for automatic layout of ar-rays to reduce the communication are discussed.
Reference: [18] <author> M. Mace and R. A. Wagner. </author> <title> Globally optimum selection of memory storage patterns. </title> <booktitle> In International Conference of Parallel Processing, </booktitle> <pages> pages 264-271, </pages> <month> Jul. </month> <year> 1985. </year>
Reference-contexts: Work in the literature has been restricted to optimizing the evaluation of array expressions on vector machines and massively parallel SIMD architectures such as the Connection Machine, AMT DAP. Mace and Wagner <ref> [17, 18] </ref> determine globally optimal storage patterns for efficient access during vector operations. Knobe, Lukas and Steele [14, 15] have addressed the expression 3 evaluation problem for data parallel SIMD architectures. Techniques for automatic layout of ar-rays to reduce the communication are discussed.
Reference: [19] <author> J. Merlin. </author> <title> Techniques for automatic parallelisation of `Distributed Fortran 90'. </title> <type> Technical Report SNARC 92-02, </type> <institution> Southampton Novel Architecture Research Centre, </institution> <month> Jun. </month> <year> 1992. </year>
Reference-contexts: Extensions for Fortran-90 such as Fortran-90D [1], Fortran-90 Yale Extension [4] and Distributed Fortran-90 <ref> [19] </ref> have been proposed. In Fortran-90D, parallelism is represented largely in terms of parallel constructs such as array operations, forall loops and intrinsic functions. Current compilers generate data parallel code based on the owner-computes philosophy [3, 7, 10, 11].
Reference: [20] <author> M. Metcalf and J. Reid. </author> <title> Fortran 90 Explained. </title> <publisher> Oxford University Press, </publisher> <year> 1990. </year>
Reference-contexts: of processors at appropriate points in the execution of the generated parallel program. 1 7) + a 2 fl X2 (4 : 11) + a 3 fl X3 (8 : 15) + a 4 fl X4 (12 : 19) This programming model has been incorporated in array-based languages like Fortran-90 <ref> [12, 20] </ref>. Extensions for Fortran-90 such as Fortran-90D [1], Fortran-90 Yale Extension [4] and Distributed Fortran-90 [19] have been proposed. In Fortran-90D, parallelism is represented largely in terms of parallel constructs such as array operations, forall loops and intrinsic functions.

References-found: 20

