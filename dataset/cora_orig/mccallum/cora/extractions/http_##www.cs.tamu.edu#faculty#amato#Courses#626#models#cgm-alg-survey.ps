URL: http://www.cs.tamu.edu/faculty/amato/Courses/626/models/cgm-alg-survey.ps
Refering-URL: http://www.cs.tamu.edu/faculty/amato/Courses/626/modelrefs.html
Root-URL: http://www.cs.tamu.edu
Title: Algorithms in CGM, BSP and BSP* Model A Survey  
Author: Silvia Gotz 
Note: 95.574 Parallel Algorithms and their VLSI Implementation  
Address: Ottawa  
Affiliation: Carleton University,  
Pubnum: Project No.  
Email: sylvie@scs.carleton.ca  
Date: Fall 1996  1:  
Abstract: Several models for parallel computation were proposed in the last years but only some of them have received considerable attention. This paper gives a survey of algorithms in the BSP, the BSP* and the CGM model. Related work, i.e., BSP- or coarse grained-like algorithms without using these models explicitly, are partly covered, as well. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. Adler, J. W. Byers, R. M. Karp, </author> <title> "Parallel Sorting With Limited Bandwidth", </title> <booktitle> in Proc. 7th ACM Symp. on Parallel Algorithms and Architectures, </booktitle> <pages> pp. 129-136, </pages> <year> 1995. </year>
Reference-contexts: Primitives in the BSP model are also provided by Juurlink et. al. in [42]. Among other algorithms they present a similar result as the broadcast algorithm in [37]. 2 maxfL; 2gng <ref> [n &gt; 1] </ref> + h maxfL; 2gtg [n &lt; p] where h and t are chosen in the same way as above. <p> An over-partitioning scheme is used to reduce load imbalance. The approach was also applied to quicksort and radix sort. Deterministic sorting on a variant of the BSP model, the XPRAM, was also done by Adler, Byers and Karp in <ref> [1] </ref>. (The XPRAM has shared memory and is not discussed in detail in this paper.) The algorithm is based on a version of Columnsort and imposes an upper bound on the sorting problem. <p> Another randomized algorithm of the same authors presented in [35] has the same time complexities but assumes that p and n are such that n log log n log 1+* n = p for * 0. The sorting algorithm in [33][34] improves all the three approaches in <ref> [1] </ref>, [38] and [32] mentioned above. The algorithm needs with high probability (1 + o (1)) T seq p computation and O ( gn log n p ) communication time, for all values of n and p such that p = !( n log log n log n ). <p> But it can also be shown that for the full range of p the number of communication rounds is asymptotically optimal. A variation of Radix Sort is used for a stable sorting algorithm. n integers in the range <ref> [0; 1; : : : ; R 1] </ref> are sorted, for any integer 2 t p. (The algorithm is used as a primitive in [34].) It requires computation time of r (3 maxfL; maxfdn=pe; tdlog t pegg + maxfL; dn=peg + C ppf (p)) and communication time gr (2 maxfL; g; <p> For a randsom set of points in <ref> [0; 1] </ref> d the problems of Voronoi diagram, nearest neighbour, largest empty circle inside the convex hull, largest empty hyperrectangle inside the smallest hyperrectangle which contains the data set are solved with high probability algorithms.
Reference: [2] <author> A. Aggarwal, A. K. Chandra, M. Snir, </author> <title> "Communication complexity of PRAMs", </title> <booktitle> in Theoretical Computer Science, </booktitle> <volume> 71: </volume> <pages> pp. 3-28, </pages> <year> 1990. </year>
Reference-contexts: T n ppf (p) = C n M n ppf (p) denotes the total time for n independent parallel prefix opertions. * sorting (see section 2.2) These results were refined and extended in [37] to a n-word broadcasting that needs for any integer t in <ref> [2; : : : ; p] </ref> 2 maxfL; g (p 1)d n eg [n p] + (2h 1) maxfL; gtd n eg [n &lt; p] time, where h = dlog t ((t 1)dp=ne + 1)e 1. <p> Each processor computes an n p 1=2 fi n p 1=2 submatrix of C and the input matrices A and B are uniformly distributed among the processors. An alternative algorithm is given in <ref> [2] </ref> which requires fewer messages and runs in O ( n 3 p ), provided l = O ( n 3 p ) and g = O ( n A more efficient but more complex realisation of the n 3 algorithm, due to McColl and Valiant, is given in [52].
Reference: [3] <author> A. Alexandrov, M. Ionescu, K. E. Schauser, C. Scheiman, "LogGP: </author> <title> Incorporating Long Messages into the LogP Model", </title> <booktitle> in 7th Annual Symposium on Parallel Algorithms and Architectures (SPAA'95), </booktitle> <month> July </month> <year> 1995. </year>
Reference-contexts: Related work, i.e., BSP or coarse grained-like algorithms without using the model explicitly are partly covered, as well. The survey does not include the work in the C 3 model [41], the LogP [21] model and its extension, the LogGP <ref> [3] </ref> model, although some research has been done in these models, too. Some conclusions end the paper. 2 Algorithms 2.1 Communication and Computation Primitives In the literature quite a lot of primitives have been proposed. Primitives have been modified to match the goal for more complex algorithms that use them.
Reference: [4] <author> A. G. Alexandrakis, A. V. Gerbessiotis, D. S. Lecomber, C. J. Siniolakis, </author> <title> "Bandwidth, Space and Computation Efficient PRAM Programming: The BSP Approach", </title> <booktitle> in Proceedings of SUPEUR'96, </booktitle> <address> Krakow, </address> <month> May </month> <year> 1996. </year>
Reference-contexts: 1 INTRODUCTION 3 simulate PRAM algorithms optimally on distributed memory parallel systems. For some cases and with the help of the BSP library, it can be done efficiently, see e.g. <ref> [4] </ref>, but in other cases, e.g., when g is high, the simulation performs badly [38] . Unfortunately, this is true for most currently available multiprocessors.
Reference: [5] <author> D. A. Bader, J. Jaa, </author> <title> "Parallel Algorithms for Image Histogramming and Connected Components with an Experimental Study", </title> <booktitle> in 5th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, </booktitle> <year> 1995. </year>
Reference-contexts: The algorithms use a known approach but the communication rounds are reduced to O (log p) and blockwise communication is used. Experimental results show that this algorithm performs for larger inputs better than the compared algorithm of Bader et. al. in <ref> [5] </ref>. 2.8 Applications using BSP There is a wide range of application where the considered models are applicable. As an example, two simulations are described here which make use of the BSP model. Several BSP variants of conservative simulation algorithms are given by Calinescu in [17].
Reference: [6] <author> A. Baumker, W. Dittrich, </author> <title> "Parallel Algorithms for Image Processing: Practical Algorithms with Experiments", </title> <booktitle> in Proc. of the 10th IPPS, </booktitle> <year> 1996, </year> <pages> pp. 429-433. </pages>
Reference-contexts: The algorithms are fairly simple (contrary to former work) and use the notion of a derived grid and oversampling of the image to reduce the computation of the block-based MAT. In <ref> [6] </ref> an BSP*-algorithm is proposed for a basic image processing problem, the Connected Component Labeling.
Reference: [7] <author> A. Baumker, W. Dittrich, </author> <title> "Fully dynamic search trees for an extension of the BSP model", </title> <booktitle> in Proc. of the 8th SPAA, </booktitle> <year> 1996, </year> <pages> pp. 233-242. </pages>
Reference-contexts: This algorithms is used in <ref> [7] </ref> as a primitive. Two cases are differentiated: n p = log 1+ff and p = n ff . <p> If m is polynomial in n and some appropriate values for g and * the algorithm is c-optimal for some constant c, i.e., it takes (c + o (1)) n log m p computation time and o (1) n log m p communication time. In <ref> [7] </ref> Baumker and Dittrich present an algorithm on dynamic search trees for the BSP* model contrary to their previous work on static search trees. Their data structure, called BB*-tree, supports n-element search, insert and delete. The algorithms maintain a 2-3 tree under insert and delete.
Reference: [8] <editor> A. Baumker, W. Dittrich, F. Meyer auf der Heide, </editor> <title> "Truly Efficient Parallel Algorithms: c-Optimal Multisearch for an Extension of the BSP Model", </title> <booktitle> in Proc. of European Symposium on Algorithms, </booktitle> <year> 1995, </year> <pages> pp. 17-30. </pages>
Reference-contexts: Therefore, algorithms are designed in the BSP model which try to utilize local computations and minimize global operations instead of simulating PRAM algorithms. 1.2 BSP*-Model A extension of Valiant's BSP model was proposed by Baumker, Dittrich and Meyer auf der Heide <ref> [8] </ref> in 1995 . They added to the parameters p, L and g a parameter B, which is the minimum size that a message must have to fully exploit the bandwidth of the router. Messages of smaller size than B are treated the same way as messages of size B. <p> O (1)g) where T ppf (p) is the time required for the earlier in the text mentioned parallel prefix operation (see section 2.1, for n = 1). (This result is used in some work of Gerbessiotis and Siniolakis as a primitive.) 2 ALGORITHMS 7 Using a load balance method of <ref> [8] </ref> for the rearrangement of the keys while sorting with Valiant's Samplesort [38] in the BSP* model, gives also an improvement upon [38]. This algorithms is used in [7] as a primitive. Two cases are differentiated: n p = log 1+ff and p = n ff . <p> A variation of this algorithm is used to solve the problem for changing node values. The same time and space as in the above algorithm are achieved. Baumker et. al. propose in <ref> [8] </ref> two parallel algorithms for multisearch on the BSP* Model. In contrary to Dehne's algorithm, this approach considers constant factors and blockwise communication. The first of the presented algorithms works for the case of many queries compared to the number of segments, i.e., m n and is deterministic. <p> As in <ref> [8] </ref> for the case m n a deterministic algorithm is applied, and for the case m &gt; n a randomized solution is given. In fact, when the out-degree of the graph is limited by the block size, the results are similar to those in [8] on the BSP* model, but the <p> As in <ref> [8] </ref> for the case m n a deterministic algorithm is applied, and for the case m &gt; n a randomized solution is given. In fact, when the out-degree of the graph is limited by the block size, the results are similar to those in [8] on the BSP* model, but the work of Gerbessiotis et. al. gives a algorithms for a wider spectrum of graphs (namely ordered h-level graphs) contrary to static balanced d-ary trees in [8]. (Applying the presented algorithm to the multi-way point location, induced by n queries, n = !(p log p), <p> the out-degree of the graph is limited by the block size, the results are similar to those in <ref> [8] </ref> on the BSP* model, but the work of Gerbessiotis et. al. gives a algorithms for a wider spectrum of graphs (namely ordered h-level graphs) contrary to static balanced d-ary trees in [8]. (Applying the presented algorithm to the multi-way point location, induced by n queries, n = !(p log p), Gerbessiotis et. al. describe furthermore a 1-optimal algorithm for this problem.) Ferreira et. al present in [29] an algorithm for d-dimensional range search (description of the problem: see Appendix) on the CGM
Reference: [9] <editor> A. Baumker, W. Dittrich, F. Meyer auf der Heide, </editor> <title> "Truly Efficient Parallel Algorithms: 1-Optimal Multisearch for an Extension of the BSP Model", </title> <note> in Technical Report Un-viversity of Paderborn, 1996. REFERENCES 20 </note>
Reference-contexts: For the second case the nodes are distributed among the processors partially randomly. Therefore some locality is maintained so that blockwise communication can be exploited. "Large" and "small" jobs are differently but at the same time handled. These results have been improved by the same authors in <ref> [9] </ref>, so that even the randomized approach for the second case is 1-optimal with high probability for n p log 3 n. 2 ALGORITHMS 9 In another paper [11] Baumker et. al. present a variation of the above deterministic algorithm for multisearch on the BSP* Model, but for the case m <p> Their data structure, called BB*-tree, supports n-element search, insert and delete. The algorithms maintain a 2-3 tree under insert and delete. Two versions are developed: The first one uses a mapping of a high degree static search tree used in <ref> [9] </ref> and allows a 1-optimal search and amortized c-optimal insertion and deletion for a small constant c. Using a randomized mapping of the tree nodes, a 2-optimal search, and c-optimal deletion and insertion for a small constant c can be achieved for the worst case.
Reference: [10] <editor> A. Baumker, W. Dittrich, F. Meyer auf der Heide, I. Rieping, </editor> <title> "Realistic Parallel Algorithms: Priority Queue Operations and Selection for the BSP* Model", </title> <booktitle> in Proc. </booktitle> <institution> of Euro-Par'96, LIP, Ecole Normale Superiure de Lyon, Lyon, France, </institution> <month> August </month> <year> 1996, </year> <pages> pp. 27-29 </pages>
Reference-contexts: Selection is the problem of finding the Cth smallest key in a set of n input keys. The time complexity of the randomized algorithm is with high probability n+C p + o ( n A similar algorithm was independently developed by Baumker et. al. in <ref> [10] </ref>. The randomized selection algorithm is work-optimal and uses less communication time as previous ones. If the input keys are randomly distributed, the algorithm requires asymptotically less communication than computation. It is based on oversampling and "random distribution" of the query elements. <p> The presented algorithms are based on a new randomized mapping of a variant of n-Bandwidth-Heaps, called (n,d)-Bandwidth-Concurrent-Heap. The algoriths use a new selection algorithm which is mentioned in section 2.5. Two randomized approaches for a priority queue are proposed for the BSP*-Model in <ref> [10] </ref>. The two algorithms are work-optimal and need asymptotically less communication than computation time and use blockwise communication. The work is foccused on the insertion of n keys (Insert) and deletion of the best m keys (DeleteMin). N dennotes the total number of keys currently stored in the queue.
Reference: [11] <author> A. Baumker, W. Dittrich, A. Pietracaprina, </author> <title> "The Deterministic Complexity of Parallel Multisearch", </title> <booktitle> in Proc. 5th SWAT, </booktitle> <year> 1996. </year>
Reference-contexts: These results have been improved by the same authors in [9], so that even the randomized approach for the second case is 1-optimal with high probability for n p log 3 n. 2 ALGORITHMS 9 In another paper <ref> [11] </ref> Baumker et. al. present a variation of the above deterministic algorithm for multisearch on the BSP* Model, but for the case m = !(n). This approach exploits redundant representation of the segments.
Reference: [12] <author> G. E. Belloch, C. E. Leiserson, B. M. Maggs, C. G. Plaxton, S. J. Smith, M. Zagha, </author> <title> "A Comparison of Sorting Algorithms for the Connection Machine CM-2", </title> <booktitle> in SPAA91, </booktitle> <pages> pp. 3-16. </pages>
Reference-contexts: It is used for a lots of problems. Each of the following algorithms assumes that at the beginning the n items are evenly distributed among the p processors. Coarse-grained sorting algorithms not explicitly done in one of the models include the work of <ref> [12] </ref> and [43]. In [12] coarse-grained sorting algorithms were analyzed. The work 2 ALGORITHMS 6 includes Batcher's bitonic sort, radix sort, and a sample sort. Another coarse-grained sorting algorithm with only a few communications was done by Li and Sevcik [43]. <p> It is used for a lots of problems. Each of the following algorithms assumes that at the beginning the n items are evenly distributed among the p processors. Coarse-grained sorting algorithms not explicitly done in one of the models include the work of <ref> [12] </ref> and [43]. In [12] coarse-grained sorting algorithms were analyzed. The work 2 ALGORITHMS 6 includes Batcher's bitonic sort, radix sort, and a sample sort. Another coarse-grained sorting algorithm with only a few communications was done by Li and Sevcik [43].
Reference: [13] <author> R. H. Bisseling, </author> <title> "Sparse Matrix Computations on Bulk Synchronous Parallel Computers", </title> <journal> in Zeitschrift fuer Angewandte Mathematik und Mechanik (Special issue Proceedings International Conference on Industrial and Applie Mathematics), </journal> <year> 1996 </year>
Reference-contexts: Its time complexity is O ( n 2 p + gn p 1=2 ) which is optimal. This bound can be gained by both, a block-grid and by a block-block distribution of matrix A. Another kind of sparse matrix computation on the BSP model was analysed by Bisseling in <ref> [13] </ref>, namely for sparse Cholesky factorisation. The Cholesky factor L of a real symmetric positive definite matrix A is defined as the lower triangular matrix that satisfies A = L L T .
Reference: [14] <author> R. H. Bisseling, W. F. McColl, </author> <title> "Scientific Computing on Bulk Synchronous Parallel Architectures", </title> <type> in Technical Report 836, </type> <institution> Department of Mathematics, University of Utrecht, </institution> <month> December </month> <year> 1993. </year>
Reference-contexts: Thus, the running time of O ( n 3 p ) can be achieved with l = O ( n 3 p 3=2 ) and g = O ( n The multiplication of a sparse matrix A with a dense vector in the BSP model is considered in <ref> [14] </ref>. Matrix A has to be distributed in a Cartesian manner, i.e., the p processors are numbered by two-dimensional coordinates (s,t), and that each matrix row (column) is assigned to a set of processors with the same first (second) coordinate. This leads to a simple sparse matrix vector algorithm.
Reference: [15] <author> L. Boxer, R. Miller, A. Rau-Chaplin, </author> <title> "Some Scalable Parallel Algorithms for Geometric Problems", </title> <booktitle> in Proc. 8th Int. Conf. on Parallel and Distributed Computing and Systems (PDCS'96), </booktitle> <address> Chicago, </address> <month> October </month> <year> 1996. </year>
Reference-contexts: A CGM (s; p) consists of p processors P 1 ; : : : ; P p , where each processor has O ( s p ) local memory. (In some work <ref> [15] </ref> [16] ( n p ) local memory is assumed.) The processors can be connected through any communication medium, i.e., any interconnection network or shared memory. The local memory will typically be "considerably lager" than O (1) (e.g., s p p). This feature gives the model its name "coarse grained". <p> Laurence, Miller and Rau-Chaplin present in <ref> [15] </ref> an algorithm for the All Rectangle (AR) problem on the CGM (n,p) with ( n p ) local memory. The AR problem is to find all rectangles whose vertices are in a given set S R 2 ; jSj = n. <p> T sort (n; p) denotes the time required by the most efficient algorithm to sort fi (n) data items on a CGM (n; p) and T seq (n) the running time of the best sequential solutions. Moreover, <ref> [15] </ref> gives an algorithm for the Iso-oriented Line Intersection Counting (LIC) problem: Given a set S of iso-oriented, i.e., vertical or horizontal, line segments in the plane. The LIC problem is to determine for each line segment s 2 S the number of other line segments that s intersects. <p> The LIC problem is to determine for each line segment s 2 S the number of other line segments that s intersects. The algorithm in <ref> [15] </ref> solves this problem in T seq p + T sort (n; p) on a CGM (n; p). It is based on a partitioning of the plane in horizontal and vertical slabs. Lower envelope problems are also addressed in [15]: The lower envelope (LE) of poly nomials of degree at most <p> The algorithm in <ref> [15] </ref> solves this problem in T seq p + T sort (n; p) on a CGM (n; p). It is based on a partitioning of the plane in horizontal and vertical slabs. Lower envelope problems are also addressed in [15]: The lower envelope (LE) of poly nomials of degree at most k can be done in time T sort (p (( n p ; k + 2); k + 2); p) on a p ; k + 2); k + 2); p), if the domain of each polynomial function is
Reference: [16] <author> L. Boxer, R. Miller, A. Rau-Chaplin, </author> <title> "Some Scalable Parallel Algorithms for Geometric Problems", </title> <type> in Technical Report 96-12, </type> <institution> SUNY at Buffalo Department of Computer Science, </institution> <year> 1996. </year>
Reference-contexts: A CGM (s; p) consists of p processors P 1 ; : : : ; P p , where each processor has O ( s p ) local memory. (In some work [15] <ref> [16] </ref> ( n p ) local memory is assumed.) The processors can be connected through any communication medium, i.e., any interconnection network or shared memory. The local memory will typically be "considerably lager" than O (1) (e.g., s p p). This feature gives the model its name "coarse grained". <p> Other sort-based primitives on the CGM (n,p) with ( n p ) memory per processor can be found in <ref> [16] </ref>. Boxer et. al. describes algorithms for permutation exchange, merge, search, formation of combinations and pairs, etc.. 2.2 Sorting Sorting is one of the most important problems in computer science. It is used for a lots of problems. <p> It runs in T sort (n 2 log n; p) on a CGM (n 2 log n; p) and uses the fact that a rectangle may be determined by a pair of opposite sides with non-negative slope. This algorithm can be modified to solve other rectangle problems <ref> [16] </ref>: the All Isonormal Rectangles and All Squares problem in T sort (n 2 ; p) on a CGM (n 2 ; p), and the All Isonormal Squares in T sort (n 3=2 ; p) on a CGM (n 3=2 ; p). <p> These problems can be determined for a set of n points in slightly more than linear time and space. In the technical report <ref> [16] </ref> belonging to this paper even more problems are solved. Find 2 ALGORITHMS 13 ing the minimal subset of a set of n circular arcs that covers a circle (miminal cover of a circle) can be solved in optimal time T sort (n; p) on a CGM (n; p).
Reference: [17] <author> R. Calinescu, </author> <title> "Conservative discrete-event simulations on bulk synchronous architectures", </title> <note> in Technical Report TR-16-95, </note> <institution> Oxford University, </institution> <year> 1995 </year>
Reference-contexts: As an example, two simulations are described here which make use of the BSP model. Several BSP variants of conservative simulation algorithms are given by Calinescu in <ref> [17] </ref>. The work shows that the BSP algorithms achieve significant speed-ups and allow an analysis of the algorithms. Another kind of simulations, plasma simulations, were also applied to the BSP Model (on a network of workstations) [47]. The plasma particles are modeled on a grid.
Reference: [18] <author> A. Chan, F. Dehne, A. Rau-Chaplin, </author> <title> "Coarse Grained Parallel Geometric Search", </title> <note> 1996, submitted to IPPS'97. </note>
Reference-contexts: In the search algorithm to balance the number of queries in the subtrees, subtrees are copied and distributed if necessary. To distribut the number of reports, queries are copied. In <ref> [18] </ref> Dehne, Chan, and Rau-Chaplin present two algorithms for the next element search problem on the CGM (n,p). 2 ALGORITHMS 10 Given a set of m query points, a set of n non-intersecting line segments and a direction, the next element search problem consists of determining for each point of the <p> This result was improved by an algorithm of Dehne et. al. in <ref> [18] </ref> which is based on next element search mentioned earlier (section 2.3) in the text. The problem of trapezoidal decomposition can be solved on a CGM in O (1) communication rounds and O ( n p log n) local computation using O ( n p log n) memory per processor. <p> The problem of trapezoidal decomposition can be solved on a CGM in O (1) communication rounds and O ( n p log n) local computation using O ( n p log n) memory per processor. Moreover, using the same algorithm of next element search in <ref> [18] </ref>, other computational geometry problems can be solved: The planar subdivision search problem (see appendix) and the triangulation problem for a simple polygon.
Reference: [19] <author> T. Cheatham, </author> <title> "Linguistic Constructs for BSP Style Programming", </title> <booktitle> Proceedings of 8th Annual ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <month> July </month> <year> 1996. </year>
Reference-contexts: The BSP approach has evaluated to more than a computational model. Efforts have REFERENCES 19 been made for a BSP standard. A BSP library that provides communication primitives has been established. Research is being done to develope a general purpose parallel computation environment based on the BSP model. Cheatham <ref> [19] </ref> describes such an approach called H-BSP. Moreover, there are other approaches for parallel applications of using the BSP model, e.g., building a scalable parallel object dadabase [50].
Reference: [20] <author> R. Cole, </author> <title> "Parallel Merge Sort", </title> <journal> in SIAM J. Comput., </journal> <volume> 17(4): </volume> <pages> 770-785, </pages> <year> 1988. </year>
Reference: [21] <author> D. Culler, R. Karp, D. Patterson, A. Sahay, K. E. Schauser, E. Santos, R. Subramonian, T. von Eicken, </author> <title> "LogP: Towards a Realistic Model of Parallel Computation", </title> <booktitle> in Proceedings of 4th ACM SIGPLAN Symp. on Principles and Practices of Parallel Programming, </booktitle> <pages> pp. 1-12, </pages> <year> 1993 </year>
Reference-contexts: Related work, i.e., BSP or coarse grained-like algorithms without using the model explicitly are partly covered, as well. The survey does not include the work in the C 3 model [41], the LogP <ref> [21] </ref> model and its extension, the LogGP [3] model, although some research has been done in these models, too. Some conclusions end the paper. 2 Algorithms 2.1 Communication and Computation Primitives In the literature quite a lot of primitives have been proposed.
Reference: [22] <author> F. Dehne, X. Deng, P. Dymond, A. Fabri, A. Khokhar, </author> <title> "A Randomized Parallel 3D Convex Hull Algorithm For Coarse Grained Multicomputers", </title> <booktitle> in Proc. of the ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <address> Santa Barbara, USA, 1995 REFERENCES 21 </address>
Reference-contexts: The algorithm uses the idea of selecting splitter sets. The problem of the computing a convex hull for 3 dimensions is addressed in <ref> [22] </ref> by Dehne et. al.. They present a randomized parallel algorithm designed on the CGM (n,p), for n p p 2+* ; * &gt; 0 an arbitrary small constant. The algorithm can also be transfered to the BSP model.
Reference: [23] <author> F. Dehne, A. Fabri, A. Rau-Chaplin, </author> <title> "Scalable Parallel Computational Geometry for Coarse Grained Multicomputers", </title> <booktitle> in Proc. ACM Symposium on Computational Geometry, </booktitle> <year> 1993, </year> <pages> pp. 298-307. </pages>
Reference-contexts: the charged time is maxft; Lg. * and the communication supersteps: The routing of an h-relation where the messages have sizes at most s costs in this model maxfg h d s B e; Lg. 1.3 CGM Model The Coarse Grained Multicomputer (CGM) model was proposed by Dehne et. al. <ref> [23] </ref> in 1993. <p> Using a constant number of global sort operations and O ( n p ) time local computations, Dehne et. al. present in <ref> [23] </ref> the following primitives: segmented broadcast, multinode broadcast, total exchange and partial sum. <p> Sequentially, multisearch can be done in time n log m in the worst case. In <ref> [23] </ref> Dehne et. al. describes an algorithm for the multisearch problem on the CGM. The processors need local memory of size O ( n p ), n p p. <p> This algorithm is based on the lower envelope algorithm that was proposed in <ref> [23] </ref> by Dehne et. al.. 2.4 Geometric Problems Note that search algorithms are listed under section 2.3. 2.4.1 Convex Hull Problems The convex hull for a set of n points is a fundamental problem in computational geometry. <p> of points of the original data set that lie in a cone (formed by starting at the origin and including a face of the convex hull of the sampling) or lie on a plane which goes through a neighbouring face. 2.4.2 Other Computational Geometry Problems Dehne et. al. present in <ref> [23] </ref> several algorithms for computational geometry problems on the CGM (n; p); n p p, . <p> Contrary to these deterministic algorithms Dehne et. al. present in [24] high probability algorithms on a variation of the CGM (n,p) for some geometric problems and improve the time complexity for the earlier <ref> [23] </ref> presented lower envelope algorithm. The algorithms are applicable for n p p ff , ff an arbitrary small but fixed constant and n "a large number". The main drawback of these algorithms, however, is that the complexity analysis holds only for uniformly distributed data.
Reference: [24] <author> F. Dehne, C. Kenyon, A. Fabri, </author> <title> "Scalable And Architecture Independent Parallel Geometric Algorithms With High Probability Opitmal Time", </title> <booktitle> in Proc. IEEE Symposium on Parallel and Distributed Processing, </booktitle> <address> Dallas, Tx, </address> <year> 1994, </year> <pages> pp. 586-593. </pages>
Reference-contexts: Several work has been done to solve it in the coarse grained setting, especially for the 2d case. O (1) communication phases with high probabilit are achieved in the randomized approach of Dehne et. al. in <ref> [24] </ref> on a variation of the CGM (n,p). The required computation time of the algorithm is (k + 2)( T 1 (n) p )), where k is a fixed constant, and for practical purposes it can be assumed that k 6. <p> The first one is deterministic and needs O (log p) communication phases. The second one is a randomized approach with a constant number of communication rounds and does not assume uniform distribution as the approach in <ref> [24] </ref>. Finally, a deterministic 2d convex hull algorithm with a constant number of communication rounds could be developed by Diallo et. al. [27] on the CGM (n,p). <p> Contrary to these deterministic algorithms Dehne et. al. present in <ref> [24] </ref> high probability algorithms on a variation of the CGM (n,p) for some geometric problems and improve the time complexity for the earlier [23] presented lower envelope algorithm. The algorithms are applicable for n p p ff , ff an arbitrary small but fixed constant and n "a large number".
Reference: [25] <author> F. Dehne, S. W. Song, </author> <title> "Randomized Parallel List Ranking for Distributed Memory Multiprocessors", </title> <year> 1996. </year>
Reference-contexts: This problem is considered by Dehne and Song in <ref> [25] </ref> on the CGM with O ( n p ) local memory per processor and n p p. A simple version of the algorithm requires with high probability O (log p + log log n) communication rounds.
Reference: [26] <author> X. Deng, N. Gu, </author> <title> "Good algorithm design style for multiprocessors", </title> <booktitle> Proceedings of the 6th IEEE Symposium on Parallel and Distributed Processing, </booktitle> <address> Dallas, Usa, </address> <month> October </month> <year> 1994. </year>
Reference-contexts: This algorithm can be used for higher dimensional convex hull problems, as well. However, the algorithm makes the assumption that the points are uniformly distributed, which is the main drawback of this algorithm. Deng and Gu describe in <ref> [26] </ref> two 2d convex algorithms for the case n p p 2+* , * &gt; 0. The first one is deterministic and needs O (log p) communication phases.
Reference: [27] <author> A. Diallo, A. Ferreira, A. Rau-Chaplin, S. Ubeda, </author> <title> "Scalable 2d Convex Hull and Triangulation Algorithms for Coarse Grained Multicomputers", </title> <booktitle> in Proc. 7th IEEE Symposium on Parallel and Distributed Processing (SPDD'95), </booktitle> <year> 1995. </year>
Reference-contexts: T 1 (n) denotes the high probability sequential time complexity of the convex hull problem. The algorithm is applicable for n p p ff , ff &gt; 0 an arbitrary small but fixed constant and the number of points n needs to be "large". In <ref> [27] </ref> these assumption were combined to n p p 2+* ; * &gt; O. This algorithm can be used for higher dimensional convex hull problems, as well. However, the algorithm makes the assumption that the points are uniformly distributed, which is the main drawback of this algorithm. <p> The second one is a randomized approach with a constant number of communication rounds and does not assume uniform distribution as the approach in [24]. Finally, a deterministic 2d convex hull algorithm with a constant number of communication rounds could be developed by Diallo et. al. <ref> [27] </ref> on the CGM (n,p). <p> Based on the convex hull algorithm in <ref> [27] </ref> (see section 2.4.1) a triangulation algorithm for n points in R 2 is presented [27]. It runs on a CGM (n,p) with O ( n p ) local memory, in O ( n log n p + T s (n; p)); n p 1+* ; * &gt; 0. <p> Based on the convex hull algorithm in <ref> [27] </ref> (see section 2.4.1) a triangulation algorithm for n points in R 2 is presented [27]. It runs on a CGM (n,p) with O ( n p ) local memory, in O ( n log n p + T s (n; p)); n p 1+* ; * &gt; 0.
Reference: [28] <author> A. Fabri, O. Devillers, </author> <title> "Scalable Algorithms for Bichromatic Line Segment Intersection Problems on Coarse Grained Multicomputers", </title> <booktitle> in Proc. 3rd Workshop on Algorithms and Data Structures, Lecture Notes in Computer Science, </booktitle> <volume> Volume 709, </volume> <pages> pp. 277-288, </pages> <year> 1993. </year>
Reference-contexts: Although multisearch and next element search have their applications in computational geometry, search algorithms might be of general interest and are, therefore, listed in a seperate section (and not in section 2.4). A binary search algorithm with n queries in a sorted sequence of n elements is given in <ref> [28] </ref>. Each processor holds initially a consecutive subsequence of n p elements and n p queries. <p> The sequential time for counting is fi (n log n) and for report fi (n log n + k) with k the number of intersections. For these problems Fabri et. al. constructed algorithms on the CGM <ref> [28] </ref>. <p> The problem is to report all pairs of points and segments where a point is covered by a segment. This problem can be solved <ref> [28] </ref> on an CGM (max (n; k); p); n p p, in time O ( n log n p + k p + T s (n; p)), where k is the size of the output and T s (n; p) as mentioned earlier in the text. <p> In [38] a straight-forward algorithm for the Gauss-Jordan elimination is given. The rows and the columns of the n fi n-matrix are divided into p p pieces, each owned by a processor. (The running time is somewhat difficult to describe in the parameters, and is, therefore, not mentioned here.) <ref> [28] </ref> 2.7.3 Miscellanous The list ranking problem consists of determining for each element in a linear linked list the distance to the last element in the list.
Reference: [29] <author> A. Ferreira, C. Kenyon, A. Rau-Chaplin, S. Ub'eda, </author> <title> "d-Dimensional Range Search on Multicomputers", </title> <note> in Technical Report RR96-23, </note> <institution> Laboratoire de l'informatique du Par-all'elisme, </institution> <month> August </month> <year> 1996. </year>
Reference-contexts: A CGM algorithm consists of alternating local computation and global communication rounds. In a communication round a single h-relation (with h = O ( n p )) is routed, i.e., each processor sends O ( n p ) and receives O ( n p ) data. (In some work <ref> [29] </ref> h = O ( s p ).) The time for a CGM algorithm is the sum of the times for the computation and communication rounds. <p> wider spectrum of graphs (namely ordered h-level graphs) contrary to static balanced d-ary trees in [8]. (Applying the presented algorithm to the multi-way point location, induced by n queries, n = !(p log p), Gerbessiotis et. al. describe furthermore a 1-optimal algorithm for this problem.) Ferreira et. al present in <ref> [29] </ref> an algorithm for d-dimensional range search (description of the problem: see Appendix) on the CGM (s,p), s = n log d1 n. They use a distributed version of the range tree in a fashion of figure 1.
Reference: [30] <author> A. Ferreira, J. M. Robson, </author> <title> "Fast and Scalable Parallel Algorithms for Knapsack-Like Problems" </title>
Reference-contexts: Ferreira et. al. show in <ref> [30] </ref> two algorithms for this kind of problem. One of them can be run with optimal speed-up on a coarse-grained multicomputer with p n and memory size of O (n).
Reference: [31] <author> A. Ferreira, S. Ubeda, </author> <title> "Computing the Medial Axis Transform in Parallel with 8 scan operations" </title>
Reference-contexts: The medial axis is a shape descriptor that allows a full reconstruction of the original shape and has good properties for data reduction. Ferreira et. al. show in <ref> [31] </ref> that the medial axis transform (MAT) in parallel can be done by using a constant (in particular: 8) number of scan (parallel prefix) operations. There are two forms of MAT: distance-based and block based MAT.
Reference: [32] <author> A. V. Gerbessiotis, C. J. Siniolakis, </author> <title> "Deterministic Sorting and Randomized Median Finding on the BSP model", </title> <booktitle> in Proceedings of the 8th ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <year> 1996. </year>
Reference-contexts: Another deterministic sort is proposed by Gerbessiotis et. al. in <ref> [32] </ref> on the BSP model, which improves the upper bound of Adler's algorithm. <p> The sorting algorithm in [33][34] improves all the three approaches in [1], [38] and <ref> [32] </ref> mentioned above. The algorithm needs with high probability (1 + o (1)) T seq p computation and O ( gn log n p ) communication time, for all values of n and p such that p = !( n log log n log n ). <p> that the region between the convex hull of two x-disjoint subsets is a funnel-shaped polygon, for which the convex hull is easier to determine. 2.5 Selection and Related Problems The median of n distinct elements can be found on the BSP model with a randomized algorithm of Gerbessiotis et. al. <ref> [32] </ref>. With high probability the algorithm is optimal using 3n p ) comparisons, provided that n p = ! n log n, with ! n any slow growing function of n so that ! n ! 1 as n ! 1.
Reference: [33] <author> A. V. Gerbessiotis, C. J. Siniolakis, </author> <title> "Communication Efficient Data Structures on the BSP Model with Applications in Computational Geometry", </title> <booktitle> in Proceedings of Eu-roPar'96, Lyon, France, Leture Notes in Computer Science, </booktitle> <publisher> Springer-Verlag, </publisher> <month> August </month> <year> 1996. </year>
Reference-contexts: The amortized approach holds for a wider range of parameters. Both algorithms need memory proportional to m. Multi-way search on an ordered h-level graph on the BSP model is given by Gerbessiotis et. al. in <ref> [33] </ref>, [34]. (The multi-way search problem is to find the search paths induced by the queries on the ordered h-level graph and is, therefore, a slightly more difficult problem than the multisearch.) Ordered h-level graphs contain most of the standard data structures.
Reference: [34] <author> A. V. Gerbessiotis, C. J. Siniolakis, </author> <title> "Communication Efficient Data Structures on the BSP Model with Applications in Computational Geometry", </title> <type> in Technical Report, </type> <institution> PRG-TR-13-96, Oxford University Computing Laboratory, </institution> <year> 1996. </year>
Reference-contexts: In both cases k denotes the number of supersteps which can be chosen as large as log p. In the work of Gerbessiotis and Siniolakis in the BSP model the following results on primitives are used: * n-word broadcasting <ref> [34] </ref> [36]: M n n e + h 1) maxfL; gtd n eg for any integer 2 t p, where h = dlog t ((t 1)p + 1)e 1. 2 ALGORITHMS 5 * n independent parallel prefix [34] [36] : computation time C n n e + h 1) maxfL; td <p> the BSP model the following results on primitives are used: * n-word broadcasting <ref> [34] </ref> [36]: M n n e + h 1) maxfL; gtd n eg for any integer 2 t p, where h = dlog t ((t 1)p + 1)e 1. 2 ALGORITHMS 5 * n independent parallel prefix [34] [36] : computation time C n n e + h 1) maxfL; td n eg and communication time of M n ppf (p) = 2 M n brd (p) the broadcast time for n elements mentioned above, but for h = dlog t pe and any integer 2 t p. <p> A variation of Radix Sort is used for a stable sorting algorithm. n integers in the range [0; 1; : : : ; R 1] are sorted, for any integer 2 t p. (The algorithm is used as a primitive in <ref> [34] </ref>.) It requires computation time of r (3 maxfL; maxfdn=pe; tdlog t pegg + maxfL; dn=peg + C ppf (p)) and communication time gr (2 maxfL; g; maxfdn=pe; tdlog t pegg + maxfL=g; dn=peg + M ppf (p)), where r = d log R log maxfdn=pe;tdlog t peg e. <p> The amortized approach holds for a wider range of parameters. Both algorithms need memory proportional to m. Multi-way search on an ordered h-level graph on the BSP model is given by Gerbessiotis et. al. in [33], <ref> [34] </ref>. (The multi-way search problem is to find the search paths induced by the queries on the ordered h-level graph and is, therefore, a slightly more difficult problem than the multisearch.) Ordered h-level graphs contain most of the standard data structures.
Reference: [35] <author> A. V. Gerbessiotis, C. J. Siniolakis, </author> <title> "Randomized BSP Sorting", </title> <note> submitted in 1996. REFERENCES 22 </note>
Reference-contexts: Another randomized algorithm of the same authors presented in <ref> [35] </ref> has the same time complexities but assumes that p and n are such that n log log n log 1+* n = p for * 0. The sorting algorithm in [33][34] improves all the three approaches in [1], [38] and [32] mentioned above.
Reference: [36] <author> A. V. Gerbessiotis, C. J. Siniolakis, </author> <title> "Selection on the Bulk-Synchronous Parallel Model with Applications to Priority Queues", </title> <booktitle> in Proceedings of the 1996 International Conference on Parallel and Distributed Processing Techniques and Applications (PDPTA'96), </booktitle> <address> Sunnyvale, California, USA, </address> <month> August, </month> <year> 1996. </year>
Reference-contexts: In both cases k denotes the number of supersteps which can be chosen as large as log p. In the work of Gerbessiotis and Siniolakis in the BSP model the following results on primitives are used: * n-word broadcasting [34] <ref> [36] </ref>: M n n e + h 1) maxfL; gtd n eg for any integer 2 t p, where h = dlog t ((t 1)p + 1)e 1. 2 ALGORITHMS 5 * n independent parallel prefix [34] [36] : computation time C n n e + h 1) maxfL; td n <p> BSP model the following results on primitives are used: * n-word broadcasting [34] <ref> [36] </ref>: M n n e + h 1) maxfL; gtd n eg for any integer 2 t p, where h = dlog t ((t 1)p + 1)e 1. 2 ALGORITHMS 5 * n independent parallel prefix [34] [36] : computation time C n n e + h 1) maxfL; td n eg and communication time of M n ppf (p) = 2 M n brd (p) the broadcast time for n elements mentioned above, but for h = dlog t pe and any integer 2 t p. <p> It needs O ( log n log k maxfL; k 2 log k + gk 2 g) time, where k = maxf2; d q To improve the above mentioned algorithm in [38] for the case p &gt; n a randomized sorting algorithm was proposed in <ref> [36] </ref>. <p> With high probability the median of the n elements is in the middle subset which can be shown not to be "large" with high probability. This work was extended to the more general problem of selection on the BSP model in <ref> [36] </ref>. Selection is the problem of finding the Cth smallest key in a set of n input keys. The time complexity of the randomized algorithm is with high probability n+C p + o ( n A similar algorithm was independently developed by Baumker et. al. in [10]. <p> His fine-grained algorithm uses sampling to detect the n smallest values and is improved by some considerations to reduce communication. (But this coarse grained work is not explicitly done in the CGM.) 2 ALGORITHMS 15 This method is improved by the work of Gerbessiotis et. al. in <ref> [36] </ref>. The algorithms require less communication and improve the parallel slack of the parameters to achieve optimal performance. The presented algorithms are based on a new randomized mapping of a variant of n-Bandwidth-Heaps, called (n,d)-Bandwidth-Concurrent-Heap. The algoriths use a new selection algorithm which is mentioned in section 2.5.
Reference: [37] <author> A. V. Gervessiotis, C. J. Siniolakis, </author> <title> "Primitive Operations on the BSP Model", </title> <note> in Technical Report PRG-TR-23-96, </note> <institution> Ocfort University Computing Laboratory, Oxford, </institution> <year> 1996. </year>
Reference-contexts: T n ppf (p) = C n M n ppf (p) denotes the total time for n independent parallel prefix opertions. * sorting (see section 2.2) These results were refined and extended in <ref> [37] </ref> to a n-word broadcasting that needs for any integer t in [2; : : : ; p] 2 maxfL; g (p 1)d n eg [n p] + (2h 1) maxfL; gtd n eg [n &lt; p] time, where h = dlog t ((t 1)dp=ne + 1)e 1. <p> Primitives in the BSP model are also provided by Juurlink et. al. in [42]. Among other algorithms they present a similar result as the broadcast algorithm in <ref> [37] </ref>. 2 maxfL; 2gng [n &gt; 1] + h maxfL; 2gtg [n &lt; p] where h and t are chosen in the same way as above.
Reference: [38] <author> A. V. Gerbessiotis, L. G. Valiant, </author> <title> "Direct Bulk-Synchronous Parallel Algorithms", </title> <journal> in Journal of Parallel and Sistributed Computing, </journal> <volume> 22: </volume> <pages> pp. 251-267, </pages> <year> 1994. </year>
Reference-contexts: 1 INTRODUCTION 3 simulate PRAM algorithms optimally on distributed memory parallel systems. For some cases and with the help of the BSP library, it can be done efficiently, see e.g. [4], but in other cases, e.g., when g is high, the simulation performs badly <ref> [38] </ref> . Unfortunately, this is true for most currently available multiprocessors. <p> Primitives have been modified to match the goal for more complex algorithms that use them. To give priority to these non-primitive algorithms and because of space limitations, only some primitives are mentioned here. In <ref> [38] </ref> Gerbessiotis and Valiant give straight-forward algorithms for broadcasting and parallel prefix. The algorithms use an organization of the processors in a t-ary tree fashion (for an appropriate t). This approach leads for the broadcasting to a communication time of gkmaxf L g ; p k g. <p> The sorted initial runs are sampled. This provides efficiency but still guarantees deterministic behaviour of the algorithm. Gerbessiotis and Valiant present in <ref> [38] </ref> a randomized sorting algorithm on BSP which is based on Samplesort. The algorithm is one-optimal for a range of parameters p; n and L, and also one-optimal in communication if g is bounded appropriately. <p> Another randomized algorithm of the same authors presented in [35] has the same time complexities but assumes that p and n are such that n log log n log 1+* n = p for * 0. The sorting algorithm in [33][34] improves all the three approaches in [1], <ref> [38] </ref> and [32] mentioned above. The algorithm needs with high probability (1 + o (1)) T seq p computation and O ( gn log n p ) communication time, for all values of n and p such that p = !( n log log n log n ). <p> The algorithm provides an optimal BSP sorting algorithm for L and g appropriately bounded and n p. It needs O ( log n log k maxfL; k 2 log k + gk 2 g) time, where k = maxf2; d q To improve the above mentioned algorithm in <ref> [38] </ref> for the case p &gt; n a randomized sorting algorithm was proposed in [36]. <p> earlier in the text mentioned parallel prefix operation (see section 2.1, for n = 1). (This result is used in some work of Gerbessiotis and Siniolakis as a primitive.) 2 ALGORITHMS 7 Using a load balance method of [8] for the rearrangement of the keys while sorting with Valiant's Samplesort <ref> [38] </ref> in the BSP* model, gives also an improvement upon [38]. This algorithms is used in [7] as a primitive. Two cases are differentiated: n p = log 1+ff and p = n ff . <p> 2.1, for n = 1). (This result is used in some work of Gerbessiotis and Siniolakis as a primitive.) 2 ALGORITHMS 7 Using a load balance method of [8] for the rearrangement of the keys while sorting with Valiant's Samplesort <ref> [38] </ref> in the BSP* model, gives also an improvement upon [38]. This algorithms is used in [7] as a primitive. Two cases are differentiated: n p = log 1+ff and p = n ff . <p> A rough estimate of the cost of the algorithm (which only deals with the numerical part) is 2nc 2 p + 2nc m l. In <ref> [38] </ref> a straight-forward algorithm for the Gauss-Jordan elimination is given.
Reference: [39] <author> M. T. Goodrich, </author> <title> "Communication-Efficient Parallel Sorting", </title> <booktitle> in Proc. of the 28 th annual ACM Symposium on Theory of Computing (STOC), </booktitle> <address> May 22-24, Philadelphia, USA, </address> <year> 1996. </year>
Reference-contexts: It is essentially the same as the Coarse Grained Multicomputer model. It was proposed by Goodrich in 1996 <ref> [39] </ref>. Processors are numbered 1; 2; : : : ; p and messages can be duplicated by the network so long as the destinations for any message are a contiguous set of processors i; i + 1; : : : ; j. <p> Finally, with the algorithms presented in <ref> [39] </ref> sorting of n items on the weak-CREW BSP model and on the BSP model can be done in O ( log n log (h+1) ) communication rounds and O ( n log n p ) computation time, where h = fi ( n p ).
Reference: [40] <author> S. E. Hambrusch, </author> <title> "Models for Parallel Computation", </title> <booktitle> in Proceedings of Workshop on Challenges for Parallel Processing, International Conference on Parallel Processing, </booktitle> <year> 1996. </year>
Reference: [41] <author> S. E. Hambrusch, A. Khokhar, </author> <title> "C 3 : A Parallel Model for Coarse-grained Machines", </title> <journal> in Journal on Parallel and Distributed Computing, </journal> <volume> Vol. 32, Nr. 2, </volume> <pages> pp. 139-154, </pages> <year> 1996. </year>
Reference-contexts: Related work, i.e., BSP or coarse grained-like algorithms without using the model explicitly are partly covered, as well. The survey does not include the work in the C 3 model <ref> [41] </ref>, the LogP [21] model and its extension, the LogGP [3] model, although some research has been done in these models, too. Some conclusions end the paper. 2 Algorithms 2.1 Communication and Computation Primitives In the literature quite a lot of primitives have been proposed.
Reference: [42] <author> B. H. H. Juurlink, H. A. G. Wijshoff, </author> <title> "Communication Primitives for BSP computers", </title> <journal> in Information Processing Letters, </journal> <volume> 58 </volume> <pages> 303-310, </pages> <year> 1996. </year>
Reference-contexts: Primitives in the BSP model are also provided by Juurlink et. al. in <ref> [42] </ref>. Among other algorithms they present a similar result as the broadcast algorithm in [37]. 2 maxfL; 2gng [n &gt; 1] + h maxfL; 2gtg [n &lt; p] where h and t are chosen in the same way as above.
Reference: [43] <author> Hui Li, K. C. Sevcik, </author> <title> "Parallel Sorting by Overpartitioning", </title> <booktitle> in SPAA 94, </booktitle> <pages> pp. 46-56, </pages> <year> 1994. </year>
Reference-contexts: It is used for a lots of problems. Each of the following algorithms assumes that at the beginning the n items are evenly distributed among the p processors. Coarse-grained sorting algorithms not explicitly done in one of the models include the work of [12] and <ref> [43] </ref>. In [12] coarse-grained sorting algorithms were analyzed. The work 2 ALGORITHMS 6 includes Batcher's bitonic sort, radix sort, and a sample sort. Another coarse-grained sorting algorithm with only a few communications was done by Li and Sevcik [43]. <p> done in one of the models include the work of [12] and <ref> [43] </ref>. In [12] coarse-grained sorting algorithms were analyzed. The work 2 ALGORITHMS 6 includes Batcher's bitonic sort, radix sort, and a sample sort. Another coarse-grained sorting algorithm with only a few communications was done by Li and Sevcik [43]. They use a single-step algorithm, i.e., merging of the sorted sublists or partitioning into sublists is done in one step. An over-partitioning scheme is used to reduce load imbalance. The approach was also applied to quicksort and radix sort.
Reference: [44] <author> W. F. McColl, </author> <title> "Scalable Parallel Computing: A Grand Unified Theory and its Practical Development", </title> <booktitle> in Proc. 13th IFIP World Computer Congress Volume 1 (Invited Paper), </booktitle> <publisher> Elsevier, </publisher> <year> 1994. </year>
Reference-contexts: Both algorithms use the randomized selection algorithm presented in the same paper and which is mentioned in section 2.5. 2.7 Numerical Problems 2.7.1 Matrix Multiplication: A B = C A straight-forward algorithm for matrix multiplication on the BSP model is given in <ref> [44] </ref> for p n 2 with time complexity O ( n 3 p + n 2 p ), provided l = O ( n 3 p ) and p 1=2 ). <p> It runs in O ( n log 2 7 p + n 2 p 2=log 2 7 g + l) and is applicable for all p n ff , where ff = 2 log 2 7 2.7.2 BSP complexities of some other standard problems The algorithms can be found in <ref> [44] </ref> or in [45]. For an n point FFT computation on the BSP model time O ( n log n p ) is needed provided l = O ( n p ) and g = O (log n p ).
Reference: [45] <author> W. F. McColl, </author> <title> "The BSP Approach to Architecture Independent Parallel Programming", </title> <type> in Technical Report, </type> <institution> Oxford University Computing Laboratory, </institution> <month> December </month> <year> 1994. </year>
Reference-contexts: O ( n log 2 7 p + n 2 p 2=log 2 7 g + l) and is applicable for all p n ff , where ff = 2 log 2 7 2.7.2 BSP complexities of some other standard problems The algorithms can be found in [44] or in <ref> [45] </ref>. For an n point FFT computation on the BSP model time O ( n log n p ) is needed provided l = O ( n p ) and g = O (log n p ).
Reference: [46] <author> W.F. McColl, </author> <title> "A BSP Realisation of Strassen's Algorithm", </title> <type> in Technical Report, </type> <institution> Oxford University Computing Laboratory, </institution> <month> May </month> <year> 1995. </year>
Reference: [47] <author> M. V. Nibhanupudi, C. D. Norton, B. K. Szymanski, </author> <title> "Plasma Simulation on Networks or Workstations using the Bulk-Synchronous Parallel Model", </title> <booktitle> in Proc. International Conference on Parallel and Distributed Techniques and Applications, </booktitle> <address> Athens, GA, </address> <month> November </month> <year> 1995. </year>
Reference-contexts: Several BSP variants of conservative simulation algorithms are given by Calinescu in [17]. The work shows that the BSP algorithms achieve significant speed-ups and allow an analysis of the algorithms. Another kind of simulations, plasma simulations, were also applied to the BSP Model (on a network of workstations) <ref> [47] </ref>. The plasma particles are modeled on a grid. An existing algorithm is modified by using a repicated grid to reduce communication and to group communication together.
Reference: [48] <author> P. Sanders, </author> <title> "Fast Priority Queues for Parallel Branch-and-Bound", in Workshop on Algorithms for Irregular Structured Problems, </title> <publisher> LNCS, </publisher> <address> Lyon, </address> <year> 1995. </year>
Reference-contexts: For n = (p log 4 n) and k any constant the algorithm needs O ( n p + L log p) computation and O ( g B n=p + (L + g) log p) communication time with high probability, provieded B is appropriately bounded. 2.6 Priority Queue Operations Sanders <ref> [48] </ref> created a randomized algorithm of implementing a priority queue where O (n) insert or delete-min functions can be realized with high probability in O (d+log m n ) amortized time, where m 2 (n log n) is the number of elements in the queue. <p> The work is foccused on the insertion of n keys (Insert) and deletion of the best m keys (DeleteMin). N dennotes the total number of keys currently stored in the queue. The fist algorithm is based on the coarse grained algorithm of Sanders <ref> [48] </ref> but uses blockwise communication.
Reference: [49] <author> C. J. Siniolakis, </author> <title> "On the Complexity of BSP Sorting", </title> <note> in Technical Reprort, </note> <institution> PRG-TR-09-96, Oxford University Computing Laboratory, Oxford, </institution> <year> 1996. </year> <note> 4 APPENDIX 23 </note>
Reference-contexts: This approach uses oversampling and an ordered h-level graph, on which the n-way search problem is solved (see section 2.3). The work of [1],[38],[32],[35] is improved by the merge-based sorting algorithm of Sin-iolakis in <ref> [49] </ref>. The algorithm provides an optimal BSP sorting algorithm for L and g appropriately bounded and n p.
Reference: [50] <author> K. R. Sujithan, </author> <title> "Towards a Scalable Parallel Object Database The Bulk Synchronous Parallel Approach", </title> <note> in Technical Report PRG-TR-17-96, </note> <institution> Oxford University, </institution> <month> August </month> <year> 1996 </year>
Reference-contexts: Research is being done to develope a general purpose parallel computation environment based on the BSP model. Cheatham [19] describes such an approach called H-BSP. Moreover, there are other approaches for parallel applications of using the BSP model, e.g., building a scalable parallel object dadabase <ref> [50] </ref>. Despite the considerable amount of work that has been done in BSP- and CGM-like models, there are still a lot of problems for which PRAM, fine-grained, or network dependent algorithms exist but for which solutions in the BSP or CGM setting have not been developed yet.
Reference: [51] <author> L. G. Valiant, </author> <title> "A Bridging Model for parallel Computation", </title> <journal> in Communication of the ACM, </journal> <volume> 33(8) </volume> <pages> 103-111, </pages> <year> 1990. </year>

References-found: 51

