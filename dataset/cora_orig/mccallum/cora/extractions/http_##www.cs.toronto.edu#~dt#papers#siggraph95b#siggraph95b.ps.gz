URL: http://www.cs.toronto.edu/~dt/papers/siggraph95b/siggraph95b.ps.gz
Refering-URL: http://www.cs.toronto.edu/~dt/graphics.html
Root-URL: http://www.cs.toronto.edu
Title: Realistic Modeling for Facial Animation  
Author: Yuencheng Lee Demetri Terzopoulos and Keith Waters 
Keyword: CR Categories: I.3.5 [Computer Graphics]: Physically based modeling; I.3.7 [Computer Graphics]: Animation. Additional Keywords: Physics-based Facial Modeling, Facial Animation, RGB/Range Scanners, Feature-Based Facial Adaptation, Texture Mapping, Discrete Deformable Models.  
Date: 2  
Note: 1 and Digital Equipment Corporation  
Affiliation: University of Toronto  
Abstract: A major unsolved problem in computer graphics is the construction and animation of realistic human facial models. Traditionally, facial models have been built painstakingly by manual digitization and animated by ad hoc parametrically controlled facial mesh deformations or kinematic approximation of muscle actions. Fortunately, animators are now able to digitize facial geometries through the use of scanning range sensors and animate them through the dynamic simulation of facial tissues and muscles. However, these techniques require considerable user input to construct facial models of individuals suitable for animation. In this paper, we present a methodology for automating this challenging task. Starting with a structured facial mesh, we develop algorithms that automatically construct functional models of the heads of human subjects from laser-scanned range and reflectance data. These algorithms automatically insert contractile muscles at anatomically correct positions within a dynamic skin model and root them in an estimated skull structure with a hinged jaw. They also synthesize functional eyes, eyelids, teeth, and a neck and fit them to the final model. The constructed face may be animated via muscle actuations. In this way, we create the most authentic and functional facial models of individuals available to date and demonstrate their use in facial animation. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> T. Akimoto, Y. Suenaga, and R. Wallace. </author> <title> Automatic creation of 3D facial models. </title> <journal> IEEE Computer Graphics and Applications, </journal> <volume> 13(5) </volume> <pages> 16-22, </pages> <month> September </month> <year> 1993. </year>
Reference-contexts: An alternative technique is to manually digitize a plaster cast of the face using manual 3D dig-itization devices such as orthogonal magnetic fields sound captors [9], or one to two photographs <ref> [9, 7, 1] </ref>. More recently, automated laser range finders can digitize on the order of 10 5 3D points from a solid object such as a person's head and shoulders in just a few seconds [23].
Reference: [2] <author> James Doyle and James Philips. </author> <title> Manual on Experimental Stress Analysis. Society for Experimental Mechanics, </title> <booktitle> fifth edition, </booktitle> <year> 1989. </year>
Reference-contexts: The remaining muscle force computations are the same as in sec tion 3.4. Plate 4 shows all the linear muscles and the piecewise linear sphincter muscles around the mouth. 3.6 Volume Preservation Forces In order to faithfully exhibit the incompressibility <ref> [2] </ref> of real human skin in our model, a volume constraint force based on the change of volume (see Figure 9 (a)) and displacements of nodes is calculated and applied to nodes. In Figure 9 (b) the expected effect of volume preservation is demonstrated.
Reference: [3] <author> Irfan A. Essa. </author> <title> Visual Interpretation of Facial Expressions using Dynamic Modeling. </title> <type> PhD thesis, </type> <institution> MIT, </institution> <year> 1994. </year>
Reference-contexts: Various approaches have been proposed for deforming a facial mesh to produce facial expressions; for example, parameterized models [14, 15], control-point models [12, 7], kinematic muscle models [21, 9], a texture-map-assembly model [25], a spline model [11], feature-tracking models [24, 16], a finite element model [6], and dynamic muscle models <ref> [17, 20, 8, 3] </ref>. 1.1 Our Approach The goal of our work is to automate the challenging task of creating realistic facial models of individuals suitable for animation.
Reference: [4] <author> Frick and Hans. </author> <title> Human Anatomy, volume 1. </title> <publisher> Thieme Medical Publishers, Stuttgart, </publisher> <year> 1991. </year>
Reference-contexts: The following sections describe each of these components. We also describe our high-performance parallel, numerical simulation of the dynamic facial tissue model. 3.1 Layered Synthetic Tissue Model The skull is covered by deformable tissue which has five distinct layers <ref> [4] </ref>. Four layersepidermis, dermis, sub-cutaneous connective tissue, and fasciacomprise the skin, and the fifth consists of the muscles of facial expression. Following [20], and in accordance with the structure of real skin [5], we have designed a new, synthetic tissue model (Figure 6 (a)).
Reference: [5] <author> H. Gray. </author> <title> Anatomy of the Human Body. </title> <publisher> Lea & Febiber, </publisher> <address> Philadelphia, PA, 29th edition, </address> <year> 1985. </year>
Reference-contexts: Four layersepidermis, dermis, sub-cutaneous connective tissue, and fasciacomprise the skin, and the fifth consists of the muscles of facial expression. Following [20], and in accordance with the structure of real skin <ref> [5] </ref>, we have designed a new, synthetic tissue model (Figure 6 (a)). The tissue model is composed of triangular prism elements (see The epidermal surface is defined by nodes 1, 2, and 3, which are connected by epidermal springs.
Reference: [6] <author> Brian Guenter. </author> <title> A system for simulating human facial expression. </title> <booktitle> In State of the Art in Computer Animation, </booktitle> <pages> pages 191-202. </pages> <publisher> Springer-Verlag, </publisher> <year> 1992. </year>
Reference-contexts: Various approaches have been proposed for deforming a facial mesh to produce facial expressions; for example, parameterized models [14, 15], control-point models [12, 7], kinematic muscle models [21, 9], a texture-map-assembly model [25], a spline model [11], feature-tracking models [24, 16], a finite element model <ref> [6] </ref>, and dynamic muscle models [17, 20, 8, 3]. 1.1 Our Approach The goal of our work is to automate the challenging task of creating realistic facial models of individuals suitable for animation.
Reference: [7] <author> T. Kurihara and K. Arai. </author> <title> A transformation method for modeling and animation of the human face from photographs. </title> <booktitle> In State of the Art in Computer Animation, </booktitle> <pages> pages 45-57. </pages> <publisher> Springer-Verlag, </publisher> <year> 1991. </year>
Reference-contexts: An alternative technique is to manually digitize a plaster cast of the face using manual 3D dig-itization devices such as orthogonal magnetic fields sound captors [9], or one to two photographs <ref> [9, 7, 1] </ref>. More recently, automated laser range finders can digitize on the order of 10 5 3D points from a solid object such as a person's head and shoulders in just a few seconds [23]. <p> In procedure (3), an animator must decide which mesh nodes to articulate and how much they should be displaced in order to produce a specific facial expression. Various approaches have been proposed for deforming a facial mesh to produce facial expressions; for example, parameterized models [14, 15], control-point models <ref> [12, 7] </ref>, kinematic muscle models [21, 9], a texture-map-assembly model [25], a spline model [11], feature-tracking models [24, 16], a finite element model [6], and dynamic muscle models [17, 20, 8, 3]. 1.1 Our Approach The goal of our work is to automate the challenging task of creating realistic facial models
Reference: [8] <author> Y.C. Lee, D. Terzopoulos, and K. Waters. </author> <title> Constructing physics-based facial models of individuals. </title> <booktitle> In Proceedings of Graphics Interface '93, </booktitle> <pages> pages 1-8, </pages> <address> Toronto, </address> <month> May </month> <year> 1993. </year>
Reference-contexts: Various approaches have been proposed for deforming a facial mesh to produce facial expressions; for example, parameterized models [14, 15], control-point models [12, 7], kinematic muscle models [21, 9], a texture-map-assembly model [25], a spline model [11], feature-tracking models [24, 16], a finite element model [6], and dynamic muscle models <ref> [17, 20, 8, 3] </ref>. 1.1 Our Approach The goal of our work is to automate the challenging task of creating realistic facial models of individuals suitable for animation. <p> For details about the operator, see <ref> [8] </ref>. The field function highlights important features of interest. <p> The feature nodes include eye contours, nose contours, mouth contours, and chin contours. For any specific range image and its positive Laplacian field function (Figure 3), the generic mesh adaptation procedure performs the following steps to locate feature points in the range data (see <ref> [8] </ref> for details): Mesh Adaptation Procedures 1. Locate nose tip 2. Locate chin tip 3. Locate mouth contour 4. Locate chin contour 5. Locate ears 6. Locate eyes 7. Activate spring forces 8. Adapt hair mesh 9. Adapt body mesh 10.
Reference: [9] <author> N. Magneneat-Thalmann,H. Minh, M. Angelis, and D. Thalmann. </author> <title> Design, transformation and animation of human faces. </title> <journal> Visual Computer, </journal> <volume> 5 </volume> <pages> 32-39, </pages> <year> 1989. </year>
Reference-contexts: Care must be taken not to oversample the surface because there is a trade-off between the number of nodes and the computational cost of the model. Consequently, meshes developed to date capture the salient features of the face with as few nodes as possible (see <ref> [17, 14, 21, 9, 23] </ref> for several different mesh designs). In procedure (2), a general 3D digitization technique uses pho-togrammetry of several images of the face taken from different angles. A common technique is to place markers on the face that can be seen from two or more cameras. <p> A common technique is to place markers on the face that can be seen from two or more cameras. An alternative technique is to manually digitize a plaster cast of the face using manual 3D dig-itization devices such as orthogonal magnetic fields sound captors <ref> [9] </ref>, or one to two photographs [9, 7, 1]. More recently, automated laser range finders can digitize on the order of 10 5 3D points from a solid object such as a person's head and shoulders in just a few seconds [23]. <p> An alternative technique is to manually digitize a plaster cast of the face using manual 3D dig-itization devices such as orthogonal magnetic fields sound captors [9], or one to two photographs <ref> [9, 7, 1] </ref>. More recently, automated laser range finders can digitize on the order of 10 5 3D points from a solid object such as a person's head and shoulders in just a few seconds [23]. <p> Various approaches have been proposed for deforming a facial mesh to produce facial expressions; for example, parameterized models [14, 15], control-point models [12, 7], kinematic muscle models <ref> [21, 9] </ref>, a texture-map-assembly model [25], a spline model [11], feature-tracking models [24, 16], a finite element model [6], and dynamic muscle models [17, 20, 8, 3]. 1.1 Our Approach The goal of our work is to automate the challenging task of creating realistic facial models of individuals suitable for animation.
Reference: [10] <author> D. Metaxas and E. Milios. </author> <title> Reconstruction of a color image from nonuniformly distributed sparse and noisy data. Computer Vision, </title> <journal> Graphics, and Image Processing, </journal> <volume> 54(2) </volume> <pages> 103-111, </pages> <month> March </month> <year> 1992. </year>
Reference-contexts: A thin-plate relaxation algorithm [18] may be more effective in these regions because it would fill in the larger gaps with less flattening than a membrane <ref> [10] </ref>. Although the head structure in the cylindrical laser range data is distorted along the longitudinal direction, important features such as the slope changes of the nose, forehead, chin, and the contours of the mouth, eyes, and nose are still discernible.
Reference: [11] <author> M. Nahas, H. Hutric, M. Rioux, and J. Domey. </author> <title> Facial image synthesis using skin texture recording. </title> <journal> Visual Computer, </journal> <volume> 6(6) </volume> <pages> 337-343, </pages> <year> 1990. </year>
Reference-contexts: Various approaches have been proposed for deforming a facial mesh to produce facial expressions; for example, parameterized models [14, 15], control-point models [12, 7], kinematic muscle models [21, 9], a texture-map-assembly model [25], a spline model <ref> [11] </ref>, feature-tracking models [24, 16], a finite element model [6], and dynamic muscle models [17, 20, 8, 3]. 1.1 Our Approach The goal of our work is to automate the challenging task of creating realistic facial models of individuals suitable for animation.
Reference: [12] <author> M. Oka, K. Tsutsui, A. Ohba, Y. Kurauchi, and T. Tago. </author> <title> Real-time manipulation of texture-mapped surfaces. </title> <booktitle> In SIGGRAPH 21, </booktitle> <pages> pages 181-188. </pages> <institution> ACM Computer Graphics, </institution> <year> 1987. </year>
Reference-contexts: In procedure (3), an animator must decide which mesh nodes to articulate and how much they should be displaced in order to produce a specific facial expression. Various approaches have been proposed for deforming a facial mesh to produce facial expressions; for example, parameterized models [14, 15], control-point models <ref> [12, 7] </ref>, kinematic muscle models [21, 9], a texture-map-assembly model [25], a spline model [11], feature-tracking models [24, 16], a finite element model [6], and dynamic muscle models [17, 20, 8, 3]. 1.1 Our Approach The goal of our work is to automate the challenging task of creating realistic facial models
Reference: [13] <author> F. Parke. </author> <title> Computer generated animation of faces. </title> <booktitle> In ACM National Conference, </booktitle> <pages> pages 451-457. </pages> <publisher> ACM, </publisher> <year> 1972. </year>
Reference-contexts: 1 Introduction Two decades have passed since Parke's pioneering work in animating faces <ref> [13] </ref>. In the span of time, significant effort has been devoted to the development of computational models of the human face for applications in such diverse areas as entertainment, low bandwidth teleconferencing, surgical facial planning, and virtual reality.
Reference: [14] <author> F. Parke. </author> <title> Parameterized models for facial animation. </title> <journal> IEEE Computer Graphics and Applications, </journal> <volume> 2(9) </volume> <pages> 61-68, </pages> <month> November </month> <year> 1982. </year>
Reference-contexts: Care must be taken not to oversample the surface because there is a trade-off between the number of nodes and the computational cost of the model. Consequently, meshes developed to date capture the salient features of the face with as few nodes as possible (see <ref> [17, 14, 21, 9, 23] </ref> for several different mesh designs). In procedure (2), a general 3D digitization technique uses pho-togrammetry of several images of the face taken from different angles. A common technique is to place markers on the face that can be seen from two or more cameras. <p> In procedure (3), an animator must decide which mesh nodes to articulate and how much they should be displaced in order to produce a specific facial expression. Various approaches have been proposed for deforming a facial mesh to produce facial expressions; for example, parameterized models <ref> [14, 15] </ref>, control-point models [12, 7], kinematic muscle models [21, 9], a texture-map-assembly model [25], a spline model [11], feature-tracking models [24, 16], a finite element model [6], and dynamic muscle models [17, 20, 8, 3]. 1.1 Our Approach The goal of our work is to automate the challenging task of
Reference: [15] <author> F. Parke. </author> <title> Parameterized models for facial animation revisited. </title> <booktitle> In SIG-GRAPH Facial Animation Tutorial Notes, </booktitle> <pages> pages 43-56. </pages> <publisher> ACM SIG-GRAPH, </publisher> <year> 1989. </year>
Reference-contexts: In procedure (3), an animator must decide which mesh nodes to articulate and how much they should be displaced in order to produce a specific facial expression. Various approaches have been proposed for deforming a facial mesh to produce facial expressions; for example, parameterized models <ref> [14, 15] </ref>, control-point models [12, 7], kinematic muscle models [21, 9], a texture-map-assembly model [25], a spline model [11], feature-tracking models [24, 16], a finite element model [6], and dynamic muscle models [17, 20, 8, 3]. 1.1 Our Approach The goal of our work is to automate the challenging task of
Reference: [16] <author> Elizabeth C. Patterson, Peter C. Litwinowicz, and N. Greene. </author> <title> Facial animation by spatial mapping. </title> <booktitle> In State of the Art in Computer Animation, </booktitle> <pages> pages 31-44. </pages> <publisher> Springer-Verlag, </publisher> <year> 1991. </year>
Reference-contexts: Various approaches have been proposed for deforming a facial mesh to produce facial expressions; for example, parameterized models [14, 15], control-point models [12, 7], kinematic muscle models [21, 9], a texture-map-assembly model [25], a spline model [11], feature-tracking models <ref> [24, 16] </ref>, a finite element model [6], and dynamic muscle models [17, 20, 8, 3]. 1.1 Our Approach The goal of our work is to automate the challenging task of creating realistic facial models of individuals suitable for animation.
Reference: [17] <author> S. Platt and N. Badler. </author> <title> Animating facial expression. </title> <journal> Computer Graphics, </journal> <volume> 15(3) </volume> <pages> 245-252, </pages> <month> August </month> <year> 1981. </year>
Reference-contexts: Care must be taken not to oversample the surface because there is a trade-off between the number of nodes and the computational cost of the model. Consequently, meshes developed to date capture the salient features of the face with as few nodes as possible (see <ref> [17, 14, 21, 9, 23] </ref> for several different mesh designs). In procedure (2), a general 3D digitization technique uses pho-togrammetry of several images of the face taken from different angles. A common technique is to place markers on the face that can be seen from two or more cameras. <p> Various approaches have been proposed for deforming a facial mesh to produce facial expressions; for example, parameterized models [14, 15], control-point models [12, 7], kinematic muscle models [21, 9], a texture-map-assembly model [25], a spline model [11], feature-tracking models [24, 16], a finite element model [6], and dynamic muscle models <ref> [17, 20, 8, 3] </ref>. 1.1 Our Approach The goal of our work is to automate the challenging task of creating realistic facial models of individuals suitable for animation.
Reference: [18] <author> D. Terzopoulos. </author> <title> The computation of visible-surface representations. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> PAMI-10(4):417-438, </volume> <year> 1988. </year>
Reference-contexts: We must correct for missing range and texture information. We use a relaxation method to interpolate the range data. In particular, we apply a membrane interpolation method described in <ref> [18] </ref>. The relaxation interpolates values for the missing points so as to bring them into successively closer agreement with surrounding points by repeatedly indexing nearest neighbor values. Intuitively, it stretches an elastic membrane over the gaps in the surface. <p> The original texture image in (a) (b) in white and (b) texture image interpolated using relaxation method. The method is somewhat problematic in the hair area where range variations may be large and there is a relatively high percentage of missing surface points. A thin-plate relaxation algorithm <ref> [18] </ref> may be more effective in these regions because it would fill in the larger gaps with less flattening than a membrane [10].
Reference: [19] <author> D. Terzopoulos and M. Vasilescu. </author> <title> Sampling and reconstruction with adaptive meshes. </title> <booktitle> In Proceedings of Computer Vision and Pattern Recognition Conference, </booktitle> <pages> pages 70-75. </pages> <publisher> IEEE, </publisher> <month> June </month> <year> 1991. </year>
Reference-contexts: Motivated by the adaptive meshing techniques <ref> [19] </ref> that were employed in [23], we significantly (a) (b) function of (a). improved the technique by adapting a generic face mesh to the data. a cylindrical projection of the 3D face mesh from [21].
Reference: [20] <author> D. Terzopoulos and K. Waters. </author> <title> Physically-based facial modeling, analysis, and animation. </title> <journal> Visualization and Computer Animation, </journal> <volume> 1 </volume> <pages> 73-80, </pages> <year> 1990. </year>
Reference-contexts: Various approaches have been proposed for deforming a facial mesh to produce facial expressions; for example, parameterized models [14, 15], control-point models [12, 7], kinematic muscle models [21, 9], a texture-map-assembly model [25], a spline model [11], feature-tracking models [24, 16], a finite element model [6], and dynamic muscle models <ref> [17, 20, 8, 3] </ref>. 1.1 Our Approach The goal of our work is to automate the challenging task of creating realistic facial models of individuals suitable for animation. <p> In step 2, the algorithm elaborates the geometric model constructed in step 1 into a functional, physics-based model of the subject's face which is capable of facial expression, as shown in the lower portion of Plate 1. We follow the physics-based facial modeling approach proposed by Terzopoulos and Waters <ref> [20] </ref>. Its basic features are that it ani-mates facial expressions by contracting synthetic muscles embedded in an anatomically motivated model of skin composed of three spring-mass layers. The physical simulation propagates the muscle forces through the physics-based synthetic skin thereby deforming the skin to produce facial expressions. <p> We propose a more accurate biomechanical model for facial animation compared to previous models. We develop a new biomechanical facial skin model which is simpler and better than the one proposed in <ref> [20] </ref>. Furthermore, we argue that the skull is an important biomechanical structure with regard to facial expression [22]. <p> Four layersepidermis, dermis, sub-cutaneous connective tissue, and fasciacomprise the skin, and the fifth consists of the muscles of facial expression. Following <ref> [20] </ref>, and in accordance with the structure of real skin [5], we have designed a new, synthetic tissue model (Figure 6 (a)). The tissue model is composed of triangular prism elements (see The epidermal surface is defined by nodes 1, 2, and 3, which are connected by epidermal springs. <p> a face which is automatically assembled by following the above approach. * The force spring j exerts on node i is g j = c j (l j l r each layer has its own stress-strain relationship c j and the dermal-fatty layer uses biphasic springs (non-constant c j ) <ref> [20] </ref> j and l j = jjx j x i jj are the rest and current lengths for spring j - s j = (x j x i )=l j is the spring direction vector for spring j 3.4 Linear Muscle Forces The muscles of facial expression, or the muscular plate, <p> Finally, Plate 8 shows several frames from a two-minute animation Bureaucrat Too (a second-generation version of the 1990 Bureaucrat which was animated using the generic facial model in <ref> [20] </ref>).
Reference: [21] <author> K. Waters. </author> <title> A muscle model for animating three-dimensional facial expression. </title> <journal> Computer Graphics, </journal> <volume> 22(4) </volume> <pages> 17-24, </pages> <year> 1987. </year>
Reference-contexts: Care must be taken not to oversample the surface because there is a trade-off between the number of nodes and the computational cost of the model. Consequently, meshes developed to date capture the salient features of the face with as few nodes as possible (see <ref> [17, 14, 21, 9, 23] </ref> for several different mesh designs). In procedure (2), a general 3D digitization technique uses pho-togrammetry of several images of the face taken from different angles. A common technique is to place markers on the face that can be seen from two or more cameras. <p> Various approaches have been proposed for deforming a facial mesh to produce facial expressions; for example, parameterized models [14, 15], control-point models [12, 7], kinematic muscle models <ref> [21, 9] </ref>, a texture-map-assembly model [25], a spline model [11], feature-tracking models [24, 16], a finite element model [6], and dynamic muscle models [17, 20, 8, 3]. 1.1 Our Approach The goal of our work is to automate the challenging task of creating realistic facial models of individuals suitable for animation. <p> The algorithm is applicable to various individuals (Plate 2 shows the raw scans of several individuals). It proceeds in two steps: In step 1, the algorithm adapts a well-structured face mesh from <ref> [21] </ref> to the range and reflectance data acquired by scanning the subject, thereby capturing the shape of the subject's face. This approach has significant advantages because it avoids repeated manual modification of control parameters to compensate for geometric variations in the facial features from person to person. <p> Motivated by the adaptive meshing techniques [19] that were employed in [23], we significantly (a) (b) function of (a). improved the technique by adapting a generic face mesh to the data. a cylindrical projection of the 3D face mesh from <ref> [21] </ref>. One of the advantages of the generic mesh is that it has well-defined features which form the basis for accurate feature based adaptation to the scanned data and automatic scaling and positioning of facial muscles as the mesh is deformed to fit the images.
Reference: [22] <author> K. Waters. </author> <title> A physcial model of facial tissue and muscle articulation derived from computer tomography data. </title> <booktitle> In Visualization in Biomedical Computing, </booktitle> <pages> pages 574-583. </pages> <booktitle> SPIE, </booktitle> <volume> Vol. 1808, </volume> <year> 1992. </year>
Reference-contexts: We propose a more accurate biomechanical model for facial animation compared to previous models. We develop a new biomechanical facial skin model which is simpler and better than the one proposed in [20]. Furthermore, we argue that the skull is an important biomechanical structure with regard to facial expression <ref> [22] </ref>.
Reference: [23] <author> K. Waters and D. Terzopoulos. </author> <title> Modeling and animating faces using scanned data. </title> <journal> Visualization and Computer Animation, </journal> <volume> 2 </volume> <pages> 123-128, </pages> <year> 1991. </year>
Reference-contexts: Care must be taken not to oversample the surface because there is a trade-off between the number of nodes and the computational cost of the model. Consequently, meshes developed to date capture the salient features of the face with as few nodes as possible (see <ref> [17, 14, 21, 9, 23] </ref> for several different mesh designs). In procedure (2), a general 3D digitization technique uses pho-togrammetry of several images of the face taken from different angles. A common technique is to place markers on the face that can be seen from two or more cameras. <p> More recently, automated laser range finders can digitize on the order of 10 5 3D points from a solid object such as a person's head and shoulders in just a few seconds <ref> [23] </ref>. In procedure (3), an animator must decide which mesh nodes to articulate and how much they should be displaced in order to produce a specific facial expression. <p> Motivated by the adaptive meshing techniques [19] that were employed in <ref> [23] </ref>, we significantly (a) (b) function of (a). improved the technique by adapting a generic face mesh to the data. a cylindrical projection of the 3D face mesh from [21].
Reference: [24] <author> L. Williams. </author> <title> Performance-driven facial animation. </title> <booktitle> In SIGGRAPH 24, </booktitle> <pages> pages 235-242. </pages> <institution> ACM Computer Graphics, </institution> <year> 1990. </year>
Reference-contexts: Various approaches have been proposed for deforming a facial mesh to produce facial expressions; for example, parameterized models [14, 15], control-point models [12, 7], kinematic muscle models [21, 9], a texture-map-assembly model [25], a spline model [11], feature-tracking models <ref> [24, 16] </ref>, a finite element model [6], and dynamic muscle models [17, 20, 8, 3]. 1.1 Our Approach The goal of our work is to automate the challenging task of creating realistic facial models of individuals suitable for animation.

References-found: 24

