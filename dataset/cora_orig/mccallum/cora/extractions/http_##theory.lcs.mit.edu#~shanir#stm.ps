URL: http://theory.lcs.mit.edu/~shanir/stm.ps
Refering-URL: http://theory.lcs.mit.edu/~shanir/
Root-URL: 
Title: Software Transactional Memory  
Author: Nir Shavit Dan Touitou 
Affiliation: Tel-Aviv University  Tel-Aviv University  
Abstract: As we learn from the literature, flexibility in choosing synchronization operations greatly simplifies the task of designing highly concurrent programs. Unfortunately, existing hardware is inflexible and is at best on the level of a Load Linked/Store Conditional operation on a single word. Building on the hardware based transactional synchronization methodology of Herlihy and Moss, we offer software transactional memory (STM), a novel software method for supporting flexible transactional programming of synchronization operations. STM is non-blocking, and can be implemented on existing machines using only a Load Linked/Store Conditional operation. We use STM to provide a general highly concurrent method for translating sequential object implementations to non-blocking ones based on implementing a k-word compare&swap STM-transaction. Empirical evidence collected on simulated multiprocessor architectures shows that the our method always outperforms all the non-blocking translation methods in the style of Barnes, and outperforms Her-lihy's translation method for sufficiently large numbers of processors. The key to the efficiency of our software-transactional approach is that unlike Barnes style methods, it is not based on a costly "recursive helping" policy. fl Contact Author: E-mail: shanir@theory.lcs.mit.edu y A preliminary version of this paper appeared in the 14th ACM Symposium on the Principles of Distributed Computing, Ottowa, Ontario, Canada, 1995 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Agarwal et al. </author> <title> The MIT Alewife Machine: A Large-Scale Distributed-Memory Multiprocessor. </title> <booktitle> In Proceedings of Workshop on Scalable Shared Memory Multiprocessors. </booktitle> <publisher> Kluwer Academic Publishers, </publisher> <year> 1991. </year> <note> An extended version of this paper has been submitted for publication, and appears as MIT/LCS Memo TM-454, </note> <year> 1991. </year>
Reference-contexts: We present (see Section 5) the first experimental comparison of the performance under stable conditions of the translation techniques cited above. We use the well accepted Proteus Parallel Hardware Simulator [8, 9]. We found that on a simulated Alewife <ref> [1] </ref> cache-coherent distributed shared-memory machine, as the potential for concurrency in accessing the object grows, the STM non-blocking translation method outperforms both Herlihy's method and the cooperative method. <p> Each processor has a cache with 2048 lines of 8 bytes and the cache coherence is maintained using Goodman's [18] "snoopy" cache-coherence protocol. The simulated network architecture is similar to that of the Alewife cache-coherent distributed-memory machine currently under development at MIT <ref> [1] </ref>. Each node of the machines Torus shaped communication grid consists of a processor, cache memory, a router, and a portion of the globally-addressable memory. The cost of switching or wiring in the Alewife architecture was 1 cycle/packet.
Reference: [2] <author> R. J. Anderson. </author> <title> Primitives for Asynchronous List Compression. </title> <booktitle> Proceeding of the 4th ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 199-208, </pages> <year> 1992. </year> <note> 29 - -Two locations - - -Four locations - - -Six locations - 30 </note>
Reference-contexts: As we learn from the literature, flexibility in choosing the synchronization operations greatly simplifies the task of designing non-blocking concurrent programs. Examples are the non-blocking data-structures of Massalin and Pu [24] which use a Compare&Swap on two words, Anderson's <ref> [2] </ref> parallel path compression on lists which uses a special Splice operation, the counting networks of [5] which use combination of Fetch&Complement and Fetch&Inc, Israeli and Rappoport's Heap [20] which can be implemented using a three-word Compare&Swap, and many more.
Reference: [3] <author> T.E. Anderson. </author> <title> The performance of spin lock alternatives for shared memory multiprocessors. </title> <journal> In IEEE Transaction on Parallel and Distributed Systems, </journal> <volume> 1(1) </volume> <pages> 6-16, </pages> <month> January </month> <year> 1990. </year>
Reference-contexts: The non-blocking methods include Herlihy's Method and Israeli and Rappoport's k-word Compare&Swap based implementation of the cooperative method. All the non-blocking methods use exponential backoff <ref> [3] </ref> to reduce contention. 5.2 Results The data to be presented leads us to conclude that there are three factors differentiating among the performance of the four methods: 1.
Reference: [4] <author> J. Alemany, </author> <title> E.W. Felten Performance Issues in Non-Blocking Synchronization on Shared-Memory Multiprocessors. </title> <booktitle> In Proceedings of 11th ACM Symposium on Principles of Distributed Computation, </booktitle> <month> Pages 125-134 August </month> <year> 1992. </year>
Reference-contexts: Unfortunately, Herlihy's method does not provide a suitable solution for large data structures and like the standard approach of locking the whole object, does not support concurrent updating. Alemany and Felten <ref> [4] </ref> and LaMarca [22] suggested to improve the efficiency of this general method at the price of loosing portability, by using operating system support making a set of strong assumptions on system behavior.
Reference: [5] <author> J. Aspnes, M.P. Herlihy, and N. Shavit. </author> <title> Counting Networks. </title> <journal> Journal of the ACM, </journal> <volume> Vol. 41, No. </volume> <month> 5 (September </month> <year> 1994), </year> <pages> pp. 1020-1048. </pages>
Reference-contexts: Examples are the non-blocking data-structures of Massalin and Pu [24] which use a Compare&Swap on two words, Anderson's [2] parallel path compression on lists which uses a special Splice operation, the counting networks of <ref> [5] </ref> which use combination of Fetch&Complement and Fetch&Inc, Israeli and Rappoport's Heap [20] which can be implemented using a three-word Compare&Swap, and many more.
Reference: [6] <author> G. </author> <booktitle> Barnes A Method for Implementing Lock-Free Shared Data Structures In Proceedings of the 5th ACM Symposium on Parallel Algorithms and Architectures 1993. </booktitle>
Reference-contexts: overhead of coordination among several transactions attempting to help release a location by employing a "reactive" helping policy which we call non-redundant-helping. 1.2 Sequential-to-Non-Blocking Translation One can use STM to provide a general highly concurrent method for translating sequential object implementations into non-blocking ones based on the caching approach of <ref> [6, 28] </ref>. The approach is straightforward: use transactional memory to to implement any collection of changes to a shared object, performing them as an atomic k-word Compare&Swap transaction (see Figure 2) on the desired locations. The non-blocking STM implementation guarantees that some transaction will always succeed. <p> Alemany and Felten [4] and LaMarca [22] suggested to improve the efficiency of this general method at the price of loosing portability, by using operating system support making a set of strong assumptions on system behavior. To overcome the limitations of Herlihy's method , Barnes, in <ref> [6] </ref>, introduced his caching method, that avoids copying the whole object and allows concurrent disjoint updating. A similar approach was independently proposed by Turek, Shasha, and Prakash [28]. <p> Barnes suggested to implement the k-word Read-Modify-Write by locking in ascending order of their key, the locations involved in the update executing the operation and, after executing the operation needed, releasing the locks. The key to achieving the non-blocking resilient behavior in the caching approach of <ref> [6, 28] </ref> is the cooperative method: whenever a process needs a location already locked by another process it helps the locking process to complete its own operation, and this is done recursively along the dependency chain. <p> The current version of Proteus does not support Load Linked/Store Conditional instructions. Instead we used a slightly modified version that supports a 64-bit Compare&Swap operation where 32 bits serve as a time stamp. Naturally this operation is less efficient than the theoretical Load Linked/Store Conditional proposed in <ref> [6, 16, 20] </ref> (which we could have built directly into Proteus), since a failing Compare&Swap will cost a memory access while a failing Store Conditional wont.
Reference: [7] <author> B.N Bershad. </author> <title> Practical consideration for lock-free concurrent objects. </title> <type> Technical Report, </type> <institution> CMU-CS-91-183, Carnegie Mellon University. </institution> <month> September </month> <year> 1991. </year>
Reference-contexts: The key to highly concurrent programming is to decrease the number and size of critical sections a multiprocessor program uses (possibly eliminating critical sections altogether) by constructing classes of implementations that are non-blocking <ref> [7, 16, 15] </ref>. As we learn from the literature, flexibility in choosing the synchronization operations greatly simplifies the task of designing non-blocking concurrent programs. <p> Unfortunately, most of the current or soon to be developed architectures support operations on the level of a Load Linked/Store Conditional operation for a single word, making most of these highly concurrent algorithms impractical in the near future. Bershad <ref> [7] </ref> suggested to overcome the problem of providing efficient programming primitives on existing machines by employing operating system support. Herlihy and Moss [17] have proposed an ingenious hardware solution: transactional memory. <p> On existing machines the 64 bits Compare&Swap may be implemented by using the a 64 bits Load Linked/Store Conditional as on the Alpha or using Bershad's lock-free methodology 2 <ref> [7] </ref>. We used four synthetic benchmarks for evaluating various methods for implementing shared data structures. The methods vary in the size of the data structure and the amount of parallelism. Counting Each of n processes increments a shared counter 10000=n times.
Reference: [8] <author> E.A. Brewer C.N. Dellarocas, A. Colbrook, and W. E. Weihl. Proteus: </author> <title> A High-Performance Parallel-Architecture Simulator. </title> <address> MIT/LCS/TR-516. </address> <month> September </month> <year> 1989. </year>
Reference-contexts: We present (see Section 5) the first experimental comparison of the performance under stable conditions of the translation techniques cited above. We use the well accepted Proteus Parallel Hardware Simulator <ref> [8, 9] </ref>. We found that on a simulated Alewife [1] cache-coherent distributed shared-memory machine, as the potential for concurrency in accessing the object grows, the STM non-blocking translation method outperforms both Herlihy's method and the cooperative method. <p> the interval between helps as a function of the "redundant helps" it discovered. 5 An Empirical Evaluation of Translation Methods 5.1 Methodology We compared the performance of STM and other software methods on 64 processor bus and network architectures using the Proteus simulator developed by Brewer, Dellarocas, Colbrook and Weihl <ref> [8] </ref>. Proteus simulates parallel code by multiplexing several parallel threads on a single CPU. Each thread runs on its own virtual CPU with accompanying local memory, cache and communications hardware, keeping track of how much time is spent using each component.
Reference: [9] <author> E.A. Brewer C.N. Dellarocas. Proteus. </author> <title> User Documentation. </title>
Reference-contexts: We present (see Section 5) the first experimental comparison of the performance under stable conditions of the translation techniques cited above. We use the well accepted Proteus Parallel Hardware Simulator <ref> [8, 9] </ref>. We found that on a simulated Alewife [1] cache-coherent distributed shared-memory machine, as the potential for concurrency in accessing the object grows, the STM non-blocking translation method outperforms both Herlihy's method and the cooperative method.
Reference: [10] <author> K. Chandy and J. Misra. </author> <title> The Drinking Philosophers Problem. </title> <booktitle> In ACM Transaction on Programming Languages and Systems, </booktitle> <volume> 6(4) </volume> <pages> 632-646, </pages> <month> October </month> <year> 1984. </year>
Reference-contexts: The methods vary in the size of the data structure and the amount of parallelism. Counting Each of n processes increments a shared counter 10000=n times. In this benchmark updates are short, change the whole object state, and have no built in parallelism. Resource Allocation A resource allocation scenario <ref> [10] </ref>: a few processes share a set of resources and from time to time a process tries to atomically acquire a subset of size s of those resources. This is the typical behavior of a well designed distributed data structure.
Reference: [11] <author> T.H. Cormen, C.E. Leiserson and R.L. Rivest. </author> <title> Introduction to algorithms. </title> <publisher> MIT Press. </publisher> <pages> 31 </pages>
Reference-contexts: We used a variant of a sequential heap implementation <ref> [11] </ref>. In this benchmark each of the n processes consequently enqueues a random value in a heap and dequeues the greatest value from it 5000=n times. The heap is initially empty and its maximal size is n.
Reference: [12] <author> David Chaiken. </author> <title> Cache Coherence Protocols for Large-Scale Multiprocessors. </title> <type> S.M. thesis, </type> <institution> Massachusetts Institute of Technology, Laboratory for Computer Science Technical Report MIT/LCS/TR-489, </institution> <month> September </month> <year> 1990. </year>
Reference-contexts: The cost of switching or wiring in the Alewife architecture was 1 cycle/packet. As for the bus architecture, each processor has a cache with 2048 lines of 8 bytes. The cache coherence is provided using a using a version of Chaiken's <ref> [12] </ref> directory-based cache-coherence protocol. The current version of Proteus does not support Load Linked/Store Conditional instructions. Instead we used a slightly modified version that supports a 64-bit Compare&Swap operation where 32 bits serve as a time stamp.
Reference: [13] <author> DEC. </author> <title> Alpha system reference manual. </title>
Reference-contexts: However, we believe the 64-bit Compare&Swap is closer to the real world then the theoretical Load Linked/Store Conditional since existing implementations of Load Linked/Store Conditional as on Alpha <ref> [13] </ref> or PowerPC [19] do not allow access to the shared memory between the Load Linked and the Store Conditional operations.
Reference: [14] <author> M. Herlihy and J.M. Wing. </author> <title> Linearizability: A correctness condition for concurrent objects. </title> <booktitle> In ACM Transaction on Programming Languages and Systems, </booktitle> <volume> 12(3), </volume> <pages> pages 463-492, </pages> <month> July </month> <year> 1990. </year>
Reference-contexts: A transaction is a thread of control that applies a finite sequence of primitive operations to memory. The basic correctness requirement for a STM implementation is linearizability <ref> [14] </ref>: every concurrent history is "equiva lent" to some legal sequential history which which is consistent with the real-time order induced by the concurrent history. 5 A static transaction is a special form of transaction in which the data set is known in advance, and can thus be thought of as <p> However, if used only for static transactions, their implementation can be made swap-tolerant (but not non-blocking, since a single process which is repeatedly swapped during the execution of a transaction will never terminates successfully). 2.1 The System Model Our computation model follows Herlihy and Wing <ref> [14] </ref> and can also be cast in terms of the I/O automata model of Lynch and Tuttle [23]. A concurrent system consists of a collection of processes. Processes communicate through shared data structures called objects. <p> A concurrent system consists of a collection of processes. Processes communicate through shared data structures called objects. Each object has a set of primitive operations that provide the only means to manipulate that object. Each process is a sequential thread of control <ref> [14] </ref> which applies a sequence of operations to objects by issuing an invocation and receiving the associated response. A history is a sequence of invocations and responses of some system execution. <p> A sequential history is a history in which each invocation is followed immediately by its corresponding response. The sequential specification of an object is the set of legal sequential histories associated with it. The basic correctness requirement for a concurrent implementation is linearizability <ref> [14] </ref>: every concurrent history is "equivalent" to some legal sequential history which which is consistent with the partial real-time order induced by the concurrent history. In a linearizable implementation, operations appear to take effect atomically at some point between their invocation and response.
Reference: [15] <author> M. Herlihy. </author> <title> Wait-Free Synchronization. </title> <booktitle> In ACM Transaction on Programming Languages and Systems, </booktitle> <volume> 13(1), </volume> <pages> pages 124-149, </pages> <month> January </month> <year> 1991. </year>
Reference-contexts: The key to highly concurrent programming is to decrease the number and size of critical sections a multiprocessor program uses (possibly eliminating critical sections altogether) by constructing classes of implementations that are non-blocking <ref> [7, 16, 15] </ref>. As we learn from the literature, flexibility in choosing the synchronization operations greatly simplifies the task of designing non-blocking concurrent programs. <p> Otherwise returns a failure status. The a more detailed formal specification of these operation can be found in <ref> [15, 16] </ref>. 2.2 A Sequential Specification of STM The following is the sequential specification of STM. Let L N be a set of locations. A memory state is a function s : L 7! V which returns for each location of L a value from some set V .
Reference: [16] <author> M. Herlihy. </author> <title> A methodology for implementing highly concurrent data objects. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 15(9): </volume> <pages> 745-770, </pages> <month> November </month> <year> 1993. </year>
Reference-contexts: The key to highly concurrent programming is to decrease the number and size of critical sections a multiprocessor program uses (possibly eliminating critical sections altogether) by constructing classes of implementations that are non-blocking <ref> [7, 16, 15] </ref>. As we learn from the literature, flexibility in choosing the synchronization operations greatly simplifies the task of designing non-blocking concurrent programs. <p> The approach is straightforward: use transactional memory to to implement any collection of changes to a shared object, performing them as an atomic k-word Compare&Swap transaction (see Figure 2) on the desired locations. The non-blocking STM implementation guarantees that some transaction will always succeed. Herlihy, in <ref> [16] </ref> (referred to in the sequel as Herlihy's method), was the first to offer a general transformation of sequential objects into non-blocking concurrent ones. <p> Otherwise returns a failure status. The a more detailed formal specification of these operation can be found in <ref> [15, 16] </ref>. 2.2 A Sequential Specification of STM The following is the sequential specification of STM. Let L N be a set of locations. A memory state is a function s : L 7! V which returns for each location of L a value from some set V . <p> The current version of Proteus does not support Load Linked/Store Conditional instructions. Instead we used a slightly modified version that supports a 64-bit Compare&Swap operation where 32 bits serve as a time stamp. Naturally this operation is less efficient than the theoretical Load Linked/Store Conditional proposed in <ref> [6, 16, 20] </ref> (which we could have built directly into Proteus), since a failing Compare&Swap will cost a memory access while a failing Store Conditional wont.
Reference: [17] <author> M. Herlihy and J.E B. Moss. </author> <title> Transactional Memory: Architectural Support for Lock-Free Data Structures. </title> <booktitle> In 20th Annual Symposium on Computer Architecture, </booktitle> <pages> pages 289-300, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: Bershad [7] suggested to overcome the problem of providing efficient programming primitives on existing machines by employing operating system support. Herlihy and Moss <ref> [17] </ref> have proposed an ingenious hardware solution: transactional memory. By adding a specialized associative cache and making several minor changes to the cache consistency protocols, they are able to support a flexible transactional language for writing synchronization operations. <p> The following section introduces STM. In Section 3 we describe our implementation and and provide a sketch of the correctness proof. Finally, in Section 5 we present our empirical performance evaluation. 2 Transactional Memory We begin by presenting software transactional memory, a variant of the transactional memory of <ref> [17] </ref>. A transaction is a finite sequence of local and shared memory machine instructions: Read-transactional reads the value of a shared location into a local register. Write-transactional stores the contents of a local register into a shared location. <p> An STM implementation is swap tolerant, if it is non-blocking under the assumption that a process cannot be swapped out infinitely many times. The hardware implemented transactions of <ref> [17] </ref> could in theory repeatedly fail forever, if processes try to write two locations in different order (as when updating a doubly linked list).
Reference: [18] <author> J. R. Goodman. </author> <title> Using cache-memory to reduce processor-memory traffic. </title> <booktitle> In Proceeding of the 10th International Symposium on Computer Architectures, </booktitle> <volume> 13(1), </volume> <pages> pages 124-131, </pages> <month> June </month> <year> 1983. </year>
Reference-contexts: Each processor has a cache with 2048 lines of 8 bytes and the cache coherence is maintained using Goodman's <ref> [18] </ref> "snoopy" cache-coherence protocol. The simulated network architecture is similar to that of the Alewife cache-coherent distributed-memory machine currently under development at MIT [1]. Each node of the machines Torus shaped communication grid consists of a processor, cache memory, a router, and a portion of the globally-addressable memory.
Reference: [19] <author> IBM. </author> <title> Power PC. Reference manual. </title>
Reference-contexts: However, we believe the 64-bit Compare&Swap is closer to the real world then the theoretical Load Linked/Store Conditional since existing implementations of Load Linked/Store Conditional as on Alpha [13] or PowerPC <ref> [19] </ref> do not allow access to the shared memory between the Load Linked and the Store Conditional operations. On existing machines the 64 bits Compare&Swap may be implemented by using the a 64 bits Load Linked/Store Conditional as on the Alpha or using Bershad's lock-free methodology 2 [7].
Reference: [20] <author> A. Israeli and L. Rappoport. </author> <title> Efficient Wait Free Implementation of a Concurrent Priority Queue. </title> <booktitle> In WDAG 1993. Lecture Notes in Computer Science 725, </booktitle> <publisher> Springer Verlag, </publisher> <pages> pages 1-17. </pages>
Reference-contexts: Examples are the non-blocking data-structures of Massalin and Pu [24] which use a Compare&Swap on two words, Anderson's [2] parallel path compression on lists which uses a special Splice operation, the counting networks of [5] which use combination of Fetch&Complement and Fetch&Inc, Israeli and Rappoport's Heap <ref> [20] </ref> which can be implemented using a three-word Compare&Swap, and many more. Unfortunately, most of the current or soon to be developed architectures support operations on the level of a Load Linked/Store Conditional operation for a single word, making most of these highly concurrent algorithms impractical in the near future. <p> Helping is performed only if the helped transaction's record is in a stable state. 1 The use of this unbounded field can be avoided if an additional Validate operation is available <ref> [20, 21] </ref>. 9 Transaction (rec,version,IsInitiator) AcquireOwnerships (rec,version) (status,failadd) = LL (rec":status) if status = Null then if (version 6= rec":version) then return SC (rec":status,(Success,0)) (status,failadd) = LL (rec":status) if status = Success then AgreeOldValues (rec,version) NewValues = CalcNewValues (rec":OldValues) UpdateMemory (rec,version,NewValues) ReleaseOwnerships (rec,version) else ReleaseOwnerships (rec,version) if IsInitiator then failtran= Ownerships <p> The current version of Proteus does not support Load Linked/Store Conditional instructions. Instead we used a slightly modified version that supports a 64-bit Compare&Swap operation where 32 bits serve as a time stamp. Naturally this operation is less efficient than the theoretical Load Linked/Store Conditional proposed in <ref> [6, 16, 20] </ref> (which we could have built directly into Proteus), since a failing Compare&Swap will cost a memory access while a failing Store Conditional wont. <p> We also compare the cooperative k-word Compare&Swap with STM for a specific implementation which explicitly needs such a software supported operation. We chose Israeli and Rappoport's algorithm for a concurrent priority queue <ref> [20] </ref>, since it is based on recursive helping. Therefore, whenever a process during the execution of a k-word Compare&Swap helps another remote disjoint process, it should give an advantage to Israeli and Rappoport method. <p> As in the counter and the sequential priority queue benchmarks, the reason for this is 3 In fact, using 3-word Compare&Swap simplifies the implementation since it avoids freezing <ref> [20] </ref> nodes 26 the high number of failing k-word Compare&Swap operations in Israeli and Rappoport method: up to 2.5 times the number of successful k-word Compare&Swap . Every theoretical method can be improved in many ways when implemented in practice.
Reference: [21] <author> A. Israeli and L. Rappoport. </author> <title> Disjoint-Access-Parallel Implementations of Strong Shared Memory Proc. </title> <booktitle> of the 13th ACM Symposium on Principles of Distributed Computing pages 151-160. </booktitle>
Reference-contexts: Though Barnes and Turek, Shasha, and Prakash are vague on specific implementation details, a recent paper by Israeli and Rappoport <ref> [21] </ref> gives, using the cooperative method, a clean and streamlined implementation of a non-blocking k-word Compare&Swap using Load Linked/Store Conditional . <p> Helping is performed only if the helped transaction's record is in a stable state. 1 The use of this unbounded field can be avoided if an additional Validate operation is available <ref> [20, 21] </ref>. 9 Transaction (rec,version,IsInitiator) AcquireOwnerships (rec,version) (status,failadd) = LL (rec":status) if status = Null then if (version 6= rec":version) then return SC (rec":status,(Success,0)) (status,failadd) = LL (rec":status) if status = Success then AgreeOldValues (rec,version) NewValues = CalcNewValues (rec":OldValues) UpdateMemory (rec,version,NewValues) ReleaseOwnerships (rec,version) else ReleaseOwnerships (rec,version) if IsInitiator then failtran= Ownerships
Reference: [22] <author> A. LaMarca. </author> <title> A Performance Evaluation of Lock-Free Synchronization Protocols. </title> <booktitle> Proc. of the 13th ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pages 130-140. </pages>
Reference-contexts: Unfortunately, Herlihy's method does not provide a suitable solution for large data structures and like the standard approach of locking the whole object, does not support concurrent updating. Alemany and Felten [4] and LaMarca <ref> [22] </ref> suggested to improve the efficiency of this general method at the price of loosing portability, by using operating system support making a set of strong assumptions on system behavior.
Reference: [23] <author> N. Lynch and M. Tuttle. </author> <title> Hierachical Correctness Proofs for Distributed Algorithm. </title> <booktitle> In Proceedings of 6th ACM Symposium on Principles of Distributed Computation, </booktitle> <month> Pages 137-151 August </month> <year> 1987. </year> <note> Full version available as MIT Technical Report MIT/LCS/TR-387. </note>
Reference-contexts: swap-tolerant (but not non-blocking, since a single process which is repeatedly swapped during the execution of a transaction will never terminates successfully). 2.1 The System Model Our computation model follows Herlihy and Wing [14] and can also be cast in terms of the I/O automata model of Lynch and Tuttle <ref> [23] </ref>. A concurrent system consists of a collection of processes. Processes communicate through shared data structures called objects. Each object has a set of primitive operations that provide the only means to manipulate that object.
Reference: [24] <author> H. Massalin and C. Pu. </author> <title> A lock-free multiprocessor OS kernel. </title> <type> Technical Report CUCS-005-91. </type> <institution> Columbia University. </institution> <month> Mars </month> <year> 1991. </year>
Reference-contexts: As we learn from the literature, flexibility in choosing the synchronization operations greatly simplifies the task of designing non-blocking concurrent programs. Examples are the non-blocking data-structures of Massalin and Pu <ref> [24] </ref> which use a Compare&Swap on two words, Anderson's [2] parallel path compression on lists which uses a special Splice operation, the counting networks of [5] which use combination of Fetch&Complement and Fetch&Inc, Israeli and Rappoport's Heap [20] which can be implemented using a three-word Compare&Swap, and many more.
Reference: [25] <author> J.M. </author> <title> Mellor-Crummey and M.L. Scott Synchronization without Contention. </title> <booktitle> In Proceedings of the 4th International Conference on Architecture Support for Programming Languages and Operating Systems, </booktitle> <month> April </month> <year> 1991. </year> <month> 32 </month>
Reference-contexts: Unfortunately, our experiments show that in general STM and other non-blocking techniques are inferior to standard non-resilient lock-based methods such as queue-locks <ref> [25] </ref>. Results for a shared bus architecture were similar in flavor. In summary, STM offers a novel software package of flexible coordination-operation for the design of highly concurrent shared objects, which ensures resiliency in faulty runs and improved performance in non-faulty ones. The following section introduces STM. <p> We used the above benchmarks to compare STM to the two nonblocking software translation methods described earlier and a blocking MCS queue-lock <ref> [25] </ref> based solution (the data structure is accessed in a mutually exclusive manner). The non-blocking methods include Herlihy's Method and Israeli and Rappoport's k-word Compare&Swap based implementation of the cooperative method.
Reference: [26] <author> L. Rudolph, M. Slivkin, and E. Upfal. </author> <title> A Simple Load Balancing Scheme for Task Allocation in Parallel Machines. </title> <booktitle> In Proceedings of the 3rd ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 237-245, </pages> <month> July </month> <year> 1991. </year>
Reference-contexts: For lack of space we show only the benchmark which has n processes atomically increment 5000=n times with s = 2; 4; 6 locations chosen uniformly at random from a vector of length 60. The benchmark captures the behavior of highly concurrent queue and counter implementations as in <ref> [26, 27] </ref>. 2 The non-blocking property will be achieved only if the number of spurious failures is finite. 21 Priority Queue A shared priority queue on a heap of size n. We used a variant of a sequential heap implementation [11].
Reference: [27] <author> N. Shavit and A. Zemach. </author> <title> Diffracting Trees. </title> <booktitle> In Proceedings of the Annual Symposium on Parallel Algorithms and Architectures (SPAA), </booktitle> <month> June </month> <year> 1994. </year>
Reference-contexts: For lack of space we show only the benchmark which has n processes atomically increment 5000=n times with s = 2; 4; 6 locations chosen uniformly at random from a vector of length 60. The benchmark captures the behavior of highly concurrent queue and counter implementations as in <ref> [26, 27] </ref>. 2 The non-blocking property will be achieved only if the number of spurious failures is finite. 21 Priority Queue A shared priority queue on a heap of size n. We used a variant of a sequential heap implementation [11].
Reference: [28] <author> J. Turek D. Shasha and S. Prakash. </author> <title> Locking without blocking: Making Lock Based Concurrent Data Structure Algorithms Non-blocking. </title> <booktitle> In Proceedings of the 1992 Principle of Database Systems pages 212-222. </booktitle>
Reference-contexts: overhead of coordination among several transactions attempting to help release a location by employing a "reactive" helping policy which we call non-redundant-helping. 1.2 Sequential-to-Non-Blocking Translation One can use STM to provide a general highly concurrent method for translating sequential object implementations into non-blocking ones based on the caching approach of <ref> [6, 28] </ref>. The approach is straightforward: use transactional memory to to implement any collection of changes to a shared object, performing them as an atomic k-word Compare&Swap transaction (see Figure 2) on the desired locations. The non-blocking STM implementation guarantees that some transaction will always succeed. <p> To overcome the limitations of Herlihy's method , Barnes, in [6], introduced his caching method, that avoids copying the whole object and allows concurrent disjoint updating. A similar approach was independently proposed by Turek, Shasha, and Prakash <ref> [28] </ref>. According to Barnes, a process first "simulates" the execution of the updating in its private memory, i.e reading a location for the 2 first time is done from the shared memory but writing is done into the private memory. <p> Barnes suggested to implement the k-word Read-Modify-Write by locking in ascending order of their key, the locations involved in the update executing the operation and, after executing the operation needed, releasing the locks. The key to achieving the non-blocking resilient behavior in the caching approach of <ref> [6, 28] </ref> is the cooperative method: whenever a process needs a location already locked by another process it helps the locking process to complete its own operation, and this is done recursively along the dependency chain.
Reference: [29] <author> D. Touitou. </author> <title> Lock-Free Programming: A Thesis Proposal. </title> <address> Tel Aviv University April 1993. </address> <month> 33 </month>
References-found: 29

