URL: http://www.lsi.upc.es/dept/techreps/ps/R95-18.ps.gz
Refering-URL: http://www.lsi.upc.es/dept/techreps/1995.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: On Parallel versus Sequential Approximation  
Author: Maria Serna Fatos Xhafa Jordi Girona Salgado, - 
Note: 08034-Barcelona, Spain Third European Symposium on Algorithms, ESA'95 Lecture Notes on Computer Science, (979) 409-419 Springer-Verlag, 1995  
Address: Modul C6 Campus Nord  
Affiliation: Departament de Llenguatges i Sistemes Informatics Universitat Politecnica de Catalunya  
Abstract-found: 0
Intro-found: 1
Reference: [ACP94] <author> G. Ausiello, P. Crescenzi, and M. Protasi. </author> <title> Approximate Solution of NP Optimization Problems. </title> <type> Technical Report SI/RR - 94/03, </type> <institution> Dipartimento di Scienze dell'Informazione. University of Rome, La Sapienza, </institution> <year> 1994. </year> <month> 13 </month>
Reference-contexts: In order to reduce to Max Bounded Weighted SAT we first reduce it, using a NCAS-reduction, to another problem and then reduce to Max Bounded Weighted SAT. Our reduction is based in that given in <ref> [ACP94] </ref> but extended to the parallel setting. Let T be the NC ffi-approximation algorithm for . The problem is as follows. <p> This transformation preserves the relative error when passing from solutions of to those of (see details in <ref> [ACP94] </ref>). Since NCAS-reductions compose we have that NCAS Max Bounded Weighted SAT. The minimization case uses similar arguments. 2 4 The Parallel Complexity of Local Search Problems The sequential complexity of local search algorithms has been extensively treated in [JPY88, SY91]. <p> For example, Luby [Lub88] shows that a simple 1-approximation algorithm for Max CUT that puts a vertex in one side of the cut with probability 1=2 can be done also in parallel. In <ref> [ACP94] </ref> was given a sequential 1-approximation for Max 3SAT, we give a different and simple algorithm that achieves the same ratio in NC for the general Max SAT.
Reference: [ADP80] <author> G. Ausiello, A. D'Atri, and M. Protasi. </author> <title> Structure Preserving Reductions Among Convex Optimization Problems. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 21 </volume> <pages> 136-153, </pages> <year> 1980. </year>
Reference-contexts: We show that Max Bounded Weighted SAT is complete for NCX under NCAS-reductions, notice that this problem is also complete for the class APX under PTAS-reductions <ref> [ADP80] </ref>. One general approach when dealing with hard combinatorial problems is to use a local search algorithm. Starting from an initial solution, the algorithm moves to a better one among its neighbors, until a locally optimal solution is found. <p> Definition 2 Given an instance x of any function problem and an " &gt; 0, the "- problem is: compute a value V (x) such that "(x) V (x) (x). Based on the definition of PTAS-reductions <ref> [ADP80, CS81, PM81] </ref> we define the error preserving reductions in NC. Definition 3 Let A and B be two NPO problems.
Reference: [AP81] <author> D. Aldous and J. </author> <title> Pitman. The Asymptotic Speed and Shape of a Particle System. </title> <publisher> Cambridge University Press, </publisher> <year> 1981. </year>
Reference-contexts: Let us denote by k , the growth rate of L k , i.e., its average increase. The key fact is the following theorem <ref> [AP81] </ref>. Theorem 13 [AP81] Let m be a positive integer and let M be a sequence of m's. Then the expected rate of growth, m , of the sequence L M is less than or equal to e=m, for large m. <p> Let us denote by k , the growth rate of L k , i.e., its average increase. The key fact is the following theorem <ref> [AP81] </ref>. Theorem 13 [AP81] Let m be a positive integer and let M be a sequence of m's. Then the expected rate of growth, m , of the sequence L M is less than or equal to e=m, for large m.
Reference: [CS81] <author> B. Corte and R. Schrader. </author> <title> On the Existence of Fast Approximation Schemes. </title> <booktitle> In Nonlinear Programming, </booktitle> <pages> pages 415-437. </pages> <publisher> Academic Press, </publisher> <year> 1981. </year>
Reference-contexts: Definition 2 Given an instance x of any function problem and an " &gt; 0, the "- problem is: compute a value V (x) such that "(x) V (x) (x). Based on the definition of PTAS-reductions <ref> [ADP80, CS81, PM81] </ref> we define the error preserving reductions in NC. Definition 3 Let A and B be two NPO problems.
Reference: [DST93] <author> J. Daz, M. Serna, and J. Toran. </author> <title> Parallel Approximation Classes. </title> <booktitle> In Workshop on Parallel Algorithms, </booktitle> <address> WOPA'93, San Diego, </address> <year> 1993. </year>
Reference-contexts: In the parallel setting we have an analogous situation. We consider the class of problems that are approximable within a constant ratio in NC that we denote NCX. Many properties are common for the classes NCX and APX. For example, in <ref> [DST93] </ref> it was shown that MAXSNP is contained in NCX, to do so they introduced L-reductions under the logspace criterion and proved that all known MAXSNP-complete problems proved in [PY91] are also complete under this reducibility.
Reference: [GJ79] <author> M.R. Garey and D.S. Johnson. </author> <title> Computers and Intractability A Guide to the Theory of NP-Completeness. W.H. </title> <publisher> Freeman and Co., </publisher> <year> 1979. </year>
Reference-contexts: Now, the reduction from to Max Bounded Weighted SAT goes as follows. Given an instance x of , we apply Cook's theorem (see, e.g., <ref> [GJ79] </ref>). Then we will have a transformation (in polynomial time) from the problem to SAT. We observe that this transformation ca be achieved also in logspace.
Reference: [JPY88] <author> D. Jonson, Ch. Papadimitriou, and M. Yannakakis. </author> <title> How Easy Is Local Search? Journal of Computer and System Sciences, </title> <booktitle> 37 </booktitle> <pages> 79-100, </pages> <year> 1988. </year>
Reference-contexts: Since NCAS-reductions compose we have that NCAS Max Bounded Weighted SAT. The minimization case uses similar arguments. 2 4 The Parallel Complexity of Local Search Problems The sequential complexity of local search algorithms has been extensively treated in <ref> [JPY88, SY91] </ref>. Here we deal with this issue in the parallel setting. Let us start by the definition of such algorithms.
Reference: [Kle81] <author> J.K. Kleitman. </author> <title> Hypergraphic Extremal Properties. </title> <booktitle> In Proceedings of the 7th British Combinatorial Conference., </booktitle> <pages> pages 59-78, </pages> <year> 1981. </year>
Reference-contexts: Then we apply Kruskal-Katona theorem <ref> [Kle81] </ref> that shows how to find a set of i vertices in a hypercube with minimal boundary size. From this theorem the bounds on S (i) follow. 2 The stochastic process described below, will stochastically dominate the pathlengths of the vertices of the tree.
Reference: [KMSV94] <author> S. Khanna, R. Motwani, M. Sudan, and U. Vazirani. </author> <title> On Syntactic versus Computational Views of Approximability. </title> <booktitle> In Proceedings of 35th IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pages 819-830, </pages> <year> 1994. </year>
Reference-contexts: They proved that any problem in MAXSNP/MAXNP class can be approximated in polynomial time with constant ratio and many problems were shown to be MAXSNP-complete under L-reductions (for linear reductions). Later on, <ref> [KMSV94] </ref> proved that the class APX coincides with the closure under E-reductions of MAXNP and MAXSNP, thus reconciling both views (syntactic and computational) of approximability. In the parallel setting we have an analogous situation. <p> One general approach when dealing with hard combinatorial problems is to use a local search algorithm. Starting from an initial solution, the algorithm moves to a better one among its neighbors, until a locally optimal solution is found. This approach was used in <ref> [KMSV94] </ref> where they provided a characterization of MAXSNP in terms of a class of problems called Max kCSP (for Constraint Satisfaction Problem), and show that a simple non-oblivious local search provides a polynomial time approximation algorithm for the problems of the class. <p> The local search defined above is also called Standard Local Search or Oblivious Local Search. A more generalized (astute) method for local search, Non-oblivious Local Search is given in <ref> [KMSV94] </ref>. The Non-oblivious Local Search was shown to be more powerful than the oblivious one since it permits to explore in both directions: that of the objective function and also that of the distance function.
Reference: [Lub88] <author> M. Luby. </author> <title> Removing Randomness in Parallel Computation without a Processor Penalty. </title> <booktitle> In Proceedings of 29th IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pages 162-173, </pages> <year> 1988. </year>
Reference-contexts: Proving constant approximability in NC is an important issue. Many constant factor approximation results in sequential can be translated also into parallel approximation results of (almost) the same factor. For example, Luby <ref> [Lub88] </ref> shows that a simple 1-approximation algorithm for Max CUT that puts a vertex in one side of the cut with probability 1=2 can be done also in parallel.
Reference: [PM81] <author> A. Paz and S. Moran. </author> <title> Non-Deterministic Polynomial Optimization Problems and their Approximation. </title> <journal> Theoretical Computer Science, </journal> <volume> 15 </volume> <pages> 251-277, </pages> <year> 1981. </year>
Reference-contexts: Definition 2 Given an instance x of any function problem and an " &gt; 0, the "- problem is: compute a value V (x) such that "(x) V (x) (x). Based on the definition of PTAS-reductions <ref> [ADP80, CS81, PM81] </ref> we define the error preserving reductions in NC. Definition 3 Let A and B be two NPO problems.
Reference: [PY91] <author> C.H. Papadimitriou and M. Yannakakis. </author> <title> Optimization, Approximation, and Complexity Classes. </title> <journal> Computer and System Sciences, </journal> <volume> 43 </volume> <pages> 425-440, </pages> <year> 1991. </year>
Reference-contexts: problems in APX which could be proved constant approximable in a generic way, or, alternatively, is there any complexity class between the classes P and NP whose members do not accept Polynomial Time Approximation Schemes? In order to give a precise characterization of such (possible) complexity classes, Papadimitriou and Yannakakis <ref> [PY91] </ref> fl This research was supported by the ESPRIT BRA Program of the European Community under contract No. 7141, Project ALCOM II. 1 used Fagin's syntactic definition of the class NP and introduced the classes MAXNP and MAXSNP. <p> Many properties are common for the classes NCX and APX. For example, in [DST93] it was shown that MAXSNP is contained in NCX, to do so they introduced L-reductions under the logspace criterion and proved that all known MAXSNP-complete problems proved in <ref> [PY91] </ref> are also complete under this reducibility. Then, the inclusion MAXSNP NCX is straightforward by observing that a complete problem (for example Max CUT) is constant approximable in NC. We first consider the possibility, for the class NCX, of having complete problems. <p> We first consider the possibility, for the class NCX, of having complete problems. To this aim we define some kind of NC-reduction, called NCAS-reduction, that preserves the "relative error" of approximations. This reduction generalizes the logspace L-reduction of <ref> [PY91] </ref> in the following sense: L-reductions relate the optima of both problems, while NCAS-reduction only has the property that constant approximations to one problem translates into constant approximations to the other. <p> On the other hand this kind of reduction also "transmits" the non-approximability from A to B. We recall also the L-reduction as defined in <ref> [PY91] </ref>. <p> First, since non-oblivious local search algorithm approximate Max CUT then, under the supposition that P 6= NP there exist a positive constant " such that Max CUT cannot approximated in NC for factors smaller than ". Secondly, recall that Max CUT is MAXSNP-complete under logspace L-reductions <ref> [PY91] </ref>, therefore from Theorem 6 and Theorem 8 we obtain: Theorem 9 For every MAXSNP-complete problem , there exist " 0 , " 1 , " 1 " 0 , such that can be approximated in NC for any " " 0 but cannot be approximated for any " &lt; "
Reference: [Roh76] <author> V. Rohatgi. </author> <title> An Introduction to Probability Theory and Mathematical Satistics. </title> <publisher> John Wiley, </publisher> <year> 1976. </year>
Reference-contexts: So it suffices to find an upper bound for the expected height of the tree generated in the second model. A formal definition of stochastic dominance (see, e.g., <ref> [Roh76] </ref>) follows. Definition 9 If X and Y are two random variables with distribution functions F x (t) and F y (t), then we say that X stochastically dominate Y (X - Y ), if F x (t) F y (t), 8t.
Reference: [Ser91] <author> M. Serna. </author> <title> Approximating Linear Programming is Logspace Complete for P. </title> <journal> Information Processing Letters, </journal> <volume> 37 </volume> <pages> 233-236, </pages> <year> 1991. </year>
Reference-contexts: Our proof uses a reduction from the Circuit True Gates, a problem that was shown non-approximable in NC <ref> [Ser91] </ref>, to Local Max CUT. Theorem 6 There is an " 1 &gt; 0 such that the "-Local Max CUT is P-complete for any " &lt; " 1 .
Reference: [SY91] <author> A.A. Schaffer and M. Yannakakis. </author> <title> Simple Local Search Problems that are Hard to Solve. </title> <journal> SIAM Journal of Computing, </journal> <volume> 20 </volume> <pages> 56-87, </pages> <year> 1991. </year>
Reference-contexts: Since NCAS-reductions compose we have that NCAS Max Bounded Weighted SAT. The minimization case uses similar arguments. 2 4 The Parallel Complexity of Local Search Problems The sequential complexity of local search algorithms has been extensively treated in <ref> [JPY88, SY91] </ref>. Here we deal with this issue in the parallel setting. Let us start by the definition of such algorithms. <p> We show that the Local Max CUT problem is non-approximable in NC, unless P=NC. Our results builts on the result of <ref> [SY91] </ref> where was shown that finding a locally optimal solution to the unweighted Max CUT is P-complete. Moreover, we do not refer to any particular method (standard local search, non-oblivious local search, etc.) used to find the locally optimal solution, i.e. the non-aproximability result is independent of the method used. <p> Proof: [Sketch] Given an instance of Circuit True Gates, let us consider the instance of CVP corresponding to it, i.e., the encoding a of the circuit together with the input assignment. Then, we use the reduction given in <ref> [SY91] </ref> to reduce the CVP to Local Max CUT. This reduction goes through three stages. <p> Here we give the most relevant points of the reduction (the reduction is quite involved), the full details are found in <ref> [SY91] </ref>. Our main observation here is to relate the value of the CUT with the number of true gates of the circuit instance from which we deduce the non-approximability result. Having the instance of CVP, the variables for POS NAE 3SAT are as follows.
Reference: [Tov86] <author> C. Tovey. </author> <title> Low Order Polynomial Bounds on the Expected Performance of Local Improvment Algorithms. </title> <journal> Journal of Mathematical Programming, </journal> <volume> 35 </volume> <pages> 193-224, </pages> <year> 1986. </year>
Reference-contexts: In order to evaluate the expected number of iterations done by the algorithm, we must precise how do we choose at step 2. Many reasonable probability distributions exist for this choice <ref> [Tov86] </ref>. Here we will consider the boundary distribution, defined as follows. Let B (i) be the boundary of the vertices chosen until step i. Then, the (i + 1)th vertex is chosen uniformly at random in the boundary B (i).
References-found: 16

