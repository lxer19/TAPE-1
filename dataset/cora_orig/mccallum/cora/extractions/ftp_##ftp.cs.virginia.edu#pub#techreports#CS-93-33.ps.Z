URL: ftp://ftp.cs.virginia.edu/pub/techreports/CS-93-33.ps.Z
Refering-URL: ftp://ftp.cs.virginia.edu/pub/techreports/README.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: On the Implementation of Local Synchrony  
Abstract: Raymond R. Wagner, Jr. UVA Computer Science Technical Report TR-93-33 June 1993 
Abstract-found: 1
Intro-found: 1
Reference: [AbP89] <author> S. Abraham and K. Padmanabhan, </author> <title> Performance of the Direct Binary n-Cube Network for Multiprocessors, </title> <journal> IEEE Trans. on Computers 38,7 (July 1989), </journal> <pages> 1000-1011. </pages>
Reference-contexts: The third approach is probabilistic mean value analysis. This type of analysis has been applied with success to banyan networks and their equivalents [Jen83] [YLL90] [KiL90] and to direct binary n-cubes <ref> [AbP89] </ref>. In [Jen83], Jenq presents an analytical model for the performance of Banyan (Omega) networks composed of 2-input, 2-output switching elements in a synchronous, single buffered, packet-switching system. <p> The studies discussed so far have considered only indirect and mostly equidistant network configurations. <ref> [AbP89] </ref> and [Abr90] take up the analytical study of the performance of directly connected architectures related to the hypercube. Abraham provides mathematical models and discusses performance characteristics of direct binary d-cube networks. The results of these analyses compare favorably to those for indirect shufe-exchange networks.
Reference: [Abr90] <author> S. Abraham, </author> <title> Issues in the Architecture of Direct Interconnection Schemes for Multiprocessors, </title> <type> in Ph.D. </type> <institution> Dissertation University of Illinois, Urbanna, IL, </institution> <month> March </month> <year> 1990. </year>
Reference-contexts: The studies discussed so far have considered only indirect and mostly equidistant network configurations. [AbP89] and <ref> [Abr90] </ref> take up the analytical study of the performance of directly connected architectures related to the hypercube. Abraham provides mathematical models and discusses performance characteristics of direct binary d-cube networks. The results of these analyses compare favorably to those for indirect shufe-exchange networks.
Reference: [AdS82] <author> G. B. Adams, III and H. J. Siegel, </author> <title> The Extra Stage Cube: A Fault-Tolerant Interconnection Network for Supersystems, </title> <journal> IEEE Transactions on Computers C-31,5 (May 1982), </journal> <pages> 443-454. </pages>
Reference: [Agr83] <author> D. P. Agrawal, </author> <title> Graph Theoretical Analysis and Design of Multistage Interconnection Networks, </title> <journal> IEEE Transactions on Computers, </journal> <month> July </month> <year> 1983, </year> <pages> 637-648. </pages>
Reference-contexts: A simple solution to the problem of deadlock can be found in the work on the topological equivalence of different types of networks and architectures. In [Wu80], Wu and Feng demonstrate the equivalence of data manipulators, ip networks, omega networks, regular SW banyan networks, and indirect binary n-cubes. Agrawal <ref> [Agr83] </ref> goes on to show that all such log 2 N stage interconnection networks are topologically equivalent. Padmanabhan [Pad90] presents the exact structural relationship between binary n-cubes and the hypercube, bridging the gap between equidistant and non-equidistant architectures.
Reference: [Awe85] <author> B. Awerbuch, </author> <title> Complexity of Network Synchronization, </title> <journal> J. ACM 32,4 (October 1985), </journal> <pages> 804-823. </pages>
Reference-contexts: Local synchrony is a conservative timestamp ordering protocol, which guarantees serial scheduling and sequential consistency, as well as the atomicity of isochrons, without the possibility of rollback. Awerbuch <ref> [Awe85] </ref> utilizes a system similar to local synchrony in order to simulate synchronous architectures on asynchronous networks. Awerbuch uses the notion of safetywhere a node knows that it is finished with its operation for a given time unitto generate a barrier for the whole network.
Reference: [BaJ88] <author> M. Balakrishnan and R. Jain, </author> <title> On Array Storage for Conict-Free memory Access for Parallel Processors, </title> <booktitle> in Proc. 1988 International Conference on Parallel Processing Vol. 1, IEEE, </booktitle> <year> 1988, </year> <pages> 103-107. </pages>
Reference: [BaB87] <author> V. Balasubramanian and P. Banerjee, </author> <title> A Fault Tolerant Massively Parallel Processing Architecture, </title> <journal> Journal of Parallel and Distributed Computing 4 (1987), </journal> <pages> 363-383. </pages>
Reference-contexts: Redundancy schemes have also been proposed for the Buttery <ref> [BaB87] </ref> and the Hypercube [IIS82], where an extra dimension is added to the cube for fault-tolerance and load-balancing measures.
Reference: [BaD89] <author> P. Banerjee and A. Dugar, </author> <title> The Design, Analysis and Simulation of a FaultTolerant Interconnection Network Supporting the Fetch-and-Add Primitive, </title> <journal> IEEE Trans. on Computers 38,1 (Jan 1989), </journal> <pages> 30-46. </pages>
Reference-contexts: Adding an extra stage to the network makes it a multi-path design, which can be used to tolerate both node and connection faults by replicating messages along all possible paths <ref> [BaD89] </ref>, or by utilizing non-faulty paths after faults have been detected [PaL83]. Redundancy schemes have also been proposed for the Buttery [BaB87] and the Hypercube [IIS82], where an extra dimension is added to the cube for fault-tolerance and load-balancing measures.
Reference: [BeG80] <author> P. A. Bernstein and N. Goodman, </author> <title> Timestamp Based Algorithms for Concurrency Control in Distributed Database Systems, </title> <booktitle> in Proc. 6th International Conf. on Very Large Data Bases, </booktitle> <month> October </month> <year> 1980. </year>
Reference-contexts: In the basic timestamp ordering system, this means that an access will be aborted if it does not meet the above requirements. Conservative timestamp ordering systems eliminate rollbacks by executing accesses only if no older access will ever be received <ref> [BeG80] </ref> [Mil79]. This type of system is generally based on global knowledge about accesses currently in the system and the current timestamps of processes. Timestamp ordering systems generally enforce a policy of sequential consistency, which dictates that processes issue timestamps in ascending order.
Reference: [BeG81] <author> P. A. Bernstein and N. Goodman, </author> <title> Concurrency Control in Distributed Database Systems, </title> <booktitle> ACM Computer Surveys 13 (1981), </booktitle> <pages> 185-222. </pages>
Reference-contexts: To be executed, a READ access must have a timestamp greater than the last WRITE, and a WRITE access must have a timestamp greater than any preceding access <ref> [BeG81] </ref>. In the basic timestamp ordering system, this means that an access will be aborted if it does not meet the above requirements. Conservative timestamp ordering systems eliminate rollbacks by executing accesses only if no older access will ever be received [BeG80] [Mil79]. <p> Local synchrony may be cast as a conservative timestamp ordering system. Local synchrony is constrained to produce sequentially consistent serial schedules for global memory accesses. The atomicity of isochrons is guaranteed with no possibility of rollback. Bernstein and Goodman <ref> [BeG81] </ref> state that, in a conservative system, When a scheduler [node] receives an 24 operation O that might cause a future restart [logical time conict], the scheduler [node] delays O until it is sure that no future restarts [logical time conicts] are possible.
Reference: [BGCS89] <author> Y. Birk, P. Gibbons, J. Sanz, and D. Soroker, </author> <title> A Simple mechanism for Efficient Barrier Synchronization in MIMD Machines, </title> <type> IBM Research Report 7078 (67141), </type> <month> October </month> <year> 1989. </year>
Reference: [BNR89] <author> R. Bisiani, A. Nowatzyk and M. Ravishankar, </author> <title> Coherent Shared Memory on a Distributed Memory Machine, </title> <booktitle> in Proc. 1989 International Conference on Parallel Processing, IEEE, </booktitle> <year> 1989, </year> <month> I-133-141. </month>
Reference: [ChM79] <author> K. Chandi and J. Misra, </author> <title> Distributed Simulation: A Case Study in Design and Verification of Distributed Programs, </title> <journal> IEEE Trans. on Software Engineering SE-5, </journal> <volume> 5 (Septembe 1979), </volume> <pages> 440-452. </pages>
Reference-contexts: Ranade also, in order to guarantee bounds on the emulation, is able to implement efficient (no associative search) combining by keeping accesses sorted as they traverse the network. Efficient (FIFO) combining is discussed in section 2.2. In <ref> [ChM79] </ref>, Chandy and Misra present a scheme for distributed simulation. The Chandy/ Misra system is a conservative timestamp ordering system much like local synchrony. The authors implementation scheme is less efficient than ours, however, and their proof of deadlock freedom is slightly awed. <p> Ghost messages are similar to the null messages found in parallel simulation literature <ref> [ChM79] </ref>. Null messages ensure deadlock freedom in groups of processes that communicate via message passing in a parallel simulation. When an SE passes (or is waiting to pass) an access on a given output channel, its other output channel may be idle. This condition can cause deadlock. <p> In local synchrony, sources (PEs) generate messages with a unique logical timestamp and are required to release messages in timestamp order. Other nodes are also required to release messages in timestamp order. 89 As logical systems, local synchrony and the Chandy/Misra logical simulation <ref> [ChM79] </ref> are quite similar. <p> This creates a situation where two (or more) nodes may be waiting on each other, but cannot communicate to break the deadlock because of the conservative processing constraints in the system. This situation was overlooked in the Chandy/Misra logical simulation system <ref> [ChM79] </ref>. While this system can deadlock, it exhibits many traits which make it attractive as a possi ble implementation of local synchrony. Switching elements are able to operate independently, making decisions based only on local communication. No global communication is required to make progress at any time. <p> The next section presents an implementation plan for local synchrony on LS architectures. 4.4 Local Synchrony Implementation on LS Architectures We now discuss the implementation of local synchrony on architectures based on LS graph communication topologies, as presented in section 4.3. As in <ref> [ChM79] </ref>, we assume a simple communication protocol for messages: a message is sent from node i to node j if and only if node i is ready to send the message and node j is ready to receive the message. We assume that a protocol, e.g. <p> Because there are no directed loops in the network, and the network is finite, this chain must end at a source node. Contradiction. n 104 4.5.2 Deadlock Freedom We derive this argument in part from the deadlock freedom arguments in <ref> [ChM79] </ref>. Chandy and Misra define a communication line (i, j) to be a WN line if node i is waiting to output to node j, but j is not waiting for input from node i. NW, NN, and WW lines are defined similarly. <p> The second area includes comparison of the various approaches to logical timestamp ordering. We intend to compare local synchrony implementations to the Chandy/Misra <ref> [ChM79] </ref> timestamp ordering system, and to make a thorough comparison of pulse ordering implementations as presented in Chapter 6. We intend further to investigate possible optimistic implementations of logical timestamp ordering systems for concurrency control. The final area for comparative analysis is between local synchrony and other concurrency control approaches.
Reference: [ChM87] <author> K. Chandy and J. Misra, </author> <title> Conditional Knowledge as a Basis for Distributed Simulation, </title> <type> CIT CS tech. Rep. </type> <institution> 5251:TR:87, </institution> <year> 1987. </year>
Reference-contexts: The authors implementation scheme is less efficient than ours, however, and their proof of deadlock freedom is slightly awed. Kumar [Kum86] proves the Chandy/Misra system to be deadlock-free for feedforward networks consisting of fork and join nodes. In <ref> [ChM87] </ref>, Chandy and Misra develop the idea of conditional knowledge, which increases the efficiency of their distributed simulation scheme. This section provides us with a background with which to present an Operative Condition of local synchrony.
Reference: [ChS89] <author> M. Chen and K. G. Shin, </author> <title> Fault-Tolerant Routing in Hypercube Multicomputers Using Depth-First Search, </title> <booktitle> in International Computer Science Institute Tech. </booktitle> <address> Rep.- 89-006, </address> <month> February </month> <year> 1989. </year> <month> 222 </month>
Reference-contexts: More interest has recently focused on dynamic systems that route messages based on current network load conditions and the presence of faulty nodes or links in the network <ref> [ChS89] </ref>. One important factor in the design of these types of systems is the method of gathering local or global information on load conditions and faults. Another important issue is the level of compatibility with concurrency control mechanisms and network performance enhancements such as combining, which require certain path restrictions. <p> The designer of a dynamic routing system must take into account the degree to which his design depends on global knowledge, the gathering of which can seriously impact processing efficiency. Fault-tolerant routing in a multi-path system such as the Hypercube can be implemented as a simple depth-first search <ref> [ChS89] </ref>, where a node can initiate a forward search of the system in order to efficiently route messages around faults.
Reference: [Dal87] <author> W. Daly, </author> <title> Wire-Efficient VLSI Multiprocessor Communication Networks, </title> <booktitle> Proc. Stanford Conference on Advanced Research in VLSI, </booktitle> <publisher> MIT Press, </publisher> <month> March </month> <year> 1987, </year> <pages> 391-415. </pages>
Reference-contexts: This is the simplest scheme, and a significant volume of work has been produced on deadlock-free routing algorithms for these systems [Gun81][MeS80][Gel81]. These algorithms assign a partial order to resources by utilizing a structured buffer pool, ensuring that circular wait situations which cause deadlock cannot occur. Wormhole systems <ref> [Dal87] </ref> break messages into small manageable packets. Routing information is contained in ow-control digits or its. In wormhole routing, the head of a message (including routing its) is advanced directly from incoming to outgoing channels at a node. <p> In section 4.6, we present an algorithm which generates an LS graph from the interconnection topology of a general connected shared memory architecture. A generated LS graph can then be mapped back onto the candidate architecture using virtual channels <ref> [Dal87] </ref>. LS graphs can be used to implement local synchrony correctly on architectures having directed cycles without compromising locality. 97 We present LS graphs because they are consistent with the goals of local synchrony and they represent the most space efficient implementation we have found.
Reference: [Dal90] <author> W. Dally, </author> <title> Virtual-Channel Flow Control, </title> <booktitle> Proc. 17th IEEE International Symposium on Computer Architecture, </booktitle> <month> May </month> <year> 1990, </year> <pages> 60-68. </pages>
Reference-contexts: Dally and Seitz prove that E-routing is deadlock-free for the hypercube. The authors present a method for creating deadlock-free routing schemes using Virtual Channels [DaS87], and Dally goes on to show that virtual channels also can provide increased efficiency in parallel communication systems <ref> [Dal90] </ref>. It is important to distinguish here between physical, virtual, and routable paths. The network topology of any given architecture defines physical paths, which are made up of actual physical links between nodes.
Reference: [DaS87] <author> W. J. Dally and C. L. Sietz, </author> <title> Deadlock-Free Message Routing in Multiprocessor Interconnection Networks, </title> <journal> IEEE Transactions on Computers C-36,5 (May 1987), </journal> <pages> 547-553. </pages>
Reference-contexts: This scheme is provably minimal. The selection of possible lines along which to route the message can be non-deterministic, or can take into account any criteria, such as network load or faulty lines. Dally and Seitz <ref> [DaS87] </ref> describe a system called E-Routing, where the message always crosses the highest-order uncrossed dimension that needs to be crossed. E-routing may also be low-order, crossing the lowest-order dimension first. Dally and Seitz prove that E-routing is deadlock-free for the hypercube. <p> E-routing may also be low-order, crossing the lowest-order dimension first. Dally and Seitz prove that E-routing is deadlock-free for the hypercube. The authors present a method for creating deadlock-free routing schemes using Virtual Channels <ref> [DaS87] </ref>, and Dally goes on to show that virtual channels also can provide increased efficiency in parallel communication systems [Dal90]. It is important to distinguish here between physical, virtual, and routable paths. <p> Because message its cannot be interleaved in buffers, the priority buffer approach to deadlock freedom is not feasible for wormhole systems. However, Dally and Seitz <ref> [DaS87] </ref> show that assigning a partial order to channels rather than using buffers is sufficient for deadlock free 12 dom in wormhole systems. This is the virtual channels approach, in which links between nodes are treated as multiple virtual links through context switching. <p> In order to demonstrate the feasibility of FIFO combining, we assume in our further discussion that accesses remain sorted on return from shared memory. 3.2.1.2 Transport mechanism We choose the store-and-forward access transport paradigm for the implementation, although local synchrony is compatible with wormhole routing <ref> [DaS87] </ref> and virtual cut-through [KeK79]. We assume that shared memory accesses have a fixed size, which greatly simplifies the model (for this discussion, we assume word access, although local synchrony is not limited in this 51 respect). <p> Such a situation can be characterized by a deadlock dependency graph (DDG) <ref> [DaS87] </ref>, which includes each node in the set of deadlocked nodes and arcs representing a given nodes dependencies on others within the set. There are only two types of dependencies that can cause an SE to block and possibly contribute to deadlock in a banyan network implementing local synchrony. <p> Our approach was to define a class of directed graphs, LS graphs, which represent architectures on which local synchrony can be correctly implemented, and then to present an algorithm which creates an LS graph from any shared memory architecture. The target architecture then uses virtual channels <ref> [DaS87] </ref> to emulate the LS graph topology. Our general implementation uses less memory and provides greater opportunities for parallelism than other approaches, and is proven correct and deadlock-free. The proof of correctness of the general implementation of local synchrony is a significant addition to the theory of parallel processing. <p> Further enhancements to our designs would include providing for multi-input switches (as opposed to the two-input design presented here). 219 Another implementation goal would be to assess whether other routing techniques would enhance the performance of local synchrony. Virtual Cut-Through [KeK79] and Wormhole Routing <ref> [DaS87] </ref> are both compatible with local synchrony implementations, and it may be possible to use these approaches to increase the efficiency of the local synchrony implementation, perhaps through timestamp look-ahead at the switch level.
Reference: [DGKL86] <author> S. Dickey, A. Gottlieb, R. Kenner, and Y. Liu, </author> <title> Designing VLSI Network Nodes to Reduce Memory Traffic in a Shared Memory parallel Computer, NYU Ultracom-puter Note #125, </title> <month> August </month> <year> 1986. </year>
Reference: [DiJ81a] <author> D. M. Dias and R. </author> <title> Jump, Analysis and Simulation of Buffered Delta Networks, </title> <journal> IEEE TOC C30,4 (April 1981), </journal> <pages> 273-282. </pages>
Reference-contexts: Dias and Jump [DiJ81b] <ref> [DiJ81a] </ref> consider the performance of both buffered and unbuffered delta networks, compared to crossbar-type switches. This analysis is extended in [KuJ86]. Kruskal and Snir [KrS83] present asymptotic analysis of unbuffered and buffered Ban-yan networks, compared to equivalent networks.
Reference: [DiJ81b] <author> D. M. Dias and J. R. </author> <title> Jump, Packet Switching Interconnection Networks for Modular Systems, </title> <booktitle> IEEE Computer 14,12 (December 1981), </booktitle> <pages> 43-53. </pages>
Reference-contexts: Dias and Jump <ref> [DiJ81b] </ref> [DiJ81a] consider the performance of both buffered and unbuffered delta networks, compared to crossbar-type switches. This analysis is extended in [KuJ86]. Kruskal and Snir [KrS83] present asymptotic analysis of unbuffered and buffered Ban-yan networks, compared to equivalent networks.
Reference: [DiK92] <author> S. Dickey and R. Kenner, </author> <title> A Combining Switch for the NYU Ultracomputer, </title> <month> June </month> <year> 1992. </year>
Reference-contexts: We find, after considering the implementation of this design using off-the-shelf components, that expected performance is comparable to current combining switches for non-locally synchronous operation <ref> [DiK92] </ref>. <p> Our goal was to limit combinable access types to a set of operations that could be combined in any combination. This is not generally the case in conventional combining systems <ref> [DiK92] </ref>. Limiting the size of global memory contained within each MM, or limiting the size of the network, would allow more types of memory operations, if necessary. Local synchrony requires that combinable operations be combinable in any orientation (perceived order of execution). This is possible for many types of operations. <p> This will free up those bits for other purposes, like expanding the number of PE/MMs, the size of global memory, or the number of possible operations. In <ref> [DiK92] </ref>, the authors present the design for a switch that replaces the routing bit of the MM address with a bit designating the input port that received the access. When the access reaches global memory, it has a full address for the PE to which it must return.
Reference: [DSB88] <author> M. Dubois, C. Scheurich and F. Briggs, </author> <title> Synchronization, Coherence, and Event Ordering in Multiprocessors, </title> <note> IEEE Computer 21,2 (February 1988). </note>
Reference: [EGL76] <author> K. P. Eswaran, J. N. Gray, R. A. Lorie and I. L. Traiger, </author> <title> The Notions of Consis-tancy and Predicate Locks in a Database System, </title> <journal> Comm. ACM 19,11 (November 1976), </journal> <pages> 624-633. </pages>
Reference-contexts: Atomicity may be ensured by an underlying system based on two-phase locking or times-tamp ordering. Atomic actions were developed in the database literature by Eswaran et al <ref> [EGL76] </ref>. Reed [Ree83] suggests a timestamp ordering implementation of atomic actions based on timestamping by physical clocks and the use of version histories in memory. A physical clock is based at each processing element, and the clocks are kept loosely synchronized by a global clock synchronization algorithm. <p> In all analytical studies and in most simulations, the raw power is measured for a full input load (i.e., the network inputs are always full). 41 In section 3.1 we discuss various methods of concurrency control by contrasting locking methods (two-phase locking <ref> [EGL76] </ref>) with access-ordering methods. Using simple arguments, we show that local synchrony can outperform traditional locking systems if the local synchrony implementation has greater than a certain fraction of the raw power of a similar locking implementation. <p> If all locks are acquired, then the atomic action can be sent and executed. If all locks are not acquired, any acquired locks must be relinquished and re-acquired with the entire group in order to avoid deadlock. Thrashing and live-lock are still possible, however. Livelock-free locking (2PL) <ref> [EGL76] </ref> orders lock requests according to a pre-set priority and emits them one at a time. As each lock is acquired, the next may be requested. This system eliminates deadlock and livelock, at a larger lock acquirement cost.
Reference: [Fly66] <author> M. J. Flynn, </author> <title> Very High Speed Computers, </title> <booktitle> Proceedings of the IEEE 54 (December 1966), </booktitle> <pages> 1901-1909. </pages>
Reference-contexts: Section 2.7 reviews research related to concurrency control, isochrons, and local synchrony. Sections 2.8 and 2.9 present previous work on fault tolerance and performance issues in multiprocessing systems. 2.1 MIMD Architectures Our research deals with asynchronous multiprocessing computers utilizing the Multiple-Instruction Stream, Multiple-Data Stream (MIMD) <ref> [Fly66] </ref> system architecture. A MIMD proces 8 sor generally consists of a number of nodes connected by communication channels that areusu-allyorganized in a regular pattern (e.g., a hypercube).
Reference: [GGH91] <author> K. Gharachlorloo, A. Gupta, and J. Hennessy, </author> <title> Performance Evaluation of Memory Consistency Models for Shared-Memory Multiprocessors, </title> <booktitle> Proc. ACM APLOS-IV, </booktitle> <month> April </month> <year> 1991, </year> <pages> 245-257. </pages>
Reference: [Gel81] <author> D. Gelertner, </author> <title> A DAG-based algorithm for Prevention of Store-andForward Deadlock in Packet Networks, </title> <journal> IEEE Transactions on Computers C-30 (October 1981), </journal> <pages> 709-715. </pages>
Reference: [Gib89] <author> P. B. Gibbons, </author> <title> The Asynchronous PRAM: A Semi-Synchronous Model for Shared Memory MIMD Machines, </title> <booktitle> in International Computer Science Institute Tech. </booktitle> <address> Rep.-89-062, </address> <month> December </month> <year> 1989. </year>
Reference: [GLR81] <author> A. Gottlieb, B. D. Lubachevsky and L. Rudolph, </author> <title> Coordinating Large Numbers of Processors, </title> <booktitle> in Proc. 1981 International Conference on Parallel Processing, </booktitle> <year> 1981. </year>
Reference-contexts: This guarantee is necessary to avoid buffer deadlock within the network. 3.2.1.7 Combining system Dancehall-type networks like the Banyan network are highly compatible with access combining <ref> [GLR81] </ref> [KRS88]. Because the implementation presented here assumes that accesses are ordered during transmission to and from shared memory, accesses combined at a given SE will return in the same order in which they left the switch.
Reference: [GGK83] <author> A. Gottlieb, R. Grishman, C. P. Kruskal, K. P. McAuliffe, L. Rudolph and M. Snir, </author> <title> The NYU Ultracomputer Designing a MIMD Shared Memory Parallel Computer, </title> <journal> IEEE Transactions on Computers 32,2 (February 1983), </journal> <pages> 175-189. </pages>
Reference-contexts: In an equidistant system, the distance an access requested by any processing element travels to any shared memory location is constant for all processing elements and memory locations. Equidistant architectures generally take the form of shared-memory, indirect machines (e.g., the NYU Ultracomputer <ref> [GGK83] </ref>). Non-equidistant systems are usually directly interconnected and include most message-passing and several shared memory designs. In a non-equidistant architecture, a node generally includes both processing and memory elements, along with switching hardware.
Reference: [GLR83] <author> A. Gottlieb, B. Lubachevsky and L. Rudolph, </author> <title> Basic Techniques for the Efficient Coordination of Very Large Numbers of Cooperating Sequential Processes, </title> <journal> ACM Trans. Prog. Lang. and Systems 5,2 (April 1983), </journal> <pages> 164-189. </pages>
Reference: [Gun81] <author> K. D. Gunther, </author> <title> Prevention of Deadlocks in Packet-Switched Data Transport Systems, </title> <journal> IEEE Transactions on Communications COM-29,4 (April 1981), </journal> <pages> 512-524. 223 </pages>
Reference: [Jef83] <author> D. Jefferson, </author> <title> Virtual Time, </title> <booktitle> in Proc. 1983 International Conference on Parallel Processing, </booktitle> <year> 1983, </year> <pages> 384-394. </pages>
Reference-contexts: The semantics of such systems obey the requirement that, If an event A has a virtual time less than that of event B, then the execution of A and B must be scheduled so that A appears to be completed before B starts <ref> [Jef83] </ref>. Note that there is no requirement for actual physical ordering 26 of events in such a system. The requirement is only that, to the processes in the system, the events appear to have occurred in the given order.
Reference: [Jef85] <author> D. R. Jefferson, </author> <title> Virtual Time, </title> <journal> ACM Trans. Prog. Lang. and Systems 7,3 (July 1985), </journal> <pages> 404-426. </pages>
Reference: [Jen83] <author> Y. Jenq, </author> <title> Performance Analysis of a Packet Switch Based on Single-Buffered Ban-yan Network, </title> <journal> IEEE Journal on Selected Areas in Communications SAC-1,6 (December 1983), </journal> <volume> 10141020. </volume>
Reference-contexts: In general, neither field can handle the multiplicity of message types or the infinite priority scheme which is inherent in a timestamping system of this type. The third approach is probabilistic mean value analysis. This type of analysis has been applied with success to banyan networks and their equivalents <ref> [Jen83] </ref> [YLL90] [KiL90] and to direct binary n-cubes [AbP89]. In [Jen83], Jenq presents an analytical model for the performance of Banyan (Omega) networks composed of 2-input, 2-output switching elements in a synchronous, single buffered, packet-switching system. <p> The third approach is probabilistic mean value analysis. This type of analysis has been applied with success to banyan networks and their equivalents <ref> [Jen83] </ref> [YLL90] [KiL90] and to direct binary n-cubes [AbP89]. In [Jen83], Jenq presents an analytical model for the performance of Banyan (Omega) networks composed of 2-input, 2-output switching elements in a synchronous, single buffered, packet-switching system. <p> The switch consists of two inputs with packet buffers for at least one packet, a switch router, and two outputs with packet buffers. Figure 39 shows the switch topology. FIGURE 39. Switch I1 architecture. Router 144 We can apply Jenqs probabilistic approach <ref> [Jen83] </ref> to this type of architecture. This is the simplest model for performance of this type of switch, and it does not consider either the packet transfer protocol inherent in locally synchronous operation or the different types of local synchrony packets. <p> Finally, we showed that under certain conditions it is possible to limit the number of saved checkpoints. Our third goal was a simulation and analytical study of performance of local synchrony implementations. Extending the probabilistic method of Jenq <ref> [Jen83] </ref>, we developed several analytical models of local synchrony implementations that predict the raw power of the locally synchronous communication networks studied (switch architectures I1 and I2section 6.1). These predictions enable us to validate the performance predictions of our simulations.
Reference: [KHM87] <author> M. Karol, M. Hluchyj, and S. Morgan, </author> <title> Input Versus Output Queueing on a Space-Division Packet Switch, </title> <journal> IEEE Trans. on Communications Com-35, </journal> <month> 12 (December </month> <year> 1987), </year> <pages> 1347-1356. </pages>
Reference-contexts: In the context of a conventional network, the z-switch is similar to switch designs with output buffers <ref> [KHM87] </ref> or internal buffers [KuJ84]. We assume switches in C1 and I1 have the same cycle time; i. e., we assume that the amount of time required in the absence of conicts for a message to travel through a switch in C1 is the same as in I1.
Reference: [KeK79] <author> P. Kermani and L. Kleinrock, </author> <title> Virtual Cut-Through: A New Computer Communication Switching Technique, </title> <booktitle> Computer Networks 3 (1979), </booktitle> <pages> 267-286. </pages>
Reference-contexts: This is the virtual channels approach, in which links between nodes are treated as multiple virtual links through context switching. A third approach with similarities to both systems is Virtual Cut-Through <ref> [KeK79] </ref>. Here messages are broken up and allowed to spread throughout the network, but a node may not accept any part of an incoming message unless it can buffer the whole message (in the event that it is blocked). <p> In order to demonstrate the feasibility of FIFO combining, we assume in our further discussion that accesses remain sorted on return from shared memory. 3.2.1.2 Transport mechanism We choose the store-and-forward access transport paradigm for the implementation, although local synchrony is compatible with wormhole routing [DaS87] and virtual cut-through <ref> [KeK79] </ref>. We assume that shared memory accesses have a fixed size, which greatly simplifies the model (for this discussion, we assume word access, although local synchrony is not limited in this 51 respect). <p> Further enhancements to our designs would include providing for multi-input switches (as opposed to the two-input design presented here). 219 Another implementation goal would be to assess whether other routing techniques would enhance the performance of local synchrony. Virtual Cut-Through <ref> [KeK79] </ref> and Wormhole Routing [DaS87] are both compatible with local synchrony implementations, and it may be possible to use these approaches to increase the efficiency of the local synchrony implementation, perhaps through timestamp look-ahead at the switch level.
Reference: [KrS83] <author> C. P. Kruskal and M. Snir, </author> <title> The Performance of Multistage Interconnection Networks for Multiprocessors, </title> <journal> IEEE Transactions on Computers C-32,12 (December 1983), </journal> <pages> 1091-1098. </pages>
Reference-contexts: Dias and Jump [DiJ81b] [DiJ81a] consider the performance of both buffered and unbuffered delta networks, compared to crossbar-type switches. This analysis is extended in [KuJ86]. Kruskal and Snir <ref> [KrS83] </ref> present asymptotic analysis of unbuffered and buffered Ban-yan networks, compared to equivalent networks. Analytical studies have also considered the bandwidth, or number of requests accepted (by the network) per cycle, of several types of both unbuffered and single-buffered shufe-exchange networks [Pat81] [YLL87].
Reference: [KRS88] <author> C. P. Kruskal, L. Rudolph and M. Snir, </author> <title> Efficient Synchronization on Multiprocessors with Shared Memory, </title> <journal> ACM Trans. Prog. Lang. and Systems 10,4 (October 1988), </journal> <pages> 579-601. </pages>
Reference-contexts: The READ access from Process 2 is sent back with the value 5, and the WRITE access from Process 1 is returned successfully. In order to add power to the combining mechanism, Kruskal, Rudolph, and Snir <ref> [KRS88] </ref> have proposed the implementation of the READ-MODIFY-WRITE [Rud81] formalism in combining systems. Such a system would have as its basic memory access operation RMW (X,f), where X is the shared variable and f is a function to be performed on that variable. <p> Kruskal, Rudolph, and Snir prove that their combining algorithm is correct by showing that the execution of a given combined operation is equivalent to a possible serial execution of the operations from which it is composed <ref> [KRS88] </ref>. A by-product of this work, which is important to our research, concerns the orientation of combined operations. When two operations are combined, the resulting combined operation, when performed, achieves the same result as some serial execution of the original operations. <p> Now consider a system implementing RMW operations. RMW operations always return the previous value of the memory location, and can thus be combined in any orientation. In general, any pair of RMW operations that can be combined can be combined in either orientation <ref> [KRS88] </ref>. Little research has gone into memory access combining on non-equidistant architectures. The most important addition to the combining literature has been the work at Yale on the Fluent Architecture [Ran87] [RBJ88]. <p> This guarantee is necessary to avoid buffer deadlock within the network. 3.2.1.7 Combining system Dancehall-type networks like the Banyan network are highly compatible with access combining [GLR81] <ref> [KRS88] </ref>. Because the implementation presented here assumes that accesses are ordered during transmission to and from shared memory, accesses combined at a given SE will return in the same order in which they left the switch.
Reference: [Kum86] <author> D. Kumar, </author> <title> Simulating Feedforward Systems Using a Newtork of Processors, </title> <booktitle> Proceedings of the Annual Simulation Symposium, </booktitle> <year> 1986, </year> <pages> 127-144. </pages>
Reference-contexts: In [ChM79], Chandy and Misra present a scheme for distributed simulation. The Chandy/ Misra system is a conservative timestamp ordering system much like local synchrony. The authors implementation scheme is less efficient than ours, however, and their proof of deadlock freedom is slightly awed. Kumar <ref> [Kum86] </ref> proves the Chandy/Misra system to be deadlock-free for feedforward networks consisting of fork and join nodes. In [ChM87], Chandy and Misra develop the idea of conditional knowledge, which increases the efficiency of their distributed simulation scheme.
Reference: [KuR85] <author> V. P. Kumar and S. M. Reddy, </author> <title> Design and Analysis of Fault-Tolerant Multistage Interconnection Networks With Low Link Complexity, </title> <year> 1985. </year>
Reference-contexts: Analytical studies have also considered the bandwidth, or number of requests accepted (by the network) per cycle, of several types of both unbuffered and single-buffered shufe-exchange networks [Pat81] [YLL87]. Other performance analyses have been conducted for fault-tolerant versions of these types of networks <ref> [KuR85] </ref> [YoL89]. Finally, performance studies have been presented for combining systems [Lee86] [Won86]. These studies report performance measures for combining systems in normal operation, where a random distribution of requests is assumed, and in cases of hot spots [Pfi85], situations in which more requests are targeted for certain outputs.
Reference: [KuJ86] <author> M. Kumar and J. R. </author> <title> Jump, Performance of Unbuffered Shufe-Exchange Networks, </title> <journal> IEEE TOC C-35,6 (June 1986), </journal> <pages> 573-578. </pages>
Reference-contexts: Dias and Jump [DiJ81b] [DiJ81a] consider the performance of both buffered and unbuffered delta networks, compared to crossbar-type switches. This analysis is extended in <ref> [KuJ86] </ref>. Kruskal and Snir [KrS83] present asymptotic analysis of unbuffered and buffered Ban-yan networks, compared to equivalent networks. Analytical studies have also considered the bandwidth, or number of requests accepted (by the network) per cycle, of several types of both unbuffered and single-buffered shufe-exchange networks [Pat81] [YLL87].
Reference: [Lam78] <author> L. L. Lamport, </author> <title> Time, Clocks, and the Ordering of Events in a Distributed System, </title> <journal> Comm. ACM 21,7 (July 1978), </journal> <pages> 558-565. </pages>
Reference-contexts: Again, while this implementation does allow the implementation of atomic actions, the problem of aborted operations still exists. Concurrency control as applied to parallel architectures and operating systems has only recently come under study. In <ref> [Lam78] </ref>, Lamport proposed a system of logical clocks, which would provide partial ordering to the events of a system of processes.
Reference: [Lam79] <author> L. Lamport, </author> <title> How to Make a Multiprocessor Computer that Correctly Executes Multiprocess Programs, </title> <journal> IEEE Transactions on Computers C-28,9 (September 1979), </journal> <pages> 690-691. </pages>
Reference-contexts: - Any two accesses made by the same process are exe cuted in the order specified by the process, if any. 17 The accesses of a given process are sequentially consistent if the order in which they are executed is consistent with the order specified by the processs sequential program <ref> [Lam79] </ref>. In other words, the memory access requests of a process must be executed in the order in which the process submitted them. <p> Version consistency is generally enforced by different types of locking mechanisms. Williams characterization of the goal of concurrency control for parallel programs is inuenced by literature on concurrency control for concurrent databases, by Lamports definition of sequential consistency <ref> [Lam79] </ref>, and by Shasha and Snirs definition of correct execution of parallel programs [ShS88]. These and related works are discussed in more detail in the following sections. <p> The execution of a parallel program is said to be sequentially consistent if the result of any execution is the same as if the operations were executed in some sequential order, and the operations of each individual processor appear in this sequence in the order specified by its program <ref> [Lam79] </ref>. An isochron program, when executed, must be sequentially consistent and also ensure the atomicity of parallel accesses to global memory.
Reference: [Lee86] <author> G. Lee, </author> <title> Some Issues in General-Purpose Shared Memory Multiprocessing: Parallelism Exploitation and Memory Access Combining, </title> <type> Ph.D. Thesis, </type> <institution> CS Dept. Univ. of Illinois at Urbana-Champaign, </institution> <year> 1986. </year>
Reference-contexts: Other performance analyses have been conducted for fault-tolerant versions of these types of networks [KuR85] [YoL89]. Finally, performance studies have been presented for combining systems <ref> [Lee86] </ref> [Won86]. These studies report performance measures for combining systems in normal operation, where a random distribution of requests is assumed, and in cases of hot spots [Pfi85], situations in which more requests are targeted for certain outputs.
Reference: [LiK91] <author> T. Lin and L. Kleinrock, </author> <title> Performance Analysis of Finite-Buffered Multistage Interconnection Networks with a General Traffic Pattern, </title> <booktitle> Proc. 1991 ACM SIG-METRICS Conf., </booktitle> <pages> 68-78. </pages>
Reference-contexts: Thus, our discussion will consider studies in which messages may not be removed from the system, but must be blocked. 37 There are three general approaches to analytical modeling of these types of systems. Researchers using Markov analysis have had some success <ref> [LiK91] </ref> [WuL92] [Mer91], but the combinatorial explosion of states involved in this technique makes complex models difficult. Queueing networks have also been suggested [WiE90]. Both of these techniques have significant drawbacks when applied to locally synchronous systems.
Reference: [Mer91] <author> A. Merchant, </author> <title> A Markov Chain Approximation for the Analysis of Banyan Networks, </title> <booktitle> Proc. 1991 ACM SIGMETRICS Conference, </booktitle> <pages> 60-66. </pages>
Reference-contexts: Thus, our discussion will consider studies in which messages may not be removed from the system, but must be blocked. 37 There are three general approaches to analytical modeling of these types of systems. Researchers using Markov analysis have had some success [LiK91] [WuL92] <ref> [Mer91] </ref>, but the combinatorial explosion of states involved in this technique makes complex models difficult. Queueing networks have also been suggested [WiE90]. Both of these techniques have significant drawbacks when applied to locally synchronous systems.
Reference: [MeS80] <author> P. M. Merlin and P. J. Schweitzer, </author> <title> Deadlock Avoidance in Store-and-Forward Networks 1: Store-and-Forward Deadlock... 2: Other Deadlock Types, </title> <journal> IEEE Transactions on Communications COM-28,3 (1980), </journal> <volume> 345360. </volume>
Reference: [Mil79] <author> M. Milenkovic, </author> <title> Update Synchronization in Multiaccess Systems, </title> <institution> University of Massachusetts, Amherst, </institution> <month> May, </month> <year> 1979. </year> <month> 224 </month>
Reference-contexts: In the basic timestamp ordering system, this means that an access will be aborted if it does not meet the above requirements. Conservative timestamp ordering systems eliminate rollbacks by executing accesses only if no older access will ever be received [BeG80] <ref> [Mil79] </ref>. This type of system is generally based on global knowledge about accesses currently in the system and the current timestamps of processes. Timestamp ordering systems generally enforce a policy of sequential consistency, which dictates that processes issue timestamps in ascending order.
Reference: [OwL82] <author> S. Owicki and L. Lamport, </author> <title> Proving Liveness Properties of Concurrent Programs, </title> <journal> ACM Trans. Prog. Lang. and Systems 4,3 (July 1982), </journal> <pages> 455-495. </pages>
Reference-contexts: Isochrons are a limited form of atomic action. The general form of atomic actions is a group of operations which are performed atomically <ref> [OwL82] </ref>, meaning that no process other than the issuer can observe or affect an intermediate state in the execution. This general form of atomic actions allows data-dependent operations.
Reference: [Pad90] <author> K. Padmanabhan, </author> <title> Cube Structures for Multiprocessors, </title> <journal> Comm. ACM 33,1 (Janu-ary 1990), </journal> <pages> 43-52. </pages>
Reference-contexts: These applications are better suited to the asynchronous model. Our work investigates the efficiency and fault-tolerance of local synchrony as a way to achieve the benefits of synchronous processing on asynchronous processors, without unduly compromising the benefits (e.g., performance) of asynchronous operation. Padmanabhan <ref> [Pad90] </ref> distinguishes between direct and indirect interconnection schemes. In a direct interconnection scheme, processing elements are connected in a network using point-to-point links. An indirect scheme separates the architecture into processors and memory (or combined processing/memory nodes) and a switching network. <p> In [Wu80], Wu and Feng demonstrate the equivalence of data manipulators, ip networks, omega networks, regular SW banyan networks, and indirect binary n-cubes. Agrawal [Agr83] goes on to show that all such log 2 N stage interconnection networks are topologically equivalent. Padmanabhan <ref> [Pad90] </ref> presents the exact structural relationship between binary n-cubes and the hypercube, bridging the gap between equidistant and non-equidistant architectures.
Reference: [Pat81] <author> J. H. Patel, </author> <title> Performance of Processor-Memory Interconnections for Multiprocessors, </title> <journal> IEEE Transactions on Computers C-30,10 (October 1981), </journal> <pages> 771-780. </pages>
Reference-contexts: Kruskal and Snir [KrS83] present asymptotic analysis of unbuffered and buffered Ban-yan networks, compared to equivalent networks. Analytical studies have also considered the bandwidth, or number of requests accepted (by the network) per cycle, of several types of both unbuffered and single-buffered shufe-exchange networks <ref> [Pat81] </ref> [YLL87]. Other performance analyses have been conducted for fault-tolerant versions of these types of networks [KuR85] [YoL89]. Finally, performance studies have been presented for combining systems [Lee86] [Won86].
Reference: [Pfi85] <author> G. F. Pfister, </author> <title> The IBM Research Parallel Processor (RP3): Introduction and Architecture, </title> <booktitle> Proc. Int. Conf. on Parallel Processing, </booktitle> <year> 1985, </year> <pages> 764-771. </pages>
Reference-contexts: The NYU Ultracomputer was the first to combine accesses to global memory [GLR81][GLR83]; combining was later proposed for the IBM RP3 <ref> [Pfi85] </ref>. The Ultracomputer is an equidistant, shared-memory multiprocessor consisting of a number of processing elements, each with its own private memory, and a number of memory elements, which house global memory. <p> Finally, performance studies have been presented for combining systems [Lee86] [Won86]. These studies report performance measures for combining systems in normal operation, where a random distribution of requests is assumed, and in cases of hot spots <ref> [Pfi85] </ref>, situations in which more requests are targeted for certain outputs. The studies discussed so far have considered only indirect and mostly equidistant network configurations. [AbP89] and [Abr90] take up the analytical study of the performance of directly connected architectures related to the hypercube. <p> We suggest that an architecture utilizing a locally synchronous network for concurrency and a low-latency network for singleton operations (similar to the RP3 <ref> [Pfi85] </ref>) might achieve an extremely high degree of efficiency. <p> We intend to explore hybrid implementations of local synchrony in which accesses that need not be subject to concurrency control requirements are able to pass more quickly through the network. This approach is similar to that proposed for the IBM RP3 <ref> [Pfi85] </ref>. For example, a singleton READ access sent by a PE may not have sequential consistency restraints (as a singleton, there are no atomicity restraints). Such an access might have higher priority than normal accesses in the hybrid approach.
Reference: [PrV81] <author> F.P. Preparata and J. Vuillemin, </author> <title> The Cube-Connected Cycles: A Versatile Network for Parallel Computation, </title> <journal> Comm. ACM 24,5 (May 1981), </journal> <pages> 300-309. </pages>
Reference-contexts: Non-equidistant systems are usually directly interconnected and include most message-passing and several shared memory designs. In a non-equidistant architecture, a node generally includes both processing and memory elements, along with switching hardware. Examples of non-equidistant architectures are numerous and include hypercubes [Sei85], cube-connected cycles <ref> [PrV81] </ref>, rings, toroids, and meshes. 2.2 Routing, Message Transfer, and Deadlock A multiprocessor with a uni-path network architecture has a unique physical path from any processing element to any memory element. Uni-path systems tend to be limited to equidistant systems, but neither is a requirement for the other.
Reference: [RAK89] <author> U. Ramachandran, M. Ahamad and M. Khalidi, </author> <title> Coherence of Distributed Shared Memory: Unifying Synchronization and Data Transfer, </title> <booktitle> in Proc. 1989 International Conference on Parallel Processing, IEEE, </booktitle> <year> 1989, </year> <month> II-160-169. </month>
Reference: [Ran75] <author> B. Randell, </author> <title> System Structure for Software Fault Tolerance, </title> <journal> IEEE Trans. on Software Engineering SE-1 (June 1975), </journal> <pages> 220-232. </pages>
Reference-contexts: These issues must be addressed to provide a fault tolerant implementation of local synchrony and combining. Another facet of fault tolerance research that we address is rollback recovery. A compromised computation must be rolled back to a previously saved coherent state. Randell <ref> [Ran75] </ref> and others have pointed out that the domino effect, in which a rollback causes further rollbacks in a chain, can be eliminated if state savings can be synchronized. Others [TKT92 et al.] have proposed different methods for achieving this type of synchronization. <p> If faults conict, then the conservatism of the implementation may be compromised (out of order message processing) or deadlock can occur, and a rollback (with fault removal) or restart of the calculation must occur. 5.3 A Rollback Algorithm for Local Synchrony The domino effect <ref> [Ran75] </ref> is the main obstacle to implementing rollback recovery in a distributed system. An elements rollback to a checkpoint can cause other entities to roll back in a potentially unlimited chain.
Reference: [Ran87] <author> A. G. Ranade, </author> <title> How To Emulate Shared Memory, </title> <booktitle> in Annual Symp. on Foundations of Computer Science 87, IEEE, </booktitle> <year> 1987, </year> <pages> 185-194. </pages>
Reference-contexts: In general, any pair of RMW operations that can be combined can be combined in either orientation [KRS88]. Little research has gone into memory access combining on non-equidistant architectures. The most important addition to the combining literature has been the work at Yale on the Fluent Architecture <ref> [Ran87] </ref> [RBJ88]. While the goal of this work had little to do with combining systems (its goal was efficient PRAM emulation), Ranade was able to show that, given some synchronization, combining operations in the network could be greatly simplified, removing the need for associative search when decombining. <p> Safety is recognized by a node when it receives confirmation from each of its neighbors that they will send it no more work prior to the next barrier. Local synchrony elements use safety in order to safely proceed to the next logical time unit. Ranade <ref> [Ran87] </ref> uses end-of-stream (EOS) messages, similar to local synchrony tokens, to emulate a CRCW PRAM on a buttery. Unlike local synchrony, EOS messages are sent after each access. The EOS messages act to synchronize the operation of the system. <p> Each times-tamp includes information about the logical time unit (ltu) of the access, the source (pid) of the access, and the rank (among accesses from the same source) of the access. The timestamp may also include information about the destination (dest) of the access. A ghost message <ref> [Ran87] </ref> is a message which contains only logical timestamp information. A ghost message serves only to increase network efficiency and facilitate deadlock freedom. The local synchrony ordering constraint forces PEs, switches, and MMs to process accesses in order by their logical timestamp. <p> MM is a contiguous set of addresses, and that the MMs are ordered contiguously in the architecture, then routing is simply checking whether the destination address of the packet is greater than or less than a given address and choosing the output channel accordingly. 3.2.1.4 Deadlock avoidance system Ghost messages <ref> [Ran87] </ref> [RBJ88] avoid deadlock within the network by disseminating information from SE to SE as soon as it is available. Ghost messages are similar to the null messages found in parallel simulation literature [ChM79]. <p> The other access may be copied into the combine buffer, and used to decombine the accesses on return. Since combined accesses return to a given SE in the same order they left it, decombining information can be kept in a FIFO queue <ref> [Ran87] </ref>, instead of the traditional associative search queue. Each access packet can include bits that determine whether a given access was combined at a given stage in the network. <p> This information already passes to the consumer receiving the latest access from the given producer. The other consumer may receive this information as a ghost message <ref> [Ran87] </ref>, which reports the last timestamp of an access sent by the producing switch. 10 00 10 10 00 00 a Stage 1 Stage 0 Stage 1 Stage 0 Stage 1 Stage 0 MMsPEs 59 With the information supplied by the ghost message, one of the two consumer nodes (00 and <p> This approach is wasteful of buffer space. Our approach solves this problem by eliminating the possibility of comparing dissimilar priorities (the priorities of messages with differing distances to travel in the network), without making messages travel any further than necessary (Ranade <ref> [Ran87] </ref> achieves a similar result by requiring all message to travel the same distance, compromising locality). Our approach also provides better space efficiency and more opportunities for parallelism. Several processing threads can occur in parallel, so greater efficiency is possible and more opportunities for parallelism exist. <p> Route-tags are lexicographically ordered. Local synchrony networks carry two types of messages in addition to operations: tokens and ghosts. As described in chapter 2 and elsewhere, tokens are control signals that divide ltus. A ghost <ref> [Ran87] </ref> is a copy of an operation with a bit set to indicate it is not a real operation. In other respects, ghosts look like operations. In particular, ghosts have route-tags.
Reference: [RBJ88] <author> A. G. Ranade, S. N. Bhatt and S. L. Johnsson, </author> <title> The Fluent Abstract Machine, </title> <institution> Yale University Department of Computer Science Tech. Rep.-573, </institution> <month> January </month> <year> 1988. </year>
Reference-contexts: In general, any pair of RMW operations that can be combined can be combined in either orientation [KRS88]. Little research has gone into memory access combining on non-equidistant architectures. The most important addition to the combining literature has been the work at Yale on the Fluent Architecture [Ran87] <ref> [RBJ88] </ref>. While the goal of this work had little to do with combining systems (its goal was efficient PRAM emulation), Ranade was able to show that, given some synchronization, combining operations in the network could be greatly simplified, removing the need for associative search when decombining. <p> is a contiguous set of addresses, and that the MMs are ordered contiguously in the architecture, then routing is simply checking whether the destination address of the packet is greater than or less than a given address and choosing the output channel accordingly. 3.2.1.4 Deadlock avoidance system Ghost messages [Ran87] <ref> [RBJ88] </ref> avoid deadlock within the network by disseminating information from SE to SE as soon as it is available. Ghost messages are similar to the null messages found in parallel simulation literature [ChM79].
Reference: [Ree83] <author> D. P. Reed, </author> <title> Implementing Atomic Actions on Decentralized Data, </title> <journal> ACM Transactions on Computer Systems 1,1 (February 1983), </journal> <pages> 3-23. </pages>
Reference-contexts: An isochron program, when executed, must be sequentially consistent and also ensure the atomicity of parallel accesses to global memory. This idea is similar to Reeds notion of Concurrent Atomicity <ref> [Ree83] </ref>: For all executed steps o not in A (the atomic action), either o precedes all steps in A, or o follows all steps in A. Isochrons are an attempt to apply this property to memory access in distributed systems. <p> Atomicity may be ensured by an underlying system based on two-phase locking or times-tamp ordering. Atomic actions were developed in the database literature by Eswaran et al [EGL76]. Reed <ref> [Ree83] </ref> suggests a timestamp ordering implementation of atomic actions based on timestamping by physical clocks and the use of version histories in memory. A physical clock is based at each processing element, and the clocks are kept loosely synchronized by a global clock synchronization algorithm. <p> The use of this pid in the timestamp assigns a disjoint interval of logical time during each ltu to the accesses issued by the given PE. This disjoint interval provides atomicity for isochrons. This technique for providing atomicity is widely used in database concurrency control <ref> [Ree83] </ref> [RSL78]. The tock component of the timestamp provides sequentially consistent ordering for any operations accessing the same variable, from the same process, in the same ltu, i.e.
Reference: [ReT86] <author> R. Rettberg and R. Thomas, </author> <title> Contention is No Obstacle to Shared-Memory Multiprocessing, </title> <journal> Comm. ACM 29,12 (December 1986), </journal> <pages> 1202-1212. </pages>
Reference: [ReW91] <author> P. F. Reynolds, Jr. and R. R. Wagner, Jr., </author> <title> A Local Synchrony Implementation: Banyan Networks, </title> <type> UVA CS Tech. </type> <institution> Rep.-91-38, </institution> <month> December </month> <year> 1991. </year>
Reference-contexts: A message traverses a step in the network when it moves from one element to a neighboring element. A message must travel a distance of some number of steps to reach its destination. In local synchrony implementations, tokens are passed to mark the barriers between ltus. Isotach networks <ref> [ReW91] </ref> are special local synchrony networks which enforce the isotach velocity invariant, that a message requires one ltu to proceed one step in the network. An architecture exhibits locality if accesses to shared or distributed memory from a PE in the architecture can have varying distances to travel. <p> This knowledge may enable the switch to route an operation on its other input. Ghosts improve network performance and are necessary in some networks for deadlock freedom <ref> [ReW91] </ref>. 140 6.1.3 Local synchrony network I1 In network I1 the switches have the same structure as the switches in C1; i.e., each switch has two input queues, two output buffers, and a router. Each switch in I1 records the route-tag of the last message it routed as last_tag.
Reference: [RWW89] <author> P. F. Reynolds, Jr., C. Williams and R. R. Wagner, Jr., </author> <title> Parallel Operations, </title> <type> UVA CS Tech. </type> <institution> Rep.-89-16, </institution> <month> December </month> <year> 1989. </year>
Reference-contexts: When multiple entities (i.e., processes) are competing for the use of multiple resources (i.e., global variables) extreme care must be taken to enforce proper accessing principles. The motivation for our own work in this area is parallel memory operations [Wag87] <ref> [RWW89] </ref> or isochrons [Wil93]. Isochrons allow a process to perform exclusive operations on sets of global variables without the need for locking or global synchronization. Local synchrony is a concurrency control mechanism which supports isochrons. <p> Local synchrony meets the criteria for sequential consistency and atomicity as defined in [Wil93] and discussed in section 2.4. One benefit would be that local synchrony supports isochrons [Wil93], a concept derived from parallel operations [Wag87] <ref> [RWW89] </ref>. An isochron consists of a set of memory accesses emitted by a given process which appear to be executed simultaneously, so that 18 memory coherency is maintained. <p> The implementation of isochrons requires a system which guarantees exclusive access to distributed memory locations. Our own requirements for such a system exclude explicit locking of locations and process synchronization in making this guarantee. Local synchrony <ref> [RWW89] </ref> [Wil93] meets these requirements though implicit logical timestamping of global memory accesses. Our research studies the implementation of local synchrony on various asynchronous architectures. The next section presents Williams [Wil90] theoretical definitions for Locally Synchronous systems. 2.6 Local Synchrony In [Wil90], Williams describes a set of clock conditions. <p> These conditions describe the operation of a timestamping system for global memory accesses in a parallel architecture. A system operating under these conditions is shown to have a conict-free serial execution which meets the requirements for sequential consistency and atomicity discussed in section 2.4. In <ref> [RWW89] </ref>, a method of implementation is described which meets these clock conditions. This concurrency control mechanism is called local synchrony. Williams distinguishes the following types of events: Definition: An issue event occurs when a process queues a global memory access to be sent for execution. <p> In a non-equidistant system such as the hypercube, only the pid need be explicitly represented in each access, in order to ensure correct ordering of accesses from different PEs within logical time units. The notion of convexity was introduced in <ref> [RWW89] </ref>.
Reference: [RWW92] <author> P. F. Reynolds, Jr., C. Williams and R. R. Wagner, Jr., </author> <title> Empirical Analysis of Iso-tach Networks, </title> <type> UVA CS Tech. </type> <institution> Rep.-92-19, June1992. </institution>
Reference-contexts: We use mean value analysis in modeling local synchrony. Our analytical models predict the theoretical raw power performance of the implementations and agree closely with the raw power results of our simulation studies. The simulation studies, performed jointly with Craig Williams <ref> [RWW92] </ref>, compare the performance of local synchrony implementations with conventional implementations for different types of workloads, based on various levels of concurrency control requirements. Section 6.1 presents an overview of the architectures modeled and the internal communication algorithms performed by each. <p> Networks C1 and I1 are both composed of 2x2 crossbar switches with input and output buffer queues. Networks C2 and I2 use more sophisticated switches, called z-switches, that yield higher throughput at some cost in latency. We developed the z-switch <ref> [RWW92] </ref> to improve the throughput of the local synchrony network. When it proved successful, we translated it into a conventional switch design to enable us to compare the z-switch version of the local synchrony network (I2) to a conventional network with comparable routing advantages (C2). <p> 0.2 0.4 0.6 0.8 1.0 READ Probability 0.0 100.0 200.0 Delay 207 Series 6 indicates that isotach systems outperform conventional systems by a wider margin when accesses are not uniformly distributed. 6.3.7 Conclusions from the Simulation Study We have presented results from a simulation study, performed jointly with Craig Williams <ref> [RWW92] </ref>, comparing the performance of locally synchronous isotach and conventional networks. The study shows conventional networks have higher raw power than isotach networks, but that under a workload of operations with atomicity and sequencing constraints, isotach networks outperform conventional networks. <p> Our analytical models extend the probabilistic method to more complex systems involving multiple message types. Our analytical models agree closely with the raw power results of our simulation studies. The simulation studies, performed jointly with Craig Williams <ref> [RWW92] </ref>, compare the performance of local synchrony implementations with conventional implementations for different types of workloads, based on various levels of concurrency control requirements. <p> These predictions enable us to validate the performance predictions of our simulations. The analytical models also extend the probabilistic method to more complex types of systems than previously investigated. Our simulation study (performed jointly with Craig Williams <ref> [RWW92] </ref>) compares the performance of locally synchronous isotach [WiR91] networks to similarly constructed conventional networks. We present data for a conventional single-stage switch architecture (switches C1 and I1section 6.1), and for a two-stage, high-throughput architecture (switches C2 and I2).
Reference: [RSL78] <author> D. Rosenkrantz, R. Stearns and P. Lewis, </author> <title> System-Level Concurrency Control for Distributed Data Bases, </title> <journal> ACM Trans. Database Systems 3,2 (1978), </journal> <pages> 178-198. </pages>
Reference-contexts: The use of this pid in the timestamp assigns a disjoint interval of logical time during each ltu to the accesses issued by the given PE. This disjoint interval provides atomicity for isochrons. This technique for providing atomicity is widely used in database concurrency control [Ree83] <ref> [RSL78] </ref>. The tock component of the timestamp provides sequentially consistent ordering for any operations accessing the same variable, from the same process, in the same ltu, i.e.
Reference: [Rud81] <author> L. Rudolph, </author> <title> Software Structures for Ultraparallel Computing, </title> <type> Ph.D. </type> <institution> Dissertaion, NYU, </institution> <year> 1981. </year>
Reference-contexts: The READ access from Process 2 is sent back with the value 5, and the WRITE access from Process 1 is returned successfully. In order to add power to the combining mechanism, Kruskal, Rudolph, and Snir [KRS88] have proposed the implementation of the READ-MODIFY-WRITE <ref> [Rud81] </ref> formalism in combining systems. Such a system would have as its basic memory access operation RMW (X,f), where X is the shared variable and f is a function to be performed on that variable.
Reference: [SaS88] <author> Y. Saad and M. H. Shultz, </author> <title> Topological Properties of Hypercubes, </title> <journal> IEEE Transactions on Computers C-37,7 (July 1988), </journal> <pages> 867-872. </pages>
Reference-contexts: Agrawal [Agr83] goes on to show that all such log 2 N stage interconnection networks are topologically equivalent. Padmanabhan [Pad90] presents the exact structural relationship between binary n-cubes and the hypercube, bridging the gap between equidistant and non-equidistant architectures. Saad and Schultz <ref> [SaS88] </ref> also show that various topologies, most importantly linear arrays (meshes), may be mapped into the n-cube topology. 34 A deadlock-free implementation of local synchrony on an Ultracomputer, then, could be translated to the hypercube through topological equivalence, which allows the hypercube to emulate the Ultracomputer architecture.
Reference: [Sch83] <author> F. B. Schneider, </author> <title> Fail-Stop Processors, </title> <booktitle> in Digest of Papers Spring Compcon 83, IEEE Computer Society, </booktitle> <address> San Francisco, CA, </address> <month> March </month> <year> 1983. </year>
Reference-contexts: The fault in this case will be the failure of a single physical communication channel. The operation of a fail-stop <ref> [Sch83] </ref> system requires that failures be detected before the system may enter any state resulting from the fault. The importance of fail-stop operation is that no information in the system is changed or lost due to a fault.
Reference: [Sei85] <author> C. L. Seitz, </author> <title> The Cosmic Cube, </title> <journal> Comm. </journal> <note> ACM 28,1 (January 1985), 22-33. </note>
Reference-contexts: Non-equidistant systems are usually directly interconnected and include most message-passing and several shared memory designs. In a non-equidistant architecture, a node generally includes both processing and memory elements, along with switching hardware. Examples of non-equidistant architectures are numerous and include hypercubes <ref> [Sei85] </ref>, cube-connected cycles [PrV81], rings, toroids, and meshes. 2.2 Routing, Message Transfer, and Deadlock A multiprocessor with a uni-path network architecture has a unique physical path from any processing element to any memory element.
Reference: [ShS88] <author> D. Shasha and M. Snir, </author> <title> Efficient and Correct Execution of Parallel Programs that Share Memory, </title> <journal> ACM Trans. Prog. Lang. and Systems 10,2 (April 1988), </journal> <pages> 282-312. 225 </pages>
Reference-contexts: Williams characterization of the goal of concurrency control for parallel programs is inuenced by literature on concurrency control for concurrent databases, by Lamports definition of sequential consistency [Lam79], and by Shasha and Snirs definition of correct execution of parallel programs <ref> [ShS88] </ref>. These and related works are discussed in more detail in the following sections.
Reference: [TAF88] <author> Y. Tamir and G. Frazier, </author> <title> High-Performance Multi-Queue Buffers for VLSI Communication Switches, </title> <booktitle> Proc. 15th IEEE Symposium on Computer Architecture, </booktitle> <month> May </month> <year> 1988, </year> <pages> 343-354. </pages>
Reference: [TKT92] <author> Z. Tong, R. Kain, and W. Tsai, </author> <title> Rollback Recovery in Distributed Systems Using Loosely Synchronized Clocks, </title> <journal> IEEE Trans on Parallel and Distributed Systems 3, </journal> <month> 2 (March </month> <year> 1992), </year> <pages> 246-251. </pages>
Reference-contexts: Randell pointed out that the domino effect can be eliminated if it is 126 possible to synchronize state saving checkpoints. Local synchrony allows absolute synchronization of checkpoints to be implemented without checkpoint communication and with no more synchronization overhead than is already present in the system. In <ref> [TKT92] </ref>, the authors define a consistent system state as a set of recovery points, one for each node within the system, such that restoring all recovery points will not cause any orphan (lost) messages.
Reference: [TuR88] <author> L. W. Tucker and G. G. Robertson, </author> <title> Architecture and Applications of the Connection Machine, </title> <note> IEEE Computer 21,8 (August 1988), 2638. </note>
Reference: [TYZ85] <author> N. Tzeng, P. Yew and C. Zhu, </author> <title> A Fault-Tolerant Scheme for Multistage Interconnection Networks, </title> <year> 1985. </year>
Reference-contexts: Banyan type interconnection networks for uni-path, equidistant architectures such as the NYU Ultracomputer can be 35 given a measure of connection fault tolerance by connecting switching units in the same stage <ref> [TYZ85] </ref> [TYZ86]. Adding an extra stage to the network makes it a multi-path design, which can be used to tolerate both node and connection faults by replicating messages along all possible paths [BaD89], or by utilizing non-faulty paths after faults have been detected [PaL83].
Reference: [TYZ86] <author> N. Tzeng, P. Yew and C. Zhu, </author> <title> Fault-Diagnosis in a Multiple-Path Interconnection Network, </title> <journal> IEEE Transactions on Computers, </journal> <year> 1986, </year> <pages> 98-103. </pages>
Reference-contexts: Banyan type interconnection networks for uni-path, equidistant architectures such as the NYU Ultracomputer can be 35 given a measure of connection fault tolerance by connecting switching units in the same stage [TYZ85] <ref> [TYZ86] </ref>. Adding an extra stage to the network makes it a multi-path design, which can be used to tolerate both node and connection faults by replicating messages along all possible paths [BaD89], or by utilizing non-faulty paths after faults have been detected [PaL83].
Reference: [VaR86] <author> A. Varma and C. S. Raghavendra, </author> <title> Fault-Tolerant Routing in Multistage Interconnection Networks, </title> <journal> IEEE Transactions on Computers, </journal> <year> 1986, </year> <pages> 104-109. </pages>
Reference-contexts: An important condition that must be maintained is Dynamic Full Access (DFA) <ref> [VaR86] </ref>, which means that a message from any given process within the system must be able to reach any destination available to it.
Reference: [Wag87] <author> R. R. Wagner, Jr., </author> <title> Parallel Operations in Shared Memory, </title> <institution> Masters Thesis University of Virginia, </institution> <year> 1987. </year>
Reference-contexts: When multiple entities (i.e., processes) are competing for the use of multiple resources (i.e., global variables) extreme care must be taken to enforce proper accessing principles. The motivation for our own work in this area is parallel memory operations <ref> [Wag87] </ref> [RWW89] or isochrons [Wil93]. Isochrons allow a process to perform exclusive operations on sets of global variables without the need for locking or global synchronization. Local synchrony is a concurrency control mechanism which supports isochrons. <p> Local synchrony meets the criteria for sequential consistency and atomicity as defined in [Wil93] and discussed in section 2.4. One benefit would be that local synchrony supports isochrons [Wil93], a concept derived from parallel operations <ref> [Wag87] </ref> [RWW89]. An isochron consists of a set of memory accesses emitted by a given process which appear to be executed simultaneously, so that 18 memory coherency is maintained.
Reference: [WiE90] <author> D. Willick and D. Eager, </author> <title> An Analytical Model of Multistage Interconnection Networks, </title> <booktitle> Proc. 1990 ACM SIGMETRICS Conf., </booktitle> <pages> 192-199. </pages>
Reference-contexts: Researchers using Markov analysis have had some success [LiK91] [WuL92] [Mer91], but the combinatorial explosion of states involved in this technique makes complex models difficult. Queueing networks have also been suggested <ref> [WiE90] </ref>. Both of these techniques have significant drawbacks when applied to locally synchronous systems. In general, neither field can handle the multiplicity of message types or the infinite priority scheme which is inherent in a timestamping system of this type. The third approach is probabilistic mean value analysis.
Reference: [Wil90] <author> C. Williams, </author> <title> Concurrency Control in Asynchronous Parallel Computations: A Research Proposal, </title> <institution> University of Virginia, </institution> <month> June </month> <year> 1990. </year>
Reference-contexts: In [Wil93], Williams characterizes the goal of concurrency control for parallel programs as to ensure that every execution is serializable. Williams notion of serializability considers several important factors which extend beyond the definition of a serial schedule given above. The following discussion draws on definitions and results appearing in <ref> [Wil90] </ref>. A parallel execution and a serial execution are said to be conict equivalent if, in both executions, each shared variable is accessed by the same operations and conicting operations are executed in the same order. <p> Local synchrony [RWW89] [Wil93] meets these requirements though implicit logical timestamping of global memory accesses. Our research studies the implementation of local synchrony on various asynchronous architectures. The next section presents Williams <ref> [Wil90] </ref> theoretical definitions for Locally Synchronous systems. 2.6 Local Synchrony In [Wil90], Williams describes a set of clock conditions. These conditions describe the operation of a timestamping system for global memory accesses in a parallel architecture. <p> Local synchrony [RWW89] [Wil93] meets these requirements though implicit logical timestamping of global memory accesses. Our research studies the implementation of local synchrony on various asynchronous architectures. The next section presents Williams <ref> [Wil90] </ref> theoretical definitions for Locally Synchronous systems. 2.6 Local Synchrony In [Wil90], Williams describes a set of clock conditions. These conditions describe the operation of a timestamping system for global memory accesses in a parallel architecture. <p> Each event is assumed to be atomic. In other words, each process issues operations one at a time, and each operation is executed at memory one at a time. In <ref> [Wil90] </ref>, two relations are defined on operations: OP i fi OP j (precedes) if (1) each accesses the same variable and the execute event of OP i occurs before that of OP j . or (2) each is issued by the same process and the issue event of OP i occurs <p> Williams goes on to show that any isochron program, E p , that conforms to these conditions is sequentially consistent and preserves atomicity of isochrons by proving that E s is sequentially consistent, atomic, and conict equivalent to E p <ref> [Wil90] </ref>. Since all execute operations are executed at distinct logical times, those times define a serial schedule, or total ordering, of the global memory accesses of E p . <p> Proposition 4: For any operation OP i , C (OP i ) = TS (OP i ). Williams shows that the algorithm specified by the above propositions and the conditions on operation of the PEs and switches correctly implements the clock conditions for equidistant systems <ref> [Wil90] </ref>. Clock condition 2 follows directly from propositions 1 and 4. Clock condition 1 is implied by propositions 2, 3, and 4. For any pair of operations, OP i and OP j , OP i fi OP j fi C (OP i ) &lt; C (OP j ).
Reference: [Wil93] <author> C. Williams, </author> <title> Concurrency Control in Asynchronous Parallel Computations, </title> <type> PhD Dissertation, </type> <institution> University of Virginia, </institution> <month> January </month> <year> 1993. </year>
Reference-contexts: These sections act as an introduction to the general area of our work. Section 2.3 introduces combining systems and reviews relevant research in this area. Section 2.4 presents Williams <ref> [Wil93] </ref> approach to concurrency control. This is the main theoretical background for our work. The basis of our work is the implementation of a concurrency control mechanism which meets Williams constraints of atomicity and sequential consistency, and ensures conict-free serial schedules [Wil93] for any execution. <p> Section 2.4 presents Williams <ref> [Wil93] </ref> approach to concurrency control. This is the main theoretical background for our work. The basis of our work is the implementation of a concurrency control mechanism which meets Williams constraints of atomicity and sequential consistency, and ensures conict-free serial schedules [Wil93] for any execution. These conditions are discussed in this section. Section 2.5 presents the concurrency control mechanism isochrons [Wil93]. Isochrons are a concurrency control mechanism, designed for multiprocessing systems, which are compatible with the concurrency control approach defined in section 2.4. <p> The basis of our work is the implementation of a concurrency control mechanism which meets Williams constraints of atomicity and sequential consistency, and ensures conict-free serial schedules <ref> [Wil93] </ref> for any execution. These conditions are discussed in this section. Section 2.5 presents the concurrency control mechanism isochrons [Wil93]. Isochrons are a concurrency control mechanism, designed for multiprocessing systems, which are compatible with the concurrency control approach defined in section 2.4. Isochrons provide a limited form of atomic access in multiprocessing architectures. Section 2.6 presents local synchrony as a method for the implementation of isochrons. <p> When multiple entities (i.e., processes) are competing for the use of multiple resources (i.e., global variables) extreme care must be taken to enforce proper accessing principles. The motivation for our own work in this area is parallel memory operations [Wag87] [RWW89] or isochrons <ref> [Wil93] </ref>. Isochrons allow a process to perform exclusive operations on sets of global variables without the need for locking or global synchronization. Local synchrony is a concurrency control mechanism which supports isochrons. <p> Local synchrony is a concurrency control mechanism which supports isochrons. Definition: The execution trace of a parallel program is equivalent to a serial schedule if all accesses to shared variables are executed in an order that is consis tent with some serial execution of the same program. In <ref> [Wil93] </ref>, Williams characterizes the goal of concurrency control for parallel programs as to ensure that every execution is serializable. Williams notion of serializability considers several important factors which extend beyond the definition of a serial schedule given above. The following discussion draws on definitions and results appearing in [Wil90]. <p> Local synchrony meets the criteria for sequential consistency and atomicity as defined in <ref> [Wil93] </ref> and discussed in section 2.4. One benefit would be that local synchrony supports isochrons [Wil93], a concept derived from parallel operations [Wag87] [RWW89]. <p> Local synchrony meets the criteria for sequential consistency and atomicity as defined in <ref> [Wil93] </ref> and discussed in section 2.4. One benefit would be that local synchrony supports isochrons [Wil93], a concept derived from parallel operations [Wag87] [RWW89]. An isochron consists of a set of memory accesses emitted by a given process which appear to be executed simultaneously, so that 18 memory coherency is maintained. <p> The implementation of isochrons requires a system which guarantees exclusive access to distributed memory locations. Our own requirements for such a system exclude explicit locking of locations and process synchronization in making this guarantee. Local synchrony [RWW89] <ref> [Wil93] </ref> meets these requirements though implicit logical timestamping of global memory accesses. Our research studies the implementation of local synchrony on various asynchronous architectures. The next section presents Williams [Wil90] theoretical definitions for Locally Synchronous systems. 2.6 Local Synchrony In [Wil90], Williams describes a set of clock conditions. <p> Either of the two general implementation techniques (sorted transmission, sorting at memory) fits this description. There are several differences between databases and applications programming which affect the problem solver in this area <ref> [Wil93] </ref>. First, database systems generally require full recov-erability of data in the case of system failure, whereas a parallel program can just be rerun. <p> Local synchrony requires only 28 that the MMs operate conservatively in processing global memory accesses. However, an implementation of local synchrony may include conservative operation by switches and/or PEs as well. 2.8 An Implementation of Local Synchrony In <ref> [Wil93] </ref>, Williams presents basic implementation suggestions for local synchrony on an equidistant network and discusses extensions to this technique for non-equidistant architectures. Williams does not present specific local synchrony implementations or prove deadlock freedom. We present here the general implementation technique. <p> Williams does not present specific local synchrony implementations or prove deadlock freedom. We present here the general implementation technique. For simplicity, we make several assumptions, which are based on those of Williams in <ref> [Wil93] </ref>: 1. The system is a network of nodes communicating over FIFO channels with finite but unbounded delay. 2. Each node consists of a switch, a processing element (PE) and a switch, a mem ory module (MM) and a switch, or a PE, an MM, and a switch. 3. <p> For simplicity, the reader may wish to assume in the following discussion that accesses are kept sorted by timestamp throughout their traversal of the network. Given the operative condition of local synchrony, MMs must process accesses (perform execute events) in a conservative manner. Extended from <ref> [Wil93] </ref>, a PE schedules emission events subject to two constraints: 1. All the accesses in any given isochron are emitted in such a way that the execute event of each will occur during the same ltu. <p> The logical time of execution of each access is determined by the issuing PE through explicit timestamping, implicit timestamping (determined by ordering conventions implemented in the system), or a combination of the two. The timestamp for access OP i , denoted TS (OP i ) <ref> [Wil93] </ref>, is an ordered pair (tick, tock), where the tick component is itself an ordered pair (ltu, pid). The ltu component of TS (OP i ) is the ltu in which the execute event of OP i will occur. <p> access is designed to manipulate only a single 32-bit memory word, locally synchronous operation allows double or multi-word loads, stores, and other operations to be performed atomically, eliminating the need for variable length access messages or specific design for double-word operations (in fact, local synchrony in combination with split operations <ref> [Wil93] </ref> allows any memory operation to be performed on double-length or more mem A1 a G N 65 ory words using fixed length accesses, whether or not the memory is contiguous or distributed among several MMs). <p> We choose REPLACE&ADD rather than FETCH&ADD because the combine and decombine operations are simpler in the former. The other two operations are left undefined, but might be used for other combinable operations or non-combinable operations such as split operations <ref> [Wil93] </ref>, broadcast, or partial word operations. The REPLACE&ADD operation with operand of zero implements a simple load. <p> Consume (remove from the system) all input messages in LOW. 8. Send each message on its respective output channel. We note here that step 1 is only necessary for the implementation to be an isotach network <ref> [Wil93] </ref>. This approach is equivalent to the time increment approach, and PEs generate and send isochrons according to the description in Chapter 2. Since there are no cycles in the LS graph, it may be efficient to implement the time propagate approach. <p> The requirements of a database and those of an operating environment are significantly different. The approach to timestamping systems for parallel architectures must, therefore, be different as well. We believe this field has many opportunities for further study. For example, Williams delta-cache protocols <ref> [Wil93] </ref> show that isotach systems can be used to develop an entirely new method of cache coherency techniques. A significant area of future research would be to explore other applications for local synchrony implementations. <p> We intend further to investigate possible optimistic implementations of logical timestamp ordering systems for concurrency control. The final area for comparative analysis is between local synchrony and other concurrency control approaches. In Chapter 6 we performed this type of analysis with locking implementations. This dissertation and <ref> [Wil93] </ref> have presented strong evidence that logical timestamping systems and local synchrony are a viable alternative to conventional methods of concurrency control. That the study of logical timestamping methods for concurrency control is a field rich with opportunities.
Reference: [WiR89] <author> C. Williams and P. F. Reynolds, Jr., </author> <title> On Variables as Access Sequences in Parallel Asynchronous Computations, </title> <type> UVA CS Tech. </type> <institution> Rep.-89-17, </institution> <month> December, </month> <year> 1989. </year>
Reference: [WiR91] <author> C. Williams and P. F. Reynolds, Jr., </author> <title> Combining Atomic Actions in a Recombining Network, </title> <type> UVA CS Tech. </type> <institution> Rep.-91-33, </institution> <month> November, </month> <year> 1991. </year>
Reference-contexts: A message leaving a given node will travel the same distance before returning, regardless of the distance to its destination. This means that most messages will travel significantly farther than necessary in order to be serviced. In <ref> [WiR91] </ref>, Reynolds and Williams show that atomic actions can be combined in a recombining network, without compromising the integrity of the atomic actions. <p> These predictions enable us to validate the performance predictions of our simulations. The analytical models also extend the probabilistic method to more complex types of systems than previously investigated. Our simulation study (performed jointly with Craig Williams [RWW92]) compares the performance of locally synchronous isotach <ref> [WiR91] </ref> networks to similarly constructed conventional networks. We present data for a conventional single-stage switch architecture (switches C1 and I1section 6.1), and for a two-stage, high-throughput architecture (switches C2 and I2). The study considers in detail the performance of the various implementations under sequencing and atomicity constraints.
Reference: [Won86] <author> M. C. Wong, </author> <title> A Combining Omega Network: Performance vs. Implementation, </title> <type> IBM Research Report RC 11977 (#53952), 6/24/86. </type>
Reference-contexts: Other performance analyses have been conducted for fault-tolerant versions of these types of networks [KuR85] [YoL89]. Finally, performance studies have been presented for combining systems [Lee86] <ref> [Won86] </ref>. These studies report performance measures for combining systems in normal operation, where a random distribution of requests is assumed, and in cases of hot spots [Pfi85], situations in which more requests are targeted for certain outputs. <p> This eliminates the need for blocking, along with its added complexity. The FIFOs generally must be long, however (for this design, assuming that a PE can issue 8 accesses per ltu, the FIFO would have to be able to buffer 256 messages [2 5 *8]). The literature <ref> [Won86] </ref> suggests that buffering more than 2 or 3 accesses at a port is counterproductive. ScalabilityThis design scales quite well to larger networks and applications.
Reference: [Wu80] <author> C. L. Wu and T. Y. Feng, </author> <title> On a Class of Multistage Interconnection Networks, </title> <journal> IEEE Transactions on Computers, </journal> <month> August </month> <year> 1980, </year> <pages> 694-702. </pages>
Reference-contexts: Of major importance is the question of deadlock. Deadlock situations are most complex and prevalent in direct, non-equidistant architectures such as the hypercube. A simple solution to the problem of deadlock can be found in the work on the topological equivalence of different types of networks and architectures. In <ref> [Wu80] </ref>, Wu and Feng demonstrate the equivalence of data manipulators, ip networks, omega networks, regular SW banyan networks, and indirect binary n-cubes. Agrawal [Agr83] goes on to show that all such log 2 N stage interconnection networks are topologically equivalent.
Reference: [WuL92] <author> C. Wu and M. Lee, </author> <title> Performance Analysis of Multistage Interconnection Network Configurations and Operations, </title> <journal> IEEE Trans. on Computers 41, </journal> <month> 1 (January </month> <year> 1992), </year> <pages> 18-27. </pages>
Reference-contexts: Thus, our discussion will consider studies in which messages may not be removed from the system, but must be blocked. 37 There are three general approaches to analytical modeling of these types of systems. Researchers using Markov analysis have had some success [LiK91] <ref> [WuL92] </ref> [Mer91], but the combinatorial explosion of states involved in this technique makes complex models difficult. Queueing networks have also been suggested [WiE90]. Both of these techniques have significant drawbacks when applied to locally synchronous systems.
Reference: [YLL87] <author> H. Yoon, K. Y. Lee and M. T. Liu, </author> <title> Performance Analysis and Comparison of Packet Switching Interconnection Networks, </title> <booktitle> in Proc. 1987 International Conference on Parallel Processing, </booktitle> <month> August </month> <year> 1987, </year> <pages> 542-545. </pages>
Reference-contexts: Kruskal and Snir [KrS83] present asymptotic analysis of unbuffered and buffered Ban-yan networks, compared to equivalent networks. Analytical studies have also considered the bandwidth, or number of requests accepted (by the network) per cycle, of several types of both unbuffered and single-buffered shufe-exchange networks [Pat81] <ref> [YLL87] </ref>. Other performance analyses have been conducted for fault-tolerant versions of these types of networks [KuR85] [YoL89]. Finally, performance studies have been presented for combining systems [Lee86] [Won86].
Reference: [YLL90] <author> H. Yoon, K. Lee and M. Liu, </author> <title> Performance Analysis of Multibuffered Packet-Switching Networks in Multiprocessor Systems, </title> <journal> IEEE TOC 39,3 (March 1990), </journal> <pages> 319-327. </pages>
Reference-contexts: The third approach is probabilistic mean value analysis. This type of analysis has been applied with success to banyan networks and their equivalents [Jen83] <ref> [YLL90] </ref> [KiL90] and to direct binary n-cubes [AbP89]. In [Jen83], Jenq presents an analytical model for the performance of Banyan (Omega) networks composed of 2-input, 2-output switching elements in a synchronous, single buffered, packet-switching system. This model forms the basis for later work by Yoon et. al. [YLL90], which extends the <p> their equivalents [Jen83] <ref> [YLL90] </ref> [KiL90] and to direct binary n-cubes [AbP89]. In [Jen83], Jenq presents an analytical model for the performance of Banyan (Omega) networks composed of 2-input, 2-output switching elements in a synchronous, single buffered, packet-switching system. This model forms the basis for later work by Yoon et. al. [YLL90], which extends the model both to n-input, n-output switching elements and to multi-buffering of packets, and others. In [KiL90], the authors apply the probabilistic technique to non-uniform traffic patterns.
Reference: [YoL89] <author> H. Yoon and K. Lee, </author> <title> B-Banyan and B-Delta Networks for Multiprocessor Systems, </title> <journal> Journal of Parallel and Distributed Computing 7 (1989), </journal> <pages> 570-582. 226 </pages>
Reference-contexts: Analytical studies have also considered the bandwidth, or number of requests accepted (by the network) per cycle, of several types of both unbuffered and single-buffered shufe-exchange networks [Pat81] [YLL87]. Other performance analyses have been conducted for fault-tolerant versions of these types of networks [KuR85] <ref> [YoL89] </ref>. Finally, performance studies have been presented for combining systems [Lee86] [Won86]. These studies report performance measures for combining systems in normal operation, where a random distribution of requests is assumed, and in cases of hot spots [Pfi85], situations in which more requests are targeted for certain outputs.
Reference: [YYF85] <author> W. C. Yen, D. W. L. Yen and K. Fu, </author> <title> Data Coherence Problem in a Multicache System, </title> <journal> IEEE Transactions on Computers C-34,1 (January 1985), </journal> <pages> 56-65. </pages>
References-found: 88

