URL: http://www.cs.wisc.edu/~fischer/ftp/pub/tech-reports/reports/98/tr1364.ps.Z
Refering-URL: http://www.cs.wisc.edu/~fischer/ftp/pub/tech-reports/reports/98/
Root-URL: http://www.cs.wisc.edu
Email: fjussara,dabu,manikuti,caog@cs.wisc.edu  
Title: Providing Differentiated Levels of Service in Web Content Hosting  
Author: Jussara Almeida Mihaela Dabu Anand Manikutty Pei Cao 
Affiliation: Computer Sciences Department University of Wisconsin-Madison  
Abstract: Web content hosting, in which a Web server stores and provides Web access to documents for different customers, is becoming increasingly common. Due to the variety of customers (corporate, individuals, etc.), providing differentiated levels of service is often an important issue for the hosts. Most server implementations, however, are not structured to service requests based on different levels of quality of service (QoS). This paper presents our attempts at augmenting a popular server implementation with differentiated QoS features. We explore priority-based request scheduling at both user and kernel levels. We find that simple strategies such as controlling the numbers of processes can improve the response time of high-priority requests notably while preserving the system throughput. We also find that the kernel-level approach tends to penalize low-priority requests less significantly than the user-level approach, while improving the performance of high-priority requests similarly. Based on our experiments, we discuss the bottlenecks and limitations from kernel implementations that prevent the augmented server from achieving better performance.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Trent, G. & Sake, M. WebSTONE: </author> <title> The First Generation in HTTP Server Benchmarking, </title> <month> February </month> <year> 1995. </year> <note> URL: http://www.sgi.com/Products/WebFORCE/WebStone. </note>
Reference-contexts: Our Apache server was configured to run in standalone mode. The KeepAlive option was deactivated (only one HTTP request was serviced per connection) and all other parameters are set as the default values. To generate a WWW workload, we used WebStone <ref> [1] </ref> (version 2.0.0), an industry-standard benchmark for generating HTTP requests. WebStone is a configurable client-server benchmark that uses workload parameters and client processes to generate Web requests. This allows a server to be evaluated in a number of different ways.
Reference: [2] <author> Arlitt, M. and Williamson, C., </author> <title> Web Server Workload Characterization, </title> <booktitle> Proceedings of the 1996 SIGMETRICS Conference on Measurement and Modeling of Computer Systems, </booktitle> <month> May </month> <year> 1996. </year>
Reference-contexts: In our experiments, we set the number of client processes as 30 and used two different workloads, described in Table 1. The parameters that define workload WB are representative of the kinds of workload typically found in busy WWW servers <ref> [2] </ref>. 5 Results This section discusses the results obtained for both user and kernel level approaches. Recall that the performance metric is the average latency of a request as perceived by the server.
Reference: [3] <author> Robinnson, D. </author> <title> and the Apache Group, APACHE An HTTP Server, Reference Manual, </title> <note> 1995. URL: http://www.apache.org. </note>
Reference-contexts: However, most Web servers today do not provide support for differentiated quality of service. To do so would require the incoming requests be classified into different categories and different levels of service be applied to each category. Apache <ref> [3] </ref>, one of the most used Web servers, handles incoming requests in a first-come first-served manner. All the requests correctly received are eventually handled, regardless of the type of requests and the load on the system. <p> For the kernel-level approach, we used the Linux 2.1.54 operating system on a DEC Celebris XL590 90MHz Pentium machine with 32 MB of main memory. The server software for both setups was Apache, version 1.3b2, a public domain HTTP server <ref> [3] </ref>. Our Apache server was configured to run in standalone mode. The KeepAlive option was deactivated (only one HTTP request was serviced per connection) and all other parameters are set as the default values.
Reference: [4] <author> Beck, M., Bohme, H., Dziadzka, M., Kunitz, U., Magnus, R. and Verworner, D., </author> <title> Linux Kernel Internals, </title> <publisher> Addison-Wesley, </publisher> <year> 1996. </year>
Reference-contexts: In the user-level approach, Apache was modified to include a scheduler process, responsible for deciding the order in which the requests should be handled. The scheduler restricts the maximum number of concurrent processes servicing requests of each priority. In the kernel-level approach, the Linux kernel code <ref> [4] </ref> was instrumented, and request priorities were mapped into priorities assigned to the HTTP processes handling them. Using the Webstone benchmark suite, we measure the effect of the approaches on request latency.
Reference: [5] <author> Mogul, J., </author> <title> Network Behavior of a Busy Web Server and its Clients, </title> <type> Research Report 95/5, </type> <institution> DEC Western Research Laboratory, </institution> <month> October </month> <year> 1995 </year>
Reference-contexts: 1 Introduction Due to the explosive growth of the Web and the ever-increasing resource demands on the servers <ref> [5, 6, 7] </ref>, Web content hosting is an increasingly common practice.
Reference: [6] <author> Mogul, J., </author> <title> Operating System Support for Busy Internet Servers, </title> <booktitle> Proceedings of the Fifth Workshop on Hot Topics in Operating Systems, </booktitle> <month> May </month> <year> 1995. </year>
Reference-contexts: 1 Introduction Due to the explosive growth of the Web and the ever-increasing resource demands on the servers <ref> [5, 6, 7] </ref>, Web content hosting is an increasingly common practice.
Reference: [7] <institution> Internet Domain Survey, Network Wizards, </institution> <month> January, </month> <year> 1997. </year> <note> URL: http://www.nw.cm/zone/summary-reports/report-9701.doc. </note>
Reference-contexts: 1 Introduction Due to the explosive growth of the Web and the ever-increasing resource demands on the servers <ref> [5, 6, 7] </ref>, Web content hosting is an increasingly common practice.
Reference: [8] <author> Banatre, M., Issamy, V., Leleu F. and Charpiot B., </author> <title> Providing Quality of Service over the Web: A Newspaper-based Approach, </title> <booktitle> Proceedings of the Sixth International World Wide Web Conference, </booktitle> <address> California, </address> <month> April, </month> <year> 1997. </year>
Reference-contexts: Here, we focus on the end systems, and investigate issues such as process scheduling and OS resource scheduling that are not typically addressed in the networking QoS studies. Previous works have addressed the general problem of quality of service by using different techniques such as data prefetching <ref> [8] </ref> and image compression [10]. Other approaches [12, 11] address the problem in the context of a distributed web server. In [12], the authors developed a system that implements fast packet interposing that can be used to balance the load across a cluster of servers.
Reference: [9] <author> Crovella, M., and Bestavros, A., </author> <title> Self-similarity in World Wide Web Traffic: Evidence and Possible Causes, </title> <booktitle> Proceedings of the 1996 SIGMETRICS Conference on Measurement and Modeling of Computer Systems, </booktitle> <month> May </month> <year> 1996. </year>
Reference: [10] <author> Fox, A., and Brewer, E., </author> <title> Reducing WWW Latency and Bandwidth Requirements by Real-Time Distillation, </title> <booktitle> Proceedings of the Fifth International World Wide Web Conference, </booktitle> <address> Paris, France, </address> <month> May, </month> <year> 1996. </year>
Reference-contexts: Previous works have addressed the general problem of quality of service by using different techniques such as data prefetching [8] and image compression <ref> [10] </ref>. Other approaches [12, 11] address the problem in the context of a distributed web server. In [12], the authors developed a system that implements fast packet interposing that can be used to balance the load across a cluster of servers.
Reference: [11] <author> Damani, O., Chung, P., Huang, Y., Kintala, C., Wang, Y., ONE-IP: </author> <title> Techniques for Hosting a Service on a Cluster of Machines, </title> <booktitle> 6th International World Wide Web Conference, </booktitle> <month> April </month> <year> 1997. </year>
Reference-contexts: Previous works have addressed the general problem of quality of service by using different techniques such as data prefetching [8] and image compression [10]. Other approaches <ref> [12, 11] </ref> address the problem in the context of a distributed web server. In [12], the authors developed a system that implements fast packet interposing that can be used to balance the load across a cluster of servers. <p> Other approaches [12, 11] address the problem in the context of a distributed web server. In [12], the authors developed a system that implements fast packet interposing that can be used to balance the load across a cluster of servers. In <ref> [11] </ref>, the authors address the problem of load balancing in a cluster of servers by using secondary IP addresses.
Reference: [12] <author> Anderson, E., Patterson, D., Brewer E., </author> <title> The Magicrouter, an Application of Fast Packet Interposing, </title> <booktitle> Second Symposium on Operating Systems Design and Implementation, </booktitle> <month> May, </month> <year> 1996. </year>
Reference-contexts: Previous works have addressed the general problem of quality of service by using different techniques such as data prefetching [8] and image compression [10]. Other approaches <ref> [12, 11] </ref> address the problem in the context of a distributed web server. In [12], the authors developed a system that implements fast packet interposing that can be used to balance the load across a cluster of servers. <p> Previous works have addressed the general problem of quality of service by using different techniques such as data prefetching [8] and image compression [10]. Other approaches [12, 11] address the problem in the context of a distributed web server. In <ref> [12] </ref>, the authors developed a system that implements fast packet interposing that can be used to balance the load across a cluster of servers. In [11], the authors address the problem of load balancing in a cluster of servers by using secondary IP addresses.
References-found: 12

