URL: ftp://ftp.cse.ucsc.edu/pub/reinas/craig/vol2col.ps.Z
Refering-URL: http://www.cse.ucsc.edu/~craig/craig_pdr.html
Root-URL: http://www.cse.ucsc.edu
Email: e-mail: craig@shasta.ee.washington.edu mikeh@apl.washington.edu  
Title: A Scalable MIMD Volume Rendering Algorithm  
Author: Craig M. Wittenbrink Michael Harrington 
Keyword: Parallel Algorithms, Object Space Partitioning, Permutation Warping.  
Address: Seattle, WA 98195 Seattle, WA 98105  
Affiliation: Dept. of Electrical Engineering, Applied Physics Laboratory University of Washington University of Washington  
Abstract: Volume rendering is a compute intensive graphics algorithm with wide application. Researchers have sought to speed it up using parallel computers. Our new algorithm distributes the data for storage efficiency, avoids bottlenecks, and scales to more processors than rays. The main contribution is explicit partitioning of the input volume for higher memory utilization, while retaining viewpoint freedom and speedup. The largest volumes processed on our MIMD (multiple instruction multiple data) machine (Proteus) are 512x512x128 voxels (32 Mbytes). Performance measurements show a speedup of 22 over our sequential code on 32 Intel i860 processors. We have used no preprocessing or data dependent optimization. The efficiency results from nonconicting communication, a permutation warp, that remains efficient with larger data sets, larger parallel machines, and high order filters showing scalability can be achieved through object space partitioning. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. Bajura et al., </author> <title> Merging Virtual Objects with the Real World: Seeing Ultrasound Imagery within the Patient, </title> <journal> Computer Graphics, </journal> <volume> Vol. 26, No. 2, </volume> <pages> pp. 203-210, </pages> <month> Aug. </month> <year> 1992. </year>
Reference-contexts: And a significant advantage of this algorithm over those using hierarchical data structures is the elimination of a costly preprocessing step which increases the latency of data collection to visualization. Lower latency is essential in interactive applications such as virtual real visualization <ref> [1] </ref>. Processors can composite spatial neighbors sub-frames in object space, but because spatial neighbors change with view direction, communication congestion may result. Instead, a permutation of communication is used, and then compositing is more efficient in the aligned dimensions of the machine, the screen space.
Reference: [2] <editor> J. Foley et al., </editor> <booktitle> Computer Graphics Principles and Practice, Second Edition. </booktitle> <address> Reading, MA: </address> <publisher> Addison Wesley, </publisher> <year> 1990. </year>
Reference-contexts: 1 Introduction Volume rendering <ref> [2] </ref> is transparency visualization of sampled 3D data. Inputs are point samples, or volume elements called voxels. A variety of applications create voxels such as magnetic resonance imaging and finite element analysis. <p> Most applications are calculation intensive because of the size of the data sets (up to one billion voxels), and even the simplest calculations on workstations take too much time for interactive visualization. Volume rendering is described fully elsewhere <ref> [2] </ref>. Parallelism is difficult to use because partitioning may result in lower quality (See [12] for filter comparison), or large memory requirements [13] (and [8] where shared memory requires large caches and high cache overhead). We have developed a practical solution that does not sacrifice quality or memory. <p> FIGURE 4 shows the parallel volume rendering algorithm with resampling and product calculations. Voxels are viewed from an arbitrary viewpoint (Eye). For each pixel, resampling occurs along the rays, then the samples are combined by a product (any associative operator) evaluation, . Product includes compositing <ref> [2] </ref> (used for volume rendering in [2]), maximum intensity [4], numerical integration, etc. FIGURE 4 also shows the parallel data ow of Vol-ume_Render in FIGURE 1 from Steps 1 through 4 for 16 processors. Each processor preprocesses its locally assigned subvolume in Step 1. <p> Voxels are viewed from an arbitrary viewpoint (Eye). For each pixel, resampling occurs along the rays, then the samples are combined by a product (any associative operator) evaluation, . Product includes compositing <ref> [2] </ref> (used for volume rendering in [2]), maximum intensity [4], numerical integration, etc. FIGURE 4 also shows the parallel data ow of Vol-ume_Render in FIGURE 1 from Steps 1 through 4 for 16 processors. Each processor preprocesses its locally assigned subvolume in Step 1.
Reference: [3] <editor> C.P. Kruskal et al., </editor> <title> The Power of Parallel Prefix, </title> <booktitle> in Proceedings IEEE International Conference on Parallel Processing, </booktitle> <year> 1985, </year> <pages> pp. 180-185. </pages>
Reference-contexts: In order to avoid idling of processors, every processor remains busy through this stage by binary tree compositing the frames. The algorithm calculates compositing through a parallel product evaluation. A parallel product evaluation <ref> [3] </ref>, is work efficient up to , where is the number of processors and is the number of voxels. A slight variation from the usual parallel product is used because of the higher dimensionality.
Reference: [4] <author> G. Laub, </author> <title> Displays for MR Angiography, </title> <journal> Magnetic Resonance in Medicine, </journal> <volume> Vol. 14, </volume> <pages> pp. 222-229, </pages> <year> 1990. </year>
Reference-contexts: Voxels are viewed from an arbitrary viewpoint (Eye). For each pixel, resampling occurs along the rays, then the samples are combined by a product (any associative operator) evaluation, . Product includes compositing [2] (used for volume rendering in [2]), maximum intensity <ref> [4] </ref>, numerical integration, etc. FIGURE 4 also shows the parallel data ow of Vol-ume_Render in FIGURE 1 from Steps 1 through 4 for 16 processors. Each processor preprocesses its locally assigned subvolume in Step 1. The subvolume is assigned through a static object space partitioning of the volume. <p> Max intensity ray combining is used, and different shading is possible with the same filters. As mentioned earlier any associative (not commutative) operator can be calculated by a parallel product operation including compositing. Compositing was not used because it is inappropriate for the MR angiography application <ref> [4] </ref>. MR angiography images were used after being window and leveled to eight bits/voxel. Images created were eight bits/pixel. All measurements were taken using multiple runs of the code, and averaging. FIGURE 5 displays example outputs of blood vessels in the window on the lower left.
Reference: [5] <author> K. L. Ma and J. Painter, </author> <title> A Data Distributed Parallel Algorithm for Ray-Traced Volume Rendering, in Visualization 93, </title> <booktitle> Parallel Rendering Symposium, </booktitle> <month> Oct. </month> <pages> 25-26, </pages> <year> 1993. </year>
Reference-contexts: The approach of sending large messages, using object space partitioning, and evaluating compositing by parallel product is new for a MIMD volume rendering algorithm. Paper reviewers have also made us aware of recent results of others using large messages <ref> [5] </ref>, object space partitioning [5][7], and parallel compositing [5][6]. Our approach uses an innovative resampling step without communication congestion that scales in input and machine size. The resampling is performed by permutation warping.
Reference: [6] <author> Mackerras, </author> <title> A Fast Parallel Marching Cubes Implementation on the Fujitsu AP1000, </title> <type> Tech. Rep. </type> <institution> TR-CS-92-10, Dept. of Comp. Science, Australian National Univ., </institution> <year> 1992. </year> <title> TABLE 2 Proteus Run Times, </title> <booktitle> all output images are 256x256, </booktitle> <volume> Milliseconds vol size 32 PEs Tril 32 PEs Zoh 1PE tril 1 PE Zoh 32 3 161 150 241 97 128 3 1046 498 13846 3870 </volume>
Reference: [7] <author> U. Neumann, </author> <title> Volume Reconstruction and Parallel Ren--dering Algorithms: A Comparative Analysis, </title> <type> Ph.D. Dissertation, </type> <institution> UNC, Chapel Hill, </institution> <year> 1993. </year>
Reference: [8] <author> J. Nieh and M. Levoy, </author> <title> Volume Rendering on Scalable Shared-Memory MIMD Architectures, </title> <booktitle> in Proceedings of 1992 Workshop on Volume Visualization, </booktitle> <address> Boston, </address> <month> Oct. </month> <pages> 19-20, </pages> <year> 1992, </year> <pages> pp. 17-24. </pages>
Reference-contexts: Volume rendering is described fully elsewhere [2]. Parallelism is difficult to use because partitioning may result in lower quality (See [12] for filter comparison), or large memory requirements [13] (and <ref> [8] </ref> where shared memory requires large caches and high cache overhead). We have developed a practical solution that does not sacrifice quality or memory. <p> The performance in millions of voxels per second ranges from three to 12. This compares to the 23.30 TABLE 1 Proteus Speedup for 32 Processors Volume Size Trilinear Zoh 64 3 6.05 2.73 256 3 22.03 17.38 'O S ( ) S RW= R Mvoxels/second of <ref> [8] </ref> and 21.18 Mvoxels/second of [10]. 5 Conclusions We presented a parallel volume rendering algorithm that uses exclusive reads and writes for data locality. We illustrated that only a general interconnection network is needed, and then demonstrated measured performance on our parallel machine, Proteus.
Reference: [9] <editor> A. K. Somani et al., </editor> <booktitle> Proteus System Architecture & Organization, in Fifth International Parallel Processing Symposium, </booktitle> <address> Anaheim CA, </address> <month> April 30 - May 2, </month> <year> 1991, </year> <pages> pp. 276-284. </pages>
Reference-contexts: We have developed a practical solution that does not sacrifice quality or memory. In this paper we discuss the performance attained on the Proteus Supercomputer <ref> [9] </ref> and how to maintain full parallelism on scalable MIMD (multiple instruction multiple data) machines. <p> software development environment, and existing methods for parallel volume rendering. 2 MIMD Volume Rendering Algorithm In data parallel machines such as the CM-2 and Mas-Par MP-1, our preferred solution is a one step warping phase to align to the view direction [11][12], but in high granularity machines such as Proteus <ref> [9] </ref> small messages create network congestion. Instead we use an algorithm that takes advantage of the high virtualization ratio and sends large messages. The approach of sending large messages, using object space partitioning, and evaluating compositing by parallel product is new for a MIMD volume rendering algorithm. <p> Proteus is a scalable MIMD (multiple instruction multiple data) parallel computer <ref> [9] </ref>. The machine, shown in FIGURE 2, has from 32 to 1024 processors. A prototype group with 32 Intel i860s has been implemented.
Reference: [10] <author> D. Stredney et al., </author> <title> Supercomputer Assisted Brain Visualization with an Extended Ray Tracer, </title> <booktitle> in Proceedings of 1992 Workshop on Volume Visualization, </booktitle> <address> Boston, </address> <month> Oct. </month> <pages> 19-20, </pages> <year> 1992, </year> <pages> pp. 33-38. </pages>
Reference-contexts: This compares to the 23.30 TABLE 1 Proteus Speedup for 32 Processors Volume Size Trilinear Zoh 64 3 6.05 2.73 256 3 22.03 17.38 'O S ( ) S RW= R Mvoxels/second of [8] and 21.18 Mvoxels/second of <ref> [10] </ref>. 5 Conclusions We presented a parallel volume rendering algorithm that uses exclusive reads and writes for data locality. We illustrated that only a general interconnection network is needed, and then demonstrated measured performance on our parallel machine, Proteus. The paper showed an algorithm technique and a practical result.
Reference: [11] <author> C. M. Wittenbrink and A. K. Somani, </author> <title> 2D and 3D optimal parallel image warping, </title> <booktitle> in Seventh International Parallel Processing Symposium, </booktitle> <address> Newport Beach, CA, </address> <pages> pp. 331-337, </pages> <month> April 13-16, </month> <year> 1993. </year>
Reference: [12] <author> C. M. Wittenbrink and A. K. Somani, </author> <title> Permutation Warping for Data Parallel Volume Rendering, in Visualization 93, </title> <booktitle> Parallel Rendering Symposium, </booktitle> <address> San Jose, CA, </address> <pages> pp. 57-60, </pages> <editor> color plate p. </editor> <volume> 110, </volume> <month> Oct. </month> <pages> 25-26, </pages> <year> 1993. </year>
Reference-contexts: Volume rendering is described fully elsewhere [2]. Parallelism is difficult to use because partitioning may result in lower quality (See <ref> [12] </ref> for filter comparison), or large memory requirements [13] (and [8] where shared memory requires large caches and high cache overhead). We have developed a practical solution that does not sacrifice quality or memory. <p> Two different reconstruction filters are used, a first order hold (trilinear interpolation) and a zero order hold (nearest neighbor). We refer the reader to <ref> [12] </ref> which compares zero order holds, first order holds, and multipass shearing. Direct warps support high order filters more effectively. Max intensity ray combining is used, and different shading is possible with the same filters.
Reference: [13] <author> S. Yoo et al., </author> <title> Achieving Direct Volume Visualization with Interactive Semantic Region Selection, </title> <booktitle> in Proceedings IEEE Visualization 91, </booktitle> <address> San Diego, CA, </address> <month> Oct. </month> <pages> 22-25, </pages> <year> 1991, </year> <pages> pp. </pages> <month> 58-65. </month> <title> FIGURE 4 Parallel Algorithm Flow: Object Space to Resampled View Volume to Final Image FIGURE 5 Proteus Graphical User Interface 1 z 1 3 5 11 13 15 Overlapped 1 0 4 7 7 3 SubVolumes SubFrames Parallel Product Final Image 15 4 Aligned View Volume 0 2 0 11 10 3 2 7 6 11 10 15 14 3 2 Virtualization Cubes View Rounds of Step 3 Step 2 Step 4 Permutations </title>
Reference-contexts: Volume rendering is described fully elsewhere [2]. Parallelism is difficult to use because partitioning may result in lower quality (See [12] for filter comparison), or large memory requirements <ref> [13] </ref> (and [8] where shared memory requires large caches and high cache overhead). We have developed a practical solution that does not sacrifice quality or memory.
References-found: 13

