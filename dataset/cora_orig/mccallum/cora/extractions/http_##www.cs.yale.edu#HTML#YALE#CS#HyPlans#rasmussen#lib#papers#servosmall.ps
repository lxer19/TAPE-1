URL: http://www.cs.yale.edu/HTML/YALE/CS/HyPlans/rasmussen/lib/papers/servosmall.ps
Refering-URL: http://www.cs.yale.edu/HTML/YALE/CS/AI/VisionRobotics/YaleMobile.html
Root-URL: http://www.cs.yale.edu
Title: Visual Servoing  
Author: Christopher Rasmussen 
Date: April 27, 1995  
Affiliation: Final Project for Computer Science 576 Vision  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> F. Chaumette, P. Rives, and B. Espian. </author> <title> Positioning of a Robot with respect to an Object, Tracking it, and Estimating its Velocity by Visual Servoing. </title> <booktitle> In Proceedings of the IEEE International Conference on Robotics and Automation, </booktitle> <address> Sacramento, CA, </address> <month> April, </month> <year> 1991, </year> <pages> pp. 2248-2253. </pages>
Reference-contexts: 1 Introduction This project is essentially an implementation of a technique called visual ser-voing, as described in <ref> [1] </ref>. The idea is to home in on a scene feature or object in three-dimensional space using its image location and knowledge of how 3-D motions give rise to 2-D image changes in a feedback loop.
Reference: [2] <author> G. Hager. </author> <title> The "X-Vision" System: A General-Purpose Substrate for Vision-Based Robotics. </title> <booktitle> Submitted to Workshop on Vision for Robotics, </booktitle> <year> 1995. </year>
Reference-contexts: These are the corners of a square centered at the center of the image. To keep track of the features, we used the SSD tracking package of the X-Vision system described in <ref> [2] </ref>. The features (corners of a square) that made up s were initialized by the user by pointing and clicking on a 640 x 480 pixel video display. In other words, the user was responsible for locating the square in the robot field of view and appropriately indicating its corners.
Reference: [3] <author> B. K. Horn. </author> <title> Robot Vision. </title> <publisher> MIT Press, </publisher> <address> Cambridge, </address> <year> 1986. </year> <month> 3 </month>
Reference-contexts: We assume perspective projection (x = X=Z, y = Y =Z, where x and y are image coordinates and X, Y , and Z are global coordinates), leading to the familiar equation from optical flow described in <ref> [3] </ref>: _y = 1=Z 0 x=Z xy 1 x 2 y By appropriately substituting the x and y portions of s where x and y appear in (2), we get J, as will be seen in the next section. 3 Implementation We chose s fl = (a; a; a; a; a;
References-found: 3

