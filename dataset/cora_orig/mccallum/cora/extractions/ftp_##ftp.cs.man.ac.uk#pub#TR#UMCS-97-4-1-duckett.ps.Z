URL: ftp://ftp.cs.man.ac.uk/pub/TR/UMCS-97-4-1-duckett.ps.Z
Refering-URL: http://www.cs.man.ac.uk/robotics/lopapers.html
Root-URL: 
Email: t.duckett@cs.man.ac.uk, u.nehmzow@cs.man.ac.uk  
Title: Experiments in Evidence Based Localisation for a Mobile Robot  
Author: Tom Duckett and Ulrich Nehmzow 
Date: 7/4/97  
Address: Oxford Road, Manchester M13 9PL, England.  
Affiliation: Department of Computer Science, University of Manchester  
Abstract: This paper addresses the problem of localisation in autonomous mobile robot navigation, i.e., the task of identifying places after prior exploration and mapbuilding by the robot. In particular, the work is concerned with the more general problem of relocalisation without using past experience (i.e., knowing roughly where you are to start with), referred to here as the lost robot problem. In the experiments presented here, the robot had to relocalise after being moved to a randomly chosen location, its sensors being disabled during that move. The robot therefore had no a priori knowledge of its position, and had to use current sensory perceptions and map knowledge alone to relocalise. A perception-based localisation method is presented which is resilient to the problem of perceptual aliasing (i.e., perceptual identity of distinct locations), and is capable of relocalising even in environments where no single place has a unique perceptual signature. During an exploration phase, the robot builds a map of its environment, using a self-organising neural network to cluster its perceptual space. The robot is then moved to an arbitrary location, where it will attempt to relocalise. By actively exploring, and accumulating evidence through the use of relative odometry between competing place memories, the robot is able to establish its location with respect to perceptual landmarks very quickly.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> G. Carpenter and S. Grossberg, "ART2: </author> <title> Self-Organization of Stable Category Recognition Codes for Analog Input Patterns", </title> <journal> Applied Optics, </journal> <volume> Vol. 26, No. 23, </volume> <pages> pp. 4919-4930, </pages> <year> 1987. </year>
Reference-contexts: In order to deal with sensor noise, the robot should be capable of generalising to extract the most important features in a given situation without being distracted by the finer detail of individual sensor images. In these experiments, the self-organising neural network architecture ART2 <ref> [1] </ref> was used to cluster the robot's sonar and infrared sensor readings. This also helps to avoid the "correspondence problem" of matching specific environmental features against a detailed world model.
Reference: [2] <author> T. Duckett and U. Nehmzow, </author> <title> "A Robust, Perception-Based Localisation Method for a Mobile Robot", </title> <institution> Dept. Computer Science, University of Manchester, </institution> <type> Technical Report Series UMCS-96-11-1, </type> <year> 1996. </year>
Reference-contexts: The ART network is effectively used as a "black box" for classifying the robot's sensory input, and various other classification paradigms could also be used, e.g., Kohonen self-organising feature map [4]. (See <ref> [2] </ref> for a full discussion of the motivations for using ART.) dependencies between different parts of the system. The shaded box denotes the representation used for the map, and the dashed boxes show hardware components.
Reference: [3] <author> A. Kurz, </author> <title> "Constructing Maps for Mobile Robot Navigation Based on Ultrasonic Range Data", </title> <journal> IEEE Trans. Systems, Man, and Cybernetics Part B: Cybernetics, </journal> <volume> Vol. 26, No. 2, </volume> <month> April </month> <year> 1996. </year>
Reference-contexts: Some authors combine proprioception and exteroception, relying on global odometry corrected by sightings on known environmental features. For example, Kurz <ref> [3] </ref> uses a self-organising neural network to cluster the robot's sensor readings, associating each cluster with an (x; y) coordinate obtained by dead reckoning. <p> This is similar to the mapbuilding mechanism described by Kurz <ref> [3] </ref>, where the robot's (x; y) coordinates are averaged as the robot moves through a particular "situation area", i.e., an area of physical space associated with a particular classifier category.
Reference: [4] <author> U. Nehmzow, T. Smithers and J. Hallam, </author> <title> "Location Recognition in a Mobile Robot Using Self-Organising Feature Maps", </title> <editor> in G. Schmidt (ed.), </editor> <booktitle> "Information Processing in Autonomous Mobile Robots", </booktitle> <publisher> Springer Verlag, </publisher> <year> 1991. </year>
Reference-contexts: Another exteroception-based approach attempts to deal with perceptual ambiguity by incorporating history of local sensor sequences into the recognition of locations. The basic idea is to uniquely identify places by adding context information to their perceptual signatures. Nehmzow et al <ref> [4] </ref> combine past and present sensorimotor experience of the robot in the input to a self-organising feature map. Similarly, Tani and Fukumara [7] add previous sensor patterns to the input field of a neural network controller. <p> This also helps to avoid the "correspondence problem" of matching specific environmental features against a detailed world model. The ART network is effectively used as a "black box" for classifying the robot's sensory input, and various other classification paradigms could also be used, e.g., Kohonen self-organising feature map <ref> [4] </ref>. (See [2] for a full discussion of the motivations for using ART.) dependencies between different parts of the system. The shaded box denotes the representation used for the map, and the dashed boxes show hardware components. <p> This showed the same level of performance as before, demonstrating the ability to relocalise independently of a fixed temporal sequence of landmarks as in previous work, e.g., <ref> [4] </ref>.
Reference: [5] <author> U. Nehmzow, </author> <title> "Autonomous Acquisition of Sensor-Motor Couplings in Robots", </title> <institution> Dept. Computer Science, University of Manchester, </institution> <type> Technical Report Series UMCS-94-11-1, </type> <year> 1994. </year>
Reference-contexts: During both mapbuilding and relocalisation, the robot explores its environment using a reactive behaviour previously acquired using instinct rules <ref> [5] </ref>. In the experiments presented here, either wall-following or random wandering behaviours were used for exploration. The robot begins by building a map of its environment, using a self-organising classifier to cluster its exteroceptive sensor readings. <p> The shaded box denotes the representation used for the map, and the dashed boxes show hardware components. In previous work (e.g., <ref> [5] </ref>), the rotational and turret motors of the Nomad 200 robot have been controlled in unison, so that the sensors always point in the same direction relative to the heading of the robot. <p> ART network will trigger an extra iteration through the localisation algorithm, plus another one when the correct category is perceived once more. 5.2 Random Wandering A further set of simulations involved exploring another enclosed environment (see figure 8) using a random wandering behaviour based on smooth, continuous obstacle avoidance (see <ref> [5] </ref> for details) instead of wall-following. Sonar was used for input to the ART network rather than infrared, as much of the space away from the walls of the enclosure contained no features discernible by infrared.
Reference: [6] <author> U. Nehmzow, </author> <title> "Animal and Robot Navigation", </title> <booktitle> Robotics and Autonomous Systems, </booktitle> <volume> Vol. 15, No. 1 - 2, </volume> <pages> pp. 71-81, </pages> <year> 1995. </year>
Reference-contexts: Furthermore, a map constructed from a single tour of the environment can contain all of the information needed by the lost robot to relocalise using the same exploration strategy. (See <ref> [6] </ref> on the use of canonical paths in animal and robot navigation.) 6 Summary A complete robot mapbuilding and localisation system has been presented which can localise even in environments where no single place has a unique perceptual signature, both on a robot and using a simulator.
Reference: [7] <author> J. Tani and N. Fukumara, </author> <title> "Learning Goal-Directed Sensory-Based Navigation of a Mobile Robot", </title> <booktitle> Neural Networks, </booktitle> <volume> Vol. 7, No. 3, </volume> <pages> pp. 553-563, </pages> <year> 1994. </year>
Reference-contexts: The basic idea is to uniquely identify places by adding context information to their perceptual signatures. Nehmzow et al [4] combine past and present sensorimotor experience of the robot in the input to a self-organising feature map. Similarly, Tani and Fukumara <ref> [7] </ref> add previous sensor patterns to the input field of a neural network controller. A disadvantage of this approach is that the identical set of previously stored locations must be revisited turret. In these experiments, the turret was kept at a constant orientation to provide a "compass sense".
Reference: [8] <author> B. Yamauchi and P. Langley, </author> <title> "Place Recognition in Dynamic Environments", </title> <note> to appear in Journal of Robotics Systems, Special Issue on Mobile Robots, </note> <year> 1996. </year>
Reference-contexts: Another approach attempts to uniquely identify distinct places without proprioception, using more and more sensory information from the robot's exteroceptors to disambiguate similar looking places. For example, Yamauchi and Langley <ref> [8] </ref> rotate the turret of a stationary robot equipped with range sensors to construct a detailed grid model of the robot's immediate environment, effectively increasing the robot's perceptual resolution by a factor of s, where s is the number of rotational steps used to build the grid model.
Reference: [9] <author> U. R. Zimmer, </author> <title> "Self-Localization in Dynamic Environments", </title> <booktitle> IEEE/SOFT International Workshop BIES'95, </booktitle> <address> Tokyo, Japan, </address> <month> May 30-31 </month> <year> 1995. </year>
Reference-contexts: This system will fail however if two or more places share the same perceptual category, as a lost robot would be unable to distinguish between such places without prior knowledge of its approximate position. In a different approach, Zimmer <ref> [9] </ref> combines position information from odometry with the corresponding sensor readings in the input vector to a continuously adaptable mapbuilding and localisation system. However, localisation may fail if reasonably accurate odometer information becomes unavailable and several stored sensor situations match the current sensor data. <p> We are therefore currently investigating the use of lifelong learning, where the map would be continuously updated on the basis of new perceptions, as in Zimmer <ref> [9] </ref>. The mapbuilding scheme, as it currently stands, is dependent on a global reference frame, and would be negatively affected by odometry errors. We are therefore also investigating the use of continuous relocalisation during mapbuilding to compensate for drift errors.
References-found: 9

