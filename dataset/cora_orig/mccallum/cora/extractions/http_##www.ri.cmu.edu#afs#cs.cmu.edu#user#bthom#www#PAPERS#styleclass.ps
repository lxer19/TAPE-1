URL: http://www.ri.cmu.edu/afs/cs.cmu.edu/user/bthom/www/PAPERS/styleclass.ps
Refering-URL: http://www.ri.cmu.edu/afs/cs.cmu.edu/user/bthom/www/index.html
Root-URL: 
Email: frbd,bthom,dwatsong@cs.cmu.edu  
Title: A Machine Learning Approach to Musical Style Recognition  
Author: Roger B. Dannenberg, Belinda Thom, and David Watson 
Affiliation: School of Computer Science, Carnegie Mellon University  
Abstract: Much of the work on perception and understanding of music by computers has focused on low-level perceptual features such as pitch and tempo. Our work demonstrates that machine learning can be used to build effective style classifiers for interactive performance systems. We also present an analysis explaining why these techniques work so well when hand-coded approaches have consistently failed. We also describe a reliable real-time performance style classifier. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Bishop, C. M. </author> <title> Neural Networks for Pattern Recognition. </title> <publisher> Clarendon Press, </publisher> <year> 1995. </year>
Reference-contexts: Duty factor means the ratio of duration to inter-onset interval.) 3.1 Bayesian Classifier The naive Bayesian classifier <ref> [1] </ref> assumes that the features are uncorrelated and normally distributed. (Neither of these is true, but this approach works well anyway.) Given a vector of features, F , we would like to know which classification C is most likely. <p> Depending on the features, this division may or may not be very successful. 3.3 Neural Networks Of the three approaches we tried, neural networks are the most powerful because they incorporate nonlinear terms and they do not make strong assumptions about the feature probability distributions. <ref> [1] </ref> We used a Cascade-Correlation architecture [2] which consists initially of only input and output units Number of Bayesian Linear Neural Classes Network 4 98.1 99.4 98.5 Table 1: Percentage of correct classifications by different classifiers. (equivalent to a linear classifier).
Reference: [2] <author> Fahlman, S. E., and Lebiere, C. </author> <title> The Cascade-Correlation learning architecture. </title> <type> Tech. Rep. </type> <institution> CMU-CS-90-100, School of Computer Science, Carnegie Mellon University, </institution> <address> Pittsburgh, PA, </address> <month> Feb. </month> <year> 1990. </year>
Reference-contexts: on the features, this division may or may not be very successful. 3.3 Neural Networks Of the three approaches we tried, neural networks are the most powerful because they incorporate nonlinear terms and they do not make strong assumptions about the feature probability distributions. [1] We used a Cascade-Correlation architecture <ref> [2] </ref> which consists initially of only input and output units Number of Bayesian Linear Neural Classes Network 4 98.1 99.4 98.5 Table 1: Percentage of correct classifications by different classifiers. (equivalent to a linear classifier).
Reference: [3] <author> Rowe, R. </author> <title> Interactive Music Systems. </title> <publisher> MIT Press, </publisher> <year> 1993. </year>
Reference-contexts: 1 Introduction The perception and understanding of music by computers offers a challenging set of problems. Much of the work to date has focused on low-level perceptual features such as pitch and tempo, yet many computer music applications would benefit from higher-level understanding. For example, interactive performance systems <ref> [3] </ref> are sometimes designed to react to higher-level intentions of the performer.
Reference: [4] <author> Rubine, D. </author> <title> The automatic recognition of gestures. </title> <type> Tech. rep., </type> <institution> School of Computer Science, Carnegie Mellon University, </institution> <year> 1991. </year>
Reference-contexts: The linear classifier algorithm we used <ref> [4] </ref> also assumes features are normally distributed, but not that they are uncorrelated. A linear classifier tries to separate members of the class from non-members by cutting the feature vector space with a hyperplane.
References-found: 4

