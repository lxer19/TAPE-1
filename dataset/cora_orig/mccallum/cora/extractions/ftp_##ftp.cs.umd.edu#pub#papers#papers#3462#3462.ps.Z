URL: ftp://ftp.cs.umd.edu/pub/papers/papers/3462/3462.ps.Z
Refering-URL: http://www.cs.dartmouth.edu/pario/new.html
Root-URL: 
Email: skelleyg@cs.umd.edu  
Title: The Tower of Pizzas  
Author: Michael Tan Nick Roussopoulos Steve Kelley fmdtanx, nick, 
Date: 1, 1995  
Note: May  This research was partially sponsored by NSF under contract number ASC 9318183, by ARPA under contract number F30602-93-C-0177, by ARPA through High Performance Computing Fellowship MDA972-92-J-1019, and by NASA under contract number USRA 5555-09.  
Address: College Park, MD 20742  
Affiliation: University of Maryland Institute for Advanced Computer Studies (UMIACS) and Computer Science Department University of Maryland  
Abstract: Technical Report CS-TR-3462 or UMIACS-TR-95-52 Abstract CPU speeds are increasing at a much faster rate than secondary storage device speeds. Many important applications face an I/O bottleneck. We demonstrate that this bottleneck can be alleviated through 1) scalable striping of data and 2) caching/prefetching techniques. This paper describes the design and performance of the Tower of Pizzas (TOPs), a portable software system providing parallel I/O and buffering services. 
Abstract-found: 1
Intro-found: 1
Reference: [ACPtNt95] <author> Thomas E. Anderson, David E. Culler, David A. Patterson, </author> <title> and the NOW team. A case for NOW (networks of workstations). </title> <note> To appear in IEEE Micro, </note> <year> 1995. </year>
Reference: [BBS + 94] <author> Robert Bennett, Kelvin Bryant, Alan Sussman, Raja Das, and Joel Saltz. Jovian: </author> <title> A framework for optimizing parallel I/O. </title> <booktitle> In Proceedings of the 1994 Scalable Parallel Libraries Conference, </booktitle> <pages> pages 10-20. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> October </month> <year> 1994. </year>
Reference-contexts: In [Kot94], I/O requests are all passed to the I/O nodes, which sort and perform the requests in some order favorable for disk head motion (disk directed I/O). This work focuses on predicting the next page reference, whereas TOPs deals with a known access pattern. JOVIAN <ref> [BBS + 94] </ref> provides ideas for dealing with many small references by conglomerating the references into disk block requests, but doesn't deal with buffering/prefetching. ADOPT [SC94] is a parallel I/O system which provides for user level and compiler level generation of prefetch hints, including conditional I/O requests.
Reference: [BLL92] <author> Allan Bricker, Michael Litzkow, and Miron Livny. </author> <title> Condor technical summary. </title> <type> Technical Report CS-TR-92-1069, </type> <institution> University of Wisconsin - Madison, </institution> <year> 1992. </year>
Reference: [BP94] <author> Robert D. Blumofe and David S. Park. </author> <title> Scheduling large-scale parallel computations on networks of worstations. </title> <booktitle> In Proceedings of the Third International Symposium on High Performance Distributed Computing, </booktitle> <month> August </month> <year> 1994. </year>
Reference: [CBF93] <author> Peter F. Corbett, Sandra Johnson Baylor, and Dror G. Feitelson. </author> <title> Overview of the Vesta parallel file system. </title> <booktitle> In IPPS '93 Workshop on Input/Output in Parallel Computer Systems, </booktitle> <pages> pages 1-16, </pages> <year> 1993. </year> <note> Also published in Computer Architecture News 21(5), </note> <month> December </month> <year> 1993, </year> <pages> pages 7-14. </pages>
Reference-contexts: PIOUS also does not focus on buffering and prefetching issues. In the realm of parallel processing, several parallel file systems with interesting ideas have emerged <ref> [Kot94, DSE88, DS89, FBD94, CBF93, TBC + 94] </ref>. These systems are often geared toward matrix operations, and a number of descriptors to encapsulate typical access patterns are described [Kot94, CBF93]. SPIFFI [FBD94] implements global shared file pointers of varying flavors (multiple clients access the same file pointer). <p> In the realm of parallel processing, several parallel file systems with interesting ideas have emerged [Kot94, DSE88, DS89, FBD94, CBF93, TBC + 94]. These systems are often geared toward matrix operations, and a number of descriptors to encapsulate typical access patterns are described <ref> [Kot94, CBF93] </ref>. SPIFFI [FBD94] implements global shared file pointers of varying flavors (multiple clients access the same file pointer). SPIFFI also implements a form of prefetching to handle the out of order requests generated when multiple clients sequentially access the same file.
Reference: [CLD + 93] <author> Peter M. Chen, Edward K. Lee, Ann L. Drapeau, Ken Lutz, Ethan L. Miller, Srinivasan Seshan, Ken Shirriff, David A. Patterson, and Randy H. Katz. </author> <title> Performance and design evaluation of the RAID-II storage server. </title> <booktitle> In IPPS '93 Workshop on Input/Output in Parallel Computer Systems, </booktitle> <pages> pages 110-120, </pages> <year> 1993. </year>
Reference-contexts: RAID-II <ref> [CLD + 93] </ref> views the network as a backplane, with several RAID-5 devices directly connected to a HIPPI network and ethernet. RAID-II seeks to deliver high bandwidth for large requests and low latency for small requests. Other projects stripe across networks and tape drives [Sto91, DK93].
Reference: [CLG + 94] <author> Peter M. Chen, Edward K. Lee, Garth A. Gibson, Randy H. Katz, and David A. Patterson. </author> <title> RAID: high-performance, reliable secondary storage. </title> <journal> ACM Computing Surveys, </journal> <volume> 26(2) </volume> <pages> 145-185, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: Today's typical workstation has a 40 MHz CPU, 32 MB of memory, and .5 GB of disk space. 1.1 The Tower of Pizzas Solution Data striping, buffering, and prefetching are methods which can help overcome the I/O bottleneck. Data striping is a widely accepted method of boosting I/O throughput <ref> [SGM86, CLG + 94, NBC + 94] </ref>. With striping, data can be read and written from multiple disks in parallel. Another way to alleviate the high cost of disk I/O is to avoid it or to hide it.
Reference: [DK93] <author> Ann L. Drapeau and Randy H. Katz. </author> <title> Striping in large tape libraries. </title> <booktitle> In Proceedings of Supercomputing '93, </booktitle> <pages> pages 378-387, </pages> <year> 1993. </year>
Reference-contexts: RAID-II [CLD + 93] views the network as a backplane, with several RAID-5 devices directly connected to a HIPPI network and ethernet. RAID-II seeks to deliver high bandwidth for large requests and low latency for small requests. Other projects stripe across networks and tape drives <ref> [Sto91, DK93] </ref>. However, with such low-level approaches, there is less user control over buffering and prefetching policies.
Reference: [DS89] <author> Peter C. Dibble and Michael L. Scott. </author> <title> Beyond striping: The Bridge multiprocessor file system. </title> <journal> Computer Architecture News, </journal> <volume> 19(5), </volume> <month> September </month> <year> 1989. </year>
Reference-contexts: PIOUS also does not focus on buffering and prefetching issues. In the realm of parallel processing, several parallel file systems with interesting ideas have emerged <ref> [Kot94, DSE88, DS89, FBD94, CBF93, TBC + 94] </ref>. These systems are often geared toward matrix operations, and a number of descriptors to encapsulate typical access patterns are described [Kot94, CBF93]. SPIFFI [FBD94] implements global shared file pointers of varying flavors (multiple clients access the same file pointer).
Reference: [DSE88] <author> Peter Dibble, Michael Scott, and Carla Ellis. </author> <title> Bridge: A high-performance file system for parallel processors. </title> <booktitle> In Proceedings of the Eighth International Conference on Distributed Computer Systems, </booktitle> <pages> pages 154-161, </pages> <month> June </month> <year> 1988. </year>
Reference-contexts: PIOUS also does not focus on buffering and prefetching issues. In the realm of parallel processing, several parallel file systems with interesting ideas have emerged <ref> [Kot94, DSE88, DS89, FBD94, CBF93, TBC + 94] </ref>. These systems are often geared toward matrix operations, and a number of descriptors to encapsulate typical access patterns are described [Kot94, CBF93]. SPIFFI [FBD94] implements global shared file pointers of varying flavors (multiple clients access the same file pointer).
Reference: [FBD94] <author> Craig S. Freedman, Josef Burger, and David J. Dewitt. </author> <title> SPIFFI | a scalable parallel file system for the Intel Paragon. </title> <note> Submitted to IEEE TPDS, </note> <year> 1994. </year>
Reference-contexts: PIOUS also does not focus on buffering and prefetching issues. In the realm of parallel processing, several parallel file systems with interesting ideas have emerged <ref> [Kot94, DSE88, DS89, FBD94, CBF93, TBC + 94] </ref>. These systems are often geared toward matrix operations, and a number of descriptors to encapsulate typical access patterns are described [Kot94, CBF93]. SPIFFI [FBD94] implements global shared file pointers of varying flavors (multiple clients access the same file pointer). <p> In the realm of parallel processing, several parallel file systems with interesting ideas have emerged [Kot94, DSE88, DS89, FBD94, CBF93, TBC + 94]. These systems are often geared toward matrix operations, and a number of descriptors to encapsulate typical access patterns are described [Kot94, CBF93]. SPIFFI <ref> [FBD94] </ref> implements global shared file pointers of varying flavors (multiple clients access the same file pointer). SPIFFI also implements a form of prefetching to handle the out of order requests generated when multiple clients sequentially access the same file.
Reference: [Gra94] <author> Jim Gray. </author> <title> Parallelism: The new imperative in computer architecture. </title> <booktitle> Slides from talk at VLDB 1994, </booktitle> <year> 1994. </year>
Reference-contexts: With the increasing size of datasets and the increasing speed of CPUs, the means of getting the data to the CPU must also be increasing in throughput. Otherwise, much of the power of these future CPUs will be wasted. Gray <ref> [Gra94] </ref> has made the observation that if we count a cycle from a CPU of the future as a minute, the idle CPU cycles spent waiting for a single request to be fetched from disk is equivalent to the time to walk from the Earth to Pluto.
Reference: [HO93] <author> John H. Hartman and John K. Ousterhout. </author> <title> The Zebra striped network file system. </title> <booktitle> In Proceedings of the Fourteenth ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 29-43, </pages> <year> 1993. </year>
Reference-contexts: From the figure 10, we see that each disk delivered about 3MB/s, which is consistent with the sequential read tests on the SP2 disk (table 1). 4 Related Work A number of projects have contributed to the research in scalable I/O. Parallel file systems such as <ref> [HO93, Mon93, MS94] </ref> can run on workstation clusters. Zebra [HO93] has a client-server architecture and is implemented on the Sprite operating system, using a log structured file system to store files on the servers. <p> Parallel file systems such as [HO93, Mon93, MS94] can run on workstation clusters. Zebra <ref> [HO93] </ref> has a client-server architecture and is implemented on the Sprite operating system, using a log structured file system to store files on the servers. Zebra also implements parity-codes in its striping (RAID level 4), but does not address buffering or prefetching issues.
Reference: [Kot94] <author> David Kotz. </author> <title> Disk-directed I/O for MIMD multiprocessors. </title> <type> Technical Report PCS-TR94-226, </type> <institution> Dept. of Computer Science, Dartmouth College, </institution> <month> July </month> <year> 1994. </year> <note> Revised Novem-ber 8, </note> <year> 1994. </year>
Reference-contexts: PIOUS also does not focus on buffering and prefetching issues. In the realm of parallel processing, several parallel file systems with interesting ideas have emerged <ref> [Kot94, DSE88, DS89, FBD94, CBF93, TBC + 94] </ref>. These systems are often geared toward matrix operations, and a number of descriptors to encapsulate typical access patterns are described [Kot94, CBF93]. SPIFFI [FBD94] implements global shared file pointers of varying flavors (multiple clients access the same file pointer). <p> In the realm of parallel processing, several parallel file systems with interesting ideas have emerged [Kot94, DSE88, DS89, FBD94, CBF93, TBC + 94]. These systems are often geared toward matrix operations, and a number of descriptors to encapsulate typical access patterns are described <ref> [Kot94, CBF93] </ref>. SPIFFI [FBD94] implements global shared file pointers of varying flavors (multiple clients access the same file pointer). SPIFFI also implements a form of prefetching to handle the out of order requests generated when multiple clients sequentially access the same file. <p> Their approach seems to use larger disk blocks and some buffering to handle out of order requests. However, it is unclear whether SPIFFI completely preloads all the pages in the "gap" between two non-consecutive page requests. In <ref> [Kot94] </ref>, I/O requests are all passed to the I/O nodes, which sort and perform the requests in some order favorable for disk head motion (disk directed I/O). This work focuses on predicting the next page reference, whereas TOPs deals with a known access pattern.
Reference: [Mon93] <author> Bruce R. Montague. </author> <title> The Swift/RAID distributed transaction driver. </title> <type> Technical Report UCSC-CRL-93-99, </type> <institution> UC Santa Cruz, </institution> <month> January </month> <year> 1993. </year>
Reference-contexts: From the figure 10, we see that each disk delivered about 3MB/s, which is consistent with the sequential read tests on the SP2 disk (table 1). 4 Related Work A number of projects have contributed to the research in scalable I/O. Parallel file systems such as <ref> [HO93, Mon93, MS94] </ref> can run on workstation clusters. Zebra [HO93] has a client-server architecture and is implemented on the Sprite operating system, using a log structured file system to store files on the servers.
Reference: [MS94] <author> Steven A. Moyer and V. S. Sunderam. </author> <title> PIOUS: a scalable parallel I/O system for distributed computing environments. </title> <booktitle> In Proceedings of the Scalable High-Performance Computing Conference, </booktitle> <pages> pages 71-78, </pages> <year> 1994. </year>
Reference-contexts: From the figure 10, we see that each disk delivered about 3MB/s, which is consistent with the sequential read tests on the SP2 disk (table 1). 4 Related Work A number of projects have contributed to the research in scalable I/O. Parallel file systems such as <ref> [HO93, Mon93, MS94] </ref> can run on workstation clusters. Zebra [HO93] has a client-server architecture and is implemented on the Sprite operating system, using a log structured file system to store files on the servers. <p> Zebra [HO93] has a client-server architecture and is implemented on the Sprite operating system, using a log structured file system to store files on the servers. Zebra also implements parity-codes in its striping (RAID level 4), but does not address buffering or prefetching issues. The PIOUS <ref> [MS94] </ref> system uses PVM to communicate over the network, targeting workstation clusters or parallel clusters. PIOUS stripes files and supports a form of transactions (which guarantee file system integrity in case of a crash) and global shared files pointers. [MS94] reports results for ethernet tests. <p> The PIOUS <ref> [MS94] </ref> system uses PVM to communicate over the network, targeting workstation clusters or parallel clusters. PIOUS stripes files and supports a form of transactions (which guarantee file system integrity in case of a crash) and global shared files pointers. [MS94] reports results for ethernet tests. PIOUS also does not focus on buffering and prefetching issues. In the realm of parallel processing, several parallel file systems with interesting ideas have emerged [Kot94, DSE88, DS89, FBD94, CBF93, TBC + 94].
Reference: [NBC + 94] <author> Chris Nyberg, Tom Barclay, Zarka Cvetanovic, Jim Gray, and Dave Lomet. AlphaSort: </author> <title> a RISC machine sort. </title> <booktitle> In Proceedings of the 1994 ACM SIGMOD. </booktitle> <publisher> ACM Press, </publisher> <year> 1994. </year> <month> 17 </month>
Reference-contexts: Today's typical workstation has a 40 MHz CPU, 32 MB of memory, and .5 GB of disk space. 1.1 The Tower of Pizzas Solution Data striping, buffering, and prefetching are methods which can help overcome the I/O bottleneck. Data striping is a widely accepted method of boosting I/O throughput <ref> [SGM86, CLG + 94, NBC + 94] </ref>. With striping, data can be read and written from multiple disks in parallel. Another way to alleviate the high cost of disk I/O is to avoid it or to hide it.
Reference: [SC94] <author> Tarvinder Pal Singh and Alok Choudhary. ADOPT: </author> <title> A dynamic scheme for optimal prefetching in parallel file systems. </title> <type> Technical report, </type> <institution> NPAC, </institution> <month> June </month> <year> 1994. </year>
Reference-contexts: This work focuses on predicting the next page reference, whereas TOPs deals with a known access pattern. JOVIAN [BBS + 94] provides ideas for dealing with many small references by conglomerating the references into disk block requests, but doesn't deal with buffering/prefetching. ADOPT <ref> [SC94] </ref> is a parallel I/O system which provides for user level and compiler level generation of prefetch hints, including conditional I/O requests.
Reference: [SGM86] <author> Kenneth Salem and Hector Garcia-Molina. </author> <title> Disk striping. </title> <booktitle> In IEEE 1986 Conference on Data Engineering, </booktitle> <pages> pages 336-342, </pages> <year> 1986. </year>
Reference-contexts: Today's typical workstation has a 40 MHz CPU, 32 MB of memory, and .5 GB of disk space. 1.1 The Tower of Pizzas Solution Data striping, buffering, and prefetching are methods which can help overcome the I/O bottleneck. Data striping is a widely accepted method of boosting I/O throughput <ref> [SGM86, CLG + 94, NBC + 94] </ref>. With striping, data can be read and written from multiple disks in parallel. Another way to alleviate the high cost of disk I/O is to avoid it or to hide it.
Reference: [Sto91] <author> Michael Stonebraker. </author> <title> An overview of the Sequoia 2000 project. </title> <type> Technical Report 91-5, </type> <institution> University of California, Berkeley, </institution> <year> 1991. </year>
Reference-contexts: 1 Introduction Forthcoming applications in multimedia, satellite observation, electronic libraries, and scientific computing will use datasets whose sizes are an order of magnitude larger than those handled by current systems. In 1992, global change researchers wanted to manipulate databases of 100 terabytes <ref> [Sto91] </ref>). Future satellites will download terabytes of data every day. Because the speed of secondary storage technology (disks) is increasing at a slower rate than CPU speed, I/O is predicted to be the bottleneck in many applications. <p> RAID-II [CLD + 93] views the network as a backplane, with several RAID-5 devices directly connected to a HIPPI network and ethernet. RAID-II seeks to deliver high bandwidth for large requests and low latency for small requests. Other projects stripe across networks and tape drives <ref> [Sto91, DK93] </ref>. However, with such low-level approaches, there is less user control over buffering and prefetching policies.
Reference: [TBC + 94] <author> Rajeev Thakur, Rajesh Bordawekar, Alok Choudhary, Ravi Ponnusamy, and Tarvinder Singh. </author> <title> PASSION runtime library for parallel I/O. </title> <booktitle> In Proceedings of the Scalable Parallel Libraries Conference, </booktitle> <pages> pages 119-128, </pages> <month> October </month> <year> 1994. </year> <month> 18 </month>
Reference-contexts: PIOUS also does not focus on buffering and prefetching issues. In the realm of parallel processing, several parallel file systems with interesting ideas have emerged <ref> [Kot94, DSE88, DS89, FBD94, CBF93, TBC + 94] </ref>. These systems are often geared toward matrix operations, and a number of descriptors to encapsulate typical access patterns are described [Kot94, CBF93]. SPIFFI [FBD94] implements global shared file pointers of varying flavors (multiple clients access the same file pointer).
References-found: 21

