URL: http://www.research.microsoft.com/~conal/papers/elliott90.ps.gz
Refering-URL: http://www.research.microsoft.com/~conal/
Root-URL: http://www.research.microsoft.com
Title: Extensions and Applications of Higher-order Unification  
Author: Conal M. Elliott Conal M. Elliott 
Degree: Submitted in partial fulfillment of the requirements for the degree of Doctor of Philos ophy in  
Note: Copyright c 1990  This research was supported in part by the Office of Naval Research and in part by the Defense Advanced Research Projects Agency (DOD), monitored by the Office of Naval Research under Contract N00014-84-K-0415, ARPA Order No. 5404, and in part by NSF Grant CCR-8620191. The views and conclusions contained in this document are those of the author and should not be interpreted as representing the official policies, either expressed or implied, of ONR, DARPA or the U.S. government.  
Affiliation: Computer Science at Carnegie Mellon University.  
Date: May, 1990  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Peter B. Andrews. </author> <title> Theorem proving via general matings. </title> <journal> Journal of the ACM, </journal> <volume> 28 </volume> <pages> 193-214, </pages> <year> 1981. </year>
Reference-contexts: While the original purpose of higher-order unification was higher-order resolution, many diverse applications followed. Andrews developed the technique of matings for automated 1.2. RICHER TYPE THEORIES 3 theorem proving in higher-order logic <ref> [1] </ref>. Huet and Lang showed how to use a fragment of ! to encode program transformation rules and then use second-order matching and substitution to automatically apply them [37].
Reference: [2] <author> Arnon Avron, Furio A. Honsell, and Ian A. Mason. </author> <title> Using Typed Lambda Calculus to Implement Formal Systems on a Machine. </title> <type> Technical Report ECS-LFCS-87-31, </type> <institution> Laboratory for Foundations of Computer Science, University of Edinburgh, Edinburgh, </institution> <address> Scotland, </address> <month> June </month> <year> 1987. </year>
Reference-contexts: e s n ), for object-types s 1 ; : : : ; s n . 3 How can this intent be enforced, so that non-legitimate let expressions do not have well-typed encodings? Our solution is similar to Mason's technique of "syntactic judgments" used in the encoding of Hoare logic <ref> [2, 44] </ref>. One problem in representing Hoare logic is that there are boolean expressions (used in constructing statements of the imperative programming language) and first-order formulas (used in assertions), and the boolean expressions are identified with the quantifier-free first-order formulas.
Reference: [3] <author> Hendrik P. Barendregt. </author> <title> The Lambda-Calculus: Its Syntax and Semantics. </title> <publisher> North-Holland, </publisher> <year> 1980. </year>
Reference-contexts: Instead, we perform fi reductions and some -expansions. We can now explain why we use weak head normal forms, as opposed to the more common "head normal form", which requires some beta-reductions even inside an abstraction <ref> [3, page 41] </ref>. The reason is simply that we know how to decompose a disagreement pair involving an abstraction, regardless of the reductions that apply inside the abstraction. Proof of Proposition 4.22: We will treat only two of the six cases, since the others are analogous.
Reference: [4] <author> Hans-J. Boehm. </author> <title> Partial polymorphic type inference is undecidable. </title> <booktitle> In 26th Annual Symposium on Foundations of Computer Science, </booktitle> <pages> pages 339-345, </pages> <publisher> IEEE, </publisher> <month> October </month> <year> 1985. </year>
Reference-contexts: An object-language whose type inference problem requires truly higher-order unification is the polymorphic -calculus [25, 24, 65, 45], which we will refer to as " ". 4 The undecidability of this type inference problem for even the second-order polymorphic -calculus was shown by Boehm in <ref> [4] </ref>, by reducing it to second-order unification. In [59], Pfenning shows a more general converse, namely that partial type inference for the nth order polymorphic -calculus reduces to nth order unification. He then gives an implementation in Prolog, based on an encoding of in !ffi ( ! plus implicit polymorphism).
Reference: [5] <author> R. M. Burstall and John Darlington. </author> <title> A transformation system for developing recursive programs. </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> 24(1) </volume> <pages> 44-67, </pages> <month> January </month> <year> 1977. </year>
Reference-contexts: instances of p in a by true and some instances of p in b by false. 5 The higher-order term structure lets us do this very naturally: "if p then a [p] else b [p]" , "if p then a [true] else b [false]" Unfolding The unfold rule, described in <ref> [5] </ref>, transforms a set of mutually recursive function definitions, by replacing a call to one of the functions by that function's body, with formal parameters 5 This formulation is due to Tim Freeman. 7.5. PROGRAM TRANSFORMATION 119 replaced by actual parameters.
Reference: [6] <author> R. M. Burstall, D. B. MacQueen, and D. T. Sanella. </author> <title> HOPE: an Experimental Applicative Language. </title> <type> Technical Report CSR-62-80, </type> <institution> Department of Computer Science, University of Edinburgh, Edinburgh, U.K., </institution> <year> 1981. </year>
Reference-contexts: Consider the following the following function for reversing a pair: z: i fi o: snd z; fst z Many modern functional programming languages provide a convert notation for functions that operate on structured information <ref> [6, 29, 74] </ref>. In the fashion of these languages, we can write the above as (x; y): i fi o: y; x We will use such expressions in the examples of this chapter, as an abbreviation for terms like the previous one (that binds z). 7.3.
Reference: [7] <author> Luca Cardelli. </author> <title> Basic polymorphic typechecking. </title> <note> Polymorphism Newsletter, </note> <year> 1986. </year>
Reference-contexts: t: tp: (e s!e t)!e s!e t Example 7.3 The expression "let x = 2 in x &gt; 1" is represented let int bool (x: e int: gtr x (num 1)) (num 2) Note that although this let is (object language) polymorphic, it is not "genericly polymorphic" as is ML <ref> [51, 7] </ref>.
Reference: [8] <author> Alonzo Church. </author> <title> A formulation of the simple theory of types. </title> <journal> Journal of Symbolic Logic, </journal> <volume> 5 </volume> <pages> 56-68, </pages> <year> 1940. </year>
Reference-contexts: The language of terms (called "objects" in [30]) in this calculus has the same structure as the simply typed -calculus ( ! ) <ref> [8] </ref>. In place of simple function types "A!B" we have dependent function types 1 , "v: A: B", in which the type B of the result of a function may depend on the value v of the term to which it is applied. <p> The general idea goes back to Church, who expressed all of the binding constructs of higher-order logic in terms of the of the simply typed -calculus <ref> [8] </ref>. The use of second-order matching and substitution for transformation of programs represented in the simply typed -calculus was suggested in [37].
Reference: [9] <author> A. Colmerauer, H. Kanoui, and M. van Caneghem. </author> <title> Un Systeme de Communication Homme-machine en Francais. </title> <type> Research Report, </type> <institution> Groupe Intelligence Artificielle, Uni-versite Aix-Marseille II, </institution> <year> 1973. </year>
Reference-contexts: Colmerauer and Roussel first implemented the programming language Prolog based on this idea <ref> [9] </ref>. In 1940, Church had formulated a higher-order logic, based on the incorporation of simple types in his -calculus. Formulas and proofs in higher-order logic can be much more succinct than their corresponding versions in first-order logic.
Reference: [10] <author> Robert L. Constable et al. </author> <title> Implementing Mathematics with the Nuprl Proof Development System. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, New Jersey, </address> <year> 1986. </year> <note> 123 124 Bibliography </note>
Reference-contexts: This correspondence has been further pursued in the work of deBruijn's group [15], Martin-Lof (e.g., [42]), NuPrl <ref> [10] </ref>, and the Calculus of Constructions (CoC) [11]. More recently, a related but different approach has been proposed for representing logics within a type theory.
Reference: [11] <author> Thierry Coquand and Gerard Huet. </author> <title> The Calculus of Constructions. </title> <journal> Information and Computation, </journal> 76(2/3):95-120, February/March 1988. 
Reference-contexts: This correspondence has been further pursued in the work of deBruijn's group [15], Martin-Lof (e.g., [42]), NuPrl [10], and the Calculus of Constructions (CoC) <ref> [11] </ref>. More recently, a related but different approach has been proposed for representing logics within a type theory. <p> The resulting calculus, which would resemble the second- or !-order polymorphic -calculus [25, 24, 65, 45], or the Calculus of Constructions <ref> [11] </ref>, is very powerful computationally. However, unification is a topic for future research. 99 100 CHAPTER 6. POLYMORPHISM 6.1.1 Substitution and Conversion The meaning of applying substitutions to terms, types, and kinds carries over from Definition 2.7, with the obvious extensions.
Reference: [12] <author> Thierry Coquand and Gerard Huet. </author> <title> Constructions: a higher order proof system for mechanizing mathematics. In EUROCAL85, </title> <publisher> Springer-Verlag LNCS 203, </publisher> <year> 1985. </year>
Reference-contexts: The other is to provide automatic type inference in encoded languages, as described in Chapter 7. As in many type inference algorithms, the basic idea is to combine type-checking and unification, in this case, HOU . A similar problem is dealt with by Coquand and Huet <ref> [12, 33] </ref> and by Pollack [61] under the name of "argument synthesis". We reported on a slightly different algorithm for HOU in [18].
Reference: [13] <author> H. B. Curry and R. Feys. </author> <title> Combinatory Logic. </title> <publisher> North-Holland, </publisher> <address> Amsterdam, </address> <year> 1958. </year>
Reference-contexts: One very important paradigm is that of "formulas as types" introduced by Curry <ref> [13] </ref> and Howard [32], who observed a correspondence between types and terms of a given type on the one hand, and formulas and proofs of a given formula on the other.
Reference: [14] <author> N. G. de Bruijn. </author> <title> Lambda-calculus notation with nameless dummies: a tool for automatic formula manipulation with application to the Church-Rosser theorem. </title> <journal> Indag. Math., </journal> <volume> 34(5) </volume> <pages> 381-392, </pages> <year> 1972. </year>
Reference-contexts: We will sometimes use the meta-variable U to range over terms and types, and occasionally kinds. For the most part, we will ignore the issues of ff-conversion (bound variable renaming) and variable capture. In implementations, we prefer de Bruijn's "nameless" representation <ref> [14] </ref>, in which bound variable occurrences are integers denoting the number of 's between the occurrence and its binding . The mechanics of substitution in this representation are described well in [33, Section 8.3]. <p> A potential disadvantage of our approach is that with a traditional representation for the calculus that uses variable names, we would have to perform ff-conversion, before removing binding constructs. This disadvantage is removed by adopting de Bruijn's index based representation <ref> [14] </ref>. Definition 3.2 A disagreement set over is a finite multiset of disagreement pairs over . 3 We will use the meta-variable D to range over disagreement sets.
Reference: [15] <author> N. G. de Bruijn. </author> <title> A survey of the project Automath. </title> <editor> In J. P. Seldin and J. R. Hindley, editors, To H. B. </editor> <booktitle> Curry: Essays on Combinatory Logic, Lambda Calculus and Formalism, </booktitle> <publisher> Academic Press, </publisher> <year> 1980. </year>
Reference-contexts: This correspondence has been further pursued in the work of deBruijn's group <ref> [15] </ref>, Martin-Lof (e.g., [42]), NuPrl [10], and the Calculus of Constructions (CoC) [11]. More recently, a related but different approach has been proposed for representing logics within a type theory. <p> This calculus is the one used by the Logical Framework (LF) [30] (which itself is derived from members of the AUTOMATH family of languages <ref> [15] </ref>) for the purpose of encoding the syntax, rules and proofs of a wide class of logics. After presenting the syntax of the terms, types, and kinds of and their associated typing rules, we go on to present our somewhat unconventional definition of substitutions and their composition operation. <p> Finally, we present the typing rules of the calculus and some of their important properties. 2.1 The Language The calculus is the one used by the Logical Framework (LF) [30], which itself is derived from members of the AUTOMATH family of languages <ref> [15] </ref>. The language of terms (called "objects" in [30]) in this calculus has the same structure as the simply typed -calculus ( ! ) [8].
Reference: [16] <author> Scott Dietzen and Frank Pfenning. </author> <title> Higher-order and modal logic as a framework for explanation-based generalization. </title> <editor> In Alberto Maria Segre, editor, </editor> <booktitle> Sixth International Workshop on Machine Learning, </booktitle> <pages> pages 447-449, </pages> <publisher> Morgan Kaufmann Publishers, </publisher> <address> San Mateo, California, </address> <month> June </month> <year> 1989. </year> <note> Expanded version available as Technical Report CMU-CS-89-160, </note> <institution> Carnegie Mellon University, Pittsburgh. </institution>
Reference-contexts: Some other applications of Prolog have been computational linguistics [46], specifying and implementing theorem provers for various logics [22, 23], program analysis [28], partial type inference in the !-order polymorphic -calculus [59], and explanation based generalization (EBG) <ref> [16] </ref>. Donat and Wallen [17] also used higher-order unification for EBG.
Reference: [17] <author> Michael R. Donat and Lincoln A. Wallen. </author> <title> Learning and applying generalised solutions using higher order resolution. </title> <editor> In Ewing Lusk and Ross Overbeek, editors, </editor> <booktitle> 9th International Conference on Automated Deduction, </booktitle> <address> Argonne, </address> <publisher> Illinois, </publisher> <pages> pages 41-60, </pages> <publisher> Springer-Verlag LNCS 310, </publisher> <address> Berlin, </address> <month> May </month> <year> 1988. </year>
Reference-contexts: Some other applications of Prolog have been computational linguistics [46], specifying and implementing theorem provers for various logics [22, 23], program analysis [28], partial type inference in the !-order polymorphic -calculus [59], and explanation based generalization (EBG) [16]. Donat and Wallen <ref> [17] </ref> also used higher-order unification for EBG.
Reference: [18] <author> Conal Elliott. </author> <title> Higher-order unification with dependent types. </title> <booktitle> In Rewriting Techniques and Applications, </booktitle> <pages> pages 121-136, </pages> <publisher> Springer-Verlag LNCS 355, </publisher> <month> April </month> <year> 1989. </year>
Reference-contexts: A similar problem is dealt with by Coquand and Huet [12, 33] and by Pollack [61] under the name of "argument synthesis". We reported on a slightly different algorithm for HOU in <ref> [18] </ref>. <p> In HOU , however, as we have remarked, we will be forced to deal with terms that are ill-typed, and so 44 CHAPTER 4. A PRE-UNIFICATION ALGORITHM the concept of long normal form would need careful reconsideration. This was the approach we took in <ref> [18] </ref>, using the notion of "approximate well-typedness". We can also make a comparison to the use of in the standard method for testing convertibility of well-typed terms, which is to completely fi and normalize them, and then test the result for ff-equivalence. Instead, we perform fi reductions and some -expansions. <p> Completeness, however, makes no claims about unification problems with no solutions. This is one reason we choose to treat one-step weak head reduction as a transformation, rather than taking normalization for granted as is usually done in HOU ! (e.g., [36] and [70]). In <ref> [18] </ref>, we described an optimization based on the idea of approximate well-typedness that allows us to avoid ever constructing terms that are not strongly normalizing. Given a pair of terms M and M 0 to unify, we can satisfy the invariant initially in either of two ways.
Reference: [19] <author> Conal Elliott and Frank Pfenning. </author> <title> A Standard ML implementation of extended higher-order unification, Prolog and Elf. 1990. Send mail to fp@cs.cmu.edu on the Internet for further information. </title>
Reference-contexts: This was observed in the LF encoding in [30] of Church's higher-order logic, and is explored in Chapter 7 of this thesis. Pfenning has designed a programming language Elf [58] that combines the ideas of LF and Prolog. There is an implementation of it in Standard ML <ref> [19] </ref>. 1.3 Overview of the Thesis 1.3.1 The Calculus We begin in Chapter 2 by presenting the calculus " ", which is an extension of the ! in two ways: First, in place of a simple function type A!B, the type of the result of applying a function in may depend <p> As usual, is the unification context, and is a universal context. There is a Standard ML [29] implementation based on this procedure extended to deal with type variables <ref> [19] </ref>. Definition 4.76 Let the judgments "; ` A 2 K with D" and "; ` M 2 A with D" be defined by the following inference system.
Reference: [20] <author> Fran~cois Fages and Gerard Huet. </author> <title> Complete sets of unifiers and matchers in equational theories. </title> <booktitle> Theoretical Computer Science, </booktitle> <address> 43(2,3):189-200, </address> <year> 1986. </year>
Reference-contexts: However, we can still look for a complete set of unifiers (CSU), whose instances forms the set of all unifiers <ref> [20] </ref>. One would also like to have the property of minimality (non-redundancy), saying that the enumerated unifiers have no instances in common. However, as shown in [34], even for ! , it is not generally possible to enumerate minimal CSUs. 32 CHAPTER 3.
Reference: [21] <author> William M. Farmer. </author> <title> A Unification Algorithm for Second-Order Monadic Terms. </title> <type> Technical Report, </type> <institution> Mitre Corporation, Bedford, Massachusetts, </institution> <month> June </month> <year> 1986. </year> <note> To appear in the Journal of Pure and Applied Logic. </note>
Reference-contexts: Goldfarb showed undecidability for even a restriction of the problem to second-order unification, with a single binary function constant. In contrast, Huet [34, 37] showed second-order matching to be decidable, and Farmer <ref> [21] </ref> showed decid-ability of monadic second-order unification. Decidability of higher-order matching is still an open problem. A complete algorithm for enumerating CSUs was presented by Jensen and Pietrzykowski [38], but it had the problem of being extremely undirected for certain kinds of problems.
Reference: [22] <author> Amy Felty. </author> <title> Implementing Theorem Provers in Logic Programming. </title> <type> Technical Report MS-CIS-87-109, </type> <institution> University of Pennsylvania, </institution> <address> Philadelphia, </address> <month> December </month> <year> 1987. </year>
Reference-contexts: This extra expressiveness has proved extremely useful in many applications dealing with the manipulation of programs and formulas [50]. Some other applications of Prolog have been computational linguistics [46], specifying and implementing theorem provers for various logics <ref> [22, 23] </ref>, program analysis [28], partial type inference in the !-order polymorphic -calculus [59], and explanation based generalization (EBG) [16]. Donat and Wallen [17] also used higher-order unification for EBG.
Reference: [23] <author> Amy Felty and Dale A. Miller. </author> <title> Specifying theorem provers in a higher-order logic programming language. </title> <editor> In Ewing Lusk and Ross Overbeek, editors, </editor> <booktitle> 9th International Bibliography 125 Conference on Automated Deduction, </booktitle> <address> Argonne, </address> <publisher> Illinois, </publisher> <pages> pages 61-80, </pages> <publisher> Springer-Verlag LNCS 310, </publisher> <address> Berlin, </address> <month> May </month> <year> 1988. </year>
Reference-contexts: This extra expressiveness has proved extremely useful in many applications dealing with the manipulation of programs and formulas [50]. Some other applications of Prolog have been computational linguistics [46], specifying and implementing theorem provers for various logics <ref> [22, 23] </ref>, program analysis [28], partial type inference in the !-order polymorphic -calculus [59], and explanation based generalization (EBG) [16]. Donat and Wallen [17] also used higher-order unification for EBG. <p> However, even this wold be insufficient in practice. A very convenient way to use this kind of rule, in a unification based language as discussed in <ref> [23, page 8] </ref>, is to introduce a new unification variable, which will be instantiated later, when the desired value for t becomes known.
Reference: [24] <author> Jean-Yves Girard. </author> <title> Interpretation fonctionelle et elimination des coupures de l'arithme-tique d'ordre superieur. </title> <type> PhD thesis, </type> <institution> Universite Paris VII, </institution> <year> 1972. </year>
Reference-contexts: The resulting calculus, which would resemble the second- or !-order polymorphic -calculus <ref> [25, 24, 65, 45] </ref>, or the Calculus of Constructions [11], is very powerful computationally. However, unification is a topic for future research. 99 100 CHAPTER 6. POLYMORPHISM 6.1.1 Substitution and Conversion The meaning of applying substitutions to terms, types, and kinds carries over from Definition 2.7, with the obvious extensions. <p> We then instantiate our original encoding to (cons int (num 1) (nil int)) which has type (list int). The previous example required only very simple first-order unifications. An object-language whose type inference problem requires truly higher-order unification is the polymorphic -calculus <ref> [25, 24, 65, 45] </ref>, which we will refer to as " ". 4 The undecidability of this type inference problem for even the second-order polymorphic -calculus was shown by Boehm in [4], by reducing it to second-order unification.
Reference: [25] <author> Jean-Yves Girard. </author> <title> Une extension de l'interpretation de Godel a l'analyse, et son application a l'elimination des coupures dans l'analyse et la theorie des types. </title> <editor> In J. E. Fenstad, editor, </editor> <booktitle> Proceedings of the Second Scandinavian Logic Symposium, </booktitle> <pages> pages 63-92, </pages> <publisher> North-Holland Publishing Co., </publisher> <address> Amsterdam, London, </address> <year> 1971. </year>
Reference-contexts: The resulting calculus, which would resemble the second- or !-order polymorphic -calculus <ref> [25, 24, 65, 45] </ref>, or the Calculus of Constructions [11], is very powerful computationally. However, unification is a topic for future research. 99 100 CHAPTER 6. POLYMORPHISM 6.1.1 Substitution and Conversion The meaning of applying substitutions to terms, types, and kinds carries over from Definition 2.7, with the obvious extensions. <p> We then instantiate our original encoding to (cons int (num 1) (nil int)) which has type (list int). The previous example required only very simple first-order unifications. An object-language whose type inference problem requires truly higher-order unification is the polymorphic -calculus <ref> [25, 24, 65, 45] </ref>, which we will refer to as " ". 4 The undecidability of this type inference problem for even the second-order polymorphic -calculus was shown by Boehm in [4], by reducing it to second-order unification.
Reference: [26] <author> Warren D. Goldfarb. </author> <title> The undecidability of the second-order unification problem. </title> <journal> Theoretical Computer Science, </journal> <volume> 13 </volume> <pages> 225-230, </pages> <year> 1981. </year>
Reference-contexts: Guard [27] pointed out that CSUs must sometimes be infinite, and the general problem of unifiability was shown to be undecidable by Lucchesi [40], Huet [35], and Goldfarb <ref> [26] </ref>. Goldfarb showed undecidability for even a restriction of the problem to second-order unification, with a single binary function constant. In contrast, Huet [34, 37] showed second-order matching to be decidable, and Farmer [21] showed decid-ability of monadic second-order unification. Decidability of higher-order matching is still an open problem.
Reference: [27] <author> J. R. </author> <title> Guard. Automated Logic for Semi-Automated Mathematics. </title> <type> Scientific Report 1, </type> <address> AFCRL 64-411, </address> <year> 1964. </year>
Reference-contexts: Given the success of first-order resolution in mechanizing first-order logic, it was natural to consider the possibility of higher-order resolution for mechanizing higher-order logic. This form of resolution depends on being able to enumerate complete sets of unifiers (CSUs) in the simply typed -calculus ( ! ). Guard <ref> [27] </ref> pointed out that CSUs must sometimes be infinite, and the general problem of unifiability was shown to be undecidable by Lucchesi [40], Huet [35], and Goldfarb [26]. Goldfarb showed undecidability for even a restriction of the problem to second-order unification, with a single binary function constant.
Reference: [28] <author> John J. Hannan. </author> <title> Proof-theoretic Methods for Analysis of Functional Programs. </title> <type> Technical Report MS-CIS-89-07, </type> <institution> University of Pennsylvania, </institution> <address> Philadelphia, </address> <month> January </month> <year> 1989. </year> <title> Dissertation Proposal. </title>
Reference-contexts: This extra expressiveness has proved extremely useful in many applications dealing with the manipulation of programs and formulas [50]. Some other applications of Prolog have been computational linguistics [46], specifying and implementing theorem provers for various logics [22, 23], program analysis <ref> [28] </ref>, partial type inference in the !-order polymorphic -calculus [59], and explanation based generalization (EBG) [16]. Donat and Wallen [17] also used higher-order unification for EBG.
Reference: [29] <author> Robert Harper. </author> <title> Standard ML. </title> <type> Technical Report ECS-LFCS-86-2, </type> <institution> Laboratory for the Foundations of Computer Science, Edinburgh University, </institution> <month> March </month> <year> 1986. </year>
Reference-contexts: Along with types, there are type families, which are instantiated by applying them to terms. (They are thus different from, e.g., the type constructors of ML <ref> [29] </ref>, which are instantiated by applying them to types.) Types and type families are classified by their kind. Letting the meta-variables M and N range over terms, A and B 1 These are also sometimes called "dependent product types". <p> Unifiers of D, if any, will lead to instantiations of M and A (or A and K), as will be made precise below. As usual, is the unification context, and is a universal context. There is a Standard ML <ref> [29] </ref> implementation based on this procedure extended to deal with type variables [19]. Definition 4.76 Let the judgments "; ` A 2 K with D" and "; ` M 2 A with D" be defined by the following inference system. <p> Consider the following the following function for reversing a pair: z: i fi o: snd z; fst z Many modern functional programming languages provide a convert notation for functions that operate on structured information <ref> [6, 29, 74] </ref>. In the fashion of these languages, we can write the above as (x; y): i fi o: y; x We will use such expressions in the examples of this chapter, as an abbreviation for terms like the previous one (that binds z). 7.3. <p> In languages with this kind of binding construct, such as ML <ref> [29] </ref>, Scheme [72], and Lisp [71], it is often possible to bind many variables in parallel, so that the general form is instead e ::= let v = e; : : : ; v = e in e One way of dealing with this flexibility is to have an infinite (or
Reference: [30] <author> Robert Harper, Furio Honsell, and Gordon Plotkin. </author> <title> A framework for defining logics. </title> <month> January </month> <year> 1989. </year> <note> Submitted for publication. A preliminary version appeared in Symposium on Logic in Computer Science, pages 194-204, </note> <month> June </month> <year> 1987. </year>
Reference-contexts: INTRODUCTION languages is reduced to type checking in the representing typed -calculus, and thus the decidability of type-checking is vital. As pointed out in <ref> [30] </ref>, this is of great practical value, because it allows for the implementation of general tools, e.g., an interactive proof editor, that work for a variety of logical systems. In comparison with CoC, the LF type theory is very weak, having the same computational power as the simply typed -calculus. <p> The addition of dependent function types also allows the direct representation of the typing systems of various languages. This was observed in the LF encoding in <ref> [30] </ref> of Church's higher-order logic, and is explored in Chapter 7 of this thesis. Pfenning has designed a programming language Elf [58] that combines the ideas of LF and Prolog. <p> Second, in order for such a B to depend on the variable v, the base types of ! are generalized to type families, as indexed by zero or more appropriately typed terms. This calculus is the one used by the Logical Framework (LF) <ref> [30] </ref> (which itself is derived from members of the AUTOMATH family of languages [15]) for the purpose of encoding the syntax, rules and proofs of a wide class of logics. <p> Finally, we present the typing rules of the calculus and some of their important properties. 2.1 The Language The calculus is the one used by the Logical Framework (LF) <ref> [30] </ref>, which itself is derived from members of the AUTOMATH family of languages [15]. The language of terms (called "objects" in [30]) in this calculus has the same structure as the simply typed -calculus ( ! ) [8]. <p> Finally, we present the typing rules of the calculus and some of their important properties. 2.1 The Language The calculus is the one used by the Logical Framework (LF) <ref> [30] </ref>, which itself is derived from members of the AUTOMATH family of languages [15]. The language of terms (called "objects" in [30]) in this calculus has the same structure as the simply typed -calculus ( ! ) [8]. <p> Occasionally, we will also use "ran ()" for the range A 1 ; : : : ; A n of . Following <ref> [30] </ref>, we then define five judgments: Definition 2.29 The five basic typing judgments are defined below. <p> The typing rules below are taken from <ref> [30] </ref>, and depend on the notions of substitution and of convertibility. 3 Signatures ` h i sig ` sig [ ] ` K kind c 62 dom () ` c: K sig ` sig [ ] ` A 2 Type c 62 dom () ` c: A sig Thus valid signatures <p> Many of these properties are proved in <ref> [30] </ref> for a very similar calculus based on fi convertibility. Proposition 2.31 (Strengthening) If (a) 1 2 ` M 2 A, (b) v 62 dom ( 1 2 ), and (c) 1 ` A 2 Type, then 1 v: A 2 ` M 2 A. <p> For well-typed terms in , SN is fairly simple to show <ref> [30, Theorem A.7] </ref>. The CR property for with as well as fi has, for some time, been generally believed to be true. This conjecture has only recently been verified and the proof is quite complex [68]. <p> An alternative to relying on CR for ! fi would be to use just ! fi , for which CR has been shown (even for ill-typed terms) <ref> [30] </ref>. The algorithm we develop in Chapter 4 could be modified to perform unification for this calculus by following the reasoning behind Huet's fi unification algorithm for ! . However, this does not seem worthwhile, because the rule is necessary for language representation, on which most applications of interest depend. <p> The only problem is the relative well-typedness condition on the new disagreement pairs, as is demonstrated in the following. Example 4.27 Let our signature be a small fragment of the one given in <ref> [30] </ref> for encoding first-order logic: h o: Type ; i: Type ; 8: (i!o)!o ; :: o!o ; &gt;: o i 4 The usefulness of the lemma is based the CR property. <p> In our terminology, this would require a unifier 2 fi [ ] . This problem is discussed for ! in [48], but is much more difficult in , because determining the existence of closed terms of a given type is equivalent to general theorem proving <ref> [30] </ref>. 4.7. AUTOMATIC TERM INFERENCE 73 for c : y 1 : B 1 : y n : B n : Type The reason that the types of both v and v 0 must involve the same type constant c, is that C M 0 have the same type. <p> (fi-reduction and ff-conversion) for substitution and bound variable renaming that work correctly for even the binding constructs of a (correctly encoded) object-language. * Using dependent types, when the object-language is a logic (an object-logic) one can capture the theorem/proof relationship, as convincingly demonstrated by the work on the Logical Framework <ref> [30] </ref>. <p> In Prolog the representation is enriched to include implicit polymorphism, and the logic programming framework allows one to program control of the selection and application of rules [50]. In LF <ref> [30] </ref> a -calculus with dependent types is used as a meta-logic to encode the "language of a logic, its axiom and rule schemes, and its proofs", but unification is not used. In [60] the value of products together with polymorphism is demonstrated. <p> Thus for each well-typed term s of type tp, there is a one-to-one correspondence between long normal form terms of type (e s) and well-typed object-language expressions whose type is represented by s. (See <ref> [30] </ref> for a definition of these normal forms and a rigorous account of the correspondence.) A fortunate consequence is that when these techniques apply, object-language type checking is reduced to meta-language type checking, which may be implemented once, independently of any object-language. <p> APPLICATIONS 7.6 Theorem Proving Another general area of application for the unification algorithms developed in the preceding chapters is theorem proving in various logics. In <ref> [30] </ref>, the Logical Framework (LF) is presented as a "first step towards a general theory of interactive proof checking and proof construction." The key ingredients are the calculus and the judgments as types principle, forming the basis of a very elegant and expressive system encompassing the syntax, rules, and proofs for
Reference: [31] <author> Jacques Herbrand. </author> <title> Recherches sur la theorie de la demonstration. </title> <institution> Travaux de la Societe des Sciences et de Letrres de Varsovic, </institution> <month> 33, </month> <year> 1930. </year>
Reference-contexts: One is the necessity to deal with ill-typed terms during the unification process. Our technique for dealing with ill-typedness significantly complicates the proofs, but fortunately requires little additional complexity in the algorithms. 1 2 CHAPTER 1. INTRODUCTION 1.1 Higher-order Unification The development of (first-order) unification, first studied by Herbrand <ref> [31] </ref>, had a major impact on the field of automated theorem proving in first-order logic, because it was the key component of the new mechanization procedure resolution, due to Robinson [67, 66] (who also reintroduced unification).
Reference: [32] <author> W. A. Howard. </author> <title> The formulae-as-types notion of construction. </title> <type> Unpublished manuscript, </type> <year> 1969. </year> <note> Reprinted in To H. </note> <editor> B. </editor> <booktitle> Curry: Essays on Combinatory Logic, Lambda Calculus and Formalism, </booktitle> <year> 1980. </year>
Reference-contexts: One very important paradigm is that of "formulas as types" introduced by Curry [13] and Howard <ref> [32] </ref>, who observed a correspondence between types and terms of a given type on the one hand, and formulas and proofs of a given formula on the other.
Reference: [33] <author> Gerard Huet. </author> <title> Formal structures for computation and deduction. </title> <month> May </month> <year> 1986. </year> <note> Lecture notes for a graduate course at Carnegie Mellon University. </note>
Reference-contexts: The other is to provide automatic type inference in encoded languages, as described in Chapter 7. As in many type inference algorithms, the basic idea is to combine type-checking and unification, in this case, HOU . A similar problem is dealt with by Coquand and Huet <ref> [12, 33] </ref> and by Pollack [61] under the name of "argument synthesis". We reported on a slightly different algorithm for HOU in [18]. <p> In implementations, we prefer de Bruijn's "nameless" representation [14], in which bound variable occurrences are integers denoting the number of 's between the occurrence and its binding . The mechanics of substitution in this representation are described well in <ref> [33, Section 8.3] </ref>. For purposes of presentation, however, the conventional named representation is much easier to work with. 2.2 Substitution Substitution is a fundamental notion in the study of unification. Our approach is somewhat unconventional, in that we associate every substitution with two sets of variables. <p> The other is to provide automatic type inference in encoded languages, as described in Chapter 7. As in the type inference algorithms mentioned above, the basic idea is to combine type-checking and unification, in this case, HOU . A similar problem is addressed by Huet <ref> [33] </ref> and by Pollack [61] under the name of "argument synthesis". Given a signature , context , and a term M whose free variables are all typed by , it may be the case that M is not well-typed, but it has well-typed substitution instances.
Reference: [34] <author> Gerard Huet. </author> <type> Resolution d'equations dans des langages d'ordre 1; 2; : : : ; !. PhD thesis, </type> <institution> Universite Paris VII, </institution> <month> September </month> <year> 1976. </year>
Reference-contexts: Goldfarb showed undecidability for even a restriction of the problem to second-order unification, with a single binary function constant. In contrast, Huet <ref> [34, 37] </ref> showed second-order matching to be decidable, and Farmer [21] showed decid-ability of monadic second-order unification. Decidability of higher-order matching is still an open problem. <p> Decidability of higher-order matching is still an open problem. A complete algorithm for enumerating CSUs was presented by Jensen and Pietrzykowski [38], but it had the problem of being extremely undirected for certain kinds of problems. Huet showed that it is impossible in general to enumerate minimal (nonredundant) CSUs <ref> [34] </ref>. In [34], Huet presented a pre-unification algorithm that avoids some of the problems of undirectedness and redundancy. The key new idea was to postpone unification subproblems of a certain form, called "flexible-flexible". <p> A complete algorithm for enumerating CSUs was presented by Jensen and Pietrzykowski [38], but it had the problem of being extremely undirected for certain kinds of problems. Huet showed that it is impossible in general to enumerate minimal (nonredundant) CSUs <ref> [34] </ref>. In [34], Huet presented a pre-unification algorithm that avoids some of the problems of undirectedness and redundancy. The key new idea was to postpone unification subproblems of a certain form, called "flexible-flexible". <p> However, we can still look for a complete set of unifiers (CSU), whose instances forms the set of all unifiers [20]. One would also like to have the property of minimality (non-redundancy), saying that the enumerated unifiers have no instances in common. However, as shown in <ref> [34] </ref>, even for ! , it is not generally possible to enumerate minimal CSUs. 32 CHAPTER 3. AN APPROACH TO UNIFICATION Huet's idea of pre-unification [34] (implicit in [36]) solved this difficulty. <p> However, as shown in <ref> [34] </ref>, even for ! , it is not generally possible to enumerate minimal CSUs. 32 CHAPTER 3. AN APPROACH TO UNIFICATION Huet's idea of pre-unification [34] (implicit in [36]) solved this difficulty. For this, we need the notion of a unification problem being in solved form. (We have borrowed this term from [70].) The precise meaning of this property varies from one calculus to another and is motivated by considerations in developing the pre-unification algorithms.
Reference: [35] <author> Gerard Huet. </author> <title> The undecidability of unification in third order logic. </title> <journal> Information and Control, </journal> <volume> 22(3) </volume> <pages> 257-267, </pages> <year> 1973. </year>
Reference-contexts: This form of resolution depends on being able to enumerate complete sets of unifiers (CSUs) in the simply typed -calculus ( ! ). Guard [27] pointed out that CSUs must sometimes be infinite, and the general problem of unifiability was shown to be undecidable by Lucchesi [40], Huet <ref> [35] </ref>, and Goldfarb [26]. Goldfarb showed undecidability for even a restriction of the problem to second-order unification, with a single binary function constant. In contrast, Huet [34, 37] showed second-order matching to be decidable, and Farmer [21] showed decid-ability of monadic second-order unification.
Reference: [36] <author> Gerard Huet. </author> <title> A unification algorithm for typed -calculus. </title> <journal> Theoretical Computer Science, </journal> <volume> 1 </volume> <pages> 27-57, </pages> <year> 1975. </year> <note> 126 Bibliography </note>
Reference-contexts: As a secondary contribution, we offer a new presentation of this kind of algorithm, which we hope serves to clarify the issues involved in these and other problems and algorithms. Although many of the important ideas in our algorithms have their roots in Huet's algorithm for higher-order unification <ref> [36] </ref>, there are serious technical difficulties that arise only in extensions to richer calculi. One is the necessity to deal with ill-typed terms during the unification process. Our technique for dealing with ill-typedness significantly complicates the proofs, but fortunately requires little additional complexity in the algorithms. 1 2 CHAPTER 1. <p> The idea in each of these transformations is to either 1.3. OVERVIEW OF THE THESIS 7 show nonunifiablity or to replace a chosen disagreement pair (pair of terms or types being unified) with a finite collection of simpler disagreement pairs. These cases correspond roughly to Huet's SIMPL phase <ref> [36] </ref>. The final transformation deals with "flexible-rigid" disagreement pairs. In this case we deduce a useful constraint on the possible unifiers of the chosen disagreement pair. We then show how to use this constraint to instantiate the unification problem into a finite collection of alternate unification problems. <p> They thus define an algorithm for enumerating CSPs, as described in Chapter 3. The value of pre-unification in ! is that solved disagreement sets (ones containing only flexible-flexible pairs) are always unifiable, and so pre-unifiability implies unifiability <ref> [36] </ref>. By making vital use of our definition of acceptability, we can generalize Huet's constructive proof of this fact to acceptable solved-form unification problems in . For the simply typed subset of , the substitution that we construct specializes to Huet's. <p> These latter, universal, variables arise because at a certain point in each of our algorithms, binding constructs are removed, e.g., an abstraction term v: A: M is replaced by M . The 's record the types of these variables, which would otherwise be lost. 2 In contrast, Huet's presentation <ref> [36] </ref> maintains explicit abstractions, which accumulate during execution of his algorithm. A potential disadvantage of our approach is that with a traditional representation for the calculus that uses variable names, we would have to perform ff-conversion, before removing binding constructs. <p> In this process, substitutions are performed (as in Huet's MATCH phase), and disagreement pairs are decomposed into sets of disagreement pairs (as in Huet's SIMPL phase). We compose the individual substitutions leading toward a unifier and keep them as the 0 component of a unification problem. By comparison, in <ref> [36] </ref>, the individual substitutions are kept in the edges of a "matching tree". We do not wish to emphasize this difference, as it seems to be mostly one of convenience of presentation. <p> However, as shown in [34], even for ! , it is not generally possible to enumerate minimal CSUs. 32 CHAPTER 3. AN APPROACH TO UNIFICATION Huet's idea of pre-unification [34] (implicit in <ref> [36] </ref>) solved this difficulty. For this, we need the notion of a unification problem being in solved form. (We have borrowed this term from [70].) The precise meaning of this property varies from one calculus to another and is motivated by considerations in developing the pre-unification algorithms. <p> It turns out that the second kind of choice may be made completely arbitrarily, but, in order to have completeness, the first kind must be done in a fair way. 4 As pointed out in <ref> [36] </ref>, this allows for various strategies. Huet formulated this difference by constructing "matching trees", in which the nodes are disagreement sets and the edges are substitutions, and then showed that all matching trees are complete. <p> Completeness, however, makes no claims about unification problems with no solutions. This is one reason we choose to treat one-step weak head reduction as a transformation, rather than taking normalization for granted as is usually done in HOU ! (e.g., <ref> [36] </ref> and [70]). In [18], we described an optimization based on the idea of approximate well-typedness that allows us to avoid ever constructing terms that are not strongly normalizing. <p> A PRE-UNIFICATION ALGORITHM 4.6 Unifiability of Solved Form Unification Problems The value of pre-unification in ! is that solved form disagreement sets (ones containing only flexible-flexible pairs) are always unifiable, and so pre-unifiability implies unifiability <ref> [36] </ref>. By making vital use of the accounting in the definition of acceptability, we can generalize Huet's constructive proof of this fact to acceptable solved form unification problems in .
Reference: [37] <author> Gerard Huet and Bernard Lang. </author> <title> Proving and applying program transformations expressed with second-order patterns. </title> <journal> Acta Informatica, </journal> <volume> 11 </volume> <pages> 31-55, </pages> <year> 1978. </year>
Reference-contexts: Goldfarb showed undecidability for even a restriction of the problem to second-order unification, with a single binary function constant. In contrast, Huet <ref> [34, 37] </ref> showed second-order matching to be decidable, and Farmer [21] showed decid-ability of monadic second-order unification. Decidability of higher-order matching is still an open problem. <p> Andrews developed the technique of matings for automated 1.2. RICHER TYPE THEORIES 3 theorem proving in higher-order logic [1]. Huet and Lang showed how to use a fragment of ! to encode program transformation rules and then use second-order matching and substitution to automatically apply them <ref> [37] </ref>. Just as first-order unification and first-order resolution led to Prolog, Nadathur applied higher-order unification and higher-order resolution in the design of a new programming language Prolog [53]. <p> The general idea goes back to Church, who expressed all of the binding constructs of higher-order logic in terms of the of the simply typed -calculus [8]. The use of second-order matching and substitution for transformation of programs represented in the simply typed -calculus was suggested in <ref> [37] </ref>. In recent years the idea has appeared in several guises: In Isabelle [56, 57] the syntax of logics are encoded as simply typed terms and their inference rules are encoded as formulas in intuitionistic higher-order logic.
Reference: [38] <author> D. C. Jensen and T. Pietrzykowski. </author> <title> Mechanizing !-order type theory through unification. </title> <journal> Theoretical Computer Science, </journal> <volume> 3 </volume> <pages> 123-171, </pages> <year> 1976. </year>
Reference-contexts: In contrast, Huet [34, 37] showed second-order matching to be decidable, and Farmer [21] showed decid-ability of monadic second-order unification. Decidability of higher-order matching is still an open problem. A complete algorithm for enumerating CSUs was presented by Jensen and Pietrzykowski <ref> [38] </ref>, but it had the problem of being extremely undirected for certain kinds of problems. Huet showed that it is impossible in general to enumerate minimal (nonredundant) CSUs [34]. In [34], Huet presented a pre-unification algorithm that avoids some of the problems of undirectedness and redundancy.
Reference: [39] <author> Kevin Knight. </author> <title> Unification: a multi-disciplinary survey. </title> <journal> ACM Computing Surveys, </journal> <volume> 2(1) </volume> <pages> 93-124, </pages> <month> March </month> <year> 1989. </year>
Reference-contexts: Because of the success of resolution, much work was focused on the efficient implementation of unification. (See <ref> [39] </ref> for a survey.) Another significant development was the observation that a subset of first-order logic, now called Horn logic, could serve as an elegant programming language, for which interpretation was performed by a restricted form of resolution known as SLD resolution (which is complete for Horn logic) [75]. <p> unifier (MGU), of which all other unifiers are instances. (In particular, every MGU is an instance of every other MGU, so in that sense they are unique.) There are many efficient algorithms to decide whether a first-order unification problem has a unifier, and if so, to produce an MGU. (See <ref> [39] </ref> for a survey.) With higher-order unification (and equational unification), MGUs no longer exist. However, we can still look for a complete set of unifiers (CSU), whose instances forms the set of all unifiers [20].
Reference: [40] <author> C. L. Lucchesi. </author> <title> The Undecidability of the Unification Problem for Third Order Languages. </title> <note> Report CSRR 2059, </note> <institution> University of Waterloo, Waterloo, Canada, </institution> <year> 1972. </year>
Reference-contexts: This form of resolution depends on being able to enumerate complete sets of unifiers (CSUs) in the simply typed -calculus ( ! ). Guard [27] pointed out that CSUs must sometimes be infinite, and the general problem of unifiability was shown to be undecidable by Lucchesi <ref> [40] </ref>, Huet [35], and Goldfarb [26]. Goldfarb showed undecidability for even a restriction of the problem to second-order unification, with a single binary function constant. In contrast, Huet [34, 37] showed second-order matching to be decidable, and Farmer [21] showed decid-ability of monadic second-order unification.
Reference: [41] <author> Alberto Martelli and Ugo Montanari. </author> <title> An efficient unification algorithm. </title> <journal> ACM Transactions on Programming Lanugaes and Systems, </journal> <volume> 4(2) </volume> <pages> 258-282, </pages> <month> April </month> <year> 1982. </year>
Reference-contexts: Our approach is related to the transformation-based approaches of Martelli and Montanari for first-order unification <ref> [41] </ref> and of Snyder and Gallier for higher-order and equational unification [70, 69], which was itself inspired by the work of Martelli and Monta-nari [41]. However, as discussed below, unlike these works, our approach makes the important distinction between two kinds of "nondeterminism" present in the search for unifiers. <p> Our approach is related to the transformation-based approaches of Martelli and Montanari for first-order unification <ref> [41] </ref> and of Snyder and Gallier for higher-order and equational unification [70, 69], which was itself inspired by the work of Martelli and Monta-nari [41]. However, as discussed below, unlike these works, our approach makes the important distinction between two kinds of "nondeterminism" present in the search for unifiers. This distinction is necessary to formulate an algorithm for enumerating complete and minimal sets of solutions (as defined in the chapter). <p> A related approach, by Snyder and Gal-lier, for HOU ! , (unification in the simply typed -calculus, ! ), and equational unification, is presented in [70, 69], which was itself inspired by the work of Martelli and Montanari <ref> [41] </ref>. However, as discussed below, unlike these works, our approach makes the important distinction between two kinds of "nondeterminism" present in the search for unifiers.
Reference: [42] <author> Per Martin-Lof. </author> <title> Constructive mathematics and computer programming. </title> <booktitle> In Logic, Methodology and Philosophy of Science VI, </booktitle> <pages> pages 153-175, </pages> <publisher> North-Holland, </publisher> <year> 1980. </year>
Reference-contexts: This correspondence has been further pursued in the work of deBruijn's group [15], Martin-Lof (e.g., <ref> [42] </ref>), NuPrl [10], and the Calculus of Constructions (CoC) [11]. More recently, a related but different approach has been proposed for representing logics within a type theory.
Reference: [43] <author> Per Martin-Lof. </author> <title> On the Meanings of the Logical Constants and the Justifications of the Logical Laws. </title> <type> Technical Report 2, </type> <institution> Scuola di Specializzazione in Logica Matematica, Dipartimento di Matematica, Universita di Siena, </institution> <year> 1985. </year>
Reference-contexts: The Logical Framework (LF), based on ! extended with dependent function () types, makes a correspondence between types families (functions from terms to types) and the fundamental units of inference systems, called judgements (following Martin-Lof <ref> [43] </ref>). Logical formulas are encoded as terms rather than types, and the judgment type families are applied to these terms. The intent of LF is different from the previous formalisms, since it is intended for supporting not just one, but a wide range of logics, even nonconstructive ones. <p> step towards a general theory of interactive proof checking and proof construction." A crucial property of LF, due to the rich representations allowed by dependent types, is that proof checking in appropriately encoded 1 Variations on this general idea have also been suggested by Martin-Lof as a "system of arities" <ref> [43] </ref>, and by Pfenning and Elliott as "higher-order abstract syntax" [60]. 4 CHAPTER 1. INTRODUCTION languages is reduced to type checking in the representing typed -calculus, and thus the decidability of type-checking is vital. <p> In [60] the value of products together with polymorphism is demonstrated. The basic idea is also present in Martin-Lof's system of arities <ref> [43] </ref>. 7.1 Some Motivating Examples In this section we highlight some of the problems that arise in matching and substitution due to the presence of binding constructs in a language. Almost all languages have these binding constructs, though sometimes they are not immediately apparent.
Reference: [44] <author> Ian A. Mason. </author> <title> Hoare's Logic in the LF. </title> <type> Technical Report ECS-LFCS-87-32, </type> <institution> Laboratory for Foundations of Computer Science, University of Edinburgh, Edinburgh, </institution> <address> Scotland, </address> <month> June </month> <year> 1987. </year>
Reference-contexts: e s n ), for object-types s 1 ; : : : ; s n . 3 How can this intent be enforced, so that non-legitimate let expressions do not have well-typed encodings? Our solution is similar to Mason's technique of "syntactic judgments" used in the encoding of Hoare logic <ref> [2, 44] </ref>. One problem in representing Hoare logic is that there are boolean expressions (used in constructing statements of the imperative programming language) and first-order formulas (used in assertions), and the boolean expressions are identified with the quantifier-free first-order formulas. <p> expression "let n = 1; b = true in (b and n &gt; 0)" is now represented as let e intfie bool (okx e int;e bool (oke int) (oke bool)) bool ((n; b): e int fi e bool: and b (gtr n (num 0))) (num 1; true) As discussed in <ref> [44] </ref> in reference to the representation of quantifier-freeness and interference, all proofs of a given syntactic judgment (i.e., terms of the representing type) are convertible, and moreover could be constructed automatically.
Reference: [45] <author> Nancy McCracken. </author> <title> The typechecking of programs with implicit type structure. </title> <editor> In G. Kahn, D.B. MacQueen, and G. Plotkin, editors, </editor> <booktitle> Semantics of Data Types, </booktitle> <pages> pages 301-315, </pages> <publisher> Springer-Verlag LNCS 173, </publisher> <year> 1984. </year>
Reference-contexts: The resulting calculus, which would resemble the second- or !-order polymorphic -calculus <ref> [25, 24, 65, 45] </ref>, or the Calculus of Constructions [11], is very powerful computationally. However, unification is a topic for future research. 99 100 CHAPTER 6. POLYMORPHISM 6.1.1 Substitution and Conversion The meaning of applying substitutions to terms, types, and kinds carries over from Definition 2.7, with the obvious extensions. <p> We then instantiate our original encoding to (cons int (num 1) (nil int)) which has type (list int). The previous example required only very simple first-order unifications. An object-language whose type inference problem requires truly higher-order unification is the polymorphic -calculus <ref> [25, 24, 65, 45] </ref>, which we will refer to as " ". 4 The undecidability of this type inference problem for even the second-order polymorphic -calculus was shown by Boehm in [4], by reducing it to second-order unification.
Reference: [46] <author> Dale Miller and Gopalan Nadathur. </author> <title> Some uses of higher-order logic in computational linguistics. </title> <booktitle> In Proceedings of the 24th Anual Meeting of the Associtation for Computational Linguistics, </booktitle> <pages> pages 247-255, </pages> <year> 1986. </year>
Reference-contexts: This extra expressiveness has proved extremely useful in many applications dealing with the manipulation of programs and formulas [50]. Some other applications of Prolog have been computational linguistics <ref> [46] </ref>, specifying and implementing theorem provers for various logics [22, 23], program analysis [28], partial type inference in the !-order polymorphic -calculus [59], and explanation based generalization (EBG) [16]. Donat and Wallen [17] also used higher-order unification for EBG.
Reference: [47] <author> Dale Miller, Gopalan Nadathur, Frank Pfenning, and Andre Scedrov. </author> <title> Uniform proofs as a foundation for logic programming. </title> <journal> Journal of Pure and Applied Logic, </journal> <note> 1988. To appear. Available as Ergo Report 88-055, </note> <institution> School of Computer Science, Carnegie Mellon University, Pittsburgh. </institution>
Reference-contexts: Although first based on a higher-order Horn logic, Miller et al. generalized the logic to higher-order hereditary Harrop formulas, which include use of explicit existential and universal quantification and implication <ref> [49, 47] </ref>. This extra expressiveness has proved extremely useful in many applications dealing with the manipulation of programs and formulas [50].
Reference: [48] <author> Dale A. Miller. </author> <title> Unification under mixed prefixes. 1987. </title> <type> Unpublished manuscript. </type>
Reference-contexts: We adopted the word from the notion of a "permanent occurrence" in <ref> [48] </ref>. 4.3. <p> In our terminology, this would require a unifier 2 fi [ ] . This problem is discussed for ! in <ref> [48] </ref>, but is much more difficult in , because determining the existence of closed terms of a given type is equivalent to general theorem proving [30]. 4.7. <p> A general solution in a case like this is to raise the order of the rule through explicit abstraction. This solution is inspired by Paulson's 8-lifting [56], which was discovered independently by Miller and called raising <ref> [48] </ref>. Both increase the order of some of the variables involved. Raising requires that we be able to explicitly mention the "l" of the l-calculus representation in the pattern.
Reference: [49] <author> Dale A. Miller and Gopalan Nadathur. </author> <title> Higher-order logic programming. </title> <booktitle> In Proceedings of the Third International Conference on Logic Programming, </booktitle> <publisher> Springer Verlag, </publisher> <month> July </month> <year> 1986. </year> <note> Bibliography 127 </note>
Reference-contexts: Although first based on a higher-order Horn logic, Miller et al. generalized the logic to higher-order hereditary Harrop formulas, which include use of explicit existential and universal quantification and implication <ref> [49, 47] </ref>. This extra expressiveness has proved extremely useful in many applications dealing with the manipulation of programs and formulas [50].
Reference: [50] <author> Dale A. Miller and Gopalan Nadathur. </author> <title> A logic programming approach to manipulating formulas and programs. </title> <booktitle> In Symposium on Logic Programming, </booktitle> <address> San Francisco, </address> <publisher> IEEE, </publisher> <month> September </month> <year> 1987. </year>
Reference-contexts: This extra expressiveness has proved extremely useful in many applications dealing with the manipulation of programs and formulas <ref> [50] </ref>. Some other applications of Prolog have been computational linguistics [46], specifying and implementing theorem provers for various logics [22, 23], program analysis [28], partial type inference in the !-order polymorphic -calculus [59], and explanation based generalization (EBG) [16]. Donat and Wallen [17] also used higher-order unification for EBG. <p> In Prolog the representation is enriched to include implicit polymorphism, and the logic programming framework allows one to program control of the selection and application of rules <ref> [50] </ref>. In LF [30] a -calculus with dependent types is used as a meta-logic to encode the "language of a logic, its axiom and rule schemes, and its proofs", but unification is not used. In [60] the value of products together with polymorphism is demonstrated.
Reference: [51] <author> Robin Milner. </author> <title> A theory of type polymorphism in programming. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 17 </volume> <pages> 348-375, </pages> <month> August </month> <year> 1978. </year>
Reference-contexts: j = ^ N 0 j , and also that each ^ C i = ^ C 0 i , so C M 0 . 2 4.7 Automatic Term Inference It is well known that first-order unification provides for type inference in ! with type variables and in similar languages <ref> [51] </ref>. Recently, it has been shown that HOU ! is the key ingredient for the corresponding problem in the !-order polymorphic -calculus [59]. In there is another problem of interest, namely term inference, which requires HOU . This problem has two important applications. <p> t: tp: (e s!e t)!e s!e t Example 7.3 The expression "let x = 2 in x &gt; 1" is represented let int bool (x: e int: gtr x (num 1)) (num 2) Note that although this let is (object language) polymorphic, it is not "genericly polymorphic" as is ML <ref> [51, 7] </ref>.
Reference: [52] <author> B. Moller. </author> <title> A survey of the project CIP: Computer-aided, intuition-guided programming. </title> <type> Technical Report TUM-18406, </type> <institution> Institut fur Informatik der TU Munchen, Munich, West Germany, </institution> <year> 1984. </year>
Reference-contexts: APPLICATIONS "let p = false in if p then 1 else 2" /, "if p then let p = false in 1 else let p = false in 2" As noted in <ref> [52] </ref> syntactic conditions on C are difficult to formulate if one wishes to eliminate the possibility of incorrect rule application as in the example.
Reference: [53] <author> Gopalan Nadathur. </author> <title> A Higher-Order Logic as the Basis for Logic Programming. </title> <type> PhD thesis, </type> <institution> University of Pennsylvania, </institution> <year> 1987. </year>
Reference-contexts: Just as first-order unification and first-order resolution led to Prolog, Nadathur applied higher-order unification and higher-order resolution in the design of a new programming language Prolog <ref> [53] </ref>. Although first based on a higher-order Horn logic, Miller et al. generalized the logic to higher-order hereditary Harrop formulas, which include use of explicit existential and universal quantification and implication [49, 47].
Reference: [54] <author> Gopalan Nadathur and Dale Miller. </author> <title> An overview of Prolog. </title> <editor> In Robert A. Kowalski and Kenneth A. Bowen, editors, </editor> <booktitle> Logic Programming: Proceedings of the Fifth International Conference and Symposium, </booktitle> <volume> Volume 1, </volume> <pages> pages 810-827, </pages> <publisher> MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <month> August </month> <year> 1988. </year>
Reference-contexts: THE TRANSFORMATIONS 103 6.2.3 Term Flexible-rigid We adopt the flexible-rigid transformation from HOU , although it is incomplete in the presence of polymorphism. In this section, we show under what conditions completeness is lost. Extensive experience with Prolog <ref> [54] </ref>, which uses a similarly incomplete algorithm (without dependent types), has shown that these conditions are rare in practice, but do occur.
Reference: [55] <author> Lawrence Paulson. </author> <title> A higher-order implementation of rewriting. </title> <booktitle> Science of Computer Programing, </booktitle> <volume> 3 </volume> <pages> 119-149, </pages> <year> 1983. </year>
Reference-contexts: For example, simple program derivations are often unfolding, followed by simplification, followed by folding. Similarly, simple proofs are often induction accompanied by simplification <ref> [55] </ref>. Higher-order abstract syntax and unification provides a simple way to do such subexpres-sion rewriting.
Reference: [56] <author> Lawrence Paulson. </author> <title> Natural deduction as higher-order resolution. </title> <journal> Journal of Logic Programming, </journal> <volume> 3 </volume> <pages> 237-258, </pages> <year> 1986. </year>
Reference-contexts: Donat and Wallen [17] also used higher-order unification for EBG. Paulson's Isabelle system for theorem proving in logics encoded in higher-order logic <ref> [56, 57] </ref> is similar in spirit to the Prolog work of Felty and Miller. 1.2 Richer Type Theories Many of the applications of higher-order unification listed above involve the use of ! for representing (encoding) various formal languages, in particular logics and programming languages. 1 Another area of research has been <p> The use of second-order matching and substitution for transformation of programs represented in the simply typed -calculus was suggested in [37]. In recent years the idea has appeared in several guises: In Isabelle <ref> [56, 57] </ref> the syntax of logics are encoded as simply typed terms and their inference rules are encoded as formulas in intuitionistic higher-order logic. <p> A general solution in a case like this is to raise the order of the rule through explicit abstraction. This solution is inspired by Paulson's 8-lifting <ref> [56] </ref>, which was discovered independently by Miller and called raising [48]. Both increase the order of some of the variables involved. Raising requires that we be able to explicitly mention the "l" of the l-calculus representation in the pattern.
Reference: [57] <author> Lawrence C. Paulson. </author> <title> The Representation of Logics in Higher-Order Logic. </title> <type> Technical Report 113, </type> <institution> University of Cambridge, </institution> <address> Cambridge, England, </address> <month> August </month> <year> 1987. </year>
Reference-contexts: Donat and Wallen [17] also used higher-order unification for EBG. Paulson's Isabelle system for theorem proving in logics encoded in higher-order logic <ref> [56, 57] </ref> is similar in spirit to the Prolog work of Felty and Miller. 1.2 Richer Type Theories Many of the applications of higher-order unification listed above involve the use of ! for representing (encoding) various formal languages, in particular logics and programming languages. 1 Another area of research has been <p> The use of second-order matching and substitution for transformation of programs represented in the simply typed -calculus was suggested in [37]. In recent years the idea has appeared in several guises: In Isabelle <ref> [56, 57] </ref> the syntax of logics are encoded as simply typed terms and their inference rules are encoded as formulas in intuitionistic higher-order logic.
Reference: [58] <author> Frank Pfenning. </author> <title> Elf: a language for logic definition and verified meta-programming. </title> <booktitle> In Fourth Annual Symposium on Logic in Computer Science, </booktitle> <pages> pages 313-322, </pages> <publisher> IEEE, </publisher> <month> June </month> <year> 1989. </year> <note> Also available as Ergo Report 89-067, </note> <institution> School of Computer Science, Carnegie Mellon University, Pittsburgh. </institution>
Reference-contexts: The addition of dependent function types also allows the direct representation of the typing systems of various languages. This was observed in the LF encoding in [30] of Church's higher-order logic, and is explored in Chapter 7 of this thesis. Pfenning has designed a programming language Elf <ref> [58] </ref> that combines the ideas of LF and Prolog. <p> This allows for object-logic independent proof checking and interactive proof construction, but also some degree of automated theorem proving, given a suitable unification-based language, such as Elf <ref> [58] </ref>. * Again, using the dependent features of the type system, we can internalize object-language typing rules, so that only object-language terms that are well-typed according the the object-language typing rules have meta-language representations that are well-typed acording to the meta-language typing rules. <p> A very elegant framework for this kind of automatic proof term construction is provided by Pfenning's programming language Elf, which "unifies logic definition (in the style of LF) with logic programming (in the style of Prolog)" <ref> [58] </ref>. (As described in [58], Elf does not allow polymorphism. <p> A very elegant framework for this kind of automatic proof term construction is provided by Pfenning's programming language Elf, which "unifies logic definition (in the style of LF) with logic programming (in the style of Prolog)" <ref> [58] </ref>. (As described in [58], Elf does not allow polymorphism. <p> These theorem provers could be expressed, e.g., in a Prolog based on (or or ffi ), or in Elf, a language for logic definition and verified meta-programming <ref> [58] </ref>.
Reference: [59] <author> Frank Pfenning. </author> <title> Partial polymorphic type inference and higher-order unification. </title> <booktitle> In Proceedings of the 1988 ACM Conference on Lisp and Functional Programming, Snow-bird, Utah, </booktitle> <pages> pages 153-163, </pages> <publisher> ACM Press, </publisher> <month> July </month> <year> 1988. </year> <note> Also available as Ergo Report 88-048, </note> <institution> School of Computer Science, Carnegie Mellon University, Pittsburgh. </institution>
Reference-contexts: Some other applications of Prolog have been computational linguistics [46], specifying and implementing theorem provers for various logics [22, 23], program analysis [28], partial type inference in the !-order polymorphic -calculus <ref> [59] </ref>, and explanation based generalization (EBG) [16]. Donat and Wallen [17] also used higher-order unification for EBG. <p> Recently, it has been shown that HOU ! is the key ingredient for the corresponding problem in the !-order polymorphic -calculus <ref> [59] </ref>. In there is another problem of interest, namely term inference, which requires HOU . This problem has two important applications. One is making our unification algorithm more widely applicable, by initially establishing the required invariant, as mentioned at the end of Section 4.3, and made precise below. <p> In <ref> [59] </ref>, Pfenning shows a more general converse, namely that partial type inference for the nth order polymorphic -calculus reduces to nth order unification. He then gives an implementation in Prolog, based on an encoding of in !ffi ( ! plus implicit polymorphism).
Reference: [60] <author> Frank Pfenning and Conal Elliott. </author> <title> Higher-order abstract syntax. </title> <booktitle> In Proceedings of the SIGPLAN '88 Symposium on Language Design and Implementation, Atlanta, Georgia, </booktitle> <pages> pages 199-208, </pages> <publisher> ACM Press, </publisher> <month> June </month> <year> 1988. </year> <note> Available as Ergo Report 88-036, </note> <institution> School of Computer Science, Carnegie Mellon University, Pittsburgh. </institution>
Reference-contexts: proof construction." A crucial property of LF, due to the rich representations allowed by dependent types, is that proof checking in appropriately encoded 1 Variations on this general idea have also been suggested by Martin-Lof as a "system of arities" [43], and by Pfenning and Elliott as "higher-order abstract syntax" <ref> [60] </ref>. 4 CHAPTER 1. INTRODUCTION languages is reduced to type checking in the representing typed -calculus, and thus the decidability of type-checking is vital. <p> The problem of unification in CoC's type theory seems to be significantly harder than unification in LF's type theory. The enhanced representational ability of extending the ! with product types and implicit polymorphism (free type variables) has been demonstrated in <ref> [60] </ref>. The usefulness of these extensions comes from the fact that many languages contain constructs that are made up of a variable number of components (e.g., a parallel "let" binding expression, as in ML or Lisp). <p> In LF [30] a -calculus with dependent types is used as a meta-logic to encode the "language of a logic, its axiom and rule schemes, and its proofs", but unification is not used. In <ref> [60] </ref> the value of products together with polymorphism is demonstrated.
Reference: [61] <author> Randy Pollack. </author> <title> The theory of LEGO. </title> <month> October </month> <year> 1988. </year> <title> Unpublished manuscript and documentation. 128 Bibliography </title>
Reference-contexts: As in many type inference algorithms, the basic idea is to combine type-checking and unification, in this case, HOU . A similar problem is dealt with by Coquand and Huet [12, 33] and by Pollack <ref> [61] </ref> under the name of "argument synthesis". We reported on a slightly different algorithm for HOU in [18]. <p> The other is to provide automatic type inference in encoded languages, as described in Chapter 7. As in the type inference algorithms mentioned above, the basic idea is to combine type-checking and unification, in this case, HOU . A similar problem is addressed by Huet [33] and by Pollack <ref> [61] </ref> under the name of "argument synthesis". Given a signature , context , and a term M whose free variables are all typed by , it may be the case that M is not well-typed, but it has well-typed substitution instances.
Reference: [62] <author> Garrel Pottinger. </author> <title> The Church-Rosser theorem for the typed -calculus with surjective pairing. </title> <journal> Notre Dame Journal of Formal Logic, </journal> <volume> 22(3) </volume> <pages> 264-268, </pages> <month> July </month> <year> 1981. </year>
Reference-contexts: Then we extend our notion of convertibility: Definition 5.4 The convertibility relation = is $ fl fi 1 2 . 82 CHAPTER 5. PRODUCTS The well-typed terms in the analogous extension " !fi " of ! have the important normalization and Church-Rosser properties <ref> [62, 73] </ref>. Again, we will assume that the proof can be carried through to , and again, we could eliminate this assumption by redefining convertibility as discussed in Section 2.3.
Reference: [63] <author> Garrel Pottinger. </author> <title> Proof of the normalization and Church-Rosser theorems for the typed -calculus. </title> <journal> Notre Dame Journal of Formal Logic, </journal> <volume> 19(3) </volume> <pages> 445-451, </pages> <month> July </month> <year> 1978. </year>
Reference-contexts: in cases the derivation ends in an instance of the term or type application rule. 2 2.4.1 Typing and Conversion For ! , it is well known that ! fi has the strong normalization (SN) and Church-Rosser (CR) properties for well-typed terms, guaranteeing the existence and uniqueness of normal forms <ref> [63] </ref>. For well-typed terms in , SN is fairly simple to show [30, Theorem A.7]. The CR property for with as well as fi has, for some time, been generally believed to be true. This conjecture has only recently been verified and the proof is quite complex [68].
Reference: [64] <author> D. J. Pym. </author> <title> Proof, Search and Computation in General Logic. </title> <type> PhD thesis, </type> <institution> University of Edinburgh, </institution> <year> 1990. </year> <month> forthcoming. </month>
Reference-contexts: A similar problem is dealt with by Coquand and Huet [12, 33] and by Pollack [61] under the name of "argument synthesis". We reported on a slightly different algorithm for HOU in [18]. Pym has reported an independent development of an algorithm for HOU as well <ref> [64] </ref>. 1.3.4 Products Chapter 5 extends the pre-unification algorithm developed in the previous chapter to the calculus " ", which is enriched with a dependent version of Cartesian product types, often called "strong sum types", or simply " types".
Reference: [65] <author> John Reynolds. </author> <title> Towards a theory of type structure. </title> <booktitle> In Proc. Colloque sur la Program-mation, </booktitle> <pages> pages 408-425, </pages> <publisher> Springer-Verlag LNCS 19, </publisher> <address> New York, </address> <year> 1974. </year>
Reference-contexts: The resulting calculus, which would resemble the second- or !-order polymorphic -calculus <ref> [25, 24, 65, 45] </ref>, or the Calculus of Constructions [11], is very powerful computationally. However, unification is a topic for future research. 99 100 CHAPTER 6. POLYMORPHISM 6.1.1 Substitution and Conversion The meaning of applying substitutions to terms, types, and kinds carries over from Definition 2.7, with the obvious extensions. <p> We then instantiate our original encoding to (cons int (num 1) (nil int)) which has type (list int). The previous example required only very simple first-order unifications. An object-language whose type inference problem requires truly higher-order unification is the polymorphic -calculus <ref> [25, 24, 65, 45] </ref>, which we will refer to as " ". 4 The undecidability of this type inference problem for even the second-order polymorphic -calculus was shown by Boehm in [4], by reducing it to second-order unification.
Reference: [66] <author> J. A. Robinson. </author> <title> Computational logic: the unification computation. </title> <journal> Machine Intelligence, </journal> <volume> 6 </volume> <pages> 63-72, </pages> <year> 1971. </year>
Reference-contexts: INTRODUCTION 1.1 Higher-order Unification The development of (first-order) unification, first studied by Herbrand [31], had a major impact on the field of automated theorem proving in first-order logic, because it was the key component of the new mechanization procedure resolution, due to Robinson <ref> [67, 66] </ref> (who also reintroduced unification).
Reference: [67] <author> J. A. Robinson. </author> <title> A machine-oriented logic based on the resolution principle. </title> <journal> Journal of the ACM, </journal> <volume> 12(1) </volume> <pages> 23-41, </pages> <month> January </month> <year> 1965. </year>
Reference-contexts: INTRODUCTION 1.1 Higher-order Unification The development of (first-order) unification, first studied by Herbrand [31], had a major impact on the field of automated theorem proving in first-order logic, because it was the key component of the new mechanization procedure resolution, due to Robinson <ref> [67, 66] </ref> (who also reintroduced unification).
Reference: [68] <author> Anne Salvesen. </author> <title> The Church-Rosser Theorem for LF with fi Reduction. </title> <type> Technical Report forthcoming, </type> <institution> Laboratory for Foundations of Computer Science, University of Edinburgh, Edinburgh, </institution> <address> Scotland, </address> <year> 1990. </year>
Reference-contexts: The Church-Rosser (CR) property for with as well as fi has, for some time, been generally believed to be true. This conjecture has only recently been verified and the proof is quite complex <ref> [68] </ref>. We describe two alternatives to relying on CR. <p> For well-typed terms in , SN is fairly simple to show [30, Theorem A.7]. The CR property for with as well as fi has, for some time, been generally believed to be true. This conjecture has only recently been verified and the proof is quite complex <ref> [68] </ref>. The importance of CR, together with the strong normalization property (SN) is that they reduce the question of convertibility (of well-typed terms and types) to equivalence (modulo ff-conversion) of normal forms.
Reference: [69] <author> Wayne Snyder. </author> <title> Complete Sets of Transformations for General Unification. </title> <type> PhD thesis, </type> <institution> University of Pennsylvania, </institution> <year> 1988. </year>
Reference-contexts: Our approach is related to the transformation-based approaches of Martelli and Montanari for first-order unification [41] and of Snyder and Gallier for higher-order and equational unification <ref> [70, 69] </ref>, which was itself inspired by the work of Martelli and Monta-nari [41]. However, as discussed below, unlike these works, our approach makes the important distinction between two kinds of "nondeterminism" present in the search for unifiers. <p> A related approach, by Snyder and Gal-lier, for HOU ! , (unification in the simply typed -calculus, ! ), and equational unification, is presented in <ref> [70, 69] </ref>, which was itself inspired by the work of Martelli and Montanari [41]. However, as discussed below, unlike these works, our approach makes the important distinction between two kinds of "nondeterminism" present in the search for unifiers.
Reference: [70] <author> Wayne Snyder and Jean H. Gallier. </author> <title> Higher-order unification revisited: complete sets of transformations. </title> <journal> Journal of Symbolic Computation, </journal> <note> 1988. To appear in the special issue on unification. </note>
Reference-contexts: Our approach is related to the transformation-based approaches of Martelli and Montanari for first-order unification [41] and of Snyder and Gallier for higher-order and equational unification <ref> [70, 69] </ref>, which was itself inspired by the work of Martelli and Monta-nari [41]. However, as discussed below, unlike these works, our approach makes the important distinction between two kinds of "nondeterminism" present in the search for unifiers. <p> A related approach, by Snyder and Gal-lier, for HOU ! , (unification in the simply typed -calculus, ! ), and equational unification, is presented in <ref> [70, 69] </ref>, which was itself inspired by the work of Martelli and Montanari [41]. However, as discussed below, unlike these works, our approach makes the important distinction between two kinds of "nondeterminism" present in the search for unifiers. <p> AN APPROACH TO UNIFICATION Huet's idea of pre-unification [34] (implicit in [36]) solved this difficulty. For this, we need the notion of a unification problem being in solved form. (We have borrowed this term from <ref> [70] </ref>.) The precise meaning of this property varies from one calculus to another and is motivated by considerations in developing the pre-unification algorithms. The precise meaning of this property will be given as Definition 4.46. For now we need only the following: Assumption 3.7 The solved form property satisfies 1. <p> Completeness, however, makes no claims about unification problems with no solutions. This is one reason we choose to treat one-step weak head reduction as a transformation, rather than taking normalization for granted as is usually done in HOU ! (e.g., [36] and <ref> [70] </ref>). In [18], we described an optimization based on the idea of approximate well-typedness that allows us to avoid ever constructing terms that are not strongly normalizing. Given a pair of terms M and M 0 to unify, we can satisfy the invariant initially in either of two ways.
Reference: [71] <author> Guy L. Steele. </author> <title> Common Lisp: The Language. </title> <publisher> Digital Press, </publisher> <year> 1984. </year>
Reference-contexts: In languages with this kind of binding construct, such as ML [29], Scheme [72], and Lisp <ref> [71] </ref>, it is often possible to bind many variables in parallel, so that the general form is instead e ::= let v = e; : : : ; v = e in e One way of dealing with this flexibility is to have an infinite (or for practical purposes, reasonably large)
Reference: [72] <author> Guy Lewis Steele and Gerald Jay Sussman. </author> <title> The Revised Report on SCHEME|A Dialect of LISP. AI Memo 452, </title> <publisher> MIT, </publisher> <address> Cambridge, </address> <month> January </month> <year> 1978. </year>
Reference-contexts: In languages with this kind of binding construct, such as ML [29], Scheme <ref> [72] </ref>, and Lisp [71], it is often possible to bind many variables in parallel, so that the general form is instead e ::= let v = e; : : : ; v = e in e One way of dealing with this flexibility is to have an infinite (or for practical
Reference: [73] <author> Anne S. Troelstra. </author> <title> Strong normalization for typed terms with surjective pairing. </title> <journal> Notre Dame Journal of Formal Logic, </journal> <volume> 27(4) </volume> <pages> 547-550, </pages> <month> October </month> <year> 1986. </year>
Reference-contexts: Then we extend our notion of convertibility: Definition 5.4 The convertibility relation = is $ fl fi 1 2 . 82 CHAPTER 5. PRODUCTS The well-typed terms in the analogous extension " !fi " of ! have the important normalization and Church-Rosser properties <ref> [62, 73] </ref>. Again, we will assume that the proof can be carried through to , and again, we could eliminate this assumption by redefining convertibility as discussed in Section 2.3.
Reference: [74] <author> David A. Turner. Miranda: </author> <title> a non-strict functional lanugage with polymorphic types. </title> <booktitle> In Functional Programming Languages and Computer Architecture, </booktitle> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <month> September </month> <year> 1985. </year>
Reference-contexts: Consider the following the following function for reversing a pair: z: i fi o: snd z; fst z Many modern functional programming languages provide a convert notation for functions that operate on structured information <ref> [6, 29, 74] </ref>. In the fashion of these languages, we can write the above as (x; y): i fi o: y; x We will use such expressions in the examples of this chapter, as an abbreviation for terms like the previous one (that binds z). 7.3.

Reference: [ M 1 =x 1 ; : : : ; M m =x m ] <editor> V 0 V Substitution specified by images of a subset of its domain, </editor> <title> 15 fi; Conversion rules for , 17 ! The one step subterm rewriting extension of , 17 ! fl Transitive closure of ! , 18 129 130 Glossary $ fl Equivalence closure of ! , 18 = Convertibility, 18 h c 1 : U 1 ; : : : ; c n : U n i Signature, 20 dom() Domain of a signature, 20 v: A Signature extension, </title> <type> 20 </type>

References-found: 75

