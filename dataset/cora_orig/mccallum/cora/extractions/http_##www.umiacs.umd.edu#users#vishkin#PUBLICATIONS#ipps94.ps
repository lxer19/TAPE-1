URL: http://www.umiacs.umd.edu/users/vishkin/PUBLICATIONS/ipps94.ps
Refering-URL: http://www.umiacs.umd.edu/users/vishkin/PUBLICATIONS/papers.html
Root-URL: 
Title: Can Parallel Algorithms Enhance Serial Implementation? (Extended Abstract)  
Author: Uzi Vishkin 
Affiliation: University of Maryland Tel Aviv University  
Abstract: The broad thesis presented in this paper suggests that the serial emulation of a parallel algorithm has the potential advantage of running on a serial machine faster than a standard serial algorithm for the same problem. It is too early to reach definite conclusions regarding the significance of this thesis. However, using some imagination, validity of the thesis and some arguments supporting it may lead to several far-reaching outcomes: (1) Reliance on "predictability of reference" in the design of computer systems will increase. (2) Parallel algorithms will be taught as part of the standard computer science and engineering undergraduate curriculum irrespective of whether (or when) parallel processing will become ubiquitous in the general-purpose computing world. (3) A strategic agenda for high-performance parallel computing: A multi-stage agenda, which in no stage compromises user-friendliness of the programmer's model, and thereby potentially alleviates the so-called "parallel software crisis", is discussed. Stimulating a debate is one goal of our presentation. 
Abstract-found: 1
Intro-found: 1
Reference: [AKP] <author> F. Abolhassan, J. Keller and W.J. Paul. </author> <booktitle> On the cost-effectiveness of PRAMs. In Proc. 3rd IEEE Symp. on Par. and Dist. Proc., 1991, </booktitle> <address> Dallas, TX. </address> <month> 9 </month>
Reference-contexts: Even if p 1 is fixed, having larger and larger p 2 (and therefore larger processor slackness) leads to improvements in efficiency. Several parallel machine designs take advantage of processor slackness; this includes the 1981 HEP design by B.J. Smith and the more recent design [ACCKPS], as well as <ref> [AKP] </ref> In other words, the concept of processor slackness considers parallelism as a resource. Our thesis takes advantage of this resource for the degenerate case where the computer has a single processor.
Reference: [ACF] <author> B. Alpern, L. Carter and E. Feig. </author> <title> Uniform mem-ory hierarchies. </title> <booktitle> In Proc. 31st Ann. IEEE Symp. on Found. of Comp. Sci., </booktitle> <pages> 600-608, </pages> <year> 1990. </year>
Reference-contexts: This heuristic will not be able to identify opportunities for prefetching that are described in this paper. However, the literature seems to emphasize another approach for getting more efficient algorithms in cases where large memories are involved. As a representative of this literature, we select <ref> [ACF] </ref> which suggests revising algorithms to work more efficiently on a particular model of memory organization. Such an approach essentially requires programming algorithms in a far less user-friendly language, a trend which is not considered desirable in modern computer science. Comparison with these works is not entirely appropriate since [ACF], for <p> select <ref> [ACF] </ref> which suggests revising algorithms to work more efficiently on a particular model of memory organization. Such an approach essentially requires programming algorithms in a far less user-friendly language, a trend which is not considered desirable in modern computer science. Comparison with these works is not entirely appropriate since [ACF], for instance, assumes a relatively low upper bound on the throughput of secondary memories, where throughput is defined as the rate at which these memories can transfer data. In Section 6, we observe that upper bounds on throughput have led to parallel programming languages which are not sufficiently user-friendly.
Reference: [ACCKPS] <author> R. Alverson, D. Callahan, D. Cumming, B. Koblenz, A. Porterfield and B. Smith. </author> <title> The Tera computer system. </title> <booktitle> In Proc. Int. Conf. on Super-comp., 1990, </booktitle> <address> Amsterdam. </address>
Reference-contexts: Even if p 1 is fixed, having larger and larger p 2 (and therefore larger processor slackness) leads to improvements in efficiency. Several parallel machine designs take advantage of processor slackness; this includes the 1981 HEP design by B.J. Smith and the more recent design <ref> [ACCKPS] </ref>, as well as [AKP] In other words, the concept of processor slackness considers parallelism as a resource. Our thesis takes advantage of this resource for the degenerate case where the computer has a single processor.
Reference: [AM] <author> R.J. Anderson and G.L. Miller. </author> <title> A simple randomized parallel algorithm for list ranking. </title> <journal> Inf. Proc. Lett., </journal> <volume> 33(5) </volume> <pages> 269-273, </pages> <year> 1990. </year>
Reference-contexts: The total number of operations of the serial list-ranking algorithm given earlier is 2. So, for the linear model for F , the comparison is between 8 (log n log log n)A + 8nB and 2nA. The simple randomized algorithms in <ref> [AM] </ref> and [Vi84b] achieve also similar performance. See [Vi93] for another example. 5 Caveats, Extensions and Discussion * Memory consistency. The main issue is how to avoid a situation where an outdated copy of an address is interpreted as having a correct value.
Reference: [AILSV] <author> A. Apostolico, C. Iliopoulos, G.M. Landau, B. Schieber, and U. Vishkin. </author> <title> Parallel construction of a suffix tree with applications. </title> <journal> Algorithmica, </journal> <volume> 3 </volume> <pages> 347-365, </pages> <year> 1988. </year>
Reference-contexts: Next, we review some preliminary experimental work that, using simulations, compares McCreight's serial algorithm against a serially-emulated parallel algorithm <ref> [AILSV] </ref>. Henceforth, these algorithms are referred to as Algorithm M and Algorithm P, respectively. We considered it more appropriate to base our experiment with Algorithm M on code written by others, rather than by ourselves. William Chang kindly agreed to provide us with his code for Algorithm M.
Reference: [BLMPSZ] <author> G.E. Blelloch, C.E. Leiserson, B.M. Maggs, C.G. Plaxton, S.J. Smith, and M. Zagha. </author> <title> A comparison of sorting algorithms for the Connection Machine CM-2. </title> <booktitle> In Proc. 3rd SPAA, </booktitle> <pages> 3-16, </pages> <year> 1991. </year>
Reference-contexts: It is interesting to mention that following experiments with implementation of parallel sorting algorithms, it has been observed that "throughput bottlenecks of this nature" exist in modern parallel machines such as the CM-2, by Thinking Machines Corporation <ref> [BLMPSZ] </ref>.
Reference: [BCHSZ] <author> G.E. Blelloch, S. Chatterjee, J.C. Harwick, J. Sipelstein, and M. Zagha. </author> <title> Implementation of a portable nested data-parallel language. </title> <booktitle> In Proc. 4th ACM PPOPP, </booktitle> <pages> 102-111, </pages> <year> 1993. </year>
Reference-contexts: Programming languages which enable to express parallelism should be available. Henceforth, we assume that such a programming language is available, since designing such a language is clearly doable. Actually, some languages already exist: FORTRAN 90 [MR] and SETL <ref> [BCHSZ] </ref> are two examples. For the user, this would mean the following. 1. Given a problem, and an algorithm for it, try to redesign the algorithm into an efficient parallel one.
Reference: [CKP] <author> D. Callahan, K. Kennedy and A. Porterfield. </author> <title> Software prefetching. </title> <booktitle> In Proc. 4th ACM Int. Conf. on Arch. Support for Prog. Lang. and Op. Sys., </booktitle> <address> Santa Clara, CA 40-52, </address> <year> 1991. </year>
Reference-contexts: These thoughts led the author to work on [Vi94]. Prefetching in the context of hardware is discussed in [Jo] and references therein. A recent paper that advocates the use of software prefetching is <ref> [CKP] </ref>; a helpful heuristic that guides compilers to identify cases where prefetching is possible is suggested. This heuristic will not be able to identify opportunities for prefetching that are described in this paper. <p> This calls for an effort concerning both languages and compilers. Given a programming language, the challenge for compiler writers is well defined; the work by <ref> [CKP] </ref> is in this spirit. Next, consider design of programming languages which will enable expressing relevant information, that will later be used by the compiler to improve its predictions. <p> This paper provides some evidence that prefetch-ing will increase the effectiveness of serial machines. The challenge is twofold: (1) Advance the prefetching facility in hardware; and (2) find more ways to take advantage of software prefetching, either in the spirit of <ref> [CKP] </ref> or the present paper. The fine structure of parallel programs may be beneficial in ways which are beyond the scope of this paper. Our thesis, in section 3, calls for exploring such opportunities. Acknowledgements The suffix tree programming was done by Suleyman Sahinalp.
Reference: [CV] <author> R. Cole and U. Vishkin. </author> <title> Deterministic coin tossing with applications to optimal parallel list ranking. </title> <journal> Inf. and Cont., </journal> <volume> 70 </volume> <pages> 32-53, </pages> <year> 1986. </year>
Reference-contexts: Our experimental results actually demonstrate that such development may lead to an implementation of Algorithm P which is several orders of magnitude faster than that of Algorithm M. 4.3 Additional examples List ranking. For the list-ranking problem, we actually suggest an algorithm which is referred to, in <ref> [CV] </ref>, as the "Basic list-ranking algorithm". This algorithm runs in O (log n log log n) time and O (n) operation, and the constant factors hidden by the big-oh notation are 8 for both time and operations.
Reference: [DG] <author> D. DeWitt and J. Gray. </author> <title> Parallel database systems: the future of high-performance data base systems. </title> <journal> CACM, </journal> <volume> 35 </volume> <pages> 85-98, </pages> <year> 1992. </year>
Reference-contexts: This prediction is yet to be proven wrong, but is there reason for optimism? In recent years, multiprocessors based on inexpensive microprocessors, each with a large local memory ("shared nothing architectures"), allowed drastic increase in the size of fast memories, and led to a success of parallel data base systems <ref> [DG] </ref>, increasing the interest of that community in faster parallel computation. Hash partitioning of data and hash join appear to become main stream techniques in this context.
Reference: [DM] <editor> M. Dietzfelbinger and F. Meyer auf der Heide. </editor> <title> How to distribute a dictionary in a complete network. </title> <booktitle> In Proc. 22nd ACM Symp. on Theory of Comp., </booktitle> <pages> 117-127, </pages> <year> 1990. </year>
Reference-contexts: If w i m then with high probability we will have no more than say 2w i =m requests from any module (for a formal discussion see Fact 2 in <ref> [DM] </ref> which is based on an analysis by [KRS]).
Reference: [FKLMSY] <author> A. Fiat, R.M. Karp, M. Luby, L. McGeoch, D. Sleator, and N. Young. </author> <title> Competitive paging algorithms. </title> <journal> J. Algorithms, </journal> <volume> 12,4: </volume> <pages> 685-699, </pages> <year> 1991. </year>
Reference-contexts: We also note that our approach circumvents the need for on-line paging strategies as in <ref> [FKLMSY] </ref>. Our presentation proceeds as follows. Section 2.1 presents the main problem addressed in this paper. Section 2.2 outlines a measurement model, which enables quantifying the quality of a solution for the problem. Our broad thesis, and the concrete suggestion for the main problem, are described in Section 3.
Reference: [HP] <author> J.L. Hennessy and D.A. Patterson. </author> <title> Computer Architecture A Qualitative Approach. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, California, </address> <year> 1990. </year>
Reference-contexts: We use the term fetch unit as a generic name for a memory page, or a memory line, containing the desired element. For common organizations of main memory a typical value for A will be 5, <ref> [HP] </ref>. In case the secondary memory is on a disk these values are drastically higher (by [HP] one million (!) is a typical value). 1 The list-ranking example (revisited). <p> For common organizations of main memory a typical value for A will be 5, <ref> [HP] </ref>. In case the secondary memory is on a disk these values are drastically higher (by [HP] one million (!) is a typical value). 1 The list-ranking example (revisited). Under these assumptions, the implementation of the serial list-ranking algorithm takes at least nA time in the worst case, since there are at least n accesses to memory and all of them may be to secondary memory. <p> Also, it appears that the bus transfer time is unlikely to be a bottleneck, because the fetch unit size (or, in other words additional data that have to be transmitted along with a requested datum) is becoming smaller (see <ref> [HP] </ref>), permitting a more effective use of the bus bandwidth. At the same time, the present approach copes well with the fact that bus access time is less predictable. <p> Finally, we note that in case the secondary memory is main memory, this whole suggestion falls within the area of memory banks and interleaved memories (see the example concerning a Cray machine in Section 6 and <ref> [HP] </ref>). Next, we mention a possibility (which has limited promise by available technology because of throughput problems): it is possible to use a considerable number of disks for memory modules. (It appears that technology advances in the right direction, since it already enables effective use of over a hundred disks. <p> Use Direct Memory Access. See [Vi93]. 3. Other kinds of main memory. See [Vi93]. 4. Locality of reference. Following <ref> [HP] </ref>, we distinguish two kinds of locality of reference properties. (i) Locality in time: If an item is referenced, it will tend to be referenced again soon; and (ii) Locality in space: If an item is referenced, nearby items tend to be referenced soon. <p> The idea of random distribution of addresses on Cray-like memories appears to meet these throughput requirements, as explained in the next paragraph. * Hardware technology for implementation of random distribution of addresses. See <ref> [HP] </ref> regarding the the technology of memory banks. Since 1982 Cray machines have multiple memory pipelines. On the Cray X-MP (see [HJ]), one can make from 1 to 64 memory requests at a time.
Reference: [HJ] <author> R.W. Hockney and C.R. Jesshope. </author> <title> Parallel Computers 2. Adam Hilger, </title> <address> Philadelphia, PA, </address> <year> 1988. </year>
Reference-contexts: See [HP] regarding the the technology of memory banks. Since 1982 Cray machines have multiple memory pipelines. On the Cray X-MP (see <ref> [HJ] </ref>), one can make from 1 to 64 memory requests at a time. These memory requests do not have to be in any pattern, but can be scattered across memory. <p> Throughput bottlenecks occurred even at the Cray Y-MP [ZB], when interpreted as a parallel machine with 512 processors. (However, considering the Cray X-MP and Cray Y-MP machines as having between 1 and 8 Cray-1-like CPUs <ref> [HJ] </ref>, as we do in the present paper, alleviates throughput bottlenecks.) There might be some insight in observing that, for both serial and parallel processing, alleviating throughput bottlenecks is helpful for supporting a user-friendly language. Building a parallel machine that supports the PRAM is a considerable challenge.
Reference: [Ja] <author> J. JaJa. </author> <title> An Introduction to Parallel Algorithms. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1992. </year>
Reference-contexts: We do not expect the possible need for development of a new parallel algorithm to be a significant disadvantage: Parallel algorithmics has undergone major develop-ments in the last few years (for brevity, we reference here only <ref> [Ja] </ref> and [Vi94]). So parallel algorithms and techniques for many problems already exist. <p> A starting point for a weaker model than the PRAM for describing parallelism might be Informal Data-Parallelism, (originally presented in [SV] using Brent's theorem), as per [Vi94]; this has also been called the work-time presentation paradigm for parallel algorithms, as elucidated by the author in <ref> [Ja] </ref>. This paradigm suggests preceding a "full-PRAM" description of a parallel algorithm by a high-level description of work and time only. Specifically, this includes the operations to be performed at each parallel round, and even this can be done in an implicit way.
Reference: [Jo] <author> N. Jouppi. </author> <title> Improving direct-mapped cache performance by the addition of a small fully associative cache and prefetch buffers. </title> <booktitle> In Proc. 14th Annual Conf. Int. Symp. on Comp. Arch., </booktitle> <year> 1990. </year>
Reference-contexts: This curriculum update should occur in anticipation of future changes since one of the objectives of such a curriculum is to prepare young graduates for a life-time professional career. These thoughts led the author to work on [Vi94]. Prefetching in the context of hardware is discussed in <ref> [Jo] </ref> and references therein. A recent paper that advocates the use of software prefetching is [CKP]; a helpful heuristic that guides compilers to identify cases where prefetching is possible is suggested. This heuristic will not be able to identify opportunities for prefetching that are described in this paper.
Reference: [KRS] <author> C.P. Kruskal, L. Rudolph, and M. Snir. </author> <title> A complexity theory of efficient parallel algorithms. </title> <booktitle> In Theoretical Computer Science, </booktitle> <volume> 71 </volume> <pages> 95-132, </pages> <year> 1990. </year>
Reference-contexts: efficient parallel algorithms have been interested in designing optimal parallel algorithms (even if their run ning time could not be upper bounded by O (log k n), where n is the input length and k is a constant, as demonstrated in a 1977 thesis by Eckstein, [RC], [SV], [VS], and <ref> [KRS] </ref>). A notion of performance which is similar to the one of optimal algorithms, but not identical, is needed in the context of this paper. <p> If w i m then with high probability we will have no more than say 2w i =m requests from any module (for a formal discussion see Fact 2 in [DM] which is based on an analysis by <ref> [KRS] </ref>). Suppose the random distribution idea is applied and the values of w i and m imply the 2w i =m upper bound; with a slight abuse of the linear model, we apply it for evaluating the transmission time from a module to its cache.
Reference: [Mc] <author> E.M. McCreight. </author> <title> A space-economical suffix tree construction algorithm. </title> <journal> J. ACM, </journal> <volume> 23 </volume> <pages> 262-272, </pages> <year> 1976. </year>
Reference-contexts: High Performance Computing and Communication Program. The linear-time serial algorithms (by P. Weiner, or E.M. McCreight <ref> [Mc] </ref>), which are considered theoretically superior because of the asymptotic upper bounds on their running time, seem to suffer from the following problem: their memory access often depends on the preceding step, as in the serial depth-first search, or serial list-ranking algorithms.
Reference: [MV] <author> K. Mehlhorn, and U. Vishkin. </author> <title> Randomized and deterministic simulations of PRAMs by parallel machines with restricted granularity of parallel memories. </title> <journal> Acta Informatica, </journal> <volume> 21 </volume> <pages> 339-374, </pages> <year> 1984. </year>
Reference-contexts: This random distribution idea is implemented by randomly selecting a hash function from some set of easy-to-evaluate hash functions, as in <ref> [MV] </ref>. If w i m then with high probability we will have no more than say 2w i =m requests from any module (for a formal discussion see Fact 2 in [DM] which is based on an analysis by [KRS]). <p> Hash partitioning of data and hash join appear to become main stream techniques in this context. Note that <ref> [MV] </ref> actually suggested hash partitioning of memory addresses among the local memories of parallel processors as a general method for emulating a PRAM programmer's model on a similar shared nothing architecture! Facing problems which are similar to possible bottlenecks targeted by commercial data base applications is a reason for some optimism.
Reference: [MR] <author> M. Metcalf and J. Reid. </author> <title> Fortran 90 Explained. </title> <publisher> Oxford University Press, </publisher> <address> New York, </address> <year> 1990. </year>
Reference-contexts: Programming languages which enable to express parallelism should be available. Henceforth, we assume that such a programming language is available, since designing such a language is clearly doable. Actually, some languages already exist: FORTRAN 90 <ref> [MR] </ref> and SETL [BCHSZ] are two examples. For the user, this would mean the following. 1. Given a problem, and an algorithm for it, try to redesign the algorithm into an efficient parallel one.
Reference: [P] <author> C.M. Pancake. </author> <title> Software support for parallel computing: where are we headed? CACM, </title> <booktitle> 34,11: </booktitle> <pages> 53-64, </pages> <year> 1991. </year>
Reference-contexts: The only reasonable business decision under this circumstances is to write code for some existing robust programming language, which presently would mean a serial programming language. This lack of a robust language is part of the "par 8 allel software crisis" <ref> [P] </ref>. Following a meeting of an industry advisory board panel [P], pessimism is expressed about reaching agreement on a robust parallel programming language, because of the following. <p> This lack of a robust language is part of the "par 8 allel software crisis" <ref> [P] </ref>. Following a meeting of an industry advisory board panel [P], pessimism is expressed about reaching agreement on a robust parallel programming language, because of the following.
Reference: [RC] <author> E. Reghbati and D.G. Corneil. </author> <title> Parallel computations in graph theory. </title> <journal> SIAM J. Computing, </journal> <volume> 7: </volume> <pages> 230-237, </pages> <year> 1978. </year>
Reference-contexts: Typically, researchers on efficient parallel algorithms have been interested in designing optimal parallel algorithms (even if their run ning time could not be upper bounded by O (log k n), where n is the input length and k is a constant, as demonstrated in a 1977 thesis by Eckstein, <ref> [RC] </ref>, [SV], [VS], and [KRS]). A notion of performance which is similar to the one of optimal algorithms, but not identical, is needed in the context of this paper.
Reference: [SV] <author> Y. Shiloach and U. Vishkin. </author> <title> An O(nlog 2 n) parallel Max-Flow Algorithm. </title> <journal> J. Algorithms, </journal> <volume> 3 </volume> <pages> 128-146, </pages> <year> 1982. </year>
Reference-contexts: Typically, researchers on efficient parallel algorithms have been interested in designing optimal parallel algorithms (even if their run ning time could not be upper bounded by O (log k n), where n is the input length and k is a constant, as demonstrated in a 1977 thesis by Eckstein, [RC], <ref> [SV] </ref>, [VS], and [KRS]). A notion of performance which is similar to the one of optimal algorithms, but not identical, is needed in the context of this paper. <p> Observe that the whole processor allocation, which is an essential part of a PRAM algorithm, will typically not be such a serious issue for extracting the parallelism needed here. A starting point for a weaker model than the PRAM for describing parallelism might be Informal Data-Parallelism, (originally presented in <ref> [SV] </ref> using Brent's theorem), as per [Vi94]; this has also been called the work-time presentation paradigm for parallel algorithms, as elucidated by the author in [Ja]. This paradigm suggests preceding a "full-PRAM" description of a parallel algorithm by a high-level description of work and time only.
Reference: [St] <author> W. </author> <title> Stallings. </title> <journal> Handbook of Computer Communications Standards, </journal> <volume> Volume 2. </volume> <publisher> Macmillan, </publisher> <year> 1987. </year>
Reference-contexts: Another intriguing possibility is that of using, instead of disks, the fast memories of other computers that are connected by a local area network (LAN), such as an Ethernet, to the computer on which the algorithm under consideration is being run. By <ref> [St] </ref>, a computer on an Ethernet can send a block of over 1K bytes within roughly the same time (about 1ms) as sending a single byte; a more up-to-date technology allows several thousands bytes in a block.
Reference: [Va] <author> L.G. Valiant. </author> <title> General purpose parallel architectures. In Handbook of Theor. Comp. Sci.: Volume A, </title> <editor> (Editor J. van Leeuwen), </editor> <publisher> MIT Press/Elsevier, </publisher> <year> 1990, </year> <pages> 942-971. </pages>
Reference-contexts: As explained elsewhere (e.g., [Vi84a]), the PRAM should be viewed as a programmer's model for a parallel machine and not as a physical parallel machine, and improvement in the parallel running time of a PRAM algorithm can benefit us in reducing the actual running time in several ways. Specifically, <ref> [Va] </ref> (also in a CACM 1990 paper by L. Valiant) and [Vi84a] advocate slackness in processors as explained next. Suppose we are given an efficient PRAM algorithm and a (real) parallel machine with p 1 processors, on which we wish to simulate the algorithm.
Reference: [Vi84a] <author> U. Vishkin. </author> <title> A parallel-design distributed-implementation (PDDI) general purpose computer. </title> <journal> Theor. Comp. Sci., </journal> <volume> 32 </volume> <pages> 157-172, </pages> <year> 1984. </year>
Reference-contexts: Such a high-level description might be enough here. 6 Relevance for Parallel Computers Most of the above considerations are valid also for the design of a parallel machine that will support the PRAM model of parallel computation. This paragraph includes some background. As explained elsewhere (e.g., <ref> [Vi84a] </ref>), the PRAM should be viewed as a programmer's model for a parallel machine and not as a physical parallel machine, and improvement in the parallel running time of a PRAM algorithm can benefit us in reducing the actual running time in several ways. <p> Specifically, [Va] (also in a CACM 1990 paper by L. Valiant) and <ref> [Vi84a] </ref> advocate slackness in processors as explained next. Suppose we are given an efficient PRAM algorithm and a (real) parallel machine with p 1 processors, on which we wish to simulate the algorithm.
Reference: [Vi84b] <author> U. Vishkin. </author> <title> Randomized speed-ups in parallel computations. </title> <booktitle> In Proc. 16th Ann. ACM Symp. on Theory of Comp., </booktitle> <pages> 230-239, </pages> <year> 1984. </year>
Reference-contexts: The total number of operations of the serial list-ranking algorithm given earlier is 2. So, for the linear model for F , the comparison is between 8 (log n log log n)A + 8nB and 2nA. The simple randomized algorithms in [AM] and <ref> [Vi84b] </ref> achieve also similar performance. See [Vi93] for another example. 5 Caveats, Extensions and Discussion * Memory consistency. The main issue is how to avoid a situation where an outdated copy of an address is interpreted as having a correct value.
Reference: [Vi88] <author> U. Vishkin. </author> <title> PRAM algorithms: teach and preach. In collection of position papers, IBM-NSF Workshop on "Opportunities and Constraints of Parallel Computing", </title> <institution> IBM Almaden, </institution> <year> 1988. </year>
Reference-contexts: Since the computer science curriculum is meant to prepare young graduates for a life time career, it is timely to put on the agenda a curriculum update to include the topic of parallel algorithms. In <ref> [Vi88] </ref> I made the following prediction: A future parallel computer, which does not support the PRAM model of parallel computation (as a programmer's model), will not be competitive, as a general-purpose computer, with the strongest non parallel computer that will become available at the same time.
Reference: [Vi92] <author> U. Vishkin. </author> <title> A case for the PRAM as a standard programmer's model. </title> <booktitle> In Proc. 1st Heinz Nixdorf Symp. on Par. Arch. and Their Efficient Use, 1992, </booktitle> <volume> Vol. 678, </volume> <booktitle> Lect. Notes in Comp. </booktitle> <publisher> Sci., Springer, </publisher> <year> 1993. </year>
Reference-contexts: In contrast to this, our multi-stage approach is based on using a shared-memory parallel programming language already in its first stage. The companion paper <ref> [Vi92] </ref> considers this multistage approach and adds the following perspective. The new generation of "serial machines" is far from being literally serial. Each possible state of a machine can be described by listing the contents of all its data cells, where data cells include memory cells and registers.
Reference: [Vi93] <author> U. Vishkin. </author> <title> Can parallel algorithms enhance serial implementation? Univ. </title> <institution> of Maryland Inst. for Advanced Computer Studies, UMIACS-TR-91-145.1, </institution> <year> 1991, </year> <note> revised 1993. </note>
Reference-contexts: Use Direct Memory Access. See <ref> [Vi93] </ref>. 3. Other kinds of main memory. See [Vi93]. 4. Locality of reference. <p> Use Direct Memory Access. See <ref> [Vi93] </ref>. 3. Other kinds of main memory. See [Vi93]. 4. Locality of reference. Following [HP], we distinguish two kinds of locality of reference properties. (i) Locality in time: If an item is referenced, it will tend to be referenced again soon; and (ii) Locality in space: If an item is referenced, nearby items tend to be referenced soon. <p> Throughout this paper we elaborate only on a case where locality in space occurs, since as explained in <ref> [Vi93] </ref> we see no inherent reason for why locality in space should be satisfied in a "typical" serial program, but not in a serial emulation of a "typical" parallel program. <p> The total number of operations of the serial list-ranking algorithm given earlier is 2. So, for the linear model for F , the comparison is between 8 (log n log log n)A + 8nB and 2nA. The simple randomized algorithms in [AM] and [Vi84b] achieve also similar performance. See <ref> [Vi93] </ref> for another example. 5 Caveats, Extensions and Discussion * Memory consistency. The main issue is how to avoid a situation where an outdated copy of an address is interpreted as having a correct value. See [Vi93]. * How much parallelism depends on the serial machine and the algorithms. <p> The simple randomized algorithms in [AM] and [Vi84b] achieve also similar performance. See <ref> [Vi93] </ref> for another example. 5 Caveats, Extensions and Discussion * Memory consistency. The main issue is how to avoid a situation where an outdated copy of an address is interpreted as having a correct value. See [Vi93]. * How much parallelism depends on the serial machine and the algorithms. Figuring out which parallel algorithm yields the fastest running time on a serial computer, will involve a trade-off between the level of parallelism and the total number of operations (including constant factors). * Throughput.
Reference: [Vi94] <author> U. Vishkin. </author> <title> Thinking in Parallel: Some Basic Data-Parallel Algorithms and Techniques. </title> <journal> Monograph, </journal> <note> in preparation. </note>
Reference-contexts: We do not expect the possible need for development of a new parallel algorithm to be a significant disadvantage: Parallel algorithmics has undergone major develop-ments in the last few years (for brevity, we reference here only [Ja] and <ref> [Vi94] </ref>). So parallel algorithms and techniques for many problems already exist. <p> This curriculum update should occur in anticipation of future changes since one of the objectives of such a curriculum is to prepare young graduates for a life-time professional career. These thoughts led the author to work on <ref> [Vi94] </ref>. Prefetching in the context of hardware is discussed in [Jo] and references therein. A recent paper that advocates the use of software prefetching is [CKP]; a helpful heuristic that guides compilers to identify cases where prefetching is possible is suggested. <p> A starting point for a weaker model than the PRAM for describing parallelism might be Informal Data-Parallelism, (originally presented in [SV] using Brent's theorem), as per <ref> [Vi94] </ref>; this has also been called the work-time presentation paradigm for parallel algorithms, as elucidated by the author in [Ja]. This paradigm suggests preceding a "full-PRAM" description of a parallel algorithm by a high-level description of work and time only.
Reference: [VS] <author> J.S. Vitter, and R.A. Simmons. </author> <title> New classes for parallel complexity: a study of unification and other complete problems for P. </title> <journal> IEEE Trans. on Computers, </journal> <volume> C-35,5:403-418, </volume> <year> 1986. </year>
Reference-contexts: researchers on efficient parallel algorithms have been interested in designing optimal parallel algorithms (even if their run ning time could not be upper bounded by O (log k n), where n is the input length and k is a constant, as demonstrated in a 1977 thesis by Eckstein, [RC], [SV], <ref> [VS] </ref>, and [KRS]). A notion of performance which is similar to the one of optimal algorithms, but not identical, is needed in the context of this paper. <p> Next, we provide a parallel variant of this algorithm. While unaware of a reference, we will not be surprised if this variant has appeared in print. A variant that uses concurrent writes by several processors to the same memory location is given in <ref> [VS] </ref>, and one that uses more space is given in a 1977 University of Iowa Doctoral Thesis by D. Eckstein.
Reference: [ZB] <author> M. Zagha and G.E. Blelloch. </author> <title> Radix sort of vector multiprocessors. </title> <booktitle> In Proc. Supercomp. </booktitle> <volume> 91. </volume> <pages> 10 </pages>
Reference-contexts: It is interesting to mention that following experiments with implementation of parallel sorting algorithms, it has been observed that "throughput bottlenecks of this nature" exist in modern parallel machines such as the CM-2, by Thinking Machines Corporation [BLMPSZ]. Throughput bottlenecks occurred even at the Cray Y-MP <ref> [ZB] </ref>, when interpreted as a parallel machine with 512 processors. (However, considering the Cray X-MP and Cray Y-MP machines as having between 1 and 8 Cray-1-like CPUs [HJ], as we do in the present paper, alleviates throughput bottlenecks.) There might be some insight in observing that, for both serial and parallel
References-found: 33

