URL: http://www-psrg.lcs.mit.edu/ftpdir/rweiss/structured_video_tr.ps
Refering-URL: http://www.psrg.lcs.mit.edu/Projects/AVS/intro.html
Root-URL: 
Title: Structured Video: A Data Type with Content-Based Access  
Author: Andrzej Duda Ron Weiss 
Note: Also with Bull-IMAG Systemes, and INRIA This research was sponsored by the Defense Advanced Research Projects Agency (DARPA) under contract DABT63-92-C-0012. The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies, either expressed or implied, of the Defense Advanced Research Projects Agency or the U.S. Government.  
Address: Cambridge, MA 02139  
Affiliation: Laboratory for Computer Science Massachusetts Institute of Technology  
Date: September 1993  
Pubnum: MIT/LCS/TR-580  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> David K. Gifford, Pierre Jouvelot, Mark A. Sheldon, and James W. O'Toole. </author> <title> Semantic file systems. </title> <booktitle> In Thirteenth ACM Symposium on Operating Systems Principles. ACM, </booktitle> <month> October </month> <year> 1991. </year> <title> Available as Operating Systems Review Volume 25, Number 5. </title>
Reference-contexts: The system offers a query based interface for searching and playback of relevant video segments (see Figure 2). Our implementation is based on two subsystems: VuSystem [10] a toolkit for recording, manipulating and playing video, and the Semantic File System <ref> [1] </ref> a storage subsystem with content-based access to data.
Reference: [2] <author> R. Hamakawa and J. Rekimoto. </author> <title> Object composition and playback models for handling multimedia data. </title> <booktitle> In Proc. First ACM Int'l Conference on Multimedia., </booktitle> <pages> pages 273-281, </pages> <address> Anaheim, CA, </address> <month> August </month> <year> 1993. </year>
Reference-contexts: Multimedia authoring systems such as CMIFed [12] have rich structuring primitives for multimedia documents, but fail to address the structure of the video data itself. Hamakawa and Rekimoto <ref> [2] </ref> propose a multimedia authoring system that supports editing and reuse of multimedia data. Their system is based on a hierarchical and compositional model of multimedia objects. It allows the user to mark objects with a title at a certain point in time.
Reference: [3] <author> T.D.C Little, G. Ahanger, R.J. Folz, J.F. Gibbon, F.W. Reeve, D.H. Schelleng, and D. Venkatesh. </author> <title> A digital on-demand video service supporting content-based queries. </title> <booktitle> In ACM, First Multimedia Conference., </booktitle> <address> Anaheim, California, </address> <month> August </month> <year> 1993. </year> <note> ACM. </note>
Reference-contexts: A drawback of the stratification mechanism is 2 the absence of relationships between the strata. Our system provides a full hierarchical organization of video footage that permits flexible browsing. Little, et al. <ref> [3] </ref> implemented a system that supports content-based retrieval of video footage. They define a specific data schema composed of movie, scene and actor relations with a fixed set of attributes. The system requires manual feature extraction, and then fits these features into the data schema.
Reference: [4] <author> J.K. Ousterhout. </author> <title> An x11 toolkit based on the tcl language. </title> <booktitle> In USENIX Association 1991 Winter Conference Proceedings, </booktitle> <pages> pages 105-115, </pages> <address> Dal-las, TX, </address> <month> January </month> <year> 1991. </year>
Reference-contexts: The VuSys-tem provides an environment for recording, processing and playing video. A set of C++ classes manage basic functions such as synchronizing video streams, displaying in a window, and processing video streams. TCL <ref> [4] </ref> scripts control C++ classes and offer a programmable user interface that can be customized. For example, our structured video browser is written as a TCL script.
Reference: [5] <author> Roger Price. Mheg: </author> <title> An introduction to the future international standard for hypermedia object interchange. </title> <booktitle> In Proc. First ACM Int'l Conference on Multimedia., </booktitle> <pages> pages 121-128, </pages> <address> Anaheim, CA, </address> <month> August </month> <year> 1993. </year>
Reference-contexts: Their system is based on a hierarchical and compositional model of multimedia objects. It allows the user to mark objects with a title at a certain point in time. However, it does not support a fully functional free form annotation mechanism that enables subsequent content-based access. The MHEG <ref> [5] </ref> multimedia and hypermedia standard is intended for final formatted documents, and lacks mechanisms for content-based access, editing and annotation of the multimedia data. In our approach, the context of video segments is represented in the organization of and hierarchical relations between the structured video nodes.
Reference: [6] <author> T.G. Aguierre Smith and G. Davenport. </author> <title> The stratification system: A design environment for random access video. </title> <booktitle> In Proc. 3rd International 16 Workshop on Network and Operating System Support for Digital Audio and Video., </booktitle> <address> La Jolla, CA, </address> <month> November </month> <year> 1992. </year>
Reference-contexts: The structured video is indexed in a manner that preserves the correspondence between video segments so that all relevant segments and their neighbors can be efficiently found. 1.1 Related Work In related work, Davenport, Aguierre Smith and Pincever <ref> [6, 7] </ref> implemented a video annotation system. It uses the concept of stratification to assign descriptions to video footage, where each stratum refers to a sequence of video frames. The strata may overlap or totally encompass each other. <p> Nested Stratification Figure 1 illustrates segments of a structured video node that point to overlapping portions of video data. This overlap enables the user to assign multiple meanings to the same footage, and serves the 7 same purpose as the stratification mechanism described in <ref> [6] </ref>. Individual video segments that overlap are indexed by the system separately. A query may yield a structured video result that incorporates multiple segments when the query matches more than one segment. Other queries can result in structured video that corresponds to only one of these segments.
Reference: [7] <author> T.G. Aguierre Smith and N.C. Pincever. </author> <title> Parsing movies in context. </title> <booktitle> In Proc Summer 1991 Usenix Conference., </booktitle> <pages> pages 157-168, </pages> <address> Nashville, Tennessee, </address> <month> June </month> <year> 1991. </year>
Reference-contexts: The structured video is indexed in a manner that preserves the correspondence between video segments so that all relevant segments and their neighbors can be efficiently found. 1.1 Related Work In related work, Davenport, Aguierre Smith and Pincever <ref> [6, 7] </ref> implemented a video annotation system. It uses the concept of stratification to assign descriptions to video footage, where each stratum refers to a sequence of video frames. The strata may overlap or totally encompass each other.
Reference: [8] <author> D. Swanberg, C.F. Chu, and R. Jain. </author> <title> Architecture of a multimedia information system for content-based retrieval. </title> <booktitle> In Proc. 3rd International Workshop on Network and Operating System Support for Digital Audio and Video., </booktitle> <address> La Jolla, CA, </address> <month> November </month> <year> 1992. </year>
Reference-contexts: For example, users cannot create a new movie from the collection of scenes that are returned as a result of a query. Moreover, the browser does not support queries based on the temporal ordering of scenes. Swanberg, et al. <ref> [8, 9] </ref> defines an architecture for parsing data semantics from the video stream. It uses a fixed set of video elements (including a shot and an episode), and is not suitable for free form modeling of the complex relations between video segments.
Reference: [9] <author> D. Swanberg, C.F. Chu, and R. Jain. </author> <title> Knowledge guided parsing in video datbases. </title> <booktitle> In IS&/SPIE's Symposium on Electronic Imaging: Science & Technology, </booktitle> <address> San Jose, CA, </address> <month> January </month> <year> 1993. </year>
Reference-contexts: For example, users cannot create a new movie from the collection of scenes that are returned as a result of a query. Moreover, the browser does not support queries based on the temporal ordering of scenes. Swanberg, et al. <ref> [8, 9] </ref> defines an architecture for parsing data semantics from the video stream. It uses a fixed set of video elements (including a shot and an episode), and is not suitable for free form modeling of the complex relations between video segments.
Reference: [10] <author> David K. Tennenhouse. Telemedia, </author> <title> networks and systems group annual report. </title> <type> Technical Report MIT/LCS/AR-001, </type> <institution> MIT Laboratory for Computer Science, </institution> <month> June </month> <year> 1992. </year>
Reference-contexts: We have implemented a structured video system that extracts video attribute information and supports content-based access, as well as video playback. The system offers a query based interface for searching and playback of relevant video segments (see Figure 2). Our implementation is based on two subsystems: VuSystem <ref> [10] </ref> a toolkit for recording, manipulating and playing video, and the Semantic File System [1] a storage subsystem with content-based access to data.
Reference: [11] <author> L. Teodosio and W. Bender. </author> <title> Salient video stills: Content and context preserved. </title> <booktitle> In Proc. First ACM Int'l Conference on Multimedia., </booktitle> <pages> pages 39-46, </pages> <address> Anaheim, CA, </address> <month> August </month> <year> 1993. </year>
Reference-contexts: For example, the nodes pointing to an unstructured video segment may contain close-captioned text recorded by the system. The user may add other attributes, such as title, author, characters, and the scene summary. Descriptions can also be non-textual such as key frames, icons, and salient stills <ref> [11] </ref>. The scope of a given structured video node description is the subgraph that originates from the node. 5 2.2 Video Algebra A structured video node controls the temporal playback characteristics of its children. There are two methods of expressing these characteristics: relative time coordinates and video algebra.
Reference: [12] <author> G. van Rossum and et al. Cmifed: </author> <title> A presentation environment for portable hypermedia documents. </title> <booktitle> In Proc. First ACM Int'l Conference on Multimedia., </booktitle> <pages> pages 183-188, </pages> <address> Anaheim, CA, </address> <month> August </month> <year> 1993. </year> <month> 17 </month>
Reference-contexts: It uses a fixed set of video elements (including a shot and an episode), and is not suitable for free form modeling of the complex relations between video segments. Multimedia authoring systems such as CMIFed <ref> [12] </ref> have rich structuring primitives for multimedia documents, but fail to address the structure of the video data itself. Hamakawa and Rekimoto [2] propose a multimedia authoring system that supports editing and reuse of multimedia data. Their system is based on a hierarchical and compositional model of multimedia objects.
References-found: 12

