URL: http://www.cs.cmu.edu/~necula/lics98.ps.gz
Refering-URL: http://www.cs.cmu.edu/~necula/cv.html
Root-URL: 
Email: fnecula,petelg@cs.cmu.edu  
Title: Efficient Representation and Validation of Proofs  
Author: George C. Necula Peter Lee 
Address: Pittsburgh, Pennsylvania 15213-3891  
Affiliation: School of Computer Science Carnegie Mellon University  
Abstract: This paper presents a logical framework derived from the Edinburgh Logical Framework (LF) [5] that can be used to obtain compact representations of proofs and efficient proof checkers. These are essential ingredients of any application that manipulates proofs as first-class objects, such as a Proof-Carrying Code [11] system, in which proofs are used to allow the easy validation of properties of safety-critical or untrusted code. Our framework, which we call LF i , inherits from LF the capability to encode various logics in a natural way. In addition, the LF i framework allows proof representations without the high degree of redundancy that is characteristic of LF representations. The missing parts of LF i proof representations can be reconstructed during proof checking by an efficient reconstruction algorithm. We also describe an algorithm that can be used to strip the unnecessary parts of an LF representation of a proof. The experimental data that we gathered in the context of a Proof-Carrying Code system shows that the savings obtained from using LF i instead of LF can make the difference between practically useless proofs of several megabytes and manageable proofs of tens of kilobytes. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Abadi, M., Cardelli, L., Curien, P.-L., and L evy, J.-J. </author> <title> Explicit substitutions. </title> <journal> Journal of Functional Programming 1, </journal> <month> 4 (Oct. </month> <year> 1991), </year> <pages> 375-416. </pages>
Reference-contexts: A more detailed presentation of the implementation can be found in [13]. Our implementation of LF i reconstruction is based on explicit substitutions <ref> [1] </ref> and deBruijn indices [2].
Reference: [2] <author> DeBruijn, N. </author> <title> Lambda-calculus notation with nameless dummies, a tool for automatic formula manipulation. </title> <journal> Indag. Mat. </journal> <volume> 34 (1972), </volume> <pages> 381-392. </pages>
Reference-contexts: A more detailed presentation of the implementation can be found in [13]. Our implementation of LF i reconstruction is based on explicit substitutions [1] and deBruijn indices <ref> [2] </ref>.
Reference: [3] <author> Dowek, G., Felty, A., Herbelin, H., Huet, G. P., Murthy, C., Parent, C., Paulin-Mohring, C., and Werner, B. </author> <title> The Coq proof assistant user's guide. Version 5.8. </title> <type> Tech. rep., </type> <institution> IN-RIA - Rocquencourt, </institution> <month> May </month> <year> 1993. </year>
Reference-contexts: Furthermore, in the presence of interpreted function symbols and arithmetic (as is always the case in the PCC proofs) the tautology checking problem can easily become undecidable. The argument synthesis and term reconstruction algorithms implemented in the LEGO [6, 18] and Coq <ref> [3] </ref> proof assistants are less effective than our algorithm, in the sense that fewer proof subterms can be omitted from the proof representation, and therefore more redundancy has to be tolerated.
Reference: [4] <author> Elliott, C. </author> <title> Higher-order unification with dependent types. In Rewriting Techniques and Applications (Chapel Hill, </title> <publisher> North Carolina, </publisher> <month> Apr. </month> <year> 1989), </year> <editor> N. Dershowitz, Ed., </editor> <publisher> Springer-Verlag LNCS 355, </publisher> <pages> pp. 121-136. </pages>
Reference: [5] <author> Harper, R., Honsell, F., and Plotkin, G. </author> <title> A framework for defining logics. </title> <journal> Journal of the Association for Computing Machinery 40, </journal> <month> 1 (Jan. </month> <year> 1993), </year> <pages> 143-184. </pages>
Reference-contexts: In a Proof-Carrying Code system, as well as in any application involving the explicit manipulation of proofs, it is of utmost importance that the proof representation is compact and the proof checking is efficient. In this paper we present a logical framework derived from the Edinburgh Logical Framework <ref> [5] </ref>, along with associated proof representation and proof checking algorithms, that have the following desirable properties: * The framework can be used to encode judgments and derivations from a wide variety of logics, in cluding first-order and higher-order logics. * The proof checker performs a directed, one-pass inspection of the proof <p> For reasons of space, we omit many interesting details that can be found in the expanded version of this paper [13]. 2 The Edinburgh Logical Framework The Edinburgh Logical Framework (also referred to as LF) has been introduced by Harper, Honsell and Plotkin <ref> [5] </ref> as a metalanguage for high-level specification of logics. LF provides natural support for the management of binding operators and of the hypothetical and schematic judgments through LF bound variables. This is a crucial factor for the succinct formalization of proofs. <p> type-checking judgment is written as ` LF where is a type environment for the free variables of M and A. 1 A definition of LF type checking, along with a proof of adequacy of using LF type checking for proof validation for first-order and higher-order logics, can be found in <ref> [5] </ref>.
Reference: [6] <author> Luo, Z., and Pollack, R. </author> <title> The LEGO proof development system: A user's manual. </title> <type> Tech. Rep. </type> <institution> ECS-LFCS-92-211, University of Edinburgh, </institution> <month> May </month> <year> 1992. </year>
Reference-contexts: Furthermore, in the presence of interpreted function symbols and arithmetic (as is always the case in the PCC proofs) the tautology checking problem can easily become undecidable. The argument synthesis and term reconstruction algorithms implemented in the LEGO <ref> [6, 18] </ref> and Coq [3] proof assistants are less effective than our algorithm, in the sense that fewer proof subterms can be omitted from the proof representation, and therefore more redundancy has to be tolerated.
Reference: [7] <author> Michaylov, S., and Pfenning, F. </author> <title> An empiri-cal study of the runtime behavior of higher-order logic programs. </title> <booktitle> In Proceedings of the Workshop on the Prolog Programming Language (Philadel-phia, </booktitle> <address> Pennsylvania, </address> <month> July </month> <year> 1992), </year> <editor> D. Miller, Ed., </editor> <publisher> University of Pennsylvania, </publisher> <pages> pp. 257-271. </pages> <note> Available as Technical Report MS-CIS-92-86. </note>
Reference-contexts: If initially the cost of the occurs-check was 44% of the whole reconstruction time, the optimization reduces it to only 2%, thus eliminating over 90% of the cost of occurs checks. These results are consistent with those presented in <ref> [7] </ref>. <p> However, the restrictions of L are too strict for our purposes because they prevent the free use of higher-order abstract syntax in the representation of predicates and proofs, requiring instead costly <ref> [7, 8] </ref> explicit implementations of substitution. In our framework we can still make use of all the representation techniques of the full LF language, and thus gain leverage from substitution in the meta-language, because the restrictions are imposed only on which subterms might be missing from the representation.
Reference: [8] <author> Michaylov, S., and Pfenning, F. </author> <title> Higher-order logic programming as constraint logic programming. </title> <booktitle> In PPCP'93: First Workshop on Principles and Practice of Constraint Programming (New-port, </booktitle> <address> Rhode Island, </address> <month> Apr. </month> <title> 1993), </title> <publisher> Brown University, </publisher> <pages> pp. 221-229. </pages>
Reference-contexts: However, the restrictions of L are too strict for our purposes because they prevent the free use of higher-order abstract syntax in the representation of predicates and proofs, requiring instead costly <ref> [7, 8] </ref> explicit implementations of substitution. In our framework we can still make use of all the representation techniques of the full LF language, and thus gain leverage from substitution in the meta-language, because the restrictions are imposed only on which subterms might be missing from the representation.
Reference: [9] <author> Miller, D. </author> <title> A logic programming language with lambda-abstraction, function variables, and simple unification. </title> <journal> Journal of Logic and Computation 1, </journal> <month> 4 (Sept. </month> <year> 1991), </year> <pages> 497-536. </pages>
Reference-contexts: The design of the language L <ref> [9] </ref> also relies on syntactic restrictions for the purpose of eliminating the need for higher-order unification during type checking.
Reference: [10] <author> Miller, D. A. </author> <title> A compact representation of proofs. </title> <journal> Studia Logica 46, </journal> <volume> 4 (1987), </volume> <pages> 347-370. </pages>
Reference-contexts: Miller <ref> [10] </ref> suggests an extreme approach where the proof object records only the substitutions for the quantifiers, relying on the decidability of the tautology of the resulting matrix. This leads to very compact proof representations at the expense of an NP-complete tautology checking problem.
Reference: [11] <author> Necula, G. C. </author> <title> Proof-carrying code. </title> <booktitle> In The 24th Annual ACM Symposium on Principles of Programming Languages (Jan. 1997), ACM, </booktitle> <pages> pp. 106-119. </pages>
Reference-contexts: Another direct use of explicit proof objects is in the context of Proof-Carrying Code (PCC) <ref> [11] </ref>, which is a technique for safe execution of untrusted code. PCC requires the code producer to attach to the code a formal proof attesting that the code meets a safety specification that is published in advance by the code receiver. <p> Some of the published case studies discuss the uses of PCC in extensible operating systems [12], for safe interaction between components written in safe languages and native code <ref> [11] </ref> and for systems based on mobile-code agents [14].
Reference: [12] <author> Necula, G. C., and Lee, P. </author> <title> Safe kernel extensions without run-time checking. </title> <booktitle> In Second Symposium on Operating Systems Design and Implementations (Oct. 1996), Usenix, </booktitle> <pages> pp. 229-243. </pages>
Reference-contexts: Some of the published case studies discuss the uses of PCC in extensible operating systems <ref> [12] </ref>, for safe interaction between components written in safe languages and native code [11] and for systems based on mobile-code agents [14]. <p> accompanies the untrusted code as part of a proof-carrying code is the key element that enables the enforcement of a wide variety of safety policies, ranging from simple memory safety and type safety to resource-usage bounds, without the performance penalties incurred by the approaches based on interpretation or run-time checking <ref> [12] </ref>. In a Proof-Carrying Code system, as well as in any application involving the explicit manipulation of proofs, it is of utmost importance that the proof representation is compact and the proof checking is efficient.
Reference: [13] <author> Necula, G. C., and Lee, P. </author> <title> Efficient representation and validation of logical proofs. </title> <type> Technical Report CMU-CS-97-172, </type> <institution> Computer Science Department, Carnegie Mellon University, </institution> <month> Oct. </month> <year> 1997. </year>
Reference-contexts: For reasons of space, we omit many interesting details that can be found in the expanded version of this paper <ref> [13] </ref>. 2 The Edinburgh Logical Framework The Edinburgh Logical Framework (also referred to as LF) has been introduced by Harper, Honsell and Plotkin [5] as a metalanguage for high-level specification of logics. <p> For a more detailed discussion, including the complete proofs of soundness, we refer the interested reader to <ref> [13] </ref>. <p> The reader can verify that this algorithm for computing representation recipes generates the results shown in Figure 7. The interested reader can find in <ref> [13] </ref> two more representation algorithms, one simpler and one more complex. All these representation algorithms yield implicit objects that are suitable for the reconstruction algorithm discussed in Section 4. We do not show here proofs of correctness of the representation algorithm. <p> A more detailed presentation of the implementation can be found in <ref> [13] </ref>. Our implementation of LF i reconstruction is based on explicit substitutions [1] and deBruijn indices [2].
Reference: [14] <author> Necula, G. C., and Lee, P. </author> <title> Safe, untrusted agents using proof-carrying code. In Special Issue on Mobile Agent Security (Jan. </title> <note> 1998), G. Vigna, Ed., Springer-Verlag LNCS. To appear. </note>
Reference-contexts: Some of the published case studies discuss the uses of PCC in extensible operating systems [12], for safe interaction between components written in safe languages and native code [11] and for systems based on mobile-code agents <ref> [14] </ref>.
Reference: [15] <author> Pfenning, F. </author> <title> Logic programming in the LF logical framework. In Logical Frameworks (1991), </title> <editor> G. Huet and G. Plotkin, Eds., </editor> <publisher> Cambridge University Press, </publisher> <pages> pp. 149-181. </pages>
Reference-contexts: In fact, the Elf reconstruction algorithm is more powerful than ours because it does not impose any restriction on which terms can be missing from the proof. To achieve this flexibility, Elf type reconstruction uses an incomplete algorithm based on constraint solving <ref> [16, 15] </ref>.
Reference: [16] <author> Pfenning, F. </author> <title> Unification and anti-unification in the Calculus of Constructions. </title> <booktitle> In Sixth Annual IEEE Symposium on Logic in Computer Science (Amsterdam, </booktitle> <address> The Netherlands, </address> <month> July </month> <year> 1991), </year> <pages> pp. 74-85. </pages>
Reference-contexts: The condition Dom () Dom () from the atom rule requires that all placeholder variables introduced during constraint collection have been instantiated during local constraint solving. In this respect, our algorithm is less powerful than that used by Elf <ref> [16] </ref>, which can postpone unsolved constraints. This restriction does not seem to limit the power of our algorithm for reconstructing implicit proof representations while eliminating the need for the machinery for managing postponed constraints. <p> In fact, the Elf reconstruction algorithm is more powerful than ours because it does not impose any restriction on which terms can be missing from the proof. To achieve this flexibility, Elf type reconstruction uses an incomplete algorithm based on constraint solving <ref> [16, 15] </ref>.
Reference: [17] <author> Pfenning, F. </author> <title> Elf: A meta-language for deductive systems (system description). </title> <booktitle> In 12th International Conference on Automated Deduction (Nancy, </booktitle> <address> France, June 26-July 1, </address> <year> 1994), </year> <editor> A. Bundy, Ed., </editor> <publisher> LNAI 814, Springer-Verlag, </publisher> <pages> pp. 811-815. </pages>
Reference-contexts: Our algorithm is able to synthesize more proof subterms by using information both from the context and from the predicate that the proof is supposed to prove. The implementation of Elf <ref> [17] </ref>, a logic programming language based on LF, contains a reconstruction algorithm that is similar to the one presented here in the sense that missing application arguments can be recovered both from the type of the application (inherited arguments) and from the other arguments of the same application (synthesized arguments).
Reference: [18] <author> Pollack, R. </author> <title> Implicit syntax. </title> <booktitle> Informal Proceedings of First Workshop on Logical Frameworks, </booktitle> <address> An-tibes, </address> <month> May </month> <year> 1990. </year> <month> 11 </month>
Reference-contexts: Furthermore, in the presence of interpreted function symbols and arithmetic (as is always the case in the PCC proofs) the tautology checking problem can easily become undecidable. The argument synthesis and term reconstruction algorithms implemented in the LEGO <ref> [6, 18] </ref> and Coq [3] proof assistants are less effective than our algorithm, in the sense that fewer proof subterms can be omitted from the proof representation, and therefore more redundancy has to be tolerated.
References-found: 18

