URL: http://www.mli.gmu.edu/~bloedorn/papers/mli91-12.ps.gz
Refering-URL: http://www.mli.gmu.edu/~bloedorn/pubs.html
Root-URL: 
Title: CONSTRUCTIVE INDUCTION FROM DATA IN AQ17-DCI: Further Experiments  
Author: Eric Bloedorn and Ryszard S. Michalski 
Date: December 1991  
Address: Fairfax, VA 22030  
Affiliation: Artificial Intelligence Center George Mason University  
Pubnum: MLI 91-12  
Abstract-found: 0
Intro-found: 1
Reference: <author> F. Bergadano, S. Matwin, R.S. Michalksi, and J. Zhang, </author> <title> Learning Two-Tiered Descriptions of Flexible Concepts: The POSEIDON System, Reports of Machine Learning and Inference Laboratory, </title> <type> MLI 90-10, </type> <institution> Center for Artificial Intelligence, George Mason University, Fairfax, VA, </institution> <year> 1990. </year>
Reference-contexts: Results from testing AQ17-DCI, AQ14, POSEIDON, ASSISTANT and a simple-exemplar based method on the 1981 data and AQ17-DCI and AQ14 on the 1984 data are shown in table 8. The results for POSEIDON, ASSISTANT, and the exemplar method are taken from <ref> (Bergadano et al, 1990) </ref>. Results for AQ17-DCI, and AQ14 are overall percent correct first rank results from ATEST (see section 5.1 for description of ATEST). AQ17-DCI 95.9 % POSEIDON ASSISTANT Simple exemplar based method 92 % 86 % - - 93.1 % Program Percentage Correct Classification Table 8.
Reference: <author> G.H. Greene, </author> <title> Quantitative Discovery: Using Dependencies to Discover NonLinear Terms, M.S. </title> <type> Thesis, </type> <institution> University of Illinois at Urbana-Champaign, </institution> <year> 1988. </year>
Reference-contexts: There are a number of other programs which perform constructive induction. One of the first programs to exhibit some constructive induction abilities was INDUCE (Michalksi, 1980) which generated new attributes or predicates by applying "constructive generalization rules". BACON.1 (Langley, Bradshaw and Simon, 1983), and ABACUS.2 <ref> (Greene, 1988) </ref> are quantitative discovery programs which search for mathematical relationships that summarize all of the data.
Reference: <author> G. Jensen, "SYM-1: </author> <title> A Program that Detects Symmetry of Variable-Valued Logic Functions", </title> <institution> UIUCDCS-R-75-729, Department of Computer Science, University of Illinois at Urbana-Champaign, </institution> <year> 1975. </year>
Reference-contexts: This stage of the algorithm is constructs sums of binary attributes, which is equivalent to searching for m of n concepts. Stage II is partially based on ideas found in SYM-1 <ref> (Jensen, 1975) </ref>. Stage I 1. Identify in the data all attributes that are linear. 2. Repeat steps 3 through 5 for each possible attribute pair. 3. Repeat steps 4 and 5 for each binary mathematical, or relational operator. (operators available include addition, subtraction, multiplication, division, and relation) 4.
Reference: <author> C. J. Matheus, and L.A. Rendell, </author> <title> Constructive Induction on Decision Trees, </title> <booktitle> In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <pages> pp. 645-650, </pages> <year> 1989. </year>
Reference-contexts: Other similar efforts include CITRE <ref> (Matheus and Rendell, 1989) </ref> which constructs new terms using the repeated application of boolean operators to nodes on the positively labelled branches. An approach which uses boolean and arithmetic combinations of the original attributes to extend the initial attribute set is proposed by Utgoff (Utgoff, 1986).
Reference: <author> R.S. Michalski, </author> <title> Recognition of Total or Partial Symmetry in a Completely or Incompletely Secefies Switching Function, </title> <booktitle> Proceedings of the IV Congress of the International Federation on Automatic Control (IFAC), Vol. 27 (Finite Automata and Switching Systems), </booktitle> <pages> pp. 109-129, </pages> <address> Warsaw, </address> <month> June 16-21, </month> <year> 1969. </year>
Reference-contexts: This search is guided by a rule preference criterion. The program is based on the AQ algorithm for solving the general covering problem <ref> (Michalski, 1969) </ref>. A detailed description of the data-driven method is given in section 3, and a brief review of the AQ algorithm is given in section 4. A drawback of programs that cannot construct new attributes is an inability to take advantage of some fairly simple relationships.
Reference: <editor> R.S. Michalski, </editor> <booktitle> On the Quasi-Minimal Solution of the Covering Problem Proceedings of the V International Symposium on Information Processing (FCIP 69), Vol. A3 (Switching Circuits), Bled, Yugoslavia, </booktitle> <pages> pp. 125-128, </pages> <year> 1969. </year>
Reference-contexts: This search is guided by a rule preference criterion. The program is based on the AQ algorithm for solving the general covering problem <ref> (Michalski, 1969) </ref>. A detailed description of the data-driven method is given in section 3, and a brief review of the AQ algorithm is given in section 4. A drawback of programs that cannot construct new attributes is an inability to take advantage of some fairly simple relationships.
Reference: <author> R.S. Michalski and B.H. McCormick, </author> <title> Interval Generalization of Switching Theory. </title> <type> Report No. 442, </type> <institution> Dept. of Computer Science, University of Illinois, Urbana. </institution> <year> 1971. </year>
Reference: <editor> R.S. Michalski, </editor> <booktitle> Variable-Valued Logic: System VL 1 , Proceedings of the 1974 International Symposium on Multiple-Valued Logic, </booktitle> <pages> pp. 323-346. </pages> <institution> West Virginia University, Morgantown, </institution> <year> 1974. </year>
Reference-contexts: The description of a class is expressed using the variable-valued logic system 1 (VL 1 ), which is a multiple-valued logic propositional calculus with typed variables <ref> (Michalski, 1974) </ref>. A class description is called a cover which is a disjunction of complexes describing all positive examples and none of the negative examples. A complex is a conjunction of selectors, and is the simplest statement in VL 1 .
Reference: <author> R.S. Michalski and J.B. Larson, </author> <title> Selection of Most Representative Training Examples and Incremental Generation of VL 1 Hypotheses: the underlying methodology and the description of programs ESEL and AQ11, </title> <type> Report No. 867, </type> <institution> Dept. of Computer Science, University of Illinois, Urbana, </institution> <year> 1978. </year>
Reference-contexts: The criteria may be simplicity of description (measured by the number of variables used), cost (the sum of the given costs of the individual variables), or other criteria <ref> (Michalski and Larson, 1978) </ref>. The description of a class is expressed using the variable-valued logic system 1 (VL 1 ), which is a multiple-valued logic propositional calculus with typed variables (Michalski, 1974).
Reference: <author> R.S. Michalski, </author> <title> Pattern Recognition as Rule-Guided Inductive Inference, </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, PAMI, </journal> <volume> vol 2, No. 4, pp.349-361, </volume> <year> 1980. </year>
Reference: <author> T. Mitchell, Utgoff, P. and Banerji, R., </author> <title> "Learning by Experimentation: Acquiring and Refining ProblemSolving Heuristics," in Machine Learning: An Artificial Intelligence Approach, </title> <editor> R. Michalski, </editor> <publisher> J. </publisher>
Reference: <editor> Carbonell, and T. Mitchell (eds.), </editor> <publisher> Morgan Kaufman, </publisher> <address> Los Altos, CA, </address> <year> 1983. </year>
Reference: <author> I. Mozetic, "NEWGEM: </author> <title> Program for Learning from Examples - Program Documentation and Users Guide, </title> <type> Report No. </type> <institution> UIUCDCS-F-85-949, Department of Computer Science, University of Illinois at Urbana-Champaign, </institution> <year> 1986. </year>
Reference: <author> S. Muggleton, "Duce, </author> <title> an Oracle-Based Approach to Constructive Induction", </title> <booktitle> Proceedings of IJCAI-87, </booktitle> <pages> pp. 287-292, </pages> <publisher> Morgan Kaufman, </publisher> <address> Milan, Italy, </address> <year> 1987. </year>
Reference-contexts: Other programs include the LEX system for acquiring and refining problemsolving heuristics (Mitchell, Utgoff and Banerji, 1983), Schlimmer's STAGGER (Schlimmer, 1986), which uses three learning modules, Muggleton's Duce <ref> (Muggleton, 1987) </ref> which is an oracle based approach and Pagallo and Haussler's FRINGE, GREEDY3 and GROVE (Pagallo and Haussler, 1990). Other similar efforts include CITRE (Matheus and Rendell, 1989) which constructs new terms using the repeated application of boolean operators to nodes on the positively labelled branches.
Reference: <author> G. Pagallo and D. Haussler, </author> <title> "Boolean Feature Discovery in Empirical Learning", </title> <journal> Machine Learning, </journal> <volume> vol. 5, </volume> <pages> pp. 71-99, </pages> <year> 1990.. </year>
Reference-contexts: Other programs include the LEX system for acquiring and refining problemsolving heuristics (Mitchell, Utgoff and Banerji, 1983), Schlimmer's STAGGER (Schlimmer, 1986), which uses three learning modules, Muggleton's Duce (Muggleton, 1987) which is an oracle based approach and Pagallo and Haussler's FRINGE, GREEDY3 and GROVE <ref> (Pagallo and Haussler, 1990) </ref>. Other similar efforts include CITRE (Matheus and Rendell, 1989) which constructs new terms using the repeated application of boolean operators to nodes on the positively labelled branches.
Reference: <author> R.E. Reinke, </author> <title> Knowledge Acquisition and Refinement Tools for the ADVISE Meta-expert System, </title> <type> Masters Thesis, </type> <institution> University of Illinois, </institution> <year> 1984. </year>
Reference-contexts: A detailed description of the noise-tolerant method can be found in the AQ17-NT description (Thrun, et al, 1991). The values shown in Table 6 and table 8 for the AQ programs were calculated using a testing tool called ATEST <ref> (Reinke, 1984) </ref>.
Reference: <author> J. Schlimmer, </author> <title> "Concept Acquisition Through Representational Adjustment," </title> <journal> Machine Learning, </journal> <volume> vol. </volume> <pages> 1 , pp. 81-106, </pages> <year> 1986. </year>
Reference-contexts: BACON.1 (Langley, Bradshaw and Simon, 1983), and ABACUS.2 (Greene, 1988) are quantitative discovery programs which search for mathematical relationships that summarize all of the data. Other programs include the LEX system for acquiring and refining problemsolving heuristics (Mitchell, Utgoff and Banerji, 1983), Schlimmer's STAGGER <ref> (Schlimmer, 1986) </ref>, which uses three learning modules, Muggleton's Duce (Muggleton, 1987) which is an oracle based approach and Pagallo and Haussler's FRINGE, GREEDY3 and GROVE (Pagallo and Haussler, 1990).
Reference: <author> S. Thrun, J. Bala, E. Bloedorn, I. Bratko, B. Cestnik, J. Cheng, K. De Jong, S. </author> <title> Dzeroski, </title> <address> S </address> . 
Reference: <author> Fahlman, R. Hammann, K. Kaufman, S. Keller, I. Kononenko, J. Kreuziger, </author> <title> R.S. </title> <type> Michalski, </type> <institution> T. </institution>
Reference: <author> Mitchell, P. Pachowicz, H. Vafaie, W. Van de Velde, W. Wenzel, J. Wnek, and J. Zhang, </author> <title> The Monks Problems: A Performance Comparison of Different Learning Methods, </title> <institution> Carnegie Mellon University, </institution> <month> October, </month> <year> 1991. </year>
Reference: <author> P. Utgoff, </author> <title> "Shift of Bias for Inductive Learning,", </title> <booktitle> in Machine Learning: An Artificial Intelligence Approach, </booktitle> <volume> Vol. II, </volume> <editor> R. Michalski, J. Carbonell, and T. Mitchell (eds.), </editor> <publisher> Morgan Kaufman, </publisher> <address> Los Altos, CA, </address> <pages> pp. 107-148, </pages> <year> 1986. </year>
Reference-contexts: Other similar efforts include CITRE (Matheus and Rendell, 1989) which constructs new terms using the repeated application of boolean operators to nodes on the positively labelled branches. An approach which uses boolean and arithmetic combinations of the original attributes to extend the initial attribute set is proposed by Utgoff <ref> (Utgoff, 1986) </ref>. A method complementary to data-driven constructive induction for producing new features involves an analysis of the resulting hypotheses, rather than the training data. In this method learning on a subset of the training data results in rules oftern characterized by patterns of features and values.
Reference: <author> J. Wnek, </author> <title> R.S. Michalksi, Hypothesis-Driven Constructive Induction in AQ17: A Method and Experiments, </title> <type> MLI Report 91-9, </type> <institution> Center for Artificial Intelligence, George Mason University, Fairfax, Va. </institution> <year> 1991. </year>
Reference-contexts: In this method learning on a subset of the training data results in rules oftern characterized by patterns of features and values. These features are then proposed as new attributes <ref> (AQ17-HCI, Wnek and Michalski, 1991) </ref>. AQ14 (Mozetic, 1985), the rule generation program used by DCI, learns decision rules by performing inductive inference on examples. Training examples are vectors of attribute values.
References-found: 22

