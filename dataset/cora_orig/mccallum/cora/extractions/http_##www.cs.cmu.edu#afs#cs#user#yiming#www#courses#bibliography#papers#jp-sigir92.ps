URL: http://www.cs.cmu.edu/afs/cs/user/yiming/www/courses/bibliography/papers/jp-sigir92.ps
Refering-URL: http://www.cs.cmu.edu/afs/cs/user/yiming/www/courses/bibliography/papers/
Root-URL: 
Title: Scatter/Gather: A Cluster-based Approach to Browsing Large Document Collections  
Author: Douglass R. Cutting David R. Karger ; Jan O. Pedersen John W. Tukey ; 
Abstract: We argue that these problems arise only when clustering is used in an attempt to improve conventional search techniques. However, looking at clustering as an information access tool in its own right obviates these objections, and provides a powerful new access paradigm. We present a document browsing technique that employs document clustering as its primary operation. We also present fast (linear time) clustering algorithms which support this interactive browsing paradigm. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Chris Buckley and Alan F. Lewit. </author> <title> Optimizations of inverted vector searches. </title> <booktitle> In Proceedings of the Eighth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <pages> pages 97-110, </pages> <year> 1985. </year>
Reference-contexts: It is therefore un-surprising that cluster search, with its indifferent performance, has not gained wide popularity. Document clustering has also been studied as a method for accelerating near-neighbor search, but the development of fast algorithms for near-neighbor search has decreased interest in that possibility <ref> [1] </ref>. In this paper, we take a new approach to document clustering. Rather than dismissing document clustering as a poor tool for enhancing near-neighbor search, we ask how clustering can be effective as an access method in its own right.
Reference: [2] <author> W.B. Croft. </author> <title> Clustering large files of documents using the single-link method. </title> <journal> Journal of the American Society for Information Science, </journal> <volume> 28 </volume> <pages> 341-344, </pages> <year> 1977. </year>
Reference-contexts: Typically a fixed corpus of documents is clustered either into an exhaustive partition, disjoint or otherwise, or into a hierarchical tree structure (see, for example, <ref> [8, 13, 2] </ref>). In the case of a partition, queries are matched against clusters and the contents of the best scoring clusters are returned as a result, possibly sorted by score. <p> A hierarchical clustering defines a tree, called a dendrogram, on the documents. Numerous clustering algorithms have been applied to build hierarchical document clusters, including, most prominently, single-linkage hierarchical clustering <ref> [5, 2] </ref>. These algorithms generally proceed by iteratively considering all pairs of clusters built so far, and fusing the pair which exhibits the greatest similarity into a single document group (which then becomes a node of the dendro-gram).
Reference: [3] <author> A. El-Hamdouchi and P. Willett. </author> <title> Hierarchical document clustering using Ward's method. </title> <booktitle> In Proceedings of the Ninth International Conference on Research and Development in Information Retrieval, </booktitle> <pages> pages 149-156, </pages> <year> 1986. </year>
Reference-contexts: This is similar to the algorithm presented in <ref> [3] </ref>. Let be a document group. The average similarity between any two documents in is defined to be S () = jj (jj 1) ff2 fi6=ff Let G be a set of disjoint document groups.
Reference: [4] <author> A. Griffiths, H.C. Luckhurst, and P. Willett. </author> <title> Using inter-document similarity information in document retrieval systems. </title> <journal> Journal of the American Society for Information Science, </journal> <volume> 37 </volume> <pages> 3-11, </pages> <year> 1986. </year>
Reference-contexts: Indeed, cluster search techniques are typically compared to direct near-neighbor search [9], and are evaluated in terms of precision and recall. Various studies indicate that cluster search strategies are not markedly superior to near-neighbor search, and, in some situations, can be inferior (see, for example, <ref> [6, 12, 4] </ref>). Furthermore, document clustering algorithms are often slow, with quadratic running times. It is therefore un-surprising that cluster search, with its indifferent performance, has not gained wide popularity.
Reference: [5] <author> Anil K. Jain and Richard C. Dubes. </author> <title> Algorithms for Clustering Data. </title> <publisher> Pretice Hall, </publisher> <address> Engelwood Cliffs, N.J. 07632, </address> <year> 1988. </year>
Reference-contexts: A hierarchical clustering defines a tree, called a dendrogram, on the documents. Numerous clustering algorithms have been applied to build hierarchical document clusters, including, most prominently, single-linkage hierarchical clustering <ref> [5, 2] </ref>. These algorithms generally proceed by iteratively considering all pairs of clusters built so far, and fusing the pair which exhibits the greatest similarity into a single document group (which then becomes a node of the dendro-gram).
Reference: [6] <author> N. Jardine and C.J. van Rijsbergen. </author> <title> The use of hierarchical clustering in information retrieval. </title> <booktitle> Information Storage and Retrieval, </booktitle> <volume> 7 </volume> <pages> 217-240, </pages> <year> 1971. </year>
Reference-contexts: Indeed, cluster search techniques are typically compared to direct near-neighbor search [9], and are evaluated in terms of precision and recall. Various studies indicate that cluster search strategies are not markedly superior to near-neighbor search, and, in some situations, can be inferior (see, for example, <ref> [6, 12, 4] </ref>). Furthermore, document clustering algorithms are often slow, with quadratic running times. It is therefore un-surprising that cluster search, with its indifferent performance, has not gained wide popularity.
Reference: [7] <author> J. O. Pedersen, D. R. Cutting, and J. W. Tukey. </author> <title> Snippet search: a single phrase approach to text access. </title> <booktitle> In Proceedings of the 1991 Joint Statistical Meetings. American Statistical Association, </booktitle> <year> 1991. </year> <note> Also available as Xerox PARC technical report SSL-91-08. </note>
Reference-contexts: By direct analogy, we propose an information access system with two components: our browsing method, Scatter/Gather, which uses a cluster-based, dynamic table-of-contents metaphor for navigating a collection of documents; and one or more word-based, directed, text search methods, such as near-neighbor search or snippet search <ref> [7] </ref>. The browsing component describes groups of similar documents, one or more of which can be selected for further examination. This can be iterated until the user is directly viewing individual documents.
Reference: [8] <author> G. Salton. </author> <title> The SMART Retrieval System. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, N.J., </address> <year> 1971. </year>
Reference-contexts: Typically a fixed corpus of documents is clustered either into an exhaustive partition, disjoint or otherwise, or into a hierarchical tree structure (see, for example, <ref> [8, 13, 2] </ref>). In the case of a partition, queries are matched against clusters and the contents of the best scoring clusters are returned as a result, possibly sorted by score. <p> This sharply limits their usefulness, even given algorithms that attain the theoretical quadratic lower bound on performance. Partitional strategies, those that strive for a flat decomposition of the collection into sets of documents rather than a hierarchy of nested partitions, have also been studied <ref> [8, 13] </ref>. Some of these algorithms are global in nature and thus have the same slow performance as the above mentioned greedy, global, agglomerative algorithms. Other partitional algorithms, by contrast, typically have rectangular running times, i.e., O (kn).
Reference: [9] <author> G. Salton and M. J. McGill. </author> <title> Introduction to Modern Information Retrieval. </title> <publisher> McGraw-Hill, </publisher> <year> 1983. </year>
Reference-contexts: Hybrid strategies are also available. These strategies are essentially variations of near-neighbor search 1 where nearness is defined in terms of the pairwise document similarity measure used to generate the clustering. Indeed, cluster search techniques are typically compared to direct near-neighbor search <ref> [9] </ref>, and are evaluated in terms of precision and recall. Various studies indicate that cluster search strategies are not markedly superior to near-neighbor search, and, in some situations, can be inferior (see, for example, [6, 12, 4]). Furthermore, document clustering algorithms are often slow, with quadratic running times.
Reference: [10] <author> R. Sibson. SLINK: </author> <title> an optimally efficient algorithm for the single link cluster method. </title> <journal> Computer Journal, </journal> <volume> 16 </volume> <pages> 30-34, </pages> <year> 1973. </year>
Reference-contexts: Although single-linkage clustering is known to have an undesirable chaining behavior, typically forming elongated straggly clusters, it remains popular due to its simplicity and the availability of an optimal space and time algorithm for its computation <ref> [10] </ref>. These algorithms share certain common characteristics. They are agglomerative, in that they proceed by iteratively choosing two document groups to agglomerate into a single document group.
Reference: [11] <editor> C.J. van Rijsbergen. </editor> <booktitle> Information Retrieval. </booktitle> <address> Butter-worths, London, </address> <note> second edition, </note> <year> 1979. </year>
Reference-contexts: The general assumption is that mutually similar documents will tend to be relevant to the same queries, and, hence, that automatic determination of groups of such documents can improve recall by effectively broadening a search request (see <ref> [11] </ref> for a discussion of the cluster hypothesis). Typically a fixed corpus of documents is clustered either into an exhaustive partition, disjoint or otherwise, or into a hierarchical tree structure (see, for example, [8, 13, 2]). <p> Numerous document similarity measures have been proposed, all of which treat each document as a 3 set of words, often with frequency information, and mea-sure the degree of word overlap between documents <ref> [11] </ref>. The documents are typically represented by sparse vectors of length equal to the number of unique words (or types) in the corpus. Each component of the vector has a value reflecting the occurrence of the corresponding word in the document.
Reference: [12] <author> C.J. van Rijsbergen and W.B. Croft. </author> <title> Document clustering: An evaluation of some experiments with the Cranfield 1400 collection. </title> <booktitle> Information Processing & Management, </booktitle> <volume> 11 </volume> <pages> 171-182, </pages> <year> 1975. </year>
Reference-contexts: Indeed, cluster search techniques are typically compared to direct near-neighbor search [9], and are evaluated in terms of precision and recall. Various studies indicate that cluster search strategies are not markedly superior to near-neighbor search, and, in some situations, can be inferior (see, for example, <ref> [6, 12, 4] </ref>). Furthermore, document clustering algorithms are often slow, with quadratic running times. It is therefore un-surprising that cluster search, with its indifferent performance, has not gained wide popularity.
Reference: [13] <author> P. Willett. </author> <title> Document clustering using an inverted file approach. </title> <journal> Journal of Information Science, </journal> <volume> 2 </volume> <pages> 223-231, </pages> <year> 1980. </year>
Reference-contexts: Typically a fixed corpus of documents is clustered either into an exhaustive partition, disjoint or otherwise, or into a hierarchical tree structure (see, for example, <ref> [8, 13, 2] </ref>). In the case of a partition, queries are matched against clusters and the contents of the best scoring clusters are returned as a result, possibly sorted by score. <p> This sharply limits their usefulness, even given algorithms that attain the theoretical quadratic lower bound on performance. Partitional strategies, those that strive for a flat decomposition of the collection into sets of documents rather than a hierarchy of nested partitions, have also been studied <ref> [8, 13] </ref>. Some of these algorithms are global in nature and thus have the same slow performance as the above mentioned greedy, global, agglomerative algorithms. Other partitional algorithms, by contrast, typically have rectangular running times, i.e., O (kn). <p> However, to be useful for near-neighbor search, the partition must be fairly fine, since it is desirable for each set to only contain a few documents. For example, Willett generates a partition who size is related to the number of unique words in the document collection <ref> [13] </ref>. From this perspective, the potential computational benefits of a seed-based strategy are largely obviated by the large size (relative to the number of documents) of the required partition. For this reason partitional strategies have not been aggressively pursued by the information retrieval community.
Reference: [14] <author> P. Willett. </author> <title> A fast procedure for the calculation of similarity coefficients in automatic classification. </title> <booktitle> Information Processing & Management, </booktitle> <volume> 17 </volume> <pages> 53-60, </pages> <year> 1981. </year>
Reference-contexts: We present two partitioning algorithms which use techniques drawn from the hierarchical algorithms, but which acheive rectangular time bounds. For our application, the number of clusters desired is small and thus the speedup over quadratic time algorithms is substantial. 2 Willett <ref> [14] </ref> discusses an inverted file approach which can ameliorate this quadratic behavior when a large number of small clusters are desired.
Reference: [15] <author> P. Willett. </author> <title> Recent trends in hierarchical document clustering: A critical review. </title> <booktitle> Information Processing & Management, </booktitle> <volume> 24(5) </volume> <pages> 577-597, </pages> <year> 1988. </year> <month> 12 </month>
Reference-contexts: 1 Introduction Document clustering has been extensively investigated as a methodology for improving document search and retrieval (see <ref> [15] </ref> for an excellent review). The general assumption is that mutually similar documents will tend to be relevant to the same queries, and, hence, that automatic determination of groups of such documents can improve recall by effectively broadening a search request (see [11] for a discussion of the cluster hypothesis). <p> If both document vectors are normalized to unit length, the cosine is, of course, simply the inner product of the two vectors. Other measures include the Dice and Jaccard coefficients, which are normalized word overlap counts. Willett <ref> [15] </ref> has suggested that that the choice of similarity measure has less qualitative impact on clustering results than the choice of clustering algorithm. Two different types of document clusters can be constructed. One is a flat partition of the documents into a collection of subsets.
References-found: 15

