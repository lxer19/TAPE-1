URL: http://www.cs.berkeley.edu/~neal/wm_public_html/thesis.ps.gz
Refering-URL: http://www.cs.berkeley.edu/~neal/wm_public_html/honors.html
Root-URL: 
Title: CAUSALLY-STRUCTURED OUTPUT STREAMS FOR DISTRIBUTED COMPUTATIONS  
Author: Neal Douglas Cardwell 
Degree: A thesis submitted in partial fulfillment of the requirements for the degree of Bachelor of Science with Honors in Computer Science from the College of William Mary in Virginia, by  
Date: May 1996  
Address: Williamsburg, Virginia  
Affiliation: Accepted for  
Abstract-found: 0
Intro-found: 1
Reference: [1] <institution> Proceedings of the ACM Symposium on High Level Debugging (Aug. </institution> <year> 1983), </year> <title> vol. </title> <journal> 18 of SIGPLAN Notices. </journal>
Reference-contexts: Consider again the events in figure 3.8. From vector time stamps it can be deduced that a ! g, since every element of <ref> [1; 3; 2] </ref> is greater than or equal to the corresponding element in [1; 0; 0]. <p> Consider again the events in figure 3.8. From vector time stamps it can be deduced that a ! g, since every element of [1; 3; 2] is greater than or equal to the corresponding element in <ref> [1; 0; 0] </ref>. <p> From vector time stamps it can be deduced that a ! g, since every element of [1; 3; 2] is greater than or equal to the corresponding element in [1; 0; 0]. On the other hand, events b and d are concurrent, since neither [2; 0; 0] &lt; <ref> [1; 1; 0] </ref> nor [1; 1; 0] &lt; [2; 0; 0]. 3.5.3 Limitations of Mattern's System One limitation of Mattern's presentation of vector-based logical time is that it assumes that a distributed system contains a fixed number, n, of processes. <p> On the other hand, events b and d are concurrent, since neither [2; 0; 0] &lt; <ref> [1; 1; 0] </ref> nor [1; 1; 0] &lt; [2; 0; 0]. 3.5.3 Limitations of Mattern's System One limitation of Mattern's presentation of vector-based logical time is that it assumes that a distributed system contains a fixed number, n, of processes. <p> Interfering with the timing of a distributed system risks the occurrence of a "Heisenbug," so named because it is an error that arises due to timing changes caused by instrumentation of the distributed system for debugging, monitoring, or visualization <ref> [1] </ref>. * The implementation should be able to handle large output streams. This means that it will have to use files for storing the stream entries, rather than relying solely on memory. * The implementation should allow the programmer easy and flexible viewing of the components of the stream.
Reference: [2] <author> Edwards, D., and Kearns, P. DTVS: </author> <title> a distributed trace visualization system. </title> <booktitle> In Proceedings of 1994 6th IEEE Symposium on Parallel and Distributed Processing. </booktitle> <publisher> IEEE Comput. Soc. Press, </publisher> <month> Oct. </month> <year> 1994. </year>
Reference-contexts: Topol, Stasko, et. al [13] describe a visualization tool that uses an extension to PVM, the popular Parallel Virtual Machine message-passing library, to automatically produce data to drive a visualization. Their system uses Lamport logical clocks for causal ordering and local real-time clocks for performance analysis. Edwards and Kearns <ref> [2] </ref> describe a distributed trace visualization 10 system that uses per-process trace files with vector time-stamped informa-tion to provide post-mortem space-time diagrams as well as variable views and predicate evaluation. Joyce et. al [6] describe a tool that provides live textual and graphical display of events in a distributed computation. <p> Consider again the events in figure 3.8. From vector time stamps it can be deduced that a ! g, since every element of <ref> [1; 3; 2] </ref> is greater than or equal to the corresponding element in [1; 0; 0]. <p> From vector time stamps it can be deduced that a ! g, since every element of [1; 3; 2] is greater than or equal to the corresponding element in [1; 0; 0]. On the other hand, events b and d are concurrent, since neither <ref> [2; 0; 0] </ref> &lt; [1; 1; 0] nor [1; 1; 0] &lt; [2; 0; 0]. 3.5.3 Limitations of Mattern's System One limitation of Mattern's presentation of vector-based logical time is that it assumes that a distributed system contains a fixed number, n, of processes. <p> On the other hand, events b and d are concurrent, since neither <ref> [2; 0; 0] </ref> &lt; [1; 1; 0] nor [1; 1; 0] &lt; [2; 0; 0]. 3.5.3 Limitations of Mattern's System One limitation of Mattern's presentation of vector-based logical time is that it assumes that a distributed system contains a fixed number, n, of processes.
Reference: [3] <author> Fidge, C. </author> <title> Logical time in distributed computing systems. </title> <booktitle> Computer 24, </booktitle> <month> 8 (Aug </month> <year> 1991), </year> <pages> 28-33. </pages>
Reference-contexts: Consider again the events in figure 3.8. From vector time stamps it can be deduced that a ! g, since every element of <ref> [1; 3; 2] </ref> is greater than or equal to the corresponding element in [1; 0; 0]. <p> * What should be the initial time vector for a new process? * Are there performance concerns involved in maintaining vector clocks when hundreds or thousands of processes are created? How do we avoid wasting resources on keeping track of dead processes? 3.6 Extending Vector Time to Dynamically-Sized Systems Fidge <ref> [3] </ref> proposed a straightforward extension of Mattern's logical time to allow for dynamic distributed systems. 3.6.1 The Structure of Dynamic Vector Time As stated before, Mattern's formulation of logical time was a vector of n non-negative integers, where n is the (constant) number of processes in the system and V [i] <p> But several researchers (for example, Fidge <ref> [3] </ref>) have noted that this is unnecessary. Since PVM tasks and pvmd's will typically communicate quite frequently, space in each message is dedicated to clock values that haven't changed since the last message.
Reference: [4] <author> Fidge, C. </author> <title> Fundamentals of distributed system observation. </title> <type> Tech. Rep. 93-15, </type> <institution> University of Queensland, </institution> <month> Nov. </month> <year> 1993. </year>
Reference-contexts: The challenge in defining output streams for distributed systems is choosing an order for the entries in the stream. Unfortunately, for streams generated in a distributed computation there are a variety of choices for the ordering scheme, each of which has different characteristics. Fidge <ref> [4] </ref> provides a comprehensive taxonomy of these alternative ordering mechanisms, with a characterization of the faults of each. Most ordering mechanisms for distributed systems are defined in terms of events. An event is a discrete action in some process in a distributed system. <p> Events are then ordered by the order in which their notifications reach the observing process. This approach suffers from several problems, as noted by Fidge <ref> [4] </ref>. First, the ordering of events may be incorrect. Consider the situation in figure 3.2. In this example the central monitoring process, R, perceives event b to precede event a, even though these events occur in the opposite order.
Reference: [5] <author> Geist, A., Beguelin, A., Dongarra, J., Jiang, W., manchek, R., and Sunderan, V. </author> <title> PVM: Parallel Virtual Machine. </title> <publisher> The MIT Press, </publisher> <year> 1994. </year>
Reference-contexts: Chapter 8 wraps up with a summary of the results of this research. 13 Chapter 2 PVM 2.1 Description PVM, Parallel Virtual Machine, is a software library that allows a heterogeneous collection of networked computers to be used as a single computing resource a parallel virtual machine <ref> [5] </ref>. PVM is a standard, full-featured, well-documented library well-accepted in the research community for use in scientific computation and other computationally-intensive applications.
Reference: [6] <author> Joyce, J., Lomow, G., Slind, K., and Unger, B. </author> <title> Monitoring distributed systems. </title> <journal> ACM transactions on Computer Systems 5, </journal> <month> 2 (May </month> <year> 1987), </year> <pages> 121-150. </pages>
Reference-contexts: Edwards and Kearns [2] describe a distributed trace visualization 10 system that uses per-process trace files with vector time-stamped informa-tion to provide post-mortem space-time diagrams as well as variable views and predicate evaluation. Joyce et. al <ref> [6] </ref> describe a tool that provides live textual and graphical display of events in a distributed computation. Other systems a post-mortem replay of the execution of the distributed system. R.
Reference: [7] <author> Lamport, L. </author> <title> Time, clocks, and the ordering of events in a distributed system. </title> <booktitle> In Communications of the ACM. </booktitle> <month> July </month> <year> 1978. </year>
Reference-contexts: But any discrete action the programmer finds significant such as a function call or an assignment to a variable maybe considered an event. One standard way to graphically depict the events in a distributed system is a space-time diagram <ref> [7] </ref>. Figure 3.1 presents an example. In a space-time diagram events are placed according to the process in which they occur and the absolute real time at which they occur. Processes are depicted as vertical lines and events are dots on these lines. Time increases along the vertical axis. <p> The causal structure of a distributed system is most appropriately described by the "happened-before" relation, commonly denoted by !, defined by Lamport <ref> [7] </ref>: Definition 3.1. The relation ! E fi E on the set E of all events in a distributed system is the smallest relation satisfying the following conditions: 1. <p> This allows a programmer to quickly see several of the possible interleavings of concurrent events without having to re-execute the application. See figure 6.1. Space-Time A view inspired by the traditional Lamport space-time diagram <ref> [7] </ref> of a distributed system. Entry nodes display the contents of the entry and arrows between nodes denote causal relationships between entries.
Reference: [8] <author> LeBlanc, R. J., and Robbins, A. D. </author> <title> Event-driven monitoring of distributed programs. </title> <booktitle> In Proc. of the 5th International Conf. on Distributed Computing Systems. IEEE, </booktitle> <month> May </month> <year> 1985, </year> <pages> pp. 515-522. </pages>
Reference-contexts: Joyce et. al [6] describe a tool that provides live textual and graphical display of events in a distributed computation. Other systems a post-mortem replay of the execution of the distributed system. R. LeBlanc et. al <ref> [8] </ref> present a system featuring graphical animation of events such as process creation and termination and message sends and receives. Some tools provide complete interactive debuggers that allow programmers to stop processes, investigate the state of the computation, step processes, set breakpoints, and restart the processes.
Reference: [9] <author> Mattern, F. </author> <title> Virtual time and global states of distributed systems. </title> <booktitle> In Parallel and Distributed Algorithms: Proceedings of the International Workshop on Parallel & Distributed Algorithms, </booktitle> <editor> M. C. et. al., Ed. </editor> <publisher> El-sevier Science Publishers B. V., </publisher> <year> 1989, </year> <pages> pp. 215-226. </pages>
Reference-contexts: Finally, many pairs of events are causally related because of transitivity (rule 3), including a ! e, a ! g, and c ! g. 23 3.5 Mattern's Logical Time Mattern <ref> [9] </ref> suggested an ordering scheme that relies on a vector-valued logical clock at each process to order events according to their causal relations.
Reference: [10] <editor> Miller, B. P., and McDowell, C., Eds. </editor> <booktitle> Summary of ACM/ONR Workshop on Parallel and Distributed Debugging (1993), vol. 27 of Operating Sysetsms Review. </booktitle>
Reference-contexts: Allowing the programmer to specify what information ends up in a stream, and to which stream information is written, will help eliminate the problem that visualizations of distributed and parallel computations are often so busy and cluttered that they resemble an "angry fruit salad on drugs" <ref> [10] </ref> and are thus very difficult to use to use to learn anything useful about the system. 1.5 Organization Chapter 2 offers a brief introduction to PVM. Chapter 3 describes the causal relation used to order events and explains why this ordering scheme is the best alternative.
Reference: [11] <author> Ousterhout, J. K. </author> <title> Tcl and the Tk Toolkit. </title> <publisher> Addison-Wesley, </publisher> <year> 1994. </year>
Reference-contexts: The sv user can clear the contents of the currently-displayed streams so that output from multiple executions of a program can be viewed in the same sv session. 6.4 Implementation Languages The stream-viewing tool is implemented in C++ and Tcl/Tk <ref> [11] </ref>. The data model all of the computationally-intensive manipulations of stream entries and their text is in C++ in order to maximize performance. The entire user interface is written in Tcl/Tk in order to provide a standard, easy-to-use user interface for the tool.
Reference: [12] <author> Paul K. Harter, J., Heimbigner, D. M., and King, R. IDD: </author> <title> An interactive distributed debugger. </title> <booktitle> In Proc. of the 5th International Conf. on Distributed Computing Systems. IEEE, </booktitle> <month> May </month> <year> 1985, </year> <pages> pp. 498-506. </pages>
Reference-contexts: Some of these systems are essentially off-the-shelf debuggers attached to each process in the computation; others are systems custom-tailored to debug distributed systems. Some even <ref> [12] </ref> perform run-time assertion checking.
Reference: [13] <author> Topol, B., Stasko, J., and Sunderam, V. </author> <title> Integrating visualization support into distributed computing systems. </title> <booktitle> In Proceedings of the 15th International Conference on Distributed Computing Systems. </booktitle> <month> June </month> <year> 1995. </year>
Reference-contexts: Many of these tools for distributed computations provide a graphical representation of the messages sent and received in the system. Topol, Stasko, et. al <ref> [13] </ref> describe a visualization tool that uses an extension to PVM, the popular Parallel Virtual Machine message-passing library, to automatically produce data to drive a visualization. Their system uses Lamport logical clocks for causal ordering and local real-time clocks for performance analysis.
Reference: [14] <author> Walker, D., and Dongarra, J. </author> <title> MPI: A standard message passing interface. </title> <booktitle> Supercomputer 12, </booktitle> <month> 1 (Jan </month> <year> 1996), </year> <pages> 56-68. 92 </pages>
Reference-contexts: A message-passing library was chosen instead because this enables changes to be made without recompiling the kernel and rebooting the machine. This also allows the use of a standard user-level debugger during development. PVM was chosen instead of the Message-Passing Interface (MPI), another popular message-passing environment, <ref> [14] </ref> because it lacks PVM's facilities for dynamically adding tasks and hosts to a computation. 2.3 Implementation Every host in the PVM virtual machine has a pvmd daemon executing on it.
References-found: 14

