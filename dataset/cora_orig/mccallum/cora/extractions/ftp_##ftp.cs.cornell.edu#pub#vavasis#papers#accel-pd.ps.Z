URL: ftp://ftp.cs.cornell.edu/pub/vavasis/papers/accel-pd.ps.Z
Refering-URL: http://www.cs.cornell.edu/home/vavasis/vavasis.html
Root-URL: 
Title: A Primal-Dual Accelerated Interior Point Method Whose Running Time Depends Only on A for linear
Author: Stephen A. Vavasis Yinyu Ye 
Note: rithm  
Date: December 10, 1994  
Abstract: We propose a primal-dual "layered-step" interior point (LIP) algo fl This paper represents a simplification of an earlier manuscript "An accelerated interior point method whose running depends only on A" by the same authors. y Department of Computer Science, Upson Hall, Cornell University, Ithaca, NY 14853. Email: vavasis@cs.cornell.edu. This work is supported in part by the National Science Foundation, the Air Force Office of Scientific Research, and the Office of Naval Research, through NSF grant DMS-8920550. Also supported in part by an NSF Presidential Young Investigator award with matching funds received from AT&T and Xerox Corp. Part of this work was done while the author was visiting Sandia National Laboratories, supported by the U.S. Department of Energy under contract DE-AC04-76DP00789. z Department of Management Sciences, The University of Iowa, Iowa City, IA 52242. E-mail: bbuyin@vaxa.weeg.uiowa.edu. This author is supported in part by NSF Grant DDM-9207347. Part of this work was done while the author was on a sabbatical leave from the University of Iowa and visiting the Cornell Theory Center, Cornell University, Ithaca, NY 14853, supported in part by the Cornell Center for Applied Mathematics and by the Advanced Computing Research Institute, a unit of the Cornell Theory Center, which receives major funding from the National Science Foundation and IBM Corporation, with additional support from New York State and members of its Corporate Research Institute. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. K. Ahuja, T. L. Magnanti, and J. B. Orlin. </author> <title> Network Flows: Theory, Algorithms, and Applications. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, New Jersey, </address> <year> 1993. </year>
Reference-contexts: Theorem 1 Let ff 2 <ref> [ ff; 1] </ref> be chosen arbitrarily, where ff is defined by (38) and Case III in the last section holds. In the case that ff = 0, assume further that ff &gt; 0. <p> According to Ahuja, Magnanti and Orlin <ref> [1] </ref>, the best currently-known strongly polynomial algorithm for this problem is O (m 2 log n + mn (log n) 2 ) and is due to Orlin [23]. Thus, the LIP method needs considerable improvement in order to reach this bound.
Reference: [2] <author> D. A. Bayer and J. C. Lagarias. </author> <title> The nonlinear geometry of linear pro-gramming. I. Affine and projective scaling trajectories. </title> <journal> Transactions of the AMS, </journal> <volume> 314 </volume> <pages> 499-526, </pages> <year> 1989. </year>
Reference-contexts: Note that as ! 0 + , (6) approaches (5) and (x (); y (); s ()) approaches an optimal solution. The definition of the central path is credited to Bayer and Lagarias <ref> [2, 3, 4] </ref>, Megiddo [16], and Sonnevend [28], and it was partially analyzed by McLinden [15] earlier. For the relationship between the central path and the classical log-barrier method, see Wright [40]. For interesting properties of the central path, see the excellent review article by Gonzaga [8].
Reference: [3] <author> D. A. Bayer and J. C. Lagarias. </author> <title> The nonlinear geometry of linear pro-gramming. II. Legendre transform coordinates and central trajectories. </title> <journal> Transactions of the AMS, </journal> <volume> 314 </volume> <pages> 527-581, </pages> <year> 1989. </year>
Reference-contexts: Note that as ! 0 + , (6) approaches (5) and (x (); y (); s ()) approaches an optimal solution. The definition of the central path is credited to Bayer and Lagarias <ref> [2, 3, 4] </ref>, Megiddo [16], and Sonnevend [28], and it was partially analyzed by McLinden [15] earlier. For the relationship between the central path and the classical log-barrier method, see Wright [40]. For interesting properties of the central path, see the excellent review article by Gonzaga [8].
Reference: [4] <author> D. A. Bayer and J. C. Lagarias. </author> <title> The nonlinear geometry of linear pro-gramming. III. Projective Legendre transform coordinates and Hilbert geometry. </title> <journal> Transactions of the AMS, </journal> <volume> 320 </volume> <pages> 193-225, </pages> <year> 1990. </year>
Reference-contexts: Note that as ! 0 + , (6) approaches (5) and (x (); y (); s ()) approaches an optimal solution. The definition of the central path is credited to Bayer and Lagarias <ref> [2, 3, 4] </ref>, Megiddo [16], and Sonnevend [28], and it was partially analyzed by McLinden [15] earlier. For the relationship between the central path and the classical log-barrier method, see Wright [40]. For interesting properties of the central path, see the excellent review article by Gonzaga [8].
Reference: [5] <author> T. Coleman. </author> <title> Large-scale numerical optimization: introduction and overview. </title> <editor> In A. Kent and J. G. Williams, editors, </editor> <booktitle> Encyclopedia of com-puter science and technology. </booktitle> <publisher> Marcel Dekker, </publisher> <address> New York, </address> <year> 1993. </year>
Reference-contexts: For example, we carried out this process for min-cost flow problems in Section 12. Other good candidates for special-case analysis would be linear programs arising in scheduling, optimization problems involving finite-element subprob- lems (see example 3 of Coleman <ref> [5] </ref>), and LP relaxations of combina <br>- torial optimization problems. 2. For floating-point number computations|where one usually is inter <br>- ested in computing an approximate solution rather than an exact optimum| perhaps there is a different strategy for picking g.
Reference: [6] <author> J. Edmonds. </author> <title> Systems of distinct representatives and linear algebra. </title> <institution> J. Res. Nat. Bur. Standards, 71B:241-245, </institution> <year> 1967. </year>
Reference-contexts: The step involves solving linear equations, which can be done in polynomial time <ref> [6, 35] </ref>. It can be proved that this truncation preserves approximate centering; see, for example, Chapter 3 of [35].
Reference: [7] <author> G. H. Golub and C. F. Van Loan. </author> <title> Matrix Computations, 2nd Edition. </title> <publisher> Johns Hopkins University Press, </publisher> <address> Baltimore, </address> <year> 1989. </year> <month> 51 </month>
Reference-contexts: Thus, our new results can be thought of a link between condition number and complexity of iterative processes (also see [34] and [38]). Such links are well-known in numerical analysis; the classic example is the conjugate gradient algorithm (see <ref> [7] </ref>). Renegar [26] is currently also developing a theory connecting complexity and conditioning for interior point methods. His setting, however, is more general than ours (general convex constraints in Banach spaces are allowed) but his condition measure involves b and c as well as A.
Reference: [8] <author> C. C. Gonzaga. </author> <title> Path-following methods for linear programming. </title> <journal> SIAM Review, </journal> <volume> 34 </volume> <pages> 167-224, </pages> <year> 1992. </year>
Reference-contexts: For the relationship between the central path and the classical log-barrier method, see Wright [40]. For interesting properties of the central path, see the excellent review article by Gonzaga <ref> [8] </ref>. In an interior point method, an exactly central point is never computed because there is no finite algorithm to solve the nonlinear equations (6). Therefore, one defines approximate centering. Many definitions are possible, but we use the following proximity measure. <p> (7) Xffis + Sffix = e SXe and returns a point x = x + ffix, y = y + ffiy and s = s + ffis such that ( x; y; s; ) 2 ( 1 ) 2 : We also have the following corollary, which appears in Gonzaga <ref> [8] </ref>. Corollary 1 Suppose (x; y; s; ) = 1 &lt; 1, and let (x (); y (); s ()) be the center path point for parameter .
Reference: [9] <author> J. A. Kaliski and Y. Ye. </author> <title> A short-cut potential reduction algorithm for linear programming. </title> <journal> Management Science, </journal> <volume> 39 </volume> <pages> 757-773, </pages> <year> 1993. </year>
Reference-contexts: The idea of partitioning the slacks into layers based on their relative sizes has been proposed by Kaliski and Ye <ref> [9] </ref> and Tone [33], who both propose a decomposition into two layers. The interest of these authors is in improving the running-time of computing one iteration of an interior point method, rather than in obtaining new bounds on the number of iterations.
Reference: [10] <author> N. Karmarkar. </author> <title> A new polynomial-time algorithm for linear program-ming. </title> <journal> Combinatorica, </journal> <volume> 4 </volume> <pages> 373-395, </pages> <year> 1984. </year>
Reference-contexts: We propose a path-following interior point method for these problems that simultaneously produces a primal and dual solution. Interior point methods were originally introduced by Karmarkar <ref> [10] </ref>, and the first path-following method is due to Renegar [25]. The first primal- dual path following algorithm is due to Kojima et al. [13]. See Nesterov and Nemirovsky [21] for a high-level and very general description of interior point methods.
Reference: [11] <author> L. Khachiyan. </author> <title> On the complexity of approximating extremal determi-nants in matrices. </title> <type> Preprint, </type> <year> 1994. </year>
Reference-contexts: The only known algorithm for computing these parameters is implicit in the results of Stewart [30] and O'Leary [22] and requires exponential- time. We suspect that computing them, or even getting a good upper bound, may be a hard problem. Khachiyan <ref> [11] </ref> has shown that it is NP-hard to compute or approximate A , and his results may extend to A .
Reference: [12] <author> L. G. Khachiyan. </author> <title> A polynomial algorithm in linear programming. </title> <journal> Dokl. Akad. Nauk SSSR, </journal> <volume> 244 </volume> <pages> 1093-1086, </pages> <year> 1979. </year> <journal> Translated in Soviet Math. Dokl. </journal> 20:191-194. 
Reference-contexts: See Nesterov and Nemirovsky [21] for a high-level and very general description of interior point methods. Traditional path-following methods take small steps along the central path until they are "sufficiently" close to an optimum. Once sufficiently close, a "rounding" procedure such as Khachiyan's <ref> [12] </ref> or least- squares computation such as Ye's [41] is used to obtain an exact optimum. In our new method, we interleave small steps with longer layered least- squares (LLS) steps to follow the central path.
Reference: [13] <author> M. Kojima, S. Mizuno, and A. Yoshise. </author> <title> A polynomial-time algorithm for a class of linear complementarity problems. </title> <journal> Mathematical Programming, </journal> <volume> 44 </volume> <pages> 1-26, </pages> <year> 1989. </year>
Reference-contexts: Interior point methods were originally introduced by Karmarkar [10], and the first path-following method is due to Renegar [25]. The first primal- dual path following algorithm is due to Kojima et al. <ref> [13] </ref>. See Nesterov and Nemirovsky [21] for a high-level and very general description of interior point methods. Traditional path-following methods take small steps along the central path until they are "sufficiently" close to an optimum. <p> Let &gt; 0 be fixed, and let (x; y; s) be an interior point feasible for the both the primal and dual. Then we define the proximity measure (x; y; s; ) = kSXe= ek 8 (e.g., Kojima et al. <ref> [13] </ref> and Monteiro and Adler [20]). The norm used in this definition, and all norms in the remainder of the paper, are 2-norms unless otherwise noted. One sees that for an exactly centered point (x; y; s), we have (x; y; s; ) = 0 because SXe = e. <p> The constant c 0 depends on 0 and on the particular algorithm but has 10 as an upper bound <ref> [13] </ref> for 0 = 0:2. Theorem 2 Consider one main loop iteration of Algorithm LIP. (If Case III holds for the iteration, assume further that ff &gt; 0, i.e., the algorithm does not terminate.) This iteration causes a crossover event to take place. Proof.
Reference: [14] <author> I. J. Lustig, R. E. Marsten, and D. F. Shanno. </author> <title> Computational experience with a primal-dual interior point method for linear programming. </title> <journal> Linear Algebra and Its Applications, </journal> <volume> 152 </volume> <pages> 191-222, </pages> <year> 1991. </year>
Reference-contexts: An alternative initialization procedure gaining popularity is the so- called "infeasible" interior point method (for example, see Lustig et al. <ref> [14] </ref>). It would be interesting if there were a layered version of these algorithms. 6. As mentioned in Section 3, there is a relationship between A ; A and condition numbers of weighted least-squares problems as demonstrated by [37].
Reference: [15] <author> L. McLinden. </author> <title> An analogue of Moreau's proximation theorem, with ap-plications to the nonlinear complementarity problem. </title> <journal> Pacific Journal of Mathematics, </journal> <volume> 88 </volume> <pages> 101-161, </pages> <year> 1980. </year>
Reference-contexts: Note that as ! 0 + , (6) approaches (5) and (x (); y (); s ()) approaches an optimal solution. The definition of the central path is credited to Bayer and Lagarias [2, 3, 4], Megiddo [16], and Sonnevend [28], and it was partially analyzed by McLinden <ref> [15] </ref> earlier. For the relationship between the central path and the classical log-barrier method, see Wright [40]. For interesting properties of the central path, see the excellent review article by Gonzaga [8].
Reference: [16] <author> N. Megiddo. </author> <title> Pathways to the optimal set in linear programming. </title> <editor> In N. Megiddo, editor, </editor> <booktitle> Progress in Mathematical Programming: Interior Point and Related Method, </booktitle> <pages> pages 131-158. </pages> <publisher> Springer, </publisher> <address> New York, </address> <year> 1989. </year>
Reference-contexts: Note that as ! 0 + , (6) approaches (5) and (x (); y (); s ()) approaches an optimal solution. The definition of the central path is credited to Bayer and Lagarias [2, 3, 4], Megiddo <ref> [16] </ref>, and Sonnevend [28], and it was partially analyzed by McLinden [15] earlier. For the relationship between the central path and the classical log-barrier method, see Wright [40]. For interesting properties of the central path, see the excellent review article by Gonzaga [8].
Reference: [17] <author> N. Megiddo and M. Shub. </author> <title> Boundary behavior of interior point algo-rithms in linear programming. </title> <journal> Mathematics of Operations Research, </journal> <volume> 14 </volume> <pages> 97-146, </pages> <year> 1989. </year>
Reference-contexts: Sonnevend, Stoer and Zhao [29] have considered the total integral of the curvature in the path in order to bound complexity. Megiddo and Shub <ref> [17] </ref> have considered bends in the limiting behavior of the central path trajectory as the boundary of the feasible set is reached.
Reference: [18] <author> S. Mizuno, M. J. Todd, and Y. Ye. </author> <title> A surface of analytic centers and infeasible interior-point algorithms for linear programming. </title> <type> Technical Report 1037, </type> <institution> School of Operations Research and Industrial Engineering, Cornell University, Ithaca, NY. </institution> <note> To appear in Math. </note> <institution> Oper. Res. </institution> <month> 52 </month>
Reference-contexts: If the polytope is not full dimensional (which is always the case for the following corollary) and it is given as fy : A T 0 y = c 0 ; A T y cg, then its analytic center y fl satisfies (see Mizuno et al. <ref> [18] </ref>) A 0 x 0 + AS 1 e = 0; for some x 0 (39) where s = A T y fl c.
Reference: [19] <author> S. Mizuno, M. J. Todd, and Y. Ye. </author> <title> On adaptive-step primal-dual interior-point algorithms for linear programming. </title> <journal> Mathematics of Operations Research, </journal> <volume> 18 </volume> <pages> 964-981, </pages> <year> 1993. </year>
Reference-contexts: One sees that for an exactly centered point (x; y; s), we have (x; y; s; ) = 0 because SXe = e. We have the following useful lemma which is proved in Mizuno et al. <ref> [19] </ref> (also see references therein). Lemma 1 Let (x; y; s) be a given feasible primal and dual interior solution, and let &gt; 0 be fixed. <p> Then two Newton steps with this fixed + restores the proximity to 0:2. Note that if p = 1, then this approach is precisely the so-called predictor and corrector algorithm developed by Mizuno et al. <ref> [19] </ref>. This is because, in the p = 1 case, the LLS steps ffis fl and ffix fl are exactly the affine-scaling directions computed by the standard method.
Reference: [20] <author> R. C. Monteiro and I. Adler. </author> <title> Interior path following primal-dual algo-rithm. Part I: linear programming. </title> <booktitle> Mathematical Programming, </booktitle> <address> 44:2741, </address> <year> 1989. </year>
Reference-contexts: Let &gt; 0 be fixed, and let (x; y; s) be an interior point feasible for the both the primal and dual. Then we define the proximity measure (x; y; s; ) = kSXe= ek 8 (e.g., Kojima et al. [13] and Monteiro and Adler <ref> [20] </ref>). The norm used in this definition, and all norms in the remainder of the paper, are 2-norms unless otherwise noted. One sees that for an exactly centered point (x; y; s), we have (x; y; s; ) = 0 because SXe = e.
Reference: [21] <author> Y. E. Nesterov and A. S. Nemirovsky. </author> <title> Interior Point Polynomial Methods in Convex Programming: Theory and Algorithms. </title> <publisher> SIAM Publications. SIAM, </publisher> <address> Philadelphia, USA, </address> <year> 1993. </year>
Reference-contexts: Interior point methods were originally introduced by Karmarkar [10], and the first path-following method is due to Renegar [25]. The first primal- dual path following algorithm is due to Kojima et al. [13]. See Nesterov and Nemirovsky <ref> [21] </ref> for a high-level and very general description of interior point methods. Traditional path-following methods take small steps along the central path until they are "sufficiently" close to an optimum.
Reference: [22] <author> D. P. O'Leary. </author> <title> On bounds for scaled projections and pseudoinverses. </title> <journal> Linear Algebra and its Applications, </journal> <volume> 132 </volume> <pages> 115-117, </pages> <year> 1990. </year>
Reference-contexts: Note that we do not need to know these parameters exactly|good upper bounds will suffice. The only known algorithm for computing these parameters is implicit in the results of Stewart [30] and O'Leary <ref> [22] </ref> and requires exponential- time. We suspect that computing them, or even getting a good upper bound, may be a hard problem. Khachiyan [11] has shown that it is NP-hard to compute or approximate A , and his results may extend to A .
Reference: [23] <author> J. B. Orlin. </author> <title> A faster strongly polynomial minimum cost flow algorithm. </title> <booktitle> In Proc. 20th ACM Symposium on the Theory of Computing, </booktitle> <pages> pages 377387, </pages> <year> 1988. </year>
Reference-contexts: According to Ahuja, Magnanti and Orlin [1], the best currently-known strongly polynomial algorithm for this problem is O (m 2 log n + mn (log n) 2 ) and is due to Orlin <ref> [23] </ref>. Thus, the LIP method needs considerable improvement in order to reach this bound.
Reference: [24] <author> C. H. Papadimitriou and K. Steiglitz. </author> <title> Combinatorial Optimization: Algorithms and Complexity. </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, New Jersey, </address> <year> 1982. </year>
Reference-contexts: Note that for every basis B of A, B 1 is a matrix whose every entry is either 1, 1 or 0 because A is a node-arc incidence matrix <ref> [24, sec. 13.2] </ref>. Now consider the min-cost flow constraint matrix: ^ A = A 0 ! Note that ^ A is an (m + n) fi 2m matrix.
Reference: [25] <author> J. Renegar. </author> <title> A polynomial-time algorithm based on Newton's method for linear programming. </title> <journal> Mathematical Programming, </journal> <volume> 40 </volume> <pages> 59-94, </pages> <year> 1988. </year>
Reference-contexts: We propose a path-following interior point method for these problems that simultaneously produces a primal and dual solution. Interior point methods were originally introduced by Karmarkar [10], and the first path-following method is due to Renegar <ref> [25] </ref>. The first primal- dual path following algorithm is due to Kojima et al. [13]. See Nesterov and Nemirovsky [21] for a high-level and very general description of interior point methods. Traditional path-following methods take small steps along the central path until they are "sufficiently" close to an optimum.
Reference: [26] <author> J. Renegar. </author> <title> Linear programming, complexity theory, and elementary functional analysis. </title> <type> Unpublished manuscript, </type> <institution> Department of Operations Research and Industrial Engineering, Cornell University, </institution> <year> 1993. </year>
Reference-contexts: Thus, our new results can be thought of a link between condition number and complexity of iterative processes (also see [34] and [38]). Such links are well-known in numerical analysis; the classic example is the conjugate gradient algorithm (see [7]). Renegar <ref> [26] </ref> is currently also developing a theory connecting complexity and conditioning for interior point methods. His setting, however, is more general than ours (general convex constraints in Banach spaces are allowed) but his condition measure involves b and c as well as A.
Reference: [27] <author> M. G. C. Resende and G. Veiga. </author> <title> An efficient implementation of a net-work interior point method. </title> <type> Technical report, </type> <institution> Mathematical Sciences Research Center, AT & T Bell Laboratories, </institution> <address> Murray Hill, NJ 079740636, USA, </address> <year> 1992. </year> <note> Revised March 1992. Revised version 2.0 August 1992. To appear in DIMACS Series in Discrete Mathematics and Theoretical Computer Science. </note>
Reference-contexts: On the other hand, in practice, interior point methods usually perform much better than their worst-case bounds, so we suspect that Algorithm LIP could be competitive in practice, especially if a good method for solving the least-squares problems is used. See Resende and Veiga <ref> [27] </ref>. 13 Conclusions We have proposed the first known method whose running time depends only on A for linear programming with data given by real numbers. This is attained by including a step called the "LLS" step that accelerates the convergence of an interior-point method.
Reference: [28] <author> G. Sonnevend. </author> <title> An analytical center for polyhedrons and new classes of global algorithms for linear (smooth, convex) programming. </title> <booktitle> In Lecture 53 Notes in Control and Information Sciences 84, </booktitle> <pages> pages 866-876. </pages> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1985. </year>
Reference-contexts: Note that as ! 0 + , (6) approaches (5) and (x (); y (); s ()) approaches an optimal solution. The definition of the central path is credited to Bayer and Lagarias [2, 3, 4], Megiddo [16], and Sonnevend <ref> [28] </ref>, and it was partially analyzed by McLinden [15] earlier. For the relationship between the central path and the classical log-barrier method, see Wright [40]. For interesting properties of the central path, see the excellent review article by Gonzaga [8].
Reference: [29] <author> G. Sonnevend, J. Stoer, and G. Zhao. </author> <title> On the complexity of following the central path of linear programs by linear extrapolation II. </title> <journal> Mathematical Programming, </journal> <volume> 52 </volume> <pages> 527-553, </pages> <year> 1991. </year>
Reference-contexts: This fact is the basis for results on asymptotic quadratic convergence of interior point methods such as the result of Ye et al. [42] and earlier works cited therein. Sonnevend, Stoer and Zhao <ref> [29] </ref> have considered the total integral of the curvature in the path in order to bound complexity. Megiddo and Shub [17] have considered bends in the limiting behavior of the central path trajectory as the boundary of the feasible set is reached.
Reference: [30] <author> G. W. Stewart. </author> <title> On scaled projections and pseudoinverses. </title> <journal> Linear Algebra and its Applications, </journal> <volume> 112 </volume> <pages> 189-193, </pages> <year> 1989. </year>
Reference-contexts: The remainder of this paper is organized as follows. In Section 2 we define the central path and characterize points that are "approximately" centered. In Section 3 we describe quantities A ; A that were discovered independently by Stewart <ref> [30] </ref> and Todd [32], and state some of their properties. Our complexity bounds depend on these parameters. In Section 4 we describe the layered least-squares step and the LIP method. <p> Let us define D to be the set of all positive definite n fi n diagonal matrices. Let us define A = supfkA T (ADA T ) 1 ADk : D 2 Dg: 9 Stewart <ref> [30] </ref> and Todd [32] independently proved that this quantity is always finite. Equivalently, one can show that A = supfk (ADA T ) 1 ADk : D 2 Dg is also finite. These bounds apply for any induced matrix norm, but for this paper, we confine ourselves to 2-norms. <p> One major gap in our understanding of these parameters is the question of computing them; we do not know of efficient algorithms for computing either parameter. See Section 13 for more comments on this matter. A final note is that in some earlier work such as <ref> [30] </ref> and [37] it was assumed that A was an m fi n matrix of rank n, and the definitions of A ; A in those papers involved the transpose matrix rather than the definition used above. <p> Note that we do not need to know these parameters exactly|good upper bounds will suffice. The only known algorithm for computing these parameters is implicit in the results of Stewart <ref> [30] </ref> and O'Leary [22] and requires exponential- time. We suspect that computing them, or even getting a good upper bound, may be a hard problem. Khachiyan [11] has shown that it is NP-hard to compute or approximate A , and his results may extend to A .
Reference: [31] <author> E. Tardos. </author> <title> A strongly polynomial algorithm to solve combinatorial linear programs. </title> <journal> Operations Research, </journal> <volume> 34 </volume> <pages> 250-256, </pages> <year> 1986. </year>
Reference-contexts: For a problem with no near-degeneracies, there is only one curved segment followed by an approximately straight segment leading to the optimum. Ours is not the first complexity bound for linear programming that depends only on A; Tardos <ref> [31] </ref> earlier proposed such a method. Tardos' method, however, "probably should be considered a purely theoretical contribution" [31, p. 251] because it requires the solution of n complete LP's. <p> Ours is not the first complexity bound for linear programming that depends only on A; Tardos [31] earlier proposed such a method. Tardos' method, however, "probably should be considered a purely theoretical contribution" <ref> [31, p. 251] </ref> because it requires the solution of n complete LP's. <p> Our method is the first polynomial-time linear programming algorithm that also has a complexity bound depending only on A in the real-number model of computation for finding an optimum. In contrast, Tardos uses the assumption of integer data in a fairly central way because an important tool in <ref> [31] </ref> is the operation of rounding down to the nearest integer. The remainder of this paper is organized as follows. In Section 2 we define the central path and characterize points that are "approximately" centered. <p> Similarly, A is bounded by kAk A , so we obtain a bound of the same order. This leads to a new proof of the following corollary, which is a well-known result due to Tardos. Corollary 4 <ref> [31] </ref> Consider solving an LP of the form (2) on a Turing machine. Suppose that A; b; c have integer entries, and suppose that L A is the 45 number of bits to write m fi n matrix A.
Reference: [32] <author> M. J. Todd. </author> <title> A Dantzig-Wolfe-like variant of Karmarkar's interiorpoint linear programming algorithm. </title> <journal> Operations Research, </journal> <volume> 38:10061018, </volume> <year> 1990. </year>
Reference-contexts: The remainder of this paper is organized as follows. In Section 2 we define the central path and characterize points that are "approximately" centered. In Section 3 we describe quantities A ; A that were discovered independently by Stewart [30] and Todd <ref> [32] </ref>, and state some of their properties. Our complexity bounds depend on these parameters. In Section 4 we describe the layered least-squares step and the LIP method. <p> Let us define D to be the set of all positive definite n fi n diagonal matrices. Let us define A = supfkA T (ADA T ) 1 ADk : D 2 Dg: 9 Stewart [30] and Todd <ref> [32] </ref> independently proved that this quantity is always finite. Equivalently, one can show that A = supfk (ADA T ) 1 ADk : D 2 Dg is also finite. These bounds apply for any induced matrix norm, but for this paper, we confine ourselves to 2-norms.
Reference: [33] <author> K. Tone. </author> <title> An active-set strategy in an interior point method for linear programming. </title> <journal> Mathematical Programming, </journal> <volume> 59 </volume> <pages> 345-360, </pages> <year> 1993. </year>
Reference-contexts: The idea of partitioning the slacks into layers based on their relative sizes has been proposed by Kaliski and Ye [9] and Tone <ref> [33] </ref>, who both propose a decomposition into two layers. The interest of these authors is in improving the running-time of computing one iteration of an interior point method, rather than in obtaining new bounds on the number of iterations.
Reference: [34] <author> L. Tuncel. </author> <title> A pseudo-polynomial complexity analysis for interior-point al-gorithms. </title> <type> Technical Report CORR 93-16, </type> <institution> Department of Combinatorics and Optimization, University of Waterloo, Waterloo, </institution> <address> Ontario, Canada, </address> <year> 1993. </year>
Reference-contexts: Suppose that the total number of bits required to write A is L A . We have the following result (similar results can be found in Tuncel <ref> [34] </ref> and Vavasis and Ye [38]): Lemma 15 The parameters A and A are both bounded by 2 O (L A ) . Proof. We follow Todd's proof of the finiteness of A ; A . <p> As mentioned in Section 3, there is a relationship between A ; A and condition numbers of weighted least-squares problems as demonstrated by [37]. Thus, our new results can be thought of a link between condition number and complexity of iterative processes (also see <ref> [34] </ref> and [38]). Such links are well-known in numerical analysis; the classic example is the conjugate gradient algorithm (see [7]). Renegar [26] is currently also developing a theory connecting complexity and conditioning for interior point methods.
Reference: [35] <author> S. A. Vavasis. </author> <title> Nonlinear Optimization: Complexity Issues. </title> <publisher> Oxford University Press, </publisher> <address> New York, </address> <year> 1991. </year>
Reference-contexts: A vertex v satisfies A T B v = c B for some basic set of constraints. Thus, A supfkA T B k : B indexes a basisg: This in turn is bounded by 2 O (L A ) ; see, for example, Lemma 3.1 in <ref> [35] </ref>. Similarly, A is bounded by kAk A , so we obtain a bound of the same order. This leads to a new proof of the following corollary, which is a well-known result due to Tardos. <p> The step involves solving linear equations, which can be done in polynomial time <ref> [6, 35] </ref>. It can be proved that this truncation preserves approximate centering; see, for example, Chapter 3 of [35]. <p> The step involves solving linear equations, which can be done in polynomial time [6, 35]. It can be proved that this truncation preserves approximate centering; see, for example, Chapter 3 of <ref> [35] </ref>.
Reference: [36] <author> S. A. Vavasis. </author> <title> Stable finite elements for problems with wild coefficients. </title> <type> Technical Report 93-1364, </type> <institution> Department of Computer Science, Cornell University, </institution> <address> Ithaca, NY, </address> <year> 1993. </year> <note> To appear in SIAM J. Numerical Analysis. </note>
Reference-contexts: Thus, numbering these rows first for simpler notation, we have U * ! A T 0 A T B A = A 1 0 : Further theory concerning these parameters has been developed, for ex-ample, by Vavasis <ref> [36, 37] </ref>. The second paper shows that A ; A act like condition numbers for numerically stable solution of weighted least-squares problems involving A. The first paper estimates variants of these parameters for finite-element problems in terms of the geometry of the finite-element triangulation.
Reference: [37] <author> S. A. Vavasis. </author> <title> Stable numerical algorithms for equilibrium systems. </title> <journal> SIAM J. Matrix Anal. Appl, </journal> <volume> 15 </volume> <pages> 1108-1131, </pages> <year> 1994. </year>
Reference-contexts: Thus, numbering these rows first for simpler notation, we have U * ! A T 0 A T B A = A 1 0 : Further theory concerning these parameters has been developed, for ex-ample, by Vavasis <ref> [36, 37] </ref>. The second paper shows that A ; A act like condition numbers for numerically stable solution of weighted least-squares problems involving A. The first paper estimates variants of these parameters for finite-element problems in terms of the geometry of the finite-element triangulation. <p> One major gap in our understanding of these parameters is the question of computing them; we do not know of efficient algorithms for computing either parameter. See Section 13 for more comments on this matter. A final note is that in some earlier work such as [30] and <ref> [37] </ref> it was assumed that A was an m fi n matrix of rank n, and the definitions of A ; A in those papers involved the transpose matrix rather than the definition used above. <p> It would be interesting if there were a layered version of these algorithms. 6. As mentioned in Section 3, there is a relationship between A ; A and condition numbers of weighted least-squares problems as demonstrated by <ref> [37] </ref>. Thus, our new results can be thought of a link between condition number and complexity of iterative processes (also see [34] and [38]). Such links are well-known in numerical analysis; the classic example is the conjugate gradient algorithm (see [7]).
Reference: [38] <author> S. A. Vavasis and Y. Ye. </author> <title> Condition numbers for polyhedra with real number data. </title> <type> Technical Report 93-1398, </type> <institution> Department of Computer Science, Cornell University, </institution> <year> 1993. </year>
Reference-contexts: Suppose that the total number of bits required to write A is L A . We have the following result (similar results can be found in Tuncel [34] and Vavasis and Ye <ref> [38] </ref>): Lemma 15 The parameters A and A are both bounded by 2 O (L A ) . Proof. We follow Todd's proof of the finiteness of A ; A . Specifically, consider solving a weighted LS problem of finding y to minimize kD (A T y c)k. <p> As mentioned in Section 3, there is a relationship between A ; A and condition numbers of weighted least-squares problems as demonstrated by [37]. Thus, our new results can be thought of a link between condition number and complexity of iterative processes (also see [34] and <ref> [38] </ref>). Such links are well-known in numerical analysis; the classic example is the conjugate gradient algorithm (see [7]). Renegar [26] is currently also developing a theory connecting complexity and conditioning for interior point methods.
Reference: [39] <author> M. H. Wright. </author> <title> Numerical methods for nonlinearly constrained optimiza-tion. </title> <type> PhD thesis, </type> <institution> Stanford University, </institution> <year> 1976. </year> <month> 54 </month>
Reference-contexts: The interest of these authors is in improving the running-time of computing one iteration of an interior point method, rather than in obtaining new bounds on the number of iterations. Wright <ref> [39] </ref> in her PhD thesis also proposed the partitioning idea in the more general setting of barrier methods for constrained optimization. By the assumption of approximate centrality, each diagonal entry of SX is between (1 0 ) and (1 + 0 ).
Reference: [40] <author> M. H. Wright. </author> <title> Interior methods for constrained optimization. </title> <editor> In A. Iser-les, editor, </editor> <booktitle> Acta Numerica 1992, </booktitle> <pages> pages 341-407. </pages> <publisher> Cambridge University Press, </publisher> <address> Cambridge, </address> <year> 1992. </year>
Reference-contexts: The definition of the central path is credited to Bayer and Lagarias [2, 3, 4], Megiddo [16], and Sonnevend [28], and it was partially analyzed by McLinden [15] earlier. For the relationship between the central path and the classical log-barrier method, see Wright <ref> [40] </ref>. For interesting properties of the central path, see the excellent review article by Gonzaga [8]. In an interior point method, an exactly central point is never computed because there is no finite algorithm to solve the nonlinear equations (6). Therefore, one defines approximate centering. <p> Another very important issue for practical application is the best way to compute the LLS step. This computation can of course be reduced to solving linear equations, but there are many different ways to solve linear equations in interior point methods, and some are better than others|see <ref> [40] </ref>. 4. Our upper bound on the total number of main-loop iterations is n 2 =4, but we have not been able to construct any examples that required more than n main-loop iterations. Furthermore, another factor of n in the final complexity bound comes from g 2n appearing (43).
Reference: [41] <author> Y. Ye. </author> <title> On the finite convergence of interior-point algorithms for linear programming. </title> <journal> Mathematical Programming, </journal> <volume> 57 </volume> <pages> 325-336, </pages> <year> 1992. </year>
Reference-contexts: Traditional path-following methods take small steps along the central path until they are "sufficiently" close to an optimum. Once sufficiently close, a "rounding" procedure such as Khachiyan's [12] or least- squares computation such as Ye's <ref> [41] </ref> is used to obtain an exact optimum. In our new method, we interleave small steps with longer layered least- squares (LLS) steps to follow the central path. Thus, our method is always at least as efficient as existing path-following interior point methods.
Reference: [42] <author> Y. Ye, O. Guler, R. A. Tapia, and Y. Zhang. </author> <title> A quadratically conver-gent O( p nL)-iteration algorithm for linear programming. </title> <journal> Mathematical Programming, </journal> <volume> 59 </volume> <pages> 151-162, </pages> <year> 1993. </year> <month> 55 </month>
Reference-contexts: This fact is the basis for results on asymptotic quadratic convergence of interior point methods such as the result of Ye et al. <ref> [42] </ref> and earlier works cited therein. Sonnevend, Stoer and Zhao [29] have considered the total integral of the curvature in the path in order to bound complexity.
References-found: 42

