URL: ftp://ftp.cs.umass.edu/pub/techrept/techreport/1990/UM-CS-1990-015.ps
Refering-URL: http://forum.swarthmore.edu/~jay/learn-game/indexes/other-papers.html
Root-URL: 
Title: Feature Discovery for Inductive Concept Learning  
Author: Tom E. Fawcett 
Address: Amherst, MA 01003 U.S.A.  
Affiliation: Department of Computer and Information Science University of Massachusetts  
Abstract: COINS Technical Report 90-15 May 15, 1993 Abstract This paper describes Zenith, a discovery system that performs constructive induction. The system is able to generate and extend new features for concept learning using agenda-based heuristic search. The search is guided by feature worth (a composite measure of discriminability and cost). Zenith is distinguished from existing constructive induction systems by its interaction with a performance system, and its ability to extend its knowledge base by creating new domain classes. Zenith is able to discover known useful features for the Othello board game. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Callan, J. P. </author> <year> (1989). </year> <title> Knowledge-based feature generation. </title> <booktitle> Proceedings of the Sixth International Workshop on Machine Learning (pp. </booktitle> <pages> 441-443). </pages> <address> Ithaca, NY: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: The LTU is trained after every game on the current set of preference pairs, until a plateau of performance is reached. 2 A more detailed discussion may be found in <ref> (Utgoff, Saxena, Callan & Fawcett, 1989) </ref>. Feature Discovery for Inductive Concept Learning 5 2.3.3 Selecting moves with the LTU The LTU is then used by the performance system to choose its moves. The performance system first enumerates all successor states of the current state. <p> These produce an initial set of features from the goal expression, for use in the evaluation function, and so are only used once. These goal transformation heuristics currently used in Zenith are similar to those of <ref> (Callan, 1989) </ref>. For example, if a goal is to achieve the relationship f (s) &lt; g (s), then one such heuristic will produce three separate features measuring f (s), g (s), and f (s) g (s). Feature specialization heuristics. Specializing a feature can increase its discriminability by excluding negative instances.
Reference: <author> Dietterich, T., & Michalski, R. </author> <year> (1983). </year> <title> A comparative review of selected methods for learning from examples. </title> <editor> In Michalski, Carbonell & Mitchell (Eds.), </editor> <booktitle> Machine learning: An artificial intelligence approach. </booktitle> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Lenat, D. </author> <year> (1983). </year> <title> The role of heuristics in learning by discovery: Three case studies. </title> <editor> In Michalski, Carbonell & Mitchell (Eds.), </editor> <booktitle> Machine learning: An artificial intelligence approach. </booktitle> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: After this is done, the successor state with the highest count determines the performance system's move. 2.4 The Discovery System The discovery system is the major part of Zenith, and its structure is based on that of AM <ref> (Lenat, 1983) </ref>. The discovery system is agenda-driven and based on a set of heuristics. The agenda contains a set of tasks, ordered by priority 3 . The basic cycle of the discovery system is to remove the highest rated task from the agenda and execute it. <p> These problems make Othello intractable for existing discovery systems that depend on operators adding and deleting individual conditions (Scott & Markovitch, 1987; Shen & Simon, 1989), or that do not analyze state transitions <ref> (Lenat, 1983) </ref>. 4 Derivation of a Corner Square Feature One of the first things a beginning Othello player notices is the importance of occupying the corner squares. Recall that a disk is stable on a board if there is no sequence of subsequent moves that will flip it.
Reference: <author> Matheus, C. J., & Rendell, L. A. </author> <year> (1989). </year> <title> Constructive induction on decision trees. </title> <booktitle> Proceedings of the Eleventh International Joint Conference on Artificial Intelligence (pp. </booktitle> <pages> 645-650). </pages> <address> Detroit, Michigan: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: The problem of automatically generating or extending such a language has been called constructive induction (Michalski, 1983) and shift of bias (Utgoff & Mitchell, 1982). There have been a number of approaches to this problem. Methods such as FRINGE (Pagallo, 1989) and CITRE <ref> (Matheus & Rendell, 1989) </ref> are concept-based, in that the examples are processed using an existing set of features, then new features are created from the induced concept. For example, FRINGE looks for binary path segments near the leaves of a decision tree, and creates a new feature for each segment.
Reference: <author> Michalski, R. S., & Chilausky, R. L. </author> <year> (1980). </year> <title> Learning by being told and learning from examples: An experimental comparison of the two methods of knowledge acquisition in the context of developing an expert system for soybean disease diagnosis. </title> <journal> Policy Analysis and Information Systems, </journal> <volume> 4, </volume> <pages> 125-160. </pages>
Reference: <author> Michalski, R. S. </author> <year> (1983). </year> <title> A theory and methodology of inductive learning. </title> <editor> In Michalski, Carbonell & Mitchell (Eds.), </editor> <booktitle> Machine learning: An artificial intelligence approach. </booktitle> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Before a machine learning system can be used successfully, typically much human effort must go into selecting an appropriate instance description language. The problem of automatically generating or extending such a language has been called constructive induction <ref> (Michalski, 1983) </ref> and shift of bias (Utgoff & Mitchell, 1982). There have been a number of approaches to this problem.
Reference: <author> Nilsson, N. J. </author> <year> (1965). </year> <title> Learning machines. </title> <address> New York: </address> <publisher> McGraw-Hill. </publisher>
Reference-contexts: For example, decision tree algorithms (Quinlan, 1986) represent concepts implicitly as boolean expressions and split disjunctively on different attribute values at every branch point along a path. Linear threshhold units <ref> (Nilsson, 1965) </ref> represent the concept predicate as an inequality involving a threshhold and a weighted sum of example features. Many concept-learning systems (Michalski & Chilausky, 1980; Dietterich & Michalski, 1983) represent the concept as a boolean expression, but employ various different procedural biases that constrain the concept form.
Reference: <author> Pagallo, G. </author> <year> (1989). </year> <title> Learning DNF by decision trees. </title> <booktitle> Proceedings of the Eleventh International Joint Conference on Artificial Intelligence (pp. </booktitle> <pages> 639-644). </pages> <address> Detroit, Michigan: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: The problem of automatically generating or extending such a language has been called constructive induction (Michalski, 1983) and shift of bias (Utgoff & Mitchell, 1982). There have been a number of approaches to this problem. Methods such as FRINGE <ref> (Pagallo, 1989) </ref> and CITRE (Matheus & Rendell, 1989) are concept-based, in that the examples are processed using an existing set of features, then new features are created from the induced concept.
Reference: <author> Quinlan, J. R. </author> <year> (1986). </year> <title> Induction of decision trees. </title> <journal> Machine Learning, </journal> <volume> 1, </volume> <pages> 81-106. </pages>
Reference-contexts: Many induction algorithms have been devised that are able to inductively generalize in different formalisms, using learning rules appropriate for that formalism. For example, decision tree algorithms <ref> (Quinlan, 1986) </ref> represent concepts implicitly as boolean expressions and split disjunctively on different attribute values at every branch point along a path. Linear threshhold units (Nilsson, 1965) represent the concept predicate as an inequality involving a threshhold and a weighted sum of example features.
Reference: <author> Rosenbloom, P. </author> <year> (1982). </year> <title> A world-championship-level othello program. </title> <journal> Artificial Intelligence, </journal> <volume> 19, </volume> <pages> 279-320. </pages>
Reference-contexts: Corners are inherently stable, since no span can ever encompass them, and other stable disk configurations can be built out from them. Noticing the importance of corner squares is a critical step in developing a winning strategy for Othello <ref> (Rosenbloom, 1982) </ref>. However, the rules of the game do not mention stability, and they do not distinguish corner squares from other squares. Initially, Zenith's frame network contains little more than the rules of the game. <p> It is able to derive two well-known Othello features: corner square occupancy and piece mobility Feature Discovery for Inductive Concept Learning 9 (see <ref> (Rosenbloom, 1982) </ref> for a discussion of these). Zenith currently contains about fifteen heuristics, several from each of the classes given in Section 2.4.1. Feature regression heuristics have been designed but not yet implemented.
Reference: <author> Saxena, S. </author> <year> (1989). </year> <title> Evaluating alternative instance representations. </title> <booktitle> Proceedings of the Sixth International Workshop on Machine Learning (pp. </booktitle> <pages> 465-468). </pages> <address> Ithaca, NY: </address> <publisher> Morgan Kauf-mann. </publisher>
Reference-contexts: The LTU is trained after every game on the current set of preference pairs, until a plateau of performance is reached. 2 A more detailed discussion may be found in <ref> (Utgoff, Saxena, Callan & Fawcett, 1989) </ref>. Feature Discovery for Inductive Concept Learning 5 2.3.3 Selecting moves with the LTU The LTU is then used by the performance system to choose its moves. The performance system first enumerates all successor states of the current state. <p> For example, two features in conjunction may discriminate much more effectively than either alone could. Ideally a feature should be evaluated in the context of the entire feature pool. Recent advances in evaluating representation quality <ref> (Saxena, 1989) </ref> have produced algorithms that are able to accomplish this, and we expect to replace the current evaluation method and eliminate this problem. 10 Feature Discovery for Inductive Concept Learning 7 Acknowledgements This material is based on work supported by the Office of Naval Research through a University Research Initiative
Reference: <author> Schank, R., Collins, G., & Hunter, L. </author> <year> (1986). </year> <title> Transcending inductive category formation in learning. </title> <journal> Behavioral and Brain Sciences, </journal> <volume> 9, </volume> <pages> 639-686. </pages>
Reference: <author> Schlimmer, J. C., & Fisher, D. </author> <year> (1986). </year> <title> A case study of incremental concept induction. </title> <booktitle> Proceedings of the Fifth National Conference on Artificial Intelligence (pp. </booktitle> <pages> 496-501). </pages> <address> Philadelpha, PA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Schlimmer, J. C. </author> <year> (1987). </year> <title> Incremental adjustment of representations. </title> <booktitle> Proceedings of the Fourth International Workshop on Machine Learning (pp. </booktitle> <pages> 79-90). </pages> <address> Irvine, CA: </address> <note> Morgan Kaufmann. 12 Feature Discovery for Inductive Concept Learning Scott, </note> <author> Paul D., & Markovitch, </author> <title> Shaul (1987). Learning novel domains through curiosity and conjecture. </title> <booktitle> Proceedings of the Tenth International Joint Conference on Artificial Intelligence (pp. </booktitle> <pages> 669-674). </pages> <address> Milan, Italy: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Once these new features are added, the learning algorithm is applied again to the examples and the process continues until no new useful features are created. Other methods include defining new features by clustering attribute values (Schlimmer & Fisher, 1986; Michalski, 1983) and partitioning numeric attribute ranges <ref> (Schlimmer, 1987) </ref>. Although these are able to change the representation by creating new features, they share the disadvantage that they only work well if the features are already appropriate to the task. <p> An LTU was chosen for several reasons. An LTU is very fast both to train and to use. Zenith requires a learning method that can accomodate the addition and deletion of features, and an LTU is one of the few methods that can. A hybrid method (such as STAGGER <ref> (Schlimmer, 1987) </ref>) is undesirable since it may confound limitations in the algorithm and limitations in the feature set. Since the representational limitation of an LTU (linearly discriminable sets) is well known, this confusion is avoided. <p> Another specialization heuristic is to conjoin two features that have many common positive instances but few negative instances. This is similar to the method used by STAGGER <ref> (Schlimmer, 1987) </ref> for conjoining features. Feature generalization heuristics. These generalize or cluster a set of existing features, in order to increase generality and efficiency.
Reference: <author> Shen, Wei-Min, & Simon, </author> <title> Herbert (1989). Rule creation and rule learning through environmental exploration. </title> <booktitle> Proceedings of the Eleventh International Joint Conference on Artificial Intelligence (pp. </booktitle> <pages> 675-680). </pages> <address> Detroit, Michigan: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Utgoff, P. E., & Mitchell, T. M. </author> <year> (1982). </year> <title> Acquisition of appropriate bias for inductive concept learning. </title> <booktitle> Proceedings of the Second National Conference on Artificial Intelligence (pp. </booktitle> <pages> 414-417). </pages> <address> Pittsburgh, PA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Before a machine learning system can be used successfully, typically much human effort must go into selecting an appropriate instance description language. The problem of automatically generating or extending such a language has been called constructive induction (Michalski, 1983) and shift of bias <ref> (Utgoff & Mitchell, 1982) </ref>. There have been a number of approaches to this problem. Methods such as FRINGE (Pagallo, 1989) and CITRE (Matheus & Rendell, 1989) are concept-based, in that the examples are processed using an existing set of features, then new features are created from the induced concept. <p> Another approach is to use strong domain knowledge combined with information about the learning goal to guide the creation of new terms. The STABB component <ref> (Utgoff & Mitchell, 1982) </ref> of LEX used constraint back-propagation to extend its concept description language when it was found to be inadequate.
Reference: <author> Utgoff, P. E., & Saxena, S. </author> <year> (1987). </year> <title> Learning a preference predicate. </title> <booktitle> Proceedings of the Fourth International Workshop on Machine Learning (pp. </booktitle> <pages> 115-121). </pages> <address> Irvine, CA: </address> <publisher> Morgan Kauf-mann. </publisher>
Reference-contexts: Its opponent is an Othello-playing program that searches to a fixed depth using a handcoded evaluation function. The performance system chooses its moves using a preference predicate <ref> (Utgoff & Saxena, 1987) </ref> based on the currently active features. A preference predicate p is a generalization of an evaluation function, such that p (S 1 ; S 2 ) is true iff state S 1 is better than S 2 for the performance system.
Reference: <author> Utgoff, P. E., Saxena, S., Callan, J. P., & Fawcett, T. E. </author> <year> (1989). </year> <title> Representation problems in machine learning: A proposal, </title> <type> (COINS Technical Report 89-23), </type> <institution> Amherst, MA: University of Massachusetts, Department of Computer and Information Science. </institution>
Reference-contexts: The LTU is trained after every game on the current set of preference pairs, until a plateau of performance is reached. 2 A more detailed discussion may be found in <ref> (Utgoff, Saxena, Callan & Fawcett, 1989) </ref>. Feature Discovery for Inductive Concept Learning 5 2.3.3 Selecting moves with the LTU The LTU is then used by the performance system to choose its moves. The performance system first enumerates all successor states of the current state.
References-found: 18

