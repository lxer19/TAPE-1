URL: http://www.cs.cmu.edu/~jr6b/papers/ifile98.ps.gz
Refering-URL: http://www.cs.cmu.edu/~jr6b/
Root-URL: http://www.cs.cmu.edu/~jr6b
Email: jr6b@andrew.cmu.edu  
Title: ifile: An Application of Machine Learning to E-Mail Filtering  
Author: Jason Rennie 
Date: December 1, 1998  
Address: Pittsburgh, PA 15213  
Affiliation: School of Computer Science Carnegie Mellon University  
Abstract: With the proliferation of electronic mail in the modern era, it becomes ever more important to devise methods for the organization, categorization and searching of such mail. Mail filtering is such a method for the organization of incoming e-mail. In this paper, we critique modern mail filters and describe how Machine Learning techniques could improve upon them without eliminating the benefits they provide. We then present ifile, a mail filter which makes use of the text classification algorithm naive Bayes. Furthermore, we present experiments showing its classification performance on sets of private e-mail and point out some of the issues involved with creating a Machine Learning based mail filter. We conclude that ifile eliminates some of the problems with modern mail filters while still maintaining high classification accuracy. 
Abstract-found: 1
Intro-found: 1
Reference: [Coh96] <author> William Cohen. </author> <title> Learning rules that classify e-mail. </title> <booktitle> In AAAI Spring Symposium on Machine Learning in Information Access, </booktitle> <year> 1996. </year>
Reference-contexts: David Lewis and Kimberly Knowles use a TF-IDF classifier to successfully match e-mail messages with their "parents" [LK97]. William Cohen tests TF-IDF and a rule-based classifier on a corpus of her own e-mail <ref> [Coh96] </ref>. Finally, Thorsten Joachims uses Support Vector Machines to classify Reuters documents [Joa98]. Studies which concern themselves with the classification of e-mail documents generally show Machine Learning algorithms achieving accuracies of 80% or better, even when the classification task is across a wide range of classes.
Reference: [Joa98] <author> Thorsten Joachims. </author> <title> Text categorization with support vector machines: Learning with many relevant features. </title> <booktitle> In European Conference on Machine Learning, </booktitle> <year> 1998. </year>
Reference-contexts: David Lewis and Kimberly Knowles use a TF-IDF classifier to successfully match e-mail messages with their "parents" [LK97]. William Cohen tests TF-IDF and a rule-based classifier on a corpus of her own e-mail [Coh96]. Finally, Thorsten Joachims uses Support Vector Machines to classify Reuters documents <ref> [Joa98] </ref>. Studies which concern themselves with the classification of e-mail documents generally show Machine Learning algorithms achieving accuracies of 80% or better, even when the classification task is across a wide range of classes.
Reference: [Lan95] <author> Ken Lang. Newsweeder: </author> <title> Learning to filter netnews. </title> <booktitle> In International Conference on Machine Learning, </booktitle> <pages> pages 331-339, </pages> <year> 1995. </year>
Reference-contexts: Ken Lang uses TF-IDF to score high classification accuracy on the task of classifying an array of netnews documents into newsgroups in which they belong <ref> [Lan95] </ref>. David Lewis and Kimberly Knowles use a TF-IDF classifier to successfully match e-mail messages with their "parents" [LK97]. William Cohen tests TF-IDF and a rule-based classifier on a corpus of her own e-mail [Coh96]. Finally, Thorsten Joachims uses Support Vector Machines to classify Reuters documents [Joa98].
Reference: [LK97] <author> David D. Lewis and Kimberly A. Knowles. </author> <title> Threading electronic mail: A preliminary study. </title> <booktitle> Information Processing and Management, </booktitle> <volume> 33(2) </volume> <pages> 209-217, </pages> <year> 1997. </year>
Reference-contexts: Ken Lang uses TF-IDF to score high classification accuracy on the task of classifying an array of netnews documents into newsgroups in which they belong [Lan95]. David Lewis and Kimberly Knowles use a TF-IDF classifier to successfully match e-mail messages with their "parents" <ref> [LK97] </ref>. William Cohen tests TF-IDF and a rule-based classifier on a corpus of her own e-mail [Coh96]. Finally, Thorsten Joachims uses Support Vector Machines to classify Reuters documents [Joa98]. <p> It might also be useful to detect threads as in <ref> [LK97] </ref> under the assumption that all messages which are part of a certain thread belong to the same mailbox.
Reference: [Mit97] <author> Tom Mitchell. </author> <title> Machine Learning. </title> <publisher> McGraw-Hill Companies, Inc., </publisher> <year> 1997. </year>
Reference-contexts: Without further ado, we present the text classifier which is used in the ifile mail filtering system. A more complete description is available in chapter 6 of <ref> [Mit97] </ref>. Naive Bayes is a statistical machine learning algorithm which makes the assumption that a document is simply a set of words chosen randomly from some underlying distribution determined by the document's class. Thus, each word is considered independent of its actual location within a document.
Reference: [Pay94] <author> Terry Payne. </author> <title> Learning email filtering rules with magi, a mail agent interface. 1994. </title> <type> MSc Thesis, </type> <institution> Department of Computing Science, University of Aberdeen, </institution> <address> Scotland. </address>
Reference-contexts: Motivated by the quest to achieve greater filtering accuracy, one interesting area of possible exploration would be the combination of a rule-learning algorithm with a text classification algorithm such as naive Bayes. Rule-based learning algorithms, such as CN2, used in <ref> [Pay94] </ref>, often allow fine control of the tradeoff between precision and recall.
Reference: [YP97] <author> Y. Yang and J.P. Pedersen. </author> <title> Feature selection in statistical learning of text categorization. </title> <booktitle> In Fourteenth International Conference on Machine Learning, </booktitle> <year> 1997. </year> <month> 12 </month>
Reference-contexts: In the context of text categorization, feature selection limits the number of words which are used for the purposes of classification. This can be used to increase the performance of an algorithm on certain data sets. It can also be useful for making the classification task less computationally daunting. <ref> [YP97] </ref> compares the performance of four different feature selection methods and determines that document frequency is a reasonable method.
References-found: 7

