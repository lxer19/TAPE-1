URL: http://www.cs.cornell.edu/Info/People/coleman/PAPERS/wave.ps
Refering-URL: http://www.cs.cornell.edu/Info/People/coleman/papers.html
Root-URL: 
Title: Efficient Calculation of Jacobian and Adjoint Vector Products in Wave Propagational Inverse Problem Using Automatic Differentiation  
Author: Thomas F. Coleman Fadil Santosa Arun Verma 
Abstract: Wave propagational inverse problems arise in several applications including medical imaging and geophysical exploration. In these problems, one is interested in obtaining the parameters describing the medium from its response to excitations. The problems are characterized by their large size, and by the hyperbolic equation which models the physical phenomena. The inverse problems are often posed as a nonlinear data-fitting where the unknown parameters are found by minimizing the misfit between the predicted data and the actual data. In order to solve the problem numerically using a gradient-type approach, one must calculate the action of the Jacobian and its adjoint on a given vector. In this paper, we explore the use of automatic differentiation (AD) to develop codes that perform these calculations. We show that by exploiting structure at 2 scales, we can arrive at a very efficient code whose main components are produced by AD. In the first scale we exploit the time-stepping nature of the hyperbolic solver by using the "Extended Jacobian" framework. In the second (finer) scale, we exploit the finite difference stencil in order to make explicit use of the sparsity in the dependence of the output variables to the input variables. The main ideas in this work are illustrated with a simpler, one-dimensional version of the problem. Numerical results are given for both one- and two- dimensional problems. We present computational templates that can be used in conjunction with optimization packages to solve the inverse problem.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> G. Chavent, F. Clement, and S. Gomez, </author> <title> Waveform inversion by MBTT formulation, in Mathematical and Numerical Aspects of Wave Propagation, </title> <editor> Cohen et al eds., </editor> <publisher> SIAM, </publisher> <address> 19 Philadephia, </address> <year> 1995, </year> <pages> pp. 713-722. </pages>
Reference-contexts: Often, the most convenient way to solve this type of inverse is to pose it as an optimization, either using using nonlinear leastsquares [16, 12] or other approach specialized to take advantage of the properties afforded by the particular application <ref> [14, 1] </ref>. In any event, what one will need for computation is derivative information of the relation between medium parameters and data. <p> Then the finite difference scheme amounts to u k+1 = F (c; u k ; u k1 ); with u 1 = u 0 = 0: (4) The forward map from c to A [c] is given by, letting e 1 = <ref> [1; 0; ; 0] </ref> T A [c] k = e T The inverse problem is to solve for c in min kA [c] gk 2 (6) where g is a data vector corresponding to a measurement. 5 2.2 Two-dimensional problem The two-dimensional problem is motivated by a problem in acoustic imaging
Reference: [2] <author> T. Coleman and A. Verma, </author> <title> The efficient computation of sparse Jacobian matrices using automatic differentiation, </title> <journal> SIAM Journal on Scientific Computing (1998), </journal> <volume> 19, </volume> <pages> pp. 1210-1233. </pages>
Reference-contexts: We discuss how this is done in the next section. In principle, what we are exploiting is specific sparsity structure that is inherent in the finite difference scheme. A general approach for exploiting sparsity in AD is described in <ref> [2] </ref>. 4 Exploiting the stencil structure The finite difference method that we used in the 1-D can be written as indicated in (4) which we rewrite here u k+1 = F (c; u k ; u k1 ); with u 1 = u 0 = 0: This shorthand notation does not
Reference: [3] <author> T. Coleman and A. Verma, </author> <title> Structure and efficient Hessian calculation, in Advances in Nonlinear Programming, </title> <editor> Yuan, ed., </editor> <publisher> Kluwer, </publisher> <address> Boston, </address> <year> 1996. </year>
Reference-contexts: As we will show in the next section, the wave propagation can be modeled effectively using time-stepping finite difference schemes. The time-stepping nature of the scheme can be exploited using the general Extended Jacobian framework <ref> [3, 4] </ref>. The spatial discretiza 3 tion by finite differences reveal further structure. Each finite difference stencil encodes the dependence of a computed intermediate variable on other variables. In particular, it shows that there is an inherent sparsity in the Jacobian. <p> The desired directional derivative (Jacobian times vector dc) is dh = (dh 1 ; dh 2 ; ; dh m ) T . 3.1 Adjoint computation via linear algebra The above calculation can be defined as a set of matrix equations through the use of the extended Jacobian framework <ref> [3, 4] </ref>. Let dU = 6 6 4 du 2 du m 7 7 5 Define the m (n + 1) fi m (n + 1) matrix M = 6 6 6 6 6 4 . . .
Reference: [4] <author> T. Coleman and A. Verma, </author> <title> Structure and efficient Jacobian calculation, in Computational Differentiation: Techniques, Applications, and Tools, </title> <editor> Berz, et al eds., </editor> <publisher> SIAM, </publisher> <address> Philadelphia, </address> <year> 1996, </year> <pages> pp. 149-159. </pages>
Reference-contexts: As we will show in the next section, the wave propagation can be modeled effectively using time-stepping finite difference schemes. The time-stepping nature of the scheme can be exploited using the general Extended Jacobian framework <ref> [3, 4] </ref>. The spatial discretiza 3 tion by finite differences reveal further structure. Each finite difference stencil encodes the dependence of a computed intermediate variable on other variables. In particular, it shows that there is an inherent sparsity in the Jacobian. <p> The desired directional derivative (Jacobian times vector dc) is dh = (dh 1 ; dh 2 ; ; dh m ) T . 3.1 Adjoint computation via linear algebra The above calculation can be defined as a set of matrix equations through the use of the extended Jacobian framework <ref> [3, 4] </ref>. Let dU = 6 6 4 du 2 du m 7 7 5 Define the m (n + 1) fi m (n + 1) matrix M = 6 6 6 6 6 4 . . .
Reference: [5] <author> T. Coleman, F. Santosa, and A. Verma, </author> <title> Semi-automatic differentiation, </title> <booktitle> Proceedings of Optimal Design and Control Workshop, </booktitle> <address> VPI, </address> <year> 1997. </year>
Reference: [6] <author> B. Enquist and A. Majda, </author> <title> Absorbing boundary conditions for the numerical simulation of waves, </title> <journal> Math. Comp. (1977), </journal> <volume> 31, </volume> <pages> pp. 629-651. </pages>
Reference-contexts: To simulate the unbounded medium, we assume that c is constant near the boundary of and apply the Engquist-Majda boundary conditions <ref> [6] </ref> along the flat parts of @ (and a modification of Enquist-Majda at the corners of @).
Reference: [7] <author> R. Giering, </author> <title> Tangent Linear and Adjoint Model Compiler, User Manual, </title> <note> TAMC Version 4.7, </note> <year> 1997. </year>
Reference-contexts: Indeed, we have coded a version of algorithms (19) and (20) for the 2-D problem. We discuss the results of our numerical calculations next. 5 Numerical results We present some results from our numerical computations. In both examples, we use TAMC <ref> [7] </ref> to obtain derivative and adjoint codes from fortran sources. All the fortran codes were `wrapped' as MATLAB mex-files and used in conjunction with MATLAB codes. Our goal in this paper is to demonstrate the use of extended Jacobian framework together with exploitation of stencil in Jacobian and adjoint calculations.
Reference: [8] <author> A. Griewank, </author> <title> Achieving logarithmic growth of temporal and spatial complexity in reverse automatic differentiation, </title> <journal> Optimization Methods and Software (1992), </journal> <volume> 1, </volume> <pages> pp. 35-54. </pages>
Reference-contexts: Depending on the size of the problem, it may be more efficient to store only values of u k for some indices k 2 K, and use (9) to generate the field for other indices k =2 K. An efficient method to do this is discussed in <ref> [8] </ref>. 3.2 Adjoint computation via adjoint variables We give an alternate derivation of the algorithm in (14) which is based on using adjoint variables. Consider a simple calculation involving the following 3 steps.
Reference: [9] <author> A. Griewank, </author> <title> Some bounds on the complexity of gradients, Jacobians, and Hessians, in Complexity in Nonlinear Optimization, </title> <editor> Pardalos, ed., </editor> <publisher> World Scientific Publishers, </publisher> <year> 1993. </year>
Reference-contexts: v 2 = f 2 (c; u 2 ; u 1 )v 3 p = f 1 (c; u 2 ; u 1 )v 3 + f 1 (c; u 1 ; u 0 )v 2 + f 1 (c; u 0 ; 0)v 1 This is the reverse computation <ref> [9] </ref>. We can generalize this concept to the 1-D wave propagation problem. In (10), we identify adjoint variables p with dc for the input, and q with dh for the output. To the intermediate variables du k , we associate adjoint variables v k .
Reference: [10] <author> A. Griewank, D. Juedes, and J. Utke, ADOL-C, </author> <title> a package for the automatic differentiation of algorithms written in C/C++, </title> <journal> ACM Trans. Math. Software (1996), </journal> <volume> 22, </volume> <pages> 131-167. </pages>
Reference-contexts: This assumption on dependence generates a `table' which is used in computing intermediate values in the reverse product mode. For example, ADOL-C <ref> [10] </ref> implements this lookup by creating a tape, which it will write on the disk if the problem size is large. When it does this, it becomes unacceptably inefficient. This concern brings us to the main idea of this paper, i.e., that of AD applied to the finite difference stencil.
Reference: [11] <author> T. Mast, A. Nachman, and R. Waag, </author> <title> Focussing and imaging using eigenfunctions of the scattering operator, </title> <journal> J. Acous. Soc. Am., </journal> <note> to appear. </note>
Reference-contexts: The geometry of the problem has been described in the previous section, and elsewhere <ref> [11] </ref>. Here we give a mathematical model of the physics. Because any computational domain is necessarily finite, we will consider a box := [a; a] fi [a; a].
Reference: [12] <author> F. Santosa and W. Symes, </author> <title> An Analysis of Least-Squares Velocity Inversion, </title> <booktitle> Society of Exploration Geophysicists, </booktitle> <address> Tulsa, </address> <year> 1989. </year>
Reference-contexts: Typically, the number of unknowns and equations could be in the range of 10 3 to 10 6 . Often, the most convenient way to solve this type of inverse is to pose it as an optimization, either using using nonlinear leastsquares <ref> [16, 12] </ref> or other approach specialized to take advantage of the properties afforded by the particular application [14, 1]. In any event, what one will need for computation is derivative information of the relation between medium parameters and data.
Reference: [13] <author> F. Santosa and W. Symes, </author> <title> Computation of the Hessian for least-squares solutions of inverse problems of reflection seismology, Inverse Problem, </title> <booktitle> 4(1988), </booktitle> <pages> pp. 211-233 </pages>
Reference-contexts: The resulting code is as efficient as those that are obtained by directly performing summations-by-parts calculation on the simulation program. The advantage here is that we have avoided the error-prone and tedious procedure <ref> [13] </ref>. Instead, we can view the code writing process at a higher level, leaving the most difficult parts to AD. The plan of this article is as follows. We proceed with a short introduction to inverse problem for acoustic waves.
Reference: [14] <author> W. Symes, </author> <title> A differential semblance criterion for inversion of multioffset seismic reflection data, </title> <journal> J. Geophys. Res (1993), </journal> <volume> 98, </volume> <pages> pp. 2061-2073. </pages>
Reference-contexts: Often, the most convenient way to solve this type of inverse is to pose it as an optimization, either using using nonlinear leastsquares [16, 12] or other approach specialized to take advantage of the properties afforded by the particular application <ref> [14, 1] </ref>. In any event, what one will need for computation is derivative information of the relation between medium parameters and data.
Reference: [15] <author> W. Symes and C. Zhang, </author> <title> A finite difference time stepping class, </title> <institution> Rice University TRIP report, </institution> <year> 1997. </year>
Reference-contexts: Templates for calculating Jacobian and adjoint vector products that uses stencils are given. Section 5 summarizes our experience with this method of computation. A final section contains concluding remarks. We acknowledge helpful discussions with William Symes, who has a similar on-going effort on automatic differentiation as ours <ref> [15] </ref>. Some of the ideas in this work were inspired by his presentation at the Institute for Mathematics and its Applications, Minnesota, in July 1997. 2 Inverse Problems and Numerical Modeling 2.1 One-dimensional problem Consider a bar or string of unit length whose sound speed is location dependent.
Reference: [16] <author> A. Tarantola, </author> <title> Inverse Problem Theory, </title> <publisher> Elsevier, </publisher> <address> Amsterdam, </address> <year> 1987. </year> <title> 20 speed anomalies. The darker cylinder is 2% faster while the lighter cylinder is 1% faster than the background medium. Shown in circles are the receiver locations. Star marks the location of the point source. (b) The receiver data when the two cylinders are present. (c) The difference between (b) and receiver data when the medium is constant. (d) The adjoint applied to (c). (e) The two cylinders plotted on the same scale as in (d) for comparison. </title>
Reference-contexts: Typically, the number of unknowns and equations could be in the range of 10 3 to 10 6 . Often, the most convenient way to solve this type of inverse is to pose it as an optimization, either using using nonlinear leastsquares <ref> [16, 12] </ref> or other approach specialized to take advantage of the properties afforded by the particular application [14, 1]. In any event, what one will need for computation is derivative information of the relation between medium parameters and data.
References-found: 16

