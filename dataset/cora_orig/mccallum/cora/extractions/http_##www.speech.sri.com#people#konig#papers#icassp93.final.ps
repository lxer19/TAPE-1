URL: http://www.speech.sri.com/people/konig/papers/icassp93.final.ps
Refering-URL: http://www.speech.sri.com/people/konig/resume.html
Root-URL: 
Title: SUPERVISED AND UNSUPERVISED CLUSTERING OF THE SPEAKER SPACE FOR CONNECTIONIST SPEECH RECOGNITION  
Author: Yochai Konig Nelson Morgan 
Address: 1947 Center Street, Suite 600 Berkeley, CA 94704, USA.  
Affiliation: International Computer Science Institute  
Abstract: One of the challenging problems of a speaker independent - continuous speech recognition system is how to achieve good performance with a new speaker, when the only available source of information about the new speaker is the utterance to be recognized. We propose here a first step towards a solution, based on clustering of the speaker space. Our study had two steps: first we searched for a set of features to cluster speakers. Then, using the chosen features, we investigated two kinds of clustering: supervised using two clusters: males and females, and unsupervised using two, three, and five clusters. We have integrated the cluster information into our connectionist speech recognition system by using the Speaker Cluster Neural Network(SCNN). The SCNN attempts to share the speaker independent parameters and to model the cluster dependent parameters. Our results show that the best performance is achieved with the supervised clusters, resulting in an overall improvement in recognition performance. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Bourlard, H., Morgan, .N., </author> " <title> Merging Multilayer Perceptrons and Hidden Markov Models: Some Experiments in Continuous Speech Recognition", Neural Networks: </title> <booktitle> Advances and Applications, </booktitle> <publisher> Elsevier Science Publishers B.V., North Holland, </publisher> <year> 1991. </year>
Reference-contexts: 1. INTRODUCTION 1.1. Motivation and Description Reports over the last few years have described improvements in continuous speech recognition using a Multilayer Perceptron (MLP) to estimate output probabilities for Hidden Markov Models (HMMs) <ref> [1] </ref>. However, both hybrid HMM/MLP systems and conventional HMM speaker-independent speech recognition systems do not incorporate parameters chosen for speaker-dependent sensitivity in the process of phonemic probability estimation. <p> We have experimented with k = 2; 3; 5. For each value of k we have trained a net to estimate the probability P (clusterjData). For the training of these nets we have averaged the feature vectors along each sentence. For further details on training, see <ref> [1] </ref>. 3. INCORPORATING THE CLUSTER INFORMATION INTO OUR CONNECTIONIST SPEECH RECOGNITION SYSTEM Our goal is to find an architecture that enables us to model cluster dependent parameters and to share the speaker independent parameters.
Reference: [2] <author> Pallett, D., Fiscus, J., and Garofolo, J., </author> <title> "DARPA Resource Management Benchmark Test Results June 1990, </title> <booktitle> DARPA Speech and Language Workshop. </booktitle> <publisher> Morgan Kauf-mann Publishers, </publisher> <address> San Mateo, CA, </address> <year> 1990, </year> <month> pp.298-305. </month>
Reference-contexts: in the speaker-dependent parameters as a function of the available information about the speaker? Ultimately, when we have almost perfect answers to the above questions, we will be able to reach the performance of speaker-dependent systems that are two to three times better than speaker-independent systems for a given task <ref> [2] </ref>. In our study the only available information from a new speaker is the utterance to be recognized. We attempt to bias the probability estimation of phonemes according to the cluster of the speaker.
Reference: [3] <author> Lee, K. F., </author> <title> Automatic Speech Recognition: The Development of SPHINX System, </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1989. </year>
Reference-contexts: For the cluster identification stage, the speaker has to provide a training sentence with its correct identity, in order to find the correct cluster. K.F. Lee experimented with an algorithm for speaker clustering <ref> [3] </ref>. However, his results are not better than those with speaker-independent recognition, because he did not have enough training data for each speaker cluster.
Reference: [4] <author> Hampshire, J.B., and Waibel, A., </author> <title> "Connectionist Architectures for Multi-Speaker Phoneme Recognition", </title> <editor> in D.S. Touretzky, editor, </editor> <booktitle> Advances in Neural Information Processing Systems 2, </booktitle> <address> San Mateo,CA, </address> <publisher> Morgan Kaufman, </publisher> <year> 1990. </year>
Reference-contexts: He suggests that the entire speaker-independent training set may be used for each cluster to train similar speaker-independent parameters, and in our solution we have applied this idea. Hampshire and Waibel presented the "Meta-Pi" architecture <ref> [4] </ref>. The building blocks for the "Meta-Pi" architecture are multiple TDNN's that are trained to recognize the speech of an individual speaker. These building blocks are integrated by another multiple TDNN trained in a Bayesian MAP scheme to maximize the phoneme recognition rate of the over-all architecture.
Reference: [5] <author> Huang, X. D., Lee, K. F., and Waibel, A., </author> <title> "Connectionist Speaker Normalization and Its Applications To Speech Recognition ", Neural Networks for Signal Processing, </title> <booktitle> Proc. of the 1991 IEEE Workshop, </booktitle> <address> Princeton, New Jersey, </address> <month> October </month> <year> 1991. </year>
Reference-contexts: Another example of related work is speaker normalization, which attempts to minimize between-speaker variations by transforming the data of a new speaker to a reference speaker, and then applying the speaker dependent system for the reference speaker <ref> [5] </ref>. 1.3.
Reference: [6] <author> Konig, Y., Morgan, N., "GDNN: </author> <title> A Gender-Dependent Neural Network for Continuous Speech Recognition", </title> <booktitle> Proc. of the 1992 International Joint Conference on Neural Networks, </booktitle> <address> Baltimore, Maryland, </address> <month> June </month> <year> 1992. </year>
Reference-contexts: INCORPORATING THE CLUSTER INFORMATION INTO OUR CONNECTIONIST SPEECH RECOGNITION SYSTEM Our goal is to find an architecture that enables us to model cluster dependent parameters and to share the speaker independent parameters. As an extension to our previous work on the Gender-Dependent Neural Network (GDNN) <ref> [6] </ref> we have found an architecture that attempts to achieve this goal as shown in fig 1. During training we set the binary units according to the main cluster of the speaker, i.e., 1 for the main cluster unit and 0 for all the other units.
Reference: [7] <author> Abrash. V., Franco. H., Cohen. M., Morgan. N., and Konig. Y., </author> <title> "Connectionist Gender Adaptation in a Hybrid Neural Network/Hidden Markov Model Speech Recognition System", </title> <booktitle> Proc. of the International Conference on Spoken Language Processing, </booktitle> <address> Banff, Alberta, Canada, </address> <month> October </month> <year> 1992. </year>
Reference: [8] <author> Konig. Y., Morgan. N., Wooters. C., Abrash. V., Cohen. M., and Franco. H., </author> <title> "Modeling Consistency in a Speaker Independent Continuous Speech Recognition System" in Hanson. </title> <editor> J.S., Cowan. J.D., and Giles. C.L., editors, </editor> <booktitle> Advances in Neural Information Processing Systems 5, </booktitle> <address> San Mateo,CA, </address> <note> Morgan Kaufman, to appear. </note>
Reference: [9] <author> Morgan. N., and Bourlard. H., </author> <title> "Factoring Networks by a Statistical Method", Neural Computation, </title> <publisher> 4,835-838, MIT,1992. </publisher>
Reference-contexts: Note that the probability P (cluster i jdata) is estimated by the classification net referred to above, and that P (phonejcluster i ; data) is estimated by the net in Figure 1. The other probabilities can be trivially estimated from the training data. See <ref> [9] </ref> for further discussion on how to factor probabilities by networks. 4. EXPERIMENTS AND RESULTS We have compared our baseline system with our Speaker Cluster Neural Network (SCNN) described above. In the supervised case we have used two clusters: males and females.
Reference: [10] <author> Cohen, M., Franco, H., Morgan, N., Rumelhart, D., and Abrash, V., </author> <title> "Hybrid Neural Network/Hidden Markov Model Continuous Speech Recognition", </title> <booktitle> Proc. of the International Conference on Spoken Language Processing, </booktitle> <address> Banff, Alberta, Canada, </address> <month> October </month> <year> 1992. </year>
Reference-contexts: The results are summarized in table 1. We should note here that these results are all somewhat worse than our joint results with SRI published in <ref> [10] </ref>, as the latter were achieved using SRI's phonological models, and these were done with a single-pronunciation single-state HMM (with each state repeated for a rough duration model). We have also experimented with a different architecture than the SCNN.
References-found: 10

