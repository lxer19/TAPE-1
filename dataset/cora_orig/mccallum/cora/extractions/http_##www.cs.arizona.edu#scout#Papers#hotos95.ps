URL: http://www.cs.arizona.edu/scout/Papers/hotos95.ps
Refering-URL: http://www.cs.arizona.edu/scout/publications.html
Root-URL: http://www.cs.arizona.edu
Title: Scout: A Communications-Oriented Operating System  
Author: Allen B. Montz David Mosberger Sean W. O'Malley Larry L. Peterson Todd A. Proebsting 
Abstract:  
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. B. Abbott and L. L. Peterson. </author> <title> Increasing network throughput by integrating protocol layers. </title> <journal> IEEE/ACM Transactions on Networking, </journal> <volume> 1(5) </volume> <pages> 600-610, </pages> <month> Oct. </month> <year> 1993. </year>
Reference-contexts: Improving OS performance is the main reason to revisit the compiler issue. For example, our experience with protocol software shows that there is an opportunity for the compiler to automatically organize OS code so that it is more compatible with the memory architectures on modern RISC processors <ref> [1] </ref>. We have also found code patterns unique to operating systems, but not necessarily common in application-level code, that can be more heavily optimized [1]. Such optimizations are necessary if the operating system has any hope of staying on the processor performance curve. <p> there is an opportunity for the compiler to automatically organize OS code so that it is more compatible with the memory architectures on modern RISC processors <ref> [1] </ref>. We have also found code patterns unique to operating systems, but not necessarily common in application-level code, that can be more heavily optimized [1]. Such optimizations are necessary if the operating system has any hope of staying on the processor performance curve. Not only is the compiler a key to performance, but it is also an important tool for easing the task of the operating system implementor.
Reference: [2] <author> A. F. Brian N. Berhad, Richard P. Draves. </author> <title> Using mi-crobenchmarks to evaluate system performance. </title> <booktitle> In Proc. Third Workshop on Workstation Operating Systems, </booktitle> <pages> pages 148-153, </pages> <address> Key Biscayne, FL (USA), </address> <month> Apr. </month> <year> 1992. </year> <note> IEEE. </note>
Reference-contexts: Finally, we have observed numerous cases where the performance of micro-benchmarks bear little relationship to the performance of the system as a whole, and in fact, optimizing a particular module is just as likely to hurt overall system performance as help it. Others have reported similar phenomena <ref> [2] </ref>. The bottom line is that OS performance will not scale until the OS is able to consistently take advantage of those very architectural features that are responsible for improved performancecaches and instruction pipelines.
Reference: [3] <author> J. B. Chen and B. Bershad. </author> <title> The impact of operating system structure on memory system performance. </title> <booktitle> In Proceedings of the Fourteenth ACM Symposium on Operating Systems Principles, </booktitle> <month> Dec. </month> <year> 1993. </year>
Reference-contexts: In the case of the data cache (D-cache), we found that only 5% of the message fragments brought into the cache when they are received are still there by the time the application is scheduled to run [12]; other studies have uncovered similar effects <ref> [3] </ref>. We also found that making the wrong branch prediction on a critical path can mean the difference between whether or not a real-time embedded system is able to live within its instruction budget [6].
Reference: [4] <author> P. Druschel, M. B. Abbott, M. Pagels, and L. L. Pe-terson. </author> <title> Network subsystem design. </title> <journal> IEEE Network (Special Issue on End-System Support for High Speed Networks), </journal> <volume> 7(4) </volume> <pages> 8-17, </pages> <month> July </month> <year> 1993. </year>
Reference-contexts: Given this situation, it is little wonder that operating systems are not becoming faster as fast as processors are becoming faster [11]. Our experiences integrating the x-kernel into Mach illustrates the problem <ref> [4] </ref>. For example, we have protocol stacks that have no better latency on DECstation 5000 workstations than they did on Sun3 workstations, and changing the load order of the object modules in the system sometimes led to a 50% change in network software latency.
Reference: [5] <author> P. Druschel and L. L. Peterson. Fbufs: </author> <title> A high-bandwidth cross-domain transfer facility. </title> <booktitle> In Proceedings of the Fourteenth ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 189-202, </pages> <month> Dec. </month> <year> 1993. </year>
Reference-contexts: We observe that there has recently been a trend in OS design to improve support for the implicit concept of a path, mostly for the sake of improving the performance of layered systems. For example, fbufs are a path-centric buffer management mechanism <ref> [5] </ref>, packet filters are a mechanism for determining which path an incoming packet belongs on [14], and two recent systems provide support for the thread operating on behalf of a path-like computation to migrate across protection boundaries [7].
Reference: [6] <author> P. Druschel, L. L. Peterson, and B. S. Davie. </author> <title> Experience with a high-speed network adaptor: A software perspective. </title> <booktitle> In Proceedings of the SIGCOMM '94 Symposium, </booktitle> <month> Aug. </month> <year> 1994. </year>
Reference-contexts: We also found that making the wrong branch prediction on a critical path can mean the difference between whether or not a real-time embedded system is able to live within its instruction budget <ref> [6] </ref>. Finally, we have observed numerous cases where the performance of micro-benchmarks bear little relationship to the performance of the system as a whole, and in fact, optimizing a particular module is just as likely to hurt overall system performance as help it. Others have reported similar phenomena [2].
Reference: [7] <author> B. Ford and J. Lepreau. </author> <title> Evolving Mach 3.0 to use migrating threads. </title> <booktitle> In Winter 1994 Usenix Conference, </booktitle> <month> Jan. </month> <year> 1994. </year>
Reference-contexts: For example, fbufs are a path-centric buffer management mechanism [5], packet filters are a mechanism for determining which path an incoming packet belongs on [14], and two recent systems provide support for the thread operating on behalf of a path-like computation to migrate across protection boundaries <ref> [7] </ref>.
Reference: [8] <author> N. C. Hutchinson and L. L. Peterson. </author> <title> The x-Kernel: An architecture for implementing network protocols. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 17(1) </volume> <pages> 64-76, </pages> <month> Jan. </month> <year> 1991. </year>
Reference-contexts: In the case of Scout, the focus is on communication, which requires support for varying degrees of reliability, security, mobility, and real-time. To support this diversity, Scout will draw heavily from a predecessor system, the x-kernel <ref> [8] </ref>, in which network protocols define the fundamental building blocks from which the system is configured. Scout will go beyond the x-kernel in two ways. First, it will broaden the scope from network-specific to all communication-related functions, most notably, file access.
Reference: [9] <author> D. Mosberger, L. L. Peterson, and S. W. O'Malley. </author> <title> Protocol latency: Mips and reality. </title> <type> Technical Report 95-02, </type> <institution> Department of Computer Science, University of Arizona, </institution> <month> Feb. </month> <year> 1995. </year>
Reference: [10] <author> NIST. </author> <title> R&D for the NII: </title> <type> Technical Challenges. </type> <address> Gaithersburg, MD, </address> <month> Mar. </month> <year> 1994. </year>
Reference-contexts: In fact, a recent report on the NII rejects the term computer because of its emphasis on computation, and instead chooses to call these systems information appliances that support communication, information storage, and user interactions <ref> [10] </ref>. We expect these information appliances to include video displays, cameras, Personal Digital Assists (PDAs), thermostats, and data servers, as well as more conventional compute servers and desktop workstations.
Reference: [11] <author> J. K. Ousterhout. </author> <title> Why aren't operating systems getting faster as fast as hardware? In Proc. </title> <booktitle> Summer 1990 USENIX Conf., </booktitle> <pages> pages 247-256, </pages> <address> Anaheim, CA (USA), June 1990. </address> <publisher> USENIX. </publisher>
Reference-contexts: Given this situation, it is little wonder that operating systems are not becoming faster as fast as processors are becoming faster <ref> [11] </ref>. Our experiences integrating the x-kernel into Mach illustrates the problem [4].
Reference: [12] <author> M. A. Pagels, P. Druschel, and L. L. Peterson. </author> <title> Analysis of cache and TLB effectiveness in processing network I/O. </title> <type> Technical Report 94-08, </type> <institution> Department of Computer Science, University of Arizona, </institution> <month> Mar. </month> <year> 1994. </year>
Reference-contexts: In the case of the data cache (D-cache), we found that only 5% of the message fragments brought into the cache when they are received are still there by the time the application is scheduled to run <ref> [12] </ref>; other studies have uncovered similar effects [3]. We also found that making the wrong branch prediction on a critical path can mean the difference between whether or not a real-time embedded system is able to live within its instruction budget [6].
Reference: [13] <author> R. Wahbe, S. Lucco, T. E. Anderson, and S. L. Graham. </author> <title> Efficient software-based fault isolation. </title> <booktitle> In 14th Symposium on Operating System Principles, </booktitle> <pages> pages 203-216, </pages> <month> Dec. </month> <year> 1993. </year>
Reference-contexts: Similarly, rather than beginning with protection domains (tasks) as a primary abstraction, and trying to manage the flow of I/O data across multiple domains, Scout starts with the path abstraction, and annotates it with zero or more fault-isolation boundaries <ref> [13] </ref> and zero or more privacy boundaries. The path abstraction provides the focal point for realizing the goals outlined above. First, paths define an infrastructure for composing together various collections of protocols to provide different communication services.
Reference: [14] <author> M. Yuhara, B. N. Bershad, C. Maeda, and J. E. Moss. </author> <title> Efficient packet demultiplexing for multiple endpoints and large messages. </title> <booktitle> In Winter 1994 Usenix Conference, </booktitle> <month> Jan. </month> <year> 1994. </year>
Reference-contexts: For example, fbufs are a path-centric buffer management mechanism [5], packet filters are a mechanism for determining which path an incoming packet belongs on <ref> [14] </ref>, and two recent systems provide support for the thread operating on behalf of a path-like computation to migrate across protection boundaries [7].
References-found: 14

