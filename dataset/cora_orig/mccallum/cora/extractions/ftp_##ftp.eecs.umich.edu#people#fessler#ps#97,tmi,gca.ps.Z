URL: ftp://ftp.eecs.umich.edu/people/fessler/ps/97,tmi,gca.ps.Z
Refering-URL: http://www.eecs.umich.edu/~fessler/papers/jour.html
Root-URL: http://www.cs.umich.edu
Email: Email: fessler@umich.edu,  
Phone: Voice: 313-763-1434, FAX: 313-764-8041  
Title: Grouped-Coordinate Ascent Algorithms for Penalized-Likelihood Transmission Image Reconstruction  
Author: Jeffrey A. Fessler, Edward P. Ficaro, Neal H. Clinthorne, and Kenneth Lange 
Address: Ann Arbor, MI 48109-2122  
Affiliation: 4240 EECS Bldg., University of Michigan,  
Date: December 17, 1996 1  
Note: IEEE TRANSACTIONS ON MEDICAL IMAGING (TO APPEAR). VERSION  
Abstract: This paper presents a new class of algorithms for penalized-likelihood reconstruction of attenuation maps from low-count transmission scans. We derive the algorithms by applying to the transmission log-likelihood a version of the convexity technique developed by De Pierro for emission tomography. The new class includes the single-coordinate ascent (SCA) algorithm and Lange's convex algorithm for transmission tomography as special cases. The new grouped-coordinate ascent (GCA) algorithms in the class overcome several limitations associated with previous algorithms. (1) Fewer exponentiations are required than in the transmission ML-EM algorithm or in the SCA algorithm. (2) The algorithms intrinsically accommodate nonnegativity constraints, unlike many gradient-based methods. (3) The algorithms are easily parallelizable, unlike the SCA algorithm and perhaps line-search algorithms. We show that the GCA algorithms converge faster than the SCA algorithm, even on conventional workstations. An example from a low-count positron emission tomography (PET) transmission scan illustrates the method. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> K Wienhard, L Eriksson, S Grootoonk, M Casey, U Pietrzyk, and W D Heiss. </author> <title> Performance evaluation of a new generation positron scanner ECAT EXACT. </title> <journal> J. Comp. Assisted Tomo., </journal> <volume> 16(5) </volume> <pages> 804-813, </pages> <month> Sept. </month> <year> 1992. </year>
Reference-contexts: V. Results In [27] we presented convergence rate results using simulated PET transmission scans. Here we present analogous results using real data. Using an Siemens/CTI ECAT EXACT 921 PET scanner equipped with rotating rod transmission sources <ref> [1] </ref>, we acquired a 15-hour blank scan (b i 's) and two transmission scans (y i 's) of an anthropomorphic thorax phantom (Data Spectrum, North Car-olina).
Reference: [2] <author> S R Cherry, M Dahlbom, and E J Hoffman. </author> <title> High sensitivity, total body PET scanning using 3D data acquisition and reconstruction. </title> <journal> IEEE Tr. Nuc. Sci., </journal> <volume> 39(4) </volume> <pages> 1088-1092, </pages> <month> Aug. </month> <year> 1992. </year>
Reference: [3] <author> E P Ficaro, J A Fessler, W L Rogers, and M Schwaiger. </author> <title> Comparison of Americium-241 and Technicium-99m as transmission sources for attenuation correction of Thallium-201 SPECT imaging of the heart. </title> <journal> J. Nuc. Med., </journal> <volume> 35(4) </volume> <pages> 652-663, </pages> <month> Apr. </month> <year> 1994. </year>
Reference: [4] <author> S R Meikle, M Dahlbom, and S R Cherry. </author> <title> Attenuation correction using count-limited transmission data in positron emission tomography. </title> <journal> J. Nuc. Med., </journal> <volume> 34(1) </volume> <pages> 143-150, </pages> <month> Jan. </month> <year> 1993. </year>
Reference: [5] <author> K Sauer and C Bouman. </author> <title> A local update strategy for iterative reconstruction from projections. </title> <journal> IEEE Tr. Sig. Proc., </journal> <volume> 41(2) </volume> <pages> 534-548, </pages> <month> Feb. </month> <year> 1993. </year>
Reference: [6] <author> J A Fessler. </author> <title> Hybrid Poisson/polynomial objective functions for tomographic image reconstruction from transmission scans. </title> <journal> IEEE Tr. Im. Proc., </journal> <volume> 4(10) </volume> <pages> 1439-50, </pages> <month> Oct. </month> <year> 1995. </year>
Reference-contexts: Unfortunately, the partial derivatives of j (; n ) are fairly expensive to compute exactly, so (20) is impractical. To reduce computation, we apply methods from [11] and <ref> [6] </ref>. For the numerator, we approximate the Q j function in (17) (but not the penalty!) by its second-order Taylor series about the current estimate n j , in a spirit similar to [11]. For the denominator, we use a trick similar to [6] for precomputing an approximation to the second <p> computation, we apply methods from [11] and <ref> [6] </ref>. For the numerator, we approximate the Q j function in (17) (but not the penalty!) by its second-order Taylor series about the current estimate n j , in a spirit similar to [11]. For the denominator, we use a trick similar to [6] for precomputing an approximation to the second derivative of the Q j function, and a new trick for the penalty term that exploits its bounded curvature. <p> follows that d Q j ( j ; n ) fi fi = @ j fi fi = n and that d j ( n ) = d 2 Q j ( j ; n ) fi fi j = n j X a 2 ff ij (21) where (see <ref> [6] </ref>): h i (l) = 1 (b i e l + r i ) 2 b i e l : (22) Note that n only enters d j ( n ) through its projections ha i ; n i. <p> has bounded curvature: (x) = (1 + jx=ffij) 2 1; (25) we replace the denominator of (20) with d 2 j ( j ; n ) fi fi j = work j ^ d j + fi k which is independent of n so can be precomputed as described in <ref> [6] </ref>. Note that this replacement has no effect on the fixed point of (20). Using the approximation (26) provides a form of built-in under-relaxation because of the bounded curvature (25) of . <p> This complicates both implementation and convergence analysis. Second, as n j ! 0, ff ij ! 0, so ^ d j ! 1. Thus, pixels that 10 Excepting possible acceleration for small jSj due to under-relaxation as noted in <ref> [6, 24] </ref> for quadratic penalties. FESSLER: GROUPED-COORDINATE ASCENT TOMOGRAPHY 7 approach 0 in the limit will converge increasingly slowly, perhaps even at sublinear rates (as observed in the emission case [45]). Third, the choice (32) makes ^ d j dependent on n , so ^ d j cannot be precomputed. <p> We use the choice (34) for the remainder of this paper. Whether better choices exist is an open question [47]. B. Special Cases In the special case where the subset S contains only one pixel (S = fjg), then the "algorithm" (19) is equivalent to SCA <ref> [10, 11, 6] </ref>, i.e., it turns out that j ( j ; n ) = ( n j1 ; j ; n p ): And in that case, the choice (34) leads to a coordinate-wise Newton-Raphson update [10, 11, 6]. <p> one pixel (S = fjg), then the "algorithm" (19) is equivalent to SCA <ref> [10, 11, 6] </ref>, i.e., it turns out that j ( j ; n ) = ( n j1 ; j ; n p ): And in that case, the choice (34) leads to a coordinate-wise Newton-Raphson update [10, 11, 6]. At the other extreme, when S = f1; : : : ; pg, then using the choice (32) with one sub-iteration of (20) is equivalent to the convex algorithm of [20]. The choice (34) thus corresponds to an alternative convex algorithm (and one that converges faster). <p> Thus the required number of exponentiations is only m 2 N , which is considerably smaller than the number of nonzero a ij 's for small m. Note that m = 1 is closely related to the convex algorithm [20], and m = p gives the SCA algorithm <ref> [6] </ref>. As one increases m, the pixels within each group become more separated and therefore less coupled, which increases the convergence rate, but the computation also increases. Thus there is a basic tradeoff that can be adapted to the characteristics of the particular computer architecture. V. <p> The sinogram dimension was 160 radial bins and 192 angles, and the reconstructed images were 128 2 with 4.5mm pixels. For the a ij 's, we used 6mm wide strip integrals having 3mm spacing <ref> [6] </ref>, which roughly approximates the system geometry. Reconstructions of the phantom are shown in Fig. 3, by both FBP and by 20 iterations of 4 fi 4 GCA. For the penalized likelihood reconstructions we used ffi = 0:004cm 1 in (6), chosen by visual inspection. <p> The qualitative properties were rather sensitive to the choice of this parameter. (A 3D penalty function might reduce this sensitivity by improving the reconstruction of thin axial structures such as the patient table in Fig. 3.) The statistical method appears to produce somewhat better image quality. (See <ref> [6] </ref> for quantitative resolution-vs-noise comparisons.) Fig. 4 shows that with m = 4 (16 groups), the proposed GCA algorithm increased the penalized-likelihood objective almost as fast as the SCA algorithm per iteration. <p> Our results demonstrate that even on a conventional workstation the new algorithms converge faster than both SCA and (an improved version of) the convex algorithm of [20]. The results in [20] and <ref> [6] </ref> provide additional comparisons to other alternative algorithms. Based on all of these comparisons, we consider the transmission EM algorithm [9, 18] to be obsolete. For penalized-likelihood transmission image reconstruction, our proposed GCA algorithms have fast convergence, reduced exponentiations per iteration, easily accommodate nonnegativity, and are flexibly parallelizable. <p> Such processing times bring this statistical method within the realm of clinical utility, although further time reductions would still be FESSLER: GROUPED-COORDINATE ASCENT TOMOGRAPHY 9 helpful. One could combine the grouped-ascent idea in this paper with the hybrid Poisson/polynomial approximations described in <ref> [6] </ref> to further reduce computation. The reductions would be less dramatic than in [6] since for our GCA method the exponentiations in Table I have been moved outside of the backprojection step, whereas for SCA the calculations in (27) must be done during the backprojec-tion (8) since n is continually changing. <p> One could combine the grouped-ascent idea in this paper with the hybrid Poisson/polynomial approximations described in <ref> [6] </ref> to further reduce computation. The reductions would be less dramatic than in [6] since for our GCA method the exponentiations in Table I have been moved outside of the backprojection step, whereas for SCA the calculations in (27) must be done during the backprojec-tion (8) since n is continually changing. There are additional advantages of GCA that we have not exploited here.
Reference: [7] <author> D S Lalush and B M W Tsui. </author> <title> MAP-EM and WLS-MAP-CG reconstruction methods for transmission imaging in cardiac SPECT. </title> <booktitle> In Proc. IEEE Nuc. Sci. Symp. Med. Im. Conf., </booktitle> <volume> vol. 2, </volume> <pages> pp. 1174-1178, </pages> <year> 1993. </year>
Reference: [8] <author> J A Fessler. </author> <title> Mean and variance of implicitly defined biased estimators (such as penalized maximum likelihood): Applications to tomography. </title> <journal> IEEE Tr. Im. Proc., </journal> <volume> 5(3) </volume> <pages> 493-506, </pages> <month> Mar. </month> <year> 1996. </year>
Reference: [9] <author> K Lange and R Carson. </author> <title> EM reconstruction algorithms for emission and transmission tomography. </title> <journal> J. Comp. Assisted Tomo., </journal> <volume> 8(2) </volume> <pages> 306-316, </pages> <month> Apr. </month> <year> 1984. </year>
Reference-contexts: The results in [20] and [6] provide additional comparisons to other alternative algorithms. Based on all of these comparisons, we consider the transmission EM algorithm <ref> [9, 18] </ref> to be obsolete. For penalized-likelihood transmission image reconstruction, our proposed GCA algorithms have fast convergence, reduced exponentiations per iteration, easily accommodate nonnegativity, and are flexibly parallelizable.
Reference: [10] <author> C Bouman and K Sauer. </author> <title> Fast numerical methods for emission and transmission tomographic reconstruction. </title> <booktitle> In Proc. 27th Conf. Info. Sci. Sys., </booktitle> <publisher> Johns Hopkins, </publisher> <pages> pp. 611-616, </pages> <year> 1993. </year>
Reference-contexts: We use the choice (34) for the remainder of this paper. Whether better choices exist is an open question [47]. B. Special Cases In the special case where the subset S contains only one pixel (S = fjg), then the "algorithm" (19) is equivalent to SCA <ref> [10, 11, 6] </ref>, i.e., it turns out that j ( j ; n ) = ( n j1 ; j ; n p ): And in that case, the choice (34) leads to a coordinate-wise Newton-Raphson update [10, 11, 6]. <p> one pixel (S = fjg), then the "algorithm" (19) is equivalent to SCA <ref> [10, 11, 6] </ref>, i.e., it turns out that j ( j ; n ) = ( n j1 ; j ; n p ): And in that case, the choice (34) leads to a coordinate-wise Newton-Raphson update [10, 11, 6]. At the other extreme, when S = f1; : : : ; pg, then using the choice (32) with one sub-iteration of (20) is equivalent to the convex algorithm of [20]. The choice (34) thus corresponds to an alternative convex algorithm (and one that converges faster).
Reference: [11] <author> C A Bouman and K Sauer. </author> <title> A unified approach to statistical tomography using coordinate descent optimization. </title> <journal> IEEE Tr. Im. Proc., </journal> <volume> 5(3) </volume> <pages> 480-92, </pages> <month> Mar. </month> <year> 1996. </year>
Reference-contexts: The ":=" symbol in the middle step above indicates "in place" computation, and typically this step would be repeated a few times. Unfortunately, the partial derivatives of j (; n ) are fairly expensive to compute exactly, so (20) is impractical. To reduce computation, we apply methods from <ref> [11] </ref> and [6]. For the numerator, we approximate the Q j function in (17) (but not the penalty!) by its second-order Taylor series about the current estimate n j , in a spirit similar to [11]. <p> To reduce computation, we apply methods from <ref> [11] </ref> and [6]. For the numerator, we approximate the Q j function in (17) (but not the penalty!) by its second-order Taylor series about the current estimate n j , in a spirit similar to [11]. For the denominator, we use a trick similar to [6] for precomputing an approximation to the second derivative of the Q j function, and a new trick for the penalty term that exploits its bounded curvature. <p> We use the choice (34) for the remainder of this paper. Whether better choices exist is an open question [47]. B. Special Cases In the special case where the subset S contains only one pixel (S = fjg), then the "algorithm" (19) is equivalent to SCA <ref> [10, 11, 6] </ref>, i.e., it turns out that j ( j ; n ) = ( n j1 ; j ; n p ): And in that case, the choice (34) leads to a coordinate-wise Newton-Raphson update [10, 11, 6]. <p> one pixel (S = fjg), then the "algorithm" (19) is equivalent to SCA <ref> [10, 11, 6] </ref>, i.e., it turns out that j ( j ; n ) = ( n j1 ; j ; n p ): And in that case, the choice (34) leads to a coordinate-wise Newton-Raphson update [10, 11, 6]. At the other extreme, when S = f1; : : : ; pg, then using the choice (32) with one sub-iteration of (20) is equivalent to the convex algorithm of [20]. The choice (34) thus corresponds to an alternative convex algorithm (and one that converges faster). <p> Specifically: (x x k ) maxf (x x k ); (x + x k )g 4 13 Thanks to Ken Sauer for bringing this point to the attention of the first author when discussing <ref> [11] </ref>. Note that fl k 1. Thus we replace the denominator in (29) with ^ d j + fi k This leads to faster convergence since the denominator in (29) is smaller, therefore the step size is larger.
Reference: [12] <author> J A Fessler and W L Rogers. </author> <title> Spatial resolution properties of penalized-likelihood image reconstruction methods: </title> <journal> Space-invariant tomographs. IEEE Tr. Im. Proc., </journal> <volume> 5(9) </volume> <pages> 1346-58, </pages> <month> Sept. </month> <year> 1996. </year>
Reference: [13] <author> A J Rockmore and A Macovski. </author> <title> A maximum likelihood approach to transmission image reconstruction from projections. </title> <journal> IEEE Tr. Nuc. Sci., </journal> <volume> 24(3) </volume> <pages> 1929-1935, </pages> <month> June </month> <year> 1977. </year>
Reference: [14] <author> K Lange, M Bahn, and R Little. </author> <title> A theoretical study of some maximum likelihood algorithms for emission and transmission tomography. </title> <journal> IEEE Tr. Med. Im., </journal> <volume> 6(2) </volume> <pages> 106-114, </pages> <month> June </month> <year> 1987. </year>
Reference: [15] <author> K Lange. </author> <title> An overview of Bayesian methods in image reconstruction. </title> <booktitle> In Proc. SPIE 1351, Dig. Im. Synth. and Inverse Optics, </booktitle> <pages> pp. 270-287, </pages> <year> 1990. </year>
Reference: [16] <author> K Lange. </author> <title> Convergence of EM image reconstruction algorithms with Gibbs smoothing. </title> <journal> IEEE Tr. Med. Im., </journal> <volume> 9(4) </volume> <pages> 439-446, </pages> <month> Dec. </month> <year> 1990. </year> <title> Corrections, </title> <month> June </month> <year> 1991. </year>
Reference: [17] <author> E Mumcuoglu, R Leahy, and S Cherry. </author> <title> A statistical approach to transmission image reconstruction from ring source calibration measurements in PET. </title> <booktitle> In Proc. IEEE Nuc. Sci. Symp. Med. Im. Conf., </booktitle> <volume> vol. 2, </volume> <pages> pp. 910-912, </pages> <year> 1992. </year>
Reference: [18] <author> J M Ollinger. </author> <title> Maximum likelihood reconstruction of transmission images in emission computed tomography via the EM algorithm. </title> <journal> IEEE Tr. Med. Im., </journal> <volume> 13(1) </volume> <pages> 89-101, </pages> <month> Mar. </month> <year> 1994. </year>
Reference-contexts: The results in [20] and [6] provide additional comparisons to other alternative algorithms. Based on all of these comparisons, we consider the transmission EM algorithm <ref> [9, 18] </ref> to be obsolete. For penalized-likelihood transmission image reconstruction, our proposed GCA algorithms have fast convergence, reduced exponentiations per iteration, easily accommodate nonnegativity, and are flexibly parallelizable.
Reference: [19] <author> E U Mumcuoglu, R Leahy, S R Cherry, and Z Zhou. </author> <title> Fast gradient-based methods for Bayesian reconstruction of transmission and emission PET images. </title> <journal> IEEE Tr. Med. Im., </journal> <volume> 13(3) </volume> <pages> 687-701, </pages> <month> Dec. </month> <year> 1994. </year> <note> 10 IEEE TRANSACTIONS ON MEDICAL IMAGING (TO APPEAR). VERSION December 17, </note> <year> 1996 </year>
Reference: [20] <author> K Lange and J A Fessler. </author> <title> Globally convergent algorithms for maximum a posteriori transmission tomography. </title> <journal> IEEE Tr. Im. Proc., </journal> <volume> 4(10) </volume> <pages> 1430-8, </pages> <month> Oct. </month> <year> 1995. </year>
Reference-contexts: De Pierro [25] proposed an algorithm for emission to mography that updates all pixels simultaneously (i.e. S = f1; : : : ; pg) and essentially uses (12) with ff ij = j k2S a ik n : (32) This was also applied to transmission tomography in <ref> [20] </ref>. The choice (32) has three disadvantages. First, if n j = 0, then ff ij =0, so (22) would not be well defined. This complicates both implementation and convergence analysis. Second, as n j ! 0, ff ij ! 0, so ^ d j ! 1. <p> At the other extreme, when S = f1; : : : ; pg, then using the choice (32) with one sub-iteration of (20) is equivalent to the convex algorithm of <ref> [20] </ref>. The choice (34) thus corresponds to an alternative convex algorithm (and one that converges faster). However, the algorithms that are "in between" those two extreme choices of S are the most useful, as discussed next. C. <p> Thus the required number of exponentiations is only m 2 N , which is considerably smaller than the number of nonzero a ij 's for small m. Note that m = 1 is closely related to the convex algorithm <ref> [20] </ref>, and m = p gives the SCA algorithm [6]. As one increases m, the pixels within each group become more separated and therefore less coupled, which increases the convergence rate, but the computation also increases. <p> With m = 3 or m = 4, the GCA algorithms converge in less than half the CPU time of SCA. Furthermore, the GCA algorithms are parallelizable, so with appropriate hardware could be significantly accelerated. Note that "1 fi 1 GCA" is closely related to the convex algorithm of <ref> [20] </ref>. Table III compares the estimated attenuation coefficients for three rectangular regions of interest (ROIs) corresponding to soft tissue, bone, and lung. The ROI values for the 12-minute data both agree well with the 14-hour reference image. <p> Thus the algorithm design parameters only affect the convergence rate, not the image quality, unlike the many popular unregularized methods. Our results demonstrate that even on a conventional workstation the new algorithms converge faster than both SCA and (an improved version of) the convex algorithm of <ref> [20] </ref>. The results in [20] and [6] provide additional comparisons to other alternative algorithms. Based on all of these comparisons, we consider the transmission EM algorithm [9, 18] to be obsolete. <p> Our results demonstrate that even on a conventional workstation the new algorithms converge faster than both SCA and (an improved version of) the convex algorithm of <ref> [20] </ref>. The results in [20] and [6] provide additional comparisons to other alternative algorithms. Based on all of these comparisons, we consider the transmission EM algorithm [9, 18] to be obsolete. For penalized-likelihood transmission image reconstruction, our proposed GCA algorithms have fast convergence, reduced exponentiations per iteration, easily accommodate nonnegativity, and are flexibly parallelizable.
Reference: [21] <author> E U Mumcuoglu and R M Leahy. </author> <title> A gradient projection conjugate gradient algorithm for Bayesian PET reconstruction. </title> <booktitle> In Proc. IEEE Nuc. Sci. Symp. Med. Im. Conf., </booktitle> <volume> vol. 3, </volume> <pages> pp. 1212-6, </pages> <year> 1994. </year>
Reference: [22] <author> L Kaufman. </author> <title> Maximum likelihood, least squares, and penalized least squares for PET. </title> <journal> IEEE Tr. Med. Im., </journal> <volume> 12(2) </volume> <pages> 200-214, </pages> <month> June </month> <year> 1993. </year>
Reference: [23] <author> J A Fessler and A O Hero. </author> <title> Space-alternating generalized expectation-maximization algorithm. </title> <journal> IEEE Tr. Sig. Proc., </journal> <volume> 42(10) </volume> <pages> 2664-2677, </pages> <month> Oct. </month> <year> 1994. </year>
Reference-contexts: is a jSj fi jSj diagonal matrix with entries f ^ d j + fi k w jk g j2S : We could use (31) to develop expressions for the asymptotic convergence rate of the algorithm (for any particular choice of ff ij 's and S's) following the analysis in <ref> [23] </ref>. Here we take a more informal approach and simply note that (31) suggests that smaller values for the diagonal entries of D will lead to larger step sizes, and hence faster 9 One sub-iteration is adequate when is quadratic, for example, or when the algorithm has nearly converged.
Reference: [24] <author> J A Fessler and A O Hero. </author> <title> Penalized maximum-likelihood image reconstruction using space-alternating generalized EM algorithms. </title> <journal> IEEE Tr. Im. Proc., </journal> <volume> 4(10) </volume> <pages> 1417-29, </pages> <month> Oct. </month> <year> 1995. </year>
Reference-contexts: This complicates both implementation and convergence analysis. Second, as n j ! 0, ff ij ! 0, so ^ d j ! 1. Thus, pixels that 10 Excepting possible acceleration for small jSj due to under-relaxation as noted in <ref> [6, 24] </ref> for quadratic penalties. FESSLER: GROUPED-COORDINATE ASCENT TOMOGRAPHY 7 approach 0 in the limit will converge increasingly slowly, perhaps even at sublinear rates (as observed in the emission case [45]). Third, the choice (32) makes ^ d j dependent on n , so ^ d j cannot be precomputed. <p> Third, the choice (32) makes ^ d j dependent on n , so ^ d j cannot be precomputed. One way to overcome the first two drawbacks is to express the emission algorithm (PML-SAGE-3) developed in <ref> [24] </ref> in terms of De Pierro's convexity method. This leads to the following choice: ff ij = j + z j ) k2S a ik ( n ; (33) for almost 11 any positive values z j .
Reference: [25] <author> A R De Pierro. </author> <title> On the relation between the ISRA and the EM algorithm for positron emission tomography. </title> <journal> IEEE Tr. Med. Im., </journal> <volume> 12(2) </volume> <pages> 328-333, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: Clearly this constraint depends on one's choices for S, but for the moment assume we have fixed S and we want to choose the ff ij 's. De Pierro <ref> [25] </ref> proposed an algorithm for emission to mography that updates all pixels simultaneously (i.e. S = f1; : : : ; pg) and essentially uses (12) with ff ij = j k2S a ik n : (32) This was also applied to transmission tomography in [20].
Reference: [26] <author> A R De Pierro. </author> <title> A modified expectation maximization algorithm for penalized likelihood estimation in emission tomography. </title> <journal> IEEE Tr. Med. Im., </journal> <volume> 14(1) </volume> <pages> 132-137, </pages> <month> Mar. </month> <year> 1995. </year>
Reference-contexts: To eliminate this dependency, we let z j ! 1 in (33). This leads to the following choice: ff ij = k2S a ik which is independent of n . This choice is similar to that made by De Pierro for the emission penalty function in <ref> [26] </ref>, and was used in [27,37]. Note that the denominator in (34) can be easily precomputed and stored once-and-for-all for a given tomographic system and choices for S. We use the choice (34) for the remainder of this paper. Whether better choices exist is an open question [47]. B.
Reference: [27] <author> J A Fessler, E P Ficaro, N H Clinthorne, and K Lange. </author> <title> Fast parallelizable algorithms for transmission image reconstruction. </title> <booktitle> In Proc. IEEE Nuc. Sci. Symp. Med. Im. Conf., </booktitle> <volume> vol. 3, </volume> <pages> pp. 1346-50, </pages> <year> 1995. </year>
Reference-contexts: As one increases m, the pixels within each group become more separated and therefore less coupled, which increases the convergence rate, but the computation also increases. Thus there is a basic tradeoff that can be adapted to the characteristics of the particular computer architecture. V. Results In <ref> [27] </ref> we presented convergence rate results using simulated PET transmission scans. Here we present analogous results using real data.
Reference: [28] <author> G Gullberg and B M W Tsui. </author> <title> Maximum entropy reconstruction with constraints: iterative algorithms for solving the primal and dual programs. </title> <editor> In C N de Graaf and M A Viergever, editors, </editor> <booktitle> Proc. Tenth Intl. Conf. on Information Processing in Medical Im., </booktitle> <pages> pp. 181-200. </pages> <publisher> Plenum Press, </publisher> <address> New York, </address> <year> 1987. </year>
Reference: [29] <author> J A Fessler. </author> <title> Penalized weighted least-squares image reconstruction for positron emission tomography. </title> <journal> IEEE Tr. Med. Im., </journal> <volume> 13(2) </volume> <pages> 290-300, </pages> <month> June </month> <year> 1994. </year>
Reference: [30] <author> M Wax. </author> <title> Detection and estimation of superimposed signals. </title> <type> PhD thesis, </type> <institution> Stanford Univ., Stanford, </institution> <address> CA., </address> <month> Mar. </month> <year> 1985. </year>
Reference: [31] <author> I Ziskind and M Wax. </author> <title> Maximum likelihood localization of multiple sources by alternating projection. </title> <journal> IEEE Tr. Acoust. Sp. Sig. Proc., </journal> <volume> 36(10) </volume> <pages> 1553-1560, </pages> <month> Oct. </month> <year> 1988. </year>
Reference: [32] <author> M Feder and E Weinstein. </author> <title> Parameter estimation of superimposed signals using the EM algorithm. </title> <journal> IEEE Tr. Acoust. Sp. Sig. Proc., </journal> <volume> 36(4) </volume> <pages> 477-489, </pages> <month> Apr. </month> <year> 1988. </year>
Reference: [33] <author> A J Weiss, A S Willsky, and B C Levy. </author> <title> Maximum likelihood array processing for the estimation of superimposed signals. </title> <journal> Proc. IEEE, </journal> <volume> 76(2) </volume> <pages> 203-205, </pages> <month> Feb. </month> <year> 1988. </year> <booktitle> Correction in IEEE Proc., </booktitle> <volume> Vol. 76, No. 6, </volume> <editor> p. </editor> <volume> 734, </volume> <month> June </month> <year> 1988. </year>
Reference: [34] <author> J A Fessler. </author> <title> Object-Based 3-D Reconstruction of Arterial Trees from a Few Projections. </title> <type> PhD thesis, </type> <institution> Stanford Univ., Stanford, </institution> <address> CA., </address> <month> Aug. </month> <year> 1990. </year>
Reference: [35] <author> J Besag. </author> <title> On the statistical analysis of dirty pictures. </title> <journal> J. Royal Stat. Soc. Ser. B, </journal> <volume> 48(3) </volume> <pages> 259-302, </pages> <year> 1986. </year>
Reference: [36] <author> J A Cadzow. </author> <title> Signal processing via least squares error modeling. </title> <journal> IEEE Signal Proc. Mag., </journal> <pages> pp. 12-31, </pages> <month> Oct. </month> <year> 1990. </year>
Reference: [37] <author> K D Sauer, </author> <title> S Borman, and C A Bouman. Parallel computation of sequential pixel updates in statistical tomographic reconstruction. </title> <booktitle> In Proc. IEEE Intl. Conf. on Image Processing, </booktitle> <volume> vol. 3, </volume> <pages> pp. 93-6, </pages> <year> 1995. </year>
Reference: [38] <author> S T Jensen, S Johansen, and S L Lauritzen. </author> <title> Globally convergent algorithms for maximizing a likelihood function. </title> <journal> Biometrika, </journal> <volume> 78(4) </volume> <pages> 867-77, </pages> <year> 1991. </year>
Reference: [39] <author> M E Casey and E J Hoffman. </author> <title> Quantitation in positron emission computed tomography: 7 A technique to reduce noise in accidental coincidence measurements and coincidence efficiency calibration. </title> <journal> J. Comp. Assisted Tomo., </journal> <volume> 10(5) </volume> <pages> 845-850, </pages> <year> 1986. </year>
Reference: [40] <author> B Chan, M Bergstrom, M R Palmer, C Sayre, and B D Pate. </author> <title> Scatter distribution in transmission measurements with positron emission tomography. </title> <journal> J. Comp. Assisted Tomo., </journal> <volume> 10(2) </volume> <pages> 296-301, </pages> <month> Mar. </month> <year> 1986. </year>
Reference: [41] <author> G T Herman. </author> <title> Image reconstruction from projections: The fundamentals of computerized tomography. </title> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1980. </year>
Reference: [42] <author> J M M Anderson, B A Mair, M Rao, and C H Wu. </author> <title> A weighted least-squares method for PET. </title> <booktitle> In Proc. IEEE Nuc. Sci. Symp. Med. Im. Conf., </booktitle> <volume> vol. 2, </volume> <pages> pp. 1292-6, </pages> <year> 1995. </year>
Reference: [43] <author> J A Fessler. </author> <title> Resolution properties of regularized image reconstruction methods. </title> <type> Technical Report 297, </type> <institution> Comm. and Sign. Proc. Lab., Dept. of EECS, Univ. of Michigan, </institution> <address> Ann Arbor, MI, 48109-2122, </address> <month> Aug. </month> <year> 1995. </year>
Reference: [44] <author> J A Fessler and W L Rogers. </author> <title> Uniform quadratic penalties cause nonuniform image resolution (and sometimes vice versa). </title> <booktitle> In Proc. IEEE Nuc. Sci. Symp. Med. Im. Conf., </booktitle> <volume> vol. 4, </volume> <pages> pp. 1915-1919, </pages> <year> 1994. </year>
Reference: [45] <author> J A Fessler, N H Clinthorne, and W L Rogers. </author> <title> On complete data spaces for PET reconstruction algorithms. </title> <journal> IEEE Tr. Nuc. Sci., </journal> <volume> 40(4) </volume> <pages> 1055-1061, </pages> <month> Aug. </month> <year> 1993. </year>
Reference-contexts: Thus, pixels that 10 Excepting possible acceleration for small jSj due to under-relaxation as noted in [6, 24] for quadratic penalties. FESSLER: GROUPED-COORDINATE ASCENT TOMOGRAPHY 7 approach 0 in the limit will converge increasingly slowly, perhaps even at sublinear rates (as observed in the emission case <ref> [45] </ref>). Third, the choice (32) makes ^ d j dependent on n , so ^ d j cannot be precomputed. One way to overcome the first two drawbacks is to express the emission algorithm (PML-SAGE-3) developed in [24] in terms of De Pierro's convexity method.
Reference: [46] <author> J A Fessler. </author> <title> ASPIRE 3.0 user's guide: A sparse iterative reconstruction library. </title> <type> Technical Report 293, </type> <institution> Comm. and Sign. Proc. Lab., Dept. of EECS, Univ. of Michigan, </institution> <address> Ann Arbor, MI, 48109-2122, </address> <month> July </month> <year> 1995. </year> <note> Available from WWW at http://www.eecs.umich.edu/~fessler/. </note>
Reference-contexts: Since proper ordering of the steps is essential for efficient computation, we give the details of the algorithm in Table I. (Software is also available; see <ref> [46] </ref>.) The Appendix describes a modification to (29) that further improves the rate of convergence. IV. Convergence Rate and Algorithm Design The method described in the preceding section is a class of algorithms since there are several factors that the algorithm designer may specify.
Reference: [47] <author> K Lange. </author> <title> Numerical analysis for statisticians, </title> <booktitle> 1996. Preprint of text. </booktitle>
Reference-contexts: Note that the denominator in (34) can be easily precomputed and stored once-and-for-all for a given tomographic system and choices for S. We use the choice (34) for the remainder of this paper. Whether better choices exist is an open question <ref> [47] </ref>. B.
Reference: [48] <author> A R De Pierro. </author> <title> A generalization of the EM algorithm for maximum likelihood estimates from incomplete data. </title> <type> Technical Report MIPG119, </type> <institution> Med. Im. Proc. Group, Dept. of Radiol., Univ. of Pennsylvania, </institution> <month> Feb. </month> <year> 1987. </year>
Reference-contexts: duration of one transmission scan was 14 hours (64M prompt coincidences in the slice of interest) and the other scan was 12 minutes (0.921M prompt coincidences in the slice of interest). (Most of these counts correspond 12 Similar "generalized checkerboard" decompositions of the image have been considered for emission tomography <ref> [48] </ref> [49]. 8 IEEE TRANSACTIONS ON MEDICAL IMAGING (TO APPEAR).

References-found: 48

