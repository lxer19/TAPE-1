URL: http://burton.cs.ucla.edu/tech-docs/kdd93.ps
Refering-URL: http://burton.cs.ucla.edu/tech-docs/kdd93/kdd93.html
Root-URL: http://www.cs.ucla.edu
Title: Pattern-Based Clustering for Database Attribute Values  
Author: Matthew Merzbacher Wesley W. Chu 
Address: Los Angeles, CA 90024  
Affiliation: Computer Science Department University of California  
Note: in Proceedings AAAI Workshop on Knowledge Discovery in Databases, 1993 Washington D.C.  
Abstract: We present a method for automatically clustering similar attribute values in a database system spanning mulitple domains. The method constructs an attribute abstraction hierarchy for each attribute using rules that are derived from the database instance. The rules have a confidence and popularity that combine to express the "usefullness" of the rule. Attribute values are clustered if they are used as the premise for rules with the same consequence. By iteratively applying the algorithm, a hierarchy of clusters can be found. The algorithm can be improved by allowing domain expert supervision during the clustering process. An example as well as experimental results from a large transportation database are included. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Y. Cai, N. Cercone, and J. Han. </author> <title> Attribute-oriented induction in relational databases. </title> <editor> In G. Piatetsky-Shapiro and W. J. Frawley, editors, </editor> <title> Knowledge Discovery in Databases. </title> <publisher> AAAI Press/The MIT Press, </publisher> <address> Menlo Park, CA, </address> <year> 1991. </year>
Reference-contexts: For databases with many attributes having a large number of values, manaully constructing the AAHs is time consuming and prone to error. Thus the hierarchies must be induced automatically, but previous knowledge discovery techniques are inadequate for CQA. Attribute Oriented Induction <ref> [1] </ref> provides summary information and charactarizes tuples in the database, but is inappropriate for attribute values and focuses too closely on a spe Aircraft Length Runway Turning Taxi Weight Storage Type Takeoff Landing Width Radius Space Max.
Reference: [2] <author> Q. Chen, W. W. Chu, and R. Lee. </author> <title> Pattern-based knowledge induction from databases. In Database Systems for Next Generation Applications. </title> <publisher> World Science Publishing Co., </publisher> <year> 1992. </year>
Reference-contexts: Note that the confidences of rules for two opposite inference directions are neither symmetric nor complementary. More sophisticated boolean combinations of rules can be derived from the basic rules <ref> [2] </ref>. Popularity is another important measure of a rule, indicating "how common" the rule is. Consider the rule type = C-5 ! runway width = 90 ft. that has confidence of 100% but only applies to one tuple in AIRCRAFT.
Reference: [3] <author> W. W. Chu, Q. Chen, and R. Lee. </author> <title> Cooperative query answering via type abstraction hierarchy. In S.M. </title> <editor> Deen, editor, </editor> <booktitle> Cooperating Knowledge Based Systems, </booktitle> <pages> pages 271-292. </pages> <publisher> North-Holland, Elsevier Science Publishing Co., Inc., </publisher> <year> 1991. </year>
Reference-contexts: If searching one cluster in the hierarchy is unsuccessful in yielding an answer, then the condition can be further relaxed by traversing up another level in the hierarchy. Eventually, the query will be sufficiently relaxed to generate an answer <ref> [3] </ref>. There is an AAH for each attribute domain. Figure 1 shows a classification of aircraft types for the aircraft example. Each level of the hierarchy represents a level of abstraction. <p> However, if rules are eliminated, then the values in the premise of those rules can no longer be clustered. Thus, eliminating rules will yield hierarchies that only cluster values that appear more frequently in the database. These incomplete hierarchies still prove useful, as CoBase <ref> [3] </ref> can use partial hierarchies when full ones are not available. Since incomplete hierarchies include only values which appear frequently in the database, they require much less space than full hierarchies.
Reference: [4] <author> W. W. Chu and K. Chiang. </author> <title> A distribution sensitive clustering method for numerical values. </title> <type> Technical Report 93-0006, </type> <institution> UCLA Computer Science Department, </institution> <year> 1993. </year>
Reference-contexts: The PKI clustering algorithm works well for discrete values, but is not as suitable for continuous domains, such as numeric values. Clustering of continuous numeric domains is more effectively handled by an algorithm which takes advantage of the ordering and range of the data, such as DISC <ref> [4] </ref>. These methods can be used to pre-cluster the numeric domain into ranges which can then be used as input to PKI, thus significantly improving the performance of the algorithm. The PKI algorithm for rule detection is exponential on the number of attribute values.
Reference: [5] <author> F. Cuppers and R. Demoloube. </author> <title> Cooperative answering: a methodology to provide intelligent access to databases. </title> <booktitle> In Proc. 2nd International Conference on Expert Database Systems, </booktitle> <address> Vir-ginia, USA, </address> <year> 1988. </year>
Reference-contexts: If a query has no exact answer, then the user's needs remain unsatisfied. A cooperative query answering (CQA) system behaves like a conventional system when the query can be answered normally, but tries to find an approximate answer when the original query condition cannot be matched exactly <ref> [5, 6] </ref>. When a query has no answer, the query conditions are relaxed to obtain an approximate answer. For example, consider a query about C-21 cargo aircraft in a transportation application.
Reference: [6] <author> J. Minker, G.A. Wilson, and B.H. Zimmerman. </author> <title> Query expansion by the addition of clustered terms for a document retrieval system. </title> <booktitle> Information Storage and Retrieval, </booktitle> <volume> 8 </volume> <pages> 329-348, </pages> <year> 1972. </year>
Reference-contexts: If a query has no exact answer, then the user's needs remain unsatisfied. A cooperative query answering (CQA) system behaves like a conventional system when the query can be answered normally, but tries to find an approximate answer when the original query condition cannot be matched exactly <ref> [5, 6] </ref>. When a query has no answer, the query conditions are relaxed to obtain an approximate answer. For example, consider a query about C-21 cargo aircraft in a transportation application.
Reference: [7] <author> J. R. Quinlan. </author> <title> The effect of noise on concept learning. </title> <editor> In R. S. Michalski, J. G. Carbonell, and T. M. Mitchell, editors, </editor> <booktitle> Machine Learning, </booktitle> <volume> volume 2. </volume> <publisher> Morgan Kaufmann Publishers, Inc., </publisher> <address> Los Altos, CA, </address> <year> 1986. </year>
Reference-contexts: Conceptual Clustering <ref> [8, 7] </ref> is a top-down method, iteratively subdividing the tuple-space into smaller sets. The top-down approach does not yield clusters the best correlation near the bottom of the hierarchy. CQA operates from the bottom of the hierarchy, so better clustering near the bottom is desirable.
Reference: [8] <author> R. E. Stepp III and R. S. Michalski. </author> <title> Conceptual clustering: Inventing goal-oriented classifications of structured objects. </title> <editor> In R. S. Michalski, J. G. Carbonell, and T. M. Mitchell, editors, </editor> <booktitle> Machine Learning, </booktitle> <volume> volume 2. </volume> <publisher> Morgan Kauf-mann Publishers, Inc., </publisher> <address> Los Altos, CA, </address> <year> 1986. </year>
Reference-contexts: Conceptual Clustering <ref> [8, 7] </ref> is a top-down method, iteratively subdividing the tuple-space into smaller sets. The top-down approach does not yield clusters the best correlation near the bottom of the hierarchy. CQA operates from the bottom of the hierarchy, so better clustering near the bottom is desirable.
References-found: 8

