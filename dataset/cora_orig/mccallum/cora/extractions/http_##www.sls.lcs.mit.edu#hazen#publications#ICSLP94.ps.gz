URL: http://www.sls.lcs.mit.edu/hazen/publications/ICSLP94.ps.gz
Refering-URL: http://www.sls.lcs.mit.edu/hazen/publications.html
Root-URL: 
Email: email: hazen@goldilocks.lcs.mit.edu  
Title: RECENT IMPROVEMENTS IN AN APPROACH TO SEGMENT-BASED AUTOMATIC LANGUAGE IDENTIFICATION 1  
Author: Timothy J. Hazen and Victor W. Zue 
Address: Cambridge, Massachusetts 02139 USA  
Affiliation: Spoken Language Systems Group, Laboratory for Computer Science Massachusetts Institute of Technology,  
Abstract: In 1993, a segment-based system for Automatic Lan- guage Identification (ALI) was developed and introduced. The system incorporates phonetic, acoustic, and prosodic information within a probabilistic framework. The original system was trained and tested using the OGI Multi- Language Telephone Speech Corpus and achieved an accuracy of 57.3% in identifying the language of test utterances from the OGI corpus. Recent improvements to the system have included the addition of channel normalization during preprocessing, the utilization of the recently transcribed utterances from the OGI corpus for phonetic recognition training, the use of mixture Gaussian density functions for the modeling of prosodic information, and the development of a hill-climbing optimization procedure for determining the scaling factors used when combining the scores from different models. The current system has achieved an accuracy of 79.7% in identifying the language of test utterances. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> T. J. Hazen and V. W. Zue, </author> <title> "Automatic language iden-tification using a segment-based approach," </title> <booktitle> In Proc. Eurospeech 93, </booktitle> <pages> pp. 1303-1306, </pages> <year> 1993. </year>
Reference-contexts: This system, previously described in <ref> [1] </ref> and [2], incorporates phonetic, acoustic and prosodic information within a probabilistic framework. SYSTEM DESCRIPTION Corpus The ALI system described herein was trained and tested using the OGI Multi-Language Telephone Speech Corpus [3]. <p> RESULTS Development Results As shown in the first row of Table 1, our first implementation of an ALI system, as reported in <ref> [1] </ref>, achieved an accuracy of 47.7% when tested on the complete de Date Comments Accuracy 4/93 System presented in [1] 47.7% 8/93 System presented in [2] 48.6% 1/94 + Channel normalization 54.8% 1/94 + Mixture Gaussian duration model 55.8% 2/94 + Recognizer trained w/ OGI data 58.5% Table 1: Summary of <p> RESULTS Development Results As shown in the first row of Table 1, our first implementation of an ALI system, as reported in <ref> [1] </ref>, achieved an accuracy of 47.7% when tested on the complete de Date Comments Accuracy 4/93 System presented in [1] 47.7% 8/93 System presented in [2] 48.6% 1/94 + Channel normalization 54.8% 1/94 + Mixture Gaussian duration model 55.8% 2/94 + Recognizer trained w/ OGI data 58.5% Table 1: Summary of development test results Test date March '94 June '94 Utt. length 10 sec. &gt;30 sec. 10 sec. &gt;30 sec. <p> 43.3% 31.7% 44.4% F0 model 12.4% 20.9% 12.4% 20.9% Complete system 65.4% 70.1% 62.6% 69.0% Table 2: Summary of recent test results on NIST's March '94 evaluation test set (all values are accuracy percentages) velopment test set. 3 The system described in [2] contained incremental improvements over the system in <ref> [1] </ref> and, as shown in the second row of Table 1, achieved an accuracy of 48.6% on the development test set. Since then significant improvements have been made to the system.
Reference: [2] <author> T. J. Hazen, </author> <title> Automatic Language Identification Using a Segment-Based Approach, </title> <type> SM thesis, </type> <institution> MIT, </institution> <year> 1993. </year>
Reference-contexts: This system, previously described in [1] and <ref> [2] </ref>, incorporates phonetic, acoustic and prosodic information within a probabilistic framework. SYSTEM DESCRIPTION Corpus The ALI system described herein was trained and tested using the OGI Multi-Language Telephone Speech Corpus [3]. The original OGI database consisted of utterances spoken in 10 different languages that were collected over the telephone lines. <p> RESULTS Development Results As shown in the first row of Table 1, our first implementation of an ALI system, as reported in [1], achieved an accuracy of 47.7% when tested on the complete de Date Comments Accuracy 4/93 System presented in [1] 47.7% 8/93 System presented in <ref> [2] </ref> 48.6% 1/94 + Channel normalization 54.8% 1/94 + Mixture Gaussian duration model 55.8% 2/94 + Recognizer trained w/ OGI data 58.5% Table 1: Summary of development test results Test date March '94 June '94 Utt. length 10 sec. &gt;30 sec. 10 sec. &gt;30 sec. <p> model 48.8% 52.9% 49.0% 50.8% Duration model 34.7% 43.3% 31.7% 44.4% F0 model 12.4% 20.9% 12.4% 20.9% Complete system 65.4% 70.1% 62.6% 69.0% Table 2: Summary of recent test results on NIST's March '94 evaluation test set (all values are accuracy percentages) velopment test set. 3 The system described in <ref> [2] </ref> contained incremental improvements over the system in [1] and, as shown in the second row of Table 1, achieved an accuracy of 48.6% on the development test set. Since then significant improvements have been made to the system.
Reference: [3] <author> Y. K. Muthusamy, R. A. Cole, and B. T. Oshika, </author> <title> "The OGI Multi-Language Speech Corpus," </title> <booktitle> In Proc. of ICSLP 92, </booktitle> <pages> pp. 895-898, </pages> <year> 1992. </year>
Reference-contexts: This system, previously described in [1] and [2], incorporates phonetic, acoustic and prosodic information within a probabilistic framework. SYSTEM DESCRIPTION Corpus The ALI system described herein was trained and tested using the OGI Multi-Language Telephone Speech Corpus <ref> [3] </ref>. The original OGI database consisted of utterances spoken in 10 different languages that were collected over the telephone lines. The ten languages are English, Farsi, French, German, Japanese, Korean, Mandarin, Spanish, Tamil, and Vietnamese. Each language contained utterances from 90 different speakers.
Reference: [4] <author> V. Zue, J. Glass, M. Phillips, and S. Seneff, </author> <title> "The MIT SUMMIT Speech Recognition System: A progress re-port," </title> <booktitle> In Proc. of the DARPA Speech and Natural Language Workshop, </booktitle> <pages> pp. 179-189, </pages> <month> February, </month> <year> 1989. </year>
Reference-contexts: A delta log 2 F0 value was also computed for each voiced frame. Phonetic Recognition The summit phonetic recognizer <ref> [4, 5] </ref> is used to determine the most likely string of phonetic elements C and segmentation S. The phonetic string C is represented using 87 different phones. The recognition phase is completely language independent. The recognizer is trained using the phonetically transcribed utterances in the OGI corpus.
Reference: [5] <author> V. Zue, J. Glass, D. Goodine, H. Leung, M. Phillips, J. Polifroni, and S. Seneff, </author> <title> "Recent progress on the SUMMIT system," </title> <booktitle> In Proc. of the Third DARPA Speech and Natural Language Workshop, </booktitle> <pages> pp. 380-384, </pages> <month> June, </month> <year> 1990. </year>
Reference-contexts: A delta log 2 F0 value was also computed for each voiced frame. Phonetic Recognition The summit phonetic recognizer <ref> [4, 5] </ref> is used to determine the most likely string of phonetic elements C and segmentation S. The phonetic string C is represented using 87 different phones. The recognition phase is completely language independent. The recognizer is trained using the phonetically transcribed utterances in the OGI corpus.
References-found: 5

