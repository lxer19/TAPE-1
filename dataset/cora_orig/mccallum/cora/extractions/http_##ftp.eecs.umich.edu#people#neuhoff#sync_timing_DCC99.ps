URL: http://ftp.eecs.umich.edu/people/neuhoff/sync_timing_DCC99.ps
Refering-URL: http://ftp.eecs.umich.edu/people/neuhoff/
Root-URL: http://www.eecs.umich.edu
Email: nkashyap@eecs.umich.edu  
Title: Data Compression Conference (DCC '99) Codes for Data Synchronization with Timing  
Author: Navin Kashyap David L. Neuhoff 
Address: Ann Arbor, MI 48109-2122 USA  
Affiliation: Department of Electrical Engineering and Computer Science University of Michigan,  
Abstract: This paper investigates the design and analysis of data synchronization codes whose decoders have the property that, in addition to reestablishing correct decoding after encoded data is lost or a*icted with errors, they produce the original time index of each decoded data symbol modulo some integer T . The motivation for such data synchronization with timing is that in many situations where data must be encoded, it is not sufficient for the decoder to present a sequence of correct data symbols. Instead, the user also needs to know the position in the original source sequence of the symbols being presented. With this goal in mind, periodic prefix-synchronized (PPS) codes are introduced and analyzed on the basis of their synchronization delay D, rate R, and timing span T . Introduced are two specific PPS designs called natural marker and cascaded codes. A principal result is that when coding binary data with rate R, the largest possible timing span attainable with PPS codes grows exponentially with delay D, with exponent D(1 R). Thus, large timing span can be attained with little redundancy and moderate values of delay. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> T.J. Ferguson and J.H. Rabinowitz, </author> <title> "Self synchronizing Huffman codes," </title> <journal> IEEE Trans. Inform. Theory, </journal> <volume> vol. 30, no. 4, </volume> <pages> pp. 687-693, </pages> <month> July </month> <year> 1984. </year>
Reference: [2] <author> Shaw-Min Lei, </author> <title> "The construction of efficient variable-length codes with clear synchronizing codewords for digital video applications," </title> <booktitle> Proc. SPIE Visual Communications and Image Processing '91, Boston, </booktitle> <pages> pp. 863-873, </pages> <month> Nov. </month> <year> 1991. </year>
Reference: [3] <author> W.-M. Lam and A.R. Reibman, </author> <title> "Self-synchronizing variable length codes for image transmission," </title> <booktitle> Proc. ICASSP, </booktitle> <pages> pp. </pages> <address> III-477 III-480, </address> <month> March </month> <year> 1992. </year>
Reference: [4] <author> E.N. Gilbert, </author> <title> "Synchronization of binary messages," </title> <journal> IRE Trans. Inform. Theory, </journal> <volume> vol. IT-6, </volume> <pages> pp. 470-477, </pages> <year> 1960. </year>
Reference-contexts: A specific PPS code with period p and markers of length m, whose codebooks contain sequences of length n = m + L, will be referred to as a (p; m; n) code. A (1; m; n) code is simply a prefix-synchronized code, first studied by Gilbert <ref> [4] </ref>, and subsequently, by Guibas and Odlyzko [5] among others. The PPS code with markers M 1 = 000, M 2 = 111, and codebooks C 1 = f0001100; 0001010g, C 2 = f1110011; 1110101g, is an example of a (2; 3; 7) code. <p> we shall explore the tradeoffs between the three performance measures and determine some of the properties of the functions mentioned above. 4 Analysis using Generating Functions 4.1 Gilbert's Prefix-Synchronized Codes As mentioned earlier, for p = 1, PPS codes are nothing but the prefix-synchronized codes introduced by Gilbert in 1960 <ref> [4] </ref>. Given a binary sequence, M , of length m and an integer n &gt; m, let g M (n) be the cardinality of the set of all binary sequences that can be used as codewords in a (1; m; n) code with marker M .
Reference: [5] <author> L.J. Guibas and A.M. Odlyzko, </author> <title> "Maximal prefix-synchronized codes," </title> <journal> SIAM J. Appl. Math., </journal> <volume> vol. 35, no. 2, </volume> <pages> pp. 401-418, </pages> <month> Sept. </month> <year> 1978. </year>
Reference-contexts: A (1; m; n) code is simply a prefix-synchronized code, first studied by Gilbert [4], and subsequently, by Guibas and Odlyzko <ref> [5] </ref> among others. The PPS code with markers M 1 = 000, M 2 = 111, and codebooks C 1 = f0001100; 0001010g, C 2 = f1110011; 1110101g, is an example of a (2; 3; 7) code. <p> In other words, given an integer m &gt; 0, for all sufficiently large n, R (1; m; n) = blog 2 g M (n)c=n, with M = 1 m . The work of Gilbert, and subsequently, that of Guibas and Odlyzko <ref> [5] </ref> contained methods for evaluating g M (n) using generating functions. In particular, from [5], it follows that for M = 1 m and n &gt; m, g M (n) is the coefficient of z n in the expansion 5 of (2 z)z m1 (1) P 1 Now, it is a <p> The work of Gilbert, and subsequently, that of Guibas and Odlyzko <ref> [5] </ref> contained methods for evaluating g M (n) using generating functions. In particular, from [5], it follows that for M = 1 m and n &gt; m, g M (n) is the coefficient of z n in the expansion 5 of (2 z)z m1 (1) P 1 Now, it is a well known fact from the theory of complex variables that if the power series
Reference: [6] <author> L.J. Guibas and A.M. Odlyzko, </author> <title> "String overlaps, pattern matching, and non-transitive games," </title> <journal> J. Comb. Theory, series A, </journal> <volume> vol. 30, </volume> <pages> pp. 183-208, </pages> <year> 1981. </year> <month> 10 </month>
Reference-contexts: Following the method of analysis of Guibas and Odlyzko <ref> [6] </ref>, we can derive a generating function for f AB (n), as shown in [8]. With this, one can numerically evaluate R (2; m; n) and, consequently, D (2; r) for any desired value of r.
Reference: [7] <author> D.A. Wolfram, </author> <title> "Solving generalized Fibonacci recurrences," </title> <journal> The Fibonacci Quar--terly, </journal> <volume> vol. 36.2, </volume> <pages> pp. 129-145, </pages> <month> May </month> <year> 1998. </year>
Reference-contexts: It can be shown that for m 2, the largest zero, ae m , of the polynomial z m : : : z 1 is real, and lies in the interval (1,2) <ref> [7] </ref>. Combining all the above facts leads to the following result. Theorem 1: For m 2, lim n!1 R (1; m; n) = log 2 ae m . (Detailed proofs of this and the other results in this paper can be found in [8].) In [7], it is shown that ae <p> lies in the interval (1,2) <ref> [7] </ref>. Combining all the above facts leads to the following result. Theorem 1: For m 2, lim n!1 R (1; m; n) = log 2 ae m . (Detailed proofs of this and the other results in this paper can be found in [8].) In [7], it is shown that ae m increases with m and that lim m!1 ae m = 2. From this, it follows that lim n!1 R (1; m; n) is an increasing function of m whose limit as m ! 1 is 1.
Reference: [8] <author> N. Kashyap and D.L. Neuhoff, </author> <title> "Data synchronization with timing," </title> <journal> IEEE Trans. Inform. Theory, </journal> <note> in preparation. 11 </note>
Reference-contexts: Combining all the above facts leads to the following result. Theorem 1: For m 2, lim n!1 R (1; m; n) = log 2 ae m . (Detailed proofs of this and the other results in this paper can be found in <ref> [8] </ref>.) In [7], it is shown that ae m increases with m and that lim m!1 ae m = 2. From this, it follows that lim n!1 R (1; m; n) is an increasing function of m whose limit as m ! 1 is 1. <p> Following the method of analysis of Guibas and Odlyzko [6], we can derive a generating function for f AB (n), as shown in <ref> [8] </ref>. With this, one can numerically evaluate R (2; m; n) and, consequently, D (2; r) for any desired value of r. One can also find T (2; r; d), the maximum timing span attainable with PPS codes with period 2, delay at most d, and rate at least r. <p> These bounds follow easily from the definitions of D (p; r) and T (r; d) <ref> [8] </ref>. Theorem 3: (i) For r 2 (0; 1) and p &gt; 0, D (p; r) (log 2 p)=(1r). (ii) For r 2 (0; 1) and d 0, T (r; d) d 2 d (1r) .
References-found: 8

