URL: http://www.cs.rutgers.edu/hpcd/Area_III.3/all_ps_files/chong_irreg95-inverses.ps
Refering-URL: http://www.cs.rutgers.edu/hpcd/Area_III.3/all_html_files/sched.html
Root-URL: http://www.cs.rutgers.edu
Email: ftchong@lcs.mit.edu, schreibr@riacs.edu,  
Title: on Solving Irregular Problems on Distributed Memory Machines, Parallel Sparse Triangular Solution with Partitioned Inverses
Author: Frederic T. Chong Robert Schreiber 
Web: http://www.ai.mit.edu/people/ftchong/.  
Address: Cambridge, MA 02139 Moffet Field, CA 94035  
Affiliation: Santa Barbara, California.  Laboratory for Computer Science Research Institute for Advanced Computer Science Massachusetts Institute of Technology NASA Ames Research Center  
Note: To appear in the 1995 Workshop  Contact:  Support: This work was supported in part by ARPA contract N00014-94-1-09885, by NSF Experimental Systems grant MIP-9012773, by an NSF Presidential Young Investigator Award to Prof. Anant Agarwal, by Project SCOUT (ARPA Contract MDA972-92-J-1032) and by NASA via Contract NAS 2-13721 between NASA and the Universities Space Research Association (USRA).  
Abstract: Unfortunately, when L is a complete factor, parallelism is extremely limited. This study uses the method of partitioned inverses [3] [4] to increase available parallelism over substitution, commonly by an order of magnitude. We also represent our partitioned inverses computation as a DAG and preschedule using DSC. Our preliminary results exhibit dramatically improved speedups on the CM5 and CM5E. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> F. T. Chong, S. D. Sharma, E. A. Brewer, and J. Saltz, </author> <title> "Multiprocessor runtime support for irregular DAGs," in Toward Teraflop Computing and New Grand Challenge Applications (R. </title> <editor> K. Kalia and P. Vashishta, eds.), </editor> <publisher> Nova Science Publishers, Inc., </publisher> <year> 1995. </year> <note> To appear. </note>
Reference-contexts: Sections 6 and 7 describe our experiments and results. Finally, Sections 8 and 9 discuss the shortcomings and open issues of this work. 2 Substitution The basic method of solving a triangular system, Lx = b, where L is lower triangular, is through substitution. Our previous study <ref> [1] </ref> used a row-based distribution and represented the substitution computation as a DAG. Figure 1 illustrates how the DAG is derived from the triangular system. Each row i is represented by a DAG node i. <p> Additionally, polling fits well into our application. We poll during active message sends and while waiting for the next presched-uled DAG node to become available. We also use a version of active message send provided by the Strata [13] communications library, SendBothLRPollBoth. In our previous study <ref> [1] </ref>, we found that using SendBothLRPollBoth, which polls on every message injection, keeps the network clear of congestion and results in superior performance to the TMC's CMAML [14] functions. <p> In this case, however, there is no regular pattern of fill. The incomplete factor reflects the same structure, however irregular, of the original matrix. Aggregation may not be possible in such cases and fine-grained methods must suffice. 10 Conclusion While our previous study <ref> [1] </ref> demonstrated that solution by substitution performs well on incomplete factors, substitution lacks the parallelism necessary for solving complete factors on parallel systems. The key conclusion is that partitioned inverses extracts dramatically improved parallelism for solving complete factors.
Reference: [2] <author> A. Gerasoulis and T. Yang, </author> <title> "A comparison of clustering heuristics for scheduling directed acyclic graphs on multiprocessors," </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> vol. 16, </volume> <pages> pp. 276-291, </pages> <year> 1992. </year>
Reference-contexts: The dashed arcs in L 0 no longer apply because the 4-to-5 dependency has been partitioned to L 1 , breaking the original transitive closure. 4 DSC Scheduling Dominant Sequence Clustering (DSC) is a compile-time scheduling and mapping algorithm developed by Yang and Gerasoulos <ref> [2] </ref> that runs on sequential platforms. Although we expect our approach to be most useful for runtime preprocessing, we use DSC in this study to provide an upper bound on prescheduled performance.
Reference: [3] <author> F. Alvarado and R. Schreiber, </author> <title> "Optimal parallel solution of sparse triangular systems," </title> <journal> SIAM Journal of Scientific and Statistical Computation, </journal> <volume> vol. 14, </volume> <pages> pp. 446-460, </pages> <year> 1993. </year>
Reference-contexts: Fill corresponds to any extra arcs added to our DAG representation by transitive closure. Extra arcs are shown as dashed arrows and fill is shown as empty circles. 3 Partitioned Inverses Partitioned inverses is an alternative method of sparse triangular solution that has been shown to greatly enhance parallelism <ref> [3] </ref> [4]. In general, the system Lx = b can be solved through the computation x = L 1 b. Unfortunately, as we can see in Figure 2 the calculation of L 1 can lead to fill, nonzeros that were not in the original sparse structure of L. <p> Figure 4 shows how we represent this calculation as a DAG. In general, Lx = b may be solved by computing: x = i i b where the L i 's are chosen to have transitively closed column subgraphs. We use the rp2 algorithm given in <ref> [3] </ref> to choose our partitions.
Reference: [4] <author> F. Alvarado, A. Pothen, and R. Schreiber, </author> <title> Highly parallel sparse triangular solution, </title> <journal> pp. </journal> <pages> 141-157. </pages> <address> New York: </address> <publisher> Springer-Verlag, </publisher> <year> 1993. </year> <note> The IMA Volumes in Mathematics and Its Applications, Volume 56. </note>
Reference-contexts: Extra arcs are shown as dashed arrows and fill is shown as empty circles. 3 Partitioned Inverses Partitioned inverses is an alternative method of sparse triangular solution that has been shown to greatly enhance parallelism [3] <ref> [4] </ref>. In general, the system Lx = b can be solved through the computation x = L 1 b. Unfortunately, as we can see in Figure 2 the calculation of L 1 can lead to fill, nonzeros that were not in the original sparse structure of L. <p> DSC speedup is an estimate derived by DSC and is an upper bound on speedup given DSC's mapping and scheduling of DAG nodes. Note the dramatic improvement in estimated speedup between solution by substitution and solution by partitioned inverses. This is consistent with previous results <ref> [4] </ref>. Also note the that the higher the ratio of nonzeros to number of partitions, the higher the estimated speedup. Figure 5 gives a more detailed view of DSC estimated speedups for each benchmark from 4 to 128 CM5 processors.
Reference: [5] <author> E. Rothberg, </author> <title> "Performance of panel and block approaches to sparse Cholesky factorization on iPSC/860 and Paragon multiprocessors," </title> <type> technical report, </type> <institution> Intel SSD, </institution> <address> 14924 N.W. Greenbrier Parkway, Beaverton OR 97006, </address> <year> 1993. </year> <title> [6] "Analysis of performance accelerator running ETMSP," Technical Report TR-102856, Performance Processors, </title> <publisher> Inc., </publisher> <address> Palo Alto, California 94301, </address> <month> October </month> <year> 1993. </year> <note> Research Project 8010-31. </note>
Reference-contexts: Most parallel computing involving sparse matrices has focused on factorization rather than solution for two reasons. First, both the unit of computation and the messages sizes are larger. Block factorization algorithms have performed well on parallel machines with relatively large communications overhead <ref> [5] </ref>. We have specifically chosen sparse triangular solve as a challenging application for emerging parallel systems with finer grain capabilities. The second reason for the emphasis on factorization is that factorization takes much more computation than sparse solution. However, there are many applications where the solve time is important.
Reference: [7] <author> T. H. Cormen, C. E. Leiserson, and R. L. Rivest, </author> <title> Introduction to Algorithms. </title> <publisher> MIT Press, </publisher> <year> 1989. </year>
Reference-contexts: DSC takes a general DAG as its input and minimizes communication on critical paths of the DAG, while simultaneously attempting to maintain reasonable load balance. DSC is essentially a heap-based algorithm, similar to Dijkstra-shortest-paths <ref> [7] </ref>. DSC maintains a heap of DAG nodes that are ordered according to the longest computation path they belong to. Nodes are put into clusters one at a time. Nodes in a cluster are mapped to the same processor.
Reference: [8] <author> I. S. Duff, R. G. Grimes, and J. G. Lewis, </author> <title> "User's guide for the Harwell-Boeing sparse matrix collection," </title> <type> Technical Report TR/PA/92/86, CER-FACS, 42 Ave G. Coriolis, </type> <address> 31057 Toulouse Cedex, France, </address> <month> October </month> <year> 1992. </year>
Reference-contexts: DSC's estimate does not include communications overhead or network congestion. However, the estimate serves as a useful upper bound on performance and we present it with our benchmarks in Section 5. 5 Benchmarks We ran our experiments on several sparse matrices taken from the Harwell-Boeing <ref> [8] </ref> benchmark set. We took lower triangular factors from five power grid matrices and two structures matrices. Table 1 lists the attributes of these lower triangular factors. Max DSC Speedup is the maximum DSC speedup achieved for a parallel system with the CM5's parameters with up to 128 processors.
Reference: [9] <institution> Thinking Machines Corporation, Cambridge, MA, </institution> <type> CM-5 Technical Summary, </type> <month> November </month> <year> 1993. </year>
Reference-contexts: Preprocessing for mappings and schedules, however, may be more difficult to amortize and may require an even simpler algorithm than DSC. and communications delay, but not communications overhead. 6 Experiments We ran experiments on the CM5 and the CM5E <ref> [9] </ref>. The CM5 has 33 Mhz Cypress SPARC processors. The CM5E has 40 Mhz Viking superscalar processors, but is otherwise identical to a CM5. The sequential performance of the Cypress on our sparse floating point computation is roughly one MFLOP.
Reference: [10] <author> C. E. Leiserson et al., </author> <title> "The network architecture of the connection machine CM-5," </title> <booktitle> in Symposium on Parallel Architectures and Algorithms, </booktitle> <address> (San Diego, California), </address> <pages> pp. 272-285, </pages> <publisher> ACM, </publisher> <month> June </month> <year> 1992. </year>
Reference-contexts: The sequential performance of the Cypress on our sparse floating point computation is roughly one MFLOP. The sequential performance of the Viking is roughly a factor of two better than the Cypress. Both machines have a fat-tree-based network <ref> [10] </ref> that provides fairly uniform communications delays and sustainable bandwidth. It also has a control network for global operations. To keep our study architecturally general, we do not use the vector units, nor do we use the control network.
Reference: [11] <author> T. v. Eicken et al., </author> <title> "Active messages: a mechanism for integrated communication and computation," </title> <booktitle> in Proceedings of the 19th Annual Symposium on Computer Architecture, </booktitle> <address> (Queensland, Australia), </address> <month> May </month> <year> 1992. </year>
Reference-contexts: It also has a control network for global operations. To keep our study architecturally general, we do not use the vector units, nor do we use the control network. We executed our DAGs in a data-driven fashion using active messages <ref> [11] </ref> for communication. Our method is closely related to the dataflow paradigm [12]. Each arc in our DAG requires communication of three data words, two words of data and one word of address. Our implementation stores the coefficient required for the multiply at the source node in of an arc.
Reference: [12] <author> Arvind, D. E. Culler, and G. K. Maa, </author> <title> "Assessing the benefits of fine-grained parallelism in dataflow programs," </title> <booktitle> in Supercomputing `88, IEEE, </booktitle> <year> 1988. </year>
Reference-contexts: To keep our study architecturally general, we do not use the vector units, nor do we use the control network. We executed our DAGs in a data-driven fashion using active messages [11] for communication. Our method is closely related to the dataflow paradigm <ref> [12] </ref>. Each arc in our DAG requires communication of three data words, two words of data and one word of address. Our implementation stores the coefficient required for the multiply at the source node in of an arc.
Reference: [13] <author> E. A. Brewer and R. D. Blumofe, "Strata: </author> <title> A high-performance communications library." </title> <note> Technical Report (to appear). </note> <institution> MIT Laboratory for Computer Science, </institution> <month> January </month> <year> 1994. </year>
Reference-contexts: We use polling in our communication because interrupts are extremely expensive. Additionally, polling fits well into our application. We poll during active message sends and while waiting for the next presched-uled DAG node to become available. We also use a version of active message send provided by the Strata <ref> [13] </ref> communications library, SendBothLRPollBoth. In our previous study [1], we found that using SendBothLRPollBoth, which polls on every message injection, keeps the network clear of congestion and results in superior performance to the TMC's CMAML [14] functions.
Reference: [14] <institution> Thinking Machines Corporation, </institution> <address> Cambridge, MA, </address> <note> CMMD Reference Manual (Version 3.0), </note> <month> May </month> <year> 1993. </year>
Reference-contexts: We also use a version of active message send provided by the Strata [13] communications library, SendBothLRPollBoth. In our previous study [1], we found that using SendBothLRPollBoth, which polls on every message injection, keeps the network clear of congestion and results in superior performance to the TMC's CMAML <ref> [14] </ref> functions. Differences were as high as a factor of three in communications overhead and ranged from 25 to 30 percent in overall applications performance. 7 Results Our results demonstrate that, using partitioned inverses, speedups are possible where substitution would only produce slowdowns.
Reference: [15] <author> E. Rothberg, </author> <title> "Alternatives for solving sparse triangular systems on distributed-memory multiprocessors," </title> <booktitle> Parallel Computing, </booktitle> <year> 1994. </year> <note> To Appear. </note>
Reference-contexts: Our efficiency could also be improved by attempting to find larger units of computations and attempting to aggregate small messages into larger ones. This coarser granularity is inherently available in completely factored matrices and have been effectively used in other studies <ref> [15] </ref>. During factorization, fill is introduced in a regular pattern that can be formed into blocks of computation and communication. These blocks may either be given explicitly to the DAG scheduler as large DAG nodes or an intelligent sched-uler may find such aggregations automatically from small DAG nodes.
References-found: 14

