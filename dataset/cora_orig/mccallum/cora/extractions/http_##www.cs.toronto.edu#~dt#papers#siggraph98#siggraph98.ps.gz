URL: http://www.cs.toronto.edu/~dt/papers/siggraph98/siggraph98.ps.gz
Refering-URL: http://www.cs.toronto.edu/~dt/graphics.html
Root-URL: http://www.cs.toronto.edu
Title: NeuroAnimator: Fast Neural Network Emulation and Control of Physics-Based Models  
Author: Radek Grzeszczuk Demetri Terzopoulos ; Geoffrey Hinton 
Keyword: CR Categories: I.3.7 [Computer Graphics]: Three-Dimensional Graphics and RealismAnimation; I.6.8 [Simulation and Modeling]: Types of SimulationAnimation Keywords: physics-based animation, neural networks, learning, motion control, backpropagation, dynamical systems, simulation.  
Address: Toronto  
Affiliation: 1 Intel Corporation 2 University of  
Abstract: Animation through the numerical simulation of physics-based graphics models offers unsurpassed realism, but it can be computationally demanding. Likewise, the search for controllers that enable physics-based models to produce desired animations usually entails formidable computational cost. This paper demonstrates the possibility of replacing the numerical simulation and control of dynamic models with a dramatically more efficient alternative. In particular, we propose the NeuroAnimator, a novel approach to creating physically realistic animation that exploits neural networks. NeuroAnimators are automatically trained off-line to emulate physical dynamics through the observation of physics-based models in action. Depending on the model, its neural network emulator can yield physically realistic animation one or two orders of magnitude faster than conventional numerical simulation. Furthermore, by exploiting the network structure of the NeuroAni-mator, we introduce a fast algorithm for learning controllers that enables either physics-based models or their neural network emulators to synthesize motions satisfying prescribed animation goals. We demonstrate NeuroAnimators for a variety of physics-based models. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> David Baraff. </author> <title> Analytical methods for dynamic simulation of non-penetrating rigid bodies. </title> <editor> In Jeffrey Lane, editor, </editor> <booktitle> Computer Graphics (SIGGRAPH '89 Proceedings), </booktitle> <volume> volume 23, </volume> <pages> pages 223232, </pages> <month> July </month> <year> 1989. </year>
Reference-contexts: structure of NeuroAnimators furthermore enables a new solution to the control problem associated with physics-based models, leading to a remarkably fast algorithm for synthesizing motions that satisfy prescribed animation goals. 1.1 Overview of the NeuroAnimator Approach Our approach is motivated by the following considerations: Whether we are dealing with rigid <ref> [6, 1] </ref>, articulated [7, 19], or non-rigid [17, 10] dynamic animation models, the numerical simulation of the associated equations of motion leads to the computation of a discrete-time dynamical system of the form s t+ffit = [s t ; u t ; f t ]: (1) These (generally nonlinear) equations express <p> We begin the off-line training process by initializing the weights of N oe to random values from a uniform distribution in the range <ref> [0; 1] </ref> (due to the normalization of inputs and outputs). Xerion automatically terminates the backpropagation learning algorithm when it can no longer reduce the network approximation error (3) significantly. We use the conjugate gradient method to train networks of small and moderate size.
Reference: [2] <author> C. M. Bishop. </author> <title> Neural Networks for Pattern Recognition. </title> <publisher> Clarendon Press, </publisher> <year> 1995. </year>
Reference-contexts: Neural networks <ref> [2] </ref> offer a general mechanism for approximating complex maps in higher dimensional spaces. 2 Our premise is that, to a sufficient degree of accuracy and at significant computational savings, trained neural networks can approximate maps 2 Note that in (1) is in general a high-dimensional map from &lt; s+u+f 7! &lt;
Reference: [3] <author> G. Cybenko. </author> <title> Approximation by superposition of sigmoidal function. Mathematics of Control Signals and Systems, </title> <address> 2(4):303314, </address> <year> 1989. </year>
Reference-contexts: One with too many neurons overfits the data. The solid curve represents a properly chosen network which provides a good compromise between approximation (fits the training data) and generalization (generates reasonable output values away from the training examples). a compact domain x 2 X <ref> [3, 8] </ref>; i.e., for an arbitrarily small * &gt; 0 there exists a network N such that 8x 2 X ; e (x; w) = k (x) N (x; w)k &lt; *; (3) where e is the approximation error.
Reference: [4] <author> R. Grzeszczuk. NeuroAnimator: </author> <title> Fast Neural Network Emulation and Control of Physics-Based Models. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, University of Toronto, </institution> <month> May </month> <year> 1998. </year>
Reference-contexts: A more detailed presentation of the restructured emulator can be found in <ref> [4] </ref>. 3.3 Hierarchical Networks As a universal function approximator, a neural network should in principle be able to approximate the map in (1) for any dynamical system given enough sigmoid hidden units and training data. <p> Although this definition covers a wide range of practical problems, our approach to control learning can handle objective functions whose analytic form is unknown in advance. See <ref> [4] </ref> for further discussion.
Reference: [5] <author> Radek Grzeszczuk and Demetri Terzopoulos. </author> <title> Automated learning of Muscle-Actuated locomotion through control abstraction. </title> <editor> In Robert Cook, editor, </editor> <booktitle> SIG-GRAPH 95 Conference Proceedings, Annual Conference Series, </booktitle> <pages> pages 6370. </pages> <publisher> ACM SIGGRAPH, Addison Wesley, </publisher> <month> August </month> <year> 1995. </year> <title> held in Los Angeles, </title> <address> Cali-fornia, </address> <month> 06-11 August </month> <year> 1995. </year>
Reference-contexts: Hierarchical representations are also useful when dealing with deformable models with large state spaces, such as the biomechani cal model of a dolphin described in <ref> [5] </ref> which we use in our experiments. The mass-spring-damper dolphin model (Fig. 7) consists of 1 3 5 numbered local centers of mass. <p> at the lower right shows the emulator of a physics-based deformable (mass-spring-damper) model of a dolphin capable of locomoting via the coordinated contraction of 6 independently controlled muscle actuators which deform its body, producing hydrodynamic propulsion forces. 4.1 Motivation A popular approach to the animation control problem is controller synthesis <ref> [11, 19, 5] </ref>. Controller synthesis is a generate-and-test strategy. Through repeated forward simulation of the physics-based model, controller synthesis optimizes a control objective function that measures the degree to which the animation generated by the controlled physical model achieves the desired goals. <p> Evaluation of the objective function requires a forward simulation of the dynamic model, often subject to complex applied forces and constraints. Hence the function is almost never analytically differentiable, prompting the application of non-gradient optimization methods such as simulated annealing <ref> [19, 5] </ref> and genetic algorithms [11]. In general, since gradient-free optimization methods perform essentially a random walk through the huge search space of possible controllers, computing many dynamic simulations before finding a good solution, they generally converge slowly compared to optimization methods guided by gradient directions. <p> Figure 4 illustrates forward emulation by the NeuroAnimator according to this index notation. Following the control learning formulation in <ref> [5] </ref>, we define a discrete objective function J (u) = u J u (u) + s J s (s); (11) a weighted sum (with scalar weights u and s ) of a term J u that evaluates the controller u = [u 1 ; u 2 ; : : : ; <p> Referring to the locomotion learning problem studied in <ref> [5] </ref>, we next compare the efficiency of our new backpropagation through time control learning algorithm using NeuroAnimators and the undirected search techniquessimulated annealing and simplex reported in [5]. <p> Referring to the locomotion learning problem studied in <ref> [5] </ref>, we next compare the efficiency of our new backpropagation through time control learning algorithm using NeuroAnimators and the undirected search techniquessimulated annealing and simplex reported in [5]. The locomotion learning problem requires the dolphin to learn how to actuate its 6 independent muscles over time in order to swim forward as efficiently as possible, as defined by an objective function that includes actuator work and distance traveled. <p> In terms of actual running times, the synthesis of the swimming controller which took more than 1 hour using the technique in <ref> [5] </ref> now takes less than 10 seconds on the same computer. Hierarchically structured emulators, in which a global network represents the global aspects of motion and a set of sub-networks refine the motion produced by the global network, enable us to enhance the performance of our controller learning algorithm.
Reference: [6] <author> James K. Hahn. </author> <title> Realistic animation of rigid bodies. </title> <editor> In John Dill, editor, </editor> <booktitle> Computer Graphics (SIGGRAPH '88 Proceedings), </booktitle> <volume> volume 22, </volume> <pages> pages 299308, </pages> <month> August </month> <year> 1988. </year>
Reference-contexts: structure of NeuroAnimators furthermore enables a new solution to the control problem associated with physics-based models, leading to a remarkably fast algorithm for synthesizing motions that satisfy prescribed animation goals. 1.1 Overview of the NeuroAnimator Approach Our approach is motivated by the following considerations: Whether we are dealing with rigid <ref> [6, 1] </ref>, articulated [7, 19], or non-rigid [17, 10] dynamic animation models, the numerical simulation of the associated equations of motion leads to the computation of a discrete-time dynamical system of the form s t+ffit = [s t ; u t ; f t ]: (1) These (generally nonlinear) equations express
Reference: [7] <author> Jessica K. Hodgins, Wayne L. Wooten, David C. Brogan, and James F. O'Brien. </author> <title> Animating human athletics. </title> <editor> In Robert Cook, editor, </editor> <booktitle> SIGGRAPH 95 Conference Proceedings, Annual Conference Series, </booktitle> <pages> pages 7178. </pages> <publisher> ACM SIGGRAPH, Addi-son Wesley, </publisher> <month> August </month> <year> 1995. </year> <institution> held in Los Angeles, California, </institution> <month> 06-11 August </month> <year> 1995. </year>
Reference-contexts: furthermore enables a new solution to the control problem associated with physics-based models, leading to a remarkably fast algorithm for synthesizing motions that satisfy prescribed animation goals. 1.1 Overview of the NeuroAnimator Approach Our approach is motivated by the following considerations: Whether we are dealing with rigid [6, 1], articulated <ref> [7, 19] </ref>, or non-rigid [17, 10] dynamic animation models, the numerical simulation of the associated equations of motion leads to the computation of a discrete-time dynamical system of the form s t+ffit = [s t ; u t ; f t ]: (1) These (generally nonlinear) equations express the vector s <p> A natural example of hierarchical networks arises when approximating complex articulated models, such as Hodgins' mechanical human runner model <ref> [7] </ref> which has a tree structure with a torso and limbs. Rather than collect all of its 30 controlled degrees of freedom into a single large network, it is natural to emulate the model using 5 smaller networks: a torso network plus left and right arm and leg networks.
Reference: [8] <author> K. Hornik, M. Stinchcomb, and H. White. </author> <title> Multilayer feedforward networks are universal approximators. Neural Networks, </title> <address> 2:359366, </address> <year> 1989. </year>
Reference-contexts: One with too many neurons overfits the data. The solid curve represents a properly chosen network which provides a good compromise between approximation (fits the training data) and generalization (generates reasonable output values away from the training examples). a compact domain x 2 X <ref> [3, 8] </ref>; i.e., for an arbitrarily small * &gt; 0 there exists a network N such that 8x 2 X ; e (x; w) = k (x) N (x; w)k &lt; *; (3) where e is the approximation error.
Reference: [9] <author> M. I. Jordan and D. E. Rumelhart. </author> <title> Supervised learning with a distal teacher. </title> <booktitle> Cognitive Science, </booktitle> <address> 16:307354, </address> <year> 1992. </year>
Reference-contexts: The basis of our approach is related to work presented in the mainstream neural network literature on connectionist control of complex systems. Nguyen and Widrow demonstrated the neural network based approximation and control of a nonlinear kinematic system in their truck backer-upper [12]. More recently, Jordan and Rumelhart <ref> [9] </ref> proposed a two step approach to learning controllers for physical robots. In step one, a neural net learns a predictive internal model of the robot, which maps from actions to state transitions.
Reference: [10] <author> Gavin S. P. Miller. </author> <title> The motion dynamics of snakes and worms. </title> <editor> In John Dill, editor, </editor> <booktitle> Computer Graphics (SIGGRAPH '88 Proceedings), </booktitle> <volume> volume 22, </volume> <pages> pages 169178, </pages> <month> August </month> <year> 1988. </year>
Reference-contexts: solution to the control problem associated with physics-based models, leading to a remarkably fast algorithm for synthesizing motions that satisfy prescribed animation goals. 1.1 Overview of the NeuroAnimator Approach Our approach is motivated by the following considerations: Whether we are dealing with rigid [6, 1], articulated [7, 19], or non-rigid <ref> [17, 10] </ref> dynamic animation models, the numerical simulation of the associated equations of motion leads to the computation of a discrete-time dynamical system of the form s t+ffit = [s t ; u t ; f t ]: (1) These (generally nonlinear) equations express the vector s t+ffit of state variables
Reference: [11] <author> J. Thomas Ngo and Joe Marks. </author> <title> Spacetime constraints revisited. </title> <editor> In James T. Kajiya, editor, </editor> <booktitle> Computer Graphics (SIGGRAPH '93 Proceedings), </booktitle> <volume> volume 27, </volume> <pages> pages 343350, </pages> <month> August </month> <year> 1993. </year>
Reference-contexts: at the lower right shows the emulator of a physics-based deformable (mass-spring-damper) model of a dolphin capable of locomoting via the coordinated contraction of 6 independently controlled muscle actuators which deform its body, producing hydrodynamic propulsion forces. 4.1 Motivation A popular approach to the animation control problem is controller synthesis <ref> [11, 19, 5] </ref>. Controller synthesis is a generate-and-test strategy. Through repeated forward simulation of the physics-based model, controller synthesis optimizes a control objective function that measures the degree to which the animation generated by the controlled physical model achieves the desired goals. <p> Evaluation of the objective function requires a forward simulation of the dynamic model, often subject to complex applied forces and constraints. Hence the function is almost never analytically differentiable, prompting the application of non-gradient optimization methods such as simulated annealing [19, 5] and genetic algorithms <ref> [11] </ref>. In general, since gradient-free optimization methods perform essentially a random walk through the huge search space of possible controllers, computing many dynamic simulations before finding a good solution, they generally converge slowly compared to optimization methods guided by gradient directions.
Reference: [12] <author> D. Nguyen and B. Widrow. </author> <title> The truck backer-upper: An example of self-learning in neural networks. </title> <booktitle> In Proceedings of the International Joint Conference on Neural Networks, </booktitle> <volume> volume 2, </volume> <pages> pages 357363. </pages> <publisher> IEEE Press, </publisher> <year> 1989. </year>
Reference-contexts: Our work differs fundamentally from these efforts. The basis of our approach is related to work presented in the mainstream neural network literature on connectionist control of complex systems. Nguyen and Widrow demonstrated the neural network based approximation and control of a nonlinear kinematic system in their truck backer-upper <ref> [12] </ref>. More recently, Jordan and Rumelhart [9] proposed a two step approach to learning controllers for physical robots. In step one, a neural net learns a predictive internal model of the robot, which maps from actions to state transitions.
Reference: [13] <author> W. H. Press, S. A. Teukolsky, W. T. Vetterling, and B. P. Flannery. </author> <title> Numerical Recipes: The Art of Scientific Computing, Second Edition. </title> <publisher> Cambridge University Press, </publisher> <year> 1992. </year>
Reference-contexts: Line search offers one way to accelerate the training by searching for the optimal size step in the gradient direction. Additional performance improvement can be achieved by taking at each optimization step a direction orthogonal to previous directions. This is known as the conjugate gra dient method <ref> [13] </ref>. A simple but effective method for increasing the learning rate augments the gradient descent update rule with a momentum term.
Reference: [14] <author> G. Ridsdale. </author> <title> Connectionist modeling of skill dynamics. </title> <journal> Journal of Visualization and Computer Animation, </journal> <volume> 1(2):6672, </volume> <year> 1990. </year>
Reference-contexts: NeuroAni-mator controllers are equally applicable to controlling the original physics-based models. 1.2 Related Work To date, network architectures have found only a few applications in computer graphics. One application has been the control of animated characters. Ridsdale <ref> [14] </ref> reports a method for skill acquisition using a connectionist model of skill memory. The sensor-actuator networks of van de Panne and Fiume [19] are recurrent networks of units that take sensory information as input and produce actuator controls as output.
Reference: [15] <author> D. E. Rumelhart, G. E. Hinton, and R. J. Williams. </author> <title> Learning internal representations by error backpropagation. </title> <editor> In D. E. Rumelhart, J. L. McCleland, and the PDP Research Group, editors, </editor> <booktitle> Parallel Distributed Processing: Explorations in the Microstructure of Cognition, </booktitle> <volume> volume 1, </volume> <pages> pages 318362. </pages> <publisher> MIT Press, </publisher> <year> 1986. </year>
Reference-contexts: To avoid overfitting, we make sure that we use sufficient training data. We use 8-10 times as many examples as there are weights in the network, which seems sufficient to avoid serious overfitting or underfitting. 2.3 Backpropagation Learning Algorithm Rumelhart, Hinton and Williams <ref> [15] </ref> proposed an efficient algorithm for training multi-layer feedforward networks, called the backpropagation algorithm. The backpropagation algorithm seeks to minimize the objective function E (w) = o=1 o n X E (w) (5) which sums the approximation errors e from (3) over the n training examples. <p> Depicted here is the on-line version of the algorithm that adjusts the weights of the network after observing each training example. An on-line training version of the backpropagation algorithm that adjusts the weights of the network after each training example is presented in <ref> [15] </ref>. Fig. 3 illustrates this process. Backpropagation refers to the practical, recursive method to calculate the component error derivatives of the gradient term in (6). <p> Next, it computes the components of r u J in (13) in an efficient manner. The cascade network structure enables us to apply the chain rule of differentiation within each network, chaining backwards across networks, yielding a variant of the backpropagation algorithm called backpropagation through time <ref> [15] </ref>. Instead of adjusting weights as in normal backpropagation, however, the algorithm adjusts neuronal inputs, specifically, the control inputs. It thus proceeds in reverse through the network cascade computing components of the gradient.
Reference: [16] <author> Karl Sims. </author> <title> Evolving virtual creatures. </title> <editor> In Andrew Glassner, editor, </editor> <booktitle> Proceedings of SIGGRAPH '94 (Orlando, </booktitle> <address> Florida, </address> <month> July 2429, </month> <year> 1994), </year> <booktitle> Computer Graphics Proceedings, Annual Conference Series, </booktitle> <pages> pages 1522. </pages> <publisher> ACM SIGGRAPH, ACM Press, </publisher> <month> July </month> <year> 1994. </year> <note> ISBN 0-89791-667-0. </note>
Reference-contexts: Ridsdale [14] reports a method for skill acquisition using a connectionist model of skill memory. The sensor-actuator networks of van de Panne and Fiume [19] are recurrent networks of units that take sensory information as input and produce actuator controls as output. Sims <ref> [16] </ref> employed a network architecture to structure simple brains that control evolved creatures. Our work differs fundamentally from these efforts. The basis of our approach is related to work presented in the mainstream neural network literature on connectionist control of complex systems.
Reference: [17] <author> Demetri Terzopoulos, John Platt, Alan Barr, and Kurt Fleischer. </author> <title> Elastically de-formable models. </title> <editor> In Maureen C. Stone, editor, </editor> <booktitle> Computer Graphics (SIGGRAPH '87 Proceedings), </booktitle> <volume> volume 21, </volume> <pages> pages 205214, </pages> <month> July </month> <year> 1987. </year>
Reference-contexts: solution to the control problem associated with physics-based models, leading to a remarkably fast algorithm for synthesizing motions that satisfy prescribed animation goals. 1.1 Overview of the NeuroAnimator Approach Our approach is motivated by the following considerations: Whether we are dealing with rigid [6, 1], articulated [7, 19], or non-rigid <ref> [17, 10] </ref> dynamic animation models, the numerical simulation of the associated equations of motion leads to the computation of a discrete-time dynamical system of the form s t+ffit = [s t ; u t ; f t ]: (1) These (generally nonlinear) equations express the vector s t+ffit of state variables
Reference: [18] <author> Xiaoyuan Tu and Demetri Terzopoulos. </author> <title> Artificial fishes: Physics, locomotion, perception, behavior. </title> <editor> In Andrew Glassner, editor, </editor> <booktitle> Proceedings of SIGGRAPH '94 (Orlando, </booktitle> <address> Florida, </address> <month> July 2429, </month> <year> 1994), </year> <booktitle> Computer Graphics Proceedings, Annual Conference Series, </booktitle> <pages> pages 4350. </pages> <publisher> ACM SIGGRAPH, ACM Press, </publisher> <month> July </month> <year> 1994. </year> <note> ISBN 0-89791-667-0. </note>
Reference-contexts: We used SD/FAST 4 to simulate the dynamics of the rigid body and articulated models, and we employ the simulator developed in <ref> [18] </ref> to simulate the deformable-body dynamics of the dolphin. Fig. 10 shows rendered stills from animations created using NeuroAnimators trained with these models. <p> To improve the stability when applying the explicit Euler step, we used a smaller spring stiffness and larger damping factor when compared to the semi-implicit Euler step used during the numerical simulation <ref> [18] </ref>. Otherwise the system would oscillate too much or would simply become unstable. We achieve the best results when performing a few regularization steps after each emulation step. This produces much smoother motion than performing more regularization step but less frequently. <p> This produces much smoother motion than performing more regularization step but less frequently. Referring to Table 2 for the case of the deformable dolphin model, the second column indicates the simulation time using the physical simulator described in <ref> [18] </ref>, the fourth column shows the simulation time using the N 50 emulator, and the last column reveals the impact of regularization on the emulation time.
Reference: [19] <author> Michiel van de Panne and Eugene Fiume. </author> <title> Sensor-actuator networks. </title> <editor> In James T. Kajiya, editor, </editor> <booktitle> Computer Graphics (SIGGRAPH '93 Proceedings), </booktitle> <volume> volume 27, </volume> <pages> pages 335342, </pages> <month> August </month> <year> 1993. </year>
Reference-contexts: furthermore enables a new solution to the control problem associated with physics-based models, leading to a remarkably fast algorithm for synthesizing motions that satisfy prescribed animation goals. 1.1 Overview of the NeuroAnimator Approach Our approach is motivated by the following considerations: Whether we are dealing with rigid [6, 1], articulated <ref> [7, 19] </ref>, or non-rigid [17, 10] dynamic animation models, the numerical simulation of the associated equations of motion leads to the computation of a discrete-time dynamical system of the form s t+ffit = [s t ; u t ; f t ]: (1) These (generally nonlinear) equations express the vector s <p> One application has been the control of animated characters. Ridsdale [14] reports a method for skill acquisition using a connectionist model of skill memory. The sensor-actuator networks of van de Panne and Fiume <ref> [19] </ref> are recurrent networks of units that take sensory information as input and produce actuator controls as output. Sims [16] employed a network architecture to structure simple brains that control evolved creatures. Our work differs fundamentally from these efforts. <p> at the lower right shows the emulator of a physics-based deformable (mass-spring-damper) model of a dolphin capable of locomoting via the coordinated contraction of 6 independently controlled muscle actuators which deform its body, producing hydrodynamic propulsion forces. 4.1 Motivation A popular approach to the animation control problem is controller synthesis <ref> [11, 19, 5] </ref>. Controller synthesis is a generate-and-test strategy. Through repeated forward simulation of the physics-based model, controller synthesis optimizes a control objective function that measures the degree to which the animation generated by the controlled physical model achieves the desired goals. <p> Evaluation of the objective function requires a forward simulation of the dynamic model, often subject to complex applied forces and constraints. Hence the function is almost never analytically differentiable, prompting the application of non-gradient optimization methods such as simulated annealing <ref> [19, 5] </ref> and genetic algorithms [11]. In general, since gradient-free optimization methods perform essentially a random walk through the huge search space of possible controllers, computing many dynamic simulations before finding a good solution, they generally converge slowly compared to optimization methods guided by gradient directions.
References-found: 19

