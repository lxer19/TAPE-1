URL: http://www.ai.mit.edu/~edelman/mirror/maria-tr.ps.Z
Refering-URL: http://www.ai.mit.edu/~edelman/archive.html
Root-URL: 
Email: edelman@wisdom.weizmann.ac.il  
Title: Receptive field spaces and class-based generalization from a single view in face recognition  
Author: Maria Lando Shimon Edelman yfl 
Date: August 29, 1995  
Address: Rehovot 76100, Israel  
Affiliation: Department of Applied Mathematics and Computer Science The Weizmann Institute of Science  
Abstract: We describe a computational model of face recognition, which generalizes from single views of faces by taking advantage of prior experience with other faces, seen under a wider range of viewing conditions. The model represents face images by vectors of activities of graded overlapping receptive fields (RFs). It relies on high spatial frequency information to estimate the viewing conditions, which are then used to normalize (via a transformation specific for faces), and identify, the low spatial frequency representation of the input. The class-specific transformation approach allows the model to replicate a series of psychophysical findings on face recognition, and constitutes an advance over current face recognition methods, which are incapable of generalization from a single example. fl To whom all correspondence should be addressed.
Abstract-found: 1
Intro-found: 1
Reference: <author> Amari, S. </author> <year> (1968). </year> <title> Invariant structures of signal and feature spaces in pattern recognition problems. </title> <journal> RAAG Memoirs, </journal> <volume> 4 </volume> <pages> 553-566. </pages>
Reference: <author> Amari, S. </author> <year> (1978). </year> <title> Feature spaces which admit and detect invariant signal transformations. </title> <booktitle> In Proc. 4th Intl. Conf. Pattern Recognition, </booktitle> <pages> pages 452-456, </pages> <address> Tokyo. </address>
Reference: <author> Basri, R. </author> <year> (1992). </year> <title> Recognition by prototypes. </title> <journal> A.I. </journal> <volume> Memo No. </volume> <pages> 1391, </pages> <institution> Artificial Intelligence Laboratory, Massachusetts Institute of Technology, </institution> <address> Cambridge, MA. </address> <note> Intl. Journal of Computer Vision, in press. </note>
Reference-contexts: At least two different computational approaches to these issues has been suggested recently. The first of these <ref> (Basri, 1992) </ref> concentrates on the relationship between classification and recognition, and assumes the availability of a library of 3D models of prototypical objects. In the first stage of the recognition process in Basri's system, the prototypes are aligned (Ullman, 1989) with the input image.
Reference: <author> Beymer, D., Shashua, A., and Poggio, T. </author> <year> (1993). </year> <title> Example based image analysis and synthesis. </title>
Reference-contexts: Right: Whereas in computer graphics applications the goal of this operation is to generate the image of the new face under the specified transformation <ref> (Beymer et al., 1993) </ref>, recognizing a face from an unfamiliar viewpoint calls merely for the normalization of its representation in some feature space that preserves face identity (e.g., the space spanned by properly chosen receptive fields); see section 1.2.1. appears to be, to a considerable extent, an acquired ability.
Reference: <author> A.I. </author> <title> Memo No. </title> <type> 1431, </type> <institution> Artificial Intelligence Laboratory, Massachusetts Institute of Technology, </institution> <address> Cambridge, MA. </address>
Reference: <author> Brigham, J. C. </author> <year> (1986). </year> <title> The influence of race on face recognition. </title> <editor> In Ellis, H. D., Jeeves, M. A., and Newcombe, F., editors, </editor> <booktitle> Aspects of face processing, </booktitle> <pages> pages 170-177. </pages> <publisher> Martinus Nijhoff, Dordrecht. </publisher>
Reference-contexts: The interpretation offered by our model for the results obtained with distinctive faces can be extended to account for the peculiarities of recognition of faces across race <ref> (Brigham, 1986) </ref>. It is well known that people used to see predominantly Caucasian faces find it more difficult to distinguish among Oriental faces than people living in the Orient, and vice versa.
Reference: <author> Carey, S. and Diamond, R. </author> <year> (1977). </year> <title> From piecemeal to configurational representation of faces. </title> <journal> Science, </journal> <volume> 195 </volume> <pages> 312-314. </pages>
Reference: <author> Carey, S., Diamond, R., and Woods, B. </author> <year> (1980). </year> <title> Development of face recognition-a maturational component? Developmental Psychology, </title> <booktitle> 16 </booktitle> <pages> 257-269. </pages>
Reference-contexts: Children's recognition of upright faces improves steadily from age 6 to 10, dips temporarily between ages 11 and 12, then climbs to an adult level <ref> (Carey et al., 1980) </ref>. In comparison, recognition performance on inverted faces does not change throughout the life and remains significantly worse (Carey and Diamond, 1977; Carey et al., 1980).
Reference: <author> Diamond, R. and Carey, S. </author> <year> (1986). </year> <title> Why faces are and are not special: an effect of expertise. </title> <journal> Journal of experimental psychology, </journal> <volume> 115(2) </volume> <pages> 107-117. </pages>
Reference-contexts: The extensive experience of the human visual system with upright faces in everyday life constitutes the central difference between upright and inverted faces <ref> (Diamond and Carey, 1986) </ref>. Presumably, it is this experience that allows upright, but not inverted, faces to be recognized easily under a wide range of unfamiliar conditions (see Figure 1).
Reference: <author> Duvdevani-Bar, S. and Edelman, S. </author> <year> (1995). </year> <title> On similarity to prototypes in 3D object representation. </title> <type> CS-TR 95-11, </type> <institution> Weizmann Institute of Science. </institution> <note> 21 Edelman, </note> <author> S. </author> <year> (1995). </year> <title> Representation, Similarity, and the Chorus of Prototypes. </title> <journal> Minds and Machines, </journal> <volume> 5 </volume> <pages> 45-68. </pages>
Reference: <author> Edelman, S., Reisfeld, D., and Yeshurun, Y. </author> <year> (1992). </year> <title> Learning to recognize faces from examples. </title> <editor> In Sandini, G., editor, </editor> <booktitle> Proc. 2nd European Conf. on Computer Vision, Lecture Notes in Computer Science, </booktitle> <volume> volume 588, </volume> <pages> pages 787-791. </pages> <publisher> Springer Verlag. </publisher>
Reference-contexts: by the subscript 0: L ^ X 0 = L X V n i=1 The hypothesized prototype in its normalized form, L ^ X (f 0 ) 0 , is passed on to the matching module, which, by interpolation among stored examples, identifies it with one of the familiar faces <ref> (for details regarding this procedure, see, e.g., Edelman et al., 1992) </ref>. The identification performance is summarized in Figure 16, right, and in Table 1. <p> Edelman, 1995). The benefits of class-specific dimensionality reduction implemented by such a two-stage system include the improvement of about 20% in the recognition performance <ref> (Edelman et al., 1992) </ref>; this approach should have a similar effect on the performance of the present model. 19 6 Summary and discussion We have presented a model of the human ability to generalize face recognition from a single image. <p> The model also replicated the central findings of a recent psychophysical study which examined generalization in upright and inverted faces in human subjects. From the practical standpoint, the model constitutes a significant advance over the approach of <ref> (Edelman et al., 1992) </ref>, which also used RBF classifiers to learn face recognition from examples, but was incapable of generalization from a single image of a face.
Reference: <author> Moody, J. and Darken, C. </author> <year> (1989). </year> <title> Fast learning in networks of locally tuned processing units. </title> <journal> Neural Computation, </journal> <volume> 1 </volume> <pages> 281-289. </pages>
Reference-contexts: The performance is similar to that of human subjects (Figure 15) in several respects (upright/inverted comparison; better generalization over illumination vs. viewpoint). (Moses et al., 1993)). 16 4.1 Recovery of viewing conditions We have trained an RBF classifier <ref> (Moody and Darken, 1989) </ref> to approximate the mapping from the high-frequency (16 cpd) RF-space representation H X of a face image to the space of viewing conditions of the face.
Reference: <author> Moses, Y., Edelman, S., and Ullman, S. </author> <year> (1993). </year> <title> Generalization across illumination and orientation changes for inverted and upright faces. </title> <type> CS-TR 14, </type> <institution> Weizmann Institute of Science. </institution>
Reference-contexts: for face recognition, which are by and large incapable of generalization from a single view. 1.1 Psychophysical background A new insight into the computational basis of human generalization performance in face recognition has been achieved as a result of a recent study that compared generalization for upright and inverted faces <ref> (Moses et al., 1993) </ref>. In that study, human subjects performing an upright face discrimination task were found to generalize nearly perfectly to face images obtained under novel illumination and viewpoint direction. <p> Moreover, subjects who, following training, successfully recognize inverted faces under fixed viewing conditions still perform relatively poorly when required to generalize to a novel viewpoint or even a novel illumination <ref> (Moses et al., 1993) </ref>. 2 1.2 Computational background 1.2.1 Related work The main purpose of the present work is to formalize the intuitive notions of perceptual experience and of class-based generalization, outlined in the preceding section. At least two different computational approaches to these issues has been suggested recently. <p> of ffi = 0:05 (see Figure 7). 2.4 Class-specific transformations for real faces We next assessed the behavior of kX (f i ) X (f j ) k and 6 (X (f i ) ; X (f j ) ) on real face images, taken from the Weizmann Face Base <ref> (Moses et al., 1993) </ref>. 3 The results for the length and the 2 The minimum was over all 166 surface patches composing each face model and was the same for all faces. 3 This database contains twenty images of each of 18 different male faces, without distinctive features (e.g. no glasses, <p> In our experiments, each face was represented by 15 images, taken under all combinations of 5 viewpoints and 3 illuminations. These conditions parallel closely the range of viewpoints and illuminations used in the psychophysical study of <ref> (Moses et al., 1993) </ref>; only one value of illumination (corresponding to a superposition of two other illumination directions) was omitted. experience= 1, upright faces. Middle: experience= 18, upright faces. Right: experience= 18 with upright faces, testing with inverted faces (cf. (Moses et al., 1993)). <p> of viewpoints and illuminations used in the psychophysical study of <ref> (Moses et al., 1993) </ref>; only one value of illumination (corresponding to a superposition of two other illumination directions) was omitted. experience= 1, upright faces. Middle: experience= 18, upright faces. Right: experience= 18 with upright faces, testing with inverted faces (cf. (Moses et al., 1993)). The performance is similar to that of human subjects (Figure 15) in several respects (upright/inverted comparison; better generalization over illumination vs. viewpoint). (Moses et al., 1993)). 16 4.1 Recovery of viewing conditions We have trained an RBF classifier (Moody and Darken, 1989) to approximate the mapping from <p> Middle: experience= 18, upright faces. Right: experience= 18 with upright faces, testing with inverted faces (cf. <ref> (Moses et al., 1993) </ref>). The performance is similar to that of human subjects (Figure 15) in several respects (upright/inverted comparison; better generalization over illumination vs. viewpoint). (Moses et al., 1993)). 16 4.1 Recovery of viewing conditions We have trained an RBF classifier (Moody and Darken, 1989) to approximate the mapping from the high-frequency (16 cpd) RF-space representation H X of a face image to the space of viewing conditions of the face. <p> In this manner, the model is capable of improving its performance with experience. 5 Comparing model and human performance We compared the performance of the model with that of human subjects, by replicating the upright/inverted face generalization experiments described in <ref> (Moses et al., 1993) </ref>. In the simulated experiment, the model was trained to recognize single images of three different faces taken under a fixed combination of viewpoint and illumination. <p> Importantly, the increase in the level of experience on upright faces from 1 to 18 did not improve the model's generalization performance on inverted face images, replicating the main psychophysical finding of <ref> (Moses et al., 1993) </ref> (see Figure 14).
Reference: <author> Newell, F., Chiroro, P., and Valentine, T. </author> <year> (1995). </year> <title> Recognising unfamiliar faces: The effects of distinctiveness and view. </title> <note> in preparation. </note>
Reference: <author> Poggio, T. and Girosi, F. </author> <year> (1990). </year> <title> Regularization algorithms for learning that are equivalent to multilayer networks. </title> <journal> Science, </journal> <volume> 247 </volume> <pages> 978-982. </pages>
Reference: <author> Poggio, T. and Vetter, T. </author> <year> (1992). </year> <title> Recognition and structure from one 2D model view: observations on prototypes, object classes, and symmetries. </title> <journal> A.I. </journal> <volume> Memo No. </volume> <pages> 1347, </pages> <institution> Artificial Intelligence Laboratory, Massachusetts Institute of Technology. </institution>
Reference-contexts: One possible approach here is to rely on the symmetry property of faces: for bilaterally symmetric objects, a simple transformation of a generic 2D view of the object yields another legal view <ref> (Poggio and Vetter, 1992) </ref>. For faces, this transformation corresponds to the mirroring of one view of a face with respect to the sagittal plane to obtain another view. The newly available view can then be used to improve the training of the viewpoint recovery module.
Reference: <author> Snippe, H. P. and Koenderink, J. J. </author> <year> (1992). </year> <title> Discrimination thresholds for channel-coded systems. </title> <journal> Biological Cybernetics, </journal> <volume> 66 </volume> <pages> 543-551. </pages>
Reference-contexts: The overlap between the constituent RFs has been shown to improve the utility of a representation <ref> (Snippe and Koenderink, 1992) </ref>. This improvement, however, saturates when the number of RFs reaches a few hundreds, making a relatively small set of RFs nearly as useful as a full dimensionality-preserving coverage of the retinal space (Weiss and Edelman, 1995). Clustering by face identity.
Reference: <author> Ullman, S. </author> <year> (1989). </year> <title> Aligning pictorial descriptions: an approach to object recognition. </title> <journal> Cognition, </journal> <volume> 32 </volume> <pages> 193-254. </pages>
Reference-contexts: The first of these (Basri, 1992) concentrates on the relationship between classification and recognition, and assumes the availability of a library of 3D models of prototypical objects. In the first stage of the recognition process in Basri's system, the prototypes are aligned <ref> (Ullman, 1989) </ref> with the input image. Alignment here is class-based in the sense that the transformation between the best-matching prototype and the input is taken to apply to the entire class of shapes which the prototype represents.
Reference: <author> Weiss, Y. and Edelman, S. </author> <year> (1995). </year> <title> Representation of similarity as a goal of early visual processing. </title> <journal> Network, </journal> <volume> 6 </volume> <pages> 19-41. </pages>
Reference-contexts: This improvement, however, saturates when the number of RFs reaches a few hundreds, making a relatively small set of RFs nearly as useful as a full dimensionality-preserving coverage of the retinal space <ref> (Weiss and Edelman, 1995) </ref>. Clustering by face identity. <p> This assumption relies on a recent computational investigation, which found that images of the same face form tighter clusters at the higher levels of an RF-based representation hierarchy resembling the one found in mammalian vision <ref> (Weiss and Edelman, 1995) </ref>. 1.2.3 Class-based generalization requires that those transformations commute with the feature extraction process (solid arrows; see Amari, 1968). <p> Figure 3 depicts four of the 50 faces that were obtained by varying the 19 parameters. Each of the 50 face models was rendered under five different viewing positions and three illumination directions, and the resulting images were represented by activities of 500 RFs <ref> (Weiss and Edelman, 1995) </ref>. <p> Note the small absolute value of angle changes across viewing conditions, both for synthetic and for human faces. The spatial frequency analysis of face-difference images reported in <ref> (Weiss and Edelman, 1995) </ref> suggests that the nature of clustering of faces in RF-space should depend on the size of the RFs used in the representation.
Reference: <author> Wilson, H. R. and Bergen, J. R. </author> <year> (1979). </year> <title> A four mechanism model for threshold spatial vision. </title> <journal> Vision Research, </journal> <volume> 19 </volume> <pages> 19-32. </pages>
Reference-contexts: In biological visual systems, a natural basis for the defini-tion of similarity can be derived from the concept of processing units with localized receptive fields (RFs). The RFs of the primary visual cortex correspond to the psychophysically defined spatial frequency channels of <ref> (Wilson and Bergen, 1979) </ref>; activities of the graded-profile highly overlapping RFs at the previous stages is the only input available to any processing stage in the visual pathway past the retina. <p> We tested this conjecture, by convolving face images with Difference of Gaussian RFs, corresponding in size to the different spatial frequency channels described in <ref> (Wilson and Bergen, 1979) </ref>. Eight values of RF size, between 0:8 cycles per degree (cpd) and 16 cpd, were used with images of different faces, under different viewing conditions. For each RF size, we conducted 60 trials, with faces chosen randomly from the Weizmann database.
References-found: 20

