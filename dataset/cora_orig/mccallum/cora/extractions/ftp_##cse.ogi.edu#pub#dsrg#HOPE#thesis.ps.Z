URL: ftp://cse.ogi.edu/pub/dsrg/HOPE/thesis.ps.Z
Refering-URL: http://www.cse.ogi.edu/~crispin/
Root-URL: http://www.cse.ogi.edu
Title: A Programming Model for Optimism  
Author: by Crispin Cowan 
Degree: Submitted in partial fulfillment of the requirements for the degree of Doctor of Philosophy Faculty of Graduate Studies  
Note: c Crispin Cowan 1995  
Date: January 1995  
Address: Ontario London, Ontario  
Affiliation: Department of Computer Science  The University of Western  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Jonathan R. Agre and Divyakant Agrawal. </author> <title> Recovering From Process Failures in the Time Warp Mechanism. </title> <booktitle> In 8th Symposium on Reliable Distributed Systems, </booktitle> <pages> pages 53-61, </pages> <address> Seattle, WA, </address> <month> October </month> <year> 1989. </year>
Reference-contexts: Optimistically assuming that such a contributing factor does not exist increases available parallelism. Jefferson's Virtual Time [31] is an algorithm for distributed process synchronization that has been widely studied <ref> [1, 26, 32, 42, 55] </ref>.
Reference: [2] <author> G. M. </author> <title> Amdahl. Validity of the Single Processor Approach to Achieving Large Scale Computing Capabilities. </title> <booktitle> In Proc. AFIPS 1967 Spring Joint Computer Conference 30, </booktitle> <pages> pages 483-485, </pages> <address> Atlantic City, New Jersey, </address> <month> April </month> <year> 1967. </year>
Reference-contexts: Naturally, the response time is of interest only if there is a user waiting for the response. There are limits to the effectiveness of reducing response time through parallelism. Amdahl's Law <ref> [2] </ref> states that the speedup due to parallelism is as follows: Speedup = 1 (1fraction parallelized)+ fraction parallelized speedup of parallelism This equation shows that the speedup due to parallelism is limited by the fraction 4 of a program that can actually be parallelized.
Reference: [3] <institution> American National Standards Institute, Inc. Programming Language - C, ANSI Standard X3.159. American National Standards Institute, Inc., </institution> <year> 1989. </year>
Reference-contexts: Both make the assumption that each of the three data areas is contiguously mapped, and checkpoints them by taking the start and end address of each and saving each to disk with a single write. This assumption, while in violation of the ANSI C Standard <ref> [3] </ref>, is nonetheless true of a large number of C/UNIX implementations. In both cases, the restart mechanism is to re-execute the user's program with special switches that cause the program to invoke the restart mechanism instead of proceeding to the user's code.
Reference: [4] <author> J.S. Auerbach, D.F. Bacon, A.P. Goldberg, G.S. Goldszmidt, M.T. Kennedy, A.R. Lowry, J.R. Russell, W. Silverman, R.E. Strom, D.M. Yellin, and S.A. Yemini. </author> <title> High-Level Language Support for Programming Distributed Systems. </title> <booktitle> In Proceedings of the 1991 CAS Conference, </booktitle> <pages> pages 173-196, </pages> <address> Toronto, Ontario, </address> <month> November </month> <year> 1991. </year>
Reference-contexts: Because S 3 changes the line number, S 1 's test is invalidated. The free of (Order) primitive is used to detect this causality violation and force rollbacks to solve the problem. 3.2 Linguistic Assumptions Like Linda [13] and Concert <ref> [4] </ref>, HOPE is not a complete programming language. Rather it is a programming model for optimism, embodied as a set of primitives designed to be embedded in some other programming language. There are very few restrictions on the kinds of systems in which HOPE can be embedded. <p> HOPE does dependency tracking by marking communications between processes with references to AIDs, and so inter-process communications must be explicit, as is the case in many concurrent and distributed systems <ref> [4, 12, 30, 62] </ref>. Shared memory programming models would be impractical with HOPE, because HOPE dependency tracking operations would have to accompany every shared memory access. Chapter 4 Operational Semantics 1 This chapter defines the formal operational semantics of the HOPE primitives introduced in Chapter 3.
Reference: [5] <author> David F. Bacon and Robert E. Strom. </author> <title> Optimistic Parallelization of Communicating Sequential Processes. </title> <booktitle> In Third ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, </booktitle> <month> April </month> <year> 1991. </year>
Reference-contexts: HOPE is also applicable to the distributed processing domain, where remote communications latency can be avoided by making optimistic assumptions about the behaviour of remote tasks, such as assuming that a remote database server will grant an access lock [15], or that a remote function will return an expected result <ref> [5] </ref>. 22 =fl ATM Process fl= aid t pin ok; =fl the assumption ID for the expected result assumption that pin ok = OK fl= pin = get PIN (); pin ok = aid init (); send (WorryWart, pin ok, pin, user id); if (guess (pin ok)) f =fl Implicitly assume <p> S 2 takes the line number and checks to see if the line number now exceeds page size. If it does, then S 2 creates a new page; otherwise execution can immediately proceed to S 3 . Bacon and Strom <ref> [5] </ref> present an algorithm for optimistically parallelizing two such statements. We can still parallelize S 1 and S 2 (and hence the statements after S 2 ) by making the (likely) optimistic assumption that the report does not end exactly at the bottom of the page, i.e., line &lt; PageSize. <p> Instead, this chapter's purpose is to show that the HOPE prototype can provide performance improvements under some plausibly practical circumstances. Bacon and Strom's Call Streaming <ref> [5] </ref> (see Section 3.1.3) provides one of the most powerful new applications for optimism: parallelizing remote procedure calls in a distributed system. <p> Automatic transformation of pessimistic programs into optimistic programs is an attractive notion because pessimistic programs are easier for programmers to reason about and understand. Both Strom et al. <ref> [5, 59] </ref>, and Bubenik [9] have studied the prospect of automatically optimistic transformation. However, Strom did not have an environment for executing optimistic programs, and so did no experimental work. <p> Finally, there are numerous studies examining the theoretical properties of various schemes for maintaining consistency in the presence of distributed rollback <ref> [5, 16, 42, 54, 55] </ref>. However, an extensive literature search failed to turn up a general purpose rollback facility for UNIX processes. Systems that actually do process rollback seem always to do so in a restricted domain.
Reference: [6] <author> Rajive L. Bagrodia and Wen-Toh Liao. Maisie: </author> <title> A Language for the Design of Efficient Discrete-Event Simulations. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 20(4) </volume> <pages> 225-238, </pages> <month> April </month> <year> 1994. </year>
Reference-contexts: rollback-free algorithms would require blocking for an amount of time equal to that spent on wasted computation [31]. 1.2 HOPE: Hopefully Optimistic Programming Environment Optimistic algorithms have been used for fault tolerance [57, 33], replication [15, 24, 35, 49, 64], concurrency control [29, 32, 36, 68], and discrete event simulation <ref> [6, 22, 31, 50, 65] </ref>. However, the notion of optimism has not been generally exploited because optimistic algorithms are difficult to write. Obstacles to optimism include the following: Checkpoint & Rollback This is difficult and non-portable.
Reference: [7] <author> D. J. Bernstein. </author> <title> Poor Man's Checkpointer. Public Domain Software, </title> <year> 1990. </year>
Reference-contexts: This appendix describes our checkpoint and rollback facility for UNIX processes. The desired facility is a portable, user-space mechanism for checkpointing the state of a UNIX process in C, and then later rolling the process back to that state. There are numerous checkpoint and restart systems <ref> [7, 14, 34, 43, 67] </ref> for UNIX processes. There are also numerous specific systems that include rollback, but are confined to some specific environment or domain, such as discrete event simulation [22, 31, 65] or transaction processing [53, 56, 66]. <p> Recently, the Condor project has undertaken to create a new checkpointing mechanism that does not kill the process [51], but details are not available at this time. Yee's Save World [67] and Bernstein's Pmckpt <ref> [7] </ref> are similar to one another, in that they are small libraries of portable software that provide rudimentary process checkpoint and restart. Both save and restore process state by simply reading and writing the appropriate address ranges.
Reference: [8] <author> Philip A. Bernstein, Vassos Hadzilacos, and Nathan Goodman. </author> <title> Concurrency Control and Recovery in Database Systems. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Massachusetts, </address> <year> 1987. </year>
Reference-contexts: Because HOPE primitives may be executed by concurrent processes, they may be executed concurrently. Thus the remote data access of HOPE prim 45 itive execution may result in concurrent access to shared data items. Using the definitions of Bernstein et al. <ref> [8, page 11] </ref>, we can describe the interaction of HOPE primitive execution as follows. Let a i be an operation in the execution of a HOPE primitive by process P in interval A. <p> Definition 5.3 If the execution of two HOPE primitives produces interleaved, conflicting operations, then that execution of the two HOPE primitives is said to interfere. Bernstein et al. <ref> [8, page 1] </ref> describe an atomic operation such that: 1. each operation accesses shared data without interfering with other operations; and 2. if an operation terminates normally, then all of its effects are made permanent; oth erwise it has no effect at all. <p> interference problems is to prevent the interleaved execution of HOPE primitives: Definition 5.5 A serial execution of two or more HOPE primitives is one in which for every pair of HOPE primitive executions, all operations of one primitive execution complete before any of the operations of the other primitive execution <ref> [8, page 13] </ref>. Definition 5.6 A concurrent execution of two or more HOPE primitives is one that is not serial. Serially-executed HOPE primitives cannot interfere with one another. Serial execution of HOPE primitives is trivially achieved, for example, by processing HOPE primitives in a single, sequential process. <p> Serializable executions can be achieved by applying one of many concurrency control algorithms <ref> [8, 29, 32, 36, 68] </ref> to the execution of HOPE primitives. However, the time and space requirements of incorporating a general concurrency control system within the HOPE run-time are prohibitive.
Reference: [9] <author> R.G. Bubenik. </author> <title> Optimistic Computation. </title> <type> PhD thesis, </type> <institution> Rice University, </institution> <month> May </month> <year> 1990. </year>
Reference-contexts: The speculative predicate (the wouldbe argument) is evaluated at the end of the speculative if or while block, and the computation is either retained or rolled back at that point. 2.2.2 Bubenik's Optimistic Computation In <ref> [9, 10] </ref>, Bubenik et al. describe a formalism for automatically transforming pessimistic algorithms into optimistic algorithms based on concepts in [57, 59]. Bubenik translates the algorithm into a program dependence graph, and then performs optimistic transformations on the graph. <p> Automatic transformation of pessimistic programs into optimistic programs is an attractive notion because pessimistic programs are easier for programmers to reason about and understand. Both Strom et al. [5, 59], and Bubenik <ref> [9] </ref> have studied the prospect of automatically optimistic transformation. However, Strom did not have an environment for executing optimistic programs, and so did no experimental work.
Reference: [10] <author> Rick Bubenik and Willy Zwaenepoel. </author> <title> Semantics of Optimistic Computation. </title> <booktitle> In 10th International Conference on Distributed Computing Systems, </booktitle> <pages> pages 20-27, </pages> <year> 1990. </year>
Reference-contexts: The speculative predicate (the wouldbe argument) is evaluated at the end of the speculative if or while block, and the computation is either retained or rolled back at that point. 2.2.2 Bubenik's Optimistic Computation In <ref> [9, 10] </ref>, Bubenik et al. describe a formalism for automatically transforming pessimistic algorithms into optimistic algorithms based on concepts in [57, 59]. Bubenik translates the algorithm into a program dependence graph, and then performs optimistic transformations on the graph.
Reference: [11] <author> Rick Bubenik and Willy Zwaenepoel. </author> <title> Optimistic Make. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 41(2) </volume> <pages> 207-217, </pages> <month> February </month> <year> 1992. </year>
Reference-contexts: Non-optimistic segments of a program cannot benefit from the optimism of an encapsulation if it does not propagate its results until it is mandated. Bubenik and Zwaenepoel argue their granularity is deliberately large for efficiency reasons <ref> [11] </ref>. 2.2.3 Time Warp Discrete event simulation is a computing application that simulates the behavior of complex systems for the purposes of design and modeling. The number of "events" being simulated 15 in such a system is often very large, and so such simulations may run for a long time.
Reference: [12] <author> F. J. Burkowski, C. L. A. Clarke, Crispin Cowan, and G. J. Vreugdenhil. </author> <title> Architectural Support for Lightweight Tasking in the Sylvan Multiprocessor System. </title> <booktitle> In Symposium on Experience with Distributed and Multiprocessor Systems (SEDMS II), </booktitle> <pages> pages 165-184, </pages> <address> Atlanta, Georgia, </address> <month> March </month> <year> 1991. </year> <pages> 133 134 </pages>
Reference-contexts: HOPE does dependency tracking by marking communications between processes with references to AIDs, and so inter-process communications must be explicit, as is the case in many concurrent and distributed systems <ref> [4, 12, 30, 62] </ref>. Shared memory programming models would be impractical with HOPE, because HOPE dependency tracking operations would have to accompany every shared memory access. Chapter 4 Operational Semantics 1 This chapter defines the formal operational semantics of the HOPE primitives introduced in Chapter 3.
Reference: [13] <author> N. Carriero and D. Gelernter. </author> <title> Linda in Context. </title> <journal> Communications of the ACM, </journal> <volume> 31(4) </volume> <pages> 444-458, </pages> <month> April </month> <year> 1989. </year>
Reference-contexts: Because S 3 changes the line number, S 1 's test is invalidated. The free of (Order) primitive is used to detect this causality violation and force rollbacks to solve the problem. 3.2 Linguistic Assumptions Like Linda <ref> [13] </ref> and Concert [4], HOPE is not a complete programming language. Rather it is a programming model for optimism, embodied as a set of primitives designed to be embedded in some other programming language. There are very few restrictions on the kinds of systems in which HOPE can be embedded.
Reference: [14] <institution> NASA Ames Research Center. Network queueing system. </institution>
Reference-contexts: This appendix describes our checkpoint and rollback facility for UNIX processes. The desired facility is a portable, user-space mechanism for checkpointing the state of a UNIX process in C, and then later rolling the process back to that state. There are numerous checkpoint and restart systems <ref> [7, 14, 34, 43, 67] </ref> for UNIX processes. There are also numerous specific systems that include rollback, but are confined to some specific environment or domain, such as discrete event simulation [22, 31, 65] or transaction processing [53, 56, 66].
Reference: [15] <author> Crispin Cowan. </author> <title> Optimistic Replication in HOPE. </title> <booktitle> In Proceedings of the 1992 CAS Conference, </booktitle> <pages> pages 269-282, </pages> <address> Toronto, Ontario, </address> <month> November </month> <year> 1992. </year>
Reference-contexts: However, it should also be noted that whenever rollback occurs, other rollback-free algorithms would require blocking for an amount of time equal to that spent on wasted computation [31]. 1.2 HOPE: Hopefully Optimistic Programming Environment Optimistic algorithms have been used for fault tolerance [57, 33], replication <ref> [15, 24, 35, 49, 64] </ref>, concurrency control [29, 32, 36, 68], and discrete event simulation [6, 22, 31, 50, 65]. However, the notion of optimism has not been generally exploited because optimistic algorithms are difficult to write. <p> Chapter 7 describes the applicability of HOPE to some problem domains by describing how some of the optimistic algorithms and systems in Chapter 2 can be expressed with HOPE, including optimistic replication as discussed in <ref> [15] </ref>. Chapter 7 also assesses the effectiveness of HOPE by comparing the source code size and runtime characteristics of some example programs written for the HOPE prototype to their pessimistic counterparts. Finally, Chapter 8 presents conclusions and future research opportunities. <p> optimistically assuming that cheap approximations are close enough. 3.1.2 Expected Result HOPE is also applicable to the distributed processing domain, where remote communications latency can be avoided by making optimistic assumptions about the behaviour of remote tasks, such as assuming that a remote database server will grant an access lock <ref> [15] </ref>, or that a remote function will return an expected result [5]. 22 =fl ATM Process fl= aid t pin ok; =fl the assumption ID for the expected result assumption that pin ok = OK fl= pin = get PIN (); pin ok = aid init (); send (WorryWart, pin ok, <p> The full generality of aggressive optimism is necessary for some kinds of applications, such as optimistic replication protocols <ref> [15] </ref> (as discussed in Sections 2.1.2 and 2.1.3). However, aggressive optimism may not always deliver the best performance. To test the performance impact of speculative affirm, the response times of both aggressive and conservative optimistic programs are compared to the response times of the pessimistic programs. <p> As shown in Chapter 2, Call Streaming is not the only kind of optimistic algorithm. In particular, an investigation should be made into the performance of optimistic replication algorithms, which often require speculative affirm primitives to function correctly <ref> [15] </ref>. However, these experiments have shown that the HOPE prototype system can deliver performance gains in program response time for all optimistic assumptions relating to remote operations tested taking more than 2.0 seconds and having a greater than 60% chance of producing the expected result. <p> However, replication often trades reduced read latency for increased write latency <ref> [15] </ref>. Using optimism to maintain consistency among replicas can help to reduce this increase in the latency of writing to replicated objects. HOPE can be of particular assistance by making it feasible to incorporate optimistic object replication directly into an application.
Reference: [16] <author> Crispin Cowan and Hanan Lutfiyya. </author> <title> Formal Semantics for Expressing Optimism. </title> <type> Report 414, </type> <institution> Computer Science Department, </institution> <address> UWO, London, On-tario, </address> <month> March </month> <year> 1994. </year> <note> Submitted for review, and available via FTP from ftp://ftp.csd.uwo.ca/pub/csd-technical-reports/414/report414.ps.Z. </note>
Reference-contexts: Finally, there are numerous studies examining the theoretical properties of various schemes for maintaining consistency in the presence of distributed rollback <ref> [5, 16, 42, 54, 55] </ref>. However, an extensive literature search failed to turn up a general purpose rollback facility for UNIX processes. Systems that actually do process rollback seem always to do so in a restricted domain.
Reference: [17] <author> Crispin Cowan, Hanan Lutfiyya, and Mike Bauer. </author> <title> Increasing Concurrency Through Optimism: A Reason for HOPE. </title> <booktitle> In Proceedings of the 1994 ACM Computer Science Conference, </booktitle> <pages> pages 218-225, </pages> <address> Phoenix, Arizona, </address> <month> March </month> <year> 1994. </year>
Reference-contexts: Chapter 2 Related Work in Optimism 1 This chapter surveys related work in optimism. Such work can be subdivided into optimistic algorithms and optimistic systems. Optimistic algorithms are algorithms that use optimism to meet some specific objective, such as concurrency control or replication control <ref> [17] </ref>. Optimistic systems are programming environments that provide some facility for programmers to make optimistic assumptions.
Reference: [18] <author> J. de Kleer. </author> <title> A Assumption-based Truth Maintenance System. </title> <journal> Artificial Intelligence, </journal> <volume> 28 </volume> <pages> 127-162, </pages> <year> 1986. </year>
Reference-contexts: In the area of artificial intelligence, non-monotonic reasoning is the notion of tentatively drawing a conclusion based on questionable evidence or reasoning, and if the conclusion is later disproved, discarding the conclusion from the knowledge base. Truth Maintenance systems <ref> [18, 19, 20] </ref> do their own management of adding and removing conclusions 112 from the knowledge base.
Reference: [19] <author> J. de Kleer. </author> <title> Extending the ATMS. </title> <journal> Artificial Intelligence, </journal> <volume> 28 </volume> <pages> 163-196, </pages> <year> 1986. </year>
Reference-contexts: In the area of artificial intelligence, non-monotonic reasoning is the notion of tentatively drawing a conclusion based on questionable evidence or reasoning, and if the conclusion is later disproved, discarding the conclusion from the knowledge base. Truth Maintenance systems <ref> [18, 19, 20] </ref> do their own management of adding and removing conclusions 112 from the knowledge base.
Reference: [20] <author> J. Doyle. </author> <title> A Truth Maintenance System. </title> <journal> Artificial Intelligence, </journal> <volume> 12 </volume> <pages> 231-272, </pages> <year> 1979. </year>
Reference-contexts: In the area of artificial intelligence, non-monotonic reasoning is the notion of tentatively drawing a conclusion based on questionable evidence or reasoning, and if the conclusion is later disproved, discarding the conclusion from the knowledge base. Truth Maintenance systems <ref> [18, 19, 20] </ref> do their own management of adding and removing conclusions 112 from the knowledge base.
Reference: [21] <author> A. Ege and C.A. Ellis. </author> <title> Design and Implementation of GORDION, an Object Base Management System. </title> <booktitle> In Procedings of the International Conference on Data Engineering, </booktitle> <pages> pages 226-234, </pages> <address> Los Angeles, California, </address> <month> February 3-5 </month> <year> 1987. </year>
Reference-contexts: Cooperative work is an active new area of study in distributed systems. It is a particular specialization of replication, in which a document is replicated among multiple users who concurrently edit the document. Cooperative editors often use locking schemes to maintain consistency among the replicated documents <ref> [21, 25, 37, 41] </ref>. If the multiple users are geographically removed from one another, locking can impose undesirable amounts of latency on traditionally "simple" edit operations. Optimistic replicated consistency protocols can help reduce this latency. Optimism is often used in hardware fault-tolerant systems to maintain consistency.
Reference: [22] <author> Richard M. Fujimoto. </author> <title> The Virtual Time Machine. </title> <journal> Computer Architecture News, </journal> <volume> 19(1) </volume> <pages> 35-44, </pages> <month> March </month> <year> 1991. </year> <booktitle> Re-printed from the Symposium on Parallel Algorithms and Architectures 1990. </booktitle>
Reference-contexts: rollback-free algorithms would require blocking for an amount of time equal to that spent on wasted computation [31]. 1.2 HOPE: Hopefully Optimistic Programming Environment Optimistic algorithms have been used for fault tolerance [57, 33], replication [15, 24, 35, 49, 64], concurrency control [29, 32, 36, 68], and discrete event simulation <ref> [6, 22, 31, 50, 65] </ref>. However, the notion of optimism has not been generally exploited because optimistic algorithms are difficult to write. Obstacles to optimism include the following: Checkpoint & Rollback This is difficult and non-portable. <p> There are numerous checkpoint and restart systems [7, 14, 34, 43, 67] for UNIX processes. There are also numerous specific systems that include rollback, but are confined to some specific environment or domain, such as discrete event simulation <ref> [22, 31, 65] </ref> or transaction processing [53, 56, 66]. Finally, there are numerous studies examining the theoretical properties of various schemes for maintaining consistency in the presence of distributed rollback [5, 16, 42, 54, 55].
Reference: [23] <author> D. Gifford. </author> <title> Weighted Voting for Replicated Data. </title> <booktitle> In 7th ACM Symposium on Operating System Principles, </booktitle> <pages> pages 150-162, </pages> <year> 1979. </year>
Reference-contexts: The second assumption is that a lock acquired only at the leader site will be granted by a quorum of other replica sites. Thus, Triantafillou is using the conventional techniques of a location service and quorum consensus <ref> [23] </ref>, but is enhancing them by using optimism to execute these functions asynchronously. The location-based algorithm proceeds as follows: clients processing transactions begin by asking the location service for a list of up-to-date replicas of each object desired (the granularity of objects is not discussed).
Reference: [24] <author> Arthur P. Goldberg. </author> <title> Optimistic Algorithms for Distributed Transparent Process Replication. </title> <type> PhD thesis, </type> <institution> University of California at Los Angeles, </institution> <year> 1991. </year> <note> (UCLA Tech. Report CSD-910050). </note>
Reference-contexts: However, it should also be noted that whenever rollback occurs, other rollback-free algorithms would require blocking for an amount of time equal to that spent on wasted computation [31]. 1.2 HOPE: Hopefully Optimistic Programming Environment Optimistic algorithms have been used for fault tolerance [57, 33], replication <ref> [15, 24, 35, 49, 64] </ref>, concurrency control [29, 32, 36, 68], and discrete event simulation [6, 22, 31, 50, 65]. However, the notion of optimism has not been generally exploited because optimistic algorithms are difficult to write. <p> In the rare event that a failure or recovery has occurred, the client issues a write to the logically centralized location service updating the list of up-to-date replicas. 2.1.3 Goldberg's Optimistic Process Replication In <ref> [24] </ref> Goldberg describes several mechanisms to transparently support process replication. Replicated processes appear to function identically to a single, un-replicated process, but provide lower latency for read and non-conflicting write operations.
Reference: [25] <author> I. Greif, R. Seliger, and W. Weihl. </author> <title> Atomic Data Abstractions in a Distributed collaborative Editing System. </title> <booktitle> In 13th Annual ACM Symp. on Principles of Programming Languages, </booktitle> <pages> pages 160-172, </pages> <month> January 13-15 </month> <year> 1986. </year>
Reference-contexts: Cooperative work is an active new area of study in distributed systems. It is a particular specialization of replication, in which a document is replicated among multiple users who concurrently edit the document. Cooperative editors often use locking schemes to maintain consistency among the replicated documents <ref> [21, 25, 37, 41] </ref>. If the multiple users are geographically removed from one another, locking can impose undesirable amounts of latency on traditionally "simple" edit operations. Optimistic replicated consistency protocols can help reduce this latency. Optimism is often used in hardware fault-tolerant systems to maintain consistency.
Reference: [26] <author> Anurag Gupta, Ian F. Akyildiz, and Richard M. Fujimoto. </author> <title> Performance Analysis of Time Warp with Multiple Homogeneous Processors. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 17(10) </volume> <pages> 1013-1027, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: Optimistically assuming that such a contributing factor does not exist increases available parallelism. Jefferson's Virtual Time [31] is an algorithm for distributed process synchronization that has been widely studied <ref> [1, 26, 32, 42, 55] </ref>.
Reference: [27] <author> Reed Hastings and Bob Joyce. Purify: </author> <title> Fast Detection of Memory Leaks and Access Errors. </title> <booktitle> In Proceedings of the Winter USENIX Conference, </booktitle> <year> 1992. </year>
Reference-contexts: Debuggers invariably store some of their debugging information in the user process's address space. Hence a buggy rollback mechanism can corrupt the debugging structures as well. Some debugging tools such as Purify <ref> [27] </ref> go to considerable effort to avoid this problem by mapping in their debugging structures in the middle of the address space, well away from the stack and data areas. As a result, the debugging information is not rolled back with the rest of the process. <p> We spent considerable effort examining all aspects of the checkpoint and rollback system, the buffered I/O exemption system, as well as the application being tested. We were searching for flaws that could cause corruption of malloc's data structures. We applied the most powerful malloc debugging tools we could find <ref> [27] </ref>, to no avail; the problem always vanished in the presence of malloc debuggers. While trying to symbolically trace the precise location of the corruption, it was only accidentally discovered that alternative malloc libraries did not manifest the problem, and that the solution was to replace SunOS's malloc.
Reference: [28] <author> Matthew Hennessy. </author> <title> The Semantics of Programming Languages. </title> <publisher> John Wiley & Sons Ltd., </publisher> <address> Baffins Lane, Chichester West Sussex PO19 1UD, England, first edition, </address> <year> 1990. </year>
Reference-contexts: The machine interprets a program by passing through a sequence of discrete states. This approach requires that the structure of states and the allowable transitions from one state to another be specifically defined. We did not use any of the various metalanguages <ref> [28, 45] </ref> for describing the semantics of programming languages, regarding them as inadequate for our use for the following reasons. First, some of the metalanguages are for sequential languages. Second, most are state-based in the sense that the only thing defined is allowable transitions from one state to another.
Reference: [29] <author> Maurice Herlihy. </author> <title> Apologizing Versus Asking Permission: Optimistic Concurrency Control for Abstract Data Types. </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 15(1) </volume> <pages> 96-124, </pages> <month> March </month> <year> 1990. </year> <month> 135 </month>
Reference-contexts: also be noted that whenever rollback occurs, other rollback-free algorithms would require blocking for an amount of time equal to that spent on wasted computation [31]. 1.2 HOPE: Hopefully Optimistic Programming Environment Optimistic algorithms have been used for fault tolerance [57, 33], replication [15, 24, 35, 49, 64], concurrency control <ref> [29, 32, 36, 68] </ref>, and discrete event simulation [6, 22, 31, 50, 65]. However, the notion of optimism has not been generally exploited because optimistic algorithms are difficult to write. Obstacles to optimism include the following: Checkpoint & Rollback This is difficult and non-portable. <p> Since many optimistic concurrency control algorithms have been published <ref> [29, 32, 68] </ref>, we do not attempt to discuss them all, and instead present only a sample: Kung & Robinson's optimistic concurrency control, and Triantafillou and Taylor's optimistic replicated concurrency control. 2.1.1 Kung and Robinson's Optimistic Concurrency Control Concurrency control is the problem of scheduling concurrent operations in such a way <p> Serializable executions can be achieved by applying one of many concurrency control algorithms <ref> [8, 29, 32, 36, 68] </ref> to the execution of HOPE primitives. However, the time and space requirements of incorporating a general concurrency control system within the HOPE run-time are prohibitive.
Reference: [30] <author> International Standards Orgainzation. </author> <title> Ada 9X Reference Manual (ANSI/ISO DIS 8652 Draft International Standard). Intermetrics, </title> <publisher> Inc., </publisher> <address> Cambridge, Massaachusetts, </address> <month> June </month> <year> 1994. </year>
Reference-contexts: HOPE does dependency tracking by marking communications between processes with references to AIDs, and so inter-process communications must be explicit, as is the case in many concurrent and distributed systems <ref> [4, 12, 30, 62] </ref>. Shared memory programming models would be impractical with HOPE, because HOPE dependency tracking operations would have to accompany every shared memory access. Chapter 4 Operational Semantics 1 This chapter defines the formal operational semantics of the HOPE primitives introduced in Chapter 3.
Reference: [31] <author> D. Jefferson. </author> <title> Virtual Time. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 3(7) </volume> <pages> 404-425, </pages> <month> July </month> <year> 1985. </year>
Reference-contexts: However, it should also be noted that whenever rollback occurs, other rollback-free algorithms would require blocking for an amount of time equal to that spent on wasted computation <ref> [31] </ref>. 1.2 HOPE: Hopefully Optimistic Programming Environment Optimistic algorithms have been used for fault tolerance [57, 33], replication [15, 24, 35, 49, 64], concurrency control [29, 32, 36, 68], and discrete event simulation [6, 22, 31, 50, 65]. <p> rollback-free algorithms would require blocking for an amount of time equal to that spent on wasted computation [31]. 1.2 HOPE: Hopefully Optimistic Programming Environment Optimistic algorithms have been used for fault tolerance [57, 33], replication [15, 24, 35, 49, 64], concurrency control [29, 32, 36, 68], and discrete event simulation <ref> [6, 22, 31, 50, 65] </ref>. However, the notion of optimism has not been generally exploited because optimistic algorithms are difficult to write. Obstacles to optimism include the following: Checkpoint & Rollback This is difficult and non-portable. <p> Replicated processes appear to function identically to a single, un-replicated process, but provide lower latency for read and non-conflicting write operations. Goldberg presents one mechanism layered on top of Jefferson's Virtual Time <ref> [31] </ref>, a second mechanism integrated with Virtual Time, and a third mechanism based loosely on the dependency tracking mechanisms of Strom and Yemini's Optimistic Recovery [57]. Goldberg assumes that processes communicate only with messages. <p> Optimistically assuming that such a contributing factor does not exist increases available parallelism. Jefferson's Virtual Time <ref> [31] </ref> is an algorithm for distributed process synchronization that has been widely studied [1, 26, 32, 42, 55]. <p> It is a theorem due to Jefferson <ref> [31] </ref> that the amount of time "wasted" on speculative computations based on incorrect optimistic assumptions would have been spent blocked waiting for results in a pessimistic program. The only penalty for using optimism is 103 the extra time required to perform checkpointing, dependency tracking, and rollback. <p> There are numerous checkpoint and restart systems [7, 14, 34, 43, 67] for UNIX processes. There are also numerous specific systems that include rollback, but are confined to some specific environment or domain, such as discrete event simulation <ref> [22, 31, 65] </ref> or transaction processing [53, 56, 66]. Finally, there are numerous studies examining the theoretical properties of various schemes for maintaining consistency in the presence of distributed rollback [5, 16, 42, 54, 55].
Reference: [32] <author> D. Jefferson and A. Motro. </author> <title> The Time Warp Mechanism for Database Concurrency Control. </title> <type> Report Technical Report TR-84-302, </type> <institution> University of Southern California, </institution> <month> Jan-uary </month> <year> 1984. </year>
Reference-contexts: also be noted that whenever rollback occurs, other rollback-free algorithms would require blocking for an amount of time equal to that spent on wasted computation [31]. 1.2 HOPE: Hopefully Optimistic Programming Environment Optimistic algorithms have been used for fault tolerance [57, 33], replication [15, 24, 35, 49, 64], concurrency control <ref> [29, 32, 36, 68] </ref>, and discrete event simulation [6, 22, 31, 50, 65]. However, the notion of optimism has not been generally exploited because optimistic algorithms are difficult to write. Obstacles to optimism include the following: Checkpoint & Rollback This is difficult and non-portable. <p> Since many optimistic concurrency control algorithms have been published <ref> [29, 32, 68] </ref>, we do not attempt to discuss them all, and instead present only a sample: Kung & Robinson's optimistic concurrency control, and Triantafillou and Taylor's optimistic replicated concurrency control. 2.1.1 Kung and Robinson's Optimistic Concurrency Control Concurrency control is the problem of scheduling concurrent operations in such a way <p> Optimistically assuming that such a contributing factor does not exist increases available parallelism. Jefferson's Virtual Time [31] is an algorithm for distributed process synchronization that has been widely studied <ref> [1, 26, 32, 42, 55] </ref>. <p> Serializable executions can be achieved by applying one of many concurrency control algorithms <ref> [8, 29, 32, 36, 68] </ref> to the execution of HOPE primitives. However, the time and space requirements of incorporating a general concurrency control system within the HOPE run-time are prohibitive.
Reference: [33] <author> D.B. Johnson and W. Zwaenepoel. </author> <title> Recovery in Distributed Systems using Optimistic Message Logging and Checkpointing. </title> <journal> J. Algorithms, </journal> <volume> 11(3) </volume> <pages> 462-491, </pages> <month> September </month> <year> 1990. </year>
Reference-contexts: However, it should also be noted that whenever rollback occurs, other rollback-free algorithms would require blocking for an amount of time equal to that spent on wasted computation [31]. 1.2 HOPE: Hopefully Optimistic Programming Environment Optimistic algorithms have been used for fault tolerance <ref> [57, 33] </ref>, replication [15, 24, 35, 49, 64], concurrency control [29, 32, 36, 68], and discrete event simulation [6, 22, 31, 50, 65]. However, the notion of optimism has not been generally exploited because optimistic algorithms are difficult to write.
Reference: [34] <author> Brent A. Kingsbury and John T. Kline. </author> <title> Job and Process Recovery in a UNIX-based Operating System. </title> <booktitle> In Proceedings of the Winter USENIX Conference, </booktitle> <pages> pages 355-364, </pages> <year> 1989. </year>
Reference-contexts: This appendix describes our checkpoint and rollback facility for UNIX processes. The desired facility is a portable, user-space mechanism for checkpointing the state of a UNIX process in C, and then later rolling the process back to that state. There are numerous checkpoint and restart systems <ref> [7, 14, 34, 43, 67] </ref> for UNIX processes. There are also numerous specific systems that include rollback, but are confined to some specific environment or domain, such as discrete event simulation [22, 31, 65] or transaction processing [53, 56, 66]. <p> To be suitable as a basis, the checkpoint mechanism should be portable, it must leave the process running, the source code must be available and the restart mechanism must be adaptable to an already running process. Kingsbury and Kline <ref> [34] </ref> describe the effort at Cray Research to add a checkpoint and restart facility to their UNICOS variant of UNIX. While highly sophisticated and robust, UNICOS is also commercial software bound to a specific platform; this is not suitable. <p> The only way to recover the state of the external process is to force it also to roll back. Such a strategy requires either a globally consistent snapshot <ref> [34, 40] </ref>, or a dependency tracking scheme such as HOPE. If the external entity is a device, such as a tty, then write operations can only be rolled back with specific knowledge of what the operation was and the device's resultant behavior.
Reference: [35] <author> Puneet Kumar. </author> <title> Coping with Conflicts in an Optimistically Replicated File System. </title> <booktitle> In 1990 Workshop on the Management of Replicated Data, </booktitle> <pages> pages 60-64, </pages> <address> Houston, TX, </address> <month> November </month> <year> 1990. </year>
Reference-contexts: However, it should also be noted that whenever rollback occurs, other rollback-free algorithms would require blocking for an amount of time equal to that spent on wasted computation [31]. 1.2 HOPE: Hopefully Optimistic Programming Environment Optimistic algorithms have been used for fault tolerance [57, 33], replication <ref> [15, 24, 35, 49, 64] </ref>, concurrency control [29, 32, 36, 68], and discrete event simulation [6, 22, 31, 50, 65]. However, the notion of optimism has not been generally exploited because optimistic algorithms are difficult to write.
Reference: [36] <author> H.T. Kung and John T. Robinson. </author> <title> On Optimistic Methods for Concurrency Control. </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 6(2) </volume> <pages> 213-226, </pages> <month> June </month> <year> 1981. </year>
Reference-contexts: also be noted that whenever rollback occurs, other rollback-free algorithms would require blocking for an amount of time equal to that spent on wasted computation [31]. 1.2 HOPE: Hopefully Optimistic Programming Environment Optimistic algorithms have been used for fault tolerance [57, 33], replication [15, 24, 35, 49, 64], concurrency control <ref> [29, 32, 36, 68] </ref>, and discrete event simulation [6, 22, 31, 50, 65]. However, the notion of optimism has not been generally exploited because optimistic algorithms are difficult to write. Obstacles to optimism include the following: Checkpoint & Rollback This is difficult and non-portable. <p> A conservative approach to scheduling would be to look at each operation, and try to find a schedule that will not force any of the operations to roll back. However, there are 1 A reason for HOPE. 8 9 no deadlock-free conservative protocols that always provide high concurrency <ref> [36] </ref>. Thus the problem of finding a schedule forms a serial bottleneck to the concurrent execution of operations on shared data. Kung and Robinson's Optimistic Concurrency Control [36] is an optimistic algorithm for scheduling concurrent transactions. <p> However, there are 1 A reason for HOPE. 8 9 no deadlock-free conservative protocols that always provide high concurrency <ref> [36] </ref>. Thus the problem of finding a schedule forms a serial bottleneck to the concurrent execution of operations on shared data. Kung and Robinson's Optimistic Concurrency Control [36] is an optimistic algorithm for scheduling concurrent transactions. <p> Serializable executions can be achieved by applying one of many concurrency control algorithms <ref> [8, 29, 32, 36, 68] </ref> to the execution of HOPE primitives. However, the time and space requirements of incorporating a general concurrency control system within the HOPE run-time are prohibitive.
Reference: [37] <author> L. Lamont, G. Henderson, </author> <title> and N.D. Georgannas. A Multimedia Real-time Conferencing System: </title> <booktitle> Architecture and Implementation. In Proceedings of the 1993 CAS Conference, </booktitle> <pages> pages 64-71, </pages> <address> Toronto, Ontario, </address> <month> October </month> <year> 1993. </year>
Reference-contexts: Cooperative work is an active new area of study in distributed systems. It is a particular specialization of replication, in which a document is replicated among multiple users who concurrently edit the document. Cooperative editors often use locking schemes to maintain consistency among the replicated documents <ref> [21, 25, 37, 41] </ref>. If the multiple users are geographically removed from one another, locking can impose undesirable amounts of latency on traditionally "simple" edit operations. Optimistic replicated consistency protocols can help reduce this latency. Optimism is often used in hardware fault-tolerant systems to maintain consistency.
Reference: [38] <author> Leslie Lamport. </author> <title> Time, Clocks, and the Ordering of Events in a Distributed System. </title> <journal> Communications of the ACM, </journal> <volume> 21(7) </volume> <pages> 558-565, </pages> <month> July </month> <year> 1978. </year>
Reference-contexts: Time Warp is a discrete event simulation system based on the Virtual Time concept that provides the illusion of a globally synchronized clock that can be used to preserve a total ordering across the system as defined by Lamport <ref> [38] </ref>, even though processes actually are being executed out of order. Thus the semantics that it guarantees are those of a sequentially executed series of computations.
Reference: [39] <author> Jonathan I. Leivent and Ronald J. Watro. </author> <title> Mathematical Foundations for Time Warp Systems. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 15(5) </volume> <pages> 771-794, </pages> <month> November </month> <year> 1993. </year>
Reference-contexts: Rare as optimistic systems are, formally defined optimistic systems are even more scarce: HOPE is one of the first formally specified systems for expressing optimism <ref> [39] </ref>.
Reference: [40] <author> Juan Leon. </author> <title> Fail-Safe PVM. </title> <type> TR CMU-CS-93-124, </type> <institution> Carnegie Mellon University, School of Computer Science, </institution> <address> Pittsburgh, PA, </address> <year> 1993. </year>
Reference-contexts: The only way to recover the state of the external process is to force it also to roll back. Such a strategy requires either a globally consistent snapshot <ref> [34, 40] </ref>, or a dependency tracking scheme such as HOPE. If the external entity is a device, such as a tty, then write operations can only be rolled back with specific knowledge of what the operation was and the device's resultant behavior.
Reference: [41] <author> B.T. Lewis and J.D. Hodges. </author> <title> Shared Books: Collaborative Publications Management for an Office Information System. </title> <booktitle> In Procedings of the Conference on Office Information Systems, </booktitle> <pages> pages 197-204, </pages> <address> Palo Alto, California, </address> <month> March 23-25 </month> <year> 1988. </year>
Reference-contexts: Cooperative work is an active new area of study in distributed systems. It is a particular specialization of replication, in which a document is replicated among multiple users who concurrently edit the document. Cooperative editors often use locking schemes to maintain consistency among the replicated documents <ref> [21, 25, 37, 41] </ref>. If the multiple users are geographically removed from one another, locking can impose undesirable amounts of latency on traditionally "simple" edit operations. Optimistic replicated consistency protocols can help reduce this latency. Optimism is often used in hardware fault-tolerant systems to maintain consistency.
Reference: [42] <author> Yi-Bing Lin and Edward D. Lazowska. </author> <title> Optimality Considerations of the `Time Warp' Parallel Simulation. </title> <booktitle> In Proceedings of the SCS Multiconference on Distributed Simulation, </booktitle> <pages> pages 29-34, </pages> <address> San Diego, CA, </address> <month> January </month> <year> 1990. </year>
Reference-contexts: Optimistically assuming that such a contributing factor does not exist increases available parallelism. Jefferson's Virtual Time [31] is an algorithm for distributed process synchronization that has been widely studied <ref> [1, 26, 32, 42, 55] </ref>. <p> Finally, there are numerous studies examining the theoretical properties of various schemes for maintaining consistency in the presence of distributed rollback <ref> [5, 16, 42, 54, 55] </ref>. However, an extensive literature search failed to turn up a general purpose rollback facility for UNIX processes. Systems that actually do process rollback seem always to do so in a restricted domain.
Reference: [43] <author> Michael Litzkow and Marvin Solomon. </author> <title> Supporting Checkpointing and Process Migration Outside the UNIX Kernel. </title> <booktitle> In Proceedings of the Winter USENIX Conference, </booktitle> <year> 1992. </year>
Reference-contexts: This appendix describes our checkpoint and rollback facility for UNIX processes. The desired facility is a portable, user-space mechanism for checkpointing the state of a UNIX process in C, and then later rolling the process back to that state. There are numerous checkpoint and restart systems <ref> [7, 14, 34, 43, 67] </ref> for UNIX processes. There are also numerous specific systems that include rollback, but are confined to some specific environment or domain, such as discrete event simulation [22, 31, 65] or transaction processing [53, 56, 66]. <p> Kingsbury and Kline [34] describe the effort at Cray Research to add a checkpoint and restart facility to their UNICOS variant of UNIX. While highly sophisticated and robust, UNICOS is also commercial software bound to a specific platform; this is not suitable. Condor <ref> [43] </ref> is a resource management system that implements process migration, necessitating process checkpoint and restart. Unfortunately, Condor's checkpoint mechanism, a special signal causing the process to dump core, terminates the process, and so it is not suitable for rollback.
Reference: [44] <author> Hanan Lutfiyya and Crispin Cowan. </author> <title> The Application-Oriented Fault Tolerance Paradigm with Rollback. </title> <note> To be submitted for review. 136 </note>
Reference-contexts: However, the time required to verify some executable assertions may be prohibitive. Replacing an executable assertion with a HOPE guess, and concurrently executing the assertion to validate the optimistic assumption can avoid imposing this latency on the application <ref> [44] </ref>. Automatic transformation of pessimistic programs into optimistic programs is an attractive notion because pessimistic programs are easier for programmers to reason about and understand. Both Strom et al. [5, 59], and Bubenik [9] have studied the prospect of automatically optimistic transformation.
Reference: [45] <author> M. Marcotty, H.F. Ledgard, and G.V. Bochmann. </author> <title> A Sampler of Formal Definitions. </title> <journal> Computing Surveys, </journal> <volume> 8(2) </volume> <pages> 191-276, </pages> <year> 1976. </year>
Reference-contexts: The machine interprets a program by passing through a sequence of discrete states. This approach requires that the structure of states and the allowable transitions from one state to another be specifically defined. We did not use any of the various metalanguages <ref> [28, 45] </ref> for describing the semantics of programming languages, regarding them as inadequate for our use for the following reasons. First, some of the metalanguages are for sequential languages. Second, most are state-based in the sense that the only thing defined is allowable transitions from one state to another.
Reference: [46] <author> Sun Microsystems. </author> <title> TMPFS Memory Based File System. section 4 of the SunOS 4.1 manual. </title>
Reference-contexts: The checkpointing technique used (save the entire stack, heap, and static data area to disk) works, but is very expensive: Checkpointing a sample 250 KB process takes 20 94 milliseconds to a RAM disk <ref> [46] </ref>, and 300 milliseconds to a remote physical disk across a 10 MBit Ethernet. More efficient methods, such as message logging [57] could be used to greatly reduce the cost of checkpointing. The potential for using compiler-driven checkpointing schemes also remains unexplored.
Reference: [47] <author> C. Papadimitriou. </author> <title> The Serializability of Concurrent Updates. </title> <journal> Journal of the ACM, </journal> <volume> 24(4) </volume> <pages> 631-653, </pages> <month> October </month> <year> 1979. </year>
Reference-contexts: Such a schedule is called serializable <ref> [47] </ref>. However, it is possible to schedule such operations concurrently, so that non-interfering operations are executed in parallel. A conservative approach to scheduling would be to look at each operation, and try to find a schedule that will not force any of the operations to roll back.
Reference: [48] <author> J. Peterson and A. Silberschatz. </author> <title> Operating System Concepts. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Massachusetts, </address> <year> 1983. </year>
Reference-contexts: Often, latency can be reduced by executing operations in parallel. Executing operations in parallel may reduce the overall response time of an application: Definition 1.2 Response time is the time from the submission of a user request until the first response is produced <ref> [48, pages 115-6] </ref>. Naturally, the response time is of interest only if there is a user waiting for the response. There are limits to the effectiveness of reducing response time through parallelism. <p> Many techniques have been developed to hide or work around latency. The notion of multiprogramming was first invented to hide the latency of slow I/O devices to get more throughput from expensive CPU's <ref> [48, page 19] </ref>. Multiprogramming is a traditional way to hide latency from a computer by using parallelism among applications. Parallel programming is a more aggressive way to overcome latency by executing components of an application in parallel.
Reference: [49] <author> Gerald J. Popek, Richard G. Guy, Jr. Thomas W. Page, and John S. Heidemann. </author> <title> Replication in Ficus Distribued Files Systems. </title> <booktitle> In 1990 Workshop on the Management of Replicated Data, </booktitle> <pages> pages 5-10, </pages> <address> Houston, TX, </address> <month> November </month> <year> 1990. </year>
Reference-contexts: However, it should also be noted that whenever rollback occurs, other rollback-free algorithms would require blocking for an amount of time equal to that spent on wasted computation [31]. 1.2 HOPE: Hopefully Optimistic Programming Environment Optimistic algorithms have been used for fault tolerance [57, 33], replication <ref> [15, 24, 35, 49, 64] </ref>, concurrency control [29, 32, 36, 68], and discrete event simulation [6, 22, 31, 50, 65]. However, the notion of optimism has not been generally exploited because optimistic algorithms are difficult to write.
Reference: [50] <author> B. R. Preiss, W. M. Loucks, and V. C. Hamacher. </author> <title> A Unified Modelling Methodology for Performance Evaluation of Distributed Discrete Event Simulation Mechanisms. </title> <booktitle> In Winter Simulation Conference, </booktitle> <year> 1988. </year>
Reference-contexts: rollback-free algorithms would require blocking for an amount of time equal to that spent on wasted computation [31]. 1.2 HOPE: Hopefully Optimistic Programming Environment Optimistic algorithms have been used for fault tolerance [57, 33], replication [15, 24, 35, 49, 64], concurrency control [29, 32, 36, 68], and discrete event simulation <ref> [6, 22, 31, 50, 65] </ref>. However, the notion of optimism has not been generally exploited because optimistic algorithms are difficult to write. Obstacles to optimism include the following: Checkpoint & Rollback This is difficult and non-portable.
Reference: [51] <author> Jim Pruyne. </author> <title> Process Checkpointing. </title> <type> Personal Communications, </type> <month> May </month> <year> 1994. </year> <institution> University of Wisconsin, Madison. </institution>
Reference-contexts: Unfortunately, Condor's checkpoint mechanism, a special signal causing the process to dump core, terminates the process, and so it is not suitable for rollback. Recently, the Condor project has undertaken to create a new checkpointing mechanism that does not kill the process <ref> [51] </ref>, but details are not available at this time. Yee's Save World [67] and Bernstein's Pmckpt [7] are similar to one another, in that they are small libraries of portable software that provide rudimentary process checkpoint and restart.
Reference: [52] <author> William Pugh. </author> <title> Skip Lists: A Probabilistic Alternative to Balanced Trees. </title> <journal> Communications of the ACM, </journal> <volume> 33(6), </volume> <month> June </month> <year> 1990. </year>
Reference-contexts: The potential for using compiler-driven checkpointing schemes also remains unexplored. The data structures used to implement the dependency tracking sets are less than optimal. Numerous sites in the code have been commented with the string "OPTIMIZE" where obvious optimizations could be introduced, such as using a logarithmic data structure <ref> [52] </ref> instead of the simple linear linked lists that were used. However, since the current system performance is dominated by the time required to take checkpoints, spawn processes, and exchange messages, the time required for set processing does not as yet affect system performance.
Reference: [53] <author> Erhard Rahm and Alexander Thomasian. </author> <title> Distributed Optimistic Concurrency control for High Performance Transaction Processing. </title> <booktitle> In International Conference on Databases, Parallel Architectures, and their Applications (PARBASE-90), </booktitle> <pages> pages 490-495, </pages> <month> March </month> <year> 1990. </year>
Reference-contexts: There are numerous checkpoint and restart systems [7, 14, 34, 43, 67] for UNIX processes. There are also numerous specific systems that include rollback, but are confined to some specific environment or domain, such as discrete event simulation [22, 31, 65] or transaction processing <ref> [53, 56, 66] </ref>. Finally, there are numerous studies examining the theoretical properties of various schemes for maintaining consistency in the presence of distributed rollback [5, 16, 42, 54, 55]. However, an extensive literature search failed to turn up a general purpose rollback facility for UNIX processes.
Reference: [54] <author> Parameswaran Ramanathan and Kang G. Shin. </author> <title> Use of Common Time Base for Check-pointing and Rollback Recovery in a Distributed System. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 19(6) </volume> <pages> 571-583, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: Finally, there are numerous studies examining the theoretical properties of various schemes for maintaining consistency in the presence of distributed rollback <ref> [5, 16, 42, 54, 55] </ref>. However, an extensive literature search failed to turn up a general purpose rollback facility for UNIX processes. Systems that actually do process rollback seem always to do so in a restricted domain.
Reference: [55] <author> Peter Reiher, Richard Fujimoto, Steven Bellenot, and David Jefferson. </author> <title> Cancellation Strategies in Optimistic Execution Systems. </title> <booktitle> In Proceedings of the SCS Multiconference on Distributed Simulation, </booktitle> <pages> pages 112-121, </pages> <address> San Diego, CA, </address> <month> January </month> <year> 1990. </year>
Reference-contexts: Optimistically assuming that such a contributing factor does not exist increases available parallelism. Jefferson's Virtual Time [31] is an algorithm for distributed process synchronization that has been widely studied <ref> [1, 26, 32, 42, 55] </ref>. <p> Finally, there are numerous studies examining the theoretical properties of various schemes for maintaining consistency in the presence of distributed rollback <ref> [5, 16, 42, 54, 55] </ref>. However, an extensive literature search failed to turn up a general purpose rollback facility for UNIX processes. Systems that actually do process rollback seem always to do so in a restricted domain.
Reference: [56] <author> A. S. Spector, J. L. Eppinger, D. S. Daniels, J. J. Block R. Draves, D. Duchamp, R. F. Paush, and D. Thompson. </author> <title> High Performance Distributed Transaction Processing in a General Purpose Computing Environment. </title> <type> Report, </type> <institution> Computer Science Department, </institution> <address> CMU, Pitsburgh, PA, </address> <month> September </month> <year> 1987. </year>
Reference-contexts: There are numerous checkpoint and restart systems [7, 14, 34, 43, 67] for UNIX processes. There are also numerous specific systems that include rollback, but are confined to some specific environment or domain, such as discrete event simulation [22, 31, 65] or transaction processing <ref> [53, 56, 66] </ref>. Finally, there are numerous studies examining the theoretical properties of various schemes for maintaining consistency in the presence of distributed rollback [5, 16, 42, 54, 55]. However, an extensive literature search failed to turn up a general purpose rollback facility for UNIX processes.
Reference: [57] <author> R.E. Strom and S. Yemini. </author> <title> Optimistic Recovery in Distributed Systems. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 3(3) </volume> <pages> 204-226, </pages> <month> August </month> <year> 1985. </year>
Reference-contexts: However, it should also be noted that whenever rollback occurs, other rollback-free algorithms would require blocking for an amount of time equal to that spent on wasted computation [31]. 1.2 HOPE: Hopefully Optimistic Programming Environment Optimistic algorithms have been used for fault tolerance <ref> [57, 33] </ref>, replication [15, 24, 35, 49, 64], concurrency control [29, 32, 36, 68], and discrete event simulation [6, 22, 31, 50, 65]. However, the notion of optimism has not been generally exploited because optimistic algorithms are difficult to write. <p> Goldberg presents one mechanism layered on top of Jefferson's Virtual Time [31], a second mechanism integrated with Virtual Time, and a third mechanism based loosely on the dependency tracking mechanisms of Strom and Yemini's Optimistic Recovery <ref> [57] </ref>. Goldberg assumes that processes communicate only with messages. He further partitions messages into write messages (those that change the recipient's state) and read messages (those that do not) 2 . <p> However, waiting for writes to stable storage introduces large amounts of latency because I/O devices are very slow parts of a computing system. Better performance is obtained by executing I/O operations concurrent with subsequent computations. Strom and Yemini <ref> [57] </ref> present a system for high performance fault-tolerant distributed computing based on the optimistic notion that computers mostly do not fail. <p> Any node's state that depends on a previous state that was lost due to failure is called an orphan, and is discarded and re-computed. The semantics presented is that of reliable, persistent processes that run transparently on unreliable computing nodes. In <ref> [57] </ref> Strom and Yemini present a system for high-performance fault-tolerant distributed computing based on the optimistic notion that computers mostly do not fail. <p> argument) is evaluated at the end of the speculative if or while block, and the computation is either retained or rolled back at that point. 2.2.2 Bubenik's Optimistic Computation In [9, 10], Bubenik et al. describe a formalism for automatically transforming pessimistic algorithms into optimistic algorithms based on concepts in <ref> [57, 59] </ref>. Bubenik translates the algorithm into a program dependence graph, and then performs optimistic transformations on the graph. Bubenik also constructed an optimistic run-time environment in which to exercise these transformations. Bubenik's optimistic facility is somewhat more dynamic than Strothotte's, but less dynamic than HOPE. <p> More efficient methods, such as message logging <ref> [57] </ref> could be used to greatly reduce the cost of checkpointing. The potential for using compiler-driven checkpointing schemes also remains unexplored. The data structures used to implement the dependency tracking sets are less than optimal.
Reference: [58] <author> Rob Strom. </author> <title> The Need For Optimism in Hermes. </title> <type> Personal Communications, </type> <month> August </month> <year> 1991. </year>
Reference-contexts: Checkpointing mechanisms often assume that they must transparently work with arbitrary programs. However, since HOPE programs already have been enhanced at 110 the source-code level to include the use of HOPE primitives, it is possible to introduce compiler driven checkpointing mechanisms <ref> [58] </ref>. A compiler has enough information to determine what aspects of a process's state have potentially changed between checkpoints. Instead of checkpointing the entire state of the process, a compiler driven checkpoint mechanism can save only those aspects of the state that have changed.
Reference: [59] <author> Rob Strom and Shaula Yemini. </author> <title> Synthesizing Distributed and Parallel Programs through Optimistic Transformations. </title> <editor> In Y. Yemini, editor, </editor> <booktitle> Current Advances in Dis-trubuted Computing and Communications, </booktitle> <pages> pages 234-256. </pages> <publisher> Computer Science Press, </publisher> <address> Rockville, MD, </address> <year> 1987. </year> <month> 137 </month>
Reference-contexts: Improved performance depends on the probability of the assumption being correct, the costs of rolling back computations, and the fixed costs of making rollback of computations possible <ref> [59] </ref>. <p> argument) is evaluated at the end of the speculative if or while block, and the computation is either retained or rolled back at that point. 2.2.2 Bubenik's Optimistic Computation In [9, 10], Bubenik et al. describe a formalism for automatically transforming pessimistic algorithms into optimistic algorithms based on concepts in <ref> [57, 59] </ref>. Bubenik translates the algorithm into a program dependence graph, and then performs optimistic transformations on the graph. Bubenik also constructed an optimistic run-time environment in which to exercise these transformations. Bubenik's optimistic facility is somewhat more dynamic than Strothotte's, but less dynamic than HOPE. <p> Section 3.1 illustrates the meaning of the HOPE primitives by presenting some example HOPE programs. Section 3.2 describes necessary and desirable language features for embedding HOPE in other languages. 3.1 Examples This section illustrates the meaning of the HOPE primitives by presenting two optimistic program transformations <ref> [59] </ref>. An optimistic transformation is a transformation of a pessimistic (conventional) program into an equivalent program that uses optimism. Two programs are presented in each example: an optimistic program, and a pessimistic (conventional) program. <p> Automatic transformation of pessimistic programs into optimistic programs is an attractive notion because pessimistic programs are easier for programmers to reason about and understand. Both Strom et al. <ref> [5, 59] </ref>, and Bubenik [9] have studied the prospect of automatically optimistic transformation. However, Strom did not have an environment for executing optimistic programs, and so did no experimental work.
Reference: [60] <author> Thomas Strothotte. </author> <title> Temporal Constructs for an Algorithmic Language. </title> <type> PhD thesis, </type> <institution> McGill University, </institution> <year> 1984. </year>
Reference-contexts: To overcome these obstacles and make optimism more attractive to developers and researchers, the rollback and bookkeeping tasks of optimism must be automated. In this section, we review several previous efforts to automate parts of optimism. 2.2.1 Strothotte's Temporal Language Constructs In <ref> [60, 61] </ref> Strothotte describes three classes of programming language constructs for expressing temporal notions in a program: those for the past tense, the future tense, and the subjunctive tense.
Reference: [61] <author> Thomas Strothotte. </author> <title> Temporal Constructs for an Algorithmic Language. </title> <type> Report SOCS-84.20, </type> <institution> McGill University, </institution> <address> Montreal, Quebec, </address> <month> December </month> <year> 1984. </year>
Reference-contexts: To overcome these obstacles and make optimism more attractive to developers and researchers, the rollback and bookkeeping tasks of optimism must be automated. In this section, we review several previous efforts to automate parts of optimism. 2.2.1 Strothotte's Temporal Language Constructs In <ref> [60, 61] </ref> Strothotte describes three classes of programming language constructs for expressing temporal notions in a program: those for the past tense, the future tense, and the subjunctive tense.
Reference: [62] <author> V.S. Sunderam. </author> <title> PVM: A Framework for Parallel Distributed Computing. </title> <journal> Concur-rency: Practice & Experience, </journal> <volume> 2(4) </volume> <pages> 315-339, </pages> <month> December </month> <year> 1990. </year>
Reference-contexts: HOPE does dependency tracking by marking communications between processes with references to AIDs, and so inter-process communications must be explicit, as is the case in many concurrent and distributed systems <ref> [4, 12, 30, 62] </ref>. Shared memory programming models would be impractical with HOPE, because HOPE dependency tracking operations would have to accompany every shared memory access. Chapter 4 Operational Semantics 1 This chapter defines the formal operational semantics of the HOPE primitives introduced in Chapter 3. <p> Thus it was determined that HOPE should be built on top of a pre-existing message passing environment, preferably one with a large user base. The PVM system <ref> [62] </ref> was selected as the first target environment for HOPE. PVM (Parallel Virtual Machine) is a software package that allows a network of computers to appear as a single concurrent computational resource. <p> An prototype implementation of HOPE has been constructed, and its algorithms have been described. The prototype allows HOPE programs to be written in ordinary C, with message passing primitives provided by the widely-used PVM system <ref> [62] </ref>, and HOPE primitives provided by additions and modifications to the PVM library of functions. While the performance delivered by the HOPE prototype is far from optimal, the design is faithful to the basic use of optimism, which is to avoid latency.
Reference: [63] <author> Gerard Tel and Friedmann Mattern. </author> <title> Derivation of Distributed Termination Detection Algorithms from Garbage Collection Schemes. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 15(1) </volume> <pages> 1-35, </pages> <month> January </month> <year> 1993. </year>
Reference-contexts: To garbage collect a given AID process, it must first be determined that no process in the system will apply a HOPE primitive to that assumption identifier. Such garbage collection can be done by counting references from assumption identifiers to AID processes <ref> [63] </ref>. is the initial state, and the states True and False are terminal. Figure 5.3 shows the top level of the formal specification of the AID state machine.
Reference: [64] <author> P. Triantafillou and D.J. Taylor. </author> <title> A New Paradigm for High Availability and Efficiency in Replicated and Distributed Databases. </title> <booktitle> In 2nd IEEE Symposium on Parallel and Distributed Processing, </booktitle> <pages> pages 136-143, </pages> <month> December </month> <year> 1990. </year>
Reference-contexts: However, it should also be noted that whenever rollback occurs, other rollback-free algorithms would require blocking for an amount of time equal to that spent on wasted computation [31]. 1.2 HOPE: Hopefully Optimistic Programming Environment Optimistic algorithms have been used for fault tolerance [57, 33], replication <ref> [15, 24, 35, 49, 64] </ref>, concurrency control [29, 32, 36, 68], and discrete event simulation [6, 22, 31, 50, 65]. However, the notion of optimism has not been generally exploited because optimistic algorithms are difficult to write. <p> Thus write operations in a replicated system actually suffer greater latency than in non-replicated systems. Triantafillou and Taylor <ref> [64] </ref> present a consistency mechanism for replicated data in transaction-based distributed systems. Like Kung & Robinson, Triantafillou makes the optimistic assumption that write operations do not conflict, and executes the replica consistency check in parallel with the body of the transaction.
Reference: [65] <author> Brian Unger, John Cleary, Alan Dewar, and Zhong e Xiao. </author> <title> Multi-lingual Optimistic Distributed Simulator. </title> <journal> Transactions of the Society for Computer Simulation, </journal> <volume> 7(2) </volume> <pages> 121-151, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: rollback-free algorithms would require blocking for an amount of time equal to that spent on wasted computation [31]. 1.2 HOPE: Hopefully Optimistic Programming Environment Optimistic algorithms have been used for fault tolerance [57, 33], replication [15, 24, 35, 49, 64], concurrency control [29, 32, 36, 68], and discrete event simulation <ref> [6, 22, 31, 50, 65] </ref>. However, the notion of optimism has not been generally exploited because optimistic algorithms are difficult to write. Obstacles to optimism include the following: Checkpoint & Rollback This is difficult and non-portable. <p> There are numerous checkpoint and restart systems [7, 14, 34, 43, 67] for UNIX processes. There are also numerous specific systems that include rollback, but are confined to some specific environment or domain, such as discrete event simulation <ref> [22, 31, 65] </ref> or transaction processing [53, 56, 66]. Finally, there are numerous studies examining the theoretical properties of various schemes for maintaining consistency in the presence of distributed rollback [5, 16, 42, 54, 55].
Reference: [66] <author> Kun-Lung Wu and W. Kent Fuchs. </author> <title> Twin-page Storage Management for Rapid Transaction-undo Recovery. </title> <booktitle> In 14th Annual International Computer Software and Applications conference (COMPSAC 90), </booktitle> <pages> pages 5-10, </pages> <address> Houston, TX, </address> <month> November </month> <year> 1990. </year>
Reference-contexts: There are numerous checkpoint and restart systems [7, 14, 34, 43, 67] for UNIX processes. There are also numerous specific systems that include rollback, but are confined to some specific environment or domain, such as discrete event simulation [22, 31, 65] or transaction processing <ref> [53, 56, 66] </ref>. Finally, there are numerous studies examining the theoretical properties of various schemes for maintaining consistency in the presence of distributed rollback [5, 16, 42, 54, 55]. However, an extensive literature search failed to turn up a general purpose rollback facility for UNIX processes.
Reference: [67] <author> Bennet Yee and David Applegate. </author> <title> Save World. Public Domain Software, </title> <note> available via FTP from ftp://Play.Trust.CS.CMU.Edu/usr/ftpguest/pub/save world.tar.Z., </note> <year> 1993. </year>
Reference-contexts: This appendix describes our checkpoint and rollback facility for UNIX processes. The desired facility is a portable, user-space mechanism for checkpointing the state of a UNIX process in C, and then later rolling the process back to that state. There are numerous checkpoint and restart systems <ref> [7, 14, 34, 43, 67] </ref> for UNIX processes. There are also numerous specific systems that include rollback, but are confined to some specific environment or domain, such as discrete event simulation [22, 31, 65] or transaction processing [53, 56, 66]. <p> Recently, the Condor project has undertaken to create a new checkpointing mechanism that does not kill the process [51], but details are not available at this time. Yee's Save World <ref> [67] </ref> and Bernstein's Pmckpt [7] are similar to one another, in that they are small libraries of portable software that provide rudimentary process checkpoint and restart. Both save and restore process state by simply reading and writing the appropriate address ranges.

References-found: 67

