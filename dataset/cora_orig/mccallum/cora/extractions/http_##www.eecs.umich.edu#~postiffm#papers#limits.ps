URL: http://www.eecs.umich.edu/~postiffm/papers/limits.ps
Refering-URL: http://www.eecs.umich.edu/~postiffm/papers/published.papers.html
Root-URL: http://www.cs.umich.edu
Email: fpostiffm,greened,tyson,tnmg@eecs.umich.edu  
Title: The Limits of Instruction Level Parallelism in SPEC95 Applications  
Author: Matthew A. Postiff, David A. Greene, Gary S. Tyson and Trevor N. Mudge 
Address: Michigan  
Affiliation: Advanced Computer Architecture Lab The University of  
Abstract: This paper examines the limits to instruction level parallelism that can be found in programs, in particular the SPEC95 benchmark suite. Apart from using a more recent version of the SPEC benchmark suite, it differs from earlier studies in removing non-essential true dependencies that occur as a result of the compiler employing a stack for subroutine linkage. This is a subtle limitation to parallelism that is not readily evident as it appears as a true dependency on the stack pointer. Other methods can be used that do not employ a stack to remove this dependency. In this paper we show that its removal exposes far more parallelism than has been seen previously. We refer to this type of parallelism as "parallelism at a distance" because it requires impossibly large instruction windows for detection. We conclude with two observations: 1) that a single instruction window characteristic of superscalar machines is inadequate for detecting parallelism at a distance; and 2) in order to take advantage of this parallelism the compiler must be involved, or separate threads must be explicitly programmed. 
Abstract-found: 1
Intro-found: 1
Reference: [AS92] <author> T. M. Austin and G. S. Sohi. </author> <title> Dynamic dependency analysis of ordinary programs. </title> <editor> In David Abramson and Jean-Luc Gau-diot, editors, </editor> <booktitle> Proc. ISCA-19, </booktitle> <pages> pages 342-351. </pages> <publisher> ACM Press, </publisher> <month> May </month> <year> 1992. </year>
Reference-contexts: Perfect alias analysis was studied in [Wal93]. Memory renaming was considered in a limit study in <ref> [AS92] </ref>. IPC as high as several thousand was reported. Recent developments that employ relatively small value files to rename locally live memory addresses have shown that memory renaming is not as impractical as was thought [TA97].
Reference: [BA97] <author> Douglas C. Burger and Todd M. Austin. </author> <title> The simplescalar tool set, version 2.0. </title> <type> Tech. Report CS-TR-97-1342, </type> <institution> University of Wisconsin, Madison, </institution> <month> June </month> <year> 1997. </year>
Reference-contexts: parallelism at a distance supports much previous work in multi-threaded execution [TEL95], and provides some insight into how multiple threads may be found from a single "sequential" program. 3 Methodology In order to examine the available parallelism, we constructed an execution driven simulator based on the the simplescalar simulation environment <ref> [BA97] </ref>. A graphical image is generated based on information produced by the simulator.
Reference: [BYP + 91] <author> M. Butler, T.-Y. Yeh, Y. Patt, M. Alsup, H. Scales, and M. Shebanow. </author> <title> Single instruction stream parallelism is greater than two. </title> <booktitle> In Proc. ISCA-18, </booktitle> <volume> volume 19, </volume> <pages> pages 276-286, </pages> <month> June </month> <year> 1991. </year>
Reference-contexts: It is now possible to achieve predic tion rates that are correct more that 95% of the time. The possibility of high prediction rates also prompted limit studies that considered speculative execution scenarios that extended beyond the basic block boundaries. Many of the earlier limit studies <ref> [Wal91, JW89, Wal93, BYP + 91] </ref> also removed WAR and WAW dependencies in the case of registers by modeling renaming. The use of register renaming hardware in current processors has given added relevance to these studies [Kel75]. <p> Furthermore, not all researchers who considered the attenuation that results from implementation complexities were as pessimistic as [JW89] and [SJH89]. In <ref> [BYP + 91] </ref>, as the title suggests, the authors argue a strong case for implementation complexities being less limiting. Indeed, in the past few years manufacturers have now started to produce machines with the ability to issue six instructions per cycle, with more on the horizon [Gwe97].
Reference: [Gwe97] <author> Linley Gwennap. </author> <title> Design concepts for merced. </title> <type> Microprocessor Report, 11(3) </type> <pages> 9-11, </pages> <month> March </month> <year> 1997. </year>
Reference-contexts: In [BYP + 91], as the title suggests, the authors argue a strong case for implementation complexities being less limiting. Indeed, in the past few years manufacturers have now started to produce machines with the ability to issue six instructions per cycle, with more on the horizon <ref> [Gwe97] </ref>. This work is focused on logical limits rather than on implementation issues (we use unlimited window size and perfect branch prediction, for example).
Reference: [JT97] <author> G. P. Jones and N. P. Topham. </author> <title> A comparison of data prefetching on an access de-coupled and superscalar machine. </title> <booktitle> In Proc. Micro-30, </booktitle> <pages> pages 65-70, </pages> <month> December </month> <year> 1997. </year>
Reference-contexts: This is especially true when multiple branch predictions are attempted in a single cycle. Other work has shown the potential of multiple instruction windows to ease implementation by de-coupling reference and computation streams <ref> [JT97] </ref>. Though the effective window size of the two separate windows proposed in that work can exceed the sum of their individual sizes, the two instruction streams are very tightly coupled (by a single program counter) compared to the separate instruction streams discovered here.
Reference: [JW89] <author> N. P. Jouppi and D. W. Wall. </author> <title> Available instruction-level parallelism for superscalar and superpipelined machines. </title> <booktitle> In Proc. ASPLOS-3, </booktitle> <volume> volume 24, </volume> <pages> pages 272-282, </pages> <month> May </month> <year> 1989. </year>
Reference-contexts: It is now possible to achieve predic tion rates that are correct more that 95% of the time. The possibility of high prediction rates also prompted limit studies that considered speculative execution scenarios that extended beyond the basic block boundaries. Many of the earlier limit studies <ref> [Wal91, JW89, Wal93, BYP + 91] </ref> also removed WAR and WAW dependencies in the case of registers by modeling renaming. The use of register renaming hardware in current processors has given added relevance to these studies [Kel75]. <p> Other studies that considered the complexities of the hardware needed to detect data dependencies between instructions, the complexities of fetching noncontiguous instructions from memory, and gathering multiple data items from memory in single cycles, arrived at much more pessimistic results that suggested 2-3 as a realistic limit for IPC <ref> [JW89, SJH89] </ref>. Nevertheless, the limit studies showed that the limitations were one of physical implementation, not logical limitations, and thus provided a realistic goal for implementers. <p> Even earlier studies by Kuck's group at the University of Illinois showed that 16 or more processors could be kept busy on workloads characterized by FORTRAN DO-loops [KBC + 74]. Furthermore, not all researchers who considered the attenuation that results from implementation complexities were as pessimistic as <ref> [JW89] </ref> and [SJH89]. In [BYP + 91], as the title suggests, the authors argue a strong case for implementation complexities being less limiting.
Reference: [KBC + 74] <author> D. Kuck, P. Budnik, S. C. Chen, E. Davis, Jr., J. Han, P. Kraska, D. Lawrie, Y. Mu-raoka, R. Strebendt, and R. Towle. </author> <title> Measurements of parallelism in ordinary FORTRAN programs. </title> <journal> Computer, </journal> <volume> 7(1) </volume> <pages> 37-46, </pages> <month> January </month> <year> 1974. </year>
Reference-contexts: In [NF84] IPC of tens and in some cases hundreds are reported for benchmarks of DO-loops style programs. Even earlier studies by Kuck's group at the University of Illinois showed that 16 or more processors could be kept busy on workloads characterized by FORTRAN DO-loops <ref> [KBC + 74] </ref>. Furthermore, not all researchers who considered the attenuation that results from implementation complexities were as pessimistic as [JW89] and [SJH89]. In [BYP + 91], as the title suggests, the authors argue a strong case for implementation complexities being less limiting.
Reference: [Kel75] <author> Robert M. Keller. </author> <title> Look-ahead processors. </title> <journal> ACM Computing Surveys, </journal> <volume> 7(4) </volume> <pages> 177-195, </pages> <month> December </month> <year> 1975. </year>
Reference-contexts: Many of the earlier limit studies [Wal91, JW89, Wal93, BYP + 91] also removed WAR and WAW dependencies in the case of registers by modeling renaming. The use of register renaming hardware in current processors has given added relevance to these studies <ref> [Kel75] </ref>. Work reported by Wall [Wal93] showed that there was a potential for IPC greater than 60 if perfect prediction was assumed.
Reference: [LS84] <author> J. K. F. Lee and A. J. Smith. </author> <title> Branch prediction strategies and branch target buffer design. </title> <journal> Computer, </journal> <volume> 17(1) </volume> <pages> 6-22, </pages> <month> January </month> <year> 1984. </year>
Reference-contexts: The importance of branches as a limit on parallelism was more fully explored by Riseman and Foster [RF72]. The recognition of the importance of branch prediction as enabling parallelism lead to a significant effort in branch prediction that continues today <ref> [LS84, YP92] </ref>. It is now possible to achieve predic tion rates that are correct more that 95% of the time. The possibility of high prediction rates also prompted limit studies that considered speculative execution scenarios that extended beyond the basic block boundaries.
Reference: [LY97] <author> Tim Lindholm and Frank Yellin. </author> <title> The Java Virtual Machine Specification. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1997. </year>
Reference-contexts: Many early languages (e.g. early versions of Fortran) used fixed allocation of function variables, while some current languages are implemented using heap allocated activation records to support multi-threaded execution models. The best known example is Sun's implementation of the Java virtual machine <ref> [LY97] </ref>. While a fixed frame is not reentrant, heap allocation is a viable alternative to stack based activation records | trading higher overhead (in instructions required to allocate space) with the ability to perform allocations in parallel.
Reference: [NF84] <author> A. Nicolau and J. A. Fisher. </author> <title> Measuring the parallelism available for very long instruction word architectures. </title> <journal> In IEEE Trans. Computers, </journal> <volume> volume C-33, </volume> <pages> pages 968-976. </pages> <year> 1984. </year>
Reference-contexts: The VLIW work was one of the best examples of this approach. Scheduling techniques were developed in which branch prediction was essentially done by the compiler so that it could assemble long execution traces. In <ref> [NF84] </ref> IPC of tens and in some cases hundreds are reported for benchmarks of DO-loops style programs. Even earlier studies by Kuck's group at the University of Illinois showed that 16 or more processors could be kept busy on workloads characterized by FORTRAN DO-loops [KBC + 74].
Reference: [RF72] <author> E. M. Riseman and C. C. Foster. </author> <title> The inhibition of potential parallelism by conditional jumps. </title> <journal> In IEEE Trans. Computers, </journal> <volume> volume C-21, </volume> <pages> pages 1405-1411. </pages> <year> 1972. </year>
Reference-contexts: However, these studies did not consider the possibilities of looking past a branch and were therefore bound by basic block sizes, which are typically four to eight instructions. The importance of branches as a limit on parallelism was more fully explored by Riseman and Foster <ref> [RF72] </ref>. The recognition of the importance of branch prediction as enabling parallelism lead to a significant effort in branch prediction that continues today [LS84, YP92]. It is now possible to achieve predic tion rates that are correct more that 95% of the time.
Reference: [SJH89] <author> M. D. Smith, M. Johnson, and M. A. Horowitz. </author> <title> Limits on multiple instruction issue. </title> <booktitle> In Proc. ASPLOS-3, </booktitle> <volume> number 5, </volume> <pages> pages 290-302, </pages> <month> May </month> <year> 1989. </year>
Reference-contexts: Other studies that considered the complexities of the hardware needed to detect data dependencies between instructions, the complexities of fetching noncontiguous instructions from memory, and gathering multiple data items from memory in single cycles, arrived at much more pessimistic results that suggested 2-3 as a realistic limit for IPC <ref> [JW89, SJH89] </ref>. Nevertheless, the limit studies showed that the limitations were one of physical implementation, not logical limitations, and thus provided a realistic goal for implementers. <p> Even earlier studies by Kuck's group at the University of Illinois showed that 16 or more processors could be kept busy on workloads characterized by FORTRAN DO-loops [KBC + 74]. Furthermore, not all researchers who considered the attenuation that results from implementation complexities were as pessimistic as [JW89] and <ref> [SJH89] </ref>. In [BYP + 91], as the title suggests, the authors argue a strong case for implementation complexities being less limiting. Indeed, in the past few years manufacturers have now started to produce machines with the ability to issue six instructions per cycle, with more on the horizon [Gwe97].
Reference: [SV97] <author> James E. Smith and Sriram Vajapeyam. </author> <title> Trace processors: Moving to fourth-generation microarchitectures. </title> <journal> Computer, </journal> <volume> 30(9) </volume> <pages> 68-74, </pages> <month> September </month> <year> 1997. </year>
Reference-contexts: A single window model of parallelism is not scalable to this level of parallelism. Research on very wide processors have shown that large instructions windows can provide significant wins in performance <ref> [SV97] </ref>. However, no single instruction window, no matter how large, will be able to capture the parellelism we demonstrate in this paper-the distances between independent instructions is simply too vast. As mentioned earlier, branch prediction allows a machine to look further down a (potential) instruction stream to extract parallelism.
Reference: [TA97] <author> Gary S. Tyson and Todd M. Austin. </author> <title> Improving the accuracy and performance of memory communication through renaming. </title> <booktitle> In Proc. Micro-30, </booktitle> <pages> pages 218-227, </pages> <month> De-cember </month> <year> 1997. </year>
Reference-contexts: Memory renaming was considered in a limit study in [AS92]. IPC as high as several thousand was reported. Recent developments that employ relatively small value files to rename locally live memory addresses have shown that memory renaming is not as impractical as was thought <ref> [TA97] </ref>. Such studies have shown promise in reducing the effect of false memory dependencies and allowing more memory references to execute out-of-order. We extend previous work in memory renaming to the limit case to explore the possible gains of an unrestricted memory renaming model.
Reference: [TEL95] <author> Dean M. Tullsen, Susan J. Eggers, and Henry M. Levy. </author> <title> Simultaneous multithread-ing: Maximizing on-chip parallelism. </title> <booktitle> In Proc. ISCA-22, </booktitle> <pages> pages 392-403, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: This parallelism at a distance supports much previous work in multi-threaded execution <ref> [TEL95] </ref>, and provides some insight into how multiple threads may be found from a single "sequential" program. 3 Methodology In order to examine the available parallelism, we constructed an execution driven simulator based on the the simplescalar simulation environment [BA97].
Reference: [TF70] <author> G. S. Tjaden and M. J. Flynn. </author> <title> Detection and parallel execution of independent instructions. </title> <journal> Journal of the ACM, </journal> 19(10) 889-895, October 1970. 
Reference-contexts: In Section 6 we discuss methods of exploiting the parallelism exposed in this study and in Section 7 we conclude and present several areas of further research. 2 Previous Studies Early studies by Tjaden and Flynn showed that 2-3 instructions per clock (IPC) were possible <ref> [TF70] </ref>. However, these studies did not consider the possibilities of looking past a branch and were therefore bound by basic block sizes, which are typically four to eight instructions. The importance of branches as a limit on parallelism was more fully explored by Riseman and Foster [RF72].
Reference: [Wal91] <author> D. W. Wall. </author> <title> Limits of instruction-level parallelism. </title> <booktitle> In Proc. ASPLOS-4, </booktitle> <volume> volume 26, </volume> <pages> pages 176-189, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: It is now possible to achieve predic tion rates that are correct more that 95% of the time. The possibility of high prediction rates also prompted limit studies that considered speculative execution scenarios that extended beyond the basic block boundaries. Many of the earlier limit studies <ref> [Wal91, JW89, Wal93, BYP + 91] </ref> also removed WAR and WAW dependencies in the case of registers by modeling renaming. The use of register renaming hardware in current processors has given added relevance to these studies [Kel75].
Reference: [Wal93] <author> David W. Wall. </author> <title> Limits of instruction-level parallelism. </title> <type> Technical Report DEC-WRL-93-6, </type> <institution> Digital Equipment Corporation, Western Research Lab, </institution> <month> November 93. </month>
Reference-contexts: It is now possible to achieve predic tion rates that are correct more that 95% of the time. The possibility of high prediction rates also prompted limit studies that considered speculative execution scenarios that extended beyond the basic block boundaries. Many of the earlier limit studies <ref> [Wal91, JW89, Wal93, BYP + 91] </ref> also removed WAR and WAW dependencies in the case of registers by modeling renaming. The use of register renaming hardware in current processors has given added relevance to these studies [Kel75]. <p> Many of the earlier limit studies [Wal91, JW89, Wal93, BYP + 91] also removed WAR and WAW dependencies in the case of registers by modeling renaming. The use of register renaming hardware in current processors has given added relevance to these studies [Kel75]. Work reported by Wall <ref> [Wal93] </ref> showed that there was a potential for IPC greater than 60 if perfect prediction was assumed. To achieve this limit it was also necessary to assume that caches were perfect, that data dependency analysis could be done essentially instantaneously and that register renaming was supported. <p> The use of algorithm information by the compiler can make the problem tractable for large classes of address calculation, and thus it has made sense to assume a solution to the aliasing problem in limit studies. Perfect alias analysis was studied in <ref> [Wal93] </ref>. Memory renaming was considered in a limit study in [AS92]. IPC as high as several thousand was reported. Recent developments that employ relatively small value files to rename locally live memory addresses have shown that memory renaming is not as impractical as was thought [TA97].
Reference: [YP92] <author> T.-Y. Yeh and Y. N. Patt. </author> <title> Alternative implementations of two-level adaptive branch prediction. </title> <editor> In David Abramson and Jean-Luc Gaudiot, editors, </editor> <booktitle> Proc. ISCA-19, </booktitle> <pages> pages 124-135, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: The importance of branches as a limit on parallelism was more fully explored by Riseman and Foster [RF72]. The recognition of the importance of branch prediction as enabling parallelism lead to a significant effort in branch prediction that continues today <ref> [LS84, YP92] </ref>. It is now possible to achieve predic tion rates that are correct more that 95% of the time. The possibility of high prediction rates also prompted limit studies that considered speculative execution scenarios that extended beyond the basic block boundaries.
References-found: 20

