URL: http://www.ri.cmu.edu/afs/cs/user/fp/public/papers/cade92.ps.gz
Refering-URL: http://www.ri.cmu.edu/afs/cs/user/fp/public/papers/
Root-URL: 
Email: fp+@cs.cmu.edu and er+@cs.cmu.edu  
Title: Implementing the Meta-Theory of Deductive Systems  
Author: Frank Pfenning and Ekkehard Rohwedder 
Address: Pittsburgh, Pennsylvania 15213-3890, U.S.A.  
Affiliation: School of Computer Science Carnegie Mellon University  
Abstract: We exhibit a methodology for formulating and verifying meta-theorems about deductive systems in the Elf language, an implementation of the LF Logical Framework with an operational semantics in the spirit of logic programming. It is based on the mechanical verification of properties of transformations between deductions, which relies on type reconstruction and schema-checking. The latter is justified by induction principles for closed LF objects, which can be constructed over a given signature. We illustrate our technique through several examples, the most extensive of which is an interpretation of classical logic in minimal logic through a continuation-passing-style transformation on proofs.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Arnon Avron, Furio A. Honsell, and Ian A. Mason. </author> <title> Using typed lambda calculus to implement formal systems on a machine. </title> <type> Technical Report ECS-LFCS-87-31, </type> <institution> Laboratory for Foundations of Computer Science, University of Edinburgh, Edinburgh, </institution> <address> Scotland, </address> <month> June </month> <year> 1987. </year>
Reference-contexts: Unification and proof search algorithms have been developed [7, 27, 28, 24] and it has been amenable to an operational interpretation which is realized in the Elf programming language [21, 23]. A wide range of deductive systems have been specified in LF and implemented in Elf <ref> [1, 15, 19, 20] </ref>. In this paper we investigate the use of Elf to implement the meta-theory of deductive systems, thus addressing the third of the principal applications listed above. Our approach is based on three observations.
Reference: [2] <author> David A. Basin and Robert L. Constable. </author> <note> Metalogical frameworks. Submitted, </note> <month> July </month> <year> 1991. </year>
Reference-contexts: The limitations of this alternative approach are also discussed, but more work is required to understand the precise relationship to schema-checking. Another line of investigation is followed by Basin and Constable <ref> [2] </ref>, who propose using inductively defined types in the NuPrl type theory in order to represent deductive systems. However, their approach is not especially tailored towards developing the meta-theory of deductive systems, but applies an already existing apparatus to a new and more difficult problem.
Reference: [3] <author> Alan Bundy, Frank van Harmelen, Alan Smaill, and Andrew Ireland. </author> <title> Extensions to the rippling-out tactic for guiding inductive proofs. </title> <editor> In M. E. Stickel, editor, </editor> <booktitle> 10th International Conference on Automated Deduction, </booktitle> <pages> pages 132-146. </pages> <publisher> Springer-Verlag LNAI 449, </publisher> <year> 1990. </year>
Reference-contexts: The primary difficulty in applying our methodology is to construct the transformations between deductions. Due to the strong constraints imposed by the dependent types, we believe that in many cases such transformations could be constructed automatically. Other work in inductive theorem proving and logic programming such as, for example <ref> [3, 12, 26] </ref>, should be applicable in our setting to aid in the construction of such transformations. Closely related to the ideas presented here is work by Fribourg [9] in the simpler setting of Horn clauses. Again, his ideas could add to the degree of automation available within our methodology.
Reference: [4] <author> Rod Burstall and Furio Honsell. </author> <title> Operational semantics in a natural deduction setting. </title> <editor> In Gerard Huet and Gordon Plotkin, editors, </editor> <booktitle> Logical Frameworks, </booktitle> <pages> pages 185-214. </pages> <publisher> Cambridge University Press, </publisher> <year> 1991. </year>
Reference-contexts: This was one of Gentzen's original motivations for his calculus of natural deduction [10]. Secondly, they can form the basis for an implementation of a deductive system. For example, it is not difficult to translate an operational semantics presented in the style of natural deduction <ref> [18, 13, 4] </ref> into an implementation of an interpreter. Thirdly, deductive systems help in developing the meta-theory of a language. For example, the soundness of a type system with respect to an operational semantics is most easily expressed as a property of two inference systems.
Reference: [5] <author> Dominique Clement, Joelle Despeyroux, Thierry Despeyroux, and Gilles Kahn. </author> <title> A simple applicative language: </title> <booktitle> Mini-ML. In Proceedings of the 1986 Conference on LISP and Functional Programming, </booktitle> <pages> pages 13-27. </pages> <publisher> ACM Press, </publisher> <year> 1986. </year>
Reference-contexts: Stage 4 (Schema-Checking) is the mechanical verification of a property of the transformations axiomatized in Stage 3. We have carried out this methodology for a number of examples, the most intricate of which is a verification of the subject reduction property for Mini-ML <ref> [5, 20] </ref>. Currently, Stage 4 is done mostly by hand, as we have not yet implemented a general schema-checker. As we will illustrate, in the current Elf implementation schema-checking can be directly achieved through a set of queries which can be constructed from a signature on a case-by-case basis.
Reference: [6] <author> Thierry Coquand and Christine Paulin. </author> <title> Inductively defined types. </title> <editor> In P. Martin-Lof and G. Mints, editors, </editor> <booktitle> COLOG-88, </booktitle> <pages> pages 50-66. </pages> <publisher> Springer-Verlag LNCS 417, </publisher> <month> December </month> <year> 1988. </year>
Reference-contexts: Many types, such as the type of exp defined below, are not inductive in the usual sense (see, for example, <ref> [6] </ref>).
Reference: [7] <author> Conal M. Elliott. </author> <title> Extensions and Applications of Higher-Order Unification. </title> <type> PhD thesis, </type> <institution> School of Computer Science, Carnegie Mellon University, </institution> <month> May </month> <year> 1990. </year> <note> Available as Technical Report CMU-CS-90-134. </note>
Reference-contexts: Since type-checking in the LF type theory is decidable, purported deductions can be checked automatically for validity. However, LF is a powerful basis for much more comprehensive tasks than mere proof-checking. Unification and proof search algorithms have been developed <ref> [7, 27, 28, 24] </ref> and it has been amenable to an operational interpretation which is realized in the Elf programming language [21, 23]. A wide range of deductive systems have been specified in LF and implemented in Elf [1, 15, 19, 20].
Reference: [8] <author> Steven Fortune, Daniel Leivant, and Michael O'Donnell. </author> <title> The expressiveness of simple and second-order type structures. </title> <journal> Journal of the ACM, </journal> <volume> 30 </volume> <pages> 151-185, </pages> <year> 1983. </year>
Reference-contexts: Interestingly, neither choice is a priori weaker than the other. For example, the functions provably total in second-order arithmetic are exactly the functions which can be defined using a schema of primitive recursion at higher types <ref> [8] </ref>. As we hope to illustrate in this paper, the latter choice is a very natural one, and many examples can be treated very elegantly. Moreover, it does not preclude the application of automated theorem proving methods, as they can be used to synthesize schematic relations.
Reference: [9] <author> Laurent Fribourg. </author> <title> Extracting logic programs from proofs that use extended Prolog execution and induction. </title> <editor> In David H.D. Warren and Peter Szeredi, editors, </editor> <booktitle> Proceedings of the Seventh International Conference on Logic Programming, </booktitle> <pages> pages 685-699. </pages> <publisher> MIT Press, </publisher> <month> June </month> <year> 1990. </year>
Reference-contexts: Other work in inductive theorem proving and logic programming such as, for example [3, 12, 26], should be applicable in our setting to aid in the construction of such transformations. Closely related to the ideas presented here is work by Fribourg <ref> [9] </ref> in the simpler setting of Horn clauses. Again, his ideas could add to the degree of automation available within our methodology. <p> Moreover, it does not preclude the application of automated theorem proving methods, as they can be used to synthesize schematic relations. This is one of Fribourg's basic observations <ref> [9] </ref> and 5 illustrated in Section 3. But even without any automatic assistance beyond term reconstruction it is feasible to demonstrate non-trivial meta-theorems. We now return to the example. The induction principle for objects constructed over the given signature is just the familiar induction principle for natural numbers.
Reference: [10] <author> Gerhard Gentzen. </author> <title> Untersuchungen uber das logische Schlieen. </title> <journal> Mathematische Zeitschrift, </journal> <volume> 39 </volume> <pages> 176-210, 405-431, </pages> <year> 1935. </year>
Reference-contexts: The role of such specifications is three-fold. Firstly, inference rules serve as a high-level notation which helps to explain the meaning of the language under consideration. This was one of Gentzen's original motivations for his calculus of natural deduction <ref> [10] </ref>. Secondly, they can form the basis for an implementation of a deductive system. For example, it is not difficult to translate an operational semantics presented in the style of natural deduction [18, 13, 4] into an implementation of an interpreter.
Reference: [11] <author> Timothy G. Griffin. </author> <title> Logical interpretations as computational simulations. </title> <type> Draft paper. </type> <institution> Talk given at the North American Jumelage, AT&T Bell Laboratories, </institution> <address> Murray Hill, New Jersey 1991, </address> <month> October </month> <year> 1991. </year>
Reference-contexts: This succeeds with substitution Qpi1 = [e][v1][v2][m][q][q1][q2] q1 q. 4 Logic Interpretations and CPS Transform In <ref> [11] </ref>, Griffin presents a number of interpretations between logics and shows how they can be viewed as computational simulations. We have transcribed and verified 8 of these interpretations. In this section we will verify the type-soundness of the continuation-passing-style (CPS) transform of Plotkin [25], which is one of Griffin's examples.
Reference: [12] <author> Lars Hallnas and Peter Schroeder-Heister. </author> <title> A proof-theoretic approach to logic programming. </title> <journal> Journal of Logic and Computation, </journal> <volume> 1(5) </volume> <pages> 635-660, </pages> <year> 1991. </year>
Reference-contexts: The primary difficulty in applying our methodology is to construct the transformations between deductions. Due to the strong constraints imposed by the dependent types, we believe that in many cases such transformations could be constructed automatically. Other work in inductive theorem proving and logic programming such as, for example <ref> [3, 12, 26] </ref>, should be applicable in our setting to aid in the construction of such transformations. Closely related to the ideas presented here is work by Fribourg [9] in the simpler setting of Horn clauses. Again, his ideas could add to the degree of automation available within our methodology.
Reference: [13] <author> John Hannan and Dale Miller. </author> <title> From operational semantics to abstract machines: Preliminary results. </title> <editor> In M. Wand, editor, </editor> <booktitle> ACM Conference on Lisp and Functional Programming, </booktitle> <pages> pages 323-332. </pages> <publisher> ACM Press, </publisher> <year> 1990. </year>
Reference-contexts: This was one of Gentzen's original motivations for his calculus of natural deduction [10]. Secondly, they can form the basis for an implementation of a deductive system. For example, it is not difficult to translate an operational semantics presented in the style of natural deduction <ref> [18, 13, 4] </ref> into an implementation of an interpreter. Thirdly, deductive systems help in developing the meta-theory of a language. For example, the soundness of a type system with respect to an operational semantics is most easily expressed as a property of two inference systems.
Reference: [14] <author> John Hannan and Frank Pfenning. </author> <title> Compiler verification in LF. </title> <booktitle> In Seventh Annual IEEE Symposium on Logic in Computer Science, </booktitle> <address> Santa Cruz, California, </address> <month> June </month> <year> 1992. </year> <note> IEEE Computer Society Press. To appear. Preliminary version available as POP Report 91-003, </note> <institution> School of Computer Science, Carnegie Mellon University. </institution>
Reference-contexts: a Mini-ML expression results in a value if it terminates, * equivalence of an algorithmic and a more declarative operational semantics for Mini-ML, * type-soundness of Mini-ML (sometimes called the subject reduction theorem), including polymorphism, * correctness of a compiler from Mini-ML to a variant of the Categorical Abstract Machine <ref> [14] </ref>, 2 * the deduction theorem for an axiomatic formulation of propositional logic in the style of Hilbert, * equivalence of natural deduction and Hilbert's calculus, * soundness of two theorem provers, one using Prolog-style depth-first search and one employing bounded search, * equivalence of two formulations of the Lambek-calculus, *
Reference: [15] <author> Robert Harper. </author> <title> Systems of polymorphic type assignment in LF. </title> <type> Technical Report CMU-CS-90-144, </type> <institution> Carnegie Mellon University, Pittsburgh, Pennsylvania, </institution> <month> June </month> <year> 1990. </year> <month> 14 </month>
Reference-contexts: Unification and proof search algorithms have been developed [7, 27, 28, 24] and it has been amenable to an operational interpretation which is realized in the Elf programming language [21, 23]. A wide range of deductive systems have been specified in LF and implemented in Elf <ref> [1, 15, 19, 20] </ref>. In this paper we investigate the use of Elf to implement the meta-theory of deductive systems, thus addressing the third of the principal applications listed above. Our approach is based on three observations.
Reference: [16] <author> Robert Harper, Furio Honsell, and Gordon Plotkin. </author> <title> A framework for defining logics. </title> <journal> Journal of the ACM, </journal> <note> To appear. A preliminary version appeared in Symposium on Logic in Computer Science, pages 194-204, </note> <month> June </month> <year> 1987. </year>
Reference-contexts: Thirdly, deductive systems help in developing the meta-theory of a language. For example, the soundness of a type system with respect to an operational semantics is most easily expressed as a property of two inference systems. The LF Logical Framework <ref> [16] </ref> has been designed to provide an appropriate language for the high-level specification of deductive systems. In LF, judgments are represented as types and deductions as objects. The validity of a deduction is reduced to the well-typedness of the representing object. <p> This is an important requirement and cannot easily be relaxed, because it would destroy the adequacy of encodings of deductive systems in LF (see <ref> [16] </ref> and [17] for further discussion). Thus, non-trivial operations on objects must be defined as relations. Fortunately, such relations are operationally adequate within the Elf programming language, as Elf gives them an operational reading in the style of Prolog. <p> This can also be thought of as a refinement of the representation of untyped programs in Section 3, by indexing expressions by their type, thus dividing and restricting the space of legal programs. For a further discussion of such issues of representation, the reader is referred to <ref> [16] </ref>. pf : form -&gt; type. 9 %% minimal logic lam : (pf A -&gt; pf B) -&gt; pf (imp A B). pair : pf A -&gt; pf B -&gt; pf (and A B). pi1 : pf (and A B) -&gt; pf A. inj1 : pf A -&gt; pf (or A
Reference: [17] <author> Robert Harper and Frank Pfenning. </author> <title> Modularity in the LF logical framework. </title> <note> Submitted. Available as POP Report 91-001, </note> <institution> School of Computer Science, Carnegie Mellon University, </institution> <month> November </month> <year> 1991. </year>
Reference-contexts: Schema-checking as presented in this paper verifies properties of signatures. Therefore, our work draws upon a calculus for LF signatures <ref> [17] </ref>. In that paper, it is also shown how some simple meta-theoretic properties can be witnessed directly by realizations (functions between signatures). The limitations of this alternative approach are also discussed, but more work is required to understand the precise relationship to schema-checking. <p> Valid (that is, well-typed), closed objects of type nat represent natural numbers. We refer to a list of declarations such as the ones above as a signature. A calculus of signatures for Elf is described in <ref> [17] </ref>. As this module calculus has not yet been implemented, we only use the Elf core language in this exposition. Judgments. The calculus of functions underlying LF is not very rich: it permits only -abstraction and application, and functions cannot be defined by primitive recursion, for example. <p> This is an important requirement and cannot easily be relaxed, because it would destroy the adequacy of encodings of deductive systems in LF (see [16] and <ref> [17] </ref> for further discussion). Thus, non-trivial operations on objects must be defined as relations. Fortunately, such relations are operationally adequate within the Elf programming language, as Elf gives them an operational reading in the style of Prolog. <p> This can be guaranteed through proper use of the module system for Elf, which is beyond the scope of this paper and can be found in <ref> [17] </ref>. Translations ( ) and ( ) fl are mutually recursive.
Reference: [18] <author> G. Kahn. </author> <title> Natural semantics. </title> <booktitle> In Proceedings of the Symposium on Theoretical Aspects of Computer Science, </booktitle> <pages> pages 22-39. </pages> <publisher> Springer-Verlag LNCS 247, </publisher> <year> 1987. </year>
Reference-contexts: This was one of Gentzen's original motivations for his calculus of natural deduction [10]. Secondly, they can form the basis for an implementation of a deductive system. For example, it is not difficult to translate an operational semantics presented in the style of natural deduction <ref> [18, 13, 4] </ref> into an implementation of an interpreter. Thirdly, deductive systems help in developing the meta-theory of a language. For example, the soundness of a type system with respect to an operational semantics is most easily expressed as a property of two inference systems.
Reference: [19] <author> Ian A. Mason. </author> <title> Hoare's logic in the LF. </title> <type> Technical Report ECS-LFCS-87-32, </type> <institution> Laboratory for Foundations of Computer Science, University of Edinburgh, Edinburgh, </institution> <address> Scotland, </address> <month> June </month> <year> 1987. </year>
Reference-contexts: Unification and proof search algorithms have been developed [7, 27, 28, 24] and it has been amenable to an operational interpretation which is realized in the Elf programming language [21, 23]. A wide range of deductive systems have been specified in LF and implemented in Elf <ref> [1, 15, 19, 20] </ref>. In this paper we investigate the use of Elf to implement the meta-theory of deductive systems, thus addressing the third of the principal applications listed above. Our approach is based on three observations.
Reference: [20] <author> Spiro Michaylov and Frank Pfenning. </author> <title> Natural semantics and some of its meta-theory in Elf. </title> <editor> In Lars Hallnas, editor, </editor> <title> Extensions of Logic Programming. </title> <note> Springer-Verlag LNCS. To appear. A preliminary version is available as Technical Report MPI-I-91-211, </note> <institution> Max-Planck-Institute for Computer Science, Saarbrucken, Germany, </institution> <month> August </month> <year> 1991. </year>
Reference-contexts: Unification and proof search algorithms have been developed [7, 27, 28, 24] and it has been amenable to an operational interpretation which is realized in the Elf programming language [21, 23]. A wide range of deductive systems have been specified in LF and implemented in Elf <ref> [1, 15, 19, 20] </ref>. In this paper we investigate the use of Elf to implement the meta-theory of deductive systems, thus addressing the third of the principal applications listed above. Our approach is based on three observations. <p> Stage 4 (Schema-Checking) is the mechanical verification of a property of the transformations axiomatized in Stage 3. We have carried out this methodology for a number of examples, the most intricate of which is a verification of the subject reduction property for Mini-ML <ref> [5, 20] </ref>. Currently, Stage 4 is done mostly by hand, as we have not yet implemented a general schema-checker. As we will illustrate, in the current Elf implementation schema-checking can be directly achieved through a set of queries which can be constructed from a signature on a case-by-case basis.
Reference: [21] <author> Frank Pfenning. </author> <title> Elf: A language for logic definition and verified meta-programming. </title> <booktitle> In Fourth Annual Symposium on Logic in Computer Science, </booktitle> <pages> pages 313-322. </pages> <publisher> IEEE, </publisher> <month> June </month> <year> 1989. </year>
Reference-contexts: However, LF is a powerful basis for much more comprehensive tasks than mere proof-checking. Unification and proof search algorithms have been developed [7, 27, 28, 24] and it has been amenable to an operational interpretation which is realized in the Elf programming language <ref> [21, 23] </ref>. A wide range of deductive systems have been specified in LF and implemented in Elf [1, 15, 19, 20]. In this paper we investigate the use of Elf to implement the meta-theory of deductive systems, thus addressing the third of the principal applications listed above.
Reference: [22] <author> Frank Pfenning. </author> <title> An implementation of the Elf core language in Standard ML. </title> <note> Available via ftp over the Internet, September 1991. Send mail to elf-request@cs.cmu.edu for further information. </note>
Reference-contexts: This would mean that an Elf theorem prover would try to synthesize an appropriate deduction transformation, such as tr or cps above. We currently have a small prototype implementation of schema-checking as an extension of the current Elf core language <ref> [22] </ref>. Several further verifications of standard meta-theorems in logic and computer science using the methods described here are subject of current work. 3 We omit from this discussion the unit refinements for the different cases of cps* that are needed in other parts of the proof. 13
Reference: [23] <author> Frank Pfenning. </author> <title> Logic programming in the LF logical framework. </title> <editor> In Gerard Huet and Gordon Plotkin, editors, </editor> <booktitle> Logical Frameworks, </booktitle> <pages> pages 149-181. </pages> <publisher> Cambridge University Press, </publisher> <year> 1991. </year>
Reference-contexts: However, LF is a powerful basis for much more comprehensive tasks than mere proof-checking. Unification and proof search algorithms have been developed [7, 27, 28, 24] and it has been amenable to an operational interpretation which is realized in the Elf programming language <ref> [21, 23] </ref>. A wide range of deductive systems have been specified in LF and implemented in Elf [1, 15, 19, 20]. In this paper we investigate the use of Elf to implement the meta-theory of deductive systems, thus addressing the third of the principal applications listed above. <p> The gaps in the first form shown above are filled during term reconstruction in Elf, which employs an algorithm for solving constraints between types, described in [24]. For a further discussion on term reconstruction and the operational semantics of Elf, the reader is referred to <ref> [23] </ref>. Schema-Checking | Induction. In this first example, we will directly verify a property of double, so there is no need to formulate a translation between deductions as they arise in Sections 3 and 4. The meta-theorem we verify states that double is total in its first argument.
Reference: [24] <author> Frank Pfenning. </author> <title> Unification and anti-unification in the Calculus of Constructions. </title> <booktitle> In Sixth Annual IEEE Symposium on Logic in Computer Science, </booktitle> <pages> pages 74-85. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> July </month> <year> 1991. </year>
Reference-contexts: Since type-checking in the LF type theory is decidable, purported deductions can be checked automatically for validity. However, LF is a powerful basis for much more comprehensive tasks than mere proof-checking. Unification and proof search algorithms have been developed <ref> [7, 27, 28, 24] </ref> and it has been amenable to an operational interpretation which is realized in the Elf programming language [21, 23]. A wide range of deductive systems have been specified in LF and implemented in Elf [1, 15, 19, 20]. <p> The gaps in the first form shown above are filled during term reconstruction in Elf, which employs an algorithm for solving constraints between types, described in <ref> [24] </ref>. For a further discussion on term reconstruction and the operational semantics of Elf, the reader is referred to [23]. Schema-Checking | Induction.
Reference: [25] <author> G. D. Plotkin. </author> <title> Call-by-name, call-by-value and the -calculus. </title> <journal> Theoretical Computer Science, </journal> <volume> 1 </volume> <pages> 125-159, </pages> <year> 1975. </year>
Reference-contexts: We have transcribed and verified 8 of these interpretations. In this section we will verify the type-soundness of the continuation-passing-style (CPS) transform of Plotkin <ref> [25] </ref>, which is one of Griffin's examples. Syntax. Once more, the first task will be to represent the logics under consideration. Here we deal with a propositional logic, which allows their direct interpretation as types of a programming language (using the Curry-Howard isomorphism).
Reference: [26] <author> Lutz Plumer. </author> <title> Termination Proofs for Logic Programs. </title> <publisher> Springer-Verlag LNAI 446, </publisher> <year> 1991. </year>
Reference-contexts: The primary difficulty in applying our methodology is to construct the transformations between deductions. Due to the strong constraints imposed by the dependent types, we believe that in many cases such transformations could be constructed automatically. Other work in inductive theorem proving and logic programming such as, for example <ref> [3, 12, 26] </ref>, should be applicable in our setting to aid in the construction of such transformations. Closely related to the ideas presented here is work by Fribourg [9] in the simpler setting of Horn clauses. Again, his ideas could add to the degree of automation available within our methodology.
Reference: [27] <author> David Pym. </author> <title> Proofs, Search and Computation in General Logic. </title> <type> PhD thesis, </type> <institution> University of Edinburgh, </institution> <year> 1990. </year> <note> Available as CST-69-90, also published as ECS-LFCS-90-125. </note>
Reference-contexts: Since type-checking in the LF type theory is decidable, purported deductions can be checked automatically for validity. However, LF is a powerful basis for much more comprehensive tasks than mere proof-checking. Unification and proof search algorithms have been developed <ref> [7, 27, 28, 24] </ref> and it has been amenable to an operational interpretation which is realized in the Elf programming language [21, 23]. A wide range of deductive systems have been specified in LF and implemented in Elf [1, 15, 19, 20].
Reference: [28] <author> David Pym and Lincoln Wallen. </author> <title> Investigations into proof-search in a system of first-order dependent function types. In M.E. </title> <editor> Stickel, editor, </editor> <booktitle> 10th International Conference on Automated Deduction, </booktitle> <address> Kaiserslautern, Germany, </address> <pages> pages 236-250. </pages> <publisher> Springer-Verlag LNCS 449, </publisher> <month> July </month> <year> 1990. </year> <month> 15 </month>
Reference-contexts: Since type-checking in the LF type theory is decidable, purported deductions can be checked automatically for validity. However, LF is a powerful basis for much more comprehensive tasks than mere proof-checking. Unification and proof search algorithms have been developed <ref> [7, 27, 28, 24] </ref> and it has been amenable to an operational interpretation which is realized in the Elf programming language [21, 23]. A wide range of deductive systems have been specified in LF and implemented in Elf [1, 15, 19, 20].
References-found: 28

