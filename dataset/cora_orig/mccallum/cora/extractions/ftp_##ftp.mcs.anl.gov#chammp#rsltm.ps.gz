URL: ftp://ftp.mcs.anl.gov/chammp/rsltm.ps.gz
Refering-URL: http://www.mcs.anl.gov/RSL/
Root-URL: http://www.mcs.anl.gov
Title: A Runtime System Library for Parallel Finite Difference Models with Nesting  
Author: John Michalakes 
Abstract: RSL is a parallel run-time system library for implementing regular-grid models with nesting on distributed memory parallel computers. RSL provides support for automatically decomposing multiple model domains and for redistributing work between processors at run time for dynamic load balancing. A unique feature of RSL is that processor subdomains need not be rectangular patches; rather, grid points are independently allocated to processors, allowing more precisely balanced allocation of work to processors. Communication mechanisms are tailored to the application: RSL provides an efficient high-level stencil exchange operation for updating subdomain ghost areas and interdomain communication to support two-way interaction between nest levels. RSL also provides run-time support for local iteration over subdomains, global-local index translation, and distributed I/O from ordinary Fortran record-blocked data sets. The interface to RSL supports Fortran77 and Fortran90. RSL has been used to paral-lelize the NCAR/Penn State Mesoscale Model (MM5). 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. Balay, W. D. Gropp, L. C. McInnes, and B. F. Smith, </author> <title> Efficient Management of Parallelism in Object-Oriented Numerical Software Libraries, in Modern Software Tools in Scientific Computing, </title> <editor> E. Arge, A. M. Bruaset, and H. P. Langtangen, eds., </editor> <publisher> Birkhauser Press, </publisher> <year> 1997. </year> <note> To appear (Also Argonne National Laboratory Mathematics and Computer Science Division preprint P634-0197). </note>
Reference-contexts: Support for global communication in the form of parallel transpose routines is under future work. The transposes may be implemented in a code outside the RSL framework by calling MPI directly. The interested reader may also wish to consider routines in the PETSc tools package <ref> [1] </ref>. Continuing RSL development focuses on the FLIC source translation software, which is based on a full Fortran-parser front-end and application specific back-end software, to generate distributed-memory code mapped transparently onto the RSL library from original model source code [7].
Reference: [2] <author> I. Foster and J. Michalakes, MPMM: </author> <title> A Massively Parallel Mesoscale Model, </title> <booktitle> in Parallel Supercomputing in Atmospheric Science, </booktitle> <editor> G.-R. Hoffmann and T. Kauranne, eds., </editor> <publisher> World Scientific, </publisher> <address> River Edge, NJ 07661, </address> <year> 1993, </year> <pages> pp. 354-363. </pages>
Reference-contexts: Ability to read and write ordinary Fortran record-blocked serial data sets, allow ing the parallel code to use native data sets. MPMM and MM90, parallel versions of the Penn State/NCAR Mesoscale Model MM5 were parallelized using RSL <ref> [2, 3, 4, 8] </ref>. At the present time, RSL is applicable only to models using explicit solvers. Support for global communication in the form of parallel transpose routines is under future work. The transposes may be implemented in a code outside the RSL framework by calling MPI directly.
Reference: [3] <author> G. A. Grell, J. Dudhia, and D. R. Stauffer, </author> <title> A Description of the Fifth-Generation Penn State/NCAR Mesoscale Model (MM5), </title> <type> Tech. Rep. </type> <institution> NCAR/TN-398+STR, National Center for Atmospheric Research, Boulder, Colorado, </institution> <month> June </month> <year> 1994. </year> <month> 38 </month>
Reference-contexts: Ability to read and write ordinary Fortran record-blocked serial data sets, allow ing the parallel code to use native data sets. MPMM and MM90, parallel versions of the Penn State/NCAR Mesoscale Model MM5 were parallelized using RSL <ref> [2, 3, 4, 8] </ref>. At the present time, RSL is applicable only to models using explicit solvers. Support for global communication in the form of parallel transpose routines is under future work. The transposes may be implemented in a code outside the RSL framework by calling MPI directly. <p> For this implementation, atmospheric dynamics is nonhydrostatic and uses finite-difference approximation. Physics includes the Blackadar high-resolution planetary boundary layer scheme, the Grell cumulus scheme, explicit moisture with treatment of mixed-phase processes (ice), shallow convection, dry convective adjustment, and the Dud-hia long- and short-wave radiation scheme <ref> [3] </ref>. MM5 was first converted to column-callable form and then parallelized using the first generation of RSL. MPMM, as the parallel version is called (for Massively Parallel Mesoscale Model), was validated and benchmarked on the IBM SP1 and SP2.
Reference: [4] <author> P. L. Haagenson, J. Dudhia, G. A. Grell, and D. R. Stauffer, </author> <title> The Penn State/NCAR Mesoscale Model (MM5), Source Code Documentation, </title> <type> Tech. Rep. </type> <institution> NCAR/TN-328+STR, National Center for Atmospheric Research, Boulder, Colorado, </institution> <month> March </month> <year> 1994. </year>
Reference-contexts: Ability to read and write ordinary Fortran record-blocked serial data sets, allow ing the parallel code to use native data sets. MPMM and MM90, parallel versions of the Penn State/NCAR Mesoscale Model MM5 were parallelized using RSL <ref> [2, 3, 4, 8] </ref>. At the present time, RSL is applicable only to models using explicit solvers. Support for global communication in the form of parallel transpose routines is under future work. The transposes may be implemented in a code outside the RSL framework by calling MPI directly.
Reference: [5] <author> R. Hempel and H. Ritzdorf, </author> <title> The GMD communications library for grid-oriented problems, </title> <type> Tech. Rep. </type> <institution> GMD-0589, German National Research Center for Information Technology, </institution> <year> 1991. </year>
Reference-contexts: Section 5 walks through the parallelization of a simple relaxation code using RSL. Section 6 discusses the implementation of a MM5 using RSL. Section 7 presents conclusions and directions for future work. 2 Related Work RSL is similar to efforts of a number of other groups, particularly Comlib <ref> [5] </ref>, LAPRX [6], and NNT/SMS [9], in that it provides high-level, efficient mechanisms for performing data-parallel computations over multiple interrelated grids. Like the LAPRX software abstractions, RSL is able to support dynamic load balancing, efficient intergrid communication, irregularly shaped logical domains, and irregularly shaped processor subdomains.
Reference: [6] <author> S. R. Kohn and S. B. Baden, </author> <title> A Parallel Software Infrastructure for Structured Adaptive Mesh Methods, </title> <booktitle> in Proceedings of Supercomputing '95, </booktitle> <publisher> IEEE Computer Society Press, </publisher> <year> 1996. </year>
Reference-contexts: Section 6 discusses the implementation of a MM5 using RSL. Section 7 presents conclusions and directions for future work. 2 Related Work RSL is similar to efforts of a number of other groups, particularly Comlib [5], LAPRX <ref> [6] </ref>, and NNT/SMS [9], in that it provides high-level, efficient mechanisms for performing data-parallel computations over multiple interrelated grids. Like the LAPRX software abstractions, RSL is able to support dynamic load balancing, efficient intergrid communication, irregularly shaped logical domains, and irregularly shaped processor subdomains.
Reference: [7] <author> J. Michalakes, FLIC: </author> <title> A Translator for Same-source Parallel Implementation of Regular Grid Applications, </title> <type> Tech. Rep. </type> <institution> ANL/MCS-TM-223, Mathematics and Computer Science Division, Argonne National Laboratory, Argonne, Illinois, </institution> <month> March </month> <year> 1997. </year>
Reference-contexts: Continuing RSL development focuses on the FLIC source translation software, which is based on a full Fortran-parser front-end and application specific back-end software, to generate distributed-memory code mapped transparently onto the RSL library from original model source code <ref> [7] </ref>.
Reference: [8] <author> J. Michalakes, T. Canfield, R. Nanjundiah, and S. Hammond, </author> <title> Parallel Implementation, Validation, and Performance of MM5, </title> <booktitle> in Coming of Age: Proceedings of the Sixth ECMWF Workshop on the Use of Parallel Procesors in Meteorology, World Scientific, </booktitle> <address> River Edge, NJ, </address> <year> 1995, </year> <pages> pp. 266-276. </pages>
Reference-contexts: Ability to read and write ordinary Fortran record-blocked serial data sets, allow ing the parallel code to use native data sets. MPMM and MM90, parallel versions of the Penn State/NCAR Mesoscale Model MM5 were parallelized using RSL <ref> [2, 3, 4, 8] </ref>. At the present time, RSL is applicable only to models using explicit solvers. Support for global communication in the form of parallel transpose routines is under future work. The transposes may be implemented in a code outside the RSL framework by calling MPI directly. <p> It has since been ported to the Intel Paragon, Cray T3D, Fujutsu AP1000, Silicon Graphics Power Challenge, and networks of workstations using MPI. Performance of 1.2 Gflops has been generated for a single domain problem running on 64 SP1 processors. Additional information regarding the parallel MM5 is available in <ref> [8] </ref> and on the World Wide Web at the location http://www.mcs.anl.gov/Projects/mpmm/index.html. 23 after 50 iterations of the main loop, plotted as 2D density plots. The value of each point is represented by shades of grey.
Reference: [9] <author> B. Rodriguez, L. Hart, and T. Henderson, </author> <title> A Library for the Portable Parall-lelization of Operational Weather Forecast Models, </title> <booktitle> in Coming of Age: Proceedings of the Sixth ECMWF Workshop on the Use of Parallel Procesors in Meteorology, World Scientific, </booktitle> <address> River Edge, NJ, </address> <year> 1995, </year> <pages> pp. 148-161. 39 </pages>
Reference-contexts: Section 6 discusses the implementation of a MM5 using RSL. Section 7 presents conclusions and directions for future work. 2 Related Work RSL is similar to efforts of a number of other groups, particularly Comlib [5], LAPRX [6], and NNT/SMS <ref> [9] </ref>, in that it provides high-level, efficient mechanisms for performing data-parallel computations over multiple interrelated grids. Like the LAPRX software abstractions, RSL is able to support dynamic load balancing, efficient intergrid communication, irregularly shaped logical domains, and irregularly shaped processor subdomains.
References-found: 9

