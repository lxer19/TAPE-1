URL: http://www.cs.gmu.edu:80/research/gag/papers/ijcai95.ps
Refering-URL: http://www.cs.gmu.edu:80/research/gag/pubs.html
Root-URL: 
Title: Hybrid Learning Using Genetic Algorithms and Decision Trees for Pattern Classification  
Author: J. Bala, J. Huang and H. Vafaie K. DeJong and H. Wechsler 
Address: Fairfax, VA 22030  Fairfax, VA 22030  
Affiliation: School of Information Technology and Engineering George Mason University  Department of Computer Science George Mason University  
Date: August 19-25, 1995  
Note: IJCAI conference, Montreal,  
Abstract: This paper introduces a hybrid learning methodology that integrates genetic algorithms (GAs) and decision tree learning (ID3) in order to evolve optimal subsets of discriminatory features for robust pattern classification. A GA is used to search the space of all possible subsets of a large set of candidate discrimination features. For a given feature subset, ID3 is invoked to produce a decision tree. The classification performance of the decision tree on unseen data is used as a measure of fitness for the given feature set, which, in turn, is used by the GA to evolve better feature sets. This GA-ID3 process iterates until a feature subset is found with satisfactory classification performance. Experimental results are presented which illustrate the feasibility of our approach on difficult problems involving recognizing visual concepts in satellite and facial image data. The results also show improved classification performance and reduced description complexity when compared against standard methods for feature selection.
Abstract-found: 1
Intro-found: 1
Reference: [Bala et al, 1996] <author> J. Bala, P. Pachowicz, and K. De Jong, </author> <title> Multistrategy Learning from Engineering Data by Integrating Inductive Generalization and Genetic Algorithms, in Machine Learning: A Multistrategy Approach, Vol. IV, R.S. </title> <editor> Michalski and G. Tecuci (Eds.), </editor> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA., </address> <pages> pp. 121-138, </pages> <year> 1994. </year>
Reference: [Gruau and Whitley, 1993] <author> F. Gruau and D. Whitley, </author> <title> Adding Learning to the Cellular Development of Neural Networks: Evolution and the Baldwin Effect, Evolutionary Computation, </title> <journal> Vol.1, </journal> <volume> No.3, </volume> <pages> pp. 213-234, </pages> <year> 1993. </year>
Reference-contexts: Learning systems that employ several strategies can potentially offer significant advantages over singlestrategy systems. Since the type of input and acquired knowledge are more flexible, such hybrid systems can be applied to a wider range of problems. Examples of such integration include combinations of genetic algorithms and neural networks <ref> [Gruau and Whitley, 1993] </ref> and genetic algorithms and rule-based systems [Bala et al, 1994] [Vafaie and De Jong, 1994].
Reference: [Grefenstette et al, 1991] <author> J. Grefenstette, L. David and D. Cerys, </author> <title> Genesis and OOGA: Two Genetic Algorithms System, TSP: </title> <address> Melorse, MA, </address> <year> 1991. </year>
Reference: [Hinton and Nowlan, 1987] <author> G. E Hinton and S. J. Nolan, </author> <title> How Learning Can Guide Evolution, </title> <journal> Complex Systems, </journal> <volume> Vol.1, </volume> <pages> pp. 495-502, </pages> <year> 1987. </year>
Reference-contexts: The integration of genetic algorithms and decision tree learning advocated in this paper is also part of a broader issue being actively explored, namely, that evolution and learning can work synergistically <ref> [Hinton and Nowlan, 1987] </ref>. The ability to learn can be shown to ease the burden on evolution. Evolution (genotype learning) only has to get close to the goal; (phenotype) learning can then fine tune the behavior [Muhlenbein and Kinderman, 1989].
Reference: [Linsker, 1988] <author> R. Linsker, </author> <title> Self-Organization in a Perceptual Network, </title> <journal> Computer, </journal> <volume> Vol. 21, No. 3, </volume> <pages> pp. 105-117, </pages> <year> 1988. </year>
Reference: [Michalski, 1994] <author> R. Michalski, </author> <title> Inferential Theory of Learning: Developing Foundations for Multistrategy Learning, in Machine Learning: A Multistrategy Approach, Vol. IV, R.S. </title> <editor> Michalski and G. Tecuci (Eds.), </editor> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA., </address> <pages> pp. 3-61, </pages> <year> 1994. </year>
Reference-contexts: Large feature sets with noisy numerical data also provide considerable difficulty for traditional symbolic inductive learning systems. The running time of the learning system and the accuracy and complexity of the output rapidly fall below an acceptable level. The rationale behind our approach is the belief <ref> [Michalski, 1994] </ref> that further advances in pattern analysis and classification require the integration of various learning processes in a modular fashion. Learning systems that employ several strategies can potentially offer significant advantages over singlestrategy systems.
Reference: [Muhlenbein and Kinderman, 1989] <author> H. Muhlenbein, and J. Kinderman, </author> <title> The dynamics of Evolution and Learning. Toward Genetic Neural Networks, </title> <editor> in R. Pfeifer, Z. Schreter, F. Fogelman-Soulie, and L. Steels, </editor> <booktitle> Connectionism in Perspective, </booktitle> <publisher> Elsevier Science, </publisher> <pages> pp. 173-197, </pages> <year> 1989. </year>
Reference-contexts: The ability to learn can be shown to ease the burden on evolution. Evolution (genotype learning) only has to get close to the goal; (phenotype) learning can then fine tune the behavior <ref> [Muhlenbein and Kinderman, 1989] </ref>. Although Darwinian theory does not allow for the inheritance of acquired characteristics (Lamarckian evolution), learning (acquired behaviors) can still influence the course of evolution.
Reference: [Quinlan, 1986] <author> J. R. Quinlan, </author> <title> The Effect of Noise on Concept Learning, in Machine Learning: an Artificial Intelligence Approach, R.S. </title> <editor> Michalski, J.G. Carbonell and T.M. Mitchell (Eds.), </editor> <publisher> Morgan Kaufmann publishers, </publisher> <address> San Mateo, CA, </address> <pages> pp. 149-166, </pages> <year> 1986. </year>
Reference-contexts: In order to test our ideas we have implemented a prototype version of the system. For the GA component, we used without modification GENESIS [Grefenstette, 1991], a standard GA implementation. Similarly, we used without modification C4.5, a standard implementation of ID3 <ref> [Quinlan, 1986] </ref>, to build up the decision trees for the evaluation procedure. For both components, standard default parameter settings from the literature were used.
Reference: [Vafaie and De Jong, 1994] <author> H. Vafaie and K. De Jong, </author> <title> Improving a Rule Induction System Using Genetic Algorithms, in Machine Learning: A Multistrategy Approach, Vol. IV, R.S. </title> <editor> Michalski and G. Tecuci (Eds.), </editor> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA., </address> <pages> pp. 453-469, </pages> <year> 1994. </year>
Reference-contexts: Since the type of input and acquired knowledge are more flexible, such hybrid systems can be applied to a wider range of problems. Examples of such integration include combinations of genetic algorithms and neural networks [Gruau and Whitley, 1993] and genetic algorithms and rule-based systems [Bala et al, 1994] <ref> [Vafaie and De Jong, 1994] </ref>. The integration of genetic algorithms and inductive decision tree learning for optimal feature selection and pattern classification is a novel application of such an approach and is the topic of this paper.
Reference: [Wechsler, 1993] <author> H. Wechsler, </author> <title> APerspective on Evolution and the Lamarckian Hypothesis Using artificial Worlds and Genetic Algorithms, </title> <journal> Revue Internationale de Systemique, </journal> <volume> Vol. 7, No. 5, </volume> <pages> pp. 573-592, </pages> <year> 1993. </year>
Reference-contexts: One can gain a further perspective on the Lamarckian hypothesis by moving up from the individual chromosome (agent) to ecosystems (species) and addressing cultural evolution as well <ref> [Wechsler, 1993] </ref>. 3 GA-ID3 Hybrid Learning The basic idea of our hybrid system is to use GAs to efficiently explore the space of all possible subsets of a given feature set in order to find feature subsets which are of low order and high discriminatory power.
Reference: [Whitley et al, 1994] <author> D. Whitley, V. S. Gordon, and K. Mathias, </author> <title> Lamarckian Evolution, the Baldwin Effect, and Function Optimization, </title> <editor> in Y. Davidor, H.P. Schwefel, and R. Manner (Eds.), </editor> <booktitle> Parallel Problem Solving from Nature PPSN III, </booktitle> <publisher> Springer Verlag, </publisher> <pages> pp. 6-15, </pages> <year> 1994. </year>
Reference-contexts: The Baldwin effect where local search is employed to change the fitness of strings, but the acquired improvements do not change the genetic encoding of the individual is under active study <ref> [Whitley et al, 1994] </ref>.
References-found: 11

